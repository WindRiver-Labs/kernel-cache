From 189df83310ee4fd383998e3bc0399cb108d937ca Mon Sep 17 00:00:00 2001
From: Lans Zhang <jia.zhang@windriver.com>
Date: Mon, 5 Jan 2015 09:54:33 +0800
Subject: [PATCH 10/31] Enable Quark SCH GPIO.

source: Intel quark BSP release 1.1.0-rc2

Signed-off-by: Lans Zhang <jia.zhang@windriver.com>
---
 drivers/gpio/Kconfig    |    5 +-
 drivers/gpio/gpio-sch.c |  783 +++++++++++++++++++++++++++++++++++++++++------
 2 files changed, 687 insertions(+), 101 deletions(-)

diff --git a/drivers/gpio/Kconfig b/drivers/gpio/Kconfig
index 573c449..1d68a96 100644
--- a/drivers/gpio/Kconfig
+++ b/drivers/gpio/Kconfig
@@ -245,13 +245,14 @@ config GPIO_VR41XX
 	  Say yes here to support the NEC VR4100 series General-purpose I/O Uint
 
 config GPIO_SCH
-	tristate "Intel SCH/TunnelCreek/Centerton GPIO"
+	tristate "Intel SCH/TunnelCreek/Centerton/Quark GPIO"
 	depends on PCI && X86
 	select MFD_CORE
 	select LPC_SCH
 	help
 	  Say yes here to support GPIO interface on Intel Poulsbo SCH,
-	  Intel Tunnel Creek processor or Intel Centerton processor.
+	  Intel Tunnel Creek processor, Intel Centerton processor or Intel
+	  Quark.
 	  The Intel SCH contains a total of 14 GPIO pins. Ten GPIOs are
 	  powered by the core power rail and are turned off during sleep
 	  modes (S3 and higher). The remaining four GPIOs are powered by
diff --git a/drivers/gpio/gpio-sch.c b/drivers/gpio/gpio-sch.c
index 90785f8..70e588d 100644
--- a/drivers/gpio/gpio-sch.c
+++ b/drivers/gpio/gpio-sch.c
@@ -26,8 +26,13 @@
 #include <linux/acpi.h>
 #include <linux/platform_device.h>
 #include <linux/pci_ids.h>
+#include <linux/uio_driver.h>
 
 #include <linux/gpio.h>
+#include <linux/interrupt.h>
+#include <linux/irq.h>
+#include <linux/bitmap.h>
+#include <linux/types.h>
 
 static DEFINE_SPINLOCK(gpio_lock);
 
@@ -35,107 +40,189 @@ static DEFINE_SPINLOCK(gpio_lock);
 #define CGIO	(0x04)
 #define CGLV	(0x08)
 
+#define CGTPE  (0x0C)
+#define CGTNE  (0x10)
+#define CGGPE  (0x14)
+#define CGSMI  (0x18)
+#define CGTS   (0x1C)
+
 #define RGEN	(0x20)
 #define RGIO	(0x24)
 #define RGLV	(0x28)
 
-static unsigned short gpio_ba;
+#define RGTPE   (0x2C)
+#define RGTNE   (0x30)
+#define RGGPE   (0x34)
+#define RGSMI   (0x38)
+#define RGTS    (0x3C)
 
-void sch_gpio_resume_set_enable(unsigned gpio_num, int val)
+#define CGNMIEN (0x40)
+#define RGNMIEN (0x44)
+
+#define RESOURCE_IRQ    9
+
+/* Maximum number of resume GPIOS supported by this driver */
+#define MAX_GPIO_IRQS   9
+
+static unsigned long gpio_ba;
+
+static struct uio_info *info;
+
+static int irq_num;
+
+struct sch_gpio_core_int_regvals {
+	u32 cgen;
+	u32 cgio;
+	u32 cglvl;
+	u32 cgtpe;
+	u32 cgtne;
+	u32 cggpe;
+	u32 cgsmi;
+	u32 cgnmien;
+};
+
+struct sch_gpio {
+	int irq_base_core;
+	struct sch_gpio_core_int_regvals	lp_core;
+	int irq_base_resume;
+	DECLARE_BITMAP(wake_irqs, MAX_GPIO_IRQS);
+};
+
+static struct sch_gpio *chip_ptr;
+
+static void qrk_gpio_restrict_release(struct device *dev) {}
+static struct platform_device qrk_gpio_restrict_pdev = {
+	.name   = "qrk-gpio-restrict-nc",
+	.dev.release = qrk_gpio_restrict_release,
+};
+
+static void sch_gpio_reg_clear_if_set(unsigned short reg,
+					unsigned short gpio_num)
 {
-	u8 curr_en;
+	u8 curr_dirs;
 	unsigned short offset, bit;
 
-	spin_lock(&gpio_lock);
-
-	offset = RGEN + gpio_num / 8;
+	offset = reg + gpio_num / 8;
 	bit = gpio_num % 8;
 
-	curr_en = inb(gpio_ba + offset);
-
-	if (val) {
-		if (!(curr_en & (1 << bit)))
-			outb(curr_en | (1 << bit), gpio_ba + offset);
-	} else {
-		if ((curr_en & (1 << bit)))
-			outb(curr_en & ~(1 << bit), gpio_ba + offset);
-	}
+	curr_dirs = inb(gpio_ba + offset);
 
-	spin_unlock(&gpio_lock);
+	if (curr_dirs & (1 << bit))
+		outb(curr_dirs & ~(1 << bit), gpio_ba + offset);
 }
-EXPORT_SYMBOL_GPL(sch_gpio_resume_set_enable);
 
-static int sch_gpio_core_direction_in(struct gpio_chip *gc, unsigned  gpio_num)
+static void sch_gpio_reg_set_if_clear(unsigned short reg,
+					unsigned short gpio_num)
 {
 	u8 curr_dirs;
 	unsigned short offset, bit;
 
-	spin_lock(&gpio_lock);
-
-	offset = CGIO + gpio_num / 8;
+	offset = reg + gpio_num / 8;
 	bit = gpio_num % 8;
 
 	curr_dirs = inb(gpio_ba + offset);
 
 	if (!(curr_dirs & (1 << bit)))
 		outb(curr_dirs | (1 << bit), gpio_ba + offset);
+}
 
-	spin_unlock(&gpio_lock);
-	return 0;
+static void sch_gpio_reg_set(unsigned short reg, unsigned short gpio_num,
+				int val)
+{
+	u8 curr_dirs;
+	unsigned short offset, bit;
+
+	offset = reg + gpio_num / 8;
+	bit = gpio_num % 8;
+
+	curr_dirs = inb(gpio_ba + offset);
+
+	if (val)
+		outb(curr_dirs | (1 << bit), gpio_ba + offset);
+	else
+		outb(curr_dirs & ~(1 << bit), gpio_ba + offset);
 }
 
-static int sch_gpio_core_get(struct gpio_chip *gc, unsigned gpio_num)
+static unsigned short sch_gpio_reg_get(unsigned short reg,
+					unsigned short gpio_num)
 {
-	int res;
+	u8 curr_dirs;
 	unsigned short offset, bit;
 
-	offset = CGLV + gpio_num / 8;
+	offset = reg + gpio_num / 8;
 	bit = gpio_num % 8;
 
-	res = !!(inb(gpio_ba + offset) & (1 << bit));
-	return res;
+	curr_dirs = !!(inb(gpio_ba + offset) & (1 << bit));
+
+	return curr_dirs;
 }
 
-static void sch_gpio_core_set(struct gpio_chip *gc, unsigned gpio_num, int val)
+void sch_gpio_resume_set_enable(unsigned gpio_num, int val)
 {
-	u8 curr_vals;
+	u8 curr_en;
 	unsigned short offset, bit;
 
 	spin_lock(&gpio_lock);
 
-	offset = CGLV + gpio_num / 8;
+	offset = RGEN + gpio_num / 8;
 	bit = gpio_num % 8;
 
-	curr_vals = inb(gpio_ba + offset);
+	curr_en = inb(gpio_ba + offset);
+
+	if (val) {
+		if (!(curr_en & (1 << bit)))
+			outb(curr_en | (1 << bit), gpio_ba + offset);
+	} else {
+		if ((curr_en & (1 << bit)))
+			outb(curr_en & ~(1 << bit), gpio_ba + offset);
+	}
 
-	if (val)
-		outb(curr_vals | (1 << bit), gpio_ba + offset);
-	else
-		outb((curr_vals & ~(1 << bit)), gpio_ba + offset);
 	spin_unlock(&gpio_lock);
 }
+EXPORT_SYMBOL_GPL(sch_gpio_resume_set_enable);
 
-static int sch_gpio_core_direction_out(struct gpio_chip *gc,
-					unsigned gpio_num, int val)
+static int sch_gpio_core_direction_in(struct gpio_chip *gc, unsigned  gpio_num)
 {
-	u8 curr_dirs;
-	unsigned short offset, bit;
+	unsigned long flags = 0;
+	spin_lock_irqsave(&gpio_lock, flags);
+	sch_gpio_reg_set_if_clear(CGIO, gpio_num);
+	spin_unlock_irqrestore(&gpio_lock, flags);
 
-	sch_gpio_core_set(gc, gpio_num, val);
+	return 0;
+}
 
-	spin_lock(&gpio_lock);
+static int sch_gpio_core_get(struct gpio_chip *gc, unsigned gpio_num)
+{
+	int res;
+	res = sch_gpio_reg_get(CGLV, gpio_num);
 
-	offset = CGIO + gpio_num / 8;
-	bit = gpio_num % 8;
+	return res;
+}
 
-	curr_dirs = inb(gpio_ba + offset);
-	if (curr_dirs & (1 << bit))
-		outb(curr_dirs & ~(1 << bit), gpio_ba + offset);
+static void sch_gpio_core_set(struct gpio_chip *gc, unsigned gpio_num, int val)
+{
+	unsigned long flags = 0;
+	spin_lock_irqsave(&gpio_lock, flags);
+	sch_gpio_reg_set(CGLV, gpio_num, val);
+	spin_unlock_irqrestore(&gpio_lock, flags);
+}
+
+static int sch_gpio_core_direction_out(struct gpio_chip *gc,
+					unsigned gpio_num, int val)
+{
+	unsigned long flags = 0;
+	spin_lock_irqsave(&gpio_lock, flags);
+	sch_gpio_reg_clear_if_set(CGIO, gpio_num);
+	spin_unlock_irqrestore(&gpio_lock, flags);
 
-	spin_unlock(&gpio_lock);
 	return 0;
 }
 
+static int sch_gpio_core_to_irq(struct gpio_chip *gc, unsigned offset)
+{
+	return chip_ptr->irq_base_core + offset;
+}
+
 static struct gpio_chip sch_gpio_core = {
 	.label			= "sch_gpio_core",
 	.owner			= THIS_MODULE,
@@ -143,78 +230,209 @@ static struct gpio_chip sch_gpio_core = {
 	.get			= sch_gpio_core_get,
 	.direction_output	= sch_gpio_core_direction_out,
 	.set			= sch_gpio_core_set,
+	.to_irq			= sch_gpio_core_to_irq,
 };
 
-static int sch_gpio_resume_direction_in(struct gpio_chip *gc,
-					unsigned gpio_num)
+static void sch_gpio_core_irq_enable(struct irq_data *d)
 {
-	u8 curr_dirs;
-	unsigned short offset, bit;
+	u32 gpio_num = 0;
 
-	spin_lock(&gpio_lock);
+	gpio_num = d->irq - chip_ptr->irq_base_core;
+	sch_gpio_reg_set_if_clear(CGGPE, gpio_num);
+}
 
-	offset = RGIO + gpio_num / 8;
-	bit = gpio_num % 8;
+static void sch_gpio_core_irq_disable(struct irq_data *d)
+{
+	unsigned long flags = 0;
+	u32 gpio_num = 0;
 
-	curr_dirs = inb(gpio_ba + offset);
+	gpio_num = d->irq - chip_ptr->irq_base_core;
 
-	if (!(curr_dirs & (1 << bit)))
-		outb(curr_dirs | (1 << bit), gpio_ba + offset);
+	spin_lock_irqsave(&gpio_lock, flags);
+	sch_gpio_reg_clear_if_set(CGGPE, gpio_num);
+	sch_gpio_reg_clear_if_set(CGTPE, gpio_num);
+	sch_gpio_reg_clear_if_set(CGTNE, gpio_num);
+	outb(BIT(gpio_num), gpio_ba + CGTS);
+	spin_unlock_irqrestore(&gpio_lock, flags);
+}
 
-	spin_unlock(&gpio_lock);
-	return 0;
+static void sch_gpio_core_irq_ack(struct irq_data *d)
+{
+	u32 gpio_num = 0;
+
+	gpio_num = d->irq - chip_ptr->irq_base_core;
+	outb(BIT(gpio_num), gpio_ba + CGTS);
 }
 
-static int sch_gpio_resume_get(struct gpio_chip *gc, unsigned gpio_num)
+static int sch_gpio_core_irq_type(struct irq_data *d, unsigned type)
 {
-	unsigned short offset, bit;
+	int ret = 0;
+	unsigned long flags = 0;
+	u32 gpio_num = 0;
 
-	offset = RGLV + gpio_num / 8;
-	bit = gpio_num % 8;
+	if (NULL == d) {
+		pr_err("%s(): null irq_data\n",  __func__);
+		return -EFAULT;
+	}
+
+	gpio_num = d->irq - chip_ptr->irq_base_core;
+
+	spin_lock_irqsave(&gpio_lock, flags);
+
+	switch (type) {
+	case IRQ_TYPE_EDGE_RISING:
+		sch_gpio_reg_clear_if_set(CGTNE, gpio_num);
+		sch_gpio_reg_set_if_clear(CGTPE, gpio_num);
+		break;
+	case IRQ_TYPE_EDGE_FALLING:
+		sch_gpio_reg_clear_if_set(CGTPE, gpio_num);
+		sch_gpio_reg_set_if_clear(CGTNE, gpio_num);
+		break;
+	case IRQ_TYPE_EDGE_BOTH:
+		sch_gpio_reg_set_if_clear(CGTPE, gpio_num);
+		sch_gpio_reg_set_if_clear(CGTNE, gpio_num);
+		break;
+	case IRQ_TYPE_NONE:
+		sch_gpio_reg_clear_if_set(CGTPE, gpio_num);
+		sch_gpio_reg_clear_if_set(CGTNE, gpio_num);
+		break;
+	default:
+		ret = -EINVAL;
+	break;
+	}
 
-	return !!(inb(gpio_ba + offset) & (1 << bit));
+	spin_unlock_irqrestore(&gpio_lock, flags);
+
+	return ret;
 }
 
-static void sch_gpio_resume_set(struct gpio_chip *gc,
-				unsigned gpio_num, int val)
+static struct irq_chip sch_irq_core = {
+	.irq_ack		= sch_gpio_core_irq_ack,
+	.irq_set_type	   = sch_gpio_core_irq_type,
+	.irq_enable	     = sch_gpio_core_irq_enable,
+	.irq_disable	    = sch_gpio_core_irq_disable,
+};
+
+static void sch_gpio_core_irqs_init(struct sch_gpio *chip, unsigned int num)
 {
-	u8 curr_vals;
-	unsigned short offset, bit;
+	int i;
+
+	for (i = 0; i < num; i++) {
+		irq_set_chip_data(i + chip->irq_base_core, chip);
+		irq_set_chip_and_handler_name(i + chip->irq_base_core,
+						&sch_irq_core,
+						handle_edge_irq,
+						"sch_gpio_irq_core");
+	}
+}
 
-	spin_lock(&gpio_lock);
+static void sch_gpio_core_irqs_deinit(struct sch_gpio *chip, unsigned int num)
+{
+	int i;
 
-	offset = RGLV + gpio_num / 8;
-	bit = gpio_num % 8;
+	for (i = 0; i < num; i++) {
+		irq_set_chip_data(i + chip->irq_base_core, 0);
+		irq_set_chip_and_handler_name(i + chip->irq_base_core,
+						0, 0, 0);
+	}
+}
 
-	curr_vals = inb(gpio_ba + offset);
+static void sch_gpio_core_irq_disable_all(struct sch_gpio *chip,
+						unsigned int num)
+{
+	unsigned long flags = 0;
+	u32 gpio_num = 0;
+
+	spin_lock_irqsave(&gpio_lock, flags);
+
+	for (gpio_num = 0; gpio_num < num; gpio_num++) {
+		sch_gpio_reg_clear_if_set(CGTPE, gpio_num);
+		sch_gpio_reg_clear_if_set(CGTNE, gpio_num);
+		sch_gpio_reg_clear_if_set(CGGPE, gpio_num);
+		sch_gpio_reg_clear_if_set(CGSMI, gpio_num);
+		sch_gpio_reg_clear_if_set(CGNMIEN, gpio_num);
+		/* clear any pending interrupt */
+		sch_gpio_reg_set(CGTS, gpio_num, 1);
+	}
 
-	if (val)
-		outb(curr_vals | (1 << bit), gpio_ba + offset);
-	else
-		outb((curr_vals & ~(1 << bit)), gpio_ba + offset);
+	spin_unlock_irqrestore(&gpio_lock, flags);
 
-	spin_unlock(&gpio_lock);
 }
 
-static int sch_gpio_resume_direction_out(struct gpio_chip *gc,
-					unsigned gpio_num, int val)
+void sch_gpio_core_save_state(struct sch_gpio_core_int_regvals *regs)
 {
-	u8 curr_dirs;
-	unsigned short offset, bit;
+	 unsigned long flags = 0;
+	 spin_lock_irqsave(&gpio_lock, flags);
+
+	 regs->cgen      = inl(gpio_ba + CGEN);
+	 regs->cgio      = inl(gpio_ba + CGIO);
+	 regs->cglvl     = inl(gpio_ba + CGLV);
+	 regs->cgtpe     = inl(gpio_ba + CGTPE);
+	 regs->cgtne     = inl(gpio_ba + CGTNE);
+	 regs->cggpe     = inl(gpio_ba + CGGPE);
+	 regs->cgsmi     = inl(gpio_ba + CGSMI);
+	 regs->cgnmien   = inl(gpio_ba + CGNMIEN);
+
+	 spin_unlock_irqrestore(&gpio_lock, flags);
+}
 
-	sch_gpio_resume_set(gc, gpio_num, val);
+void sch_gpio_core_restore_state(struct sch_gpio_core_int_regvals *regs)
+{
+	 unsigned long flags = 0;
+	 spin_lock_irqsave(&gpio_lock, flags);
+
+	 outl(regs->cgio, gpio_ba + CGIO);
+	 outl(regs->cglvl, gpio_ba + CGLV);
+	 outl(regs->cgtpe, gpio_ba + CGTPE);
+	 outl(regs->cgtne, gpio_ba + CGTNE);
+	 outl(regs->cggpe, gpio_ba + CGGPE);
+	 outl(regs->cgsmi, gpio_ba + CGSMI);
+	 outl(regs->cgnmien, gpio_ba + CGNMIEN);
+	 outl(regs->cgen, gpio_ba + CGEN);
+
+	 spin_unlock_irqrestore(&gpio_lock, flags);
+}
 
-	offset = RGIO + gpio_num / 8;
-	bit = gpio_num % 8;
+static int sch_gpio_resume_direction_in(struct gpio_chip *gc,
+					     unsigned gpio_num)
+{
+	 unsigned long flags = 0;
+	 spin_lock_irqsave(&gpio_lock, flags);
+	 sch_gpio_reg_set_if_clear(RGIO, gpio_num);
+	 spin_unlock_irqrestore(&gpio_lock, flags);
+	 return 0;
+}
 
-	spin_lock(&gpio_lock);
+static int sch_gpio_resume_get(struct gpio_chip *gc, unsigned gpio_num)
+{
+	 int res;
+	 res = sch_gpio_reg_get(RGLV, gpio_num);
+	 return res;
+}
 
-	curr_dirs = inb(gpio_ba + offset);
-	if (curr_dirs & (1 << bit))
-		outb(curr_dirs & ~(1 << bit), gpio_ba + offset);
+static void sch_gpio_resume_set(struct gpio_chip *gc, unsigned gpio_num,
+					     int val)
+{
+	 unsigned long flags = 0;
+	 spin_lock_irqsave(&gpio_lock, flags);
+	 sch_gpio_reg_set(RGLV, gpio_num, val);
+	 spin_unlock_irqrestore(&gpio_lock, flags);
 
-	spin_unlock(&gpio_lock);
-	return 0;
+}
+
+static int sch_gpio_resume_direction_out(struct gpio_chip *gc,
+					     unsigned gpio_num, int val)
+{
+	 unsigned long flags = 0;
+	 spin_lock_irqsave(&gpio_lock, flags);
+	 sch_gpio_reg_clear_if_set(RGIO, gpio_num);
+	 spin_unlock_irqrestore(&gpio_lock, flags);
+	 return 0;
+}
+
+static int sch_gpio_resume_to_irq(struct gpio_chip *gc, unsigned offset)
+{
+	 return chip_ptr->irq_base_resume + offset;
 }
 
 static struct gpio_chip sch_gpio_resume = {
@@ -224,17 +442,220 @@ static struct gpio_chip sch_gpio_resume = {
 	.get			= sch_gpio_resume_get,
 	.direction_output	= sch_gpio_resume_direction_out,
 	.set			= sch_gpio_resume_set,
+	.to_irq			= sch_gpio_resume_to_irq,
 };
 
+static void sch_gpio_resume_irq_enable(struct irq_data *d)
+{
+	u32 gpio_num = 0;
+
+	gpio_num = d->irq - chip_ptr->irq_base_resume;
+	sch_gpio_reg_set_if_clear(RGGPE, gpio_num);
+}
+
+static void sch_gpio_resume_irq_disable(struct irq_data *d)
+{
+	unsigned long flags = 0;
+	u32 gpio_num = 0;
+
+	gpio_num = d->irq - chip_ptr->irq_base_resume;
+
+	if (!test_bit(gpio_num, chip_ptr->wake_irqs)){
+		spin_lock_irqsave(&gpio_lock, flags);
+		sch_gpio_reg_clear_if_set(RGGPE, gpio_num);
+		sch_gpio_reg_clear_if_set(RGTPE, gpio_num);
+		sch_gpio_reg_clear_if_set(RGTNE, gpio_num);
+		outb(BIT(gpio_num), gpio_ba + RGTS);
+		spin_unlock_irqrestore(&gpio_lock, flags);
+	}
+}
+
+static void sch_gpio_resume_irq_ack(struct irq_data *d)
+{
+	u32 gpio_num = 0;
+
+	gpio_num = d->irq - chip_ptr->irq_base_resume;
+	outb(BIT(gpio_num), gpio_ba + RGTS);
+}
+
+static int sch_gpio_resume_irq_type(struct irq_data *d, unsigned type)
+{
+	int ret = 0;
+	unsigned long flags = 0;
+	u32 gpio_num = 0;
+
+	if (NULL == d) {
+		pr_err("%s(): null irq_data\n",  __func__);
+		return -EFAULT;
+	}
+
+	gpio_num = d->irq - chip_ptr->irq_base_resume;
+
+	spin_lock_irqsave(&gpio_lock, flags);
+
+	switch (type) {
+	case IRQ_TYPE_EDGE_RISING:
+		sch_gpio_reg_clear_if_set(RGTNE, gpio_num);
+		sch_gpio_reg_set_if_clear(RGTPE, gpio_num);
+		break;
+	case IRQ_TYPE_EDGE_FALLING:
+		sch_gpio_reg_clear_if_set(RGTPE, gpio_num);
+		sch_gpio_reg_set_if_clear(RGTNE, gpio_num);
+		break;
+	case IRQ_TYPE_EDGE_BOTH:
+		sch_gpio_reg_set_if_clear(RGTPE, gpio_num);
+		sch_gpio_reg_set_if_clear(RGTNE, gpio_num);
+		break;
+	case IRQ_TYPE_NONE:
+		sch_gpio_reg_clear_if_set(RGTPE, gpio_num);
+		sch_gpio_reg_clear_if_set(RGTNE, gpio_num);
+		break;
+	default:
+		ret = -EINVAL;
+		break;
+	}
+
+	spin_unlock_irqrestore(&gpio_lock, flags);
+
+	return ret;
+}
+
+/*
+ * Enables/Disables power-management wake-on of an IRQ.
+ * Inhibits disabling of the specified IRQ if on != 0.
+ * Make sure you call it via irq_set_irq_wake() with on = 1 during suspend and
+ * with on = 0 during resume.
+ * Returns 0 if success, negative error code otherwhise
+ */
+int sch_gpio_resume_irq_set_wake(struct irq_data *d, unsigned int on)
+{
+	u32 gpio_num = 0;
+	int ret = 0;
+
+	if (NULL == d) {
+		pr_err("%s(): Null irq_data\n", __func__);
+		ret = -EFAULT;
+		goto end;
+	}
+	gpio_num = d->irq - chip_ptr->irq_base_resume;
+	if (gpio_num >= MAX_GPIO_IRQS) {
+		pr_err("%s(): gpio_num bigger(%d) than MAX_GPIO_IRQS(%d)-1\n",
+				__func__, gpio_num, MAX_GPIO_IRQS);
+		ret = -EINVAL;
+		goto end;
+	}
+	if (on)
+		set_bit(gpio_num, chip_ptr->wake_irqs);
+	else
+		clear_bit(gpio_num, chip_ptr->wake_irqs);
+
+end:
+	return ret;
+}
+
+static struct irq_chip sch_irq_resume = {
+	.irq_ack		= sch_gpio_resume_irq_ack,
+	.irq_set_type		= sch_gpio_resume_irq_type,
+	.irq_enable		= sch_gpio_resume_irq_enable,
+	.irq_disable		= sch_gpio_resume_irq_disable,
+	.irq_set_wake		= sch_gpio_resume_irq_set_wake,
+};
+
+static void sch_gpio_resume_irqs_init(struct sch_gpio *chip, unsigned int num)
+{
+	int i;
+
+	for (i = 0; i < num; i++) {
+		irq_set_chip_data(i + chip->irq_base_resume, chip);
+		irq_set_chip_and_handler_name(i + chip->irq_base_resume,
+						&sch_irq_resume,
+						handle_edge_irq,
+						"sch_gpio_irq_resume");
+	}
+}
+
+static void sch_gpio_resume_irqs_deinit(struct sch_gpio *chip, unsigned int num)
+{
+	int i;
+
+	for (i = 0; i < num; i++) {
+		irq_set_chip_data(i + chip->irq_base_core, 0);
+		irq_set_chip_and_handler_name(i + chip->irq_base_core,
+						0, 0, 0);
+	}
+}
+
+static void sch_gpio_resume_irq_disable_all(struct sch_gpio *chip,
+						unsigned int num)
+{
+	unsigned long flags = 0;
+	u32 gpio_num = 0;
+
+	spin_lock_irqsave(&gpio_lock, flags);
+
+	for (gpio_num = 0; gpio_num < num; gpio_num++) {
+		sch_gpio_reg_clear_if_set(RGTPE, gpio_num);
+		sch_gpio_reg_clear_if_set(RGTNE, gpio_num);
+		sch_gpio_reg_clear_if_set(RGGPE, gpio_num);
+		sch_gpio_reg_clear_if_set(RGSMI, gpio_num);
+		sch_gpio_reg_clear_if_set(RGNMIEN, gpio_num);
+		/* clear any pending interrupt */
+		sch_gpio_reg_set(RGTS, gpio_num, 1);
+	}
+
+	spin_unlock_irqrestore(&gpio_lock, flags);
+}
+
+static inline irqreturn_t do_serve_irq(int reg_status, unsigned int irq_base)
+{
+	int ret = IRQ_NONE;
+	u32 pending = 0, gpio = 0;
+
+	/* Which pin (if any) triggered the interrupt */
+	while ((pending = inb(reg_status))) {
+		/* Serve each asserted interrupt */
+		do {
+			gpio = __ffs(pending);
+			generic_handle_irq(irq_base + gpio);
+			pending &= ~BIT(gpio);
+			ret = IRQ_HANDLED;
+		} while (pending);
+	}
+
+	return ret;
+}
+
+static irqreturn_t sch_gpio_irq_handler(int irq, void *dev_id)
+{
+	int ret = IRQ_NONE;
+
+	ret |= do_serve_irq(gpio_ba + CGTS, chip_ptr->irq_base_core);
+	ret |= do_serve_irq(gpio_ba + RGTS, chip_ptr->irq_base_resume);
+
+	return ret;
+}
+
 static int sch_gpio_probe(struct platform_device *pdev)
 {
 	struct resource *res;
+	struct sch_gpio *chip;
 	int err, id;
 
+	chip = kzalloc(sizeof(*chip), GFP_KERNEL);
+	if (chip == NULL)
+		return -ENOMEM;
+
+	chip_ptr = chip;
+
 	id = pdev->id;
 	if (!id)
 		return -ENODEV;
 
+	/* Get UIO memory */
+	info = kzalloc(sizeof(struct uio_info), GFP_KERNEL);
+	if (!info)
+		return -ENOMEM;
+
 	res = platform_get_resource(pdev, IORESOURCE_IO, 0);
 	if (!res)
 		return -EBUSY;
@@ -244,6 +665,8 @@ static int sch_gpio_probe(struct platform_device *pdev)
 
 	gpio_ba = res->start;
 
+	irq_num = RESOURCE_IRQ;
+
 	switch (id) {
 	case PCI_DEVICE_ID_INTEL_SCH_LPC:
 		sch_gpio_core.base = 0;
@@ -277,6 +700,14 @@ static int sch_gpio_probe(struct platform_device *pdev)
 		sch_gpio_resume.ngpio = 9;
 		break;
 
+	case PCI_DEVICE_ID_INTEL_QUARK_X1000_ILB:
+		 sch_gpio_core.base = 0;
+		 sch_gpio_core.ngpio = 2;
+
+		 sch_gpio_resume.base = 2;
+		 sch_gpio_resume.ngpio = 6;
+		 break;
+
 	default:
 		err = -ENODEV;
 		goto err_sch_gpio_core;
@@ -293,49 +724,203 @@ static int sch_gpio_probe(struct platform_device *pdev)
 	if (err < 0)
 		goto err_sch_gpio_resume;
 
+	 chip->irq_base_core = irq_alloc_descs(-1, 0,
+						      sch_gpio_core.ngpio,
+						      NUMA_NO_NODE);
+	 if (chip->irq_base_core < 0) {
+		  dev_err(&pdev->dev, "failure adding GPIO core IRQ descs\n");
+		  chip->irq_base_core = -1;
+		  goto err_sch_intr_core;
+	 }
+
+	 chip->irq_base_resume = irq_alloc_descs(-1, 0,
+						      sch_gpio_resume.ngpio,
+						      NUMA_NO_NODE);
+	 if (chip->irq_base_resume < 0) {
+		  dev_err(&pdev->dev, "failure adding GPIO resume IRQ descs\n");
+		  chip->irq_base_resume = -1;
+		  goto err_sch_intr_resume;
+	 }
+
+	 platform_set_drvdata(pdev, chip);
+
+	 err = platform_device_register(&qrk_gpio_restrict_pdev);
+	 if (err < 0)
+		  goto err_sch_gpio_device_register;
+
+	 /* disable interrupts */
+	 sch_gpio_core_irq_disable_all(chip, sch_gpio_core.ngpio);
+	 sch_gpio_resume_irq_disable_all(chip, sch_gpio_resume.ngpio);
+
+
+	 err = request_irq(irq_num, sch_gpio_irq_handler,
+				    IRQF_SHARED, KBUILD_MODNAME, chip);
+	 if (err != 0) {
+			   dev_err(&pdev->dev,
+				    "%s request_irq failed\n", __func__);
+			   goto err_sch_request_irq;
+	 }
+
+	 sch_gpio_core_irqs_init(chip, sch_gpio_core.ngpio);
+	 sch_gpio_resume_irqs_init(chip, sch_gpio_resume.ngpio);
+
+	 /* UIO */
+	 info->port[0].name = "gpio_regs";
+	 info->port[0].start = res->start;
+	 info->port[0].size = resource_size(res);
+	 info->port[0].porttype = UIO_PORT_X86;
+	 info->name = "sch_gpio";
+	 info->version = "0.0.1";
+
+	 if (uio_register_device(&pdev->dev, info))
+		  goto err_sch_uio_register;
+
+	 pr_info("%s UIO port addr 0x%04x size %lu porttype %d\n",
+		  __func__, (unsigned int)info->port[0].start,
+		  info->port[0].size, info->port[0].porttype);
+
 	return 0;
 
+err_sch_uio_register:
+	 free_irq(irq_num, chip);
+
+err_sch_request_irq:
+	 platform_device_unregister(&qrk_gpio_restrict_pdev);
+
+err_sch_gpio_device_register:
+	 irq_free_descs(chip->irq_base_resume, sch_gpio_resume.ngpio);
+
+err_sch_intr_resume:
+	 irq_free_descs(chip->irq_base_core, sch_gpio_core.ngpio);
+
+err_sch_intr_core:
+	 err = gpiochip_remove(&sch_gpio_resume);
+	 if (err)
+		  dev_err(&pdev->dev, "%s failed, %d\n",
+		  "resume gpiochip_remove()", err);
+
 err_sch_gpio_resume:
 	if (gpiochip_remove(&sch_gpio_core))
-		dev_err(&pdev->dev, "%s gpiochip_remove failed\n", __func__);
+		dev_err(&pdev->dev, "%s core gpiochip_remove failed\n", __func__);
 
 err_sch_gpio_core:
 	release_region(res->start, resource_size(res));
 	gpio_ba = 0;
 
+	kfree(chip);
+	chip_ptr = 0;
+
+	if (info != NULL)
+		kfree(info);
+
 	return err;
 }
 
 static int sch_gpio_remove(struct platform_device *pdev)
 {
+	int err = 0;
 	struct resource *res;
+	struct sch_gpio *chip = platform_get_drvdata(pdev);
+
 	if (gpio_ba) {
-		int err;
 
-		err  = gpiochip_remove(&sch_gpio_core);
+		if (info != NULL) {
+			uio_unregister_device(info);
+			kfree(info);
+		}
+
+		sch_gpio_resume_irqs_deinit(chip, sch_gpio_resume.ngpio);
+		sch_gpio_core_irqs_deinit(chip, sch_gpio_core.ngpio);
+
+		if (irq_num > 0)
+			free_irq(irq_num, chip);
+
+		platform_device_unregister(&qrk_gpio_restrict_pdev);
+
+		irq_free_descs(chip->irq_base_resume,
+				sch_gpio_resume.ngpio);
+
+		irq_free_descs(chip->irq_base_core, sch_gpio_core.ngpio);
+
+		err = gpiochip_remove(&sch_gpio_resume);
 		if (err)
 			dev_err(&pdev->dev, "%s failed, %d\n",
-				"gpiochip_remove()", err);
-		err = gpiochip_remove(&sch_gpio_resume);
+				"resume gpiochip_remove()", err);
+
+		err  = gpiochip_remove(&sch_gpio_core);
 		if (err)
 			dev_err(&pdev->dev, "%s failed, %d\n",
-				"gpiochip_remove()", err);
+				"core gpiochip_remove()", err);
 
 		res = platform_get_resource(pdev, IORESOURCE_IO, 0);
 
 		release_region(res->start, resource_size(res));
 		gpio_ba = 0;
-
-		return err;
 	}
 
+	kfree(chip);
+
+	chip_ptr = 0;
+
+	return err;
+}
+
+/*
+ * Disables IRQ line of Legacy GPIO chip so that its state is not controlled by
+ * PM framework (disabled before calling suspend_noirq callback and re-enabled
+ * after calling resume_noirq callback of devices).
+ */
+static int sch_gpio_suspend_sys(struct device *dev)
+{
+	disable_irq(irq_num);
+	return 0;
+}
+
+/*
+ * Saves the state of configuration registers for Core Well GPIOs.
+ * Don't touch Suspend Well GPIO registers because they are alive and
+ * functional in both S3 and S0 states.
+ */
+static int sch_gpio_suspend_sys_noirq(struct device *dev)
+{
+	sch_gpio_core_save_state(&(chip_ptr->lp_core));
+	return 0;
+}
+
+/*
+ * Restore the Core Well GPIOs configuration registers.
+ */
+static int sch_gpio_resume_sys_noirq(struct device *dev)
+{
+	sch_gpio_core_restore_state(&(chip_ptr->lp_core));
+	return 0;
+}
+
+/*
+ * Re-enables the IRQ line of Legacy GPIO chip.
+ * Done here instead of dpm_resume_no_irq() PM handler in order to be sure that
+ * all the system busses (I2C, SPI) are resumed when the IRQ is fired, otherwise
+ * a SPI or I2C device might fail to handle its own interrupt because the IRQ
+ * handler (bottom half) involves talking to the device.
+ */
+static int sch_gpio_resume_sys(struct device *dev)
+{
+	enable_irq(irq_num);
 	return 0;
 }
 
+const struct dev_pm_ops sch_gpio_pm_ops = {
+	.suspend	= sch_gpio_suspend_sys,
+	.suspend_noirq	= sch_gpio_suspend_sys_noirq,
+	.resume_noirq	= sch_gpio_resume_sys_noirq,
+	.resume		= sch_gpio_resume_sys,
+};
+
 static struct platform_driver sch_gpio_driver = {
 	.driver = {
 		.name = "sch_gpio",
 		.owner = THIS_MODULE,
+		.pm = &sch_gpio_pm_ops,
 	},
 	.probe		= sch_gpio_probe,
 	.remove		= sch_gpio_remove,
-- 
1.7.5.4

