From 79cfcd51a1a166bbe4d776f8b318bedcf4cb2bb1 Mon Sep 17 00:00:00 2001
From: Liwei Song <liwei.song@windriver.com>
Date: Tue, 1 Mar 2016 19:57:49 -0500
Subject: [PATCH 08/11] intel-mcu: enable Intel co-processor support

This patch is from yocto Intel Edison support:
http://downloadmirror.intel.com/25028/eng/edison-src-ww25.5-15.tgz

Intel Edison has a quirk co-procesosr onboard, this driver is use to
enabe the co-processor, and named intel mcu.

Signed-off-by: Liwei Song <liwei.song@windriver.com>
---
 arch/x86/Kconfig                                   |   13 +
 arch/x86/include/asm/bcm_bt_lpm.h                  |   46 +
 arch/x86/include/asm/fixmap.h                      |    1 +
 arch/x86/include/asm/intel-mid.h                   |   70 +
 arch/x86/include/asm/intel_mid_gpadc.h             |   19 +
 arch/x86/include/asm/intel_mid_pcihelpers.h        |   25 +
 arch/x86/include/asm/intel_mid_powerbtn.h          |   14 +
 arch/x86/include/asm/intel_mid_pwm.h               |   30 +
 arch/x86/include/asm/intel_mid_thermal.h           |   77 +
 arch/x86/include/asm/intel_mid_vrtc.h              |    4 +-
 arch/x86/include/asm/intel_psh_ipc.h               |   35 +
 arch/x86/include/asm/intel_soc_debug.h             |   43 +
 arch/x86/include/asm/pmic_pdata.h                  |   45 +
 arch/x86/kernel/apic/apic.c                        |   25 +-
 arch/x86/kernel/apic/io_apic.c                     |   24 +
 arch/x86/kernel/cpu/common.c                       |    6 +-
 arch/x86/kernel/cpu/intel.c                        |    1 +
 arch/x86/kernel/irq.c                              |    4 +-
 arch/x86/kernel/smpboot.c                          |   45 +-
 arch/x86/platform/intel-mid/Makefile               |   17 +-
 arch/x86/platform/intel-mid/device_libs/Makefile   |    8 +
 .../intel-mid/device_libs/platform_bcove_adc.c     |  143 ++
 .../platform/intel-mid/device_libs/platform_ipc.c  |   43 +-
 .../intel-mid/device_libs/platform_mid_pwm.c       |  121 +
 .../intel-mid/device_libs/platform_mid_pwm.h       |   21 +
 .../intel-mid/device_libs/platform_mrfl_pmic.c     |   54 +
 .../intel-mid/device_libs/platform_mrfl_thermal.c  |  133 +
 .../platform/intel-mid/device_libs/platform_msic.h |    2 +
 .../intel-mid/device_libs/platform_msic_adc.c      |   56 +
 .../intel-mid/device_libs/platform_scu_flis.c      |  290 +++
 .../intel-mid/device_libs/platform_scu_flis.h      |   17 +
 arch/x86/platform/intel-mid/intel-mid.c            |   40 +-
 arch/x86/platform/intel-mid/intel_mid_pcihelpers.c |  105 +
 arch/x86/platform/intel-mid/intel_mid_scu.c        |   92 +
 arch/x86/platform/intel-mid/intel_mid_scu.h        |   15 +
 arch/x86/platform/intel-mid/intel_mid_sfi.c        |  608 +++++
 arch/x86/platform/intel-mid/intel_mid_vrtc.c       |   50 +-
 arch/x86/platform/intel-mid/intel_mid_weak_decls.h |    2 +
 arch/x86/platform/intel-mid/intel_soc_clv.h        |  352 +++
 arch/x86/platform/intel-mid/intel_soc_dump.c       | 1586 ++++++++++++
 arch/x86/platform/intel-mid/intel_soc_mdfld.h      |  353 +++
 arch/x86/platform/intel-mid/intel_soc_mrfld.c      |  446 ++++
 arch/x86/platform/intel-mid/intel_soc_mrfld.h      |  161 ++
 arch/x86/platform/intel-mid/intel_soc_pm_debug.c   | 2518 ++++++++++++++++++++
 arch/x86/platform/intel-mid/intel_soc_pm_debug.h   |  234 ++
 arch/x86/platform/intel-mid/intel_soc_pmu.c        | 2144 +++++++++++++++++
 arch/x86/platform/intel-mid/intel_soc_pmu.h        |  511 ++++
 arch/x86/platform/intel-mid/pmu_tng.c              |  218 ++
 arch/x86/platform/intel-mid/pmu_tng.h              |  180 ++
 drivers/hwmon/Kconfig                              |   25 +
 drivers/hwmon/Makefile                             |    2 +
 drivers/hwmon/coretemp.c                           |  362 +++-
 drivers/hwmon/intel_mcu_common.c                   |  700 ++++++
 drivers/hwmon/intel_mcu_common.h                   |   79 +
 drivers/hwmon/intel_mid_gpadc.c                    | 1212 ++++++++++
 drivers/misc/Kconfig                               |   27 +
 drivers/misc/Makefile                              |    3 +
 drivers/misc/bcm-lpm/Kconfig                       |    6 +
 drivers/misc/bcm-lpm/Makefile                      |    1 +
 drivers/misc/bcm-lpm/bcm_bt_lpm.c                  |  581 +++++
 drivers/misc/pti.c                                 |   95 +-
 drivers/misc/stm.c                                 |  470 ++++
 drivers/misc/stm.h                                 |  114 +
 drivers/pci/Makefile                               |    1 +
 drivers/pci/pci-atom_soc.c                         |   78 +
 drivers/pci/pci.c                                  |    5 +-
 drivers/pci/quirks.c                               |    6 +-
 drivers/platform/x86/Kconfig                       |   16 +
 drivers/platform/x86/Makefile                      |    3 +-
 drivers/platform/x86/intel_mid_powerbtn.c          |  255 ++-
 drivers/platform/x86/intel_psh_ipc.c               |  637 +++++
 drivers/platform/x86/intel_scu_fw_update.c         | 1087 +++++++++
 drivers/power/Kconfig                              |   20 +
 drivers/power/Makefile                             |   12 +-
 drivers/power/bq24261_charger.c                    | 1887 +++++++++++++++
 drivers/power/pmic_ccsm.c                          | 2001 ++++++++++++++++
 drivers/power/pmic_ccsm.h                          |  366 +++
 drivers/power/power_supply.h                       |   21 +
 drivers/power/power_supply_charger.c               | 1151 +++++++++
 drivers/power/power_supply_charger.h               |  244 ++
 drivers/power/power_supply_core.c                  |  100 +-
 drivers/regulator/Kconfig                          |    4 +
 drivers/regulator/Makefile                         |    2 +
 drivers/regulator/pmic_basin_cove.c                |  302 +++
 drivers/remoteproc/Makefile                        |    1 +
 drivers/remoteproc/intel_mid_rproc_core.c          |  269 +++
 drivers/remoteproc/intel_mid_rproc_core.h          |   82 +
 drivers/remoteproc/intel_mid_rproc_scu.c           |  441 ++++
 drivers/rpmsg/virtio_rpmsg_bus.c                   |   12 +-
 drivers/rtc/rtc-mrst.c                             |  294 ++-
 drivers/thermal/Kconfig                            |   28 +
 drivers/thermal/Makefile                           |    9 +
 drivers/thermal/intel_mrfl_thermal.c               |  909 +++++++
 drivers/thermal/intel_soc_thermal.c                |  834 +++++++
 drivers/thermal/thermal_core.c                     |  175 ++-
 drivers/usb/dwc3/core.h                            |   71 +
 include/linux/irq.h                                |    1 +
 include/linux/irqdesc.h                            |    7 +
 include/linux/power/battery_id.h                   |   78 +
 include/linux/power/bq24261_charger.h              |   56 +
 include/linux/regulator/intel_basin_cove_pmic.h    |   59 +
 include/linux/sdm.h                                |   60 +
 include/linux/thermal.h                            |   26 +-
 include/linux/usb/phy.h                            |   14 +
 104 files changed, 26082 insertions(+), 266 deletions(-)
 create mode 100644 arch/x86/include/asm/bcm_bt_lpm.h
 create mode 100644 arch/x86/include/asm/intel_mid_gpadc.h
 create mode 100644 arch/x86/include/asm/intel_mid_pcihelpers.h
 create mode 100644 arch/x86/include/asm/intel_mid_powerbtn.h
 create mode 100644 arch/x86/include/asm/intel_mid_pwm.h
 create mode 100644 arch/x86/include/asm/intel_mid_thermal.h
 create mode 100644 arch/x86/include/asm/intel_psh_ipc.h
 create mode 100644 arch/x86/include/asm/intel_soc_debug.h
 create mode 100644 arch/x86/include/asm/pmic_pdata.h
 create mode 100644 arch/x86/platform/intel-mid/device_libs/platform_bcove_adc.c
 create mode 100644 arch/x86/platform/intel-mid/device_libs/platform_mid_pwm.c
 create mode 100644 arch/x86/platform/intel-mid/device_libs/platform_mid_pwm.h
 create mode 100644 arch/x86/platform/intel-mid/device_libs/platform_mrfl_pmic.c
 create mode 100644 arch/x86/platform/intel-mid/device_libs/platform_mrfl_thermal.c
 create mode 100644 arch/x86/platform/intel-mid/device_libs/platform_msic_adc.c
 create mode 100644 arch/x86/platform/intel-mid/device_libs/platform_scu_flis.c
 create mode 100644 arch/x86/platform/intel-mid/device_libs/platform_scu_flis.h
 create mode 100644 arch/x86/platform/intel-mid/intel_mid_pcihelpers.c
 create mode 100644 arch/x86/platform/intel-mid/intel_mid_scu.c
 create mode 100644 arch/x86/platform/intel-mid/intel_mid_scu.h
 create mode 100644 arch/x86/platform/intel-mid/intel_mid_sfi.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_clv.h
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_dump.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_mdfld.h
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_mrfld.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_mrfld.h
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_pm_debug.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_pm_debug.h
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_pmu.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_pmu.h
 create mode 100644 arch/x86/platform/intel-mid/pmu_tng.c
 create mode 100644 arch/x86/platform/intel-mid/pmu_tng.h
 create mode 100644 drivers/hwmon/intel_mcu_common.c
 create mode 100644 drivers/hwmon/intel_mcu_common.h
 create mode 100644 drivers/hwmon/intel_mid_gpadc.c
 create mode 100644 drivers/misc/bcm-lpm/Kconfig
 create mode 100644 drivers/misc/bcm-lpm/Makefile
 create mode 100644 drivers/misc/bcm-lpm/bcm_bt_lpm.c
 create mode 100644 drivers/misc/stm.c
 create mode 100644 drivers/misc/stm.h
 create mode 100644 drivers/pci/pci-atom_soc.c
 create mode 100644 drivers/platform/x86/intel_psh_ipc.c
 create mode 100644 drivers/platform/x86/intel_scu_fw_update.c
 create mode 100644 drivers/power/bq24261_charger.c
 create mode 100644 drivers/power/pmic_ccsm.c
 create mode 100644 drivers/power/pmic_ccsm.h
 create mode 100644 drivers/power/power_supply_charger.c
 create mode 100644 drivers/power/power_supply_charger.h
 create mode 100644 drivers/regulator/pmic_basin_cove.c
 create mode 100644 drivers/remoteproc/intel_mid_rproc_core.c
 create mode 100644 drivers/remoteproc/intel_mid_rproc_core.h
 create mode 100644 drivers/remoteproc/intel_mid_rproc_scu.c
 create mode 100644 drivers/thermal/intel_mrfl_thermal.c
 create mode 100644 drivers/thermal/intel_soc_thermal.c
 create mode 100644 include/linux/power/battery_id.h
 create mode 100644 include/linux/power/bq24261_charger.h
 create mode 100644 include/linux/regulator/intel_basin_cove_pmic.h
 create mode 100644 include/linux/sdm.h

diff --git a/arch/x86/Kconfig b/arch/x86/Kconfig
index ce5aa02..fb662cd 100644
--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -439,6 +439,17 @@ config X86_INTEL_CE
 	  This option compiles in support for the CE4100 SOC for settop
 	  boxes and media devices.
 
+config X86_WANT_INTEL_MID
+	bool "Intel MID platform support"
+	depends on X86_32
+	depends on X86_EXTENDED_PLATFORM
+	---help---
+	  Select to build a kernel capable of supporting Intel MID platform
+	  systems which do not have the PCI legacy interfaces (Moorestown,
+	  Medfield). If you are building for a PC class system say N here.
+
+if X86_WANT_INTEL_MID
+
 config X86_INTEL_MID
 	bool "Intel MID platform support"
 	depends on X86_32
@@ -491,6 +502,8 @@ config INTEL_DEBUG_FEATURE
 	 the device is in (e.g. manufacturing, production,
 	 end user, etc...).
 
+endif
+
 config X86_INTEL_QUARK
 	bool "Intel Quark platform support"
 	depends on X86_32
diff --git a/arch/x86/include/asm/bcm_bt_lpm.h b/arch/x86/include/asm/bcm_bt_lpm.h
new file mode 100644
index 0000000..d6d0557
--- /dev/null
+++ b/arch/x86/include/asm/bcm_bt_lpm.h
@@ -0,0 +1,46 @@
+/*
+ * Copyright (C) 2009 Google, Inc.
+*
+* This software is licensed under the terms of the GNU General Public
+* License version 2, as published by the Free Software Foundation, and
+* may be copied, distributed, and modified under those terms.
+*
+* This program is distributed in the hope that it will be useful,
+* but WITHOUT ANY WARRANTY; without even the implied warranty of
+* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+* GNU General Public License for more details.
+*/
+
+#ifndef BCM_BT_LMP_H
+#define BCM_BT_LMP_H
+
+#include <linux/serial_core.h>
+#include <net/bluetooth/bluetooth.h>
+#include <net/bluetooth/hci_core.h>
+
+/* Uart driver must call this every time it beings TX, to ensure
+* this driver keeps WAKE asserted during TX. Called with uart
+* spinlock held. */
+extern void bcm_bt_lpm_exit_lpm_locked(struct device *dev,
+							struct hci_dev *hdev);
+
+struct bcm_bt_lpm_platform_data {
+	int gpio_wake;		/* CPU -> BCM wakeup gpio */
+	int gpio_host_wake;	/* BCM -> CPU wakeup gpio */
+	int int_host_wake;	/* BCM -> CPU wakeup irq */
+	int gpio_enable;	/* GPIO enable/disable BT/FM */
+
+	int port;			/* UART port to use with BT/FM */
+	/*
+	 * Callback to request the uart driver to clock off.
+	 * Called with uart spinlock held.
+	 */
+	void (*uart_disable)(struct device *tty);
+	/*
+	 * Callback to request the uart driver to clock on.
+	 * Called with uart spinlock held.
+	 */
+	void (*uart_enable)(struct device *tty);
+};
+
+#endif
diff --git a/arch/x86/include/asm/fixmap.h b/arch/x86/include/asm/fixmap.h
index 65d5fe5..db845c3 100644
--- a/arch/x86/include/asm/fixmap.h
+++ b/arch/x86/include/asm/fixmap.h
@@ -111,6 +111,7 @@ enum fixed_addresses {
 	FIX_TEXT_POKE0, /* first page is last, because allocation is backward */
 #ifdef	CONFIG_X86_INTEL_MID
 	FIX_LNW_VRTC,
+	FIX_CLOCK_CTL,
 #endif
 	__end_of_permanent_fixed_addresses,
 
diff --git a/arch/x86/include/asm/intel-mid.h b/arch/x86/include/asm/intel-mid.h
index 149eab0..a38c793 100644
--- a/arch/x86/include/asm/intel-mid.h
+++ b/arch/x86/include/asm/intel-mid.h
@@ -11,8 +11,20 @@
 #ifndef _ASM_X86_INTEL_MID_H
 #define _ASM_X86_INTEL_MID_H
 
+#include <linux/types.h>
+#include <linux/init.h>
 #include <linux/sfi.h>
+#include <linux/pci.h>
 #include <linux/platform_device.h>
+#include <asm/intel_mid_pcihelpers.h>
+
+#ifdef CONFIG_SFI
+extern void install_irq_resource(struct platform_device *pdev, int irq);
+#else
+/* Dummy function to prevent compilation error in byt */
+static inline void install_irq_resource(struct platform_device *pdev, int irq)
+{};
+#endif
 
 extern int intel_mid_pci_init(void);
 extern int get_gpio_by_name(const char *name);
@@ -21,8 +33,46 @@ extern int __init sfi_parse_mrtc(struct sfi_table_header *table);
 extern int __init sfi_parse_mtmr(struct sfi_table_header *table);
 extern int sfi_mrtc_num;
 extern struct sfi_rtc_table_entry sfi_mrtc_array[];
+extern void register_rpmsg_service(char *name, int id, u32 addr);
 extern int sdhci_pci_request_regulators(void);
 
+/* Define soft platform ID to comply with the OEMB table format. But SPID is not supported */
+#define INTEL_PLATFORM_SSN_SIZE 32
+struct soft_platform_id {
+        u16 customer_id; /*Defines the final customer for the product */
+        u16 vendor_id; /* Defines who owns the final product delivery */
+        u16 manufacturer_id; /* Defines who build the hardware. This can be
+                              * different for the same product */
+        u16 platform_family_id; /* Defined by vendor and defines the family of
+                                 * the product with the same root components */
+        u16 product_line_id; /* Defined by vendor and defines the name of the
+                              * product. This can be used to differentiate the
+                              * feature set for the same product family (low
+                              * cost vs full feature). */
+        u16 hardware_id; /* Defined by vendor and defines the physical hardware
+                          * component set present on the PCB/FAB */
+        u8  fru[SPID_FRU_SIZE]; /* Field Replaceabl Unit */
+} __packed;
+
+/* OEMB table */
+struct sfi_table_oemb {
+	struct sfi_table_header header;
+	u32 board_id;
+	u32 board_fab;
+	u8 iafw_major_version;
+	u8 iafw_main_version;
+	u8 val_hooks_major_version;
+	u8 val_hooks_minor_version;
+	u8 ia_suppfw_major_version;
+	u8 ia_suppfw_minor_version;
+	u8 scu_runtime_major_version;
+	u8 scu_runtime_minor_version;
+	u8 ifwi_major_version;
+	u8 ifwi_minor_version;
+	struct soft_platform_id spid;
+	u8 ssn[INTEL_PLATFORM_SSN_SIZE];
+} __packed;
+
 /*
  * Here defines the array of devices platform data that IAFW would export
  * through SFI "DEVS" table, we use name and type to match the device and
@@ -38,6 +88,24 @@ struct devs_id {
 				struct devs_id *dev);
 };
 
+#define SD_NAME_SIZE 16
+/**
+ * struct sd_board_info - template for device creation
+ * @name: Initializes sdio_device.name; identifies the driver.
+ * @bus_num: board-specific identifier for a given SDIO controller.
+ * @board_ref_clock: Initializes sd_device.board_ref_clock;
+ * @platform_data: Initializes sd_device.platform_data; the particular
+ *      data stored there is driver-specific.
+ *
+ */
+struct sd_board_info {
+	char            name[SD_NAME_SIZE];
+	int             bus_num;
+	unsigned short  addr;
+	u32             board_ref_clock;
+	void            *platform_data;
+};
+
 #define sfi_device(i)   \
 	static const struct devs_id *const __intel_mid_sfi_##i##_dev __used \
 	__attribute__((__section__(".x86_intel_mid_dev.init"))) = &i
@@ -149,6 +217,8 @@ extern void hsu_early_console_init(const char *);
 
 extern void intel_scu_devices_create(void);
 extern void intel_scu_devices_destroy(void);
+extern void intel_psh_devices_create(void);
+extern void intel_psh_devices_destroy(void);
 
 /* VRTC timer */
 #define MRST_VRTC_MAP_SZ	(1024)
diff --git a/arch/x86/include/asm/intel_mid_gpadc.h b/arch/x86/include/asm/intel_mid_gpadc.h
new file mode 100644
index 0000000..ba62f83
--- /dev/null
+++ b/arch/x86/include/asm/intel_mid_gpadc.h
@@ -0,0 +1,19 @@
+#ifndef __INTEL_MID_GPADC_H__
+#define __INTEL_MID_GPADC_H__
+
+struct intel_mid_gpadc_platform_data {
+	unsigned long intr;
+};
+
+#define CH_NEED_VREF		(1 << 8)
+#define CH_NEED_VCALIB		(1 << 9)
+#define CH_NEED_ICALIB		(1 << 10)
+
+int intel_mid_gpadc_gsmpulse_sample(int *vol, int *cur);
+int intel_mid_gpadc_sample(void *handle, int sample_count, ...);
+int get_gpadc_sample(void *handle, int sample_count, int *buffer);
+void intel_mid_gpadc_free(void *handle);
+void *intel_mid_gpadc_alloc(int count, ...);
+void *gpadc_alloc_channels(int count, int *channel_info);
+#endif
+
diff --git a/arch/x86/include/asm/intel_mid_pcihelpers.h b/arch/x86/include/asm/intel_mid_pcihelpers.h
new file mode 100644
index 0000000..d48026f
--- /dev/null
+++ b/arch/x86/include/asm/intel_mid_pcihelpers.h
@@ -0,0 +1,25 @@
+/*
+ * Access to message bus through three registers
+ * in CUNIT(0:0:0) PCI configuration space.
+ * MSGBUS_CTRL_REG(0xD0):
+ *   31:24      = message bus opcode
+ *   23:16      = message bus port
+ *   15:8       = message bus address, low 8 bits.
+ *   7:4        = message bus byte enables
+ * MSGBUS_CTRL_EXT_REG(0xD8):
+ *   31:8       = message bus address, high 24 bits.
+ * MSGBUS_DATA_REG(0xD4):
+ *   hold the data for write or read
+ */
+#define PCI_ROOT_MSGBUS_CTRL_REG        0xD0
+#define PCI_ROOT_MSGBUS_DATA_REG        0xD4
+#define PCI_ROOT_MSGBUS_CTRL_EXT_REG    0xD8
+#define PCI_ROOT_MSGBUS_READ            0x10
+#define PCI_ROOT_MSGBUS_WRITE           0x11
+#define PCI_ROOT_MSGBUS_DWORD_ENABLE    0xf0
+
+u32 intel_mid_msgbus_read32_raw(u32 cmd);
+u32 intel_mid_msgbus_read32(u8 port, u32 addr);
+void intel_mid_msgbus_write32_raw(u32 cmd, u32 data);
+void intel_mid_msgbus_write32(u8 port, u32 addr, u32 data);
+u32 intel_mid_soc_stepping(void);
diff --git a/arch/x86/include/asm/intel_mid_powerbtn.h b/arch/x86/include/asm/intel_mid_powerbtn.h
new file mode 100644
index 0000000..a0b4c87
--- /dev/null
+++ b/arch/x86/include/asm/intel_mid_powerbtn.h
@@ -0,0 +1,14 @@
+#ifndef __INTEL_MID_POWERBTN_H__
+#define __INTEL_MID_POWERBTN_H__
+
+struct intel_msic_power_btn_platform_data {
+	u32 pbstat;
+	u16 pb_level;
+	u16 irq_lvl1_mask;
+	int (*irq_ack)(struct intel_msic_power_btn_platform_data *);
+};
+
+#define MSIC_PB_LEN	1
+#define MSIC_PWRBTNM	(1 << 0)
+
+#endif
diff --git a/arch/x86/include/asm/intel_mid_pwm.h b/arch/x86/include/asm/intel_mid_pwm.h
new file mode 100644
index 0000000..fdd5221
--- /dev/null
+++ b/arch/x86/include/asm/intel_mid_pwm.h
@@ -0,0 +1,30 @@
+#ifndef __INTEL_MID_PWM_H__
+#define __INTEL_MID_PWM_H__
+
+#define MAX_DUTYCYCLE_PERCENTAGE 100
+
+enum {
+	PWM_LED = 0,
+	PWM_VIBRATOR,
+	PWM_LCD_BACKLIGHT,
+	PWM_NUM,
+};
+
+struct intel_mid_pwm_device_data {
+	u16 reg_clkdiv0;
+	u16 reg_clkdiv1;
+	u16 reg_dutycyc;
+	u8 val_clkdiv0;
+	u8 val_clkdiv1;
+};
+
+struct intel_mid_pwm_platform_data {
+	int pwm_num;
+	struct intel_mid_pwm_device_data *ddata;
+	u16 reg_clksel;
+	u8 val_clksel;
+};
+
+int intel_mid_pwm(int id, int value);
+#endif
+
diff --git a/arch/x86/include/asm/intel_mid_thermal.h b/arch/x86/include/asm/intel_mid_thermal.h
new file mode 100644
index 0000000..6a604a1
--- /dev/null
+++ b/arch/x86/include/asm/intel_mid_thermal.h
@@ -0,0 +1,77 @@
+#ifndef __INTEL_MID_THERMAL_H__
+#define __INTEL_MID_THERMAL_H__
+
+#include <linux/thermal.h>
+
+#define BPTHERM_NAME	"bptherm"
+#define SKIN0_NAME	"skin0"
+#define SKIN1_NAME	"skin1"
+#define MSIC_DIE_NAME	"msicdie"
+#define MSIC_SYS_NAME	"sys"
+#define SYSTHERM2       "systherm2"
+/**
+ * struct intel_mid_thermal_sensor - intel_mid_thermal sensor information
+ * @name:		name of the sensor
+ * @index:		index number of sensor
+ * @slope:		slope used for temp calculation
+ * @intercept:		intercept used for temp calculation
+ * @adc_channel:	adc channel id|flags
+ * @direct:		If true then direct conversion is used.
+ * @priv:		private sensor data
+ * @temp_correlation:	temp correlation function
+ */
+struct intel_mid_thermal_sensor {
+	char name[THERMAL_NAME_LENGTH];
+	int index;
+	long slope;
+	long intercept;
+	int adc_channel;
+	bool direct;
+	void *priv;
+	int (*temp_correlation)(void *info, long temp, long *res);
+};
+
+/**
+ * struct soc_throttle_data - SoC level power limits for thermal throttling
+ * @power_limit:	power limit value
+ * @floor_freq:		The CPU frequency may not go below this value
+ */
+struct soc_throttle_data {
+	int power_limit;
+	int floor_freq;
+};
+
+/**
+ * struct intel_mid_thermal_platform_data - Platform data for
+ *		intel mid thermal driver
+ *
+ * @num_sensors:	Maximum number of sensors supported
+ * @sensors:		sensor info
+ * @soc_cooling:	True or false
+ */
+struct intel_mid_thermal_platform_data {
+	int num_sensors;
+	struct intel_mid_thermal_sensor *sensors;
+	bool soc_cooling;
+};
+
+/**
+ * struct skin1_private_info - skin1 sensor private data
+ *
+ * @dependent:		dependency on other sensors
+			0   - no dependency,
+			> 0 - depends on other sensors
+ * @sensors:		dependent sensor address.
+ */
+struct skin1_private_info {
+	int dependent;
+	struct intel_mid_thermal_sensor **sensors;
+};
+
+/* skin0 sensor temperature correlation function*/
+int skin0_temp_correlation(void *info, long temp, long *res);
+/* skin1 sensor temperature correlation function*/
+int skin1_temp_correlation(void *info, long temp, long *res);
+/* bptherm sensor temperature correlation function*/
+int bptherm_temp_correlation(void *info, long temp, long *res);
+#endif
diff --git a/arch/x86/include/asm/intel_mid_vrtc.h b/arch/x86/include/asm/intel_mid_vrtc.h
index 86ff468..11ababf 100644
--- a/arch/x86/include/asm/intel_mid_vrtc.h
+++ b/arch/x86/include/asm/intel_mid_vrtc.h
@@ -3,7 +3,7 @@
 
 extern unsigned char vrtc_cmos_read(unsigned char reg);
 extern void vrtc_cmos_write(unsigned char val, unsigned char reg);
-extern void vrtc_get_time(struct timespec *now);
-extern int vrtc_set_mmss(const struct timespec *now);
+extern unsigned long vrtc_get_time(void);
+extern int vrtc_set_mmss(unsigned long nowtime);
 
 #endif
diff --git a/arch/x86/include/asm/intel_psh_ipc.h b/arch/x86/include/asm/intel_psh_ipc.h
new file mode 100644
index 0000000..ed4d3c14
--- /dev/null
+++ b/arch/x86/include/asm/intel_psh_ipc.h
@@ -0,0 +1,35 @@
+#ifndef _ASM_X86_INTEL_PSH_IPC_H_
+#define _ASM_X86_INTEL_PSH_IPC_H_
+
+#define CHANNEL_BUSY		(1 << 31)
+#define PSH_IPC_CONTINUE	(1 << 30)
+
+struct psh_msg {
+	u32 msg;
+	u32 param;
+};
+
+enum psh_channel {
+	PSH_SEND_CH0 = 0,
+	PSH_SEND_CH1,
+	PSH_SEND_CH2,
+	PSH_SEND_CH3,
+	NUM_IA2PSH_IPC,
+	PSH_RECV_CH0 = NUM_IA2PSH_IPC,
+	PSH_RECV_CH1,
+	PSH_RECV_CH2,
+	PSH_RECV_CH3,
+	PSH_RECV_END,
+	NUM_PSH2IA_IPC = PSH_RECV_END - PSH_RECV_CH0,
+	NUM_ALL_CH = NUM_IA2PSH_IPC + NUM_PSH2IA_IPC,
+};
+
+typedef void(*psh_channel_handle_t)(u32 msg, u32 param, void *data);
+int intel_ia2psh_command(struct psh_msg *in, struct psh_msg *out,
+			 int ch, int timeout);
+int intel_psh_ipc_bind(int ch, psh_channel_handle_t handle, void *data);
+void intel_psh_ipc_unbind(int ch);
+
+void intel_psh_ipc_disable_irq(void);
+void intel_psh_ipc_enable_irq(void);
+#endif
diff --git a/arch/x86/include/asm/intel_soc_debug.h b/arch/x86/include/asm/intel_soc_debug.h
new file mode 100644
index 0000000..9edb166
--- /dev/null
+++ b/arch/x86/include/asm/intel_soc_debug.h
@@ -0,0 +1,43 @@
+/*
+ * intel_soc_debug.h
+ * Copyright (c) 2013, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#ifndef INTEL_SOC_DEBUG_H
+#define INTEL_SOC_DEBUG_H
+
+#define DEBUG_FEATURE_PTI      0x00000001
+#define DEBUG_FEATURE_RTIT     0x00000002
+#define DEBUG_FEATURE_LAKEMORE 0x00000004
+#define DEBUG_FEATURE_SOCHAPS  0x00000008
+#define DEBUG_FEATURE_USB3DFX  0x00000010
+
+/* cpu_has_debug_feature checks whether the debug
+ * feature passed as parameter is enabled.
+ * The passed parameter shall be one (and only one)
+ * of the above values (DEBUG_FEATURE_XXX).
+ * The function returns 1 if the debug feature is
+ * enabled and 0 otherwise.
+ */
+
+#ifdef CONFIG_INTEL_DEBUG_FEATURE
+extern int cpu_has_debug_feature(u32 bit);
+#else
+static inline int cpu_has_debug_feature(u32 bit) { return 0; };
+#endif
+
+#endif
diff --git a/arch/x86/include/asm/pmic_pdata.h b/arch/x86/include/asm/pmic_pdata.h
new file mode 100644
index 0000000..d88c64a
--- /dev/null
+++ b/arch/x86/include/asm/pmic_pdata.h
@@ -0,0 +1,45 @@
+#ifndef __PMIC_PDATA_H__
+#define __PMIC_PDATA_H__
+
+struct temp_lookup {
+	int adc_val;
+	int temp;
+	int temp_err;
+};
+
+/*
+ * pmic cove charger driver info
+ */
+struct pmic_platform_data {
+	void (*cc_to_reg)(int, u8*);
+	void (*cv_to_reg)(int, u8*);
+	void (*inlmt_to_reg)(int, u8*);
+	int max_tbl_row_cnt;
+	struct temp_lookup *adc_tbl;
+};
+
+extern int pmic_get_status(void);
+extern int pmic_enable_charging(bool);
+extern int pmic_set_cc(int);
+extern int pmic_set_cv(int);
+extern int pmic_set_ilimma(int);
+extern int pmic_enable_vbus(bool enable);
+/* WA for ShadyCove VBUS removal detect issue */
+extern int pmic_handle_low_supply(void);
+
+extern void dump_pmic_regs(void);
+#ifdef CONFIG_PMIC_CCSM
+extern int pmic_get_health(void);
+extern int pmic_get_battery_pack_temp(int *);
+#else
+static int pmic_get_health(void)
+{
+	return 0;
+}
+static int pmic_get_battery_pack_temp(int *temp)
+{
+	return 0;
+}
+#endif
+
+#endif
diff --git a/arch/x86/kernel/apic/apic.c b/arch/x86/kernel/apic/apic.c
index 523f147..9c7aca2 100644
--- a/arch/x86/kernel/apic/apic.c
+++ b/arch/x86/kernel/apic/apic.c
@@ -55,6 +55,7 @@
 #include <asm/mce.h>
 #include <asm/tsc.h>
 #include <asm/hypervisor.h>
+#include <asm/intel-mid.h>
 
 unsigned int num_processors;
 
@@ -709,7 +710,7 @@ static int __init calibrate_APIC_clock(void)
 		lapic_clockevent.mult = div_sc(lapic_timer_frequency/APIC_DIVISOR,
 					TICK_NSEC, lapic_clockevent.shift);
 		lapic_clockevent.max_delta_ns =
-			clockevent_delta2ns(0x7FFFFF, &lapic_clockevent);
+			clockevent_delta2ns(0x7FFFFFFF, &lapic_clockevent);
 		lapic_clockevent.min_delta_ns =
 			clockevent_delta2ns(0xF, &lapic_clockevent);
 		lapic_clockevent.features &= ~CLOCK_EVT_FEAT_DUMMY;
@@ -2311,6 +2312,19 @@ static int lapic_suspend(void)
 	unsigned long flags;
 	int maxlvt;
 
+	/*
+	 * On intel_mid, the suspend flow is a bit different, and the lapic
+	 * hw implementation, and integration is not supporting standard
+	 * suspension.
+	 * This implementation is only putting high value to the timer, so that
+	 * AONT global timer will be updated with this big value at s0i3 entry,
+	 * and wont produce timer based wake up event.
+	 */
+	if (intel_mid_identify_cpu() != 0) {
+		apic_write(APIC_TMICT, ~0);
+		return 0;
+	}
+
 	if (!apic_pm_state.active)
 		return 0;
 
@@ -2349,6 +2363,15 @@ static void lapic_resume(void)
 	unsigned long flags;
 	int maxlvt;
 
+	/*
+	 * On intel_mid, the resume flow is a bit different.
+	 * Refer explanation on lapic_suspend.
+	 */
+	if (intel_mid_identify_cpu() != 0) {
+		apic_write(APIC_TMICT, 10);
+		return;
+	}
+
 	if (!apic_pm_state.active)
 		return;
 
diff --git a/arch/x86/kernel/apic/io_apic.c b/arch/x86/kernel/apic/io_apic.c
index b7175c0..29d16fe 100644
--- a/arch/x86/kernel/apic/io_apic.c
+++ b/arch/x86/kernel/apic/io_apic.c
@@ -313,6 +313,24 @@ void io_apic_eoi(unsigned int apic, unsigned int vector)
 	writel(vector, &io_apic->eoi);
 }
 
+/*
+ * This index matches with 1024 - 4 address in SCU RTE table area.
+ * That is not used for anything. Works in CLVP only
+ */
+#define LAST_INDEX_IN_IO_APIC_SPACE 255
+#define KERNEL_TO_SCU_PANIC_REQUEST (0x0515dead)
+void apic_scu_panic_dump(void)
+{
+	unsigned long flags;
+
+	printk(KERN_ERR "Request SCU panic dump");
+	raw_spin_lock_irqsave(&ioapic_lock, flags);
+	io_apic_write(0, LAST_INDEX_IN_IO_APIC_SPACE,
+		      KERNEL_TO_SCU_PANIC_REQUEST);
+	raw_spin_unlock_irqrestore(&ioapic_lock, flags);
+}
+EXPORT_SYMBOL_GPL(apic_scu_panic_dump);
+
 unsigned int native_io_apic_read(unsigned int apic, unsigned int reg)
 {
 	struct io_apic __iomem *io_apic = io_apic_base(apic);
@@ -2357,6 +2375,10 @@ int native_ioapic_set_affinity(struct irq_data *data,
 	return ret;
 }
 
+static int ioapic_set_wake(struct irq_data *data, unsigned int on)
+{
+	return 0;
+}
 static void ack_apic_edge(struct irq_data *data)
 {
 	irq_complete_move(data->chip_data);
@@ -2521,7 +2543,9 @@ static struct irq_chip ioapic_chip __read_mostly = {
 	.irq_ack		= ack_apic_edge,
 	.irq_eoi		= ack_apic_level,
 	.irq_set_affinity	= native_ioapic_set_affinity,
+	.irq_set_wake		= ioapic_set_wake,
 	.irq_retrigger		= ioapic_retrigger_irq,
+	.flags			= IRQCHIP_SKIP_SET_WAKE,
 };
 
 static inline void init_IO_APIC_traps(void)
diff --git a/arch/x86/kernel/cpu/common.c b/arch/x86/kernel/cpu/common.c
index e6bddd5..94533eb 100644
--- a/arch/x86/kernel/cpu/common.c
+++ b/arch/x86/kernel/cpu/common.c
@@ -1197,15 +1197,17 @@ DEFINE_PER_CPU_ALIGNED(struct stack_canary, stack_canary);
  */
 static void clear_all_debug_regs(void)
 {
-	int i;
+/*	int i;
 
 	for (i = 0; i < 8; i++) {
+*/
 		/* Ignore db4, db5 */
-		if ((i == 4) || (i == 5))
+/*		if ((i == 4) || (i == 5))
 			continue;
 
 		set_debugreg(0, i);
 	}
+*/
 }
 
 #ifdef CONFIG_KGDB
diff --git a/arch/x86/kernel/cpu/intel.c b/arch/x86/kernel/cpu/intel.c
index 13f6b32..a0bfddd 100644
--- a/arch/x86/kernel/cpu/intel.c
+++ b/arch/x86/kernel/cpu/intel.c
@@ -100,6 +100,7 @@ static void early_init_intel(struct cpuinfo_x86 *c)
 		switch (c->x86_model) {
 		case 0x27:	/* Penwell */
 		case 0x35:	/* Cloverview */
+		case 0x4A:	/* Merrifield */
 			set_cpu_cap(c, X86_FEATURE_NONSTOP_TSC_S3);
 			break;
 		default:
diff --git a/arch/x86/kernel/irq.c b/arch/x86/kernel/irq.c
index d99f31d..5ca0306 100644
--- a/arch/x86/kernel/irq.c
+++ b/arch/x86/kernel/irq.c
@@ -367,7 +367,9 @@ void fixup_irqs(void)
 
 		data = irq_desc_get_irq_data(desc);
 		affinity = data->affinity;
-		if (!irq_has_action(irq) || irqd_is_per_cpu(data) ||
+		/* include IRQs who have no action, but are chained */
+		if ((!irq_has_action(irq) && !irq_is_chained(irq)) ||
+			irqd_is_per_cpu(data) ||
 		    cpumask_subset(affinity, cpu_online_mask)) {
 			raw_spin_unlock(&desc->lock);
 			continue;
diff --git a/arch/x86/kernel/smpboot.c b/arch/x86/kernel/smpboot.c
index d8e6049..e7213b3 100644
--- a/arch/x86/kernel/smpboot.c
+++ b/arch/x86/kernel/smpboot.c
@@ -1371,21 +1371,25 @@ int native_cpu_disable(void)
 	return 0;
 }
 
+/*
+ * We let cpus' idle tasks announce their own death to complete
+ * logical cpu unplug sequence.
+ */
+DECLARE_COMPLETION(cpu_die_comp);
+
 void native_cpu_die(unsigned int cpu)
 {
 	/* We don't do anything here: idle task is faking death itself. */
-	unsigned int i;
+	unsigned long timeout = HZ; /* 1 sec */
 
-	for (i = 0; i < 10; i++) {
-		/* They ack this in play_dead by setting CPU_DEAD */
-		if (per_cpu(cpu_state, cpu) == CPU_DEAD) {
-			if (system_state == SYSTEM_RUNNING)
-				pr_info("CPU %u is now offline\n", cpu);
-			return;
-		}
-		msleep(100);
-	}
-	pr_err("CPU %u didn't die...\n", cpu);
+	/* They ack this in play_dead by setting CPU_DEAD */
+	wait_for_completion_timeout(&cpu_die_comp, timeout);
+	if (per_cpu(cpu_state, cpu) == CPU_DEAD) {
+		if (system_state == SYSTEM_RUNNING)
+			pr_info("CPU %u is now offline\n", cpu);
+		return;
+	} else
+		pr_err("CPU %u didn't die...\n", cpu);
 }
 
 void play_dead_common(void)
@@ -1397,6 +1401,7 @@ void play_dead_common(void)
 	mb();
 	/* Ack it */
 	__this_cpu_write(cpu_state, CPU_DEAD);
+	complete(&cpu_die_comp);
 
 	/*
 	 * With physical CPU hotplug, we should halt the cpu
@@ -1449,8 +1454,15 @@ static inline void mwait_play_dead(void)
 				highest_subcstate = edx & MWAIT_SUBSTATE_MASK;
 			}
 		}
-		eax = (highest_cstate << MWAIT_SUBSTATE_SIZE) |
-			(highest_subcstate - 1);
+
+		if (highest_cstate < 6) {
+			eax = (highest_cstate << MWAIT_SUBSTATE_SIZE) |
+				(highest_subcstate - 1);
+		} else {
+			/* For s0i3 substate code is 4 */
+			eax = (highest_cstate << MWAIT_SUBSTATE_SIZE) |
+				((highest_subcstate - 1) * 2);
+		}
 	}
 
 	/*
@@ -1462,6 +1474,13 @@ static inline void mwait_play_dead(void)
 
 	wbinvd();
 
+	/*
+	 * FIXME: SCU will abort S3 entry with ACK C6 timeout
+	 * if the lapic timer value programmed is low.
+	 * Hence program a high value before offlineing the CPU
+	 */
+	apic_write(APIC_TMICT, ~0);
+
 	while (1) {
 		/*
 		 * The CLFLUSH is a workaround for erratum AAI65 for
diff --git a/arch/x86/platform/intel-mid/Makefile b/arch/x86/platform/intel-mid/Makefile
index a63c34b..4b64cd2 100644
--- a/arch/x86/platform/intel-mid/Makefile
+++ b/arch/x86/platform/intel-mid/Makefile
@@ -2,7 +2,18 @@ obj-$(CONFIG_X86_INTEL_MID) += intel-mid.o intel_mid_vrtc.o mfld.o mrfl.o
 obj-$(CONFIG_EARLY_PRINTK_INTEL_MID) += early_printk_intel_mid.o
 
 # SFI specific code
-ifdef CONFIG_X86_INTEL_MID
-obj-$(CONFIG_SFI) += sfi.o device_libs/
-endif
+obj-$(CONFIG_SFI) += intel_mid_sfi.o
+
+# platform configuration for board devices
+obj-y += device_libs/
+
 obj-$(CONFIG_X86_INTEL_MID) += board.o
+
+# SoC specific files
+obj-$(CONFIG_X86_WANT_INTEL_MID) += intel_mid_pcihelpers.o
+obj-$(CONFIG_X86_INTEL_MID) += intel_mid_scu.o
+
+# PMU driver
+obj-$(CONFIG_ATOM_SOC_POWER) += intel_soc_pmu.o intel_soc_pm_debug.o intel_soc_dump.o
+obj-$(CONFIG_REMOVEME_INTEL_ATOM_MRFLD_POWER) += intel_soc_mrfld.o
+obj-$(CONFIG_REMOVEME_INTEL_ATOM_MRFLD_POWER) += pmu_tng.o
diff --git a/arch/x86/platform/intel-mid/device_libs/Makefile b/arch/x86/platform/intel-mid/device_libs/Makefile
index b038a02..02b97fa 100644
--- a/arch/x86/platform/intel-mid/device_libs/Makefile
+++ b/arch/x86/platform/intel-mid/device_libs/Makefile
@@ -9,6 +9,11 @@ obj-$(subst m,y,$(CONFIG_INTEL_MID_POWER_BUTTON)) += platform_msic_power_btn.o
 obj-$(subst m,y,$(CONFIG_GPIO_INTEL_PMIC)) += platform_pmic_gpio.o
 obj-$(subst m,y,$(CONFIG_INTEL_MFLD_THERMAL)) += platform_msic_thermal.o
 obj-y += pci/
+obj-$(subst m,y,$(CONFIG_INTEL_MID_POWER_BUTTON)) += platform_msic_power_btn.o
+obj-$(subst m,y,$(CONFIG_GPIO_INTEL_PMIC)) += platform_pmic_gpio.o
+obj-$(subst m,y,$(CONFIG_SENSORS_THERMAL_MRFLD)) += platform_mrfl_thermal.o
+obj-$(subst m,y,$(CONFIG_INTEL_SCU_FLIS)) += platform_scu_flis.o
+obj-$(subst m,y,$(CONFIG_PMIC_CCSM)) += platform_mrfl_pmic.o
 # I2C Devices
 obj-$(subst m,y,$(CONFIG_SENSORS_EMC1403)) += platform_emc1403.o
 obj-$(subst m,y,$(CONFIG_SENSORS_LIS3LV02D)) += platform_lis331.o
@@ -20,6 +25,9 @@ obj-$(subst m,y,$(CONFIG_DRM_MEDFIELD)) += platform_tc35876x.o
 obj-$(subst m,y,$(CONFIG_I2C_DESIGNWARE_CORE_FORK)) += platform_dw_i2c.o
 # SPI Devices
 obj-$(subst m,y,$(CONFIG_SERIAL_MRST_MAX3110)) += platform_max3111.o
+# ADC
+obj-$(subst m,y,$(CONFIG_MSIC_GPADC))  += platform_msic_adc.o
+obj-$(subst m,y,$(CONFIG_IIO_BASINCOVE_GPADC)) += platform_bcove_adc.o
 # MISC Devices
 obj-$(subst m,y,$(CONFIG_KEYBOARD_GPIO)) += platform_gpio_keys.o
 # UART Devices
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_bcove_adc.c b/arch/x86/platform/intel-mid/device_libs/platform_bcove_adc.c
new file mode 100644
index 0000000..88125ac
--- /dev/null
+++ b/arch/x86/platform/intel-mid/device_libs/platform_bcove_adc.c
@@ -0,0 +1,143 @@
+/*
+ * platform_bcove_adc.c: Platform data for Merrifield Basincove GPADC driver
+ *
+ * (C) Copyright 2012 Intel Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/sfi.h>
+#include <linux/iio/iio.h>
+#include <linux/iio/machine.h>
+#include <linux/iio/types.h>
+#include <asm/intel-mid.h>
+#include <asm/intel_basincove_gpadc.h>
+#include <asm/intel_mid_remoteproc.h>
+
+#include "platform_bcove_adc.h"
+
+/* SRAM address where the GPADC interrupt register is cached */
+#define GPADC_SRAM_INTR_ADDR	0xfffff615
+
+static struct gpadc_regmap_t basincove_gpadc_regmaps[GPADC_CH_NUM] = {
+	{"VBAT",        5, 0xE9, 0xEA, },
+	{"BATID",       4, 0xEB, 0xEC, },
+	{"IBAT",        5, 0xED, 0xEE, },
+	{"PMICTEMP",    3, 0xCC, 0xCD, },
+	{"BATTEMP0",    2, 0xC8, 0xC9, },
+	{"BATTEMP1",    2, 0xCA, 0xCB, },
+	{"SYSTEMP0",    3, 0xC2, 0xC3, },
+	{"SYSTEMP1",    3, 0xC4, 0xC5, },
+	{"SYSTEMP2",    3, 0xC6, 0xC7, },
+};
+
+static struct gpadc_regs_t basincove_gpadc_regs = {
+	.gpadcreq		= 0xDC,
+	.gpadcreq_irqen		= (1 << 1),
+	.gpadcreq_busy		= (1 << 0),
+	.mirqlvl1		= 0x0C,
+	.mirqlvl1_adc		= (1 << 4),
+	.adc1cntl		= 0xDD,
+	.adcirq			= 0x06,
+	.madcirq		= 0x11,
+};
+
+#define MSIC_ADC_MAP(_adc_channel_label,			\
+		     _consumer_dev_name,                        \
+		     _consumer_channel)                         \
+	{                                                       \
+		.adc_channel_label = _adc_channel_label,        \
+		.consumer_dev_name = _consumer_dev_name,        \
+		.consumer_channel = _consumer_channel,          \
+	}
+
+struct iio_map basincove_iio_maps[] = {
+	MSIC_ADC_MAP("CH0", "VIBAT", "VBAT"),
+	MSIC_ADC_MAP("CH1", "BATID", "BATID"),
+	MSIC_ADC_MAP("CH2", "VIBAT", "IBAT"),
+	MSIC_ADC_MAP("CH3", "PMICTEMP", "PMICTEMP"),
+	MSIC_ADC_MAP("CH4", "BATTEMP", "BATTEMP0"),
+	MSIC_ADC_MAP("CH5", "BATTEMP", "BATTEMP1"),
+	MSIC_ADC_MAP("CH6", "SYSTEMP", "SYSTEMP0"),
+	MSIC_ADC_MAP("CH7", "SYSTEMP", "SYSTEMP1"),
+	MSIC_ADC_MAP("CH8", "SYSTEMP", "SYSTEMP2"),
+	MSIC_ADC_MAP("CH6", "bcove_thrm", "SYSTEMP0"),
+	MSIC_ADC_MAP("CH7", "bcove_thrm", "SYSTEMP1"),
+	MSIC_ADC_MAP("CH8", "bcove_thrm", "SYSTEMP2"),
+	MSIC_ADC_MAP("CH3", "bcove_thrm", "PMICTEMP"),
+	{ },
+};
+
+#define MSIC_ADC_CHANNEL(_type, _channel, _datasheet_name) \
+	{                               \
+		.indexed = 1,           \
+		.type = _type,          \
+		.channel = _channel,    \
+		.datasheet_name = _datasheet_name,      \
+	}
+
+static const struct iio_chan_spec const basincove_adc_channels[] = {
+	MSIC_ADC_CHANNEL(IIO_VOLTAGE, 0, "CH0"),
+	MSIC_ADC_CHANNEL(IIO_RESISTANCE, 1, "CH1"),
+	MSIC_ADC_CHANNEL(IIO_CURRENT, 2, "CH2"),
+	MSIC_ADC_CHANNEL(IIO_TEMP, 3, "CH3"),
+	MSIC_ADC_CHANNEL(IIO_TEMP, 4, "CH4"),
+	MSIC_ADC_CHANNEL(IIO_TEMP, 5, "CH5"),
+	MSIC_ADC_CHANNEL(IIO_TEMP, 6, "CH6"),
+	MSIC_ADC_CHANNEL(IIO_TEMP, 7, "CH7"),
+	MSIC_ADC_CHANNEL(IIO_TEMP, 8, "CH8"),
+};
+
+static struct intel_basincove_gpadc_platform_data bcove_adc_pdata = {
+	.channel_num = GPADC_CH_NUM,
+	.intr = GPADC_SRAM_INTR_ADDR,
+	.gpadc_iio_maps = basincove_iio_maps,
+	.gpadc_regmaps = basincove_gpadc_regmaps,
+	.gpadc_regs = &basincove_gpadc_regs,
+	.gpadc_channels = basincove_adc_channels,
+};
+
+void __init *bcove_adc_platform_data(void *info)
+{
+	struct platform_device *pdev = NULL;
+	struct sfi_device_table_entry *entry = info;
+	int ret;
+
+	pdev = platform_device_alloc(BCOVE_ADC_DEV_NAME, -1);
+
+	if (!pdev) {
+		pr_err("out of memory for SFI platform dev %s\n",
+					BCOVE_ADC_DEV_NAME);
+		goto out;
+	}
+
+	bcove_adc_pdata.channel_num = GPADC_CH_NUM;
+	bcove_adc_pdata.intr = GPADC_SRAM_INTR_ADDR;
+	bcove_adc_pdata.intr_mask = MBATTEMP | MSYSTEMP | MBATT
+		| MVIBATT | MCCTICK;
+	bcove_adc_pdata.gpadc_iio_maps = basincove_iio_maps;
+	bcove_adc_pdata.gpadc_regmaps = basincove_gpadc_regmaps;
+	bcove_adc_pdata.gpadc_regs = &basincove_gpadc_regs;
+	bcove_adc_pdata.gpadc_channels = basincove_adc_channels;
+
+	pdev->dev.platform_data = &bcove_adc_pdata;
+
+	ret = platform_device_add(pdev);
+	if (ret) {
+		pr_err("failed to add bcove adc platform device\n");
+		platform_device_put(pdev);
+		goto out;
+	}
+
+	install_irq_resource(pdev, entry->irq);
+
+	register_rpmsg_service("rpmsg_bcove_adc", RPROC_SCU,
+				RP_BCOVE_ADC);
+out:
+	return &bcove_adc_pdata;
+}
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_ipc.c b/arch/x86/platform/intel-mid/device_libs/platform_ipc.c
index a84b73d..f93b703 100644
--- a/arch/x86/platform/intel-mid/device_libs/platform_ipc.c
+++ b/arch/x86/platform/intel-mid/device_libs/platform_ipc.c
@@ -18,44 +18,23 @@
 #include <asm/intel-mid.h>
 #include "platform_ipc.h"
 
-void __init ipc_device_handler(struct sfi_device_table_entry *pentry,
-				struct devs_id *dev)
-{
-	struct platform_device *pdev;
+void ipc_device_handler(struct sfi_device_table_entry *pentry,
+				struct devs_id *dev) {
 	void *pdata = NULL;
-	static struct resource res __initdata = {
-		.name = "IRQ",
-		.flags = IORESOURCE_IRQ,
-	};
-
-	pr_debug("IPC bus, name = %16.16s, irq = 0x%2x\n",
-		pentry->name, pentry->irq);
-
 	/*
-	 * We need to call platform init of IPC devices to fill misc_pdata
-	 * structure. It will be used in msic_init for initialization.
+	 * IPC device creation is handled by the MSIC
+	 * MFD driver so we don't need to do it here.
 	 */
-	if (dev != NULL)
-		pdata = dev->get_platform_data(pentry);
 
 	/*
-	 * On Medfield the platform device creation is handled by the MSIC
-	 * MFD driver so we don't need to do it here.
+	 * We need to call platform init of IPC devices to fill
+	 * misc_pdata structure. It will be used in msic_init for
+	 * initialization.
 	 */
-	if (intel_mid_has_msic())
-		return;
-
-	pdev = platform_device_alloc(pentry->name, 0);
-	if (pdev == NULL) {
-		pr_err("out of memory for SFI platform device '%s'.\n",
-			pentry->name);
-		return;
-	}
-	res.start = pentry->irq;
-	platform_device_add_resources(pdev, &res, 1);
-
-	pdev->dev.platform_data = pdata;
-	intel_scu_device_register(pdev);
+	pr_info("IPC bus, name = %16.16s, irq = 0x%2x\n",
+		pentry->name, pentry->irq);
+	if (dev != NULL)
+		pdata = dev->get_platform_data(pentry);
 }
 
 static const struct devs_id pmic_audio_dev_id __initconst = {
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_mid_pwm.c b/arch/x86/platform/intel-mid/device_libs/platform_mid_pwm.c
new file mode 100644
index 0000000..c184fed
--- /dev/null
+++ b/arch/x86/platform/intel-mid/device_libs/platform_mid_pwm.c
@@ -0,0 +1,121 @@
+/*
+ * platform_mid_pwm.c: mid_pwm platform data initilization file
+ *
+ * (C) Copyright 2008 Intel Corporation
+ * Author:
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+#include <linux/input.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/gpio.h>
+#include <linux/platform_device.h>
+#include <linux/lnw_gpio.h>
+
+#include <asm/intel-mid.h>
+#include <asm/intel_mid_pwm.h>
+#include <asm/intel_mid_remoteproc.h>
+
+#include "platform_mid_pwm.h"
+
+static struct intel_mid_pwm_device_data mfld_pwms[] = {
+	[PWM_LED] = {
+		.reg_clkdiv0 = 0x62,
+		.reg_clkdiv1 = 0x61,
+		.reg_dutycyc = 0x67,
+		.val_clkdiv1 = 0x00,
+		.val_clkdiv0 = 0x03,
+	},
+	[PWM_VIBRATOR] = {
+		.reg_clkdiv0 = 0x64,
+		.reg_clkdiv1 = 0x63,
+		.reg_dutycyc = 0x68,
+		.val_clkdiv1 = 0x00,
+		.val_clkdiv0 = 0x03,
+	},
+	[PWM_LCD_BACKLIGHT] = {
+		.reg_clkdiv0 = 0x66,
+		.reg_clkdiv1 = 0x65,
+		.reg_dutycyc = 0x69,
+		.val_clkdiv1 = 0x00,
+		.val_clkdiv0 = 0x03,
+	},
+};
+
+static struct intel_mid_pwm_device_data ctp_pwms[] = {
+	[PWM_LED] = {
+		.reg_clkdiv0 = 0x62,
+		.reg_clkdiv1 = 0x61,
+		.reg_dutycyc = 0x67,
+		.val_clkdiv1 = 0x00,
+		.val_clkdiv0 = 0x00,
+	},
+	[PWM_VIBRATOR] = {
+		.reg_clkdiv0 = 0x64,
+		.reg_clkdiv1 = 0x63,
+		.reg_dutycyc = 0x68,
+		.val_clkdiv1 = 0x00,
+		.val_clkdiv0 = 0x03,
+	},
+	[PWM_LCD_BACKLIGHT] = {
+		.reg_clkdiv0 = 0x66,
+		.reg_clkdiv1 = 0x65,
+		.reg_dutycyc = 0x69,
+		.val_clkdiv1 = 0x00,
+		.val_clkdiv0 = 0x03,
+	},
+};
+
+static struct intel_mid_pwm_platform_data pdata[] = {
+	[mfld_pwm] = {
+		.pwm_num = PWM_NUM,
+		.ddata = mfld_pwms,
+		.reg_clksel = 0x38F,
+		.val_clksel = 0x01,
+	},
+	[ctp_pwm] = {
+		.pwm_num = PWM_NUM,
+		.ddata = ctp_pwms,
+		.reg_clksel = 0x38F,
+		.val_clksel = 0x00,
+	},
+};
+
+static void *get_pwm_platform_data(void)
+{
+	pr_info("%s, MFLD board detected\n", __func__);
+	return &pdata[mfld_pwm];
+}
+
+static int __init intel_mid_pwm_init(void)
+{
+	struct platform_device *pdev = NULL;
+	int ret = 0;
+
+	pdev = platform_device_alloc(DEVICE_NAME, -1);
+
+	if (!pdev) {
+		pr_err("out of memory for platform dev %s\n",
+					DEVICE_NAME);
+		return -1;
+	}
+
+	pdev->dev.platform_data = get_pwm_platform_data();
+
+	ret = platform_device_add(pdev);
+	if (ret) {
+		pr_err("failed to add platform device %s\n",
+					DEVICE_NAME);
+		platform_device_put(pdev);
+		return -1;
+	}
+
+	return 0;
+}
+
+fs_initcall(intel_mid_pwm_init);
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_mid_pwm.h b/arch/x86/platform/intel-mid/device_libs/platform_mid_pwm.h
new file mode 100644
index 0000000..fb9a26c
--- /dev/null
+++ b/arch/x86/platform/intel-mid/device_libs/platform_mid_pwm.h
@@ -0,0 +1,21 @@
+/*
+ * platform_mid_pwm.h: mid_pwm platform data header file
+ *
+ * (C) Copyright 2008 Intel Corporation
+ * Author:
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+#ifndef _PLATFORM_MID_PWM_H_
+#define _PLATFORM_MID_PWM_H_
+
+#define DEVICE_NAME "intel_mid_pwm"
+
+enum {
+	mfld_pwm,
+	ctp_pwm,
+};
+#endif
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_mrfl_pmic.c b/arch/x86/platform/intel-mid/device_libs/platform_mrfl_pmic.c
new file mode 100644
index 0000000..9f69867
--- /dev/null
+++ b/arch/x86/platform/intel-mid/device_libs/platform_mrfl_pmic.c
@@ -0,0 +1,54 @@
+/*
+ * platform_mrfl_pmic.c: Platform data for Merrifield PMIC driver
+ *
+ * (C) Copyright 2012 Intel Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/scatterlist.h>
+#include <linux/init.h>
+#include <linux/sfi.h>
+#include <asm/intel-mid.h>
+#include <asm/pmic_pdata.h>
+#include <asm/intel_mid_remoteproc.h>
+#include <linux/power/bq24261_charger.h>
+
+#include "platform_ipc.h"
+#include "platform_mrfl_pmic.h"
+
+void __init *mrfl_pmic_ccsm_platform_data(void *info)
+{
+	struct sfi_device_table_entry *entry = info;
+	static struct pmic_platform_data pmic_pdata;
+	struct platform_device *pdev = NULL;
+	int ret;
+
+	pdev = platform_device_alloc(entry->name, -1);
+	if (!pdev) {
+		pr_err("Out of memory for SFI platform dev %s\n", entry->name);
+		goto out;
+	}
+	pdev->dev.platform_data = &pmic_pdata;
+	ret = platform_device_add(pdev);
+	if (ret) {
+		pr_err("Failed to add adc platform device\n");
+		platform_device_put(pdev);
+		goto out;
+	}
+	install_irq_resource(pdev, entry->irq);
+#ifdef CONFIG_BQ24261_CHARGER
+	pmic_pdata.cc_to_reg = bq24261_cc_to_reg;
+	pmic_pdata.cv_to_reg = bq24261_cv_to_reg;
+#endif
+	register_rpmsg_service("rpmsg_pmic_ccsm", RPROC_SCU,
+				RP_PMIC_CCSM);
+out:
+	return &pmic_pdata;
+}
+
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_mrfl_thermal.c b/arch/x86/platform/intel-mid/device_libs/platform_mrfl_thermal.c
new file mode 100644
index 0000000..8e118a4
--- /dev/null
+++ b/arch/x86/platform/intel-mid/device_libs/platform_mrfl_thermal.c
@@ -0,0 +1,133 @@
+/*
+ * platform_mrfl_thermal.c: Platform data initilization file for
+ *			Intel Merrifield Platform thermal driver
+ *
+ * (C) Copyright 2013 Intel Corporation
+ * Author: Durgadoss R <durgadoss.r@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+#include <linux/init.h>
+#include <linux/input.h>
+#include <linux/kernel.h>
+#include <linux/mfd/intel_msic.h>
+#include <linux/platform_device.h>
+#include <asm/intel_mid_thermal.h>
+#include <asm/intel-mid.h>
+#include <asm/intel_mid_remoteproc.h>
+#include "platform_mrfl_thermal.h"
+
+/* 'enum' of Thermal ADC channels */
+enum thermal_adc_channels { SYS0, SYS1, SYS2, PMIC_DIE };
+
+static int linear_temp_correlation(void *info, long temp, long *res)
+{
+	struct intel_mid_thermal_sensor *sensor = info;
+
+	*res = ((temp * sensor->slope) / 1000) + sensor->intercept;
+
+	return 0;
+}
+
+/*
+ * Naming convention:
+ * skin0 -> front skin,
+ * skin1--> back skin
+ */
+
+static struct intel_mid_thermal_sensor mrfl_sensors[] = {
+	{
+		.name = SKIN0_NAME,
+		.index = SYS2,
+		.slope = 969,
+		.intercept = -3741,
+		.temp_correlation = linear_temp_correlation,
+		.direct = false,
+	},
+	{
+		.name = SKIN1_NAME,
+		.index = SYS0,
+		.slope = 966,
+		.intercept = -2052,
+		.temp_correlation = linear_temp_correlation,
+		.direct = false,
+	},
+	{
+		.name = MSIC_DIE_NAME,
+		.index = PMIC_DIE,
+		.slope = 1000,
+		.intercept = 0,
+		.temp_correlation = linear_temp_correlation,
+		.direct = true,
+	},
+};
+
+/* Bodegabay - PRh thermal sensor list */
+static struct intel_mid_thermal_sensor bdgb_sensors[] = {
+	{
+		.name = SKIN0_NAME,
+		.index = SYS0,
+		.slope = 410,
+		.intercept = 16808,
+		.temp_correlation = linear_temp_correlation,
+		.direct = false,
+	},
+	{
+		.name = SKIN1_NAME,
+		.index = SYS0,
+		.slope = 665,
+		.intercept = 8375,
+		.temp_correlation = linear_temp_correlation,
+		.direct = false,
+	},
+	{
+		.name = MSIC_DIE_NAME,
+		.index = PMIC_DIE,
+		.slope = 1000,
+		.intercept = 0,
+		.temp_correlation = linear_temp_correlation,
+		.direct = true,
+	},
+};
+
+static struct intel_mid_thermal_platform_data pdata[] = {
+	[mrfl_thermal] = {
+		.num_sensors = 3,
+		.sensors = mrfl_sensors,
+	},
+	[bdgb_thermal] = {
+		.num_sensors = 3,
+		.sensors = bdgb_sensors,
+	},
+};
+
+void __init *mrfl_thermal_platform_data(void *info)
+{
+	struct platform_device *pdev;
+	struct sfi_device_table_entry *entry = info;
+
+	pdev = platform_device_alloc(MRFL_THERM_DEV_NAME, -1);
+	if (!pdev) {
+		pr_err("out of memory for SFI platform dev %s\n",
+			MRFL_THERM_DEV_NAME);
+		return NULL;
+	}
+
+	if (platform_device_add(pdev)) {
+		pr_err("failed to add thermal platform device\n");
+		platform_device_put(pdev);
+		return NULL;
+	}
+
+	pdev->dev.platform_data = &pdata[mrfl_thermal];
+
+	install_irq_resource(pdev, entry->irq);
+	register_rpmsg_service("rpmsg_mrfl_thermal", RPROC_SCU,
+				RP_BCOVE_THERMAL);
+
+	return 0;
+}
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_msic.h b/arch/x86/platform/intel-mid/device_libs/platform_msic.h
index b7be1d0..f5b78d4 100644
--- a/arch/x86/platform/intel-mid/device_libs/platform_msic.h
+++ b/arch/x86/platform/intel-mid/device_libs/platform_msic.h
@@ -12,6 +12,8 @@
 #ifndef _PLATFORM_MSIC_H_
 #define _PLATFORM_MSIC_H_
 
+#include <linux/mfd/intel_msic.h>
+
 extern struct intel_msic_platform_data msic_pdata;
 
 void *msic_generic_platform_data(void *info, enum intel_msic_block block);
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_msic_adc.c b/arch/x86/platform/intel-mid/device_libs/platform_msic_adc.c
new file mode 100644
index 0000000..f1ed88e
--- /dev/null
+++ b/arch/x86/platform/intel-mid/device_libs/platform_msic_adc.c
@@ -0,0 +1,56 @@
+/*
+ * platform_msic_adc.c: MSIC ADC platform data initilization file
+ *
+ * (C) Copyright 2008 Intel Corporation
+ * Author:
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/scatterlist.h>
+#include <linux/init.h>
+#include <linux/sfi.h>
+#include <asm/intel-mid.h>
+#include <asm/intel_mid_gpadc.h>
+#include <asm/intel_mid_remoteproc.h>
+#include "platform_msic.h"
+#include "platform_msic_adc.h"
+
+void __init *msic_adc_platform_data(void *info)
+{
+	struct platform_device *pdev = NULL;
+	struct sfi_device_table_entry *entry = info;
+	static struct intel_mid_gpadc_platform_data msic_adc_pdata;
+	int ret = 0;
+
+	pdev = platform_device_alloc(ADC_DEVICE_NAME, -1);
+
+	if (!pdev) {
+		pr_err("out of memory for SFI platform dev %s\n",
+					ADC_DEVICE_NAME);
+		goto out;
+	}
+
+	msic_adc_pdata.intr = 0xffff7fc0;
+
+	pdev->dev.platform_data = &msic_adc_pdata;
+
+	ret = platform_device_add(pdev);
+	if (ret) {
+		pr_err("failed to add adc platform device\n");
+		platform_device_put(pdev);
+		goto out;
+	}
+
+	install_irq_resource(pdev, entry->irq);
+
+	register_rpmsg_service("rpmsg_msic_adc", RPROC_SCU,
+				RP_MSIC_ADC);
+out:
+	return &msic_adc_pdata;
+}
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_scu_flis.c b/arch/x86/platform/intel-mid/device_libs/platform_scu_flis.c
new file mode 100644
index 0000000..778f70c
--- /dev/null
+++ b/arch/x86/platform/intel-mid/device_libs/platform_scu_flis.c
@@ -0,0 +1,290 @@
+/*
+ * platform_scu_flis.c: scu_flis platform data initilization file
+ *
+ * (C) Copyright 2013 Intel Corporation
+ * Author: Ning Li <ning.li@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+#include <linux/input.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <asm/intel-mid.h>
+#include <asm/intel_mid_remoteproc.h>
+#include <asm/intel_scu_flis.h>
+#include "platform_scu_flis.h"
+
+static struct pin_mmio_flis_t tng_pin_mmio_flis_table[TNG_PIN_NUM] = {
+	[tng_usb_ulpi_0_clk] = { writable, 0x0500 },
+	[tng_usb_ulpi_0_data_0] = { writable, 0x0504 },
+	[tng_usb_ulpi_0_data_1] = { writable, 0x0508 },
+	[tng_usb_ulpi_0_data_2] = { writable, 0x050C },
+	[tng_usb_ulpi_0_data_3] = { writable, 0x0510 },
+	[tng_usb_ulpi_0_data_4] = { writable, 0x0514 },
+	[tng_usb_ulpi_0_data_5] = { writable, 0x0518 },
+	[tng_usb_ulpi_0_data_6] = { writable, 0x051C },
+	[tng_usb_ulpi_0_data_7] = { writable, 0x0520 },
+	[tng_usb_ulpi_0_dir] = { writable, 0x0524 },
+	[tng_usb_ulpi_0_nxt] = { writable, 0x0528 },
+	[tng_usb_ulpi_0_refclk] = { writable, 0x052C },
+	[tng_usb_ulpi_0_stp] = { writable, 0x0530 },
+	[tng_emmc_0_clk] = { writable, 0x0900 },
+	[tng_emmc_0_cmd] = { writable, 0x0904 },
+	[tng_emmc_0_d_0] = { writable, 0x0908 },
+	[tng_emmc_0_d_1] = { writable, 0x090C },
+	[tng_emmc_0_d_2] = { writable, 0x0910 },
+	[tng_emmc_0_d_3] = { writable, 0x0914 },
+	[tng_emmc_0_d_4] = { writable, 0x0918 },
+	[tng_emmc_0_d_5] = { writable, 0x091C },
+	[tng_emmc_0_d_6] = { writable, 0x0920 },
+	[tng_emmc_0_d_7] = { writable, 0x0924 },
+	[tng_emmc_0_rst_b] = { writable, 0x0928 },
+	[tng_gp_emmc_1_clk] = { writable, 0x092C },
+	[tng_gp_emmc_1_cmd] = { writable, 0x0930 },
+	[tng_gp_emmc_1_d_0] = { writable, 0x0934 },
+	[tng_gp_emmc_1_d_1] = { writable, 0x0938 },
+	[tng_gp_emmc_1_d_2] = { writable, 0x093C },
+	[tng_gp_emmc_1_d_3] = { writable, 0x0940 },
+	[tng_gp_emmc_1_d_4] = { writable, 0x0944 },
+	[tng_gp_emmc_1_d_5] = { writable, 0x0948 },
+	[tng_gp_emmc_1_d_6] = { writable, 0x094C },
+	[tng_gp_emmc_1_d_7] = { writable, 0x0950 },
+	[tng_gp_emmc_1_rst_b] = { writable, 0x0954 },
+	[tng_gp_28] = { writable, 0x0958 },
+	[tng_gp_29] = { writable, 0x095C },
+	[tng_gp_sdio_0_cd_b] = { writable, 0x0D00 },
+	[tng_gp_sdio_0_clk] = { writable, 0x0D04 },
+	[tng_gp_sdio_0_cmd] = { writable, 0x0D08 },
+	[tng_gp_sdio_0_dat_0] = { writable, 0x0D0C },
+	[tng_gp_sdio_0_dat_1] = { writable, 0x0D10 },
+	[tng_gp_sdio_0_dat_2] = { writable, 0x0D14 },
+	[tng_gp_sdio_0_dat_3] = { writable, 0x0D18 },
+	[tng_gp_sdio_0_lvl_clk_fb] = { writable, 0x0D1C },
+	[tng_gp_sdio_0_lvl_cmd_dir] = { writable, 0x0D20 },
+	[tng_gp_sdio_0_lvl_dat_dir] = { writable, 0x0D24 },
+	[tng_gp_sdio_0_lvl_sel] = { writable, 0x0D28 },
+	[tng_gp_sdio_0_powerdown_b] = { writable, 0x0D2C },
+	[tng_gp_sdio_0_wp] = { writable, 0x0D30 },
+	[tng_gp_sdio_1_clk] = { writable, 0x0D34 },
+	[tng_gp_sdio_1_cmd] = { writable, 0x0D38 },
+	[tng_gp_sdio_1_dat_0] = { writable, 0x0D3C },
+	[tng_gp_sdio_1_dat_1] = { writable, 0x0D40 },
+	[tng_gp_sdio_1_dat_2] = { writable, 0x0D44 },
+	[tng_gp_sdio_1_dat_3] = { writable, 0x0D48 },
+	[tng_gp_sdio_1_powerdown_b] = { writable, 0x0D4C },
+	[tng_mhsi_acdata] = { writable, 0x1100 },
+	[tng_mhsi_acflag] = { writable, 0x1104 },
+	[tng_mhsi_acready] = { writable, 0x1108 },
+	[tng_mhsi_acwake] = { writable, 0x110C },
+	[tng_mhsi_cadata] = { writable, 0x1110 },
+	[tng_mhsi_caflag] = { writable, 0x1114 },
+	[tng_mhsi_caready] = { writable, 0x1118 },
+	[tng_mhsi_cawake] = { writable, 0x111C },
+	[tng_gp_mslim_0_bclk] = { writable, 0x1500 },
+	[tng_gp_mslim_0_bdat] = { writable, 0x1504 },
+	[tng_gp_ssp_0_clk] = { writable, 0x1508 },
+	[tng_gp_ssp_0_fs] = { writable, 0x150C },
+	[tng_gp_ssp_0_rxd] = { writable, 0x1510 },
+	[tng_gp_ssp_0_txd] = { writable, 0x1514 },
+	[tng_gp_ssp_1_clk] = { writable, 0x1518 },
+	[tng_gp_ssp_1_fs] = { writable, 0x151C },
+	[tng_gp_ssp_1_rxd] = { writable, 0x1520 },
+	[tng_gp_ssp_1_txd] = { writable, 0x1524 },
+	[tng_gp_ssp_2_clk] = { writable, 0x1528 },
+	[tng_gp_ssp_2_fs] = { writable, 0x152C },
+	[tng_gp_ssp_2_rxd] = { writable, 0x1530 },
+	[tng_gp_ssp_2_txd] = { writable, 0x1534 },
+	[tng_gp_ssp_3_clk] = { writable, 0x1900 },
+	[tng_gp_ssp_3_fs] = { writable, 0x1904 },
+	[tng_gp_ssp_3_rxd] = { writable, 0x1908 },
+	[tng_gp_ssp_3_txd] = { writable, 0x190C },
+	[tng_gp_ssp_4_clk] = { writable, 0x1910 },
+	[tng_gp_ssp_4_fs_0] = { writable, 0x1914 },
+	[tng_gp_ssp_4_fs_1] = { writable, 0x1918 },
+	[tng_gp_ssp_4_fs_2] = { writable, 0x191C },
+	[tng_gp_ssp_4_fs_3] = { writable, 0x1920 },
+	[tng_gp_ssp_4_rxd] = { writable, 0x1924 },
+	[tng_gp_ssp_4_txd] = { writable, 0x1928 },
+	[tng_gp_ssp_5_clk] = { writable, 0x192C },
+	[tng_gp_ssp_5_fs_0] = { writable, 0x1930 },
+	[tng_gp_ssp_5_fs_1] = { writable, 0x1934 },
+	[tng_gp_ssp_5_fs_2] = { writable, 0x1938 },
+	[tng_gp_ssp_5_fs_3] = { writable, 0x193C },
+	[tng_gp_ssp_5_rxd] = { writable, 0x1940 },
+	[tng_gp_ssp_5_txd] = { writable, 0x1944 },
+	[tng_gp_ssp_6_clk] = { writable, 0x1948 },
+	[tng_gp_ssp_6_fs] = { writable, 0x194C },
+	[tng_gp_ssp_6_rxd] = { writable, 0x1950 },
+	[tng_gp_ssp_6_txd] = { writable, 0x1954 },
+	[tng_gp_i2c_1_scl] = { writable, 0x1D00 },
+	[tng_gp_i2c_1_sda] = { writable, 0x1D04 },
+	[tng_gp_i2c_2_scl] = { writable, 0x1D08 },
+	[tng_gp_i2c_2_sda] = { writable, 0x1D0C },
+	[tng_gp_i2c_3_scl] = { writable, 0x1D10 },
+	[tng_gp_i2c_3_sda] = { writable, 0x1D14 },
+	[tng_gp_i2c_4_scl] = { writable, 0x1D18 },
+	[tng_gp_i2c_4_sda] = { writable, 0x1D1C },
+	[tng_gp_i2c_5_scl] = { writable, 0x1D20 },
+	[tng_gp_i2c_5_sda] = { writable, 0x1D24 },
+	[tng_gp_i2c_6_scl] = { writable, 0x1D28 },
+	[tng_gp_i2c_6_sda] = { writable, 0x1D2C },
+	[tng_gp_i2c_7_scl] = { writable, 0x1D30 },
+	[tng_gp_i2c_7_sda] = { writable, 0x1D34 },
+	[tng_gp_uart_0_cts] = { writable, 0x2100 },
+	[tng_gp_uart_0_rts] = { writable, 0x2104 },
+	[tng_gp_uart_0_rx] = { writable, 0x2108 },
+	[tng_gp_uart_0_tx] = { writable, 0x210C },
+	[tng_gp_uart_1_cts] = { writable, 0x2110 },
+	[tng_gp_uart_1_rts] = { writable, 0x2114 },
+	[tng_gp_uart_1_rx] = { writable, 0x2118 },
+	[tng_gp_uart_1_tx] = { writable, 0x211C },
+	[tng_gp_uart_2_cts] = { writable, 0x2120 },
+	[tng_gp_uart_2_rts] = { writable, 0x2124 },
+	[tng_gp_uart_2_rx] = { writable, 0x2128 },
+	[tng_gp_uart_2_tx] = { writable, 0x212C },
+	[tng_gp_13] = { writable, 0x2500 },
+	[tng_gp_14] = { writable, 0x2504 },
+	[tng_gp_15] = { writable, 0x2508 },
+	[tng_gp_16] = { writable, 0x250C },
+	[tng_gp_17] = { writable, 0x2510 },
+	[tng_gp_18] = { writable, 0x2514 },
+	[tng_gp_19] = { writable, 0x2518 },
+	[tng_gp_20] = { writable, 0x251C },
+	[tng_gp_21] = { writable, 0x2520 },
+	[tng_gp_22] = { writable, 0x2524 },
+	[tng_gp_23] = { writable, 0x2528 },
+	[tng_gp_24] = { writable, 0x252C },
+	[tng_gp_25] = { writable, 0x2530 },
+	[tng_gp_fast_int_0] = { writable, 0x2534 },
+	[tng_gp_fast_int_1] = { writable, 0x2538 },
+	[tng_gp_fast_int_2] = { writable, 0x253C },
+	[tng_gp_fast_int_3] = { writable, 0x2540 },
+	[tng_gp_pwm_0] = { writable, 0x2544 },
+	[tng_gp_pwm_1] = { writable, 0x2548 },
+	[tng_gp_camerasb_0] = { writable, 0x2900 },
+	[tng_gp_camerasb_1] = { writable, 0x2904 },
+	[tng_gp_camerasb_2] = { writable, 0x2908 },
+	[tng_gp_camerasb_3] = { writable, 0x290C },
+	[tng_gp_camerasb_4] = { writable, 0x2910 },
+	[tng_gp_camerasb_5] = { writable, 0x2914 },
+	[tng_gp_camerasb_6] = { writable, 0x2918 },
+	[tng_gp_camerasb_7] = { writable, 0x291C },
+	[tng_gp_camerasb_8] = { writable, 0x2920 },
+	[tng_gp_camerasb_9] = { writable, 0x2924 },
+	[tng_gp_camerasb_10] = { writable, 0x2928 },
+	[tng_gp_camerasb_11] = { writable, 0x292C },
+	[tng_gp_clkph_0] = { writable, 0x2D00 },
+	[tng_gp_clkph_1] = { writable, 0x2D04 },
+	[tng_gp_clkph_2] = { writable, 0x2D08 },
+	[tng_gp_clkph_3] = { writable, 0x2D0C },
+	[tng_gp_clkph_4] = { writable, 0x2D10 },
+	[tng_gp_clkph_5] = { writable, 0x2D14 },
+	[tng_gp_hdmi_hpd] = { writable, 0x2D18 },
+	[tng_gp_intd_dsi_te1] = { writable, 0x2D1C },
+	[tng_gp_intd_dsi_te2] = { writable, 0x2D20 },
+	[tng_osc_clk_ctrl_0] = { writable, 0x2D24 },
+	[tng_osc_clk_ctrl_1] = { writable, 0x2D28 },
+	[tng_osc_clk_out_0] = { writable, 0x2D2C },
+	[tng_osc_clk_out_1] = { writable, 0x2D30 },
+	[tng_osc_clk_out_2] = { writable, 0x2D34 },
+	[tng_osc_clk_out_3] = { writable, 0x2D38 },
+	[tng_osc_clk_out_4] = { writable, 0x2D3C },
+	[tng_resetout_b] = { writable, 0x2D40 },
+	[tng_xxpmode] = { writable, 0x2D44 },
+	[tng_xxprdy] = { writable, 0x2D48 },
+	[tng_xxpreq_b] = { writable, 0x2D4C },
+	[tng_gp_26] = { writable, 0x2D50 },
+	[tng_gp_27] = { writable, 0x2D54 },
+	[tng_i2c_0_scl] = { writable, 0x3100 },
+	[tng_i2c_0_sda] = { writable, 0x3104 },
+	[tng_ierr_b] = { writable, 0x3108 },
+	[tng_jtag_tckc] = { writable, 0x310C },
+	[tng_jtag_tdic] = { writable, 0x3110 },
+	[tng_jtag_tdoc] = { writable, 0x3114 },
+	[tng_jtag_tmsc] = { writable, 0x3118 },
+	[tng_jtag_trst_b] = { writable, 0x311C },
+	[tng_prochot_b] = { writable, 0x3120 },
+	[tng_rtc_clk] = { writable, 0x3124 },
+	[tng_svid_vclk] = { writable, 0x3128 },
+	[tng_svid_vdio] = { writable, 0x3130 },
+	[tng_thermtrip_b] = { writable, 0x3134 },
+	[tng_standby] = { writable, 0x3138 },
+	[tng_gp_kbd_dkin_0] = { writable, 0x3500 },
+	[tng_gp_kbd_dkin_1] = { writable, 0x3504 },
+	[tng_gp_kbd_dkin_2] = { writable, 0x3508 },
+	[tng_gp_kbd_dkin_3] = { writable, 0x350C },
+	[tng_gp_kbd_mkin_0] = { writable, 0x3510 },
+	[tng_gp_kbd_mkin_1] = { writable, 0x3514 },
+	[tng_gp_kbd_mkin_2] = { writable, 0x3518 },
+	[tng_gp_kbd_mkin_3] = { writable, 0x351C },
+	[tng_gp_kbd_mkin_4] = { writable, 0x3520 },
+	[tng_gp_kbd_mkin_5] = { writable, 0x3524 },
+	[tng_gp_kbd_mkin_6] = { writable, 0x3528 },
+	[tng_gp_kbd_mkin_7] = { writable, 0x352C },
+	[tng_gp_kbd_mkout_0] = { writable, 0x3530 },
+	[tng_gp_kbd_mkout_1] = { writable, 0x3534 },
+	[tng_gp_kbd_mkout_2] = { writable, 0x3538 },
+	[tng_gp_kbd_mkout_3] = { writable, 0x353C },
+	[tng_gp_kbd_mkout_4] = { writable, 0x3540 },
+	[tng_gp_kbd_mkout_5] = { writable, 0x3544 },
+	[tng_gp_kbd_mkout_6] = { writable, 0x3548 },
+	[tng_gp_kbd_mkout_7] = { writable, 0x354C },
+	[tng_gp_0] = { writable, 0x3900 },
+	[tng_gp_1] = { writable, 0x3904 },
+	[tng_gp_2] = { writable, 0x3908 },
+	[tng_gp_3] = { writable, 0x390C },
+	[tng_gp_4] = { writable, 0x3910 },
+	[tng_gp_5] = { writable, 0x3914 },
+	[tng_gp_6] = { writable, 0x3918 },
+	[tng_gp_7] = { writable, 0x391C },
+	[tng_gp_8] = { writable, 0x3920 },
+	[tng_gp_9] = { writable, 0x3924 },
+	[tng_gp_10] = { writable, 0x3928 },
+	[tng_gp_11] = { writable, 0x392C },
+	[tng_gp_12] = { writable, 0x3930 },
+	[tng_gp_mpti_clk] = { writable, 0x3D00 },
+	[tng_gp_mpti_data_0] = { writable, 0x3D04 },
+	[tng_gp_mpti_data_1] = { writable, 0x3D08 },
+	[tng_gp_mpti_data_2] = { writable, 0x3D0C },
+	[tng_gp_mpti_data_3] = { writable, 0x3D10 },
+};
+
+static int __init intel_scu_flis_init(void)
+{
+	int ret;
+	struct platform_device *pdev = NULL;
+	static struct intel_scu_flis_platform_data flis_pdata;
+
+	flis_pdata.pin_t = NULL;
+	flis_pdata.pin_num = TNG_PIN_NUM;
+	flis_pdata.flis_base = 0xFF0C0000;
+	flis_pdata.flis_len = 0x8000;
+	flis_pdata.mmio_flis_t = tng_pin_mmio_flis_table;
+
+	pdev = platform_device_alloc(FLIS_DEVICE_NAME, -1);
+	if (!pdev) {
+		pr_err("out of memory for platform dev %s\n", FLIS_DEVICE_NAME);
+		ret = -EINVAL;
+		goto out;
+	}
+
+	pdev->dev.platform_data = &flis_pdata;
+
+	ret = platform_device_add(pdev);
+	if (ret) {
+		pr_err("failed to add flis platform device\n");
+		platform_device_put(pdev);
+		goto out;
+	}
+
+	pr_info("intel_scu_flis platform device created\n");
+out:
+	return ret;
+}
+fs_initcall(intel_scu_flis_init);
+
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_scu_flis.h b/arch/x86/platform/intel-mid/device_libs/platform_scu_flis.h
new file mode 100644
index 0000000..cf48ae5
--- /dev/null
+++ b/arch/x86/platform/intel-mid/device_libs/platform_scu_flis.h
@@ -0,0 +1,17 @@
+/*
+ * platform_scu_flis.h: scu_flis platform data header file
+ *
+ * (C) Copyright 2012 Intel Corporation
+ * Author:
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+#ifndef _PLATFORM_SCU_FLIS_H_
+#define _PLATFORM_SCU_FLIS_H_
+
+#define FLIS_DEVICE_NAME "intel_scu_flis"
+
+#endif
diff --git a/arch/x86/platform/intel-mid/intel-mid.c b/arch/x86/platform/intel-mid/intel-mid.c
index 1bbedc4..0ba0699 100644
--- a/arch/x86/platform/intel-mid/intel-mid.c
+++ b/arch/x86/platform/intel-mid/intel-mid.c
@@ -10,7 +10,7 @@
  * as published by the Free Software Foundation; version 2
  * of the License.
  */
-
+#define	SFI_SIG_OEM0	"OEM0"
 #define pr_fmt(fmt) "intel_mid: " fmt
 
 #include <linux/init.h>
@@ -21,6 +21,7 @@
 #include <linux/irq.h>
 #include <linux/module.h>
 #include <linux/notifier.h>
+#include <linux/spinlock.h>
 
 #include <asm/setup.h>
 #include <asm/mpspec_def.h>
@@ -28,14 +29,14 @@
 #include <asm/apic.h>
 #include <asm/io_apic.h>
 #include <asm/intel-mid.h>
-#include <asm/intel_mid_vrtc.h>
 #include <asm/io.h>
 #include <asm/i8259.h>
 #include <asm/intel_scu_ipc.h>
+#include <asm/intel_mid_rpmsg.h>
 #include <asm/apb_timer.h>
 #include <asm/reboot.h>
-
 #include "intel_mid_weak_decls.h"
+#include "intel_soc_pmu.h"
 
 /*
  * the clockevent devices on Moorestown/Medfield can be APBT or LAPIC clock,
@@ -67,13 +68,26 @@ static void *(*get_intel_mid_ops[])(void) = INTEL_MID_OPS_INIT;
 enum intel_mid_cpu_type __intel_mid_cpu_chip;
 EXPORT_SYMBOL_GPL(__intel_mid_cpu_chip);
 
+static int force_cold_boot;
+module_param(force_cold_boot, int, 0644);
+MODULE_PARM_DESC(force_cold_boot,
+		 "Set to Y to force a COLD BOOT instead of a COLD RESET "
+		 "on the next reboot system call.");
+u32 nbr_hsi_clients = 2;
 static void intel_mid_power_off(void)
 {
+	pmu_power_off();
 };
 
 static void intel_mid_reboot(void)
 {
-	intel_scu_ipc_simple_command(IPCMSG_COLD_BOOT, 0);
+	if (intel_scu_ipc_fw_update()) {
+		pr_debug("intel_scu_fw_update: IFWI upgrade failed...\n");
+	}
+	if (force_cold_boot)
+		rpmsg_send_generic_simple_command(IPCMSG_COLD_BOOT, 0);
+	else
+		rpmsg_send_generic_simple_command(IPCMSG_COLD_RESET, 0);
 }
 
 static unsigned long __init intel_mid_calibrate_tsc(void)
@@ -83,7 +97,9 @@ static unsigned long __init intel_mid_calibrate_tsc(void)
 
 static void __init intel_mid_time_init(void)
 {
+#ifdef CONFIG_SFI
 	sfi_table_parse(SFI_SIG_MTMR, NULL, NULL, sfi_parse_mtmr);
+#endif
 	switch (intel_mid_timer_options) {
 	case INTEL_MID_TIMER_APBT_ONLY:
 		break;
@@ -103,15 +119,14 @@ static void __init intel_mid_time_init(void)
 	apbt_time_init();
 }
 
-static void intel_mid_arch_setup(void)
+static void __cpuinit intel_mid_arch_setup(void)
 {
 	if (boot_cpu_data.x86 != 6) {
 		pr_err("Unknown Intel MID CPU (%d:%d), default to Penwell\n",
 			boot_cpu_data.x86, boot_cpu_data.x86_model);
 		__intel_mid_cpu_chip = INTEL_MID_CPU_CHIP_PENWELL;
-		goto out;
+		return;
 	}
-
 	switch (boot_cpu_data.x86_model) {
 	case 0x35:
 		__intel_mid_cpu_chip = INTEL_MID_CPU_CHIP_CLOVERVIEW;
@@ -120,6 +135,12 @@ static void intel_mid_arch_setup(void)
 	case 0x4A:
 		__intel_mid_cpu_chip = INTEL_MID_CPU_CHIP_TANGIER;
 		break;
+	case 0x5A:
+		__intel_mid_cpu_chip = INTEL_MID_CPU_CHIP_ANNIEDALE;
+		break;
+	case 0x5D:
+		__intel_mid_cpu_chip = INTEL_MID_CPU_CHIP_CARBONCANYON;
+		break;
 	case 0x27:
 	default:
 		__intel_mid_cpu_chip = INTEL_MID_CPU_CHIP_PENWELL;
@@ -133,7 +154,6 @@ static void intel_mid_arch_setup(void)
 		pr_info("ARCH: Uknown SoC, assuming PENWELL!\n");
 	}
 
-out:
 	if (intel_mid_ops->arch_setup)
 		intel_mid_ops->arch_setup();
 }
@@ -163,6 +183,9 @@ void __init x86_intel_mid_early_setup(void)
 {
 	x86_init.resources.probe_roms = x86_init_noop;
 	x86_init.resources.reserve_resources = x86_init_noop;
+	x86_init.oem.arch_setup = intel_mid_arch_setup;
+	x86_init.timers.setup_percpu_clockev = x86_init_noop;
+	x86_cpuinit.setup_percpu_clockev = apbt_setup_secondary_clock;
 
 	x86_init.timers.timer_init = intel_mid_time_init;
 	x86_init.timers.setup_percpu_clockev = x86_init_noop;
@@ -214,4 +237,3 @@ static inline int __init setup_x86_intel_mid_timer(char *arg)
 	return 0;
 }
 __setup("x86_intel_mid_timer=", setup_x86_intel_mid_timer);
-
diff --git a/arch/x86/platform/intel-mid/intel_mid_pcihelpers.c b/arch/x86/platform/intel-mid/intel_mid_pcihelpers.c
new file mode 100644
index 0000000..85d4be8
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_mid_pcihelpers.c
@@ -0,0 +1,105 @@
+#include <linux/export.h>
+#include <linux/pci.h>
+
+#include <asm/intel_mid_pcihelpers.h>
+
+/* Unified message bus read/write operation */
+static DEFINE_SPINLOCK(msgbus_lock);
+
+static struct pci_dev *pci_root;
+
+static int intel_mid_msgbus_init(void)
+{
+        pci_root = pci_get_bus_and_slot(0, PCI_DEVFN(0, 0));
+        if (!pci_root) {
+                printk(KERN_ALERT "%s: Error: msgbus PCI handle NULL",
+                        __func__);
+                return -ENODEV;
+        }
+        return 0;
+}
+fs_initcall(intel_mid_msgbus_init);
+
+u32 intel_mid_msgbus_read32_raw(u32 cmd)
+{
+        unsigned long irq_flags;
+        u32 data;
+
+        spin_lock_irqsave(&msgbus_lock, irq_flags);
+        pci_write_config_dword(pci_root, PCI_ROOT_MSGBUS_CTRL_REG, cmd);
+        pci_read_config_dword(pci_root, PCI_ROOT_MSGBUS_DATA_REG, &data);
+        spin_unlock_irqrestore(&msgbus_lock, irq_flags);
+
+        return data;
+}
+EXPORT_SYMBOL(intel_mid_msgbus_read32_raw);
+
+void intel_mid_msgbus_write32_raw(u32 cmd, u32 data)
+{
+        unsigned long irq_flags;
+
+        spin_lock_irqsave(&msgbus_lock, irq_flags);
+        pci_write_config_dword(pci_root, PCI_ROOT_MSGBUS_DATA_REG, data);
+        pci_write_config_dword(pci_root, PCI_ROOT_MSGBUS_CTRL_REG, cmd);
+        spin_unlock_irqrestore(&msgbus_lock, irq_flags);
+}
+EXPORT_SYMBOL(intel_mid_msgbus_write32_raw);
+
+u32 intel_mid_msgbus_read32(u8 port, u32 addr)
+{
+        unsigned long irq_flags;
+        u32 data;
+        u32 cmd;
+        u32 cmdext;
+
+        cmd = (PCI_ROOT_MSGBUS_READ << 24) | (port << 16) |
+                ((addr & 0xff) << 8) | PCI_ROOT_MSGBUS_DWORD_ENABLE;
+        cmdext = addr & 0xffffff00;
+
+        spin_lock_irqsave(&msgbus_lock, irq_flags);
+
+        if (cmdext) {
+                /* This resets to 0 automatically, no need to write 0 */
+                pci_write_config_dword(pci_root, PCI_ROOT_MSGBUS_CTRL_EXT_REG,
+                        cmdext);
+        }
+
+        pci_write_config_dword(pci_root, PCI_ROOT_MSGBUS_CTRL_REG, cmd);
+        pci_read_config_dword(pci_root, PCI_ROOT_MSGBUS_DATA_REG, &data);
+        spin_unlock_irqrestore(&msgbus_lock, irq_flags);
+
+        return data;
+}
+
+EXPORT_SYMBOL(intel_mid_msgbus_read32);
+void intel_mid_msgbus_write32(u8 port, u32 addr, u32 data)
+{
+        unsigned long irq_flags;
+        u32 cmd;
+        u32 cmdext;
+
+        cmd = (PCI_ROOT_MSGBUS_WRITE << 24) | (port << 16) |
+                ((addr & 0xFF) << 8) | PCI_ROOT_MSGBUS_DWORD_ENABLE;
+        cmdext = addr & 0xffffff00;
+
+        spin_lock_irqsave(&msgbus_lock, irq_flags);
+        pci_write_config_dword(pci_root, PCI_ROOT_MSGBUS_DATA_REG, data);
+
+        if (cmdext) {
+                /* This resets to 0 automatically, no need to write 0 */
+                pci_write_config_dword(pci_root, PCI_ROOT_MSGBUS_CTRL_EXT_REG,
+                        cmdext);
+        }
+
+        pci_write_config_dword(pci_root, PCI_ROOT_MSGBUS_CTRL_REG, cmd);
+        spin_unlock_irqrestore(&msgbus_lock, irq_flags);
+}
+EXPORT_SYMBOL(intel_mid_msgbus_write32);
+
+/* called only from where is later then fs_initcall */
+u32 intel_mid_soc_stepping(void)
+{
+        return pci_root->revision;
+}
+EXPORT_SYMBOL(intel_mid_soc_stepping);
+
diff --git a/arch/x86/platform/intel-mid/intel_mid_scu.c b/arch/x86/platform/intel-mid/intel_mid_scu.c
new file mode 100644
index 0000000..a8e633c
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_mid_scu.c
@@ -0,0 +1,92 @@
+/*
+ * intel_mid_scu.c: Intel MID SCU platform initialization code
+ *
+ * (C) Copyright 2012 Intel Corporation
+ * Author:
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/scatterlist.h>
+#include <linux/sfi.h>
+#include <linux/intel_pmic_gpio.h>
+#include <linux/irq.h>
+#include <linux/rpmsg.h>
+#include <linux/module.h>
+#include <linux/list.h>
+#include <linux/platform_device.h>
+#include <linux/dma-mapping.h>
+
+#include <linux/platform_data/intel_mid_remoteproc.h>
+
+struct rpmsg_ns_list nslist = {
+	.list = LIST_HEAD_INIT(nslist.list),
+	.lock = __MUTEX_INITIALIZER(nslist.lock),
+};
+
+static struct intel_mid_rproc_pdata intel_scu_pdata = {
+	.name		= "intel_rproc_scu",
+	.firmware	= "intel_mid/intel_mid_remoteproc.fw",
+	.nslist		= &nslist,
+};
+
+static u64 intel_scu_dmamask = DMA_BIT_MASK(32);
+
+static struct platform_device intel_scu_device = {
+	.name		= "intel_rproc_scu",
+	.id		= -1,
+	.dev		= {
+		.platform_data = &intel_scu_pdata,
+		.dma_mask = &intel_scu_dmamask,
+	},
+};
+
+void register_rpmsg_service(char *name, int id, u32 addr)
+{
+	struct rpmsg_ns_info *info;
+	info = rpmsg_ns_alloc(name, id, addr);
+	rpmsg_ns_add_to_list(info, &nslist);
+}
+
+int intel_mid_rproc_init(void)
+{
+	int err;
+
+	/* generic rpmsg channels */
+	register_rpmsg_service("rpmsg_ipc_command", RPROC_SCU, RP_IPC_COMMAND);
+	register_rpmsg_service("rpmsg_ipc_simple_command",
+				RPROC_SCU, RP_IPC_SIMPLE_COMMAND);
+	register_rpmsg_service("rpmsg_ipc_raw_command",
+				RPROC_SCU, RP_IPC_RAW_COMMAND);
+
+	register_rpmsg_service("rpmsg_pmic", RPROC_SCU, RP_PMIC_ACCESS);
+	register_rpmsg_service("rpmsg_mip", RPROC_SCU, RP_MIP_ACCESS);
+	register_rpmsg_service("rpmsg_fw_update",
+					RPROC_SCU, RP_FW_ACCESS);
+	register_rpmsg_service("rpmsg_ipc_util",
+					RPROC_SCU, RP_IPC_UTIL);
+	register_rpmsg_service("rpmsg_flis", RPROC_SCU, RP_FLIS_ACCESS);
+	register_rpmsg_service("rpmsg_watchdog", RPROC_SCU, RP_SET_WATCHDOG);
+	register_rpmsg_service("rpmsg_umip", RPROC_SCU, RP_UMIP_ACCESS);
+	register_rpmsg_service("rpmsg_osip", RPROC_SCU, RP_OSIP_ACCESS);
+	register_rpmsg_service("rpmsg_vrtc", RPROC_SCU, RP_VRTC);
+	register_rpmsg_service("rpmsg_fw_logging", RPROC_SCU, RP_FW_LOGGING);
+	register_rpmsg_service("rpmsg_kpd_led", RPROC_SCU,
+				RP_MSIC_KPD_LED);
+	register_rpmsg_service("rpmsg_modem_nvram", RPROC_SCU,
+					RP_IPC_RAW_COMMAND);
+	register_rpmsg_service("rpmsg_mid_pwm", RPROC_SCU,
+				RP_MSIC_PWM);
+
+	err = platform_device_register(&intel_scu_device);
+	if (err < 0)
+		pr_err("Fail to register intel-mid-rproc platform device.\n");
+
+	return 0;
+}
+arch_initcall_sync(intel_mid_rproc_init);
diff --git a/arch/x86/platform/intel-mid/intel_mid_scu.h b/arch/x86/platform/intel-mid/intel_mid_scu.h
new file mode 100644
index 0000000..0601fe9
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_mid_scu.h
@@ -0,0 +1,15 @@
+/*
+ * intel_mid_scu.h: SCU initialization header file
+ *
+ * (C) Copyright 2012 Intel Corporation
+ * Author:
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+#ifndef _INTEL_MID_SCU_H_
+#define _INTEL_MID_SCU_H_
+extern int intel_mid_rproc_init(void) __attribute__((weak));
+#endif
diff --git a/arch/x86/platform/intel-mid/intel_mid_sfi.c b/arch/x86/platform/intel-mid/intel_mid_sfi.c
new file mode 100644
index 0000000..f73b84e
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_mid_sfi.c
@@ -0,0 +1,608 @@
+/*
+ * intel_mid_sfi.c: Intel MID SFI initialization code
+ *
+ * (C) Copyright 2012 Intel Corporation
+ * Author: Sathyanarayanan KN
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/scatterlist.h>
+#include <linux/sfi.h>
+#include <linux/intel_pmic_gpio.h>
+#include <linux/spi/spi.h>
+#include <linux/i2c.h>
+#include <linux/skbuff.h>
+#include <linux/gpio.h>
+#include <linux/gpio_keys.h>
+#include <linux/input.h>
+#include <linux/platform_device.h>
+#include <linux/irq.h>
+#include <linux/module.h>
+#include <linux/notifier.h>
+#include <linux/mmc/core.h>
+#include <linux/mmc/card.h>
+#include <linux/blkdev.h>
+
+#include <asm/setup.h>
+#include <asm/mpspec_def.h>
+#include <asm/hw_irq.h>
+#include <asm/apic.h>
+#include <asm/io_apic.h>
+#include <asm/intel-mid.h>
+#include <asm/intel_mid_vrtc.h>
+#include <asm/io.h>
+#include <asm/i8259.h>
+#include <asm/intel_scu_ipc.h>
+#include <asm/apb_timer.h>
+#include <asm/reboot.h>
+#include "intel_mid_weak_decls.h"
+
+#define	SFI_SIG_OEM0	"OEM0"
+#define MAX_IPCDEVS	24
+#define MAX_SCU_SPI	24
+#define MAX_SCU_I2C	24
+
+static struct platform_device *ipc_devs[MAX_IPCDEVS];
+static struct spi_board_info *spi_devs[MAX_SCU_SPI];
+static struct i2c_board_info *i2c_devs[MAX_SCU_I2C];
+static struct sfi_gpio_table_entry *gpio_table;
+static struct sfi_timer_table_entry sfi_mtimer_array[SFI_MTMR_MAX_NUM];
+static int ipc_next_dev;
+static int spi_next_dev;
+static int i2c_next_dev;
+static int i2c_bus[MAX_SCU_I2C];
+static int gpio_num_entry;
+static u32 sfi_mtimer_usage[SFI_MTMR_MAX_NUM];
+int sfi_mrtc_num;
+int sfi_mtimer_num;
+
+struct sfi_rtc_table_entry sfi_mrtc_array[SFI_MRTC_MAX];
+EXPORT_SYMBOL_GPL(sfi_mrtc_array);
+
+struct blocking_notifier_head intel_scu_notifier =
+			BLOCKING_NOTIFIER_INIT(intel_scu_notifier);
+EXPORT_SYMBOL_GPL(intel_scu_notifier);
+
+/* parse all the mtimer info to a static mtimer array */
+int __init sfi_parse_mtmr(struct sfi_table_header *table)
+{
+	struct sfi_table_simple *sb;
+	struct sfi_timer_table_entry *pentry;
+	struct mpc_intsrc mp_irq;
+	int totallen;
+
+	sb = (struct sfi_table_simple *)table;
+	if (!sfi_mtimer_num) {
+		sfi_mtimer_num = SFI_GET_NUM_ENTRIES(sb,
+					struct sfi_timer_table_entry);
+		pentry = (struct sfi_timer_table_entry *) sb->pentry;
+		totallen = sfi_mtimer_num * sizeof(*pentry);
+		memcpy(sfi_mtimer_array, pentry, totallen);
+	}
+
+	pr_debug("SFI MTIMER info (num = %d):\n", sfi_mtimer_num);
+	pentry = sfi_mtimer_array;
+	for (totallen = 0; totallen < sfi_mtimer_num; totallen++, pentry++) {
+		pr_debug("timer[%d]: paddr = 0x%08x, freq = %dHz, irq = %d\n",
+			totallen, (u32)pentry->phys_addr,
+			pentry->freq_hz, pentry->irq);
+			if (!pentry->irq)
+				continue;
+			mp_irq.type = MP_INTSRC;
+			mp_irq.irqtype = mp_INT;
+/* triggering mode edge bit 2-3, active high polarity bit 0-1 */
+			mp_irq.irqflag = 5;
+			mp_irq.srcbus = MP_BUS_ISA;
+			mp_irq.srcbusirq = pentry->irq;	/* IRQ */
+			mp_irq.dstapic = MP_APIC_ALL;
+			mp_irq.dstirq = pentry->irq;
+			mp_save_irq(&mp_irq);
+	}
+
+	return 0;
+}
+
+struct sfi_timer_table_entry *sfi_get_mtmr(int hint)
+{
+	int i;
+	if (hint < sfi_mtimer_num) {
+		if (!sfi_mtimer_usage[hint]) {
+			pr_debug("hint taken for timer %d irq %d\n",
+				hint, sfi_mtimer_array[hint].irq);
+			sfi_mtimer_usage[hint] = 1;
+			return &sfi_mtimer_array[hint];
+		}
+	}
+	/* take the first timer available */
+	for (i = 0; i < sfi_mtimer_num;) {
+		if (!sfi_mtimer_usage[i]) {
+			sfi_mtimer_usage[i] = 1;
+			return &sfi_mtimer_array[i];
+		}
+		i++;
+	}
+	return NULL;
+}
+
+void sfi_free_mtmr(struct sfi_timer_table_entry *mtmr)
+{
+	int i;
+	for (i = 0; i < sfi_mtimer_num;) {
+		if (mtmr->irq == sfi_mtimer_array[i].irq) {
+			sfi_mtimer_usage[i] = 0;
+			return;
+		}
+		i++;
+	}
+}
+
+/* parse all the mrtc info to a global mrtc array */
+int __init sfi_parse_mrtc(struct sfi_table_header *table)
+{
+	struct sfi_table_simple *sb;
+	struct sfi_rtc_table_entry *pentry;
+	struct mpc_intsrc mp_irq;
+
+	int totallen;
+
+	sb = (struct sfi_table_simple *)table;
+	if (!sfi_mrtc_num) {
+		sfi_mrtc_num = SFI_GET_NUM_ENTRIES(sb,
+						struct sfi_rtc_table_entry);
+		pentry = (struct sfi_rtc_table_entry *)sb->pentry;
+		totallen = sfi_mrtc_num * sizeof(*pentry);
+		memcpy(sfi_mrtc_array, pentry, totallen);
+	}
+
+	pr_debug("SFI RTC info (num = %d):\n", sfi_mrtc_num);
+	pentry = sfi_mrtc_array;
+	for (totallen = 0; totallen < sfi_mrtc_num; totallen++, pentry++) {
+		pr_debug("RTC[%d]: paddr = 0x%08x, irq = %d\n",
+			totallen, (u32)pentry->phys_addr, pentry->irq);
+		mp_irq.type = MP_INTSRC;
+		mp_irq.irqtype = mp_INT;
+		mp_irq.irqflag = 0xf;	/* level trigger and active low */
+		mp_irq.srcbus = MP_BUS_ISA;
+		mp_irq.srcbusirq = pentry->irq;	/* IRQ */
+		mp_irq.dstapic = MP_APIC_ALL;
+		mp_irq.dstirq = pentry->irq;
+		mp_save_irq(&mp_irq);
+	}
+	return 0;
+}
+
+
+/*
+ * Parsing GPIO table first, since the DEVS table will need this table
+ * to map the pin name to the actual pin.
+ */
+static int __init sfi_parse_gpio(struct sfi_table_header *table)
+{
+	struct sfi_table_simple *sb;
+	struct sfi_gpio_table_entry *pentry;
+	int num, i;
+
+	if (gpio_table)
+		return 0;
+	sb = (struct sfi_table_simple *)table;
+	num = SFI_GET_NUM_ENTRIES(sb, struct sfi_gpio_table_entry);
+	pentry = (struct sfi_gpio_table_entry *)sb->pentry;
+
+	gpio_table = (struct sfi_gpio_table_entry *)
+				kmalloc(num * sizeof(*pentry), GFP_KERNEL);
+	if (!gpio_table)
+		return -1;
+	memcpy(gpio_table, pentry, num * sizeof(*pentry));
+	gpio_num_entry = num;
+
+	pr_debug("GPIO pin info:\n");
+	for (i = 0; i < num; i++, pentry++)
+		pr_debug("info[%2d]: controller = %16.16s, pin_name = %16.16s,"
+		" pin = %d\n", i,
+			pentry->controller_name,
+			pentry->pin_name,
+			pentry->pin_no);
+	return 0;
+}
+
+int get_gpio_by_name(const char *name)
+{
+	struct sfi_gpio_table_entry *pentry = gpio_table;
+	int i;
+
+	if (!pentry)
+		return -1;
+	for (i = 0; i < gpio_num_entry; i++, pentry++) {
+		if (!strncmp(name, pentry->pin_name, SFI_NAME_LEN))
+			return pentry->pin_no;
+	}
+	return -1;
+}
+
+void __init intel_scu_device_register(struct platform_device *pdev)
+{
+	if (ipc_next_dev == MAX_IPCDEVS)
+		pr_err("too many SCU IPC devices");
+	else
+		ipc_devs[ipc_next_dev++] = pdev;
+}
+
+static void __init intel_scu_spi_device_register(struct spi_board_info *sdev)
+{
+	struct spi_board_info *new_dev;
+
+	if (spi_next_dev == MAX_SCU_SPI) {
+		pr_err("too many SCU SPI devices");
+		return;
+	}
+
+	new_dev = kzalloc(sizeof(*sdev), GFP_KERNEL);
+	if (!new_dev) {
+		pr_err("failed to alloc mem for delayed spi dev %s\n",
+			sdev->modalias);
+		return;
+	}
+	memcpy(new_dev, sdev, sizeof(*sdev));
+
+	spi_devs[spi_next_dev++] = new_dev;
+}
+
+static void __init intel_scu_i2c_device_register(int bus,
+						struct i2c_board_info *idev)
+{
+	struct i2c_board_info *new_dev;
+
+	if (i2c_next_dev == MAX_SCU_I2C) {
+		pr_err("too many SCU I2C devices");
+		return;
+	}
+
+	new_dev = kzalloc(sizeof(*idev), GFP_KERNEL);
+	if (!new_dev) {
+		pr_err("failed to alloc mem for delayed i2c dev %s\n",
+			idev->type);
+		return;
+	}
+	memcpy(new_dev, idev, sizeof(*idev));
+
+	i2c_bus[i2c_next_dev] = bus;
+	i2c_devs[i2c_next_dev++] = new_dev;
+}
+
+/* Called by IPC driver */
+void intel_scu_devices_create(void)
+{
+	int i;
+
+	for (i = 0; i < ipc_next_dev; i++)
+		platform_device_add(ipc_devs[i]);
+
+	for (i = 0; i < spi_next_dev; i++)
+		spi_register_board_info(spi_devs[i], 1);
+
+	for (i = 0; i < i2c_next_dev; i++) {
+		struct i2c_adapter *adapter;
+		struct i2c_client *client;
+
+		adapter = i2c_get_adapter(i2c_bus[i]);
+		if (adapter) {
+			client = i2c_new_device(adapter, i2c_devs[i]);
+			if (!client)
+				pr_err("can't create i2c device %s\n",
+					i2c_devs[i]->type);
+		} else
+			i2c_register_board_info(i2c_bus[i], i2c_devs[i], 1);
+	}
+	intel_scu_notifier_post(SCU_AVAILABLE, NULL);
+}
+EXPORT_SYMBOL_GPL(intel_scu_devices_create);
+
+/* Called by IPC driver */
+void intel_scu_devices_destroy(void)
+{
+	int i;
+
+	intel_scu_notifier_post(SCU_DOWN, NULL);
+
+	for (i = 0; i < ipc_next_dev; i++)
+		platform_device_del(ipc_devs[i]);
+}
+EXPORT_SYMBOL_GPL(intel_scu_devices_destroy);
+
+static struct platform_device *psh_ipc;
+void intel_psh_devices_create(void)
+{
+	psh_ipc = platform_device_alloc("intel_psh_ipc", 0);
+	if (psh_ipc == NULL) {
+		pr_err("out of memory for platform device psh_ipc.\n");
+		return;
+	}
+
+	platform_device_add(psh_ipc);
+}
+EXPORT_SYMBOL_GPL(intel_psh_devices_create);
+
+void intel_psh_devices_destroy(void)
+{
+	if (psh_ipc)
+		platform_device_del(psh_ipc);
+}
+EXPORT_SYMBOL_GPL(intel_psh_devices_destroy);
+
+void __init install_irq_resource(struct platform_device *pdev, int irq)
+{
+	/* Single threaded */
+	static struct resource __initdata res = {
+		.name = "IRQ",
+		.flags = IORESOURCE_IRQ,
+	};
+	res.start = irq;
+	platform_device_add_resources(pdev, &res, 1);
+}
+
+static void __init sfi_handle_ipc_dev(struct sfi_device_table_entry *pentry,
+					struct devs_id *dev)
+{
+	struct platform_device *pdev;
+	void *pdata = NULL;
+	pr_info("IPC bus, name = %16.16s, irq = 0x%2x\n",
+		pentry->name, pentry->irq);
+	pdata = dev->get_platform_data(pentry);
+	pdev = platform_device_alloc(pentry->name, 0);
+	if (pdev == NULL) {
+		pr_err("out of memory for SFI platform device '%s'.\n",
+			pentry->name);
+		return;
+	}
+	install_irq_resource(pdev, pentry->irq);
+
+	pdev->dev.platform_data = pdata;
+	intel_scu_device_register(pdev);
+}
+
+static void __init sfi_handle_spi_dev(struct sfi_device_table_entry *pentry,
+					struct devs_id *dev)
+{
+	struct spi_board_info spi_info;
+	void *pdata = NULL;
+
+	memset(&spi_info, 0, sizeof(spi_info));
+	strncpy(spi_info.modalias, pentry->name, SFI_NAME_LEN);
+	spi_info.irq = ((pentry->irq == (u8)0xff) ? 0 : pentry->irq);
+	spi_info.bus_num = pentry->host_num;
+	spi_info.chip_select = pentry->addr;
+	spi_info.max_speed_hz = pentry->max_freq;
+	pr_info("SPI bus=%d, name=%16.16s, irq=0x%2x, max_freq=%d, cs=%d\n",
+		spi_info.bus_num,
+		spi_info.modalias,
+		spi_info.irq,
+		spi_info.max_speed_hz,
+		spi_info.chip_select);
+
+	pdata = dev->get_platform_data(&spi_info);
+
+	spi_info.platform_data = pdata;
+	if (dev->delay)
+		intel_scu_spi_device_register(&spi_info);
+	else
+		spi_register_board_info(&spi_info, 1);
+}
+
+static void __init sfi_handle_i2c_dev(struct sfi_device_table_entry *pentry,
+					struct devs_id *dev)
+{
+	struct i2c_board_info i2c_info;
+	void *pdata = NULL;
+
+	memset(&i2c_info, 0, sizeof(i2c_info));
+	strncpy(i2c_info.type, pentry->name, SFI_NAME_LEN);
+	i2c_info.irq = ((pentry->irq == (u8)0xff) ? 0 : pentry->irq);
+	i2c_info.addr = pentry->addr;
+	pr_info("I2C bus = %d, name = %16.16s, irq = 0x%2x, addr = 0x%x\n",
+		pentry->host_num,
+		i2c_info.type,
+		i2c_info.irq,
+		i2c_info.addr);
+	pdata = dev->get_platform_data(&i2c_info);
+	i2c_info.platform_data = pdata;
+
+	if (dev->delay)
+		intel_scu_i2c_device_register(pentry->host_num, &i2c_info);
+	else
+		i2c_register_board_info(pentry->host_num, &i2c_info, 1);
+}
+
+static void __init sfi_handle_sd_dev(struct sfi_device_table_entry *pentry,
+					struct devs_id *dev)
+{
+	struct sd_board_info sd_info;
+	void *pdata = NULL;
+
+	memset(&sd_info, 0, sizeof(sd_info));
+	strncpy(sd_info.name, pentry->name, 16);
+	sd_info.bus_num = pentry->host_num;
+	sd_info.board_ref_clock = pentry->max_freq;
+	sd_info.addr = pentry->addr;
+	pr_info("SDIO bus = %d, name = %16.16s, "
+			"ref_clock = %d, addr =0x%x\n",
+			sd_info.bus_num,
+			sd_info.name,
+			sd_info.board_ref_clock,
+			sd_info.addr);
+	pdata = dev->get_platform_data(&sd_info);
+	sd_info.platform_data = pdata;
+}
+
+struct devs_id __init *get_device_id(u8 type, char *name)
+{
+	struct devs_id *dev = device_ids;
+
+	if (device_ids == NULL)
+		return NULL;
+
+	while (dev->name[0]) {
+		if (dev->type == type &&
+			!strncmp(dev->name, name, SFI_NAME_LEN)) {
+			return dev;
+		}
+		dev++;
+	}
+
+	return NULL;
+}
+
+static int __init sfi_parse_devs(struct sfi_table_header *table)
+{
+	struct sfi_table_simple *sb;
+	struct sfi_device_table_entry *pentry;
+	struct devs_id *dev = NULL;
+	int num, i;
+	int ioapic;
+	struct io_apic_irq_attr irq_attr;
+
+	sb = (struct sfi_table_simple *)table;
+	num = SFI_GET_NUM_ENTRIES(sb, struct sfi_device_table_entry);
+	pentry = (struct sfi_device_table_entry *)sb->pentry;
+
+	for (i = 0; i < num; i++, pentry++) {
+		int irq = pentry->irq;
+
+		if (irq != (u8)0xff) { /* native RTE case */
+			/* these SPI2 devices are not exposed to system as PCI
+			 * devices, but they have separate RTE entry in IOAPIC
+			 * so we have to enable them one by one here
+			 */
+			ioapic = mp_find_ioapic(irq);
+			if (ioapic >= 0) {
+				irq_attr.ioapic = ioapic;
+				irq_attr.ioapic_pin = irq;
+				irq_attr.trigger = 1;
+				if (intel_mid_identify_cpu() ==
+						INTEL_MID_CPU_CHIP_TANGIER) {
+					if (!strncmp(pentry->name,
+							"r69001-ts-i2c", 13))
+						/* active low */
+						irq_attr.polarity = 1;
+					else if (!strncmp(pentry->name,
+							"synaptics_3202", 14))
+						/* active low */
+						irq_attr.polarity = 1;
+					else if (irq == 41)
+						/* fast_int_1 */
+						irq_attr.polarity = 1;
+					else
+						/* active high */
+						irq_attr.polarity = 0;
+				} else {
+					/* PNW and CLV go with active low */
+					irq_attr.polarity = 1;
+				}
+				io_apic_set_pci_routing(NULL, irq, &irq_attr);
+			} else
+				printk(KERN_INFO "APIC entry not found for: name=%s, irq=%d, ioapic=%d\n",
+					pentry->name, irq, ioapic);
+		}
+		dev = get_device_id(pentry->type, pentry->name);
+
+		if ((dev == NULL) || (dev->get_platform_data == NULL))
+			continue;
+
+		if (dev->device_handler) {
+			dev->device_handler(pentry, dev);
+		} else {
+			switch (pentry->type) {
+			case SFI_DEV_TYPE_IPC:
+				sfi_handle_ipc_dev(pentry, dev);
+				break;
+			case SFI_DEV_TYPE_SPI:
+				sfi_handle_spi_dev(pentry, dev);
+				break;
+			case SFI_DEV_TYPE_I2C:
+				sfi_handle_i2c_dev(pentry, dev);
+				break;
+			case SFI_DEV_TYPE_SD:
+				sfi_handle_sd_dev(pentry, dev);
+				break;
+			case SFI_DEV_TYPE_HSI:
+			case SFI_DEV_TYPE_UART:
+			default:
+				break;
+			}
+		}
+	}
+
+	return 0;
+}
+
+static int __init sfi_parse_oemb(struct sfi_table_header *table)
+{
+	struct sfi_table_oemb *oemb;
+	u32 board_id;
+	u8 sig[SFI_SIGNATURE_SIZE + 1] = {'\0'};
+	u8 oem_id[SFI_OEM_ID_SIZE + 1] = {'\0'};
+	u8 oem_table_id[SFI_OEM_TABLE_ID_SIZE + 1] = {'\0'};
+
+	oemb = (struct sfi_table_oemb *) table;
+	if (!oemb) {
+		pr_err("%s: fail to read SFI OEMB Layout\n",
+			__func__);
+		return -ENODEV;
+	}
+
+	board_id = oemb->board_id | (oemb->board_fab << 4);
+
+	snprintf(sig, (SFI_SIGNATURE_SIZE + 1), "%s", oemb->header.sig);
+	snprintf(oem_id, (SFI_OEM_ID_SIZE + 1), "%s", oemb->header.oem_id);
+	snprintf(oem_table_id, (SFI_OEM_TABLE_ID_SIZE + 1), "%s",
+		 oemb->header.oem_table_id);
+	pr_info("SFI OEMB Layout\n");
+	pr_info("\tOEMB signature               : %s\n"
+		"\tOEMB length                  : %d\n"
+		"\tOEMB revision                : %d\n"
+		"\tOEMB checksum                : 0x%X\n"
+		"\tOEMB oem_id                  : %s\n"
+		"\tOEMB oem_table_id            : %s\n"
+		"\tOEMB board_id                : 0x%02X\n"
+		"\tOEMB iafw version            : %03d.%03d\n"
+		"\tOEMB val_hooks version       : %03d.%03d\n"
+		"\tOEMB ia suppfw version       : %03d.%03d\n"
+		"\tOEMB scu runtime version     : %03d.%03d\n"
+		"\tOEMB ifwi version            : %03d.%03d\n",
+		sig,
+		oemb->header.len,
+		oemb->header.rev,
+		oemb->header.csum,
+		oem_id,
+		oem_table_id,
+		board_id,
+		oemb->iafw_major_version,
+		oemb->iafw_main_version,
+		oemb->val_hooks_major_version,
+		oemb->val_hooks_minor_version,
+		oemb->ia_suppfw_major_version,
+		oemb->ia_suppfw_minor_version,
+		oemb->scu_runtime_major_version,
+		oemb->scu_runtime_minor_version,
+		oemb->ifwi_major_version,
+		oemb->ifwi_minor_version
+		);
+	return 0;
+}
+
+static int __init intel_mid_platform_init(void)
+{
+	/* Get SFI OEMB Layout */
+	sfi_table_parse(SFI_SIG_OEMB, NULL, NULL, sfi_parse_oemb);
+	sfi_table_parse(SFI_SIG_GPIO, NULL, NULL, sfi_parse_gpio);
+	sfi_table_parse(SFI_SIG_DEVS, NULL, NULL, sfi_parse_devs);
+
+	return 0;
+}
+arch_initcall(intel_mid_platform_init);
diff --git a/arch/x86/platform/intel-mid/intel_mid_vrtc.c b/arch/x86/platform/intel-mid/intel_mid_vrtc.c
index 4762cff..80f3edd 100644
--- a/arch/x86/platform/intel-mid/intel_mid_vrtc.c
+++ b/arch/x86/platform/intel-mid/intel_mid_vrtc.c
@@ -56,7 +56,7 @@ void vrtc_cmos_write(unsigned char val, unsigned char reg)
 }
 EXPORT_SYMBOL_GPL(vrtc_cmos_write);
 
-void vrtc_get_time(struct timespec *now)
+unsigned long vrtc_get_time(void)
 {
 	u8 sec, min, hour, mday, mon;
 	unsigned long flags;
@@ -82,38 +82,30 @@ void vrtc_get_time(struct timespec *now)
 	pr_info("vRTC: sec: %d min: %d hour: %d day: %d "
 		"mon: %d year: %d\n", sec, min, hour, mday, mon, year);
 
-	now->tv_sec = mktime(year, mon, mday, hour, min, sec);
-	now->tv_nsec = 0;
+	return mktime(year, mon, mday, hour, min, sec);
 }
 
-int vrtc_set_mmss(const struct timespec *now)
+/* Only care about the minutes and seconds */
+int vrtc_set_mmss(unsigned long nowtime)
 {
+	int real_sec, real_min;
 	unsigned long flags;
-	struct rtc_time tm;
-	int year;
-	int retval = 0;
-
-	rtc_time_to_tm(now->tv_sec, &tm);
-	if (!rtc_valid_tm(&tm) && tm.tm_year >= 72) {
-		/*
-		 * tm.year is the number of years since 1900, and the
-		 * vrtc need the years since 1972.
-		 */
-		year = tm.tm_year - 72;
-		spin_lock_irqsave(&rtc_lock, flags);
-		vrtc_cmos_write(year, RTC_YEAR);
-		vrtc_cmos_write(tm.tm_mon, RTC_MONTH);
-		vrtc_cmos_write(tm.tm_mday, RTC_DAY_OF_MONTH);
-		vrtc_cmos_write(tm.tm_hour, RTC_HOURS);
-		vrtc_cmos_write(tm.tm_min, RTC_MINUTES);
-		vrtc_cmos_write(tm.tm_sec, RTC_SECONDS);
-		spin_unlock_irqrestore(&rtc_lock, flags);
-	} else {
-		pr_err("%s: Invalid vRTC value: write of %lx to vRTC failed\n",
-			__FUNCTION__, now->tv_sec);
-		retval = -EINVAL;
-	}
-	return retval;
+	int vrtc_min;
+
+	spin_lock_irqsave(&rtc_lock, flags);
+	vrtc_min = vrtc_cmos_read(RTC_MINUTES);
+
+	real_sec = nowtime % 60;
+	real_min = nowtime / 60;
+	if (((abs(real_min - vrtc_min) + 15)/30) & 1)
+		real_min += 30;
+	real_min %= 60;
+
+	vrtc_cmos_write(real_sec, RTC_SECONDS);
+	vrtc_cmos_write(real_min, RTC_MINUTES);
+	spin_unlock_irqrestore(&rtc_lock, flags);
+
+	return 0;
 }
 
 void __init intel_mid_rtc_init(void)
diff --git a/arch/x86/platform/intel-mid/intel_mid_weak_decls.h b/arch/x86/platform/intel-mid/intel_mid_weak_decls.h
index 46aa25c..8b0910c 100644
--- a/arch/x86/platform/intel-mid/intel_mid_weak_decls.h
+++ b/arch/x86/platform/intel-mid/intel_mid_weak_decls.h
@@ -11,9 +11,11 @@
 
 
 /* __attribute__((weak)) makes these declarations overridable */
+extern struct devs_id __initconst device_ids[] __attribute__((weak));
 /* For every CPU addition a new get_<cpuname>_ops interface needs
  * to be added.
  */
 extern void *get_penwell_ops(void) __attribute__((weak));
 extern void *get_cloverview_ops(void) __attribute__((weak));
 extern void *get_tangier_ops(void) __attribute__((weak));
+extern void * __init get_anniedale_ops(void) __attribute__((weak));
diff --git a/arch/x86/platform/intel-mid/intel_soc_clv.h b/arch/x86/platform/intel-mid/intel_soc_clv.h
new file mode 100644
index 0000000..0b8294e
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_clv.h
@@ -0,0 +1,352 @@
+/*
+ * intel_soc_clv.h
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#ifdef CONFIG_REMOVEME_INTEL_ATOM_CLV_POWER
+
+#define   PM_SUPPORT				0x21
+
+#define ISP_POS			7
+#define ISP_SUB_CLASS		0x80
+#define PMU_MISC_SET_TIMEOUT	15000
+
+#define PMU1_MAX_DEVS   8
+#define PMU2_MAX_DEVS   55
+
+#define GFX_LSS_INDEX			1
+#define PMU_SDIO0_LSS_00		0
+#define PMU_EMMC0_LSS_01		1
+#define PMU_AONT_LSS_02			2
+#define PMU_HSI_LSS_03			3
+#define PMU_SECURITY_LSS_04		4
+#define PMU_EMMC1_LSS_05		5
+#define PMU_USB_OTG_LSS_06		6
+#define PMU_USB_HSIC_LSS_07		7
+#define PMU_AUDIO_ENGINE_LSS_08		8
+#define PMU_AUDIO_DMA_LSS_09		9
+#define PMU_SRAM_LSS_10			10
+#define PMU_SRAM_LSS_11			11
+#define PMU_SRAM_LSS_12			12
+#define PMU_SRAM_LSS_13			13
+#define PMU_SDIO2_LSS_14		14
+#define PMU_PTI_DAFCA_LSS_15		15
+#define PMU_SC_DMA_LSS_16		16
+#define PMU_SPIO_LSS_17			17
+#define PMU_SPI1_LSS_18			18
+#define PMU_SPI2_LSS_19			19
+#define PMU_I2C0_LSS_20			20
+#define PMU_I2C1_LSS_21			21
+#define PMU_HPET_LSS_22			22
+#define PMU_EXTTMR_LSS_23		23
+#define PMU_SC_FABRIC_LSS_24		24
+#define PMU_AUDIO_RAM_LSS_25		25
+#define PMU_SCU_ROM_LSS_26		26
+#define PMU_I2C2_LSS_27			27
+#define PMU_SSC_LSS_28			28
+#define PMU_SECURITY_LSS_29		29
+#define PMU_SDIO1_LSS_30		30
+#define PMU_vRTC_LSS_31			31
+#define PMU_SEC_TIMER_LSS_32		32
+#define PMU_I2C3_LSS_33			33
+#define PMU_I2C4_LSS_34			34
+#define PMU_I2C5_LSS_35			35
+#define PMU_SPI3_LSS_36			36
+#define PMU_GPIO1_LSS_37		37
+#define PMU_PWR_BUTTON_LSS_38		38
+#define PMU_GPIO0_LSS_39		39
+#define PMU_KEYBRD_LSS_40		40
+#define PMU_UART2_LSS_41		41
+#define PMU_ADC_LSS_42			42
+#define PMU_CHARGER_LSS_43		43
+#define PMU_SEC_TAPC_LSS_44		44
+#define PMU_RTC_LSS_45			45
+#define PMU_GPI_LSS_46			46
+#define PMU_BCU_LSS_47			47
+#define PMU_SSP2_LSS_48			48
+#define PMU_AUDIO_SLIM1_LSS_49		49
+#define PMU_AUDIO_SLIM2_LSS_50		50
+#define PMU_AUDIO_SSP0_LSS_51		51
+#define PMU_AUDIO_SSP1_LSS_52		52
+#define PMU_IOSF_OCP_BRG_LSS_53		53
+#define PMU_GP_DMA_LSS_54		54
+#define PMU_MSIC_RESET_LSS_55		55
+#define PMU_SOC_FUSE_LSS_56		56
+#define PMU_RSVD3_LSS_57		57
+#define PMU_SSP4_LSS_58			58
+#define PMU_RSVD5_LSS_59		59
+#define PMU_RSVD6_LSS_60		60
+#define PMU_RSVD7_LSS_61		61
+#define PMU_RSVD8_LSS_62		62
+#define PMU_RSVD9_LSS_63		63
+
+#define PMU_MAX_LSS			63
+#define PMU_LSS_IN_FIRST_DWORD		32
+
+#define EMMC0_LSS			PMU_EMMC0_LSS_01
+
+#define S0IX_TARGET_SSS0_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I3_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0IX_TARGET_SSS1_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+#define S0IX_TARGET_SSS2_MASK ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_UART2_LSS_41-32))
+
+#define S0IX_TARGET_SSS3_MASK ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define S0IX_TARGET_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0IX_TARGET_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define S0IX_TARGET_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define S0IX_TARGET_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define LPMP3_TARGET_SSS0_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I3_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_TARGET_SSS1_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_TARGET_SSS2_MASK ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_TARGET_SSS3_MASK ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define LPMP3_TARGET_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I0_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_TARGET_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_TARGET_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_TARGET_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define IGNORE_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_10) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_11) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_12) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_13) | \
+	SSMSK(D0I3_MASK, PMU_PTI_DAFCA_LSS_15))
+
+#define IGNORE_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SC_DMA_LSS_16-16) | \
+	SSMSK(D0I3_MASK, PMU_SPIO_LSS_17-16) | \
+	SSMSK(D0I3_MASK, PMU_HPET_LSS_22-16) | \
+	SSMSK(D0I3_MASK, PMU_EXTTMR_LSS_23-16) | \
+	SSMSK(D0I3_MASK, PMU_SC_FABRIC_LSS_24-16) | \
+	SSMSK(D0I3_MASK, PMU_SCU_ROM_LSS_26-16) | \
+	SSMSK(D0I3_MASK, PMU_SSC_LSS_28-16) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_29-16) | \
+	SSMSK(D0I3_MASK, PMU_vRTC_LSS_31-16))
+
+#define IGNORE_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_SEC_TIMER_LSS_32-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO0_LSS_39-32) | \
+	SSMSK(D0I3_MASK, PMU_ADC_LSS_42-32) | \
+	SSMSK(D0I3_MASK, PMU_CHARGER_LSS_43-32) | \
+	SSMSK(D0I3_MASK, PMU_SEC_TAPC_LSS_44-32) | \
+	SSMSK(D0I3_MASK, PMU_RTC_LSS_45-32) | \
+	SSMSK(D0I3_MASK, PMU_GPI_LSS_46-32) | \
+	SSMSK(D0I3_MASK, PMU_BCU_LSS_47-32))
+
+#define IGNORE_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_IOSF_OCP_BRG_LSS_53-48) | \
+	SSMSK(D0I3_MASK, PMU_MSIC_RESET_LSS_55-48) | \
+	SSMSK(D0I3_MASK, PMU_SOC_FUSE_LSS_56-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD3_LSS_57-48) | \
+	SSMSK(D0I3_MASK, PMU_SSP4_LSS_58-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD5_LSS_59-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD6_LSS_60-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD7_LSS_61-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD8_LSS_62-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD9_LSS_63-48))
+
+#define IGNORE_S3_WKC0 SSWKC(PMU_AONT_LSS_02)
+#define IGNORE_S3_WKC1 SSWKC(PMU_ADC_LSS_42-32)
+
+/* FIXME:: CVT Platform gives SRAM Error if SRAM is put in D0i3 */
+#define S0I3_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_AONT_LSS_02) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0I3_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_SPI2_LSS_19-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_RAM_LSS_25-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define S0I3_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_KEYBRD_LSS_40-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define S0I3_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM1_LSS_49-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM2_LSS_50-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48) | \
+	SSMSK(D0I3_MASK, PMU_GP_DMA_LSS_54-48))
+
+#define S0I1_SSS0 S0I3_SSS0
+#define S0I1_SSS1 S0I3_SSS1
+#define S0I1_SSS2 S0I3_SSS2
+#define S0I1_SSS3 S0I3_SSS3
+
+#define LPMP3_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_AONT_LSS_02) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_SPI2_LSS_19-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_KEYBRD_LSS_40-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM1_LSS_49-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM2_LSS_50-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48) | \
+	SSMSK(D0I3_MASK, PMU_GP_DMA_LSS_54-48))
+
+extern void pmu_set_s0ix_possible(int state);
+extern void log_wakeup_irq(void);
+extern void s0ix_complete(void);
+extern int mdfld_clv_nc_set_power_state(int, int, int, int *);
+
+#endif
diff --git a/arch/x86/platform/intel-mid/intel_soc_dump.c b/arch/x86/platform/intel-mid/intel_soc_dump.c
new file mode 100644
index 0000000..2441b1c
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_dump.c
@@ -0,0 +1,1586 @@
+/*
+ * intel_soc_dump.c - This driver provides a debugfs interface to read or
+ * write any registers inside the SoC. Supported access methods are:
+ * mmio, msg_bus, pci and i2c.
+ *
+ * Copyright (c) 2012, Intel Corporation.
+ * Author: Bin Gao <bin.gao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+/*
+ * Two files are created in debugfs root folder: dump_cmd and dump_output.
+ * Echo a dump command to the file dump_cmd, and then cat the file dump_output.
+ * Even for write command, you still have to run "cat dump_output", otherwise
+ * the data will not be really written.
+ *
+ * It works like this:
+ * $ echo "dump command" > dump_cmd
+ * $ cat dump_output
+ *
+ * I/O memory read: echo "r[1|2|4] mmio <addr> [<len>]" > dump_cmd
+ *     e.g.  echo "r mmio 0xff180000" > dump_cmd
+ *
+ * I/O memory write: echo "w[1|2|4] <addr> <val>" > dump_cmd
+ *     e.g.  echo "w mmio 0xff190000 0xf0107a08" > dump_cmd
+ *
+ * I/O port read: echo "r[1|2|4] port <port>" > dump_cmd
+ *     e.g.  echo "r port 0xcf8" > dump_cmd
+ *
+ * I/O port write: echo "w[1|2|4] <port> <val>" > dump_cmd
+ *     e.g.  echo "w4 port 0xcfc 0x80002188" > dump_cmd
+ *
+ * message bus read: echo "r msg_bus <port> <addr> [<len>]" > dump_cmd
+ *     e.g.  echo "r msg_bus 0x02 0x30" > dump_cmd
+ *
+ * message bus write: echo "w msg_bus <port> <addr> <val>" > dump_cmd
+ *     e.g.  echo "w msg_bus 0x02 0x30 0x1020003f" > dump_cmd
+ *
+ * pci config read: echo "r[1|2|4] pci <bus> <dev> <func> <reg> [<len>]" >
+ * dump_cmd
+ *     e.g.  echo "r1 pci 0 2 0 0x20" > dump_cmd
+ *
+ * pci config write: echo "w[1|2|4] pci <bus> <dev> <func> <reg> <value>" >
+ * dump_cmd
+ *     e.g.  echo "w pci 0 2 0 0x20 0x380020f3" > dump_cmd
+ *
+ * msr read: echo "r[4|8]  msr [<cpu>|all] <reg>" > dump_cmd
+ * read cab be 32bit(r4) or 64bit(r8), default is r8 (=r)
+ * cpu can be 0, 1, 2, 3, ... or all, default is all
+ *     e.g.  echo "r msr 0 0xcd" > dump_cmd
+ *     (read all cpu's msr reg 0xcd in 64bit mode)
+ *
+ * msr write: echo "w[4|8] msr [<cpu>|all] <reg> <val>" > dump_cmd
+ * write cab be 32bit(w4) or 64bit(w8), default is w8 (=w)
+ * cpu can be 0, 1, 2, 3, ... or all, default is all
+ *     e.g.  echo "w msr 1 289 0xf03090a0cc73be64" > dump_cmd
+ *     (write value 0xf03090a0cc73be64 to cpu 1's msr reg 289 in 64bit mode)
+ *
+ * i2c read:  echo "r i2c <bus> <addr>" > dump_cmd
+ *     e.g.  echo "r i2c 1 0x3e" > dump_cmd
+ *
+ * i2c write: echo "w i2c <bus> <addr> <val>" > dump_cmd
+ *      e.g.  echo "w i2c 2 0x70 0x0f" > dump_cmd
+ *
+ * SCU indirect memory read: echo "r[4] scu <addr>" > dump_cmd
+ *     e.g.  echo "r scu 0xff108194" > dump_cmd
+ *
+ * SCU indirect memory write: echo "w[4] scu <addr> <val>" > dump_cmd
+ *     e.g.  echo "w scu 0xff108194 0x03000001" > dump_cmd
+ *
+ *  SCU indirect read/write is limited to those addresses in
+ *  IndRdWrValidAddrRange array in SCU FW.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/delay.h>
+#include <linux/debugfs.h>
+#include <linux/io.h>
+#include <linux/err.h>
+#include <linux/seq_file.h>
+#include <linux/i2c.h>
+#include <linux/pm_runtime.h>
+#include <asm/uaccess.h>
+#include <asm/intel-mid.h>
+#include <asm/processor.h>
+#include <asm/msr.h>
+#include <asm/intel_mid_rpmsg.h>
+
+#define MAX_CMDLEN		96
+#define MAX_ERRLEN		255
+#define MIN_ARGS_NUM		3
+#define MAX_ARGS_NUM		8
+#define MAX_MMIO_PCI_LEN	4096
+#define MAX_MSG_BUS_LEN		64
+
+#define ACCESS_WIDTH_DEFAULT	0
+#define ACCESS_WIDTH_8BIT	1
+#define ACCESS_WIDTH_16BIT	2
+#define ACCESS_WIDTH_32BIT	4
+#define ACCESS_WIDTH_64BIT	8
+
+#define ACCESS_BUS_MMIO		1 /* I/O memory */
+#define ACCESS_BUS_PORT		2 /* I/O port */
+#define ACCESS_BUS_MSG_BUS	3 /* message bus */
+#define ACCESS_BUS_PCI		4 /* PCI bus */
+#define ACCESS_BUS_MSR		5 /* MSR registers */
+#define ACCESS_BUS_I2C		6 /* I2C bus */
+#define ACCESS_BUS_SCU_INDRW	7 /* SCU indirect read/write */
+
+#define ACCESS_DIR_READ		1
+#define ACCESS_DIR_WRITE	2
+
+#define RP_INDIRECT_READ	0x02 /* MSG_ID for indirect read via SCU */
+#define RP_INDIRECT_WRITE	0x05 /* MSG_ID for indirect write via SCU */
+
+#define SHOW_NUM_PER_LINE	(32 / access_width)
+#define LINE_WIDTH		(access_width * SHOW_NUM_PER_LINE)
+#define IS_WHITESPACE(c)	((c) == ' ' || (c) == '\t' || (c) == '\n')
+#define ADDR_RANGE(start, size, addr) \
+	((addr >= start) && (addr < (start + size)))
+
+/* mmio <--> device map */
+struct mmio_pci_map {
+	u32 start;
+	size_t size;
+	u32 pci_bus:8;
+	u32 pci_dev:8;
+	u32 pci_func:8;
+	char name[24];
+};
+
+static struct dentry *dump_cmd_dentry, *dump_output_dentry;
+static int dump_cmd_was_set;
+static char dump_cmd_buf[MAX_CMDLEN], err_buf[MAX_ERRLEN + 1];
+
+static int access_dir, access_width, access_bus, access_len;
+static u32 access_value;
+static u64 access_value_64;
+
+/* I/O memory */
+static u32 mmio_addr;
+
+/* I/O port */
+static unsigned port_addr;
+
+/* msg_bus */
+static u8 msg_bus_port;
+static u32 msg_bus_addr;
+
+/* pci */
+static u8 pci_bus, pci_dev, pci_func;
+static u16 pci_reg;
+
+/* msr */
+static int msr_cpu;
+static u32 msr_reg;
+
+/* i2c */
+static u8 i2c_bus;
+static u32 i2c_addr;
+
+/* scu */
+static u32 scu_addr;
+
+static const struct mmio_pci_map soc_pnw_map[] = {
+	{ 0xff128000, 0x400, 0, 0, 1, "SPI0" },
+	{ 0xff128400, 0x400, 0, 0, 2, "SPI1" },
+	{ 0xff128800, 0x400, 0, 2, 4, "SPI2" },
+
+	{ 0xff12a000, 0x400, 0, 0, 3, "I2C0" },
+	{ 0xff12a400, 0x400, 0, 0, 4, "I2C1" },
+	{ 0xff12a800, 0x400, 0, 0, 5, "I2C2" },
+	{ 0xff12ac00, 0x400, 0, 3, 2, "I2C3" },
+	{ 0xff12b000, 0x400, 0, 3, 3, "I2C4" },
+	{ 0xff12b400, 0x400, 0, 3, 4, "I2C5" },
+
+	{ 0xffae5800, 0x400, 0, 2, 7, "SSP0" },
+	{ 0xffae6000, 0x400, 0, 1, 4, "SSP1" },
+	{ 0xffae6400, 0x400, 0, 1, 3, "SSP2" },
+	{ 0xffaf0000, 0x800, 0, 2, 6, "LPE DMA1" },
+
+	{ 0xff0d0000, 0x10000, 0, 1, 5, "SEP SECURITY" },
+	{ 0xff11c000, 0x400, 0, 1, 7, "SCU IPC1" },
+
+	{ 0xdff00000, 0x100000, 0, 2, 0, "GVD BAR0" },
+	{ 0x40000000, 0x10000000, 0, 2, 0, "GVD BAR2" },
+	{ 0xdfec0000, 0x40000, 0, 2, 0, "GVD BAR3" },
+
+	{ 0xff11d000, 0x1000, 0, 2, 2, "PMU" },
+	{ 0xffa60000, 0x20000, 0, 2, 3, "USB OTG" },
+
+	{ 0xdf800000, 0x400000, 0, 3, 0, "ISP" },
+
+	{ 0xff12c000, 0x800, 0, 2, 1, "GPIO0" },
+	{ 0xff12c800, 0x800, 0, 3, 5, "GPIO1" },
+	{ 0xff12b800, 0x800, 0, 2, 5, "GP DMA" },
+
+	{ 0xffa58000, 0x100, 0, 4, 0, "SDIO0(HC2)" },
+	{ 0xffa5c000, 0x100, 0, 4, 1, "SDIO1(HC1a)" },
+	{ 0xffa2a000, 0x100, 0, 4, 2, "SDIO3(HC1b)" },
+	{ 0xffa50000, 0x100, 0, 1, 0, "SDIO3/eMMC0(HC0a)" },
+	{ 0xffa54000, 0x100, 0, 1, 1, "SDIO4/eMMC1(HC0b)" },
+
+	{ 0xffa28080, 0x80, 0, 5, 0, "UART0" },
+	{ 0xffa28100, 0x80, 0, 5, 1, "UART1" },
+	{ 0xffa28180, 0x80, 0, 5, 2, "UART2" },
+	{ 0xffa28400, 0x400, 0, 5, 3, "UART DMA" },
+
+	{ 0xffa2e000, 0x400, 0, 6, 0, "PTI" },
+
+	/* no address assigned:	{ 0x0, 0, 0, 6, 1, "xx" }, */
+
+	{ 0xffa29000, 0x800, 0, 6, 3, "HSI" },
+	{ 0xffa29800, 0x800, 0, 6, 4, "HSI DMA" },
+};
+
+static const struct mmio_pci_map soc_clv_map[] = {
+	{ 0xff138000, 0x400, 0, 0, 3, "I2C0" },
+	{ 0xff139000, 0x400, 0, 0, 4, "I2C1" },
+	{ 0xff13a000, 0x400, 0, 0, 5, "I2C2" },
+	{ 0xff13b000, 0x400, 0, 3, 2, "I2C3" },
+	{ 0xff13c000, 0x400, 0, 3, 3, "I2C4" },
+	{ 0xff13d000, 0x400, 0, 3, 4, "I2C5" },
+
+	{ 0xff128000, 0x400, 0, 0, 1, "SPI0/MSIC" },
+	{ 0xff135000, 0x400, 0, 0, 2, "SPI1" },
+	{ 0xff136000, 0x400, 0, 2, 4, "SPI2" },
+	/* invisible to IA: { 0xff137000, 0, -1, -1, -1, "SPI3" }, */
+
+	{ 0xffa58000, 0x100, 0, 4, 0, "SDIO0 (HC2)" },
+	{ 0xffa48000, 0x100, 0, 4, 1, "SDIO1 (HC1a)" },
+	{ 0xffa4c000, 0x100, 0, 4, 2, "SDIO2 (HC1b)" },
+	{ 0xffa50000, 0x100, 0, 1, 0, "SDIO3/eMMC0 (HC0a)" },
+	{ 0xffa54000, 0x100, 0, 1, 1, "SDIO4/eMMC1 (HC0b)" },
+
+	{ 0xff119000, 0x800, 0, 2, 1, "GPIO0" },
+	{ 0xff13f000, 0x800, 0, 3, 5, "GPIO1" },
+	{ 0xff13e000, 0x800, 0, 2, 5, "GP DMA" },
+
+	{ 0xffa20000, 0x400, 0, 2, 7, "SSP0" },
+	{ 0xffa21000, 0x400, 0, 1, 4, "SSP1" },
+	{ 0xffa22000, 0x400, 0, 1, 3, "SSP2" },
+	/* invisible to IA: { 0xffa23000, 0, -1, -1, -1, "SSP3" }, */
+
+	/* invisible to IA: { 0xffaf8000, 0, -1, -1, -1, "LPE DMA0" }, */
+	{ 0xffaf0000, 0x800, 0, 2, 6, "LPE DMA1" },
+	{ 0xffae8000, 0x1000, 0, 1, 3, "LPE SHIM" },
+	/* { 0xffae9000, 0, 0, 6, 5, "VIBRA" }, LPE SHIM BASE + 0x1000 */
+
+	{ 0xffa28080, 0x80, 0, 5, 0, "UART0" },
+	{ 0xffa28100, 0x80, 0, 5, 1, "UART1" },
+	{ 0xffa28180, 0x80, 0, 5, 2, "UART2" },
+	{ 0xffa28400, 0x400, 0, 5, 3, "UART DMA" },
+
+	{ 0xffa29000, 0x800, 0, 6, 3, "HSI" },
+	{ 0xffa2a000, 0x800, 0, 6, 4, "HSI DMA" },
+
+	{ 0xffa60000, 0x20000, 0, 2, 3, "USB OTG" },
+	{ 0xffa80000, 0x60000, 0, 6, 5, "USB SPH" },
+
+	{ 0xff0d0000, 0x10000, 0, 1, 5, "SEP SECURITY" },
+
+	{ 0xdff00000, 0x100000, 0, 2, 0, "GVD BAR0" },
+	{ 0x40000000, 0x10000000, 0, 2, 0, "GVD BAR2" },
+	{ 0xdfec0000, 0x40000, 0, 2, 0, "GVD BAR3" },
+	/* No address assigned: { 0x0, 0, 0, 6, 1, "HDMI HOTPLUG" }, */
+
+	{ 0xdf800000, 0x400000, 0, 3, 0, "ISP" },
+
+	{ 0xffa2e000, 0x400, 0, 6, 0, "PTI" },
+	{ 0xff11c000, 0x400, 0, 1, 7, "SCU IPC1" },
+	{ 0xff11d000, 0x1000, 0, 2, 2, "PMU" },
+};
+
+static const struct mmio_pci_map soc_tng_map[] = {
+	/* I2C0 is reserved for SCU<-->PMIC communication */
+	{ 0xff18b000, 0x400, 0, 8, 0, "I2C1" },
+	{ 0xff18c000, 0x400, 0, 8, 1, "I2C2" },
+	{ 0xff18d000, 0x400, 0, 8, 2, "I2C3" },
+	{ 0xff18e000, 0x400, 0, 8, 3, "I2C4" },
+	{ 0xff18f000, 0x400, 0, 9, 0, "I2C5" },
+	{ 0xff190000, 0x400, 0, 9, 1, "I2C6" },
+	{ 0xff191000, 0x400, 0, 9, 2, "I2C7" },
+
+	/* SDIO controllers number: 4 (compared to 5 of PNW/CLV) */
+	{ 0xff3fa000, 0x100, 0, 1, 2, "SDIO0 (HC2)" },
+	{ 0xff3fb000, 0x100, 0, 1, 3, "SDIO1 (HC1a)" },
+	{ 0xff3fc000, 0x100, 0, 1, 0, "SDIO3/eMMC0 (HC0a)" },
+	{ 0xff3fd000, 0x100, 0, 1, 1, "SDIO4/eMMC1 (HC0b)" },
+
+	/* GPIO0 and GPIO1 are merged to one GPIO controller in TNG */
+	{ 0xff008000, 0x1000, 0, 12, 0, "GPIO" },
+	{ 0xff192000, 0x1000, 0, 21, 0, "GP DMA" },
+
+	/* SSP Audio: SSP0: Modem, SSP1: Audio Codec, SSP2: Bluetooth */
+
+	/* LPE */
+	{ 0xff340000, 0x4000, 0, 13, 0, "LPE SHIM" },
+	{ 0xff344000, 0x1000, 0, 13, 0, "MAILBOX RAM" },
+	{ 0xff2c0000, 0x14000, 0, 13, 0, "ICCM" },
+	{ 0xff300000, 0x28000, 0, 13, 0, "DCCM" },
+	{ 0xff298000, 0x4000, 0, 14, 0, "LPE DMA0" },
+	/* invisible to IA: { 0xff29c000, 0x4000, -1, -1, -1, "LPE DMA1" }, */
+
+
+	/* SSP SC: SSP4: used by SCU for SPI Debug Card */
+	/* invisible to IA: { 0xff00e000, 0x1000, -1, -1, -1, "SSP SC" }, */
+
+	/* SSP General Purpose */
+	{ 0xff188000, 0x1000, 0, 7, 0, "SSP3" },
+	{ 0xff189000, 0x1000, 0, 7, 1, "SSP5" },
+	{ 0xff18a000, 0x1000, 0, 7, 2, "SSP6" },
+
+	/* UART */
+	{ 0xff010080, 0x80, 0, 4, 1, "UART0" },
+	{ 0xff011000, 0x80, 0, 4, 2, "UART1" },
+	{ 0xff011080, 0x80, 0, 4, 3, "UART2" },
+	{ 0xff011400, 0x400, 0, 5, 0, "UART DMA" },
+
+	/* HSI */
+	{ 0xff3f8000, 0x1000, 0, 10, 0, "HSI" },
+
+	/* USB */
+	{ 0xf9040000, 0x20000, 0, 15, 0, "USB2 OTG" },
+	{ 0xf9060000, 0x20000, 0, 16, 0, "USB2 MPH/HSIC" },
+	{ 0xf9100000, 0x100000, 0, 17, 0, "USB3 OTG" },
+	/* { 0xf90f0000, 0x1000, -1, -1, -1, "USB3 PHY" }, */
+	/* { 0xf90a0000, 0x10000, -1, -1, -1, "USB3 DMA FETCH" }, */
+
+	/* Security/Chaabi */
+	{ 0xf9030000, 0x1000, 0, 11, 0, "SEP SECURITY" },
+
+	/* Graphics/Display */
+	{ 0xc0000000, 0x2000000, 0, 2, 0, "GVD BAR0" },
+	{ 0x80000000, 0x10000000, 0, 2, 0, "GVD BAR2" },
+
+	/* ISP */
+	{ 0xc2000000, 0x400000, 0, 3, 0, "ISP" },
+
+	/* PTI */
+	{ 0xf9009000, 0x1000, 0, 18, 0, "PTI STM" },
+	{ 0xf90a0000, 0x10000, 0, 18, 0, "PTI USB3 DMA FETCH" },
+	{ 0xfa000000, 0x1000000, 0, 18, 0, "PTI APERTURE A" },
+
+	{ 0xff009000, 0x1000, 0, 19, 0, "SCU-IA IPC" },
+	{ 0xff00b000, 0x1000, 0, 20, 0, "PMU" },
+};
+
+static struct pci_dev *mmio_to_pci(u32 addr, char **name)
+{
+	int i, count;
+	struct mmio_pci_map *map;
+
+	if (intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_PENWELL) {
+		count = ARRAY_SIZE(soc_pnw_map);
+		map = (struct mmio_pci_map *) &soc_pnw_map[0];
+	} else if (intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_CLOVERVIEW) {
+		count = ARRAY_SIZE(soc_clv_map);
+		map = (struct mmio_pci_map *) &soc_clv_map[0];
+	} else if (intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_TANGIER) {
+		count = ARRAY_SIZE(soc_tng_map);
+		map = (struct mmio_pci_map *) &soc_tng_map[0];
+	} else {
+		return NULL;
+	}
+
+	for (i = 0; i < count; i++) {
+		if (ADDR_RANGE(map[i].start, map[i].size, addr))
+			break;
+	}
+
+	if (i >= count)
+		return NULL;
+
+	*name = &map[i].name[0];
+	return pci_get_bus_and_slot(map[i].pci_bus,
+		PCI_DEVFN(map[i].pci_dev, map[i].pci_func));
+}
+
+static int parse_argument(char *input, char **args)
+{
+	int count, located;
+	char *p = input;
+	int input_len = strlen(input);
+
+	count = 0;
+	located = 0;
+	while (*p != 0) {
+		if (p - input >= input_len)
+			break;
+
+		/* Locate the first character of a argument */
+		if (!IS_WHITESPACE(*p)) {
+			if (!located) {
+				located = 1;
+				args[count++] = p;
+				if (count > MAX_ARGS_NUM)
+					break;
+			}
+		} else {
+			if (located) {
+				*p = 0;
+				located = 0;
+			}
+		}
+		p++;
+	}
+
+	return count;
+}
+
+static int dump_cmd_show(struct seq_file *s, void *unused)
+{
+	seq_printf(s, dump_cmd_buf);
+	return 0;
+}
+
+static int dump_cmd_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, dump_cmd_show, NULL);
+}
+
+static int parse_mmio_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if (arg_num < 3) {
+		snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+			"usage: r[1|2|4] <mmio> <addr> [<len>]\n"
+			"       w[1|2|4] <mmio> <addr> <val>\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_32BIT;
+
+	ret = kstrtou32(arg_list[2], 0, &mmio_addr);
+	if (ret) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid mmio address %s\n",
+							 arg_list[2]);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_32BIT) &&
+		(mmio_addr % 4)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"addr %x is not 4 bytes aligned!\n",
+						mmio_addr);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_16BIT) &&
+		(mmio_addr % 2)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"addr %x is not 2 bytes aligned!\n",
+						mmio_addr);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (arg_num == 4) {
+			ret = kstrtou32(arg_list[3], 0, &access_len);
+			if (ret) {
+				snprintf(err_buf, MAX_ERRLEN,
+					"invalid mmio read length %s\n",
+							arg_list[3]);
+				goto failed;
+			}
+		} else if (arg_num > 4) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"usage: r[1|2|4] mmio <addr> "
+						"[<len>]\n");
+			goto failed;
+		}
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (arg_num != 4) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"need exact 4 arguments for "
+					"mmio write.\n");
+			goto failed;
+		}
+		ret = kstrtou32(arg_list[3], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid mmio address %s\n",
+						arg_list[3]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_port_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if (arg_num < 2) {
+		snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+			"usage: r[1|2|4] port <port>\n"
+			"       w[1|2|4] port <port> <val>\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_8BIT;
+
+	ret = kstrtou16(arg_list[2], 0, (u16 *)&port_addr);
+	if (ret) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid port address %s\n",
+							 arg_list[2]);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_32BIT) &&
+		(port_addr % ACCESS_WIDTH_32BIT)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"port %x is not 4 bytes aligned!\n", port_addr);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_16BIT) &&
+		(port_addr % ACCESS_WIDTH_16BIT)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"port %x is not 2 bytes aligned!\n", port_addr);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (arg_num != 3) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"usage: r[1|2|4] port <port>\n");
+			goto failed;
+		}
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (arg_num != 4) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"need exact 4 arguments for port write.\n");
+			goto failed;
+		}
+		ret = kstrtou32(arg_list[3], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid value %s\n", arg_list[3]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_msg_bus_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if (arg_num < 4) {
+		snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+			"usage: r msg_bus <port> <addr> [<len>]\n"
+			"       w msg_bus <port> <addr> <val>\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_32BIT;
+
+	if (access_width != ACCESS_WIDTH_32BIT) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"only 32bit read/write are supported.\n");
+		goto failed;
+	}
+
+	ret = kstrtou8(arg_list[2], 0, &msg_bus_port);
+	if (ret || msg_bus_port > 255) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid msg_bus port %s\n",
+								arg_list[2]);
+		goto failed;
+	}
+
+	ret = kstrtou32(arg_list[3], 0, &msg_bus_addr);
+	if (ret) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid msg_bus address %s\n",
+								arg_list[3]);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (arg_num == 5) {
+			ret = kstrtou32(arg_list[4], 0, &access_len);
+			if (ret) {
+				snprintf(err_buf, MAX_ERRLEN,
+					"invalid msg_bus read length %s\n",
+								arg_list[4]);
+				goto failed;
+			}
+		} else if (arg_num > 5) {
+			snprintf(err_buf, MAX_ERRLEN, "too many arguments\n"
+						"usage: r[1|2|4] msg_bus "
+						"<port> <addr> [<len>]\n");
+			goto failed;
+		}
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (arg_num != 5) {
+			snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+				"usage: w msg_bus <port> <addr> <val>]\n");
+			goto failed;
+		}
+		ret = kstrtou32(arg_list[4], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid value for msg_bus write %s\n",
+							 arg_list[4]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_pci_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if (arg_num < 6) {
+		snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+			"usage: r[1|2|4] pci <bus> <dev> <func> <reg> [<len>]\n"
+			"       w[1|2|4] pci <bus> <dev> <func> <reg> <val>\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_32BIT;
+
+	ret = kstrtou8(arg_list[2], 0, &pci_bus);
+	if (ret || pci_bus > 255) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid pci bus %s\n",
+							arg_list[2]);
+		goto failed;
+	}
+
+	ret = kstrtou8(arg_list[3], 0, &pci_dev);
+	if (ret || pci_dev > 255) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid pci device %s\n",
+							arg_list[3]);
+		goto failed;
+	}
+
+	ret = kstrtou8(arg_list[4], 0, &pci_func);
+	if (ret || pci_func > 255) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid pci function %s\n",
+							arg_list[4]);
+		goto failed;
+	}
+
+	ret = kstrtou16(arg_list[5], 0, &pci_reg);
+	if (ret || pci_reg > 4 * 1024) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid pci register %s\n",
+							arg_list[5]);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_32BIT) && (pci_reg % 4)) {
+		snprintf(err_buf, MAX_ERRLEN, "reg %x is not 4 bytes aligned!\n"
+							 , (u32) pci_reg);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_16BIT) && (pci_reg % 2)) {
+		snprintf(err_buf, MAX_ERRLEN, "reg %x is not 2 bytes aligned\n",
+								pci_reg);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (arg_num == 7) {
+			ret = kstrtou32(arg_list[6], 0, &access_len);
+			if (ret || access_len > 4 * 1024) {
+				snprintf(err_buf, MAX_ERRLEN,
+					"invalid pci read length %s\n",
+							arg_list[6]);
+				return ret;
+			}
+		} else if (arg_num > 7) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"max 7 args are allowed for pci read\n"
+				"usage: r[1|2|4] pci <bus> <dev> <func> "
+							"<reg> [<len>]\n");
+			goto failed;
+		}
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (arg_num != 7) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"need exact 7 args for pci write.\n");
+			goto failed;
+		}
+		ret = kstrtou32(arg_list[6], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid value for pci write %s\n",
+							 arg_list[6]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_msr_args(char **arg_list, int arg_num)
+{
+	int ret, arg_reg, arg_val;
+
+	if (((access_dir == ACCESS_DIR_READ) && (arg_num < 3)) ||
+		((access_dir == ACCESS_DIR_WRITE) && (arg_num < 4))) {
+		snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+			"usage: r[4|8] msr [<cpu> | all] <reg>]\n"
+			"       w[4|8] msr [<cpu> | all] <reg> <val>]\n");
+		goto failed;
+	}
+
+	if (((access_dir == ACCESS_DIR_READ) && (arg_num > 4)) ||
+		((access_dir == ACCESS_DIR_WRITE) && (arg_num > 5))) {
+		snprintf(err_buf, MAX_ERRLEN, "too many arguments\n"
+			"usage: r[4|8] msr [<cpu> | all] <reg>]\n"
+			"       w[4|8] msr [<cpu> | all] <reg> <val>]\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_64BIT;
+
+	if (!strncmp(arg_list[2], "all", 3)) {
+		msr_cpu = -1;
+		arg_reg = 3;
+		arg_val = 4;
+	} else if ((access_dir == ACCESS_DIR_READ && arg_num == 4) ||
+		(access_dir == ACCESS_DIR_WRITE && arg_num == 5)) {
+		ret = kstrtou32(arg_list[2], 0, &msr_cpu);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN, "invalid cpu: %s\n",
+							arg_list[2]);
+			goto failed;
+		}
+		arg_reg = 3;
+		arg_val = 4;
+	} else {
+		/* Default cpu for msr read is all, for msr write is 0 */
+		if (access_dir == ACCESS_DIR_READ)
+			msr_cpu = -1;
+		else
+			msr_cpu = 0;
+		arg_reg = 2;
+		arg_val = 3;
+	}
+
+
+	ret = kstrtou32(arg_list[arg_reg], 0, &msr_reg);
+	if (ret) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid msr reg: %s\n",
+							arg_list[2]);
+		goto failed;
+	}
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (access_width == ACCESS_WIDTH_32BIT)
+			ret = kstrtou32(arg_list[arg_val], 0, &access_value);
+		else
+			ret = kstrtou64(arg_list[arg_val], 0, &access_value_64);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN, "invalid value: %s\n",
+							arg_list[arg_val]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_i2c_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if ((access_dir == ACCESS_DIR_READ && arg_num != 4) ||
+		(access_dir == ACCESS_DIR_WRITE && arg_num != 5)) {
+		snprintf(err_buf, MAX_ERRLEN, "usage: r i2c <bus> <addr>\n"
+			"       w i2c <bus> <addr> <val>\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_8BIT;
+
+	if (access_width != ACCESS_WIDTH_8BIT) {
+		snprintf(err_buf, MAX_ERRLEN, "only 8bit access is allowed\n");
+		goto failed;
+	}
+
+	ret = kstrtou8(arg_list[2], 0, &i2c_bus);
+	if (ret || i2c_bus > 9) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid i2c bus %s\n",
+							arg_list[2]);
+		goto failed;
+	}
+
+	ret = kstrtou32(arg_list[3], 0, &i2c_addr);
+
+	pr_err("ret = %d, i2c_addr is 0x%x\n", ret, i2c_addr);
+	if (ret || (i2c_addr > 1024)) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid i2c address %s\n",
+							arg_list[3]);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		ret = kstrtou32(arg_list[4], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid value for i2c write %s\n",
+							 arg_list[4]);
+			goto failed;
+		}
+	}
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_scu_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if (access_width != ACCESS_WIDTH_32BIT)
+		access_width = ACCESS_WIDTH_32BIT;
+
+	ret = kstrtou32(arg_list[2], 0, &scu_addr);
+	if (ret) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid scu address %s\n",
+							arg_list[2]);
+		goto failed;
+	}
+
+	if (scu_addr % 4) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"addr %x is not 4 bytes aligned!\n",
+						scu_addr);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (arg_num != 3) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"usage: r[4] scu <addr>\n");
+			goto failed;
+		}
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (arg_num != 4) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"usage: w[4] scu <addr> <val>\n");
+			goto failed;
+		}
+		ret = kstrtou32(arg_list[3], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid scu write value %s\n",
+						arg_list[3]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static ssize_t dump_cmd_write(struct file *file, const char __user *buf,
+				size_t len, loff_t *offset)
+{
+	char cmd[MAX_CMDLEN];
+	char *arg_list[MAX_ARGS_NUM];
+	int arg_num, ret = -EINVAL;
+
+	err_buf[0] = 0;
+
+	if (len >= MAX_CMDLEN) {
+		snprintf(err_buf, MAX_ERRLEN, "input command is too long.\n"
+					"max allowed input length is %d\n",
+							MAX_CMDLEN);
+		goto done;
+	}
+
+	if (copy_from_user(cmd, buf, len)) {
+		snprintf(err_buf, MAX_ERRLEN, "copy_from_user() failed.\n");
+		goto done;
+	}
+	cmd[len] = 0;
+
+	dump_cmd_buf[0] = 0;
+	strncpy(dump_cmd_buf, cmd, len);
+	dump_cmd_buf[len] = 0;
+
+	arg_num = parse_argument(cmd, arg_list);
+	if (arg_num < MIN_ARGS_NUM) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"invalid command(too few arguments): "
+					"%s\n", dump_cmd_buf);
+		goto done;
+	}
+	if (arg_num > MAX_ARGS_NUM) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"invalid command(too many arguments): "
+					"%s\n", dump_cmd_buf);
+		goto done;
+	}
+
+	/* arg 1: direction(read/write) and mode (8/16/32/64 bit) */
+	if (!strncmp(arg_list[0], "r8", 2)) {
+		access_dir = ACCESS_DIR_READ;
+		access_width = ACCESS_WIDTH_64BIT;
+	} else if (!strncmp(arg_list[0], "r4", 2)) {
+		access_dir = ACCESS_DIR_READ;
+		access_width = ACCESS_WIDTH_32BIT;
+	} else if (!strncmp(arg_list[0], "r2", 2)) {
+		access_dir = ACCESS_DIR_READ;
+		access_width = ACCESS_WIDTH_16BIT;
+	} else if (!strncmp(arg_list[0], "r1", 2)) {
+		access_dir = ACCESS_DIR_READ;
+		access_width = ACCESS_WIDTH_8BIT;
+	} else if (!strncmp(arg_list[0], "r", 1)) {
+		access_dir = ACCESS_DIR_READ;
+		access_width = ACCESS_WIDTH_DEFAULT;
+	} else if (!strncmp(arg_list[0], "w8", 2)) {
+		access_dir = ACCESS_DIR_WRITE;
+		access_width = ACCESS_WIDTH_64BIT;
+	} else if (!strncmp(arg_list[0], "w4", 2)) {
+		access_dir = ACCESS_DIR_WRITE;
+		access_width = ACCESS_WIDTH_32BIT;
+	} else if (!strncmp(arg_list[0], "w2", 2)) {
+		access_dir = ACCESS_DIR_WRITE;
+		access_width = ACCESS_WIDTH_16BIT;
+	} else if (!strncmp(arg_list[0], "w1", 2)) {
+		access_dir = ACCESS_DIR_WRITE;
+		access_width = ACCESS_WIDTH_8BIT;
+	} else if (!strncmp(arg_list[0], "w", 1)) {
+		access_dir = ACCESS_DIR_WRITE;
+		access_width = ACCESS_WIDTH_DEFAULT;
+	} else {
+		snprintf(err_buf, MAX_ERRLEN, "unknown argument: %s\n",
+							arg_list[0]);
+		goto done;
+	}
+
+	/* arg2: bus type(mmio, msg_bus, pci or i2c) */
+	access_len = 1;
+	if (!strncmp(arg_list[1], "mmio", 4)) {
+		access_bus = ACCESS_BUS_MMIO;
+		ret = parse_mmio_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "port", 4)) {
+		access_bus = ACCESS_BUS_PORT;
+		ret = parse_port_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "msg_bus", 7)) {
+		access_bus = ACCESS_BUS_MSG_BUS;
+		ret = parse_msg_bus_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "pci", 3)) {
+		access_bus = ACCESS_BUS_PCI;
+		ret = parse_pci_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "msr", 3)) {
+		access_bus = ACCESS_BUS_MSR;
+		ret = parse_msr_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "i2c", 3)) {
+		access_bus = ACCESS_BUS_I2C;
+		ret = parse_i2c_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "scu", 3)) {
+		access_bus = ACCESS_BUS_SCU_INDRW;
+		ret = parse_scu_args(arg_list, arg_num);
+	} else {
+		snprintf(err_buf, MAX_ERRLEN, "unknown argument: %s\n",
+							arg_list[1]);
+	}
+
+	if (access_len == 0) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"access length must be larger than 0\n");
+		ret = -EINVAL;
+		goto done;
+	}
+
+	if ((access_bus == ACCESS_BUS_MMIO || access_bus == ACCESS_BUS_PCI) &&
+					 (access_len > MAX_MMIO_PCI_LEN)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"%d exceeds max mmio/pci read length(%d)\n",
+					access_len, MAX_MMIO_PCI_LEN);
+		ret = -EINVAL;
+		goto done;
+	}
+
+	if ((access_bus == ACCESS_BUS_MSG_BUS) &&
+		(access_len > MAX_MSG_BUS_LEN)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"%d exceeds max msg_bus read length(%d)\n",
+					access_len, MAX_MSG_BUS_LEN);
+		ret = -EINVAL;
+	}
+
+	if (access_bus == ACCESS_BUS_MSR) {
+		if ((access_width != ACCESS_WIDTH_32BIT) &&
+			(access_width != ACCESS_WIDTH_64BIT) &&
+			(access_width != ACCESS_WIDTH_DEFAULT)) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"only 32bit or 64bit is allowed for msr\n");
+			ret = -EINVAL;
+		}
+	}
+
+done:
+	dump_cmd_was_set = ret ? 0 : 1;
+	return ret ? ret : len;
+}
+
+static int dump_output_show_mmio(struct seq_file *s)
+{
+	void __iomem *base;
+	int i, comp1, comp2;
+	u32 start, end, end_natural;
+	struct pci_dev *pdev;
+	char *name;
+
+	pdev = mmio_to_pci(mmio_addr, &name);
+	if (pdev && pm_runtime_get_sync(&pdev->dev) < 0) {
+		seq_printf(s, "can't put device %s into D0i0 state\n", name);
+		return 0;
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		base = ioremap_nocache(mmio_addr, access_width);
+		if (!base) {
+			seq_printf(s, "can't map physical address: %x\n",
+				mmio_addr);
+			if (pdev)
+				pm_runtime_put_sync(&pdev->dev);
+			return 0;
+		}
+		switch (access_width) {
+		case ACCESS_WIDTH_8BIT:
+			iowrite8((u8) access_value, base);
+			break;
+		case ACCESS_WIDTH_16BIT:
+			iowrite16((u16) access_value, base);
+			break;
+		case ACCESS_WIDTH_32BIT:
+		case ACCESS_WIDTH_DEFAULT:
+			iowrite32(access_value, base);
+			break;
+		default:
+			break; /* never happen */
+		}
+		seq_printf(s, "write succeeded\n");
+	} else {
+		start = (mmio_addr / LINE_WIDTH) * LINE_WIDTH;
+		end_natural = mmio_addr + (access_len - 1) * access_width;
+		end = (end_natural / LINE_WIDTH + 1) * LINE_WIDTH -
+						access_width;
+		comp1 = (mmio_addr - start) / access_width;
+		comp2 = (end - end_natural) / access_width;
+
+		base = ioremap_nocache(start, (comp1 + comp2 +
+			access_len) * access_width);
+		if (!base) {
+			seq_printf(s, "can't map physical address: %x\n",
+				mmio_addr);
+			if (pdev)
+				pm_runtime_put_sync(&pdev->dev);
+			return 0;
+		}
+
+		for (i = 0; i < comp1 + comp2 + access_len; i++) {
+			if ((i % SHOW_NUM_PER_LINE) == 0)
+					seq_printf(s, "[%08x]", start + i * 4);
+
+			if (i < comp1 || i >= access_len + comp1) {
+				switch (access_width) {
+				case ACCESS_WIDTH_32BIT:
+					seq_printf(s, "         ");
+					break;
+				case ACCESS_WIDTH_16BIT:
+					seq_printf(s, "     ");
+					break;
+				case ACCESS_WIDTH_8BIT:
+					seq_printf(s, "   ");
+					break;
+				}
+
+			} else {
+				switch (access_width) {
+				case ACCESS_WIDTH_32BIT:
+					seq_printf(s, " %08x",
+						ioread32(base + i * 4));
+					break;
+				case ACCESS_WIDTH_16BIT:
+					seq_printf(s, " %04x",
+						(u16) ioread16(base + i * 2));
+					break;
+				case ACCESS_WIDTH_8BIT:
+					seq_printf(s, " %02x",
+						(u8) ioread8(base + i));
+					break;
+				}
+			}
+
+			if ((i + 1) % SHOW_NUM_PER_LINE == 0)
+				seq_printf(s, "\n");
+		}
+	}
+
+	iounmap(base);
+	if (pdev)
+		pm_runtime_put_sync(&pdev->dev);
+	return 0;
+}
+
+static int dump_output_show_port(struct seq_file *s)
+{
+	if (access_dir == ACCESS_DIR_WRITE) {
+		switch (access_width) {
+		case ACCESS_WIDTH_8BIT:
+		case ACCESS_WIDTH_DEFAULT:
+			outb((u8) access_value, port_addr);
+			break;
+		case ACCESS_WIDTH_16BIT:
+			outw((u16) access_value, port_addr);
+			break;
+		case ACCESS_WIDTH_32BIT:
+			outl(access_value, port_addr);
+			break;
+		default:
+			break; /* never happen */
+		}
+		seq_printf(s, "write succeeded\n");
+	} else {
+		switch (access_width) {
+		case ACCESS_WIDTH_32BIT:
+			seq_printf(s, " %08x\n", inl(port_addr));
+			break;
+		case ACCESS_WIDTH_16BIT:
+			seq_printf(s, " %04x\n", (u16) inw(port_addr));
+			break;
+		case ACCESS_WIDTH_8BIT:
+			seq_printf(s, " %02x\n", (u8) inb(port_addr));
+			break;
+		default:
+			break;
+		}
+	}
+
+	return 0;
+}
+
+static int dump_output_show_msg_bus(struct seq_file *s)
+{
+	int i, comp1, comp2;
+	u32 start, end, end_natural;
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		intel_mid_msgbus_write32(msg_bus_port,
+			msg_bus_addr, access_value);
+		seq_printf(s, "write succeeded\n");
+	} else {
+		start = (msg_bus_addr / LINE_WIDTH) * LINE_WIDTH;
+		end_natural = msg_bus_addr + (access_len - 1) * access_width;
+		end = (end_natural / LINE_WIDTH + 1) * LINE_WIDTH -
+						access_width;
+		comp1 = (msg_bus_addr - start) / access_width;
+		comp2 = (end - end_natural) / access_width;
+
+	for (i = 0; i < comp1 + comp2 + access_len; i++) {
+			if ((i % SHOW_NUM_PER_LINE) == 0)
+					seq_printf(s, "[%08x]", start + i * 4);
+
+			if (i < comp1 || i >= access_len + comp1)
+				seq_printf(s, "         ");
+
+			else
+				seq_printf(s, " %08x", intel_mid_msgbus_read32(
+					msg_bus_port, msg_bus_addr + i));
+
+			if ((i + 1) % SHOW_NUM_PER_LINE == 0)
+				seq_printf(s, "\n");
+		}
+	}
+
+	return 0;
+}
+
+static int dump_output_show_pci(struct seq_file *s)
+{
+	int i, comp1, comp2;
+	u32 start, end, end_natural, val;
+	struct pci_dev *pdev;
+
+	pdev = pci_get_bus_and_slot(pci_bus, PCI_DEVFN(pci_dev, pci_func));
+	if (!pdev) {
+		seq_printf(s, "pci bus %d:%d:%d doesn't exist\n",
+			pci_bus, pci_dev, pci_func);
+		return 0;
+	}
+
+	if (pm_runtime_get_sync(&pdev->dev) < 0) {
+		seq_printf(s, "can't put pci device %d:%d:%d into D0i0 state\n",
+			pci_bus, pci_dev, pci_func);
+		return 0;
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		switch (access_width) {
+		case ACCESS_WIDTH_8BIT:
+			pci_write_config_byte(pdev, (int)pci_reg,
+					(u8)access_value);
+			break;
+		case ACCESS_WIDTH_16BIT:
+			pci_write_config_word(pdev, (int)pci_reg,
+				(u16)access_value);
+			break;
+		case ACCESS_WIDTH_32BIT:
+		case ACCESS_WIDTH_DEFAULT:
+			pci_write_config_dword(pdev, (int)pci_reg,
+				access_value);
+			break;
+		default:
+			break; /* never happen */
+		}
+		seq_printf(s, "write succeeded\n");
+	} else {
+		start = (pci_reg / LINE_WIDTH) * LINE_WIDTH;
+		end_natural = pci_reg + (access_len - 1) * access_width;
+		end = (end_natural / LINE_WIDTH + 1) * LINE_WIDTH -
+						access_width;
+		comp1 = (pci_reg - start) / access_width;
+		comp2 = (end - end_natural) / access_width;
+
+		for (i = 0; i < comp1 + comp2 + access_len; i++) {
+			if ((i % SHOW_NUM_PER_LINE) == 0)
+					seq_printf(s, "[%08x]", start + i * 4);
+
+			if (i < comp1 || i >= access_len + comp1) {
+				switch (access_width) {
+				case ACCESS_WIDTH_32BIT:
+					seq_printf(s, "         ");
+					break;
+				case ACCESS_WIDTH_16BIT:
+					seq_printf(s, "     ");
+					break;
+				case ACCESS_WIDTH_8BIT:
+					seq_printf(s, "   ");
+					break;
+				}
+
+			} else {
+				switch (access_width) {
+				case ACCESS_WIDTH_32BIT:
+					pci_read_config_dword(pdev,
+						start + i * 4, &val);
+					seq_printf(s, " %08x", val);
+					break;
+				case ACCESS_WIDTH_16BIT:
+					pci_read_config_word(pdev,
+						start + i * 2, (u16 *) &val);
+					seq_printf(s, " %04x", (u16)val);
+					break;
+				case ACCESS_WIDTH_8BIT:
+					pci_read_config_byte(pdev,
+						start + i, (u8 *) &val);
+					seq_printf(s, " %04x", (u8)val);
+					break;
+				}
+			}
+
+			if ((i + 1) % SHOW_NUM_PER_LINE == 0)
+				seq_printf(s, "\n");
+		}
+	}
+
+	return 0;
+}
+
+static int dump_output_show_msr(struct seq_file *s)
+{
+	int ret, i, count;
+	u32 data[2];
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (msr_cpu < 0) {
+			/* loop for all cpus */
+			i = 0;
+			count = nr_cpu_ids;
+		} else if (msr_cpu >= nr_cpu_ids || msr_cpu < 0) {
+			seq_printf(s, "cpu should be between 0 - %d\n",
+							nr_cpu_ids - 1);
+			return 0;
+		} else {
+			/* loop for one cpu */
+			i = msr_cpu;
+			count = msr_cpu + 1;
+		}
+		for (; i < count; i++) {
+			ret = rdmsr_safe_on_cpu(i, msr_reg, &data[0], &data[1]);
+			if (ret) {
+				seq_printf(s, "msr read error: %d\n", ret);
+				return 0;
+			} else {
+				if (access_width == ACCESS_WIDTH_32BIT)
+					seq_printf(s, "[cpu %1d] %08x\n",
+							i, data[0]);
+				else
+					seq_printf(s, "[cpu %1d] %08x%08x\n",
+						 i, data[1], data[0]);
+			}
+		}
+	} else {
+		if (access_width == ACCESS_WIDTH_32BIT) {
+			ret = rdmsr_safe_on_cpu(msr_cpu, msr_reg,
+					&data[0], &data[1]);
+			if (ret) {
+				seq_printf(s, "msr write error: %d\n", ret);
+				return 0;
+			}
+			data[0] = access_value;
+		} else {
+			data[0] = (u32)access_value_64;
+			data[1] = (u32)(access_value_64 >> 32);
+		}
+		if (msr_cpu < 0) {
+			/* loop for all cpus */
+			i = 0;
+			count = nr_cpu_ids;
+		} else {
+			if (msr_cpu >= nr_cpu_ids || msr_cpu < 0) {
+				seq_printf(s, "cpu should be between 0 - %d\n",
+						nr_cpu_ids - 1);
+				return 0;
+			}
+			/* loop for one cpu */
+			i = msr_cpu;
+			count = msr_cpu + 1;
+		}
+		for (; i < count; i++) {
+			ret = wrmsr_safe_on_cpu(i, msr_reg, data[0], data[1]);
+			if (ret) {
+				seq_printf(s, "msr write error: %d\n", ret);
+				return 0;
+			} else {
+				seq_printf(s, "write succeeded.\n");
+			}
+		}
+	}
+
+	return 0;
+}
+
+static int dump_output_show_i2c(struct seq_file *s)
+{
+	int ret;
+	struct i2c_adapter *adap;
+	struct i2c_msg msg;
+	u8 val;
+
+	adap = i2c_get_adapter(i2c_bus);
+	if (!adap) {
+		seq_printf(s, "can't find bus adapter for i2c bus %d\n",
+							i2c_bus);
+		return 0;
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		msg.addr = i2c_addr;
+		msg.len = 1;
+		msg.buf = (u8 *) &access_value;
+		ret = i2c_transfer(adap, &msg, 1);
+		if (ret != 1)
+			seq_printf(s, "i2c write error: %d\n", ret);
+		else
+			seq_printf(s, "write succeeded.\n");
+	} else {
+		msg.flags |= I2C_M_RD;
+		msg.addr = i2c_addr;
+		msg.len = 1;
+		msg.buf = &val;
+		ret = i2c_transfer(adap, &msg, 1);
+		if (ret != 1)
+			seq_printf(s, "i2c read error: %d\n", ret);
+		else
+			seq_printf(s, "%02x\n", val);
+	}
+
+	return 0;
+}
+
+static int dump_output_show_scu(struct seq_file *s)
+{
+	struct pci_dev *pdev;
+	char *name;
+	int ret;
+	u32 cmd, sub = 0, dptr = 0, sptr = 0;
+	u8 wbuflen = 4, rbuflen = 4;
+	u8 wbuf[16];
+	u8 rbuf[16];
+
+	memset(wbuf, 0, 16);
+	memset(rbuf, 0, 16);
+
+	pdev = mmio_to_pci(scu_addr, &name);
+	if (pdev && pm_runtime_get_sync(&pdev->dev) < 0) {
+		seq_printf(s, "can't put device %s into D0i0 state\n", name);
+		return 0;
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		cmd = RP_INDIRECT_WRITE;
+		dptr = scu_addr;
+		wbuf[0] = (u8) (access_value & 0xff);
+		wbuf[1] = (u8) ((access_value >> 8) & 0xff);
+		wbuf[2] = (u8) ((access_value >> 16) & 0xff);
+		wbuf[3] = (u8) ((access_value >> 24) & 0xff);
+
+		ret = rpmsg_send_generic_raw_command(cmd, sub, wbuf, wbuflen,
+			(u32 *)rbuf, rbuflen, dptr, sptr);
+
+		if (ret) {
+			seq_printf(s,
+				"Indirect write failed (check dmesg): "
+						"[%08x]\n", scu_addr);
+		} else {
+			seq_printf(s, "write succeeded\n");
+		}
+	} else if (access_dir == ACCESS_DIR_READ) {
+		cmd = RP_INDIRECT_READ;
+		sptr = scu_addr;
+
+		ret = rpmsg_send_generic_raw_command(cmd, sub, wbuf, wbuflen,
+			(u32 *)rbuf, rbuflen, dptr, sptr);
+
+		if (ret) {
+			seq_printf(s,
+				"Indirect read failed (check dmesg): "
+						"[%08x]\n", scu_addr);
+		} else {
+			access_value = (rbuf[3] << 24) | (rbuf[2] << 16) |
+				(rbuf[1] << 8) | (rbuf[0]);
+			seq_printf(s, "[%08x] %08x\n", scu_addr, access_value);
+		}
+	}
+
+	if (pdev)
+		pm_runtime_put_sync(&pdev->dev);
+
+	return 0;
+}
+
+static int dump_output_show(struct seq_file *s, void *unused)
+{
+	int ret = 0;
+
+	if (!dump_cmd_was_set) {
+		seq_printf(s, "%s", err_buf);
+		return 0;
+	}
+
+	switch (access_bus) {
+	case ACCESS_BUS_MMIO:
+		ret = dump_output_show_mmio(s);
+		break;
+	case ACCESS_BUS_PORT:
+		ret = dump_output_show_port(s);
+		break;
+	case ACCESS_BUS_MSG_BUS:
+		ret = dump_output_show_msg_bus(s);
+		break;
+	case ACCESS_BUS_PCI:
+		ret = dump_output_show_pci(s);
+		break;
+	case ACCESS_BUS_MSR:
+		ret = dump_output_show_msr(s);
+		break;
+	case ACCESS_BUS_I2C:
+		ret = dump_output_show_i2c(s);
+		break;
+	case ACCESS_BUS_SCU_INDRW:
+		ret = dump_output_show_scu(s);
+		break;
+	default:
+		seq_printf(s, "unknow bus type: %d\n", access_bus);
+		break;
+
+	}
+
+	return ret;
+}
+
+static const struct file_operations dump_cmd_fops = {
+	.owner		= THIS_MODULE,
+	.open		= dump_cmd_open,
+	.read		= seq_read,
+	.write		= dump_cmd_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int dump_output_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, dump_output_show, NULL);
+}
+
+static const struct file_operations dump_output_fops = {
+	.owner		= THIS_MODULE,
+	.open		= dump_output_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int __init intel_mid_dump_init(void)
+{
+	dump_cmd_dentry = debugfs_create_file("dump_cmd",
+		S_IFREG | S_IRUGO | S_IWUSR, NULL, NULL, &dump_cmd_fops);
+	dump_output_dentry = debugfs_create_file("dump_output",
+		S_IFREG | S_IRUGO, NULL, NULL, &dump_output_fops);
+	if (!dump_cmd_dentry || !dump_output_dentry) {
+		pr_err("intel_mid_dump: can't create debugfs node\n");
+		return -EFAULT;
+	}
+	return 0;
+}
+module_init(intel_mid_dump_init);
+
+static void __exit intel_mid_dump_exit(void)
+{
+	if (dump_cmd_dentry)
+		debugfs_remove(dump_cmd_dentry);
+	if (dump_output_dentry)
+		debugfs_remove(dump_output_dentry);
+}
+module_exit(intel_mid_dump_exit);
+
+MODULE_DESCRIPTION("Intel Atom SoC register dump driver");
+MODULE_VERSION("1.0");
+MODULE_AUTHOR("Bin Gao <bin.gao@intel.com>");
+MODULE_LICENSE("GPL v2");
diff --git a/arch/x86/platform/intel-mid/intel_soc_mdfld.h b/arch/x86/platform/intel-mid/intel_soc_mdfld.h
new file mode 100644
index 0000000..85c25b5
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_mdfld.h
@@ -0,0 +1,353 @@
+/*
+ * intel_soc_mdfld.h
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#ifdef CONFIG_REMOVEME_INTEL_REMOVEME_ATOM_MDFLD_POWER
+
+#define   PM_SUPPORT				0x21
+
+#define ISP_POS			7
+#define ISP_SUB_CLASS		0x80
+#define C6_OFFLOAD_REG_ADDR	0xffd01ffc
+#define PMU_MISC_SET_TIMEOUT	50 /* 50usec timeout */
+#define PMU_C6OFFLOAD_ACCESS_TIMEOUT 1500 /* 1.5msecs timeout */
+
+#define PMU1_MAX_DEVS   8
+#define PMU2_MAX_DEVS   55
+
+#define GFX_LSS_INDEX			1
+#define PMU_SDIO0_LSS_00		0
+#define PMU_EMMC0_LSS_01		1
+#define PMU_AONT_LSS_02			2
+#define PMU_HSI_LSS_03			3
+#define PMU_SECURITY_LSS_04		4
+#define PMU_EMMC1_LSS_05		5
+#define PMU_USB_OTG_LSS_06		6
+#define PMU_USB_HSIC_LSS_07		7
+#define PMU_AUDIO_ENGINE_LSS_08		8
+#define PMU_AUDIO_DMA_LSS_09		9
+#define PMU_SRAM_LSS_10			10
+#define PMU_SRAM_LSS_11			11
+#define PMU_SRAM_LSS_12			12
+#define PMU_SRAM_LSS_13			13
+#define PMU_SDIO2_LSS_14		14
+#define PMU_PTI_DAFCA_LSS_15		15
+#define PMU_SC_DMA_LSS_16		16
+#define PMU_SPIO_LSS_17			17
+#define PMU_SPI1_LSS_18			18
+#define PMU_SPI2_LSS_19			19
+#define PMU_I2C0_LSS_20			20
+#define PMU_I2C1_LSS_21			21
+#define PMU_MAIN_FABRIC_LSS_22		22
+#define PMU_SEC_FABRIC_LSS_23		23
+#define PMU_SC_FABRIC_LSS_24		24
+#define PMU_AUDIO_RAM_LSS_25		25
+#define PMU_SCU_ROM_LSS_26		26
+#define PMU_I2C2_LSS_27			27
+#define PMU_SSC_LSS_28			28
+#define PMU_SECURITY_LSS_29		29
+#define PMU_SDIO1_LSS_30		30
+#define PMU_SCU_RAM0_LSS_31		31
+#define PMU_SCU_RAM1_LSS_32		32
+#define PMU_I2C3_LSS_33			33
+#define PMU_I2C4_LSS_34			34
+#define PMU_I2C5_LSS_35			35
+#define PMU_SPI3_LSS_36			36
+#define PMU_GPIO1_LSS_37		37
+#define PMU_PWR_BUTTON_LSS_38		38
+#define PMU_GPIO0_LSS_39		39
+#define PMU_KEYBRD_LSS_40		40
+#define PMU_UART2_LSS_41		41
+#define PMU_ADC_LSS_42			42
+#define PMU_CHARGER_LSS_43		43
+#define PMU_SEC_TAPC_LSS_44		44
+#define PMU_RTC_LSS_45			45
+#define PMU_GPI_LSS_46			46
+#define PMU_HDMI_VREG_LSS_47		47
+#define PMU_RESERVED_LSS_48		48
+#define PMU_AUDIO_SLIM1_LSS_49		49
+#define PMU_RESET_LSS_50		50
+#define PMU_AUDIO_SSP0_LSS_51		51
+#define PMU_AUDIO_SSP1_LSS_52		52
+#define PMU_IOSF_OCP_BRG_LSS_53		53
+#define PMU_GP_DMA_LSS_54		54
+#define PMU_SVID_LSS_55			55
+#define PMU_SOC_FUSE_LSS_56		56
+#define PMU_RSVD3_LSS_57		57
+#define PMU_RSVD4_LSS_58		58
+#define PMU_RSVD5_LSS_59		59
+#define PMU_RSVD6_LSS_60		60
+#define PMU_RSVD7_LSS_61		61
+#define PMU_RSVD8_LSS_62		62
+#define PMU_RSVD9_LSS_63		63
+
+#define PMU_MAX_LSS			63
+#define PMU_LSS_IN_FIRST_DWORD		32
+
+#define EMMC0_LSS			PMU_EMMC0_LSS_01
+
+#define S0IX_TARGET_SSS0_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0IX_TARGET_SSS1_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+#define S0IX_TARGET_SSS2_MASK ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_UART2_LSS_41-32))
+
+#define S0IX_TARGET_SSS3_MASK ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define S0IX_TARGET_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0IX_TARGET_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define S0IX_TARGET_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define S0IX_TARGET_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define LPMP3_TARGET_SSS0_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_TARGET_SSS1_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_TARGET_SSS2_MASK ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_TARGET_SSS3_MASK ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define LPMP3_TARGET_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I0_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_TARGET_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_TARGET_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_TARGET_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define IGNORE_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_10) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_11) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_12) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_13) | \
+	SSMSK(D0I3_MASK, PMU_PTI_DAFCA_LSS_15))
+
+#define IGNORE_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SC_DMA_LSS_16-16) | \
+	SSMSK(D0I3_MASK, PMU_SPIO_LSS_17-16) | \
+	SSMSK(D0I3_MASK, PMU_MAIN_FABRIC_LSS_22-16) | \
+	SSMSK(D0I3_MASK, PMU_SEC_FABRIC_LSS_23-16) | \
+	SSMSK(D0I3_MASK, PMU_SC_FABRIC_LSS_24-16) | \
+	SSMSK(D0I3_MASK, PMU_SCU_ROM_LSS_26-16) | \
+	SSMSK(D0I3_MASK, PMU_SSC_LSS_28-16) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_29-16) | \
+	SSMSK(D0I3_MASK, PMU_SCU_RAM0_LSS_31-16))
+
+#define IGNORE_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_SCU_RAM1_LSS_32-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO0_LSS_39-32) | \
+	SSMSK(D0I3_MASK, PMU_ADC_LSS_42-32) | \
+	SSMSK(D0I3_MASK, PMU_CHARGER_LSS_43-32) | \
+	SSMSK(D0I3_MASK, PMU_SEC_TAPC_LSS_44-32) | \
+	SSMSK(D0I3_MASK, PMU_RTC_LSS_45-32) | \
+	SSMSK(D0I3_MASK, PMU_GPI_LSS_46-32) | \
+	SSMSK(D0I3_MASK, PMU_HDMI_VREG_LSS_47-32))
+
+#define IGNORE_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_IOSF_OCP_BRG_LSS_53-48) | \
+	SSMSK(D0I3_MASK, PMU_SVID_LSS_55-48) | \
+	SSMSK(D0I3_MASK, PMU_SOC_FUSE_LSS_56-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD3_LSS_57-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD4_LSS_58-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD5_LSS_59-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD6_LSS_60-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD7_LSS_61-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD8_LSS_62-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD9_LSS_63-48))
+
+#define IGNORE_S3_WKC0 SSWKC(PMU_AONT_LSS_02)
+#define IGNORE_S3_WKC1 SSWKC(PMU_ADC_LSS_42-32)
+
+#define S0I3_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_AONT_LSS_02) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_12) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_13) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0I3_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_SPI2_LSS_19-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_RAM_LSS_25-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define S0I3_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_KEYBRD_LSS_40-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define S0I3_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM1_LSS_49-48) | \
+	SSMSK(D0I3_MASK, PMU_RESET_LSS_50-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48) | \
+	SSMSK(D0I3_MASK, PMU_GP_DMA_LSS_54-48))
+
+#define S0I1_SSS0 S0I3_SSS0
+#define S0I1_SSS1 S0I3_SSS1
+#define S0I1_SSS2 S0I3_SSS2
+#define S0I1_SSS3 S0I3_SSS3
+
+#define LPMP3_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_AONT_LSS_02) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_SPI2_LSS_19-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_KEYBRD_LSS_40-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM1_LSS_49-48) | \
+	SSMSK(D0I3_MASK, PMU_RESET_LSS_50-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48) | \
+	SSMSK(D0I3_MASK, PMU_GP_DMA_LSS_54-48))
+
+extern void pmu_set_s0ix_possible(int state);
+extern void log_wakeup_irq(void);
+extern void s0ix_complete(void);
+extern int mdfld_clv_nc_set_power_state(int, int, int, int *);
+
+
+#endif
diff --git a/arch/x86/platform/intel-mid/intel_soc_mrfld.c b/arch/x86/platform/intel-mid/intel_soc_mrfld.c
new file mode 100644
index 0000000..0683935
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_mrfld.c
@@ -0,0 +1,446 @@
+/*
+ * intel_soc_mrfld.c - This driver provides utility api's for merrifield
+ * platform
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#include "intel_soc_pmu.h"
+
+u32 __iomem *residency[SYS_STATE_MAX];
+u32 __iomem *s0ix_counter[SYS_STATE_MAX];
+
+/* list of north complex devices */
+char *mrfl_nc_devices[] = {
+	"GFXSLC",
+	"GSDKCK",
+	"GRSCD",
+	"VED",
+	"VEC",
+	"DPA",
+	"DPB",
+	"DPC",
+	"VSP",
+	"ISP",
+	"MIO",
+	"HDMIO",
+	"GFXSLCLDO"
+};
+
+int mrfl_no_of_nc_devices =
+	sizeof(mrfl_nc_devices)/sizeof(mrfl_nc_devices[0]);
+
+static int mrfld_pmu_init(void)
+{
+	mid_pmu_cxt->s3_hint = MRFLD_S3_HINT;
+
+
+	/* Put all unused LSS in D0i3 */
+	mid_pmu_cxt->os_sss[0] = (SSMSK(D0I3_MASK, PMU_RESERVED_LSS_03)	|
+				SSMSK(D0I3_MASK, PMU_HSI_LSS_05)	|
+				SSMSK(D0I3_MASK, PMU_SECURITY_LSS_06)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_07)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_11)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_12)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_13)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_14)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_15));
+
+	/* Put LSS8 as unused on Tangier */
+	mid_pmu_cxt->os_sss[0] |= \
+				SSMSK(D0I3_MASK, PMU_USB_MPH_LSS_08);
+
+	mid_pmu_cxt->os_sss[1] = (SSMSK(D0I3_MASK, PMU_RESERVED_LSS_16-16)|
+				SSMSK(D0I3_MASK, PMU_SSP3_LSS_17-16)|
+				SSMSK(D0I3_MASK, PMU_SSP6_LSS_19-16)|
+				SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_28-16)|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_29-16)|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_30-16));
+
+	/* Excpet for LSS 35 keep all in D0i3 */
+	mid_pmu_cxt->os_sss[2] = 0xFFFFFFFF;
+	mid_pmu_cxt->os_sss[3] = 0xFFFFFFFF;
+
+	mid_pmu_cxt->os_sss[2] &= ~SSMSK(D0I3_MASK, PMU_SSP4_LSS_35-32);
+
+	/* Map S0ix residency counters */
+	residency[SYS_STATE_S0I1] = ioremap_nocache(S0I1_RES_ADDR, sizeof(u64));
+	if (residency[SYS_STATE_S0I1] == NULL)
+		goto err1;
+	residency[SYS_STATE_LPMP3] = ioremap_nocache(LPMP3_RES_ADDR,
+								sizeof(u64));
+	if (residency[SYS_STATE_LPMP3] == NULL)
+		goto err2;
+	residency[SYS_STATE_S0I2] = ioremap_nocache(S0I2_RES_ADDR, sizeof(u64));
+	if (residency[SYS_STATE_S0I2] == NULL)
+		goto err3;
+	residency[SYS_STATE_S0I3] = ioremap_nocache(S0I3_RES_ADDR, sizeof(u64));
+	if (residency[SYS_STATE_S0I3] == NULL)
+		goto err4;
+
+	/* Map S0ix iteration counters */
+	s0ix_counter[SYS_STATE_S0I1] = ioremap_nocache(S0I1_COUNT_ADDR,
+								sizeof(u32));
+	if (s0ix_counter[SYS_STATE_S0I1] == NULL)
+		goto err5;
+	s0ix_counter[SYS_STATE_LPMP3] = ioremap_nocache(LPMP3_COUNT_ADDR,
+								sizeof(u32));
+	if (s0ix_counter[SYS_STATE_LPMP3] == NULL)
+		goto err6;
+	s0ix_counter[SYS_STATE_S0I2] = ioremap_nocache(S0I2_COUNT_ADDR,
+								sizeof(u32));
+	if (s0ix_counter[SYS_STATE_S0I2] == NULL)
+		goto err7;
+	s0ix_counter[SYS_STATE_S0I3] = ioremap_nocache(S0I3_COUNT_ADDR,
+								sizeof(u32));
+	if (s0ix_counter[SYS_STATE_S0I3] == NULL)
+		goto err8;
+	/* Keep PSH LSS's 00, 33, 34 in D0i0 if PM is disabled */
+	if (!enable_s0ix && !enable_s3) {
+		mid_pmu_cxt->os_sss[2] &=
+				~SSMSK(D0I3_MASK, PMU_I2C8_LSS_33-32);
+		mid_pmu_cxt->os_sss[2] &=
+				~SSMSK(D0I3_MASK, PMU_I2C9_LSS_34-32);
+	} else {
+		mid_pmu_cxt->os_sss[0] |= SSMSK(D0I3_MASK, PMU_PSH_LSS_00);
+	}
+
+	/* Disable the Interrupt Enable bit in PM ICS register */
+	pmu_clear_interrupt_enable();
+
+	return PMU_SUCCESS;
+
+err8:
+	iounmap(s0ix_counter[SYS_STATE_S0I3]);
+	s0ix_counter[SYS_STATE_S0I3] = NULL;
+err7:
+	iounmap(s0ix_counter[SYS_STATE_S0I2]);
+	s0ix_counter[SYS_STATE_S0I2] = NULL;
+err6:
+	iounmap(s0ix_counter[SYS_STATE_LPMP3]);
+	s0ix_counter[SYS_STATE_LPMP3] = NULL;
+err5:
+	iounmap(s0ix_counter[SYS_STATE_S0I1]);
+	s0ix_counter[SYS_STATE_S0I1] = NULL;
+err4:
+	iounmap(residency[SYS_STATE_S0I3]);
+	residency[SYS_STATE_S0I3] = NULL;
+err3:
+	iounmap(residency[SYS_STATE_S0I2]);
+	residency[SYS_STATE_S0I2] = NULL;
+err2:
+	iounmap(residency[SYS_STATE_LPMP3]);
+	residency[SYS_STATE_LPMP3] = NULL;
+err1:
+	iounmap(residency[SYS_STATE_S0I1]);
+	residency[SYS_STATE_S0I1] = NULL;
+
+	pr_err("Cannot map memory to read S0ix residency and count\n");
+	return PMU_FAILED;
+}
+
+/* This function checks north complex (NC) and
+ * south complex (SC) device status in MRFLD.
+ * returns TRUE if all NC and SC devices are in d0i3
+ * else FALSE.
+ */
+static bool mrfld_nc_sc_status_check(void)
+{
+	int i;
+	u32 val, nc_pwr_sts;
+	struct pmu_ss_states cur_pmsss;
+	bool nc_status, sc_status;
+
+	/* assuming nc and sc are good */
+	nc_status = true;
+	sc_status = true;
+
+	/* Check south complex device status */
+	pmu_read_sss(&cur_pmsss);
+
+	if (!(((cur_pmsss.pmu2_states[0] & S0IX_TARGET_SSS0_MASK) ==
+					 S0IX_TARGET_SSS0) &&
+		((cur_pmsss.pmu2_states[1] & S0IX_TARGET_SSS1_MASK) ==
+					 S0IX_TARGET_SSS1) &&
+		((cur_pmsss.pmu2_states[2] & S0IX_TARGET_SSS2_MASK) ==
+					 S0IX_TARGET_SSS2) &&
+		((cur_pmsss.pmu2_states[3] & S0IX_TARGET_SSS3_MASK) ==
+					 (S0IX_TARGET_SSS3)))) {
+		sc_status = false;
+		pr_warn("SC device/devices not in d0i3!!\n");
+		for (i = 0; i < 4; i++)
+			pr_warn("pmu2_states[%d] = %08lX\n", i,
+					cur_pmsss.pmu2_states[i]);
+	}
+
+	if (sc_status) {
+		/* Check north complex status */
+		nc_pwr_sts =
+			 intel_mid_msgbus_read32(PUNIT_PORT, NC_PM_SSS);
+		/* loop through the status to see if any of nc power island
+		 * is not in D0i3 state
+		 */
+		for (i = 0; i < mrfl_no_of_nc_devices; i++) {
+			val = nc_pwr_sts & 3;
+			if (val != 3) {
+				nc_status = false;
+				pr_warn("NC device (%s) is not in d0i3!!\n",
+							mrfl_nc_devices[i]);
+				pr_warn("nc_pm_sss = %08X\n", nc_pwr_sts);
+				break;
+			}
+			nc_pwr_sts >>= BITS_PER_LSS;
+		}
+	}
+
+	return nc_status & sc_status;
+}
+
+/* FIXME: Need to start the counter only if debug is
+ * needed. This will save SCU cycles if debug is
+ * disabled
+ */
+static int __init start_scu_s0ix_res_counters(void)
+{
+	int ret;
+
+	ret = intel_scu_ipc_simple_command(START_RES_COUNTER, 0);
+	if (ret) {
+		pr_err("IPC command to start res counter failed\n");
+		BUG();
+		return ret;
+	}
+	return 0;
+}
+late_initcall(start_scu_s0ix_res_counters);
+
+void platform_update_all_lss_states(struct pmu_ss_states *pmu_config,
+					int *PCIALLDEV_CFG)
+{
+	/* Overwrite the pmu_config values that we get */
+	pmu_config->pmu2_states[0] =
+				(SSMSK(D0I3_MASK, PMU_RESERVED_LSS_03)	|
+				SSMSK(D0I3_MASK, PMU_HSI_LSS_05)	|
+				SSMSK(D0I3_MASK, PMU_SECURITY_LSS_06)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_07)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_11)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_12)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_13)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_14)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_15));
+
+	/* Put LSS8 as unused on Tangier */
+	pmu_config->pmu2_states[0] |= \
+				SSMSK(D0I3_MASK, PMU_USB_MPH_LSS_08);
+
+	pmu_config->pmu2_states[1] =
+				(SSMSK(D0I3_MASK, PMU_RESERVED_LSS_16-16)|
+				SSMSK(D0I3_MASK, PMU_SSP3_LSS_17-16)|
+				SSMSK(D0I3_MASK, PMU_SSP6_LSS_19-16)|
+				SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_28-16)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_29-16)|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_30-16));
+
+	pmu_config->pmu2_states[0] &= ~IGNORE_SSS0;
+	pmu_config->pmu2_states[1] &= ~IGNORE_SSS1;
+	pmu_config->pmu2_states[2] = ~IGNORE_SSS2;
+	pmu_config->pmu2_states[3] = ~IGNORE_SSS3;
+
+	/* Excpet for LSS 35 keep all in D0i3 */
+	pmu_config->pmu2_states[2] &= ~SSMSK(D0I3_MASK, PMU_SSP4_LSS_35-32);
+
+	/* Keep PSH LSS's 00, 33, 34 in D0i0 if PM is disabled */
+	if (!enable_s0ix && !enable_s3) {
+		pmu_config->pmu2_states[2] &=
+				~SSMSK(D0I3_MASK, PMU_I2C8_LSS_33-32);
+		pmu_config->pmu2_states[2] &=
+				~SSMSK(D0I3_MASK, PMU_I2C9_LSS_34-32);
+	} else {
+		pmu_config->pmu2_states[0] |= SSMSK(D0I3_MASK, PMU_PSH_LSS_00);
+	}
+}
+
+/*
+ * In MDFLD and CLV this callback is used to issue
+ * PM_CMD which is not required in MRFLD
+ */
+static bool mrfld_pmu_enter(int s0ix_state)
+{
+	mid_pmu_cxt->s0ix_entered = s0ix_state;
+	if (s0ix_state == MID_S3_STATE) {
+		mid_pmu_cxt->pmu_current_state = SYS_STATE_S3;
+		pmu_set_interrupt_enable();
+	}
+
+	return true;
+}
+
+/**
+ *      platform_set_pmu_ops - Set the global pmu method table.
+ *      @ops:   Pointer to ops structure.
+ */
+void platform_set_pmu_ops(void)
+{
+	pmu_ops = &mrfld_pmu_ops;
+}
+
+/*
+ * As of now since there is no sequential mapping between
+ * LSS abd WKS bits the following two calls are dummy
+ */
+
+bool mid_pmu_is_wake_source(u32 lss_number)
+{
+	return false;
+}
+
+/* return the last wake source id, and make statistics about wake sources */
+int pmu_get_wake_source(void)
+{
+	return INVALID_WAKE_SRC;
+}
+
+
+int set_extended_cstate_mode(const char *val, struct kernel_param *kp)
+{
+	return 0;
+}
+
+int get_extended_cstate_mode(char *buffer, struct kernel_param *kp)
+{
+	const char *default_string = "not supported";
+	strcpy(buffer, default_string);
+	return strlen(default_string);
+}
+
+static int wait_for_nc_pmcmd_complete(int verify_mask,
+				int status_mask, int state_type , int reg)
+{
+	int pwr_sts;
+	int count = 0;
+
+	while (true) {
+		pwr_sts = intel_mid_msgbus_read32(PUNIT_PORT, reg);
+		pwr_sts = pwr_sts >> SSS_SHIFT;
+		if (state_type == OSPM_ISLAND_DOWN ||
+					state_type == OSPM_ISLAND_SR) {
+			if ((pwr_sts & status_mask) ==
+						(verify_mask & status_mask))
+				break;
+			else
+				udelay(10);
+		} else if (state_type == OSPM_ISLAND_UP) {
+			if ((~pwr_sts & status_mask)  ==
+						(~verify_mask & status_mask))
+				break;
+			else
+				udelay(10);
+		}
+
+		count++;
+		if (WARN_ONCE(count > 500000, "Timed out waiting for P-Unit"))
+			return -EBUSY;
+	}
+	return 0;
+}
+
+static int mrfld_nc_set_power_state(int islands, int state_type,
+							int reg, int *change)
+{
+	u32 pwr_sts = 0;
+	u32 pwr_mask = 0;
+	int i, lss, mask;
+	int ret = 0;
+	int status_mask = 0;
+
+	*change = 0;
+	pwr_sts = intel_mid_msgbus_read32(PUNIT_PORT, reg);
+	pwr_mask = pwr_sts;
+
+	for (i = 0; i < OSPM_MAX_POWER_ISLANDS; i++) {
+		lss = islands & (0x1 << i);
+		if (lss) {
+			mask = D0I3_MASK << (BITS_PER_LSS * i);
+			status_mask = status_mask | mask;
+			if (state_type == OSPM_ISLAND_DOWN)
+				pwr_mask |= mask;
+			else if (state_type == OSPM_ISLAND_UP)
+				pwr_mask &= ~mask;
+			/* Soft reset case */
+			else if (state_type == OSPM_ISLAND_SR) {
+				pwr_mask &= ~mask;
+				mask = SR_MASK << (BITS_PER_LSS * i);
+				pwr_mask |= mask;
+			}
+		}
+	}
+
+	if (pwr_mask != pwr_sts) {
+		intel_mid_msgbus_write32(PUNIT_PORT, reg, pwr_mask);
+		ret = wait_for_nc_pmcmd_complete(pwr_mask,
+					status_mask, state_type, reg);
+		if (!ret)
+			*change = 1;
+		if (nc_report_power_state)
+			nc_report_power_state(pwr_mask, reg);
+	}
+
+	return ret;
+}
+
+void s0ix_complete(void)
+{
+	if (mid_pmu_cxt->s0ix_entered) {
+		log_wakeup_irq();
+
+		if (mid_pmu_cxt->s0ix_entered == SYS_STATE_S3)
+			pmu_clear_interrupt_enable();
+
+		mid_pmu_cxt->pmu_current_state	=
+		mid_pmu_cxt->s0ix_entered	= 0;
+	}
+}
+
+bool could_do_s0ix(void)
+{
+	bool ret = false;
+	if (unlikely(!pmu_initialized))
+		goto ret;
+
+	/* dont do s0ix if suspend in progress */
+	if (unlikely(mid_pmu_cxt->suspend_started))
+		goto ret;
+
+	/* dont do s0ix if shutdown in progress */
+	if (unlikely(mid_pmu_cxt->shutdown_started))
+		goto ret;
+
+	if (nc_device_state())
+		goto ret;
+
+	ret = true;
+ret:
+	return ret;
+}
+EXPORT_SYMBOL(could_do_s0ix);
+
+struct platform_pmu_ops mrfld_pmu_ops = {
+	.init	 = mrfld_pmu_init,
+	.enter	 = mrfld_pmu_enter,
+	.set_s0ix_complete = s0ix_complete,
+	.nc_set_power_state = mrfld_nc_set_power_state,
+	.check_nc_sc_status = mrfld_nc_sc_status_check,
+};
diff --git a/arch/x86/platform/intel-mid/intel_soc_mrfld.h b/arch/x86/platform/intel-mid/intel_soc_mrfld.h
new file mode 100644
index 0000000..dd14cba
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_mrfld.h
@@ -0,0 +1,161 @@
+/*
+ * intel_soc_mrfld.h
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#ifdef CONFIG_REMOVEME_INTEL_ATOM_MRFLD_POWER
+
+#define PM_SUPPORT		0x21
+
+#define ISP_POS			7
+#define ISP_SUB_CLASS		0x80
+
+#define PUNIT_PORT		0x04
+#define SSS_SHIFT		24
+
+/* Soft reset mask */
+#define SR_MASK			0x2
+
+#define PMU1_MAX_DEVS			8
+#define PMU2_MAX_DEVS			55
+
+#define MRFLD_S3_HINT			0x64
+
+#define PUNIT_PORT			0x04
+#define NC_PM_SSS			0x3F
+
+/* SRAM locations to get S0ix residency */
+#define S0I1_RES_ADDR		0xFFFFF560
+#define LPMP3_RES_ADDR		0xFFFFF578
+#define S0I2_RES_ADDR		0xFFFFF568
+#define S0I3_RES_ADDR		0xFFFFF570
+
+/* SRAM locations to get S0ix count */
+#define S0I1_COUNT_ADDR		0xFFFFF588
+#define LPMP3_COUNT_ADDR	0xFFFFF594
+#define S0I2_COUNT_ADDR		0xFFFFF58C
+#define S0I3_COUNT_ADDR		0xFFFFF590
+
+/* IPC commands to start, stop and
+ * dump S0ix residency counters */
+#define START_RES_COUNTER	0x00EB
+#define STOP_RES_COUNTER	0x10EB
+#define DUMP_RES_COUNTER	0x20EB
+
+/* IPC commands to start/reset and
+ * dump S0ix count */
+#define START_S0IX_COUNT	0x00E1
+#define DUMP_S0IX_COUNT		0x10E1
+
+#define GFX_LSS_INDEX			1
+
+#define PMU_PSH_LSS_00			0
+#define PMU_SDIO0_LSS_01		1
+#define PMU_EMMC0_LSS_02		2
+#define PMU_RESERVED_LSS_03		3
+#define PMU_SDIO1_LSS_04		4
+#define PMU_HSI_LSS_05			5
+#define PMU_SECURITY_LSS_06		6
+#define PMU_RESERVED_LSS_07		7
+#define PMU_USB_MPH_LSS_08		8
+#define PMU_USB3_LSS_09			9
+#define PMU_AUDIO_LSS_10		10
+#define PMU_RESERVED_LSS_11		11
+#define PMU_RESERVED_LSS_12		12
+#define PMU_RESERVED_LSS_13		13
+#define PMU_RESERVED_LSS_14		14
+#define PMU_RESERVED_LSS_15		15
+#define PMU_RESERVED_LSS_16		16
+#define PMU_SSP3_LSS_17			17
+#define PMU_SSP5_LSS_18			18
+#define PMU_SSP6_LSS_19			19
+#define PMU_I2C1_LSS_20			20
+#define PMU_I2C2_LSS_21			21
+#define PMU_I2C3_LSS_22			22
+#define PMU_I2C4_LSS_23			23
+#define PMU_I2C5_LSS_24			24
+#define PMU_GP_DMA_LSS_25		25
+#define PMU_I2C6_LSS_26			26
+#define PMU_I2C7_LSS_27			27
+#define PMU_USB_OTG_LSS_28		28
+#define PMU_RESERVED_LSS_29		29
+#define PMU_RESERVED_LSS_30		30
+#define PMU_UART0_LSS_31		31
+#define PMU_UART1_LSS_31		31
+#define PMU_UART2_LSS_31		31
+
+#define PMU_I2C8_LSS_33			33
+#define PMU_I2C9_LSS_34			34
+#define PMU_SSP4_LSS_35			35
+#define PMU_PMW_LSS_36			36
+
+#define EMMC0_LSS			PMU_EMMC0_LSS_02
+
+#define IGNORE_SSS0			0
+#define IGNORE_SSS1			0
+#define IGNORE_SSS2			0
+#define IGNORE_SSS3			0
+
+#define PMU_WAKE_GPIO0      (1 << 0)
+#define PMU_WAKE_GPIO1      (1 << 1)
+#define PMU_WAKE_GPIO2      (1 << 2)
+#define PMU_WAKE_GPIO3      (1 << 3)
+#define PMU_WAKE_GPIO4      (1 << 4)
+#define PMU_WAKE_GPIO5      (1 << 5)
+#define PMU_WAKE_TIMERS     (1 << 6)
+#define PMU_WAKE_SECURITY   (1 << 7)
+#define PMU_WAKE_AONT32K    (1 << 8)
+#define PMU_WAKE_AONT       (1 << 9)
+#define PMU_WAKE_SVID_ALERT (1 << 10)
+#define PMU_WAKE_AUDIO      (1 << 11)
+#define PMU_WAKE_USB2       (1 << 12)
+#define PMU_WAKE_USB3       (1 << 13)
+#define PMU_WAKE_ILB        (1 << 14)
+#define PMU_WAKE_TAP        (1 << 15)
+#define PMU_WAKE_WATCHDOG   (1 << 16)
+#define PMU_WAKE_HSIC       (1 << 17)
+#define PMU_WAKE_PSH        (1 << 18)
+#define PMU_WAKE_PSH_GPIO   (1 << 19)
+#define PMU_WAKE_PSH_AONT   (1 << 20)
+#define PMU_WAKE_PSH_HALT   (1 << 21)
+#define PMU_GLBL_WAKE_MASK  (1 << 31)
+
+/* Ignore AONT WAKES and ALL from WKC1 */
+#define IGNORE_S3_WKC0 (PMU_WAKE_AONT32K | PMU_WAKE_AONT)
+#define IGNORE_S3_WKC1 (~0)
+
+#define S0IX_TARGET_SSS0_MASK (0xFFF3FFFF)
+#define S0IX_TARGET_SSS1_MASK (0xFFFFFFFF)
+#define S0IX_TARGET_SSS2_MASK (0xFFFFFFFF)
+#define S0IX_TARGET_SSS3_MASK (0xFFFFFFFF)
+
+#define S0IX_TARGET_SSS0 (0xFFF3FFFF)
+#define S0IX_TARGET_SSS1 (0xFFFFFFFF)
+#define S0IX_TARGET_SSS2 (0xFFFFFF3F)
+#define S0IX_TARGET_SSS3 (0xFFFFFFFF)
+
+#define LPMP3_TARGET_SSS0_MASK (0xFFF3FFFF)
+#define LPMP3_TARGET_SSS0 (0xFFC3FFFF)
+
+extern char *mrfl_nc_devices[];
+extern int mrfl_no_of_nc_devices;
+extern int intel_scu_ipc_simple_command(int, int);
+extern void log_wakeup_irq(void);
+extern void s0ix_complete(void);
+extern bool could_do_s0ix(void);
+
+#endif
diff --git a/arch/x86/platform/intel-mid/intel_soc_pm_debug.c b/arch/x86/platform/intel-mid/intel_soc_pm_debug.c
new file mode 100644
index 0000000..8ce4c81d
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_pm_debug.c
@@ -0,0 +1,2518 @@
+/*
+ * intel_soc_pm_debug.c - This driver provides debug utilities across
+ * multiple platforms
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+#include <linux/time.h>
+#include <asm/intel_mid_rpmsg.h>
+#include <linux/cpuidle.h>
+#include "intel_soc_pm_debug.h"
+#include <asm-generic/io-64-nonatomic-hi-lo.h>
+#include <asm/tsc.h>
+
+#ifdef CONFIG_PM_DEBUG
+#define MAX_CSTATES_POSSIBLE	32
+
+
+
+static struct latency_stat *lat_stat;
+
+static void latency_measure_enable_disable(bool enable_measure)
+{
+	int err;
+	u32 sub;
+
+	if (enable_measure == lat_stat->latency_measure)
+		return;
+
+	if (enable_measure)
+		sub = IPC_SUB_MEASURE_START_CLVP;
+	else
+		sub = IPC_SUB_MEASURE_STOP_CLVP;
+
+	err = rpmsg_send_generic_command(IPC_CMD_S0IX_LATENCY_CLVP,
+						sub, NULL, 0, NULL, 0);
+	if (unlikely(err)) {
+		pr_err("IPC to %s S0IX Latency Measurement failed!\n",
+					enable_measure ? "start" : "stop");
+		return;
+	}
+
+	if (enable_measure) {
+		memset(lat_stat->scu_latency, 0, sizeof(lat_stat->scu_latency));
+		memset(lat_stat->os_latency, 0, sizeof(lat_stat->os_latency));
+		memset(lat_stat->s3_parts_lat, 0,
+				sizeof(lat_stat->s3_parts_lat));
+		memset(lat_stat->count, 0, sizeof(lat_stat->count));
+	}
+
+	lat_stat->latency_measure = enable_measure;
+}
+
+static void print_simple_stat(struct seq_file *s, int divisor, int rem_div,
+					int count, struct simple_stat stat)
+{
+	unsigned long long min, avg, max;
+	unsigned long min_rem = 0, avg_rem = 0, max_rem = 0;
+
+	min = stat.min;
+	max = stat.max;
+	avg = stat.total;
+
+	if (count)
+		do_div(avg, count);
+
+	if (divisor > 1) {
+		min_rem = do_div(min, divisor);
+		max_rem = do_div(max, divisor);
+		avg_rem = do_div(avg, divisor);
+	}
+
+	if (rem_div > 1) {
+		min_rem /= rem_div;
+		max_rem /= rem_div;
+		avg_rem /= rem_div;
+	}
+
+	seq_printf(s, " %5llu.%03lu/%5llu.%03lu/%5llu.%03lu",
+			min, min_rem, avg, avg_rem, max, max_rem);
+}
+
+static int show_pmu_s0ix_lat(struct seq_file *s, void *unused)
+{
+	int i = 0;
+
+	char *states[] = {
+		"S0I1",
+		"LPMP3",
+		"S0I3",
+		"S3"
+	};
+
+	char *s3_parts_names[] = {
+		"PROC_FRZ",
+		"DEV_SUS",
+		"NB_CPU_OFF",
+		"NB_CPU_ON",
+		"DEV_RES",
+		"PROC_UNFRZ"
+	};
+
+	seq_printf(s, "%29s %35s\n", "SCU Latency", "OS Latency");
+	seq_printf(s, "%33s %35s\n", "min/avg/max(msec)", "min/avg/max(msec)");
+
+	for (i = SYS_STATE_S0I1; i <= SYS_STATE_S3; i++) {
+		seq_printf(s, "\n%s(%llu)", states[i - SYS_STATE_S0I1],
+							lat_stat->count[i]);
+
+		seq_printf(s, "\n%5s", "entry");
+		print_simple_stat(s, USEC_PER_MSEC, 1, lat_stat->count[i],
+						lat_stat->scu_latency[i].entry);
+		seq_printf(s, "      ");
+		print_simple_stat(s, NSEC_PER_MSEC, NSEC_PER_USEC,
+			lat_stat->count[i], lat_stat->os_latency[i].entry);
+
+		seq_printf(s, "\n%5s", "exit");
+		print_simple_stat(s, USEC_PER_MSEC, 1, lat_stat->count[i],
+						lat_stat->scu_latency[i].exit);
+		seq_printf(s, "      ");
+		print_simple_stat(s, NSEC_PER_MSEC, NSEC_PER_USEC,
+			lat_stat->count[i], lat_stat->os_latency[i].exit);
+
+	}
+
+	seq_printf(s, "\n\n");
+
+	if (!lat_stat->count[SYS_STATE_S3])
+		return 0;
+
+	seq_printf(s, "S3 Latency dissection:\n");
+	seq_printf(s, "%38s\n", "min/avg/max(msec)");
+
+	for (i = 0; i < MAX_S3_PARTS; i++) {
+		seq_printf(s, "%10s\t", s3_parts_names[i]);
+		print_simple_stat(s, NSEC_PER_MSEC, NSEC_PER_USEC,
+					lat_stat->count[SYS_STATE_S3],
+					lat_stat->s3_parts_lat[i]);
+		seq_printf(s, "\n");
+	}
+
+	return 0;
+}
+
+static int pmu_s0ix_lat_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, show_pmu_s0ix_lat, NULL);
+}
+
+static ssize_t pmu_s0ix_lat_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+
+	buf[buf_size] = 0;
+
+	if (((strlen("start") + 1) == buf_size) &&
+		!strncmp(buf, "start", strlen("start"))) {
+		latency_measure_enable_disable(true);
+	} else if (((strlen("stop") + 1) == buf_size) &&
+		!strncmp(buf, "stop", strlen("stop"))) {
+		latency_measure_enable_disable(false);
+	}
+
+	return buf_size;
+}
+
+static const struct file_operations s0ix_latency_ops = {
+	.open		= pmu_s0ix_lat_open,
+	.read		= seq_read,
+	.write		= pmu_s0ix_lat_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static void update_simple_stat(struct simple_stat *simple_stat, int count)
+{
+	u64 duration = simple_stat->curr;
+
+	if (!count) {
+		simple_stat->min =
+		simple_stat->max =
+		simple_stat->total = duration;
+	} else {
+		if (duration < simple_stat->min)
+			simple_stat->min = duration;
+		else if (duration > simple_stat->max)
+			simple_stat->max = duration;
+		simple_stat->total += duration;
+	}
+}
+
+void s0ix_scu_latency_stat(int type)
+{
+	if (!lat_stat || !lat_stat->latency_measure)
+		return;
+
+	if (type < SYS_STATE_S0I1 || type > SYS_STATE_S3)
+		return;
+
+	lat_stat->scu_latency[type].entry.curr =
+			readl(lat_stat->scu_s0ix_lat_addr);
+	lat_stat->scu_latency[type].exit.curr =
+			readl(lat_stat->scu_s0ix_lat_addr + 1);
+
+	update_simple_stat(&lat_stat->scu_latency[type].entry,
+					lat_stat->count[type]);
+	update_simple_stat(&lat_stat->scu_latency[type].exit,
+					lat_stat->count[type]);
+}
+
+void s0ix_lat_stat_init(void)
+{
+	if (!platform_is(INTEL_ATOM_CLV))
+		return;
+
+	lat_stat = kzalloc(sizeof(struct latency_stat), GFP_KERNEL);
+	if (unlikely(!lat_stat)) {
+		pr_err("Failed to allocate memory for s0ix latency!\n");
+		goto out_err0;
+	}
+
+	lat_stat->scu_s0ix_lat_addr =
+		ioremap_nocache(S0IX_LAT_SRAM_ADDR_CLVP,
+					S0IX_LAT_SRAM_SIZE_CLVP);
+	if (unlikely(!lat_stat->scu_s0ix_lat_addr)) {
+		pr_err("Failed to map SCU_S0IX_LAT_ADDR!\n");
+		goto out_err1;
+	}
+
+	lat_stat->dentry = debugfs_create_file("s0ix_latency",
+			S_IFREG | S_IRUGO, NULL, NULL, &s0ix_latency_ops);
+	if (unlikely(!lat_stat->dentry)) {
+		pr_err("Failed to create debugfs for s0ix latency!\n");
+		goto out_err2;
+	}
+
+	return;
+
+out_err2:
+	iounmap(lat_stat->scu_s0ix_lat_addr);
+out_err1:
+	kfree(lat_stat);
+	lat_stat = NULL;
+out_err0:
+	pr_err("%s: Initialization failed\n", __func__);
+}
+
+void s0ix_lat_stat_finish(void)
+{
+	if (!platform_is(INTEL_ATOM_CLV))
+		return;
+
+	if (unlikely(!lat_stat))
+		return;
+
+	if (likely(lat_stat->scu_s0ix_lat_addr))
+		iounmap(lat_stat->scu_s0ix_lat_addr);
+
+	if (likely(lat_stat->dentry))
+		debugfs_remove(lat_stat->dentry);
+
+	kfree(lat_stat);
+	lat_stat = NULL;
+}
+
+void time_stamp_in_suspend_flow(int mark, bool start)
+{
+	if (!lat_stat || !lat_stat->latency_measure)
+		return;
+
+	if (start) {
+		lat_stat->s3_parts_lat[mark].curr = cpu_clock(0);
+		return;
+	}
+
+	lat_stat->s3_parts_lat[mark].curr = cpu_clock(0) -
+				lat_stat->s3_parts_lat[mark].curr;
+}
+
+static void collect_sleep_state_latency_stat(int sleep_state)
+{
+	int i;
+	if (sleep_state == SYS_STATE_S3)
+		for (i = 0; i < MAX_S3_PARTS; i++)
+			update_simple_stat(&lat_stat->s3_parts_lat[i],
+						lat_stat->count[sleep_state]);
+
+	update_simple_stat(&lat_stat->os_latency[sleep_state].entry,
+						lat_stat->count[sleep_state]);
+	update_simple_stat(&lat_stat->os_latency[sleep_state].exit,
+						lat_stat->count[sleep_state]);
+	lat_stat->count[sleep_state]++;
+}
+
+void time_stamp_for_sleep_state_latency(int sleep_state, bool start, bool entry)
+{
+	if (!lat_stat || !lat_stat->latency_measure)
+		return;
+
+	if (start) {
+		if (entry)
+			lat_stat->os_latency[sleep_state].entry.curr =
+								cpu_clock(0);
+		else
+			lat_stat->os_latency[sleep_state].exit.curr =
+								cpu_clock(0);
+		return;
+	}
+
+	if (entry)
+		lat_stat->os_latency[sleep_state].entry.curr = cpu_clock(0) -
+				lat_stat->os_latency[sleep_state].entry.curr;
+	else {
+		lat_stat->os_latency[sleep_state].exit.curr = cpu_clock(0) -
+				lat_stat->os_latency[sleep_state].exit.curr;
+		collect_sleep_state_latency_stat(sleep_state);
+	}
+}
+#else /* CONFIG_PM_DEBUG */
+void s0ix_scu_latency_stat(int type) {}
+void s0ix_lat_stat_init(void) {}
+void s0ix_lat_stat_finish(void) {}
+void time_stamp_for_sleep_state_latency(int sleep_state, bool start,
+							bool entry) {}
+void time_stamp_in_suspend_flow(int mark, bool start) {}
+inline unsigned int pmu_get_new_cstate
+		(unsigned int cstate, int *index) { return cstate; };
+#endif /* CONFIG_PM_DEBUG */
+
+static char *dstates[] = {"D0", "D0i1", "D0i2", "D0i3"};
+
+/* This can be used to report NC power transitions */
+void (*nc_report_power_state) (u32, int);
+
+#if defined(CONFIG_REMOVEME_INTEL_ATOM_MDFLD_POWER)			\
+			|| defined(CONFIG_REMOVEME_INTEL_ATOM_CLV_POWER)
+
+#define PMU_DEBUG_PRINT_STATS	(1U << 0)
+static int debug_mask;
+module_param_named(debug_mask, debug_mask, int, S_IRUGO | S_IWUSR | S_IWGRP);
+
+#define DEBUG_PRINT(logging_type, s, debug_level_mask, args...)		\
+	do {								\
+		if (logging_type)					\
+			seq_printf(s, args);				\
+		else if (debug_mask &					\
+			PMU_DEBUG_PRINT_##debug_level_mask)		\
+			pr_info(args);					\
+	} while (0)
+
+static struct island display_islands[] = {
+	{APM_REG_TYPE, APM_GRAPHICS_ISLAND, "GFX"},
+	{APM_REG_TYPE, APM_VIDEO_DEC_ISLAND, "Video Decoder"},
+	{APM_REG_TYPE, APM_VIDEO_ENC_ISLAND, "Video Encoder"},
+	{APM_REG_TYPE, APM_GL3_CACHE_ISLAND, "GL3 Cache"},
+	{OSPM_REG_TYPE, OSPM_DISPLAY_A_ISLAND, "Display A"},
+	{OSPM_REG_TYPE, OSPM_DISPLAY_B_ISLAND, "Display B"},
+	{OSPM_REG_TYPE, OSPM_DISPLAY_C_ISLAND, "Display C"},
+	{OSPM_REG_TYPE, OSPM_MIPI_ISLAND, "MIPI-DSI"}
+};
+
+static struct island camera_islands[] = {
+	{APM_REG_TYPE, APM_ISP_ISLAND, "ISP"},
+	{APM_REG_TYPE, APM_IPH_ISLAND, "Iunit PHY"}
+};
+
+static char *lss_device_status[4] = { "D0i0", "D0i1", "D0i2", "D0i3" };
+
+static int lsses_num =
+			sizeof(lsses)/sizeof(lsses[0]);
+
+#ifdef LOG_PMU_EVENTS
+static void pmu_log_timestamp(struct timespec *ts)
+{
+	if (timekeeping_suspended) {
+		ts->tv_sec = 0;
+		ts->tv_nsec = 0;
+	} else {
+		ktime_get_ts(ts);
+	}
+}
+
+void pmu_log_pmu_irq(int status)
+{
+	struct mid_pmu_pmu_irq_log *log =
+		&mid_pmu_cxt->pmu_irq_log[mid_pmu_cxt->pmu_irq_log_idx];
+
+	log->status = status;
+	pmu_log_timestamp(&log->ts);
+	mid_pmu_cxt->pmu_irq_log_idx =
+		(mid_pmu_cxt->pmu_irq_log_idx + 1) % LOG_SIZE;
+}
+
+static void pmu_dump_pmu_irq_log(void)
+{
+	struct mid_pmu_pmu_irq_log *log;
+	int i = mid_pmu_cxt->pmu_irq_log_idx, j;
+
+	printk(KERN_ERR"%d last pmu irqs:\n", LOG_SIZE);
+
+	for (j = 0; j  < LOG_SIZE; j++) {
+		i ? i-- : (i = LOG_SIZE - 1);
+		log = &mid_pmu_cxt->pmu_irq_log[i];
+		printk(KERN_ERR"Timestamp: %lu.%09lu\n",
+			log->ts.tv_sec, log->ts.tv_nsec);
+		printk(KERN_ERR"Status = 0x%02x", log->status);
+		printk(KERN_ERR"\n");
+	}
+}
+
+void pmu_log_ipc_irq(void)
+{
+	struct mid_pmu_ipc_irq_log *log =
+		&mid_pmu_cxt->ipc_irq_log[mid_pmu_cxt->ipc_irq_log_idx];
+
+	pmu_log_timestamp(&log->ts);
+	mid_pmu_cxt->ipc_irq_log_idx =
+	(mid_pmu_cxt->ipc_irq_log_idx + 1) % LOG_SIZE;
+}
+
+static void pmu_dump_ipc_irq_log(void)
+{
+	struct mid_pmu_ipc_irq_log *log;
+	int i = mid_pmu_cxt->ipc_irq_log_idx, j;
+
+	printk(KERN_ERR"%d last ipc irqs:\n", LOG_SIZE);
+
+	for (j = 0; j  < LOG_SIZE; j++) {
+		i ? i-- : (i = LOG_SIZE - 1);
+		log = &mid_pmu_cxt->ipc_irq_log[i];
+		printk(KERN_ERR"Timestamp: %lu.%09lu\n",
+			log->ts.tv_sec, log->ts.tv_nsec);
+		printk(KERN_ERR"\n");
+	}
+}
+
+void pmu_log_ipc(u32 command)
+{
+	struct mid_pmu_ipc_log *log =
+	&mid_pmu_cxt->ipc_log[mid_pmu_cxt->ipc_log_idx];
+
+	log->command = command;
+	pmu_log_timestamp(&log->ts);
+	mid_pmu_cxt->ipc_log_idx = (mid_pmu_cxt->ipc_log_idx + 1) % LOG_SIZE;
+}
+
+static void pmu_dump_ipc_log(void)
+{
+	struct mid_pmu_ipc_log *log;
+	int i = mid_pmu_cxt->ipc_log_idx, j;
+
+	printk(KERN_ERR"%d last ipc commands:\n", LOG_SIZE);
+
+	for (j = 0; j  < LOG_SIZE; j++) {
+		i  ? i-- : (i = LOG_SIZE - 1);
+		log = &mid_pmu_cxt->ipc_log[i];
+		printk(KERN_ERR"Timestamp: %lu.%09lu\n",
+			log->ts.tv_sec, log->ts.tv_nsec);
+		printk(KERN_ERR"Command: 0x%08x", log->command);
+		printk(KERN_ERR"\n");
+	}
+}
+
+void pmu_log_command(u32 command, struct pmu_ss_states *pm_ssc)
+{
+	struct mid_pmu_cmd_log *log =
+		&mid_pmu_cxt->cmd_log[mid_pmu_cxt->cmd_log_idx];
+
+	if (pm_ssc != NULL)
+		memcpy(&log->pm_ssc, pm_ssc, sizeof(struct pmu_ss_states));
+	else
+		memset(&log->pm_ssc, 0, sizeof(struct pmu_ss_states));
+	log->command = command;
+	pmu_log_timestamp(&log->ts);
+	mid_pmu_cxt->cmd_log_idx = (mid_pmu_cxt->cmd_log_idx + 1) % LOG_SIZE;
+}
+
+static void pmu_dump_command_log(void)
+{
+	struct mid_pmu_cmd_log *log;
+	int i = mid_pmu_cxt->cmd_log_idx, j, k;
+	u32 cmd_state;
+	printk(KERN_ERR"%d last pmu commands:\n", LOG_SIZE);
+
+	for (j = 0; j  < LOG_SIZE; j++) {
+		i ? i-- : (i = LOG_SIZE - 1);
+		log = &mid_pmu_cxt->cmd_log[i];
+		cmd_state = log->command;
+		printk(KERN_ERR"Timestamp: %lu.%09lu\n",
+			log->ts.tv_sec, log->ts.tv_nsec);
+		switch (cmd_state) {
+		case INTERACTIVE_VALUE:
+			printk(KERN_ERR"PM_CMD = Interactive_CMD IOC bit not set.\n");
+			break;
+		case INTERACTIVE_IOC_VALUE:
+			printk(KERN_ERR"PM_CMD = Interactive_CMD IOC bit set.\n");
+			break;
+		case S0I1_VALUE:
+			printk(KERN_ERR"PM_CMD = S0i1_CMD\n");
+			break;
+		case S0I3_VALUE:
+			printk(KERN_ERR"PM_CMD = S0i3_CMD\n");
+			break;
+		case LPMP3_VALUE:
+			printk(KERN_ERR"PM_CMD = LPMP3_CMD\n");
+			break;
+		default:
+			printk(KERN_ERR "Invalid PM_CMD\n");
+			break;
+		}
+		for (k = 0; k < 4; k++)
+			printk(KERN_ERR"pmu2_states[%d]: 0x%08lx\n",
+				k, log->pm_ssc.pmu2_states[k]);
+			printk(KERN_ERR"\n");
+	}
+}
+
+void pmu_dump_logs(void)
+{
+	struct timespec ts;
+
+	pmu_log_timestamp(&ts);
+	printk(KERN_ERR"Dumping out pmu logs\n");
+	printk(KERN_ERR"Timestamp: %lu.%09lu\n\n", ts.tv_sec, ts.tv_nsec);
+	printk(KERN_ERR"---------------------------------------\n\n");
+	pmu_dump_command_log();
+	printk(KERN_ERR"---------------------------------------\n\n");
+	pmu_dump_pmu_irq_log();
+	printk(KERN_ERR"---------------------------------------\n\n");
+	pmu_dump_ipc_log();
+	printk(KERN_ERR"---------------------------------------\n\n");
+	pmu_dump_ipc_irq_log();
+}
+#else
+void pmu_log_pmu_irq(int status) {}
+void pmu_log_command(u32 command, struct pmu_ss_states *pm_ssc) {}
+void pmu_dump_logs(void) {}
+#endif /* LOG_PMU_EVENTS */
+
+void pmu_stat_start(enum sys_state type)
+{
+	mid_pmu_cxt->pmu_current_state = type;
+	mid_pmu_cxt->pmu_stats[type].last_try = cpu_clock(smp_processor_id());
+}
+
+void pmu_stat_end(void)
+{
+	enum sys_state type = mid_pmu_cxt->pmu_current_state;
+
+	if (type > SYS_STATE_S0I0 && type < SYS_STATE_MAX) {
+		mid_pmu_cxt->pmu_stats[type].last_entry =
+			mid_pmu_cxt->pmu_stats[type].last_try;
+
+		if (!mid_pmu_cxt->pmu_stats[type].count)
+			mid_pmu_cxt->pmu_stats[type].first_entry =
+				mid_pmu_cxt->pmu_stats[type].last_entry;
+
+		mid_pmu_cxt->pmu_stats[type].time +=
+			cpu_clock(smp_processor_id())
+			- mid_pmu_cxt->pmu_stats[type].last_entry;
+
+		mid_pmu_cxt->pmu_stats[type].count++;
+
+		s0ix_scu_latency_stat(type);
+		if (type >= SYS_STATE_S0I1 && type <= SYS_STATE_S0I3)
+			/* time stamp for end of s0ix exit */
+			time_stamp_for_sleep_state_latency(type, false, false);
+	}
+
+	mid_pmu_cxt->pmu_current_state = SYS_STATE_S0I0;
+}
+
+void pmu_stat_error(u8 err_type)
+{
+	enum sys_state type = mid_pmu_cxt->pmu_current_state;
+	u8 err_index;
+
+	if (type > SYS_STATE_S0I0 && type < SYS_STATE_MAX) {
+		switch (err_type) {
+		case SUBSYS_POW_ERR_INT:
+			trace_printk("S0ix_POW_ERR_INT\n");
+			err_index = 0;
+			break;
+		case S0ix_MISS_INT:
+			trace_printk("S0ix_MISS_INT\n");
+			err_index = 1;
+			break;
+		case NO_ACKC6_INT:
+			trace_printk("S0ix_NO_ACKC6_INT\n");
+			err_index = 2;
+			break;
+		default:
+			err_index = 3;
+			break;
+		}
+
+		if (err_index < 3)
+			mid_pmu_cxt->pmu_stats[type].err_count[err_index]++;
+	}
+}
+
+static void pmu_stat_seq_printf(struct seq_file *s, int type, char *typestr)
+{
+	unsigned long long t;
+	unsigned long nanosec_rem, remainder;
+	unsigned long time, init_2_now_time;
+
+	seq_printf(s, "%s\t%5llu\t%10llu\t%9llu\t%9llu\t", typestr,
+		 mid_pmu_cxt->pmu_stats[type].count,
+		 mid_pmu_cxt->pmu_stats[type].err_count[0],
+		 mid_pmu_cxt->pmu_stats[type].err_count[1],
+		 mid_pmu_cxt->pmu_stats[type].err_count[2]);
+
+	t = mid_pmu_cxt->pmu_stats[type].time;
+	nanosec_rem = do_div(t, NANO_SEC);
+
+	/* convert time in secs */
+	time = (unsigned long)t;
+
+	seq_printf(s, "%5lu.%06lu\t",
+	   (unsigned long) t, nanosec_rem / 1000);
+
+	t = mid_pmu_cxt->pmu_stats[type].last_entry;
+	nanosec_rem = do_div(t, NANO_SEC);
+	seq_printf(s, "%5lu.%06lu\t",
+	   (unsigned long) t, nanosec_rem / 1000);
+
+	t = mid_pmu_cxt->pmu_stats[type].first_entry;
+	nanosec_rem = do_div(t, NANO_SEC);
+	seq_printf(s, "%5lu.%06lu\t",
+	   (unsigned long) t, nanosec_rem / 1000);
+
+	t =  cpu_clock(raw_smp_processor_id());
+	t -= mid_pmu_cxt->pmu_init_time;
+	nanosec_rem = do_div(t, NANO_SEC);
+
+	init_2_now_time =  (unsigned long) t;
+
+	/* for calculating percentage residency */
+	t = (u64) time;
+	t *= 100;
+
+	/* take care of divide by zero */
+	if (init_2_now_time) {
+		remainder = do_div(t, init_2_now_time);
+		time = (unsigned long) t;
+
+		/* for getting 3 digit precision after
+		 * decimal dot */
+		t = (u64) remainder;
+		t *= 1000;
+		remainder = do_div(t, init_2_now_time);
+	} else
+		time = t = 0;
+
+	seq_printf(s, "%5lu.%03lu\n", time, (unsigned long) t);
+}
+
+static unsigned long pmu_dev_res_print(int index, unsigned long *precision,
+				unsigned long *sampled_time, bool dev_state)
+{
+	unsigned long long t, delta_time = 0;
+	unsigned long nanosec_rem, remainder;
+	unsigned long time, init_to_now_time;
+
+	t =  cpu_clock(raw_smp_processor_id());
+
+	if (dev_state) {
+		/* print for d0ix */
+		if ((mid_pmu_cxt->pmu_dev_res[index].state != PCI_D0))
+			delta_time = t -
+				mid_pmu_cxt->pmu_dev_res[index].d0i3_entry;
+
+			delta_time += mid_pmu_cxt->pmu_dev_res[index].d0i3_acc;
+	} else {
+		/* print for d0i0 */
+		if ((mid_pmu_cxt->pmu_dev_res[index].state == PCI_D0))
+			delta_time = t -
+				mid_pmu_cxt->pmu_dev_res[index].d0i0_entry;
+
+		delta_time += mid_pmu_cxt->pmu_dev_res[index].d0i0_acc;
+	}
+
+	t -= mid_pmu_cxt->pmu_dev_res[index].start;
+	nanosec_rem = do_div(t, NANO_SEC);
+
+	init_to_now_time =  (unsigned long) t;
+
+	t = delta_time;
+	nanosec_rem = do_div(t, NANO_SEC);
+
+	/* convert time in secs */
+	time = (unsigned long)t;
+	*sampled_time = time;
+
+	/* for calculating percentage residency */
+	t = (u64) time;
+	t *= 100;
+
+	/* take care of divide by zero */
+	if (init_to_now_time) {
+		remainder = do_div(t, init_to_now_time);
+		time = (unsigned long) t;
+
+		/* for getting 3 digit precision after
+		* decimal dot */
+		t = (u64) remainder;
+		t *= 1000;
+		remainder = do_div(t, init_to_now_time);
+	} else
+		time = t = 0;
+
+	*precision = (unsigned long)t;
+
+	return time;
+}
+
+static void nc_device_state_show(struct seq_file *s, struct pci_dev *pdev)
+{
+	int off, i, islands_num, state;
+	struct island *islands;
+
+	if (PCI_SLOT(pdev->devfn) == DEV_GFX &&
+			PCI_FUNC(pdev->devfn) == FUNC_GFX) {
+		off = mid_pmu_cxt->display_off;
+		islands_num = ISLANDS_GFX;
+		islands = &display_islands[0];
+	} else if (PCI_SLOT(pdev->devfn) == DEV_ISP &&
+			PCI_FUNC(pdev->devfn) == FUNC_ISP) {
+		off = mid_pmu_cxt->camera_off;
+		islands_num = ISLANDS_ISP;
+		islands = &camera_islands[0];
+	} else {
+		return;
+	}
+
+	seq_printf(s, "pci %04x %04X %s %20s: %41s %s\n",
+		pdev->vendor, pdev->device, dev_name(&pdev->dev),
+		dev_driver_string(&pdev->dev),
+		"", off ? "" : "blocking s0ix");
+	for (i = 0; i < islands_num; i++) {
+		state = pmu_nc_get_power_state(islands[i].index,
+				islands[i].type);
+		seq_printf(s, "%52s %15s %17s %s\n",
+				 "|------->", islands[i].name, "",
+				(state >= 0) ? dstates[state & 3] : "ERR");
+	}
+}
+
+static int pmu_devices_state_show(struct seq_file *s, void *unused)
+{
+	struct pci_dev *pdev = NULL;
+	int index, i, pmu_num, ss_idx, ss_pos;
+	unsigned int base_class;
+	u32 target_mask, mask, val, needed;
+	struct pmu_ss_states cur_pmsss;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	_pmu2_wait_not_busy();
+	pmu_read_sss(&cur_pmsss);
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	seq_printf(s, "TARGET_CFG: ");
+	seq_printf(s, "SSS0:%08X ", S0IX_TARGET_SSS0_MASK);
+	seq_printf(s, "SSS1:%08X ", S0IX_TARGET_SSS1_MASK);
+	seq_printf(s, "SSS2:%08X ", S0IX_TARGET_SSS2_MASK);
+	seq_printf(s, "SSS3:%08X ", S0IX_TARGET_SSS3_MASK);
+
+	seq_printf(s, "\n");
+	seq_printf(s, "CONDITION FOR S0I3: ");
+	seq_printf(s, "SSS0:%08X ", S0IX_TARGET_SSS0);
+	seq_printf(s, "SSS1:%08X ", S0IX_TARGET_SSS1);
+	seq_printf(s, "SSS2:%08X ", S0IX_TARGET_SSS2);
+	seq_printf(s, "SSS3:%08X ", S0IX_TARGET_SSS3);
+
+	seq_printf(s, "\n");
+	seq_printf(s, "SSS: ");
+
+	for (i = 0; i < 4; i++)
+		seq_printf(s, "%08lX ", cur_pmsss.pmu2_states[i]);
+
+	if (!mid_pmu_cxt->display_off)
+		seq_printf(s, "display not suspended: blocking s0ix\n");
+	else if (!mid_pmu_cxt->camera_off)
+		seq_printf(s, "camera not suspended: blocking s0ix\n");
+	else if (mid_pmu_cxt->s0ix_possible & MID_S0IX_STATE)
+		seq_printf(s, "can enter s0i1 or s0i3\n");
+	else if (mid_pmu_cxt->s0ix_possible & MID_LPMP3_STATE)
+		seq_printf(s, "can enter lpmp3\n");
+	else
+		seq_printf(s, "blocking s0ix\n");
+
+	seq_printf(s, "cmd_error_int count: %d\n", mid_pmu_cxt->cmd_error_int);
+
+	seq_printf(s,
+	"\tcount\tsybsys_pow\ts0ix_miss\tno_ack_c6\ttime (secs)\tlast_entry");
+	seq_printf(s, "\tfirst_entry\tresidency(%%)\n");
+
+	pmu_stat_seq_printf(s, SYS_STATE_S0I1, "s0i1");
+	pmu_stat_seq_printf(s, SYS_STATE_S0I2, "lpmp3");
+	pmu_stat_seq_printf(s, SYS_STATE_S0I3, "s0i3");
+	pmu_stat_seq_printf(s, SYS_STATE_S3, "s3");
+
+	for_each_pci_dev(pdev) {
+		/* find the base class info */
+		base_class = pdev->class >> 16;
+
+		if (base_class == PCI_BASE_CLASS_BRIDGE)
+			continue;
+
+		if (pmu_pci_to_indexes(pdev, &index, &pmu_num, &ss_idx,
+								  &ss_pos))
+			continue;
+
+		if (pmu_num == PMU_NUM_1) {
+			nc_device_state_show(s, pdev);
+			continue;
+		}
+
+		mask	= (D0I3_MASK << (ss_pos * BITS_PER_LSS));
+		val	= (cur_pmsss.pmu2_states[ss_idx] & mask) >>
+						(ss_pos * BITS_PER_LSS);
+		switch (ss_idx) {
+		case 0:
+			target_mask = S0IX_TARGET_SSS0_MASK;
+			break;
+		case 1:
+			target_mask = S0IX_TARGET_SSS1_MASK;
+			break;
+		case 2:
+			target_mask = S0IX_TARGET_SSS2_MASK;
+			break;
+		case 3:
+			target_mask = S0IX_TARGET_SSS3_MASK;
+			break;
+		default:
+			target_mask = 0;
+			break;
+		}
+		needed	= ((target_mask &  mask) != 0);
+
+		seq_printf(s, "pci %04x %04X %s %20s: lss:%02d reg:%d"
+			"mask:%08X wk:%02d:%02d:%02d:%03d %s  %s\n",
+			pdev->vendor, pdev->device, dev_name(&pdev->dev),
+			dev_driver_string(&pdev->dev),
+			index - mid_pmu_cxt->pmu1_max_devs, ss_idx, mask,
+			mid_pmu_cxt->num_wakes[index][SYS_STATE_S0I1],
+			mid_pmu_cxt->num_wakes[index][SYS_STATE_S0I2],
+			mid_pmu_cxt->num_wakes[index][SYS_STATE_S0I3],
+			mid_pmu_cxt->num_wakes[index][SYS_STATE_S3],
+			dstates[val & 3],
+			(needed && !val) ? "blocking s0ix" : "");
+
+	}
+
+	return 0;
+}
+
+static int devices_state_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, pmu_devices_state_show, NULL);
+}
+
+static ssize_t devices_state_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+
+	buf[buf_size] = 0;
+
+	if (((strlen("clear")+1) == buf_size) &&
+		!strncmp(buf, "clear", strlen("clear"))) {
+		down(&mid_pmu_cxt->scu_ready_sem);
+		memset(mid_pmu_cxt->pmu_stats, 0,
+					sizeof(mid_pmu_cxt->pmu_stats));
+		memset(mid_pmu_cxt->num_wakes, 0,
+					sizeof(mid_pmu_cxt->num_wakes));
+		mid_pmu_cxt->pmu_current_state = SYS_STATE_S0I0;
+		mid_pmu_cxt->pmu_init_time =
+			cpu_clock(raw_smp_processor_id());
+		clear_d0ix_stats();
+		up(&mid_pmu_cxt->scu_ready_sem);
+	}
+
+	return buf_size;
+}
+
+static const struct file_operations devices_state_operations = {
+	.open		= devices_state_open,
+	.read		= seq_read,
+	.write		= devices_state_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int show_pmu_lss_status(struct seq_file *s, void *unused)
+{
+	int sss_reg_index;
+	int offset;
+	int lss;
+	unsigned long status;
+	unsigned long sub_status;
+	unsigned long lss_status[4];
+	struct lss_definition *entry;
+
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	lss_status[0] = readl(&mid_pmu_cxt->pmu_reg->pm_sss[0]);
+	lss_status[1] = readl(&mid_pmu_cxt->pmu_reg->pm_sss[1]);
+	lss_status[2] = readl(&mid_pmu_cxt->pmu_reg->pm_sss[2]);
+	lss_status[3] = readl(&mid_pmu_cxt->pmu_reg->pm_sss[3]);
+
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	lss = 0;
+	seq_printf(s, "%5s\t%12s %35s %5s %4s %4s %4s %4s\n",
+			"lss", "block", "subsystem", "state", "D0i0", "D0i1",
+			"D0i2", "D0i3");
+	seq_printf(s, "====================================================="
+		      "=====================\n");
+	for (sss_reg_index = 0; sss_reg_index < 4; sss_reg_index++) {
+		status = lss_status[sss_reg_index];
+		for (offset = 0; offset < sizeof(unsigned long) * 8 / 2;
+								offset++) {
+			sub_status = status & 3;
+			if (lss >= lsses_num)
+				entry = &lsses[lsses_num - 1];
+			else
+				entry = &lsses[lss];
+			seq_printf(s, "%5s\t%12s %35s %4s %4d %4d %4d %4d\n",
+					entry->lss_name, entry->block,
+					entry->subsystem,
+					lss_device_status[sub_status],
+					get_d0ix_stat(lss, SS_STATE_D0I0),
+					get_d0ix_stat(lss, SS_STATE_D0I1),
+					get_d0ix_stat(lss, SS_STATE_D0I2),
+					get_d0ix_stat(lss, SS_STATE_D0I3));
+
+			status >>= 2;
+			lss++;
+		}
+	}
+
+	return 0;
+}
+
+static int pmu_sss_state_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, show_pmu_lss_status, NULL);
+}
+
+static const struct file_operations pmu_sss_state_operations = {
+	.open		= pmu_sss_state_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int show_pmu_dev_stats(struct seq_file *s, void *unused)
+{
+	struct pci_dev *pdev = NULL;
+	unsigned long sampled_time, precision;
+	int index, pmu_num, ss_idx, ss_pos;
+	unsigned int base_class;
+
+	seq_printf(s, "%5s\t%20s\t%10s\t%10s\t%s\n",
+		"lss", "Name", "D0_res", "D0ix_res", "Sampled_Time");
+	seq_printf(s,
+	"==================================================================\n");
+
+	for_each_pci_dev(pdev) {
+		/* find the base class info */
+		base_class = pdev->class >> 16;
+
+		if (base_class == PCI_BASE_CLASS_BRIDGE)
+			continue;
+
+		if (pmu_pci_to_indexes(pdev, &index, &pmu_num, &ss_idx,
+							&ss_pos))
+			continue;
+
+		if (pmu_num == PMU_NUM_1) {
+			seq_printf(s,
+			"%5s%20s\t%5lu.%03lu%%\t%5lu.%03lu%%\t%lu\n",
+			"NC", dev_driver_string(&pdev->dev),
+			pmu_dev_res_print(index, &precision,
+				 &sampled_time, false),
+			precision,
+			pmu_dev_res_print(index, &precision,
+				 &sampled_time, true),
+			precision, sampled_time);
+			continue;
+		}
+
+		/* Print for South Complex devices */
+		seq_printf(s, "%5d\t%20s\t%5lu.%03lu%%\t%5lu.%03lu%%\t%lu\n",
+		index - mid_pmu_cxt->pmu1_max_devs,
+		dev_driver_string(&pdev->dev),
+		pmu_dev_res_print(index, &precision, &sampled_time, false),
+		precision,
+		pmu_dev_res_print(index, &precision, &sampled_time, true),
+		precision, sampled_time);
+	}
+	return 0;
+}
+
+static int pmu_dev_stat_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, show_pmu_dev_stats, NULL);
+}
+
+static const struct file_operations pmu_dev_stat_operations = {
+	.open		= pmu_dev_stat_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+#ifdef CONFIG_PM_DEBUG
+static int pmu_stats_interval = PMU_LOG_INTERVAL_SECS;
+module_param_named(pmu_stats_interval, pmu_stats_interval,
+				int, S_IRUGO | S_IWUSR | S_IWGRP);
+
+void pmu_s0ix_demotion_stat(int req_state, int grant_state)
+{
+	struct pmu_ss_states cur_pmsss;
+	int i, req_sys_state, offset;
+	unsigned long status, sub_status;
+	unsigned long s0ix_target_sss_mask[4] = {
+				S0IX_TARGET_SSS0_MASK,
+				S0IX_TARGET_SSS1_MASK,
+				S0IX_TARGET_SSS2_MASK,
+				S0IX_TARGET_SSS3_MASK};
+
+	unsigned long s0ix_target_sss[4] = {
+				S0IX_TARGET_SSS0,
+				S0IX_TARGET_SSS1,
+				S0IX_TARGET_SSS2,
+				S0IX_TARGET_SSS3};
+
+	unsigned long lpmp3_target_sss_mask[4] = {
+				LPMP3_TARGET_SSS0_MASK,
+				LPMP3_TARGET_SSS1_MASK,
+				LPMP3_TARGET_SSS2_MASK,
+				LPMP3_TARGET_SSS3_MASK};
+
+	unsigned long lpmp3_target_sss[4] = {
+				LPMP3_TARGET_SSS0,
+				LPMP3_TARGET_SSS1,
+				LPMP3_TARGET_SSS2,
+				LPMP3_TARGET_SSS3};
+
+	req_sys_state = mid_state_to_sys_state(req_state);
+	if ((grant_state >= C4_STATE_IDX) && (grant_state <= S0I3_STATE_IDX))
+		mid_pmu_cxt->pmu_stats
+			[req_sys_state].demote_count
+				[grant_state-C4_STATE_IDX]++;
+
+	if (down_trylock(&mid_pmu_cxt->scu_ready_sem))
+		return;
+
+	pmu_read_sss(&cur_pmsss);
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	if (!mid_pmu_cxt->camera_off)
+		mid_pmu_cxt->pmu_stats[req_sys_state].camera_blocker_count++;
+
+	if (!mid_pmu_cxt->display_off)
+		mid_pmu_cxt->pmu_stats[req_sys_state].display_blocker_count++;
+
+	if (!mid_pmu_cxt->s0ix_possible) {
+		for (i = 0; i < 4; i++) {
+			unsigned int lss_per_register;
+			if (req_state == MID_LPMP3_STATE)
+				status = lpmp3_target_sss[i] ^
+					(cur_pmsss.pmu2_states[i] &
+						lpmp3_target_sss_mask[i]);
+			else
+				status = s0ix_target_sss[i] ^
+					(cur_pmsss.pmu2_states[i] &
+						s0ix_target_sss_mask[i]);
+			if (!status)
+				continue;
+
+			lss_per_register =
+				(sizeof(unsigned long)*8)/BITS_PER_LSS;
+
+			for (offset = 0; offset < lss_per_register; offset++) {
+				sub_status = status & SS_IDX_MASK;
+				if (sub_status) {
+					mid_pmu_cxt->pmu_stats[req_sys_state].
+						blocker_count
+						[offset + lss_per_register*i]++;
+				}
+
+				status >>= BITS_PER_LSS;
+			}
+		}
+	}
+}
+EXPORT_SYMBOL(pmu_s0ix_demotion_stat);
+
+static void pmu_log_s0ix_status(int type, char *typestr,
+		struct seq_file *s, bool logging_type)
+{
+	unsigned long long t;
+	unsigned long time, remainder, init_2_now_time;
+
+	t = mid_pmu_cxt->pmu_stats[type].time;
+	remainder = do_div(t, NANO_SEC);
+
+	/* convert time in secs */
+	time = (unsigned long)t;
+
+	t =  cpu_clock(0);
+	t -= mid_pmu_cxt->pmu_init_time;
+	remainder = do_div(t, NANO_SEC);
+
+	init_2_now_time =  (unsigned long) t;
+
+	/* for calculating percentage residency */
+	t = (u64) time;
+	t *= 100;
+
+	/* take care of divide by zero */
+	if (init_2_now_time) {
+		remainder = do_div(t, init_2_now_time);
+		time = (unsigned long) t;
+
+		/* for getting 3 digit precision after
+		 * decimal dot */
+		t = (u64) remainder;
+		t *= 1000;
+		remainder = do_div(t, init_2_now_time);
+	} else
+		time = t = 0;
+	DEBUG_PRINT(logging_type, s, STATS,
+			"%s\t%5llu\t%9llu\t%9llu\t%5lu.%03lu\n"
+			, typestr, mid_pmu_cxt->pmu_stats[type].count,
+			mid_pmu_cxt->pmu_stats[type].err_count[1],
+			mid_pmu_cxt->pmu_stats[type].err_count[2],
+			time, (unsigned long) t);
+}
+
+static void pmu_log_s0ix_demotion(int type, char *typestr,
+		struct seq_file *s, bool logging_type)
+{
+	DEBUG_PRINT(logging_type, s, STATS, "%s:\t%6d\t%6d\t%6d\t%6d\t%6d\n",
+		typestr,
+		mid_pmu_cxt->pmu_stats[type].demote_count[0],
+		mid_pmu_cxt->pmu_stats[type].demote_count[1],
+		mid_pmu_cxt->pmu_stats[type].demote_count[2],
+		mid_pmu_cxt->pmu_stats[type].demote_count[3],
+		mid_pmu_cxt->pmu_stats[type].demote_count[4]);
+}
+
+static void pmu_log_s0ix_lss_blocked(int type, char *typestr,
+		struct seq_file *s, bool logging_type)
+{
+	int i, block_count;
+
+	DEBUG_PRINT(logging_type, s, STATS, "%s: Block Count\n", typestr);
+
+	block_count = mid_pmu_cxt->pmu_stats[type].display_blocker_count;
+
+	if (block_count)
+		DEBUG_PRINT(logging_type, s, STATS,
+			 "\tDisplay blocked: %d times\n", block_count);
+
+	block_count = mid_pmu_cxt->pmu_stats[type].camera_blocker_count;
+
+	if (block_count)
+		DEBUG_PRINT(logging_type, s, STATS,
+			"\tCamera blocked: %d times\n", block_count);
+
+	DEBUG_PRINT(logging_type, s, STATS, "\tLSS\t #blocked\n");
+
+	for  (i = 0; i < MAX_LSS_POSSIBLE; i++) {
+		block_count = mid_pmu_cxt->pmu_stats[type].blocker_count[i];
+		if (block_count)
+			DEBUG_PRINT(logging_type, s, STATS, "\t%02d\t %6d\n", i,
+						block_count);
+	}
+	DEBUG_PRINT(logging_type, s, STATS, "\n");
+}
+
+static void pmu_stats_logger(bool logging_type, struct seq_file *s)
+{
+
+	if (!logging_type)
+		DEBUG_PRINT(logging_type, s, STATS,
+			"\n----MID_PMU_STATS_LOG_BEGIN----\n");
+
+	DEBUG_PRINT(logging_type, s, STATS,
+			"\tcount\ts0ix_miss\tno_ack_c6\tresidency(%%)\n");
+	pmu_log_s0ix_status(SYS_STATE_S0I1, "s0i1", s, logging_type);
+	pmu_log_s0ix_status(SYS_STATE_S0I2, "lpmp3", s, logging_type);
+	pmu_log_s0ix_status(SYS_STATE_S0I3, "s0i3", s, logging_type);
+	pmu_log_s0ix_status(SYS_STATE_S3, "s3", s, logging_type);
+
+	DEBUG_PRINT(logging_type, s, STATS, "\nFrom:\tTo\n");
+	DEBUG_PRINT(logging_type, s, STATS,
+		"\t    C4\t   C6\t  S0i1\t  Lpmp3\t  S0i3\n");
+
+	/* storing C6 demotion info in S0I0 */
+	pmu_log_s0ix_demotion(SYS_STATE_S0I0, "  C6", s, logging_type);
+
+	pmu_log_s0ix_demotion(SYS_STATE_S0I1, "s0i1", s, logging_type);
+	pmu_log_s0ix_demotion(SYS_STATE_S0I2, "lpmp3", s, logging_type);
+	pmu_log_s0ix_demotion(SYS_STATE_S0I3, "s0i3", s, logging_type);
+
+	DEBUG_PRINT(logging_type, s, STATS, "\n");
+	pmu_log_s0ix_lss_blocked(SYS_STATE_S0I1, "s0i1", s, logging_type);
+	pmu_log_s0ix_lss_blocked(SYS_STATE_S0I2, "lpmp3", s, logging_type);
+	pmu_log_s0ix_lss_blocked(SYS_STATE_S0I3, "s0i3", s, logging_type);
+
+	if (!logging_type)
+		DEBUG_PRINT(logging_type, s, STATS,
+				"\n----MID_PMU_STATS_LOG_END----\n");
+}
+
+static void pmu_log_stat(struct work_struct *work)
+{
+
+	pmu_stats_logger(false, NULL);
+
+	schedule_delayed_work(&mid_pmu_cxt->log_work,
+			msecs_to_jiffies(pmu_stats_interval*1000));
+}
+
+static int show_pmu_stats_log(struct seq_file *s, void *unused)
+{
+	pmu_stats_logger(true, s);
+	return 0;
+}
+
+static int pmu_stats_log_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, show_pmu_stats_log, NULL);
+}
+
+static const struct file_operations pmu_stats_log_operations = {
+	.open		= pmu_stats_log_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+#else
+void pmu_s0ix_demotion_stat(int req_state, int grant_state) {}
+EXPORT_SYMBOL(pmu_s0ix_demotion_stat);
+#endif
+
+void pmu_stats_init(void)
+{
+	struct dentry *fentry;
+
+	/* /sys/kernel/debug/mid_pmu_states */
+	(void) debugfs_create_file("mid_pmu_states", S_IFREG | S_IRUGO,
+				NULL, NULL, &devices_state_operations);
+
+	/* /sys/kernel/debug/pmu_sss_states */
+	(void) debugfs_create_file("pmu_sss_states", S_IFREG | S_IRUGO,
+				NULL, NULL, &pmu_sss_state_operations);
+
+	/* /sys/kernel/debug/pmu_dev_stats */
+	(void) debugfs_create_file("pmu_dev_stats", S_IFREG | S_IRUGO,
+				NULL, NULL, &pmu_dev_stat_operations);
+
+	s0ix_lat_stat_init();
+
+#ifdef CONFIG_PM_DEBUG
+	/* dynamic debug tracing in every 5 mins */
+	INIT_DEFERRABLE_WORK(&mid_pmu_cxt->log_work, pmu_log_stat);
+	schedule_delayed_work(&mid_pmu_cxt->log_work,
+				msecs_to_jiffies(pmu_stats_interval*1000));
+
+	debug_mask = PMU_DEBUG_PRINT_STATS;
+
+	/* /sys/kernel/debug/pmu_stats_log */
+	fentry = debugfs_create_file("pmu_stats_log", S_IFREG | S_IRUGO,
+				NULL, NULL, &pmu_stats_log_operations);
+	if (fentry == NULL)
+		printk(KERN_ERR "Failed to create pmu_stats_log debugfs\n");
+#endif
+}
+
+void pmu_s3_stats_update(int enter)
+{
+
+}
+
+void pmu_stats_finish(void)
+{
+#ifdef CONFIG_PM_DEBUG
+	cancel_delayed_work_sync(&mid_pmu_cxt->log_work);
+#endif
+	s0ix_lat_stat_finish();
+}
+
+#endif /*if CONFIG_X86_MDFLD_POWER || CONFIG_X86_CLV_POWER*/
+
+#ifdef CONFIG_REMOVEME_INTEL_ATOM_MRFLD_POWER
+
+static u32 prev_s0ix_cnt[SYS_STATE_MAX];
+static unsigned long long prev_s0ix_res[SYS_STATE_MAX];
+static unsigned long long cur_s0ix_res[SYS_STATE_MAX];
+static unsigned long long cur_s0ix_cnt[SYS_STATE_MAX];
+static u32 S3_count;
+static unsigned long long S3_res;
+
+static void pmu_stat_seq_printf(struct seq_file *s, int type, char *typestr,
+							long long uptime)
+{
+	unsigned long long t;
+	u32 scu_val = 0, time = 0;
+	u32 remainder;
+	unsigned long init_2_now_time;
+	unsigned long long tsc_freq = 1330000;
+
+	/* If tsc calibration fails use the default as 1330Mhz */
+	if (tsc_khz)
+		tsc_freq = tsc_khz;
+
+	/* Print S0ix residency counter */
+	if (type == SYS_STATE_S0I0) {
+		for (t = SYS_STATE_S0I1; t <= SYS_STATE_S3; t++)
+			time += cur_s0ix_res[t];
+	} else if (type < SYS_STATE_S3) {
+		t = readq(residency[type]);
+		if (t < prev_s0ix_res[type])
+			t += (((unsigned long long)~0) - prev_s0ix_res[type]);
+		else
+			t -= prev_s0ix_res[type];
+
+		if (type == SYS_STATE_S0I3)
+			t -= prev_s0ix_res[SYS_STATE_S3];
+	} else
+		t = prev_s0ix_res[SYS_STATE_S3];
+
+	if (type == SYS_STATE_S0I0) {
+		/* uptime(nanoS) - sum_res(miliSec) */
+		t = uptime;
+		do_div(t, MICRO_SEC);
+		time = t - time;
+	} else {
+		/* s0ix residency counters are in TSC cycle count domain
+		 * convert this to milli second time domain
+		 */
+		remainder = do_div(t, tsc_freq);
+
+		/* store time in millisecs */
+		time = (unsigned int)t;
+	}
+	cur_s0ix_res[type] = (unsigned int)time;
+
+	seq_printf(s, "%s\t%5lu.%03lu\t", typestr,
+		(unsigned long)(time/1000), (unsigned long)(time%1000));
+
+	t = uptime;
+	do_div(t, MICRO_SEC); /* time in milli secs */
+
+	/* Note: with millisecs accuracy we get more
+	 * precise residency percentages, but we have
+	 * to trade off with the max number of days
+	 * that we can run without clearing counters,
+	 * with 32bit counter this value is ~50days.
+	 */
+	init_2_now_time =  (unsigned long) t;
+
+	/* for calculating percentage residency */
+	t	= (u64)(time);
+	t	*= 100;
+
+	/* take care of divide by zero */
+	if (init_2_now_time) {
+		remainder = do_div(t, init_2_now_time);
+		time = (unsigned long) t;
+
+		/* for getting 3 digit precision after
+		 * decimal dot */
+		t = (u64) remainder;
+		t *= 1000;
+		remainder = do_div(t, init_2_now_time);
+	} else
+		time = t = 0;
+
+	seq_printf(s, "%5lu.%03lu\t", (unsigned long) time, (unsigned long) t);
+
+	/* Print S0ix counters */
+	if (type == SYS_STATE_S0I0) {
+		for (t = SYS_STATE_S0I1; t <= SYS_STATE_S3; t++)
+			scu_val += cur_s0ix_cnt[t];
+		if (scu_val == 0) /* S0I0 residency 100% */
+			scu_val = 1;
+	} else if (type < SYS_STATE_S3) {
+		scu_val = readl(s0ix_counter[type]);
+		if (scu_val < prev_s0ix_cnt[type])
+			scu_val += (((u32)~0) - prev_s0ix_cnt[type]);
+		else
+			scu_val -= prev_s0ix_cnt[type];
+
+		if (type == SYS_STATE_S0I3)
+			scu_val -= prev_s0ix_cnt[SYS_STATE_S3];
+	} else
+			scu_val = prev_s0ix_cnt[SYS_STATE_S3];
+
+	if (type != SYS_STATE_S0I0)
+		cur_s0ix_cnt[type] = scu_val;
+
+	seq_printf(s, "%5lu\t", (unsigned long) scu_val);
+
+	remainder = 0;
+	t = cur_s0ix_res[type];
+	if (scu_val) { /* s0ix_time in millisecs */
+		do_div(t, scu_val);
+		remainder = do_div(t, 1000);
+	}
+	seq_printf(s, "%5lu.%03lu\n", (unsigned long) t,
+			(unsigned long) remainder);
+}
+
+static int pmu_devices_state_show(struct seq_file *s, void *unused)
+{
+	struct pci_dev *pdev = NULL;
+	int index, i, pmu_num, ss_idx, ss_pos;
+	unsigned int base_class;
+	u32 mask, val, nc_pwr_sts;
+	struct pmu_ss_states cur_pmsss;
+	long long uptime;
+	int ret;
+
+	if (!pmu_initialized)
+		return 0;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	_pmu2_wait_not_busy();
+	pmu_read_sss(&cur_pmsss);
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	seq_printf(s, "SSS: ");
+
+	for (i = 0; i < 4; i++)
+		seq_printf(s, "%08lX ", cur_pmsss.pmu2_states[i]);
+
+	seq_printf(s, "cmd_error_int count: %d\n", mid_pmu_cxt->cmd_error_int);
+
+	seq_printf(s, "\ttime(secs)\tresidency(%%)\tcount\tAvg.Res(Sec)\n");
+
+	down(&mid_pmu_cxt->scu_ready_sem);
+	/* Dump S0ix residency counters */
+	ret = intel_scu_ipc_simple_command(DUMP_RES_COUNTER, 0);
+	if (ret)
+		seq_printf(s, "IPC command to DUMP S0ix residency failed\n");
+
+	/* Dump number of interations of S0ix */
+	ret = intel_scu_ipc_simple_command(DUMP_S0IX_COUNT, 0);
+	if (ret)
+		seq_printf(s, "IPC command to DUMP S0ix count failed\n");
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	uptime =  cpu_clock(0);
+	uptime -= mid_pmu_cxt->pmu_init_time;
+	pmu_stat_seq_printf(s, SYS_STATE_S0I1, "s0i1", uptime);
+	pmu_stat_seq_printf(s, SYS_STATE_LPMP3, "lpmp3", uptime);
+	pmu_stat_seq_printf(s, SYS_STATE_S0I2, "s0i2", uptime);
+	pmu_stat_seq_printf(s, SYS_STATE_S0I3, "s0i3", uptime);
+	pmu_stat_seq_printf(s, SYS_STATE_S3, "s3", uptime);
+	pmu_stat_seq_printf(s, SYS_STATE_S0I0, "s0", uptime);
+
+	val = do_div(uptime, NANO_SEC);
+	seq_printf(s, "\n\nTotal time: %5lu.%03lu Sec\n", (unsigned long)uptime,
+		   (unsigned long) val/1000000);
+
+	seq_printf(s, "\nNORTH COMPLEX DEVICES :\n\n");
+
+	nc_pwr_sts = intel_mid_msgbus_read32(PUNIT_PORT, NC_PM_SSS);
+	for (i = 0; i < mrfl_no_of_nc_devices; i++) {
+		val = nc_pwr_sts & 3;
+		nc_pwr_sts >>= BITS_PER_LSS;
+		seq_printf(s, "%9s : %s\n", mrfl_nc_devices[i], dstates[val]);
+	}
+
+	seq_printf(s, "\nSOUTH COMPLEX DEVICES :\n\n");
+
+	for_each_pci_dev(pdev) {
+		/* find the base class info */
+		base_class = pdev->class >> 16;
+
+		if (base_class == PCI_BASE_CLASS_BRIDGE)
+			continue;
+
+		if (pmu_pci_to_indexes(pdev, &index, &pmu_num, &ss_idx,
+								  &ss_pos))
+			continue;
+
+		if (pmu_num == PMU_NUM_1)
+			continue;
+
+		mask	= (D0I3_MASK << (ss_pos * BITS_PER_LSS));
+		val	= (cur_pmsss.pmu2_states[ss_idx] & mask) >>
+						(ss_pos * BITS_PER_LSS);
+
+		seq_printf(s, "pci %04x %04X %s %20.20s: lss:%02d reg:%d ",
+			pdev->vendor, pdev->device, dev_name(&pdev->dev),
+			dev_driver_string(&pdev->dev),
+			index - mid_pmu_cxt->pmu1_max_devs, ss_idx);
+		seq_printf(s, "mask:%08X  %s\n",  mask, dstates[val & 3]);
+	}
+
+	return 0;
+}
+
+static int devices_state_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, pmu_devices_state_show, NULL);
+}
+
+static ssize_t devices_state_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int ret;
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+	buf[buf_size] = 0;
+
+	if (((strlen("clear")+1) == buf_size) &&
+		!strncmp(buf, "clear", strlen("clear"))) {
+		down(&mid_pmu_cxt->scu_ready_sem);
+
+		/* Dump S0ix residency counters */
+		ret = intel_scu_ipc_simple_command(DUMP_RES_COUNTER, 0);
+		if (ret)
+			printk(KERN_ERR "IPC command to DUMP S0ix residency failed\n");
+
+		/* Dump number of interations of S0ix */
+		ret = intel_scu_ipc_simple_command(DUMP_S0IX_COUNT, 0);
+		if (ret)
+			printk(KERN_ERR "IPC command to DUMP S0ix count failed\n");
+		up(&mid_pmu_cxt->scu_ready_sem);
+
+		mid_pmu_cxt->pmu_init_time = cpu_clock(0);
+		prev_s0ix_cnt[SYS_STATE_S0I1] = readl(s0ix_counter[SYS_STATE_S0I1]);
+		prev_s0ix_cnt[SYS_STATE_LPMP3] = readl(s0ix_counter[SYS_STATE_LPMP3]);
+		prev_s0ix_cnt[SYS_STATE_S0I2] = readl(s0ix_counter[SYS_STATE_S0I2]);
+		prev_s0ix_cnt[SYS_STATE_S0I3] = readl(s0ix_counter[SYS_STATE_S0I3]);
+		prev_s0ix_cnt[SYS_STATE_S3] = 0;
+		prev_s0ix_res[SYS_STATE_S0I1] = readq(residency[SYS_STATE_S0I1]);
+		prev_s0ix_res[SYS_STATE_LPMP3] = readq(residency[SYS_STATE_LPMP3]);
+		prev_s0ix_res[SYS_STATE_S0I2] = readq(residency[SYS_STATE_S0I2]);
+		prev_s0ix_res[SYS_STATE_S0I3] = readq(residency[SYS_STATE_S0I3]);
+		prev_s0ix_res[SYS_STATE_S3] = 0 ;
+	}
+	return buf_size;
+}
+
+
+static const struct file_operations devices_state_operations = {
+	.open		= devices_state_open,
+	.read		= seq_read,
+	.write		= devices_state_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+#ifdef CONFIG_PM_DEBUG
+static int ignore_lss_show(struct seq_file *s, void *unused)
+{
+	u32 local_ignore_lss[4];
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	memcpy(local_ignore_lss, mid_pmu_cxt->ignore_lss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	seq_printf(s, "IGNORE_LSS[0]: %08X\n", local_ignore_lss[0]);
+	seq_printf(s, "IGNORE_LSS[1]: %08X\n", local_ignore_lss[1]);
+	seq_printf(s, "IGNORE_LSS[2]: %08X\n", local_ignore_lss[2]);
+	seq_printf(s, "IGNORE_LSS[3]: %08X\n", local_ignore_lss[3]);
+
+	return 0;
+}
+
+static int ignore_add_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, ignore_lss_show, NULL);
+}
+
+static ssize_t ignore_add_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int buf_size = min(count, sizeof(buf)-1);
+	int sub_sys_pos, sub_sys_index;
+	u32 lss, local_ignore_lss[4];
+	u32 pm_cmd_val;
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &lss);
+
+	if (res)
+		return -EINVAL;
+
+	if (lss > MAX_LSS_POSSIBLE)
+		return -EINVAL;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	memcpy(local_ignore_lss, mid_pmu_cxt->ignore_lss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	/* If set to MAX_LSS_POSSIBLE it means
+	 * ignore all.
+	 */
+	if (lss == MAX_LSS_POSSIBLE) {
+		local_ignore_lss[0] = 0xFFFFFFFF;
+		local_ignore_lss[1] = 0xFFFFFFFF;
+		local_ignore_lss[2] = 0xFFFFFFFF;
+		local_ignore_lss[3] = 0xFFFFFFFF;
+	} else {
+		sub_sys_index	= lss / mid_pmu_cxt->ss_per_reg;
+		sub_sys_pos	= lss % mid_pmu_cxt->ss_per_reg;
+
+		pm_cmd_val =
+			(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+		local_ignore_lss[sub_sys_index] |= pm_cmd_val;
+	}
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	memcpy(mid_pmu_cxt->ignore_lss, local_ignore_lss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return buf_size;
+}
+
+static const struct file_operations ignore_add_ops = {
+	.open		= ignore_add_open,
+	.read		= seq_read,
+	.write		= ignore_add_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int ignore_remove_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, ignore_lss_show, NULL);
+}
+
+static ssize_t ignore_remove_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int buf_size = min(count, sizeof(buf)-1);
+	int sub_sys_pos, sub_sys_index;
+	u32 lss, local_ignore_lss[4];
+	u32 pm_cmd_val;
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &lss);
+
+	if (res)
+		return -EINVAL;
+
+	if (lss > MAX_LSS_POSSIBLE)
+		return -EINVAL;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	memcpy(local_ignore_lss, mid_pmu_cxt->ignore_lss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	/* If set to MAX_LSS_POSSIBLE it means
+	 * remove all from ignore list.
+	 */
+	if (lss == MAX_LSS_POSSIBLE) {
+		local_ignore_lss[0] = 0;
+		local_ignore_lss[1] = 0;
+		local_ignore_lss[2] = 0;
+		local_ignore_lss[3] = 0;
+	} else {
+		sub_sys_index	= lss / mid_pmu_cxt->ss_per_reg;
+		sub_sys_pos	= lss % mid_pmu_cxt->ss_per_reg;
+
+		pm_cmd_val =
+			(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+		local_ignore_lss[sub_sys_index] &= ~pm_cmd_val;
+	}
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	memcpy(mid_pmu_cxt->ignore_lss, local_ignore_lss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return buf_size;
+}
+
+static const struct file_operations ignore_remove_ops = {
+	.open		= ignore_remove_open,
+	.read		= seq_read,
+	.write		= ignore_remove_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int pmu_sync_d0ix_show(struct seq_file *s, void *unused)
+{
+	int i;
+	u32 local_os_sss[4];
+	struct pmu_ss_states cur_pmsss;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	_pmu2_wait_not_busy();
+	/* Read SCU SSS */
+	pmu_read_sss(&cur_pmsss);
+	/* Read OS SSS */
+	memcpy(local_os_sss, mid_pmu_cxt->os_sss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	for (i = 0; i < 4; i++)
+		seq_printf(s, "OS_SSS[%d]: %08X\tSSS[%d]: %08lX\n", i,
+				local_os_sss[i], i, cur_pmsss.pmu2_states[i]);
+
+	return 0;
+}
+
+static int pmu_sync_d0ix_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, pmu_sync_d0ix_show, NULL);
+}
+
+static ssize_t pmu_sync_d0ix_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res, i;
+	bool send_cmd;
+	int buf_size = min(count, sizeof(buf)-1);
+	u32 lss, local_os_sss[4];
+	int sub_sys_pos, sub_sys_index;
+	u32 pm_cmd_val;
+	u32 temp_sss;
+
+	struct pmu_ss_states cur_pmsss;
+
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &lss);
+
+	if (res)
+		return -EINVAL;
+
+	if (lss > MAX_LSS_POSSIBLE)
+		return -EINVAL;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	_pmu2_wait_not_busy();
+	/* Read SCU SSS */
+	pmu_read_sss(&cur_pmsss);
+
+	for (i = 0; i < 4; i++)
+		local_os_sss[i] = mid_pmu_cxt->os_sss[i] &
+				~mid_pmu_cxt->ignore_lss[i];
+
+	send_cmd = false;
+	for (i = 0; i < 4; i++) {
+		if (local_os_sss[i] != cur_pmsss.pmu2_states[i]) {
+			send_cmd = true;
+			break;
+		}
+	}
+
+	if (send_cmd) {
+		int status;
+
+		if (lss == MAX_LSS_POSSIBLE) {
+			memcpy(cur_pmsss.pmu2_states, local_os_sss,
+							 (sizeof(u32)*4));
+		} else {
+			bool same;
+			sub_sys_index	= lss / mid_pmu_cxt->ss_per_reg;
+			sub_sys_pos	= lss % mid_pmu_cxt->ss_per_reg;
+			pm_cmd_val =
+				(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+
+			/* dont send d0ix request if its same */
+			same =
+			((cur_pmsss.pmu2_states[sub_sys_index] & pm_cmd_val)
+			== (mid_pmu_cxt->os_sss[sub_sys_index] & pm_cmd_val));
+
+			if (same)
+				goto unlock;
+
+			cur_pmsss.pmu2_states[sub_sys_index] &= ~pm_cmd_val;
+			temp_sss =
+				mid_pmu_cxt->os_sss[sub_sys_index] & pm_cmd_val;
+			cur_pmsss.pmu2_states[sub_sys_index] |= temp_sss;
+		}
+
+		/* Issue the pmu command to PMU 2
+		 * flag is needed to distinguish between
+		 * S0ix vs interactive command in pmu_sc_irq()
+		 */
+		status = pmu_issue_interactive_command(&cur_pmsss, false,
+							false);
+
+		if (unlikely(status != PMU_SUCCESS)) {
+			dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+				 "Failed to Issue a PM command to PMU2\n");
+			goto unlock;
+		}
+
+		/*
+		 * Wait for interactive command to complete.
+		 * If we dont wait, there is a possibility that
+		 * the driver may access the device before its
+		 * powered on in SCU.
+		 *
+		 */
+		status = _pmu2_wait_not_busy();
+		if (unlikely(status)) {
+			printk(KERN_CRIT "%s: D0ix transition failure\n",
+				__func__);
+		}
+	}
+
+unlock:
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return buf_size;
+}
+
+static const struct file_operations pmu_sync_d0ix_ops = {
+	.open		= pmu_sync_d0ix_open,
+	.read		= seq_read,
+	.write		= pmu_sync_d0ix_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int pmu_force_d0ix_show(struct seq_file *s, void *unused)
+{
+	int i;
+	u32 local_os_sss[4];
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	/* Read OS SSS */
+	memcpy(local_os_sss, mid_pmu_cxt->os_sss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	for (i = 0; i < 4; i++)
+		seq_printf(s, "OS_SSS[%d]: %08X\n", i, local_os_sss[i]);
+
+	return 0;
+}
+
+static int pmu_force_d0ix_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, pmu_force_d0ix_show, NULL);
+}
+
+static ssize_t pmu_force_d0i3_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int buf_size = min(count, sizeof(buf)-1);
+	u32 lss, local_os_sss[4];
+	int sub_sys_pos, sub_sys_index;
+	u32 pm_cmd_val;
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &lss);
+
+	if (res)
+		return -EINVAL;
+
+	if (lss > MAX_LSS_POSSIBLE)
+		return -EINVAL;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	if (lss == MAX_LSS_POSSIBLE) {
+		local_os_sss[0] =
+		local_os_sss[1] =
+		local_os_sss[2] =
+		local_os_sss[3] = 0xFFFFFFFF;
+	} else {
+		memcpy(local_os_sss, mid_pmu_cxt->os_sss, (sizeof(u32)*4));
+		sub_sys_index	= lss / mid_pmu_cxt->ss_per_reg;
+		sub_sys_pos	= lss % mid_pmu_cxt->ss_per_reg;
+		pm_cmd_val =
+			(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+
+		local_os_sss[sub_sys_index] |= pm_cmd_val;
+	}
+
+	memcpy(mid_pmu_cxt->os_sss, local_os_sss, (sizeof(u32)*4));
+
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return buf_size;
+}
+
+static const struct file_operations pmu_force_d0i3_ops = {
+	.open		= pmu_force_d0ix_open,
+	.read		= seq_read,
+	.write		= pmu_force_d0i3_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static ssize_t pmu_force_d0i0_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int buf_size = min(count, sizeof(buf)-1);
+	u32 lss, local_os_sss[4];
+	int sub_sys_pos, sub_sys_index;
+	u32 pm_cmd_val;
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &lss);
+
+	if (res)
+		return -EINVAL;
+
+	if (lss > MAX_LSS_POSSIBLE)
+		return -EINVAL;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	if (lss == MAX_LSS_POSSIBLE) {
+		local_os_sss[0] =
+		local_os_sss[1] =
+		local_os_sss[2] =
+		local_os_sss[3] = 0;
+	} else {
+		memcpy(local_os_sss, mid_pmu_cxt->os_sss, (sizeof(u32)*4));
+		sub_sys_index	= lss / mid_pmu_cxt->ss_per_reg;
+		sub_sys_pos	= lss % mid_pmu_cxt->ss_per_reg;
+		pm_cmd_val =
+			(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+
+		local_os_sss[sub_sys_index] &= ~pm_cmd_val;
+	}
+
+	memcpy(mid_pmu_cxt->os_sss, local_os_sss, (sizeof(u32)*4));
+
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return buf_size;
+}
+
+static const struct file_operations pmu_force_d0i0_ops = {
+	.open		= pmu_force_d0ix_open,
+	.read		= seq_read,
+	.write		= pmu_force_d0i0_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int cstate_ignore_add_show(struct seq_file *s, void *unused)
+{
+	int i;
+	seq_printf(s, "CSTATES IGNORED: ");
+	for (i = 0; i < CPUIDLE_STATE_MAX; i++)
+		if ((mid_pmu_cxt->cstate_ignore & (1 << i)))
+			seq_printf(s, "%d, ", i+1);
+
+	seq_printf(s, "\n");
+	return 0;
+}
+
+static int cstate_ignore_add_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, cstate_ignore_add_show, NULL);
+}
+
+static ssize_t cstate_ignore_add_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int cstate;
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &cstate);
+
+	if (res)
+		return -EINVAL;
+
+	if (cstate > MAX_CSTATES_POSSIBLE)
+		return -EINVAL;
+
+	/* cannot add/remove C0, C1 */
+	if (((cstate == 0) || (cstate == 1))) {
+		printk(KERN_CRIT "C0 C1 state cannot be used.\n");
+		return -EINVAL;
+	}
+
+	if (!mid_pmu_cxt->cstate_qos)
+		return -EINVAL;
+
+	if (cstate == MAX_CSTATES_POSSIBLE) {
+		mid_pmu_cxt->cstate_ignore = ((1 << CPUIDLE_STATE_MAX) - 1);
+		pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+					CSTATE_EXIT_LATENCY_C1 - 1);
+	} else {
+		u32 cstate_exit_latency[CPUIDLE_STATE_MAX+1];
+		u32 local_cstate_allowed;
+		int max_cstate_allowed;
+
+		/* 0 is C1 state */
+		cstate--;
+		mid_pmu_cxt->cstate_ignore |= (1 << cstate);
+
+		/* by default remove C1 from ignore list */
+		mid_pmu_cxt->cstate_ignore &= ~(1 << 0);
+
+		/* populate cstate latency table */
+		cstate_exit_latency[0] = CSTATE_EXIT_LATENCY_C1;
+		cstate_exit_latency[1] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[2] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[3] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[4] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[5] = CSTATE_EXIT_LATENCY_C6;
+		cstate_exit_latency[6] = CSTATE_EXIT_LATENCY_S0i1;
+		cstate_exit_latency[7] = CSTATE_EXIT_LATENCY_S0i2;
+		cstate_exit_latency[8] = CSTATE_EXIT_LATENCY_S0i3;
+		cstate_exit_latency[9] = PM_QOS_DEFAULT_VALUE;
+		cstate_exit_latency[10] = PM_QOS_DEFAULT_VALUE;
+
+		local_cstate_allowed = ~mid_pmu_cxt->cstate_ignore;
+
+		/* restrict to max c-states */
+		local_cstate_allowed &= ((1<<CPUIDLE_STATE_MAX)-1);
+
+		/* If no states allowed will return 0 */
+		max_cstate_allowed = fls(local_cstate_allowed);
+
+		printk(KERN_CRIT "max_cstate: %d local_cstate_allowed = %x\n",
+			max_cstate_allowed, local_cstate_allowed);
+		printk(KERN_CRIT "exit latency = %d\n",
+				(cstate_exit_latency[max_cstate_allowed]-1));
+		pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+				(cstate_exit_latency[max_cstate_allowed]-1));
+	}
+
+	return buf_size;
+}
+
+static const struct file_operations cstate_ignore_add_ops = {
+	.open		= cstate_ignore_add_open,
+	.read		= seq_read,
+	.write		= cstate_ignore_add_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int cstate_ignore_remove_show(struct seq_file *s, void *unused)
+{
+	int i;
+	seq_printf(s, "CSTATES ALLOWED: ");
+	for (i = 0; i < CPUIDLE_STATE_MAX; i++)
+		if (!(mid_pmu_cxt->cstate_ignore & (1 << i)))
+			seq_printf(s, "%d, ", i+1);
+
+	seq_printf(s, "\n");
+
+	return 0;
+}
+
+static int cstate_ignore_remove_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, cstate_ignore_remove_show, NULL);
+}
+
+static ssize_t cstate_ignore_remove_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int cstate;
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &cstate);
+
+	if (res)
+		return -EINVAL;
+
+	if (cstate > MAX_CSTATES_POSSIBLE)
+		return -EINVAL;
+
+	/* cannot add/remove C0, C1 */
+	if (((cstate == 0) || (cstate == 1))) {
+		printk(KERN_CRIT "C0 C1 state cannot be used.\n");
+		return -EINVAL;
+	}
+
+	if (!mid_pmu_cxt->cstate_qos)
+		return -EINVAL;
+
+	if (cstate == MAX_CSTATES_POSSIBLE) {
+		mid_pmu_cxt->cstate_ignore =
+				~((1 << CPUIDLE_STATE_MAX) - 1);
+		/* Ignore C2, C3, C5, C8 and C10 states */
+		mid_pmu_cxt->cstate_ignore |= (1 << 1);
+		mid_pmu_cxt->cstate_ignore |= (1 << 2);
+		mid_pmu_cxt->cstate_ignore |= (1 << 4);
+		mid_pmu_cxt->cstate_ignore |= (1 << 7);
+		mid_pmu_cxt->cstate_ignore |= (1 << 9);
+
+		pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+						PM_QOS_DEFAULT_VALUE);
+	} else {
+		u32 cstate_exit_latency[CPUIDLE_STATE_MAX+1];
+		u32 local_cstate_allowed;
+		int max_cstate_allowed;
+
+		/* populate cstate latency table */
+		cstate_exit_latency[0] = CSTATE_EXIT_LATENCY_C1;
+		cstate_exit_latency[1] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[2] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[3] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[4] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[5] = CSTATE_EXIT_LATENCY_C6;
+		cstate_exit_latency[6] = CSTATE_EXIT_LATENCY_S0i1;
+		cstate_exit_latency[7] = CSTATE_EXIT_LATENCY_S0i2;
+		cstate_exit_latency[8] = CSTATE_EXIT_LATENCY_S0i3;
+		cstate_exit_latency[9] = PM_QOS_DEFAULT_VALUE;
+		cstate_exit_latency[10] = PM_QOS_DEFAULT_VALUE;
+
+		/* 0 is C1 state */
+		cstate--;
+		mid_pmu_cxt->cstate_ignore &= ~(1 << cstate);
+
+		/* by default remove C1 from ignore list */
+		mid_pmu_cxt->cstate_ignore &= ~(1 << 0);
+
+		/* Ignore C2, C3, C5, C8 and C10 states */
+		mid_pmu_cxt->cstate_ignore |= (1 << 1);
+		mid_pmu_cxt->cstate_ignore |= (1 << 2);
+		mid_pmu_cxt->cstate_ignore |= (1 << 4);
+		mid_pmu_cxt->cstate_ignore |= (1 << 7);
+		mid_pmu_cxt->cstate_ignore |= (1 << 9);
+
+		local_cstate_allowed = ~mid_pmu_cxt->cstate_ignore;
+		/* restrict to max c-states */
+		local_cstate_allowed &= ((1<<CPUIDLE_STATE_MAX)-1);
+
+		/* If no states allowed will return 0 */
+		max_cstate_allowed = fls(local_cstate_allowed);
+		printk(KERN_CRIT "max_cstate: %d local_cstate_allowed = %x\n",
+			max_cstate_allowed, local_cstate_allowed);
+		printk(KERN_CRIT "exit latency = %d\n",
+				(cstate_exit_latency[max_cstate_allowed]-1));
+		pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+				(cstate_exit_latency[max_cstate_allowed]-1));
+	}
+
+	return buf_size;
+}
+
+static const struct file_operations cstate_ignore_remove_ops = {
+	.open		= cstate_ignore_remove_open,
+	.read		= seq_read,
+	.write		= cstate_ignore_remove_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int s3_ctrl_show(struct seq_file *s, void *unused)
+{
+	seq_printf(s, "%d\n", enable_s3);
+	return 0;
+}
+
+static int s3_ctrl_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, s3_ctrl_show, NULL);
+}
+
+static ssize_t s3_ctrl_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int local_s3_ctrl;
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &local_s3_ctrl);
+
+	if (res)
+		return -EINVAL;
+
+	enable_s3 = local_s3_ctrl ? 1 : 0;
+
+	if (enable_s3)
+		__pm_relax(mid_pmu_cxt->pmu_wake_lock);
+	else
+		__pm_stay_awake(mid_pmu_cxt->pmu_wake_lock);
+
+	return buf_size;
+}
+
+static const struct file_operations s3_ctrl_ops = {
+	.open		= s3_ctrl_open,
+	.read		= seq_read,
+	.write		= s3_ctrl_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+
+unsigned int pmu_get_new_cstate(unsigned int cstate, int *index)
+{
+	static int cstate_index_table[CPUIDLE_STATE_MAX] = {
+					1, 1, 1, 1, 1, 2, 3, 3, 4, 4};
+	unsigned int new_cstate = cstate;
+	u32 local_cstate = (u32)(cstate);
+	u32 local_cstate_allowed = ~mid_pmu_cxt->cstate_ignore;
+	u32 cstate_mask, cstate_no_s0ix_mask = (u32)((1 << 6) - 1);
+
+	if (platform_is(INTEL_ATOM_MRFLD)) {
+		/* cstate is also 7 for C9 so correct */
+		if ((local_cstate == 7) && (*index == 4))
+			local_cstate = 9;
+
+		/* get next low cstate allowed */
+		cstate_mask = (u32)((1 << local_cstate)-1);
+		/* in case if cstate == 0 which should not be the case*/
+		cstate_mask |= 1;
+		local_cstate_allowed	&= ((1<<CPUIDLE_STATE_MAX)-1);
+		local_cstate_allowed	&= cstate_mask;
+		if (!could_do_s0ix())
+			local_cstate_allowed &= cstate_no_s0ix_mask;
+		new_cstate	= fls(local_cstate_allowed);
+
+		*index	= cstate_index_table[new_cstate-1];
+	}
+
+	return new_cstate;
+}
+#endif
+
+DEFINE_PER_CPU(u64[NUM_CSTATES_RES_MEASURE], c_states_res);
+
+static int read_c_states_res(void)
+{
+	int cpu, i;
+	u32 lo, hi;
+
+	u32 c_states_res_msr[NUM_CSTATES_RES_MEASURE] = {
+		PUNIT_CR_CORE_C1_RES_MSR,
+		PUNIT_CR_CORE_C4_RES_MSR,
+		PUNIT_CR_CORE_C6_RES_MSR
+	};
+
+	for_each_online_cpu(cpu)
+		for (i = 0; i < NUM_CSTATES_RES_MEASURE; i++) {
+			u64 temp;
+			rdmsr_on_cpu(cpu, c_states_res_msr[i], &lo, &hi);
+			temp = hi;
+			temp <<= 32;
+			temp |= lo;
+			per_cpu(c_states_res, cpu)[i] = temp;
+		}
+
+	return 0;
+}
+
+static int c_states_stat_show(struct seq_file *s, void *unused)
+{
+	char *c_states_name[] = {
+		"C1",
+		"C4",
+		"C6"
+	};
+
+	int i, cpu;
+
+	seq_printf(s, "C STATES: %20s\n", "Residecy");
+	for_each_online_cpu(cpu)
+		seq_printf(s, "%18s %d", "Core", cpu);
+	seq_printf(s, "\n");
+
+	read_c_states_res();
+	for (i = 0; i < NUM_CSTATES_RES_MEASURE; i++) {
+		seq_printf(s, "%s", c_states_name[i]);
+		for_each_online_cpu(cpu)
+			seq_printf(s, "%18llu", per_cpu(c_states_res, cpu)[i]);
+		seq_printf(s, "\n");
+	}
+	return 0;
+}
+
+static int c_states_stat_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, c_states_stat_show, NULL);
+}
+
+static const struct file_operations c_states_stat_ops = {
+	.open		= c_states_stat_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+/*These are place holders and will be enabled in next patch*/
+
+void pmu_log_pmu_irq(int status) { return; };
+void pmu_log_ipc_irq(void) { return; };
+void pmu_log_ipc(u32 command) { return; };
+void pmu_log_command(u32 command, struct pmu_ss_states *pm_ssc) { return; };
+void pmu_dump_logs(void) { return; };
+void pmu_stat_start(enum sys_state type) { return; };
+void pmu_stat_end(void) { return; };
+void pmu_stat_error(u8 err_type) { return; };
+void pmu_s0ix_demotion_stat(int req_state, int grant_state) { return; };
+EXPORT_SYMBOL(pmu_s0ix_demotion_stat);
+
+void pmu_stats_finish(void)
+{
+#ifdef CONFIG_PM_DEBUG
+	if (mid_pmu_cxt->cstate_qos) {
+		pm_qos_remove_request(mid_pmu_cxt->cstate_qos);
+		kfree(mid_pmu_cxt->cstate_qos);
+		mid_pmu_cxt->cstate_qos = NULL;
+	}
+#endif
+
+	return;
+}
+
+void pmu_s3_stats_update(int enter)
+{
+#ifdef CONFIG_PM_DEBUG
+	int ret;
+
+	down(&mid_pmu_cxt->scu_ready_sem);
+	/* Dump S0ix residency counters */
+	ret = intel_scu_ipc_simple_command(DUMP_RES_COUNTER, 0);
+	if (ret)
+		printk(KERN_ERR "IPC command to DUMP S0ix residency failed\n");
+
+	/* Dump number of interations of S0ix */
+	ret = intel_scu_ipc_simple_command(DUMP_S0IX_COUNT, 0);
+	if (ret)
+		printk(KERN_ERR "IPC command to DUMP S0ix count failed\n");
+
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	if (enter == 1) {
+		S3_count  = readl(s0ix_counter[SYS_STATE_S0I3]);
+		S3_res = readq(residency[SYS_STATE_S0I3]);
+	} else {
+		prev_s0ix_cnt[SYS_STATE_S3] +=
+			(readl(s0ix_counter[SYS_STATE_S0I3])) - S3_count;
+		prev_s0ix_res[SYS_STATE_S3] += (readq(residency[SYS_STATE_S0I3])) - S3_res;
+	}
+
+#endif
+	return;
+}
+
+
+void pmu_stats_init(void)
+{
+	/* /sys/kernel/debug/mid_pmu_states */
+	(void) debugfs_create_file("mid_pmu_states", S_IFREG | S_IRUGO,
+				NULL, NULL, &devices_state_operations);
+
+	/* /sys/kernel/debug/c_p_states_stat */
+	(void) debugfs_create_file("c_states_stat", S_IFREG | S_IRUGO,
+				NULL, NULL, &c_states_stat_ops);
+#ifdef CONFIG_PM_DEBUG
+	if (platform_is(INTEL_ATOM_MRFLD)) {
+		/* If s0ix is disabled then restrict to C6 */
+		if (!enable_s0ix) {
+			mid_pmu_cxt->cstate_ignore =
+				~((1 << CPUIDLE_STATE_MAX) - 1);
+
+			/* Ignore C2, C3, C5 states */
+			mid_pmu_cxt->cstate_ignore |= (1 << 1);
+			mid_pmu_cxt->cstate_ignore |= (1 << 2);
+			mid_pmu_cxt->cstate_ignore |= (1 << 4);
+
+			/* For now ignore C7, C8, C9, C10 states */
+			mid_pmu_cxt->cstate_ignore |= (1 << 6);
+			mid_pmu_cxt->cstate_ignore |= (1 << 7);
+			mid_pmu_cxt->cstate_ignore |= (1 << 8);
+			mid_pmu_cxt->cstate_ignore |= (1 << 9);
+		} else {
+			mid_pmu_cxt->cstate_ignore =
+				~((1 << CPUIDLE_STATE_MAX) - 1);
+
+			/* Ignore C2, C3, C5, C8 and C10 states */
+			mid_pmu_cxt->cstate_ignore |= (1 << 1);
+			mid_pmu_cxt->cstate_ignore |= (1 << 2);
+			mid_pmu_cxt->cstate_ignore |= (1 << 4);
+			mid_pmu_cxt->cstate_ignore |= (1 << 7);
+			mid_pmu_cxt->cstate_ignore |= (1 << 9);
+		}
+
+		mid_pmu_cxt->cstate_qos =
+			kzalloc(sizeof(struct pm_qos_request), GFP_KERNEL);
+		if (mid_pmu_cxt->cstate_qos) {
+			pm_qos_add_request(mid_pmu_cxt->cstate_qos,
+				 PM_QOS_CPU_DMA_LATENCY, PM_QOS_DEFAULT_VALUE);
+		}
+
+		/* If s0ix is disabled then restrict to C6 */
+		if (!enable_s0ix) {
+			/* Restrict platform Cx state to C6 */
+			pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+						(CSTATE_EXIT_LATENCY_S0i1-1));
+		}
+
+		/* /sys/kernel/debug/ignore_add */
+		(void) debugfs_create_file("ignore_add", S_IFREG | S_IRUGO,
+					NULL, NULL, &ignore_add_ops);
+		/* /sys/kernel/debug/ignore_remove */
+		(void) debugfs_create_file("ignore_remove", S_IFREG | S_IRUGO,
+					NULL, NULL, &ignore_remove_ops);
+		/* /sys/kernel/debug/pmu_sync_d0ix */
+		(void) debugfs_create_file("pmu_sync_d0ix", S_IFREG | S_IRUGO,
+					NULL, NULL, &pmu_sync_d0ix_ops);
+		/* /sys/kernel/debug/pmu_force_d0i0 */
+		(void) debugfs_create_file("pmu_force_d0i0", S_IFREG | S_IRUGO,
+					NULL, NULL, &pmu_force_d0i0_ops);
+		/* /sys/kernel/debug/pmu_force_d0i3 */
+		(void) debugfs_create_file("pmu_force_d0i3", S_IFREG | S_IRUGO,
+					NULL, NULL, &pmu_force_d0i3_ops);
+		/* /sys/kernel/debug/cstate_ignore_add */
+		(void) debugfs_create_file("cstate_ignore_add",
+			S_IFREG | S_IRUGO, NULL, NULL, &cstate_ignore_add_ops);
+		/* /sys/kernel/debug/cstate_ignore_remove */
+		(void) debugfs_create_file("cstate_ignore_remove",
+		S_IFREG | S_IRUGO, NULL, NULL, &cstate_ignore_remove_ops);
+		/* /sys/kernel/debug/cstate_ignore_remove */
+		(void) debugfs_create_file("s3_ctrl",
+		S_IFREG | S_IRUGO, NULL, NULL, &s3_ctrl_ops);
+	}
+#endif
+}
+
+#endif /*if CONFIG_REMOVEME_INTEL_ATOM_MRFLD_POWER*/
diff --git a/arch/x86/platform/intel-mid/intel_soc_pm_debug.h b/arch/x86/platform/intel-mid/intel_soc_pm_debug.h
new file mode 100644
index 0000000..51e0871
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_pm_debug.h
@@ -0,0 +1,234 @@
+/*
+ * intel_soc_pm_debug.h
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+#ifndef _INTEL_SOC_PM_DEBUG_H
+#define _INTEL_SOC_PM_DEBUG_H
+#include <linux/intel_mid_pm.h>
+
+#include "intel_soc_pmu.h"
+
+
+#define NANO_SEC		1000000000UL /* 10^9 in sec */
+#define MICRO_SEC		1000000UL /* 10^6 in sec */
+#define PMU_LOG_INTERVAL_SECS	(60*5) /* 5 mins in secs */
+
+#define S0IX_LAT_SRAM_ADDR_CLVP		0xFFFF7FD0
+#define S0IX_LAT_SRAM_SIZE_CLVP		8
+
+#define IPC_CMD_S0IX_LATENCY_CLVP	0xCE
+#define IPC_SUB_MEASURE_START_CLVP	0x00
+#define IPC_SUB_MEASURE_STOP_CLVP	0x01
+
+struct simple_stat {
+	u64 min;
+	u64 max;
+	u64 total;
+	u64 curr;
+};
+
+struct entry_exit_stat {
+	struct simple_stat entry;
+	struct simple_stat exit;
+};
+
+struct latency_stat {
+	struct entry_exit_stat scu_latency[SYS_STATE_MAX];
+	struct entry_exit_stat os_latency[SYS_STATE_MAX];
+	struct simple_stat s3_parts_lat[MAX_S3_PARTS];
+	u64 count[SYS_STATE_MAX];
+	u32 __iomem *scu_s0ix_lat_addr;
+	struct dentry *dentry;
+	bool latency_measure;
+};
+
+struct island {
+	int type;
+	int index;
+	char *name;
+};
+
+struct lss_definition {
+	char *lss_name;
+	char *block;
+	char *subsystem;
+};
+
+#ifdef CONFIG_REMOVEME_INTEL_ATOM_MRFLD_POWER
+#define PUNIT_CR_CORE_C1_RES_MSR	0x660
+#define PUNIT_CR_CORE_C4_RES_MSR	0x3fc
+#define PUNIT_CR_CORE_C6_RES_MSR	0x3fd
+
+#define NUM_CSTATES_RES_MEASURE		3
+
+extern unsigned int enable_s3;
+extern unsigned int enable_s0ix;
+
+extern u32 __iomem *residency[];
+extern u32 __iomem *s0ix_counter[];
+
+#endif
+
+/* platform dependency starts */
+#ifdef CONFIG_INTEL_REMOVEME_ATOM_MDFLD_POWER
+
+#define DEV_GFX		2
+#define FUNC_GFX	0
+#define ISLANDS_GFX	8
+#define DEV_ISP		3
+#define FUNC_ISP	0
+#define ISLANDS_ISP	2
+#define NC_DEVS		2
+
+static struct lss_definition lsses[] = {
+	{"Lss00", "Storage", "SDIO0 (HC2)"},
+	{"Lss01", "Storage", "eMMC0 (HC0a)"},
+	{"NA", "Storage", "ND_CTL (Note 5)"},
+	{"Lss03", "H S I", "H S I DMA"},
+	{"Lss04", "Security", "RNG"},
+	{"Lss05", "Storage", "eMMC1 (HC0b)"},
+	{"Lss06", "USB", "USB OTG (ULPI)"},
+	{"Lss07", "USB", "USB_SPH"},
+	{"Lss08", "Audio", ""},
+	{"Lss09", "Audio", ""},
+	{"Lss10", "SRAM", " SRAM CTL+SRAM_16KB"},
+	{"Lss11", "SRAM", " SRAM CTL+SRAM_16KB"},
+	{"Lss12", "SRAM", "SRAM BANK (16KB+3x32KBKB)"},
+	{"Lss13", "SRAM", "SRAM BANK(4x32KB)"},
+	{"Lss14", "SDIO COMMS", "SDIO2 (HC1b)"},
+	{"Lss15", "PTI, DAFCA", " DFX Blocks"},
+	{"Lss16", "SC", " DMA"},
+	{"NA", "SC", "SPI0/MSIC"},
+	{"Lss18", "GP", "SPI1"},
+	{"Lss19", "GP", " SPI2"},
+	{"Lss20", "GP", " I2C0"},
+	{"Lss21", "GP", " I2C1"},
+	{"NA", "Fabrics", " Main Fabric"},
+	{"NA", "Fabrics", " Secondary Fabric"},
+	{"NA", "SC", "SC Fabric"},
+	{"Lss25", "Audio", " I-RAM BANK1 (32 + 256KB)"},
+	{"NA", "SCU", " ROM BANK1 (18KB+18KB+18KB)"},
+	{"Lss27", "GP", "I2C2"},
+	{"NA", "SSC", "SSC (serial bus controller to FLIS)"},
+	{"Lss29", "Security", "Chaabi AON Registers"},
+	{"Lss30", "SDIO COMMS", "SDIO1 (HC1a)"},
+	{"NA", "SCU", "I-RAM BANK0 (32KB)"},
+	{"NA", "SCU", "I-RAM BANK1 (32KB)"},
+	{"Lss33", "GP", "I2C3 (HDMI)"},
+	{"Lss34", "GP", "I2C4"},
+	{"Lss35", "GP", "I2C5"},
+	{"Lss36", "GP", "SSP (SPI3)"},
+	{"Lss37", "GP", "GPIO1"},
+	{"NA", "GP", "GP Fabric"},
+	{"Lss39", "SC", "GPIO0"},
+	{"Lss40", "SC", "KBD"},
+	{"Lss41", "SC", "UART2:0"},
+	{"NA", "NA", "NA"},
+	{"NA", "NA", "NA"},
+	{"Lss44", "Security", " Security TAPC"},
+	{"NA", "MISC", "AON Timers"},
+	{"NA", "PLL", "LFHPLL and Spread Spectrum"},
+	{"NA", "PLL", "USB PLL"},
+	{"NA", "NA", "NA"},
+	{"NA", "Audio", "SLIMBUS CTL 1 (note 5)"},
+	{"NA", "Audio", "SLIMBUS CTL 2 (note 5)"},
+	{"Lss51", "Audio", "SSP0"},
+	{"Lss52", "Audio", "SSP1"},
+	{"NA", "Bridge", "IOSF to OCP Bridge"},
+	{"Lss54", "GP", "DMA"},
+	{"NA", "SC", "SVID (Serial Voltage ID)"},
+	{"NA", "SOC Fuse", "SoC Fuse Block (note 3)"},
+	{"NA", "NA", "NA"},
+};
+#endif
+
+
+#ifdef CONFIG_REMOVEME_INTEL_ATOM_CLV_POWER
+
+#define DEV_GFX		2
+#define FUNC_GFX	0
+#define ISLANDS_GFX	8
+#define DEV_ISP		3
+#define FUNC_ISP	0
+#define ISLANDS_ISP	2
+#define NC_DEVS		2
+
+static struct lss_definition lsses[] = {
+	{"Lss00", "Storage", "SDIO0 (HC2)"},
+	{"Lss01", "Storage", "eMMC0 (HC0a)"},
+	{"NA", "Timer", "AONT"},
+	{"Lss03", "H S I", "H S I DMA"},
+	{"Lss04", "Security", "RNG"},
+	{"Lss05", "Storage", "eMMC1 (HC0b)"},
+	{"Lss06", "USB", "USB OTG (ULPI)"},
+	{"Lss07", "USB", "USB_SPH"},
+	{"Lss08", "Audio", "Audio ENGINE"},
+	{"Lss09", "Audio", "Audio DMA"},
+	{"Lss10", "SRAM", " SRAM CTL+SRAM_16KB"},
+	{"Lss11", "SRAM", " SRAM CTL+SRAM_16KB"},
+	{"Lss12", "SRAM", "SRAM BANK (16KB+3x32KBKB)"},
+	{"Lss13", "SRAM", "SRAM BANK(4x32KB)"},
+	{"Lss14", "SDIO COMMS", "SDIO2 (HC1b)"},
+	{"Lss15", "PTI, DAFCA", " DFX Blocks"},
+	{"Lss16", "SC", " DMA"},
+	{"NA", "SC", "SPI0/MSIC"},
+	{"Lss18", "GP", "SPI1"},
+	{"Lss19", "GP", " SPI2"},
+	{"Lss20", "GP", " I2C0"},
+	{"Lss21", "GP", " I2C1"},
+	{"NA", "Timer", "HPET"},
+	{"NA", "Timer", "External Timer"},
+	{"NA", "SC", "SC Fabric"},
+	{"Lss25", "Audio", " I-RAM BANK1 (32 + 256KB)"},
+	{"NA", "SCU", " ROM BANK1 (18KB+18KB+18KB)"},
+	{"Lss27", "GP", "I2C2"},
+	{"NA", "SSC", "SSC (serial bus controller to FLIS)"},
+	{"Lss29", "Security", "Chaabi AON Registers"},
+	{"Lss30", "SDIO COMMS", "SDIO1 (HC1a)"},
+	{"NA", "Timer", "vRTC"},
+	{"NA", "Security", "Security Timer"},
+	{"Lss33", "GP", "I2C3 (HDMI)"},
+	{"Lss34", "GP", "I2C4"},
+	{"Lss35", "GP", "I2C5"},
+	{"Lss36", "GP", "SSP (SPI3)"},
+	{"Lss37", "GP", "GPIO1"},
+	{"NA", "MSIC", "Power Button"},
+	{"Lss39", "SC", "GPIO0"},
+	{"Lss40", "SC", "KBD"},
+	{"Lss41", "SC", "UART2:0"},
+	{"NA", "MSIC", "ADC"},
+	{"NA", "MSIC", "Charger"},
+	{"Lss44", "Security", " Security TAPC"},
+	{"NA", "MSIC", "AON Timers"},
+	{"NA", "MSIC", "GPI"},
+	{"NA", "MSIC", "BCU"},
+	{"NA", "NA", "SSP2"},
+	{"NA", "Audio", "SLIMBUS CTL 1 (note 5)"},
+	{"NA", "Audio", "SLIMBUS CTL 2 (note 5)"},
+	{"Lss51", "Audio", "SSP0"},
+	{"Lss52", "Audio", "SSP1"},
+	{"NA", "Bridge", "IOSF to OCP Bridge"},
+	{"Lss54", "GP", "DMA"},
+	{"NA", "MSIC", "RESET"},
+	{"NA", "SOC Fuse", "SoC Fuse Block (note 3)"},
+	{"NA", "NA", "NA"},
+	{"Lss58", "NA", "SSP4"},
+};
+#endif
+/* platform dependency ends */
+
+#endif
diff --git a/arch/x86/platform/intel-mid/intel_soc_pmu.c b/arch/x86/platform/intel-mid/intel_soc_pmu.c
new file mode 100644
index 0000000..e696c23
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_pmu.c
@@ -0,0 +1,2144 @@
+/*
+ * intel_soc_pmu.c - This driver provides interface to configure the 2 pmu's
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#include "intel_soc_pmu.h"
+#include <linux/cpuidle.h>
+#include <linux/proc_fs.h>
+#include <asm/intel_mid_rpmsg.h>
+#include <asm/mwait.h>
+
+#ifdef CONFIG_DRM_INTEL_MID
+#define GFX_ENABLE
+#endif
+
+bool pmu_initialized;
+
+DEFINE_MUTEX(pci_root_lock);
+
+/* mid_pmu context structure */
+struct mid_pmu_dev *mid_pmu_cxt;
+
+struct platform_pmu_ops *pmu_ops;
+/*
+ * Locking strategy::
+ *
+ * one semaphore (scu_ready sem) is used for accessing busy bit,
+ * issuing interactive cmd in the code.
+ * The entry points in pmu driver are pmu_pci_set_power_state()
+ * and PMU interrupt handler contexts, so here is the flow of how
+ * the semaphore is used.
+ *
+ * In D0ix command case::
+ * set_power_state process context:
+ * set_power_state()->acquire_scu_ready_sem()->issue_interactive_cmd->
+ * wait_for_interactive_complete->release scu_ready sem
+ *
+ * PMU Interrupt context:
+ * pmu_interrupt_handler()->release interactive_complete->return
+ *
+ * In Idle handler case::
+ * Idle context:
+ * idle_handler()->try_acquire_scu_ready_sem->if acquired->
+ * issue s0ix command->return
+ *
+ * PMU Interrupt context:
+ * pmu_Interrupt_handler()->release scu_ready_sem->return
+ *
+ */
+
+/* Maps pci power states to SCU D0ix mask */
+static int pci_to_platform_state(pci_power_t pci_state)
+{
+
+	static int mask[]  = {D0I0_MASK, D0I1_MASK,
+				D0I2_MASK, D0I3_MASK, D0I3_MASK};
+
+	int state = D0I0_MASK;
+
+	if (pci_state > 4)
+		WARN(1, "%s: wrong pci_state received.\n", __func__);
+
+	else
+		state = mask[pci_state];
+
+	return state;
+}
+
+/* Maps power states to pmu driver's internal indexes */
+int mid_state_to_sys_state(int mid_state)
+{
+	int sys_state = 0;
+	switch (mid_state) {
+	case MID_S0I1_STATE:
+		sys_state = SYS_STATE_S0I1;
+		break;
+	case MID_LPMP3_STATE:
+		sys_state = SYS_STATE_S0I2;
+		break;
+	case MID_S0I3_STATE:
+		sys_state = SYS_STATE_S0I3;
+		break;
+	case MID_S3_STATE:
+		sys_state = SYS_STATE_S3;
+		break;
+
+	case C6_HINT:
+		sys_state = SYS_STATE_S0I0;
+	}
+
+	return sys_state;
+}
+
+/* PCI Device Id structure */
+static DEFINE_PCI_DEVICE_TABLE(mid_pm_ids) = {
+	{PCI_VDEVICE(INTEL, MID_PMU_MFLD_DRV_DEV_ID), 0},
+	{PCI_VDEVICE(INTEL, MID_PMU_CLV_DRV_DEV_ID), 0},
+	{PCI_VDEVICE(INTEL, MID_PMU_MRFL_DRV_DEV_ID), 0},
+	{}
+};
+
+MODULE_DEVICE_TABLE(pci, mid_pm_ids);
+
+char s0ix[5] = "s0ix";
+
+module_param_call(s0ix, set_extended_cstate_mode,
+		get_extended_cstate_mode, NULL, 0644);
+
+MODULE_PARM_DESC(s0ix,
+	"setup extended c state s0ix mode [s0i3|s0i1|lmp3|"
+				"i1i3|lpi1|lpi3|s0ix|none]");
+
+/**
+ * This function set all devices in d0i0 and deactivates pmu driver.
+ * The function is used before IFWI update as it needs devices to be
+ * in d0i0 during IFWI update. Reboot is needed to work pmu
+ * driver properly again. After calling this function and IFWI
+ * update, system is always rebooted as IFWI update function,
+ * intel_scu_ipc_medfw_upgrade() is called from mrst_emergency_reboot().
+ */
+int pmu_set_devices_in_d0i0(void)
+{
+	int status;
+	struct pmu_ss_states cur_pmssc;
+
+	/* Ignore request until we have initialized */
+	if (unlikely((!pmu_initialized)))
+		return 0;
+
+	cur_pmssc.pmu2_states[0] = D0I0_MASK;
+	cur_pmssc.pmu2_states[1] = D0I0_MASK;
+	cur_pmssc.pmu2_states[2] = D0I0_MASK;
+	cur_pmssc.pmu2_states[3] = D0I0_MASK;
+
+	/* Restrict platform Cx state to C6 */
+	pm_qos_update_request(mid_pmu_cxt->s3_restrict_qos,
+				(CSTATE_EXIT_LATENCY_S0i1-1));
+
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	mid_pmu_cxt->shutdown_started = true;
+
+	/* Issue the pmu command to PMU 2
+	 * flag is needed to distinguish between
+	 * S0ix vs interactive command in pmu_sc_irq()
+	 */
+	status = pmu_issue_interactive_command(&cur_pmssc, false, false);
+
+	if (unlikely(status != PMU_SUCCESS)) {	/* pmu command failed */
+		printk(KERN_CRIT "%s: Failed to Issue a PM command to PMU2\n",
+								__func__);
+		mid_pmu_cxt->shutdown_started = false;
+
+		/* allow s0ix now */
+		pm_qos_update_request(mid_pmu_cxt->s3_restrict_qos,
+						PM_QOS_DEFAULT_VALUE);
+		goto unlock;
+	}
+
+	if (_pmu2_wait_not_busy()) {
+		pmu_dump_logs();
+		BUG();
+	}
+
+unlock:
+	up(&mid_pmu_cxt->scu_ready_sem);
+	return status;
+}
+EXPORT_SYMBOL(pmu_set_devices_in_d0i0);
+
+static int _pmu_read_status(int type)
+{
+	u32 temp;
+	union pmu_pm_status result;
+
+	temp = readl(&mid_pmu_cxt->pmu_reg->pm_sts);
+
+	/* extract the busy bit */
+	result.pmu_status_value = temp;
+
+	if (type == PMU_BUSY_STATUS)
+		return result.pmu_status_parts.pmu_busy;
+	else if (type == PMU_MODE_ID)
+		return result.pmu_status_parts.mode_id;
+
+	return 0;
+}
+
+int _pmu2_wait_not_busy(void)
+{
+	int pmu_busy_retry = PMU2_BUSY_TIMEOUT;
+
+	/* wait 500ms that the latest pmu command finished */
+	do {
+		if (_pmu_read_status(PMU_BUSY_STATUS) == 0)
+			return 0;
+
+		udelay(1);
+	} while (--pmu_busy_retry);
+
+	WARN(1, "pmu2 busy!");
+
+	return -EBUSY;
+}
+
+static int _pmu2_wait_not_busy_yield(void)
+{
+	int pmu_busy_retry = PMU2_BUSY_TIMEOUT;
+
+	/* wait max 500ms that the latest pmu command finished */
+	do {
+		if (_pmu_read_status(PMU_BUSY_STATUS) == 0)
+			return 0;
+
+		usleep_range(10, 12);
+		pmu_busy_retry -= 11;
+	} while (pmu_busy_retry > 0);
+
+	WARN(1, "pmu2 busy!");
+
+	return -EBUSY;
+}
+
+static void pmu_write_subsys_config(struct pmu_ss_states *pm_ssc)
+{
+	/* South complex in Penwell has multiple registers for
+	 * PM_SSC, etc.
+	 */
+	writel(pm_ssc->pmu2_states[0], &mid_pmu_cxt->pmu_reg->pm_ssc[0]);
+	writel(pm_ssc->pmu2_states[1], &mid_pmu_cxt->pmu_reg->pm_ssc[1]);
+	writel(pm_ssc->pmu2_states[2], &mid_pmu_cxt->pmu_reg->pm_ssc[2]);
+	writel(pm_ssc->pmu2_states[3], &mid_pmu_cxt->pmu_reg->pm_ssc[3]);
+}
+
+void log_wakeup_irq(void)
+{
+	unsigned int irr = 0, vector = 0;
+	int offset = 0, irq = 0;
+	struct irq_desc *desc;
+	const char *act_name;
+
+	if ((mid_pmu_cxt->pmu_current_state != SYS_STATE_S3)
+	    || !mid_pmu_cxt->suspend_started)
+		return;
+
+	for (offset = (FIRST_EXTERNAL_VECTOR/32);
+	offset < (NR_VECTORS/32); offset++) {
+		irr = apic_read(APIC_IRR + (offset * 0x10));
+		while (irr) {
+			vector = __ffs(irr);
+			irr &= ~(1 << vector);
+			irq = __this_cpu_read(
+					vector_irq[vector + (offset * 32)]);
+			if (irq < 0)
+				continue;
+			pr_info("wakeup from  IRQ %d\n", irq);
+
+			desc = irq_to_desc(irq);
+
+			if ((desc) && (desc->action)) {
+				act_name = desc->action->name;
+				pr_info("IRQ %d,action name:%s\n",
+					irq,
+					(act_name) ? (act_name) : "no action");
+			}
+		}
+	}
+	return;
+}
+
+static inline int pmu_interrupt_pending(void)
+{
+	u32 temp;
+	union pmu_pm_ics result;
+
+	/* read the pm interrupt status register */
+	temp = readl(&mid_pmu_cxt->pmu_reg->pm_ics);
+	result.pmu_pm_ics_value = temp;
+
+	/* return the pm interrupt status int pending bit info */
+	return result.pmu_pm_ics_parts.int_pend;
+}
+
+static inline void pmu_clear_pending_interrupt(void)
+{
+	u32 temp;
+
+	/* read the pm interrupt status register */
+	temp = readl(&mid_pmu_cxt->pmu_reg->pm_ics);
+
+	/* write into the PM_ICS register */
+	writel(temp, &mid_pmu_cxt->pmu_reg->pm_ics);
+}
+
+void pmu_set_interrupt_enable(void)
+{
+	u32 temp;
+	union pmu_pm_ics result;
+
+	/* read the pm interrupt status register */
+	temp = readl(&mid_pmu_cxt->pmu_reg->pm_ics);
+	result.pmu_pm_ics_value = temp;
+
+	/* Set the interrupt enable bit */
+	result.pmu_pm_ics_parts.int_enable = 1;
+
+	temp = result.pmu_pm_ics_value;
+
+	/* write into the PM_ICS register */
+	writel(temp, &mid_pmu_cxt->pmu_reg->pm_ics);
+}
+
+void pmu_clear_interrupt_enable(void)
+{
+	u32 temp;
+	union pmu_pm_ics result;
+
+	/* read the pm interrupt status register */
+	temp = readl(&mid_pmu_cxt->pmu_reg->pm_ics);
+	result.pmu_pm_ics_value = temp;
+
+	/* Clear the interrupt enable bit */
+	result.pmu_pm_ics_parts.int_enable = 0;
+
+	temp = result.pmu_pm_ics_value;
+
+	/* write into the PM_ICS register */
+	writel(temp, &mid_pmu_cxt->pmu_reg->pm_ics);
+}
+
+static inline int pmu_read_interrupt_status(void)
+{
+	u32 temp;
+	union pmu_pm_ics result;
+
+	/* read the pm interrupt status register */
+	temp = readl(&mid_pmu_cxt->pmu_reg->pm_ics);
+
+	result.pmu_pm_ics_value = temp;
+
+	if (result.pmu_pm_ics_parts.int_status == 0)
+		return PMU_FAILED;
+
+	/* return the pm interrupt status int pending bit info */
+	return result.pmu_pm_ics_parts.int_status;
+}
+
+/*This function is used for programming the wake capable devices*/
+static void pmu_prepare_wake(int s0ix_state)
+{
+
+	struct pmu_ss_states cur_pmsss;
+
+	/* setup the wake capable devices */
+	if (s0ix_state == MID_S3_STATE) {
+		writel(~IGNORE_S3_WKC0, &mid_pmu_cxt->pmu_reg->pm_wkc[0]);
+		writel(~IGNORE_S3_WKC1, &mid_pmu_cxt->pmu_reg->pm_wkc[1]);
+	}
+
+	if (platform_is(INTEL_ATOM_MFLD) || platform_is(INTEL_ATOM_CLV)) {
+
+		/* Re-program the sub systems state on wakeup as
+		 * the current SSS
+		 */
+		pmu_read_sss(&cur_pmsss);
+
+		writel(cur_pmsss.pmu2_states[0],
+				&mid_pmu_cxt->pmu_reg->pm_wssc[0]);
+		writel(cur_pmsss.pmu2_states[1],
+				&mid_pmu_cxt->pmu_reg->pm_wssc[1]);
+		writel(cur_pmsss.pmu2_states[2],
+				&mid_pmu_cxt->pmu_reg->pm_wssc[2]);
+		writel(cur_pmsss.pmu2_states[3],
+				&mid_pmu_cxt->pmu_reg->pm_wssc[3]);
+	}
+}
+
+int mid_s0ix_enter(int s0ix_state)
+{
+	int ret = 0;
+
+	if (unlikely(!pmu_ops || !pmu_ops->enter))
+		goto ret;
+
+	/* check if we can acquire scu_ready_sem
+	 * if we are not able to then do a c6 */
+	if (down_trylock(&mid_pmu_cxt->scu_ready_sem))
+		goto ret;
+
+	/* If PMU is busy, we'll retry on next C6 */
+	if (unlikely(_pmu_read_status(PMU_BUSY_STATUS))) {
+		up(&mid_pmu_cxt->scu_ready_sem);
+		pr_debug("mid_pmu_cxt->scu_read_sem is up\n");
+		goto ret;
+	}
+
+	pmu_prepare_wake(s0ix_state);
+
+	/* no need to proceed if schedule pending */
+	if (unlikely(need_resched())) {
+		pmu_stat_clear();
+		/*set wkc to appropriate value suitable for s0ix*/
+		writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[0],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[0]);
+		writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[1],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[1]);
+		up(&mid_pmu_cxt->scu_ready_sem);
+		goto ret;
+	}
+
+	/* entry function for pmu driver ops */
+	if (pmu_ops->enter(s0ix_state))
+		ret = s0ix_state;
+	else  {
+		/*set wkc to appropriate value suitable for s0ix*/
+		writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[0],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[0]);
+		writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[1],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[1]);
+	}
+
+ret:
+	return ret;
+}
+
+/**
+ * pmu_sc_irq - pmu driver interrupt handler
+ * Context: interrupt context
+ */
+static irqreturn_t pmu_sc_irq(int irq, void *ignored)
+{
+	int status;
+	irqreturn_t ret = IRQ_NONE;
+	int wake_source;
+
+	/* check if interrup pending bit is set, if not ignore interrupt */
+	if (unlikely(!pmu_interrupt_pending())) {
+		goto ret_no_clear;
+	}
+
+	/* read the interrupt status */
+	status = pmu_read_interrupt_status();
+	if (unlikely(status == PMU_FAILED))
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev, "Invalid interrupt source\n");
+
+	switch (status) {
+	case INVALID_INT:
+		goto ret_no_clear;
+
+	case CMD_COMPLETE_INT:
+		break;
+
+	case CMD_ERROR_INT:
+		mid_pmu_cxt->cmd_error_int++;
+		break;
+
+	case SUBSYS_POW_ERR_INT:
+	case NO_ACKC6_INT:
+	case S0ix_MISS_INT:
+		pmu_stat_error(status);
+		break;
+
+	case WAKE_RECEIVED_INT:
+		wake_source = pmu_get_wake_source();
+		trace_printk("wake_from_lss%d\n",
+				wake_source);
+		pmu_stat_end();
+		break;
+	case TRIGGERERR:
+		pmu_dump_logs();
+		WARN(1, "%s: TRIGGERERR caused, but proceeding...\n", __func__);
+		break;
+	}
+
+	pmu_stat_clear();
+
+	/* clear the interrupt pending bit */
+	pmu_clear_pending_interrupt();
+
+	if (pmu_ops->wakeup)
+		pmu_ops->wakeup();
+
+	if (platform_is(INTEL_ATOM_MFLD) ||
+				platform_is(INTEL_ATOM_CLV)) {
+		mid_pmu_cxt->s0ix_entered = 0;
+		/* S0ix case release it */
+		up(&mid_pmu_cxt->scu_ready_sem);
+	}
+
+	ret = IRQ_HANDLED;
+ret_no_clear:
+	/* clear interrupt enable bit */
+	pmu_clear_interrupt_enable();
+
+	return ret;
+}
+
+void pmu_set_s0ix_complete(void)
+{
+	if (pmu_ops->set_s0ix_complete)
+		pmu_ops->set_s0ix_complete();
+}
+EXPORT_SYMBOL(pmu_set_s0ix_complete);
+
+bool pmu_is_s0ix_in_progress(void)
+{
+	bool state = false;
+
+	if (pmu_initialized && mid_pmu_cxt->s0ix_entered)
+		state = true;
+
+	return state;
+}
+EXPORT_SYMBOL(pmu_is_s0ix_in_progress);
+
+static inline u32 find_index_in_hash(struct pci_dev *pdev, int *found)
+{
+	u32 h_index;
+	int i;
+
+	/* assuming pdev is not null */
+	WARN_ON(pdev == NULL);
+
+	/*assuming pdev pionter will not change from platfrom
+	 *boot to shutdown*/
+	h_index = jhash_1word((u32) (long) pdev,
+		 MID_PCI_INDEX_HASH_INITVALUE) & MID_PCI_INDEX_HASH_MASK;
+
+	/* assume not found */
+	*found = 0;
+
+	for (i = 0; i < MID_PCI_INDEX_HASH_SIZE; i++) {
+		if (likely(mid_pmu_cxt->pci_dev_hash[h_index].pdev == pdev)) {
+			*found = 1;
+			break;
+		}
+
+		/* assume no deletions, hence there shouldn't be any
+		 * gaps ie., NULL's */
+		if (unlikely(mid_pmu_cxt->pci_dev_hash[h_index].pdev == NULL)) {
+			/* found NULL, that means we wont have
+			 * it in hash */
+			break;
+		}
+
+		h_index = (h_index+1)%MID_PCI_INDEX_HASH_SIZE;
+	}
+
+	/* Assume hash table wont be full */
+	WARN_ON(i == MID_PCI_INDEX_HASH_SIZE);
+
+	return h_index;
+}
+
+static bool is_display_subclass(unsigned int sub_class)
+{
+	/* On MDFLD and CLV, we have display PCI device class 0x30000,
+	 * On MRFLD, we have display PCI device class 0x38000
+	 */
+
+	if ((sub_class == 0x0 &&
+		(platform_is(INTEL_ATOM_MFLD) ||
+		platform_is(INTEL_ATOM_CLV))) ||
+		(sub_class == 0x80 && platform_is(INTEL_ATOM_MRFLD)))
+		return true;
+
+	return false;
+}
+
+static int get_pci_to_pmu_index(struct pci_dev *pdev)
+{
+	int pm, type;
+	unsigned int base_class;
+	unsigned int sub_class;
+	u8 ss;
+	int index = PMU_FAILED;
+	u32 h_index;
+	int found;
+
+	h_index = find_index_in_hash(pdev, &found);
+
+	if (found)
+		return (int)mid_pmu_cxt->pci_dev_hash[h_index].index;
+
+	/* if not found, h_index would be where
+	 * we can insert this */
+
+	base_class = pdev->class >> 16;
+	sub_class  = (pdev->class & SUB_CLASS_MASK) >> 8;
+	pm = pci_find_capability(pdev, PCI_CAP_ID_VNDR);
+
+	/* read the logical sub system id & cap if present */
+	pci_read_config_byte(pdev, pm + 4, &ss);
+
+	type = ss & LOG_SS_MASK;
+	ss = ss & LOG_ID_MASK;
+
+	if ((base_class == PCI_BASE_CLASS_DISPLAY) &&
+			is_display_subclass(sub_class))
+		index = 1;
+	else if ((base_class == PCI_BASE_CLASS_MULTIMEDIA) &&
+			(sub_class == ISP_SUB_CLASS))
+				index = ISP_POS;
+	else if (type) {
+		WARN_ON(ss >= MAX_LSS_POSSIBLE);
+		index = mid_pmu_cxt->pmu1_max_devs + ss;
+	}
+
+	if (index != PMU_FAILED) {
+		/* insert into hash table */
+		mid_pmu_cxt->pci_dev_hash[h_index].pdev = pdev;
+
+		/* assume index never exceeds 0xff */
+		WARN_ON(index > 0xFF);
+
+		mid_pmu_cxt->pci_dev_hash[h_index].index = (u8)index;
+
+		if (index < mid_pmu_cxt->pmu1_max_devs) {
+			set_mid_pci_ss_idx(index, 0);
+			set_mid_pci_ss_pos(index, (u8)index);
+			set_mid_pci_pmu_num(index, PMU_NUM_1);
+		} else if (index >= mid_pmu_cxt->pmu1_max_devs &&
+			   index < (mid_pmu_cxt->pmu1_max_devs +
+						mid_pmu_cxt->pmu2_max_devs)) {
+			set_mid_pci_ss_idx(index,
+					(u8)(ss / mid_pmu_cxt->ss_per_reg));
+			set_mid_pci_ss_pos(index,
+					(u8)(ss % mid_pmu_cxt->ss_per_reg));
+			set_mid_pci_pmu_num(index, PMU_NUM_2);
+		} else {
+			index = PMU_FAILED;
+		}
+
+		WARN_ON(index == PMU_FAILED);
+	}
+
+	return index;
+}
+
+static void get_pci_lss_info(struct pci_dev *pdev)
+{
+	int index, pm;
+	unsigned int base_class;
+	unsigned int sub_class;
+	u8 ss, cap;
+	int i;
+	base_class = pdev->class >> 16;
+	sub_class  = (pdev->class & SUB_CLASS_MASK) >> 8;
+
+	pm = pci_find_capability(pdev, PCI_CAP_ID_VNDR);
+
+	/* read the logical sub system id & cap if present */
+	pci_read_config_byte(pdev, pm + 4, &ss);
+	pci_read_config_byte(pdev, pm + 5, &cap);
+
+	/* get the index for the copying of ss info */
+	index = get_pci_to_pmu_index(pdev);
+
+	if ((index == PMU_FAILED) || (index >= MAX_DEVICES))
+		return;
+
+	/* initialize gfx subsystem info */
+	if ((base_class == PCI_BASE_CLASS_DISPLAY) &&
+			is_display_subclass(sub_class)) {
+		set_mid_pci_log_id(index, (u32)index);
+		set_mid_pci_cap(index, PM_SUPPORT);
+	} else if ((base_class == PCI_BASE_CLASS_MULTIMEDIA) &&
+		(sub_class == ISP_SUB_CLASS)) {
+			set_mid_pci_log_id(index, (u32)index);
+			set_mid_pci_cap(index, PM_SUPPORT);
+	} else if (ss && cap) {
+		set_mid_pci_log_id(index, (u32)(ss & LOG_ID_MASK));
+		set_mid_pci_cap(index, cap);
+	}
+
+	for (i = 0; i < PMU_MAX_LSS_SHARE &&
+		get_mid_pci_drv(index, i); i++) {
+		/* do nothing */
+	}
+
+	WARN_ON(i >= PMU_MAX_LSS_SHARE);
+
+	if (i < PMU_MAX_LSS_SHARE) {
+		set_mid_pci_drv(index, i, pdev);
+		set_mid_pci_power_state(index, i, PCI_D3hot);
+	}
+}
+
+static void pmu_enumerate(void)
+{
+	struct pci_dev *pdev = NULL;
+	unsigned int base_class;
+
+	for_each_pci_dev(pdev) {
+		if (platform_is(INTEL_ATOM_MRFLD) &&
+			pdev->device == MID_MRFL_HDMI_DRV_DEV_ID)
+			continue;
+
+		/* find the base class info */
+		base_class = pdev->class >> 16;
+
+		if (base_class == PCI_BASE_CLASS_BRIDGE)
+			continue;
+
+		get_pci_lss_info(pdev);
+	}
+}
+
+void pmu_read_sss(struct pmu_ss_states *pm_ssc)
+{
+	pm_ssc->pmu2_states[0] =
+			readl(&mid_pmu_cxt->pmu_reg->pm_sss[0]);
+	pm_ssc->pmu2_states[1] =
+			readl(&mid_pmu_cxt->pmu_reg->pm_sss[1]);
+	pm_ssc->pmu2_states[2] =
+			readl(&mid_pmu_cxt->pmu_reg->pm_sss[2]);
+	pm_ssc->pmu2_states[3] =
+			readl(&mid_pmu_cxt->pmu_reg->pm_sss[3]);
+}
+
+
+/*
+ * For all devices in this lss, we check what is the weakest power state
+ *
+ * Thus we dont power down if another device needs more power
+ */
+
+static pci_power_t  pmu_pci_get_weakest_state_for_lss(int lss_index,
+				struct pci_dev *pdev, pci_power_t state)
+{
+	int i;
+	pci_power_t weakest = state;
+
+	for (i = 0; i < PMU_MAX_LSS_SHARE; i++) {
+		if (get_mid_pci_drv(lss_index, i) == pdev)
+			set_mid_pci_power_state(lss_index, i, state);
+
+		if (get_mid_pci_drv(lss_index, i) &&
+			(get_mid_pci_power_state(lss_index, i) < weakest))
+			weakest = get_mid_pci_power_state(lss_index, i);
+	}
+	return weakest;
+}
+
+int pmu_pci_to_indexes(struct pci_dev *pdev, int *index,
+				int *pmu_num, int *ss_idx, int *ss_pos)
+{
+	int i;
+
+	i = get_pci_to_pmu_index(pdev);
+	if (i == PMU_FAILED)
+		return PMU_FAILED;
+
+	*index		= i;
+	*ss_pos		= get_mid_pci_ss_pos(i);
+	*ss_idx		= get_mid_pci_ss_idx(i);
+	*pmu_num	= get_mid_pci_pmu_num(i);
+
+	return PMU_SUCCESS;
+}
+
+static bool update_nc_device_states(int i, pci_power_t state)
+{
+	int status = 0;
+	int islands = 0;
+	int reg;
+
+	/* store the display status */
+	if (i == GFX_LSS_INDEX) {
+		mid_pmu_cxt->display_off = (state != PCI_D0);
+		return true;
+	}
+
+	/*Update the Camera status per ISP Driver Suspended/Resumed
+	* ISP power islands are also updated accordingly, otherwise Dx state
+	* in PMCSR refuses to change.
+	*/
+	else if (i == ISP_POS) {
+		if (platform_is(INTEL_ATOM_MFLD) ||
+				 platform_is(INTEL_ATOM_CLV)) {
+			islands = APM_ISP_ISLAND | APM_IPH_ISLAND;
+			reg = APM_REG_TYPE;
+		} else if (platform_is(INTEL_ATOM_MRFLD)) {
+			islands = TNG_ISP_ISLAND;
+			reg = ISP_SS_PM0;
+		} else
+			return false;
+		status = pmu_nc_set_power_state(islands,
+			(state != PCI_D0) ?
+			OSPM_ISLAND_DOWN : OSPM_ISLAND_UP,
+			reg);
+		if (status)
+			return false;
+		mid_pmu_cxt->camera_off = (state != PCI_D0);
+		return true;
+	}
+
+	return false;
+}
+
+void init_nc_device_states(void)
+{
+#if !IS_ENABLED(CONFIG_VIDEO_ATOMISP)
+	mid_pmu_cxt->camera_off = true;
+#endif
+
+#ifndef GFX_ENABLE
+	/* If Gfx is disabled
+	 * assume s0ix is not blocked
+	 * from gfx side
+	 */
+	mid_pmu_cxt->display_off = true;
+#endif
+
+	return;
+}
+
+/* FIXME::Currently HSI Modem 7060 (BZ# 28529) is having a issue and
+* it will not go to Low Power State on CVT. So Standby will not work
+* if HSI is enabled.
+* We can choose between Standby/HSI based on enable_stadby 1/0.
+*/
+unsigned int enable_standby __read_mostly;
+module_param(enable_standby, uint, 0000);
+
+/* FIXME:: We have issues with S0ix/S3 enabling by default
+ * with display lockup, HSIC etc., so have a boot time option
+ * to enable S0ix/S3
+ */
+unsigned int enable_s3 __read_mostly = 1;
+int set_enable_s3(const char *val, struct kernel_param *kp)
+{
+	int rv = param_set_int(val, kp);
+	if (rv)
+		return rv;
+
+	if (unlikely((!pmu_initialized)))
+		return 0;
+
+	if (platform_is(INTEL_ATOM_MRFLD)) {
+		if (!enable_s3)
+			__pm_stay_awake(mid_pmu_cxt->pmu_wake_lock);
+		else
+			__pm_relax(mid_pmu_cxt->pmu_wake_lock);
+	}
+
+	return 0;
+}
+module_param_call(enable_s3, set_enable_s3, param_get_uint,
+				&enable_s3, S_IRUGO | S_IWUSR);
+
+/* FIXME:: We have issues with S0ix/S3 enabling by default
+ * with display lockup, HSIC etc., so have a boot time option
+ * to enable S0ix/S3
+ */
+unsigned int enable_s0ix __read_mostly = 1;
+int set_enable_s0ix(const char *val, struct kernel_param *kp)
+{
+	int rv = param_set_int(val, kp);
+	if (rv)
+		return rv;
+
+	if (unlikely((!pmu_initialized)))
+		return 0;
+
+	if (platform_is(INTEL_ATOM_MRFLD)) {
+		if (!enable_s0ix) {
+			mid_pmu_cxt->cstate_ignore =
+				~((1 << CPUIDLE_STATE_MAX) - 1);
+
+			/* Ignore C2, C3, C5 states */
+			mid_pmu_cxt->cstate_ignore |= (1 << 1);
+			mid_pmu_cxt->cstate_ignore |= (1 << 2);
+			mid_pmu_cxt->cstate_ignore |= (1 << 4);
+
+			/* For now ignore C7, C8, C9, C10 states */
+			mid_pmu_cxt->cstate_ignore |= (1 << 6);
+			mid_pmu_cxt->cstate_ignore |= (1 << 7);
+			mid_pmu_cxt->cstate_ignore |= (1 << 8);
+			mid_pmu_cxt->cstate_ignore |= (1 << 9);
+
+			/* Restrict platform Cx state to C6 */
+			pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+						(CSTATE_EXIT_LATENCY_S0i1-1));
+		} else {
+			mid_pmu_cxt->cstate_ignore =
+				~((1 << CPUIDLE_STATE_MAX) - 1);
+
+			/* Ignore C2, C3, C5, C8 and C10 states */
+			mid_pmu_cxt->cstate_ignore |= (1 << 1);
+			mid_pmu_cxt->cstate_ignore |= (1 << 2);
+			mid_pmu_cxt->cstate_ignore |= (1 << 4);
+			mid_pmu_cxt->cstate_ignore |= (1 << 7);
+			mid_pmu_cxt->cstate_ignore |= (1 << 9);
+
+			pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+							PM_QOS_DEFAULT_VALUE);
+		}
+	}
+
+	return 0;
+}
+module_param_call(enable_s0ix, set_enable_s0ix, param_get_uint,
+				&enable_s0ix, S_IRUGO | S_IWUSR);
+
+unsigned int pmu_ignore_lss0 __read_mostly = IGNORE_SSS0;
+module_param(pmu_ignore_lss0, uint, S_IRUGO | S_IWUSR);
+
+unsigned int pmu_ignore_lss1 __read_mostly = IGNORE_SSS1;
+module_param(pmu_ignore_lss1, uint, S_IRUGO | S_IWUSR);
+
+unsigned int pmu_ignore_lss2 __read_mostly = IGNORE_SSS2;
+module_param(pmu_ignore_lss2, uint, S_IRUGO | S_IWUSR);
+
+unsigned int pmu_ignore_lss3 __read_mostly = IGNORE_SSS3;
+module_param(pmu_ignore_lss3, uint, S_IRUGO | S_IWUSR);
+
+int pmu_set_emmc_to_d0i0_atomic(void)
+{
+	u32 pm_cmd_val;
+	u32 new_value;
+	int sub_sys_pos, sub_sys_index;
+	struct pmu_ss_states cur_pmssc;
+	int status = 0;
+
+	if (unlikely((!pmu_initialized)))
+		return 0;
+
+	/* LSS 01 is index = 0, pos = 1 */
+	sub_sys_index	= EMMC0_LSS / mid_pmu_cxt->ss_per_reg;
+	sub_sys_pos	= EMMC0_LSS % mid_pmu_cxt->ss_per_reg;
+
+	memset(&cur_pmssc, 0, sizeof(cur_pmssc));
+
+	/*
+	 * Give time for possible previous PMU operation to finish in
+	 * case where SCU is functioning normally. For SCU crashed case
+	 * PMU may stay busy but check if the emmc is accessible.
+	 */
+	status = _pmu2_wait_not_busy();
+	if (status) {
+		dev_err(&mid_pmu_cxt->pmu_dev->dev,
+			"PMU2 busy, ignoring as emmc might be already d0i0\n");
+		status = 0;
+	}
+
+	pmu_read_sss(&cur_pmssc);
+
+	/* set D0i0 the LSS bits */
+	pm_cmd_val =
+		(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+	new_value = cur_pmssc.pmu2_states[sub_sys_index] &
+						(~pm_cmd_val);
+	if (new_value == cur_pmssc.pmu2_states[sub_sys_index])
+		goto err;
+
+	status = _pmu2_wait_not_busy();
+	if (status)
+		goto err;
+
+	cur_pmssc.pmu2_states[sub_sys_index] = new_value;
+
+	/* Request SCU for PM interrupt enabling */
+	writel(PMU_PANIC_EMMC_UP_REQ_CMD, mid_pmu_cxt->emergeny_emmc_up_addr);
+
+	status = pmu_issue_interactive_command(&cur_pmssc, false, false);
+
+	if (unlikely(status != PMU_SUCCESS)) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+			 "Failed to Issue a PM command to PMU2\n");
+		goto err;
+
+	}
+
+	/*
+	 * Wait for interactive command to complete.
+	 * If we dont wait, there is a possibility that
+	 * the driver may access the device before its
+	 * powered on in SCU.
+	 *
+	 */
+	if (_pmu2_wait_not_busy()) {
+		pmu_dump_logs();
+		BUG();
+	}
+
+err:
+
+	return status;
+}
+
+
+#define SAVED_HISTORY_ADDRESS_NUM	10
+#define SAVED_HISTORY_NUM		20
+#define PCI_MAX_RECORD_NUM		10
+
+struct saved_nc_power_history {
+	unsigned long long ts;
+	unsigned short pci;
+	unsigned short cpu:4;
+	unsigned short state_type:8;
+	unsigned short real_change:2;
+	int reg_type;
+	int islands;
+	void *address[SAVED_HISTORY_ADDRESS_NUM];
+};
+
+static atomic_t saved_nc_power_history_current = ATOMIC_INIT(-1);
+static struct saved_nc_power_history all_history[SAVED_HISTORY_NUM];
+static struct saved_nc_power_history *get_new_record_history(void)
+{
+	unsigned int ret =
+		atomic_add_return(1, &saved_nc_power_history_current);
+	return &all_history[ret%SAVED_HISTORY_NUM];
+}
+
+static unsigned short pci_need_record[PCI_MAX_RECORD_NUM] = { 0x08c8, 0x0130, };
+static int num_pci_need_record = 2;
+module_param_array(pci_need_record, ushort, &num_pci_need_record, 0644);
+MODULE_PARM_DESC(pci_need_record,
+		"devices need be traced power state transition.");
+
+static bool pci_need_record_power_state(struct pci_dev *pdev)
+{
+	int i;
+	for (i = 0; i < num_pci_need_record; i++)
+		if (pdev->device == pci_need_record[i])
+			return true;
+
+	return false;
+}
+
+static void print_saved_record(struct saved_nc_power_history *record)
+{
+	int i;
+	unsigned long long ts = record->ts;
+	unsigned long nanosec_rem = do_div(ts, 1000000000);
+
+	printk(KERN_INFO "----\n");
+	printk(KERN_INFO "ts[%5lu.%06lu] cpu[%d] is pci[%04x] reg_type[%d] "
+			"state_type[%d] islands[%x] real_change[%d]\n",
+		(unsigned long)ts,
+		nanosec_rem / 1000,
+		record->cpu,
+		record->pci,
+		record->reg_type,
+		record->state_type,
+		record->islands,
+		record->real_change);
+	for (i = 0; i < SAVED_HISTORY_ADDRESS_NUM; i++) {
+		printk(KERN_INFO "%pf real_addr[%p]\n",
+			record->address[i],
+			record->address[i]);
+	}
+}
+
+int verify_stack_ok(unsigned int *good_ebp, unsigned int *_ebp)
+{
+	return ((unsigned int)_ebp & 0xffffe000) ==
+		((unsigned int)good_ebp & 0xffffe000);
+}
+
+size_t backtrace_safe(void **array, size_t max_size)
+{
+	unsigned int *_ebp, *base_ebp;
+	unsigned int *caller;
+	unsigned int i;
+
+	asm ("movl %%ebp, %0"
+		: "=r" (_ebp)
+	    );
+
+	base_ebp = _ebp;
+	caller = (unsigned int *) *(_ebp+1);
+
+	for (i = 0; i < max_size; i++)
+		array[i] = 0;
+	for (i = 0; i < max_size; i++) {
+		array[i] = caller;
+		_ebp = (unsigned int *) *_ebp;
+		if (!verify_stack_ok(base_ebp, _ebp))
+			break;
+		caller = (unsigned int *) *(_ebp+1);
+	}
+
+	return i + 1;
+}
+
+void dump_nc_power_history(void)
+{
+	int i, start;
+	unsigned int total = atomic_read(&saved_nc_power_history_current);
+
+	start = total % SAVED_HISTORY_NUM;
+	printk(KERN_INFO "<----current timestamp\n");
+	printk(KERN_INFO "start[%d] saved[%d]\n",
+			start, total);
+	for (i = start; i >= 0; i--)
+		print_saved_record(&all_history[i]);
+	for (i = SAVED_HISTORY_NUM - 1; i > start; i--)
+		print_saved_record(&all_history[i]);
+}
+EXPORT_SYMBOL(dump_nc_power_history);
+
+static ssize_t debug_read_history(struct file *file, char __user *buffer,
+			size_t count, loff_t *pos)
+{
+	dump_nc_power_history();
+
+	return 0;
+}
+
+static ssize_t debug_write_read_history_entry(struct file *file,
+		const char __user *buffer, size_t count, loff_t *pos)
+{
+	char buf[20] = "0";
+	unsigned long len = min(sizeof(buf) - 1, count);
+	u32 islands;
+	u32 on;
+	int ret;
+
+	/*do nothing if platform is nether medfield or clv*/
+	if (!platform_is(INTEL_ATOM_MFLD) && !platform_is(INTEL_ATOM_CLV))
+		return count;
+
+	if (copy_from_user(buf, buffer, len))
+		return -1;
+
+	buf[len] = 0;
+
+	ret = sscanf(buf, "%x%x", &islands, &on);
+	if (ret == 2)
+		pmu_nc_set_power_state(islands, on, OSPM_REG_TYPE);
+
+	return count;
+}
+
+static const struct file_operations proc_debug_operations = {
+	.owner	= THIS_MODULE,
+	.read	= debug_read_history,
+	.write	= debug_write_read_history_entry,
+};
+
+static int __init debug_read_history_entry(void)
+{
+	struct proc_dir_entry *res = NULL;
+
+	res = proc_create("debug_read_history", S_IRUGO | S_IWUSR, NULL,
+		&proc_debug_operations);
+
+	if (!res)
+		return -ENOMEM;
+
+	return 0;
+}
+device_initcall(debug_read_history_entry);
+
+/**
+ * pmu_nc_set_power_state - Callback function is used by all the devices
+ * in north complex for a platform  specific device power on/shutdown.
+ * Following assumptions are made by this function
+ *
+ * Every new request starts from scratch with no assumptions
+ * on previous/pending request to Punit.
+ * Caller is responsible to retry if request fails.
+ * Avoids multiple requests to Punit if target state is
+ * already in the expected state.
+ * spin_locks guarantee serialized access to these registers
+ * and avoid concurrent access from 2d/3d, VED, VEC, ISP & IPH.
+ *
+ */
+int pmu_nc_set_power_state(int islands, int state_type, int reg)
+{
+	unsigned long flags;
+	struct saved_nc_power_history *record = NULL;
+	int ret = 0;
+	int change;
+
+	spin_lock_irqsave(&mid_pmu_cxt->nc_ready_lock, flags);
+
+	record = get_new_record_history();
+	record->cpu = raw_smp_processor_id();
+	record->ts = cpu_clock(record->cpu);
+	record->islands = islands;
+	record->pci = 0;
+	record->state_type = state_type;
+	backtrace_safe(record->address, SAVED_HISTORY_ADDRESS_NUM);
+	record->real_change = 0;
+	record->reg_type = reg;
+
+	if (pmu_ops->nc_set_power_state)	{
+		ret = pmu_ops->nc_set_power_state(islands, state_type,
+								reg, &change);
+		if (change) {
+			record->real_change = 1;
+			record->ts = cpu_clock(record->cpu);
+		}
+	}
+
+	spin_unlock_irqrestore(&mid_pmu_cxt->nc_ready_lock, flags);
+	return ret;
+}
+EXPORT_SYMBOL(pmu_nc_set_power_state);
+
+/**
+ * pmu_nc_get_power_state - Callback function is used to
+ * query power status of all the devices in north complex.
+ * Following assumptions are made by this function
+ *
+ * Every new request starts from scratch with no assumptions
+ * on previous/pending request to Punit.
+ * Caller is responsible to retry if request fails.
+ * Avoids multiple requests to Punit if target state is
+ * already in the expected state.
+ * spin_locks guarantee serialized access to these registers
+ * and avoid concurrent access from 2d/3d, VED, VEC, ISP & IPH.
+ *
+ */
+int pmu_nc_get_power_state(int island, int reg_type)
+{
+	u32 pwr_sts;
+	unsigned long flags;
+	int i, lss;
+	int ret = -EINVAL;
+
+	/*do nothing if platform is nether medfield or clv*/
+	if (!platform_is(INTEL_ATOM_MFLD) && !platform_is(INTEL_ATOM_CLV))
+		return 0;
+
+	spin_lock_irqsave(&mid_pmu_cxt->nc_ready_lock, flags);
+
+	switch (reg_type) {
+	case APM_REG_TYPE:
+		pwr_sts = inl(mid_pmu_cxt->apm_base + APM_STS);
+		break;
+	case OSPM_REG_TYPE:
+		pwr_sts = inl(mid_pmu_cxt->ospm_base + OSPM_PM_SSS);
+		break;
+	default:
+		pr_err("%s: invalid argument 'island': %d.\n",
+				 __func__, island);
+		goto unlock;
+	}
+
+	for (i = 0; i < OSPM_MAX_POWER_ISLANDS; i++) {
+		lss = island & (0x1 << i);
+		if (lss) {
+			ret = (pwr_sts >> (2 * i)) & 0x3;
+			break;
+		}
+	}
+
+unlock:
+	spin_unlock_irqrestore(&mid_pmu_cxt->nc_ready_lock, flags);
+	return ret;
+}
+EXPORT_SYMBOL(pmu_nc_get_power_state);
+
+/*
+* update_dev_res - Calulates & Updates the device residency when
+* a device state change occurs.
+* Computation of respective device residency starts when
+* its first state tranisition happens after the pmu driver
+* is initialised.
+*
+*/
+void update_dev_res(int index, pci_power_t state)
+{
+	if (state != PCI_D0) {
+		if (mid_pmu_cxt->pmu_dev_res[index].start == 0) {
+			mid_pmu_cxt->pmu_dev_res[index].start = cpu_clock(0);
+			mid_pmu_cxt->pmu_dev_res[index].d0i3_entry =
+				mid_pmu_cxt->pmu_dev_res[index].start;
+				mid_pmu_cxt->pmu_dev_res[index].d0i0_acc = 0;
+		} else{
+			mid_pmu_cxt->pmu_dev_res[index].d0i3_entry =
+							cpu_clock(0);
+			mid_pmu_cxt->pmu_dev_res[index].d0i0_acc +=
+			(mid_pmu_cxt->pmu_dev_res[index].d0i3_entry -
+				 mid_pmu_cxt->pmu_dev_res[index].d0i0_entry);
+		}
+	} else {
+		if (mid_pmu_cxt->pmu_dev_res[index].start == 0) {
+			mid_pmu_cxt->pmu_dev_res[index].start =
+						 cpu_clock(0);
+			mid_pmu_cxt->pmu_dev_res[index].d0i0_entry
+				= mid_pmu_cxt->pmu_dev_res[index].start;
+			mid_pmu_cxt->pmu_dev_res[index].d0i3_acc = 0;
+		} else {
+			mid_pmu_cxt->pmu_dev_res[index].d0i0_entry =
+						 cpu_clock(0);
+			mid_pmu_cxt->pmu_dev_res[index].d0i3_acc +=
+			(mid_pmu_cxt->pmu_dev_res[index].d0i0_entry -
+			mid_pmu_cxt->pmu_dev_res[index].d0i3_entry);
+		}
+	}
+	mid_pmu_cxt->pmu_dev_res[index].state = state;
+}
+
+/**
+ * pmu_pci_set_power_state - Callback function is used by all the PCI devices
+ *			for a platform  specific device power on/shutdown.
+ *
+ */
+int __ref pmu_pci_set_power_state(struct pci_dev *pdev, pci_power_t state)
+{
+	u32 new_value;
+	int i = 0;
+	u32 pm_cmd_val, chk_val;
+	int sub_sys_pos, sub_sys_index;
+	int pmu_num;
+	struct pmu_ss_states cur_pmssc;
+	int status = 0;
+	int retry_times = 0;
+	ktime_t calltime, delta, rettime;
+	struct saved_nc_power_history *record = NULL;
+	bool d3_cold = false;
+
+	/* Ignore callback from devices until we have initialized */
+	if (unlikely((!pmu_initialized)))
+		return 0;
+
+	might_sleep();
+
+	/* Try to acquire the scu_ready_sem, if not
+	 * get blocked, until pmu_sc_irq() releases */
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	/*get LSS index corresponding to pdev, its position in
+	 *32 bit register and its register numer*/
+	status =
+		pmu_pci_to_indexes(pdev, &i, &pmu_num,
+				&sub_sys_index,  &sub_sys_pos);
+
+	if (status)
+		goto unlock;
+
+	if (pci_need_record_power_state(pdev)) {
+		record = get_new_record_history();
+		record->cpu = raw_smp_processor_id();
+		record->ts = cpu_clock(record->cpu);
+		record->islands = 0;
+		record->reg_type = 0;
+		record->pci = pdev->device;
+		record->state_type = state;
+		backtrace_safe(record->address, SAVED_HISTORY_ADDRESS_NUM);
+		record->real_change = 0;
+	}
+
+	/* Ignore HDMI HPD driver d0ix on LSS 0 on MRFLD */
+	if (platform_is(INTEL_ATOM_MRFLD) &&
+			pdev->device == MID_MRFL_HDMI_DRV_DEV_ID)
+			goto unlock;
+
+	/*in case a LSS is assigned to more than one pdev, we need
+	  *to find the shallowest state the LSS should be put into*/
+	state = pmu_pci_get_weakest_state_for_lss(i, pdev, state);
+
+	/*If the LSS corresponds to northcomplex device, update
+	  *the status and return*/
+	if (update_nc_device_states(i, state)) {
+		if (mid_pmu_cxt->pmu_dev_res[i].state == state)
+			goto nc_done;
+		else {
+			if (i < MAX_DEVICES)
+				update_dev_res(i, state);
+			goto nc_done;
+		}
+	}
+
+	/* initialize the current pmssc states */
+	memset(&cur_pmssc, 0, sizeof(cur_pmssc));
+
+	status = _pmu2_wait_not_busy();
+
+	if (status)
+		goto unlock;
+
+	pmu_read_sss(&cur_pmssc);
+
+	/* Read the pm_cmd val & update the value */
+	pm_cmd_val =
+		(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+
+	/* First clear the LSS bits */
+	new_value = cur_pmssc.pmu2_states[sub_sys_index] &
+						(~pm_cmd_val);
+	mid_pmu_cxt->os_sss[sub_sys_index] &= ~pm_cmd_val;
+
+	if (state != PCI_D0) {
+		pm_cmd_val =
+			(pci_to_platform_state(state) <<
+				(sub_sys_pos * BITS_PER_LSS));
+
+		new_value |= pm_cmd_val;
+
+		mid_pmu_cxt->os_sss[sub_sys_index] |= pm_cmd_val;
+	}
+
+	new_value &= ~mid_pmu_cxt->ignore_lss[sub_sys_index];
+
+	/* nothing to do, so dont do it... */
+	if (new_value == cur_pmssc.pmu2_states[sub_sys_index])
+		goto unlock;
+
+	cur_pmssc.pmu2_states[sub_sys_index] = new_value;
+
+	/* Check if the state is D3_cold or D3_Hot in TNG platform*/
+	if (platform_is(INTEL_ATOM_MRFLD) && (state == PCI_D3cold))
+		d3_cold = true;
+
+	/* Issue the pmu command to PMU 2
+	 * flag is needed to distinguish between
+	 * S0ix vs interactive command in pmu_sc_irq()
+	 */
+	status = pmu_issue_interactive_command(&cur_pmssc, false, d3_cold);
+
+	if (unlikely(status != PMU_SUCCESS)) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+			 "Failed to Issue a PM command to PMU2\n");
+		goto unlock;
+	}
+
+	calltime = ktime_get();
+retry:
+	/*
+	 * Wait for interactive command to complete.
+	 * If we dont wait, there is a possibility that
+	 * the driver may access the device before its
+	 * powered on in SCU.
+	 *
+	 */
+	status = _pmu2_wait_not_busy_yield();
+	if (unlikely(status)) {
+		rettime = ktime_get();
+		delta = ktime_sub(rettime, calltime);
+		retry_times++;
+
+		printk(KERN_CRIT "%s: D0ix transition failure: %04x %04X %s %20s:\n",
+				__func__,
+				pdev->vendor, pdev->device,
+				dev_name(&pdev->dev),
+				dev_driver_string(&pdev->dev));
+		printk(KERN_CRIT "interrupt pending = %d\n",
+				pmu_interrupt_pending());
+		printk(KERN_CRIT "pmu_busy_status = %d\n",
+				_pmu_read_status(PMU_BUSY_STATUS));
+		printk(KERN_CRIT "suspend_started = %d\n",
+				mid_pmu_cxt->suspend_started);
+		printk(KERN_CRIT "shutdown_started = %d\n",
+				mid_pmu_cxt->shutdown_started);
+		printk(KERN_CRIT "camera_off = %d display_off = %d\n",
+				mid_pmu_cxt->camera_off,
+				mid_pmu_cxt->display_off);
+		printk(KERN_CRIT "s0ix_possible = 0x%x\n",
+				mid_pmu_cxt->s0ix_possible);
+		printk(KERN_CRIT "s0ix_entered = 0x%x\n",
+				mid_pmu_cxt->s0ix_entered);
+		printk(KERN_CRIT "pmu_current_state = %d\n",
+				mid_pmu_cxt->pmu_current_state);
+		printk(KERN_CRIT "PMU is BUSY! retry_times[%d] total_delay[%lli]ms. Retry ...\n",
+				retry_times, (long long) ktime_to_ms(delta));
+		pmu_dump_logs();
+
+		trigger_all_cpu_backtrace();
+		if (retry_times < 60)
+			goto retry;
+		else
+			BUG();
+	}
+	if (record) {
+		record->real_change = 1;
+		record->ts = cpu_clock(record->cpu);
+	}
+
+	if (pmu_ops->set_power_state_ops)
+		pmu_ops->set_power_state_ops(state);
+
+	/* update stats */
+	inc_d0ix_stat((i-mid_pmu_cxt->pmu1_max_devs),
+				pci_to_platform_state(state));
+
+	/* check if tranisition to requested state has happened */
+	pmu_read_sss(&cur_pmssc);
+
+	chk_val = cur_pmssc.pmu2_states[sub_sys_index] &
+		(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+	new_value &= (D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+
+	if ((chk_val == new_value) && (i < MAX_DEVICES))
+		update_dev_res(i, state);
+
+	WARN_ON(chk_val != new_value);
+
+nc_done:
+#if !IS_ENABLED(CONFIG_VIDEO_ATOMISP)
+	/* ATOMISP is always powered up on system-resume path. It needs
+	 * to be turned off here if there is no driver to do it. */
+	if (!mid_pmu_cxt->camera_off) {
+		/* power down isp */
+		pmu_nc_set_power_state(APM_ISP_ISLAND | APM_IPH_ISLAND,
+				       OSPM_ISLAND_DOWN, APM_REG_TYPE);
+		/* power down DPHY */
+		new_value = intel_mid_msgbus_read32(0x09, 0x03);
+		new_value |= 0x300;
+		intel_mid_msgbus_write32(0x09, 0x03, new_value);
+		mid_pmu_cxt->camera_off = true;
+	}
+#endif
+
+	/* FIXME:: If S0ix is enabled when North Complex is ON we see
+	 * Fabric errors, tracked in BZ: 115181, hence hold pm_qos
+	 * to restrict s0ix during North Island in D0i0
+	 */
+	if (nc_device_state()) {
+		if (!pm_qos_request_active(mid_pmu_cxt->nc_restrict_qos))
+			pm_qos_add_request(mid_pmu_cxt->nc_restrict_qos,
+			 PM_QOS_CPU_DMA_LATENCY, (CSTATE_EXIT_LATENCY_S0i1-1));
+	} else {
+		if (pm_qos_request_active(mid_pmu_cxt->nc_restrict_qos))
+			pm_qos_remove_request(mid_pmu_cxt->nc_restrict_qos);
+	}
+
+unlock:
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return status;
+}
+
+pci_power_t platfrom_pmu_choose_state(int lss)
+{
+	pci_power_t state = PCI_D3hot;
+
+	if (pmu_ops->pci_choose_state)
+		state = pmu_ops->pci_choose_state(lss);
+
+	return state;
+}
+
+/* return platform specific deepest states that the device can enter */
+pci_power_t pmu_pci_choose_state(struct pci_dev *pdev)
+{
+	int i;
+	int sub_sys_pos, sub_sys_index;
+	int status;
+	int device_lss;
+	int pmu_num;
+
+	pci_power_t state = PCI_D3hot;
+
+	if (pmu_initialized) {
+		status =
+		pmu_pci_to_indexes(pdev, &i, &pmu_num,
+					&sub_sys_index,  &sub_sys_pos);
+
+		if ((status == PMU_SUCCESS) &&
+			(pmu_num == PMU_NUM_2)) {
+
+			device_lss =
+				(sub_sys_index * mid_pmu_cxt->ss_per_reg) +
+								sub_sys_pos;
+
+			state = platfrom_pmu_choose_state(device_lss);
+		}
+	}
+
+	return state;
+}
+
+int pmu_issue_interactive_command(struct pmu_ss_states *pm_ssc, bool ioc,
+					bool d3_cold)
+{
+	u32 command;
+
+	if (_pmu2_wait_not_busy()) {
+		dev_err(&mid_pmu_cxt->pmu_dev->dev,
+			"SCU BUSY. Operation not permitted\n");
+		return PMU_FAILED;
+	}
+
+	/* enable interrupts in PMU2 so that interrupts are
+	 * propagated when ioc bit for a particular set
+	 * command is set
+	 */
+	/* Enable the hardware interrupt */
+	if (ioc)
+		pmu_set_interrupt_enable();
+
+	/* Configure the sub systems for pmu2 */
+	pmu_write_subsys_config(pm_ssc);
+
+	command = (ioc) ? INTERACTIVE_IOC_VALUE : INTERACTIVE_VALUE;
+
+	 /* Special handling for PCI_D3cold in Tangier */
+	if (d3_cold)
+		command |= PM_CMD_D3_COLD;
+
+	/* send interactive command to SCU */
+	writel(command, &mid_pmu_cxt->pmu_reg->pm_cmd);
+
+	pmu_log_command(command, pm_ssc);
+
+	return 0;
+}
+
+/* Reads the status of each driver and updates the LSS values.
+ * To be called with scu_ready_sem mutex held, and pmu_config
+ * initialized with '0's
+ */
+static void update_all_lss_states(struct pmu_ss_states *pmu_config)
+{
+	int i;
+	u32 PCIALLDEV_CFG[4] = {0, 0, 0, 0};
+
+	if (platform_is(INTEL_ATOM_MFLD) || platform_is(INTEL_ATOM_CLV)) {
+		for (i = 0; i < MAX_DEVICES; i++) {
+			int pmu_num = get_mid_pci_pmu_num(i);
+			struct pci_dev *pdev = get_mid_pci_drv(i, 0);
+
+			if ((pmu_num == PMU_NUM_2) && pdev) {
+				int ss_idx, ss_pos;
+				pci_power_t state;
+
+				ss_idx = get_mid_pci_ss_idx(i);
+				ss_pos = get_mid_pci_ss_pos(i);
+				state = pdev->current_state;
+				/* The case of device not probed yet:
+				 * Force D0i3 */
+				if (state == PCI_UNKNOWN)
+					state = pmu_pci_choose_state(pdev);
+
+				/* By default its set to '0' hence
+				 * no need to update PCI_D0 state
+				 */
+				state = pmu_pci_get_weakest_state_for_lss
+							(i, pdev, state);
+
+				pmu_config->pmu2_states[ss_idx] |=
+				 (pci_to_platform_state(state) <<
+					(ss_pos * BITS_PER_LSS));
+
+				PCIALLDEV_CFG[ss_idx] |=
+					(D0I3_MASK << (ss_pos * BITS_PER_LSS));
+			}
+		}
+	}
+
+	platform_update_all_lss_states(pmu_config, PCIALLDEV_CFG);
+}
+
+static int pmu_init(void)
+{
+	int status;
+	struct pmu_ss_states pmu_config;
+	struct pmu_suspend_config *ss_config;
+	int ret = 0;
+	int retry_times = 0;
+
+
+	dev_dbg(&mid_pmu_cxt->pmu_dev->dev, "PMU Driver loaded\n");
+	spin_lock_init(&mid_pmu_cxt->nc_ready_lock);
+
+	/* enumerate the PCI configuration space */
+	pmu_enumerate();
+
+	/* initialize the stats for pmu driver */
+	pmu_stats_init();
+
+	/* register platform pmu ops */
+	platform_set_pmu_ops();
+
+	/* platform specific initialization */
+	if (pmu_ops->init) {
+		status = pmu_ops->init();
+		if (status) {
+			dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+				"pmu_ops->init failed\n");
+			goto out_err1;
+		}
+	}
+
+	/* initialize the state variables here */
+	ss_config = kzalloc(sizeof(struct pmu_suspend_config), GFP_KERNEL);
+
+	if (ss_config == NULL) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+			"Allocation of memory for ss_config has failed\n");
+		status = PMU_FAILED;
+		goto out_err1;
+	}
+
+	memset(&pmu_config, 0, sizeof(pmu_config));
+
+	ss_config->ss_state = pmu_config;
+
+	/* initialize for the autonomous S0i3 */
+	mid_pmu_cxt->ss_config = ss_config;
+
+	/* setup the wake capable devices */
+	mid_pmu_cxt->ss_config->wake_state.wake_enable[0] = WAKE_ENABLE_0;
+	mid_pmu_cxt->ss_config->wake_state.wake_enable[1] = WAKE_ENABLE_1;
+
+	/* setup the ignore lss list */
+	mid_pmu_cxt->ignore_lss[0] = pmu_ignore_lss0;
+	mid_pmu_cxt->ignore_lss[1] = pmu_ignore_lss1;
+	mid_pmu_cxt->ignore_lss[2] = pmu_ignore_lss2;
+	mid_pmu_cxt->ignore_lss[3] = pmu_ignore_lss3;
+
+	/*set wkc to appropriate value suitable for s0ix*/
+	writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[0],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[0]);
+	writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[1],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[1]);
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	/* Now we have initialized the driver
+	 * Allow drivers to get blocked in
+	 * pmu_pci_set_power_state(), until we finish
+	 * first interactive command.
+	 */
+
+	pmu_initialized = true;
+
+	/* get the current status of each of the driver
+	 * and update it in SCU
+	 */
+	update_all_lss_states(&pmu_config);
+
+	status = pmu_issue_interactive_command(&pmu_config, false,
+						false);
+	if (status != PMU_SUCCESS) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,\
+		 "Failure from pmu mode change to interactive."
+		" = %d\n", status);
+		status = PMU_FAILED;
+		up(&mid_pmu_cxt->scu_ready_sem);
+		goto out_err2;
+	}
+
+	/*
+	 * Wait for interactive command to complete.
+	 * If we dont wait, there is a possibility that
+	 * the driver may access the device before its
+	 * powered on in SCU.
+	 *
+	 */
+retry:
+	ret = _pmu2_wait_not_busy();
+	if (unlikely(ret)) {
+		retry_times++;
+		if (retry_times < 60) {
+			usleep_range(10, 500);
+			goto retry;
+		} else {
+			pmu_dump_logs();
+			BUG();
+		}
+	}
+
+	/* In cases were gfx is not enabled
+	 * this will enable s0ix immediately
+	 */
+	if (pmu_ops->set_power_state_ops)
+		pmu_ops->set_power_state_ops(PCI_D3hot);
+
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return PMU_SUCCESS;
+
+out_err2:
+	kfree(ss_config);
+	mid_pmu_cxt->ss_config = NULL;
+out_err1:
+	return status;
+}
+
+/**
+ * mid_pmu_probe - This is the function where most of the PMU driver
+ *		   initialization happens.
+ */
+static int
+mid_pmu_probe(struct pci_dev *dev, const struct pci_device_id *pci_id)
+{
+	int ret;
+	struct mrst_pmu_reg __iomem *pmu;
+	u32 data;
+
+	mid_pmu_cxt->pmu_wake_lock =
+				wakeup_source_register("pmu_wake_lock");
+
+	if (!mid_pmu_cxt->pmu_wake_lock) {
+		pr_err("%s: unable to register pmu wake source.\n", __func__);
+		return -ENOMEM;
+	}
+
+	/* Init the device */
+	ret = pci_enable_device(dev);
+	if (ret) {
+		pr_err("Mid PM device cant be enabled\n");
+		goto out_err0;
+	}
+
+	/* store the dev */
+	mid_pmu_cxt->pmu_dev = dev;
+	dev_warn(&dev->dev, "PMU DRIVER Probe called\n");
+
+	ret = pci_request_regions(dev, PMU_DRV_NAME);
+	if (ret < 0) {
+		pr_err("pci request region has failed\n");
+		goto out_err1;
+	}
+
+	mid_pmu_cxt->pmu1_max_devs = PMU1_MAX_DEVS;
+	mid_pmu_cxt->pmu2_max_devs = PMU2_MAX_DEVS;
+	mid_pmu_cxt->ss_per_reg = 16;
+
+	/* Following code is used to map address required for NC PM
+	 * which is not needed for all platforms
+	 */
+	if (platform_is(INTEL_ATOM_MFLD) || platform_is(INTEL_ATOM_CLV)) {
+		data = intel_mid_msgbus_read32(OSPM_PUNIT_PORT, OSPM_APMBA);
+		mid_pmu_cxt->apm_base = data & 0xffff;
+
+		data = intel_mid_msgbus_read32(OSPM_PUNIT_PORT, OSPM_OSPMBA);
+		mid_pmu_cxt->ospm_base = data & 0xffff;
+	}
+
+	/* Map the memory of pmu1 PMU reg base */
+	pmu = pci_iomap(dev, 0, 0);
+	if (pmu == NULL) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+				"Unable to map the PMU2 address space\n");
+		ret = PMU_FAILED;
+		goto out_err2;
+	}
+
+	mid_pmu_cxt->pmu_reg = pmu;
+
+	/* Map the memory of emergency emmc up */
+	mid_pmu_cxt->emergeny_emmc_up_addr =
+		ioremap_nocache(PMU_PANIC_EMMC_UP_ADDR, 4);
+	if (mid_pmu_cxt->emergeny_emmc_up_addr == NULL) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+		"Unable to map the emergency emmc up address space\n");
+		ret = PMU_FAILED;
+		goto out_err3;
+	}
+
+	if (request_irq(dev->irq, pmu_sc_irq, IRQF_NO_SUSPEND, PMU_DRV_NAME,
+			NULL)) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev, "Registering isr has failed\n");
+		ret = PMU_FAILED;
+		goto out_err4;
+	}
+
+	/* call pmu init() for initialization of pmu interface */
+	ret = pmu_init();
+	if (ret != PMU_SUCCESS) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev, "PMU initialization has failed\n");
+		goto out_err5;
+	}
+	dev_warn(&mid_pmu_cxt->pmu_dev->dev, "after pmu initialization\n");
+
+	mid_pmu_cxt->pmu_init_time =
+		cpu_clock(raw_smp_processor_id());
+
+#ifdef CONFIG_PM_DEBUG
+	/*
+	 * FIXME: Since S3 is not enabled yet we need to take
+	 * a wake lock here. Else S3 will be triggered on display
+	 * time out and platform will hang
+	 */
+	if (platform_is(INTEL_ATOM_MRFLD) && !enable_s3)
+		__pm_stay_awake(mid_pmu_cxt->pmu_wake_lock);
+#endif
+
+	return 0;
+
+out_err5:
+	free_irq(dev->irq, &pmu_sc_irq);
+out_err4:
+	iounmap(mid_pmu_cxt->emergeny_emmc_up_addr);
+	mid_pmu_cxt->emergeny_emmc_up_addr = NULL;
+out_err3:
+	iounmap(mid_pmu_cxt->pmu_reg);
+	mid_pmu_cxt->base_addr.pmu1_base = NULL;
+	mid_pmu_cxt->base_addr.pmu2_base = NULL;
+out_err2:
+	pci_release_region(dev, 0);
+out_err1:
+	pci_disable_device(dev);
+out_err0:
+	wakeup_source_unregister(mid_pmu_cxt->pmu_wake_lock);
+	return ret;
+}
+
+static void mid_pmu_remove(struct pci_dev *dev)
+{
+	/* Freeing up the irq */
+	free_irq(dev->irq, &pmu_sc_irq);
+
+	if (pmu_ops->remove)
+		pmu_ops->remove();
+
+	iounmap(mid_pmu_cxt->emergeny_emmc_up_addr);
+	mid_pmu_cxt->emergeny_emmc_up_addr = NULL;
+
+	pci_iounmap(dev, mid_pmu_cxt->pmu_reg);
+	mid_pmu_cxt->base_addr.pmu1_base = NULL;
+	mid_pmu_cxt->base_addr.pmu2_base = NULL;
+
+	/* disable the current PCI device */
+	pci_release_region(dev, 0);
+	pci_disable_device(dev);
+
+	wakeup_source_unregister(mid_pmu_cxt->pmu_wake_lock);
+}
+
+static void mid_pmu_shutdown(struct pci_dev *dev)
+{
+	dev_dbg(&mid_pmu_cxt->pmu_dev->dev, "Mid PM mid_pmu_shutdown called\n");
+
+	if (mid_pmu_cxt) {
+		/* Restrict platform Cx state to C6 */
+		pm_qos_update_request(mid_pmu_cxt->s3_restrict_qos,
+					(CSTATE_EXIT_LATENCY_S0i1-1));
+
+		down(&mid_pmu_cxt->scu_ready_sem);
+		mid_pmu_cxt->shutdown_started = true;
+		up(&mid_pmu_cxt->scu_ready_sem);
+	}
+}
+
+static struct pci_driver driver = {
+	.name = PMU_DRV_NAME,
+	.id_table = mid_pm_ids,
+	.probe = mid_pmu_probe,
+	.remove = mid_pmu_remove,
+	.shutdown = mid_pmu_shutdown
+};
+
+static int standby_enter(void)
+{
+	u32 temp = 0;
+	int s3_state = mid_state_to_sys_state(MID_S3_STATE);
+
+	if (mid_s0ix_enter(MID_S3_STATE) != MID_S3_STATE) {
+		pmu_set_s0ix_complete();
+		return -EINVAL;
+	}
+
+	/* time stamp for end of s3 entry */
+	time_stamp_for_sleep_state_latency(s3_state, false, true);
+
+	__monitor((void *) &temp, 0, 0);
+	smp_mb();
+	__mwait(mid_pmu_cxt->s3_hint, 1);
+
+	/* time stamp for start of s3 exit */
+	time_stamp_for_sleep_state_latency(s3_state, true, false);
+
+	pmu_set_s0ix_complete();
+
+	/*set wkc to appropriate value suitable for s0ix*/
+	writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[0],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[0]);
+	writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[1],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[1]);
+
+	if (platform_is(INTEL_ATOM_MRFLD))
+		up(&mid_pmu_cxt->scu_ready_sem);
+
+	return 0;
+}
+
+static int mid_suspend_begin(suspend_state_t state)
+{
+	mid_pmu_cxt->suspend_started = true;
+	pmu_s3_stats_update(1);
+
+	/* Restrict to C6 during suspend */
+	pm_qos_update_request(mid_pmu_cxt->s3_restrict_qos,
+					(CSTATE_EXIT_LATENCY_S0i1-1));
+	return 0;
+}
+
+static int mid_suspend_valid(suspend_state_t state)
+{
+	int ret = 0;
+
+	switch (state) {
+	case PM_SUSPEND_ON:
+	case PM_SUSPEND_MEM:
+		/* check if we are ready */
+		if (likely(pmu_initialized))
+			ret = 1;
+	break;
+	}
+
+	return ret;
+}
+
+static int mid_suspend_prepare(void)
+{
+	return 0;
+}
+
+static int mid_suspend_prepare_late(void)
+{
+	return 0;
+}
+
+static int mid_suspend_enter(suspend_state_t state)
+{
+	int ret;
+
+	if (state != PM_SUSPEND_MEM)
+		return -EINVAL;
+
+	/* one last check before entering standby */
+	if (pmu_ops->check_nc_sc_status) {
+		if (!(pmu_ops->check_nc_sc_status())) {
+			trace_printk("Device d0ix status check failed! Aborting Standby entry!\n");
+			WARN_ON(1);
+		}
+	}
+
+	trace_printk("s3_entry\n");
+	ret = standby_enter();
+	trace_printk("s3_exit %d\n", ret);
+	if (ret != 0)
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+				"Failed to enter S3 status: %d\n", ret);
+
+	return ret;
+}
+
+static void mid_suspend_end(void)
+{
+	/* allow s0ix now */
+	pm_qos_update_request(mid_pmu_cxt->s3_restrict_qos,
+					PM_QOS_DEFAULT_VALUE);
+
+	pmu_s3_stats_update(0);
+	mid_pmu_cxt->suspend_started = false;
+}
+
+static const struct platform_suspend_ops mid_suspend_ops = {
+	.begin = mid_suspend_begin,
+	.valid = mid_suspend_valid,
+	.prepare = mid_suspend_prepare,
+	.prepare_late = mid_suspend_prepare_late,
+	.enter = mid_suspend_enter,
+	.end = mid_suspend_end,
+};
+
+/**
+ * mid_pci_register_init - register the PMU driver as PCI device
+ */
+static int __init mid_pci_register_init(void)
+{
+	int ret;
+
+	mid_pmu_cxt = kzalloc(sizeof(struct mid_pmu_dev), GFP_KERNEL);
+
+	if (mid_pmu_cxt == NULL)
+		return -ENOMEM;
+
+	mid_pmu_cxt->s3_restrict_qos =
+		kzalloc(sizeof(struct pm_qos_request), GFP_KERNEL);
+	if (mid_pmu_cxt->s3_restrict_qos) {
+		pm_qos_add_request(mid_pmu_cxt->s3_restrict_qos,
+			 PM_QOS_CPU_DMA_LATENCY, PM_QOS_DEFAULT_VALUE);
+	} else {
+		return -ENOMEM;
+	}
+
+	init_nc_device_states();
+
+	mid_pmu_cxt->nc_restrict_qos =
+		kzalloc(sizeof(struct pm_qos_request), GFP_KERNEL);
+	if (mid_pmu_cxt->nc_restrict_qos == NULL)
+		return -ENOMEM;
+
+	/* initialize the semaphores */
+	sema_init(&mid_pmu_cxt->scu_ready_sem, 1);
+
+	/* registering PCI device */
+	ret = pci_register_driver(&driver);
+	suspend_set_ops(&mid_suspend_ops);
+
+	return ret;
+}
+fs_initcall(mid_pci_register_init);
+
+void pmu_power_off(void)
+{
+	/* wait till SCU is ready */
+	if (!_pmu2_wait_not_busy())
+		writel(S5_VALUE, &mid_pmu_cxt->pmu_reg->pm_cmd);
+
+	if (!_pmu2_wait_not_busy())
+		rpmsg_send_generic_simple_command(IPCMSG_COLD_OFF, 1);
+}
+
+static void __exit mid_pci_cleanup(void)
+{
+	if (mid_pmu_cxt) {
+		if (mid_pmu_cxt->s3_restrict_qos)
+			pm_qos_remove_request(mid_pmu_cxt->s3_restrict_qos);
+
+		if (pm_qos_request_active(mid_pmu_cxt->nc_restrict_qos))
+			pm_qos_remove_request(mid_pmu_cxt->nc_restrict_qos);
+	}
+
+	suspend_set_ops(NULL);
+
+	/* registering PCI device */
+	pci_unregister_driver(&driver);
+
+	if (mid_pmu_cxt) {
+		pmu_stats_finish();
+		kfree(mid_pmu_cxt->ss_config);
+	}
+
+	kfree(mid_pmu_cxt);
+}
+module_exit(mid_pci_cleanup);
diff --git a/arch/x86/platform/intel-mid/intel_soc_pmu.h b/arch/x86/platform/intel-mid/intel_soc_pmu.h
new file mode 100644
index 0000000..243ae47
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_pmu.h
@@ -0,0 +1,511 @@
+/*
+ * intel_soc_pmu.h
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+#ifndef _MID_PMU_H_
+#define _MID_PMU_H_
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/delay.h>
+#include <linux/debugfs.h>
+#include <linux/seq_file.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/pci.h>
+#include <linux/semaphore.h>
+#include <linux/completion.h>
+#include <linux/spinlock.h>
+#include <linux/timer.h>
+#include <linux/jhash.h>
+#include <linux/suspend.h>
+#include <linux/workqueue.h>
+#include <linux/nmi.h>
+#include <linux/pm_qos.h>
+#include <linux/pm_wakeup.h>
+#include <asm/apic.h>
+#include <asm/intel_scu_ipc.h>
+#include <linux/intel_mid_pm.h>
+
+#include "intel_soc_mdfld.h"
+#include "intel_soc_clv.h"
+#include "intel_soc_mrfld.h"
+
+#define MID_PMU_MFLD_DRV_DEV_ID                 0x0828
+#define MID_PMU_CLV_DRV_DEV_ID			0x08EC
+#define MID_PMU_MRFL_DRV_DEV_ID			0x11A1
+
+#define MID_MRFL_HDMI_DRV_DEV_ID		0x11A6
+
+/* SRAM address where PANIC START is written */
+#define PMU_PANIC_EMMC_UP_ADDR			0xFFFF3080
+#define PMU_PANIC_EMMC_UP_REQ_CMD		0xDEADBEEF
+
+#define MAX_DEVICES	(PMU1_MAX_DEVS + PMU2_MAX_DEVS)
+#define PMU_MAX_LSS_SHARE 4
+
+#define PMU2_BUSY_TIMEOUT			500000
+#define HSU0_PCI_ID				0x81c
+#define HSU1_PCI_ID				0x81b
+#define HSI_PCI_ID				0x833
+
+#define MODE_ID_MAGIC_NUM			1
+
+#define   LOG_ID_MASK				0x7F
+#define   SUB_CLASS_MASK			0xFF00
+
+
+/* Definition for C6 Offload MSR Address */
+#define MSR_C6OFFLOAD_CTL_REG			0x120
+
+#define MSR_C6OFFLOAD_SET_LOW			1
+#define MSR_C6OFFLOAD_SET_HIGH			0
+
+#define C6OFFLOAD_BIT_MASK			0x2
+#define C6OFFLOAD_BIT				0x2
+
+#define PMU_DRV_NAME				"intel_pmu_driver"
+
+#define MID_PCI_INDEX_HASH_BITS		8 /*size 256*/
+#define MID_PCI_INDEX_HASH_SIZE		(1<<MID_PCI_INDEX_HASH_BITS)
+#define MID_PCI_INDEX_HASH_MASK		(MID_PCI_INDEX_HASH_SIZE-1)
+
+/* some random number for initvalue */
+#define	MID_PCI_INDEX_HASH_INITVALUE	0x27041975
+
+/*
+ * Values for programming the PM_CMD register based on the PM
+ * architecture speci
+*/
+
+#define S5_VALUE	0x309D2601
+#define S0I1_VALUE	0X30992601
+#define LPMP3_VALUE	0X40492601
+#define S0I3_VALUE	0X309B2601
+#define FAST_ON_OFF_VALUE	0X309E2601
+#define INTERACTIVE_VALUE	0X00002201
+#define INTERACTIVE_IOC_VALUE	0X00002301
+
+#define WAKE_ENABLE_0		0xffffffff
+#define WAKE_ENABLE_1		0xffffffff
+#define INVALID_WAKE_SRC	0xFFFF
+
+#define LOG_SS_MASK		0x80
+
+#define D0I0_MASK		0
+#define D0I1_MASK		1
+#define D0I2_MASK		2
+#define D0I3_MASK		3
+
+#define BITS_PER_LSS		2
+#define MAX_LSS_POSSIBLE	64
+#define SS_IDX_MASK		0x3
+#define SS_POS_MASK		0xF
+
+#define PMU_BASE_ADDR(pmu_num) ((pmu_num == 0) ? \
+				(u32) base_addr.pmu1_base :\
+				(u32) base_addr.pmu2_base);
+
+#define SSMSK(mask, lss) ((mask) << ((lss) * 2))
+#define SSWKC(lss) (1 << (lss))
+
+/* North Complex Power management */
+#define OSPM_PUNIT_PORT         0x04
+#define OSPM_OSPMBA             0x78
+#define OSPM_PM_SSC             0x20
+#define OSPM_PM_SSS             0x30
+
+#define OSPM_APMBA              0x7a
+#define APM_CMD                 0x0
+#define APM_STS                 0x04
+#define PM_CMD_D3_COLD		(0x1 << 21)
+
+/* Size of command logging array */
+#define LOG_SIZE	5
+
+enum sys_state {
+	SYS_STATE_S0I0,
+	SYS_STATE_S0I1,
+	SYS_STATE_LPMP3,
+	SYS_STATE_S0I2,
+	SYS_STATE_S0I3,
+	SYS_STATE_S3,
+	SYS_STATE_S5,
+	SYS_STATE_MAX
+};
+
+enum int_status {
+	INVALID_INT = 0,
+	CMD_COMPLETE_INT = 1,
+	CMD_ERROR_INT = 2,
+	WAKE_RECEIVED_INT = 3,
+	SUBSYS_POW_ERR_INT = 4,
+	S0ix_MISS_INT = 5,
+	NO_ACKC6_INT = 6,
+	TRIGGERERR = 7,
+	INVALID_SRC_INT
+};
+
+enum pmu_number {
+	PMU_NUM_1,
+	PMU_NUM_2,
+	PMU_MAX_DEVS
+};
+
+enum pmu_ss_state {
+	SS_STATE_D0I0 = 0,
+	SS_STATE_D0I1 = 1,
+	SS_STATE_D0I2 = 2,
+	SS_STATE_D0I3 = 3
+};
+
+
+struct pmu_ss_states {
+	unsigned long pmu1_states;
+	unsigned long pmu2_states[4];
+};
+
+struct pci_dev_info {
+	u8 ss_pos;
+	u8 ss_idx;
+	u8 pmu_num;
+
+	u32 log_id;
+	u32 cap;
+	struct pci_dev *drv[PMU_MAX_LSS_SHARE];
+	pci_power_t power_state[PMU_MAX_LSS_SHARE];
+};
+
+struct pmu_wake_ss_states {
+	unsigned long wake_enable[2];
+	unsigned long pmu1_wake_states;
+	unsigned long pmu2_wake_states[4];
+};
+
+struct pmu_suspend_config {
+	struct pmu_ss_states ss_state;
+	struct pmu_wake_ss_states wake_state;
+};
+
+struct pci_dev_index {
+	struct pci_dev	*pdev;
+	u8		index;
+};
+
+/* PMU register interface */
+struct mrst_pmu_reg {
+	u32 pm_sts;             /* 0x00 */
+	u32 pm_cmd;             /* 0x04 */
+	u32 pm_ics;             /* 0x08 */
+	u32 _resv1;
+	u32 pm_wkc[2];          /* 0x10 */
+	u32 pm_wks[2];          /* 0x18 */
+	u32 pm_ssc[4];          /* 0x20 */
+	u32 pm_sss[4];          /* 0x30 */
+	u32 pm_wssc[4];         /* 0x40 */
+	u32 pm_c3c4;            /* 0x50 */
+	u32 pm_c5c6;            /* 0x54 */
+	u32 pm_msic;            /* 0x58 */
+};
+
+struct mid_pmu_cmd_log {
+	struct timespec ts;
+	u32 command;
+	struct pmu_ss_states pm_ssc;
+};
+
+struct mid_pmu_irq_log {
+	struct timespec ts;
+	u32 status;
+};
+
+struct mid_pmu_ipc_log {
+	struct timespec ts;
+	u32 command;
+};
+
+struct mid_pmu_pmu_irq_log {
+	struct timespec ts;
+	u8 status;
+};
+
+struct mid_pmu_ipc_irq_log {
+	struct timespec ts;
+};
+
+union pmu_pm_status {
+	struct {
+		u32 pmu_rev:8;
+		u32 pmu_busy:1;
+		u32 mode_id:4;
+		u32 Reserved:19;
+	} pmu_status_parts;
+	u32 pmu_status_value;
+};
+
+union pmu_pm_ics {
+	struct {
+		u32 int_status:8;
+		u32 int_enable:1;
+		u32 int_pend:1;
+		/* New bit added in TNG to indicate device wakes*/
+		u32 sw_int_status:1;
+		u32 reserved:21;
+	} pmu_pm_ics_parts;
+	u32 pmu_pm_ics_value;
+};
+
+struct intel_mid_base_addr {
+	u32 *pmu1_base;
+	void __iomem *pmu2_base;
+	u32 *pm_table_base;
+	u32 __iomem *offload_reg;
+};
+
+#define MAX_PMU_LOG_STATES	(S0I3_STATE_IDX - C4_STATE_IDX + 1)
+
+struct mid_pmu_stats {
+	u64 err_count[3];
+	u64 count;
+	u64 time;
+	u64 last_entry;
+	u64 last_try;
+	u64 first_entry;
+	u32 demote_count[MAX_PMU_LOG_STATES];
+	u32 display_blocker_count;
+	u32 camera_blocker_count;
+	u32 blocker_count[MAX_LSS_POSSIBLE];
+};
+
+struct device_residency {
+	u64 d0i0_entry;
+	u64 d0i3_entry;
+	u64 d0i0_acc;
+	u64 d0i3_acc;
+	u64 start;
+	pci_power_t state;
+};
+
+struct mid_pmu_dev {
+	bool suspend_started;
+	bool shutdown_started;
+	bool camera_off;
+	bool display_off;
+
+	u32 apm_base;
+	u32 ospm_base;
+	u32 pmu1_max_devs;
+	u32 pmu2_max_devs;
+	u32 ss_per_reg;
+	u32 d0ix_stat[MAX_LSS_POSSIBLE][SS_STATE_D0I3+1];
+	u32 num_wakes[MAX_DEVICES][SYS_STATE_MAX];
+	u32 ignore_lss[4];
+	u32 os_sss[4];
+#ifdef CONFIG_PM_DEBUG
+	u32 cstate_ignore;
+	struct pm_qos_request *cstate_qos;
+#endif
+
+	u32 __iomem *emergeny_emmc_up_addr;
+	u64 pmu_init_time;
+
+	int cmd_error_int;
+	int s0ix_possible;
+	int s0ix_entered;
+
+#ifdef LOG_PMU_EVENTS
+	int cmd_log_idx;
+	int ipc_log_idx;
+	int ipc_irq_log_idx;
+	int pmu_irq_log_idx;
+#endif
+
+	enum sys_state  pmu_current_state;
+
+	struct pci_dev_info pci_devs[MAX_DEVICES];
+	struct pci_dev_index
+		pci_dev_hash[MID_PCI_INDEX_HASH_SIZE];
+	struct intel_mid_base_addr base_addr;
+	struct mrst_pmu_reg	__iomem *pmu_reg;
+	struct semaphore scu_ready_sem;
+	struct mid_pmu_stats pmu_stats[SYS_STATE_MAX];
+	struct device_residency pmu_dev_res[MAX_DEVICES];
+	struct delayed_work log_work;
+	struct pm_qos_request *s3_restrict_qos;
+
+#ifdef LOG_PMU_EVENTS
+	struct mid_pmu_cmd_log cmd_log[LOG_SIZE];
+	struct mid_pmu_ipc_log ipc_log[LOG_SIZE];
+	struct mid_pmu_ipc_irq_log ipc_irq_log[LOG_SIZE];
+	struct mid_pmu_pmu_irq_log pmu_irq_log[LOG_SIZE];
+#endif
+	struct wakeup_source *pmu_wake_lock;
+
+	struct pmu_suspend_config *ss_config;
+	struct pci_dev *pmu_dev;
+	struct pm_qos_request *nc_restrict_qos;
+
+	spinlock_t nc_ready_lock;
+
+	int s3_hint;
+};
+
+struct platform_pmu_ops {
+	int (*init)(void);
+	void (*prepare)(int);
+	bool (*enter)(int);
+	void (*wakeup)(void);
+	void (*remove)(void);
+	pci_power_t (*pci_choose_state) (int);
+	void (*set_power_state_ops) (int);
+	void (*set_s0ix_complete) (void);
+	int (*nc_set_power_state) (int, int, int, int *);
+	bool (*check_nc_sc_status) (void);
+};
+
+extern char s0ix[5];
+extern struct platform_pmu_ops mfld_pmu_ops;
+extern struct platform_pmu_ops clv_pmu_ops;
+extern struct platform_pmu_ops mrfld_pmu_ops;
+extern struct platform_pmu_ops *get_platform_ops(void);
+extern void mfld_s0ix_sram_save_cleanup(void);
+extern void pmu_stats_init(void);
+extern void pmu_s3_stats_update(int enter);
+extern void pmu_stats_finish(void);
+extern void mfld_s0ix_sram_restore(u32 s0ix);
+extern void pmu_stat_error(u8 err_type);
+extern void pmu_stat_end(void);
+extern void pmu_stat_start(enum sys_state type);
+extern int pmu_pci_to_indexes(struct pci_dev *pdev, int *index,
+				int *pmu_num, int *ss_idx, int *ss_pos);
+extern struct mid_pmu_dev *mid_pmu_cxt;
+extern void platform_set_pmu_ops(void);
+extern void pmu_read_sss(struct pmu_ss_states *pm_ssc);
+extern int pmu_issue_interactive_command(struct pmu_ss_states *pm_ssc,
+				bool ioc, bool d3_cold);
+extern int _pmu2_wait_not_busy(void);
+extern u32 get_s0ix_val_set_pm_ssc(int);
+extern int pmu_get_wake_source(void);
+extern bool pmu_initialized;
+extern struct platform_pmu_ops *pmu_ops;
+extern void platform_update_all_lss_states(struct pmu_ss_states *, int *);
+extern int set_extended_cstate_mode(const char *val, struct kernel_param *kp);
+extern int get_extended_cstate_mode(char *buffer, struct kernel_param *kp);
+extern int byt_pmu_nc_set_power_state(int islands, int state_type, int reg);
+extern int byt_pmu_nc_get_power_state(int islands, int reg);
+extern void pmu_set_interrupt_enable(void);
+extern void pmu_clear_interrupt_enable(void);
+
+#ifdef LOG_PMU_EVENTS
+extern void pmu_log_pmu_irq(int status);
+extern void pmu_log_command(u32 command, struct pmu_ss_states *pm_ssc);
+extern void pmu_dump_logs(void);
+#endif
+
+/* Accessor function for pci_devs start */
+static inline void pmu_stat_clear(void)
+{
+	mid_pmu_cxt->pmu_current_state = SYS_STATE_S0I0;
+}
+
+static inline struct pci_dev *get_mid_pci_drv(int lss_index, int i)
+{
+	return mid_pmu_cxt->pci_devs[lss_index].drv[i];
+}
+
+static inline pci_power_t get_mid_pci_power_state(int lss_index, int i)
+{
+	return mid_pmu_cxt->pci_devs[lss_index].power_state[i];
+}
+
+static inline u8 get_mid_pci_ss_idx(int lss_index)
+{
+	return mid_pmu_cxt->pci_devs[lss_index].ss_idx & SS_IDX_MASK;
+}
+
+static inline u8 get_mid_pci_ss_pos(int lss_index)
+{
+	return mid_pmu_cxt->pci_devs[lss_index].ss_pos & SS_POS_MASK;
+}
+
+static inline u8 get_mid_pci_pmu_num(int lss_index)
+{
+	return mid_pmu_cxt->pci_devs[lss_index].pmu_num;
+}
+
+static inline void set_mid_pci_drv(int lss_index,
+					int i, struct pci_dev *pdev)
+{
+	mid_pmu_cxt->pci_devs[lss_index].drv[i] = pdev;
+}
+
+static inline void set_mid_pci_power_state(int lss_index,
+					int i, pci_power_t state)
+{
+	mid_pmu_cxt->pci_devs[lss_index].power_state[i] = state;
+}
+
+static inline void set_mid_pci_ss_idx(int lss_index, u8 ss_idx)
+{
+	mid_pmu_cxt->pci_devs[lss_index].ss_idx = ss_idx;
+}
+
+static inline void set_mid_pci_ss_pos(int lss_index, u8 ss_pos)
+{
+	mid_pmu_cxt->pci_devs[lss_index].ss_pos = ss_pos;
+}
+
+static inline void set_mid_pci_pmu_num(int lss_index, u8 pmu_num)
+{
+	mid_pmu_cxt->pci_devs[lss_index].pmu_num = pmu_num;
+}
+
+static inline void set_mid_pci_log_id(int lss_index, u32 log_id)
+{
+	mid_pmu_cxt->pci_devs[lss_index].log_id = log_id;
+}
+
+static inline void set_mid_pci_cap(int lss_index, u32 cap)
+{
+	mid_pmu_cxt->pci_devs[lss_index].cap = cap;
+}
+
+static inline u32 get_d0ix_stat(int lss_index, int state)
+{
+	return mid_pmu_cxt->d0ix_stat[lss_index][state];
+}
+
+static inline void inc_d0ix_stat(int lss_index, int state)
+{
+	mid_pmu_cxt->d0ix_stat[lss_index][state]++;
+}
+
+static inline void clear_d0ix_stats(void)
+{
+	memset(mid_pmu_cxt->d0ix_stat, 0, sizeof(mid_pmu_cxt->d0ix_stat));
+}
+
+/* Accessor functions for pci_devs end */
+
+static inline bool nc_device_state(void)
+{
+	return !mid_pmu_cxt->display_off || !mid_pmu_cxt->camera_off;
+}
+
+#endif
diff --git a/arch/x86/platform/intel-mid/pmu_tng.c b/arch/x86/platform/intel-mid/pmu_tng.c
new file mode 100644
index 0000000..dd69354
--- /dev/null
+++ b/arch/x86/platform/intel-mid/pmu_tng.c
@@ -0,0 +1,218 @@
+/**************************************************************************
+ * Copyright (c) 2012, Intel Corporation.
+ * All Rights Reserved.
+
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ * Authors:
+ *    Dale B. Stimson <dale.b.stimson@intel.com>
+ *
+ */
+
+
+#include <linux/kernel.h>
+#include <linux/printk.h>
+#include <linux/delay.h>
+
+#include <asm/intel-mid.h>
+#include "pmu_tng.h"
+
+
+#if (defined DEBUG_PM_CMD) && DEBUG_PM_CMD
+const char *pm_cmd_reg_name(u32 reg_addr)
+{
+	const char *pstr;
+
+	switch (reg_addr) {
+	case GFX_SS_PM0:
+		pstr = "GFX_SS_PM0";
+		break;
+	case GFX_SS_PM1:
+		pstr = "GFX_SS_PM1";
+		break;
+	case VED_SS_PM0:
+		pstr = "VED_SS_PM0";
+		break;
+	case VED_SS_PM1:
+		pstr = "VED_SS_PM1";
+		break;
+	case VEC_SS_PM0:
+		pstr = "VEC_SS_PM0";
+		break;
+	case VEC_SS_PM1:
+		pstr = "VEC_SS_PM1";
+		break;
+	case DSP_SS_PM:
+		pstr = "DSP_SS_PM";
+		break;
+	case VSP_SS_PM0:
+		pstr = "VSP_SS_PM0";
+		break;
+	case VSP_SS_PM1:
+		pstr = "VSP_SS_PM1";
+		break;
+	case MIO_SS_PM:
+		pstr = "MIO_SS_PM";
+		break;
+	case HDMIO_SS_PM:
+		pstr = "HDMIO_SS_PM";
+		break;
+	case NC_PM_SSS:
+		pstr = "NC_PM_SSS";
+		break;
+	default:
+		pstr = "(unknown_pm_reg)";
+		break;
+	}
+
+	return pstr;
+}
+#endif /* if (defined DEBUG_PM_CMD) && DEBUG_PM_CMD */
+
+
+/**
+ * pmu_set_power_state_tng() - Send power management cmd to punit and
+ * wait for completion.
+ *
+ * This function implements Tangier/Merrifield punit-based power control.
+ *
+ * @reg_pm0 - Address of PM control register.  Example: GFX_SS_PM0
+ *
+ * @si_mask: Control bits.  "si" stands for "sub-islands".
+ * Bit mask specifying of one or more of the power islands to be affected.
+ * Each power island is a two bit field.  These bits are set for every bit
+ * in each power island to be affected by this command.
+ * For each island, either 0 or all 2 of its bits may be specified, but it
+ * is an error to specify only 1 of its bits.
+ *
+ * @ns_mask: "ns" stands for "new state".
+ * New state for bits specified by si_mask.
+ * Bits in ns_mask that are not set in si_mask are ignored.
+ * Mask of new power state for the power islands specified by si_mask.
+ * These bits are 0b00 for full power off and 0b11 for full power on.
+ * Note that other values may be specified (0b01 and 0b10).
+ *
+ * Bit field values:
+ *   TNG_SSC_I0    0b00      - i0 - power on, no clock or p[ower gating
+ *   TNG_SSC_I1    0b01      - i1 - clock gated
+ *   TNG_SSC_I2    0b01      - i2 - soft reset
+ *   TNG_SSC_D3    0b11      - d3 - power off, hw state not retained
+ *
+ * NOTE: Bit mask ns_mask is inverted from the *actual* hardware register
+ * values being used for power control.  This convention was adopted so that
+ * the API accepts 0b11 for full power-on and 0b00 for full power-off.
+ *
+ * Function return value: 0 if success, or -error_value.
+ *
+ * Example calls (ignoring return status):
+ * Turn on all gfx islands:
+ *   si_mask = GFX_SLC_LDO_SSC | GFX_SLC_SSC | GFX_SDKCK_SSC | GFX_RSCD_SSC;
+ *   ns_mask = GFX_SLC_LDO_SSC | GFX_SLC_SSC | GFX_SDKCK_SSC | GFX_RSCD_SSC;
+ *   pmu_set_power_state_tng(GFX_SS_PM0, this_mask, new_state);
+ * Turn on all gfx islands:  (Another way):
+ *   si_mask = GFX_SLC_LDO_SSC | GFX_SLC_SSC | GFX_SDKCK_SSC | GFX_RSCD_SSC;
+ *   ns_mask = 0xFFFFFFFF;
+ *   pmu_set_power_state_tng(GFX_SS_PM0, this_mask, new_state);
+ * Turn off all gfx islands:
+ *   si_mask = GFX_SLC_LDO_SSC | GFX_SLC_SSC | GFX_SDKCK_SSC | GFX_RSCD_SSC;
+ *   ns_mask = 0;
+ *   pmu_set_power_state_tng(GFX_SS_PM0, this_mask, new_state);
+ *
+ * Replaces (for Tangier):
+ *    int pmu_nc_set_power_state(int islands, int state_type, int reg_type);
+ */
+int pmu_set_power_state_tng(u32 reg_pm0, u32 si_mask, u32 ns_mask)
+{
+	u32 pwr_cur;
+	u32 pwr_val;
+	int tcount;
+
+#if (defined DEBUG_PM_CMD) && DEBUG_PM_CMD
+	u32 pwr_prev;
+	int pwr_stored;
+#endif
+
+	ns_mask &= si_mask;
+
+#if (defined DEBUG_PM_CMD) && DEBUG_PM_CMD
+	printk(KERN_ALERT "%s(\"%s\"=%#x, %#x, %#x);\n", __func__,
+		pm_cmd_reg_name(reg_pm0), reg_pm0, si_mask, ns_mask);
+#endif
+
+	pwr_cur = intel_mid_msgbus_read32(PUNIT_PORT, reg_pm0);
+
+#if (defined DEBUG_PM_CMD) && DEBUG_PM_CMD
+	printk(KERN_ALERT "%s: before: %s: read: %#x\n",
+		__func__, pm_cmd_reg_name(reg_pm0), pwr_cur);
+#endif
+	/*  Return if already in desired state. */
+	if ((((pwr_cur >> SSC_TO_SSS_SHIFT) ^ ns_mask) & si_mask) == 0)
+		return 0;
+
+	pwr_val = (pwr_cur & ~si_mask) | ns_mask;
+	intel_mid_msgbus_write32(PUNIT_PORT, reg_pm0, pwr_val);
+
+#if (defined DEBUG_PM_CMD) && DEBUG_PM_CMD
+	printk(KERN_ALERT "%s: %s: write: %#x\n",
+		__func__, pm_cmd_reg_name(reg_pm0), pwr_val);
+	pwr_prev = 0;
+	pwr_stored = 0;
+#endif
+
+	for (tcount = 0; ; tcount++) {
+		if (tcount > 50) {
+			WARN(1, "%s: P-Unit PM action request timeout",
+				__func__);
+			return -EBUSY;
+		}
+		pwr_cur = intel_mid_msgbus_read32(PUNIT_PORT, reg_pm0);
+
+#if (defined DEBUG_PM_CMD) && DEBUG_PM_CMD
+		if (!pwr_stored || (pwr_prev != pwr_cur)) {
+			printk(KERN_ALERT
+				"%s: tries=%d: %s: read: %#x\n",
+				__func__, tcount,
+				pm_cmd_reg_name(reg_pm0),
+				pwr_cur);
+			pwr_stored = 1;
+			pwr_prev = pwr_cur;
+		}
+#endif
+
+		if ((((pwr_cur >> SSC_TO_SSS_SHIFT) ^ ns_mask) & si_mask) == 0)
+			break;
+		udelay(10);
+	}
+
+	return 0;
+}
+
+static int __init pmu_nc_poweroff(void) {
+	/* Power off DPA */
+	pmu_set_power_state_tng (DSP_SS_PM, DPA_SSC, TNG_COMPOSITE_D3);
+	/* Power off MIO */
+	pmu_set_power_state_tng (MIO_SS_PM, MIO_SSC, TNG_COMPOSITE_D3);
+	/* Power off ISP */
+	pmu_set_power_state_tng (ISP_SS_PM0, ISP_SSC, TNG_COMPOSITE_D3);
+	return 0;
+}
+
+late_initcall(pmu_nc_poweroff);
+
diff --git a/arch/x86/platform/intel-mid/pmu_tng.h b/arch/x86/platform/intel-mid/pmu_tng.h
new file mode 100644
index 0000000..ef91013
--- /dev/null
+++ b/arch/x86/platform/intel-mid/pmu_tng.h
@@ -0,0 +1,180 @@
+/**************************************************************************
+ * Copyright (c) 2012, Intel Corporation.
+ * All Rights Reserved.
+
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the next
+ * paragraph) shall be included in all copies or substantial portions of the
+ * Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ * Authors:
+ *    Dale B. Stimson <dale.b.stimson@intel.com>
+ *    Austin Hu <austin.hu@intel.com>
+ */
+
+#ifndef _PMU_TNG_H_
+#define _PMU_TNG_H_
+
+#include <linux/types.h>
+
+/* Per TNG Punit HAS */
+
+#define PUNIT_PORT              0x04
+
+/*
+ * Registers on msgbus port 4 (p-unit) for power/freq control.
+ * Bits 7:0 of the PM0 (or just PM) registers are power control bits, whereas
+ * bits 31:24 are the corresponding status bits.
+*/
+
+/*  Subsystem status of all North Cluster IPs (bits NC_PM_SSS_*) */
+#define NC_PM_SSS               0x3f
+
+/*
+ * Bit masks for power islands, as present in PM0 or PM registers.
+ * These reside as control bits in bits 7:0 of each register and
+ * as status bits in bits 31:24 of each register.
+ * Each power island has a 2-bit field which contains a value of TNG_SSC_*.
+ */
+#define SSC_TO_SSS_SHIFT        24
+
+/* GFX_SS_PM0 island */
+#define GFX_SS_PM0              0x30
+#define GFX_SS_PM1              0x31
+
+#define GFX_SLC_SSC             0x03
+#define GFX_SDKCK_SSC           0x0c
+#define GFX_RSCD_SSC            0x30
+#define GFX_SLC_LDO_SSC         0xc0
+
+#define GFX_SLC_SHIFT           0
+#define GFX_SDKCK_SHIFT         2
+#define GFX_RSCD_SHIFT          4
+#define GFX_SLC_LDO_SHIFT       6
+
+/* VED_SS_PMx power island */
+#define VED_SS_PM0              0x32
+#define VED_SS_PM1              0x33
+
+#define VED_SSC                 0x03
+
+/* VEC_SS_PMx power island */
+#define VEC_SS_PM0              0x34
+#define VEC_SS_PM1              0x35
+
+#define VEC_SSC                 0x03
+
+/* DSP_SS_PM power islands */
+#define DSP_SS_PM               0x36
+
+#define DPA_SSC                 0x03
+#define DPB_SSC                 0x0c
+#define DPC_SSC                 0x30
+
+#define DPA_SHIFT               0
+#define DPB_SHIFT               2
+#define DPC_SHIFT               4
+
+/* VSP_SS_PMx power islands */
+#define VSP_SS_PM0              0x37
+#define VSP_SS_PM1              0x38
+
+#define VSP_SSC                 0x03
+
+/* ISP_SS_PMx power islands */
+#define ISP_SS_PM0              0x39
+#define ISP_SS_PM1              0x3a
+
+#define ISP_SSC                 0x03
+
+/* MIO_SS_PM power island */
+#define MIO_SS_PM               0x3b
+
+#define MIO_SSC                 0x03
+
+/* HDMIO_SS_PM power island */
+#define HDMIO_SS_PM             0x3c
+
+#define HDMIO_SSC               0x03
+
+/*
+ * Subsystem status bits for NC_PM_SSS.  Status of all North Cluster IPs.
+ * These correspond to the above bits.
+ */
+#define NC_PM_SSS_GFX_SLC       0x00000003
+#define NC_PM_SSS_GFX_SDKCK     0x0000000c
+#define NC_PM_SSS_GFX_RSCD      0x00000030
+#define NC_PM_SSS_VED           0x000000c0
+#define NC_PM_SSS_VEC           0x00000300
+#define NC_PM_SSS_DPA           0x00000c00
+#define NC_PM_SSS_DPB           0x00003000
+#define NC_PM_SSS_DPC           0x0000c000
+#define NC_PM_SSS_VSP           0x00030000
+#define NC_PM_SSS_ISP           0x000c0000
+#define NC_PM_SSS_MIO           0x00300000
+#define NC_PM_SSS_HDMIO         0x00c00000
+#define NC_PM_SSS_GFX_SLC_LDO   0x03000000
+
+/*
+ * Frequency bits for *_PM1 registers above.
+ */
+#define IP_FREQ_VALID     0x80     /* Freq is valid bit */
+
+#define IP_FREQ_SIZE         5     /* number of bits in freq fields */
+#define IP_FREQ_MASK      0x1f     /* Bit mask for freq field */
+
+/*  Positions of various frequency fields */
+#define IP_FREQ_POS          0     /* Freq control [4:0] */
+#define IP_FREQ_GUAR_POS     8     /* Freq guar   [12:8] */
+#define IP_FREQ_STAT_POS    24     /* Freq status [28:24] */
+
+#define IP_FREQ_100_00 0x1f        /* 0b11111 100.00 */
+#define IP_FREQ_106_67 0x1d        /* 0b11101 106.67 */
+#define IP_FREQ_133_30 0x17        /* 0b10111 133.30 */
+#define IP_FREQ_160_00 0x13        /* 0b10011 160.00 */
+#define IP_FREQ_177_78 0x11        /* 0b10001 177.78 */
+#define IP_FREQ_200_00 0x0f        /* 0b01111 200.00 */
+#define IP_FREQ_213_33 0x0e        /* 0b01110 213.33 */
+#define IP_FREQ_266_67 0x0b        /* 0b01011 266.67 */
+#define IP_FREQ_320_00 0x09        /* 0b01001 320.00 */
+#define IP_FREQ_355_56 0x08        /* 0b01000 355.56 */
+#define IP_FREQ_400_00 0x07        /* 0b00111 400.00 */
+#define IP_FREQ_457_14 0x06        /* 0b00110 457.14 */
+#define IP_FREQ_533_33 0x05        /* 0b00101 533.33 */
+#define IP_FREQ_640_00 0x04        /* 0b00100 640.00 */
+#define IP_FREQ_800_00 0x03        /* 0b00011 800.00 */
+#define IP_FREQ_RESUME_SET 0x64
+
+/*  Tangier power states for each island */
+#define TNG_SSC_I0    (0b00)    /* i0 - power on, no clock or p[ower gating */
+#define TNG_SSC_I1    (0b01)    /* i1 - clock gated */
+#define TNG_SSC_I2    (0b01)    /* i2 - soft reset */
+#define TNG_SSC_D3    (0b11)    /* d3 - power off, hw state not retained */
+
+#define TNG_SSC_MASK  (0b11)    /* bit mask of all involved bits. */
+
+/*  Masks for the completely on and off states for 4 islands */
+#define TNG_COMPOSITE_I0    (0b00000000)
+#define TNG_COMPOSITE_D3    (0b11111111)
+
+#define DEBUG_PM_CMD 0
+#if !defined DEBUG_PM_CMD
+#define DEBUG_PM_CMD 1
+#endif
+
+int pmu_set_power_state_tng(u32 reg_pm0, u32 si_mask, u32 ns_mask);
+#endif /* ifndef _PMU_TNG_H_ */
diff --git a/drivers/hwmon/Kconfig b/drivers/hwmon/Kconfig
index 7703e3b..d17efe4 100644
--- a/drivers/hwmon/Kconfig
+++ b/drivers/hwmon/Kconfig
@@ -529,6 +529,16 @@ config SENSORS_CORETEMP
 	  sensor inside your CPU. Most of the family 6 CPUs
 	  are supported. Check Documentation/hwmon/coretemp for details.
 
+config SENSORS_CORETEMP_INTERRUPT
+	tristate "Intel Core/Core2/Atom temperature sensor Interrupts"
+	depends on SENSORS_CORETEMP
+	help
+	  If you say yes here you get support for interrupts when the
+	  CPU temperature crosses the programmed threshold.
+
+	  This is tested only for specific platforms(e.g Atom). If you
+	  are not sure, say N here.
+
 config SENSORS_IBMAEM
 	tristate "IBM Active Energy Manager temperature/power sensors and control"
 	select IPMI_SI
@@ -849,6 +859,21 @@ config SENSORS_LM95245
 	  This driver can also be built as a module.  If so, the module
 	  will be called lm95245.
 
+config MSIC_GPADC
+	tristate "MSIC GPADC driver for Intel Medfield platform"
+	depends on INTEL_SCU_IPC
+	help
+	  Say Y here to enable MSIC GPADC driver on Intel Medfield Platform
+
+config INTEL_MCU
+	tristate "Intel generic MCU control interface"
+	help
+	  Say Y here to enable control interface for intel mcu
+
+	  This driver provide userspace tty interface for the control and
+	  message output.
+	  You could use normal read/write to complete those operation.
+
 config SENSORS_MAX1111
 	tristate "Maxim MAX1111 Serial 8-bit ADC chip and compatibles"
 	depends on SPI_MASTER
diff --git a/drivers/hwmon/Makefile b/drivers/hwmon/Makefile
index ec7cde0..19f835d 100644
--- a/drivers/hwmon/Makefile
+++ b/drivers/hwmon/Makefile
@@ -142,6 +142,8 @@ obj-$(CONFIG_SENSORS_W83L785TS)	+= w83l785ts.o
 obj-$(CONFIG_SENSORS_W83L786NG)	+= w83l786ng.o
 obj-$(CONFIG_SENSORS_WM831X)	+= wm831x-hwmon.o
 obj-$(CONFIG_SENSORS_WM8350)	+= wm8350-hwmon.o
+obj-$(CONFIG_MSIC_GPADC)        += intel_mid_gpadc.o
+obj-$(CONFIG_INTEL_MCU)        += intel_mcu_common.o
 
 obj-$(CONFIG_PMBUS)		+= pmbus/
 
diff --git a/drivers/hwmon/coretemp.c b/drivers/hwmon/coretemp.c
index 1599310..70438b9 100644
--- a/drivers/hwmon/coretemp.c
+++ b/drivers/hwmon/coretemp.c
@@ -38,6 +38,7 @@
 #include <linux/moduleparam.h>
 #include <linux/pci.h>
 #include <asm/msr.h>
+#include <asm/mce.h>
 #include <asm/processor.h>
 #include <asm/cpu_device_id.h>
 
@@ -53,9 +54,10 @@ MODULE_PARM_DESC(tjmax, "TjMax value in degrees Celsius");
 
 #define BASE_SYSFS_ATTR_NO	2	/* Sysfs Base attr no for coretemp */
 #define NUM_REAL_CORES		32	/* Number of Real cores per cpu */
-#define CORETEMP_NAME_LENGTH	19	/* String Length of attrs */
-#define MAX_CORE_ATTRS		4	/* Maximum no of basic attrs */
-#define TOTAL_ATTRS		(MAX_CORE_ATTRS + 1)
+#define CORETEMP_NAME_LENGTH	33	/* String Length of attrs */
+#define MAX_CORE_ATTRS		5	/* Maximum no of basic attrs */
+#define MAX_THRESH_ATTRS	4	/* Maximum no of threshold attrs */
+#define TOTAL_ATTRS		(MAX_CORE_ATTRS + MAX_THRESH_ATTRS)
 #define MAX_CORE_DATA		(NUM_REAL_CORES + BASE_SYSFS_ATTR_NO)
 
 #define TO_PHYS_ID(cpu)		(cpu_data(cpu).phys_proc_id)
@@ -76,6 +78,8 @@ MODULE_PARM_DESC(tjmax, "TjMax value in degrees Celsius");
  *		This value is passed as "id" field to rdmsr/wrmsr functions.
  * @status_reg: One of IA32_THERM_STATUS or IA32_PACKAGE_THERM_STATUS,
  *		from where the temperature values should be read.
+ * @intrpt_reg: One of IA32_THERM_INTERRUPT or IA32_PACKAGE_THERM_INTERRUPT,
+ *		from where the thresholds are read.
  * @attr_size:  Total number of pre-core attrs displayed in the sysfs.
  * @is_pkg_data: If this is 1, the temp_data holds pkgtemp data.
  *		Otherwise, temp_data holds coretemp data.
@@ -89,6 +93,7 @@ struct temp_data {
 	unsigned int cpu;
 	u32 cpu_core_id;
 	u32 status_reg;
+	u32 intrpt_reg;
 	int attr_size;
 	bool is_pkg_data;
 	bool valid;
@@ -103,6 +108,7 @@ struct platform_data {
 	u16 phys_proc_id;
 	struct temp_data *core_data[MAX_CORE_DATA];
 	struct device_attribute name_attr;
+
 };
 
 struct pdev_entry {
@@ -114,12 +120,119 @@ struct pdev_entry {
 static LIST_HEAD(pdev_list);
 static DEFINE_MUTEX(pdev_list_mutex);
 
+#ifdef CONFIG_SENSORS_CORETEMP_INTERRUPT
+static DEFINE_PER_CPU(struct delayed_work, core_threshold_work);
+#endif
 static ssize_t show_name(struct device *dev,
 			struct device_attribute *devattr, char *buf)
 {
 	return sprintf(buf, "%s\n", DRVNAME);
 }
 
+static ssize_t show_tx_triggered(struct device *dev,
+				 struct device_attribute *devattr, char *buf,
+				 u32 mask)
+{
+	u32 eax, edx;
+	struct sensor_device_attribute *attr = to_sensor_dev_attr(devattr);
+	struct platform_data *pdata = dev_get_drvdata(dev);
+	struct temp_data *tdata = pdata->core_data[attr->index];
+
+	rdmsr_on_cpu(tdata->cpu, tdata->status_reg, &eax, &edx);
+
+	return sprintf(buf, "%d\n", !!(eax & mask));
+}
+
+static ssize_t show_t0_triggered(struct device *dev,
+				 struct device_attribute *devattr, char *buf)
+{
+	return show_tx_triggered(dev, devattr, buf, THERM_STATUS_THRESHOLD0);
+}
+
+static ssize_t show_t1_triggered(struct device *dev,
+				 struct device_attribute *devattr, char *buf)
+{
+	return show_tx_triggered(dev, devattr, buf, THERM_STATUS_THRESHOLD1);
+}
+
+static ssize_t show_tx(struct device *dev,
+		       struct device_attribute *devattr, char *buf,
+		       u32 mask, int shift)
+{
+	struct platform_data *pdata = dev_get_drvdata(dev);
+	struct sensor_device_attribute *attr = to_sensor_dev_attr(devattr);
+	struct temp_data *tdata = pdata->core_data[attr->index];
+	u32 eax, edx;
+	int t;
+
+	rdmsr_on_cpu(tdata->cpu, tdata->intrpt_reg, &eax, &edx);
+	t = tdata->tjmax - ((eax & mask) >> shift) * 1000;
+	return sprintf(buf, "%d\n", t);
+}
+
+static ssize_t store_tx(struct device *dev,
+			struct device_attribute *devattr,
+			const char *buf, size_t count,
+			u32 mask, int shift)
+{
+	struct platform_data *pdata = dev_get_drvdata(dev);
+	struct sensor_device_attribute *attr = to_sensor_dev_attr(devattr);
+	struct temp_data *tdata = pdata->core_data[attr->index];
+	u32 eax, edx;
+	unsigned long val;
+	int diff;
+
+	if (kstrtoul(buf, 10, &val))
+		return -EINVAL;
+
+	/*
+	 * Thermal threshold mask is 7 bits wide. Values are entered in terms
+	 * of milli degree celsius. Hence don't accept val > (127 * 1000)
+	 */
+	if (val > tdata->tjmax || val > 127000)
+		return -EINVAL;
+
+	diff = (tdata->tjmax - val) / 1000;
+
+	mutex_lock(&tdata->update_lock);
+	rdmsr_on_cpu(tdata->cpu, tdata->intrpt_reg, &eax, &edx);
+	eax = (eax & ~mask) | (diff << shift);
+	wrmsr_on_cpu(tdata->cpu, tdata->intrpt_reg, eax, edx);
+	mutex_unlock(&tdata->update_lock);
+
+	return count;
+}
+
+static ssize_t show_t0(struct device *dev,
+		       struct device_attribute *devattr, char *buf)
+{
+	return show_tx(dev, devattr, buf, THERM_MASK_THRESHOLD0,
+		       THERM_SHIFT_THRESHOLD0);
+}
+
+static ssize_t store_t0(struct device *dev,
+			struct device_attribute *devattr,
+			const char *buf, size_t count)
+{
+	return store_tx(dev, devattr, buf, count, THERM_MASK_THRESHOLD0,
+			THERM_SHIFT_THRESHOLD0);
+}
+
+static ssize_t show_t1(struct device *dev,
+		       struct device_attribute *devattr, char *buf)
+{
+	return show_tx(dev, devattr, buf, THERM_MASK_THRESHOLD1,
+		       THERM_SHIFT_THRESHOLD1);
+}
+
+static ssize_t store_t1(struct device *dev,
+			struct device_attribute *devattr,
+			const char *buf, size_t count)
+{
+	return store_tx(dev, devattr, buf, count, THERM_MASK_THRESHOLD1,
+			THERM_SHIFT_THRESHOLD1);
+}
+
 static ssize_t show_label(struct device *dev,
 				struct device_attribute *devattr, char *buf)
 {
@@ -189,6 +302,7 @@ static ssize_t show_temp(struct device *dev,
 	}
 
 	mutex_unlock(&tdata->update_lock);
+
 	return sprintf(buf, "%d\n", tdata->temp);
 }
 
@@ -223,7 +337,7 @@ struct tjmax_model {
 #define ANY 0xff
 
 static const struct tjmax_model tjmax_model_table[] = {
-	{ 0x1c, 10, 100000 },	/* D4xx, K4xx, N4xx, D5xx, K5xx, N5xx */
+	{ 0x1c, 10, 100000 },	/* D4xx, N4xx, D5xx, N5xx */
 	{ 0x1c, ANY, 90000 },	/* Z5xx, N2xx, possibly others
 				 * Note: Also matches 230 and 330,
 				 * which are covered by tjmax_table
@@ -233,7 +347,7 @@ static const struct tjmax_model tjmax_model_table[] = {
 				 * is undetectable by software
 				 */
 	{ 0x27, ANY, 90000 },	/* Atom Medfield (Z2460) */
-	{ 0x35, ANY, 90000 },	/* Atom Clover Trail/Cloverview (Z27x0) */
+	{ 0x35, ANY, 90000 },	/* Atom Clovertrail */
 	{ 0x36, ANY, 100000 },	/* Atom Cedar Trail/Cedarview (N2xxx, D2xxx)
 				 * Also matches S12x0 (stepping 9), covered by
 				 * PCI table
@@ -393,6 +507,168 @@ static int get_tjmax(struct cpuinfo_x86 *c, u32 id, struct device *dev)
 	return adjust_tjmax(c, id, dev);
 }
 
+static struct platform_device *coretemp_get_pdev(unsigned int cpu)
+{
+	u16 phys_proc_id = TO_PHYS_ID(cpu);
+	struct pdev_entry *p;
+
+	mutex_lock(&pdev_list_mutex);
+
+	list_for_each_entry(p, &pdev_list, list)
+		if (p->phys_proc_id == phys_proc_id) {
+			mutex_unlock(&pdev_list_mutex);
+			return p->pdev;
+		}
+
+	mutex_unlock(&pdev_list_mutex);
+	return NULL;
+}
+
+#ifdef CONFIG_SENSORS_CORETEMP_INTERRUPT
+/* Interrupt Handler for Core Threshold Events */
+static int coretemp_interrupt(__u64 msr_val)
+{
+	unsigned int cpu = smp_processor_id();
+
+	schedule_delayed_work_on(cpu, &per_cpu(core_threshold_work, cpu), 0);
+	return 0;
+}
+
+static void core_threshold_work_fn(struct work_struct *work)
+{
+	u32 eax, edx;
+	int thresh, event, t0, t1, temp;
+	char *thermal_event[5];
+	bool notify = false;
+	unsigned int cpu = smp_processor_id();
+	int indx = TO_ATTR_NO(cpu);
+	struct platform_device *pdev = coretemp_get_pdev(cpu);
+	struct platform_data *pdata = platform_get_drvdata(pdev);
+	struct temp_data *tdata = pdata->core_data[indx];
+
+	if (!tdata) {
+		pr_err("Could not retrieve temp_data\n");
+		return;
+	}
+
+	rdmsr_on_cpu(cpu, MSR_IA32_THERM_STATUS, &eax, &edx);
+	if (eax & THERM_LOG_THRESHOLD0) {
+		thresh = 0;
+		event = !!(eax & THERM_STATUS_THRESHOLD0);
+
+		/* Reset the Threshold0 interrupt */
+		eax = eax & ~THERM_LOG_THRESHOLD0;
+		wrmsr_on_cpu(cpu, MSR_IA32_THERM_STATUS, eax, edx);
+
+		/* Notify only when we go below the lower threshold */
+		if (event != 1)
+			notify = true;
+
+	} else if (eax & THERM_LOG_THRESHOLD1) {
+		thresh = 1;
+		event = !!(eax & THERM_STATUS_THRESHOLD1);
+
+		/* Reset the Threshold1 interrupt */
+		eax = eax & ~THERM_LOG_THRESHOLD1;
+		wrmsr_on_cpu(cpu, MSR_IA32_THERM_STATUS, eax, edx);
+
+		/* Notify only when we go above the upper threshold */
+		if (event != 0)
+			notify = true;
+	}
+
+	/*
+	 * Read the current Temperature and send it to user land;
+	 * so that the user space can avoid a sysfs read.
+	 */
+	temp = tdata->tjmax - ((eax >> 16) & 0x7f) * 1000;
+
+	/* Read the threshold registers (only) to print threshold values. */
+	rdmsr_on_cpu(cpu, MSR_IA32_THERM_INTERRUPT, &eax, &edx);
+	t0 = tdata->tjmax - ((eax & THERM_MASK_THRESHOLD0) >> THERM_SHIFT_THRESHOLD0) * 1000;
+	t1 = tdata->tjmax - ((eax & THERM_MASK_THRESHOLD1) >> THERM_SHIFT_THRESHOLD1) * 1000;
+
+
+	if (!notify) {
+		pr_debug("Thermal Event: Sensor: Core %u, cur_temp: %d,\
+			event: %d, level: %d, t0: %d, t1: %d\n",
+			tdata->cpu_core_id, temp, event, thresh, t0, t1);
+		return;
+	} else {
+		pr_info("Thermal Event: Sensor: Core %u, cur_temp: %d,\
+			event: %d, level: %d, t0: %d, t1: %d\n",
+			tdata->cpu_core_id, temp, event, thresh, t0, t1);
+	}
+
+	thermal_event[0] = kasprintf(GFP_KERNEL, "NAME=Core %u",
+						tdata->cpu_core_id);
+	thermal_event[1] = kasprintf(GFP_KERNEL, "TEMP=%d", temp);
+	thermal_event[2] = kasprintf(GFP_KERNEL, "EVENT=%d", event);
+	thermal_event[3] = kasprintf(GFP_KERNEL, "LEVEL=%d", thresh);
+	thermal_event[4] = NULL;
+
+	kobject_uevent_env(&pdev->dev.kobj, KOBJ_CHANGE, thermal_event);
+
+	kfree(thermal_event[3]);
+	kfree(thermal_event[2]);
+	kfree(thermal_event[1]);
+	kfree(thermal_event[0]);
+}
+
+static void configure_apic(void *info)
+{
+	u32 l;
+	int *flag = (int *)info;
+
+	l = apic_read(APIC_LVTTHMR);
+
+	if (*flag)	/* Non-Zero flag Masks the APIC */
+		apic_write(APIC_LVTTHMR, l | APIC_LVT_MASKED);
+	else		/* Zero flag UnMasks the APIC */
+		apic_write(APIC_LVTTHMR, l & ~APIC_LVT_MASKED);
+}
+
+static int config_thresh_intrpt(struct temp_data *data, int enable)
+{
+	u32 eax, edx;
+	unsigned int cpu = data->cpu;
+	int flag = 1; /* Non-Zero Flag masks the apic */
+
+	smp_call_function_single(cpu, &configure_apic, &flag, 1);
+
+	rdmsr_on_cpu(cpu, MSR_IA32_THERM_INTERRUPT, &eax, &edx);
+
+	if (enable) {
+		INIT_DELAYED_WORK(&per_cpu(core_threshold_work, cpu),
+					core_threshold_work_fn);
+
+		eax |= (THERM_INT_THRESHOLD0_ENABLE |
+						THERM_INT_THRESHOLD1_ENABLE);
+		platform_thermal_notify = coretemp_interrupt;
+
+		pr_info("Enabled Aux0/Aux1 interrupts for coretemp\n");
+	} else {
+		eax &= (~(THERM_INT_THRESHOLD0_ENABLE |
+						THERM_INT_THRESHOLD1_ENABLE));
+		platform_thermal_notify = NULL;
+
+		cancel_delayed_work_sync(&per_cpu(core_threshold_work, cpu));
+	}
+
+	wrmsr_on_cpu(cpu, MSR_IA32_THERM_INTERRUPT, eax, edx);
+
+	flag = 0; /* Flag should be zero to unmask the apic */
+	smp_call_function_single(cpu, &configure_apic, &flag, 1);
+
+	return 0;
+}
+#else
+static inline int config_thresh_intrpt(struct temp_data *data, int enable)
+{
+	return 0;
+}
+#endif
+
 static int create_name_attr(struct platform_data *pdata,
 				      struct device *dev)
 {
@@ -403,25 +679,38 @@ static int create_name_attr(struct platform_data *pdata,
 	return device_create_file(dev, &pdata->name_attr);
 }
 
-static int create_core_attrs(struct temp_data *tdata, struct device *dev,
-			     int attr_no)
+static int create_core_attrs(struct temp_data *tdata,
+			struct device *dev, int attr_no, bool have_ttarget)
 {
 	int err, i;
 	static ssize_t (*const rd_ptr[TOTAL_ATTRS]) (struct device *dev,
 			struct device_attribute *devattr, char *buf) = {
 			show_label, show_crit_alarm, show_temp, show_tjmax,
-			show_ttarget };
+			show_ttarget, show_t0, show_t0_triggered,
+			show_t1, show_t1_triggered };
+	static ssize_t (*rw_ptr[TOTAL_ATTRS]) (struct device *dev,
+			struct device_attribute *devattr, const char *buf,
+			size_t count) = { NULL, NULL, NULL, NULL, NULL,
+					store_t0, NULL, store_t1, NULL };
 	static const char *const names[TOTAL_ATTRS] = {
 					"temp%d_label", "temp%d_crit_alarm",
 					"temp%d_input", "temp%d_crit",
-					"temp%d_max" };
+					"temp%d_max",
+					"temp%d_threshold1",
+					"temp%d_threshold1_triggered",
+					"temp%d_threshold2",
+					"temp%d_threshold2_triggered" };
 
 	for (i = 0; i < tdata->attr_size; i++) {
-		snprintf(tdata->attr_name[i], CORETEMP_NAME_LENGTH, names[i],
-			attr_no);
+		snprintf(tdata->attr_name[i], sizeof(tdata->attr_name[i]),
+				names[i], attr_no);
 		sysfs_attr_init(&tdata->sd_attrs[i].dev_attr.attr);
 		tdata->sd_attrs[i].dev_attr.attr.name = tdata->attr_name[i];
 		tdata->sd_attrs[i].dev_attr.attr.mode = S_IRUGO;
+		if (rw_ptr[i]) {
+			tdata->sd_attrs[i].dev_attr.attr.mode |= S_IWUSR;
+			tdata->sd_attrs[i].dev_attr.store = rw_ptr[i];
+		}
 		tdata->sd_attrs[i].dev_attr.show = rd_ptr[i];
 		tdata->sd_attrs[i].index = attr_no;
 		err = device_create_file(dev, &tdata->sd_attrs[i].dev_attr);
@@ -431,8 +720,11 @@ static int create_core_attrs(struct temp_data *tdata, struct device *dev,
 	return 0;
 
 exit_free:
-	while (--i >= 0)
+	while (--i >= 0) {
+		if (!tdata->sd_attrs[i].dev_attr.attr.name)
+			continue;
 		device_remove_file(dev, &tdata->sd_attrs[i].dev_attr);
+	}
 	return err;
 }
 
@@ -447,29 +739,13 @@ static int chk_ucode_version(unsigned int cpu)
 	 * fixed for stepping D0 (6EC).
 	 */
 	if (c->x86_model == 0xe && c->x86_mask < 0xc && c->microcode < 0x39) {
-		pr_err("Errata AE18 not fixed, update BIOS or microcode of the CPU!\n");
+		pr_err("Errata AE18 not fixed, update BIOS or "
+		       "microcode of the CPU!\n");
 		return -ENODEV;
 	}
 	return 0;
 }
 
-static struct platform_device *coretemp_get_pdev(unsigned int cpu)
-{
-	u16 phys_proc_id = TO_PHYS_ID(cpu);
-	struct pdev_entry *p;
-
-	mutex_lock(&pdev_list_mutex);
-
-	list_for_each_entry(p, &pdev_list, list)
-		if (p->phys_proc_id == phys_proc_id) {
-			mutex_unlock(&pdev_list_mutex);
-			return p->pdev;
-		}
-
-	mutex_unlock(&pdev_list_mutex);
-	return NULL;
-}
-
 static struct temp_data *init_temp_data(unsigned int cpu, int pkg_flag)
 {
 	struct temp_data *tdata;
@@ -480,6 +756,8 @@ static struct temp_data *init_temp_data(unsigned int cpu, int pkg_flag)
 
 	tdata->status_reg = pkg_flag ? MSR_IA32_PACKAGE_THERM_STATUS :
 							MSR_IA32_THERM_STATUS;
+	tdata->intrpt_reg = pkg_flag ? MSR_IA32_PACKAGE_THERM_INTERRUPT :
+						MSR_IA32_THERM_INTERRUPT;
 	tdata->is_pkg_data = pkg_flag;
 	tdata->cpu = cpu;
 	tdata->cpu_core_id = TO_CORE_ID(cpu);
@@ -496,6 +774,7 @@ static int create_core_data(struct platform_device *pdev, unsigned int cpu,
 	struct cpuinfo_x86 *c = &cpu_data(cpu);
 	u32 eax, edx;
 	int err, attr_no;
+	bool have_ttarget = false;
 
 	/*
 	 * Find attr number for sysfs:
@@ -541,17 +820,28 @@ static int create_core_data(struct platform_device *pdev, unsigned int cpu,
 		if (!err) {
 			tdata->ttarget
 			  = tdata->tjmax - ((eax >> 8) & 0xff) * 1000;
-			tdata->attr_size++;
+			have_ttarget = true;
 		}
 	}
 
+	/*
+	 * Test if we can access the intrpt register. If so, increase
+	 * 'size' enough to support t0 and t1 attributes.
+	 */
+	err = rdmsr_safe_on_cpu(cpu, tdata->intrpt_reg, &eax, &edx);
+	if (!err)
+		tdata->attr_size += MAX_THRESH_ATTRS;
+
 	pdata->core_data[attr_no] = tdata;
 
 	/* Create sysfs interfaces */
-	err = create_core_attrs(tdata, &pdev->dev, attr_no);
+	err = create_core_attrs(tdata, &pdev->dev, attr_no, have_ttarget);
 	if (err)
 		goto exit_free;
 
+	/* Enable threshold interrupt support */
+	config_thresh_intrpt(tdata, 1);
+
 	return 0;
 exit_free:
 	pdata->core_data[attr_no] = NULL;
@@ -579,8 +869,14 @@ static void coretemp_remove_core(struct platform_data *pdata,
 	struct temp_data *tdata = pdata->core_data[indx];
 
 	/* Remove the sysfs attributes */
-	for (i = 0; i < tdata->attr_size; i++)
+	for (i = 0; i < tdata->attr_size; i++) {
+		if (!tdata->sd_attrs[i].dev_attr.attr.name)
+			continue;
 		device_remove_file(dev, &tdata->sd_attrs[i].dev_attr);
+	}
+
+	/* Enable threshold interrupt support */
+	config_thresh_intrpt(tdata, 0);
 
 	kfree(pdata->core_data[indx]);
 	pdata->core_data[indx] = NULL;
diff --git a/drivers/hwmon/intel_mcu_common.c b/drivers/hwmon/intel_mcu_common.c
new file mode 100644
index 0000000..cdf078c
--- /dev/null
+++ b/drivers/hwmon/intel_mcu_common.c
@@ -0,0 +1,700 @@
+/**
+ * intel_mcu_common.c - Intel MCU common interface file
+ *
+ * Copyright (C) 2014 Intel Inc. - http://www.intel.com
+ *
+ * Authors: Lei Wen <lei.wen@intel.com>,
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions, and the following disclaimer,
+ *    without modification.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in the
+ *    documentation and/or other materials provided with the distribution.
+ * 3. The names of the above-listed copyright holders may not be used
+ *    to endorse or promote products derived from this software without
+ *    specific prior written permission.
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") version 2, as published by the Free
+ * Software Foundation.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
+ * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
+ * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR
+ * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
+ * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
+ * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
+ * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
+ * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
+ * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include <linux/delay.h>
+#include <linux/kernel.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/tty.h>
+#include <linux/tty_driver.h>
+#include <linux/tty_flip.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/uaccess.h>
+#include <asm/byteorder.h>
+#include <asm/unaligned.h>
+#include <linux/list.h>
+#include <linux/pci.h>
+#include <linux/completion.h>
+#include <linux/firmware.h>
+#include <asm/intel_psh_ipc.h>
+#include "intel_mcu_common.h"
+#include <linux/circ_buf.h>
+
+#define APP_IMR_SIZE (1024 * 126)
+#define DRIVER_AUTHOR "Lei Wen <lei.wen@intel.com>"
+#define DRIVER_DESC "Intel mcu common control interface"
+#define INTEL_MCU_TTY_MAJOR		168
+#define INTEL_MCU_TTY_MINORS		3
+
+#define LOAD_APP		"load mcu app"
+#define GET_VERSION		"get mcu app version"
+struct tty_driver *intel_mcu_tty_driver;
+
+#define VER_LEN		1024
+struct mcu {
+	char ver[VER_LEN];
+	uintptr_t ddr_phy[2];
+	void *ddr[2];
+	int load_in_progress;
+};
+
+struct mcu_data {
+	struct device *dev;
+	struct tty_port port;
+	struct mcu *mcu;
+	struct completion cmp;
+	struct loop_buffer lbuf;
+	int index;
+};
+
+static struct mcu_data *mcu_table[INTEL_MCU_TTY_MINORS];
+static int log_level = 1;
+static char *debug_msg[] = {
+	"fatal",
+	"error",
+	"warning",
+	"info",
+	"debug",
+};
+
+static int send_cmd(struct mcu_data *data,
+		struct psh_msg *in, int ch, int wait)
+{
+	int ret;
+	ret = intel_ia2psh_command(in, NULL, ch, 1000000);
+	if (ret)
+		return ret;
+
+	if (wait) {
+		ret = wait_for_completion_timeout(&data->cmp, 3 * HZ);
+		if (ret == 0)
+			return -ETIME;
+	}
+
+	return 0;
+}
+
+static void lbuf_read_reset(struct loop_buffer *lbuf)
+{
+	if (lbuf) {
+		lbuf->off_head = lbuf->off_tail = 0;
+		lbuf->in_reading = 0;
+	}
+}
+
+static int lbuf_read_next(struct loop_buffer *lbuf, u8 **buf, u16 *size)
+{
+	struct frame_head *fhead =
+		(struct frame_head *)(lbuf->addr + lbuf->off_head);
+	*buf = NULL;
+	*size = 0;
+
+	if (lbuf->in_reading) {
+		lbuf->in_reading = 0;
+
+		/* go over previous frame has been read */
+		lbuf->off_head += frame_size(fhead->length);
+		lbuf->off_tail = lbuf->off_head;
+		fhead = (struct frame_head *)(lbuf->addr + lbuf->off_head);
+	}
+
+	if (fhead->sign == LBUF_DISCARD_SIGN) {
+		fhead = (struct frame_head *)lbuf->addr;
+		lbuf->off_head = lbuf->off_tail = 0;
+	}
+
+	if (fhead->sign == LBUF_CELL_SIGN) {
+
+		*buf = lbuf->addr + lbuf->off_head + sizeof(*fhead);
+		*size = fhead->length;
+		lbuf->in_reading = 1;
+	}
+
+	return !lbuf->in_reading;
+}
+
+static int intel_mcu_mcudbg_level(struct mcu_data *data, int level)
+{
+	struct psh_msg in;
+	struct cmd_debug_param *param;
+
+	in.param = 0;
+	in.msg = CMD_MCU_APP_DEBUG;
+	param = (struct cmd_debug_param *) (&(in.param));
+	if (level > 0) {
+		param->level = level;
+		param->sub_cmd = CMD_DEBUG_SET_MASK;
+	} else
+		param->sub_cmd = CMD_DEBUG_GET_MASK;
+
+	return send_cmd(data, &in, PSH2IA_CHANNEL2, 1);
+}
+
+static void push_char_into_port(struct tty_port *port, const char *buf, int len)
+{
+	int count;
+
+	if (len <= 0)
+		return;
+
+	do {
+		count = tty_insert_flip_string(port, buf, len);
+		len -= count;
+		buf += count;
+	} while (len > 0);
+
+	tty_flip_buffer_push(port);
+}
+
+static int intel_mcu_tty_open(struct tty_struct *tty, struct file *filp)
+{
+	dev_dbg(tty->dev, "%s\n", __func__);
+	tty->driver_data = mcu_table[tty->index];
+	/*
+	 * For we may get data cached while we don't open this tty,
+	 * so we need to flush out buffer, then we could
+	 * get full content without disappoint user
+	 */
+	if (tty->port)
+		tty_flip_buffer_push(tty->port);
+
+	return 0;
+}
+
+static void intel_mcu_tty_close(struct tty_struct *tty, struct file *filp)
+{
+	dev_dbg(tty->dev, "%s\n", __func__);
+	tty->driver_data = NULL;
+}
+
+static int do_get_ver(struct mcu_data *data)
+{
+	struct psh_msg in;
+
+	in.param = 0;
+	in.msg = CMD_MCU_APP_GET_VERSION;
+	return send_cmd(data, &in, PSH2IA_CHANNEL2, 1);
+}
+
+static int do_setup_ddr(struct mcu_data *data)
+{
+	struct mcu *mcu = data->mcu;
+	const struct firmware *fw_entry;
+	static int fw_load_done;
+	char fname[20];
+	struct psh_msg in;
+
+	if (fw_load_done)
+		return 0;
+
+	snprintf(fname, 20, "intel_mcu.bin");
+	if (!request_firmware(&fw_entry, fname, data->dev)) {
+		if (!fw_entry)
+			return -ENOMEM;
+
+		pr_debug("psh fw size %d virt:0x%p\n",
+				(int)fw_entry->size, fw_entry->data);
+		if (fw_entry->size > APP_IMR_SIZE) {
+			pr_err("psh fw size too big\n");
+		} else {
+			memcpy(mcu->ddr[0], fw_entry->data,
+					fw_entry->size);
+			in.msg = CMD_MCU_LOAD_APP;
+			in.param = mcu->ddr_phy[0];
+			mcu->load_in_progress = 1;
+			if (send_cmd(data, &in, PSH2IA_CHANNEL3, 1))
+				return -1;
+			fw_load_done = 1;
+		}
+		release_firmware(fw_entry);
+	} else {
+		pr_err("cannot find psh firmware(%s)\n", fname);
+		return -ENODEV;
+	}
+	in.msg = CMD_MCU_SETUP_DDR;
+	in.param = mcu->ddr_phy[1];
+	return send_cmd(data, &in, PSH2IA_CHANNEL2, 1);
+}
+
+static ssize_t load_app_store(struct device *device,
+		struct device_attribute *attr,
+		const char *buf, size_t count)
+{
+	int len = strlen(LOAD_APP);
+
+	if (count >= len && strncmp(buf, LOAD_APP, len) == 0) {
+		do_setup_ddr(mcu_table[2]);
+		return count;
+	}
+
+	pr_err("Please provide right string as [%s]!\n", LOAD_APP);
+	return -1;
+}
+
+static ssize_t get_ver_show(struct device *device,
+		struct device_attribute *attr, char *buf)
+{
+	struct mcu_data *data = mcu_table[2];
+	struct mcu *mcu = data->mcu;
+
+	if (do_get_ver(data))
+		return -1;
+
+	return scnprintf(buf, VER_LEN, "%s", mcu->ver);
+}
+
+static ssize_t mdbg_control_show(struct device *device,
+		struct device_attribute *attr, char *buf)
+{
+	if (intel_mcu_mcudbg_level(mcu_table[2], -1) < 0)
+		goto err;
+
+	if (log_level > 0 && log_level < 6)
+		return scnprintf(buf, 8, "%s\n", debug_msg[log_level - 1]);
+
+err:
+	pr_info("get log level err\n");
+	return -1;
+}
+/*
+ *set msg level:echo log_level=fatal|info|warning|error|debug| >control
+*/
+#define LOG_LEVEL	"fatal|error|warning|info|debug"
+static ssize_t mdbg_control_store(struct device *device,
+		struct device_attribute *attr,
+		const char *buf, size_t count)
+{
+	struct mcu_data *data = mcu_table[2];
+	int level = 0;
+	long ltmp = 0;
+
+	if (!buf)
+		return -1;
+	if (!strncmp(buf, "fatal", strlen("fatal")))
+		level = 1;
+	else if (!strncmp(buf, "error", strlen("error")))
+		level = 2;
+	else if (!strncmp(buf, "warning", strlen("warning")))
+		level = 3;
+	else if (!strncmp(buf, "info", strlen("info")))
+		level = 4;
+	else if (!strncmp(buf, "debug", strlen("debug")))
+		level = 5;
+	else {
+		int err;
+		err = kstrtol(buf, 10, &ltmp);
+		if (!err && (ltmp > 0) && (ltmp < 6))
+			level = ltmp;
+		else {
+			pr_err("Please input words as [%s]\n", LOG_LEVEL);
+			return -1;
+		}
+	}
+	pr_info("set level:%d\n", level);
+	if (intel_mcu_mcudbg_level(data, level) < 0)
+		return -1;
+	return count;
+}
+
+static DEVICE_ATTR(control, 0200, NULL, load_app_store);
+static DEVICE_ATTR(fw_version, 0400, get_ver_show, NULL);
+static DEVICE_ATTR(log_level, 0600, mdbg_control_show, mdbg_control_store);
+
+static struct attribute *control_sysfs_attrs[] = {
+	&dev_attr_control.attr,
+	&dev_attr_fw_version.attr,
+	&dev_attr_log_level.attr,
+	NULL,
+
+};
+
+static struct attribute_group intel_mcu_tty_attribute_group = {
+	.name = NULL,
+	.attrs = control_sysfs_attrs,
+
+};
+
+static void raw_output(struct mcu_data *data, int ch,
+		const unsigned char *buf, int count)
+{
+	struct psh_msg in;
+	int i, left;
+
+	for (i = 0; i < count; i += 4) {
+		left = count - i;
+		if (left > 4) {
+			left = 4;
+			in.msg = PSH_IPC_CONTINUE;
+		} else
+			in.msg = 0;
+
+		memcpy(&in.param, buf, left);
+		buf += left;
+		send_cmd(data, &in, ch, 0);
+	}
+}
+
+#define TTY_WRITE_ROOM		512
+static int intel_mcu_tty_write(struct tty_struct *tty,
+		const unsigned char *buf, int count)
+{
+	struct mcu_data *data = tty->driver_data;
+
+	switch (tty->index) {
+	default:
+		pr_err("TTY index %d not supported!\n", tty->index);
+	case 1:
+		return -1;
+	case 0:
+		if (count > TTY_WRITE_ROOM) {
+			pr_err("Port 0's input size is limited by %d!\n",
+					TTY_WRITE_ROOM);
+			return -1;
+		}
+		raw_output(data, tty->index, buf, count);
+		break;
+	}
+	return count;
+}
+
+static int intel_mcu_tty_write_room(struct tty_struct *tty)
+{
+	return TTY_WRITE_ROOM;
+}
+
+static const struct tty_operations intel_mcu_ops = {
+	.open =			intel_mcu_tty_open,
+	.close =		intel_mcu_tty_close,
+	.write =		intel_mcu_tty_write,
+	.write_room =		intel_mcu_tty_write_room,
+};
+
+static int mem_alloc(struct pci_dev *pdev, uintptr_t *phy_addr,
+		void **virt_addr, int bar)
+{
+	void __iomem *mem;
+	int ret = 0;
+	unsigned long start = 0, len;
+
+	/* dedicate isolated memory region */
+	start = pci_resource_start(pdev, bar);
+	len = pci_resource_len(pdev, bar);
+	if (!start || !len) {
+		dev_err(&pdev->dev, "bar %d address not set\n", bar);
+		ret = -EINVAL;
+		goto err;
+	}
+
+	ret = pci_request_region(pdev, bar, "intel_mcu");
+	if (ret) {
+		dev_err(&pdev->dev,
+				"failed to request psh region 0x%lx-0x%lx\n",
+				start,
+				(unsigned long)pci_resource_end(pdev, bar));
+		goto err;
+	}
+
+	mem = ioremap_nocache(start, len);
+	if (!mem) {
+		dev_err(&pdev->dev, "can not ioremap app imr address\n");
+		ret = -EINVAL;
+		goto err_ioremap;
+	}
+
+	*phy_addr = start;
+	*virt_addr = (void *)mem;
+	return 0;
+
+err_ioremap:
+	pci_release_region(pdev, bar);
+err:
+	return ret;
+}
+
+static void cmd_handler(u32 msg, u32 param, void *_data)
+{
+	struct mcu_data *data = (struct mcu_data *)_data;
+	struct mcu *mcu = data->mcu;
+	struct cmd_resp *resp;
+	const struct version_resp *version;
+	struct debug_resp *debug_resp;
+	u8 *dbuf = NULL;
+	u16 size = 0;
+
+	if (mcu->load_in_progress) {
+		mcu->load_in_progress = 0;
+		goto done;
+	}
+
+	while (!lbuf_read_next(&data->lbuf, &dbuf, &size)) {
+		resp = (struct cmd_resp *)dbuf;
+
+		if (!resp->len)
+			continue;
+
+		switch (resp->cmd_id) {
+		case CMD_MCU_APP_GET_VERSION:
+			version = (struct version_resp *)resp->param;
+			if (version->total_length)
+				snprintf(mcu->ver, VER_LEN, version->buf,
+						version->total_length);
+			break;
+		case CMD_MCU_APP_DEBUG:
+			debug_resp = (struct debug_resp *)resp->param;
+			log_level = debug_resp->level;
+		default:
+			break;
+		}
+	}
+done:
+	complete(&data->cmp);
+}
+
+static void raw_data_handler(u32 msg, u32 param, void *_data)
+{
+	struct mcu_data *data = (struct mcu_data *)_data;
+	struct cmd_resp *resp;
+	u8 *dbuf = NULL;
+	u16 size = 0;
+
+	while (!lbuf_read_next(&data->lbuf, &dbuf, &size)) {
+		resp = (struct cmd_resp *)dbuf;
+		push_char_into_port(&data->port, resp->param, resp->len);
+	}
+	complete(&data->cmp);
+}
+
+static int mcu_platform_probe(struct platform_device *pdev)
+{
+	int ret, i;
+	struct mcu_data *data;
+	struct mcu *mcu;
+	u8 *base;
+
+	mcu = platform_get_drvdata(pdev);
+	intel_mcu_tty_driver = alloc_tty_driver(INTEL_MCU_TTY_MINORS);
+	if (!intel_mcu_tty_driver) {
+		dev_err(&pdev->dev, "fail to alloc tty driver\n");
+		return -ENODEV;
+	}
+
+	intel_mcu_tty_driver->name = "ttymcu";
+	intel_mcu_tty_driver->major = INTEL_MCU_TTY_MAJOR;
+	intel_mcu_tty_driver->minor_start = 0;
+	intel_mcu_tty_driver->type = TTY_DRIVER_TYPE_SERIAL;
+	intel_mcu_tty_driver->subtype = SERIAL_TYPE_NORMAL;
+	intel_mcu_tty_driver->flags = TTY_DRIVER_REAL_RAW
+		| TTY_DRIVER_DYNAMIC_DEV;
+	intel_mcu_tty_driver->init_termios = tty_std_termios;
+	intel_mcu_tty_driver->init_termios.c_cflag = B9600 | CS8 | CREAD |
+		HUPCL | CLOCAL;
+	intel_mcu_tty_driver->init_termios.c_ispeed = 38400;
+	intel_mcu_tty_driver->init_termios.c_ospeed = 38400;
+	intel_mcu_tty_driver->init_termios.c_iflag = 0;
+	intel_mcu_tty_driver->init_termios.c_oflag = 0;
+	intel_mcu_tty_driver->init_termios.c_lflag = 0;
+	tty_set_operations(intel_mcu_tty_driver, &intel_mcu_ops);
+
+	ret = tty_register_driver(intel_mcu_tty_driver);
+	if (ret) {
+		dev_err(&pdev->dev, "fail to register tty driver\n");
+		goto tty_reg_fail;
+	}
+
+	base = (u8 *)mcu->ddr[1];
+	for (i = INTEL_MCU_TTY_MINORS - 1; i >= 0; i--) {
+		data = kzalloc(sizeof(struct mcu_data), GFP_KERNEL);
+		if (data == NULL) {
+			dev_err(&pdev->dev, "fail to alloc mcu data\n");
+			goto data_alloc_fail;
+		}
+
+		data->index = i;
+		tty_port_init(&data->port);
+		data->dev = tty_port_register_device(&data->port,
+				intel_mcu_tty_driver, i, &pdev->dev);
+		mcu_table[i] = data;
+		data->mcu = mcu;
+		init_completion(&data->cmp);
+		data->lbuf.addr = base;
+		data->lbuf.length = BUF_IA_DDR_SIZE;
+		lbuf_read_reset(&data->lbuf);
+		base += BUF_IA_DDR_SIZE;
+	}
+	ret = sysfs_create_group(&pdev->dev.kobj,
+			&intel_mcu_tty_attribute_group);
+	if (ret) {
+		pr_err("failed to create the mdbg sysfs attributes\n");
+		sysfs_remove_group(&pdev->dev.kobj,
+				&intel_mcu_tty_attribute_group);
+		goto data_alloc_fail;
+	}
+
+	intel_psh_ipc_bind(PSH_RECV_CH0, raw_data_handler, mcu_table[0]);
+	intel_psh_ipc_bind(PSH_RECV_CH1, raw_data_handler, mcu_table[1]);
+	intel_psh_ipc_bind(PSH_RECV_CH2, cmd_handler, mcu_table[2]);
+
+	pr_info("MCU detected and ready to used!\n");
+
+	return 0;
+
+data_alloc_fail:
+	for (i = 0; i < INTEL_MCU_TTY_MINORS; i++)
+		kfree(mcu_table[i]);
+tty_reg_fail:
+	put_tty_driver(intel_mcu_tty_driver);
+	return ret;
+}
+
+static int mcu_platform_remove(struct platform_device *pdev)
+{
+	struct mcu *mcu;
+	int i;
+
+	mcu = platform_get_drvdata(pdev);
+	sysfs_remove_group(&pdev->dev.kobj,
+			&intel_mcu_tty_attribute_group);
+
+	for (i = 0; i < INTEL_MCU_TTY_MINORS; i++)
+		kfree(mcu_table[i]);
+	put_tty_driver(intel_mcu_tty_driver);
+	kfree(mcu);
+
+	return 0;
+}
+
+static struct platform_driver intel_mcu_platform = {
+	.driver = {
+		.name	= "intel_mcu",
+	},
+	.probe		= mcu_platform_probe,
+	.remove		= mcu_platform_remove,
+};
+module_platform_driver(intel_mcu_platform);
+
+static int intel_mcu_probe(struct pci_dev *pdev, const struct pci_device_id *id)
+{
+	struct platform_device *dev;
+	struct mcu *mcu;
+	int ret;
+
+	ret = pci_enable_device(pdev);
+	if (ret) {
+		dev_err(&pdev->dev, "fail to enable psh pci device\n");
+		return -ENODEV;
+	}
+
+	mcu = kzalloc(sizeof(struct mcu), GFP_KERNEL);
+	if (!mcu) {
+		dev_err(&pdev->dev, "cannot allocate memory for mcu\n");
+		ret = -ENOMEM;
+		goto mcu_err;
+	}
+
+	ret = mem_alloc(pdev, &mcu->ddr_phy[0], &mcu->ddr[0], 0);
+	if (ret)
+		goto plat_alloc_fail;
+
+	ret = mem_alloc(pdev, &mcu->ddr_phy[1], &mcu->ddr[1], 1);
+	if (ret)
+		goto plat_alloc_fail;
+
+	dev = platform_device_alloc("intel_mcu", -1);
+	if (!dev) {
+		ret = -ENODEV;
+		goto plat_alloc_fail;
+	}
+
+	dev->dev.dma_mask = &dev->dev.coherent_dma_mask;
+	platform_set_drvdata(dev, mcu);
+	dev_set_drvdata(&pdev->dev, mcu);
+
+	ret = platform_device_add(dev);
+	return ret;
+
+plat_alloc_fail:
+	kfree(mcu);
+mcu_err:
+	pci_dev_put(pdev);
+	return ret;
+}
+
+static void intel_mcu_remove(struct pci_dev *pdev)
+{
+	struct mcu *mcu;
+
+	mcu = dev_get_drvdata(&pdev->dev);
+	iounmap((void __iomem *)mcu->ddr[0]);
+	iounmap((void __iomem *)mcu->ddr[1]);
+
+	pci_release_region(pdev, 0);
+	pci_release_region(pdev, 1);
+	pci_dev_put(pdev);
+}
+
+static DEFINE_PCI_DEVICE_TABLE(pci_ids) = {
+	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x11a4)},
+	{ 0,}
+};
+
+MODULE_DEVICE_TABLE(pci, pci_ids);
+static struct pci_driver intel_mcu_driver = {
+	.name = "intel_mcu",
+	.id_table = pci_ids,
+	.probe	= intel_mcu_probe,
+	.remove	= intel_mcu_remove,
+};
+
+static int __init intel_mcu_init(void)
+{
+	return pci_register_driver(&intel_mcu_driver);
+}
+
+static void __exit intel_mcu_exit(void)
+{
+	pci_unregister_driver(&intel_mcu_driver);
+}
+
+module_init(intel_mcu_init);
+module_exit(intel_mcu_exit);
+MODULE_AUTHOR(DRIVER_AUTHOR);
+MODULE_DESCRIPTION(DRIVER_DESC);
+MODULE_LICENSE("GPL");
+MODULE_ALIAS_CHARDEV_MAJOR(INTEL_MCU_TTY_MAJOR);
diff --git a/drivers/hwmon/intel_mcu_common.h b/drivers/hwmon/intel_mcu_common.h
new file mode 100644
index 0000000..1ffd081
--- /dev/null
+++ b/drivers/hwmon/intel_mcu_common.h
@@ -0,0 +1,79 @@
+#ifndef _EDISON_COMMON_H_
+#define _EDISON_COMMON_H_
+
+#define PSH2IA_CHANNEL0	0
+#define PSH2IA_CHANNEL1	1
+#define PSH2IA_CHANNEL2	2
+#define PSH2IA_CHANNEL3	3
+
+enum cmd_id {
+	CMD_MCU_LOAD_APP = 0,
+	CMD_MCU_SETUP_DDR,
+	CMD_MCU_APP_DEBUG,
+	CMD_MCU_APP_GET_VERSION,
+};
+
+#define CIRC_SIZE (1024 * 64)
+struct ddr_param {
+	u32 ddr;
+	u32 ddr1;
+} __packed;
+
+#define CMD_DEBUG_SET_MASK	((u8)0x1)
+#define CMD_DEBUG_GET_MASK	((u8)0x2)
+#define MCU_DBG_ALL		((u16)-1)
+#define MCU_DBG_FATAL		1
+#define MCU_DBG_ERR		2
+#define MCU_DBG_WARN	3
+#define MCU_DBG_INFO	4
+#define MCU_DBG_DBG		5
+
+struct cmd_debug_param {
+	u8 sub_cmd;
+	u16 level;
+	char tag[30];
+} __packed;
+
+#define RESP_PARAM_MAX_SIZE	56
+struct cmd_resp {
+	u8 cmd_id;
+	u8 len;
+	int ret;
+	char param[RESP_PARAM_MAX_SIZE];
+} __packed;
+
+struct debug_resp {
+	u16 level;
+} __packed;
+
+struct version_resp {
+	u8 total_length;
+	u8 segment_length;
+	u8 sequence_number;
+	char buf[0];
+} __packed;
+
+#define LBUF_CELL_SIGN ((u16)0x4853)
+#define LBUF_EMPTY_SIGN ((u16)0x0000)
+#define LBUF_DISCARD_SIGN ((u16)0x4944)
+#define size_align(size) ((size % 4) ? (size + 4 - (size % 4)) : size)
+#define frame_size(size) (size_align(size) + \
+		sizeof(struct frame_head))
+
+struct frame_head {
+	u16 sign;
+	u16 length;
+	u8 buf[0];
+} __packed;
+
+#define BUF_IA_DDR_SIZE 8192
+struct loop_buffer {
+	int in_reading;
+	u8 *addr;
+	u16 length;
+
+	u16 off_head;
+	u16 off_tail;
+};
+
+#endif
diff --git a/drivers/hwmon/intel_mid_gpadc.c b/drivers/hwmon/intel_mid_gpadc.c
new file mode 100644
index 0000000..b68cffc
--- /dev/null
+++ b/drivers/hwmon/intel_mid_gpadc.c
@@ -0,0 +1,1212 @@
+/*
+ * intel_mdf_msic_gpadc.c - Intel Medfield MSIC GPADC Driver
+ *
+ * Copyright (C) 2010 Intel Corporation
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ * Author: Jenny TC <jenny.tc@intel.com>
+ * Author: Bin Yang <bin.yang@intel.com>
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/io.h>
+#include <linux/interrupt.h>
+#include <linux/device.h>
+#include <linux/delay.h>
+#include <linux/sched.h>
+#include <linux/pm_qos.h>
+#include <linux/intel_mid_pm.h>
+#include <linux/workqueue.h>
+#include <linux/fs.h>
+#include <linux/rpmsg.h>
+
+#include <asm/intel_scu_pmic.h>
+#include <asm/intel_mid_rpmsg.h>
+#include <asm/intel_mid_remoteproc.h>
+#include <asm/intel_mid_gpadc.h>
+
+#define VAUDACNT		0x0DB
+#define MCCINT			0x013
+#define IRQLVL1			0x002
+#define IRQLVL1MSK		0x021
+#define ADC1INT			0x003
+#define ADC1ADDR0		0x1C5
+#define ADC1SNS0H		0x1D4
+#define ADC1OFFSETH		0x1C3
+#define ADC1OFFSETL		0x1C4
+#define ADC1CNTL1		0x1C0
+#define ADC1CNTL2		0x1C1
+#define ADC1CNTL3		0x1C2
+#define	ADC1BV0H		0x1F2
+#define ADC1BI0H		0x1FA
+
+#ifdef CONFIG_BOARD_CTP
+#define EEPROMCAL1		0x309
+#define EEPROMCAL2		0x30A
+#else
+#define EEPROMCAL1		0x317
+#define EEPROMCAL2		0x318
+#endif
+
+#define MCCINT_MCCCAL		(1 << 1)
+#define MCCINT_MOVERFLOW	(1 << 0)
+
+#define IRQLVL1MSK_ADCM		(1 << 1)
+
+#define ADC1CNTL1_AD1OFFSETEN	(1 << 6)
+#define ADC1CNTL1_AD1CALEN	(1 << 5)
+#define ADC1CNTL1_ADEN		(1 << 4)
+#define ADC1CNTL1_ADSTRT	(1 << 3)
+#define ADC1CNTL1_ADSLP		7
+#define ADC1CNTL1_ADSLP_DEF	1
+
+#define ADC1INT_ADC1CAL		(1 << 2)
+#define ADC1INT_GSM		(1 << 1)
+#define ADC1INT_RND		(1 << 0)
+
+#define ADC1CNTL3_ADCTHERM	(1 << 2)
+#define ADC1CNTL3_GSMDATARD	(1 << 1)
+#define ADC1CNTL3_RRDATARD	(1 << 0)
+
+#define ADC1CNTL2_DEF		0x7
+#define ADC1CNTL2_ADCGSMEN	(1 << 7)
+
+#define MSIC_STOPCH		(1 << 4)
+
+#define GPADC_CH_MAX		15
+
+#define GPADC_POWERON_DELAY	1
+
+#define SAMPLE_CH_MAX		2
+
+static void *adc_handle[GPADC_CH_MAX] = {};
+static int sample_result[GPADC_CH_MAX][SAMPLE_CH_MAX];
+static struct completion gsmadc_complete;
+static int vol_val;
+static int cur_val;
+
+struct gpadc_info {
+	int initialized;
+	int depth;
+
+	struct workqueue_struct *workq;
+	wait_queue_head_t trimming_wait;
+	struct work_struct trimming_work;
+	struct work_struct gsmpulse_work;
+	int trimming_start;
+
+	/* This mutex protects gpadc sample/config from concurrent conflict.
+	   Any function, which does the sample or config, needs to
+	   hold this lock.
+	   If it is locked, it also means the gpadc is in active mode.
+	   GSM mode sample does not need to hold this lock. It can be used with
+	   normal sample concurrent without poweron.
+	*/
+	struct mutex lock;
+	struct device *dev;
+	int irq;
+	void __iomem *intr;
+	int irq_status;
+
+	int vzse;
+	int vge;
+	int izse;
+	int ige;
+	int addr_mask;
+
+	wait_queue_head_t wait;
+	int rnd_done;
+	int conv_done;
+	int gsmpulse_done;
+
+	struct pm_qos_request pm_qos_request;
+	void (*gsmadc_notify)(int vol, int cur);
+
+	int pmic_ipc_status;
+};
+
+struct gpadc_request {
+	int count;
+	int vref;
+	int ch[GPADC_CH_MAX];
+	int addr[GPADC_CH_MAX];
+};
+
+static struct gpadc_info gpadc_info;
+
+static inline int gpadc_clear_bits(u16 addr, u8 mask)
+{
+	struct gpadc_info *mgi = &gpadc_info;
+	int ret;
+
+	if (mgi->pmic_ipc_status)
+		return -EINVAL;
+
+	ret = intel_scu_ipc_update_register(addr, 0, mask);
+	if (ret)
+		mgi->pmic_ipc_status = -EINVAL;
+
+	return ret;
+}
+
+static inline int gpadc_set_bits(u16 addr, u8 mask)
+{
+	struct gpadc_info *mgi = &gpadc_info;
+	int ret;
+
+	if (mgi->pmic_ipc_status)
+		return -EINVAL;
+
+	ret = intel_scu_ipc_update_register(addr, 0xff, mask);
+	if (ret)
+		mgi->pmic_ipc_status = -EINVAL;
+
+	return ret;
+}
+
+static inline int gpadc_write(u16 addr, u8 data)
+{
+	struct gpadc_info *mgi = &gpadc_info;
+	int ret;
+
+	if (mgi->pmic_ipc_status)
+		return -EINVAL;
+
+	ret = intel_scu_ipc_iowrite8(addr, data);
+	if (ret)
+		mgi->pmic_ipc_status = -EINVAL;
+
+	return ret;
+}
+
+static inline int gpadc_read(u16 addr, u8 *data)
+{
+	struct gpadc_info *mgi = &gpadc_info;
+	int ret;
+
+	if (mgi->pmic_ipc_status)
+		return -EINVAL;
+
+	ret = intel_scu_ipc_ioread8(addr, data);
+	if (ret)
+		mgi->pmic_ipc_status = -EINVAL;
+
+	return ret;
+}
+
+static void gpadc_dump(struct gpadc_info *mgi)
+{
+	u8 data;
+	int i;
+
+	dev_err(mgi->dev, "pmic ipc status: %s\n",
+			mgi->pmic_ipc_status ? "bad" : "good");
+	gpadc_read(VAUDACNT, &data);
+	dev_err(mgi->dev, "VAUDACNT: 0x%x\n", data);
+	gpadc_read(IRQLVL1MSK, &data);
+	dev_err(mgi->dev, "IRQLVL1MSK: 0x%x\n", data);
+	gpadc_read(IRQLVL1, &data);
+	dev_err(mgi->dev, "IRQLVL1: 0x%x\n", data);
+	gpadc_read(ADC1INT, &data);
+	dev_err(mgi->dev, "ADC1INT: 0x%x\n", data);
+	gpadc_read(ADC1CNTL1, &data);
+	dev_err(mgi->dev, "ADC1CNTL1: 0x%x\n", data);
+	gpadc_read(ADC1CNTL2, &data);
+	dev_err(mgi->dev, "ADC1CNTL2: 0x%x\n", data);
+	gpadc_read(ADC1CNTL3, &data);
+	dev_err(mgi->dev, "ADC1CNTL3: 0x%x\n", data);
+	for (i = 0; i < GPADC_CH_MAX; i++) {
+		gpadc_read(ADC1ADDR0+i, &data);
+		dev_err(mgi->dev, "ADC1ADDR[%d]: 0x%x\n", i, data);
+	}
+}
+
+static int gpadc_poweron(struct gpadc_info *mgi, int vref)
+{
+	if (!mgi->depth++) {
+		if (gpadc_set_bits(ADC1CNTL1, ADC1CNTL1_ADEN) != 0)
+			return -EIO;
+		msleep(GPADC_POWERON_DELAY);
+	}
+	if (vref) {
+		if (gpadc_set_bits(ADC1CNTL3, ADC1CNTL3_ADCTHERM) != 0)
+			return -EIO;
+		msleep(GPADC_POWERON_DELAY);
+	}
+	return 0;
+}
+
+static int gpadc_poweroff(struct gpadc_info *mgi)
+{
+	if (!--mgi->depth) {
+		if (gpadc_clear_bits(ADC1CNTL1, ADC1CNTL1_ADEN) != 0)
+			return -EIO;
+		if (gpadc_clear_bits(ADC1CNTL3, ADC1CNTL3_ADCTHERM) != 0)
+			return -EIO;
+	}
+	return 0;
+}
+
+static int gpadc_calib(int rc, int zse, int ge)
+{
+	struct gpadc_info *mgi = &gpadc_info;
+	int tmp;
+
+	if (intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_CLOVERVIEW) {
+		if (ge == 0) {
+			dev_err(mgi->dev, "calibration divider is zero\n");
+			return 0;
+		}
+
+		/**
+		 * For Cloverview, using the calibration data, we have the
+		 * voltage and current after calibration correction as below:
+		 * V_CAL_CODE = 213.33 * (V_RAW_CODE - VZSE) / VGE
+		 * I_CAL_CODE = 213.33 * (I_RAW_CODE - IZSE) / IGE
+		 */
+
+		/* note: the input zse is multipled by 10,
+		 * input ge is multipled by 100, need to handle them here
+		 */
+		tmp = 21333 * (10 * rc - zse) / ge;
+	} else {
+		/**
+		 * For Medfield, using the calibration data, we have the
+		 * voltage and current after calibration correction as below:
+		 * V_CAL_CODE = V_RAW_CODE - (VZSE + (VGE)* VRAW_CODE/1023)
+		 * I_CAL_CODE = I_RAW_CODE - (IZSE + (IGE)* IRAW_CODE/1023)
+		 */
+		tmp = (10230 * rc - (10230 * zse + 10 * ge * rc)) / 1023;
+	}
+
+	/* tmp is 10 times of result value,
+	 * and it's used to obtain result's closest integer
+	 */
+	return DIV_ROUND_CLOSEST(tmp, 10);
+
+}
+
+static void gpadc_calc_zse_ge(struct gpadc_info *mgi)
+{
+	u8 data;
+	int fse, zse, fse_sign, zse_sign, ge, ge_sign;
+
+	if (intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_CLOVERVIEW) {
+		gpadc_read(EEPROMCAL1, &data);
+		zse = data & 0xf;
+		ge = (data >> 4) & 0xf;
+		gpadc_read(EEPROMCAL2, &data);
+		zse_sign = (data & (1 << 6)) ? -1 : 1;
+		ge_sign = (data & (1 << 7)) ? -1 : 1;
+		zse *= zse_sign;
+		ge *= ge_sign;
+		/* vzse divided by 2 may cause 0.5, x10 to avoid float */
+		mgi->vzse = mgi->izse = zse * 10 / 2;
+		/* vge multiple 100 to avoid float */
+		mgi->vge = mgi->ige = 21333 - (ge * 100 / 4);
+	} else {
+		/* voltage trim */
+		gpadc_read(EEPROMCAL1, &data);
+		zse = (data & 0xf)/2;
+		fse = ((data >> 4) & 0xf)/2;
+		gpadc_read(EEPROMCAL2, &data);
+		zse_sign = (data & (1 << 6)) ? 1 : 0;
+		fse_sign = (data & (1 << 7)) ? 1 : 0;
+		zse *= zse_sign;
+		fse *= fse_sign;
+		mgi->vzse = zse;
+		mgi->vge = fse - zse;
+
+		/* current trim */
+		fse = (data & 0xf)/2;
+		fse_sign = (data & (1 << 5)) ? 1 : 0;
+		fse = ~(fse_sign * fse) + 1;
+		gpadc_read(ADC1OFFSETH, &data);
+		zse = data << 2;
+		gpadc_read(ADC1OFFSETL, &data);
+		zse += data & 0x3;
+		mgi->izse = zse;
+		mgi->ige = fse + zse;
+	}
+}
+
+static void gpadc_trimming(struct work_struct *work)
+{
+	u8 data;
+	struct gpadc_info *mgi =
+		container_of(work, struct gpadc_info, trimming_work);
+
+	mutex_lock(&mgi->lock);
+	mgi->trimming_start = 1;
+	wake_up(&mgi->trimming_wait);
+	if (gpadc_poweron(mgi, 1)) {
+		dev_err(mgi->dev, "power on failed\n");
+		goto failed;
+	}
+	/* calibration */
+	gpadc_read(ADC1CNTL1, &data);
+	data &= ~ADC1CNTL1_AD1OFFSETEN;
+	data |= ADC1CNTL1_AD1CALEN;
+	gpadc_write(ADC1CNTL1, data);
+	gpadc_read(ADC1INT, &data);
+
+	/*workarround: no calib int */
+	msleep(300);
+	gpadc_set_bits(ADC1INT, ADC1INT_ADC1CAL);
+	gpadc_clear_bits(ADC1CNTL1, ADC1CNTL1_AD1CALEN);
+
+	gpadc_calc_zse_ge(mgi);
+
+	if (gpadc_poweroff(mgi)) {
+		dev_err(mgi->dev, "power off failed\n");
+		goto failed;
+	}
+
+failed:
+	mutex_unlock(&mgi->lock);
+}
+
+static irqreturn_t msic_gpadc_isr(int irq, void *data)
+{
+	struct gpadc_info *mgi = data;
+
+	if (intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_CLOVERVIEW)
+		mgi->irq_status = ADC1INT_RND;
+	else
+		mgi->irq_status = readl(mgi->intr) >> 8 & 0xff;
+
+	return IRQ_WAKE_THREAD;
+}
+
+static irqreturn_t msic_gpadc_irq(int irq, void *data)
+{
+	struct gpadc_info *mgi = data;
+
+	if (mgi->irq_status & ADC1INT_GSM) {
+		mgi->gsmpulse_done = 1;
+		queue_work(mgi->workq, &mgi->gsmpulse_work);
+	} else if (mgi->irq_status & ADC1INT_RND) {
+		mgi->rnd_done = 1;
+		wake_up(&mgi->wait);
+	} else if (mgi->irq_status & ADC1INT_ADC1CAL) {
+		mgi->conv_done = 1;
+		wake_up(&mgi->wait);
+	} else {
+		/* coulomb counter should be handled by firmware. Ignore it */
+		dev_dbg(mgi->dev, "coulomb counter is not support\n");
+	}
+	return IRQ_HANDLED;
+}
+
+static int alloc_channel_addr(struct gpadc_info *mgi, int ch)
+{
+	int i;
+	int addr = -EBUSY;
+	int last = 0;
+
+	for (i = 0; i < GPADC_CH_MAX; i++)
+		if (mgi->addr_mask & (1 << i))
+			last = i;
+
+	for (i = 0; i < GPADC_CH_MAX; i++) {
+		if (!(mgi->addr_mask & (1 << i))) {
+			addr = i;
+			mgi->addr_mask |= 1 << i;
+			if (addr > last) {
+				gpadc_clear_bits(ADC1ADDR0+last, MSIC_STOPCH);
+				gpadc_write(ADC1ADDR0+addr, ch|MSIC_STOPCH);
+			} else {
+				gpadc_write(ADC1ADDR0+addr, ch);
+			}
+			break;
+		}
+	}
+	return addr;
+}
+
+static void free_channel_addr(struct gpadc_info *mgi, int addr)
+{
+	int last = 0;
+	int i;
+
+	mgi->addr_mask &= ~(1 << addr);
+	for (i = 0; i < GPADC_CH_MAX; i++)
+		if (mgi->addr_mask & (1 << i))
+			last = i;
+	if (addr > last)
+		gpadc_set_bits(ADC1ADDR0+last, MSIC_STOPCH);
+}
+
+static void gpadc_gsmpulse_work(struct work_struct *work)
+{
+	int i;
+	u8 data;
+	int tmp;
+	int vol, cur;
+	struct gpadc_info *mgi =
+		container_of(work, struct gpadc_info, gsmpulse_work);
+
+	mutex_lock(&mgi->lock);
+	gpadc_set_bits(ADC1CNTL3, ADC1CNTL3_GSMDATARD);
+
+	vol = 0;
+	cur = 0;
+	for (i = 0; i < 4; i++) {
+		gpadc_read(ADC1BV0H + i * 2, &data);
+		tmp = data << 2;
+		gpadc_read(ADC1BV0H + i * 2 + 1, &data);
+		tmp += data & 0x3;
+		if (tmp > vol)
+			vol = tmp;
+
+		gpadc_read(ADC1BI0H + i * 2, &data);
+		tmp = data << 2;
+		gpadc_read(ADC1BI0H + i * 2 + 1, &data);
+		tmp += data & 0x3;
+		if (tmp > cur)
+			cur = tmp;
+	}
+
+	vol = gpadc_calib(vol, mgi->vzse, mgi->vge);
+	cur = gpadc_calib(cur, mgi->izse, mgi->ige);
+
+	gpadc_set_bits(ADC1INT, ADC1INT_GSM);
+	gpadc_clear_bits(ADC1CNTL3, ADC1CNTL3_GSMDATARD);
+	if (mgi->gsmadc_notify)
+		mgi->gsmadc_notify(vol, cur);
+	mutex_unlock(&mgi->lock);
+}
+
+/**
+ * intel_mid_gpadc_gsmpulse_register - power on gsm adc and register a callback
+ * @fn: callback function after gsm adc conversion is completed
+ *
+ * Returns 0 on success or an error code.
+ *
+ * This function may sleep.
+ */
+int intel_mid_gpadc_gsmpulse_register(void(*fn)(int vol, int cur))
+{
+	int ret = 0;
+	struct gpadc_info *mgi = &gpadc_info;
+
+	if (!mgi->initialized)
+		return -ENODEV;
+	mutex_lock(&mgi->lock);
+	if (!mgi->gsmadc_notify) {
+		gpadc_write(ADC1CNTL2, ADC1CNTL2_DEF);
+		gpadc_set_bits(ADC1CNTL2, ADC1CNTL2_ADCGSMEN);
+		mgi->gsmadc_notify = fn;
+	} else {
+		ret = -EBUSY;
+	}
+	mutex_unlock(&mgi->lock);
+	return ret;
+}
+EXPORT_SYMBOL(intel_mid_gpadc_gsmpulse_register);
+
+/**
+ * intel_mid_gpadc_gsmpulse_unregister - power off gsm adc and unregister
+ *					the callback
+ * @fn: callback function after gsm adc conversion is completed
+ *
+ * Returns 0 on success or an error code.
+ *
+ * This function may sleep.
+ */
+int intel_mid_gpadc_gsmpulse_unregister(void(*fn)(int vol, int cur))
+{
+	int ret = 0;
+	struct gpadc_info *mgi = &gpadc_info;
+
+	if (!mgi->initialized)
+		return -ENODEV;
+	mutex_lock(&mgi->lock);
+	if (mgi->gsmadc_notify == fn) {
+		mgi->gsmadc_notify = NULL;
+		gpadc_clear_bits(ADC1CNTL2, ADC1CNTL2_ADCGSMEN);
+	}
+	mutex_unlock(&mgi->lock);
+	return ret;
+}
+EXPORT_SYMBOL(intel_mid_gpadc_gsmpulse_unregister);
+
+/**
+ * intel_mid_gpadc_sample - do gpadc sample.
+ * @handle: the gpadc handle
+ * @sample_count: do sample serveral times and get the average value.
+ * @...: sampling resulting arguments of all channels. refer to sscanf.
+ *       caller should not access it before return.
+ *
+ * Returns 0 on success or an error code.
+ *
+ * This function may sleep.
+ */
+int intel_mid_gpadc_sample(void *handle, int sample_count, ...)
+{
+
+	struct gpadc_request *rq = handle;
+	struct gpadc_info *mgi = &gpadc_info;
+	int i;
+	u8 data;
+	int ret = 0;
+	int count;
+	int tmp;
+	int *val[GPADC_CH_MAX];
+	va_list args;
+
+	if (!mgi->initialized)
+		return -ENODEV;
+
+	mutex_lock(&mgi->lock);
+	mgi->pmic_ipc_status = 0;
+
+	va_start(args, sample_count);
+	for (i = 0; i < rq->count; i++) {
+		val[i] = va_arg(args, int*);
+		*val[i] = 0;
+	}
+	va_end(args);
+
+	pm_qos_add_request(&mgi->pm_qos_request,
+			PM_QOS_CPU_DMA_LATENCY,	CSTATE_EXIT_LATENCY_S0i1-1);
+	gpadc_poweron(mgi, rq->vref);
+	gpadc_clear_bits(ADC1CNTL1, ADC1CNTL1_AD1OFFSETEN);
+	gpadc_read(ADC1CNTL1, &data);
+	data = (data & ~ADC1CNTL1_ADSLP) + ADC1CNTL1_ADSLP_DEF;
+	gpadc_write(ADC1CNTL1, data);
+	mgi->rnd_done = 0;
+	gpadc_set_bits(ADC1CNTL1, ADC1CNTL1_ADSTRT);
+	for (count = 0; count < sample_count; count++) {
+		if (wait_event_timeout(mgi->wait, mgi->rnd_done, HZ) == 0) {
+			gpadc_dump(mgi);
+			dev_err(mgi->dev, "sample timeout\n");
+			ret = -ETIMEDOUT;
+			goto fail;
+		}
+		gpadc_set_bits(ADC1CNTL3, ADC1CNTL3_RRDATARD);
+		for (i = 0; i < rq->count; ++i) {
+			tmp = 0;
+			gpadc_read(ADC1SNS0H + 2 * rq->addr[i], &data);
+			tmp += data << 2;
+			gpadc_read(ADC1SNS0H + 2 * rq->addr[i] + 1, &data);
+			tmp += data & 0x3;
+
+			if (rq->ch[i] & CH_NEED_VCALIB)
+				tmp = gpadc_calib(tmp, mgi->vzse, mgi->vge);
+			if (rq->ch[i] & CH_NEED_ICALIB)
+				tmp = gpadc_calib(tmp, mgi->izse, mgi->ige);
+
+			*val[i] += tmp;
+		}
+		gpadc_clear_bits(ADC1CNTL3, ADC1CNTL3_RRDATARD);
+		mgi->rnd_done = 0;
+	}
+
+	for (i = 0; i < rq->count; ++i)
+		*val[i] /= sample_count;
+
+fail:
+	gpadc_clear_bits(ADC1CNTL1, ADC1CNTL1_ADSTRT);
+	gpadc_poweroff(mgi);
+	pm_qos_remove_request(&mgi->pm_qos_request);
+
+	if (mgi->pmic_ipc_status) {
+		dev_err(mgi->dev, "sample broken\n");
+		ret = mgi->pmic_ipc_status;
+	}
+	mutex_unlock(&mgi->lock);
+	return ret;
+}
+EXPORT_SYMBOL(intel_mid_gpadc_sample);
+
+/**
+ * get_gpadc_sample() - get gpadc sample.
+ * @handle: the gpadc handle
+ * @sample_count: do sample serveral times and get the average value.
+ * @buffer: sampling resulting arguments of all channels.
+ *
+ * Returns 0 on success or an error code.
+ *
+ * This function may sleep.
+ */
+int get_gpadc_sample(void *handle, int sample_count, int *buffer)
+{
+
+	struct gpadc_request *rq = handle;
+	struct gpadc_info *mgi = &gpadc_info;
+	int i;
+	u8 data;
+	int ret = 0;
+	int count;
+	int tmp;
+
+	if (!mgi->initialized)
+		return -ENODEV;
+
+	mutex_lock(&mgi->lock);
+	mgi->pmic_ipc_status = 0;
+
+	for (i = 0; i < rq->count; i++)
+		buffer[i] = 0;
+
+	pm_qos_add_request(&mgi->pm_qos_request,
+			PM_QOS_CPU_DMA_LATENCY,	CSTATE_EXIT_LATENCY_S0i1-1);
+	gpadc_poweron(mgi, rq->vref);
+	gpadc_clear_bits(ADC1CNTL1, ADC1CNTL1_AD1OFFSETEN);
+	gpadc_read(ADC1CNTL1, &data);
+	data = (data & ~ADC1CNTL1_ADSLP) + ADC1CNTL1_ADSLP_DEF;
+	gpadc_write(ADC1CNTL1, data);
+	mgi->rnd_done = 0;
+	gpadc_set_bits(ADC1CNTL1, ADC1CNTL1_ADSTRT);
+	for (count = 0; count < sample_count; count++) {
+		if (wait_event_timeout(mgi->wait, mgi->rnd_done, HZ) == 0) {
+			gpadc_dump(mgi);
+			dev_err(mgi->dev, "sample timeout\n");
+			ret = -ETIMEDOUT;
+			goto fail;
+		}
+		gpadc_set_bits(ADC1CNTL3, ADC1CNTL3_RRDATARD);
+		for (i = 0; i < rq->count; ++i) {
+			tmp = 0;
+			gpadc_read(ADC1SNS0H + 2 * rq->addr[i], &data);
+			tmp += data << 2;
+			gpadc_read(ADC1SNS0H + 2 * rq->addr[i] + 1, &data);
+			tmp += data & 0x3;
+
+			if (rq->ch[i] & CH_NEED_VCALIB)
+				tmp = gpadc_calib(tmp, mgi->vzse, mgi->vge);
+			if (rq->ch[i] & CH_NEED_ICALIB)
+				tmp = gpadc_calib(tmp, mgi->izse, mgi->ige);
+			buffer[i] += tmp;
+		}
+		gpadc_clear_bits(ADC1CNTL3, ADC1CNTL3_RRDATARD);
+		mgi->rnd_done = 0;
+	}
+
+	for (i = 0; i < rq->count; ++i)
+		buffer[i] /= sample_count;
+
+fail:
+	gpadc_clear_bits(ADC1CNTL1, ADC1CNTL1_ADSTRT);
+	gpadc_poweroff(mgi);
+	pm_qos_remove_request(&mgi->pm_qos_request);
+	if (mgi->pmic_ipc_status) {
+		dev_err(mgi->dev, "sample broken\n");
+		ret = mgi->pmic_ipc_status;
+	}
+	mutex_unlock(&mgi->lock);
+	return ret;
+}
+EXPORT_SYMBOL(get_gpadc_sample);
+
+/**
+ * intel_mid_gpadc_free - free gpadc
+ * @handle: the gpadc handle
+ *
+ * This function may sleep.
+ */
+void intel_mid_gpadc_free(void *handle)
+{
+	struct gpadc_request *rq = handle;
+	struct gpadc_info *mgi = &gpadc_info;
+	int i;
+
+	mutex_lock(&mgi->lock);
+	mgi->pmic_ipc_status = 0;
+	for (i = 0; i < rq->count; i++)
+		free_channel_addr(mgi, rq->addr[i]);
+
+	if (mgi->pmic_ipc_status)
+		dev_err(mgi->dev, "gpadc free broken\n");
+
+	mutex_unlock(&mgi->lock);
+	kfree(rq);
+}
+EXPORT_SYMBOL(intel_mid_gpadc_free);
+
+/**
+ * intel_mid_gpadc_alloc - allocate gpadc for channels
+ * @count: the count of channels
+ * @...: the channel parameters. (channel idx | flags)
+ *       flags:
+ *             CH_NEED_VCALIB   it needs voltage calibration
+ *             CH_NEED_ICALIB   it needs current calibration
+ *
+ * Returns gpadc handle on success or NULL on fail.
+ *
+ * This function may sleep.
+ */
+void *intel_mid_gpadc_alloc(int count, ...)
+{
+	struct gpadc_request *rq;
+	struct gpadc_info *mgi = &gpadc_info;
+	va_list args;
+	int ch;
+	int i;
+
+	if (!mgi->initialized)
+		return NULL;
+
+	rq = kzalloc(sizeof(struct gpadc_request), GFP_KERNEL);
+	if (rq == NULL)
+		return NULL;
+
+	va_start(args, count);
+	mutex_lock(&mgi->lock);
+	mgi->pmic_ipc_status = 0;
+
+	rq->count = count;
+	for (i = 0; i < count; i++) {
+		ch = va_arg(args, int);
+		rq->ch[i] = ch;
+		if (ch & CH_NEED_VREF)
+			rq->vref = 1;
+		ch &= 0xf;
+		rq->addr[i] = alloc_channel_addr(mgi, ch);
+		if (rq->addr[i] < 0) {
+			dev_err(mgi->dev, "alloc addr failed\n");
+			while (i-- > 0)
+				free_channel_addr(mgi, rq->addr[i]);
+			kfree(rq);
+			rq = NULL;
+			break;
+		}
+	}
+	if (mgi->pmic_ipc_status)
+		dev_err(mgi->dev, "gpadc alloc broken\n");
+
+	mutex_unlock(&mgi->lock);
+	va_end(args);
+
+	return rq;
+}
+EXPORT_SYMBOL(intel_mid_gpadc_alloc);
+
+ /**
+ * gpadc_alloc_channels - allocate gpadc for channels
+ * @count: the count of channels
+ * @...: the channel parameters. (channel idx | flags)
+ *       flags:
+ *             CH_NEED_VCALIB   it needs voltage calibration
+ *             CH_NEED_ICALIB   it needs current calibration
+ *
+ * Returns gpadc handle on success or NULL on fail.
+ *
+ * This function may sleep.
+ *
+ * TODO: Cleanup intel_mid_gpadc_alloc() once all its users
+ *       are moved to gpadc_alloc_channels()
+ *
+ */
+
+void *gpadc_alloc_channels(int n, int *channel_info)
+{
+	struct gpadc_request *rq;
+	struct gpadc_info *mgi = &gpadc_info;
+	int ch;
+	int i;
+
+	if (!mgi->initialized)
+		return NULL;
+
+	rq = kzalloc(sizeof(struct gpadc_request), GFP_KERNEL);
+	if (rq == NULL)
+		return NULL;
+
+	mutex_lock(&mgi->lock);
+	mgi->pmic_ipc_status = 0;
+
+	rq->count = n;
+	for (i = 0; i < n; i++) {
+		ch = channel_info[i];
+		rq->ch[i] = ch;
+		if (ch & CH_NEED_VREF)
+			rq->vref = 1;
+		ch &= 0xf;
+		rq->addr[i] = alloc_channel_addr(mgi, ch);
+		if (rq->addr[i] < 0) {
+			dev_err(mgi->dev, "alloc addr failed\n");
+			while (i-- > 0)
+				free_channel_addr(mgi, rq->addr[i]);
+			kfree(rq);
+			rq = NULL;
+			break;
+		}
+	}
+	if (mgi->pmic_ipc_status)
+		dev_err(mgi->dev, "gpadc alloc broken\n");
+
+	mutex_unlock(&mgi->lock);
+
+	return rq;
+}
+EXPORT_SYMBOL(gpadc_alloc_channels);
+
+static ssize_t intel_mid_gpadc_store_alloc_channel(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t size)
+{
+	int val, hdn;
+	int ch[SAMPLE_CH_MAX];
+
+	val = sscanf(buf, "%d %x %x", &hdn, &ch[0], &ch[1]);
+
+	if (val < 2 || val > 3) {
+		dev_err(dev, "invalid number of arguments");
+		return -EINVAL;
+	}
+
+	if (hdn < 1 || hdn > GPADC_CH_MAX) {
+		dev_err(dev, "invalid handle value");
+		return -EINVAL;
+	}
+
+	if (adc_handle[hdn - 1]) {
+		dev_err(dev, "adc handle %d has been occupied", hdn);
+		return -EBUSY;
+	}
+
+	if (val == 2)
+		adc_handle[hdn - 1] = intel_mid_gpadc_alloc(1, ch[0]);
+	else
+		adc_handle[hdn - 1] = intel_mid_gpadc_alloc(2, ch[0], ch[1]);
+
+	if (!adc_handle[hdn - 1]) {
+		dev_err(dev, "allocating adc handle %d failed", hdn);
+		return -ENOMEM;
+	}
+
+	return size;
+}
+
+static ssize_t intel_mid_gpadc_store_free_channel(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t size)
+{
+	int hdn;
+
+	if (sscanf(buf, "%d", &hdn) != 1) {
+		dev_err(dev, "invalid number of argument");
+		return -EINVAL;
+	}
+
+	if (hdn < 1 || hdn > GPADC_CH_MAX) {
+		dev_err(dev, "invalid handle value");
+		return -EINVAL;
+	}
+
+	if (adc_handle[hdn - 1]) {
+		intel_mid_gpadc_free(adc_handle[hdn - 1]);
+		adc_handle[hdn - 1] = NULL;
+	}
+
+	return size;
+}
+
+static ssize_t intel_mid_gpadc_store_sample(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t size)
+{
+	int hdn, spc;
+	int ret;
+	struct gpadc_request *rq;
+
+	if (sscanf(buf, "%d %d", &hdn, &spc) != 2) {
+		dev_err(dev, "invalid number of arguments");
+		return -EINVAL;
+	}
+
+	if (hdn < 1 || hdn > GPADC_CH_MAX) {
+		dev_err(dev, "invalid handle value");
+		return -EINVAL;
+	}
+
+	rq = adc_handle[hdn - 1];
+	if (!rq) {
+		dev_err(dev, "null handle");
+		return -EINVAL;
+	}
+
+	if (rq->count == 1)
+		ret = intel_mid_gpadc_sample(adc_handle[hdn-1],
+			spc, &sample_result[hdn - 1][0]);
+	else
+		ret = intel_mid_gpadc_sample(adc_handle[hdn - 1],
+			spc, &sample_result[hdn - 1][0],
+			&sample_result[hdn - 1][1]);
+
+	if (ret) {
+		dev_err(dev, "sampling failed. adc handle: %d", hdn);
+		return -EINVAL;
+	}
+
+	return size;
+}
+
+static ssize_t intel_mid_gpadc_show_sample(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	int hdc;
+	int used = 0;
+	struct gpadc_request *rq;
+
+	for (hdc = 0; hdc < GPADC_CH_MAX; hdc++) {
+		if (adc_handle[hdc]) {
+			rq = adc_handle[hdc];
+			if (rq->count == 1)
+				used += snprintf(buf + used, PAGE_SIZE - used,
+					  "%d ", sample_result[hdc][0]);
+			else
+				used += snprintf(buf + used, PAGE_SIZE - used,
+					  "%d %d ", sample_result[hdc][0],
+					  sample_result[hdc][1]);
+		}
+	}
+
+	return used;
+}
+
+
+static void gsmpulse_sysfs_callback(int vol, int cur)
+{
+	vol_val = vol;
+	cur_val = cur;
+	complete(&gsmadc_complete);
+}
+
+static ssize_t intel_mid_gpadc_show_gsmpulse_sample(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	int ret;
+
+	reinit_completion(&gsmadc_complete);
+	intel_mid_gpadc_gsmpulse_register(gsmpulse_sysfs_callback);
+	ret = wait_for_completion_interruptible(&gsmadc_complete);
+	intel_mid_gpadc_gsmpulse_unregister(gsmpulse_sysfs_callback);
+	if (ret)
+		return 0;
+	else
+		return snprintf(buf, PAGE_SIZE, "%d %d", vol_val, cur_val);
+}
+
+static DEVICE_ATTR(alloc_channel, S_IWUSR, NULL,
+		intel_mid_gpadc_store_alloc_channel);
+static DEVICE_ATTR(free_channel, S_IWUSR, NULL,
+		intel_mid_gpadc_store_free_channel);
+static DEVICE_ATTR(sample, S_IRUGO | S_IWUSR,
+		intel_mid_gpadc_show_sample, intel_mid_gpadc_store_sample);
+static DEVICE_ATTR(gsmpulse_sample, S_IRUGO,
+		intel_mid_gpadc_show_gsmpulse_sample, NULL);
+
+static struct attribute *intel_mid_gpadc_attrs[] = {
+	&dev_attr_alloc_channel.attr,
+	&dev_attr_free_channel.attr,
+	&dev_attr_sample.attr,
+	&dev_attr_gsmpulse_sample.attr,
+	NULL,
+};
+
+static struct attribute_group intel_mid_gpadc_attr_group = {
+	.name = "mid_gpadc",
+	.attrs = intel_mid_gpadc_attrs,
+};
+
+static int msic_gpadc_probe(struct platform_device *pdev)
+{
+	struct gpadc_info *mgi = &gpadc_info;
+	struct intel_mid_gpadc_platform_data *pdata = pdev->dev.platform_data;
+	int err = 0;
+
+	mutex_init(&mgi->lock);
+	init_waitqueue_head(&mgi->wait);
+	init_waitqueue_head(&mgi->trimming_wait);
+	mgi->workq = create_singlethread_workqueue(dev_name(&pdev->dev));
+	if (mgi->workq == NULL)
+		return -ENOMEM;
+
+	mgi->dev = &pdev->dev;
+	mgi->intr = ioremap_nocache(pdata->intr, 4);
+	mgi->irq = platform_get_irq(pdev, 0);
+
+	gpadc_clear_bits(IRQLVL1MSK, IRQLVL1MSK_ADCM);
+	if (request_threaded_irq(mgi->irq, msic_gpadc_isr, msic_gpadc_irq,
+					IRQF_ONESHOT, "msic_adc", mgi)) {
+		dev_err(&pdev->dev, "unable to register irq %d\n", mgi->irq);
+		err = -ENODEV;
+		goto err_exit;
+	}
+
+	gpadc_write(ADC1ADDR0, MSIC_STOPCH);
+	INIT_WORK(&mgi->trimming_work, gpadc_trimming);
+	INIT_WORK(&mgi->gsmpulse_work, gpadc_gsmpulse_work);
+	queue_work(mgi->workq, &mgi->trimming_work);
+	wait_event(mgi->trimming_wait, mgi->trimming_start);
+	mgi->initialized = 1;
+
+	init_completion(&gsmadc_complete);
+
+	err = sysfs_create_group(&pdev->dev.kobj,
+			&intel_mid_gpadc_attr_group);
+	if (err) {
+		dev_err(&pdev->dev, "Unable to export sysfs interface, error: %d\n",
+			err);
+		goto err_release_irq;
+	}
+
+	return 0;
+
+err_release_irq:
+	free_irq(mgi->irq, mgi);
+err_exit:
+	if (mgi->intr)
+		iounmap(mgi->intr);
+	return err;
+}
+
+static int msic_gpadc_remove(struct platform_device *pdev)
+{
+	struct gpadc_info *mgi = &gpadc_info;
+
+	sysfs_remove_group(&pdev->dev.kobj, &intel_mid_gpadc_attr_group);
+	free_irq(mgi->irq, mgi);
+	iounmap(mgi->intr);
+	flush_workqueue(mgi->workq);
+	destroy_workqueue(mgi->workq);
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int msic_gpadc_suspend_noirq(struct device *dev)
+{
+	struct gpadc_info *mgi = &gpadc_info;
+
+	/* If the gpadc is locked, it means gpadc is still in active mode. */
+	if (mutex_trylock(&mgi->lock))
+		return 0;
+	else
+		return -EBUSY;
+}
+
+static int msic_gpadc_resume_noirq(struct device *dev)
+{
+	struct gpadc_info *mgi = &gpadc_info;
+
+	mutex_unlock(&mgi->lock);
+	return 0;
+}
+#else
+#define msic_gpadc_suspend_noirq    NULL
+#define msic_gpadc_resume_noirq     NULL
+#endif
+
+static const struct dev_pm_ops msic_gpadc_driver_pm_ops = {
+	.suspend_noirq	= msic_gpadc_suspend_noirq,
+	.resume_noirq	= msic_gpadc_resume_noirq,
+};
+
+static struct platform_driver msic_gpadc_driver = {
+	.driver = {
+		   .name = "msic_adc",
+		   .owner = THIS_MODULE,
+		   .pm = &msic_gpadc_driver_pm_ops,
+		   },
+	.probe = msic_gpadc_probe,
+	.remove = msic_gpadc_remove,
+};
+
+static int msic_gpadc_module_init(void)
+{
+	return platform_driver_register(&msic_gpadc_driver);
+}
+
+static void msic_gpadc_module_exit(void)
+{
+	platform_driver_unregister(&msic_gpadc_driver);
+}
+
+static int msic_adc_rpmsg_probe(struct rpmsg_channel *rpdev)
+{
+	int ret = 0;
+
+	if (rpdev == NULL) {
+		pr_err("rpmsg channel not created\n");
+		ret = -ENODEV;
+		goto out;
+	}
+
+	dev_info(&rpdev->dev, "Probed msic_gpadc rpmsg device\n");
+
+	ret = msic_gpadc_module_init();
+
+out:
+	return ret;
+}
+
+static void msic_adc_rpmsg_remove(struct rpmsg_channel *rpdev)
+{
+	msic_gpadc_module_exit();
+	dev_info(&rpdev->dev, "Removed msic_gpadc rpmsg device\n");
+}
+
+static void msic_adc_rpmsg_cb(struct rpmsg_channel *rpdev, void *data,
+					int len, void *priv, u32 src)
+{
+	dev_warn(&rpdev->dev, "unexpected, message\n");
+
+	print_hex_dump(KERN_DEBUG, __func__, DUMP_PREFIX_NONE, 16, 1,
+		       data, len,  true);
+}
+
+static struct rpmsg_device_id msic_adc_rpmsg_id_table[] = {
+	{ .name	= "rpmsg_msic_adc" },
+	{ },
+};
+MODULE_DEVICE_TABLE(rpmsg, msic_adc_rpmsg_id_table);
+
+static struct rpmsg_driver msic_adc_rpmsg = {
+	.drv.name	= KBUILD_MODNAME,
+	.drv.owner	= THIS_MODULE,
+	.id_table	= msic_adc_rpmsg_id_table,
+	.probe		= msic_adc_rpmsg_probe,
+	.callback	= msic_adc_rpmsg_cb,
+	.remove		= msic_adc_rpmsg_remove,
+};
+
+static int __init msic_adc_rpmsg_init(void)
+{
+	return register_rpmsg_driver(&msic_adc_rpmsg);
+}
+
+#ifdef MODULE
+module_init(msic_adc_rpmsg_init);
+#else
+rootfs_initcall(msic_adc_rpmsg_init);
+#endif
+
+static void __exit msic_adc_rpmsg_exit(void)
+{
+	return unregister_rpmsg_driver(&msic_adc_rpmsg);
+}
+module_exit(msic_adc_rpmsg_exit);
+
+MODULE_AUTHOR("Jenny TC <jenny.tc@intel.com>");
+MODULE_DESCRIPTION("Intel Medfield MSIC GPADC Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/misc/Kconfig b/drivers/misc/Kconfig
index 6cb388e..f068def 100644
--- a/drivers/misc/Kconfig
+++ b/drivers/misc/Kconfig
@@ -147,6 +147,18 @@ config INTEL_MID_PTI
 	  an Intel Atom (non-netbook) mobile device containing a MIPI
 	  P1149.7 standard implementation.
 
+config INTEL_PTI_STM
+	tristate "MIPI Sytem Trace Macro (STM) for Intel"
+	default n
+	depends on INTEL_MID_PTI
+	help
+	  The STM (Sytem Trace Monitor) driver control trace data
+	  route through an Intel Tangier PTI port or through USB xDCI
+	  interface with Debug-Class DvC.Trace support.
+
+	  It provide the ability to PTI driver to setup the output and
+	  to user to change the output with sysfs and exported header.
+
 config SGI_IOC4
 	tristate "SGI IOC4 Base IO support"
 	depends on PCI
@@ -515,6 +527,20 @@ config SRAM
 	  the genalloc API. It is supposed to be used for small on-chip SRAM
 	  areas found on many SoCs.
 
+config EMMC_IPANIC
+	bool "Intel kernel panic diagnostics driver FOR EMMC"
+	default n
+	---help---
+	  Driver which handles kernel panics and attempts to write
+	  critical debugging data to EMMC.
+
+config EMMC_IPANIC_PLABEL
+	string "Intel kernel panic driver (EMMC_IPANIC) partition label"
+	depends on EMMC_IPANIC
+	default "panic"
+	---help---
+	  Set the default mmc partition label for EMMC_IPANIC driver.
+
 source "drivers/misc/c2port/Kconfig"
 source "drivers/misc/eeprom/Kconfig"
 source "drivers/misc/cb710/Kconfig"
@@ -524,6 +550,7 @@ source "drivers/misc/carma/Kconfig"
 source "drivers/misc/altera-stapl/Kconfig"
 source "drivers/misc/mei/Kconfig"
 source "drivers/misc/vmw_vmci/Kconfig"
+source "drivers/misc/bcm-lpm/Kconfig"
 source "drivers/misc/mic/Kconfig"
 source "drivers/misc/genwqe/Kconfig"
 endmenu
diff --git a/drivers/misc/Makefile b/drivers/misc/Makefile
index 99b9424..2d49352 100644
--- a/drivers/misc/Makefile
+++ b/drivers/misc/Makefile
@@ -7,6 +7,7 @@ obj-$(CONFIG_AD525X_DPOT)	+= ad525x_dpot.o
 obj-$(CONFIG_AD525X_DPOT_I2C)	+= ad525x_dpot-i2c.o
 obj-$(CONFIG_AD525X_DPOT_SPI)	+= ad525x_dpot-spi.o
 obj-$(CONFIG_INTEL_MID_PTI)	+= pti.o
+obj-$(CONFIG_INTEL_PTI_STM)	+= stm.o
 obj-$(CONFIG_ATMEL_PWM)		+= atmel_pwm.o
 obj-$(CONFIG_ATMEL_SSC)		+= atmel-ssc.o
 obj-$(CONFIG_ATMEL_TCLIB)	+= atmel_tclib.o
@@ -52,5 +53,7 @@ obj-$(CONFIG_INTEL_MEI)		+= mei/
 obj-$(CONFIG_VMWARE_VMCI)	+= vmw_vmci/
 obj-$(CONFIG_LATTICE_ECP3_CONFIG)	+= lattice-ecp3-config.o
 obj-$(CONFIG_SRAM)		+= sram.o
+obj-$(CONFIG_BCM_BT_LPM)	+=bcm-lpm/
+obj-$(CONFIG_EMMC_IPANIC)	+= emmc_ipanic.o
 obj-y				+= mic/
 obj-$(CONFIG_GENWQE)		+= genwqe/
diff --git a/drivers/misc/bcm-lpm/Kconfig b/drivers/misc/bcm-lpm/Kconfig
new file mode 100644
index 0000000..cb8443a
--- /dev/null
+++ b/drivers/misc/bcm-lpm/Kconfig
@@ -0,0 +1,6 @@
+config BCM_BT_LPM
+	tristate "Broadcom Bluetooth Low Power Mode"
+	depends on SERIAL_MFD_HSU
+	default m
+	help
+	   Select this module for Broadcom Bluetooth low power management.
diff --git a/drivers/misc/bcm-lpm/Makefile b/drivers/misc/bcm-lpm/Makefile
new file mode 100644
index 0000000..6dd43fd
--- /dev/null
+++ b/drivers/misc/bcm-lpm/Makefile
@@ -0,0 +1 @@
+obj-$(CONFIG_BCM_BT_LPM) += bcm_bt_lpm.o
diff --git a/drivers/misc/bcm-lpm/bcm_bt_lpm.c b/drivers/misc/bcm-lpm/bcm_bt_lpm.c
new file mode 100644
index 0000000..335a925
--- /dev/null
+++ b/drivers/misc/bcm-lpm/bcm_bt_lpm.c
@@ -0,0 +1,581 @@
+/*
+ * Bluetooth Broadcomm  and low power control via GPIO
+ *
+ *  Copyright (C) 2011 Google, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of the GNU General Public License as published by
+ *  the Free Software Foundation; either version 2 of the License, or
+ *  (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ *
+ */
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/gpio.h>
+#include <linux/hrtimer.h>
+#include <linux/irq.h>
+#include <linux/rfkill.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/pm_runtime.h>
+#include <linux/delay.h>
+#include <asm/intel-mid.h>
+#include <asm/intel_mid_hsu.h>
+
+#ifndef CONFIG_ACPI
+#include <asm/bcm_bt_lpm.h>
+#else
+#include <linux/acpi.h>
+#include <linux/acpi_gpio.h>
+
+enum {
+	gpio_wake_acpi_idx,
+	gpio_enable_bt_acpi_idx,
+	host_wake_acpi_idx
+};
+#endif
+
+static struct rfkill *bt_rfkill;
+static bool bt_enabled;
+static bool host_wake_uart_enabled;
+static bool wake_uart_enabled;
+static bool int_handler_enabled;
+
+#define LPM_ON
+
+static void activate_irq_handler(void);
+
+struct bcm_bt_lpm {
+	unsigned int gpio_wake;
+	unsigned int gpio_host_wake;
+	unsigned int int_host_wake;
+	unsigned int gpio_enable_bt;
+
+	int wake;
+	int host_wake;
+
+	struct hrtimer enter_lpm_timer;
+	ktime_t enter_lpm_delay;
+
+	struct device *tty_dev;
+
+	int port;
+} bt_lpm;
+
+#ifdef LPM_ON
+static void uart_enable(struct device *tty)
+{
+	pr_debug("%s: runtime get\n", __func__);
+	/* Tell PM runtime to power on the tty device and block s0i3 */
+	pm_runtime_get(tty);
+}
+
+static void uart_disable(struct device *tty)
+{
+	pr_debug("%s: runtime put\n", __func__);
+	/* Tell PM runtime to release tty device and allow s0i3 */
+	pm_runtime_put(tty);
+}
+#endif
+
+#ifdef CONFIG_ACPI
+static int bcm_bt_lpm_acpi_probe(struct platform_device *pdev)
+{
+	struct acpi_gpio_info info;
+	acpi_handle handle;
+	acpi_integer port;
+
+	/*
+	 * Handle ACPI specific initializations.
+	 */
+	dev_dbg(&pdev->dev, "BCM2E1A ACPI specific probe\n");
+
+	bt_lpm.gpio_enable_bt = acpi_get_gpio_by_index(&pdev->dev,
+						gpio_enable_bt_acpi_idx, &info);
+	if (!gpio_is_valid(bt_lpm.gpio_enable_bt)) {
+		pr_err("%s: gpio %d for gpio_enable_bt not valid\n", __func__,
+							bt_lpm.gpio_enable_bt);
+		return -EINVAL;
+	}
+
+#ifdef LPM_ON
+	bt_lpm.gpio_wake = acpi_get_gpio_by_index(&pdev->dev,
+						gpio_wake_acpi_idx, &info);
+	if (!gpio_is_valid(bt_lpm.gpio_wake)) {
+		pr_err("%s: gpio %d for gpio_wake not valid\n", __func__,
+							bt_lpm.gpio_wake);
+		return -EINVAL;
+	}
+
+	bt_lpm.gpio_host_wake = acpi_get_gpio_by_index(&pdev->dev,
+						host_wake_acpi_idx, &info);
+	if (!gpio_is_valid(bt_lpm.gpio_host_wake)) {
+		pr_err("%s: gpio %d for gpio_host_wake not valid\n", __func__,
+							bt_lpm.gpio_host_wake);
+		return -EINVAL;
+	}
+
+	bt_lpm.int_host_wake = gpio_to_irq(bt_lpm.gpio_host_wake);
+
+	pr_debug("%s: gpio_wake %d, gpio_host_wake %d, int_host_wake %d\n",
+							__func__,
+							bt_lpm.gpio_wake,
+							bt_lpm.gpio_host_wake,
+							bt_lpm.int_host_wake);
+#endif
+
+	handle = DEVICE_ACPI_HANDLE(&pdev->dev);
+
+	if (ACPI_FAILURE(acpi_evaluate_integer(handle, "UART", NULL, &port))) {
+		dev_err(&pdev->dev, "Error evaluating UART port number\n");
+
+		/* FIXME - Force port 0 if the information is missing from the
+		 * ACPI table.
+		 * That will be removed once the ACPI tables will all have been
+		 * updated.
+		 */
+		 port = 0;
+	}
+
+	bt_lpm.port = port;
+	pr_debug("%s: UART port %d\n", __func__, bt_lpm.port);
+
+	return 0;
+}
+#endif /* CONFIG_ACPI */
+
+static int bcm43xx_bt_rfkill_set_power(void *data, bool blocked)
+{
+	/* rfkill_ops callback. Turn transmitter on when blocked is false */
+
+	if (!blocked) {
+		gpio_set_value(bt_lpm.gpio_wake, 1);
+		/*
+		* Delay advice by BRCM is min 2.5ns,
+		* setting it between 10 and 50us for more confort
+		*/
+		usleep_range(10, 50);
+
+		gpio_set_value(bt_lpm.gpio_enable_bt, 1);
+		pr_debug("%s: turn BT on\n", __func__);
+	} else {
+		gpio_set_value(bt_lpm.gpio_enable_bt, 0);
+		pr_debug("%s: turn BT off\n", __func__);
+	}
+
+	bt_enabled = !blocked;
+
+	return 0;
+}
+
+static const struct rfkill_ops bcm43xx_bt_rfkill_ops = {
+	.set_block = bcm43xx_bt_rfkill_set_power,
+};
+
+#ifdef LPM_ON
+static void set_wake_locked(int wake)
+{
+	bt_lpm.wake = wake;
+
+	if (!wake_uart_enabled && wake) {
+		WARN_ON(!bt_lpm.tty_dev);
+		uart_enable(bt_lpm.tty_dev);
+	}
+
+	gpio_set_value(bt_lpm.gpio_wake, wake);
+
+	if (wake_uart_enabled && !wake) {
+		WARN_ON(!bt_lpm.tty_dev);
+		uart_disable(bt_lpm.tty_dev);
+	}
+	wake_uart_enabled = wake;
+}
+
+static enum hrtimer_restart enter_lpm(struct hrtimer *timer)
+{
+	pr_debug("%s\n", __func__);
+
+	set_wake_locked(0);
+
+	return HRTIMER_NORESTART;
+}
+
+
+static void update_host_wake_locked(int host_wake)
+{
+	if (host_wake == bt_lpm.host_wake)
+		return;
+
+	bt_lpm.host_wake = host_wake;
+
+	if (host_wake) {
+		if (!host_wake_uart_enabled) {
+			WARN_ON(!bt_lpm.tty_dev);
+			uart_enable(bt_lpm.tty_dev);
+		}
+	} else  {
+		if (host_wake_uart_enabled) {
+			WARN_ON(!bt_lpm.tty_dev);
+			uart_disable(bt_lpm.tty_dev);
+		}
+	}
+
+	host_wake_uart_enabled = host_wake;
+
+}
+
+static irqreturn_t host_wake_isr(int irq, void *dev)
+{
+	int host_wake;
+
+	host_wake = gpio_get_value(bt_lpm.gpio_host_wake);
+
+	pr_debug("%s: lpm %s\n", __func__, host_wake ? "off" : "on");
+
+	irq_set_irq_type(irq, host_wake ? IRQF_TRIGGER_FALLING :
+							IRQF_TRIGGER_RISING);
+
+	if (!bt_lpm.tty_dev) {
+		bt_lpm.host_wake = host_wake;
+		return IRQ_HANDLED;
+	}
+
+	update_host_wake_locked(host_wake);
+
+	return IRQ_HANDLED;
+}
+
+static void activate_irq_handler(void)
+{
+	int ret;
+
+	pr_debug("%s\n", __func__);
+
+	ret = request_irq(bt_lpm.int_host_wake, host_wake_isr,
+				IRQF_TRIGGER_RISING, "bt_host_wake", NULL);
+
+	if (ret < 0) {
+		pr_err("Error lpm request IRQ");
+		gpio_free(bt_lpm.gpio_wake);
+		gpio_free(bt_lpm.gpio_host_wake);
+	}
+}
+
+
+static void bcm_bt_lpm_wake_peer(struct device *dev)
+{
+	bt_lpm.tty_dev = dev;
+
+	/*
+	 * the irq is enabled after the first host wake up signal.
+	 * in the original code, the irq should be in levels but, since mfld
+	 * does not support them, irq is triggering with edges.
+	 */
+
+	if (!int_handler_enabled) {
+		int_handler_enabled = true;
+		activate_irq_handler();
+	}
+
+	hrtimer_try_to_cancel(&bt_lpm.enter_lpm_timer);
+
+	set_wake_locked(1);
+
+	hrtimer_start(&bt_lpm.enter_lpm_timer, bt_lpm.enter_lpm_delay,
+		HRTIMER_MODE_REL);
+
+}
+
+static int bcm_bt_lpm_init(struct platform_device *pdev)
+{
+	int ret;
+	struct device *tty_dev;
+
+	hrtimer_init(&bt_lpm.enter_lpm_timer, CLOCK_MONOTONIC,
+							HRTIMER_MODE_REL);
+	bt_lpm.enter_lpm_delay = ktime_set(1, 0);  /* 1 sec */
+	bt_lpm.enter_lpm_timer.function = enter_lpm;
+
+	bt_lpm.host_wake = 0;
+
+	if (bt_lpm.gpio_host_wake < 0) {
+		pr_err("Error bt_lpm.gpio_host_wake\n");
+		return -ENODEV;
+	}
+
+	ret = irq_set_irq_wake(bt_lpm.int_host_wake, 1);
+	if (ret < 0) {
+		pr_err("Error lpm set irq IRQ");
+		gpio_free(bt_lpm.gpio_wake);
+		gpio_free(bt_lpm.gpio_host_wake);
+		return ret;
+	}
+
+	tty_dev = intel_mid_hsu_set_wake_peer(bt_lpm.port,
+			bcm_bt_lpm_wake_peer);
+	if (!tty_dev) {
+		pr_err("Error no tty dev");
+		gpio_free(bt_lpm.gpio_wake);
+		gpio_free(bt_lpm.gpio_host_wake);
+		return -ENODEV;
+	}
+
+	bcm_bt_lpm_wake_peer(tty_dev);
+	return 0;
+}
+#endif
+
+#ifndef CONFIG_ACPI
+static int bcm43xx_bluetooth_pdata_probe(struct platform_device *pdev)
+{
+	struct bcm_bt_lpm_platform_data *pdata = pdev->dev.platform_data;
+
+	if (pdata == NULL) {
+		pr_err("Cannot register bcm_bt_lpm drivers, pdata is NULL\n");
+		return -EINVAL;
+	}
+
+	if (!gpio_is_valid(pdata->gpio_enable)) {
+		pr_err("%s: gpio not valid\n", __func__);
+		return -EINVAL;
+	}
+
+#ifdef LPM_ON
+	if (!gpio_is_valid(pdata->gpio_wake) ||
+		!gpio_is_valid(pdata->gpio_host_wake)) {
+		pr_err("%s: gpio not valid\n", __func__);
+		return -EINVAL;
+	}
+#endif
+
+	bt_lpm.gpio_wake = pdata->gpio_wake;
+	bt_lpm.gpio_host_wake = pdata->gpio_host_wake;
+	bt_lpm.int_host_wake = pdata->int_host_wake;
+	bt_lpm.gpio_enable_bt = pdata->gpio_enable;
+
+	bt_lpm.port = pdata->port;
+
+	return 0;
+}
+#endif /* !CONFIG_ACPI */
+
+static int bcm43xx_bluetooth_probe(struct platform_device *pdev)
+{
+	bool default_state = true;	/* off */
+	int ret = 0;
+
+	int_handler_enabled = false;
+
+#ifdef CONFIG_ACPI
+	if (ACPI_HANDLE(&pdev->dev)) {
+		/*
+		 * acpi specific probe
+		 */
+		pr_debug("%s for ACPI device %s\n", __func__,
+							dev_name(&pdev->dev));
+		if (bcm_bt_lpm_acpi_probe(pdev) < 0)
+			ret = -EINVAL;
+	} else
+		ret = -ENODEV;
+#else
+	ret = bcm43xx_bluetooth_pdata_probe(pdev);
+#endif
+
+	if (ret < 0) {
+		pr_err("%s: Cannot register platform data\n", __func__);
+		goto err_data_probe;
+	}
+
+	ret = gpio_request(bt_lpm.gpio_enable_bt, pdev->name);
+	if (ret < 0) {
+		pr_err("%s: Unable to request gpio %d\n", __func__,
+							bt_lpm.gpio_enable_bt);
+		goto err_gpio_enable_req;
+	}
+
+	ret = gpio_direction_output(bt_lpm.gpio_enable_bt, 0);
+	if (ret < 0) {
+		pr_err("%s: Unable to set int direction for gpio %d\n",
+					__func__, bt_lpm.gpio_enable_bt);
+		goto err_gpio_enable_dir;
+	}
+
+#ifdef LPM_ON
+	ret = gpio_request(bt_lpm.gpio_host_wake, pdev->name);
+	if (ret < 0) {
+		pr_err("%s: Unable to request gpio %d\n",
+					__func__, bt_lpm.gpio_host_wake);
+		goto err_gpio_host_wake_req;
+	}
+
+	ret = gpio_direction_input(bt_lpm.gpio_host_wake);
+	if (ret < 0) {
+		pr_err("%s: Unable to set direction for gpio %d\n", __func__,
+							bt_lpm.gpio_host_wake);
+		goto err_gpio_host_wake_dir;
+	}
+
+	ret = gpio_request(bt_lpm.gpio_wake, pdev->name);
+	if (ret < 0) {
+		pr_err("%s: Unable to request gpio %d\n", __func__,
+							bt_lpm.gpio_wake);
+		goto err_gpio_wake_req;
+	}
+
+	ret =  gpio_direction_output(bt_lpm.gpio_wake, 0);
+	if (ret < 0) {
+		pr_err("%s: Unable to set direction for gpio %d\n", __func__,
+							bt_lpm.gpio_wake);
+		goto err_gpio_wake_dir;
+	}
+
+	pr_debug("%s: gpio_enable=%d, gpio_wake=%d, gpio_host_wake=%d\n",
+							__func__,
+							bt_lpm.gpio_enable_bt,
+							bt_lpm.gpio_wake,
+							bt_lpm.gpio_host_wake);
+#endif
+
+	bt_rfkill = rfkill_alloc("bcm43xx Bluetooth", &pdev->dev,
+				RFKILL_TYPE_BLUETOOTH, &bcm43xx_bt_rfkill_ops,
+				NULL);
+	if (unlikely(!bt_rfkill)) {
+		ret = -ENOMEM;
+		goto err_rfkill_alloc;
+	}
+
+	bcm43xx_bt_rfkill_set_power(NULL, default_state);
+	rfkill_init_sw_state(bt_rfkill, default_state);
+
+	ret = rfkill_register(bt_rfkill);
+	if (unlikely(ret))
+		goto err_rfkill_register;
+
+#ifdef LPM_ON
+	ret = bcm_bt_lpm_init(pdev);
+	if (ret)
+		goto err_lpm_init;
+#endif
+
+	return ret;
+
+err_lpm_init:
+	rfkill_unregister(bt_rfkill);
+err_rfkill_register:
+	rfkill_destroy(bt_rfkill);
+err_rfkill_alloc:
+#ifdef LPM_ON
+err_gpio_wake_dir:
+	gpio_free(bt_lpm.gpio_wake);
+err_gpio_wake_req:
+err_gpio_host_wake_dir:
+	gpio_free(bt_lpm.gpio_host_wake);
+err_gpio_host_wake_req:
+#endif
+err_gpio_enable_dir:
+	gpio_free(bt_lpm.gpio_enable_bt);
+err_gpio_enable_req:
+err_data_probe:
+	return ret;
+}
+
+static int bcm43xx_bluetooth_remove(struct platform_device *pdev)
+{
+	rfkill_unregister(bt_rfkill);
+	rfkill_destroy(bt_rfkill);
+
+	gpio_free(bt_lpm.gpio_enable_bt);
+#ifdef LPM_ON
+	gpio_free(bt_lpm.gpio_wake);
+	gpio_free(bt_lpm.gpio_host_wake);
+#endif
+	return 0;
+}
+#ifdef LPM_ON
+int bcm43xx_bluetooth_suspend(struct platform_device *pdev, pm_message_t state)
+{
+	int host_wake;
+
+	pr_debug("%s\n", __func__);
+
+	if (!bt_enabled)
+		return 0;
+
+	disable_irq(bt_lpm.int_host_wake);
+	host_wake = gpio_get_value(bt_lpm.gpio_host_wake);
+	if (host_wake) {
+		enable_irq(bt_lpm.int_host_wake);
+		pr_err("%s suspend error, gpio %d set\n", __func__,
+							bt_lpm.gpio_host_wake);
+		return -EBUSY;
+	}
+
+	return 0;
+}
+
+int bcm43xx_bluetooth_resume(struct platform_device *pdev)
+{
+	pr_debug("%s\n", __func__);
+
+	if (bt_enabled)
+		enable_irq(bt_lpm.int_host_wake);
+	return 0;
+}
+#endif
+
+#ifdef CONFIG_ACPI
+static struct acpi_device_id bcm_id_table[] = {
+	/* ACPI IDs here */
+	{ "BCM2E1A", 0 },
+	{ "BCM2E3A", 0 },
+	{ }
+};
+
+MODULE_DEVICE_TABLE(acpi, bcm_id_table);
+#endif
+
+static struct platform_driver bcm43xx_bluetooth_platform_driver = {
+	.probe = bcm43xx_bluetooth_probe,
+	.remove = bcm43xx_bluetooth_remove,
+#ifdef LPM_ON
+	.suspend = bcm43xx_bluetooth_suspend,
+	.resume = bcm43xx_bluetooth_resume,
+#endif
+	.driver = {
+		   .name = "bcm_bt_lpm",
+		   .owner = THIS_MODULE,
+#ifdef CONFIG_ACPI
+		.acpi_match_table = ACPI_PTR(bcm_id_table),
+#endif
+		   },
+};
+
+static int __init bcm43xx_bluetooth_init(void)
+{
+	bt_enabled = false;
+	return platform_driver_register(&bcm43xx_bluetooth_platform_driver);
+}
+
+static void __exit bcm43xx_bluetooth_exit(void)
+{
+	platform_driver_unregister(&bcm43xx_bluetooth_platform_driver);
+}
+
+
+module_init(bcm43xx_bluetooth_init);
+module_exit(bcm43xx_bluetooth_exit);
+
+MODULE_ALIAS("platform:bcm43xx");
+MODULE_DESCRIPTION("bcm43xx_bluetooth");
+MODULE_AUTHOR("Jaikumar Ganesh <jaikumar@google.com>");
+MODULE_LICENSE("GPL");
+
diff --git a/drivers/misc/pti.c b/drivers/misc/pti.c
index eda38cb..2c8d513 100644
--- a/drivers/misc/pti.c
+++ b/drivers/misc/pti.c
@@ -21,6 +21,8 @@
  * compact JTAG, standard.
  */
 
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
 #include <linux/init.h>
 #include <linux/sched.h>
 #include <linux/interrupt.h>
@@ -36,6 +38,12 @@
 #include <linux/slab.h>
 #include <linux/uaccess.h>
 
+#include <asm/intel_scu_ipc.h>
+
+#ifdef CONFIG_INTEL_PTI_STM
+#include "stm.h"
+#endif
+
 #define DRIVERNAME		"pti"
 #define PCINAME			"pciPTI"
 #define TTYNAME			"ttyPTI"
@@ -55,6 +63,55 @@
 #define APERTURE_14		0x3800000 /* offset to first OS write addr */
 #define APERTURE_LEN		0x400000  /* address length */
 
+#define SMIP_PTI_OFFSET	0x30C  /* offset to PTI config in MIP header */
+#define SMIP_PTI_EN	(1<<7) /* PTI enable bit in PTI configuration */
+
+#define PTI_PNW_PCI_ID			0x082B
+#define PTI_CLV_PCI_ID			0x0900
+#define PTI_TNG_PCI_ID			0x119F
+
+#define INTEL_PTI_PCI_DEVICE(dev, info) {	\
+	.vendor = PCI_VENDOR_ID_INTEL,		\
+	.device = dev,				\
+	.subvendor = PCI_ANY_ID,		\
+	.subdevice = PCI_ANY_ID,		\
+	.driver_data = (unsigned long) info }
+
+struct pti_device_info {
+	u8 pci_bar;
+	u8 scu_secure_mode:1;
+	u8 has_d8_d16_support:1;
+};
+
+static const struct pti_device_info intel_pti_pnw_info = {
+	.pci_bar = 1,
+	.scu_secure_mode = 0,
+	.has_d8_d16_support = 0,
+};
+
+static const struct pti_device_info intel_pti_clv_info = {
+	.pci_bar = 1,
+	.scu_secure_mode = 1,
+	.has_d8_d16_support = 0,
+};
+
+static const struct pti_device_info intel_pti_tng_info = {
+	.pci_bar = 2,
+	.scu_secure_mode = 0,
+	.has_d8_d16_support = 1,
+};
+
+static DEFINE_PCI_DEVICE_TABLE(pci_ids) = {
+	INTEL_PTI_PCI_DEVICE(PTI_PNW_PCI_ID, &intel_pti_pnw_info),
+	INTEL_PTI_PCI_DEVICE(PTI_CLV_PCI_ID, &intel_pti_clv_info),
+	INTEL_PTI_PCI_DEVICE(PTI_TNG_PCI_ID, &intel_pti_tng_info),
+	{0}
+};
+
+#define GET_PCI_BAR(pti_dev) (pti_dev->pti_dev_info->pci_bar)
+#define HAS_SCU_SECURE_MODE(pti_dev) (pti_dev->pti_dev_info->scu_secure_mode)
+#define HAS_D8_D16_SUPPORT(pti_dev) (pti_dev->pti_dev_info->has_d8_d16_support)
+
 struct pti_tty {
 	struct pti_masterchannel *mc;
 };
@@ -67,8 +124,16 @@ struct pti_dev {
 	u8 ia_app[MAX_APP_IDS];
 	u8 ia_os[MAX_OS_IDS];
 	u8 ia_modem[MAX_MODEM_IDS];
+	struct pti_device_info *pti_dev_info;
+#ifdef CONFIG_INTEL_PTI_STM
+	struct stm_dev stm;
+#endif
 };
 
+static unsigned int stm_enabled;
+module_param(stm_enabled, uint, 0600);
+MODULE_PARM_DESC(stm_enabled, "set to 1 to enable stm");
+
 /*
  * This protects access to ia_app, ia_os, and ia_modem,
  * which keeps track of channels allocated in
@@ -76,11 +141,6 @@ struct pti_dev {
  */
 static DEFINE_MUTEX(alloclock);
 
-static const struct pci_device_id pci_ids[] = {
-		{PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x82B)},
-		{0}
-};
-
 static struct tty_driver *pti_tty_driver;
 static struct pti_dev *drv_data;
 
@@ -801,7 +861,6 @@ static int pti_pci_probe(struct pci_dev *pdev,
 {
 	unsigned int a;
 	int retval = -EINVAL;
-	int pci_bar = 1;
 
 	dev_dbg(&pdev->dev, "%s %s(%d): PTI PCI ID %04x:%04x\n", __FILE__,
 			__func__, __LINE__, pdev->vendor, pdev->device);
@@ -831,9 +890,13 @@ static int pti_pci_probe(struct pci_dev *pdev,
 			__func__, __LINE__);
 		goto err_disable_pci;
 	}
-	drv_data->pti_addr = pci_resource_start(pdev, pci_bar);
 
-	retval = pci_request_region(pdev, pci_bar, dev_name(&pdev->dev));
+	drv_data->pti_dev_info = (struct pti_device_info *)ent->driver_data;
+
+	drv_data->pti_addr = pci_resource_start(pdev, GET_PCI_BAR(drv_data));
+
+	retval = pci_request_region(pdev, GET_PCI_BAR(drv_data),
+				    dev_name(&pdev->dev));
 	if (retval != 0) {
 		dev_err(&pdev->dev,
 			"%s(%d): pci_request_region() returned error %d\n",
@@ -849,6 +912,14 @@ static int pti_pci_probe(struct pci_dev *pdev,
 		goto err_rel_reg;
 	}
 
+#ifdef CONFIG_INTEL_PTI_STM
+	/* Initialize STM resources */
+	if ((stm_enabled) && (stm_dev_init(pdev, &drv_data->stm) != 0)) {
+		retval = -ENOMEM;
+		goto err_rel_reg;
+	}
+#endif
+
 	pci_set_drvdata(pdev, drv_data);
 
 	for (a = 0; a < PTITTY_MINOR_NUM; a++) {
@@ -863,7 +934,7 @@ static int pti_pci_probe(struct pci_dev *pdev,
 
 	return 0;
 err_rel_reg:
-	pci_release_region(pdev, pci_bar);
+	pci_release_region(pdev, GET_PCI_BAR(drv_data));
 err_free_dd:
 	kfree(drv_data);
 err_disable_pci:
@@ -891,9 +962,13 @@ static void pti_pci_remove(struct pci_dev *pdev)
 		tty_port_destroy(&drv_data->port[a]);
 	}
 
+#ifdef CONFIG_INTEL_PTI_STM
+	if (stm_enabled)
+		stm_dev_clean(pdev, &drv_data->stm);
+#endif
 	iounmap(drv_data->pti_ioaddr);
+	pci_release_region(pdev, GET_PCI_BAR(drv_data));
 	kfree(drv_data);
-	pci_release_region(pdev, 1);
 	pci_disable_device(pdev);
 
 	misc_deregister(&pti_char_driver);
diff --git a/drivers/misc/stm.c b/drivers/misc/stm.c
new file mode 100644
index 0000000..492d079
--- /dev/null
+++ b/drivers/misc/stm.c
@@ -0,0 +1,470 @@
+/*
+ *  stm.c - MIPI STM Debug Unit driver
+ *
+ *  Copyright (C) Intel 2013
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * The STM (Sytem Trace Macro) Unit driver configure trace output
+ * to the Intel Tangier PTI port and DWC3 USB xHCI controller
+ * out of the mobile device for analysis with a debugging tool
+ * (Lauterbach, Fido). This is part of a solution for the MIPI P1149.7,
+ * compact JTAG, standard and USB Debug-Class
+ *
+ * This header file will allow other parts of the OS to use the
+ * interface to write out it's contents for debugging a mobile system.
+ */
+
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
+
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/mutex.h>
+#include <linux/sdm.h>
+
+#include "stm.h"
+#include <asm/intel_soc_debug.h>
+#include "../usb/dwc3/core.h"
+
+/* STM Registers */
+#define STM_CTRL		0x0000
+#define STM_USB3DBGGTHR		0x0008
+#define STM_MASMSK		0x0010
+#define STM_CHMSK		0x0080
+#define STM_AGTBAR0		0x00C0
+#define STM_AGTBAR1		0x0140
+#define STM_AGTBAR2		0x01C0
+#define STM_AGTBAR3		0x0240
+#define STM_AGTBAR4		0x02C0
+#define STM_AGTBAR5		0x0340
+#define STM_AGTBAR6		0x03C0
+#define STM_AGTBAR7		0x0440
+#define STM_AGTBAR8		0x04C0
+#define STM_AGTBAR9		0x0540
+#define STM_AGTBAR10		0x05C0
+#define STM_AGTBAR11		0x0640
+
+/*
+ * STM registers
+ */
+#define STM_REG_BASE		0x0        /* registers base offset */
+#define STM_REG_LEN		0x20       /* address length */
+/*
+ * TRB buffers
+ */
+#define STM_TRB_BASE		0x400      /* TRB base offset */
+#define STM_TRB_LEN		0x100	   /* address length */
+#define STM_TRB_NUM		16         /* number of TRBs */
+
+/*
+ * This protects R/W to stm registers
+ */
+static DEFINE_MUTEX(stmlock);
+
+static struct stm_dev *_dev_stm;
+
+static inline u32 stm_readl(void __iomem *base, u32 offset)
+{
+	return readl(base + offset);
+}
+
+static inline void stm_writel(void __iomem *base, u32 offset, u32 value)
+{
+	writel(value, base + offset);
+}
+
+/**
+ * stm_kernel_set_out()-
+ * Kernel API function used to
+ * set STM output configuration to PTI or USB.
+ *
+ * @bus_type:
+ *	0 = PTI 4-bits legacy end user
+ *	1 = PTI 4-bits NiDnT
+ *	2 = PTI 16-bits
+ *	3 = PTI 12-bits
+ *	4 = PTI 8-bits
+ *	15 = USB Debug-Class (DvC.Trace)
+ *
+ */
+int stm_kernel_set_out(int bus_type)
+{
+
+	struct stm_dev *drv_stm = _dev_stm;
+
+	/*
+	 * since this function is exported, this is treated like an
+	 * API function, thus, all parameters should
+	 * be checked for validity.
+	 */
+	if (drv_stm == NULL)
+		return 0;
+
+	mutex_lock(&stmlock);
+
+	drv_stm->stm_ctrl_hwreg.reg_word =
+		stm_readl(drv_stm->stm_ioaddr, (u32)STM_CTRL);
+
+	switch (bus_type) {
+	case STM_PTI_4BIT_LEGACY:
+	case STM_PTI_4BIT_NIDNT:
+	case STM_PTI_16BIT:
+	case STM_PTI_12BIT:
+	case STM_PTI_8BIT:
+		drv_stm->stm_ctrl_hwreg.pti_out_en = true;
+		drv_stm->stm_ctrl_hwreg.usb_debug_en = false;
+		drv_stm->stm_ctrl_hwreg.pti_out_mode_sel = bus_type;
+		stm_writel(drv_stm->stm_ioaddr, (u32)STM_CTRL,
+			   drv_stm->stm_ctrl_hwreg.reg_word);
+		break;
+	case STM_USB:
+		drv_stm->stm_ctrl_hwreg.pti_out_en = false;
+		drv_stm->stm_ctrl_hwreg.usb_debug_en = true;
+		stm_writel(drv_stm->stm_ioaddr, (u32)STM_CTRL,
+			   drv_stm->stm_ctrl_hwreg.reg_word);
+		break;
+	default:
+		/* N/A */
+		break;
+	}
+	mutex_unlock(&stmlock);
+
+	return 1;
+}
+EXPORT_SYMBOL_GPL(stm_kernel_set_out);
+
+/**
+ * stm_kernel_get_out()-
+ * Kernel API function used to get
+ * STM output cofiguration PTI or USB.
+ *
+ */
+int stm_kernel_get_out(void)
+{
+	struct stm_dev *drv_stm = _dev_stm;
+	int ret = -EOPNOTSUPP;
+
+	if (drv_stm == NULL)
+		return -EOPNOTSUPP;
+
+	mutex_lock(&stmlock);
+
+	drv_stm->stm_ctrl_hwreg.reg_word =
+		stm_readl(drv_stm->stm_ioaddr, (u32)STM_CTRL);
+
+	if (!drv_stm->stm_ctrl_hwreg.usb_debug_en) {
+		if (drv_stm->stm_ctrl_hwreg.pti_out_en)
+			ret = (int)drv_stm->stm_ctrl_hwreg.pti_out_mode_sel;
+	} else {
+		ret = (int)STM_USB;
+	}
+	mutex_unlock(&stmlock);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(stm_kernel_get_out);
+
+/**
+ * stm_set_out() - 'out' parameter set function from 'STM' module
+ *
+ * called when writing to 'out' parameter from 'STM' module in sysfs
+ */
+static int stm_set_out(const char *val, struct kernel_param *kp)
+{
+	int bus_type_value;
+	int ret = -EINVAL;
+
+	if (sscanf(val, "%2d", &bus_type_value) != 1)
+		return ret;
+
+	return stm_kernel_set_out(bus_type_value);
+}
+
+/**
+ * stm_get_out() - 'out' parameter get function from 'STM' module
+ *
+ * called when reading 'out' parameter from 'STM' module in sysfs
+ */
+static int stm_get_out(char *buffer, struct kernel_param *kp)
+{
+	int i;
+
+	i = stm_kernel_get_out();
+	if (i == -EOPNOTSUPP) {
+		buffer[0] = '\0';
+		return 0;
+	}
+
+	return sprintf(buffer, "%2d", i);
+}
+
+/**
+ * stm_init() - initialize stmsub3dbgthr register
+ *
+ * @return - 0 on Success
+ */
+static int stm_init(void)
+{
+	struct stm_dev *stm = _dev_stm;
+	struct stm_usb3_ctrl *usb3dbg;
+
+	if (!stm)
+		return -ENODEV;
+
+	usb3dbg = &stm->stm_usb3_hwreg;
+	usb3dbg->reg_word = stm_readl(stm->stm_ioaddr, (u32)STM_USB3DBGGTHR);
+
+	usb3dbg->reg_word = 0xFF;
+
+	stm_writel(stm->stm_ioaddr, (u32)STM_USB3DBGGTHR, usb3dbg->reg_word);
+
+	return 0;
+}
+
+/**
+ * stm_alloc_static_trb_pool() - set stm trb pool dma_addr and return
+ * trb_pool
+ *
+ * @dma_addr - trb pool dma physical address to set
+ * @return - trb pool address ioremaped pointer
+ */
+static void *stm_alloc_static_trb_pool(dma_addr_t *dma_addr)
+{
+	struct stm_dev *stm = _dev_stm;
+	if (!stm)
+		return NULL;
+
+	*dma_addr = stm->stm_trb_base;
+	return stm->trb_ioaddr;
+}
+
+static void ebc_io_free_static_trb_pool(void)
+{
+	/* Nothing to do, HW TRB */
+}
+
+static int stm_xfer_start(void)
+{
+	struct stm_dev *stm = _dev_stm;
+	struct stm_ctrl *stm_ctrl;
+
+	if (!stm)
+		return -ENODEV;
+
+	stm_ctrl = &stm->stm_ctrl_hwreg;
+	stm_ctrl->reg_word = stm_readl(stm->stm_ioaddr, (u32)STM_CTRL);
+
+	stm_ctrl->usb_debug_en = true;
+	stm_ctrl->pti_out_en = false;
+
+	stm_writel(stm->stm_ioaddr, (u32)STM_CTRL, stm_ctrl->reg_word);
+	pr_info("%s\n switch STM output to DvC.Trace ", __func__);
+
+	return 0;
+}
+
+static int stm_xfer_stop(void)
+{
+	struct stm_dev *stm = _dev_stm;
+	struct stm_ctrl *stm_ctrl;
+
+	if (!stm)
+		return -ENODEV;
+
+	stm_ctrl = &stm->stm_ctrl_hwreg;
+	stm_ctrl->reg_word = stm_readl(stm->stm_ioaddr, (u32)STM_CTRL);
+
+	stm_ctrl->usb_debug_en = false;
+	stm_ctrl->pti_out_en = true;
+
+	stm_writel(stm->stm_ioaddr, (u32)STM_CTRL, stm_ctrl->reg_word);
+	pr_info("%s\n switch STM to 4bits MIPI PTI (default)", __func__);
+
+	return 0;
+}
+
+static struct ebc_io stm_ebc_io_ops = {
+	.name = "stmbuf4kB",
+	.epname = "ep1in",
+	.epnum = 3,
+	.is_ondemand = 1,
+	.static_trb_pool_size = 4,
+	.init = stm_init,
+	.alloc_static_trb_pool = stm_alloc_static_trb_pool,
+	.free_static_trb_pool = ebc_io_free_static_trb_pool,
+	.xfer_start = stm_xfer_start,
+	.xfer_stop = stm_xfer_stop,
+};
+
+#define EXI_IN_TRB_POOL_OFFSET (4*16)
+static void *exi_inbound_alloc_static_trb_pool(dma_addr_t *dma_addr)
+{
+	struct stm_dev *stm = _dev_stm;
+	if (!stm)
+		return NULL;
+
+	*dma_addr = stm->stm_trb_base + EXI_IN_TRB_POOL_OFFSET;
+	return stm->trb_ioaddr + EXI_IN_TRB_POOL_OFFSET;
+}
+
+static struct ebc_io exi_in_ebc_io_ops = {
+	.name = "exi-inbound",
+	.epname = "ep8in",
+	.epnum = 17,
+	.is_ondemand = 0,
+	.static_trb_pool_size = 4,
+	.alloc_static_trb_pool = exi_inbound_alloc_static_trb_pool,
+	.free_static_trb_pool = ebc_io_free_static_trb_pool,
+};
+
+#define EXI_OUT_TRB_POOL_OFFSET (8*16)
+static void *exi_outbound_alloc_static_trb_pool(dma_addr_t *dma_addr)
+{
+	struct stm_dev *stm = _dev_stm;
+	if (!stm)
+		return NULL;
+
+	*dma_addr = stm->stm_trb_base + EXI_OUT_TRB_POOL_OFFSET;
+	return stm->trb_ioaddr + EXI_OUT_TRB_POOL_OFFSET;
+}
+
+static struct ebc_io exi_out_ebc_io_ops = {
+	.name = "exi-outbound",
+	.epname = "ep8out",
+	.epnum = 16,
+	.is_ondemand = 0,
+	.static_trb_pool_size = 2,
+	.alloc_static_trb_pool = exi_outbound_alloc_static_trb_pool,
+	.free_static_trb_pool = ebc_io_free_static_trb_pool,
+};
+
+int stm_is_enabled()
+{
+	return (_dev_stm != NULL);
+}
+EXPORT_SYMBOL_GPL(stm_is_enabled);
+
+/**
+ * stm_dev_init()- Used to setup STM resources on the pci bus.
+ *
+ * @pdev- pci_dev struct values for pti device.
+ * @stm- stm_dev struct managing stm resources
+ *
+ * Returns:
+ *	0 for success
+ *	otherwise, error
+ */
+int stm_dev_init(struct pci_dev *pdev,
+		 struct stm_dev *stm)
+{
+	int retval = 0;
+	int pci_bar = 0;
+
+	if (!cpu_has_debug_feature(DEBUG_FEATURE_PTI))
+		return -ENODEV;
+
+	dev_dbg(&pdev->dev, "%s %s(%d): STM PCI ID %04x:%04x\n", __FILE__,
+		__func__, __LINE__, pdev->vendor, pdev->device);
+
+	stm->stm_addr = pci_resource_start(pdev, pci_bar);
+
+	retval = pci_request_region(pdev, pci_bar, dev_name(&pdev->dev));
+	if (retval != 0) {
+		dev_err(&pdev->dev,
+			"%s(%d): pci_request_region() returned error %d\n",
+			__func__, __LINE__, retval);
+		return retval;
+	}
+	pr_info("stm add %x\n", stm->stm_addr);
+
+	stm->stm_reg_base = stm->stm_addr+STM_REG_BASE;
+	stm->stm_ioaddr = ioremap_nocache((u32)stm->stm_reg_base,
+					  STM_REG_LEN);
+	if (!stm->stm_ioaddr) {
+		retval = -ENOMEM;
+		goto out_release_region;
+	}
+
+	stm->stm_trb_base = stm->stm_addr+STM_TRB_BASE;
+	stm->trb_ioaddr = ioremap_nocache((u32)stm->stm_trb_base,
+					  STM_TRB_LEN);
+	if (!stm->trb_ioaddr) {
+		retval = -ENOMEM;
+		goto out_iounmap_stm_ioaddr;
+	}
+
+	stm->stm_ctrl_hwreg.reg_word = stm_readl(stm->stm_ioaddr,
+						 (u32)STM_CTRL);
+	stm->stm_usb3_hwreg.reg_word = stm_readl(stm->stm_ioaddr,
+						 (u32)STM_USB3DBGGTHR);
+
+	_dev_stm = stm;
+
+	dwc3_register_io_ebc(&stm_ebc_io_ops);
+	dwc3_register_io_ebc(&exi_in_ebc_io_ops);
+	dwc3_register_io_ebc(&exi_out_ebc_io_ops);
+
+	pr_info("successfully registered ebc io ops\n");
+
+	return retval;
+
+out_iounmap_stm_ioaddr:
+	pci_iounmap(pdev, stm->stm_ioaddr);
+
+out_release_region:
+	pci_release_region(pdev, pci_bar);
+
+	_dev_stm = NULL;
+	return retval;
+
+}
+EXPORT_SYMBOL_GPL(stm_dev_init);
+
+/**
+ * stm_dev_clean()- Driver exit method to free STM resources from
+ *		   PCI bus.
+ * @pdev: variable containing pci info of STM.
+ * @dev_stm: stm_dev resources to clean.
+ */
+void stm_dev_clean(struct pci_dev *pdev,
+		   struct stm_dev *dev_stm)
+{
+	int pci_bar = 0;
+
+	/* If STM driver was not initialized properly,
+	 * there is nothing to do.
+	 */
+	if (_dev_stm == NULL)
+		return;
+
+	list_del(&stm_ebc_io_ops.list);
+	list_del(&exi_in_ebc_io_ops.list);
+	list_del(&exi_out_ebc_io_ops.list);
+
+	if (dev_stm != NULL) {
+		pci_iounmap(pdev, dev_stm->stm_ioaddr);
+		pci_iounmap(pdev, dev_stm->trb_ioaddr);
+	}
+
+	pci_release_region(pdev, pci_bar);
+
+	_dev_stm = NULL;
+}
+EXPORT_SYMBOL_GPL(stm_dev_clean);
+
+module_param_call(stm_out, stm_set_out, stm_get_out, NULL, 0644);
+MODULE_PARM_DESC(stm_out, "configure System Trace Macro output");
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Florent Pirou");
+MODULE_DESCRIPTION("STM Driver");
diff --git a/drivers/misc/stm.h b/drivers/misc/stm.h
new file mode 100644
index 0000000..1fb2d2e
--- /dev/null
+++ b/drivers/misc/stm.h
@@ -0,0 +1,114 @@
+/*
+ * stm.h
+ *
+ *  Copyright (C) Intel 2011
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * The STM (Sytem Trace Macro) Unit driver configure trace output
+ * to the Intel Tangier PTI port and DWC3 USB xHCI controller
+ * out of the mobile device for analysis with a debugging tool
+ * (Lauterbach, Fido). This is part of a solution for the MIPI P1149.7,
+ * compact JTAG, standard and USB Debug-Class
+ *
+ * This header file will allow other parts of the OS to use the
+ * interface to write out it's contents for debugging a mobile system.
+ */
+
+#ifndef _STM_H
+#define _STM_H
+
+#include <linux/pci.h>
+
+/* STM_CTRL register bitmap */
+/**
+ * struct stm_ctrl - STM control block
+ * @usb_debug_en : STM needs to redirece the trace packet to the USB3
+ * @pti_io_idle_threshold : threshold for disabling the IO clock.
+ * @pkt_transfer_size : asserts the *buff_avail signal after it has
+ * 1 or 2 KB of data in buffer
+ * @dis_dcu7_use : disables the useage of DCU7 instead of PTI_Disable
+ * @en_sw_ms : enables software master usage
+ * @mst_id_en : enables the PTI unit to suppress sending the Master Command
+ * @d64_cmd_en : PTI unit to use the D64 commands
+ * @pti_out_mode_sel
+ *	0 = PTI 4-bits legacy end user
+ *	1 = PTI 4-bits NiDnT
+ *	2 = PTI 16-bits
+ *	3 = PTI 12-bits
+ *	4 = PTI 8-bits
+ * @pti_out_en : PTI output enable muxselects that propagate
+ * to the FLIS to be enabled
+ * @lossy_mode_enable : Output Agent will continue to accept writes,
+ * even if the queuese are full. The data will be dropped and the
+ * dropped packet indicator will be incremented
+ * @time_stamp_enable : Enable time stamping the final packet in trace record.
+ */
+struct stm_ctrl {
+	union {
+		struct {
+			u32             time_stamp_enable:1;
+			u32             lossy_mode_enable:1;
+			u32             pti_out_en:1;
+			u32             reserved:1;
+			u32             pti_out_mode_sel:4;
+			u32             d64_cmd_en:1;
+			u32             mst_id_en:1;
+			u32             en_sw_ms:1;
+			u32             dis_dcu7_use:1;
+			u32             pkt_transfer_size:1;
+			u32             pti_io_idle_threshold:5;
+			u32             usb_debug_en:1;
+			u32             reserved31_19:13;
+		};
+		u32 reg_word;
+	};
+} __packed;
+
+/**
+ * struct stm_usb3_ctrl - STM buffer USB3 hardware EBC
+ * @region_closure_threshold : This is the threshold for closing
+ * the 1KB region in the debug trace buffer. STM will wait for the
+ * configured time as specified in this field and then closes the region.
+ * The unit of this field is in 64 us. Eg when this field value is set
+ * to 0xffff, then it indicates 2 ms
+ * @empty_packets_threshold : When STM does not have data to send,
+ * it can send empty packets to keep the USB3 alive. This is useful
+ * in case of ISOC traffic, because in this mode the wake up latency
+ * is high. STM will send the configured number of empty packets as
+ * specified in this field.
+ */
+struct stm_usb3_ctrl {
+	union {
+		struct {
+			u32             region_closure_threshold:15;
+			u32             empty_packets_threshold:6;
+			u32             reserved31_21:11;
+		};
+		u32 reg_word;
+	};
+} __packed;
+
+struct stm_dev {
+	unsigned long stm_addr;
+	unsigned long stm_reg_base;
+	unsigned long stm_trb_base;
+	void __iomem *stm_ioaddr;
+	void __iomem *trb_ioaddr;
+	struct stm_ctrl stm_ctrl_hwreg;
+	struct stm_usb3_ctrl stm_usb3_hwreg;
+};
+
+int stm_dev_init(struct pci_dev *pdev, struct stm_dev *dev_stm);
+void stm_dev_clean(struct pci_dev *pdev, struct stm_dev *dev_stm);
+
+#endif /* _STM_H */
diff --git a/drivers/pci/Makefile b/drivers/pci/Makefile
index 17d2b07..2085671 100644
--- a/drivers/pci/Makefile
+++ b/drivers/pci/Makefile
@@ -34,6 +34,7 @@ obj-$(CONFIG_PCI_IOV) += iov.o
 # Some architectures use the generic PCI setup functions
 #
 obj-$(CONFIG_X86) += setup-bus.o
+obj-$(CONFIG_ATOM_SOC_POWER) += pci-atom_soc.o
 obj-$(CONFIG_ALPHA) += setup-bus.o setup-irq.o
 obj-$(CONFIG_ARM) += setup-bus.o setup-irq.o
 obj-$(CONFIG_UNICORE32) += setup-bus.o setup-irq.o
diff --git a/drivers/pci/pci-atom_soc.c b/drivers/pci/pci-atom_soc.c
new file mode 100644
index 0000000..edc3e23
--- /dev/null
+++ b/drivers/pci/pci-atom_soc.c
@@ -0,0 +1,78 @@
+/*
+ * pci-atom_soc.c - register Intel MID PCI plaform ops
+ *
+ * Copyright (c) 2013, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ */
+
+#include <linux/init.h>
+#include <linux/intel_mid_pm.h>
+#include <linux/kernel.h>
+
+#include "pci.h"
+
+static bool mid_pci_power_manageable(struct pci_dev *dev)
+{
+	return true;
+}
+
+static pci_power_t mid_pci_choose_state(struct pci_dev *pdev)
+{
+	return PCI_D3hot;
+}
+
+static int mid_pci_sleep_wake(struct pci_dev *dev, bool enable)
+{
+	return 0;
+}
+
+static int mid_pci_run_wake(struct pci_dev *dev, bool enable)
+{
+	return 0;
+}
+
+static struct pci_platform_pm_ops mid_pci_platform_pm = {
+	.is_manageable = mid_pci_power_manageable,
+	.choose_state = mid_pci_choose_state,
+	.sleep_wake = mid_pci_sleep_wake,
+	.run_wake = mid_pci_run_wake,
+	.set_state = pmu_pci_set_power_state,
+	.choose_state = pmu_pci_choose_state,
+};
+
+/**
+ * mid_pci_init - It registers callback function for all the PCI devices
+ * for platform specific device power on/shutdown acticities.
+ */
+static int __init mid_pci_init(void)
+{
+	if (boot_cpu_data.x86 != 6)
+		return 0;
+
+	/*
+	 * n.b. this model check does not uniquely identify the platform,
+	 * and additional checks are necessary inside the pmu driver
+	 */
+	switch (boot_cpu_data.x86_model) {
+	case INTEL_ATOM_MFLD:
+	case INTEL_ATOM_CLV:
+	case INTEL_ATOM_MRFLD:
+		pci_set_platform_pm(&mid_pci_platform_pm);
+		break;
+	}
+
+	return 0;
+}
+arch_initcall(mid_pci_init);
diff --git a/drivers/pci/pci.c b/drivers/pci/pci.c
index b2f7301..407a5e7 100644
--- a/drivers/pci/pci.c
+++ b/drivers/pci/pci.c
@@ -589,8 +589,11 @@ static int pci_raw_set_power_state(struct pci_dev *dev, pci_power_t state)
 	if (state == PCI_D3hot || dev->current_state == PCI_D3hot)
 		pci_dev_d3_sleep(dev);
 	else if (state == PCI_D2 || dev->current_state == PCI_D2)
+#ifdef CONFIG_ATOM_SOC_POWER
+		; /* On Intel mid platforms pci delays are handled by SCU */
+#else
 		udelay(PCI_PM_D2_DELAY);
-
+#endif
 	pci_read_config_word(dev, dev->pm_cap + PCI_PM_CTRL, &pmcsr);
 	dev->current_state = (pmcsr & PCI_PM_CTRL_STATE_MASK);
 	if (dev->current_state != state && printk_ratelimit())
diff --git a/drivers/pci/quirks.c b/drivers/pci/quirks.c
index abc0167..bf7e4d6 100644
--- a/drivers/pci/quirks.c
+++ b/drivers/pci/quirks.c
@@ -3120,7 +3120,11 @@ static int __init pci_apply_final_quirks(void)
 
 	pci_apply_fixup_final_quirks = true;
 	for_each_pci_dev(dev) {
-		pci_fixup_device(pci_fixup_final, dev);
+		if (dev->device==0x119d)
+			printk("Ignore USB EHCI Tanhier (HSIC) since we do not have the driver in the kernel\n");
+		else
+			pci_fixup_device(pci_fixup_final, dev);
+
 		/*
 		 * If arch hasn't set it explicitly yet, use the CLS
 		 * value shared by all PCI devices.  If there's a
diff --git a/drivers/platform/x86/Kconfig b/drivers/platform/x86/Kconfig
index 0c60a1f..106b800 100644
--- a/drivers/platform/x86/Kconfig
+++ b/drivers/platform/x86/Kconfig
@@ -853,6 +853,22 @@ config INTEL_SCU_FLIS
 	  We could read write the flis address and configure the
 	  pin pull up/down using these interfaces.
 
+config INTEL_PSH_IPC
+	bool "Intel PSH IPC Support"
+	depends on X86_INTEL_MID
+	---help---
+	  PSH(Platform Services Hub) is a low frequence IA core on Tangier Platform,
+	  whose power consumption is quite low. PSH runs RTOS software inside itself,
+	  which independently controls and collects sensor data, pre-processes the data,
+	  and communicates with Atom. Thus ATOM side could be put into low power mode
+	  with more time, while all the sensor data are collected without any lost.
+
+	  PSH IPC is used as a  bridge for OS sensor service to control and access PSH
+	  sensors communications between kernel and PSH. This is not needed for PC-type
+	  machines.
+
+	  Say Y here to get Intel PSH IPC support.
+
 config INTEL_BAYTRAIL_MBI
 	tristate
 	depends on PCI
diff --git a/drivers/platform/x86/Makefile b/drivers/platform/x86/Makefile
index 2acdf96..15c8c2c 100644
--- a/drivers/platform/x86/Makefile
+++ b/drivers/platform/x86/Makefile
@@ -37,7 +37,7 @@ obj-$(CONFIG_TOPSTAR_LAPTOP)	+= topstar-laptop.o
 obj-$(CONFIG_ACPI_TOSHIBA)	+= toshiba_acpi.o
 
 obj-$(CONFIG_TOSHIBA_BT_RFKILL)	+= toshiba_bluetooth.o
-obj-$(CONFIG_INTEL_SCU_IPC)	+= intel_scu_ipc.o intel_scu_pmic.o intel_scu_mip.o
+obj-$(CONFIG_INTEL_SCU_IPC)	+= intel_scu_ipc.o intel_scu_pmic.o intel_scu_mip.o intel_scu_fw_update.o
 obj-$(CONFIG_INTEL_SCU_IPC_UTIL) += intel_scu_ipcutil.o
 obj-$(CONFIG_INTEL_MFLD_THERMAL) += intel_mid_thermal.o
 obj-$(CONFIG_INTEL_SCU_FLIS)   += intel_scu_flis.o
@@ -57,3 +57,4 @@ obj-$(CONFIG_INTEL_SMARTCONNECT)	+= intel-smartconnect.o
 
 obj-$(CONFIG_PVPANIC)           += pvpanic.o
 obj-$(CONFIG_INTEL_BAYTRAIL_MBI)	+= intel_baytrail.o
+obj-$(CONFIG_INTEL_PSH_IPC)	+= intel_psh_ipc.o
diff --git a/drivers/platform/x86/intel_mid_powerbtn.c b/drivers/platform/x86/intel_mid_powerbtn.c
index 8d67752..ad69fe6 100644
--- a/drivers/platform/x86/intel_mid_powerbtn.c
+++ b/drivers/platform/x86/intel_mid_powerbtn.c
@@ -21,53 +21,97 @@
 #include <linux/init.h>
 #include <linux/interrupt.h>
 #include <linux/slab.h>
+#include <linux/device.h>
 #include <linux/platform_device.h>
 #include <linux/input.h>
-#include <linux/mfd/intel_msic.h>
+#include <linux/io.h>
+#include <linux/rpmsg.h>
+#include <linux/async.h>
+#include <asm/intel_mid_powerbtn.h>
+#include <asm/intel_scu_pmic.h>
+#include <asm/intel_mid_rpmsg.h>
 
 #define DRIVER_NAME "msic_power_btn"
 
-#define MSIC_PB_LEVEL	(1 << 3) /* 1 - release, 0 - press */
+struct mid_pb_priv {
+	struct input_dev *input;
+	int irq;
+	void __iomem *pb_stat;
+	u16 pb_level;
+	u16 irq_lvl1_mask;
+	bool irq_ack;
+};
 
-/*
- * MSIC document ti_datasheet defines the 1st bit reg 0x21 is used to mask
- * power button interrupt
- */
-#define MSIC_PWRBTNM    (1 << 0)
+static inline int pb_clear_bits(u16 addr, u8 mask)
+{
+	return intel_scu_ipc_update_register(addr, 0, mask);
+}
 
-static irqreturn_t mfld_pb_isr(int irq, void *dev_id)
+static irqreturn_t mid_pb_isr(int irq, void *dev_id)
 {
-	struct input_dev *input = dev_id;
-	int ret;
+	struct mid_pb_priv *priv = dev_id;
 	u8 pbstat;
 
-	ret = intel_msic_reg_read(INTEL_MSIC_PBSTATUS, &pbstat);
-	dev_dbg(input->dev.parent, "PB_INT status= %d\n", pbstat);
+	pbstat = readb(priv->pb_stat);
+	dev_dbg(&priv->input->dev, "pbstat: 0x%x\n", pbstat);
 
-	if (ret < 0) {
-		dev_err(input->dev.parent, "Read error %d while reading"
-			       " MSIC_PB_STATUS\n", ret);
-	} else {
-		input_event(input, EV_KEY, KEY_POWER,
-			       !(pbstat & MSIC_PB_LEVEL));
-		input_sync(input);
-	}
+	input_event(priv->input, EV_KEY, KEY_POWER, !(pbstat & priv->pb_level));
+	input_sync(priv->input);
+
+	if (pbstat & priv->pb_level)
+		pr_info("[%s] power button released\n", priv->input->name);
+	else
+		pr_info("[%s] power button pressed\n", priv->input->name);
+
+	return IRQ_WAKE_THREAD;
+}
+
+static irqreturn_t mid_pb_threaded_isr(int irq, void *dev_id)
+{
+	struct mid_pb_priv *priv = dev_id;
+
+	if (priv->irq_ack)
+		pb_clear_bits(priv->irq_lvl1_mask, MSIC_PWRBTNM);
 
 	return IRQ_HANDLED;
 }
 
-static int mfld_pb_probe(struct platform_device *pdev)
+static int mid_pb_probe(struct platform_device *pdev)
 {
 	struct input_dev *input;
-	int irq = platform_get_irq(pdev, 0);
-	int error;
+	struct mid_pb_priv *priv;
+	int irq;
+	int ret;
+	struct intel_msic_power_btn_platform_data *pdata;
+
+	if (pdev == NULL)
+		return -ENODEV;
+
+	pdata = pdev->dev.platform_data;
+	if (pdata == NULL) {
+		dev_err(&pdev->dev, "No power button platform data\n");
+		return -EINVAL;
+	}
+
+	dev_info(&pdev->dev, "Probed mid powerbutton devivce\n");
 
+	irq = platform_get_irq(pdev, 0);
 	if (irq < 0)
 		return -EINVAL;
 
+	priv = kzalloc(sizeof(struct mid_pb_priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
 	input = input_allocate_device();
-	if (!input)
+	if (!input){
+		kfree(priv);
 		return -ENOMEM;
+	}
+
+	priv->input = input;
+	priv->irq = irq;
+	platform_set_drvdata(pdev, priv);
 
 	input->name = pdev->name;
 	input->phys = "power-button/input0";
@@ -76,70 +120,159 @@ static int mfld_pb_probe(struct platform_device *pdev)
 
 	input_set_capability(input, EV_KEY, KEY_POWER);
 
-	error = request_threaded_irq(irq, NULL, mfld_pb_isr, IRQF_NO_SUSPEND,
-			DRIVER_NAME, input);
-	if (error) {
-		dev_err(&pdev->dev, "Unable to request irq %d for mfld power"
-				"button\n", irq);
-		goto err_free_input;
+	priv->pb_stat = ioremap(pdata->pbstat, MSIC_PB_LEN);
+	if (!priv->pb_stat) {
+		ret = -ENOMEM;
+		goto fail;
 	}
 
-	error = input_register_device(input);
-	if (error) {
-		dev_err(&pdev->dev, "Unable to register input dev, error "
-				"%d\n", error);
-		goto err_free_irq;
+	ret = input_register_device(input);
+	if (ret) {
+		dev_err(&pdev->dev,
+			"unable to register input dev, error %d\n", ret);
+		goto out_iounmap;
 	}
 
-	platform_set_drvdata(pdev, input);
+	priv->pb_level = pdata->pb_level;
+	priv->irq_lvl1_mask = pdata->irq_lvl1_mask;
+
+	/* Unmask the PBIRQ and MPBIRQ on Tangier */
+	if (pdata->irq_ack) {
+		pdata->irq_ack(pdata);
+		priv->irq_ack = true;
+	}
 
-	/*
-	 * SCU firmware might send power button interrupts to IA core before
+	ret = request_threaded_irq(priv->irq, mid_pb_isr, mid_pb_threaded_isr,
+		IRQF_NO_SUSPEND, DRIVER_NAME, priv);
+
+	if (ret) {
+		dev_err(&pdev->dev,
+			"unable to request irq %d for power button\n", irq);
+		goto out_unregister_input;
+	}
+
+	/* SCU firmware might send power button interrupts to IA core before
 	 * kernel boots and doesn't get EOI from IA core. The first bit of
-	 * MSIC reg 0x21 is kept masked, and SCU firmware doesn't send new
+	 * MSIC lvl1 mask reg is kept masked, and SCU firmware doesn't send new
 	 * power interrupt to Android kernel. Unmask the bit when probing
 	 * power button in kernel.
-	 * There is a very narrow race between irq handler and power button
-	 * initialization. The race happens rarely. So we needn't worry
-	 * about it.
 	 */
-	error = intel_msic_reg_update(INTEL_MSIC_IRQLVL1MSK, 0, MSIC_PWRBTNM);
-	if (error) {
-		dev_err(&pdev->dev, "Unable to clear power button interrupt, "
-				"error: %d\n", error);
-		goto err_free_irq;
-	}
+	pb_clear_bits(priv->irq_lvl1_mask, MSIC_PWRBTNM);
 
 	return 0;
 
-err_free_irq:
-	free_irq(irq, input);
-err_free_input:
+out_unregister_input:
+	input_unregister_device(input);
+	input = NULL;
+out_iounmap:
+	iounmap(priv->pb_stat);
+fail:
+	platform_set_drvdata(pdev, NULL);
 	input_free_device(input);
-	return error;
+	kfree(priv);
+	return ret;
 }
 
-static int mfld_pb_remove(struct platform_device *pdev)
+static int mid_pb_remove(struct platform_device *pdev)
 {
-	struct input_dev *input = platform_get_drvdata(pdev);
-	int irq = platform_get_irq(pdev, 0);
+	struct mid_pb_priv *priv = platform_get_drvdata(pdev);
 
-	free_irq(irq, input);
-	input_unregister_device(input);
+	iounmap(priv->pb_stat);
+	free_irq(priv->irq, priv);
+ 	platform_set_drvdata(pdev, NULL);
+	input_unregister_device(priv->input);
+	kfree(priv);
 
 	return 0;
 }
 
-static struct platform_driver mfld_pb_driver = {
+static const struct platform_device_id mid_pb_table[] = {
+	{"mid_powerbtn", 1},
+};
+
+static struct platform_driver mid_pb_driver = {
 	.driver = {
 		.name = DRIVER_NAME,
 		.owner = THIS_MODULE,
 	},
-	.probe	= mfld_pb_probe,
-	.remove	= mfld_pb_remove,
+	.probe	= mid_pb_probe,
+	.remove	= mid_pb_remove,
+	.id_table = mid_pb_table,
 };
 
-module_platform_driver(mfld_pb_driver);
+static int __init mid_pb_module_init(void)
+{
+	return platform_driver_register(&mid_pb_driver);
+}
+
+static void  mid_pb_module_exit(void)
+{
+	platform_driver_unregister(&mid_pb_driver);
+}
+
+/* RPMSG related functionality */
+
+static int mid_pb_rpmsg_probe(struct rpmsg_channel *rpdev)
+{
+	int ret = 0;
+	if (rpdev == NULL) {
+		pr_err("rpmsg channel not created\n");
+		ret = -ENODEV;
+		goto out;
+	}
+
+	dev_info(&rpdev->dev, "Probed mid_pb rpmsg device\n");
+
+	ret = mid_pb_module_init();
+out:
+	return ret;
+}
+
+
+static void mid_pb_rpmsg_remove(struct rpmsg_channel *rpdev)
+{
+	mid_pb_module_exit();
+	dev_info(&rpdev->dev, "Removed mid_pb rpmsg device\n");
+}
+
+static void mid_pb_rpmsg_cb(struct rpmsg_channel *rpdev, void *data,
+					int len, void *priv, u32 src)
+{
+	dev_warn(&rpdev->dev, "unexpected, message\n");
+
+	print_hex_dump(KERN_DEBUG, __func__, DUMP_PREFIX_NONE, 16, 1,
+		       data, len,  true);
+}
+
+static struct rpmsg_device_id mid_pb_id_table[] = {
+	{ .name	= "rpmsg_mid_powerbtn" },
+	{ },
+};
+MODULE_DEVICE_TABLE(rpmsg, mid_pb_id_table);
+
+
+static struct rpmsg_driver mid_pb_rpmsg_driver = {
+	.drv.name	= DRIVER_NAME,
+	.drv.owner	= THIS_MODULE,
+	.probe		= mid_pb_rpmsg_probe,
+	.callback	= mid_pb_rpmsg_cb,
+	.remove		= mid_pb_rpmsg_remove,
+	.id_table	= mid_pb_id_table,
+};
+
+static int __init mid_pb_rpmsg_init(void)
+{
+	return register_rpmsg_driver(&mid_pb_rpmsg_driver);
+}
+
+static void __exit mid_pb_rpmsg_exit(void)
+{
+	return unregister_rpmsg_driver(&mid_pb_rpmsg_driver);
+}
+
+late_initcall(mid_pb_rpmsg_init);
+
+module_exit(mid_pb_rpmsg_exit);
 
 MODULE_AUTHOR("Hong Liu <hong.liu@intel.com>");
 MODULE_DESCRIPTION("Intel Medfield Power Button Driver");
diff --git a/drivers/platform/x86/intel_psh_ipc.c b/drivers/platform/x86/intel_psh_ipc.c
new file mode 100644
index 0000000..12e8bf1
--- /dev/null
+++ b/drivers/platform/x86/intel_psh_ipc.c
@@ -0,0 +1,637 @@
+/*
+ * intel_psh_ipc.c: Driver for the Intel PSH IPC mechanism
+ *
+ * (C) Copyright 2012 Intel Corporation
+ * Author: Yang Bin (bin.yang@intel.com)
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/semaphore.h>
+#include <linux/workqueue.h>
+#include <linux/pm_runtime.h>
+#include <asm/intel_psh_ipc.h>
+#include <asm/intel-mid.h>
+#include <linux/fs.h>
+#include <linux/intel_mid_pm.h>
+
+#define PSH_ERR(fmt, arg...)	dev_err(&ipc_ctrl.pdev->dev, fmt, ##arg)
+#define PSH_DBG(fmt, arg...)	dev_dbg(&ipc_ctrl.pdev->dev, fmt, ##arg)
+
+#define STATUS_PSH2IA(x)	(1 << ((x) + 6))
+#define FLAG_BIND		(1 << 0)
+
+#define PIMR_ADDR(x)		(&ipc_ctrl.psh_regs->psh_regs_b_step.pimr##x)
+
+#define PSH_REG_ADDR(x)		(&ipc_ctrl.psh_regs->psh_regs_b_step.x)
+
+#define PSH_CH_HANDLE(x)	(ipc_ctrl.channel_handle[x])
+#define PSH_CH_DATA(x)		(ipc_ctrl.channel_data[x])
+#define PSH_CH_FLAG(x)		(ipc_ctrl.flags[x])
+
+/* PSH registers */
+union psh_registers {
+	/* reg mem map A */
+	struct {
+		u32		csr;	/* 00h */
+		u32		res1;	/* padding */
+		u32		pisr;	/* 08h */
+		u32		pimr0;	/* 0Ch */
+		u32		pimr1;	/* 10h */
+		u32		pimr2;	/* 14h */
+		u32		pimr3;	/* 18h */
+		u32		pmctl;	/* 1Ch */
+		u32		pmstat;	/* 20h */
+		u32		res2;	/* padding */
+		struct psh_msg	ia2psh[NUM_IA2PSH_IPC];/* 28h ~ 44h + 3 */
+		struct psh_msg	cry2psh;/* 48h ~ 4Ch + 3 */
+		struct psh_msg	scu2psh;/* 50h ~ 54h + 3 */
+		u32		res3[2];/* padding */
+		struct psh_msg	psh2ia[NUM_PSH2IA_IPC];/* 60h ~ 7Ch + 3 */
+		struct psh_msg	psh2cry;/* 80h ~ 84h + 3 */
+		struct psh_msg  psh2scu;/* 88h */
+		u32		msi_dir;/* 90h */
+		u32		res4[3];
+		u32		scratchpad[2];/* A0 */
+	} __packed psh_regs_a_step;
+	/* reg mem map B */
+	struct {
+		u32		pimr0;		/* 00h */
+		u32		csr;		/* 04h */
+		u32		pmctl;		/* 08h */
+		u32		pmstat;		/* 0Ch */
+		u32		psh_msi_direct;	/* 10h */
+		u32		res1[59];	/* 14h ~ FCh + 3, padding */
+		u32		pimr3;		/* 100h */
+		struct psh_msg	scu2psh;	/* 104h ~ 108h + 3 */
+		struct psh_msg	psh2scu;	/* 10Ch ~ 110h + 3 */
+		u32		res2[187];	/* 114h ~ 3FCh + 3, padding */
+		u32		pisr;		/* 400h */
+		u32		scratchpad[2];	/* 404h ~ 407h */
+		u32		res3[61];	/* 40Ch ~ 4FCh + 3, padding */
+		u32		pimr1;		/* 500h */
+		struct psh_msg	ia2psh[NUM_IA2PSH_IPC];	/* 504h ~ 520h + 3 */
+		struct psh_msg	psh2ia[NUM_PSH2IA_IPC];	/* 524h ~ 540h + 3 */
+		u32		res4[175];	/* 544h ~ 7FCh + 3, padding */
+		u32		pimr2;		/* 800h */
+		struct psh_msg	cry2psh;	/* 804h ~ 808h + 3 */
+		struct psh_msg	psh2cry;	/* 80Ch ~ 810h + 3 */
+	} __packed psh_regs_b_step;
+} __packed;
+
+static struct ipc_controller_t {
+	int			reg_map;
+	int			initialized;
+	struct pci_dev		*pdev;
+	spinlock_t		lock;
+	int			flags[NUM_ALL_CH];
+	union psh_registers	*psh_regs;
+	struct semaphore	ch_lock[NUM_ALL_CH];
+	struct mutex		psh_mutex;
+	psh_channel_handle_t	channel_handle[NUM_PSH2IA_IPC];
+	void			*channel_data[NUM_PSH2IA_IPC];
+} ipc_ctrl;
+
+
+/**
+ * intel_ia2psh_command - send IA to PSH command
+ * Send ia2psh command and return psh message and status
+ *
+ * @in: input psh message
+ * @out: output psh message
+ * @ch: psh channel
+ * @timeout: timeout for polling busy bit, in us
+ */
+int intel_ia2psh_command(struct psh_msg *in, struct psh_msg *out,
+			 int ch, int timeout)
+{
+	int ret = 0;
+	u32 status;
+
+	might_sleep();
+
+	if (!ipc_ctrl.initialized)
+		return -ENODEV;
+
+	if (ch < PSH_SEND_CH0 || ch > PSH_SEND_CH0 + NUM_IA2PSH_IPC - 1
+		|| in == NULL)
+		return -EINVAL;
+
+	if (!in || in->msg & CHANNEL_BUSY)
+		return -EINVAL;
+
+	pm_runtime_get_sync(&ipc_ctrl.pdev->dev);
+	down(&ipc_ctrl.ch_lock[ch]);
+
+	in->msg |= CHANNEL_BUSY;
+	/* Check if channel is ready for IA sending command */
+
+	if (readl(PSH_REG_ADDR(ia2psh[ch].msg)) & CHANNEL_BUSY) {
+		ret = -EBUSY;
+		goto end;
+	}
+
+	writel(in->param, PSH_REG_ADDR(ia2psh[ch].param));
+	writel(in->msg, PSH_REG_ADDR(ia2psh[ch].msg));
+
+	/* Input timeout is zero, do not check channel status */
+	if (timeout == 0)
+		goto end;
+
+	/* Input timeout is nonzero, check channel status */
+	while (((status = readl(PSH_REG_ADDR(ia2psh[ch].msg))) & CHANNEL_BUSY)
+		&& timeout) {
+		usleep_range(100, 101);
+		timeout -= 100;
+	}
+
+	if (timeout <= 0) {
+		ret = -ETIMEDOUT;
+		PSH_ERR("ia2psh channel %d is always busy!\n", ch);
+		goto end;
+	} else {
+		if (out == NULL)
+			goto end;
+
+		out->param = readl(PSH_REG_ADDR(ia2psh[ch].param));
+		out->msg = status;
+	}
+
+end:
+	up(&ipc_ctrl.ch_lock[ch]);
+	pm_runtime_put(&ipc_ctrl.pdev->dev);
+
+	return ret;
+}
+EXPORT_SYMBOL(intel_ia2psh_command);
+
+/**
+ * intel_psh_ipc_bind - bind a handler to a psh channel
+ *
+ * @ch: psh channel
+ * @handle: handle function called when IA received psh interrupt
+ * @data: data passed to handle
+ */
+int intel_psh_ipc_bind(int ch, psh_channel_handle_t handle, void *data)
+{
+	unsigned long flags;
+
+	if (!ipc_ctrl.initialized)
+		return -ENODEV;
+
+	if (!handle || ch < PSH_RECV_CH0
+			|| ch > PSH_RECV_CH0 + NUM_PSH2IA_IPC - 1)
+		return -EINVAL;
+
+	mutex_lock(&ipc_ctrl.psh_mutex);
+	down(&ipc_ctrl.ch_lock[ch]);
+	if (PSH_CH_HANDLE(ch - PSH_RECV_CH0) != NULL) {
+		up(&ipc_ctrl.ch_lock[ch]);
+		mutex_unlock(&ipc_ctrl.psh_mutex);
+		return -EBUSY;
+	} else {
+		PSH_CH_DATA(ch - PSH_RECV_CH0) = data;
+		PSH_CH_HANDLE(ch - PSH_RECV_CH0) = handle;
+	}
+	up(&ipc_ctrl.ch_lock[ch]);
+
+	pm_runtime_get_sync(&ipc_ctrl.pdev->dev);
+	spin_lock_irqsave(&ipc_ctrl.lock, flags);
+	PSH_CH_FLAG(ch) |= FLAG_BIND;
+	writel(readl(PIMR_ADDR(1)) | (1 << (ch - PSH_RECV_CH0)), PIMR_ADDR(1));
+	spin_unlock_irqrestore(&ipc_ctrl.lock, flags);
+	pm_runtime_put(&ipc_ctrl.pdev->dev);
+	mutex_unlock(&ipc_ctrl.psh_mutex);
+
+	return 0;
+}
+EXPORT_SYMBOL(intel_psh_ipc_bind);
+
+/**
+ * intel_psh_ipc_unbind - unbind a handler to a psh channel
+ *
+ * @ch: psh channel
+ */
+void intel_psh_ipc_unbind(int ch)
+{
+	unsigned long flags;
+
+	if (!ipc_ctrl.initialized)
+		return;
+
+	if (ch < PSH_RECV_CH0 || ch > PSH_RECV_CH0 + NUM_PSH2IA_IPC - 1)
+		return;
+
+	if (!(PSH_CH_FLAG(ch) & FLAG_BIND))
+		return;
+
+	mutex_lock(&ipc_ctrl.psh_mutex);
+	pm_runtime_get_sync(&ipc_ctrl.pdev->dev);
+	spin_lock_irqsave(&ipc_ctrl.lock, flags);
+	PSH_CH_FLAG(ch) &= ~FLAG_BIND;
+	writel(readl(PIMR_ADDR(1)) & (~(1 << (ch - PSH_RECV_CH0))),
+						PIMR_ADDR(1));
+	spin_unlock_irqrestore(&ipc_ctrl.lock, flags);
+	pm_runtime_put(&ipc_ctrl.pdev->dev);
+
+	down(&ipc_ctrl.ch_lock[ch]);
+	PSH_CH_HANDLE(ch - PSH_RECV_CH0) = NULL;
+	up(&ipc_ctrl.ch_lock[ch]);
+	mutex_unlock(&ipc_ctrl.psh_mutex);
+}
+EXPORT_SYMBOL(intel_psh_ipc_unbind);
+
+void intel_psh_ipc_disable_irq(void)
+{
+	disable_irq(ipc_ctrl.pdev->irq);
+}
+EXPORT_SYMBOL(intel_psh_ipc_disable_irq);
+
+void intel_psh_ipc_enable_irq(void)
+{
+	enable_irq(ipc_ctrl.pdev->irq);
+}
+EXPORT_SYMBOL(intel_psh_ipc_enable_irq);
+
+static void psh_recv_handle(int i)
+{
+	int msg, param;
+
+	down(&ipc_ctrl.ch_lock[i + PSH_RECV_CH0]);
+
+	msg = readl(PSH_REG_ADDR(psh2ia[i].msg)) & (~CHANNEL_BUSY);
+	param = readl(PSH_REG_ADDR(psh2ia[i].param));
+
+	if (PSH_CH_HANDLE(i) == NULL) {
+		PSH_ERR("Ignore message from channel %d\n", i+PSH_RECV_CH0);
+		goto end;
+	}
+
+	/* write back to clear the busy bit */
+	writel(msg, PSH_REG_ADDR(psh2ia[i].msg));
+	PSH_CH_HANDLE(i)(msg, param, PSH_CH_DATA(i));
+end:
+	up(&ipc_ctrl.ch_lock[i+PSH_RECV_CH0]);
+}
+
+static irqreturn_t psh_ipc_irq(int irq, void *data)
+{
+	int i;
+	u32 status;
+
+	pm_runtime_get_sync(&ipc_ctrl.pdev->dev);
+	status = readl(PSH_REG_ADDR(pisr));
+
+	for (i = 0; i < NUM_PSH2IA_IPC; i++) {
+		if (status & STATUS_PSH2IA(i))
+			psh_recv_handle(i);
+	}
+
+	pm_runtime_put(&ipc_ctrl.pdev->dev);
+	return IRQ_HANDLED;
+}
+
+static void psh_regs_dump(void)
+{
+	int i;
+
+	pm_runtime_get_sync(&ipc_ctrl.pdev->dev);
+	PSH_ERR("\n<-------------start------------>\n");
+
+	PSH_ERR("csr:\t%#x\n", readl(PSH_REG_ADDR(csr)));
+	PSH_ERR("pisr:\t%#x\n", readl(PSH_REG_ADDR(pisr)));
+
+	PSH_ERR("pimr0:\t%#x\n", readl(PIMR_ADDR(0)));
+	PSH_ERR("pimr1:\t%#x\n", readl(PIMR_ADDR(1)));
+	PSH_ERR("pimr2:\t%#x\n", readl(PIMR_ADDR(2)));
+	PSH_ERR("pimr3:\t%#x\n", readl(PIMR_ADDR(3)));
+
+	PSH_ERR("pmctl:\t%#x\n", readl(PSH_REG_ADDR(pmctl)));
+	PSH_ERR("pmstat:\t%#x\n", readl(PSH_REG_ADDR(pmstat)));
+	PSH_ERR("scratchpad0:\t%#x\n", readl(PSH_REG_ADDR(scratchpad[0])));
+	PSH_ERR("scratchpad1:\t%#x\n", readl(PSH_REG_ADDR(scratchpad[1])));
+
+	for (i = 0; i < NUM_IA2PSH_IPC; i++) {
+		PSH_ERR("ia2psh[%d].msg:\t%#x\n", i,
+				readl(PSH_REG_ADDR(ia2psh[i].msg)));
+		PSH_ERR("ia2psh[%d].param:\t%#x\n", i,
+				readl(PSH_REG_ADDR(ia2psh[i].param)));
+	}
+
+	PSH_ERR("cry2psh.msg:\t%#x\n", readl(PSH_REG_ADDR(cry2psh.msg)));
+	PSH_ERR("cry2psh.param:\t%#x\n", readl(PSH_REG_ADDR(cry2psh.param)));
+	PSH_ERR("scu2psh.msg:\t%#x\n", readl(PSH_REG_ADDR(scu2psh.msg)));
+	PSH_ERR("scu2psh.param:\t%#x\n", readl(PSH_REG_ADDR(scu2psh.param)));
+
+	for (i = 0; i < NUM_PSH2IA_IPC; i++) {
+		PSH_ERR("psh2ia[%d].msg:\t%#x\n", i,
+				readl(PSH_REG_ADDR(psh2ia[i].msg)));
+		PSH_ERR("psh2ia[%d].param:\t%#x\n", i,
+				readl(PSH_REG_ADDR(psh2ia[i].param)));
+	}
+
+	PSH_ERR("psh2cry.msg:\t%#x\n", readl(PSH_REG_ADDR(psh2cry.msg)));
+	PSH_ERR("psh2cry.param:\t%#x\n", readl(PSH_REG_ADDR(psh2cry.param)));
+
+	PSH_ERR("\n<-------------end------------>\n");
+	pm_runtime_put(&ipc_ctrl.pdev->dev);
+}
+
+static struct psh_msg psh_dbg_msg;
+static int psh_ch;
+
+static ssize_t psh_msg_show(struct device *dev,
+			    struct device_attribute *attr,
+			    char *buf)
+{
+	return snprintf(buf, PAGE_SIZE,
+			"\nLast ia2psh command with msg: %#x\nparam: %#x\n",
+			psh_dbg_msg.msg, psh_dbg_msg.param);
+}
+
+static ssize_t psh_msg_store(struct device *dev,
+			     struct device_attribute *attr,
+			     const char *buf, size_t size)
+{
+	int ret;
+	u32 msg, param;
+
+	memset(&psh_dbg_msg, 0, sizeof(psh_dbg_msg));
+
+	ret = sscanf(buf, "%x %x", &msg, &param);
+	if (ret != 2) {
+		PSH_ERR("Input two arguments as psh msg and param\n");
+		return -EINVAL;
+	}
+
+	psh_dbg_msg.msg = msg;
+	psh_dbg_msg.param = param;
+
+	return size;
+}
+
+static ssize_t psh_ch_show(struct device *dev,
+			   struct device_attribute *attr,
+			   char *buf)
+{
+	return snprintf(buf, PAGE_SIZE,
+			"\nLast psh channel: %d\n", psh_ch);
+}
+
+static ssize_t psh_ch_store(struct device *dev,
+			    struct device_attribute *attr,
+			    const char *buf, size_t size)
+{
+	int ret;
+
+	ret = sscanf(buf, "%d", &psh_ch);
+	if (ret != 1) {
+		PSH_ERR("Input one argument as psh channel\n");
+		return -EINVAL;
+	}
+
+	return size;
+}
+
+static ssize_t psh_send_cmd_store(struct device *dev,
+			    struct device_attribute *attr,
+			    const char *buf, size_t size)
+{
+	int psh_dbg_err;
+	struct psh_msg out_msg;
+
+	memset(&out_msg, 0, sizeof(out_msg));
+
+	psh_dbg_err = intel_ia2psh_command(&psh_dbg_msg, &out_msg,
+					psh_ch, 3000000);
+	if (psh_dbg_err) {
+		PSH_ERR("Send ia2psh command failed, err %d\n", psh_dbg_err);
+		psh_regs_dump();
+		return psh_dbg_err;
+	}
+
+	return size;
+}
+
+static DEVICE_ATTR(psh_msg, S_IRUGO | S_IWUSR, psh_msg_show, psh_msg_store);
+static DEVICE_ATTR(psh_ch, S_IRUGO | S_IWUSR, psh_ch_show, psh_ch_store);
+static DEVICE_ATTR(ia2psh_cmd, S_IWUSR, NULL, psh_send_cmd_store);
+
+static struct attribute *psh_attrs[] = {
+	&dev_attr_psh_msg.attr,
+	&dev_attr_psh_ch.attr,
+	&dev_attr_ia2psh_cmd.attr,
+	NULL,
+};
+
+static struct attribute_group psh_attr_group = {
+	.name = "psh_debug",
+	.attrs = psh_attrs,
+};
+
+static int intel_psh_debug_sysfs_create(struct pci_dev *pdev)
+{
+	return sysfs_create_group(&pdev->dev.kobj, &psh_attr_group);
+}
+
+static void pmic_sysfs_remove(struct pci_dev *pdev)
+{
+	sysfs_remove_group(&pdev->dev.kobj, &psh_attr_group);
+}
+
+#ifdef CONFIG_PM
+static int psh_ipc_suspend_noirq(struct device *dev)
+{
+	int i;
+	int ret = 0;
+
+	for (i = 0; i < NUM_ALL_CH; i++) {
+		if (down_trylock(&ipc_ctrl.ch_lock[i])) {
+			ret = -EBUSY;
+			break;
+		}
+	}
+
+	if (ret) {
+		for (; i > 0; i--)
+			up(&ipc_ctrl.ch_lock[i - 1]);
+	}
+
+	return ret;
+}
+
+static int psh_ipc_resume_noirq(struct device *dev)
+{
+	int i;
+
+	for (i = 0; i < NUM_ALL_CH; i++)
+		up(&ipc_ctrl.ch_lock[i]);
+
+	return 0;
+}
+
+#else
+
+#define psh_ipc_suspend_noirq	NULL
+#define psh_ipc_resume_noirq	NULL
+
+#endif
+
+#ifdef CONFIG_PM_RUNTIME
+static int psh_ipc_runtime_suspend(struct device *dev)
+{
+	dev_dbg(dev, "runtime suspend called\n");
+	return 0;
+}
+
+static int psh_ipc_runtime_resume(struct device *dev)
+{
+	dev_dbg(dev, "runtime resume called\n");
+	return 0;
+}
+
+#else
+
+#define psh_ipc_runtime_suspend	NULL
+#define psh_ipc_runtime_resume	NULL
+
+#endif
+
+static int psh_ipc_probe(struct pci_dev *pdev, const struct pci_device_id *id)
+{
+	int i, ret;
+	unsigned long start, len;
+
+	ipc_ctrl.pdev = pci_dev_get(pdev);
+	ret = pci_enable_device(pdev);
+	if (ret)
+		goto err1;
+
+	start = pci_resource_start(pdev, 0);
+	len = pci_resource_len(pdev, 0);
+	if (!start || !len) {
+		ret = -ENODEV;
+		goto err1;
+	}
+
+	ret = pci_request_regions(pdev, "intel_psh_ipc");
+	if (ret)
+		goto err1;
+
+	switch (intel_mid_identify_cpu()) {
+	case INTEL_MID_CPU_CHIP_TANGIER:
+		ipc_ctrl.reg_map = 1;
+		break;
+	case INTEL_MID_CPU_CHIP_ANNIEDALE:
+		ipc_ctrl.reg_map = 1;
+		break;
+	default:
+		dev_err(&pdev->dev, "error register map\n");
+		ret = -EINVAL;
+		goto err2;
+		break;
+	}
+
+	ipc_ctrl.psh_regs = (union psh_registers *)ioremap_nocache(start, len);
+	if (!ipc_ctrl.psh_regs) {
+		ret = -ENOMEM;
+		goto err2;
+	}
+
+	ret = request_threaded_irq(pdev->irq, NULL, psh_ipc_irq, IRQF_ONESHOT,
+			"intel_psh_ipc", NULL);
+	if (ret) {
+		dev_err(&pdev->dev, "Unable to register irq %d\n", pdev->irq);
+		goto err3;
+	}
+
+	irq_set_irq_wake(pdev->irq, 1);
+
+	spin_lock_init(&ipc_ctrl.lock);
+	mutex_init(&ipc_ctrl.psh_mutex);
+
+	for (i = 0; i < NUM_ALL_CH; i++)
+		sema_init(&ipc_ctrl.ch_lock[i], 1);
+
+	intel_psh_devices_create();
+
+	intel_psh_debug_sysfs_create(pdev);
+
+	ipc_ctrl.initialized = 1;
+
+	pm_runtime_put_noidle(&pdev->dev);
+	pm_runtime_allow(&pdev->dev);
+
+	return 0;
+
+err3:
+	iounmap(ipc_ctrl.psh_regs);
+err2:
+	pci_release_regions(pdev);
+err1:
+	pci_dev_put(pdev);
+
+	return ret;
+}
+
+static void psh_ipc_remove(struct pci_dev *pdev)
+{
+	pm_runtime_forbid(&pdev->dev);
+	pm_runtime_get_noresume(&pdev->dev);
+	free_irq(pdev->irq, NULL);
+	iounmap(ipc_ctrl.psh_regs);
+	pci_release_regions(pdev);
+	pci_dev_put(pdev);
+	intel_psh_devices_destroy();
+	pmic_sysfs_remove(pdev);
+	ipc_ctrl.initialized = 0;
+}
+
+static const struct dev_pm_ops psh_ipc_drv_pm_ops = {
+	.suspend_noirq		= psh_ipc_suspend_noirq,
+	.resume_noirq		= psh_ipc_resume_noirq,
+	.runtime_suspend	= psh_ipc_runtime_suspend,
+	.runtime_resume		= psh_ipc_runtime_resume,
+};
+
+static DEFINE_PCI_DEVICE_TABLE(pci_ids) = {
+	{PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x11a3)},
+	{ 0,}
+};
+MODULE_DEVICE_TABLE(pci, pci_ids);
+
+static struct pci_driver psh_ipc_driver = {
+	.name = "intel_psh_ipc",
+	.driver = {
+		.pm = &psh_ipc_drv_pm_ops,
+	},
+	.id_table = pci_ids,
+	.probe = psh_ipc_probe,
+	.remove = psh_ipc_remove,
+};
+
+static int __init psh_ipc_init(void)
+{
+	return  pci_register_driver(&psh_ipc_driver);
+}
+
+static void __exit psh_ipc_exit(void)
+{
+	pci_unregister_driver(&psh_ipc_driver);
+}
+
+MODULE_AUTHOR("bin.yang@intel.com");
+MODULE_DESCRIPTION("Intel PSH IPC driver");
+MODULE_LICENSE("GPL v2");
+
+fs_initcall(psh_ipc_init);
+module_exit(psh_ipc_exit);
diff --git a/drivers/platform/x86/intel_scu_fw_update.c b/drivers/platform/x86/intel_scu_fw_update.c
new file mode 100644
index 0000000..59f8c7f
--- /dev/null
+++ b/drivers/platform/x86/intel_scu_fw_update.c
@@ -0,0 +1,1087 @@
+/*
+ * fw_update.c - Intel SCU Firmware Update Driver
+ *
+ * Copyright (C) 2012 Intel Corporation
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/io.h>
+#include <linux/delay.h>
+#include <linux/fs.h>
+#include <linux/vmalloc.h>
+#include <linux/rpmsg.h>
+#include <linux/intel_mid_pm.h>
+#include <asm/intel_scu_ipc.h>
+#include <asm/intel_mid_rpmsg.h>
+#include <asm/intel-mid.h>
+
+/* Medfield & Cloverview firmware update.
+ * The flow and communication between IA and SCU has changed for
+ * Medfield firmware update. For more details, please refer to
+ * Firmware Arch Spec.
+ * Below macros and structs apply for medfield firmware update
+ */
+
+#define IPC_CMD_FW_UPDATE_GO	0x02
+
+#define MAX_FW_CHUNK		(128*1024)
+#define IFWX_CHUNK_SIZE		(96*1024)
+
+#define SRAM_ADDR		0xFFFC0000
+#define MAILBOX_ADDR		0xFFFE0000
+
+#define SCU_FLAG_OFFSET		8
+#define IA_FLAG_OFFSET		12
+
+#define MIP_HEADER_OFFSET	0
+#define SUCP_OFFSET		0x1D8000
+#define VEDFW_OFFSET		0x1A6000
+
+#define DNX_HDR_LEN		24
+#define FUPH_HDR_LEN		36
+
+#define DNX_IMAGE	"DXBL"
+#define FUPH_HDR_SIZE	"RUPHS"
+#define FUPH		"RUPH"
+#define MIP		"DMIP"
+#define IFWI		"IFW"
+#define LOWER_128K	"LOFW"
+#define UPPER_128K	"HIFW"
+#define PSFW1		"PSFW1"
+#define PSFW2		"PSFW2"
+#define SSFW		"SSFW"
+#define SUCP		"SuCP"
+#define VEDFW		"VEDFW"
+#define UPDATE_DONE	"HLT$"
+#define UPDATE_ABORT	"HLT0"
+#define UPDATE_ERROR	"ER"
+
+#define MAX_LEN_IFW	4
+#define MAX_LEN_PSFW	7
+#define MAX_LEN_SSFW	6
+#define MAX_LEN_SUCP	6
+#define MAX_LEN_VEDFW	7
+
+#define FUPH_MIP_OFFSET		0x04
+#define FUPH_IFWI_OFFSET	0x08
+#define FUPH_PSFW1_OFFSET	0x0c
+#define FUPH_PSFW2_OFFSET	0x10
+#define FUPH_SSFW_OFFSET	0x14
+#define FUPH_SUCP_OFFSET	0x18
+#define FUPH_VEDFW_OFFSET	0x1c
+
+#define DNX_MAX_SIZE	(128*1024)
+#define IFWI_MAX_SIZE	(3*1024*1024)
+#define FOTA_MEM_SIZE	(4*1024*1024)
+
+#define DNX_SIZE_OFFSET	0
+#define GP_FLAG_OFFSET	4
+#define XOR_CHK_OFFSET	20
+
+#define GPF_BIT32	1
+#define FUPH_STR	"UPH$"
+#define FUPH_MAX_LEN	36
+#define SKIP_BYTES	8
+
+static struct kobject *scu_fw_update_kobj;
+static struct rpmsg_instance *fw_update_instance;
+
+/* Modified IA-SCU mailbox for medfield firmware update. */
+struct ia_scu_mailbox {
+	char mail[8];
+	u32 scu_flag;
+	u32 ia_flag;
+};
+
+/* Structure to parse input from firmware-update application. */
+struct fw_ud {
+	u8 *fw_file_data;
+	u32 fsize;
+	u8 *dnx_hdr;
+	u8 *dnx_file_data;
+	u32 dnx_size;
+	u32 fuph_hdr_len;
+};
+
+struct mfld_fw_update {
+	void __iomem *sram;
+	void __iomem *mailbox;
+	u32 wscu;
+	u32 wia;
+	char mb_status[8];
+};
+
+/* Holds size parameters read from fuph header */
+struct fuph_hdr_attrs {
+	u32 mip_size;
+	u32 ifwi_size;
+	u32 psfw1_size;
+	u32 psfw2_size;
+	u32 ssfw_size;
+	u32 sucp_size;
+	u32 vedfw_size;
+};
+
+enum mailbox_status {
+	MB_DONE,
+	MB_CONTINUE,
+	MB_ERROR
+};
+
+/* Misc. firmware components that are part of integrated firmware */
+struct misc_fw {
+	const char *fw_type;
+	u8 str_len;
+};
+
+/* lock used to prevent multiple calls to fw update sysfs interface */
+static DEFINE_MUTEX(fwud_lock);
+
+static char err_buf[50];
+static u8 *pending_data;
+
+struct fw_update_info {
+	struct device *dev;
+	struct fw_ud *fwud_pending;
+};
+
+static struct fw_update_info fui;
+
+static struct misc_fw misc_fw_table[] = {
+	{ .fw_type = IFWI, .str_len  = MAX_LEN_IFW },
+	{ .fw_type = PSFW1, .str_len  = MAX_LEN_PSFW },
+	{ .fw_type = SSFW, .str_len  = MAX_LEN_SSFW },
+	{ .fw_type = PSFW2, .str_len  = MAX_LEN_PSFW },
+	{ .fw_type = SUCP, .str_len  = MAX_LEN_SUCP },
+	{ .fw_type = VEDFW, .str_len  = MAX_LEN_VEDFW }
+};
+
+static int alloc_fota_mem_early;
+
+int __init alloc_mem_fota_early_flag(char *p)
+{
+	alloc_fota_mem_early = 1;
+	return 0;
+}
+early_param("alloc_fota_mem_early", alloc_mem_fota_early_flag);
+
+/*
+ * IA will wait in busy-state, and poll mailbox, to check
+ * if SCU is done processing.
+ * If it has to wait for more than a second, it will exit with
+ * error code.
+ */
+static int busy_wait(struct mfld_fw_update *mfld_fw_upd)
+{
+	u32 count = 0;
+	u32 flag;
+
+	flag = mfld_fw_upd->wscu;
+
+	while (ioread32(mfld_fw_upd->mailbox + SCU_FLAG_OFFSET) != flag
+		&& count < 500) {
+		/* There are synchronization issues between IA and SCU */
+		mb();
+		/* FIXME: we must use mdelay currently */
+		mdelay(10);
+		count++;
+	}
+
+	if (ioread32(mfld_fw_upd->mailbox + SCU_FLAG_OFFSET) != flag) {
+		dev_err(fui.dev, "IA-waited and quitting\n");
+		return -ETIMEDOUT;
+	}
+
+	return 0;
+}
+
+/* This function will
+ * 1)copy firmware chunk from user-space to kernel-space.
+ * 2) Copy from kernel-space to shared SRAM.
+ * 3) Write to mailbox.
+ * 4) And wait for SCU to process that firmware chunk.
+ * Returns 0 on success, and < 0 for failure.
+ */
+static int process_fw_chunk(u8 *fws, u8 *userptr, u32 chunklen,
+					struct mfld_fw_update *mfld_fw_upd)
+{
+	memcpy(fws, userptr, chunklen);
+
+	/* IA copy to sram */
+	memcpy_toio(mfld_fw_upd->sram, fws, chunklen);
+
+	/* There are synchronization issues between IA and SCU */
+	mb();
+	mfld_fw_upd->wia = !(mfld_fw_upd->wia);
+	iowrite32(mfld_fw_upd->wia, mfld_fw_upd->mailbox + IA_FLAG_OFFSET);
+
+	mb();
+	dev_dbg(fui.dev, "wrote ia_flag=%d\n",
+		 ioread32(mfld_fw_upd->mailbox + IA_FLAG_OFFSET));
+
+	mfld_fw_upd->wscu = !mfld_fw_upd->wscu;
+	return busy_wait(mfld_fw_upd);
+}
+
+/*
+ * This function will check mailbox status flag, and return state of mailbox.
+ */
+static enum mailbox_status check_mb_status(struct mfld_fw_update *mfld_fw_upd)
+{
+
+	enum mailbox_status mb_state;
+
+	/* There are synchronization issues between IA and SCU */
+	mb();
+
+	memcpy_fromio(mfld_fw_upd->mb_status, mfld_fw_upd->mailbox, 8);
+
+	if (!strncmp(mfld_fw_upd->mb_status, UPDATE_ERROR,
+					sizeof(UPDATE_ERROR) - 1) ||
+		!strncmp(mfld_fw_upd->mb_status, UPDATE_ABORT,
+					sizeof(UPDATE_ABORT) - 1)) {
+		dev_dbg(fui.dev,
+			"mailbox error=%s\n", mfld_fw_upd->mb_status);
+		return MB_ERROR;
+	} else {
+		mb_state = (!strncmp(mfld_fw_upd->mb_status, UPDATE_DONE,
+			sizeof(UPDATE_DONE) - 1)) ? MB_DONE : MB_CONTINUE;
+		dev_dbg(fui.dev,
+			"mailbox pass=%s, mb_state=%d\n",
+			mfld_fw_upd->mb_status, mb_state);
+	}
+
+	return mb_state;
+}
+
+/* Helper function used to calculate length and offset.  */
+int helper_for_calc_offset_length(struct fw_ud *fw_ud_ptr, char *scu_req,
+			void **offset, u32 *len, struct fuph_hdr_attrs *fuph,
+			const char *fw_type)
+{
+	unsigned long chunk_no;
+	u32 chunk_rem;
+	u32 max_chunk_cnt;
+	u32 fw_size;
+	u32 fw_offset;
+	u32 max_fw_chunk_size = MAX_FW_CHUNK;
+
+	if (!strncmp(fw_type, IFWI, strlen(IFWI))) {
+
+		if (kstrtoul(scu_req + strlen(IFWI), 10, &chunk_no) < 0)
+			return -EINVAL;
+
+		/* On CTP, IFWx starts from IFW1, not IFW0, thus adjust the
+		 * chunk_no to make '*offset' point to the correct address.
+		 * Besides, the size of each IFWx chunk is 96k, not 128k
+		 */
+		chunk_no = chunk_no - 1;
+		fw_size = fuph->ifwi_size;
+		fw_offset = fuph->mip_size;
+		max_fw_chunk_size = IFWX_CHUNK_SIZE;
+	} else if (!strncmp(fw_type, PSFW1, strlen(PSFW1))) {
+
+		if (kstrtoul(scu_req + strlen(PSFW1), 10, &chunk_no) < 0)
+			return -EINVAL;
+
+		fw_size = fuph->psfw1_size;
+		fw_offset = fuph->mip_size + fuph->ifwi_size;
+	} else if (!strncmp(fw_type, PSFW2, strlen(PSFW2))) {
+
+		if (kstrtoul(scu_req + strlen(PSFW2), 10, &chunk_no) < 0)
+			return -EINVAL;
+
+		fw_size = fuph->psfw2_size;
+		fw_offset = fuph->mip_size + fuph->ifwi_size +
+				fuph->psfw1_size + fuph->ssfw_size;
+	} else if (!strncmp(fw_type, SSFW, strlen(SSFW))) {
+
+		if (kstrtoul(scu_req + strlen(SSFW), 10, &chunk_no) < 0)
+			return -EINVAL;
+
+		fw_size = fuph->ssfw_size;
+		fw_offset = fuph->mip_size + fuph->ifwi_size +
+				fuph->psfw1_size;
+	} else if (!strncmp(fw_type, SUCP, strlen(SUCP))) {
+
+		if (kstrtoul(scu_req + strlen(SUCP), 10, &chunk_no) < 0)
+			return -EINVAL;
+
+		fw_size = fuph->sucp_size;
+		fw_offset = SUCP_OFFSET;
+	} else if (!strncmp(fw_type, VEDFW, strlen(VEDFW))) {
+
+		if (kstrtoul(scu_req + strlen(VEDFW), 10, &chunk_no) < 0)
+			return -EINVAL;
+
+		fw_size = fuph->vedfw_size;
+		fw_offset = VEDFW_OFFSET;
+	} else
+		return -EINVAL;
+
+	chunk_rem = fw_size % max_fw_chunk_size;
+	max_chunk_cnt = (fw_size/max_fw_chunk_size) + (chunk_rem ? 1 : 0);
+
+	dev_dbg(fui.dev,
+		"str=%s,chunk_no=%lx, chunk_rem=%d,max_chunk_cnt=%d\n",
+		fw_type, chunk_no, chunk_rem, max_chunk_cnt);
+
+	if ((chunk_no + 1) > max_chunk_cnt)
+		return -EINVAL;
+
+	/* Note::Logic below will make sure, that we get right length if input
+	 is 128K or multiple. */
+	*len = (chunk_no == (max_chunk_cnt - 1)) ?
+		(chunk_rem ? chunk_rem : max_fw_chunk_size) : max_fw_chunk_size;
+
+	*offset = fw_ud_ptr->fw_file_data + fw_offset +
+		chunk_no * max_fw_chunk_size;
+
+	return 0;
+}
+
+/*
+ * This api calculates offset and length depending on type of firmware chunk
+ * requested by SCU. Note: Intent is to follow the architecture such that,
+ * SCU controls the flow, and IA simply hands out, what is requested by SCU.
+ * IA will simply follow SCU's commands, unless SCU requests for something
+ * IA cannot give. TODO:That will be a special error case, need to figure out
+ * how to handle that.
+ */
+int calc_offset_and_length(struct fw_ud *fw_ud_ptr, char *scu_req,
+			void **offset, u32 *len, struct fuph_hdr_attrs *fuph)
+{
+	u8 cnt;
+
+	if (!strncmp(DNX_IMAGE, scu_req, strlen(scu_req))) {
+		*offset = fw_ud_ptr->dnx_file_data;
+		*len = fw_ud_ptr->dnx_size;
+		return 0;
+	} else if (!strncmp(FUPH, scu_req, strlen(scu_req))) {
+		*offset = fw_ud_ptr->fw_file_data + fw_ud_ptr->fsize
+				- fw_ud_ptr->fuph_hdr_len;
+		*len = fw_ud_ptr->fuph_hdr_len;
+		return 0;
+	} else if (!strncmp(MIP, scu_req, strlen(scu_req))) {
+		*offset = fw_ud_ptr->fw_file_data + MIP_HEADER_OFFSET;
+		*len = fuph->mip_size;
+		return 0;
+	} else if (!strncmp(LOWER_128K, scu_req, strlen(scu_req))) {
+		*offset = fw_ud_ptr->fw_file_data + fuph->mip_size;
+		*len = MAX_FW_CHUNK;
+		return 0;
+	} else if (!strncmp(UPPER_128K, scu_req, strlen(scu_req))) {
+		*offset = fw_ud_ptr->fw_file_data
+				+ fuph->mip_size + MAX_FW_CHUNK;
+		*len = MAX_FW_CHUNK;
+		return 0;
+	} else {
+		for (cnt = 0; cnt < ARRAY_SIZE(misc_fw_table); cnt++) {
+
+			if (!strncmp(misc_fw_table[cnt].fw_type, scu_req,
+					strlen(misc_fw_table[cnt].fw_type))) {
+
+				if (strlen(scu_req) ==
+						misc_fw_table[cnt].str_len) {
+
+					if (helper_for_calc_offset_length
+						(fw_ud_ptr, scu_req,
+						offset, len, fuph,
+						misc_fw_table[cnt].fw_type) < 0)
+						goto error_case;
+
+					dev_dbg(fui.dev,
+					"\nmisc fw type=%s, len=%d,offset=%d",
+					misc_fw_table[cnt].fw_type, *len,
+					(int)*offset);
+
+					return 0;
+
+				} else
+					goto error_case;
+			}
+		}
+
+	}
+
+	dev_dbg(fui.dev, "Unexpected mailbox request from scu\n");
+
+error_case:
+	/* TODO::Need to test this error case..and see how SCU reacts
+	* and how IA handles
+	* subsequent error response and whether exit is graceful...
+	*/
+
+	dev_dbg(fui.dev, "error case,respond back to SCU..\n");
+	dev_dbg(fui.dev, "scu_req=%s\n", scu_req);
+	*len = 0;
+	*offset = 0;
+
+	return -EINVAL;
+}
+
+/**
+ * intel_scu_ipc_medfw_upgrade - Medfield Firmware update utility
+ *
+ * The flow and communication between IA and SCU has changed for
+ * Medfield firmware update. So we have a different api below
+ * to support Medfield firmware update.
+ *
+ * On success returns 0, for failure , returns < 0.
+ */
+static int intel_scu_ipc_medfw_upgrade(void)
+{
+	struct fw_ud *fw_ud_param = fui.fwud_pending;
+	struct mfld_fw_update	mfld_fw_upd;
+	u8 *fw_file_data = NULL;
+	u8 *fws = NULL;
+	u8 *fuph_start = NULL;
+	int ret_val = 0;
+
+	struct fuph_hdr_attrs fuph;
+	u32 length = 0;
+	void *offset;
+	enum mailbox_status mb_state;
+
+	/* set all devices in d0i0 before IFWI upgrade */
+	if (unlikely(pmu_set_devices_in_d0i0())) {
+		pr_debug("pmu: failed to set all devices in d0i0...\n");
+		BUG();
+	}
+
+	rpmsg_global_lock();
+	mfld_fw_upd.wscu = 0;
+	mfld_fw_upd.wia = 0;
+	memset(mfld_fw_upd.mb_status, 0, sizeof(char) * 8);
+
+	fw_file_data = fw_ud_param->fw_file_data;
+	mfld_fw_upd.sram = ioremap_nocache(SRAM_ADDR, MAX_FW_CHUNK);
+	if (mfld_fw_upd.sram == NULL) {
+		dev_err(fui.dev, "unable to map sram\n");
+		ret_val = -ENOMEM;
+		goto out_unlock;
+	}
+
+	mfld_fw_upd.mailbox = ioremap_nocache(MAILBOX_ADDR,
+					sizeof(struct ia_scu_mailbox));
+
+	if (mfld_fw_upd.mailbox == NULL) {
+		dev_err(fui.dev, "unable to map the mailbox\n");
+		ret_val = -ENOMEM;
+		goto unmap_sram;
+	}
+
+	/*IA initializes both IAFlag and SCUFlag to zero */
+	iowrite32(0, mfld_fw_upd.mailbox + SCU_FLAG_OFFSET);
+	iowrite32(0, mfld_fw_upd.mailbox + IA_FLAG_OFFSET);
+	memset_io(mfld_fw_upd.mailbox, 0, 8);
+
+	fws = kmalloc(MAX_FW_CHUNK, GFP_KERNEL);
+	if (fws == NULL) {
+		ret_val = -ENOMEM;
+		goto unmap_mb;
+	}
+
+	/* fuph header start */
+	fuph_start = fw_ud_param->fw_file_data + (fw_ud_param->fsize - 1)
+					- (fw_ud_param->fuph_hdr_len - 1);
+
+	/* Convert sizes in DWORDS to number of bytes. */
+	fuph.mip_size = (*((u32 *)(fuph_start + FUPH_MIP_OFFSET)))*4;
+	fuph.ifwi_size = (*((u32 *)(fuph_start + FUPH_IFWI_OFFSET)))*4;
+	fuph.psfw1_size = (*((u32 *)(fuph_start + FUPH_PSFW1_OFFSET)))*4;
+	fuph.psfw2_size = (*((u32 *)(fuph_start + FUPH_PSFW2_OFFSET)))*4;
+	fuph.ssfw_size = (*((u32 *)(fuph_start + FUPH_SSFW_OFFSET)))*4;
+	fuph.sucp_size = (*((u32 *)(fuph_start + FUPH_SUCP_OFFSET)))*4;
+
+	if (fw_ud_param->fuph_hdr_len == FUPH_HDR_LEN) {
+		fuph.vedfw_size =
+				(*((u32 *)(fuph_start + FUPH_VEDFW_OFFSET)))*4;
+	} else
+		fuph.vedfw_size = 0;
+
+	dev_dbg(fui.dev,
+		"ln=%d, mi=%d, if=%d, ps1=%d, ps2=%d, sfw=%d, sucp=%d, vd=%d\n",
+		fw_ud_param->fuph_hdr_len, fuph.mip_size, fuph.ifwi_size,
+		fuph.psfw1_size, fuph.psfw2_size, fuph.ssfw_size,
+		fuph.sucp_size,	fuph.vedfw_size);
+
+	/* TODO_SK::There is just
+	 *  1 write required from IA side for DFU.
+	 *  So commenting this-out, until it gets confirmed */
+	/*ipc_command(IPC_CMD_FW_UPDATE_READY); */
+
+	/*1. DNX SIZE HEADER   */
+	memcpy(fws, fw_ud_param->dnx_hdr, DNX_HDR_LEN);
+
+	memcpy_toio(mfld_fw_upd.sram, fws, DNX_HDR_LEN);
+
+	/* There are synchronization issues between IA and SCU */
+	mb();
+
+	/* Write cmd to trigger an interrupt to SCU for firmware update*/
+	ret_val = rpmsg_send_simple_command(fw_update_instance,
+					    IPCMSG_FW_UPDATE,
+					    IPC_CMD_FW_UPDATE_GO);
+	if (ret_val) {
+		dev_err(fui.dev, "IPC_CMD_FW_UPDATE_GO failed\n");
+		goto term;
+	}
+
+	mfld_fw_upd.wscu = !mfld_fw_upd.wscu;
+
+	if (busy_wait(&mfld_fw_upd) < 0) {
+		ret_val = -1;
+		goto term;
+	}
+
+	/* TODO:Add a count for iteration, based on sizes of security firmware,
+	 * so that we determine finite number of iterations to loop thro.
+	 * That way at the very least, we can atleast control the number
+	 * of iterations, and prevent infinite looping if there are any bugs.
+	 * The only catch being for B0, SCU will request twice for each firmware
+	 * chunk, since its writing to 2 partitions.
+	 * TODO::Investigate if we need to increase timeout for busy_wait,
+	 * since SCU is now writing to 2 partitions.
+	 */
+
+	while ((mb_state = check_mb_status(&mfld_fw_upd)) != MB_DONE) {
+
+		if (mb_state == MB_ERROR) {
+			dev_dbg(fui.dev, "check_mb_status,error\n");
+			ret_val = -1;
+			goto term;
+		}
+
+		if (!strncmp(mfld_fw_upd.mb_status, FUPH_HDR_SIZE,
+				strlen(FUPH_HDR_SIZE))) {
+			iowrite32(fw_ud_param->fuph_hdr_len, mfld_fw_upd.sram);
+			/* There are synchronization issues between IA-SCU */
+			mb();
+			dev_dbg(fui.dev,
+				"copied fuph hdr size=%d\n",
+				ioread32(mfld_fw_upd.sram));
+			mfld_fw_upd.wia = !mfld_fw_upd.wia;
+			iowrite32(mfld_fw_upd.wia, mfld_fw_upd.mailbox +
+				IA_FLAG_OFFSET);
+			dev_dbg(fui.dev, "ia_flag=%d\n",
+				ioread32(mfld_fw_upd.mailbox + IA_FLAG_OFFSET));
+			mb();
+			mfld_fw_upd.wscu = !mfld_fw_upd.wscu;
+
+			if (busy_wait(&mfld_fw_upd) < 0) {
+				ret_val = -1;
+				goto term;
+			}
+
+			continue;
+		}
+
+		if (calc_offset_and_length(fw_ud_param, mfld_fw_upd.mb_status,
+					&offset, &length, &fuph) < 0) {
+			dev_err(fui.dev,
+			"calc_offset_and_length_error,error\n");
+			ret_val = -1;
+			goto term;
+		}
+
+		if ((process_fw_chunk(fws, offset, length,
+				      &mfld_fw_upd)) != 0) {
+			dev_err(fui.dev,
+			"Error processing fw chunk=%s\n",
+			mfld_fw_upd.mb_status);
+			ret_val = -1;
+			goto term;
+		} else
+			dev_dbg(fui.dev,
+				"PASS processing fw chunk=%s\n",
+				mfld_fw_upd.mb_status);
+	}
+	ret_val = intel_scu_ipc_check_status();
+
+term:
+	kfree(fws);
+unmap_mb:
+	iounmap(mfld_fw_upd.mailbox);
+unmap_sram:
+	iounmap(mfld_fw_upd.sram);
+out_unlock:
+	rpmsg_global_unlock();
+	return ret_val;
+}
+
+static void cur_err(const char *err_info)
+{
+	strncpy(err_buf, err_info, sizeof(err_buf) - 1);
+}
+
+static ssize_t write_dnx(struct file *file, struct kobject *kobj,
+	struct bin_attribute *attr, char *buf, loff_t off, size_t count)
+{
+	int ret;
+
+	mutex_lock(&fwud_lock);
+
+	if (!pending_data) {
+		pending_data = vmalloc(FOTA_MEM_SIZE);
+		if (NULL == pending_data) {
+			cur_err("alloc fota memory by sysfs failed\n");
+			ret = -ENOMEM;
+			goto end;
+		}
+	}
+
+	fui.fwud_pending->dnx_file_data = pending_data + IFWI_MAX_SIZE;
+
+	if (unlikely(off >= DNX_MAX_SIZE)) {
+		fui.fwud_pending->dnx_file_data = NULL;
+		cur_err("too large dnx binary stream!");
+		ret = -EFBIG;
+		goto end;
+	}
+
+	memcpy(fui.fwud_pending->dnx_file_data + off, buf, count);
+
+	if (!off)
+		fui.fwud_pending->dnx_size = count;
+	else
+		fui.fwud_pending->dnx_size += count;
+
+	mutex_unlock(&fwud_lock);
+	return count;
+
+end:
+	mutex_unlock(&fwud_lock);
+	return ret;
+}
+
+/* Parses from the end of IFWI, and looks for UPH$,
+ * to determine length of FUPH header
+ */
+static int find_fuph_header_len(unsigned int *len,
+		unsigned char *file_data, unsigned int file_size)
+{
+	int ret = -EINVAL;
+	unsigned char *temp;
+	unsigned int cnt = 0;
+
+	if (!len || !file_data || !file_size) {
+		dev_err(fui.dev, "find_fuph_header_len: Invalid inputs\n");
+		return ret;
+	}
+
+	/* Skipping the checksum at the end, and moving to the
+	 * start of the last add-on firmware size in fuph.
+	 */
+	temp = file_data + file_size - SKIP_BYTES;
+
+	while (cnt <= FUPH_MAX_LEN) {
+		if (!strncmp(temp, FUPH_STR, sizeof(FUPH_STR) - 1)) {
+			pr_info("Fuph_hdr_len=%d\n", cnt + SKIP_BYTES);
+			*len = cnt + SKIP_BYTES;
+			ret = 0;
+			break;
+		}
+		temp -= 4;
+		cnt += 4;
+	}
+
+	return ret;
+}
+
+static ssize_t write_ifwi(struct file *file, struct kobject *kobj,
+	struct bin_attribute *attr, char *buf, loff_t off, size_t count)
+{
+	int ret;
+
+	mutex_lock(&fwud_lock);
+
+	if (!pending_data) {
+		pending_data = vmalloc(FOTA_MEM_SIZE);
+		if (NULL == pending_data) {
+			cur_err("alloc fota memory by sysfs failed\n");
+			ret = -ENOMEM;
+			goto end;
+		}
+	}
+
+	fui.fwud_pending->fw_file_data = pending_data;
+
+	if (unlikely(off >= IFWI_MAX_SIZE)) {
+		fui.fwud_pending->fw_file_data = NULL;
+		cur_err("too large ifwi binary stream!\n");
+		ret = -EFBIG;
+		goto end;
+	}
+
+	memcpy(fui.fwud_pending->fw_file_data + off, buf, count);
+
+	if (!off)
+		fui.fwud_pending->fsize = count;
+	else
+		fui.fwud_pending->fsize += count;
+
+	mutex_unlock(&fwud_lock);
+	return count;
+
+end:
+	mutex_unlock(&fwud_lock);
+	return ret;
+}
+
+/*
+ * intel_scu_fw_prepare - prepare dnx_hdr and fuph
+ *
+ * This function will be invoked at reboot, when DNX and IFWI data are ready.
+ */
+static int intel_scu_fw_prepare(struct fw_ud *fwud_pending)
+{
+	unsigned int size;
+	unsigned int gpFlags = 0;
+	unsigned int xorcs;
+	unsigned char dnxSH[DNX_HDR_LEN] = { 0 };
+
+	mutex_lock(&fwud_lock);
+
+	size = fui.fwud_pending->dnx_size;
+
+	/* Set GPFlags parameter */
+	gpFlags = gpFlags | (GPF_BIT32 << 31);
+	xorcs = (size ^ gpFlags);
+
+	memcpy((dnxSH + DNX_SIZE_OFFSET), (unsigned char *)(&size), 4);
+	memcpy((dnxSH + GP_FLAG_OFFSET), (unsigned char *)(&gpFlags), 4);
+	memcpy((dnxSH + XOR_CHK_OFFSET), (unsigned char *)(&xorcs), 4);
+
+	/* assign the last DNX_HDR_LEN bytes memory to dnx header */
+	fui.fwud_pending->dnx_hdr = pending_data + FOTA_MEM_SIZE - DNX_HDR_LEN;
+
+	/* directly memcpy to dnx_hdr */
+	memcpy(fui.fwud_pending->dnx_hdr, dnxSH, DNX_HDR_LEN);
+
+	if (find_fuph_header_len(&(fui.fwud_pending->fuph_hdr_len),
+			fui.fwud_pending->fw_file_data,
+			fui.fwud_pending->fsize) < 0) {
+		dev_err(fui.dev, "Error with FUPH header\n");
+		mutex_unlock(&fwud_lock);
+		return -EINVAL;
+	}
+
+	dev_dbg(fui.dev, "fupd_hdr_len=%d, fsize=%d, dnx_size=%d",
+		fui.fwud_pending->fuph_hdr_len,	fui.fwud_pending->fsize,
+		fui.fwud_pending->dnx_size);
+
+	mutex_unlock(&fwud_lock);
+	return 0;
+}
+
+int intel_scu_ipc_fw_update(void)
+{
+	int ret = 0;
+
+	/* jump fw upgrade process when fota memory not allocated
+	 * or when user cancels update
+	 * or when one of dnx and ifwi is not written
+	 * or when failure happens in writing one of dnx and ifwi
+	 */
+	if (!pending_data || !fui.fwud_pending ||
+		!fui.fwud_pending->dnx_file_data ||
+		!fui.fwud_pending->fw_file_data) {
+		pr_info("Jump FW upgrade process\n");
+		goto end;
+	}
+
+	ret = intel_scu_fw_prepare(fui.fwud_pending);
+	if (ret) {
+		dev_err(fui.dev, "intel_scu_fw_prepare failed\n");
+		goto end;
+	}
+
+	ret = intel_scu_ipc_medfw_upgrade();
+	if (ret)
+		dev_err(fui.dev, "intel_scu_ipc_medfw_upgrade failed\n");
+
+end:
+	return ret;
+}
+EXPORT_SYMBOL(intel_scu_ipc_fw_update);
+
+static ssize_t fw_version_show(struct kobject *kobj,
+		struct kobj_attribute *attr, char *buf)
+{
+	u8 data[16] = { 0 };
+	int ret;
+	int i;
+	int used = 0;
+
+	ret = rpmsg_send_command(fw_update_instance, IPCMSG_FW_REVISION, 0,
+					NULL, (u32 *)data, 0, 4);
+	if (ret < 0) {
+		cur_err("Error getting fw version");
+		return -EINVAL;
+	}
+
+	for (i = 0; i < 16; i++)
+		used += snprintf(buf + used, PAGE_SIZE - used, "%x ", data[i]);
+
+	if (intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_TANGIER) {
+		ret = rpmsg_send_command(fw_update_instance,
+			IPCMSG_FW_REVISION, 1, NULL, (u32 *)data, 0, 4);
+		if (ret < 0) {
+			cur_err("Error getting fw version");
+			return -EINVAL;
+		}
+		for (i = 0; i < 16; i++)
+			used += snprintf(buf + used, PAGE_SIZE - used,
+				"%x ", data[i]);
+	}
+
+	return used;
+}
+
+static ssize_t last_error_show(struct kobject *kobj,
+		struct kobj_attribute *attr, char *buf)
+{
+	return snprintf(buf, PAGE_SIZE, "%s\n", err_buf);
+}
+
+static ssize_t cancel_update_store(struct kobject *kobj,
+		struct kobj_attribute *attr, const char *buf, size_t size)
+{
+	int value;
+
+	if (sscanf(buf, "%d", &value) != 1) {
+		cur_err("One argument is needed\n");
+		return -EINVAL;
+	}
+
+	if (value == 1) {
+		mutex_lock(&fwud_lock);
+		fui.fwud_pending->fw_file_data = NULL;
+		fui.fwud_pending->dnx_file_data = NULL;
+		mutex_unlock(&fwud_lock);
+	} else {
+		cur_err("input '1' to cancel fw upgrade\n");
+		return -EINVAL;
+	}
+
+	return size;
+}
+
+#define __BIN_ATTR(_name, _mode, _size, _read, _write) { \
+	.attr = {.name = __stringify(_name), .mode = _mode },	\
+	.size	= _size,					\
+	.read	= _read,					\
+	.write	= _write,					\
+}
+
+#define BIN_ATTR(_name, _mode, _size, _read, _write) \
+struct bin_attribute bin_attr_##_name =	\
+	__BIN_ATTR(_name, _mode, _size, _read, _write)
+
+#define KOBJ_FW_UPDATE_ATTR(_name, _mode, _show, _store) \
+	struct kobj_attribute _name##_attr = __ATTR(_name, _mode, _show, _store)
+
+static KOBJ_FW_UPDATE_ATTR(cancel_update, S_IWUSR, NULL, cancel_update_store);
+static KOBJ_FW_UPDATE_ATTR(fw_version, S_IRUGO, fw_version_show, NULL);
+static KOBJ_FW_UPDATE_ATTR(last_error, S_IRUGO, last_error_show, NULL);
+static BIN_ATTR(dnx, S_IWUSR, DNX_MAX_SIZE, NULL, write_dnx);
+static BIN_ATTR(ifwi, S_IWUSR, IFWI_MAX_SIZE, NULL, write_ifwi);
+
+static struct attribute *fw_update_attrs[] = {
+	&cancel_update_attr.attr,
+	&fw_version_attr.attr,
+	&last_error_attr.attr,
+	NULL,
+};
+
+static struct attribute_group fw_update_attr_group = {
+	.name = "fw_info",
+	.attrs = fw_update_attrs,
+};
+
+static int intel_fw_update_sysfs_create(struct kobject *kobj)
+{
+	int ret;
+
+	ret = sysfs_create_group(kobj, &fw_update_attr_group);
+	if (ret) {
+		dev_err(fui.dev, "Unable to export sysfs interface\n");
+		goto out;
+	}
+
+	ret = sysfs_create_bin_file(kobj, &bin_attr_dnx);
+	if (ret) {
+		dev_err(fui.dev, "Unable to create dnx bin file\n");
+		goto err_dnx_bin;
+	}
+
+	ret = sysfs_create_bin_file(kobj, &bin_attr_ifwi);
+	if (ret) {
+		dev_err(fui.dev, "Unable to create ifwi bin file\n");
+		goto err_ifwi_bin;
+	}
+
+	return 0;
+
+err_ifwi_bin:
+	sysfs_remove_bin_file(kobj, &bin_attr_dnx);
+err_dnx_bin:
+	sysfs_remove_group(kobj, &fw_update_attr_group);
+out:
+	return ret;
+}
+
+static void intel_fw_update_sysfs_remove(struct kobject *kobj)
+{
+	sysfs_remove_bin_file(kobj, &bin_attr_ifwi);
+	sysfs_remove_bin_file(kobj, &bin_attr_dnx);
+	sysfs_remove_group(kobj, &fw_update_attr_group);
+}
+
+static int fw_update_rpmsg_probe(struct rpmsg_channel *rpdev)
+{
+	int ret;
+	struct fw_update_info *fu_info = &fui;
+
+	if (rpdev == NULL) {
+		pr_err("fw_update rpmsg channel not created\n");
+		ret = -ENODEV;
+		goto out;
+	}
+
+	dev_info(&rpdev->dev, "Probed fw_update rpmsg device\n");
+
+	/* Allocate rpmsg instance for fw_update*/
+	ret = alloc_rpmsg_instance(rpdev, &fw_update_instance);
+	if (!fw_update_instance) {
+		dev_err(&rpdev->dev, "kzalloc fw_update instance failed\n");
+		goto out;
+	}
+	/* Initialize rpmsg instance */
+	init_rpmsg_instance(fw_update_instance);
+
+	fu_info->dev = &rpdev->dev;
+
+	fui.fwud_pending = kzalloc(sizeof(struct fw_ud), GFP_KERNEL);
+	if (NULL == fui.fwud_pending) {
+		ret = -ENOMEM;
+		dev_err(fui.dev, "alloc fwud_pending memory failed\n");
+		goto err_fwud_pending;
+	}
+
+	scu_fw_update_kobj = kobject_create_and_add("fw_update", kernel_kobj);
+	if (!scu_fw_update_kobj) {
+		ret = -ENOMEM;
+		dev_err(fui.dev, "create kobject failed\n");
+		goto err_kobj;
+	}
+
+	ret = intel_fw_update_sysfs_create(scu_fw_update_kobj);
+	if (ret) {
+		dev_err(fui.dev, "creating fw update sysfs failed\n");
+		goto err_free_fwud;
+	}
+
+	/* If alloc_fota_mem_early flag is set, allocate FOTA_MEM_SIZE
+	 * bytes memory.
+	 * reserve the first contiguous IFWI_MAX_SIZE bytes for IFWI,
+	 * the next contiguous DNX_MAX_SIZE bytes are reserved for DNX,
+	 * the last DNX_HDR_LEN bytes for DNX Header
+	 */
+	if (alloc_fota_mem_early) {
+		pending_data = vmalloc(FOTA_MEM_SIZE);
+		if (NULL == pending_data) {
+			ret = -ENOMEM;
+			dev_err(fui.dev, "early alloc fota memory failed\n");
+			goto err_sysfs;
+		}
+	}
+
+	return 0;
+
+err_sysfs:
+	intel_fw_update_sysfs_remove(scu_fw_update_kobj);
+err_free_fwud:
+	kobject_put(scu_fw_update_kobj);
+err_kobj:
+	kfree(fui.fwud_pending);
+	fui.fwud_pending = NULL;
+err_fwud_pending:
+	free_rpmsg_instance(rpdev, &fw_update_instance);
+out:
+	return ret;
+}
+
+static void fw_update_rpmsg_remove(struct rpmsg_channel *rpdev)
+{
+	free_rpmsg_instance(rpdev, &fw_update_instance);
+	intel_fw_update_sysfs_remove(scu_fw_update_kobj);
+	kobject_put(scu_fw_update_kobj);
+
+	vfree(pending_data);
+	pending_data = NULL;
+	kfree(fui.fwud_pending);
+	fui.fwud_pending = NULL;
+}
+
+static void fw_update_rpmsg_cb(struct rpmsg_channel *rpdev, void *data,
+					int len, void *priv, u32 src)
+{
+	dev_warn(&rpdev->dev, "unexpected, message\n");
+
+	print_hex_dump(KERN_DEBUG, __func__, DUMP_PREFIX_NONE, 16, 1,
+		       data, len,  true);
+}
+
+static struct rpmsg_device_id fw_update_rpmsg_id_table[] = {
+	{ .name	= "rpmsg_fw_update" },
+	{ },
+};
+MODULE_DEVICE_TABLE(rpmsg, fw_update_rpmsg_id_table);
+
+static struct rpmsg_driver fw_update_rpmsg = {
+	.drv.name	= KBUILD_MODNAME,
+	.drv.owner	= THIS_MODULE,
+	.id_table	= fw_update_rpmsg_id_table,
+	.probe		= fw_update_rpmsg_probe,
+	.callback	= fw_update_rpmsg_cb,
+	.remove		= fw_update_rpmsg_remove,
+};
+
+static int __init fw_update_module_init(void)
+{
+	return register_rpmsg_driver(&fw_update_rpmsg);
+}
+
+static void __exit fw_update_module_exit(void)
+{
+	unregister_rpmsg_driver(&fw_update_rpmsg);
+}
+
+module_init(fw_update_module_init);
+module_exit(fw_update_module_exit);
+
+MODULE_AUTHOR("Sreedhara DS <sreedhara.ds@intel.com>");
+MODULE_AUTHOR("Ning Li <ning.li@intel.com>");
+MODULE_DESCRIPTION("Intel SCU Firmware Update Driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/power/Kconfig b/drivers/power/Kconfig
index ba69751..242479d 100644
--- a/drivers/power/Kconfig
+++ b/drivers/power/Kconfig
@@ -14,6 +14,26 @@ config POWER_SUPPLY_DEBUG
 	  Say Y here to enable debugging messages for power supply class
 	  and drivers.
 
+config PMIC_CCSM
+	tristate "PMIC CCSM driver"
+	select POWER_SUPPLY_BATTID
+	depends on INTEL_SCU_IPC && IIO
+	help
+	  Say Y to include support for PMIC Charger Control State Machine driver
+	  Driver for initializing and monitoring the CCSM in PMIC
+	  This driver sets the CCSM registers and handles the PMIC
+	  charger interrupts.
+
+config BQ24261_CHARGER
+	tristate "BQ24261 charger driver"
+	select POWER_SUPPLY_CHARGER
+	depends on I2C
+	help
+	  Say Y to include support for BQ24261 Charger driver. This driver
+	  makes use of power supply charging framework. So the driver gives
+	  the charger hardware abstraction only. Charging logic is abstracted
+	  in the charging framework.
+
 config PDA_POWER
 	tristate "Generic PDA/phone power driver"
 	depends on !S390
diff --git a/drivers/power/Makefile b/drivers/power/Makefile
index ee54a3e..219ba9e 100644
--- a/drivers/power/Makefile
+++ b/drivers/power/Makefile
@@ -1,12 +1,15 @@
 ccflags-$(CONFIG_POWER_SUPPLY_DEBUG) := -DDEBUG
 
-power_supply-y				:= power_supply_core.o
-power_supply-$(CONFIG_SYSFS)		+= power_supply_sysfs.o
-power_supply-$(CONFIG_LEDS_TRIGGERS)	+= power_supply_leds.o
+power_supply-y					:= power_supply_core.o
+power_supply-$(CONFIG_SYSFS)			+= power_supply_sysfs.o
+power_supply-$(CONFIG_LEDS_TRIGGERS)		+= power_supply_leds.o
+power_supply-$(CONFIG_POWER_SUPPLY_CHARGER)	+= power_supply_charger.o
+power_supply-$(CONFIG_POWER_SUPPLY_BATTID)	+= battery_id.o
 
 obj-$(CONFIG_POWER_SUPPLY)	+= power_supply.o
 obj-$(CONFIG_GENERIC_ADC_BATTERY)	+= generic-adc-battery.o
 
+obj-$(CONFIG_POWER_SUPPLY_CHARGING_ALGO_PSE)	+= charging_algo_pse.o
 obj-$(CONFIG_PDA_POWER)		+= pda_power.o
 obj-$(CONFIG_APM_POWER)		+= apm_power.o
 obj-$(CONFIG_MAX8925_POWER)	+= max8925_power.o
@@ -58,3 +61,6 @@ obj-$(CONFIG_POWER_AVS)		+= avs/
 obj-$(CONFIG_CHARGER_SMB347)	+= smb347-charger.o
 obj-$(CONFIG_CHARGER_TPS65090)	+= tps65090-charger.o
 obj-$(CONFIG_POWER_RESET)	+= reset/
+
+obj-$(CONFIG_BQ24261_CHARGER)	+= bq24261_charger.o
+obj-$(CONFIG_PMIC_CCSM) += pmic_ccsm.o
diff --git a/drivers/power/bq24261_charger.c b/drivers/power/bq24261_charger.c
new file mode 100644
index 0000000..0f621e1
--- /dev/null
+++ b/drivers/power/bq24261_charger.c
@@ -0,0 +1,1887 @@
+/*
+ * bq24261_charger.c - BQ24261 Charger I2C client driver
+ *
+ * Copyright (C) 2011 Intel Corporation
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ * Author: Jenny TC <jenny.tc@intel.com>
+ */
+
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/err.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/slab.h>
+#include <linux/device.h>
+#include <linux/i2c.h>
+#include <linux/power_supply.h>
+#include <linux/pm_runtime.h>
+#include <linux/io.h>
+#include <linux/sched.h>
+#include <linux/delay.h>
+#include <linux/usb/otg.h>
+#include <linux/power/bq24261_charger.h>
+#include <linux/seq_file.h>
+#include <linux/debugfs.h>
+
+#include <asm/intel_scu_ipc.h>
+
+#define DEV_NAME "bq24261_charger"
+#define DEV_MANUFACTURER "TI"
+#define MODEL_NAME_SIZE 8
+#define DEV_MANUFACTURER_NAME_SIZE 4
+
+#define CHRG_TERM_WORKER_DELAY (30 * HZ)
+#define EXCEPTION_MONITOR_DELAY (60 * HZ)
+#define WDT_RESET_DELAY (15 * HZ)
+
+/* BQ24261 registers */
+#define BQ24261_STAT_CTRL0_ADDR		0x00
+#define BQ24261_CTRL_ADDR		0x01
+#define BQ24261_BATT_VOL_CTRL_ADDR	0x02
+#define BQ24261_VENDOR_REV_ADDR		0x03
+#define BQ24261_TERM_FCC_ADDR		0x04
+#define BQ24261_VINDPM_STAT_ADDR	0x05
+#define BQ24261_ST_NTC_MON_ADDR		0x06
+
+#define BQ24261_RESET_MASK		(0x01 << 7)
+#define BQ24261_RESET_ENABLE		(0x01 << 7)
+
+#define BQ24261_FAULT_MASK		0x07
+#define BQ24261_STAT_MASK		(0x03 << 4)
+#define BQ24261_BOOST_MASK		(0x01 << 6)
+#define BQ24261_TMR_RST_MASK		(0x01 << 7)
+#define BQ24261_TMR_RST			(0x01 << 7)
+
+#define BQ24261_ENABLE_BOOST		(0x01 << 6)
+
+#define BQ24261_VOVP			0x01
+#define BQ24261_LOW_SUPPLY		0x02
+#define BQ24261_THERMAL_SHUTDOWN	0x03
+#define BQ24261_BATT_TEMP_FAULT		0x04
+#define BQ24261_TIMER_FAULT		0x05
+#define BQ24261_BATT_OVP		0x06
+#define BQ24261_NO_BATTERY		0x07
+#define BQ24261_STAT_READY		0x00
+
+#define BQ24261_STAT_CHRG_PRGRSS	(0x01 << 4)
+#define BQ24261_STAT_CHRG_DONE		(0x02 << 4)
+#define BQ24261_STAT_FAULT		(0x03 << 4)
+
+#define BQ24261_CE_MASK			(0x01 << 1)
+#define BQ24261_CE_DISABLE		(0x01 << 1)
+
+#define BQ24261_HZ_MASK			(0x01)
+#define BQ24261_HZ_ENABLE		(0x01)
+
+#define BQ24261_ICHRG_MASK		(0x1F << 3)
+#define BQ24261_ICHRG_100ma		(0x01 << 3)
+#define BQ24261_ICHRG_200ma		(0x01 << 4)
+#define BQ24261_ICHRG_400ma		(0x01 << 5)
+#define BQ24261_ICHRG_800ma		(0x01 << 6)
+#define BQ24261_ICHRG_1600ma		(0x01 << 7)
+
+#define BQ24261_ITERM_MASK		(0x03)
+#define BQ24261_ITERM_50ma		(0x01 << 0)
+#define BQ24261_ITERM_100ma		(0x01 << 1)
+#define BQ24261_ITERM_200ma		(0x01 << 2)
+
+#define BQ24261_VBREG_MASK		(0x3F << 2)
+
+#define BQ24261_INLMT_MASK		(0x03 << 4)
+#define BQ24261_INLMT_100		0x00
+#define BQ24261_INLMT_150		(0x01 << 4)
+#define BQ24261_INLMT_500		(0x02 << 4)
+#define BQ24261_INLMT_900		(0x03 << 4)
+#define BQ24261_INLMT_1500		(0x04 << 4)
+#define BQ24261_INLMT_2500		(0x06 << 4)
+
+#define BQ24261_TE_MASK			(0x01 << 2)
+#define BQ24261_TE_ENABLE		(0x01 << 2)
+#define BQ24261_STAT_ENABLE_MASK	(0x01 << 3)
+#define BQ24261_STAT_ENABLE		(0x01 << 3)
+
+#define BQ24261_VENDOR_MASK		(0x07 << 5)
+#define BQ24261_VENDOR			(0x02 << 5)
+#define BQ24261_REV_MASK		(0x07)
+#define BQ24261_2_3_REV			(0x06)
+#define BQ24261_REV			(0x02)
+#define BQ24260_REV			(0x01)
+
+#define BQ24261_TS_MASK			(0x01 << 3)
+#define BQ24261_TS_ENABLED		(0x01 << 3)
+#define BQ24261_BOOST_ILIM_MASK		(0x01 << 4)
+#define BQ24261_BOOST_ILIM_500ma	(0x0)
+#define BQ24261_BOOST_ILIM_1A		(0x01 << 4)
+
+#define BQ24261_SAFETY_TIMER_MASK	(0x03 << 5)
+#define BQ24261_SAFETY_TIMER_40MIN	0x00
+#define BQ24261_SAFETY_TIMER_6HR	(0x01 << 5)
+#define BQ24261_SAFETY_TIMER_9HR	(0x02 << 5)
+#define BQ24261_SAFETY_TIMER_DISABLED	(0x03 << 5)
+
+/* 1% above voltage max design to report over voltage */
+#define BQ24261_OVP_MULTIPLIER			1010
+#define BQ24261_OVP_RECOVER_MULTIPLIER		990
+#define BQ24261_DEF_BAT_VOLT_MAX_DESIGN		4200000
+
+/* Settings for Voltage / DPPM Register (05) */
+#define BQ24261_VBATT_LEVEL1		3700000
+#define BQ24261_VBATT_LEVEL2		3960000
+#define BQ24261_VINDPM_MASK		(0x07)
+#define BQ24261_VINDPM_320MV		(0x01 << 2)
+#define BQ24261_VINDPM_160MV		(0x01 << 1)
+#define BQ24261_VINDPM_80MV		(0x01 << 0)
+#define BQ24261_CD_STATUS_MASK		(0x01 << 3)
+#define BQ24261_DPM_EN_MASK		(0x01 << 4)
+#define BQ24261_DPM_EN_FORCE		(0x01 << 4)
+#define BQ24261_LOW_CHG_MASK		(0x01 << 5)
+#define BQ24261_LOW_CHG_EN		(0x01 << 5)
+#define BQ24261_LOW_CHG_DIS		(~BQ24261_LOW_CHG_EN)
+#define BQ24261_DPM_STAT_MASK		(0x01 << 6)
+#define BQ24261_MINSYS_STAT_MASK	(0x01 << 7)
+
+#define BQ24261_MIN_CC			500
+
+u16 bq24261_sfty_tmr[][2] = {
+	{0, BQ24261_SAFETY_TIMER_DISABLED}
+	,
+	{40, BQ24261_SAFETY_TIMER_40MIN}
+	,
+	{360, BQ24261_SAFETY_TIMER_6HR}
+	,
+	{540, BQ24261_SAFETY_TIMER_9HR}
+	,
+};
+
+
+u16 bq24261_inlmt[][2] = {
+	{100, BQ24261_INLMT_100}
+	,
+	{150, BQ24261_INLMT_150}
+	,
+	{500, BQ24261_INLMT_500}
+	,
+	{900, BQ24261_INLMT_900}
+	,
+	{1500, BQ24261_INLMT_1500}
+	,
+	{2500, BQ24261_INLMT_2500}
+	,
+};
+
+u16 bq24261_iterm[][2] = {
+	{0, 0x00}
+	,
+	{50, BQ24261_ITERM_50ma}
+	,
+	{100, BQ24261_ITERM_100ma}
+	,
+	{150, BQ24261_ITERM_100ma | BQ24261_ITERM_50ma}
+	,
+	{200, BQ24261_ITERM_200ma}
+	,
+	{250, BQ24261_ITERM_200ma | BQ24261_ITERM_50ma}
+	,
+	{300, BQ24261_ITERM_200ma | BQ24261_ITERM_100ma}
+	,
+	{350, BQ24261_ITERM_200ma | BQ24261_ITERM_100ma | BQ24261_ITERM_50ma}
+	,
+};
+
+u16 bq24261_cc[][2] = {
+
+	{500, 0x00}
+	,
+	{600, BQ24261_ICHRG_100ma}
+	,
+	{700, BQ24261_ICHRG_200ma}
+	,
+	{800, BQ24261_ICHRG_100ma | BQ24261_ICHRG_200ma}
+	,
+	{900, BQ24261_ICHRG_400ma}
+	,
+	{1000, BQ24261_ICHRG_400ma | BQ24261_ICHRG_100ma}
+	,
+	{1100, BQ24261_ICHRG_400ma | BQ24261_ICHRG_200ma}
+	,
+	{1200, BQ24261_ICHRG_400ma | BQ24261_ICHRG_200ma | BQ24261_ICHRG_100ma}
+	,
+	{1300, BQ24261_ICHRG_800ma}
+	,
+	{1400, BQ24261_ICHRG_800ma | BQ24261_ICHRG_100ma}
+	,
+	{1500, BQ24261_ICHRG_800ma | BQ24261_ICHRG_200ma}
+	,
+};
+
+#define BQ24261_MIN_CV 3500
+#define BQ24261_MAX_CV 4440
+#define BQ24261_CV_DIV 20
+#define BQ24261_CV_BIT_POS 2
+
+static enum power_supply_property bq24261_usb_props[] = {
+	POWER_SUPPLY_PROP_PRESENT,
+	POWER_SUPPLY_PROP_ONLINE,
+	POWER_SUPPLY_PROP_TYPE,
+	POWER_SUPPLY_PROP_HEALTH,
+	POWER_SUPPLY_PROP_MAX_CHARGE_CURRENT,
+	POWER_SUPPLY_PROP_MAX_CHARGE_VOLTAGE,
+	POWER_SUPPLY_PROP_CHARGE_CURRENT,
+	POWER_SUPPLY_PROP_CHARGE_VOLTAGE,
+	POWER_SUPPLY_PROP_INLMT,
+	POWER_SUPPLY_PROP_ENABLE_CHARGING,
+	POWER_SUPPLY_PROP_ENABLE_CHARGER,
+	POWER_SUPPLY_PROP_CHARGE_TERM_CUR,
+	POWER_SUPPLY_PROP_CABLE_TYPE,
+	POWER_SUPPLY_PROP_CHARGE_CONTROL_LIMIT,
+	POWER_SUPPLY_PROP_CHARGE_CONTROL_LIMIT_MAX,
+	POWER_SUPPLY_PROP_MODEL_NAME,
+	POWER_SUPPLY_PROP_MANUFACTURER,
+	POWER_SUPPLY_PROP_MAX_TEMP,
+	POWER_SUPPLY_PROP_MIN_TEMP,
+};
+
+enum bq24261_chrgr_stat {
+	BQ24261_CHRGR_STAT_UNKNOWN,
+	BQ24261_CHRGR_STAT_READY,
+	BQ24261_CHRGR_STAT_CHARGING,
+	BQ24261_CHRGR_STAT_BAT_FULL,
+	BQ24261_CHRGR_STAT_FAULT,
+};
+
+struct bq24261_otg_event {
+	struct list_head node;
+	bool is_enable;
+};
+
+struct bq24261_charger {
+
+	struct mutex lock;
+	struct i2c_client *client;
+	struct bq24261_plat_data *pdata;
+	struct power_supply psy_usb;
+	struct delayed_work sw_term_work;
+	struct delayed_work wdt_work;
+	struct delayed_work low_supply_fault_work;
+	struct delayed_work exception_mon_work;
+	struct notifier_block otg_nb;
+	struct usb_phy *transceiver;
+	struct work_struct otg_work;
+	struct work_struct irq_work;
+	struct list_head otg_queue;
+	struct list_head irq_queue;
+	wait_queue_head_t wait_ready;
+	spinlock_t otg_queue_lock;
+	void __iomem *irq_iomap;
+
+	int chrgr_health;
+	int bat_health;
+	int cc;
+	int cv;
+	int inlmt;
+	int max_cc;
+	int max_cv;
+	int iterm;
+	int cable_type;
+	int cntl_state;
+	int max_temp;
+	int min_temp;
+	int revision;
+	enum bq24261_chrgr_stat chrgr_stat;
+	bool online;
+	bool present;
+	bool is_charging_enabled;
+	bool is_charger_enabled;
+	bool is_vsys_on;
+	bool boost_mode;
+	bool is_hw_chrg_term;
+	char model_name[MODEL_NAME_SIZE];
+	char manufacturer[DEV_MANUFACTURER_NAME_SIZE];
+};
+
+enum bq2426x_model_num {
+	BQ2426X = 0,
+	BQ24260,
+	BQ24261,
+};
+
+struct bq2426x_model {
+	char model_name[MODEL_NAME_SIZE];
+	enum bq2426x_model_num model;
+};
+
+static struct bq2426x_model bq24261_model_name[] = {
+	{ "bq2426x", BQ2426X },
+	{ "bq24260", BQ24260 },
+	{ "bq24261", BQ24261 },
+};
+
+struct i2c_client *bq24261_client;
+static inline int get_battery_voltage(int *volt);
+static inline int get_battery_current(int *cur);
+static int bq24261_handle_irq(struct bq24261_charger *chip, u8 stat_reg);
+static inline int bq24261_set_iterm(struct bq24261_charger *chip, int iterm);
+
+enum power_supply_type get_power_supply_type(
+		enum power_supply_charger_cable_type cable)
+{
+
+	switch (cable) {
+
+	case POWER_SUPPLY_CHARGER_TYPE_USB_DCP:
+		return POWER_SUPPLY_TYPE_USB_DCP;
+	case POWER_SUPPLY_CHARGER_TYPE_USB_CDP:
+		return POWER_SUPPLY_TYPE_USB_CDP;
+	case POWER_SUPPLY_CHARGER_TYPE_USB_ACA:
+	case POWER_SUPPLY_CHARGER_TYPE_ACA_DOCK:
+		return POWER_SUPPLY_TYPE_USB_ACA;
+	case POWER_SUPPLY_CHARGER_TYPE_AC:
+		return POWER_SUPPLY_TYPE_MAINS;
+	case POWER_SUPPLY_CHARGER_TYPE_NONE:
+	case POWER_SUPPLY_CHARGER_TYPE_USB_SDP:
+	default:
+		return POWER_SUPPLY_TYPE_USB;
+	}
+
+	return POWER_SUPPLY_TYPE_USB;
+}
+
+static void lookup_regval(u16 tbl[][2], size_t size, u16 in_val, u8 *out_val)
+{
+	int i;
+	for (i = 1; i < size; ++i)
+		if (in_val < tbl[i][0])
+			break;
+
+	*out_val = (u8) tbl[i - 1][1];
+}
+
+void bq24261_cc_to_reg(int cc, u8 *reg_val)
+{
+	return lookup_regval(bq24261_cc, ARRAY_SIZE(bq24261_cc), cc, reg_val);
+
+}
+
+void bq24261_cv_to_reg(int cv, u8 *reg_val)
+{
+	int val;
+
+	val = clamp_t(int, cv, BQ24261_MIN_CV, BQ24261_MAX_CV);
+	*reg_val =
+		(((val - BQ24261_MIN_CV) / BQ24261_CV_DIV)
+			<< BQ24261_CV_BIT_POS);
+}
+
+void bq24261_inlmt_to_reg(int inlmt, u8 *regval)
+{
+	return lookup_regval(bq24261_inlmt, ARRAY_SIZE(bq24261_inlmt),
+			     inlmt, regval);
+}
+
+static inline void bq24261_iterm_to_reg(int iterm, u8 *regval)
+{
+	return lookup_regval(bq24261_iterm, ARRAY_SIZE(bq24261_iterm),
+			     iterm, regval);
+}
+
+static inline void bq24261_sfty_tmr_to_reg(int tmr, u8 *regval)
+{
+	return lookup_regval(bq24261_sfty_tmr, ARRAY_SIZE(bq24261_sfty_tmr),
+			     tmr, regval);
+}
+
+static inline int bq24261_read_reg(struct i2c_client *client, u8 reg)
+{
+	int ret;
+
+	ret = i2c_smbus_read_byte_data(client, reg);
+	if (ret < 0)
+		dev_err(&client->dev, "Error(%d) in reading reg %d\n", ret,
+			reg);
+
+	return ret;
+}
+
+
+static inline void bq24261_dump_regs(bool dump_master)
+{
+	int i;
+	int ret;
+	int bat_cur, bat_volt;
+	struct bq24261_charger *chip;
+
+	if (!bq24261_client)
+		return;
+
+	chip = i2c_get_clientdata(bq24261_client);
+
+	ret = get_battery_current(&bat_cur);
+	if (ret)
+		dev_err(&bq24261_client->dev,
+			"%s: Error in getting battery current", __func__);
+	else
+		dev_info(&bq24261_client->dev, "Battery Current=%dma\n",
+				(bat_cur/1000));
+
+	ret = get_battery_voltage(&bat_volt);
+	if (ret)
+		dev_err(&bq24261_client->dev,
+			"%s: Error in getting battery voltage", __func__);
+	else
+		dev_info(&bq24261_client->dev, "Battery VOlatge=%dmV\n",
+			(bat_volt/1000));
+
+
+	dev_info(&bq24261_client->dev, "BQ24261 Register dump\n");
+
+	dev_info(&bq24261_client->dev, "*======================*\n");
+	for (i = 0; i < 7; ++i) {
+		ret = bq24261_read_reg(bq24261_client, i);
+		if (ret < 0)
+			dev_err(&bq24261_client->dev,
+				"Error in reading REG 0x%X\n", i);
+		else
+			dev_info(&bq24261_client->dev,
+				"0x%X=0x%X ", i, ret);
+	}
+	dev_info(&bq24261_client->dev, "*======================*\n");
+
+	if (chip->pdata->dump_master_regs && dump_master)
+			chip->pdata->dump_master_regs();
+
+}
+
+
+#ifdef CONFIG_DEBUG_FS
+static int bq24261_reg_show(struct seq_file *seq, void *unused)
+{
+	int val;
+	u8 reg;
+
+	reg = *((u8 *)seq->private);
+	val = bq24261_read_reg(bq24261_client, reg);
+
+	seq_printf(seq, "0x%02x\n", val);
+	return 0;
+}
+
+static int bq24261_dbgfs_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, bq24261_reg_show, inode->i_private);
+}
+
+static u32 bq24261_register_set[] = {
+	BQ24261_STAT_CTRL0_ADDR,
+	BQ24261_CTRL_ADDR,
+	BQ24261_BATT_VOL_CTRL_ADDR,
+	BQ24261_VENDOR_REV_ADDR,
+	BQ24261_TERM_FCC_ADDR,
+	BQ24261_VINDPM_STAT_ADDR,
+	BQ24261_ST_NTC_MON_ADDR,
+};
+
+static struct dentry *bq24261_dbgfs_dir;
+
+static const struct file_operations bq24261_dbg_fops = {
+	.open = bq24261_dbgfs_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release
+};
+
+static void bq24261_debugfs_init(void)
+{
+	struct dentry *fentry;
+	u32 count = ARRAY_SIZE(bq24261_register_set);
+	u32 i;
+	char name[6] = {0};
+
+	bq24261_dbgfs_dir = debugfs_create_dir(DEV_NAME, NULL);
+	if (bq24261_dbgfs_dir == NULL)
+		goto debugfs_root_exit;
+
+	for (i = 0; i < count; i++) {
+		snprintf(name, 6, "%02x", bq24261_register_set[i]);
+		fentry = debugfs_create_file(name, S_IRUGO,
+						bq24261_dbgfs_dir,
+						&bq24261_register_set[i],
+						&bq24261_dbg_fops);
+		if (fentry == NULL)
+			goto debugfs_err_exit;
+	}
+	dev_err(&bq24261_client->dev, "Debugfs created successfully!!\n");
+	return;
+
+debugfs_err_exit:
+	debugfs_remove_recursive(bq24261_dbgfs_dir);
+debugfs_root_exit:
+	dev_err(&bq24261_client->dev, "Error Creating debugfs!!\n");
+	return;
+}
+
+static void bq24261_debugfs_exit(void)
+{
+	if (bq24261_dbgfs_dir)
+		debugfs_remove_recursive(bq24261_dbgfs_dir);
+
+	return;
+}
+
+#else
+static void bq24261_debugfs_init(void)
+{
+	return;
+}
+
+static void bq24261_debugfs_exit(void)
+{
+	return;
+}
+#endif
+
+static inline int bq24261_write_reg(struct i2c_client *client, u8 reg, u8 data)
+{
+	int ret;
+
+	ret = i2c_smbus_write_byte_data(client, reg, data);
+	if (ret < 0)
+		dev_err(&client->dev, "Error(%d) in writing %d to reg %d\n",
+			ret, data, reg);
+
+	return ret;
+}
+
+static inline int bq24261_read_modify_reg(struct i2c_client *client, u8 reg,
+					  u8 mask, u8 val)
+{
+	int ret;
+
+	ret = bq24261_read_reg(client, reg);
+	if (ret < 0)
+		return ret;
+	ret = (ret & ~mask) | (mask & val);
+	return bq24261_write_reg(client, reg, ret);
+}
+
+static inline int bq24261_tmr_ntc_init(struct bq24261_charger *chip)
+{
+	u8 reg_val;
+	int ret;
+
+	bq24261_sfty_tmr_to_reg(chip->pdata->safety_timer, &reg_val);
+
+	if (chip->pdata->is_ts_enabled)
+		reg_val |= BQ24261_TS_ENABLED;
+
+	/* Check if boost mode current configuration is above 1A*/
+	if (chip->pdata->boost_mode_ma >= 1000)
+		reg_val |= BQ24261_BOOST_ILIM_1A;
+
+	ret = bq24261_read_modify_reg(chip->client, BQ24261_ST_NTC_MON_ADDR,
+			BQ24261_TS_MASK|BQ24261_SAFETY_TIMER_MASK|
+			BQ24261_BOOST_ILIM_MASK, reg_val);
+
+	return ret;
+}
+
+static inline int bq24261_enable_charging(
+	struct bq24261_charger *chip, bool val)
+{
+	int ret;
+	u8 reg_val;
+	bool is_ready;
+
+	ret = bq24261_read_reg(chip->client,
+					BQ24261_STAT_CTRL0_ADDR);
+	if (ret < 0) {
+		dev_err(&chip->client->dev,
+			"Error(%d) in reading BQ24261_STAT_CTRL0_ADDR\n", ret);
+	}
+
+	is_ready =  (ret & BQ24261_STAT_MASK) != BQ24261_STAT_FAULT;
+
+	/* If status is fault, wait for READY before enabling the charging */
+
+	if (!is_ready) {
+		ret = wait_event_timeout(chip->wait_ready,
+			(chip->chrgr_stat != BQ24261_CHRGR_STAT_READY),
+				HZ);
+		dev_info(&chip->client->dev,
+			"chrgr_stat=%x\n", chip->chrgr_stat);
+		if (ret == 0) {
+			dev_err(&chip->client->dev,
+				"Waiting for Charger Ready Failed.Enabling charging anyway\n");
+		}
+	}
+
+	if (chip->pdata->enable_charging)
+		chip->pdata->enable_charging(val);
+
+	if (val) {
+		reg_val = (~BQ24261_CE_DISABLE & BQ24261_CE_MASK);
+		if (chip->is_hw_chrg_term)
+			reg_val |= BQ24261_TE_ENABLE;
+	} else {
+		reg_val = BQ24261_CE_DISABLE;
+	}
+
+	reg_val |=  BQ24261_STAT_ENABLE;
+
+	ret = bq24261_read_modify_reg(chip->client, BQ24261_CTRL_ADDR,
+		       BQ24261_STAT_ENABLE_MASK|BQ24261_RESET_MASK|
+				BQ24261_CE_MASK|BQ24261_TE_MASK,
+					reg_val);
+	if (ret || !val)
+		return ret;
+
+	bq24261_set_iterm(chip, chip->iterm);
+	return bq24261_tmr_ntc_init(chip);
+}
+
+static inline int bq24261_reset_timer(struct bq24261_charger *chip)
+{
+	return bq24261_read_modify_reg(chip->client, BQ24261_STAT_CTRL0_ADDR,
+			BQ24261_TMR_RST_MASK, BQ24261_TMR_RST);
+}
+
+static inline int bq24261_enable_charger(
+	struct bq24261_charger *chip, int val)
+{
+
+	/* TODO: Implement enable/disable HiZ mode to enable/
+	*  disable charger
+	*/
+	u8 reg_val;
+	int ret;
+
+	reg_val = val ? (~BQ24261_HZ_ENABLE & BQ24261_HZ_MASK)  :
+			BQ24261_HZ_ENABLE;
+
+	ret = bq24261_read_modify_reg(chip->client, BQ24261_CTRL_ADDR,
+		       BQ24261_HZ_MASK|BQ24261_RESET_MASK, reg_val);
+	if (ret)
+		return ret;
+
+	return bq24261_reset_timer(chip);
+}
+
+static inline int bq24261_set_cc(struct bq24261_charger *chip, int cc)
+{
+	u8 reg_val;
+	int ret;
+
+	dev_dbg(&chip->client->dev, "cc=%d\n", cc);
+	if (chip->pdata->set_cc) {
+		ret = chip->pdata->set_cc(cc);
+		if (unlikely(ret))
+			return ret;
+	}
+
+	if (cc && (cc < BQ24261_MIN_CC)) {
+		dev_dbg(&chip->client->dev, "Set LOW_CHG bit\n");
+		reg_val = BQ24261_LOW_CHG_EN;
+		ret = bq24261_read_modify_reg(chip->client,
+				BQ24261_VINDPM_STAT_ADDR,
+				BQ24261_LOW_CHG_MASK, reg_val);
+	} else {
+		dev_dbg(&chip->client->dev, "Clear LOW_CHG bit\n");
+		reg_val = BQ24261_LOW_CHG_DIS;
+		ret = bq24261_read_modify_reg(chip->client,
+				BQ24261_VINDPM_STAT_ADDR,
+				BQ24261_LOW_CHG_MASK, reg_val);
+	}
+
+	/* Return from here since the cc setting will be done
+	   by platform specific hardware */
+	if (chip->pdata->set_cc)
+		return ret;
+
+	bq24261_cc_to_reg(cc, &reg_val);
+
+	return bq24261_read_modify_reg(chip->client, BQ24261_TERM_FCC_ADDR,
+			BQ24261_ICHRG_MASK, reg_val);
+}
+
+static inline int bq24261_set_cv(struct bq24261_charger *chip, int cv)
+{
+	int bat_volt;
+	int ret;
+	u8 reg_val;
+	u8 vindpm_val = 0x0;
+
+	/*
+	* Setting VINDPM value as per the battery voltage
+	*  VBatt           Vindpm     Register Setting
+	*  < 3.7v           4.2v       0x0 (default)
+	*  3.71v - 3.96v    4.36v      0x2
+	*  > 3.96v          4.6v       0x5
+	*/
+	ret = get_battery_voltage(&bat_volt);
+	if (ret) {
+		dev_err(&chip->client->dev,
+			"Error getting battery voltage!!\n");
+	} else {
+		if (bat_volt > BQ24261_VBATT_LEVEL2)
+			vindpm_val =
+				(BQ24261_VINDPM_320MV | BQ24261_VINDPM_80MV);
+		else if (bat_volt > BQ24261_VBATT_LEVEL1)
+			vindpm_val = BQ24261_VINDPM_160MV;
+	}
+
+	ret = bq24261_read_modify_reg(chip->client,
+			BQ24261_VINDPM_STAT_ADDR,
+			BQ24261_VINDPM_MASK,
+			vindpm_val);
+	if (ret) {
+		dev_err(&chip->client->dev,
+			"Error setting VINDPM setting!!\n");
+		return ret;
+	}
+
+	if (chip->pdata->set_cv)
+		return chip->pdata->set_cv(cv);
+
+	bq24261_cv_to_reg(cv, &reg_val);
+
+	return bq24261_read_modify_reg(chip->client, BQ24261_BATT_VOL_CTRL_ADDR,
+				       BQ24261_VBREG_MASK, reg_val);
+}
+
+static inline int bq24261_set_inlmt(struct bq24261_charger *chip, int inlmt)
+{
+	u8 reg_val;
+
+	if (chip->pdata->set_inlmt)
+		return chip->pdata->set_inlmt(inlmt);
+
+	bq24261_inlmt_to_reg(inlmt, &reg_val);
+
+	return bq24261_read_modify_reg(chip->client, BQ24261_CTRL_ADDR,
+		       BQ24261_RESET_MASK|BQ24261_INLMT_MASK, reg_val);
+
+}
+
+static inline void resume_charging(struct bq24261_charger *chip)
+{
+
+	if (chip->is_charger_enabled)
+		bq24261_enable_charger(chip, true);
+	if (chip->inlmt)
+		bq24261_set_inlmt(chip, chip->inlmt);
+	if (chip->cc)
+		bq24261_set_cc(chip, chip->cc);
+	if (chip->cv)
+		bq24261_set_cv(chip, chip->cv);
+	if (chip->is_charging_enabled)
+		bq24261_enable_charging(chip, true);
+}
+
+static inline int bq24261_set_iterm(struct bq24261_charger *chip, int iterm)
+{
+	u8 reg_val;
+
+	if (chip->pdata->set_iterm)
+		return chip->pdata->set_iterm(iterm);
+
+	bq24261_iterm_to_reg(iterm, &reg_val);
+
+	return bq24261_read_modify_reg(chip->client, BQ24261_TERM_FCC_ADDR,
+				       BQ24261_ITERM_MASK, reg_val);
+}
+
+static inline int bq24261_enable_hw_charge_term(
+	struct bq24261_charger *chip, bool val)
+{
+	u8 data;
+	int ret;
+
+	data = val ? BQ24261_TE_ENABLE : (~BQ24261_TE_ENABLE & BQ24261_TE_MASK);
+
+
+	ret = bq24261_read_modify_reg(chip->client, BQ24261_CTRL_ADDR,
+			       BQ24261_RESET_MASK|BQ24261_TE_MASK, data);
+
+	if (ret)
+		return ret;
+
+	chip->is_hw_chrg_term = val ? true : false;
+
+	return ret;
+}
+
+static inline int bq24261_enable_boost_mode(
+	struct bq24261_charger *chip, int val)
+{
+	int ret = 0;
+
+
+	if (val) {
+
+		if ((chip->revision & BQ24261_REV_MASK) == BQ24261_REV) {
+			if (chip->pdata->enable_vbus)
+				chip->pdata->enable_vbus(true);
+		}
+
+		/* TODO: Support different Host Mode Current limits */
+
+		bq24261_enable_charger(chip, true);
+		ret =
+		    bq24261_read_modify_reg(chip->client,
+					    BQ24261_STAT_CTRL0_ADDR,
+					    BQ24261_BOOST_MASK,
+					    BQ24261_ENABLE_BOOST);
+		if (unlikely(ret))
+			return ret;
+
+		ret = bq24261_tmr_ntc_init(chip);
+		if (unlikely(ret))
+			return ret;
+		chip->boost_mode = true;
+
+		if ((chip->revision & BQ24261_REV_MASK) == BQ24261_REV)
+			schedule_delayed_work(&chip->wdt_work, 0);
+
+		dev_info(&chip->client->dev, "Boost Mode enabled\n");
+	} else {
+
+		ret =
+		    bq24261_read_modify_reg(chip->client,
+					    BQ24261_STAT_CTRL0_ADDR,
+					    BQ24261_BOOST_MASK,
+					    ~BQ24261_ENABLE_BOOST);
+
+		if (unlikely(ret))
+			return ret;
+		/* if charging need not to be enabled, disable
+		* the charger else keep the charger on
+		*/
+		if (!chip->is_charging_enabled)
+			bq24261_enable_charger(chip, false);
+		chip->boost_mode = false;
+		dev_info(&chip->client->dev, "Boost Mode disabled\n");
+
+		if ((chip->revision & BQ24261_REV_MASK) == BQ24261_REV) {
+			cancel_delayed_work_sync(&chip->wdt_work);
+
+			if (chip->pdata->enable_vbus)
+				chip->pdata->enable_vbus(false);
+		}
+
+		/* Notify power supply subsystem to enable charging
+		 * if needed. Eg. if DC adapter is connected
+		 */
+		power_supply_changed(&chip->psy_usb);
+	}
+
+	return ret;
+}
+
+static inline bool bq24261_is_vsys_on(struct bq24261_charger *chip)
+{
+	int ret;
+	struct i2c_client *client = chip->client;
+
+	ret = bq24261_read_reg(client, BQ24261_CTRL_ADDR);
+	if (ret < 0) {
+		dev_err(&client->dev,
+			"Error(%d) in reading BQ24261_CTRL_ADDR\n", ret);
+		return false;
+	}
+
+	if (((ret & BQ24261_HZ_MASK) == BQ24261_HZ_ENABLE) &&
+			chip->is_charger_enabled) {
+		dev_err(&client->dev, "Charger in Hi Z Mode\n");
+		bq24261_dump_regs(true);
+		return false;
+	}
+
+	ret = bq24261_read_reg(client, BQ24261_VINDPM_STAT_ADDR);
+	if (ret < 0) {
+		dev_err(&client->dev,
+			"Error(%d) in reading BQ24261_VINDPM_STAT_ADDR\n", ret);
+		return false;
+	}
+
+	if (ret & BQ24261_CD_STATUS_MASK) {
+		dev_err(&client->dev, "CD line asserted\n");
+		bq24261_dump_regs(true);
+		return false;
+	}
+
+	return true;
+}
+
+
+static inline bool bq24261_is_online(struct bq24261_charger *chip)
+{
+	if (chip->cable_type == POWER_SUPPLY_CHARGER_TYPE_NONE)
+		return false;
+	else if (!chip->is_charger_enabled)
+		return false;
+	/* BQ24261 gives interrupt only on stop/resume charging.
+	 * If charging is already stopped, we need to query the hardware
+	 * to see charger is still active and can supply vsys or not.
+	 */
+	else if ((chip->chrgr_stat == BQ24261_CHRGR_STAT_FAULT) ||
+		 (!chip->is_charging_enabled))
+		return bq24261_is_vsys_on(chip);
+	else
+		return chip->is_vsys_on;
+}
+
+static int bq24261_usb_set_property(struct power_supply *psy,
+				    enum power_supply_property psp,
+				    const union power_supply_propval *val)
+{
+	struct bq24261_charger *chip = container_of(psy,
+						    struct bq24261_charger,
+						    psy_usb);
+	int ret = 0;
+
+
+	mutex_lock(&chip->lock);
+
+
+	switch (psp) {
+
+	case POWER_SUPPLY_PROP_PRESENT:
+		chip->present = val->intval;
+		/*If charging capable cable is present, then
+		hold the charger wakelock so that the target
+		does not enter suspend mode when charging is
+		in progress.
+		If charging cable has been removed, then
+		unlock the wakelock to allow the target to
+		enter the sleep mode*/
+/*		if (!wake_lock_active(&chip->chrgr_en_wakelock) &&
+					val->intval)
+			wake_lock(&chip->chrgr_en_wakelock);
+		else if (wake_lock_active(&chip->chrgr_en_wakelock) &&
+					!val->intval)
+			wake_unlock(&chip->chrgr_en_wakelock);
+*/
+		break;
+	case POWER_SUPPLY_PROP_ONLINE:
+		chip->online = val->intval;
+		break;
+	case POWER_SUPPLY_PROP_ENABLE_CHARGING:
+
+		ret = bq24261_enable_charging(chip, val->intval);
+
+		if (ret)
+			dev_err(&chip->client->dev,
+				"Error(%d) in %s charging", ret,
+				(val->intval ? "enable" : "disable"));
+		else
+			chip->is_charging_enabled = val->intval;
+
+		if (val->intval)
+			bq24261_enable_hw_charge_term(chip, true);
+		else
+			cancel_delayed_work_sync(&chip->sw_term_work);
+
+		break;
+	case POWER_SUPPLY_PROP_ENABLE_CHARGER:
+
+		/* Don't enable the charger unless overvoltage is recovered */
+
+		if (chip->bat_health != POWER_SUPPLY_HEALTH_OVERVOLTAGE) {
+			ret = bq24261_enable_charger(chip, val->intval);
+
+			if (ret)
+				dev_err(&chip->client->dev,
+					"Error(%d) in %s charger", ret,
+					(val->intval ? "enable" : "disable"));
+			else
+				chip->is_charger_enabled = val->intval;
+		} else {
+			dev_info(&chip->client->dev, "Battery Over Voltage. Charger will be disabled\n");
+		}
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_CURRENT:
+		ret = bq24261_set_cc(chip, val->intval);
+		if (!ret)
+			chip->cc = val->intval;
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_VOLTAGE:
+		ret = bq24261_set_cv(chip, val->intval);
+		if (!ret)
+			chip->cv = val->intval;
+		break;
+	case POWER_SUPPLY_PROP_MAX_CHARGE_CURRENT:
+		chip->max_cc = val->intval;
+		break;
+	case POWER_SUPPLY_PROP_MAX_CHARGE_VOLTAGE:
+		chip->max_cv = val->intval;
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_TERM_CUR:
+		ret = bq24261_set_iterm(chip, val->intval);
+		if (!ret)
+			chip->iterm = val->intval;
+		break;
+	case POWER_SUPPLY_PROP_CABLE_TYPE:
+
+		chip->cable_type = val->intval;
+		chip->psy_usb.type = get_power_supply_type(chip->cable_type);
+		if (chip->cable_type != POWER_SUPPLY_CHARGER_TYPE_NONE) {
+			chip->chrgr_health = POWER_SUPPLY_HEALTH_GOOD;
+			chip->chrgr_stat = BQ24261_CHRGR_STAT_UNKNOWN;
+
+			/* Adding this processing in order to check
+			for any faults during connect */
+
+			ret = bq24261_read_reg(chip->client,
+						BQ24261_STAT_CTRL0_ADDR);
+			if (ret < 0)
+				dev_err(&chip->client->dev,
+				"Error (%d) in reading status register(0x00)\n",
+				ret);
+			else
+				bq24261_handle_irq(chip, ret);
+		} else {
+			chip->chrgr_stat = BQ24261_CHRGR_STAT_UNKNOWN;
+			chip->chrgr_health = POWER_SUPPLY_HEALTH_UNKNOWN;
+			cancel_delayed_work_sync(&chip->low_supply_fault_work);
+		}
+
+
+		break;
+	case POWER_SUPPLY_PROP_INLMT:
+		ret = bq24261_set_inlmt(chip, val->intval);
+		if (!ret)
+			chip->inlmt = val->intval;
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_CONTROL_LIMIT:
+		chip->cntl_state = val->intval;
+		break;
+	case POWER_SUPPLY_PROP_MAX_TEMP:
+		chip->max_temp = val->intval;
+		break;
+	case POWER_SUPPLY_PROP_MIN_TEMP:
+		chip->min_temp = val->intval;
+		break;
+	default:
+		ret = -ENODATA;
+	}
+
+	mutex_unlock(&chip->lock);
+	return ret;
+}
+
+static int bq24261_usb_get_property(struct power_supply *psy,
+				    enum power_supply_property psp,
+				    union power_supply_propval *val)
+{
+	struct bq24261_charger *chip = container_of(psy,
+						    struct bq24261_charger,
+						    psy_usb);
+
+	mutex_lock(&chip->lock);
+
+	switch (psp) {
+	case POWER_SUPPLY_PROP_PRESENT:
+		val->intval = chip->present;
+		break;
+	case POWER_SUPPLY_PROP_ONLINE:
+		val->intval = chip->online;
+		break;
+	case POWER_SUPPLY_PROP_HEALTH:
+		val->intval = chip->chrgr_health;
+		break;
+	case POWER_SUPPLY_PROP_MAX_CHARGE_CURRENT:
+		val->intval = chip->max_cc;
+		break;
+	case POWER_SUPPLY_PROP_MAX_CHARGE_VOLTAGE:
+		val->intval = chip->max_cv;
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_CURRENT:
+		val->intval = chip->cc;
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_VOLTAGE:
+		val->intval = chip->cv;
+		break;
+	case POWER_SUPPLY_PROP_INLMT:
+		val->intval = chip->inlmt;
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_TERM_CUR:
+		val->intval = chip->iterm;
+		break;
+	case POWER_SUPPLY_PROP_CABLE_TYPE:
+		val->intval = chip->cable_type;
+		break;
+	case POWER_SUPPLY_PROP_ENABLE_CHARGING:
+		if (chip->boost_mode)
+			val->intval = false;
+		else
+			val->intval = (chip->is_charging_enabled &&
+			(chip->chrgr_stat == BQ24261_CHRGR_STAT_CHARGING));
+
+		break;
+	case POWER_SUPPLY_PROP_ENABLE_CHARGER:
+		val->intval = bq24261_is_online(chip);
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_CONTROL_LIMIT:
+		val->intval = chip->cntl_state;
+		break;
+	case POWER_SUPPLY_PROP_CHARGE_CONTROL_LIMIT_MAX:
+		val->intval = chip->pdata->num_throttle_states;
+		break;
+	case POWER_SUPPLY_PROP_MODEL_NAME:
+		val->strval = chip->model_name;
+		break;
+	case POWER_SUPPLY_PROP_MANUFACTURER:
+		val->strval = chip->manufacturer;
+		break;
+	case POWER_SUPPLY_PROP_MAX_TEMP:
+		val->intval = chip->max_temp;
+		break;
+	case POWER_SUPPLY_PROP_MIN_TEMP:
+		val->intval = chip->min_temp;
+		break;
+	default:
+		mutex_unlock(&chip->lock);
+		return -EINVAL;
+	}
+
+	mutex_unlock(&chip->lock);
+	return 0;
+}
+
+static inline struct power_supply *get_psy_battery(void)
+{
+	struct class_dev_iter iter;
+	struct device *dev;
+	static struct power_supply *pst;
+
+	class_dev_iter_init(&iter, power_supply_class, NULL, NULL);
+	while ((dev = class_dev_iter_next(&iter))) {
+		pst = (struct power_supply *)dev_get_drvdata(dev);
+		if (pst->type == POWER_SUPPLY_TYPE_BATTERY) {
+			class_dev_iter_exit(&iter);
+			return pst;
+		}
+	}
+	class_dev_iter_exit(&iter);
+
+	return NULL;
+}
+
+static inline int get_battery_voltage(int *volt)
+{
+	struct power_supply *psy;
+	union power_supply_propval val;
+	int ret;
+
+	psy = get_psy_battery();
+	if (!psy)
+		return -EINVAL;
+
+	ret = psy->get_property(psy, POWER_SUPPLY_PROP_VOLTAGE_NOW, &val);
+	if (!ret)
+		*volt = (val.intval);
+
+	return ret;
+}
+
+static inline int get_battery_volt_max_design(int *volt)
+{
+	struct power_supply *psy;
+	union power_supply_propval val;
+	int ret;
+
+	psy = get_psy_battery();
+	if (!psy)
+		return -EINVAL;
+
+	ret = psy->get_property(psy,
+		POWER_SUPPLY_PROP_VOLTAGE_MAX_DESIGN, &val);
+	if (!ret)
+		(*volt = val.intval);
+	return ret;
+}
+
+static inline int get_battery_current(int *cur)
+{
+	struct power_supply *psy;
+	union power_supply_propval val;
+	int ret;
+
+	psy = get_psy_battery();
+	if (!psy)
+		return -EINVAL;
+
+	ret = psy->get_property(psy, POWER_SUPPLY_PROP_CURRENT_NOW, &val);
+	if (!ret)
+		*cur = val.intval;
+
+	return ret;
+}
+
+static void bq24261_wdt_reset_worker(struct work_struct *work)
+{
+
+	struct bq24261_charger *chip = container_of(work,
+			    struct bq24261_charger, wdt_work.work);
+	int ret;
+	ret = bq24261_reset_timer(chip);
+
+	if (ret)
+		dev_err(&chip->client->dev, "Error (%d) in WDT reset\n");
+	else
+		dev_info(&chip->client->dev, "WDT reset\n");
+
+	schedule_delayed_work(&chip->wdt_work, WDT_RESET_DELAY);
+}
+
+static void bq24261_sw_charge_term_worker(struct work_struct *work)
+{
+
+	struct bq24261_charger *chip = container_of(work,
+						    struct bq24261_charger,
+						    sw_term_work.work);
+
+	power_supply_changed(NULL);
+
+	schedule_delayed_work(&chip->sw_term_work,
+			      CHRG_TERM_WORKER_DELAY);
+
+}
+
+int bq24261_get_bat_health(void)
+{
+
+	struct bq24261_charger *chip;
+
+	if (!bq24261_client)
+		return -ENODEV;
+
+	chip = i2c_get_clientdata(bq24261_client);
+
+	return chip->bat_health;
+}
+
+
+static void bq24261_low_supply_fault_work(struct work_struct *work)
+{
+	struct bq24261_charger *chip = container_of(work,
+						    struct bq24261_charger,
+						    low_supply_fault_work.work);
+
+	if (chip->chrgr_stat == BQ24261_CHRGR_STAT_FAULT) {
+		dev_err(&chip->client->dev, "Low Supply Fault detected!!\n");
+		chip->chrgr_health = POWER_SUPPLY_HEALTH_DEAD;
+		power_supply_changed(&chip->psy_usb);
+		bq24261_dump_regs(true);
+	}
+	return;
+}
+
+
+/* is_bat_over_voltage: check battery is over voltage or not
+*  @chip: bq24261_charger context
+*
+*  This function is used to verify the over voltage condition.
+*  In some scenarios, HW generates Over Voltage exceptions when
+*  battery voltage is normal. This function uses the over voltage
+*  condition (voltage_max_design * 1.01) to verify battery is really
+*  over charged or not.
+*/
+
+static bool is_bat_over_voltage(struct bq24261_charger *chip,
+		bool verify_recovery)
+{
+
+	int bat_volt, bat_volt_max_des, ret;
+
+	ret = get_battery_voltage(&bat_volt);
+	if (ret)
+		return verify_recovery ? false : true;
+
+	ret = get_battery_volt_max_design(&bat_volt_max_des);
+
+	if (ret)
+		bat_volt_max_des = BQ24261_DEF_BAT_VOLT_MAX_DESIGN;
+
+	dev_info(&chip->client->dev, "bat_volt=%d Voltage Max Design=%d OVP_VOLT=%d OVP recover volt=%d\n",
+			bat_volt, bat_volt_max_des,
+			(bat_volt_max_des/1000 * BQ24261_OVP_MULTIPLIER),
+			(bat_volt_max_des/1000 *
+				BQ24261_OVP_RECOVER_MULTIPLIER));
+	if (verify_recovery) {
+		if ((bat_volt) <= (bat_volt_max_des / 1000 *
+				BQ24261_OVP_RECOVER_MULTIPLIER))
+			return true;
+		else
+			return false;
+	} else {
+		if ((bat_volt) >= (bat_volt_max_des / 1000 *
+					BQ24261_OVP_MULTIPLIER))
+			return true;
+		else
+			return false;
+	}
+
+	return false;
+}
+
+#define IS_BATTERY_OVER_VOLTAGE(chip) \
+	is_bat_over_voltage(chip , false)
+
+#define IS_BATTERY_OVER_VOLTAGE_RECOVERED(chip) \
+	is_bat_over_voltage(chip , true)
+
+static void handle_battery_over_voltage(struct bq24261_charger *chip)
+{
+	/* Set Health to Over Voltage. Disable charger to discharge
+	*  battery to reduce the battery voltage.
+	*/
+	chip->bat_health = POWER_SUPPLY_HEALTH_OVERVOLTAGE;
+	bq24261_enable_charger(chip, false);
+	chip->is_charger_enabled = false;
+	cancel_delayed_work_sync(&chip->exception_mon_work);
+	schedule_delayed_work(&chip->exception_mon_work,
+			EXCEPTION_MONITOR_DELAY);
+}
+
+static void bq24261_exception_mon_work(struct work_struct *work)
+{
+	struct bq24261_charger *chip = container_of(work,
+						    struct bq24261_charger,
+						    exception_mon_work.work);
+	/* Only overvoltage exception need to monitor.*/
+	if (IS_BATTERY_OVER_VOLTAGE_RECOVERED(chip)) {
+		dev_info(&chip->client->dev, "Over Voltage Exception Recovered\n");
+		chip->bat_health = POWER_SUPPLY_HEALTH_GOOD;
+		bq24261_enable_charger(chip, true);
+		chip->is_charger_enabled = true;
+		resume_charging(chip);
+	} else {
+		schedule_delayed_work(&chip->exception_mon_work,
+			      EXCEPTION_MONITOR_DELAY);
+	}
+}
+
+static int bq24261_handle_irq(struct bq24261_charger *chip, u8 stat_reg)
+{
+	struct i2c_client *client = chip->client;
+	bool notify = true;
+
+	dev_info(&client->dev, "%s:%d stat=0x%x\n",
+			__func__, __LINE__, stat_reg);
+
+	switch (stat_reg & BQ24261_STAT_MASK) {
+	case BQ24261_STAT_READY:
+		chip->chrgr_stat = BQ24261_CHRGR_STAT_READY;
+		chip->chrgr_health = POWER_SUPPLY_HEALTH_GOOD;
+		chip->bat_health = POWER_SUPPLY_HEALTH_GOOD;
+		dev_info(&client->dev, "Charger Status: Ready\n");
+		notify = false;
+		break;
+	case BQ24261_STAT_CHRG_PRGRSS:
+		chip->chrgr_stat = BQ24261_CHRGR_STAT_CHARGING;
+		chip->chrgr_health = POWER_SUPPLY_HEALTH_GOOD;
+		chip->bat_health = POWER_SUPPLY_HEALTH_GOOD;
+		dev_info(&client->dev, "Charger Status: Charge Progress\n");
+		bq24261_dump_regs(false);
+		break;
+	case BQ24261_STAT_CHRG_DONE:
+		chip->chrgr_health = POWER_SUPPLY_HEALTH_GOOD;
+		chip->bat_health = POWER_SUPPLY_HEALTH_GOOD;
+		dev_info(&client->dev, "Charger Status: Charge Done\n");
+
+		bq24261_enable_hw_charge_term(chip, false);
+		resume_charging(chip);
+		schedule_delayed_work(&chip->sw_term_work, 0);
+		break;
+
+	case BQ24261_STAT_FAULT:
+		break;
+	}
+
+	if (stat_reg & BQ24261_BOOST_MASK)
+		dev_info(&client->dev, "Boost Mode\n");
+
+	if ((stat_reg & BQ24261_STAT_MASK) == BQ24261_STAT_FAULT) {
+		bool dump_master = true;
+		chip->chrgr_stat = BQ24261_CHRGR_STAT_FAULT;
+
+		switch (stat_reg & BQ24261_FAULT_MASK) {
+		case BQ24261_VOVP:
+			chip->chrgr_health = POWER_SUPPLY_HEALTH_OVERVOLTAGE;
+			dev_err(&client->dev, "Charger OVP Fault\n");
+			break;
+
+		case BQ24261_LOW_SUPPLY:
+			notify = false;
+
+			if (chip->pdata->handle_low_supply)
+				chip->pdata->handle_low_supply();
+
+			if (chip->cable_type !=
+					POWER_SUPPLY_CHARGER_TYPE_NONE) {
+				schedule_delayed_work
+					(&chip->low_supply_fault_work,
+					5*HZ);
+				dev_dbg(&client->dev,
+					"Schedule Low Supply Fault work!!\n");
+			}
+			break;
+
+		case BQ24261_THERMAL_SHUTDOWN:
+			chip->chrgr_health = POWER_SUPPLY_HEALTH_OVERHEAT;
+			dev_err(&client->dev, "Charger Thermal Fault\n");
+			break;
+
+		case BQ24261_BATT_TEMP_FAULT:
+			chip->bat_health = POWER_SUPPLY_HEALTH_OVERHEAT;
+			dev_err(&client->dev, "Battery Temperature Fault\n");
+			break;
+
+		case BQ24261_TIMER_FAULT:
+			chip->bat_health = POWER_SUPPLY_HEALTH_UNSPEC_FAILURE;
+			chip->chrgr_health = POWER_SUPPLY_HEALTH_UNSPEC_FAILURE;
+			dev_err(&client->dev, "Charger Timer Fault\n");
+			break;
+
+		case BQ24261_BATT_OVP:
+			notify = false;
+			if (chip->bat_health !=
+					POWER_SUPPLY_HEALTH_OVERVOLTAGE) {
+				if (!IS_BATTERY_OVER_VOLTAGE(chip)) {
+					chip->chrgr_stat =
+						BQ24261_CHRGR_STAT_UNKNOWN;
+					resume_charging(chip);
+				} else {
+					dev_err(&client->dev, "Battery Over Voltage Fault\n");
+					handle_battery_over_voltage(chip);
+					notify = true;
+				}
+			}
+			break;
+		case BQ24261_NO_BATTERY:
+			dev_err(&client->dev, "No Battery Connected\n");
+			break;
+
+		}
+
+		if (chip->chrgr_stat == BQ24261_CHRGR_STAT_FAULT && notify)
+			bq24261_dump_regs(dump_master);
+	}
+
+	wake_up(&chip->wait_ready);
+
+	chip->is_vsys_on = bq24261_is_vsys_on(chip);
+	if (notify)
+		power_supply_changed(&chip->psy_usb);
+
+	return 0;
+}
+
+static void bq24261_irq_worker(struct work_struct *work)
+{
+	struct bq24261_charger *chip =
+	    container_of(work, struct bq24261_charger, irq_work);
+	int ret;
+
+	/*Lock to ensure that interrupt register readings are done
+	* and processed sequentially. The interrupt Fault registers
+	* are read on clear and without sequential processing double
+	* fault interrupts or fault recovery cannot be handlled propely
+	*/
+
+	mutex_lock(&chip->lock);
+
+	dev_dbg(&chip->client->dev, "%s\n", __func__);
+
+	ret = bq24261_read_reg(chip->client, BQ24261_STAT_CTRL0_ADDR);
+	if (ret < 0) {
+		dev_err(&chip->client->dev,
+			"Error (%d) in reading BQ24261_STAT_CTRL0_ADDR\n", ret);
+	}
+	else {
+		bq24261_handle_irq(chip, ret);
+	}
+	mutex_unlock(&chip->lock);
+}
+
+static irqreturn_t bq24261_thread_handler(int id, void *data)
+{
+	struct bq24261_charger *chip = (struct bq24261_charger *)data;
+
+	queue_work(system_nrt_wq, &chip->irq_work);
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t bq24261_irq_handler(int irq, void *data)
+{
+	struct bq24261_charger *chip = (struct bq24261_charger *)data;
+	u8 intr_stat;
+
+	if (chip->irq_iomap) {
+		intr_stat = ioread8(chip->irq_iomap);
+		if ((intr_stat & chip->pdata->irq_mask)) {
+			dev_dbg(&chip->client->dev, "%s\n", __func__);
+			return IRQ_WAKE_THREAD;
+		}
+	}
+
+	return IRQ_NONE;
+}
+
+static void bq24261_boostmode_worker(struct work_struct *work)
+{
+	struct bq24261_charger *chip =
+	    container_of(work, struct bq24261_charger, otg_work);
+	struct bq24261_otg_event *evt, *tmp;
+	unsigned long flags;
+
+	spin_lock_irqsave(&chip->otg_queue_lock, flags);
+	list_for_each_entry_safe(evt, tmp, &chip->otg_queue, node) {
+		list_del(&evt->node);
+		spin_unlock_irqrestore(&chip->otg_queue_lock, flags);
+
+		dev_info(&chip->client->dev,
+			"%s:%d state=%d\n", __FILE__, __LINE__,
+				evt->is_enable);
+		mutex_lock(&chip->lock);
+		if (evt->is_enable)
+			bq24261_enable_boost_mode(chip, 1);
+		else
+			bq24261_enable_boost_mode(chip, 0);
+
+		mutex_unlock(&chip->lock);
+		spin_lock_irqsave(&chip->otg_queue_lock, flags);
+		kfree(evt);
+
+	}
+	spin_unlock_irqrestore(&chip->otg_queue_lock, flags);
+}
+
+static int otg_handle_notification(struct notifier_block *nb,
+				   unsigned long event, void *param)
+{
+
+	struct bq24261_charger *chip =
+	    container_of(nb, struct bq24261_charger, otg_nb);
+	struct bq24261_otg_event *evt;
+
+	dev_dbg(&chip->client->dev, "OTG notification: %lu\n", event);
+	if (!param || event != USB_EVENT_DRIVE_VBUS)
+		return NOTIFY_DONE;
+
+	evt = kzalloc(sizeof(*evt), GFP_ATOMIC);
+	if (!evt) {
+		dev_err(&chip->client->dev,
+			"failed to allocate memory for OTG event\n");
+		return NOTIFY_DONE;
+	}
+
+	evt->is_enable = *(int *)param;
+	INIT_LIST_HEAD(&evt->node);
+
+	spin_lock(&chip->otg_queue_lock);
+	list_add_tail(&evt->node, &chip->otg_queue);
+	spin_unlock(&chip->otg_queue_lock);
+
+	queue_work(system_nrt_wq, &chip->otg_work);
+	return NOTIFY_OK;
+}
+
+static inline int register_otg_notifications(struct bq24261_charger *chip)
+{
+
+	int retval;
+
+	INIT_LIST_HEAD(&chip->otg_queue);
+	INIT_WORK(&chip->otg_work, bq24261_boostmode_worker);
+	spin_lock_init(&chip->otg_queue_lock);
+
+	chip->otg_nb.notifier_call = otg_handle_notification;
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 10, 0))
+	chip->transceiver = usb_get_transceiver();
+#else
+	chip->transceiver = usb_get_phy(USB_PHY_TYPE_USB2);
+#endif
+	if (!chip->transceiver || IS_ERR(chip->transceiver)) {
+		dev_err(&chip->client->dev, "failed to get otg transceiver\n");
+		return -EINVAL;
+	}
+	retval = usb_register_notifier(chip->transceiver, &chip->otg_nb);
+	if (retval) {
+		dev_err(&chip->client->dev,
+			"failed to register otg notifier\n");
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+static enum bq2426x_model_num bq24261_get_model(int bq24261_rev_reg)
+{
+	switch (bq24261_rev_reg & BQ24261_REV_MASK) {
+	case BQ24260_REV:
+		return BQ24260;
+	case BQ24261_REV:
+	case BQ24261_2_3_REV:
+		return BQ24261;
+	default:
+		return BQ2426X;
+	}
+}
+
+static int bq24261_probe(struct i2c_client *client,
+			 const struct i2c_device_id *id)
+{
+	struct i2c_adapter *adapter;
+	struct bq24261_charger *chip;
+	int ret;
+	int bq2426x_rev;
+	enum bq2426x_model_num bq24261_rev_index;
+
+	adapter = to_i2c_adapter(client->dev.parent);
+
+	if (!client->dev.platform_data) {
+		dev_err(&client->dev, "platform data is null");
+		return -EFAULT;
+	}
+
+	if (!i2c_check_functionality(adapter, I2C_FUNC_SMBUS_BYTE_DATA)) {
+		dev_err(&client->dev,
+			"I2C adapter %s doesn'tsupport BYTE DATA transfer\n",
+			adapter->name);
+		return -EIO;
+	}
+
+	bq2426x_rev = bq24261_read_reg(client, BQ24261_VENDOR_REV_ADDR);
+	if (bq2426x_rev < 0) {
+		dev_err(&client->dev,
+			"Error (%d) in reading BQ24261_VENDOR_REV_ADDR\n", bq2426x_rev);
+		return bq2426x_rev;
+	}
+	dev_info(&client->dev, "bq2426x revision: 0x%x found!!\n", bq2426x_rev);
+
+	bq24261_rev_index = bq24261_get_model(bq2426x_rev);
+	if ((bq2426x_rev & BQ24261_VENDOR_MASK) != BQ24261_VENDOR) {
+		dev_err(&client->dev,
+			"Invalid Vendor/Revision number in BQ24261_VENDOR_REV_ADDR: %d",
+			bq2426x_rev);
+		return -ENODEV;
+	}
+
+	chip = devm_kzalloc(&client->dev, sizeof(*chip), GFP_KERNEL);
+	if (!chip) {
+		dev_err(&client->dev, "mem alloc failed\n");
+		return -ENOMEM;
+	}
+
+	init_waitqueue_head(&chip->wait_ready);
+	i2c_set_clientdata(client, chip);
+	chip->pdata = client->dev.platform_data;
+
+	/* Remap IRQ map address to read the IRQ status */
+	if ((chip->pdata->irq_map) && (chip->pdata->irq_mask)) {
+		chip->irq_iomap = ioremap_nocache(chip->pdata->irq_map, 8);
+		if (!chip->irq_iomap) {
+			dev_err(&client->dev, "Failed: ioremap_nocache\n");
+			return -EFAULT;
+		}
+	}
+
+	chip->client = client;
+	chip->pdata = client->dev.platform_data;
+
+	chip->psy_usb.name = DEV_NAME;
+	chip->psy_usb.type = POWER_SUPPLY_TYPE_USB;
+	chip->psy_usb.properties = bq24261_usb_props;
+	chip->psy_usb.num_properties = ARRAY_SIZE(bq24261_usb_props);
+	chip->psy_usb.get_property = bq24261_usb_get_property;
+	chip->psy_usb.set_property = bq24261_usb_set_property;
+	chip->psy_usb.supplied_to = chip->pdata->supplied_to;
+	chip->psy_usb.num_supplicants = chip->pdata->num_supplicants;
+	chip->psy_usb.throttle_states = chip->pdata->throttle_states;
+	chip->psy_usb.num_throttle_states = chip->pdata->num_throttle_states;
+	chip->psy_usb.supported_cables = POWER_SUPPLY_CHARGER_TYPE_USB;
+	chip->max_cc = 1500;
+	chip->chrgr_stat = BQ24261_CHRGR_STAT_UNKNOWN;
+	chip->chrgr_health = POWER_SUPPLY_HEALTH_UNKNOWN;
+	chip->revision = bq2426x_rev;
+
+	strncpy(chip->model_name,
+		bq24261_model_name[bq24261_rev_index].model_name,
+		MODEL_NAME_SIZE);
+	strncpy(chip->manufacturer, DEV_MANUFACTURER,
+		DEV_MANUFACTURER_NAME_SIZE);
+
+	mutex_init(&chip->lock);
+	ret = power_supply_register(&client->dev, &chip->psy_usb);
+	if (ret) {
+		dev_err(&client->dev, "Failed: power supply register (%d)\n",
+			ret);
+		iounmap(chip->irq_iomap);
+		return ret;
+	}
+
+	INIT_DELAYED_WORK(&chip->sw_term_work, bq24261_sw_charge_term_worker);
+	INIT_DELAYED_WORK(&chip->low_supply_fault_work,
+				bq24261_low_supply_fault_work);
+	INIT_DELAYED_WORK(&chip->exception_mon_work,
+				bq24261_exception_mon_work);
+	if ((chip->revision & BQ24261_REV_MASK) == BQ24261_REV) {
+		INIT_DELAYED_WORK(&chip->wdt_work,
+					bq24261_wdt_reset_worker);
+	}
+
+	INIT_WORK(&chip->irq_work, bq24261_irq_worker);
+	if (chip->client->irq) {
+		ret = request_threaded_irq(chip->client->irq,
+					   bq24261_irq_handler,
+					   bq24261_thread_handler,
+					   IRQF_SHARED|IRQF_NO_SUSPEND,
+					   DEV_NAME, chip);
+		if (ret) {
+			dev_err(&client->dev, "Failed: request_irq (%d)\n",
+				ret);
+			iounmap(chip->irq_iomap);
+			power_supply_unregister(&chip->psy_usb);
+			return ret;
+		}
+	}
+
+	if (IS_BATTERY_OVER_VOLTAGE(chip))
+		handle_battery_over_voltage(chip);
+	else
+		chip->bat_health = POWER_SUPPLY_HEALTH_GOOD;
+
+	if (register_otg_notifications(chip))
+		dev_err(&client->dev, "Error in registering OTG notifications. Unable to supply power to Host\n");
+
+	bq24261_client = client;
+	power_supply_changed(&chip->psy_usb);
+	bq24261_debugfs_init();
+
+	return 0;
+}
+
+static int bq24261_remove(struct i2c_client *client)
+{
+	struct bq24261_charger *chip = i2c_get_clientdata(client);
+
+	if (client->irq)
+		free_irq(client->irq, chip);
+
+	flush_scheduled_work();
+	if (chip->irq_iomap)
+		iounmap(chip->irq_iomap);
+	if (chip->transceiver)
+		usb_unregister_notifier(chip->transceiver, &chip->otg_nb);
+
+	power_supply_unregister(&chip->psy_usb);
+	bq24261_debugfs_exit();
+	return 0;
+}
+
+static int bq24261_suspend(struct device *dev)
+{
+	struct bq24261_charger *chip = dev_get_drvdata(dev);
+
+	if ((chip->revision & BQ24261_REV_MASK) == BQ24261_REV) {
+		if (chip->boost_mode)
+			cancel_delayed_work_sync(&chip->wdt_work);
+	}
+	dev_dbg(&chip->client->dev, "bq24261 suspend\n");
+	return 0;
+}
+
+static int bq24261_resume(struct device *dev)
+{
+	struct bq24261_charger *chip = dev_get_drvdata(dev);
+
+	if ((chip->revision & BQ24261_REV_MASK) == BQ24261_REV) {
+		if (chip->boost_mode)
+			bq24261_enable_boost_mode(chip, 1);
+	}
+
+	dev_dbg(&chip->client->dev, "bq24261 resume\n");
+	return 0;
+}
+
+static int bq24261_runtime_suspend(struct device *dev)
+{
+	dev_dbg(dev, "%s called\n", __func__);
+	return 0;
+}
+
+static int bq24261_runtime_resume(struct device *dev)
+{
+	dev_dbg(dev, "%s called\n", __func__);
+	return 0;
+}
+
+static int bq24261_runtime_idle(struct device *dev)
+{
+
+	dev_dbg(dev, "%s called\n", __func__);
+	return 0;
+}
+
+static const struct dev_pm_ops bq24261_pm_ops = {
+	.suspend = bq24261_suspend,
+	.resume = bq24261_resume,
+	.runtime_suspend = bq24261_runtime_suspend,
+	.runtime_resume = bq24261_runtime_resume,
+	.runtime_idle = bq24261_runtime_idle,
+};
+
+static const struct i2c_device_id bq24261_id[] = {
+	{DEV_NAME, 0},
+	{},
+};
+
+MODULE_DEVICE_TABLE(i2c, bq24261_id);
+
+static struct i2c_driver bq24261_driver = {
+	.driver = {
+		   .name = DEV_NAME,
+		   .pm = &bq24261_pm_ops,
+		   },
+	.probe = bq24261_probe,
+	.remove = bq24261_remove,
+	.id_table = bq24261_id,
+};
+
+static int __init bq24261_init(void)
+{
+	return i2c_add_driver(&bq24261_driver);
+}
+
+module_init(bq24261_init);
+
+static void __exit bq24261_exit(void)
+{
+	i2c_del_driver(&bq24261_driver);
+}
+
+module_exit(bq24261_exit);
+
+MODULE_AUTHOR("Jenny TC <jenny.tc@intel.com>");
+MODULE_DESCRIPTION("BQ24261 Charger Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/power/pmic_ccsm.c b/drivers/power/pmic_ccsm.c
new file mode 100644
index 0000000..eb34ddc
--- /dev/null
+++ b/drivers/power/pmic_ccsm.c
@@ -0,0 +1,2001 @@
+/*
+ * pmic_ccsm.c - Intel MID PMIC Charger Driver
+ *
+ * Copyright (C) 2011 Intel Corporation
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ * Author: Jenny TC <jenny.tc@intel.com>
+ * Author: Yegnesh Iyer <yegnesh.s.iyer@intel.com>
+ */
+
+/* Includes */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/err.h>
+#include <linux/interrupt.h>
+#include <linux/workqueue.h>
+#include <linux/jiffies.h>
+#include <linux/seq_file.h>
+#include <linux/debugfs.h>
+#include <linux/slab.h>
+#include <linux/kfifo.h>
+#include <linux/param.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/usb/otg.h>
+#include <linux/power_supply.h>
+#include <linux/power_supply.h>
+#include <linux/rpmsg.h>
+#include <linux/version.h>
+#include <asm/intel_basincove_gpadc.h>
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 10, 0))
+#include <linux/iio/consumer.h>
+#else
+#include "../../../kernel/drivers/staging/iio/consumer.h"
+#endif
+#include <asm/intel_scu_pmic.h>
+#include <asm/intel_mid_rpmsg.h>
+#include <asm/intel_mid_remoteproc.h>
+#include <linux/io.h>
+#include <linux/sched.h>
+#include <linux/pm_runtime.h>
+#include <linux/sfi.h>
+#include <linux/async.h>
+#include <linux/reboot.h>
+#include <linux/notifier.h>
+#include <linux/power/battery_id.h>
+#include "pmic_ccsm.h"
+
+/* Macros */
+#define DRIVER_NAME "pmic_ccsm"
+#define PMIC_SRAM_INTR_ADDR 0xFFFFF616
+#define ADC_TO_TEMP 1
+#define TEMP_TO_ADC 0
+#define is_valid_temp(tmp)\
+	(!(tmp > chc.pdata->adc_tbl[0].temp ||\
+	tmp < chc.pdata->adc_tbl[chc.pdata->max_tbl_row_cnt - 1].temp))
+#define is_valid_adc_code(val)\
+	(!(val < chc.pdata->adc_tbl[0].adc_val ||\
+	val > chc.pdata->adc_tbl[chc.pdata->max_tbl_row_cnt - 1].adc_val))
+#define CONVERT_ADC_TO_TEMP(adc_val, temp)\
+	adc_temp_conv(adc_val, temp, ADC_TO_TEMP)
+#define CONVERT_TEMP_TO_ADC(temp, adc_val)\
+	adc_temp_conv(temp, adc_val, TEMP_TO_ADC)
+#define NEED_ZONE_SPLIT(bprof)\
+	 ((bprof->temp_mon_ranges < MIN_BATT_PROF))
+
+#define USB_WAKE_LOCK_TIMEOUT	(5 * HZ)
+
+/* 100mA value definition for setting the inlimit in bq24261 */
+#define USBINPUTICC100VAL	100
+
+/* Type definitions */
+static void pmic_bat_zone_changed(void);
+static void pmic_battery_overheat_handler(bool);
+
+/* Extern definitions */
+
+/* Global declarations */
+static DEFINE_MUTEX(pmic_lock);
+static struct pmic_chrgr_drv_context chc;
+static struct interrupt_info chgrirq0_info[] = {
+	{
+		CHGIRQ0_BZIRQ_MASK,
+		0,
+		"Battery temperature zone changed",
+		NULL,
+		NULL,
+		pmic_bat_zone_changed,
+		NULL,
+	},
+	{
+		CHGIRQ0_BAT_CRIT_MASK,
+		SCHGIRQ0_SBAT_CRIT_MASK,
+		NULL,
+		"Battery Over heat exception",
+		"Battery Over heat exception Recovered",
+		NULL,
+		pmic_battery_overheat_handler
+	},
+	{
+		CHGIRQ0_BAT0_ALRT_MASK,
+		SCHGIRQ0_SBAT0_ALRT_MASK,
+		NULL,
+		"Battery0 temperature inside boundary",
+		"Battery0 temperature outside boundary",
+		NULL,
+		pmic_battery_overheat_handler
+	},
+	{
+		CHGIRQ0_BAT1_ALRT_MASK,
+		SCHGIRQ0_SBAT1_ALRT_MASK,
+		NULL,
+		"Battery1 temperature inside boundary",
+		"Battery1 temperature outside boundary",
+		NULL,
+		NULL
+	},
+};
+
+u16 pmic_inlmt[][2] = {
+	{ 100, CHGRCTRL1_FUSB_INLMT_100},
+	{ 150, CHGRCTRL1_FUSB_INLMT_150},
+	{ 500, CHGRCTRL1_FUSB_INLMT_500},
+	{ 900, CHGRCTRL1_FUSB_INLMT_900},
+	{ 1500, CHGRCTRL1_FUSB_INLMT_1500},
+};
+
+static inline struct power_supply *get_psy_battery(void)
+{
+	struct class_dev_iter iter;
+	struct device *dev;
+	struct power_supply *pst;
+
+	class_dev_iter_init(&iter, power_supply_class, NULL, NULL);
+	while ((dev = class_dev_iter_next(&iter))) {
+		pst = (struct power_supply *)dev_get_drvdata(dev);
+		if (pst->type == POWER_SUPPLY_TYPE_BATTERY) {
+			class_dev_iter_exit(&iter);
+			return pst;
+		}
+	}
+	class_dev_iter_exit(&iter);
+
+	return NULL;
+}
+
+
+/* Function definitions */
+static void lookup_regval(u16 tbl[][2], size_t size, u16 in_val, u8 *out_val)
+{
+	int i;
+	for (i = 1; i < size; ++i)
+		if (in_val < tbl[i][0])
+			break;
+
+	*out_val = (u8)tbl[i-1][1];
+}
+
+static int interpolate_y(int dx1x0, int dy1y0, int dxx0, int y0)
+{
+	return y0 + DIV_ROUND_CLOSEST((dxx0 * dy1y0), dx1x0);
+}
+
+static int interpolate_x(int dy1y0, int dx1x0, int dyy0, int x0)
+{
+	return x0 + DIV_ROUND_CLOSEST((dyy0 * dx1x0), dy1y0);
+}
+
+static int adc_temp_conv(int in_val, int *out_val, int conv)
+{
+	int tbl_row_cnt, i;
+	struct temp_lookup *adc_temp_tbl;
+
+	if (!chc.pdata) {
+		dev_err(chc.dev, "ADC-lookup table not yet available\n");
+		return -ERANGE;
+	}
+
+	tbl_row_cnt = chc.pdata->max_tbl_row_cnt;
+	adc_temp_tbl = chc.pdata->adc_tbl;
+
+	if (conv == ADC_TO_TEMP) {
+		if (!is_valid_adc_code(in_val))
+			return -ERANGE;
+
+		if (in_val == adc_temp_tbl[tbl_row_cnt-1].adc_val)
+			i = tbl_row_cnt - 1;
+		else {
+			for (i = 0; i < tbl_row_cnt; ++i)
+				if (in_val < adc_temp_tbl[i].adc_val)
+					break;
+		}
+
+		*out_val =
+		    interpolate_y((adc_temp_tbl[i].adc_val
+					- adc_temp_tbl[i - 1].adc_val),
+				  (adc_temp_tbl[i].temp
+				   - adc_temp_tbl[i - 1].temp),
+				  (in_val - adc_temp_tbl[i - 1].adc_val),
+				  adc_temp_tbl[i - 1].temp);
+	} else {
+		if (!is_valid_temp(in_val))
+			return -ERANGE;
+
+		if (in_val == adc_temp_tbl[tbl_row_cnt-1].temp)
+			i = tbl_row_cnt - 1;
+		else {
+			for (i = 0; i < tbl_row_cnt; ++i)
+				if (in_val > adc_temp_tbl[i].temp)
+					break;
+		}
+
+		*((short int *)out_val) =
+		    interpolate_x((adc_temp_tbl[i].temp
+					- adc_temp_tbl[i - 1].temp),
+				  (adc_temp_tbl[i].adc_val
+				   - adc_temp_tbl[i - 1].adc_val),
+				  (in_val - adc_temp_tbl[i - 1].temp),
+				  adc_temp_tbl[i - 1].adc_val);
+	}
+	return 0;
+}
+
+static int pmic_write_reg(u16 addr, u8 *val)
+{
+	int ret;
+
+	ret = intel_scu_ipc_iowrite8(addr, val);
+	if (ret) {
+		dev_err(chc.dev,
+			"Error in intel_scu_ipc_ioread8 0x%.4x\n", addr);
+		return -EIO;
+	}
+	return 0;
+}
+
+static int pmic_read_reg(u16 addr, u8 *val)
+{
+	int ret;
+
+	ret = intel_scu_ipc_ioread8(addr, val);
+	if (ret) {
+		dev_err(chc.dev,
+			"Error in intel_scu_ipc_ioread8 0x%.4x\n", addr);
+		return -EIO;
+	}
+	return 0;
+}
+
+
+static int __pmic_write_tt(u8 addr, u8 data)
+{
+	int ret;
+
+	ret = intel_scu_ipc_iowrite8(CHRTTADDR_ADDR, addr);
+	if (unlikely(ret))
+		return ret;
+
+	return intel_scu_ipc_iowrite8(CHRTTDATA_ADDR, data);
+}
+
+static inline int pmic_write_tt(u8 addr, u8 data)
+{
+	int ret;
+
+	mutex_lock(&pmic_lock);
+	ret = __pmic_write_tt(addr, data);
+	mutex_unlock(&pmic_lock);
+
+	/* If access is blocked return success to avoid additional
+	*  error handling at client side
+	*/
+	if (ret == -EACCES) {
+		dev_warn(chc.dev, "IPC write blocked due to unsigned kernel/invalid battery\n");
+		ret = 0;
+	}
+	return ret;
+}
+
+static int __pmic_read_tt(u8 addr, u8 *data)
+{
+	int ret;
+
+	ret = intel_scu_ipc_iowrite8(CHRTTADDR_ADDR, addr);
+	if (ret)
+		return ret;
+
+	usleep_range(2000, 3000);
+
+	return intel_scu_ipc_ioread8(CHRTTDATA_ADDR, data);
+}
+
+static inline int pmic_read_tt(u8 addr, u8 *data)
+{
+	int ret;
+
+	mutex_lock(&pmic_lock);
+	ret = __pmic_read_tt(addr, data);
+	mutex_unlock(&pmic_lock);
+
+	return ret;
+}
+
+static int pmic_update_tt(u8 addr, u8 mask, u8 data)
+{
+	u8 tdata;
+	int ret;
+
+	mutex_lock(&pmic_lock);
+	ret = __pmic_read_tt(addr, &tdata);
+	if (unlikely(ret))
+		goto exit;
+
+	tdata = (tdata & ~mask) | (data & mask);
+	ret = __pmic_write_tt(addr, tdata);
+exit:
+	mutex_unlock(&pmic_lock);
+	return ret;
+}
+
+#ifdef CONFIG_DEBUG_FS
+static int pmic_chrgr_reg_show(struct seq_file *seq, void *unused)
+{
+	int ret;
+	u16 addr;
+	u16 val1;
+	u8 val;
+
+	addr = *((u8 *)seq->private);
+
+	if (addr == CHRGRIRQ1_ADDR) {
+		val1 = ioread16(chc.pmic_intr_iomap);
+		val = (u8)(val1 >> 8);
+	} else if (addr == CHGRIRQ0_ADDR) {
+		val1 = ioread16(chc.pmic_intr_iomap);
+		val = (u8)val1;
+	} else {
+		ret = pmic_read_reg(addr, &val);
+		if (ret != 0) {
+			dev_err(chc.dev,
+				"Error reading tt register 0x%2x\n",
+				addr);
+			return -EIO;
+		}
+	}
+
+	seq_printf(seq, "0x%x\n", val);
+	return 0;
+}
+
+static int pmic_chrgr_tt_reg_show(struct seq_file *seq, void *unused)
+{
+	int ret;
+	u8 addr;
+	u8 val;
+
+	addr = *((u8 *)seq->private);
+
+	ret = pmic_read_tt(addr, &val);
+	if (ret != 0) {
+		dev_err(chc.dev,
+			"Error reading tt register 0x%2x\n",
+			addr);
+		return -EIO;
+	}
+
+	seq_printf(seq, "0x%x\n", val);
+	return 0;
+}
+
+static int pmic_chrgr_tt_reg_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, pmic_chrgr_tt_reg_show, inode->i_private);
+}
+
+static int pmic_chrgr_reg_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, pmic_chrgr_reg_show, inode->i_private);
+}
+
+static struct dentry *charger_debug_dir;
+static struct pmic_regs_def pmic_regs_bc[] = {
+	PMIC_REG_DEF(PMIC_ID_ADDR),
+	PMIC_REG_DEF(IRQLVL1_ADDR),
+	PMIC_REG_DEF(IRQLVL1_MASK_ADDR),
+	PMIC_REG_DEF(CHGRIRQ0_ADDR),
+	PMIC_REG_DEF(SCHGRIRQ0_ADDR),
+	PMIC_REG_DEF(MCHGRIRQ0_ADDR),
+	PMIC_REG_DEF(LOWBATTDET0_ADDR),
+	PMIC_REG_DEF(LOWBATTDET1_ADDR),
+	PMIC_REG_DEF(BATTDETCTRL_ADDR),
+	PMIC_REG_DEF(VBUSDETCTRL_ADDR),
+	PMIC_REG_DEF(VDCINDETCTRL_ADDR),
+	PMIC_REG_DEF(CHRGRIRQ1_ADDR),
+	PMIC_REG_DEF(SCHGRIRQ1_ADDR),
+	PMIC_REG_DEF(MCHGRIRQ1_ADDR),
+	PMIC_REG_DEF(CHGRCTRL0_ADDR),
+	PMIC_REG_DEF(CHGRCTRL1_ADDR),
+	PMIC_REG_DEF(CHGRSTATUS_ADDR),
+	PMIC_REG_DEF(USBIDCTRL_ADDR),
+	PMIC_REG_DEF(USBIDSTAT_ADDR),
+	PMIC_REG_DEF(WAKESRC_ADDR),
+	PMIC_REG_DEF(THRMBATZONE_ADDR_BC),
+	PMIC_REG_DEF(THRMZN0L_ADDR_BC),
+	PMIC_REG_DEF(THRMZN0H_ADDR_BC),
+	PMIC_REG_DEF(THRMZN1L_ADDR_BC),
+	PMIC_REG_DEF(THRMZN1H_ADDR_BC),
+	PMIC_REG_DEF(THRMZN2L_ADDR_BC),
+	PMIC_REG_DEF(THRMZN2H_ADDR_BC),
+	PMIC_REG_DEF(THRMZN3L_ADDR_BC),
+	PMIC_REG_DEF(THRMZN3H_ADDR_BC),
+	PMIC_REG_DEF(THRMZN4L_ADDR_BC),
+	PMIC_REG_DEF(THRMZN4H_ADDR_BC),
+	PMIC_REG_DEF(VBATRSLTH_ADDR_BC),
+	PMIC_REG_DEF(VBATRSLTL_ADDR_BC),
+};
+
+static struct pmic_regs_def pmic_regs_sc[] = {
+	PMIC_REG_DEF(PMIC_ID_ADDR),
+	PMIC_REG_DEF(IRQLVL1_ADDR),
+	PMIC_REG_DEF(IRQLVL1_MASK_ADDR),
+	PMIC_REG_DEF(CHGRIRQ0_ADDR),
+	PMIC_REG_DEF(SCHGRIRQ0_ADDR),
+	PMIC_REG_DEF(MCHGRIRQ0_ADDR),
+	PMIC_REG_DEF(LOWBATTDET0_ADDR),
+	PMIC_REG_DEF(LOWBATTDET1_ADDR),
+	PMIC_REG_DEF(BATTDETCTRL_ADDR),
+	PMIC_REG_DEF(VBUSDETCTRL_ADDR),
+	PMIC_REG_DEF(VDCINDETCTRL_ADDR),
+	PMIC_REG_DEF(CHRGRIRQ1_ADDR),
+	PMIC_REG_DEF(SCHGRIRQ1_ADDR),
+	PMIC_REG_DEF(MCHGRIRQ1_ADDR),
+	PMIC_REG_DEF(CHGRCTRL0_ADDR),
+	PMIC_REG_DEF(CHGRCTRL1_ADDR),
+	PMIC_REG_DEF(CHGRSTATUS_ADDR),
+	PMIC_REG_DEF(USBIDCTRL_ADDR),
+	PMIC_REG_DEF(USBIDSTAT_ADDR),
+	PMIC_REG_DEF(WAKESRC_ADDR),
+	PMIC_REG_DEF(USBPATH_ADDR),
+	PMIC_REG_DEF(USBSRCDETSTATUS_ADDR),
+	PMIC_REG_DEF(THRMBATZONE_ADDR_SC),
+	PMIC_REG_DEF(THRMZN0L_ADDR_SC),
+	PMIC_REG_DEF(THRMZN0H_ADDR_SC),
+	PMIC_REG_DEF(THRMZN1L_ADDR_SC),
+	PMIC_REG_DEF(THRMZN1H_ADDR_SC),
+	PMIC_REG_DEF(THRMZN2L_ADDR_SC),
+	PMIC_REG_DEF(THRMZN2H_ADDR_SC),
+	PMIC_REG_DEF(THRMZN3L_ADDR_SC),
+	PMIC_REG_DEF(THRMZN3H_ADDR_SC),
+	PMIC_REG_DEF(THRMZN4L_ADDR_SC),
+	PMIC_REG_DEF(THRMZN4H_ADDR_SC),
+};
+
+static struct pmic_regs_def pmic_tt_regs[] = {
+	PMIC_REG_DEF(TT_I2CDADDR_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT0OS_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT1OS_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT2OS_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT3OS_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT4OS_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT5OS_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT6OS_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT7OS_ADDR),
+	PMIC_REG_DEF(TT_USBINPUTICCOS_ADDR),
+	PMIC_REG_DEF(TT_USBINPUTICCMASK_ADDR),
+	PMIC_REG_DEF(TT_CHRCVOS_ADDR),
+	PMIC_REG_DEF(TT_CHRCVMASK_ADDR),
+	PMIC_REG_DEF(TT_CHRCCOS_ADDR),
+	PMIC_REG_DEF(TT_CHRCCMASK_ADDR),
+	PMIC_REG_DEF(TT_LOWCHROS_ADDR),
+	PMIC_REG_DEF(TT_LOWCHRMASK_ADDR),
+	PMIC_REG_DEF(TT_WDOGRSTOS_ADDR),
+	PMIC_REG_DEF(TT_WDOGRSTMASK_ADDR),
+	PMIC_REG_DEF(TT_CHGRENOS_ADDR),
+	PMIC_REG_DEF(TT_CHGRENMASK_ADDR),
+	PMIC_REG_DEF(TT_CUSTOMFIELDEN_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT0VAL_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT1VAL_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT2VAL_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT3VAL_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT4VAL_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT5VAL_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT6VAL_ADDR),
+	PMIC_REG_DEF(TT_CHGRINIT7VAL_ADDR),
+	PMIC_REG_DEF(TT_USBINPUTICC100VAL_ADDR),
+	PMIC_REG_DEF(TT_USBINPUTICC150VAL_ADDR),
+	PMIC_REG_DEF(TT_USBINPUTICC500VAL_ADDR),
+	PMIC_REG_DEF(TT_USBINPUTICC900VAL_ADDR),
+	PMIC_REG_DEF(TT_USBINPUTICC1500VAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCVEMRGLOWVAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCVCOLDVAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCVCOOLVAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCVWARMVAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCVHOTVAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCVEMRGHIVAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCCEMRGLOWVAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCCCOLDVAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCCCOOLVAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCCWARMVAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCCHOTVAL_ADDR),
+	PMIC_REG_DEF(TT_CHRCCEMRGHIVAL_ADDR),
+	PMIC_REG_DEF(TT_LOWCHRENVAL_ADDR),
+	PMIC_REG_DEF(TT_LOWCHRDISVAL_ADDR),
+};
+
+void dump_pmic_regs(void)
+{
+	int vendor_id = chc.pmic_id & PMIC_VENDOR_ID_MASK;
+	u32 pmic_reg_cnt = 0;
+	u32 reg_index;
+	u8 data;
+	int retval;
+	struct pmic_regs_def *pmic_regs = NULL;
+
+	if (vendor_id == BASINCOVE_VENDORID) {
+		pmic_reg_cnt = ARRAY_SIZE(pmic_regs_bc);
+		pmic_regs = pmic_regs_bc;
+	} else if (vendor_id == SHADYCOVE_VENDORID) {
+		pmic_reg_cnt = ARRAY_SIZE(pmic_regs_sc);
+		pmic_regs = pmic_regs_sc;
+	}
+
+	dev_info(chc.dev, "PMIC Register dump\n");
+	dev_info(chc.dev, "====================\n");
+
+	for (reg_index = 0; reg_index < pmic_reg_cnt; reg_index++) {
+
+		retval = intel_scu_ipc_ioread8(pmic_regs[reg_index].addr,
+				&data);
+		if (retval)
+			dev_err(chc.dev, "Error in reading %x\n",
+				pmic_regs[reg_index].addr);
+		else
+			dev_info(chc.dev, "0x%x=0x%x\n",
+				pmic_regs[reg_index].addr, data);
+	}
+	dev_info(chc.dev, "====================\n");
+}
+
+void dump_pmic_tt_regs(void)
+{
+	u32 pmic_tt_reg_cnt = ARRAY_SIZE(pmic_tt_regs);
+	u32 reg_index;
+	u8 data;
+	int retval;
+
+	dev_info(chc.dev, "PMIC CHRGR TT dump\n");
+	dev_info(chc.dev, "====================\n");
+
+	for (reg_index = 0; reg_index < pmic_tt_reg_cnt; reg_index++) {
+
+		retval = pmic_read_tt(pmic_tt_regs[reg_index].addr, &data);
+		if (retval)
+			dev_err(chc.dev, "Error in reading %x\n",
+				pmic_tt_regs[reg_index].addr);
+		else
+			dev_info(chc.dev, "0x%x=0x%x\n",
+				pmic_tt_regs[reg_index].addr, data);
+	}
+
+	dev_info(chc.dev, "====================\n");
+}
+static const struct file_operations pmic_chrgr_reg_fops = {
+	.open = pmic_chrgr_reg_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release
+};
+
+static const struct file_operations pmic_chrgr_tt_reg_fops = {
+	.open = pmic_chrgr_tt_reg_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release
+};
+
+static void pmic_debugfs_init(void)
+{
+	struct dentry *fentry;
+	struct dentry *pmic_regs_dir;
+	struct dentry *pmic_tt_regs_dir;
+
+	u32 reg_index;
+	int vendor_id = chc.pmic_id & PMIC_VENDOR_ID_MASK;
+	u32 pmic_reg_cnt = 0;
+	u32 pmic_tt_reg_cnt = ARRAY_SIZE(pmic_tt_regs);
+	char name[PMIC_REG_NAME_LEN] = {0};
+	struct pmic_regs_def *pmic_regs = NULL;
+
+	if (vendor_id == BASINCOVE_VENDORID) {
+		pmic_reg_cnt = ARRAY_SIZE(pmic_regs_bc);
+		pmic_regs = pmic_regs_bc;
+	} else if (vendor_id == SHADYCOVE_VENDORID) {
+		pmic_reg_cnt = ARRAY_SIZE(pmic_regs_sc);
+		pmic_regs = pmic_regs_sc;
+	}
+
+	/* Creating a directory under debug fs for charger */
+	charger_debug_dir = debugfs_create_dir(DRIVER_NAME , NULL) ;
+	if (charger_debug_dir == NULL)
+		goto debugfs_root_exit;
+
+	/* Create a directory for pmic charger registers */
+	pmic_regs_dir = debugfs_create_dir("pmic_ccsm_regs",
+			charger_debug_dir);
+
+	if (pmic_regs_dir == NULL)
+		goto debugfs_err_exit;
+
+	for (reg_index = 0; reg_index < pmic_reg_cnt; reg_index++) {
+
+		sprintf(name, "%s",
+			pmic_regs[reg_index].reg_name);
+
+		fentry = debugfs_create_file(name,
+				S_IRUGO,
+				pmic_regs_dir,
+				&pmic_regs[reg_index].addr,
+				&pmic_chrgr_reg_fops);
+
+		if (fentry == NULL)
+			goto debugfs_err_exit;
+	}
+
+	/* Create a directory for pmic tt charger registers */
+	pmic_tt_regs_dir = debugfs_create_dir("pmic_ccsm_tt_regs",
+			charger_debug_dir);
+
+	if (pmic_tt_regs_dir == NULL)
+		goto debugfs_err_exit;
+
+	for (reg_index = 0; reg_index < pmic_tt_reg_cnt; reg_index++) {
+
+		sprintf(name, "%s", pmic_tt_regs[reg_index].reg_name);
+
+		fentry = debugfs_create_file(name,
+				S_IRUGO,
+				pmic_tt_regs_dir,
+				&pmic_tt_regs[reg_index].addr,
+				&pmic_chrgr_tt_reg_fops);
+
+		if (fentry == NULL)
+			goto debugfs_err_exit;
+	}
+
+	dev_dbg(chc.dev, "Debugfs created successfully!!");
+	return;
+
+debugfs_err_exit:
+	debugfs_remove_recursive(charger_debug_dir);
+debugfs_root_exit:
+	dev_err(chc.dev, "Error creating debugfs entry!!");
+	return;
+}
+
+static void pmic_debugfs_exit(void)
+{
+	if (charger_debug_dir != NULL)
+		debugfs_remove_recursive(charger_debug_dir);
+}
+#endif
+
+static void pmic_bat_zone_changed(void)
+{
+	int retval;
+	int cur_zone;
+	u16 addr = 0;
+	u8 data = 0;
+	struct power_supply *psy_bat;
+	int vendor_id;
+
+	vendor_id = chc.pmic_id & PMIC_VENDOR_ID_MASK;
+	if (vendor_id == BASINCOVE_VENDORID)
+		addr = THRMBATZONE_ADDR_BC;
+	else if (vendor_id == SHADYCOVE_VENDORID)
+		addr = THRMBATZONE_ADDR_SC;
+
+	retval = intel_scu_ipc_ioread8(addr, &data);
+	if (retval) {
+		dev_err(chc.dev, "Error in reading battery zone\n");
+		return;
+	}
+
+	cur_zone = data & THRMBATZONE_MASK;
+	dev_info(chc.dev, "Battery Zone changed. Current zone is %d\n",
+			(data & THRMBATZONE_MASK));
+
+	/* if current zone is the top and bottom zones then report OVERHEAT
+	 */
+	if ((cur_zone == PMIC_BZONE_LOW) || (cur_zone == PMIC_BZONE_HIGH))
+		chc.health = POWER_SUPPLY_HEALTH_OVERHEAT;
+	else
+		chc.health = POWER_SUPPLY_HEALTH_GOOD;
+
+	psy_bat = get_psy_battery();
+
+	if (psy_bat && psy_bat->external_power_changed)
+		psy_bat->external_power_changed(psy_bat);
+
+	return;
+}
+
+static void pmic_battery_overheat_handler(bool stat)
+{
+	if (stat)
+		chc.health = POWER_SUPPLY_HEALTH_OVERHEAT;
+	else
+		chc.health = POWER_SUPPLY_HEALTH_GOOD;
+	return;
+}
+
+int pmic_get_health(void)
+{
+	return chc.health;
+}
+
+int pmic_enable_vbus(bool enable)
+{
+	int ret;
+	int vendor_id;
+
+	vendor_id = chc.pmic_id & PMIC_VENDOR_ID_MASK;
+
+	if (enable) {
+		ret = intel_scu_ipc_update_register(CHGRCTRL0_ADDR,
+				WDT_NOKICK_ENABLE, CHGRCTRL0_WDT_NOKICK_MASK);
+		if (ret)
+			return ret;
+
+		if (vendor_id == SHADYCOVE_VENDORID)
+			ret = intel_scu_ipc_update_register(CHGRCTRL1_ADDR,
+					CHGRCTRL1_OTGMODE_MASK,
+					CHGRCTRL1_OTGMODE_MASK);
+	} else {
+		ret = intel_scu_ipc_update_register(CHGRCTRL0_ADDR,
+				WDT_NOKICK_DISABLE, CHGRCTRL0_WDT_NOKICK_MASK);
+		if (ret)
+			return ret;
+
+		if (vendor_id == SHADYCOVE_VENDORID)
+			ret = intel_scu_ipc_update_register(CHGRCTRL1_ADDR,
+					0x0, CHGRCTRL1_OTGMODE_MASK);
+	}
+
+	/* If access is blocked return success to avoid additional
+	*  error handling at client side
+	*/
+	if (ret == -EACCES) {
+		dev_warn(chc.dev, "IPC blocked due to unsigned kernel/invalid battery\n");
+		ret = 0;
+	}
+
+	return ret;
+}
+
+int pmic_enable_charging(bool enable)
+{
+	int ret;
+	u8 val;
+
+	if (enable) {
+		ret = intel_scu_ipc_update_register(CHGRCTRL1_ADDR,
+			CHGRCTRL1_FTEMP_EVENT_MASK, CHGRCTRL1_FTEMP_EVENT_MASK);
+		if (ret)
+			return ret;
+	}
+
+	val = (enable) ? 0 : EXTCHRDIS_ENABLE;
+
+	ret = intel_scu_ipc_update_register(CHGRCTRL0_ADDR,
+			val, CHGRCTRL0_EXTCHRDIS_MASK);
+	/* If access is blocked return success to avoid additional
+	*  error handling at client side
+	*/
+	if (ret == -EACCES) {
+		dev_warn(chc.dev, "IPC blocked due to unsigned kernel/invalid battery\n");
+		ret = 0;
+	}
+
+	return ret;
+}
+
+static inline int update_zone_cc(int zone, u8 reg_val)
+{
+	u8 addr_cc = TT_CHRCCHOTVAL_ADDR - zone;
+	dev_dbg(chc.dev, "%s:%X=%X\n", __func__, addr_cc, reg_val);
+	return pmic_write_tt(addr_cc, reg_val);
+}
+
+static inline int update_zone_cv(int zone, u8 reg_val)
+{
+	u8 addr_cv = TT_CHRCVHOTVAL_ADDR - zone;
+	dev_dbg(chc.dev, "%s:%X=%X\n", __func__, addr_cv, reg_val);
+	return pmic_write_tt(addr_cv, reg_val);
+}
+
+static inline int update_zone_temp(int zone, u16 adc_val)
+{
+	int ret;
+	u16 addr_tzone;
+	int vendor_id = chc.pmic_id & PMIC_VENDOR_ID_MASK;
+
+	if (vendor_id == BASINCOVE_VENDORID)
+		addr_tzone = THRMZN4H_ADDR_BC - (2 * zone);
+	else if (vendor_id == SHADYCOVE_VENDORID) {
+		/* to take care of address-discontinuity of zone-registers */
+		int offset_zone = zone;
+		if (zone >= 3)
+			offset_zone += 1;
+
+		addr_tzone = THRMZN4H_ADDR_SC - (2 * offset_zone);
+	} else {
+		dev_err(chc.dev, "%s: invalid vendor id %X\n", __func__, vendor_id);
+		return -EINVAL;
+	}
+
+	ret = intel_scu_ipc_iowrite8(addr_tzone, (u8)(adc_val >> 8));
+	if (unlikely(ret))
+		return ret;
+	dev_dbg(chc.dev, "%s:%X:%X=%X\n", __func__, addr_tzone,
+				(addr_tzone+1), adc_val);
+
+	return intel_scu_ipc_iowrite8(addr_tzone+1, (u8)(adc_val & 0xFF));
+}
+
+int pmic_set_cc(int new_cc)
+{
+	struct ps_pse_mod_prof *bcprof = chc.actual_bcprof;
+	struct ps_pse_mod_prof *r_bcprof = chc.runtime_bcprof;
+	int temp_mon_ranges;
+	int new_cc1;
+	int ret;
+	int i;
+	u8 reg_val = 0;
+
+	/* No need to write PMIC if CC = 0 */
+	if (!new_cc)
+		return 0;
+
+	temp_mon_ranges = min_t(u16, bcprof->temp_mon_ranges,
+			BATT_TEMP_NR_RNG);
+
+	for (i = 0; i < temp_mon_ranges; ++i) {
+		new_cc1 = min_t(int, new_cc,
+				bcprof->temp_mon_range[i].full_chrg_cur);
+
+		if (new_cc1 != r_bcprof->temp_mon_range[i].full_chrg_cur) {
+			if (chc.pdata->cc_to_reg) {
+				chc.pdata->cc_to_reg(new_cc1, &reg_val);
+				ret = update_zone_cc(i, reg_val);
+				if (unlikely(ret))
+					return ret;
+			}
+			r_bcprof->temp_mon_range[i].full_chrg_cur = new_cc1;
+		}
+	}
+
+	/* send the new CC and CV */
+	intel_scu_ipc_update_register(CHGRCTRL1_ADDR,
+		CHGRCTRL1_FTEMP_EVENT_MASK, CHGRCTRL1_FTEMP_EVENT_MASK);
+
+	return 0;
+}
+
+int pmic_set_cv(int new_cv)
+{
+	struct ps_pse_mod_prof *bcprof = chc.actual_bcprof;
+	struct ps_pse_mod_prof *r_bcprof = chc.runtime_bcprof;
+	int temp_mon_ranges;
+	int new_cv1;
+	int ret;
+	int i;
+	u8 reg_val = 0;
+
+	/* No need to write PMIC if CV = 0 */
+	if (!new_cv)
+		return 0;
+
+	temp_mon_ranges = min_t(u16, bcprof->temp_mon_ranges,
+			BATT_TEMP_NR_RNG);
+
+	for (i = 0; i < temp_mon_ranges; ++i) {
+		new_cv1 = min_t(int, new_cv,
+				bcprof->temp_mon_range[i].full_chrg_vol);
+
+		if (new_cv1 != r_bcprof->temp_mon_range[i].full_chrg_vol) {
+			if (chc.pdata->cv_to_reg) {
+				chc.pdata->cv_to_reg(new_cv1, &reg_val);
+				ret = update_zone_cv(i, reg_val);
+				if (unlikely(ret))
+					return ret;
+			}
+			r_bcprof->temp_mon_range[i].full_chrg_vol = new_cv1;
+		}
+	}
+
+	/* send the new CC and CV */
+	intel_scu_ipc_update_register(CHGRCTRL1_ADDR,
+		CHGRCTRL1_FTEMP_EVENT_MASK, CHGRCTRL1_FTEMP_EVENT_MASK);
+
+	return 0;
+}
+
+int pmic_set_ilimma(int ilim_ma)
+{
+	u8 reg_val;
+	int ret;
+
+	lookup_regval(pmic_inlmt, ARRAY_SIZE(pmic_inlmt),
+			ilim_ma, &reg_val);
+	dev_dbg(chc.dev, "Setting inlmt %d in register %x=%x\n", ilim_ma,
+		CHGRCTRL1_ADDR, reg_val);
+	ret = intel_scu_ipc_iowrite8(CHGRCTRL1_ADDR, reg_val);
+
+	/* If access is blocked return success to avoid additional
+	*  error handling at client side
+	*/
+	if (ret == -EACCES) {
+		dev_warn(chc.dev, "IPC blocked due to unsigned kernel/invalid battery\n");
+		ret = 0;
+	}
+
+	return ret;
+}
+
+/**
+ * pmic_read_adc_val - read ADC value of specified sensors
+ * @channel: channel of the sensor to be sampled
+ * @sensor_val: pointer to the charger property to hold sampled value
+ * @chc :  battery info pointer
+ *
+ * Returns 0 if success
+ */
+static int pmic_read_adc_val(int channel, int *sensor_val,
+			      struct pmic_chrgr_drv_context *chc)
+{
+	int val;
+	int ret;
+	struct iio_channel *indio_chan;
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 10, 0))
+	indio_chan = iio_st_channel_get("BATTEMP", "BATTEMP0");
+#else
+	indio_chan = iio_channel_get(NULL, "BATTEMP0");
+#endif
+	if (IS_ERR_OR_NULL(indio_chan)) {
+		ret = PTR_ERR(indio_chan);
+		goto exit;
+	}
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 10, 0))
+	ret = iio_st_read_channel_raw(indio_chan, &val);
+#else
+	ret = iio_read_channel_raw(indio_chan, &val);
+#endif
+	if (ret) {
+		dev_err(chc->dev, "IIO channel read error\n");
+		goto err_exit;
+	}
+
+	switch (channel) {
+	case GPADC_BATTEMP0:
+		ret = CONVERT_ADC_TO_TEMP(val, sensor_val);
+		break;
+	default:
+		dev_err(chc->dev, "invalid sensor%d", channel);
+		ret = -EINVAL;
+	}
+	dev_dbg(chc->dev, "pmic_ccsm pmic_ccsm.0: %s adc val=%x, %d temp=%d\n",
+		__func__, val, val, *sensor_val);
+
+err_exit:
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 10, 0))
+	iio_st_channel_release(indio_chan);
+#else
+	iio_channel_release(indio_chan);
+#endif
+exit:
+	return ret;
+}
+
+int pmic_get_battery_pack_temp(int *temp)
+{
+	if (chc.invalid_batt)
+		return -ENODEV;
+	return pmic_read_adc_val(GPADC_BATTEMP0, temp, &chc);
+}
+
+int pmic_get_battery_voltage(int *vol)
+{
+	long tmp;
+	int ret;
+	u8 val;
+
+	ret = pmic_write_reg(GPADCREQ_ADDR_BC, GPADCREG_VIBATT_REQ);
+	if (ret != 0) {
+		dev_err(chc.dev,
+			"Error writing GPADCREQ_ADDR_BC-register\n");
+		return -EINVAL;
+	}
+	msleep(200);
+
+	ret = pmic_read_reg(VBATRSLTH_ADDR_BC, &val);
+	if (ret != 0) {
+		dev_err(chc.dev,
+			"Error reading VBATRSLTH_ADDR_BC-register\n");
+		return -EINVAL;
+	}
+	tmp = val * 0x100;
+
+	ret = pmic_read_reg(VBATRSLTL_ADDR_BC, &val);
+	if (ret != 0) {
+		dev_err(chc.dev,
+			"Error reading VBATRSLTL_ADDR_BC-register\n");
+		return -EINVAL;
+	}
+
+	tmp += val;
+	tmp *= GPADC_MAX_VOLTAGE;
+	tmp /= GPADC_MAX_RANGE;
+	*vol = tmp;
+
+	return 0;
+}
+
+static int get_charger_type(void)
+{
+	int ret, i = 0;
+	u8 val;
+	int chgr_type;
+
+	do {
+		ret = pmic_read_reg(USBSRCDETSTATUS_ADDR, &val);
+		if (ret != 0) {
+			dev_err(chc.dev,
+				"Error reading USBSRCDETSTAT-register 0x%2x\n",
+				USBSRCDETSTATUS_ADDR);
+			return 0;
+		}
+
+		i++;
+		dev_info(chc.dev, "Read USBSRCDETSTATUS val: %x\n", val);
+
+		if (val & USBSRCDET_SUSBHWDET_DETSUCC)
+			break;
+		else
+			msleep(USBSRCDET_SLEEP_TIME);
+	} while (i < USBSRCDET_RETRY_CNT);
+
+	if (!(val & USBSRCDET_SUSBHWDET_DETSUCC)) {
+		dev_err(chc.dev, "Charger detection unsuccessful after %dms\n",
+			i * USBSRCDET_SLEEP_TIME);
+		return 0;
+	}
+
+	chgr_type = (val & USBSRCDET_USBSRCRSLT_MASK) >> 2;
+	dev_info(chc.dev, "Charger type after detection complete: %d\n",
+			(val & USBSRCDET_USBSRCRSLT_MASK) >> 2);
+
+	switch (chgr_type) {
+	case PMIC_CHARGER_TYPE_SDP:
+		return POWER_SUPPLY_CHARGER_TYPE_USB_SDP;
+	case PMIC_CHARGER_TYPE_DCP:
+		return POWER_SUPPLY_CHARGER_TYPE_USB_DCP;
+	case PMIC_CHARGER_TYPE_CDP:
+		return POWER_SUPPLY_CHARGER_TYPE_USB_CDP;
+	case PMIC_CHARGER_TYPE_ACA:
+		return POWER_SUPPLY_CHARGER_TYPE_USB_ACA;
+	case PMIC_CHARGER_TYPE_SE1:
+		return POWER_SUPPLY_CHARGER_TYPE_SE1;
+	case PMIC_CHARGER_TYPE_MHL:
+		return POWER_SUPPLY_CHARGER_TYPE_MHL;
+	default:
+		return POWER_SUPPLY_CHARGER_TYPE_NONE;
+	}
+}
+
+static void handle_internal_usbphy_notifications(int mask)
+{
+	struct power_supply_cable_props cap;
+
+	if (mask) {
+		cap.chrg_evt = POWER_SUPPLY_CHARGER_EVENT_CONNECT;
+		cap.chrg_type = get_charger_type();
+		chc.charger_type = cap.chrg_type;
+	} else {
+		cap.chrg_evt = POWER_SUPPLY_CHARGER_EVENT_DISCONNECT;
+		cap.chrg_type = chc.charger_type;
+	}
+
+	if (cap.chrg_type == POWER_SUPPLY_CHARGER_TYPE_USB_SDP)
+		cap.ma = 0;
+	else if ((cap.chrg_type == POWER_SUPPLY_CHARGER_TYPE_USB_DCP)
+			|| (cap.chrg_type == POWER_SUPPLY_TYPE_USB_CDP)
+			|| (cap.chrg_type == POWER_SUPPLY_CHARGER_TYPE_SE1))
+		cap.ma = 1500;
+
+	dev_info(chc.dev, "Notifying OTG ev:%d, evt:%d, chrg_type:%d, mA:%d\n",
+			USB_EVENT_CHARGER, cap.chrg_evt, cap.chrg_type,
+			cap.ma);
+	atomic_notifier_call_chain(&chc.otg->notifier,
+			USB_EVENT_CHARGER, &cap);
+}
+
+/* ShadyCove-WA for VBUS removal detect issue */
+int pmic_handle_low_supply(void)
+{
+	int ret;
+	u8 val;
+	int vendor_id = chc.pmic_id & PMIC_VENDOR_ID_MASK;
+
+	dev_info(chc.dev, "Low-supply event received from external-charger\n");
+	if (vendor_id == BASINCOVE_VENDORID || !chc.vbus_connect_status) {
+		dev_err(chc.dev, "Ignore Low-supply event received\n");
+		return 0;
+	}
+
+	msleep(50);
+	ret = pmic_read_reg(SCHGRIRQ1_ADDR, &val);
+	if (ret) {
+		dev_err(chc.dev,
+			"Error reading SCHGRIRQ1-register 0x%2x\n",
+			SCHGRIRQ1_ADDR);
+		return ret;
+	}
+
+	if (!(val & SCHRGRIRQ1_SVBUSDET_MASK)) {
+		int mask = 0;
+
+		dev_info(chc.dev, "USB VBUS Removed. Notifying OTG driver\n");
+		chc.vbus_connect_status = false;
+
+		if (chc.is_internal_usb_phy)
+			handle_internal_usbphy_notifications(mask);
+		else
+			atomic_notifier_call_chain(&chc.otg->notifier,
+					USB_EVENT_VBUS, &mask);
+	}
+
+	return ret;
+}
+
+static void handle_level0_interrupt(u8 int_reg, u8 stat_reg,
+				struct interrupt_info int_info[],
+				int int_info_size)
+{
+	int i;
+	bool int_stat;
+	char *log_msg;
+
+	for (i = 0; i < int_info_size; ++i) {
+
+		/*continue if interrupt register bit is not set */
+		if (!(int_reg & int_info[i].int_reg_mask))
+			continue;
+
+		/*log message if interrupt bit is set */
+		if (int_info[i].log_msg_int_reg_true)
+			dev_err(chc.dev, "%s",
+					int_info[i].log_msg_int_reg_true);
+
+		/* interrupt bit is set.call int handler. */
+		if (int_info[i].int_handle)
+			int_info[i].int_handle();
+
+		/* continue if stat_reg_mask is zero which
+		 *  means ignore status register
+		 */
+		if (!(int_info[i].stat_reg_mask))
+			continue;
+
+		dev_dbg(chc.dev,
+				"stat_reg=%X int_info[i].stat_reg_mask=%X",
+				stat_reg, int_info[i].stat_reg_mask);
+
+		/* check if the interrupt status is true */
+		int_stat = (stat_reg & int_info[i].stat_reg_mask);
+
+		/* log message */
+		log_msg = int_stat ? int_info[i].log_msg_stat_true :
+			int_info[i].log_msg_stat_false;
+
+		if (log_msg)
+			dev_err(chc.dev, "%s", log_msg);
+
+		/* call status handler function */
+		if (int_info[i].stat_handle)
+			int_info[i].stat_handle(int_stat);
+
+	}
+
+	return ;
+}
+
+static void handle_level1_interrupt(u8 int_reg, u8 stat_reg)
+{
+	int mask;
+	u8 usb_id_sts;
+	int ret;
+
+	if (!int_reg)
+		return;
+
+	mask = !!(int_reg & stat_reg);
+	if (int_reg & CHRGRIRQ1_SUSBIDDET_MASK) {
+		if (mask)
+			dev_info(chc.dev,
+				"USB ID Detected. Notifying OTG driver\n");
+		else
+			dev_info(chc.dev,
+				"USB ID Removed. Notifying OTG driver\n");
+		atomic_notifier_call_chain(&chc.otg->notifier,
+				USB_EVENT_ID, &mask);
+	}
+
+	if (int_reg & CHRGRIRQ1_SVBUSDET_MASK) {
+		if (mask) {
+			dev_info(chc.dev,
+				"USB VBUS Detected. Notifying OTG driver\n");
+			chc.vbus_connect_status = true;
+		} else {
+			dev_info(chc.dev, "USB VBUS Removed. Notifying OTG driver\n");
+			chc.vbus_connect_status = false;
+		}
+
+		if (chc.is_internal_usb_phy)
+			handle_internal_usbphy_notifications(mask);
+		else
+			atomic_notifier_call_chain(&chc.otg->notifier,
+					USB_EVENT_VBUS, &mask);
+	}
+
+	return;
+}
+static void pmic_event_worker(struct work_struct *work)
+{
+	struct pmic_event *evt, *tmp;
+
+	dev_dbg(chc.dev, "%s\n", __func__);
+
+	mutex_lock(&chc.evt_queue_lock);
+	list_for_each_entry_safe(evt, tmp, &chc.evt_queue, node) {
+		list_del(&evt->node);
+
+		dev_dbg(chc.dev, "CHGRIRQ0=%X SCHGRIRQ0=%X CHGRIRQ1=%x SCHGRIRQ1=%X\n",
+				evt->chgrirq0_int, evt->chgrirq0_stat,
+				evt->chgrirq1_int, evt->chgrirq1_stat);
+		if (evt->chgrirq0_int)
+			handle_level0_interrupt(evt->chgrirq0_int,
+				evt->chgrirq0_stat, chgrirq0_info,
+				ARRAY_SIZE(chgrirq0_info));
+
+		if (evt->chgrirq1_stat)
+			handle_level1_interrupt(evt->chgrirq1_int,
+							evt->chgrirq1_stat);
+		kfree(evt);
+	}
+
+	mutex_unlock(&chc.evt_queue_lock);
+}
+
+static irqreturn_t pmic_isr(int irq, void *data)
+{
+	u16 pmic_intr;
+	u8 chgrirq0_int;
+	u8 chgrirq1_int;
+	u8 mask = ((CHRGRIRQ1_SVBUSDET_MASK) | (CHRGRIRQ1_SUSBIDDET_MASK));
+
+	pmic_intr = ioread16(chc.pmic_intr_iomap);
+	chgrirq0_int = (u8)pmic_intr;
+	chgrirq1_int = (u8)(pmic_intr >> 8);
+
+	if (!chgrirq1_int && !(chgrirq0_int & PMIC_CHRGR_INT0_MASK))
+		return IRQ_NONE;
+
+	dev_dbg(chc.dev, "%s", __func__);
+
+	return IRQ_WAKE_THREAD;
+}
+static irqreturn_t pmic_thread_handler(int id, void *data)
+{
+	u16 pmic_intr;
+	struct pmic_event *evt;
+	int ret;
+
+	evt = kzalloc(sizeof(*evt), GFP_ATOMIC);
+	if (evt == NULL) {
+		dev_dbg(chc.dev, "Error allocating evt structure in fn:%s\n",
+			__func__);
+		return IRQ_NONE;
+	}
+
+	pmic_intr = ioread16(chc.pmic_intr_iomap);
+	evt->chgrirq0_int = (u8)pmic_intr;
+	evt->chgrirq1_int = (u8)(pmic_intr >> 8);
+	dev_dbg(chc.dev, "irq0=%x irq1=%x\n",
+		evt->chgrirq0_int, evt->chgrirq1_int);
+
+	/*
+	In case this is an external charger interrupt, we are
+	clearing the level 1 irq register and let external charger
+	driver handle the interrupt.
+	 */
+
+	if (!(evt->chgrirq1_int) &&
+		!(evt->chgrirq0_int & PMIC_CHRGR_CCSM_INT0_MASK)) {
+		intel_scu_ipc_update_register(IRQLVL1_MASK_ADDR, 0x00,
+				IRQLVL1_CHRGR_MASK);
+		if ((chc.invalid_batt) &&
+			(evt->chgrirq0_int & PMIC_CHRGR_EXT_CHRGR_INT_MASK)) {
+			dev_dbg(chc.dev, "Handling external charger interrupt!!\n");
+			kfree(evt);
+			return IRQ_HANDLED;
+		}
+		kfree(evt);
+		dev_dbg(chc.dev, "Unhandled interrupt!!\n");
+		return IRQ_NONE;
+	}
+
+	if (evt->chgrirq0_int & PMIC_CHRGR_CCSM_INT0_MASK) {
+		ret = intel_scu_ipc_ioread8(SCHGRIRQ0_ADDR,
+				&evt->chgrirq0_stat);
+		if (ret) {
+			dev_err(chc.dev,
+				"%s: Error(%d) in intel_scu_ipc_ioread8. Faile to read SCHGRIRQ0_ADDR\n",
+					__func__, ret);
+			kfree(evt);
+			goto end;
+		}
+	}
+	if (evt->chgrirq1_int) {
+		ret = intel_scu_ipc_ioread8(SCHGRIRQ1_ADDR,
+				&evt->chgrirq1_stat);
+		if (ret) {
+			dev_err(chc.dev,
+				"%s: Error(%d) in intel_scu_ipc_ioread8. Faile to read SCHGRIRQ1_ADDR\n",
+					__func__, ret);
+			kfree(evt);
+			goto end;
+		}
+	}
+
+	INIT_LIST_HEAD(&evt->node);
+
+	mutex_lock(&chc.evt_queue_lock);
+	list_add_tail(&evt->node, &chc.evt_queue);
+	mutex_unlock(&chc.evt_queue_lock);
+
+	queue_work(system_nrt_wq, &chc.evt_work);
+
+end:
+	/*clear first level IRQ */
+	dev_dbg(chc.dev, "Clearing IRQLVL1_MASK_ADDR\n");
+	intel_scu_ipc_update_register(IRQLVL1_MASK_ADDR, 0x00,
+			IRQLVL1_CHRGR_MASK);
+
+	return IRQ_HANDLED;
+}
+
+static int pmic_init(void)
+{
+	int ret = 0, i, temp_mon_ranges;
+	u16 adc_val;
+	u8 reg_val;
+	struct ps_pse_mod_prof *bcprof = chc.actual_bcprof;
+
+
+	temp_mon_ranges = min_t(u16, bcprof->temp_mon_ranges,
+			BATT_TEMP_NR_RNG);
+	for (i = 0; i < temp_mon_ranges; ++i) {
+		ret =
+		CONVERT_TEMP_TO_ADC(bcprof->temp_mon_range[i].temp_up_lim,
+				(int *)&adc_val);
+		if (unlikely(ret)) {
+			dev_err(chc.dev,
+				"Error converting temperature for zone %d!!\n",
+				i);
+			return ret;
+		}
+		ret = update_zone_temp(i, adc_val);
+		if (unlikely(ret)) {
+			dev_err(chc.dev,
+				"Error updating zone temp for zone %d\n",
+				i);
+			return ret;
+		}
+
+		if (chc.pdata->cc_to_reg)
+			chc.pdata->cc_to_reg(bcprof->temp_mon_range[i].
+					full_chrg_cur, &reg_val);
+
+		ret = update_zone_cc(i, reg_val);
+		if (unlikely(ret)) {
+			dev_err(chc.dev,
+				"Error updating zone cc for zone %d\n",
+				i);
+			return ret;
+		}
+
+		if (chc.pdata->cv_to_reg)
+			chc.pdata->cv_to_reg(bcprof->temp_mon_range[i].
+					full_chrg_vol, &reg_val);
+
+		ret = update_zone_cv(i, reg_val);
+		if (unlikely(ret)) {
+			dev_err(chc.dev,
+				"Error updating zone cv for zone %d\n",
+				i);
+			return ret;
+		}
+
+		/* Write lowest temp limit */
+		if (i == (bcprof->temp_mon_ranges - 1)) {
+			ret = CONVERT_TEMP_TO_ADC(bcprof->temp_low_lim,
+							(int *)&adc_val);
+			if (unlikely(ret)) {
+				dev_err(chc.dev,
+					"Error converting low lim temp!!\n");
+				return ret;
+			}
+
+			ret = update_zone_temp(i+1, adc_val);
+
+			if (unlikely(ret)) {
+				dev_err(chc.dev,
+					"Error updating last temp for zone %d\n",
+					i+1);
+				return ret;
+			}
+		}
+	}
+	ret = pmic_update_tt(TT_CUSTOMFIELDEN_ADDR,
+				TT_HOT_COLD_LC_MASK,
+				TT_HOT_COLD_LC_DIS);
+
+	if (unlikely(ret)) {
+		dev_err(chc.dev, "Error updating TT_CUSTOMFIELD_EN reg\n");
+		return ret;
+	}
+
+	if (chc.pdata->inlmt_to_reg)
+		chc.pdata->inlmt_to_reg(USBINPUTICC100VAL, &reg_val);
+
+	ret = pmic_write_tt(TT_USBINPUTICC100VAL_ADDR, reg_val);
+	return ret;
+}
+
+static inline void print_ps_pse_mod_prof(struct ps_pse_mod_prof *bcprof)
+{
+	int i, temp_mon_ranges;
+
+	dev_info(chc.dev, "ChrgProf: batt_id:%s\n", bcprof->batt_id);
+	dev_info(chc.dev, "ChrgProf: battery_type:%u\n", bcprof->battery_type);
+	dev_info(chc.dev, "ChrgProf: capacity:%u\n", bcprof->capacity);
+	dev_info(chc.dev, "ChrgProf: voltage_max:%u\n", bcprof->voltage_max);
+	dev_info(chc.dev, "ChrgProf: chrg_term_ma:%u\n", bcprof->chrg_term_ma);
+	dev_info(chc.dev, "ChrgProf: low_batt_mV:%u\n", bcprof->low_batt_mV);
+	dev_info(chc.dev, "ChrgProf: disch_tmp_ul:%d\n", bcprof->disch_tmp_ul);
+	dev_info(chc.dev, "ChrgProf: disch_tmp_ll:%d\n", bcprof->disch_tmp_ll);
+	dev_info(chc.dev, "ChrgProf: temp_mon_ranges:%u\n",
+			bcprof->temp_mon_ranges);
+	temp_mon_ranges = min_t(u16, bcprof->temp_mon_ranges,
+			BATT_TEMP_NR_RNG);
+
+	for (i = 0; i < temp_mon_ranges; ++i) {
+		dev_info(chc.dev, "ChrgProf: temp_up_lim[%d]:%d\n",
+				i, bcprof->temp_mon_range[i].temp_up_lim);
+		dev_info(chc.dev, "ChrgProf: full_chrg_vol[%d]:%d\n",
+				i, bcprof->temp_mon_range[i].full_chrg_vol);
+		dev_info(chc.dev, "ChrgProf: full_chrg_cur[%d]:%d\n",
+				i, bcprof->temp_mon_range[i].full_chrg_cur);
+		dev_info(chc.dev, "ChrgProf: maint_chrgr_vol_ll[%d]:%d\n",
+				i, bcprof->temp_mon_range[i].maint_chrg_vol_ll);
+		dev_info(chc.dev, "ChrgProf: maint_chrgr_vol_ul[%d]:%d\n",
+				i, bcprof->temp_mon_range[i].maint_chrg_vol_ul);
+		dev_info(chc.dev, "ChrgProf: maint_chrg_cur[%d]:%d\n",
+				i, bcprof->temp_mon_range[i].maint_chrg_cur);
+	}
+	dev_info(chc.dev, "ChrgProf: temp_low_lim:%d\n", bcprof->temp_low_lim);
+}
+
+static int find_tempzone_index(short int *interval,
+				int *num_zones,
+				short int *temp_up_lim)
+{
+	struct ps_pse_mod_prof *bprof = chc.sfi_bcprof->batt_prof;
+	int up_lim_index = 0, low_lim_index = -1;
+	int diff = 0;
+	int i;
+
+	*num_zones = MIN_BATT_PROF - bprof->temp_mon_ranges + 1;
+	if ((*num_zones) <= 0)
+		return 0;
+
+	for (i = 0 ; i < bprof->temp_mon_ranges ; i++) {
+		if (bprof->temp_mon_range[i].temp_up_lim == BATT_TEMP_WARM)
+			up_lim_index = i;
+	}
+
+	low_lim_index = up_lim_index + 1;
+
+	if (low_lim_index == bprof->temp_mon_ranges)
+		diff = bprof->temp_low_lim -
+			bprof->temp_mon_range[up_lim_index].temp_up_lim;
+	else
+		diff = bprof->temp_mon_range[low_lim_index].temp_up_lim -
+			bprof->temp_mon_range[up_lim_index].temp_up_lim;
+
+	*interval = diff / (*num_zones);
+	*temp_up_lim = bprof->temp_mon_range[up_lim_index].temp_up_lim;
+
+	return up_lim_index;
+}
+
+
+static void set_pmic_batt_prof(struct ps_pse_mod_prof *new_prof,
+				struct ps_pse_mod_prof *bprof)
+{
+	int num_zones;
+	int split_index;
+	int i, j = 0;
+	short int temp_up_lim;
+	short int interval;
+
+	if ((new_prof == NULL) || (bprof == NULL))
+		return;
+
+	if (!NEED_ZONE_SPLIT(bprof)) {
+		dev_info(chc.dev, "No need to split the zones!!\n");
+		memcpy(new_prof, bprof, sizeof(struct ps_pse_mod_prof));
+		return;
+	}
+
+	strcpy(&(new_prof->batt_id[0]), &(bprof->batt_id[0]));
+	new_prof->battery_type = bprof->battery_type;
+	new_prof->capacity = bprof->capacity;
+	new_prof->voltage_max =  bprof->voltage_max;
+	new_prof->chrg_term_ma = bprof->chrg_term_ma;
+	new_prof->low_batt_mV =  bprof->low_batt_mV;
+	new_prof->disch_tmp_ul = bprof->disch_tmp_ul;
+	new_prof->disch_tmp_ll = bprof->disch_tmp_ll;
+
+	split_index = find_tempzone_index(&interval, &num_zones, &temp_up_lim);
+
+	for (i = 0 ; i < bprof->temp_mon_ranges; i++) {
+		if ((i == split_index) && (num_zones > 0)) {
+			for (j = 0; j < num_zones; j++,
+					temp_up_lim += interval) {
+				memcpy(&new_prof->temp_mon_range[i+j],
+					&bprof->temp_mon_range[i],
+					sizeof(bprof->temp_mon_range[i]));
+				new_prof->temp_mon_range[i+j].temp_up_lim =
+					temp_up_lim;
+			}
+			j--;
+		} else {
+			memcpy(&new_prof->temp_mon_range[i+j],
+				&bprof->temp_mon_range[i],
+				sizeof(bprof->temp_mon_range[i]));
+		}
+	}
+
+	new_prof->temp_mon_ranges = i+j;
+	new_prof->temp_low_lim = bprof->temp_low_lim;
+
+	return;
+}
+
+
+static int pmic_check_initial_events(void)
+{
+	struct pmic_event *evt;
+	int ret;
+	u8 mask = (CHRGRIRQ1_SVBUSDET_MASK);
+
+	evt = kzalloc(sizeof(struct pmic_event), GFP_KERNEL);
+	if (evt == NULL) {
+		dev_dbg(chc.dev, "Error allocating evt structure in fn:%s\n",
+			__func__);
+		return -1;
+	}
+
+	ret = intel_scu_ipc_ioread8(SCHGRIRQ0_ADDR, &evt->chgrirq0_stat);
+	evt->chgrirq0_int = evt->chgrirq0_stat;
+	ret = intel_scu_ipc_ioread8(SCHGRIRQ1_ADDR, &evt->chgrirq1_stat);
+	evt->chgrirq1_int = evt->chgrirq1_stat;
+
+	if (evt->chgrirq1_stat || evt->chgrirq0_int) {
+		INIT_LIST_HEAD(&evt->node);
+		mutex_lock(&chc.evt_queue_lock);
+		list_add_tail(&evt->node, &chc.evt_queue);
+		mutex_unlock(&chc.evt_queue_lock);
+		schedule_work(&chc.evt_work);
+	}
+
+	pmic_bat_zone_changed();
+
+	return ret;
+}
+
+static ssize_t
+pmic_show_battery_level(struct device *d, struct device_attribute *attr,
+			char *buf)
+{
+	int ret = 0;
+
+	ret = pmic_get_battery_voltage(&chc.battry_voltage);
+	if (ret != 0) {
+		dev_info(chc.dev, "read error!\n");
+		return -1;
+	}
+
+	return sprintf(buf, "0x%x\n", chc.battry_voltage);
+}
+
+static DEVICE_ATTR(battery_level, S_IWUSR | S_IRUGO, pmic_show_battery_level,
+		   NULL);
+
+static struct attribute *pmic_sysfs_entries[] = {
+	&dev_attr_battery_level.attr,
+	NULL
+};
+
+static struct attribute_group pmic_attribute_group = {
+	.name  = NULL,		/* put in device directory */
+	.attrs = pmic_sysfs_entries,
+};
+
+/**
+ * pmic_charger_probe - PMIC charger probe function
+ * @pdev: pmic platform device structure
+ * Context: can sleep
+ *
+ * pmic charger driver initializes its internal data
+ * structure and other  infrastructure components for it
+ * to work as expected.
+ */
+static int pmic_chrgr_probe(struct platform_device *pdev)
+{
+	int retval = 0;
+	u8 val;
+
+	if (!pdev)
+		return -ENODEV;
+
+	chc.health = POWER_SUPPLY_HEALTH_UNKNOWN;
+	chc.dev = &pdev->dev;
+	chc.irq = platform_get_irq(pdev, 0);
+	chc.pdata = pdev->dev.platform_data;
+	platform_set_drvdata(pdev, &chc);
+
+	if (chc.pdata == NULL) {
+		dev_err(chc.dev, "Platform data not initialized\n");
+		return -EFAULT;
+	}
+
+	retval = intel_scu_ipc_ioread8(PMIC_ID_ADDR, &chc.pmic_id);
+	if (retval) {
+		dev_err(chc.dev,
+			"Error reading PMIC ID register\n");
+		return retval;
+	}
+
+	dev_info(chc.dev, "PMIC-ID: %x\n", chc.pmic_id);
+	if ((chc.pmic_id & PMIC_VENDOR_ID_MASK) == SHADYCOVE_VENDORID) {
+		retval = pmic_read_reg(USBPATH_ADDR, &val);
+		if (retval) {
+			dev_err(chc.dev,
+				"Error reading CHGRSTATUS-register 0x%2x\n",
+				CHGRSTATUS_ADDR);
+			return retval;
+		}
+
+		if (val & USBPATH_USBSEL_MASK) {
+			dev_info(chc.dev, "SOC-Internal-USBPHY used\n");
+			chc.is_internal_usb_phy = true;
+		} else
+			dev_info(chc.dev, "External-USBPHY used\n");
+	}
+
+	chc.sfi_bcprof = kzalloc(sizeof(struct ps_batt_chg_prof),
+				GFP_KERNEL);
+	if (chc.sfi_bcprof == NULL) {
+		dev_err(chc.dev,
+			"Error allocating memeory SFI battery profile\n");
+		return -ENOMEM;
+	}
+
+	retval = get_batt_prop(chc.sfi_bcprof);
+	if (retval) {
+		dev_err(chc.dev,
+			"Error reading battery profile from battid frmwrk\n");
+		kfree(chc.sfi_bcprof);
+		chc.invalid_batt = true;
+		chc.sfi_bcprof = NULL;
+	}
+
+	retval = intel_scu_ipc_update_register(CHGRCTRL0_ADDR, SWCONTROL_ENABLE,
+			CHGRCTRL0_SWCONTROL_MASK);
+	if (retval)
+		dev_err(chc.dev, "Error enabling sw control. Charging may continue in h/w control mode\n");
+
+	if (!chc.invalid_batt) {
+		chc.actual_bcprof = kzalloc(sizeof(struct ps_pse_mod_prof),
+					GFP_KERNEL);
+		if (chc.actual_bcprof == NULL) {
+			dev_err(chc.dev,
+				"Error allocating mem for local battery profile\n");
+			kfree(chc.sfi_bcprof);
+			return -ENOMEM;
+		}
+
+		chc.runtime_bcprof = kzalloc(sizeof(struct ps_pse_mod_prof),
+					GFP_KERNEL);
+		if (chc.runtime_bcprof == NULL) {
+			dev_err(chc.dev,
+			"Error allocating mem for runtime batt profile\n");
+			kfree(chc.sfi_bcprof);
+			kfree(chc.actual_bcprof);
+			return -ENOMEM;
+		}
+
+		set_pmic_batt_prof(chc.actual_bcprof,
+				chc.sfi_bcprof->batt_prof);
+		print_ps_pse_mod_prof(chc.actual_bcprof);
+		retval = pmic_init();
+		if (retval)
+			dev_err(chc.dev, "Error in Initializing PMIC. Continue in h/w charging mode\n");
+
+		memcpy(chc.runtime_bcprof, chc.actual_bcprof,
+			sizeof(struct ps_pse_mod_prof));
+	}
+
+	chc.pmic_intr_iomap = ioremap_nocache(PMIC_SRAM_INTR_ADDR, 8);
+	if (!chc.pmic_intr_iomap) {
+		dev_err(&pdev->dev, "ioremap Failed\n");
+		retval = -ENOMEM;
+		goto ioremap_failed;
+	}
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(3, 10, 0))
+	chc.otg = usb_get_transceiver();
+#else
+	chc.otg = usb_get_phy(USB_PHY_TYPE_USB2);
+#endif
+	if (!chc.otg || IS_ERR(chc.otg)) {
+		dev_err(&pdev->dev, "Failed to get otg transceiver!!\n");
+		retval = -ENOMEM;
+		goto otg_req_failed;
+	}
+
+	INIT_WORK(&chc.evt_work, pmic_event_worker);
+	INIT_LIST_HEAD(&chc.evt_queue);
+	mutex_init(&chc.evt_queue_lock);
+
+	/* register interrupt */
+	retval = request_threaded_irq(chc.irq, pmic_isr,
+			pmic_thread_handler,
+			IRQF_SHARED|IRQF_NO_SUSPEND ,
+			DRIVER_NAME, &chc);
+	if (retval) {
+		dev_err(&pdev->dev,
+			"Error in request_threaded_irq(irq(%d)!!\n",
+			chc.irq);
+		goto otg_req_failed;
+	}
+
+	retval = pmic_check_initial_events();
+	if (unlikely(retval)) {
+		dev_err(&pdev->dev,
+			"Error posting initial events\n");
+		goto req_irq_failed;
+	}
+
+	/* unmask charger interrupts in second level IRQ register*/
+	retval = intel_scu_ipc_update_register(MCHGRIRQ0_ADDR, 0x00,
+			PMIC_CHRGR_INT0_MASK);
+	/* unmask charger interrupts in second level IRQ register*/
+	retval = intel_scu_ipc_iowrite8(MCHGRIRQ1_ADDR, 0x00);
+	if (unlikely(retval))
+		goto unmask_irq_failed;
+
+
+	/* unmask IRQLVL1 register */
+	retval = intel_scu_ipc_update_register(IRQLVL1_MASK_ADDR, 0x00,
+			IRQLVL1_CHRGR_MASK);
+	if (unlikely(retval))
+		goto unmask_irq_failed;
+
+	retval = intel_scu_ipc_update_register(USBIDCTRL_ADDR,
+			 ACADETEN_MASK | USBIDEN_MASK,
+			ACADETEN_MASK | USBIDEN_MASK);
+	if (unlikely(retval))
+		goto unmask_irq_failed;
+
+	retval = sysfs_create_group(&pdev->dev.kobj, &pmic_attribute_group);
+	if (retval) {
+		dev_err(&pdev->dev, "failed to create sysfs device attributes\n");
+		goto unmask_irq_failed;
+	}
+
+	chc.health = POWER_SUPPLY_HEALTH_GOOD;
+#ifdef CONFIG_DEBUG_FS
+	pmic_debugfs_init();
+#endif
+	return 0;
+
+unmask_irq_failed:
+req_irq_failed:
+	free_irq(chc.irq, &chc);
+otg_req_failed:
+	iounmap(chc.pmic_intr_iomap);
+ioremap_failed:
+	kfree(chc.sfi_bcprof);
+	kfree(chc.actual_bcprof);
+	kfree(chc.runtime_bcprof);
+	return retval;
+}
+
+static void pmic_chrgr_do_exit_ops(struct pmic_chrgr_drv_context *chc)
+{
+	/*TODO:
+	 * If charger is connected send IPC message to SCU to continue charging
+	 */
+#ifdef CONFIG_DEBUG_FS
+	pmic_debugfs_exit();
+#endif
+}
+
+/**
+ * pmic_charger_remove - PMIC Charger driver remove
+ * @pdev: PMIC charger platform device structure
+ * Context: can sleep
+ *
+ * PMIC charger finalizes its internal data structure and other
+ * infrastructure components that it initialized in
+ * pmic_chrgr_probe.
+ */
+static int pmic_chrgr_remove(struct platform_device *pdev)
+{
+	struct pmic_chrgr_drv_context *chc = platform_get_drvdata(pdev);
+
+	if (chc) {
+		pmic_chrgr_do_exit_ops(chc);
+		free_irq(chc->irq, chc);
+		iounmap(chc->pmic_intr_iomap);
+		kfree(chc->sfi_bcprof);
+		kfree(chc->actual_bcprof);
+		kfree(chc->runtime_bcprof);
+		sysfs_remove_group(&pdev->dev.kobj, &pmic_attribute_group);
+	}
+
+	return 0;
+}
+
+#ifdef CONFIG_PM
+static int pmic_chrgr_suspend(struct device *dev)
+{
+	dev_dbg(dev, "%s called\n", __func__);
+	return 0;
+}
+
+static int pmic_chrgr_resume(struct device *dev)
+{
+	dev_dbg(dev, "%s called\n", __func__);
+	return 0;
+}
+#endif
+
+#ifdef CONFIG_PM_RUNTIME
+static int pmic_chrgr_runtime_suspend(struct device *dev)
+{
+	dev_dbg(dev, "%s called\n", __func__);
+	return 0;
+}
+
+static int pmic_chrgr_runtime_resume(struct device *dev)
+{
+	dev_dbg(dev, "%s called\n", __func__);
+	return 0;
+}
+
+static int pmic_chrgr_runtime_idle(struct device *dev)
+{
+	dev_dbg(dev, "%s called\n", __func__);
+	return 0;
+}
+#endif
+
+/*********************************************************************
+ *		Driver initialisation and finalization
+ *********************************************************************/
+
+static const struct dev_pm_ops pmic_chrgr_pm_ops = {
+	SET_SYSTEM_SLEEP_PM_OPS(pmic_chrgr_suspend,
+				pmic_chrgr_resume)
+	SET_RUNTIME_PM_OPS(pmic_chrgr_runtime_suspend,
+				pmic_chrgr_runtime_resume,
+				pmic_chrgr_runtime_idle)
+};
+
+static struct platform_driver pmic_chrgr_driver = {
+	.driver = {
+		   .name = DRIVER_NAME,
+		   .owner = THIS_MODULE,
+		   .pm = &pmic_chrgr_pm_ops,
+		   },
+	.probe = pmic_chrgr_probe,
+	.remove = pmic_chrgr_remove,
+};
+
+static int pmic_chrgr_init(void)
+{
+	return platform_driver_register(&pmic_chrgr_driver);
+}
+
+static void pmic_chrgr_exit(void)
+{
+	platform_driver_unregister(&pmic_chrgr_driver);
+}
+
+static int pmic_ccsm_rpmsg_probe(struct rpmsg_channel *rpdev)
+{
+	int ret = 0;
+
+	if (rpdev == NULL) {
+		pr_err("rpmsg channel not created\n");
+		ret = -ENODEV;
+		goto out;
+	}
+
+	dev_info(&rpdev->dev, "Probed pmic_ccsm rpmsg device\n");
+
+	ret = pmic_chrgr_init();
+
+out:
+	return ret;
+}
+
+static void pmic_ccsm_rpmsg_remove(struct rpmsg_channel *rpdev)
+{
+	pmic_chrgr_exit();
+	dev_info(&rpdev->dev, "Removed pmic_ccsm rpmsg device\n");
+}
+
+static void pmic_ccsm_rpmsg_cb(struct rpmsg_channel *rpdev, void *data,
+					int len, void *priv, u32 src)
+{
+	dev_warn(&rpdev->dev, "unexpected, message\n");
+
+	print_hex_dump(KERN_DEBUG, __func__, DUMP_PREFIX_NONE, 16, 1,
+		       data, len,  true);
+}
+
+static struct rpmsg_device_id pmic_ccsm_rpmsg_id_table[] = {
+	{ .name	= "rpmsg_pmic_ccsm" },
+	{ },
+};
+MODULE_DEVICE_TABLE(rpmsg, pmic_ccsm_rpmsg_id_table);
+
+static struct rpmsg_driver pmic_ccsm_rpmsg = {
+	.drv.name	= KBUILD_MODNAME,
+	.drv.owner	= THIS_MODULE,
+	.id_table	= pmic_ccsm_rpmsg_id_table,
+	.probe		= pmic_ccsm_rpmsg_probe,
+	.callback	= pmic_ccsm_rpmsg_cb,
+	.remove		= pmic_ccsm_rpmsg_remove,
+};
+
+static int __init pmic_ccsm_rpmsg_init(void)
+{
+	return register_rpmsg_driver(&pmic_ccsm_rpmsg);
+}
+
+static void __exit pmic_ccsm_rpmsg_exit(void)
+{
+	return unregister_rpmsg_driver(&pmic_ccsm_rpmsg);
+}
+/* Defer init call so that dependant drivers will be loaded. Using  async
+ * for parallel driver initialization */
+late_initcall(pmic_ccsm_rpmsg_init);
+module_exit(pmic_ccsm_rpmsg_exit);
+
+MODULE_AUTHOR("Jenny TC <jenny.tc@intel.com>");
+MODULE_DESCRIPTION("PMIC Charger  Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/power/pmic_ccsm.h b/drivers/power/pmic_ccsm.h
new file mode 100644
index 0000000..77b6b2e
--- /dev/null
+++ b/drivers/power/pmic_ccsm.h
@@ -0,0 +1,366 @@
+/*
+ * pmic_ccsm.h - Intel MID PMIC CCSM Driver header file
+ *
+ * Copyright (C) 2011 Intel Corporation
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ * Author: Jenny TC <jenny.tc@intel.com>
+ */
+
+#ifndef __PMIC_CCSM_H__
+#define __PMIC_CCSM_H__
+
+#include <asm/pmic_pdata.h>
+/*********************************************************************
+ *		Generic defines
+ *********************************************************************/
+
+#define D7 (1 << 7)
+#define D6 (1 << 6)
+#define D5 (1 << 5)
+#define D4 (1 << 4)
+#define D3 (1 << 3)
+#define D2 (1 << 2)
+#define D1 (1 << 1)
+#define D0 (1 << 0)
+
+#define PMIC_ID_ADDR	0x00
+
+#define PMIC_VENDOR_ID_MASK	(0x03 << 6)
+#define PMIC_MINOR_REV_MASK	0x07
+#define PMIC_MAJOR_REV_MASK	(0x07 << 3)
+
+#define BASINCOVE_VENDORID	(0x03 << 6)
+#define SHADYCOVE_VENDORID	0x00
+
+#define BC_PMIC_MAJOR_REV_A0	0x00
+#define BC_PMIC_MAJOR_REV_B0	(0x01 << 3)
+
+#define PMIC_BZONE_LOW 0
+#define PMIC_BZONE_HIGH 5
+
+#define IRQLVL1_ADDR			0x01
+#define IRQLVL1_MASK_ADDR		0x0c
+#define IRQLVL1_CHRGR_MASK		D5
+
+#define THRMZN0H_ADDR_BC		0xCE
+#define THRMZN0L_ADDR_BC		0xCF
+#define THRMZN1H_ADDR_BC		0xD0
+#define THRMZN1L_ADDR_BC		0xD1
+#define THRMZN2H_ADDR_BC		0xD2
+#define THRMZN2L_ADDR_BC		0xD3
+#define THRMZN3H_ADDR_BC		0xD4
+#define THRMZN3L_ADDR_BC		0xD5
+#define THRMZN4H_ADDR_BC		0xD6
+#define THRMZN4L_ADDR_BC		0xD7
+
+#define GPADCREQ_ADDR_BC		0xDC
+#define GPADCREG_VIBATT_REQ		(0x01 << 5)
+
+#define VBATRSLTH_ADDR_BC		0xE9
+#define VBATRSLTL_ADDR_BC		0xEA
+
+#define THRMZN0H_ADDR_SC		0xD7
+#define THRMZN0L_ADDR_SC		0xD8
+#define THRMZN1H_ADDR_SC		0xD9
+#define THRMZN1L_ADDR_SC		0xDA
+#define THRMZN2H_ADDR_SC		0xDD
+#define THRMZN2L_ADDR_SC		0xDE
+#define THRMZN3H_ADDR_SC		0xDF
+#define THRMZN3L_ADDR_SC		0xE0
+#define THRMZN4H_ADDR_SC		0xE1
+#define THRMZN4L_ADDR_SC		0xE2
+
+#define CHGRIRQ0_ADDR			0x07
+#define CHGIRQ0_BZIRQ_MASK		D7
+#define CHGIRQ0_BAT_CRIT_MASK		D6
+#define CHGIRQ0_BAT1_ALRT_MASK		D5
+#define CHGIRQ0_BAT0_ALRT_MASK		D4
+
+#define MCHGRIRQ0_ADDR			0x12
+#define MCHGIRQ0_RSVD_MASK		D7
+#define MCHGIRQ0_MBAT_CRIT_MASK		D6
+#define MCHGIRQ0_MBAT1_ALRT_MASK	D5
+#define MCHGIRQ0_MBAT0_ALRT_MASK	D4
+
+#define SCHGRIRQ0_ADDR			0x4E
+#define SCHGIRQ0_RSVD_MASK		D7
+#define SCHGIRQ0_SBAT_CRIT_MASK		D6
+#define SCHGIRQ0_SBAT1_ALRT_MASK	D5
+#define SCHGIRQ0_SBAT0_ALRT_MASK	D4
+
+#define LOWBATTDET0_ADDR		0x2C
+#define LOWBATTDET1_ADDR		0x2D
+#define BATTDETCTRL_ADDR		0x2E
+#define VBUSDETCTRL_ADDR		0x50
+#define VDCINDETCTRL_ADDR		0x51
+
+#define CHRGRIRQ1_ADDR			0x08
+#define CHRGRIRQ1_SUSBIDDET_MASK	D3
+#define CHRGRIRQ1_SBATTDET_MASK		D2
+#define CHRGRIRQ1_SDCDET_MASK		D1
+#define CHRGRIRQ1_SVBUSDET_MASK		D0
+#define MCHGRIRQ1_ADDR			0x13
+#define MCHRGRIRQ1_SUSBIDDET_MASK	D3
+#define MCHRGRIRQ1_SBATTDET_MAS		D2
+#define MCHRGRIRQ1_SDCDET_MASK		D1
+#define MCHRGRIRQ1_SVBUSDET_MASK	D0
+#define SCHGRIRQ1_ADDR			0x4F
+#define SCHRGRIRQ1_SUSBIDDET_MASK	D3
+#define SCHRGRIRQ1_SBATTDET_MASK	D2
+#define SCHRGRIRQ1_SDCDET_MASK		D1
+#define SCHRGRIRQ1_SVBUSDET_MASK	D0
+
+#define PMIC_CHRGR_INT0_MASK		0xB1
+#define PMIC_CHRGR_CCSM_INT0_MASK	0xB0
+#define PMIC_CHRGR_EXT_CHRGR_INT_MASK	0x01
+
+#define CHGRCTRL0_ADDR			0x4B
+#define CHGRCTRL0_WDT_NOKICK_MASK	D7
+#define CHGRCTRL0_DBPOFF_MASK		D6
+#define CHGRCTRL0_CCSM_OFF_MASK		D5
+#define CHGRCTRL0_TTLCK_MASK		D4
+#define CHGRCTRL0_SWCONTROL_MASK	D3
+#define CHGRCTRL0_EXTCHRDIS_MASK	D2
+#define	CHRCTRL0_EMRGCHREN_MASK		D1
+#define	CHRCTRL0_CHGRRESET_MASK		D0
+
+#define WDT_NOKICK_ENABLE		(0x01 << 7)
+#define WDT_NOKICK_DISABLE		(~WDT_NOKICK_ENABLE & 0xFF)
+
+#define EXTCHRDIS_ENABLE		(0x01 << 2)
+#define EXTCHRDIS_DISABLE		(~EXTCHRDIS_ENABLE & 0xFF)
+#define SWCONTROL_ENABLE		(0x01 << 3)
+#define EMRGCHREN_ENABLE		(0x01 << 1)
+
+#define CHGRCTRL1_ADDR			0x4C
+#define CHGRCTRL1_DBPEN_MASK		D7
+#define CHGRCTRL1_OTGMODE_MASK		D6
+#define CHGRCTRL1_FTEMP_EVENT_MASK	D5
+#define CHGRCTRL1_FUSB_INLMT_1500	D4
+#define CHGRCTRL1_FUSB_INLMT_900	D3
+#define CHGRCTRL1_FUSB_INLMT_500	D2
+#define CHGRCTRL1_FUSB_INLMT_150	D1
+#define CHGRCTRL1_FUSB_INLMT_100	D0
+
+#define CHGRSTATUS_ADDR			0x4D
+#define CHGRSTATUS_RSVD_MASK		(D7|D6|D5|D3)
+#define CHGRSTATUS_SDPB_MASK		D4
+#define CHGRSTATUS_CHGDISLVL_MASK	D2
+#define CHGRSTATUS_CHGDETB_LATCH_MASK	D1
+#define CHGDETB_MASK			D0
+
+#define THRMBATZONE_ADDR_BC		0xB5
+#define THRMBATZONE_ADDR_SC		0xB6
+#define THRMBATZONE_MASK		(D0|D1|D2)
+
+#define USBIDCTRL_ADDR		0x19
+#define USBIDEN_MASK		0x01
+#define ACADETEN_MASK		(0x01 << 1)
+
+#define USBIDSTAT_ADDR		0x1A
+#define ID_SHORT		D4
+#define ID_SHORT_VBUS		(1 << 4)
+#define ID_NOT_SHORT_VBUS	0
+#define ID_FLOAT_STS		D3
+#define R_ID_FLOAT_DETECT	(1 << 3)
+#define R_ID_FLOAT_NOT_DETECT	0
+#define ID_RAR_BRC_STS		((D2 | D1))
+#define ID_ACA_NOT_DETECTED	0
+#define R_ID_A			(1 << 1)
+#define R_ID_B			(2 << 1)
+#define R_ID_C			(3 << 1)
+#define ID_GND			D0
+#define ID_TYPE_A		0
+#define ID_TYPE_B		1
+#define is_aca(x) ((x & R_ID_A) || (x & R_ID_B) || (x & R_ID_C))
+
+#define WAKESRC_ADDR		0x24
+
+#define CHRTTADDR_ADDR		0x56
+#define CHRTTDATA_ADDR		0x57
+
+#define USBSRCDET_RETRY_CNT		4
+#define USBSRCDET_SLEEP_TIME		200
+#define USBSRCDETSTATUS_ADDR		0x5D
+#define USBSRCDET_SUSBHWDET_MASK	(D0|D1)
+#define USBSRCDET_USBSRCRSLT_MASK	(D2|D3|D4|D5)
+#define USBSRCDET_SDCD_MASK		(D6|D7)
+#define USBSRCDET_SUSBHWDET_DETON	(0x01 << 0)
+#define USBSRCDET_SUSBHWDET_DETSUCC	(0x01 << 1)
+#define USBSRCDET_SUSBHWDET_DETFAIL	(0x03 << 0)
+
+/* Register on I2C-dev2-0x6E */
+#define USBPATH_ADDR		0x011C
+#define USBPATH_USBSEL_MASK	D3
+
+#define TT_I2CDADDR_ADDR		0x00
+#define TT_CHGRINIT0OS_ADDR		0x01
+#define TT_CHGRINIT1OS_ADDR		0x02
+#define TT_CHGRINIT2OS_ADDR		0x03
+#define TT_CHGRINIT3OS_ADDR		0x04
+#define TT_CHGRINIT4OS_ADDR		0x05
+#define TT_CHGRINIT5OS_ADDR		0x06
+#define TT_CHGRINIT6OS_ADDR		0x07
+#define TT_CHGRINIT7OS_ADDR		0x08
+#define TT_USBINPUTICCOS_ADDR		0x09
+#define TT_USBINPUTICCMASK_ADDR		0x0A
+#define TT_CHRCVOS_ADDR			0X0B
+#define TT_CHRCVMASK_ADDR		0X0C
+#define TT_CHRCCOS_ADDR			0X0D
+#define TT_CHRCCMASK_ADDR		0X0E
+#define TT_LOWCHROS_ADDR		0X0F
+#define TT_LOWCHRMASK_ADDR		0X10
+#define TT_WDOGRSTOS_ADDR		0X11
+#define TT_WDOGRSTMASK_ADDR		0X12
+#define TT_CHGRENOS_ADDR		0X13
+#define TT_CHGRENMASK_ADDR		0X14
+
+#define TT_CUSTOMFIELDEN_ADDR		0X15
+#define TT_HOT_LC_EN			D1
+#define TT_COLD_LC_EN			D0
+#define TT_HOT_COLD_LC_MASK		(TT_HOT_LC_EN | TT_COLD_LC_EN)
+#define TT_HOT_COLD_LC_EN		(TT_HOT_LC_EN | TT_COLD_LC_EN)
+#define TT_HOT_COLD_LC_DIS		0
+
+#define TT_CHGRINIT0VAL_ADDR		0X20
+#define TT_CHGRINIT1VAL_ADDR		0X21
+#define TT_CHGRINIT2VAL_ADDR		0X22
+#define TT_CHGRINIT3VAL_ADDR		0X23
+#define TT_CHGRINIT4VAL_ADDR		0X24
+#define TT_CHGRINIT5VAL_ADDR		0X25
+#define TT_CHGRINIT6VAL_ADDR		0X26
+#define TT_CHGRINIT7VAL_ADDR		0X27
+#define TT_USBINPUTICC100VAL_ADDR	0X28
+#define TT_USBINPUTICC150VAL_ADDR	0X29
+#define TT_USBINPUTICC500VAL_ADDR	0X2A
+#define TT_USBINPUTICC900VAL_ADDR	0X2B
+#define TT_USBINPUTICC1500VAL_ADDR	0X2C
+#define TT_CHRCVEMRGLOWVAL_ADDR		0X2D
+#define TT_CHRCVCOLDVAL_ADDR		0X2E
+#define TT_CHRCVCOOLVAL_ADDR		0X2F
+#define TT_CHRCVWARMVAL_ADDR		0X30
+#define TT_CHRCVHOTVAL_ADDR		0X31
+#define TT_CHRCVEMRGHIVAL_ADDR		0X32
+#define TT_CHRCCEMRGLOWVAL_ADDR		0X33
+#define TT_CHRCCCOLDVAL_ADDR		0X34
+#define TT_CHRCCCOOLVAL_ADDR		0X35
+#define TT_CHRCCWARMVAL_ADDR		0X36
+#define TT_CHRCCHOTVAL_ADDR		0X37
+#define TT_CHRCCEMRGHIVAL_ADDR		0X38
+#define TT_LOWCHRENVAL_ADDR		0X39
+#define TT_LOWCHRDISVAL_ADDR		0X3A
+#define TT_WDOGRSTVAL_ADDR		0X3B
+#define TT_CHGRENVAL_ADDR		0X3C
+#define TT_CHGRDISVAL_ADDR		0X3D
+
+/*Interrupt registers*/
+#define BATT_CHR_BATTDET_MASK	D2
+/*Status registers*/
+#define BATT_PRESENT		1
+#define BATT_NOT_PRESENT	0
+
+#define BATT_STRING_MAX		8
+#define BATTID_STR_LEN		8
+
+#define CHARGER_PRESENT		1
+#define CHARGER_NOT_PRESENT	0
+
+/*FIXME: Modify default values */
+#define BATT_DEAD_CUTOFF_VOLT		3400	/* 3400 mV */
+#define BATT_CRIT_CUTOFF_VOLT		3700	/* 3700 mV */
+
+#define MSIC_BATT_TEMP_MAX		60	/* 60 degrees */
+#define MSIC_BATT_TEMP_MIN		0
+
+#define BATT_TEMP_WARM			45	/* 45 degrees */
+#define MIN_BATT_PROF			4
+
+#define PMIC_REG_NAME_LEN		28
+#define PMIC_REG_DEF(x) { .reg_name = #x, .addr = x }
+
+#define GPADC_MAX_VOLTAGE		450
+#define GPADC_MAX_RANGE 		1024
+
+struct interrupt_info {
+	/* Interrupt register mask*/
+	u8 int_reg_mask;
+	/* interrupt status register mask */
+	u8 stat_reg_mask;
+	/* log message if interrupt is set */
+	char *log_msg_int_reg_true;
+	/* log message if stat is true or false */
+	char *log_msg_stat_true;
+	char *log_msg_stat_false;
+	/* handle if interrupt bit is set */
+	void (*int_handle) (void);
+	/* interrupt status handler */
+	void (*stat_handle) (bool);
+};
+
+enum pmic_charger_cable_type {
+	PMIC_CHARGER_TYPE_NONE = 0,
+	PMIC_CHARGER_TYPE_SDP,
+	PMIC_CHARGER_TYPE_DCP,
+	PMIC_CHARGER_TYPE_CDP,
+	PMIC_CHARGER_TYPE_ACA,
+	PMIC_CHARGER_TYPE_SE1,
+	PMIC_CHARGER_TYPE_MHL,
+	PMIC_CHARGER_TYPE_FLOAT_DP_DN,
+	PMIC_CHARGER_TYPE_OTHER,
+	PMIC_CHARGER_TYPE_DCP_EXTPHY,
+};
+
+struct pmic_chrgr_drv_context {
+	bool invalid_batt;
+	bool is_batt_present;
+	bool current_sense_enabled;
+	unsigned int irq;		/* GPE_ID or IRQ# */
+	void __iomem *pmic_intr_iomap;
+	struct device *dev;
+	int health;
+	int battry_voltage;
+	u8 pmic_id;
+	bool is_internal_usb_phy;
+	enum pmic_charger_cable_type charger_type;
+	/* ShadyCove-WA for VBUS removal detect issue */
+	bool vbus_connect_status;
+	struct ps_batt_chg_prof *sfi_bcprof;
+	struct ps_pse_mod_prof *actual_bcprof;
+	struct ps_pse_mod_prof *runtime_bcprof;
+	struct pmic_platform_data *pdata;
+	struct usb_phy *otg;
+	struct list_head evt_queue;
+	struct work_struct evt_work;
+	struct mutex evt_queue_lock;
+};
+
+struct pmic_event {
+	struct list_head node;
+	u8 chgrirq0_int;
+	u8 chgrirq1_int;
+	u8 chgrirq0_stat;
+	u8 chgrirq1_stat;
+};
+
+struct pmic_regs_def {
+	char reg_name[PMIC_REG_NAME_LEN];
+	u16 addr;
+};
+
+#endif
diff --git a/drivers/power/power_supply.h b/drivers/power/power_supply.h
index cc439fd..d2b3a53 100644
--- a/drivers/power/power_supply.h
+++ b/drivers/power/power_supply.h
@@ -40,3 +40,24 @@ static inline int power_supply_create_triggers(struct power_supply *psy)
 static inline void power_supply_remove_triggers(struct power_supply *psy) {}
 
 #endif /* CONFIG_LEDS_TRIGGERS */
+#ifdef CONFIG_POWER_SUPPLY_CHARGER
+
+extern void power_supply_trigger_charging_handler(struct power_supply *psy);
+extern int power_supply_register_charger(struct power_supply *psy);
+extern int power_supply_unregister_charger(struct power_supply *psy);
+extern int psy_charger_throttle_charger(struct power_supply *psy,
+					unsigned long state);
+
+#else
+
+static inline void
+	power_supply_trigger_charging_handler(struct power_supply *psy) { }
+static inline int power_supply_register_charger(struct power_supply *psy)
+{ return 0; }
+static inline int power_supply_unregister_charger(struct power_supply *psy)
+{ return 0; }
+static inline int psy_charger_throttle_charger(struct power_supply *psy,
+					unsigned long state)
+{ return 0; }
+
+#endif
diff --git a/drivers/power/power_supply_charger.c b/drivers/power/power_supply_charger.c
new file mode 100644
index 0000000..9ed83bd
--- /dev/null
+++ b/drivers/power/power_supply_charger.c
@@ -0,0 +1,1151 @@
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/device.h>
+#include <linux/err.h>
+#include <linux/power_supply.h>
+#include <linux/thermal.h>
+#include <linux/extcon.h>
+#include <linux/power/battery_id.h>
+#include <linux/notifier.h>
+#include <linux/usb/otg.h>
+#include "power_supply.h"
+#include "power_supply_charger.h"
+
+struct work_struct otg_work;
+#define MAX_CHARGER_COUNT 5
+
+static LIST_HEAD(algo_list);
+
+struct power_supply_charger {
+	bool is_cable_evt_reg;
+	/*cache battery and charger properties */
+	struct list_head chrgr_cache_lst;
+	struct list_head batt_cache_lst;
+	struct list_head evt_queue;
+	struct work_struct algo_trigger_work;
+	struct mutex evt_lock;
+	wait_queue_head_t wait_chrg_enable;
+};
+
+struct charger_cable {
+	struct work_struct work;
+	struct notifier_block nb;
+	struct extcon_chrgr_cbl_props cable_props;
+	enum extcon_cable_name extcon_cable_type;
+	enum power_supply_charger_cable_type psy_cable_type;
+	struct extcon_specific_cable_nb extcon_dev;
+	struct extcon_dev *edev;
+};
+
+static struct power_supply_charger psy_chrgr;
+
+static struct charger_cable cable_list[] = {
+	{
+	 .psy_cable_type = POWER_SUPPLY_CHARGER_TYPE_USB_SDP,
+	 .extcon_cable_type = EXTCON_SDP,
+	 },
+	{
+	 .psy_cable_type = POWER_SUPPLY_CHARGER_TYPE_USB_CDP,
+	 .extcon_cable_type = EXTCON_CDP,
+	 },
+	{
+	 .psy_cable_type = POWER_SUPPLY_CHARGER_TYPE_USB_DCP,
+	 .extcon_cable_type = EXTCON_DCP,
+	 },
+	{
+	 .psy_cable_type = POWER_SUPPLY_CHARGER_TYPE_USB_ACA,
+	 .extcon_cable_type = EXTCON_ACA,
+	 },
+	{
+	 .psy_cable_type = POWER_SUPPLY_CHARGER_TYPE_ACA_DOCK,
+	 .extcon_cable_type = EXTCON_ACA,
+	 },
+	{
+	 .psy_cable_type = POWER_SUPPLY_CHARGER_TYPE_SE1,
+	 .extcon_cable_type = EXTCON_TA,
+	 },
+	{
+	 .psy_cable_type = POWER_SUPPLY_CHARGER_TYPE_AC,
+	 .extcon_cable_type = EXTCON_AC,
+	 },
+};
+
+static int get_supplied_by_list(struct power_supply *psy,
+				struct power_supply *psy_lst[]);
+
+static int otg_handle_notification(struct notifier_block *nb,
+				   unsigned long event, void *data);
+struct usb_phy *otg_xceiver;
+struct notifier_block otg_nb = {
+		   .notifier_call = otg_handle_notification,
+		};
+static void configure_chrgr_source(struct charger_cable *cable_lst);
+
+struct charger_cable *get_cable(unsigned long usb_chrgr_type)
+{
+
+	switch (usb_chrgr_type) {
+	case POWER_SUPPLY_CHARGER_TYPE_USB_SDP:
+		pr_info("%s:%d SDP\n", __FILE__, __LINE__);
+		return &cable_list[0];
+	case POWER_SUPPLY_CHARGER_TYPE_USB_CDP:
+		pr_info("%s:%d CDP\n", __FILE__, __LINE__);
+		return &cable_list[1];
+	case POWER_SUPPLY_CHARGER_TYPE_USB_DCP:
+		pr_info("%s:%d DCP\n", __FILE__, __LINE__);
+		return &cable_list[2];
+	case POWER_SUPPLY_CHARGER_TYPE_USB_ACA:
+		pr_info("%s:%d ACA\n", __FILE__, __LINE__);
+		return &cable_list[3];
+	case POWER_SUPPLY_CHARGER_TYPE_ACA_DOCK:
+		pr_info("%s:%d ACA DOCK\n", __FILE__, __LINE__);
+		return &cable_list[4];
+	case POWER_SUPPLY_CHARGER_TYPE_AC:
+		pr_info("%s:%d AC\n", __FILE__, __LINE__);
+		return &cable_list[6];
+	case POWER_SUPPLY_CHARGER_TYPE_SE1:
+		pr_info("%s:%d SE1\n", __FILE__, __LINE__);
+		return &cable_list[5];
+	}
+
+	return NULL;
+}
+
+
+static void otg_event_worker(struct work_struct *work)
+{
+	configure_chrgr_source(cable_list);
+
+}
+
+static int process_cable_props(struct power_supply_cable_props *cap)
+{
+
+	struct charger_cable *cable = NULL;
+
+	cable = get_cable(cap->chrg_type);
+	if (!cable) {
+
+		pr_err("%s:%d Error in getting charger cable from get_cable\n",
+				__FILE__, __LINE__);
+		return -EINVAL;
+	}
+
+	switch (cap->chrg_evt) {
+	case POWER_SUPPLY_CHARGER_EVENT_CONNECT:
+		printk(KERN_ERR "%s:%d Connected inlmt=%d\n",
+				__FILE__, __LINE__, cap->mA);
+		cable->cable_props.cable_stat = EXTCON_CHRGR_CABLE_CONNECTED;
+		break;
+	case POWER_SUPPLY_CHARGER_EVENT_UPDATE:
+		printk(KERN_ERR "%s:%d Connected\n", __FILE__, __LINE__);
+		cable->cable_props.cable_stat = EXTCON_CHRGR_CABLE_UPDATED;
+		break;
+	case POWER_SUPPLY_CHARGER_EVENT_DISCONNECT:
+		printk(KERN_ERR "%s:%d Disconnected inlmt=%d\n",
+			__FILE__, __LINE__, cap->mA);
+		cable->cable_props.cable_stat = EXTCON_CHRGR_CABLE_DISCONNECTED;
+		break;
+	case POWER_SUPPLY_CHARGER_EVENT_SUSPEND:
+		printk(KERN_ERR "%s:%d Suspended inlmt=%d\n",
+			__FILE__, __LINE__, cap->mA);
+		cable->cable_props.cable_stat = EXTCON_CHRGR_CABLE_SUSPENDED;
+		break;
+	default:
+		printk(KERN_ERR "%s:%d Invalid event\n", __FILE__, __LINE__);
+		break;
+	}
+
+	cable->cable_props.mA = cap->mA;
+	schedule_work(&otg_work);
+
+	return 0;
+
+}
+
+static int otg_handle_notification(struct notifier_block *nb,
+				   unsigned long event, void *data)
+{
+
+	struct power_supply_cable_props *cap;
+
+	cap = (struct power_supply_cable_props *)data;
+
+	if (event != USB_EVENT_CHARGER)
+		return NOTIFY_DONE;
+
+	process_cable_props(cap);
+
+
+	return NOTIFY_OK;
+}
+
+int otg_register(void)
+{
+	int retval;
+
+	otg_xceiver = usb_get_transceiver();
+	if (!otg_xceiver) {
+		pr_err("%s:%d failure to get otg transceiver\n",
+					__FILE__, __LINE__);
+		goto otg_reg_failed;
+	}
+	retval = usb_register_notifier(otg_xceiver, &otg_nb);
+	if (retval) {
+		pr_err("%s:%d failure to register otg notifier\n",
+			__FILE__, __LINE__);
+		goto otg_reg_failed;
+	}
+
+	INIT_WORK(&otg_work, otg_event_worker);
+
+
+	return 0;
+
+otg_reg_failed:
+
+	return -EIO;
+}
+
+static int charger_cable_notifier(struct notifier_block *nb,
+				  unsigned long event, void *ptr);
+static void charger_cable_event_worker(struct work_struct *work);
+struct charging_algo *power_supply_get_charging_algo
+		(struct power_supply *, struct ps_batt_chg_prof *);
+
+static void init_charger_cables(struct charger_cable *cable_lst, int count)
+{
+	struct charger_cable *cable;
+	struct extcon_chrgr_cbl_props cable_props;
+	const char *cable_name;
+	struct power_supply_cable_props cap;
+
+	otg_register();
+
+	while (--count) {
+		cable = cable_lst++;
+		/* initialize cable instance */
+		INIT_WORK(&cable->work, charger_cable_event_worker);
+		cable->nb.notifier_call = charger_cable_notifier;
+		cable->cable_props.cable_stat = EXTCON_CHRGR_CABLE_DISCONNECTED;
+		cable->cable_props.mA = 0;
+		cable_name = extcon_cable_name[cable->extcon_cable_type];
+
+		if (extcon_register_interest(&cable->extcon_dev,
+				NULL, cable_name, &cable->nb))
+				continue;
+
+		cable->edev = cable->extcon_dev.edev;
+
+		if (!cable->edev)
+			continue;
+
+		if (cable->edev->get_cable_properties(cable_name,
+						      (void *)&cable_props)) {
+			continue;
+
+		} else if (cable_props.cable_stat !=
+			   cable->cable_props.cable_stat) {
+			cable->cable_props.cable_stat = cable_props.cable_stat;
+			cable->cable_props.mA = cable_props.mA;
+		}
+	}
+
+	if (!otg_get_chrg_status(otg_xceiver, &cap))
+		process_cable_props(&cap);
+
+}
+
+static inline void get_cur_chrgr_prop(struct power_supply *psy,
+				      struct charger_props *chrgr_prop)
+{
+	chrgr_prop->is_charging = IS_CHARGING_ENABLED(psy);
+	chrgr_prop->name = psy->name;
+	chrgr_prop->online = IS_ONLINE(psy);
+	chrgr_prop->present = IS_PRESENT(psy);
+	chrgr_prop->cable = CABLE_TYPE(psy);
+	chrgr_prop->health = HEALTH(psy);
+	chrgr_prop->tstamp = get_jiffies_64();
+
+}
+
+static inline int get_chrgr_prop_cache(struct power_supply *psy,
+				       struct charger_props *chrgr_cache)
+{
+
+	struct charger_props *chrgr_prop;
+	int ret = -ENODEV;
+
+	list_for_each_entry(chrgr_prop, &psy_chrgr.chrgr_cache_lst, node) {
+		if (!strcmp(chrgr_prop->name, psy->name)) {
+			memcpy(chrgr_cache, chrgr_prop, sizeof(*chrgr_cache));
+			ret = 0;
+			break;
+		}
+	}
+
+	return ret;
+}
+
+static void dump_charger_props(struct charger_props *props)
+{
+	pr_devel("%s:name=%s present=%d is_charging=%d health=%d online=%d cable=%d tstamp=%d\n",
+		__func__, props->name, props->present, props->is_charging,
+		props->health, props->online, props->cable, props->tstamp);
+}
+
+static void dump_battery_props(struct batt_props *props)
+{
+	pr_devel("%s:name=%s voltage_now=%d current_now=%d temperature=%d status=%d health=%d tstamp=%d algo_stat=%d ",
+		__func__, props->name, props->voltage_now, props->current_now,
+		props->temperature, props->status, props->health,
+		props->tstamp, props->algo_stat);
+}
+
+static inline void cache_chrgr_prop(struct charger_props *chrgr_prop_new)
+{
+
+	struct charger_props *chrgr_cache;
+
+	list_for_each_entry(chrgr_cache, &psy_chrgr.chrgr_cache_lst, node) {
+		if (!strcmp(chrgr_cache->name, chrgr_prop_new->name))
+			goto update_props;
+	}
+
+	chrgr_cache = kzalloc(sizeof(*chrgr_cache), GFP_KERNEL);
+	if (chrgr_cache == NULL) {
+		pr_err("%s:%dError in allocating memory\n", __FILE__, __LINE__);
+		return;
+	}
+
+	INIT_LIST_HEAD(&chrgr_cache->node);
+	list_add_tail(&chrgr_cache->node, &psy_chrgr.chrgr_cache_lst);
+
+	chrgr_cache->name = chrgr_prop_new->name;
+
+update_props:
+	chrgr_cache->is_charging = chrgr_prop_new->is_charging;
+	chrgr_cache->online = chrgr_prop_new->online;
+	chrgr_cache->health = chrgr_prop_new->health;
+	chrgr_cache->present = chrgr_prop_new->present;
+	chrgr_cache->cable = chrgr_prop_new->cable;
+	chrgr_cache->tstamp = chrgr_prop_new->tstamp;
+}
+
+
+static inline bool is_chrgr_prop_changed(struct power_supply *psy)
+{
+
+	struct charger_props chrgr_prop_cache, chrgr_prop;
+
+	get_cur_chrgr_prop(psy, &chrgr_prop);
+	/* Get cached battery property. If no cached property available
+	 *  then cache the new property and return true
+	 */
+	if (get_chrgr_prop_cache(psy, &chrgr_prop_cache)) {
+		cache_chrgr_prop(&chrgr_prop);
+		return true;
+	}
+
+	pr_devel("%s\n", __func__);
+	dump_charger_props(&chrgr_prop);
+	dump_charger_props(&chrgr_prop_cache);
+
+	if (!IS_CHARGER_PROP_CHANGED(chrgr_prop, chrgr_prop_cache))
+		return false;
+
+	cache_chrgr_prop(&chrgr_prop);
+	return true;
+}
+static void cache_successive_samples(long *sample_array, long new_sample)
+{
+
+	int i;
+
+	for (i = 0; i < MAX_CUR_VOLT_SAMPLES - 1; ++i)
+		*(sample_array + i) = *(sample_array + i + 1);
+
+	*(sample_array + i) = new_sample;
+
+}
+
+static inline void cache_bat_prop(struct batt_props *bat_prop_new)
+{
+
+	struct batt_props *bat_cache;
+
+	/* Find entry in cache list. If an entry is located update
+	 * the existing entry else create new entry in the list */
+	list_for_each_entry(bat_cache, &psy_chrgr.batt_cache_lst, node) {
+		if (!strcmp(bat_cache->name, bat_prop_new->name))
+			goto update_props;
+	}
+
+	bat_cache = kzalloc(sizeof(*bat_cache), GFP_KERNEL);
+	if (bat_cache == NULL) {
+		pr_err("%s:%dError in allocating memory\n", __FILE__, __LINE__);
+		return;
+	}
+	INIT_LIST_HEAD(&bat_cache->node);
+	list_add_tail(&bat_cache->node, &psy_chrgr.batt_cache_lst);
+
+	bat_cache->name = bat_prop_new->name;
+
+update_props:
+	if (time_after(bat_prop_new->tstamp,
+		(bat_cache->tstamp + DEF_CUR_VOLT_SAMPLE_JIFF)) ||
+						bat_cache->tstamp == 0) {
+		cache_successive_samples(bat_cache->voltage_now_cache,
+						bat_prop_new->voltage_now);
+		cache_successive_samples(bat_cache->current_now_cache,
+						bat_prop_new->current_now);
+		bat_cache->tstamp = bat_prop_new->tstamp;
+	}
+
+	bat_cache->voltage_now = bat_prop_new->voltage_now;
+	bat_cache->current_now = bat_prop_new->current_now;
+	bat_cache->health = bat_prop_new->health;
+
+	bat_cache->temperature = bat_prop_new->temperature;
+	bat_cache->status = bat_prop_new->status;
+	bat_cache->algo_stat = bat_prop_new->algo_stat;
+	bat_cache->throttle_state = bat_prop_new->throttle_state;
+}
+
+static inline int get_bat_prop_cache(struct power_supply *psy,
+				     struct batt_props *bat_cache)
+{
+
+	struct batt_props *bat_prop;
+	int ret = -ENODEV;
+
+	list_for_each_entry(bat_prop, &psy_chrgr.batt_cache_lst, node) {
+		if (!strcmp(bat_prop->name, psy->name)) {
+			memcpy(bat_cache, bat_prop, sizeof(*bat_cache));
+			ret = 0;
+			break;
+		}
+	}
+
+	return ret;
+}
+
+static inline void get_cur_bat_prop(struct power_supply *psy,
+				    struct batt_props *bat_prop)
+{
+	struct batt_props bat_prop_cache;
+	int ret;
+
+	bat_prop->name = psy->name;
+	bat_prop->voltage_now = VOLTAGE_OCV(psy) / 1000;
+	bat_prop->current_now = CURRENT_NOW(psy) / 1000;
+	bat_prop->temperature = TEMPERATURE(psy) / 10;
+	bat_prop->status = STATUS(psy);
+	bat_prop->health = HEALTH(psy);
+	bat_prop->tstamp = get_jiffies_64();
+	bat_prop->throttle_state = CURRENT_THROTTLE_STATE(psy);
+
+	/* Populate cached algo data to new profile */
+	ret = get_bat_prop_cache(psy, &bat_prop_cache);
+	if (!ret)
+		bat_prop->algo_stat = bat_prop_cache.algo_stat;
+}
+
+static inline bool is_batt_prop_changed(struct power_supply *psy)
+{
+
+	struct batt_props bat_prop_cache, bat_prop;
+
+	/* Get cached battery property. If no cached property available
+	 *  then cache the new property and return true
+	 */
+	get_cur_bat_prop(psy, &bat_prop);
+	if (get_bat_prop_cache(psy, &bat_prop_cache)) {
+		cache_bat_prop(&bat_prop);
+		return true;
+	}
+
+	pr_devel("%s\n", __func__);
+	dump_battery_props(&bat_prop);
+	dump_battery_props(&bat_prop_cache);
+
+	if (!IS_BAT_PROP_CHANGED(bat_prop, bat_prop_cache))
+		return false;
+
+	cache_bat_prop(&bat_prop);
+	return true;
+}
+
+static inline bool is_supplied_to_has_ext_pwr_changed(struct power_supply *psy)
+{
+	int i;
+	struct power_supply *psb;
+	bool is_pwr_changed_defined = true;
+
+	for (i = 0; i < psy->num_supplicants; i++) {
+		psb =
+		    power_supply_get_by_name(psy->
+					     supplied_to[i]);
+		if (psb && !psb->external_power_changed)
+			is_pwr_changed_defined &= false;
+	}
+
+	return is_pwr_changed_defined;
+
+}
+
+static inline bool is_supplied_by_changed(struct power_supply *psy)
+{
+
+	int cnt;
+	struct power_supply *chrgr_lst[MAX_CHARGER_COUNT];
+
+	cnt = get_supplied_by_list(psy, chrgr_lst);
+	while (cnt--) {
+		if ((IS_CHARGER(chrgr_lst[cnt])) &&
+			is_chrgr_prop_changed(chrgr_lst[cnt]))
+			return true;
+	}
+
+	return false;
+}
+
+static inline bool is_trigger_charging_algo(struct power_supply *psy)
+{
+
+	/* trigger charging alorithm if battery or
+	 * charger properties are changed. Also no need to
+	 * invoke algorithm for power_supply_changed from
+	 * charger, if all supplied_to has the ext_port_changed defined.
+	 * On invoking the ext_port_changed the supplied to can send
+	 * power_supplied_changed event.
+	 */
+
+	if ((IS_CHARGER(psy) && !is_supplied_to_has_ext_pwr_changed(psy)) &&
+			is_chrgr_prop_changed(psy))
+		return true;
+
+	if ((IS_BATTERY(psy)) && (is_batt_prop_changed(psy) ||
+				is_supplied_by_changed(psy)))
+		return true;
+
+	return false;
+}
+
+static int get_supplied_by_list(struct power_supply *psy,
+				struct power_supply *psy_lst[])
+{
+	struct class_dev_iter iter;
+	struct device *dev;
+	struct power_supply *pst;
+	int cnt = 0, i, j;
+
+	if (!IS_BATTERY(psy))
+		return 0;
+
+	/* Identify chargers which are supplying power to the battery */
+	class_dev_iter_init(&iter, power_supply_class, NULL, NULL);
+	while ((dev = class_dev_iter_next(&iter))) {
+		pst = (struct power_supply *)dev_get_drvdata(dev);
+		if (!IS_CHARGER(pst))
+			continue;
+		for (i = 0; i < pst->num_supplicants; i++) {
+			if (!strcmp(pst->supplied_to[i], psy->name))
+				psy_lst[cnt++] = pst;
+		}
+	}
+	class_dev_iter_exit(&iter);
+
+	if (cnt <= 1)
+		return cnt;
+
+	/*sort based on priority. 0 has the highest priority  */
+	for (i = 0; i < cnt; ++i)
+		for (j = 0; j < cnt; ++j)
+			if (PRIORITY(psy_lst[j]) > PRIORITY(psy_lst[i]))
+				swap(psy_lst[j], psy_lst[i]);
+
+	return cnt;
+}
+
+static int get_battery_status(struct power_supply *psy)
+{
+	int cnt, status, ret;
+	struct power_supply *chrgr_lst[MAX_CHARGER_COUNT];
+	struct batt_props bat_prop;
+
+	if (!IS_BATTERY(psy))
+		return -EINVAL;
+
+	ret = get_bat_prop_cache(psy, &bat_prop);
+	if (ret)
+		return ret;
+
+	status = POWER_SUPPLY_STATUS_DISCHARGING;
+	cnt = get_supplied_by_list(psy, chrgr_lst);
+
+
+	while (cnt--) {
+
+
+		if (IS_PRESENT(chrgr_lst[cnt]))
+			status = POWER_SUPPLY_STATUS_NOT_CHARGING;
+
+		if (IS_CHARGING_CAN_BE_ENABLED(chrgr_lst[cnt]) &&
+			(IS_HEALTH_GOOD(psy)) &&
+				(IS_HEALTH_GOOD(chrgr_lst[cnt]))) {
+
+			if ((bat_prop.algo_stat == PSY_ALGO_STAT_FULL) ||
+				(bat_prop.algo_stat == PSY_ALGO_STAT_MAINT))
+				status = POWER_SUPPLY_STATUS_FULL;
+			else if (IS_CHARGING_ENABLED(chrgr_lst[cnt]))
+				status = POWER_SUPPLY_STATUS_CHARGING;
+		}
+	}
+	pr_devel("%s: Set status=%d for %s\n", __func__, status, psy->name);
+
+	return status;
+}
+
+static void update_charger_online(struct power_supply *psy)
+{
+	if (IS_CHARGER_ENABLED(psy))
+		set_charger_online(psy, 1);
+	else
+		set_charger_online(psy, 0);
+}
+
+static void update_sysfs(struct power_supply *psy)
+{
+	int i, cnt;
+	struct power_supply *psb;
+	struct power_supply *chrgr_lst[MAX_CHARGER_COUNT];
+
+	if (IS_BATTERY(psy)) {
+		/* set battery status */
+		set_battery_status(psy, get_battery_status(psy));
+
+		/* set charger online */
+		cnt = get_supplied_by_list(psy, chrgr_lst);
+		while (cnt--) {
+			if (!IS_PRESENT(chrgr_lst[cnt]))
+				continue;
+
+			update_charger_online(psy);
+		}
+	} else {
+		/*set battery status */
+		for (i = 0; i < psy->num_supplicants; i++) {
+			psb =
+			    power_supply_get_by_name(psy->
+						     supplied_to[i]);
+			if (psb && IS_BATTERY(psb) && IS_PRESENT(psb))
+				set_battery_status(psb,
+					get_battery_status(psb));
+		}
+
+		/*set charger online */
+		update_charger_online(psy);
+
+	}
+}
+
+static int trigger_algo(struct power_supply *psy)
+{
+	unsigned long cc = 0, cv = 0, cc_min;
+	struct power_supply *chrgr_lst[MAX_CHARGER_COUNT];
+	struct batt_props bat_prop;
+	struct charging_algo *algo;
+	struct ps_batt_chg_prof chrg_profile;
+	int cnt;
+
+
+	if (psy->type != POWER_SUPPLY_TYPE_BATTERY)
+		return 0;
+
+	if (get_batt_prop(&chrg_profile)) {
+		pr_err("Error in getting charge profile:%s:%d\n", __FILE__,
+		       __LINE__);
+		return -EINVAL;
+	}
+
+
+	get_bat_prop_cache(psy, &bat_prop);
+
+	algo = power_supply_get_charging_algo(psy, &chrg_profile);
+	if (!algo) {
+		pr_err("Error in getting charging algo!!\n");
+		return -EINVAL;
+	}
+
+	bat_prop.algo_stat = algo->get_next_cc_cv(bat_prop,
+						chrg_profile, &cc, &cv);
+
+	switch (bat_prop.algo_stat) {
+	case PSY_ALGO_STAT_CHARGE:
+		pr_devel("%s:Algo_status: Charging Enabled\n", __func__);
+		break;
+	case PSY_ALGO_STAT_FULL:
+		pr_devel("%s:Algo_status: Battery is Full\n", __func__);
+		break;
+	case PSY_ALGO_STAT_MAINT:
+		pr_devel("%s:Algo_status: Maintenance charging started\n",
+			__func__);
+		break;
+	case PSY_ALGO_STAT_UNKNOWN:
+		pr_devel("%s:Algo Status: unknown\n", __func__);
+		break;
+	case PSY_ALGO_STAT_NOT_CHARGE:
+		pr_devel("%s:Algo Status: charging not enabled\n",
+			__func__);
+		break;
+	}
+
+	cache_bat_prop(&bat_prop);
+
+	if (!cc || !cv)
+		return -ENODATA;
+
+	/* CC needs to be updated for all chargers which are supplying
+	 *  power to this battery to ensure that the sum of CCs of all
+	 * chargers are never more than the CC selected by the algo.
+	 * The CC is set based on the charger priority.
+	 */
+	cnt = get_supplied_by_list(psy, chrgr_lst);
+
+	while (cnt--) {
+		if (!IS_PRESENT(chrgr_lst[cnt]))
+			continue;
+
+		cc_min = min_t(unsigned long, MAX_CC(chrgr_lst[cnt]), cc);
+		if (cc_min < 0)
+			cc_min = 0;
+		cc -= cc_min;
+		set_cc(chrgr_lst[cnt], cc_min);
+		set_cv(chrgr_lst[cnt], cv);
+	}
+
+	return 0;
+}
+
+static inline void wait_for_charging_enabled(struct power_supply *psy)
+{
+	wait_event_timeout(psy_chrgr.wait_chrg_enable,
+			(IS_CHARGING_ENABLED(psy)), HZ);
+}
+
+static inline void enable_supplied_by_charging
+		(struct power_supply *psy, bool is_enable)
+{
+	struct power_supply *chrgr_lst[MAX_CHARGER_COUNT];
+	int cnt;
+
+	if (psy->type != POWER_SUPPLY_TYPE_BATTERY)
+		return;
+	/* Get list of chargers supplying power to this battery and
+	 * disable charging for all chargers
+	 */
+	cnt = get_supplied_by_list(psy, chrgr_lst);
+	if (cnt == 0)
+		return;
+	while (cnt--) {
+		if (!IS_PRESENT(chrgr_lst[cnt]))
+			continue;
+		if (is_enable && IS_CHARGING_CAN_BE_ENABLED(chrgr_lst[cnt])) {
+			enable_charging(chrgr_lst[cnt]);
+			wait_for_charging_enabled(chrgr_lst[cnt]);
+		} else
+			disable_charging(chrgr_lst[cnt]);
+	}
+}
+
+static void __power_supply_trigger_charging_handler(struct power_supply *psy)
+{
+	int i;
+	struct power_supply *psb = NULL;
+
+
+	mutex_lock(&psy_chrgr.evt_lock);
+
+	if (is_trigger_charging_algo(psy)) {
+
+		if (IS_BATTERY(psy)) {
+			if (trigger_algo(psy))
+				enable_supplied_by_charging(psy, false);
+			else
+				enable_supplied_by_charging(psy, true);
+
+		} else if (IS_CHARGER(psy)) {
+			for (i = 0; i < psy->num_supplicants; i++) {
+				psb =
+				    power_supply_get_by_name(psy->
+							     supplied_to[i]);
+
+				if (psb && IS_BATTERY(psb) && IS_PRESENT(psb)) {
+					if (trigger_algo(psb)) {
+						disable_charging(psy);
+						break;
+					} else if (IS_CHARGING_CAN_BE_ENABLED
+								(psy)) {
+						enable_charging(psy);
+						wait_for_charging_enabled(psy);
+					}
+				}
+			}
+		}
+		update_sysfs(psy);
+		power_supply_changed(psy);
+	}
+	mutex_unlock(&psy_chrgr.evt_lock);
+
+}
+
+static int __trigger_charging_handler(struct device *dev, void *data)
+{
+	struct power_supply *psy = dev_get_drvdata(dev);
+
+
+	__power_supply_trigger_charging_handler(psy);
+
+	return 0;
+}
+
+static void trigger_algo_psy_class(struct work_struct *work)
+{
+
+	class_for_each_device(power_supply_class, NULL, NULL,
+			__trigger_charging_handler);
+
+}
+
+static bool is_cable_connected(void)
+{
+	int i;
+	struct charger_cable *cable;
+
+	for (i = 0; i < ARRAY_SIZE(cable_list); ++i) {
+		cable = cable_list + i;
+		if (IS_CABLE_ACTIVE(cable->cable_props.cable_stat))
+			return true;
+	}
+	return false;
+}
+
+void power_supply_trigger_charging_handler(struct power_supply *psy)
+{
+
+	if (!psy_chrgr.is_cable_evt_reg || !is_cable_connected())
+		return;
+
+	wake_up(&psy_chrgr.wait_chrg_enable);
+
+	if (psy)
+		__power_supply_trigger_charging_handler(psy);
+	else
+		schedule_work(&psy_chrgr.algo_trigger_work);
+
+}
+EXPORT_SYMBOL(power_supply_trigger_charging_handler);
+
+static inline int get_battery_thresholds(struct power_supply *psy,
+	struct psy_batt_thresholds *bat_thresh)
+{
+	struct charging_algo *algo;
+	struct ps_batt_chg_prof chrg_profile;
+
+
+	/* FIXME: Get iterm only for supplied_to arguments*/
+	if (get_batt_prop(&chrg_profile)) {
+		pr_err("Error in getting charge profile:%s:%d\n", __FILE__,
+		       __LINE__);
+		return -EINVAL;
+	}
+
+	algo = power_supply_get_charging_algo(psy, &chrg_profile);
+	if (!algo) {
+		pr_err("Error in getting charging algo!!\n");
+		return -EINVAL;
+	}
+
+	if (algo->get_batt_thresholds) {
+		algo->get_batt_thresholds(chrg_profile, bat_thresh);
+	} else {
+		pr_err("Error in getting battery thresholds from %s:%s\n",
+			algo->name, __func__);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static int select_chrgr_cable(struct device *dev, void *data)
+{
+	struct power_supply *psy = dev_get_drvdata(dev);
+	struct charger_cable *cable, *max_mA_cable = NULL;
+	struct charger_cable *cable_lst = (struct charger_cable *)data;
+	unsigned int max_mA = 0, iterm;
+	int i;
+
+	if (!IS_CHARGER(psy))
+		return 0;
+
+	mutex_lock(&psy_chrgr.evt_lock);
+
+	/* get cable with maximum capability */
+	for (i = 0; i < ARRAY_SIZE(cable_list); ++i) {
+		cable = cable_lst + i;
+		if ((!IS_CABLE_ACTIVE(cable->cable_props.cable_stat)) ||
+		    (!IS_SUPPORTED_CABLE(psy, cable->psy_cable_type)))
+			continue;
+
+		if (cable->cable_props.mA > max_mA) {
+			max_mA_cable = cable;
+			max_mA = cable->cable_props.mA;
+		}
+	}
+
+	/* no cable connected. disable charging */
+	if (!max_mA_cable) {
+
+		if ((IS_CHARGER_ENABLED(psy) || IS_CHARGING_ENABLED(psy))) {
+			disable_charging(psy);
+			disable_charger(psy);
+		}
+		set_cc(psy, 0);
+		set_cv(psy, 0);
+		set_inlmt(psy, 0);
+
+		/* set present and online as 0 */
+		set_present(psy, 0);
+		update_charger_online(psy);
+
+		switch_cable(psy, POWER_SUPPLY_CHARGER_TYPE_NONE);
+
+		mutex_unlock(&psy_chrgr.evt_lock);
+		power_supply_changed(psy);
+		return 0;
+	}
+
+	/* cable type changed.New cable connected or existing cable
+	 * capabilities changed.switch cable and enable charger and charging
+	 */
+	set_present(psy, 1);
+
+	if (CABLE_TYPE(psy) != max_mA_cable->psy_cable_type)
+		switch_cable(psy, max_mA_cable->psy_cable_type);
+
+	if (IS_CHARGER_CAN_BE_ENABLED(psy)) {
+		struct psy_batt_thresholds bat_thresh;
+		memset(&bat_thresh, 0, sizeof(bat_thresh));
+		enable_charger(psy);
+
+		update_charger_online(psy);
+
+		set_inlmt(psy, max_mA_cable->cable_props.mA);
+		if (!get_battery_thresholds(psy, &bat_thresh)) {
+			SET_ITERM(psy, bat_thresh.iterm);
+			SET_MIN_TEMP(psy, bat_thresh.temp_min);
+			SET_MAX_TEMP(psy, bat_thresh.temp_max);
+		}
+
+	} else {
+
+		disable_charger(psy);
+		update_charger_online(psy);
+	}
+
+
+	mutex_unlock(&psy_chrgr.evt_lock);
+	power_supply_trigger_charging_handler(NULL);
+	/* Cable status is same as previous. No action to be taken */
+	return 0;
+
+}
+
+static void configure_chrgr_source(struct charger_cable *cable_lst)
+{
+
+	class_for_each_device(power_supply_class, NULL,
+			      cable_lst, select_chrgr_cable);
+
+}
+
+static void charger_cable_event_worker(struct work_struct *work)
+{
+	struct charger_cable *cable =
+	    container_of(work, struct charger_cable, work);
+	struct extcon_chrgr_cbl_props cable_props;
+
+	if (cable->edev->
+	    get_cable_properties(extcon_cable_name[cable->extcon_cable_type],
+				 (void *)&cable_props)) {
+		pr_err("Erron in getting cable(%s) properties from extcon device(%s):%s:%d",
+				extcon_cable_name[cable->extcon_cable_type],
+				cable->edev->name, __FILE__, __LINE__);
+		return;
+	} else {
+		if (cable_props.cable_stat != cable->cable_props.cable_stat) {
+			cable->cable_props.cable_stat = cable_props.cable_stat;
+			cable->cable_props.mA = cable_props.mA;
+			configure_chrgr_source(cable_list);
+		}
+	}
+
+}
+
+static int charger_cable_notifier(struct notifier_block *nb,
+				  unsigned long stat, void *ptr)
+{
+
+	struct charger_cable *cable =
+	    container_of(nb, struct charger_cable, nb);
+
+	schedule_work(&cable->work);
+
+	return NOTIFY_DONE | NOTIFY_STOP_MASK;
+}
+
+int psy_charger_throttle_charger(struct power_supply *psy,
+					unsigned long state)
+{
+	int ret = 0;
+
+	if (state < 0 || state > MAX_THROTTLE_STATE(psy))
+		return -EINVAL;
+
+	mutex_lock(&psy_chrgr.evt_lock);
+
+	switch THROTTLE_ACTION(psy, state)
+	{
+
+		case PSY_THROTTLE_DISABLE_CHARGER:
+			SET_MAX_CC(psy, 0);
+			disable_charger(psy);
+			break;
+		case PSY_THROTTLE_DISABLE_CHARGING:
+			SET_MAX_CC(psy, 0);
+			disable_charging(psy);
+			break;
+		case PSY_THROTTLE_CC_LIMIT:
+			SET_MAX_CC(psy, THROTTLE_CC_VALUE(psy, state));
+			break;
+		case PSY_THROTTLE_INPUT_LIMIT:
+			set_inlmt(psy, THROTTLE_CC_VALUE(psy, state));
+			break;
+		default:
+			pr_err("Invalid throttle action for %s\n", psy->name);
+			ret = -EINVAL;
+			break;
+	}
+	mutex_unlock(&psy_chrgr.evt_lock);
+
+	/* Configure the driver based on new state */
+	if (!ret)
+		configure_chrgr_source(cable_list);
+	return ret;
+}
+EXPORT_SYMBOL(psy_charger_throttle_charger);
+
+int power_supply_register_charger(struct power_supply *psy)
+{
+	int ret = 0;
+
+	if (!psy_chrgr.is_cable_evt_reg) {
+		mutex_init(&psy_chrgr.evt_lock);
+		init_waitqueue_head(&psy_chrgr.wait_chrg_enable);
+		init_charger_cables(cable_list, ARRAY_SIZE(cable_list));
+		INIT_LIST_HEAD(&psy_chrgr.chrgr_cache_lst);
+		INIT_LIST_HEAD(&psy_chrgr.batt_cache_lst);
+		INIT_WORK(&psy_chrgr.algo_trigger_work, trigger_algo_psy_class);
+		psy_chrgr.is_cable_evt_reg = true;
+	}
+	return ret;
+}
+EXPORT_SYMBOL(power_supply_register_charger);
+
+static inline void flush_charger_context(struct power_supply *psy)
+{
+	struct charger_props *chrgr_prop, *tmp;
+
+
+	list_for_each_entry_safe(chrgr_prop, tmp,
+				&psy_chrgr.chrgr_cache_lst, node) {
+		if (!strcmp(chrgr_prop->name, psy->name)) {
+			list_del(&chrgr_prop->node);
+			kfree(chrgr_prop);
+		}
+	}
+}
+int power_supply_unregister_charger(struct power_supply *psy)
+{
+	flush_charger_context(psy);
+	return 0;
+}
+EXPORT_SYMBOL(power_supply_unregister_charger);
+
+int power_supply_register_charging_algo(struct charging_algo *algo)
+{
+
+	struct charging_algo *algo_new;
+
+	algo_new = kzalloc(sizeof(*algo_new), GFP_KERNEL);
+	if (algo_new == NULL) {
+		pr_err("%s: Error allocating memory for algo!!", __func__);
+		return -1;
+	}
+	memcpy(algo_new, algo, sizeof(*algo_new));
+
+	list_add_tail(&algo_new->node, &algo_list);
+	return 0;
+}
+EXPORT_SYMBOL(power_supply_register_charging_algo);
+
+int power_supply_unregister_charging_algo(struct charging_algo *algo)
+{
+	struct charging_algo *algo_l, *tmp;
+
+	list_for_each_entry_safe(algo_l, tmp, &algo_list, node) {
+		if (!strcmp(algo_l->name, algo->name)) {
+			list_del(&algo_l->node);
+			kfree(algo_l);
+		}
+	}
+	return 0;
+
+}
+EXPORT_SYMBOL(power_supply_unregister_charging_algo);
+
+static struct charging_algo *get_charging_algo_byname(char *algo_name)
+{
+	struct charging_algo *algo;
+
+	list_for_each_entry(algo, &algo_list, node) {
+		if (!strcmp(algo->name, algo_name))
+			return algo;
+	}
+
+	return NULL;
+}
+
+static struct charging_algo *get_charging_algo_by_type
+		(enum batt_chrg_prof_type chrg_prof_type)
+{
+	struct charging_algo *algo;
+
+	list_for_each_entry(algo, &algo_list, node) {
+		if (algo->chrg_prof_type == chrg_prof_type)
+			return algo;
+	}
+
+	return NULL;
+}
+
+struct charging_algo *power_supply_get_charging_algo
+	(struct power_supply *psy, struct ps_batt_chg_prof *batt_prof)
+{
+
+	return get_charging_algo_by_type(batt_prof->chrg_prof_type);
+
+}
+EXPORT_SYMBOL_GPL(power_supply_get_charging_algo);
diff --git a/drivers/power/power_supply_charger.h b/drivers/power/power_supply_charger.h
new file mode 100644
index 0000000..81324a4
--- /dev/null
+++ b/drivers/power/power_supply_charger.h
@@ -0,0 +1,244 @@
+
+#ifndef __POWER_SUPPLY_CHARGER_H__
+
+#define __POWER_SUPPLY_CHARGER_H__
+#include <linux/power/battery_id.h>
+#include <linux/power_supply.h>
+
+#define MAX_CUR_VOLT_SAMPLES 3
+#define DEF_CUR_VOLT_SAMPLE_JIFF (30*HZ)
+
+enum psy_algo_stat {
+	PSY_ALGO_STAT_UNKNOWN,
+	PSY_ALGO_STAT_NOT_CHARGE,
+	PSY_ALGO_STAT_CHARGE,
+	PSY_ALGO_STAT_FULL,
+	PSY_ALGO_STAT_MAINT,
+};
+
+struct batt_props {
+	struct list_head node;
+	const char *name;
+	long voltage_now;
+	long voltage_now_cache[MAX_CUR_VOLT_SAMPLES];
+	long current_now;
+	long current_now_cache[MAX_CUR_VOLT_SAMPLES];
+	int temperature;
+	long status;
+	unsigned long tstamp;
+	enum psy_algo_stat algo_stat;
+	int health;
+	int throttle_state;
+};
+
+struct charger_props {
+	struct list_head node;
+	const char *name;
+	bool present;
+	bool is_charging;
+	int health;
+	bool online;
+	unsigned long cable;
+	unsigned long tstamp;
+};
+
+struct psy_batt_thresholds {
+	int temp_min;
+	int temp_max;
+	unsigned int iterm;
+};
+
+struct charging_algo {
+	struct list_head node;
+	unsigned int chrg_prof_type;
+	char *name;
+	enum psy_algo_stat (*get_next_cc_cv)(struct batt_props,
+			struct ps_batt_chg_prof, unsigned long *cc,
+			unsigned long *cv);
+	int (*get_batt_thresholds)(struct ps_batt_chg_prof,
+			struct psy_batt_thresholds *bat_thr);
+};
+
+
+extern int power_supply_register_charging_algo(struct charging_algo *);
+extern int power_supply_unregister_charging_algo(struct charging_algo *);
+
+static inline int set_ps_int_property(struct power_supply *psy,
+				      enum power_supply_property psp,
+				      int prop_val)
+{
+
+	union power_supply_propval val;
+
+	val.intval = prop_val;
+	return psy->set_property(psy, psp, &val);
+}
+
+static inline int get_ps_int_property(struct power_supply *psy,
+				      enum power_supply_property psp)
+{
+	union power_supply_propval val;
+
+	val.intval = 0;
+
+	psy->get_property(psy, psp, &val);
+	return val.intval;
+}
+/* Define a TTL for some properies to optimize the frequency of
+* algorithm calls. This can be used by properties which will be changed
+* very frequently (eg. current, volatge..)
+*/
+#define PROP_TTL (HZ*10)
+#define enable_charging(psy) \
+		({if ((CABLE_TYPE(psy) != POWER_SUPPLY_CHARGER_TYPE_NONE) &&\
+			!IS_CHARGING_ENABLED(psy)) { \
+		enable_charger(psy); \
+		set_ps_int_property(psy, POWER_SUPPLY_PROP_ENABLE_CHARGING,\
+					true); } })
+#define disable_charging(psy) \
+		set_ps_int_property(psy,\
+				POWER_SUPPLY_PROP_ENABLE_CHARGING, false);
+
+#define enable_charger(psy) \
+		set_ps_int_property(psy, POWER_SUPPLY_PROP_ENABLE_CHARGER, true)
+#define disable_charger(psy) \
+		({  disable_charging(psy); \
+			set_ps_int_property(psy,\
+				POWER_SUPPLY_PROP_ENABLE_CHARGER, false); })
+
+#define set_cc(psy, cc) \
+		set_ps_int_property(psy, POWER_SUPPLY_PROP_CHARGE_CURRENT, cc)
+
+#define set_cv(psy, cv) \
+		set_ps_int_property(psy, POWER_SUPPLY_PROP_CHARGE_VOLTAGE, cv)
+
+#define set_inlmt(psy, inlmt) \
+		set_ps_int_property(psy, POWER_SUPPLY_PROP_INLMT, inlmt)
+
+#define set_present(psy, present) \
+		set_ps_int_property(psy, POWER_SUPPLY_PROP_PRESENT, present)
+
+#define SET_MAX_CC(psy, max_cc) \
+		set_ps_int_property(psy,\
+				POWER_SUPPLY_PROP_MAX_CHARGE_CURRENT, max_cc)
+#define SET_ITERM(psy, iterm) \
+		set_ps_int_property(psy,\
+				POWER_SUPPLY_PROP_CHARGE_TERM_CUR, iterm)
+#define SET_MAX_TEMP(psy, temp) \
+		set_ps_int_property(psy,\
+				POWER_SUPPLY_PROP_MAX_TEMP, temp)
+#define SET_MIN_TEMP(psy, temp) \
+		set_ps_int_property(psy,\
+				POWER_SUPPLY_PROP_MIN_TEMP, temp)
+#define switch_cable(psy, new_cable) \
+		set_ps_int_property(psy,\
+				POWER_SUPPLY_PROP_CABLE_TYPE, new_cable)
+
+#define HEALTH(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_HEALTH)
+#define CV(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_CHARGE_VOLTAGE)
+#define CC(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_CHARGE_CURRENT)
+#define INLMT(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_INLMT)
+#define MAX_CC(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_MAX_CHARGE_CURRENT)
+#define MAX_CV(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_MAX_CHARGE_VOLTAGE)
+#define VOLTAGE_NOW(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_VOLTAGE_NOW)
+#define VOLTAGE_OCV(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_VOLTAGE_OCV)
+#define CURRENT_NOW(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_CURRENT_NOW)
+#define STATUS(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_STATUS)
+#define TEMPERATURE(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_TEMP)
+#define BATTERY_TYPE(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_TECHNOLOGY)
+#define PRIORITY(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_PRIORITY)
+#define CABLE_TYPE(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_CABLE_TYPE)
+#define ONLINE(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_ONLINE)
+
+#define IS_CHARGING_ENABLED(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_ENABLE_CHARGING)
+#define IS_CHARGER_ENABLED(psy) \
+		get_ps_int_property(psy, POWER_SUPPLY_PROP_ENABLE_CHARGER)
+#define IS_BATTERY(psy) (psy->type == POWER_SUPPLY_TYPE_BATTERY)
+#define IS_CHARGER(psy) (psy->type == POWER_SUPPLY_TYPE_USB ||\
+				psy->type == POWER_SUPPLY_TYPE_USB_CDP || \
+			psy->type == POWER_SUPPLY_TYPE_USB_DCP ||\
+			psy->type == POWER_SUPPLY_TYPE_USB_ACA)
+#define IS_ONLINE(psy) \
+		(get_ps_int_property(psy, POWER_SUPPLY_PROP_ONLINE) == 1)
+#define IS_PRESENT(psy) \
+		(get_ps_int_property(psy, POWER_SUPPLY_PROP_PRESENT) == 1)
+#define IS_SUPPORTED_CABLE(psy, cable_type) \
+		(psy->supported_cables & cable_type)
+#define IS_CABLE_ACTIVE(status) \
+	(!((status == EXTCON_CHRGR_CABLE_DISCONNECTED) ||\
+			(status == EXTCON_CHRGR_CABLE_SUSPENDED)))
+
+#define IS_CHARGER_PROP_CHANGED(prop, cache_prop)\
+	((cache_prop.online != prop.online) || \
+	(cache_prop.present != prop.present) || \
+	(cache_prop.is_charging != prop.is_charging) || \
+	(cache_prop.health != prop.health))
+
+#define IS_BAT_PROP_CHANGED(bat_prop, bat_cache)\
+	((bat_cache.voltage_now != bat_prop.voltage_now) || \
+	(time_after64(bat_prop.tstamp, (bat_cache.tstamp + PROP_TTL)) &&\
+	((bat_cache.current_now != bat_prop.current_now) || \
+	(bat_cache.voltage_now != bat_prop.voltage_now))) || \
+	(bat_cache.temperature != bat_prop.temperature) || \
+	(bat_cache.health != bat_prop.health) || \
+	(bat_cache.throttle_state != bat_prop.throttle_state))
+
+#define THROTTLE_ACTION(psy, state)\
+		(((psy->throttle_states)+state)->throttle_action)
+
+#define MAX_THROTTLE_STATE(psy)\
+		((psy->num_throttle_states))
+
+#define CURRENT_THROTTLE_STATE(psy)\
+		(get_ps_int_property(psy,\
+			POWER_SUPPLY_PROP_CHARGE_CONTROL_LIMIT))
+
+#define CURRENT_THROTTLE_ACTION(psy)\
+		THROTTLE_ACTION(psy, CURRENT_THROTTLE_STATE(psy))
+
+#define THROTTLE_CC_VALUE(psy, state)\
+		(((psy->throttle_states)+state)->throttle_val)
+
+#define IS_CHARGING_CAN_BE_ENABLED(psy) \
+	((CURRENT_THROTTLE_ACTION(psy) != PSY_THROTTLE_DISABLE_CHARGER)  &&\
+	(CURRENT_THROTTLE_ACTION(psy) != PSY_THROTTLE_DISABLE_CHARGING))
+#define IS_CHARGER_CAN_BE_ENABLED(psy) \
+	(CURRENT_THROTTLE_ACTION(psy) != PSY_THROTTLE_DISABLE_CHARGER)
+
+#define IS_HEALTH_GOOD(psy)\
+	(HEALTH(psy) == POWER_SUPPLY_HEALTH_GOOD)
+
+static inline void set_battery_status(struct power_supply *psy, int status)
+{
+
+	if (STATUS(psy) != status)
+		set_ps_int_property(psy, POWER_SUPPLY_PROP_STATUS, status);
+
+
+}
+
+static inline void set_charger_online(struct power_supply *psy, int online)
+{
+
+	if (ONLINE(psy) != online)
+		set_ps_int_property(psy, POWER_SUPPLY_PROP_ONLINE, online);
+
+}
+
+#endif
diff --git a/drivers/power/power_supply_core.c b/drivers/power/power_supply_core.c
index 2660664..a3bbe0a 100644
--- a/drivers/power/power_supply_core.c
+++ b/drivers/power/power_supply_core.c
@@ -20,6 +20,7 @@
 #include <linux/power_supply.h>
 #include <linux/thermal.h>
 #include "power_supply.h"
+#include "power_supply_charger.h"
 
 /* exported for the APM Power driver, APM emulation */
 struct class *power_supply_class;
@@ -30,6 +31,13 @@ EXPORT_SYMBOL_GPL(power_supply_notifier);
 
 static struct device_type power_supply_dev_type;
 
+static struct mutex ps_chrg_evt_lock;
+
+static struct power_supply_charger_cap power_supply_chrg_cap = {
+		.chrg_evt	= POWER_SUPPLY_CHARGER_EVENT_DISCONNECT,
+		.chrg_type	= POWER_SUPPLY_TYPE_USB,
+		.mA		= 0	/* 0 mA */
+};
 static bool __power_supply_is_supplied_by(struct power_supply *supplier,
 					 struct power_supply *supply)
 {
@@ -83,6 +91,9 @@ static void power_supply_changed_work(struct work_struct *work)
 		spin_unlock_irqrestore(&psy->changed_lock, flags);
 		class_for_each_device(power_supply_class, NULL, psy,
 				      __power_supply_changed_work);
+
+		power_supply_trigger_charging_handler(psy);
+
 		power_supply_update_leds(psy);
 		atomic_notifier_call_chain(&power_supply_notifier,
 				PSY_EVENT_PROP_CHANGED, psy);
@@ -103,6 +114,11 @@ void power_supply_changed(struct power_supply *psy)
 {
 	unsigned long flags;
 
+	if (psy == NULL) {
+		power_supply_trigger_charging_handler(psy);
+		return;
+	}
+
 	dev_dbg(psy->dev, "%s\n", __func__);
 
 	spin_lock_irqsave(&psy->changed_lock, flags);
@@ -113,6 +129,37 @@ void power_supply_changed(struct power_supply *psy)
 }
 EXPORT_SYMBOL_GPL(power_supply_changed);
 
+static int __power_supply_charger_event(struct device *dev, void *data)
+{
+	struct power_supply_charger_cap *cap =
+				(struct power_supply_charger_cap *)data;
+	struct power_supply *psy = dev_get_drvdata(dev);
+
+	if (psy->charging_port_changed)
+		psy->charging_port_changed(psy, cap);
+
+	return 0;
+}
+
+void power_supply_charger_event(struct power_supply_charger_cap cap)
+{
+	class_for_each_device(power_supply_class, NULL, &cap,
+				      __power_supply_charger_event);
+
+	mutex_lock(&ps_chrg_evt_lock);
+	memcpy(&power_supply_chrg_cap, &cap, sizeof(power_supply_chrg_cap));
+	mutex_unlock(&ps_chrg_evt_lock);
+}
+EXPORT_SYMBOL_GPL(power_supply_charger_event);
+
+void power_supply_query_charger_caps(struct power_supply_charger_cap *cap)
+{
+	mutex_lock(&ps_chrg_evt_lock);
+	memcpy(cap, &power_supply_chrg_cap, sizeof(power_supply_chrg_cap));
+	mutex_unlock(&ps_chrg_evt_lock);
+}
+EXPORT_SYMBOL_GPL(power_supply_query_charger_caps);
+
 #ifdef CONFIG_OF
 #include <linux/of.h>
 
@@ -300,12 +347,12 @@ int power_supply_is_system_supplied(void)
 	unsigned int count = 0;
 
 	error = class_for_each_device(power_supply_class, NULL, &count,
-				      __power_supply_is_system_supplied);
+					__power_supply_is_system_supplied);
 
 	/*
-	 * If no power class device was found at all, most probably we are
-	 * running on a desktop system, so assume we are on mains power.
-	 */
+	* If no power class device was found at all, most probably we are
+	* running on a desktop system, so assume we are on mains power.
+	*/
 	if (count == 0)
 		return 1;
 
@@ -313,6 +360,30 @@ int power_supply_is_system_supplied(void)
 }
 EXPORT_SYMBOL_GPL(power_supply_is_system_supplied);
 
+static int __power_supply_is_battery_connected(struct device *dev, void *data)
+{
+	union power_supply_propval ret = {0,};
+	struct power_supply *psy = dev_get_drvdata(dev);
+
+	if (psy->type == POWER_SUPPLY_TYPE_BATTERY) {
+		if (psy->get_property(psy, POWER_SUPPLY_PROP_PRESENT, &ret))
+			return 0;
+		if (ret.intval)
+			return ret.intval;
+	}
+	return 0;
+}
+
+int power_supply_is_battery_connected(void)
+{
+	int error;
+
+	error = class_for_each_device(power_supply_class, NULL, NULL,
+					__power_supply_is_battery_connected);
+	return error;
+}
+EXPORT_SYMBOL_GPL(power_supply_is_battery_connected);
+
 int power_supply_set_battery_charged(struct power_supply *psy)
 {
 	if (psy->type == POWER_SUPPLY_TYPE_BATTERY && psy->set_charged) {
@@ -399,7 +470,8 @@ static int power_supply_read_temp(struct thermal_zone_device *tzd,
 	union power_supply_propval val;
 	int ret;
 
-	WARN_ON(tzd == NULL);
+	if (WARN_ON(tzd == NULL))
+		return -EINVAL;
 	psy = tzd->devdata;
 	ret = psy->get_property(psy, POWER_SUPPLY_PROP_TEMP, &val);
 
@@ -446,6 +518,8 @@ static int ps_get_max_charge_cntl_limit(struct thermal_cooling_device *tcd,
 	union power_supply_propval val;
 	int ret;
 
+	if (WARN_ON(tcd == NULL))
+		return -EINVAL;
 	psy = tcd->devdata;
 	ret = psy->get_property(psy,
 		POWER_SUPPLY_PROP_CHARGE_CONTROL_LIMIT_MAX, &val);
@@ -462,6 +536,8 @@ static int ps_get_cur_chrage_cntl_limit(struct thermal_cooling_device *tcd,
 	union power_supply_propval val;
 	int ret;
 
+	if (WARN_ON(tcd == NULL))
+		return -EINVAL;
 	psy = tcd->devdata;
 	ret = psy->get_property(psy,
 		POWER_SUPPLY_PROP_CHARGE_CONTROL_LIMIT, &val);
@@ -478,11 +554,15 @@ static int ps_set_cur_charge_cntl_limit(struct thermal_cooling_device *tcd,
 	union power_supply_propval val;
 	int ret;
 
+	if (WARN_ON(tcd == NULL))
+		return -EINVAL;
 	psy = tcd->devdata;
 	val.intval = state;
 	ret = psy->set_property(psy,
 		POWER_SUPPLY_PROP_CHARGE_CONTROL_LIMIT, &val);
 
+	psy_charger_throttle_charger(psy, state);
+
 	return ret;
 }
 
@@ -588,10 +668,16 @@ int power_supply_register(struct device *parent, struct power_supply *psy)
 	if (rc)
 		goto create_triggers_failed;
 
+	if (IS_CHARGER(psy))
+		rc = power_supply_register_charger(psy);
+	if (rc)
+		goto charger_register_failed;
+
 	power_supply_changed(psy);
 
 	goto success;
 
+charger_register_failed:
 create_triggers_failed:
 	psy_unregister_cooler(psy);
 register_cooler_failed:
@@ -613,6 +699,9 @@ void power_supply_unregister(struct power_supply *psy)
 	cancel_work_sync(&psy->changed_work);
 	sysfs_remove_link(&psy->dev->kobj, "powers");
 	power_supply_remove_triggers(psy);
+	if (IS_CHARGER(psy))
+		power_supply_unregister_charger(psy);
+	power_supply_remove_triggers(psy);
 	psy_unregister_cooler(psy);
 	psy_unregister_thermal(psy);
 	device_init_wakeup(psy->dev, false);
@@ -629,6 +718,7 @@ static int __init power_supply_class_init(void)
 
 	power_supply_class->dev_uevent = power_supply_uevent;
 	power_supply_init_attrs(&power_supply_dev_type);
+	mutex_init(&ps_chrg_evt_lock);
 
 	return 0;
 }
diff --git a/drivers/regulator/Kconfig b/drivers/regulator/Kconfig
index 6a79328..8c43c1f 100644
--- a/drivers/regulator/Kconfig
+++ b/drivers/regulator/Kconfig
@@ -592,5 +592,9 @@ config REGULATOR_WM8994
 	  This driver provides support for the voltage regulators on the
 	  WM8994 CODEC.
 
+config REGULATOR_PMIC_BASIN_COVE
+	tristate "PMIC Basin Cove voltage regulator"
+	help
+	  This driver controls intel Basin Cove pmic voltage output regulator
 endif
 
diff --git a/drivers/regulator/Makefile b/drivers/regulator/Makefile
index 979f9dd..3161f19 100644
--- a/drivers/regulator/Makefile
+++ b/drivers/regulator/Makefile
@@ -2,6 +2,7 @@
 # Makefile for regulator drivers.
 #
 
+CFLAGS_pmic_basin_cove.o		:= -Werror
 
 obj-$(CONFIG_REGULATOR) += core.o dummy.o fixed-helper.o helpers.o devres.o
 obj-$(CONFIG_OF) += of_regulator.o
@@ -56,6 +57,7 @@ obj-$(CONFIG_REGULATOR_PFUZE100) += pfuze100-regulator.o
 obj-$(CONFIG_REGULATOR_TPS51632) += tps51632-regulator.o
 obj-$(CONFIG_REGULATOR_PCAP) += pcap-regulator.o
 obj-$(CONFIG_REGULATOR_PCF50633) += pcf50633-regulator.o
+obj-$(CONFIG_REGULATOR_PMIC_BASIN_COVE) += pmic_basin_cove.o
 obj-$(CONFIG_REGULATOR_RC5T583)  += rc5t583-regulator.o
 obj-$(CONFIG_REGULATOR_S2MPS11) += s2mps11.o
 obj-$(CONFIG_REGULATOR_S5M8767) += s5m8767.o
diff --git a/drivers/regulator/pmic_basin_cove.c b/drivers/regulator/pmic_basin_cove.c
new file mode 100644
index 0000000..6f23578
--- /dev/null
+++ b/drivers/regulator/pmic_basin_cove.c
@@ -0,0 +1,302 @@
+/*
+ * pmic_basin_cove.c - Merrifield regulator driver
+ * Copyright (c) 2013, Intel Corporation.
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/regulator/driver.h>
+#include <linux/regulator/intel_basin_cove_pmic.h>
+#include <linux/regulator/machine.h>
+
+#include <asm/intel_scu_pmic.h>
+
+/* Intel Voltage cntrl register parameters*/
+#define REG_ENA_STATUS_MASK	0x01
+#define REG_VSEL_MASK		0xc0
+#define VSEL_SHIFT		6
+
+#define REG_ON			0x01
+#define REG_OFF			0xfe
+
+const u16 reg_addr_offset[] = { VPROG1CNT_ADDR, VPROG2CNT_ADDR,
+					 VPROG3CNT_ADDR };
+
+/**
+* intel_pmic_reg_is_enabled - To check if the regulator is enabled
+* @rdev:    regulator_dev structure
+* @return value : 1 - Regulator is ON
+*			  :0 - Regulator is OFF
+*/
+static int intel_pmic_reg_is_enabled(struct regulator_dev *rdev)
+{
+	struct intel_pmic_info *pmic_info = rdev_get_drvdata(rdev);
+	u8 reg;
+	int ret;
+
+	/*FIXME: Is it ok to use the following IPC API*/
+	ret = intel_scu_ipc_ioread8(pmic_info->pmic_reg, &reg);
+	if (ret) {
+		dev_err(&rdev->dev,
+			"intel_scu_ipc_ioread8 returns error %08x\n", ret);
+		return ret;
+	}
+
+	return reg & REG_ENA_STATUS_MASK;
+}
+/**
+* intel_pmic_reg_enable - To enable the regulator
+* @rdev:    regulator_dev structure
+* @return value : 0 - Regulator enabling success
+*			:1 - Regulator enabling failed
+*/
+static int intel_pmic_reg_enable(struct regulator_dev *rdev)
+{
+	struct intel_pmic_info *pmic_info = rdev_get_drvdata(rdev);
+	u8  reg;
+	int ret;
+
+	ret = intel_scu_ipc_ioread8(pmic_info->pmic_reg, &reg);
+	if (ret) {
+		dev_err(&rdev->dev,
+			"intel_scu_ipc_ioread8 returns error %08x\n", ret);
+		return ret;
+	}
+	return intel_scu_ipc_iowrite8(pmic_info->pmic_reg, (reg | REG_ON));
+}
+/**
+* intel_pmic_reg_disable - To disable the regulator
+* @rdev:    regulator_dev structure
+* @return value :0 - Regulator disabling success
+*			:1 - Regulator disabling failed
+*/
+static int intel_pmic_reg_disable(struct regulator_dev *rdev)
+{
+	struct intel_pmic_info *pmic_info = rdev_get_drvdata(rdev);
+	u8  reg;
+	int ret;
+
+	ret = intel_scu_ipc_ioread8(pmic_info->pmic_reg, &reg);
+	if (ret) {
+		dev_err(&rdev->dev,
+			"intel_scu_ipc_ioread8 returns error %08x\n", ret);
+		return ret;
+	}
+	return intel_scu_ipc_iowrite8(pmic_info->pmic_reg,
+		(reg & REG_OFF));
+}
+/**
+* intel_pmic_reg_listvoltage - Return the voltage value,this is called
+*                                   from core framework
+* @rdev: regulator source
+* @index : passed on from core
+* @return value : Returns the value in micro volts.
+ */
+static int intel_pmic_reg_listvoltage(struct regulator_dev *rdev,
+								unsigned index)
+{
+	struct intel_pmic_info *pmic_info = rdev_get_drvdata(rdev);
+
+	if (index >= pmic_info->table_len) {
+		dev_err(&rdev->dev, "Index out of range in listvoltage\n");
+		return -EINVAL;
+	}
+	return pmic_info->table[index] * 1000;
+}
+/**
+* intel_pmic_reg_getvoltage - Return the current voltage value in  uV
+* @rdev:    regulator_dev structure
+*  @return value : Returns the voltage value.
+*/
+static int intel_pmic_reg_getvoltage(struct regulator_dev *rdev)
+{
+	struct intel_pmic_info *pmic_info = rdev_get_drvdata(rdev);
+	u8  reg, vsel;
+	int ret;
+
+	ret = intel_scu_ipc_ioread8(pmic_info->pmic_reg, &reg);
+	if (ret) {
+		dev_err(&rdev->dev,
+			"intel_scu_ipc_ioread8 returns error %08x\n", ret);
+		return ret;
+	}
+	vsel = (reg & REG_VSEL_MASK) >> VSEL_SHIFT;
+	if (vsel >= pmic_info->table_len) {
+		dev_err(&rdev->dev, "vsel value is out of range\n");
+		return -EINVAL;
+	}
+	dev_dbg(&rdev->dev, "Voltage value is %d mV\n",
+		pmic_info->table[vsel]);
+	return pmic_info->table[vsel] * 1000;
+}
+
+/**
+* intel_pmic_reg_setvoltage - Set voltage to the regulator
+* @rdev:    regulator_dev structure
+* @min_uV: Minimum required voltage in uV
+* @max_uV: Maximum acceptable voltage in uV
+* @selector: Voltage value passed back to core layer
+* Sets a voltage regulator to the desired output voltage
+* @return value : Returns 0 if success
+*			: Return error value on failure
+*/
+static int intel_pmic_reg_setvoltage(struct regulator_dev *rdev, int min_uV,
+					int max_uV, unsigned *selector)
+{
+	struct intel_pmic_info *pmic_info = rdev_get_drvdata(rdev);
+	int ret;
+	u8 reg, vsel;
+
+	for (vsel = 0; vsel < pmic_info->table_len; vsel++) {
+		int mV = pmic_info->table[vsel];
+		int uV = mV * 1000;
+		if (min_uV > uV || uV > max_uV)
+			continue;
+
+		*selector = vsel;
+		ret = intel_scu_ipc_ioread8(pmic_info->pmic_reg, &reg);
+		if (ret) {
+			dev_err(&rdev->dev,
+				"intel_scu_ipc_ioread8 error %08x\n", ret);
+			return ret;
+		}
+		reg &= ~REG_VSEL_MASK;
+		reg |= vsel << VSEL_SHIFT;
+		dev_dbg(&rdev->dev,
+			"intel_pmic_reg_setvoltage voltage: %u uV\n", uV);
+		return intel_scu_ipc_iowrite8(pmic_info->pmic_reg, reg);
+	}
+	return -EINVAL;
+}
+
+/* regulator_ops registration */
+static struct regulator_ops intel_pmic_ops = {
+	.is_enabled = intel_pmic_reg_is_enabled,
+	.enable = intel_pmic_reg_enable,
+	.disable = intel_pmic_reg_disable,
+	.get_voltage = intel_pmic_reg_getvoltage,
+	.set_voltage = intel_pmic_reg_setvoltage,
+	.list_voltage = intel_pmic_reg_listvoltage,
+};
+/**
+* struct regulator_desc - Regulator descriptor
+* Each regulator registered with the core is described with a structure of
+* this type.
+* @name: Identifying name for the regulator.
+* @id: Numerical identifier for the regulator.
+* @n_voltages: Number of selectors available for ops.list_voltage().
+* @ops: Regulator operations table.
+* @irq: Interrupt number for the regulator.
+* @type: Indicates if the regulator is a voltage or current regulator.
+* @owner: Module providing the regulator, used for refcounting.
+*/
+static struct regulator_desc intel_pmic_desc[] = {
+	{
+		.name = "vprog1",
+		.id = VPROG1,
+		.ops = &intel_pmic_ops,
+		.n_voltages = ARRAY_SIZE(VPROG1_VSEL_table),
+		.type = REGULATOR_VOLTAGE,
+		.owner = THIS_MODULE,
+	},
+	{
+		.name = "vprog2",
+		.id = VPROG2,
+		.ops = &intel_pmic_ops,
+		.n_voltages = ARRAY_SIZE(VPROG2_VSEL_table),
+		.type = REGULATOR_VOLTAGE,
+		.owner = THIS_MODULE,
+	},
+	{
+		.name = "vprog3",
+		.id = VPROG3,
+		.ops = &intel_pmic_ops,
+		.n_voltages = ARRAY_SIZE(VPROG3_VSEL_table),
+		.type = REGULATOR_VOLTAGE,
+		.owner = THIS_MODULE,
+	},
+};
+
+static int basin_cove_pmic_probe(struct platform_device *pdev)
+{
+	struct intel_pmic_info *pdata = dev_get_platdata(&pdev->dev);
+	struct regulator_config config = { };
+	unsigned int i;
+
+	if (!pdata || !pdata->pmic_reg)
+		return -EINVAL;
+
+	config.dev = &pdev->dev;
+	config.init_data = pdata->init_data;
+	config.driver_data = pdata;
+
+	for (i = 0; i < ARRAY_SIZE(reg_addr_offset); i++) {
+		if (reg_addr_offset[i] == pdata->pmic_reg)
+			break;
+	}
+	if (i == (ARRAY_SIZE(reg_addr_offset)))
+		return -EINVAL;
+
+	pdata->intel_pmic_rdev =
+	regulator_register(&intel_pmic_desc[i], &config);
+	if (IS_ERR(pdata->intel_pmic_rdev)) {
+		dev_err(&pdev->dev, "can't register regulator..error %ld\n",
+				PTR_ERR(pdata->intel_pmic_rdev));
+		return PTR_ERR(pdata->intel_pmic_rdev);
+	}
+	platform_set_drvdata(pdev, pdata->intel_pmic_rdev);
+	dev_dbg(&pdev->dev, "registered regulator\n");
+	return 0;
+}
+
+static int basin_cove_pmic_remove(struct platform_device *pdev)
+{
+	regulator_unregister(platform_get_drvdata(pdev));
+	return 0;
+}
+
+static const struct platform_device_id basin_cove_id_table[] = {
+	{ "intel_regulator", 0 },
+	{ },
+};
+
+MODULE_DEVICE_TABLE(platform, basin_cove_id_table);
+
+static struct platform_driver basin_cove_pmic_driver = {
+	.driver		= {
+		.name = "intel_regulator",
+		.owner = THIS_MODULE,
+	},
+	.probe = basin_cove_pmic_probe,
+	.remove = basin_cove_pmic_remove,
+	.id_table = basin_cove_id_table,
+};
+static int __init basin_cove_pmic_init(void)
+{
+	return platform_driver_register(&basin_cove_pmic_driver);
+}
+subsys_initcall(basin_cove_pmic_init);
+
+static void __exit basin_cove_pmic_exit(void)
+{
+	platform_driver_unregister(&basin_cove_pmic_driver);
+}
+module_exit(basin_cove_pmic_exit);
+
+MODULE_DESCRIPTION("Basin Cove voltage regulator driver");
+MODULE_AUTHOR("Vishwesh/Mahesh/Sudarshan");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/remoteproc/Makefile b/drivers/remoteproc/Makefile
index ac2ff75..efb0eb8 100644
--- a/drivers/remoteproc/Makefile
+++ b/drivers/remoteproc/Makefile
@@ -10,3 +10,4 @@ remoteproc-y				+= remoteproc_elf_loader.o
 obj-$(CONFIG_OMAP_REMOTEPROC)		+= omap_remoteproc.o
 obj-$(CONFIG_STE_MODEM_RPROC)	 	+= ste_modem_rproc.o
 obj-$(CONFIG_DA8XX_REMOTEPROC)		+= da8xx_remoteproc.o
+obj-$(CONFIG_INTEL_MID_REMOTEPROC)	+= intel_mid_rproc_scu.o intel_mid_rproc_core.o
diff --git a/drivers/remoteproc/intel_mid_rproc_core.c b/drivers/remoteproc/intel_mid_rproc_core.c
new file mode 100644
index 0000000..dc30ba1f
--- /dev/null
+++ b/drivers/remoteproc/intel_mid_rproc_core.c
@@ -0,0 +1,269 @@
+/*
+ * INTEL MID Remote Processor Core driver
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/remoteproc.h>
+#include <linux/rpmsg.h>
+#include <linux/slab.h>
+#include <linux/virtio_ring.h>
+#include <linux/virtio_ids.h>
+#include <linux/platform_data/intel_mid_remoteproc.h>
+
+#include "intel_mid_rproc_core.h"
+#include "remoteproc_internal.h"
+
+#define RPMSG_NS_ADDR	53
+
+/**
+ * rpmsg_ns_alloc() - allocate a name service annoucement structure
+ * @name: name of remote service
+ * @id: rproc type
+ * @addr: address of remote service
+ */
+struct rpmsg_ns_info *rpmsg_ns_alloc(const char *name, int id, u32 addr)
+{
+	struct rpmsg_ns_info *ns_info;
+
+	ns_info = kzalloc(sizeof(struct rpmsg_ns_info), GFP_KERNEL);
+	if (ns_info) {
+		strcpy(ns_info->name, name);
+		ns_info->type = id;
+		ns_info->addr = addr;
+		ns_info->flags = RPMSG_NS_CREATE;
+	}
+
+	return ns_info;
+};
+EXPORT_SYMBOL_GPL(rpmsg_ns_alloc);
+
+/**
+ * rpmsg_ns_add_to_list() -- add a name service node to the global list
+ * @info: name service node
+ */
+void rpmsg_ns_add_to_list(struct rpmsg_ns_info *info,
+				struct rpmsg_ns_list *nslist)
+{
+	mutex_lock(&nslist->lock);
+	list_add_tail(&info->node, &nslist->list);
+	mutex_unlock(&nslist->lock);
+}
+EXPORT_SYMBOL_GPL(rpmsg_ns_add_to_list);
+
+/**
+ * free_rpmsg_ns() -- free rpmsg name service node
+ * @info: name service node
+ */
+void free_rpmsg_ns(struct rpmsg_ns_info *info)
+{
+	kfree(info);
+}
+
+/**
+ * rpmsg_ns_del_list() -- free rpmsg name service list
+ */
+void rpmsg_ns_del_list(struct rpmsg_ns_list *nslist)
+{
+	struct rpmsg_ns_info *info, *next;
+	mutex_lock(&nslist->lock);
+	list_for_each_entry_safe(info, next, &nslist->list, node) {
+		list_del(&info->node);
+		free_rpmsg_ns(info);
+	}
+	mutex_unlock(&nslist->lock);
+}
+EXPORT_SYMBOL_GPL(rpmsg_ns_del_list);
+
+/**
+ * find_rvdev() - find the rproc state of a supported virtio device
+ * @rproc: rproc handle
+ * @id: virtio device id
+ */
+struct rproc_vdev *find_rvdev(struct rproc *rproc, int id)
+{
+	struct rproc_vdev *rvdev;
+
+	list_for_each_entry(rvdev, &rproc->rvdevs, node)
+		if (rvdev->vdev.id.device == id)
+			return rvdev;
+
+	return NULL;
+}
+
+/*
+ * Since we could not get vring structure directly from rproc_vring
+ * structure, we have to create two local vrings and identify them
+ * by matching with rproc_vrings.
+ * @id: virtio device id.
+ * Currently one rproc_vdev is supported by firmware, and the id is
+ * VIRTIO_ID_RPMSG (declared in linux/virtio_ids.h).
+ */
+int find_vring_index(struct rproc *rproc, int vqid, int id)
+{
+	struct rproc_vdev *rvdev;
+	struct device *dev = rproc->dev.parent;
+	int vring_idx = 0;
+
+	rvdev = find_rvdev(rproc, id);
+	if (rvdev == NULL) {
+		dev_err(dev, "virtio device not found\n");
+		return -EINVAL;
+	}
+
+	while (vring_idx < RVDEV_NUM_VRINGS) {
+		if (rvdev->vring[vring_idx].notifyid == vqid)
+			break;
+		vring_idx++;
+	}
+
+	/* no match found? there's a problem */
+	if (vring_idx == RVDEV_NUM_VRINGS) {
+		dev_err(dev, "Can not find vring\n");
+		return -EINVAL;
+	}
+
+	return vring_idx;
+}
+
+void intel_mid_rproc_vring_init(struct rproc *rproc,
+			struct vring *vring, enum local_vring_idx id)
+{
+	int align, len;
+	void *addr;
+	struct rproc_vdev *rvdev;
+	struct device *dev = rproc->dev.parent;
+
+	rvdev = find_rvdev(rproc, VIRTIO_ID_RPMSG);
+	if (rvdev == NULL) {
+		dev_err(dev, "virtio device not found\n");
+		return;
+	}
+
+	addr = rvdev->vring[id].va;
+	align = rvdev->vring[id].align;
+	len = rvdev->vring[id].len;
+	vring_init(vring, len, addr, align);
+}
+
+/**
+ * intel_mid_rproc_vq_interrupt() - inform a vq interrupt to rproc
+ *				    after vq buffers are handled
+ * @rproc: rproc handle
+ * @msg: vq notify id
+ */
+void intel_mid_rproc_vq_interrupt(struct rproc *rproc, int msg)
+{
+	struct device *dev = rproc->dev.parent;
+
+	if (rproc_vq_interrupt(rproc, msg) == IRQ_NONE)
+		dev_err(dev, "no message was found in vqid %d\n", msg);
+}
+
+/**
+ * intel_mid_rproc_msg_handle() - generic interface as a vq buffer handle
+ *				  during rpmsg transaction
+ * @iproc: intel mid rproc data
+ */
+int intel_mid_rproc_msg_handle(struct intel_mid_rproc *iproc)
+{
+	int ret;
+	struct vring *r_vring, *s_vring;
+	void *r_virt_addr, *s_virt_addr;
+	u16 r_idx, s_idx;
+	u64 r_dma_addr, s_dma_addr;
+	u32 r_len, s_len;
+
+	r_vring = &iproc->rx_vring;
+	s_vring = &iproc->tx_vring;
+
+	r_idx = iproc->r_vring_last_used & (r_vring->num - 1);
+	s_idx = iproc->s_vring_last_used & (s_vring->num - 1);
+
+	r_dma_addr = r_vring->desc[r_idx].addr;
+	s_dma_addr = s_vring->desc[s_idx].addr;
+
+	r_virt_addr = phys_to_virt(r_dma_addr);
+	s_virt_addr = phys_to_virt(s_dma_addr);
+
+	ret = iproc->rproc_rpmsg_handle(r_virt_addr, s_virt_addr,
+						&r_len, &s_len);
+
+	r_vring->used->ring[r_idx].id = r_idx;
+	r_vring->used->ring[r_idx].len = r_len;
+	r_vring->used->idx++;
+
+	s_vring->used->ring[s_idx].id = s_idx;
+	s_vring->used->ring[s_idx].len = s_len;
+	s_vring->used->idx++;
+
+	iproc->r_vring_last_used++;
+	iproc->s_vring_last_used++;
+
+	return ret;
+}
+
+/**
+ * Remoteproc side rx buffer handler during name service creation.
+ * @iproc: intel mid rproc data
+ * @ns_info: name service info
+ *
+ * After remote processor receives name service messages, it needs to
+ * update the elements of its virtio device's rx virtqueue buffer
+ * before next rpmsg transaction.
+ * Here we have this function simulating the above effect.
+ */
+int intel_mid_rproc_ns_handle(struct intel_mid_rproc *iproc,
+				struct rpmsg_ns_info *ns_info)
+{
+	u16 index;
+	u32 len;
+	u64 dma_addr;
+	void *virt_addr;
+
+	struct vring *r_vring;
+	struct rpmsg_hdr *msg;
+	struct rpmsg_ns_msg *nsm;
+
+	if (ns_info == NULL) {
+		pr_err("ns_info = NULL\n");
+		return -ENODEV;
+	}
+
+	r_vring = &iproc->rx_vring;
+
+	index = iproc->r_vring_last_used & (r_vring->num - 1);
+
+	len = sizeof(*msg) + sizeof(*nsm);
+
+	dma_addr = r_vring->desc[index].addr;
+	virt_addr = phys_to_virt(dma_addr);
+
+	msg = (struct rpmsg_hdr *)virt_addr;
+	nsm = (struct rpmsg_ns_msg *)(virt_addr + sizeof(*msg));
+
+	nsm->addr = ns_info->addr;
+	nsm->flags = ns_info->flags;
+	strncpy(nsm->name, ns_info->name, RPMSG_NAME_SIZE);
+
+	msg->len = sizeof(*nsm);
+	msg->src = nsm->addr;
+	msg->dst = RPMSG_NS_ADDR;
+
+	r_vring->used->ring[index].id = index;
+	r_vring->used->ring[index].len = len;
+	r_vring->used->idx++;
+
+	iproc->r_vring_last_used++;
+
+	return 0;
+}
diff --git a/drivers/remoteproc/intel_mid_rproc_core.h b/drivers/remoteproc/intel_mid_rproc_core.h
new file mode 100644
index 0000000..bfe6f6c
--- /dev/null
+++ b/drivers/remoteproc/intel_mid_rproc_core.h
@@ -0,0 +1,82 @@
+/*
+ * INTEL MID Remote Processor Core Head File
+ *
+ * Copyright (C) 2012 Intel, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+typedef int (*rpmsg_handle_t)(void *rx_buf, void *tx_buf,
+				u32 *r_len, u32 *s_len);
+
+int scu_ipc_rpmsg_handle(void *rx_buf, void *tx_buf, u32 *r_len, u32 *s_len);
+int psh_ipc_rpmsg_handle(void *rx_buf, void *tx_buf, u32 *len);
+
+#define RPROC_FW_LOADING_TIMEOUT	(3 * HZ)
+#define IPROC_NAME_SIZE 20
+
+/**
+ * struct intel_mid_rproc - intel mid remote processor
+ * @ns_enabled: name service enabled flag
+ * @name: rproc name
+ * @type: rproc type
+ * @r_vring_last_used: last used index of rx vring
+ * @s_vring_last_used: last used index of tx vring
+ * @rproc: rproc handle
+ * @rx_vring: rproc rx vring
+ * @tx_vring: rproc tx vring
+ * @ns_info: loop cursor when creating ns channels
+ * @rproc_rpmsg_handle: rproc private rpmsg handle
+ */
+struct intel_mid_rproc {
+	bool ns_enabled;
+	char name[IPROC_NAME_SIZE];
+	u32 type;
+	u32 r_vring_last_used;
+	u32 s_vring_last_used;
+	struct rproc *rproc;
+	struct vring rx_vring;
+	struct vring tx_vring;
+	struct rpmsg_ns_info *ns_info;
+	rpmsg_handle_t rproc_rpmsg_handle;
+};
+
+enum local_vring_idx {
+	RX_VRING,
+	TX_VRING,
+};
+
+extern void intel_mid_rproc_vq_interrupt(struct rproc *rproc, int msg);
+extern int intel_mid_rproc_msg_handle(struct intel_mid_rproc *iproc);
+extern int intel_mid_rproc_ns_handle(struct intel_mid_rproc *iproc,
+					struct rpmsg_ns_info *ns_info);
+
+extern struct rproc_vdev *find_rvdev(struct rproc *rproc, int id);
+extern int find_vring_index(struct rproc *rproc, int vqid, int id);
+extern void intel_mid_rproc_vring_init(struct rproc *rproc,
+			struct vring *vring, enum local_vring_idx id);
+
+extern void rpmsg_ns_del_list(struct rpmsg_ns_list *nslist);
+
+/* Please do NOT use these APIs to send ipc commands,
+ * use rpmsg commands defined in <asm/intel_mid_rpmsg.h>
+ */
+extern void intel_scu_ipc_send_command(u32 cmd);
+
+/* Issue commands to the SCU with or without data */
+extern int intel_scu_ipc_simple_command(int cmd, int sub);
+extern int intel_scu_ipc_command(u32 cmd, u32 sub, u8 *in, u32 inlen,
+		u32 *out, u32 outlen);
+extern int intel_scu_ipc_raw_cmd(u32 cmd, u32 sub, u8 *in, u32 inlen,
+		u32 *out, u32 outlen, u32 dptr, u32 sptr);
+
+/* IPC locking */
+extern void intel_scu_ipc_lock(void);
+extern void intel_scu_ipc_unlock(void);
diff --git a/drivers/remoteproc/intel_mid_rproc_scu.c b/drivers/remoteproc/intel_mid_rproc_scu.c
new file mode 100644
index 0000000..53a1cdc
--- /dev/null
+++ b/drivers/remoteproc/intel_mid_rproc_scu.c
@@ -0,0 +1,441 @@
+/*
+ * INTEL MID Remote Processor - SCU driver
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/err.h>
+#include <linux/platform_device.h>
+#include <linux/dma-mapping.h>
+#include <linux/remoteproc.h>
+#include <linux/delay.h>
+#include <linux/rpmsg.h>
+#include <linux/slab.h>
+#include <linux/virtio_ring.h>
+#include <linux/virtio_ids.h>
+#include <linux/platform_data/intel_mid_remoteproc.h>
+
+#include <asm/intel_scu_ipc.h>
+#include <asm/scu_ipc_rpmsg.h>
+#include <asm/intel-mid.h>
+
+#include "intel_mid_rproc_core.h"
+#include "remoteproc_internal.h"
+
+static struct rpmsg_ns_list *nslist;
+
+
+static int scu_ipc_command(void *tx_buf)
+{
+	struct tx_ipc_msg *tx_msg;
+	int ret = 0;
+
+	tx_msg = (struct tx_ipc_msg *)tx_buf;
+
+	ret = intel_scu_ipc_command(tx_msg->cmd, tx_msg->sub,
+				tx_msg->in, tx_msg->inlen,
+				tx_msg->out, tx_msg->outlen);
+	return ret;
+}
+
+static int scu_ipc_raw_command(void *tx_buf)
+{
+	struct tx_ipc_msg *tx_msg;
+	int ret = 0;
+
+	tx_msg = (struct tx_ipc_msg *)tx_buf;
+
+	intel_scu_ipc_lock();
+	ret = intel_scu_ipc_raw_cmd(tx_msg->cmd, tx_msg->sub,
+				tx_msg->in, tx_msg->inlen,
+				tx_msg->out, tx_msg->outlen,
+				tx_msg->dptr, tx_msg->sptr);
+	intel_scu_ipc_unlock();
+
+	return ret;
+}
+
+static int scu_ipc_simple_command(void *tx_buf)
+{
+	struct tx_ipc_msg *tx_msg;
+	int ret = 0;
+
+	tx_msg = (struct tx_ipc_msg *)tx_buf;
+
+	ret = intel_scu_ipc_simple_command(tx_msg->cmd, tx_msg->sub);
+
+	return ret;
+}
+
+static void scu_ipc_send_command(void *tx_buf)
+{
+	struct tx_ipc_msg *tx_msg;
+
+	tx_msg = (struct tx_ipc_msg *)tx_buf;
+	intel_scu_ipc_send_command(tx_msg->sub << 12 | tx_msg->cmd);
+}
+
+static int scu_ipc_fw_command(void *tx_buf)
+{
+	struct tx_ipc_msg *tx_msg;
+	int ret = 0;
+
+	tx_msg = (struct tx_ipc_msg *)tx_buf;
+
+	switch (tx_msg->cmd) {
+	case RP_GET_FW_REVISION:
+		ret = scu_ipc_command(tx_buf);
+		break;
+	case RP_FW_UPDATE:
+		/* Only scu_ipc_send_command works for fw update */
+		scu_ipc_send_command(tx_buf);
+		break;
+	default:
+		pr_info("Command %x not supported\n", tx_msg->cmd);
+		break;
+	};
+
+	return ret;
+}
+
+static int scu_ipc_util_command(void *tx_buf)
+{
+	struct tx_ipc_msg *tx_msg;
+	int ret = 0;
+
+	tx_msg = (struct tx_ipc_msg *)tx_buf;
+
+	switch (tx_msg->cmd) {
+	case RP_GET_FW_REVISION:
+	case RP_GET_HOBADDR:
+	case RP_OSC_CLK_CTRL:
+		ret = scu_ipc_command(tx_buf);
+		break;
+	case RP_S0IX_COUNTER:
+		ret = scu_ipc_simple_command(tx_buf);
+		break;
+	case RP_WRITE_OSNIB:
+		ret = scu_ipc_raw_command(tx_buf);
+		break;
+	default:
+		pr_info("Command %x not supported\n", tx_msg->cmd);
+		break;
+	};
+
+	return ret;
+}
+
+static int scu_ipc_vrtc_command(void *tx_buf)
+{
+	struct tx_ipc_msg *tx_msg;
+	int ret = 0;
+
+	tx_msg = (struct tx_ipc_msg *)tx_buf;
+
+	switch (tx_msg->cmd) {
+	case RP_GET_HOBADDR:
+		ret = scu_ipc_command(tx_buf);
+		break;
+	case RP_VRTC:
+		ret = scu_ipc_simple_command(tx_buf);
+		break;
+	default:
+		pr_info("Command %x not supported\n", tx_msg->cmd);
+		break;
+	};
+
+	return ret;
+}
+
+static int scu_ipc_fw_logging_command(void *tx_buf)
+{
+	struct tx_ipc_msg *tx_msg;
+	int ret = 0;
+
+	tx_msg = (struct tx_ipc_msg *)tx_buf;
+
+	switch (tx_msg->cmd) {
+	case RP_GET_HOBADDR:
+		ret = scu_ipc_command(tx_buf);
+		break;
+	case RP_CLEAR_FABERROR:
+		ret = scu_ipc_simple_command(tx_buf);
+		break;
+	default:
+		pr_info("Command %x not supported\n", tx_msg->cmd);
+		break;
+	};
+
+	return ret;
+}
+
+/**
+ * scu_ipc_rpmsg_handle() - scu rproc specified ipc rpmsg handle
+ * @rx_buf: rx buffer to be add
+ * @tx_buf: tx buffer to be get
+ * @r_len: rx buffer length
+ * @s_len: tx buffer length
+ */
+int scu_ipc_rpmsg_handle(void *rx_buf, void *tx_buf, u32 *r_len, u32 *s_len)
+{
+	struct rpmsg_hdr *tx_hdr, *tmp_hdr;
+	struct tx_ipc_msg *tx_msg;
+	struct rx_ipc_msg *tmp_msg;
+	int ret = 0;
+
+	*r_len = sizeof(struct rpmsg_hdr) + sizeof(struct rx_ipc_msg);
+	*s_len = sizeof(struct rpmsg_hdr) + sizeof(struct tx_ipc_msg);
+
+	/* get tx_msg and send scu ipc command */
+	tx_hdr = (struct rpmsg_hdr *)tx_buf;
+	tx_msg = (struct tx_ipc_msg *)(tx_buf + sizeof(*tx_hdr));
+
+	tmp_hdr = (struct rpmsg_hdr *)rx_buf;
+	tmp_msg = (struct rx_ipc_msg *)tmp_hdr->data;
+
+	switch (tx_hdr->dst) {
+	case RP_PMIC_ACCESS:
+	case RP_FLIS_ACCESS:
+	case RP_IPC_COMMAND:
+		tmp_msg->status = scu_ipc_command(tx_msg);
+		break;
+	case RP_SET_WATCHDOG:
+		if (intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_TANGIER)
+			tmp_msg->status = scu_ipc_raw_command(tx_msg);
+		else
+			tmp_msg->status = scu_ipc_command(tx_msg);
+		break;
+	case RP_MIP_ACCESS:
+	case RP_IPC_RAW_COMMAND:
+		tmp_msg->status = scu_ipc_raw_command(tx_msg);
+		break;
+	case RP_IPC_SIMPLE_COMMAND:
+		tmp_msg->status = scu_ipc_simple_command(tx_msg);
+		break;
+	case RP_IPC_UTIL:
+		tmp_msg->status = scu_ipc_util_command(tx_msg);
+		break;
+	case RP_FW_ACCESS:
+		tmp_msg->status = scu_ipc_fw_command(tx_msg);
+		break;
+	case RP_VRTC:
+		tmp_msg->status = scu_ipc_vrtc_command(tx_msg);
+		break;
+	case RP_FW_LOGGING:
+		tmp_msg->status = scu_ipc_fw_logging_command(tx_msg);
+		break;
+	default:
+		tmp_msg->status = 0;
+		pr_info("Command %x not supported yet\n", tx_hdr->dst);
+		break;
+	};
+
+	/* prepare rx buffer, switch src and dst */
+	tmp_hdr->src = tx_hdr->dst;
+	tmp_hdr->dst = tx_hdr->src;
+
+	tmp_hdr->flags = tx_hdr->flags;
+	tmp_hdr->len = sizeof(struct rx_ipc_msg);
+
+	return ret;
+}
+
+/* kick a virtqueue */
+static void intel_rproc_scu_kick(struct rproc *rproc, int vqid)
+{
+	int idx;
+	int ret;
+	struct intel_mid_rproc *iproc;
+	struct rproc_vdev *rvdev;
+	struct device *dev = rproc->dev.parent;
+	static unsigned long ns_info_all_received;
+
+	iproc = (struct intel_mid_rproc *)rproc->priv;
+
+	/*
+	 * Remote processor virtqueue being kicked.
+	 * This part simulates remote processor handling messages.
+	 */
+	idx = find_vring_index(rproc, vqid, VIRTIO_ID_RPMSG);
+
+	switch (idx) {
+	case RX_VRING:
+		if (iproc->ns_enabled && !ns_info_all_received) {
+			/* push messages with ns_info for ALL available
+			name services in the list (nslist) into
+			rx buffers. */
+			list_for_each_entry_continue(iproc->ns_info,
+				&nslist->list, node) {
+				ret = intel_mid_rproc_ns_handle(iproc,
+					iproc->ns_info);
+				if (ret) {
+					dev_err(dev, "ns handle error\n");
+					return;
+				}
+			}
+
+			ns_info_all_received = 1;
+			intel_mid_rproc_vq_interrupt(rproc, vqid);
+		}
+		break;
+
+	case TX_VRING:
+
+		dev_dbg(dev, "remote processor got the message ...\n");
+		intel_mid_rproc_msg_handle(iproc);
+		intel_mid_rproc_vq_interrupt(rproc, vqid);
+
+		/*
+		 * After remoteproc handles the message, it calls
+		 * the receive callback.
+		 * TODO: replace this part with real remote processor
+		 * operation.
+		 */
+		rvdev = find_rvdev(rproc, VIRTIO_ID_RPMSG);
+		if (rvdev)
+			intel_mid_rproc_vq_interrupt(rproc,
+				rvdev->vring[RX_VRING].notifyid);
+		else
+			WARN(1, "%s: can't find given rproc state\n", __func__);
+		break;
+
+	default:
+		dev_err(dev, "invalid vring index\n");
+		break;
+	}
+}
+
+/* power up the remote processor */
+static int intel_rproc_scu_start(struct rproc *rproc)
+{
+	struct intel_mid_rproc *iproc;
+
+	pr_info("Started intel scu remote processor\n");
+	iproc = (struct intel_mid_rproc *)rproc->priv;
+	intel_mid_rproc_vring_init(rproc, &iproc->rx_vring, RX_VRING);
+	intel_mid_rproc_vring_init(rproc, &iproc->tx_vring, TX_VRING);
+
+	return 0;
+}
+
+/* power off the remote processor */
+static int intel_rproc_scu_stop(struct rproc *rproc)
+{
+	pr_info("Stopped intel scu remote processor\n");
+	return 0;
+}
+
+static struct rproc_ops intel_rproc_scu_ops = {
+	.start		= intel_rproc_scu_start,
+	.stop		= intel_rproc_scu_stop,
+	.kick		= intel_rproc_scu_kick,
+};
+
+static int intel_rproc_scu_probe(struct platform_device *pdev)
+{
+	struct intel_mid_rproc_pdata *pdata = pdev->dev.platform_data;
+	struct intel_mid_rproc *iproc;
+	struct rproc *rproc;
+	int ret;
+
+	ret = dma_set_coherent_mask(&pdev->dev, DMA_BIT_MASK(32));
+	if (ret) {
+		dev_err(pdev->dev.parent, "dma_set_coherent_mask: %d\n", ret);
+		return ret;
+	}
+
+	rproc = rproc_alloc(&pdev->dev, pdata->name, &intel_rproc_scu_ops,
+				pdata->firmware, sizeof(*iproc));
+	if (!rproc)
+		return -ENOMEM;
+
+	iproc = rproc->priv;
+	iproc->rproc = rproc;
+	nslist = pdata->nslist;
+
+	platform_set_drvdata(pdev, rproc);
+
+	ret = rproc_add(rproc);
+	if (ret)
+		goto free_rproc;
+
+	/*
+	 * Temporarily follow the rproc framework to load firmware
+	 * TODO: modify remoteproc code according to X86 architecture
+	 */
+	if (0 == wait_for_completion_timeout(&rproc->firmware_loading_complete,
+		RPROC_FW_LOADING_TIMEOUT)) {
+		dev_err(pdev->dev.parent, "fw loading not complete\n");
+		goto free_rproc;
+	}
+
+	/* Initialize intel_rproc_scu private data */
+	strncpy(iproc->name, pdev->id_entry->name, sizeof(iproc->name) - 1);
+	iproc->type = pdev->id_entry->driver_data;
+	iproc->r_vring_last_used = 0;
+	iproc->s_vring_last_used = 0;
+	iproc->ns_enabled = true;
+	iproc->rproc_rpmsg_handle = scu_ipc_rpmsg_handle;
+	iproc->ns_info = list_entry(&nslist->list,
+			struct rpmsg_ns_info, node);
+
+	return 0;
+
+free_rproc:
+	rproc_put(rproc);
+	return ret;
+}
+
+static int intel_rproc_scu_remove(struct platform_device *pdev)
+{
+	struct rproc *rproc = platform_get_drvdata(pdev);
+
+	if (nslist)
+		rpmsg_ns_del_list(nslist);
+
+	rproc_del(rproc);
+	rproc_put(rproc);
+
+	return 0;
+}
+
+static const struct platform_device_id intel_rproc_scu_id_table[] = {
+	{ "intel_rproc_scu", RPROC_SCU },
+	{ },
+};
+
+static struct platform_driver intel_rproc_scu_driver = {
+	.probe = intel_rproc_scu_probe,
+	.remove = intel_rproc_scu_remove,
+	.driver = {
+		.name = "intel_rproc_scu",
+		.owner = THIS_MODULE,
+	},
+	.id_table = intel_rproc_scu_id_table,
+};
+
+static int __init intel_rproc_scu_init(void)
+{
+	return platform_driver_register(&intel_rproc_scu_driver);
+}
+
+static void __exit intel_rproc_scu_exit(void)
+{
+	platform_driver_unregister(&intel_rproc_scu_driver);
+}
+
+subsys_initcall(intel_rproc_scu_init);
+module_exit(intel_rproc_scu_exit);
+
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("Ning Li<ning.li@intel.com>");
+MODULE_DESCRIPTION("INTEL MID Remoteproc Core driver");
diff --git a/drivers/rpmsg/virtio_rpmsg_bus.c b/drivers/rpmsg/virtio_rpmsg_bus.c
index b6135d4..a9ad4a7 100644
--- a/drivers/rpmsg/virtio_rpmsg_bus.c
+++ b/drivers/rpmsg/virtio_rpmsg_bus.c
@@ -749,9 +749,9 @@ int rpmsg_send_offchannel_raw(struct rpmsg_channel *rpdev, u32 src, u32 dst,
 	dev_dbg(dev, "TX From 0x%x, To 0x%x, Len %d, Flags %d, Reserved %d\n",
 					msg->src, msg->dst, msg->len,
 					msg->flags, msg->reserved);
-	print_hex_dump(KERN_DEBUG, "rpmsg_virtio TX: ", DUMP_PREFIX_NONE, 16, 1,
+/*	print_hex_dump(KERN_DEBUG, "rpmsg_virtio TX: ", DUMP_PREFIX_NONE, 16, 1,
 					msg, sizeof(*msg) + msg->len, true);
-
+*/
 	sg_init_one(&sg, msg, sizeof(*msg) + len);
 
 	mutex_lock(&vrp->tx_lock);
@@ -786,9 +786,9 @@ static int rpmsg_recv_single(struct virtproc_info *vrp, struct device *dev,
 	dev_dbg(dev, "From: 0x%x, To: 0x%x, Len: %d, Flags: %d, Reserved: %d\n",
 					msg->src, msg->dst, msg->len,
 					msg->flags, msg->reserved);
-	print_hex_dump(KERN_DEBUG, "rpmsg_virtio RX: ", DUMP_PREFIX_NONE, 16, 1,
+/*	print_hex_dump(KERN_DEBUG, "rpmsg_virtio RX: ", DUMP_PREFIX_NONE, 16, 1,
 					msg, sizeof(*msg) + msg->len, true);
-
+*/
 	/*
 	 * We currently use fixed-sized buffers, so trivially sanitize
 	 * the reported payload length.
@@ -898,10 +898,10 @@ static void rpmsg_ns_cb(struct rpmsg_channel *rpdev, void *data, int len,
 	struct device *dev = &vrp->vdev->dev;
 	int ret;
 
-	print_hex_dump(KERN_DEBUG, "NS announcement: ",
+/*	print_hex_dump(KERN_DEBUG, "NS announcement: ",
 			DUMP_PREFIX_NONE, 16, 1,
 			data, len, true);
-
+*/
 	if (len != sizeof(*msg)) {
 		dev_err(dev, "malformed ns msg (%d)\n", len);
 		return;
diff --git a/drivers/rtc/rtc-mrst.c b/drivers/rtc/rtc-mrst.c
index e2436d1..ed25947 100644
--- a/drivers/rtc/rtc-mrst.c
+++ b/drivers/rtc/rtc-mrst.c
@@ -35,11 +35,14 @@
 #include <linux/module.h>
 #include <linux/init.h>
 #include <linux/sfi.h>
+#include <linux/io.h>
 
 #include <asm-generic/rtc.h>
 #include <asm/intel_scu_ipc.h>
 #include <asm/intel-mid.h>
 #include <asm/intel_mid_vrtc.h>
+#include <linux/rpmsg.h>
+#include <asm/intel_mid_rpmsg.h>
 
 struct mrst_rtc {
 	struct rtc_device	*rtc;
@@ -51,10 +54,24 @@ struct mrst_rtc {
 	u8			suspend_ctrl;
 };
 
+/* both platform and pnp busses use negative numbers for invalid irqs */
+#define is_valid_irq(n)		((n) >= 0)
+
 static const char driver_name[] = "rtc_mrst";
 
 #define	RTC_IRQMASK	(RTC_PF | RTC_AF)
 
+#define OSHOB_ALARM_OFFSET 0x68
+#define OSHOB_DAYW_OFFSET  0x00
+#define OSHOB_DAYM_OFFSET  0x01
+#define OSHOB_MON_OFFSET   0x02
+#define OSHOB_YEAR_OFFSET  0x03
+
+static u32 oshob_base;
+static void __iomem *oshob_addr;
+
+static struct rpmsg_instance *vrtc_mrst_instance;
+
 static inline int is_intr(u8 rtc_intr)
 {
 	if (!(rtc_intr & RTC_IRQF))
@@ -73,6 +90,34 @@ static inline unsigned char vrtc_is_updating(void)
 	return uip;
 }
 
+/* If the interrupt is of alarm-type-RTC_AF, then check if it's for
+ * the correct day. With the support for alarms more than 24-hours,
+ * alarm-date is compared with date-fields in OSHOB, as the vRTC
+ * doesn't have date-fields for alarm
+ */
+static int is_valid_af(u8 rtc_intr)
+{
+	char *p;
+	unsigned long vrtc_date, oshob_date;
+
+	if ((__intel_mid_cpu_chip == INTEL_MID_CPU_CHIP_PENWELL) ||
+	    (__intel_mid_cpu_chip == INTEL_MID_CPU_CHIP_CLOVERVIEW)) {
+		if (rtc_intr & RTC_AF) {
+			p = (char *) &vrtc_date;
+			*(p+1) = vrtc_cmos_read(RTC_DAY_OF_MONTH);
+			*(p+2) = vrtc_cmos_read(RTC_MONTH);
+			*(p+3) = vrtc_cmos_read(RTC_YEAR);
+
+			oshob_date = readl(oshob_addr);
+			if ((oshob_date & 0xFFFFFF00)
+					!= (vrtc_date & 0xFFFFFF00))
+				return false;
+		}
+	}
+
+	return true;
+}
+
 /*
  * rtc_time's year contains the increment over 1900, but vRTC's YEAR
  * register can't be programmed to value larger than 0x64, so vRTC
@@ -137,7 +182,8 @@ static int mrst_set_time(struct device *dev, struct rtc_time *time)
 
 	spin_unlock_irqrestore(&rtc_lock, flags);
 
-	ret = intel_scu_ipc_simple_command(IPCMSG_VRTC, IPC_CMD_VRTC_SETTIME);
+	ret = rpmsg_send_simple_command(vrtc_mrst_instance,
+				IPCMSG_VRTC, IPC_CMD_VRTC_SETTIME);
 	return ret;
 }
 
@@ -146,7 +192,7 @@ static int mrst_read_alarm(struct device *dev, struct rtc_wkalrm *t)
 	struct mrst_rtc	*mrst = dev_get_drvdata(dev);
 	unsigned char rtc_control;
 
-	if (mrst->irq <= 0)
+	if (!is_valid_irq(mrst->irq))
 		return -EIO;
 
 	/* Basic alarms only support hour, minute, and seconds fields.
@@ -182,7 +228,7 @@ static void mrst_checkintr(struct mrst_rtc *mrst, unsigned char rtc_control)
 	 */
 	rtc_intr = vrtc_cmos_read(RTC_INTR_FLAGS);
 	rtc_intr &= (rtc_control & RTC_IRQMASK) | RTC_IRQF;
-	if (is_intr(rtc_intr))
+	if (is_intr(rtc_intr) && is_valid_af(rtc_intr))
 		rtc_update_irq(mrst->rtc, 1, rtc_intr);
 }
 
@@ -217,15 +263,21 @@ static int mrst_set_alarm(struct device *dev, struct rtc_wkalrm *t)
 {
 	struct mrst_rtc	*mrst = dev_get_drvdata(dev);
 	unsigned char hrs, min, sec;
+	unsigned char wday, mday, mon, year;
 	int ret = 0;
 
-	if (!mrst->irq)
+	if (!is_valid_irq(mrst->irq))
 		return -EIO;
 
 	hrs = t->time.tm_hour;
 	min = t->time.tm_min;
 	sec = t->time.tm_sec;
 
+	wday = t->time.tm_wday;
+	mday = t->time.tm_mday;
+	mon = t->time.tm_mon;
+	year = t->time.tm_year;
+
 	spin_lock_irq(&rtc_lock);
 	/* Next rtc irq must not be from previous alarm setting */
 	mrst_irq_disable(mrst, RTC_AIE);
@@ -235,13 +287,18 @@ static int mrst_set_alarm(struct device *dev, struct rtc_wkalrm *t)
 	vrtc_cmos_write(min, RTC_MINUTES_ALARM);
 	vrtc_cmos_write(sec, RTC_SECONDS_ALARM);
 
-	spin_unlock_irq(&rtc_lock);
-
-	ret = intel_scu_ipc_simple_command(IPCMSG_VRTC, IPC_CMD_VRTC_SETALARM);
-	if (ret)
-		return ret;
+	if ((__intel_mid_cpu_chip == INTEL_MID_CPU_CHIP_PENWELL) ||
+	    (__intel_mid_cpu_chip == INTEL_MID_CPU_CHIP_CLOVERVIEW)) {
+		/* Support for date-field in Alarm using OSHOB
+		 * Since, vRTC doesn't have Alarm-registers for date-fields,
+		 * write date-fields into OSHOB for SCU to sync to MSIC-RTC */
+		writeb(wday, oshob_addr+OSHOB_DAYW_OFFSET);
+		writeb(mday, oshob_addr+OSHOB_DAYM_OFFSET);
+		writeb(mon+1, oshob_addr+OSHOB_MON_OFFSET);
+		/* Adjust for the 1972/1900 */
+		writeb(year-72, oshob_addr+OSHOB_YEAR_OFFSET);
+	}
 
-	spin_lock_irq(&rtc_lock);
 	if (t->enabled)
 		mrst_irq_enable(mrst, RTC_AIE);
 
@@ -250,21 +307,42 @@ static int mrst_set_alarm(struct device *dev, struct rtc_wkalrm *t)
 	return 0;
 }
 
+#if defined(CONFIG_RTC_INTF_DEV) || defined(CONFIG_RTC_INTF_DEV_MODULE)
+
 /* Currently, the vRTC doesn't support UIE ON/OFF */
-static int mrst_rtc_alarm_irq_enable(struct device *dev, unsigned int enabled)
+static int
+mrst_rtc_ioctl(struct device *dev, unsigned int cmd, unsigned long arg)
 {
 	struct mrst_rtc	*mrst = dev_get_drvdata(dev);
 	unsigned long	flags;
 
+	switch (cmd) {
+	case RTC_AIE_OFF:
+	case RTC_AIE_ON:
+		if (!is_valid_irq(mrst->irq))
+			return -EINVAL;
+		break;
+	default:
+		/* PIE ON/OFF is handled by mrst_irq_set_state() */
+		return -ENOIOCTLCMD;
+	}
+
 	spin_lock_irqsave(&rtc_lock, flags);
-	if (enabled)
-		mrst_irq_enable(mrst, RTC_AIE);
-	else
+	switch (cmd) {
+	case RTC_AIE_OFF:	/* alarm off */
 		mrst_irq_disable(mrst, RTC_AIE);
+		break;
+	case RTC_AIE_ON:	/* alarm on */
+		mrst_irq_enable(mrst, RTC_AIE);
+		break;
+	}
 	spin_unlock_irqrestore(&rtc_lock, flags);
 	return 0;
 }
 
+#else
+#define	mrst_rtc_ioctl	NULL
+#endif
 
 #if defined(CONFIG_RTC_INTF_PROC) || defined(CONFIG_RTC_INTF_PROC_MODULE)
 
@@ -290,13 +368,26 @@ static int mrst_procfs(struct device *dev, struct seq_file *seq)
 #define	mrst_procfs	NULL
 #endif
 
+static int mrst_alarm_irq_enable(struct device *dev, unsigned int enabled)
+{
+	struct mrst_rtc *mrst = dev_get_drvdata(dev);
+
+	if (enabled)
+		mrst_irq_enable(mrst, RTC_AIE);
+	else
+		mrst_irq_disable(mrst, RTC_AIE);
+
+	return 0;
+}
+
 static const struct rtc_class_ops mrst_rtc_ops = {
-	.read_time	= mrst_read_time,
-	.set_time	= mrst_set_time,
-	.read_alarm	= mrst_read_alarm,
-	.set_alarm	= mrst_set_alarm,
-	.proc		= mrst_procfs,
-	.alarm_irq_enable = mrst_rtc_alarm_irq_enable,
+	.ioctl		  = mrst_rtc_ioctl,
+	.read_time	  = mrst_read_time,
+	.set_time	  = mrst_set_time,
+	.read_alarm	  = mrst_read_alarm,
+	.set_alarm	  = mrst_set_alarm,
+	.proc		  = mrst_procfs,
+	.alarm_irq_enable = mrst_alarm_irq_enable,
 };
 
 static struct mrst_rtc	mrst_rtc;
@@ -308,22 +399,33 @@ static struct mrst_rtc	mrst_rtc;
 static irqreturn_t mrst_rtc_irq(int irq, void *p)
 {
 	u8 irqstat;
+	int ret = 0;
 
 	spin_lock(&rtc_lock);
 	/* This read will clear all IRQ flags inside Reg C */
 	irqstat = vrtc_cmos_read(RTC_INTR_FLAGS);
+	irqstat &= RTC_IRQMASK | RTC_IRQF;
+	ret = is_valid_af(irqstat);
 	spin_unlock(&rtc_lock);
 
-	irqstat &= RTC_IRQMASK | RTC_IRQF;
 	if (is_intr(irqstat)) {
-		rtc_update_irq(p, 1, irqstat);
+		/* If it's an alarm-interrupt, update RTC-IRQ only if it's
+		 * for current day. Alarms beyond 24-hours will result in
+		 * interrupts at given time, everyday till actual alarm-date.
+		 * From hardware perspective, it's still a valid interrupt,
+		 * hence need to return IRQ_HANDLED. */
+		if (ret)
+			rtc_update_irq(p, 1, irqstat);
+
 		return IRQ_HANDLED;
+	} else {
+		pr_err("vRTC: error in IRQ handler\n");
+		return IRQ_NONE;
 	}
-	return IRQ_NONE;
 }
 
-static int vrtc_mrst_do_probe(struct device *dev, struct resource *iomem,
-			      int rtc_irq)
+static int
+vrtc_mrst_do_probe(struct device *dev, struct resource *iomem, int rtc_irq)
 {
 	int retval = 0;
 	unsigned char rtc_control;
@@ -335,8 +437,9 @@ static int vrtc_mrst_do_probe(struct device *dev, struct resource *iomem,
 	if (!iomem)
 		return -ENODEV;
 
-	iomem = request_mem_region(iomem->start, resource_size(iomem),
-				   driver_name);
+	iomem = request_mem_region(iomem->start,
+			iomem->end + 1 - iomem->start,
+			driver_name);
 	if (!iomem) {
 		dev_dbg(dev, "i/o mem already in use.\n");
 		return -EBUSY;
@@ -364,9 +467,9 @@ static int vrtc_mrst_do_probe(struct device *dev, struct resource *iomem,
 	if (!(rtc_control & RTC_24H) || (rtc_control & (RTC_DM_BINARY)))
 		dev_dbg(dev, "TODO: support more than 24-hr BCD mode\n");
 
-	if (rtc_irq) {
+	if (is_valid_irq(rtc_irq)) {
 		retval = request_irq(rtc_irq, mrst_rtc_irq,
-				0, dev_name(&mrst_rtc.rtc->dev),
+				IRQF_NO_SUSPEND, dev_name(&mrst_rtc.rtc->dev),
 				mrst_rtc.rtc);
 		if (retval < 0) {
 			dev_dbg(dev, "IRQ %d is already in use, err %d\n",
@@ -374,7 +477,30 @@ static int vrtc_mrst_do_probe(struct device *dev, struct resource *iomem,
 			goto cleanup1;
 		}
 	}
-	dev_dbg(dev, "initialised\n");
+
+	/* make RTC device wake capable from sleep */
+	device_init_wakeup(dev, true);
+
+	if ((__intel_mid_cpu_chip == INTEL_MID_CPU_CHIP_PENWELL) ||
+	    (__intel_mid_cpu_chip == INTEL_MID_CPU_CHIP_CLOVERVIEW)) {
+		retval = rpmsg_send_command(vrtc_mrst_instance,
+				IPCMSG_GET_HOBADDR, 0, NULL, &oshob_base, 0, 1);
+		if (retval < 0) {
+			dev_dbg(dev,
+				"Unable to get OSHOB base address, err %d\n",
+				retval);
+			goto cleanup1;
+		}
+
+		oshob_addr = ioremap_nocache(oshob_base+OSHOB_ALARM_OFFSET, 4);
+		if (!oshob_addr) {
+			dev_dbg(dev, "Unable to do ioremap for OSHOB\n");
+			retval = -ENOMEM;
+			goto cleanup1;
+		}
+	}
+
+	dev_info(dev, "vRTC driver initialised\n");
 	return 0;
 
 cleanup1:
@@ -400,9 +526,15 @@ static void rtc_mrst_do_remove(struct device *dev)
 
 	rtc_mrst_do_shutdown();
 
-	if (mrst->irq)
+	if (is_valid_irq(mrst->irq))
 		free_irq(mrst->irq, mrst->rtc);
 
+	if ((__intel_mid_cpu_chip == INTEL_MID_CPU_CHIP_PENWELL) ||
+	    (__intel_mid_cpu_chip == INTEL_MID_CPU_CHIP_CLOVERVIEW)) {
+		if (oshob_addr != NULL)
+			iounmap(oshob_addr);
+	}
+
 	rtc_device_unregister(mrst->rtc);
 	mrst->rtc = NULL;
 
@@ -414,7 +546,7 @@ static void rtc_mrst_do_remove(struct device *dev)
 }
 
 #ifdef	CONFIG_PM
-static int mrst_suspend(struct device *dev, pm_message_t mesg)
+static int mrst_suspend(struct device *dev)
 {
 	struct mrst_rtc	*mrst = dev_get_drvdata(dev);
 	unsigned char	tmp;
@@ -453,7 +585,7 @@ static int mrst_suspend(struct device *dev, pm_message_t mesg)
  */
 static inline int mrst_poweroff(struct device *dev)
 {
-	return mrst_suspend(dev, PMSG_HIBERNATE);
+	return mrst_suspend(dev);
 }
 
 static int mrst_resume(struct device *dev)
@@ -476,7 +608,7 @@ static int mrst_resume(struct device *dev)
 
 			mask = vrtc_cmos_read(RTC_INTR_FLAGS);
 			mask &= (tmp & RTC_IRQMASK) | RTC_IRQF;
-			if (!is_intr(mask))
+			if (!(is_intr(mask) && is_valid_af(mask)))
 				break;
 
 			rtc_update_irq(mrst->rtc, 1, mask);
@@ -524,18 +656,102 @@ static void vrtc_mrst_platform_shutdown(struct platform_device *pdev)
 
 MODULE_ALIAS("platform:vrtc_mrst");
 
+static const struct dev_pm_ops vrtc_mrst_platform_driver_pm_ops = {
+	.suspend	= mrst_suspend,
+	.resume		= mrst_resume,
+};
+
 static struct platform_driver vrtc_mrst_platform_driver = {
 	.probe		= vrtc_mrst_platform_probe,
 	.remove		= vrtc_mrst_platform_remove,
 	.shutdown	= vrtc_mrst_platform_shutdown,
-	.driver = {
-		.name		= (char *) driver_name,
-		.suspend	= mrst_suspend,
-		.resume		= mrst_resume,
+	.driver.name	= (char *) driver_name,
+	.driver.pm	= &vrtc_mrst_platform_driver_pm_ops,
+};
+
+static int vrtc_mrst_init(void)
+{
+	return platform_driver_register(&vrtc_mrst_platform_driver);
+}
+
+static void vrtc_mrst_exit(void)
+{
+	platform_driver_unregister(&vrtc_mrst_platform_driver);
+}
+
+static int vrtc_mrst_rpmsg_probe(struct rpmsg_channel *rpdev)
+{
+	int ret;
+
+	if (rpdev == NULL) {
+		pr_err("vrtc_mrst rpmsg channel not created\n");
+		ret = -ENODEV;
+		goto out;
 	}
+
+	dev_info(&rpdev->dev, "Probed vrtc_mrst rpmsg device\n");
+
+	/* Allocate rpmsg instance for fw_update*/
+	ret = alloc_rpmsg_instance(rpdev, &vrtc_mrst_instance);
+	if (!vrtc_mrst_instance) {
+		dev_err(&rpdev->dev, "kzalloc vrtc_mrst instance failed\n");
+		goto out;
+	}
+
+	/* Initialize rpmsg instance */
+	init_rpmsg_instance(vrtc_mrst_instance);
+
+	ret = vrtc_mrst_init();
+	if (ret)
+		free_rpmsg_instance(rpdev, &vrtc_mrst_instance);
+
+out:
+	return ret;
+}
+
+static void vrtc_mrst_rpmsg_remove(struct rpmsg_channel *rpdev)
+{
+	vrtc_mrst_exit();
+	free_rpmsg_instance(rpdev, &vrtc_mrst_instance);
+	dev_info(&rpdev->dev, "Removed vrtc_mrst rpmsg device\n");
+}
+
+static void vrtc_mrst_rpmsg_cb(struct rpmsg_channel *rpdev, void *data,
+					int len, void *priv, u32 src)
+{
+	dev_warn(&rpdev->dev, "unexpected, message\n");
+
+	print_hex_dump(KERN_DEBUG, __func__, DUMP_PREFIX_NONE, 16, 1,
+		       data, len,  true);
+}
+
+static struct rpmsg_device_id vrtc_mrst_rpmsg_id_table[] = {
+	{ .name	= "rpmsg_vrtc" },
+	{ },
+};
+MODULE_DEVICE_TABLE(rpmsg, vrtc_mrst_rpmsg_id_table);
+
+static struct rpmsg_driver vrtc_mrst_rpmsg = {
+	.drv.name	= KBUILD_MODNAME,
+	.drv.owner	= THIS_MODULE,
+	.id_table	= vrtc_mrst_rpmsg_id_table,
+	.probe		= vrtc_mrst_rpmsg_probe,
+	.callback	= vrtc_mrst_rpmsg_cb,
+	.remove		= vrtc_mrst_rpmsg_remove,
 };
 
-module_platform_driver(vrtc_mrst_platform_driver);
+static int __init vrtc_mrst_rpmsg_init(void)
+{
+	return register_rpmsg_driver(&vrtc_mrst_rpmsg);
+}
+
+static void __exit vrtc_mrst_rpmsg_exit(void)
+{
+	return unregister_rpmsg_driver(&vrtc_mrst_rpmsg);
+}
+
+module_init(vrtc_mrst_rpmsg_init);
+module_exit(vrtc_mrst_rpmsg_exit);
 
 MODULE_AUTHOR("Jacob Pan; Feng Tang");
 MODULE_DESCRIPTION("Driver for Moorestown virtual RTC");
diff --git a/drivers/thermal/Kconfig b/drivers/thermal/Kconfig
index 5f88d76..d8e3a86 100644
--- a/drivers/thermal/Kconfig
+++ b/drivers/thermal/Kconfig
@@ -196,6 +196,34 @@ config INTEL_POWERCLAMP
 	  enforce idle time which results in more package C-state residency. The
 	  user interface is exposed via generic thermal framework.
 
+config SENSORS_THERMAL_MRFLD
+	tristate "Thermal driver for Intel Merrifield platform"
+	depends on THERMAL && IIO && IIO_BASINCOVE_GPADC
+	help
+	  Say Y here to enable thermal driver on Intel Merrifield platform.
+
+	  To load this driver as a module, select M here. The module
+	  will be called "mrfl_thermal"
+
+config INTEL_BYT_EC_THERMAL
+	tristate "Thermal driver for Intel Baytrail platform"
+	depends on THERMAL && INTEL_BYT_EC
+	help
+	  Say Y here to enable thermal driver on Intel Baytrail-M platform.
+
+	  To load this driver as a module, select M here. The module
+	  will be called "byt_ec_thermal"
+
+config SOC_THERMAL
+	tristate "SoC Thermal driver"
+	depends on THERMAL
+	help
+	  SoC Thermal driver registers to Generic Thermal Framework.
+	  Exposes SoC DTS and aux trip point values through the framework.
+
+	  Say Y here to enable thermal driver on Intel Merrifield
+	  platform. To load this driver as a module, select M here.
+
 config X86_PKG_TEMP_THERMAL
 	tristate "X86 package temperature thermal driver"
 	depends on X86_THERMAL_VECTOR
diff --git a/drivers/thermal/Makefile b/drivers/thermal/Makefile
index 54e4ec9..3ccc86d 100644
--- a/drivers/thermal/Makefile
+++ b/drivers/thermal/Makefile
@@ -2,9 +2,18 @@
 # Makefile for sensor chip drivers.
 #
 
+CFLAGS_intel_mrfl_thermal.o := -Werror
+CFLAGS_intel_soc_thermal.o := -Werror
+CFLAGS_thermal_core.o := -Werror
+
 obj-$(CONFIG_THERMAL)		+= thermal_sys.o
 thermal_sys-y			+= thermal_core.o
 
+obj-$(CONFIG_INTEL_MFLD_THERMAL) += intel_mid_thermal.o
+obj-$(CONFIG_INTEL_BYT_THERMAL)  += intel_byt_thermal.o
+obj-$(CONFIG_SENSORS_THERMAL_MRFLD)     += intel_mrfl_thermal.o
+obj-$(CONFIG_SOC_THERMAL)     += intel_soc_thermal.o
+
 # interface to/from other layers providing sensors
 thermal_sys-$(CONFIG_THERMAL_HWMON)		+= thermal_hwmon.o
 thermal_sys-$(CONFIG_THERMAL_OF)		+= of-thermal.o
diff --git a/drivers/thermal/intel_mrfl_thermal.c b/drivers/thermal/intel_mrfl_thermal.c
new file mode 100644
index 0000000..ab34846
--- /dev/null
+++ b/drivers/thermal/intel_mrfl_thermal.c
@@ -0,0 +1,909 @@
+/*
+ * intel_mrfl_thermal.c - Intel Merrifield Platform Thermal Driver
+ *
+ *
+ * Copyright (C) 2011 Intel Corporation
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ * Author: Durgadoss R <durgadoss.r@intel.com>
+ *
+ * DEVICE_NAME: Intel Merrifield platform - PMIC: Thermal Monitor
+ */
+
+#define pr_fmt(fmt)  "intel_mrfl_thermal: " fmt
+
+#include <linux/pm.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/rpmsg.h>
+#include <linux/module.h>
+#include <linux/thermal.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
+
+#include <asm/intel_scu_pmic.h>
+#include <asm/intel_mid_rpmsg.h>
+#include <asm/intel_basincove_gpadc.h>
+#include <asm/intel_mid_thermal.h>
+#include <linux/iio/consumer.h>
+
+#define DRIVER_NAME "bcove_thrm"
+
+/* Number of Thermal sensors on the PMIC */
+#define PMIC_THERMAL_SENSORS	4
+
+/* Registers that govern Thermal Monitoring */
+#define THRMMONCFG	0xB3
+#define THRMMONCTL	0xB4
+#define THRMIRQ		0x04
+#define MTHRMIRQ	0x0F
+#define STHRMIRQ	0xB2
+#define IRQLVL1		0x01
+#define MIRQLVL1	0x0C
+#define IRQ_MASK_ALL	0x0F
+
+/* PMIC SRAM base address and offset for Thermal register */
+#define PMIC_SRAM_BASE_ADDR	0xFFFFF610
+#define PMIC_SRAM_THRM_OFFSET	0x03
+#define IOMAP_SIZE		0x04
+
+/* NVM BANK REGISTER */
+#define EEPROM_CTRL		0x1FE
+#define EEPROM_REG15		0x1EE
+#define EEPROM_BANK1_SELECT	0x02
+#define EEPROM_BANK1_UNSELECT	0x00
+
+#define PMICALRT	(1 << 3)
+#define SYS2ALRT	(1 << 2)
+#define SYS1ALRT	(1 << 1)
+#define SYS0ALRT	(1 << 0)
+#define THERM_EN	(1 << 0)
+#define THERM_ALRT	(1 << 2)
+
+/* ADC to Temperature conversion table length */
+#define TABLE_LENGTH	34
+#define TEMP_INTERVAL	5
+
+/* Default _max 85 C */
+#define DEFAULT_MAX_TEMP	85
+
+/* Constants defined in BasinCove PMIC spec */
+#define PMIC_DIE_ADC_MIN	395
+#define PMIC_DIE_ADC_MAX	661
+#define PMIC_DIE_TEMP_MIN	-40
+#define PMIC_DIE_TEMP_MAX	125
+#define ADC_VAL_27C		470
+#define ADC_COEFFICIENT		675
+#define TEMP_OFFSET		27000
+
+/* 'enum' of Thermal sensors */
+enum thermal_sensors { SYS0, SYS1, SYS2, PMIC_DIE, _COUNT };
+
+/*
+ * Alert registers store the 'alert' temperature for each sensor,
+ * as 10 bit ADC code. The higher two bits are stored in bits[0:1] of
+ * alert_regs_h. The lower eight bits are stored in alert_regs_l.
+ * The hysteresis value is stored in bits[2:6] of alert_regs_h.
+ * Order: SYS0 SYS1 SYS2 PMIC_DIE
+ *
+ * static const int alert_regs_l[] = { 0xB7, 0xB9, 0xBB, 0xC1 };
+ */
+static const int alert_regs_h[] = { 0xB6, 0xB8, 0xBA, 0xC0 };
+
+/*
+ * ADC code vs Temperature table
+ * This table will be different for different thermistors
+ * Row 0: ADC code
+ * Row 1: Temperature (in degree celsius)
+ */
+static const int adc_code[2][TABLE_LENGTH] = {
+	{952, 932, 906, 877, 843, 804, 761, 714, 665, 614,
+	563, 512, 462, 415, 370, 329, 291, 257, 226, 199,
+	174, 153, 135, 119, 104, 92, 81, 72, 64, 56,
+	50, 45, 40, 36},
+	{-40, -35, -30, -25, -20, -15, -10, -5, 0, 5,
+	10, 15, 20, 25, 30, 35, 40, 45, 50, 55,
+	60, 65, 70, 75, 80, 85, 90, 95, 100, 105,
+	110, 115, 120, 125},
+	};
+
+static DEFINE_MUTEX(thrm_update_lock);
+
+struct thermal_device_info {
+	struct intel_mid_thermal_sensor *sensor;
+};
+
+struct thermal_data {
+	struct platform_device *pdev;
+	struct iio_channel *iio_chan;
+	struct thermal_zone_device **tzd;
+	void *thrm_addr;
+	unsigned int irq;
+	/* Caching information */
+	bool is_initialized;
+	unsigned long last_updated;
+	int cached_vals[PMIC_THERMAL_SENSORS];
+	int num_sensors;
+	struct intel_mid_thermal_sensor *sensors;
+};
+static struct thermal_data *tdata;
+
+static inline int adc_to_pmic_die_temp(unsigned int val)
+{
+	/* return temperature in mC */
+	return (val - ADC_VAL_27C) * ADC_COEFFICIENT + TEMP_OFFSET;
+}
+
+static inline int pmic_die_temp_to_adc(int temp)
+{
+	/* 'temp' is in C, convert to mC and then do calculations */
+	return ((temp * 1000) - TEMP_OFFSET) / ADC_COEFFICIENT + ADC_VAL_27C;
+}
+
+/**
+ * find_adc_code - searches the ADC code using binary search
+ * @val: value to find in the array
+ *
+ * This function does binary search on an array sorted in 'descending' order
+ * Can sleep
+ */
+static int find_adc_code(uint16_t val)
+{
+	int left = 0;
+	int right = TABLE_LENGTH - 1;
+	int mid;
+	while (left <= right) {
+		mid = (left + right)/2;
+		if (val == adc_code[0][mid] ||
+			(mid > 0 &&
+			val > adc_code[0][mid] && val < adc_code[0][mid-1]))
+			return mid;
+		else if (val > adc_code[0][mid])
+			right = mid - 1;
+		else if (val < adc_code[0][mid])
+			left = mid + 1;
+	}
+	return -EINVAL;
+}
+
+/**
+ * adc_to_temp - converts the ADC code to temperature in mC
+ * @direct: true if the sensor uses direct conversion
+ * @adc_val: the ADC code to be converted
+ * @tp: temperature return value
+ *
+ * Can sleep
+ */
+static int adc_to_temp(int direct, uint16_t adc_val, unsigned long *tp)
+{
+	int x0, x1, y0, y1;
+	int nr, dr;		/* Numerator & Denominator */
+	int indx;
+	int x = adc_val;
+	int8_t pmic_temp_offset;
+
+	/* Direct conversion for pmic die temperature */
+	if (direct) {
+		if (adc_val < PMIC_DIE_ADC_MIN || adc_val > PMIC_DIE_ADC_MAX)
+			return -EINVAL;
+
+		/* An offset added for pmic temp from NVM in TNG B0 */
+		intel_scu_ipc_iowrite8(EEPROM_CTRL, EEPROM_BANK1_SELECT);
+		intel_scu_ipc_ioread8(EEPROM_REG15, &pmic_temp_offset);
+		intel_scu_ipc_iowrite8(EEPROM_CTRL, EEPROM_BANK1_UNSELECT);
+
+		adc_val = adc_val + pmic_temp_offset;
+
+		*tp = adc_to_pmic_die_temp(adc_val);
+		return 0;
+	}
+
+	indx = find_adc_code(adc_val);
+	if (indx < 0)
+		return -EINVAL;
+
+	if (adc_code[0][indx] == adc_val) {
+		*tp = adc_code[1][indx] * 1000;
+		return 0;
+	}
+
+	/*
+	 * The ADC code is in between two values directly defined in the
+	 * table. So, do linear interpolation to calculate the temperature.
+	 */
+	x0 = adc_code[0][indx];
+	x1 = adc_code[0][indx - 1];
+	y0 = adc_code[1][indx];
+	y1 = adc_code[1][indx - 1];
+
+	/*
+	 * Find y:
+	 * Of course, we can avoid these variables, but keep them
+	 * for readability and maintainability.
+	 */
+	nr = (x-x0)*y1 + (x1-x)*y0;
+	dr =  x1-x0;
+
+	if (!dr)
+		return -EINVAL;
+	/*
+	 * We have to report the temperature in milli degree celsius.
+	 * So, to reduce the loss of precision, do (Nr*1000)/Dr, instead
+	 * of (Nr/Dr)*1000.
+	 */
+	*tp = (nr * 1000)/dr;
+
+	return 0;
+}
+
+/**
+ * temp_to_adc - converts the temperature(in C) to ADC code
+ * @direct: true if the sensor uses direct conversion
+ * @temp: the temperature to be converted
+ * @adc_val: ADC code return value
+ *
+ * Can sleep
+ */
+static int temp_to_adc(int direct, int temp, int *adc_val)
+{
+	int indx;
+	int x0, x1, y0, y1;
+	int nr, dr;		/* Numerator & Denominator */
+	int x = temp;
+
+	/* Direct conversion for pmic die temperature */
+	if (direct) {
+		if (temp < PMIC_DIE_TEMP_MIN || temp > PMIC_DIE_TEMP_MAX)
+			return -EINVAL;
+
+		*adc_val = pmic_die_temp_to_adc(temp);
+		return 0;
+	}
+
+	if (temp < adc_code[1][0] || temp > adc_code[1][TABLE_LENGTH - 1])
+		return -EINVAL;
+
+
+	/* Find the 'indx' of this 'temp' in the table */
+	indx = (temp - adc_code[1][0]) / TEMP_INTERVAL;
+
+	if (temp == adc_code[1][indx]) {
+		*adc_val = adc_code[0][indx];
+		return 0;
+	}
+
+	/*
+	 * Temperature is not a multiple of 'TEMP_INTERVAL'. So,
+	 * do linear interpolation to obtain a better ADC code.
+	 */
+	x0 = adc_code[1][indx];
+	x1 = adc_code[1][indx + 1];
+	y0 = adc_code[0][indx];
+	y1 = adc_code[0][indx + 1];
+
+	nr = (x-x0)*y1 + (x1-x)*y0;
+	dr =  x1-x0;
+
+	if (!dr)
+		return -EINVAL;
+
+	*adc_val = nr/dr;
+
+	return 0;
+}
+
+/**
+ * set_tmax - sets the given 'adc_val' to the 'alert_reg'
+ * @alert_reg: register address
+ * @adc_val: ADC value to be programmed
+ *
+ * Not protected. Calling function should handle synchronization.
+ * Can sleep
+ */
+static int set_tmax(int alert_reg, int adc_val)
+{
+	int ret;
+
+	/* Set bits[0:1] of alert_reg_h to bits[8:9] of 'adc_val' */
+	ret = intel_scu_ipc_update_register(alert_reg, (adc_val >> 8), 0x03);
+	if (ret)
+		return ret;
+
+	/* Extract bits[0:7] of 'adc_val' and write them into alert_reg_l */
+	return intel_scu_ipc_iowrite8(alert_reg + 1, adc_val & 0xFF);
+}
+
+/**
+ * program_tmax - programs a default _max value for each sensor
+ * @dev: device pointer
+ *
+ * Can sleep
+ */
+static int program_tmax(struct device *dev)
+{
+	int i, ret;
+	int pmic_die_val, adc_val;
+
+	ret = temp_to_adc(0, DEFAULT_MAX_TEMP, &adc_val);
+	if (ret)
+		return ret;
+
+	ret = temp_to_adc(1, DEFAULT_MAX_TEMP, &pmic_die_val);
+	if (ret)
+		return ret;
+	/*
+	 * Since this function sets max value, do for all sensors even if
+	 * the sensor does not register as a thermal zone.
+	 */
+	for (i = 0; i < PMIC_THERMAL_SENSORS - 1; i++) {
+		ret = set_tmax(alert_regs_h[i], adc_val);
+		if (ret)
+			goto exit_err;
+	}
+
+	/* Set _max for pmic die sensor */
+	ret = set_tmax(alert_regs_h[i], pmic_die_val);
+	if (ret)
+		goto exit_err;
+
+	return ret;
+
+exit_err:
+	dev_err(dev, "set_tmax for channel %d failed:%d\n", i, ret);
+	return ret;
+}
+
+static int store_trip_hyst(struct thermal_zone_device *tzd,
+				int trip, long hyst)
+{
+	int ret;
+	uint8_t data;
+	struct thermal_device_info *td_info = tzd->devdata;
+	int alert_reg = alert_regs_h[td_info->sensor->index];
+
+	/* Hysteresis value is 5 bits wide */
+	if (hyst > 31)
+		return -EINVAL;
+
+	mutex_lock(&thrm_update_lock);
+
+	ret = intel_scu_ipc_ioread8(alert_reg, &data);
+	if (ret)
+		goto ipc_fail;
+
+	/* Set bits [2:6] to value of hyst */
+	data = (data & 0x83) | (hyst << 2);
+
+	ret = intel_scu_ipc_iowrite8(alert_reg, data);
+
+ipc_fail:
+	mutex_unlock(&thrm_update_lock);
+	return ret;
+}
+
+static int show_trip_hyst(struct thermal_zone_device *tzd,
+				int trip, long *hyst)
+{
+	int ret;
+	uint8_t data;
+	struct thermal_device_info *td_info = tzd->devdata;
+	int alert_reg = alert_regs_h[td_info->sensor->index];
+
+	mutex_lock(&thrm_update_lock);
+
+	ret = intel_scu_ipc_ioread8(alert_reg, &data);
+	if (!ret)
+		*hyst = (data >> 2) & 0x1F; /* Extract bits[2:6] of data */
+
+	mutex_unlock(&thrm_update_lock);
+
+	return ret;
+}
+
+static int store_trip_temp(struct thermal_zone_device *tzd,
+				int trip, long trip_temp)
+{
+	int ret, adc_val;
+	struct thermal_device_info *td_info = tzd->devdata;
+	int alert_reg = alert_regs_h[td_info->sensor->index];
+
+	if (trip_temp < 1000) {
+		dev_err(&tzd->device, "Temperature should be in mC\n");
+		return -EINVAL;
+	}
+
+	mutex_lock(&thrm_update_lock);
+
+	/* Convert from mC to C */
+	trip_temp /= 1000;
+
+	ret = temp_to_adc(td_info->sensor->direct, (int)trip_temp, &adc_val);
+	if (ret)
+		goto exit;
+
+	ret =  set_tmax(alert_reg, adc_val);
+exit:
+	mutex_unlock(&thrm_update_lock);
+	return ret;
+}
+
+static int show_trip_temp(struct thermal_zone_device *tzd,
+				int trip, long *trip_temp)
+{
+	int ret, adc_val;
+	uint8_t l, h;
+	struct thermal_device_info *td_info = tzd->devdata;
+	int alert_reg = alert_regs_h[td_info->sensor->index];
+
+	mutex_lock(&thrm_update_lock);
+
+	ret = intel_scu_ipc_ioread8(alert_reg, &h);
+	if (ret)
+		goto exit;
+
+	ret = intel_scu_ipc_ioread8(alert_reg + 1, &l);
+	if (ret)
+		goto exit;
+
+	/* Concatenate 'h' and 'l' to get 10-bit ADC code */
+	adc_val = ((h & 0x03) << 8) | l;
+
+	ret = adc_to_temp(td_info->sensor->direct, adc_val, trip_temp);
+exit:
+	mutex_unlock(&thrm_update_lock);
+	return ret;
+}
+
+static int show_trip_type(struct thermal_zone_device *tzd,
+			int trip, enum thermal_trip_type *trip_type)
+{
+	/* All are passive trip points */
+	*trip_type = THERMAL_TRIP_PASSIVE;
+
+	return 0;
+}
+
+static int show_temp(struct thermal_zone_device *tzd, long *temp)
+{
+	int ret;
+	struct thermal_device_info *td_info = tzd->devdata;
+	int indx = td_info->sensor->index;
+
+	if (!tdata->iio_chan)
+		return -EINVAL;
+
+	mutex_lock(&thrm_update_lock);
+
+	if (!tdata->is_initialized ||
+			time_after(jiffies, tdata->last_updated + HZ)) {
+		ret = iio_read_channel_all_raw(tdata->iio_chan,
+						tdata->cached_vals);
+		if (ret) {
+			dev_err(&tzd->device, "ADC sampling failed:%d\n", ret);
+			goto exit;
+		}
+		tdata->last_updated = jiffies;
+		tdata->is_initialized = true;
+	}
+
+	ret = adc_to_temp(td_info->sensor->direct, tdata->cached_vals[indx],
+								temp);
+	if (ret)
+		goto exit;
+
+	if (td_info->sensor->temp_correlation)
+		ret = td_info->sensor->temp_correlation(td_info->sensor,
+							*temp, temp);
+exit:
+	mutex_unlock(&thrm_update_lock);
+	return ret;
+}
+
+#ifdef CONFIG_DEBUG_THERMAL
+static int read_slope(struct thermal_zone_device *tzd, long *slope)
+{
+	struct thermal_device_info *td_info = tzd->devdata;
+
+	*slope = td_info->sensor->slope;
+
+	return 0;
+}
+
+static int update_slope(struct thermal_zone_device *tzd, long slope)
+{
+	struct thermal_device_info *td_info = tzd->devdata;
+
+	td_info->sensor->slope = slope;
+
+	return 0;
+}
+
+static int read_intercept(struct thermal_zone_device *tzd, long *intercept)
+{
+	struct thermal_device_info *td_info = tzd->devdata;
+
+	*intercept = td_info->sensor->intercept;
+
+	return 0;
+}
+
+static int update_intercept(struct thermal_zone_device *tzd, long intercept)
+{
+	struct thermal_device_info *td_info = tzd->devdata;
+
+	td_info->sensor->intercept = intercept;
+
+	return 0;
+}
+#endif
+
+static int enable_tm(void)
+{
+	int ret;
+	uint8_t data;
+
+	mutex_lock(&thrm_update_lock);
+
+	ret = intel_scu_ipc_ioread8(THRMMONCTL, &data);
+	if (ret)
+		goto ipc_fail;
+
+	ret = intel_scu_ipc_iowrite8(THRMMONCTL, data | THERM_EN);
+
+ipc_fail:
+	mutex_unlock(&thrm_update_lock);
+	return ret;
+}
+
+static struct thermal_device_info *initialize_sensor(
+				struct intel_mid_thermal_sensor *sensor)
+{
+	struct thermal_device_info *td_info =
+		kzalloc(sizeof(struct thermal_device_info), GFP_KERNEL);
+
+	if (!td_info)
+		return NULL;
+
+	td_info->sensor = sensor;
+
+	return td_info;
+}
+
+static irqreturn_t thermal_intrpt(int irq, void *dev_data)
+{
+	int ret, sensor, event_type;
+	uint8_t irq_status;
+	unsigned int irq_data;
+	struct thermal_data *tdata = (struct thermal_data *)dev_data;
+
+	if (!tdata)
+		return IRQ_NONE;
+
+	mutex_lock(&thrm_update_lock);
+
+	irq_data = ioread8(tdata->thrm_addr + PMIC_SRAM_THRM_OFFSET);
+
+	ret = intel_scu_ipc_ioread8(STHRMIRQ, &irq_status);
+	if (ret)
+		goto ipc_fail;
+
+	dev_dbg(&tdata->pdev->dev, "STHRMIRQ: %.2x\n", irq_status);
+
+	/*
+	 * -1 for invalid interrupt
+	 * 1 for LOW to HIGH temperature alert
+	 * 0 for HIGH to LOW temperature alert
+	 */
+	event_type = -1;
+
+	/* Check which interrupt occured and for what event */
+	if (irq_data & PMICALRT) {
+		event_type = !!(irq_status & PMICALRT);
+		sensor = PMIC_DIE;
+	} else if (irq_data & SYS2ALRT) {
+		event_type = !!(irq_status & SYS2ALRT);
+		sensor = SYS2;
+	} else if (irq_data & SYS1ALRT) {
+		event_type = !!(irq_status & SYS1ALRT);
+		sensor = SYS1;
+	} else if (irq_data & SYS0ALRT) {
+		event_type = !!(irq_status & SYS0ALRT);
+		sensor = SYS0;
+	} else {
+		dev_err(&tdata->pdev->dev, "Invalid Interrupt\n");
+		ret = IRQ_HANDLED;
+		goto ipc_fail;
+	}
+
+	if (event_type != -1) {
+		dev_info(&tdata->pdev->dev,
+				"%s interrupt for thermal sensor %d\n",
+				event_type ? "HIGH" : "LOW", sensor);
+	}
+
+	/* Notify using UEvent */
+	kobject_uevent(&tdata->pdev->dev.kobj, KOBJ_CHANGE);
+
+	/* Unmask Thermal Interrupt in the mask register */
+	ret = intel_scu_ipc_update_register(MIRQLVL1, 0xFF, THERM_ALRT);
+	if (ret)
+		goto ipc_fail;
+
+	ret = IRQ_HANDLED;
+
+ipc_fail:
+	mutex_unlock(&thrm_update_lock);
+	return ret;
+}
+
+static struct thermal_zone_device_ops tzd_ops = {
+	.get_temp = show_temp,
+	.get_trip_type = show_trip_type,
+	.get_trip_temp = show_trip_temp,
+	.set_trip_temp = store_trip_temp,
+	.get_trip_hyst = show_trip_hyst,
+	.set_trip_hyst = store_trip_hyst,
+#ifdef CONFIG_DEBUG_THERMAL
+	.get_slope = read_slope,
+	.set_slope = update_slope,
+	.get_intercept = read_intercept,
+	.set_intercept = update_intercept,
+#endif
+};
+
+static irqreturn_t mrfl_thermal_intrpt_handler(int irq, void* dev_data)
+{
+	return IRQ_WAKE_THREAD;
+}
+
+static int mrfl_thermal_probe(struct platform_device *pdev)
+{
+	int ret, i;
+	struct intel_mid_thermal_platform_data *pdata;
+
+	pdata = pdev->dev.platform_data;
+	if (!pdata) {
+		dev_err(&pdev->dev, "platform data not found\n");
+		return -EINVAL;
+	}
+
+	tdata = kzalloc(sizeof(struct thermal_data), GFP_KERNEL);
+	if (!tdata) {
+		dev_err(&pdev->dev, "kzalloc failed\n");
+		return -ENOMEM;
+	}
+
+	tdata->pdev = pdev;
+	tdata->num_sensors = pdata->num_sensors;
+	tdata->sensors = pdata->sensors;
+	tdata->irq = platform_get_irq(pdev, 0);
+	platform_set_drvdata(pdev, tdata);
+
+	tdata->tzd = kzalloc(
+		(sizeof(struct thermal_zone_device *) * tdata->num_sensors),
+								GFP_KERNEL);
+	if (!tdata->tzd) {
+		dev_err(&pdev->dev, "kzalloc failed\n");
+		ret = -ENOMEM;
+		goto exit_free;
+	}
+
+	/* Program a default _max value for each sensor */
+	ret = program_tmax(&pdev->dev);
+	if (ret) {
+		dev_err(&pdev->dev, "Programming _max failed:%d\n", ret);
+		goto exit_tzd;
+	}
+
+	/*
+	 * Register with IIO to sample temperature values
+	 *
+	 * Order of the channels obtained from adc:
+	 * "SYSTHERM0", "SYSTHERM1", "SYSTHERM2", "PMICDIE"
+	 */
+	tdata->iio_chan = iio_channel_get_all(&pdev->dev);
+	if (tdata->iio_chan == NULL) {
+		dev_err(&pdev->dev, "tdata->iio_chan is null\n");
+		ret = -EINVAL;
+		goto exit_tzd;
+	}
+
+	/* Check whether we got all the four channels */
+	ret = iio_channel_get_num(tdata->iio_chan);
+	if (ret != PMIC_THERMAL_SENSORS) {
+		dev_err(&pdev->dev, "incorrect number of channels:%d\n", ret);
+		ret = -EFAULT;
+		goto exit_iio;
+	}
+
+	/* Register each sensor with the generic thermal framework */
+	for (i = 0; i < tdata->num_sensors; i++) {
+		tdata->tzd[i] = thermal_zone_device_register(
+				tdata->sensors[i].name,	1, 1,
+		initialize_sensor(&tdata->sensors[i]), &tzd_ops, NULL, 0, 0);
+
+		if (IS_ERR(tdata->tzd[i])) {
+			ret = PTR_ERR(tdata->tzd[i]);
+			dev_err(&pdev->dev,
+				"registering thermal sensor %s failed: %d\n",
+				tdata->sensors[i].name, ret);
+			goto exit_reg;
+		}
+	}
+
+	tdata->thrm_addr = ioremap_nocache(PMIC_SRAM_BASE_ADDR, IOMAP_SIZE);
+	if (!tdata->thrm_addr) {
+		ret = -ENOMEM;
+		dev_err(&pdev->dev, "ioremap_nocache failed\n");
+		goto exit_reg;
+	}
+
+	/* Register for Interrupt Handler */
+	ret = request_threaded_irq(tdata->irq, mrfl_thermal_intrpt_handler, thermal_intrpt,
+						IRQF_TRIGGER_RISING,
+						DRIVER_NAME, tdata);
+	if (ret) {
+		dev_err(&pdev->dev, "request_threaded_irq failed:%d\n", ret);
+		goto exit_ioremap;
+	}
+
+	/* Enable Thermal Monitoring */
+	ret = enable_tm();
+	if (ret) {
+		dev_err(&pdev->dev, "Enabling TM failed:%d\n", ret);
+		goto exit_irq;
+	}
+
+	return 0;
+
+exit_irq:
+	free_irq(tdata->irq, tdata);
+exit_ioremap:
+	iounmap(tdata->thrm_addr);
+exit_reg:
+	while (--i >= 0)
+		thermal_zone_device_unregister(tdata->tzd[i]);
+exit_iio:
+	iio_channel_release_all(tdata->iio_chan);
+exit_tzd:
+	kfree(tdata->tzd);
+exit_free:
+	kfree(tdata);
+	return ret;
+}
+
+static int mrfl_thermal_resume(struct device *dev)
+{
+	dev_info(dev, "resume called.\n");
+	return 0;
+}
+
+static int mrfl_thermal_suspend(struct device *dev)
+{
+	dev_info(dev, "suspend called.\n");
+	return 0;
+}
+
+static int mrfl_thermal_remove(struct platform_device *pdev)
+{
+	int i;
+	struct thermal_data *tdata = platform_get_drvdata(pdev);
+
+	if (!tdata)
+		return 0;
+
+	for (i = 0; i < tdata->num_sensors; i++)
+		thermal_zone_device_unregister(tdata->tzd[i]);
+
+	free_irq(tdata->irq, tdata);
+	iounmap(tdata->thrm_addr);
+	iio_channel_release_all(tdata->iio_chan);
+	kfree(tdata->tzd);
+	kfree(tdata);
+	return 0;
+}
+
+/*********************************************************************
+ *		Driver initialization and finalization
+ *********************************************************************/
+
+static const struct dev_pm_ops thermal_pm_ops = {
+	.suspend = mrfl_thermal_suspend,
+	.resume = mrfl_thermal_resume,
+};
+
+static struct platform_driver mrfl_thermal_driver = {
+	.driver = {
+		.name = DRIVER_NAME,
+		.owner = THIS_MODULE,
+		.pm = &thermal_pm_ops,
+		},
+	.probe = mrfl_thermal_probe,
+	.remove = mrfl_thermal_remove,
+};
+
+static int mrfl_thermal_module_init(void)
+{
+	return platform_driver_register(&mrfl_thermal_driver);
+}
+
+static void mrfl_thermal_module_exit(void)
+{
+	platform_driver_unregister(&mrfl_thermal_driver);
+}
+
+/* RPMSG related functionality */
+static int mrfl_thermal_rpmsg_probe(struct rpmsg_channel *rpdev)
+{
+	if (!rpdev) {
+		pr_err("rpmsg channel not created\n");
+		return -ENODEV;
+	}
+
+	dev_info(&rpdev->dev, "Probed mrfl_thermal rpmsg device\n");
+
+	return mrfl_thermal_module_init();
+}
+
+static void mrfl_thermal_rpmsg_remove(struct rpmsg_channel *rpdev)
+{
+	mrfl_thermal_module_exit();
+	dev_info(&rpdev->dev, "Removed mrfl_thermal rpmsg device\n");
+}
+
+static void mrfl_thermal_rpmsg_cb(struct rpmsg_channel *rpdev, void *data,
+			int len, void *priv, u32 src)
+{
+	dev_warn(&rpdev->dev, "unexpected, message\n");
+
+	print_hex_dump(KERN_DEBUG, __func__, DUMP_PREFIX_NONE, 16, 1,
+				data, len, true);
+}
+
+static struct rpmsg_device_id mrfl_thermal_id_table[] = {
+	{ .name = "rpmsg_mrfl_thermal" },
+	{ },
+};
+
+MODULE_DEVICE_TABLE(rpmsg, mrfl_thermal_id_table);
+
+static struct rpmsg_driver mrfl_thermal_rpmsg = {
+	.drv.name	= DRIVER_NAME,
+	.drv.owner	= THIS_MODULE,
+	.probe		= mrfl_thermal_rpmsg_probe,
+	.callback	= mrfl_thermal_rpmsg_cb,
+	.remove		= mrfl_thermal_rpmsg_remove,
+	.id_table	= mrfl_thermal_id_table,
+};
+
+static int __init mrfl_thermal_rpmsg_init(void)
+{
+	return register_rpmsg_driver(&mrfl_thermal_rpmsg);
+}
+
+static void __exit mrfl_thermal_rpmsg_exit(void)
+{
+	return unregister_rpmsg_driver(&mrfl_thermal_rpmsg);
+}
+
+module_init(mrfl_thermal_rpmsg_init);
+module_exit(mrfl_thermal_rpmsg_exit);
+
+MODULE_AUTHOR("Durgadoss R <durgadoss.r@intel.com>");
+MODULE_DESCRIPTION("Intel Merrifield Platform Thermal Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/thermal/intel_soc_thermal.c b/drivers/thermal/intel_soc_thermal.c
new file mode 100644
index 0000000..f30b5371
--- /dev/null
+++ b/drivers/thermal/intel_soc_thermal.c
@@ -0,0 +1,834 @@
+/*
+ * intel_soc_thermal.c - Intel SoC Platform Thermal Driver
+ *
+ * Copyright (C) 2012 Intel Corporation
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; version 2 of the License.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.	See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License along
+ * with this program; if not, write to the Free Software Foundation, Inc.,
+ * 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ * Author: Shravan B M <shravan.k.b.m@intel.com>
+ *
+ * This driver registers to Thermal framework as SoC zone. It exposes
+ * two SoC DTS temperature with two writeable trip points.
+ */
+
+#define pr_fmt(fmt)  "intel_soc_thermal: " fmt
+
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/debugfs.h>
+#include <linux/thermal.h>
+#include <linux/seq_file.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
+#include <asm/msr.h>
+#include <asm/intel-mid.h>
+#include <asm/intel_mid_thermal.h>
+
+#define DRIVER_NAME	"soc_thrm"
+
+/* SOC DTS Registers */
+#define SOC_THERMAL_SENSORS	2
+#define SOC_THERMAL_TRIPS	2
+#define SOC_MAX_STATES		4
+#define DTS_ENABLE_REG		0xB0
+#define DTS_ENABLE		0x03
+#define DTS_TRIP_RW		0x03
+
+#define PUNIT_PORT		0x04
+#define PUNIT_TEMP_REG		0xB1
+#define PUNIT_AUX_REG		0xB2
+
+#define TJMAX_TEMP		90
+#define TJMAX_CODE		0x7F
+
+/* Default hysteresis values in C */
+#define DEFAULT_H2C_HYST	3
+#define MAX_HYST		7
+
+/* Power Limit registers */
+#define PKG_TURBO_POWER_LIMIT	0x610
+#define PKG_TURBO_CFG		0x670
+#define MSR_THERM_CFG1		0x673
+#define CPU_PWR_BUDGET_CTL	0x02
+
+/* PKG_TURBO_PL1 holds PL1 in terms of 32mW */
+#define PL_UNIT_MW		32
+
+/* Magic number symbolising Dynamic Turbo OFF */
+#define DISABLE_DYNAMIC_TURBO	0xB0FF
+
+/* IRQ details */
+#define SOC_DTS_CONTROL		0x80
+#define TRIP_STATUS_RO		0xB3
+#define TRIP_STATUS_RW		0xB4
+/* TE stands for THERMAL_EVENT */
+#define TE_AUX0			0xB5
+#define ENABLE_AUX_INTRPT	0x0F
+#define ENABLE_CPU0		(1 << 16)
+#define RTE_ENABLE		(1 << 9)
+
+static int tjmax_temp;
+
+static DEFINE_MUTEX(thrm_update_lock);
+
+struct platform_soc_data {
+	struct thermal_zone_device *tzd[SOC_THERMAL_SENSORS];
+	struct thermal_cooling_device *soc_cdev; /* PL1 control */
+	int irq;
+};
+
+struct cooling_device_info {
+	struct soc_throttle_data *soc_data;
+	/* Lock protecting the soc_cur_state variable */
+	struct mutex lock_state;
+	unsigned long soc_cur_state;
+};
+
+struct thermal_device_info {
+	int sensor_index;
+	struct mutex lock_aux;
+};
+
+static inline u32 read_soc_reg(unsigned int addr)
+{
+	return intel_mid_msgbus_read32(PUNIT_PORT, addr);
+}
+
+static inline void write_soc_reg(unsigned int addr, u32 val)
+{
+	intel_mid_msgbus_write32(PUNIT_PORT, addr, val);
+}
+
+#ifdef CONFIG_DEBUG_FS
+struct dts_regs {
+	char *name;
+	u32 addr;
+} dts_regs[] = {
+	/* Thermal Management Registers */
+	{"PTMC",	0x80},
+	{"TRR0",	0x81},
+	{"TRR1",	0x82},
+	{"TTS",		0x83},
+	{"TELB",	0x84},
+	{"TELT",	0x85},
+	{"GFXT",	0x88},
+	{"VEDT",	0x89},
+	{"VECT",	0x8A},
+	{"VSPT",	0x8B},
+	{"ISPT",	0x8C},
+	{"SWT",		0x8D},
+	/* Trip Event Registers */
+	{"DTSC",	0xB0},
+	{"TRR",		0xB1},
+	{"PTPS",	0xB2},
+	{"PTTS",	0xB3},
+	{"PTTSS",	0xB4},
+	{"TE_AUX0",	0xB5},
+	{"TE_AUX1",	0xB6},
+	{"TE_AUX2",	0xB7},
+	{"TE_AUX3",	0xB8},
+	{"TTE_VRIcc",	0xB9},
+	{"TTE_VRHOT",	0xBA},
+	{"TTE_PROCHOT",	0xBB},
+	{"TTE_SLM0",	0xBC},
+	{"TTE_SLM1",	0xBD},
+	{"BWTE",	0xBE},
+	{"TTE_SWT",	0xBF},
+	/* MSI Message Registers */
+	{"TMA",		0xC0},
+	{"TMD",		0xC1},
+};
+
+/* /sys/kernel/debug/soc_thermal/soc_dts */
+static struct dentry *soc_dts_dent;
+static struct dentry *soc_thermal_dir;
+
+static int soc_dts_debugfs_show(struct seq_file *s, void *unused)
+{
+	int i;
+	u32 val;
+
+	for (i = 0; i < ARRAY_SIZE(dts_regs); i++) {
+		val = read_soc_reg(dts_regs[i].addr);
+		seq_printf(s,
+			"%s[0x%X]	Val: 0x%X\n",
+			dts_regs[i].name, dts_regs[i].addr, val);
+	}
+	return 0;
+}
+
+static int debugfs_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, soc_dts_debugfs_show, NULL);
+}
+
+static const struct file_operations soc_dts_debugfs_fops = {
+	.open           = debugfs_open,
+	.read           = seq_read,
+	.llseek         = seq_lseek,
+	.release        = single_release,
+};
+
+static void create_soc_dts_debugfs(void)
+{
+	int err;
+
+	/* /sys/kernel/debug/soc_thermal/ */
+	soc_thermal_dir = debugfs_create_dir("soc_thermal", NULL);
+	if (IS_ERR(soc_thermal_dir)) {
+		err = PTR_ERR(soc_thermal_dir);
+		pr_err("debugfs_create_dir failed:%d\n", err);
+		return;
+	}
+
+	/* /sys/kernel/debug/soc_thermal/soc_dts */
+	soc_dts_dent = debugfs_create_file("soc_dts", S_IFREG | S_IRUGO,
+					soc_thermal_dir, NULL,
+					&soc_dts_debugfs_fops);
+	if (IS_ERR(soc_dts_dent)) {
+		err = PTR_ERR(soc_dts_dent);
+		debugfs_remove_recursive(soc_thermal_dir);
+		pr_err("debugfs_create_file failed:%d\n", err);
+	}
+}
+
+static void remove_soc_dts_debugfs(void)
+{
+	debugfs_remove_recursive(soc_thermal_dir);
+}
+#else
+static inline void create_soc_dts_debugfs(void) { }
+static inline void remove_soc_dts_debugfs(void) { }
+#endif
+
+static
+struct cooling_device_info *initialize_cdev(struct platform_device *pdev)
+{
+	struct cooling_device_info *cdev_info =
+		kzalloc(sizeof(struct cooling_device_info), GFP_KERNEL);
+	if (!cdev_info)
+		return NULL;
+
+	cdev_info->soc_data = pdev->dev.platform_data;
+	mutex_init(&cdev_info->lock_state);
+	return cdev_info;
+}
+
+static struct thermal_device_info *initialize_sensor(int index)
+{
+	struct thermal_device_info *td_info =
+		kzalloc(sizeof(struct thermal_device_info), GFP_KERNEL);
+
+	if (!td_info)
+		return NULL;
+	td_info->sensor_index = index;
+	mutex_init(&td_info->lock_aux);
+
+	return td_info;
+}
+
+static void enable_soc_dts(void)
+{
+	int i;
+	u32 val, eax, edx;
+
+	rdmsr_on_cpu(0, MSR_THERM_CFG1, &eax, &edx);
+
+	/* B[8:10] H2C Hyst */
+	eax = (eax & ~(0x7 << 8)) | (DEFAULT_H2C_HYST << 8);
+
+	/* Set the Hysteresis value */
+	wrmsr_on_cpu(0, MSR_THERM_CFG1, eax, edx);
+
+	/* Enable the DTS */
+	write_soc_reg(DTS_ENABLE_REG, DTS_ENABLE);
+
+	val = read_soc_reg(SOC_DTS_CONTROL);
+	write_soc_reg(SOC_DTS_CONTROL, val | ENABLE_AUX_INTRPT | ENABLE_CPU0);
+
+	/* Enable Interrupts for all the AUX trips for the DTS */
+	for (i = 0; i < SOC_THERMAL_TRIPS; i++) {
+		val = read_soc_reg(TE_AUX0 + i);
+		write_soc_reg(TE_AUX0 + i, (val | RTE_ENABLE));
+	}
+}
+
+static int show_trip_hyst(struct thermal_zone_device *tzd,
+				int trip, long *hyst)
+{
+	u32 eax, edx;
+	struct thermal_device_info *td_info = tzd->devdata;
+
+	/* Hysteresis is only supported for trip point 0 */
+	if (trip != 0) {
+		*hyst = 0;
+		return 0;
+	}
+
+	mutex_lock(&td_info->lock_aux);
+
+	rdmsr_on_cpu(0, MSR_THERM_CFG1, &eax, &edx);
+
+	/* B[8:10] H2C Hyst, for trip 0. Report hysteresis in mC */
+	*hyst = ((eax >> 8) & 0x7) * 1000;
+
+	mutex_unlock(&td_info->lock_aux);
+	return 0;
+}
+
+static int store_trip_hyst(struct thermal_zone_device *tzd,
+				int trip, long hyst)
+{
+	u32 eax, edx;
+	struct thermal_device_info *td_info = tzd->devdata;
+
+	/* Convert from mC to C */
+	hyst /= 1000;
+
+	if (trip != 0 || hyst < 0 || hyst > MAX_HYST)
+		return -EINVAL;
+
+	mutex_lock(&td_info->lock_aux);
+
+	rdmsr_on_cpu(0, MSR_THERM_CFG1, &eax, &edx);
+
+	/* B[8:10] H2C Hyst */
+	eax = (eax & ~(0x7 << 8)) | (hyst << 8);
+
+	wrmsr_on_cpu(0, MSR_THERM_CFG1, eax, edx);
+
+	mutex_unlock(&td_info->lock_aux);
+	return 0;
+}
+
+static int show_temp(struct thermal_zone_device *tzd, long *temp)
+{
+	struct thermal_device_info *td_info = tzd->devdata;
+	u32 val = read_soc_reg(PUNIT_TEMP_REG);
+
+	/* Extract bits[0:7] or [8:15] using sensor_index */
+	*temp =  (val >> (8 * td_info->sensor_index)) & 0xFF;
+
+	if (*temp == 0)
+		return 0;
+
+	/* Calibrate the temperature */
+	*temp = TJMAX_CODE - *temp + tjmax_temp;
+
+	/* Convert to mC */
+	*temp *= 1000;
+
+	return 0;
+}
+
+static int show_trip_type(struct thermal_zone_device *tzd,
+			int trip, enum thermal_trip_type *trip_type)
+{
+	/* All are passive trip points */
+	*trip_type = THERMAL_TRIP_PASSIVE;
+
+	return 0;
+}
+
+static int show_trip_temp(struct thermal_zone_device *tzd,
+				int trip, long *trip_temp)
+{
+	u32 aux_value = read_soc_reg(PUNIT_AUX_REG);
+
+	/* aux0 b[0:7], aux1 b[8:15], aux2 b[16:23], aux3 b[24:31] */
+	*trip_temp = (aux_value >> (8 * trip)) & 0xFF;
+
+	/* Calibrate the trip point temperature */
+	*trip_temp = tjmax_temp - *trip_temp;
+
+	/* Convert to mC and report */
+	*trip_temp *= 1000;
+
+	return 0;
+}
+
+static int store_trip_temp(struct thermal_zone_device *tzd,
+				int trip, long trip_temp)
+{
+	u32 aux_trip, aux = 0;
+	struct thermal_device_info *td_info = tzd->devdata;
+
+	/* Convert from mC to C */
+	trip_temp /= 1000;
+
+	/* The trip temp is 8 bits wide (unsigned) */
+	if (trip_temp > 255)
+		return -EINVAL;
+
+	/* Assign last byte to unsigned 32 */
+	aux_trip = trip_temp & 0xFF;
+
+	/* Calibrate w.r.t TJMAX_TEMP */
+	aux_trip = tjmax_temp - aux_trip;
+
+	mutex_lock(&td_info->lock_aux);
+	aux = read_soc_reg(PUNIT_AUX_REG);
+	switch (trip) {
+	case 0:
+		/* aux0 bits 0:7 */
+		aux = (aux & 0xFFFFFF00) | (aux_trip << (8 * trip));
+		break;
+	case 1:
+		/* aux1 bits 8:15 */
+		aux = (aux & 0xFFFF00FF) | (aux_trip << (8 * trip));
+		break;
+	}
+	write_soc_reg(PUNIT_AUX_REG, aux);
+
+	mutex_unlock(&td_info->lock_aux);
+
+	return 0;
+}
+
+/* SoC cooling device callbacks */
+static int soc_get_max_state(struct thermal_cooling_device *cdev,
+				unsigned long *state)
+{
+	/* SoC has 4 levels of throttling from 0 to 3 */
+	*state = SOC_MAX_STATES - 1;
+	return 0;
+}
+
+static int soc_get_cur_state(struct thermal_cooling_device *cdev,
+				unsigned long *state)
+{
+	struct cooling_device_info *cdev_info =
+			(struct cooling_device_info *)cdev->devdata;
+
+	mutex_lock(&cdev_info->lock_state);
+	*state = cdev_info->soc_cur_state;
+	mutex_unlock(&cdev_info->lock_state);
+
+	return 0;
+}
+
+static void set_floor_freq(int val)
+{
+	u32 eax;
+
+	eax = read_soc_reg(CPU_PWR_BUDGET_CTL);
+
+	/* Set bits[8:14] of eax to val */
+	eax = (eax & ~(0x7F << 8)) | (val << 8);
+
+	write_soc_reg(CPU_PWR_BUDGET_CTL, eax);
+}
+
+static int disable_dynamic_turbo(struct cooling_device_info *cdev_info)
+{
+	u32 eax, edx;
+
+	mutex_lock(&cdev_info->lock_state);
+
+	rdmsr_on_cpu(0, PKG_TURBO_CFG, &eax, &edx);
+
+	/* Set bits[0:2] to 0 to enable TjMax Turbo mode */
+	eax = eax & ~0x07;
+
+	/* Set bit[8] to 0 to disable Dynamic Turbo */
+	eax = eax & ~(1 << 8);
+
+	/* Set bits[9:11] to 0 disable Dynamic Turbo Policy */
+	eax = eax & ~(0x07 << 9);
+
+	wrmsr_on_cpu(0, PKG_TURBO_CFG, eax, edx);
+
+	/*
+	 * Now that we disabled Dynamic Turbo, we can
+	 * make the floor frequency ratio also 0.
+	 */
+	set_floor_freq(0);
+
+	cdev_info->soc_cur_state = DISABLE_DYNAMIC_TURBO;
+
+	mutex_unlock(&cdev_info->lock_state);
+	return 0;
+}
+
+static int soc_set_cur_state(struct thermal_cooling_device *cdev,
+				unsigned long state)
+{
+	u32 eax, edx;
+	struct soc_throttle_data *data;
+	struct cooling_device_info *cdev_info =
+			(struct cooling_device_info *)cdev->devdata;
+
+	if (state == DISABLE_DYNAMIC_TURBO)
+		return disable_dynamic_turbo(cdev_info);
+
+	if (state >= SOC_MAX_STATES) {
+		pr_err("Invalid SoC throttle state:%ld\n", state);
+		return -EINVAL;
+	}
+
+	mutex_lock(&cdev_info->lock_state);
+
+	data = &cdev_info->soc_data[state];
+
+	rdmsr_on_cpu(0, PKG_TURBO_POWER_LIMIT, &eax, &edx);
+
+	/* Set bits[0:14] of eax to 'data->power_limit' */
+	eax = (eax & ~0x7FFF) | data->power_limit;
+
+	wrmsr_on_cpu(0, PKG_TURBO_POWER_LIMIT, eax, edx);
+
+	set_floor_freq(data->floor_freq);
+
+	cdev_info->soc_cur_state = state;
+
+	mutex_unlock(&cdev_info->lock_state);
+	return 0;
+}
+
+#ifdef CONFIG_DEBUG_THERMAL
+static int soc_get_force_state_override(struct thermal_cooling_device *cdev,
+					char *buf)
+{
+	int i;
+	int pl1_vals_mw[SOC_MAX_STATES];
+	struct cooling_device_info *cdev_info =
+			(struct cooling_device_info *)cdev->devdata;
+
+	mutex_lock(&cdev_info->lock_state);
+
+	/* PKG_TURBO_PL1 holds PL1 in terms of 32mW. So, multiply by 32 */
+	for (i = 0; i < SOC_MAX_STATES; i++) {
+		pl1_vals_mw[i] =
+			cdev_info->soc_data[i].power_limit * PL_UNIT_MW;
+	}
+
+	mutex_unlock(&cdev_info->lock_state);
+
+	return sprintf(buf, "%d %d %d %d\n", pl1_vals_mw[0], pl1_vals_mw[1],
+					pl1_vals_mw[2], pl1_vals_mw[3]);
+}
+
+static int soc_set_force_state_override(struct thermal_cooling_device *cdev,
+					char *buf)
+{
+	int i, ret;
+	int pl1_vals_mw[SOC_MAX_STATES];
+	unsigned long cur_state;
+	struct cooling_device_info *cdev_info =
+				(struct cooling_device_info *)cdev->devdata;
+
+	/*
+	 * The four space separated values entered via the sysfs node
+	 * override the default values configured through platform data.
+	 */
+	ret = sscanf(buf, "%d %d %d %d", &pl1_vals_mw[0], &pl1_vals_mw[1],
+					&pl1_vals_mw[2], &pl1_vals_mw[3]);
+	if (ret != SOC_MAX_STATES) {
+		pr_err("Invalid values in soc_set_force_state_override\n");
+		return -EINVAL;
+	}
+
+	mutex_lock(&cdev_info->lock_state);
+
+	/* PKG_TURBO_PL1 takes PL1 in terms of 32mW. So, divide by 32 */
+	for (i = 0; i < SOC_MAX_STATES; i++) {
+		cdev_info->soc_data[i].power_limit =
+					pl1_vals_mw[i] / PL_UNIT_MW;
+	}
+
+	/* Update the cur_state value of this cooling device */
+	cur_state = cdev_info->soc_cur_state;
+
+	mutex_unlock(&cdev_info->lock_state);
+
+	return soc_set_cur_state(cdev, cur_state);
+}
+#endif
+
+static void notify_thermal_event(struct thermal_zone_device *tzd,
+				long temp, int event, int level)
+{
+	char *thermal_event[5];
+
+	pr_info("Thermal Event: sensor: %s, cur_temp: %ld, event: %d, level: %d\n",
+				tzd->type, temp, event, level);
+
+	thermal_event[0] = kasprintf(GFP_KERNEL, "NAME=%s", tzd->type);
+	thermal_event[1] = kasprintf(GFP_KERNEL, "TEMP=%ld", temp);
+	thermal_event[2] = kasprintf(GFP_KERNEL, "EVENT=%d", event);
+	thermal_event[3] = kasprintf(GFP_KERNEL, "LEVEL=%d", level);
+	thermal_event[4] = NULL;
+
+	kobject_uevent_env(&tzd->device.kobj, KOBJ_CHANGE, thermal_event);
+
+	kfree(thermal_event[3]);
+	kfree(thermal_event[2]);
+	kfree(thermal_event[1]);
+	kfree(thermal_event[0]);
+
+	return;
+}
+
+static int get_max_temp(struct platform_soc_data *pdata, long *cur_temp)
+{
+	int i, ret;
+	long temp;
+
+	/*
+	 * The SoC has two or more DTS placed, to determine the
+	 * temperature of the SoC. The hardware actions are taken
+	 * using T(DTS) which is MAX(T(DTS0), T(DTS1), ... T(DTSn))
+	 *
+	 * Do not report error, as long as we can read at least
+	 * one DTS correctly.
+	 */
+	ret = show_temp(pdata->tzd[0], cur_temp);
+	if (ret)
+		return ret;
+
+	for (i = 1; i < SOC_THERMAL_SENSORS; i++) {
+		ret = show_temp(pdata->tzd[i], &temp);
+		if (ret)
+			goto fail_safe;
+
+		if (temp > *cur_temp)
+			*cur_temp = temp;
+	}
+
+fail_safe:
+	/*
+	 * We have one valid DTS temperature; Use that,
+	 * instead of reporting error.
+	 */
+	return 0;
+}
+
+static irqreturn_t soc_dts_intrpt(int irq, void *dev_data)
+{
+	u32 irq_sts, cur_sts;
+	int i, ret, event, level = -1;
+	long cur_temp;
+	struct thermal_zone_device *tzd;
+	struct platform_soc_data *pdata = (struct platform_soc_data *)dev_data;
+
+	if (!pdata || !pdata->tzd[0])
+		return IRQ_NONE;
+
+	mutex_lock(&thrm_update_lock);
+
+	tzd = pdata->tzd[0];
+
+	irq_sts = read_soc_reg(TRIP_STATUS_RW);
+	cur_sts = read_soc_reg(TRIP_STATUS_RO);
+
+	for (i = 0; i < SOC_THERMAL_TRIPS; i++) {
+		if (irq_sts & (1 << i)) {
+			level = i;
+			event = !!(cur_sts & (1 << i));
+			/* Clear the status bit by writing 1 */
+			irq_sts |= (1 << i);
+			break;
+		}
+	}
+
+	/* level == -1, indicates an invalid event */
+	if (level == -1) {
+		dev_err(&tzd->device, "Invalid event from SoC DTS\n");
+		goto exit;
+	}
+
+	ret = get_max_temp(pdata, &cur_temp);
+	if (ret) {
+		dev_err(&tzd->device, "Cannot read SoC DTS temperature\n");
+		goto exit;
+	}
+
+	/* Notify using UEvent */
+	notify_thermal_event(tzd, cur_temp, event, level);
+
+	/* Clear the status bits */
+	write_soc_reg(TRIP_STATUS_RW, irq_sts);
+
+exit:
+	mutex_unlock(&thrm_update_lock);
+	return IRQ_HANDLED;
+}
+
+static struct thermal_zone_device_ops tzd_ops = {
+	.get_temp = show_temp,
+	.get_trip_type = show_trip_type,
+	.get_trip_temp = show_trip_temp,
+	.set_trip_temp = store_trip_temp,
+	.get_trip_hyst = show_trip_hyst,
+	.set_trip_hyst = store_trip_hyst,
+};
+
+static struct thermal_cooling_device_ops soc_cooling_ops = {
+	.get_max_state = soc_get_max_state,
+	.get_cur_state = soc_get_cur_state,
+	.set_cur_state = soc_set_cur_state,
+#ifdef CONFIG_DEBUG_THERMAL
+	.get_force_state_override = soc_get_force_state_override,
+	.set_force_state_override = soc_set_force_state_override,
+#endif
+};
+
+/*********************************************************************
+ *		Driver initialization and finalization
+ *********************************************************************/
+
+static irqreturn_t soc_dts_intrpt_handler(int irq, void *dev_data)
+{
+	return IRQ_WAKE_THREAD;
+}
+
+static int soc_thermal_probe(struct platform_device *pdev)
+{
+	struct platform_soc_data *pdata;
+	int i, ret;
+	u32 eax, edx;
+	static char *name[SOC_THERMAL_SENSORS] = {"SoC_DTS0", "SoC_DTS1"};
+
+	pdata = kzalloc(sizeof(struct platform_soc_data), GFP_KERNEL);
+	if (!pdata)
+		return -ENOMEM;
+
+	ret = rdmsr_safe_on_cpu(0, MSR_IA32_TEMPERATURE_TARGET, &eax, &edx);
+	if (ret) {
+		tjmax_temp = TJMAX_TEMP;
+		dev_err(&pdev->dev, "TjMax read from MSR %x failed, error:%d\n",
+				MSR_IA32_TEMPERATURE_TARGET, ret);
+	} else {
+		tjmax_temp = (eax >> 16) & 0xff;
+		dev_dbg(&pdev->dev, "TjMax is %d degrees C\n", tjmax_temp);
+	}
+
+	/* Register each sensor with the generic thermal framework */
+	for (i = 0; i < SOC_THERMAL_SENSORS; i++) {
+		pdata->tzd[i] = thermal_zone_device_register(name[i],
+					SOC_THERMAL_TRIPS, DTS_TRIP_RW,
+					initialize_sensor(i),
+					&tzd_ops, NULL, 0, 0);
+		if (IS_ERR(pdata->tzd[i])) {
+			ret = PTR_ERR(pdata->tzd[i]);
+			dev_err(&pdev->dev, "tzd register failed: %d\n", ret);
+			goto exit_reg;
+		}
+	}
+
+	/* Register a cooling device for PL1 (power limit) control */
+	pdata->soc_cdev = thermal_cooling_device_register("SoC",
+						initialize_cdev(pdev),
+						&soc_cooling_ops);
+	if (IS_ERR(pdata->soc_cdev)) {
+		ret = PTR_ERR(pdata->soc_cdev);
+		pdata->soc_cdev = NULL;
+		goto exit_reg;
+	}
+
+	platform_set_drvdata(pdev, pdata);
+
+	ret = platform_get_irq(pdev, 0);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "platform_get_irq failed:%d\n", ret);
+		goto exit_cdev;
+	}
+
+	pdata->irq = ret;
+
+	/* Register for Interrupt Handler */
+	ret = request_threaded_irq(pdata->irq, soc_dts_intrpt_handler,
+						soc_dts_intrpt,
+						IRQF_TRIGGER_RISING,
+						DRIVER_NAME, pdata);
+	if (ret) {
+		dev_err(&pdev->dev, "request_threaded_irq failed:%d\n", ret);
+		goto exit_cdev;
+	}
+
+	/* Enable DTS0 and DTS1 */
+	enable_soc_dts();
+
+	create_soc_dts_debugfs();
+
+	return 0;
+
+exit_cdev:
+	thermal_cooling_device_unregister(pdata->soc_cdev);
+exit_reg:
+	while (--i >= 0) {
+		struct thermal_device_info *td_info = pdata->tzd[i]->devdata;
+		kfree(td_info);
+		thermal_zone_device_unregister(pdata->tzd[i]);
+	}
+	platform_set_drvdata(pdev, NULL);
+	kfree(pdata);
+	return ret;
+}
+
+static int soc_thermal_remove(struct platform_device *pdev)
+{
+	int i;
+	struct platform_soc_data *pdata = platform_get_drvdata(pdev);
+
+	/* Unregister each sensor with the generic thermal framework */
+	for (i = 0; i < SOC_THERMAL_SENSORS; i++) {
+		struct thermal_device_info *td_info = pdata->tzd[i]->devdata;
+		kfree(td_info);
+		thermal_zone_device_unregister(pdata->tzd[i]);
+	}
+	thermal_cooling_device_unregister(pdata->soc_cdev);
+	platform_set_drvdata(pdev, NULL);
+	free_irq(pdata->irq, pdata);
+	kfree(pdata);
+
+	remove_soc_dts_debugfs();
+
+	return 0;
+}
+
+static const struct platform_device_id therm_id_table[] = {
+	{ DRIVER_NAME, 1},
+};
+
+static struct platform_driver soc_thermal_driver = {
+	.driver = {
+		.owner = THIS_MODULE,
+		.name = DRIVER_NAME,
+	},
+	.probe = soc_thermal_probe,
+	.remove = soc_thermal_remove,
+	.id_table = therm_id_table,
+};
+
+static int __init soc_thermal_module_init(void)
+{
+	return platform_driver_register(&soc_thermal_driver);
+}
+
+static void __exit soc_thermal_module_exit(void)
+{
+	platform_driver_unregister(&soc_thermal_driver);
+}
+
+module_init(soc_thermal_module_init);
+module_exit(soc_thermal_module_exit);
+
+MODULE_AUTHOR("Shravan B M <shravan.k.b.m@intel.com>");
+MODULE_DESCRIPTION("Intel SoC Thermal Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/thermal/thermal_core.c b/drivers/thermal/thermal_core.c
index 284733e..1bb96e7 100644
--- a/drivers/thermal/thermal_core.c
+++ b/drivers/thermal/thermal_core.c
@@ -596,7 +596,7 @@ trip_point_temp_store(struct device *dev, struct device_attribute *attr,
 {
 	struct thermal_zone_device *tz = to_thermal_zone(dev);
 	int trip, ret;
-	unsigned long temperature;
+	long temperature;
 
 	if (!tz->ops->set_trip_temp)
 		return -EPERM;
@@ -740,6 +740,82 @@ passive_show(struct device *dev, struct device_attribute *attr,
 }
 
 static ssize_t
+slope_store(struct device *dev, struct device_attribute *attr,
+		    const char *buf, size_t count)
+{
+	int ret;
+	long slope;
+	struct thermal_zone_device *tz = to_thermal_zone(dev);
+
+	if (!tz->ops->set_slope)
+		return -EPERM;
+
+	if (kstrtol(buf, 10, &slope))
+		return -EINVAL;
+
+	ret = tz->ops->set_slope(tz, slope);
+	if (ret)
+		return ret;
+
+	return count;
+}
+
+static ssize_t
+slope_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	int ret;
+	long slope;
+	struct thermal_zone_device *tz = to_thermal_zone(dev);
+
+	if (!tz->ops->get_slope)
+		return -EINVAL;
+
+	ret = tz->ops->get_slope(tz, &slope);
+	if (ret)
+		return ret;
+
+	return sprintf(buf, "%ld\n", slope);
+}
+
+static ssize_t
+intercept_store(struct device *dev, struct device_attribute *attr,
+		    const char *buf, size_t count)
+{
+	int ret;
+	long intercept;
+	struct thermal_zone_device *tz = to_thermal_zone(dev);
+
+	if (!tz->ops->set_intercept)
+		return -EPERM;
+
+	if (kstrtol(buf, 10, &intercept))
+		return -EINVAL;
+
+	ret = tz->ops->set_intercept(tz, intercept);
+	if (ret)
+		return ret;
+
+	return count;
+}
+
+static ssize_t
+intercept_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	int ret;
+	long intercept;
+	struct thermal_zone_device *tz = to_thermal_zone(dev);
+
+	if (!tz->ops->get_intercept)
+		return -EINVAL;
+
+	ret = tz->ops->get_intercept(tz, &intercept);
+	if (ret)
+		return ret;
+
+	return sprintf(buf, "%ld\n", intercept);
+}
+
+static ssize_t
 policy_store(struct device *dev, struct device_attribute *attr,
 		    const char *buf, size_t count)
 {
@@ -804,6 +880,9 @@ static DEVICE_ATTR(type, 0444, type_show, NULL);
 static DEVICE_ATTR(temp, 0444, temp_show, NULL);
 static DEVICE_ATTR(mode, 0644, mode_show, mode_store);
 static DEVICE_ATTR(passive, S_IRUGO | S_IWUSR, passive_show, passive_store);
+static DEVICE_ATTR(slope, S_IRUGO | S_IWUSR, slope_show, slope_store);
+static DEVICE_ATTR(intercept,
+		S_IRUGO | S_IWUSR, intercept_show, intercept_store);
 static DEVICE_ATTR(policy, S_IRUGO | S_IWUSR, policy_show, policy_store);
 
 /* sys I/F for cooling device */
@@ -833,6 +912,43 @@ thermal_cooling_device_max_state_show(struct device *dev,
 	return sprintf(buf, "%ld\n", state);
 }
 
+/*
+ * Sysfs to read the mapped values and to override
+ * the default values mapped to each state during runtime.
+ */
+static ssize_t
+thermal_cooling_device_force_state_override_show(struct device *dev,
+			struct device_attribute *attr, char *buf)
+{
+	struct thermal_cooling_device *cdev = to_cooling_device(dev);
+
+	return cdev->ops->get_force_state_override(cdev, buf);
+}
+
+static ssize_t
+thermal_cooling_device_force_state_override_store(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t count)
+{
+	int ret;
+	struct thermal_cooling_device *cdev = to_cooling_device(dev);
+
+	ret = cdev->ops->set_force_state_override(cdev, (char *) buf);
+	if (ret)
+		return ret;
+
+	return count;
+}
+
+static ssize_t
+thermal_cooling_device_available_states_show(struct device *dev,
+				struct device_attribute *attr, char *buf)
+{
+	struct thermal_cooling_device *cdev = to_cooling_device(dev);
+
+	return cdev->ops->get_available_states(cdev, buf);
+}
+
 static ssize_t
 thermal_cooling_device_cur_state_show(struct device *dev,
 				      struct device_attribute *attr, char *buf)
@@ -875,6 +991,11 @@ static DEVICE_ATTR(max_state, 0444,
 static DEVICE_ATTR(cur_state, 0644,
 		   thermal_cooling_device_cur_state_show,
 		   thermal_cooling_device_cur_state_store);
+static DEVICE_ATTR(force_state_override, 0644,
+		thermal_cooling_device_force_state_override_show,
+		thermal_cooling_device_force_state_override_store);
+static DEVICE_ATTR(available_states, 0444,
+		thermal_cooling_device_available_states_show, NULL);
 
 static ssize_t
 thermal_cooling_device_trip_point_show(struct device *dev,
@@ -1138,13 +1259,26 @@ __thermal_cooling_device_register(struct device_node *np,
 
 	result = device_create_file(&cdev->device, &dev_attr_max_state);
 	if (result)
-		goto unregister;
+		goto remove_type;
 
 	result = device_create_file(&cdev->device, &dev_attr_cur_state);
 	if (result)
-		goto unregister;
+		goto remove_max_state;
+
+	if (ops->get_force_state_override) {
+		result = device_create_file(&cdev->device,
+					&dev_attr_force_state_override);
+		if (result)
+			goto remove_cur_state;
+	}
 
 	/* Add 'this' new cdev to the global cdev list */
+	if (ops->get_available_states) {
+		result = device_create_file(&cdev->device,
+						&dev_attr_available_states);
+		if (result)
+			goto remove_force_override;
+	}
 	mutex_lock(&thermal_list_lock);
 	list_add(&cdev->node, &thermal_cdev_list);
 	mutex_unlock(&thermal_list_lock);
@@ -1154,6 +1288,16 @@ __thermal_cooling_device_register(struct device_node *np,
 
 	return cdev;
 
+remove_force_override:
+	if (cdev->ops->get_force_state_override)
+		device_remove_file(&cdev->device,
+				&dev_attr_force_state_override);
+remove_cur_state:
+	device_remove_file(&cdev->device, &dev_attr_cur_state);
+remove_max_state:
+	device_remove_file(&cdev->device, &dev_attr_max_state);
+remove_type:
+	device_remove_file(&cdev->device, &dev_attr_cdev_type);
 unregister:
 	release_idr(&thermal_cdev_idr, &thermal_idr_lock, cdev->id);
 	device_unregister(&cdev->device);
@@ -1258,7 +1402,12 @@ void thermal_cooling_device_unregister(struct thermal_cooling_device *cdev)
 		device_remove_file(&cdev->device, &dev_attr_cdev_type);
 	device_remove_file(&cdev->device, &dev_attr_max_state);
 	device_remove_file(&cdev->device, &dev_attr_cur_state);
-
+	if (cdev->ops->get_force_state_override)
+		device_remove_file(&cdev->device,
+					&dev_attr_force_state_override);
+	if (cdev->ops->get_available_states)
+		device_remove_file(&cdev->device,
+					&dev_attr_available_states);
 	release_idr(&thermal_cdev_idr, &thermal_idr_lock, cdev->id);
 	device_unregister(&cdev->device);
 	return;
@@ -1528,6 +1677,19 @@ struct thermal_zone_device *thermal_zone_device_register(const char *type,
 			goto unregister;
 	}
 
+	/* Create Sysfs for slope/intercept values */
+	if (tz->ops->get_slope) {
+		result = device_create_file(&tz->device, &dev_attr_slope);
+		if (result)
+			goto unregister;
+	}
+
+	if (tz->ops->get_intercept) {
+		result = device_create_file(&tz->device, &dev_attr_intercept);
+		if (result)
+			goto unregister;
+	}
+
 #ifdef CONFIG_THERMAL_EMULATION
 	result = device_create_file(&tz->device, &dev_attr_emul_temp);
 	if (result)
@@ -1632,6 +1794,11 @@ void thermal_zone_device_unregister(struct thermal_zone_device *tz)
 	device_remove_file(&tz->device, &dev_attr_temp);
 	if (tz->ops->get_mode)
 		device_remove_file(&tz->device, &dev_attr_mode);
+	if (tz->ops->get_slope)
+		device_remove_file(&tz->device, &dev_attr_slope);
+	if (tz->ops->get_intercept)
+		device_remove_file(&tz->device, &dev_attr_intercept);
+
 	device_remove_file(&tz->device, &dev_attr_policy);
 	remove_trip_attrs(tz);
 	tz->governor = NULL;
diff --git a/drivers/usb/dwc3/core.h b/drivers/usb/dwc3/core.h
index 719601e..fc4169f 100644
--- a/drivers/usb/dwc3/core.h
+++ b/drivers/usb/dwc3/core.h
@@ -32,6 +32,7 @@
 #include <linux/usb/otg.h>
 
 /* Global constants */
+#define DWC3_SCRATCH_BUF_SIZE	4096
 #define DWC3_EP0_BOUNCE_SIZE	512
 #define DWC3_ENDPOINTS_NUM	32
 #define DWC3_XHCI_RESOURCES_NUM	2
@@ -179,6 +180,10 @@
 #define DWC3_GEVNTSIZ_INTMASK		(1 << 31)
 #define DWC3_GEVNTSIZ_SIZE(n)		((n) & 0xffff)
 
+/* Global Event Size Registers */
+#define DWC3_GEVNTSIZ_INTMASK		(1 << 31)
+#define DWC3_GEVNTSIZ_SIZE(n)		((n) & 0xffff)
+
 /* Global HWPARAMS1 Register */
 #define DWC3_GHWPARAMS1_EN_PWROPT(n)	(((n) & (3 << 24)) >> 24)
 #define DWC3_GHWPARAMS1_EN_PWROPT_NO	0
@@ -293,6 +298,7 @@
 #define DWC3_DGCMD_SET_LMP		0x01
 #define DWC3_DGCMD_SET_PERIODIC_PAR	0x02
 #define DWC3_DGCMD_XMIT_FUNCTION	0x03
+#define DWC3_DGCMD_SET_SCRATCH_ADDR_LO	0x04
 
 /* These apply for core versions 1.94a and later */
 #define DWC3_DGCMD_SET_SCRATCHPAD_ADDR_LO	0x04
@@ -391,9 +397,11 @@ struct dwc3_event_buffer {
  * @trb_pool_dma: dma address of @trb_pool
  * @free_slot: next slot which is going to be used
  * @busy_slot: first slot which is owned by HW
+ * @ep_state: endpoint state
  * @desc: usb_endpoint_descriptor pointer
  * @dwc: pointer to DWC controller
  * @flags: endpoint flags (wedged, stalled, ...)
+ * @flags_backup: backup endpoint flags
  * @current_trb: index of current used trb
  * @number: endpoint number (1 - 15)
  * @type: set to bmAttributes & USB_ENDPOINT_XFERTYPE_MASK
@@ -412,16 +420,23 @@ struct dwc3_ep {
 	dma_addr_t		trb_pool_dma;
 	u32			free_slot;
 	u32			busy_slot;
+	u32			ep_state;
 	const struct usb_ss_ep_comp_descriptor *comp_desc;
 	struct dwc3		*dwc;
 
+	struct ebc_io		*ebc;
+#define DWC3_EP_EBC_OUT_NB	16
+#define DWC3_EP_EBC_IN_NB	17
+
 	unsigned		flags;
+	unsigned		flags_backup;
 #define DWC3_EP_ENABLED		(1 << 0)
 #define DWC3_EP_STALL		(1 << 1)
 #define DWC3_EP_WEDGE		(1 << 2)
 #define DWC3_EP_BUSY		(1 << 4)
 #define DWC3_EP_PENDING_REQUEST	(1 << 5)
 #define DWC3_EP_MISSED_ISOC	(1 << 6)
+#define DWC3_EP_HIBERNATION	(1 << 7)
 
 	/* This last one is specific to EP0 */
 #define DWC3_EP0_DIR_IN		(1 << 31)
@@ -478,6 +493,13 @@ enum dwc3_link_state {
 	DWC3_LINK_STATE_MASK		= 0x0f,
 };
 
+enum dwc3_pm_state {
+	PM_DISCONNECTED = 0,
+	PM_ACTIVE,
+	PM_SUSPENDED,
+	PM_RESUMING,
+};
+
 /* TRB Length, PCM and Status */
 #define DWC3_TRB_SIZE_MASK	(0x00ffffff)
 #define DWC3_TRB_SIZE_LENGTH(n)	((n) & DWC3_TRB_SIZE_MASK)
@@ -578,6 +600,7 @@ struct dwc3_request {
 	unsigned		direction:1;
 	unsigned		mapped:1;
 	unsigned		queued:1;
+	unsigned		short_packet:1;
 };
 
 /*
@@ -589,6 +612,22 @@ struct dwc3_scratchpad_array {
 };
 
 /**
+ * struct dwc3_hwregs - registers saved when entering hibernation
+ */
+struct dwc3_hwregs {
+	u32	guctl;
+	u32	dcfg;
+	u32	devten;
+	u32	gctl;
+	u32	gusb3pipectl0;
+	u32	gusb2phycfg0;
+	u32	gevntadrlo;
+	u32	gevntadrhi;
+	u32	gevntsiz;
+	u32	grxthrcfg;
+};
+
+/**
  * struct dwc3 - representation of our controller
  * @ctrl_req: usb control request which is used for ep0
  * @ep0_trb: trb which is used for the ctrl_req
@@ -708,6 +747,7 @@ struct dwc3 {
 	unsigned		needs_fifo_resize:1;
 	unsigned		resize_fifos:1;
 	unsigned		pullups_connected:1;
+	unsigned		quirks_disable_irqthread:1;
 
 	bool			has_gadget;
 	bool			has_xhci;
@@ -731,9 +771,23 @@ struct dwc3 {
 	struct dwc3_hwparams	hwparams;
 	struct dentry		*root;
 	struct debugfs_regset32	*regset;
+	enum dwc3_pm_state	pm_state;
+	u8			is_otg;
+	u8			soft_connected;
 
 	u8			test_mode;
 	u8			test_mode_nr;
+
+	/* delayed work for handling Link State Change */
+	struct delayed_work	link_work;
+
+	u8			is_ebc;
+
+	struct dwc3_scratchpad_array	*scratch_array;
+	dma_addr_t		scratch_array_dma;
+	void			*scratch_buffer[DWC3_MAX_HIBER_SCRATCHBUFS];
+	struct dwc3_hwregs	hwregs;
+	bool			hiber_enabled;
 };
 
 /* -------------------------------------------------------------------------- */
@@ -873,6 +927,23 @@ struct dwc3_gadget_ep_cmd_params {
 	u32	param0;
 };
 
+struct ebc_io {
+	const char	*name;
+	const char	*epname;
+	u8		epnum;
+	u8		is_ondemand;
+	u8		static_trb_pool_size;
+	struct list_head	list;
+	int		(*init) (void);
+	void		*(*alloc_static_trb_pool) (dma_addr_t *dma_addr);
+	void		(*free_static_trb_pool) (void);
+	int		(*xfer_start) (void);
+	int		(*xfer_stop) (void);
+};
+
+void dwc3_register_io_ebc(struct ebc_io *ebc);
+void dwc3_unregister_io_ebc(struct ebc_io *ebc);
+
 /*
  * DWC3 Features to be used as Driver Data
  */
diff --git a/include/linux/irq.h b/include/linux/irq.h
index 7cb37bf..f7a07fb 100644
--- a/include/linux/irq.h
+++ b/include/linux/irq.h
@@ -98,6 +98,7 @@ enum {
 	IRQ_NOTHREAD		= (1 << 16),
 	IRQ_PER_CPU_DEVID	= (1 << 17),
 	IRQ_IS_POLLED		= (1 << 18),
+	IRQ_CHAINED		= (1 << 19),
 };
 
 #define IRQF_MODIFY_MASK	\
diff --git a/include/linux/irqdesc.h b/include/linux/irqdesc.h
index ff24667..ad76fcc 100644
--- a/include/linux/irqdesc.h
+++ b/include/linux/irqdesc.h
@@ -144,6 +144,13 @@ static inline int irq_has_action(unsigned int irq)
 	return desc->action != NULL;
 }
 
+/* Test to see if the IRQ is chained */
+static inline int irq_is_chained(unsigned int irq)
+{
+	struct irq_desc *desc = irq_to_desc(irq);
+	return desc->status_use_accessors & IRQ_CHAINED;
+}
+
 /* caller has locked the irq_desc and both params are valid */
 static inline void __irq_set_handler_locked(unsigned int irq,
 					    irq_flow_handler_t handler)
diff --git a/include/linux/power/battery_id.h b/include/linux/power/battery_id.h
new file mode 100644
index 0000000..417160d
--- /dev/null
+++ b/include/linux/power/battery_id.h
@@ -0,0 +1,78 @@
+#ifndef __BATTERY_ID_H__
+
+#define __BATTERY_ID_H__
+
+enum {
+	POWER_SUPPLY_BATTERY_REMOVED = 0,
+	POWER_SUPPLY_BATTERY_INSERTED,
+};
+
+enum batt_chrg_prof_type {
+	PSE_MOD_CHRG_PROF = 0,
+};
+
+/* charging profile structure definition */
+struct ps_batt_chg_prof {
+	enum batt_chrg_prof_type chrg_prof_type;
+	void *batt_prof;
+};
+
+/* PSE Modified Algo Structure */
+/* Parameters defining the charging range */
+struct ps_temp_chg_table {
+	/* upper temperature limit for each zone */
+	short int temp_up_lim;
+	/* charge current and voltage */
+	short int full_chrg_vol;
+	short int full_chrg_cur;
+	/* maintenance thresholds */
+	/* maintenance lower threshold. Once battery hits full, charging
+	*  charging will be resumed when battery voltage <= this voltage
+	*/
+	short int maint_chrg_vol_ll;
+	/* Charge current and voltage in maintenance mode */
+	short int maint_chrg_vol_ul;
+	short int maint_chrg_cur;
+} __packed;
+
+
+#define BATTID_STR_LEN		8
+#define BATT_TEMP_NR_RNG	6
+/* Charging Profile */
+struct ps_pse_mod_prof {
+	/* battery id */
+	char batt_id[BATTID_STR_LEN];
+	/* type of battery */
+	u16 battery_type;
+	u16 capacity;
+	u16 voltage_max;
+	/* charge termination current */
+	u16 chrg_term_ma;
+	/* Low battery level voltage */
+	u16 low_batt_mV;
+	/* upper and lower temperature limits on discharging */
+	u8 disch_tmp_ul;
+	u8 disch_tmp_ll;
+	/* number of temperature monitoring ranges */
+	u16 temp_mon_ranges;
+	struct ps_temp_chg_table temp_mon_range[BATT_TEMP_NR_RNG];
+	/* Lowest temperature supported */
+	short int temp_low_lim;
+} __packed;
+
+/*For notification during battery change event*/
+extern struct atomic_notifier_head    batt_id_notifier;
+
+extern void battery_prop_changed(int battery_conn_stat,
+				struct ps_batt_chg_prof *batt_prop);
+#ifdef CONFIG_POWER_SUPPLY_BATTID
+extern int get_batt_prop(struct ps_batt_chg_prof *batt_prop);
+#else
+static inline int get_batt_prop(struct ps_batt_chg_prof *batt_prop)
+{
+	return -ENOMEM;
+}
+#endif
+extern int batt_id_reg_notifier(struct notifier_block *nb);
+extern void batt_id_unreg_notifier(struct notifier_block *nb);
+#endif
diff --git a/include/linux/power/bq24261_charger.h b/include/linux/power/bq24261_charger.h
new file mode 100644
index 0000000..f185659
--- /dev/null
+++ b/include/linux/power/bq24261_charger.h
@@ -0,0 +1,56 @@
+/*
+ * bq24261_charger.h: platform data structure for bq24261 driver
+ *
+ * (C) Copyright 2012 Intel Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+#ifndef __BQ24261_CHARGER_H__
+#define __BQ24261_CHARGER_H__
+
+struct bq24261_plat_data {
+	u32 irq_map;
+	u8 irq_mask;
+	char **supplied_to;
+	size_t num_supplicants;
+	struct power_supply_throttle *throttle_states;
+	size_t num_throttle_states;
+	int safety_timer;
+	int boost_mode_ma;
+	bool is_ts_enabled;
+
+	int (*enable_charging) (bool val);
+	int (*enable_charger) (bool val);
+	int (*set_inlmt) (int val);
+	int (*set_cc) (int val);
+	int (*set_cv) (int val);
+	int (*set_iterm) (int val);
+	int (*enable_vbus) (bool val);
+	/* WA for ShadyCove VBUS removal detect issue */
+	int (*handle_low_supply) (void);
+	void (*dump_master_regs) (void);
+};
+
+extern void bq24261_cv_to_reg(int, u8*);
+extern void bq24261_cc_to_reg(int, u8*);
+extern void bq24261_inlmt_to_reg(int, u8*);
+
+#ifdef CONFIG_BQ24261_CHARGER
+extern int bq24261_get_bat_health(void);
+extern int bq24261_get_bat_status(void);
+#else
+static int bq24261_get_bat_health(void)
+{
+	return 0;
+}
+static int bq24261_get_bat_status(void)
+{
+	return 0;
+}
+#endif
+
+#endif
diff --git a/include/linux/regulator/intel_basin_cove_pmic.h b/include/linux/regulator/intel_basin_cove_pmic.h
new file mode 100644
index 0000000..8dcdfa7
--- /dev/null
+++ b/include/linux/regulator/intel_basin_cove_pmic.h
@@ -0,0 +1,59 @@
+/*
+ * intel_basin_cove_pmic.h - Support for Basin Cove pmic VR
+ * Copyright (c) 2012, Intel Corporation.
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ *
+ */
+#ifndef __INTEL_BASIN_COVE_PMIC_H_
+#define __INTEL_BASIN_COVE_PMIC_H_
+
+struct regulator_init_data;
+
+enum intel_regulator_id {
+	VPROG1,
+	VPROG2,
+	VPROG3,
+};
+
+/* Voltage tables for Regulators */
+static const u16 VPROG1_VSEL_table[] = {
+	1500, 1800, 2500, 2800,
+};
+
+static const u16 VPROG2_VSEL_table[] = {
+	1500, 1800, 2500, 2850,
+};
+
+static const u16 VPROG3_VSEL_table[] = {
+	1050, 1800, 2500, 2800,
+};
+
+/* Slave Address for all regulators */
+#define VPROG1CNT_ADDR	0x0ac
+#define VPROG2CNT_ADDR	0x0ad
+#define VPROG3CNT_ADDR	0x0ae
+/**
+ * intel_pmic_info - platform data for intel pmic
+ * @pmic_reg: pmic register that is to be used for this VR
+ */
+struct intel_pmic_info {
+	struct regulator_init_data *init_data;
+	struct regulator_dev *intel_pmic_rdev;
+	const u16 *table;
+	u16 pmic_reg;
+	u8 table_len;
+};
+
+#endif /* __INTEL_BASIN_COVE_PMIC_H_ */
diff --git a/include/linux/sdm.h b/include/linux/sdm.h
new file mode 100644
index 0000000..0a75ffb
--- /dev/null
+++ b/include/linux/sdm.h
@@ -0,0 +1,60 @@
+/*
+ *  Copyright (C) Intel 2011
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ *
+ * The SDM (System Debug Monitor) directs trace data routed from
+ * various parts in the system out through the Intel Tangier PTI port and
+ * out of the mobile device for analysis with a debugging tool
+ * (Lauterbach, Fido). This is part of a solution for the MIPI P1149.7,
+ * compact JTAG, standard and USB Debug-Class
+ *
+ * This header file will allow other parts of the OS to use the
+ * interface to write out it's contents for debugging a mobile system.
+ */
+
+#ifndef SDM_H_
+#define SDM_H_
+
+#ifdef CONFIG_INTEL_PTI_STM
+/* the following functions are defined in drivers/misc/stm.c */
+int stm_kernel_get_out(void);
+int stm_kernel_set_out(int bus_type);
+int stm_is_enabled(void);
+#else
+static inline int stm_kernel_get_out(void) { return -EOPNOTSUPP; };
+static inline int stm_kernel_set_out(int bus_type) { return -EOPNOTSUPP; };
+static inline int stm_is_enabled(void) { return 0; };
+#endif
+
+/* Temporary : To be replace later with dynamic*/
+#define STM_NB_IN_PINS                  0
+
+/* STM output configurations */
+#define STM_PTI_4BIT_LEGACY                    0
+#define STM_PTI_4BIT_NIDNT                     1
+#define STM_PTI_16BIT                          2
+#define STM_PTI_12BIT                          3
+#define STM_PTI_8BIT                           4
+#define STM_USB                                15
+
+/* Buffer configurations */
+#define DFX_BULK_BUFFER_SIZE		64 /* for Tangier A0 */
+#define DFX_BULK_OUT_BUFFER_ADDR	0xF90B0000
+#define DFX_BULK_IN_BUFFER_ADDR		0xF90B0000
+#define DFX_BULK_IN_BUFFER_ADDR_2	0xF90B0400
+
+#define TRACE_BULK_BUFFER_SIZE		65536 /* revision */
+#define TRACE_BULK_IN_BUFFER_ADDR	0xF90A0000 /* revision */
+
+#endif /*SDM_H_*/
+
diff --git a/include/linux/thermal.h b/include/linux/thermal.h
index f7e11c7..6d30ec7 100644
--- a/include/linux/thermal.h
+++ b/include/linux/thermal.h
@@ -111,22 +111,22 @@ struct thermal_zone_device_ops {
 		     struct thermal_cooling_device *);
 	int (*unbind) (struct thermal_zone_device *,
 		       struct thermal_cooling_device *);
-	int (*get_temp) (struct thermal_zone_device *, unsigned long *);
+	int (*get_temp) (struct thermal_zone_device *, long *);
 	int (*get_mode) (struct thermal_zone_device *,
 			 enum thermal_device_mode *);
 	int (*set_mode) (struct thermal_zone_device *,
 		enum thermal_device_mode);
 	int (*get_trip_type) (struct thermal_zone_device *, int,
 		enum thermal_trip_type *);
-	int (*get_trip_temp) (struct thermal_zone_device *, int,
-			      unsigned long *);
-	int (*set_trip_temp) (struct thermal_zone_device *, int,
-			      unsigned long);
-	int (*get_trip_hyst) (struct thermal_zone_device *, int,
-			      unsigned long *);
-	int (*set_trip_hyst) (struct thermal_zone_device *, int,
-			      unsigned long);
-	int (*get_crit_temp) (struct thermal_zone_device *, unsigned long *);
+	int (*get_trip_temp) (struct thermal_zone_device *, int, long *);
+	int (*set_trip_temp) (struct thermal_zone_device *, int, long);
+	int (*get_trip_hyst) (struct thermal_zone_device *, int, long *);
+	int (*set_trip_hyst) (struct thermal_zone_device *, int, long);
+	int (*get_slope) (struct thermal_zone_device *, long *);
+	int (*set_slope) (struct thermal_zone_device *, long);
+	int (*get_intercept) (struct thermal_zone_device *, long *);
+	int (*set_intercept) (struct thermal_zone_device *, long);
+	int (*get_crit_temp) (struct thermal_zone_device *, long *);
 	int (*set_emul_temp) (struct thermal_zone_device *, unsigned long);
 	int (*get_trend) (struct thermal_zone_device *, int,
 			  enum thermal_trend *);
@@ -138,6 +138,12 @@ struct thermal_cooling_device_ops {
 	int (*get_max_state) (struct thermal_cooling_device *, unsigned long *);
 	int (*get_cur_state) (struct thermal_cooling_device *, unsigned long *);
 	int (*set_cur_state) (struct thermal_cooling_device *, unsigned long);
+	int (*get_force_state_override) (struct thermal_cooling_device *,
+								char *);
+	int (*set_force_state_override) (struct thermal_cooling_device *,
+								char *);
+	int (*get_available_states) (struct thermal_cooling_device *,
+								char *);
 };
 
 struct thermal_cooling_device {
diff --git a/include/linux/usb/phy.h b/include/linux/usb/phy.h
index 6c0b1c5..f1a95a1 100644
--- a/include/linux/usb/phy.h
+++ b/include/linux/usb/phy.h
@@ -27,6 +27,7 @@ enum usb_phy_events {
 	USB_EVENT_ID,           /* id was grounded */
 	USB_EVENT_CHARGER,      /* usb dedicated charger */
 	USB_EVENT_ENUMERATED,   /* gadget driver enumerated */
+	USB_EVENT_DRIVE_VBUS,	/* drive vbus request */
 };
 
 /* associate a type with PHY */
@@ -116,6 +117,9 @@ struct usb_phy {
 			enum usb_device_speed speed);
 	int	(*notify_disconnect)(struct usb_phy *x,
 			enum usb_device_speed speed);
+
+	/* check charger status */
+	int	(*get_chrg_status)(struct usb_phy *x, void *data);
 };
 
 /**
@@ -306,4 +310,14 @@ static inline const char *usb_phy_type_string(enum usb_phy_type type)
 		return "UNKNOWN PHY TYPE";
 	}
 }
+
+static inline int
+otg_get_chrg_status(struct usb_phy *x, void *data)
+{
+	if (x && x->get_chrg_status)
+		return x->get_chrg_status(x, data);
+
+	return -ENOTSUPP;
+}
+
 #endif /* __LINUX_USB_PHY_H */
-- 
1.7.5.4

