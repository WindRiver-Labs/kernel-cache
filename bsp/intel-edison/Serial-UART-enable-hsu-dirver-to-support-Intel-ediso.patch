From 3d9d07d0adb2caa74bad386b6767092e2f18111a Mon Sep 17 00:00:00 2001
From: Liwei Song <liwei.song@windriver.com>
Date: Wed, 13 Jan 2016 00:22:50 -0500
Subject: [PATCH 01/11] Serial/UART: enable hsu dirver to support Intel edison
 UART

This patch is from yocto Intel Edison support:
http://downloadmirror.intel.com/25028/eng/edison-src-ww25.5-15.tgz

The patch is use to enable Intel Edison UART, with this
dirver Intel Edison will give out four ports: ttyMFD[0-3]

Signed-off-by: Liwei Song <liwei.song@windriver.com>
---
 arch/x86/include/asm/intel_mid_hsu.h               |   69 +
 arch/x86/platform/intel-mid/device_libs/Makefile   |    2 +
 .../platform/intel-mid/device_libs/platform_hsu.c  |  452 ++++
 .../platform/intel-mid/device_libs/platform_hsu.h  |   56 +
 drivers/tty/serial/Kconfig                         |   12 +-
 drivers/tty/serial/Makefile                        |    2 +-
 drivers/tty/serial/mfd.c                           | 1508 ------------
 drivers/tty/serial/mfd.h                           |  252 ++
 drivers/tty/serial/mfd_core.c                      | 2479 ++++++++++++++++++++
 drivers/tty/serial/mfd_dma.c                       |  753 ++++++
 drivers/tty/serial/mfd_pci.c                       |  297 +++
 drivers/tty/serial/mfd_plat.c                      |  244 ++
 drivers/tty/serial/mfd_trace.h                     |  197 ++
 drivers/tty/serial/serial_core.c                   |    3 +
 include/linux/intel_mid_pm.h                       |  234 ++
 include/linux/lnw_gpio.h                           |   14 +
 include/linux/serial_core.h                        |    1 +
 include/linux/serial_max3110.h                     |   16 +
 include/linux/serial_mfd.h                         |    7 +-
 19 files changed, 5080 insertions(+), 1518 deletions(-)
 create mode 100644 arch/x86/include/asm/intel_mid_hsu.h
 create mode 100644 arch/x86/platform/intel-mid/device_libs/platform_hsu.c
 create mode 100644 arch/x86/platform/intel-mid/device_libs/platform_hsu.h
 delete mode 100644 drivers/tty/serial/mfd.c
 create mode 100644 drivers/tty/serial/mfd.h
 create mode 100644 drivers/tty/serial/mfd_core.c
 create mode 100644 drivers/tty/serial/mfd_dma.c
 create mode 100644 drivers/tty/serial/mfd_pci.c
 create mode 100644 drivers/tty/serial/mfd_plat.c
 create mode 100644 drivers/tty/serial/mfd_trace.h
 create mode 100644 include/linux/intel_mid_pm.h
 create mode 100644 include/linux/lnw_gpio.h
 create mode 100644 include/linux/serial_max3110.h

diff --git a/arch/x86/include/asm/intel_mid_hsu.h b/arch/x86/include/asm/intel_mid_hsu.h
new file mode 100644
index 0000000..36b91fc
--- /dev/null
+++ b/arch/x86/include/asm/intel_mid_hsu.h
@@ -0,0 +1,69 @@
+#ifndef __INTEL_MID_HSU_H__
+#define __INTEL_MID_HSU_H__
+
+#define hsu_port_func_max 4
+
+enum {
+	hsu_port0,
+	hsu_port1,
+	hsu_port2,
+	hsu_port_share,
+	hsu_port_max,
+	hsu_dma,
+};
+
+enum {
+	bt_port,
+	modem_port,
+	gps_port,
+	debug_port,
+};
+
+enum {
+	hsu_intel,
+	hsu_dw,
+};
+
+struct hsu_port_cfg {
+	int type;
+	int hw_ip;
+	int index;
+	char *name;
+	int idle;
+	int has_alt;
+	int alt;
+	int force_suspend;
+	int preamble;
+	int hw_context_save;
+	int hw_ctrl_cts;
+	struct device *dev;
+	int (*hw_init)(struct device *dev, int port);
+	void(*hw_set_alt)(int port);
+	void(*hw_set_rts)(int port, int value);
+	void(*hw_suspend)(int port, struct device *dev, irq_handler_t wake_isr);
+	void(*hw_suspend_post)(int port);
+	void(*hw_resume)(int port, struct device *dev);
+	unsigned int (*hw_get_clk)(void);
+	void (*wake_peer)(struct device *tty);
+	void (*set_clk)(unsigned int m, unsigned int n,
+			void __iomem *addr);
+	void (*hw_reset)(void __iomem *addr);
+};
+
+
+void intel_mid_hsu_suspend(int port, struct device *dev,
+				irq_handler_t wake_isr);
+void intel_mid_hsu_resume(int port, struct device *dev);
+void intel_mid_hsu_rts(int port, int value);
+void intel_mid_hsu_switch(int port);
+int intel_mid_hsu_init(struct device *dev, int port);
+int intel_mid_hsu_func_to_port(unsigned int func);
+unsigned int intel_mid_hsu_get_clk(void);
+int hsu_register_board_info(void *inf);
+void intel_mid_hsu_suspend_post(int port);
+struct device *intel_mid_hsu_set_wake_peer(int port,
+			void (*wake_peer)(struct device *));
+void intel_mid_hsu_reset(void __iomem *addr);
+void intel_mid_hsu_set_clk(unsigned int m, unsigned int n,
+			void __iomem *addr);
+#endif
diff --git a/arch/x86/platform/intel-mid/device_libs/Makefile b/arch/x86/platform/intel-mid/device_libs/Makefile
index 097e7a7..6dc3b04 100644
--- a/arch/x86/platform/intel-mid/device_libs/Makefile
+++ b/arch/x86/platform/intel-mid/device_libs/Makefile
@@ -20,3 +20,5 @@ obj-$(subst m,y,$(CONFIG_DRM_MEDFIELD)) += platform_tc35876x.o
 obj-$(subst m,y,$(CONFIG_SERIAL_MRST_MAX3110)) += platform_max3111.o
 # MISC Devices
 obj-$(subst m,y,$(CONFIG_KEYBOARD_GPIO)) += platform_gpio_keys.o
+# UART Devices
+obj-$(subst m,y,$(CONFIG_SERIAL_MFD_HSU)) += platform_hsu.o
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_hsu.c b/arch/x86/platform/intel-mid/device_libs/platform_hsu.c
new file mode 100644
index 0000000..f4f6eae
--- /dev/null
+++ b/arch/x86/platform/intel-mid/device_libs/platform_hsu.c
@@ -0,0 +1,452 @@
+/*
+ * platform_hsu.c: hsu platform data initilization file
+ *
+ * (C) Copyright 2008 Intel Corporation
+ * Author:
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/pm_runtime.h>
+#include <linux/lnw_gpio.h>
+#include <linux/gpio.h>
+#include <asm/setup.h>
+#include <asm/intel-mid.h>
+#include <asm/intel_mid_hsu.h>
+
+#include "platform_hsu.h"
+
+#define TNG_CLOCK_CTL 0xFF00B830
+#define TNG_CLOCK_SC  0xFF00B868
+
+#define VLV_HSU_CLOCK	0x0800
+#define VLV_HSU_RESET	0x0804
+
+static unsigned int clock;
+static struct hsu_port_pin_cfg *hsu_port_gpio_mux;
+static struct hsu_port_cfg *platform_hsu_info;
+
+static struct
+hsu_port_pin_cfg hsu_port_pin_cfgs[][hsu_pid_max][hsu_port_max] = {
+	[hsu_tng] = {
+		[hsu_pid_def] = {
+			[hsu_port0] = {
+				.id = 0,
+				.name = HSU_BT_PORT,
+				.rx_gpio = 126,
+				.rx_alt = 1,
+				.tx_gpio = 127,
+				.tx_alt = 1,
+				.cts_gpio = 124,
+				.cts_alt = 1,
+				.rts_gpio = 125,
+				.rts_alt = 1,
+			},
+			[hsu_port1] = {
+				.id = 1,
+				.name = HSU_UART1_PORT,
+				.wake_gpio = 130,
+				.rx_gpio = 130,
+				.rx_alt = 1,
+				.tx_gpio = 131,
+				.tx_alt = 1,
+				.cts_gpio = 128,
+				.cts_alt = 1,
+				.rts_gpio = 129,
+				.rts_alt = 1,
+			},
+			[hsu_port2] = {
+				.id = 2,
+				.name = HSU_UART2_PORT,
+				.wake_gpio = 134,
+				.rx_gpio = 134,
+				.rx_alt = 1,
+				.cts_gpio = 132,
+				.cts_alt = 1,
+				.rts_gpio = 133,
+				.rts_alt = 1,
+			},
+		},
+	},
+
+};
+
+static struct hsu_port_cfg hsu_port_cfgs[][hsu_port_max] = {
+	[hsu_tng] = {
+		[hsu_port0] = {
+			.type = bt_port,
+			.hw_ip = hsu_intel,
+			.index = 0,
+			.name = HSU_BT_PORT,
+			.idle = 20,
+			.hw_init = intel_mid_hsu_init,
+			/*.hw_set_alt = intel_mid_hsu_switch,*/
+			/*.hw_set_rts = intel_mid_hsu_rts,*/
+			/*.hw_suspend = intel_mid_hsu_suspend,*/
+			/*.hw_resume = intel_mid_hsu_resume,*/
+			.hw_get_clk = intel_mid_hsu_get_clk,
+			.hw_context_save = 1,
+		},
+		[hsu_port1] = {
+			.type = gps_port,
+			.hw_ip = hsu_intel,
+			.index = 1,
+			.name = HSU_UART1_PORT,
+			.idle = 30,
+			.preamble = 1,
+			.hw_init = intel_mid_hsu_init,
+			/*.hw_set_alt = intel_mid_hsu_switch,*/
+			/*.hw_set_rts = intel_mid_hsu_rts,*/
+			/*.hw_suspend = intel_mid_hsu_suspend,*/
+			/*.hw_suspend_post = intel_mid_hsu_suspend_post,*/
+			/*.hw_resume = intel_mid_hsu_resume,*/
+			.hw_get_clk = intel_mid_hsu_get_clk,
+			.hw_context_save = 1,
+		},
+		[hsu_port2] = {
+			.type = debug_port,
+			.hw_ip = hsu_intel,
+			.index = 2,
+			.name = HSU_UART2_PORT,
+			.idle = 5000,
+			.hw_init = intel_mid_hsu_init,
+			/*.hw_set_alt = intel_mid_hsu_switch,*/
+			/*.hw_suspend = intel_mid_hsu_suspend,*/
+			/*.hw_resume = intel_mid_hsu_resume,*/
+			.hw_get_clk = intel_mid_hsu_get_clk,
+			.hw_context_save = 1,
+		},
+	},
+};
+
+static struct hsu_func2port hsu_port_func_id_tlb[][hsu_port_func_max] = {
+	[hsu_tng] = {
+		[0] = {
+			.func = 0,
+			.port = -1,
+		},
+		[1] = {
+			.func = 1,
+			.port = hsu_port0,
+		},
+		[2] = {
+			.func = 2,
+			.port = hsu_port1,
+		},
+		[3] = {
+			.func = 3,
+			.port = hsu_port2,
+		},
+	},
+};
+
+static void hsu_port_enable(int port)
+{
+#if 0
+	struct hsu_port_pin_cfg *info = hsu_port_gpio_mux + port;
+
+	if (info->rx_gpio) {
+		lnw_gpio_set_alt(info->rx_gpio, info->rx_alt);
+		gpio_direction_input(info->rx_gpio);
+	}
+	if (info->tx_gpio) {
+		gpio_direction_output(info->tx_gpio, 1);
+		lnw_gpio_set_alt(info->tx_gpio, info->tx_alt);
+		usleep_range(10, 10);
+		gpio_direction_output(info->tx_gpio, 0);
+
+	}
+	if (info->cts_gpio) {
+		lnw_gpio_set_alt(info->cts_gpio, info->cts_alt);
+		gpio_direction_input(info->cts_gpio);
+	}
+	if (info->rts_gpio) {
+		gpio_direction_output(info->rts_gpio, 0);
+		lnw_gpio_set_alt(info->rts_gpio, info->rts_alt);
+	}
+#endif
+}
+
+static void hsu_port_disable(int port)
+{
+#if 0
+	struct hsu_port_pin_cfg *info = hsu_port_gpio_mux + port;
+
+	if (info->rx_gpio) {
+		lnw_gpio_set_alt(info->rx_gpio, LNW_GPIO);
+		gpio_direction_input(info->rx_gpio);
+	}
+	if (info->tx_gpio) {
+		gpio_direction_output(info->tx_gpio, 1);
+		lnw_gpio_set_alt(info->tx_gpio, LNW_GPIO);
+		usleep_range(10, 10);
+		gpio_direction_input(info->tx_gpio);
+	}
+	if (info->cts_gpio) {
+		lnw_gpio_set_alt(info->cts_gpio, LNW_GPIO);
+		gpio_direction_input(info->cts_gpio);
+	}
+	if (info->rts_gpio) {
+		lnw_gpio_set_alt(info->rts_gpio, LNW_GPIO);
+		gpio_direction_input(info->rts_gpio);
+	}
+#endif
+}
+
+void intel_mid_hsu_suspend(int port, struct device *dev,
+							irq_handler_t wake_isr)
+{
+#if 0
+	int ret;
+	struct hsu_port_pin_cfg *info = hsu_port_gpio_mux + port;
+
+	info->dev = dev;
+	info->wake_isr = wake_isr;
+
+	if (info->wake_gpio) {
+		lnw_gpio_set_alt(info->wake_gpio, LNW_GPIO);
+		gpio_direction_input(info->wake_gpio);
+		udelay(10);
+		ret = request_irq(gpio_to_irq(info->wake_gpio), info->wake_isr,
+				IRQ_TYPE_EDGE_FALLING | IRQ_TYPE_EDGE_RISING,
+				info->name, info->dev);
+		if (ret)
+			dev_err(info->dev, "failed to register wakeup irq\n");
+	}
+#endif
+}
+
+void intel_mid_hsu_resume(int port, struct device *dev)
+{
+#if 0
+	struct hsu_port_pin_cfg *info = hsu_port_gpio_mux + port;
+
+	if (info->wake_gpio)
+		free_irq(gpio_to_irq(info->wake_gpio), info->dev);
+
+	if (info->rx_gpio) {
+		lnw_gpio_set_alt(info->rx_gpio, info->rx_alt);
+		gpio_direction_input(info->rx_gpio);
+	}
+	if (info->tx_gpio) {
+		gpio_direction_output(info->tx_gpio, 1);
+		lnw_gpio_set_alt(info->tx_gpio, info->tx_alt);
+		usleep_range(10, 10);
+		gpio_direction_output(info->tx_gpio, 0);
+
+	}
+	if (info->cts_gpio) {
+		lnw_gpio_set_alt(info->cts_gpio, info->cts_alt);
+		gpio_direction_input(info->cts_gpio);
+	}
+#endif
+}
+
+void intel_mid_hsu_switch(int port)
+{
+	int i;
+	struct hsu_port_pin_cfg *tmp;
+	struct hsu_port_pin_cfg *info = hsu_port_gpio_mux + port;
+
+	for (i = 0; i < hsu_port_max; i++) {
+		tmp = hsu_port_gpio_mux + i;
+		if (tmp != info && tmp->id == info->id)
+			hsu_port_disable(i);
+	}
+	hsu_port_enable(port);
+}
+
+void intel_mid_hsu_rts(int port, int value)
+{
+#if 0
+	struct hsu_port_pin_cfg *info = hsu_port_gpio_mux + port;
+
+	if (!info->rts_gpio)
+		return;
+
+	if (value) {
+		gpio_direction_output(info->rts_gpio, 1);
+		lnw_gpio_set_alt(info->rts_gpio, LNW_GPIO);
+	} else
+		lnw_gpio_set_alt(info->rts_gpio, info->rts_alt);
+#endif
+}
+
+void intel_mid_hsu_suspend_post(int port)
+{
+#if 0
+	struct hsu_port_pin_cfg *info = hsu_port_gpio_mux + port;
+
+	if (info->rts_gpio && info->wake_gpio
+		&& info->wake_gpio == info->rx_gpio) {
+		gpio_direction_output(info->rts_gpio, 0);
+		lnw_gpio_set_alt(info->rts_gpio, LNW_GPIO);
+	}
+#endif
+}
+
+void intel_mid_hsu_set_clk(unsigned int m, unsigned int n,
+				void __iomem *addr)
+{
+	unsigned int param, update_bit;
+
+	update_bit = 1 << 31;
+	param = (m << 1) | (n << 16) | 0x1;
+
+	writel(param, addr + VLV_HSU_CLOCK);
+	writel((param | update_bit), addr + VLV_HSU_CLOCK);
+	writel(param, addr + VLV_HSU_CLOCK);
+}
+
+void intel_mid_hsu_reset(void __iomem *addr)
+{
+	writel(0, addr + VLV_HSU_RESET);
+	writel(3, addr + VLV_HSU_RESET);
+}
+
+unsigned int intel_mid_hsu_get_clk(void)
+{
+	return clock;
+}
+
+int intel_mid_hsu_func_to_port(unsigned int func)
+{
+	int i;
+	struct hsu_func2port *tbl = NULL;
+
+	switch (intel_mid_identify_cpu()) {
+	case INTEL_MID_CPU_CHIP_TANGIER:
+		tbl = &hsu_port_func_id_tlb[hsu_tng][0];
+		break;
+	default:
+		/* FIXME: VALLEYVIEW2? */
+		/* 1e.3 and 1e.4 */
+		tbl = &hsu_port_func_id_tlb[hsu_vlv2][0];
+		break;
+	}
+
+	for (i = 0; i < hsu_port_func_max; i++) {
+		if (tbl->func == func)
+			return tbl->port;
+		tbl++;
+	}
+
+	return -1;
+}
+
+int intel_mid_hsu_init(struct device *dev, int port)
+{
+	struct hsu_port_cfg *port_cfg = platform_hsu_info + port;
+	struct hsu_port_pin_cfg *info;
+
+	if (port >= hsu_port_max)
+		return -ENODEV;
+
+	port_cfg->dev = dev;
+
+	info = hsu_port_gpio_mux + port;
+	if (info->wake_gpio) {
+		gpio_request(info->wake_gpio, "hsu");
+    }
+	if (info->rx_gpio) {
+		gpio_request(info->rx_gpio, "hsu");
+		gpio_export(info->rx_gpio, 1);
+    }
+	if (info->tx_gpio) {
+		gpio_request(info->tx_gpio, "hsu");
+		gpio_export(info->tx_gpio, 1);
+    }
+	if (info->cts_gpio) {
+		gpio_request(info->cts_gpio, "hsu");
+		gpio_export(info->cts_gpio, 1);
+    }
+	if (info->rts_gpio) {
+		gpio_request(info->rts_gpio, "hsu");
+		gpio_export(info->rts_gpio, 1);
+    }
+
+	return 1;
+}
+
+static void hsu_platform_clk(enum intel_mid_cpu_type cpu_type)
+{
+	void __iomem *clkctl, *clksc;
+	u32 clk_src, clk_div;
+
+	switch (cpu_type) {
+	case INTEL_MID_CPU_CHIP_TANGIER:
+		clock = 100000;
+		clkctl = ioremap_nocache(TNG_CLOCK_CTL, 4);
+		if (!clkctl) {
+			pr_err("tng scu clk ctl ioremap error\n");
+			break;
+		}
+
+		clksc = ioremap_nocache(TNG_CLOCK_SC, 4);
+		if (!clksc) {
+			pr_err("tng scu clk sc ioremap error\n");
+			iounmap(clkctl);
+			break;
+		}
+
+		clk_src = readl(clkctl);
+		clk_div = readl(clksc);
+
+		if (clk_src & (1 << 16))
+			/* source SCU fabric 100M */
+			clock = clock / ((clk_div & 0x7) + 1);
+		else {
+			if (clk_src & (1 << 31))
+				/* source OSCX2 38.4M */
+				clock = 38400;
+			else
+				/* source OSC clock 19.2M */
+				clock = 19200;
+		}
+
+		iounmap(clkctl);
+		iounmap(clksc);
+		break;
+
+	default:
+		/* FIXME: VALLEYVIEW2? */
+		clock = 100000;
+		break;
+	}
+
+	pr_info("hsu core clock %u M\n", clock / 1000);
+}
+
+static __init int hsu_dev_platform_data(void)
+{
+	switch (intel_mid_identify_cpu()) {
+	case INTEL_MID_CPU_CHIP_TANGIER:
+		platform_hsu_info = &hsu_port_cfgs[hsu_tng][0];
+		hsu_port_gpio_mux = &hsu_port_pin_cfgs[hsu_tng][hsu_pid_def][0];
+		break;
+	default:
+		platform_hsu_info = NULL;
+		hsu_port_gpio_mux = NULL;
+		break;
+	}
+
+	if (platform_hsu_info == NULL)
+		return -ENODEV;
+
+	if (hsu_port_gpio_mux == NULL)
+		return -ENODEV;
+
+	hsu_register_board_info(platform_hsu_info);
+	hsu_platform_clk(intel_mid_identify_cpu());
+
+	return 0;
+}
+
+fs_initcall(hsu_dev_platform_data);
diff --git a/arch/x86/platform/intel-mid/device_libs/platform_hsu.h b/arch/x86/platform/intel-mid/device_libs/platform_hsu.h
new file mode 100644
index 0000000..7bc6eaf
--- /dev/null
+++ b/arch/x86/platform/intel-mid/device_libs/platform_hsu.h
@@ -0,0 +1,56 @@
+/*
+ * platform_hsu.h: hsu platform data header file
+ *
+ * (C) Copyright 2008 Intel Corporation
+ * Author:
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+#ifndef _PLATFORM_HSU_H_
+#define _PLATFORM_HSU_H_
+
+#define HSU_BT_PORT "hsu_bt_port"
+#define HSU_UART0_PORT "hsu_uart0_port"
+#define HSU_UART1_PORT "hsu_uart1_port"
+#define HSU_UART2_PORT "hsu_uart2_port"
+
+enum hsu_core {
+	hsu_pnw,
+	hsu_clv,
+	hsu_tng,
+	hsu_vlv2,
+};
+
+enum hsu_pid {
+	hsu_pid_def = 0,
+	hsu_pid_rhb = 0,
+	hsu_pid_vtb_pro = 1,
+	hsu_pid_vtb_eng = 2,
+	hsu_pid_max,
+};
+
+struct hsu_func2port {
+	int func;
+	int port;
+};
+
+struct hsu_port_pin_cfg {
+	char *name;
+	int id;
+	int wake_gpio;
+	int rx_gpio;
+	int rx_alt;
+	int tx_gpio;
+	int tx_alt;
+	int cts_gpio;
+	int cts_alt;
+	int rts_gpio;
+	int rts_alt;
+	struct device *dev;
+	irq_handler_t wake_isr;
+};
+
+#endif
diff --git a/drivers/tty/serial/Kconfig b/drivers/tty/serial/Kconfig
index a3815ea..41334b5 100644
--- a/drivers/tty/serial/Kconfig
+++ b/drivers/tty/serial/Kconfig
@@ -454,14 +454,14 @@ config SERIAL_MRST_MAX3110
 	  driver.
 
 config SERIAL_MFD_HSU
-	tristate "Medfield High Speed UART support"
-	depends on PCI
-	select SERIAL_CORE
+        tristate "Medfield High Speed UART support"
+        depends on PCI
+        select SERIAL_CORE
 
 config SERIAL_MFD_HSU_CONSOLE
-	boolean "Medfile HSU serial console support"
-	depends on SERIAL_MFD_HSU=y
-	select SERIAL_CORE_CONSOLE
+        boolean "Medfield HSU serial console support"
+        depends on SERIAL_MFD_HSU=y
+        select SERIAL_CORE_CONSOLE
 
 config SERIAL_BFIN
 	tristate "Blackfin serial port support"
diff --git a/drivers/tty/serial/Makefile b/drivers/tty/serial/Makefile
index 3680854..1f0dc89 100644
--- a/drivers/tty/serial/Makefile
+++ b/drivers/tty/serial/Makefile
@@ -73,7 +73,7 @@ obj-$(CONFIG_SERIAL_GRLIB_GAISLER_APBUART) += apbuart.o
 obj-$(CONFIG_SERIAL_ALTERA_JTAGUART) += altera_jtaguart.o
 obj-$(CONFIG_SERIAL_VT8500) += vt8500_serial.o
 obj-$(CONFIG_SERIAL_MRST_MAX3110)	+= mrst_max3110.o
-obj-$(CONFIG_SERIAL_MFD_HSU)	+= mfd.o
+obj-$(CONFIG_SERIAL_MFD_HSU)	+= mfd_core.o mfd_dma.o mfd_pci.o mfd_plat.o
 obj-$(CONFIG_SERIAL_IFX6X60)  	+= ifx6x60.o
 obj-$(CONFIG_SERIAL_PCH_UART)	+= pch_uart.o
 obj-$(CONFIG_SERIAL_MSM_SMD)	+= msm_smd_tty.o
diff --git a/drivers/tty/serial/mfd.c b/drivers/tty/serial/mfd.c
deleted file mode 100644
index 445799d..0000000
--- a/drivers/tty/serial/mfd.c
+++ /dev/null
@@ -1,1508 +0,0 @@
-/*
- * mfd.c: driver for High Speed UART device of Intel Medfield platform
- *
- * Refer pxa.c, 8250.c and some other drivers in drivers/serial/
- *
- * (C) Copyright 2010 Intel Corporation
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License
- * as published by the Free Software Foundation; version 2
- * of the License.
- */
-
-/* Notes:
- * 1. DMA channel allocation: 0/1 channel are assigned to port 0,
- *    2/3 chan to port 1, 4/5 chan to port 3. Even number chans
- *    are used for RX, odd chans for TX
- *
- * 2. The RI/DSR/DCD/DTR are not pinned out, DCD & DSR are always
- *    asserted, only when the HW is reset the DDCD and DDSR will
- *    be triggered
- */
-
-#if defined(CONFIG_SERIAL_MFD_HSU_CONSOLE) && defined(CONFIG_MAGIC_SYSRQ)
-#define SUPPORT_SYSRQ
-#endif
-
-#include <linux/module.h>
-#include <linux/init.h>
-#include <linux/console.h>
-#include <linux/sysrq.h>
-#include <linux/slab.h>
-#include <linux/serial_reg.h>
-#include <linux/circ_buf.h>
-#include <linux/delay.h>
-#include <linux/interrupt.h>
-#include <linux/tty.h>
-#include <linux/tty_flip.h>
-#include <linux/serial_core.h>
-#include <linux/serial_mfd.h>
-#include <linux/dma-mapping.h>
-#include <linux/pci.h>
-#include <linux/nmi.h>
-#include <linux/io.h>
-#include <linux/debugfs.h>
-#include <linux/pm_runtime.h>
-
-#define HSU_DMA_BUF_SIZE	2048
-
-#define chan_readl(chan, offset)	readl(chan->reg + offset)
-#define chan_writel(chan, offset, val)	writel(val, chan->reg + offset)
-
-#define mfd_readl(obj, offset)		readl(obj->reg + offset)
-#define mfd_writel(obj, offset, val)	writel(val, obj->reg + offset)
-
-static int hsu_dma_enable;
-module_param(hsu_dma_enable, int, 0);
-MODULE_PARM_DESC(hsu_dma_enable,
-		 "It is a bitmap to set working mode, if bit[x] is 1, then port[x] will work in DMA mode, otherwise in PIO mode.");
-
-struct hsu_dma_buffer {
-	u8		*buf;
-	dma_addr_t	dma_addr;
-	u32		dma_size;
-	u32		ofs;
-};
-
-struct hsu_dma_chan {
-	u32	id;
-	enum dma_data_direction	dirt;
-	struct uart_hsu_port	*uport;
-	void __iomem		*reg;
-};
-
-struct uart_hsu_port {
-	struct uart_port        port;
-	unsigned char           ier;
-	unsigned char           lcr;
-	unsigned char           mcr;
-	unsigned int            lsr_break_flag;
-	char			name[12];
-	int			index;
-	struct device		*dev;
-
-	struct hsu_dma_chan	*txc;
-	struct hsu_dma_chan	*rxc;
-	struct hsu_dma_buffer	txbuf;
-	struct hsu_dma_buffer	rxbuf;
-	int			use_dma;	/* flag for DMA/PIO */
-	int			running;
-	int			dma_tx_on;
-};
-
-/* Top level data structure of HSU */
-struct hsu_port {
-	void __iomem	*reg;
-	unsigned long	paddr;
-	unsigned long	iolen;
-	u32		irq;
-
-	struct uart_hsu_port	port[3];
-	struct hsu_dma_chan	chans[10];
-
-	struct dentry *debugfs;
-};
-
-static inline unsigned int serial_in(struct uart_hsu_port *up, int offset)
-{
-	unsigned int val;
-
-	if (offset > UART_MSR) {
-		offset <<= 2;
-		val = readl(up->port.membase + offset);
-	} else
-		val = (unsigned int)readb(up->port.membase + offset);
-
-	return val;
-}
-
-static inline void serial_out(struct uart_hsu_port *up, int offset, int value)
-{
-	if (offset > UART_MSR) {
-		offset <<= 2;
-		writel(value, up->port.membase + offset);
-	} else {
-		unsigned char val = value & 0xff;
-		writeb(val, up->port.membase + offset);
-	}
-}
-
-#ifdef CONFIG_DEBUG_FS
-
-#define HSU_REGS_BUFSIZE	1024
-
-
-static ssize_t port_show_regs(struct file *file, char __user *user_buf,
-				size_t count, loff_t *ppos)
-{
-	struct uart_hsu_port *up = file->private_data;
-	char *buf;
-	u32 len = 0;
-	ssize_t ret;
-
-	buf = kzalloc(HSU_REGS_BUFSIZE, GFP_KERNEL);
-	if (!buf)
-		return 0;
-
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"MFD HSU port[%d] regs:\n", up->index);
-
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"=================================\n");
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"IER: \t\t0x%08x\n", serial_in(up, UART_IER));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"IIR: \t\t0x%08x\n", serial_in(up, UART_IIR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"LCR: \t\t0x%08x\n", serial_in(up, UART_LCR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"MCR: \t\t0x%08x\n", serial_in(up, UART_MCR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"LSR: \t\t0x%08x\n", serial_in(up, UART_LSR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"MSR: \t\t0x%08x\n", serial_in(up, UART_MSR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"FOR: \t\t0x%08x\n", serial_in(up, UART_FOR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"PS: \t\t0x%08x\n", serial_in(up, UART_PS));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"MUL: \t\t0x%08x\n", serial_in(up, UART_MUL));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"DIV: \t\t0x%08x\n", serial_in(up, UART_DIV));
-
-	if (len > HSU_REGS_BUFSIZE)
-		len = HSU_REGS_BUFSIZE;
-
-	ret =  simple_read_from_buffer(user_buf, count, ppos, buf, len);
-	kfree(buf);
-	return ret;
-}
-
-static ssize_t dma_show_regs(struct file *file, char __user *user_buf,
-				size_t count, loff_t *ppos)
-{
-	struct hsu_dma_chan *chan = file->private_data;
-	char *buf;
-	u32 len = 0;
-	ssize_t ret;
-
-	buf = kzalloc(HSU_REGS_BUFSIZE, GFP_KERNEL);
-	if (!buf)
-		return 0;
-
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"MFD HSU DMA channel [%d] regs:\n", chan->id);
-
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"=================================\n");
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"CR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_CR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"DCR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_DCR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"BSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_BSR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"MOTSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_MOTSR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"D0SAR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D0SAR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"D0TSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D0TSR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"D0SAR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D1SAR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"D0TSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D1TSR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"D0SAR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D2SAR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"D0TSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D2TSR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"D0SAR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D3SAR));
-	len += snprintf(buf + len, HSU_REGS_BUFSIZE - len,
-			"D0TSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D3TSR));
-
-	if (len > HSU_REGS_BUFSIZE)
-		len = HSU_REGS_BUFSIZE;
-
-	ret =  simple_read_from_buffer(user_buf, count, ppos, buf, len);
-	kfree(buf);
-	return ret;
-}
-
-static const struct file_operations port_regs_ops = {
-	.owner		= THIS_MODULE,
-	.open		= simple_open,
-	.read		= port_show_regs,
-	.llseek		= default_llseek,
-};
-
-static const struct file_operations dma_regs_ops = {
-	.owner		= THIS_MODULE,
-	.open		= simple_open,
-	.read		= dma_show_regs,
-	.llseek		= default_llseek,
-};
-
-static int hsu_debugfs_init(struct hsu_port *hsu)
-{
-	int i;
-	char name[32];
-
-	hsu->debugfs = debugfs_create_dir("hsu", NULL);
-	if (!hsu->debugfs)
-		return -ENOMEM;
-
-	for (i = 0; i < 3; i++) {
-		snprintf(name, sizeof(name), "port_%d_regs", i);
-		debugfs_create_file(name, S_IFREG | S_IRUGO,
-			hsu->debugfs, (void *)(&hsu->port[i]), &port_regs_ops);
-	}
-
-	for (i = 0; i < 6; i++) {
-		snprintf(name, sizeof(name), "dma_chan_%d_regs", i);
-		debugfs_create_file(name, S_IFREG | S_IRUGO,
-			hsu->debugfs, (void *)&hsu->chans[i], &dma_regs_ops);
-	}
-
-	return 0;
-}
-
-static void hsu_debugfs_remove(struct hsu_port *hsu)
-{
-	if (hsu->debugfs)
-		debugfs_remove_recursive(hsu->debugfs);
-}
-
-#else
-static inline int hsu_debugfs_init(struct hsu_port *hsu)
-{
-	return 0;
-}
-
-static inline void hsu_debugfs_remove(struct hsu_port *hsu)
-{
-}
-#endif /* CONFIG_DEBUG_FS */
-
-static void serial_hsu_enable_ms(struct uart_port *port)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-
-	up->ier |= UART_IER_MSI;
-	serial_out(up, UART_IER, up->ier);
-}
-
-static void hsu_dma_tx(struct uart_hsu_port *up)
-{
-	struct circ_buf *xmit = &up->port.state->xmit;
-	struct hsu_dma_buffer *dbuf = &up->txbuf;
-	int count;
-
-	/* test_and_set_bit may be better, but anyway it's in lock protected mode */
-	if (up->dma_tx_on)
-		return;
-
-	/* Update the circ buf info */
-	xmit->tail += dbuf->ofs;
-	xmit->tail &= UART_XMIT_SIZE - 1;
-
-	up->port.icount.tx += dbuf->ofs;
-	dbuf->ofs = 0;
-
-	/* Disable the channel */
-	chan_writel(up->txc, HSU_CH_CR, 0x0);
-
-	if (!uart_circ_empty(xmit) && !uart_tx_stopped(&up->port)) {
-		dma_sync_single_for_device(up->port.dev,
-					   dbuf->dma_addr,
-					   dbuf->dma_size,
-					   DMA_TO_DEVICE);
-
-		count = CIRC_CNT_TO_END(xmit->head, xmit->tail, UART_XMIT_SIZE);
-		dbuf->ofs = count;
-
-		/* Reprogram the channel */
-		chan_writel(up->txc, HSU_CH_D0SAR, dbuf->dma_addr + xmit->tail);
-		chan_writel(up->txc, HSU_CH_D0TSR, count);
-
-		/* Reenable the channel */
-		chan_writel(up->txc, HSU_CH_DCR, 0x1
-						 | (0x1 << 8)
-						 | (0x1 << 16)
-						 | (0x1 << 24));
-		up->dma_tx_on = 1;
-		chan_writel(up->txc, HSU_CH_CR, 0x1);
-	}
-
-	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
-		uart_write_wakeup(&up->port);
-}
-
-/* The buffer is already cache coherent */
-static void hsu_dma_start_rx_chan(struct hsu_dma_chan *rxc,
-					struct hsu_dma_buffer *dbuf)
-{
-	dbuf->ofs = 0;
-
-	chan_writel(rxc, HSU_CH_BSR, 32);
-	chan_writel(rxc, HSU_CH_MOTSR, 4);
-
-	chan_writel(rxc, HSU_CH_D0SAR, dbuf->dma_addr);
-	chan_writel(rxc, HSU_CH_D0TSR, dbuf->dma_size);
-	chan_writel(rxc, HSU_CH_DCR, 0x1 | (0x1 << 8)
-					 | (0x1 << 16)
-					 | (0x1 << 24)	/* timeout bit, see HSU Errata 1 */
-					 );
-	chan_writel(rxc, HSU_CH_CR, 0x3);
-}
-
-/* Protected by spin_lock_irqsave(port->lock) */
-static void serial_hsu_start_tx(struct uart_port *port)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-
-	if (up->use_dma) {
-		hsu_dma_tx(up);
-	} else if (!(up->ier & UART_IER_THRI)) {
-		up->ier |= UART_IER_THRI;
-		serial_out(up, UART_IER, up->ier);
-	}
-}
-
-static void serial_hsu_stop_tx(struct uart_port *port)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-	struct hsu_dma_chan *txc = up->txc;
-
-	if (up->use_dma)
-		chan_writel(txc, HSU_CH_CR, 0x0);
-	else if (up->ier & UART_IER_THRI) {
-		up->ier &= ~UART_IER_THRI;
-		serial_out(up, UART_IER, up->ier);
-	}
-}
-
-/* This is always called in spinlock protected mode, so
- * modify timeout timer is safe here */
-static void hsu_dma_rx(struct uart_hsu_port *up, u32 int_sts,
-			unsigned long *flags)
-{
-	struct hsu_dma_buffer *dbuf = &up->rxbuf;
-	struct hsu_dma_chan *chan = up->rxc;
-	struct uart_port *port = &up->port;
-	struct tty_port *tport = &port->state->port;
-	int count;
-
-	/*
-	 * First need to know how many is already transferred,
-	 * then check if its a timeout DMA irq, and return
-	 * the trail bytes out, push them up and reenable the
-	 * channel
-	 */
-
-	/* Timeout IRQ, need wait some time, see Errata 2 */
-	if (int_sts & 0xf00)
-		udelay(2);
-
-	/* Stop the channel */
-	chan_writel(chan, HSU_CH_CR, 0x0);
-
-	count = chan_readl(chan, HSU_CH_D0SAR) - dbuf->dma_addr;
-	if (!count) {
-		/* Restart the channel before we leave */
-		chan_writel(chan, HSU_CH_CR, 0x3);
-		return;
-	}
-
-	dma_sync_single_for_cpu(port->dev, dbuf->dma_addr,
-			dbuf->dma_size, DMA_FROM_DEVICE);
-
-	/*
-	 * Head will only wrap around when we recycle
-	 * the DMA buffer, and when that happens, we
-	 * explicitly set tail to 0. So head will
-	 * always be greater than tail.
-	 */
-	tty_insert_flip_string(tport, dbuf->buf, count);
-	port->icount.rx += count;
-
-	dma_sync_single_for_device(up->port.dev, dbuf->dma_addr,
-			dbuf->dma_size, DMA_FROM_DEVICE);
-
-	/* Reprogram the channel */
-	chan_writel(chan, HSU_CH_D0SAR, dbuf->dma_addr);
-	chan_writel(chan, HSU_CH_D0TSR, dbuf->dma_size);
-	chan_writel(chan, HSU_CH_DCR, 0x1
-					 | (0x1 << 8)
-					 | (0x1 << 16)
-					 | (0x1 << 24)	/* timeout bit, see HSU Errata 1 */
-					 );
-	spin_unlock_irqrestore(&up->port.lock, *flags);
-	tty_flip_buffer_push(tport);
-	spin_lock_irqsave(&up->port.lock, *flags);
-
-	chan_writel(chan, HSU_CH_CR, 0x3);
-
-}
-
-static void serial_hsu_stop_rx(struct uart_port *port)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-	struct hsu_dma_chan *chan = up->rxc;
-
-	if (up->use_dma)
-		chan_writel(chan, HSU_CH_CR, 0x2);
-	else {
-		up->ier &= ~UART_IER_RLSI;
-		up->port.read_status_mask &= ~UART_LSR_DR;
-		serial_out(up, UART_IER, up->ier);
-	}
-}
-
-static inline void receive_chars(struct uart_hsu_port *up, int *status,
-		unsigned long *flags)
-{
-	unsigned int ch, flag;
-	unsigned int max_count = 256;
-
-	do {
-		ch = serial_in(up, UART_RX);
-		flag = TTY_NORMAL;
-		up->port.icount.rx++;
-
-		if (unlikely(*status & (UART_LSR_BI | UART_LSR_PE |
-				       UART_LSR_FE | UART_LSR_OE))) {
-
-			dev_warn(up->dev, "We really rush into ERR/BI case"
-				"status = 0x%02x", *status);
-			/* For statistics only */
-			if (*status & UART_LSR_BI) {
-				*status &= ~(UART_LSR_FE | UART_LSR_PE);
-				up->port.icount.brk++;
-				/*
-				 * We do the SysRQ and SAK checking
-				 * here because otherwise the break
-				 * may get masked by ignore_status_mask
-				 * or read_status_mask.
-				 */
-				if (uart_handle_break(&up->port))
-					goto ignore_char;
-			} else if (*status & UART_LSR_PE)
-				up->port.icount.parity++;
-			else if (*status & UART_LSR_FE)
-				up->port.icount.frame++;
-			if (*status & UART_LSR_OE)
-				up->port.icount.overrun++;
-
-			/* Mask off conditions which should be ignored. */
-			*status &= up->port.read_status_mask;
-
-#ifdef CONFIG_SERIAL_MFD_HSU_CONSOLE
-			if (up->port.cons &&
-				up->port.cons->index == up->port.line) {
-				/* Recover the break flag from console xmit */
-				*status |= up->lsr_break_flag;
-				up->lsr_break_flag = 0;
-			}
-#endif
-			if (*status & UART_LSR_BI) {
-				flag = TTY_BREAK;
-			} else if (*status & UART_LSR_PE)
-				flag = TTY_PARITY;
-			else if (*status & UART_LSR_FE)
-				flag = TTY_FRAME;
-		}
-
-		if (uart_handle_sysrq_char(&up->port, ch))
-			goto ignore_char;
-
-		uart_insert_char(&up->port, *status, UART_LSR_OE, ch, flag);
-	ignore_char:
-		*status = serial_in(up, UART_LSR);
-	} while ((*status & UART_LSR_DR) && max_count--);
-
-	spin_unlock_irqrestore(&up->port.lock, *flags);
-	tty_flip_buffer_push(&up->port.state->port);
-	spin_lock_irqsave(&up->port.lock, *flags);
-}
-
-static void transmit_chars(struct uart_hsu_port *up)
-{
-	struct circ_buf *xmit = &up->port.state->xmit;
-	int count;
-
-	if (up->port.x_char) {
-		serial_out(up, UART_TX, up->port.x_char);
-		up->port.icount.tx++;
-		up->port.x_char = 0;
-		return;
-	}
-	if (uart_circ_empty(xmit) || uart_tx_stopped(&up->port)) {
-		serial_hsu_stop_tx(&up->port);
-		return;
-	}
-
-	/* The IRQ is for TX FIFO half-empty */
-	count = up->port.fifosize / 2;
-
-	do {
-		serial_out(up, UART_TX, xmit->buf[xmit->tail]);
-		xmit->tail = (xmit->tail + 1) & (UART_XMIT_SIZE - 1);
-
-		up->port.icount.tx++;
-		if (uart_circ_empty(xmit))
-			break;
-	} while (--count > 0);
-
-	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
-		uart_write_wakeup(&up->port);
-
-	if (uart_circ_empty(xmit))
-		serial_hsu_stop_tx(&up->port);
-}
-
-static inline void check_modem_status(struct uart_hsu_port *up)
-{
-	int status;
-
-	status = serial_in(up, UART_MSR);
-
-	if ((status & UART_MSR_ANY_DELTA) == 0)
-		return;
-
-	if (status & UART_MSR_TERI)
-		up->port.icount.rng++;
-	if (status & UART_MSR_DDSR)
-		up->port.icount.dsr++;
-	/* We may only get DDCD when HW init and reset */
-	if (status & UART_MSR_DDCD)
-		uart_handle_dcd_change(&up->port, status & UART_MSR_DCD);
-	/* Will start/stop_tx accordingly */
-	if (status & UART_MSR_DCTS)
-		uart_handle_cts_change(&up->port, status & UART_MSR_CTS);
-
-	wake_up_interruptible(&up->port.state->port.delta_msr_wait);
-}
-
-/*
- * This handles the interrupt from one port.
- */
-static irqreturn_t port_irq(int irq, void *dev_id)
-{
-	struct uart_hsu_port *up = dev_id;
-	unsigned int iir, lsr;
-	unsigned long flags;
-
-	if (unlikely(!up->running))
-		return IRQ_NONE;
-
-	spin_lock_irqsave(&up->port.lock, flags);
-	if (up->use_dma) {
-		lsr = serial_in(up, UART_LSR);
-		if (unlikely(lsr & (UART_LSR_BI | UART_LSR_PE |
-				       UART_LSR_FE | UART_LSR_OE)))
-			dev_warn(up->dev,
-				"Got lsr irq while using DMA, lsr = 0x%2x\n",
-				lsr);
-		check_modem_status(up);
-		spin_unlock_irqrestore(&up->port.lock, flags);
-		return IRQ_HANDLED;
-	}
-
-	iir = serial_in(up, UART_IIR);
-	if (iir & UART_IIR_NO_INT) {
-		spin_unlock_irqrestore(&up->port.lock, flags);
-		return IRQ_NONE;
-	}
-
-	lsr = serial_in(up, UART_LSR);
-	if (lsr & UART_LSR_DR)
-		receive_chars(up, &lsr, &flags);
-	check_modem_status(up);
-
-	/* lsr will be renewed during the receive_chars */
-	if (lsr & UART_LSR_THRE)
-		transmit_chars(up);
-
-	spin_unlock_irqrestore(&up->port.lock, flags);
-	return IRQ_HANDLED;
-}
-
-static inline void dma_chan_irq(struct hsu_dma_chan *chan)
-{
-	struct uart_hsu_port *up = chan->uport;
-	unsigned long flags;
-	u32 int_sts;
-
-	spin_lock_irqsave(&up->port.lock, flags);
-
-	if (!up->use_dma || !up->running)
-		goto exit;
-
-	/*
-	 * No matter what situation, need read clear the IRQ status
-	 * There is a bug, see Errata 5, HSD 2900918
-	 */
-	int_sts = chan_readl(chan, HSU_CH_SR);
-
-	/* Rx channel */
-	if (chan->dirt == DMA_FROM_DEVICE)
-		hsu_dma_rx(up, int_sts, &flags);
-
-	/* Tx channel */
-	if (chan->dirt == DMA_TO_DEVICE) {
-		chan_writel(chan, HSU_CH_CR, 0x0);
-		up->dma_tx_on = 0;
-		hsu_dma_tx(up);
-	}
-
-exit:
-	spin_unlock_irqrestore(&up->port.lock, flags);
-	return;
-}
-
-static irqreturn_t dma_irq(int irq, void *dev_id)
-{
-	struct hsu_port *hsu = dev_id;
-	u32 int_sts, i;
-
-	int_sts = mfd_readl(hsu, HSU_GBL_DMAISR);
-
-	/* Currently we only have 6 channels may be used */
-	for (i = 0; i < 6; i++) {
-		if (int_sts & 0x1)
-			dma_chan_irq(&hsu->chans[i]);
-		int_sts >>= 1;
-	}
-
-	return IRQ_HANDLED;
-}
-
-static unsigned int serial_hsu_tx_empty(struct uart_port *port)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-	unsigned long flags;
-	unsigned int ret;
-
-	spin_lock_irqsave(&up->port.lock, flags);
-	ret = serial_in(up, UART_LSR) & UART_LSR_TEMT ? TIOCSER_TEMT : 0;
-	spin_unlock_irqrestore(&up->port.lock, flags);
-
-	return ret;
-}
-
-static unsigned int serial_hsu_get_mctrl(struct uart_port *port)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-	unsigned char status;
-	unsigned int ret;
-
-	status = serial_in(up, UART_MSR);
-
-	ret = 0;
-	if (status & UART_MSR_DCD)
-		ret |= TIOCM_CAR;
-	if (status & UART_MSR_RI)
-		ret |= TIOCM_RNG;
-	if (status & UART_MSR_DSR)
-		ret |= TIOCM_DSR;
-	if (status & UART_MSR_CTS)
-		ret |= TIOCM_CTS;
-	return ret;
-}
-
-static void serial_hsu_set_mctrl(struct uart_port *port, unsigned int mctrl)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-	unsigned char mcr = 0;
-
-	if (mctrl & TIOCM_RTS)
-		mcr |= UART_MCR_RTS;
-	if (mctrl & TIOCM_DTR)
-		mcr |= UART_MCR_DTR;
-	if (mctrl & TIOCM_OUT1)
-		mcr |= UART_MCR_OUT1;
-	if (mctrl & TIOCM_OUT2)
-		mcr |= UART_MCR_OUT2;
-	if (mctrl & TIOCM_LOOP)
-		mcr |= UART_MCR_LOOP;
-
-	mcr |= up->mcr;
-
-	serial_out(up, UART_MCR, mcr);
-}
-
-static void serial_hsu_break_ctl(struct uart_port *port, int break_state)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-	unsigned long flags;
-
-	spin_lock_irqsave(&up->port.lock, flags);
-	if (break_state == -1)
-		up->lcr |= UART_LCR_SBC;
-	else
-		up->lcr &= ~UART_LCR_SBC;
-	serial_out(up, UART_LCR, up->lcr);
-	spin_unlock_irqrestore(&up->port.lock, flags);
-}
-
-/*
- * What special to do:
- * 1. chose the 64B fifo mode
- * 2. start dma or pio depends on configuration
- * 3. we only allocate dma memory when needed
- */
-static int serial_hsu_startup(struct uart_port *port)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-	unsigned long flags;
-
-	pm_runtime_get_sync(up->dev);
-
-	/*
-	 * Clear the FIFO buffers and disable them.
-	 * (they will be reenabled in set_termios())
-	 */
-	serial_out(up, UART_FCR, UART_FCR_ENABLE_FIFO);
-	serial_out(up, UART_FCR, UART_FCR_ENABLE_FIFO |
-			UART_FCR_CLEAR_RCVR | UART_FCR_CLEAR_XMIT);
-	serial_out(up, UART_FCR, 0);
-
-	/* Clear the interrupt registers. */
-	(void) serial_in(up, UART_LSR);
-	(void) serial_in(up, UART_RX);
-	(void) serial_in(up, UART_IIR);
-	(void) serial_in(up, UART_MSR);
-
-	/* Now, initialize the UART, default is 8n1 */
-	serial_out(up, UART_LCR, UART_LCR_WLEN8);
-
-	spin_lock_irqsave(&up->port.lock, flags);
-
-	up->port.mctrl |= TIOCM_OUT2;
-	serial_hsu_set_mctrl(&up->port, up->port.mctrl);
-
-	/*
-	 * Finally, enable interrupts.  Note: Modem status interrupts
-	 * are set via set_termios(), which will be occurring imminently
-	 * anyway, so we don't enable them here.
-	 */
-	if (!up->use_dma)
-		up->ier = UART_IER_RLSI | UART_IER_RDI | UART_IER_RTOIE;
-	else
-		up->ier = 0;
-	serial_out(up, UART_IER, up->ier);
-
-	spin_unlock_irqrestore(&up->port.lock, flags);
-
-	/* DMA init */
-	if (up->use_dma) {
-		struct hsu_dma_buffer *dbuf;
-		struct circ_buf *xmit = &port->state->xmit;
-
-		up->dma_tx_on = 0;
-
-		/* First allocate the RX buffer */
-		dbuf = &up->rxbuf;
-		dbuf->buf = kzalloc(HSU_DMA_BUF_SIZE, GFP_KERNEL);
-		if (!dbuf->buf) {
-			up->use_dma = 0;
-			goto exit;
-		}
-		dbuf->dma_addr = dma_map_single(port->dev,
-						dbuf->buf,
-						HSU_DMA_BUF_SIZE,
-						DMA_FROM_DEVICE);
-		dbuf->dma_size = HSU_DMA_BUF_SIZE;
-
-		/* Start the RX channel right now */
-		hsu_dma_start_rx_chan(up->rxc, dbuf);
-
-		/* Next init the TX DMA */
-		dbuf = &up->txbuf;
-		dbuf->buf = xmit->buf;
-		dbuf->dma_addr = dma_map_single(port->dev,
-					       dbuf->buf,
-					       UART_XMIT_SIZE,
-					       DMA_TO_DEVICE);
-		dbuf->dma_size = UART_XMIT_SIZE;
-
-		/* This should not be changed all around */
-		chan_writel(up->txc, HSU_CH_BSR, 32);
-		chan_writel(up->txc, HSU_CH_MOTSR, 4);
-		dbuf->ofs = 0;
-	}
-
-exit:
-	 /* And clear the interrupt registers again for luck. */
-	(void) serial_in(up, UART_LSR);
-	(void) serial_in(up, UART_RX);
-	(void) serial_in(up, UART_IIR);
-	(void) serial_in(up, UART_MSR);
-
-	up->running = 1;
-	return 0;
-}
-
-static void serial_hsu_shutdown(struct uart_port *port)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-	unsigned long flags;
-
-	/* Disable interrupts from this port */
-	up->ier = 0;
-	serial_out(up, UART_IER, 0);
-	up->running = 0;
-
-	spin_lock_irqsave(&up->port.lock, flags);
-	up->port.mctrl &= ~TIOCM_OUT2;
-	serial_hsu_set_mctrl(&up->port, up->port.mctrl);
-	spin_unlock_irqrestore(&up->port.lock, flags);
-
-	/* Disable break condition and FIFOs */
-	serial_out(up, UART_LCR, serial_in(up, UART_LCR) & ~UART_LCR_SBC);
-	serial_out(up, UART_FCR, UART_FCR_ENABLE_FIFO |
-				  UART_FCR_CLEAR_RCVR |
-				  UART_FCR_CLEAR_XMIT);
-	serial_out(up, UART_FCR, 0);
-
-	pm_runtime_put(up->dev);
-}
-
-static void
-serial_hsu_set_termios(struct uart_port *port, struct ktermios *termios,
-		       struct ktermios *old)
-{
-	struct uart_hsu_port *up =
-			container_of(port, struct uart_hsu_port, port);
-	unsigned char cval, fcr = 0;
-	unsigned long flags;
-	unsigned int baud, quot;
-	u32 ps, mul;
-
-	switch (termios->c_cflag & CSIZE) {
-	case CS5:
-		cval = UART_LCR_WLEN5;
-		break;
-	case CS6:
-		cval = UART_LCR_WLEN6;
-		break;
-	case CS7:
-		cval = UART_LCR_WLEN7;
-		break;
-	default:
-	case CS8:
-		cval = UART_LCR_WLEN8;
-		break;
-	}
-
-	/* CMSPAR isn't supported by this driver */
-	termios->c_cflag &= ~CMSPAR;
-
-	if (termios->c_cflag & CSTOPB)
-		cval |= UART_LCR_STOP;
-	if (termios->c_cflag & PARENB)
-		cval |= UART_LCR_PARITY;
-	if (!(termios->c_cflag & PARODD))
-		cval |= UART_LCR_EPAR;
-
-	/*
-	 * The base clk is 50Mhz, and the baud rate come from:
-	 *	baud = 50M * MUL / (DIV * PS * DLAB)
-	 *
-	 * For those basic low baud rate we can get the direct
-	 * scalar from 2746800, like 115200 = 2746800/24. For those
-	 * higher baud rate, we handle them case by case, mainly by
-	 * adjusting the MUL/PS registers, and DIV register is kept
-	 * as default value 0x3d09 to make things simple
-	 */
-	baud = uart_get_baud_rate(port, termios, old, 0, 4000000);
-
-	quot = 1;
-	ps = 0x10;
-	mul = 0x3600;
-	switch (baud) {
-	case 3500000:
-		mul = 0x3345;
-		ps = 0xC;
-		break;
-	case 1843200:
-		mul = 0x2400;
-		break;
-	case 3000000:
-	case 2500000:
-	case 2000000:
-	case 1500000:
-	case 1000000:
-	case 500000:
-		/* mul/ps/quot = 0x9C4/0x10/0x1 will make a 500000 bps */
-		mul = baud / 500000 * 0x9C4;
-		break;
-	default:
-		/* Use uart_get_divisor to get quot for other baud rates */
-		quot = 0;
-	}
-
-	if (!quot)
-		quot = uart_get_divisor(port, baud);
-
-	if ((up->port.uartclk / quot) < (2400 * 16))
-		fcr = UART_FCR_ENABLE_FIFO | UART_FCR_HSU_64_1B;
-	else if ((up->port.uartclk / quot) < (230400 * 16))
-		fcr = UART_FCR_ENABLE_FIFO | UART_FCR_HSU_64_16B;
-	else
-		fcr = UART_FCR_ENABLE_FIFO | UART_FCR_HSU_64_32B;
-
-	fcr |= UART_FCR_HSU_64B_FIFO;
-
-	/*
-	 * Ok, we're now changing the port state.  Do it with
-	 * interrupts disabled.
-	 */
-	spin_lock_irqsave(&up->port.lock, flags);
-
-	/* Update the per-port timeout */
-	uart_update_timeout(port, termios->c_cflag, baud);
-
-	up->port.read_status_mask = UART_LSR_OE | UART_LSR_THRE | UART_LSR_DR;
-	if (termios->c_iflag & INPCK)
-		up->port.read_status_mask |= UART_LSR_FE | UART_LSR_PE;
-	if (termios->c_iflag & (IGNBRK | BRKINT | PARMRK))
-		up->port.read_status_mask |= UART_LSR_BI;
-
-	/* Characters to ignore */
-	up->port.ignore_status_mask = 0;
-	if (termios->c_iflag & IGNPAR)
-		up->port.ignore_status_mask |= UART_LSR_PE | UART_LSR_FE;
-	if (termios->c_iflag & IGNBRK) {
-		up->port.ignore_status_mask |= UART_LSR_BI;
-		/*
-		 * If we're ignoring parity and break indicators,
-		 * ignore overruns too (for real raw support).
-		 */
-		if (termios->c_iflag & IGNPAR)
-			up->port.ignore_status_mask |= UART_LSR_OE;
-	}
-
-	/* Ignore all characters if CREAD is not set */
-	if ((termios->c_cflag & CREAD) == 0)
-		up->port.ignore_status_mask |= UART_LSR_DR;
-
-	/*
-	 * CTS flow control flag and modem status interrupts, disable
-	 * MSI by default
-	 */
-	up->ier &= ~UART_IER_MSI;
-	if (UART_ENABLE_MS(&up->port, termios->c_cflag))
-		up->ier |= UART_IER_MSI;
-
-	serial_out(up, UART_IER, up->ier);
-
-	if (termios->c_cflag & CRTSCTS)
-		up->mcr |= UART_MCR_AFE | UART_MCR_RTS;
-	else
-		up->mcr &= ~UART_MCR_AFE;
-
-	serial_out(up, UART_LCR, cval | UART_LCR_DLAB);	/* set DLAB */
-	serial_out(up, UART_DLL, quot & 0xff);		/* LS of divisor */
-	serial_out(up, UART_DLM, quot >> 8);		/* MS of divisor */
-	serial_out(up, UART_LCR, cval);			/* reset DLAB */
-	serial_out(up, UART_MUL, mul);			/* set MUL */
-	serial_out(up, UART_PS, ps);			/* set PS */
-	up->lcr = cval;					/* Save LCR */
-	serial_hsu_set_mctrl(&up->port, up->port.mctrl);
-	serial_out(up, UART_FCR, fcr);
-	spin_unlock_irqrestore(&up->port.lock, flags);
-}
-
-static void
-serial_hsu_pm(struct uart_port *port, unsigned int state,
-	      unsigned int oldstate)
-{
-}
-
-static void serial_hsu_release_port(struct uart_port *port)
-{
-}
-
-static int serial_hsu_request_port(struct uart_port *port)
-{
-	return 0;
-}
-
-static void serial_hsu_config_port(struct uart_port *port, int flags)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-	up->port.type = PORT_MFD;
-}
-
-static int
-serial_hsu_verify_port(struct uart_port *port, struct serial_struct *ser)
-{
-	/* We don't want the core code to modify any port params */
-	return -EINVAL;
-}
-
-static const char *
-serial_hsu_type(struct uart_port *port)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-	return up->name;
-}
-
-/* Mainly for uart console use */
-static struct uart_hsu_port *serial_hsu_ports[3];
-static struct uart_driver serial_hsu_reg;
-
-#ifdef CONFIG_SERIAL_MFD_HSU_CONSOLE
-
-#define BOTH_EMPTY (UART_LSR_TEMT | UART_LSR_THRE)
-
-/* Wait for transmitter & holding register to empty */
-static inline void wait_for_xmitr(struct uart_hsu_port *up)
-{
-	unsigned int status, tmout = 1000;
-
-	/* Wait up to 1ms for the character to be sent. */
-	do {
-		status = serial_in(up, UART_LSR);
-
-		if (status & UART_LSR_BI)
-			up->lsr_break_flag = UART_LSR_BI;
-
-		if (--tmout == 0)
-			break;
-		udelay(1);
-	} while (!(status & BOTH_EMPTY));
-
-	/* Wait up to 1s for flow control if necessary */
-	if (up->port.flags & UPF_CONS_FLOW) {
-		tmout = 1000000;
-		while (--tmout &&
-		       ((serial_in(up, UART_MSR) & UART_MSR_CTS) == 0))
-			udelay(1);
-	}
-}
-
-static void serial_hsu_console_putchar(struct uart_port *port, int ch)
-{
-	struct uart_hsu_port *up =
-		container_of(port, struct uart_hsu_port, port);
-
-	wait_for_xmitr(up);
-	serial_out(up, UART_TX, ch);
-}
-
-/*
- * Print a string to the serial port trying not to disturb
- * any possible real use of the port...
- *
- *	The console_lock must be held when we get here.
- */
-static void
-serial_hsu_console_write(struct console *co, const char *s, unsigned int count)
-{
-	struct uart_hsu_port *up = serial_hsu_ports[co->index];
-	unsigned long flags;
-	unsigned int ier;
-	int locked = 1;
-
-	touch_nmi_watchdog();
-
-	local_irq_save(flags);
-	if (up->port.sysrq)
-		locked = 0;
-	else if (oops_in_progress) {
-		locked = spin_trylock(&up->port.lock);
-	} else
-		spin_lock(&up->port.lock);
-
-	/* First save the IER then disable the interrupts */
-	ier = serial_in(up, UART_IER);
-	serial_out(up, UART_IER, 0);
-
-	uart_console_write(&up->port, s, count, serial_hsu_console_putchar);
-
-	/*
-	 * Finally, wait for transmitter to become empty
-	 * and restore the IER
-	 */
-	wait_for_xmitr(up);
-	serial_out(up, UART_IER, ier);
-
-	if (locked)
-		spin_unlock(&up->port.lock);
-	local_irq_restore(flags);
-}
-
-static struct console serial_hsu_console;
-
-static int __init
-serial_hsu_console_setup(struct console *co, char *options)
-{
-	struct uart_hsu_port *up;
-	int baud = 115200;
-	int bits = 8;
-	int parity = 'n';
-	int flow = 'n';
-
-	if (co->index == -1 || co->index >= serial_hsu_reg.nr)
-		co->index = 0;
-	up = serial_hsu_ports[co->index];
-	if (!up)
-		return -ENODEV;
-
-	if (options)
-		uart_parse_options(options, &baud, &parity, &bits, &flow);
-
-	return uart_set_options(&up->port, co, baud, parity, bits, flow);
-}
-
-static struct console serial_hsu_console = {
-	.name		= "ttyMFD",
-	.write		= serial_hsu_console_write,
-	.device		= uart_console_device,
-	.setup		= serial_hsu_console_setup,
-	.flags		= CON_PRINTBUFFER,
-	.index		= -1,
-	.data		= &serial_hsu_reg,
-};
-
-#define SERIAL_HSU_CONSOLE	(&serial_hsu_console)
-#else
-#define SERIAL_HSU_CONSOLE	NULL
-#endif
-
-static struct uart_ops serial_hsu_pops = {
-	.tx_empty	= serial_hsu_tx_empty,
-	.set_mctrl	= serial_hsu_set_mctrl,
-	.get_mctrl	= serial_hsu_get_mctrl,
-	.stop_tx	= serial_hsu_stop_tx,
-	.start_tx	= serial_hsu_start_tx,
-	.stop_rx	= serial_hsu_stop_rx,
-	.enable_ms	= serial_hsu_enable_ms,
-	.break_ctl	= serial_hsu_break_ctl,
-	.startup	= serial_hsu_startup,
-	.shutdown	= serial_hsu_shutdown,
-	.set_termios	= serial_hsu_set_termios,
-	.pm		= serial_hsu_pm,
-	.type		= serial_hsu_type,
-	.release_port	= serial_hsu_release_port,
-	.request_port	= serial_hsu_request_port,
-	.config_port	= serial_hsu_config_port,
-	.verify_port	= serial_hsu_verify_port,
-};
-
-static struct uart_driver serial_hsu_reg = {
-	.owner		= THIS_MODULE,
-	.driver_name	= "MFD serial",
-	.dev_name	= "ttyMFD",
-	.major		= TTY_MAJOR,
-	.minor		= 128,
-	.nr		= 3,
-	.cons		= SERIAL_HSU_CONSOLE,
-};
-
-#ifdef CONFIG_PM
-static int serial_hsu_suspend(struct pci_dev *pdev, pm_message_t state)
-{
-	void *priv = pci_get_drvdata(pdev);
-	struct uart_hsu_port *up;
-
-	/* Make sure this is not the internal dma controller */
-	if (priv && (pdev->device != 0x081E)) {
-		up = priv;
-		uart_suspend_port(&serial_hsu_reg, &up->port);
-	}
-
-	pci_save_state(pdev);
-	pci_set_power_state(pdev, pci_choose_state(pdev, state));
-        return 0;
-}
-
-static int serial_hsu_resume(struct pci_dev *pdev)
-{
-	void *priv = pci_get_drvdata(pdev);
-	struct uart_hsu_port *up;
-	int ret;
-
-	pci_set_power_state(pdev, PCI_D0);
-	pci_restore_state(pdev);
-
-	ret = pci_enable_device(pdev);
-	if (ret)
-		dev_warn(&pdev->dev,
-			"HSU: can't re-enable device, try to continue\n");
-
-	if (priv && (pdev->device != 0x081E)) {
-		up = priv;
-		uart_resume_port(&serial_hsu_reg, &up->port);
-	}
-	return 0;
-}
-#else
-#define serial_hsu_suspend	NULL
-#define serial_hsu_resume	NULL
-#endif
-
-#ifdef CONFIG_PM_RUNTIME
-static int serial_hsu_runtime_idle(struct device *dev)
-{
-	pm_schedule_suspend(dev, 500);
-	return -EBUSY;
-}
-
-static int serial_hsu_runtime_suspend(struct device *dev)
-{
-	return 0;
-}
-
-static int serial_hsu_runtime_resume(struct device *dev)
-{
-	return 0;
-}
-#else
-#define serial_hsu_runtime_idle		NULL
-#define serial_hsu_runtime_suspend	NULL
-#define serial_hsu_runtime_resume	NULL
-#endif
-
-static const struct dev_pm_ops serial_hsu_pm_ops = {
-	.runtime_suspend = serial_hsu_runtime_suspend,
-	.runtime_resume = serial_hsu_runtime_resume,
-	.runtime_idle = serial_hsu_runtime_idle,
-};
-
-/* temp global pointer before we settle down on using one or four PCI dev */
-static struct hsu_port *phsu;
-
-static int serial_hsu_probe(struct pci_dev *pdev,
-				const struct pci_device_id *ent)
-{
-	struct uart_hsu_port *uport;
-	int index, ret;
-
-	printk(KERN_INFO "HSU: found PCI Serial controller(ID: %04x:%04x)\n",
-		pdev->vendor, pdev->device);
-
-	switch (pdev->device) {
-	case 0x081B:
-		index = 0;
-		break;
-	case 0x081C:
-		index = 1;
-		break;
-	case 0x081D:
-		index = 2;
-		break;
-	case 0x081E:
-		/* internal DMA controller */
-		index = 3;
-		break;
-	default:
-		dev_err(&pdev->dev, "HSU: out of index!");
-		return -ENODEV;
-	}
-
-	ret = pci_enable_device(pdev);
-	if (ret)
-		return ret;
-
-	if (index == 3) {
-		/* DMA controller */
-		ret = request_irq(pdev->irq, dma_irq, 0, "hsu_dma", phsu);
-		if (ret) {
-			dev_err(&pdev->dev, "can not get IRQ\n");
-			goto err_disable;
-		}
-		pci_set_drvdata(pdev, phsu);
-	} else {
-		/* UART port 0~2 */
-		uport = &phsu->port[index];
-		uport->port.irq = pdev->irq;
-		uport->port.dev = &pdev->dev;
-		uport->dev = &pdev->dev;
-
-		ret = request_irq(pdev->irq, port_irq, 0, uport->name, uport);
-		if (ret) {
-			dev_err(&pdev->dev, "can not get IRQ\n");
-			goto err_disable;
-		}
-		uart_add_one_port(&serial_hsu_reg, &uport->port);
-
-		pci_set_drvdata(pdev, uport);
-	}
-
-	pm_runtime_put_noidle(&pdev->dev);
-	pm_runtime_allow(&pdev->dev);
-
-	return 0;
-
-err_disable:
-	pci_disable_device(pdev);
-	return ret;
-}
-
-static void hsu_global_init(void)
-{
-	struct hsu_port *hsu;
-	struct uart_hsu_port *uport;
-	struct hsu_dma_chan *dchan;
-	int i, ret;
-
-	hsu = kzalloc(sizeof(struct hsu_port), GFP_KERNEL);
-	if (!hsu)
-		return;
-
-	/* Get basic io resource and map it */
-	hsu->paddr = 0xffa28000;
-	hsu->iolen = 0x1000;
-
-	if (!(request_mem_region(hsu->paddr, hsu->iolen, "HSU global")))
-		pr_warning("HSU: error in request mem region\n");
-
-	hsu->reg = ioremap_nocache((unsigned long)hsu->paddr, hsu->iolen);
-	if (!hsu->reg) {
-		pr_err("HSU: error in ioremap\n");
-		ret = -ENOMEM;
-		goto err_free_region;
-	}
-
-	/* Initialise the 3 UART ports */
-	uport = hsu->port;
-	for (i = 0; i < 3; i++) {
-		uport->port.type = PORT_MFD;
-		uport->port.iotype = UPIO_MEM;
-		uport->port.mapbase = (resource_size_t)hsu->paddr
-					+ HSU_PORT_REG_OFFSET
-					+ i * HSU_PORT_REG_LENGTH;
-		uport->port.membase = hsu->reg + HSU_PORT_REG_OFFSET
-					+ i * HSU_PORT_REG_LENGTH;
-
-		sprintf(uport->name, "hsu_port%d", i);
-		uport->port.fifosize = 64;
-		uport->port.ops = &serial_hsu_pops;
-		uport->port.line = i;
-		uport->port.flags = UPF_IOREMAP;
-		/* set the scalable maxim support rate to 2746800 bps */
-		uport->port.uartclk = 115200 * 24 * 16;
-
-		uport->running = 0;
-		uport->txc = &hsu->chans[i * 2];
-		uport->rxc = &hsu->chans[i * 2 + 1];
-
-		serial_hsu_ports[i] = uport;
-		uport->index = i;
-
-		if (hsu_dma_enable & (1<<i))
-			uport->use_dma = 1;
-		else
-			uport->use_dma = 0;
-
-		uport++;
-	}
-
-	/* Initialise 6 dma channels */
-	dchan = hsu->chans;
-	for (i = 0; i < 6; i++) {
-		dchan->id = i;
-		dchan->dirt = (i & 0x1) ? DMA_FROM_DEVICE : DMA_TO_DEVICE;
-		dchan->uport = &hsu->port[i/2];
-		dchan->reg = hsu->reg + HSU_DMA_CHANS_REG_OFFSET +
-				i * HSU_DMA_CHANS_REG_LENGTH;
-
-		dchan++;
-	}
-
-	phsu = hsu;
-	hsu_debugfs_init(hsu);
-	return;
-
-err_free_region:
-	release_mem_region(hsu->paddr, hsu->iolen);
-	kfree(hsu);
-	return;
-}
-
-static void serial_hsu_remove(struct pci_dev *pdev)
-{
-	void *priv = pci_get_drvdata(pdev);
-	struct uart_hsu_port *up;
-
-	if (!priv)
-		return;
-
-	pm_runtime_forbid(&pdev->dev);
-	pm_runtime_get_noresume(&pdev->dev);
-
-	/* For port 0/1/2, priv is the address of uart_hsu_port */
-	if (pdev->device != 0x081E) {
-		up = priv;
-		uart_remove_one_port(&serial_hsu_reg, &up->port);
-	}
-
-	free_irq(pdev->irq, priv);
-	pci_disable_device(pdev);
-}
-
-/* First 3 are UART ports, and the 4th is the DMA */
-static const struct pci_device_id pci_ids[] = {
-	{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x081B) },
-	{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x081C) },
-	{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x081D) },
-	{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, 0x081E) },
-	{},
-};
-
-static struct pci_driver hsu_pci_driver = {
-	.name =		"HSU serial",
-	.id_table =	pci_ids,
-	.probe =	serial_hsu_probe,
-	.remove =	serial_hsu_remove,
-	.suspend =	serial_hsu_suspend,
-	.resume	=	serial_hsu_resume,
-	.driver = {
-		.pm = &serial_hsu_pm_ops,
-	},
-};
-
-static int __init hsu_pci_init(void)
-{
-	int ret;
-
-	hsu_global_init();
-
-	ret = uart_register_driver(&serial_hsu_reg);
-	if (ret)
-		return ret;
-
-	return pci_register_driver(&hsu_pci_driver);
-}
-
-static void __exit hsu_pci_exit(void)
-{
-	pci_unregister_driver(&hsu_pci_driver);
-	uart_unregister_driver(&serial_hsu_reg);
-
-	hsu_debugfs_remove(phsu);
-
-	kfree(phsu);
-}
-
-module_init(hsu_pci_init);
-module_exit(hsu_pci_exit);
-
-MODULE_LICENSE("GPL v2");
-MODULE_DEVICE_TABLE(pci, pci_ids);
diff --git a/drivers/tty/serial/mfd.h b/drivers/tty/serial/mfd.h
new file mode 100644
index 0000000..22cb3f3
--- /dev/null
+++ b/drivers/tty/serial/mfd.h
@@ -0,0 +1,252 @@
+#ifndef _MFD_H
+#define _MFD_H
+
+#include <linux/serial_core.h>
+#include <linux/serial_reg.h>
+#include <linux/serial_mfd.h>
+#include <linux/intel_mid_dma.h>
+#include <linux/intel_mid_pm.h>
+#include <linux/dma-direction.h>
+#include <asm/intel_mid_hsu.h>
+
+#define HSU_PORT_MAX		8
+#define HSU_DMA_BUF_SIZE	2048
+#define HSU_Q_MAX		4096
+#define HSU_CL_BUF_LEN		(1 << CONFIG_LOG_BUF_SHIFT)
+#define HSU_DMA_BSR		32
+#define HSU_DMA_MOTSR		4
+#define HSU_PIO_RX_ERR		0x06
+#define HSU_PIO_RX_AVB		0x04
+#define HSU_PIO_RX_TMO		0x0C
+#define HSU_PIO_TX_REQ		0x02
+
+enum {
+	flag_console = 0,
+	flag_reopen,
+	flag_suspend,
+	flag_active,
+	flag_set_alt,
+	flag_tx_on,
+	flag_rx_on,
+	flag_rx_pending,
+	flag_startup,
+	flag_cmd_on,
+	flag_cmd_off,
+};
+
+enum {
+	qcmd_overflow = 0,
+	qcmd_get_msr,
+	qcmd_set_mcr,
+	qcmd_set_ier,
+	qcmd_start_rx,
+	qcmd_stop_rx,
+	qcmd_start_tx,
+	qcmd_stop_tx,
+	qcmd_cl,
+	qcmd_port_irq,
+	qcmd_dma_irq,
+	qcmd_enable_irq,
+	qcmd_cmd_off,
+	qcmd_max,
+};
+
+enum {
+	context_save,
+	context_load,
+};
+
+struct hsu_dma_buffer {
+	u8		*buf;
+	dma_addr_t	dma_addr;
+	u32		dma_size;
+	u32		ofs;
+};
+
+struct hsu_dma_chan {
+	u32	id;
+	enum dma_data_direction	dirt;
+	struct uart_hsu_port	*uport;
+	void __iomem		*reg;
+	u32	cr;
+	u32	dcr;
+	u32	sar;
+	u32	tsr;
+};
+
+struct dw_dma_priv {
+	struct intel_mid_dma_slave	txs;
+	struct intel_mid_dma_slave	rxs;
+
+	struct uart_hsu_port	*up;
+
+	struct dma_chan		*txchan;
+	struct dma_chan		*rxchan;
+
+	/* phy address of the Data register */
+	dma_addr_t		dma_addr;
+	struct pci_dev		*dmac;
+};
+
+struct intel_dma_priv {
+	unsigned int		tx_addr;
+	struct hsu_dma_chan	*txc;
+	struct hsu_dma_chan	*rxc;
+};
+
+struct hsu_dma_ops {
+	int (*init)(struct uart_hsu_port *up);
+	int (*exit)(struct uart_hsu_port *up);
+	int (*suspend)(struct uart_hsu_port *up);
+	int (*resume)(struct uart_hsu_port *up);
+	void (*start_tx)(struct uart_hsu_port *up);
+	void (*stop_tx)(struct uart_hsu_port *up);
+	void (*start_rx)(struct uart_hsu_port *up);
+	void (*stop_rx)(struct uart_hsu_port *up);
+	/* op will be context_save or context_load */
+	void (*context_op)(struct uart_hsu_port *up, int op);
+};
+
+struct uart_hsu_port {
+	struct uart_port        port;
+	struct mutex		q_mutex;
+	int			q_start;
+	struct workqueue_struct *workqueue;
+	struct work_struct	work;
+	struct tasklet_struct	tasklet;
+	struct circ_buf		qcirc;
+	int			qbuf[HSU_Q_MAX];
+	struct circ_buf		cl_circ;
+	spinlock_t		cl_lock;
+
+	/* Intel HSU or Designware */
+	int			hw_type;
+
+	unsigned char           msr;
+	unsigned char           ier;
+	unsigned char           lcr;
+	unsigned char           mcr;
+	unsigned char           lsr;
+	unsigned char           dll;
+	unsigned char           dlm;
+	unsigned char		fcr;
+	/* intel_hsu's clk param */
+	unsigned int		mul;
+	unsigned int		div;
+	unsigned int		ps;
+
+	/* Buffered value due to runtime PM and sharing IRQ */
+	unsigned char		iir;
+
+	/* intel_dw's clk param */
+	unsigned int		m;
+	unsigned int		n;
+
+	unsigned int            lsr_break_flag;
+	char			name[24];
+	int			index;
+	struct device		*dev;
+
+	unsigned int		tx_addr;
+	struct hsu_dma_chan	*txc;
+	struct hsu_dma_chan	*rxc;
+	struct hsu_dma_buffer	txbuf;
+	struct hsu_dma_buffer	rxbuf;
+
+	unsigned char		rxc_chcr_save;
+
+	unsigned long		flags;
+
+	unsigned int		qcmd_num;
+	unsigned int		qcmd_done;
+	unsigned int		port_irq_num;
+	unsigned int		port_irq_cmddone;
+	unsigned int		port_irq_no_alt;
+	unsigned int		port_irq_no_startup;
+	unsigned int		port_irq_pio_no_irq_pend;
+	unsigned int		port_irq_pio_tx_req;
+	unsigned int		port_irq_pio_rx_avb;
+	unsigned int		port_irq_pio_rx_err;
+	unsigned int		port_irq_pio_rx_timeout;
+	unsigned int		cts_status;
+	unsigned int		dma_irq_num;
+	unsigned int		dma_invalid_irq_num;
+	unsigned int		dma_irq_cmddone;
+	unsigned int		dma_tx_irq_cmddone;
+	unsigned int		dma_rx_irq_cmddone;
+	unsigned int		dma_rx_tmt_irq_cmddone;
+	unsigned int		tasklet_done;
+	unsigned int		workq_done;
+	unsigned int		in_workq;
+	unsigned int		in_tasklet;
+
+	unsigned int		byte_delay;
+
+	int			use_dma;	/* flag for DMA/PIO */
+	unsigned int		dma_irq;
+	unsigned int		port_dma_sts;
+
+	void			*dma_priv;
+	struct hsu_dma_ops	*dma_ops;
+	struct pm_qos_request   qos;
+	int			dma_inited;
+};
+
+struct hsu_port {
+	int dma_irq;
+	int port_num;
+	int irq_port_and_dma;
+	struct hsu_port_cfg	*configs[HSU_PORT_MAX];
+	void __iomem	*reg;
+	struct uart_hsu_port	port[HSU_PORT_MAX];
+	struct hsu_dma_chan	chans[HSU_PORT_MAX * 2];
+	spinlock_t		dma_lock;
+	struct dentry *debugfs;
+};
+
+#define chan_readl(chan, offset)	readl(chan->reg + offset)
+#define chan_writel(chan, offset, val)	writel(val, chan->reg + offset)
+
+#define mfd_readl(obj, offset)		readl(obj->reg + offset)
+#define mfd_writel(obj, offset, val)	writel(val, obj->reg + offset)
+
+static inline unsigned int serial_in(struct uart_hsu_port *up, int offset)
+{
+	unsigned int val;
+
+	if (offset > UART_MSR || up->hw_type == hsu_dw) {
+		offset <<= 2;
+		val = readl(up->port.membase + offset);
+	} else
+		val = (unsigned int)readb(up->port.membase + offset);
+
+	return val;
+}
+
+static inline void serial_out(struct uart_hsu_port *up, int offset, int value)
+{
+	if (offset > UART_MSR || up->hw_type == hsu_dw) {
+		offset <<= 2;
+		writel(value, up->port.membase + offset);
+	} else {
+		unsigned char val = value & 0xff;
+		writeb(val, up->port.membase + offset);
+	}
+}
+void serial_sched_cmd(struct uart_hsu_port *up, char cmd);
+extern struct hsu_dma_ops *pdw_dma_ops;
+extern struct hsu_dma_ops intel_dma_ops;
+
+struct uart_hsu_port *serial_hsu_port_setup(struct device *pdev, int port,
+	resource_size_t start, resource_size_t len, int irq);
+void serial_hsu_port_free(struct uart_hsu_port *up);
+void serial_hsu_port_shutdown(struct uart_hsu_port *up);
+int serial_hsu_dma_setup(struct device *pdev,
+	resource_size_t start, resource_size_t len, unsigned int irq, int share);
+void serial_hsu_dma_free(void);
+int serial_hsu_do_suspend(struct uart_hsu_port *up);
+int serial_hsu_do_resume(struct uart_hsu_port *up);
+int serial_hsu_do_runtime_idle(struct uart_hsu_port *up);
+
+#include "mfd_trace.h"
+#endif
diff --git a/drivers/tty/serial/mfd_core.c b/drivers/tty/serial/mfd_core.c
new file mode 100644
index 0000000..bbb318d
--- /dev/null
+++ b/drivers/tty/serial/mfd_core.c
@@ -0,0 +1,2479 @@
+/*
+ * mfd_core.c: driver core for High Speed UART device of Intel Medfield platform
+ *
+ * Refer pxa.c, 8250.c and some other drivers in drivers/serial/
+ *
+ * (C) Copyright 2010 Intel Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+/* Notes:
+ * 1. DMA channel allocation: 0/1 channel are assigned to port 0,
+ *    2/3 chan to port 1, 4/5 chan to port 3. Even number chans
+ *    are used for RX, odd chans for TX
+ *
+ * 2. The RI/DSR/DCD/DTR are not pinned out, DCD & DSR are always
+ *    asserted, only when the HW is reset the DDCD and DDSR will
+ *    be triggered
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/console.h>
+#include <linux/sysrq.h>
+#include <linux/slab.h>
+#include <linux/circ_buf.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/tty.h>
+#include <linux/tty_flip.h>
+#include <linux/dma-mapping.h>
+#include <linux/io.h>
+#include <linux/debugfs.h>
+#include <linux/pm_runtime.h>
+#include <linux/irq.h>
+#include <linux/intel_mid_pm.h>
+#include <linux/pm_qos.h>
+
+#define CREATE_TRACE_POINTS
+#include "mfd.h"
+
+static int hsu_dma_enable = 0xff;
+module_param(hsu_dma_enable, int, 0);
+MODULE_PARM_DESC(hsu_dma_enable,
+		 "It is a bitmap to set working mode, if bit[x] is 1, then port[x] will work in DMA mode, otherwise in PIO mode.");
+
+static struct hsu_port hsu;
+static struct hsu_port *phsu = &hsu;
+static struct uart_driver serial_hsu_reg;
+static struct hsu_port_cfg *hsu_port_func_cfg;
+
+static void serial_hsu_command(struct uart_hsu_port *up);
+
+int hsu_register_board_info(void *inf)
+{
+	hsu_port_func_cfg = inf;
+	return 0;
+}
+
+static inline int check_qcmd(struct uart_hsu_port *up, char *cmd)
+{
+	struct circ_buf *circ = &up->qcirc;
+	char *buf;
+
+	buf = circ->buf + circ->tail;
+	*cmd = *buf;
+	return CIRC_CNT(circ->head, circ->tail, HSU_Q_MAX);
+}
+
+static inline void insert_qcmd(struct uart_hsu_port *up, char cmd)
+{
+	struct circ_buf *circ = &up->qcirc;
+	char *buf;
+	char last_cmd;
+
+	trace_hsu_cmd_insert(up->index, cmd);
+	if (check_qcmd(up, &last_cmd) && last_cmd == cmd &&
+		cmd != qcmd_enable_irq && cmd != qcmd_port_irq &&
+                cmd != qcmd_dma_irq)
+		return;
+	trace_hsu_cmd_add(up->index, cmd);
+	up->qcmd_num++;
+	buf = circ->buf + circ->head;
+	if (CIRC_SPACE(circ->head, circ->tail, HSU_Q_MAX) < 1)
+		*buf = qcmd_overflow;
+	else {
+		*buf = cmd;
+		circ->head++;
+		if (circ->head == HSU_Q_MAX)
+			circ->head = 0;
+	}
+}
+
+static inline int get_qcmd(struct uart_hsu_port *up, char *cmd)
+{
+	struct circ_buf *circ = &up->qcirc;
+	char *buf;
+
+	if (!CIRC_CNT(circ->head, circ->tail, HSU_Q_MAX))
+		return 0;
+	buf = circ->buf + circ->tail;
+	*cmd = *buf;
+	circ->tail++;
+	if (circ->tail == HSU_Q_MAX)
+		circ->tail = 0;
+	up->qcmd_done++;
+	return 1;
+}
+
+static inline void cl_put_char(struct uart_hsu_port *up, char c)
+{
+	struct circ_buf *circ = &up->cl_circ;
+	char *buf;
+	unsigned long flags;
+
+	spin_lock_irqsave(&up->cl_lock, flags);
+	buf = circ->buf + circ->head;
+	if (CIRC_SPACE(circ->head, circ->tail, HSU_CL_BUF_LEN) > 1) {
+		*buf = c;
+		circ->head++;
+		if (circ->head == HSU_CL_BUF_LEN)
+			circ->head = 0;
+	}
+	spin_unlock_irqrestore(&up->cl_lock, flags);
+}
+
+static inline int cl_get_char(struct uart_hsu_port *up, char *c)
+{
+	struct circ_buf *circ = &up->cl_circ;
+	char *buf;
+	unsigned long flags;
+
+	spin_lock_irqsave(&up->cl_lock, flags);
+	if (!CIRC_CNT(circ->head, circ->tail, HSU_CL_BUF_LEN)) {
+		spin_unlock_irqrestore(&up->cl_lock, flags);
+		return 0;
+	}
+	buf = circ->buf + circ->tail;
+	*c = *buf;
+	circ->tail++;
+	if (circ->tail == HSU_CL_BUF_LEN)
+		circ->tail = 0;
+	spin_unlock_irqrestore(&up->cl_lock, flags);
+	return 1;
+}
+
+
+
+void serial_sched_cmd(struct uart_hsu_port *up, char cmd)
+{
+	pm_runtime_get(up->dev);
+	insert_qcmd(up, cmd);
+	if (test_bit(flag_cmd_on, &up->flags)) {
+		if (up->use_dma)
+			tasklet_schedule(&up->tasklet);
+		else
+			queue_work(up->workqueue, &up->work);
+	}
+	pm_runtime_put(up->dev);
+}
+
+static inline void serial_sched_sync(struct uart_hsu_port *up)
+{
+	mutex_lock(&up->q_mutex);
+	if (up->q_start > 0) {
+		if (up->use_dma) {
+			tasklet_disable(&up->tasklet);
+			serial_hsu_command(up);
+			tasklet_enable(&up->tasklet);
+		} else {
+			flush_workqueue(up->workqueue);
+		}
+	}
+	mutex_unlock(&up->q_mutex);
+}
+
+static inline void serial_sched_start(struct uart_hsu_port *up)
+{
+	unsigned long flags;
+
+	mutex_lock(&up->q_mutex);
+	up->q_start++;
+	if (up->q_start == 1) {
+		clear_bit(flag_cmd_off, &up->flags);
+		spin_lock_irqsave(&up->port.lock, flags);
+		set_bit(flag_cmd_on, &up->flags);
+		spin_unlock_irqrestore(&up->port.lock, flags);
+		if (up->use_dma)
+			tasklet_schedule(&up->tasklet);
+		else
+			queue_work(up->workqueue, &up->work);
+	}
+	mutex_unlock(&up->q_mutex);
+}
+
+static inline void serial_sched_stop(struct uart_hsu_port *up)
+{
+	unsigned long flags;
+
+	mutex_lock(&up->q_mutex);
+	up->q_start--;
+	if (up->q_start == 0) {
+		spin_lock_irqsave(&up->port.lock, flags);
+		clear_bit(flag_cmd_on, &up->flags);
+		insert_qcmd(up, qcmd_cmd_off);
+		spin_unlock_irqrestore(&up->port.lock, flags);
+		if (up->use_dma) {
+			tasklet_schedule(&up->tasklet);
+			while (!test_bit(flag_cmd_off, &up->flags))
+				cpu_relax();
+		} else {
+			queue_work(up->workqueue, &up->work);
+			flush_workqueue(up->workqueue);
+		}
+	}
+	mutex_unlock(&up->q_mutex);
+}
+
+static void serial_set_alt(int index)
+{
+	struct uart_hsu_port *up = phsu->port + index;
+	struct hsu_dma_chan *txc = up->txc;
+	struct hsu_dma_chan *rxc = up->rxc;
+	struct hsu_port_cfg *cfg = phsu->configs[index];
+
+	if (test_bit(flag_set_alt, &up->flags))
+		return;
+
+	trace_hsu_func_start(up->index, __func__);
+	pm_runtime_get_sync(up->dev);
+	disable_irq(up->port.irq);
+	disable_irq(up->dma_irq);
+	serial_sched_stop(up);
+	if (up->use_dma && up->hw_type == hsu_intel) {
+		txc->uport = up;
+		rxc->uport = up;
+	}
+	dev_set_drvdata(up->dev, up);
+	if (cfg->hw_set_alt)
+		cfg->hw_set_alt(index);
+	if (cfg->hw_set_rts)
+		cfg->hw_set_rts(up->index, 0);
+	set_bit(flag_set_alt, &up->flags);
+	serial_sched_start(up);
+	enable_irq(up->dma_irq);
+	enable_irq(up->port.irq);
+	pm_runtime_put(up->dev);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+static void serial_clear_alt(int index)
+{
+	struct uart_hsu_port *up = phsu->port + index;
+	struct hsu_port_cfg *cfg = phsu->configs[index];
+
+	if (!test_bit(flag_set_alt, &up->flags))
+		return;
+
+	pm_runtime_get_sync(up->dev);
+	disable_irq(up->port.irq);
+	disable_irq(up->dma_irq);
+	serial_sched_stop(up);
+	if (cfg->hw_set_rts)
+		cfg->hw_set_rts(up->index, 1);
+	clear_bit(flag_set_alt, &up->flags);
+	serial_sched_start(up);
+	enable_irq(up->dma_irq);
+	enable_irq(up->port.irq);
+	pm_runtime_put(up->dev);
+}
+
+#ifdef CONFIG_DEBUG_FS
+
+#define HSU_DBGFS_BUFSIZE	8192
+
+static int hsu_show_regs_open(struct inode *inode, struct file *file)
+{
+	file->private_data = inode->i_private;
+	return 0;
+}
+
+static ssize_t port_show_regs(struct file *file, char __user *user_buf,
+				size_t count, loff_t *ppos)
+{
+	struct uart_hsu_port *up = file->private_data;
+	char *buf;
+	u32 len = 0;
+	ssize_t ret;
+
+	buf = kzalloc(HSU_DBGFS_BUFSIZE, GFP_KERNEL);
+	if (!buf)
+		return 0;
+
+	pm_runtime_get_sync(up->dev);
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"MFD HSU port[%d] regs:\n", up->index);
+
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"=================================\n");
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"IER: \t\t0x%08x\n", serial_in(up, UART_IER));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"IIR: \t\t0x%08x\n", serial_in(up, UART_IIR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"LCR: \t\t0x%08x\n", serial_in(up, UART_LCR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"MCR: \t\t0x%08x\n", serial_in(up, UART_MCR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"LSR: \t\t0x%08x\n", serial_in(up, UART_LSR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"MSR: \t\t0x%08x\n", serial_in(up, UART_MSR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"FOR: \t\t0x%08x\n", serial_in(up, UART_FOR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"PS: \t\t0x%08x\n", serial_in(up, UART_PS));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"MUL: \t\t0x%08x\n", serial_in(up, UART_MUL));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"DIV: \t\t0x%08x\n", serial_in(up, UART_DIV));
+	pm_runtime_put(up->dev);
+
+	if (len > HSU_DBGFS_BUFSIZE)
+		len = HSU_DBGFS_BUFSIZE;
+
+	ret =  simple_read_from_buffer(user_buf, count, ppos, buf, len);
+	kfree(buf);
+	return ret;
+}
+
+static ssize_t dma_show_regs(struct file *file, char __user *user_buf,
+				size_t count, loff_t *ppos)
+{
+	struct hsu_dma_chan *chan = file->private_data;
+	char *buf;
+	u32 len = 0;
+	ssize_t ret;
+
+	buf = kzalloc(HSU_DBGFS_BUFSIZE, GFP_KERNEL);
+	if (!buf)
+		return 0;
+
+	pm_runtime_get_sync(chan->uport->dev);
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"MFD HSU DMA channel [%d] regs:\n", chan->id);
+
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"=================================\n");
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"CR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_CR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"DCR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_DCR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"BSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_BSR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"MOTSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_MOTSR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"D0SAR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D0SAR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"D0TSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D0TSR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"D0SAR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D1SAR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"D0TSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D1TSR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"D0SAR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D2SAR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"D0TSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D2TSR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"D0SAR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D3SAR));
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"D0TSR: \t\t0x%08x\n", chan_readl(chan, HSU_CH_D3TSR));
+	pm_runtime_put(chan->uport->dev);
+
+	if (len > HSU_DBGFS_BUFSIZE)
+		len = HSU_DBGFS_BUFSIZE;
+
+	ret =  simple_read_from_buffer(user_buf, count, ppos, buf, len);
+	kfree(buf);
+	return ret;
+}
+
+static ssize_t hsu_dump_show(struct file *file, char __user *user_buf,
+				size_t count, loff_t *ppos)
+{
+	struct uart_hsu_port *up;
+	struct hsu_port_cfg *cfg;
+	char *buf;
+	char cmd;
+	int i;
+	u32 len = 0;
+	ssize_t ret;
+	struct irq_desc *dma_irqdesc = irq_to_desc(phsu->dma_irq);
+	struct irq_desc *port_irqdesc;
+	struct circ_buf *xmit;
+
+	buf = kzalloc(HSU_DBGFS_BUFSIZE, GFP_KERNEL);
+	if (!buf)
+		return 0;
+
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+		"HSU status dump:\n");
+	len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+		"\tdma irq (>0: disable): %d\n",
+		dma_irqdesc ? dma_irqdesc->depth : 0);
+	for (i = 0; i < phsu->port_num; i++) {
+		up = phsu->port + i;
+		cfg = hsu_port_func_cfg + i;
+		port_irqdesc = irq_to_desc(up->port.irq);
+		xmit = &up->port.state->xmit;
+
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"HSU port[%d] %s:\n", up->index, cfg->name);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"xmit empty[%d] xmit pending[%d]\n",
+			uart_circ_empty(xmit),
+			(int)uart_circ_chars_pending(xmit));
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tsuspend idle: %d\n", cfg->idle);
+		if (cfg->has_alt)
+			len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+				"\talt port: %d\n", cfg->alt);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+				"\tforce_suspend: %d\n", cfg->force_suspend);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+				"\tcts status: %d\n", up->cts_status);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tuse_dma: %s\n",
+			up->use_dma ? "yes" : "no");
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tflag_console: %s\n",
+			test_bit(flag_console, &up->flags) ? "yes" : "no");
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tflag_suspend: %s\n",
+			test_bit(flag_suspend, &up->flags) ? "yes" : "no");
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tflag_active: %s\n",
+			test_bit(flag_active, &up->flags) ? "yes" : "no");
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tflag_set_alt: %s\n",
+			test_bit(flag_set_alt, &up->flags) ? "yes" : "no");
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tflag_startup: %s\n",
+			test_bit(flag_startup, &up->flags) ? "yes" : "no");
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tqcmd q_start: %d\n", up->q_start);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tqcmd total count: %d\n", up->qcmd_num);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tqcmd done count: %d\n", up->qcmd_done);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq count: %d\n", up->port_irq_num);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq cmddone: %d\n", up->port_irq_cmddone);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq cts: %d\n", up->port.icount.cts);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq rng: %d\n", up->port.icount.rng);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq dsr: %d\n", up->port.icount.dsr);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq no irq pending: %d\n",
+			up->port_irq_pio_no_irq_pend);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq no alt: %d\n",
+			up->port_irq_no_alt);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq no startup: %d\n",
+			up->port_irq_no_startup);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq pio rx error: %d\n",
+			up->port_irq_pio_rx_err);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq pio rx available: %d\n",
+			up->port_irq_pio_rx_avb);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq pio rx fifo timeout: %d\n",
+			up->port_irq_pio_rx_timeout);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq pio tx request: %d\n",
+			up->port_irq_pio_tx_req);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tdma invalid irq count: %d\n",
+			up->dma_invalid_irq_num);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tdma irq count: %d\n", up->dma_irq_num);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tdma irq cmddone: %d\n", up->dma_irq_cmddone);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tdma tx irq cmddone: %d\n",
+			up->dma_tx_irq_cmddone);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport&dma rx irq cmddone: %d\n",
+			up->dma_rx_irq_cmddone);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport&dma rx timeout irq cmddone: %d\n",
+			up->dma_rx_tmt_irq_cmddone);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\ttasklet done: %d\n", up->tasklet_done);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tworkq done: %d\n", up->workq_done);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tqcmd pending count: %d\n", check_qcmd(up, &cmd));
+		if (check_qcmd(up, &cmd))
+			len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+				"\tqcmd pending next: %d\n", cmd);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tin tasklet: %d\n", up->in_tasklet);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tin workq: %d\n", up->in_workq);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tport irq (>0: disable): %d\n",
+			port_irqdesc ? port_irqdesc->depth : 0);
+		len += snprintf(buf + len, HSU_DBGFS_BUFSIZE - len,
+			"\tbyte delay: %d\n", up->byte_delay);
+	}
+	if (len > HSU_DBGFS_BUFSIZE)
+		len = HSU_DBGFS_BUFSIZE;
+
+	ret =  simple_read_from_buffer(user_buf, count, ppos, buf, len);
+	kfree(buf);
+	return ret;
+}
+
+
+static const struct file_operations port_regs_ops = {
+	.owner		= THIS_MODULE,
+	.open		= hsu_show_regs_open,
+	.read		= port_show_regs,
+	.llseek		= default_llseek,
+};
+
+static const struct file_operations dma_regs_ops = {
+	.owner		= THIS_MODULE,
+	.open		= hsu_show_regs_open,
+	.read		= dma_show_regs,
+	.llseek		= default_llseek,
+};
+
+static const struct file_operations hsu_dump_ops = {
+	.owner		= THIS_MODULE,
+	.read		= hsu_dump_show,
+	.llseek		= default_llseek,
+};
+
+static int hsu_debugfs_init(struct hsu_port *hsu)
+{
+	int i;
+	char name[32];
+
+	hsu->debugfs = debugfs_create_dir("hsu", NULL);
+	if (!hsu->debugfs)
+		return -ENOMEM;
+
+	for (i = 0; i < 3; i++) {
+		snprintf(name, sizeof(name), "port_%d_regs", i);
+		debugfs_create_file(name, S_IFREG | S_IRUGO,
+			hsu->debugfs, (void *)(&hsu->port[i]), &port_regs_ops);
+	}
+
+	for (i = 0; i < 6; i++) {
+		snprintf(name, sizeof(name), "dma_chan_%d_regs", i);
+		debugfs_create_file(name, S_IFREG | S_IRUGO,
+			hsu->debugfs, (void *)&hsu->chans[i], &dma_regs_ops);
+	}
+
+	snprintf(name, sizeof(name), "dump_status");
+	debugfs_create_file(name, S_IFREG | S_IRUGO,
+		hsu->debugfs, NULL, &hsu_dump_ops);
+
+	return 0;
+}
+
+static void hsu_debugfs_remove(struct hsu_port *hsu)
+{
+	if (hsu->debugfs)
+		debugfs_remove_recursive(hsu->debugfs);
+}
+
+#else
+static inline int hsu_debugfs_init(struct hsu_port *hsu)
+{
+	return 0;
+}
+
+static inline void hsu_debugfs_remove(struct hsu_port *hsu)
+{
+}
+#endif /* CONFIG_DEBUG_FS */
+
+static void serial_hsu_enable_ms(struct uart_port *port)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+
+	trace_hsu_func_start(up->index, __func__);
+	up->ier |= UART_IER_MSI;
+	serial_sched_cmd(up, qcmd_set_ier);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+/* Protected by spin_lock_irqsave(port->lock) */
+static void serial_hsu_start_tx(struct uart_port *port)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+
+	trace_hsu_func_start(up->index, __func__);
+	serial_sched_cmd(up, qcmd_start_tx);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+static void serial_hsu_stop_tx(struct uart_port *port)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+
+	trace_hsu_func_start(up->index, __func__);
+	serial_sched_cmd(up, qcmd_stop_tx);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+static void hsu_stop_tx(struct uart_port *port)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+
+	trace_hsu_func_start(up->index, __func__);
+	serial_sched_cmd(up, qcmd_stop_tx);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+/* This is always called in spinlock protected mode, so
+ * modify timeout timer is safe here */
+void intel_dma_do_rx(struct uart_hsu_port *up, u32 int_sts)
+{
+	struct hsu_dma_buffer *dbuf = &up->rxbuf;
+	struct hsu_dma_chan *chan = up->rxc;
+	struct uart_port *port = &up->port;
+	struct tty_struct *tty;
+	struct tty_port *tport = &port->state->port;
+	int count;
+
+	trace_hsu_func_start(up->index, __func__);
+	tty = tty_port_tty_get(&up->port.state->port);
+	if (!tty) {
+		trace_hsu_func_end(up->index, __func__, "notty");
+		return;
+	}
+
+	/*
+	 * First need to know how many is already transferred,
+	 * then check if its a timeout DMA irq, and return
+	 * the trail bytes out, push them up and reenable the
+	 * channel
+	 */
+
+	/* Timeout IRQ, need wait some time, see Errata 2 */
+	if (int_sts & 0xf00) {
+		up->dma_rx_tmt_irq_cmddone++;
+		udelay(2);
+	} else
+		up->dma_rx_irq_cmddone++;
+
+	/* Stop the channel */
+	chan_writel(chan, HSU_CH_CR, 0x0);
+
+	count = chan_readl(chan, HSU_CH_D0SAR) - dbuf->dma_addr;
+	if (!count) {
+		/* Restart the channel before we leave */
+		chan_writel(chan, HSU_CH_CR, 0x3);
+		tty_kref_put(tty);
+		trace_hsu_func_end(up->index, __func__, "nodata");
+		return;
+	}
+
+	dma_sync_single_for_cpu(port->dev, dbuf->dma_addr,
+			dbuf->dma_size, DMA_FROM_DEVICE);
+
+	/*
+	 * Head will only wrap around when we recycle
+	 * the DMA buffer, and when that happens, we
+	 * explicitly set tail to 0. So head will
+	 * always be greater than tail.
+	 */
+	tty_insert_flip_string(tport, dbuf->buf, count);
+	port->icount.rx += count;
+
+	dma_sync_single_for_device(up->port.dev, dbuf->dma_addr,
+			dbuf->dma_size, DMA_FROM_DEVICE);
+
+	/* Reprogram the channel */
+	chan_writel(chan, HSU_CH_D0SAR, dbuf->dma_addr);
+	chan_writel(chan, HSU_CH_D0TSR, dbuf->dma_size);
+	chan_writel(chan, HSU_CH_DCR, 0x1
+					 | (0x1 << 8)
+					 | (0x1 << 16)
+					 | (0x1 << 24)	/* timeout bit, see HSU Errata 1 */
+					 );
+	tty_flip_buffer_push(tport);
+
+	chan_writel(chan, HSU_CH_CR, 0x3);
+	tty_kref_put(tty);
+	trace_hsu_func_end(up->index, __func__, "");
+
+}
+
+static void serial_hsu_stop_rx(struct uart_port *port)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+
+	trace_hsu_func_start(up->index, __func__);
+	serial_sched_cmd(up, qcmd_stop_rx);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+static inline void receive_chars(struct uart_hsu_port *up, int *status)
+{
+	struct tty_struct *tty = up->port.state->port.tty;
+	struct tty_port *tport = &up->port.state->port;
+	unsigned int ch, flag;
+	unsigned int max_count = 256;
+
+	if (!tty)
+		return;
+
+	trace_hsu_func_start(up->index, __func__);
+	do {
+		ch = serial_in(up, UART_RX);
+		flag = TTY_NORMAL;
+		up->port.icount.rx++;
+
+		if (unlikely(*status & (UART_LSR_BI | UART_LSR_PE |
+				       UART_LSR_FE | UART_LSR_OE))) {
+
+			dev_warn(up->dev,
+				"We really rush into ERR/BI case"
+				"status = 0x%02x\n", *status);
+			/* For statistics only */
+			if (*status & UART_LSR_BI) {
+				*status &= ~(UART_LSR_FE | UART_LSR_PE);
+				up->port.icount.brk++;
+				/*
+				 * We do the SysRQ and SAK checking
+				 * here because otherwise the break
+				 * may get masked by ignore_status_mask
+				 * or read_status_mask.
+				 */
+				if (uart_handle_break(&up->port))
+					goto ignore_char;
+			} else if (*status & UART_LSR_PE)
+				up->port.icount.parity++;
+			else if (*status & UART_LSR_FE)
+				up->port.icount.frame++;
+			if (*status & UART_LSR_OE)
+				up->port.icount.overrun++;
+
+			/* Mask off conditions which should be ignored. */
+			*status &= up->port.read_status_mask;
+
+#ifdef CONFIG_SERIAL_MFD_HSU_CONSOLE
+			if (up->port.cons &&
+				up->port.cons->index == up->port.line) {
+				/* Recover the break flag from console xmit */
+				*status |= up->lsr_break_flag;
+				up->lsr_break_flag = 0;
+			}
+#endif
+			if (*status & UART_LSR_BI) {
+				flag = TTY_BREAK;
+			} else if (*status & UART_LSR_PE)
+				flag = TTY_PARITY;
+			else if (*status & UART_LSR_FE)
+				flag = TTY_FRAME;
+		}
+
+		if (uart_handle_sysrq_char(&up->port, ch))
+			goto ignore_char;
+
+		uart_insert_char(&up->port, *status, UART_LSR_OE, ch, flag);
+	ignore_char:
+		*status = serial_in(up, UART_LSR);
+	} while ((*status & UART_LSR_DR) && max_count--);
+
+	tty_flip_buffer_push(tport);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+static void transmit_chars(struct uart_hsu_port *up)
+{
+	struct circ_buf *xmit = &up->port.state->xmit;
+	unsigned long flags;
+	int count;
+
+	spin_lock_irqsave(&up->port.lock, flags);
+	trace_hsu_func_start(up->index, __func__);
+	if (up->port.x_char) {
+		serial_out(up, UART_TX, up->port.x_char);
+		up->port.icount.tx++;
+		up->port.x_char = 0;
+		trace_hsu_func_end(up->index, __func__, "x_char");
+		goto out;
+	}
+	if (uart_circ_empty(xmit) || uart_tx_stopped(&up->port)) {
+		hsu_stop_tx(&up->port);
+		if (uart_circ_empty(xmit))
+			trace_hsu_func_end(up->index, __func__, "empty");
+		else
+			trace_hsu_func_end(up->index, __func__, "stop");
+		goto out;
+	}
+
+	/* The IRQ is for TX FIFO half-empty */
+	count = up->port.fifosize / 2;
+
+	do {
+		if (uart_tx_stopped(&up->port)) {
+			hsu_stop_tx(&up->port);
+			break;
+		}
+		serial_out(up, UART_TX, xmit->buf[xmit->tail]);
+		xmit->tail = (xmit->tail + 1) & (UART_XMIT_SIZE - 1);
+
+		up->port.icount.tx++;
+		if (uart_circ_empty(xmit))
+			break;
+	} while (--count > 0);
+
+	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
+		uart_write_wakeup(&up->port);
+
+	if (uart_circ_empty(xmit)) {
+		hsu_stop_tx(&up->port);
+		trace_hsu_func_end(up->index, __func__, "tx_complete");
+	}
+	else
+		trace_hsu_func_end(up->index, __func__, "");
+
+out:
+	spin_unlock_irqrestore(&up->port.lock, flags);
+}
+
+static void check_modem_status(struct uart_hsu_port *up)
+{
+	struct uart_port *uport = &up->port;
+	struct tty_port *port = &uport->state->port;
+	struct tty_struct *tty = port->tty;
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+	int status;
+	int delta_msr = 0;
+
+	trace_hsu_func_start(up->index, __func__);
+	status = serial_in(up, UART_MSR);
+	trace_hsu_mctrl(up->index, status);
+	if (port->flags & ASYNC_CTS_FLOW && !cfg->hw_ctrl_cts) {
+		if (tty->hw_stopped) {
+			if (status & UART_MSR_CTS) {
+				serial_sched_cmd(up, qcmd_start_tx);
+				tty->hw_stopped = 0;
+				up->cts_status = 0;
+				uport->icount.cts++;
+				delta_msr = 1;
+				uart_write_wakeup(uport);
+			}
+		} else {
+			if (!(status & UART_MSR_CTS)) {
+				/* Is this automitically controlled */
+				if (up->use_dma)
+					up->dma_ops->stop_tx(up);
+				clear_bit(flag_tx_on, &up->flags);
+				tty->hw_stopped = 1;
+				up->cts_status = 1;
+				delta_msr = 1;
+				uport->icount.cts++;
+			}
+		}
+	}
+
+	if ((status & UART_MSR_ANY_DELTA)) {
+		if (status & UART_MSR_TERI)
+			up->port.icount.rng++;
+		if (status & UART_MSR_DDSR)
+			up->port.icount.dsr++;
+		/* We may only get DDCD when HW init and reset */
+		if (status & UART_MSR_DDCD)
+			uart_handle_dcd_change(&up->port,
+					status & UART_MSR_DCD);
+		delta_msr = 1;
+	}
+
+	if (delta_msr)
+		wake_up_interruptible(&up->port.state->port.delta_msr_wait);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+static void hsu_dma_chan_handler(struct hsu_port *hsu, int index)
+{
+	unsigned long flags;
+	struct uart_hsu_port *up = hsu->chans[index * 2].uport;
+	struct hsu_dma_chan *txc = up->txc;
+	struct hsu_dma_chan *rxc = up->rxc;
+
+	up->dma_irq_num++;
+	if (unlikely(!up->use_dma
+		|| !test_bit(flag_startup, &up->flags))) {
+		up->dma_invalid_irq_num++;
+		chan_readl(txc, HSU_CH_SR);
+		chan_readl(rxc, HSU_CH_SR);
+		return;
+	}
+	disable_irq_nosync(up->dma_irq);
+	spin_lock_irqsave(&up->port.lock, flags);
+	serial_sched_cmd(up, qcmd_dma_irq);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+}
+
+/*
+ * This handles the interrupt from one port.
+ */
+static irqreturn_t hsu_port_irq(int irq, void *dev_id)
+{
+	struct uart_hsu_port *up = dev_id;
+	unsigned long flags;
+	u8 lsr;
+
+	trace_hsu_func_start(up->index, __func__);
+	up->port_irq_num++;
+
+	if (up->hw_type == hsu_intel) {
+		if (unlikely(!test_bit(flag_set_alt, &up->flags))) {
+			up->port_irq_no_alt++;
+			trace_hsu_func_end(up->index, __func__, "noalt");
+			return IRQ_NONE;
+		}
+	} else {
+		if (unlikely(test_bit(flag_suspend, &up->flags))) {
+			trace_hsu_func_end(up->index, __func__, "suspend");
+			return IRQ_NONE;
+		}
+
+		/* On BYT, this IRQ may be shared with other HW */
+		up->iir = serial_in(up, UART_IIR);
+		if (unlikely(up->iir & 0x1)) {
+			/*
+			 * Read  UART_BYTE_COUNT and UART_OVERFLOW
+			 * registers to clear the overrun error on
+			 * Tx. This is a HW issue on VLV2 B0.
+			 * more information on HSD 4683358.
+			 */
+			serial_in(up, 0x818 / 4);
+			serial_in(up, 0x820 / 4);
+			trace_hsu_func_end(up->index, __func__, "workaround");
+			return IRQ_NONE;
+		}
+	}
+
+	if (unlikely(!test_bit(flag_startup, &up->flags))) {
+		pr_err("recv IRQ when we are not startup yet\n");
+		/*SCU might forward it too late when it is closed already*/
+		serial_in(up, UART_LSR);
+		up->port_irq_no_startup++;
+		trace_hsu_func_end(up->index, __func__, "nostart");
+		return IRQ_HANDLED;
+	}
+
+	/* DesignWare HW's DMA mode still needs the port irq */
+	if (up->use_dma && up->hw_type == hsu_intel) {
+		lsr = serial_in(up, UART_LSR);
+		spin_lock_irqsave(&up->port.lock, flags);
+		check_modem_status(up);
+		spin_unlock_irqrestore(&up->port.lock, flags);
+		if (unlikely(lsr & (UART_LSR_BI | UART_LSR_PE |
+				UART_LSR_FE | UART_LSR_OE)))
+			dev_warn(up->dev,
+				"Got LSR irq(0x%02x) while using DMA", lsr);
+		trace_hsu_func_end(up->index, __func__, "lsr");
+		return IRQ_HANDLED;
+	}
+
+	disable_irq_nosync(up->port.irq);
+	spin_lock_irqsave(&up->port.lock, flags);
+	serial_sched_cmd(up, qcmd_port_irq);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+
+	trace_hsu_func_end(up->index, __func__, "");
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t hsu_dma_irq(int irq, void *dev_id)
+{
+	struct uart_hsu_port *up;
+	unsigned long flags;
+	unsigned int dmairq;
+	int i;
+
+	spin_lock_irqsave(&phsu->dma_lock, flags);
+	dmairq = mfd_readl(phsu, HSU_GBL_DMAISR);
+	if (phsu->irq_port_and_dma) {
+		up = dev_id;
+		up->port_dma_sts = dmairq;
+		if (up->port_dma_sts & (3 << (up->index * 2)))
+			hsu_dma_chan_handler(phsu, up->index);
+	} else {
+		for (i = 0; i < 3; i++)
+			if (dmairq & (3 << (i * 2))) {
+				up = phsu->chans[i * 2].uport;
+				up->port_dma_sts = dmairq;
+				hsu_dma_chan_handler(phsu, i);
+			}
+	}
+	spin_unlock_irqrestore(&phsu->dma_lock, flags);
+
+	return IRQ_HANDLED;
+}
+
+static unsigned int serial_hsu_tx_empty(struct uart_port *port)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+	int ret = 1;
+
+	trace_hsu_func_start(up->index, __func__);
+	pm_runtime_get_sync(up->dev);
+	serial_sched_stop(up);
+
+	if (up->use_dma && test_bit(flag_tx_on, &up->flags))
+		ret = 0;
+	ret = ret &&
+		(serial_in(up, UART_LSR) & UART_LSR_TEMT ? TIOCSER_TEMT : 0);
+	serial_sched_start(up);
+	pm_runtime_put(up->dev);
+	trace_hsu_func_end(up->index, __func__, "");
+	return ret;
+}
+
+static unsigned int serial_hsu_get_mctrl(struct uart_port *port)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+	unsigned char status = up->msr;
+	unsigned int ret = 0;
+
+	trace_hsu_func_start(up->index, __func__);
+	if (status & UART_MSR_DCD)
+		ret |= TIOCM_CAR;
+	if (status & UART_MSR_RI)
+		ret |= TIOCM_RNG;
+	if (status & UART_MSR_DSR)
+		ret |= TIOCM_DSR;
+	if (status & UART_MSR_CTS)
+		ret |= TIOCM_CTS;
+	trace_hsu_func_end(up->index, __func__, "");
+	return ret;
+}
+
+static void set_mctrl(struct uart_hsu_port *up, unsigned int mctrl)
+{
+	trace_hsu_func_start(up->index, __func__);
+	if (mctrl & TIOCM_RTS)
+		up->mcr |= UART_MCR_RTS;
+	if (mctrl & TIOCM_DTR)
+		up->mcr |= UART_MCR_DTR;
+	if (mctrl & TIOCM_OUT1)
+		up->mcr |= UART_MCR_OUT1;
+	if (mctrl & TIOCM_OUT2)
+		up->mcr |= UART_MCR_OUT2;
+	if (mctrl & TIOCM_LOOP)
+		up->mcr |= UART_MCR_LOOP;
+	trace_hsu_mctrl(up->index, mctrl);
+	serial_out(up, UART_MCR, up->mcr);
+	udelay(100);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+static void serial_hsu_set_mctrl(struct uart_port *port, unsigned int mctrl)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+
+	trace_hsu_func_start(up->index, __func__);
+	if (mctrl & TIOCM_RTS)
+		up->mcr |= UART_MCR_RTS;
+	if (mctrl & TIOCM_DTR)
+		up->mcr |= UART_MCR_DTR;
+	if (mctrl & TIOCM_OUT1)
+		up->mcr |= UART_MCR_OUT1;
+	if (mctrl & TIOCM_OUT2)
+		up->mcr |= UART_MCR_OUT2;
+	if (mctrl & TIOCM_LOOP)
+		up->mcr |= UART_MCR_LOOP;
+	serial_sched_cmd(up, qcmd_set_mcr);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+static void serial_hsu_break_ctl(struct uart_port *port, int break_state)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+
+	trace_hsu_func_start(up->index, __func__);
+	pm_runtime_get_sync(up->dev);
+	serial_sched_stop(up);
+	if (break_state == -1)
+		up->lcr |= UART_LCR_SBC;
+	else
+		up->lcr &= ~UART_LCR_SBC;
+	serial_out(up, UART_LCR, up->lcr);
+	serial_sched_start(up);
+	pm_runtime_put(up->dev);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+/*
+ * What special to do:
+ * 1. chose the 64B fifo mode
+ * 2. start dma or pio depends on configuration
+ * 3. we only allocate dma memory when needed
+ */
+static int serial_hsu_startup(struct uart_port *port)
+{
+	static int console_first_init = 1;
+	int ret = 0;
+	unsigned long flags;
+	static DEFINE_MUTEX(lock);
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+
+	trace_hsu_func_start(up->index, __func__);
+	mutex_lock(&lock);
+
+	pm_runtime_get_sync(up->dev);
+
+	/* HW start it */
+	if (cfg->hw_reset)
+		cfg->hw_reset(up->port.membase);
+
+	if (console_first_init && test_bit(flag_console, &up->flags)) {
+		serial_sched_stop(up);
+		console_first_init = 0;
+	}
+	clear_bit(flag_reopen, &up->flags);
+	if (cfg->has_alt) {
+		struct hsu_port_cfg *alt_cfg = hsu_port_func_cfg + cfg->alt;
+		struct uart_hsu_port *alt_up = phsu->port + alt_cfg->index;
+
+		if (test_bit(flag_startup, &alt_up->flags) &&
+			alt_up->port.state->port.tty) {
+			if (alt_cfg->force_suspend) {
+				uart_suspend_port(&serial_hsu_reg,
+							&alt_up->port);
+				serial_clear_alt(alt_up->index);
+				set_bit(flag_reopen, &alt_up->flags);
+			} else {
+				int loop = 50;
+
+				while (test_bit(flag_startup,
+						&alt_up->flags) && --loop)
+					msleep(20);
+				if (test_bit(flag_startup, &alt_up->flags)) {
+					WARN(1, "Share port open timeout\n");
+					ret = -EBUSY;
+					goto out;
+				}
+			}
+		}
+	}
+	serial_set_alt(up->index);
+	serial_sched_start(up);
+	serial_sched_stop(up);
+
+	/*
+	 * Clear the FIFO buffers and disable them.
+	 * (they will be reenabled in set_termios())
+	 */
+	serial_out(up, UART_FCR, UART_FCR_ENABLE_FIFO);
+	serial_out(up, UART_FCR, UART_FCR_ENABLE_FIFO |
+			UART_FCR_CLEAR_RCVR |
+			UART_FCR_CLEAR_XMIT);
+	serial_out(up, UART_FCR, 0);
+
+	/* Clear the interrupt registers. */
+	(void) serial_in(up, UART_LSR);
+	(void) serial_in(up, UART_RX);
+	(void) serial_in(up, UART_IIR);
+	(void) serial_in(up, UART_MSR);
+
+	/* Now, initialize the UART, default is 8n1 */
+	serial_out(up, UART_LCR, UART_LCR_WLEN8);
+	up->port.mctrl |= TIOCM_OUT2;
+	set_mctrl(up, up->port.mctrl);
+
+	/* DMA init */
+	if (up->use_dma) {
+		ret = up->dma_ops->init ? up->dma_ops->init(up) : -ENODEV;
+		if (ret) {
+			dev_warn(up->dev, "Fail to init DMA, will use PIO\n");
+			up->use_dma = 0;
+		}
+	}
+
+	/*
+	 * Finally, enable interrupts.  Note: Modem status
+	 * interrupts are set via set_termios(), which will
+	 *  be occurring imminently
+	 * anyway, so we don't enable them here.
+	 */
+	/* bit 4 for DW is reserved, but SEG need it to be set */
+	if (!up->use_dma || up->hw_type == hsu_dw)
+		up->ier = UART_IER_RLSI | UART_IER_RDI | UART_IER_RTOIE;
+	else
+		up->ier = 0;
+	serial_out(up, UART_IER, up->ier);
+
+	/* And clear the interrupt registers again for luck. */
+	(void) serial_in(up, UART_LSR);
+	(void) serial_in(up, UART_RX);
+	(void) serial_in(up, UART_IIR);
+	(void) serial_in(up, UART_MSR);
+
+	set_bit(flag_startup, &up->flags);
+	serial_sched_start(up);
+	spin_lock_irqsave(&up->port.lock, flags);
+	serial_sched_cmd(up, qcmd_get_msr);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+	serial_sched_sync(up);
+
+out:
+	pm_runtime_put(up->dev);
+	mutex_unlock(&lock);
+	trace_hsu_func_end(up->index, __func__, "");
+	return ret;
+}
+
+static void serial_hsu_shutdown(struct uart_port *port)
+{
+	static DEFINE_MUTEX(lock);
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+
+	trace_hsu_func_start(up->index, __func__);
+	mutex_lock(&lock);
+	pm_runtime_get_sync(up->dev);
+	serial_sched_stop(up);
+	clear_bit(flag_startup, &up->flags);
+
+	/* Disable interrupts from this port */
+	up->ier = 0;
+	serial_out(up, UART_IER, 0);
+
+	clear_bit(flag_tx_on, &up->flags);
+
+	up->port.mctrl &= ~TIOCM_OUT2;
+	set_mctrl(up, up->port.mctrl);
+
+	/* Disable break condition and FIFOs */
+	serial_out(up, UART_LCR,
+			serial_in(up, UART_LCR) & ~UART_LCR_SBC);
+	serial_out(up, UART_FCR, UART_FCR_ENABLE_FIFO |
+			UART_FCR_CLEAR_RCVR |
+			UART_FCR_CLEAR_XMIT);
+	serial_out(up, UART_FCR, 0);
+
+	/* Free allocated dma buffer */
+	if (up->use_dma)
+		up->dma_ops->exit(up);
+
+	if (cfg->has_alt) {
+		struct hsu_port_cfg *alt_cfg = hsu_port_func_cfg + cfg->alt;
+		struct uart_hsu_port *alt_up = phsu->port + alt_cfg->index;
+
+		if (test_bit(flag_reopen, &alt_up->flags)) {
+			serial_clear_alt(up->index);
+			uart_resume_port(&serial_hsu_reg, &alt_up->port);
+		}
+	}
+
+	pm_runtime_put_sync(up->dev);
+	mutex_unlock(&lock);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+/* calculate mul,div for low fref e.g. TNG B0 38.4M
+ * finally the fref will swith to high fref e.g. 100M
+*/
+static bool calc_for_low_fref(u32 clock, u32 baud, u32 *mul, u32 *div)
+{
+	if (clock == 38400) {
+		switch (baud) {
+		case 3500000:
+			/* ps: 10 */
+			*mul = 350;
+			*div = 384;
+			break;
+		case 3000000:
+			/* ps: 12 */
+			*mul = 360;
+			*div = 384;
+			break;
+		case 2500000:
+			/* ps: 12 */
+			*mul = 300;
+			*div = 384;
+			break;
+		case 2000000:
+			/* ps: 16 */
+			*mul = 320;
+			*div = 384;
+			break;
+		case 1843200:
+			/* ps: 16 */
+			*mul = 294912;
+			*div = 384000;
+			break;
+		case 1500000:
+			/* ps: 16 */
+			*mul = 240;
+			*div = 384;
+			break;
+		case 1000000:
+			/* ps: 16 */
+			*mul = 160;
+			*div = 384;
+			break;
+		case 500000:
+			/* ps: 16 */
+			*mul = 80;
+			*div = 384;
+			break;
+		}
+		return true;
+	} else
+		return false;
+}
+
+static void
+serial_hsu_set_termios(struct uart_port *port, struct ktermios *termios,
+		       struct ktermios *old)
+{
+	struct uart_hsu_port *up =
+			container_of(port, struct uart_hsu_port, port);
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+	unsigned char cval, fcr = 0;
+	unsigned long flags;
+	unsigned int baud, quot, clock, bits;
+	/* 0x3d09 is default dividor value refer for deatils
+	 * please refer high speed UART HAS documents.
+	 */
+	u32 ps = 0, mul = 0, div = 0x3D09, m = 0, n = 0;
+
+	trace_hsu_func_start(up->index, __func__);
+	switch (termios->c_cflag & CSIZE) {
+	case CS5:
+		cval = UART_LCR_WLEN5;
+		bits = 7;
+		break;
+	case CS6:
+		cval = UART_LCR_WLEN6;
+		bits = 8;
+		break;
+	case CS7:
+		cval = UART_LCR_WLEN7;
+		bits = 9;
+		break;
+	default:
+	case CS8:
+		cval = UART_LCR_WLEN8;
+		bits = 10;
+		break;
+	}
+
+	/* CMSPAR isn't supported by this driver */
+	termios->c_cflag &= ~CMSPAR;
+
+	if (termios->c_cflag & CSTOPB) {
+		cval |= UART_LCR_STOP;
+		bits++;
+	}
+	if (termios->c_cflag & PARENB) {
+		cval |= UART_LCR_PARITY;
+		bits++;
+	}
+	if (!(termios->c_cflag & PARODD))
+		cval |= UART_LCR_EPAR;
+
+	baud = uart_get_baud_rate(port, termios, old, 0, 4000000);
+	trace_hsu_set_termios(up->index, baud, termios->c_cflag & CRTSCTS ? 1 : 0);
+
+	if (up->hw_type == hsu_intel) {
+		/*
+		 * If base clk is 50Mhz, and the baud rate come from:
+		 *	baud = 50M * MUL / (DIV * PS * DLAB)
+		 *
+		 * For those basic low baud rate we can get the direct
+		 * scalar from 2746800, like 115200 = 2746800/24. For those
+		 * higher baud rate, we handle them case by case, mainly by
+		 * adjusting the MUL/PS registers, and DIV register is kept
+		 * as default value 0x3d09 to make things simple
+		 */
+
+		if (cfg->hw_get_clk)
+			clock = cfg->hw_get_clk();
+		else
+			clock = 50000;
+		/* ps = 16 is prefered, if not have to use 12, l0 */
+		if (baud * 16 <= clock * 1000)
+			ps = 16;
+		else if (baud * 12 <= clock * 1000)
+			ps = 12;
+		else if (baud * 10 <= clock * 1000)
+			ps = 10;
+		else
+			pr_err("port:%d baud:%d is too high for clock:%u M\n",
+				up->index, baud, clock / 1000);
+
+		switch (baud) {
+		case 3500000:
+		case 3000000:
+		case 2500000:
+		case 2000000:
+		case 1843200:
+		case 1500000:
+		case 1000000:
+		case 500000:
+			quot = 1;
+			if (!calc_for_low_fref(clock, baud, &mul, &div))
+				/*
+				 * mul = baud * 0x3d09 * ps / 1000 / clock
+				 * change the formula order to avoid overflow
+				 */
+				mul = (0x3d09 * ps / 100) * (baud / 100)
+					* 10 / clock;
+			break;
+		default:
+			/* Use uart_get_divisor to get quot for other baud rates
+			 * avoid overflow: mul = uartclk * 0x3d09 / clock / 1000
+			 * uartclk is multiply of 115200 * n * 16 */
+			mul = (up->port.uartclk / 1600) * 0x3d09 /
+				clock * 16 / 10;
+			quot = 0;
+		}
+
+		if (!quot)
+			quot = uart_get_divisor(port, baud);
+
+		if ((up->port.uartclk / quot) < (2400 * 16))
+			fcr = UART_FCR_ENABLE_FIFO | UART_FCR_HSU_64_1B;
+		else if ((up->port.uartclk / quot) < (230400 * 16))
+			fcr = UART_FCR_ENABLE_FIFO | UART_FCR_HSU_64_16B;
+		else
+			fcr = UART_FCR_ENABLE_FIFO | UART_FCR_HSU_64_32B;
+
+		fcr |= UART_FCR_HSU_64B_FIFO;
+	} else {
+		/* need calc quot here */
+		switch (baud) {
+		case 3000000:
+		case 1500000:
+		case 1000000:
+		case 500000:
+			m = 48;
+			n = 100;
+			quot = 3000000 / baud;
+			break;
+		default:
+			m = 9216;
+			n = 15625;
+			quot = 0;
+		}
+		if (!quot)
+			quot = uart_get_divisor(port, baud);
+
+		fcr = UART_FCR_ENABLE_FIFO | UART_FCR_R_TRIG_10 |
+			UART_FCR_T_TRIG_11;
+		if (baud < 2400) {
+			fcr &= ~UART_FCR_TRIGGER_MASK;
+			fcr |= UART_FCR_TRIGGER_1;
+		}
+	}
+
+	/* one byte transfer duration unit microsecond */
+	up->byte_delay = (bits * 1000000 + baud - 1) / baud;
+
+	pm_runtime_get_sync(up->dev);
+	serial_sched_stop(up);
+	/*
+	 * Ok, we're now changing the port state.  Do it with
+	 * interrupts disabled.
+	 */
+	spin_lock_irqsave(&up->port.lock, flags);
+
+	/* Update the per-port timeout */
+	uart_update_timeout(port, termios->c_cflag, baud);
+
+	up->port.read_status_mask = UART_LSR_OE | UART_LSR_THRE | UART_LSR_DR;
+	if (termios->c_iflag & INPCK)
+		up->port.read_status_mask |= UART_LSR_FE | UART_LSR_PE;
+	if (termios->c_iflag & (BRKINT | PARMRK))
+		up->port.read_status_mask |= UART_LSR_BI;
+
+	/* Characters to ignore */
+	up->port.ignore_status_mask = 0;
+	if (termios->c_iflag & IGNPAR)
+		up->port.ignore_status_mask |= UART_LSR_PE | UART_LSR_FE;
+	if (termios->c_iflag & IGNBRK) {
+		up->port.ignore_status_mask |= UART_LSR_BI;
+		/*
+		 * If we're ignoring parity and break indicators,
+		 * ignore overruns too (for real raw support).
+		 */
+		if (termios->c_iflag & IGNPAR)
+			up->port.ignore_status_mask |= UART_LSR_OE;
+	}
+
+	/* Ignore all characters if CREAD is not set */
+	if ((termios->c_cflag & CREAD) == 0)
+		up->port.ignore_status_mask |= UART_LSR_DR;
+
+	/*
+	 * CTS flow control flag and modem status interrupts, disable
+	 * MSI by default
+	 */
+	up->ier &= ~UART_IER_MSI;
+	if (UART_ENABLE_MS(&up->port, termios->c_cflag))
+		up->ier |= UART_IER_MSI;
+
+	serial_out(up, UART_IER, up->ier);
+
+	if (termios->c_cflag & CRTSCTS)
+		up->mcr |= UART_MCR_AFE | UART_MCR_RTS;
+	else
+		up->mcr &= ~UART_MCR_AFE;
+
+	up->dll	= quot & 0xff;
+	up->dlm	= quot >> 8;
+	up->fcr	= fcr;
+	up->lcr = cval;					/* Save LCR */
+
+	serial_out(up, UART_LCR, cval | UART_LCR_DLAB);	/* set DLAB */
+	serial_out(up, UART_DLL, up->dll);		/* LS of divisor */
+	serial_out(up, UART_DLM, up->dlm);		/* MS of divisor */
+	serial_out(up, UART_LCR, cval);			/* reset DLAB */
+
+	if (up->hw_type == hsu_intel) {
+		up->mul	= mul;
+		up->div = div;
+		up->ps	= ps;
+		serial_out(up, UART_MUL, up->mul);	/* set MUL */
+		serial_out(up, UART_DIV, up->div);	/* set DIV */
+		serial_out(up, UART_PS, up->ps);	/* set PS */
+	} else {
+		if (m != up->m || n != up->n) {
+			if (cfg->set_clk)
+				cfg->set_clk(m, n, up->port.membase);
+			up->m = m;
+			up->n = n;
+		}
+	}
+
+	serial_out(up, UART_FCR, fcr);
+	set_mctrl(up, up->port.mctrl);
+	serial_sched_cmd(up, qcmd_get_msr);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+	serial_sched_start(up);
+	serial_sched_sync(up);
+	pm_runtime_put(up->dev);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+static void
+serial_hsu_pm(struct uart_port *port, unsigned int state,
+	      unsigned int oldstate)
+{
+}
+
+static void serial_hsu_release_port(struct uart_port *port)
+{
+}
+
+static int serial_hsu_request_port(struct uart_port *port)
+{
+	return 0;
+}
+
+static void serial_hsu_config_port(struct uart_port *port, int flags)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+	up->port.type = PORT_MFD;
+}
+
+static int
+serial_hsu_verify_port(struct uart_port *port, struct serial_struct *ser)
+{
+	/* We don't want the core code to modify any port params */
+	return -EINVAL;
+}
+
+static const char *
+serial_hsu_type(struct uart_port *port)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+	return up->name;
+}
+
+struct device *intel_mid_hsu_set_wake_peer(int port,
+	void (*wake_peer)(struct device *))
+{
+	struct hsu_port_cfg *cfg = phsu->configs[port];
+
+	cfg->wake_peer = wake_peer;
+	return cfg->dev;
+}
+EXPORT_SYMBOL(intel_mid_hsu_set_wake_peer);
+
+static void serial_hsu_wake_peer(struct uart_port *port)
+{
+	struct uart_hsu_port *up =
+			container_of(port, struct uart_hsu_port, port);
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+
+	trace_hsu_func_start(up->index, __func__);
+	if (cfg->wake_peer)
+		cfg->wake_peer(cfg->dev);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+#define BOTH_EMPTY (UART_LSR_TEMT | UART_LSR_THRE)
+/* Wait for transmitter & holding register to empty */
+static inline int wait_for_xmitr(struct uart_hsu_port *up)
+{
+	unsigned int status, tmout = 10000;
+
+	while (--tmout) {
+		status = serial_in(up, UART_LSR);
+		if (status & UART_LSR_BI)
+			up->lsr_break_flag = UART_LSR_BI;
+		udelay(1);
+		if (status & BOTH_EMPTY)
+			break;
+	}
+	if (tmout == 0)
+		return 0;
+
+	if (up->port.flags & UPF_CONS_FLOW) {
+		tmout = 10000;
+		while (--tmout &&
+		       ((serial_in(up, UART_MSR) & UART_MSR_CTS) == 0))
+			udelay(1);
+		if (tmout == 0)
+			return 0;
+	}
+	return 1;
+}
+
+#ifdef CONFIG_CONSOLE_POLL
+static int serial_hsu_get_poll_char(struct uart_port *port)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+	u8 lsr;
+
+	lsr = serial_in(up, UART_LSR);
+	if (!(lsr & UART_LSR_DR))
+		return NO_POLL_CHAR;
+	return serial_in(up, UART_RX);
+}
+
+static void serial_hsu_put_poll_char(struct uart_port *port,
+			unsigned char c)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+
+	serial_out(up, UART_IER, 0);
+	while (!wait_for_xmitr(up))
+		cpu_relax();
+	serial_out(up, UART_TX, c);
+	while (!wait_for_xmitr(up))
+		cpu_relax();
+	serial_out(up, UART_IER, up->ier);
+}
+#endif
+
+#ifdef CONFIG_SERIAL_MFD_HSU_CONSOLE
+static void serial_hsu_console_putchar(struct uart_port *port, int ch)
+{
+	struct uart_hsu_port *up =
+		container_of(port, struct uart_hsu_port, port);
+	cl_put_char(up, ch);
+}
+
+/*
+ * Print a string to the serial port trying not to disturb
+ * any possible real use of the port...
+ *
+ *	The console_lock must be held when we get here.
+ */
+static void
+serial_hsu_console_write(struct console *co, const char *s, unsigned int count)
+{
+	struct uart_hsu_port *up = phsu->port + co->index;
+	unsigned long flags;
+
+	uart_console_write(&up->port, s, count, serial_hsu_console_putchar);
+	spin_lock_irqsave(&up->cl_lock, flags);
+	serial_sched_cmd(up, qcmd_cl);
+	spin_unlock_irqrestore(&up->cl_lock, flags);
+}
+
+static struct console serial_hsu_console;
+
+static int __init
+serial_hsu_console_setup(struct console *co, char *options)
+{
+	struct uart_hsu_port *up = phsu->port + co->index;
+	int baud = 115200;
+	int bits = 8;
+	int parity = 'n';
+	int flow = 'n';
+	unsigned long flags;
+
+	if (co->index < 0 || co->index >= hsu_port_max)
+		return -ENODEV;
+
+	if (options)
+		uart_parse_options(options, &baud, &parity, &bits, &flow);
+
+	pm_runtime_get_sync(up->dev);
+	set_bit(flag_console, &up->flags);
+	set_bit(flag_startup, &up->flags);
+	serial_set_alt(up->index);
+	serial_sched_start(up);
+	spin_lock_irqsave(&up->port.lock, flags);
+	serial_sched_cmd(up, qcmd_get_msr);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+	serial_sched_sync(up);
+	pm_runtime_put(up->dev);
+	up->cl_circ.buf = kzalloc(HSU_CL_BUF_LEN, GFP_KERNEL);
+	if (up->cl_circ.buf == NULL)
+		return -ENOMEM;
+	return uart_set_options(&up->port, co, baud, parity, bits, flow);
+}
+
+static struct console serial_hsu_console = {
+	.name		= "ttyMFD",
+	.write		= serial_hsu_console_write,
+	.device		= uart_console_device,
+	.setup		= serial_hsu_console_setup,
+	.flags		= CON_PRINTBUFFER,
+	.index		= -1,
+	.data		= &serial_hsu_reg,
+};
+
+#define SERIAL_HSU_CONSOLE	(&serial_hsu_console)
+#else
+#define SERIAL_HSU_CONSOLE	NULL
+#endif
+
+struct uart_ops serial_hsu_pops = {
+	.tx_empty	= serial_hsu_tx_empty,
+	.set_mctrl	= serial_hsu_set_mctrl,
+	.get_mctrl	= serial_hsu_get_mctrl,
+	.stop_tx	= serial_hsu_stop_tx,
+	.start_tx	= serial_hsu_start_tx,
+	.stop_rx	= serial_hsu_stop_rx,
+	.enable_ms	= serial_hsu_enable_ms,
+	.break_ctl	= serial_hsu_break_ctl,
+	.startup	= serial_hsu_startup,
+	.shutdown	= serial_hsu_shutdown,
+	.set_termios	= serial_hsu_set_termios,
+	.pm		= serial_hsu_pm,
+	.type		= serial_hsu_type,
+	.release_port	= serial_hsu_release_port,
+	.request_port	= serial_hsu_request_port,
+	.config_port	= serial_hsu_config_port,
+	.verify_port	= serial_hsu_verify_port,
+	.wake_peer	= serial_hsu_wake_peer,
+#ifdef CONFIG_CONSOLE_POLL
+	.poll_get_char = serial_hsu_get_poll_char,
+	.poll_put_char = serial_hsu_put_poll_char,
+#endif
+};
+
+static struct uart_driver serial_hsu_reg = {
+	.owner		= THIS_MODULE,
+	.driver_name	= "MFD serial",
+	.dev_name	= "ttyMFD",
+	.major		= TTY_MAJOR,
+	.minor		= 128,
+	.nr		= HSU_PORT_MAX,
+};
+
+static irqreturn_t wakeup_irq(int irq, void *dev)
+{
+	struct uart_hsu_port *up = dev_get_drvdata(dev);
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+
+	trace_hsu_func_start(up->index, __func__);
+	set_bit(flag_active, &up->flags);
+	if (cfg->preamble && cfg->hw_set_rts)
+		cfg->hw_set_rts(up->index, 1);
+	pm_runtime_get(dev);
+	pm_runtime_put(dev);
+	trace_hsu_func_end(up->index, __func__, "");
+	return IRQ_HANDLED;
+}
+
+#if defined(CONFIG_PM) || defined(CONFIG_PM_RUNTIME)
+static void hsu_flush_rxfifo(struct uart_hsu_port *up)
+{
+	unsigned int lsr, cnt;
+
+	if (up->hw_type == hsu_intel) {
+		cnt = serial_in(up, UART_FOR) & 0x7F;
+		if (cnt)
+			dev_dbg(up->dev,
+				"Warning: %d bytes are received"
+				" in RX fifo after RTS active for %d us\n",
+				cnt, up->byte_delay);
+		lsr = serial_in(up, UART_LSR);
+		if (lsr & UART_LSR_DR && cnt)
+			dev_dbg(up->dev,
+				"flush abnormal data in rx fifo\n");
+			while (cnt) {
+				serial_in(up, UART_RX);
+				cnt--;
+			}
+	}
+}
+
+static void hsu_regs_context(struct uart_hsu_port *up, int op)
+{
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+
+	if (op == context_load) {
+		/*
+		 * Delay a while before HW get stable. Without this the
+		 * resume will just fail, as the value you write to the
+		 * HW register will not be really written.
+		 *
+		 * This is only needed for Tangier, which really powers gate
+		 * the HSU HW in runtime suspend. While in Penwell/CLV it is
+		 * only clock gated.
+		*/
+		usleep_range(500, 510);
+
+		if (cfg->hw_reset)
+			cfg->hw_reset(up->port.membase);
+
+		serial_out(up, UART_LCR, up->lcr);
+		serial_out(up, UART_LCR, up->lcr | UART_LCR_DLAB);
+		serial_out(up, UART_DLL, up->dll);
+		serial_out(up, UART_DLM, up->dlm);
+		serial_out(up, UART_LCR, up->lcr);
+
+		if (up->hw_type == hsu_intel) {
+			serial_out(up, UART_MUL, up->mul);
+			serial_out(up, UART_DIV, up->div);
+			serial_out(up, UART_PS, up->ps);
+		} else {
+			if (cfg->set_clk)
+				cfg->set_clk(up->m, up->n, up->port.membase);
+		}
+
+		serial_out(up, UART_MCR, up->mcr);
+		serial_out(up, UART_FCR, up->fcr);
+		serial_out(up, UART_IER, up->ier);
+	}
+
+	if (up->use_dma && up->dma_ops->context_op)
+		up->dma_ops->context_op(up, op);
+}
+
+int serial_hsu_do_suspend(struct uart_hsu_port *up)
+{
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+	struct uart_port *uport = &up->port;
+	struct tty_port *tport = &uport->state->port;
+	struct tty_struct *tty = tport->tty;
+	struct circ_buf *xmit = &up->port.state->xmit;
+	char cmd;
+	unsigned long flags;
+
+	trace_hsu_func_start(up->index, __func__);
+
+	if (test_bit(flag_startup, &up->flags)) {
+		if (up->hw_type == hsu_intel &&
+			serial_in(up, UART_FOR) & 0x7F)
+			goto busy;
+		else if (up->hw_type == hsu_dw &&
+			serial_in(up, 0x7c / 4) & BIT(3))
+			goto busy;
+	}
+
+	if (up->use_dma) {
+		if (up->hw_type == hsu_intel) {
+			if (chan_readl(up->rxc, HSU_CH_D0SAR) >
+					up->rxbuf.dma_addr)
+				goto busy;
+		}
+	}
+
+	if (cfg->hw_set_rts)
+		cfg->hw_set_rts(up->index, 1);
+
+	disable_irq(up->port.irq);
+	disable_irq(up->dma_irq);
+
+	if (cfg->hw_set_rts)
+		usleep_range(up->byte_delay, up->byte_delay + 1);
+
+	serial_sched_stop(up);
+	set_bit(flag_suspend, &up->flags);
+
+	if (test_bit(flag_startup, &up->flags) && check_qcmd(up, &cmd)) {
+		dev_info(up->dev, "ignore suspend cmd: %d\n", cmd);
+		goto err;
+	}
+
+	if (test_bit(flag_tx_on, &up->flags)) {
+		dev_info(up->dev, "ignore suspend for tx on\n");
+		dev_info(up->dev,
+			"xmit pending:%d, stopped:%d, hw_stopped:%d, MSR:%x\n",
+			(int)uart_circ_chars_pending(xmit), tty->stopped,
+			tty->hw_stopped, serial_in(up, UART_MSR));
+		goto err;
+	}
+
+	if (test_bit(flag_startup, &up->flags) && !uart_circ_empty(xmit) &&
+		!uart_tx_stopped(&up->port)) {
+		dev_info(up->dev, "ignore suspend for xmit\n");
+		dev_info(up->dev,
+			"xmit pending:%d, stopped:%d, hw_stopped:%d, MSR:%x\n",
+			(int)uart_circ_chars_pending(xmit),
+			tty->stopped,
+			tty->hw_stopped,
+			serial_in(up, UART_MSR));
+		goto err;
+	}
+
+	if (up->use_dma) {
+		if (up->dma_ops->suspend(up))
+			goto err;
+	} else if (test_bit(flag_startup, &up->flags)) {
+		if (up->hw_type == hsu_intel &&
+			serial_in(up, UART_FOR) & 0x7F)
+			goto err;
+		else if (up->hw_type == hsu_dw &&
+			serial_in(up, 0x7c / 4) & BIT(3))
+			goto err;
+	}
+
+	if (cfg->hw_suspend)
+		cfg->hw_suspend(up->index, up->dev, wakeup_irq);
+	if (cfg->hw_context_save)
+		hsu_regs_context(up, context_save);
+	if (cfg->preamble && cfg->hw_suspend_post)
+		cfg->hw_suspend_post(up->index);
+	enable_irq(up->dma_irq);
+	if (up->hw_type == hsu_dw)
+		enable_irq(up->port.irq);
+
+	trace_hsu_func_end(up->index, __func__, "");
+	return 0;
+err:
+	if (cfg->hw_set_rts)
+		cfg->hw_set_rts(up->index, 0);
+	clear_bit(flag_suspend, &up->flags);
+	enable_irq(up->port.irq);
+	if (up->use_dma && up->hw_type == hsu_intel)
+		intel_dma_do_rx(up, 0);
+	enable_irq(up->dma_irq);
+	serial_sched_start(up);
+	spin_lock_irqsave(&up->port.lock, flags);
+	serial_sched_cmd(up, qcmd_get_msr);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+	serial_sched_sync(up);
+busy:
+	pm_schedule_suspend(up->dev, cfg->idle);
+	trace_hsu_func_end(up->index, __func__, "busy");
+	return -EBUSY;
+}
+EXPORT_SYMBOL(serial_hsu_do_suspend);
+
+int serial_hsu_do_resume(struct uart_hsu_port *up)
+{
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+	unsigned long flags;
+
+	trace_hsu_func_start(up->index, __func__);
+	if (!test_and_clear_bit(flag_suspend, &up->flags)) {
+		trace_hsu_func_end(up->index, __func__, "ignore");
+		return 0;
+	}
+	if (up->hw_type == hsu_dw)
+		disable_irq(up->port.irq);
+	if (cfg->hw_context_save)
+		hsu_regs_context(up, context_load);
+	if (cfg->hw_resume)
+		cfg->hw_resume(up->index, up->dev);
+	if (test_bit(flag_startup, &up->flags))
+		hsu_flush_rxfifo(up);
+	if (up->use_dma)
+		up->dma_ops->resume(up);
+	if (cfg->hw_set_rts)
+		cfg->hw_set_rts(up->index, 0);
+	enable_irq(up->port.irq);
+
+	serial_sched_start(up);
+	spin_lock_irqsave(&up->port.lock, flags);
+	serial_sched_cmd(up, qcmd_get_msr);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+	serial_sched_sync(up);
+	trace_hsu_func_end(up->index, __func__, "");
+	return 0;
+}
+EXPORT_SYMBOL(serial_hsu_do_resume);
+#endif
+
+#ifdef CONFIG_PM_RUNTIME
+int serial_hsu_do_runtime_idle(struct uart_hsu_port *up)
+{
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+
+	trace_hsu_func_start(up->index, __func__);
+	if (cfg->type == debug_port
+			&& system_state == SYSTEM_BOOTING)
+		/* if HSU is set as default console, but earlyprintk is not hsu,
+		 * then it will enter suspend and can not get back since system
+		 * is on boot up, no contex switch to let it resume, here just
+		 * postpone the suspend retry 30 seconds, then system should
+		 * have finished booting
+		 */
+		pm_schedule_suspend(up->dev, 30000);
+	else
+		pm_schedule_suspend(up->dev, cfg->idle);
+	trace_hsu_func_end(up->index, __func__, "");
+	return -EBUSY;
+}
+EXPORT_SYMBOL(serial_hsu_do_runtime_idle);
+#endif
+
+static void serial_hsu_command(struct uart_hsu_port *up)
+{
+	char cmd, c;
+	unsigned long flags;
+	unsigned int iir, lsr;
+	int status;
+	struct hsu_dma_chan *txc = up->txc;
+	struct hsu_dma_chan *rxc = up->rxc;
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+
+	trace_hsu_func_start(up->index, __func__);
+	if (unlikely(test_bit(flag_cmd_off, &up->flags))) {
+		trace_hsu_func_end(up->index, __func__, "cmd_off");
+		return;
+	}
+	if (unlikely(test_bit(flag_suspend, &up->flags))) {
+		dev_err(up->dev,
+			"Error to handle cmd while port is suspended\n");
+		if (check_qcmd(up, &cmd))
+			dev_err(up->dev, "Command pending: %d\n", cmd);
+		trace_hsu_func_end(up->index, __func__, "suspend");
+		return;
+	}
+	set_bit(flag_active, &up->flags);
+	spin_lock_irqsave(&up->port.lock, flags);
+	while (get_qcmd(up, &cmd)) {
+		spin_unlock_irqrestore(&up->port.lock, flags);
+		trace_hsu_cmd_start(up->index, cmd);
+		switch (cmd) {
+		case qcmd_overflow:
+			dev_err(up->dev, "queue overflow!!\n");
+			break;
+		case qcmd_set_mcr:
+			serial_out(up, UART_MCR, up->mcr);
+			break;
+		case qcmd_set_ier:
+			serial_out(up, UART_IER, up->ier);
+			break;
+		case qcmd_start_rx:
+			/* use for DW DMA RX only */
+			if (test_and_clear_bit(flag_rx_pending, &up->flags)) {
+				if (up->use_dma)
+					up->dma_ops->start_rx(up);
+			}
+			break;
+		case qcmd_stop_rx:
+			if (!up->use_dma || up->hw_type == hsu_dw) {
+				up->ier &= ~UART_IER_RLSI;
+				up->port.read_status_mask &= ~UART_LSR_DR;
+				serial_out(up, UART_IER, up->ier);
+			}
+
+			if (up->use_dma)
+				up->dma_ops->stop_rx(up);
+			break;
+		case qcmd_start_tx:
+			if (up->use_dma) {
+				if (!test_bit(flag_tx_on, &up->flags))
+					up->dma_ops->start_tx(up);
+			} else if (!(up->ier & UART_IER_THRI)) {
+				up->ier |= UART_IER_THRI;
+				serial_out(up, UART_IER, up->ier);
+			}
+			break;
+		case qcmd_stop_tx:
+			if (up->use_dma) {
+				spin_lock_irqsave(&up->port.lock, flags);
+				up->dma_ops->stop_tx(up);
+				clear_bit(flag_tx_on, &up->flags);
+				spin_unlock_irqrestore(&up->port.lock, flags);
+			} else if (up->ier & UART_IER_THRI) {
+				up->ier &= ~UART_IER_THRI;
+				serial_out(up, UART_IER, up->ier);
+			}
+			break;
+		case qcmd_cl:
+			serial_out(up, UART_IER, 0);
+			while (cl_get_char(up, &c)) {
+				while (!wait_for_xmitr(up))
+					schedule();
+				serial_out(up, UART_TX, c);
+			}
+			serial_out(up, UART_IER, up->ier);
+			break;
+		case qcmd_port_irq:
+			up->port_irq_cmddone++;
+
+			/* Baytrail patform use shared IRQ and need more care */
+			if (up->hw_type == hsu_intel) {
+				iir = serial_in(up, UART_IIR);
+			} else {
+				if (up->iir & 0x1)
+					up->iir = serial_in(up, UART_IIR);
+				iir = up->iir;
+				up->iir = 1;
+			}
+
+			if (iir & UART_IIR_NO_INT) {
+				enable_irq(up->port.irq);
+				up->port_irq_pio_no_irq_pend++;
+				break;
+			}
+
+			if (iir & HSU_PIO_RX_ERR)
+				up->port_irq_pio_rx_err++;
+			if (iir & HSU_PIO_RX_AVB)
+				up->port_irq_pio_rx_avb++;
+			if (iir & HSU_PIO_RX_TMO)
+				up->port_irq_pio_rx_timeout++;
+			if (iir & HSU_PIO_TX_REQ)
+				up->port_irq_pio_tx_req++;
+
+			lsr = serial_in(up, UART_LSR);
+
+			/* We need to judge it's timeout or data available */
+			if (lsr & UART_LSR_DR) {
+				if (!up->use_dma) {
+					receive_chars(up, &lsr);
+				} else if (up->hw_type == hsu_dw) {
+					if ((iir & 0xf) == 0xc) {
+						/*
+						 * RX timeout IRQ, the DMA
+						 * channel may be stalled
+						 */
+						up->dma_ops->stop_rx(up);
+						receive_chars(up, &lsr);
+					} else
+						up->dma_ops->start_rx(up);
+				}
+			}
+
+			/* lsr will be renewed during the receive_chars */
+			if (!up->use_dma && (lsr & UART_LSR_THRE))
+				transmit_chars(up);
+
+			spin_lock_irqsave(&up->port.lock, flags);
+			serial_sched_cmd(up, qcmd_enable_irq);
+			spin_unlock_irqrestore(&up->port.lock, flags);
+			break;
+		case qcmd_enable_irq:
+			enable_irq(up->port.irq);
+			break;
+		case qcmd_dma_irq:
+			/* Only hsu_intel has this irq */
+			up->dma_irq_cmddone++;
+			if (up->port_dma_sts & (1 << txc->id)) {
+				up->dma_tx_irq_cmddone++;
+				status = chan_readl(txc, HSU_CH_SR);
+				up->dma_ops->start_tx(up);
+			}
+
+			if (up->port_dma_sts & (1 << rxc->id)) {
+				status = chan_readl(rxc, HSU_CH_SR);
+				intel_dma_do_rx(up, status);
+			}
+			enable_irq(up->dma_irq);
+			break;
+		case qcmd_cmd_off:
+			set_bit(flag_cmd_off, &up->flags);
+			break;
+		case qcmd_get_msr:
+			break;
+		default:
+			dev_err(up->dev, "invalid command!!\n");
+			break;
+		}
+		trace_hsu_cmd_end(up->index, cmd);
+		spin_lock_irqsave(&up->port.lock, flags);
+		if (unlikely(test_bit(flag_cmd_off, &up->flags)))
+			break;
+	}
+	up->msr = serial_in(up, UART_MSR);
+	if (cfg->hw_ctrl_cts)
+		up->msr |= UART_MSR_CTS;
+	check_modem_status(up);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+	trace_hsu_func_end(up->index, __func__, "");
+}
+
+static void serial_hsu_tasklet(unsigned long data)
+{
+	struct uart_hsu_port *up = (struct uart_hsu_port *)data;
+
+	up->in_tasklet = 1;
+	serial_hsu_command(up);
+	up->tasklet_done++;
+	up->in_tasklet = 0;
+}
+
+static void serial_hsu_work(struct work_struct *work)
+{
+	struct uart_hsu_port *uport =
+		container_of(work, struct uart_hsu_port, work);
+
+	uport->in_workq = 1;
+	serial_hsu_command(uport);
+	uport->workq_done++;
+	uport->in_workq = 0;
+}
+
+static int serial_port_setup(struct uart_hsu_port *up,
+		struct hsu_port_cfg *cfg)
+{
+	int ret;
+	int index = cfg->index;
+
+	phsu->configs[index] = cfg;
+	up->port.line = index;
+	snprintf(up->name, sizeof(up->name) - 1, "%s_p", cfg->name);
+	up->index = index;
+
+	if ((hsu_dma_enable & (1 << index)) && up->dma_ops)
+		up->use_dma = 1;
+	else
+		up->use_dma = 0;
+
+	if (cfg->hw_init)
+		cfg->hw_init(up->dev, index);
+	mutex_init(&up->q_mutex);
+	tasklet_init(&up->tasklet, serial_hsu_tasklet,
+				(unsigned long)up);
+	up->workqueue =
+		create_singlethread_workqueue(up->name);
+	INIT_WORK(&up->work, serial_hsu_work);
+	up->qcirc.buf = (char *)up->qbuf;
+	spin_lock_init(&up->cl_lock);
+	set_bit(flag_cmd_off, &up->flags);
+
+	if (cfg->type == debug_port) {
+		serial_hsu_reg.cons = SERIAL_HSU_CONSOLE;
+		if (serial_hsu_reg.cons)
+			serial_hsu_reg.cons->index = index;
+	} else
+		serial_hsu_reg.cons = NULL;
+
+	uart_add_one_port(&serial_hsu_reg, &up->port);
+
+	if (phsu->irq_port_and_dma) {
+		up->dma_irq = up->port.irq;
+		ret = request_irq(up->dma_irq, hsu_dma_irq, IRQF_SHARED,
+				"hsu dma", up);
+		if (ret) {
+			dev_err(up->dev, "can not get dma IRQ\n");
+			return ret;
+		}
+		ret = request_irq(up->port.irq, hsu_port_irq, IRQF_SHARED,
+				up->name, up);
+		if (ret) {
+			dev_err(up->dev, "can not get port IRQ\n");
+			return ret;
+		}
+	} else {
+		up->dma_irq = phsu->dma_irq;
+		ret = request_irq(up->port.irq, hsu_port_irq, IRQF_SHARED,
+				up->name, up);
+		if (ret) {
+			dev_err(up->dev, "can not get port IRQ\n");
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+struct uart_hsu_port *serial_hsu_port_setup(struct device *pdev, int port,
+	resource_size_t start, resource_size_t len, int irq)
+{
+	struct uart_hsu_port *up;
+	int index;
+	unsigned int uclk, clock;
+	struct hsu_port_cfg *cfg;
+
+	cfg = hsu_port_func_cfg + port;
+	if (!cfg)
+		return ERR_PTR(-EINVAL);
+
+	pr_info("Found a %s HSU\n", cfg->hw_ip ? "Designware" : "Intel");
+
+	index = cfg->index;
+	up = phsu->port + index;
+
+	up->dev = pdev;
+	up->port.type = PORT_MFD;
+	up->port.iotype = UPIO_MEM;
+	up->port.mapbase = start;
+	up->port.membase = ioremap_nocache(up->port.mapbase, len);
+	up->port.fifosize = 64;
+	up->port.ops = &serial_hsu_pops;
+	up->port.flags = UPF_IOREMAP;
+	up->hw_type = cfg->hw_ip;
+	/* calculate if DLAB=1, the ideal uartclk */
+	if (cfg->hw_get_clk)
+		clock = cfg->hw_get_clk();
+	else
+		clock = 50000;
+	uclk = clock * 1000 / (115200 * 16); /* 16 is default ps */
+	if (uclk >= 24)
+		uclk = 24;
+	else if (uclk >= 16)
+		uclk = 16;
+	else if (uclk >= 8)
+		uclk = 8;
+	else
+		uclk = 1;
+
+	if (up->hw_type == hsu_intel)
+		up->port.uartclk = 115200 * uclk * 16;
+	else
+		up->port.uartclk = 115200 * 32 * 16;
+
+	up->port.irq = irq;
+	up->port.dev = pdev;
+
+	if (up->hw_type == hsu_intel) {
+		up->txc = &phsu->chans[index * 2];
+		up->rxc = &phsu->chans[index * 2 + 1];
+		up->dma_ops = &intel_dma_ops;
+	} else {
+		up->dma_ops = pdw_dma_ops;
+	}
+
+	if (cfg->has_alt) {
+		struct hsu_port_cfg *alt_cfg =
+			hsu_port_func_cfg + cfg->alt;
+		struct uart_hsu_port *alt_up =
+			phsu->port + alt_cfg->index;
+
+		memcpy(alt_up, up, sizeof(*up));
+		serial_port_setup(alt_up, alt_cfg);
+		phsu->port_num++;
+	}
+
+	serial_port_setup(up, cfg);
+	phsu->port_num++;
+
+	return up;
+}
+EXPORT_SYMBOL(serial_hsu_port_setup);
+
+void serial_hsu_port_free(struct uart_hsu_port *up)
+{
+	struct hsu_port_cfg *cfg = phsu->configs[up->index];
+
+	uart_remove_one_port(&serial_hsu_reg, &up->port);
+	free_irq(up->port.irq, up);
+	if (cfg->has_alt) {
+		struct hsu_port_cfg *alt_cfg = phsu->configs[cfg->alt];
+		struct uart_hsu_port *alt_up =
+			phsu->port + alt_cfg->index;
+		uart_remove_one_port(&serial_hsu_reg, &alt_up->port);
+		free_irq(up->port.irq, alt_up);
+	}
+}
+EXPORT_SYMBOL(serial_hsu_port_free);
+
+void serial_hsu_port_shutdown(struct uart_hsu_port *up)
+{
+	uart_suspend_port(&serial_hsu_reg, &up->port);
+}
+EXPORT_SYMBOL(serial_hsu_port_shutdown);
+
+int serial_hsu_dma_setup(struct device *pdev,
+	resource_size_t start, resource_size_t len, unsigned int irq, int share)
+{
+	struct hsu_dma_chan *dchan;
+	int i, ret;
+
+	phsu->reg = ioremap_nocache(start, len);
+	dchan = phsu->chans;
+	for (i = 0; i < 6; i++) {
+		dchan->id = i;
+		dchan->dirt = (i & 0x1) ? DMA_FROM_DEVICE :
+			DMA_TO_DEVICE;
+		dchan->uport = &phsu->port[i/2];
+		dchan->reg = phsu->reg + HSU_DMA_CHANS_REG_OFFSET +
+			i * HSU_DMA_CHANS_REG_LENGTH;
+
+		dchan++;
+	}
+
+	/* will share irq with port if irq < 0 */
+	if (share)
+		phsu->irq_port_and_dma = 1;
+	else {
+		phsu->dma_irq = irq;
+		ret = request_irq(irq, hsu_dma_irq, 0, "hsu dma", phsu);
+		if (ret) {
+			dev_err(pdev, "can not get dma IRQ\n");
+			goto err;
+		}
+	}
+
+	dev_set_drvdata(pdev, phsu);
+
+	return 0;
+err:
+	iounmap(phsu->reg);
+	return ret;
+}
+EXPORT_SYMBOL(serial_hsu_dma_setup);
+
+void serial_hsu_dma_free(void)
+{
+	free_irq(phsu->dma_irq, phsu);
+}
+EXPORT_SYMBOL(serial_hsu_dma_free);
+
+static int __init hsu_init(void)
+{
+	int ret;
+
+	ret = uart_register_driver(&serial_hsu_reg);
+	if (ret)
+		return ret;
+
+	spin_lock_init(&phsu->dma_lock);
+	return hsu_debugfs_init(phsu);
+}
+
+static void __exit hsu_exit(void)
+{
+	uart_unregister_driver(&serial_hsu_reg);
+	hsu_debugfs_remove(phsu);
+}
+
+module_init(hsu_init);
+module_exit(hsu_exit);
+
+MODULE_AUTHOR("Yang Bin <bin.yang@intel.com>");
+MODULE_LICENSE("GPL v2");
+MODULE_ALIAS("platform:medfield-hsu");
diff --git a/drivers/tty/serial/mfd_dma.c b/drivers/tty/serial/mfd_dma.c
new file mode 100644
index 0000000..a9371fb
--- /dev/null
+++ b/drivers/tty/serial/mfd_dma.c
@@ -0,0 +1,753 @@
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/console.h>
+#include <linux/sysrq.h>
+#include <linux/slab.h>
+#include <linux/serial_reg.h>
+#include <linux/circ_buf.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/tty.h>
+#include <linux/tty_flip.h>
+#include <linux/serial_core.h>
+#include <linux/serial_mfd.h>
+#include <linux/dma-mapping.h>
+#include <linux/pci.h>
+#include <linux/io.h>
+#include <linux/debugfs.h>
+#include <linux/pm_runtime.h>
+#include <linux/intel_mid_pm.h>
+#include <linux/intel_mid_dma.h>
+#include <linux/irq.h>
+#include <linux/acpi.h>
+#include <asm/intel_mid_hsu.h>
+#include <linux/intel_mid_pm.h>
+#include <linux/pm_qos.h>
+
+#include "mfd.h"
+
+static int dma_init_common(struct uart_hsu_port *up)
+{
+	struct hsu_dma_buffer *dbuf;
+	struct circ_buf *xmit = &up->port.state->xmit;
+
+	/* 1. Allocate the RX buffer */
+	dbuf = &up->rxbuf;
+	dbuf->buf = kzalloc(HSU_DMA_BUF_SIZE, GFP_KERNEL);
+	if (!dbuf->buf) {
+		up->use_dma = 0;
+		dev_err(up->dev, "allocate DMA buffer failed!!\n");
+		return -ENOMEM;
+	}
+
+	dbuf->dma_addr = dma_map_single(up->dev,
+			dbuf->buf,
+			HSU_DMA_BUF_SIZE,
+			DMA_FROM_DEVICE);
+	dbuf->dma_size = HSU_DMA_BUF_SIZE;
+
+	/* 2. prepare teh TX buffer */
+	dbuf = &up->txbuf;
+	dbuf->buf = xmit->buf;
+	dbuf->dma_addr = dma_map_single(up->dev,
+			dbuf->buf,
+			UART_XMIT_SIZE,
+			DMA_TO_DEVICE);
+	dbuf->dma_size = UART_XMIT_SIZE;
+	dbuf->ofs = 0;
+	return 0;
+}
+
+static void dma_exit_common(struct uart_hsu_port *up)
+{
+	struct hsu_dma_buffer *dbuf;
+	struct uart_port *port = &up->port;
+
+	/* Free and unmap rx dma buffer */
+	dbuf = &up->rxbuf;
+	dma_unmap_single(port->dev,
+			dbuf->dma_addr,
+			dbuf->dma_size,
+			DMA_FROM_DEVICE);
+	kfree(dbuf->buf);
+
+	/* Next unmap tx dma buffer*/
+	dbuf = &up->txbuf;
+	dma_unmap_single(port->dev,
+			dbuf->dma_addr,
+			dbuf->dma_size,
+			DMA_TO_DEVICE);
+}
+
+#ifdef CONFIG_INTEL_MID_DMAC
+static bool dw_dma_chan_filter(struct dma_chan *chan, void *param)
+{
+	struct dw_dma_priv *dw_dma = param;
+
+	if (dw_dma->dmac && (&dw_dma->dmac->dev == chan->device->dev))
+		return true;
+	else {
+#ifdef CONFIG_ACPI
+		acpi_handle handle = ACPI_HANDLE(chan->device->dev);
+		struct acpi_device *device;
+		int ret;
+		const char *hid;
+		ret = acpi_bus_get_device(handle, &device);
+		if (ret) {
+			pr_warn("DW HSU: no acpi entry\n");
+			return false;
+		}
+		hid = acpi_device_hid(device);
+		if (!strncmp(hid, "INTL9C60", strlen(hid))) {
+			acpi_status status;
+			unsigned long long tmp;
+			status = acpi_evaluate_integer(handle,
+					"_UID", NULL, &tmp);
+			if (!ACPI_FAILURE(status) && (tmp == 1))
+				return true;
+		}
+		if (!strncmp(hid, "80862286", strlen(hid))) {
+			return true;
+		}
+
+#endif
+		return false;
+	}
+}
+
+/* the RX/TX buffer init should be a common stuff */
+static int dw_dma_init(struct uart_hsu_port *up)
+{
+	struct dw_dma_priv *dw_dma;
+	struct intel_mid_dma_slave *rxs, *txs;
+	dma_cap_mask_t mask;
+	int ret = 0;
+
+	dw_dma = kzalloc(sizeof(*dw_dma), GFP_KERNEL);
+	if (!dw_dma) {
+		pr_warn("DW HSU: Can't alloc memory for dw_dm_priv\n");
+		return -1;
+	}
+
+	up->dma_priv = dw_dma;
+
+	/*
+	 * Get pci device for DMA controller, currently it could only
+	 * be the DMA controller of baytrail
+	 */
+	dw_dma->dmac = pci_get_device(PCI_VENDOR_ID_INTEL, 0x0f06, NULL);
+	if (!dw_dma->dmac) {
+		/* still have chance to get from ACPI dev */
+		pr_warn("DW HSU: Can't find LPIO1 DMA controller by PCI, try ACPI\n");
+	}
+
+	ret = dma_init_common(up);
+	if (ret)
+		return ret;
+
+	dma_cap_zero(mask);
+	dma_cap_set(DMA_SLAVE, mask);
+
+	/* 1. Init rx channel */
+	dw_dma->rxchan = dma_request_channel(mask, dw_dma_chan_filter, dw_dma);
+	if (!dw_dma->rxchan)
+		goto err_exit;
+	rxs = &dw_dma->rxs;
+	rxs->dma_slave.direction = DMA_FROM_DEVICE;
+	rxs->hs_mode = LNW_DMA_HW_HS;
+	rxs->cfg_mode = LNW_DMA_PER_TO_MEM;
+	rxs->dma_slave.dst_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+
+	/* These are fixed HW info from Baytrail datasheet */
+	if (up->index == 0)
+		rxs->device_instance = 3;
+	else
+		rxs->device_instance = 5;
+	dw_dma->rxchan->private = rxs;
+
+	/* 2. Init tx channel */
+	dw_dma->txchan = dma_request_channel(mask, dw_dma_chan_filter, dw_dma);
+	if (!dw_dma->txchan)
+		goto free_rxchan;
+
+	txs = &dw_dma->txs;
+	txs->dma_slave.direction = DMA_TO_DEVICE;
+	txs->hs_mode = LNW_DMA_HW_HS;
+	txs->cfg_mode = LNW_DMA_MEM_TO_PER;
+	txs->dma_slave.src_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+	if (up->index == 0)
+		txs->device_instance = 2;
+	else
+		txs->device_instance = 4;
+	dw_dma->txchan->private = txs;
+
+	/* TX/RX reg share the same addr */
+	dw_dma->dma_addr = up->port.mapbase + UART_RX;
+
+	pm_qos_add_request(&up->qos, PM_QOS_CPU_DMA_LATENCY,
+			PM_QOS_DEFAULT_VALUE);
+
+	dw_dma->up = up;
+	up->dma_inited = 1;
+	return 0;
+
+free_rxchan:
+	dma_release_channel(dw_dma->rxchan);
+err_exit:
+	return -1;
+
+}
+
+static int dw_dma_suspend(struct uart_hsu_port *up)
+{
+	struct dw_dma_priv *dw_dma = up->dma_priv;
+	struct dma_chan *txchan;
+	struct dma_chan *rxchan;
+
+	if (!up->dma_inited)
+		return 0;
+
+	txchan = dw_dma->txchan;
+	rxchan = dw_dma->rxchan;
+
+	if (test_bit(flag_rx_on, &up->flags) ||
+		test_bit(flag_rx_pending, &up->flags)) {
+		dev_warn(up->dev, "ignore suspend for rx dma is running\n");
+		return -1;
+	}
+
+	txchan->device->device_control(txchan, DMA_TERMINATE_ALL, 0);
+	rxchan->device->device_control(rxchan, DMA_TERMINATE_ALL, 0);
+
+	txchan->device->device_control(txchan, DMA_PAUSE, 0);
+	rxchan->device->device_control(rxchan, DMA_PAUSE, 0);
+	pm_qos_update_request(&up->qos, PM_QOS_DEFAULT_VALUE);
+	return 0;
+}
+
+static int dw_dma_resume(struct uart_hsu_port *up)
+{
+	struct dw_dma_priv *dw_dma = up->dma_priv;
+	struct dma_chan *txchan;
+	struct dma_chan *rxchan;
+
+	if (!up->dma_inited)
+		return 0;
+
+	txchan = dw_dma->txchan;
+	rxchan = dw_dma->rxchan;
+
+	rxchan->device->device_control(rxchan, DMA_RESUME, 0);
+	txchan->device->device_control(txchan, DMA_RESUME, 0);
+	pm_qos_update_request(&up->qos, CSTATE_EXIT_LATENCY_C2);
+	return 0;
+}
+
+
+static int dw_dma_exit(struct uart_hsu_port *up)
+{
+	struct dw_dma_priv *dw_dma = up->dma_priv;
+	struct dma_chan *txchan = dw_dma->txchan;
+	struct dma_chan *rxchan = dw_dma->rxchan;
+
+	pm_qos_remove_request(&up->qos);
+	txchan->device->device_control(txchan, DMA_TERMINATE_ALL, 0);
+	rxchan->device->device_control(rxchan, DMA_TERMINATE_ALL, 0);
+	dma_release_channel(dw_dma->txchan);
+	dma_release_channel(dw_dma->rxchan);
+
+	dma_exit_common(up);
+
+	kfree(dw_dma);
+
+	up->dma_inited = 0;
+	up->dma_priv = NULL;
+	return 0;
+}
+
+static void dw_dma_tx_done(void *arg)
+{
+	struct dw_dma_priv *dw_dma = arg;
+	struct uart_hsu_port *up = dw_dma->up;
+	struct circ_buf *xmit = &up->port.state->xmit;
+	struct hsu_dma_buffer *dbuf = &up->txbuf;
+	unsigned long flags;
+	int count = 0;
+
+	count = intel_dma_get_src_addr(dw_dma->txchan) - dbuf->dma_addr
+			- xmit->tail;
+
+	/* Update the circ buf info */
+	xmit->tail += dbuf->ofs;
+	xmit->tail &= UART_XMIT_SIZE - 1;
+	up->port.icount.tx += dbuf->ofs;
+
+	dbuf->ofs = 0;
+
+	clear_bit(flag_tx_on, &up->flags);
+
+	if (!uart_circ_empty(xmit) && !uart_tx_stopped(&up->port)) {
+		spin_lock_irqsave(&up->port.lock, flags);
+		serial_sched_cmd(up, qcmd_start_tx);
+		spin_unlock_irqrestore(&up->port.lock, flags);
+	}
+
+	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
+		uart_write_wakeup(&up->port);
+}
+
+static void dw_dma_start_tx(struct uart_hsu_port *up)
+{
+	struct dw_dma_priv *dw_dma = up->dma_priv;
+	struct dma_async_tx_descriptor *txdesc = NULL;
+	struct dma_chan *txchan;
+	struct dma_slave_config *txconf;
+	struct hsu_dma_buffer *dbuf = &up->txbuf;
+	struct circ_buf *xmit = &up->port.state->xmit;
+	int count;
+	enum dma_ctrl_flags		flag;
+
+	txchan = dw_dma->txchan;
+	txconf = &dw_dma->txs.dma_slave;
+
+	if (uart_circ_empty(xmit) || uart_tx_stopped(&up->port)) {
+		if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
+			uart_write_wakeup(&up->port);
+		return;
+	}
+
+	/*
+	 * Need to check if FCR is set, better to be set only once when
+	 * use_dma == 1
+	 */
+
+	set_bit(flag_tx_on, &up->flags);
+	count = CIRC_CNT_TO_END(xmit->head, xmit->tail, UART_XMIT_SIZE);
+
+	if (count >= 2000)
+		count = 2000;
+
+	dbuf->ofs = count;
+
+
+	if (!count) {
+		pr_err("we see a case of TX Len == 0!!!\n\n");
+		dump_stack();
+		clear_bit(flag_tx_on, &up->flags);
+		return;
+	}
+
+	/* 2. Prepare the TX dma transfer */
+	txconf->direction = DMA_TO_DEVICE;
+	txconf->dst_addr = dw_dma->dma_addr;
+	txconf->src_maxburst = LNW_DMA_MSIZE_8;
+	txconf->dst_maxburst = LNW_DMA_MSIZE_8;
+	txconf->src_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+	txconf->dst_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+
+	txchan->device->device_control(txchan, DMA_SLAVE_CONFIG,
+				       (unsigned long) txconf);
+
+	dma_sync_single_for_device(up->port.dev,
+					   dbuf->dma_addr,
+					   dbuf->dma_size,
+					   DMA_TO_DEVICE);
+
+	flag = DMA_PREP_INTERRUPT | DMA_COMPL_SKIP_DEST_UNMAP | DMA_CTRL_ACK;
+
+	txdesc = txchan->device->device_prep_dma_memcpy(
+					txchan,		/* DMA Channel */
+					dw_dma->dma_addr,	/* DAR */
+					dbuf->dma_addr + xmit->tail, /* SAR */
+					count,		/* Data len */
+					flag);		/* Flag */
+	if (!txdesc) {
+		pr_warn("DW HSU: fail to prepare TX DMA operation\n");
+		return;
+	}
+
+	txdesc->callback = dw_dma_tx_done;
+	txdesc->callback_param = dw_dma;
+	txdesc->tx_submit(txdesc);
+}
+
+static void dw_dma_stop_tx(struct uart_hsu_port *up)
+{
+	struct dw_dma_priv *dw_dma = up->dma_priv;
+	struct dma_chan *txchan = dw_dma->txchan;
+	struct hsu_dma_buffer *dbuf = &up->txbuf;
+	int ret;
+	int count;
+
+	if (!test_bit(flag_tx_on, &up->flags))
+		return;
+
+	count = intel_dma_get_src_addr(dw_dma->txchan) - dbuf->dma_addr;
+
+	/* ? this may be sleepable */
+	ret = txchan->device->device_control(txchan, DMA_TERMINATE_ALL, 0);
+	if (ret)
+		dev_warn(up->dev, "Fail to stop DMA RX channel!\n");
+}
+
+static void dw_dma_rx_done(void *arg)
+{
+	struct dw_dma_priv *dw_dma = arg;
+	struct uart_hsu_port *up = dw_dma->up;
+	struct hsu_dma_buffer *dbuf = &up->rxbuf;
+	struct uart_port *port = &up->port;
+	struct tty_struct *tty;
+	struct tty_port *tport = &port->state->port;
+	int count;
+	unsigned long flags;
+
+	tty = tty_port_tty_get(&up->port.state->port);
+	if (!tty)
+		return;
+
+	dma_sync_single_for_cpu(port->dev, dbuf->dma_addr,
+			dbuf->dma_size, DMA_FROM_DEVICE);
+
+	count = dbuf->ofs;
+	tty_insert_flip_string(tport, dbuf->buf, count);
+	port->icount.rx += count;
+
+	/* Do we really need it for x86? */
+	dma_sync_single_for_device(up->port.dev, dbuf->dma_addr,
+			dbuf->dma_size, DMA_FROM_DEVICE);
+
+	tty_flip_buffer_push(tport);
+	tty_kref_put(tty);
+
+	clear_bit(flag_rx_on, &up->flags);
+
+	spin_lock_irqsave(&up->port.lock, flags);
+	if (test_bit(flag_rx_pending, &up->flags))
+		serial_sched_cmd(up, qcmd_start_rx);
+	spin_unlock_irqrestore(&up->port.lock, flags);
+
+}
+
+
+static void dw_dma_start_rx(struct uart_hsu_port *up)
+{
+	struct dma_async_tx_descriptor *rxdesc = NULL;
+	struct dw_dma_priv *dw_dma = up->dma_priv;
+	struct hsu_dma_buffer *dbuf = &up->rxbuf;
+	struct dma_chan *rxchan = dw_dma->rxchan;
+	struct dma_slave_config *rxconf = &dw_dma->rxs.dma_slave;
+	enum dma_ctrl_flags flag;
+
+	if (test_and_set_bit(flag_rx_on, &up->flags)) {
+		set_bit(flag_rx_pending, &up->flags);
+		return;
+	}
+
+	dbuf->ofs = 2048 - 64;
+
+	/* Prepare the RX dma transfer */
+	rxconf->direction = DMA_FROM_DEVICE;
+	rxconf->src_addr = dw_dma->dma_addr;
+	rxconf->dst_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+	rxconf->src_addr_width = DMA_SLAVE_BUSWIDTH_1_BYTE;
+
+	/* feng: better to calculate a best size */
+	rxconf->src_maxburst = LNW_DMA_MSIZE_8;
+	rxconf->dst_maxburst = LNW_DMA_MSIZE_8;
+
+	rxchan->device->device_control(rxchan, DMA_SLAVE_CONFIG,
+				       (unsigned long) rxconf);
+	flag = DMA_PREP_INTERRUPT | DMA_COMPL_SKIP_DEST_UNMAP | DMA_CTRL_ACK;
+	rxdesc = rxchan->device->device_prep_dma_memcpy(
+					rxchan,			/* DMA chan */
+					dbuf->dma_addr,		/* DAR */
+					dw_dma->dma_addr,	/* SAR */
+					dbuf->ofs,		/* data len */
+					flag);
+	if (!rxdesc) {
+		pr_warn("DW HSU: fail to prepare TX DMA operation\n");
+		return;
+	}
+
+	rxdesc->callback = dw_dma_rx_done;
+	rxdesc->callback_param = dw_dma;
+	rxdesc->tx_submit(rxdesc);
+}
+
+static void dw_dma_stop_rx(struct uart_hsu_port *up)
+{
+	struct dw_dma_priv *dw_dma = up->dma_priv;
+	struct hsu_dma_buffer *dbuf = &up->rxbuf;
+	struct dma_chan *rxchan = dw_dma->rxchan;
+	int count, ret;
+	struct uart_port *port = &up->port;
+	struct tty_struct *tty;
+	struct tty_port *tport = &port->state->port;
+
+	if (!test_bit(flag_rx_on, &up->flags)) {
+		clear_bit(flag_rx_pending, &up->flags);
+		return;
+	}
+
+	ret = rxchan->device->device_control(rxchan, DMA_TERMINATE_ALL, 0);
+	if (ret) {
+		WARN(1, "DMA TERMINATE of TX returns error\n");
+		return;
+	}
+
+	tty = tty_port_tty_get(&up->port.state->port);
+	if (!tty)
+		return;
+
+	count = intel_dma_get_dst_addr(rxchan) - dbuf->dma_addr;
+	if (!count)
+		goto exit;
+
+	dma_sync_single_for_cpu(port->dev, dbuf->dma_addr,
+		dbuf->dma_size, DMA_FROM_DEVICE);
+
+	tty_insert_flip_string(tport, dbuf->buf, count);
+	port->icount.rx += count;
+
+	/* Do we really need it for x86? */
+	dma_sync_single_for_device(up->port.dev, dbuf->dma_addr,
+			dbuf->dma_size, DMA_FROM_DEVICE);
+
+	tty_flip_buffer_push(tport);
+
+exit:
+	tty_kref_put(tty);
+	clear_bit(flag_rx_on, &up->flags);
+	clear_bit(flag_rx_pending, &up->flags);
+}
+
+struct hsu_dma_ops dw_dma_ops = {
+	.init =		dw_dma_init,
+	.exit =		dw_dma_exit,
+	.suspend =	dw_dma_suspend,
+	.resume	=	dw_dma_resume,
+	.start_tx =	dw_dma_start_tx,
+	.stop_tx =	dw_dma_stop_tx,
+	.start_rx =	dw_dma_start_rx,
+	.stop_rx =	dw_dma_stop_rx,
+};
+
+struct hsu_dma_ops *pdw_dma_ops = &dw_dma_ops;
+
+#else
+struct hsu_dma_ops *pdw_dma_ops = NULL;
+#endif
+
+/* Intel DMA ops */
+
+/* The buffer is already cache coherent */
+void hsu_dma_start_rx_chan(struct hsu_dma_chan *rxc,
+			struct hsu_dma_buffer *dbuf)
+{
+	dbuf->ofs = 0;
+
+	chan_writel(rxc, HSU_CH_BSR, HSU_DMA_BSR);
+	chan_writel(rxc, HSU_CH_MOTSR, HSU_DMA_MOTSR);
+
+	chan_writel(rxc, HSU_CH_D0SAR, dbuf->dma_addr);
+	chan_writel(rxc, HSU_CH_D0TSR, dbuf->dma_size);
+	chan_writel(rxc, HSU_CH_DCR, 0x1 | (0x1 << 8)
+					 | (0x1 << 16)
+					 | (0x1 << 24)	/* timeout, Errata 1 */
+					 );
+	chan_writel(rxc, HSU_CH_CR, 0x3);
+}
+
+static int intel_dma_init(struct uart_hsu_port *up)
+{
+	int ret;
+
+	clear_bit(flag_tx_on, &up->flags);
+
+	ret = dma_init_common(up);
+	if (ret)
+		return ret;
+
+	/* This should not be changed all around */
+	chan_writel(up->txc, HSU_CH_BSR, HSU_DMA_BSR);
+	chan_writel(up->txc, HSU_CH_MOTSR, HSU_DMA_MOTSR);
+
+	/* Start the RX channel right now */
+	hsu_dma_start_rx_chan(up->rxc, &up->rxbuf);
+
+	up->dma_inited = 1;
+	return 0;
+}
+
+static int intel_dma_exit(struct uart_hsu_port *up)
+{
+	chan_writel(up->txc, HSU_CH_CR, 0x0);
+	clear_bit(flag_tx_on, &up->flags);
+	chan_writel(up->rxc, HSU_CH_CR, 0x2);
+	dma_exit_common(up);
+
+	up->dma_inited = 0;
+	return 0;
+}
+
+
+static void intel_dma_start_tx(struct uart_hsu_port *up)
+{
+	struct circ_buf *xmit = &up->port.state->xmit;
+	struct hsu_dma_buffer *dbuf = &up->txbuf;
+	unsigned long flags;
+	int count;
+
+	spin_lock_irqsave(&up->port.lock, flags);
+	chan_writel(up->txc, HSU_CH_CR, 0x0);
+	while (chan_readl(up->txc, HSU_CH_CR))
+		cpu_relax();
+	clear_bit(flag_tx_on, &up->flags);
+	if (dbuf->ofs) {
+		u32 real = chan_readl(up->txc, HSU_CH_D0SAR) - up->tx_addr;
+
+		/* we found in flow control case, TX irq came without sending
+		 * all TX buffer
+		 */
+		if (real < dbuf->ofs)
+			dbuf->ofs = real; /* adjust to real chars sent */
+
+		/* Update the circ buf info */
+		xmit->tail += dbuf->ofs;
+		xmit->tail &= UART_XMIT_SIZE - 1;
+
+		up->port.icount.tx += dbuf->ofs;
+		dbuf->ofs = 0;
+	}
+
+	if (!uart_circ_empty(xmit) && !uart_tx_stopped(&up->port)) {
+		set_bit(flag_tx_on, &up->flags);
+		dma_sync_single_for_device(up->port.dev,
+					   dbuf->dma_addr,
+					   dbuf->dma_size,
+					   DMA_TO_DEVICE);
+
+		count = CIRC_CNT_TO_END(xmit->head, xmit->tail, UART_XMIT_SIZE);
+		dbuf->ofs = count;
+
+		/* Reprogram the channel */
+		up->tx_addr = dbuf->dma_addr + xmit->tail;
+		chan_writel(up->txc, HSU_CH_D0SAR, up->tx_addr);
+		chan_writel(up->txc, HSU_CH_D0TSR, count);
+
+		/* Reenable the channel */
+		chan_writel(up->txc, HSU_CH_DCR, 0x1
+						 | (0x1 << 8)
+						 | (0x1 << 16));
+		chan_writel(up->txc, HSU_CH_CR, 0x1);
+	}
+
+	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
+		uart_write_wakeup(&up->port);
+
+	spin_unlock_irqrestore(&up->port.lock, flags);
+	return;
+}
+
+static void intel_dma_stop_tx(struct uart_hsu_port *up)
+{
+	chan_writel(up->txc, HSU_CH_CR, 0x0);
+	return;
+}
+
+static void intel_dma_start_rx(struct uart_hsu_port *up)
+{
+	return;
+}
+
+static void intel_dma_stop_rx(struct uart_hsu_port *up)
+{
+	chan_writel(up->rxc, HSU_CH_CR, 0x2);
+	return;
+}
+
+static void intel_dma_context_op(struct uart_hsu_port *up, int op)
+{
+	if (op == context_save) {
+		up->txc->cr  = chan_readl(up->txc, HSU_CH_CR);
+		up->txc->dcr = chan_readl(up->txc, HSU_CH_DCR);
+		up->txc->sar = chan_readl(up->txc, HSU_CH_D0SAR);
+		up->txc->tsr = chan_readl(up->txc, HSU_CH_D0TSR);
+
+		up->rxc->cr  = chan_readl(up->rxc, HSU_CH_CR);
+		up->rxc->dcr = chan_readl(up->rxc, HSU_CH_DCR);
+		up->rxc->sar = chan_readl(up->rxc, HSU_CH_D0SAR);
+		up->rxc->tsr = chan_readl(up->rxc, HSU_CH_D0TSR);
+	} else {
+		chan_writel(up->txc, HSU_CH_DCR, up->txc->dcr);
+		chan_writel(up->txc, HSU_CH_D0SAR, up->txc->sar);
+		chan_writel(up->txc, HSU_CH_D0TSR, up->txc->tsr);
+		chan_writel(up->txc, HSU_CH_BSR, HSU_DMA_BSR);
+		chan_writel(up->txc, HSU_CH_MOTSR, HSU_DMA_MOTSR);
+
+		chan_writel(up->rxc, HSU_CH_DCR, up->rxc->dcr);
+		chan_writel(up->rxc, HSU_CH_D0SAR, up->rxc->sar);
+		chan_writel(up->rxc, HSU_CH_D0TSR, up->rxc->tsr);
+		chan_writel(up->rxc, HSU_CH_BSR, HSU_DMA_BSR);
+		chan_writel(up->rxc, HSU_CH_MOTSR, HSU_DMA_MOTSR);
+	}
+}
+
+
+static int intel_dma_resume(struct uart_hsu_port *up)
+{
+	chan_writel(up->rxc, HSU_CH_CR, up->rxc_chcr_save);
+	return 0;
+}
+
+static int intel_dma_suspend(struct uart_hsu_port *up)
+{
+	int loop = 100000;
+	struct hsu_dma_chan *chan = up->rxc;
+
+	up->rxc_chcr_save = chan_readl(up->rxc, HSU_CH_CR);
+
+	if (test_bit(flag_startup, &up->flags)
+			&& serial_in(up, UART_FOR) & 0x7F) {
+		dev_err(up->dev, "ignore suspend for rx fifo\n");
+		return -1;
+	}
+
+	if (chan_readl(up->txc, HSU_CH_CR)) {
+		dev_info(up->dev, "ignore suspend for tx dma\n");
+		return -1;
+	}
+
+	chan_writel(up->rxc, HSU_CH_CR, 0x2);
+	while (--loop) {
+		if (chan_readl(up->rxc, HSU_CH_CR) == 0x2)
+			break;
+		cpu_relax();
+	}
+
+	if (!loop) {
+		dev_err(up->dev, "Can't stop rx dma\n");
+		return -1;
+	}
+
+	if (chan_readl(chan, HSU_CH_D0SAR) - up->rxbuf.dma_addr) {
+		dev_err(up->dev, "ignore suspend for dma pointer\n");
+		return -1;
+	}
+
+	return 0;
+}
+
+struct hsu_dma_ops intel_dma_ops = {
+	.init =		intel_dma_init,
+	.exit =		intel_dma_exit,
+	.suspend =	intel_dma_suspend,
+	.resume	=	intel_dma_resume,
+	.start_tx =	intel_dma_start_tx,
+	.stop_tx =	intel_dma_stop_tx,
+	.start_rx =	intel_dma_start_rx,
+	.stop_rx =	intel_dma_stop_rx,
+	.context_op =	intel_dma_context_op,
+};
+
+
diff --git a/drivers/tty/serial/mfd_pci.c b/drivers/tty/serial/mfd_pci.c
new file mode 100644
index 0000000..b876e87
--- /dev/null
+++ b/drivers/tty/serial/mfd_pci.c
@@ -0,0 +1,297 @@
+/*
+ * mfd_pci.c: driver for High Speed UART device of Intel Medfield platform
+ *
+ * Refer pxa.c, 8250.c and some other drivers in drivers/serial/
+ *
+ * (C) Copyright 2010 Intel Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+/* Notes:
+ * 1. DMA channel allocation: 0/1 channel are assigned to port 0,
+ *    2/3 chan to port 1, 4/5 chan to port 3. Even number chans
+ *    are used for RX, odd chans for TX
+ *
+ * 2. The RI/DSR/DCD/DTR are not pinned out, DCD & DSR are always
+ *    asserted, only when the HW is reset the DDCD and DDSR will
+ *    be triggered
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/io.h>
+#include <linux/pm_runtime.h>
+#include <linux/intel_mid_pm.h>
+#include <linux/pm_qos.h>
+
+#include "mfd.h"
+
+#ifdef CONFIG_PM
+static int serial_hsu_pci_suspend(struct device *dev)
+{
+	struct pci_dev *pdev = container_of(dev, struct pci_dev, dev);
+	struct uart_hsu_port *up = pci_get_drvdata(pdev);
+	int ret = 0;
+
+	if (up) {
+		trace_hsu_func_start(up->index, __func__);
+		ret = serial_hsu_do_suspend(up);
+		trace_hsu_func_end(up->index, __func__, "");
+	}
+	return ret;
+}
+
+static int serial_hsu_pci_resume(struct device *dev)
+{
+	struct pci_dev *pdev = container_of(dev, struct pci_dev, dev);
+	struct uart_hsu_port *up = pci_get_drvdata(pdev);
+	int ret = 0;
+
+	if (up) {
+		trace_hsu_func_start(up->index, __func__);
+		ret = serial_hsu_do_resume(up);
+		trace_hsu_func_end(up->index, __func__, "");
+	}
+	return ret;
+}
+#else
+#define serial_hsu_pci_suspend	NULL
+#define serial_hsu_pci_resume	NULL
+#endif
+
+#ifdef CONFIG_PM_RUNTIME
+static int serial_hsu_pci_runtime_idle(struct device *dev)
+{
+	struct pci_dev *pdev = container_of(dev, struct pci_dev, dev);
+	struct uart_hsu_port *up = pci_get_drvdata(pdev);
+
+	return serial_hsu_do_runtime_idle(up);
+}
+
+static int serial_hsu_pci_runtime_suspend(struct device *dev)
+{
+	struct pci_dev *pdev = container_of(dev, struct pci_dev, dev);
+	struct uart_hsu_port *up = pci_get_drvdata(pdev);
+	int ret = 0;
+
+	trace_hsu_func_start(up->index, __func__);
+	ret = serial_hsu_do_suspend(up);
+	trace_hsu_func_end(up->index, __func__, "");
+	return ret;
+}
+
+static int serial_hsu_pci_runtime_resume(struct device *dev)
+{
+	struct pci_dev *pdev = container_of(dev, struct pci_dev, dev);
+	struct uart_hsu_port *up = pci_get_drvdata(pdev);
+	int ret = 0;
+
+	trace_hsu_func_start(up->index, __func__);
+	ret = serial_hsu_do_resume(up);
+	trace_hsu_func_end(up->index, __func__, "");
+	return ret;
+}
+#else
+#define serial_hsu_pci_runtime_idle		NULL
+#define serial_hsu_pci_runtime_suspend	NULL
+#define serial_hsu_pci_runtime_resume	NULL
+#endif
+
+static const struct dev_pm_ops serial_hsu_pci_pm_ops = {
+
+	SET_SYSTEM_SLEEP_PM_OPS(serial_hsu_pci_suspend,
+				serial_hsu_pci_resume)
+	SET_RUNTIME_PM_OPS(serial_hsu_pci_runtime_suspend,
+				serial_hsu_pci_runtime_resume,
+				serial_hsu_pci_runtime_idle)
+};
+
+DEFINE_PCI_DEVICE_TABLE(hsuart_port_pci_ids) = {
+	{ PCI_VDEVICE(INTEL, 0x081B), hsu_port0 },
+	{ PCI_VDEVICE(INTEL, 0x081C), hsu_port1 },
+	{ PCI_VDEVICE(INTEL, 0x081D), hsu_port2 },
+	/* Cloverview support */
+	{ PCI_VDEVICE(INTEL, 0x08FC), hsu_port0 },
+	{ PCI_VDEVICE(INTEL, 0x08FD), hsu_port1 },
+	{ PCI_VDEVICE(INTEL, 0x08FE), hsu_port2 },
+	/* Tangier support */
+	{ PCI_VDEVICE(INTEL, 0x1191), hsu_port0 },
+	/* VLV2 support */
+	{ PCI_VDEVICE(INTEL, 0x0F0A), hsu_port0 },
+	{ PCI_VDEVICE(INTEL, 0x0F0C), hsu_port1 },
+	/* CHV support */
+	{ PCI_VDEVICE(INTEL, 0x228A), hsu_port0 },
+	{ PCI_VDEVICE(INTEL, 0x228C), hsu_port1 },
+	{},
+};
+
+DEFINE_PCI_DEVICE_TABLE(hsuart_dma_pci_ids) = {
+	{ PCI_VDEVICE(INTEL, 0x081E), hsu_dma },
+	/* Cloverview support */
+	{ PCI_VDEVICE(INTEL, 0x08FF), hsu_dma },
+	/* Tangier support */
+	{ PCI_VDEVICE(INTEL, 0x1192), hsu_dma },
+	{},
+};
+
+static int serial_hsu_pci_port_probe(struct pci_dev *pdev,
+				const struct pci_device_id *ent)
+{
+	struct uart_hsu_port *up;
+	int ret, port, hw_type;
+	resource_size_t start, len;
+
+	start = pci_resource_start(pdev, 0);
+	len = pci_resource_len(pdev, 0);
+
+	dev_info(&pdev->dev,
+		"FUNC: %d driver: %ld addr:%lx len:%lx\n",
+		PCI_FUNC(pdev->devfn), ent->driver_data,
+		(unsigned long) start, (unsigned long) len);
+
+	port = intel_mid_hsu_func_to_port(PCI_FUNC(pdev->devfn));
+	if (port == -1)
+		return 0;
+
+	ret = pci_enable_device(pdev);
+	if (ret)
+		return ret;
+
+	ret = pci_request_region(pdev, 0, "hsu");
+	if (ret)
+		goto err;
+
+	up = serial_hsu_port_setup(&pdev->dev, port, start, len,
+			pdev->irq);
+	if (IS_ERR(up))
+		goto err;
+
+	pci_set_drvdata(pdev, up);
+
+	pm_runtime_put_noidle(&pdev->dev);
+	pm_runtime_forbid(&pdev->dev);
+	return 0;
+err:
+	pci_disable_device(pdev);
+	return ret;
+}
+
+static void serial_hsu_pci_port_remove(struct pci_dev *pdev)
+{
+	struct uart_hsu_port *up = pci_get_drvdata(pdev);
+
+	pm_runtime_forbid(&pdev->dev);
+	pm_runtime_get_noresume(&pdev->dev);
+	serial_hsu_port_free(up);
+	pci_set_drvdata(pdev, NULL);
+	pci_disable_device(pdev);
+}
+
+static void serial_hsu_pci_port_shutdown(struct pci_dev *pdev)
+{
+	struct uart_hsu_port *up = pci_get_drvdata(pdev);
+
+	if (!up)
+		return;
+
+	serial_hsu_port_shutdown(up);
+}
+
+static struct pci_driver hsu_port_pci_driver = {
+	.name =		"HSU serial",
+	.id_table =	hsuart_port_pci_ids,
+	.probe =	serial_hsu_pci_port_probe,
+	.remove =	serial_hsu_pci_port_remove,
+	.shutdown =	serial_hsu_pci_port_shutdown,
+/* Disable PM only when kgdb(poll mode uart) is enabled */
+#if defined(CONFIG_PM) && !defined(CONFIG_CONSOLE_POLL)
+	.driver = {
+		.pm = &serial_hsu_pci_pm_ops,
+	},
+#endif
+};
+
+static int serial_hsu_pci_dma_probe(struct pci_dev *pdev,
+				const struct pci_device_id *ent)
+{
+	struct hsu_dma_chan *dchan;
+	int ret, share_irq = 0;
+	resource_size_t start, len;
+
+	start = pci_resource_start(pdev, 0);
+	len = pci_resource_len(pdev, 0);
+
+	dev_info(&pdev->dev,
+		"FUNC: %d driver: %ld addr:%lx len:%lx\n",
+		PCI_FUNC(pdev->devfn), ent->driver_data,
+		(unsigned long) pci_resource_start(pdev, 0),
+		(unsigned long) pci_resource_len(pdev, 0));
+
+	ret = pci_enable_device(pdev);
+	if (ret)
+		return ret;
+
+	ret = pci_request_region(pdev, 0, "hsu dma");
+	if (ret)
+		goto err;
+
+	/* share irq with port? ANN all and TNG chip from B0 stepping */
+	if ((intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_TANGIER &&
+		pdev->revision >= 0x1))
+		share_irq = 1;
+
+	ret = serial_hsu_dma_setup(&pdev->dev, start, len, pdev->irq, share_irq);
+	if (ret)
+		goto err;
+
+	return 0;
+err:
+	pci_disable_device(pdev);
+	return ret;
+}
+
+static void serial_hsu_pci_dma_remove(struct pci_dev *pdev)
+{
+	serial_hsu_dma_free();
+	pci_disable_device(pdev);
+	pci_unregister_driver(&hsu_port_pci_driver);
+}
+
+static struct pci_driver hsu_dma_pci_driver = {
+	.name =		"HSU DMA",
+	.id_table =	hsuart_dma_pci_ids,
+	.probe =	serial_hsu_pci_dma_probe,
+	.remove =	serial_hsu_pci_dma_remove,
+};
+
+static int __init hsu_pci_init(void)
+{
+	int ret;
+
+	ret = pci_register_driver(&hsu_dma_pci_driver);
+	if (!ret) {
+		ret = pci_register_driver(&hsu_port_pci_driver);
+		if (ret)
+			pci_unregister_driver(&hsu_dma_pci_driver);
+	}
+
+	return ret;
+}
+
+static void __exit hsu_pci_exit(void)
+{
+	pci_unregister_driver(&hsu_port_pci_driver);
+	pci_unregister_driver(&hsu_dma_pci_driver);
+}
+
+module_init(hsu_pci_init);
+module_exit(hsu_pci_exit);
+
+MODULE_AUTHOR("Yang Bin <bin.yang@intel.com>");
+MODULE_LICENSE("GPL v2");
+MODULE_ALIAS("platform:medfield-hsu");
diff --git a/drivers/tty/serial/mfd_plat.c b/drivers/tty/serial/mfd_plat.c
new file mode 100644
index 0000000..261acd5
--- /dev/null
+++ b/drivers/tty/serial/mfd_plat.c
@@ -0,0 +1,244 @@
+/*
+ * mfd_plat.c: driver for High Speed UART device of Intel Medfield platform
+ *
+ * (C) Copyright 2013 Intel Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; version 2
+ * of the License.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/platform_device.h>
+#include <linux/io.h>
+#include <linux/pm_runtime.h>
+#include <linux/acpi.h>
+#include <linux/intel_mid_pm.h>
+#include <linux/pm_qos.h>
+#include <linux/pci.h>
+
+#include "mfd.h"
+
+#ifdef CONFIG_ACPI
+static const struct acpi_device_id hsu_acpi_ids[] = {
+	{ "80860F0A", 0 },
+	{ "8086228A", 0 },
+	{ }
+};
+MODULE_DEVICE_TABLE(acpi, hsu_acpi_ids);
+#endif
+
+#ifdef CONFIG_PM
+static int serial_hsu_plat_suspend(struct device *dev)
+{
+	struct uart_hsu_port *up = dev_get_drvdata(dev);
+	int ret = 0;
+
+	if (up) {
+		trace_hsu_func_start(up->index, __func__);
+		ret = serial_hsu_do_suspend(up);
+		trace_hsu_func_end(up->index, __func__, "");
+	}
+	return ret;
+}
+
+static int serial_hsu_plat_resume(struct device *dev)
+{
+	struct uart_hsu_port *up = dev_get_drvdata(dev);
+	int ret = 0;
+
+	if (up) {
+		trace_hsu_func_start(up->index, __func__);
+		ret = serial_hsu_do_resume(up);
+		trace_hsu_func_end(up->index, __func__, "");
+	}
+	return ret;
+}
+#else
+#define serial_hsu_plat_suspend	NULL
+#define serial_hsu_plat_resume	NULL
+#endif
+
+#ifdef CONFIG_PM_RUNTIME
+static int serial_hsu_plat_runtime_idle(struct device *dev)
+{
+	struct uart_hsu_port *up = dev_get_drvdata(dev);
+
+	return serial_hsu_do_runtime_idle(up);
+}
+
+static int serial_hsu_plat_runtime_suspend(struct device *dev)
+{
+	struct uart_hsu_port *up = dev_get_drvdata(dev);
+	int ret = 0;
+
+	trace_hsu_func_start(up->index, __func__);
+	ret = serial_hsu_do_suspend(up);
+	trace_hsu_func_end(up->index, __func__, "");
+	return ret;
+}
+
+static int serial_hsu_plat_runtime_resume(struct device *dev)
+{
+	struct uart_hsu_port *up = dev_get_drvdata(dev);
+	int ret = 0;
+
+	trace_hsu_func_start(up->index, __func__);
+	ret = serial_hsu_do_resume(up);
+	trace_hsu_func_end(up->index, __func__, "");
+	return ret;
+}
+#else
+#define serial_hsu_plat_runtime_idle		NULL
+#define serial_hsu_plat_runtime_suspend	NULL
+#define serial_hsu_plat_runtime_resume	NULL
+#endif
+
+static const struct dev_pm_ops serial_hsu_plat_pm_ops = {
+
+	SET_SYSTEM_SLEEP_PM_OPS(serial_hsu_plat_suspend,
+				serial_hsu_plat_resume)
+	SET_RUNTIME_PM_OPS(serial_hsu_plat_runtime_suspend,
+				serial_hsu_plat_runtime_resume,
+				serial_hsu_plat_runtime_idle)
+};
+
+static int serial_hsu_plat_port_probe(struct platform_device *pdev)
+{
+	struct uart_hsu_port *up;
+	int port = pdev->id, irq;
+	struct resource *mem, *ioarea;
+	const struct acpi_device_id *id;
+	resource_size_t start, len;
+
+#ifdef CONFIG_ACPI
+	for (id = hsu_acpi_ids; id->id[0]; id++)
+		if (!strncmp(id->id, dev_name(&pdev->dev), strlen(id->id))) {
+			acpi_status status;
+			unsigned long long tmp;
+
+			status = acpi_evaluate_integer(ACPI_HANDLE(&pdev->dev),
+					"_UID", NULL, &tmp);
+			if (ACPI_FAILURE(status))
+				return -ENODEV;
+			port = tmp - 1;
+		}
+#endif
+
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!mem) {
+		dev_err(&pdev->dev, "no mem resource?\n");
+		return -EINVAL;
+	}
+	start = mem->start;
+	len = resource_size(mem);
+
+	irq = platform_get_irq(pdev, 0);
+	if (irq < 0) {
+		dev_err(&pdev->dev, "no irq resource?\n");
+		return irq; /* -ENXIO */
+	}
+
+	ioarea = request_mem_region(mem->start, resource_size(mem),
+			pdev->name);
+	if (!ioarea) {
+		dev_err(&pdev->dev, "HSU region already claimed\n");
+		return -EBUSY;
+	}
+
+	up = serial_hsu_port_setup(&pdev->dev, port, start, len,
+			irq);
+	if (IS_ERR(up)) {
+		release_mem_region(mem->start, resource_size(mem));
+		dev_err(&pdev->dev, "failed to setup HSU\n");
+		return -EINVAL;
+	}
+
+	platform_set_drvdata(pdev, up);
+
+	if (!pdev->dev.dma_mask) {
+		pdev->dev.dma_mask = &pdev->dev.coherent_dma_mask;
+		pdev->dev.coherent_dma_mask = DMA_BIT_MASK(32);
+	}
+	dma_set_mask(&pdev->dev, DMA_BIT_MASK(32));
+
+	pm_runtime_set_active(&pdev->dev);
+	pm_runtime_enable(&pdev->dev);
+	pm_runtime_allow(&pdev->dev);
+
+	return 0;
+}
+
+static int serial_hsu_plat_port_remove(struct platform_device *pdev)
+{
+	struct uart_hsu_port *up = platform_get_drvdata(pdev);
+	struct resource *mem;
+
+	pm_runtime_forbid(&pdev->dev);
+	serial_hsu_port_free(up);
+	platform_set_drvdata(pdev, NULL);
+	mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (mem)
+		release_mem_region(mem->start, resource_size(mem));
+
+	return 0;
+}
+
+static void serial_hsu_plat_port_shutdown(struct platform_device *pdev)
+{
+	struct uart_hsu_port *up = platform_get_drvdata(pdev);
+
+	if (!up)
+		return;
+
+	serial_hsu_port_shutdown(up);
+}
+
+static struct platform_driver hsu_plat_driver = {
+	.remove		= serial_hsu_plat_port_remove,
+	.shutdown 	= serial_hsu_plat_port_shutdown,
+	.driver		= {
+		.name	= "HSU serial",
+		.owner	= THIS_MODULE,
+/* Disable PM only when kgdb(poll mode uart) is enabled */
+#if defined(CONFIG_PM) && !defined(CONFIG_CONSOLE_POLL)
+		.pm     = &serial_hsu_plat_pm_ops,
+#endif
+#ifdef CONFIG_ACPI
+		.acpi_match_table = ACPI_PTR(hsu_acpi_ids),
+#endif
+	},
+};
+
+static int __init hsu_plat_init(void)
+{
+	struct pci_dev *hsu_pci;
+
+	/*
+	 * Try to get pci device, if exist, then exit ACPI platform
+	 * register, On BYT FDK, include two enum mode: PCI, ACPI,
+	 * ignore ACPI enum mode.
+	 */
+	hsu_pci = pci_get_device(PCI_VENDOR_ID_INTEL, 0x0F0A, NULL);
+	if (hsu_pci) {
+		pr_info("HSU serial: Find HSU controller in PCI device, "
+			"exit ACPI platform register!\n");
+		return 0;
+	}
+
+	return platform_driver_probe(&hsu_plat_driver, serial_hsu_plat_port_probe);
+}
+
+static void __exit hsu_plat_exit(void)
+{
+	platform_driver_unregister(&hsu_plat_driver);
+}
+
+module_init(hsu_plat_init);
+module_exit(hsu_plat_exit);
+
+MODULE_AUTHOR("Jason Chen <jason.cj.chen@intel.com>");
+MODULE_LICENSE("GPL v2");
+MODULE_ALIAS("platform:medfield-hsu-plat");
diff --git a/drivers/tty/serial/mfd_trace.h b/drivers/tty/serial/mfd_trace.h
new file mode 100644
index 0000000..49afd9b
--- /dev/null
+++ b/drivers/tty/serial/mfd_trace.h
@@ -0,0 +1,197 @@
+#undef TRACE_INCLUDE_PATH
+#undef TRACE_INCLUDE_FILE
+#define TRACE_INCLUDE_PATH .
+#define TRACE_INCLUDE_FILE mfd_trace
+
+#define TRACE_SYSTEM hsu
+
+#if !defined(_TRACE_HSU_H) || defined(TRACE_HEADER_MULTI_READ)
+#define _TRACE_HSU_H
+
+#include <linux/tracepoint.h>
+
+#define hsucmd_name(cmd) { cmd, #cmd }
+#define show_hsucmd_name(val)			\
+	__print_symbolic(val,			\
+		hsucmd_name(qcmd_overflow),	\
+		hsucmd_name(qcmd_get_msr),	\
+		hsucmd_name(qcmd_set_mcr),	\
+		hsucmd_name(qcmd_set_ier),	\
+		hsucmd_name(qcmd_start_rx),	\
+		hsucmd_name(qcmd_stop_rx),	\
+		hsucmd_name(qcmd_start_tx),	\
+		hsucmd_name(qcmd_stop_tx),	\
+		hsucmd_name(qcmd_cl),		\
+		hsucmd_name(qcmd_port_irq),	\
+		hsucmd_name(qcmd_dma_irq),	\
+		hsucmd_name(qcmd_enable_irq),   \
+		hsucmd_name(qcmd_cmd_off))
+
+
+TRACE_EVENT(hsu_cmd_insert,
+
+	TP_PROTO(unsigned port, char cmd),
+
+	TP_ARGS(port, cmd),
+
+	TP_STRUCT__entry(
+		__field(unsigned, port)
+		__field(char, cmd)
+	),
+
+	TP_fast_assign(
+		__entry->port = port;
+		__entry->cmd = cmd;
+	),
+
+	TP_printk("port=%u cmd=%s", __entry->port,
+		show_hsucmd_name(__entry->cmd))
+);
+
+TRACE_EVENT(hsu_cmd_add,
+
+	TP_PROTO(unsigned port, char cmd),
+
+	TP_ARGS(port, cmd),
+
+	TP_STRUCT__entry(
+		__field(unsigned, port)
+		__field(char, cmd)
+	),
+
+	TP_fast_assign(
+		__entry->port = port;
+		__entry->cmd = cmd;
+	),
+
+	TP_printk("port=%u cmd=%s", __entry->port,
+		show_hsucmd_name(__entry->cmd))
+);
+
+TRACE_EVENT(hsu_cmd_start,
+
+	TP_PROTO(unsigned port, char cmd),
+
+	TP_ARGS(port, cmd),
+
+	TP_STRUCT__entry(
+		__field(unsigned, port)
+		__field(char, cmd)
+	),
+
+	TP_fast_assign(
+		__entry->port = port;
+		__entry->cmd = cmd;
+	),
+
+	TP_printk("port=%u cmd=%s", __entry->port,
+		show_hsucmd_name(__entry->cmd))
+);
+
+TRACE_EVENT(hsu_cmd_end,
+
+	TP_PROTO(unsigned port, char cmd),
+
+	TP_ARGS(port, cmd),
+
+	TP_STRUCT__entry(
+		__field(unsigned, port)
+		__field(char, cmd)
+	),
+
+	TP_fast_assign(
+		__entry->port = port;
+		__entry->cmd = cmd;
+	),
+
+	TP_printk("port=%u cmd=%s", __entry->port,
+		show_hsucmd_name(__entry->cmd))
+);
+
+TRACE_EVENT(hsu_func_start,
+
+	TP_PROTO(unsigned port, const char *func),
+
+	TP_ARGS(port, func),
+
+	TP_STRUCT__entry(
+		__field(unsigned, port)
+		__string(name, func)
+	),
+
+	TP_fast_assign(
+		__entry->port = port;
+		__assign_str(name, func);
+	),
+
+	TP_printk("port=%u func=%s", __entry->port,
+		__get_str(name))
+);
+
+TRACE_EVENT(hsu_func_end,
+
+	TP_PROTO(unsigned port, const char *func, char *err),
+
+	TP_ARGS(port, func, err),
+
+	TP_STRUCT__entry(
+		__field(unsigned, port)
+		__string(name, func)
+		__string(ret, err)
+	),
+
+	TP_fast_assign(
+		__entry->port = port;
+		__assign_str(name, func);
+		__assign_str(ret, err);
+	),
+
+	TP_printk("port=%u func=%s err=%s", __entry->port,
+		__get_str(name), __get_str(ret))
+);
+
+TRACE_EVENT(hsu_mctrl,
+
+	TP_PROTO(unsigned port, unsigned mctrl),
+
+	TP_ARGS(port, mctrl),
+
+	TP_STRUCT__entry(
+		__field(unsigned, port)
+		__field(unsigned, mctrl)
+	),
+
+	TP_fast_assign(
+		__entry->port = port;
+		__entry->mctrl = mctrl;
+	),
+
+	TP_printk("port=%u mctrl=%d", __entry->port, __entry->mctrl)
+);
+
+TRACE_EVENT(hsu_set_termios,
+
+	TP_PROTO(unsigned port, unsigned int baud, int ctsrts),
+
+	TP_ARGS(port, baud, ctsrts),
+
+	TP_STRUCT__entry(
+		__field(unsigned, port)
+		__field(unsigned int, baud)
+		__field(int, ctsrts)
+	),
+
+	TP_fast_assign(
+		__entry->port = port;
+		__entry->baud = baud;
+		__entry->ctsrts = ctsrts;
+	),
+
+	TP_printk("port=%u baud=%d ctsrts=%d", __entry->port,
+		__entry->baud, __entry->ctsrts)
+);
+
+#endif /* if !defined(_TRACE_HSU_H) || defined(TRACE_HEADER_MULTI_READ) */
+
+/* This part must be outside protection */
+#include <trace/define_trace.h>
diff --git a/drivers/tty/serial/serial_core.c b/drivers/tty/serial/serial_core.c
index 45a85b5..97e102e 100644
--- a/drivers/tty/serial/serial_core.c
+++ b/drivers/tty/serial/serial_core.c
@@ -89,6 +89,9 @@ static void __uart_start(struct tty_struct *tty)
 	struct uart_state *state = tty->driver_data;
 	struct uart_port *port = state->uart_port;
 
+	if (port->ops->wake_peer)
+		port->ops->wake_peer(port);
+
 	if (!uart_circ_empty(&state->xmit) && state->xmit.buf &&
 	    !tty->stopped && !tty->hw_stopped)
 		port->ops->start_tx(port);
diff --git a/include/linux/intel_mid_pm.h b/include/linux/intel_mid_pm.h
new file mode 100644
index 0000000..4dfaa81
--- /dev/null
+++ b/include/linux/intel_mid_pm.h
@@ -0,0 +1,234 @@
+/*
+ * intel_mid_pm.h
+ * Copyright (c) 2010, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+#include <linux/errno.h>
+
+#ifndef INTEL_MID_PM_H
+#define INTEL_MID_PM_H
+
+#include <asm/intel-mid.h>
+#include <linux/init.h>
+#include <linux/pci.h>
+
+
+/* Chip ID of Intel Atom SOC*/
+#define INTEL_ATOM_MRST 0x26
+#define INTEL_ATOM_MFLD 0x27
+#define INTEL_ATOM_CLV 0x35
+#define INTEL_ATOM_MRFLD 0x4a
+#define INTEL_ATOM_BYT 0x37
+
+static inline int platform_is(u8 model)
+{
+	return (boot_cpu_data.x86_model == model);
+}
+
+/* Register Type definitions */
+#define OSPM_REG_TYPE          0x0
+#define APM_REG_TYPE           0x1
+#define OSPM_MAX_POWER_ISLANDS 16
+#define OSPM_ISLAND_UP         0x0
+#define OSPM_ISLAND_DOWN       0x1
+/*Soft reset*/
+#define OSPM_ISLAND_SR         0x2
+
+/* North complex power islands definitions for APM block*/
+#define APM_GRAPHICS_ISLAND    0x1
+#define APM_VIDEO_DEC_ISLAND   0x2
+#define APM_VIDEO_ENC_ISLAND   0x4
+#define APM_GL3_CACHE_ISLAND   0x8
+#define APM_ISP_ISLAND         0x10
+#define APM_IPH_ISLAND         0x20
+
+/* North complex power islands definitions for OSPM block*/
+#define OSPM_DISPLAY_A_ISLAND  0x2
+#define OSPM_DISPLAY_B_ISLAND  0x80
+#define OSPM_DISPLAY_C_ISLAND  0x100
+#define OSPM_MIPI_ISLAND       0x200
+
+/* North Complex power islands definitions for Tangier */
+#define TNG_ISP_ISLAND		0x1
+/* North Complex Register definitions for Tangier */
+#define	ISP_SS_PM0		0x39
+
+#define C4_STATE_IDX	3
+#define C6_STATE_IDX	4
+#define S0I1_STATE_IDX  5
+#define LPMP3_STATE_IDX 6
+#define S0I3_STATE_IDX  7
+
+#define C4_HINT	(0x30)
+#define C6_HINT	(0x52)
+
+#define CSTATE_EXIT_LATENCY_C1	 1
+#define CSTATE_EXIT_LATENCY_C2	 20
+#define CSTATE_EXIT_LATENCY_C4	 100
+#define CSTATE_EXIT_LATENCY_C6	 140
+
+/* Since entry latency is substantial
+ * put exit_latency = entry+exit latency
+ */
+#ifdef CONFIG_REMOVEME_INTEL_ATOM_MRFLD_POWER
+#define CSTATE_EXIT_LATENCY_S0i1 1200
+#define CSTATE_EXIT_LATENCY_S0i2 2000
+#define CSTATE_EXIT_LATENCY_S0i3 10000
+#else
+#define CSTATE_EXIT_LATENCY_LPMP3 1040
+#define CSTATE_EXIT_LATENCY_S0i1 1040
+#define CSTATE_EXIT_LATENCY_S0i3 2800
+#endif
+#define BYT_S0I1_STATE         0x60
+#define BYT_S0I2_STATE         0x62
+#define BYT_LPMP3_STATE        0x62
+#define BYT_S0I3_STATE         0x64
+
+enum s3_parts {
+	PROC_FRZ,
+	DEV_SUS,
+	NB_CPU_OFF,
+	NB_CPU_ON,
+	DEV_RES,
+	PROC_UNFRZ,
+	MAX_S3_PARTS
+};
+
+#ifdef CONFIG_ATOM_SOC_POWER
+#define LOG_PMU_EVENTS
+
+/* Error codes for pmu */
+#define	PMU_SUCCESS			0
+#define PMU_FAILED			-1
+#define PMU_BUSY_STATUS			0
+#define PMU_MODE_ID			1
+#define	SET_MODE			1
+#define	SET_AOAC_S0i1			2
+#define	SET_AOAC_S0i3			3
+#define	SET_LPAUDIO			4
+#define	SET_AOAC_S0i2			7
+
+#ifdef CONFIG_REMOVEME_INTEL_ATOM_MRFLD_POWER
+#define MID_S0I1_STATE         0x60
+#define MID_S0I2_STATE         0x62
+#define MID_LPMP3_STATE        0x62
+#define MID_S0I3_STATE         0x64
+#else
+#define MID_S0I1_STATE         0x1
+#define MID_LPMP3_STATE        0x3
+#define MID_S0I2_STATE         0x7
+#define MID_S0I3_STATE         0x7
+#endif
+
+#define MID_S0IX_STATE         0xf
+#define MID_S3_STATE           0x1f
+#define MID_FAST_ON_OFF_STATE  0x3f
+
+/* combinations */
+#define MID_LPI1_STATE         0x1f
+#define MID_LPI3_STATE         0x7f
+#define MID_I1I3_STATE         0xff
+
+#define REMOVE_LP_FROM_LPIX    4
+
+/* Power number for MID_POWER */
+#define C0_POWER_USAGE         450
+#define C6_POWER_USAGE         200
+#define LPMP3_POWER_USAGE      130
+#define S0I1_POWER_USAGE       50
+#define S0I3_POWER_USAGE       31
+
+extern unsigned int enable_s3;
+extern unsigned int enable_s0ix;
+
+extern void pmu_s0ix_demotion_stat(int req_state, int grant_state);
+extern unsigned int pmu_get_new_cstate(unsigned int cstate, int *index);
+extern int get_target_platform_state(unsigned long *eax);
+extern int mid_s0ix_enter(int);
+extern int pmu_set_devices_in_d0i0(void);
+extern int pmu_pci_set_power_state(struct pci_dev *pdev, pci_power_t state);
+extern pci_power_t pmu_pci_choose_state(struct pci_dev *pdev);
+
+extern void time_stamp_in_suspend_flow(int mark, bool start);
+extern void time_stamp_for_sleep_state_latency(int sleep_state,
+						bool start, bool entry);
+extern int mid_state_to_sys_state(int mid_state);
+extern void pmu_power_off(void);
+extern void pmu_set_s0ix_complete(void);
+extern bool pmu_is_s0ix_in_progress(void);
+extern int pmu_nc_set_power_state
+	(int islands, int state_type, int reg_type);
+extern int pmu_nc_get_power_state(int island, int reg_type);
+extern int pmu_set_emmc_to_d0i0_atomic(void);
+
+#ifdef LOG_PMU_EVENTS
+extern void pmu_log_ipc(u32 command);
+extern void pmu_log_ipc_irq(void);
+#else
+static inline void pmu_log_ipc(u32 command) { return; };
+static inline void pmu_log_ipc_irq(void) { return; };
+#endif
+extern void dump_nc_power_history(void);
+
+extern bool mid_pmu_is_wake_source(u32 lss_number);
+
+extern void (*nc_report_power_state) (u32, int);
+#else
+
+/*
+ * If CONFIG_ATOM_SOC_POWER is not defined
+ * fall back to C6
+ */
+
+#define MID_S0I1_STATE         C6_HINT
+#define MID_LPMP3_STATE        C6_HINT
+#define MID_S0I3_STATE         C6_HINT
+#define MID_S3_STATE           C6_HINT
+#define MID_FAST_ON_OFF_STATE  C6_HINT
+
+/* Power usage unknown if MID_POWER not defined */
+#define C0_POWER_USAGE         0
+#define C6_POWER_USAGE         0
+#define LPMP3_POWER_USAGE      0
+#define S0I1_POWER_USAGE       0
+#define S0I3_POWER_USAGE       0
+
+#define TEMP_DTS_ID     43
+
+static inline int pmu_nc_set_power_state
+	(int islands, int state_type, int reg_type) { return 0; }
+static inline int pmu_nc_get_power_state(int island, int reg_type) { return 0; }
+
+static inline void pmu_set_s0ix_complete(void) { return; }
+static inline bool pmu_is_s0ix_in_progress(void) { return false; };
+static inline unsigned int pmu_get_new_cstate
+			(unsigned int cstate, int *index) { return cstate; };
+
+/*returns function not implemented*/
+static inline void time_stamp_in_suspend_flow(int mark, bool start) {}
+static inline void time_stamp_for_sleep_state_latency(int sleep_state,
+					bool start, bool entry) {}
+static inline int mid_state_to_sys_state(int mid_state) { return 0; }
+
+static inline int pmu_set_devices_in_d0i0(void) { return 0; }
+static inline void pmu_log_ipc(u32 command) { return; };
+static inline void pmu_log_ipc_irq(void) { return; };
+static inline int pmu_set_emmc_to_d0i0_atomic(void) { return -ENOSYS; }
+static inline void pmu_power_off(void) { return; }
+static inline bool mid_pmu_is_wake_source(u32 lss_number) { return false; }
+#endif /* #ifdef CONFIG_ATOM_SOC_POWER */
+
+#endif /* #ifndef INTEL_MID_PM_H */
diff --git a/include/linux/lnw_gpio.h b/include/linux/lnw_gpio.h
new file mode 100644
index 0000000..2e9f6b2
--- /dev/null
+++ b/include/linux/lnw_gpio.h
@@ -0,0 +1,14 @@
+#ifndef _H_LANGWELL_GPIO_H
+#define _H_LANGWELL_GPIO_H
+
+enum {
+	LNW_GPIO = 0,
+	LNW_ALT_1 = 1,
+	LNW_ALT_2 = 2,
+	LNW_ALT_3 = 3,
+};
+
+void lnw_gpio_set_alt(int gpio, int alt);
+int gpio_get_alt(int gpio);
+
+#endif
diff --git a/include/linux/serial_core.h b/include/linux/serial_core.h
index 6ca1546..66c673c 100644
--- a/include/linux/serial_core.h
+++ b/include/linux/serial_core.h
@@ -66,6 +66,7 @@ struct uart_ops {
 	void		(*set_ldisc)(struct uart_port *, int new);
 	void		(*pm)(struct uart_port *, unsigned int state,
 			      unsigned int oldstate);
+	void		(*wake_peer)(struct uart_port *);
 
 	/*
 	 * Return a string describing the type of the port
diff --git a/include/linux/serial_max3110.h b/include/linux/serial_max3110.h
new file mode 100644
index 0000000..5470556
--- /dev/null
+++ b/include/linux/serial_max3110.h
@@ -0,0 +1,16 @@
+#ifndef _LINUX_SERIAL_MAX3110_H
+#define _LINUX_SERIAL_MAX3110_H
+
+/**
+ * struct plat_max3110 - MAX3110 SPI UART platform data
+ * @irq_edge_trigger: if IRQ is edge triggered
+ *
+ * You should use this structure in your machine description to specify
+ * how the MAX3110 is connected.
+ *
+ */
+struct plat_max3110 {
+	int irq_edge_triggered;
+};
+
+#endif
diff --git a/include/linux/serial_mfd.h b/include/linux/serial_mfd.h
index 2b071e0..0c0ba99 100644
--- a/include/linux/serial_mfd.h
+++ b/include/linux/serial_mfd.h
@@ -3,6 +3,7 @@
 
 /* HW register offset definition */
 #define UART_FOR	0x08
+#define UART_ABR	0x09
 #define UART_PS		0x0C
 #define UART_MUL	0x0D
 #define UART_DIV	0x0E
@@ -18,8 +19,8 @@
 #define HSU_GBL_INT_BIT_DMA	0x5
 
 #define HSU_GBL_ISR	0x8
-#define HSU_GBL_DMASR	0x400
-#define HSU_GBL_DMAISR	0x404
+#define HSU_GBL_DMASR	0x0
+#define HSU_GBL_DMAISR	0x4
 
 #define HSU_PORT_REG_OFFSET	0x80
 #define HSU_PORT0_REG_OFFSET	0x80
@@ -27,7 +28,7 @@
 #define HSU_PORT2_REG_OFFSET	0x180
 #define HSU_PORT_REG_LENGTH	0x80
 
-#define HSU_DMA_CHANS_REG_OFFSET	0x500
+#define HSU_DMA_CHANS_REG_OFFSET	0x100
 #define HSU_DMA_CHANS_REG_LENGTH	0x40
 
 #define HSU_CH_SR		0x0	/* channel status reg */
-- 
1.7.5.4

