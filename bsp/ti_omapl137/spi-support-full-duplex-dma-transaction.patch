From b9de9ef7d8e385b7abeb2e8a833fa037b87c4cd6 Mon Sep 17 00:00:00 2001
From: Bi Junxiao <Junxiao.Bi@windriver.com>
Date: Mon, 17 May 2010 17:51:45 +0800
Subject: [PATCH] spi: support full duplex dma transaction

This patch is a significant overhaul of the davinci spi controller driver
that corrects multiple errors:

- Eliminate a race condition that exists for slow SPI devices
- Fix DMA transfer length error
- Fix limitations preventing multiple SPI devices on the same controller

Signed-off-by: Brian Niebuhr <bniebuhr@efjohnson.com>
[YN: Original patch take from this linux kernel mailing list archive:
https://patchwork.kernel.org/patch/85350/
This is a large patch to redesign the davinci spi driver. I split it, pick
up some DMA setting code snippet and make it work on full duplex DMA transaction.
I also rewrite the patch subject to make it match this patch]
Signed-off-by: Junxiao Bi <junxiao.bi@windriver.com>
---
 drivers/spi/davinci_spi.c              |  117 +++++++++++++++++---------------
 include/linux/spi/davinci_spi_master.h |    2 +
 2 files changed, 64 insertions(+), 55 deletions(-)

diff --git a/drivers/spi/davinci_spi.c b/drivers/spi/davinci_spi.c
index dce80b5..bcd9d7a 100644
--- a/drivers/spi/davinci_spi.c
+++ b/drivers/spi/davinci_spi.c
@@ -227,8 +227,6 @@ static void davinci_spi_dma_rx_callback(unsigned lch, u16 ch_status, void *data)
 		edma_clean_channel(davinci_spi_dma->dma_rx_channel);
 
 	complete(&davinci_spi_dma->dma_rx_completion);
-	/* We must disable the DMA RX request */
-	davinci_spi_set_dma_req(spi, 0);
 
 }
 
@@ -249,8 +247,6 @@ static void davinci_spi_dma_tx_callback(unsigned lch, u16 ch_status, void *data)
 		edma_clean_channel(davinci_spi_dma->dma_tx_channel);
 
 	complete(&davinci_spi_dma->dma_tx_completion);
-	/* We must disable the DMA TX request */
-	davinci_spi_set_dma_req(spi, 0);
 
 }
 
@@ -270,21 +266,41 @@ static int davinci_spi_request_dma(struct spi_device *spi)
 				davinci_spi_dma->eventq);
 	if (r < 0) {
 		pr_err("Unable to request DMA channel for MibSPI RX\n");
-		return -EAGAIN;
+		r = -EAGAIN;
+		goto rx_dma_failed;
 	}
 	davinci_spi_dma->dma_rx_channel = r;
 	r = edma_alloc_channel(davinci_spi_dma->dma_tx_sync_dev,
 				davinci_spi_dma_tx_callback, spi,
 				davinci_spi_dma->eventq);
 	if (r < 0) {
-		edma_free_channel(davinci_spi_dma->dma_rx_channel);
-		davinci_spi_dma->dma_rx_channel = -1;
 		pr_err("Unable to request DMA channel for MibSPI TX\n");
-		return -EAGAIN;
+		r = -EAGAIN;
+		goto tx_dma_failed;
 	}
 	davinci_spi_dma->dma_tx_channel = r;
 
-	return 0;
+        r = edma_alloc_slot(EDMA_CTLR(davinci_spi_dma->dma_tx_sync_dev),
+                        EDMA_SLOT_ANY);
+        if (r < 0) {
+                pr_err("Unable to request SPI DMA param slot\n");
+                r = -EAGAIN;
+                goto param_failed;
+        }
+        davinci_spi_dma->dummy_param_slot = r;
+        edma_link(davinci_spi_dma->dummy_param_slot,
+                        davinci_spi_dma->dummy_param_slot);
+
+        return 0;
+
+param_failed:
+        edma_free_channel(davinci_spi_dma->dma_tx_channel);
+        davinci_spi_dma->dma_tx_channel = -1;
+tx_dma_failed:
+        edma_free_channel(davinci_spi_dma->dma_rx_channel);
+        davinci_spi_dma->dma_rx_channel = -1;
+rx_dma_failed:
+        return r;
 }
 
 /**
@@ -336,12 +352,15 @@ static void davinci_spi_cleanup(struct spi_device *spi)
 	if (use_dma && davinci_spi->dma_channels) {
 		davinci_spi_dma = &davinci_spi->dma_channels[spi->chip_select];
 
-		if ((davinci_spi_dma->dma_rx_channel != -1)
-				&& (davinci_spi_dma->dma_tx_channel != -1)) {
-			edma_free_channel(davinci_spi_dma->dma_tx_channel);
+		if (davinci_spi_dma->dma_rx_channel != -1)
 			edma_free_channel(davinci_spi_dma->dma_rx_channel);
-		}
-	}
+
+		if (davinci_spi_dma->dma_tx_channel != -1)
+			edma_free_channel(davinci_spi_dma->dma_tx_channel);
+
+		if (davinci_spi_dma->dummy_param_slot != -1)
+			edma_free_slot(davinci_spi_dma->dummy_param_slot);
+	}	
 }
 
 static int davinci_spi_bufs_prep(struct spi_device *spi,
@@ -672,6 +691,7 @@ static int davinci_spi_bufs_dma(struct spi_device *spi, struct spi_transfer *t)
 	unsigned long tx_reg, rx_reg;
 	struct davinci_spi_config_t *spi_cfg;
 	struct davinci_spi_platform_data *pdata;
+	struct edmacc_param rx_param, tx_param;
 
 	davinci_spi = spi_master_get_devdata(spi->master);
 	pdata = davinci_spi->pdata;
@@ -732,7 +752,6 @@ static int davinci_spi_bufs_dma(struct spi_device *spi, struct spi_transfer *t)
 	clear_bits(davinci_spi->base + SPIINT, SPI_SPIINT_MASKALL);
 	/* Disable SPI to write configuration bits in SPIDAT */
 	clear_bits(davinci_spi->base + SPIGCR1, SPI_SPIGCR1_SPIENA_MASK);
-	iowrite32(data1_reg_val, davinci_spi->base + SPIDAT1);
 	/* Enable SPI */
 	set_bits(davinci_spi->base + SPIGCR1, SPI_SPIGCR1_SPIENA_MASK);
 
@@ -744,49 +763,36 @@ static int davinci_spi_bufs_dma(struct spi_device *spi, struct spi_transfer *t)
 	if (t->tx_buf != NULL) {
 		t->tx_dma = dma_map_single(&spi->dev, (void *)t->tx_buf, count,
 				DMA_TO_DEVICE);
-
-		edma_set_transfer_params(davinci_spi_dma->dma_tx_channel, data_type,
-			count, 1, 0, ASYNC);
-		edma_set_dest(davinci_spi_dma->dma_tx_channel,
-				tx_reg, INCR, W8BIT);
-		edma_set_src(davinci_spi_dma->dma_tx_channel,
-				t->tx_dma, INCR, W8BIT);
-		edma_set_src_index(davinci_spi_dma->dma_tx_channel, data_type, 0);
-		edma_set_dest_index(davinci_spi_dma->dma_tx_channel, 0, 0);
-	} else {
-		/* We need TX clocking for RX transaction */
-		t->tx_dma = dma_map_single(&spi->dev,
-				(void *)davinci_spi->tmp_buf, count + 1,
-				DMA_TO_DEVICE);
-
-		edma_set_transfer_params(davinci_spi_dma->dma_tx_channel,
-				data_type, count + 1, 1, 0, ASYNC);
-		edma_set_dest(davinci_spi_dma->dma_tx_channel, tx_reg,
-				INCR, W8BIT);
-		edma_set_src(davinci_spi_dma->dma_tx_channel,
-				t->tx_dma, INCR, W8BIT);
-		edma_set_src_index(davinci_spi_dma->dma_tx_channel,
-				data_type, 0);
-		edma_set_dest_index(davinci_spi_dma->dma_tx_channel, 0, 0);
 	}
 
 	if (t->rx_buf != NULL) {
-		/* initiate transaction */
-		iowrite32(data1_reg_val, davinci_spi->base + SPIDAT1);
-
 		t->rx_dma = dma_map_single(&spi->dev, (void *)t->rx_buf, count,
 				DMA_FROM_DEVICE);
-
-		edma_set_transfer_params(davinci_spi_dma->dma_rx_channel, data_type,
-				count, 1, 0, ASYNC);
-		edma_set_src(davinci_spi_dma->dma_rx_channel,
-				rx_reg, INCR, W8BIT);
-		edma_set_dest(davinci_spi_dma->dma_rx_channel,
-				t->rx_dma, INCR, W8BIT);
-		edma_set_src_index(davinci_spi_dma->dma_rx_channel, 0, 0);
-		edma_set_dest_index(davinci_spi_dma->dma_rx_channel, data_type, 0);
+		rx_param.opt = TCINTEN | EDMA_TCC(davinci_spi_dma->dma_rx_channel);
+		rx_param.src = rx_reg;
+		rx_param.a_b_cnt = count << 16 | data_type;
+		rx_param.dst = t->rx_dma;
+		rx_param.src_dst_bidx = (t->rx_buf ? data_type : 0) << 16;
+		rx_param.link_bcntrld = 0xffff;
+		rx_param.src_dst_cidx = 0;
+		rx_param.ccnt = 1;
+		edma_write_slot(davinci_spi_dma->dma_rx_channel, &rx_param);
 	}
+	
+	/*We need TX clocking for RX transaction*/
+	tx_param.opt = TCINTEN | EDMA_TCC(davinci_spi_dma->dma_tx_channel);
+	tx_param.src = t->tx_buf ? t->tx_dma : tx_reg;
+	tx_param.a_b_cnt = count << 16 | data_type;
+	tx_param.dst = tx_reg;
+	tx_param.src_dst_bidx = t->tx_buf ? data_type : 0;
+	tx_param.link_bcntrld = 0xffff;
+	tx_param.src_dst_cidx = 0;
+	tx_param.ccnt = 1;
+	edma_write_slot(davinci_spi_dma->dma_tx_channel, &tx_param);
+	edma_link(davinci_spi_dma->dma_tx_channel,
+                        davinci_spi_dma->dummy_param_slot);
 
+	iowrite32(data1_reg_val, davinci_spi->base + SPIDAT1);
 	if ((t->tx_buf != NULL) || (t->rx_buf != NULL))
 		edma_start(davinci_spi_dma->dma_tx_channel);
 
@@ -804,14 +810,14 @@ static int davinci_spi_bufs_dma(struct spi_device *spi, struct spi_transfer *t)
 		wait_for_completion_interruptible(
 				&davinci_spi_dma->dma_rx_completion);
 
-	if (t->tx_buf != NULL)
+	clear_bits(davinci_spi->base + SPIINT, SPI_SPIINT_MASKALL);
+	if (t->tx_buf != NULL) 
 		dma_unmap_single(NULL, t->tx_dma, count, DMA_TO_DEVICE);
-	else
-		dma_unmap_single(NULL, t->tx_dma, count + 1, DMA_TO_DEVICE);
-
 	if (t->rx_buf != NULL)
 		dma_unmap_single(NULL, t->rx_dma, count, DMA_FROM_DEVICE);
 
+        clear_bits(davinci_spi->base + SPIGCR1, SPI_SPIGCR1_SPIENA_MASK);
+
 	/*
 	 * Check for bit error, desync error,parity error,timeout error and
 	 * receive overflow errors
@@ -1034,6 +1040,7 @@ static int davinci_spi_probe(struct platform_device *pdev)
 			davinci_spi->dma_channels[i].dma_tx_channel = -1;
 			davinci_spi->dma_channels[i].dma_tx_sync_dev =
 				dma_tx_chan;
+			davinci_spi->dma_channels[i].dummy_param_slot = -1;
 			davinci_spi->dma_channels[i].eventq = dma_eventq;
 		}
 	}
diff --git a/include/linux/spi/davinci_spi_master.h b/include/linux/spi/davinci_spi_master.h
index 9da536c..c7cde50 100644
--- a/include/linux/spi/davinci_spi_master.h
+++ b/include/linux/spi/davinci_spi_master.h
@@ -90,6 +90,7 @@
 #define SPI_SPIGCR1_SPIENA_MASK      (0x01000000u)
 #define SPI_SPIGCR1_SPIENA_SHIFT     (0x00000018u)
 #define SPI_SPIGCR1_SPIENA_RESETVAL  (0x00000000u)
+#define SPI_SPIGCR1_POWERDOWN_MASK   (0x00000100)
 
 #define SPI_INTLVL_1				 (0x000001FFu)
 #define SPI_INTLVL_0				 (0x00000000u)
@@ -284,6 +285,7 @@ struct davinci_spi_dma {
 	int			dma_rx_channel;
 	int			dma_tx_sync_dev;
 	int			dma_rx_sync_dev;
+	int			dummy_param_slot;
 	enum dma_event_q	eventq;
 
 	struct completion	dma_tx_completion;
-- 
1.6.0.4

