From 764674979e34359d08ba23818a3e648571978a54 Mon Sep 17 00:00:00 2001
From: Wang Hui <Hui.Wang@windriver.com>
Date: Tue, 15 Jan 2013 10:28:59 +0800
Subject: [PATCH 03/50] arm: armadaxp: cpu errata: fix SHEEVA cpu errata 6075

This is a workaround of errata 6075 (data memory barrier malfunction)
for armadaxp cpu rev A0.

The code is extracted from linux-3.2.27-axp_a370-2012_Q4.1, which
can be downloaded from:
https://extranet.marvell.com/extranet/dms/documents.do?groupID=4&\
subGroupID=53015

Signed-off-by: Wang Hui <Hui.Wang@windriver.com>
---
 arch/arm/include/asm/assembler.h |    8 ++++++++
 arch/arm/include/asm/barrier.h   |    4 ++++
 arch/arm/kernel/entry-armv.S     |   37 +++++++++++++++++++++++++++++++++++++
 arch/arm/mm/cache-v7.S           |    8 ++++++++
 4 files changed, 57 insertions(+), 0 deletions(-)

diff --git a/arch/arm/include/asm/assembler.h b/arch/arm/include/asm/assembler.h
index 5c8b3bf..486d2c8 100644
--- a/arch/arm/include/asm/assembler.h
+++ b/arch/arm/include/asm/assembler.h
@@ -211,9 +211,17 @@
 #ifdef CONFIG_SMP
 #if __LINUX_ARM_ARCH__ >= 7
 	.ifeqs "\mode","arm"
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_6075
+	ALT_SMP(dsb)
+#else
 	ALT_SMP(dmb)
+#endif
 	.else
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_6075
+	ALT_SMP(W(dsb))
+#else
 	ALT_SMP(W(dmb))
+#endif
 	.endif
 #elif __LINUX_ARM_ARCH__ == 6
 	ALT_SMP(mcr	p15, 0, r0, c7, c10, 5)	@ dmb
diff --git a/arch/arm/include/asm/barrier.h b/arch/arm/include/asm/barrier.h
index 0511238..cfab866 100644
--- a/arch/arm/include/asm/barrier.h
+++ b/arch/arm/include/asm/barrier.h
@@ -16,7 +16,11 @@
 #if __LINUX_ARM_ARCH__ >= 7
 #define isb() __asm__ __volatile__ ("isb" : : : "memory")
 #define dsb() __asm__ __volatile__ ("dsb" : : : "memory")
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_6075
+#define dmb() __asm__ __volatile__ ("dsb" : : : "memory")
+#else
 #define dmb() __asm__ __volatile__ ("dmb" : : : "memory")
+#endif
 #elif defined(CONFIG_CPU_XSC3) || __LINUX_ARM_ARCH__ == 6
 #define isb() __asm__ __volatile__ ("mcr p15, 0, %0, c7, c5, 4" \
 				    : : "r" (0) : "memory")
diff --git a/arch/arm/kernel/entry-armv.S b/arch/arm/kernel/entry-armv.S
index 8f29865..15de207 100644
--- a/arch/arm/kernel/entry-armv.S
+++ b/arch/arm/kernel/entry-armv.S
@@ -791,6 +791,35 @@ ENDPROC(__switch_to)
 	.globl	__kuser_helper_start
 __kuser_helper_start:
 
+#ifdef CONFIG_ARMADA_XP_A0_WITH_B0
+/*
+ * Due to the sheeva arm errata 6075 - DMB must be replaced with DSB when using revision A0 of the Armada-XP
+ * In order to make the revision check on runtime, we added the following functions that implement the custom memory barrier
+ */
+__kuser_memory_barrier_errata_6075_1:				@ 0xffff0f20
+	ldr		r3, [pc, #0x1C]
+	teqeq	r3, #0x2								@ MV_78XX0_B0_REV
+	beq		1f
+	dsb
+	b errata_6075_barrier_return
+1:	dmb
+	b errata_6075_barrier_return
+	.word 0
+
+	.align	5
+
+__kuser_memory_barrier_errata_6075_2:				@ 0xffff0f40
+	ldr		r3, [pc, #0x1C]
+	teqeq	r3, #0x2								@ MV_78XX0_B0_REV
+	beq		1f
+	dsb
+	usr_ret	lr
+1:	dmb
+	usr_ret	lr
+	.word 0
+	.align	5
+#endif
+
 /*
  * Due to the length of some sequences, __kuser_cmpxchg64 spans 2 regular
  * kuser "slots", therefore 0xffff0f80 is not used as a valid entry point.
@@ -948,7 +977,11 @@ kuser_cmpxchg32_fixup:
 
 #else
 
+#ifdef CONFIG_ARMADA_XP_A0_WITH_B0
+	ALT_SMP(b	__kuser_memory_barrier_errata_6075_1)
+#else
 	smp_dmb	arm
+#endif
 1:	ldrex	r3, [r2]
 	subs	r3, r3, r0
 	strexeq	r3, r1, [r2]
@@ -956,7 +989,11 @@ kuser_cmpxchg32_fixup:
 	beq	1b
 	rsbs	r0, r3, #0
 	/* beware -- each __kuser slot must be 8 instructions max */
+#ifdef CONFIG_ARMADA_XP_A0_WITH_B0
+	ALT_SMP(b	__kuser_memory_barrier_errata_6075_2)
+#else
 	ALT_SMP(b	__kuser_memory_barrier)
+#endif
 	ALT_UP(usr_ret	lr)
 
 #endif
diff --git a/arch/arm/mm/cache-v7.S b/arch/arm/mm/cache-v7.S
index 82ab2c5..2e280fb 100644
--- a/arch/arm/mm/cache-v7.S
+++ b/arch/arm/mm/cache-v7.S
@@ -42,7 +42,15 @@ ENDPROC(v7_flush_icache_all)
  *	- mm    - mm_struct describing address space
  */
 ENTRY(v7_flush_dcache_all)
+#ifdef CONFIG_SHEEVA_ERRATA_ARM_CPU_6075
+#ifdef CONFIG_ARMADA_XP_A0_WITH_B0
+	a0_with_b0_errata_6075 r0
+#else
+	dsb
+#endif
+#else
 	dmb					@ ensure ordering with previous memory accesses
+#endif
 	mrc	p15, 1, r0, c0, c0, 1		@ read clidr
 	ands	r3, r0, #0x7000000		@ extract loc from clidr
 	mov	r3, r3, lsr #23			@ left align loc bit field
-- 
1.7.0

