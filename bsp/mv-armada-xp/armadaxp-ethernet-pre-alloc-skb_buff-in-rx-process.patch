From 8d2f91b402e51cb61ebb94688838958205448b99 Mon Sep 17 00:00:00 2001
From: Zhang Xiao <xiao.zhang@windriver.com>
Date: Mon, 14 Nov 2016 15:08:56 +0800
Subject: [PATCH] armadaxp: ethernet: pre-alloc skb_buff in rx process

In original rx process, once the new skb can't be allocated, a
mistake eth_pbuf will be constructe and reused thus will cause
a panic later. To avoid this issue, pre-allocate a skb before
dealing with the eth_pbuf. In case the allocation failed, reuse
the old one to avoid the later panic. This will drop an
ethernet package each time the allocation failed.

Signed-off-by: Zhang Xiao <xiao.zhang@windriver.com>
---
 .../mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c     |   41 ++++++++++++++++----
 1 files changed, 33 insertions(+), 8 deletions(-)

diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
index 6c92288..c21b3bd 100755
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
@@ -1356,11 +1356,10 @@ EXPORT_SYMBOL(mv_eth_skb_recycle);
 
 #endif /* CONFIG_NET_SKB_RECYCLE */
 
-static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, struct eth_pbuf *pkt)
+static struct sk_buff *mv_eth_skb_alloc(struct bm_pool *pool, struct eth_pbuf *pkt, struct sk_buff *skb)
 {
-	struct sk_buff *skb;
-
-	skb = dev_alloc_skb(pool->pkt_size);
+	if(!skb)
+		skb = dev_alloc_skb(pool->pkt_size);
 	if (!skb) {
 		STAT_ERR(pool->stats.skb_alloc_oom++);
 		return NULL;
@@ -1471,7 +1470,7 @@ inline struct eth_pbuf *mv_eth_pool_get(struct bm_pool *pool)
 	/* Try to allocate new pkt + skb */
 	pkt = mvOsMalloc(sizeof(struct eth_pbuf));
 	if (pkt) {
-		skb = mv_eth_skb_alloc(pool, pkt);
+		skb = mv_eth_skb_alloc(pool, pkt, NULL);
 		if (!skb) {
 			mvOsFree(pkt);
 			pkt = NULL;
@@ -1480,6 +1479,24 @@ inline struct eth_pbuf *mv_eth_pool_get(struct bm_pool *pool)
 	return pkt;
 }
 
+/* Reuse pkt if possible, move BM pool or RXQ ring */
+static inline int mv_eth_refill_skb(struct eth_port *pp, int rxq,
+			     struct eth_pbuf *pkt, struct bm_pool *pool,
+			     struct neta_rx_desc *rx_desc, struct sk_buff *skb)
+{
+	if (pkt == NULL) {
+		pkt = mv_eth_pool_get(pool);
+		if (pkt == NULL)
+			return 1;
+	} else {
+		/* No recycle -  use new skb */
+		skb = mv_eth_skb_alloc(pool, pkt, skb);
+	}
+	mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+
+	return 0;
+}
+
 /* Reuse pkt if possible, allocate new skb and move BM pool or RXQ ring */
 inline int mv_eth_refill(struct eth_port *pp, int rxq,
 				struct eth_pbuf *pkt, struct bm_pool *pool, struct neta_rx_desc *rx_desc)
@@ -1492,7 +1509,7 @@ inline int mv_eth_refill(struct eth_port *pp, int rxq,
 		struct sk_buff *skb;
 
 		/* No recycle -  alloc new skb */
-		skb = mv_eth_skb_alloc(pool, pkt);
+		skb = mv_eth_skb_alloc(pool, pkt, NULL);
 		if (!skb) {
 			mvOsFree(pkt);
 			pool->missed++;
@@ -1577,6 +1594,7 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq)
 	struct eth_pbuf *pkt;
 	struct sk_buff *skb;
 	struct bm_pool *pool;
+	struct sk_buff *skb_new;
 
 	/* Get number of received packets */
 	rx_done = mvNetaRxqBusyDescNumGet(pp->port, rxq);
@@ -1704,6 +1722,12 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq)
 		}
 #endif /* CONFIG_MV_ETH_NFP || CONFIG_MV_ETH_NFP_MODULE */
 
+		skb_new = dev_alloc_skb(pool->pkt_size);
+		if(!skb_new) {
+			skb_new = (struct sk_buff *)(pkt->osInfo);
+			dev->stats.rx_dropped++;
+			goto eth_refill;
+		}
 		/* Linux processing */
 		skb = (struct sk_buff *)(pkt->osInfo);
 
@@ -1744,8 +1768,9 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq)
 			STAT_DBG((rx_status == 0) ? : pp->stats.rx_drop_sw++);
 		}
 
+eth_refill:
 		/* Refill processing: */
-		err = mv_eth_refill(pp, rxq, pkt, pool, rx_desc);
+		err = mv_eth_refill_skb(pp, rxq, pkt, pool, rx_desc, skb_new);
 		if (err) {
 			printk(KERN_ERR "Linux processing - Can't refill\n");
 			pp->rxq_ctrl[rxq].missed++;
@@ -2543,7 +2568,7 @@ static int mv_eth_pool_add(int pool, int buf_num)
 			break;
 		}
 
-		skb = mv_eth_skb_alloc(bm_pool, pkt);
+		skb = mv_eth_skb_alloc(bm_pool, pkt, NULL);
 		if (!skb) {
 			kfree(pkt);
 			break;
-- 
1.7.5.4

