From 0d83e22f8d2a37ca7aaa091a831064ae3b9aee93 Mon Sep 17 00:00:00 2001
From: Zhong Hongbo <hongbo.zhong@windriver.com>
Date: Fri, 23 Nov 2012 13:16:23 +0800
Subject: [PATCH 2/2] ARM: SMP: use per cpu state to replace

CPU hotplug will bring following call trace in the RT kernel:
BUG: sleeping function called from invalid context at linux/kernel/rtmutex.c:707
pcnt: 1 0 in_atomic(): 1, irqs_disabled(): 128, pid: 0, name: swapper
[<800413a0>] (unwind_backtrace+0x0/0xe4) from [<804ff214>] (rt_spin_lock+0x30/0x5c)
[<804ff214>] (rt_spin_lock+0x30/0x5c) from [<8005a848>] (complete+0x1c/0x54)
[<8005a848>] (complete+0x1c/0x54) from [<804f59f8>] (cpu_die+0x34/0x70)
[<804f59f8>] (cpu_die+0x34/0x70) from [<8003b840>] (cpu_idle+0x54/0xd8)
[<8003b840>] (cpu_idle+0x54/0xd8) from [<104f9ecc>] (0x104f9ecc)

To avoid this call trace, we use per cpu variable to replace
completion, and it is safe for this modification since all reference
of per cpu_state variable is in the preempt disabled context.

Signed-off-by: Hui Wang <hui.wang@windriver.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 arch/arm/kernel/smp.c |   41 +++++++++++++++++++++++++++++++++++++----
 1 files changed, 37 insertions(+), 4 deletions(-)

diff --git a/arch/arm/kernel/smp.c b/arch/arm/kernel/smp.c
index 18525543..90fd3b6 100644
--- a/arch/arm/kernel/smp.c
+++ b/arch/arm/kernel/smp.c
@@ -43,6 +43,11 @@
 #include <asm/localtimer.h>
 #include <asm/smp_plat.h>
 
+#ifdef CONFIG_HOTPLUG_CPU
+/* State of each CPU during hotplug phases */
+DEFINE_PER_CPU(int, cpu_state) = { 0 };
+#endif
+
 /*
  * as from 2.5, kernels no longer have an init_tasks structure
  * so we need some other way of telling a new secondary core
@@ -58,12 +63,17 @@ enum ipi_msg_type {
 	IPI_CPU_STOP,
 };
 
+#ifndef CONFIG_HOTPLUG_CPU
 static DECLARE_COMPLETION(cpu_running);
+#endif
 
 int __cpuinit __cpu_up(unsigned int cpu)
 {
 	struct cpuinfo_arm *ci = &per_cpu(cpu_data, cpu);
 	struct task_struct *idle = ci->idle;
+#ifdef CONFIG_HOTPLUG_CPU
+	unsigned long timeout;
+#endif
 	int ret;
 
 	/*
@@ -104,6 +114,17 @@ int __cpuinit __cpu_up(unsigned int cpu)
 		 * CPU was successfully started, wait for it
 		 * to come online or time out.
 		 */
+#ifdef CONFIG_HOTPLUG_CPU
+		timeout = jiffies + msecs_to_jiffies(1000);
+
+		while (per_cpu(cpu_state, cpu) != CPU_ONLINE) {
+			if (time_after(jiffies, timeout)) {
+				pr_crit("CPU%u: failed to come online\n", cpu);
+				ret = -EIO;
+			}
+			cpu_relax();
+		}
+#else
 		wait_for_completion_timeout(&cpu_running,
 						 msecs_to_jiffies(1000));
 
@@ -111,6 +132,7 @@ int __cpuinit __cpu_up(unsigned int cpu)
 			pr_crit("CPU%u: failed to come online\n", cpu);
 			ret = -EIO;
 		}
+#endif
 	} else {
 		pr_err("CPU%u: failed to boot: %d\n", cpu, ret);
 	}
@@ -171,6 +193,7 @@ static DECLARE_COMPLETION(cpu_died);
 void __cpu_die(unsigned int cpu)
 {
 	struct task_struct *p;
+	unsigned long timeout;
 
 	read_lock(&tasklist_lock);
 	for_each_process(p) {
@@ -179,10 +202,16 @@ void __cpu_die(unsigned int cpu)
 	}
 	read_unlock(&tasklist_lock);
 
-	if (!wait_for_completion_timeout(&cpu_died, msecs_to_jiffies(5000))) {
-		pr_err("CPU%u: cpu didn't die\n", cpu);
-		return;
+	timeout = jiffies + msecs_to_jiffies(5000);
+
+	while (per_cpu(cpu_state, cpu) != CPU_DEAD) {
+		if (time_after(jiffies, timeout)) {
+			pr_err("CPU%u: cpu didn't die\n", cpu);
+			return;
+		}
+		cpu_relax();
 	}
+
 	printk(KERN_NOTICE "CPU%u: shutdown\n", cpu);
 
 	if (!platform_cpu_kill(cpu))
@@ -207,7 +236,7 @@ void __ref cpu_die(void)
 	mb();
 
 	/* Tell __cpu_die() that this CPU is now safe to dispose of */
-	complete(&cpu_died);
+	per_cpu(cpu_state, cpu) = CPU_DEAD;
 
 	/*
 	 * actual CPU shutdown procedure is at least platform (if not
@@ -292,7 +321,11 @@ asmlinkage void __cpuinit secondary_start_kernel(void)
 	 * before we continue - which happens after __cpu_up returns.
 	 */
 	set_cpu_online(cpu, true);
+#ifdef CONFIG_HOTPLUG_CPU
+	per_cpu(cpu_state, cpu) = CPU_ONLINE;
+#else
 	complete(&cpu_running);
+#endif
 
 	/*
 	 * Setup the percpu timer for this CPU.
-- 
1.7.5.4

