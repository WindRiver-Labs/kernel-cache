From b6aea3dfbfc04d94037f578bd38b13a9b23e3c03 Mon Sep 17 00:00:00 2001
From: Srikanth Thokala <srikanth.thokala@xilinx.com>
Date: Fri, 27 Sep 2013 21:20:39 +0530
Subject: [PATCH 348/509] axidma: xilinx: Reorganize IO read/write functions

https://github.com/analogdevicesinc/linux.git xcomm_zynq
commit 0b2d283ba97eed29246008936b87ebb6d1367d66

This patch reorganizes IO read/write access implementation
and this also removes sparse warnings.

Signed-off-by: Srikanth Thokala <sthokal@xilinx.com>
Signed-off-by: Michal Simek <michal.simek@xilinx.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 drivers/dma/xilinx/xilinx_axidma.c |  127 ++++++++++++++++++++----------------
 1 files changed, 71 insertions(+), 56 deletions(-)

diff --git a/drivers/dma/xilinx/xilinx_axidma.c b/drivers/dma/xilinx/xilinx_axidma.c
index 0c2531c..69e93a9 100644
--- a/drivers/dma/xilinx/xilinx_axidma.c
+++ b/drivers/dma/xilinx/xilinx_axidma.c
@@ -35,6 +35,15 @@
 #define XILINX_DMA_MAX_CHANS_PER_DEVICE	0x2	/* Max no of channels */
 #define XILINX_DMA_MAX_TRANS_LEN	0x7FFFFF /* Max transfer length */
 
+/* Register Offsets */
+#define XILINX_DMA_CONTROL_OFFSET	0x00 /* Control Reg */
+#define XILINX_DMA_STATUS_OFFSET	0x04 /* Status Reg */
+#define XILINX_DMA_CDESC_OFFSET		0x08 /* Current descriptor Reg */
+#define XILINX_DMA_TDESC_OFFSET		0x10 /* Tail descriptor Reg */
+#define XILINX_DMA_SRCADDR_OFFSET	0x18 /* Source Address Reg */
+#define XILINX_DMA_DSTADDR_OFFSET	0x20 /* Dest Address Reg */
+#define XILINX_DMA_BTT_OFFSET		0x28 /* Bytes to transfer Reg */
+
 /* General register bits definitions */
 #define XILINX_DMA_CR_RESET_MASK	0x00000004
 						/* Reset DMA engine */
@@ -87,10 +96,6 @@
 #define XILINX_DMA_RESET_LOOP		1000000
 #define XILINX_DMA_HALT_LOOP		1000000
 
-/* IO accessors */
-#define dma_write(addr, val)	(iowrite32(val, addr))
-#define dma_read(addr)		(ioread32(addr))
-
 #if defined(CONFIG_XILINX_DMATEST) || defined(CONFIG_XILINX_DMATEST_MODULE)
 # define TEST_DMA_WITH_LOOPBACK
 #endif
@@ -120,24 +125,9 @@ struct xilinx_dma_desc_sw {
 	struct dma_async_tx_descriptor async_tx;
 } __aligned(64);
 
-/* AXI DMA Registers Structure */
-struct xdma_regs {
-	u32 cr;		/* 0x00 Control Register */
-	u32 sr;		/* 0x04 Status Register */
-	u32 cdr;	/* 0x08 Current Descriptor Register */
-	u32 pad1;
-	u32 tdr;	/* 0x10 Tail Descriptor Register */
-	u32 pad2;
-	u32 src;	/* 0x18 Source Address Register (sg = 0) */
-	u32 pad3;
-	u32 dst;	/* 0x20 Destination Address Register (sg = 0) */
-	u32 pad4;
-	u32 btt_ref;	/* 0x28 Bytes To Transfer (sg = 0) */
-};
-
 /* Per DMA specific operations should be embedded in the channel structure */
 struct xilinx_dma_chan {
-	struct xdma_regs __iomem *regs;	/* Control status registers */
+	void __iomem *regs;		/* Control status registers */
 	dma_cookie_t completed_cookie;	/* The maximum cookie completed */
 	dma_cookie_t cookie;		/* The current cookie */
 	spinlock_t lock;		/* Descriptor operation lock */
@@ -175,6 +165,17 @@ struct xilinx_dma_device {
 #define to_xilinx_chan(chan) \
 	container_of(chan, struct xilinx_dma_chan, common)
 
+/* IO accessors */
+static inline void dma_write(struct xilinx_dma_chan *chan, u32 reg, u32 val)
+{
+	writel(val, chan->regs + reg);
+}
+
+static inline u32 dma_read(struct xilinx_dma_chan *chan, u32 reg)
+{
+	return readl(chan->regs + reg);
+}
+
 /* Required functions */
 
 static int xilinx_dma_alloc_chan_resources(struct dma_chan *dchan)
@@ -306,13 +307,16 @@ static enum dma_status xilinx_tx_status(struct dma_chan *dchan,
 
 static int dma_is_running(struct xilinx_dma_chan *chan)
 {
-	return !(dma_read(&chan->regs->sr) & XILINX_DMA_SR_HALTED_MASK) &&
-	       (dma_read(&chan->regs->cr) & XILINX_DMA_CR_RUNSTOP_MASK);
+	return !(dma_read(chan, XILINX_DMA_STATUS_OFFSET) &
+		 XILINX_DMA_SR_HALTED_MASK) &&
+	       (dma_read(chan, XILINX_DMA_CONTROL_OFFSET) &
+		XILINX_DMA_CR_RUNSTOP_MASK);
 }
 
 static int dma_is_idle(struct xilinx_dma_chan *chan)
 {
-	return dma_read(&chan->regs->sr) & XILINX_DMA_SR_IDLE_MASK;
+	return dma_read(chan, XILINX_DMA_STATUS_OFFSET) &
+	       XILINX_DMA_SR_IDLE_MASK;
 }
 
 /* Stop the hardware, the ongoing transfer will be finished */
@@ -320,12 +324,14 @@ static void dma_halt(struct xilinx_dma_chan *chan)
 {
 	int loop = XILINX_DMA_HALT_LOOP;
 
-	dma_write(&chan->regs->cr,
-		  dma_read(&chan->regs->cr) & ~XILINX_DMA_CR_RUNSTOP_MASK);
+	dma_write(chan, XILINX_DMA_CONTROL_OFFSET,
+		  dma_read(chan, XILINX_DMA_CONTROL_OFFSET) &
+		  ~XILINX_DMA_CR_RUNSTOP_MASK);
 
 	/* Wait for the hardware to halt */
 	while (loop) {
-		if (!(dma_read(&chan->regs->cr) & XILINX_DMA_CR_RUNSTOP_MASK))
+		if (!(dma_read(chan, XILINX_DMA_CONTROL_OFFSET) &
+		      XILINX_DMA_CR_RUNSTOP_MASK))
 			break;
 
 		loop -= 1;
@@ -334,7 +340,8 @@ static void dma_halt(struct xilinx_dma_chan *chan)
 	if (!loop) {
 		pr_debug("Cannot stop channel %x: %x\n",
 			 (unsigned int)chan,
-			 (unsigned int)dma_read(&chan->regs->cr));
+			 (unsigned int)dma_read(chan,
+						XILINX_DMA_CONTROL_OFFSET));
 		chan->err = 1;
 	}
 
@@ -346,12 +353,14 @@ static void dma_start(struct xilinx_dma_chan *chan)
 {
 	int loop = XILINX_DMA_HALT_LOOP;
 
-	dma_write(&chan->regs->cr,
-		  dma_read(&chan->regs->cr) | XILINX_DMA_CR_RUNSTOP_MASK);
+	dma_write(chan, XILINX_DMA_CONTROL_OFFSET,
+		  dma_read(chan, XILINX_DMA_CONTROL_OFFSET) |
+		  XILINX_DMA_CR_RUNSTOP_MASK);
 
 	/* Wait for the hardware to start */
 	while (loop) {
-		if (dma_read(&chan->regs->cr) & XILINX_DMA_CR_RUNSTOP_MASK)
+		if (dma_read(chan, XILINX_DMA_CONTROL_OFFSET) &
+		    XILINX_DMA_CR_RUNSTOP_MASK)
 			break;
 
 		loop -= 1;
@@ -360,7 +369,8 @@ static void dma_start(struct xilinx_dma_chan *chan)
 	if (!loop) {
 		pr_debug("Cannot start channel %x: %x\n",
 			 (unsigned int)chan,
-			 (unsigned int)dma_read(&chan->regs->cr));
+			 (unsigned int)dma_read(chan,
+						XILINX_DMA_CONTROL_OFFSET));
 
 		chan->err = 1;
 	}
@@ -405,7 +415,7 @@ static void xilinx_dma_start_transfer(struct xilinx_dma_chan *chan)
 		desct = container_of(chan->pending_list.prev,
 				     struct xilinx_dma_desc_sw, node);
 
-		dma_write(&chan->regs->cdr, desch->async_tx.phys);
+		dma_write(chan, XILINX_DMA_CDESC_OFFSET, desch->async_tx.phys);
 
 		dma_start(chan);
 
@@ -414,12 +424,12 @@ static void xilinx_dma_start_transfer(struct xilinx_dma_chan *chan)
 		list_splice_tail_init(&chan->pending_list, &chan->active_list);
 
 		/* Enable interrupts */
-		dma_write(&chan->regs->cr,
-			  dma_read(&chan->regs->cr) |
+		dma_write(chan, XILINX_DMA_CONTROL_OFFSET,
+			  dma_read(chan, XILINX_DMA_CONTROL_OFFSET) |
 			  XILINX_DMA_XR_IRQ_ALL_MASK);
 
 		/* Update tail ptr register and start the transfer */
-		dma_write(&chan->regs->tdr, desct->async_tx.phys);
+		dma_write(chan, XILINX_DMA_TDESC_OFFSET, desct->async_tx.phys);
 		goto out_unlock;
 	}
 
@@ -445,13 +455,14 @@ static void xilinx_dma_start_transfer(struct xilinx_dma_chan *chan)
 	hw = &desch->hw;
 
 	/* Enable interrupts */
-	dma_write(&chan->regs->cr,
-		  dma_read(&chan->regs->cr) | XILINX_DMA_XR_IRQ_ALL_MASK);
+	dma_write(chan, XILINX_DMA_CONTROL_OFFSET,
+		  dma_read(chan, XILINX_DMA_CONTROL_OFFSET) |
+		  XILINX_DMA_XR_IRQ_ALL_MASK);
 
-	dma_write(&chan->regs->src, hw->buf_addr);
+	dma_write(chan, XILINX_DMA_SRCADDR_OFFSET, hw->buf_addr);
 
 	/* Start the transfer */
-	dma_write(&chan->regs->btt_ref,
+	dma_write(chan, XILINX_DMA_BTT_OFFSET,
 		  hw->control & XILINX_DMA_MAX_TRANS_LEN);
 
 out_unlock:
@@ -518,20 +529,24 @@ static int dma_reset(struct xilinx_dma_chan *chan)
 	int loop = XILINX_DMA_RESET_LOOP;
 	u32 tmp;
 
-	dma_write(&chan->regs->cr,
-		  dma_read(&chan->regs->cr) | XILINX_DMA_CR_RESET_MASK);
+	dma_write(chan, XILINX_DMA_CONTROL_OFFSET,
+		  dma_read(chan, XILINX_DMA_CONTROL_OFFSET) |
+		  XILINX_DMA_CR_RESET_MASK);
 
-	tmp = dma_read(&chan->regs->cr) & XILINX_DMA_CR_RESET_MASK;
+	tmp = dma_read(chan, XILINX_DMA_CONTROL_OFFSET) &
+	      XILINX_DMA_CR_RESET_MASK;
 
 	/* Wait for the hardware to finish reset */
 	while (loop && tmp) {
-		tmp = dma_read(&chan->regs->cr) & XILINX_DMA_CR_RESET_MASK;
+		tmp = dma_read(chan, XILINX_DMA_CONTROL_OFFSET) &
+		      XILINX_DMA_CR_RESET_MASK;
 		loop -= 1;
 	}
 
 	if (!loop) {
 		dev_err(chan->dev, "reset timeout, cr %x, sr %x\n",
-			dma_read(&chan->regs->cr), dma_read(&chan->regs->sr));
+			dma_read(chan, XILINX_DMA_CONTROL_OFFSET),
+			dma_read(chan, XILINX_DMA_STATUS_OFFSET));
 		return -EBUSY;
 	}
 
@@ -546,18 +561,19 @@ static irqreturn_t dma_intr_handler(int irq, void *data)
 	int to_transfer = 0;
 	u32 stat, reg;
 
-	reg = dma_read(&chan->regs->cr);
+	reg = dma_read(chan, XILINX_DMA_CONTROL_OFFSET);
 
 	/* Disable intr */
-	dma_write(&chan->regs->cr,
+	dma_write(chan, XILINX_DMA_CONTROL_OFFSET,
 		  reg & ~XILINX_DMA_XR_IRQ_ALL_MASK);
 
-	stat = dma_read(&chan->regs->sr);
+	stat = dma_read(chan, XILINX_DMA_STATUS_OFFSET);
 	if (!(stat & XILINX_DMA_XR_IRQ_ALL_MASK))
 		return IRQ_NONE;
 
 	/* Ack the interrupts */
-	dma_write(&chan->regs->sr, XILINX_DMA_XR_IRQ_ALL_MASK);
+	dma_write(chan, XILINX_DMA_STATUS_OFFSET,
+		  XILINX_DMA_XR_IRQ_ALL_MASK);
 
 	/* Check for only the interrupts which are enabled */
 	stat &= (reg & XILINX_DMA_XR_IRQ_ALL_MASK);
@@ -566,9 +582,9 @@ static irqreturn_t dma_intr_handler(int irq, void *data)
 		dev_err(chan->dev,
 			"Channel %x has errors %x, cdr %x tdr %x\n",
 			(unsigned int)chan,
-			(unsigned int)dma_read(&chan->regs->sr),
-			(unsigned int)dma_read(&chan->regs->cdr),
-			(unsigned int)dma_read(&chan->regs->tdr));
+			(unsigned int)dma_read(chan, XILINX_DMA_STATUS_OFFSET),
+			(unsigned int)dma_read(chan, XILINX_DMA_CDESC_OFFSET),
+			(unsigned int)dma_read(chan, XILINX_DMA_TDESC_OFFSET));
 		chan->err = 1;
 	}
 
@@ -867,7 +883,7 @@ static int xilinx_dma_device_control(struct dma_chan *dchan,
 		 * Use value XILINX_DMA_NO_CHANGE to signal no change
 		 */
 		struct xilinx_dma_config *cfg = (struct xilinx_dma_config *)arg;
-		u32 reg = dma_read(&chan->regs->cr);
+		u32 reg = dma_read(chan, XILINX_DMA_CONTROL_OFFSET);
 
 		if (cfg->coalesc <= XILINX_DMA_COALESCE_MAX) {
 			reg &= ~XILINX_DMA_XR_COALESCE_MASK;
@@ -882,7 +898,7 @@ static int xilinx_dma_device_control(struct dma_chan *dchan,
 			chan->config.delay = cfg->delay;
 		}
 
-		dma_write(&chan->regs->cr, reg);
+		dma_write(chan, XILINX_DMA_CONTROL_OFFSET, reg);
 
 		return 0;
 	} else
@@ -956,11 +972,10 @@ static int xilinx_dma_chan_probe(struct xilinx_dma_device *xdev,
 				    "xlnx,axi-dma-s2mm-channel"))
 		chan->direction = DMA_DEV_TO_MEM;
 
-	chan->regs = (struct xdma_regs *)xdev->regs;
+	chan->regs = xdev->regs;
 
 	if (chan->direction == DMA_DEV_TO_MEM) {
-		chan->regs = (struct xdma_regs *)((u32)xdev->regs +
-						  XILINX_DMA_RX_CHANNEL_OFFSET);
+		chan->regs = (xdev->regs + XILINX_DMA_RX_CHANNEL_OFFSET);
 		chan->id = 1;
 	}
 
-- 
1.7.5.4

