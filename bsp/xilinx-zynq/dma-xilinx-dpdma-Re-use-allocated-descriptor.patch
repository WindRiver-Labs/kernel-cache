From a06fb53eae4590c63c506440a32f558dca40c49a Mon Sep 17 00:00:00 2001
From: Hyun Kwon <hyun.kwon@xilinx.com>
Date: Fri, 15 Jul 2016 17:23:55 -0700
Subject: [PATCH 732/793] dma: xilinx: dpdma: Re-use allocated descriptor

This patch allows to re-use previously allocated descriptor instead
of allocating a descriptor every time unnecessarily. The descriptor
allocation is throttled by current framerate, so when a client
requests descriptors faster than framerate, the actual descriptor
allocation happens at framerate, while one descriptor is re-used
for additional requests. Otherwise, the consuming rate is slower
than the allocation rate, which results in the out of memory.

Signed-off-by: Hyun Kwon <hyun.kwon@xilinx.com>
Signed-off-by: Michal Simek <michal.simek@xilinx.com>
---
 drivers/dma/xilinx/xilinx_dpdma.c |   76 +++++++++++++++++++++++++-----------
 1 files changed, 53 insertions(+), 23 deletions(-)

diff --git a/drivers/dma/xilinx/xilinx_dpdma.c b/drivers/dma/xilinx/xilinx_dpdma.c
index d7e8bc9..d85e545 100644
--- a/drivers/dma/xilinx/xilinx_dpdma.c
+++ b/drivers/dma/xilinx/xilinx_dpdma.c
@@ -256,12 +256,13 @@ enum xilinx_dpdma_chan_status {
  * --------------------------
  * DPDMA descritpor life time is described with following placements:
  *
- * pending_list -> pending_desc -> active_desc -> done_list
+ * allocated_desc -> submitted_desc -> pending_desc -> active_desc -> done_list
  *
  * Transition is triggered as following:
  *
- * -> pending_list : a descriptor submission to the channel
- * pending_list -> pending_desc: request to issue pending a descriptor
+ * -> allocated_desc : a descriptor allocation
+ * allocated_desc -> submitted_desc: a descriptorsubmission
+ * submitted_desc -> pending_desc: request to issue pending a descriptor
  * pending_desc -> active_desc: VSYNC intr when a desc is scheduled to DPDMA
  * active_desc -> done_list: VSYNC intr when DPDMA switches to a new desc
  */
@@ -279,7 +280,8 @@ enum xilinx_dpdma_chan_status {
  * @desc_pool: descriptor allocation pool
  * @done_task: done IRQ bottom half handler
  * @err_task: error IRQ bottom half handler
- * @pending_list: pending descriptor list
+ * @allocated_desc: allocated descriptor
+ * @submitted_desc: submitted descriptor
  * @pending_desc: pending descriptor to be scheduled in next period
  * @active_desc: descriptor that the DPDMA channel is active on
  * @done_list: done descriptor list
@@ -300,7 +302,8 @@ struct xilinx_dpdma_chan {
 	struct tasklet_struct done_task;
 	struct tasklet_struct err_task;
 
-	struct list_head pending_list;
+	struct xilinx_dpdma_tx_desc *allocated_desc;
+	struct xilinx_dpdma_tx_desc *submitted_desc;
 	struct xilinx_dpdma_tx_desc *pending_desc;
 	struct xilinx_dpdma_tx_desc *active_desc;
 	struct list_head done_list;
@@ -612,6 +615,12 @@ xilinx_dpdma_chan_submit_tx_desc(struct xilinx_dpdma_chan *chan,
 	unsigned long flags;
 
 	spin_lock_irqsave(&chan->lock, flags);
+
+	if (chan->submitted_desc) {
+		cookie = chan->submitted_desc->async_tx.cookie;
+		goto out_unlock;
+	}
+
 	cookie = dma_cookie_assign(&tx_desc->async_tx);
 
 	/* Assign the cookie to descriptors in this transaction */
@@ -619,11 +628,18 @@ xilinx_dpdma_chan_submit_tx_desc(struct xilinx_dpdma_chan *chan,
 	list_for_each_entry(sw_desc, &tx_desc->descriptors, node)
 		sw_desc->hw.desc_id = cookie;
 
-	list_add_tail(&tx_desc->node, &chan->pending_list);
+	if (tx_desc != chan->allocated_desc)
+		dev_err(chan->xdev->dev, "desc != allocated_desc\n");
+	else
+		chan->allocated_desc = NULL;
+	chan->submitted_desc = tx_desc;
+
 	if (chan->id == VIDEO1 || chan->id == VIDEO2) {
 		chan->video_group = true;
 		chan->xdev->chan[VIDEO0]->video_group = true;
 	}
+
+out_unlock:
 	spin_unlock_irqrestore(&chan->lock, flags);
 
 	return cookie;
@@ -665,7 +681,10 @@ static void xilinx_dpdma_chan_free_all_desc(struct xilinx_dpdma_chan *chan)
 	dev_dbg(chan->xdev->dev, "chan->status = %s\n",
 		chan->status == STREAMING ? "STREAMING" : "IDLE");
 
-	xilinx_dpdma_chan_free_desc_list(chan, &chan->pending_list);
+	xilinx_dpdma_chan_free_tx_desc(chan, chan->allocated_desc);
+	chan->allocated_desc = NULL;
+	xilinx_dpdma_chan_free_tx_desc(chan, chan->submitted_desc);
+	chan->submitted_desc = NULL;
 	xilinx_dpdma_chan_free_tx_desc(chan, chan->pending_desc);
 	chan->pending_desc = NULL;
 	xilinx_dpdma_chan_free_tx_desc(chan, chan->active_desc);
@@ -802,6 +821,9 @@ xilinx_dpdma_chan_prep_slave_sg(struct xilinx_dpdma_chan *chan,
 	struct scatterlist *iter = sgl;
 	u32 line_size = 0;
 
+	if (chan->allocated_desc)
+		return &chan->allocated_desc->async_tx;
+
 	tx_desc = xilinx_dpdma_chan_alloc_tx_desc(chan);
 	if (!tx_desc)
 		return NULL;
@@ -854,6 +876,8 @@ xilinx_dpdma_chan_prep_slave_sg(struct xilinx_dpdma_chan *chan,
 	last->hw.control |= XILINX_DPDMA_DESC_CONTROL_COMPLETE_INTR;
 	last->hw.control |= XILINX_DPDMA_DESC_CONTROL_LAST_OF_FRAME;
 
+	chan->allocated_desc = tx_desc;
+
 	return &tx_desc->async_tx;
 
 error:
@@ -884,6 +908,9 @@ xilinx_dpdma_chan_prep_cyclic(struct xilinx_dpdma_chan *chan,
 	unsigned int periods = buf_len / period_len;
 	unsigned int i;
 
+	if (chan->allocated_desc)
+		return &chan->allocated_desc->async_tx;
+
 	tx_desc = xilinx_dpdma_chan_alloc_tx_desc(chan);
 	if (!tx_desc)
 		return NULL;
@@ -929,6 +956,8 @@ xilinx_dpdma_chan_prep_cyclic(struct xilinx_dpdma_chan *chan,
 		xilinx_dpdma_sw_desc_next_32(last, sw_desc);
 	last->hw.control |= XILINX_DPDMA_DESC_CONTROL_LAST_OF_FRAME;
 
+	chan->allocated_desc = tx_desc;
+
 	return &tx_desc->async_tx;
 
 error:
@@ -963,6 +992,9 @@ xilinx_dpdma_chan_prep_interleaved(struct xilinx_dpdma_chan *chan,
 		return NULL;
 	}
 
+	if (chan->allocated_desc)
+		return &chan->allocated_desc->async_tx;
+
 	tx_desc = xilinx_dpdma_chan_alloc_tx_desc(chan);
 	if (!tx_desc)
 		return NULL;
@@ -984,6 +1016,7 @@ xilinx_dpdma_chan_prep_interleaved(struct xilinx_dpdma_chan *chan,
 	hw_desc->control |= XILINX_DPDMA_DESC_CONTROL_LAST_OF_FRAME;
 
 	list_add_tail(&sw_desc->node, &tx_desc->descriptors);
+	chan->allocated_desc = tx_desc;
 
 	return &tx_desc->async_tx;
 
@@ -1084,29 +1117,26 @@ xilinx_dpdma_chan_video_group_ready(struct xilinx_dpdma_chan *chan)
  * xilinx_dpdma_chan_issue_pending - Issue the pending descriptor
  * @chan: DPDMA channel
  *
- * Issue the first pending descriptor from @chan->pending_list. If the channel
+ * Issue the first pending descriptor from @chan->submitted_desc. If the channel
  * is already streaming, the channel is re-triggered with the pending
  * descriptor.
  */
 static void xilinx_dpdma_chan_issue_pending(struct xilinx_dpdma_chan *chan)
 {
 	struct xilinx_dpdma_device *xdev = chan->xdev;
-	struct xilinx_dpdma_tx_desc *tx_desc;
 	struct xilinx_dpdma_sw_desc *sw_desc;
 	unsigned long flags;
 	u32 reg, channels;
 
 	spin_lock_irqsave(&chan->lock, flags);
 
-	if (list_empty(&chan->pending_list) || chan->pending_desc)
+	if (!chan->submitted_desc || chan->pending_desc)
 		goto out_unlock;
 
-	tx_desc = list_first_entry(&chan->pending_list,
-				   struct xilinx_dpdma_tx_desc, node);
-	list_del(&tx_desc->node);
-	chan->pending_desc = tx_desc;
+	chan->pending_desc = chan->submitted_desc;
+	chan->submitted_desc = NULL;
 
-	sw_desc = list_first_entry(&tx_desc->descriptors,
+	sw_desc = list_first_entry(&chan->pending_desc->descriptors,
 				   struct xilinx_dpdma_sw_desc, node);
 	dpdma_write(chan->reg, XILINX_DPDMA_CH_DESC_START_ADDR,
 		    (u32)sw_desc->phys);
@@ -1156,7 +1186,7 @@ static void xilinx_dpdma_chan_start(struct xilinx_dpdma_chan *chan)
 
 	spin_lock_irqsave(&chan->lock, flags);
 
-	if (list_empty(&chan->pending_list) || chan->status == STREAMING)
+	if (!chan->submitted_desc || chan->status == STREAMING)
 		goto out_unlock;
 
 	xilinx_dpdma_chan_unpause(chan);
@@ -1432,13 +1462,14 @@ static void xilinx_dpdma_chan_handle_err(struct xilinx_dpdma_chan *chan)
 		switch (chan->active_desc->status) {
 		case ACTIVE:
 		case PREPARED:
-			if (chan->pending_desc) {
-				list_add(&chan->pending_desc->node,
-					 &chan->pending_list);
-				chan->pending_desc = NULL;
-			}
+			xilinx_dpdma_chan_free_tx_desc(chan,
+						       chan->submitted_desc);
+			chan->submitted_desc = NULL;
+			xilinx_dpdma_chan_free_tx_desc(chan,
+						       chan->pending_desc);
+			chan->pending_desc = NULL;
 			chan->active_desc->status = ERRORED;
-			list_add(&chan->active_desc->node, &chan->pending_list);
+			chan->submitted_desc = chan->active_desc;
 			break;
 		case ERRORED:
 			dev_err(dev, "desc is dropped by unrecoverable err\n");
@@ -1833,7 +1864,6 @@ xilinx_dpdma_chan_probe(struct device_node *node,
 	chan->status = IDLE;
 
 	spin_lock_init(&chan->lock);
-	INIT_LIST_HEAD(&chan->pending_list);
 	INIT_LIST_HEAD(&chan->done_list);
 	init_waitqueue_head(&chan->wait_to_stop);
 
-- 
1.7.5.4

