From 54386a3fd84c7d8b03a5ec1857d53089bf2ce827 Mon Sep 17 00:00:00 2001
From: Kevin Hao <kexin.hao@windriver.com>
Date: Thu, 27 Jun 2013 11:22:41 +0800
Subject: [PATCH 5/9] powerpc: introduce PPC_PIN_SIZE for 6xx

For a relocatable kdump kernel, we may create a tlb map which is
beyond the real memory allocated to the kdump kernel. For example,
when the boot kernel reserve 32M memory for the kdump kernel by
using 'crashkernel=32M@64M', we will have to create a 128M tlb
entry in the kdump kernel. So define PPC_PIN_SIZE for 6xx,
this will make sure that we still get the right VMALLOC_START in
this case.

Signed-off-by: Kevin Hao <kexin.hao@windriver.com>
---
 arch/powerpc/include/asm/mmu-hash32.h |    3 +++
 arch/powerpc/mm/ppc_mmu_32.c          |   18 +++++++++++++++---
 2 files changed, 18 insertions(+), 3 deletions(-)

diff --git a/arch/powerpc/include/asm/mmu-hash32.h b/arch/powerpc/include/asm/mmu-hash32.h
index 16f513e..be4e192 100644
--- a/arch/powerpc/include/asm/mmu-hash32.h
+++ b/arch/powerpc/include/asm/mmu-hash32.h
@@ -90,4 +90,7 @@ typedef struct {
 #define mmu_virtual_psize	MMU_PAGE_4K
 #define mmu_linear_psize	MMU_PAGE_256M
 
+/* The max size that one tlb can map in a 32bit kernel. */
+#define PPC_PIN_SIZE	(1 << 28)	/* 256M */
+
 #endif /* _ASM_POWERPC_MMU_HASH32_H_ */
diff --git a/arch/powerpc/mm/ppc_mmu_32.c b/arch/powerpc/mm/ppc_mmu_32.c
index 99ce477..5d8a8a9 100644
--- a/arch/powerpc/mm/ppc_mmu_32.c
+++ b/arch/powerpc/mm/ppc_mmu_32.c
@@ -76,6 +76,7 @@ unsigned long __init mmu_mapin_ram(unsigned long top)
 {
 	unsigned long tot, bl, done;
 	unsigned long max_size = (256<<20);
+	phys_addr_t phys = memstart_addr;
 
 	if (__map_without_bats) {
 		printk(KERN_DEBUG "RAM mapped without BATs\n");
@@ -86,13 +87,24 @@ unsigned long __init mmu_mapin_ram(unsigned long top)
 
 	/* Make sure we don't map a block larger than the
 	   smallest alignment of the physical address. */
-	tot = top + memstart_addr;
+	tot = top;
+
+#ifdef CONFIG_RELOCATABLE
+	/*
+	 * For a relocatable kernel, we would not map from memstart_addr.
+	 * We first align to PPC_PIN_SIZE (256M), then map the PAGE_OFFSET
+	 * from there.
+	 */
+	phys &= ~(PPC_PIN_SIZE - 1);
+	tot += memstart_addr & (PPC_PIN_SIZE - 1);
+#endif
+
 	for (bl = 128<<10; bl < max_size; bl <<= 1) {
 		if (bl * 2 > tot)
 			break;
 	}
 
-	setbat(2, PAGE_OFFSET, 0, bl, PAGE_KERNEL_X);
+	setbat(2, PAGE_OFFSET, phys, bl, PAGE_KERNEL_X);
 	done = (unsigned long)bat_addrs[2].limit - PAGE_OFFSET + 1;
 	if ((done < tot) && !bat_addrs[3].limit) {
 		/* use BAT3 to cover a bit more */
@@ -100,7 +112,7 @@ unsigned long __init mmu_mapin_ram(unsigned long top)
 		for (bl = 128<<10; bl < max_size; bl <<= 1)
 			if (bl * 2 > tot)
 				break;
-		setbat(3, PAGE_OFFSET+done, done, bl, PAGE_KERNEL_X);
+		setbat(3, PAGE_OFFSET+done, done + phys, bl, PAGE_KERNEL_X);
 		done = (unsigned long)bat_addrs[3].limit - PAGE_OFFSET + 1;
 	}
 
-- 
1.7.5.4

