From f4a846586eab84068a590f22e3864f02cfe34e5b Mon Sep 17 00:00:00 2001
From: Hareesh R <hareeshr@broadcom.com>
Date: Tue, 6 Mar 2012 13:56:40 +0530
Subject: [PATCH 726/762] bcm_xlp: SAE: Cryptolib changes for tcmalloc library

SAE: Cryptolib changes for tcmalloc library

Based on Broadcom SDK 2.3.

Signed-off-by: Hareesh R <hareeshr@broadcom.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 drivers/crypto/sae/cryptoapi.c |  149 ++++++++++++++++++++++++++--------------
 drivers/crypto/sae/cryptodev.h |   81 +++++++++++++++-------
 drivers/crypto/sae/nlmcrypto.h |   22 ++++++-
 3 files changed, 174 insertions(+), 78 deletions(-)

diff --git a/drivers/crypto/sae/cryptoapi.c b/drivers/crypto/sae/cryptoapi.c
index 7630972..fcb4d3a 100644
--- a/drivers/crypto/sae/cryptoapi.c
+++ b/drivers/crypto/sae/cryptoapi.c
@@ -48,11 +48,9 @@
 #include <nlm_hal_macros.h>
 #include <nlm_hal_xlp_dev.h>
 #include <nlm_hal_fmn.h>
-#include "cryptodev.h"
-#define CRYPTO_API_drivers/crypto/sae
 //#define NLM_CRYPTO_DEBUG_EN
 #include "nlmcrypto.h"
-
+#include "cryptodev.h"
 /**
 * @file_name drivers/crypto/sae/cryptoapi.c
 */
@@ -92,8 +90,7 @@ static inline int crypto_async_push_msg(struct nlm_crypto_ctx *ctx)
 	if(fifo_full(ctx->mtail, ctx->max_msgs, ctx->mhead))
 		return NLM_CRYPTO_EBUSY;
 	ctx->mtail = (ctx->mtail + 1) % ctx->max_msgs;
-	ctx->msgs[ctx->mtail].msg[0] = 0ULL;
-	ctx->msgs[ctx->mtail].msg[1] = 0ULL;
+	ctx->req[ctx->mtail].msg[NLM_CRYPTO_REQ_RSPIDX] = ctx->rsp->msg[ctx->mtail][NLM_CRYPTO_RSP_RSPIDX];
 	ctx->rsp_pend++;
 	return ctx->mtail;
 }
@@ -104,19 +101,23 @@ static inline int crypto_async_pop_msg(struct nlm_crypto_ctx *ctx, void **ctrl,
 	if(fifo_empty(ctx->mtail, ctx->mhead))
 		return 0;
 	tmp = (ctx->mhead + 1) % ctx->max_msgs;
-	if((!ctx->msgs[tmp].msg[0]) && (!ctx->msgs[tmp].msg[1]))
+	if(ctx->req[tmp].msg[NLM_CRYPTO_REQ_RSPIDX] == ctx->rsp->msg[tmp][NLM_CRYPTO_RSP_RSPIDX])
 	       return 0;	
 	ctx->mhead = tmp;
-	 ctx->rsp_pend--;
+	ctx->rsp_pend--;
 	if(ctrl)
-		*ctrl = (void *)ctx->msgs[tmp].msg[2];
+		*ctrl = (void *)ctx->req[tmp].msg[0];
 	if(param)
-		*param = (void *)ctx->msgs[tmp].msg[3];
+		*param = (void *)ctx->req[tmp].msg[1];
 	if(arg)
-		*arg = (void *)ctx->msgs[tmp].msg[4];
+		*arg = (void *)ctx->req[tmp].msg[2];
 	return 1;
 }
 
+#define gen_msg_2(ctx, rv)  \
+	((uint64_t)ctx->rsp->sessionid << NLM_CRYPTO_SESSION_ID_OFF) | \
+	((uint64_t)ctx->rsp->index << NLM_CRYPTO_RSP_ID_OFF) | \
+	 (uint64_t)rv << NLM_CRYPTO_ASYNC_MSG_OUT_OFF 
 
 /**
 * @brief The crypto lib init fuction calls the application specific init function.
@@ -181,7 +182,7 @@ nlm_crypto_ctx_t *nlm_crypto_open_sync_session(int sync_mode, int cpu, void *arg
 	/* In sync, as there is no way to order the requests and response, only one 
 	 outstanding request is allowed. */
 
-	size =  sizeof(struct nlm_crypto_ctx) + max_outstanding_reqs * sizeof(struct nlm_crypto_msg);
+	size =  sizeof(struct nlm_crypto_ctx);
 	if((ctx = crypto_malign(XLP_CACHELINE_SIZE, size)) == NULL) {
 		errno = ENOMEM;
 		goto err_exit;
@@ -208,8 +209,7 @@ nlm_crypto_ctx_t *nlm_crypto_open_sync_session(int sync_mode, int cpu, void *arg
 		ctx->fd = eventfd(0, 0);
 		if(ctx->fd < 0) 
 			goto err_exit;
-		ctx->fdctxt = crypto_get_eventfd_ctxt(crypto_virt_to_phys(ctx));
-		if(ctx->fdctxt == 0) {
+		if(crypto_ctxt_alloc(ctx) < 0) {
 			close(ctx->fd);
 			goto err_exit;
 		}
@@ -253,17 +253,19 @@ nlm_crypto_ctx_t *nlm_crypto_open_async_session(int max_outstanding_reqs,
 	int size;
 	struct nlm_crypto_ctx *ctx = NULL;
 
-	if(max_outstanding_reqs > NLM_CRYPTO_MAX_OUT_REQS || iparam.sae_rx_vc < 0) {
+	if(max_outstanding_reqs > NLM_CRYPTO_MAX_PENDING_REQS_PER_CTXT || iparam.sae_rx_vc < 0) {
 		nlm_err_print("Error : Invalid param reqs %d(%d) or sae_rx_vc %d\n", 
-				max_outstanding_reqs, NLM_CRYPTO_MAX_OUT_REQS, iparam.sae_rx_vc);
+				max_outstanding_reqs, NLM_CRYPTO_MAX_PENDING_REQS_PER_CTXT, iparam.sae_rx_vc);
 		errno = EINVAL;
 		return NULL;
 	}
+
 	/* We need one more for push and pop operation, where one entry will not be 
 	 used for storing data */
-	max_outstanding_reqs++;
+	if(max_outstanding_reqs == NLM_CRYPTO_MAX_PENDING_REQS_PER_CTXT)
+		max_outstanding_reqs--;
 			       
-	size =  sizeof(struct nlm_crypto_ctx) + max_outstanding_reqs * sizeof(struct nlm_crypto_msg);
+	size =  sizeof(struct nlm_crypto_ctx);
 	if((ctx = crypto_malign(XLP_CACHELINE_SIZE, size)) == NULL) {
 		errno = ENOMEM;
 		goto err_exit;
@@ -280,11 +282,12 @@ nlm_crypto_ctx_t *nlm_crypto_open_async_session(int max_outstanding_reqs,
 	ctx->fd = eventfd(0, 0);
 	if(ctx->fd < 0) 
 		goto err_exit;
-	ctx->fdctxt = crypto_get_eventfd_ctxt(crypto_virt_to_phys(ctx));
-	if(ctx->fdctxt == 0) {
+	if(crypto_ctxt_alloc(ctx) < 0) {
 		close(ctx->fd);
 		goto err_exit;
 	}
+	
+	
 #endif
 	ctx->async_callback = (uint64_t)callback;
 	ctx->mhead = 0;
@@ -320,7 +323,7 @@ int nlm_crypto_close_session(nlm_crypto_ctx_t *ctxt)
 		return NLM_CRYPTO_EBUSY;
 	}
 	if(ctx->fd) {
-		if((rv = crypto_put_eventfd_ctxt(crypto_virt_to_phys(ctx))) < 0)
+		if((rv = crypto_ctxt_free(ctx)) < 0)
 			return rv;
 		if(close(ctx->fd) < 0)
 			return NLM_CRYPTO_ERROR;
@@ -387,9 +390,14 @@ struct nlm_crypto_rsa_param *nlm_crypto_rsa_param_alloc(nlm_crypto_ctx_t *ctxt,
 	int blksz_nbytes = blksz_nbits >> 3;
 	int size = sizeof(struct nlm_crypto_rsa_param) + XLP_CACHELINE_SIZE + 
 		(blksz_nbytes * NLM_CRYPTO_RSA_PARAMS_NELMNTS);
-	int i;
+	int i, alignment;
 
-	if((prsa = crypto_malign(XLP_CACHELINE_SIZE, size)) == NULL) {
+	/* As the default memory allocator allocates only 128K of physically contiguous memory, 
+	 play with the alignment to get the cont memory
+	 */
+	alignment = crypto_roundup(size, NLM_CRYPTO_DEF_PARAM_ALIGNMENT);
+	
+	if((prsa = crypto_malign(alignment, size)) == NULL) {
 		errno = ENOMEM;
 		return NULL;
 	}
@@ -425,9 +433,14 @@ struct  nlm_crypto_ecc_param *nlm_crypto_ecc_param_alloc(nlm_crypto_ctx_t *ctxt,
 	int blksz_nbytes = blksz_nbits >> 3;
 	int size = sizeof(struct nlm_crypto_ecc_param) + XLP_CACHELINE_SIZE + 
 		(blksz_nbytes * NLM_CRYPTO_ECC_PARAMS_NELMNTS);
-	int i;
+	int i, alignment;
 
-	if((pecc = crypto_malign(XLP_CACHELINE_SIZE, size)) == NULL) {
+	/* As the default memory allocator allocates only 128K of physically contiguous memory, 
+	 play with the alignment to get the cont memory
+	 */
+	alignment = crypto_roundup(size, NLM_CRYPTO_DEF_PARAM_ALIGNMENT);
+
+	if((pecc = crypto_malign(alignment, size)) == NULL) {
 		errno = ENOMEM;
 		return NULL;
 	}
@@ -484,10 +497,17 @@ struct nlm_crypto_rsa_result *nlm_crypto_rsa_result_alloc(nlm_crypto_ctx_t *ctxt
 	uint32_t elmnts  = NLM_CRYPTO_RSA_RESULT_NELMNTS;
 	unsigned char **params;
 	unsigned char *result , *r;
-	int blksz_nbytes = blksz_nbits >> 3, i;
+	int blksz_nbytes = blksz_nbits >> 3, i, alignment, size;
+
+	/* XLP_CACHELINE_SIZE covers the size of the structure*/
+	size = (blksz_nbytes * elmnts) + XLP_CACHELINE_SIZE; 
 
-	result = crypto_malign(XLP_CACHELINE_SIZE, (blksz_nbytes * elmnts) + 
-			XLP_CACHELINE_SIZE /* this covers the size of the structure*/);
+	/* As the default memory allocator allocates only 128K of physically contiguous memory, 
+	 play with the alignment to get the cont memory
+	 */
+	alignment = crypto_roundup(size, NLM_CRYPTO_DEF_PARAM_ALIGNMENT);
+
+	result = crypto_malign(alignment, size);
 	if(!result) {
 		errno = ENOMEM;
 		return NULL;
@@ -523,10 +543,17 @@ struct nlm_crypto_ecc_result *nlm_crypto_ecc_result_alloc(nlm_crypto_ctx_t *ctxt
 	uint32_t elmnts  = NLM_CRYPTO_ECC_RESULT_NELMNTS;
 	unsigned char **params;
 	unsigned char *result , *r;
-	int blksz_nbytes = blksz_nbits >> 3, i;
+	int blksz_nbytes = blksz_nbits >> 3, i, alignment, size;
+
+	/*  XLP_CACHELINE_SIZE covers the size of the structure*/
+	size = (blksz_nbytes * elmnts) + XLP_CACHELINE_SIZE; 
 
-	result = crypto_malign(XLP_CACHELINE_SIZE, (blksz_nbytes * elmnts) + 
-			XLP_CACHELINE_SIZE /* this covers the size of the structure*/);
+	/* As the default memory allocator allocates only 128K of physically contiguous memory, 
+	 play with the alignment to get the cont memory
+	 */
+	alignment = crypto_roundup(size, NLM_CRYPTO_DEF_PARAM_ALIGNMENT);
+
+	result = crypto_malign(alignment, size);
 	if(!result) {
 		errno = ENOMEM;
 		return NULL;
@@ -578,7 +605,7 @@ int nlm_crypto_do_op(nlm_crypto_ctx_t *ctxt, enum nlm_crypto_op_type_t optype,
 		void *ctrl,  void *param, int nsegs, void *arg)
 {
 	struct nlm_crypto_ctx *ctx = ctxt;
-	uint64_t msg0, msg1;
+	uint64_t msg0, msg1, msg2;
 	uint32_t size, code, src;
 	int cpu = my_cpu_id(), type, op;
 	int dstvc_base, dstvc_lmt, etype;
@@ -664,7 +691,7 @@ int nlm_crypto_do_op(nlm_crypto_ctx_t *ctxt, enum nlm_crypto_op_type_t optype,
 
 		crypto_lock(&crypto_sync_lock[cpu]);
 		ctx->rsp_pend++;
-		xlp_message_send_block_fast_3(0, dstvc_base, msg0, msg1, crypto_virt_to_phys(ctx));
+		xlp_message_send_block_fast_3(0, dstvc_base, msg0, msg1, 0ULL);
 cont_rcv:
 		while(xlp_message_receive_2(ctx->rx_vc, &src, &size, &code, &msg0, &msg1) != 0);
 
@@ -695,9 +722,11 @@ cont_rcv:
 		nlm_dbg_print("Mode is shared-vc\n");
 		
 		crypto_lock((cryptolock_t *)&ctx->lock);
-		ctx->msgs[0].msg[0] = 0ULL;
-		ctx->msgs[0].msg[1] = 0ULL;
-		xlp_message_send_block_fast_3(0, dstvc_base, msg0, msg1, crypto_virt_to_phys(ctx));
+		ctx->req[0].msg[NLM_CRYPTO_REQ_RSPIDX] = ctx->rsp->msg[0][NLM_CRYPTO_RSP_RSPIDX];
+
+		msg2 = gen_msg_2(ctx, 0);
+		nlm_dbg_print("Do op msg2 %llx\n", (unsigned long long)msg2);
+		xlp_message_send_block_fast_3(0, dstvc_base, msg0, msg1, msg2);
 		ctx->rsp_pend++;
 
 		pfd[0].fd = ctx->fd;
@@ -721,10 +750,11 @@ cont_poll:
 			return NLM_CRYPTO_ERROR;;
 		}
 		
-		msg0 = ctx->msgs[0].msg[0];
-		msg1 = ctx->msgs[0].msg[1];
-		if((msg0 == 0ULL) && (msg1 == 0ULL))
+		msg0 = ctx->rsp->msg[0][0];
+		if(ctx->req[0].msg[NLM_CRYPTO_REQ_RSPIDX] == ctx->rsp->msg[0][NLM_CRYPTO_RSP_RSPIDX])
 			goto cont_poll;
+		if(etype == 1)
+			msg1 = msg0;
 
 		ctx->rsp_pend--;
 		crypto_unlock((cryptolock_t *)&ctx->lock);
@@ -748,12 +778,13 @@ cont_poll:
 		}
 		crypto_unlock((cryptolock_t *)&ctx->lock);
 		/* save the param and result */
-		ctx->msgs[rv].msg[2] = (uint64_t)ctrl;
-		ctx->msgs[rv].msg[3] = (uint64_t)param;
-		ctx->msgs[rv].msg[4] = (uint64_t)arg;
+		ctx->req[rv].msg[0] = (uint64_t)ctrl;
+		ctx->req[rv].msg[1] = (uint64_t)param;
+		ctx->req[rv].msg[2] = (uint64_t)arg;
 
-		xlp_message_send_block_fast_3(0, dstvc_base, msg0, msg1, (crypto_virt_to_phys(ctx) 
-				| (uint64_t)rv << NLM_CRYPTO_ASYNC_MSG_OUT_INDEX));
+		msg2 = gen_msg_2(ctx, rv);
+		nlm_dbg_print("Do op msg3 %llx\n", (unsigned long long)msg2);
+		xlp_message_send_block_fast_3(0, dstvc_base, msg0, msg1, msg2);
 	}
 
 	return NLM_CRYPTO_OK;
@@ -811,16 +842,16 @@ int nlm_crypto_aync_callback(enum nlm_crypto_op_type_t type, unsigned long long
 	int (*func)(nlm_crypto_ctx_t *, void *, void *, void *);
 
 	if(type == NLM_CRYPTO_PKT) {
-		instance = msg0 >> NLM_CRYPTO_ASYNC_MSG_OUT_INDEX;
+		instance = msg0 >> NLM_CRYPTO_ASYNC_MSG_OUT_OFF;
 		ctx = crypto_phys_to_virt(msg0 & 0xffffffffffULL);
 	} else {
-		instance = msg1 >> NLM_CRYPTO_ASYNC_MSG_OUT_INDEX;
+		instance = msg1 >> NLM_CRYPTO_ASYNC_MSG_OUT_OFF;
 		ctx = crypto_phys_to_virt(msg1 & 0xffffffffffULL);
 	}
 
-	ctrl = (void *)ctx->msgs[instance].msg[2];
-	param = (void *)ctx->msgs[instance].msg[3];
-	arg = (void *)ctx->msgs[instance].msg[4];
+	ctrl = (void *)ctx->req[instance].msg[0];
+	param = (void *)ctx->req[instance].msg[1];
+	arg = (void *)ctx->req[instance].msg[2];
 
 	func = (void *)ctx->async_callback;
 
@@ -874,7 +905,14 @@ void nlm_crypto_mfree(void *ptr)
 */
 struct nlm_crypto_pkt_ctrl *nlm_crypto_pkt_ctrl_alloc(nlm_crypto_ctx_t *ctxt)
 {
-	 return crypto_malign(XLP_CACHELINE_SIZE, sizeof(struct nlm_crypto_pkt_ctrl));
+	int alignment, size;
+	size = sizeof(struct nlm_crypto_pkt_ctrl);
+	/* As the default memory allocator allocates only 128K of physically contiguous memory, 
+	   play with the alignment to get the cont memory
+	 */
+	alignment = crypto_roundup(size, NLM_CRYPTO_DEF_PARAM_ALIGNMENT);  
+
+	return crypto_malign(alignment, sizeof(struct nlm_crypto_pkt_ctrl));
 }
 
 /**
@@ -891,10 +929,19 @@ struct nlm_crypto_pkt_ctrl *nlm_crypto_pkt_ctrl_alloc(nlm_crypto_ctx_t *ctxt)
 */
 struct nlm_crypto_pkt_param *nlm_crypto_pkt_param_alloc(nlm_crypto_ctx_t *ctxt, unsigned int nsegs)
 {
-	void *ptr = crypto_malign(XLP_CACHELINE_SIZE, (sizeof(struct nlm_crypto_pkt_param) + (16 * nsegs)));
+	void *ptr;
+	int alignment, size;
+
+	size = sizeof(struct nlm_crypto_pkt_param) + (16 * nsegs);
+	/* As the default memory allocator allocates only 128K of physically contiguous memory, 
+	 play with the alignment to get the cont memory
+	 */
+	alignment = crypto_roundup(size, NLM_CRYPTO_DEF_PARAM_ALIGNMENT);  
+
+	ptr = crypto_malign(alignment, size);
 	/* memset requires as the source and dst segments can be unequal but 
 	we copy only the valid ones */
-	memset(ptr, 0, sizeof(struct nlm_crypto_pkt_param) + (16 * nsegs));
+	memset(ptr, 0, size);
 	return ptr;
 }
 
diff --git a/drivers/crypto/sae/cryptodev.h b/drivers/crypto/sae/cryptodev.h
index 0c21f3a..fe32a34 100644
--- a/drivers/crypto/sae/cryptodev.h
+++ b/drivers/crypto/sae/cryptodev.h
@@ -32,12 +32,14 @@
 
 #define NLM_CRYPTO_DEV_NAME "nlmcrypto"
 
-enum crypto_ioctl_events { 
-		NLM_CRYPTO_GET_EVENTFD_CTXT = 1, NLM_CRYPTO_PUT_EVENTFD_CTXT,
-		NLM_CRYPTO_GET_RX_VC_NUMS, NLM_CRYPTO_GET_COMMON_SHM_ADDR_SZ,
-		NLM_CRYPTO_SHMMEM_ALLOC, NLM_CRYPTO_SHMMEM_FREE,
-	       NLM_CRYPTO_GET_SAE_VC_NUMS
-};
+#define NLM_CRYPTO_IOC 'C'
+
+#define NLM_CRYPTO_CTXT_ALLOC 			_IOWR(NLM_CRYPTO_IOC, 1, unsigned long long *)
+#define NLM_CRYPTO_CTXT_FREE			_IOWR(NLM_CRYPTO_IOC, 2, unsigned long long *)
+#define NLM_CRYPTO_GET_RX_VC_NUMS 		_IOWR(NLM_CRYPTO_IOC, 3, unsigned int *)
+#define NLM_CRYPTO_GET_COMMON_SHM_ADDR_SZ 	_IOWR(NLM_CRYPTO_IOC, 4, unsigned long long *)
+#define NLM_CRYPTO_GET_SAE_VC_NUMS		_IOWR(NLM_CRYPTO_IOC, 5, unsigned int *)
+
 
 #ifndef XLP_CACHELINE_SIZE
 #define XLP_CACHELINE_SIZE 64
@@ -53,17 +55,50 @@ enum crypto_ioctl_events {
 #define NLM_CRYPTO_RSA_TYPE_SVALUE 		0x40
 #define NLM_CRYPTO_RSA_TYPE_EVALUE 		0x44
 
-/* In async when max_msgs > 1, the message send id is specified in 40th bit onwards
- int the msg3 */
-#define NLM_CRYPTO_ASYNC_MSG_OUT_INDEX 40
+/* In async when max_msgs > 1, the message send id is specified in 52nd bit onwards
+ int the msg2 
+ 0-31(32 bits) - session id
+ 32-51(20 bits) - rsp index 
+ 52-63(12 bits) - msg index */
+
+#define NLM_CRYPTO_SESSION_ID_OFF 0
+#define NLM_CRYPTO_GET_SESSION_ID(x) ((unsigned long long)x & ((1ULL << 32) - 1))
+
+#define NLM_CRYPTO_RSP_ID_OFF 32
+#define NLM_CRYPTO_GET_RSP_ID(x) (((unsigned long long)x >> 32) & ((1ULL << 20) - 1))
+
+#define NLM_CRYPTO_ASYNC_MSG_OUT_OFF 52
+#define NLM_CRYPTO_GET_ASYNC_MSG_OUT_ID(x) ((unsigned long long)x >> 52)
 
-/* Can be used by the kernel/netos for storing some data */
-#define NLM_CRYPOT_CTX_PRIV_DATA_SZ    64
+/* How many pages for the context response maintainance ,
+ Don't increast it as I am using a uint64_t variable to 
+ find the empty vs non-empty status . Play with the page-order instead */
+#define NLM_CRYPTO_MAX_CTXT_PAGES 64
 
-/* 0 and 1 are return msg, 
-   2 contains param vaddr, 3 contain result address, used only in async mode */
-struct nlm_crypto_msg {
-	volatile uint64_t msg[5]; 
+/* Message rsp index in request and response structures */
+#define NLM_CRYPTO_REQ_RSPIDX	3
+#define NLM_CRYPTO_RSP_RSPIDX	1
+
+struct nlm_crypto_req {
+	/* Used in async mode to save ctrl(0), param(1) and user-arg(2), and expected-rsp-index(3) */
+	volatile uint64_t msg[4]; 
+};
+
+struct nlm_crypto_rsp {
+	/* Used to save responses from the engine, used in async and shared-vc mode */
+	volatile uint64_t msg[NLM_CRYPTO_MAX_PENDING_REQS_PER_CTXT][2]; 
+	unsigned int nrcvd; /* number of messages received by kernel */
+	unsigned int index; 
+	unsigned int sessionid;
+	unsigned int owner; /* pid, Only it can delete the context */
+	unsigned int allocated; /* whether it is allocated or not */
+#ifdef NLM_HAL_LINUX_KERNEL
+	atomic_t used_by_intr; /* used by interrupt */
+#else
+	unsigned int used_by_intr;
+#endif
+	unsigned long long fdctxt;
+	char priv_data[16]; /* used by kernel*/
 };
 
 struct nlm_crypto_ctx {
@@ -86,13 +121,9 @@ struct nlm_crypto_ctx {
 	unsigned int mhead; /* head and tail for async operation */
 	unsigned int mtail;
 
-	/* Can be used by the kernel/netos for storing some data,
-	   cannot be accessed by the application  */
-	unsigned char priv_data[NLM_CRYPOT_CTX_PRIV_DATA_SZ];
-
-	uint64_t fdctxt;
 	uint64_t async_callback;
-	struct nlm_crypto_msg msgs[1];
+	struct nlm_crypto_req req[NLM_CRYPTO_MAX_PENDING_REQS_PER_CTXT];
+	struct nlm_crypto_rsp *rsp; /* mmaped to userspace and wrritten by the kernel */
 };
 
 
@@ -126,12 +157,12 @@ extern int contig_memory_init(void *shmaddr, unsigned long long paddr, unsigned
 #ifdef NLM_CRYPTO_LINUX_U
 /* Linux specific calls, no need to provide by others */
 extern int app_set_affinity(int cpu);
-extern uint64_t crypto_get_eventfd_ctxt(uint64_t ctxtpaddr);
-extern int crypto_put_eventfd_ctxt(uint64_t ctxtpaddr);
+extern int crypto_ctxt_alloc(struct nlm_crypto_ctx *);
+extern int crypto_ctxt_free(struct nlm_crypto_ctx *);
 #else
 static inline int app_set_affinity(int cpu) { return 0; }
-static inline uint64_t crypto_get_eventfd_ctxt(uint64_t ctxtpaddr) { return 0; }
-static inline int crypto_put_eventfd_ctxt(uint64_t ctxtpaddr) { return 0; }
+static inline int crypto_ctxt_alloc(struct nlm_crypto_ctx *ctx) { return 0; }
+static inline int crypto_ctxt_free(struct nlm_crypto_ctx *ctx) { return 0; }
 #endif //NLM_CRYPTO_LINUX_U
 
 
diff --git a/drivers/crypto/sae/nlmcrypto.h b/drivers/crypto/sae/nlmcrypto.h
index f8acdce..da75ddc 100644
--- a/drivers/crypto/sae/nlmcrypto.h
+++ b/drivers/crypto/sae/nlmcrypto.h
@@ -55,7 +55,6 @@ typedef void nlm_crypto_ctx_t;
 */
 #define nlm_crypto_get_ctxt_arg(ctxt) (*((unsigned long long *)ctxt + 1))
 
-#include "nlmcrypto_ifc.h"
 /**
 * @brief Crypto return values
 * @ingroup crypto
@@ -70,7 +69,7 @@ enum nlm_crypto_mode { NLM_CRYPTO_MODE_ASYNC = 1, NLM_CRYPTO_MODE_SYNC_EXLVC, NL
 
 /* Max value of this is 64, as we are using a uint64_t 
    to find out the empty or nonemty status */
-#define NLM_CRYPTO_MAX_OUT_REQS 64
+#define NLM_CRYPTO_MAX_PENDING_REQS_PER_CTXT 64
 
 /* seglen is 16 bits */
 #define NLM_CRYPTO_MAX_SEG_LEN (64 * 1024) 
@@ -258,6 +257,8 @@ struct nlm_crypto_ecc_ctrl  {
 #define NLM_CRYPTO_ECC_MAX_BLK_SIZE 576
 #define NLM_CRYPTO_ECC_PARAMS_NELMNTS 6
 
+#define NLM_CRYPTO_DEF_PARAM_ALIGNMENT	1024
+
 #ifndef NLM_ENCRYPT
 #define NLM_ENCRYPT 1
 #endif
@@ -473,6 +474,8 @@ static inline int nlm_crypto_fill_pkt_ctrl(struct nlm_crypto_pkt_ctrl *ctrl,
 	return 0;
 }
 
+#ifndef NLM_CRYPTO_EXCL_IFC
+#include "nlmcrypto_ifc.h"
 /**
 * @brief Top level function for generation pkt desc 0 to 3 for cipher auth
 * @ingroup crypto
@@ -604,6 +607,7 @@ static inline unsigned int nlm_crypto_fill_dst_seg(struct nlm_crypto_pkt_param *
 	}
 	return seg;
 }
+#endif
 
 #ifndef MAX_CPUS
 #define MAX_CPUS		128
@@ -695,6 +699,20 @@ static inline int crypto_get_lbs64(unsigned long long x)
 	return 64 - x;
 }
 
+/* find last bit cleared indication - from lsb to msb
+   clo instruction scans from msb to lsb for set bits 
+   get_lbc64(0) = 64, get_lbc64(0x80000000000000) = 63
+ */
+static inline int crypto_get_lbc64(unsigned long long x)
+{
+	__asm__(".set push	\n"
+		".set mips64	\n"
+		"dclo %0, %1	\n"
+		".set pop	\n"
+		: "=r" (x) 
+		: "r" (x));
+	return 64 - x;
+}
 
 #ifndef XLP_CACHELINE_SIZE
 #define XLP_CACHELINE_SIZE 64
-- 
1.7.0.4

