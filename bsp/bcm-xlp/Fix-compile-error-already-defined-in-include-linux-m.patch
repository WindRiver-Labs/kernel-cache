From deff4a86f8837dab78b5823a9b3c04969c72293c Mon Sep 17 00:00:00 2001
From: Zi Shen Lim <zlim@netlogicmicro.com>
Date: Fri, 30 Sep 2011 13:57:54 -0700
Subject: [PATCH 416/761] Fix compile error: already defined in
 include/linux/msi.h

Based on Broadcom SDK 2.3.

Signed-off-by: Zi Shen Lim <zlim@netlogicmicro.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/netlogic/xlp/irq.c |   97 ++++++++++++++----------------------------
 1 file changed, 33 insertions(+), 64 deletions(-)

diff --git a/arch/mips/netlogic/xlp/irq.c b/arch/mips/netlogic/xlp/irq.c
index e7cf764..1fa6dac 100644
--- a/arch/mips/netlogic/xlp/irq.c
+++ b/arch/mips/netlogic/xlp/irq.c
@@ -59,12 +59,6 @@ THE POSSIBILITY OF SUCH DAMAGE.
 /* Externs */
 extern void nlm_common_timer_interrupt(struct pt_regs *, int);
 extern void nlm_xlp_msgring_int_handler(int , struct pt_regs *);
-extern int xlp_ctrl_fn_from_dev(const struct pci_dev *);
-extern const struct cpumask *xlp_closest_match_cpumask(struct cpumask *);
-extern void xlp_intx_enable(int);
-extern void xlp_intx_disable(int);
-extern void xlp_set_cpumask(const struct cpumask *m, int irt);
-#if defined CONFIG_PCI_MSI
 extern int xlp_msi_status_clear(struct pci_dev *, int);
 extern int xlp_msi_enable(struct pci_dev *, u32);
 extern int xlp_msi_base_vector(struct pci_dev *);
@@ -74,13 +68,15 @@ extern void xlp_msi_disable(int, int);
 extern u32 xlp_msi_set_mask(int, int, int);
 volatile const void *xlp_msix_addr_start(int);
 volatile const void *xlp_msi_addr_start(int);
+extern int xlp_ctrl_fn_from_dev(const struct pci_dev *);
 extern u32 xlp_msix_status_clear(int);
 extern u32 xlp_msix_set_mask(int, int, int);
 extern int xlp_msix_enable(struct pci_dev *);
 extern void xlp_msix_disable(int);
-void mask_msi_irq(unsigned int);
-void unmask_msi_irq(unsigned int);
-#endif
+extern const struct cpumask *xlp_closest_match_cpumask(struct cpumask *);
+extern void xlp_set_cpumask(const struct cpumask *m, int irt);
+extern void xlp_intx_enable(int);
+extern void xlp_intx_disable(int);
 
 /* own variables */
 
@@ -95,7 +91,6 @@ static volatile uint64_t xlp_irq_mask;
  */
 DEFINE_SPINLOCK(xlp_pic_lock);
 EXPORT_SYMBOL(xlp_pic_lock);
-#if defined CONFIG_PCI_MSI
 /*
  * This bitmap keeps track of the MSI vectors allocated from
  * XLP_MSIX_IRQ_START(x)
@@ -105,7 +100,6 @@ struct msix_alloc_bitmap {
 	u32 count;	/* #of bits set at any point of time */
 };
 static struct msix_alloc_bitmap msix_vec[XLP_MAX_SLOTS];
-#endif
 
 /*
  * There are two data structures pivotal for interrupt delivery mechanism
@@ -496,10 +490,7 @@ static void __nlm_irq_mask(unsigned int irq)
 	if (rvec < 0) {
 		return;
 	}
-	if (read_64bit_cp0_eimr() & (1ULL << rvec)) {
-		/* We do not clear eimr, this is a TODO for later time */
-		//on_each_cpu(xlp_clear_eimr, (void *) (1ULL << rvec), 1);
-	}
+	on_each_cpu(xlp_clear_eimr, (void *) (1ULL << rvec), 1);
 	return;
 }
 
@@ -519,9 +510,8 @@ static void nlm_irq_mask(unsigned int irq)
 		pr_err("irq = %d. Invalid irq requested\n", irq);
 		return;
 	}
-	// Once enabled, we don't mask it out
 	//spin_lock_irqsave(&xlp_pic_lock, flags);	// Remove XXX
-	__nlm_irq_mask(irq);				// XXX
+	__nlm_irq_mask(irq);
 	//spin_unlock_irqrestore(&xlp_pic_lock, flags);	// XXX remove
 	return;
 }
@@ -537,11 +527,8 @@ static void __nlm_irq_unmask(int irq)
 
 	if (rvec < 0) {
 		return;
-	} else if (((1ULL << rvec) & read_64bit_cp0_eimr()) == 0) {
-		/* This is only for those interrupts which are not statically
-		 * set in EIMR. Could dump stack if spin lock held */
-		 on_each_cpu(xlp_set_eimr, (void *) (1ULL << rvec), 1);
 	}
+	on_each_cpu(xlp_set_eimr, (void *) (1ULL << rvec), 1);
 	return;
 }
 
@@ -689,14 +676,14 @@ static void nlm_irq_shutdown(unsigned int irq)
 	}
 	spin_lock_irqsave(&xlp_pic_lock, flags);
 	if (irq_map[irq].usage == 0) {
-		//fdebug("irq = %d, usage = %d\n", irq, irq_map[irq].usage);
+		fdebug("irq = %d, usage = %d\n", irq, irq_map[irq].usage);
 		spin_unlock_irqrestore(&xlp_pic_lock, flags);
 		return;
 	} else if (irq_map[irq].usage > 0) {
 		irq_map[irq].usage--;
 	}
 	if (irq_map[irq].usage == 0) {
-		//fdebug("irq = %d, usage = %d\n", irq, irq_map[irq].usage);
+		fdebug("irq = %d, usage = %d\n", irq, irq_map[irq].usage);
 		rvec = xlp_rvec_from_irq(irq);
 		idx = irq - __irqbase_from_rvec(rvec);
 		clear_bit(idx, &(rvec_map[rvec].bitmap));
@@ -857,7 +844,8 @@ void __cpuinit nlm_smp_irq_init(void)
 	/* Set up kseg0 to be cachable coherent */
 	change_c0_config(CONF_CM_CMASK, CONF_CM_DEFAULT);
 #endif
-	write_64bit_cp0_eimr(xlp_irq_mask);
+	/* set interrupt mask for non-zero cpus */
+	write_64bit_cp0_eimr(xlp_irq_mask | (1 << XLP_IRQ_TIMER));
 }
 
 void destroy_irq(unsigned int irq)
@@ -865,7 +853,7 @@ void destroy_irq(unsigned int irq)
     /* no-op */
 }
 
-#ifdef CONFIG_PCI_MSI
+#ifdef CONFIG_PCI_MSI_XLP
 
 /*
  * The MSI and MSI-X functionality is supported only by the PCIe Controller.
@@ -1111,13 +1099,13 @@ static int xlp_msi_compose_msg(struct pci_dev *pdev, struct msi_desc *desc,
 	if (fn < 0) return -EINVAL;
 	if (desc->msi_attrib.is_msix) {
 		if (irq < XLP_MSIX_INDEX_START) {	/* enforce minimum */
-			dev_err(&pdev->dev, "Invalid irq %d", irq);
+			fdebug("Invalid irq %d", irq);
 			return -EINVAL;
 		}
 		offset = irq - XLP_MSIX_INDEX_START;
 		msg->address_hi = (virt_to_phys(xlp_msix_addr_start(fn)) >> 32);
 		msg->address_lo = (virt_to_phys(xlp_msix_addr_start(fn)) & 0xffffffff);
-		//dev_dbg(&pdev->dev, "MSI-X hi = %#x, lo = %#x, data = %#x\n", msg->address_hi, msg->address_lo, offset);
+		dev_err(&pdev->dev, "MSI-X hi = %#x, lo = %#x, data = %#x\n", msg->address_hi, msg->address_lo, offset);
 	} else {
 		if (irq < XLP_MSI_IRQ_OFFSET) {	/* enforce minimum */
 			return -EINVAL;
@@ -1142,7 +1130,7 @@ u32 __xlp_msix_bitmask(int fn)
 
 	while (idx < XLP_MSIX_PER_SLOT) {
 		if (irq_map[XLP_MSIX_IRQ_START(fn) + idx].usage > 0) {
-			ret |= (1ULL << idx);
+			ret |= (1 << idx);
 		}
 		idx++;
 	}
@@ -1184,7 +1172,7 @@ void arch_teardown_msi_irq(unsigned int msi)
 		spin_lock_irqsave(&xlp_pic_lock, flags);
 		if (irq_map[msi].usage > 0) {
 			irq_map[msi].usage--;
-			msix_vec[fn].bitmap &= ~(1ULL << bit);
+			msix_vec[fn].bitmap &= ~(1 << bit);
 			msix_vec[fn].count--;
 		}
 		if (!__xlp_msix_bitmask(fn)) {
@@ -1220,7 +1208,7 @@ asmlinkage void plat_irq_dispatch(void)
 	eirr = read_64bit_cp0_eirr();
 	eimr = read_64bit_cp0_eimr();
 	eirr &= eimr;
-	if (eirr & (1ULL << XLP_IRQ_TIMER)) {
+	if (eirr & (1 << XLP_IRQ_TIMER)) {
 		nlm_common_timer_interrupt(pt_regs, XLP_IRQ_TIMER);
 		return;
 	}
@@ -1252,7 +1240,6 @@ asmlinkage void plat_irq_dispatch(void)
 		bitmap = rvec_map[rvec].bitmap;
 		spin_unlock_irqrestore(&xlp_pic_lock, flags);
 		switch(base_irq) {
-#if defined CONFIG_PCI_MSI
 		/* These are not MSIs, but IRT #s */
 		case XLP_PCIE_LINK_IRQ(0) ... XLP_PCIE_LINK_IRQ(3):
 			/* Here fn # of controller is easily calculated
@@ -1274,7 +1261,6 @@ asmlinkage void plat_irq_dispatch(void)
 			base_irq = XLP_MSIX_IRQ_START(fn);
 			/* now handle it as any other interrupt */
 			break;
-#endif
 		default:
 			break;
 		}
@@ -1303,7 +1289,6 @@ int nlm_xlp_request_irq(int irq)
 }
 EXPORT_SYMBOL(nlm_xlp_request_irq);
 
-#if defined CONFIG_PCI_MSI
 #ifdef arch_setup_msi_irqs
 /*
  * Arch specific setup functions and helpers
@@ -1435,7 +1420,7 @@ int xlp_setup_msix_irq(struct pci_dev *dev, struct msi_desc *desc, int nvec)
 		}
 		/* We hit an unused entry */
 		irq_map[base_msix + idx].usage = 1;
-		msix_vec[fn].bitmap |= (1ULL << idx);
+		msix_vec[fn].bitmap |= 1 << idx;
 		msix_vec[fn].count++;
 		break;
 	}
@@ -1484,17 +1469,15 @@ int arch_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 }
 EXPORT_SYMBOL(arch_setup_msi_irqs);
 #endif
-#endif
 
 void __init init_nlm_common_irqs(void)
 {
 	int i;
-	u64	mask = 0;
 
 	for (i = 0; i < XLP_IRQ_MAX; i++) {	// IRQ : 0 - 167
 		set_irq_chip(i, &nlm_irq_pic);
 	}
-#ifdef CONFIG_PCI_MSI
+#ifdef CONFIG_PCI_MSI_XLP
 	for (i = XLP_MSI_INDEX_START; i <= XLP_MSI_INDEX_END; i++) {
 		set_irq_chip(i, &nlm_msi_pic);
 	}
@@ -1503,11 +1486,12 @@ void __init init_nlm_common_irqs(void)
 	}
 #endif
 
-#ifdef CONFIG_REMOTE_DEBUG	/* REMOVE on XLP TODO */
+#ifdef CONFIG_REMOTE_DEBUG
 	irq_desc[XLP_IRQ_REMOTE_DEBUG].chip = &nlm_common_rsvd_pic;
 	irq_desc[XLP_IRQ_REMOTE_DEBUG].action = nlm_common_rsvd_action;
-	// xlp_irq_mask |= (1ULL << XLP_IRQ_REMOTE_DEBUG);
+	xlp_irq_mask |= (1ULL << XLP_IRQ_REMOTE_DEBUG);
 #endif
+
 #ifdef CONFIG_SMP
 	irq_desc[XLP_IRQ_IPI_SMP_FUNCTION].chip = &nlm_common_rsvd_pic;
 	irq_desc[XLP_IRQ_IPI_SMP_FUNCTION].action = &nlm_common_rsvd_action;
@@ -1515,46 +1499,31 @@ void __init init_nlm_common_irqs(void)
 	irq_desc[XLP_IRQ_IPI_SMP_RESCHEDULE].chip = &nlm_common_rsvd_pic;
 	irq_desc[XLP_IRQ_IPI_SMP_RESCHEDULE].action = &nlm_common_rsvd_action;
 
-#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY	/* REMOVE on XLP TODO */
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY
 	/* PR: New IPI added here for netrx balancing */
 	irq_desc[XLP_IRQ_IPI_NETRX].chip = &nlm_common_rsvd_pic;
 	irq_desc[XLP_IRQ_IPI_NETRX].action = &nlm_common_rsvd_action;
-	//xlp_irq_mask |= (1ULL << XLP_IRQ_IPI_NETRX);
+	xlp_irq_mask |= (1ULL << XLP_IRQ_IPI_NETRX);
 #endif				/* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
 
+	xlp_irq_mask |= ((1ULL << XLP_IRQ_IPI_SMP_FUNCTION) |
+			     (1ULL << XLP_IRQ_IPI_SMP_RESCHEDULE));
 #endif
 
 	/* msgring interrupt */
 	irq_desc[XLP_IRQ_MSGRING].chip = &nlm_common_rsvd_pic;
 	irq_desc[XLP_IRQ_MSGRING].action = &nlm_common_rsvd_action;
+	xlp_irq_mask |= (1ULL << XLP_IRQ_MSGRING);
 
-	mask = (
-			(1ULL << XLP_IRQ_TIMER) |
-			(1ULL << 10) |	/* timer */
-			(1ULL << 49) |	/* msg_idx */
-			(0x3ULL << 48) |	/* msg_idx */
-			(0xfULL << 32) |	/* pci msix */
-			(0xfULL << 41) |	/* pci and msi */
-			(0x1ULL << 58) |	/* nae */
-			(0x3ULL << 24) |	/* usb */
-			(0x3ULL	<< 17) |	/* uart */
-			(0xfULL << 13) |	/* gpio */
-#ifdef CONFIG_SMP
-			(1ULL << XLP_IRQ_IPI_SMP_FUNCTION) |
-			(1ULL << XLP_IRQ_IPI_SMP_RESCHEDULE) |
-#endif
 #ifdef CONFIG_OPROFILE
-			(1ULL << XLP_IRQ_IPI_OPROFILE) |
+	xlp_irq_mask |= (1ULL << XLP_IRQ_IPI_OPROFILE);
 #endif
+
 #ifdef CONFIG_KGDB
-			(1ULL << XLP_IRQ_IPI_SMP_KGDB) |
+	xlp_irq_mask |= (1ULL << XLP_IRQ_IPI_SMP_KGDB);
 #endif
-			(1ULL << XLP_IRQ_MSGRING) |
-			(0xfULL << 20)		/* nor, nand, spi and mmc */
-	       );
-	/* set interrupt mask for non-zero cpus */
-	mask |= read_64bit_cp0_eimr();
-	xlp_irq_mask = mask;
+
+	xlp_irq_mask |= (1ULL << XLP_IRQ_TIMER);
 }
 
 
-- 
1.7.10.4

