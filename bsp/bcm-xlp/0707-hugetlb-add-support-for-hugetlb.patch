From bdb138cee8197f5ea377553144a6e51c3fd9ebec Mon Sep 17 00:00:00 2001
From: Yanjiang Jin <yanjiang.jin@windriver.com>
Date: Thu, 25 Apr 2013 17:17:46 +0800
Subject: [PATCH 707/762] hugetlb: add support for hugetlb

- See Documentation/vm/hugetlbpage.txt for detailed information about
  how to use hugetlb through linux kernel
- By default, 8MB huge page size is assumed.

Based on Broadcom SDK 2.3.

Signed-off-by: Sreenidhi B R <sreenira@broadcom.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/Kconfig                |   47 ++++++++++++++++++
 arch/mips/include/asm/hugetlb.h  |   41 ++++++++--------
 arch/mips/include/asm/mipsregs.h |   21 ++++++---
 arch/mips/include/asm/page.h     |   20 ++++++++-
 arch/mips/mm/hugetlbpage.c       |   96 +++++++++++++++++++++++++++++++++++---
 arch/mips/mm/tlb-r4k.c           |   39 +++++++++++++---
 arch/mips/mm/tlbex-fault.S       |    7 +++
 arch/mips/mm/tlbex.c             |   74 ++++++++++++++++-------------
 arch/mips/netlogic/xlp/mmu.c     |    7 ++-
 9 files changed, 276 insertions(+), 76 deletions(-)

diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig
index 82f22b3..e6d0ff8 100644
--- a/arch/mips/Kconfig
+++ b/arch/mips/Kconfig
@@ -784,6 +784,7 @@ config NLM_XLP_EVP_BOARD
         select SYS_HAS_EARLY_PRINTK
 	select SYS_SUPPORTS_NUMA
 	select SYS_SUPPORTS_ZBOOT
+	select SYS_SUPPORTS_HUGETLBFS
         help
           This board is based on Netlogic XLP Processor.
           Say Y here to support this machine type
@@ -871,6 +872,7 @@ config NLM_XLP_BOARD
 	select SYNC_R4K
 	select SYS_HAS_EARLY_PRINTK
 	select SYS_SUPPORTS_NUMA
+	select SYS_SUPPORTS_HUGETLBFS
 	help
 	  This board is based on Netlogic XLP Processor.
 	  Say Y here if you have a XLP based board.
@@ -1591,6 +1593,7 @@ config CPU_XLP
         select GENERIC_GPIO
         select GPIO_SYSFS
         select ARCH_REQUIRE_GPIOLIB
+	select CPU_SUPPORTS_HUGEPAGES
 	help
 	  Netlogic Microsystems XLP processors.
 endchoice
@@ -1879,8 +1882,52 @@ config PAGE_SIZE_64KB
 
 endchoice
 
+choice
+        prompt "Huge page size"
+	depends on HUGETLB_PAGE
+        default HUGE_PAGE_SIZE_8M
+
+config HUGE_PAGE_SIZE_128K
+        bool "128kB"
+	help
+	  Using 128KB as the hugetlb page size
+
+config HUGE_PAGE_SIZE_512K
+        bool "512kB"
+	help
+	  Using 512KB as the hugetlb page size
+
+config HUGE_PAGE_SIZE_2M
+        bool "2mB"
+	help
+	  Using 2MB as the hugetlb page size
+
+config HUGE_PAGE_SIZE_8M
+        bool "8mB"
+	help
+	  Using 8MB as the hugetlb page size
+
+config HUGE_PAGE_SIZE_32M
+        bool "32mB"
+	help
+	  Using 32MB as the hugetlb page size
+
+config HUGE_PAGE_SIZE_128M
+        bool "128mB"
+	help
+	  Using 128MB as the hugetlb page size
+
+config HUGE_PAGE_SIZE_512M
+        bool "512mB"
+	help
+	  Using 512MB as the hugetlb page size
+
+endchoice
+
 config FORCE_MAX_ZONEORDER
 	int "Maximum zone order"
+	range 14 64 if SYS_SUPPORTS_HUGETLBFS && PAGE_SIZE_64KB
+	default "14" if SYS_SUPPORTS_HUGETLBFS && PAGE_SIZE_64KB
 	range 13 64 if SYS_SUPPORTS_HUGETLBFS && PAGE_SIZE_32KB
 	default "13" if SYS_SUPPORTS_HUGETLBFS && PAGE_SIZE_32KB
 	range 12 64 if SYS_SUPPORTS_HUGETLBFS && PAGE_SIZE_16KB
diff --git a/arch/mips/include/asm/hugetlb.h b/arch/mips/include/asm/hugetlb.h
index 58d3688..06d8477 100644
--- a/arch/mips/include/asm/hugetlb.h
+++ b/arch/mips/include/asm/hugetlb.h
@@ -50,22 +50,11 @@ static inline void hugetlb_free_pgd_range(struct mmu_gather *tlb,
 	free_pgd_range(tlb, addr, end, floor, ceiling);
 }
 
-static inline void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,
-				   pte_t *ptep, pte_t pte)
-{
-	set_pte_at(mm, addr, ptep, pte);
-}
+extern void set_huge_pte_at(struct mm_struct *mm, unsigned long addr,
+		pte_t *ptep, pte_t pte);
 
-static inline pte_t huge_ptep_get_and_clear(struct mm_struct *mm,
-					    unsigned long addr, pte_t *ptep)
-{
-	pte_t clear;
-	pte_t pte = *ptep;
-
-	pte_val(clear) = (unsigned long)invalid_pte_table;
-	set_pte_at(mm, addr, ptep, clear);
-	return pte;
-}
+extern pte_t huge_ptep_get_and_clear(struct mm_struct *mm,
+		unsigned long addr, pte_t *ptep);
 
 static inline void huge_ptep_clear_flush(struct vm_area_struct *vma,
 					 unsigned long addr, pte_t *ptep)
@@ -73,6 +62,15 @@ static inline void huge_ptep_clear_flush(struct vm_area_struct *vma,
 	flush_tlb_page(vma, addr & huge_page_mask(hstate_vma(vma)));
 }
 
+static inline pte_t huge_ptep_get(pte_t *ptep)
+{
+	/* Get the pte value for the even entry */
+	unsigned long pte = pte_val(*ptep) & ~(HPAGE_SIZE >> 1);
+
+	/* for XLP hpw, clear bit 61 which is indicates hpw it is a hpage */
+	return __pte(pte & ~(1ULL << 61));
+}
+
 static inline int huge_pte_none(pte_t pte)
 {
 	unsigned long val = pte_val(pte) & ~_PAGE_GLOBAL;
@@ -87,7 +85,7 @@ static inline pte_t huge_pte_wrprotect(pte_t pte)
 static inline void huge_ptep_set_wrprotect(struct mm_struct *mm,
 					   unsigned long addr, pte_t *ptep)
 {
-	ptep_set_wrprotect(mm, addr, ptep);
+	set_huge_pte_at(mm, addr, ptep, pte_wrprotect(huge_ptep_get(ptep)));
 }
 
 static inline int huge_ptep_set_access_flags(struct vm_area_struct *vma,
@@ -95,12 +93,13 @@ static inline int huge_ptep_set_access_flags(struct vm_area_struct *vma,
 					     pte_t *ptep, pte_t pte,
 					     int dirty)
 {
-	return ptep_set_access_flags(vma, addr, ptep, pte, dirty);
-}
+	int changed = !pte_same(*ptep, pte);
+	if (changed) {
+		set_huge_pte_at(vma->vm_mm, addr, ptep, pte);
+		flush_tlb_page(vma, addr);
+	}
+	return changed;
 
-static inline pte_t huge_ptep_get(pte_t *ptep)
-{
-	return *ptep;
 }
 
 static inline int arch_prepare_hugepage(struct page *page)
diff --git a/arch/mips/include/asm/mipsregs.h b/arch/mips/include/asm/mipsregs.h
index 5b31ea8..f15a366 100644
--- a/arch/mips/include/asm/mipsregs.h
+++ b/arch/mips/include/asm/mipsregs.h
@@ -236,21 +236,28 @@
 #error Bad page size configuration!
 #endif
 
+#ifdef CONFIG_HUGETLB_PAGE
 /*
  * Default huge tlb size for a given kernel configuration
  */
-#ifdef CONFIG_PAGE_SIZE_4KB
+#ifdef CONFIG_HUGE_PAGE_SIZE_128K
+#define PM_HUGE_MASK	PM_64K
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512K)
+#define PM_HUGE_MASK	PM_256K
+#elif defined(CONFIG_HUGE_PAGE_SIZE_2M)
 #define PM_HUGE_MASK	PM_1M
-#elif defined(CONFIG_PAGE_SIZE_8KB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_8M)
 #define PM_HUGE_MASK	PM_4M
-#elif defined(CONFIG_PAGE_SIZE_16KB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_32M)
 #define PM_HUGE_MASK	PM_16M
-#elif defined(CONFIG_PAGE_SIZE_32KB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_128M)
 #define PM_HUGE_MASK	PM_64M
-#elif defined(CONFIG_PAGE_SIZE_64KB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512M)
 #define PM_HUGE_MASK	PM_256M
-#elif defined(CONFIG_HUGETLB_PAGE)
-#error Bad page size configuration for hugetlbfs!
+#else
+#error Bad huge page size configuration!
+#endif
+
 #endif
 
 /*
diff --git a/arch/mips/include/asm/page.h b/arch/mips/include/asm/page.h
index 91ef435..6356dff 100644
--- a/arch/mips/include/asm/page.h
+++ b/arch/mips/include/asm/page.h
@@ -43,7 +43,25 @@
 #define PAGE_MASK       (~((1 << PAGE_SHIFT) - 1))
 
 #ifdef CONFIG_HUGETLB_PAGE
-#define HPAGE_SHIFT	(PAGE_SHIFT + PAGE_SHIFT - 3)
+
+#ifdef CONFIG_HUGE_PAGE_SIZE_128K
+#define HPAGE_SHIFT	(PL_64K + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512K)
+#define HPAGE_SHIFT	(PL_256 + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_2M)
+#define HPAGE_SHIFT	(PL_1M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_8M)
+#define HPAGE_SHIFT	(PL_4M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_32M)
+#define HPAGE_SHIFT	(PL_16M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_128M)
+#define HPAGE_SHIFT	(PL_64M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512M)
+#define HPAGE_SHIFT	(PL_256M + 1)
+#else
+#error no proper huge page size defined!
+#endif
+
 #define HPAGE_SIZE	(_AC(1,UL) << HPAGE_SHIFT)
 #define HPAGE_MASK	(~(HPAGE_SIZE - 1))
 #define HUGETLB_PAGE_ORDER	(HPAGE_SHIFT - PAGE_SHIFT)
diff --git a/arch/mips/mm/hugetlbpage.c b/arch/mips/mm/hugetlbpage.c
index a7fee0d..caaac95 100644
--- a/arch/mips/mm/hugetlbpage.c
+++ b/arch/mips/mm/hugetlbpage.c
@@ -22,18 +22,47 @@
 #include <asm/tlb.h>
 #include <asm/tlbflush.h>
 
-pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr,
-		      unsigned long sz)
+pte_t *huge_pte_alloc_single(struct mm_struct *mm, unsigned long addr)
 {
 	pgd_t *pgd;
 	pud_t *pud;
+	pmd_t *pmd;
 	pte_t *pte = NULL;
 
 	pgd = pgd_offset(mm, addr);
 	pud = pud_alloc(mm, pgd, addr);
-	if (pud)
-		pte = (pte_t *)pmd_alloc(mm, pud, addr);
+	if (pud) {
+		pmd = (pmd_t *)pmd_alloc(mm, pud, addr);
+		if (pmd)
+			pte = pte_alloc_map(mm, NULL, pmd, addr);
+	}
+
+	return pte;
+}
+
+/**
+ * Given any address, we need to allocate page table entries
+ * for all pte's covered by the same huge page. This is needed if
+ * any address referencing the huge page faults and the tlb refill handler
+ * can refill the tlb entry with correct value.
+ *
+ * Return any valid pte pointer is fine as later on we still have
+ * "addr" to identify the correct huge page.
+ */
+pte_t *huge_pte_alloc(struct mm_struct *mm, unsigned long addr,
+		      unsigned long sz)
+{
+	pte_t *pte = NULL;
+	unsigned long i = 0;
+	unsigned long htlb_entries = 1 << HUGETLB_PAGE_ORDER;
 
+	addr &= HPAGE_MASK;
+	for (i = 0; i < htlb_entries; i++) {
+		pte = huge_pte_alloc_single(mm, addr);
+		if (!pte)
+			return NULL;
+		addr += PAGE_SIZE;
+	}
 	return pte;
 }
 
@@ -41,15 +70,68 @@ pte_t *huge_pte_offset(struct mm_struct *mm, unsigned long addr)
 {
 	pgd_t *pgd;
 	pud_t *pud;
-	pmd_t *pmd = NULL;
+	pmd_t *pmd;
+	pte_t *pte = NULL;
 
 	pgd = pgd_offset(mm, addr);
 	if (pgd_present(*pgd)) {
 		pud = pud_offset(pgd, addr);
-		if (pud_present(*pud))
+		if (pud_present(*pud)) {
 			pmd = pmd_offset(pud, addr);
+			if (pmd_present(*pmd))
+				pte = pte_offset_map(pmd, addr);
+		}
+	}
+	return pte;
+}
+
+/**
+ * Fill the pte value to all pte's covered by the same huge page.
+ */
+void set_huge_pte_at(struct mm_struct *mm, unsigned long addr, pte_t *ptep,
+pte_t entry)
+{
+	unsigned long i;
+	unsigned long htlb_entries = 1 << HUGETLB_PAGE_ORDER;
+	pte_t entry2;
+
+	entry2 =  __pte(pte_val(entry) + (HPAGE_SIZE >> 1));
+
+	/* for hardware page walker, bit 61 tells hpw it is a hpage */
+	entry  = __pte(pte_val(entry)  | (1ULL << 61));
+	entry2 = __pte(pte_val(entry2) | (1ULL << 61));
+
+	addr &= HPAGE_MASK;
+	for (i = 0; i < htlb_entries; i += 2) {
+		ptep = huge_pte_offset(mm, addr);
+		set_pte_at(mm, addr, ptep, entry);
+		addr += PAGE_SIZE;
+
+		ptep = huge_pte_offset(mm, addr);
+		set_pte_at(mm, addr, ptep, entry2);
+		addr += PAGE_SIZE;
+	}
+}
+
+pte_t huge_ptep_get_and_clear(struct mm_struct *mm, unsigned long addr,
+				pte_t *ptep)
+{
+	pte_t entry;
+	unsigned long i;
+	unsigned long htlb_entries = 1 << HUGETLB_PAGE_ORDER;
+
+	entry = *ptep;
+
+	/* clear bit 61 before giving back to the upper level function */
+	entry = __pte(pte_val(entry) & ~(1ULL << 61));
+
+	addr &= HPAGE_MASK;
+	for (i = 0; i < htlb_entries; i++) {
+		ptep = huge_pte_offset(mm, addr);
+		pte_clear(mm, addr, ptep);
+		addr += PAGE_SIZE;
 	}
-	return (pte_t *) pmd;
+	return entry;
 }
 
 int huge_pmd_unshare(struct mm_struct *mm, unsigned long *addr, pte_t *ptep)
diff --git a/arch/mips/mm/tlb-r4k.c b/arch/mips/mm/tlb-r4k.c
index 5d383a1..100a69c 100644
--- a/arch/mips/mm/tlb-r4k.c
+++ b/arch/mips/mm/tlb-r4k.c
@@ -264,6 +264,32 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
 	}
 }
 
+#ifdef CONFIG_HUGETLB_PAGE
+asmlinkage void do_hugetlb_invalidate(void)
+{
+	int oldpid, idx;
+
+	oldpid = read_c0_entryhi();
+	tlb_probe();
+	tlb_probe_hazard();
+	idx = read_c0_index();
+	if (idx > 0) {
+		int ridx = idx & 0x1fff;
+
+		if (ridx > ((read_c0_config6() >> 6) & 0x3ff)) {
+			/* Make sure all entries differ. */
+			write_c0_entrylo0(0);
+			write_c0_entrylo1(0);
+			write_c0_entryhi(UNIQUE_ENTRYHI(idx & 0x1fff));
+			mtc0_tlbw_hazard();
+			tlb_write_indexed();
+			tlbw_use_hazard();
+			write_c0_entryhi(oldpid);
+		}
+	}
+}
+#endif
+
 /*
  * This one is only used for pages with the global bit set so we don't care
  * much about the ASID.
@@ -333,19 +359,18 @@ void __update_tlb(struct vm_area_struct * vma, unsigned long address, pte_t pte)
 	idx = read_c0_index();
 #ifdef CONFIG_HUGETLB_PAGE
 	/* this could be a huge page  */
-	if (pmd_huge(*pmdp)) {
-		unsigned long lo;
+	if (is_vm_hugetlb_page(vma)) {
 		write_c0_pagemask(PM_HUGE_MASK);
-		ptep = (pte_t *)pmdp;
-		lo = pte_to_entrylo(pte_val(*ptep));
-		write_c0_entrylo0(lo);
-		write_c0_entrylo1(lo + (HPAGE_SIZE >> 7));
+		ptep = pte_offset_map(pmdp, address);
+		write_c0_entrylo0(pte_to_entrylo(pte_val(*ptep++)));
+		write_c0_entrylo1(pte_to_entrylo(pte_val(*ptep)));
 
 		mtc0_tlbw_hazard();
 		if (idx < 0)
 			tlb_write_random();
-		else
+		else {
 			tlb_write_indexed();
+		}
 		write_c0_pagemask(PM_DEFAULT_MASK);
 	} else
 #endif
diff --git a/arch/mips/mm/tlbex-fault.S b/arch/mips/mm/tlbex-fault.S
index e99eaa1..ca1369b 100644
--- a/arch/mips/mm/tlbex-fault.S
+++ b/arch/mips/mm/tlbex-fault.S
@@ -15,6 +15,13 @@
 	NESTED(tlb_do_page_fault_\write, PT_SIZE, sp)
 	SAVE_ALL
 	MFC0	a2, CP0_BADVADDR
+
+#ifdef CONFIG_HUGETLB_PAGE
+	/* invalidate the tlb entry in fixed tlb */
+	jal     do_hugetlb_invalidate
+	nop
+#endif
+
 	KMODE
 	move	a0, sp
 	REG_S	a2, PT_BVADDR(sp)
diff --git a/arch/mips/mm/tlbex.c b/arch/mips/mm/tlbex.c
index f84f859..cb361b4 100644
--- a/arch/mips/mm/tlbex.c
+++ b/arch/mips/mm/tlbex.c
@@ -60,6 +60,7 @@ static struct tlb_reg_save handler_reg_save[NR_CPUS];
 #include <asm/netlogic/mips-exts.h>
 #endif
 
+
 static inline int r45k_bvahwbug(void)
 {
 	/* XXX: We should probe for the presence of this bug, but we don't. */
@@ -172,6 +173,9 @@ enum label_id {
 	label_illegal_access_tlbl,
 	label_exl_refill_exception,
 	label_r4000_write_probe_fail,
+#ifdef CONFIG_HUGETLB_PAGE
+	label_r4000_write_huge_probe_fail,
+#endif
 #endif
 };
 
@@ -200,6 +204,9 @@ UASM_L_LA(_read_entrylo1)
 UASM_L_LA(_illegal_access_tlbl)
 UASM_L_LA(_exl_refill_exception)
 UASM_L_LA(_r4000_write_probe_fail)
+#ifdef CONFIG_HUGETLB_PAGE
+UASM_L_LA(_r4000_write_huge_probe_fail)
+#endif
 #endif
 
 /*
@@ -233,6 +240,8 @@ static inline void dump_handler(const u32 *handler, int count)
 #define C0_ENTRYHI	10, 0
 #define C0_EPC		14, 0
 #define C0_XCONTEXT	20, 0
+#define C0_CONFIG6     16, 6
+#define C0_WIRED        6, 0
 
 #ifdef CONFIG_64BIT
 # define GET_CONTEXT(buf, reg) UASM_i_MFC0(buf, reg, C0_XCONTEXT)
@@ -716,32 +725,14 @@ static __cpuinit void build_huge_update_entries(u32 **p,
 						unsigned int pte,
 						unsigned int tmp)
 {
-	int small_sequence;
-
-	/*
-	 * A huge PTE describes an area the size of the
-	 * configured huge page size. This is twice the
-	 * of the large TLB entry size we intend to use.
-	 * A TLB entry half the size of the configured
-	 * huge page size is configured into entrylo0
-	 * and entrylo1 to cover the contiguous huge PTE
-	 * address space.
-	 */
-	small_sequence = (HPAGE_SIZE >> 7) < 0x10000;
-
-	/* We can clobber tmp.  It isn't used after this.*/
-	if (!small_sequence)
-		uasm_i_lui(p, tmp, HPAGE_SIZE >> (7 + 16));
-
 	build_convert_pte_to_entrylo(p, pte);
 	UASM_i_MTC0(p, pte, C0_ENTRYLO0); /* load it */
-	/* convert to entrylo1 */
-	if (small_sequence)
-		UASM_i_ADDIU(p, pte, pte, HPAGE_SIZE >> 7);
-	else
-		UASM_i_ADDU(p, pte, pte, tmp);
 
+	uasm_i_ld(p, pte, sizeof(pte_t), tmp);
+	build_convert_pte_to_entrylo(p, pte);
 	UASM_i_MTC0(p, pte, C0_ENTRYLO1); /* load it */
+
+	uasm_i_ehb(p);
 }
 
 static __cpuinit void build_huge_handler_tail(u32 **p,
@@ -757,8 +748,32 @@ static __cpuinit void build_huge_handler_tail(u32 **p,
 #else
 	UASM_i_SW(p, pte, 0, ptr);
 #endif
+
+	/* adjust the ptep pointer to be at even entry boundary.
+	 * this is needed to write back entries to tlb.
+	 */
+	uasm_i_ori(p, ptr, ptr, sizeof(pte_t));
+	uasm_i_xori(p, ptr, ptr, sizeof(pte_t));
+	UASM_i_LW(p, pte, 0, ptr);
+
 	build_huge_update_entries(p, pte, ptr);
+
+#ifdef CONFIG_NLM_XLP
+	/* Similar to no hugetlb case, checking probe result.
+	 * FIXME: this should not happen really.
+	 */
+	uasm_i_mfc0(p, ptr, C0_INDEX);
+
+	uasm_il_bltz(p, r, ptr, label_r4000_write_huge_probe_fail);
+	uasm_i_nop(p);
+
 	build_huge_tlb_write_entry(p, l, r, pte, tlb_indexed, 0);
+	uasm_l_r4000_write_huge_probe_fail(l, *p);
+
+	build_huge_tlb_write_entry(p, l, r, pte, tlb_random, 0);
+#else
+	build_huge_tlb_write_entry(p, l, r, pte, tlb_indexed, 0);
+#endif
 }
 #endif /* CONFIG_HUGETLB_PAGE */
 
@@ -1335,11 +1350,11 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 		build_get_pgde32(&p, K0, K1); /* get pgd in K1 */
 #endif
 
+		build_get_ptep(&p, K0, K1);
 #ifdef CONFIG_HUGETLB_PAGE
 		build_is_huge_pte(&p, &r, K0, K1, label_tlb_huge_update);
 #endif
 
-		build_get_ptep(&p, K0, K1);
 		build_update_entries(&p, K0, K1);
 		build_tlb_write_entry(&p, &l, &r, tlb_random);
 		uasm_l_leave(&l, p);
@@ -1907,21 +1922,16 @@ build_r4000_tlbchange_handler_head(u32 **p, struct uasm_label **l,
 	build_get_pgde32(p, wr.r1, wr.r2); /* get pgd in ptr */
 #endif
 
-#ifdef CONFIG_HUGETLB_PAGE
-	/*
-	 * For huge tlb entries, pmd doesn't contain an address but
-	 * instead contains the tlb pte. Check the PAGE_HUGE bit and
-	 * see if we need to jump to huge tlb processing.
-	 */
-	build_is_huge_pte(p, r, wr.r1, wr.r2, label_tlb_huge_update);
-#endif
-
 	UASM_i_MFC0(p, wr.r1, C0_BADVADDR);
 	UASM_i_LW(p, wr.r2, 0, wr.r2);
 	UASM_i_SRL(p, wr.r1, wr.r1, PAGE_SHIFT + PTE_ORDER - PTE_T_LOG2);
 	uasm_i_andi(p, wr.r1, wr.r1, (PTRS_PER_PTE - 1) << PTE_T_LOG2);
 	UASM_i_ADDU(p, wr.r2, wr.r2, wr.r1);
 
+#ifdef CONFIG_HUGETLB_PAGE
+	build_is_huge_pte(p, r, wr.r1, wr.r2, label_tlb_huge_update);
+#endif
+
 #ifdef CONFIG_SMP
 	uasm_l_smp_pgtable_change(l, *p);
 #endif
diff --git a/arch/mips/netlogic/xlp/mmu.c b/arch/mips/netlogic/xlp/mmu.c
index 314aa80..f97aee0 100644
--- a/arch/mips/netlogic/xlp/mmu.c
+++ b/arch/mips/netlogic/xlp/mmu.c
@@ -307,7 +307,12 @@ void __cpuinit mmu_init(void)
                 * shift right half the number of 1s in
                 * the pagemask and populate that value
                 */
-                write_c0_config7(PM_DEFAULT_MASK >> (13 + (ffz(PM_DEFAULT_MASK >> 13) / 2)));
+#ifdef CONFIG_HUGETLB_PAGE
+		write_c0_config7(PM_DEFAULT_MASK >> (13 + (ffz(PM_DEFAULT_MASK >> 13) / 2))
+		| ((PM_HUGE_MASK >> (13 + (ffz(PM_HUGE_MASK >> 13) / 2))) << 8));
+#else
+		write_c0_config7(PM_DEFAULT_MASK >> (13 + (ffz(PM_DEFAULT_MASK >> 13) / 2)));
+#endif
 
 #ifdef DEBUG
                 printk(KERN_INFO "( %s ): write_c0_config7 = %d\n", __FUNCTION__,
-- 
1.7.0.4

