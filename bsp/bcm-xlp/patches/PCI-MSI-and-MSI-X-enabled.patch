From f3db9b6e27d5a77bde49e6d217dbad3329e5592d Mon Sep 17 00:00:00 2001
From: Om Narasimhan <omn@broadcom.com>
Date: Thu, 26 Jul 2012 14:46:41 -0700
Subject: [PATCH 390/565] PCI : MSI and MSI-X enabled

This commit enables PCI controllers' MSI/MSI-X functionality.

Based on Broadcom SDK 2.3.

Signed-off-by: Om Narasimhan <omn@broadcom.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/include/asm/netlogic/msi.h         |  46 ++
 arch/mips/include/asm/netlogic/xlp_irq.h     |   2 +-
 arch/mips/include/asm/netlogic/xlp_irq_map.h |  15 +-
 arch/mips/netlogic/Kconfig                   |   9 +-
 arch/mips/netlogic/xlp/Makefile              |   1 +
 arch/mips/netlogic/xlp/irq.c                 |  22 +-
 arch/mips/netlogic/xlp/msi.c                 | 662 +++++++++++++++++++++++++++
 arch/mips/netlogic/xlp/pic/xlp_irq_map.c     |   3 +-
 arch/mips/netlogic/xlp/pic/xlp_pic.c         |   6 +-
 arch/mips/pci/Makefile                       |   1 +
 arch/mips/pci/pci-xlp-msi.c                  | 298 ++++++++++++
 arch/mips/pci/pci-xlp.c                      |  86 ++--
 12 files changed, 1082 insertions(+), 69 deletions(-)
 create mode 100644 arch/mips/include/asm/netlogic/msi.h
 create mode 100644 arch/mips/netlogic/xlp/msi.c
 create mode 100644 arch/mips/pci/pci-xlp-msi.c

diff --git a/arch/mips/include/asm/netlogic/msi.h b/arch/mips/include/asm/netlogic/msi.h
new file mode 100644
index 0000000..77a324d
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/msi.h
@@ -0,0 +1,46 @@
+#ifndef _ASM_BRCM_MSI_H
+#define _ASM_BRCM_MSI_H
+
+#if defined CONFIG_XLP_MSI_ADDRESSES
+#define XLP_MSI_ADDR		0xFEE00000
+#endif
+#define XLP_MSI_ADDR_SIZE	0x00004000
+#define XLP_MSIX_ADDR_SIZE	0x00004000
+
+/* We are using IRQ 256 - 383 for MSI */
+#define XLP_MSI_MM_CAP		5	/* Multiple message capability */
+#define XLP_MSI_PER_SLOT	(1 << XLP_MSI_MM_CAP)
+#define XLP_MSI_IRQ_OFFSET	256	/* Note IRQ not IRT */
+#define XLP_MSI_IRQ_START(n,fn)	((XLP_IRQS_PER_NODE * (n)) + \
+			XLP_MSI_IRQ_OFFSET + (fn) * XLP_MSI_PER_SLOT)
+#define XLP_MSI_INDEX_START	XLP_MSI_IRQ_START(0, 0)
+#define XLP_MSI_INDEX_END	(XLP_MSI_IRQ_START(0, XLP_MAX_SLOTS) - 1) /* 128 Vectors */
+#define XLP_MSI_TO_CTRL_FN(msi) (((msi % XLP_IRQS_PER_NODE) >> (XLP_MSI_MM_CAP)) & 3)
+#define XLP_MSI_TO_NODE(x)	XLP_IRQ_TO_NODE(x)
+
+ /* We are using IRQ 192 - 223 for MSI-X */
+#define XLP_MSIX_PER_SLOT	8
+#define XLP_MSIX_IRQ_OFFSET	192
+#define XLP_MSIX_TO_CTRL_FN(msix) (((msix % XLP_IRQS_PER_NODE) >> 3) & 3)
+#define XLP_MSIX_TO_NODE(x)	XLP_IRQ_TO_NODE(x)
+#define XLP_MSIX_IRQ_START(n, fn)	((XLP_IRQS_PER_NODE * n) + XLP_MSIX_IRQ_OFFSET + (fn) * XLP_MSIX_PER_SLOT)
+#define XLP_MSIX_INDEX_START	XLP_MSIX_IRQ_START(0, 0)
+#define XLP_MSIX_INDEX_END	(XLP_MSIX_IRQ_START(0, XLP_MAX_SLOTS) - 1)// 31 vectors
+
+int xlp_msi_enable(u8, int, u32);
+int xlp_msi_disable(u8, int, u32);
+u32 xlp_msi_set_mask(u8, int, int, int);
+volatile const void *xlp_msi_addr_start(u8, int);
+int is_msi_set(u8, int);
+u32 calc_msi_vector_offset(u8, int);
+
+int xlp_msix_enable(u8,  int);
+int xlp_msix_disable(u8, int);
+u32 xlp_msi_set_mask(u8, int, int, int);
+volatile const void *xlp_msix_addr_start(u8, int);
+u32 xlp_msix_status_clear(u8, int);
+extern struct irq_chip nlm_msi_pic, nlm_msix_pic;
+void xlp_msi_controller_init(u8 node, int fn);
+int setup_msi_base_address(void);
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/xlp_irq.h b/arch/mips/include/asm/netlogic/xlp_irq.h
index 3f1a09cf..4aa7512 100644
--- a/arch/mips/include/asm/netlogic/xlp_irq.h
+++ b/arch/mips/include/asm/netlogic/xlp_irq.h
@@ -81,7 +81,7 @@ void nlm_hal_pic_update_control(u64);
 #define XLP_INTX_TO_CTRL_FN(irq)\
 ({\
  u32 lirq = irq % XLP_IRQS_PER_NODE;\
- ((lirq - XLP_PCIE_LINK_IRQ(0,0)) & 0x3);\
+ ((lirq - XLP_PCIE_INTX_IRQ(0,0)) & 0x3);\
 })
 #define XLP_IRQ_TO_NODE(x)		((u8)((x) / XLP_IRQS_PER_NODE))
 
diff --git a/arch/mips/include/asm/netlogic/xlp_irq_map.h b/arch/mips/include/asm/netlogic/xlp_irq_map.h
index a18d639..52663f5 100644
--- a/arch/mips/include/asm/netlogic/xlp_irq_map.h
+++ b/arch/mips/include/asm/netlogic/xlp_irq_map.h
@@ -34,5 +34,18 @@ int xlp_rvec_from_irq(int irq);
 /* These are constant across all XLP versions.
  * Compile time defined to make look up faster/
  */
-#define XLP_PCIE_LINK_IRQ(node, fn) xlp_irt_to_irq(node, 78 + (fn))
+#define XLP_INTX_IRT_START	(78)	/* Intx and Msi share same IRTs */
+#define XLP_MSI_IRT_START	(78)
+#define XLP_MSIX_IRT_START	(46)
+#define XLP_PCIE_INTX_IRQ(node, x) xlp_irt_to_irq(node,XLP_INTX_IRT_START + (x))
+#define XLP_PCIE_MSI_IRQ(node, x) xlp_irt_to_irq(node, XLP_MSI_IRT_START + (x))
+#define XLP_PCIE_MSIX_IRQ(node, x) xlp_irt_to_irq(node, XLP_MSIX_IRT_START + (x))
+#define xlp_msi_to_irq(msi) XLP_PCIE_MSI_IRQ(XLP_MSI_TO_NODE(msi),\
+		XLP_MSI_TO_CTRL_FN(msi))
+#define xlp_msi_to_irt(msi) (XLP_MSI_TO_CTRL_FN(msi) + XLP_MSI_IRT_START)
+
+#define xlp_msix_to_irq(msix) XLP_PCIE_MSIX_IRQ(XLP_MSIX_TO_NODE(msix),\
+		(msix % XLP_IRQS_PER_NODE) - XLP_MSIX_INDEX_START)
+#define xlp_msix_to_irt(msix) ((msix % XLP_IRQS_PER_NODE) - XLP_MSIX_INDEX_START + XLP_MSIX_IRT_START)
+
 #endif
diff --git a/arch/mips/netlogic/Kconfig b/arch/mips/netlogic/Kconfig
index b1cb565..cf159c7 100644
--- a/arch/mips/netlogic/Kconfig
+++ b/arch/mips/netlogic/Kconfig
@@ -157,9 +157,14 @@ config NLM_EXCL_VC_NAPI_HANDLER_SUPPORT
        depends on NLM_XLP && 64BIT
        default n
 
-# PCI_XLP is a non selectable value used only to compile PCI controller support
-# implemented in arch/mips/pci/pci-xlp.c
+# PCI_XLP and PCI_XLP_MSI are non selectable values used only to compile PCI
+# controller and MSI support
+#
 config PCI_XLP
 	bool
 	depends on NLM_XLP && PCI
 	default y
+config PCI_XLP_MSI
+	bool
+	depends on NLM_XLP && PCI && PCI_MSI
+	default y
diff --git a/arch/mips/netlogic/xlp/Makefile b/arch/mips/netlogic/xlp/Makefile
index 517b8ca..3a05926 100644
--- a/arch/mips/netlogic/xlp/Makefile
+++ b/arch/mips/netlogic/xlp/Makefile
@@ -6,6 +6,7 @@ obj-y 				+= irq.o time.o on_chip.o mmu.o
 obj-$(CONFIG_NLM_XLP) 		+= platform.o board.o  xlp_gpio.o
 obj-$(CONFIG_SMP)       	+= smp.o
 obj-y				+= pic/
+obj-$(CONFIG_PCI_MSI)		+= msi.o
 
 obj-$(CONFIG_KGDB)      += nmi.o
 obj-$(CONFIG_NLM_XLP) += cop2.o
diff --git a/arch/mips/netlogic/xlp/irq.c b/arch/mips/netlogic/xlp/irq.c
index 14563d2..a402a5b 100644
--- a/arch/mips/netlogic/xlp/irq.c
+++ b/arch/mips/netlogic/xlp/irq.c
@@ -46,6 +46,9 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include <asm/netlogic/pic_hal.h>
 #include <asm/netlogic/pci_hal.h>
 #include <asm/netlogic/xlp_irq_map.h>
+#if defined CONFIG_PCI_MSI
+#include <asm/netlogic/msi.h>
+#endif
 
 /* About this file: irq.c
  * This file contains routines that handle all the low level interrupt stuff.
@@ -234,8 +237,8 @@ static unsigned int nlm_intx_startup(struct irq_data *data)
 	}
 	/* if this irq correspond to any of the pci slots in any node,
 	 * enable intx on the controller of node */
-	if ((irq >= XLP_PCIE_LINK_IRQ(pic->node, 0))
-			&& (irq <= XLP_PCIE_LINK_IRQ(pic->node, 3))) {
+	if ((irq >= XLP_PCIE_INTX_IRQ(pic->node, 0))
+			&& (irq <= XLP_PCIE_INTX_IRQ(pic->node, 3))) {
 		fn = XLP_INTX_TO_CTRL_FN(irq);
 		if ((ret = xlp_intx_enable(pic->node, fn)) < 0) {
 			return (unsigned int)ret;
@@ -259,8 +262,8 @@ static void nlm_intx_shutdown(struct irq_data *data)
 	}
 	/* if this irq correspond to any of the pci slots, disable intx on
 	 * the controller  before shutting it down */
-	if ((irq >= XLP_PCIE_LINK_IRQ(pic->node, 0))
-			&& (irq <= XLP_PCIE_LINK_IRQ(pic->node, 3))) {
+	if ((irq >= XLP_PCIE_INTX_IRQ(pic->node, 0))
+			&& (irq <= XLP_PCIE_INTX_IRQ(pic->node, 3))) {
 		fn = XLP_INTX_TO_CTRL_FN(irq);
 		if ((ret = xlp_intx_disable(pic->node, fn)) < 0) {
 			return;
@@ -297,7 +300,8 @@ static int nlm_intx_set_affinity(struct irq_data *data, const struct cpumask *ma
 	if (check_intx_range(pic, irq) < 0) {
 		return -EINVAL;
 	}
-	return pic->set_irq_affinity(pic, irq % XLP_IRQS_PER_NODE, UPIC_AFFINITY_ITE, mask, &m);
+	return pic->set_irq_affinity(pic, xlp_irq_to_irt(irq),
+			UPIC_AFFINITY_ITE, mask, &m);
 }
 
 static struct irq_chip nlm_intx_pic = {
@@ -409,7 +413,7 @@ asmlinkage void plat_irq_dispatch(void)
 	volatile u64 eimr;
 	u64 bitmap;
 	struct pt_regs *pt_regs = current_thread_info()->regs;
-	int rvec = 0, idx = 0, base_irq, irq, fn;
+	int rvec = 0, idx = 0, base_irq, fn;
 	struct pic_dev *pic;
 
 	retrieve_node_pic_dev(hard_smp_processor_id() / NLM_MAX_CPU_PER_NODE, &pic);
@@ -456,10 +460,10 @@ asmlinkage void plat_irq_dispatch(void)
 		/* For INTX, bitmap and base irq already set */
 #if defined CONFIG_PCI_MSI
 		/* These are not MSI vector numbers, but IRT #s */
-		case XLP_PCIE_LINK_IRQ(0, 0) ... XLP_PCIE_LINK_IRQ(0, 3):
+		case XLP_PCIE_MSI_IRQ(0, 0) ... XLP_PCIE_MSI_IRQ(0, 3):
 			/* Here fn # of controller is easily calculated
 			 * Check the IRT table : 0 -> 78, 1-> 79 ..etc */
-			fn = base_irq - XLP_PCIE_LINK_IRQ(0, 0);
+			fn = base_irq - XLP_PCIE_MSI_IRQ(0, 0);
 			if (is_msi_set(pic->node, fn) != 0) { /* this is an MSI */
 				/* find vectors set, overwrite bitmap */
 				bitmap = calc_msi_vector_offset(pic->node, fn);
@@ -522,7 +526,7 @@ void __init init_xlp_irqs(void)
 			irq_set_chip_data((node * XLP_IRQS_PER_NODE) + i,
 					(void *)pic);
 		}
-#ifdef CONFIG_PCI_MSI
+#if defined CONFIG_PCI_MSI
 		for (i = XLP_MSI_INDEX_START; i <= XLP_MSI_INDEX_END; i++) {
 			irq_set_chip_data((node * XLP_IRQS_PER_NODE) + i,
 					(void *)pic);
diff --git a/arch/mips/netlogic/xlp/msi.c b/arch/mips/netlogic/xlp/msi.c
new file mode 100644
index 0000000..1c00684
--- /dev/null
+++ b/arch/mips/netlogic/xlp/msi.c
@@ -0,0 +1,662 @@
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/pci.h>
+#include <asm/errno.h>
+#include <asm/signal.h>
+#include <asm/ptrace.h>
+#include <asm/kgdb.h>
+#include <asm/mipsregs.h>
+#include <linux/irq.h>
+#include <linux/msi.h>
+
+#include <asm/netlogic/xlp_irq.h>
+#include <asm/netlogic/xlp.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/debug.h>
+#include <asm/thread_info.h>
+#include <asm/netlogic/pic_hal.h>
+#include <asm/netlogic/pci_hal.h>
+#include <asm/netlogic/xlp_irq_map.h>
+#include <asm/netlogic/msi.h>
+
+extern int xlp_ctrl_fn_from_dev(const struct pci_dev *, struct xlp_nodefn_struct *);
+
+/*
+ * This bitmap keeps track of the MSI vectors allocated from
+ * XLP_MSIX_IRQ_START(x)
+ */
+struct msi_alloc_bitmap {
+	u64 bitmap;	/* Can be any data structure to keep bits */
+	u32 count;	/* #of bits set at any point of time */
+};
+static struct msi_alloc_bitmap msix_vec[NLM_MAX_NODES][XLP_MAX_SLOTS];
+static struct msi_alloc_bitmap msi_vec[NLM_MAX_NODES][XLP_MAX_SLOTS];
+static DEFINE_SPINLOCK(xlp_msi_lock);
+
+static int check_msi_range(unsigned int msi)
+{
+	int lirq = msi % XLP_IRQS_PER_NODE;
+	if((lirq < XLP_IRQ_RESERVED_MAX) && (lirq >= 0)) {
+		return -EINVAL;
+	} else if(lirq < XLP_MSI_INDEX_START || lirq > XLP_MSI_INDEX_END) {
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static int check_msix_range(unsigned int msix)
+{
+	int lirq = msix % XLP_IRQS_PER_NODE;
+	if((lirq < XLP_IRQ_RESERVED_MAX) && (lirq >= 0)) {
+		return -EINVAL;
+	} else if(lirq < XLP_MSIX_INDEX_START || lirq > XLP_MSIX_INDEX_END) {
+		return -EINVAL;
+	}
+	return 0;
+}
+
+/*
+ * Composes MSI/MSI-X messages
+ */
+static int xlp_msi_compose_msg(struct pci_dev *pdev, struct msi_desc *desc,
+		unsigned int irq, struct msi_msg *msg)
+{
+	struct xlp_nodefn_struct nfn;
+	u8 offset;
+
+	if( xlp_ctrl_fn_from_dev(pdev, &nfn) < 0) {
+		return -EINVAL;
+	}
+	if (desc->msi_attrib.is_msix) {
+		if (check_msix_range(irq)) {	/* enforce minimum */
+			dev_err(&pdev->dev, "Invalid irq %d", irq);
+			return -EINVAL;
+		}
+		offset = (irq % XLP_IRQS_PER_NODE) - XLP_MSIX_INDEX_START;
+		msg->address_hi = (virt_to_phys(xlp_msix_addr_start(nfn.node, nfn.fn)) >> 32);
+		msg->address_lo = (virt_to_phys(xlp_msix_addr_start(nfn.node, nfn.fn)) & 0xffffffff);
+		dev_err(&pdev->dev, "MSI-X hi = %#x, lo = %#x, data = %#x\n", msg->address_hi, msg->address_lo, offset);
+	} else {
+		if (check_msi_range(irq)) {	/* enforce minimum */
+			return -EINVAL;
+		}
+		offset = (irq % XLP_IRQS_PER_NODE) -
+					(XLP_MSI_IRQ_START(0, nfn.fn));
+		msg->address_hi = (virt_to_phys(xlp_msi_addr_start(nfn.node, nfn.fn)) >> 32) & 0xffffffff;
+		msg->address_lo = (virt_to_phys(xlp_msi_addr_start(nfn.node, nfn.fn)) & 0xffffffff);
+		dev_err(&pdev->dev, "MSI hi = %#x, lo = %#x, data = %#x\n", msg->address_hi, msg->address_lo, offset);
+	}
+	msg->data = offset;
+	return 0;
+}
+
+#ifdef arch_setup_msi_irqs
+/*
+ * Backend function that sets up MSI.
+ * Called from arch_setup_msi_irqs()
+ *
+ * On XLP, we can have more than one MSI per device. But no device requests it
+ * because of possible x86 influence (one MSI per device limitation).
+ * We enforce this limitation as well.
+ */
+int xlp_setup_msi_irq(struct pci_dev *dev, struct msi_desc *desc, int nvec)
+{
+	__label__ setup_end;
+	__label__ setup_fail;
+	struct msi_msg msg;
+	int ret, bit, base_msi;
+	unsigned long flags;
+	struct xlp_nodefn_struct nfn;
+
+	if (xlp_ctrl_fn_from_dev(dev, &nfn) < 0) {
+		return -EFAULT;
+	}
+	base_msi = XLP_MSI_IRQ_START(nfn.node, nfn.fn);
+	if (nvec != 1) {	/* This condition to be removed TBD */
+		return -EINVAL;
+	}
+	spin_lock_irqsave(&xlp_msi_lock, flags);
+	ret = xlp_get_ctrl_intmode(nfn.node, nfn.fn);
+	if ((ret == XLP_INTMODE_MSIX ) || (ret == XLP_INTMODE_INTX)) {
+		ret = -EBUSY;
+		goto setup_end;
+	}
+	/* search for the first unused bit in the bitmap.
+	 * Please note that the usage is different from that of MSIX allocation
+	 * where we have the luxury of 1 irt entry per MSIX. Here we have to
+	 * multiplex in software */
+	if (msi_vec[nfn.node][nfn.fn].bitmap == 0) {
+		bit = 0;
+	} else {
+		bit = ffz(msi_vec[nfn.node][nfn.fn].bitmap);
+	}
+	if (bit > (XLP_MSI_PER_SLOT - 1)) {
+		ret = -ENOSPC;
+		goto setup_end;
+	}
+	msi_vec[nfn.node][nfn.fn].bitmap |= (1ULL << bit);
+	msi_vec[nfn.node][nfn.fn].count++;
+	base_msi += bit;
+	irq_set_msi_desc(base_msi, desc);
+	ret = xlp_msi_compose_msg(dev, desc, base_msi, &msg);
+	if (ret < 0) {
+		goto setup_fail;
+	}
+	write_msi_msg(base_msi, &msg);
+	ret = xlp_set_ctrl_intmode(nfn.node, nfn.fn, XLP_INTMODE_MSI);
+	if (ret == 0) {	/* success */
+		goto setup_end;	/* All done */
+	}
+setup_fail:
+	msi_vec[nfn.node][nfn.fn].bitmap &= ~(1ULL << bit);
+	msi_vec[nfn.node][nfn.fn].count--;
+setup_end:
+	spin_unlock_irqrestore(&xlp_msi_lock, flags);
+	return ret;
+}
+
+/*
+ * MSI-X setup functions
+ */
+
+/*
+ * Allocates a single MSI-X vector for msi_desc entry
+ * @dev		: pci device
+ * @desc	: msi_descriptor for this msi entry
+ * @nvec	: outstanding number of interrupts required for this device
+ */
+int xlp_setup_msix_irq(struct pci_dev *dev, int nvec)
+{
+	__label__ fail_loop;
+	__label__ setup_end;
+	struct msi_msg msg;
+	int old_mode, ret, idx, base_msix, bit, old_count;
+	u32 old_bitmap;
+	unsigned long flags;
+	struct msi_desc *desc;
+	struct xlp_nodefn_struct nfn;
+
+	if (xlp_ctrl_fn_from_dev(dev, &nfn) < 0) {
+		return -EFAULT;
+	}
+	base_msix = XLP_MSIX_IRQ_START(nfn.node, nfn.fn);
+	spin_lock_irqsave(&xlp_msi_lock, flags);
+	old_bitmap = msix_vec[nfn.node][nfn.fn].bitmap;
+	old_count = msix_vec[nfn.node][nfn.fn].count;
+	old_mode = xlp_get_ctrl_intmode(nfn.node, nfn.fn);
+	if ((old_mode == XLP_INTMODE_MSI ) || (old_mode == XLP_INTMODE_INTX)) {
+		ret = -EBUSY;
+		goto setup_end;
+	}
+	ret = xlp_set_ctrl_intmode(nfn.node, nfn.fn, XLP_INTMODE_MSIX);
+	if (ret < 0) {
+		goto setup_end;
+	}
+	bit = 0, idx = 0;
+	list_for_each_entry(desc, &dev->msi_list, list) {
+		/* this loops exactly nvec times */
+		if (msix_vec[nfn.node][nfn.fn].bitmap == 0) {
+			bit = 0;
+		} else {
+			bit = ffz(msix_vec[nfn.node][nfn.fn].bitmap);
+		}
+		if (bit > (XLP_MSIX_PER_SLOT - 1)) {
+			dev_err(&dev->dev, "No more vectors to allocate\n");
+			/* if we allocated at least one vector, we need to
+			 * return a positve value. Else return negative */
+			if (idx > 0) {
+				ret = idx;
+			} else {
+				ret = -ENOSPC;
+			}
+			goto setup_end;	/* could be a partial success */
+		}
+		/* We have allocated one bit, now get a vector for it */
+		msix_vec[nfn.node][nfn.fn].bitmap |= (1ULL << bit);
+		msix_vec[nfn.node][nfn.fn].count++;
+		irq_set_msi_desc(base_msix + bit, desc);
+		ret = xlp_msi_compose_msg(dev, desc, base_msix + bit, &msg);
+		if (ret < 0) {
+			goto fail_loop;
+		}
+		write_msi_msg(base_msix + bit, &msg);
+		idx++;
+	}
+	spin_unlock_irqrestore(&xlp_msi_lock, flags);
+	return 0;
+fail_loop:
+	msi_vec[nfn.node][nfn.fn].bitmap = old_bitmap;
+	msi_vec[nfn.node][nfn.fn].count = old_count;
+	xlp_set_ctrl_intmode(nfn.node, nfn.fn, old_mode);
+setup_end:
+	spin_unlock_irqrestore(&xlp_msi_lock, flags);
+	return ret;
+}
+
+int arch_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
+{
+	struct msi_desc *entry;
+	int ret;
+
+	if (nvec == 0) {
+		return -EINVAL;
+	}
+	/*
+	 * For MSI, nvec = 1 is not an architectural limitation
+	 * But at least in Linux 2.6.32, there is only one entry allocated
+	 * in dev->msi_list. That means, we cannot setup more than one
+	 * MSI, even if architecture allows it.  */
+	if (type == PCI_CAP_ID_MSI) {
+		if (nvec > 1) {
+			return -EINVAL;
+		}
+		entry = list_first_entry(&dev->msi_list, struct msi_desc, list);
+		ret = xlp_setup_msi_irq(dev, entry, nvec);
+	} else if (type == PCI_CAP_ID_MSIX) {
+	/* MSI-X has nvec entries allocated
+	 * if nvec is greater than max number vectors that can be allocated,
+	 * ret will be a positive value. For any failures, ret will be -ve */
+		ret = xlp_setup_msix_irq(dev, nvec);
+	} else {
+		ret = -EINVAL;	/* To suppress compiler "ret unused" warning */
+	}
+	return ret;
+}
+EXPORT_SYMBOL(arch_setup_msi_irqs);
+#endif
+/*
+ * The MSI and MSI-X functionality is supported only by the PCIe Controller.
+ * Whenever there is a request for MSI/MSI-X, we need to find out the
+ * controller on which that request is made. But in the PCI structure, I could
+ * not find a place where that information can be kept. Moreover, a hack job
+ * is not justified for the reason that only a small subset of PCI devices
+ * (no onboard ones) require this. So, we have the file arch/mips/pci/pci-xlp.c
+ * for XLP specific functionality.
+ *
+ * In case of MSI, we have to share one interrupt (XLP_PCIE_MSI_IRQ(x)) for
+ * for 32 possible MSI on a slot.
+ * We work around this problem by limiting the #of MSI per slot to
+ * XLP_MSI_PER_SLOT. MSI IRQ vectors start from XLP_MSI_IRQ_OFFSET.
+ * plat_irq_dispatch checks the vector number and dispatch it correctly.
+ *
+ * These bunch of functions would find out the controller function using the
+ * passed parameter and use nlm_irq_* function to operate on that IRT
+ */
+static unsigned int nlm_msi_startup(struct irq_data *data)
+{
+	int bit, irq, fn, base_msi, ret, msi;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+
+	msi = data->irq;
+	if (check_msi_range(msi) < 0) {
+		return 0;
+	}
+	BUG_ON(pic->node != XLP_MSI_TO_NODE(msi));
+	fn = XLP_MSI_TO_CTRL_FN(msi);
+	irq = xlp_msi_to_irq(msi);
+	base_msi = XLP_MSI_IRQ_START(0, fn);		/*Note:NODE == 0*/
+	bit = msi - base_msi;
+	if ((ret = xlp_msi_enable(pic->node, fn, bit)) < 0) {
+		return ret;
+	}
+	/* unmask MSI in the device */
+	unmask_msi_irq(data);
+	return xlp_irq_startup(pic, irq % XLP_IRQS_PER_NODE);
+}
+
+static int nlm_msi_set_affinity(struct irq_data *data, const struct cpumask *mask, bool force)
+{
+	struct cpumask m;
+	unsigned int msi = data->irq;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+
+	BUG_ON(pic->node != XLP_MSI_TO_NODE(msi));
+	msi = data->irq;
+	if (check_msi_range(msi) < 0) {
+		return -EINVAL;
+	}
+	return pic->set_irq_affinity(pic, xlp_msi_to_irt(msi),
+			UPIC_AFFINITY_ITE, mask, &m);
+}
+
+static void nlm_msi_shutdown(struct irq_data *data)
+{
+	int bit, irq, fn, base_msi;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+	unsigned int msi = data->irq;
+
+	if (check_msi_range(msi) < 0) {
+		return;
+	}
+	BUG_ON(pic->node != XLP_MSI_TO_NODE(msi));
+	/* mask MSI in the device */
+	mask_msi_irq(data);
+	fn = XLP_MSI_TO_CTRL_FN(msi);
+	irq = xlp_msi_to_irq(msi); /* actual irq line (irt + max reserved) */
+	base_msi = XLP_MSI_IRQ_START(pic->node, fn);
+	bit = msi - base_msi;
+	if (xlp_msi_disable(pic->node, fn, bit) < 0) {
+		return;
+	}
+	return xlp_irq_shutdown(pic, irq % XLP_IRQS_PER_NODE);
+}
+
+static void nlm_msi_end(struct irq_data *data)
+{
+	unsigned int msi = data->irq;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+
+	BUG_ON(pic->node != XLP_MSI_TO_NODE(msi));
+	if (check_msi_range(msi) < 0) {
+		return;
+	}
+	pic->interrupt_ack(pic, xlp_msi_to_irt(msi), 0);
+	return;
+}
+
+static void nlm_msi_ack(struct irq_data *data)
+{
+	unsigned int msi = data->irq;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+
+	BUG_ON(pic->node != XLP_MSI_TO_NODE(msi));
+	if (check_msi_range(msi) < 0) {
+		return;
+	}
+	pic->interrupt_ack(pic, xlp_msi_to_irt(msi), 0);
+}
+
+/*
+ * Masks just one MSI
+ * @msi : the MSI to mask
+ */
+
+static u32 nlm_msi_change_mask(struct pic_dev *pic, unsigned int msi, int val)
+{
+	unsigned long flags;
+	int bit, fn;
+	u32 mask;
+
+	BUG_ON(pic->node != XLP_MSI_TO_NODE(msi));
+	fn = XLP_MSI_TO_CTRL_FN(msi);
+	bit = msi - XLP_MSI_IRQ_START(pic->node, fn);
+	spin_lock_irqsave(&xlp_msi_lock, flags);
+	mask = xlp_msi_set_mask(pic->node, fn, bit, val);
+	if (val == 0) {
+		if (mask == 0) { /* This was the last bit to clear */
+			__xlp_irq_mask(pic, xlp_msi_to_irq(msi));
+		}
+		if ((mask & (mask - 1)) == 0) {	/* Just set the only bit*/
+			__xlp_irq_unmask(pic, xlp_msi_to_irq(msi));
+		}
+	}
+	spin_unlock_irqrestore(&xlp_msi_lock, flags);
+	return mask;
+}
+
+/*
+ * Mask just one MSI
+ * The corresponding IRT will also be masked
+ */
+static void nlm_msi_mask(struct irq_data *data)
+{
+	unsigned int msi = data->irq;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+
+	if (check_msi_range(msi) < 0) {
+		return ;
+	}
+	/* mask MSI in the device */
+	mask_msi_irq(data);
+	/* This is the h/w specific per vector masking function
+	 * We can't use the standard function because we don't support
+	 * it in the capability structure */
+	nlm_msi_change_mask(pic, msi, 0);
+	return;
+}
+
+/*
+ * Unmask just one MSI
+ * The corresponding IRT will also be unmasked
+ */
+static void nlm_msi_unmask(struct irq_data *data)
+{
+	unsigned int msi = data->irq;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+
+	if (check_msi_range(msi) < 0) {
+		return ;
+	}
+	/* unmask MSI in the device */
+	unmask_msi_irq(data);
+	nlm_msi_change_mask(pic, msi, 1);
+	return;
+}
+
+/*
+ * MSI hook-up routines for Netlogic Boards;
+ * Arch-dependent implementation called
+ * from generic msi.c routines.
+ */
+
+struct irq_chip nlm_msi_pic = {
+	.name = "XLP-PIC-MSI",
+	.irq_startup = nlm_msi_startup,
+	.irq_shutdown = nlm_msi_shutdown,
+	.irq_ack = nlm_msi_ack,
+	.irq_eoi = nlm_msi_end,
+	.irq_mask = nlm_msi_mask,
+	.irq_unmask = nlm_msi_unmask,
+	.irq_set_affinity = nlm_msi_set_affinity
+};
+
+/*
+ * These functions would find out the controller function using the
+ * passed parameter and use nlm_irq_* function to operate on that IRT
+ */
+static int nlm_msix_set_affinity(struct irq_data *data, const struct cpumask *mask, bool force)
+{
+	struct cpumask m;
+	unsigned int msix = data->irq;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+
+	BUG_ON(pic->node != XLP_MSIX_TO_NODE(msix));
+	if (check_msix_range(msix) < 0) {
+		return -EINVAL;
+	}
+	return pic->set_irq_affinity(pic, xlp_msix_to_irt(msix),
+			UPIC_AFFINITY_ITE, mask, &m);
+}
+
+static void nlm_msix_end(struct irq_data *data)
+{
+	unsigned int msix = data->irq;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+
+	BUG_ON(pic->node != XLP_MSIX_TO_NODE(msix));
+	if (check_msix_range(msix) < 0) {
+		return;
+	}
+	pic->interrupt_ack(pic, xlp_msix_to_irt(msix), 0);
+	return;
+}
+
+static void nlm_msix_ack(struct irq_data *data)
+{
+	unsigned int msix = data->irq;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+
+	BUG_ON(pic->node != XLP_MSIX_TO_NODE(msix));
+	if (check_msix_range(msix) < 0) {
+		return;
+	}
+	pic->interrupt_ack(pic, xlp_msix_to_irt(msix), 0);
+	return;
+}
+
+/*
+ * Masks just one MSIX
+ * @msix : the MSIX to mask
+ *
+ * MSI-X masking is different from MSI masking (msi->temporarily disable
+ * in the h/w. That is an XLP oddity.
+ * MSI-X has masking as a standard feature
+ */
+static void nlm_msix_mask(struct irq_data *data)
+{
+	unsigned long flags;
+	unsigned int msix = data->irq;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+
+	BUG_ON(pic->node != XLP_MSIX_TO_NODE(msix));
+	if (check_msix_range(msix) < 0) {
+		return;
+	}
+	spin_lock_irqsave(&xlp_msi_lock, flags);
+	mask_msi_irq(data); /* This function masks MSI-X -- please note */
+	__xlp_irq_mask(pic, xlp_msix_to_irq(msix));
+	spin_unlock_irqrestore(&xlp_msi_lock, flags);
+	return;
+}
+
+/*
+ * Unmask just one MSIX
+ * If required, unmask the corresponding IRT as well
+ */
+static void nlm_msix_unmask(struct irq_data *data)
+{
+	unsigned long flags;
+	unsigned int msix = data->irq;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+
+	BUG_ON(pic->node != XLP_MSIX_TO_NODE(msix));
+	if (check_msix_range(msix) < 0) {
+		return;
+	}
+	spin_lock_irqsave(&xlp_msi_lock, flags);
+	__xlp_irq_unmask(pic, xlp_msix_to_irq(msix));
+	unmask_msi_irq(data); /* Enable MSI-X -- please note */
+	spin_unlock_irqrestore(&xlp_msi_lock, flags);
+	return;
+}
+
+static unsigned int nlm_msix_startup(struct irq_data *data)
+{
+	unsigned int msix = data->irq;
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+	int fn = XLP_MSIX_TO_CTRL_FN(msix), ret;
+
+	BUG_ON(pic->node != XLP_MSIX_TO_NODE(msix));
+	if (check_msix_range(msix) < 0) {
+		return -EINVAL;
+	}
+	if ((ret = xlp_msix_enable(pic->node, fn)) < 0) {
+		return ret;
+	}
+	nlm_msix_unmask(data);
+	return xlp_irq_startup(pic, xlp_msix_to_irq(msix) % XLP_IRQS_PER_NODE);
+}
+
+static void nlm_msix_shutdown(struct irq_data *data)
+{
+	unsigned int msix = data->irq;
+
+	struct pic_dev *pic = (struct pic_dev *)data->chip_data;
+	int fn = XLP_MSIX_TO_CTRL_FN(msix), ret;
+
+	BUG_ON(pic->node != XLP_MSIX_TO_NODE(msix));
+	if (check_msix_range(msix) < 0) {
+		return;
+	}
+	nlm_msix_mask(data);
+	if ((ret = xlp_msix_disable(pic->node, fn)) < 0) {
+		return;
+	}
+	xlp_irq_shutdown(pic, xlp_msix_to_irq(msix) % XLP_IRQS_PER_NODE);
+	return;
+}
+
+/*
+ * MSI-X hook-up routines for Netlogic Boards;
+ * Arch-dependent implementation called
+ * from generic msi.c routines.
+ */
+
+struct irq_chip nlm_msix_pic = {
+	.name = "XLP-PIC-MSIX",
+	.irq_startup = nlm_msix_startup,
+	.irq_shutdown = nlm_msix_shutdown,
+	.irq_ack = nlm_msix_ack,
+	.irq_eoi = nlm_msix_end,
+	.irq_mask = nlm_msix_mask,
+	.irq_unmask = nlm_msix_unmask,
+	.irq_set_affinity = nlm_msix_set_affinity
+};
+
+
+/*
+ * Returns the bitmask of currently used MSI-X on controller fn
+ *
+ * Must call with lock held
+ * @fn : controller number
+ */
+# if 0
+u32 __xlp_msix_bitmask(u8 node, int fn)
+{
+	int idx = 0, ret = 0;
+
+	while (idx < XLP_MSIX_PER_SLOT) {
+		if (irq_map[XLP_MSIX_IRQ_START(fn) + idx].usage[node] > 0) {
+			ret |= (1ULL << idx);
+		}
+		idx++;
+	}
+	return ret;
+}
+#endif
+
+/*
+ * Back end of disable_msi()/ disable_msix()
+ */
+void arch_teardown_msi_irq(unsigned int msi)
+{
+	unsigned long flags;
+	int bit, fn;
+	u8 node = XLP_MSIX_TO_NODE(msi);
+	unsigned int lmsi = msi % XLP_IRQS_PER_NODE;
+
+	switch (msi) {
+	case XLP_MSI_INDEX_START ... XLP_MSI_INDEX_END:
+		spin_lock_irqsave(&xlp_msi_lock, flags);
+		fn = XLP_MSI_TO_CTRL_FN(msi);
+		bit = lmsi - XLP_MSI_IRQ_START(0, fn);
+		msi_vec[node][fn].count--;
+		msi_vec[node][fn].bitmap &= ~(1ULL << bit);
+		if (xlp_get_ctrl_intmode(node, fn) == XLP_INTMODE_MSI) {
+			if (xlp_set_ctrl_intmode(node, fn, XLP_INTMODE_NONE) < 0){
+			}
+		}
+		spin_unlock_irqrestore(&xlp_msi_lock, flags);
+		return;
+	case XLP_MSIX_INDEX_START ... XLP_MSIX_INDEX_END:
+		fn = XLP_MSIX_TO_CTRL_FN(msi);
+		bit = (msi % XLP_IRQS_PER_NODE) - XLP_MSIX_IRQ_START(0, fn);
+		spin_lock_irqsave(&xlp_msi_lock, flags);
+		msix_vec[node][fn].count--;
+		msix_vec[node][fn].bitmap &= ~(1ULL << bit);
+		if (xlp_get_ctrl_intmode(node, fn) == XLP_INTMODE_MSIX) {
+			if (xlp_set_ctrl_intmode(node, fn, XLP_INTMODE_NONE) < 0){
+			}
+		}
+		spin_unlock_irqrestore(&xlp_msi_lock, flags);
+		return;
+	default:
+		return;	/* Do not proceed if !(msi || msix) */
+	}
+}
+
diff --git a/arch/mips/netlogic/xlp/pic/xlp_irq_map.c b/arch/mips/netlogic/xlp/pic/xlp_irq_map.c
index 74a148f..76d24aa 100644
--- a/arch/mips/netlogic/xlp/pic/xlp_irq_map.c
+++ b/arch/mips/netlogic/xlp/pic/xlp_irq_map.c
@@ -706,7 +706,8 @@ void __xlp_irq_unmask(struct pic_dev *pic, int irq)
 
 /*
  * Startup function for any IRQ
- * @irq: irq number
+ * @irq: irq number. This must be an IRQ, i.e, the client should call
+ * xlp_msi_to_irq or xlp_msix_to_irq before calling this function
  *
  * When an interrupt is started, we force it to be enabled only in cpu0, it can
  * be changed later by calling nlm_irq_set_affinity()
diff --git a/arch/mips/netlogic/xlp/pic/xlp_pic.c b/arch/mips/netlogic/xlp/pic/xlp_pic.c
index 1e17921..280a690 100644
--- a/arch/mips/netlogic/xlp/pic/xlp_pic.c
+++ b/arch/mips/netlogic/xlp/pic/xlp_pic.c
@@ -303,18 +303,18 @@ static int xlp_get_closest_mask(struct pic_dev *pic,
  * corresponding to IRQ# passed
  *
  * @pic		: pic device structure
- * @irq		: irq number
+ * @irt		: IRT to program
  * @in		: passed cpumask
  * @out		: actual set cpu mask
  */
-static int xlp_set_irq_affinity(struct pic_dev *pic, int irq, u64 type,
+static int xlp_set_irq_affinity(struct pic_dev *pic, int irt, u64 type,
 		const struct cpumask *in, struct cpumask *out)
 {
 	__label__ unsupported;
 	u8 ite;
 	u64 val;
 	unsigned long flags;
-	int irt = xlp_irq_to_irt(irq), ret = 0;
+	int ret = 0;
 
 	if (type != UPIC_AFFINITY_ITE) { /* We don't do DTE now */
 		return -EINVAL;
diff --git a/arch/mips/pci/Makefile b/arch/mips/pci/Makefile
index 2cb1d31..e6a3429 100644
--- a/arch/mips/pci/Makefile
+++ b/arch/mips/pci/Makefile
@@ -57,6 +57,7 @@ obj-$(CONFIG_MIKROTIK_RB532)	+= pci-rc32434.o ops-rc32434.o fixup-rc32434.o
 obj-$(CONFIG_CPU_CAVIUM_OCTEON) += pci-octeon.o pcie-octeon.o
 obj-$(CONFIG_CPU_XLR)		+= pci-xlr.o
 obj-$(CONFIG_CPU_XLP)		+= pci-xlp.o
+obj-$(CONFIG_PCI_XLP_MSI)  	+= pci-xlp-msi.o
 
 ifdef CONFIG_PCI_MSI
 obj-$(CONFIG_CPU_CAVIUM_OCTEON) += msi-octeon.o
diff --git a/arch/mips/pci/pci-xlp-msi.c b/arch/mips/pci/pci-xlp-msi.c
new file mode 100644
index 0000000..9aadb5d
--- /dev/null
+++ b/arch/mips/pci/pci-xlp-msi.c
@@ -0,0 +1,298 @@
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/pci.h>
+#include <asm/errno.h>
+#include <asm/signal.h>
+#include <asm/ptrace.h>
+#include <asm/kgdb.h>
+#include <asm/mipsregs.h>
+#include <linux/irq.h>
+#include <linux/msi.h>
+
+#include <asm/netlogic/xlp_irq.h>
+#include <asm/netlogic/xlp.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/debug.h>
+#include <asm/thread_info.h>
+#include <asm/netlogic/pic_hal.h>
+#include <asm/netlogic/pci_hal.h>
+#include <asm/netlogic/xlp_irq_map.h>
+#include <asm/netlogic/msi.h>
+#include <asm/netlogic/msi.h>
+
+/*
+ * We have asked for an address range for MSI/MSIX. If it gets allocated,
+ * define CONFIG_XLP_MSI_ADDRESSES
+ */
+#ifndef CONFIG_XLP_MSI_ADDRESSES
+static u64 XLP_MSI_ADDR = 0;
+#endif
+int setup_msi_base_address(void)
+{
+#ifndef CONFIG_XLP_MSI_ADDRESSES
+	u64 size = (XLP_MSIX_ADDR_SIZE > XLP_MSI_ADDR_SIZE) ? XLP_MSIX_ADDR_SIZE : XLP_MSI_ADDR_SIZE;
+	size = size * XLP_MAX_SLOTS * NLM_MAX_CPU_NODE;
+	/* The controller will never read from /write to this area.
+	 * Strictly speaking this allocation is not necessary.
+	 * But if we don't allocate, we will have to keep in different
+	 * processors/boards a range of address which is not used anywhere else
+	 * like physical mem, pci mem ..etc. It is just easier to allocate
+	 * some memory and not use it for anything else.  */
+	/* We don't need 16M, all we need is 2 pages per controller
+	 * => 2 * 4ctr * 4 nodes pages */
+	XLP_MSI_ADDR = (u64)__get_free_pages(GFP_KERNEL,
+			get_order(size));
+	if (XLP_MSI_ADDR == 0) {
+		printk(KERN_ERR "Failed to get memory for MSI/MSI-X tables\n");
+		return -ENOMEM;
+	}
+#endif
+	return 0;
+}
+
+volatile const void *xlp_msix_addr_start(u8 node, int fn)
+{
+	if (XLP_MSI_ADDR == 0) {
+		return 0;
+	}
+	return (volatile const void *)(XLP_MSI_ADDR +
+		(XLP_MSIX_ADDR_SIZE * XLP_MAX_SLOTS * node) +
+		(fn * XLP_MSIX_ADDR_SIZE));
+}
+
+volatile const void *xlp_msi_addr_start(u8 node, int fn)
+{
+	if (XLP_MSI_ADDR == 0) {
+		return 0;
+	}
+	return (volatile const void *)(XLP_MSI_ADDR +
+		(XLP_MSI_ADDR_SIZE * XLP_MAX_SLOTS * node) +
+		(fn * XLP_MSI_ADDR_SIZE));
+}
+
+/* Irrespective of any device requesting MSI/MSI-X, we keep the controller
+ * ready by programming the corresponding registers. This action, per se,
+ * does not start MSI/MSI-X for they have to be enabled explicitly.
+ */
+void xlp_msi_controller_init(u8 node, int fn)
+{
+	u32 mmc, msi;
+
+	if (XLP_MSI_ADDR == 0) {
+		printk(KERN_ERR "MSI/MSI-X CANNOT be programmed\n");
+		return;
+	}
+	msi = nlh_pci_r32r(node, fn,  0x14);
+	mmc = (msi >> 17) & 0x7;
+	/* Initialize MSI Base register */
+	nlh_pci_w32r(node, fn, 0x15,
+		virt_to_phys(xlp_msi_addr_start(node, fn)) & 0xffffffff);
+	nlh_pci_w32r(node, fn, 0x16,
+		(virt_to_phys(xlp_msi_addr_start(node, fn)) >> 32) & 0xffffffff);
+	nlh_pci_w32r(node, fn, 0x17, 0x0);
+	msi |= ((mmc << 20) | (1 << 16));
+	nlh_pci_w32r(node, fn, 0x14, msi);
+	/* Initialize MSI-X Base and Address reg. Note >> 8 in the address.
+	 * This is how 40bit address goes in 32bit registers.*/
+	nlh_pci_w32r(node, fn, 0x24F,
+		(virt_to_phys(xlp_msix_addr_start(node, fn)) >> 8));
+	nlh_pci_w32r(node, fn, 0x250,
+		(virt_to_phys(xlp_msix_addr_start(node, fn) + XLP_MSIX_ADDR_SIZE) >> 8));
+}
+
+/*
+ * Finds the slot on which this device is placed and enables corresponding
+ * MSI enable register on the _controller_ if not already enabled
+ * @dev : pci device corresponding to this device
+ */
+static int __xlp_msi_enable(u8 node, int fn, u32 bit)
+{
+	u32 msi_en;
+
+	/* First, set PCIe MSI Enable register. __KEEP_THIS_ORDER__ */
+	msi_en = nlh_pci_r32r(node, fn,  0x261);
+	msi_en &= ~(0xf);
+	if ((msi_en & (1 << 9)) == 0) {
+		msi_en |= (1 << 9);	/* controls ONLY MSI, Not MSI-X */
+		nlh_pci_w32r(node, fn, 0x261, msi_en);
+	}
+	/* Now, set the individual bit */
+	xlp_msi_set_mask(node, fn, bit, 1);
+	return 0;
+}
+
+int xlp_msi_enable(u8 node, int fn, u32 bit)
+{
+	int tmp = xlp_get_ctrl_intmode(node, fn);
+
+	if ((tmp & XLP_INTMODE_INTX) || (tmp & XLP_INTMODE_MSIX)) {
+		return -EBUSY;
+	}
+
+	/* Enable MSI bis
+	 * Multiple MSI can get enabled at different point of time (especially
+	 * with a switch present. So, setting the bitmap should not depend on
+	 * present value of reg 0x25b or 0x261
+	 */
+	__xlp_msi_enable(node, fn, bit);
+	xlp_incr_ctrl_intmode(node, fn, XLP_INTMODE_MSI);
+	return 0;
+}
+
+/*
+ * Finds the slot on which this device is placed and enables corresponding
+ * MSI-X enable register on the controller
+ */
+static int __xlp_msix_enable(u8 node, int fn)
+{
+	u32 msix_ctrl;
+
+	msix_ctrl = nlh_pci_r32r(node, fn,  0x2C);
+	if (!(msix_ctrl & 0x80000000)) {
+		msix_ctrl |= 0x80000000;	/* MSI-X enable */
+		nlh_pci_w32r(node, fn, 0x2C, msix_ctrl);
+	}
+	//nlh_pci_w32r(node, fn, 0xf, 0xFF);
+	return 0;
+}
+
+int xlp_msix_enable(u8 node, int fn)
+{
+	int mode = xlp_get_ctrl_intmode(node, fn);
+
+	if ((mode & XLP_INTMODE_MSI) || (mode & XLP_INTMODE_INTX)) {
+		return -EBUSY;
+	}
+	__xlp_msix_enable(node, fn);
+	xlp_incr_ctrl_intmode(node, fn, XLP_INTMODE_MSIX);
+	return 0;
+}
+
+/*
+ * Disables MSI on controller function
+ */
+static int __xlp_msi_disable(u8 node, int fn)
+{
+	u32 msi_en;
+
+	/* We dont call xlp_decr_ctrl.... here because it has already been 
+	 * called before xlp_msi_disable is called */
+
+	/*set PCIe Int Enable register */
+	msi_en = nlh_pci_r32r(node, fn,  0x261);
+	if ((msi_en & (1 << 9)) != 0) {
+		msi_en &= ~(1 << 9);
+		msi_en |= 0xf;
+		nlh_pci_w32r(node, fn, 0x261, msi_en);
+	}
+	return 0;
+}
+
+int xlp_msi_disable(u8 node, int fn, u32 bit)
+{
+	int tmp = xlp_get_ctrl_intmode(node, fn);
+	u32 r25b;
+
+	if (!(tmp & XLP_INTMODE_MSI)) {
+		return -EBUSY;
+	}
+	r25b = xlp_msi_set_mask(node, fn, bit, 0);
+	if (r25b == 0) {
+		__xlp_msi_disable(node, fn);
+	}
+	xlp_decr_ctrl_intmode(node, fn, XLP_INTMODE_MSI);
+	return 0;
+}
+
+/*
+ * Disables MSI-X on a controller function
+ */
+static int __xlp_msix_disable(u8 node, int fn)
+{
+	u32 msix_ctrl;
+
+	msix_ctrl = nlh_pci_r32r(node, fn,  0x2C);
+	msix_ctrl &= ~(0x80000000);	/* MSI-X disable */
+	nlh_pci_w32r(node, fn, 0x2C, msix_ctrl);
+	//nlh_pci_w32r(node, fn, 0xf, 0xFF);	/* TODO Get from dev */
+	return 0;
+}
+
+int xlp_msix_disable(u8 node, int fn)
+{
+	int mode = xlp_get_ctrl_intmode(node, fn);
+
+	if (!(mode & XLP_INTMODE_MSIX)) {
+		return -EBUSY;
+	}
+	if (xlp_decr_ctrl_intmode(node, fn, XLP_INTMODE_MSIX) == 0) {
+		__xlp_msix_disable(node, fn);
+	}
+	return 0;
+}
+
+/*
+ * checks if msi is enabled for this controller
+ * @fn	: controller function number
+ */
+int is_msi_set(u8 node, int fn)
+{
+	u32 msi_en, status;
+
+	msi_en = nlh_pci_r32r(node, fn,  0x261);
+	status = (msi_en >> 9) & 1 ;
+	return status;
+}
+
+
+u32 calc_msi_vector_offset(u8 node, int fn)
+{
+	u32 msi_en, msi_stat;
+
+	msi_en = nlh_pci_r32r(node, fn,  0x25B);
+	msi_stat = nlh_pci_r32r(node, fn,  0x25A);
+	nlh_pci_w32r(node, fn, 0x25A, msi_stat);
+	msi_stat &= msi_en;
+	return msi_stat;
+}
+
+/*
+ * Clears MSI-X status bits for a controller
+ * @fn : controller number
+ *
+ * status register is Read, Write 1 to clear.
+ * Figure out the mask (the bits corresponding to fn), read register, clear
+ * them and return the bits corresponding to fn
+ */
+u32 xlp_msix_status_clear(u8 node, int fn)
+{
+	u32 msix_stat;
+	u32 mask = ((XLP_MSIX_PER_SLOT - 1) << (fn * XLP_MSIX_PER_SLOT));
+
+	msix_stat = nlh_pci_r32r(node, fn,  0x25D);
+	msix_stat &= mask;
+	nlh_pci_w32r(node, fn, 0x25D, msix_stat);
+	return (msix_stat >> (fn * XLP_MSIX_PER_SLOT));
+}
+
+/*
+ * Masks the bit corresponding to an MSI and return the resulting bitmask
+ */
+u32 xlp_msi_set_mask(u8 node, int fn, int bit, int val)
+{
+	u32 bits;
+
+	bits = nlh_pci_r32r(node, fn,  0x25B);
+	if (val == 0) {	/* Clear bit `bit` */
+		bits &= ~( 1 << bit);
+	} else {	/* Set bit `bit` */
+		bits |= ( 1 << bit);
+	}
+	nlh_pci_w32r(node, fn, 0x25B, bits);
+	return bits;
+}
diff --git a/arch/mips/pci/pci-xlp.c b/arch/mips/pci/pci-xlp.c
index 0f8982f..810ed82 100644
--- a/arch/mips/pci/pci-xlp.c
+++ b/arch/mips/pci/pci-xlp.c
@@ -42,6 +42,7 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #include <asm/netlogic/hal/nlm_hal.h>
 #include <asm/netlogic/pic_hal.h>
 #include <asm/netlogic/pci_hal.h>
+#include <asm/netlogic/msi.h>
 
 static int pci_probe_only;
 static void *pci_config_base;
@@ -114,41 +115,41 @@ struct xlp_plc_fn_struct {
 static struct xlp_plc_fn_struct
 	node_irqmap[NLM_MAX_CPU_NODE][XLP_PCI_LANE_CONFIG] = {
 {
-	{0, {{XLP_PCIE_LINK_IRQ(0,0), 0, 0}, {0, 0, 0},
-		{XLP_PCIE_LINK_IRQ(0,2), 0, 0}, {0, 0, 0}}},
-	{1, {{XLP_PCIE_LINK_IRQ(0,0), 0, 0}, {XLP_PCIE_LINK_IRQ(0,1), 0, 0},
-		{XLP_PCIE_LINK_IRQ(0,2), 0, 0}, {0, 0, 0}}},
-	{2, {{XLP_PCIE_LINK_IRQ(0,0), 0, 0}, {0, 0, 0},
-		{XLP_PCIE_LINK_IRQ(0,2), 0, 0}, {XLP_PCIE_LINK_IRQ(0,3),0,0}}},
-	{3, {{XLP_PCIE_LINK_IRQ(0,0), 0, 0}, {XLP_PCIE_LINK_IRQ(0,1), 0, 0},
-		{XLP_PCIE_LINK_IRQ(0,2), 0, 0}, {XLP_PCIE_LINK_IRQ(0,3),0,0}}},
+	{0, {{XLP_PCIE_INTX_IRQ(0,0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_INTX_IRQ(0,2), 0, 0}, {0, 0, 0}}},
+	{1, {{XLP_PCIE_INTX_IRQ(0,0), 0, 0}, {XLP_PCIE_INTX_IRQ(0,1), 0, 0},
+		{XLP_PCIE_INTX_IRQ(0,2), 0, 0}, {0, 0, 0}}},
+	{2, {{XLP_PCIE_INTX_IRQ(0,0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_INTX_IRQ(0,2), 0, 0}, {XLP_PCIE_INTX_IRQ(0,3),0,0}}},
+	{3, {{XLP_PCIE_INTX_IRQ(0,0), 0, 0}, {XLP_PCIE_INTX_IRQ(0,1), 0, 0},
+		{XLP_PCIE_INTX_IRQ(0,2), 0, 0}, {XLP_PCIE_INTX_IRQ(0,3),0,0}}},
 }, {
-	{0, {{XLP_PCIE_LINK_IRQ(1,0), 0, 0}, {0, 0, 0},
-		{XLP_PCIE_LINK_IRQ(1,2), 0, 0}, {0, 0, 0}}},
-	{1, {{XLP_PCIE_LINK_IRQ(1,0), 0, 0}, {XLP_PCIE_LINK_IRQ(1,1), 0, 0},
-		{XLP_PCIE_LINK_IRQ(1,2), 0, 0}, {0, 0, 0}}},
-	{2, {{XLP_PCIE_LINK_IRQ(1,0), 0, 0}, {0, 0, 0},
-		{XLP_PCIE_LINK_IRQ(1,2), 0, 0}, {XLP_PCIE_LINK_IRQ(1,3),0,0}}},
-	{3, {{XLP_PCIE_LINK_IRQ(1,0), 0, 0}, {XLP_PCIE_LINK_IRQ(1,1), 0, 0},
-		{XLP_PCIE_LINK_IRQ(1,2), 0, 0}, {XLP_PCIE_LINK_IRQ(1,3),0,0}}},
+	{0, {{XLP_PCIE_INTX_IRQ(1,0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_INTX_IRQ(1,2), 0, 0}, {0, 0, 0}}},
+	{1, {{XLP_PCIE_INTX_IRQ(1,0), 0, 0}, {XLP_PCIE_INTX_IRQ(1,1), 0, 0},
+		{XLP_PCIE_INTX_IRQ(1,2), 0, 0}, {0, 0, 0}}},
+	{2, {{XLP_PCIE_INTX_IRQ(1,0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_INTX_IRQ(1,2), 0, 0}, {XLP_PCIE_INTX_IRQ(1,3),0,0}}},
+	{3, {{XLP_PCIE_INTX_IRQ(1,0), 0, 0}, {XLP_PCIE_INTX_IRQ(1,1), 0, 0},
+		{XLP_PCIE_INTX_IRQ(1,2), 0, 0}, {XLP_PCIE_INTX_IRQ(1,3),0,0}}},
 }, {
-	{0, {{XLP_PCIE_LINK_IRQ(2,0), 0, 0}, {0, 0, 0},
-		{XLP_PCIE_LINK_IRQ(2,2), 0, 0}, {0, 0, 0}}},
-	{1, {{XLP_PCIE_LINK_IRQ(2,0), 0, 0}, {XLP_PCIE_LINK_IRQ(2,1), 0, 0},
-		{XLP_PCIE_LINK_IRQ(2,2), 0, 0}, {0, 0, 0}}},
-	{2, {{XLP_PCIE_LINK_IRQ(2,0), 0, 0}, {0, 0, 0},
-		{XLP_PCIE_LINK_IRQ(2,2), 0, 0}, {XLP_PCIE_LINK_IRQ(2,3),0,0}}},
-	{3, {{XLP_PCIE_LINK_IRQ(2,0), 0, 0}, {XLP_PCIE_LINK_IRQ(2,1), 0, 0},
-		{XLP_PCIE_LINK_IRQ(2,2), 0, 0}, {XLP_PCIE_LINK_IRQ(2,3),0,0}}},
+	{0, {{XLP_PCIE_INTX_IRQ(2,0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_INTX_IRQ(2,2), 0, 0}, {0, 0, 0}}},
+	{1, {{XLP_PCIE_INTX_IRQ(2,0), 0, 0}, {XLP_PCIE_INTX_IRQ(2,1), 0, 0},
+		{XLP_PCIE_INTX_IRQ(2,2), 0, 0}, {0, 0, 0}}},
+	{2, {{XLP_PCIE_INTX_IRQ(2,0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_INTX_IRQ(2,2), 0, 0}, {XLP_PCIE_INTX_IRQ(2,3),0,0}}},
+	{3, {{XLP_PCIE_INTX_IRQ(2,0), 0, 0}, {XLP_PCIE_INTX_IRQ(2,1), 0, 0},
+		{XLP_PCIE_INTX_IRQ(2,2), 0, 0}, {XLP_PCIE_INTX_IRQ(2,3),0,0}}},
 }, {
-	{0, {{XLP_PCIE_LINK_IRQ(3,0), 0, 0}, {0, 0, 0},
-		{XLP_PCIE_LINK_IRQ(3,2), 0, 0}, {0, 0, 0}}},
-	{1, {{XLP_PCIE_LINK_IRQ(3,0), 0, 0}, {XLP_PCIE_LINK_IRQ(3,1), 0, 0},
-		{XLP_PCIE_LINK_IRQ(3,2), 0, 0}, {0, 0, 0}}},
-	{2, {{XLP_PCIE_LINK_IRQ(3,0), 0, 0}, {0, 0, 0},
-		{XLP_PCIE_LINK_IRQ(3,2), 0, 0}, {XLP_PCIE_LINK_IRQ(3,3),0,0}}},
-	{3, {{XLP_PCIE_LINK_IRQ(3,0), 0, 0}, {XLP_PCIE_LINK_IRQ(3,1), 0, 0},
-		{XLP_PCIE_LINK_IRQ(3,2), 0, 0}, {XLP_PCIE_LINK_IRQ(3,3),0,0}}},
+	{0, {{XLP_PCIE_INTX_IRQ(3,0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_INTX_IRQ(3,2), 0, 0}, {0, 0, 0}}},
+	{1, {{XLP_PCIE_INTX_IRQ(3,0), 0, 0}, {XLP_PCIE_INTX_IRQ(3,1), 0, 0},
+		{XLP_PCIE_INTX_IRQ(3,2), 0, 0}, {0, 0, 0}}},
+	{2, {{XLP_PCIE_INTX_IRQ(3,0), 0, 0}, {0, 0, 0},
+		{XLP_PCIE_INTX_IRQ(3,2), 0, 0}, {XLP_PCIE_INTX_IRQ(3,3),0,0}}},
+	{3, {{XLP_PCIE_INTX_IRQ(3,0), 0, 0}, {XLP_PCIE_INTX_IRQ(3,1), 0, 0},
+		{XLP_PCIE_INTX_IRQ(3,2), 0, 0}, {XLP_PCIE_INTX_IRQ(3,3),0,0}}},
 }
 };
 
@@ -262,25 +263,7 @@ static void pcie_controller_init_done(void)
 	u32 plc, syscfg, mode, count = 0, node = 0;
 
 #if defined CONFIG_PCI_MSI
-#ifndef CONFIG_XLP_MSI_ADDRESSES
-	/* The controller will never read from /write to this area.
-	 * Strictly speaking this allocation is not necessary.
-	 * But if we don't allocate, we will have to keep in different
-	 * processors/boards a range of address which is not used anywhere else
-	 * like physical mem, pci mem ..etc. It is just easier to allocate
-	 * some memory and not use it for anything else.  */
-#ifdef CONFIG_32BIT
-	XLP_MSI_ADDR = (u64)__get_free_pages(GFP_KERNEL, get_order(0x100000));
-#else
-	/* We don't need 16M, all we need is 2 pages per controller
-	 * => 2 * 4ctr * 4 nodes pages */
-	XLP_MSI_ADDR = (u64)__get_free_pages(GFP_KERNEL,
-			get_order(0x1000000));
-#endif
-	if (XLP_MSI_ADDR == 0) {
-		printk(KERN_ERR "Failed to get memory for MSI/MSI-X tables\n");
-	}
-#endif
+	BUG_ON(setup_msi_base_address() < 0);
 #endif
 	if (!pci_probe_only){
 		printk(KERN_WARNING "PCIe bus IRQs configured incorrectly\n");
@@ -491,7 +474,6 @@ struct pci_controller xlp_controller = {
 int __init pcibios_map_irq(const struct pci_dev *dev, u8 slot, u8 pin)
 {
 	int row = 0;
-	u8 node = 0;
 	struct xlp_nodefn_struct nfn;
 
 	if (xlp_ctrl_fn_from_dev(dev, &nfn) != 0) {
-- 
1.8.4.93.g57e4c17

