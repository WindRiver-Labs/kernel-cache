From b3d522d68ef38107328a2752322ecf5cde968171 Mon Sep 17 00:00:00 2001
From: Mehul <vmehul@netlogicmicro.com>
Date: Wed, 6 Oct 2010 11:27:36 +0530
Subject: [PATCH 179/565] bcm-xlp: add RIXI support

Add RIXI support.

Based on Broadcom SDK 2.3.

Signed-off-by: Mehul <vmehul@netlogicmicro.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/include/asm/pgtable-64.h | 57 ++++++++++----------------------------
 arch/mips/mm/tlb-r4k.c             | 19 ++++++-------
 arch/mips/netlogic/Kconfig         |  5 ++++
 3 files changed, 28 insertions(+), 53 deletions(-)

diff --git a/arch/mips/include/asm/pgtable-64.h b/arch/mips/include/asm/pgtable-64.h
index a7bdff4..d78afba 100644
--- a/arch/mips/include/asm/pgtable-64.h
+++ b/arch/mips/include/asm/pgtable-64.h
@@ -16,11 +16,7 @@
 #include <asm/cachectl.h>
 #include <asm/fixmap.h>
 
-#ifdef CONFIG_PAGE_SIZE_64KB
-#include <asm-generic/pgtable-nopmd.h>
-#else
 #include <asm-generic/pgtable-nopud.h>
-#endif
 
 /*
  * Each address space has 2 4K pages as its page directory, giving 1024
@@ -41,20 +37,13 @@
  * fault address - VMALLOC_START.
  */
 
-
-/* PGDIR_SHIFT determines what a third-level page table entry can map */
-#ifdef __PAGETABLE_PMD_FOLDED
-#define PGDIR_SHIFT	(PAGE_SHIFT + PAGE_SHIFT + PTE_ORDER - 3)
-#else
-
 /* PMD_SHIFT determines the size of the area a second-level page table can map */
 #define PMD_SHIFT	(PAGE_SHIFT + (PAGE_SHIFT + PTE_ORDER - 3))
 #define PMD_SIZE	(1UL << PMD_SHIFT)
 #define PMD_MASK	(~(PMD_SIZE-1))
 
-
+/* PGDIR_SHIFT determines what a third-level page table entry can map */
 #define PGDIR_SHIFT	(PMD_SHIFT + (PAGE_SHIFT + PMD_ORDER - 3))
-#endif
 #define PGDIR_SIZE	(1UL << PGDIR_SHIFT)
 #define PGDIR_MASK	(~(PGDIR_SIZE-1))
 
@@ -103,32 +92,26 @@
 #ifdef CONFIG_PAGE_SIZE_64KB
 #define PGD_ORDER		0
 #define PUD_ORDER		aieeee_attempt_to_allocate_pud
-#define PMD_ORDER		aieeee_attempt_to_allocate_pmd
+#define PMD_ORDER		0
 #define PTE_ORDER		0
 #endif
 
 #define PTRS_PER_PGD	((PAGE_SIZE << PGD_ORDER) / sizeof(pgd_t))
-#ifndef __PAGETABLE_PMD_FOLDED
 #define PTRS_PER_PMD	((PAGE_SIZE << PMD_ORDER) / sizeof(pmd_t))
-#endif
 #define PTRS_PER_PTE	((PAGE_SIZE << PTE_ORDER) / sizeof(pte_t))
 
-#if PGDIR_SIZE >= TASK_SIZE64
+#if PGDIR_SIZE >= TASK_SIZE
 #define USER_PTRS_PER_PGD       (1)
 #else
-#define USER_PTRS_PER_PGD	(TASK_SIZE64 / PGDIR_SIZE)
+#define USER_PTRS_PER_PGD	(TASK_SIZE / PGDIR_SIZE)
 #endif
 #define FIRST_USER_ADDRESS	0UL
 
-/*
- * TLB refill handlers also map the vmalloc area into xuseg.  Avoid
- * the first couple of pages so NULL pointer dereferences will still
- * reliably trap.
- */
 #if defined(CONFIG_MAPPED_KERNEL) && defined(CONFIG_KSEG2_LOWMEM)
-#define VMALLOC_START		0xe0000000
+extern unsigned long __vmalloc_start;
+#define VMALLOC_START		__vmalloc_start
 #else
-#define VMALLOC_START		(MAP_BASE + (2 * PAGE_SIZE))
+#define VMALLOC_START		MAP_BASE
 #endif
 
 #define VMALLOC_END	\
@@ -152,30 +135,15 @@
 
 #define pte_ERROR(e) \
 	printk("%s:%d: bad pte %016lx.\n", __FILE__, __LINE__, pte_val(e))
-#ifndef __PAGETABLE_PMD_FOLDED
 #define pmd_ERROR(e) \
 	printk("%s:%d: bad pmd %016lx.\n", __FILE__, __LINE__, pmd_val(e))
-#endif
 #define pgd_ERROR(e) \
 	printk("%s:%d: bad pgd %016lx.\n", __FILE__, __LINE__, pgd_val(e))
 
 extern pte_t invalid_pte_table[PTRS_PER_PTE];
 extern pte_t empty_bad_page_table[PTRS_PER_PTE];
-
-
-#ifndef __PAGETABLE_PMD_FOLDED
-/*
- * For 3-level pagetables we defines these ourselves, for 2-level the
- * definitions are supplied by <asm-generic/pgtable-nopmd.h>.
- */
-typedef struct { unsigned long pmd; } pmd_t;
-#define pmd_val(x)	((x).pmd)
-#define __pmd(x)	((pmd_t) { (x) } )
-
-
 extern pmd_t invalid_pmd_table[PTRS_PER_PMD];
 extern pmd_t empty_bad_pmd_table[PTRS_PER_PMD];
-#endif
 
 /*
  * Empty pgd/pmd entries point to the invalid_pte_table.
@@ -196,7 +164,6 @@ static inline void pmd_clear(pmd_t *pmdp)
 {
 	pmd_val(*pmdp) = ((unsigned long) invalid_pte_table);
 }
-#ifndef __PAGETABLE_PMD_FOLDED
 
 /*
  * Empty pud entries point to the invalid_pmd_table.
@@ -220,7 +187,6 @@ static inline void pud_clear(pud_t *pudp)
 {
 	pud_val(*pudp) = ((unsigned long) invalid_pmd_table);
 }
-#endif
 
 #define pte_page(x)		pfn_to_page(pte_pfn(x))
 
@@ -228,7 +194,11 @@ static inline void pud_clear(pud_t *pudp)
 #define pte_pfn(x)		((unsigned long)((x).pte >> (PAGE_SHIFT + 2)))
 #define pfn_pte(pfn, prot)	__pte(((pfn) << (PAGE_SHIFT + 2)) | pgprot_val(prot))
 #else
+#ifdef CONFIG_NLM_XLP
+#define pte_pfn(x)		((unsigned long)(((x).pte & ~((1ULL << _PAGE_NO_READ_SHIFT) | (1ULL << _PAGE_NO_EXEC_SHIFT))) >> _PFN_SHIFT))
+#else
 #define pte_pfn(x)		((unsigned long)((x).pte >> _PFN_SHIFT))
+#endif
 #define pfn_pte(pfn, prot)	__pte(((pfn) << _PFN_SHIFT) | pgprot_val(prot))
 #endif
 
@@ -245,7 +215,6 @@ static inline void pud_clear(pud_t *pudp)
 /* to find an entry in a page-table-directory */
 #define pgd_offset(mm, addr)	((mm)->pgd + pgd_index(addr))
 
-#ifndef __PAGETABLE_PMD_FOLDED
 static inline unsigned long pud_page_vaddr(pud_t pud)
 {
 	return pud_val(pud);
@@ -258,7 +227,6 @@ static inline pmd_t *pmd_offset(pud_t * pud, unsigned long address)
 {
 	return (pmd_t *) pud_page_vaddr(*pud) + pmd_index(address);
 }
-#endif
 
 /* Find an entry in the third-level page table.. */
 #define __pte_offset(address)						\
@@ -269,7 +237,10 @@ static inline pmd_t *pmd_offset(pud_t * pud, unsigned long address)
 	((pte_t *) pmd_page_vaddr(*(dir)) + __pte_offset(address))
 #define pte_offset_map(dir, address)					\
 	((pte_t *)page_address(pmd_page(*(dir))) + __pte_offset(address))
+#define pte_offset_map_nested(dir, address)				\
+	((pte_t *)page_address(pmd_page(*(dir))) + __pte_offset(address))
 #define pte_unmap(pte) ((void)(pte))
+#define pte_unmap_nested(pte) ((void)(pte))
 
 /*
  * Initialize a new pgd / pmd table with invalid pointers.
diff --git a/arch/mips/mm/tlb-r4k.c b/arch/mips/mm/tlb-r4k.c
index 117def4..8df5264 100644
--- a/arch/mips/mm/tlb-r4k.c
+++ b/arch/mips/mm/tlb-r4k.c
@@ -565,19 +565,18 @@ void __cpuinit tlb_init(void)
 	write_c0_framemask(0);
 #endif
 
-	if (kernel_uses_smartmips_rixi) {
-		/*
-		 * Enable the no read, no exec bits, and enable large virtual
-		 * address.
-		 */
-		u32 pg = PG_RIE | PG_XIE;
+   if (kernel_uses_smartmips_rixi) {
+       /*
+        * Enable the no read, no exec bits, and enable large virtual
+        * address.
+        */
+       u32 pg = PG_RIE | PG_XIE;
 #ifdef CONFIG_64BIT
-		pg |= PG_ELPA;
+       pg |= PG_ELPA;
 #endif
-		write_c0_pagegrain(pg);
-	}
+       write_c0_pagegrain(pg);
+   }
 
->>>>>>> 6a1653f... Resolve merge conflict: merge, cosmetic cleanup
 	temp_tlb_entry = current_cpu_data.tlbsize - 1;
 
         /* From this point on the ARC firmware is dead.  */
diff --git a/arch/mips/netlogic/Kconfig b/arch/mips/netlogic/Kconfig
index 544811f..bfcc46a 100644
--- a/arch/mips/netlogic/Kconfig
+++ b/arch/mips/netlogic/Kconfig
@@ -210,3 +210,8 @@ config NLM_ENABLE_COP2
 	default n
 	help
 	  This option enables cop2 access for both user and kernel space.
+
+config NLM_RIXI
+       bool "Enable Read Inhibit/ Execute Inhibit support"
+       depends on NLM_XLP && 64BIT
+       default n
-- 
1.8.4.93.g57e4c17

