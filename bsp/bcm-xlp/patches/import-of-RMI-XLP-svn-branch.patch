From fe2975c1498dbcaec96202d4502f73195dae17c7 Mon Sep 17 00:00:00 2001
From: Yanjiang Jin <yanjiang.jin@windriver.com>
Date: Thu, 25 Apr 2013 13:07:49 +0800
Subject: [PATCH 002/565] import of RMI XLP svn branch

Import of RMI XLP svn branch
@ r2449 e38a0ec8-7566-4368-984d-d703fc0d8259

Based on Broadcom SDK 2.3.

Signed-off-by: Venu Vadapalli <vvadapalli@netlogicmicro.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/Makefile                                 |  87 ++-
 arch/mips/include/asm/Kbuild                       |   5 +
 arch/mips/include/asm/addrspace.h                  |  10 +-
 arch/mips/include/asm/atomic.h                     |  86 +--
 arch/mips/include/asm/auxvec.h                     |   4 +
 arch/mips/include/asm/barrier.h                    |  16 +-
 arch/mips/include/asm/bitops.h                     |  21 +
 arch/mips/include/asm/bitsperlong.h                |   8 +
 arch/mips/include/asm/bootinfo.h                   |  55 +-
 arch/mips/include/asm/break.h                      |  23 +-
 arch/mips/include/asm/byteorder.h                  |  19 +
 arch/mips/include/asm/cachectl.h                   |  26 +
 arch/mips/include/asm/cacheflush.h                 |  22 +-
 arch/mips/include/asm/cmpxchg.h                    |   7 +-
 arch/mips/include/asm/cpu-features.h               |   8 +
 arch/mips/include/asm/cpu.h                        |   2 +
 arch/mips/include/asm/dma.h                        | 116 ++--
 arch/mips/include/asm/fcntl.h                      |  77 +++
 arch/mips/include/asm/gpio.h                       |   1 +
 arch/mips/include/asm/io.h                         |   2 +-
 arch/mips/include/asm/ioctl.h                      |  27 +
 arch/mips/include/asm/kexec.h                      |  27 +-
 arch/mips/include/asm/linkage.h                    |   3 -
 arch/mips/include/asm/mach-generic/spaces.h        |  15 +-
 .../asm/mach-mipssim/cpu-feature-overrides.h       |  67 +++
 arch/mips/include/asm/mach-mipssim/war.h           |  25 +
 .../asm/mach-netlogic/cpu-feature-overrides.h      |  34 +-
 arch/mips/include/asm/mach-netlogic/irq.h          |   6 +-
 arch/mips/include/asm/mach-netlogic/war.h          |   1 +
 arch/mips/include/asm/mips-boards/prom.h           |  47 ++
 arch/mips/include/asm/mips-boards/sim.h            |  14 +-
 arch/mips/include/asm/mips-boards/simint.h         |  31 ++
 arch/mips/include/asm/mips_machine.h               |   4 +
 arch/mips/include/asm/mipsregs.h                   |  46 +-
 arch/mips/include/asm/mmu_context.h                |  58 +-
 arch/mips/include/asm/msgbuf.h                     |  47 ++
 arch/mips/include/asm/msi.h                        |  28 +
 arch/mips/include/asm/netlogic/common.h            |  61 +--
 arch/mips/include/asm/netlogic/haldefs.h           |  92 ++--
 arch/mips/include/asm/netlogic/interrupt.h         |   2 +-
 arch/mips/include/asm/netlogic/xlp-hal/bridge.h    |   4 +-
 .../mips/include/asm/netlogic/xlp-hal/cpucontrol.h |   6 +-
 arch/mips/include/asm/netlogic/xlp-hal/iomap.h     |  51 +-
 arch/mips/include/asm/netlogic/xlp-hal/pic.h       | 209 ++++---
 arch/mips/include/asm/netlogic/xlp-hal/sys.h       | 162 +++---
 arch/mips/include/asm/netlogic/xlp-hal/uart.h      |   4 +-
 arch/mips/include/asm/netlogic/xlp-hal/xlp.h       |  17 +-
 arch/mips/include/asm/netlogic/xlr/gpio.h          |  59 +-
 arch/mips/include/asm/netlogic/xlr/iomap.h         |  88 +--
 arch/mips/include/asm/netlogic/xlr/msidef.h        |  18 +-
 arch/mips/include/asm/netlogic/xlr/pic.h           |  58 +-
 arch/mips/include/asm/netlogic/xlr/xlr.h           |   6 +-
 arch/mips/include/asm/paccess.h                    |   2 +-
 arch/mips/include/asm/page.h                       |  84 ++-
 arch/mips/include/asm/param.h                      |  16 +
 arch/mips/include/asm/pci.h                        |  17 +-
 arch/mips/include/asm/pci/bridge.h                 |  30 +-
 arch/mips/include/asm/pgtable-32.h                 |  29 +-
 arch/mips/include/asm/pgtable-64.h                 |  32 +-
 arch/mips/include/asm/pgtable-bits.h               |  71 ++-
 arch/mips/include/asm/poll.h                       |   9 +
 arch/mips/include/asm/posix_types.h                |  37 ++
 arch/mips/include/asm/processor.h                  |  80 ++-
 arch/mips/include/asm/ptrace.h                     |  12 +
 arch/mips/include/asm/r4kcache.h                   |  12 +-
 arch/mips/include/asm/resource.h                   |  35 ++
 arch/mips/include/asm/rio.h                        |  15 +
 arch/mips/include/asm/sembuf.h                     |  22 +
 arch/mips/include/asm/shmbuf.h                     |  38 ++
 arch/mips/include/asm/smp.h                        |  33 +-
 arch/mips/include/asm/sparsemem.h                  |   8 +-
 arch/mips/include/asm/spinlock.h                   | 124 +++--
 arch/mips/include/asm/stackframe.h                 |  26 +-
 arch/mips/include/asm/stat.h                       | 132 +++++
 arch/mips/include/asm/statfs.h                     | 100 ++++
 arch/mips/include/asm/swab.h                       |  59 ++
 arch/mips/include/asm/thread_info.h                |  19 +
 arch/mips/include/asm/timex.h                      | 102 ++++
 arch/mips/kernel/Makefile                          |   1 +
 arch/mips/kernel/asm-offsets.c                     |  23 +
 arch/mips/kernel/binfmt_elfn32.c                   |  43 +-
 arch/mips/kernel/binfmt_elfo32.c                   |  51 +-
 arch/mips/kernel/bmips_vec.S                       |   6 +-
 arch/mips/kernel/cevt-r4k.c                        |  24 +-
 arch/mips/kernel/cpu-bugs64.c                      |  10 +-
 arch/mips/kernel/ftrace.c                          |  52 +-
 arch/mips/kernel/head.S                            |  51 +-
 arch/mips/kernel/i8259.c                           |   2 +-
 arch/mips/kernel/init_task.c                       |  35 ++
 arch/mips/kernel/irq_cpu.c                         |  50 +-
 arch/mips/kernel/kgdb.c                            |  59 ++
 arch/mips/kernel/kspd.c                            | 423 +++++++++++++++
 arch/mips/kernel/machine_kexec.c                   |  33 +-
 arch/mips/kernel/mcount.S                          |  12 +-
 arch/mips/kernel/mips-mt-fpaff.c                   |   4 +-
 arch/mips/kernel/mips-mt.c                         |   2 +-
 arch/mips/kernel/mips_machine.c                    |  22 +-
 arch/mips/kernel/prom.c                            |  28 +
 arch/mips/kernel/ptrace.c                          |  22 +
 arch/mips/kernel/ptrace32.c                        |   2 +-
 arch/mips/kernel/r4k_switch.S                      |  11 +-
 arch/mips/kernel/relocate_kernel.S                 | 112 +---
 arch/mips/kernel/scall32-o32.S                     |  33 ++
 arch/mips/kernel/scall64-64.S                      |   5 +
 arch/mips/kernel/scall64-n32.S                     |  15 +
 arch/mips/kernel/scall64-o32.S                     |  26 +
 arch/mips/kernel/setup.c                           | 291 ++++------
 arch/mips/kernel/smp-bmips.c                       |  15 +-
 arch/mips/kernel/smp-cmp.c                         |   6 +-
 arch/mips/kernel/smtc-proc.c                       |  64 ++-
 arch/mips/kernel/smtc.c                            | 118 ++--
 arch/mips/kernel/time.c                            |  13 +-
 arch/mips/kernel/vmlinux.lds.S                     |  34 +-
 arch/mips/lib/dump_tlb.c                           |   6 +-
 arch/mips/lib/memcpy-inatomic.S                    | 451 ++++++++++++++++
 arch/mips/math-emu/kernel_linkage.c                | 213 +++++++-
 arch/mips/mm/Makefile                              |   4 +
 arch/mips/mm/c-phoenix.c                           | 600 +++++++++++++++++++++
 arch/mips/mm/c-r4k.c                               | 122 ++---
 arch/mips/mm/cache.c                               |  39 +-
 arch/mips/mm/cex-gen.S                             |  45 +-
 arch/mips/mm/extable.c                             |  21 +
 arch/mips/mm/fault.c                               |   3 +-
 arch/mips/mm/init.c                                |   9 +-
 arch/mips/mm/ioremap.c                             |  22 +-
 arch/mips/mm/mmap.c                                | 117 +++-
 arch/mips/mm/pgtable-64.c                          |  73 ++-
 arch/mips/mm/tlb-r4k.c                             | 227 +++++++-
 arch/mips/mm/tlbex-fault.S                         |   4 +
 arch/mips/mm/tlbex.c                               |   1 +
 arch/mips/oprofile/Makefile                        |   5 +-
 arch/mips/oprofile/common.c                        |  32 +-
 crypto/Makefile                                    |   1 +
 drivers/char/Kconfig                               |  19 +
 drivers/i2c/busses/Kconfig                         |  11 +
 drivers/mtd/maps/Makefile                          |   1 +
 drivers/mtd/nand/nand_base.c                       |   3 +
 drivers/net/Kconfig                                |   6 +
 drivers/oprofile/oprofile_files.c                  |   4 +-
 drivers/pci/proc.c                                 |   8 +
 drivers/watchdog/Kconfig                           |   8 +
 include/linux/memblk.h                             |  55 ++
 include/linux/mm.h                                 |   1 +
 include/linux/oprofile.h                           |   2 +
 include/linux/skbuff.h                             |  20 +
 145 files changed, 5192 insertions(+), 1695 deletions(-)
 create mode 100644 arch/mips/include/asm/auxvec.h
 create mode 100644 arch/mips/include/asm/bitsperlong.h
 create mode 100644 arch/mips/include/asm/byteorder.h
 create mode 100644 arch/mips/include/asm/cachectl.h
 create mode 100644 arch/mips/include/asm/fcntl.h
 create mode 100644 arch/mips/include/asm/ioctl.h
 create mode 100644 arch/mips/include/asm/mach-mipssim/cpu-feature-overrides.h
 create mode 100644 arch/mips/include/asm/mach-mipssim/war.h
 create mode 100644 arch/mips/include/asm/mips-boards/prom.h
 create mode 100644 arch/mips/include/asm/mips-boards/simint.h
 create mode 100644 arch/mips/include/asm/msgbuf.h
 create mode 100644 arch/mips/include/asm/msi.h
 create mode 100644 arch/mips/include/asm/param.h
 create mode 100644 arch/mips/include/asm/poll.h
 create mode 100644 arch/mips/include/asm/posix_types.h
 create mode 100644 arch/mips/include/asm/resource.h
 create mode 100644 arch/mips/include/asm/rio.h
 create mode 100644 arch/mips/include/asm/sembuf.h
 create mode 100644 arch/mips/include/asm/shmbuf.h
 create mode 100644 arch/mips/include/asm/stat.h
 create mode 100644 arch/mips/include/asm/statfs.h
 create mode 100644 arch/mips/include/asm/swab.h
 create mode 100644 arch/mips/kernel/init_task.c
 create mode 100644 arch/mips/kernel/kspd.c
 create mode 100644 arch/mips/lib/memcpy-inatomic.S
 create mode 100644 arch/mips/mm/c-phoenix.c
 create mode 100644 include/linux/memblk.h

diff --git a/arch/mips/Makefile b/arch/mips/Makefile
index dd58a04..a200909 100644
--- a/arch/mips/Makefile
+++ b/arch/mips/Makefile
@@ -42,6 +42,10 @@ tool-archpref		= $(64bit-tool-archpref)
 UTS_MACHINE		:= mips64
 endif
 
+ifdef CONFIG_CROSSCOMPILE
+CROSS_COMPILE		:= $(tool-archpref)
+endif
+
 ifneq ($(SUBARCH),$(ARCH))
   ifeq ($(CROSS_COMPILE),)
     CROSS_COMPILE := $(call cc-cross-prefix, $(tool-archpref)-linux-  $(tool-archpref)-linux-gnu-  $(tool-archpref)-unknown-linux-gnu-)
@@ -90,8 +94,12 @@ all-$(CONFIG_SYS_SUPPORTS_ZBOOT)+= vmlinuz
 cflags-y			+= -G 0 -mno-abicalls -fno-pic -pipe
 cflags-y			+= -msoft-float
 LDFLAGS_vmlinux			+= -G 0 -static -n -nostdlib
+
+ifndef CONFIG_MAPPED_KERNEL
+MODFLAGS			+= -mlong-calls
 KBUILD_AFLAGS_MODULE		+= -mlong-calls
 KBUILD_CFLAGS_MODULE		+= -mlong-calls
+endif
 
 cflags-y += -ffreestanding
 
@@ -114,7 +122,6 @@ cflags-$(CONFIG_CPU_BIG_ENDIAN)		+= $(shell $(CC) -dumpmachine |grep -q 'mips.*e
 cflags-$(CONFIG_CPU_LITTLE_ENDIAN)	+= $(shell $(CC) -dumpmachine |grep -q 'mips.*el-.*' || echo -EL $(undef-all) $(predef-le))
 
 cflags-$(CONFIG_CPU_HAS_SMARTMIPS)	+= $(call cc-option,-msmartmips)
-cflags-$(CONFIG_CPU_MICROMIPS) += $(call cc-option,-mmicromips -mno-jals)
 
 cflags-$(CONFIG_SB1XXX_CORELIS)	+= $(call cc-option,-mno-sched-prolog) \
 				   -fno-omit-frame-pointer
@@ -146,6 +153,8 @@ cflags-$(CONFIG_CPU_NEVADA)	+= $(call cc-option,-march=rm5200,-march=r5000) \
 			-Wa,--trap
 cflags-$(CONFIG_CPU_RM7000)	+= $(call cc-option,-march=rm7000,-march=r5000) \
 			-Wa,--trap
+cflags-$(CONFIG_CPU_RM9000)	+= $(call cc-option,-march=rm9000,-march=r5000) \
+			-Wa,--trap
 cflags-$(CONFIG_CPU_SB1)	+= $(call cc-option,-march=sb1,-march=r5000) \
 			-Wa,--trap
 cflags-$(CONFIG_CPU_R8000)	+= -march=r8000 -Wa,--trap
@@ -158,6 +167,8 @@ endif
 cflags-$(CONFIG_CAVIUM_CN63XXP1) += -Wa,-mfix-cn63xxp1
 cflags-$(CONFIG_CPU_BMIPS)	+= -march=mips32 -Wa,-mips32 -Wa,--trap
 
+cflags-$(CONFIG_CPU_XLR)    += $(call cc-option,-march=xlr) -Wa,--trap
+cflags-$(CONFIG_CPU_XLP)    += $(call cc-option,-march=xlp) -Wa,--trap
 cflags-$(CONFIG_CPU_R4000_WORKAROUNDS)	+= $(call cc-option,-mfix-r4000,)
 cflags-$(CONFIG_CPU_R4400_WORKAROUNDS)	+= $(call cc-option,-mfix-r4400,)
 cflags-$(CONFIG_CPU_DADDI_WORKAROUNDS)	+= $(call cc-option,-mno-daddi,)
@@ -172,9 +183,9 @@ endif
 #
 # Firmware support
 #
-libs-$(CONFIG_FW_ARC)		+= arch/mips/fw/arc/
-libs-$(CONFIG_FW_CFE)		+= arch/mips/fw/cfe/
-libs-$(CONFIG_FW_SNIPROM)	+= arch/mips/fw/sni/
+libs-$(CONFIG_ARC)		+= arch/mips/fw/arc/
+libs-$(CONFIG_CFE)		+= arch/mips/fw/cfe/
+libs-$(CONFIG_SNIPROM)		+= arch/mips/fw/sni/
 libs-y				+= arch/mips/fw/lib/
 
 #
@@ -191,11 +202,38 @@ endif
 #
 include $(srctree)/arch/mips/Kbuild.platforms
 
-ifdef CONFIG_PHYSICAL_START
-load-y					= $(CONFIG_PHYSICAL_START)
-endif
+#
+# RMI SOC Common (phoenix)
+core-$(CONFIG_RMI_PHOENIX)      	+= arch/mips/rmi/phoenix/
+core-$(CONFIG_RMI_PHOENIX) 		+= arch/mips/rmi/mm/
+cflags-$(CONFIG_RMI_PHOENIX)    	+= -DXLS -I$(srctree)/arch/mips/include/asm/mach-rmi
+cflags-$(CONFIG_RMI_PHOENIX)    	+= -I$(srctree)/arch/mips/include/asm/rmi
+
+#
+# RMI XLR/XLS SoC, Simulator and boards
+#
+core-$(CONFIG_RMI_XLR)      		+= arch/mips/rmi/xlr/
+core-$(CONFIG_RMI_PTR) 		+= arch/mips/rmi/ptr/
+cflags-$(CONFIG_CRYPTO_XLR)		+= -Idrivers/crypto/rmi/common
+cflags-$(CONFIG_RMI_XLR)    		+= -DRMI_BRIDGE_WKAROUND
+# This address is now configured via kernel configuration file
+load-$(CONFIG_RMI_PTR)          	+= $(CONFIG_RMI_PHOENIX_LOAD_ADDRESS)
+
+#
+# RMI XLP Soc, Simulator and boards
+#
+core-$(CONFIG_RMI_XLP) 		+= arch/mips/rmi/xlp/
+core-$(CONFIG_RMI_XLP_SIM)          	+= arch/mips/rmi/ptr/
+cflags-$(CONFIG_RMI_XLP_SIM)        	+= -DXLP_SIM=1
+cflags-$(CONFIG_RMI_XLP)    		+= -DXLS -I$(srctree)/arch/mips/include/asm/rmi/xlp_common/
+# This address is now configured via kernel configuration file
+load-$(CONFIG_RMI_XLP_SIM)      += $(CONFIG_RMI_PHOENIX_LOAD_ADDRESS)
+
+#
+# Generic MIPS headers
+#
+cflags-y                        += -I$(srctree)/arch/mips/include/asm/mach-generic
 
-cflags-y			+= -I$(srctree)/arch/mips/include/asm/mach-generic
 drivers-$(CONFIG_PCI)		+= arch/mips/pci/
 
 #
@@ -222,11 +260,17 @@ endif
 
 KBUILD_AFLAGS	+= $(cflags-y)
 KBUILD_CFLAGS	+= $(cflags-y)
-KBUILD_CPPFLAGS += -DVMLINUX_LOAD_ADDRESS=$(load-y)
-KBUILD_CPPFLAGS += -DDATAOFFSET=$(if $(dataoffset-y),$(dataoffset-y),0)
+KBUILD_CPPFLAGS += -D"VMLINUX_LOAD_ADDRESS=$(load-y)"
+KBUILD_CPPFLAGS += -D"DATAOFFSET=$(if $(dataoffset-y),$(dataoffset-y),0)"
 
 LDFLAGS			+= -m $(ld-emul)
 
+ifdef CONFIG_CPU_LITTLE_ENDIAN
+AFLAGS += -EL
+CFLAGS += -EL
+LDFLAGS += -EL
+endif
+
 ifdef CONFIG_MIPS
 CHECKFLAGS += $(shell $(CC) $(KBUILD_CFLAGS) -dM -E -x c /dev/null | \
 	egrep -vw '__GNUC_(|MINOR_|PATCHLEVEL_)_' | \
@@ -238,7 +282,28 @@ endif
 
 OBJCOPYFLAGS		+= --remove-section=.reginfo
 
-head-y := arch/mips/kernel/head.o
+ifdef CONFIG_MAPPED_KERNEL
+PHYS_LOAD_ADDRESS = -D"PHYSADDR=$(CONFIG_PHYS_LOAD_ADDRESS)"
+endif
+
+#
+# Choosing incompatible machines durings configuration will result in
+# error messages during linking.  Select a default linkscript if
+# none has been choosen above.
+#
+
+
+CPPFLAGS_vmlinux.lds := \
+	$(CFLAGS) \
+	-D"LOADADDR=$(load-y)" $(PHYS_LOAD_ADDRESS) \
+	-D"JIFFIES=$(JIFFIES)" \
+	-D"DATAOFFSET=$(if $(dataoffset-y),$(dataoffset-y),0)"
+
+ifdef CONFIG_MAPPED_KERNEL
+KBUILD_CFLAGS += -D"LOADADDR=$(load-y)" $(PHYS_LOAD_ADDRESS)
+endif
+
+head-y := arch/mips/kernel/head.o arch/mips/kernel/init_task.o
 
 libs-y			+= arch/mips/lib/
 
diff --git a/arch/mips/include/asm/Kbuild b/arch/mips/include/asm/Kbuild
index 9b54b7a..0e39d87 100644
--- a/arch/mips/include/asm/Kbuild
+++ b/arch/mips/include/asm/Kbuild
@@ -1,2 +1,7 @@
 # MIPS headers
 generic-y += trace_clock.h
+include include/asm-generic/Kbuild.asm
+
+header-y += cachectl.h
+header-y += sgidefs.h
+header-y += sysmips.h
diff --git a/arch/mips/include/asm/addrspace.h b/arch/mips/include/asm/addrspace.h
index 13d61c0..7cf85bd 100644
--- a/arch/mips/include/asm/addrspace.h
+++ b/arch/mips/include/asm/addrspace.h
@@ -51,14 +51,14 @@
  * Returns the physical address of a CKSEGx / XKPHYS address
  */
 #define CPHYSADDR(a)		((_ACAST32_(a)) & 0x1fffffff)
-#define XPHYSADDR(a)		((_ACAST64_(a)) &			\
+#define XPHYSADDR(a)            ((_ACAST64_(a)) &			\
 				 _CONST64_(0x000000ffffffffff))
 
 #ifdef CONFIG_64BIT
 
 /*
  * Memory segments (64bit kernel mode addresses)
- * The compatibility segments use the full 64-bit sign extended value.	Note
+ * The compatibility segments use the full 64-bit sign extended value.  Note
  * the R8000 doesn't have them so don't reference these in generic MIPS code.
  */
 #define XKUSEG			_CONST64_(0x0000000000000000)
@@ -131,10 +131,14 @@
 
 /*
  * The ultimate limited of the 64-bit MIPS architecture:  2 bits for selecting
- * the region, 3 bits for the CCA mode.	 This leaves 59 bits of which the
+ * the region, 3 bits for the CCA mode.  This leaves 59 bits of which the
  * R8000 implements most with its 48-bit physical address space.
  */
+#if defined(CONFIG_CPU_XLR) || defined(CONFIG_CPU_XLP)
+#define TO_PHYS_MASK	_CONST64_(0x000000ffffffffff)	/* 2^^40 - 1 */
+#else
 #define TO_PHYS_MASK	_CONST64_(0x07ffffffffffffff)	/* 2^^59 - 1 */
+#endif
 
 #ifndef CONFIG_CPU_R8000
 
diff --git a/arch/mips/include/asm/atomic.h b/arch/mips/include/asm/atomic.h
index 08b6079..c387c16 100644
--- a/arch/mips/include/asm/atomic.h
+++ b/arch/mips/include/asm/atomic.h
@@ -1,5 +1,5 @@
 /*
- * Atomic operations that C can't guarantee us.	 Useful for
+ * Atomic operations that C can't guarantee us.  Useful for
  * resource counting etc..
  *
  * But use these as seldom as possible since they are much more slower
@@ -21,7 +21,7 @@
 #include <asm/cmpxchg.h>
 #include <asm/war.h>
 
-#define ATOMIC_INIT(i)	  { (i) }
+#define ATOMIC_INIT(i)    { (i) }
 
 /*
  * atomic_read - read atomic variable
@@ -49,6 +49,9 @@
  */
 static __inline__ void atomic_add(int i, atomic_t * v)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	ldadd_w_no_read(i, &v->counter);
+#else
 	if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
@@ -59,8 +62,8 @@ static __inline__ void atomic_add(int i, atomic_t * v)
 		"	sc	%0, %1					\n"
 		"	beqzl	%0, 1b					\n"
 		"	.set	mips0					\n"
-		: "=&r" (temp), "+m" (v->counter)
-		: "Ir" (i));
+		: "=&r" (temp), "=m" (v->counter)
+		: "Ir" (i), "m" (v->counter));
 	} else if (kernel_uses_llsc) {
 		int temp;
 
@@ -71,8 +74,8 @@ static __inline__ void atomic_add(int i, atomic_t * v)
 			"	addu	%0, %2				\n"
 			"	sc	%0, %1				\n"
 			"	.set	mips0				\n"
-			: "=&r" (temp), "+m" (v->counter)
-			: "Ir" (i));
+			: "=&r" (temp), "=m" (v->counter)
+			: "Ir" (i), "m" (v->counter));
 		} while (unlikely(!temp));
 	} else {
 		unsigned long flags;
@@ -81,6 +84,7 @@ static __inline__ void atomic_add(int i, atomic_t * v)
 		v->counter += i;
 		raw_local_irq_restore(flags);
 	}
+#endif
 }
 
 /*
@@ -92,6 +96,9 @@ static __inline__ void atomic_add(int i, atomic_t * v)
  */
 static __inline__ void atomic_sub(int i, atomic_t * v)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	ldadd_w_no_read(-i,&v->counter);
+#else
 	if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
@@ -102,8 +109,8 @@ static __inline__ void atomic_sub(int i, atomic_t * v)
 		"	sc	%0, %1					\n"
 		"	beqzl	%0, 1b					\n"
 		"	.set	mips0					\n"
-		: "=&r" (temp), "+m" (v->counter)
-		: "Ir" (i));
+		: "=&r" (temp), "=m" (v->counter)
+		: "Ir" (i), "m" (v->counter));
 	} else if (kernel_uses_llsc) {
 		int temp;
 
@@ -114,8 +121,8 @@ static __inline__ void atomic_sub(int i, atomic_t * v)
 			"	subu	%0, %2				\n"
 			"	sc	%0, %1				\n"
 			"	.set	mips0				\n"
-			: "=&r" (temp), "+m" (v->counter)
-			: "Ir" (i));
+			: "=&r" (temp), "=m" (v->counter)
+			: "Ir" (i), "m" (v->counter));
 		} while (unlikely(!temp));
 	} else {
 		unsigned long flags;
@@ -124,6 +131,7 @@ static __inline__ void atomic_sub(int i, atomic_t * v)
 		v->counter -= i;
 		raw_local_irq_restore(flags);
 	}
+#endif
 }
 
 /*
@@ -135,6 +143,10 @@ static __inline__ int atomic_add_return(int i, atomic_t * v)
 
 	smp_mb__before_llsc();
 
+#ifdef CONFIG_RMI_PHOENIX
+	result = ldadd_w(i, &v->counter);
+	result += i;
+#else
 	if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
@@ -146,8 +158,9 @@ static __inline__ int atomic_add_return(int i, atomic_t * v)
 		"	beqzl	%0, 1b					\n"
 		"	addu	%0, %1, %3				\n"
 		"	.set	mips0					\n"
-		: "=&r" (result), "=&r" (temp), "+m" (v->counter)
-		: "Ir" (i));
+		: "=&r" (result), "=&r" (temp), "=m" (v->counter)
+		: "Ir" (i), "m" (v->counter)
+		: "memory");
 	} else if (kernel_uses_llsc) {
 		int temp;
 
@@ -158,8 +171,9 @@ static __inline__ int atomic_add_return(int i, atomic_t * v)
 			"	addu	%0, %1, %3			\n"
 			"	sc	%0, %2				\n"
 			"	.set	mips0				\n"
-			: "=&r" (result), "=&r" (temp), "+m" (v->counter)
-			: "Ir" (i));
+			: "=&r" (result), "=&r" (temp), "=m" (v->counter)
+			: "Ir" (i), "m" (v->counter)
+			: "memory");
 		} while (unlikely(!result));
 
 		result = temp + i;
@@ -172,6 +186,7 @@ static __inline__ int atomic_add_return(int i, atomic_t * v)
 		v->counter = result;
 		raw_local_irq_restore(flags);
 	}
+#endif
 
 	smp_llsc_mb();
 
@@ -184,6 +199,10 @@ static __inline__ int atomic_sub_return(int i, atomic_t * v)
 
 	smp_mb__before_llsc();
 
+#ifdef CONFIG_RMI_PHOENIX
+	result = ldadd_w(-i, &v->counter);
+	result -= i;
+#else
 	if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
@@ -210,8 +229,9 @@ static __inline__ int atomic_sub_return(int i, atomic_t * v)
 			"	subu	%0, %1, %3			\n"
 			"	sc	%0, %2				\n"
 			"	.set	mips0				\n"
-			: "=&r" (result), "=&r" (temp), "+m" (v->counter)
-			: "Ir" (i));
+			: "=&r" (result), "=&r" (temp), "=m" (v->counter)
+			: "Ir" (i), "m" (v->counter)
+			: "memory");
 		} while (unlikely(!result));
 
 		result = temp - i;
@@ -224,6 +244,7 @@ static __inline__ int atomic_sub_return(int i, atomic_t * v)
 		v->counter = result;
 		raw_local_irq_restore(flags);
 	}
+#endif
 
 	smp_llsc_mb();
 
@@ -259,7 +280,7 @@ static __inline__ int atomic_sub_if_positive(int i, atomic_t * v)
 		"	.set	reorder					\n"
 		"1:							\n"
 		"	.set	mips0					\n"
-		: "=&r" (result), "=&r" (temp), "+m" (v->counter)
+		: "=&r" (result), "=&r" (temp), "=m" (v->counter)
 		: "Ir" (i), "m" (v->counter)
 		: "memory");
 	} else if (kernel_uses_llsc) {
@@ -277,8 +298,9 @@ static __inline__ int atomic_sub_if_positive(int i, atomic_t * v)
 		"	.set	reorder					\n"
 		"1:							\n"
 		"	.set	mips0					\n"
-		: "=&r" (result), "=&r" (temp), "+m" (v->counter)
-		: "Ir" (i));
+		: "=&r" (result), "=&r" (temp), "=m" (v->counter)
+		: "Ir" (i), "m" (v->counter)
+		: "memory");
 	} else {
 		unsigned long flags;
 
@@ -426,8 +448,8 @@ static __inline__ void atomic64_add(long i, atomic64_t * v)
 		"	scd	%0, %1					\n"
 		"	beqzl	%0, 1b					\n"
 		"	.set	mips0					\n"
-		: "=&r" (temp), "+m" (v->counter)
-		: "Ir" (i));
+		: "=&r" (temp), "=m" (v->counter)
+		: "Ir" (i), "m" (v->counter));
 	} else if (kernel_uses_llsc) {
 		long temp;
 
@@ -438,8 +460,8 @@ static __inline__ void atomic64_add(long i, atomic64_t * v)
 			"	daddu	%0, %2				\n"
 			"	scd	%0, %1				\n"
 			"	.set	mips0				\n"
-			: "=&r" (temp), "+m" (v->counter)
-			: "Ir" (i));
+			: "=&r" (temp), "=m" (v->counter)
+			: "Ir" (i), "m" (v->counter));
 		} while (unlikely(!temp));
 	} else {
 		unsigned long flags;
@@ -469,8 +491,8 @@ static __inline__ void atomic64_sub(long i, atomic64_t * v)
 		"	scd	%0, %1					\n"
 		"	beqzl	%0, 1b					\n"
 		"	.set	mips0					\n"
-		: "=&r" (temp), "+m" (v->counter)
-		: "Ir" (i));
+		: "=&r" (temp), "=m" (v->counter)
+		: "Ir" (i), "m" (v->counter));
 	} else if (kernel_uses_llsc) {
 		long temp;
 
@@ -481,8 +503,8 @@ static __inline__ void atomic64_sub(long i, atomic64_t * v)
 			"	dsubu	%0, %2				\n"
 			"	scd	%0, %1				\n"
 			"	.set	mips0				\n"
-			: "=&r" (temp), "+m" (v->counter)
-			: "Ir" (i));
+			: "=&r" (temp), "=m" (v->counter)
+			: "Ir" (i), "m" (v->counter));
 		} while (unlikely(!temp));
 	} else {
 		unsigned long flags;
@@ -513,8 +535,9 @@ static __inline__ long atomic64_add_return(long i, atomic64_t * v)
 		"	beqzl	%0, 1b					\n"
 		"	daddu	%0, %1, %3				\n"
 		"	.set	mips0					\n"
-		: "=&r" (result), "=&r" (temp), "+m" (v->counter)
-		: "Ir" (i));
+		: "=&r" (result), "=&r" (temp), "=m" (v->counter)
+		: "Ir" (i), "m" (v->counter)
+		: "memory");
 	} else if (kernel_uses_llsc) {
 		long temp;
 
@@ -644,8 +667,9 @@ static __inline__ long atomic64_sub_if_positive(long i, atomic64_t * v)
 		"	.set	reorder					\n"
 		"1:							\n"
 		"	.set	mips0					\n"
-		: "=&r" (result), "=&r" (temp), "+m" (v->counter)
-		: "Ir" (i));
+		: "=&r" (result), "=&r" (temp), "=m" (v->counter)
+		: "Ir" (i), "m" (v->counter)
+		: "memory");
 	} else {
 		unsigned long flags;
 
diff --git a/arch/mips/include/asm/auxvec.h b/arch/mips/include/asm/auxvec.h
new file mode 100644
index 0000000..7cf7f2d
--- /dev/null
+++ b/arch/mips/include/asm/auxvec.h
@@ -0,0 +1,4 @@
+#ifndef _ASM_AUXVEC_H
+#define _ASM_AUXVEC_H
+
+#endif /* _ASM_AUXVEC_H */
diff --git a/arch/mips/include/asm/barrier.h b/arch/mips/include/asm/barrier.h
index 314ab55..a230cde 100644
--- a/arch/mips/include/asm/barrier.h
+++ b/arch/mips/include/asm/barrier.h
@@ -18,7 +18,7 @@
  * over this barrier.  All reads preceding this primitive are guaranteed
  * to access memory (but not necessarily other CPUs' caches) before any
  * reads following this primitive that depend on the data return by
- * any of the preceding reads.	This primitive is much lighter weight than
+ * any of the preceding reads.  This primitive is much lighter weight than
  * rmb() on most CPUs, and is never heavier weight than is
  * rmb().
  *
@@ -43,7 +43,7 @@
  * </programlisting>
  *
  * because the read of "*q" depends on the read of "p" and these
- * two reads are separated by a read_barrier_depends().	 However,
+ * two reads are separated by a read_barrier_depends().  However,
  * the following code, with the same initial values for "a" and "b":
  *
  * <programlisting>
@@ -57,7 +57,7 @@
  * </programlisting>
  *
  * does not enforce ordering, since there is no data dependency between
- * the read of "a" and the read of "b".	 Therefore, on some CPUs, such
+ * the read of "a" and the read of "b".  Therefore, on some CPUs, such
  * as Alpha, "y" could be set to 3 and "x" to 0.  Use rmb()
  * in cases like this where there are no data dependencies.
  */
@@ -92,7 +92,7 @@
 		: "memory")
 #ifdef CONFIG_CPU_CAVIUM_OCTEON
 # define OCTEON_SYNCW_STR	".set push\n.set arch=octeon\nsyncw\nsyncw\n.set pop\n"
-# define __syncw()	__asm__ __volatile__(OCTEON_SYNCW_STR : : : "memory")
+# define __syncw() 	__asm__ __volatile__(OCTEON_SYNCW_STR : : : "memory")
 
 # define fast_wmb()	__syncw()
 # define fast_rmb()	barrier()
@@ -158,7 +158,7 @@
 #endif
 
 #if defined(CONFIG_WEAK_REORDERING_BEYOND_LLSC) && defined(CONFIG_SMP)
-#define __WEAK_LLSC_MB		"	sync	\n"
+#define __WEAK_LLSC_MB		"       sync	\n"
 #else
 #define __WEAK_LLSC_MB		"		\n"
 #endif
@@ -180,4 +180,10 @@
 #define nudge_writes() mb()
 #endif
 
+/*
+ * MIPS does not have any instruction to serialize instruction execution on the
+ * core.
+ */
+#define sync_core()
+
 #endif /* __ASM_BARRIER_H */
diff --git a/arch/mips/include/asm/bitops.h b/arch/mips/include/asm/bitops.h
index 71305a8..7809d66 100644
--- a/arch/mips/include/asm/bitops.h
+++ b/arch/mips/include/asm/bitops.h
@@ -564,6 +564,14 @@ static inline unsigned long __ffs(unsigned long word)
 static inline int fls(int x)
 {
 	int r;
+#if defined(CONFIG_CPU_XLP)
+	__asm__("       .set push                       \n"
+		"       .set mips32                     \n"
+		"       clz %0, %1                      \n"
+		"       .set pop                        \n"
+		: "=r" (x) : "r" (x));
+	return 32 - x;
+#endif
 
 	if (__builtin_constant_p(cpu_has_clo_clz) && cpu_has_clo_clz) {
 		__asm__("clz %0, %1" : "=r" (x) : "r" (x));
@@ -597,7 +605,19 @@ static inline int fls(int x)
 	return r;
 }
 
+#if defined(CONFIG_64BIT) && defined(CONFIG_CPU_XLP)
+static __always_inline int fls64(__u64 word)
+{
+	__asm__("       .set push               \n"
+		"       .set mips64             \n"
+		"       dclz %0, %1             \n"
+		"       .set pop                \n"
+		: "=r" (word) : "r" (word));
+	return 64 - word;
+}
+#else
 #include <asm-generic/bitops/fls64.h>
+#endif
 
 /*
  * ffs - find first bit set.
@@ -631,3 +651,4 @@ static inline int ffs(int word)
 #endif /* __KERNEL__ */
 
 #endif /* _ASM_BITOPS_H */
+
diff --git a/arch/mips/include/asm/bitsperlong.h b/arch/mips/include/asm/bitsperlong.h
new file mode 100644
index 0000000..3e4c10a
--- /dev/null
+++ b/arch/mips/include/asm/bitsperlong.h
@@ -0,0 +1,8 @@
+#ifndef __ASM_MIPS_BITSPERLONG_H
+#define __ASM_MIPS_BITSPERLONG_H
+
+#define __BITS_PER_LONG _MIPS_SZLONG
+
+#include <asm-generic/bitsperlong.h>
+
+#endif /* __ASM_MIPS_BITSPERLONG_H */
diff --git a/arch/mips/include/asm/bootinfo.h b/arch/mips/include/asm/bootinfo.h
index 4d2cdea..5f35b7f 100644
--- a/arch/mips/include/asm/bootinfo.h
+++ b/arch/mips/include/asm/bootinfo.h
@@ -1,3 +1,14 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file COPYING in the main directory of this archive
@@ -44,19 +55,22 @@
 /*
  * Valid machtype for group PMC-MSP
  */
-#define MACH_MSP4200_EVAL	0	/* PMC-Sierra MSP4200 Evaluation */
-#define MACH_MSP4200_GW		1	/* PMC-Sierra MSP4200 Gateway demo */
-#define MACH_MSP4200_FPGA	2	/* PMC-Sierra MSP4200 Emulation */
-#define MACH_MSP7120_EVAL	3	/* PMC-Sierra MSP7120 Evaluation */
-#define MACH_MSP7120_GW		4	/* PMC-Sierra MSP7120 Residential GW */
-#define MACH_MSP7120_FPGA	5	/* PMC-Sierra MSP7120 Emulation */
-#define MACH_MSP_OTHER	      255	/* PMC-Sierra unknown board type */
+#define MACH_MSP4200_EVAL       0	/* PMC-Sierra MSP4200 Evaluation */
+#define MACH_MSP4200_GW         1	/* PMC-Sierra MSP4200 Gateway demo */
+#define MACH_MSP4200_FPGA       2	/* PMC-Sierra MSP4200 Emulation */
+#define MACH_MSP7120_EVAL       3	/* PMC-Sierra MSP7120 Evaluation */
+#define MACH_MSP7120_GW         4	/* PMC-Sierra MSP7120 Residential GW */
+#define MACH_MSP7120_FPGA       5	/* PMC-Sierra MSP7120 Emulation */
+#define MACH_MSP_OTHER        255	/* PMC-Sierra unknown board type */
 
 /*
  * Valid machtype for group Mikrotik
  */
-#define MACH_MIKROTIK_RB532	0	/* Mikrotik RouterBoard 532	*/
-#define MACH_MIKROTIK_RB532A	1	/* Mikrotik RouterBoard 532A	*/
+#define	MACH_MIKROTIK_RB532	0	/* Mikrotik RouterBoard 532 	*/
+#define MACH_MIKROTIK_RB532A	1	/* Mikrotik RouterBoard 532A 	*/
+
+#define MACH_GROUP_RMI         23
+#define MACH_PTR                0
 
 /*
  * Valid machtype for Loongson family
@@ -67,7 +81,7 @@
 #define MACH_LEMOTE_ML2F7      3
 #define MACH_LEMOTE_YL2F89     4
 #define MACH_DEXXON_GDIUM2F10  5
-#define MACH_LEMOTE_NAS	       6
+#define MACH_LEMOTE_NAS        6
 #define MACH_LEMOTE_LL2F       7
 #define MACH_LOONGSON_END      8
 
@@ -77,6 +91,12 @@
 #define  MACH_INGENIC_JZ4730	0	/* JZ4730 SOC		*/
 #define  MACH_INGENIC_JZ4740	1	/* JZ4740 SOC		*/
 
+#ifdef CONFIG_RMI_PHOENIX
+#define CL_SIZE			(2048)
+#else
+#define CL_SIZE			COMMAND_LINE_SIZE
+#endif
+
 extern char *system_type;
 const char *get_system_type(void);
 
@@ -95,16 +115,15 @@ extern unsigned long mips_machtype;
 struct boot_mem_map {
 	int nr_map;
 	struct boot_mem_map_entry {
-		phys_t addr;	/* start of memory segment */
-		phys_t size;	/* size of memory segment */
-		long type;		/* type of memory segment */
+		uint64_t addr;	/* start of memory segment */
+		uint64_t size;	/* size of memory segment */
+		uint32_t type;		/* type of memory segment */
 	} map[BOOT_MEM_MAP_MAX];
 };
 
 extern struct boot_mem_map boot_mem_map;
 
-extern void add_memory_region(phys_t start, phys_t size, long type);
-extern void detect_memory_region(phys_t start, phys_t sz_min,  phys_t sz_max);
+extern void add_memory_region(uint64_t start, uint64_t size, long type);
 
 extern void prom_init(void);
 extern void prom_free_prom_memory(void);
@@ -139,4 +158,10 @@ static inline void plat_swiotlb_setup(void) {}
 
 #endif /* CONFIG_SWIOTLB */
 
+#define MAX_EXCLUDE 16
+struct boot_mem_map_exclude_region {
+	uint64_t start;
+	uint64_t end;
+};
+
 #endif /* _ASM_BOOTINFO_H */
diff --git a/arch/mips/include/asm/break.h b/arch/mips/include/asm/break.h
index 0ef1142..9161e68 100644
--- a/arch/mips/include/asm/break.h
+++ b/arch/mips/include/asm/break.h
@@ -9,14 +9,25 @@
 #ifndef __ASM_BREAK_H
 #define __ASM_BREAK_H
 
-#ifdef __UAPI_ASM_BREAK_H
-#error "Error: Do not directly include <uapi/asm/break.h>"
-#endif
-#include <uapi/asm/break.h>
-
 /*
- * Break codes used internally to the kernel.
+ * The following break codes are or were in use for specific purposes in
+ * other MIPS operating systems.  Linux/MIPS doesn't use all of them.  The
+ * unused ones are here as placeholders; we might encounter them in
+ * non-Linux/MIPS object files or make use of them in the future.
  */
+#define BRK_USERBP	0	/* User bp (used by debuggers) */
+#define BRK_KERNELBP	1	/* Break in the kernel */
+#define BRK_ABORT	2	/* Sometimes used by abort(3) to SIGIOT */
+#define BRK_BD_TAKEN	3	/* For bd slot emulation - not implemented */
+#define BRK_BD_NOTTAKEN	4	/* For bd slot emulation - not implemented */
+#define BRK_SSTEPBP	5	/* User bp (used by debuggers) */
+#define BRK_OVERFLOW	6	/* Overflow check */
+#define BRK_DIVZERO	7	/* Divide by zero check */
+#define BRK_RANGE	8	/* Range error check */
+#define BRK_STACKOVERFLOW 9	/* For Ada stackchecking */
+#define BRK_NORLD	10	/* No rld found - not used by Linux/MIPS */
+#define _BRK_THREADBP	11	/* For threads, user bp (used by debuggers) */
+#define BRK_BUG		512	/* Used by BUG() */
 #define BRK_KDB		513	/* Used in KDB_ENTER() */
 #define BRK_MEMU	514	/* Used by FPU emulator */
 #define BRK_KPROBE_BP	515	/* Kprobe break */
diff --git a/arch/mips/include/asm/byteorder.h b/arch/mips/include/asm/byteorder.h
new file mode 100644
index 0000000..9579051
--- /dev/null
+++ b/arch/mips/include/asm/byteorder.h
@@ -0,0 +1,19 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1996, 99, 2003 by Ralf Baechle
+ */
+#ifndef _ASM_BYTEORDER_H
+#define _ASM_BYTEORDER_H
+
+#if defined(__MIPSEB__)
+#include <linux/byteorder/big_endian.h>
+#elif defined(__MIPSEL__)
+#include <linux/byteorder/little_endian.h>
+#else
+# error "MIPS, but neither __MIPSEB__, nor __MIPSEL__???"
+#endif
+
+#endif /* _ASM_BYTEORDER_H */
diff --git a/arch/mips/include/asm/cachectl.h b/arch/mips/include/asm/cachectl.h
new file mode 100644
index 0000000..f3ce721
--- /dev/null
+++ b/arch/mips/include/asm/cachectl.h
@@ -0,0 +1,26 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1994, 1995, 1996 by Ralf Baechle
+ */
+#ifndef	_ASM_CACHECTL
+#define	_ASM_CACHECTL
+
+/*
+ * Options for cacheflush system call
+ */
+#define	ICACHE	(1<<0)		/* flush instruction cache        */
+#define	DCACHE	(1<<1)		/* writeback and flush data cache */
+#define	BCACHE	(ICACHE|DCACHE)	/* flush both caches              */
+
+/*
+ * Caching modes for the cachectl(2) call
+ *
+ * cachectl(2) is currently not supported and returns ENOSYS.
+ */
+#define CACHEABLE	0	/* make pages cacheable */
+#define UNCACHEABLE	1	/* make pages uncacheable */
+
+#endif	/* _ASM_CACHECTL */
diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
index 69468de..541b6f5 100644
--- a/arch/mips/include/asm/cacheflush.h
+++ b/arch/mips/include/asm/cacheflush.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -41,9 +53,13 @@ extern void __flush_dcache_page(struct page *page);
 #define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1
 static inline void flush_dcache_page(struct page *page)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	extern void phoenix_flush_dcache_page(struct page *page);
+	phoenix_flush_dcache_page(page);
+#else
 	if (cpu_has_dc_aliases || !cpu_has_ic_fills_f_dc)
 		__flush_dcache_page(page);
-
+#endif
 }
 
 #define flush_dcache_mmap_lock(mapping)		do { } while (0)
@@ -107,6 +123,10 @@ extern void (*flush_data_cache_page)(unsigned long addr);
 	set_bit(PG_dcache_dirty, &(page)->flags)
 #define ClearPageDcacheDirty(page)	\
 	clear_bit(PG_dcache_dirty, &(page)->flags)
+#ifdef CONFIG_RMI_PHOENIX
+#define TestPageDcacheDirty(page)	\
+	test_bit(PG_dcache_dirty, &(page)->flags)
+#endif
 
 /* Run kernel code uncached, useful for cache probing functions. */
 unsigned long run_uncached(void *func);
diff --git a/arch/mips/include/asm/cmpxchg.h b/arch/mips/include/asm/cmpxchg.h
index 466069b..285a41f 100644
--- a/arch/mips/include/asm/cmpxchg.h
+++ b/arch/mips/include/asm/cmpxchg.h
@@ -8,7 +8,6 @@
 #ifndef __ASM_CMPXCHG_H
 #define __ASM_CMPXCHG_H
 
-#include <linux/bug.h>
 #include <linux/irqflags.h>
 #include <asm/war.h>
 
@@ -146,7 +145,7 @@ static inline unsigned long __xchg(unsigned long x, volatile void * ptr, int siz
 		"	.set	push				\n"	\
 		"	.set	noat				\n"	\
 		"	.set	mips3				\n"	\
-		"1:	" ld "	%0, %2		# __cmpxchg_asm \n"	\
+		"1:	" ld "	%0, %2		# __cmpxchg_asm	\n"	\
 		"	bne	%0, %z3, 2f			\n"	\
 		"	.set	mips0				\n"	\
 		"	move	$1, %z4				\n"	\
@@ -163,7 +162,7 @@ static inline unsigned long __xchg(unsigned long x, volatile void * ptr, int siz
 		"	.set	push				\n"	\
 		"	.set	noat				\n"	\
 		"	.set	mips3				\n"	\
-		"1:	" ld "	%0, %2		# __cmpxchg_asm \n"	\
+		"1:	" ld "	%0, %2		# __cmpxchg_asm	\n"	\
 		"	bne	%0, %z3, 2f			\n"	\
 		"	.set	mips0				\n"	\
 		"	move	$1, %z4				\n"	\
@@ -205,7 +204,7 @@ extern void __cmpxchg_called_with_bad_pointer(void);
 									\
 	switch (sizeof(*(__ptr))) {					\
 	case 4:								\
-		__res = __cmpxchg_asm("ll", "sc", __ptr, __old, __new); \
+		__res = __cmpxchg_asm("ll", "sc", __ptr, __old, __new);	\
 		break;							\
 	case 8:								\
 		if (sizeof(long) == 8) {				\
diff --git a/arch/mips/include/asm/cpu-features.h b/arch/mips/include/asm/cpu-features.h
index e5ec8fc..7713dce 100644
--- a/arch/mips/include/asm/cpu-features.h
+++ b/arch/mips/include/asm/cpu-features.h
@@ -41,6 +41,11 @@
 #ifndef cpu_has_octeon_cache
 #define cpu_has_octeon_cache	0
 #endif
+#ifdef CONFIG_NLM_XLP
+#ifndef cpu_has_nlm_cache
+#define cpu_has_nlm_cache  (cpu_data[0].options & MIPS_CPU_NLM_CACHE)
+#endif
+#endif
 #ifndef cpu_has_fpu
 #define cpu_has_fpu		(current_cpu_data.options & MIPS_CPU_FPU)
 #define raw_cpu_has_fpu		(raw_current_cpu_data.options & MIPS_CPU_FPU)
@@ -95,6 +100,9 @@
 #ifndef cpu_has_smartmips
 #define cpu_has_smartmips      (cpu_data[0].ases & MIPS_ASE_SMARTMIPS)
 #endif
+#ifndef kernel_uses_smartmips_rixi
+#define kernel_uses_smartmips_rixi 0
+#endif
 #ifndef cpu_has_rixi
 #define cpu_has_rixi		(cpu_data[0].options & MIPS_CPU_RIXI)
 #endif
diff --git a/arch/mips/include/asm/cpu.h b/arch/mips/include/asm/cpu.h
index 05993b7..8a3d5dd 100644
--- a/arch/mips/include/asm/cpu.h
+++ b/arch/mips/include/asm/cpu.h
@@ -34,6 +34,7 @@
 #define PRID_COMP_LSI		0x080000
 #define PRID_COMP_LEXRA		0x0b0000
 #define PRID_COMP_NETLOGIC	0x0c0000
+#define PRID_COMP_NLM		0x0c0000
 #define PRID_COMP_CAVIUM	0x0d0000
 #define PRID_COMP_INGENIC	0xd00000
 
@@ -326,6 +327,7 @@ enum cpu_type_enum {
 #define MIPS_CPU_PCI		0x00400000 /* CPU has Perf Ctr Int indicator */
 #define MIPS_CPU_RIXI		0x00800000 /* CPU has TLB Read/eXec Inhibit */
 #define MIPS_CPU_MICROMIPS	0x01000000 /* CPU has microMIPS capability */
+#define MIPS_CPU_NLM_CACHE	0x00400000 
 
 /*
  * CPU ASE encodings
diff --git a/arch/mips/include/asm/dma.h b/arch/mips/include/asm/dma.h
index 5b9ed1b..f482a6a 100644
--- a/arch/mips/include/asm/dma.h
+++ b/arch/mips/include/asm/dma.h
@@ -47,21 +47,21 @@
  *
  *  Address mapping for channels 0-3:
  *
- *   A23 ... A16 A15 ... A8  A7 ... A0	  (Physical addresses)
- *    |	 ...  |	  |  ... |   |	... |
- *    |	 ...  |	  |  ... |   |	... |
- *    |	 ...  |	  |  ... |   |	... |
- *   P7	 ...  P0  A7 ... A0  A7 ... A0
- * |	Page	| Addr MSB | Addr LSB |	  (DMA registers)
+ *   A23 ... A16 A15 ... A8  A7 ... A0    (Physical addresses)
+ *    |  ...  |   |  ... |   |  ... |
+ *    |  ...  |   |  ... |   |  ... |
+ *    |  ...  |   |  ... |   |  ... |
+ *   P7  ...  P0  A7 ... A0  A7 ... A0
+ * |    Page    | Addr MSB | Addr LSB |   (DMA registers)
  *
  *  Address mapping for channels 5-7:
  *
- *   A23 ... A17 A16 A15 ... A9 A8 A7 ... A1 A0	   (Physical addresses)
- *    |	 ...  |	  \   \	  ... \	 \  \  ... \  \
- *    |	 ...  |	   \   \   ... \  \  \	... \  (not used)
- *    |	 ...  |	    \	\   ... \  \  \	 ... \
- *   P7	 ...  P1 (0) A7 A6  ... A0 A7 A6 ... A0
- * |	  Page	    |  Addr MSB	  |  Addr LSB  |   (DMA registers)
+ *   A23 ... A17 A16 A15 ... A9 A8 A7 ... A1 A0    (Physical addresses)
+ *    |  ...  |   \   \   ... \  \  \  ... \  \
+ *    |  ...  |    \   \   ... \  \  \  ... \  (not used)
+ *    |  ...  |     \   \   ... \  \  \  ... \
+ *   P7  ...  P1 (0) A7 A6  ... A0 A7 A6 ... A0
+ * |      Page      |  Addr MSB   |  Addr LSB  |   (DMA registers)
  *
  * Again, channels 5-7 transfer _physical_ words (16 bits), so addresses
  * and counts _must_ be word-aligned (the lowest address bit is _ignored_ at
@@ -87,8 +87,12 @@
 /* don't care; ISA bus master won't work, ISA slave DMA supports 32bit addr */
 #define MAX_DMA_ADDRESS		PAGE_OFFSET
 #else
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+#define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x80000000)
+#else
 #define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x01000000)
 #endif
+#endif
 #define MAX_DMA_PFN		PFN_DOWN(virt_to_phys((void *)MAX_DMA_ADDRESS))
 
 #ifndef MAX_DMA32_PFN
@@ -102,55 +106,55 @@
 /* DMA controller registers */
 #define DMA1_CMD_REG		0x08	/* command register (w) */
 #define DMA1_STAT_REG		0x08	/* status register (r) */
-#define DMA1_REQ_REG		0x09	/* request register (w) */
+#define DMA1_REQ_REG            0x09    /* request register (w) */
 #define DMA1_MASK_REG		0x0A	/* single-channel mask (w) */
 #define DMA1_MODE_REG		0x0B	/* mode register (w) */
 #define DMA1_CLEAR_FF_REG	0x0C	/* clear pointer flip-flop (w) */
-#define DMA1_TEMP_REG		0x0D	/* Temporary Register (r) */
+#define DMA1_TEMP_REG           0x0D    /* Temporary Register (r) */
 #define DMA1_RESET_REG		0x0D	/* Master Clear (w) */
-#define DMA1_CLR_MASK_REG	0x0E	/* Clear Mask */
-#define DMA1_MASK_ALL_REG	0x0F	/* all-channels mask (w) */
+#define DMA1_CLR_MASK_REG       0x0E    /* Clear Mask */
+#define DMA1_MASK_ALL_REG       0x0F    /* all-channels mask (w) */
 
 #define DMA2_CMD_REG		0xD0	/* command register (w) */
 #define DMA2_STAT_REG		0xD0	/* status register (r) */
-#define DMA2_REQ_REG		0xD2	/* request register (w) */
+#define DMA2_REQ_REG            0xD2    /* request register (w) */
 #define DMA2_MASK_REG		0xD4	/* single-channel mask (w) */
 #define DMA2_MODE_REG		0xD6	/* mode register (w) */
 #define DMA2_CLEAR_FF_REG	0xD8	/* clear pointer flip-flop (w) */
-#define DMA2_TEMP_REG		0xDA	/* Temporary Register (r) */
+#define DMA2_TEMP_REG           0xDA    /* Temporary Register (r) */
 #define DMA2_RESET_REG		0xDA	/* Master Clear (w) */
-#define DMA2_CLR_MASK_REG	0xDC	/* Clear Mask */
-#define DMA2_MASK_ALL_REG	0xDE	/* all-channels mask (w) */
-
-#define DMA_ADDR_0		0x00	/* DMA address registers */
-#define DMA_ADDR_1		0x02
-#define DMA_ADDR_2		0x04
-#define DMA_ADDR_3		0x06
-#define DMA_ADDR_4		0xC0
-#define DMA_ADDR_5		0xC4
-#define DMA_ADDR_6		0xC8
-#define DMA_ADDR_7		0xCC
-
-#define DMA_CNT_0		0x01	/* DMA count registers */
-#define DMA_CNT_1		0x03
-#define DMA_CNT_2		0x05
-#define DMA_CNT_3		0x07
-#define DMA_CNT_4		0xC2
-#define DMA_CNT_5		0xC6
-#define DMA_CNT_6		0xCA
-#define DMA_CNT_7		0xCE
-
-#define DMA_PAGE_0		0x87	/* DMA page registers */
-#define DMA_PAGE_1		0x83
-#define DMA_PAGE_2		0x81
-#define DMA_PAGE_3		0x82
-#define DMA_PAGE_5		0x8B
-#define DMA_PAGE_6		0x89
-#define DMA_PAGE_7		0x8A
+#define DMA2_CLR_MASK_REG       0xDC    /* Clear Mask */
+#define DMA2_MASK_ALL_REG       0xDE    /* all-channels mask (w) */
+
+#define DMA_ADDR_0              0x00    /* DMA address registers */
+#define DMA_ADDR_1              0x02
+#define DMA_ADDR_2              0x04
+#define DMA_ADDR_3              0x06
+#define DMA_ADDR_4              0xC0
+#define DMA_ADDR_5              0xC4
+#define DMA_ADDR_6              0xC8
+#define DMA_ADDR_7              0xCC
+
+#define DMA_CNT_0               0x01    /* DMA count registers */
+#define DMA_CNT_1               0x03
+#define DMA_CNT_2               0x05
+#define DMA_CNT_3               0x07
+#define DMA_CNT_4               0xC2
+#define DMA_CNT_5               0xC6
+#define DMA_CNT_6               0xCA
+#define DMA_CNT_7               0xCE
+
+#define DMA_PAGE_0              0x87    /* DMA page registers */
+#define DMA_PAGE_1              0x83
+#define DMA_PAGE_2              0x81
+#define DMA_PAGE_3              0x82
+#define DMA_PAGE_5              0x8B
+#define DMA_PAGE_6              0x89
+#define DMA_PAGE_7              0x8A
 
 #define DMA_MODE_READ	0x44	/* I/O to memory, no autoinit, increment, single mode */
 #define DMA_MODE_WRITE	0x48	/* memory to I/O, no autoinit, increment, single mode */
-#define DMA_MODE_CASCADE 0xC0	/* pass thru DREQ->HRQ, DACK<-HLDA only */
+#define DMA_MODE_CASCADE 0xC0   /* pass thru DREQ->HRQ, DACK<-HLDA only */
 
 #define DMA_AUTOINIT	0x10
 
@@ -172,7 +176,7 @@ static __inline__ void release_dma_lock(unsigned long flags)
 static __inline__ void enable_dma(unsigned int dmanr)
 {
 	if (dmanr<=3)
-		dma_outb(dmanr,	 DMA1_MASK_REG);
+		dma_outb(dmanr,  DMA1_MASK_REG);
 	else
 		dma_outb(dmanr & 3,  DMA2_MASK_REG);
 }
@@ -204,7 +208,7 @@ static __inline__ void clear_dma_ff(unsigned int dmanr)
 static __inline__ void set_dma_mode(unsigned int dmanr, char mode)
 {
 	if (dmanr<=3)
-		dma_outb(mode | dmanr,	DMA1_MODE_REG);
+		dma_outb(mode | dmanr,  DMA1_MODE_REG);
 	else
 		dma_outb(mode | (dmanr&3),  DMA2_MODE_REG);
 }
@@ -248,10 +252,10 @@ static __inline__ void set_dma_page(unsigned int dmanr, char pagenr)
 static __inline__ void set_dma_addr(unsigned int dmanr, unsigned int a)
 {
 	set_dma_page(dmanr, a>>16);
-	if (dmanr <= 3)	 {
+	if (dmanr <= 3)  {
 	    dma_outb( a & 0xff, ((dmanr&3)<<1) + IO_DMA1_BASE );
-	    dma_outb( (a>>8) & 0xff, ((dmanr&3)<<1) + IO_DMA1_BASE );
-	}  else	 {
+            dma_outb( (a>>8) & 0xff, ((dmanr&3)<<1) + IO_DMA1_BASE );
+	}  else  {
 	    dma_outb( (a>>1) & 0xff, ((dmanr&3)<<2) + IO_DMA2_BASE );
 	    dma_outb( (a>>9) & 0xff, ((dmanr&3)<<2) + IO_DMA2_BASE );
 	}
@@ -268,14 +272,14 @@ static __inline__ void set_dma_addr(unsigned int dmanr, unsigned int a)
  */
 static __inline__ void set_dma_count(unsigned int dmanr, unsigned int count)
 {
-	count--;
-	if (dmanr <= 3)	 {
+        count--;
+	if (dmanr <= 3)  {
 	    dma_outb( count & 0xff, ((dmanr&3)<<1) + 1 + IO_DMA1_BASE );
 	    dma_outb( (count>>8) & 0xff, ((dmanr&3)<<1) + 1 + IO_DMA1_BASE );
-	} else {
+        } else {
 	    dma_outb( (count>>1) & 0xff, ((dmanr&3)<<2) + 2 + IO_DMA2_BASE );
 	    dma_outb( (count>>9) & 0xff, ((dmanr&3)<<2) + 2 + IO_DMA2_BASE );
-	}
+        }
 }
 
 
diff --git a/arch/mips/include/asm/fcntl.h b/arch/mips/include/asm/fcntl.h
new file mode 100644
index 0000000..75edded
--- /dev/null
+++ b/arch/mips/include/asm/fcntl.h
@@ -0,0 +1,77 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1995, 96, 97, 98, 99, 2003, 05 Ralf Baechle
+ */
+#ifndef _ASM_FCNTL_H
+#define _ASM_FCNTL_H
+
+
+#define O_APPEND	0x0008
+#define O_DSYNC		0x0010	/* used to be O_SYNC, see below */
+#define O_NONBLOCK	0x0080
+#define O_CREAT         0x0100	/* not fcntl */
+#define O_TRUNC		0x0200	/* not fcntl */
+#define O_EXCL		0x0400	/* not fcntl */
+#define O_NOCTTY	0x0800	/* not fcntl */
+#define FASYNC		0x1000	/* fcntl, for BSD compatibility */
+#define O_LARGEFILE	0x2000	/* allow large file opens */
+/*
+ * Before Linux 2.6.33 only O_DSYNC semantics were implemented, but using
+ * the O_SYNC flag.  We continue to use the existing numerical value
+ * for O_DSYNC semantics now, but using the correct symbolic name for it.
+ * This new value is used to request true Posix O_SYNC semantics.  It is
+ * defined in this strange way to make sure applications compiled against
+ * new headers get at least O_DSYNC semantics on older kernels.
+ *
+ * This has the nice side-effect that we can simply test for O_DSYNC
+ * wherever we do not care if O_DSYNC or O_SYNC is used.
+ *
+ * Note: __O_SYNC must never be used directly.
+ */
+#define __O_SYNC	0x4000
+#define O_SYNC		(__O_SYNC|O_DSYNC)
+#define O_DIRECT	0x8000	/* direct disk access hint */
+
+#define F_GETLK		14
+#define F_SETLK		6
+#define F_SETLKW	7
+
+#define F_SETOWN	24	/*  for sockets. */
+#define F_GETOWN	23	/*  for sockets. */
+
+#ifndef __mips64
+#define F_GETLK64	33	/*  using 'struct flock64' */
+#define F_SETLK64	34
+#define F_SETLKW64	35
+#endif
+
+/*
+ * The flavours of struct flock.  "struct flock" is the ABI compliant
+ * variant.  Finally struct flock64 is the LFS variant of struct flock.  As
+ * a historic accident and inconsistence with the ABI definition it doesn't
+ * contain all the same fields as struct flock.
+ */
+
+#ifdef CONFIG_32BIT
+#include <linux/types.h>
+
+struct flock {
+	short	l_type;
+	short	l_whence;
+	off_t	l_start;
+	off_t	l_len;
+	long	l_sysid;
+	__kernel_pid_t l_pid;
+	long	pad[4];
+};
+
+#define HAVE_ARCH_STRUCT_FLOCK
+
+#endif /* CONFIG_32BIT */
+
+#include <asm-generic/fcntl.h>
+
+#endif /* _ASM_FCNTL_H */
diff --git a/arch/mips/include/asm/gpio.h b/arch/mips/include/asm/gpio.h
index 06e46fa..7334ae8 100644
--- a/arch/mips/include/asm/gpio.h
+++ b/arch/mips/include/asm/gpio.h
@@ -2,5 +2,6 @@
 #define __ASM_MIPS_GPIO_H
 
 #include <gpio.h>
+#include <asm/netlogic/gpio.h>
 
 #endif /* __ASM_MIPS_GPIO_H */
diff --git a/arch/mips/include/asm/io.h b/arch/mips/include/asm/io.h
index b84e1fb..5f24397 100644
--- a/arch/mips/include/asm/io.h
+++ b/arch/mips/include/asm/io.h
@@ -118,7 +118,7 @@ static inline void set_io_port_base(unsigned long base)
  */
 static inline unsigned long virt_to_phys(volatile const void *address)
 {
-	return __pa(address);
+	return (unsigned long)address - PAGE_OFFSET + PHYS_OFFSET;
 }
 
 /*
diff --git a/arch/mips/include/asm/ioctl.h b/arch/mips/include/asm/ioctl.h
new file mode 100644
index 0000000..c515a1a
--- /dev/null
+++ b/arch/mips/include/asm/ioctl.h
@@ -0,0 +1,27 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1995, 96, 99, 2001 Ralf Baechle <ralf@linux-mips.org>
+ * Copyright (C) 2009 Wind River Systems
+ * Written by Ralf Baechle <ralf@linux-mips.org>
+ */
+#ifndef __ASM_IOCTL_H
+#define __ASM_IOCTL_H
+
+#define _IOC_SIZEBITS	13
+#define _IOC_DIRBITS	3
+
+/*
+ * Direction bits _IOC_NONE could be 0, but OSF/1 gives it a bit.
+ * And this turns out useful to catch old ioctl numbers in header
+ * files for us.
+ */
+#define _IOC_NONE	1U
+#define _IOC_READ	2U
+#define _IOC_WRITE	4U
+
+#include <asm-generic/ioctl.h>
+
+#endif /* __ASM_IOCTL_H */
diff --git a/arch/mips/include/asm/kexec.h b/arch/mips/include/asm/kexec.h
index ee25ebb..4314892 100644
--- a/arch/mips/include/asm/kexec.h
+++ b/arch/mips/include/asm/kexec.h
@@ -9,43 +9,22 @@
 #ifndef _MIPS_KEXEC
 # define _MIPS_KEXEC
 
-#include <asm/stacktrace.h>
-
 /* Maximum physical address we can use pages from */
 #define KEXEC_SOURCE_MEMORY_LIMIT (0x20000000)
 /* Maximum address we can reach in physical address mode */
 #define KEXEC_DESTINATION_MEMORY_LIMIT (0x20000000)
  /* Maximum address we can use for the control code buffer */
 #define KEXEC_CONTROL_MEMORY_LIMIT (0x20000000)
-/* Reserve 3*4096 bytes for board-specific info */
-#define KEXEC_CONTROL_PAGE_SIZE (4096 + 3*4096)
+
+#define KEXEC_CONTROL_PAGE_SIZE 4096
 
 /* The native architecture */
 #define KEXEC_ARCH KEXEC_ARCH_MIPS
-#define MAX_NOTE_BYTES 1024
 
 static inline void crash_setup_regs(struct pt_regs *newregs,
 				    struct pt_regs *oldregs)
 {
-	if (oldregs)
-		memcpy(newregs, oldregs, sizeof(*newregs));
-	else
-		prepare_frametrace(newregs);
+	/* Dummy implementation for now */
 }
 
-#ifdef CONFIG_KEXEC
-struct kimage;
-extern unsigned long kexec_args[4];
-extern int (*_machine_kexec_prepare)(struct kimage *);
-extern void (*_machine_kexec_shutdown)(void);
-extern void (*_machine_crash_shutdown)(struct pt_regs *regs);
-extern void default_machine_crash_shutdown(struct pt_regs *regs);
-#ifdef CONFIG_SMP
-extern const unsigned char kexec_smp_wait[];
-extern unsigned long secondary_kexec_args[4];
-extern void (*relocated_kexec_smp_wait) (void *);
-extern atomic_t kexec_ready_to_reboot;
-#endif
-#endif
-
 #endif /* !_MIPS_KEXEC */
diff --git a/arch/mips/include/asm/linkage.h b/arch/mips/include/asm/linkage.h
index 2767dda..e9a940d 100644
--- a/arch/mips/include/asm/linkage.h
+++ b/arch/mips/include/asm/linkage.h
@@ -6,8 +6,5 @@
 #endif
 
 #define __weak __attribute__((weak))
-#define cond_syscall(x) asm(".weak\t" #x "\n" #x "\t=\tsys_ni_syscall")
-#define SYSCALL_ALIAS(alias, name)					\
-	asm ( #alias " = " #name "\n\t.globl " #alias)
 
 #endif
diff --git a/arch/mips/include/asm/mach-generic/spaces.h b/arch/mips/include/asm/mach-generic/spaces.h
index 5b2f2e6..d9138fd 100644
--- a/arch/mips/include/asm/mach-generic/spaces.h
+++ b/arch/mips/include/asm/mach-generic/spaces.h
@@ -20,8 +20,9 @@
 #endif
 
 #ifdef CONFIG_32BIT
-#ifdef CONFIG_KVM_GUEST
-#define CAC_BASE		_AC(0x40000000, UL)
+
+#if defined(CONFIG_MAPPED_KERNEL) && defined(CONFIG_KSEG2_LOWMEM)
+#define CAC_BASE                _AC(0xc0000000, UL)
 #else
 #define CAC_BASE		_AC(0x80000000, UL)
 #endif
@@ -29,12 +30,8 @@
 #define UNCAC_BASE		_AC(0xa0000000, UL)
 
 #ifndef MAP_BASE
-#ifdef CONFIG_KVM_GUEST
-#define MAP_BASE		_AC(0x60000000, UL)
-#else
 #define MAP_BASE		_AC(0xc0000000, UL)
 #endif
-#endif
 
 /*
  * Memory above this physical address will be considered highmem.
@@ -51,7 +48,11 @@
 #ifdef CONFIG_DMA_NONCOHERENT
 #define CAC_BASE		_AC(0x9800000000000000, UL)
 #else
+#if defined(CONFIG_MAPPED_KERNEL) && defined(CONFIG_KSEG2_LOWMEM)
+#define CAC_BASE		XKSEG
+#else /* CONFIG_MAPPED_KERNEL */
 #define CAC_BASE		_AC(0xa800000000000000, UL)
+#endif /* CONFIG_MAPPED_KERNEL */
 #endif
 #endif
 
@@ -76,7 +77,7 @@
 #define HIGHMEM_START		(_AC(1, UL) << _AC(59, UL))
 #endif
 
-#define TO_PHYS(x)		(	      ((x) & TO_PHYS_MASK))
+#define TO_PHYS(x)		(             ((x) & TO_PHYS_MASK))
 #define TO_CAC(x)		(CAC_BASE   | ((x) & TO_PHYS_MASK))
 #define TO_UNCAC(x)		(UNCAC_BASE | ((x) & TO_PHYS_MASK))
 
diff --git a/arch/mips/include/asm/mach-mipssim/cpu-feature-overrides.h b/arch/mips/include/asm/mach-mipssim/cpu-feature-overrides.h
new file mode 100644
index 0000000..27aaaa5
--- /dev/null
+++ b/arch/mips/include/asm/mach-mipssim/cpu-feature-overrides.h
@@ -0,0 +1,67 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2003, 2004 Chris Dearman
+ */
+#ifndef __ASM_MACH_SIM_CPU_FEATURE_OVERRIDES_H
+#define __ASM_MACH_SIM_CPU_FEATURE_OVERRIDES_H
+
+
+/*
+ * CPU feature overrides for MIPS boards
+ */
+#ifdef CONFIG_CPU_MIPS32
+#define cpu_has_tlb		1
+#define cpu_has_4kex		1
+#define cpu_has_4k_cache	1
+#define cpu_has_fpu		0
+/* #define cpu_has_32fpr	? */
+#define cpu_has_counter		1
+/* #define cpu_has_watch	? */
+#define cpu_has_divec		1
+#define cpu_has_vce		0
+/* #define cpu_has_cache_cdex_p	? */
+/* #define cpu_has_cache_cdex_s	? */
+/* #define cpu_has_prefetch	? */
+#define cpu_has_mcheck		1
+/* #define cpu_has_ejtag	? */
+#define cpu_has_llsc		1
+/* #define cpu_has_vtag_icache	? */
+/* #define cpu_has_dc_aliases	? */
+/* #define cpu_has_ic_fills_f_dc ? */
+#define cpu_has_clo_clz		1
+#define cpu_has_nofpuex		0
+/* #define cpu_has_64bits	? */
+/* #define cpu_has_64bit_zero_reg ? */
+/* #define cpu_has_inclusive_pcaches ? */
+#endif
+
+#ifdef CONFIG_CPU_MIPS64
+#define cpu_has_tlb		1
+#define cpu_has_4kex		1
+#define cpu_has_4k_cache	1
+/* #define cpu_has_fpu		? */
+/* #define cpu_has_32fpr	? */
+#define cpu_has_counter		1
+/* #define cpu_has_watch	? */
+#define cpu_has_divec		1
+#define cpu_has_vce		0
+/* #define cpu_has_cache_cdex_p	? */
+/* #define cpu_has_cache_cdex_s	? */
+/* #define cpu_has_prefetch	? */
+#define cpu_has_mcheck		1
+/* #define cpu_has_ejtag	? */
+#define cpu_has_llsc		1
+/* #define cpu_has_vtag_icache	? */
+/* #define cpu_has_dc_aliases	? */
+/* #define cpu_has_ic_fills_f_dc ? */
+#define cpu_has_clo_clz		1
+#define cpu_has_nofpuex		0
+/* #define cpu_has_64bits	? */
+/* #define cpu_has_64bit_zero_reg ? */
+/* #define cpu_has_inclusive_pcaches ? */
+#endif
+
+#endif /* __ASM_MACH_MIPS_CPU_FEATURE_OVERRIDES_H */
diff --git a/arch/mips/include/asm/mach-mipssim/war.h b/arch/mips/include/asm/mach-mipssim/war.h
new file mode 100644
index 0000000..c8a74a3
--- /dev/null
+++ b/arch/mips/include/asm/mach-mipssim/war.h
@@ -0,0 +1,25 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2002, 2004, 2007 by Ralf Baechle <ralf@linux-mips.org>
+ */
+#ifndef __ASM_MIPS_MACH_MIPSSIM_WAR_H
+#define __ASM_MIPS_MACH_MIPSSIM_WAR_H
+
+#define R4600_V1_INDEX_ICACHEOP_WAR	0
+#define R4600_V1_HIT_CACHEOP_WAR	0
+#define R4600_V2_HIT_CACHEOP_WAR	0
+#define R5432_CP0_INTERRUPT_WAR		0
+#define BCM1250_M3_WAR			0
+#define SIBYTE_1956_WAR			0
+#define MIPS4K_ICACHE_REFILL_WAR	0
+#define MIPS_CACHE_SYNC_WAR		0
+#define TX49XX_ICACHE_INDEX_INV_WAR	0
+#define RM9000_CDEX_SMP_WAR		0
+#define ICACHE_REFILLS_WORKAROUND_WAR	0
+#define R10000_LLSC_WAR			0
+#define MIPS34K_MISSED_ITLB_WAR		0
+
+#endif /* __ASM_MIPS_MACH_MIPSSIM_WAR_H */
diff --git a/arch/mips/include/asm/mach-netlogic/cpu-feature-overrides.h b/arch/mips/include/asm/mach-netlogic/cpu-feature-overrides.h
index 091deb17..ccd1c16 100644
--- a/arch/mips/include/asm/mach-netlogic/cpu-feature-overrides.h
+++ b/arch/mips/include/asm/mach-netlogic/cpu-feature-overrides.h
@@ -9,6 +9,16 @@
 #ifndef __ASM_MACH_NETLOGIC_CPU_FEATURE_OVERRIDES_H
 #define __ASM_MACH_NETLOGIC_CPU_FEATURE_OVERRIDES_H
 
+#ifdef CONFIG_NLM_XLP
+
+#ifdef CONFIG_NLM_RIXI
+#define kernel_uses_smartmips_rixi (cpu_data[0].cputype == CPU_XLP)
+#else
+#define kernel_uses_smartmips_rixi  0
+#endif
+
+#else /* CONFIG_NLM_XLP */
+
 #define cpu_has_4kex		1
 #define cpu_has_4k_cache	1
 #define cpu_has_watch		1
@@ -24,33 +34,25 @@
 
 #define cpu_has_llsc		1
 #define cpu_has_vtag_icache	0
-#define cpu_has_ic_fills_f_dc	1
+#define cpu_has_dc_aliases	0
+#define cpu_has_ic_fills_f_dc	0
 #define cpu_has_dsp		0
-#define cpu_has_dsp2		0
 #define cpu_has_mipsmt		0
-#define cpu_icache_snoops_remote_store	1
+#define cpu_has_userlocal	0
+#define cpu_icache_snoops_remote_store	0
 
+#define cpu_has_nofpuex		0
 #define cpu_has_64bits		1
 
 #define cpu_has_mips32r1	1
+#define cpu_has_mips32r2	0
 #define cpu_has_mips64r1	1
+#define cpu_has_mips64r2	0
 
 #define cpu_has_inclusive_pcaches	0
 
 #define cpu_dcache_line_size()	32
 #define cpu_icache_line_size()	32
 
-#if defined(CONFIG_CPU_XLR)
-#define cpu_has_userlocal	0
-#define cpu_has_dc_aliases	0
-#define cpu_has_mips32r2	0
-#define cpu_has_mips64r2	0
-#elif defined(CONFIG_CPU_XLP)
-#define cpu_has_userlocal	1
-#define cpu_has_mips32r2	1
-#define cpu_has_mips64r2	1
-#else
-#error "Unknown Netlogic CPU"
-#endif
-
+#endif /* CONFIG_NLM_XLP */
 #endif /* __ASM_MACH_NETLOGIC_CPU_FEATURE_OVERRIDES_H */
diff --git a/arch/mips/include/asm/mach-netlogic/irq.h b/arch/mips/include/asm/mach-netlogic/irq.h
index 868ed8a..3199c65 100644
--- a/arch/mips/include/asm/mach-netlogic/irq.h
+++ b/arch/mips/include/asm/mach-netlogic/irq.h
@@ -8,9 +8,9 @@
 #ifndef __ASM_NETLOGIC_IRQ_H
 #define __ASM_NETLOGIC_IRQ_H
 
-#include <asm/mach-netlogic/multi-node.h>
-#define NR_IRQS			(64 * NLM_NR_NODES)
-
+#if !defined(CONFIG_NLM_XLP)
+#define NR_IRQS			64
+#endif
 #define MIPS_CPU_IRQ_BASE	0
 
 #endif /* __ASM_NETLOGIC_IRQ_H */
diff --git a/arch/mips/include/asm/mach-netlogic/war.h b/arch/mips/include/asm/mach-netlogic/war.h
index 2c72168..22da893 100644
--- a/arch/mips/include/asm/mach-netlogic/war.h
+++ b/arch/mips/include/asm/mach-netlogic/war.h
@@ -18,6 +18,7 @@
 #define MIPS4K_ICACHE_REFILL_WAR	0
 #define MIPS_CACHE_SYNC_WAR		0
 #define TX49XX_ICACHE_INDEX_INV_WAR	0
+#define RM9000_CDEX_SMP_WAR		0
 #define ICACHE_REFILLS_WORKAROUND_WAR	0
 #define R10000_LLSC_WAR			0
 #define MIPS34K_MISSED_ITLB_WAR		0
diff --git a/arch/mips/include/asm/mips-boards/prom.h b/arch/mips/include/asm/mips-boards/prom.h
new file mode 100644
index 0000000..a9db576
--- /dev/null
+++ b/arch/mips/include/asm/mips-boards/prom.h
@@ -0,0 +1,47 @@
+/*
+ * Carsten Langgaard, carstenl@mips.com
+ * Copyright (C) 2000 MIPS Technologies, Inc.  All rights reserved.
+ *
+ * ########################################################################
+ *
+ *  This program is free software; you can distribute it and/or modify it
+ *  under the terms of the GNU General Public License (Version 2) as
+ *  published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ *  for more details.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
+ *
+ * ########################################################################
+ *
+ * MIPS boards bootprom interface for the Linux kernel.
+ *
+ */
+
+#ifndef _MIPS_PROM_H
+#define _MIPS_PROM_H
+
+extern char *prom_getcmdline(void);
+extern char *prom_getenv(char *name);
+extern void prom_init_cmdline(void);
+extern void prom_meminit(void);
+extern void prom_fixup_mem_map(unsigned long start_mem, unsigned long end_mem);
+extern void mips_display_message(const char *str);
+extern void mips_display_word(unsigned int num);
+extern void mips_scroll_message(void);
+extern int get_ethernet_addr(char *ethernet_addr);
+
+/* Memory descriptor management. */
+#define PROM_MAX_PMEMBLOCKS    32
+struct prom_pmemblock {
+        unsigned long base; /* Within KSEG0. */
+        unsigned int size;  /* In bytes. */
+        unsigned int type;  /* free or prom memory */
+};
+
+#endif /* !(_MIPS_PROM_H) */
diff --git a/arch/mips/include/asm/mips-boards/sim.h b/arch/mips/include/asm/mips-boards/sim.h
index b112fdc..acb7c23 100644
--- a/arch/mips/include/asm/mips-boards/sim.h
+++ b/arch/mips/include/asm/mips-boards/sim.h
@@ -19,18 +19,18 @@
 #ifndef _ASM_MIPS_BOARDS_SIM_H
 #define _ASM_MIPS_BOARDS_SIM_H
 
-#define STATS_ON	1
-#define STATS_OFF	2
-#define STATS_CLEAR	3
-#define STATS_DUMP	4
+#define STATS_ON        1
+#define STATS_OFF       2
+#define STATS_CLEAR     3
+#define STATS_DUMP      4
 #define TRACE_ON		5
-#define TRACE_OFF	6
+#define TRACE_OFF       6
 
 
 #define simcfg(code)						\
 ({					   \
-	__asm__	 __volatile__( \
-	"sltiu $0,$0, %0" \
+	__asm__  __volatile__( \
+        "sltiu $0,$0, %0" \
 		::"i"(code)					\
 		); \
 })
diff --git a/arch/mips/include/asm/mips-boards/simint.h b/arch/mips/include/asm/mips-boards/simint.h
new file mode 100644
index 0000000..8ef6db7
--- /dev/null
+++ b/arch/mips/include/asm/mips-boards/simint.h
@@ -0,0 +1,31 @@
+/*
+ * Copyright (C) 2005 MIPS Technologies, Inc.  All rights reserved.
+ *
+ *  This program is free software; you can distribute it and/or modify it
+ *  under the terms of the GNU General Public License (Version 2) as
+ *  published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ *  for more details.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
+ */
+#ifndef _MIPS_SIMINT_H
+#define _MIPS_SIMINT_H
+
+#include <irq.h>
+
+#define SIM_INT_BASE		0
+#define MIPSCPU_INT_MB0		2
+#define MIPS_CPU_TIMER_IRQ	7
+
+
+#define MSC01E_INT_BASE		64
+
+#define MSC01E_INT_CPUCTR	11
+
+#endif
diff --git a/arch/mips/include/asm/mips_machine.h b/arch/mips/include/asm/mips_machine.h
index 9d00aeb..363bb35 100644
--- a/arch/mips/include/asm/mips_machine.h
+++ b/arch/mips/include/asm/mips_machine.h
@@ -42,9 +42,13 @@ extern long __mips_machines_end;
 #ifdef CONFIG_MIPS_MACHINE
 int  mips_machtype_setup(char *id) __init;
 void mips_machine_setup(void) __init;
+void mips_set_machine_name(const char *name) __init;
+char *mips_get_machine_name(void);
 #else
 static inline int mips_machtype_setup(char *id) { return 1; }
 static inline void mips_machine_setup(void) { }
+static inline void mips_set_machine_name(const char *name) { }
+static inline char *mips_get_machine_name(void) { return NULL; }
 #endif /* CONFIG_MIPS_MACHINE */
 
 #endif /* __ASM_MIPS_MACHINE_H */
diff --git a/arch/mips/include/asm/mipsregs.h b/arch/mips/include/asm/mipsregs.h
index 87e6207..2ae53b7 100644
--- a/arch/mips/include/asm/mipsregs.h
+++ b/arch/mips/include/asm/mipsregs.h
@@ -1,3 +1,12 @@
+/*-
+ * Copyright 2005-2013 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -16,6 +25,7 @@
 #include <linux/linkage.h>
 #include <asm/hazards.h>
 #include <asm/war.h>
+#include <asm/types.h>
 
 /*
  * The following macros are especially useful for __asm__
@@ -227,21 +237,28 @@
 #error Bad page size configuration!
 #endif
 
+#ifdef CONFIG_HUGETLB_PAGE
 /*
  * Default huge tlb size for a given kernel configuration
  */
-#ifdef CONFIG_PAGE_SIZE_4KB
+#ifdef CONFIG_HUGE_PAGE_SIZE_128K
+#define PM_HUGE_MASK	PM_64K
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512K)
+#define PM_HUGE_MASK	PM_256K
+#elif defined(CONFIG_HUGE_PAGE_SIZE_2M)
 #define PM_HUGE_MASK	PM_1M
-#elif defined(CONFIG_PAGE_SIZE_8KB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_8M)
 #define PM_HUGE_MASK	PM_4M
-#elif defined(CONFIG_PAGE_SIZE_16KB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_32M)
 #define PM_HUGE_MASK	PM_16M
-#elif defined(CONFIG_PAGE_SIZE_32KB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_128M)
 #define PM_HUGE_MASK	PM_64M
-#elif defined(CONFIG_PAGE_SIZE_64KB)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512M)
 #define PM_HUGE_MASK	PM_256M
-#elif defined(CONFIG_MIPS_HUGE_TLB_SUPPORT)
-#error Bad page size configuration for hugetlbfs!
+#else
+#error Bad huge page size configuration!
+#endif
+
 #endif
 
 /*
@@ -1161,6 +1178,21 @@ do {									\
 #define write_c0_brcm_sleepcount(val)	__write_32bit_c0_register($22, 7, val)
 
 /*
+ * xlp2xx pagewalker PW registers
+ */
+#define read_c0_pwbase()	__read_64bit_c0_register($5, 5)
+#define write_c0_pwbase(val)	__write_64bit_c0_register($5, 5, val)
+
+#define read_c0_pwfield()	__read_64bit_c0_register($5, 6)
+#define write_c0_pwfield(val)	__write_64bit_c0_register($5, 6, val)
+
+#define read_c0_pwsize()	__read_64bit_c0_register($5, 7)
+#define write_c0_pwsize(val)	__write_64bit_c0_register($5, 7, val)
+
+#define read_c0_pwctl()	__read_32bit_c0_register($6, 6)
+#define write_c0_pwctl(val)	__write_32bit_c0_register($6, 6, val)
+
+/*
  * Macros to access the floating point coprocessor control registers
  */
 #define read_32bit_cp1_register(source)					\
diff --git a/arch/mips/include/asm/mmu_context.h b/arch/mips/include/asm/mmu_context.h
index 516e6e9..9482ac4 100644
--- a/arch/mips/include/asm/mmu_context.h
+++ b/arch/mips/include/asm/mmu_context.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * Switch a MMU context.
  *
@@ -26,15 +38,10 @@
 
 #ifdef CONFIG_MIPS_PGD_C0_CONTEXT
 
-#define TLBMISS_HANDLER_SETUP_PGD(pgd)					\
-do {									\
-	void (*tlbmiss_handler_setup_pgd)(unsigned long);		\
-	extern u32 tlbmiss_handler_setup_pgd_array[16];			\
-									\
-	tlbmiss_handler_setup_pgd =					\
-		(__typeof__(tlbmiss_handler_setup_pgd)) tlbmiss_handler_setup_pgd_array; \
-	tlbmiss_handler_setup_pgd((unsigned long)(pgd));		\
-} while (0)
+#define TLBMISS_HANDLER_SETUP_PGD(pgd)				\
+	tlbmiss_handler_setup_pgd((unsigned long)(pgd))
+
+extern void tlbmiss_handler_setup_pgd(unsigned long pgd);
 
 #define TLBMISS_HANDLER_SETUP()						\
 	do {								\
@@ -44,6 +51,12 @@ do {									\
 
 #else /* CONFIG_MIPS_PGD_C0_CONTEXT: using  pgd_current*/
 
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/debug.h>
+#include <asm/mach-rmi/mmu.h>
+#endif
+
 /*
  * For the fast tlb miss handlers, we keep a per cpu array of pointers
  * to the current pgd for each processor. Also, the proc. id is stuffed
@@ -77,17 +90,30 @@ extern unsigned long pgd_current[];
 #define ASID_INC	0x10
 #define ASID_MASK	0xff0
 
+#elif defined(CONFIG_CPU_RM9000)
+
+#define ASID_INC	0x1
+#define ASID_MASK	0xfff
+
+/* SMTC/34K debug hack - but maybe we'll keep it */
 #elif defined(CONFIG_MIPS_MT_SMTC)
 
 #define ASID_INC	0x1
 extern unsigned long smtc_asid_mask;
 #define ASID_MASK	(smtc_asid_mask)
-#define HW_ASID_MASK	0xff
+#define	HW_ASID_MASK	0xff
 /* End SMTC/34K debug hack */
 #else /* FIXME: not correct for R6000 */
 
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+#define ASID_INC    0x1
+extern unsigned long rmi_asid_mask;
+#define ASID_MASK   rmi_asid_mask
+#else
+
 #define ASID_INC	0x1
 #define ASID_MASK	0xff
+#endif
 
 #endif
 
@@ -111,21 +137,15 @@ static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
 static inline void
 get_new_mmu_context(struct mm_struct *mm, unsigned long cpu)
 {
-	extern void kvm_local_flush_tlb_all(void);
 	unsigned long asid = asid_cache(cpu);
 
 	if (! ((asid += ASID_INC) & ASID_MASK) ) {
 		if (cpu_has_vtag_icache)
 			flush_icache_all();
-#ifdef CONFIG_KVM
-		kvm_local_flush_tlb_all();      /* start new asid cycle */
-#else
 		local_flush_tlb_all();	/* start new asid cycle */
-#endif
 		if (!asid)		/* fix version if needed */
 			asid = ASID_FIRST_VERSION;
 	}
-
 	cpu_context(cpu, mm) = asid_cache(cpu) = asid;
 }
 
@@ -144,14 +164,14 @@ init_new_context(struct task_struct *tsk, struct mm_struct *mm)
 {
 	int i;
 
-	for_each_possible_cpu(i)
+	for_each_online_cpu(i)
 		cpu_context(i, mm) = 0;
 
 	return 0;
 }
 
 static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,
-			     struct task_struct *tsk)
+                             struct task_struct *tsk)
 {
 	unsigned int cpu = smp_processor_id();
 	unsigned long flags;
@@ -249,7 +269,7 @@ activate_mm(struct mm_struct *prev, struct mm_struct *next)
 	}
 	/* See comments for similar code above */
 	write_c0_entryhi((read_c0_entryhi() & ~HW_ASID_MASK) |
-			 cpu_asid(cpu, next));
+	                 cpu_asid(cpu, next));
 	ehb(); /* Make sure it propagates to TCStatus */
 	evpe(mtflags);
 #else
diff --git a/arch/mips/include/asm/msgbuf.h b/arch/mips/include/asm/msgbuf.h
new file mode 100644
index 0000000..0d6c7f1
--- /dev/null
+++ b/arch/mips/include/asm/msgbuf.h
@@ -0,0 +1,47 @@
+#ifndef _ASM_MSGBUF_H
+#define _ASM_MSGBUF_H
+
+
+/*
+ * The msqid64_ds structure for the MIPS architecture.
+ * Note extra padding because this structure is passed back and forth
+ * between kernel and user space.
+ *
+ * Pad space is left for:
+ * - extension of time_t to 64-bit on 32-bitsystem to solve the y2038 problem
+ * - 2 miscellaneous unsigned long values
+ */
+
+struct msqid64_ds {
+	struct ipc64_perm msg_perm;
+#if defined(CONFIG_32BIT) && !defined(CONFIG_CPU_LITTLE_ENDIAN)
+	unsigned long	__unused1;
+#endif
+	__kernel_time_t msg_stime;	/* last msgsnd time */
+#if defined(CONFIG_32BIT) && defined(CONFIG_CPU_LITTLE_ENDIAN)
+	unsigned long	__unused1;
+#endif
+#if defined(CONFIG_32BIT) && !defined(CONFIG_CPU_LITTLE_ENDIAN)
+	unsigned long	__unused2;
+#endif
+	__kernel_time_t msg_rtime;	/* last msgrcv time */
+#if defined(CONFIG_32BIT) && defined(CONFIG_CPU_LITTLE_ENDIAN)
+	unsigned long	__unused2;
+#endif
+#if defined(CONFIG_32BIT) && !defined(CONFIG_CPU_LITTLE_ENDIAN)
+	unsigned long	__unused3;
+#endif
+	__kernel_time_t msg_ctime;	/* last change time */
+#if defined(CONFIG_32BIT) && defined(CONFIG_CPU_LITTLE_ENDIAN)
+	unsigned long	__unused3;
+#endif
+	unsigned long  msg_cbytes;	/* current number of bytes on queue */
+	unsigned long  msg_qnum;	/* number of messages in queue */
+	unsigned long  msg_qbytes;	/* max number of bytes on queue */
+	__kernel_pid_t msg_lspid;	/* pid of last msgsnd */
+	__kernel_pid_t msg_lrpid;	/* last receive pid */
+	unsigned long  __unused4;
+	unsigned long  __unused5;
+};
+
+#endif /* _ASM_MSGBUF_H */
diff --git a/arch/mips/include/asm/msi.h b/arch/mips/include/asm/msi.h
new file mode 100644
index 0000000..06dec3f
--- /dev/null
+++ b/arch/mips/include/asm/msi.h
@@ -0,0 +1,28 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: Defines for MSI support for RMI Eval Board
+
+  *****************************#RMI_1#************************************/
+
+/*
+ * Copyright (C) 2003-2004 Intel
+ * Copyright (C) Tom Long Nguyen (tom.l.nguyen@intel.com)
+ */
+
+#ifndef ASM_MSI_H
+#define ASM_MSI_H
+
+#define NR_VECTORS              128
+#define NR_IRQ_VECTORS          NR_IRQS
+#define FIRST_DEVICE_VECTOR     0x00
+
+#define LAST_DEVICE_VECTOR		232
+#define MSI_TARGET_CPU_SHIFT	12
+
+#endif /* ASM_MSI_H */
diff --git a/arch/mips/include/asm/netlogic/common.h b/arch/mips/include/asm/netlogic/common.h
index aef560a..fdd2f44 100644
--- a/arch/mips/include/asm/netlogic/common.h
+++ b/arch/mips/include/asm/netlogic/common.h
@@ -38,26 +38,22 @@
 /*
  * Common SMP definitions
  */
-#define RESET_VEC_PHYS		0x1fc00000
-#define RESET_DATA_PHYS		(RESET_VEC_PHYS + (1<<10))
-#define BOOT_THREAD_MODE	0
-#define BOOT_NMI_LOCK		4
-#define BOOT_NMI_HANDLER	8
+#define	RESET_VEC_PHYS		0x1fc00000
+#define	RESET_DATA_PHYS		(RESET_VEC_PHYS + (1<<10))
+#define	BOOT_THREAD_MODE	0
+#define	BOOT_NMI_LOCK		4
+#define	BOOT_NMI_HANDLER	8
 
 #ifndef __ASSEMBLY__
-#include <linux/cpumask.h>
-#include <linux/spinlock.h>
-#include <asm/irq.h>
-#include <asm/mach-netlogic/multi-node.h>
-
 struct irq_desc;
+extern struct plat_smp_ops nlm_smp_ops;
+extern char nlm_reset_entry[], nlm_reset_entry_end[];
 void nlm_smp_function_ipi_handler(unsigned int irq, struct irq_desc *desc);
 void nlm_smp_resched_ipi_handler(unsigned int irq, struct irq_desc *desc);
-void nlm_smp_irq_init(int hwcpuid);
+void nlm_smp_irq_init(void);
 void nlm_boot_secondary_cpus(void);
-int nlm_wakeup_secondary_cpus(void);
+int nlm_wakeup_secondary_cpus(u32 wakeup_mask);
 void nlm_rmiboot_preboot(void);
-void nlm_percpu_init(int hwcpuid);
 
 static inline void
 nlm_set_nmi_handler(void *handler)
@@ -72,42 +68,9 @@ nlm_set_nmi_handler(void *handler)
  * Misc.
  */
 unsigned int nlm_get_cpu_frequency(void);
-void nlm_node_init(int node);
-extern struct plat_smp_ops nlm_smp_ops;
-extern char nlm_reset_entry[], nlm_reset_entry_end[];
-
-extern unsigned int nlm_threads_per_core;
-extern cpumask_t nlm_cpumask;
-
-struct nlm_soc_info {
-	unsigned long coremask; /* cores enabled on the soc */
-	unsigned long ebase;
-	uint64_t irqmask;
-	uint64_t sysbase;	/* only for XLP */
-	uint64_t picbase;
-	spinlock_t piclock;
-};
-
-#define nlm_get_node(i)		(&nlm_nodes[i])
-#ifdef CONFIG_CPU_XLR
-#define nlm_current_node()	(&nlm_nodes[0])
-#else
-#define nlm_current_node()	(&nlm_nodes[nlm_nodeid()])
-#endif
-
-struct irq_data;
-uint64_t nlm_pci_irqmask(int node);
-void nlm_set_pic_extra_ack(int node, int irq,  void (*xack)(struct irq_data *));
-
-/*
- * The NR_IRQs is divided between nodes, each of them has a separate irq space
- */
-static inline int nlm_irq_to_xirq(int node, int irq)
-{
-	return node * NR_IRQS / NLM_NR_NODES + irq;
-}
 
-extern struct nlm_soc_info nlm_nodes[NLM_NR_NODES];
-extern int nlm_cpu_ready[];
+extern unsigned long nlm_common_ebase;
+extern int nlm_threads_per_core;
+extern uint32_t nlm_cpumask, nlm_coremask;
 #endif
 #endif /* _NETLOGIC_COMMON_H_ */
diff --git a/arch/mips/include/asm/netlogic/haldefs.h b/arch/mips/include/asm/netlogic/haldefs.h
index 79c7ccc..72a0c78 100644
--- a/arch/mips/include/asm/netlogic/haldefs.h
+++ b/arch/mips/include/asm/netlogic/haldefs.h
@@ -35,13 +35,42 @@
 #ifndef __NLM_HAL_HALDEFS_H__
 #define __NLM_HAL_HALDEFS_H__
 
-#include <linux/irqflags.h>	/* for local_irq_disable */
-
 /*
  * This file contains platform specific memory mapped IO implementation
  * and will provide a way to read 32/64 bit memory mapped registers in
  * all ABIs
  */
+#if !defined(CONFIG_64BIT) && defined(CONFIG_CPU_XLP)
+#error "o32 compile not supported on XLP yet"
+#endif
+/*
+ * For o32 compilation, we have to disable interrupts and enable KX bit to
+ * access 64 bit addresses or data.
+ *
+ * We need to disable interrupts because we save just the lower 32 bits of
+ * registers in  interrupt handling. So if we get hit by an interrupt while
+ * using the upper 32 bits of a register, we lose.
+ */
+static inline uint32_t nlm_save_flags_kx(void)
+{
+	return change_c0_status(ST0_KX | ST0_IE, ST0_KX);
+}
+
+static inline uint32_t nlm_save_flags_cop2(void)
+{
+	return change_c0_status(ST0_CU2 | ST0_IE, ST0_CU2);
+}
+
+static inline void nlm_restore_flags(uint32_t sr)
+{
+	write_c0_status(sr);
+}
+
+/*
+ * The n64 implementations are simple, the o32 implementations when they
+ * are added, will have to disable interrupts and enable KX before doing
+ * 64 bit ops.
+ */
 static inline uint32_t
 nlm_read_reg(uint64_t base, uint32_t reg)
 {
@@ -58,40 +87,13 @@ nlm_write_reg(uint64_t base, uint32_t reg, uint32_t val)
 	*addr = val;
 }
 
-/*
- * For o32 compilation, we have to disable interrupts to access 64 bit
- * registers
- *
- * We need to disable interrupts because we save just the lower 32 bits of
- * registers in  interrupt handling. So if we get hit by an interrupt while
- * using the upper 32 bits of a register, we lose.
- */
-
 static inline uint64_t
 nlm_read_reg64(uint64_t base, uint32_t reg)
 {
 	uint64_t addr = base + (reg >> 1) * sizeof(uint64_t);
 	volatile uint64_t *ptr = (volatile uint64_t *)(long)addr;
-	uint64_t val;
-
-	if (sizeof(unsigned long) == 4) {
-		unsigned long flags;
-
-		local_irq_save(flags);
-		__asm__ __volatile__(
-			".set	push"			"\n\t"
-			".set	mips64"			"\n\t"
-			"ld	%L0, %1"		"\n\t"
-			"dsra32	%M0, %L0, 0"		"\n\t"
-			"sll	%L0, %L0, 0"		"\n\t"
-			".set	pop"			"\n"
-			: "=r" (val)
-			: "m" (*ptr));
-		local_irq_restore(flags);
-	} else
-		val = *ptr;
-
-	return val;
+
+	return *ptr;
 }
 
 static inline void
@@ -100,25 +102,7 @@ nlm_write_reg64(uint64_t base, uint32_t reg, uint64_t val)
 	uint64_t addr = base + (reg >> 1) * sizeof(uint64_t);
 	volatile uint64_t *ptr = (volatile uint64_t *)(long)addr;
 
-	if (sizeof(unsigned long) == 4) {
-		unsigned long flags;
-		uint64_t tmp;
-
-		local_irq_save(flags);
-		__asm__ __volatile__(
-			".set	push"			"\n\t"
-			".set	mips64"			"\n\t"
-			"dsll32	%L0, %L0, 0"		"\n\t"
-			"dsrl32	%L0, %L0, 0"		"\n\t"
-			"dsll32	%M0, %M0, 0"		"\n\t"
-			"or	%L0, %L0, %M0"		"\n\t"
-			"sd	%L0, %2"		"\n\t"
-			".set	pop"			"\n"
-			: "=r" (tmp)
-			: "0" (val), "m" (*ptr));
-		local_irq_restore(flags);
-	} else
-		*ptr = val;
+	*ptr = val;
 }
 
 /*
@@ -159,6 +143,14 @@ nlm_pcicfg_base(uint32_t devoffset)
 	return nlm_io_base + devoffset;
 }
 
+static inline uint64_t
+nlm_xkphys_map_pcibar0(uint64_t pcibase)
+{
+	uint64_t paddr;
+
+	paddr = nlm_read_reg(pcibase, 0x4) & ~0xfu;
+	return (uint64_t)0x9000000000000000 | paddr;
+}
 #elif defined(CONFIG_CPU_XLR)
 
 static inline uint64_t
diff --git a/arch/mips/include/asm/netlogic/interrupt.h b/arch/mips/include/asm/netlogic/interrupt.h
index ed5993d..a85aadb 100644
--- a/arch/mips/include/asm/netlogic/interrupt.h
+++ b/arch/mips/include/asm/netlogic/interrupt.h
@@ -39,7 +39,7 @@
 
 #define IRQ_IPI_SMP_FUNCTION	3
 #define IRQ_IPI_SMP_RESCHEDULE	4
-#define IRQ_FMN			5
+#define IRQ_MSGRING		6
 #define IRQ_TIMER		7
 
 #endif
diff --git a/arch/mips/include/asm/netlogic/xlp-hal/bridge.h b/arch/mips/include/asm/netlogic/xlp-hal/bridge.h
index 790f0f1..ca95133 100644
--- a/arch/mips/include/asm/netlogic/xlp-hal/bridge.h
+++ b/arch/mips/include/asm/netlogic/xlp-hal/bridge.h
@@ -178,9 +178,9 @@
 
 #define nlm_read_bridge_reg(b, r)	nlm_read_reg(b, r)
 #define nlm_write_bridge_reg(b, r, v)	nlm_write_reg(b, r, v)
-#define nlm_get_bridge_pcibase(node)	\
+#define	nlm_get_bridge_pcibase(node)	\
 			nlm_pcicfg_base(XLP_IO_BRIDGE_OFFSET(node))
-#define nlm_get_bridge_regbase(node)	\
+#define	nlm_get_bridge_regbase(node)	\
 			(nlm_get_bridge_pcibase(node) + XLP_IO_PCI_HDRSZ)
 
 #endif /* __ASSEMBLY__ */
diff --git a/arch/mips/include/asm/netlogic/xlp-hal/cpucontrol.h b/arch/mips/include/asm/netlogic/xlp-hal/cpucontrol.h
index 6d2e58a..bf7d41d 100644
--- a/arch/mips/include/asm/netlogic/xlp-hal/cpucontrol.h
+++ b/arch/mips/include/asm/netlogic/xlp-hal/cpucontrol.h
@@ -46,12 +46,8 @@
 #define CPU_BLOCKID_FPU		9
 #define CPU_BLOCKID_MAP		10
 
-#define ICU_DEFEATURE		0x100
-
 #define LSU_DEFEATURE		0x304
-#define LSU_DEBUG_ADDR		0x305
-#define LSU_DEBUG_DATA0		0x306
-#define LSU_CERRLOG_REGID	0x309
+#define LSU_CERRLOG_REGID	0x09
 #define SCHED_DEFEATURE		0x700
 
 /* Offsets of interest from the 'MAP' Block */
diff --git a/arch/mips/include/asm/netlogic/xlp-hal/iomap.h b/arch/mips/include/asm/netlogic/xlp-hal/iomap.h
index 9fac46f..86cc339 100644
--- a/arch/mips/include/asm/netlogic/xlp-hal/iomap.h
+++ b/arch/mips/include/asm/netlogic/xlp-hal/iomap.h
@@ -35,12 +35,9 @@
 #ifndef __NLM_HAL_IOMAP_H__
 #define __NLM_HAL_IOMAP_H__
 
-#define XLP_DEFAULT_IO_BASE		0x18000000
-#define XLP_DEFAULT_PCI_ECFG_BASE	XLP_DEFAULT_IO_BASE
-#define XLP_DEFAULT_PCI_CFG_BASE	0x1c000000
-
+#define XLP_DEFAULT_IO_BASE             0x18000000
 #define NMI_BASE			0xbfc00000
-#define XLP_IO_CLK			133333333
+#define	XLP_IO_CLK			133333333
 
 #define XLP_PCIE_CFG_SIZE		0x1000		/* 4K */
 #define XLP_PCIE_DEV_BLK_SIZE		(8 * XLP_PCIE_CFG_SIZE)
@@ -96,8 +93,8 @@
 #define XLP_IO_NAND_OFFSET(node)	XLP_HDR_OFFSET(node, 0, 7, 1)
 #define XLP_IO_SPI_OFFSET(node)		XLP_HDR_OFFSET(node, 0, 7, 2)
 /* SD flash */
-#define XLP_IO_SD_OFFSET(node)		XLP_HDR_OFFSET(node, 0, 7, 3)
-#define XLP_IO_MMC_OFFSET(node, slot)	\
+#define XLP_IO_SD_OFFSET(node)          XLP_HDR_OFFSET(node, 0, 7, 3)
+#define XLP_IO_MMC_OFFSET(node, slot)   \
 		((XLP_IO_SD_OFFSET(node))+(slot*0x100)+XLP_IO_PCI_HDRSZ)
 
 /* PCI config header register id's */
@@ -125,26 +122,26 @@
 #define XLP_PCI_SBB_WT_REG		0x3f
 
 /* PCI IDs for SoC device */
-#define PCI_VENDOR_NETLOGIC		0x184e
-
-#define PCI_DEVICE_ID_NLM_ROOT		0x1001
-#define PCI_DEVICE_ID_NLM_ICI		0x1002
-#define PCI_DEVICE_ID_NLM_PIC		0x1003
-#define PCI_DEVICE_ID_NLM_PCIE		0x1004
-#define PCI_DEVICE_ID_NLM_EHCI		0x1007
-#define PCI_DEVICE_ID_NLM_OHCI		0x1008
-#define PCI_DEVICE_ID_NLM_NAE		0x1009
-#define PCI_DEVICE_ID_NLM_POE		0x100A
-#define PCI_DEVICE_ID_NLM_FMN		0x100B
-#define PCI_DEVICE_ID_NLM_RAID		0x100D
-#define PCI_DEVICE_ID_NLM_SAE		0x100D
-#define PCI_DEVICE_ID_NLM_RSA		0x100E
-#define PCI_DEVICE_ID_NLM_CMP		0x100F
-#define PCI_DEVICE_ID_NLM_UART		0x1010
-#define PCI_DEVICE_ID_NLM_I2C		0x1011
-#define PCI_DEVICE_ID_NLM_NOR		0x1015
-#define PCI_DEVICE_ID_NLM_NAND		0x1016
-#define PCI_DEVICE_ID_NLM_MMC		0x1018
+#define	PCI_VENDOR_NETLOGIC		0x184e
+
+#define	PCI_DEVICE_ID_NLM_ROOT		0x1001
+#define	PCI_DEVICE_ID_NLM_ICI		0x1002
+#define	PCI_DEVICE_ID_NLM_PIC		0x1003
+#define	PCI_DEVICE_ID_NLM_PCIE		0x1004
+#define	PCI_DEVICE_ID_NLM_EHCI		0x1007
+#define	PCI_DEVICE_ID_NLM_ILK		0x1008
+#define	PCI_DEVICE_ID_NLM_NAE		0x1009
+#define	PCI_DEVICE_ID_NLM_POE		0x100A
+#define	PCI_DEVICE_ID_NLM_FMN		0x100B
+#define	PCI_DEVICE_ID_NLM_RAID		0x100D
+#define	PCI_DEVICE_ID_NLM_SAE		0x100D
+#define	PCI_DEVICE_ID_NLM_RSA		0x100E
+#define	PCI_DEVICE_ID_NLM_CMP		0x100F
+#define	PCI_DEVICE_ID_NLM_UART		0x1010
+#define	PCI_DEVICE_ID_NLM_I2C		0x1011
+#define	PCI_DEVICE_ID_NLM_NOR		0x1015
+#define	PCI_DEVICE_ID_NLM_NAND		0x1016
+#define	PCI_DEVICE_ID_NLM_MMC		0x1018
 
 #ifndef __ASSEMBLY__
 
diff --git a/arch/mips/include/asm/netlogic/xlp-hal/pic.h b/arch/mips/include/asm/netlogic/xlp-hal/pic.h
index a981f46..b6628f7 100644
--- a/arch/mips/include/asm/netlogic/xlp-hal/pic.h
+++ b/arch/mips/include/asm/netlogic/xlp-hal/pic.h
@@ -36,7 +36,7 @@
 #define _NLM_HAL_PIC_H
 
 /* PIC Specific registers */
-#define PIC_CTRL		0x00
+#define PIC_CTRL                0x00
 
 /* PIC control register defines */
 #define PIC_CTRL_ITV		32 /* interrupt timeout value */
@@ -71,41 +71,41 @@
 #define PIC_IRT_DB		16 /* Destination base */
 #define PIC_IRT_DTE		0  /* Destination thread enables */
 
-#define PIC_BYTESWAP		0x02
-#define PIC_STATUS		0x04
+#define PIC_BYTESWAP            0x02
+#define PIC_STATUS              0x04
 #define PIC_INTR_TIMEOUT	0x06
 #define PIC_ICI0_INTR_TIMEOUT	0x08
 #define PIC_ICI1_INTR_TIMEOUT	0x0a
 #define PIC_ICI2_INTR_TIMEOUT	0x0c
 #define PIC_IPI_CTL		0x0e
-#define PIC_INT_ACK		0x10
-#define PIC_INT_PENDING0	0x12
-#define PIC_INT_PENDING1	0x14
-#define PIC_INT_PENDING2	0x16
-
-#define PIC_WDOG0_MAXVAL	0x18
-#define PIC_WDOG0_COUNT		0x1a
-#define PIC_WDOG0_ENABLE0	0x1c
-#define PIC_WDOG0_ENABLE1	0x1e
-#define PIC_WDOG0_BEATCMD	0x20
-#define PIC_WDOG0_BEAT0		0x22
-#define PIC_WDOG0_BEAT1		0x24
-
-#define PIC_WDOG1_MAXVAL	0x26
-#define PIC_WDOG1_COUNT		0x28
-#define PIC_WDOG1_ENABLE0	0x2a
-#define PIC_WDOG1_ENABLE1	0x2c
-#define PIC_WDOG1_BEATCMD	0x2e
-#define PIC_WDOG1_BEAT0		0x30
-#define PIC_WDOG1_BEAT1		0x32
-
-#define PIC_WDOG_MAXVAL(i)	(PIC_WDOG0_MAXVAL + ((i) ? 7 : 0))
-#define PIC_WDOG_COUNT(i)	(PIC_WDOG0_COUNT + ((i) ? 7 : 0))
-#define PIC_WDOG_ENABLE0(i)	(PIC_WDOG0_ENABLE0 + ((i) ? 7 : 0))
-#define PIC_WDOG_ENABLE1(i)	(PIC_WDOG0_ENABLE1 + ((i) ? 7 : 0))
-#define PIC_WDOG_BEATCMD(i)	(PIC_WDOG0_BEATCMD + ((i) ? 7 : 0))
-#define PIC_WDOG_BEAT0(i)	(PIC_WDOG0_BEAT0 + ((i) ? 7 : 0))
-#define PIC_WDOG_BEAT1(i)	(PIC_WDOG0_BEAT1 + ((i) ? 7 : 0))
+#define PIC_INT_ACK             0x10
+#define PIC_INT_PENDING0        0x12
+#define PIC_INT_PENDING1        0x14
+#define PIC_INT_PENDING2        0x16
+
+#define PIC_WDOG0_MAXVAL        0x18
+#define PIC_WDOG0_COUNT         0x1a
+#define PIC_WDOG0_ENABLE0       0x1c
+#define PIC_WDOG0_ENABLE1       0x1e
+#define PIC_WDOG0_BEATCMD       0x20
+#define PIC_WDOG0_BEAT0         0x22
+#define PIC_WDOG0_BEAT1         0x24
+
+#define PIC_WDOG1_MAXVAL        0x26
+#define PIC_WDOG1_COUNT         0x28
+#define PIC_WDOG1_ENABLE0       0x2a
+#define PIC_WDOG1_ENABLE1       0x2c
+#define PIC_WDOG1_BEATCMD       0x2e
+#define PIC_WDOG1_BEAT0         0x30
+#define PIC_WDOG1_BEAT1         0x32
+
+#define PIC_WDOG_MAXVAL(i)      (PIC_WDOG0_MAXVAL + ((i) ? 7 : 0))
+#define PIC_WDOG_COUNT(i)       (PIC_WDOG0_COUNT + ((i) ? 7 : 0))
+#define PIC_WDOG_ENABLE0(i)     (PIC_WDOG0_ENABLE0 + ((i) ? 7 : 0))
+#define PIC_WDOG_ENABLE1(i)     (PIC_WDOG0_ENABLE1 + ((i) ? 7 : 0))
+#define PIC_WDOG_BEATCMD(i)     (PIC_WDOG0_BEATCMD + ((i) ? 7 : 0))
+#define PIC_WDOG_BEAT0(i)       (PIC_WDOG0_BEAT0 + ((i) ? 7 : 0))
+#define PIC_WDOG_BEAT1(i)       (PIC_WDOG0_BEAT1 + ((i) ? 7 : 0))
 
 #define PIC_TIMER0_MAXVAL    0x34
 #define PIC_TIMER1_MAXVAL    0x36
@@ -127,28 +127,28 @@
 #define PIC_TIMER7_COUNT     0x52
 #define PIC_TIMER_COUNT(i)   (PIC_TIMER0_COUNT + ((i) * 2))
 
-#define PIC_ITE0_N0_N1		0x54
-#define PIC_ITE1_N0_N1		0x58
-#define PIC_ITE2_N0_N1		0x5c
-#define PIC_ITE3_N0_N1		0x60
-#define PIC_ITE4_N0_N1		0x64
-#define PIC_ITE5_N0_N1		0x68
-#define PIC_ITE6_N0_N1		0x6c
-#define PIC_ITE7_N0_N1		0x70
-#define PIC_ITE_N0_N1(i)	(PIC_ITE0_N0_N1 + ((i) * 4))
-
-#define PIC_ITE0_N2_N3		0x56
-#define PIC_ITE1_N2_N3		0x5a
-#define PIC_ITE2_N2_N3		0x5e
-#define PIC_ITE3_N2_N3		0x62
-#define PIC_ITE4_N2_N3		0x66
-#define PIC_ITE5_N2_N3		0x6a
-#define PIC_ITE6_N2_N3		0x6e
-#define PIC_ITE7_N2_N3		0x72
-#define PIC_ITE_N2_N3(i)	(PIC_ITE0_N2_N3 + ((i) * 4))
-
-#define PIC_IRT0		0x74
-#define PIC_IRT(i)		(PIC_IRT0 + ((i) * 2))
+#define PIC_ITE0_N0_N1          0x54
+#define PIC_ITE1_N0_N1          0x58
+#define PIC_ITE2_N0_N1          0x5c
+#define PIC_ITE3_N0_N1          0x60
+#define PIC_ITE4_N0_N1          0x64
+#define PIC_ITE5_N0_N1          0x68
+#define PIC_ITE6_N0_N1          0x6c
+#define PIC_ITE7_N0_N1          0x70
+#define PIC_ITE_N0_N1(i)        (PIC_ITE0_N0_N1 + ((i) * 4))
+
+#define PIC_ITE0_N2_N3          0x56
+#define PIC_ITE1_N2_N3          0x5a
+#define PIC_ITE2_N2_N3          0x5e
+#define PIC_ITE3_N2_N3          0x62
+#define PIC_ITE4_N2_N3          0x66
+#define PIC_ITE5_N2_N3          0x6a
+#define PIC_ITE6_N2_N3          0x6e
+#define PIC_ITE7_N2_N3          0x72
+#define PIC_ITE_N2_N3(i)        (PIC_ITE0_N2_N3 + ((i) * 4))
+
+#define PIC_IRT0                0x74
+#define PIC_IRT(i)              (PIC_IRT0 + ((i) * 2))
 
 #define TIMER_CYCLES_MAXVAL	0xffffffffffffffffULL
 
@@ -191,6 +191,55 @@
 #define PIC_IRT_PCIE_LINK_2_INDEX	80
 #define PIC_IRT_PCIE_LINK_3_INDEX	81
 #define PIC_IRT_PCIE_LINK_INDEX(num)	((num) + PIC_IRT_PCIE_LINK_0_INDEX)
+/* 78 to 81 */
+#define PIC_NUM_NA_IRTS			32
+/* 82 to 113 */
+#define PIC_IRT_NA_0_INDEX		82
+#define PIC_IRT_NA_INDEX(num)		((num) + PIC_IRT_NA_0_INDEX)
+#define PIC_IRT_POE_INDEX		114
+
+#define PIC_NUM_USB_IRTS		6
+#define PIC_IRT_USB_0_INDEX		115
+#define PIC_IRT_EHCI_0_INDEX		115
+#define PIC_IRT_EHCI_1_INDEX		118
+#define PIC_IRT_USB_INDEX(num)		((num) + PIC_IRT_USB_0_INDEX)
+/* 115 to 120 */
+#define PIC_IRT_GDX_INDEX		121
+#define PIC_IRT_SEC_INDEX		122
+#define PIC_IRT_RSA_INDEX		123
+
+#define PIC_NUM_COMP_IRTS		4
+#define PIC_IRT_COMP_0_INDEX		124
+#define PIC_IRT_COMP_INDEX(num)		((num) + PIC_IRT_COMP_0_INDEX)
+/* 124 to 127 */
+#define PIC_IRT_GBU_INDEX		128
+#define PIC_IRT_ICC_0_INDEX		129 /* ICC - Inter Chip Coherency */
+#define PIC_IRT_ICC_1_INDEX		130
+#define PIC_IRT_ICC_2_INDEX		131
+#define PIC_IRT_CAM_INDEX		132
+#define PIC_IRT_UART_0_INDEX		133
+#define PIC_IRT_UART_1_INDEX		134
+#define PIC_IRT_I2C_0_INDEX		135
+#define PIC_IRT_I2C_1_INDEX		136
+#define PIC_IRT_SYS_0_INDEX		137
+#define PIC_IRT_SYS_1_INDEX		138
+#define PIC_IRT_JTAG_INDEX		139
+#define PIC_IRT_PIC_INDEX		140
+#define PIC_IRT_NBU_INDEX		141
+#define PIC_IRT_TCU_INDEX		142
+#define PIC_IRT_GCU_INDEX		143 /* GBC - Global Coherency */
+#define PIC_IRT_DMC_0_INDEX		144
+#define PIC_IRT_DMC_1_INDEX		145
+
+#define PIC_NUM_GPIO_IRTS		4
+#define PIC_IRT_GPIO_0_INDEX		146
+#define PIC_IRT_GPIO_INDEX(num)		((num) + PIC_IRT_GPIO_0_INDEX)
+
+/* 146 to 149 */
+#define PIC_IRT_NOR_INDEX		150
+#define PIC_IRT_NAND_INDEX		151
+#define PIC_IRT_SPI_INDEX		152
+#define PIC_IRT_MMC_INDEX		153
 
 #define PIC_CLOCK_TIMER			7
 #define PIC_IRQ_BASE			8
@@ -208,8 +257,6 @@
 #define PIC_LOCAL_SCHEDULING		1
 #define PIC_GLOBAL_SCHEDULING		0
 
-#define PIC_CLK_HZ			133333333
-
 #define nlm_read_pic_reg(b, r)	nlm_read_reg64(b, r)
 #define nlm_write_pic_reg(b, r, v) nlm_write_reg64(b, r, v)
 #define nlm_get_pic_pcibase(node) nlm_pcicfg_base(XLP_IO_PIC_OFFSET(node))
@@ -222,16 +269,36 @@ nlm_pic_read_irt(uint64_t base, int irt_index)
 	return nlm_read_pic_reg(base, PIC_IRT(irt_index));
 }
 
+static inline uint64_t
+nlm_pic_read_control(uint64_t base)
+{
+	return nlm_read_pic_reg(base, PIC_CTRL);
+}
+
+static inline void
+nlm_pic_write_control(uint64_t base, uint64_t control)
+{
+	nlm_write_pic_reg(base, PIC_CTRL, control);
+}
+
+static inline void
+nlm_pic_update_control(uint64_t base, uint64_t control)
+{
+	uint64_t val;
+
+	val = nlm_read_pic_reg(base, PIC_CTRL);
+	nlm_write_pic_reg(base, PIC_CTRL, control | val);
+}
+
 static inline void
 nlm_set_irt_to_cpu(uint64_t base, int irt, int cpu)
 {
 	uint64_t val;
 
 	val = nlm_read_pic_reg(base, PIC_IRT(irt));
-	/* clear cpuset and mask */
-	val &= ~((0x7ull << 16) | 0xffff);
-	/* set DB, cpuset and cpumask */
-	val |= (1 << 19) | ((cpu >> 4) << 16) | (1 << (cpu & 0xf));
+	val |= cpu & 0xf;
+	if (cpu > 15)
+		val |= 1 << 16;
 	nlm_write_pic_reg(base, PIC_IRT(irt), val);
 }
 
@@ -264,12 +331,6 @@ nlm_pic_read_timer(uint64_t base, int timer)
 	return nlm_read_pic_reg(base, PIC_TIMER_COUNT(timer));
 }
 
-static inline uint32_t
-nlm_pic_read_timer32(uint64_t base, int timer)
-{
-	return (uint32_t)nlm_read_pic_reg(base, PIC_TIMER_COUNT(timer));
-}
-
 static inline void
 nlm_pic_write_timer(uint64_t base, int timer, uint64_t value)
 {
@@ -304,7 +365,7 @@ nlm_pic_enable_irt(uint64_t base, int irt)
 static inline void
 nlm_pic_disable_irt(uint64_t base, int irt)
 {
-	uint64_t reg;
+	uint32_t reg;
 
 	reg = nlm_read_pic_reg(base, PIC_IRT(irt));
 	nlm_write_pic_reg(base, PIC_IRT(irt), reg & ~((uint64_t)1 << 31));
@@ -314,9 +375,15 @@ static inline void
 nlm_pic_send_ipi(uint64_t base, int hwt, int irq, int nmi)
 {
 	uint64_t ipi;
+	int	node, ncpu;
+
+	node = hwt / 32;
+	ncpu = hwt & 0x1f;
+	ipi = ((uint64_t)nmi << 31) | (irq << 20) | (node << 17) |
+		(1 << (ncpu & 0xf));
+	if (ncpu > 15)
+		ipi |= 0x10000; /* Setting bit 16 to select cpus 16-31 */
 
-	ipi = (nmi << 31) | (irq << 20);
-	ipi |= ((hwt >> 4) << 16) | (1 << (hwt & 0xf)); /* cpuset and mask */
 	nlm_write_pic_reg(base, PIC_IPI_CTL, ipi);
 }
 
@@ -331,12 +398,14 @@ nlm_pic_ack(uint64_t base, int irt_num)
 }
 
 static inline void
-nlm_pic_init_irt(uint64_t base, int irt, int irq, int hwt, int en)
+nlm_pic_init_irt(uint64_t base, int irt, int irq, int hwt)
 {
-	nlm_pic_write_irt_direct(base, irt, en, 0, 0, irq, hwt);
+	nlm_pic_write_irt_direct(base, irt, 0, 0, 0, irq, 0);
 }
 
+extern uint64_t nlm_pic_base;
 int nlm_irq_to_irt(int irq);
+int nlm_irt_to_irq(int irt);
 
 #endif /* __ASSEMBLY__ */
 #endif /* _NLM_HAL_PIC_H */
diff --git a/arch/mips/include/asm/netlogic/xlp-hal/sys.h b/arch/mips/include/asm/netlogic/xlp-hal/sys.h
index 470e52b..6089042 100644
--- a/arch/mips/include/asm/netlogic/xlp-hal/sys.h
+++ b/arch/mips/include/asm/netlogic/xlp-hal/sys.h
@@ -40,89 +40,91 @@
 * @author Netlogic Microsystems
 * @brief HAL for System configuration registers
 */
-#define SYS_CHIP_RESET				0x00
-#define SYS_POWER_ON_RESET_CFG			0x01
-#define SYS_EFUSE_DEVICE_CFG_STATUS0		0x02
-#define SYS_EFUSE_DEVICE_CFG_STATUS1		0x03
-#define SYS_EFUSE_DEVICE_CFG_STATUS2		0x04
-#define SYS_EFUSE_DEVICE_CFG3			0x05
-#define SYS_EFUSE_DEVICE_CFG4			0x06
-#define SYS_EFUSE_DEVICE_CFG5			0x07
-#define SYS_EFUSE_DEVICE_CFG6			0x08
-#define SYS_EFUSE_DEVICE_CFG7			0x09
-#define SYS_PLL_CTRL				0x0a
-#define SYS_CPU_RESET				0x0b
-#define SYS_CPU_NONCOHERENT_MODE		0x0d
-#define SYS_CORE_DFS_DIS_CTRL			0x0e
-#define SYS_CORE_DFS_RST_CTRL			0x0f
-#define SYS_CORE_DFS_BYP_CTRL			0x10
-#define SYS_CORE_DFS_PHA_CTRL			0x11
-#define SYS_CORE_DFS_DIV_INC_CTRL		0x12
-#define SYS_CORE_DFS_DIV_DEC_CTRL		0x13
-#define SYS_CORE_DFS_DIV_VALUE			0x14
-#define SYS_RESET				0x15
-#define SYS_DFS_DIS_CTRL			0x16
-#define SYS_DFS_RST_CTRL			0x17
-#define SYS_DFS_BYP_CTRL			0x18
-#define SYS_DFS_DIV_INC_CTRL			0x19
-#define SYS_DFS_DIV_DEC_CTRL			0x1a
-#define SYS_DFS_DIV_VALUE0			0x1b
-#define SYS_DFS_DIV_VALUE1			0x1c
-#define SYS_SENSE_AMP_DLY			0x1d
-#define SYS_SOC_SENSE_AMP_DLY			0x1e
-#define SYS_CTRL0				0x1f
-#define SYS_CTRL1				0x20
-#define SYS_TIMEOUT_BS1				0x21
-#define SYS_BYTE_SWAP				0x22
-#define SYS_VRM_VID				0x23
-#define SYS_PWR_RAM_CMD				0x24
-#define SYS_PWR_RAM_ADDR			0x25
-#define SYS_PWR_RAM_DATA0			0x26
-#define SYS_PWR_RAM_DATA1			0x27
-#define SYS_PWR_RAM_DATA2			0x28
-#define SYS_PWR_UCODE				0x29
-#define SYS_CPU0_PWR_STATUS			0x2a
-#define SYS_CPU1_PWR_STATUS			0x2b
-#define SYS_CPU2_PWR_STATUS			0x2c
-#define SYS_CPU3_PWR_STATUS			0x2d
-#define SYS_CPU4_PWR_STATUS			0x2e
-#define SYS_CPU5_PWR_STATUS			0x2f
-#define SYS_CPU6_PWR_STATUS			0x30
-#define SYS_CPU7_PWR_STATUS			0x31
-#define SYS_STATUS				0x32
-#define SYS_INT_POL				0x33
-#define SYS_INT_TYPE				0x34
-#define SYS_INT_STATUS				0x35
-#define SYS_INT_MASK0				0x36
-#define SYS_INT_MASK1				0x37
-#define SYS_UCO_S_ECC				0x38
-#define SYS_UCO_M_ECC				0x39
-#define SYS_UCO_ADDR				0x3a
-#define SYS_UCO_INSTR				0x3b
-#define SYS_MEM_BIST0				0x3c
-#define SYS_MEM_BIST1				0x3d
-#define SYS_MEM_BIST2				0x3e
-#define SYS_MEM_BIST3				0x3f
-#define SYS_MEM_BIST4				0x40
-#define SYS_MEM_BIST5				0x41
-#define SYS_MEM_BIST6				0x42
-#define SYS_MEM_BIST7				0x43
-#define SYS_MEM_BIST8				0x44
-#define SYS_MEM_BIST9				0x45
-#define SYS_MEM_BIST10				0x46
-#define SYS_MEM_BIST11				0x47
-#define SYS_MEM_BIST12				0x48
-#define SYS_SCRTCH0				0x49
-#define SYS_SCRTCH1				0x4a
-#define SYS_SCRTCH2				0x4b
-#define SYS_SCRTCH3				0x4c
+#define	SYS_CHIP_RESET				0x00
+#define	SYS_POWER_ON_RESET_CFG			0x01
+#define	SYS_EFUSE_DEVICE_CFG_STATUS0		0x02
+#define	SYS_EFUSE_DEVICE_CFG_STATUS1		0x03
+#define	SYS_EFUSE_DEVICE_CFG_STATUS2		0x04
+#define	SYS_EFUSE_DEVICE_CFG3			0x05
+#define	SYS_EFUSE_DEVICE_CFG4			0x06
+#define	SYS_EFUSE_DEVICE_CFG5			0x07
+#define	SYS_EFUSE_DEVICE_CFG6			0x08
+#define	SYS_EFUSE_DEVICE_CFG7			0x09
+#define	SYS_PLL_CTRL				0x0a
+#define	SYS_CPU_RESET				0x0b
+#define	SYS_CPU_NONCOHERENT_MODE		0x0d
+#define	SYS_CORE_DFS_DIS_CTRL			0x0e
+#define	SYS_CORE_DFS_RST_CTRL			0x0f
+#define	SYS_CORE_DFS_BYP_CTRL			0x10
+#define	SYS_CORE_DFS_PHA_CTRL			0x11
+#define	SYS_CORE_DFS_DIV_INC_CTRL		0x12
+#define	SYS_CORE_DFS_DIV_DEC_CTRL		0x13
+#define	SYS_CORE_DFS_DIV_VALUE			0x14
+#define	SYS_RESET				0x15
+#define	SYS_DFS_DIS_CTRL			0x16
+#define	SYS_DFS_RST_CTRL			0x17
+#define	SYS_DFS_BYP_CTRL			0x18
+#define	SYS_DFS_DIV_INC_CTRL			0x19
+#define	SYS_DFS_DIV_DEC_CTRL			0x1a
+#define	SYS_DFS_DIV_VALUE0			0x1b
+#define	SYS_DFS_DIV_VALUE1			0x1c
+#define	SYS_SENSE_AMP_DLY			0x1d
+#define	SYS_SOC_SENSE_AMP_DLY			0x1e
+#define	SYS_CTRL0				0x1f
+#define	SYS_CTRL1				0x20
+#define	SYS_TIMEOUT_BS1				0x21
+#define	SYS_BYTE_SWAP				0x22
+#define	SYS_VRM_VID				0x23
+#define	SYS_PWR_RAM_CMD				0x24
+#define	SYS_PWR_RAM_ADDR			0x25
+#define	SYS_PWR_RAM_DATA0			0x26
+#define	SYS_PWR_RAM_DATA1			0x27
+#define	SYS_PWR_RAM_DATA2			0x28
+#define	SYS_PWR_UCODE				0x29
+#define	SYS_CPU0_PWR_STATUS			0x2a
+#define	SYS_CPU1_PWR_STATUS			0x2b
+#define	SYS_CPU2_PWR_STATUS			0x2c
+#define	SYS_CPU3_PWR_STATUS			0x2d
+#define	SYS_CPU4_PWR_STATUS			0x2e
+#define	SYS_CPU5_PWR_STATUS			0x2f
+#define	SYS_CPU6_PWR_STATUS			0x30
+#define	SYS_CPU7_PWR_STATUS			0x31
+#define	SYS_STATUS				0x32
+#define	SYS_INT_POL				0x33
+#define	SYS_INT_TYPE				0x34
+#define	SYS_INT_STATUS				0x35
+#define	SYS_INT_MASK0				0x36
+#define	SYS_INT_MASK1				0x37
+#define	SYS_UCO_S_ECC				0x38
+#define	SYS_UCO_M_ECC				0x39
+#define	SYS_UCO_ADDR				0x3a
+#define	SYS_UCO_INSTR				0x3b
+#define	SYS_MEM_BIST0				0x3c
+#define	SYS_MEM_BIST1				0x3d
+#define	SYS_MEM_BIST2				0x3e
+#define	SYS_MEM_BIST3				0x3f
+#define	SYS_MEM_BIST4				0x40
+#define	SYS_MEM_BIST5				0x41
+#define	SYS_MEM_BIST6				0x42
+#define	SYS_MEM_BIST7				0x43
+#define	SYS_MEM_BIST8				0x44
+#define	SYS_MEM_BIST9				0x45
+#define	SYS_MEM_BIST10				0x46
+#define	SYS_MEM_BIST11				0x47
+#define	SYS_MEM_BIST12				0x48
+#define	SYS_SCRTCH0				0x49
+#define	SYS_SCRTCH1				0x4a
+#define	SYS_SCRTCH2				0x4b
+#define	SYS_SCRTCH3				0x4c
 
 #ifndef __ASSEMBLY__
 
-#define nlm_read_sys_reg(b, r)		nlm_read_reg(b, r)
-#define nlm_write_sys_reg(b, r, v)	nlm_write_reg(b, r, v)
-#define nlm_get_sys_pcibase(node) nlm_pcicfg_base(XLP_IO_SYS_OFFSET(node))
-#define nlm_get_sys_regbase(node) (nlm_get_sys_pcibase(node) + XLP_IO_PCI_HDRSZ)
+#define	nlm_read_sys_reg(b, r)		nlm_read_reg(b, r)
+#define	nlm_write_sys_reg(b, r, v)	nlm_write_reg(b, r, v)
+#define	nlm_get_sys_pcibase(node) nlm_pcicfg_base(XLP_IO_SYS_OFFSET(node))
+#define	nlm_get_sys_regbase(node) (nlm_get_sys_pcibase(node) + XLP_IO_PCI_HDRSZ)
 
+extern uint64_t nlm_sys_base;
+extern u32 __dtb_start[];
 #endif
 #endif
diff --git a/arch/mips/include/asm/netlogic/xlp-hal/uart.h b/arch/mips/include/asm/netlogic/xlp-hal/uart.h
index 86d16e1..6a7046c 100644
--- a/arch/mips/include/asm/netlogic/xlp-hal/uart.h
+++ b/arch/mips/include/asm/netlogic/xlp-hal/uart.h
@@ -91,8 +91,8 @@
 
 #if !defined(LOCORE) && !defined(__ASSEMBLY__)
 
-#define nlm_read_uart_reg(b, r)		nlm_read_reg(b, r)
-#define nlm_write_uart_reg(b, r, v)	nlm_write_reg(b, r, v)
+#define	nlm_read_uart_reg(b, r)		nlm_read_reg(b, r)
+#define	nlm_write_uart_reg(b, r, v)	nlm_write_reg(b, r, v)
 #define nlm_get_uart_pcibase(node, inst)	\
 		nlm_pcicfg_base(XLP_IO_UART_OFFSET(node, inst))
 #define nlm_get_uart_regbase(node, inst)	\
diff --git a/arch/mips/include/asm/netlogic/xlp-hal/xlp.h b/arch/mips/include/asm/netlogic/xlp-hal/xlp.h
index 7e47209..1540588 100644
--- a/arch/mips/include/asm/netlogic/xlp-hal/xlp.h
+++ b/arch/mips/include/asm/netlogic/xlp-hal/xlp.h
@@ -35,21 +35,8 @@
 #ifndef _NLM_HAL_XLP_H
 #define _NLM_HAL_XLP_H
 
-#define PIC_UART_0_IRQ			17
-#define PIC_UART_1_IRQ			18
-#define PIC_PCIE_LINK_0_IRQ		19
-#define PIC_PCIE_LINK_1_IRQ		20
-#define PIC_PCIE_LINK_2_IRQ		21
-#define PIC_PCIE_LINK_3_IRQ		22
-#define PIC_EHCI_0_IRQ			23
-#define PIC_EHCI_1_IRQ			24
-#define PIC_OHCI_0_IRQ			25
-#define PIC_OHCI_1_IRQ			26
-#define PIC_OHCI_2_IRQ			27
-#define PIC_OHCI_3_IRQ			28
-#define PIC_MMC_IRQ			29
-#define PIC_I2C_0_IRQ			30
-#define PIC_I2C_1_IRQ			31
+#define PIC_UART_0_IRQ           17
+#define PIC_UART_1_IRQ           18
 
 #ifndef __ASSEMBLY__
 
diff --git a/arch/mips/include/asm/netlogic/xlr/gpio.h b/arch/mips/include/asm/netlogic/xlr/gpio.h
index 8492e83..51f6ad4 100644
--- a/arch/mips/include/asm/netlogic/xlr/gpio.h
+++ b/arch/mips/include/asm/netlogic/xlr/gpio.h
@@ -35,40 +35,39 @@
 #ifndef _ASM_NLM_GPIO_H
 #define _ASM_NLM_GPIO_H
 
-#define GPIO_INT_EN_REG			0
-#define GPIO_INPUT_INVERSION_REG	1
-#define GPIO_IO_DIR_REG			2
-#define GPIO_IO_DATA_WR_REG		3
-#define GPIO_IO_DATA_RD_REG		4
+#define NETLOGIC_GPIO_INT_EN_REG		0
+#define NETLOGIC_GPIO_INPUT_INVERSION_REG	1
+#define NETLOGIC_GPIO_IO_DIR_REG		2
+#define NETLOGIC_GPIO_IO_DATA_WR_REG		3
+#define NETLOGIC_GPIO_IO_DATA_RD_REG		4
 
-#define GPIO_SWRESET_REG		8
-#define GPIO_DRAM1_CNTRL_REG		9
-#define GPIO_DRAM1_RATIO_REG		10
-#define GPIO_DRAM1_RESET_REG		11
-#define GPIO_DRAM1_STATUS_REG		12
-#define GPIO_DRAM2_CNTRL_REG		13
-#define GPIO_DRAM2_RATIO_REG		14
-#define GPIO_DRAM2_RESET_REG		15
-#define GPIO_DRAM2_STATUS_REG		16
+#define NETLOGIC_GPIO_SWRESET_REG		8
+#define NETLOGIC_GPIO_DRAM1_CNTRL_REG		9
+#define NETLOGIC_GPIO_DRAM1_RATIO_REG		10
+#define NETLOGIC_GPIO_DRAM1_RESET_REG		11
+#define NETLOGIC_GPIO_DRAM1_STATUS_REG		12
+#define NETLOGIC_GPIO_DRAM2_CNTRL_REG		13
+#define NETLOGIC_GPIO_DRAM2_RATIO_REG		14
+#define NETLOGIC_GPIO_DRAM2_RESET_REG		15
+#define NETLOGIC_GPIO_DRAM2_STATUS_REG		16
 
-#define GPIO_PWRON_RESET_CFG_REG	21
-#define GPIO_BIST_ALL_GO_STATUS_REG	24
-#define GPIO_BIST_CPU_GO_STATUS_REG	25
-#define GPIO_BIST_DEV_GO_STATUS_REG	26
+#define NETLOGIC_GPIO_PWRON_RESET_CFG_REG	21
+#define NETLOGIC_GPIO_BIST_ALL_GO_STATUS_REG	24
+#define NETLOGIC_GPIO_BIST_CPU_GO_STATUS_REG	25
+#define NETLOGIC_GPIO_BIST_DEV_GO_STATUS_REG	26
 
-#define GPIO_FUSE_BANK_REG		35
-#define GPIO_CPU_RESET_REG		40
-#define GPIO_RNG_REG			43
+#define NETLOGIC_GPIO_FUSE_BANK_REG		35
+#define NETLOGIC_GPIO_CPU_RESET_REG		40
+#define NETLOGIC_GPIO_RNG_REG			43
 
-#define PWRON_RESET_PCMCIA_BOOT		17
+#define NETLOGIC_PWRON_RESET_PCMCIA_BOOT	17
+#define NETLOGIC_GPIO_LED_BITMAP	0x1700000
+#define NETLOGIC_GPIO_LED_0_SHIFT		20
+#define NETLOGIC_GPIO_LED_1_SHIFT		24
 
-#define GPIO_LED_BITMAP			0x1700000
-#define GPIO_LED_0_SHIFT		20
-#define GPIO_LED_1_SHIFT		24
-
-#define GPIO_LED_OUTPUT_CODE_RESET	0x01
-#define GPIO_LED_OUTPUT_CODE_HARD_RESET 0x02
-#define GPIO_LED_OUTPUT_CODE_SOFT_RESET 0x03
-#define GPIO_LED_OUTPUT_CODE_MAIN	0x04
+#define NETLOGIC_GPIO_LED_OUTPUT_CODE_RESET	0x01
+#define NETLOGIC_GPIO_LED_OUTPUT_CODE_HARD_RESET 0x02
+#define NETLOGIC_GPIO_LED_OUTPUT_CODE_SOFT_RESET 0x03
+#define NETLOGIC_GPIO_LED_OUTPUT_CODE_MAIN	0x04
 
 #endif
diff --git a/arch/mips/include/asm/netlogic/xlr/iomap.h b/arch/mips/include/asm/netlogic/xlr/iomap.h
index ff4533d..2e768f0 100644
--- a/arch/mips/include/asm/netlogic/xlr/iomap.h
+++ b/arch/mips/include/asm/netlogic/xlr/iomap.h
@@ -35,66 +35,66 @@
 #ifndef _ASM_NLM_IOMAP_H
 #define _ASM_NLM_IOMAP_H
 
-#define DEFAULT_NETLOGIC_IO_BASE	   CKSEG1ADDR(0x1ef00000)
-#define NETLOGIC_IO_DDR2_CHN0_OFFSET	   0x01000
-#define NETLOGIC_IO_DDR2_CHN1_OFFSET	   0x02000
-#define NETLOGIC_IO_DDR2_CHN2_OFFSET	   0x03000
-#define NETLOGIC_IO_DDR2_CHN3_OFFSET	   0x04000
-#define NETLOGIC_IO_PIC_OFFSET		   0x08000
-#define NETLOGIC_IO_UART_0_OFFSET	   0x14000
-#define NETLOGIC_IO_UART_1_OFFSET	   0x15100
+#define DEFAULT_NETLOGIC_IO_BASE           CKSEG1ADDR(0x1ef00000)
+#define NETLOGIC_IO_DDR2_CHN0_OFFSET       0x01000
+#define NETLOGIC_IO_DDR2_CHN1_OFFSET       0x02000
+#define NETLOGIC_IO_DDR2_CHN2_OFFSET       0x03000
+#define NETLOGIC_IO_DDR2_CHN3_OFFSET       0x04000
+#define NETLOGIC_IO_PIC_OFFSET             0x08000
+#define NETLOGIC_IO_UART_0_OFFSET          0x14000
+#define NETLOGIC_IO_UART_1_OFFSET          0x15100
 
-#define NETLOGIC_IO_SIZE		   0x1000
+#define NETLOGIC_IO_SIZE                   0x1000
 
-#define NETLOGIC_IO_BRIDGE_OFFSET	   0x00000
+#define NETLOGIC_IO_BRIDGE_OFFSET          0x00000
 
-#define NETLOGIC_IO_RLD2_CHN0_OFFSET	   0x05000
-#define NETLOGIC_IO_RLD2_CHN1_OFFSET	   0x06000
+#define NETLOGIC_IO_RLD2_CHN0_OFFSET       0x05000
+#define NETLOGIC_IO_RLD2_CHN1_OFFSET       0x06000
 
-#define NETLOGIC_IO_SRAM_OFFSET		   0x07000
+#define NETLOGIC_IO_SRAM_OFFSET            0x07000
 
-#define NETLOGIC_IO_PCIX_OFFSET		   0x09000
-#define NETLOGIC_IO_HT_OFFSET		   0x0A000
+#define NETLOGIC_IO_PCIX_OFFSET            0x09000
+#define NETLOGIC_IO_HT_OFFSET              0x0A000
 
-#define NETLOGIC_IO_SECURITY_OFFSET	   0x0B000
+#define NETLOGIC_IO_SECURITY_OFFSET        0x0B000
 
-#define NETLOGIC_IO_GMAC_0_OFFSET	   0x0C000
-#define NETLOGIC_IO_GMAC_1_OFFSET	   0x0D000
-#define NETLOGIC_IO_GMAC_2_OFFSET	   0x0E000
-#define NETLOGIC_IO_GMAC_3_OFFSET	   0x0F000
+#define NETLOGIC_IO_GMAC_0_OFFSET          0x0C000
+#define NETLOGIC_IO_GMAC_1_OFFSET          0x0D000
+#define NETLOGIC_IO_GMAC_2_OFFSET          0x0E000
+#define NETLOGIC_IO_GMAC_3_OFFSET          0x0F000
 
 /* XLS devices */
-#define NETLOGIC_IO_GMAC_4_OFFSET	   0x20000
-#define NETLOGIC_IO_GMAC_5_OFFSET	   0x21000
-#define NETLOGIC_IO_GMAC_6_OFFSET	   0x22000
-#define NETLOGIC_IO_GMAC_7_OFFSET	   0x23000
+#define NETLOGIC_IO_GMAC_4_OFFSET          0x20000
+#define NETLOGIC_IO_GMAC_5_OFFSET          0x21000
+#define NETLOGIC_IO_GMAC_6_OFFSET          0x22000
+#define NETLOGIC_IO_GMAC_7_OFFSET          0x23000
 
-#define NETLOGIC_IO_PCIE_0_OFFSET	   0x1E000
-#define NETLOGIC_IO_PCIE_1_OFFSET	   0x1F000
-#define NETLOGIC_IO_SRIO_0_OFFSET	   0x1E000
-#define NETLOGIC_IO_SRIO_1_OFFSET	   0x1F000
+#define NETLOGIC_IO_PCIE_0_OFFSET          0x1E000
+#define NETLOGIC_IO_PCIE_1_OFFSET          0x1F000
+#define NETLOGIC_IO_SRIO_0_OFFSET          0x1E000
+#define NETLOGIC_IO_SRIO_1_OFFSET          0x1F000
 
-#define NETLOGIC_IO_USB_0_OFFSET	   0x24000
-#define NETLOGIC_IO_USB_1_OFFSET	   0x25000
+#define NETLOGIC_IO_USB_0_OFFSET           0x24000
+#define NETLOGIC_IO_USB_1_OFFSET           0x25000
 
-#define NETLOGIC_IO_COMP_OFFSET		   0x1D000
+#define NETLOGIC_IO_COMP_OFFSET            0x1D000
 /* end XLS devices */
 
 /* XLR devices */
-#define NETLOGIC_IO_SPI4_0_OFFSET	   0x10000
-#define NETLOGIC_IO_XGMAC_0_OFFSET	   0x11000
-#define NETLOGIC_IO_SPI4_1_OFFSET	   0x12000
-#define NETLOGIC_IO_XGMAC_1_OFFSET	   0x13000
+#define NETLOGIC_IO_SPI4_0_OFFSET          0x10000
+#define NETLOGIC_IO_XGMAC_0_OFFSET         0x11000
+#define NETLOGIC_IO_SPI4_1_OFFSET          0x12000
+#define NETLOGIC_IO_XGMAC_1_OFFSET         0x13000
 /* end XLR devices */
 
-#define NETLOGIC_IO_I2C_0_OFFSET	   0x16000
-#define NETLOGIC_IO_I2C_1_OFFSET	   0x17000
+#define NETLOGIC_IO_I2C_0_OFFSET           0x16000
+#define NETLOGIC_IO_I2C_1_OFFSET           0x17000
 
-#define NETLOGIC_IO_GPIO_OFFSET		   0x18000
-#define NETLOGIC_IO_FLASH_OFFSET	   0x19000
-#define NETLOGIC_IO_TB_OFFSET		   0x1C000
+#define NETLOGIC_IO_GPIO_OFFSET            0x18000
+#define NETLOGIC_IO_FLASH_OFFSET           0x19000
+#define NETLOGIC_IO_TB_OFFSET              0x1C000
 
-#define NETLOGIC_CPLD_OFFSET		   KSEG1ADDR(0x1d840000)
+#define NETLOGIC_CPLD_OFFSET               KSEG1ADDR(0x1d840000)
 
 /*
  * Base Address (Virtual) of the PCI Config address space
@@ -102,8 +102,8 @@
  * Config space spans 256 (num of buses) * 256 (num functions) * 256 bytes
  * ie 1<<24 = 16M
  */
-#define DEFAULT_PCI_CONFIG_BASE		0x18000000
-#define DEFAULT_HT_TYPE0_CFG_BASE	0x16000000
-#define DEFAULT_HT_TYPE1_CFG_BASE	0x17000000
+#define DEFAULT_PCI_CONFIG_BASE         0x18000000
+#define DEFAULT_HT_TYPE0_CFG_BASE       0x16000000
+#define DEFAULT_HT_TYPE1_CFG_BASE       0x17000000
 
 #endif
diff --git a/arch/mips/include/asm/netlogic/xlr/msidef.h b/arch/mips/include/asm/netlogic/xlr/msidef.h
index c95d18e..7e39d40 100644
--- a/arch/mips/include/asm/netlogic/xlr/msidef.h
+++ b/arch/mips/include/asm/netlogic/xlr/msidef.h
@@ -45,21 +45,21 @@
  */
 
 #define MSI_DATA_VECTOR_SHIFT		0
-#define	 MSI_DATA_VECTOR_MASK		0x000000ff
+#define  MSI_DATA_VECTOR_MASK		0x000000ff
 #define	 MSI_DATA_VECTOR(v)		(((v) << MSI_DATA_VECTOR_SHIFT) & \
 						MSI_DATA_VECTOR_MASK)
 
 #define MSI_DATA_DELIVERY_MODE_SHIFT	8
-#define	 MSI_DATA_DELIVERY_FIXED	(0 << MSI_DATA_DELIVERY_MODE_SHIFT)
-#define	 MSI_DATA_DELIVERY_LOWPRI	(1 << MSI_DATA_DELIVERY_MODE_SHIFT)
+#define  MSI_DATA_DELIVERY_FIXED	(0 << MSI_DATA_DELIVERY_MODE_SHIFT)
+#define  MSI_DATA_DELIVERY_LOWPRI	(1 << MSI_DATA_DELIVERY_MODE_SHIFT)
 
 #define MSI_DATA_LEVEL_SHIFT		14
 #define	 MSI_DATA_LEVEL_DEASSERT	(0 << MSI_DATA_LEVEL_SHIFT)
 #define	 MSI_DATA_LEVEL_ASSERT		(1 << MSI_DATA_LEVEL_SHIFT)
 
 #define MSI_DATA_TRIGGER_SHIFT		15
-#define	 MSI_DATA_TRIGGER_EDGE		(0 << MSI_DATA_TRIGGER_SHIFT)
-#define	 MSI_DATA_TRIGGER_LEVEL		(1 << MSI_DATA_TRIGGER_SHIFT)
+#define  MSI_DATA_TRIGGER_EDGE		(0 << MSI_DATA_TRIGGER_SHIFT)
+#define  MSI_DATA_TRIGGER_LEVEL		(1 << MSI_DATA_TRIGGER_SHIFT)
 
 /*
  * Shift/mask fields for msi address
@@ -69,16 +69,16 @@
 #define MSI_ADDR_BASE_LO		0xfee00000
 
 #define MSI_ADDR_DEST_MODE_SHIFT	2
-#define	 MSI_ADDR_DEST_MODE_PHYSICAL	(0 << MSI_ADDR_DEST_MODE_SHIFT)
+#define  MSI_ADDR_DEST_MODE_PHYSICAL	(0 << MSI_ADDR_DEST_MODE_SHIFT)
 #define	 MSI_ADDR_DEST_MODE_LOGICAL	(1 << MSI_ADDR_DEST_MODE_SHIFT)
 
 #define MSI_ADDR_REDIRECTION_SHIFT	3
-#define	 MSI_ADDR_REDIRECTION_CPU	(0 << MSI_ADDR_REDIRECTION_SHIFT)
-#define	 MSI_ADDR_REDIRECTION_LOWPRI	(1 << MSI_ADDR_REDIRECTION_SHIFT)
+#define  MSI_ADDR_REDIRECTION_CPU	(0 << MSI_ADDR_REDIRECTION_SHIFT)
+#define  MSI_ADDR_REDIRECTION_LOWPRI	(1 << MSI_ADDR_REDIRECTION_SHIFT)
 
 #define MSI_ADDR_DEST_ID_SHIFT		12
 #define	 MSI_ADDR_DEST_ID_MASK		0x00ffff0
-#define	 MSI_ADDR_DEST_ID(dest)		(((dest) << MSI_ADDR_DEST_ID_SHIFT) & \
+#define  MSI_ADDR_DEST_ID(dest)		(((dest) << MSI_ADDR_DEST_ID_SHIFT) & \
 						 MSI_ADDR_DEST_ID_MASK)
 
 #endif /* ASM_RMI_MSIDEF_H */
diff --git a/arch/mips/include/asm/netlogic/xlr/pic.h b/arch/mips/include/asm/netlogic/xlr/pic.h
index 63c9917..868013e 100644
--- a/arch/mips/include/asm/netlogic/xlr/pic.h
+++ b/arch/mips/include/asm/netlogic/xlr/pic.h
@@ -35,11 +35,10 @@
 #ifndef _ASM_NLM_XLR_PIC_H
 #define _ASM_NLM_XLR_PIC_H
 
-#define PIC_CLK_HZ			66666666
+#define PIC_CLKS_PER_SEC		66666666ULL
 /* PIC hardware interrupt numbers */
 #define PIC_IRT_WD_INDEX		0
 #define PIC_IRT_TIMER_0_INDEX		1
-#define PIC_IRT_TIMER_INDEX(i)		((i) + PIC_IRT_TIMER_0_INDEX)
 #define PIC_IRT_TIMER_1_INDEX		2
 #define PIC_IRT_TIMER_2_INDEX		3
 #define PIC_IRT_TIMER_3_INDEX		4
@@ -100,7 +99,6 @@
 
 /* PIC Registers */
 #define PIC_CTRL			0x00
-#define PIC_CTRL_STE			8	/* timer enable start bit */
 #define PIC_IPI				0x04
 #define PIC_INT_ACK			0x06
 
@@ -118,7 +116,7 @@
 #define PIC_TIMER_COUNT_0_BASE		0x120
 #define PIC_TIMER_COUNT_1_BASE		0x130
 
-#define PIC_IRT_0(picintr)	(PIC_IRT_0_BASE + (picintr))
+#define PIC_IRT_0(picintr)      (PIC_IRT_0_BASE + (picintr))
 #define PIC_IRT_1(picintr)	(PIC_IRT_1_BASE + (picintr))
 
 #define PIC_TIMER_MAXVAL_0(i)	(PIC_TIMER_MAXVAL_0_BASE + (i))
@@ -132,9 +130,9 @@
  * 8-39. This leaves the IRQ 0-7 for cpu interrupts like
  * count/compare and FMN
  */
-#define PIC_IRQ_BASE		8
-#define PIC_INTR_TO_IRQ(i)	(PIC_IRQ_BASE + (i))
-#define PIC_IRQ_TO_INTR(i)	((i) - PIC_IRQ_BASE)
+#define PIC_IRQ_BASE            8
+#define PIC_INTR_TO_IRQ(i)      (PIC_IRQ_BASE + (i))
+#define PIC_IRQ_TO_INTR(i)      ((i) - PIC_IRQ_BASE)
 
 #define PIC_IRT_FIRST_IRQ	PIC_IRQ_BASE
 #define PIC_WD_IRQ		PIC_INTR_TO_IRQ(PIC_IRT_WD_INDEX)
@@ -170,7 +168,7 @@
 #define PIC_BRIDGE_AERR_IRQ	PIC_INTR_TO_IRQ(PIC_IRT_BRIDGE_AERR_INDEX)
 #define PIC_BRIDGE_BERR_IRQ	PIC_INTR_TO_IRQ(PIC_IRT_BRIDGE_BERR_INDEX)
 #define PIC_BRIDGE_TB_XLR_IRQ	PIC_INTR_TO_IRQ(PIC_IRT_BRIDGE_TB_XLR_INDEX)
-#define PIC_BRIDGE_AERR_NMI_IRQ PIC_INTR_TO_IRQ(PIC_IRT_BRIDGE_AERR_NMI_INDEX)
+#define PIC_BRIDGE_AERR_NMI_IRQ	PIC_INTR_TO_IRQ(PIC_IRT_BRIDGE_AERR_NMI_INDEX)
 /* XLS defines */
 #define PIC_GMAC_4_IRQ		PIC_INTR_TO_IRQ(PIC_IRT_GMAC4_INDEX)
 #define PIC_GMAC_5_IRQ		PIC_INTR_TO_IRQ(PIC_IRT_GMAC5_INDEX)
@@ -253,52 +251,14 @@ nlm_pic_ack(uint64_t base, int irt)
 }
 
 static inline void
-nlm_pic_init_irt(uint64_t base, int irt, int irq, int hwt, int en)
+nlm_pic_init_irt(uint64_t base, int irt, int irq, int hwt)
 {
 	nlm_write_reg(base, PIC_IRT_0(irt), (1u << hwt));
 	/* local scheduling, invalid, level by default */
 	nlm_write_reg(base, PIC_IRT_1(irt),
-		(en << 30) | (1 << 6) | irq);
+		(1 << 30) | (1 << 6) | irq);
 }
 
-static inline uint64_t
-nlm_pic_read_timer(uint64_t base, int timer)
-{
-	uint32_t up1, up2, low;
-
-	up1 = nlm_read_reg(base, PIC_TIMER_COUNT_1(timer));
-	low = nlm_read_reg(base, PIC_TIMER_COUNT_0(timer));
-	up2 = nlm_read_reg(base, PIC_TIMER_COUNT_1(timer));
-
-	if (up1 != up2) /* wrapped, get the new low */
-		low = nlm_read_reg(base, PIC_TIMER_COUNT_0(timer));
-	return ((uint64_t)up2 << 32) | low;
-
-}
-
-static inline uint32_t
-nlm_pic_read_timer32(uint64_t base, int timer)
-{
-	return nlm_read_reg(base, PIC_TIMER_COUNT_0(timer));
-}
-
-static inline void
-nlm_pic_set_timer(uint64_t base, int timer, uint64_t value, int irq, int cpu)
-{
-	uint32_t up, low;
-	uint64_t pic_ctrl = nlm_read_reg(base, PIC_CTRL);
-	int en;
-
-	en = (irq > 0);
-	up = value >> 32;
-	low = value & 0xFFFFFFFF;
-	nlm_write_reg(base, PIC_TIMER_MAXVAL_0(timer), low);
-	nlm_write_reg(base, PIC_TIMER_MAXVAL_1(timer), up);
-	nlm_pic_init_irt(base, PIC_IRT_TIMER_INDEX(timer), irq, cpu, 0);
-
-	/* enable the timer */
-	pic_ctrl |= (1 << (PIC_CTRL_STE + timer));
-	nlm_write_reg(base, PIC_CTRL, pic_ctrl);
-}
+extern uint64_t nlm_pic_base;
 #endif
 #endif /* _ASM_NLM_XLR_PIC_H */
diff --git a/arch/mips/include/asm/netlogic/xlr/xlr.h b/arch/mips/include/asm/netlogic/xlr/xlr.h
index c1667e0..ff4a17b 100644
--- a/arch/mips/include/asm/netlogic/xlr/xlr.h
+++ b/arch/mips/include/asm/netlogic/xlr/xlr.h
@@ -51,8 +51,10 @@ static inline unsigned int nlm_chip_is_xls_b(void)
 	return ((prid & 0xf000) == 0x4000);
 }
 
-/*  XLR chip types */
-/* The XLS product line has chip versions 0x[48c]? */
+/*
+ *  XLR chip types
+ */
+ /* The XLS product line has chip versions 0x[48c]? */
 static inline unsigned int nlm_chip_is_xls(void)
 {
 	uint32_t prid = read_c0_prid();
diff --git a/arch/mips/include/asm/paccess.h b/arch/mips/include/asm/paccess.h
index 2474fc5..9ce5a1e 100644
--- a/arch/mips/include/asm/paccess.h
+++ b/arch/mips/include/asm/paccess.h
@@ -43,7 +43,7 @@ struct __large_pstruct { unsigned long buf[100]; };
 	case 1: __get_dbe_asm("lb"); break;				\
 	case 2: __get_dbe_asm("lh"); break;				\
 	case 4: __get_dbe_asm("lw"); break;				\
-	case 8:	 __get_dbe_asm("ld"); break;				\
+	case 8:  __get_dbe_asm("ld"); break;				\
 	default: __get_dbe_unknown(); break;				\
 	}								\
 	x = (__typeof__(*(ptr))) __gu_val;				\
diff --git a/arch/mips/include/asm/page.h b/arch/mips/include/asm/page.h
index f59552f..c3b72f7 100644
--- a/arch/mips/include/asm/page.h
+++ b/arch/mips/include/asm/page.h
@@ -1,3 +1,12 @@
+/*-
+ * Copyright 2005-2013 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -33,19 +42,40 @@
 #define PAGE_SIZE	(_AC(1,UL) << PAGE_SHIFT)
 #define PAGE_MASK	(~((1 << PAGE_SHIFT) - 1))
 
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
-#define HPAGE_SHIFT	(PAGE_SHIFT + PAGE_SHIFT - 3)
+#ifdef CONFIG_HUGETLB_PAGE
+
+#ifdef CONFIG_HUGE_PAGE_SIZE_128K
+#define HPAGE_SHIFT	(PL_64K + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512K)
+#define HPAGE_SHIFT	(PL_256 + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_2M)
+#define HPAGE_SHIFT	(PL_1M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_8M)
+#define HPAGE_SHIFT	(PL_4M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_32M)
+#define HPAGE_SHIFT	(PL_16M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_128M)
+#define HPAGE_SHIFT	(PL_64M + 1)
+#elif defined(CONFIG_HUGE_PAGE_SIZE_512M)
+#define HPAGE_SHIFT	(PL_256M + 1)
+#else
+#error no proper huge page size defined!
+#endif
+
 #define HPAGE_SIZE	(_AC(1,UL) << HPAGE_SHIFT)
 #define HPAGE_MASK	(~(HPAGE_SIZE - 1))
 #define HUGETLB_PAGE_ORDER	(HPAGE_SHIFT - PAGE_SHIFT)
-#else /* !CONFIG_MIPS_HUGE_TLB_SUPPORT */
+#else /* !CONFIG_HUGETLB_PAGE */
 #define HPAGE_SHIFT	({BUILD_BUG(); 0; })
 #define HPAGE_SIZE	({BUILD_BUG(); 0; })
 #define HPAGE_MASK	({BUILD_BUG(); 0; })
 #define HUGETLB_PAGE_ORDER	({BUILD_BUG(); 0; })
-#endif /* CONFIG_MIPS_HUGE_TLB_SUPPORT */
+#endif /* CONFIG_HUGETLB_PAGE */
+
+#ifndef __ASSEMBLY__
 
 #include <linux/pfn.h>
+#include <asm/io.h>
 
 extern void build_clear_page(void);
 extern void build_copy_page(void);
@@ -73,15 +103,35 @@ struct page;
 static inline void clear_user_page(void *addr, unsigned long vaddr,
 	struct page *page)
 {
+#ifdef CONFIG_NLM_XLP
+	extern void nlm_common_flush_dcache_page(struct page *page);
+#else
 	extern void (*flush_data_cache_page)(unsigned long addr);
+#endif
 
 	clear_page(addr);
+#ifdef CONFIG_NLM_XLP
+	nlm_common_flush_dcache_page(page);
+#else
 	if (pages_do_alias((unsigned long) addr, vaddr & PAGE_MASK))
 		flush_data_cache_page((unsigned long)addr);
+#endif
 }
 
+#ifdef CONFIG_NLM_XLP
+static inline void copy_user_page(void *vto, void *vfrom, unsigned long vaddr,
+		    struct page *to)
+{
+	extern void nlm_common_flush_dcache_page(struct page *page);
+
+	copy_page(vto, vfrom);
+	nlm_common_flush_dcache_page(to);
+}
+#else
 extern void copy_user_page(void *vto, void *vfrom, unsigned long vaddr,
 	struct page *to);
+#endif
+
 struct vm_area_struct;
 extern void copy_user_highpage(struct page *to, struct page *from,
 	unsigned long vaddr, struct vm_area_struct *vma);
@@ -136,6 +186,8 @@ typedef struct { unsigned long pgprot; } pgprot_t;
  */
 #define ptep_buddy(x)	((pte_t *)((unsigned long)(x) ^ sizeof(pte_t)))
 
+#endif /* !__ASSEMBLY__ */
+
 /*
  * __pa()/__va() should be used only during mem init.
  */
@@ -150,7 +202,6 @@ typedef struct { unsigned long pgprot; } pgprot_t;
     ((unsigned long)(x) - PAGE_OFFSET + PHYS_OFFSET)
 #endif
 #define __va(x)		((void *)((unsigned long)(x) + PAGE_OFFSET - PHYS_OFFSET))
-#include <asm/io.h>
 
 /*
  * RELOC_HIDE was originally added by 6007b903dfe5f1d13e0c711ac2894bdd4a61b1ad
@@ -165,12 +216,19 @@ typedef struct { unsigned long pgprot; } pgprot_t;
  * https://patchwork.linux-mips.org/patch/1541/
  */
 
-#define __pa_symbol(x)	__pa(RELOC_HIDE((unsigned long)(x), 0))
+#ifndef __ASSEMBLY__
+#ifdef CONFIG_MAPPED_KERNEL
+#define __pa_symbol(x) (RELOC_HIDE((unsigned long)(x), 0) - (unsigned long)LOADADDR + ((unsigned long)PHYSADDR & 0x7fffffffUL))
+#else
+#define __pa_symbol(x) __pa(RELOC_HIDE((unsigned long)(x), 0))
+#endif
+#endif
 
 #define pfn_to_kaddr(pfn)	__va((pfn) << PAGE_SHIFT)
 
 #ifdef CONFIG_FLATMEM
 
+#ifndef __ASSEMBLY__
 static inline int pfn_valid(unsigned long pfn)
 {
 	/* avoid <linux/mm.h> include hell */
@@ -178,6 +236,16 @@ static inline int pfn_valid(unsigned long pfn)
 
 	return pfn >= ARCH_PFN_OFFSET && pfn < max_mapnr;
 }
+#else
+#define pfn_valid(pfn)							\
+({									\
+	unsigned long __pfn = (pfn);					\
+	/* avoid <linux/bootmem.h> include hell */			\
+	extern unsigned long max_mapnr;					\
+									\
+	__pfn >= ARCH_PFN_OFFSET && __pfn < max_mapnr;			\
+})
+#endif
 
 #elif defined(CONFIG_SPARSEMEM)
 
@@ -198,9 +266,13 @@ static inline int pfn_valid(unsigned long pfn)
 
 #define virt_to_page(kaddr)	pfn_to_page(PFN_DOWN(virt_to_phys(kaddr)))
 
+#ifndef __ASSEMBLY__
 extern int __virt_addr_valid(const volatile void *kaddr);
 #define virt_addr_valid(kaddr)						\
 	__virt_addr_valid((const volatile void *) (kaddr))
+#else
+#define virt_addr_valid(kaddr)	pfn_valid(PFN_DOWN(virt_to_phys(kaddr)))
+#endif
 
 #define VM_DATA_DEFAULT_FLAGS	(VM_READ | VM_WRITE | VM_EXEC | \
 				 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
diff --git a/arch/mips/include/asm/param.h b/arch/mips/include/asm/param.h
new file mode 100644
index 0000000..da3920f
--- /dev/null
+++ b/arch/mips/include/asm/param.h
@@ -0,0 +1,16 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright 1994 - 2000, 2002 Ralf Baechle (ralf@gnu.org)
+ * Copyright 2000 Silicon Graphics, Inc.
+ */
+#ifndef _ASM_PARAM_H
+#define _ASM_PARAM_H
+
+#define EXEC_PAGESIZE	65536
+
+#include <asm-generic/param.h>
+
+#endif /* _ASM_PARAM_H */
diff --git a/arch/mips/include/asm/pci.h b/arch/mips/include/asm/pci.h
index b8e24fd..fcd4060 100644
--- a/arch/mips/include/asm/pci.h
+++ b/arch/mips/include/asm/pci.h
@@ -12,22 +12,20 @@
 
 /*
  * This file essentially defines the interface between board
- * specific PCI code and MIPS common PCI code.	Should potentially put
+ * specific PCI code and MIPS common PCI code.  Should potentially put
  * into include/asm/pci.h file.
  */
 
 #include <linux/ioport.h>
-#include <linux/of.h>
 
 /*
- * Each pci channel is a top-level PCI bus seem by CPU.	 A machine  with
+ * Each pci channel is a top-level PCI bus seem by CPU.  A machine  with
  * multiple PCI channels may have multiple PCI host controllers or a
  * single controller supporting multiple channels.
  */
 struct pci_controller {
 	struct pci_controller *next;
 	struct pci_bus *bus;
-	struct device_node *of_node;
 
 	struct pci_ops *pci_ops;
 	struct resource *mem_resource;
@@ -99,7 +97,7 @@ extern int pci_mmap_page_range(struct pci_dev *dev, struct vm_area_struct *vma,
 struct pci_dev;
 
 /*
- * The PCI address space does equal the physical memory address space.	The
+ * The PCI address space does equal the physical memory address space.  The
  * networking and block device layers use this boolean for bounce buffer
  * decisions.  This is set if any hose does not have an IOMMU.
  */
@@ -144,13 +142,4 @@ static inline int pci_get_legacy_ide_irq(struct pci_dev *dev, int channel)
 
 extern char * (*pcibios_plat_setup)(char *str);
 
-#ifdef CONFIG_OF
-/* this function parses memory ranges from a device node */
-extern void pci_load_of_ranges(struct pci_controller *hose,
-			       struct device_node *node);
-#else
-static inline void pci_load_of_ranges(struct pci_controller *hose,
-				      struct device_node *node) {}
-#endif
-
 #endif /* _ASM_PCI_H */
diff --git a/arch/mips/include/asm/pci/bridge.h b/arch/mips/include/asm/pci/bridge.h
index af2c8a3..be44fb0 100644
--- a/arch/mips/include/asm/pci/bridge.h
+++ b/arch/mips/include/asm/pci/bridge.h
@@ -85,7 +85,7 @@ typedef volatile struct bridge_s {
 #define b_wid_llp			b_widget.w_llp_cfg
 #define b_wid_tflush			b_widget.w_tflush
 
-	/* bridge-specific widget configuration 0x000058-0x00007F */
+	/* bridge-specific widget configuration	0x000058-0x00007F */
 	bridgereg_t	    _pad_000058;
 	bridgereg_t	    b_wid_aux_err;		/* 0x00005C */
 	bridgereg_t	    _pad_000060;
@@ -167,8 +167,8 @@ typedef volatile struct bridge_s {
 		bridgereg_t	__pad;			/* 0x0002{80,,,88} */
 		bridgereg_t	reg;			/* 0x0002{84,,,8C} */
 	} b_rrb_map[2];					/* 0x000280 */
-#define b_even_resp	b_rrb_map[0].reg		/* 0x000284 */
-#define b_odd_resp	b_rrb_map[1].reg		/* 0x00028C */
+#define	b_even_resp	b_rrb_map[0].reg		/* 0x000284 */
+#define	b_odd_resp	b_rrb_map[1].reg		/* 0x00028C */
 
 	bridgereg_t	_pad_000290;
 	bridgereg_t	b_resp_status;			/* 0x000294 */
@@ -233,7 +233,7 @@ typedef volatile struct bridge_s {
 	u8	_pad_030007[0x04fff8];			/* 0x030008-0x07FFFF */
 
 	/* External Address Translation Entry RAM 0x080000-0x0FFFFF */
-	bridge_ate_t	b_ext_ate_ram[0x10000];
+	bridge_ate_t    b_ext_ate_ram[0x10000];
 
 	/* Reserved 0x100000-0x1FFFFF */
 	char	_pad_100000[0x200000-0x100000];
@@ -400,7 +400,7 @@ typedef struct bridge_err_cmdword_s {
 #define BRIDGE_REV_A			0x1
 #define BRIDGE_REV_B			0x2
 #define BRIDGE_REV_C			0x3
-#define BRIDGE_REV_D			0x4
+#define	BRIDGE_REV_D			0x4
 
 /* Bridge widget status register bits definition */
 
@@ -691,21 +691,21 @@ typedef struct bridge_err_cmdword_s {
 #define BRIDGE_CREDIT	3
 
 /* RRB assignment register */
-#define BRIDGE_RRB_EN	0x8	/* after shifting down */
-#define BRIDGE_RRB_DEV	0x7	/* after shifting down */
-#define BRIDGE_RRB_VDEV 0x4	/* after shifting down */
-#define BRIDGE_RRB_PDEV 0x3	/* after shifting down */
+#define	BRIDGE_RRB_EN	0x8	/* after shifting down */
+#define	BRIDGE_RRB_DEV	0x7	/* after shifting down */
+#define	BRIDGE_RRB_VDEV	0x4	/* after shifting down */
+#define	BRIDGE_RRB_PDEV	0x3	/* after shifting down */
 
 /* RRB status register */
-#define BRIDGE_RRB_VALID(r)	(0x00010000<<(r))
-#define BRIDGE_RRB_INUSE(r)	(0x00000001<<(r))
+#define	BRIDGE_RRB_VALID(r)	(0x00010000<<(r))
+#define	BRIDGE_RRB_INUSE(r)	(0x00000001<<(r))
 
 /* RRB clear register */
-#define BRIDGE_RRB_CLEAR(r)	(0x00000001<<(r))
+#define	BRIDGE_RRB_CLEAR(r)	(0x00000001<<(r))
 
 /* xbox system controller declarations */
-#define XBOX_BRIDGE_WID		8
-#define FLASH_PROM1_BASE	0xE00000 /* To read the xbox sysctlr status */
+#define XBOX_BRIDGE_WID         8
+#define FLASH_PROM1_BASE        0xE00000 /* To read the xbox sysctlr status */
 #define XBOX_RPS_EXISTS		1 << 6	 /* RPS bit in status register */
 #define XBOX_RPS_FAIL		1 << 4	 /* RPS status bit in register */
 
@@ -838,7 +838,7 @@ struct bridge_controller {
 	bridge_t		*base;
 	nasid_t			nasid;
 	unsigned int		widget_id;
-	unsigned int		irq_cpu;
+	unsigned int 		irq_cpu;
 	u64			baddr;
 	unsigned int		pci_int[8];
 };
diff --git a/arch/mips/include/asm/pgtable-32.h b/arch/mips/include/asm/pgtable-32.h
index b4204c1..6820b41 100644
--- a/arch/mips/include/asm/pgtable-32.h
+++ b/arch/mips/include/asm/pgtable-32.h
@@ -47,7 +47,12 @@
 #define USER_PTRS_PER_PGD	(0x80000000UL/PGDIR_SIZE)
 #define FIRST_USER_ADDRESS	0
 
-#define VMALLOC_START	  MAP_BASE
+#ifdef CONFIG_MAPPED_KERNEL
+extern unsigned long __vmalloc_start;
+#define VMALLOC_START     __vmalloc_start
+#else
+#define VMALLOC_START     MAP_BASE
+#endif
 
 #define PKMAP_BASE		(0xfe000000UL)
 
@@ -111,7 +116,11 @@ pfn_pte(unsigned long pfn, pgprot_t prot)
 #define pte_pfn(x)		((unsigned long)((x).pte >> (PAGE_SHIFT + 2)))
 #define pfn_pte(pfn, prot)	__pte(((pfn) << (PAGE_SHIFT + 2)) | pgprot_val(prot))
 #else
+#ifdef CONFIG_NLM_XLP
+#define pte_pfn(x)		((unsigned long)(((x).pte & ~((1ULL << _PAGE_NO_READ_SHIFT) | (1ULL << _PAGE_NO_EXEC_SHIFT))) >> _PFN_SHIFT))
+#else
 #define pte_pfn(x)		((unsigned long)((x).pte >> _PFN_SHIFT))
+#endif
 #define pfn_pte(pfn, prot)	__pte(((unsigned long long)(pfn) << _PFN_SHIFT) | pgprot_val(prot))
 #endif
 #endif /* defined(CONFIG_64BIT_PHYS_ADDR) && defined(CONFIG_CPU_MIPS32) */
@@ -136,7 +145,7 @@ pfn_pte(unsigned long pfn, pgprot_t prot)
 #define pte_offset_kernel(dir, address)					\
 	((pte_t *) pmd_page_vaddr(*(dir)) + __pte_offset(address))
 
-#define pte_offset_map(dir, address)					\
+#define pte_offset_map(dir, address)                                    \
 	((pte_t *)page_address(pmd_page(*(dir))) + __pte_offset(address))
 #define pte_unmap(pte) ((void)(pte))
 
@@ -155,7 +164,7 @@ pfn_pte(unsigned long pfn, pgprot_t prot)
 
 #define pte_to_pgoff(_pte)	((((_pte).pte >> 1 ) & 0x07) | \
 				 (((_pte).pte >> 2 ) & 0x38) | \
-				 (((_pte).pte >> 10) <<	 6 ))
+				 (((_pte).pte >> 10) <<  6 ))
 
 #define pgoff_to_pte(off)	((pte_t) { (((off) & 0x07) << 1 ) | \
 					   (((off) & 0x38) << 2 ) | \
@@ -167,14 +176,14 @@ pfn_pte(unsigned long pfn, pgprot_t prot)
 /* Swap entries must have VALID and GLOBAL bits cleared. */
 #if defined(CONFIG_64BIT_PHYS_ADDR) && defined(CONFIG_CPU_MIPS32)
 #define __swp_type(x)		(((x).val >> 2) & 0x1f)
-#define __swp_offset(x)		 ((x).val >> 7)
+#define __swp_offset(x) 	 ((x).val >> 7)
 #define __swp_entry(type,offset)	\
-		((swp_entry_t)	{ ((type) << 2) | ((offset) << 7) })
+		((swp_entry_t)  { ((type) << 2) | ((offset) << 7) })
 #else
 #define __swp_type(x)		(((x).val >> 8) & 0x1f)
-#define __swp_offset(x)		 ((x).val >> 13)
+#define __swp_offset(x) 	 ((x).val >> 13)
 #define __swp_entry(type,offset)	\
-		((swp_entry_t)	{ ((type) << 8) | ((offset) << 13) })
+		((swp_entry_t)  { ((type) << 8) | ((offset) << 13) })
 #endif /* defined(CONFIG_64BIT_PHYS_ADDR) && defined(CONFIG_CPU_MIPS32) */
 
 #if defined(CONFIG_64BIT_PHYS_ADDR) && defined(CONFIG_CPU_MIPS32)
@@ -184,7 +193,7 @@ pfn_pte(unsigned long pfn, pgprot_t prot)
 #define PTE_FILE_MAX_BITS	30
 
 #define pte_to_pgoff(_pte)	((_pte).pte_high >> 2)
-#define pgoff_to_pte(off)	((pte_t) { _PAGE_FILE, (off) << 2 })
+#define pgoff_to_pte(off) 	((pte_t) { _PAGE_FILE, (off) << 2 })
 
 #else
 /*
@@ -194,7 +203,7 @@ pfn_pte(unsigned long pfn, pgprot_t prot)
 
 #define pte_to_pgoff(_pte)	((((_pte).pte >> 1) & 0x7) | \
 				 (((_pte).pte >> 2) & 0x8) | \
-				 (((_pte).pte >> 8) <<	4))
+				 (((_pte).pte >> 8) <<  4))
 
 #define pgoff_to_pte(off)	((pte_t) { (((off) & 0x7) << 1) | \
 					   (((off) & 0x8) << 2) | \
@@ -208,7 +217,7 @@ pfn_pte(unsigned long pfn, pgprot_t prot)
 #define __pte_to_swp_entry(pte) ((swp_entry_t) { (pte).pte_high })
 #define __swp_entry_to_pte(x)	((pte_t) { 0, (x).val })
 #else
-#define __pte_to_swp_entry(pte) ((swp_entry_t) { pte_val(pte) })
+#define __pte_to_swp_entry(pte)	((swp_entry_t) { pte_val(pte) })
 #define __swp_entry_to_pte(x)	((pte_t) { (x).val })
 #endif
 
diff --git a/arch/mips/include/asm/pgtable-64.h b/arch/mips/include/asm/pgtable-64.h
index e1c49a9..ec84360 100644
--- a/arch/mips/include/asm/pgtable-64.h
+++ b/arch/mips/include/asm/pgtable-64.h
@@ -9,7 +9,6 @@
 #ifndef _ASM_PGTABLE_64_H
 #define _ASM_PGTABLE_64_H
 
-#include <linux/compiler.h>
 #include <linux/linkage.h>
 
 #include <asm/addrspace.h>
@@ -115,7 +114,7 @@
 #define PTRS_PER_PTE	((PAGE_SIZE << PTE_ORDER) / sizeof(pte_t))
 
 #if PGDIR_SIZE >= TASK_SIZE64
-#define USER_PTRS_PER_PGD	(1)
+#define USER_PTRS_PER_PGD       (1)
 #else
 #define USER_PTRS_PER_PGD	(TASK_SIZE64 / PGDIR_SIZE)
 #endif
@@ -126,12 +125,19 @@
  * the first couple of pages so NULL pointer dereferences will still
  * reliably trap.
  */
+#if defined(CONFIG_MAPPED_KERNEL) && defined(CONFIG_KSEG2_LOWMEM)
+#define VMALLOC_START		0xe0000000
+#else
 #define VMALLOC_START		(MAP_BASE + (2 * PAGE_SIZE))
+#endif
+
 #define VMALLOC_END	\
-	(MAP_BASE + \
+	(VMALLOC_START + \
 	 min(PTRS_PER_PGD * PTRS_PER_PMD * PTRS_PER_PTE * PAGE_SIZE, \
 	     (1UL << cpu_vmbits)) - (1UL << 32))
 
+#ifndef CONFIG_MAPPED_KERNEL
+
 #if defined(CONFIG_MODULES) && defined(KBUILD_64BIT_SYM32) && \
 	VMALLOC_START != CKSSEG
 /* Load modules into 32bit-compatible segment. */
@@ -139,6 +145,8 @@
 #define MODULE_END	(FIXADDR_START-2*PAGE_SIZE)
 #endif
 
+#endif /* CONFIG_MAPPED_KERNEL */
+
 #define pte_ERROR(e) \
 	printk("%s:%d: bad pte %016lx.\n", __FILE__, __LINE__, pte_val(e))
 #ifndef __PAGETABLE_PMD_FOLDED
@@ -163,6 +171,7 @@ typedef struct { unsigned long pmd; } pmd_t;
 
 
 extern pmd_t invalid_pmd_table[PTRS_PER_PMD];
+extern pmd_t empty_bad_pmd_table[PTRS_PER_PMD];
 #endif
 
 /*
@@ -173,19 +182,7 @@ static inline int pmd_none(pmd_t pmd)
 	return pmd_val(pmd) == (unsigned long) invalid_pte_table;
 }
 
-static inline int pmd_bad(pmd_t pmd)
-{
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
-	/* pmd_huge(pmd) but inline */
-	if (unlikely(pmd_val(pmd) & _PAGE_HUGE))
-		return 0;
-#endif
-
-	if (unlikely(pmd_val(pmd) & ~PAGE_MASK))
-		return 1;
-
-	return 0;
-}
+#define pmd_bad(pmd)		(pmd_val(pmd) & ~PAGE_MASK)
 
 static inline int pmd_present(pmd_t pmd)
 {
@@ -230,7 +227,6 @@ static inline void pud_clear(pud_t *pudp)
 #else
 #define pte_pfn(x)		((unsigned long)((x).pte >> _PFN_SHIFT))
 #define pfn_pte(pfn, prot)	__pte(((pfn) << _PFN_SHIFT) | pgprot_val(prot))
-#define pfn_pmd(pfn, prot)	__pmd(((pfn) << _PFN_SHIFT) | pgprot_val(prot))
 #endif
 
 #define __pgd_offset(address)	pgd_index(address)
@@ -288,7 +284,7 @@ static inline pte_t mk_swap_pte(unsigned long type, unsigned long offset)
 #define __swp_type(x)		(((x).val >> 32) & 0xff)
 #define __swp_offset(x)		((x).val >> 40)
 #define __swp_entry(type, offset) ((swp_entry_t) { pte_val(mk_swap_pte((type), (offset))) })
-#define __pte_to_swp_entry(pte) ((swp_entry_t) { pte_val(pte) })
+#define __pte_to_swp_entry(pte)	((swp_entry_t) { pte_val(pte) })
 #define __swp_entry_to_pte(x)	((pte_t) { (x).val })
 
 /*
diff --git a/arch/mips/include/asm/pgtable-bits.h b/arch/mips/include/asm/pgtable-bits.h
index 32aea48..9de5f60 100644
--- a/arch/mips/include/asm/pgtable-bits.h
+++ b/arch/mips/include/asm/pgtable-bits.h
@@ -146,6 +146,24 @@
 #define _PAGE_SPLITTING		({BUG(); 1; })	/* Dummy value */
 #endif
 
+#ifdef CONFIG_NLM_XLP
+/* XLP has bit 57,56 in entrylo0/1 as RI:XI.
+ * We will use pte bits 63:62 to store ri:xi,
+ * after right shift by 6, these bits will come to proper position.
+ */
+/* Page cannot be executed */
+#define _PAGE_NO_EXEC_SHIFT	(kernel_uses_smartmips_rixi ? 62 : _PAGE_HUGE_SHIFT)
+#define _PAGE_NO_EXEC		({BUG_ON(!kernel_uses_smartmips_rixi); 1 << _PAGE_NO_EXEC_SHIFT; })
+
+/* Page cannot be read */
+#define _PAGE_NO_READ_SHIFT	(kernel_uses_smartmips_rixi ? 63 : _PAGE_NO_EXEC_SHIFT)
+#define _PAGE_NO_READ		({BUG_ON(!kernel_uses_smartmips_rixi); 1 << _PAGE_NO_READ_SHIFT; })
+
+#define _PAGE_GLOBAL_SHIFT	(6)
+#define _PAGE_GLOBAL		(1 << _PAGE_GLOBAL_SHIFT)
+
+#else /* CONFIG_NLM_XLP */
+
 /* Page cannot be executed */
 #define _PAGE_NO_EXEC_SHIFT	(cpu_has_rixi ? _PAGE_SPLITTING_SHIFT + 1 : _PAGE_SPLITTING_SHIFT)
 #define _PAGE_NO_EXEC		({BUG_ON(!cpu_has_rixi); 1 << _PAGE_NO_EXEC_SHIFT; })
@@ -157,6 +175,8 @@
 #define _PAGE_GLOBAL_SHIFT	(_PAGE_NO_READ_SHIFT + 1)
 #define _PAGE_GLOBAL		(1 << _PAGE_GLOBAL_SHIFT)
 
+#endif /* CONFIG_NLM_XLP */
+
 #define _PAGE_VALID_SHIFT	(_PAGE_GLOBAL_SHIFT + 1)
 #define _PAGE_VALID		(1 << _PAGE_VALID_SHIFT)
 /* synonym		   */
@@ -198,8 +218,11 @@
  */
 static inline uint64_t pte_to_entrylo(unsigned long pte_val)
 {
-	if (cpu_has_rixi) {
+	if (kernel_uses_smartmips_rixi) {
 		int sa;
+#ifdef CONFIG_NLM_XLP
+		return (pte_val >> _PAGE_GLOBAL_SHIFT);
+#endif
 #ifdef CONFIG_32BIT
 		sa = 31 - _PAGE_NO_READ_SHIFT;
 #else
@@ -230,28 +253,48 @@ static inline uint64_t pte_to_entrylo(unsigned long pte_val)
 /* No penalty for being coherent on the SB1, so just
    use it for "noncoherent" spaces, too.  Shouldn't hurt. */
 
-#define _CACHE_UNCACHED		    (2<<_CACHE_SHIFT)
-#define _CACHE_CACHABLE_COW	    (5<<_CACHE_SHIFT)
+#define _CACHE_UNCACHED             (2<<_CACHE_SHIFT)
+#define _CACHE_CACHABLE_COW         (5<<_CACHE_SHIFT)
 #define _CACHE_CACHABLE_NONCOHERENT (5<<_CACHE_SHIFT)
 #define _CACHE_UNCACHED_ACCELERATED (7<<_CACHE_SHIFT)
 
+#elif defined(CONFIG_CPU_XLP)
+
+#define _CACHE_UNCACHED             (2<<_CACHE_SHIFT)
+#define _CACHE_CACHABLE_COW         (3<<_CACHE_SHIFT)
+#define _CACHE_CACHABLE_NONCOHERENT (3<<_CACHE_SHIFT)
+
+#elif defined(CONFIG_CPU_RM9000)
+
+#define _CACHE_WT		    (0<<_CACHE_SHIFT)
+#define _CACHE_WTWA		    (1<<_CACHE_SHIFT)
+#define _CACHE_UC_B		    (2<<_CACHE_SHIFT)
+#define _CACHE_WB		    (3<<_CACHE_SHIFT)
+#define _CACHE_CWBEA		    (4<<_CACHE_SHIFT)
+#define _CACHE_CWB		    (5<<_CACHE_SHIFT)
+#define _CACHE_UCNB		    (6<<_CACHE_SHIFT)
+#define _CACHE_FPC		    (7<<_CACHE_SHIFT)
+
+#define _CACHE_UNCACHED		    _CACHE_UC_B
+#define _CACHE_CACHABLE_NONCOHERENT _CACHE_WB
+
 #else
 
-#define _CACHE_CACHABLE_NO_WA	    (0<<_CACHE_SHIFT)  /* R4600 only	  */
-#define _CACHE_CACHABLE_WA	    (1<<_CACHE_SHIFT)  /* R4600 only	  */
-#define _CACHE_UNCACHED		    (2<<_CACHE_SHIFT)  /* R4[0246]00	  */
-#define _CACHE_CACHABLE_NONCOHERENT (3<<_CACHE_SHIFT)  /* R4[0246]00	  */
-#define _CACHE_CACHABLE_CE	    (4<<_CACHE_SHIFT)  /* R4[04]00MC only */
-#define _CACHE_CACHABLE_COW	    (5<<_CACHE_SHIFT)  /* R4[04]00MC only */
-#define _CACHE_CACHABLE_COHERENT    (5<<_CACHE_SHIFT)  /* MIPS32R2 CMP	  */
-#define _CACHE_CACHABLE_CUW	    (6<<_CACHE_SHIFT)  /* R4[04]00MC only */
-#define _CACHE_UNCACHED_ACCELERATED (7<<_CACHE_SHIFT)  /* R10000 only	  */
+#define _CACHE_CACHABLE_NO_WA	    (0<<_CACHE_SHIFT)  /* R4600 only      */
+#define _CACHE_CACHABLE_WA	    (1<<_CACHE_SHIFT)  /* R4600 only      */
+#define _CACHE_UNCACHED             (2<<_CACHE_SHIFT)  /* R4[0246]00      */
+#define _CACHE_CACHABLE_NONCOHERENT (3<<_CACHE_SHIFT)  /* R4[0246]00      */
+#define _CACHE_CACHABLE_CE          (4<<_CACHE_SHIFT)  /* R4[04]00MC only */
+#define _CACHE_CACHABLE_COW         (5<<_CACHE_SHIFT)  /* R4[04]00MC only */
+#define _CACHE_CACHABLE_COHERENT    (5<<_CACHE_SHIFT)  /* MIPS32R2 CMP    */
+#define _CACHE_CACHABLE_CUW         (6<<_CACHE_SHIFT)  /* R4[04]00MC only */
+#define _CACHE_UNCACHED_ACCELERATED (7<<_CACHE_SHIFT)  /* R10000 only     */
 
 #endif
 
-#define __READABLE	(_PAGE_SILENT_READ | _PAGE_ACCESSED | (cpu_has_rixi ? 0 : _PAGE_READ))
+#define __READABLE	(_PAGE_SILENT_READ | _PAGE_ACCESSED | (kernel_uses_smartmips_rixi ? 0 : _PAGE_READ))
 #define __WRITEABLE	(_PAGE_WRITE | _PAGE_SILENT_WRITE | _PAGE_MODIFIED)
 
-#define _PAGE_CHG_MASK	(_PFN_MASK | _PAGE_ACCESSED | _PAGE_MODIFIED | _CACHE_MASK)
+#define _PAGE_CHG_MASK  (_PFN_MASK | _PAGE_ACCESSED | _PAGE_MODIFIED | _CACHE_MASK)
 
 #endif /* _ASM_PGTABLE_BITS_H */
diff --git a/arch/mips/include/asm/poll.h b/arch/mips/include/asm/poll.h
new file mode 100644
index 0000000..47b9520
--- /dev/null
+++ b/arch/mips/include/asm/poll.h
@@ -0,0 +1,9 @@
+#ifndef __ASM_POLL_H
+#define __ASM_POLL_H
+
+#define POLLWRNORM	POLLOUT
+#define POLLWRBAND	0x0100
+
+#include <asm-generic/poll.h>
+
+#endif /* __ASM_POLL_H */
diff --git a/arch/mips/include/asm/posix_types.h b/arch/mips/include/asm/posix_types.h
new file mode 100644
index 0000000..e0308dc
--- /dev/null
+++ b/arch/mips/include/asm/posix_types.h
@@ -0,0 +1,37 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1996, 97, 98, 99, 2000 by Ralf Baechle
+ * Copyright (C) 1999, 2000 Silicon Graphics, Inc.
+ */
+#ifndef _ASM_POSIX_TYPES_H
+#define _ASM_POSIX_TYPES_H
+
+#include <asm/sgidefs.h>
+
+/*
+ * This file is generally used by user-level software, so you need to
+ * be a little careful about namespace pollution etc.  Also, we cannot
+ * assume GCC is being used.
+ */
+
+#if (_MIPS_SZLONG == 64)
+typedef unsigned int	__kernel_nlink_t;
+#define __kernel_nlink_t __kernel_nlink_t
+#endif
+
+typedef long		__kernel_daddr_t;
+#define __kernel_daddr_t __kernel_daddr_t
+
+#if (_MIPS_SZLONG == 32)
+typedef struct {
+	long	val[2];
+} __kernel_fsid_t;
+#define __kernel_fsid_t __kernel_fsid_t
+#endif
+
+#include <asm-generic/posix_types.h>
+
+#endif /* _ASM_POSIX_TYPES_H */
diff --git a/arch/mips/include/asm/processor.h b/arch/mips/include/asm/processor.h
index 1470b7b..9f24894 100644
--- a/arch/mips/include/asm/processor.h
+++ b/arch/mips/include/asm/processor.h
@@ -1,3 +1,12 @@
+/*-
+ * Copyright 2005-2013 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -28,6 +37,7 @@
 /*
  * System setup and hardware flags..
  */
+extern void (*cpu_wait)(void);
 
 extern unsigned int vced_count, vcei_count;
 
@@ -43,14 +53,17 @@ extern unsigned int vced_count, vcei_count;
 #define SPECIAL_PAGES_SIZE PAGE_SIZE
 
 #ifdef CONFIG_32BIT
-#ifdef CONFIG_KVM_GUEST
-/* User space process size is limited to 1GB in KVM Guest Mode */
-#define TASK_SIZE	0x3fff8000UL
-#else
 /*
  * User space process size: 2GB. This is hardcoded into a few places,
  * so don't change it unless you know what you are doing.
  */
+#ifdef CONFIG_NLM_XLP
+/*
+ * XLP_MERGE_TODO: changed TASK_SIZE from 0x7fff8000UL to 0x7fff0000UL
+ * to fix page alignment of initial stack (vm_start) for 64KB pages
+ * */
+#define TASK_SIZE	0x7fff0000UL
+#else
 #define TASK_SIZE	0x7fff8000UL
 #endif
 
@@ -70,7 +83,11 @@ extern unsigned int vced_count, vcei_count;
  * support 16TB; the architectural reserve for future expansion is
  * 8192EB ...
  */
-#define TASK_SIZE32	0x7fff8000UL
+/*
+ * XLP_MERGE_TODO: changed TASK_SIZE32 from 0x7fff8000UL to 0x7fff0000UL
+ * to fix page alignment of initial stack (vm_start) for 64KB pages
+ */
+#define TASK_SIZE32	0x7fff0000UL
 #define TASK_SIZE64	0x10000000000UL
 #define TASK_SIZE (test_thread_flag(TIF_32BIT_ADDR) ? TASK_SIZE32 : TASK_SIZE64)
 
@@ -116,8 +133,8 @@ struct mips_fpu_struct {
 typedef __u32 dspreg_t;
 
 struct mips_dsp_state {
-	dspreg_t	dspr[NUM_DSP_REGS];
-	unsigned int	dspcontrol;
+	dspreg_t        dspr[NUM_DSP_REGS];
+	unsigned int    dspcontrol;
 };
 
 #define INIT_CPUMASK { \
@@ -141,46 +158,46 @@ union mips_watch_reg_state {
 
 struct octeon_cop2_state {
 	/* DMFC2 rt, 0x0201 */
-	unsigned long	cop2_crc_iv;
+	unsigned long   cop2_crc_iv;
 	/* DMFC2 rt, 0x0202 (Set with DMTC2 rt, 0x1202) */
-	unsigned long	cop2_crc_length;
+	unsigned long   cop2_crc_length;
 	/* DMFC2 rt, 0x0200 (set with DMTC2 rt, 0x4200) */
-	unsigned long	cop2_crc_poly;
+	unsigned long   cop2_crc_poly;
 	/* DMFC2 rt, 0x0402; DMFC2 rt, 0x040A */
-	unsigned long	cop2_llm_dat[2];
+	unsigned long   cop2_llm_dat[2];
        /* DMFC2 rt, 0x0084 */
-	unsigned long	cop2_3des_iv;
+	unsigned long   cop2_3des_iv;
 	/* DMFC2 rt, 0x0080; DMFC2 rt, 0x0081; DMFC2 rt, 0x0082 */
-	unsigned long	cop2_3des_key[3];
+	unsigned long   cop2_3des_key[3];
 	/* DMFC2 rt, 0x0088 (Set with DMTC2 rt, 0x0098) */
-	unsigned long	cop2_3des_result;
+	unsigned long   cop2_3des_result;
 	/* DMFC2 rt, 0x0111 (FIXME: Read Pass1 Errata) */
-	unsigned long	cop2_aes_inp0;
+	unsigned long   cop2_aes_inp0;
 	/* DMFC2 rt, 0x0102; DMFC2 rt, 0x0103 */
-	unsigned long	cop2_aes_iv[2];
+	unsigned long   cop2_aes_iv[2];
 	/* DMFC2 rt, 0x0104; DMFC2 rt, 0x0105; DMFC2 rt, 0x0106; DMFC2
 	 * rt, 0x0107 */
-	unsigned long	cop2_aes_key[4];
+	unsigned long   cop2_aes_key[4];
 	/* DMFC2 rt, 0x0110 */
-	unsigned long	cop2_aes_keylen;
+	unsigned long   cop2_aes_keylen;
 	/* DMFC2 rt, 0x0100; DMFC2 rt, 0x0101 */
-	unsigned long	cop2_aes_result[2];
+	unsigned long   cop2_aes_result[2];
 	/* DMFC2 rt, 0x0240; DMFC2 rt, 0x0241; DMFC2 rt, 0x0242; DMFC2
 	 * rt, 0x0243; DMFC2 rt, 0x0244; DMFC2 rt, 0x0245; DMFC2 rt,
 	 * 0x0246; DMFC2 rt, 0x0247; DMFC2 rt, 0x0248; DMFC2 rt,
 	 * 0x0249; DMFC2 rt, 0x024A; DMFC2 rt, 0x024B; DMFC2 rt,
 	 * 0x024C; DMFC2 rt, 0x024D; DMFC2 rt, 0x024E - Pass2 */
-	unsigned long	cop2_hsh_datw[15];
+	unsigned long   cop2_hsh_datw[15];
 	/* DMFC2 rt, 0x0250; DMFC2 rt, 0x0251; DMFC2 rt, 0x0252; DMFC2
 	 * rt, 0x0253; DMFC2 rt, 0x0254; DMFC2 rt, 0x0255; DMFC2 rt,
 	 * 0x0256; DMFC2 rt, 0x0257 - Pass2 */
-	unsigned long	cop2_hsh_ivw[8];
+	unsigned long   cop2_hsh_ivw[8];
 	/* DMFC2 rt, 0x0258; DMFC2 rt, 0x0259 - Pass2 */
-	unsigned long	cop2_gfm_mult[2];
+	unsigned long   cop2_gfm_mult[2];
 	/* DMFC2 rt, 0x025E - Pass2 */
-	unsigned long	cop2_gfm_poly;
+	unsigned long   cop2_gfm_poly;
 	/* DMFC2 rt, 0x025A; DMFC2 rt, 0x025B - Pass2 */
-	unsigned long	cop2_gfm_result[2];
+	unsigned long   cop2_gfm_result[2];
 };
 #define INIT_OCTEON_COP2 {0,}
 
@@ -230,6 +247,8 @@ struct thread_struct {
 	unsigned long cp0_badvaddr;	/* Last user fault */
 	unsigned long cp0_baduaddr;	/* Last kernel fault accessing USEG */
 	unsigned long error_code;
+	unsigned long irix_trampoline;  /* Wheee... */
+	unsigned long irix_oldctx;
 #ifdef CONFIG_CPU_CAVIUM_OCTEON
     struct octeon_cop2_state cp2 __attribute__ ((__aligned__(128)));
     struct octeon_cvmseg_state cvmseg __attribute__ ((__aligned__(128)));
@@ -253,9 +272,9 @@ struct thread_struct {
 #endif /* CONFIG_CPU_CAVIUM_OCTEON */
 
 #define INIT_THREAD  {						\
-	/*							\
-	 * Saved main processor registers			\
-	 */							\
+        /*							\
+         * Saved main processor registers			\
+         */							\
 	.reg16			= 0,				\
 	.reg17			= 0,				\
 	.reg18			= 0,				\
@@ -299,6 +318,8 @@ struct thread_struct {
 	.cp0_badvaddr		= 0,				\
 	.cp0_baduaddr		= 0,				\
 	.error_code		= 0,				\
+	.irix_trampoline	= 0,				\
+	.irix_oldctx		= 0,				\
 	/*							\
 	 * Cavium Octeon specifics (null if not Octeon)		\
 	 */							\
@@ -310,6 +331,9 @@ struct task_struct;
 /* Free all resources held by a thread. */
 #define release_thread(thread) do { } while(0)
 
+/* Prepare to copy thread state - unlazy all lazy status */
+#define prepare_to_copy(tsk)	do { } while (0)
+
 extern unsigned long thread_saved_pc(struct task_struct *tsk);
 
 /*
@@ -336,7 +360,7 @@ unsigned long get_wchan(struct task_struct *p);
  * aborts compilation on some CPUs.  It's simply not possible to unwind
  * some CPU's stackframes.
  *
- * __builtin_return_address works only for non-leaf functions.	We avoid the
+ * __builtin_return_address works only for non-leaf functions.  We avoid the
  * overhead of a function call by forcing the compiler to save the return
  * address register on the stack.
  */
diff --git a/arch/mips/include/asm/ptrace.h b/arch/mips/include/asm/ptrace.h
index 5e6cd09..2c70689 100644
--- a/arch/mips/include/asm/ptrace.h
+++ b/arch/mips/include/asm/ptrace.h
@@ -46,6 +46,18 @@ struct pt_regs {
 	unsigned long long mpl[3];	  /* MTM{0,1,2} */
 	unsigned long long mtp[3];	  /* MTP{0,1,2} */
 #endif
+#ifdef CONFIG_NLM_ENABLE_COP2
+	unsigned long long tx_buf[4];
+	unsigned long long rx_buf[4];
+	unsigned int tx_msg_status;
+	unsigned int rx_msg_status;
+	unsigned int misc_status;
+	unsigned int msg_config;
+	unsigned int msg_err;
+#endif
+#ifdef CONFIG_NLM_XLP
+	unsigned int fake_ade;
+#endif
 } __aligned(8);
 
 struct task_struct;
diff --git a/arch/mips/include/asm/r4kcache.h b/arch/mips/include/asm/r4kcache.h
index a0b2650..54ea47d 100644
--- a/arch/mips/include/asm/r4kcache.h
+++ b/arch/mips/include/asm/r4kcache.h
@@ -22,10 +22,10 @@
  * for indexed cache operations.  Two issues here:
  *
  *  - The MIPS32 and MIPS64 specs permit an implementation to directly derive
- *    the index bits from the virtual address.	This breaks with tradition
- *    set by the R4000.	 To keep unpleasant surprises from happening we pick
+ *    the index bits from the virtual address.  This breaks with tradition
+ *    set by the R4000.  To keep unpleasant surprises from happening we pick
  *    an address in KSEG0 / CKSEG0.
- *  - We need a properly sign extended address for 64-bit code.	 To get away
+ *  - We need a properly sign extended address for 64-bit code.  To get away
  *    without ifdefs we let the compiler do it by a type cast.
  */
 #define INDEX_BASE	CKSEG0
@@ -347,7 +347,7 @@ static inline void blast_##pfx##cache##lsize(void)			\
 	unsigned long end = start + current_cpu_data.desc.waysize;	\
 	unsigned long ws_inc = 1UL << current_cpu_data.desc.waybit;	\
 	unsigned long ws_end = current_cpu_data.desc.ways <<		\
-			       current_cpu_data.desc.waybit;		\
+	                       current_cpu_data.desc.waybit;		\
 	unsigned long ws, addr;						\
 									\
 	__##pfx##flush_prologue						\
@@ -359,7 +359,7 @@ static inline void blast_##pfx##cache##lsize(void)			\
 	__##pfx##flush_epilogue						\
 }									\
 									\
-static inline void blast_##pfx##cache##lsize##_page(unsigned long page) \
+static inline void blast_##pfx##cache##lsize##_page(unsigned long page)	\
 {									\
 	unsigned long start = page;					\
 	unsigned long end = page + PAGE_SIZE;				\
@@ -381,7 +381,7 @@ static inline void blast_##pfx##cache##lsize##_page_indexed(unsigned long page)
 	unsigned long end = start + PAGE_SIZE;				\
 	unsigned long ws_inc = 1UL << current_cpu_data.desc.waybit;	\
 	unsigned long ws_end = current_cpu_data.desc.ways <<		\
-			       current_cpu_data.desc.waybit;		\
+	                       current_cpu_data.desc.waybit;		\
 	unsigned long ws, addr;						\
 									\
 	__##pfx##flush_prologue						\
diff --git a/arch/mips/include/asm/resource.h b/arch/mips/include/asm/resource.h
new file mode 100644
index 0000000..87cb308
--- /dev/null
+++ b/arch/mips/include/asm/resource.h
@@ -0,0 +1,35 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1995, 96, 98, 99, 2000 by Ralf Baechle
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ */
+#ifndef _ASM_RESOURCE_H
+#define _ASM_RESOURCE_H
+
+
+/*
+ * These five resource limit IDs have a MIPS/Linux-specific ordering,
+ * the rest comes from the generic header:
+ */
+#define RLIMIT_NOFILE		5	/* max number of open files */
+#define RLIMIT_AS		6	/* address space limit */
+#define RLIMIT_RSS		7	/* max resident set size */
+#define RLIMIT_NPROC		8	/* max number of processes */
+#define RLIMIT_MEMLOCK		9	/* max locked-in-memory address space */
+
+/*
+ * SuS says limits have to be unsigned.
+ * Which makes a ton more sense anyway,
+ * but we keep the old value on MIPS32,
+ * for compatibility:
+ */
+#ifdef CONFIG_32BIT
+# define RLIM_INFINITY		0x7fffffffUL
+#endif
+
+#include <asm-generic/resource.h>
+
+#endif /* _ASM_RESOURCE_H */
diff --git a/arch/mips/include/asm/rio.h b/arch/mips/include/asm/rio.h
new file mode 100644
index 0000000..a7e56fc
--- /dev/null
+++ b/arch/mips/include/asm/rio.h
@@ -0,0 +1,15 @@
+/*
+ * RapidIO architecture support
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#ifndef ASM_MIOS_RIO_H
+#define ASM_MIPS_RIO_H
+
+extern void platform_rio_init(void);
+
+#endif				/* ASM_PPC_MIPS_H */
diff --git a/arch/mips/include/asm/sembuf.h b/arch/mips/include/asm/sembuf.h
new file mode 100644
index 0000000..7281a4d
--- /dev/null
+++ b/arch/mips/include/asm/sembuf.h
@@ -0,0 +1,22 @@
+#ifndef _ASM_SEMBUF_H
+#define _ASM_SEMBUF_H
+
+/*
+ * The semid64_ds structure for the MIPS architecture.
+ * Note extra padding because this structure is passed back and forth
+ * between kernel and user space.
+ *
+ * Pad space is left for:
+ * - 2 miscellaneous 64-bit values
+ */
+
+struct semid64_ds {
+	struct ipc64_perm sem_perm;		/* permissions .. see ipc.h */
+	__kernel_time_t	sem_otime;		/* last semop time */
+	__kernel_time_t	sem_ctime;		/* last change time */
+	unsigned long	sem_nsems;		/* no. of semaphores in array */
+	unsigned long	__unused1;
+	unsigned long	__unused2;
+};
+
+#endif /* _ASM_SEMBUF_H */
diff --git a/arch/mips/include/asm/shmbuf.h b/arch/mips/include/asm/shmbuf.h
new file mode 100644
index 0000000..f994438
--- /dev/null
+++ b/arch/mips/include/asm/shmbuf.h
@@ -0,0 +1,38 @@
+#ifndef _ASM_SHMBUF_H
+#define _ASM_SHMBUF_H
+
+/*
+ * The shmid64_ds structure for the MIPS architecture.
+ * Note extra padding because this structure is passed back and forth
+ * between kernel and user space.
+ *
+ * Pad space is left for:
+ * - 2 miscellaneous 32-bit rsp. 64-bit values
+ */
+
+struct shmid64_ds {
+	struct ipc64_perm	shm_perm;	/* operation perms */
+	size_t			shm_segsz;	/* size of segment (bytes) */
+	__kernel_time_t		shm_atime;	/* last attach time */
+	__kernel_time_t		shm_dtime;	/* last detach time */
+	__kernel_time_t		shm_ctime;	/* last change time */
+	__kernel_pid_t		shm_cpid;	/* pid of creator */
+	__kernel_pid_t		shm_lpid;	/* pid of last operator */
+	unsigned long		shm_nattch;	/* no. of current attaches */
+	unsigned long		__unused1;
+	unsigned long		__unused2;
+};
+
+struct shminfo64 {
+	unsigned long	shmmax;
+	unsigned long	shmmin;
+	unsigned long	shmmni;
+	unsigned long	shmseg;
+	unsigned long	shmall;
+	unsigned long	__unused1;
+	unsigned long	__unused2;
+	unsigned long	__unused3;
+	unsigned long	__unused4;
+};
+
+#endif /* _ASM_SHMBUF_H */
diff --git a/arch/mips/include/asm/smp.h b/arch/mips/include/asm/smp.h
index eb60087..e33ea07 100644
--- a/arch/mips/include/asm/smp.h
+++ b/arch/mips/include/asm/smp.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General
  * Public License.  See the file "COPYING" in the main directory of this
@@ -13,7 +25,9 @@
 
 #include <linux/bitops.h>
 #include <linux/linkage.h>
+#ifndef CONFIG_RMI_PHOENIX
 #include <linux/smp.h>
+#endif
 #include <linux/threads.h>
 #include <linux/cpumask.h>
 
@@ -26,7 +40,7 @@ extern cpumask_t cpu_sibling_map[];
 #define raw_smp_processor_id() (current_thread_info()->cpu)
 
 /* Map from cpu id to sequential logical cpu number.  This will only
-   not be idempotent when cpus failed to come on-line.	*/
+   not be idempotent when cpus failed to come on-line.  */
 extern int __cpu_number_map[NR_CPUS];
 #define cpu_number_map(cpu)  __cpu_number_map[cpu]
 
@@ -36,16 +50,15 @@ extern int __cpu_logical_map[NR_CPUS];
 
 #define NO_PROC_ID	(-1)
 
-#define SMP_RESCHEDULE_YOURSELF 0x1	/* XXX braindead */
+#define SMP_RESCHEDULE_YOURSELF	0x1	/* XXX braindead */
 #define SMP_CALL_FUNCTION	0x2
 /* Octeon - Tell another core to flush its icache */
 #define SMP_ICACHE_FLUSH	0x4
-/* Used by kexec crashdump to save all cpu's state */
-#define SMP_DUMP		0x8
 
 extern volatile cpumask_t cpu_callin_map;
 
 extern void asmlinkage smp_bootstrap(void);
+extern void core_send_ipi(int cpu, unsigned int action);
 
 /*
  * this function sends a 'reschedule' IPI to another CPU.
@@ -62,14 +75,14 @@ static inline void smp_send_reschedule(int cpu)
 #ifdef CONFIG_HOTPLUG_CPU
 static inline int __cpu_disable(void)
 {
-	extern struct plat_smp_ops *mp_ops;	/* private */
+	extern struct plat_smp_ops *mp_ops;     /* private */
 
 	return mp_ops->cpu_disable();
 }
 
 static inline void __cpu_die(unsigned int cpu)
 {
-	extern struct plat_smp_ops *mp_ops;	/* private */
+	extern struct plat_smp_ops *mp_ops;     /* private */
 
 	mp_ops->cpu_die(cpu);
 }
@@ -81,20 +94,16 @@ extern asmlinkage void smp_call_function_interrupt(void);
 
 static inline void arch_send_call_function_single_ipi(int cpu)
 {
-	extern struct plat_smp_ops *mp_ops;	/* private */
+	extern struct plat_smp_ops *mp_ops;     /* private */
 
 	mp_ops->send_ipi_mask(&cpumask_of_cpu(cpu), SMP_CALL_FUNCTION);
 }
 
 static inline void arch_send_call_function_ipi_mask(const struct cpumask *mask)
 {
-	extern struct plat_smp_ops *mp_ops;	/* private */
+	extern struct plat_smp_ops *mp_ops;     /* private */
 
 	mp_ops->send_ipi_mask(mask, SMP_CALL_FUNCTION);
 }
 
-#if defined(CONFIG_KEXEC)
-extern void (*dump_ipi_function_ptr)(void *);
-void dump_send_ipi(void (*dump_ipi_callback)(void *));
-#endif
 #endif /* __ASM_SMP_H */
diff --git a/arch/mips/include/asm/sparsemem.h b/arch/mips/include/asm/sparsemem.h
index d2da53c..7165333 100644
--- a/arch/mips/include/asm/sparsemem.h
+++ b/arch/mips/include/asm/sparsemem.h
@@ -6,12 +6,8 @@
  * SECTION_SIZE_BITS		2^N: how big each section will be
  * MAX_PHYSMEM_BITS		2^N: how much memory we can have in that space
  */
-#if defined(CONFIG_MIPS_HUGE_TLB_SUPPORT) && defined(CONFIG_PAGE_SIZE_64KB)
-# define SECTION_SIZE_BITS	29
-#else
-# define SECTION_SIZE_BITS	28
-#endif
-#define MAX_PHYSMEM_BITS	35
+#define SECTION_SIZE_BITS       28
+#define MAX_PHYSMEM_BITS        35
 
 #endif /* CONFIG_SPARSEMEM */
 #endif /* _MIPS_SPARSEMEM_H */
diff --git a/arch/mips/include/asm/spinlock.h b/arch/mips/include/asm/spinlock.h
index 78d201f..ca61e84 100644
--- a/arch/mips/include/asm/spinlock.h
+++ b/arch/mips/include/asm/spinlock.h
@@ -17,7 +17,7 @@
 /*
  * Your basic SMP spinlocks, allowing only a single CPU anywhere
  *
- * Simple spin lock operations.	 There are two variants, one clears IRQ's
+ * Simple spin lock operations.  There are two variants, one clears IRQ's
  * on the local processor, one does not.
  *
  * These are fair FIFO ticket locks
@@ -71,6 +71,7 @@ static inline void arch_spin_lock(arch_spinlock_t *lock)
 		"	 nop						\n"
 		"	srl	%[my_ticket], %[ticket], 16		\n"
 		"	andi	%[ticket], %[ticket], 0xffff		\n"
+		"	andi	%[my_ticket], %[my_ticket], 0xffff	\n"
 		"	bne	%[ticket], %[my_ticket], 4f		\n"
 		"	 subu	%[ticket], %[my_ticket], %[ticket]	\n"
 		"2:							\n"
@@ -104,6 +105,7 @@ static inline void arch_spin_lock(arch_spinlock_t *lock)
 		"	beqz	%[my_ticket], 1b			\n"
 		"	 srl	%[my_ticket], %[ticket], 16		\n"
 		"	andi	%[ticket], %[ticket], 0xffff		\n"
+		"	andi	%[my_ticket], %[my_ticket], 0xffff	\n"
 		"	bne	%[ticket], %[my_ticket], 4f		\n"
 		"	 subu	%[ticket], %[my_ticket], %[ticket]	\n"
 		"2:							\n"
@@ -151,6 +153,7 @@ static inline unsigned int arch_spin_trylock(arch_spinlock_t *lock)
 		"							\n"
 		"1:	ll	%[ticket], %[ticket_ptr]		\n"
 		"	srl	%[my_ticket], %[ticket], 16		\n"
+		"	andi	%[my_ticket], %[my_ticket], 0xffff	\n"
 		"	andi	%[now_serving], %[ticket], 0xffff	\n"
 		"	bne	%[my_ticket], %[now_serving], 3f	\n"
 		"	 addu	%[ticket], %[ticket], %[inc]		\n"
@@ -175,6 +178,7 @@ static inline unsigned int arch_spin_trylock(arch_spinlock_t *lock)
 		"							\n"
 		"1:	ll	%[ticket], %[ticket_ptr]		\n"
 		"	srl	%[my_ticket], %[ticket], 16		\n"
+		"	andi	%[my_ticket], %[my_ticket], 0xffff	\n"
 		"	andi	%[now_serving], %[ticket], 0xffff	\n"
 		"	bne	%[my_ticket], %[now_serving], 3f	\n"
 		"	 addu	%[ticket], %[ticket], %[inc]		\n"
@@ -218,7 +222,7 @@ static inline unsigned int arch_spin_trylock(arch_spinlock_t *lock)
  * write_can_lock - would write_trylock() succeed?
  * @lock: the rwlock in question.
  */
-#define arch_write_can_lock(rw) (!(rw)->lock)
+#define arch_write_can_lock(rw)	(!(rw)->lock)
 
 static inline void arch_read_lock(arch_rwlock_t *rw)
 {
@@ -238,16 +242,25 @@ static inline void arch_read_lock(arch_rwlock_t *rw)
 		: "m" (rw->lock)
 		: "memory");
 	} else {
-		do {
-			__asm__ __volatile__(
-			"1:	ll	%1, %2	# arch_read_lock	\n"
-			"	bltz	%1, 1b				\n"
-			"	 addu	%1, 1				\n"
-			"2:	sc	%1, %0				\n"
-			: "=m" (rw->lock), "=&r" (tmp)
-			: "m" (rw->lock)
-			: "memory");
-		} while (unlikely(!tmp));
+		__asm__ __volatile__(
+		"	.set	noreorder	# arch_read_lock	\n"
+		"1:	ll	%1, %2					\n"
+		"	bltz	%1, 3f					\n"
+		"	 addu	%1, 1					\n"
+		"2:	sc	%1, %0					\n"
+		"	beqz	%1, 1b					\n"
+		"	 nop						\n"
+		"	.subsection 2					\n"
+		"3:	ll	%1, %2					\n"
+		"	bltz	%1, 3b					\n"
+		"	 addu	%1, 1					\n"
+		"	b	2b					\n"
+		"	 nop						\n"
+		"	.previous					\n"
+		"	.set	reorder					\n"
+		: "=m" (rw->lock), "=&r" (tmp)
+		: "m" (rw->lock)
+		: "memory");
 	}
 
 	smp_llsc_mb();
@@ -272,15 +285,21 @@ static inline void arch_read_unlock(arch_rwlock_t *rw)
 		: "m" (rw->lock)
 		: "memory");
 	} else {
-		do {
-			__asm__ __volatile__(
-			"1:	ll	%1, %2	# arch_read_unlock	\n"
-			"	sub	%1, 1				\n"
-			"	sc	%1, %0				\n"
-			: "=m" (rw->lock), "=&r" (tmp)
-			: "m" (rw->lock)
-			: "memory");
-		} while (unlikely(!tmp));
+		__asm__ __volatile__(
+		"	.set	noreorder	# arch_read_unlock	\n"
+		"1:	ll	%1, %2					\n"
+		"	sub	%1, 1					\n"
+		"	sc	%1, %0					\n"
+		"	beqz	%1, 2f					\n"
+		"	 nop						\n"
+		"	.subsection 2					\n"
+		"2:	b	1b					\n"
+		"	 nop						\n"
+		"	.previous					\n"
+		"	.set	reorder					\n"
+		: "=m" (rw->lock), "=&r" (tmp)
+		: "m" (rw->lock)
+		: "memory");
 	}
 }
 
@@ -302,16 +321,25 @@ static inline void arch_write_lock(arch_rwlock_t *rw)
 		: "m" (rw->lock)
 		: "memory");
 	} else {
-		do {
-			__asm__ __volatile__(
-			"1:	ll	%1, %2	# arch_write_lock	\n"
-			"	bnez	%1, 1b				\n"
-			"	 lui	%1, 0x8000			\n"
-			"2:	sc	%1, %0				\n"
-			: "=m" (rw->lock), "=&r" (tmp)
-			: "m" (rw->lock)
-			: "memory");
-		} while (unlikely(!tmp));
+		__asm__ __volatile__(
+		"	.set	noreorder	# arch_write_lock	\n"
+		"1:	ll	%1, %2					\n"
+		"	bnez	%1, 3f					\n"
+		"	 lui	%1, 0x8000				\n"
+		"2:	sc	%1, %0					\n"
+		"	beqz	%1, 3f					\n"
+		"	 nop						\n"
+		"	.subsection 2					\n"
+		"3:	ll	%1, %2					\n"
+		"	bnez	%1, 3b					\n"
+		"	 lui	%1, 0x8000				\n"
+		"	b	2b					\n"
+		"	 nop						\n"
+		"	.previous					\n"
+		"	.set	reorder					\n"
+		: "=m" (rw->lock), "=&r" (tmp)
+		: "m" (rw->lock)
+		: "memory");
 	}
 
 	smp_llsc_mb();
@@ -396,21 +424,25 @@ static inline int arch_write_trylock(arch_rwlock_t *rw)
 		: "m" (rw->lock)
 		: "memory");
 	} else {
-		do {
-			__asm__ __volatile__(
-			"	ll	%1, %3	# arch_write_trylock	\n"
-			"	li	%2, 0				\n"
-			"	bnez	%1, 2f				\n"
-			"	lui	%1, 0x8000			\n"
-			"	sc	%1, %0				\n"
-			"	li	%2, 1				\n"
-			"2:						\n"
-			: "=m" (rw->lock), "=&r" (tmp), "=&r" (ret)
-			: "m" (rw->lock)
-			: "memory");
-		} while (unlikely(!tmp));
-
-		smp_llsc_mb();
+		__asm__ __volatile__(
+		"	.set	noreorder	# arch_write_trylock	\n"
+		"	li	%2, 0					\n"
+		"1:	ll	%1, %3					\n"
+		"	bnez	%1, 2f					\n"
+		"	lui	%1, 0x8000				\n"
+		"	sc	%1, %0					\n"
+		"	beqz	%1, 3f					\n"
+		"	 li	%2, 1					\n"
+		"2:							\n"
+		__WEAK_LLSC_MB
+		"	.subsection 2					\n"
+		"3:	b	1b					\n"
+		"	 li	%2, 0					\n"
+		"	.previous					\n"
+		"	.set	reorder					\n"
+		: "=m" (rw->lock), "=&r" (tmp), "=&r" (ret)
+		: "m" (rw->lock)
+		: "memory");
 	}
 
 	return ret;
diff --git a/arch/mips/include/asm/stackframe.h b/arch/mips/include/asm/stackframe.h
index a89d1b1..cb41af5 100644
--- a/arch/mips/include/asm/stackframe.h
+++ b/arch/mips/include/asm/stackframe.h
@@ -139,7 +139,7 @@
 1:		move	ra, k0
 		li	k0, 3
 		mtc0	k0, $22
-#endif /* CONFIG_CPU_JUMP_WORKAROUNDS */
+#endif /* CONFIG_CPU_LOONGSON2F */
 #if defined(CONFIG_32BIT) || defined(KBUILD_64BIT_SYM32)
 		lui	k1, %hi(kernelsp)
 #else
@@ -189,7 +189,6 @@
 		LONG_S	$0, PT_R0(sp)
 		mfc0	v1, CP0_STATUS
 		LONG_S	$2, PT_R2(sp)
-		LONG_S	v1, PT_STATUS(sp)
 #ifdef CONFIG_MIPS_MT_SMTC
 		/*
 		 * Ideally, these instructions would be shuffled in
@@ -201,34 +200,35 @@
 		LONG_S	k0, PT_TCSTATUS(sp)
 #endif /* CONFIG_MIPS_MT_SMTC */
 		LONG_S	$4, PT_R4(sp)
-		mfc0	v1, CP0_CAUSE
 		LONG_S	$5, PT_R5(sp)
-		LONG_S	v1, PT_CAUSE(sp)
+		LONG_S	v1, PT_STATUS(sp)
+		mfc0	v1, CP0_CAUSE
 		LONG_S	$6, PT_R6(sp)
-		MFC0	v1, CP0_EPC
 		LONG_S	$7, PT_R7(sp)
+		LONG_S	v1, PT_CAUSE(sp)
+		MFC0	v1, CP0_EPC
 #ifdef CONFIG_64BIT
 		LONG_S	$8, PT_R8(sp)
 		LONG_S	$9, PT_R9(sp)
 #endif
-		LONG_S	v1, PT_EPC(sp)
 		LONG_S	$25, PT_R25(sp)
 		LONG_S	$28, PT_R28(sp)
 		LONG_S	$31, PT_R31(sp)
+		LONG_S	v1, PT_EPC(sp)
 		ori	$28, sp, _THREAD_MASK
 		xori	$28, _THREAD_MASK
 #ifdef CONFIG_CPU_CAVIUM_OCTEON
-		.set	mips64
-		pref	0, 0($28)	/* Prefetch the current pointer */
-		pref	0, PT_R31(sp)	/* Prefetch the $31(ra) */
+		.set    mips64
+		pref    0, 0($28)       /* Prefetch the current pointer */
+		pref    0, PT_R31(sp)   /* Prefetch the $31(ra) */
 		/* The Octeon multiplier state is affected by general multiply
 		    instructions. It must be saved before and kernel code might
 		    corrupt it */
-		jal	octeon_mult_save
-		LONG_L	v1, 0($28)  /* Load the current pointer */
+		jal     octeon_mult_save
+		LONG_L  v1, 0($28)  /* Load the current pointer */
 			 /* Restore $31(ra) that was changed by the jal */
-		LONG_L	ra, PT_R31(sp)
-		pref	0, 0(v1)    /* Prefetch the current thread */
+		LONG_L  ra, PT_R31(sp)
+		pref    0, 0(v1)    /* Prefetch the current thread */
 #endif
 		.set	pop
 		.endm
diff --git a/arch/mips/include/asm/stat.h b/arch/mips/include/asm/stat.h
new file mode 100644
index 0000000..6e00f75
--- /dev/null
+++ b/arch/mips/include/asm/stat.h
@@ -0,0 +1,132 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1995, 1999, 2000 Ralf Baechle
+ * Copyright (C) 2000 Silicon Graphics, Inc.
+ */
+#ifndef _ASM_STAT_H
+#define _ASM_STAT_H
+
+#include <linux/types.h>
+
+#include <asm/sgidefs.h>
+
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32)
+
+struct stat {
+	unsigned	st_dev;
+	long		st_pad1[3];		/* Reserved for network id */
+	ino_t		st_ino;
+	mode_t		st_mode;
+	nlink_t		st_nlink;
+	uid_t		st_uid;
+	gid_t		st_gid;
+	unsigned 	st_rdev;
+	long		st_pad2[2];
+	off_t		st_size;
+	long		st_pad3;
+	/*
+	 * Actually this should be timestruc_t st_atime, st_mtime and st_ctime
+	 * but we don't have it under Linux.
+	 */
+	time_t		st_atime;
+	long		st_atime_nsec;
+	time_t		st_mtime;
+	long		st_mtime_nsec;
+	time_t		st_ctime;
+	long		st_ctime_nsec;
+	long		st_blksize;
+	long		st_blocks;
+	long		st_pad4[14];
+};
+
+/*
+ * This matches struct stat64 in glibc2.1, hence the absolutely insane
+ * amounts of padding around dev_t's.  The memory layout is the same as of
+ * struct stat of the 64-bit kernel.
+ */
+
+struct stat64 {
+	unsigned long	st_dev;
+	unsigned long	st_pad0[3];	/* Reserved for st_dev expansion  */
+
+	unsigned long long	st_ino;
+
+	mode_t		st_mode;
+	nlink_t		st_nlink;
+
+	uid_t		st_uid;
+	gid_t		st_gid;
+
+	unsigned long	st_rdev;
+	unsigned long	st_pad1[3];	/* Reserved for st_rdev expansion  */
+
+	long long	st_size;
+
+	/*
+	 * Actually this should be timestruc_t st_atime, st_mtime and st_ctime
+	 * but we don't have it under Linux.
+	 */
+	time_t		st_atime;
+	unsigned long	st_atime_nsec;	/* Reserved for st_atime expansion  */
+
+	time_t		st_mtime;
+	unsigned long	st_mtime_nsec;	/* Reserved for st_mtime expansion  */
+
+	time_t		st_ctime;
+	unsigned long	st_ctime_nsec;	/* Reserved for st_ctime expansion  */
+
+	unsigned long	st_blksize;
+	unsigned long	st_pad2;
+
+	long long	st_blocks;
+};
+
+#endif /* _MIPS_SIM == _MIPS_SIM_ABI32 */
+
+#if _MIPS_SIM == _MIPS_SIM_ABI64
+
+/* The memory layout is the same as of struct stat64 of the 32-bit kernel.  */
+struct stat {
+	unsigned int		st_dev;
+	unsigned int		st_pad0[3]; /* Reserved for st_dev expansion */
+
+	unsigned long		st_ino;
+
+	mode_t			st_mode;
+	nlink_t			st_nlink;
+
+	uid_t			st_uid;
+	gid_t			st_gid;
+
+	unsigned int		st_rdev;
+	unsigned int		st_pad1[3]; /* Reserved for st_rdev expansion */
+
+	off_t			st_size;
+
+	/*
+	 * Actually this should be timestruc_t st_atime, st_mtime and st_ctime
+	 * but we don't have it under Linux.
+	 */
+	unsigned int		st_atime;
+	unsigned int		st_atime_nsec;
+
+	unsigned int		st_mtime;
+	unsigned int		st_mtime_nsec;
+
+	unsigned int		st_ctime;
+	unsigned int		st_ctime_nsec;
+
+	unsigned int		st_blksize;
+	unsigned int		st_pad2;
+
+	unsigned long		st_blocks;
+};
+
+#endif /* _MIPS_SIM == _MIPS_SIM_ABI64 */
+
+#define STAT_HAVE_NSEC 1
+
+#endif /* _ASM_STAT_H */
diff --git a/arch/mips/include/asm/statfs.h b/arch/mips/include/asm/statfs.h
new file mode 100644
index 0000000..0f805c7
--- /dev/null
+++ b/arch/mips/include/asm/statfs.h
@@ -0,0 +1,100 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1995, 1999 by Ralf Baechle
+ */
+#ifndef _ASM_STATFS_H
+#define _ASM_STATFS_H
+
+#include <linux/posix_types.h>
+#include <asm/sgidefs.h>
+
+#ifndef __KERNEL_STRICT_NAMES
+
+#include <linux/types.h>
+
+typedef __kernel_fsid_t        fsid_t;
+
+#endif
+
+struct statfs {
+	long		f_type;
+#define f_fstyp f_type
+	long		f_bsize;
+	long		f_frsize;	/* Fragment size - unsupported */
+	long		f_blocks;
+	long		f_bfree;
+	long		f_files;
+	long		f_ffree;
+	long		f_bavail;
+
+	/* Linux specials */
+	__kernel_fsid_t	f_fsid;
+	long		f_namelen;
+	long		f_flags;
+	long		f_spare[5];
+};
+
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32)
+
+/*
+ * Unlike the traditional version the LFAPI version has none of the ABI junk
+ */
+struct statfs64 {
+	__u32	f_type;
+	__u32	f_bsize;
+	__u32	f_frsize;	/* Fragment size - unsupported */
+	__u32	__pad;
+	__u64	f_blocks;
+	__u64	f_bfree;
+	__u64	f_files;
+	__u64	f_ffree;
+	__u64	f_bavail;
+	__kernel_fsid_t f_fsid;
+	__u32	f_namelen;
+	__u32	f_flags;
+	__u32	f_spare[5];
+};
+
+#endif /* _MIPS_SIM == _MIPS_SIM_ABI32 */
+
+#if _MIPS_SIM == _MIPS_SIM_ABI64
+
+struct statfs64 {			/* Same as struct statfs */
+	long		f_type;
+	long		f_bsize;
+	long		f_frsize;	/* Fragment size - unsupported */
+	long		f_blocks;
+	long		f_bfree;
+	long		f_files;
+	long		f_ffree;
+	long		f_bavail;
+
+	/* Linux specials */
+	__kernel_fsid_t	f_fsid;
+	long		f_namelen;
+	long		f_flags;
+	long		f_spare[5];
+};
+
+struct compat_statfs64 {
+	__u32	f_type;
+	__u32	f_bsize;
+	__u32	f_frsize;	/* Fragment size - unsupported */
+	__u32	__pad;
+	__u64	f_blocks;
+	__u64	f_bfree;
+	__u64	f_files;
+	__u64	f_ffree;
+	__u64	f_bavail;
+	__kernel_fsid_t f_fsid;
+	__u32	f_namelen;
+	__u32	f_flags;
+	__u32	f_spare[5];
+};
+
+#endif /* _MIPS_SIM == _MIPS_SIM_ABI64 */
+
+#endif /* _ASM_STATFS_H */
diff --git a/arch/mips/include/asm/swab.h b/arch/mips/include/asm/swab.h
new file mode 100644
index 0000000..97c2f81
--- /dev/null
+++ b/arch/mips/include/asm/swab.h
@@ -0,0 +1,59 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1996, 99, 2003 by Ralf Baechle
+ */
+#ifndef _ASM_SWAB_H
+#define _ASM_SWAB_H
+
+#include <linux/compiler.h>
+#include <linux/types.h>
+
+#define __SWAB_64_THRU_32__
+
+#ifdef CONFIG_CPU_MIPSR2
+
+static inline __attribute_const__ __u16 __arch_swab16(__u16 x)
+{
+	__asm__(
+	"	wsbh	%0, %1			\n"
+	: "=r" (x)
+	: "r" (x));
+
+	return x;
+}
+#define __arch_swab16 __arch_swab16
+
+static inline __attribute_const__ __u32 __arch_swab32(__u32 x)
+{
+	__asm__(
+	"	wsbh	%0, %1			\n"
+	"	rotr	%0, %0, 16		\n"
+	: "=r" (x)
+	: "r" (x));
+
+	return x;
+}
+#define __arch_swab32 __arch_swab32
+
+/*
+ * Having already checked for CONFIG_CPU_MIPSR2, enable the
+ * optimized version for 64-bit kernel on r2 CPUs.
+ */
+#ifdef CONFIG_64BIT
+static inline __attribute_const__ __u64 __arch_swab64(__u64 x)
+{
+	__asm__(
+	"	dsbh	%0, %1\n"
+	"	dshd	%0, %0"
+	: "=r" (x)
+	: "r" (x));
+
+	return x;
+}
+#define __arch_swab64 __arch_swab64
+#endif /* CONFIG_64BIT */
+#endif /* CONFIG_CPU_MIPSR2 */
+#endif /* _ASM_SWAB_H */
diff --git a/arch/mips/include/asm/thread_info.h b/arch/mips/include/asm/thread_info.h
index 895320e..f8e30be 100644
--- a/arch/mips/include/asm/thread_info.h
+++ b/arch/mips/include/asm/thread_info.h
@@ -92,6 +92,25 @@ static inline struct thread_info *current_thread_info(void)
 
 #define STACK_WARN	(THREAD_SIZE / 8)
 
+#ifdef CONFIG_DEBUG_STACK_USAGE
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+#define alloc_thread_info_node(tsk, node) \
+		kzalloc_node(THREAD_SIZE, GFP_KERNEL | GFP_DMA, node)
+#else /* CONFIG_NLM_16G_MEM_SUPPORT */
+#define alloc_thread_info_node(tsk, node) \
+		kzalloc_node(THREAD_SIZE, GFP_KERNEL, node)
+#endif /* CONFIG_NLM_16G_MEM_SUPPORT */
+#else
+#ifdef CONFIG_NLM_16G_MEM_SUPPORT
+#define alloc_thread_info_node(tsk, node) \
+		kmalloc_node(THREAD_SIZE, GFP_KERNEL | GFP_DMA, node)
+#else /* CONFIG_NLM_16G_MEM_SUPPORT */
+#define alloc_thread_info_node(tsk, node) \
+		kmalloc_node(THREAD_SIZE, GFP_KERNEL, node)
+#endif /* CONFIG_NLM_16G_MEM_SUPPORT */
+#endif
+
+#define free_thread_info(info) kfree(info)
 #define PREEMPT_ACTIVE		0x10000000
 
 /*
diff --git a/arch/mips/include/asm/timex.h b/arch/mips/include/asm/timex.h
index 6529704..d74d6fa 100644
--- a/arch/mips/include/asm/timex.h
+++ b/arch/mips/include/asm/timex.h
@@ -20,6 +20,8 @@
  */
 #define CLOCK_TICK_RATE 1193182
 
+extern unsigned int mips_hpt_frequency;
+
 /*
  * Standard way to access the cycle counter.
  * Currently only used on SMP for scheduling.
@@ -29,14 +31,114 @@
  * which isn't an evil thing.
  *
  * We know that all SMP capable CPUs have cycle counters.
+ *
+ * Mathieu Desnoyers <mathieu.desnoyers@polymtl.ca>
+ * HAVE_GET_CYCLES makes sure that this case is handled properly :
+ *
+ * Ralf Baechle <ralf@linux-mips.org> :
+ * This avoids us executing an mfc0 c0_count instruction on processors which
+ * don't have but also on certain R4000 and R4400 versions where reading from
+ * the count register just in the very moment when its value equals c0_compare
+ * will result in the timer interrupt getting lost.
  */
 
+#ifdef CONFIG_HAVE_GET_CYCLES
+# ifdef CONFIG_CPU_CAVIUM_OCTEON
+typedef unsigned long cycles_t;
+
+static inline cycles_t get_cycles(void)
+{
+	return read_c0_cvmcount();
+}
+
+static inline void get_cycles_barrier(void)
+{
+}
+
+static inline cycles_t get_cycles_rate(void)
+{
+	return mips_hpt_frequency;
+}
+
+extern int test_tsc_synchronization(void);
+extern int _tsc_is_sync;
+static inline int tsc_is_sync(void)
+{
+	return _tsc_is_sync;
+}
+# else /* #ifdef CONFIG_CPU_CAVIUM_OCTEON */
+#  error "64-bit get_cycles() supported only on Cavium Octeon MIPS architectures"
+# endif /* #else #ifdef CONFIG_CPU_CAVIUM_OCTEON */
+#elif defined(CONFIG_HAVE_GET_CYCLES_32)
+typedef unsigned int cycles_t;
+
+static inline cycles_t get_cycles(void)
+{
+	return read_c0_count();
+}
+
+static inline void get_cycles_barrier(void)
+{
+}
+
+static inline cycles_t get_cycles_rate(void)
+{
+	return mips_hpt_frequency;
+}
+
+extern int test_tsc_synchronization(void);
+extern int _tsc_is_sync;
+static inline int tsc_is_sync(void)
+{
+	return _tsc_is_sync;
+}
+#else
 typedef unsigned int cycles_t;
 
 static inline cycles_t get_cycles(void)
 {
 	return 0;
 }
+static inline int test_tsc_synchronization(void)
+{
+	return 0;
+}
+static inline int tsc_is_sync(void)
+{
+	return 0;
+}
+#endif
+
+#define DELAY_INTERRUPT 100
+/*
+ * Only updates 32 LSB.
+ */
+static inline void write_tsc(u32 val1, u32 val2)
+{
+	write_c0_count(val1);
+	/* Arrange for an interrupt in a short while */
+	write_c0_compare(read_c0_count() + DELAY_INTERRUPT);
+}
+
+/*
+ * Currently unused, should update internal tsc-related timekeeping sources.
+ */
+static inline void mark_tsc_unstable(char *reason)
+{
+}
+
+/*
+ * Currently simply use the tsc_is_sync value.
+ */
+static inline int unsynchronized_tsc(void)
+{
+	return !tsc_is_sync();
+}
+
+#ifdef CONFIG_RMI_PHOENIX
+#define ARCH_HAS_READ_CURRENT_TIMER	1
+extern int read_current_timer(unsigned long *timer_val);
+#endif /* CONFIG_RMI_PHOENIX */
 
 #endif /* __KERNEL__ */
 
diff --git a/arch/mips/kernel/Makefile b/arch/mips/kernel/Makefile
index 423d871..64b02c2 100644
--- a/arch/mips/kernel/Makefile
+++ b/arch/mips/kernel/Makefile
@@ -42,6 +42,7 @@ obj-$(CONFIG_CPU_R3000)		+= r2300_fpu.o r2300_switch.o
 obj-$(CONFIG_CPU_R6000)		+= r6000_fpu.o r4k_switch.o
 obj-$(CONFIG_CPU_TX39XX)	+= r2300_fpu.o r2300_switch.o
 obj-$(CONFIG_CPU_CAVIUM_OCTEON) += octeon_switch.o
+obj-$(CONFIG_CPU_XLP)		+= r4k_fpu.o r4k_switch.o
 
 obj-$(CONFIG_SMP)		+= smp.o
 obj-$(CONFIG_SMP_UP)		+= smp-up.o
diff --git a/arch/mips/kernel/asm-offsets.c b/arch/mips/kernel/asm-offsets.c
index 0845091..ec7c21e 100644
--- a/arch/mips/kernel/asm-offsets.c
+++ b/arch/mips/kernel/asm-offsets.c
@@ -12,10 +12,12 @@
 #include <linux/types.h>
 #include <linux/sched.h>
 #include <linux/mm.h>
+#include <linux/interrupt.h>
 #include <linux/kbuild.h>
 #include <linux/suspend.h>
 #include <asm/ptrace.h>
 #include <asm/processor.h>
+#include <asm/mach-netlogic/mmzone.h>
 
 #include <linux/kvm_host.h>
 
@@ -70,6 +72,14 @@ void output_ptreg_defines(void)
 	OFFSET(PT_MPL, pt_regs, mpl);
 	OFFSET(PT_MTP, pt_regs, mtp);
 #endif /* CONFIG_CPU_CAVIUM_OCTEON */
+
+#ifdef XLP_MERGE_TODO /*CONFIG_RMI_XLP_SIM*/
+	OFFSET("#define PT_CRC_POLY_0 ", pt_regs, crc_poly_0);
+	OFFSET("#define PT_CRC_POLY_1 ", pt_regs, crc_poly_1);
+	OFFSET("#define PT_CRC_POLY_2 ", pt_regs, crc_poly_2);
+	OFFSET("#define PT_CRC_POLY_3 ", pt_regs, crc_poly_3);
+#endif /* CONFIG_RMI_XLP_SIM */
+
 	DEFINE(PT_SIZE, sizeof(struct pt_regs));
 	BLANK();
 }
@@ -127,6 +137,10 @@ void output_thread_defines(void)
 	       thread.cp0_baduaddr);
 	OFFSET(THREAD_ECODE, task_struct, \
 	       thread.error_code);
+	OFFSET(THREAD_TRAMP, task_struct, \
+	       thread.irix_trampoline);
+	OFFSET(THREAD_OLDCTX, task_struct, \
+	       thread.irix_oldctx);
 	BLANK();
 }
 
@@ -292,6 +306,15 @@ void output_signal_defined(void)
 	BLANK();
 }
 
+void output_irq_cpustat_t_defines(void)
+{
+	COMMENT("Linux irq_cpustat_t offsets.");
+	DEFINE(IC_SOFTIRQ_PENDING,
+			offsetof(irq_cpustat_t, __softirq_pending));
+	DEFINE(IC_IRQ_CPUSTAT_T, sizeof(irq_cpustat_t));
+	BLANK();
+}
+
 #ifdef CONFIG_CPU_CAVIUM_OCTEON
 void output_octeon_cop2_state_defines(void)
 {
diff --git a/arch/mips/kernel/binfmt_elfn32.c b/arch/mips/kernel/binfmt_elfn32.c
index 1188e00..7497361 100644
--- a/arch/mips/kernel/binfmt_elfn32.c
+++ b/arch/mips/kernel/binfmt_elfn32.c
@@ -6,7 +6,7 @@
  *
  * Heavily inspired by the 32-bit Sparc compat code which is
  * Copyright (C) 1995, 1996, 1997, 1998 David S. Miller (davem@redhat.com)
- * Copyright (C) 1995, 1996, 1997, 1998 Jakub Jelinek	(jj@ultra.linux.cz)
+ * Copyright (C) 1995, 1996, 1997, 1998 Jakub Jelinek   (jj@ultra.linux.cz)
  */
 
 #define ELF_ARCH		EM_MIPS
@@ -48,7 +48,7 @@ typedef elf_fpreg_t elf_fpregset_t[ELF_NFPREG];
 
 #define TASK32_SIZE		0x7fff8000UL
 #undef ELF_ET_DYN_BASE
-#define ELF_ET_DYN_BASE		(TASK32_SIZE / 3 * 2)
+#define ELF_ET_DYN_BASE         (TASK32_SIZE / 3 * 2)
 
 #include <asm/processor.h>
 #include <linux/module.h>
@@ -67,8 +67,8 @@ struct elf_prstatus32
 	pid_t	pr_ppid;
 	pid_t	pr_pgrp;
 	pid_t	pr_sid;
-	struct compat_timeval pr_utime; /* User time */
-	struct compat_timeval pr_stime; /* System time */
+	struct compat_timeval pr_utime;	/* User time */
+	struct compat_timeval pr_stime;	/* System time */
 	struct compat_timeval pr_cutime;/* Cumulative user time */
 	struct compat_timeval pr_cstime;/* Cumulative system time */
 	elf_gregset_t pr_reg;	/* GP registers */
@@ -88,7 +88,7 @@ struct elf_prpsinfo32
 	pid_t	pr_pid, pr_ppid, pr_pgrp, pr_sid;
 	/* Lots missing */
 	char	pr_fname[16];	/* filename of executable */
-	char	pr_psargs[ELF_PRARGSZ]; /* initial part of arg list */
+	char	pr_psargs[ELF_PRARGSZ];	/* initial part of arg list */
 };
 
 #define elf_caddr_t	u32
@@ -108,6 +108,28 @@ jiffies_to_compat_timeval(unsigned long jiffies, struct compat_timeval *value)
 	value->tv_usec = rem / NSEC_PER_USEC;
 }
 
+#ifdef CONFIG_MICROSTATE_ACCT
+#ifdef cputime_to_timeval
+#undef cputime_to_timeval
+#endif
+#define cputime_to_timeval(__ct, __val) (*(__val) = ns_to_timeval_compat(__ct))
+
+/*
+ * ns_to_timeval_compat - same as ns_to_timeval, except
+ * it returns struct compat_timeval.
+ */
+static struct compat_timeval ns_to_timeval_compat(const s64 nsec)
+{
+       struct timespec ts = ns_to_timespec(nsec);
+       struct compat_timeval tv;
+
+       tv.tv_sec = ts.tv_sec;
+       tv.tv_usec = (suseconds_t) ts.tv_nsec / 1000;
+
+       return tv;
+}
+#endif
+
 #define ELF_CORE_EFLAGS EF_MIPS_ABI2
 
 MODULE_DESCRIPTION("Binary format loader for compatibility with n32 Linux/MIPS binaries");
@@ -119,15 +141,4 @@ MODULE_AUTHOR("Ralf Baechle (ralf@linux-mips.org)");
 #undef TASK_SIZE
 #define TASK_SIZE TASK_SIZE32
 
-#undef cputime_to_timeval
-#define cputime_to_timeval cputime_to_compat_timeval
-static __inline__ void
-cputime_to_compat_timeval(const cputime_t cputime, struct compat_timeval *value)
-{
-	unsigned long jiffies = cputime_to_jiffies(cputime);
-
-	value->tv_usec = (jiffies % HZ) * (1000000L / HZ);
-	value->tv_sec = jiffies / HZ;
-}
-
 #include "../../../fs/binfmt_elf.c"
diff --git a/arch/mips/kernel/binfmt_elfo32.c b/arch/mips/kernel/binfmt_elfo32.c
index 202e581..0eb66e7 100644
--- a/arch/mips/kernel/binfmt_elfo32.c
+++ b/arch/mips/kernel/binfmt_elfo32.c
@@ -6,7 +6,7 @@
  *
  * Heavily inspired by the 32-bit Sparc compat code which is
  * Copyright (C) 1995, 1996, 1997, 1998 David S. Miller (davem@redhat.com)
- * Copyright (C) 1995, 1996, 1997, 1998 Jakub Jelinek	(jj@ultra.linux.cz)
+ * Copyright (C) 1995, 1996, 1997, 1998 Jakub Jelinek   (jj@ultra.linux.cz)
  */
 
 #define ELF_ARCH		EM_MIPS
@@ -48,13 +48,17 @@ typedef elf_fpreg_t elf_fpregset_t[ELF_NFPREG];
 	__res;								\
 })
 
-#ifdef CONFIG_KVM_GUEST
-#define TASK32_SIZE		0x3fff8000UL
+#ifdef CONFIG_NLM_XLP
+/*
+ * XLP_MERGE_TODO: changed TASK_SIZE from 0x7fff8000UL to 0x7fff0000UL
+ * to fix page alignment of initial stack (vm_start) for 64KB pages
+ */
+#define TASK32_SIZE		0x7fff0000UL
 #else
 #define TASK32_SIZE		0x7fff8000UL
 #endif
 #undef ELF_ET_DYN_BASE
-#define ELF_ET_DYN_BASE		(TASK32_SIZE / 3 * 2)
+#define ELF_ET_DYN_BASE         (TASK32_SIZE / 3 * 2)
 
 #include <asm/processor.h>
 
@@ -90,8 +94,8 @@ struct elf_prstatus32
 	pid_t	pr_ppid;
 	pid_t	pr_pgrp;
 	pid_t	pr_sid;
-	struct compat_timeval pr_utime; /* User time */
-	struct compat_timeval pr_stime; /* System time */
+	struct compat_timeval pr_utime;	/* User time */
+	struct compat_timeval pr_stime;	/* System time */
 	struct compat_timeval pr_cutime;/* Cumulative user time */
 	struct compat_timeval pr_cstime;/* Cumulative system time */
 	elf_gregset_t pr_reg;	/* GP registers */
@@ -111,7 +115,7 @@ struct elf_prpsinfo32
 	pid_t	pr_pid, pr_ppid, pr_pgrp, pr_sid;
 	/* Lots missing */
 	char	pr_fname[16];	/* filename of executable */
-	char	pr_psargs[ELF_PRARGSZ]; /* initial part of arg list */
+	char	pr_psargs[ELF_PRARGSZ];	/* initial part of arg list */
 };
 
 #define elf_caddr_t	u32
@@ -131,6 +135,28 @@ jiffies_to_compat_timeval(unsigned long jiffies, struct compat_timeval *value)
 	value->tv_usec = rem / NSEC_PER_USEC;
 }
 
+#ifdef CONFIG_MICROSTATE_ACCT
+#ifdef cputime_to_timeval
+#undef cputime_to_timeval
+#endif
+#define cputime_to_timeval(__ct, __val) (*(__val) = ns_to_timeval_compat(__ct))
+
+/*
+ * ns_to_timeval_compat - same as ns_to_timeval, except
+ * it returns struct compat_timeval.
+ */
+static struct compat_timeval ns_to_timeval_compat(const s64 nsec)
+{
+	struct timespec ts = ns_to_timespec(nsec);
+	struct compat_timeval tv;
+
+	tv.tv_sec = ts.tv_sec;
+	tv.tv_usec = (suseconds_t) ts.tv_nsec / 1000;
+
+	return tv;
+}
+#endif
+
 void elf32_core_copy_regs(elf_gregset_t grp, struct pt_regs *regs)
 {
 	int i;
@@ -162,15 +188,4 @@ MODULE_AUTHOR("Ralf Baechle (ralf@linux-mips.org)");
 #undef TASK_SIZE
 #define TASK_SIZE TASK_SIZE32
 
-#undef cputime_to_timeval
-#define cputime_to_timeval cputime_to_compat_timeval
-static __inline__ void
-cputime_to_compat_timeval(const cputime_t cputime, struct compat_timeval *value)
-{
-	unsigned long jiffies = cputime_to_jiffies(cputime);
-
-	value->tv_usec = (jiffies % HZ) * (1000000L / HZ);
-	value->tv_sec = jiffies / HZ;
-}
-
 #include "../../../fs/binfmt_elf.c"
diff --git a/arch/mips/kernel/bmips_vec.S b/arch/mips/kernel/bmips_vec.S
index 64c4fd6..e908e81 100644
--- a/arch/mips/kernel/bmips_vec.S
+++ b/arch/mips/kernel/bmips_vec.S
@@ -170,7 +170,7 @@ bmips_smp_entry:
 
 	/* switch to permanent stack and continue booting */
 
-	.global bmips_secondary_reentry
+	.global	bmips_secondary_reentry
 bmips_secondary_reentry:
 	la	k0, bmips_smp_boot_sp
 	lw	sp, 0(k0)
@@ -182,7 +182,7 @@ bmips_secondary_reentry:
 #endif /* CONFIG_SMP */
 
 	.align	4
-	.global bmips_reset_nmi_vec_end
+	.global	bmips_reset_nmi_vec_end
 bmips_reset_nmi_vec_end:
 
 END(bmips_reset_nmi_vec)
@@ -206,7 +206,7 @@ LEAF(bmips_smp_int_vec)
 	eret
 
 	.align	4
-	.global bmips_smp_int_vec_end
+	.global	bmips_smp_int_vec_end
 bmips_smp_int_vec_end:
 
 END(bmips_smp_int_vec)
diff --git a/arch/mips/kernel/cevt-r4k.c b/arch/mips/kernel/cevt-r4k.c
index 02033ea..51095dd9 100644
--- a/arch/mips/kernel/cevt-r4k.c
+++ b/arch/mips/kernel/cevt-r4k.c
@@ -15,7 +15,6 @@
 #include <asm/smtc_ipi.h>
 #include <asm/time.h>
 #include <asm/cevt-r4k.h>
-#include <asm/gic.h>
 
 /*
  * The SMTC Kernel for the 34K, 1004K, et. al. replaces several
@@ -23,8 +22,9 @@
  */
 
 #ifndef CONFIG_MIPS_MT_SMTC
+
 static int mips_next_event(unsigned long delta,
-			   struct clock_event_device *evt)
+                           struct clock_event_device *evt)
 {
 	unsigned int cnt;
 	int res;
@@ -48,6 +48,7 @@ DEFINE_PER_CPU(struct clock_event_device, mips_clockevent_device);
 int cp0_timer_irq_installed;
 
 #ifndef CONFIG_MIPS_MT_SMTC
+
 irqreturn_t c0_compare_interrupt(int irq, void *dev_id)
 {
 	const int r2 = cpu_has_mips_r2;
@@ -64,7 +65,7 @@ irqreturn_t c0_compare_interrupt(int irq, void *dev_id)
 		goto out;
 
 	/*
-	 * The same applies to performance counter interrupts.	But with the
+	 * The same applies to performance counter interrupts.  But with the
 	 * above we now know that the reason we got here must be a timer
 	 * interrupt.  Being the paranoiacs we are we check anyway.
 	 */
@@ -72,9 +73,6 @@ irqreturn_t c0_compare_interrupt(int irq, void *dev_id)
 		/* Clear Count/Compare Interrupt */
 		write_c0_compare(read_c0_compare());
 		cd = &per_cpu(mips_clockevent_device, cpu);
-#ifdef CONFIG_CEVT_GIC
-		if (!gic_present)
-#endif
 		cd->event_handler(cd);
 	}
 
@@ -100,10 +98,6 @@ void mips_event_handler(struct clock_event_device *dev)
  */
 static int c0_compare_int_pending(void)
 {
-#ifdef CONFIG_IRQ_GIC
-	if (cpu_has_veic)
-		return gic_get_timer_pending();
-#endif
 	return (read_c0_cause() >> cp0_compare_irq_shift) & (1ul << CAUSEB_IP);
 }
 
@@ -119,12 +113,8 @@ int c0_compare_int_usable(void)
 	unsigned int delta;
 	unsigned int cnt;
 
-#ifdef CONFIG_KVM_GUEST
-    return 1;
-#endif
-
 	/*
-	 * IP7 already pending?	 Try to clear it by acking the timer.
+	 * IP7 already pending?  Try to clear it by acking the timer.
 	 */
 	if (c0_compare_int_pending()) {
 		cnt = read_c0_count();
@@ -171,6 +161,7 @@ int c0_compare_int_usable(void)
 }
 
 #ifndef CONFIG_MIPS_MT_SMTC
+
 int __cpuinit r4k_clockevent_init(void)
 {
 	unsigned int cpu = smp_processor_id();
@@ -210,9 +201,6 @@ int __cpuinit r4k_clockevent_init(void)
 	cd->set_mode		= mips_set_clock_mode;
 	cd->event_handler	= mips_event_handler;
 
-#ifdef CONFIG_CEVT_GIC
-	if (!gic_present)
-#endif
 	clockevents_register_device(cd);
 
 	if (cp0_timer_irq_installed)
diff --git a/arch/mips/kernel/cpu-bugs64.c b/arch/mips/kernel/cpu-bugs64.c
index de3c25f..d6a1864 100644
--- a/arch/mips/kernel/cpu-bugs64.c
+++ b/arch/mips/kernel/cpu-bugs64.c
@@ -84,9 +84,9 @@ static inline void mult_sh_align_mod(long *v1, long *v2, long *w,
 		".set	noreorder\n\t"
 		".set	nomacro\n\t"
 		"mult	%2, %3\n\t"
-		"dsll32 %0, %4, %5\n\t"
+		"dsll32	%0, %4, %5\n\t"
 		"mflo	$0\n\t"
-		"dsll32 %1, %4, %5\n\t"
+		"dsll32	%1, %4, %5\n\t"
 		"nop\n\t"
 		".set	pop"
 		: "=&r" (lv1), "=r" (lw)
@@ -239,7 +239,7 @@ static inline void check_daddi(void)
 	panic(bug64hit, !DADDI_WAR ? daddiwar : nowar);
 }
 
-int daddiu_bug	= -1;
+int daddiu_bug  = -1;
 
 static inline void check_daddiu(void)
 {
@@ -273,7 +273,7 @@ static inline void check_daddiu(void)
 #ifdef HAVE_AS_SET_DADDI
 		".set	daddi\n\t"
 #endif
-		"daddiu %0, %2, %4\n\t"
+		"daddiu	%0, %2, %4\n\t"
 		"addiu	%1, $0, %4\n\t"
 		"daddu	%1, %2\n\t"
 		".set	pop"
@@ -292,7 +292,7 @@ static inline void check_daddiu(void)
 	asm volatile(
 		"addiu	%2, $0, %3\n\t"
 		"dsrl	%2, %2, 1\n\t"
-		"daddiu %0, %2, %4\n\t"
+		"daddiu	%0, %2, %4\n\t"
 		"addiu	%1, $0, %4\n\t"
 		"daddu	%1, %2"
 		: "=&r" (v), "=&r" (w), "=&r" (tmp)
diff --git a/arch/mips/kernel/ftrace.c b/arch/mips/kernel/ftrace.c
index dba90ec..6a2d758 100644
--- a/arch/mips/kernel/ftrace.c
+++ b/arch/mips/kernel/ftrace.c
@@ -25,16 +25,6 @@
 #define MCOUNT_OFFSET_INSNS 4
 #endif
 
-#ifdef CONFIG_DYNAMIC_FTRACE
-
-/* Arch override because MIPS doesn't need to run this from stop_machine() */
-void arch_ftrace_update_code(int command)
-{
-	ftrace_modify_all_code(command);
-}
-
-#endif
-
 /*
  * Check if the address is in kernel space
  *
@@ -99,24 +89,6 @@ static int ftrace_modify_code(unsigned long ip, unsigned int new_code)
 	return 0;
 }
 
-#ifndef CONFIG_64BIT
-static int ftrace_modify_code_2(unsigned long ip, unsigned int new_code1,
-				unsigned int new_code2)
-{
-	int faulted;
-
-	safe_store_code(new_code1, ip, faulted);
-	if (unlikely(faulted))
-		return -EFAULT;
-	ip += 4;
-	safe_store_code(new_code2, ip, faulted);
-	if (unlikely(faulted))
-		return -EFAULT;
-	flush_icache_range(ip, ip + 8); /* original ip + 12 */
-	return 0;
-}
-#endif
-
 /*
  * The details about the calling site of mcount on MIPS
  *
@@ -129,21 +101,21 @@ static int ftrace_modify_code_2(unsigned long ip, unsigned int new_code1,
  *
  * 2.1 For KBUILD_MCOUNT_RA_ADDRESS and CONFIG_32BIT
  *
- * lui v1, hi_16bit_of_mcount	     --> b 1f (0x10000005)
+ * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000005)
  * addiu v1, v1, low_16bit_of_mcount
  * move at, ra
  * move $12, ra_address
  * jalr v1
  *  sub sp, sp, 8
- *				    1: offset = 5 instructions
+ *                                  1: offset = 5 instructions
  * 2.2 For the Other situations
  *
- * lui v1, hi_16bit_of_mcount	     --> b 1f (0x10000004)
+ * lui v1, hi_16bit_of_mcount        --> b 1f (0x10000004)
  * addiu v1, v1, low_16bit_of_mcount
  * move at, ra
  * jalr v1
  *  nop | move $12, ra_address | sub sp, sp, 8
- *				    1: offset = 4 instructions
+ *                                  1: offset = 4 instructions
  */
 
 #define INSN_B_1F (0x10000000 | MCOUNT_OFFSET_INSNS)
@@ -159,18 +131,8 @@ int ftrace_make_nop(struct module *mod,
 	 * needed.
 	 */
 	new = in_kernel_space(ip) ? INSN_NOP : INSN_B_1F;
-#ifdef CONFIG_64BIT
+
 	return ftrace_modify_code(ip, new);
-#else
-	/*
-	 * On 32 bit MIPS platforms, gcc adds a stack adjust
-	 * instruction in the delay slot after the branch to
-	 * mcount and expects mcount to restore the sp on return.
-	 * This is based on a legacy API and does nothing but
-	 * waste instructions so it's being removed at runtime.
-	 */
-	return ftrace_modify_code_2(ip, new, INSN_NOP);
-#endif
 }
 
 int ftrace_make_call(struct dyn_ftrace *rec, unsigned long addr)
@@ -232,8 +194,8 @@ int ftrace_disable_ftrace_graph_caller(void)
 
 #ifndef KBUILD_MCOUNT_RA_ADDRESS
 
-#define S_RA_SP (0xafbf << 16)	/* s{d,w} ra, offset(sp) */
-#define S_R_SP	(0xafb0 << 16)	/* s{d,w} R, offset(sp) */
+#define S_RA_SP	(0xafbf << 16)	/* s{d,w} ra, offset(sp) */
+#define S_R_SP	(0xafb0 << 16)  /* s{d,w} R, offset(sp) */
 #define OFFSET_MASK	0xffff	/* stack offset range: 0 ~ PT_SIZE */
 
 unsigned long ftrace_get_parent_ra_addr(unsigned long self_ra, unsigned long
diff --git a/arch/mips/kernel/head.S b/arch/mips/kernel/head.S
index c61cdae..8ea21b0 100644
--- a/arch/mips/kernel/head.S
+++ b/arch/mips/kernel/head.S
@@ -21,51 +21,14 @@
 #include <asm/asmmacro.h>
 #include <asm/irqflags.h>
 #include <asm/regdef.h>
+#include <asm/page.h>
 #include <asm/pgtable-bits.h>
 #include <asm/mipsregs.h>
 #include <asm/stackframe.h>
 
-#include <kernel-entry-init.h>
-
-	/*
-	 * inputs are the text nasid in t1, data nasid in t2.
-	 */
-	.macro MAPPED_KERNEL_SETUP_TLB
-#ifdef CONFIG_MAPPED_KERNEL
-	/*
-	 * This needs to read the nasid - assume 0 for now.
-	 * Drop in 0xffffffffc0000000 in tlbhi, 0+VG in tlblo_0,
-	 * 0+DVG in tlblo_1.
-	 */
-	dli	t0, 0xffffffffc0000000
-	dmtc0	t0, CP0_ENTRYHI
-	li	t0, 0x1c000		# Offset of text into node memory
-	dsll	t1, NASID_SHFT		# Shift text nasid into place
-	dsll	t2, NASID_SHFT		# Same for data nasid
-	or	t1, t1, t0		# Physical load address of kernel text
-	or	t2, t2, t0		# Physical load address of kernel data
-	dsrl	t1, 12			# 4K pfn
-	dsrl	t2, 12			# 4K pfn
-	dsll	t1, 6			# Get pfn into place
-	dsll	t2, 6			# Get pfn into place
-	li	t0, ((_PAGE_GLOBAL|_PAGE_VALID| _CACHE_CACHABLE_COW) >> 6)
-	or	t0, t0, t1
-	mtc0	t0, CP0_ENTRYLO0	# physaddr, VG, cach exlwr
-	li	t0, ((_PAGE_GLOBAL|_PAGE_VALID| _PAGE_DIRTY|_CACHE_CACHABLE_COW) >> 6)
-	or	t0, t0, t2
-	mtc0	t0, CP0_ENTRYLO1	# physaddr, DVG, cach exlwr
-	li	t0, 0x1ffe000		# MAPPED_KERN_TLBMASK, TLBPGMASK_16M
-	mtc0	t0, CP0_PAGEMASK
-	li	t0, 0			# KMAP_INX
-	mtc0	t0, CP0_INDEX
-	li	t0, 1
-	mtc0	t0, CP0_WIRED
-	tlbwi
-#else
-	mtc0	zero, CP0_WIRED
-#endif
-	.endm
-
+#include <asm/mach-rmi/kernel-entry-init.h>
+#include <asm/mach-generic/kernel-entry-init.h>
+		
 	/*
 	 * For the moment disable interrupts, mark the kernel mode and
 	 * set ST0_KX so that the CPU does not spit fire when using
@@ -133,7 +96,7 @@ EXPORT(_stext)
 #ifdef CONFIG_BOOT_RAW
 	/*
 	 * Give us a fighting chance of running if execution beings at the
-	 * kernel load address.	 This is needed because this platform does
+	 * kernel load address.  This is needed because this platform does
 	 * not have a ELF loader yet.
 	 */
 FEXPORT(__kernel_entry)
@@ -144,6 +107,8 @@ FEXPORT(__kernel_entry)
 
 NESTED(kernel_entry, 16, sp)			# kernel entry point
 
+	MAPPED_KERNEL_SETUP_TLB
+
 	kernel_entry_setup			# cpu specific setup
 
 	setup_c0_status_pri
@@ -201,7 +166,7 @@ NESTED(kernel_entry, 16, sp)			# kernel entry point
 
 #ifdef CONFIG_SMP
 /*
- * SMP slave cpus entry point.	Board specific code for bootstrap calls this
+ * SMP slave cpus entry point.  Board specific code for bootstrap calls this
  * function after setting up the stack and gp registers.
  */
 NESTED(smp_bootstrap, 16, sp)
diff --git a/arch/mips/kernel/i8259.c b/arch/mips/kernel/i8259.c
index 2b91fe8..32b397b 100644
--- a/arch/mips/kernel/i8259.c
+++ b/arch/mips/kernel/i8259.c
@@ -178,7 +178,7 @@ handle_real_irq:
 	} else {
 		inb(PIC_MASTER_IMR);	/* DUMMY - (do we need this?) */
 		outb(cached_master_mask, PIC_MASTER_IMR);
-		outb(0x60+irq, PIC_MASTER_CMD); /* 'Specific EOI to master */
+		outb(0x60+irq, PIC_MASTER_CMD);	/* 'Specific EOI to master */
 	}
 	smtc_im_ack_irq(irq);
 	raw_spin_unlock_irqrestore(&i8259A_lock, flags);
diff --git a/arch/mips/kernel/init_task.c b/arch/mips/kernel/init_task.c
new file mode 100644
index 0000000..5f9a762
--- /dev/null
+++ b/arch/mips/kernel/init_task.c
@@ -0,0 +1,35 @@
+#include <linux/mm.h>
+#include <linux/export.h>
+#include <linux/sched.h>
+#include <linux/init_task.h>
+#include <linux/fs.h>
+#include <linux/mqueue.h>
+
+#include <asm/thread_info.h>
+#include <asm/uaccess.h>
+#include <asm/pgtable.h>
+
+static struct signal_struct init_signals = INIT_SIGNALS(init_signals);
+static struct sighand_struct init_sighand = INIT_SIGHAND(init_sighand);
+/*
+ * Initial thread structure.
+ *
+ * We need to make sure that this is 8192-byte aligned due to the
+ * way process stacks are handled. This is done by making sure
+ * the linker maps this in the .text segment right after head.S,
+ * and making head.S ensure the proper alignment.
+ *
+ * The things we do for performance..
+ */
+union thread_union init_thread_union __init_task_data
+	__attribute__((__aligned__(THREAD_SIZE))) =
+		{ INIT_THREAD_INFO(init_task) };
+
+/*
+ * Initial task structure.
+ *
+ * All other task structs will be allocated on slabs in fork.c
+ */
+struct task_struct init_task = INIT_TASK(init_task);
+
+EXPORT_SYMBOL(init_task);
diff --git a/arch/mips/kernel/irq_cpu.c b/arch/mips/kernel/irq_cpu.c
index 72ef2d2..972263b 100644
--- a/arch/mips/kernel/irq_cpu.c
+++ b/arch/mips/kernel/irq_cpu.c
@@ -3,13 +3,13 @@
  * Author: Jun Sun, jsun@mvista.com or jsun@junsun.net
  *
  * Copyright (C) 2001 Ralf Baechle
- * Copyright (C) 2005  MIPS Technologies, Inc.	All rights reserved.
- *	Author: Maciej W. Rozycki <macro@mips.com>
+ * Copyright (C) 2005  MIPS Technologies, Inc.  All rights reserved.
+ *      Author: Maciej W. Rozycki <macro@mips.com>
  *
  * This file define the irq handler for MIPS CPU interrupts.
  *
- * This program is free software; you can redistribute	it and/or modify it
- * under  the terms of	the GNU General	 Public License as published by the
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
  * Free Software Foundation;  either version 2 of the  License, or (at your
  * option) any later version.
  */
@@ -31,7 +31,6 @@
 #include <linux/interrupt.h>
 #include <linux/kernel.h>
 #include <linux/irq.h>
-#include <linux/irqdomain.h>
 
 #include <asm/irq_cpu.h>
 #include <asm/mipsregs.h>
@@ -114,44 +113,3 @@ void __init mips_cpu_irq_init(void)
 		irq_set_chip_and_handler(i, &mips_cpu_irq_controller,
 					 handle_percpu_irq);
 }
-
-#ifdef CONFIG_IRQ_DOMAIN
-static int mips_cpu_intc_map(struct irq_domain *d, unsigned int irq,
-			     irq_hw_number_t hw)
-{
-	static struct irq_chip *chip;
-
-	if (hw < 2 && cpu_has_mipsmt) {
-		/* Software interrupts are used for MT/CMT IPI */
-		chip = &mips_mt_cpu_irq_controller;
-	} else {
-		chip = &mips_cpu_irq_controller;
-	}
-
-	irq_set_chip_and_handler(irq, chip, handle_percpu_irq);
-
-	return 0;
-}
-
-static const struct irq_domain_ops mips_cpu_intc_irq_domain_ops = {
-	.map = mips_cpu_intc_map,
-	.xlate = irq_domain_xlate_onecell,
-};
-
-int __init mips_cpu_intc_init(struct device_node *of_node,
-			      struct device_node *parent)
-{
-	struct irq_domain *domain;
-
-	/* Mask interrupts. */
-	clear_c0_status(ST0_IM);
-	clear_c0_cause(CAUSEF_IP);
-
-	domain = irq_domain_add_legacy(of_node, 8, MIPS_CPU_IRQ_BASE, 0,
-				       &mips_cpu_intc_irq_domain_ops, NULL);
-	if (!domain)
-		panic("Failed to add irqdomain for MIPS CPU\n");
-
-	return 0;
-}
-#endif /* CONFIG_IRQ_DOMAIN */
diff --git a/arch/mips/kernel/kgdb.c b/arch/mips/kernel/kgdb.c
index 81f6100..7fd78e4 100644
--- a/arch/mips/kernel/kgdb.c
+++ b/arch/mips/kernel/kgdb.c
@@ -234,11 +234,45 @@ static void kgdb_call_nmi_hook(void *ignored)
 	kgdb_nmicallback(raw_smp_processor_id(), NULL);
 }
 
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/interrupt.h>
+spinlock_t rmi_kgdb_lock = SPIN_LOCK_UNLOCKED;
+
+void rmi_kgdb_smp_hook(void)
+{
+	int i;
+	int cpu = smp_processor_id();
+	int cpus = num_online_cpus() - 1;
+	unsigned long flags;
+
+	BUG_ON(!cpu_online(cpu));
+
+	if (!cpus)
+		return;
+
+	spin_lock_irqsave(&rmi_kgdb_lock, flags);
+	for (i = 0; i < NR_CPUS; i++)
+		if (cpu_online(i) && i != cpu)
+			core_send_ipi(i, SMP_CALL_KGDB_HOOK);
+	spin_unlock_irqrestore(&rmi_kgdb_lock, flags);
+}
+
+void rmi_kgdb_call_nmi_hook(void)
+{
+	kgdb_nmicallback(raw_smp_processor_id(), NULL);
+}
+#endif
+
 void kgdb_roundup_cpus(unsigned long flags)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_kgdb_smp_hook();
+	return;
+#else
 	local_irq_enable();
 	smp_call_function(kgdb_call_nmi_hook, NULL, 0);
 	local_irq_disable();
+#endif
 }
 
 static int compute_signal(int tt)
@@ -295,6 +329,27 @@ void kgdb_arch_set_pc(struct pt_regs *regs, unsigned long pc)
 	regs->cp0_epc = pc;
 }
 
+extern void phoenix_flush_l1_icache_ipi(void *);
+extern void phoenix_flush_l1_caches_ipi(void *);
+
+#ifdef CONFIG_RMI_PHOENIX
+irqreturn_t xlr_kgdb_ipi_handler(int irq, struct pt_regs *regs)
+{
+	//int cpu = smp_processor_id();
+	kgdb_call_nmi_hook(NULL);
+
+	phoenix_flush_l1_caches_ipi(NULL);
+#if 0
+	if(g_xlr_kgdb[cpu]) {
+		g_xlr_kgdb[cpu] = 0;
+		kgdb_call_nmi_hook(NULL);
+	}
+#endif
+
+	return IRQ_HANDLED;
+}
+#endif
+
 /*
  * Calls linux_debug_hook before the kernel dies. If KGDB is enabled,
  * then try to fall into the debugger
@@ -380,8 +435,12 @@ static int kgdb_mips_notify(struct notifier_block *self, unsigned long cmd,
 			regs->cp0_epc += 4;
 
 	/* In SMP mode, __flush_cache_all does IPI */
+#ifdef CONFIG_RMI_PHOENIX
+	phoenix_flush_l1_icache_ipi(NULL);
+#else
 	local_irq_enable();
 	__flush_cache_all();
+#endif
 
 	return NOTIFY_STOP;
 }
diff --git a/arch/mips/kernel/kspd.c b/arch/mips/kernel/kspd.c
new file mode 100644
index 0000000..b77f56b
--- /dev/null
+++ b/arch/mips/kernel/kspd.c
@@ -0,0 +1,423 @@
+/*
+ * Copyright (C) 2005 MIPS Technologies, Inc.  All rights reserved.
+ *
+ *  This program is free software; you can distribute it and/or modify it
+ *  under the terms of the GNU General Public License (Version 2) as
+ *  published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ *  for more details.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
+ *
+ */
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/sched.h>
+#include <linux/unistd.h>
+#include <linux/file.h>
+#include <linux/fdtable.h>
+#include <linux/fs.h>
+#include <linux/syscalls.h>
+#include <linux/workqueue.h>
+#include <linux/errno.h>
+#include <linux/list.h>
+
+#include <asm/vpe.h>
+#include <asm/rtlx.h>
+#include <asm/kspd.h>
+
+static struct workqueue_struct *workqueue;
+static struct work_struct work;
+
+extern unsigned long cpu_khz;
+
+struct mtsp_syscall {
+	int cmd;
+	unsigned char abi;
+	unsigned char size;
+};
+
+struct mtsp_syscall_ret {
+	int retval;
+	int errno;
+};
+
+struct mtsp_syscall_generic {
+	int arg0;
+	int arg1;
+	int arg2;
+	int arg3;
+	int arg4;
+	int arg5;
+	int arg6;
+};
+
+static struct list_head kspd_notifylist;
+static int sp_stopping;
+
+/* these should match with those in the SDE kit */
+#define MTSP_SYSCALL_BASE	0
+#define MTSP_SYSCALL_EXIT	(MTSP_SYSCALL_BASE + 0)
+#define MTSP_SYSCALL_OPEN	(MTSP_SYSCALL_BASE + 1)
+#define MTSP_SYSCALL_READ	(MTSP_SYSCALL_BASE + 2)
+#define MTSP_SYSCALL_WRITE	(MTSP_SYSCALL_BASE + 3)
+#define MTSP_SYSCALL_CLOSE	(MTSP_SYSCALL_BASE + 4)
+#define MTSP_SYSCALL_LSEEK32	(MTSP_SYSCALL_BASE + 5)
+#define MTSP_SYSCALL_ISATTY	(MTSP_SYSCALL_BASE + 6)
+#define MTSP_SYSCALL_GETTIME	(MTSP_SYSCALL_BASE + 7)
+#define MTSP_SYSCALL_PIPEFREQ	(MTSP_SYSCALL_BASE + 8)
+#define MTSP_SYSCALL_GETTOD	(MTSP_SYSCALL_BASE + 9)
+#define MTSP_SYSCALL_IOCTL     (MTSP_SYSCALL_BASE + 10)
+
+#define MTSP_O_RDONLY		0x0000
+#define MTSP_O_WRONLY		0x0001
+#define MTSP_O_RDWR		0x0002
+#define MTSP_O_NONBLOCK		0x0004
+#define MTSP_O_APPEND		0x0008
+#define MTSP_O_SHLOCK		0x0010
+#define MTSP_O_EXLOCK		0x0020
+#define MTSP_O_ASYNC		0x0040
+/* XXX: check which of these is actually O_SYNC vs O_DSYNC */
+#define MTSP_O_FSYNC		O_SYNC
+#define MTSP_O_NOFOLLOW		0x0100
+#define MTSP_O_SYNC		0x0080
+#define MTSP_O_CREAT		0x0200
+#define MTSP_O_TRUNC		0x0400
+#define MTSP_O_EXCL		0x0800
+#define MTSP_O_BINARY		0x8000
+
+extern int tclimit;
+
+struct apsp_table  {
+	int sp;
+	int ap;
+};
+
+/* we might want to do the mode flags too */
+struct apsp_table open_flags_table[] = {
+	{ MTSP_O_RDWR, O_RDWR },
+	{ MTSP_O_WRONLY, O_WRONLY },
+	{ MTSP_O_CREAT, O_CREAT },
+	{ MTSP_O_TRUNC, O_TRUNC },
+	{ MTSP_O_NONBLOCK, O_NONBLOCK },
+	{ MTSP_O_APPEND, O_APPEND },
+	{ MTSP_O_NOFOLLOW, O_NOFOLLOW }
+};
+
+struct apsp_table syscall_command_table[] = {
+	{ MTSP_SYSCALL_OPEN, __NR_open },
+	{ MTSP_SYSCALL_CLOSE, __NR_close },
+	{ MTSP_SYSCALL_READ, __NR_read },
+	{ MTSP_SYSCALL_WRITE, __NR_write },
+	{ MTSP_SYSCALL_LSEEK32, __NR_lseek },
+	{ MTSP_SYSCALL_IOCTL, __NR_ioctl }
+};
+
+static int sp_syscall(int num, int arg0, int arg1, int arg2, int arg3)
+{
+	register long int _num  __asm__("$2") = num;
+	register long int _arg0  __asm__("$4") = arg0;
+	register long int _arg1  __asm__("$5") = arg1;
+	register long int _arg2  __asm__("$6") = arg2;
+	register long int _arg3  __asm__("$7") = arg3;
+
+	mm_segment_t old_fs;
+
+	old_fs = get_fs();
+ 	set_fs(KERNEL_DS);
+
+  	__asm__ __volatile__ (
+ 	"	syscall					\n"
+ 	: "=r" (_num), "=r" (_arg3)
+ 	: "r" (_num), "r" (_arg0), "r" (_arg1), "r" (_arg2), "r" (_arg3));
+
+	set_fs(old_fs);
+
+	/* $a3 is error flag */
+	if (_arg3)
+		return -_num;
+
+	return _num;
+}
+
+static int translate_syscall_command(int cmd)
+{
+	int i;
+	int ret = -1;
+
+	for (i = 0; i < ARRAY_SIZE(syscall_command_table); i++) {
+		if ((cmd == syscall_command_table[i].sp))
+			return syscall_command_table[i].ap;
+	}
+
+	return ret;
+}
+
+static unsigned int translate_open_flags(int flags)
+{
+	int i;
+	unsigned int ret = 0;
+
+	for (i = 0; i < ARRAY_SIZE(open_flags_table); i++) {
+		if( (flags & open_flags_table[i].sp) ) {
+			ret |= open_flags_table[i].ap;
+		}
+	}
+
+	return ret;
+}
+
+
+static int sp_setfsuidgid(uid_t uid, gid_t gid)
+{
+	struct cred *new;
+
+	new = prepare_creds();
+	if (!new)
+		return -ENOMEM;
+
+	new->fsuid = uid;
+	new->fsgid = gid;
+
+	commit_creds(new);
+
+	return 0;
+}
+
+/*
+ * Expects a request to be on the sysio channel. Reads it.  Decides whether
+ * its a linux syscall and runs it, or whatever.  Puts the return code back
+ * into the request and sends the whole thing back.
+ */
+void sp_work_handle_request(void)
+{
+	struct mtsp_syscall sc;
+	struct mtsp_syscall_generic generic;
+	struct mtsp_syscall_ret ret;
+	struct kspd_notifications *n;
+	unsigned long written;
+	mm_segment_t old_fs;
+	struct timeval tv;
+	struct timezone tz;
+	int err, cmd;
+
+	char *vcwd;
+	int size;
+
+	ret.retval = -1;
+
+	old_fs = get_fs();
+	set_fs(KERNEL_DS);
+
+	if (!rtlx_read(RTLX_CHANNEL_SYSIO, &sc, sizeof(struct mtsp_syscall))) {
+		set_fs(old_fs);
+		printk(KERN_ERR "Expected request but nothing to read\n");
+		return;
+	}
+
+	size = sc.size;
+
+	if (size) {
+		if (!rtlx_read(RTLX_CHANNEL_SYSIO, &generic, size)) {
+			set_fs(old_fs);
+			printk(KERN_ERR "Expected request but nothing to read\n");
+			return;
+		}
+	}
+
+	/* Run the syscall at the privilege of the user who loaded the
+	   SP program */
+
+	if (vpe_getuid(tclimit)) {
+		err = sp_setfsuidgid(vpe_getuid(tclimit), vpe_getgid(tclimit));
+		if (!err)
+			pr_err("Change of creds failed\n");
+	}
+
+	switch (sc.cmd) {
+	/* needs the flags argument translating from SDE kit to
+	   linux */
+ 	case MTSP_SYSCALL_PIPEFREQ:
+ 		ret.retval = cpu_khz * 1000;
+ 		ret.errno = 0;
+ 		break;
+
+ 	case MTSP_SYSCALL_GETTOD:
+ 		memset(&tz, 0, sizeof(tz));
+ 		if ((ret.retval = sp_syscall(__NR_gettimeofday, (int)&tv,
+					     (int)&tz, 0, 0)) == 0)
+			ret.retval = tv.tv_sec;
+		break;
+
+ 	case MTSP_SYSCALL_EXIT:
+		list_for_each_entry(n, &kspd_notifylist, list)
+			n->kspd_sp_exit(tclimit);
+		sp_stopping = 1;
+
+		printk(KERN_DEBUG "KSPD got exit syscall from SP exitcode %d\n",
+		       generic.arg0);
+ 		break;
+
+ 	case MTSP_SYSCALL_OPEN:
+ 		generic.arg1 = translate_open_flags(generic.arg1);
+
+		vcwd = vpe_getcwd(tclimit);
+
+		/* change to cwd of the process that loaded the SP program */
+		old_fs = get_fs();
+		set_fs(KERNEL_DS);
+		sys_chdir(vcwd);
+		set_fs(old_fs);
+
+ 		sc.cmd = __NR_open;
+
+		/* fall through */
+
+  	default:
+ 		if ((sc.cmd >= __NR_Linux) &&
+		    (sc.cmd <= (__NR_Linux +  __NR_Linux_syscalls)) )
+			cmd = sc.cmd;
+		else
+			cmd = translate_syscall_command(sc.cmd);
+
+		if (cmd >= 0) {
+			ret.retval = sp_syscall(cmd, generic.arg0, generic.arg1,
+			                        generic.arg2, generic.arg3);
+		} else
+ 			printk(KERN_WARNING
+			       "KSPD: Unknown SP syscall number %d\n", sc.cmd);
+		break;
+ 	} /* switch */
+
+	if (vpe_getuid(tclimit)) {
+		err = sp_setfsuidgid(0, 0);
+		if (!err)
+			pr_err("restoring old creds failed\n");
+	}
+
+	old_fs = get_fs();
+	set_fs(KERNEL_DS);
+	written = rtlx_write(RTLX_CHANNEL_SYSIO, &ret, sizeof(ret));
+	set_fs(old_fs);
+	if (written < sizeof(ret))
+		printk("KSPD: sp_work_handle_request failed to send to SP\n");
+}
+
+static void sp_cleanup(void)
+{
+	struct files_struct *files = current->files;
+	int i, j;
+	struct fdtable *fdt;
+
+	j = 0;
+
+	/*
+	 * It is safe to dereference the fd table without RCU or
+	 * ->file_lock
+	 */
+	fdt = files_fdtable(files);
+	for (;;) {
+		unsigned long set;
+		i = j * BITS_PER_LONG;
+		if (i >= fdt->max_fds)
+			break;
+		set = fdt->open_fds[j++];
+		while (set) {
+			if (set & 1) {
+				struct file * file = xchg(&fdt->fd[i], NULL);
+				if (file)
+					filp_close(file, files);
+			}
+			i++;
+			set >>= 1;
+		}
+	}
+
+	/* Put daemon cwd back to root to avoid umount problems */
+	sys_chdir("/");
+}
+
+static int channel_open;
+
+/* the work handler */
+static void sp_work(struct work_struct *unused)
+{
+	if (!channel_open) {
+		if( rtlx_open(RTLX_CHANNEL_SYSIO, 1) != 0) {
+			printk("KSPD: unable to open sp channel\n");
+			sp_stopping = 1;
+		} else {
+			channel_open++;
+			printk(KERN_DEBUG "KSPD: SP channel opened\n");
+		}
+	} else {
+		/* wait for some data, allow it to sleep */
+		rtlx_read_poll(RTLX_CHANNEL_SYSIO, 1);
+
+		/* Check we haven't been woken because we are stopping */
+		if (!sp_stopping)
+			sp_work_handle_request();
+	}
+
+	if (!sp_stopping)
+		queue_work(workqueue, &work);
+	else
+		sp_cleanup();
+}
+
+static void startwork(int vpe)
+{
+	sp_stopping = channel_open = 0;
+
+	if (workqueue == NULL) {
+		if ((workqueue = create_singlethread_workqueue("kspd")) == NULL) {
+			printk(KERN_ERR "unable to start kspd\n");
+			return;
+		}
+
+		INIT_WORK(&work, sp_work);
+	}
+
+	queue_work(workqueue, &work);
+}
+
+static void stopwork(int vpe)
+{
+	sp_stopping = 1;
+
+	printk(KERN_DEBUG "KSPD: SP stopping\n");
+}
+
+void kspd_notify(struct kspd_notifications *notify)
+{
+	list_add(&notify->list, &kspd_notifylist);
+}
+
+static struct vpe_notifications notify;
+static int kspd_module_init(void)
+{
+	INIT_LIST_HEAD(&kspd_notifylist);
+
+	notify.start = startwork;
+	notify.stop = stopwork;
+	vpe_notify(tclimit, &notify);
+
+	return 0;
+}
+
+static void kspd_module_exit(void)
+{
+
+}
+
+module_init(kspd_module_init);
+module_exit(kspd_module_exit);
+
+MODULE_DESCRIPTION("MIPS KSPD");
+MODULE_AUTHOR("Elizabeth Oldham, MIPS Technologies, Inc.");
+MODULE_LICENSE("GPL");
diff --git a/arch/mips/kernel/machine_kexec.c b/arch/mips/kernel/machine_kexec.c
index 992e184..85beb9b 100644
--- a/arch/mips/kernel/machine_kexec.c
+++ b/arch/mips/kernel/machine_kexec.c
@@ -5,7 +5,7 @@
  * This source code is licensed under the GNU General Public License,
  * Version 2.  See the file COPYING for more details.
  */
-#include <linux/compiler.h>
+
 #include <linux/kexec.h>
 #include <linux/mm.h>
 #include <linux/delay.h>
@@ -19,19 +19,9 @@ extern const size_t relocate_new_kernel_size;
 extern unsigned long kexec_start_address;
 extern unsigned long kexec_indirection_page;
 
-int (*_machine_kexec_prepare)(struct kimage *) = NULL;
-void (*_machine_kexec_shutdown)(void) = NULL;
-void (*_machine_crash_shutdown)(struct pt_regs *regs) = NULL;
-#ifdef CONFIG_SMP
-void (*relocated_kexec_smp_wait) (void *);
-atomic_t kexec_ready_to_reboot = ATOMIC_INIT(0);
-#endif
-
 int
 machine_kexec_prepare(struct kimage *kimage)
 {
-	if (_machine_kexec_prepare)
-		return _machine_kexec_prepare(kimage);
 	return 0;
 }
 
@@ -43,20 +33,14 @@ machine_kexec_cleanup(struct kimage *kimage)
 void
 machine_shutdown(void)
 {
-	if (_machine_kexec_shutdown)
-		_machine_kexec_shutdown();
 }
 
 void
 machine_crash_shutdown(struct pt_regs *regs)
 {
-	if (_machine_crash_shutdown)
-		_machine_crash_shutdown(regs);
-	else
-		default_machine_crash_shutdown(regs);
 }
 
-typedef void (*noretfun_t)(void) __noreturn;
+typedef void (*noretfun_t)(void) __attribute__((noreturn));
 
 void
 machine_kexec(struct kimage *image)
@@ -68,9 +52,7 @@ machine_kexec(struct kimage *image)
 	reboot_code_buffer =
 	  (unsigned long)page_address(image->control_code_page);
 
-	kexec_start_address =
-		(unsigned long) phys_to_virt(image->start);
-
+	kexec_start_address = image->start;
 	kexec_indirection_page =
 		(unsigned long) phys_to_virt(image->head & PAGE_MASK);
 
@@ -81,7 +63,7 @@ machine_kexec(struct kimage *image)
 	 * The generic kexec code builds a page list with physical
 	 * addresses. they are directly accessible through KSEG0 (or
 	 * CKSEG0 or XPHYS if on 64bit system), hence the
-	 * phys_to_virt() call.
+	 * pys_to_virt() call.
 	 */
 	for (ptr = &image->head; (entry = *ptr) && !(entry &IND_DONE);
 	     ptr = (entry & IND_INDIRECTION) ?
@@ -99,12 +81,5 @@ machine_kexec(struct kimage *image)
 	printk("Will call new kernel at %08lx\n", image->start);
 	printk("Bye ...\n");
 	__flush_cache_all();
-#ifdef CONFIG_SMP
-	/* All secondary cpus now may jump to kexec_wait cycle */
-	relocated_kexec_smp_wait = reboot_code_buffer +
-		(void *)(kexec_smp_wait - relocate_new_kernel);
-	smp_wmb();
-	atomic_set(&kexec_ready_to_reboot, 1);
-#endif
 	((noretfun_t) reboot_code_buffer)();
 }
diff --git a/arch/mips/kernel/mcount.S b/arch/mips/kernel/mcount.S
index 33d0671..4c968e7 100644
--- a/arch/mips/kernel/mcount.S
+++ b/arch/mips/kernel/mcount.S
@@ -46,9 +46,11 @@
 	PTR_L	a5, PT_R9(sp)
 	PTR_L	a6, PT_R10(sp)
 	PTR_L	a7, PT_R11(sp)
-#endif
 	PTR_ADDIU	sp, PT_SIZE
-	.endm
+#else
+	PTR_ADDIU	sp, (PT_SIZE + 8)
+#endif
+.endm
 
 	.macro RETURN_BACK
 	jr ra
@@ -67,13 +69,7 @@ NESTED(ftrace_caller, PT_SIZE, ra)
 	.globl _mcount
 _mcount:
 	b	ftrace_stub
-#ifdef CONFIG_32BIT
-	 addiu sp,sp,8
-#else
 	 nop
-#endif
-
-	/* When tracing is activated, it calls ftrace_caller+8 (aka here) */
 	lw	t1, function_trace_stop
 	bnez	t1, ftrace_stub
 	 nop
diff --git a/arch/mips/kernel/mips-mt-fpaff.c b/arch/mips/kernel/mips-mt-fpaff.c
index fd814e0..33f63ba 100644
--- a/arch/mips/kernel/mips-mt-fpaff.c
+++ b/arch/mips/kernel/mips-mt-fpaff.c
@@ -50,8 +50,8 @@ static bool check_same_owner(struct task_struct *p)
 
 	rcu_read_lock();
 	pcred = __task_cred(p);
-	match = (uid_eq(cred->euid, pcred->euid) ||
-		 uid_eq(cred->euid, pcred->uid));
+	match = (cred->euid == pcred->euid ||
+		 cred->euid == pcred->uid);
 	rcu_read_unlock();
 	return match;
 }
diff --git a/arch/mips/kernel/mips-mt.c b/arch/mips/kernel/mips-mt.c
index 6ded9bd..7f3376b 100644
--- a/arch/mips/kernel/mips-mt.c
+++ b/arch/mips/kernel/mips-mt.c
@@ -209,7 +209,7 @@ void mips_mt_set_cpuoptions(void)
 	unsigned int nconfig7 = oconfig7;
 
 	if (mt_opt_norps) {
-		printk("\"norps\" option deprecated: use \"rpsctl=\"\n");
+		printk("\"norps\" option deprectated: use \"rpsctl=\"\n");
 	}
 	if (mt_opt_rpsctl >= 0) {
 		printk("34K return prediction stack override set to %d.\n",
diff --git a/arch/mips/kernel/mips_machine.c b/arch/mips/kernel/mips_machine.c
index 8760975..411a058 100644
--- a/arch/mips/kernel/mips_machine.c
+++ b/arch/mips/kernel/mips_machine.c
@@ -11,9 +11,9 @@
 #include <linux/slab.h>
 
 #include <asm/mips_machine.h>
-#include <asm/prom.h>
 
 static struct mips_machine *mips_machine __initdata;
+static char *mips_machine_name = "Unknown";
 
 #define for_each_machine(mach) \
 	for ((mach) = (struct mips_machine *)&__mips_machines_start; \
@@ -21,6 +21,25 @@ static struct mips_machine *mips_machine __initdata;
 	     (unsigned long)(mach) < (unsigned long)&__mips_machines_end; \
 	     (mach)++)
 
+__init void mips_set_machine_name(const char *name)
+{
+	char *p;
+
+	if (name == NULL)
+		return;
+
+	p = kstrdup(name, GFP_KERNEL);
+	if (!p)
+		pr_err("MIPS: no memory for machine_name\n");
+
+	mips_machine_name = p;
+}
+
+char *mips_get_machine_name(void)
+{
+	return mips_machine_name;
+}
+
 __init int mips_machtype_setup(char *id)
 {
 	struct mips_machine *mach;
@@ -60,6 +79,7 @@ __init void mips_machine_setup(void)
 		return;
 
 	mips_set_machine_name(mips_machine->mach_name);
+	pr_info("MIPS: machine is %s\n", mips_machine_name);
 
 	if (mips_machine->mach_setup)
 		mips_machine->mach_setup();
diff --git a/arch/mips/kernel/prom.c b/arch/mips/kernel/prom.c
index 5712bb5..334324e 100644
--- a/arch/mips/kernel/prom.c
+++ b/arch/mips/kernel/prom.c
@@ -52,6 +52,16 @@ void __init early_init_dt_add_memory_arch(u64 base, u64 size)
 	return add_memory_region(base, size, BOOT_MEM_RAM);
 }
 
+int __init reserve_mem_mach(unsigned long addr, unsigned long size)
+{
+	return reserve_bootmem(addr, size, BOOTMEM_DEFAULT);
+}
+
+void __init free_mem_mach(unsigned long addr, unsigned long size)
+{
+	return free_bootmem(addr, size);
+}
+
 void * __init early_init_dt_alloc_memory_arch(u64 size, u64 align)
 {
 	return __alloc_bootmem(size, align, __pa(MAX_DMA_ADDRESS));
@@ -111,4 +121,22 @@ void __init __dt_setup_arch(struct boot_param_header *bph)
 
 	early_init_devtree(initial_boot_params);
 }
+void __init device_tree_init(void)
+{
+	unsigned long base, size;
+
+	if (!initial_boot_params)
+		return;
+
+	base = virt_to_phys((void *)initial_boot_params);
+	size = be32_to_cpu(initial_boot_params->totalsize);
+
+	/* Before we do anything, lets reserve the dt blob */
+	reserve_mem_mach(base, size);
+
+	unflatten_device_tree();
+
+	/* free the space reserved for the dt blob */
+	free_mem_mach(base, size);
+}
 #endif
diff --git a/arch/mips/kernel/ptrace.c b/arch/mips/kernel/ptrace.c
index 9c6299c..c24f6ef 100644
--- a/arch/mips/kernel/ptrace.c
+++ b/arch/mips/kernel/ptrace.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -37,6 +49,7 @@
 #include <asm/uaccess.h>
 #include <asm/bootinfo.h>
 #include <asm/reg.h>
+#include <asm/cacheflush.h>
 
 /*
  * Called by kernel/ptrace.c when detaching..
@@ -265,6 +278,11 @@ long arch_ptrace(struct task_struct *child, long request,
 	switch (request) {
 	/* when I and D space are separate, these will need to be fixed. */
 	case PTRACE_PEEKTEXT: /* read word at location addr. */
+#ifdef CONFIG_RMI_PHOENIX
+            __flush_cache_all();
+            /* Fall through */
+#endif
+
 	case PTRACE_PEEKDATA:
 		ret = generic_ptrace_peekdata(child, addr, data);
 		break;
@@ -395,6 +413,10 @@ long arch_ptrace(struct task_struct *child, long request,
 
 	/* when I and D space are separate, this will have to be fixed. */
 	case PTRACE_POKETEXT: /* write the word at location addr. */
+#ifdef CONFIG_RMI_PHOENIX
+        __flush_cache_all();
+        /* Fall through */
+#endif
 	case PTRACE_POKEDATA:
 		ret = generic_ptrace_pokedata(child, addr, data);
 		break;
diff --git a/arch/mips/kernel/ptrace32.c b/arch/mips/kernel/ptrace32.c
index 9486055..a3b0178 100644
--- a/arch/mips/kernel/ptrace32.c
+++ b/arch/mips/kernel/ptrace32.c
@@ -124,7 +124,7 @@ long compat_arch_ptrace(struct task_struct *child, compat_long_t request,
 		case FPC_CSR:
 			tmp = child->thread.fpu.fcr31;
 			break;
-		case FPC_EIR: { /* implementation / version register */
+		case FPC_EIR: {	/* implementation / version register */
 			unsigned int flags;
 #ifdef CONFIG_MIPS_MT_SMTC
 			unsigned int irqflags;
diff --git a/arch/mips/kernel/r4k_switch.S b/arch/mips/kernel/r4k_switch.S
index 5e51219..f52376b 100644
--- a/arch/mips/kernel/r4k_switch.S
+++ b/arch/mips/kernel/r4k_switch.S
@@ -15,6 +15,7 @@
 #include <asm/fpregdef.h>
 #include <asm/mipsregs.h>
 #include <asm/asm-offsets.h>
+#include <asm/page.h>
 #include <asm/pgtable-bits.h>
 #include <asm/regdef.h>
 #include <asm/stackframe.h>
@@ -52,10 +53,16 @@
 	/*
 	 * check if we need to save FPU registers
 	 */
+	PTR_L	t3, TASK_THREAD_INFO(a0)
+	LONG_L	t0, TI_FLAGS(t3)
+	li	t1, _TIF_USEDFPU
+	and	t2, t0, t1
+	beqz	t2, 1f
+	nor	t1, zero, t1
 
-	beqz	a3, 1f
+	and	t0, t0, t1
+	LONG_S	t0, TI_FLAGS(t3)
 
-	PTR_L	t3, TASK_THREAD_INFO(a0)
 	/*
 	 * clear saved user stack CU1 bit
 	 */
diff --git a/arch/mips/kernel/relocate_kernel.S b/arch/mips/kernel/relocate_kernel.S
index 43d2d78..87481f9 100644
--- a/arch/mips/kernel/relocate_kernel.S
+++ b/arch/mips/kernel/relocate_kernel.S
@@ -9,16 +9,12 @@
 #include <asm/asm.h>
 #include <asm/asmmacro.h>
 #include <asm/regdef.h>
+#include <asm/page.h>
 #include <asm/mipsregs.h>
 #include <asm/stackframe.h>
 #include <asm/addrspace.h>
 
 LEAF(relocate_new_kernel)
-	PTR_L a0,	arg0
-	PTR_L a1,	arg1
-	PTR_L a2,	arg2
-	PTR_L a3,	arg3
-
 	PTR_L		s0, kexec_indirection_page
 	PTR_L		s1, kexec_start_address
 
@@ -30,10 +26,11 @@ process_entry:
 	and		s3, s2, 0x1
 	beq		s3, zero, 1f
 	and		s4, s2, ~0x1	/* store destination addr in s4 */
+	move		a0, s4
 	b		process_entry
 
 1:
-	/* indirection page, update s0	*/
+	/* indirection page, update s0  */
 	and		s3, s2, 0x2
 	beq		s3, zero, 1f
 	and		s0, s2, ~0x2
@@ -49,7 +46,7 @@ process_entry:
 	and		s3, s2, 0x8
 	beq		s3, zero, process_entry
 	and		s2, s2, ~0x8
-	li		s6, (1 << _PAGE_SHIFT) / SZREG
+	li		s6, (1 << PAGE_SHIFT) / SZREG
 
 copy_word:
 	/* copy page word by word */
@@ -63,111 +60,10 @@ copy_word:
 	b		process_entry
 
 done:
-#ifdef CONFIG_SMP
-	/* kexec_flag reset is signal to other CPUs what kernel
-	   was moved to it's location. Note - we need relocated address
-	   of kexec_flag.  */
-
-	bal		1f
- 1:	move		t1,ra;
-	PTR_LA		t2,1b
-	PTR_LA		t0,kexec_flag
-	PTR_SUB		t0,t0,t2;
-	PTR_ADD		t0,t1,t0;
-	LONG_S		zero,(t0)
-#endif
-
-#ifdef CONFIG_CPU_CAVIUM_OCTEON
-	/* We need to flush I-cache before jumping to new kernel.
-	 * Unfortunatelly, this code is cpu-specific.
-	 */
-	.set push
-	.set noreorder
-	syncw
-	syncw
-	synci		0($0)
-	.set pop
-#else
-	sync
-#endif
 	/* jump to kexec_start_address */
 	j		s1
 	END(relocate_new_kernel)
 
-#ifdef CONFIG_SMP
-/*
- * Other CPUs should wait until code is relocated and
- * then start at entry (?) point.
- */
-LEAF(kexec_smp_wait)
-	PTR_L		a0, s_arg0
-	PTR_L		a1, s_arg1
-	PTR_L		a2, s_arg2
-	PTR_L		a3, s_arg3
-	PTR_L		s1, kexec_start_address
-
-	/* Non-relocated address works for args and kexec_start_address ( old
-	 * kernel is not overwritten). But we need relocated address of
-	 * kexec_flag.
-	 */
-
-	bal		1f
-1:	move		t1,ra;
-	PTR_LA		t2,1b
-	PTR_LA		t0,kexec_flag
-	PTR_SUB		t0,t0,t2;
-	PTR_ADD		t0,t1,t0;
-
-1:	LONG_L		s0, (t0)
-	bne		s0, zero,1b
-
-#ifdef CONFIG_CPU_CAVIUM_OCTEON
-	.set push
-	.set noreorder
-	synci		0($0)
-	.set pop
-#else
-	sync
-#endif
-	j		s1
-	END(kexec_smp_wait)
-#endif
-
-#ifdef __mips64
-       /* all PTR's must be aligned to 8 byte in 64-bit mode */
-       .align  3
-#endif
-
-/* All parameters to new kernel are passed in registers a0-a3.
- * kexec_args[0..3] are uses to prepare register values.
- */
-
-kexec_args:
-	EXPORT(kexec_args)
-arg0:	PTR		0x0
-arg1:	PTR		0x0
-arg2:	PTR		0x0
-arg3:	PTR		0x0
-	.size	kexec_args,PTRSIZE*4
-
-#ifdef CONFIG_SMP
-/*
- * Secondary CPUs may have different kernel parameters in
- * their registers a0-a3. secondary_kexec_args[0..3] are used
- * to prepare register values.
- */
-secondary_kexec_args:
-	EXPORT(secondary_kexec_args)
-s_arg0: PTR		0x0
-s_arg1: PTR		0x0
-s_arg2: PTR		0x0
-s_arg3: PTR		0x0
-	.size	secondary_kexec_args,PTRSIZE*4
-kexec_flag:
-	LONG		0x1
-
-#endif
-
 kexec_start_address:
 	EXPORT(kexec_start_address)
 	PTR		0x0
diff --git a/arch/mips/kernel/scall32-o32.S b/arch/mips/kernel/scall32-o32.S
index 9b36424..d472663 100644
--- a/arch/mips/kernel/scall32-o32.S
+++ b/arch/mips/kernel/scall32-o32.S
@@ -1,3 +1,12 @@
+/*-
+ * Copyright 2005-2013 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -26,6 +35,30 @@
 
 	.align	5
 NESTED(handle_sys, PT_SIZE, sp)
+#ifdef CONFIG_32BIT
+#ifdef CONFIG_NLM_XLP
+	.set push
+	.set mips64
+    /* XLP Specific fast system calls */
+	mfc0	k1, CP0_EPC
+	lw	k0, 0(k1)
+	dsll32	k0, k0, 0
+	dsrl32  k0, k0, 6
+	beqz	k0, 1f
+	nop
+	sll	k0, k0, 2
+	lw	k1, nlm_fs_table(k0)
+	jr	k1
+	nop
+	/* should never come here */
+2:	wait
+	b	2b
+	nop
+	.set pop
+1:
+#endif
+#endif
+
 	.set	noat
 	SAVE_SOME
 	TRACE_IRQS_ON_RELOAD
diff --git a/arch/mips/kernel/scall64-64.S b/arch/mips/kernel/scall64-64.S
index 97a5909..476d604 100644
--- a/arch/mips/kernel/scall64-64.S
+++ b/arch/mips/kernel/scall64-64.S
@@ -343,8 +343,13 @@ sys_call_table:
 	PTR	sys_tgkill			/* 5225 */
 	PTR	sys_utimes
 	PTR	sys_mbind
+#ifdef CONFIG_NUMA
+	PTR	sys_get_mempolicy
+	PTR	sys_set_mempolicy
+#else
 	PTR	sys_ni_syscall			/* sys_get_mempolicy */
 	PTR	sys_ni_syscall			/* sys_set_mempolicy */
+#endif
 	PTR	sys_mq_open			/* 5230 */
 	PTR	sys_mq_unlink
 	PTR	sys_mq_timedsend
diff --git a/arch/mips/kernel/scall64-n32.S b/arch/mips/kernel/scall64-n32.S
index edcb659..b2f6b3b 100644
--- a/arch/mips/kernel/scall64-n32.S
+++ b/arch/mips/kernel/scall64-n32.S
@@ -1,3 +1,12 @@
+/*-
+ * Copyright 2005-2013 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -335,9 +344,15 @@ EXPORT(sysn32_call_table)
 	PTR	compat_sys_clock_nanosleep
 	PTR	sys_tgkill
 	PTR	compat_sys_utimes		/* 6230 */
+#ifdef CONFIG_NUMA
+	PTR	compat_sys_mbind
+	PTR	compat_sys_get_mempolicy
+	PTR	compat_sys_set_mempolicy
+#else
 	PTR	sys_ni_syscall			/* sys_mbind */
 	PTR	sys_ni_syscall			/* sys_get_mempolicy */
 	PTR	sys_ni_syscall			/* sys_set_mempolicy */
+#endif
 	PTR	compat_sys_mq_open
 	PTR	sys_mq_unlink			/* 6235 */
 	PTR	compat_sys_mq_timedsend
diff --git a/arch/mips/kernel/scall64-o32.S b/arch/mips/kernel/scall64-o32.S
index 74f485d..949fbcb 100644
--- a/arch/mips/kernel/scall64-o32.S
+++ b/arch/mips/kernel/scall64-o32.S
@@ -26,6 +26,32 @@
 
 	.align	5
 NESTED(handle_sys, PT_SIZE, sp)
+#ifdef CONFIG_64BIT
+#ifdef CONFIG_NLM_XLP
+	.set push
+	.set	noat
+	.set mips64
+    	/* XLR Specific fast system calls */
+	dmfc0	k1, CP0_EPC
+	lw	k0, 0(k1)
+	dsll32	k0, k0, 0
+	dsrl32  k0, k0, 6
+	beqz	k0, 1f
+	nop
+	sll	k0, k0, 3
+	PTR_LA  k1, nlm_fs_table
+	PTR_ADDU k1,k0,k1
+	ld	k1, 0(k1)
+	jr	k1
+	nop
+	/* should never come here */
+2:	wait
+	b	2b
+	nop
+1:
+	.set pop
+#endif
+#endif
 	.set	noat
 	SAVE_SOME
 	TRACE_IRQS_ON_RELOAD
diff --git a/arch/mips/kernel/setup.c b/arch/mips/kernel/setup.c
index c7f9051..94fb74e 100644
--- a/arch/mips/kernel/setup.c
+++ b/arch/mips/kernel/setup.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -8,7 +20,7 @@
  * Copyright (C) 1994, 95, 96, 97, 98, 99, 2000, 01, 02, 03  Ralf Baechle
  * Copyright (C) 1996 Stoned Elipot
  * Copyright (C) 1999 Silicon Graphics, Inc.
- * Copyright (C) 2000, 2001, 2002, 2007	 Maciej W. Rozycki
+ * Copyright (C) 2000, 2001, 2002, 2007  Maciej W. Rozycki
  */
 #include <linux/init.h>
 #include <linux/ioport.h>
@@ -22,8 +34,6 @@
 #include <linux/console.h>
 #include <linux/pfn.h>
 #include <linux/debugfs.h>
-#include <linux/kexec.h>
-#include <linux/sizes.h>
 
 #include <asm/addrspace.h>
 #include <asm/bootinfo.h>
@@ -35,6 +45,10 @@
 #include <asm/smp-ops.h>
 #include <asm/prom.h>
 
+#include <asm/rmi/sim.h>
+#include <asm/rmi/debug.h>
+#include <asm/mach-rmi/mmu.h>
+
 struct cpuinfo_mips cpu_data[NR_CPUS] __read_mostly;
 
 EXPORT_SYMBOL(cpu_data);
@@ -43,6 +57,13 @@ EXPORT_SYMBOL(cpu_data);
 struct screen_info screen_info;
 #endif
 
+#ifdef CONFIG_RMI_VMIPS
+extern unsigned long long rmi_vmips_highmem_start;
+#undef  HIGHMEM_START
+#define        HIGHMEM_START   (rmi_vmips_highmem_start)
+#endif
+
+
 /*
  * Despite it's name this variable is even if we don't have PCI
  */
@@ -78,12 +99,10 @@ EXPORT_SYMBOL(mips_io_port_base);
 static struct resource code_resource = { .name = "Kernel code", };
 static struct resource data_resource = { .name = "Kernel data", };
 
-static void *detect_magic __initdata = detect_memory_region;
-
-void __init add_memory_region(phys_t start, phys_t size, long type)
+void __init add_memory_region(uint64_t start, uint64_t size, long type)
 {
 	int x = boot_mem_map.nr_map;
-	int i;
+	struct boot_mem_map_entry *prev = boot_mem_map.map + x - 1;
 
 	/* Sanity check */
 	if (start + size < start) {
@@ -92,29 +111,15 @@ void __init add_memory_region(phys_t start, phys_t size, long type)
 	}
 
 	/*
-	 * Try to merge with existing entry, if any.
+	 * Try to merge with previous entry if any.  This is far less than
+	 * perfect but is sufficient for most real world cases.
 	 */
-	for (i = 0; i < boot_mem_map.nr_map; i++) {
-		struct boot_mem_map_entry *entry = boot_mem_map.map + i;
-		unsigned long top;
-
-		if (entry->type != type)
-			continue;
-
-		if (start + size < entry->addr)
-			continue;			/* no overlap */
-
-		if (entry->addr + entry->size < start)
-			continue;			/* no overlap */
-
-		top = max(entry->addr + entry->size, start + size);
-		entry->addr = min(entry->addr, start);
-		entry->size = top - entry->addr;
-
+	if (x && prev->addr + prev->size == start && prev->type == type) {
+		prev->size += size;
 		return;
 	}
 
-	if (boot_mem_map.nr_map == BOOT_MEM_MAP_MAX) {
+	if (x == BOOT_MEM_MAP_MAX) {
 		pr_err("Ooops! Too many entries in the memory map!\n");
 		return;
 	}
@@ -125,24 +130,16 @@ void __init add_memory_region(phys_t start, phys_t size, long type)
 	boot_mem_map.nr_map++;
 }
 
-void __init detect_memory_region(phys_t start, phys_t sz_min, phys_t sz_max)
+#ifdef CONFIG_RMI_PHOENIX
+int avail_mem_above_4G;
+int force_usb __initdata = 0;
+static int __init xls_force_usb(char *p)
 {
-	void *dm = &detect_magic;
-	phys_t size;
-
-	for (size = sz_min; size < sz_max; size <<= 1) {
-		if (!memcmp(dm, dm + size, sizeof(detect_magic)))
-			break;
-	}
-
-	pr_debug("Memory: %lluMB of RAM detected at 0x%llx (min: %lluMB, max: %lluMB)\n",
-		((unsigned long long) size) / SZ_1M,
-		(unsigned long long) start,
-		((unsigned long long) sz_min) / SZ_1M,
-		((unsigned long long) sz_max) / SZ_1M);
-
-	add_memory_region(start, size, BOOT_MEM_RAM);
+    force_usb = 1;
+	return 0;
 }
+early_param("forceusb", xls_force_usb);
+#endif
 
 static void __init print_memory_map(void)
 {
@@ -168,12 +165,50 @@ static void __init print_memory_map(void)
 			printk(KERN_CONT "(reserved)\n");
 			break;
 		default:
-			printk(KERN_CONT "type %lu\n", boot_mem_map.map[i].type);
+			printk(KERN_CONT "type %llu\n", 
+                        (unsigned long long)boot_mem_map.map[i].type);
 			break;
 		}
 	}
 }
 
+#if defined(CONFIG_RMI_PHOENIX)
+/* This routine is useful when USB is desired on
+ * 64-Bit Linux with DRAM mapped >4G. On such systems,
+ * since the XLS USB controller is 32-bit, USB is
+ * disabled. Use command line option 'forceusb' to
+ * enable it; This adjusts the mapped available mem 
+ * to a max of till 0xFFFFFFFF.
+ */
+static void __init tweak_avail_dram_map(void) {
+
+    int j=0;
+    int nrmap_ctr = (boot_mem_map.nr_map - 1);
+
+    avail_mem_above_4G = 0;
+
+    for (j=nrmap_ctr; j>=0; j--) {
+        if ((boot_mem_map.map[j].addr + boot_mem_map.map[j].size) 
+                > 0x100000000ULL) {
+            avail_mem_above_4G++;
+#ifdef CONFIG_64BIT
+            if (force_usb) {
+                printk(KERN_WARNING "[USB]:Re-adjusting Available DRAM map\n");
+                if (boot_mem_map.map[j].addr > 0x100000000ULL) {
+                    boot_mem_map.nr_map--;
+                }
+                else {
+                    /* Reclaim whatever we can... */
+                    boot_mem_map.map[j].size =
+                        0x100000000ULL - boot_mem_map.map[j].addr;
+                }
+            }
+#endif
+        }
+    }
+}
+#endif
+
 /*
  * Manage initrd
  */
@@ -362,6 +397,14 @@ static void __init bootmem_init(void)
 		max_low_pfn = PFN_DOWN(HIGHMEM_START);
 	}
 
+#ifdef CONFIG_NLM_XLP
+	max_low_pfn = recalculate_max_low_pfn(max_low_pfn);
+
+#ifdef DEBUG_MAPPED_KERNEL
+	printk("max_low_pfn = 0x%lx\n", max_low_pfn);
+#endif
+#endif
+
 	/*
 	 * Initialize the boot-time allocator with low memory only.
 	 */
@@ -471,7 +514,7 @@ static void __init bootmem_init(void)
  * At this stage the bootmem allocator is ready to use.
  *
  * NOTE: historically plat_mem_setup did the entire platform initialization.
- *	 This was rather impractical because it meant plat_mem_setup had to
+ *       This was rather impractical because it meant plat_mem_setup had to
  * get away without any kind of memory allocator.  To keep old code from
  * breaking plat_setup was just renamed to plat_setup and a second platform
  * initialization hook for anything else was introduced.
@@ -491,7 +534,7 @@ static int __init early_parse_mem(char *p)
 	if (usermem == 0) {
 		boot_mem_map.nr_map = 0;
 		usermem = 1;
-	}
+ 	}
 	start = 0;
 	size = memparse(p, &p);
 	if (*p == '@')
@@ -502,75 +545,34 @@ static int __init early_parse_mem(char *p)
 }
 early_param("mem", early_parse_mem);
 
-#ifdef CONFIG_PROC_VMCORE
-unsigned long setup_elfcorehdr, setup_elfcorehdr_size;
-static int __init early_parse_elfcorehdr(char *p)
-{
-	int i;
-
-	setup_elfcorehdr = memparse(p, &p);
-
-	for (i = 0; i < boot_mem_map.nr_map; i++) {
-		unsigned long start = boot_mem_map.map[i].addr;
-		unsigned long end = (boot_mem_map.map[i].addr +
-				     boot_mem_map.map[i].size);
-		if (setup_elfcorehdr >= start && setup_elfcorehdr < end) {
-			/*
-			 * Reserve from the elf core header to the end of
-			 * the memory segment, that should all be kdump
-			 * reserved memory.
-			 */
-			setup_elfcorehdr_size = end - setup_elfcorehdr;
-			break;
-		}
-	}
-	/*
-	 * If we don't find it in the memory map, then we shouldn't
-	 * have to worry about it, as the new kernel won't use it.
-	 */
-	return 0;
-}
-early_param("elfcorehdr", early_parse_elfcorehdr);
-#endif
-
-static void __init arch_mem_addpart(phys_t mem, phys_t end, int type)
-{
-	phys_t size;
-	int i;
-
-	size = end - mem;
-	if (!size)
-		return;
-
-	/* Make sure it is in the boot_mem_map */
-	for (i = 0; i < boot_mem_map.nr_map; i++) {
-		if (mem >= boot_mem_map.map[i].addr &&
-		    mem < (boot_mem_map.map[i].addr +
-			   boot_mem_map.map[i].size))
-			return;
-	}
-	add_memory_region(mem, size, type);
-}
-
 static void __init arch_mem_init(char **cmdline_p)
 {
+	phys_t init_mem, init_end, init_size;
+
 	extern void plat_mem_setup(void);
 
 	/* call board setup routine */
 	plat_mem_setup();
 
-	/*
-	 * Make sure all kernel memory is in the maps.  The "UP" and
-	 * "DOWN" are opposite for initdata since if it crosses over
-	 * into another memory section you don't want that to be
-	 * freed when the initdata is freed.
-	 */
-	arch_mem_addpart(PFN_DOWN(__pa_symbol(&_text)) << PAGE_SHIFT,
-			 PFN_UP(__pa_symbol(&_edata)) << PAGE_SHIFT,
-			 BOOT_MEM_RAM);
-	arch_mem_addpart(PFN_UP(__pa_symbol(&__init_begin)) << PAGE_SHIFT,
-			 PFN_DOWN(__pa_symbol(&__init_end)) << PAGE_SHIFT,
-			 BOOT_MEM_INIT_RAM);
+	init_mem = PFN_UP(__pa_symbol(&__init_begin)) << PAGE_SHIFT;
+	init_end = PFN_DOWN(__pa_symbol(&__init_end)) << PAGE_SHIFT;
+	init_size = init_end - init_mem;
+	if (init_size) {
+		/* Make sure it is in the boot_mem_map */
+		int i, found;
+		found = 0;
+		for (i = 0; i < boot_mem_map.nr_map; i++) {
+			if (init_mem >= boot_mem_map.map[i].addr &&
+			    init_mem < (boot_mem_map.map[i].addr +
+					boot_mem_map.map[i].size)) {
+				found = 1;
+				break;
+			}
+		}
+		if (!found)
+			add_memory_region(init_mem, init_size,
+					  BOOT_MEM_INIT_RAM);
+	}
 
 	pr_info("Determined physical RAM map:\n");
 	print_memory_map();
@@ -599,73 +601,23 @@ static void __init arch_mem_init(char **cmdline_p)
 		print_memory_map();
 	}
 
-	bootmem_init();
-#ifdef CONFIG_PROC_VMCORE
-	if (setup_elfcorehdr && setup_elfcorehdr_size) {
-		printk(KERN_INFO "kdump reserved memory at %lx-%lx\n",
-		       setup_elfcorehdr, setup_elfcorehdr_size);
-		reserve_bootmem(setup_elfcorehdr, setup_elfcorehdr_size,
-				BOOTMEM_DEFAULT);
-	}
-#endif
-#ifdef CONFIG_KEXEC
-	if (crashk_res.start != crashk_res.end)
-		reserve_bootmem(crashk_res.start,
-				crashk_res.end - crashk_res.start + 1,
-				BOOTMEM_DEFAULT);
+#ifdef CONFIG_RMI_PHOENIX
+	tweak_avail_dram_map();
 #endif
+    
+/*
+	setup_mapped_kernel_tlbs(TRUE, TRUE);
+*/
+	bootmem_init();
+/*
+	setup_mapped_kernel_tlbs(FALSE, TRUE);
+*/
 	device_tree_init();
 	sparse_init();
 	plat_swiotlb_setup();
 	paging_init();
 }
 
-#ifdef CONFIG_KEXEC
-static inline unsigned long long get_total_mem(void)
-{
-	unsigned long long total;
-
-	total = max_pfn - min_low_pfn;
-	return total << PAGE_SHIFT;
-}
-
-static void __init mips_parse_crashkernel(void)
-{
-	unsigned long long total_mem;
-	unsigned long long crash_size, crash_base;
-	int ret;
-
-	total_mem = get_total_mem();
-	ret = parse_crashkernel(boot_command_line, total_mem,
-				&crash_size, &crash_base);
-	if (ret != 0 || crash_size <= 0)
-		return;
-
-	crashk_res.start = crash_base;
-	crashk_res.end	 = crash_base + crash_size - 1;
-}
-
-static void __init request_crashkernel(struct resource *res)
-{
-	int ret;
-
-	ret = request_resource(res, &crashk_res);
-	if (!ret)
-		pr_info("Reserving %ldMB of memory at %ldMB for crashkernel\n",
-			(unsigned long)((crashk_res.end -
-				crashk_res.start + 1) >> 20),
-			(unsigned long)(crashk_res.start  >> 20));
-}
-#else /* !defined(CONFIG_KEXEC)	 */
-static void __init mips_parse_crashkernel(void)
-{
-}
-
-static void __init request_crashkernel(struct resource *res)
-{
-}
-#endif /* !defined(CONFIG_KEXEC)  */
-
 static void __init resource_init(void)
 {
 	int i;
@@ -681,8 +633,6 @@ static void __init resource_init(void)
 	/*
 	 * Request address space for all standard RAM.
 	 */
-	mips_parse_crashkernel();
-
 	for (i = 0; i < boot_mem_map.nr_map; i++) {
 		struct resource *res;
 		unsigned long start, end;
@@ -719,7 +669,6 @@ static void __init resource_init(void)
 		 */
 		request_resource(res, &code_resource);
 		request_resource(res, &data_resource);
-		request_crashkernel(res);
 	}
 }
 
@@ -746,8 +695,6 @@ void __init setup_arch(char **cmdline_p)
 
 	resource_init();
 	plat_smp_setup();
-
-	cpu_cache_init();
 }
 
 unsigned long kernelsp[NR_CPUS];
diff --git a/arch/mips/kernel/smp-bmips.c b/arch/mips/kernel/smp-bmips.c
index 8e393b8..3046e29 100644
--- a/arch/mips/kernel/smp-bmips.c
+++ b/arch/mips/kernel/smp-bmips.c
@@ -15,6 +15,7 @@
 #include <linux/smp.h>
 #include <linux/interrupt.h>
 #include <linux/spinlock.h>
+#include <linux/init.h>
 #include <linux/cpu.h>
 #include <linux/cpumask.h>
 #include <linux/reboot.h>
@@ -196,6 +197,13 @@ static void bmips_init_secondary(void)
 
 	write_c0_brcm_action(ACTION_CLR_IPI(smp_processor_id(), 0));
 #endif
+
+	/* make sure there won't be a timer interrupt for a little while */
+	write_c0_compare(read_c0_count() + mips_hpt_frequency / HZ);
+
+	irq_enable_hazard();
+	set_c0_status(IE_SW0 | IE_SW1 | IE_IRQ1 | IE_IRQ5 | ST0_IE);
+	irq_enable_hazard();
 }
 
 /*
@@ -204,13 +212,6 @@ static void bmips_init_secondary(void)
 static void bmips_smp_finish(void)
 {
 	pr_info("SMP: CPU%d is running\n", smp_processor_id());
-
-	/* make sure there won't be a timer interrupt for a little while */
-	write_c0_compare(read_c0_count() + mips_hpt_frequency / HZ);
-
-	irq_enable_hazard();
-	set_c0_status(IE_SW0 | IE_SW1 | IE_IRQ1 | IE_IRQ5 | ST0_IE);
-	irq_enable_hazard();
 }
 
 /*
diff --git a/arch/mips/kernel/smp-cmp.c b/arch/mips/kernel/smp-cmp.c
index c2e5d74..e7e03ec 100644
--- a/arch/mips/kernel/smp-cmp.c
+++ b/arch/mips/kernel/smp-cmp.c
@@ -97,12 +97,12 @@ static void cmp_init_secondary(void)
 
 	/* Enable per-cpu interrupts: platform specific */
 
-	c->core = (read_c0_ebase() >> 1) & 0x1ff;
+	c->core = (read_c0_ebase() >> 1) & 0xff;
 #if defined(CONFIG_MIPS_MT_SMP) || defined(CONFIG_MIPS_MT_SMTC)
 	c->vpe_id = (read_c0_tcbind() >> TCBIND_CURVPE_SHIFT) & TCBIND_CURVPE;
 #endif
 #ifdef CONFIG_MIPS_MT_SMTC
-	c->tc_id  = (read_c0_tcbind() & TCBIND_CURTC) >> TCBIND_CURTC_SHIFT;
+	c->tc_id  = (read_c0_tcbind() >> TCBIND_CURTC_SHIFT) & TCBIND_CURTC;
 #endif
 }
 
@@ -172,7 +172,7 @@ void __init cmp_smp_setup(void)
 		if (amon_cpu_avail(i)) {
 			set_cpu_possible(i, true);
 			__cpu_number_map[i]	= ++ncpu;
-			__cpu_logical_map[ncpu] = i;
+			__cpu_logical_map[ncpu]	= i;
 		}
 	}
 
diff --git a/arch/mips/kernel/smtc-proc.c b/arch/mips/kernel/smtc-proc.c
index c10aa84..145771c 100644
--- a/arch/mips/kernel/smtc-proc.c
+++ b/arch/mips/kernel/smtc-proc.c
@@ -16,7 +16,6 @@
 #include <asm/mipsregs.h>
 #include <asm/cacheflush.h>
 #include <linux/proc_fs.h>
-#include <linux/seq_file.h>
 
 #include <asm/smtc_proc.h>
 
@@ -31,39 +30,51 @@ unsigned long selfipis[NR_CPUS];
 
 struct smtc_cpu_proc smtc_cpu_stats[NR_CPUS];
 
+static struct proc_dir_entry *smtc_stats;
+
 atomic_t smtc_fpu_recoveries;
 
-static int smtc_proc_show(struct seq_file *m, void *v)
+static int proc_read_smtc(char *page, char **start, off_t off,
+                          int count, int *eof, void *data)
 {
+	int totalen = 0;
+	int len;
 	int i;
 	extern unsigned long ebase;
 
-	seq_printf(m, "SMTC Status Word: 0x%08x\n", smtc_status);
-	seq_printf(m, "Config7: 0x%08x\n", read_c0_config7());
-	seq_printf(m, "EBASE: 0x%08lx\n", ebase);
-	seq_printf(m, "Counter Interrupts taken per CPU (TC)\n");
-	for (i=0; i < NR_CPUS; i++)
-		seq_printf(m, "%d: %ld\n", i, smtc_cpu_stats[i].timerints);
-	seq_printf(m, "Self-IPIs by CPU:\n");
-	for(i = 0; i < NR_CPUS; i++)
-		seq_printf(m, "%d: %ld\n", i, smtc_cpu_stats[i].selfipis);
-	seq_printf(m, "%d Recoveries of \"stolen\" FPU\n",
-		   atomic_read(&smtc_fpu_recoveries));
-	return 0;
-}
+	len = sprintf(page, "SMTC Status Word: 0x%08x\n", smtc_status);
+	totalen += len;
+	page += len;
+	len = sprintf(page, "Config7: 0x%08x\n", read_c0_config7());
+	totalen += len;
+	page += len;
+	len = sprintf(page, "EBASE: 0x%08lx\n", ebase);
+	totalen += len;
+	page += len;
+	len = sprintf(page, "Counter Interrupts taken per CPU (TC)\n");
+	totalen += len;
+	page += len;
+	for (i=0; i < NR_CPUS; i++) {
+		len = sprintf(page, "%d: %ld\n", i, smtc_cpu_stats[i].timerints);
+		totalen += len;
+		page += len;
+	}
+	len = sprintf(page, "Self-IPIs by CPU:\n");
+	totalen += len;
+	page += len;
+	for(i = 0; i < NR_CPUS; i++) {
+		len = sprintf(page, "%d: %ld\n", i, smtc_cpu_stats[i].selfipis);
+		totalen += len;
+		page += len;
+	}
+	len = sprintf(page, "%d Recoveries of \"stolen\" FPU\n",
+	              atomic_read(&smtc_fpu_recoveries));
+	totalen += len;
+	page += len;
 
-static int smtc_proc_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, smtc_proc_show, NULL);
+	return totalen;
 }
 
-static const struct file_operations smtc_proc_fops = {
-	.open		= smtc_proc_open,
-	.read		= seq_read,
-	.llseek		= seq_lseek,
-	.release	= single_release,
-};
-
 void init_smtc_stats(void)
 {
 	int i;
@@ -75,5 +86,6 @@ void init_smtc_stats(void)
 
 	atomic_set(&smtc_fpu_recoveries, 0);
 
-	proc_create("smtc", 0444, NULL, &smtc_proc_fops);
+	smtc_stats = create_proc_read_entry("smtc", 0444, NULL,
+	                                    proc_read_smtc, NULL);
 }
diff --git a/arch/mips/kernel/smtc.c b/arch/mips/kernel/smtc.c
index 75a4fd7..4c78101 100644
--- a/arch/mips/kernel/smtc.c
+++ b/arch/mips/kernel/smtc.c
@@ -34,15 +34,14 @@
 #include <asm/hardirq.h>
 #include <asm/hazards.h>
 #include <asm/irq.h>
-#include <asm/idle.h>
 #include <asm/mmu_context.h>
 #include <asm/mipsregs.h>
 #include <asm/cacheflush.h>
 #include <asm/time.h>
 #include <asm/addrspace.h>
+#include <asm/setup.h>
 #include <asm/smtc.h>
 #include <asm/smtc_proc.h>
-#include <asm/setup.h>
 
 /*
  * SMTC Kernel needs to manipulate low-level CPU interrupt mask
@@ -88,13 +87,6 @@ struct smtc_ipi_q IPIQ[NR_CPUS];
 static struct smtc_ipi_q freeIPIq;
 
 
-/*
- * Number of FPU contexts for each VPE
- */
-
-static int smtc_nconf1[MAX_SMTC_VPES];
-
-
 /* Forward declarations */
 
 void ipi_decode(struct smtc_ipi *);
@@ -183,9 +175,9 @@ static int __init tintq(char *str)
 
 __setup("tintq=", tintq);
 
-static int imstuckcount[MAX_SMTC_VPES][8];
+static int imstuckcount[2][8];
 /* vpemask represents IM/IE bits of per-VPE Status registers, low-to-high */
-static int vpemask[MAX_SMTC_VPES][8] = {
+static int vpemask[2][8] = {
 	{0, 0, 1, 0, 0, 0, 0, 1},
 	{0, 0, 0, 0, 0, 0, 0, 1}
 };
@@ -237,7 +229,7 @@ static void smtc_configure_tlb(void)
 		    mips_ihb();
 		    /* No need to un-Halt - that happens later anyway */
 		    for (i=0; i < vpes; i++) {
-			write_tc_c0_tcbind(i);
+		    	write_tc_c0_tcbind(i);
 			/*
 			 * To be 100% sure we're really getting the right
 			 * information, we exit the configuration state
@@ -288,7 +280,7 @@ static void smtc_configure_tlb(void)
 
 /*
  * Incrementally build the CPU map out of constituent MIPS MT cores,
- * using the specified available VPEs and TCs.	Plaform code needs
+ * using the specified available VPEs and TCs.  Plaform code needs
  * to ensure that each MIPS MT core invokes this routine on reset,
  * one at a time(!).
  *
@@ -331,7 +323,7 @@ int __init smtc_build_cpu_map(int start_cpu_slot)
 
 /*
  * Common setup before any secondaries are started
- * Make sure all CPUs are in a sensible state before we boot any of the
+ * Make sure all CPU's are in a sensible state before we boot any of the
  * secondaries.
  *
  * For MIPS MT "SMTC" operation, we set up all TCs, spread as evenly
@@ -340,22 +332,6 @@ int __init smtc_build_cpu_map(int start_cpu_slot)
 
 static void smtc_tc_setup(int vpe, int tc, int cpu)
 {
-	static int cp1contexts[MAX_SMTC_VPES];
-
-	/*
-	 * Make a local copy of the available FPU contexts in order
-	 * to keep track of TCs that can have one.
-	 */
-	if (tc == 1)
-	{
-		/*
-		 * FIXME: Multi-core SMTC hasn't been tested and the
-		 *	  maximum number of VPEs may change.
-		 */
-		cp1contexts[0] = smtc_nconf1[0] - 1;
-		cp1contexts[1] = smtc_nconf1[1];
-	}
-
 	settc(tc);
 	write_tc_c0_tchalt(TCHALT_H);
 	mips_ihb();
@@ -365,33 +341,26 @@ static void smtc_tc_setup(int vpe, int tc, int cpu)
 	/*
 	 * TCContext gets an offset from the base of the IPIQ array
 	 * to be used in low-level code to detect the presence of
-	 * an active IPI queue.
+	 * an active IPI queue
 	 */
 	write_tc_c0_tccontext((sizeof(struct smtc_ipi_q) * cpu) << 16);
-
-	/* Bind TC to VPE. */
+	/* Bind tc to vpe */
 	write_tc_c0_tcbind(vpe);
-
-	/* In general, all TCs should have the same cpu_data indications. */
+	/* In general, all TCs should have the same cpu_data indications */
 	memcpy(&cpu_data[cpu], &cpu_data[0], sizeof(struct cpuinfo_mips));
-
-	/* Check to see if there is a FPU context available for this TC. */
-	if (!cp1contexts[vpe])
+	/* For 34Kf, start with TC/CPU 0 as sole owner of single FPU context */
+	if (cpu_data[0].cputype == CPU_34K ||
+	    cpu_data[0].cputype == CPU_1004K)
 		cpu_data[cpu].options &= ~MIPS_CPU_FPU;
-	else
-		cp1contexts[vpe]--;
-
-	/* Store the TC and VPE into the cpu_data structure. */
 	cpu_data[cpu].vpe_id = vpe;
 	cpu_data[cpu].tc_id = tc;
-
-	/* FIXME: Multi-core SMTC hasn't been tested, but be prepared. */
+	/* Multi-core SMTC hasn't been tested, but be prepared */
 	cpu_data[cpu].core = (read_vpe_c0_ebase() >> 1) & 0xff;
 }
 
 /*
- * Tweak to get Count registers synced as closely as possible. The
- * value seems good for 34K-class cores.
+ * Tweak to get Count registes in as close a sync as possible.
+ * Value seems good for 34K-class cores.
  */
 
 #define CP0_SKEW 8
@@ -498,24 +467,6 @@ void smtc_prepare_cpus(int cpus)
 	smtc_configure_tlb();
 
 	for (tc = 0, vpe = 0 ; (vpe < nvpe) && (tc < ntc) ; vpe++) {
-		/* Get number of CP1 contexts for each VPE. */
-		if (tc == 0)
-		{
-			/*
-			 * Do not call settc() for TC0 or the FPU context
-			 * value will be incorrect. Besides, we know that
-			 * we are TC0 anyway.
-			 */
-			smtc_nconf1[0] = ((read_vpe_c0_vpeconf1() &
-				VPECONF1_NCP1) >> VPECONF1_NCP1_SHIFT);
-			if (nvpe == 2)
-			{
-				settc(1);
-				smtc_nconf1[1] = ((read_vpe_c0_vpeconf1() &
-					VPECONF1_NCP1) >> VPECONF1_NCP1_SHIFT);
-				settc(0);
-			}
-		}
 		if (tcpervpe[vpe] == 0)
 			continue;
 		if (vpe != 0)
@@ -529,18 +480,6 @@ void smtc_prepare_cpus(int cpus)
 			 */
 			if (tc != 0) {
 				smtc_tc_setup(vpe, tc, cpu);
-				if (vpe != 0) {
-					/*
-					 * Set MVP bit (possibly again).  Do it
-					 * here to catch CPUs that have no TCs
-					 * bound to the VPE at reset.  In that
-					 * case, a TC must be bound to the VPE
-					 * before we can set VPEControl[MVP]
-					 */
-					write_vpe_c0_vpeconf0(
-						read_vpe_c0_vpeconf0() |
-						VPECONF0_MVP);
-				}
 				cpu++;
 			}
 			printk(" %d", tc);
@@ -677,6 +616,7 @@ void __cpuinit smtc_boot_secondary(int cpu, struct task_struct *idle)
 
 void smtc_init_secondary(void)
 {
+	local_irq_enable();
 }
 
 void smtc_smp_finish(void)
@@ -692,8 +632,6 @@ void smtc_smp_finish(void)
 	if (cpu > 0 && (cpu_data[cpu].vpe_id != cpu_data[cpu - 1].vpe_id))
 		write_c0_compare(read_c0_count() + mips_hpt_frequency/HZ);
 
-	local_irq_enable();
-
 	printk("TC %d going on-line as CPU %d\n",
 		cpu_data[smp_processor_id()].tc_id, smp_processor_id());
 }
@@ -763,9 +701,9 @@ void smtc_forward_irq(struct irq_data *d)
 	 * mask has been purged of bits corresponding to nonexistent and
 	 * offline "CPUs", and to TCs bound to VPEs other than the VPE
 	 * connected to the physical interrupt input for the interrupt
-	 * in question.	 Otherwise we have a nasty problem with interrupt
+	 * in question.  Otherwise we have a nasty problem with interrupt
 	 * mask management.  This is best handled in non-performance-critical
-	 * platform IRQ affinity setting code,	to minimize interrupt-time
+	 * platform IRQ affinity setting code,  to minimize interrupt-time
 	 * checks.
 	 */
 
@@ -859,6 +797,7 @@ void smtc_send_ipi(int cpu, int type, unsigned int action)
 	unsigned long flags;
 	int mtflags;
 	unsigned long tcrestart;
+	extern void r4k_wait_irqoff(void), __pastwait(void);
 	int set_resched_flag = (type == LINUX_SMP_IPI &&
 				action == SMP_RESCHEDULE_YOURSELF);
 
@@ -900,10 +839,10 @@ void smtc_send_ipi(int cpu, int type, unsigned int action)
 		mips_ihb();
 
 		/*
-		 * Inspect TCStatus - if IXMT is set, we have to queue
+	 	 * Inspect TCStatus - if IXMT is set, we have to queue
 		 * a message. Otherwise, we set up the "interrupt"
 		 * of the other TC
-		 */
+	 	 */
 		tcstatus = read_tc_c0_tcstatus();
 
 		if ((tcstatus & TCSTATUS_IXMT) != 0) {
@@ -914,7 +853,8 @@ void smtc_send_ipi(int cpu, int type, unsigned int action)
 			 */
 			if (cpu_wait == r4k_wait_irqoff) {
 				tcrestart = read_tc_c0_tcrestart();
-				if (address_is_in_r4k_wait_irqoff(tcrestart)) {
+				if (tcrestart >= (unsigned long)r4k_wait_irqoff
+				    && tcrestart < (unsigned long)__pastwait) {
 					write_tc_c0_tcrestart(__pastwait);
 					tcstatus &= ~TCSTATUS_IXMT;
 					write_tc_c0_tcstatus(tcstatus);
@@ -964,7 +904,7 @@ static void post_direct_ipi(int cpu, struct smtc_ipi *pipi)
 	 * CU bit of Status is indicator that TC was
 	 * already running on a kernel stack...
 	 */
-	if (tcstatus & ST0_CU0)	 {
+	if (tcstatus & ST0_CU0)  {
 		/* Note that this "- 1" is pointer arithmetic */
 		kstack = ((struct pt_regs *)read_tc_gpr_sp()) - 1;
 	} else {
@@ -1007,10 +947,11 @@ static void __irq_entry smtc_clock_tick_interrupt(void)
 	int irq = MIPS_CPU_IRQ_BASE + 1;
 
 	irq_enter();
+	msa_start_irq(irq);
 	kstat_incr_irqs_this_cpu(irq, irq_to_desc(irq));
 	cd = &per_cpu(mips_clockevent_device, cpu);
 	cd->event_handler(cd);
-	irq_exit();
+	msa_irq_exit(irq, msa_get_reg());
 }
 
 void ipi_decode(struct smtc_ipi *pipi)
@@ -1174,7 +1115,10 @@ static irqreturn_t ipi_interrupt(int irq, void *dev_idm)
 				if (pipi->type == LINUX_SMP_IPI &&
 				    (int)pipi->arg == SMP_RESCHEDULE_YOURSELF)
 					IPIQ[cpu].resched_flag = 0;
+				irq_enter();
+				msa_start_irq(irq);
 				ipi_decode(pipi);
+				msa_irq_exit(irq, msa_get_reg());
 				local_irq_restore(flags);
 			}
 		}
@@ -1288,7 +1232,7 @@ void smtc_idle_loop_hook(void)
 			for (tc = 0; tc < hook_ntcs; tc++) {
 				tcnoprog[tc] = 0;
 				clock_hang_reported[tc] = 0;
-			}
+	    		}
 			for (vpe = 0; vpe < 2; vpe++)
 				for (im = 0; im < 8; im++)
 					imstuckcount[vpe][im] = 0;
@@ -1485,7 +1429,7 @@ static int halt_state_save[NR_CPUS];
 
 /*
  * To really, really be sure that nothing is being done
- * by other TCs, halt them all.	 This code assumes that
+ * by other TCs, halt them all.  This code assumes that
  * a DVPE has already been done, so while their Halted
  * state is theoretically architecturally unstable, in
  * practice, it's not going to change while we're looking
diff --git a/arch/mips/kernel/time.c b/arch/mips/kernel/time.c
index 9d686bf..92f2f34 100644
--- a/arch/mips/kernel/time.c
+++ b/arch/mips/kernel/time.c
@@ -5,8 +5,8 @@
  *
  * Common time service routines for MIPS machines.
  *
- * This program is free software; you can redistribute	it and/or modify it
- * under  the terms of	the GNU General	 Public License as published by the
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
  * Free Software Foundation;  either version 2 of the  License, or (at your
  * option) any later version.
  */
@@ -62,20 +62,21 @@ EXPORT_SYMBOL(perf_irq);
  * time_init() - it does the following things.
  *
  * 1) plat_time_init() -
- *	a) (optional) set up RTC routines,
- *	b) (optional) calibrate and set the mips_hpt_frequency
+ * 	a) (optional) set up RTC routines,
+ *      b) (optional) calibrate and set the mips_hpt_frequency
  *	    (only needed if you intended to use cpu counter as timer interrupt
  *	     source)
  * 2) calculate a couple of cached variables for later usage
  */
 
 unsigned int mips_hpt_frequency;
+EXPORT_SYMBOL(mips_hpt_frequency);
 
 /*
  * This function exists in order to cause an error due to a duplicate
  * definition if platform code should have its own implementation.  The hook
  * to use instead is plat_time_init.  plat_time_init does not receive the
- * irqaction pointer argument anymore.	This is because any function which
+ * irqaction pointer argument anymore.  This is because any function which
  * initializes an interrupt timer now takes care of its own request_irq rsp.
  * setup_irq calls and each clock_event_device should use its own
  * struct irqrequest.
@@ -93,7 +94,7 @@ static __init int cpu_has_mfc0_count_bug(void)
 	case CPU_R4000MC:
 		/*
 		 * V3.0 is documented as suffering from the mfc0 from count bug.
-		 * Afaik this is the last version of the R4000.	 Later versions
+		 * Afaik this is the last version of the R4000.  Later versions
 		 * were marketed as R4400.
 		 */
 		return 1;
diff --git a/arch/mips/kernel/vmlinux.lds.S b/arch/mips/kernel/vmlinux.lds.S
index 05826d2..081262f 100644
--- a/arch/mips/kernel/vmlinux.lds.S
+++ b/arch/mips/kernel/vmlinux.lds.S
@@ -1,25 +1,29 @@
 #include <asm/asm-offsets.h>
+#include <asm/page.h>
 #include <asm/thread_info.h>
-
-#define PAGE_SIZE _PAGE_SIZE
-
-/*
- * Put .bss..swapper_pg_dir as the first thing in .bss. This will
- * ensure that it has .bss alignment (64K).
- */
-#define BSS_FIRST_SECTIONS *(.bss..swapper_pg_dir)
-
 #include <asm-generic/vmlinux.lds.h>
 
 #undef mips
 #define mips mips
 OUTPUT_ARCH(mips)
+
+#ifdef PHYSADDR
+ENTRY(phys_entry)
+#define AT_LOCATION AT(PHYSADDR)
+#else
 ENTRY(kernel_entry)
+#define AT_LOCATION
+#endif
+
 PHDRS {
 	text PT_LOAD FLAGS(7);	/* RWX */
 	note PT_NOTE FLAGS(4);	/* R__ */
 }
 
+#ifdef PHYSADDR
+phys_entry = kernel_entry - LOADADDR + PHYSADDR;
+#endif
+
 #ifdef CONFIG_32BIT
 	#ifdef CONFIG_CPU_LITTLE_ENDIAN
 		jiffies	 = jiffies_64;
@@ -127,20 +131,10 @@ SECTIONS
 	}
 
 	PERCPU_SECTION(1 << CONFIG_MIPS_L1_CACHE_SHIFT)
-	/*
-	 * Align to 64K in attempt to eliminate holes before the
-	 * .bss..swapper_pg_dir section at the start of .bss.  This
-	 * also satisfies PAGE_SIZE alignment as the largest page size
-	 * allowed is 64K.
-	 */
-	. = ALIGN(0x10000);
+	. = ALIGN(PAGE_SIZE);
 	__init_end = .;
 	/* freed after init ends here */
 
-	/*
-	 * Force .bss to 64K alignment so that .bss..swapper_pg_dir
-	 * gets that alignment.	 .sbss should be empty, so there will be
-	 * no holes after __init_end. */
 	BSS_SECTION(0, 0x10000, 0)
 
 	_end = . ;
diff --git a/arch/mips/lib/dump_tlb.c b/arch/mips/lib/dump_tlb.c
index 32b9f21..3f69725 100644
--- a/arch/mips/lib/dump_tlb.c
+++ b/arch/mips/lib/dump_tlb.c
@@ -50,9 +50,8 @@ static void dump_tlb(int first, int last)
 {
 	unsigned long s_entryhi, entryhi, asid;
 	unsigned long long entrylo0, entrylo1;
-	unsigned int s_index, s_pagemask, pagemask, c0, c1, i;
+	unsigned int s_index, pagemask, c0, c1, i;
 
-	s_pagemask = read_c0_pagemask();
 	s_entryhi = read_c0_entryhi();
 	s_index = read_c0_index();
 	asid = s_entryhi & 0xff;
@@ -63,7 +62,7 @@ static void dump_tlb(int first, int last)
 		tlb_read();
 		BARRIER();
 		pagemask = read_c0_pagemask();
-		entryhi	 = read_c0_entryhi();
+		entryhi  = read_c0_entryhi();
 		entrylo0 = read_c0_entrylo0();
 		entrylo1 = read_c0_entrylo1();
 
@@ -104,7 +103,6 @@ static void dump_tlb(int first, int last)
 
 	write_c0_entryhi(s_entryhi);
 	write_c0_index(s_index);
-	write_c0_pagemask(s_pagemask);
 }
 
 void dump_tlb_all(void)
diff --git a/arch/mips/lib/memcpy-inatomic.S b/arch/mips/lib/memcpy-inatomic.S
new file mode 100644
index 0000000..68853a0
--- /dev/null
+++ b/arch/mips/lib/memcpy-inatomic.S
@@ -0,0 +1,451 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Unified implementation of memcpy, memmove and the __copy_user backend.
+ *
+ * Copyright (C) 1998, 99, 2000, 01, 2002 Ralf Baechle (ralf@gnu.org)
+ * Copyright (C) 1999, 2000, 01, 2002 Silicon Graphics, Inc.
+ * Copyright (C) 2002 Broadcom, Inc.
+ *   memcpy/copy_user author: Mark Vandevoorde
+ * Copyright (C) 2007  Maciej W. Rozycki
+ *
+ * Mnemonic names for arguments to memcpy/__copy_user
+ */
+
+/*
+ * Hack to resolve longstanding prefetch issue
+ *
+ * Prefetching may be fatal on some systems if we're prefetching beyond the
+ * end of memory on some systems.  It's also a seriously bad idea on non
+ * dma-coherent systems.
+ */
+#ifdef CONFIG_DMA_NONCOHERENT
+#undef CONFIG_CPU_HAS_PREFETCH
+#endif
+#ifdef CONFIG_MIPS_MALTA
+#undef CONFIG_CPU_HAS_PREFETCH
+#endif
+
+#include <asm/asm.h>
+#include <asm/asm-offsets.h>
+#include <asm/regdef.h>
+
+#define dst a0
+#define src a1
+#define len a2
+
+/*
+ * Spec
+ *
+ * memcpy copies len bytes from src to dst and sets v0 to dst.
+ * It assumes that
+ *   - src and dst don't overlap
+ *   - src is readable
+ *   - dst is writable
+ * memcpy uses the standard calling convention
+ *
+ * __copy_user copies up to len bytes from src to dst and sets a2 (len) to
+ * the number of uncopied bytes due to an exception caused by a read or write.
+ * __copy_user assumes that src and dst don't overlap, and that the call is
+ * implementing one of the following:
+ *   copy_to_user
+ *     - src is readable  (no exceptions when reading src)
+ *   copy_from_user
+ *     - dst is writable  (no exceptions when writing dst)
+ * __copy_user uses a non-standard calling convention; see
+ * include/asm-mips/uaccess.h
+ *
+ * When an exception happens on a load, the handler must
+ # ensure that all of the destination buffer is overwritten to prevent
+ * leaking information to user mode programs.
+ */
+
+/*
+ * Implementation
+ */
+
+/*
+ * The exception handler for loads requires that:
+ *  1- AT contain the address of the byte just past the end of the source
+ *     of the copy,
+ *  2- src_entry <= src < AT, and
+ *  3- (dst - src) == (dst_entry - src_entry),
+ * The _entry suffix denotes values when __copy_user was called.
+ *
+ * (1) is set up up by uaccess.h and maintained by not writing AT in copy_user
+ * (2) is met by incrementing src by the number of bytes copied
+ * (3) is met by not doing loads between a pair of increments of dst and src
+ *
+ * The exception handlers for stores adjust len (if necessary) and return.
+ * These handlers do not need to overwrite any data.
+ *
+ * For __rmemcpy and memmove an exception is always a kernel bug, therefore
+ * they're not protected.
+ */
+
+#define EXC(inst_reg,addr,handler)		\
+9:	inst_reg, addr;				\
+	.section __ex_table,"a";		\
+	PTR	9b, handler;			\
+	.previous
+
+/*
+ * Only on the 64-bit kernel we can made use of 64-bit registers.
+ */
+#ifdef CONFIG_64BIT
+#define USE_DOUBLE
+#endif
+
+#ifdef USE_DOUBLE
+
+#define LOAD   ld
+#define LOADL  ldl
+#define LOADR  ldr
+#define STOREL sdl
+#define STORER sdr
+#define STORE  sd
+#define ADD    daddu
+#define SUB    dsubu
+#define SRL    dsrl
+#define SRA    dsra
+#define SLL    dsll
+#define SLLV   dsllv
+#define SRLV   dsrlv
+#define NBYTES 8
+#define LOG_NBYTES 3
+
+/*
+ * As we are sharing code base with the mips32 tree (which use the o32 ABI
+ * register definitions). We need to redefine the register definitions from
+ * the n64 ABI register naming to the o32 ABI register naming.
+ */
+#undef t0
+#undef t1
+#undef t2
+#undef t3
+#define t0	$8
+#define t1	$9
+#define t2	$10
+#define t3	$11
+#define t4	$12
+#define t5	$13
+#define t6	$14
+#define t7	$15
+
+#else
+
+#define LOAD   lw
+#define LOADL  lwl
+#define LOADR  lwr
+#define STOREL swl
+#define STORER swr
+#define STORE  sw
+#define ADD    addu
+#define SUB    subu
+#define SRL    srl
+#define SLL    sll
+#define SRA    sra
+#define SLLV   sllv
+#define SRLV   srlv
+#define NBYTES 4
+#define LOG_NBYTES 2
+
+#endif /* USE_DOUBLE */
+
+#ifdef CONFIG_CPU_LITTLE_ENDIAN
+#define LDFIRST LOADR
+#define LDREST  LOADL
+#define STFIRST STORER
+#define STREST  STOREL
+#define SHIFT_DISCARD SLLV
+#else
+#define LDFIRST LOADL
+#define LDREST  LOADR
+#define STFIRST STOREL
+#define STREST  STORER
+#define SHIFT_DISCARD SRLV
+#endif
+
+#define FIRST(unit) ((unit)*NBYTES)
+#define REST(unit)  (FIRST(unit)+NBYTES-1)
+#define UNIT(unit)  FIRST(unit)
+
+#define ADDRMASK (NBYTES-1)
+
+	.text
+	.set	noreorder
+#ifndef CONFIG_CPU_DADDI_WORKAROUNDS
+	.set	noat
+#else
+	.set	at=v1
+#endif
+
+/*
+ * A combined memcpy/__copy_user
+ * __copy_user sets len to 0 for success; else to an upper bound of
+ * the number of uncopied bytes.
+ * memcpy sets v0 to dst.
+ */
+	.align	5
+LEAF(__copy_user_inatomic)
+	/*
+	 * Note: dst & src may be unaligned, len may be 0
+	 * Temps
+	 */
+#define rem t8
+
+	/*
+	 * The "issue break"s below are very approximate.
+	 * Issue delays for dcache fills will perturb the schedule, as will
+	 * load queue full replay traps, etc.
+	 *
+	 * If len < NBYTES use byte operations.
+	 */
+	PREF(	0, 0(src) )
+	PREF(	1, 0(dst) )
+	sltu	t2, len, NBYTES
+	and	t1, dst, ADDRMASK
+	PREF(	0, 1*32(src) )
+	PREF(	1, 1*32(dst) )
+	bnez	t2, .Lcopy_bytes_checklen
+	 and	t0, src, ADDRMASK
+	PREF(	0, 2*32(src) )
+	PREF(	1, 2*32(dst) )
+	bnez	t1, .Ldst_unaligned
+	 nop
+	bnez	t0, .Lsrc_unaligned_dst_aligned
+	/*
+	 * use delay slot for fall-through
+	 * src and dst are aligned; need to compute rem
+	 */
+.Lboth_aligned:
+	 SRL	t0, len, LOG_NBYTES+3    	# +3 for 8 units/iter
+	beqz	t0, .Lcleanup_both_aligned	# len < 8*NBYTES
+	 and	rem, len, (8*NBYTES-1)	 	# rem = len % (8*NBYTES)
+	PREF(	0, 3*32(src) )
+	PREF(	1, 3*32(dst) )
+	.align	4
+1:
+EXC(	LOAD	t0, UNIT(0)(src),	.Ll_exc)
+EXC(	LOAD	t1, UNIT(1)(src),	.Ll_exc_copy)
+EXC(	LOAD	t2, UNIT(2)(src),	.Ll_exc_copy)
+EXC(	LOAD	t3, UNIT(3)(src),	.Ll_exc_copy)
+	SUB	len, len, 8*NBYTES
+EXC(	LOAD	t4, UNIT(4)(src),	.Ll_exc_copy)
+EXC(	LOAD	t7, UNIT(5)(src),	.Ll_exc_copy)
+	STORE	t0, UNIT(0)(dst)
+	STORE	t1, UNIT(1)(dst)
+EXC(	LOAD	t0, UNIT(6)(src),	.Ll_exc_copy)
+EXC(	LOAD	t1, UNIT(7)(src),	.Ll_exc_copy)
+	ADD	src, src, 8*NBYTES
+	ADD	dst, dst, 8*NBYTES
+	STORE	t2, UNIT(-6)(dst)
+	STORE	t3, UNIT(-5)(dst)
+	STORE	t4, UNIT(-4)(dst)
+	STORE	t7, UNIT(-3)(dst)
+	STORE	t0, UNIT(-2)(dst)
+	STORE	t1, UNIT(-1)(dst)
+	PREF(	0, 8*32(src) )
+	PREF(	1, 8*32(dst) )
+	bne	len, rem, 1b
+	 nop
+
+	/*
+	 * len == rem == the number of bytes left to copy < 8*NBYTES
+	 */
+.Lcleanup_both_aligned:
+	beqz	len, .Ldone
+	 sltu	t0, len, 4*NBYTES
+	bnez	t0, .Lless_than_4units
+	 and	rem, len, (NBYTES-1)	# rem = len % NBYTES
+	/*
+	 * len >= 4*NBYTES
+	 */
+EXC(	LOAD	t0, UNIT(0)(src),	.Ll_exc)
+EXC(	LOAD	t1, UNIT(1)(src),	.Ll_exc_copy)
+EXC(	LOAD	t2, UNIT(2)(src),	.Ll_exc_copy)
+EXC(	LOAD	t3, UNIT(3)(src),	.Ll_exc_copy)
+	SUB	len, len, 4*NBYTES
+	ADD	src, src, 4*NBYTES
+	STORE	t0, UNIT(0)(dst)
+	STORE	t1, UNIT(1)(dst)
+	STORE	t2, UNIT(2)(dst)
+	STORE	t3, UNIT(3)(dst)
+	.set	reorder				/* DADDI_WAR */
+	ADD	dst, dst, 4*NBYTES
+	beqz	len, .Ldone
+	.set	noreorder
+.Lless_than_4units:
+	/*
+	 * rem = len % NBYTES
+	 */
+	beq	rem, len, .Lcopy_bytes
+	 nop
+1:
+EXC(	LOAD	t0, 0(src),		.Ll_exc)
+	ADD	src, src, NBYTES
+	SUB	len, len, NBYTES
+	STORE	t0, 0(dst)
+	.set	reorder				/* DADDI_WAR */
+	ADD	dst, dst, NBYTES
+	bne	rem, len, 1b
+	.set	noreorder
+
+	/*
+	 * src and dst are aligned, need to copy rem bytes (rem < NBYTES)
+	 * A loop would do only a byte at a time with possible branch
+	 * mispredicts.  Can't do an explicit LOAD dst,mask,or,STORE
+	 * because can't assume read-access to dst.  Instead, use
+	 * STREST dst, which doesn't require read access to dst.
+	 *
+	 * This code should perform better than a simple loop on modern,
+	 * wide-issue mips processors because the code has fewer branches and
+	 * more instruction-level parallelism.
+	 */
+#define bits t2
+	beqz	len, .Ldone
+	 ADD	t1, dst, len	# t1 is just past last byte of dst
+	li	bits, 8*NBYTES
+	SLL	rem, len, 3	# rem = number of bits to keep
+EXC(	LOAD	t0, 0(src),		.Ll_exc)
+	SUB	bits, bits, rem	# bits = number of bits to discard
+	SHIFT_DISCARD t0, t0, bits
+	STREST	t0, -1(t1)
+	jr	ra
+	 move	len, zero
+.Ldst_unaligned:
+	/*
+	 * dst is unaligned
+	 * t0 = src & ADDRMASK
+	 * t1 = dst & ADDRMASK; T1 > 0
+	 * len >= NBYTES
+	 *
+	 * Copy enough bytes to align dst
+	 * Set match = (src and dst have same alignment)
+	 */
+#define match rem
+EXC(	LDFIRST	t3, FIRST(0)(src),	.Ll_exc)
+	ADD	t2, zero, NBYTES
+EXC(	LDREST	t3, REST(0)(src),	.Ll_exc_copy)
+	SUB	t2, t2, t1	# t2 = number of bytes copied
+	xor	match, t0, t1
+	STFIRST t3, FIRST(0)(dst)
+	beq	len, t2, .Ldone
+	 SUB	len, len, t2
+	ADD	dst, dst, t2
+	beqz	match, .Lboth_aligned
+	 ADD	src, src, t2
+
+.Lsrc_unaligned_dst_aligned:
+	SRL	t0, len, LOG_NBYTES+2    # +2 for 4 units/iter
+	PREF(	0, 3*32(src) )
+	beqz	t0, .Lcleanup_src_unaligned
+	 and	rem, len, (4*NBYTES-1)   # rem = len % 4*NBYTES
+	PREF(	1, 3*32(dst) )
+1:
+/*
+ * Avoid consecutive LD*'s to the same register since some mips
+ * implementations can't issue them in the same cycle.
+ * It's OK to load FIRST(N+1) before REST(N) because the two addresses
+ * are to the same unit (unless src is aligned, but it's not).
+ */
+EXC(	LDFIRST	t0, FIRST(0)(src),	.Ll_exc)
+EXC(	LDFIRST	t1, FIRST(1)(src),	.Ll_exc_copy)
+	SUB     len, len, 4*NBYTES
+EXC(	LDREST	t0, REST(0)(src),	.Ll_exc_copy)
+EXC(	LDREST	t1, REST(1)(src),	.Ll_exc_copy)
+EXC(	LDFIRST	t2, FIRST(2)(src),	.Ll_exc_copy)
+EXC(	LDFIRST	t3, FIRST(3)(src),	.Ll_exc_copy)
+EXC(	LDREST	t2, REST(2)(src),	.Ll_exc_copy)
+EXC(	LDREST	t3, REST(3)(src),	.Ll_exc_copy)
+	PREF(	0, 9*32(src) )		# 0 is PREF_LOAD  (not streamed)
+	ADD	src, src, 4*NBYTES
+#ifdef CONFIG_CPU_SB1
+	nop				# improves slotting
+#endif
+	STORE	t0, UNIT(0)(dst)
+	STORE	t1, UNIT(1)(dst)
+	STORE	t2, UNIT(2)(dst)
+	STORE	t3, UNIT(3)(dst)
+	PREF(	1, 9*32(dst) )     	# 1 is PREF_STORE (not streamed)
+	.set	reorder				/* DADDI_WAR */
+	ADD	dst, dst, 4*NBYTES
+	bne	len, rem, 1b
+	.set	noreorder
+
+.Lcleanup_src_unaligned:
+	beqz	len, .Ldone
+	 and	rem, len, NBYTES-1  # rem = len % NBYTES
+	beq	rem, len, .Lcopy_bytes
+	 nop
+1:
+EXC(	LDFIRST t0, FIRST(0)(src),	.Ll_exc)
+EXC(	LDREST	t0, REST(0)(src),	.Ll_exc_copy)
+	ADD	src, src, NBYTES
+	SUB	len, len, NBYTES
+	STORE	t0, 0(dst)
+	.set	reorder				/* DADDI_WAR */
+	ADD	dst, dst, NBYTES
+	bne	len, rem, 1b
+	.set	noreorder
+
+.Lcopy_bytes_checklen:
+	beqz	len, .Ldone
+	 nop
+.Lcopy_bytes:
+	/* 0 < len < NBYTES  */
+#define COPY_BYTE(N)			\
+EXC(	lb	t0, N(src), .Ll_exc);	\
+	SUB	len, len, 1;		\
+	beqz	len, .Ldone;		\
+	 sb	t0, N(dst)
+
+	COPY_BYTE(0)
+	COPY_BYTE(1)
+#ifdef USE_DOUBLE
+	COPY_BYTE(2)
+	COPY_BYTE(3)
+	COPY_BYTE(4)
+	COPY_BYTE(5)
+#endif
+EXC(	lb	t0, NBYTES-2(src), .Ll_exc)
+	SUB	len, len, 1
+	jr	ra
+	 sb	t0, NBYTES-2(dst)
+.Ldone:
+	jr	ra
+	 nop
+	END(__copy_user_inatomic)
+
+.Ll_exc_copy:
+	/*
+	 * Copy bytes from src until faulting load address (or until a
+	 * lb faults)
+	 *
+	 * When reached by a faulting LDFIRST/LDREST, THREAD_BUADDR($28)
+	 * may be more than a byte beyond the last address.
+	 * Hence, the lb below may get an exception.
+	 *
+	 * Assumes src < THREAD_BUADDR($28)
+	 */
+	LOAD	t0, TI_TASK($28)
+	 nop
+	LOAD	t0, THREAD_BUADDR(t0)
+1:
+EXC(	lb	t1, 0(src),	.Ll_exc)
+	ADD	src, src, 1
+	sb	t1, 0(dst)	# can't fault -- we're copy_from_user
+	.set	reorder				/* DADDI_WAR */
+	ADD	dst, dst, 1
+	bne	src, t0, 1b
+	.set	noreorder
+.Ll_exc:
+	LOAD	t0, TI_TASK($28)
+	 nop
+	LOAD	t0, THREAD_BUADDR(t0)	# t0 is just past last good address
+	 nop
+	SUB	len, AT, t0		# len number of uncopied bytes
+	jr	ra
+	 nop
diff --git a/arch/mips/math-emu/kernel_linkage.c b/arch/mips/math-emu/kernel_linkage.c
index 1c58657..ed460ac 100644
--- a/arch/mips/math-emu/kernel_linkage.c
+++ b/arch/mips/math-emu/kernel_linkage.c
@@ -1,6 +1,17 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
 /*
  *  Kevin D. Kissell, kevink@mips and Carsten Langgaard, carstenl@mips.com
- *  Copyright (C) 2000 MIPS Technologies, Inc.	All rights reserved.
+ *  Copyright (C) 2000 MIPS Technologies, Inc.  All rights reserved.
  *
  *  This program is free software; you can distribute it and/or modify it
  *  under the terms of the GNU General Public License (Version 2) as
@@ -29,6 +40,198 @@
 
 #define SIGNALLING_NAN 0x7ff800007ff80000LL
 
+#ifdef CONFIG_PROFILE_MATHEMU
+
+#include <asm/inst.h>
+#include <linux/proc_fs.h>
+
+#define FPUEMU_PROC_ENT "fpuemu"
+static struct proc_dir_entry *proc_ent;
+
+/*
+ * func field of cop1 instructions using d, s or w format.
+ */
+static char *cop1_sdw_func_names[] = {
+  "fadd_op",     /* 0x00 */
+  "fsub_op",     /* 0x01 */
+  "fmul_op",     /* 0x02 */
+  "fdiv_op",     /* 0x03 */
+  "fsqrt_op",    /* 0x04 */
+  "fabs_op",     /* 0x05 */
+  "fmov_op",     /* 0x06 */
+  "fneg_op",     /* 0x07 */
+  "froundl_op",  /* 0x08 */
+  "ftruncl_op",  /* 0x09 */
+  "fceill_op",   /* 0x0a */
+  "ffloorl_op",  /* 0x0b */
+  "fround_op",   /* 0x0c */
+  "ftrunc_op",   /* 0x0d */
+  "fceil_op",    /* 0x0e */
+  "ffloor_op",   /* 0x0f */
+  NULL,          /* 0x10 */
+  "fmovc_op",    /* 0x11 */
+  "fmovz_op",    /* 0x12 */
+  "fmovn_op",    /* 0x13 */
+  NULL,          /* 0x14 */
+  "frecip_op",   /* 0x15 */
+  "frsqrt_op",   /* 0x16 */
+  NULL,          /* 0x17 */
+  NULL,          /* 0x18 */
+  NULL,          /* 0x19 */
+  NULL,          /* 0x1a */
+  NULL,          /* 0x1b */
+  NULL,          /* 0x1c */
+  NULL,          /* 0x1d */
+  NULL,          /* 0x1e */
+  NULL,          /* 0x1f */
+  "fcvts_op",    /* 0x20 */
+  "fcvtd_op",    /* 0x21 */
+  "fcvte_op",    /* 0x22 */
+  NULL,          /* 0x23 */
+  "fcvtw_op",    /* 0x24 */
+  "fcvtl_op",    /* 0x25 */
+  NULL,          /* 0x26 */
+  NULL,          /* 0x27 */
+  NULL,          /* 0x28 */
+  NULL,          /* 0x29 */
+  NULL,          /* 0x2a */
+  NULL,          /* 0x2b */
+  NULL,          /* 0x2c */
+  NULL,          /* 0x2d */
+  NULL,          /* 0x2e */
+  NULL,          /* 0x2f */
+  "fcmp_op"      /* 0x30 */
+};
+
+static int proc_read(char *buf , char **start, off_t offset,
+                        int len, int *eof, void *data)
+{
+  char *p = buf;
+
+  //printk("proc_read entered %p %p %d %d %p %p\n", buf, start, offset, len, eof, data);  
+  p += sprintf(p, "%s\n", "FPUEMU Statistics:");
+  p += sprintf(p, "emulated: %d\n", fpuemuprivate.stats.emulated);
+  p += sprintf(p, "loads: %d\n", fpuemuprivate.stats.loads);
+  p += sprintf(p, "stores: %d\n", fpuemuprivate.stats.stores);
+  p += sprintf(p, "cp1ops: %d\n", fpuemuprivate.stats.cp1ops);
+  p += sprintf(p, "cp1xops: %d\n", fpuemuprivate.stats.cp1xops);
+  p += sprintf(p, "errors: %d\n", fpuemuprivate.stats.errors);
+
+  p += sprintf(p, "format totals:\n");
+  p += sprintf(p, "\ts_fmt: %d\n", fpuemuprivate.stats.s_format.total);
+  if (fpuemuprivate.stats.s_format.total > 0) {
+    int i, j;
+    p += sprintf(p, "\tfunctions:");
+    for (i = 0; i < 8; i++) {
+      p += sprintf(p, "\n\t");
+      for (j = 0; j < 8; j++) {
+	p += sprintf(p,"%d ",
+		     fpuemuprivate.stats.s_format.ops[i*8 + j]);
+      }
+    }
+    p += sprintf(p, "\n");
+  }
+  p += sprintf(p, "\td_fmt: %d\n", fpuemuprivate.stats.d_format.total);
+  if (fpuemuprivate.stats.d_format.total > 0) {
+    int i, j;
+    p += sprintf(p, "\tfunctions:");
+    for (i = 0; i < 8; i++) {
+      p += sprintf(p, "\n\t");
+      for (j = 0; j < 8; j++) {
+	p += sprintf(p,"%d ",
+		     fpuemuprivate.stats.d_format.ops[i*8 + j]);
+      }
+    }
+    p += sprintf(p, "\n");
+  }
+  p += sprintf(p, "\tw_fmt: %d\n", fpuemuprivate.stats.w_format.total);
+  if (fpuemuprivate.stats.w_format.total > 0) {
+    int i, j;
+    p += sprintf(p, "\tfunctions:");
+    for (i = 0; i < 8; i++) {
+      p += sprintf(p, "\n\t");
+      for (j = 0; j < 8; j++) {
+	p += sprintf(p,"%d ",
+		     fpuemuprivate.stats.w_format.ops[i*8 + j]);
+      }
+    }
+    p += sprintf(p, "\n");
+  }
+  p += sprintf(p, "\tl_fmt: %d\n", fpuemuprivate.stats.l_format.total);
+  if (fpuemuprivate.stats.l_format.total > 0) {
+    int i, j;
+    p += sprintf(p, "\tfunctions:");
+    for (i = 0; i < 8; i++) {
+      p += sprintf(p, "\n\t");
+      for (j = 0; j < 8; j++) {
+	p += sprintf(p,"%d ",
+		     fpuemuprivate.stats.l_format.ops[i*8 + j]);
+      }
+    }
+    p += sprintf(p, "\n");
+  }
+  
+  if (fpuemuprivate.stats.s_format.total > 0) {
+    int i, fcmp_total;
+    p += sprintf(p, "\nSingle precision:\ttotal %d\n",
+		 fpuemuprivate.stats.s_format.total);
+    for (i = fadd_op; i < fcmp_op; i++)
+      if (fpuemuprivate.stats.s_format.ops[i] > 0)
+	p += sprintf(p, "\t%s:\t%d\n", cop1_sdw_func_names[i],
+		     fpuemuprivate.stats.s_format.ops[i]);
+    for (i = fcmp_op, fcmp_total = 0; i < 0x40; i++)
+      fcmp_total += fpuemuprivate.stats.s_format.ops[i];
+    if (fcmp_total > 0)
+      p += sprintf(p, "\t%s:\t%d (all compare ops combined)\n",
+		   cop1_sdw_func_names[fcmp_op], fcmp_total);
+    p += sprintf(p, "\n");
+  }
+
+  if (fpuemuprivate.stats.d_format.total > 0) {
+    int i, fcmp_total;
+    p += sprintf(p, "\nDouble precision:\ttotal %d\n",
+		 fpuemuprivate.stats.d_format.total);
+    for (i = fadd_op; i < fcmp_op; i++)
+      if (fpuemuprivate.stats.d_format.ops[i] > 0)
+	p += sprintf(p, "\t%s:\t%d\n", cop1_sdw_func_names[i],
+		     fpuemuprivate.stats.d_format.ops[i]);
+    for (i = fcmp_op, fcmp_total = 0; i < 0x40; i++)
+      fcmp_total += fpuemuprivate.stats.d_format.ops[i];
+    if (fcmp_total > 0)
+      p += sprintf(p, "\t%s:\t%d (all compare ops combined)\n",
+		   cop1_sdw_func_names[fcmp_op], fcmp_total);
+    p += sprintf(p, "\n");
+  }
+
+  if (fpuemuprivate.stats.w_format.total > 0) {
+    int i, fcmp_total;
+    p += sprintf(p, "\nw format:\ttotal %d\n",
+		 fpuemuprivate.stats.w_format.total);
+    for (i = fadd_op; i < fcmp_op; i++)
+      if (fpuemuprivate.stats.w_format.ops[i] > 0)
+	p += sprintf(p, "\t%s:\t%d\n", cop1_sdw_func_names[i],
+		     fpuemuprivate.stats.w_format.ops[i]);
+    for (i = fcmp_op, fcmp_total = 0; i < 0x40; i++)
+      fcmp_total += fpuemuprivate.stats.w_format.ops[i];
+    if (fcmp_total > 0)
+      p += sprintf(p, "\t%s:\t%d (all compare ops combined)\n",
+		   cop1_sdw_func_names[fcmp_op], fcmp_total);
+    p += sprintf(p, "\n");
+  }
+
+  *eof = 1;
+  return p - buf;
+}
+
+static int proc_write(struct file *file, const char *user_buffer,
+                         unsigned long count, void *data)
+{
+  printk("FPUEMU: clearing stats\n");
+  memset(&fpuemuprivate.stats, '\0', sizeof(fpuemuprivate.stats));
+  return count;
+}
+#endif
+
 void fpu_emulator_init_fpu(void)
 {
 	static int first = 1;
@@ -37,6 +240,14 @@ void fpu_emulator_init_fpu(void)
 	if (first) {
 		first = 0;
 		printk("Algorithmics/MIPS FPU Emulator v1.5\n");
+#ifdef CONFIG_PROFILE_MATHEMU
+		proc_ent = create_proc_entry(FPUEMU_PROC_ENT, S_IWUSR | S_IRUGO,
+					     &proc_root);
+		if (proc_ent) {
+		  proc_ent->read_proc = proc_read;
+		  proc_ent->write_proc = proc_write;
+		}
+#endif
 	}
 
 	current->thread.fpu.fcr31 = 0;
diff --git a/arch/mips/mm/Makefile b/arch/mips/mm/Makefile
index e87aae1..dde78cb 100644
--- a/arch/mips/mm/Makefile
+++ b/arch/mips/mm/Makefile
@@ -24,3 +24,7 @@ obj-$(CONFIG_RM7000_CPU_SCACHE) += sc-rm7k.o
 obj-$(CONFIG_MIPS_CPU_SCACHE)	+= sc-mips.o
 
 obj-$(CONFIG_SYS_SUPPORTS_MICROMIPS) += uasm-micromips.o
+
+obj-$(CONFIG_CPU_XLP)		+= c-phoenix.o tlb-r4k.o \
+				   cex-nlm.o cerr-nlm.o
+EXTRA_CFLAGS += -DNLM_HAL_LINUX_KERNEL
diff --git a/arch/mips/mm/c-phoenix.c b/arch/mips/mm/c-phoenix.c
new file mode 100644
index 0000000..92beed8
--- /dev/null
+++ b/arch/mips/mm/c-phoenix.c
@@ -0,0 +1,600 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+/*
+ * Copyright (C) 1996 David S. Miller (dm@engr.sgi.com)
+ * Copyright (C) 1997, 2001 Ralf Baechle (ralf@gnu.org)
+ * 
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
+ */ 
+#include <linux/init.h>
+#include <asm/asm.h>
+#include <asm/mmu_context.h>
+#include <asm/bootinfo.h>
+#include <asm/cacheops.h>
+#include <asm/cpu.h>
+#include <asm/uaccess.h>
+#include <linux/smp.h>
+#include <linux/kallsyms.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+
+#include <asm/rmi/debug.h>
+
+static unsigned int icache_linesz;
+static unsigned int icache_lines;
+
+#ifdef CONFIG_RMI_VMIPS
+extern void rmi_vmips_temp_xkphys_tlb_add(phys_t start, phys_t end, int *tlbs, int *tlbe);
+extern void rmi_vmips_wired_entry_remove(int index);
+#endif
+
+
+#define cacheop(op, base) __asm__ __volatile__ (".set push\n.set mips4\ncache %0, 0(%1)\n.set pop\n" : : "i"(op), "r"(base))
+
+#define cacheop_extable(op, base) do {                    \
+  __asm__ __volatile__(                                    \
+		       "    .set push                \n"   \
+		       "    .set noreorder           \n"   \
+		       "    .set mips4               \n"   \
+		       "1:  cache %0, 0(%1)           \n"  \
+		       "2:  .set pop                 \n"   \
+		       "    .section __ex_table,\"a\"\n"   \
+		            STR(PTR)"\t1b, 2b\n\t"        \
+		       "     .previous               \n"   \
+		       : : "i" (op), "r" (base));          \
+  } while (0) 
+
+#ifdef CONFIG_RMI_XLP
+
+static __inline__ void pipeline_flush(void)
+{
+	__asm__ __volatile__ (
+		".set push         \n"
+		".set arch=xlp     \n"
+		"dla      $8, 1f    \n"
+		"jr.hb   $8        \n"
+		"nop               \n"
+		"1: nop            \n"
+		".set pop          \n"
+		:
+		:
+		: "$8"
+		);
+}
+
+static __inline__ void sync_istream(void)
+{
+	pipeline_flush();
+}
+
+static __inline__ void cacheop_hazard(void)
+{
+	pipeline_flush();
+}
+
+static __inline__ void cacheop_sync_istream(void)
+{
+	pipeline_flush();
+}
+
+#else /* !CONFIG_RMI_XLP */
+
+static __inline__ void sync_istream(void)
+{
+  __asm__ __volatile__ (                                     
+                       ".set push                     \n"    
+                       ".set noreorder                \n"    
+		       //                       " la     $8, 1f                \n"    
+                       //" mtc0   $8, $14               \n"    
+                       //"eret                          \n"    
+		       //"1:nop                         \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+                       ".set pop                      \n"    
+                       : : : "$8"
+		       );
+}
+
+static __inline__ void cacheop_hazard(void)
+{
+  __asm__ __volatile__ (                                     
+                       ".set push                     \n"    
+                       ".set noreorder                \n"    
+                       " nop;nop;nop;nop              \n"    
+                       " nop;nop;nop;nop              \n"    
+                       ".set pop                      \n"    
+                       );  
+}
+
+static __inline__ void cacheop_sync_istream(void)
+{
+  cacheop_hazard();
+  sync_istream();
+}
+
+#endif /* !CONFIG_RMI_XLP */
+
+#if 0
+#define optimize_thread_flush() do { \
+  if ( (cpu_logical_map(smp_processor_id()) & 0x03) != 0) return; \
+} while(0) 
+#else
+#define optimize_thread_flush()
+#endif
+
+extern unsigned long phnx_ebase;
+/*****************************************************************************************
+ * 
+ * These routines support Generic Kernel cache flush requirements
+ *
+ *****************************************************************************************/
+void phoenix_flush_dcache_page(struct page *page)
+{
+  ClearPageDcacheDirty(page);    
+}
+
+EXPORT_SYMBOL(phoenix_flush_dcache_page);
+
+static void phoenix_local_flush_icache_range(unsigned long start, unsigned long end)
+{
+  unsigned long addr;
+  
+  //dbg_msg("flush icache range, start=%lx, end=%lx\n", start, end);
+
+  for(addr = (start & ~((unsigned long)(icache_linesz - 1))); addr < end; 
+            addr += icache_linesz) {
+    cacheop_extable(Hit_Invalidate_I, addr);
+  }
+
+  cacheop_sync_istream();
+}
+
+struct flush_icache_range_args {
+  unsigned long start;
+  unsigned long end;
+};
+struct flush_icache_range_args_paddr {
+  phys_t start;
+  phys_t end;
+};
+
+static void phoenix_flush_icache_range_ipi(void *info)
+{
+  struct flush_icache_range_args *args = info;
+
+  optimize_thread_flush();
+
+  phoenix_local_flush_icache_range(args->start, args->end);
+}
+
+void phoenix_flush_icache_range(unsigned long start, unsigned long end)
+{
+  struct flush_icache_range_args args;
+
+#ifdef CONFIG_PHOENIX_VM_DEBUG
+  dbg_msg("return address: ");
+  print_symbol("ra[0]=%s\n", return_address());
+#endif
+  
+  if ((end - start) > PAGE_SIZE) {
+    dbg_msg("flushing more than page size of icache addresses starting @ %lx\n", start);
+  }
+  
+  args.start = start;
+  args.end = end;
+  /* TODO: don't even send ipi to non-zero thread ids 
+   * This may require some changes to smp_call_function interface, for now just avoid 
+   * redundant cache ops
+   */
+  on_each_cpu(phoenix_flush_icache_range_ipi, &args, 1);
+}
+
+static void phoenix_flush_cache_sigtramp_ipi(void *info)
+{
+  unsigned long addr = (unsigned long)info;
+
+  optimize_thread_flush();
+
+  addr = addr & ~(icache_linesz - 1);
+  cacheop_extable(Hit_Invalidate_I, addr );
+  cacheop_sync_istream();
+}
+
+static void phoenix_flush_cache_sigtramp(unsigned long addr)
+{
+  on_each_cpu(phoenix_flush_cache_sigtramp_ipi, (void *) addr, 1);
+}
+
+/*****************************************************************************************
+ * 
+ * These routines support MIPS specific cache flush requirements.
+ * These are called only during bootup or special system calls 
+ *
+ *****************************************************************************************/
+
+static void phoenix_local_flush_icache(void)
+{
+  int i=0;
+  unsigned long base = CKSEG0;
+
+  //dbg_msg("flushing the whole damn local I-cache\n");
+
+  /* Index Invalidate all the lines and the ways */
+  for(i=0;i<icache_lines;i++) {
+    cacheop(Index_Invalidate_I, base);
+    base += icache_linesz;
+  }
+
+  cacheop_sync_istream(); 
+
+}
+
+static void phoenix_local_flush_dcache(void)
+{
+  int i=0;
+  unsigned long base = CKSEG0;
+  unsigned int lines;
+
+  //dbg_msg("flushing the whole damn local D-cache\n");
+
+  lines = current_cpu_data.dcache.ways * current_cpu_data.dcache.sets;
+  
+  /* Index Invalidate all the lines and the ways */  
+  for(i=0;i<lines;i++) {
+    cacheop(Index_Writeback_Inv_D, base);
+    base += current_cpu_data.dcache.linesz;
+  }
+
+  cacheop_hazard(); 
+
+}
+
+#ifdef CONFIG_KGDB
+void phoenix_flush_l1_icache_ipi(void *info)
+{
+	phoenix_local_flush_icache();
+}
+#endif
+
+#ifdef CONFIG_KGDB
+void phoenix_flush_l1_caches_ipi(void *info)
+#else
+static void phoenix_flush_l1_caches_ipi(void *info)
+#endif
+{
+  optimize_thread_flush();
+ 
+  phoenix_local_flush_dcache();
+  phoenix_local_flush_icache();
+}
+
+static void phoenix_flush_l1_caches(void)
+{
+  //dbg_msg("NASTY CACHE FLUSH: flushing L1 caches on all cpus!\n");
+  on_each_cpu(phoenix_flush_l1_caches_ipi, (void *)NULL, 1);
+}
+
+/*****************************************************************************************/
+
+static void phoenix_noflush(void) { /* do nothing */ }
+
+static __init void probe_l1_cache(void)
+{
+  struct cpuinfo_mips *c = &current_cpu_data;
+  unsigned int config1 = read_c0_config1();
+  int lsize = 0;
+  int icache_size=0, dcache_size=0;
+
+  if ((lsize = ((config1 >> 19) & 7)))
+    c->icache.linesz = 2 << lsize;
+  else
+    c->icache.linesz = lsize;
+  c->icache.sets = 64 << ((config1 >> 22) & 7);
+  c->icache.ways = 1 + ((config1 >> 16) & 7);
+
+  icache_size = c->icache.sets *
+    c->icache.ways *
+    c->icache.linesz;
+  c->icache.waybit = ffs(icache_size/c->icache.ways) - 1;
+
+  c->dcache.flags = 0;
+
+  if ((lsize = ((config1 >> 10) & 7)))
+    c->dcache.linesz = 2 << lsize;
+  else
+    c->dcache.linesz= lsize;
+  c->dcache.sets = 64 << ((config1 >> 13) & 7);
+  c->dcache.ways = 1 + ((config1 >> 7) & 7);
+
+  dcache_size = c->dcache.sets *
+    c->dcache.ways *
+    c->dcache.linesz;
+  c->dcache.waybit = ffs(dcache_size/c->dcache.ways) - 1;
+
+  if (smp_processor_id()==0) {
+    printk("Primary instruction cache %dkB, %d-way, linesize %d bytes.\n",
+	   icache_size >> 10,
+	   c->icache.ways, c->icache.linesz);
+    
+    printk("Primary data cache %dkB %d-way, linesize %d bytes.\n",
+	   dcache_size >> 10, c->dcache.ways, c->dcache.linesz);
+  }
+
+}
+
+static __inline__ void install_cerr_handler(void)
+{
+  extern char except_vec2_generic;
+
+  memcpy((void *)(phnx_ebase + 0x100), &except_vec2_generic, 0x80);
+}
+
+static void update_kseg0_coherency(void)
+{
+  int attr = read_c0_config() & CONF_CM_CMASK;
+
+  if (attr != 0x3) {
+
+    phoenix_local_flush_dcache();
+    phoenix_local_flush_icache();
+
+    change_c0_config(CONF_CM_CMASK, 0x3);
+
+    sync_istream();
+  }
+  _page_cachable_default = (0x3 << _CACHE_SHIFT);
+
+}
+
+void ld_mmu_phoenix(void)
+{
+	extern void build_clear_page(void);
+	extern void build_copy_page(void);
+	/* update cpu_data */
+
+	probe_l1_cache();
+
+	if (smp_processor_id()) {  
+
+#if 0
+		/* flush the exception vector region to make sure 
+		 * not to execute bootloader's exception code 
+		 */
+		phoenix_local_flush_icache_range(phnx_ebase, phnx_ebase + 0x400);
+#endif
+		phoenix_local_flush_icache();
+
+		update_kseg0_coherency();
+
+		return;
+	}
+
+	/* These values are assumed to be the same for all cores */
+	icache_lines = current_cpu_data.icache.ways * current_cpu_data.icache.sets;
+	icache_linesz = current_cpu_data.icache.linesz;
+
+	/* When does this function get called? Looks like MIPS has some syscalls
+	 * to flush the caches. 
+	 */
+	__flush_cache_all = phoenix_flush_l1_caches;
+
+	/* flush_cache_all: makes all kernel data coherent.
+	 * This gets called just before changing or removing
+	 * a mapping in the page-table-mapped kernel segment (kmap). 
+	 * Physical Cache -> do nothing
+	 */
+	flush_cache_all = phoenix_noflush;
+
+	/* flush_icache_range: makes the range of addresses coherent w.r.t I-cache and D-cache 
+	 * This gets called after the instructions are written to memory
+	 * All addresses are valid kernel or mapped user-space virtual addresses
+	 */
+	flush_icache_range = phoenix_flush_icache_range;
+
+	/* flush_cache_{mm, range, page}: make these memory locations, that may have been written
+	 *                                by a user process, coherent
+	 * These get called when virtual->physical translation of a user address space is about
+	 * to be changed. These are closely related to TLB coherency (flush_tlb_{mm, range, page})
+	 */
+	flush_cache_mm = (void (*)(struct mm_struct *))phoenix_noflush;
+	flush_cache_range = (void *) phoenix_noflush;
+	flush_cache_page = (void *) phoenix_noflush;
+
+	/* flush_icache_page: flush_dcache_page + update_mmu_cache takes care of this
+	 * 
+	 */
+	flush_data_cache_page = (void *) phoenix_noflush;
+
+	/* flush_cache_sigtramp: flush the single I-cache line with the proper fixup code
+	 */
+	flush_cache_sigtramp = phoenix_flush_cache_sigtramp;
+
+	/* flush_icache_all: This should get called only for Virtuall Tagged I-Caches
+	 */
+	flush_icache_all = (void *)phoenix_noflush;
+
+	local_flush_icache_range = phoenix_local_flush_icache_range;
+	local_flush_data_cache_page	= (void *)phoenix_noflush;
+
+	__flush_cache_vmap = (void *)phoenix_noflush;
+	__flush_cache_vunmap = (void *)phoenix_noflush;
+
+	install_cerr_handler();
+
+	build_clear_page();
+	build_copy_page();
+
+	phoenix_local_flush_icache();
+
+	update_kseg0_coherency();
+}
+
+#ifdef CONFIG_64BIT
+#define cacheop_paddr(op, base) __asm__ __volatile__ ( \
+                         ".set push\n"           \
+                         ".set noreorder\n"      \
+                         ".set mips64\n"          \
+                         "dli $8, 0x9800000000000000\n"              \
+                         "daddu $8, $8, %1\n"       \
+                         "cache %0, 0($8)\n"     \
+                         ".set pop\n"            \
+                         : : "i"(op), "r"(base) : "$8")
+
+#else
+static inline void cacheop_paddr(const unsigned int op, phys_t base)
+{
+	uint64_t temp_msb, temp_lsb;
+	phys_t temp1;
+
+	temp_msb = (uint64_t)(base >> 32);
+	temp_lsb = (uint64_t)(base & 0xffffffff);
+
+	__asm__ volatile(
+		".set push\n"
+		".set noreorder\n"
+		".set mips64\n"
+		"dli $8,0x9800000000000000\n"
+		"dsll32 %0, %2,0\n"
+		"or %0,%0,%3\n"
+		"daddu $8, $8, %0\n"  
+		"cache %1, 0($8)\n"
+		".set pop\n"
+		".set reorder\n"
+		: "=&r"(temp1)
+		: "i"(Hit_Invalidate_I), "r"(temp_msb) , "r"(temp_lsb)
+		:"$8"
+		);
+}
+#endif
+
+#define enable_KX(flags)   \
+ preempt_disable(); \
+ __asm__ __volatile__ (          \
+	".set push\n"              \
+	".set noat\n"               \
+	".set noreorder\n"     \
+	"mfc0 %0, $12\n\t"             \
+	"ori $1, %0, 0x81\n\t"   \
+	"xori $1, 1\n\t"      \
+	"mtc0 $1, $12\n"       \
+        ".set pop\n"          \
+        : "=r"(flags) ); \
+  preempt_enable();
+	
+#define disable_KX(flags)   \
+ __asm__ __volatile__ (          \
+	".set push\n"              \
+	"mtc0 %0, $12\n"       \
+        ".set pop\n"          \
+        : : "r"(flags) )
+	
+
+#define SETS_PER_WAY_SHIFT 22
+#define SETS_PER_WAY_MASK 0x7
+#define CACHELINE_SIZE_BITS 5
+
+static void phoenix_local_flush_icache_range_paddr(phys_t start, phys_t end)
+{
+	phys_t addr;
+#ifdef CONFIG_32BIT
+	unsigned long flags;
+	phys_t temp;
+#endif
+#ifdef CONFIG_RMI_VMIPS
+	int tlbs = 0, tlbe = 0;
+	rmi_vmips_temp_xkphys_tlb_add(start, end, &tlbs, &tlbe);
+#endif
+
+#ifdef CONFIG_RMI_XLP
+	int sets_per_way, niter, i;
+	uint64_t mask;
+
+	sets_per_way = (read_c0_config1() >> SETS_PER_WAY_SHIFT) & SETS_PER_WAY_MASK;
+	niter = sets_per_way + 6 + CACHELINE_SIZE_BITS - PAGE_SHIFT;
+	if (niter < 0)
+		niter = 0;
+	niter = 1 << niter;
+	mask = niter - 1;
+#endif
+
+#ifdef CONFIG_32BIT
+	enable_KX(flags);
+#endif
+    for (addr = (start & ~(phys_t)(icache_linesz - 1)); addr < end;
+                    addr += icache_linesz) {
+		cacheop_paddr(Hit_Invalidate_I, addr);
+#ifdef CONFIG_RMI_XLP
+		for (i = 1; i < niter; ++i)
+			cacheop_paddr(Hit_Invalidate_I, (addr & ~(mask << PAGE_SHIFT)) | (i << PAGE_SHIFT));
+#endif
+    }
+
+#ifdef CONFIG_32BIT
+	disable_KX(flags);
+#endif
+
+#ifdef CONFIG_RMI_VMIPS
+	for(;tlbe >= tlbs; tlbe--)
+        rmi_vmips_wired_entry_remove(tlbe); 
+
+#endif
+	cacheop_sync_istream();
+}
+
+static void phoenix_flush_icache_range_paddr_ipi(void *info)
+{
+  struct flush_icache_range_args_paddr *args = info;
+
+  optimize_thread_flush();
+
+  phoenix_local_flush_icache_range_paddr(args->start, args->end);
+}
+
+void phoenix_flush_icache_range_paddr(phys_t start)
+{
+  struct flush_icache_range_args_paddr args;
+
+#ifdef CONFIG_PHOENIX_VM_DEBUG
+  dbg_msg("return address: ");
+  print_symbol("ra[0]=%s\n", (unsigned long) return_address());
+#endif
+  
+  args.start = start;
+  args.end = start + PAGE_SIZE;
+  /* TODO: don't even send ipi to non-zero thread ids 
+   * This may require some changes to smp_call_function interface, for now just avoid 
+   * redundant cache ops
+   */
+  on_each_cpu(phoenix_flush_icache_range_paddr_ipi, &args, 1);
+}
+
+
diff --git a/arch/mips/mm/c-r4k.c b/arch/mips/mm/c-r4k.c
index d6414bf..3a1fa27 100644
--- a/arch/mips/mm/c-r4k.c
+++ b/arch/mips/mm/c-r4k.c
@@ -32,8 +32,7 @@
 #include <asm/mmu_context.h>
 #include <asm/war.h>
 #include <asm/cacheflush.h> /* for run_uncached() */
-#include <asm/traps.h>
-#include <asm/dma-coherence.h>
+
 
 /*
  * Special Variant of smp_call_function for use by cache functions:
@@ -137,8 +136,7 @@ static void __cpuinit r4k_blast_dcache_page_indexed_setup(void)
 		r4k_blast_dcache_page_indexed = blast_dcache64_page_indexed;
 }
 
-void (* r4k_blast_dcache)(void);
-EXPORT_SYMBOL(r4k_blast_dcache);
+static void (* r4k_blast_dcache)(void);
 
 static void __cpuinit r4k_blast_dcache_setup(void)
 {
@@ -162,7 +160,7 @@ static void __cpuinit r4k_blast_dcache_setup(void)
 		"1:\n\t" \
 		)
 #define CACHE32_UNROLL32_ALIGN	JUMP_TO_ALIGN(10) /* 32 * 32 = 1024 */
-#define CACHE32_UNROLL32_ALIGN2 JUMP_TO_ALIGN(11)
+#define CACHE32_UNROLL32_ALIGN2	JUMP_TO_ALIGN(11)
 
 static inline void blast_r4600_v1_icache32(void)
 {
@@ -179,7 +177,7 @@ static inline void tx49_blast_icache32(void)
 	unsigned long end = start + current_cpu_data.icache.waysize;
 	unsigned long ws_inc = 1UL << current_cpu_data.icache.waybit;
 	unsigned long ws_end = current_cpu_data.icache.ways <<
-			       current_cpu_data.icache.waybit;
+	                       current_cpu_data.icache.waybit;
 	unsigned long ws, addr;
 
 	CACHE32_UNROLL32_ALIGN2;
@@ -210,7 +208,7 @@ static inline void tx49_blast_icache32_page_indexed(unsigned long page)
 	unsigned long end = start + PAGE_SIZE;
 	unsigned long ws_inc = 1UL << current_cpu_data.icache.waybit;
 	unsigned long ws_end = current_cpu_data.icache.ways <<
-			       current_cpu_data.icache.waybit;
+	                       current_cpu_data.icache.waybit;
 	unsigned long ws, addr;
 
 	CACHE32_UNROLL32_ALIGN2;
@@ -266,8 +264,7 @@ static void __cpuinit r4k_blast_icache_page_indexed_setup(void)
 		r4k_blast_icache_page_indexed = blast_icache64_page_indexed;
 }
 
-void (* r4k_blast_icache)(void);
-EXPORT_SYMBOL(r4k_blast_icache);
+static void (* r4k_blast_icache)(void);
 
 static void __cpuinit r4k_blast_icache_setup(void)
 {
@@ -635,14 +632,20 @@ static void r4k_dma_cache_inv(unsigned long addr, unsigned long size)
 		if (size >= scache_size)
 			r4k_blast_scache();
 		else {
+			unsigned long lsize = cpu_scache_line_size();
+			unsigned long almask = ~(lsize - 1);
+
 			/*
 			 * There is no clearly documented alignment requirement
 			 * for the cache instruction on MIPS processors and
 			 * some processors, among them the RM5200 and RM7000
 			 * QED processors will throw an address error for cache
-			 * hit ops with insufficient alignment.	 Solved by
+			 * hit ops with insufficient alignment.  Solved by
 			 * aligning the address to cache line size.
 			 */
+			cache_op(Hit_Writeback_Inv_SD, addr & almask);
+			cache_op(Hit_Writeback_Inv_SD,
+				 (addr + size - 1) & almask);
 			blast_inv_scache_range(addr, addr + size);
 		}
 		__sync();
@@ -652,7 +655,12 @@ static void r4k_dma_cache_inv(unsigned long addr, unsigned long size)
 	if (cpu_has_safe_index_cacheops && size >= dcache_size) {
 		r4k_on_each_cpu((void *)r4k_blast_dcache, NULL);
 	} else {
+		unsigned long lsize = cpu_dcache_line_size();
+		unsigned long almask = ~(lsize - 1);
+
 		R4600_HIT_CACHEOP_WAR_IMPL;
+		cache_op(Hit_Writeback_Inv_D, addr & almask);
+		cache_op(Hit_Writeback_Inv_D, (addr + size - 1)  & almask);
 		blast_inv_dcache_range(addr, addr + size);
 	}
 
@@ -778,25 +786,6 @@ static inline void rm7k_erratum31(void)
 	}
 }
 
-static inline void alias_74k_erratum(struct cpuinfo_mips *c)
-{
-	/*
-	 * Early versions of the 74K do not update the cache tags on a
-	 * vtag miss/ptag hit which can occur in the case of KSEG0/KUSEG
-	 * aliases. In this case it is better to treat the cache as always
-	 * having aliases.
-	 */
-	if ((c->processor_id & 0xff) <= PRID_REV_ENCODE_332(2, 4, 0))
-		c->dcache.flags |= MIPS_CACHE_VTAG;
-	if ((c->processor_id & 0xff) == PRID_REV_ENCODE_332(2, 4, 0))
-		write_c0_config6(read_c0_config6() | MIPS_CONF6_SYND);
-	if (((c->processor_id & 0xff00) == PRID_IMP_1074K) &&
-	    ((c->processor_id & 0xff) <= PRID_REV_ENCODE_332(1, 1, 0))) {
-		c->dcache.flags |= MIPS_CACHE_VTAG;
-		write_c0_config6(read_c0_config6() | MIPS_CONF6_SYND);
-	}
-}
-
 static char *way_string[] __cpuinitdata = { NULL, "direct mapped", "2-way",
 	"3-way", "4-way", "5-way", "6-way", "7-way", "8-way"
 };
@@ -867,7 +856,7 @@ static void __cpuinit probe_pcache(void)
 		icache_size = 1 << (12 + ((config & CONF_IC) >> 9));
 		c->icache.linesz = 16 << ((config & CONF_IB) >> 5);
 		c->icache.ways = 1;
-		c->icache.waybit = 0;	/* doesn't matter */
+		c->icache.waybit = 0; 	/* doesn't matter */
 
 		dcache_size = 1 << (12 + ((config & CONF_DC) >> 6));
 		c->dcache.linesz = 16 << ((config & CONF_DB) >> 4);
@@ -926,7 +915,7 @@ static void __cpuinit probe_pcache(void)
 		icache_size = 1 << (10 + ((config & CONF_IC) >> 9));
 		c->icache.linesz = 16 << ((config & CONF_IB) >> 5);
 		c->icache.ways = 1;
-		c->icache.waybit = 0;	/* doesn't matter */
+		c->icache.waybit = 0; 	/* doesn't matter */
 
 		dcache_size = 1 << (10 + ((config & CONF_DC) >> 6));
 		c->dcache.linesz = 16 << ((config & CONF_DB) >> 4);
@@ -939,6 +928,7 @@ static void __cpuinit probe_pcache(void)
 	case CPU_RM7000:
 		rm7k_erratum31();
 
+	case CPU_RM9000:
 		icache_size = 1 << (12 + ((config & CONF_IC) >> 9));
 		c->icache.linesz = 16 << ((config & CONF_IB) >> 5);
 		c->icache.ways = 4;
@@ -949,7 +939,9 @@ static void __cpuinit probe_pcache(void)
 		c->dcache.ways = 4;
 		c->dcache.waybit = __ffs(dcache_size / c->dcache.ways);
 
+#if !defined(CONFIG_SMP) || !defined(RM9000_CDEX_SMP_WAR)
 		c->options |= MIPS_CPU_CACHE_CDEX_P;
+#endif
 		c->options |= MIPS_CPU_PREFETCH;
 		break;
 
@@ -985,12 +977,12 @@ static void __cpuinit probe_pcache(void)
 			c->icache.linesz = 2 << lsize;
 		else
 			c->icache.linesz = lsize;
-		c->icache.sets = 32 << (((config1 >> 22) + 1) & 7);
+		c->icache.sets = 64 << ((config1 >> 22) & 7);
 		c->icache.ways = 1 + ((config1 >> 16) & 7);
 
 		icache_size = c->icache.sets *
-			      c->icache.ways *
-			      c->icache.linesz;
+		              c->icache.ways *
+		              c->icache.linesz;
 		c->icache.waybit = __ffs(icache_size/c->icache.ways);
 
 		if (config & 0x8)		/* VI bit */
@@ -1005,12 +997,12 @@ static void __cpuinit probe_pcache(void)
 			c->dcache.linesz = 2 << lsize;
 		else
 			c->dcache.linesz= lsize;
-		c->dcache.sets = 32 << (((config1 >> 13) + 1) & 7);
+		c->dcache.sets = 64 << ((config1 >> 13) & 7);
 		c->dcache.ways = 1 + ((config1 >> 7) & 7);
 
 		dcache_size = c->dcache.sets *
-			      c->dcache.ways *
-			      c->dcache.linesz;
+		              c->dcache.ways *
+		              c->dcache.linesz;
 		c->dcache.waybit = __ffs(dcache_size/c->dcache.ways);
 
 		c->options |= MIPS_CPU_PREFETCH;
@@ -1019,7 +1011,7 @@ static void __cpuinit probe_pcache(void)
 
 	/*
 	 * Processor configuration sanity check for the R4000SC erratum
-	 * #5.	With page sizes larger than 32kB there is no possibility
+	 * #5.  With page sizes larger than 32kB there is no possibility
 	 * to get a VCE exception anymore so we don't care about this
 	 * misconfiguration.  The case is rather theoretical anyway;
 	 * presumably no vendor is shipping his hardware in the "bad"
@@ -1059,14 +1051,10 @@ static void __cpuinit probe_pcache(void)
 	case CPU_R14000:
 		break;
 
-	case CPU_M14KC:
-	case CPU_M14KEC:
 	case CPU_24K:
 	case CPU_34K:
 	case CPU_74K:
 	case CPU_1004K:
-		if (c->cputype == CPU_74K)
-			alias_74k_erratum(c);
 		if ((read_c0_config7() & (1 << 16))) {
 			/* effectively physically indexed dcache,
 			   thus no virtual aliases. */
@@ -1092,7 +1080,7 @@ static void __cpuinit probe_pcache(void)
 		break;
 	}
 
-#ifdef	CONFIG_CPU_LOONGSON2
+#ifdef  CONFIG_CPU_LOONGSON2
 	/*
 	 * LOONGSON2 has 4 way icache, but when using indexed cache op,
 	 * one op will act on all 4 ways
@@ -1232,9 +1220,10 @@ static void __cpuinit setup_scache(void)
 #ifdef CONFIG_R5000_CPU_SCACHE
 		r5k_sc_init();
 #endif
-		return;
+                return;
 
 	case CPU_RM7000:
+	case CPU_RM9000:
 #ifdef CONFIG_RM7000_CPU_SCACHE
 		rm7k_sc_init();
 #endif
@@ -1250,8 +1239,10 @@ static void __cpuinit setup_scache(void)
 		return;
 
 	default:
-		if (c->isa_level & (MIPS_CPU_ISA_M32R1 | MIPS_CPU_ISA_M32R2 |
-				    MIPS_CPU_ISA_M64R1 | MIPS_CPU_ISA_M64R2)) {
+		if (c->isa_level == MIPS_CPU_ISA_M32R1 ||
+		    c->isa_level == MIPS_CPU_ISA_M32R2 ||
+		    c->isa_level == MIPS_CPU_ISA_M64R1 ||
+		    c->isa_level == MIPS_CPU_ISA_M64R2) {
 #ifdef CONFIG_MIPS_CPU_SCACHE
 			if (mips_sc_init ()) {
 				scache_size = c->scache.ways * c->scache.sets * c->scache.linesz;
@@ -1335,10 +1326,10 @@ static int __init cca_setup(char *str)
 {
 	get_option(&str, &cca);
 
-	return 0;
+	return 1;
 }
 
-early_param("cca", cca_setup);
+__setup("cca=", cca_setup);
 
 static void __cpuinit coherency_setup(void)
 {
@@ -1380,8 +1371,24 @@ static void __cpuinit coherency_setup(void)
 	}
 }
 
-static void __cpuinit r4k_cache_error_setup(void)
+#if defined(CONFIG_DMA_NONCOHERENT)
+
+static int __cpuinitdata coherentio;
+
+static int __init setcoherentio(char *str)
+{
+	coherentio = 1;
+
+	return 1;
+}
+
+__setup("coherentio", setcoherentio);
+#endif
+
+void __cpuinit r4k_cache_init(void)
 {
+	extern void build_clear_page(void);
+	extern void build_copy_page(void);
 	extern char __weak except_vec2_generic;
 	extern char __weak except_vec2_sb1;
 	struct cpuinfo_mips *c = &current_cpu_data;
@@ -1396,13 +1403,6 @@ static void __cpuinit r4k_cache_error_setup(void)
 		set_uncached_handler(0x100, &except_vec2_generic, 0x80);
 		break;
 	}
-}
-
-void __cpuinit r4k_cache_init(void)
-{
-	extern void build_clear_page(void);
-	extern void build_copy_page(void);
-	struct cpuinfo_mips *c = &current_cpu_data;
 
 	probe_pcache();
 	setup_scache();
@@ -1461,14 +1461,8 @@ void __cpuinit r4k_cache_init(void)
 
 	build_clear_page();
 	build_copy_page();
-
-	/*
-	 * We want to run CMP kernels on core with and without coherent
-	 * caches. Therefore, do not use CONFIG_MIPS_CMP to decide whether
-	 * or not to flush caches.
-	 */
+#if !defined(CONFIG_MIPS_CMP)
 	local_r4k___flush_cache_all(NULL);
-
+#endif
 	coherency_setup();
-	board_cache_error_setup = r4k_cache_error_setup;
 }
diff --git a/arch/mips/mm/cache.c b/arch/mips/mm/cache.c
index 5aeb3eb..d1d564f 100644
--- a/arch/mips/mm/cache.c
+++ b/arch/mips/mm/cache.c
@@ -48,7 +48,6 @@ void (*flush_icache_all)(void);
 
 EXPORT_SYMBOL_GPL(local_flush_data_cache_page);
 EXPORT_SYMBOL(flush_data_cache_page);
-EXPORT_SYMBOL(flush_icache_all);
 
 #ifdef CONFIG_DMA_NONCOHERENT
 
@@ -123,6 +122,20 @@ void __update_cache(struct vm_area_struct *vma, unsigned long address,
 	pte_t pte)
 {
 	struct page *page;
+
+#ifdef CONFIG_RMI_PHOENIX
+	phys_t start;
+	//printk("[%s]: address = %lx, pte = %lx\n", __FUNCTION__, address, pte_val(pte));
+	if (!(vma->vm_flags & VM_EXEC)) return;
+	page = pte_page(pte);
+	/*  addr = (unsigned long)page_address(page); */
+	if (TestPageDcacheDirty(page)) return;
+	/*  if (addr)  */
+	/*    flush_icache_range(addr, addr+PAGE_SIZE); */
+	start = (phys_t)pte_pfn(pte);
+	phoenix_flush_icache_range_paddr(start << PAGE_SHIFT);
+	SetPageDcacheDirty(page);
+#else
 	unsigned long pfn, addr;
 	int exec = (vma->vm_flags & VM_EXEC) && !cpu_has_ic_fills_f_dc;
 
@@ -136,14 +149,22 @@ void __update_cache(struct vm_area_struct *vma, unsigned long address,
 			flush_data_cache_page(addr);
 		ClearPageDcacheDirty(page);
 	}
+#endif
 }
 
+#ifdef CONFIG_RMI_PHOENIX
+/* This variable needs to be initialized before setup_arch() if this is not
+   initialized like below
+   */
+unsigned long _page_cachable_default = (0x3 << _CACHE_SHIFT);
+#else
 unsigned long _page_cachable_default;
+#endif
 EXPORT_SYMBOL(_page_cachable_default);
 
 static inline void setup_protection_map(void)
 {
-	if (cpu_has_rixi) {
+	if (kernel_uses_smartmips_rixi) {
 		protection_map[0]  = __pgprot(_page_cachable_default | _PAGE_PRESENT | _PAGE_NO_EXEC | _PAGE_NO_READ);
 		protection_map[1]  = __pgprot(_page_cachable_default | _PAGE_PRESENT | _PAGE_NO_EXEC);
 		protection_map[2]  = __pgprot(_page_cachable_default | _PAGE_PRESENT | _PAGE_NO_EXEC | _PAGE_NO_READ);
@@ -209,6 +230,11 @@ void __cpuinit cpu_cache_init(void)
 
 		tx39_cache_init();
 	}
+	if (cpu_has_phoenix_cache) {
+		extern void __weak ld_mmu_phoenix(void);
+
+		ld_mmu_phoenix();
+	}
 
 	if (cpu_has_octeon_cache) {
 		extern void __weak octeon_cache_init(void);
@@ -224,5 +250,14 @@ int __weak __uncached_access(struct file *file, unsigned long addr)
 	if (file->f_flags & O_DSYNC)
 		return 1;
 
+#ifdef CONFIG_RMI_PHOENIX
+	{
+		extern int phnx_get_pgprot(unsigned long address);
+	  	/* check the address region, return uncached pages for IO space and
+		   cached page for memory space. */
+		return phnx_get_pgprot(addr);
+	}
+#endif
+
 	return addr >= __pa(high_memory);
 }
diff --git a/arch/mips/mm/cex-gen.S b/arch/mips/mm/cex-gen.S
index 45dff5c..31f4b94 100644
--- a/arch/mips/mm/cex-gen.S
+++ b/arch/mips/mm/cex-gen.S
@@ -1,3 +1,15 @@
+/************************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+ *
+ * This is a derived work from software originally provided by the external
+ * entity identified below. The licensing terms and warranties specified in
+ * the header of the original work apply to this derived work.
+ *
+ * Contribution by RMI: 
+ *
+ ******************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -14,17 +26,17 @@
 #include <asm/stackframe.h>
 
 /*
- * Game over.  Go to the button.  Press gently.	 Swear where allowed by
+ * Game over.  Go to the button.  Press gently.  Swear where allowed by
  * legislation.
  */
 	LEAF(except_vec2_generic)
 	.set	noreorder
 	.set	noat
-	.set	mips0
+	.set    mips0
 	/*
 	 * This is a very bad place to be.  Our cache error
 	 * detection has triggered.  If we have write-back data
-	 * in the cache, we may not be able to recover.	 As a
+	 * in the cache, we may not be able to recover.  As a
 	 * first-order desperate measure, turn off KSEG0 cacheing.
 	 */
 	mfc0	k0,CP0_CONFIG
@@ -36,7 +48,34 @@
 	nop
 	nop
 	nop
+#ifdef CONFIG_RMI_PHOENIX
+
+	/* If some other cpu is already in the handler
+	 * just wait... */
+	PTR_LA	k0, xlr_cerr_lock
+1:	lw	k1, 0(k0)
+	bnez	k1, 1b
+	nop
+	
+	/* switch stack to a new one */
+	PTR_LA	sp, xlr_cerr_stack
+	li	k1, 8192 - 64
+	PTR_ADDU	sp, sp, k1
+	
+	/* set up first argument - pt_regs */
+	move	a0, sp
+	/* read the cache error log reg in the cpu */
+	li	k1, 0x309
+	/*mfcr	k0, k1*/
+	PTR	0x737a0018
+	move	a1, k0
+	
+    j phoenix_cache_error
+	nop
+	/* should never get here */
 
+#else
 	j	cache_parity_error
 	nop
+#endif
 	END(except_vec2_generic)
diff --git a/arch/mips/mm/extable.c b/arch/mips/mm/extable.c
index 9d25d2b..fb29d08 100644
--- a/arch/mips/mm/extable.c
+++ b/arch/mips/mm/extable.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -7,6 +19,7 @@
  */
 #include <linux/module.h>
 #include <linux/spinlock.h>
+#include <linux/kgdb.h>
 #include <asm/branch.h>
 #include <asm/uaccess.h>
 
@@ -20,6 +33,14 @@ int fixup_exception(struct pt_regs *regs)
 
 		return 1;
 	}
+#if 0
+#ifdef CONFIG_KGDB
+	if (atomic_read(&debugger_active) && kgdb_may_fault)
+		/* Restore our previous state. */
+		kgdb_fault_longjmp(kgdb_fault_jmp_regs);
+		/* Not reached. */
+#endif
+#endif
 
 	return 0;
 }
diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 0fead53..88ffcdd 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -114,7 +114,7 @@ good_area:
 		if (!(vma->vm_flags & VM_WRITE))
 			goto bad_area;
 	} else {
-		if (cpu_has_rixi) {
+		if (kernel_uses_smartmips_rixi) {
 			if (address == regs->cp0_epc && !(vma->vm_flags & VM_EXEC)) {
 #if 0
 				pr_notice("Cpu%d[%s:%d:%0*lx:%ld:%0*lx] XI violation\n",
@@ -171,7 +171,6 @@ good_area:
 		}
 		if (fault & VM_FAULT_RETRY) {
 			flags &= ~FAULT_FLAG_ALLOW_RETRY;
-			flags |= FAULT_FLAG_TRIED;
 
 			/*
 			 * No need to up_read(&mm->mmap_sem) as we would
diff --git a/arch/mips/mm/init.c b/arch/mips/mm/init.c
index 9b973e0..1f21449 100644
--- a/arch/mips/mm/init.c
+++ b/arch/mips/mm/init.c
@@ -431,8 +431,11 @@ void free_init_pages(const char *what, unsigned long begin, unsigned long end)
 		struct page *page = pfn_to_page(pfn);
 		void *addr = phys_to_virt(PFN_PHYS(pfn));
 
+		ClearPageReserved(page);
+		init_page_count(page);
 		memset(addr, POISON_FREE_INITMEM, PAGE_SIZE);
-		free_reserved_page(page);
+		__free_page(page);
+		totalram_pages++;
 	}
 	printk(KERN_INFO "Freeing %s: %ldk freed\n", what, (end - begin) >> 10);
 }
@@ -447,7 +450,9 @@ void free_initrd_mem(unsigned long start, unsigned long end)
 void __init_refok free_initmem(void)
 {
 	prom_free_prom_memory();
-	free_initmem_default(POISON_FREE_INITMEM);
+	free_init_pages("unused kernel memory",
+			__pa_symbol(&__init_begin),
+			__pa_symbol(&__init_end));
 }
 
 #ifndef CONFIG_MIPS_PGD_C0_CONTEXT
diff --git a/arch/mips/mm/ioremap.c b/arch/mips/mm/ioremap.c
index 7f840bc..4f77d61 100644
--- a/arch/mips/mm/ioremap.c
+++ b/arch/mips/mm/ioremap.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -22,7 +34,7 @@ static inline void remap_area_pte(pte_t * pte, unsigned long address,
 	phys_t end;
 	unsigned long pfn;
 	pgprot_t pgprot = __pgprot(_PAGE_GLOBAL | _PAGE_PRESENT | __READABLE
-				   | __WRITEABLE | flags);
+	                           | __WRITEABLE | flags);
 
 	address &= ~PMD_MASK;
 	end = address + size;
@@ -111,7 +123,11 @@ static int remap_area_pages(unsigned long address, phys_t phys_addr,
  * caller shouldn't need to know that small detail.
  */
 
-#define IS_LOW512(addr) (!((phys_t)(addr) & (phys_t) ~0x1fffffffULL))
+#ifdef CONFIG_64BIT_PHYS_ADDR
+#define IS_LOW512(addr) (!((phys_t)(addr) & ~0x1fffffffULL))
+#else
+#define IS_LOW512(addr) (!((phys_t)(addr) & ~0x1fffffffUL))
+#endif
 
 void __iomem * __ioremap(phys_t phys_addr, phys_t size, unsigned long flags)
 {
@@ -185,7 +201,7 @@ void __iounmap(const volatile void __iomem *addr)
 	if (!p)
 		printk(KERN_ERR "iounmap: bad address %p\n", addr);
 
-	kfree(p);
+        kfree(p);
 }
 
 EXPORT_SYMBOL(__ioremap);
diff --git a/arch/mips/mm/mmap.c b/arch/mips/mm/mmap.c
index 7e5fe27..302d779 100644
--- a/arch/mips/mm/mmap.c
+++ b/arch/mips/mm/mmap.c
@@ -45,6 +45,18 @@ static unsigned long mmap_base(unsigned long rnd)
 	return PAGE_ALIGN(TASK_SIZE - gap - rnd);
 }
 
+static inline unsigned long COLOUR_ALIGN_DOWN(unsigned long addr,
+					      unsigned long pgoff)
+{
+	unsigned long base = addr & ~shm_align_mask;
+	unsigned long off = (pgoff << PAGE_SHIFT) & shm_align_mask;
+
+	if (base + off <= addr)
+		return base + off;
+
+	return base - off;
+}
+
 #define COLOUR_ALIGN(addr, pgoff)				\
 	((((addr) + shm_align_mask) & ~shm_align_mask) +	\
 	 (((pgoff) << PAGE_SHIFT) & shm_align_mask))
@@ -59,7 +71,6 @@ static unsigned long arch_get_unmapped_area_common(struct file *filp,
 	struct vm_area_struct *vma;
 	unsigned long addr = addr0;
 	int do_color_align;
-	struct vm_unmapped_area_info info;
 
 	if (unlikely(len > TASK_SIZE))
 		return -ENOMEM;
@@ -96,31 +107,97 @@ static unsigned long arch_get_unmapped_area_common(struct file *filp,
 			return addr;
 	}
 
-	info.length = len;
-	info.align_mask = do_color_align ? (PAGE_MASK & shm_align_mask) : 0;
-	info.align_offset = pgoff << PAGE_SHIFT;
-
-	if (dir == DOWN) {
-		info.flags = VM_UNMAPPED_AREA_TOPDOWN;
-		info.low_limit = PAGE_SIZE;
-		info.high_limit = mm->mmap_base;
-		addr = vm_unmapped_area(&info);
+	if (dir == UP) {
+		addr = mm->mmap_base;
+		if (do_color_align)
+			addr = COLOUR_ALIGN(addr, pgoff);
+		else
+			addr = PAGE_ALIGN(addr);
 
-		if (!(addr & ~PAGE_MASK))
-			return addr;
+		for (vma = find_vma(current->mm, addr); ; vma = vma->vm_next) {
+			/* At this point:  (!vma || addr < vma->vm_end). */
+			if (TASK_SIZE - len < addr)
+				return -ENOMEM;
+			if (!vma || addr + len <= vma->vm_start)
+				return addr;
+			addr = vma->vm_end;
+			if (do_color_align)
+				addr = COLOUR_ALIGN(addr, pgoff);
+		 }
+	 } else {
+		/* check if free_area_cache is useful for us */
+		if (len <= mm->cached_hole_size) {
+			mm->cached_hole_size = 0;
+			mm->free_area_cache = mm->mmap_base;
+		}
 
 		/*
+		 * either no address requested, or the mapping can't fit into
+		 * the requested address hole
+		 */
+		addr = mm->free_area_cache;
+		if (do_color_align) {
+			unsigned long base =
+				COLOUR_ALIGN_DOWN(addr - len, pgoff);
+			addr = base + len;
+		}
+
+		/* make sure it can fit in the remaining address space */
+		if (likely(addr > len)) {
+			vma = find_vma(mm, addr - len);
+			if (!vma || addr <= vma->vm_start) {
+				/* cache the address as a hint for next time */
+				return mm->free_area_cache = addr - len;
+			}
+		}
+
+		if (unlikely(mm->mmap_base < len))
+			goto bottomup;
+
+		addr = mm->mmap_base - len;
+		if (do_color_align)
+			addr = COLOUR_ALIGN_DOWN(addr, pgoff);
+
+		do {
+			/*
+			 * Lookup failure means no vma is above this address,
+			 * else if new region fits below vma->vm_start,
+			 * return with success:
+			 */
+			vma = find_vma(mm, addr);
+			if (likely(!vma || addr + len <= vma->vm_start)) {
+				/* cache the address as a hint for next time */
+				return mm->free_area_cache = addr;
+			}
+
+			/* remember the largest hole we saw so far */
+			if (addr + mm->cached_hole_size < vma->vm_start)
+				mm->cached_hole_size = vma->vm_start - addr;
+
+			/* try just below the current vma->vm_start */
+			addr = vma->vm_start - len;
+			if (do_color_align)
+				addr = COLOUR_ALIGN_DOWN(addr, pgoff);
+		} while (likely(len < vma->vm_start));
+
+bottomup:
+		/*
 		 * A failed mmap() very likely causes application failure,
 		 * so fall back to the bottom-up function here. This scenario
 		 * can happen with large stack limits and large mmap()
 		 * allocations.
 		 */
-	}
+		mm->cached_hole_size = ~0UL;
+		mm->free_area_cache = TASK_UNMAPPED_BASE;
+		addr = arch_get_unmapped_area(filp, addr0, len, pgoff, flags);
+		/*
+		 * Restore the topdown base:
+		 */
+		mm->free_area_cache = mm->mmap_base;
+		mm->cached_hole_size = ~0UL;
 
-	info.flags = 0;
-	info.low_limit = mm->mmap_base;
-	info.high_limit = TASK_SIZE;
-	return vm_unmapped_area(&info);
+		return addr;
+	}
 }
 
 unsigned long arch_get_unmapped_area(struct file *filp, unsigned long addr0,
@@ -192,9 +269,3 @@ unsigned long arch_randomize_brk(struct mm_struct *mm)
 
 	return ret;
 }
-
-int __virt_addr_valid(const volatile void *kaddr)
-{
-	return pfn_valid(PFN_DOWN(virt_to_phys(kaddr)));
-}
-EXPORT_SYMBOL_GPL(__virt_addr_valid);
diff --git a/arch/mips/mm/pgtable-64.c b/arch/mips/mm/pgtable-64.c
index e8adc00..7d2363c 100644
--- a/arch/mips/mm/pgtable-64.c
+++ b/arch/mips/mm/pgtable-64.c
@@ -11,7 +11,6 @@
 #include <asm/fixmap.h>
 #include <asm/pgtable.h>
 #include <asm/pgalloc.h>
-#include <asm/tlbflush.h>
 
 void pgd_init(unsigned long page)
 {
@@ -24,20 +23,20 @@ void pgd_init(unsigned long page)
 	entry = (unsigned long)invalid_pmd_table;
 #endif
 
-	p = (unsigned long *) page;
+ 	p = (unsigned long *) page;
 	end = p + PTRS_PER_PGD;
 
-	do {
+	while (p < end) {
 		p[0] = entry;
 		p[1] = entry;
 		p[2] = entry;
 		p[3] = entry;
 		p[4] = entry;
+		p[5] = entry;
+		p[6] = entry;
+		p[7] = entry;
 		p += 8;
-		p[-3] = entry;
-		p[-2] = entry;
-		p[-1] = entry;
-	} while (p != end);
+	}
 }
 
 #ifndef __PAGETABLE_PMD_FOLDED
@@ -45,57 +44,33 @@ void pmd_init(unsigned long addr, unsigned long pagetable)
 {
 	unsigned long *p, *end;
 
-	p = (unsigned long *) addr;
+ 	p = (unsigned long *) addr;
 	end = p + PTRS_PER_PMD;
 
-	do {
+	while (p < end) {
 		p[0] = pagetable;
 		p[1] = pagetable;
 		p[2] = pagetable;
 		p[3] = pagetable;
 		p[4] = pagetable;
+		p[5] = pagetable;
+		p[6] = pagetable;
+		p[7] = pagetable;
 		p += 8;
-		p[-3] = pagetable;
-		p[-2] = pagetable;
-		p[-1] = pagetable;
-	} while (p != end);
-}
-#endif
-
-#ifdef CONFIG_TRANSPARENT_HUGEPAGE
-
-void pmdp_splitting_flush(struct vm_area_struct *vma,
-			 unsigned long address,
-			 pmd_t *pmdp)
-{
-	if (!pmd_trans_splitting(*pmdp)) {
-		pmd_t pmd = pmd_mksplitting(*pmdp);
-		set_pmd_at(vma->vm_mm, address, pmdp, pmd);
 	}
 }
-
 #endif
 
-pmd_t mk_pmd(struct page *page, pgprot_t prot)
-{
-	pmd_t pmd;
-
-	pmd_val(pmd) = (page_to_pfn(page) << _PFN_SHIFT) | pgprot_val(prot);
-
-	return pmd;
-}
-
-void set_pmd_at(struct mm_struct *mm, unsigned long addr,
-		pmd_t *pmdp, pmd_t pmd)
-{
-	*pmdp = pmd;
-	flush_tlb_all();
-}
-
 void __init pagetable_init(void)
 {
 	unsigned long vaddr;
 	pgd_t *pgd_base;
+#ifdef CONFIG_HIGHMEM
+        pgd_t *pgd;
+        pud_t *pud;
+        pmd_t *pmd;
+        pte_t *pte;
+#endif
 
 	/* Initialize the entire pgd.  */
 	pgd_init((unsigned long)swapper_pg_dir);
@@ -108,4 +83,18 @@ void __init pagetable_init(void)
 	 */
 	vaddr = __fix_to_virt(__end_of_fixed_addresses - 1) & PMD_MASK;
 	fixrange_init(vaddr, vaddr + FIXADDR_SIZE, pgd_base);
+
+#ifdef CONFIG_HIGHMEM
+        /*
+         * Permanent kmaps:
+         */
+        vaddr = PKMAP_BASE;
+        fixrange_init(vaddr, vaddr + PAGE_SIZE*LAST_PKMAP, pgd_base);
+
+        pgd = swapper_pg_dir + __pgd_offset(vaddr);
+        pud = pud_offset(pgd, vaddr);
+        pmd = pmd_offset(pud, vaddr);
+        pte = pte_offset_kernel(pmd, vaddr);
+        pkmap_page_table = pte;
+#endif
 }
diff --git a/arch/mips/mm/tlb-r4k.c b/arch/mips/mm/tlb-r4k.c
index c643de4..d57481d 100644
--- a/arch/mips/mm/tlb-r4k.c
+++ b/arch/mips/mm/tlb-r4k.c
@@ -1,9 +1,21 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
  * for more details.
  *
- * Copyright (C) 1996 David S. Miller (davem@davemloft.net)
+ * Copyright (C) 1996 David S. Miller (dm@engr.sgi.com)
  * Copyright (C) 1997, 1998, 1999, 2000 Ralf Baechle ralf@gnu.org
  * Carsten Langgaard, carstenl@mips.com
  * Copyright (C) 2002 MIPS Technologies, Inc.  All rights reserved.
@@ -13,13 +25,17 @@
 #include <linux/smp.h>
 #include <linux/mm.h>
 #include <linux/hugetlb.h>
-#include <linux/module.h>
 
 #include <asm/cpu.h>
 #include <asm/bootinfo.h>
 #include <asm/mmu_context.h>
 #include <asm/pgtable.h>
-#include <asm/tlbmisc.h>
+
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/mips-exts.h>
+#include <asm/mach-rmi/mmu.h>
+#endif
+
 
 extern void build_tlb_refill_handler(void);
 
@@ -67,13 +83,34 @@ extern void build_tlb_refill_handler(void);
 
 #endif
 
+#ifdef CONFIG_RMI_VMIPS
+#define UNIQUE_VMIPS_ENTRYHI(idx)  ((1ULL << 63) + (1ULL << 40) + ((idx) << (PAGE_SHIFT + 1)) + ( 1 << 8))
+extern int rmi_vmips_max_wired_entries;
+#endif
+
+#ifdef CONFIG_RMI_XLP
+
+#define disable_pgwalker(flags) \
+({ flags = read_c0_config7(); \
+   write_c0_config7(read_c0_config7() & ~ENABLE_PGWALKER); })
+#define enable_pgwalker(flags) \
+({ write_c0_config7(read_c0_config7() | (flags & ENABLE_PGWALKER)); })
+
+#else
+
+#define disable_pgwalker(flags) {}
+#define enable_pgwalker(flags) {}
+
+#endif
+
 void local_flush_tlb_all(void)
 {
-	unsigned long flags;
+	unsigned long flags, config7_flags __maybe_unused;
 	unsigned long old_ctx;
 	int entry;
 
 	ENTER_CRITICAL(flags);
+	disable_pgwalker(config7_flags);
 	/* Save old context and create impossible VPN2 value */
 	old_ctx = read_c0_entryhi();
 	write_c0_entrylo0(0);
@@ -81,10 +118,18 @@ void local_flush_tlb_all(void)
 
 	entry = read_c0_wired();
 
+#if defined(CONFIG_MAPPED_KERNEL)
+	if (!entry) printk("[%s] flushing entry=%d in MAPPED_KERNEL mode!\n",
+			   __FUNCTION__, entry);
+#endif
 	/* Blast 'em all away. */
 	while (entry < current_cpu_data.tlbsize) {
 		/* Make sure all entries differ. */
+#ifndef CONFIG_RMI_VMIPS
 		write_c0_entryhi(UNIQUE_ENTRYHI(entry));
+#else
+        __write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(entry)));
+#endif
 		write_c0_index(entry);
 		mtc0_tlbw_hazard();
 		tlb_write_indexed();
@@ -93,24 +138,26 @@ void local_flush_tlb_all(void)
 	tlbw_use_hazard();
 	write_c0_entryhi(old_ctx);
 	FLUSH_ITLB;
+	enable_pgwalker(config7_flags);
 	EXIT_CRITICAL(flags);
 }
-EXPORT_SYMBOL(local_flush_tlb_all);
 
 /* All entries common to a mm share an asid.  To effectively flush
    these entries, we just bump the asid. */
 void local_flush_tlb_mm(struct mm_struct *mm)
 {
 	int cpu;
+	unsigned long config7_flags __maybe_unused;
 
 	preempt_disable();
 
 	cpu = smp_processor_id();
 
+	disable_pgwalker(config7_flags);
 	if (cpu_context(cpu, mm) != 0) {
 		drop_mmu_context(mm, cpu);
 	}
-
+	enable_pgwalker(config7_flags);
 	preempt_enable();
 }
 
@@ -122,15 +169,19 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 
 	if (cpu_context(cpu, mm) != 0) {
 		unsigned long size, flags;
+		unsigned long config7_flags __maybe_unused;
 
 		ENTER_CRITICAL(flags);
-		start = round_down(start, PAGE_SIZE << 1);
-		end = round_up(end, PAGE_SIZE << 1);
-		size = (end - start) >> (PAGE_SHIFT + 1);
+		disable_pgwalker(config7_flags);
+		size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
+		size = (size + 1) >> 1;
 		if (size <= current_cpu_data.tlbsize/2) {
 			int oldpid = read_c0_entryhi();
 			int newpid = cpu_asid(cpu, mm);
 
+			start &= (PAGE_MASK << 1);
+			end += ((PAGE_SIZE << 1) - 1);
+			end &= (PAGE_MASK << 1);
 			while (start < end) {
 				int idx;
 
@@ -145,7 +196,11 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 				if (idx < 0)
 					continue;
 				/* Make sure all entries differ. */
+#ifndef CONFIG_RMI_VMIPS
 				write_c0_entryhi(UNIQUE_ENTRYHI(idx));
+#else
+				__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
+#endif
 				mtc0_tlbw_hazard();
 				tlb_write_indexed();
 			}
@@ -155,6 +210,7 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 			drop_mmu_context(mm, cpu);
 		}
 		FLUSH_ITLB;
+		enable_pgwalker(config7_flags);
 		EXIT_CRITICAL(flags);
 	}
 }
@@ -162,8 +218,10 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
 {
 	unsigned long size, flags;
+	unsigned long config7_flags __maybe_unused;
 
 	ENTER_CRITICAL(flags);
+	disable_pgwalker(config7_flags);
 	size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
 	size = (size + 1) >> 1;
 	if (size <= current_cpu_data.tlbsize / 2) {
@@ -187,7 +245,11 @@ void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
 			if (idx < 0)
 				continue;
 			/* Make sure all entries differ. */
+#ifndef CONFIG_RMI_VMIPS
 			write_c0_entryhi(UNIQUE_ENTRYHI(idx));
+#else
+			__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
+#endif
 			mtc0_tlbw_hazard();
 			tlb_write_indexed();
 		}
@@ -197,6 +259,7 @@ void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
 		local_flush_tlb_all();
 	}
 	FLUSH_ITLB;
+	enable_pgwalker(config7_flags);
 	EXIT_CRITICAL(flags);
 }
 
@@ -205,12 +268,13 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
 	int cpu = smp_processor_id();
 
 	if (cpu_context(cpu, vma->vm_mm) != 0) {
-		unsigned long flags;
+		unsigned long flags, config7_flags __maybe_unused;
 		int oldpid, newpid, idx;
 
 		newpid = cpu_asid(cpu, vma->vm_mm);
 		page &= (PAGE_MASK << 1);
 		ENTER_CRITICAL(flags);
+		disable_pgwalker(config7_flags);
 		oldpid = read_c0_entryhi();
 		write_c0_entryhi(page | newpid);
 		mtc0_tlbw_hazard();
@@ -222,7 +286,11 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
 		if (idx < 0)
 			goto finish;
 		/* Make sure all entries differ. */
+#ifndef CONFIG_RMI_VMIPS
 		write_c0_entryhi(UNIQUE_ENTRYHI(idx));
+#else
+		__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
+#endif
 		mtc0_tlbw_hazard();
 		tlb_write_indexed();
 		tlbw_use_hazard();
@@ -230,6 +298,7 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
 	finish:
 		write_c0_entryhi(oldpid);
 		FLUSH_ITLB_VM(vma);
+		enable_pgwalker(config7_flags);
 		EXIT_CRITICAL(flags);
 	}
 }
@@ -240,10 +309,11 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
  */
 void local_flush_tlb_one(unsigned long page)
 {
-	unsigned long flags;
+	unsigned long flags, config7_flags __maybe_unused;
 	int oldpid, idx;
 
 	ENTER_CRITICAL(flags);
+	disable_pgwalker(config7_flags);
 	oldpid = read_c0_entryhi();
 	page &= (PAGE_MASK << 1);
 	write_c0_entryhi(page);
@@ -255,13 +325,18 @@ void local_flush_tlb_one(unsigned long page)
 	write_c0_entrylo1(0);
 	if (idx >= 0) {
 		/* Make sure all entries differ. */
+#ifndef CONFIG_RMI_VMIPS
 		write_c0_entryhi(UNIQUE_ENTRYHI(idx));
+#else
+		__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
+#endif
 		mtc0_tlbw_hazard();
 		tlb_write_indexed();
 		tlbw_use_hazard();
 	}
 	write_c0_entryhi(oldpid);
 	FLUSH_ITLB;
+	enable_pgwalker(config7_flags);
 	EXIT_CRITICAL(flags);
 }
 
@@ -297,7 +372,7 @@ void __update_tlb(struct vm_area_struct * vma, unsigned long address, pte_t pte)
 	pudp = pud_offset(pgdp, address);
 	pmdp = pmd_offset(pudp, address);
 	idx = read_c0_index();
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
+#ifdef CONFIG_HUGETLB_PAGE
 	/* this could be a huge page  */
 	if (pmd_huge(*pmdp)) {
 		unsigned long lo;
@@ -312,7 +387,6 @@ void __update_tlb(struct vm_area_struct * vma, unsigned long address, pte_t pte)
 			tlb_write_random();
 		else
 			tlb_write_indexed();
-		tlbw_use_hazard();
 		write_c0_pagemask(PM_DEFAULT_MASK);
 	} else
 #endif
@@ -338,8 +412,8 @@ void __update_tlb(struct vm_area_struct * vma, unsigned long address, pte_t pte)
 	EXIT_CRITICAL(flags);
 }
 
-void add_wired_entry(unsigned long entrylo0, unsigned long entrylo1,
-		     unsigned long entryhi, unsigned long pagemask)
+void __init add_wired_entry(unsigned long entrylo0, unsigned long entrylo1,
+	unsigned long entryhi, unsigned long pagemask)
 {
 	unsigned long flags;
 	unsigned long wired;
@@ -369,25 +443,78 @@ void add_wired_entry(unsigned long entrylo0, unsigned long entrylo1,
 	EXIT_CRITICAL(flags);
 }
 
-#ifdef CONFIG_TRANSPARENT_HUGEPAGE
+/*
+ * Used for loading TLB entries before trap_init() has started, when we
+ * don't actually want to add a wired entry which remains throughout the
+ * lifetime of the system
+ */
+
+static int temp_tlb_entry __cpuinitdata;
 
-int __init has_transparent_hugepage(void)
+__init int add_temporary_entry(unsigned long entrylo0, unsigned long entrylo1,
+			       unsigned long entryhi, unsigned long pagemask)
 {
-	unsigned int mask;
+	int ret = 0;
 	unsigned long flags;
+	unsigned long wired;
+	unsigned long old_pagemask;
+	unsigned long old_ctx;
 
 	ENTER_CRITICAL(flags);
-	write_c0_pagemask(PM_HUGE_MASK);
-	back_to_back_c0_hazard();
-	mask = read_c0_pagemask();
-	write_c0_pagemask(PM_DEFAULT_MASK);
+	/* Save old context and create impossible VPN2 value */
+	old_ctx = read_c0_entryhi();
+	old_pagemask = read_c0_pagemask();
+	wired = read_c0_wired();
+	if (--temp_tlb_entry < wired) {
+		printk(KERN_WARNING
+		       "No TLB space left for add_temporary_entry\n");
+		ret = -ENOSPC;
+		goto out;
+	}
 
-	EXIT_CRITICAL(flags);
+	write_c0_index(temp_tlb_entry);
+	write_c0_pagemask(pagemask);
+	write_c0_entryhi(entryhi);
+	write_c0_entrylo0(entrylo0);
+	write_c0_entrylo1(entrylo1);
+	mtc0_tlbw_hazard();
+	tlb_write_indexed();
+	tlbw_use_hazard();
 
-	return mask == PM_HUGE_MASK;
+	write_c0_entryhi(old_ctx);
+	write_c0_pagemask(old_pagemask);
+out:
+	EXIT_CRITICAL(flags);
+	return ret;
 }
 
-#endif /* CONFIG_TRANSPARENT_HUGEPAGE  */
+static void __cpuinit probe_tlb(unsigned long config)
+{
+	struct cpuinfo_mips *c = &current_cpu_data;
+	unsigned int reg;
+
+	/*
+	 * If this isn't a MIPS32 / MIPS64 compliant CPU.  Config 1 register
+	 * is not supported, we assume R4k style.  Cpu probing already figured
+	 * out the number of tlb entries.
+	 */
+	if ((c->processor_id & 0xff0000) == PRID_COMP_LEGACY)
+		return;
+#ifdef CONFIG_MIPS_MT_SMTC
+	/*
+	 * If TLB is shared in SMTC system, total size already
+	 * has been calculated and written into cpu_data tlbsize
+	 */
+	if((smtc_status & SMTC_TLB_SHARED) == SMTC_TLB_SHARED)
+		return;
+#endif /* CONFIG_MIPS_MT_SMTC */
+
+	reg = read_c0_config1();
+	if (!((config >> 7) & 3))
+		panic("No TLB present");
+
+	c->tlbsize = ((reg >> 25) & 0x3f) + 1;
+}
 
 static int __cpuinitdata ntlb;
 static int __init set_ntlb(char *str)
@@ -398,6 +525,25 @@ static int __init set_ntlb(char *str)
 
 __setup("ntlb=", set_ntlb);
 
+#ifdef CONFIG_RMI_PHOENIX
+extern void phoenix_tlb_init(void);
+
+void rmi_tlb_stats_init(void)
+{
+	rmi_write_os_scratch_2(0ULL);
+}
+
+#ifdef CONFIG_HUGETLBFS
+void rmi_tlb_entrylo0_mask_init(void);
+void rmi_tlb_entrylo0_mask_init()
+{
+	unsigned long long mask = ~(((1ULL<<HUGETLB_PAGE_ORDER)-1)<<6);
+	rmi_write_os_scratch_3(mask);
+}
+#endif
+
+#endif
+
 void __cpuinit tlb_init(void)
 {
 	/*
@@ -408,13 +554,23 @@ void __cpuinit tlb_init(void)
 	 *     be set to fixed-size pages.
 	 */
 	write_c0_pagemask(PM_DEFAULT_MASK);
-	write_c0_wired(0);
+
+#if defined(CONFIG_RMI_VMIPS)
+	if(ntlb && ((current_cpu_data.tlbsize-ntlb) < rmi_vmips_max_wired_entries))
+		ntlb = current_cpu_data.tlbsize - rmi_vmips_max_wired_entries;
+#endif
+
 	if (current_cpu_type() == CPU_R10000 ||
 	    current_cpu_type() == CPU_R12000 ||
 	    current_cpu_type() == CPU_R14000)
 		write_c0_framemask(0);
 
-	if (cpu_has_rixi) {
+#if !defined(CONFIG_MAPPED_KERNEL)
+	write_c0_wired(0);
+	write_c0_framemask(0);
+#endif
+
+	if (kernel_uses_smartmips_rixi) {
 		/*
 		 * Enable the no read, no exec bits, and enable large virtual
 		 * address.
@@ -426,7 +582,10 @@ void __cpuinit tlb_init(void)
 		write_c0_pagegrain(pg);
 	}
 
-	/* From this point on the ARC firmware is dead.	 */
+>>>>>>> 6a1653f... Resolve merge conflict: merge, cosmetic cleanup
+	temp_tlb_entry = current_cpu_data.tlbsize - 1;
+
+        /* From this point on the ARC firmware is dead.  */
 	local_flush_tlb_all();
 
 	/* Did I tell you that ARC SUCKS?  */
@@ -441,5 +600,17 @@ void __cpuinit tlb_init(void)
 			printk("Ignoring invalid argument ntlb=%d\n", ntlb);
 	}
 
+#ifdef CONFIG_RMI_PHOENIX
+
+	rmi_tlb_stats_init();
+
+#ifdef CONFIG_HUGETLBFS
+
+	rmi_tlb_entrylo0_mask_init();
+
+#endif
+
+#endif
+
 	build_tlb_refill_handler();
 }
diff --git a/arch/mips/mm/tlbex-fault.S b/arch/mips/mm/tlbex-fault.S
index 318855e..54c0f93 100644
--- a/arch/mips/mm/tlbex-fault.S
+++ b/arch/mips/mm/tlbex-fault.S
@@ -7,6 +7,7 @@
  * Copyright (C) 1999 Silicon Graphics, Inc.
  */
 #include <asm/mipsregs.h>
+#include <asm/page.h>
 #include <asm/regdef.h>
 #include <asm/stackframe.h>
 
@@ -25,3 +26,6 @@
 
 	tlb_do_page_fault 0
 	tlb_do_page_fault 1
+#if defined(CONFIG_READ_INHIBIT) || defined(CONFIG_EXEC_INHIBIT)
+	tlb_do_page_fault 2
+#endif
diff --git a/arch/mips/mm/tlbex.c b/arch/mips/mm/tlbex.c
index 0f25e00..59b62c0 100644
--- a/arch/mips/mm/tlbex.c
+++ b/arch/mips/mm/tlbex.c
@@ -569,6 +569,7 @@ static void __cpuinit build_tlb_write_entry(u32 **p, struct uasm_label **l,
 	case CPU_TX49XX:
 	case CPU_PR4450:
 	case CPU_XLR:
+	case CPU_XLP:
 		uasm_i_nop(p);
 		tlbw(p);
 		break;
diff --git a/arch/mips/oprofile/Makefile b/arch/mips/oprofile/Makefile
index 9c0a678..f52513b 100644
--- a/arch/mips/oprofile/Makefile
+++ b/arch/mips/oprofile/Makefile
@@ -1,3 +1,5 @@
+ccflags-y := -Werror
+
 obj-$(CONFIG_OPROFILE) += oprofile.o
 
 DRIVER_OBJS = $(addprefix ../../../drivers/oprofile/, \
@@ -12,5 +14,6 @@ oprofile-$(CONFIG_CPU_MIPS32)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_MIPS64)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_R10000)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_SB1)		+= op_model_mipsxx.o
-oprofile-$(CONFIG_CPU_XLR)		+= op_model_mipsxx.o
+oprofile-$(CONFIG_CPU_RM9000)		+= op_model_rm9000.o
+oprofile-$(CONFIG_RMI_PHOENIX)		+= op_model_mips_xlr.o
 oprofile-$(CONFIG_CPU_LOONGSON2)	+= op_model_loongson2.o
diff --git a/arch/mips/oprofile/common.c b/arch/mips/oprofile/common.c
index af763e8..8c73389 100644
--- a/arch/mips/oprofile/common.c
+++ b/arch/mips/oprofile/common.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -16,8 +28,9 @@
 #include "op_impl.h"
 
 extern struct op_mips_model op_model_mipsxx_ops __weak;
+extern struct op_mips_model op_model_rm9000_ops __weak;
 extern struct op_mips_model op_model_loongson2_ops __weak;
-
+extern struct op_mips_model op_model_phoenix __attribute__((weak));
 static struct op_mips_model *model;
 
 static struct op_counter_config ctr[20];
@@ -27,10 +40,10 @@ static int op_mips_setup(void)
 	/* Pre-compute the values to stuff in the hardware registers.  */
 	model->reg_setup(ctr);
 
-	/* Configure the registers on all cpus.	 */
+	/* Configure the registers on all cpus.  */
 	on_each_cpu(model->cpu_setup, NULL, 1);
 
-	return 0;
+        return 0;
 }
 
 static int op_mips_create_files(struct super_block *sb, struct dentry *root)
@@ -76,25 +89,28 @@ int __init oprofile_arch_init(struct oprofile_operations *ops)
 	int res;
 
 	switch (current_cpu_type()) {
+	case CPU_XLR:
+	case CPU_XLP:
+		lmodel = &op_model_phoenix;
+		break;
 	case CPU_5KC:
-	case CPU_M14KC:
-	case CPU_M14KEC:
 	case CPU_20KC:
 	case CPU_24K:
 	case CPU_25KF:
 	case CPU_34K:
 	case CPU_1004K:
 	case CPU_74K:
-	case CPU_LOONGSON1:
 	case CPU_SB1:
 	case CPU_SB1A:
 	case CPU_R10000:
 	case CPU_R12000:
 	case CPU_R14000:
-	case CPU_XLR:
 		lmodel = &op_model_mipsxx_ops;
 		break;
 
+	case CPU_RM9000:
+		lmodel = &op_model_rm9000_ops;
+		break;
 	case CPU_LOONGSON2:
 		lmodel = &op_model_loongson2_ops;
 		break;
@@ -111,7 +127,7 @@ int __init oprofile_arch_init(struct oprofile_operations *ops)
 
 	ops->create_files	= op_mips_create_files;
 	ops->setup		= op_mips_setup;
-	//ops->shutdown		= op_mips_shutdown;
+	//ops->shutdown         = op_mips_shutdown;
 	ops->start		= op_mips_start;
 	ops->stop		= op_mips_stop;
 	ops->cpu_type		= lmodel->cpu_type;
diff --git a/crypto/Makefile b/crypto/Makefile
index b72f568..768401b 100644
--- a/crypto/Makefile
+++ b/crypto/Makefile
@@ -90,6 +90,7 @@ obj-$(CONFIG_CRYPTO_RNG2) += rng.o
 obj-$(CONFIG_CRYPTO_RNG2) += krng.o
 obj-$(CONFIG_CRYPTO_ANSI_CPRNG) += ansi_cprng.o
 obj-$(CONFIG_CRYPTO_TEST) += tcrypt.o
+obj-$(CONFIG_PHOENIX_IPSEC_SEC_OFFLOAD) += phoenix_sec.o
 obj-$(CONFIG_CRYPTO_GHASH) += ghash-generic.o
 obj-$(CONFIG_CRYPTO_USER_API) += af_alg.o
 obj-$(CONFIG_CRYPTO_USER_API_HASH) += algif_hash.o
diff --git a/drivers/char/Kconfig b/drivers/char/Kconfig
index 3bb6fa3..048855d 100644
--- a/drivers/char/Kconfig
+++ b/drivers/char/Kconfig
@@ -248,6 +248,18 @@ config NWFLASH
 
 source "drivers/char/hw_random/Kconfig"
 
+config PHOENIX_RMIOS_DEBUGGER
+	bool "RMIOS Debugger support"
+	depends on RMI_PHOENIX!=n
+	default n
+	---help---
+	This module provides debugging facility for rmios images loaded on the
+	board, before loading linux image. Network interface is used to
+	communicate with remote gdb host. GDB clients communicate using the
+	network connection. Multiple rmios sessions can be run on different
+	virtual cpus. These gdb capable rmios sessions can be debugged
+	remotely by connecting to these session remotely through gdb.
+
 config NVRAM
 	tristate "/dev/nvram support"
 	depends on ATARI || X86 || (ARM && RTC_DRV_CMOS) || GENERIC_NVRAM
@@ -607,3 +619,10 @@ config TILE_SROM
 
 endmenu
 
+config RMICDE
+	tristate "RMI Compression/Decompression Engine"
+	depends on RMI_PHOENIX!=n
+	default n
+	help
+	  The CDE allows deflate/inflate through hardware
+
diff --git a/drivers/i2c/busses/Kconfig b/drivers/i2c/busses/Kconfig
index 4faf02b..2502ccb 100644
--- a/drivers/i2c/busses/Kconfig
+++ b/drivers/i2c/busses/Kconfig
@@ -322,6 +322,17 @@ config I2C_AT91
 	  the latency to fill the transmission register is too long. If you
 	  are facing this situation, use the i2c-gpio driver.
 
+config I2C_BK3220
+        tristate "PalmChip BK-3220"
+        depends on I2C && EXPERIMENTAL
+        select I2C_ALGOPALM
+        help
+          This supports the BK-3220 I2C adapter.  Say Y if you own
+          such an adapter.
+
+          This support is also available as a module.  If so, the module
+          will be called i2c-bk3220.
+
 config I2C_AU1550
 	tristate "Au1550/Au1200/Au1300 SMBus interface"
 	depends on MIPS_ALCHEMY
diff --git a/drivers/mtd/maps/Makefile b/drivers/mtd/maps/Makefile
index 395a124..2053f37 100644
--- a/drivers/mtd/maps/Makefile
+++ b/drivers/mtd/maps/Makefile
@@ -43,6 +43,7 @@ obj-$(CONFIG_MTD_INTEL_VR_NOR)	+= intel_vr_nor.o
 obj-$(CONFIG_MTD_BFIN_ASYNC)	+= bfin-async-flash.o
 obj-$(CONFIG_MTD_RBTX4939)	+= rbtx4939-flash.o
 obj-$(CONFIG_MTD_VMU)		+= vmu-flash.o
+obj-$(CONFIG_MTD_XLR)           += xlr-flash.o
 obj-$(CONFIG_MTD_GPIO_ADDR)	+= gpio-addr-flash.o
 obj-$(CONFIG_MTD_LATCH_ADDR)	+= latch-addr-flash.o
 obj-$(CONFIG_MTD_LANTIQ)	+= lantiq-flash.o
diff --git a/drivers/mtd/nand/nand_base.c b/drivers/mtd/nand/nand_base.c
index dfcd0a5..3362d946 100644
--- a/drivers/mtd/nand/nand_base.c
+++ b/drivers/mtd/nand/nand_base.c
@@ -1182,6 +1182,9 @@ static int nand_read_subpage(struct mtd_info *mtd, struct nand_chip *chip,
 					mtd->writesize + aligned_pos, -1);
 		chip->read_buf(mtd, &chip->oob_poi[aligned_pos], aligned_len);
 	}
+#ifdef	CONFIG_NLM_XLP 
+	index = start_step * chip->ecc.bytes;
+#endif
 
 	for (i = 0; i < eccfrag_len; i++)
 		chip->buffers->ecccode[i] = chip->oob_poi[eccpos[i + index]];
diff --git a/drivers/net/Kconfig b/drivers/net/Kconfig
index 3835321..89b26ea 100644
--- a/drivers/net/Kconfig
+++ b/drivers/net/Kconfig
@@ -168,6 +168,12 @@ config NETCONSOLE
 	If you want to log kernel messages over the network, enable this.
 	See <file:Documentation/networking/netconsole.txt> for details.
 
+config RMI_VNET
+	bool "Virtual Networking for CRF"
+	---help---
+	This enables internal network for CRF domains using shared memory and
+	event queues.
+
 config NETCONSOLE_DYNAMIC
 	bool "Dynamic reconfiguration of logging targets"
 	depends on NETCONSOLE && SYSFS && CONFIGFS_FS && \
diff --git a/drivers/oprofile/oprofile_files.c b/drivers/oprofile/oprofile_files.c
index 84a208d..c5413c6 100644
--- a/drivers/oprofile/oprofile_files.c
+++ b/drivers/oprofile/oprofile_files.c
@@ -190,7 +190,9 @@ void oprofile_create_files(struct super_block *sb, struct dentry *root)
 	oprofilefs_create_ulong(sb, root, "buffer_watershed", &oprofile_buffer_watershed);
 	oprofilefs_create_ulong(sb, root, "cpu_buffer_size", &oprofile_cpu_buffer_size);
 	oprofilefs_create_file(sb, root, "cpu_type", &cpu_type_fops);
-	oprofilefs_create_file(sb, root, "backtrace_depth", &depth_fops);
+	if (oprofile_ops.backtrace)
+		oprofilefs_create_file(sb, root, "backtrace_depth", 
+							&depth_fops);
 	oprofilefs_create_file(sb, root, "pointer_size", &pointer_size_fops);
 #ifdef CONFIG_OPROFILE_EVENT_MULTIPLEX
 	oprofilefs_create_file(sb, root, "time_slice", &timeout_fops);
diff --git a/drivers/pci/proc.c b/drivers/pci/proc.c
index 0812608..6de04b6 100644
--- a/drivers/pci/proc.c
+++ b/drivers/pci/proc.c
@@ -403,12 +403,20 @@ int pci_proc_attach_device(struct pci_dev *dev)
 		return -EACCES;
 
 	if (!bus->procdir) {
+#ifdef CONFIG_RMI_PHOENIX
+		/* 
+		   create /proc entries in "%02x" format at all times.
+		   Otherwise, for HT, it will be created in "%04x:%02x" format
+		   */
+		sprintf(name, "%02x", bus->number);
+#else
 		if (pci_proc_domain(bus)) {
 			sprintf(name, "%04x:%02x", pci_domain_nr(bus),
 					bus->number);
 		} else {
 			sprintf(name, "%02x", bus->number);
 		}
+#endif
 		bus->procdir = proc_mkdir(name, proc_bus_pci_dir);
 		if (!bus->procdir)
 			return -ENOMEM;
diff --git a/drivers/watchdog/Kconfig b/drivers/watchdog/Kconfig
index e5d5487..3d8afac 100644
--- a/drivers/watchdog/Kconfig
+++ b/drivers/watchdog/Kconfig
@@ -1104,6 +1104,14 @@ config LANTIQ_WDT
 	help
 	  Hardware driver for the Lantiq SoC Watchdog Timer.
 
+config RMI_WATCHDOG
+        tristate "RMI XL* Hardware Watchdog"
+        depends on WATCHDOG && RMI_PHOENIX
+        help
+          Hardware driver for the XL* watchdog. This is a watchdog timer
+          that will reboot the machine after a 60 second timer expired
+          and no process has written to /dev/watchdog during that time.
+
 # PARISC Architecture
 
 # POWERPC Architecture
diff --git a/include/linux/memblk.h b/include/linux/memblk.h
new file mode 100644
index 0000000..421642b
--- /dev/null
+++ b/include/linux/memblk.h
@@ -0,0 +1,55 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without 
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE 
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE. 
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/list.h>
+
+#define NTLBSZ 5
+
+typedef struct list_head list_t;
+
+struct memblk_list {
+	list_t list;
+	unsigned long align;
+};
+
+typedef struct memblk_list memblk_list_t;
+
+struct memblk {
+	list_t list;
+	uint64_t addr;
+	uint64_t size;
+};
+
+typedef struct memblk memblk_t;
+
+extern unsigned int vaddr_max_tlb_size(unsigned long addr);
+
+extern int add_memblk(uint64_t addr, uint64_t size);
+extern uint64_t __find_memblk(unsigned long page_size);
diff --git a/include/linux/mm.h b/include/linux/mm.h
index e0c8528..5ee41f5 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -99,6 +99,7 @@ extern unsigned int kobjsize(const void *objp);
 
 #define VM_DONTCOPY	0x00020000      /* Do not copy this vma on fork */
 #define VM_DONTEXPAND	0x00040000	/* Cannot expand with mremap() */
+#define VM_RESERVED	0x00080000	/* Count as reserved_vm like IO */
 #define VM_ACCOUNT	0x00100000	/* Is a VM accounted object */
 #define VM_NORESERVE	0x00200000	/* should the VM suppress accounting */
 #define VM_HUGETLB	0x00400000	/* Huge TLB Page VM */
diff --git a/include/linux/oprofile.h b/include/linux/oprofile.h
index a4c5624..c5e16b2 100644
--- a/include/linux/oprofile.h
+++ b/include/linux/oprofile.h
@@ -177,6 +177,8 @@ void oprofile_put_buff(unsigned long *buf, unsigned int start,
 unsigned long oprofile_get_cpu_buffer_size(void);
 void oprofile_cpu_buffer_inc_smpl_lost(void);
  
+void phoenix_oprofile_int_handler(int irq, void * dev_id, struct pt_regs *regs);
+
 /* cpu buffer functions */
 
 struct op_sample;
diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index dec1748..2e3fc99 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -522,6 +522,10 @@ struct sk_buff {
 				*data;
 	unsigned int		truesize;
 	atomic_t		users;
+#ifdef CONFIG_NLM_NET_OPTS
+	struct sk_buff 		*netl_skb;
+	unsigned int 		queue_id;
+#endif
 };
 
 #ifdef __KERNEL__
@@ -643,13 +647,21 @@ extern struct sk_buff *build_skb(void *data, unsigned int frag_size);
 static inline struct sk_buff *alloc_skb(unsigned int size,
 					gfp_t priority)
 {
+#if defined(CONFIG_NLM_XLP) && defined(CONFIG_64BIT)
+	return __alloc_skb(size, priority | GFP_DMA, 0, NUMA_NO_NODE);
+#else
 	return __alloc_skb(size, priority, 0, NUMA_NO_NODE);
+#endif
 }
 
 static inline struct sk_buff *alloc_skb_fclone(unsigned int size,
 					       gfp_t priority)
 {
+#if defined(CONFIG_NLM_XLP) && defined(CONFIG_64BIT)
+	return __alloc_skb(size, priority | GFP_DMA, SKB_ALLOC_FCLONE, NUMA_NO_NODE);
+#else
 	return __alloc_skb(size, priority, SKB_ALLOC_FCLONE, NUMA_NO_NODE);
+#endif
 }
 
 extern struct sk_buff *__alloc_skb_head(gfp_t priority, int node);
@@ -1967,14 +1979,22 @@ extern struct sk_buff *__netdev_alloc_skb(struct net_device *dev,
 static inline struct sk_buff *netdev_alloc_skb(struct net_device *dev,
 					       unsigned int length)
 {
+#if defined(CONFIG_NLM_XLP) && defined(CONFIG_64BIT)
+	return __netdev_alloc_skb(dev, length, GFP_ATOMIC | GFP_DMA);
+#else
 	return __netdev_alloc_skb(dev, length, GFP_ATOMIC);
+#endif
 }
 
 /* legacy helper around __netdev_alloc_skb() */
 static inline struct sk_buff *__dev_alloc_skb(unsigned int length,
 					      gfp_t gfp_mask)
 {
+#if defined(CONFIG_NLM_XLP) && defined(CONFIG_64BIT)
+	return __netdev_alloc_skb(NULL, length, gfp_mask | GFP_DMA);
+#else
 	return __netdev_alloc_skb(NULL, length, gfp_mask);
+#endif
 }
 
 /* legacy helper around netdev_alloc_skb() */
-- 
1.8.4.93.g57e4c17

