From b479f75f6d59c3c9a33bc82ccbbbe9985c2181cb Mon Sep 17 00:00:00 2001
From: Om Narasimhan <onarasimhan@netlogicmicro.com>
Date: Tue, 18 Oct 2011 17:49:55 -0700
Subject: [PATCH 286/565] Deleting code block repetition

Code block to find out the controller function from the table was repeated.
replaced it with a function call.

Based on Broadcom SDK 2.3.

Signed-off-by: Om Narasimhan <onarasimhan@netlogicmicro.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/netlogic/xlp/irq.c | 291 ++++++++++++++++++++++---------------------
 arch/mips/pci/pci-xlp.c      |  16 +--
 2 files changed, 153 insertions(+), 154 deletions(-)

diff --git a/arch/mips/netlogic/xlp/irq.c b/arch/mips/netlogic/xlp/irq.c
index de83249..c68c5b2 100644
--- a/arch/mips/netlogic/xlp/irq.c
+++ b/arch/mips/netlogic/xlp/irq.c
@@ -59,6 +59,12 @@ THE POSSIBILITY OF SUCH DAMAGE.
 /* Externs */
 extern void nlm_common_timer_interrupt(struct pt_regs *, int);
 extern void nlm_xlp_msgring_int_handler(int , struct pt_regs *);
+extern int xlp_ctrl_fn_from_dev(const struct pci_dev *);
+extern const struct cpumask *xlp_closest_match_cpumask(struct cpumask *);
+extern void xlp_intx_enable(int);
+extern void xlp_intx_disable(int);
+extern void xlp_set_cpumask(const struct cpumask *m, int irt);
+#if defined CONFIG_PCI_MSI
 extern int xlp_msi_status_clear(struct pci_dev *, int);
 extern int xlp_msi_enable(struct pci_dev *, u32);
 extern int xlp_msi_base_vector(struct pci_dev *);
@@ -68,15 +74,13 @@ extern void xlp_msi_disable(int, int);
 extern u32 xlp_msi_set_mask(int, int, int);
 volatile const void *xlp_msix_addr_start(int);
 volatile const void *xlp_msi_addr_start(int);
-extern int xlp_ctrl_fn_from_dev(const struct pci_dev *);
 extern u32 xlp_msix_status_clear(int);
 extern u32 xlp_msix_set_mask(int, int, int);
 extern int xlp_msix_enable(struct pci_dev *);
 extern void xlp_msix_disable(int);
-extern const struct cpumask *xlp_closest_match_cpumask(struct cpumask *);
-extern void xlp_set_cpumask(const struct cpumask *m, int irt);
-extern void xlp_intx_enable(int);
-extern void xlp_intx_disable(int);
+void mask_msi_irq(unsigned int);
+void unmask_msi_irq(unsigned int);
+#endif
 
 /* own variables */
 
@@ -89,8 +93,9 @@ static volatile uint64_t xlp_irq_mask;
 /* spin lock for all interrupt related data structures
  * This variable is used in timer init, so we export it
  */
-DEFINE_SPINLOCK(xlp_pic_lock);
+spinlock_t xlp_pic_lock = SPIN_LOCK_UNLOCKED;
 EXPORT_SYMBOL(xlp_pic_lock);
+#if defined CONFIG_PCI_MSI
 /*
  * This bitmap keeps track of the MSI vectors allocated from
  * XLP_MSIX_IRQ_START(x)
@@ -100,6 +105,7 @@ struct msix_alloc_bitmap {
 	u32 count;	/* #of bits set at any point of time */
 };
 static struct msix_alloc_bitmap msix_vec[XLP_MAX_SLOTS];
+#endif
 
 /*
  * There are two data structures pivotal for interrupt delivery mechanism
@@ -490,20 +496,21 @@ static void __nlm_irq_mask(unsigned int irq)
 	if (rvec < 0) {
 		return;
 	}
-	on_each_cpu(xlp_clear_eimr, (void *) (1ULL << rvec), 1);
+	if (read_64bit_cp0_eimr() & (1ULL << rvec)) {
+		/* We do not clear eimr, this is a TODO for later time */
+		//on_each_cpu(xlp_clear_eimr, (void *) (1ULL << rvec), 1);
+	}
 	return;
 }
 
-#if 0 /* DEPRECATED */
 /*
  * Interface function (unlocked version) to mask an IRQ
  * Calls helper function after input tests and spin_lock holds
  *
  * @irq : IRQ number
  */
-static void nlm_irq_mask(struct irq_data *d)
+static void nlm_irq_mask(unsigned int irq)
 {
-	unsigned int irq = d->irq;
 	//unsigned long flags;
 
 	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
@@ -512,12 +519,13 @@ static void nlm_irq_mask(struct irq_data *d)
 		pr_err("irq = %d. Invalid irq requested\n", irq);
 		return;
 	}
+	// Once enabled, we don't mask it out
 	//spin_lock_irqsave(&xlp_pic_lock, flags);	// Remove XXX
-	__nlm_irq_mask(irq);
+	__nlm_irq_mask(irq);				// XXX
 	//spin_unlock_irqrestore(&xlp_pic_lock, flags);	// XXX remove
 	return;
 }
-#endif
+
 
 /*
  * Changes eimr bit value corresponding to IRT
@@ -529,21 +537,22 @@ static void __nlm_irq_unmask(int irq)
 
 	if (rvec < 0) {
 		return;
+	} else if (((1ULL << rvec) & read_64bit_cp0_eimr()) == 0) {
+		/* This is only for those interrupts which are not statically
+		 * set in EIMR. Could dump stack if spin lock held */
+		 on_each_cpu(xlp_set_eimr, (void *) (1ULL << rvec), 1);
 	}
-	on_each_cpu(xlp_set_eimr, (void *) (1ULL << rvec), 1);
 	return;
 }
 
-#if 0 /* DEPRECATED */
 /*
  * Interface function (unlocked version) to mask an IRQ
  * Calls helper function after input tests and spin_lock holds
  *
  * @irq : IRQ number
  */
-static void nlm_irq_unmask(struct irq_data *d)
+static void nlm_irq_unmask(unsigned int irq)
 {
-	unsigned int irq = d->irq;
 	//unsigned long flags;
 
 	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
@@ -557,11 +566,9 @@ static void nlm_irq_unmask(struct irq_data *d)
 	//spin_unlock_irqrestore(&xlp_pic_lock, flags);
 	return;
 }
-#endif
 
-static void xlp_pic_unmask(struct irq_data *d)
+static void nlm_irq_ack(unsigned int irq)
 {
-	unsigned int irq = d->irq;
 	unsigned long flags;
 
 	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
@@ -570,9 +577,31 @@ static void xlp_pic_unmask(struct irq_data *d)
 		pr_err("irq = %d. Invalid irq requested\n", irq);
 		return;
 	}
-	spin_lock_irqsave(&xlp_pic_lock, flags);
-	nlm_hal_ack_pic(xlp_irq_to_irt(irq));
-	spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	/* If edge triggered, ack it ASAP. Handle the interrupt later */
+	if (PIC_IRQ_IS_EDGE_TRIGGERED(xlp_irq_to_irt(irq))) {
+		spin_lock_irqsave(&xlp_pic_lock, flags);
+		nlm_hal_ack_pic(xlp_irq_to_irt(irq));
+		spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	}
+}
+
+static void nlm_irq_end(unsigned int irq)
+{
+	unsigned long flags;
+
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return;
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
+		return;
+	}
+	/* If level triggered, ack it after the device condition is cleared */
+	if (!PIC_IRQ_IS_EDGE_TRIGGERED(xlp_irq_to_irt(irq))) {
+		spin_lock_irqsave(&xlp_pic_lock, flags);
+		nlm_hal_ack_pic(xlp_irq_to_irt(irq));
+		spin_unlock_irqrestore(&xlp_pic_lock, flags);
+	}
+	return;
 }
 
 /*
@@ -584,10 +613,9 @@ static void xlp_pic_unmask(struct irq_data *d)
  * When an interrupt is started, we force it to be enabled only in cpu0, it can
  * be changed later by calling nlm_irq_set_affinity()
  */
-static unsigned int nlm_irq_startup(struct irq_data *d)
+static unsigned int nlm_irq_startup(unsigned int irq)
 {
 	__label__ __failure;
-	unsigned int irq = d->irq;
 	int ret = 0;
 	unsigned long flags;
 	int idx, rvec;
@@ -648,9 +676,8 @@ __failure:
  * chip->shutdown(). In this function, the rvec bit in every EIMR is cleared if
  * usage falls to zero (in case of shared interrupts)
  */
-static void nlm_irq_shutdown(struct irq_data *d)
+static void nlm_irq_shutdown(unsigned int irq)
 {
-	unsigned int irq = d->irq;
 	unsigned long flags;
 	int idx, rvec;
 
@@ -662,14 +689,14 @@ static void nlm_irq_shutdown(struct irq_data *d)
 	}
 	spin_lock_irqsave(&xlp_pic_lock, flags);
 	if (irq_map[irq].usage == 0) {
-		fdebug("irq = %d, usage = %d\n", irq, irq_map[irq].usage);
+		//fdebug("irq = %d, usage = %d\n", irq, irq_map[irq].usage);
 		spin_unlock_irqrestore(&xlp_pic_lock, flags);
 		return;
 	} else if (irq_map[irq].usage > 0) {
 		irq_map[irq].usage--;
 	}
 	if (irq_map[irq].usage == 0) {
-		fdebug("irq = %d, usage = %d\n", irq, irq_map[irq].usage);
+		//fdebug("irq = %d, usage = %d\n", irq, irq_map[irq].usage);
 		rvec = xlp_rvec_from_irq(irq);
 		idx = irq - __irqbase_from_rvec(rvec);
 		clear_bit(idx, &(rvec_map[rvec].bitmap));
@@ -700,9 +727,8 @@ static void nlm_irq_shutdown(struct irq_data *d)
  * The actual bitmask can be different from the specified bitmask based
  * on the logic of xlp_closest_match_cpumask()
  */
-static int nlm_irq_set_affinity(struct irq_data *d, const struct cpumask *mask, bool force)
+static int nlm_irq_set_affinity(unsigned int irq, const struct cpumask *mask)
 {
-	unsigned int irq = d->irq;
 	unsigned long flags;
 	const struct cpumask *m;
 	struct cpumask n;
@@ -725,29 +751,31 @@ static int nlm_irq_set_affinity(struct irq_data *d, const struct cpumask *mask,
 	return 0;
 }
 
-/* For default handle_level_irq, the flow is as follows:
-	desc->irq_data.chip->irq_mask_ack();
-	handle_irq_event(desc->action);
-	desc->irq_data.chip->irq_unmask();
-*/
-static void xlp_pic_mask_ack(struct irq_data *d)
-{
-	/* Do nothing here. */
-	/* Since rvec is multiplexed, we do not ack eirr here. */
-}
-
 static struct irq_chip nlm_irq_pic = {
 	.name = "XLP-PIC",
-	.irq_mask_ack = xlp_pic_mask_ack,
-	.irq_unmask = xlp_pic_unmask,
-	.irq_enable = nlm_irq_startup,
-	.irq_disable = nlm_irq_shutdown,
-	.irq_set_affinity = nlm_irq_set_affinity
+	.mask = nlm_irq_mask,
+	.unmask = nlm_irq_unmask,
+	.startup = nlm_irq_startup,
+	.mask = nlm_irq_shutdown,
+	.ack = nlm_irq_ack,
+	.end = nlm_irq_end,
+	.set_affinity = nlm_irq_set_affinity
 };
 
-static void rsvd_pic_handler_1(struct irq_data *d)
+static void rsvd_pic_handler_1_1(unsigned int irq)
+{
+	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
+		return;
+	} else if(irq >= XLP_IRQ_MAX) {
+		pr_err("irq = %d. Invalid irq requested\n", irq);
+		return;
+	}
+	pr_err("Requesting a reserved irq (%d)??", irq);
+	return;
+}
+
+static void rsvd_pic_handler_1(unsigned int irq)
 {
-	unsigned int irq = d->irq;
 	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
 		return;
 	} else if(irq >= XLP_IRQ_MAX) {
@@ -758,9 +786,8 @@ static void rsvd_pic_handler_1(struct irq_data *d)
 	return;
 }
 
-static int rsvd_pic_handler_2(struct irq_data *d, const struct cpumask *mask, bool force)
+static int rsvd_pic_handler_2(unsigned int irq, const struct cpumask *mask)
 {
-	unsigned int irq = d->irq;
 	if((irq < XLP_IRQ_RESERVED_MAX) && (irq >= 0)) {
 		return 0;
 	} else if(irq >= XLP_IRQ_MAX) {
@@ -773,11 +800,11 @@ static int rsvd_pic_handler_2(struct irq_data *d, const struct cpumask *mask, bo
 
 struct irq_chip nlm_common_rsvd_pic = {
 	.name = "Netlogic-RSVD-PIC",
-	.irq_unmask = rsvd_pic_handler_1,
-	.irq_mask = rsvd_pic_handler_1,
-	.irq_ack = rsvd_pic_handler_1,
-	// .end = rsvd_pic_handler_1, /* deprecated */
-	.irq_set_affinity = rsvd_pic_handler_2
+	.unmask = rsvd_pic_handler_1_1,
+	.mask = rsvd_pic_handler_1,
+	.ack = rsvd_pic_handler_1,
+	.end = rsvd_pic_handler_1,
+	.set_affinity = rsvd_pic_handler_2
 };
 
 static irqreturn_t nlm_common_rsvd_irq_handler(int irq, void *dev_id)
@@ -830,8 +857,7 @@ void __cpuinit nlm_smp_irq_init(void)
 	/* Set up kseg0 to be cachable coherent */
 	change_c0_config(CONF_CM_CMASK, CONF_CM_DEFAULT);
 #endif
-	/* set interrupt mask for non-zero cpus */
-	write_64bit_cp0_eimr(xlp_irq_mask | (1 << XLP_IRQ_TIMER));
+	write_64bit_cp0_eimr(xlp_irq_mask);
 }
 
 void destroy_irq(unsigned int irq)
@@ -839,7 +865,7 @@ void destroy_irq(unsigned int irq)
     /* no-op */
 }
 
-#ifdef CONFIG_PCI_MSI_XLP
+#ifdef CONFIG_PCI_MSI
 
 /*
  * The MSI and MSI-X functionality is supported only by the PCIe Controller.
@@ -964,13 +990,13 @@ static void nlm_msi_unmask(unsigned int msi)
 
 struct irq_chip nlm_msi_pic = {
 	.name = "XLP-PIC-MSI",
-	.irq_startup = nlm_msi_startup,
-	.irq_shutdown = nlm_msi_shutdown,
-	.irq_ack = nlm_msi_ack,
-	// .end = nlm_msi_end, /* deprecated */
-	.irq_mask = nlm_msi_mask,
-	.irq_unmask = nlm_msi_unmask,
-	.irq_set_affinity = nlm_msi_set_affinity
+	.startup = nlm_msi_startup,
+	.shutdown = nlm_msi_shutdown,
+	.ack = nlm_msi_ack,
+	.end = nlm_msi_end,
+	.mask = nlm_msi_mask,
+	.unmask = nlm_msi_unmask,
+	.set_affinity = nlm_msi_set_affinity
 };
 
 /*
@@ -1063,13 +1089,13 @@ static void nlm_msix_shutdown(unsigned int msix)
 
 struct irq_chip nlm_msix_pic = {
 	.name = "XLP-PIC-MSIX",
-	.irq_startup = nlm_msix_startup,
-	.irq_shutdown = nlm_msix_shutdown,
-	.irq_ack = nlm_msix_ack,
-	// .end = nlm_msix_end, /* deprecated */
-	.irq_mask = nlm_msix_mask,
-	.irq_unmask = nlm_msix_unmask,
-	.irq_set_affinity = nlm_msix_set_affinity
+	.startup = nlm_msix_startup,
+	.shutdown = nlm_msix_shutdown,
+	.ack = nlm_msix_ack,
+	.end = nlm_msix_end,
+	.mask = nlm_msix_mask,
+	.unmask = nlm_msix_unmask,
+	.set_affinity = nlm_msix_set_affinity
 };
 
 
@@ -1085,13 +1111,13 @@ static int xlp_msi_compose_msg(struct pci_dev *pdev, struct msi_desc *desc,
 	if (fn < 0) return -EINVAL;
 	if (desc->msi_attrib.is_msix) {
 		if (irq < XLP_MSIX_INDEX_START) {	/* enforce minimum */
-			fdebug("Invalid irq %d", irq);
+			dev_err(&pdev->dev, "Invalid irq %d", irq);
 			return -EINVAL;
 		}
 		offset = irq - XLP_MSIX_INDEX_START;
 		msg->address_hi = (virt_to_phys(xlp_msix_addr_start(fn)) >> 32);
 		msg->address_lo = (virt_to_phys(xlp_msix_addr_start(fn)) & 0xffffffff);
-		dev_err(&pdev->dev, "MSI-X hi = %#x, lo = %#x, data = %#x\n", msg->address_hi, msg->address_lo, offset);
+		//dev_dbg(&pdev->dev, "MSI-X hi = %#x, lo = %#x, data = %#x\n", msg->address_hi, msg->address_lo, offset);
 	} else {
 		if (irq < XLP_MSI_IRQ_OFFSET) {	/* enforce minimum */
 			return -EINVAL;
@@ -1116,7 +1142,7 @@ u32 __xlp_msix_bitmask(int fn)
 
 	while (idx < XLP_MSIX_PER_SLOT) {
 		if (irq_map[XLP_MSIX_IRQ_START(fn) + idx].usage > 0) {
-			ret |= (1 << idx);
+			ret |= (1ULL << idx);
 		}
 		idx++;
 	}
@@ -1158,7 +1184,7 @@ void arch_teardown_msi_irq(unsigned int msi)
 		spin_lock_irqsave(&xlp_pic_lock, flags);
 		if (irq_map[msi].usage > 0) {
 			irq_map[msi].usage--;
-			msix_vec[fn].bitmap &= ~(1 << bit);
+			msix_vec[fn].bitmap &= ~(1ULL << bit);
 			msix_vec[fn].count--;
 		}
 		if (!__xlp_msix_bitmask(fn)) {
@@ -1194,7 +1220,7 @@ asmlinkage void plat_irq_dispatch(void)
 	eirr = read_64bit_cp0_eirr();
 	eimr = read_64bit_cp0_eimr();
 	eirr &= eimr;
-	if (eirr & (1 << XLP_IRQ_TIMER)) {
+	if (eirr & (1ULL << XLP_IRQ_TIMER)) {
 		nlm_common_timer_interrupt(pt_regs, XLP_IRQ_TIMER);
 		return;
 	}
@@ -1226,8 +1252,9 @@ asmlinkage void plat_irq_dispatch(void)
 		bitmap = rvec_map[rvec].bitmap;
 		spin_unlock_irqrestore(&xlp_pic_lock, flags);
 		switch(base_irq) {
-#ifdef CONFIG_PCI_MSI_XLP
-		/* These are not MSIs, but IRT #s */
+		/* For INTX, bitmap and base irq already set */
+#if defined CONFIG_PCI_MSI
+		/* These are not MSI vector numbers, but IRT #s */
 		case XLP_PCIE_LINK_IRQ(0) ... XLP_PCIE_LINK_IRQ(3):
 			/* Here fn # of controller is easily calculated
 			 * Check the IRT table : 0 -> 78, 1-> 79 ..etc */
@@ -1248,7 +1275,7 @@ asmlinkage void plat_irq_dispatch(void)
 			base_irq = XLP_MSIX_IRQ_START(fn);
 			/* now handle it as any other interrupt */
 			break;
-#endif /* CONFIG_PCI_MSI_XLP */
+#endif
 		default:
 			break;
 		}
@@ -1277,10 +1304,7 @@ int nlm_xlp_request_irq(int irq)
 }
 EXPORT_SYMBOL(nlm_xlp_request_irq);
 
-#ifndef CONFIG_PCI_MSI_XLP
-int arch_setup_msi_irqs(struct pci_dev *dev, int nvec, int type) { return 0; }
-void arch_teardown_msi_irq(unsigned int msi) { }
-#else /* CONFIG_PCI_MSI_XLP */
+#if defined CONFIG_PCI_MSI
 #ifdef arch_setup_msi_irqs
 /*
  * Arch specific setup functions and helpers
@@ -1362,7 +1386,7 @@ int xlp_setup_msi_irq(struct pci_dev *dev, struct msi_desc *desc, int nvec)
 	if (ret < 0) {
 		return max;
 	}
-	irq_set_msi_desc(base_msi, desc);
+	set_irq_msi(base_msi, desc);
 	ret = xlp_msi_compose_msg(dev, desc, base_msi, &msg);
 	if (ret < 0) {
 		return ret;
@@ -1412,7 +1436,7 @@ int xlp_setup_msix_irq(struct pci_dev *dev, struct msi_desc *desc, int nvec)
 		}
 		/* We hit an unused entry */
 		irq_map[base_msix + idx].usage = 1;
-		msix_vec[fn].bitmap |= 1 << idx;
+		msix_vec[fn].bitmap |= (1ULL << idx);
 		msix_vec[fn].count++;
 		break;
 	}
@@ -1420,7 +1444,7 @@ int xlp_setup_msix_irq(struct pci_dev *dev, struct msi_desc *desc, int nvec)
 	if (idx == XLP_MSIX_PER_SLOT) {
 		return -ENOSPC;
 	}
-	irq_set_msi_desc(base_msix + idx, desc);
+	set_irq_msi(base_msix + idx, desc);
 	ret = xlp_msi_compose_msg(dev, desc, base_msix + idx, &msg);
 	if (ret < 0) {
 		return ret;
@@ -1461,90 +1485,77 @@ int arch_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 }
 EXPORT_SYMBOL(arch_setup_msi_irqs);
 #endif
-#endif /* CONFIG_PCI_MSI_XLP */
-
-#define PIC_IRQ_BASE XLP_IRQ_RESERVED_MAX
-
-static void rsvd_irq_handler(struct irq_data *d)
-{
-	WARN(d->irq >= PIC_IRQ_BASE, "Bad irq %d", d->irq);
-}
-
-/*
- * Chip definition for CPU originated interrupts(timer, msg) and
- * IPIs
- */
-struct irq_chip nlm_cpu_intr = {
-	.name           = "XLP-CPU-INTR",
-	.irq_enable     = rsvd_irq_handler,
-	.irq_mask       = rsvd_irq_handler,
-	.irq_ack        = rsvd_irq_handler,
-};
-
-static inline void irq_desc_set_chip(struct irq_desc *desc, struct irq_chip *chip)
-{
-	irq_desc_get_irq_data(desc)->chip = chip;
-}
+#endif
 
 void __init init_nlm_common_irqs(void)
 {
 	int i;
+	u64	mask = 0;
 
 	for (i = 0; i < XLP_IRQ_MAX; i++) {	// IRQ : 0 - 167
-		if (i >= PIC_IRQ_BASE)
-			irq_set_chip_and_handler(i, &nlm_irq_pic,
-						 handle_level_irq);
-		else
-			irq_set_chip_and_handler(i, &nlm_cpu_intr,
-						 handle_percpu_irq);
-	}
-#ifdef CONFIG_PCI_MSI_XLP
+		set_irq_chip(i, &nlm_irq_pic);
+	}
+#ifdef CONFIG_PCI_MSI
 	for (i = XLP_MSI_INDEX_START; i <= XLP_MSI_INDEX_END; i++) {
-		irq_set_chip(i, &nlm_msi_pic);
+		set_irq_chip(i, &nlm_msi_pic);
 	}
 	for (i = XLP_MSIX_INDEX_START; i <= XLP_MSIX_INDEX_END; i++) {
-		irq_set_chip(i, &nlm_msix_pic);
+		set_irq_chip(i, &nlm_msix_pic);
 	}
 #endif
 
-#ifdef CONFIG_REMOTE_DEBUG
-	irq_desc_set_chip(&irq_desc[XLP_IRQ_REMOTE_DEBUG], &nlm_common_rsvd_pic);
-	irq_desc[XLP_IRQ_REMOTE_DEBUG].action = &nlm_common_rsvd_action;
-	xlp_irq_mask |= (1ULL << XLP_IRQ_REMOTE_DEBUG);
+#ifdef CONFIG_REMOTE_DEBUG	/* REMOVE on XLP TODO */
+	irq_desc[XLP_IRQ_REMOTE_DEBUG].chip = &nlm_common_rsvd_pic;
+	irq_desc[XLP_IRQ_REMOTE_DEBUG].action = nlm_common_rsvd_action;
+	// xlp_irq_mask |= (1ULL << XLP_IRQ_REMOTE_DEBUG);
 #endif
-
 #ifdef CONFIG_SMP
-	irq_desc_set_chip(&irq_desc[XLP_IRQ_IPI_SMP_FUNCTION], &nlm_common_rsvd_pic);
+	irq_desc[XLP_IRQ_IPI_SMP_FUNCTION].chip = &nlm_common_rsvd_pic;
 	irq_desc[XLP_IRQ_IPI_SMP_FUNCTION].action = &nlm_common_rsvd_action;
 
-	irq_desc_set_chip(&irq_desc[XLP_IRQ_IPI_SMP_RESCHEDULE], &nlm_common_rsvd_pic);
+	irq_desc[XLP_IRQ_IPI_SMP_RESCHEDULE].chip = &nlm_common_rsvd_pic;
 	irq_desc[XLP_IRQ_IPI_SMP_RESCHEDULE].action = &nlm_common_rsvd_action;
 
-#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY	/* REMOVE on XLP TODO */
 	/* PR: New IPI added here for netrx balancing */
-	irq_desc_set_chip(&irq_desc[XLP_IRQ_IPI_NETRX], &nlm_common_rsvd_pic);
+	irq_desc[XLP_IRQ_IPI_NETRX].chip = &nlm_common_rsvd_pic;
 	irq_desc[XLP_IRQ_IPI_NETRX].action = &nlm_common_rsvd_action;
-	xlp_irq_mask |= (1ULL << XLP_IRQ_IPI_NETRX);
+	//xlp_irq_mask |= (1ULL << XLP_IRQ_IPI_NETRX);
 #endif				/* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
 
-	xlp_irq_mask |= ((1ULL << XLP_IRQ_IPI_SMP_FUNCTION) |
-			     (1ULL << XLP_IRQ_IPI_SMP_RESCHEDULE));
 #endif
 
 	/* msgring interrupt */
-	irq_desc_set_chip(&irq_desc[XLP_IRQ_MSGRING], &nlm_common_rsvd_pic);
+	irq_desc[XLP_IRQ_MSGRING].chip = &nlm_common_rsvd_pic;
 	irq_desc[XLP_IRQ_MSGRING].action = &nlm_common_rsvd_action;
-	xlp_irq_mask |= (1ULL << XLP_IRQ_MSGRING);
 
+	mask = (
+			(1ULL << XLP_IRQ_TIMER) |
+			(1ULL << 10) |	/* timer */
+			(1ULL << 49) |	/* msg_idx */
+			(0x3ULL << 48) |	/* msg_idx */
+			(0xfULL << 32) |	/* pci msix */
+			(0xfULL << 41) |	/* pci and msi */
+			(0x1ULL << 58) |	/* nae */
+			(0x3ULL << 24) |	/* usb */
+			(0x3ULL	<< 17) |	/* uart */
+			(0xfULL << 13) |	/* gpio */
+#ifdef CONFIG_SMP
+			(1ULL << XLP_IRQ_IPI_SMP_FUNCTION) |
+			(1ULL << XLP_IRQ_IPI_SMP_RESCHEDULE) |
+#endif
 #ifdef CONFIG_OPROFILE
-	xlp_irq_mask |= (1ULL << XLP_IRQ_IPI_OPROFILE);
+			(1ULL << XLP_IRQ_IPI_OPROFILE) |
 #endif
-
 #ifdef CONFIG_KGDB
-	xlp_irq_mask |= (1ULL << XLP_IRQ_IPI_SMP_KGDB);
+			(1ULL << XLP_IRQ_IPI_SMP_KGDB) |
 #endif
-
-	xlp_irq_mask |= (1ULL << XLP_IRQ_TIMER);
+			(1ULL << XLP_IRQ_MSGRING) |
+			(0xfULL << 20)		/* nor, nand, spi and mmc */
+	       );
+	/* set interrupt mask for non-zero cpus */
+	mask |= read_64bit_cp0_eimr();
+	xlp_irq_mask = mask;
 }
 
 
diff --git a/arch/mips/pci/pci-xlp.c b/arch/mips/pci/pci-xlp.c
index 50e550a..384ee14 100644
--- a/arch/mips/pci/pci-xlp.c
+++ b/arch/mips/pci/pci-xlp.c
@@ -686,24 +686,12 @@ u32 xlp_msi_set_mask(int fn, int bit, int val)
  */
 int xlp_msi_status_clear(struct pci_dev *dev, int bit)
 {
-	__label__ out;
 	int row = 0, fn = 0;
 	u64 xlp_pci_base;
 	u32 msi_en;
 
-	while (row < 4) {
-		fn = 0;
-		while (fn < 4) {
-			if ((dev->bus->number >= xlp_irq_map[row][fn][1]) &&
-				(dev->bus->number <= xlp_irq_map[row][fn][2])) {
-				goto out; /* No `break', note two loops */
-			}
-			fn++;
-		}
-		row++;
-	}
-out:
-	if (fn >= 4) {
+	fn = xlp_ctrl_fn_from_dev(dev);
+	if ((fn >= 4) || (fn < 0)) {
 		return -ENODEV;
 	}
 	xlp_pci_base = XLP_BDF_BASE(0,1,fn);
-- 
1.8.4.93.g57e4c17

