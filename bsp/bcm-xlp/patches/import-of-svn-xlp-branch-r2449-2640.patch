From 44ae6640920b4722f859ca220d9aacf81089d2fd Mon Sep 17 00:00:00 2001
From: Yanjiang Jin <yanjiang.jin@windriver.com>
Date: Tue, 23 Apr 2013 16:36:03 +0800
Subject: [PATCH 007/565] import of svn/xlp branch -r2449:2640

import of svn/xlp branch -r2449:2640.

Based on Broadcom SDK 2.3.

Signed-off-by: Venu Vadapalli <vvadapalli@netlogicmicro.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/Makefile                                 |   66 +-
 arch/mips/include/asm/atomic.h                     |    8 +-
 arch/mips/include/asm/bootinfo.h                   |   18 +-
 arch/mips/include/asm/cacheflush.h                 |   27 +-
 arch/mips/include/asm/dma.h                        |    2 +-
 .../include/asm/mach-netlogic/kernel-entry-init.h  |   57 +
 arch/mips/include/asm/mach-netlogic/mmu.h          |   64 +
 arch/mips/include/asm/mach-netlogic/pgtable-xlp.h  |   59 +
 arch/mips/include/asm/mach-netlogic/pgwalker.h     |   36 +
 arch/mips/include/asm/mach-netlogic/xlp-mmu.h      |   35 +
 arch/mips/include/asm/mmu_context.h                |   37 +-
 arch/mips/include/asm/msi.h                        |   16 +-
 arch/mips/include/asm/netlogic/64bit.h             |   73 +
 arch/mips/include/asm/netlogic/debug.h             |  112 +
 arch/mips/include/asm/netlogic/gpio.h              |   72 +
 arch/mips/include/asm/netlogic/hal/nlm_hal.h       |  176 ++
 .../mips/include/asm/netlogic/hal/nlm_hal_crypto.h |  262 +++
 arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h   | 1103 +++++++++
 .../mips/include/asm/netlogic/hal/nlm_hal_macros.h | 1334 +++++++++++
 arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h   |  619 +++++
 arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h   |  465 ++++
 arch/mips/include/asm/netlogic/hal/nlm_hal_sys.h   |  182 ++
 .../include/asm/netlogic/hal/nlm_hal_xlp_dev.h     | 2366 ++++++++++++++++++++
 arch/mips/include/asm/netlogic/hal/nlm_nae.h       |  225 ++
 arch/mips/include/asm/netlogic/interrupt.h         |   86 +-
 arch/mips/include/asm/netlogic/io.h                |   48 +
 arch/mips/include/asm/netlogic/iomap.h             |  294 +++
 arch/mips/include/asm/netlogic/mips-exts.h         |  424 ++++
 arch/mips/include/asm/netlogic/msgring.h           |  687 ++++++
 arch/mips/include/asm/netlogic/msidef.h            |   73 +
 arch/mips/include/asm/netlogic/nlm_rw_lock.h       |  216 ++
 arch/mips/include/asm/netlogic/pic.h               |   62 +
 arch/mips/include/asm/netlogic/proc.h              |   46 +
 arch/mips/include/asm/netlogic/xlp-hal/iomap.h     |    2 +-
 arch/mips/include/asm/smp.h                        |   18 +-
 arch/mips/include/asm/stackframe.h                 |    2 +-
 arch/mips/include/asm/timex.h                      |    4 +-
 arch/mips/kernel/Makefile                          |    1 +
 arch/mips/kernel/asm-offsets.c                     |   14 +-
 arch/mips/kernel/cevt-r4k.c                        |    1 +
 arch/mips/kernel/genex.S                           |   14 +
 arch/mips/kernel/head.S                            |    2 +-
 arch/mips/kernel/kgdb.c                            |   34 +-
 arch/mips/kernel/proc.c                            |   27 +-
 arch/mips/kernel/ptrace.c                          |   28 +-
 arch/mips/kernel/r4k_switch.S                      |    2 +-
 arch/mips/kernel/setup.c                           |   81 +-
 arch/mips/kernel/time.c                            |    1 -
 arch/mips/kernel/traps.c                           |  119 +-
 arch/mips/math-emu/kernel_linkage.c                |   16 +-
 arch/mips/mm/c-phoenix.c                           |  138 +-
 arch/mips/mm/cache.c                               |   23 +-
 arch/mips/mm/cex-gen.S                             |   22 +-
 arch/mips/mm/extable.c                             |   21 -
 arch/mips/mm/ioremap.c                             |   16 +-
 arch/mips/mm/tlb-r4k.c                             |   72 +-
 arch/mips/mm/tlbex.c                               |  210 +-
 arch/mips/netlogic/Kconfig                         |  221 +-
 arch/mips/netlogic/Makefile                        |    3 -
 arch/mips/netlogic/boot/Makefile                   |    3 +
 arch/mips/netlogic/common/Makefile                 |   20 +-
 arch/mips/netlogic/common/cpu_proc.c               |  223 ++
 arch/mips/netlogic/common/memory.c                 |  194 ++
 arch/mips/netlogic/common/nlm_hal.c                | 1584 +++++++++++++
 arch/mips/netlogic/xlp/Makefile                    |   13 +-
 arch/mips/netlogic/xlp/irq.c                       |  609 +++++
 arch/mips/netlogic/xlp/mmu.c                       |  176 ++
 arch/mips/netlogic/xlp/nmi.S                       |  105 +
 arch/mips/netlogic/xlp/on_chip.c                   |  820 +++++++
 arch/mips/netlogic/xlp/platform-xlp.c              |  290 +++
 arch/mips/netlogic/xlp/setup.c                     |  173 +-
 arch/mips/netlogic/xlp/smp.c                       |  237 ++
 arch/mips/netlogic/xlp/time.c                      |  226 ++
 arch/mips/oprofile/Makefile                        |    2 +-
 arch/mips/oprofile/common.c                        |   16 +-
 arch/mips/pci/pci-xlp.c                            |  329 ++-
 crypto/Makefile                                    |    2 +-
 drivers/char/Kconfig                               |    6 +-
 drivers/char/Makefile                              |    2 +
 drivers/net/Kconfig                                |   11 +-
 drivers/net/xlp_nae/Makefile                       |   15 +
 drivers/net/xlp_nae/init_nae.c                     |  222 ++
 drivers/net/xlp_nae/net_common.h                   |  170 ++
 drivers/net/xlp_nae/reg.h                          |   40 +
 drivers/net/xlp_nae/ucore_apps.c                   |   77 +
 drivers/net/xlp_nae/ucore_loader.c                 |   79 +
 drivers/net/xlp_nae/ucore_loader.h                 |   18 +
 drivers/net/xlp_nae/xlp_hw.c                       |  496 ++++
 drivers/net/xlp_nae/xlp_nae.c                      | 1197 ++++++++++
 drivers/net/xlp_nae/xlp_nae.h                      |   60 +
 drivers/pci/proc.c                                 |    2 +-
 drivers/watchdog/Kconfig                           |    4 +-
 drivers/watchdog/Makefile                          |    1 +
 include/linux/memblk.h                             |   53 +-
 include/linux/oprofile.h                           |    2 +-
 net/core/skbuff.c                                  |    4 +
 96 files changed, 17166 insertions(+), 757 deletions(-)
 create mode 100644 arch/mips/include/asm/mach-netlogic/kernel-entry-init.h
 create mode 100644 arch/mips/include/asm/mach-netlogic/mmu.h
 create mode 100644 arch/mips/include/asm/mach-netlogic/pgtable-xlp.h
 create mode 100644 arch/mips/include/asm/mach-netlogic/pgwalker.h
 create mode 100644 arch/mips/include/asm/mach-netlogic/xlp-mmu.h
 create mode 100644 arch/mips/include/asm/netlogic/64bit.h
 create mode 100644 arch/mips/include/asm/netlogic/debug.h
 create mode 100644 arch/mips/include/asm/netlogic/gpio.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_hal.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_hal_crypto.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_hal_sys.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h
 create mode 100644 arch/mips/include/asm/netlogic/hal/nlm_nae.h
 create mode 100644 arch/mips/include/asm/netlogic/io.h
 create mode 100644 arch/mips/include/asm/netlogic/iomap.h
 create mode 100644 arch/mips/include/asm/netlogic/mips-exts.h
 create mode 100644 arch/mips/include/asm/netlogic/msgring.h
 create mode 100644 arch/mips/include/asm/netlogic/msidef.h
 create mode 100644 arch/mips/include/asm/netlogic/nlm_rw_lock.h
 create mode 100644 arch/mips/include/asm/netlogic/pic.h
 create mode 100644 arch/mips/include/asm/netlogic/proc.h
 create mode 100644 arch/mips/netlogic/boot/Makefile
 create mode 100644 arch/mips/netlogic/common/cpu_proc.c
 create mode 100644 arch/mips/netlogic/common/memory.c
 create mode 100644 arch/mips/netlogic/common/nlm_hal.c
 create mode 100644 arch/mips/netlogic/xlp/irq.c
 create mode 100644 arch/mips/netlogic/xlp/mmu.c
 create mode 100644 arch/mips/netlogic/xlp/nmi.S
 create mode 100644 arch/mips/netlogic/xlp/on_chip.c
 create mode 100644 arch/mips/netlogic/xlp/platform-xlp.c
 create mode 100644 arch/mips/netlogic/xlp/smp.c
 create mode 100644 arch/mips/netlogic/xlp/time.c
 create mode 100644 drivers/net/xlp_nae/Makefile
 create mode 100644 drivers/net/xlp_nae/init_nae.c
 create mode 100644 drivers/net/xlp_nae/net_common.h
 create mode 100644 drivers/net/xlp_nae/reg.h
 create mode 100644 drivers/net/xlp_nae/ucore_apps.c
 create mode 100644 drivers/net/xlp_nae/ucore_loader.c
 create mode 100644 drivers/net/xlp_nae/ucore_loader.h
 create mode 100644 drivers/net/xlp_nae/xlp_hw.c
 create mode 100644 drivers/net/xlp_nae/xlp_nae.c
 create mode 100644 drivers/net/xlp_nae/xlp_nae.h

diff --git a/arch/mips/Makefile b/arch/mips/Makefile
index 1827292..0de78a2 100644
--- a/arch/mips/Makefile
+++ b/arch/mips/Makefile
@@ -42,10 +42,6 @@ tool-archpref		= $(64bit-tool-archpref)
 UTS_MACHINE		:= mips64
 endif
 
-ifdef CONFIG_CROSSCOMPILE
-CROSS_COMPILE		:= $(tool-archpref)
-endif
-
 ifneq ($(SUBARCH),$(ARCH))
   ifeq ($(CROSS_COMPILE),)
     CROSS_COMPILE := $(call cc-cross-prefix, $(tool-archpref)-linux-  $(tool-archpref)-linux-gnu-  $(tool-archpref)-unknown-linux-gnu-)
@@ -167,8 +163,6 @@ endif
 cflags-$(CONFIG_CAVIUM_CN63XXP1) += -Wa,-mfix-cn63xxp1
 cflags-$(CONFIG_CPU_BMIPS)	+= -march=mips32 -Wa,-mips32 -Wa,--trap
 
-cflags-$(CONFIG_CPU_XLR)    += $(call cc-option,-march=xlr) -Wa,--trap
-cflags-$(CONFIG_CPU_XLP)    += $(call cc-option,-march=xlp) -Wa,--trap
 cflags-$(CONFIG_CPU_R4000_WORKAROUNDS)	+= $(call cc-option,-mfix-r4000,)
 cflags-$(CONFIG_CPU_R4400_WORKAROUNDS)	+= $(call cc-option,-mfix-r4400,)
 cflags-$(CONFIG_CPU_DADDI_WORKAROUNDS)	+= $(call cc-option,-mno-daddi,)
@@ -200,42 +194,26 @@ endif
 #
 # Board-dependent options and extra files
 #
-include $(srctree)/arch/mips/Kbuild.platforms
-
 #
-# RMI SOC Common (phoenix)
-core-$(CONFIG_RMI_PHOENIX)      	+= arch/mips/rmi/phoenix/
-core-$(CONFIG_RMI_PHOENIX) 		+= arch/mips/rmi/mm/
-cflags-$(CONFIG_RMI_PHOENIX)    	+= -DXLS -I$(srctree)/arch/mips/include/asm/mach-rmi
-cflags-$(CONFIG_RMI_PHOENIX)    	+= -I$(srctree)/arch/mips/include/asm/rmi
-
-core-$(CONFIG_XEN)			+= arch/mips/xen/
+# NETLOGIC SOC Common (common)
+core-$(CONFIG_NLM_COMMON)      	+= arch/mips/netlogic/common/
+cflags-$(CONFIG_NLM_COMMON)    	+= -DXLS -I$(srctree)/arch/mips/include/asm/mach-netlogic
+cflags-$(CONFIG_NLM_COMMON)    	+= -I$(srctree)/arch/mips/include/asm/netlogic
 
-#
-# RMI XLR/XLS SoC, Simulator and boards
-#
-core-$(CONFIG_RMI_XLR)      		+= arch/mips/rmi/xlr/
-core-$(CONFIG_RMI_PTR) 		+= arch/mips/rmi/ptr/
-cflags-$(CONFIG_CRYPTO_XLR)		+= -Idrivers/crypto/rmi/common
-cflags-$(CONFIG_RMI_XLR)    		+= -DRMI_BRIDGE_WKAROUND
+core-$(CONFIG_NLM_XLP) 		+= arch/mips/netlogic/xlp/
+cflags-$(CONFIG_NLM_XLP_SIM)        	+= -DXLP_SIM=1
+cflags-$(CONFIG_NLM_XLP)    		+= -DXLS -I$(srctree)/arch/mips/include/asm/netlogic/hal
 # This address is now configured via kernel configuration file
-load-$(CONFIG_RMI_PTR)          	+= $(CONFIG_RMI_PHOENIX_LOAD_ADDRESS)
+load-$(CONFIG_NLM_XLP_SIM)      += $(CONFIG_NLM_COMMON_LOAD_ADDRESS)
 
-#
-# RMI XLP Soc, Simulator and boards
-#
-core-$(CONFIG_RMI_XLP) 		+= arch/mips/rmi/xlp/
-core-$(CONFIG_RMI_XLP_SIM)          	+= arch/mips/rmi/ptr/
-cflags-$(CONFIG_RMI_XLP_SIM)        	+= -DXLP_SIM=1
-cflags-$(CONFIG_RMI_XLP)    		+= -DXLS -I$(srctree)/arch/mips/include/asm/rmi/xlp_common/
-# This address is now configured via kernel configuration file
-load-$(CONFIG_RMI_XLP_SIM)      += $(CONFIG_RMI_PHOENIX_LOAD_ADDRESS)
+include $(srctree)/arch/mips/Kbuild.platforms
 
 #
-# Generic MIPS headers
+# NETLOGIC XLP Soc, Simulator and boards
 #
-cflags-y                        += -I$(srctree)/arch/mips/include/asm/mach-generic
+cflags-$(CONFIG_NLM_XLP)	+= -DXLP
 
+cflags-y			+= -I$(srctree)/arch/mips/include/asm/mach-generic
 drivers-$(CONFIG_PCI)		+= arch/mips/pci/
 
 #
@@ -267,12 +245,6 @@ KBUILD_CPPFLAGS += -D"DATAOFFSET=$(if $(dataoffset-y),$(dataoffset-y),0)"
 
 LDFLAGS			+= -m $(ld-emul)
 
-ifdef CONFIG_CPU_LITTLE_ENDIAN
-AFLAGS += -EL
-CFLAGS += -EL
-LDFLAGS += -EL
-endif
-
 ifdef CONFIG_MIPS
 CHECKFLAGS += $(shell $(CC) $(KBUILD_CFLAGS) -dM -E -x c /dev/null | \
 	egrep -vw '__GNUC_(|MINOR_|PATCHLEVEL_)_' | \
@@ -288,23 +260,9 @@ ifdef CONFIG_MAPPED_KERNEL
 PHYS_LOAD_ADDRESS = -D"PHYSADDR=$(CONFIG_PHYS_LOAD_ADDRESS)"
 endif
 
-#
-# Choosing incompatible machines durings configuration will result in
-# error messages during linking.  Select a default linkscript if
-# none has been choosen above.
-#
-
-
-CPPFLAGS_vmlinux.lds := \
-	$(CFLAGS) \
-	-D"LOADADDR=$(load-y)" $(PHYS_LOAD_ADDRESS) \
-	-D"JIFFIES=$(JIFFIES)" \
-	-D"DATAOFFSET=$(if $(dataoffset-y),$(dataoffset-y),0)"
-
 ifdef CONFIG_MAPPED_KERNEL
 KBUILD_CFLAGS += -D"LOADADDR=$(load-y)" $(PHYS_LOAD_ADDRESS)
 endif
-
 head-y := arch/mips/kernel/head.o arch/mips/kernel/init_task.o
 
 libs-y			+= arch/mips/lib/
diff --git a/arch/mips/include/asm/atomic.h b/arch/mips/include/asm/atomic.h
index c387c16..6943da9 100644
--- a/arch/mips/include/asm/atomic.h
+++ b/arch/mips/include/asm/atomic.h
@@ -49,7 +49,7 @@
  */
 static __inline__ void atomic_add(int i, atomic_t * v)
 {
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 	ldadd_w_no_read(i, &v->counter);
 #else
 	if (kernel_uses_llsc && R10000_LLSC_WAR) {
@@ -96,7 +96,7 @@ static __inline__ void atomic_add(int i, atomic_t * v)
  */
 static __inline__ void atomic_sub(int i, atomic_t * v)
 {
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 	ldadd_w_no_read(-i,&v->counter);
 #else
 	if (kernel_uses_llsc && R10000_LLSC_WAR) {
@@ -143,7 +143,7 @@ static __inline__ int atomic_add_return(int i, atomic_t * v)
 
 	smp_mb__before_llsc();
 
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 	result = ldadd_w(i, &v->counter);
 	result += i;
 #else
@@ -199,7 +199,7 @@ static __inline__ int atomic_sub_return(int i, atomic_t * v)
 
 	smp_mb__before_llsc();
 
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 	result = ldadd_w(-i, &v->counter);
 	result -= i;
 #else
diff --git a/arch/mips/include/asm/bootinfo.h b/arch/mips/include/asm/bootinfo.h
index 0014011..ced7afd 100644
--- a/arch/mips/include/asm/bootinfo.h
+++ b/arch/mips/include/asm/bootinfo.h
@@ -1,14 +1,10 @@
-/************************************************************************
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
 
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI: 
-
-  *****************************#RMI_1#************************************/
+*****************************#NETL_1#********************************/
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file COPYING in the main directory of this archive
@@ -91,7 +87,7 @@
 #define  MACH_INGENIC_JZ4730	0	/* JZ4730 SOC		*/
 #define  MACH_INGENIC_JZ4740	1	/* JZ4740 SOC		*/
 
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 #define CL_SIZE			(2048)
 #else
 #define CL_SIZE			COMMAND_LINE_SIZE
diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
index 541b6f5..662a599 100644
--- a/arch/mips/include/asm/cacheflush.h
+++ b/arch/mips/include/asm/cacheflush.h
@@ -1,14 +1,10 @@
-/************************************************************************
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
 
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI: 
-
-  *****************************#RMI_1#************************************/
+*****************************#NETL_1#********************************/
 
 /*
  * This file is subject to the terms and conditions of the GNU General Public
@@ -53,12 +49,13 @@ extern void __flush_dcache_page(struct page *page);
 #define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1
 static inline void flush_dcache_page(struct page *page)
 {
-#ifdef CONFIG_RMI_PHOENIX
-	extern void phoenix_flush_dcache_page(struct page *page);
-	phoenix_flush_dcache_page(page);
+#ifdef CONFIG_NLM_COMMON
+	extern void nlm_common_flush_dcache_page(struct page *page);
+	nlm_common_flush_dcache_page(page);
 #else
 	if (cpu_has_dc_aliases || !cpu_has_ic_fills_f_dc)
 		__flush_dcache_page(page);
+
 #endif
 }
 
@@ -123,10 +120,6 @@ extern void (*flush_data_cache_page)(unsigned long addr);
 	set_bit(PG_dcache_dirty, &(page)->flags)
 #define ClearPageDcacheDirty(page)	\
 	clear_bit(PG_dcache_dirty, &(page)->flags)
-#ifdef CONFIG_RMI_PHOENIX
-#define TestPageDcacheDirty(page)	\
-	test_bit(PG_dcache_dirty, &(page)->flags)
-#endif
 
 /* Run kernel code uncached, useful for cache probing functions. */
 unsigned long run_uncached(void *func);
diff --git a/arch/mips/include/asm/dma.h b/arch/mips/include/asm/dma.h
index f482a6a..976a5f8 100644
--- a/arch/mips/include/asm/dma.h
+++ b/arch/mips/include/asm/dma.h
@@ -87,7 +87,7 @@
 /* don't care; ISA bus master won't work, ISA slave DMA supports 32bit addr */
 #define MAX_DMA_ADDRESS		PAGE_OFFSET
 #else
-#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+#if defined(CONFIG_NLM_COMMON) && defined(CONFIG_64BIT)
 #define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x80000000)
 #else
 #define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x01000000)
diff --git a/arch/mips/include/asm/mach-netlogic/kernel-entry-init.h b/arch/mips/include/asm/mach-netlogic/kernel-entry-init.h
new file mode 100644
index 0000000..9401f91
--- /dev/null
+++ b/arch/mips/include/asm/mach-netlogic/kernel-entry-init.h
@@ -0,0 +1,57 @@
+#ifndef __ASM_MACH_NLM_KERNEL_ENTRY_H
+#define __ASM_MACH_NLM_KERNEL_ENTRY_H
+
+/* XLP_MERGE_TODO */
+#if !defined(CKSSEG)
+#define CKSSEG			0xffffffffc0000000
+#endif
+
+#ifdef CONFIG_64BIT
+#define LA dla
+#define MTC0 dmtc0
+#define SW sd
+#else
+#define LA la
+#define MTC0 mtc0
+#define SW sw
+#endif
+
+#ifdef CONFIG_CPU_XLP
+#define JRHB jr.hb 
+#define EHB ehb
+#else
+#define JRHB jr
+#define EHB 
+#endif
+
+	/*
+	 * inputs are the text nasid in t1, data nasid in t2.
+	 */
+	.macro MAPPED_KERNEL_SETUP_TLB
+#ifdef CONFIG_MAPPED_KERNEL
+	/*
+	 * Drop in 0xffffffffc0000000 in tlbhi, 0+VG in tlblo_0,
+	 * 0+DVG in tlblo_1.
+	 */
+	dli	    t3, CKSSEG
+	dmtc0	t3, CP0_ENTRYHI
+	li      t1, 0x1f
+	MTC0	t1, CP0_ENTRYLO0	# physaddr, VG, cach exlwr
+	li	    t2, 0x1
+	MTC0	t2, CP0_ENTRYLO1	# physaddr, DVG, cach exlwr
+	li	    t1, 0x1fffe000		# MAPPED_KERN_TLBMASK, TLBPGMASK_256M
+	mtc0	t1, CP0_PAGEMASK
+    mtc0    zero, CP0_INDEX
+	tlbwi
+	li      t0, 1
+    mtc0	t0, CP0_WIRED
+	EHB
+    LA      v0, mapped_space
+	JRHB    v0
+mapped_space:
+#else
+	mtc0	zero, CP0_WIRED
+#endif
+	.endm
+
+#endif /* __ASM_MACH_NLM_KERNEL_ENTRY_H */
diff --git a/arch/mips/include/asm/mach-netlogic/mmu.h b/arch/mips/include/asm/mach-netlogic/mmu.h
new file mode 100644
index 0000000..92aace3
--- /dev/null
+++ b/arch/mips/include/asm/mach-netlogic/mmu.h
@@ -0,0 +1,64 @@
+#ifndef _ASM_MACH_NLM_MMU_H
+#define _ASM_MACH_NLM_MMU_H
+
+#include <linux/smp.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/page.h>
+#include <asm/pgtable-bits.h>
+
+#ifdef CONFIG_NLM_XLP
+#include <asm/mach-netlogic/xlp-mmu.h>
+#endif
+
+#define ENTRYLO_PFN_SHIFT 6
+
+#ifndef __ASSEMBLY__
+
+#define SMALLEST_TLBPAGE_SZ (4UL << 10)
+#define LARGEST_TLBPAGE_SZ  (256UL << 20)
+
+#define TRUE 1
+#define FALSE 0
+
+typedef struct
+{
+	unsigned long vaddr;
+	uint64_t paddr0;
+	uint64_t paddr1;
+	uint32_t pagesize;
+	uint32_t attr0;
+	uint32_t attr1;
+	int wired;
+} tlb_info_t;
+
+#ifdef CONFIG_MAPPED_KERNEL
+extern unsigned long __vmalloc_start;
+#endif
+extern unsigned long long nlm_common_tlb_stats[];
+
+extern void mmu_init(void);
+extern void setup_tlb(tlb_info_t *tlb);
+
+/*
+ * the following needs an used argument to confirm to the 
+ * prototype of functions passed to on_each_cpu()
+ */
+static inline void nlm_update_tlb_stats(void *arg)
+{
+	nlm_common_tlb_stats[smp_processor_id()] = nlm_read_os_scratch_2();
+}
+
+#define tlbstats_init() nlm_write_os_scratch_2(0ULL)
+
+#ifdef CONFIG_HUGETLBFS
+#define entrylo0_mask_init() \
+nlm_write_os_scratch_3(~(((1ULL << HUGETLB_PAGE_ORDER) - 1) << ENTRYLO_PFN_SHIFT))
+#else
+#define entrylo0_mask_init()
+#endif
+
+extern void setup_mapped_kernel_tlbs(int index, int secondary_cpu);
+extern unsigned long recalculate_max_low_pfn(unsigned long max_low_pfn);
+
+#endif /* __ASSEMBLY__ */
+#endif
diff --git a/arch/mips/include/asm/mach-netlogic/pgtable-xlp.h b/arch/mips/include/asm/mach-netlogic/pgtable-xlp.h
new file mode 100644
index 0000000..4ab8fec
--- /dev/null
+++ b/arch/mips/include/asm/mach-netlogic/pgtable-xlp.h
@@ -0,0 +1,59 @@
+#ifndef _ASM_MACH_NLM_PGTABLE_BITS_XLP_H
+#define _ASM_MACH_NLM_PGTABLE_BITS_XLP_H
+
+#define PAGE_NONE        __pgprot(_PAGE_PRESENT | \
+                                  _PAGE_RI | _PAGE_XI | \
+                                  _CACHE_CACHABLE_NONCOHERENT)
+#define PAGE_READONLY    __pgprot(_PAGE_PRESENT | _PAGE_READ | \
+                                  _PAGE_XI | \
+                                   PAGE_CACHABLE_DEFAULT)
+#define PAGE_WRITEONLY   __pgprot(_PAGE_PRESENT | _PAGE_READ | _PAGE_WRITE | \
+                                  _PAGE_RI | _PAGE_XI | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_WRITE_READ  __pgprot(_PAGE_PRESENT | _PAGE_READ | _PAGE_WRITE | \
+                                  _PAGE_XI | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_EXECONLY    __pgprot(_PAGE_PRESENT | _PAGE_READ | \
+                                  _PAGE_RI | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_EXEC_READ   __pgprot(_PAGE_PRESENT | _PAGE_READ | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_EXEC_WRITE  __pgprot(_PAGE_PRESENT | _PAGE_READ | _PAGE_WRITE | \
+                                  _PAGE_RI | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_ALL         __pgprot(_PAGE_PRESENT | _PAGE_READ | _PAGE_WRITE | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_COPY        __pgprot(_PAGE_PRESENT | _PAGE_READ | \
+                                  _PAGE_RI | _PAGE_XI | \
+                                   PAGE_CACHABLE_DEFAULT)
+
+#define PAGE_COPY_READ      PAGE_READONLY
+#define PAGE_EXEC_COPY      PAGE_EXECONLY
+#define PAGE_EXEC_COPY_READ PAGE_EXEC_READ
+
+/*
+ * FIXME: What do we do with kernel pages ? These are primarily 
+ *        used for modules.
+ */
+#define PAGE_KERNEL	__pgprot(_PAGE_PRESENT | __READABLE | __WRITEABLE | \
+			_PAGE_GLOBAL | PAGE_CACHABLE_DEFAULT)
+
+#define __P000	PAGE_NONE
+#define __P001	PAGE_READONLY
+#define __P010	PAGE_COPY
+#define __P011	PAGE_COPY_READ
+#define __P100	PAGE_EXECONLY
+#define __P101	PAGE_EXEC_READ
+#define __P110	PAGE_EXEC_COPY
+#define __P111	PAGE_EXEC_COPY_READ
+
+#define __S000	PAGE_NONE
+#define __S001	PAGE_READONLY
+#define __S010	PAGE_WRITEONLY
+#define __S011	PAGE_WRITE_READ
+#define __S100	PAGE_EXECONLY
+#define __S101	PAGE_EXEC_READ
+#define __S110	PAGE_EXEC_WRITE
+#define __S111	PAGE_ALL
+
+#endif
diff --git a/arch/mips/include/asm/mach-netlogic/pgwalker.h b/arch/mips/include/asm/mach-netlogic/pgwalker.h
new file mode 100644
index 0000000..8c3fb60
--- /dev/null
+++ b/arch/mips/include/asm/mach-netlogic/pgwalker.h
@@ -0,0 +1,36 @@
+#ifndef _ASM_MACH_NLM_PGWALKER_H
+#define _ASM_MACH_NLM_PGWALKER_H
+
+#include <linux/percpu.h>
+
+#define PGW_REGS_BLOCK 4
+
+enum {
+	PGW_MMU_INFO = 0x10,
+	PGW_PGD_BASES,
+	PGW_PGD_SHIFT,
+	PGW_PGD_MASK,
+	PGW_PUD_SHIFT,
+	PGW_PUD_MASK,
+	PGW_PMD_SHIFT,
+	PGW_PMD_MASK,
+	PGW_PTE_SHIFT,
+	PGW_PTE_MASK
+};
+
+#define PGD 0x8
+#define PUD 0x4
+#define PMD 0x2
+#define PTE 0x1
+
+#define pgw_register_write_w(reg, value) write_32bit_nlm_ctrl_reg(PGW_REGS_BLOCK, reg, value)
+#define pgw_register_write_d(reg, value) write_64bit_nlm_ctrl_reg(PGW_REGS_BLOCK, reg, value)
+#define pgw_register_read_w(reg) read_32bit_nlm_ctrl_reg(PGW_REGS_BLOCK, reg)
+#define pgw_register_read_d(reg) read_64bit_nlm_ctrl_reg(PGW_REGS_BLOCK, reg)
+
+#define pgw_print_w(reg) printk(KERN_INFO #reg " = 0x%x\n", pgw_register_read_w(reg))
+
+extern void pgwalker_init(void);
+extern void dump_pgwalker_config(void);
+
+#endif
diff --git a/arch/mips/include/asm/mach-netlogic/xlp-mmu.h b/arch/mips/include/asm/mach-netlogic/xlp-mmu.h
new file mode 100644
index 0000000..1589b9a
--- /dev/null
+++ b/arch/mips/include/asm/mach-netlogic/xlp-mmu.h
@@ -0,0 +1,35 @@
+#ifndef _ASM_MACH_NLM_XLP_MMU_H
+#define _ASM_MACH_NLM_XLP_MMU_H
+
+#include <linux/percpu.h>
+
+/* 
+ * These numbers correspond to Cop0 Config6 reg 
+ * bit positions 
+ */
+#define ENABLE_ETLB        0x4
+#define ENABLE_128_TLB     0x20
+#define ENABLE_PGWALKER    0x8
+
+#define USER_SEG 0
+
+#ifdef CONFIG_64BIT
+#define NR_ADDR_SEGMENTS 8  /* MUST be a power of 2 */
+#define MODULE_SEG 7
+#define VMALLOC_SEG 6
+#else /* CONFIG_32BIT */
+#define NR_ADDR_SEGMENTS 2 /* MUST be a power of 2 */
+#define VMALLOC_SEG 1
+#endif /* CONFIG_64BIT */
+
+extern DEFINE_PER_CPU(unsigned long [NR_ADDR_SEGMENTS], pgd_bases);
+
+static inline void setup_user_pgd(pgd_t *pgd)
+{
+	if (read_c0_config6() & ENABLE_PGWALKER) {
+		get_cpu_var(pgd_bases)[USER_SEG] = (unsigned long) pgd;
+		put_cpu_var(pgd_bases);
+	}
+};
+
+#endif
diff --git a/arch/mips/include/asm/mmu_context.h b/arch/mips/include/asm/mmu_context.h
index 9482ac4..ec8677f 100644
--- a/arch/mips/include/asm/mmu_context.h
+++ b/arch/mips/include/asm/mmu_context.h
@@ -1,15 +1,3 @@
-/************************************************************************
-
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI:
-
- *****************************#RMI_1#************************************/
-
 /*
  * Switch a MMU context.
  *
@@ -36,6 +24,16 @@
 #endif /* SMTC */
 #include <asm-generic/mm_hooks.h>
 
+#ifdef CONFIG_NLM_COMMON
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/debug.h>
+#include <asm/mach-netlogic/mmu.h>
+#endif
+
+#ifndef CONFIG_NLM_XLP
+static inline void setup_user_pgd(pgd_t *pgd) { }
+#endif
+
 #ifdef CONFIG_MIPS_PGD_C0_CONTEXT
 
 #define TLBMISS_HANDLER_SETUP_PGD(pgd)				\
@@ -51,12 +49,6 @@ extern void tlbmiss_handler_setup_pgd(unsigned long pgd);
 
 #else /* CONFIG_MIPS_PGD_C0_CONTEXT: using  pgd_current*/
 
-#ifdef CONFIG_RMI_PHOENIX
-#include <asm/rmi/mips-exts.h>
-#include <asm/rmi/debug.h>
-#include <asm/mach-rmi/mmu.h>
-#endif
-
 /*
  * For the fast tlb miss handlers, we keep a per cpu array of pointers
  * to the current pgd for each processor. Also, the proc. id is stuffed
@@ -105,10 +97,10 @@ extern unsigned long smtc_asid_mask;
 /* End SMTC/34K debug hack */
 #else /* FIXME: not correct for R6000 */
 
-#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+#ifdef CONFIG_NLMCOMMON_GLOBAL_TLB_SPLIT_ASID
 #define ASID_INC    0x1
-extern unsigned long rmi_asid_mask;
-#define ASID_MASK   rmi_asid_mask
+extern unsigned long nlm_asid_mask;
+#define ASID_MASK   nlm_asid_mask
 #else
 
 #define ASID_INC	0x1
@@ -216,6 +208,7 @@ static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,
 	write_c0_entryhi(cpu_asid(cpu, next));
 #endif /* CONFIG_MIPS_MT_SMTC */
 	TLBMISS_HANDLER_SETUP_PGD(next->pgd);
+	setup_user_pgd(next->pgd);
 
 	/*
 	 * Mark current->active_mm as not "active" anymore.
@@ -275,7 +268,9 @@ activate_mm(struct mm_struct *prev, struct mm_struct *next)
 #else
 	write_c0_entryhi(cpu_asid(cpu, next));
 #endif /* CONFIG_MIPS_MT_SMTC */
+
 	TLBMISS_HANDLER_SETUP_PGD(next->pgd);
+	setup_user_pgd(next->pgd);
 
 	/* mark mmu ownership change */
 	cpumask_clear_cpu(cpu, mm_cpumask(prev));
diff --git a/arch/mips/include/asm/msi.h b/arch/mips/include/asm/msi.h
index 06dec3f..fdd2794 100644
--- a/arch/mips/include/asm/msi.h
+++ b/arch/mips/include/asm/msi.h
@@ -1,14 +1,10 @@
-/************************************************************************
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
 
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI: Defines for MSI support for RMI Eval Board
-
-  *****************************#RMI_1#************************************/
+*****************************#NETL_1#********************************/
 
 /*
  * Copyright (C) 2003-2004 Intel
diff --git a/arch/mips/include/asm/netlogic/64bit.h b/arch/mips/include/asm/netlogic/64bit.h
new file mode 100644
index 0000000..1aae6f6
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/64bit.h
@@ -0,0 +1,73 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_NLM_64BIT_H
+#define _ASM_NLM_64BIT_H
+
+#include <linux/types.h>
+
+/* Implement 64bit read and write operations */
+
+static inline void out64(u64 val, unsigned long addr)
+{
+  u32 low, high, tmp;
+
+  high = val >> 32;
+  low = val & 0xffffffff;
+  __asm__ __volatile__ (
+			".set push\t\t\t# out64n"
+			".set noreorder\n"
+			".set noat\n"
+			".set mips4\n"
+			"   dsll32 %0, %2, 0   \n"
+			"   dsll32 $1, %1, 0   \n"
+			"   dsrl32 %0, %0, 0   \n"
+			"   or     $1, $1, %0  \n"
+			"   sd $1, (%3)\n"
+			".set pop\n"
+			: "=&r" (tmp)
+			: "r" (high), "r" (low), "r" (addr));
+}
+
+static inline u64 in64(unsigned long addr)
+{
+  u32 low, high;
+
+  __asm__ __volatile__ (
+			".set push\t\t\t# in64\n"
+			".set noreorder\n"
+			".set noat     \n"
+			".set mips4    \n"
+			"  ld     %1, (%2)\n"
+			"  dsra32 %0, %1, 0\n"
+			"  sll    %1, %1, 0\n"
+			".set pop\n"
+			: "=r" (high), "=r" (low)
+			: "r" (addr));
+
+  return (((u64)high) << 32) | low;
+}
+
+#endif 
diff --git a/arch/mips/include/asm/netlogic/debug.h b/arch/mips/include/asm/netlogic/debug.h
new file mode 100644
index 0000000..20b6d78
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/debug.h
@@ -0,0 +1,112 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_NLM_DEBUG_H
+#define _ASM_NLM_DEBUG_H
+
+/*Enable below macro to enable net stats. */
+//#define CONFIG_NLM_STATS
+extern void prom_printf(char *fmt, ...);
+#include <linux/threads.h>
+#include <asm/atomic.h>
+
+enum {
+  //cacheline 0
+  MSGRNG_INT,
+  MSGRNG_PIC_INT,
+  MSGRNG_MSG,
+  MSGRNG_EXIT_STATUS,
+  MSGRNG_MSG_CYCLES,
+  //cacheline 1
+  NETIF_TX = 8,
+  NETIF_RX,
+  NETIF_TX_COMPLETE,
+  NETIF_TX_COMPLETE_TX,
+  NETIF_RX_CYCLES,
+  NETIF_TX_COMPLETE_CYCLES,
+  NETIF_TX_CYCLES,
+  NETIF_TIMER_START_Q,
+  //NETIF_REG_FRIN,
+  //NETIF_INT_REG,
+  //cacheline 2
+  REPLENISH_ENTER = 16,
+  REPLENISH_ENTER_COUNT,
+  REPLENISH_CPU,
+  REPLENISH_FRIN,
+  REPLENISH_CYCLES,
+  NETIF_STACK_TX,
+  NETIF_START_Q,
+  NETIF_STOP_Q,
+  //cacheline 3
+  USER_MAC_START = 24,
+  USER_MAC_INT   = 24,
+  USER_MAC_TX_COMPLETE,
+  USER_MAC_RX,
+  USER_MAC_POLL,
+  USER_MAC_TX,
+  USER_MAC_TX_FAIL,
+  USER_MAC_TX_COUNT,
+  USER_MAC_FRIN,
+  //cacheline 4
+  USER_MAC_TX_FAIL_GMAC_CREDITS = 32,
+  USER_MAC_DO_PAGE_FAULT,
+  USER_MAC_UPDATE_TLB,
+  USER_MAC_UPDATE_TLB_PFN0,
+  USER_MAC_UPDATE_TLB_PFN1,
+  
+  NLM_MAX_COUNTERS = 40
+};
+extern atomic_t nlm_common_counters[NR_CPUS][NLM_MAX_COUNTERS];
+extern __u32 msgrng_msg_cycles;
+
+#ifdef CONFIG_NLM_STATS 
+#define xlr_inc_counter(x) atomic_inc(&nlm_common_counters[0][(x)])
+#define nlm_common_dec_counter(x) atomic_dec(&nlm_common_counters[0][(x)])
+#define xlr_set_counter(x, value) atomic_set(&nlm_common_counters[0][(x)], (value))
+#define nlm_common_get_counter(x) atomic_read(&nlm_common_counters[0][(x)])
+#else
+#define xlr_inc_counter(x) //atomic_inc(&nlm_common_counters[0][(x)])
+#define nlm_common_dec_counter(x) //atomic_dec(&nlm_common_counters[0][(x)])
+#define xlr_set_counter(x, value) //atomic_set(&nlm_common_counters[0][(x)], (value))
+#define nlm_common_get_counter(x) //atomic_read(&nlm_common_counters[0][(x)])
+#endif
+#if 0
+#define dbg_msg(fmt, args...) printk("[%s@%d|%s]: cpu_%d: " fmt, \
+                               __FILE__, __LINE__, __FUNCTION__,  smp_processor_id(), ##args)
+
+#define dbg_panic(fmt, args...) panic("[%s@%d|:%s]: cpu_%d: " fmt, \
+                               __FILE__, __LINE__, __FUNCTION__, smp_processor_id(), ##args)
+
+#define prom_dbg_msg(fmt, args...) prom_printf("[%s@%d|%s]: cpu_%d: " fmt, \
+                               __FILE__, __LINE__, __FUNCTION__,  smp_processor_id(), ##args)
+#else
+#define dbg_msg(fmt, args...)
+
+#define dbg_panic(fmt, args...) panic(fmt, ##args)
+
+#define prom_dbg_msg(fmt, args...) printk(fmt, ##args)
+#endif
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/gpio.h b/arch/mips/include/asm/netlogic/gpio.h
new file mode 100644
index 0000000..40e63c0
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/gpio.h
@@ -0,0 +1,72 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_NLM_GPIO_H
+#define _ASM_NLM_GPIO_H
+
+#include <asm/netlogic/iomap.h>
+
+#define NETLOGIC_GPIO_INT_EN_REG 0
+#define NETLOGIC_GPIO_INPUT_INVERSION_REG 1
+#define NETLOGIC_GPIO_IO_DIR_REG 2
+#define NETLOGIC_GPIO_IO_DATA_WR_REG 3
+#define NETLOGIC_GPIO_IO_DATA_RD_REG 4
+
+#define NETLOGIC_GPIO_SWRESET_REG 8
+
+#define NETLOGIC_GPIO_DRAM1_CNTRL_REG 9
+#define NETLOGIC_GPIO_DRAM1_RATIO_REG 10
+#define NETLOGIC_GPIO_DRAM1_RESET_REG 11
+#define NETLOGIC_GPIO_DRAM1_STATUS_REG 12
+
+#define NETLOGIC_GPIO_DRAM2_CNTRL_REG 13
+#define NETLOGIC_GPIO_DRAM2_RATIO_REG 14
+#define NETLOGIC_GPIO_DRAM2_RESET_REG 15
+#define NETLOGIC_GPIO_DRAM2_STATUS_REG 16
+
+#define NETLOGIC_GPIO_PWRON_RESET_CFG_REG 21
+
+#define NETLOGIC_GPIO_BIST_ALL_GO_STATUS_REG 24
+#define NETLOGIC_GPIO_BIST_CPU_GO_STATUS_REG 25
+#define NETLOGIC_GPIO_BIST_DEV_GO_STATUS_REG 26
+
+#define NETLOGIC_GPIO_FUSE_BANK_REG 35
+
+#define NETLOGIC_GPIO_CPU_RESET_REG 40
+
+#define NETLOGIC_GPIO_RNG_REG 43
+
+#define NETLOGIC_PWRON_RESET_PCMCIA_BOOT 17
+
+#define NETLOGIC_GPIO_LED_BITMAP 0x1700000
+#define NETLOGIC_GPIO_LED_0_SHIFT 20
+#define NETLOGIC_GPIO_LED_1_SHIFT 24
+
+#define NETLOGIC_GPIO_LED_OUTPUT_CODE_RESET 0x01
+#define NETLOGIC_GPIO_LED_OUTPUT_CODE_HARD_RESET 0x02
+#define NETLOGIC_GPIO_LED_OUTPUT_CODE_SOFT_RESET 0x03
+#define NETLOGIC_GPIO_LED_OUTPUT_CODE_MAIN 0x04
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal.h b/arch/mips/include/asm/netlogic/hal/nlm_hal.h
new file mode 100644
index 0000000..642fb7d
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal.h
@@ -0,0 +1,176 @@
+
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * http://www.gnu.org/licenses/gpl-2.0.txt  
+ * or the Broadcom license below:
+
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_4# */
+
+#ifndef _NLM_HAL_H_
+#define _NLM_HAL_H_
+
+#include "nlm_hal_macros.h"
+#include "nlm_hal_xlp_dev.h"
+#include "nlm_nae.h"
+#ifndef __ASSEMBLY__
+
+#include "nlm_hal_sys.h"
+
+struct nlm_netl_proc_info{
+	unsigned int proc_id;
+	unsigned int chipid;		/*example: 832, 316 etc */
+	unsigned int revision;
+	char cpu_info_str[32];
+};
+
+struct nlm_hal_mii_info{
+       uint32_t speed;
+       uint32_t duplex;
+       int link_stat;
+       int phyaddr;
+};
+/**
+* @brief Used by function ::get_phy_info and various internal PHY manufacturer-specific functions.
+* @ingroup hal
+*/
+struct nlm_hal_ext_phy{
+        char name[16];
+        uint32_t phy_idfer;
+        uint32_t ext_mdio_bus;
+        int inf;
+        int phy_addr;
+	int (*phy_get_status)(struct nlm_hal_ext_phy* ext_phy, struct nlm_hal_mii_info *mii_info, int node);
+        void (*start_phy_an)(struct nlm_hal_ext_phy* ext_phy, int node);
+        void (*ext_phy_init)(struct nlm_hal_ext_phy* ext_phy, int node);
+        /*(void) (*dump_regs)(void); */
+};
+extern void nlm_hal_init(void);
+
+extern unsigned long long nlm_hal_cpu_freq(void);
+extern int naecfg_hack;
+
+extern int nlm_hal_is_xlp_a0(void);
+extern int nlm_hal_is_xlp_le(void);
+extern void nlm_hal_xlp_pcie_rc_init(void);
+
+extern void nlm_hal_cpld_init(int node);
+/* #define SKIP_INTERFACE_TYPE_FROMCPLD 1 */
+extern int nlm_get_interface_type(int node, int slot);
+extern int is_ilk_card_onslot(int);
+extern int is_xlp_evp1(void);
+extern int is_xlp_evp2(void);
+extern int nlm_xlp_boardver(void);
+extern int nlm_xlp_cpldver(void);
+extern void sgmii_scan_phys(int node);
+
+#ifndef NLM_HAL_LINUX_KERNEL
+extern void enable_cpus(unsigned int node, unsigned long thread_bitmask, unsigned long park_func);
+#endif /* #ifndef NLM_HAL_LINUX_KERNEL */
+
+#ifdef NLM_HAL_XLOADER
+#define nlm_hal_read_16bit_reg(base, index)	(uint16_t)(nlh_read_cfg_reg16(base + (index << 1)))
+#define nlm_hal_write_16bit_reg(base, index, val)	(nlh_write_cfg_reg16(base +  (index << 1) , val))
+#define nlm_hal_read_32bit_reg(base, index)	(uint32_t)(nlh_read_cfg_reg32(base + (index << 2)))
+#define nlm_hal_write_32bit_reg(base, index, val)	(nlh_write_cfg_reg32(base +  (index << 2) , val))
+#define nlm_hal_read_64bit_reg(base, index) (uint64_t)(nlh_read_cfg_reg64(base + (index << 3)))
+#define nlm_hal_write_64bit_reg(base, index, val) 	(nlh_write_cfg_reg64(base +  (index << 3) , val))
+
+#else
+
+extern uint16_t nlm_hal_read_16bit_reg(uint64_t base, uint32_t index);
+extern void nlm_hal_write_16bit_reg(uint64_t base, uint32_t index, uint16_t val);
+extern uint32_t nlm_hal_read_32bit_reg(uint64_t base, int index);
+extern void nlm_hal_write_32bit_reg(uint64_t base, int index, uint32_t val);
+extern uint64_t nlm_hal_read_64bit_reg(uint64_t base, int index);
+extern void nlm_hal_write_64bit_reg(uint64_t base, int index, uint64_t val);
+
+#endif /*NLM_HAL_XLOADER*/
+
+extern void nlm_hal_cpld_write_16(int cs, uint16_t val, uint16_t reg);
+extern uint16_t nlm_hal_cpld_read_16(int cs, uint16_t reg);
+
+extern uint32_t efuse_cfg0(void);
+extern uint32_t efuse_cfg1(void);
+extern uint32_t efuse_cfg6(void);
+extern uint32_t get_proc_id(void);
+
+extern void nlm_hal_set_rsa_cge(int node, int enable);
+extern void nlm_hal_set_sae_engine_sel(int node);
+extern void nlm_hal_set_rsa_engine_sel(void);
+extern void nlm_hal_set_sae_freq(int node, int freq);
+extern int  nlm_hal_get_chip_feature(void);
+extern void nlm_hal_set_rsa_freq(int node, int freq);
+extern void nlm_hal_set_dtre_freq(int node, int freq);
+extern void nlm_hal_set_cde_freq(int node, int freq);
+extern void nlm_hal_get_crypto_vc_nums(int *vcbase, int *vclimit);
+extern void nlm_hal_get_rsa_vc_nums(int *vcbase, int *vclimit);
+
+#define nlh_read_dev_reg(dev, index) nlm_hal_read_32bit_reg(nlm_hal_get_dev_base(dev), index)
+#define nlh_write_dev_reg(dev, index, val) nlm_hal_write_32bit_reg(nlm_hal_get_dev_base(dev), index, val)
+
+extern uint64_t nlm_hal_get_dev_base(int node, int bus, int dev, int func);
+
+extern int nlm_hal_get_cpuinfo(struct nlm_netl_proc_info *);
+
+extern uint32_t get_dom_owner_mask(void *fdt, int dom_id, char *module);
+
+struct nlm_sae_init_param {
+	int node;
+	int freq;
+};
+
+struct nlm_rsa_init_param {
+	int node;
+	int freq;
+};
+
+extern int nlm_hal_is_ref_clk_133MHz(void);
+#define XLP_PIT_TICK_RATE       (nlm_hal_is_ref_clk_133MHz()?  133333333 : 66666666)
+
+extern int nlm_hal_get_fdt_freq(void *fdt, int type);
+/*
+TODO :
+  1. support Debug flags
+  2. XLP support ?
+ */
+
+static inline uint32_t get_xlp3xx_epid(void)
+{
+        uint32_t cfg0, epid;
+
+        cfg0=efuse_cfg0();
+        epid = (uint8_t)(( cfg0>>4 )  & 0xf);
+        return epid;
+}
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* #ifndef _NLM_HAL_H_ */
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_crypto.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_crypto.h
new file mode 100644
index 0000000..7a96261
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_crypto.h
@@ -0,0 +1,262 @@
+
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * http://www.gnu.org/licenses/gpl-2.0.txt  
+ * or the Broadcom license below:
+
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_4# */
+
+
+#ifndef _NLM_HAL_CRYPTO_H_
+#define _NLM_HAL_CRYPTO_H_
+
+#define shift_lower_bits(x, bitshift, numofbits) ((unsigned long long)(x) << (bitshift))
+
+#define shift_lower_bits_mask(x, bitshift, numofbits) (((unsigned long long)(x) & ((1ULL << (numofbits)) - 1)) << (bitshift))
+
+/**
+* @file_name nlm_hal_crypto.c
+*/
+
+/**
+* @defgroup crypto  Crypto HAL apis
+* @brief Description about the crypto HAL level apis for RSA/ECC and SAE engines
+*/
+
+/**
+* @brief Generate crypto rsa/ecc fmn message entry 0
+* @ingroup crypto
+* - l3alloc: 1 casuses source data to transit through l3 cache
+* - type: ecc prime/ecc bin/ me/ micorcode load
+* - func: point mul/add etc
+* - srcaddr : source address
+*/
+static inline unsigned long long nlm_crypto_form_rsa_ecc_fmn_entry0(unsigned int l3alloc, unsigned int type, 
+		unsigned int func, unsigned long long srcaddr)
+{
+	return shift_lower_bits(l3alloc, 61, 1) | 
+		shift_lower_bits(type, 46, 7) |
+		shift_lower_bits(func, 40, 6) |
+		shift_lower_bits(srcaddr, 0, 40);
+}
+
+/**
+* @brief Generate crypto rsa/ecc fmn message entry 1
+* @ingroup crypto
+* - dstclobber: 1 causes data to be written as 64byte cacheline
+* - l3alloc: 1 caused data written to the dram is also copied to l3 cache
+* - fbvc: freeback message vc
+* - dstaddr : destination address
+*/
+static inline unsigned long long nlm_crypto_form_rsa_ecc_fmn_entry1(unsigned int dstclobber, unsigned int l3alloc, 
+		unsigned int fbvc, unsigned long long dstaddr)
+{
+	return shift_lower_bits(dstclobber, 62, 1) |
+		shift_lower_bits(l3alloc, 61, 1) |
+		shift_lower_bits(fbvc, 40, 12) |
+		shift_lower_bits(dstaddr, 0, 40);
+}
+
+/**
+* @brief Generate crypto control descriptor
+* @ingroup crypto
+* - hmac : 1 for hash with hmac 
+* - hashalg: see hash_alg enums
+* - hashmode: see hash_mode enums
+* - cipherhalg: see  cipher_alg enums
+* - ciphermode: see  cipher_mode enums
+* - arc4_cipherkeylen : length of arc4 cipher key, 0 is interpreted as 32 
+* - arc4_keyinit : 
+* - cfbmask : cipher text for feedback, 
+*           0(1 bit), 1(2 bits), 2(4 bits), 3(8 bits), 4(16bits), 5(32 bits), 6(64 bits), 7(128 bits)
+*/
+static inline unsigned long long nlm_crypto_form_pkt_ctrl_desc(unsigned int hmac, 
+		unsigned int hashalg,  unsigned int hashmode,
+		unsigned int cipheralg, unsigned int ciphermode,
+		unsigned int arc4_cipherkeylen, unsigned int arc4_keyinit, unsigned int cfbmask)
+{
+	return shift_lower_bits(hmac, 61, 1) | 
+		shift_lower_bits(hashalg, 52, 8) | 
+		shift_lower_bits(hashmode, 43, 8) | 
+		shift_lower_bits(cipheralg, 34, 8) | 
+		shift_lower_bits(ciphermode, 25, 8) | 
+		shift_lower_bits(arc4_cipherkeylen, 18, 5) | 
+		shift_lower_bits(arc4_keyinit, 17, 1) | 
+		shift_lower_bits(cfbmask, 0, 3);
+}
+/**
+* @brief Generate crypto packet descriptor 0
+* @ingroup crypto
+* - tls : 1(tls enabled) 0(tls disabled)
+* - hash_source : 1(encrypted data is sent to the auth engine) 0(plain data is sent to the auth engine)
+* - hashout_l3alloc : 1(auth output is transited through l3 cache)
+* - encrypt : 1(for encrypt) 0(for decrypt)
+* - ivlen : iv length in bytes
+* - hashdst_addr : hash out physical address, byte aligned
+*/
+static inline unsigned long long nlm_crypto_form_pkt_desc0(unsigned int tls, unsigned int hash_source, 
+		unsigned int hashout_l3alloc,
+		unsigned int encrypt, unsigned int ivlen, unsigned long long hashdst_addr)
+{
+	return (shift_lower_bits(tls, 63, 1) |
+		shift_lower_bits(hash_source, 62, 1) |
+		shift_lower_bits(hashout_l3alloc, 60, 1) |
+		shift_lower_bits(encrypt, 59, 1) |
+		shift_lower_bits_mask((ivlen - 1), 41, 16) |
+		shift_lower_bits(hashdst_addr, 0, 40));
+}
+
+/**
+* @brief Generate crypto packet descriptor 1
+* @ingroup crypto
+* - cipherlen : cipher length in bytes
+* - hashlen : hash length in bytes
+*/
+static inline unsigned long long nlm_crypto_form_pkt_desc1(unsigned int cipherlen, unsigned int hashlen)
+{
+	return shift_lower_bits_mask((cipherlen - 1), 32, 32)
+		| shift_lower_bits_mask((hashlen - 1), 0, 32);
+}	
+
+/**
+* @brief Generate crypto packet descriptor 2
+* @ingroup crypto
+* - ivoff : iv offset, offset from start of src data addr
+* - ciperbit_cnt : number of valid bits in the last input byte to the cipher, 0(8 bits), 1(1 bit)..7(7 bits)
+* - cipheroff : cipher offset, offset from start of src data addr
+* - hashbit_cnt : number of valid bits in the last input byte to the auth, 0(8 bits), 1(1 bit)..7(7 bits)
+* - hashclobber : 1(hash output will be written as multiples of cachelines, no read modify write)
+* - hashoff : hash offset, offset from start of src data addr
+*/
+
+static inline unsigned long long nlm_crypto_form_pkt_desc2(unsigned int ivoff, unsigned int cipherbit_cnt, 
+		unsigned int cipheroff, 
+		unsigned int hashbit_cnt, unsigned int hashclobber, unsigned int hashoff)
+{
+	return shift_lower_bits(ivoff , 45, 16)
+		| shift_lower_bits(cipherbit_cnt, 42, 3) 
+		| shift_lower_bits(cipheroff, 22, 16)
+		| shift_lower_bits(hashbit_cnt, 19, 3)
+		| shift_lower_bits(hashclobber, 18, 1)
+		| shift_lower_bits(hashoff, 0, 16);
+}
+
+/**
+* @brief Generate crypto packet descriptor 3
+* @ingroup crypto
+* - designer_vc : designer freeback fmn destination id
+* - taglen : length in bits of the tag generated by the auth engine
+*          md5(128 bits), sha1(160), sha224(224), sha384(384), sha512(512), Kasumi(32), snow3g(32), gcm(128)
+* - hmacpad : 1 if hmac padding is already done 
+*/
+static  inline unsigned long long nlm_crypto_form_pkt_desc3(unsigned int designer_vc, unsigned int taglen, 
+	unsigned int arc4_state_save_l3, unsigned int arc4_save_state, unsigned int hmacpad)
+{
+	return shift_lower_bits(designer_vc, 48, 16)
+		| shift_lower_bits(taglen, 11, 16)
+		| shift_lower_bits(arc4_state_save_l3, 8, 1)
+		| shift_lower_bits(arc4_save_state, 6, 1)
+		| shift_lower_bits(hmacpad, 5, 1);
+}
+
+/**
+* @brief Generate crypto packet descriptor 4
+* @ingroup crypto
+* - srcfraglen : length of the source fragment(header + data + tail) in bytes
+* - srcfragaddr : physical address of the srouce fragment
+*/
+static inline unsigned long long nlm_crypto_form_pkt_desc4(unsigned int srcfraglen, unsigned long long srcfragaddr )
+{
+	return shift_lower_bits_mask((srcfraglen - 1), 48, 16)
+		| shift_lower_bits(srcfragaddr, 0, 40);
+}
+
+/**
+* @brief Generate crypto packet descriptor 5
+* @ingroup crypto
+* - dstfraglen : length of the dst fragment(header + data + tail) in bytes
+* - chipherout_l3alloc : 1(cipher output is transited through l3 cache)
+* - cipherclobber : 1(cipher output will be written as multiples of cachelines, no read modify write)
+* - chiperdst_addr : physical address of the cipher destination address
+*/
+static inline unsigned long long nlm_crypto_form_pkt_desc5(unsigned int dstfraglen, unsigned int cipherout_l3alloc, 
+	       unsigned int cipherclobber, unsigned long long cipherdst_addr)
+
+{
+	return shift_lower_bits_mask((dstfraglen - 1), 48, 16)
+		| shift_lower_bits(cipherout_l3alloc, 46, 1) 
+		| shift_lower_bits(cipherclobber, 41, 1)
+		| shift_lower_bits(cipherdst_addr, 0, 40);
+}
+
+/**
+  * @brief Generate crypto packet fmn message entry 0
+  * @ingroup crypto
+  * - freeback_vc: freeback response destination address
+  * - designer_fblen : Designer freeback length, 1 - 4
+  * - designerdesc_valid : designer desc valid or not
+  * - cipher_keylen : cipher key length in bytes
+  * - ctrldesc_addr : physicall address of the control descriptor
+  */
+static inline unsigned long long  nlm_crypto_form_pkt_fmn_entry0(unsigned int freeback_vc, unsigned int designer_fblen,
+		unsigned int designerdesc_valid, unsigned int cipher_keylen, unsigned long long cntldesc_addr)
+{
+	return shift_lower_bits(freeback_vc, 48, 16)
+		| shift_lower_bits_mask(designer_fblen - 1, 46, 2)
+		| shift_lower_bits(designerdesc_valid, 45, 1)
+		| shift_lower_bits_mask(((cipher_keylen + 7) >> 3), 40, 5)
+		| shift_lower_bits(cntldesc_addr >> 6, 0, 34);
+}
+
+/**
+  * @brief Generate crypto packet fmn message entry 1
+  * @ingroup crypto
+  * - arc4load_state : 1 if load state required 0 otherwise
+  * - hash_keylen : hash key length in bytes
+  * - pktdesc_size : packet descriptor size in bytes
+  * - pktdesc_addr : physicall address of the packet descriptor
+  */
+static inline unsigned long long nlm_crypto_form_pkt_fmn_entry1(unsigned int arc4load_state, unsigned int hash_keylen,
+		unsigned int pktdesc_size, unsigned long long pktdesc_addr)
+{
+	return shift_lower_bits(arc4load_state, 63, 1)
+		| shift_lower_bits_mask(((hash_keylen + 7) >> 3), 56, 5)
+		| shift_lower_bits_mask(((pktdesc_size >> 4) - 1), 43, 12)
+		| shift_lower_bits(pktdesc_addr >> 6, 0, 34);
+}
+
+enum chip_specific_features { 
+	INIT_DONE = 0x1,
+	ZUC = 0x2, 
+	DES3_KEY_SWAP = 0x4
+};
+
+#endif	
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h
new file mode 100644
index 0000000..c57c6a6
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_fmn.h
@@ -0,0 +1,1103 @@
+
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * http://www.gnu.org/licenses/gpl-2.0.txt  
+ * or the Broadcom license below:
+
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_4# */
+
+
+#ifndef _NLH_FMN_H
+#define _NLH_FMN_H
+
+#include "nlm_hal.h"
+#include "nlm_hal_xlp_dev.h"
+
+#ifndef __ASSEMBLY__
+
+#define FMN_INT_BIT_MASK 0x800000000000000ULL /* Bit 59 */
+
+#define xlp_read_tx_status() _read_32bit_cp2_register(XLP_MSG_TXSTATUS_REG)
+#define xlp_read_rx_status() _read_32bit_cp2_register(XLP_MSG_RXSTATUS_REG)
+
+#define xlp_read_status1()   _read_32bit_cp2_register(XLP_MSG_STATUS1_REG)
+#define xlp_write_status1(value)   _write_32bit_cp2_register(XLP_MSG_STATUS1_REG, value)
+
+#define xlp_read_config()       _read_32bit_cp2_register(XLP_MSG_CONFIG_REG)
+#define xlp_write_config(value) _write_32bit_cp2_register(XLP_MSG_CONFIG_REG, value)
+
+#define xlp_read_msg_int()	_read_32bit_cp2_register(XLP_MSG_INT_REG)
+#define xlp_write_msg_int(value)	_write_32bit_cp2_register(XLP_MSG_INT_REG, value)
+
+#define xlp_load_rx_msg0() _read_64bit_cp2_register_sel(XLP_RX_BUF_REG, 0)
+#define xlp_load_rx_msg1() _read_64bit_cp2_register_sel(XLP_RX_BUF_REG, 1)
+#define xlp_load_rx_msg2() _read_64bit_cp2_register_sel(XLP_RX_BUF_REG, 2)
+#define xlp_load_rx_msg3() _read_64bit_cp2_register_sel(XLP_RX_BUF_REG, 3)
+
+#define xlp_load_tx_msg0(value) _write_64bit_cp2_register_sel(XLP_TX_BUF_REG, value, 0)
+#define xlp_load_tx_msg1(value) _write_64bit_cp2_register_sel(XLP_TX_BUF_REG, value, 1)
+#define xlp_load_tx_msg2(value) _write_64bit_cp2_register_sel(XLP_TX_BUF_REG, value, 2)
+#define xlp_load_tx_msg3(value) _write_64bit_cp2_register_sel(XLP_TX_BUF_REG, value, 3)
+
+#define XLP_FMN_DEFAULT_QUEUE_SIZE 	16384 /*16K */
+#define XLP_FMN_DEFAULT_CREDITS    	50
+#define XLP_FMNQ_SPILL_DEFAULT_MEM_ADDR (256ULL << 20)
+#define XLP_FMNQ_SPILL_DEFAULT_MEM_SIZE (32ULL << 20)
+
+#define FMN_MAX_Q_SIZE (256ULL * 1024)
+#define FMN_Q_PAGE_SIZE (4ULL * 1024)
+
+enum FMN_MSG_BLKS {
+	XLP_MSG_BLK_CPU = 0, 
+	XLP_MSG_BLK_POPQ, 
+        XLP_MSG_BLK_PCIE0,
+        XLP_MSG_BLK_PCIE1,
+        XLP_MSG_BLK_PCIE2,
+        XLP_MSG_BLK_PCIE3,
+	XLP_MSG_BLK_GDX,
+	XLP_MSG_BLK_RSA_ECC,
+	XLP_MSG_BLK_CRYPTO,
+	XLP_MSG_BLK_CMP,
+	XLP_MSG_BLK_POE,
+	XLP_MSG_BLK_NAE,
+	XLP_MSG_BLK_REGX,
+	XLP_MSG_BLK_SRIO,
+	XLP_MSG_BLK_MAX
+};
+
+
+enum LVL_INT_TYPES {
+	LVL_INT_DISABLE,
+	LVL_INT_LOW_WM,
+	LVL_INT_HIGH_WM,
+	LV_INT_RESERVED
+};
+
+enum LWM_INT_VALUES {
+	LWM_EMPTY,
+	LWM_1_4_FULL,
+	LWM_1_2_FULL,
+	LWM_3_4_FULL,
+	LWM_NON_FULL,
+	LWM_NUM_VALUES
+};
+enum HWM_INT_VALUES {
+	HWM_NON_EMPTY,
+	HWM_1_4_FULL,
+	HWM_1_2_FULL,
+	HWM_3_4_FULL,
+	HWM_FULL,
+	HWM_NUM_VALUES
+};
+
+/*
+ *  FMN Reg access macros
+ */
+enum XLP_REGS{
+  XLP_OUTQ_CONFIG_REG,
+  XLP_CREDIT_CONFIG_REG,
+  XLP_INTERCHIP_LINK_CONFIG_REG,
+  XLP_ERROR_REG
+};
+
+struct fmn_qsize_credit_config
+{
+        char q_name[16]; /* fmn station type*/
+        int b_stid; /* base stations */
+        int e_stid; /* end stations */
+        int n_txstns; /* number of tranmit stations from this type, only used for credit warn */
+        int valid;
+        int q_size; /* queue size for this type */
+        unsigned int credits[NLM_MAX_NODES][XLP_MSG_BLK_MAX];
+};
+
+struct fmn_cfg {
+        uint64_t fmn_spill_base;
+        uint64_t fmn_spill_size;
+        uint32_t fmn_default_qsize;
+        uint32_t fmn_default_credits;
+        uint32_t max_msg_blk;
+        struct fmn_qsize_credit_config  fmn_q_config[XLP_MSG_BLK_MAX];
+        /* onchi mem */
+        uint64_t q_ram_base;
+        uint32_t q_ram_page_perq;
+        uint32_t q_ram_base_cur;
+
+        /* spill mem */
+        uint32_t spill_base_cur;
+};
+
+typedef volatile unsigned long long msg_reg_t;
+
+static inline unsigned long long nlh_qid_to_virt_addr(int node, int reg, int sel)
+{
+  unsigned long long base = xlp_fmn_base[node] & 0xffffffc000ULL;
+
+#if 0 /*defined(NLM_HAL_LINUX_USER) */
+  base |= NLH_XKPHYS_UNCACHED;
+#endif
+
+  if (reg == XLP_OUTQ_CONFIG_REG) {
+    return ((sel * 8) | base); /* 'sel' is the qid */
+
+  } else if (reg == XLP_CREDIT_CONFIG_REG) {
+    return (0x2000 | base);
+
+  } else if (reg == XLP_ERROR_REG) {
+    return (0x2020 | base);
+
+  } else {
+    /*    nlm_print("FMN Error: Unknown register ID %d\n", reg); */
+  }
+  return 0;
+}
+/* */
+
+#define nlm_hal_read_outq_config(node, qid) \
+	nlh_read_cfg_reg64(nlh_qid_to_virt_addr(node, XLP_OUTQ_CONFIG_REG, qid))
+
+#define nlm_hal_write_outq_config(node, qid, val) \
+	nlh_write_cfg_reg64(nlh_qid_to_virt_addr(node, XLP_OUTQ_CONFIG_REG, qid), val)
+
+/*
+ *  Messaging Operations 
+ */
+/**
+* @brief xlp_send function is used to send any configured message to a destination, used by the HAL send message API's for different number of messages. Performs a sync before sending.
+*
+* @param [in]  dest 		:Destination Message Queue number
+*
+* @return
+*  - "1" on  send success, "0" on failure
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline int xlp_send(unsigned int dest)
+{
+        unsigned int success = 0;
+
+        __asm__ volatile (".set push\n"
+                          ".set noreorder\n"
+                          ".set arch=xlp\n"
+                          "sync\n"
+                          "msgsnds %0, %1\n"
+                          ".set pop\n"
+                          : "=&r" (success)
+                          : "r" (dest));
+
+        return success;
+}
+/* */
+#if 0
+static inline void xlp_receive(unsigned int pri)
+{
+	__asm__ volatile (".set push\n"
+			  ".set noreorder\n"
+                          ".set arch=xlp\n"
+			  "msglds $0, %0\n" ".set pop\n"::"r" (pri)
+	    );
+}
+#endif
+/* */
+/**
+* @brief xlp_message_wait function is a non-blocking API used to wait for the first message to come to a mailbox. 
+*
+* @param [in]  mask 		:bitmask of the 4 VC's of the CPU, for which queues to monitor for a message
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline void xlp_message_wait(unsigned int mask)
+{
+    __asm__ volatile(".set push\n"
+            ".set noreorder\n"
+            " msgwait %0\n"
+            ".set pop\n"::"r" (mask)
+            );
+}
+/* */
+#define xlp_enable(flags)                        \
+do {                                                \
+  __asm__ volatile (                                \
+		    ".set push\n\t"                 \
+		    ".set reorder\n\t"              \
+		    ".set noat\n\t"                 \
+		    "mfc0 %0, $12\n\t"              \
+		    "li  $8, 0x40000001\n\t"        \
+		    "or  $1, %0, $8\n\t"            \
+		    "xori $1, 1\n\t"                \
+		    ".set noreorder\n\t"            \
+		    "mtc0 $1, $12\n\t"              \
+		    ".set\tpop\n\t"                 \
+		    : "=r" (flags)                  \
+		    :                               \
+		    : "$8"                          \
+		    );                              \
+} while (0)
+/* */
+#define xlp_disable(flags) __asm__ volatile (    \
+                 "mtc0 %0, $12" : : "r" (flags))
+
+/* */
+static __inline__ unsigned long long xlp_cpu_to_bucket_mask(unsigned int
+							       cpumask)
+{
+  return 0;
+}
+/* */
+static __inline__ unsigned int xlp_cpu_to_bucket(int pid)
+{
+  return 0;
+}
+/* */
+/*
+   XLP API
+   RT[63 : 32] - Reserved
+   RT[31 : 24] - Software Code
+   RT[23 : 21] - Reserved
+   RT[20 : 19] - Pop Message Source VC no.
+   RT[18 : 18] - Reserved
+   RT[17 : 16] - Message Size-1
+   RT[15 : 12] - Reserved
+   RT[11 : 0]  - Message Destination ID
+ */
+/* message send API NON blocking for single entry message*/
+/**
+* @brief xlp_message_send_1 function is a non-blocking API used to send a single entry message to a mailbox. Will retry the message send 16 times. Performs a sync before sending.
+*
+* @param [in]  dst		:Destination Message Queue number
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  data 		:64b data value for the single message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline int xlp_message_send_1(uint32_t dst, 
+				     uint32_t  code, uint64_t data)
+{
+  unsigned int dest = 0;
+  int retry = 16;
+
+  xlp_load_tx_msg0(data);
+
+  dest = ((code << 24) | dst);
+
+#ifdef MSGRING_DUMP_MESSAGES
+  nlm_hal_dbg_msg("Sending msg<%llx> to dest = %x\n", 
+	  data, dest);
+#endif
+
+  while(retry--){
+	if(xlp_send(dest))
+		return 0;
+  }
+  return xlp_read_tx_status();
+
+}
+/* message send API NON blocking for double entry message*/
+/**
+* @brief xlp_message_send_2 function is a non-blocking API used to send a two entry message to a mailbox. Will retry the message send 16 times. Performs a sync before sending.
+*
+* @param [in]  dst		:Destination Message Queue number
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  data0 		:64b data value for the first message
+* @param [in]  data1 		:64b data value for the second message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline int xlp_message_send_2(uint32_t dst, 
+				     uint32_t  code,
+				     uint64_t data0, uint64_t data1)
+{
+  unsigned int dest = 0;
+  int retry = 16;
+
+  xlp_load_tx_msg0(data0);
+  xlp_load_tx_msg1(data1);
+
+  dest = ((code << 24) | (1 << 16) | dst);
+
+#ifdef MSGRING_DUMP_MESSAGES
+  nlm_hal_dbg_msg("Sending msg<%llx, %llx> to dest = %x\n", 
+	  data0, data1, dest);
+#endif
+  while(retry--){
+	if(xlp_send(dest))
+		return 0;
+  }
+  return xlp_read_tx_status();
+}
+
+/* message send API NON blocking for double entry message*/
+/**
+* @brief xlp_message_send_3 function is a non-blocking API used to send a three entry message to a mailbox. Does not retry the send message. Performs a sync before sending.
+*
+* @param [in]  dst		:Destination Message Queue number
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  data0 		:64b data value for the first message
+* @param [in]  data1 		:64b data value for the second message
+* @param [in]  data2 		:64b data value for the third message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline int xlp_message_send_3(uint32_t dst, 
+				     uint32_t  code,
+				     uint64_t data0, uint64_t data1,
+				     uint64_t data2)
+{
+  unsigned int dest = 0;
+
+
+  xlp_load_tx_msg0(data0);
+  xlp_load_tx_msg1(data1);
+  xlp_load_tx_msg2(data2);
+
+  dest = ((code << 24) | (2 << 16) | dst);
+
+#ifdef MSGRING_DUMP_MESSAGES
+  nlm_hal_dbg_msg("Sending msg<%llx, %llx, %llx> to dest = %x\n", 
+	  data0, data1, data2, dest);
+#endif
+	
+  if (!xlp_send(dest) ) {
+	  /* Check the status */
+	  return xlp_read_tx_status();
+  }
+
+
+  return 0;
+}
+
+
+/* message send API NON blocking for double entry message*/
+/**
+* @brief xlp_message_send_4 function is a non-blocking API used to send a three entry message to a mailbox. Does not retry the send message. Performs a sync before sending.
+*
+* @param [in]  dst		:Destination Message Queue number
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  data0 		:64b data value for the first message
+* @param [in]  data1 		:64b data value for the second message
+* @param [in]  data2 		:64b data value for the third message
+* @param [in]  data3 		:64b data value for the fourth message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline int xlp_message_send_4(uint32_t dst, 
+				     uint32_t  code,
+				     uint64_t data0, uint64_t data1,
+				     uint64_t data2, uint64_t data3)
+{
+  unsigned int dest = 0;
+
+
+  xlp_load_tx_msg0(data0);
+  xlp_load_tx_msg1(data1);
+  xlp_load_tx_msg2(data2);
+  xlp_load_tx_msg2(data3);
+
+  dest = ((code << 24) | (2 << 16) | dst);
+
+#ifdef MSGRING_DUMP_MESSAGES
+  nlm_hal_dbg_msg("Sending msg<%llx, %llx, %llx, %llx> to dest = %x\n", 
+	  data0, data1, data2, data3, dest);
+#endif
+	
+  if (!xlp_send(dest) ) {
+	  /* Check the status */
+	  return xlp_read_tx_status();
+  }
+
+
+  return 0;
+}
+
+/* Generic message send API NON blocking */
+/**
+* @brief xlp_message_send function is a non-blocking API for sending a one to four entry message to a mailbox.  Does not retry the send message. Performs a sync before sending.
+*
+* @param [in]  dst		:Destination Message Queue number
+* @param [in]  size		:Number of messages to transmit (1 to 4)
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  *data 		:uint64_t array of data[0] to data[3] representing each 64b message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline int xlp_message_send(uint32_t dst, 
+				   uint32_t size,  uint32_t  code,
+				   uint64_t *data)
+{
+  unsigned int dest = 0;
+
+    switch (size)
+    {
+      case 4:
+		  xlp_load_tx_msg3(data[3]);
+
+      case 3:
+		  xlp_load_tx_msg2(data[2]);
+
+      case 2:
+		  xlp_load_tx_msg1(data[1]);
+          
+      default:
+		  xlp_load_tx_msg0(data[0]);
+    }
+
+  dest = ((code << 24) | ((size - 1) << 16) | dst);
+ 
+  if (!xlp_send(dest) ) {
+	  /* Check the status */
+	  return xlp_read_tx_status();
+  }
+
+  return 0;
+}
+
+#if (_MIPS_SIM == _MIPS_SIM_ABI32)
+static inline void xlp_message_send_block_fast_1(unsigned int code,
+						 unsigned int dest_vc,
+						 unsigned long long msg0)
+{
+	unsigned int high = msg0>>32;
+	unsigned int low = msg0 & 0xffffffff;
+
+  __asm__ __volatile__ (".set push\n"
+			".set noreorder\n"
+			".set arch=xlp\n"
+			"dsll32 $9, %3, 0\n"
+			"dsll32 $10, %2, 0\n"
+			"dsrl32 $9, $9, 0\n"
+			"or     $9, $9, $10\n"
+			"dmtc2  $9, "STR(XLP_TX_BUF_REG)", 0\n"
+			/* "dmtc2 %1, "STR(XLP_TX_BUF_REG)", 0\n" */
+			"sync\n"
+			"1: \n"
+			"msgsnds  $8, %0\n"    /* msgsnds rD, rt */
+			"andi $8, $8, 0x1\n"
+			"beqz $8, 1b\n"
+			"move $8, %0\n"
+			".set mips64\n"
+			".set pop\n"
+			:
+			: "r"((code << 24) |  dest_vc), /* %0 */
+			  "r"(msg0),
+			  "r" (high), "r" (low) /* %2, %3 */
+			: "$8", "$9", "$10"
+			);
+}
+
+static inline void xlp_message_send_block_fast_2(unsigned int code,
+						 unsigned int dest_vc,
+						 unsigned long long msg0,
+						 unsigned long long msg1)
+{
+	unsigned int high0 = msg0>>32;
+	unsigned int low0 = msg0 & 0xffffffff;
+	unsigned int high1 = msg1>>32;
+	unsigned int low1 = msg1 & 0xffffffff;
+
+  __asm__ __volatile__ (".set push\n"
+			".set noreorder\n"
+			".set arch=xlp\n"
+			"dsll32 $9, %4, 0\n"
+			"dsll32 $10, %3, 0\n"
+			"dsrl32 $9, $9, 0\n"
+			"or     $9, $9, $10\n"
+			"dmtc2  $9, "STR(XLP_TX_BUF_REG)", 0\n"
+			"sync\n"
+			/* "dmtc2 %1, "STR(XLP_TX_BUF_REG)", 0\n" */
+			"dsll32 $9, %6, 0\n"
+			"dsll32 $10, %5, 0\n"
+			"dsrl32 $9, $9, 0\n"
+			"or     $9, $9, $10\n"
+			"dmtc2  $9, "STR(XLP_TX_BUF_REG)", 1\n"
+			"sync\n"
+			/* "dmtc2 %2, "STR(XLP_TX_BUF_REG)", 1\n" */
+			"sync\n"
+			"1: \n"
+			"msgsnds  $8, %0\n"    /* msgsnds rD, rt */
+			"andi $8, $8, 0x1\n"
+			"beqz $8, 1b\n"
+			"move $8, %0\n"
+			".set mips64\n"
+			".set pop\n"
+			:
+			: "r"((code << 24) | (1 << 16) | dest_vc), /* %0 */
+			  "r"(msg0), "r" (msg1),
+			  "r"(high0), "r"(low0), /* %3, %4 */
+			  "r"(high1), "r"(low1)  /* %5, %6 */
+			: "$8", "$9", "$10"
+			);
+}
+
+static inline void xlp_message_send_block_fast_3(unsigned int code,
+						 unsigned int dest_vc,
+						 unsigned long long msg0,
+						 unsigned long long msg1,
+						 unsigned long long msg2)
+{
+	unsigned int high0 = msg0>>32;
+	unsigned int low0 = msg0 & 0xffffffff;
+	unsigned int high1 = msg1>>32;
+	unsigned int low1 = msg1 & 0xffffffff;
+	unsigned int high2 = msg2>>32;
+	unsigned int low2 = msg2 & 0xffffffff;
+
+  __asm__ __volatile__ (".set push\n"
+			".set noreorder\n"
+			".set arch=xlp\n"
+			"dsll32 $9, %5, 0\n"
+			"dsll32 $10, %4, 0\n"
+			"dsrl32 $9, $9, 0\n"
+			"or     $9, $9, $10\n"
+			"dmtc2  $9, "STR(XLP_TX_BUF_REG)", 0\n"
+			"sync\n"
+			/* "dmtc2 %1, "STR(XLP_TX_BUF_REG)", 0\n" */
+			"dsll32 $9, %7, 0\n"
+			"dsll32 $10,%6, 0\n"
+			"dsrl32 $9, $9, 0\n"
+			"or     $9, $9, $10\n"
+			"dmtc2  $9, "STR(XLP_TX_BUF_REG)", 1\n"
+			"sync\n"
+			/* "dmtc2 %2, "STR(XLP_TX_BUF_REG)", 1\n" */
+			"dsll32 $9, %9, 0\n"
+			"dsll32 $10,%8, 0\n"
+			"dsrl32 $9, $9, 0\n"
+			"or     $9, $9, $10\n"
+			"dmtc2  $9, "STR(XLP_TX_BUF_REG)", 2\n"
+			"sync\n"
+			/* "dmtc2 %3, "STR(XLP_TX_BUF_REG)", 2\n" */
+			"sync\n"
+			"1: \n"
+			"msgsnds  $8, %0\n"    /* msgsnds rD, rt */
+			"andi $8, $8, 0x1\n"
+			"beqz $8, 1b\n"
+			"move $8, %0\n"
+			".set mips64\n"
+			".set pop\n"
+			:
+			: "r"((code << 24) | (2 << 16) | dest_vc), /* %0 */
+			  "r"(msg0), "r" (msg1), "r" (msg2),
+			  "r"(high0), "r"(low0), /* %4, %5 */
+			  "r"(high1), "r"(low1), /* %6, %7 */
+			  "r"(high2), "r"(low2)  /* %8, %9 */
+			: "$8", "$9", "$10"
+			);
+}
+
+static inline void xlp_message_send_block_fast(int size, unsigned int code,
+					       unsigned int dest_vc,
+					       unsigned long long msg0,
+					       unsigned long long msg1,
+					       unsigned long long msg2,
+					       unsigned long long msg3)
+{
+	unsigned int high0 = msg0>>32;
+	unsigned int low0 = msg0 & 0xffffffff;
+	unsigned int high1 = msg1>>32;
+	unsigned int low1 = msg1 & 0xffffffff;
+	unsigned int high2 = msg2>>32;
+	unsigned int low2 = msg2 & 0xffffffff;
+	unsigned int high3 = msg3>>32;
+	unsigned int low3 = msg3 & 0xffffffff;
+
+  __asm__ __volatile__ (".set push\n"
+			".set noreorder\n"
+			".set arch=xlp\n"
+			"dsll32 $9, %6, 0\n"
+			"dsll32 $10, %5, 0\n"
+			"dsrl32 $9, $9, 0\n"
+			"or     $9, $9, $10\n"
+			"dmtc2 $9, " STR(XLP_TX_BUF_REG) ", 0\n"
+			"sync\n"
+			/* "dmtc2 %1, " STR(XLP_TX_BUF_REG) ", 0\n" */
+			"dsll32 $9, %8, 0\n"
+			"dsll32 $10, %7, 0\n"
+			"dsrl32 $9, $9, 0\n"
+			"or     $9, $9, $10\n"
+			"dmtc2 $9, " STR(XLP_TX_BUF_REG) ", 1\n"
+			"sync\n"
+			/* "dmtc2 %2, " STR(XLP_TX_BUF_REG) ", 1\n" */
+			"dsll32 $9, %10, 0\n"
+			"dsll32 $10, %9, 0\n"
+			"dsrl32 $9, $9, 0\n"
+			"or     $9, $9, $10\n"
+			"dmtc2 $9, " STR(XLP_TX_BUF_REG) ", 2\n"
+			"sync\n"
+			/* "dmtc2 %3, " STR(XLP_TX_BUF_REG) ", 2\n" */
+			"dsll32 $9, %12, 0\n"
+			"dsll32 $10, %11, 0\n"
+			"dsrl32 $9, $9, 0\n"
+			"or     $9, $9, $10\n"
+			"dmtc2 $9, " STR(XLP_TX_BUF_REG) ", 3\n"
+			"sync\n"
+			/* "dmtc2 %4, " STR(XLP_TX_BUF_REG) ", 3\n" */
+			"sync\n"
+			"1: \n"
+			"msgsnds  $8, %0\n"    /* msgsnds rD, rt */
+			"andi $8, $8, 0x1\n"
+			"beqz $8, 1b\n"
+			"move $8, %0\n"
+			".set mips64\n"
+			".set pop\n"::
+			"r"((code << 24) | ((size-1) << 16) | dest_vc), /* %0 */
+			"r"(msg0), "r"(msg1),
+			"r"(msg2), "r"(msg3),
+			"r"(high0), "r"(low0), /* %5, %6 */
+			"r"(high1), "r"(low1), /* %7, %8 */
+			"r"(high2), "r"(low2), /* %9, %10 */
+			"r"(high3), "r"(low3)  /* %11, %12 */
+			:"$8", "$9", "$10");
+}
+
+#else
+
+/* API to send a 1 entry message to "stid" with given "code" */
+/**
+* @brief xlp_message_send_block_fast_1 function is a blocking API for sending a one entry message to a mailbox.  It will continuously retry the send message until successful. Performs a sync before sending.
+*
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  dest_vc		:Destination Message Queue number
+* @param [in]  msg0 		:64b data value for the first message
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
+
+static inline void xlp_message_send_block_fast_1(unsigned int code, 
+						 unsigned int dest_vc,
+						 unsigned long long msg0)
+{
+  __asm__ __volatile__ (".set push\n"
+			".set noreorder\n"
+			".set arch=xlp\n"
+			"dmtc2 %1, "STR(XLP_TX_BUF_REG)", 0\n"
+			"sync\n"
+			"1: \n"
+			"msgsnds  $8, %0\n"    /* msgsnds rD, rt */
+			"andi $8, $8, 0x1\n"
+			"beqz $8, 1b\n"
+			"move $8, %0\n"
+			".set mips64\n"
+			".set pop\n"
+			:
+			: "r"((code << 24) |  dest_vc), /* %0 */
+			  "r"(msg0) 
+			: "$8"
+			);
+}
+
+/* */
+/* API to send a 2 entry message to "stid" with given "code" */
+/**
+* @brief xlp_message_send_block_fast_2 function is a blocking API for sending a two entry message to a mailbox.  It will continuously retry the send message until successful. Performs a sync before sending.
+*
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  dest_vc		:Destination Message Queue number
+* @param [in]  msg0 		:64b data value for the first message
+* @param [in]  msg1 		:64b data value for the second message
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline void xlp_message_send_block_fast_2(unsigned int code, 
+						 unsigned int dest_vc,
+						 unsigned long long msg0,
+						 unsigned long long msg1)
+{
+  __asm__ __volatile__ (".set push\n"
+			".set noreorder\n"
+			".set arch=xlp\n"
+			"dmtc2 %1, "STR(XLP_TX_BUF_REG)", 0\n"
+			"dmtc2 %2, "STR(XLP_TX_BUF_REG)", 1\n"
+			"sync\n"
+			"1: \n"
+			"msgsnds  $8, %0\n"    /* msgsnds rD, rt */
+			"andi $8, $8, 0x1\n"
+			"beqz $8, 1b\n"
+			"move $8, %0\n"
+			".set mips64\n"
+			".set pop\n"
+			:
+			: "r"((code << 24) | (1 << 16) | dest_vc), /* %0 */
+			  "r"(msg0), "r" (msg1) 
+			: "$8"
+			);
+}
+/* API to send a 3 entry message to "stid" with given "code" */
+/**
+* @brief xlp_message_send_block_fast_3 function is a blocking API for sending a three entry message to a mailbox.  It will continuously retry the send message until successful. Performs a sync before sending.
+*
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  dest_vc		:Destination Message Queue number
+* @param [in]  msg0 		:64b data value for the first message
+* @param [in]  msg1 		:64b data value for the second message
+* @param [in]  msg2 		:64b data value for the third message
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline void xlp_message_send_block_fast_3(unsigned int code, 
+						 unsigned int dest_vc,
+						 unsigned long long msg0,
+						 unsigned long long msg1,
+						 unsigned long long msg2)
+{
+  __asm__ __volatile__ (".set push\n"
+			".set noreorder\n"
+			".set arch=xlp\n"
+			"dmtc2 %1, "STR(XLP_TX_BUF_REG)", 0\n"
+			"dmtc2 %2, "STR(XLP_TX_BUF_REG)", 1\n"
+			"dmtc2 %3, "STR(XLP_TX_BUF_REG)", 2\n"
+			"sync\n"
+			"1: \n"
+			"msgsnds  $8, %0\n"    /* msgsnds rD, rt */
+			"andi $8, $8, 0x1\n"
+			"beqz $8, 1b\n"
+			"move $8, %0\n"
+			".set mips64\n"
+			".set pop\n"
+			:
+			: "r"((code << 24) | (2 << 16) | dest_vc), /* %0 */
+			  "r"(msg0), "r" (msg1), "r" (msg2)
+			: "$8"
+			);
+}
+
+/* */
+/**
+* @brief xlp_message_send_block_fast_3 function is a blocking API for sending a four entry message to a mailbox.  It will continuously retry the send message until successful. Performs a sync before sending.
+*
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  dest_vc		:Destination Message Queue number
+* @param [in]  msg0 		:64b data value for the first message
+* @param [in]  msg1 		:64b data value for the second message
+* @param [in]  msg2 		:64b data value for the third message
+* @param [in]  msg3 		:64b data value for the fourth message
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline void xlp_message_send_block_fast(int size, unsigned int code,
+					       unsigned int dest_vc,
+					       unsigned long long msg0,
+					       unsigned long long msg1,
+					       unsigned long long msg2,
+					       unsigned long long msg3)
+{
+  __asm__ __volatile__ (".set push\n"
+			".set noreorder\n"
+			".set arch=xlp\n"
+			"dmtc2 %1, " STR(XLP_TX_BUF_REG) ", 0\n"
+			"dmtc2 %2, " STR(XLP_TX_BUF_REG) ", 1\n"
+			"dmtc2 %3, " STR(XLP_TX_BUF_REG) ", 2\n"
+			"dmtc2 %4, " STR(XLP_TX_BUF_REG) ", 3\n"
+			"sync\n"
+			"1: \n"
+			"msgsnds  $8, %0\n"    /* msgsnds rD, rt */
+			"andi $8, $8, 0x1\n"
+			"beqz $8, 1b\n"
+			"move $8, %0\n"
+			".set mips64\n"
+			".set pop\n"::
+			"r"((code << 24) | ((size-1) << 16) | dest_vc), /* %0 */
+			"r"(msg0), "r"(msg1),
+			"r"(msg2), "r"(msg3)
+			:"$8");
+}
+
+#endif
+
+/* */
+/**
+* @brief xlp_receive function is used to receive message from a mailbox vc, used by the HAL receive message API's for different number of messages
+*
+* @param [in]  vc 		:VC mailbox of the CPU (1 to 4)
+*
+* @return
+*  - "1" on load success, "0" on failure
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline int xlp_receive(unsigned int vc)
+{
+	unsigned int success = 0;
+
+	__asm__ volatile (".set push\n"
+	                  ".set noreorder\n"
+	                  ".set arch=xlp\n"
+	                  "msglds %0, %1\n"
+	                  ".set pop\n"
+	                  : "=&r" (success)
+	                  : "r" (vc));
+
+	return success;
+}
+
+/* */
+/**
+* @brief xlp_message_receive_1 function is used to receive a single entry message from a VC of the CPU. Size should be used to determine how other 64b messages were available with data.
+*
+* @param [in]  vc 		:VC mailbox of the CPU (1 to 4)
+* @param [out]  src_id		:Source Message Queue Number
+* @param [out]  size		:# of messages returned (1 to 4)
+* @param [out]  code		:8b SW code of the received message
+* @param [out]  msg0 		:64b data value for the received message
+*
+* @return
+*  - "0" on receive success, "-1" on failure
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline int xlp_message_receive_1(uint32_t vc, uint32_t *src_id,
+	uint32_t *size, uint32_t *code,	uint64_t *msg0)
+{
+	unsigned int status;
+
+	if (!xlp_receive(vc))
+		return -1;
+
+	status = xlp_read_rx_status();
+	*size = ((status >> 26) & 0x3) + 1;
+	*code = (status >> 18) & 0xff;
+	*src_id = (status >> 4) & 0xfff;
+	*msg0 = xlp_load_rx_msg0();
+	return 0;
+}
+/**
+* @brief xlp_message_receive_2 function is used to receive a single entry message from a VC of the CPU. Size should be used to determine how many of msg0-msg1 have valid data and if there were more messages available.
+*
+* @param [in]  vc 		:VC mailbox of the CPU (1 to 4)
+* @param [out]  src_id		:Source Message Queue Number
+* @param [out]  size		:# of messages that were in this received message (1 to 4)
+* @param [out]  code		:8b SW code of the received message
+* @param [out]  msg0 		:64b data value for the first received message
+* @param [out]  msg1 		:64b data value for the second received message
+*
+* @return
+*  - "0" on receive success, "-1" on failure, "1" on load failure, "2" on pop failure
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline int xlp_message_receive_2(uint32_t vc, uint32_t *src_id,
+	uint32_t *size, uint32_t *code, uint64_t *msg0, uint64_t *msg1)
+{
+	unsigned int status;
+
+	if (!xlp_receive(vc))
+		return -1;
+
+	status = xlp_read_rx_status();
+	*size = ((status >> 26) & 0x3) + 1;
+	*code = (status >> 18) & 0xff;
+	*src_id = (status >> 4) & 0xfff;
+	*msg0 = xlp_load_rx_msg0();
+	*msg1 = xlp_load_rx_msg1();
+	return (status & 0x3);
+}
+/* */
+/**
+* @brief xlp_message_receive function is used to receive a four entry message from a VC of the CPU.  Size should be used to determine how many of msg0-msg3 have valid data.
+*
+* @param [in]  vc 		:VC mailbox of the CPU (1 to 4)
+* @param [out]  src_id		:Source Message Queue Number
+* @param [out]  size		:# of messages that were in this received message (1 to 4)
+* @param [out]  code		:8b SW code of the received message
+* @param [out]  msg0 		:64b data value for the first received message
+* @param [out]  msg1 		:64b data value for the second received message
+* @param [out]  msg2 		:64b data value for the third received message
+* @param [out]  msg3 		:64b data value for the fourth received message
+*
+* @return
+*  - "0" on receive success, "-1" on failure
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline int xlp_message_receive(uint32_t vc, uint32_t *src_id,
+	uint32_t *size, uint32_t *code, uint64_t *msg0, uint64_t *msg1,
+	uint64_t *msg2, uint64_t *msg3)
+{
+	unsigned int status;
+
+	if (!xlp_receive(vc))
+		return -1;
+
+	status = xlp_read_rx_status();
+	*size = ((status >> 26) & 0x3) + 1;
+	*code = (status >> 18) & 0xff;
+	*src_id = (status >> 4) & 0xfff;
+	*msg0 = xlp_load_rx_msg0();
+	*msg1 = xlp_load_rx_msg1();
+	*msg2 = xlp_load_rx_msg2();
+	*msg3 = xlp_load_rx_msg3();
+	return 0;
+}
+
+/* 
+   *
+   * This API can be used for both enabling and disabling the POP operation 
+   * in the msgconfig register.  
+   * 
+   * In vc_mask:
+   * '0' means disable  and 
+   * '1' means enable.
+   *
+   * bit0 = vc0, bit1 = vc1, bit2 = vc2, bit3 = vc3
+   *
+   */
+static inline int nlm_hal_pop_cfg_update (uint32_t vc_mask)
+{
+	uint32_t vc, config; 
+
+	/* mask out the other bits in vc_mask, just to be safe */
+	vc_mask &= 0x0f;
+	vc = (vc_mask << 1);
+
+	config = xlp_read_config();
+	config &= ~(0x1e);
+	config |= vc;
+	xlp_write_config(config);
+
+	return 0;
+}
+
+static inline int nlm_hal_pop_send (uint32_t popq)
+{
+	int rc = 0;
+
+	if (!xlp_send(popq) )
+	{
+		/* Check the status */
+		rc = xlp_read_tx_status();
+	}
+
+	return rc;
+}
+
+/* */
+/* Generic Messaging API */
+/* */
+/**
+* @brief xlp_message_send_block function is a blocking API for sending a one to four entry message to a mailbox.  It will continuously retry the send message until successful. Performs a sync before sending.
+*
+* @param [in]  size		:# of 64b messages to be sent (1 to 4)
+* @param [in]  code		:8b SW code to send with the message
+* @param [in]  stid		:Destination Message Queue number
+* @param [in]  data0 		:64b data value for the first message
+* @param [in]  data1 		:64b data value for the second message, if size < 2 can be any value
+* @param [in]  data2 		:64b data value for the third message, if size < 3 can be any value
+* @param [in]  data3 		:64b data value for the fourth message, if size < 4 can be any value
+*
+* @return
+*  - none
+* 
+* @ingroup hal_fmn
+*
+*/
+static inline int xlp_message_send_block(unsigned int size, unsigned int code,
+					 unsigned int stid, uint64_t data0, uint64_t data1,
+					 uint64_t data2, uint64_t data3)
+{
+    xlp_message_send_block_fast(size, code, stid, data0, data1, data2, data3);
+    return 0;
+}
+/* */
+
+#endif				/* __ASSEMBLY__ */
+
+/* Returns the TxStatus reg, if unsuccessful, 0 if success */
+extern uint32_t nlm_hal_send_msg4(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1, uint64_t data2, uint64_t data3);
+extern uint32_t nlm_hal_send_msg3(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1, uint64_t data2);
+extern uint32_t nlm_hal_send_msg2(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1);
+extern uint32_t nlm_hal_send_msg1(uint32_t dst, uint32_t code, uint64_t data0);
+/* Returns the RxStatus reg */
+extern uint32_t nlm_hal_recv_msg2(uint32_t dst, uint32_t *src, uint32_t *size, uint32_t *code, uint64_t *data0, uint64_t *data1);
+extern uint32_t nlm_hal_recv_msg1(uint32_t dst, uint32_t *src, uint32_t *size, uint32_t *code, uint64_t *data0);
+
+static __inline__ int fmn_level_int_type(uint64_t outq_config)
+{
+	return xlp_get_field_dw(outq_config, 54, 2);
+}
+
+static __inline__ int fmn_level_int_val(uint64_t outq_config)
+{
+	return xlp_get_field_dw(outq_config, 56, 3);
+}
+
+extern int get_dom_fmn_node_ownership(void *fdt, int dom_id);
+extern void nlm_hal_fmn_init(void *fdt, int node);
+extern void nlm_hal_set_fmn_interrupt(int irq);
+
+extern void nlm_hal_disable_vc_intr(int node, int vc);
+extern void nlm_hal_enable_vc_intr(int node, int vc);
+
+#endif /* #ifndef _NLH_FMN_H */
+
+	
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h
new file mode 100644
index 0000000..13c4239
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_macros.h
@@ -0,0 +1,1334 @@
+
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * http://www.gnu.org/licenses/gpl-2.0.txt  
+ * or the Broadcom license below:
+
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_4# */
+
+#ifndef _NLM_HAL_MACROS_H
+#define _NLM_HAL_MACROS_H
+
+#ifndef __ASSEMBLY__
+extern unsigned long xlp_io_base;
+extern unsigned long xlp_fmn_base[];
+extern unsigned long xlp_nae_base[];
+extern unsigned long xlp_mac_base[];
+extern unsigned long xlp_poe_base_pcie[];
+extern unsigned long xlp_poe_base_pcim[];
+extern unsigned long xlp_sys_base[];
+
+extern int nlm_chip_is_xlp3xx;
+extern unsigned long xlp_regex_base_pcie;
+extern unsigned long xlp_regex_base_pcim;
+
+
+#ifndef is_nlm_xlp8xx
+extern int is_nlm_xlp(unsigned int chipid, unsigned int rev, unsigned int ext);
+
+#define XLP_REVISION_ANY 0xFF
+#define is_nlm_xlp8xx()      (is_nlm_xlp(0x8000, XLP_REVISION_ANY, 0) || is_nlm_xlp(0x4000, XLP_REVISION_ANY, 0))
+#endif /* is_nlm_xlp8xx */
+
+#endif /* #ifndef __ASSEMBLY__ */
+
+
+#if defined(NLM_HAL_LINUX_USER) /* Linux User mode */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <unistd.h>
+#include <inttypes.h>
+
+#define nlm_print printf
+#define nlm_malloc malloc
+#define nlm_free  free
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
+    (_MIPS_SZLONG == 32)
+#define KSEG0     0x80000000UL
+#define KSEG1     0xA0000000UL
+#define KSEG2     0xC0000000UL
+#define KSEG3     0xE0000000UL
+#define KSEG0_PHY_BOUNDARY 0x10000000UL    /* 256 MB */
+#else
+#define KSEG0     (0xffffffff80000000ULL)
+#define KSEG1     (0xffffffffA0000000ULL)
+#define KSEG2     (0xffffffffC0000000ULL)
+#define KSEG3     (0xffffffffE0000000ULL)
+#define KSEG0_PHY_BOUNDARY 0x10000000ULL    /* 256 MB */
+#endif
+
+
+/* Adding a new macro for mdelay.  */
+#define nlm_udelay(n) 	usleep(n)
+#define nlm_mdelay(n) 	usleep(n * 1000) 
+				        
+
+#elif defined(NLM_HAL_LINUX_KERNEL) /* Linux Kenrel mode */
+
+#include <asm/mipsregs.h>
+#ifndef __ASSEMBLY__
+#include <linux/version.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/delay.h>
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(3,0,0))
+#include <linux/slab.h>
+#include <asm/atomic.h>
+#endif
+
+#define nlm_print printk
+#define nlm_malloc(size) kmalloc((size), GFP_KERNEL)
+#define nlm_free  kfree
+
+static inline unsigned long nlm_spill_alloc(int node, uint64_t size)
+{
+        struct page *pg;
+        pg = alloc_pages_exact_node(node, GFP_KERNEL, get_order(size));
+	if (pg == NULL) {
+		nlm_print("Spill Mem allocation on node %d failed \n", node);
+		return 0;
+	}
+        return page_to_phys(pg);
+}
+
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
+    (_MIPS_SZLONG == 32)
+#ifndef KSEG0
+#define KSEG0     0x80000000UL
+#endif
+#ifndef KSEG1
+#define KSEG1     0xA0000000UL
+#endif
+#ifndef KSEG2
+#define KSEG2     0xC0000000UL
+#endif
+#ifndef KSEG3
+#define KSEG3     0xE0000000UL
+#endif
+#define KSEG0_PHY_BOUNDARY 0x10000000UL    /* 256 MB */
+#else
+#define KSEG0     (0xffffffff80000000ULL)
+#define KSEG1     (0xffffffffA0000000ULL)
+#define KSEG2     (0xffffffffC0000000ULL)
+#define KSEG3     (0xffffffffE0000000ULL)
+#define KSEG0_PHY_BOUNDARY 0x10000000ULL    /* 256 MB */
+#endif
+#define nlm_mdelay(n) mdelay(n)
+
+#define nlm_udelay(n)	udelay(n)
+#define nlm_mdelay(n)  	mdelay(n)
+
+#endif /* __ASSEMBLY__ */
+
+#elif defined(NLM_HAL_NETOS) /* Netos */
+
+#ifndef __ASSEMBLY__
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <inttypes.h>
+
+#define nlm_print printf
+#define nlm_malloc malloc
+#define nlm_free  free
+#define nlm_udelay(x)	_netos_delay(x) /* Temporary implementation for netos-hyperex */
+#define nlm_mdelay(n) 	nlm_udelay(n * 1000)
+static __inline__ void _netos_delay(unsigned int x)
+{
+        unsigned long int i;
+
+        /* compilers beyond gcc 4.0 will remove off tight loops
+         * when optimization is enabled. This asm call is
+         * supposedly the standard way to work around this.
+         */
+        for (i = 0; i<(1000 * x) ; i++)
+                __asm__ __volatile__ ("");
+}
+#endif /* __ASSEMBLY__ */
+
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
+    (_MIPS_SZLONG == 32)
+#define KSEG0     0x80000000
+#define KSEG1     0xA0000000
+#define KSEG2     0xC0000000
+#define KSEG3     0xE0000000
+#define KSEG0_PHY_BOUNDARY 0x10000000    /* 256 MB */
+#else
+#define KSEG0     (0xffffffff80000000)
+#define KSEG1     (0xffffffffA0000000)
+#define KSEG2     (0xffffffffC0000000)
+#define KSEG3     (0xffffffffE0000000)
+#define KSEG0_PHY_BOUNDARY 0x10000000    /* 256 MB */
+#endif
+
+#elif defined(NLM_HAL_UBOOT) /* u-boot */
+
+#include <common.h>
+#include <command.h>
+#include <malloc.h>
+
+#define nlm_print printf
+#define nlm_malloc malloc
+#define nlm_free  free
+#define nlm_udelay(n)	udelay(n)
+#define nlm_mdelay(n) 	udelay(n * 1000)
+
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
+    (_MIPS_SZLONG == 32)
+#define KSEG0     0x80000000UL
+#define KSEG1     0xA0000000UL
+#define KSEG2     0xC0000000UL
+#define KSEG3     0xE0000000UL
+#define KSEG0_PHY_BOUNDARY 0x10000000UL    /* 256 MB */
+#else
+#define KSEG0     (0xffffffff80000000ULL)
+#define KSEG1     (0xffffffffA0000000ULL)
+#define KSEG2     (0xffffffffC0000000ULL)
+#define KSEG3     (0xffffffffE0000000ULL)
+#define KSEG0_PHY_BOUNDARY 0x10000000ULL    /* 256 MB */
+#endif
+
+#elif defined(NLM_HAL_XLOADER) /* x-loader */
+#include <common.h>
+#define KSEG0     0x80000000UL
+#define KSEG1     0xA0000000UL
+#define KSEG2     0xC0000000UL
+#define KSEG3     0xE0000000UL
+#define KSEG0_PHY_BOUNDARY 0x10000000UL    /* 256 MB */
+
+#elif defined(NLM_HAL_NETLBOOT) /* netlboot */
+#include <printk.h>
+
+#define nlm_print printk
+#define nlm_malloc malloc
+#define nlm_free  free
+#define nlm_udelay(n)	udelay(n)
+#define nlm_mdelay(n) 	mdelay(n)
+
+#else
+#error "Unsupported platform for NL HAL"
+#endif	/* NLM_HAL_LINUX_USER */
+
+#define CCA_UNCACHED  2
+#define CCA_CACHED    3
+
+#define CRC_POLY_REG_0_SEL 0
+#define CRC_POLY_REG_1_SEL 1
+#define CRC_POLY_REG_2_SEL 2
+#define CRC_POLY_REG_3_SEL 3
+
+#define CRC_ENDIAN_BIT 5
+#define CRC_FLIPBITS_BIT 4
+#define CRC_DESTINATION_BIT 6
+
+#define CRC_32_INIT_VALUE 0xffffffff
+#define CRC_16_INIT_VALUE 0
+
+/*
+ * Memory segments (64bit kernel mode addresses)
+ */
+/* XLP_MERGE_TODO */
+#define NLH_XKUSEG			0x0000000000000000
+#define NLH_XKSSEG			0x4000000000000000
+#ifdef CONFIG_64BIT
+#define NLH_XKPHYS                      0x8000000000000000
+#else
+#define NLH_XKPHYS			0x8000000000000000ULL
+#endif
+#define NLH_XKPHYS_UNCACHED             0x9000000000000000ULL
+#define NLH_XKSEG			0xc000000000000000
+#define NLH_CKSEG0			0xffffffff80000000
+#define NLH_CKSEG1			0xffffffffa0000000
+#define NLH_CKSSEG			0xffffffffc0000000
+#define NLH_CKSEG3			0xffffffffe0000000
+
+#define SET_MIPS64 .set mips64r2
+#define NLM_HAL_THREAD_SIZE (8 << 10)
+
+/* For hal internal debug */
+#define nlm_hal_dbg_msg(fmt, args...) nlm_print(fmt, ##args)
+
+#ifndef __STR
+#define __STR(x) #x
+#endif
+#ifndef STR
+#define STR(x) __STR(x)
+#endif
+
+#ifndef __ASSEMBLY__
+#define XLP_BIT_MASK_W(size) ((1 << (size)) - 1)
+#define XLP_BIT_MASK_DW(size) (((unsigned long long) 1 << size) - 1)
+
+#define enable_KX(flags)       \
+ __asm__ __volatile__ (        \
+        ".set push\n"          \
+        ".set noat\n"          \
+        ".set noreorder\n"     \
+        "mfc0 %0, $12\n\t"     \
+        "ori $1, %0, 0x81\n\t" \
+        "xori $1, 1\n\t"       \
+        "mtc0 $1, $12\n"       \
+        ".set pop\n"           \
+        : "=r"(flags) );
+
+#define disable_KX(flags)   \
+ __asm__ __volatile__ (     \
+        ".set push\n"       \
+        "mtc0 %0, $12\n"    \
+        ".set pop\n"        \
+        : : "r"(flags) )
+
+#ifdef CONFIG_64BIT
+static __inline__ uint8_t lb_40bit_phys(uint64_t phys, int cca)
+{
+        uint8_t value = 0;
+
+        __asm__ __volatile__(".set push\n"
+                             ".set noreorder\n"
+                             ".set mips64\n"
+                             "dli   $8, " STR(NLH_XKPHYS) "\n"
+                             "or    $8, $8, %2\n"
+                             "daddu $8, $8, %1\n"
+                             "lb    %0, 0($8) \n" 
+			     ".set pop\n":"=r"(value)
+                             :"r"(phys & 0xffffffffffULL),
+                             "r"((uint64_t) cca << 59)
+                             :"$8");
+
+        return value;
+}
+
+static __inline__ uint16_t lh_40bit_phys(uint64_t phys, int cca)
+{
+	uint16_t value = 0;
+
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     ".set mips64\n"
+			     "dli   $8, " STR(NLH_XKPHYS) "\n"
+			     "or    $8, $8, %2\n"
+			     "daddu $8, $8, %1\n"
+			     "lhu    %0, 0($8) \n"
+			     ".set pop\n"
+			     :"=r"(value)
+			     :"r"(phys & 0xfffffffffeULL),"r"((uint64_t) cca << 59)
+			     :"$8");
+
+	return value;
+}
+
+static __inline__ uint64_t lw_40bit_phys(uint64_t phys, int cca)
+{
+	uint64_t value = 0;
+
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     ".set mips64\n"
+			     "dli   $8, " STR(NLH_XKPHYS) "\n"
+			     "or    $8, $8, %2\n"
+			     "daddu $8, $8, %1\n"
+			     "lw    %0, 0($8) \n"
+			     ".set pop\n"
+			     :"=r"(value)
+			     :"r"(phys & 0xfffffffffcULL),"r"((uint64_t) cca << 59)
+			     :"$8");
+
+	return value;
+}
+static __inline__ uint64_t ld_40bit_phys(uint64_t phys, int cca)
+{
+	uint64_t value = 0;
+
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     ".set mips64\n"
+			     "dli   $8, " STR(NLH_XKPHYS) "\n"
+			     "or    $8, $8, %2\n"
+			     "daddu $8, $8, %1\n"
+			     "ld    %0, 0($8) \n"
+			     ".set pop\n"
+			     :"=r"(value)
+			     :"r"(phys & 0xfffffffff8ULL),"r"((uint64_t) cca << 59)
+			     :"$8");
+
+	return value;
+}
+#else
+
+static __inline__ uint8_t lb_40bit_phys(uint64_t phys, int cca)
+{
+        uint8_t value = 0;
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xffffffffffULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "lb %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :"=r"(value)
+                        :"r"(low), "r"(high)
+                        :"$1");
+
+        disable_KX(flags);
+
+        return value;
+}
+
+static __inline__ uint16_t lh_40bit_phys(uint64_t phys, int cca)
+{
+        uint16_t value = 0;
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xfffffffffeULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "lhu %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :"=r"(value)
+                        :"r"(low), "r"(high)
+                        :"$1");
+
+        disable_KX(flags);
+
+        return value;
+}
+
+static __inline__ uint32_t lw_40bit_phys(uint64_t phys, int cca)
+{
+        uint32_t value = 0;
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xfffffffffcULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "lw %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :"=r"(value)
+                        :"r"(low), "r"(high)
+                        :"$1");
+
+        disable_KX(flags);
+
+        return value;
+}
+
+static __inline__ uint64_t ld_40bit_phys(uint64_t phys, int cca)
+{
+        uint32_t lsw, msw, high, low;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xfffffffff8ULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low  = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %3, 0\n"
+                        "dsll32 %2, 0    \n"
+                        "dsrl32 %2, 0    \n"
+                        "or $1, $1, %2   \n"
+                        "ld $1, 0($1)    \n"
+                        "dsrl32 %1, $1 ,0\n"
+                        "dsll32 $1, $1 ,0\n"
+                        "dsrl32 %0, $1 ,0\n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :"=r"(lsw), "=r"(msw)
+                        :"r"(low),  "r"(high)
+                        :"$1");
+
+        disable_KX(flags);
+        return (((unsigned long long)msw << 32) | lsw);
+}
+
+#endif /* #ifdef CONFIG_64BIT */
+
+static __inline__ uint8_t lb_40bit_phys_uncached(uint64_t phys)
+{
+        return lb_40bit_phys(phys, CCA_UNCACHED);
+}
+
+static __inline__  uint8_t lb_40bit_phys_cached(uint64_t phys)
+{
+        return lb_40bit_phys(phys, CCA_CACHED);
+}
+
+static __inline__ uint16_t lh_40bit_phys_uncached(uint64_t phys)
+{
+        return lh_40bit_phys(phys, CCA_UNCACHED);
+}
+
+static __inline__  uint16_t lh_40bit_phys_cached(uint64_t phys)
+{
+        return lh_40bit_phys(phys, CCA_CACHED);
+}
+
+static __inline__ uint32_t lw_40bit_phys_uncached(uint64_t phys)
+{
+	return lw_40bit_phys(phys, CCA_UNCACHED);
+}
+static __inline__ uint32_t lw_40bit_phys_cached(uint64_t phys)
+{
+	return lw_40bit_phys(phys, CCA_CACHED);
+}
+static __inline__ uint64_t ld_40bit_phys_uncached(uint64_t phys)
+{
+	return ld_40bit_phys(phys, CCA_UNCACHED);
+}
+static __inline__ uint64_t ld_40bit_phys_cached(uint64_t phys)
+{
+	return ld_40bit_phys(phys, CCA_CACHED);
+}
+
+#ifdef CONFIG_64BIT
+static __inline__ void sb_40bit_phys(uint64_t phys, int cca, uint8_t value)
+{
+  __asm__ __volatile__(".set push\n"
+                       ".set noreorder\n"
+                       ".set mips64\n"
+                       "dli   $8, "STR(NLH_XKPHYS)"\n"
+                       "or    $8, $8, %2\n"
+                       "daddu $8, $8, %1\n"
+                       "sb    %0, 0($8) \n"
+                       ".set pop\n"
+                       :
+                       : "r"(value), "r"(phys & 0xffffffffffULL), "r"((uint64_t)cca << 59)
+                       : "$8"
+          );
+}
+static __inline__ void sh_40bit_phys(uint64_t phys, int cca, uint32_t value)
+{
+  __asm__ __volatile__(".set push\n"
+                       ".set noreorder\n"
+                       ".set mips64\n"
+                       "dli   $8, "STR(NLH_XKPHYS)"\n"
+                       "or    $8, $8, %2\n"
+                       "daddu $8, $8, %1\n"
+                       "sh    %0, 0($8) \n"
+                       ".set pop\n"
+                       :
+                       : "r"(value), "r"(phys & 0xfffffffffeULL), "r"((uint64_t)cca << 59)
+                       : "$8"
+	  );
+}
+static __inline__ void sw_40bit_phys(uint64_t phys, int cca, uint32_t value)
+{
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     ".set mips64\n"
+			     "dli   $8, " STR(NLH_XKPHYS) "\n"
+			     "or    $8, $8, %2\n"
+			     "daddu $8, $8, %1\n"
+			     "sw    %0, 0($8) \n"
+			     ".set pop\n"
+			     :
+			     :"r"(value), "r"(phys & 0xfffffffffcULL), "r"((uint64_t) cca << 59)
+			     :"$8"
+		);
+}
+static __inline__ void sd_40bit_phys(uint64_t phys, int cca, uint64_t value)
+{
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     ".set mips64\n"
+			     "dli   $8, " STR(NLH_XKPHYS) "\n"
+			     "or    $8, $8, %2\n"
+			     "daddu $8, $8, %1\n"
+			     "sd    %0, 0($8) \n"
+			     ".set pop\n"
+			     :
+			     :"r"(value), "r"(phys & 0xfffffffff8ULL), "r"((uint64_t) cca << 59)
+			     :"$8"
+		);
+}
+
+#else
+
+static __inline__ void sb_40bit_phys(uint64_t phys, int cca, uint8_t value)
+{
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xffffffffffULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "sb %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :
+                        :"r"(value), "r"(low), "r"(high)
+                        :"$1");
+        disable_KX(flags);
+}
+
+static __inline__ void sh_40bit_phys(uint64_t phys, int cca, uint16_t value)
+{
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xfffffffffeULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "sh %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :
+                        :"r"(value), "r"(low), "r"(high)
+                        :"$1");
+        disable_KX(flags);
+}
+
+static __inline__ void sw_40bit_phys(uint64_t phys, int cca, uint32_t value)
+{
+        uint32_t low, high;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+
+        phys &= 0xfffffffffcULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "sw %0, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :
+                        :"r"(value), "r"(low), "r"(high)
+                        :"$1");
+        disable_KX(flags);
+}
+
+static __inline__ void sd_40bit_phys(uint64_t phys, int cca, uint64_t value)
+{
+        uint32_t lsw, msw, high, low;
+        uint64_t cca64 = ((uint64_t)cca << 59);
+        unsigned long flags;
+        phys &= 0xfffffffff8ULL;
+        phys |= (NLH_XKPHYS | cca64);
+        low  = (uint32_t) phys & 0xffffffff;
+        high = (uint32_t) (phys >> 32);
+        lsw  = (uint32_t) value  & 0xffffffff;
+        msw  = (uint32_t)(value >>32);
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %3, 0\n"
+                        "dsll32 %2, 0    \n"
+                        "dsrl32 %2, 0    \n"
+                        "or $1, $1, %2   \n"
+                        "dsll32 $8, %1, 0\n"
+                        "dsll32 %0, 0   \n"
+                        "dsrl32 %0, 0   \n"
+                        "or $8, $8, %0   \n"
+                        "sd $8, 0($1)    \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :
+                        : "r"(lsw), "r"(msw), "r"(low), "r"(high)
+                        :"$1", "$8");
+        disable_KX(flags);
+}
+
+#endif /* #ifdef CONFIG_64BIT */
+
+static __inline__ void sb_40bit_phys_uncached(uint64_t phys, uint8_t value)
+{
+      sb_40bit_phys(phys, CCA_UNCACHED, value);
+}
+static __inline__ void sb_40bit_phys_cached(uint64_t phys, uint8_t value)
+{
+      sb_40bit_phys(phys, CCA_CACHED, value);
+}
+
+static __inline__ void sh_40bit_phys_uncached(uint64_t phys, uint16_t value)
+{
+      sh_40bit_phys(phys, CCA_UNCACHED, value);
+}
+static __inline__ void sh_40bit_phys_cached(uint64_t phys, uint16_t value)
+{
+      sh_40bit_phys(phys, CCA_CACHED, value);
+}
+
+static __inline__ void sw_40bit_phys_uncached(uint64_t phys, uint32_t value)
+{
+	sw_40bit_phys(phys, CCA_UNCACHED, value);
+}
+static __inline__ void sw_40bit_phys_cached(uint64_t phys, uint32_t value)
+{
+	sw_40bit_phys(phys, CCA_CACHED, value);
+}
+static __inline__ void sd_40bit_phys_uncached(uint64_t phys, uint64_t value)
+{
+	sd_40bit_phys(phys, CCA_UNCACHED, value);
+}
+static __inline__ void sd_40bit_phys_cached(uint64_t phys, uint64_t value)
+{
+	sd_40bit_phys(phys, CCA_CACHED, value);
+}
+
+        
+#define enable_ELPA()           \
+ __asm__ __volatile__ (         \
+        ".set push\n"           \
+        ".set noat\n"           \
+        ".set noreorder\n"      \
+        "mfc0 $8, $5, 1\n"      \
+        "li $9, 0x20000000\n"   \
+        "or $8, $8, $9\n"       \
+        "mtc0 $8, $5, 1\n"      \
+        ".set pop\n"            \
+        :  :  :"$8", "$9")                      
+
+
+/*
+ *  COP2 Reg access macros
+ */
+#define _read_32bit_cp2_register(source)                        \
+({ int __res;                                                   \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        "mfc2\t%0,"STR(source)"\n\t"                            \
+	".set\tpop"						\
+        : "=r" (__res));                                        \
+        __res;})
+
+#define _write_32bit_cp2_register(register,value)               \
+        __asm__ __volatile__(                                   \
+        "mtc2\t%0,"STR(register)"\n\t"				\
+	"nop"							\
+        : : "r" (value));
+
+#define _read_32bit_cp2_register_sel(source, sel)               \
+({ int __res;                                                   \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips32\n\t"                                       \
+        "mfc2\t%0,"STR(source)", %1\n\t"                        \
+	".set\tpop"						\
+        : "=r" (__res) : "i" (sel) );                           \
+        __res;})
+
+#define _write_32bit_cp2_register_sel(reg, value, sel)          \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips32\n\t"                                       \
+        "mtc2\t%0,"STR(reg)", %1\n\t"                           \
+	".set\tpop"						\
+        : : "r" (value), "i" (sel) );
+
+#ifndef _ABI64
+
+#define _read_64bit_cp2_register_sel(source, sel)                        \
+({                                                                      \
+        unsigned int high, low;                                         \
+                                                                        \
+                __asm__ __volatile__(                                   \
+                        ".set\tmips64\n\t"                              \
+                        "dmfc2\t$8, "STR(source)","STR(sel)"\n\t"       \
+                        "dsrl32\t%0, $8, 0\n\t"                         \
+                        "dsll32\t$8, $8, 0\n\t"                         \
+                        "dsrl32\t%1, $8, 0\n\t"                         \
+                        ".set\tmips0"                                   \
+                        : "=r" (high), "=r"(low): "i"(sel) : "$8");     \
+        ( (((unsigned long long)high)<<32) | low);                      \
+})
+
+#define _write_64bit_cp2_register_sel(source, val, sel)                 \
+do {                                                                    \
+     unsigned int high = val>>32;                                       \
+     unsigned int low  = val & 0xffffffff;                              \
+                __asm__ __volatile__(                                   \
+                        ".set\tmips64\n\t"                              \
+                        "dsll32 $8, %1, 0\n"                            \
+                        "dsll32 $9, %0, 0\n"                            \
+                        "dsrl32 $8, $8, 0\n"                            \
+                        "or     $8, $8, $9\n"                           \
+                        "dmtc2\t$8, "STR(source)", %2\n\t"              \
+                        ".set\tmips0"                                   \
+                        : : "r" (high), "r" (low), "i"(sel): "$8", "$9");               \
+} while (0)
+
+#define _read_64bit_cp2_register(source) \
+	_read_64bit_cp2_register_sel(source, 0)
+#define _write_64bit_cp2_register(source, val) \
+	_write_64bit_cp2_register_sel(source, val, 0)
+
+#else /* _ABI64 */
+
+#define _read_64bit_cp2_register(source)                        \
+({ unsigned long long __res;                                    \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        ".set\tmips64\n\t"                                      \
+        "dmfc2\t%0,"STR(source)"\n\t"                           \
+	".set\tpop"						\
+        : "=r" (__res));                                        \
+        __res;})
+
+#define _write_64bit_cp2_register(register,value)               \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        "dmtc2\t%0,"STR(register)"\n\t"				\
+	"nop"							\
+	".set\tpop"						\
+        : : "r" (value));
+
+#define _read_64bit_cp2_register_sel(source, sel)               \
+({ unsigned long long __res;                                    \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips64\n\t"                                       \
+        "dmfc2\t%0,"STR(source)", %1\n\t"                       \
+	".set\tpop"						\
+        : "=r" (__res) : "i" (sel) );                           \
+        __res;})
+
+#define _write_64bit_cp2_register_sel(reg, value, sel)          \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips64\n\t"                                       \
+        "dmtc2\t%0,"STR(reg)", %1\n\t"                          \
+	".set\tpop"						\
+        : : "r" (value), "i" (sel) );
+
+#endif /* _ABI64 */
+
+typedef enum crc_type {
+	NLM_CRC_32 = 0,
+	NLM_CRC_16 = 16,
+	NLM_CRC_7 = 25
+} crc_type_t;
+
+#define REG_STR(x) "$" #x
+
+#undef USE_64BIT_CRC
+#if defined(NLM_HAL_LINUX_KERNEL)
+#define USE_64BIT_CRC
+#else
+#if _MIPS_SIM != _MIPS_SIM_ABI32 && !defined(ABI_32)
+#define USE_64BIT_CRC
+#endif
+#endif /* NLM_HAL_LINUX_KERNEL */
+
+#ifdef USE_64BIT_CRC
+typedef uint64_t u_data;
+#else
+typedef uint32_t u_data;
+#endif
+
+#define INIT_CRC_POLY(poly_reg, poly_type, crc_poly) \
+({                                                            \
+    asm volatile (                                            \
+        ".set push\n"                                         \
+        ".set noat\n"                                         \
+	"dmtur %0, " REG_STR(poly_reg) "\n"                   \
+	"ehb\n"                                               \
+        ".set pop\n"                                          \
+	: : [poly] "r"((crc_poly << poly_type) & 0x00000000ffffffff)  \
+    );                                                        \
+})
+
+#ifdef USE_64BIT_CRC
+static __inline__ unsigned int
+nlm_crc32_generic(uint64_t data, unsigned int flags_len, unsigned int crc)
+{
+	unsigned int ret;
+	asm volatile (
+		".set push\n"
+		".set noreorder\n"
+		"addiu $9, %[flags_len], 0\n"
+		"dcrc   %[result], %[input], $9\n"
+		".set pop\n"
+		: [result] "=r"(ret)
+		: [input] "r"(data), [flags_len] "r"(flags_len), "0"(crc)
+		: "$9"
+	);
+	return ret;
+}
+#else
+static __inline__ unsigned int
+nlm_crc32_generic(unsigned int data, unsigned int flags_len, unsigned int crc)
+{
+	unsigned int ret;
+	asm volatile (
+		".set push\n"
+		".set noreorder\n"
+		"addiu $9, %[flags_len], 0\n"
+		"crc   %[result], %[input], $9\n"
+		".set pop\n"
+		: [result] "=r"(ret)
+		: [input] "r"(data), [flags_len] "r"(flags_len), "0"(crc)
+		: "$9"
+	);
+	return ret;
+}
+#endif
+
+static __inline__ uint32_t
+bit_flip(uint32_t t)
+{
+	unsigned int ret = 0, x = t;
+
+    asm volatile (
+	    ".set push\n"
+	    ".set mips32\n"
+	    ".set noreorder\n"
+	    "addiu   %[ret], $0, 0\n"
+	 "1: addiu   $9, $0, 32\n"
+	    "clz     $8, %[val]\n"
+	    "beq     $8, $9, 3f\n"
+
+	    /* set the bit in the correct location of result */
+	    "addiu   $9, $0, 1\n"
+	    "sllv    $9, $9, $8\n"
+	    "or      %[ret], %[ret], $9\n"
+
+	    /* reset the bit in the data */
+	    "addiu   $9, $0, 31\n"
+	    "subu    $9, $9, $8\n"
+	    "addiu   $8, $0, 1\n"
+	    "sllv    $9, $8, $9\n"
+	    "xor     %[val], %[val], $9\n"
+	    "b       1b\n"
+	    ".set pop\n"
+	    "3: nop\n"
+	    : [ret] "=&r"(ret) : [val] "r"(x)
+	    :"$8", "$9"
+	    );
+    return ret;
+}
+
+static __inline__ unsigned int
+nlm_crc32_word(int crc_reg, u_data data, unsigned int len,
+	   unsigned int crc_init)
+{
+	/* flip bit */
+	unsigned int flags_len = (1 << CRC_FLIPBITS_BIT) | (1 << CRC_DESTINATION_BIT);
+
+	/* set length and CRC poly reg */
+	flags_len |= ((len & 0x7) |
+		      ((crc_reg & 0x3) << 8));
+
+	return nlm_crc32_generic(data, flags_len, crc_init);
+}
+
+static __inline__ uint32_t
+nlm_crc16_ibm(int crc_reg, u_data data, unsigned int len,
+	  unsigned short crc_init)
+{
+	/* flip bit */
+	unsigned int flags_len = (1 << CRC_FLIPBITS_BIT) | (1 << CRC_DESTINATION_BIT);
+
+	/* set length and CRC poly reg */
+	flags_len |= ((len & 0x7) |
+		      ((crc_reg & 0x3) << 8));
+
+	return  nlm_crc32_generic(data, flags_len, crc_init);
+}
+
+static __inline__ uint32_t
+nlm_crc7_word(int crc_reg, u_data data, unsigned int len, unsigned short crc_init)
+{
+	/* flip bit */
+	unsigned int flags_len = (1 << CRC_FLIPBITS_BIT) | (1 << CRC_DESTINATION_BIT);
+
+	/* set length and CRC poly reg */
+	flags_len |= ((len & 0x7) |
+		      ((crc_reg & 0x3) << 8));
+
+	return  nlm_crc32_generic(data, flags_len, crc_init);
+}
+
+/**
+ * This macro loops on a string of data.  It is kept this way to
+ * adjust to endianess and use of 64bit instruction, so that each
+ * CRC function does not require ifdef.
+ */
+#ifdef USE_64BIT_CRC
+#define LOOP_ON_DATA(c, init, b, len, f) \
+({                                                                           \
+        uint64_t data;                                                       \
+	uint32_t i, rem = len, __ret = init, l;                              \
+	for(i = 0; rem > 0;) {                                               \
+                data = ((uint64_t *)buf)[i];                                 \
+      	        i += 1;                                                      \
+	        if(rem >= 8) {                                               \
+		        rem -= 8;                                            \
+		        l = 7;                                               \
+		} else if (rem == 7) {                                       \
+			rem -= 7;                                            \
+			l = 6;                                               \
+		} else if (rem == 6) {                                       \
+			rem -= 6;                                            \
+			l = 5;                                               \
+		} else if (rem == 5) {                                       \
+			rem -= 5;                                            \
+			l = 4;                                               \
+		} else if (rem == 4) {                                       \
+			rem -= 4;                                            \
+			l = 3;                                               \
+		} else if (rem == 3) {                                       \
+			rem -= 3;                                            \
+			l = 2;                                               \
+		} else if (rem == 2) {                                       \
+			rem -= 2;                                            \
+			l = 1;                                               \
+		} else if (rem == 1) {                                       \
+			rem -= 1;                                            \
+			l = 0;                                               \
+		}                                                            \
+		__ret = f(crc_reg, data, l, __ret);                          \
+	}                                                                    \
+        __ret;                                                               \
+})
+#else
+#define LOOP_ON_DATA(c, init, b, len, f) \
+({                                                                           \
+        uint32_t data;                                                       \
+	uint32_t i, rem = len, __ret = init, l;                              \
+	for(i = 0; rem > 0;) {                                               \
+		data = ((uint32_t *)buf)[i];                                 \
+                i += 1;                                                      \
+		if(rem >= 4) {                                               \
+			rem -= 4;                                            \
+			l = 3;                                               \
+		} else if (rem == 3) {                                       \
+			rem -= 3;                                            \
+			l = 2;                                               \
+		} else if (rem == 2) {                                       \
+			rem -= 2;                                            \
+			l = 1;                                               \
+		} else if (rem == 1) {                                       \
+			rem -= 1;                                            \
+			l = 0;                                               \
+		}                                                            \
+		__ret = f(crc_reg, data, l, __ret);                          \
+	}                                                                    \
+        __ret;                                                               \
+})
+#endif
+
+static __inline__ uint32_t
+nlm_crc32(int crc_reg, const unsigned char *buf, unsigned int len, unsigned int crc)
+{
+	return LOOP_ON_DATA(crc_reg, crc,
+			    buf, len, nlm_crc32_word) ^ 0xffffffff;
+}
+
+static __inline__ uint16_t
+nlm_crc16(int crc_reg, const unsigned char *buf, unsigned int len, unsigned short crc)
+{
+	return (uint16_t)(LOOP_ON_DATA(crc_reg, crc,
+				       buf, len, nlm_crc16_ibm) & 0xffff);
+}
+
+static __inline__ unsigned char
+nlm_crc7(int crc_reg, const unsigned char *buf, unsigned int len, unsigned char crc)
+{
+	return (unsigned char)(LOOP_ON_DATA(crc_reg, crc, buf,
+					    len, nlm_crc7_word) & 0x7f);
+}
+#if 0
+static __inline__ int num_ones(unsigned long mask)
+{
+	int  nones;
+
+	for (nones = 0; mask; mask >>= 1) {
+		if (mask & 0x1)
+			++nones;
+	}
+
+	return nones;
+}
+#endif
+static __inline__ void write_32bit_cfg_reg(uint32_t *base, unsigned int offset, uint32_t value)
+{
+  base[offset] = value;
+}
+static __inline__ uint32_t read_32bit_cfg_reg(uint32_t *base, unsigned int offset)
+{
+  return ((base)[offset]);
+}
+static __inline__ void write_64bit_cfg_reg(uint64_t *base, unsigned int offset, uint64_t value)
+{
+  base[offset] = value;
+}
+static __inline__ uint64_t read_64bit_cfg_reg(uint64_t *base, unsigned int offset)
+{
+  return ((base)[offset]);
+}
+
+static __inline__ uint32_t xlp_get_field_w(uint32_t word, int lsb, int size)
+{
+	return ((word >> lsb) & XLP_BIT_MASK_W(size));
+}
+static __inline__ uint64_t xlp_get_field_dw(uint64_t dword, int lsb, int size)
+{
+	return ((dword >> lsb) & XLP_BIT_MASK_DW(size));
+}
+
+
+#if !defined(NLM_HAL_LINUX_USER)
+static __inline__ int nlm_read_prid(void)
+{
+        int res = 0;
+
+        asm volatile(         \
+                ".set push\n"           \
+                ".set noat\n"           \
+                ".set noreorder\n"      \
+                "mfc0 %0, $15, 0\n"      \
+                ".set pop\n"            \
+                : "=r" (res));
+
+        return res;
+}
+
+#else
+#define nlm_read_prid 			nlm_uaccess_processor_id
+#endif
+
+static __inline__ uint32_t nlm_read_ebase(void)
+{
+        uint32_t res = 0;
+
+        asm volatile(         \
+                ".set push\n"           \
+                ".set noat\n"           \
+                ".set noreorder\n"      \
+                "mfc0 %0, $15, 1\n"      \
+                ".set pop\n"            \
+                : "=r" (res));
+
+        return res;
+}
+
+
+/* Linux User Mode */
+#if defined(NLM_HAL_LINUX_USER)
+#include <nlm_uaccess.h>
+#define nlh_read_cfg_reg16(addr)       nlm_uaccess_mem_read16((NLH_XKPHYS_UNCACHED | (addr)))
+#define nlh_write_cfg_reg16(addr, val) nlm_uaccess_mem_write16((NLH_XKPHYS_UNCACHED | (addr)), (val))
+#define nlh_read_cfg_reg32(addr)       nlm_uaccess_mem_read32((NLH_XKPHYS_UNCACHED | (addr)))
+#define nlh_write_cfg_reg32(addr, val) nlm_uaccess_mem_write32((NLH_XKPHYS_UNCACHED | (addr)), (val))
+#define nlh_read_cfg_reg64(addr)       nlm_uaccess_mem_read64((NLH_XKPHYS_UNCACHED | (addr)))
+#define nlh_write_cfg_reg64(addr, val) nlm_uaccess_mem_write64((NLH_XKPHYS_UNCACHED | (addr)), (val))
+
+/* For Accessing Regex Registers in PCI Memory space */
+#define WRITE_REGX_CFG_REG_PCIM(reg, val)       nlh_write_cfg_reg32((xlp_regex_base_pcim + reg), (val))
+#define READ_REGX_CFG_REG_PCIM(reg)             nlh_read_cfg_reg32((xlp_regex_base_pcim + reg))
+
+#define nlh_send_msg4(dst, code, data0, data1, data2, data3) \
+  nlm_uaccess_msgsnd_4(code, dst, data0, data1, data2, data3)
+
+#define nlh_send_msg3(dst, code, data0, data1, data2) \
+  nlm_uaccess_msgsnd_3(code, dst, data0, data1, data2)
+
+#define nlh_send_msg2(dst, code, data0, data1) \
+  nlm_uaccess_msgsnd_2(code, dst, data0, data1)
+
+#define nlh_send_msg1(dst, code, data0) \
+  nlm_uaccess_msgsnd_1(code, dst, data0)
+
+/* Returns 1 on failure and 0 on success */
+#define nlh_recv_msg2(dst, src, size, code, data0, data1)	\
+  nlm_uaccess_msgrcv_2(dst, src, size, code, data0, data1)
+
+#define nlh_recv_msg1(dst, src, size, code, data0)	\
+  nlm_uaccess_msgrcv_1(dst, src, size, code, data0)
+
+/* NETOS and Linux Kernel Mdoe */
+#elif defined(NLM_HAL_NETOS) || defined(NLM_HAL_LINUX_KERNEL) \
+	|| defined(NLM_HAL_UBOOT) || defined(NLM_HAL_NETLBOOT) || defined(NLM_HAL_XLOADER)
+
+#define nlh_read_cfg_reg16(addr)       lh_40bit_phys_uncached(addr)
+#define nlh_write_cfg_reg16(addr, val) sh_40bit_phys_uncached(addr, val)
+#define nlh_read_cfg_reg32(addr)       lw_40bit_phys_uncached(addr)
+#define nlh_write_cfg_reg32(addr, val) sw_40bit_phys_uncached(addr, val)
+#define nlh_read_cfg_reg64(addr)       ld_40bit_phys_uncached(addr)
+#define nlh_write_cfg_reg64(addr, val) sd_40bit_phys_uncached(addr, val)
+
+
+#define nlh_send_msg4(dst, code, data0, data1, data2, data3) \
+  xlp_message_send_4(dst, code, data0, data1, data2, data3)
+
+#define nlh_send_msg3(dst, code, data0, data1, data2) \
+  xlp_message_send_3(dst, code, data0, data1, data2)
+
+#define nlh_send_msg2(dst, code, data0, data1) \
+  xlp_message_send_2(dst, code, data0, data1)
+
+#define nlh_send_msg1(dst, code, data0) \
+  xlp_message_send_1(dst, code, data0)
+
+#define nlh_recv_msg2(dst, src, size, code, data0, data1) \
+  xlp_message_receive_2(dst, src, size, code, data0, data1)
+
+#define nlh_recv_msg1(dst, src, size, code, data0) \
+  xlp_message_receive_1(dst, src, size, code, data0)
+
+#else
+#error "Unsupported platform for NL HAL"
+
+#endif
+
+#if !defined(NLM_HAL_LINUX_USER)
+static __inline__ uint32_t nlm_hard_cpuid(void)
+{
+	return nlm_read_ebase() & 0x3ff;
+}
+#else
+#define nlm_hard_cpuid			nlm_uaccess_hard_cpuid
+#endif
+
+static __inline__ uint32_t nlm_node_id(void)
+{
+	if (is_nlm_xlp8xx())
+		return (nlm_hard_cpuid() >> 5) & 0x3;
+	return 0;
+}
+
+static __inline__ uint32_t nlm_cpu_id(void)
+{
+	return nlm_hard_cpuid() & 0x1f;
+}
+
+#else  /* __ASSEMBLY__ */
+
+#if (_MIPS_SIM == _MIPS_SIM_ABI32) || (_MIPS_SIM == _MIPS_SIM_NABI32) || \
+    (_MIPS_SZLONG == 32)
+#define LW lw
+#define LA la
+#define SW sw
+#else
+#define LW ld
+#define LA dla
+#define SW sd
+#endif
+
+
+#endif /* __ASSEMBLY__ */
+
+
+#endif /* #ifndef _NLM_HAL_MACROS_H */
+
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h
new file mode 100644
index 0000000..94f18ad
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_nae.h
@@ -0,0 +1,619 @@
+
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * http://www.gnu.org/licenses/gpl-2.0.txt  
+ * or the Broadcom license below:
+
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_4# */
+
+
+#ifndef _NLM_HAL_NAE_H_
+#define _NLM_HAL_NAE_H_
+#ifdef NLM_LINUX_KERNEL
+#include <linux/netdevice.h>
+#endif
+#include "nlm_hal.h"
+
+#define NUM_DIST_VEC 		16
+#define NUM_WORDS_PER_DV 	16
+#define MAX_DV_TBL_ENTRIES (NUM_DIST_VEC * NUM_WORDS_PER_DV)
+
+#define XLP_3XX_MAX_PORTS	8
+#define XLP_2XX_MAX_PORTS	8
+#define XLP_MAX_PORTS		18
+
+#define NAE_RECV_NONE          	0x00000000
+#define NAE_RECV_RX            	0x00000001
+#define NAE_RECV_TXC           	0x00000002
+#define NAE_RECV_UNKNOWN       	0x80000000
+#define NULL_VFBID             	127
+#define MAX_NAE_CONTEXTS       	524
+#define XLP8XX_MAX_NAE_COMPLEX 	5
+#define MAX_CAL_SLOTS	       	64
+#define MAX_VFBID_ENTRIES	128
+
+#define XLP_MAX_FLOWS       (64 << 10)
+
+#define SGMII_CAL_SLOTS         3
+#define XAUI_CAL_SLOTS          13
+#define ILK_CAL_SLOTS           26
+
+#define MAX_PORTS_PERBLOCK	4
+#define XLP_MAX_INTERLAKEN_IF	2
+
+#define XLP3XX_MAX_NAE_FREQUENCY	250 /* in MHZ */
+#define XLP3XX_MAX_NAE_COMPLEX	2
+#define XLP3XX_MAX_NAE_CONTEXTS	64
+#define MAX_POE_CLASSES     	8
+#define MAX_POE_CLASS_CTXT_TBL_SZ ((MAX_NAE_CONTEXTS / MAX_POE_CLASSES) + 1)
+#define XLP3XX_MAX_POE_CLASS_CTXT_TBL_SZ ((XLP3XX_MAX_NAE_CONTEXTS / MAX_POE_CLASSES) + 1)
+#define XLP3XX_SGMII_PARSERSEQ_FIFO_MAX	30
+/*################################*/
+#define XLP3XX_STG2_FIFO_SZ   512
+#define XLP3XX_EH_FIFO_SZ     512
+#define XLP3XX_FROUT_FIFO_SZ  512
+#define XLP3XX_MS_FIFO_SZ     512
+#define XLP3XX_PKT_FIFO_SZ    8192
+#define XLP3XX_PKTLEN_FIFO_SZ 512
+
+#define XLP3XX_MAX_STG2_OFFSET           0x7F
+#define XLP3XX_MAX_EH_OFFSET             0x1f
+#define XLP3XX_MAX_FREE_OUT_OFFSET       0x1f
+#define XLP3XX_MAX_MS_OFFSET             0xF
+#define XLP3XX_MAX_PMEM_OFFSET           0x7FE
+
+
+#define XLP3XX_STG1_2_CREDIT     XLP3XX_STG2_FIFO_SZ
+#define XLP3XX_STG2_EH_CREDIT    XLP3XX_EH_FIFO_SZ
+#define XLP3XX_STG2_FROUT_CREDIT XLP3XX_FROUT_FIFO_SZ
+#define XLP3XX_STG2_MS_CREDIT    XLP3XX_MS_FIFO_SZ
+
+/*################################*/
+
+/*################################*/
+#define XLP8XX_STG2_FIFO_SZ   2048
+#define XLP8XX_EH_FIFO_SZ     4096
+#define XLP8XX_FROUT_FIFO_SZ  4096
+#define XLP8XX_MS_FIFO_SZ     2048
+#define XLP8XX_PKT_FIFO_SZ    16384
+#define XLP8XX_PKTLEN_FIFO_SZ 2048
+
+#define XLP8XX_MAX_STG2_OFFSET           0x7F
+#define XLP8XX_MAX_EH_OFFSET           	 0x7F
+#define XLP8XX_MAX_FREE_OUT_OFFSET       0x7F
+#define XLP8XX_MAX_MS_OFFSET             0x14
+#define XLP8XX_MAX_PMEM_OFFSET           0x7FE
+
+#define XLP8XX_STG1_2_CREDIT     XLP8XX_STG2_FIFO_SZ
+#define XLP8XX_STG2_EH_CREDIT    XLP8XX_EH_FIFO_SZ
+#define XLP8XX_STG2_FROUT_CREDIT XLP8XX_FROUT_FIFO_SZ
+#define XLP8XX_STG2_MS_CREDIT    XLP8XX_MS_FIFO_SZ
+
+#define XLP_FREEIN_SPILL_DEFAULT_MEM_ADDR (252ULL << 20)
+#define XLP_FREEIN_SPILL_DEFAULT_MEM_SIZE (4ULL << 20)
+
+/*################################*/
+
+struct nae_complex_config {
+	uint32_t num_free_desc[MAX_PORTS_PERBLOCK];
+	uint32_t free_desc_size[MAX_PORTS_PERBLOCK];
+	uint32_t intf_fifo_size[MAX_PORTS_PERBLOCK];
+	uint32_t prsr_seq_fifo_size[MAX_PORTS_PERBLOCK];
+	uint32_t rx_buf_size[MAX_PORTS_PERBLOCK];
+	uint32_t ucore_mask[MAX_PORTS_PERBLOCK];	
+	uint32_t ext_phy_addr[MAX_PORTS_PERBLOCK];
+	uint32_t ext_phy_bus[MAX_PORTS_PERBLOCK];
+	uint32_t mgmt[MAX_PORTS_PERBLOCK];
+	uint32_t loopback[MAX_PORTS_PERBLOCK];
+	uint32_t num_channels[MAX_PORTS_PERBLOCK];
+	uint32_t num_lanes;
+	uint32_t lane_rate;
+	uint32_t higig_mode;
+	uint32_t xgmii_speed;
+	uint32_t vlan_pri_en;
+	uint32_t msec_port_enable;
+};
+
+
+struct poe_statistics {
+	uint64_t ooo_msg_count;
+	uint64_t inorder_msg_count;
+	uint64_t loc_stor_access_count;
+	uint64_t ext_stor_access_count;
+	uint64_t loc_stor_alloc_count;
+	uint64_t ext_stor_alloc_count;
+};
+
+
+/* Temporarily specifying these sizes here. 
+   These will be moved to FDT soon 
+*/
+
+static inline uint32_t nlm_stg2_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_STG2_FIFO_SZ;
+	}else{
+		return XLP8XX_STG2_FIFO_SZ;
+	}
+}
+
+static inline uint32_t nlm_eh_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_EH_FIFO_SZ;
+	}else{
+		return XLP8XX_EH_FIFO_SZ;
+	}
+}
+
+static inline uint32_t nlm_frout_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_FROUT_FIFO_SZ;
+	}else{
+		return XLP8XX_FROUT_FIFO_SZ;
+	}
+}
+
+static inline uint32_t nlm_ms_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_MS_FIFO_SZ;
+	}else{
+		return XLP8XX_MS_FIFO_SZ;
+	}
+}
+
+static inline uint32_t nlm_pkt_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_PKT_FIFO_SZ;
+	}else{
+		return XLP8XX_PKT_FIFO_SZ;
+	}
+}
+
+static inline uint32_t nlm_pktlen_fifo_sz(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_PKTLEN_FIFO_SZ;
+	}else{
+		return XLP8XX_PKTLEN_FIFO_SZ;
+	}
+}
+
+static inline uint32_t max_stg2_offset(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_MAX_STG2_OFFSET;
+	}else{
+		return XLP8XX_MAX_STG2_OFFSET;
+	}
+}
+
+static inline uint32_t max_eh_offset(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_MAX_EH_OFFSET;
+	}else{
+		return XLP8XX_MAX_EH_OFFSET;
+	}
+}
+
+static inline uint32_t max_free_out_offset(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_MAX_FREE_OUT_OFFSET;
+	}else{
+		return XLP8XX_MAX_FREE_OUT_OFFSET;
+	}
+}
+
+static inline uint32_t max_ms_offset(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_MAX_MS_OFFSET;
+	}else{
+		return XLP8XX_MAX_MS_OFFSET;
+	}
+}
+
+static inline uint32_t max_pmem_offset(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_MAX_PMEM_OFFSET;
+	}else{
+		return XLP8XX_MAX_PMEM_OFFSET;
+	}
+}
+
+static inline uint32_t stg1_2_credit(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_STG1_2_CREDIT;
+	}else{
+		return XLP8XX_STG1_2_CREDIT;
+	}
+}
+
+static inline uint32_t stg2_eh_credit(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_STG2_EH_CREDIT;
+	}else{
+		return XLP8XX_STG2_EH_CREDIT;
+	}
+}
+
+static inline uint32_t stg2_frout_credit(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_STG2_FROUT_CREDIT;
+	}else{
+		return XLP8XX_STG2_FROUT_CREDIT;
+	}
+}
+
+static inline uint32_t stg2_ms_credit(void)
+{
+	if(is_nlm_xlp3xx()||is_nlm_xlp2xx()){
+		return XLP3XX_STG2_MS_CREDIT;
+	}else{
+		return XLP8XX_STG2_MS_CREDIT;
+	}
+}
+
+
+/*###################################################*/
+/* To access Interface specific regs in NAE block */
+#define XLP_NAE_OFFSET(node, iface) \
+	(xlp_nae_base[node] | (((iface) & 0xf) << 9))
+
+/* To access individual gmac regs */
+#define XLP_MAC_OFFSET(node, blk, iface) \
+	(xlp_mac_base[node] + (((blk) * XLP_NA_REG_BLOCK_SIZE)) + ((iface) * XLP_NA_REG_IFACE_SIZE))
+
+#ifndef __ASSEMBLY__
+/* To access POE regs based in PCI Memory */
+
+#define nlm_hal_write_poe_pcim_reg(node, reg, val) nlm_hal_write_32bit_reg(xlp_poe_base_pcim[node], (reg), (val))
+#define nlm_hal_read_poe_pcim_reg(node, reg)   nlm_hal_read_32bit_reg(xlp_poe_base_pcim[node], (reg))
+
+/* To access POE regs based in PCIE config space */
+
+#define nlm_hal_write_poe_pcie_reg(node, reg, val) nlm_hal_write_32bit_reg(xlp_poe_base_pcie[node], (reg), (val))
+#define nlm_hal_read_poe_pcie_reg(node, reg)   nlm_hal_read_32bit_reg(xlp_poe_base_pcie[node], (reg))
+
+/* NAE */
+#define nlm_hal_write_nae_reg(node, reg, val) nlm_hal_write_32bit_reg(xlp_nae_base[node], (reg), (val))
+#define nlm_hal_read_nae_reg(node, reg) nlm_hal_read_32bit_reg(xlp_nae_base[node], (reg))
+
+#define nlm_hal_write_nae_iface_reg(node, iface, reg, val) nlm_hal_write_32bit_reg(XLP_NAE_OFFSET(node, iface), (reg), (val))
+#define nlm_hal_read_nae_iface_reg(node, iface, reg) nlm_hal_read_32bit_reg(XLP_NAE_OFFSET(node, iface), (reg))
+
+#define nlm_hal_write_ucode(node, ucore, offset, val) \
+  nlh_write_cfg_reg32((xlp_mac_base[node] + 0x10000 + (ucore * CODE_SIZE_PER_UCORE) + offset), (val))
+
+#define nlm_hal_read_ucode(node, ucore, offset) \
+  nlh_read_cfg_reg32((xlp_mac_base[node] + 0x10000 + (ucore * CODE_SIZE_PER_UCORE) + offset))
+
+#define nlm_hal_write_mac_reg(node, blk, iface, reg, val) nlm_hal_write_32bit_reg(XLP_MAC_OFFSET(node, blk, iface), (reg), (val))
+
+#define nlm_hal_read_mac_reg(node, blk, iface, reg) nlm_hal_read_32bit_reg(XLP_MAC_OFFSET(node, blk, iface), (reg))
+
+#define read_gmac_reg(node, idx, reg) nlm_hal_read_mac_reg(node, (((idx) & 0xff)>>2), ((idx) & 0x3), reg)
+#define write_gmac_reg(node, idx, reg, val) nlm_hal_write_mac_reg(node, (((idx) & 0xff)>>2), ((idx) & 0x3), (reg), (val))
+
+static __inline__ uint32_t vfbid_to_dest_map(unsigned int vfbid, unsigned int dest, int cmd) {
+	return ((dest & 0x3fff) << 16) | ((vfbid & 0x7f) << 4) | (cmd & 0x1);
+}
+
+static __inline__ uint32_t ucore_spray_config(unsigned int interface, unsigned int ucore_mask, int cmd) {
+	return ((cmd & 0x1) << 31) | ((ucore_mask & 0xffff) << 8) | (interface & 0x1f);
+}
+
+static __inline__ uint32_t poe_class_config(unsigned int table_index, unsigned int poe_class, int cmd) {
+	return ((poe_class & 0xffffff) << 8) | ((cmd & 0x1) << 7) | (table_index & 0x7f);
+}
+
+static __inline__ uint32_t flow_base_mask_config(unsigned int interface, unsigned int base, unsigned int mask, int cmd) {
+	return ((base & 0xffff) << 16) | ((cmd & 0x1) << 15) | ((mask & 0x1f) << 8) | (interface & 0x1f);
+}
+
+uint32_t nlm_hal_get_frin_total_queue(int node);
+uint32_t nlm_hal_get_frin_queue_base(int node);
+extern int nlm_hal_init_poe_distvec(int node, int vec, uint32_t cm0, uint32_t cm1, uint32_t cm2, uint32_t cm3, uint32_t vcmask);
+extern void nlm_hal_init_poe_ext_storage(int node, 
+					 uint64_t fbp_base_phys,
+					 uint64_t fbp_base_virt,
+					 uint64_t msg_base_phys,
+					 uint64_t msg_base_virt);
+
+extern int nlm_hal_load_ucore(int node, int ucore_mask, unsigned int *opcodes, int num_opcodes);
+
+extern int nlm_hal_init_if(int node, int intf_type, int  block, uint32_t *regs, int num_regs);
+extern int nlm_hal_open_if(int node, int intf_type, int  block);
+extern int nlm_hal_close_if(int node, int intf_type, int  block);
+extern void nlm_hal_init_ingress(int node, int desc_size);
+
+extern void nlm_hal_init_ext_phy(int node, int inf);
+extern void nlm_hal_ext_phy_an(int node, int inf);
+extern int  nlm_hal_status_ext_phy(int node, int inf,struct nlm_hal_mii_info *mii_info);
+extern void nlm_hal_restart_an(int node, int inf);
+
+extern int nlm_enable_poe_statistics(int node);
+extern int nlm_disable_poe_statistics(int node);
+extern int nlm_read_poe_statistics(int node, struct poe_statistics *stats);
+
+extern void nlm_hal_prepad_enable(int node, int size);
+extern void nlm_hal_reset_1588_accum(int node);
+extern void nlm_hal_1588_ld_freq_mul(int node, uint32_t ptp_inc_den, uint32_t ptp_inc_num, 
+					uint32_t ptp_inc_intg);
+extern void nlm_hal_1588_ld_offs(int node, uint32_t ptp_off_hi,  uint32_t ptp_off_lo);
+extern void nlm_hal_1588_ld_user_val(int node, uint32_t user_val_hi,  uint32_t user_val_lo);
+extern void nlm_hal_1588_ptp_clk_sel(int node, int clk_type);
+extern uint32_t nlm_hal_get_int_sts(int node);
+extern uint64_t  nlm_hal_1588_ptp_get_counter(int node, int counter);
+extern void nlm_hal_1588_ptp_set_counter(int node, int counter, uint64_t cnt_val);
+extern int nlm_hal_is_intr_1588(int node);
+extern void nlm_hal_enable_1588_intr(int node,int mask);
+extern void nlm_hal_clear_1588_intr(int node, int timer);
+
+extern void nlm_hal_set_context_xon_xoff_threshold(int node, int mtu_len);
+
+enum NAE_REG_CMD {
+        CMD_READ = 0,
+        CMD_WRITE
+};
+
+enum if_link {
+       LINK_DOWN=0,
+       LINK_UP
+};
+
+enum if_speed {
+        SPEED_10M = 0,
+        SPEED_100M,
+        SPEED_1000M
+};
+
+
+/* NETWORK INF CTRL REG */
+#define SOFTRESET(x)                        ((x) << 11)
+#define STATS_EN(x)                         ((x) << 16)
+#define TX_EN(x)                            ((x) << 2)
+#define SPEED(x)                            ((x) & 0x3)
+
+/* MAC_CONF1 */
+#define INF_SOFTRESET(x)                    ((x) << 31)
+#define INF_LOOP_BACK(x)                    ((x) << 8)
+#define INF_RX_ENABLE(x)                    ((x) << 2)
+#define INF_TX_ENABLE(x)                    (0x1)
+
+/* MAC_CONF2 */
+#define INF_PREMBL_LEN(x)                   (((x) & 0xf) << 12)
+#define INF_IFMODE(x)                       (((x) & 0x3) << 8)
+#define INF_LENCHK(x)                       ((((x) & 0x1)) << 4)
+#define INF_PADCRCEN(x)                     (((x) & 0x1) << 2)
+#define INF_PADCRC(x)                       (((x) & 0x1) << 1)
+#define INF_FULLDUP(x)                      ((x) & 0x1)
+#define TXINITIORCR(x)                      ((x) & 0x7ffff) << 8
+
+#define NAE_RX_ENABLE 0x1
+#define NAE_TX_ENABLE 0x1
+#define NAE_TX_ACE 0x2
+#define NAE_TX_COMPATIBLE 0x4
+
+#define INF_BYTE_MODE   0x2
+#define INF_NIBBLE_MODE 0x1
+
+/* PHY Access routines
+ * Internal MDIO: 0x799
+ *    -- support clause 22
+ *    -- support clause 45 with devType=0x5 only
+ * External MDIO: EXT_G0:0x79D EXT_G1:0x7A1
+ *    -- support clause 22 only
+ *    -- used for 1GE interface
+ * External MDIO: EXT_XG0:0x7A5 EXT_XG1:0x7A9
+ *    -- support clause 22
+ *    -- support clause 45 with devType as argument
+ *    -- used for 10GE interface
+ */
+enum {
+	NLM_HAL_INT_MDIO      = 0, /* Internal MDIO Clause 22 */
+	NLM_HAL_EXT_MDIO      = 1, /* EXT_G<0,1>: MDIO Clause 22 */
+	NLM_HAL_INT_MDIO_C45  = 2, /* Internal MDIO: Clause 45 */
+	NLM_HAL_EXT_MDIO_C45  = 3  /* EXT_XG<0,1>: External MDIO: Clause 45 */
+};
+
+/* MDIO reset/read/write
+ * Note: block, intf_type are going to be removed.
+ * block     = BLOCK_7  (NAE Block)
+ * intf_type = LINE_CFG (0xF)
+ */
+extern int nlm_hal_mdio_reset(int node, int type, int bus);
+extern int nlm_hal_mdio_wr(int node, int type, int bus, int phyaddr, int regidx, uint16_t val);
+extern int nlm_hal_mdio_rd(int node, int type, int bus, int phyaddr, int regidx);
+extern int nlm_hal_mdio_read(int node, int type, int bus, int block, int intf_type, int phyaddr, int regidx);
+extern int nlm_hal_mdio_write(int node, int type, int bus, int block, int intf_type, int phyaddr, int regidx, uint16_t val);
+
+
+/* External MDIO: C45 read/write */
+extern int nlm_hal_xgmac_mdio_read(int node, int bus, int phyaddr,
+        int dev_addr, int regidx);
+extern int nlm_hal_xgmac_mdio_write(int node, int bus, int phyaddr,
+        int dev_addr, int regidx, uint16_t val);
+
+extern int nlm_hal_c45_mdio_indirect_write_external(int node, int bus,
+			int phyaddr, int dev_addr, uint32_t reg_addr, uint32_t write_data);
+extern int nlm_hal_c45_mdio_indirect_read_external (int node, int bus,
+			int phyaddr, int dev_addr, uint32_t reg_addr);
+
+#define NLM_C45_WRITE(node, bus, phyaddr, dev_addr, reg_addr, wdata)	\
+   nlm_hal_c45_mdio_indirect_write_external(node, bus, phyaddr, dev_addr, reg_addr, wdata)
+
+#define NLM_C45_READ(node, bus, phyaddr, dev_addr, reg_addr)	\
+   nlm_hal_c45_mdio_indirect_read_external(node, bus, phyaddr, dev_addr, reg_addr)
+
+extern int xlp3xx_8xxb0_nae_lane_reset_txpll(int node, int block, int lane_ctrl, int phymode);
+extern void xlp8xx_ax_nae_lane_reset_txpll(int node, int block, int lane_ctrl, int phymode);
+
+/*  PCS initialization
+ */
+extern void nlm_hal_mdio_init(int node);
+extern void nlm_hal_sgmii_pcs_init(int node, int sgmii_cplx_mask);
+
+
+extern void nlm_hal_sgmii_phy_init(int node);
+
+extern int nlm_hal_init_nae(void *fdt, int dom_id);
+extern void nlm_hal_reset_nae_ownership(void *fdt, int dom_id);
+extern void reset_nae_mgmt(int node);
+extern int nlm_hal_nae_drain_frin_fifo_descs(int node, int inf);
+extern int nlm_hal_write_ucore_shared_mem(int node, unsigned int *data, int words);
+
+extern void nlm_hal_mac_disable(int node, int block, int intf_type);
+
+extern void nlm_hal_mac_enable(int node, int block, int intf_type);
+
+extern uint16_t nlm_hal_get_hwport(int node, uint32_t context);
+
+
+extern int nlm_hal_set_sgmii_framesize(int node, int block, int index, uint32_t size);
+
+extern int nlm_hal_set_ilk_framesize(int node, int block, int port, uint32_t size);
+extern int nlm_hal_set_xaui_framesize(int node, int block, uint32_t tx_size, uint32_t rx_size);
+#ifdef NLM_HAL_LINUX_KERNEL 
+extern int nlm_hal_get_ilk_mac_stats(int node, int block, int port, void *data);
+#endif
+
+extern int nlm_config_vfbid_table(int node, uint32_t start, uint32_t num_entries, uint32_t *vfbid_tbl);
+extern void nlm_hal_msec_tx_default_config(int node, unsigned int port_enable, unsigned int preamble_len, unsigned int packet_num, unsigned int pn_thrshld);
+extern void nlm_hal_msec_rx_default_config(int node, unsigned int port_enable, unsigned int preamble_len, unsigned int packet_num, unsigned int replay_win_size);
+extern void nlm_hal_msec_rx_mem_config(int node, int port, int index, uint64_t sci, unsigned char *key, uint64_t sci_mask);
+extern void nlm_hal_msec_rx_config(int node, unsigned int port_enable, unsigned int preamble_len, unsigned int packet_num, unsigned int replay_win_size);
+extern void nlm_hal_msec_tx_mem_config(int node, int context, int tci, uint64_t sci, unsigned char *key);
+extern void nlm_hal_msec_tx_config(int node, unsigned int port_enable, unsigned int preamble_len, unsigned int packet_num, unsigned int pn_thrshld);
+extern int nlm_hal_retrieve_shared_freein_fifo_info(void *fdt, 
+		int shared_dom_id, int *owner_replenish, char **paddr_info, int *paddr_info_len,
+		char **desc_info, int *desc_info_len);
+extern unsigned int nlm_hal_retrieve_freein_fifo_mask(void *fdt, int node, int dom_id);
+#endif /*__ASSEMBLY__ */
+
+
+/* POE APIS */
+
+static inline void nlm_write_enqspill_threshold(int node, uint32_t threshold)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_ENQ_SPILL_THOLD, (threshold & 0xFF));
+}
+
+static inline void nlm_write_deqspill_threshold(int node, uint32_t threshold)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DEQ_SPILL_THOLD, (threshold & 0xFF));
+}
+
+static inline void nlm_write_deqspill_timer(int node, uint32_t timer)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DEQ_SPILL_TIMER, (timer & 0x3FF));
+}
+
+static inline void nlm_enable_distribution_class_drop(int node, uint32_t class_mask)
+{
+        uint32_t val = nlm_hal_read_poe_pcie_reg(node, POE_DISTR_CLASS_DROP_EN);
+        val |= (class_mask & 0xFF);
+        nlm_hal_write_poe_pcie_reg(node, POE_DISTR_CLASS_DROP_EN, val);
+}
+
+static inline void nlm_enable_distribution_vector_drop(int node, uint32_t vector_mask)
+{
+        uint32_t val = nlm_hal_read_poe_pcie_reg(node, POE_DISTR_VEC_DROP_EN);
+        val |= (vector_mask & 0xFFFF);
+        nlm_hal_write_poe_pcie_reg(node, POE_DISTR_VEC_DROP_EN, val);
+}
+
+static inline void nlm_disable_distribution_class_drop(int node, uint32_t class_mask)
+{
+        uint32_t val = nlm_hal_read_poe_pcie_reg(node, POE_DISTR_CLASS_DROP_EN);
+        val &= ~(class_mask & 0xFF);
+        nlm_hal_write_poe_pcie_reg(node, POE_DISTR_CLASS_DROP_EN, val);
+}
+
+static inline void nlm_disable_distribution_vector_drop(int node, uint32_t vector_mask)
+{
+        uint32_t val = nlm_hal_read_poe_pcie_reg(node, POE_DISTR_VEC_DROP_EN);
+        val &= ~(vector_mask & 0xFFFF);
+        nlm_hal_write_poe_pcie_reg(node, POE_DISTR_VEC_DROP_EN, val);
+}
+
+static inline void nlm_write_distvec_drop_timer(int node, uint32_t timer)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DISTRVEC_DROP_TIMER, (timer & 0xFFFF));
+}
+
+static inline void nlm_enable_distribution(int node)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DIST_ENABLE, 1);
+}
+
+static inline void nlm_disable_distribution(int node)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DIST_ENABLE, 0);
+}
+
+static inline void nlm_write_poe_dest_threshold(int node, uint32_t threshold)
+{
+        nlm_hal_write_poe_pcie_reg(node, POE_DEST_THRESHOLD, (threshold & 0xFFFF));
+}
+
+static inline void nlm_write_poe_distr_threshold(int node, uint32_t threshold0, uint32_t threshold1, uint32_t threshold2, uint32_t threshold3)
+{
+	nlm_hal_write_poe_pcie_reg(node, POE_DIST_THRESHOLD_0, threshold0);
+	nlm_hal_write_poe_pcie_reg(node, POE_DIST_THRESHOLD_0+1, threshold1);
+	nlm_hal_write_poe_pcie_reg(node, POE_DIST_THRESHOLD_0+2, threshold2);
+	nlm_hal_write_poe_pcie_reg(node, POE_DIST_THRESHOLD_0+3, threshold3);
+}
+
+static inline uint32_t nlm_hal_ptp_timer_hi(int node, int inf_num)
+{
+       return nlm_hal_read_nae_reg(node, IF_1588_TMSMP_HI+(2*inf_num));
+}
+
+static inline uint32_t nlm_hal_ptp_timer_lo(int node, int inf_num)
+{
+       return nlm_hal_read_nae_reg(node, IF_1588_TMSMP_LO+(2*inf_num));
+}
+
+
+extern uint32_t nlm_hal_get_rtc(int node, uint32_t* p_val_hi,  uint32_t* p_val_lo);
+
+#endif /*#ifndef _NLM_HAL_NAE_H_ */
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h
new file mode 100644
index 0000000..0a722f8
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_pic.h
@@ -0,0 +1,465 @@
+
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * http://www.gnu.org/licenses/gpl-2.0.txt  
+ * or the Broadcom license below:
+
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_4# */
+
+
+#ifndef _NLM_HAL_PIC_H
+#define _NLM_HAL_PIC_H
+
+#include "nlm_hal.h"
+
+#define TIMER_CYCLES_MAXVAL        0xffffffffffffffffULL
+
+/*
+ *    IRT Map
+ */
+#define PIC_NUM_IRTS               160
+
+#define PIC_IRT_WD_0_INDEX         0
+#define PIC_IRT_WD_1_INDEX         1
+#define PIC_IRT_WD_NMI_0_INDEX     2
+#define PIC_IRT_WD_NMI_1_INDEX     3
+#define PIC_IRT_TIMER_0_INDEX      4
+#define PIC_IRT_TIMER_1_INDEX      5
+#define PIC_IRT_TIMER_2_INDEX      6
+#define PIC_IRT_TIMER_3_INDEX      7
+#define PIC_IRT_TIMER_4_INDEX      8
+#define PIC_IRT_TIMER_5_INDEX      9
+#define PIC_IRT_TIMER_6_INDEX      10
+#define PIC_IRT_TIMER_7_INDEX      11
+#define PIC_IRT_CLOCK_INDEX        PIC_IRT_TIMER_7_INDEX
+
+#define PIC_NUM_MSG_Q_IRTS         32
+#define PIC_IRT_MSG_Q0_INDEX       12
+#define PIC_IRT_MSG_Q_INDEX(qid)   ((qid) + PIC_IRT_MSG_Q0_INDEX) /* 12 - 43 */
+
+#define PIC_IRT_MSG_0_INDEX        44
+#define PIC_IRT_MSG_1_INDEX        45
+
+#define PIC_NUM_PCIE_MSIX_IRTS     32
+#define PIC_IRT_PCIE_MSIX_0_INDEX  46
+#define PIC_IRT_PCIE_MSIX_INDEX(num) ((num) + PIC_IRT_PCIE_MSIX_0_INDEX) /* 46 - 77 */
+
+#define PIC_NUM_PCIE_LINK_IRTS     4
+#define PIC_IRT_PCIE_LINK_0_INDEX  78
+#define PIC_IRT_PCIE_LINK_INDEX(num) ((num) + PIC_IRT_PCIE_LINK_0_INDEX) /* 78 - 81 */
+
+#define PIC_NUM_NA_IRTS            32
+#define PIC_IRT_NA_0_INDEX         82
+#define PIC_IRT_NA_INDEX(num)      ((num) + PIC_IRT_NA_0_INDEX) /* 82 - 113 */
+
+#define PIC_IRT_POE_INDEX          114
+
+#define PIC_NUM_USB_IRTS           6
+#define PIC_IRT_USB_0_INDEX        115
+#define PIC_IRT_USB_INDEX(num) ((num) + PIC_IRT_USB_0_INDEX) /* 115 - 120 */
+
+#define PIC_IRT_GDX_INDEX          121
+#define PIC_IRT_SEC_INDEX          122
+#define PIC_IRT_RSA_INDEX          123
+
+#define PIC_NUM_COMP_IRTS          4
+#define PIC_IRT_COMP_0_INDEX       124
+#define PIC_IRT_COMP_INDEX(num)    ((num) + PIC_IRT_COMP_0_INDEX) /* 124 - 127 */
+
+#define PIC_IRT_ICC_0_INDEX        129 /* ICC - Inter Chip Coherency */
+#define PIC_IRT_ICC_1_INDEX        130
+#define PIC_IRT_ICC_2_INDEX        131
+#define PIC_IRT_CAM_INDEX          132
+#define PIC_IRT_UART_0_INDEX       133
+#define PIC_IRT_UART_1_INDEX       134
+#define PIC_IRT_I2C_0_INDEX        135
+#define PIC_IRT_I2C_1_INDEX        136
+#define PIC_IRT_SYS_0              137
+#define PIC_IRT_SYS_1              138
+#define PIC_IRT_JTAG_INDEX         139
+#define PIC_IRT_PIC                140
+
+#define PIC_NUM_GPIO_IRTS          4
+#define PIC_IRT_GPIO_0_INDEX       146
+#define PIC_IRT_GPIO_INDEX(num)    ((num) + PIC_IRT_GPIO_0_INDEX) /* 146 - 149 */
+
+#define PIC_IRT_NOR                150
+#define PIC_IRT_NAND               151
+#define PIC_IRT_SPI                152
+#define PIC_IRT_MMC                153
+#define PIC_IRT_NBU                154
+#define PIC_IRT_TCU                155
+#define PIC_IRT_GCU                156 /* GBC - Global Coherency */
+#define PIC_IRT_DMC_0_INDEX        157
+#define PIC_IRT_DMC_1_INDEX        158
+#define PIC_IRT_TCB                159
+
+/*
+ *     Register Offsets
+ */
+#define PIC_CTRL             0x00
+#define PIC_BYTESWAP         0x01
+#define PIC_STATUS           0x02
+#define PIC_INT_TIMEOUT      0x03
+#define PIC_ICI0_INT_TIMEOUT 0x04
+#define PIC_ICI1_INT_TIMEOUT 0x05
+#define PIC_ICI2_INT_TIMEOUT 0x06
+#define PIC_IPI_CTL          0x07
+#define PIC_INT_ACK          0x08
+#define PIC_INT_PENDING0     0x09
+#define PIC_INT_PENDING1     0x0a
+#define PIC_INT_PENDING2     0x0b
+
+#define PIC_WD0_MAX_VAL      0x0c
+#define PIC_WD0_COUNT        0x0d
+#define PIC_WD0_MASK_0       0x0e
+#define PIC_WD0_MASK_1       0x0f
+#define PIC_WD0_HEARBEATCMD  0x10
+#define PIC_WD0_HEARBEAT_0   0x11
+#define PIC_WD0_HEARBEAT_1   0x12
+
+#define PIC_WD_MAX_VAL(id)    (PIC_WD0_MAX_VAL + ((id) ? 7 : 0))
+#define PIC_WD_COUNT(id)      (PIC_WD0_COUNT + ((id) ? 7 : 0))
+#define PIC_WD_MASK_0(id)     (PIC_WD0_MASK_0 + ((id) ? 7 : 0))
+#define PIC_WD_MASK_1(id)     (PIC_WD0_MASK_1 + ((id) ? 7 : 0))
+#define PIC_WD_HEARBEAT_0(id) (PIC_WD0_HEARTBEAT_0 + ((id) ? 7 : 0))
+#define PIC_WD_HEARBEAT_1(id) (PIC_WD0_HEARTBEAT_1 + ((id) ? 7 : 0))
+
+#define PIC_SYS_TIMER_0_MAX_VAL   0x1a
+#define PIC_SYS_TIMER_MAX_VAL(id) (PIC_SYS_TIMER_0_MAX_VAL + (id))
+
+#define PIC_SYS_TIMER_0_COUNTER   0x22
+#define PIC_SYS_TIMER_COUNTER(id) (PIC_SYS_TIMER_0_COUNTER + (id))
+
+#define PIC_TIMER_0_MAXVAL   PIC_SYS_TIMER_0_MAX_VAL
+#define PIC_TIMER_0_COUNTER  PIC_SYS_TIMER_0_COUNTER
+#define PIC_TIMER_7_MAXVAL   PIC_SYS_TIMER_MAX_VAL(7)
+#define PIC_TIMER_7_COUNTER  PIC_SYS_TIMER_COUNTER(7)
+#define PIC_TIMER_6_MAXVAL   PIC_SYS_TIMER_MAX_VAL(6)
+#define PIC_TIMER_6_COUNTER  PIC_SYS_TIMER_COUNTER(6)
+
+#define PIC_INT_THR_ENABLE_0_N01   0x2a
+#define PIC_INT_THR_ENABLE_0_N23   0x2b
+#define PIC_INT_THR_ENABLE_N01(id) (PIC_INT_THR_ENABLE_0_N01 + ((id) * 2))
+#define PIC_INT_THR_ENABLE_N23(id) (PIC_INT_THR_ENABLE_0_N23 + ((id) * 2))
+
+#define PIC_IRT_0   0x3a
+#define PIC_IRT(id) (PIC_IRT_0 + (id))
+
+#define PIC_IRT_WD_0        PIC_IRT(PIC_IRT_WD0_INDEX)
+#define PIC_IRT_WD_1        PIC_IRT(PIC_IRT_WD1_INDEX)
+#define PIC_IRT_TIMER_0     PIC_IRT(PIC_IRT_TIMER_0_INDEX)
+#define PIC_IRT_TIMER_1     PIC_IRT(PIC_IRT_TIMER_1_INDEX)
+#define PIC_IRT_TIMER_2     PIC_IRT(PIC_IRT_TIMER_2_INDEX)
+#define PIC_IRT_TIMER_3     PIC_IRT(PIC_IRT_TIMER_3_INDEX)
+#define PIC_IRT_TIMER_4     PIC_IRT(PIC_IRT_TIMER_4_INDEX)
+#define PIC_IRT_TIMER_5     PIC_IRT(PIC_IRT_TIMER_5_INDEX)
+#define PIC_IRT_TIMER_6     PIC_IRT(PIC_IRT_TIMER_6_INDEX)
+#define PIC_IRT_TIMER_7     PIC_IRT(PIC_IRT_TIMER_7_INDEX)
+#define PIC_IRT_CLOCK       PIC_IRT_TIMER_7
+#define PIC_IRT_UART_0      PIC_IRT(PIC_IRT_UART_0_INDEX)
+#define PIC_IRT_UART_1      PIC_IRT(PIC_IRT_UART_1_INDEX)
+#define PIC_IRT_I2C_0       PIC_IRT(PIC_IRT_I2C_0_INDEX)
+#define PIC_IRT_I2C_1       PIC_IRT(PIC_IRT_I2C_1_INDEX)
+
+#define PIC_CLOCK_TIMER     7
+#define PIC_IRQ_BASE        8
+
+#define ASM_XLP_IO_PIC_OFFSET        0xffffffffb8004100 /* TODO: This will change in to function */
+#define C_XLP_IO_PIC_OFFSET        0xffffffffb8004100ULL /* TODO: This will change in to function */
+
+#ifndef __ASSEMBLY__
+enum {
+	WD0 = 0,
+	WD1 = 1
+};
+extern int irt_irq_table[PIC_NUM_IRTS][4];
+extern int find_irt_from_irq(int irq_num);
+extern int nlm_hal_request_shared_irq(int irt);
+extern void nlm_hal_unrequest_shared_irq(int irt);
+
+static __inline__ int nlm_hal_irt_to_irq(int irt_num)
+{
+	if(irt_num < 0 || irt_num > PIC_NUM_IRTS)
+		return -1;
+
+	return irt_irq_table[irt_num][0];
+}
+
+static __inline__ int nlm_hal_irq_to_irt(int irq_num)
+{
+	int irt = find_irt_from_irq(irq_num);
+	return irt;
+}
+
+static __inline__ int nlm_hal_is_shared_irt(int irt_num)
+{
+	return irt_irq_table[irt_num][1];
+}
+
+#define PIC_IRT_FIRST_IRQ        (PIC_IRQ_BASE)
+#define PIC_WD_0_IRQ             nlm_hal_irt_to_irq(PIC_IRT_WD_0_INDEX)
+#define PIC_WD_1_IRQ             nlm_hal_irt_to_irq(PIC_IRT_WD_1_INDEX)
+#define PIC_TIMER_0_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_0_INDEX)
+#define PIC_TIMER_1_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_1_INDEX)
+#define PIC_TIMER_2_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_2_INDEX)
+#define PIC_TIMER_3_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_3_INDEX)
+#define PIC_TIMER_4_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_4_INDEX)
+#define PIC_TIMER_5_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_5_INDEX)
+#define PIC_TIMER_6_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_6_INDEX)
+#define PIC_TIMER_7_IRQ          nlm_hal_irt_to_irq(PIC_IRT_TIMER_7_INDEX)
+#define PIC_CLOCK_IRQ            (PIC_TIMER_7_IRQ)
+#define PIC_UART_0_IRQ           17
+#define PIC_UART_1_IRQ           18
+#define PIC_I2C_0_IRQ            nlm_hal_irt_to_irq(PIC_IRT_I2C_0_INDEX)
+#define PIC_I2C_1_IRQ            nlm_hal_irt_to_irq(PIC_IRT_I2C_1_INDEX)
+#define PIC_GPIO_IRQ(num)        nlm_hal_irt_to_irq(PIC_IRT_GPIO_INDEX(num))
+#define PIC_IRT_LAST_IRQ_        (PIC_IRQ_BASE + PIC_NUM_IRTS - 1)
+#define PIC_IRT_LAST_IRQ()       PIC_IRT_LAST_IRQ_
+
+/*
+ *   Misc
+ */
+#define IRT_VALID       	1
+#define LOCAL_SCHEDULING    1
+#define GLOBAL_SCHEDULING   0
+#define PIC_IRQ_IS_IRT(irq) ((irq >= PIC_IRT_FIRST_IRQ) && (irq <= PIC_IRT_LAST_IRQ_))
+#define PIC_IRQ_IS_EDGE_TRIGGERED(irq) 0 /* XLP interrupts are level triggered */
+
+/*
+ *
+ */
+
+#define NODE_OFFSET(node) ((node) << 18)
+#define CPU_TO_NODE(cpu) ((cpu) >> 5)
+
+static __inline__ int nlm_hal_cpu_id(void)
+{
+	int cpu;
+
+	__asm__ __volatile__ (
+		".set push\n"
+		".set noreorder\n"
+		".set mips32\n"
+		"mfc0 %0, $15, 1\n"
+		"andi %0, %0, 0x3ff\n"
+		".set pop\n"
+		: "=r"(cpu)
+		);
+
+	return cpu;
+}
+
+#define XLP_IO_PIC_OFFSET        C_XLP_IO_PIC_OFFSET
+
+typedef volatile unsigned long long pic_reg_t;
+
+static __inline__ pic_reg_t* nlm_hal_pic_offset(void)
+{
+	uint32_t cpu = nlm_hal_cpu_id();
+
+	return ( (pic_reg_t *) (unsigned long) (XLP_IO_PIC_OFFSET + NODE_OFFSET( CPU_TO_NODE(cpu) )) );
+}
+
+#ifdef CONFIG_64BIT
+
+static __inline__ void nlm_hal_write_pic_reg(pic_reg_t *base, unsigned int offset, unsigned long long value)
+{
+	base[offset] = value;
+}
+static __inline__ unsigned long long nlm_hal_read_pic_reg(pic_reg_t *base, unsigned int offset)
+{
+	return ((base)[offset]);
+}
+
+#else
+
+static __inline__ void nlm_hal_write_pic_reg(pic_reg_t *base, unsigned int offset, unsigned long long value)
+{
+        uint32_t lsw, msw;
+        uint64_t val;
+        uint32_t ls, ms;
+        unsigned long flags;
+
+        lsw = (uint32_t)  (unsigned long long) (base+offset);
+        msw = (uint32_t) 0xffffffffUL;
+        val = (uint64_t)value;
+
+        ls = (uint32_t) (val & 0xffffffff);
+        ms = (uint32_t) (val >> 32);
+
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %2, 0\n"
+                        "dsll32 %1, 0\n"
+                        "dsrl32 %1, 0\n"
+                        "or $1, $1, %1\n"
+                        "dsll32 $8, %4, 0\n"
+                        "dsll32 %3, 0\n"
+                        "dsrl32 %3, 0\n"
+                        "or $8, $8, %3\n"
+                        "sd $8, 0($1) \n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :
+                        :"r"(val), "r"(lsw), "r"(msw), "r"(ls), "r"(ms)
+                        :"$1", "$8");
+        disable_KX(flags);
+}
+
+static __inline__ unsigned long long nlm_hal_read_pic_reg(pic_reg_t *base, unsigned int offset)
+{
+        uint32_t lsw, msw;
+        uint64_t value = 0;
+        uint32_t lo, hi;
+        unsigned long flags;
+
+        lsw = (uint32_t) (unsigned long long) (base+offset);
+        msw = (uint32_t) 0xffffffffUL;
+
+        enable_KX(flags);
+        __asm__ __volatile__(".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        ".set noat\n"
+                        "dsll32 $1, %3, 0\n"
+                        "dsll32 %2, 0\n"
+                        "dsrl32 %2, 0\n"
+                        "or $1, $1, %2\n"
+                        "ld $8, 0($1) \n"
+                        "dsrl32 %1, $8, 0\n"
+                        "dsll32 $8, $8, 0\n"
+                        "dsrl32 %0, $8, 0\n"
+                        ".set at\n"
+                        ".set pop\n"
+                        :"=r"(lo), "=r"(hi)
+                        :"r"(lsw), "r"(msw)
+                        :"$1", "$8");
+
+        disable_KX(flags);
+        value = hi;
+        value = (uint64_t) ((value<<32) | lo);
+        return (value);
+}
+
+#endif /* #ifdef CONFIG_64BIT */
+static __inline__ void nlm_hal_pic_send_ipi(int nmi, int vec, int node, int cpu)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	unsigned long long ipi = (nmi << 31) | (vec << 20) | (node << 17) | (1 << (cpu & 0xf));
+	if (cpu > 15) {
+		ipi |= 0x10000; /* Setting bit 16 to select cpus 16-31 */
+	}
+
+	nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, ipi);
+}
+
+static __inline__ unsigned long long nlm_hal_pic_read_control(void)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	return nlm_hal_read_pic_reg(mmio, PIC_CTRL);
+}
+
+static __inline__ void nlm_hal_pic_write_control(unsigned long long control)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	nlm_hal_write_pic_reg(mmio, PIC_CTRL, control);
+}
+
+static __inline__ void nlm_hal_pic_update_control(unsigned long long control)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	nlm_hal_write_pic_reg(mmio, PIC_CTRL, (control | nlm_hal_read_pic_reg(mmio, PIC_CTRL)));
+}
+
+static __inline__ void nlm_hal_ack_pic(int irt_num)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	nlm_hal_write_pic_reg(mmio, PIC_INT_ACK, irt_num);
+
+	/* Ack the Status register for Watchdog & System timers */
+	if (irt_num < 12) {
+		nlm_hal_write_pic_reg(mmio, PIC_STATUS, (1 << irt_num));
+	}
+}
+
+static __inline__ unsigned long long nlm_hal_pic_read_irt(int irt_num)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	return nlm_hal_read_pic_reg(mmio, PIC_IRT(irt_num));
+}
+
+static __inline__ void nlm_hal_pic_write_irt(int irt_num, int en, int nmi, int sch, int vec, int dt, int db, int dte)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	unsigned long long val = (((en & 0x1) << 31) | ((nmi & 0x1) << 29) | ((sch & 0x1) << 28) |
+				  ((vec & 0x3f) << 20) | ((dt & 0x1 ) << 19) | ((db & 0x7) << 16) |
+				  (dte & 0xffff));
+
+	nlm_hal_write_pic_reg(mmio, PIC_IRT(irt_num), val);
+}
+
+#define CPUIDBITS01(X) ((X) & 0x3)
+#define CPUIDBIT2(X) ((X >> 2) & 0x1)
+
+static __inline__ void nlm_hal_pic_write_irt_direct(int irt_num, int en, int nmi, int sch, int vec, int cpu)
+{
+	nlm_hal_pic_write_irt(irt_num, en, nmi, sch, vec, 1, CPUIDBIT2(cpu), CPUIDBITS01(cpu));
+	/* Does not support multi node support yet */
+}
+
+static __inline__ unsigned long long nlm_hal_pic_read_timer(int timer)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	return nlm_hal_read_pic_reg(mmio, PIC_SYS_TIMER_COUNTER(timer));
+}
+
+static __inline__ void nlm_hal_pic_write_timer(int timer, pic_reg_t value)
+{
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	nlm_hal_write_pic_reg(mmio, PIC_SYS_TIMER_COUNTER(timer), value);
+}
+
+#endif /* __ASSEMBLY__ */
+
+#endif /* _NLM_HAL_PIC_H */
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_sys.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_sys.h
new file mode 100644
index 0000000..45cedc3
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_sys.h
@@ -0,0 +1,182 @@
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * http://www.gnu.org/licenses/gpl-2.0.txt  
+ * or the Broadcom license below:
+
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_4# */
+
+#ifndef _NLH_SYS_H
+#define _NLH_SYS_H
+#if !defined(__KERNEL__) && !defined(NLM_HAL_UBOOT)
+#include <stdint.h>
+#endif
+
+#define COUNT_OF(x) ((sizeof(x)/sizeof(0[x])) / ((size_t)(!(sizeof(x) % sizeof(0[x])))))
+
+/* TODO: Griffin support for different REFCLKs. */
+/* 133.333 MHz Reference Clock */
+#define REF_CLK_NUM_400 400000000ULL
+#define REF_CLK_NUM_200 200000000ULL
+#define REF_CLK_NUM_125 125000000ULL
+#define REF_CLK_NUM_100 100000000ULL
+#define REF_CLK_DEN  3
+#define REF_CLK_DEN3 3
+#define REF_CLK_DEN1 1
+
+/* 1 MHz resolution for frequency setting */
+#define FREQ_RESOLUTION 1000000ULL
+
+/* System Clock Reg: Device:6, Func:5
+ * 0x56 Clock Disable Control
+ * 0x57 Clock Reset Control
+ * 0x58 Clock Bypass Control
+ * 0x59 Clock Divider Increment Control
+ * 0x5A clock Divider Decrement Control
+ */
+typedef enum soc_dfs_device {
+	DFS_DEVICE_NAE_2X = 0,
+	DFS_DEVICE_SAE    = 1,
+	DFS_DEVICE_RSA    = 2,
+	DFS_DEVICE_DTRE   = 3,
+	DFS_DEVICE_CMP    = 4, /*xlp8xx only*/
+	DFS_DEVICE_KBP    = 5, /*xlp8xx only*/
+	DFS_DEVICE_DMC    = 6,
+	DFS_DEVICE_NAND   = 7,
+	DFS_DEVICE_MMC    = 8,
+	DFS_DEVICE_NOR    = 9,
+	DFS_DEVICE_CORE   = 10, /*0xA*/
+	DFS_DEVICE_REGEX_SLOW    = 11, /*xlp3xx only 0xB*/
+	DFS_DEVICE_REGEX_FAST    = 12, /*xlp3xx only 0xC*/
+	DFS_DEVICE_SATA          = 13, /*xlp3xx only 0xD*/
+
+	XLP2XX_CLKDEVICE_NAE	= 0x10,
+	XLP2XX_CLKDEVICE_SAE	= 0x11,
+	XLP2XX_CLKDEVICE_RSA	= 0x12,
+	XLP2XX_CLKDEVICE_GDX	= 0x13,
+	XLP2XX_CLKDEVICE_CMP	= 0x14,
+	XLP2XX_CLKDEVICE_NAND	= 0x15,
+	XLP2XX_CLKDEVICE_MMC	= 0x16,
+	XLP2XX_CLKDEVICE_GBU	= 0x17,
+	XLP2XX_CLKDEVICE_RGXF	= 0x18,
+	XLP2XX_CLKDEVICE_RGXS	= 0x19,
+	XLP2XX_CLKDEVICE_USB	= 0x1a,
+	XLP2XX_CLKDEVICE_PIC	= 0x1b,
+	XLP2XX_CLKDEVICE_NULL	= 0x1c,
+
+	INVALID_DFS_DEVICE = 0xFF
+} soc_device_id_t;
+
+typedef struct xlp2xx_soc_freq_t {
+        uint32_t nae;
+        uint32_t sae;
+        uint32_t rsa;
+        uint32_t gdx;
+        uint32_t cmp;
+        uint32_t nand;
+        uint32_t mmc;
+        uint32_t gbu;
+        uint32_t rgxf;
+        uint32_t rgxs;
+        uint32_t usb;
+        uint32_t pic;
+} xlp2xx_soc_freq_s;
+
+extern xlp2xx_soc_freq_s xlp2xx_freq_tbl[2];
+extern const char* nlm_hal_xlp2xx_get_dev_name(soc_device_id_t dev);
+
+typedef soc_device_id_t xlp2xx_clkdev_t;
+
+#ifdef NLM_HAL_LINUX_KERNEL 
+#define NLM_HAL_DO_DIV(n, base)   if(base) { do_div((n), (base)); }
+#else
+#define NLM_HAL_DO_DIV(n, base)   if(base) { ((n) /= (base)); }
+#endif 
+
+/*XLP2XX soc dev*/
+typedef enum xlp2xx_pll_type {
+	CORE0_PLL = 0,
+	CORE1_PLL = 1,
+	SYS_PLL   = 2,
+	DMC_PLL   = 3,
+	DEV0_PLL  = 4,
+	DEV1_PLL  = 5,
+	DEV2_PLL  = 6
+} xlp2xx_pll_type_t;
+
+
+typedef enum xlp2xx_clkdev_sel{
+	SEL_REF_CLK	=0x0,
+	SEL_DEV0PLL	=0x1,
+	SEL_DEV1PLL	=0x2,
+	SEL_DEV2PLL	=0x3
+} xlp2xx_clkdev_sel_t;
+
+typedef enum xlp2xx_clkdev_div{
+	DIV_BYPASS	=0x0,
+	DIV_DIV2	=0x1,
+	DIV_DIV4	=0x2,
+	DIV_DIV8	=0x3
+} xlp2xx_clkdev_div_t;
+
+extern uint8_t nlm_hal_get_soc_clock_state(int node, soc_device_id_t device);
+extern void nlm_hal_soc_clock_enable(int node, soc_device_id_t device);
+extern void nlm_hal_soc_clock_disable(int node, soc_device_id_t device);
+extern void nlm_hal_soc_clock_reset(int node, soc_device_id_t device);
+
+extern uint64_t nlm_hal_get_soc_freq(int node, soc_device_id_t device);
+extern uint64_t nlm_hal_set_soc_freq(int node, soc_device_id_t device, uint64_t freq);
+extern uint64_t nlm_hal_get_core_freq(int node, uint8_t core);
+extern uint64_t nlm_hal_set_core_freq(int node, uint8_t core, uint64_t freq);
+extern unsigned long long nlm_hal_cpu_freq(void);
+extern int nlm_hal_is_ref_clk_133MHz(void);
+extern uint64_t nlm_hal_get_ref_clk_freq(void);
+
+#define XLP_LOW_FREQ_SEL  0
+#define XLP_HIGH_FREQ_SEL 1
+extern void nlm_hal_adjust_soc_freqs(int node, int freq_sel);
+
+
+/*xlp2xx based APIs*/
+extern uint64_t xlp2xx_get_ref_clk(int node, uint64_t* ref_clk_num, uint32_t* ref_clk_den);
+extern uint64_t nlm_hal_xlp2xx_set_clkdev_frq(int node, soc_device_id_t dev_type, uint64_t frq);
+extern uint64_t nlm_hal_xlp2xx_get_clkdev_frq(int node, soc_device_id_t dev_type);
+
+#define NLM_HALT_IF(cond) while(cond) { \
+                nlm_print("ERROR: %s\n", __FUNCTION__); \
+                nlm_mdelay(10000); \
+        }
+
+#define NLM_HALT_IF_XLPII() NLM_HALT_IF(is_nlm_xlp2xx())
+#define XLP_DISABLE 1
+#define XLP_ENABLE  0
+
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h b/arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h
new file mode 100644
index 0000000..f0d3e17
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_hal_xlp_dev.h
@@ -0,0 +1,2366 @@
+
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * http://www.gnu.org/licenses/gpl-2.0.txt  
+ * or the Broadcom license below:
+
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_4# */
+
+
+#ifndef NLM_HAL_XLP_DEV_H
+#define NLM_HAL_XLP_DEV_H
+
+#define NLM_MAX_NODES           4
+
+#define MAX_VC_PERTHREAD        4
+
+#define XLP_CACHELINE_SIZE	64
+
+#ifndef NLM_NCPUS_PER_NODE
+#define NLM_NCPUS_PER_NODE	32
+#endif
+/*
+ * This File has all the XLP Device specific Defines
+ */
+#define XLP_PCIE_CFG_SIZE 0x1000 /* 4K */
+#define XLP_PCIE_DEV_BLK_SIZE 0x8000 /* 4k per function  and 8 function in a dev block */
+#define XLP_PCIE_BUS_BLK_SIZE (256 * XLP_PCIE_DEV_BLK_SIZE)
+
+/*XLP8XX/4XX B0 and A2 supported apis*/
+#define CHIP_PROCESSOR_ID_XLP_8XX    0
+#define CHIP_PROCESSOR_ID_XLP_8_4_XX 0x10
+#define CHIP_PROCESSOR_ID_XLP_3XX    0x11
+#define CHIP_PROCESSOR_ID_XLP_2XX    0x12
+#define CHIP_PROCESSOR_ID_XLP_1XX    0x13
+#define CHIP_PROCESSOR_ID_XLP_9XX    0x15
+
+/*XLP 8XX  A0,A1,A2 chip support*/
+#define CHIP_PROCESSOR_ID_XLP_832   CHIP_PROCESSOR_ID_XLP_8_4_XX
+#define CHIP_PROCESSOR_ID_XLP_816   0x14
+#define CHIP_PROCESSOR_ID_XLP_432   0x90
+#define CHIP_PROCESSOR_ID_XLP_416   0x94
+#define CHIP_PROCESSOR_ID_XLP_408   0x95
+#define CHIP_PROCESSOR_ID_XLP_208   0xB5
+#define CHIP_PROCESSOR_ID_XLP_204   0xB7
+#define CHIP_PROCESSOR_ID_XLP_104   0xF7
+
+/*Software Revision Number        XLP8XX  XLP3XX */
+#define XLP_REVISION_A0  0x00 /*    0        0   */
+#define XLP_REVISION_A1  0x01 /*    1        1   */
+#define XLP_REVISION_A2  0x02 /*    2            */
+#define XLP_REVISION_B0  0x03 /*    3        2   */
+#define XLP_REVISION_B1  0x04 /*    4        3   */
+
+#define XLP_REVISION_AX  0xAF
+#define XLP_REVISION_BX  0xBF
+#define XLP_REVISION_INV 0xFE
+#ifndef XLP_REVISION_ANY
+#define XLP_REVISION_ANY 0xFF
+#endif
+
+/*XLP 3XX EXTPID type */
+/*xlp3xx Base
+ *--------
+ *xlp316 : 4x4 16 threads
+ *xlp308   2x4  8 threads
+ *xlp304   1x4  4 threads
+ *xlp208a  2x4  8 trheads
+ *xlp108a  2x4  8 trheads
+ *xlp204a  1x4  4 trheads
+ *xlp104a  1x4  4 trheads
+ *xlp202a  2x1  2 trheads
+ *xlp201a  1x1  1 trheads
+ *xlp101a  1x1  1 trheads
+ */
+#define CPU_EXTPID_XLP_3XX_NONE  0x00
+#define CPU_EXTPID_XLP_3XX_BASE  0x00
+
+#define CPU_EXTPID_XLP_3XX_L    0x01
+#define CPU_EXTPID_XLP_3XX_LP   0x02
+#define CPU_EXTPID_XLP_3XX_LP2  0x03
+#define CPU_EXTPID_XLP_208a     0x06
+#define CPU_EXTPID_XLP_108a     0x07
+#define CPU_EXTPID_XLP_204a     0x05
+#define CPU_EXTPID_XLP_104a     0x04
+#define CPU_EXTPID_XLP_202a     0x08
+#define CPU_EXTPID_XLP_201a     0x09
+#define CPU_EXTPID_XLP_101a     0x0A
+
+#define CPU_EXTPID_XLP_3XX_MAX   0x0F
+
+#define CPU_EXTPID_XLP_208a     0x06
+#define CPU_EXTPID_XLP_108a     0x07
+#define CPU_EXTPID_XLP_204a     0x05
+#define CPU_EXTPID_XLP_104a     0x04
+#define CPU_EXTPID_XLP_202a     0x08
+#define CPU_EXTPID_XLP_201a     0x09
+#define CPU_EXTPID_XLP_101a     0x0A
+
+#define CPU_EXTPID_XLP_208a     0x06
+#define CPU_EXTPID_XLP_108a     0x07
+#define CPU_EXTPID_XLP_204a     0x05
+#define CPU_EXTPID_XLP_104a     0x04
+#define CPU_EXTPID_XLP_202a     0x08
+#define CPU_EXTPID_XLP_201a     0x09
+#define CPU_EXTPID_XLP_101a     0x0A
+
+#define CPU_EXTPID_XLP_3XX_INV   0xFE  	 /* invalid */
+#define CPU_EXTPID_XLP_3XX_ANY   0xFF	 /* Any 3XX */
+
+#ifndef __ASSEMBLY__
+#ifndef __XLP_CHIPID_MACROS__
+#define __XLP_CHIPID_MACROS__
+
+extern int is_nlm_xlp(unsigned int chipid, unsigned int rev,  unsigned int ext);
+
+/* 16 bits Software CPU ID Encoding rule:
+ * [15:12]: xlp family: 2, 3, 8, 9
+ * [11:04]: num of cores
+ * [ 3: 0]: num of threads per core
+ */
+
+#ifndef is_nlm_xlp8xx
+#define is_nlm_xlp8xx()      ( is_nlm_xlp(0x8000, XLP_REVISION_ANY, 0) || is_nlm_xlp(0x4000, XLP_REVISION_ANY, 0))
+#endif /* is_nlm_xlp8xx */
+
+#define is_nlm_xlp8xx_ax()   ( is_nlm_xlp(0x8000, XLP_REVISION_AX,  0) || is_nlm_xlp(0x4000, XLP_REVISION_AX, 0))
+#define is_nlm_xlp8xx_b0()   ( is_nlm_xlp(0x8000, XLP_REVISION_B0,  0) || is_nlm_xlp(0x4000, XLP_REVISION_B0, 0))
+#define is_nlm_xlp8xx_b1()   ( is_nlm_xlp(0x8000, XLP_REVISION_B1,  0) || is_nlm_xlp(0x4000, XLP_REVISION_B1, 0))
+#define is_nlm_xlp8xx_bx()   ( is_nlm_xlp(0x8000, XLP_REVISION_BX,  0) || is_nlm_xlp(0x4000, XLP_REVISION_BX, 0))
+#define is_nlm_xlp832_ax()   ( is_nlm_xlp(0x8084, XLP_REVISION_AX,  0))
+
+#define is_nlm_xlp3xx_B(rev)      ( is_nlm_xlp(0x3000, rev, CPU_EXTPID_XLP_3XX_BASE))
+#define is_nlm_xlp316_B(rev)      ( is_nlm_xlp(0x3044, rev, CPU_EXTPID_XLP_3XX_BASE))
+#define is_nlm_xlp312_B(rev)      ( is_nlm_xlp(0x3034, rev, CPU_EXTPID_XLP_3XX_BASE))
+#define is_nlm_xlp308_B(rev)      ( is_nlm_xlp(0x3024, rev, CPU_EXTPID_XLP_3XX_BASE))
+#define is_nlm_xlp304_B(rev)      ( is_nlm_xlp(0x3014, rev, CPU_EXTPID_XLP_3XX_BASE))
+
+#define is_nlm_xlp3xx_L(rev)      ( is_nlm_xlp(0x3000, rev, CPU_EXTPID_XLP_3XX_L))
+#define is_nlm_xlp316_L(rev)      ( is_nlm_xlp(0x3044, rev, CPU_EXTPID_XLP_3XX_L))
+#define is_nlm_xlp312_L(rev)      ( is_nlm_xlp(0x3034, rev, CPU_EXTPID_XLP_3XX_L))
+#define is_nlm_xlp308_L(rev)      ( is_nlm_xlp(0x3024, rev, CPU_EXTPID_XLP_3XX_L))
+#define is_nlm_xlp304_L(rev)      ( is_nlm_xlp(0x3014, rev, CPU_EXTPID_XLP_3XX_L))
+
+#define is_nlm_xlp3xx_LP(rev)      ( is_nlm_xlp(0x3000, rev, CPU_EXTPID_XLP_3XX_LP))
+#define is_nlm_xlp316_LP(rev)      ( is_nlm_xlp(0x3044, rev, CPU_EXTPID_XLP_3XX_LP))
+#define is_nlm_xlp312_LP(rev)      ( is_nlm_xlp(0x3034, rev, CPU_EXTPID_XLP_3XX_LP))
+#define is_nlm_xlp308_LP(rev)      ( is_nlm_xlp(0x3024, rev, CPU_EXTPID_XLP_3XX_LP))
+#define is_nlm_xlp304_LP(rev)      ( is_nlm_xlp(0x3014, rev, CPU_EXTPID_XLP_3XX_LP))
+
+#define is_nlm_xlp3xx_LP2(rev)      ( is_nlm_xlp(0x3000, rev, CPU_EXTPID_XLP_3XX_LP2))
+#define is_nlm_xlp316_LP2(rev)      ( is_nlm_xlp(0x3044, rev, CPU_EXTPID_XLP_3XX_LP2))
+#define is_nlm_xlp312_LP2(rev)      ( is_nlm_xlp(0x3034, rev, CPU_EXTPID_XLP_3XX_LP2))
+#define is_nlm_xlp308_LP2(rev)      ( is_nlm_xlp(0x3024, rev, CPU_EXTPID_XLP_3XX_LP2))
+#define is_nlm_xlp304_LP2(rev)      ( is_nlm_xlp(0x3014, rev, CPU_EXTPID_XLP_3XX_LP2))
+
+#define is_nlm_xlp316_rev(rev)  (is_nlm_xlp316_B(rev) || is_nlm_xlp316_L(rev) || is_nlm_xlp316_LP(rev) || is_nlm_xlp316_LP2(rev))
+#define is_nlm_xlp312_rev(rev)  (is_nlm_xlp312_B(rev) || is_nlm_xlp312_L(rev) || is_nlm_xlp312_LP(rev) || is_nlm_xlp312_LP2(rev))
+#define is_nlm_xlp308_rev(rev)  (is_nlm_xlp308_B(rev) || is_nlm_xlp308_L(rev) || is_nlm_xlp308_LP(rev) || is_nlm_xlp308_LP2(rev))
+#define is_nlm_xlp304_rev(rev)  (is_nlm_xlp304_B(rev) || is_nlm_xlp304_L(rev) || is_nlm_xlp304_LP(rev) || is_nlm_xlp304_LP2(rev))
+
+#define is_nlm_xlp316() is_nlm_xlp316_rev(XLP_REVISION_ANY)
+#define is_nlm_xlp312() is_nlm_xlp312_rev(XLP_REVISION_ANY)
+#define is_nlm_xlp308() is_nlm_xlp308_rev(XLP_REVISION_ANY)
+#define is_nlm_xlp304() is_nlm_xlp304_rev(XLP_REVISION_ANY)
+
+#define is_nlm_xlp3xx_rev(rev) (is_nlm_xlp(0x3000, rev, CPU_EXTPID_XLP_3XX_ANY))
+#define is_nlm_xlp3xx()	     is_nlm_xlp3xx_rev(XLP_REVISION_ANY)
+#define is_nlm_xlp3xx_ax()   is_nlm_xlp3xx_rev(XLP_REVISION_AX)
+#define is_nlm_xlp3xx_bx()   is_nlm_xlp3xx_rev(XLP_REVISION_BX)
+#define is_nlm_xlp3xx_b0()   is_nlm_xlp3xx_rev(XLP_REVISION_B0)
+
+#define is_nlm_xlp3xx_208a()      ( is_nlm_xlp(0x3024, XLP_REVISION_ANY, CPU_EXTPID_XLP_208a))
+#define is_nlm_xlp3xx_108a()      ( is_nlm_xlp(0x3024, XLP_REVISION_ANY, CPU_EXTPID_XLP_108a))
+
+#define is_nlm_xlp3xx_204a()      ( is_nlm_xlp(0x3014, XLP_REVISION_ANY, CPU_EXTPID_XLP_204a))
+#define is_nlm_xlp3xx_104a()      ( is_nlm_xlp(0x3014, XLP_REVISION_ANY, CPU_EXTPID_XLP_104a))
+
+#define is_nlm_xlp3xx_202a()      ( is_nlm_xlp(0x3021, XLP_REVISION_ANY, CPU_EXTPID_XLP_202a))
+#define is_nlm_xlp3xx_201a()      ( is_nlm_xlp(0x3011, XLP_REVISION_ANY, CPU_EXTPID_XLP_201a))
+#define is_nlm_xlp3xx_101a()      ( is_nlm_xlp(0x3011, XLP_REVISION_ANY, CPU_EXTPID_XLP_101a))
+
+#define is_nlm_xlp3xx_lite()  (is_nlm_xlp3xx() && (!is_nlm_xlp3xx_B(XLP_REVISION_ANY)) )
+
+#define is_nlm_xlp2xx()	    is_nlm_xlp(0x2000, XLP_REVISION_ANY,  0)
+
+#define is_nlm_xlp208()	    is_nlm_xlp(0x2024, XLP_REVISION_ANY,  0)
+#define is_nlm_xlp204()	    is_nlm_xlp(0x2014, XLP_REVISION_ANY,  0)
+
+#define is_nlm_xlp2xx_208a()      ( is_nlm_xlp(0x2024, XLP_REVISION_ANY, CPU_EXTPID_XLP_208a))
+#define is_nlm_xlp2xx_108a()      ( is_nlm_xlp(0x2024, XLP_REVISION_ANY, CPU_EXTPID_XLP_108a))
+
+#define is_nlm_xlp2xx_204a()      ( is_nlm_xlp(0x2014, XLP_REVISION_ANY, CPU_EXTPID_XLP_204a))
+#define is_nlm_xlp2xx_104a()      ( is_nlm_xlp(0x2014, XLP_REVISION_ANY, CPU_EXTPID_XLP_104a))
+
+#define is_nlm_xlp2xx_202a()      ( is_nlm_xlp(0x2021, XLP_REVISION_ANY, CPU_EXTPID_XLP_202a))
+#define is_nlm_xlp2xx_201a()      ( is_nlm_xlp(0x2011, XLP_REVISION_ANY, CPU_EXTPID_XLP_201a))
+#define is_nlm_xlp2xx_101a()      ( is_nlm_xlp(0x2011, XLP_REVISION_ANY, CPU_EXTPID_XLP_101a))
+
+#endif /*__XLP_CHIPID_MACROS__ */
+
+#endif /* __ASSEMBLY__ */
+
+/*
+ *    FMN
+ */
+#define XLP_STN_RX_QSIZE 256
+
+#define XLP_STNID_CPU0          0x00
+#define XLP_STNID_CPU1          0x10
+#define XLP_STNID_CPU2          0x20
+#define XLP_STNID_CPU3          0x30
+#define XLP_STNID_CPU4          0x40
+#define XLP_STNID_CPU5          0x50
+#define XLP_STNID_CPU6          0x60
+#define XLP_STNID_CPU7          0x70
+#define XLP_STNID_PCIE0         0x100
+#define XLP_STNID_PCIE1         0x102
+#define XLP_STNID_PCIE2         0x104
+#define XLP_STNID_PCIE3         0x106
+#define XLP_STNID_GDX           0x108
+#define XLP_STNID_RSA_ECC       0x110
+#define XLP_STNID_CRYPTO        0x119
+#define XLP_STNID_CMP           0x129
+#define XLP_STNID_POE           0x180
+#define XLP_STNID_NAE_TX        0x1DC
+#define XLP_STNID_NAE_RX        0x3E8
+#define XLP_STNID_INVALID       0x400
+#define XLP_MAX_TX_STNS         20
+
+#define XLP_PCIE0_VC_BASE       256
+#define XLP_PCIE0_VC_LIMIT      257
+#define XLP_PCIE1_VC_BASE       258
+#define XLP_PCIE1_VC_LIMIT      259
+#define XLP_PCIE2_VC_BASE       260
+#define XLP_PCIE2_VC_LIMIT      261
+#define XLP_PCIE3_VC_BASE       262
+#define XLP_PCIE3_VC_LIMIT      263
+#define XLP_GDX_VC_BASE         264
+#define XLP_GDX_VC_LIMIT        267
+#define XLP_RSA_ECC_VC_BASE     272
+#define XLP_RSA_ECC_VC_LIMIT    280
+#define XLP_CRYPTO_VC_BASE      281
+#define XLP_CRYPTO_VC_LIMIT     296
+#define XLP_CMP_VC_BASE         297
+#define XLP_CMP_VC_LIMIT        304
+#define XLP_POE_VC_BASE         384
+#define XLP_POE_VC_LIMIT        391
+#define XLP_NET_TX_VC_BASE      476
+#define XLP_NET_TX_VC_LIMIT     999
+#define XLP_NET_RX_VC_BASE      1000
+#define XLP_NET_RX_VC_LIMIT     1019
+#define XLP_NET_VC_BASE         XLP_NET_TX_VC_BASE
+#define XLP_NET_VC_LIMIT        1023
+
+#define XLP_POPQ_VC_BASE	128
+#define XLP_POPQ_VC_LIMIT	255
+
+#define XLP_CPU0_VC_BASE	0
+#define XLP_CPU0_VC_LIMIT       15
+#define XLP_CPU1_VC_LIMIT       31
+#define XLP_CPU2_VC_LIMIT       47
+#define XLP_CPU3_VC_LIMIT       63
+#define XLP_CPU4_VC_LIMIT       79
+#define XLP_CPU5_VC_LIMIT       95
+#define XLP_CPU6_VC_LIMIT       111
+#define XLP_CPU7_VC_LIMIT       127
+
+/* XLP_3XX */
+
+#define XLP_3XX_MAX_NAE_UCORES	8
+
+#define XLP_3XX_REGEX_VC_BASE       268
+#define XLP_3XX_REGEX_VC_LIMIT      271
+
+#define XLP_3XX_RSA_ECC_VC_BASE     272
+#define XLP_3XX_RSA_ECC_VC_LIMIT    275
+
+#define XLP_3XX_CRYPTO_VC_BASE      276
+#define XLP_3XX_CRYPTO_VC_LIMIT     279
+
+#define XLP_3XX_SRIO_VC_BASE        280
+#define XLP_3XX_SRIO_VC_LIMIT       288
+#define XLP_3XX_B0_SRIO_VC_LIMIT    289
+
+
+#define XLP_3XX_POE_VC_BASE         384
+#define XLP_3XX_POE_VC_LIMIT        391
+#define XLP_3XX_NET_TX_VC_BASE      432
+#define XLP_3XX_NET_TX_VC_LIMIT     495
+#define XLP_3XX_NET_RX_VC_BASE      496
+#define XLP_3XX_NET_RX_VC_LIMIT     503 /* 511 */
+#define XLP_3XX_NET_VC_BASE	      XLP_3XX_NET_TX_VC_BASE
+#define XLP_3XX_NET_VC_LIMIT        511
+
+#define XLP_INVALID_STATION		0xFFFF	
+#define XLP_3XX_INVALID_STATION		XLP_INVALID_STATION
+
+/* XLP2XX */
+#define XLP_2XX_CDE_VC_BASE         266
+#define XLP_2XX_CDE_VC_LIMIT        267
+
+#define XLP_2XX_REGEX_VC_BASE       268
+#define XLP_2XX_REGEX_VC_LIMIT      271
+
+#define XLP_2XX_RSA_ECC_VC_BASE     272
+#define XLP_2XX_RSA_ECC_VC_LIMIT    272
+
+#define XLP_2XX_CRYPTO_VC_BASE      276
+#define XLP_2XX_CRYPTO_VC_LIMIT     276
+
+#define XLP_2XX_POE_VC_BASE         384
+#define XLP_2XX_POE_VC_LIMIT        391
+#define XLP_2XX_NET_TX_VC_BASE      432
+#define XLP_2XX_NET_TX_VC_LIMIT     495
+#define XLP_2XX_NET_RX_VC_BASE      496
+#define XLP_2XX_NET_RX_VC_LIMIT     503 /* 511 */
+#define XLP_2XX_NET_VC_BASE	    XLP_2XX_NET_TX_VC_BASE
+#define XLP_2XX_NET_VC_LIMIT        511
+
+#define XLP_2XX_INVALID_STATION		XLP_INVALID_STATION
+
+/*Sw Code */
+#define XLP_CODE_MAC		0
+#define XLP_CODE_SEC		1
+#define XLP_CODE_BOOT_WAKEUP	200
+
+/*Cop2 Regs */
+#define XLP_TX_BUF_REG		$0
+#define XLP_RX_BUF_REG		$1
+#define XLP_MSG_TXSTATUS_REG	$2
+#define XLP_MSG_RXSTATUS_REG	$3
+#define XLP_MSG_STATUS1_REG	$4
+#define XLP_MSG_CONFIG_REG	$5
+#define XLP_MSG_CONFIG1_REG	$6
+#define XLP_MSG_INT_REG		$8
+
+/*sys register offset in pcie config space*/
+#define XLP_PCIE_NODE0_SYSOFFSET        0x35000
+#define XLP_PCIE_NODE1_SYSOFFSET        0x75000
+#define XLP_PCIE_NODE2_SYSOFFSET        0xB5000
+#define XLP_PCIE_NODE3_SYSOFFSET        0xF5000
+
+/* DTR related */
+#define XLP_DTR_NODE                    0x0
+#define XLP_DTR_BUS                     0x0
+#define XLP_DTR_DEVICE                  0x5
+#define XLP_DTR_FUNC                    0x0
+#define XLP_DTR_MASTER_CONTROL_REG      0x40
+#define XLP_DTR_CHANNEL_CONTROL_REG_0   0x48
+#define XLP_DTR_CHANNEL_CONTROL_REG_1   0x49
+#define XLP_DTR_CHANNEL_CONTROL_REG_2   0x4A
+#define XLP_DTR_CHANNEL_CONTROL_REG_3   0x4B
+
+/* Crypto related */
+#define XLP_CRYPTO_NODE                 0x0
+#define XLP_CRYPTO_BUS                  0x0
+#define XLP_CRYPTO_DEVICE               0x5
+#define XLP_CRYPTO_FUNC                 0x1
+
+/*RSA related */
+#define XLP_RSA_NODE                    0x0
+#define XLP_RSA_BUS                     0x0
+#define XLP_RSA_DEVICE                  0x5
+#define XLP_RSA_FUNC                    0x2
+
+/*CDE related */
+#define XLP_CDE_NODE                    0x0
+#define XLP_CDE_BUS                     0x0
+#define XLP_CDE_DEVICE                  0x5
+#define XLP_CDE_FUNC                    0x3
+
+/* XLP Storm Regex related */
+#define XLP_3XX_REGEX_NODE		0x0
+#define XLP_3XX_REGEX_BUS		0x0
+#define XLP_3XX_REGEX_DEVICE		0x5
+#define XLP_3XX_REGEX_FUNC		0x5
+
+#define XLP_IO_DEVICE			0x0
+#define XLP_IO_FUNC	                0x0
+
+#define XLP_FMN_DEVICE			0x4
+#define XLP_FMN_FUNC			0x0
+
+#define XLP_NAE_DEVICE			0x3
+#define XLP_NAE_FUNC			0x0
+
+#define XLP_POE_DEVICE			0x3
+#define XLP_POE_FUNC			0x1
+
+#define XLP_SAE_DEVICE			0x5
+#define XLP_SAE_FUNC			0x1
+
+#define XLP_RSA_DEVICE			0x5
+#define XLP_RSA_FUNC			0x2
+
+#define XLP_SYS_DEVICE			0x6
+#define XLP_SYS_FUNC			0x5
+
+#define XLP_MAXDEV_PERNODE		8
+
+#define XLP_CFG_BASE(node, SOC)		((((node * XLP_MAXDEV_PERNODE) + SOC##_DEVICE) << 15) | (SOC##_FUNC << 12))
+
+
+#ifndef __ASSEMBLY__
+/* Device Id: Bus[8:6], Dev[5:3], func[2:0] */
+
+enum sae_cfg_regs {
+  SECCONENGSL0 = 0x41,
+  SECCONENGSL1 = 0x42,
+  SECCONENGSL2 = 0x43,
+  SECCONENGSL3 = 0x44,
+  SECCONENGSL4 = 0x45,
+  SECCONENGSL5 = 0x46,
+  SECCONENGSL6 = 0x47,
+  SECCONENGSL7 = 0x48,
+  SECCONENGSL8 = 0x49,
+  SECEMSGCTLLO = 0x82,
+  SECEMSGCTLL1 = 0x83,
+};
+
+enum NLH_DEV_ID {
+  NLH_BRIDGE = 0,
+  NLH_PIC    = 4,
+  NLH_NAE    = 0x18,
+  NLH_POE    = 0x19,
+  NLH_FMN    = 0x20,
+  NLH_GDX    = 0x28,
+  NLH_SEC    = 0x29,
+  NLH_RSA    = 0x2a,
+  NLH_COMP   = 0x2b,
+  NLH_UART0  = 0x30,
+  NLH_UART1  = 0x31,
+  NLH_SYS    = 0x35,
+};
+
+enum XLP_MSG_HANDLES  {
+        XLP_MSG_HANDLE_CPU0,
+        XLP_MSG_HANDLE_CPU1,
+        XLP_MSG_HANDLE_CPU2,
+        XLP_MSG_HANDLE_CPU3,
+        XLP_MSG_HANDLE_CPU4,
+        XLP_MSG_HANDLE_CPU5,
+        XLP_MSG_HANDLE_CPU6,
+        XLP_MSG_HANDLE_CPU7,
+        XLP_MSG_HANDLE_PCIE0,
+        XLP_MSG_HANDLE_PCIE1,
+        XLP_MSG_HANDLE_PCIE2,
+        XLP_MSG_HANDLE_PCIE3,
+	XLP_MSG_HANDLE_DTRE,
+        XLP_MSG_HANDLE_GDX,
+        XLP_MSG_HANDLE_REGX,
+        XLP_MSG_HANDLE_RSA_ECC,
+        XLP_MSG_HANDLE_CRYPTO,
+        XLP_MSG_HANDLE_SRIO,
+        XLP_MSG_HANDLE_CMP,
+        XLP_MSG_HANDLE_POE,
+        XLP_MSG_HANDLE_NAE_0,
+        XLP_MSG_HANDLE_INVALID,
+        XLP_MSG_HANDLE_MAX,
+};
+
+/*
+ *  NET Accelerator
+ */
+#define XLP_NA_REG_BLOCK_SIZE 0x2000 /* 8KB */
+#define XLP_NA_REG_IFACE_SIZE 0x200 /* 512B */
+
+enum net_cfg_regs {
+ RX_CONFIG                          = 0x10,
+ TX_CONFIG                          = 0x11,
+ RX_IF_BASE_CONFIG_0                = 0x12,
+ RX_IF_BASE_CONFIG_1                = 0x13,
+ RX_IF_BASE_CONFIG_2                = 0x14,
+ RX_IF_BASE_CONFIG_3                = 0x15,
+ RX_IF_BASE_CONFIG_4                = 0x16,
+ RX_IF_BASE_CONFIG_5                = 0x17,
+ RX_IF_BASE_CONFIG_6                = 0x18,
+ RX_IF_BASE_CONFIG_7                = 0x19,
+ RX_IF_BASE_CONFIG_8                = 0x1a,
+ RX_IF_BASE_CONFIG_9                = 0x1b,
+ RX_IFACE_VEC_VALID                 = 0x1c,
+ RX_IFACE_SLOT_CAL                  = 0x1d,
+ XLP_PARSER_CONFIG                  = 0x1e,
+ PARSER_SEQ_FIFO_CFG                = 0x1f,
+ FREE_IN_LIFO_CFG                   = 0x20,
+ RX_BUFFER_BASE_DEPTH_ADDR_REG      = 0x21,
+ RX_BUFFER_BASE_DEPTH_REG           = 0x22,
+ RX_UCORE_CFG                       = 0x23,
+ RX_UCORE_CAM_MASK0_CFG             = 0x24,
+ RX_UCORE_CAM_MASK1_CFG             = 0x25,
+ RX_UCORE_CAM_MASK2_CFG             = 0x26,
+ RX_UCORE_CAM_MASK3_CFG             = 0x27,
+ FREE_IN_LIFO_UNIQ_SZ_CFG           = 0x28,
+ CRC_POLY0_CFG                      = 0x2a,
+ CRC_POLY1_CFG                      = 0x2b,
+ FREE_SPILL0_MEM_CFG                = 0x2c,
+ FREE_SPILL1_MEM_CFG                = 0x2d,
+ FREE_FIFO_THRESHOLD_CFG    	    = 0x2e,
+ FREE_FIFO_THRESHOLDS_CFG           = 0x87,
+ FLOW_CRC16_POLY_CFG                = 0x2f,
+ DMA_TX_CREDIT_TH                   = 0x29,
+ STG1_STG2CRDT_CMD                  = 0x30,
+ STG1_STG2CRDT_STATUS               = 0x31,
+ STG2_EHCRDT_CMD                    = 0x32,
+ STG2_EHCRDT_STATUS                 = 0x33,
+ STG2_FREECRDT_CMD                  = 0x34,
+ STG2_FREECRDT_STATUS               = 0x35,
+ STG2_STRCRDT_CMD                   = 0x36,
+ STG2_STRCRDT_STATUS                = 0x37,
+ TXFIFO_IFACE_MAP_CMD               = 0x38,
+ TXFIFO_IFACE_MAP_STATUS            = 0x39,
+ VFBID_TO_DEST_MAP_CMD              = 0x3a,
+ STG1_PMEM_PROG                     = 0x3c,
+ STG1_PMEM_STATUS                   = 0x3d,
+ STG2_PMEM_PROG                     = 0x3e,
+ STG2_PMEM_STATUS                   = 0x3f,
+ EH_PMEM_PROG                       = 0x40,
+ EH_PMEM_STATUS                     = 0x41,
+ FREE_PMEM_PROG                     = 0x42,
+ FREE_PMEM_STATUS                   = 0x43,
+ TX_DRR_ACTVLIST_CMD                = 0x44,
+ TX_DRR_ACTVLIST_STATUS             = 0x45,
+ TX_IFACE_BURSTMAX_CMD              = 0x46,
+ TX_IFACE_BURSTMAX_STATUS           = 0x47,
+ TX_IFACE_ENBL_CMD                  = 0x48,
+ TX_IFACE_ENBL_STATUS               = 0x49,
+ TX_PKTLEN_PMEM_CMD                 = 0x4a,
+ TX_PKTLEN_PMEM_STATUS              = 0x4b,
+ TX_SCHED_MAP_CMD0                  = 0x4c,
+ TX_SCHED_MAP_CMD1                  = 0x4d,
+ EGR_NIOR_CAL_LEN_REG       	    = 0x4e,
+ EGR_NIOR_CRDT_CAL_PROG     	    = 0x52,
+ TX_SCHED_MAP_STATUS0               = 0x387,
+ TX_SCHED_MAP_STATUS1               = 0x388,
+ TX_PKT_PMEM_CMD0                   = 0x50,
+ TX_PKT_PMEM_CMD1                   = 0x51,
+ TX_PKT_PMEM_STATUS                 = 0x389,
+ TX_SCHED_CTRL                      = 0x53,
+ STR_PMEM_CMD                       = 0x58,
+ TX_IORCRDT_INIT                    = 0x59,
+ RX_FREE_FIFO_POP                   = 0x62,
+ FLOW_BASE_MASK_CFG                 = 0x80,
+ POE_CLASS_SETUP_CFG                = 0x81,
+ UCORE_IFACE_MASK_CFG               = 0x82,
+ RX_BUFFER_XONOFF_THR    	    = 0x83,
+ FLOW_TABLE1_CFG                    = 0x84,
+ FLOW_TABLE3_CFG                    = 0x86,
+ IFACE_FIFO_CFG             	    = 0x8a,
+ PARSER_SEQ_FIFOTH_CFG		    = 0x8b,
+ L2_TYPE_0                          = 0x210,
+ L3_CTABLE_MASK_0                   = 0x22c,
+ L3_CTABLE_0_0                      = 0x230,
+ L3_CTABLE_0_1                      = 0x231,
+ L4_CTABLE_0_0                      = 0x250,
+ L4_CTABLE_0_1                      = 0x251,
+ VFBID_TO_DEST_MAP_STATUS           = 0x380,
+
+NET_COMMON0_INTR_STS		    = 0x2A8,
+NET_COMMON0_INTR_MASK		    = 0x2A9,
+
+ /*1588 PTP timer */
+IF_1588_TMSMP_HI		    = 0x300,
+IF_1588_TMSMP_LO		    = 0x301,
+
+PTP_OFFSET_HI		    	    = 0x784,
+PTP_OFFSET_LO		            = 0x785,
+PTP_INC_DEN		            = 0x786,
+PTP_INC_NUM		            = 0x787,
+PTP_INC_INTG		            = 0x788,
+PTP_CONTROL		            = 0x789,
+PTP_STATUS			    = 0x78A,
+PTP_USER_VALUE_HI		    = 0x78B,
+PTP_USER_VALUE_LO		    = 0x78C,
+PTP_TMR1_HI		            = 0x78D,
+PTP_TMR1_LO		            = 0x78E,
+PTP_TMR2_HI		            = 0x78F,
+PTP_TMR2_LO		            = 0x790,
+PTP_TMR3_HI		            = 0x791,
+PTP_TMR3_LO		            = 0x792,
+
+IOSYS_RTC_CMD      = 0x7C0,
+IOSYS_RTC_RDATA_HI = 0x7C1,
+IOSYS_RTC_RDATA_LO = 0x7C2,
+
+};
+
+enum if_cfg_regs {
+  MAC_CONF1 = 0,
+  MAC_CONF2 = 1,
+  SGMII_MAX_FRAME_LEN = 4,
+  NETWK_INF_CTRL3_REG = 0x7c,
+  NETWK_INF_CTRL_REG = 0x7f
+};
+
+enum xaui_cfg_regs {
+	XGMAC_CTL_REG1 = 0x7f,
+	XGMAC_CTL_REG2 = 0x7e,
+	XGMAC_CTL_REG3 = 0x7d,
+	XGMAC_STATUS_REG = 0x7c,
+};
+
+enum netior_regs {
+	NETIOR_SOFTRESET = 3,
+	NETIOR_MISC_REG1_ADDR = 0x39,
+	NETIOR_MISC_REG2_ADDR = 0x3a,
+	NETIOR_MISC_REG3_ADDR = 0x3d,
+
+};
+enum NAE_TX_TYPE {
+	P2D_NEOP = 0,
+	P2P      = 1,
+	P2D_EOP  = 2,
+	MSC      = 3
+};
+
+/* NAE Interface Definitions
+ */
+enum NAE_INTF_TYPE {
+	GMAC_0 = 0,
+	GMAC_1 = 1,
+	GMAC_2 = 2,
+	GMAC_3 = 3,
+	XGMAC  = 4,
+	INTERLAKEN = 5,
+	PHY	 = 0xE,
+	LANE_CFG = 0xF,
+};
+
+enum NAE_BLOCK_NR {
+	BLOCK_0 = 0,
+	BLOCK_1,
+	BLOCK_2,
+	BLOCK_3,
+	BLOCK_4,
+	BLOCK_5,
+	BLOCK_6,
+	BLOCK_7,
+};
+
+typedef struct {
+        unsigned int base_vc;
+        unsigned int vc_limit;
+}nlm_fmn_config_t;
+
+typedef enum PHY_LANE_INTF_TYPE {
+	LANE_DISCONNECTED,
+	LANE_GMAC,
+	LANE_XGMAC,
+	LANE_8ILAKEN,
+} phy_lane_intf_t;
+
+
+/* MACSEC
+ */
+enum nae_macsec_cfg_regs {
+TX_MSEC_ETHER_TYPE		= 0x33e,
+TX_MSEC_PORT_EN          	= 0x33f,
+TX_MSEC_BYPASS         		= 0x340,
+TX_MSEC_PROG_STATUS      	= 0x341,
+TX_MSEC_INIT_PN          	= 0x342,
+TX_MSEC_PN_THRESH        	= 0x343,
+TX_MSEC_PREAMBLE_LEN_CODE      	= 0x344,
+TX_MSEC_KEY_IN_USE0		= 0x345,
+TX_MSEC_KEY_IN_USE1		= 0x346,
+TX_MSEC_KEY_IN_USE2		= 0x347,
+TX_MSEC_KEY_IN_USE3		= 0x348,
+TX_MSEC_KEY_XED_THRESH0     	= 0x349,
+TX_MSEC_KEY_XED_THRESH1      	= 0x34a,
+TX_MSEC_KEY_XED_THRESH2      	= 0x34b,
+TX_MSEC_KEY_XED_THRESH3      	= 0x34c,
+TX_MSEC_KEY_STALE0		= 0x34d,
+TX_MSEC_KEY_STALE2		= 0x34f,
+TX_MSEC_KEY_STALE3		= 0x350,
+TX_MSEC_KEY_ERR0            	= 0x351,
+TX_MSEC_KEY_ERR1            	= 0x352,
+TX_MSEC_KEY_ERR2            	= 0x353,
+TX_MSEC_KEY_ERR3            	= 0x354,
+
+TX_MSEC_MEM_DATAREG_0           = 0x38c,
+TX_MSEC_MEM_DATAREG_1           = 0x38d,
+TX_MSEC_MEM_DATAREG_2           = 0x38e,
+TX_MSEC_MEM_DATAREG_3           = 0x38f,
+TX_MSEC_MEM_CTRL_REG            = 0x390,
+
+RX_MSEC_MEM_DATAREG_0        	= 0x400,
+RX_MSEC_MEM_DATAREG_1        	= 0x401,
+RX_MSEC_MEM_DATAREG_2        	= 0x402,
+RX_MSEC_MEM_DATAREG_3        	= 0x403,
+RX_MSEC_MEM_CTRL_REG         	= 0x404,
+
+RX_MSEC_PORT_EN         	= 0x405,
+RX_MSEC_BYPASS         		= 0x406,
+RX_MSEC_SEC_TAG0		= 0x407,
+RX_MSEC_SEC_TAG1      		= 0x408,
+RX_MSEC_INIT_PN             	= 0x409,
+RX_MSEC_REPLAY_WIN_SIZE     	= 0x40a,
+RX_MSEC_SCI_MASK0_LO        	= 0x40b,
+RX_MSEC_SCI_MASK0_HI         	= 0x40c,
+RX_MSEC_SCI_MASK1_LO         	= 0x40d,
+RX_MSEC_SCI_MASK1_HI         	= 0x40e,
+RX_MSEC_SCI_MASK2_LO         	= 0x40f,
+RX_MSEC_SCI_MASK2_HI         	= 0x410,
+RX_MSEC_SCI_MASK3_LO         	= 0x411,
+RX_MSEC_SCI_MASK3_HI         	= 0x412,
+RX_MSEC_SCI_MASK4_LO         	= 0x413,
+RX_MSEC_SCI_MASK4_HI         	= 0x414,
+RX_MSEC_SCI_MASK5_LO         	= 0x415,
+RX_MSEC_SCI_MASK5_HI         	= 0x416,
+RX_MSEC_SCI_MASK6_LO         	= 0x417,
+RX_MSEC_SCI_MASK6_HI         	= 0x418,
+RX_MSEC_SCI_MASK7_LO         	= 0x419,
+RX_MSEC_SCI_MASK7_HI		= 0x41a,
+
+};
+
+#define RX_MSEC_SCI_MASK_LO(i) (0x40b + i *2)
+#define RX_MSEC_SCI_MASK_HI(i) (0x40c + i *2)
+
+/*
+ *  POE
+ */
+
+enum poe_reg_type {
+	PCIE_CFG_POE_REG = 0,
+	PCIE_MEM_POE_REG = 1,
+};
+
+enum poe_cfg_reg {
+  MAX_FLOW_MSGS0 = 64,
+  MAX_MSGS_CLASS0 = 72,
+  CLASS0_SIZE = 88,
+  ERROR_MESG0 = 96,
+  LO_CNT_OOO_MSG = 104,
+  LO_CNT_INORDER_MSG = 105,
+  LO_CNT_LOCBUF_ST = 106,
+  LO_CNT_EXTBUF_ST = 107,
+  LO_CNT_LOCBUF_ALLOC = 108,
+  LO_CNT_EXTBUF_ALLOC = 109,
+  HI_CNT_OOO_MSG = 110,
+  HI_CNT_INORDE_RMSG = 111,
+  HI_CNT_LOCBUF_ST = 112,
+  HI_CNT_EXTBUF_ST = 113,
+  HI_CNT_LOCBUF_ALLOC = 114,
+  HI_CNT_EXTBUF_ALLOC = 115,
+  DROP_CNT_DIST0 = 192,
+  DROP_CNT_CLASS0 = 208,
+  DROP_CNT_DIST_CLASS0 = 216,
+  DROP_CNT_CPU = 224,
+  DROP_CNT_MAX_FLOW =  225,
+  INT_VECTOR = 320,
+  POE_INT_MASK = 321,
+  FATAL_ERR_MASK = 322,
+  BIU_CONFIG = 323,
+  BIU_TIMEOUT = 324,
+  ENQUED_MSG_SENT = 336,
+  ENQUED_MSG_CNT = 337,
+  DIST_THRESHOLD0 = 448,
+  DIST_CLASS_DROP_ENABLE = 459,
+  DIST_VEC_DROP_ENABLE = 460,
+  DIST_DROP_TIMER = 461,
+  ERROR_LOG_WORD0 = 462,
+  ERROR_INJ_CTL = 465,
+  DIST_VEC_0_15 = 466,
+  LOCAL_FBP_BASE = 0x400,
+  MSG_STORAGE_BASE_ADR_L = 0x60,
+  FBP_BASE_ADR_L = 0x62,
+};
+
+enum poe_stats_reg {
+	OO_MSG_CNT_LO = 0xa8,
+	IN_ORDER_MSG_CNT_LO,
+	LOC_BUF_STOR_CNT_LO,
+	EXT_BUF_STOR_CNT_LO,
+	LOC_BUF_ALLOC_CNT_LO,
+	EXT_BUF_ALLOC_CNT_LO,
+        OO_MSG_CNT_HI ,
+        IN_ORDER_MSG_CNT_HI,
+        LOC_BUF_STOR_CNT_HI,
+        EXT_BUF_STOR_CNT_HI,
+        LOC_BUF_ALLOC_CNT_HI,
+        EXT_BUF_ALLOC_CNT_HI,
+	MODE_ERR_FLOW_ID,
+	POE_STATISTICS_EN,
+	POE_MAX_SIZE_FLOW,
+	POE_MAX_SIZE
+};
+
+#define POE_CL0_ENQ_SPILL_BASE_L	0x40
+#define POE_CL0_ENQ_SPILL_BASE_H	0x41
+#define POE_CL1_ENQ_SPILL_BASE_L	0x42
+#define POE_CL1_ENQ_SPILL_BASE_H	0x43
+#define POE_CL2_ENQ_SPILL_BASE_L	0x44
+#define POE_CL2_ENQ_SPILL_BASE_H	0x45
+#define POE_CL3_ENQ_SPILL_BASE_L	0x46
+#define POE_CL3_ENQ_SPILL_BASE_H	0x47
+#define POE_CL4_ENQ_SPILL_BASE_L	0x48
+#define POE_CL4_ENQ_SPILL_BASE_H	0x49
+#define POE_CL5_ENQ_SPILL_BASE_L	0x4a
+#define POE_CL5_ENQ_SPILL_BASE_H	0x4b
+#define POE_CL6_ENQ_SPILL_BASE_L	0x4c
+#define POE_CL6_ENQ_SPILL_BASE_H	0x4d
+#define POE_CL7_ENQ_SPILL_BASE_L	0x4e
+#define POE_CL7_ENQ_SPILL_BASE_H	0x4f
+
+#define POE_CL0_DEQ_SPILL_BASE_L	0x50
+#define POE_CL0_DEQ_SPILL_BASE_H	0x51
+#define POE_CL1_DEQ_SPILL_BASE_L	0x52
+#define POE_CL1_DEQ_SPILL_BASE_H	0x53
+#define POE_CL2_DEQ_SPILL_BASE_L	0x54
+#define POE_CL2_DEQ_SPILL_BASE_H	0x55
+#define POE_CL3_DEQ_SPILL_BASE_L	0x56
+#define POE_CL3_DEQ_SPILL_BASE_H	0x57
+#define POE_CL4_DEQ_SPILL_BASE_L	0x58
+#define POE_CL4_DEQ_SPILL_BASE_H	0x59
+#define POE_CL5_DEQ_SPILL_BASE_L	0x5a
+#define POE_CL5_DEQ_SPILL_BASE_H	0x5b
+#define POE_CL6_DEQ_SPILL_BASE_L	0x5c
+#define POE_CL6_DEQ_SPILL_BASE_H	0x5d
+#define POE_CL7_DEQ_SPILL_BASE_L	0x5e
+#define POE_CL7_DEQ_SPILL_BASE_H	0x5f
+
+#define POE_CL0_ENQ_SPILL_MAXLINE	0x64
+#define POE_CL1_ENQ_SPILL_MAXLINE	0x65
+#define POE_CL2_ENQ_SPILL_MAXLINE	0x66
+#define POE_CL3_ENQ_SPILL_MAXLINE	0x67
+#define POE_CL4_ENQ_SPILL_MAXLINE	0x68
+#define POE_CL5_ENQ_SPILL_MAXLINE	0x69
+#define POE_CL6_ENQ_SPILL_MAXLINE	0x6a
+#define POE_CL7_ENQ_SPILL_MAXLINE	0x6b
+
+#define POE_CL0_DEQ_SPILL_MAXLINE	0x6c
+#define POE_CL1_DEQ_SPILL_MAXLINE	0x6d
+#define POE_CL2_DEQ_SPILL_MAXLINE	0x6e
+#define POE_CL3_DEQ_SPILL_MAXLINE	0x6f
+#define POE_CL4_DEQ_SPILL_MAXLINE	0x70
+#define POE_CL5_DEQ_SPILL_MAXLINE	0x71
+#define POE_CL6_DEQ_SPILL_MAXLINE	0x72
+#define POE_CL7_DEQ_SPILL_MAXLINE	0x73
+
+#define POE_DIST_THRESHOLD_0 	0x200
+#define POE_DEST_THRESHOLD	0x204
+#define POE_DIST_ENABLE 0x205
+#define POE_DIST_VEC0	0x100
+#define POE_DIST_THRESHOLD_VAL 0xa
+#define POE_MAX_LOCAL_MSGS (6 << 10) /* 6K */
+#define POE_TX_TIMER     0x214
+#define POE_FBP_SP       0xb8
+#define POE_FBP_SP_EN    0xb9
+#define POE_LOC_ALLOC_EN 0xba
+#define POE_EXT_ALLOC_EN 0xbb
+#define POE_LOCAL_FBP_BASE 0x400
+
+#define POE_ENQ_SPILL_THOLD	0x208
+#define POE_DEQ_SPILL_THOLD	0x209
+#define POE_DEQ_SPILL_TIMER	0x20A
+#define POE_DISTR_CLASS_DROP_EN	0x20B
+#define POE_DISTR_VEC_DROP_EN	0x20C
+#define POE_DISTRVEC_DROP_TIMER	0x20D
+
+#define EXT_FBP_START_ADDR       0x1800
+#define MAX_POE_EXT_MSG_STORAGE  (58 << 10) /* 58K entries */
+#define POE_FBP_SP_INIT	 	 0x740
+
+#define XLP3XX_EXT_FBP_START_ADDR	0x1000
+#define XLP3XX_POE_MAX_LOCAL_MSGS	(4 << 10)
+#define XLP3XX_MAX_POE_EXT_MSG_STORAGE 	(28 << 10)
+#define XLP3XX_POE_FBP_SP_INIT	 	0x380
+
+enum POE_SW_CODE {
+	DROP_IN_NAE = 0,
+	FWD_DEST,
+	RENQ_DVEC,
+	RENQ_DEST,
+	FWD_DVEC,
+	DROP_IN_POE,
+	RENQ_DVEC_SERIAL,
+	RENQ_DEST_SERIAL
+};
+
+/*
+ *  UCORE
+ */
+#define MAX_NAE_UCORES 16
+#define NAE_UCORE_MASK 0xffff
+#define CODE_SIZE_PER_UCORE (4 << 10)
+#define UC_MAGIC_REG_OFFSET_TO_INDEX(offset) (((offset) - 0x8000)/4)
+#define UCORE_OUTBUF_DONE  0x8000
+#define UCORE_RX_PKT_RDY  0x8004
+#define UCORE_RX_PKT_INFO  0x8008
+#define UCORE_CAM0  0x800c
+#define UCORE_CAM1  0x8010
+#define UCORE_CAM2  0x8014
+#define UCORE_CAM3  0x8018
+#define UCORE_CAM_RES  0x801c
+#define UCORE_CSUM_INFO  0x8020
+#define UCORE_CRC_INFO  0x8024
+#define UCORE_CRC_POS  0x8028
+#define UCORE_FREE_FIFO_EMPTY  0x802c
+#define UCORE_PKT_DISTR  0x8030
+#define UCORE_MAGIC_REG_BASE UCORE_OUTBUF_DONE
+#define UCORE_MAGIC_REG_LIMIT UCORE_PKT_DISTR
+#define UCORE_MAX_MAGIC_REGS (1 + (UCORE_MAGIC_REG_LIMIT - UCORE_MAGIC_REG_BASE) / 4)
+
+#define UCORE_PKT_DISCARD 0x2
+
+/* Ucore Memory Map. To be used in Microcode based apps only */
+#define UCORE_SHARED_CAM_START 0x17000
+#define UCORE_SHARE_CAM_END    0x17bff
+#define UCORE_SHARED_MEM_START 0x18000
+#define UCORE_SHARE_MEM_END    0x1ffff
+
+/* Ucore Shared memory Map for cpu. To be used in cpu only, to access ucore shared mem */
+#define UCORE_CPU_SHARED_CAM_START 0x18000
+#define UCORE_CPU_SHARED_CAM_END   0x18bff
+#define UCORE_CPU_SHARED_MEM_START 0x10000
+#define UCORE_CPU_SHARED_MEM_END   0x17fff
+
+#define SYS_REG_BASE	(( KSEG1 + 0x18000000 + XLP_PCIE_NODE0_SYSOFFSET) & 0x1fffffff )
+#define SYS_REG_INDEX(x)   ( 0x40 + (x))
+
+/* System Management PCIe config registers */
+enum sys_cfg_regs {
+    CHIP_RESET              = 0x00,
+    POWER_ON_RESET_CFG      = 0x01,
+    EFUSE_DEVICE_CFG0       = 0x02,
+    EFUSE_DEVICE_CFG1       = 0x03,
+    EFUSE_DEVICE_CFG2       = 0x04,
+    EFUSE_DEVICE_CFG3       = 0x05,
+    EFUSE_DEVICE_CFG4       = 0x06,
+    EFUSE_DEVICE_CFG5       = 0x07,
+    EFUSE_DEVICE_CFG6       = 0x08,
+    EFUSE_DEVICE_CFG7       = 0x09,
+    PLL_CTRL                = 0x0a,
+    CPU_RESET               = 0x0b,
+    CPU_THREAD_EN           = 0x0c,
+    CPU_NONCOHERENT_MODE    = 0x0d,
+    CORE_DFS_DIS_CTRL       = 0x0e,
+    CORE_DFS_RST_CTRL       = 0x0f,
+    CORE_DFS_BYP_CTRL       = 0x10,
+    CORE_DFS_PHA_CTRL       = 0x11,
+    CORE_DFS_DIV_INC_CTRL   = 0x12,
+    CORE_DFS_DIV_DEC_CTRL   = 0x13,
+    CORE_DFS_DIV_VALUE      = 0x14,
+    SYS_RESET               = 0x15,
+    SYS_DFS_DIS_CTRL        = 0x16,
+    SYS_DFS_RST_CTRL        = 0x17,
+    SYS_DFS_BYP_CTRL        = 0x18,
+    SYS_DFS_DIV_INC_CTRL    = 0x19,
+    SYS_DFS_DIV_DEC_CTRL    = 0x1a,
+    SYS_DFS_DIV_VALUE0      = 0x1b,
+    SYS_DFS_DIV_VALUE1      = 0x1c,
+    CPU_SENSE_AMP_DLY       = 0x1d,
+    SOC_SENSE_AMP_DLY       = 0x1e,
+    SYS_CTRL0               = 0x1f,
+    SYS_CTRL1               = 0x20,
+    TIMEOUT_BSI             = 0x21,
+    BYTE_SWAP               = 0x22,
+    VRM_VID                 = 0x23,
+    SYS_PWR_RAM_CMD         = 0x24,
+    SYS_PWR_RAM_ADDR        = 0x25,
+    SYS_PWR_RAM_DATA0       = 0x26,
+    SYS_PWR_RAM_DATA1       = 0x27,
+    SYS_PWR_RAM_DATA2       = 0x28,
+    SYS_PWR_UCODE           = 0x29,
+    CPU0_PWR_STATUS         = 0x2a,
+    CPU1_PWR_STATUS         = 0x2b,
+    CPU2_PWR_STATUS         = 0x2c,
+    CPU3_PWR_STATUS         = 0x2d,
+    CPU4_PWR_STATUS         = 0x2e,
+    CPU5_PWR_STATUS         = 0x2f,
+    CPU6_PWR_STATUS         = 0x30,
+    CPU7_PWR_STATUS         = 0x31,
+    SYS_STATUS              = 0x32,
+    SYS_INT_POL             = 0x33,
+    SYS_INT_TYPE            = 0x34,
+    SYS_INT_STATUS          = 0x35,
+    SYS_INT_EN0             = 0x36,
+    SYS_INT_EN1             = 0x37,
+
+    /* Added XLP3XX or XLP8XX.Bx Registers: from 0x38 to 0x8a*/
+    PLL_DFS_DIS_CTRL        = 0x38,
+    PLL_DFS_RST_CTRL        = 0x39,
+    PLL_DFS_BYP_CTRL        = 0x3a,
+    PLL_DFS_DIV_INC_CTRL    = 0x3b,
+    PLL_DFS_DIV_DEC_CTRL    = 0x3c,
+    PLL_DFS_DIV_VALUE       = 0x3d,
+    SYS_DISABLE             = 0x3e,
+    SYS_UCO_S_ECC           = 0x3f,
+    SYS_UCO_M_ECC           = 0x40,
+    SYS_UCO_ADDR            = 0x41,
+    SYS_UCO_INST            = 0x42,
+
+    MEM_BIST0               = 0x43,
+    MEM_BIST1               = 0x44,
+    MEM_BIST2               = 0x45,
+    MEM_BIST3               = 0x46,
+    MEM_BIST4               = 0x47,
+    MEM_BIST5               = 0x48,
+    MEM_BIST6               = 0x49,
+    MEM_BIST7               = 0x4a,
+    MEM_BIST8               = 0x4b,
+    MEM_BIST9               = 0x4c,
+    MEM_BIST10              = 0x4d,
+    MEM_BIST11              = 0x4e,
+    MEM_BIST12              = 0x4f,
+    MEM_STAT0               = 0x50,
+    MEM_STAT1               = 0x51,
+
+    SYS_SCRATCH0            = 0x52,
+    SYS_SCRATCH1            = 0x53,
+    SYS_SCRATCH2            = 0x54,
+    SYS_SCRATCH3	    = 0x55,
+
+    SYS_COUNTER             = 0x56,
+    SYS_CTRLSECUREBOOT      = 0x57,
+    SYS_SECUREKEY           = 0x60,
+    SYS_EFUSECTRL           = 0x80,
+    SYS_EFUSECMD            = 0x81,
+    SYS_EFUSECMDKEY         = 0x82,
+    SYS_EFUSESTAT           = 0x8a
+};
+
+
+#define XLP2XX_CHIPRESET_REG                           0x0
+#define XLP2XX_POWERONRESETCFG_REG                     0x1
+#define XLP2XX_EFUSEDEVICECFG0_REG                     0x2
+#define XLP2XX_EFUSEDEVICECFG1_REG                     0x3
+#define XLP2XX_EFUSEDEVICECFG2_REG                     0x4
+#define XLP2XX_EFUSEDEVICECFG3_REG                     0x5
+#define XLP2XX_EFUSEDEVICECFG4_REG                     0x6
+#define XLP2XX_EFUSEDEVICECFG5_REG                     0x7
+#define XLP2XX_EFUSEDEVICECFG6_REG                     0x8
+#define XLP2XX_EFUSEDEVICECFG7_REG                     0x9
+#define XLP2XX_PLLCTRL_REG                             0xa
+#define XLP2XX_CPURESET_REG                            0xb
+#define XLP2XX_CPUTHREADEN_REG                         0xc
+#define XLP2XX_CPUNONCOHERENTMODE_REG                  0xd
+#define XLP2XX_TCUDISABLE_REG                          0xe
+#define XLP2XX_CPUSTOP_REG                             0xf
+#define XLP2XX_CPUPSWCTRL_REG                          0x10
+#define XLP2XX_CPUPWRDOWN_REG                          0x11
+#define XLP2XX_CPUMEMCLR_REG                           0x12
+#define XLP2XX_SYSDISABLE_REG                          0x14
+#define XLP2XX_SYSRESET_REG                            0x15
+#define XLP2XX_CPUPSWISO_REG                           0x16
+#define XLP2XX_CPUPSWSET_REG                           0x17
+#define XLP2XX_CPUPSWRESET_REG                         0x18
+#define XLP2XX_CPUPSWCLKEN_REG                         0x19
+#define XLP2XX_CPUPSWIN_REG                            0x1a
+#define XLP2XX_CPUPSWSRAMOFF_REG                       0x1b
+#define XLP2XX_CPUPSWSRAMCLKEN_REG                     0x1c
+#define XLP2XX_CPUSENSEAMPDLY_REG                      0x1d
+#define XLP2XX_SOCSENSEAMPDLY_REG                      0x1e
+#define XLP2XX_SYSCTRL0_REG                            0x1f
+#define XLP2XX_SYSCTRL1_REG                            0x20
+#define XLP2XX_TIMEOUTBSI_REG                          0x21
+#define XLP2XX_BYTESWAP_REG                            0x22
+#define XLP2XX_SYSVRMVID_REG                           0x23
+#define XLP2XX_SYSPWRRAMCMD_REG                        0x24
+#define XLP2XX_SYSPWRRAMADDR_REG                       0x25
+#define XLP2XX_SYSPWRRAMDATA0_REG                      0x26
+#define XLP2XX_SYSPWRRAMDATA1_REG                      0x27
+#define XLP2XX_SYSPWRRAMDATA2_REG                      0x28
+#define XLP2XX_SYSPWRUCODE_REG                         0x29
+#define XLP2XX_SYSPWRSTATUS0_REG                       0x2a
+#define XLP2XX_SYSPWRSTATUS1_REG                       0x2b
+#define XLP2XX_SYSSTATUS_REG                           0x32
+#define XLP2XX_SYSINTPOL_REG                           0x33
+#define XLP2XX_SYSINTTYPE_REG                          0x34
+#define XLP2XX_SYSINTSTATUS_REG                        0x35
+#define XLP2XX_SYSINTENABLE0_REG                       0x36
+#define XLP2XX_SYSINTENABLE1_REG                       0x37
+#define XLP2XX_CPUSTOPPIC_REG                          0x38
+#define XLP2XX_CPUSTOPNBU_REG                          0x39
+#define XLP2XX_CPUSTOPMSG_REG                          0x3a
+#define XLP2XX_CPUPSWDATAOUT_REG                       0x3b
+#define XLP2XX_CPUPWRSTATUS_REG                        0x3c
+#define XLP2XX_CPUMEMCLRDONE_REG                       0x3d
+#define XLP2XX_SYSUCOSECC_REG                          0x3f
+#define XLP2XX_SYSUCOMECC_REG                          0x40
+#define XLP2XX_SYSUCOADDR_REG                          0x41
+#define XLP2XX_SYSUCOINST_REG                          0x42
+#define XLP2XX_SYSMEMBISTGO0_REG                       0x43
+#define XLP2XX_SYSMEMBISTGO1_REG                       0x44
+#define XLP2XX_SYSMEMBISTGO2_REG                       0x45
+#define XLP2XX_SYSMEMBISTGO3_REG                       0x46
+#define XLP2XX_SYSMEMBISTGO4_REG                       0x47
+#define XLP2XX_SYSMEMBISTGO5_REG                       0x48
+#define XLP2XX_SYSMEMBISTGO6_REG                       0x49
+#define XLP2XX_SYSMEMBISTGO7_REG                       0x4a
+#define XLP2XX_SYSMEMBISTGO8_REG                       0x4b
+#define XLP2XX_SYSMEMBISTGO9_REG                       0x4c
+#define XLP2XX_SYSMEMBISTGO10_REG                      0x4d
+#define XLP2XX_SYSMEMBISTGO11_REG                      0x4e
+#define XLP2XX_SYSMEMBISTGO12_REG                      0x4f
+#define XLP2XX_SYSMEMSTAT0_REG                         0x54
+#define XLP2XX_SYSMEMSTAT1_REG                         0x55
+#define XLP2XX_SYSSCRATCH0_REG                         0x58
+#define XLP2XX_SYSSCRATCH1_REG                         0x59
+#define XLP2XX_SYSSCRATCH2_REG                         0x5a
+#define XLP2XX_SYSSCRATCH3_REG                         0x5b
+#define XLP2XX_SYSCOUNTER_REG                          0x5c
+#define XLP2XX_SYSCTRLSECUREBOOT_REG                   0x5d
+#define XLP2XX_SYSSECUREKEY_REG                        0xc0
+#define XLP2XX_SYSEFUSECTRL_REG                        0x140
+#define XLP2XX_SYSEFUSECMD_REG                         0x141
+#define XLP2XX_SYSEFUSECMDDATA_REG                     0x142
+#define XLP2XX_SYSEFUSESTAT_REG                        0x14a
+#define XLP2XX_SYSTHERMCTRL_REG                        0x14b
+#define XLP2XX_CPUTHERMPWRDOWN_REG                     0x14c
+#define XLP2XX_SYSTHERMPWRDOWN_REG                     0x14d
+#define XLP2XX_CPUTHERMEN_REG                          0x14e
+#define XLP2XX_SYSTHERMEN_REG                          0x14f
+#define XLP2XX_THERMTHRESH0_REG                        0x150
+#define XLP2XX_THERMTHRESH1_REG                        0x151
+#define XLP2XX_THERMTHRESH2_REG                        0x152
+#define XLP2XX_THERMTHRESH3_REG                        0x153
+#define XLP2XX_CPUTHERMINTSTATUSHIGH0_REG              0x154
+#define XLP2XX_CPUTHERMINTSTATUSLOW0_REG               0x155
+#define XLP2XX_SYSTHERMINTSTATUSHIGH0_REG              0x156
+#define XLP2XX_SYSTHERMINTSTATUSLOW0_REG               0x157
+#define XLP2XX_CPUTHERMINTSTATUSHIGH1_REG              0x158
+#define XLP2XX_CPUTHERMINTSTATUSLOW1_REG               0x159
+#define XLP2XX_SYSTHERMINTSTATUSHIGH1_REG              0x15a
+#define XLP2XX_SYSTHERMINTSTATUSLOW1_REG               0x15b
+#define XLP2XX_CPUTHERMINTSTATUSHIGH2_REG              0x15c
+#define XLP2XX_CPUTHERMINTSTATUSLOW2_REG               0x15d
+#define XLP2XX_SYSTHERMINTSTATUSHIGH2_REG              0x15e
+#define XLP2XX_SYSTHERMINTSTATUSLOW2_REG               0x15f
+#define XLP2XX_CPUTHERMINTSTATUSHIGH3_REG              0x160
+#define XLP2XX_CPUTHERMINTSTATUSLOW3_REG               0x161
+#define XLP2XX_SYSTHERMINTSTATUSHIGH3_REG              0x162
+#define XLP2XX_SYSTHERMINTSTATUSLOW3_REG               0x163
+#define XLP2XX_CPUTHERMINTENHIGH0_REG                  0x164
+#define XLP2XX_CPUTHERMINTENLOW0_REG                   0x165
+#define XLP2XX_SYSTHERMINTENHIGH0_REG                  0x166
+#define XLP2XX_SYSTHERMINTENLOW0_REG                   0x167
+#define XLP2XX_CPUTHERMINTENHIGH1_REG                  0x168
+#define XLP2XX_CPUTHERMINTENLOW1_REG                   0x169
+#define XLP2XX_SYSTHERMINTENHIGH1_REG                  0x16a
+#define XLP2XX_SYSTHERMINTENLOW1_REG                   0x16b
+#define XLP2XX_CPUTHERMINTENHIGH2_REG                  0x16c
+#define XLP2XX_CPUTHERMINTENLOW2_REG                   0x16d
+#define XLP2XX_SYSTHERMINTENHIGH2_REG                  0x16e
+#define XLP2XX_SYSTHERMINTENLOW2_REG                   0x16f
+#define XLP2XX_CPUTHERMINTENHIGH3_REG                  0x170
+#define XLP2XX_CPUTHERMINTENLOW3_REG                   0x171
+#define XLP2XX_SYSTHERMINTENHIGH3_REG                  0x172
+#define XLP2XX_SYSTHERMINTENLOW3_REG                   0x173
+#define XLP2XX_CPUTHERMCOUNT_REG                       0x174
+#define XLP2XX_SYSTHERMCOUNT_REG                       0x194
+#define XLP2XX_THERMCOUNT_REG                          0x19c
+
+#define XLP2XX_SYSCPUPLLCTRL0_REG                      0x1c0
+#define XLP2XX_SYSCPUPLLCTRL1_REG                      0x1c1
+#define XLP2XX_SYSCPUPLLCTRL2_REG                      0x1c2
+#define XLP2XX_SYSCPUPLLCTRL3_REG                      0x1c3
+
+#define XLP2XX_SYSCPU1PLLCTRL0_REG                      0x1c4
+#define XLP2XX_SYSCPU1PLLCTRL1_REG                      0x1c5
+#define XLP2XX_SYSCPU1PLLCTRL2_REG                      0x1c6
+#define XLP2XX_SYSCPU1PLLCTRL3_REG                      0x1c7
+
+#define XLP2XX_SYSSYSPLLCTRL0_REG                      0x240
+#define XLP2XX_SYSSYSPLLCTRL1_REG                      0x241
+#define XLP2XX_SYSSYSPLLCTRL2_REG                      0x242
+#define XLP2XX_SYSSYSPLLCTRL3_REG                      0x243
+#define XLP2XX_SYSDMCPLLCTRL0_REG                      0x244
+#define XLP2XX_SYSDMCPLLCTRL1_REG                      0x245
+#define XLP2XX_SYSDMCPLLCTRL2_REG                      0x246
+#define XLP2XX_SYSDMCPLLCTRL3_REG                      0x247
+
+#define XLP2XX_SYSDEVPLLCTRL0_REG                      0x248
+#define XLP2XX_SYSDEVPLLCTRL1_REG                      0x249
+#define XLP2XX_SYSDEVPLLCTRL2_REG                      0x24a
+#define XLP2XX_SYSDEVPLLCTRL3_REG                      0x24b
+
+#define XLP2XX_SYSDEV1PLLCTRL0_REG                      0x24c
+#define XLP2XX_SYSDEV1PLLCTRL1_REG                      0x24d
+#define XLP2XX_SYSDEV1PLLCTRL2_REG                      0x24e
+#define XLP2XX_SYSDEV1PLLCTRL3_REG                      0x24f
+
+#define XLP2XX_SYSDEV2PLLCTRL0_REG                      0x250
+#define XLP2XX_SYSDEV2PLLCTRL1_REG                      0x251
+#define XLP2XX_SYSDEV2PLLCTRL2_REG                      0x252
+#define XLP2XX_SYSDEV2PLLCTRL3_REG                      0x253
+
+#define XLP2XX_SYSCPUPLLCHGCTRL_REG                    0x288
+#define XLP2XX_SYSSYSPLLCHGCTRL_REG                    0x289
+#define XLP2XX_SYSCLKDEVDIS_REG                        0x28a
+#define XLP2XX_SYSCLKDEVSEL_REG                        0x28b
+#define XLP2XX_SYSCLKDEVDIV_REG                        0x28c
+#define XLP2XX_SYSCLKDEVCHG_REG                        0x28d
+#define XLP2XX_SYSCLKDEVSELREG_REG                     0x28e
+#define XLP2XX_SYSCLKDEVDIVREG_REG                     0x28f
+#define XLP2XX_SYSCPUPLLLOCK_REG                       0x29f
+#define XLP2XX_SYSSYSPLLLOCK_REG                       0x2a0
+#define XLP2XX_SYSPLLMEMCMD_REG                        0x2a1
+#define XLP2XX_SYSCPUPLLMEMREQ_REG                     0x2a2
+#define XLP2XX_SYSSYSPLLMEMREQ_REG                     0x2a3
+#define XLP2XX_SYSPLLMEMSTAT_REG                       0x2a4
+
+#define XLP2XX_RTC_REG_SECONDS_REG                         0x300
+#define XLP2XX_RTC_REG_MINUTES_REG                         0x301
+#define XLP2XX_RTC_REG_CENTURY_HOURS_REG                   0x302
+#define XLP2XX_RTC_REG_DAY_REG                             0x303
+#define XLP2XX_RTC_REG_DATE_REG                            0x304
+#define XLP2XX_RTC_REG_MONTH_REG                           0x305
+#define XLP2XX_RTC_REG_YEAR_REG                            0x306
+#define XLP2XX_RTC_REG_CONTROL_REG                         0x307
+#define XLP2XX_RTC_REG_STATUS_REG                          0x308
+#define XLP2XX_RTC_REG_FLAG_REG                            0x309
+#define XLP2XX_RTC_REG_CLOCK_PERIOD_REG                    0x30a
+#define XLP2XX_RTC_REG_LOCK_REG                            0x30b
+#define XLP2XX_RTC_REG_VOLT_REG                            0x30c
+#define XLP2XX_RTC_REG_TEST_REG                            0x30f
+
+/*  Reference Clock Select 00:66; 01:100; 10:125; 11:133 */
+#define XLP2XX_SYS_PWRON_RCS(x) (((x)>>18) & 0x3)
+#define XLP2XX_SYS_NAND_BOOT(x) ( ((x) & 0x1f) == 6)
+
+enum xlp2xx_sys_cfg_regs {
+	XLP2XX_RESET			= 0,
+	XLP2XX_POWER_ON_RESET_CFG	= 1,
+    	XLP2XX_EFUSE_DEVICE_CFG0	= 2,
+    	XLP2XX_EFUSE_DEVICE_CFG1        = 3,
+	XLP2XX_EFUSE_DEVICE_CFG2       	= 4,
+	XLP2XX_EFUSE_DEVICE_CFG3       	= 5,
+	XLP2XX_EFUSE_DEVICE_CFG4       	= 6,
+	XLP2XX_EFUSE_DEVICE_CFG5       	= 7,
+	XLP2XX_EFUSE_DEVICE_CFG6       	= 8,
+	XLP2XX_EFUSE_DEVICE_CFG7       	= 9,
+	XLP2XX_SYS_PLL_CTRL             = 10,
+
+	XLP2XX_CPU_RESET                            = 0xb,
+	XLP2XX_CPU_THREAD_EN                        = 0xc,
+	XLP2XX_CPUNONCOHERENTMODE                 = 0xd,
+	XLP2XX_TCU_DISABLE                         = 0xe,
+	XLP2XX_CPU_STOP                            = 0xf,
+	XLP2XX_CPU_PSWCTRL                         = 0x10,
+	XLP2XX_CPU_PWRDOWN                         = 0x11,
+	XLP2XX_CPU_MEMCLR                          = 0x12,
+
+	XLP2XX_SYSDISABLE                         = 0x14,
+	XLP2XX_SYSRESET                           = 0x15,
+	XLP2XX_CPUPSWISO                          = 0x16,
+	XLP2XX_CPUPSWSET                          = 0x17,
+	XLP2XX_CPUPSWRESET                        = 0x18,
+	XLP2XX_CPUPSWCLKEN                        = 0x19,
+	XLP2XX_CPUPSWIN                           = 0x1a,
+	XLP2XX_CPUPSWSRAMOFF                      = 0x1b,
+	XLP2XX_CPUPSWSRAMCLKEN                    = 0x1c,
+	XLP2XX_CPUSENSEAMPDLY                     = 0x1d,
+	XLP2XX_SOCSENSEAMPDLY                     = 0x1e,
+	XLP2XX_SYSCTRL0                           = 0x1f,
+	XLP2XX_SYSCTRL1                           = 0x20,
+	XLP2XX_TIMEOUTBSI                         = 0x21,
+	XLP2XX_BYTESWAP                           = 0x22,
+	XLP2XX_SYSVRMVID                          = 0x23,
+	XLP2XX_SYSPWRRAMCMD                       = 0x24,
+	XLP2XX_SYSPWRRAMADDR                      = 0x25,
+	XLP2XX_SYSPWRRAMDATA0                     = 0x26,
+	XLP2XX_SYSPWRRAMDATA1                     = 0x27,
+	XLP2XX_SYSPWRRAMDATA2                     = 0x28,
+	XLP2XX_SYSPWRUCODE                        = 0x29,
+	XLP2XX_SYSPWRSTATUS0                      = 0x2a,
+	XLP2XX_SYSPWRSTATUS1                      = 0x2b,
+	XLP2XX_SYSSTATUS                          = 0x32,
+	XLP2XX_SYSINTPOL                          = 0x33,
+	XLP2XX_SYSINTTYPE                         = 0x34,
+	XLP2XX_SYSINTSTATUS                       = 0x35,
+	XLP2XX_SYSINTENABLE0                      = 0x36,
+	XLP2XX_SYSINTENABLE1                      = 0x37,
+	XLP2XX_CPUSTOPPIC                         = 0x38,
+	XLP2XX_CPUSTOPNBU                         = 0x39,
+	XLP2XX_CPUSTOPMSG                         = 0x3a,
+	XLP2XX_CPUPSWDATAOUT                      = 0x3b,
+	XLP2XX_CPUPWRSTATUS                       = 0x3c,
+	XLP2XX_CPUMEMCLRDONE                      = 0x3d,
+	XLP2XX_SYSUCOSECC                         = 0x3f,
+	XLP2XX_SYSUCOMECC                         = 0x40,
+	XLP2XX_SYSUCOADDR                         = 0x41,
+	XLP2XX_SYSUCOINST                         = 0x42,
+	XLP2XX_SYSMEMBISTGO0                      = 0x43,
+	XLP2XX_SYSMEMBISTGO1                      = 0x44,
+	XLP2XX_SYSMEMBISTGO2                      = 0x45,
+	XLP2XX_SYSMEMBISTGO3                      = 0x46,
+	XLP2XX_SYSMEMBISTGO4                      = 0x47,
+	XLP2XX_SYSMEMBISTGO5                      = 0x48,
+	XLP2XX_SYSMEMBISTGO6                      = 0x49,
+	XLP2XX_SYSMEMBISTGO7                      = 0x4a,
+	XLP2XX_SYSMEMBISTGO8                      = 0x4b,
+	XLP2XX_SYSMEMBISTGO9                      = 0x4c,
+	XLP2XX_SYSMEMBISTGO10                     = 0x4d,
+	XLP2XX_SYSMEMBISTGO11                     = 0x4e,
+	XLP2XX_SYSMEMBISTGO12                     = 0x4f,
+	XLP2XX_SYSMEMSTAT0                        = 0x54,
+	XLP2XX_SYSMEMSTAT1                        = 0x55,
+	XLP2XX_SYSSCRATCH0                        = 0x58,
+	XLP2XX_SYSSCRATCH1                        = 0x59,
+	XLP2XX_SYSSCRATCH2                        = 0x5a,
+	XLP2XX_SYSSCRATCH3                        = 0x5b,
+	XLP2XX_SYSCOUNTER                         = 0x5c,
+	XLP2XX_SYSCTRLSECUREBOOT                  = 0x5d,
+	XLP2XX_SYSSECUREKEY                       = 0xc0,
+	XLP2XX_SYSEFUSECTRL                       = 0x140,
+	XLP2XX_SYSEFUSECMD                        = 0x141,
+	XLP2XX_SYSEFUSECMDDATA                    = 0x142,
+	XLP2XX_SYSEFUSESTAT                       = 0x14a,
+	XLP2XX_SYSTHERMCTRL                       = 0x14b,
+	XLP2XX_CPUTHERMPWRDOWN                    = 0x14c,
+	XLP2XX_SYSTHERMPWRDOWN                    = 0x14d,
+	XLP2XX_CPUTHERMEN                         = 0x14e,
+	XLP2XX_SYSTHERMEN                         = 0x14f,
+	XLP2XX_THERMTHRESH0                       = 0x150,
+	XLP2XX_THERMTHRESH1                       = 0x151,
+	XLP2XX_THERMTHRESH2                       = 0x152,
+	XLP2XX_THERMTHRESH3                       = 0x153,
+	XLP2XX_CPUTHERMINTSTATUSHIGH0             = 0x154,
+	XLP2XX_CPUTHERMINTSTATUSLOW0              = 0x155,
+	XLP2XX_SYSTHERMINTSTATUSHIGH0             = 0x156,
+	XLP2XX_SYSTHERMINTSTATUSLOW0              = 0x157,
+	XLP2XX_CPUTHERMINTSTATUSHIGH1             = 0x158,
+	XLP2XX_CPUTHERMINTSTATUSLOW1              = 0x159,
+	XLP2XX_SYSTHERMINTSTATUSHIGH1             = 0x15a,
+	XLP2XX_SYSTHERMINTSTATUSLOW1              = 0x15b,
+	XLP2XX_CPUTHERMINTSTATUSHIGH2             = 0x15c,
+	XLP2XX_CPUTHERMINTSTATUSLOW2              = 0x15d,
+	XLP2XX_SYSTHERMINTSTATUSHIGH2             = 0x15e,
+	XLP2XX_SYSTHERMINTSTATUSLOW2              = 0x15f,
+	XLP2XX_CPUTHERMINTSTATUSHIGH3             = 0x160,
+	XLP2XX_CPUTHERMINTSTATUSLOW3              = 0x161,
+	XLP2XX_SYSTHERMINTSTATUSHIGH3             = 0x162,
+	XLP2XX_SYSTHERMINTSTATUSLOW3              = 0x163,
+	XLP2XX_CPUTHERMINTENHIGH0                 = 0x164,
+	XLP2XX_CPUTHERMINTENLOW0                  = 0x165,
+	XLP2XX_SYSTHERMINTENHIGH0                 = 0x166,
+	XLP2XX_SYSTHERMINTENLOW0                  = 0x167,
+	XLP2XX_CPUTHERMINTENHIGH1                 = 0x168,
+	XLP2XX_CPUTHERMINTENLOW1                  = 0x169,
+	XLP2XX_SYSTHERMINTENHIGH1                 = 0x16a,
+	XLP2XX_SYSTHERMINTENLOW1                  = 0x16b,
+	XLP2XX_CPUTHERMINTENHIGH2                 = 0x16c,
+	XLP2XX_CPUTHERMINTENLOW2                  = 0x16d,
+	XLP2XX_SYSTHERMINTENHIGH2                 = 0x16e,
+	XLP2XX_SYSTHERMINTENLOW2                  = 0x16f,
+	XLP2XX_CPUTHERMINTENHIGH3                 = 0x170,
+	XLP2XX_CPUTHERMINTENLOW3                  = 0x171,
+	XLP2XX_SYSTHERMINTENHIGH3                 = 0x172,
+	XLP2XX_SYSTHERMINTENLOW3                  = 0x173,
+	XLP2XX_CPUTHERMCOUNT                      = 0x174,
+	XLP2XX_SYSTHERMCOUNT                      = 0x194,
+	XLP2XX_THERMCOUNT                         = 0x19c,
+
+	XLP2XX_CORE0_PLL_CTRL0		= 0x1c0,
+	XLP2XX_CORE0_PLL_CTRL1		= 0x1c1,
+	XLP2XX_CORE0_PLL_CTRL2		= 0x1c2,
+	XLP2XX_CORE0_PLL_CTRL3		= 0x1c3,
+
+	XLP2XX_CORE1_PLL_CTRL0		= 0x1c4,
+	XLP2XX_CORE1_PLL_CTRL1		= 0x1c5,
+	XLP2XX_CORE1_PLL_CTRL2		= 0x1c6,
+	XLP2XX_CORE1_PLL_CTRL3		= 0x1c7,
+
+	XLP2XX_SYS_PLL_CTRL0		= 0x240,
+	XLP2XX_SYS_PLL_CTRL1		= 0x241,
+	XLP2XX_SYS_PLL_CTRL2		= 0x242,
+	XLP2XX_SYS_PLL_CTRL3		= 0x243,
+	XLP2XX_DMC_PLL_CTRL0		= 0x244,
+	XLP2XX_DMC_PLL_CTRL1		= 0x245,
+	XLP2XX_DMC_PLL_CTRL2		= 0x246,
+	XLP2XX_DMC_PLL_CTRL3		= 0x247,
+
+	XLP2XX_DEV0_PLL_CTRL0		= 0x248,
+	XLP2XX_DEV0_PLL_CTRL1		= 0x249,
+	XLP2XX_DEV0_PLL_CTRL2		= 0x24a,
+	XLP2XX_DEV0_PLL_CTRL3		= 0x24b,
+	XLP2XX_DEV1_PLL_CTRL0		= 0x24c,
+	XLP2XX_DEV1_PLL_CTRL1		= 0x24d,
+	XLP2XX_DEV1_PLL_CTRL2		= 0x24e,
+	XLP2XX_DEV1_PLL_CTRL3		= 0x24f,
+	XLP2XX_DEV2_PLL_CTRL0		= 0x250,
+	XLP2XX_DEV2_PLL_CTRL1		= 0x251,
+	XLP2XX_DEV2_PLL_CTRL2		= 0x252,
+	XLP2XX_DEV2_PLL_CTRL3		= 0x253,
+
+	XLP2XX_CPU_PLL_CHG_CTRL		= 0x288,
+	XLP2XX_SYS_PLL_CHG_CTRL		= 0x289,
+	XLP2XX_SYS_CLK_DEV_DIS		= 0x28a,
+	XLP2XX_SYS_CLK_DEV_SEL		= 0x28b,
+	XLP2XX_SYS_CLK_DEV_DIV		= 0x28c,
+	XLP2XX_SYS_CLK_DEV_CHG		= 0x28d,
+	XLP2XX_SYS_CLK_DEV_SEL_REG	= 0x28e,
+	XLP2XX_SYS_CLK_DEV_DIV_REG	= 0x28f,
+	XLP2XX_SYS_CPU_PLL_LOCK   	= 0x29f,
+	XLP2XX_SYS_SYS_PLL_LOCK 	= 0x2a0,
+	XLP2XX_SYS_PLL_MEM_CMD    	= 0x2a1,
+	XLP2XX_SYS_CPU_PLL_MEM_REQ	= 0x2a2,
+	XLP2XX_SYS_SYS_PLL_MEM_REQ	= 0x2a3,
+	XLP2XX_SYS_PLL_MEM_STAT		= 0x2a4,
+
+	XLP2XX_RTC_REG_SECONDS          = 0x300,
+	XLP2XX_RTC_REG_MINUTES          = 0x301,
+	XLP2XX_RTC_REG_CENTURY_HOURS    = 0x302,
+	XLP2XX_RTC_REG_DAY              = 0x303,
+	XLP2XX_RTC_REG_DATE             = 0x304,
+	XLP2XX_RTC_REG_MONTH            = 0x305,
+	XLP2XX_RTC_REG_YEAR             = 0x306,
+	XLP2XX_RTC_REG_CONTROL          = 0x307,
+	XLP2XX_RTC_REG_STATUS           = 0x308,
+	XLP2XX_RTC_REG_FLAG             = 0x309,
+	XLP2XX_RTC_REG_CLOCK_PERIOD     = 0x30a,
+	XLP2XX_RTC_REG_LOCK             = 0x30b,
+	XLP2XX_RTC_REG_VOLT             = 0x30c,
+	XLP2XX_RTC_REG_TEST             = 0x30f,
+};
+
+#define XLP2XX_RSA_BLOCK_INDEX		0
+#define XLP2XX_REGX_BLOCK_INDEX		11
+#define XLP2XX_CMP_BLOCK_INDEX		9
+#define XLP2XX_CRYPTO_BLOCK_INDEX	14
+
+/*1588-PTP CLOCK selection*/
+#define NET_SYS_CLK 		0
+#define INT_SYNCE_CLK		1
+#define GPIO_1588_CLK		2
+#define SGMII_REF_CLK		3
+
+#define nlm_hal_read_sys_reg(node, index) \
+        nlm_hal_read_32bit_reg((xlp_sys_base[node] + 0x100), (index))
+
+#define nlm_hal_write_sys_reg(node, index, val) \
+        nlm_hal_write_32bit_reg((xlp_sys_base[node] + 0x100), (index), (val))
+
+#define nlm_hal_read_rsa_reg(reg) \
+        nlm_hal_read_32bit_reg((xlp_rsa_base), (reg))
+
+#define nlm_hal_write_rsa_reg(reg, val) \
+        nlm_hal_write_32bit_reg ((xlp_rsa_base), (reg), (val))
+
+#define nlm_hal_read_sae_reg(node, reg) \
+        nlm_hal_read_32bit_reg((xlp_sae_base[node]), (reg))
+
+#define nlm_hal_write_sae_reg(node, reg, val) \
+        nlm_hal_write_32bit_reg ((xlp_sae_base[node]), (reg), (val))
+
+#if 0
+#define nlm_hal_read_rsa_reg(node, reg) \
+        nlm_hal_read_32bit_reg((xlp_rsa_base[node]), (reg))
+
+#define nlm_hal_write_rsa_reg(node, reg, val) \
+        nlm_hal_write_32bit_reg ((xlp_rsa_base[node]), (reg), (val))
+
+#endif
+enum {
+	PHYMODE_NONE = 0,
+	PHYMODE_HS_SGMII = 1,
+	PHYMODE_XAUI = 1,
+	PHYMODE_SGMII = 2,
+	PHYMODE_IL = 3,
+	PHYMODE_RXAUI = 6,
+};
+
+enum {
+	LM_UNCONNECTED = 0,
+	LM_SGMII = 1,
+	LM_XAUI = 2,
+	LM_IL = 3,
+};
+
+#define MAX_GMAC_PORT			18
+#define MAX_CPLX_BLOCK                  5
+#define MAX_LANE_PER_CPLX               4
+
+/*PRM: VSEMI  CONFIG REGISTERS*/
+#define VSEMI_CMD 			0x9
+#define VSEMI_CTL0			0xA
+	#define VSEMI_CTL_POR			(1<<9)
+	#define VSEMI_CTL_SYNTH_RST		(1<<10)
+	#define VSEMI_CTL_RTHR			(0xf<<12)
+#define VSEMI_CTL1			0xB
+
+	#define VSEMI_CTL_MASK_DR	(0x7)
+	#define VSEMI_CTL_RXAUI_10G_DR	(0x3)
+	#define VSEMI_CTL_XAUI_16G_DR	(0x3)
+	#define VSEMI_CTL_XAUI_12G_DR	(0x3)
+	#define VSEMI_CTL_XAUI_DR	(0x2)
+	#define VSEMI_CTL_SGMII_DR	(0x1)
+
+	#define VSEMI_CTL_MASK_DW	(0x70)
+	#define VSEMI_CTL_RXAUI_10G_DW	(0x30)
+	#define VSEMI_CTL_XAUI_16G_DW	(0x10)
+	#define VSEMI_CTL_XAUI_12G_DW	(0x10)
+	#define VSEMI_CTL_XAUI_DW	(0x10)
+	#define VSEMI_CTL_SGMII_DW	(0x10)
+	
+#define VSEMI_STATUS			0xC
+#define VSEMI_PINCTRL			0xD
+#define VSEMI_PIN_STS			0XE
+
+
+
+/*
+ * PRM: 11.10.2 PHY and PMA Controller Registers
+ */
+#define PHY_LANE_0_STATUS               0
+#define PHY_LANE_1_STATUS               1
+#define PHY_LANE_2_STATUS               2
+#define PHY_LANE_3_STATUS               3
+    #define PHY_LANE_STAT_SRCS          0x00000001 /* bit 1: Rx clock stable if 1 */
+    #define PHY_LANE_STAT_STD           0x00000010 /* bit 4: Transmit Detect if 1 */
+    #define PHY_LANE_STAT_SFEA          0x00000020 /* bit 5: Far end absent if 1 */
+    #define PHY_LANE_STAT_STCS          0x00000040 /* bit 6: Tx clock stable if 1 */
+    #define PHY_LANE_STAT_SPC           0x00000200 /* bit  9: SGMII PCS Sync bit; 1:synced 0:fault*/
+    #define PHY_LANE_STAT_XLF           0x00000400 /* bit 10: XAUI lane sync bit; 0:synced 1:fault*/
+    #define PHY_LANE_STAT_PCR           0x00000800 /* bit 11: PMA Controller Ready; 1:ready */
+    #define LANE_RX_CLK                     (1 << 0)
+    #define LANE_TX_CLK                     (1 << 6)
+#define PHY_LANE_0_CTRL                 4
+#define PHY_LANE_1_CTRL                 5
+#define PHY_LANE_2_CTRL                 6
+#define PHY_LANE_3_CTRL                 7
+    #define PHY_LANE_CTRL_DATA_POS      0
+    #define PHY_LANE_CTRL_ADDR_POS      8
+    #define PHY_LANE_CTRL_CMD_READ      0x00010000
+    #define PHY_LANE_CTRL_CMD_WRITE     0x00000000
+    #define PHY_LANE_CTRL_CMD_START     0x00020000
+    #define PHY_LANE_CTRL_CMD_PENDING   0x00040000
+    #define PHY_LANE_CTRL_RESET_PMA	0x00100000
+    #define PHY_LANE_CTRL_ALL           0x00200000
+    #define PHY_LANE_CTRL_FAST_INIT     0x00400000
+    #define PHY_LANE_CTRL_REXSEL_POS    23
+    #define PHY_LANE_CTRL_PHYMODE_POS   25
+    #define PHY_LANE_CTRL_PWRDOWN       0x20000000
+    #define PHY_LANE_CTRL_RST           0x40000000
+    #define PHY_LANE_CTRL_RST_XAUI      0xc0000000
+    #define PHY_LANE_CTRL_BPC_XAUI      0x80000000
+#define LANE_CFG_CPLX_0_1               0x0
+#define LANE_CFG_CPLX_2_3               0x1
+#define LANE_CFG_CPLX_4                 0x2
+    #define LANE_CFG_LANE_0_POS         0
+    #define LANE_CFG_LANE_1_POS         4
+    #define LANE_CFG_LANE_2_POS         8
+    #define LANE_CFG_LANE_3_POS         12
+
+    #define LANE_CFG_DISCONNECT         0
+    #define LANE_CFG_GMAC               1
+    #define LANE_CFG_XGMAC              2
+    #define LANE_CFG_8ILAKEN            3
+#define NET_INTF_SOFT_RST               0x3
+
+#define INT_MDIO_CTRL                   0x19
+    #define INT_MDIO_CTRL_ST		0
+    #define INT_MDIO_CTRL_ST_POS        0
+    #define INT_MDIO_CTRL_OP_POS        2
+    #define INT_MDIO_CTRL_PHYADDR_POS   4
+    #define INT_MDIO_CTRL_DEVTYPE_POS   9
+    #define INT_MDIO_CTRL_TA_POS        14
+    #define INT_MDIO_CTRL_TA    	0x02
+    #define INT_MDIO_CTRL_MIIM_POS      16
+    #define INT_MDIO_CTRL_LOAD_POS      19
+    #define INT_MDIO_CTRL_XDIV_POS      21
+    #define INT_MDIO_CTRL_MCDIV_POS     28
+    #define INT_MDIO_CTRL_RST           0x40000000
+    #define INT_MDIO_CTRL_SMP           0x00100000
+    #define INT_MDIO_CTRL_CMD_LOAD      0x00080000
+
+    #define INT_MDIO_CTRL_XDIV		7
+    #define INT_MDIO_CTRL_MCDIV		1
+
+#define INT_MDIO_CTRL_DATA              0x1A
+#define INT_MDIO_RD_STAT                0x1B
+    #define INT_MDIO_RD_STAT_MASK       0x0000FFFF
+    #define INT_MDIO_STAT_LFV           0x00010000
+    #define INT_MDIO_STAT_SC            0x00020000
+    #define INT_MDIO_STAT_SM            0x00040000
+    #define INT_MDIO_STAT_MIILFS        0x00080000
+    #define INT_MDIO_STAT_MBSY          0x00100000
+#define INT_MDIO_LINK_STAT              0x1C
+
+#define EXT_XG0_MDIO_CTRL               0x25
+#define EXT_XG1_MDIO_CTRL               0x29
+    #define EXT_XG_MDIO_CTRL_ST		0
+    #define EXT_XG_MDIO_CTRL_OP_POS     2
+#define MDIO_CTRL_OP_INDIRECT_ADDR      0x00
+#define MDIO_CTRL_OP_WRITE_10G_MMD      0x01
+#define MDIO_CTRL_OP_READ_10G_MMD       0x02
+#define MDIO_CTRL_OP_POST_RDINC_ADDR    0x03
+
+    #define EXT_XG_MDIO_CTRL_PHYADDR_POS	4
+    #define EXT_XG_MDIO_CTRL_REG_POS		9
+    #define EXT_XG_MDIO_CTRL_TA    	0x02
+    #define EXT_XG_MDIO_CTRL_TA_POS     14
+    #define EXT_XG_MDIO_CTRL_MIIM_POS   16
+    #define EXT_XG_MDIO_CTRL_LOAD_POS   19
+    #define EXT_XG_MDIO_CTRL_XDIV_POS   21
+    #define EXT_XG_MDIO_CTRL_MCDIV_POS  28
+    #define EXT_XG_MDIO_CTRL_RST        0x40000000
+    #define EXT_XG_MDIO_CTRL_SMP        0x00100000
+    #define EXT_XG_MDIO_CTRL_CMD_LOAD   0x00080000
+    #define MDIO_MIIM_CMD_IDLE		0x000
+    #define MDIO_MIIM_CMD_WRITE		0x001
+    #define MDIO_MIIM_CMD_READ		0x002
+    #define MDIO_MIIM_CMD_SM		0x003
+    #define MDIO_MIIM_CMD_MM		0x004
+    #define MDIO_MIIM_CMD_10G_MMD	0x005
+    #define MDIO_MIIM_CMD_CLEAR_LINK	0x006
+
+#define EXT_G0_MDIO_CTRL                0x1D
+#define EXT_G1_MDIO_CTRL                0x21
+    #define EXT_G_MDIO_CLOCK_DIV_4      0
+    #define EXT_G_MDIO_CLOCK_DIV_2      1
+    #define EXT_G_MDIO_CLOCK_DIV_1      2
+    #define EXT_G_MDIO_REGADDR_POS      5
+    #define EXT_G_MDIO_PHYADDR_POS      10
+    #define EXT_G_MDIO_CMD_SP           0x00008000
+    #define EXT_G_MDIO_CMD_PSIA 		0x00010000
+    #define EXT_G_MDIO_CMD_LCD          0x00020000
+    #define EXT_G_MDIO_CMD_RDS          0x00040000
+    #define EXT_G_MDIO_CMD_SC           0x00080000
+    #define EXT_G_MDIO_MMRST            0x00100000
+    #define EXT_G_MDIO_DIV              0x0000001E
+    #define EXT_G_MDIO_DIV_WITH_HW_DIV64 0x00000010
+    #define EXT_G_MDIO_DIV_WITH_HW_DIV64_11 0x00000011
+
+#define EXT_G0_MDIO_CTRL_DATA           0x1E
+#define EXT_G1_MDIO_CTRL_DATA           0x22
+
+#define EXT_G0_MDIO_LINK_STAT           0x20
+#define EXT_G1_MDIO_LINK_STAT           0x24
+
+#define EXT_G0_MDIO_RD_STAT             0x1F
+#define EXT_G1_MDIO_RD_STAT             0x23
+    #define EXT_G_MDIO_RD_STAT_MASK     0x0000FFFF
+    #define EXT_G_MDIO_STAT_LFV         0x00010000
+    #define EXT_G_MDIO_STAT_SC          0x00020000
+    #define EXT_G_MDIO_STAT_SM          0x00040000
+    #define EXT_G_MDIO_STAT_MIILFS      0x00080000
+    #define EXT_G_MDIO_STAT_MBSY        0x80000000
+    #define MDIO_OP_CMD_READ            0x10
+    #define MDIO_OP_CMD_WRITE           0x01
+
+#define EXT_XG0_MDIO_CTRL               0x25
+#define EXT_XG1_MDIO_CTRL               0x29
+    #define EXT_XG_MDIO_CTRL_ST_POS     0
+    #define EXT_XG_MDIO_CTRL_OP_POS     2
+    #define EXT_XG_MDIO_CTRL_PHYADDR_POS        4
+    #define EXT_XG_MDIO_CTRL_DEVTYPE_POS        9
+    #define EXT_XG_MDIO_CTRL_TA_POS     14
+    #define EXT_XG_MDIO_CTRL_MIIM_POS   16
+    #define EXT_XG_MDIO_CTRL_LOAD_POS   19
+    #define EXT_XG_MDIO_CTRL_XDIV_POS   21
+    #define EXT_XG_MDIO_CTRL_MCDIV_POS  28
+    #define EXT_XG_MDIO_CTRL_RST        0x40000000
+    #define EXT_XG_MDIO_CTRL_SMP        0x00100000
+    #define EXT_XG_MDIO_CTRL_CMD_LOAD   0x00080000
+
+#define EXT_XG0_MDIO_CTRL_DATA          0x26
+#define EXT_XG1_MDIO_CTRL_DATA          0x2A
+
+#define EXT_XG0_MDIO_LINK_STAT          0x28
+#define EXT_XG1_MDIO_LINK_STAT          0x2C
+
+#define EXT_XG0_MDIO_RD_STAT            0x27
+#define EXT_XG1_MDIO_RD_STAT            0x2B
+    #define EXT_XG_MDIO_RD_STAT_MASK    0x0000FFFF
+    #define EXT_XG_MDIO_STAT_LFV        0x00010000
+    #define EXT_XG_MDIO_STAT_SC         0x00020000
+    #define EXT_XG_MDIO_STAT_SM         0x00040000
+    #define EXT_XG_MDIO_STAT_MIILFS     0x00080000
+    #define EXT_XG_MDIO_STAT_MBSY       0x00100000
+
+#define GMAC_FC_SLOT0                   0x2D
+#define GMAC_FC_SLOT1                   0x2E
+#define GMAC_FC_SLOT2                   0x2F
+#define GMAC_FC_SLOT3                   0x30
+
+#define XAUI_CONFIG_0                   0
+    #define XAUI_CONFIG_MACRST          0x80000000
+    #define XAUI_CONFIG_RSTRCTL         0x00400000
+    #define XAUI_CONFIG_RSTRFN          0x00200000
+    #define XAUI_CONFIG_RSTTCTL         0x00040000
+    #define XAUI_CONFIG_RSTTFN          0x00020000
+    #define XAUI_CONFIG_RSTMIIM         0x00010000
+
+#define XAUI_CONFIG_1                   1
+    #define XAUI_CONFIG_TCTLEN          0x80000000
+    #define XAUI_CONFIG_TFEN            0x40000000
+    #define XAUI_CONFIG_RCTLEN          0x20000000
+    #define XAUI_CONFIG_RFEN            0x10000000
+    #define XAUI_CONFIG_DRPLT64         0x00000020
+    #define XAUI_CONFIG_LENCHK          0x00000008
+    #define XAUI_CONFIG_GENFCS          0x00000004
+    #define XAUI_CONFIG_PAD_0           0x00000000
+    #define XAUI_CONFIG_PAD_64          0x00000001
+    #define XAUI_CONFIG_PAD_COND        0x00000002
+    #define XAUI_CONFIG_PAD_68          0x00000003
+
+#define XAUI_CONFIG_2                   2
+
+#define XAUI_CONFIG_3                   3
+
+#define XAUI_MAX_FRAME_LEN              8
+#define XAUI_PHY_CTRL_1                 0x00
+    #define XAUI_PHY_RST                0x8000
+    #define XAUI_PHY_LOOPBACK           0x4000
+    #define XAUI_PHY_SPSEL1             0x2000
+    #define XAUI_PHY_LOW_POWER          0x0800
+    #define XAUI_PHY_SPSEL0             0x0040
+    #define XAUI_PHY_10G                0x0000
+
+#define XAUI_PHY_STAT_1                 0x01
+    #define XAUI_PHY_FAULT_DP           0x0008
+    #define XAUI_PHY_LINK_UP            0x0004
+    #define XAUI_PHY_LOWPOWER           0x0002
+
+#define XAUI_PHY_SPEED_CAP              0x04
+    #define XAUI_PHY_10G_CAP            0x0001
+
+#define XAUI_PHY_DEV_PRESENT            0x05
+    #define XAUI_PHY_DTE_XS_DP          0x0020
+    #define XAUI_PHY_XS_DP              0x0010
+    #define XAUI_PHY_PCS_DP             0x0008
+    #define XAUI_PHY_WIS_DP             0x0004
+    #define XAUI_PHY_PMD_PMA_DP         0x0002
+    #define XAUI_PHY_CL22_DP            0x0001
+
+#define XAUI_PHY_STAT_2                 0x08
+    #define XAUI_PHY_STAT2_DP           0x2000
+    #define XAUI_PHY_TXF                0x0800
+    #define XAUI_PHY_RXF                0x0400
+#define XAUI_LANE_STAT                  0x18
+    #define XAUI_LANE_ALIGNED           0x1000
+    #define XAUI_LANE_PTE_EN            0x0800
+    #define XAUI_LANE_LOOPBACK_EN       0x0400
+    #define XAUI_LANE_PTE_EN            0x0800
+    #define XAUI_LANE_PTE_EN            0x0800
+    #define XAUI_LANE_PTE_EN            0x0800
+    #define XAUI_LANE_L3S               0x0008
+    #define XAUI_LANE_L2S               0x0004
+    #define XAUI_LANE_L1S               0x0002
+    #define XAUI_LANE_L0S               0x0001
+
+#define XAUI_PHY_TEST_CTRL              0x19
+    #define XAUI_PHY_TEST_PATTERN_EN    0x04
+    #define XAUI_PHY_TEST_HI_FREQ       0x00
+    #define XAUI_PHY_TEST_LOW_FREQ      0x01
+    #define XAUI_PHY_TEST_MIXED_FREQ    0x02
+
+#define NAE_THR_SEPARATION		   8
+#define NAE_MTU_LEN			1518
+#define NAE_REACTION_LEN_XAUI		1463
+#define NAE_REACTION_LEN_SGMII		1126
+#define NAE_REACTION_LEN_PARSER		  14
+#define NAE_INFLIGHT_LEN_XAUI		 504
+#define NAE_INFLIGHT_LEN_SGMII		 108
+#define NAE_SMALLEST_PKT_LEN		  64
+#define NAE_XAUI_THR_GROUP		   1
+#define NAE_SGMII_THR_GROUP		   2
+#define NAE_RXAUI_THR_GROUP		   3
+#define NAE_ILK_THR_GROUP		   4
+#define NAE_RX_THR_BYTE_UNIT	          16
+#define NAE_PAUSE_TIMER_DELTA		  32
+
+#define NETIOR_HIGIG2_CTRL0		0x70
+#define NETIOR_HIGIG2_CTRL1		0x71
+#define NETIOR_HIGIG2_CTRL2		0x72
+#define NETIOR_HIGIG2_PAUSE_CTRL1	0x73
+#define NETIOR_HIGIG2_MACSA		0x74
+#define NETIOR_HIGIG2_STATUS		0x75
+#define NETIOR_HIGIG2_MISC		0x76
+
+
+#define NETIOR_XGMAC_CTRL1              0x7F
+    #define NETIOR_XGMAC_RXAUI_DC_POS        30 /* Rxaui Disparity calculation */
+    #define NETIOR_XGMAC_RXAUI_EN_POS        29 /* Enable RXAUI Mode */
+
+    #define NETIOR_XGMAC_VLAN_DC_POS    28
+    #define NETIOR_XGMAC_PHYADDR_POS    23
+    #define NETIOR_XGMAC_DEVID_POS      18
+    #define NETIOR_XGMAC_STATS_EN_POS   17
+    #define NETIOR_XGMAC_STATS_CLR_POS	16
+    #define NETIOR_XGMAC_TX_PFC_EN_POS  14
+    #define NETIOR_XGMAC_RX_PFC_EN_POS  13
+    #define NETIOR_XGMAC_SOFT_RST_POS   11
+    #define NETIOR_XGMAC_TX_PAUSE_POS   10
+
+    #define NETIOR_XGMAC_RXAUI_SCRAMBLER_POS 4
+
+#define NETIOR_XGMAC_CTRL2		0x7E
+#define NETIOR_XGMAC_CTRL3		0x7D
+
+#define MAC_ADDR0_LO			0x50
+#define MAC_ADDR0_HI			0x51
+#define MAC_FILTER_CONFIG		0x5c
+	#define MAC_FILTER_BCAST_EN_POS 	10
+	#define MAC_FILTER_MCAST_EN_POS		8
+	#define MAC_FILTER_ADDR0_VALID_POS 	0
+#define MAC_ADDR0_MASK_LO		0x58
+#define MAC_ADDR0_MASK_HI		0x59
+
+/* Interlaken Registers */
+
+#define ILK_TX_CONTROL			0x00
+    #define ILK_TX_CTRL_RST_INF		0x80000000
+    #define ILK_TX_CTRL_RST_CORE	0x40000000
+    #define ILK_TX_CTRL_TXO		0x20000000
+    #define ILK_TX_CTRL_TXU		0x10000000
+    #define ILK_TX_CTRL_TXBE		0x08000000
+    #define ILK_TX_CTRL_DSW		0x00000200
+    #define ILK_TX_CTRL_BAD_LANE	0x00000100
+    #define ILK_TX_CTRL_RATELIM_EN	0x00000002
+    #define ILK_TX_CTRL_TX_EN		0x00000001
+
+    #define ILK_TX_CTRL_FIFO_THR_POS	19
+    #define ILK_TX_CTRL_CAL_LEN_POS	15
+    #define ILK_TX_CTRL_BS_POS		12
+    #define ILK_TX_CTRL_BMAX_POS	10
+    #define ILK_TX_CTRL_BLS_POS		5
+    #define ILK_TX_CTRL_LLS_POS		2
+
+#define ILK_TX_RATE_LIMIT		0x01
+    #define ILK_TX_RATE_LIM_UI_POS	24
+    #define ILK_TX_RATE_LIM_DELTA_POS	12
+    #define ILK_TX_RATE_LIM_MTC_POS	0
+
+#define ILK_TX_META_CTRL		0x02
+    #define ILK_TX_META_CTRL_TXLEN_POS	16
+    #define ILK_TX_META_CTRL_RXLEN_POS	0
+
+#define ILK_RX_CONTROL			0x03
+    #define ILK_RX_CTRL_RST_CORE	0x00800000
+    #define ILK_RX_CTRL_BAD_LANE	0x00000004
+    #define ILK_RX_CTRL_FORCE_RESYNC	0x00000002
+    #define ILK_RX_CTRL_PKT_MODE	0x00000001
+
+    #define ILK_RX_CTRL_RST_LANE_POS	24
+    #define ILK_RX_CTRL_BMAX_POS	9
+    #define ILK_RX_CTRL_LLS_POS		6
+    #define ILK_RX_CTRL_BLS_POS		3
+
+#define ILK_RX_STATUS1			0x04
+    /* All fields are RWC */
+    #define ILK_RX_STAT1_MFS_POS	24
+    #define ILK_RX_STAT1_MFSE_POS	16
+    #define ILK_RX_STAT1_MFLE_POS	8
+    #define ILK_RX_STAT1_MFRE_POS	0
+
+#define ILK_RX_STATUS2			0x05
+    /* All fields are RWC */
+    #define ILK_RX_STAT2_RDCV_POS	24
+    #define ILK_RX_STAT2_RDCE_POS	16
+    #define ILK_RX_STAT2_RDIS_POS	8
+    #define ILK_RX_STAT2_RDLS_POS	0
+
+#define ILK_GENERAL_CTRL1		0x06
+    #define ILK_GEN_CTRL1_RXBTE_POS	16
+    #define ILK_GEN_CTRL1_RXMBITS_POS	12	/* PRM bug */
+    #define ILK_GEN_CTRL1_RXFC_POS	8	/* Bits 8..11 RXFC (This is not included in PRM) */
+    #define ILK_GEN_CTRL1_TXMBITS_POS	0
+
+#define ILK_RX_STATUS3			0x07
+    #define ILK_RX_STAT3_CC_MAP		0x00080000
+    #define ILK_RX_STAT3_TIME_STAMP	0x00040000  /*RWC */
+    #define ILK_RX_STAT3_RXL_ALIGN	0x00020000
+    /* Bits 16-0 RWC */
+    #define ILK_RX_STAT3_WCRC_ERR	0x00010000
+    #define ILK_RX_STAT3_CWCRC_ERR	0x00008000
+    #define ILK_RX_STAT3_SS_ERR		0x00004000
+    #define ILK_RX_STAT3_MFLEN_ERR	0x00002000
+    #define ILK_RX_STAT3_MFRPT_ERR	0x00001000
+    #define ILK_RX_STAT3_WRDSYNC_ERR	0x00000800
+    #define ILK_RX_STAT3_MF_ERR		0x00000400
+    #define ILK_RX_STAT3_FRM_ERR	0x00000200
+    #define ILK_RX_STAT3_BADTYPE_ERR	0x00000100
+    #define ILK_RX_STAT3_SOP_ERR	0x00000080
+    #define ILK_RX_STAT3_EOP_ERR	0x00000040
+    #define ILK_RX_STAT3_LA_ERR		0x00000020
+    #define ILK_RX_STAT3_LM_ERR		0x00000010
+    #define ILK_RX_STAT3_BMAX_ERR	0x00000008
+    #define ILK_RX_STAT3_BURST_ERR	0x00000004
+    #define ILK_RX_STAT3_FIFO_OVF_ERR	0x00000002
+    #define ILK_RX_STAT3_OTHER_ERR	0x00000001
+
+#define ILK_RX_FC_TMAP0			0x08
+#define ILK_RX_FC_TMAP1			0x09
+#define ILK_RX_FC_TMAP2			0x0A
+#define ILK_RX_FC_TMAP3			0x0B
+#define ILK_RX_FC_TMAP4			0x0C
+
+#define ILK_RX_FC_TADDR			0x0D
+    #define ILK_RX_FC_RXMTUDROP_EN	0x40000000
+    #define ILK_RX_FC_REQ_VALID		0x00000020
+    #define ILK_RX_FC_WRITE_REQ		0x00000010
+
+    #define ILK_RX_FC_RXMTU_SIZE_POS	17  /* size in 16byte words */
+    #define ILK_RX_FC_TABLE_IDX_POS	0
+
+#define ILK_GENERAL_CTRL2		0x0E
+    #define ILK_GEN_CTRL2_STATS_COR	0x40000000
+
+    #define ILK_GEN_CTRL2_SCS5_POS	25
+    #define ILK_GEN_CTRL2_SCS4_POS	20
+    #define ILK_GEN_CTRL2_SCS3_POS	15
+    #define ILK_GEN_CTRL2_SCS2_POS	10
+    #define ILK_GEN_CTRL2_SCS1_POS	5
+    #define ILK_GEN_CTRL2_SCS0_POS	0
+
+#define ILK_GENERAL_CTRL3		0x0F
+    #define ILK_GEN_CTRL3_LCS1_POS	17
+    #define ILK_GEN_CTRL3_LCS0_POS	14
+    #define ILK_GEN_CTRL3_MCS1_POS	12
+    #define ILK_GEN_CTRL3_MCS0_POS      10
+    #define ILK_GEN_CTRL3_SCS7_POS	5
+    #define ILK_GEN_CTRL3_SCS6_POS	0
+
+#define ILK_SMALL_COUNT0		0x10
+#define ILK_SMALL_COUNT1                0x11
+#define ILK_SMALL_COUNT2                0x12
+#define ILK_SMALL_COUNT3                0x13
+#define ILK_SMALL_COUNT4                0x14
+#define ILK_SMALL_COUNT5                0x15
+#define ILK_SMALL_COUNT6                0x16
+#define ILK_SMALL_COUNT7                0x17
+#define ILK_MID_COUNT0			0x18
+#define ILK_MID_COUNT1			0x19
+#define ILK_LARGE_COUNT_L0		0x1A
+#define ILK_LARGE_COUNT_L1              0x1B
+#define ILK_LARGE_COUNT_H0		0x1C
+#define ILK_LARGE_COUNT_H1              0x1D
+
+/* Serdes Register */
+#define SER_GEN1_PWR_DOWN		0x0E
+    #define SERDES_PMFF_ALL_SET		0x04
+
+#define SERDES_PRBS_CTRL		0x64
+    #define SERDES_LOOPBACK_EN		0x02
+
+#define ILK_BURST_MAX           	3 /* 256 bytes */
+
+#define XLP_ILK_LANE_RATE_LOW           0       /* 0, 19, 0 */
+#define XLP_ILK_LANE_RATE_HIDH          1       /* 1, 19, 0 */
+
+#define XLP_ILK_PORT_0                  0
+#define XLP_ILK_PORT_1                  8
+
+#define XLP_ILK_PORT0_CS                3
+#define XLP_ILK_PORT1_CS                4
+
+#define XLP_ILK_MAX_LANES               8
+
+/* SPI */
+#define XLP_SPI_CONFIG			0x40
+    #define XLP_SPI_CPHA		0x01
+    #define XLP_SPI_CPOL		0x02
+    #define XLP_SPI_MODE_MASK		0x03
+    #define XLP_SPI_CS_POL_HI		0x04
+    #define XLP_SPI_TXMISO_EN		0x08
+    #define XLP_SPI_TXMOSI_EN		0x10
+    #define XLP_SPI_RXMISO_EN		0x20
+    #define XLP_SPI_SB_EN		0x40
+    #define XLP_SPI_SBPOL		0x80
+    #define XLP_SPI_LSBF_EN		0x0400
+    #define XLP_SPI_RXCAP_EV		0x0800
+#define XLP_SPI_FDIV			0x41
+#define XLP_SPI_CMD			0x42
+    #define XLP_SPI_CMD_MASK		0xF
+    #define XLP_SPI_CMD_IDLE            0x0000
+    #define XLP_SPI_CMD_TX              0x0001
+    #define XLP_SPI_CMD_RX              0x0002
+    #define XLP_SPI_CMD_TXRX            0x0003
+    #define XLP_SPI_CMD_CONT		0x10
+    #define XLP_SPI_XFR_BITCNT_POS	16
+
+#define XLP_SPI_STATUS			0x43
+    #define XLP_SPI_XFR_PENDING		0x01
+    #define XLP_SPI_XFR_DONE		0x02
+    #define XLP_SPI_TX_OV_TH		0x04
+    #define XLP_SPI_RX_OV_TH		0x08
+    #define XLP_SPI_TX_UF		0x10
+    #define XLP_SPI_TX_OF		0x20
+#define XLP_SPI_INTEN			0x44
+    #define XLP_SPI_INT_XFR_DONE	0x01
+    #define XLP_SPI_INT_TX_THRESH	0x02
+    #define XLP_SPI_INT_RX_THRESH	0x04
+    #define XLP_SPI_INT_TX_UF		0x08
+    #define XLP_SPI_INT_RX_OF		0x10
+
+#define XLP_SPI_FIFO_THRESH		0x45
+    #define XLP_SPI_TXFIFO_THRESH_POS	4
+    #define XLP_SPI_RXFIFO_THRESH_POS	0
+
+#define XLP_SPI_FIFO_WCNT		0x46
+    #define XLP_SPI_TXFIFO_WCNT_POS	4
+    #define XLP_SPI_RXFIFO_WCNT_POS	0
+#define XLP_SPI_TXDATA_FIFO		0x47
+#define XLP_SPI_RXDATA_FIFO		0x48
+
+#define XLP_SPI_SYSCTRL			0x80
+    #define XLP_SPI_SYS_RESET		0x01
+    #define XLP_SPI_SYS_CLKDIS		0x0010
+    #define XLP_SPI_SYS_PMEN		0x0100
+
+/* I2C */
+#define XLP_PRESCALE0                   0x0 
+#define XLP_PRESCALE1                   0x1 
+#define XLP_I2C_CONTROL                 0x2 
+        #define XLP_I2C_CTRL_EN         0x80
+        #define XLP_I2C_CTRL_IEN        0x40
+#define XLP_I2C_DATA                    0x3              
+#define XLP_I2C_COMMAND                 0x4 
+        #define XLP_I2C_CMD_START       0x90
+        #define XLP_I2C_CMD_STOP        0x40
+        #define XLP_I2C_CMD_READ        0x20
+        #define XLP_I2C_CMD_WRITE       0x10
+        #define XLP_I2C_CMD_RDACK       0x20
+        #define XLP_I2C_CMD_RDNACK      0x28
+        #define XLP_I2C_CMD_IACK        0x01 
+#define XLP_I2C_STATUS                  0x4       
+        #define XLP_I2C_STATUS_NACK     0x80     
+        #define XLP_I2C_STATUS_BUSY     0x40
+        #define XLP_I2C_STATUS_AL       0x20    
+        #define XLP_I2C_STATUS_TIP      0x02   
+        #define XLP_I2C_STATUS_IF       0x01 
+#define XLP_WRITE_BIT                   0x00
+#define XLP_READ_BIT                    0x01
+
+#define XLP_USB_PCIE_MBAR		0x4
+#define XLP_USB_PCIE_MBAR1		0x5
+
+#define XLP_USB_PCI0			0x40
+#define XLP_USB_CTL0            	0x41
+    #define USBCONTROLLERRESET  	0x01
+    #define USBEHCI64BITEN		0x02
+    #define USBOHCISTARTCLK		0x04
+
+#define XLP_USB_CTL1            	0x42
+#define XLP_USB_CTL2            	0x43
+#define XLP_USB_CTL3            	0x44
+#define XLP_USB_CTL4            	0x45
+#define XLP_USB_CTL5            	0x46
+#define XLP_USB_CTL6            	0x47
+#define XLP_USB_CTL7            	0x48
+
+#define XLP_USB_BYTESWAP    		0x49
+
+#define XLP_USB_PHY0            	0x4A
+#define XLP_USB_PHY1            	0x4B
+#define XLP_USB_PHY2            	0x4C
+    #define USBPHYRESET         	0x01
+    #define USBVBUSDETECT		0x02
+    #define USBREFCLK_12MHZ		0x00
+    #define USBREFCLK_24MHZ     	0x04
+    #define USBREFCLK_48MHZ     	0x08
+    #define USBPHYPORTRESET0    	0x10
+    #define USBPHYPORTRESET1    	0x20
+
+#define XLP_USB_STATUS0         	0x4D
+#define XLP_USB_INT_STATUS0     	0x4E
+#define XLP_USB_INT_EN          	0x4F
+    #define USB_PHY_INTERRUPT_EN    	0x01
+    #define USB_OHCI_INTERRUPT_EN   	0x02
+    #define USB_OHCI_INTERRUPT1_EN  	0x04
+    #define USB_OHCI_INTERRUPT12_EN 	0x08
+    #define USB_CTRL_INTERRUPT_EN   	0x10
+
+
+#define XLP_USB3_CTL			0x100
+#define XLP_USB3_INT			0x102
+#define XLP_USB3_INT_MASK		0x103
+#define XLP2XX_USB_PHY_TEST		0x106
+#define XLP2XX_USB_PHY_LOS_LEV		0x109
+#define XLP2XX_USB_PHY_PLL_MULT		0x10a
+#define XLP2XX_USB_REF_CLK		0x10c
+
+
+#ifndef NLM_HAL_LINUX_KERNEL		/* This is not applicable in Linux */
+#define XLP_NOR_IRQ			20
+#define XLP_NAND_IRQ			21
+#define XLP_SPI_IRQ			22
+#define XLP_MMC_IRQ	                23
+#define XLP_USB_EHCI_IRQ                24
+#define XLP_USB_OHCI_IRQ                25
+#define XLP_USB_IRT0			115
+#define XLP_NOR_IRT			150
+#define XLP_NAND_IRT			151
+#define XLP_SPI_IRT			152
+#define XLP_MMC_IRT			153
+#endif
+
+#define XLP_PCIE_SPI_NOR_FLASH_DEV	7
+#define XLP_PCIE_SPI_NOR		0
+#define XLP_PCIE_SPI_NAND		1
+#define XLP_PCIE_SPI_CTRL		2
+#define XLP_PCIE_SPI_SD			3
+
+#define XLP_PCIE_GIO_DEV		6
+#define XLP_PCIE_USB_DEV		2
+#define XLP_PCIE_USB3_DEV		4
+#define XLP_PCIE_USB_FUNC_0		0
+#define XLP_PCIE_USB_FUNC_1		1
+#define XLP_PCIE_USB_FUNC_2		2
+#define XLP_PCIE_USB_FUNC_3		3
+#define XLP_PCIE_USB_FUNC_4		4
+#define XLP_PCIE_USB_FUNC_5		5
+
+
+#define XLP_GIO_UART0_FUNC		0
+#define XLP_GIO_UART1_FUNC		1
+#define XLP_GIO_I2C0_FUNC		2
+#define XLP_GIO_I2C1_FUNC		3
+#define XLP_GIO_GPIO_FUNC		4
+
+#define XLP_GPIO_OUTPUT_EN0		0x40	/* GPIO 31:0    */
+#define XLP_GPIO_OUTPUT_EN1		0x41	/* GPIO 40:32   */
+#define XLP_GPIO_OUTPUT0		0x42	/* outpin 31:0  */
+#define XLP_GPIO_OUTPUT1		0x43	/* outpin 40:32 */
+#define XLP_GPIO_INPUT0			0x44	/* input 31:0   */
+#define XLP_GPIO_INPUT1			0x45	/* input 40:32  */
+#define XLP_GPIO_INTEN00		0x46	/* irt 146 31:0  */
+#define XLP_GPIO_INTEN01		0x47	/* irt 146 40:32  */
+#define XLP_GPIO_INTEN10		0x48	/* irt 147 31:0  */
+#define XLP_GPIO_INTEN11		0x49	/* irt 147 40:32  */
+#define XLP_GPIO_INTEN20		0x4A	/* irt 148 31:0  */
+#define XLP_GPIO_INTEN21		0x4B	/* irt 148 40:32  */
+#define XLP_GPIO_INTEN30		0x4C	/* irt 149 31:0  */
+#define XLP_GPIO_INTEN31		0x4D	/* irt 149 40:32  */
+#define XLP_GPIO_INT_POLAR0		0x5E	/* int polarity	31:0   */
+#define XLP_GPIO_INT_POLAR1		0x5F	/* int polarity	40:32  */
+#define XLP_GPIO_INT_TYPE0		0x60	/* int level type 31:0   */
+#define XLP_GPIO_INT_TYPE1		0x61	/* int level type 40:32  */
+#define XLP_GPIO_INT_STAT0		0x62	/* int status 31:0   */
+#define XLP_GPIO_INT_STAT1		0x63	/* int status 40:32  */
+#define XLP_8XX_GPIO_INT_POLAR0		0x4E	/* int polarity	31:0   */
+#define XLP_8XX_GPIO_INT_POLAR1		0x4F	/* int polarity	40:32  */
+#define XLP_8XX_GPIO_INT_TYPE0		0x50	/* int level type 31:0   */
+#define XLP_8XX_GPIO_INT_TYPE1		0x51	/* int level type 40:32  */
+#define XLP_8XX_GPIO_INT_STAT0		0x52	/* int status 31:0   */
+#define XLP_8XX_GPIO_INT_STAT1		0x53	/* int status 40:32  */
+#define XLP_GPIO_INT0_IRT       	146
+#define XLP_GPIO_INT1_IRT       	147
+#define XLP_GPIO_INT2_IRT       	148
+#define XLP_GPIO_INT3_IRT       	149
+
+/* NOR Flash memory interface */
+
+#define NLM_NOR_BUS_NUM        0
+#define NLM_NOR_DEV_NUM        7
+#define NLM_NOR_FUN_NUM        0
+
+#define NLM_NOR_CFG_BASE        ( 0x18000000 | (NLM_NOR_DEV_NUM << 15) | (NLM_NOR_FUN_NUM << 12))
+
+#define XLP_NOR_CS_BASE         0x40
+#define XLP_NOR_CS_LIMIT        0x48
+#define XLP_NOR_DEVPARAM        0x50
+#define XLP_NOR_DEV_TIME0       0x58
+#define XLP_NOR_DEV_TIME1       0x59
+
+
+#define NAE_CLK_DIV		0x1
+#define SAE_CLK_DIV		0x2
+
+#ifdef NLM_HAL_LINUX_KERNEL
+#define DFS_OUTPUT(DR, DF, DV)  ((400/((DR+1) * 3)) * (DF+1) * 2)/(DV+1)
+#else
+#define DFS_OUTPUT(DR, DF, DV)  ((133.33/(DR+1)) * (DF+1) * 2)/(DV+1)
+#endif
+
+#endif /*__ASSEMBLY__*/
+
+/* SATA related */
+
+/* SATA CONTROLLER PORT REGISTERS */
+#define SataCLB           0x00
+#define SataCLBU          0x04
+#define SataFB            0x08
+#define SataFBU           0x0c
+#define SataIS            0x10
+#define SataIE            0x14
+#define SataCMD           0x18
+#define SataTFD           0x20
+#define SataSIG           0x24
+#define SataSSTS          0x28
+#define SataSCTL          0x2c
+#define SataSERR          0x30
+#define SataSACT          0x34
+#define SataCI            0x38
+#define SataSNTF          0x3c
+#define SataFBS           0x40
+#define SataDMACR         0x70
+#define SataPHYCR         0x78
+#define SataPHYSTS        0x7c
+
+#define ECFG_BASE               0xffffffffb8000000ULL
+#define SATA_DEV_NUM            3
+#define SATA_FUNC_NUM           2
+#define XLP_IO_SATA_BASE        (ECFG_BASE | (SATA_DEV_NUM << 15) | (SATA_FUNC_NUM << 12))
+
+/* #define XLP_MEM_SATA_BASE       0xd0042000 */
+/* #define wr_sata_mem_reg(offset, val)            sw_40bit_phys_uncached(((uint64_t)XLP_MEM_SATA_BASE) + (offset), val) */
+/* #define rd_sata_mem_reg(offset)                 lw_40bit_phys_uncached(((uint64_t)XLP_MEM_SATA_BASE) + (offset)) */
+
+#define wr_sata_glue_reg(offset, val)           write_32bit_cfg_reg((uint32_t *)(XLP_IO_SATA_BASE + 0x900), (offset >> 2), val)
+#define rd_sata_glue_reg(offset)                read_32bit_cfg_reg((uint32_t *)(XLP_IO_SATA_BASE + 0x900), (offset >> 2))
+
+#define set_sata_glue_reg(offset, bit)          wr_sata_glue_reg(offset, (rd_sata_glue_reg(offset) | bit))
+#define clear_sata_glue_reg(offset, bit)        wr_sata_glue_reg(offset, (rd_sata_glue_reg(offset) & ~bit))
+
+#define XLP_HAL_SATA_CTL                0x00    /*  */
+#define XLP_HAL_SATA_STATUS             0x04    /* SATA Status register */
+#define XLP_HAL_SATA_INT                0x08    /* SATA Interrupt Register */
+#define XLP_HAL_SATA_INT_MASK           0x0c    /* SATA Interrupt Mask Register */
+#define XLP_HAL_SATA_CR_REG_TIMER       0x10    /* PHY Conrol Timer Register */
+#define XLP_HAL_SATA_CORE_ID            0x14    /* SATA Core ID Register */
+#define XLP_HAL_SATA_AXI_SLAVE_OPT1     0x18    /* SATA AXI Slave Options Register */
+#define XLP_HAL_SATA_PHY_LOS_LEV        0x1c    /* SATA PHY LOS Level Register  */
+#define XLP_HAL_SATA_PHY_MULTI          0x20    /* SATA PHY Multiplier Register          */
+#define XLP_HAL_SATA_PHY_CLK_SEL        0x24    /* SATA PHY Clock Select Register */
+#define XLP_HAL_SATA_PHY_AMP1_GEN1      0x28    /* SATA PHY Transmit Amplitude Register 1    */
+#define XLP_HAL_SATA_PHY_AMP1_GEN2      0x2c    /* SATA PHY Transmit Amplitude Register 2    */
+#define XLP_HAL_SATA_PHY_AMP1_GEN3      0x30    /* SATA PHY Transmit Amplitude Register 3    */
+#define XLP_HAL_SATA_PHY_PRE1           0x34    /* SATA PHY Transmit Preemphasis Register 1 */
+#define XLP_HAL_SATA_PHY_PRE2           0x38    /* SATA PHY Transmit Preemphasis Register 2 */
+#define XLP_HAL_SATA_PHY_PRE3           0x3c    /* SATA PHY Transmit Preemphasis Register 3 */
+#define XLP_HAL_SATA_SPDMODE            0x40    /* SATA Speed Mode Register */
+#define XLP_HAL_SATA_REFCLK             0x44    /* SATA Reference Clock Control Register */
+#define XLP_HAL_SATA_BYTE_SWAP_DIS	0x74    /* SATA byte swap disable */
+
+/* SATA_CTL Bits */
+#define SATA_RST_N      (1 << 0)
+#define PHY0_RESET_N    (1 << 16)
+#define PHY1_RESET_N    (1 << 17)
+#define PHY2_RESET_N    (1 << 18)
+#define PHY3_RESET_N    (1 << 19)
+#define M_CSYSREQ       (1 << 2)
+#define S_CSYSREQ       (1 << 3)
+
+/* SATA_STATUS Bits */
+#define P0_PHY_READY (1 << 4)
+#define P1_PHY_READY (1 << 5)
+#define P2_PHY_READY (1 << 6)
+#define P3_PHY_READY (1 << 7)
+
+/* SATA CONTROLLER GENERIC HOST REGISTERS */
+#define SATA_CAP                0x00
+#define SATA_GHC                0x04
+#define SATA_IS                 0x08
+#define SATA_PI                 0x0c
+#define SATA_AHCI               0x10
+#define SATA_CCC_CTL            0x14
+#define SATA_CCC_PORTS          0x18
+#define SATA_CAP2               0x24
+#define SATA_BISTAFR            0xa0
+#define SATA_BISTCR             0xa4
+#define SATA_BISTFCTR           0xa8
+#define SATA_BISTSR             0xac
+#define SATA_OOBR               0xbc
+#define SATA_TIMER1MS           0xe0
+#define Reserved5               0x0
+#define SATA_GPARAM1R           0xe8
+#define SATA_GPARAM2R           0xec
+#define SATA_PPARAMR            0xf0
+#define SATA_TESTR              0xf4
+#define SATA_VERSIONR           0xf8
+#define SATA_IDR                0xfc
+
+#define HBAReset (1 << 0)
+
+
+/* XLP BIU_NUMBER
+ * Used by 6.5.0x54.SYSDISABLE & 6.5.0x55.SYS_RESET
+ */
+#define XLP2XX_IO_NUM_OF_BIUS                16
+/* sbb0 */
+#define XLP2XX_IO_PIC_BIU_NUMBER             0
+#define XLP2XX_IO_PCIE0_BIU_NUMBER           1
+#define XLP2XX_IO_PCIE1_BIU_NUMBER           2
+#define XLP2XX_IO_PCIE2_BIU_NUMBER           3
+#define XLP2XX_IO_PCIE3_BIU_NUMBER           4
+#define XLP2XX_IO_USB_BIU_NUMBER             5
+#define XLP2XX_IO_GDX_BIU_NUMBER             6
+#define XLP2XX_IO_CMP_BIU_NUMBER             7
+#define XLP2XX_IO_SEC_BIU_NUMBER             8
+#define XLP2XX_IO_RSA_BIU_NUMBER             9
+/* sbb1 */
+#define XLP2XX_IO_GIO_BIU_NUMBER             10
+#define XLP2XX_IO_GBU_BIU_NUMBER             11
+#define XLP2XX_IO_NET_BIU_NUMBER             12
+#define XLP2XX_IO_MSG_BIU_NUMBER             13
+#define XLP2XX_IO_POE_BIU_NUMBER             14
+#define XLP2XX_IO_REGX_BIU_NUMBER            15
+
+
+#define XLP3XX_IO_NUM_OF_BIUS                17
+/* sbb0 */
+#define XLP3XX_IO_PIC_BIU_NUMBER             0
+#define XLP3XX_IO_PCIE0_BIU_NUMBER           1
+#define XLP3XX_IO_PCIE1_BIU_NUMBER           2
+#define XLP3XX_IO_PCIE2_BIU_NUMBER           3
+#define XLP3XX_IO_PCIE3_BIU_NUMBER           4
+#define XLP3XX_IO_USB_BIU_NUMBER             5
+#define XLP3XX_IO_POE_BIU_NUMBER             7
+#define XLP3XX_IO_SATA_BIU_NUMBER            10
+#define XLP3XX_IO_SRIO_BIU_NUMBER            15
+#define XLP3XX_IO_REGX_BIU_NUMBER            16
+/* sbb1 */
+#define XLP3XX_IO_GIO_BIU_NUMBER             8
+#define XLP3XX_IO_GBU_BIU_NUMBER             9
+#define XLP3XX_IO_NET_BIU_NUMBER             6
+#define XLP3XX_IO_MSG_BIU_NUMBER             11
+#define XLP3XX_IO_GDX_BIU_NUMBER             12
+#define XLP3XX_IO_SEC_BIU_NUMBER             13
+#define XLP3XX_IO_RSA_BIU_NUMBER             14
+
+
+#define XLP8XX_IO_NUM_OF_BIUS                18
+/* sbb0 */
+#define XLP8XX_IO_ICI0_BIU_NUMBER            0
+#define XLP8XX_IO_ICI1_BIU_NUMBER            1
+#define XLP8XX_IO_ICI2_BIU_NUMBER            2
+#define XLP8XX_IO_PIC_BIU_NUMBER             3
+#define XLP8XX_IO_PCIE0_BIU_NUMBER           4
+#define XLP8XX_IO_PCIE1_BIU_NUMBER           5
+#define XLP8XX_IO_PCIE2_BIU_NUMBER           6
+#define XLP8XX_IO_PCIE3_BIU_NUMBER           7
+#define XLP8XX_IO_USB_BIU_NUMBER             8
+#define XLP8XX_IO_NET_BIU_NUMBER             9
+#define XLP8XX_IO_POE_BIU_NUMBER             10
+#define XLP8XX_IO_GIO_BIU_NUMBER             16
+#define XLP8XX_IO_GBU_BIU_NUMBER             17
+/* sbb1 */
+#define XLP8XX_IO_MSG_BIU_NUMBER             11
+#define XLP8XX_IO_GDX_BIU_NUMBER             12
+#define XLP8XX_IO_SEC_BIU_NUMBER             13
+#define XLP8XX_IO_RSA_BIU_NUMBER             14
+#define XLP8XX_IO_CMP_BIU_NUMBER             15
+
+#endif /* #ifndef NLM_HAL_XLP_DEV_H */
diff --git a/arch/mips/include/asm/netlogic/hal/nlm_nae.h b/arch/mips/include/asm/netlogic/hal/nlm_nae.h
new file mode 100644
index 0000000..2b72153
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/hal/nlm_nae.h
@@ -0,0 +1,225 @@
+
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * http://www.gnu.org/licenses/gpl-2.0.txt  
+ * or the Broadcom license below:
+
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_4# */
+
+
+#ifndef __NLM_NAE_H__
+#define __NLM_NAE_H__
+
+#ifndef __ASSEMBLY__
+#define MAX_NAE_CONTEXTS_PERNODE	524
+#define MAX_NAE_PORTS_PERNODE		18
+#define MAX_NAE_FREEIN_DESCS_QUEUE	18
+#define XLP_MAX_INTERLAKEN_IF		2
+
+#define NLM_MAX_NODES           4
+#define MAX_NAE_CPLX_PER_NODE   8
+
+#define FREEBACK_TO_NAE		0x01
+#define VFBID_FROM_FDT		0x02
+#define FREEIN_SPILL_DYNAMIC	0x04
+#define POE_ENQSPILL_DYNAMIC	0x08
+#define POE_DEQSPILL_DYNAMIC	0x10
+#define NAE_RESET_DONE		0x20
+#define NAE_INIT_VALID		0x40
+
+#ifndef NLM_NCPUS_PER_NODE
+#define NLM_NCPUS_PER_NODE	32
+#endif
+
+#define NLM_NAE_SH_LCPU_TO_MAP_SZ		6 /* in integers */
+#define NLM_NAE_SH_LCPU_TO_MAP_SNG_VAL_SZ  	5 /* in bits, can cover 6 cpus in single entry */
+#define NLM_NAE_SH_LCPU_TO_MAP_NVALS_PER_ENTRY 	6 /* with 5 bits, can occupy 6  */
+
+struct nlm_nae_shinfo {
+	int valid;
+	int rxvc;
+	int domid;
+	/* logical cpu to physical cpu map */
+	unsigned int lcpu_2_pcpu_map[NLM_NAE_SH_LCPU_TO_MAP_SZ]; 
+	/* cpu to freein fifo map */
+	unsigned int cpu_2_freeinfifo_map[NLM_NAE_SH_LCPU_TO_MAP_SZ];
+};
+
+enum higig_mode{
+	NO_HIGIG,
+	HIGIG,
+	HIGIG2
+};
+
+#ifndef NLM_NUM_THREADS_PER_CORE
+#define NLM_NUM_THREADS_PER_CORE	4
+#endif
+
+/* Only 3 domains can share one nae node including the owner */
+#define NLM_NAE_MAX_SHARED_DOMS		2
+
+#define NLM_NAE_MAX_FREEIN_FIFOS_PER_NODE 20
+/* XAUI Card only support XAUI mode */
+#define NLM_NAE_XAUI_MODE_XAUI      0
+
+/* RXAUI Card support 3 different modes */
+#define NLM_NAE_RXAUI_MODE_XAUI     1
+#define NLM_NAE_RXAUI_MODE_BROADCOM 2
+#define NLM_NAE_RXAUI_MODE_MARVELL  3
+
+struct nlm_hal_nae_port {
+        int  valid;
+        int  mgmt;
+        int  num_free_desc;
+        int  txq;
+        int  rxq;
+        int  hw_port_id;
+        int  vlan_pri_en;
+        int  iftype;
+        int  num_channels;
+	uint32_t  rx_buf_size;
+	uint32_t  intf_fifo_size;
+	uint32_t  free_desc_size;
+	uint32_t  prsr_seq_fifo_size;
+	uint32_t  rx_slots_reqd;
+	uint32_t  tx_slots_reqd;
+	uint32_t  ucore_mask;
+        int  ext_phy_addr;
+        int  ext_phy_bus;
+	uint32_t  rxaui_scrambler; /* 0: disable scrambler ; 1: enable scrambler */
+	uint32_t  rxaui_mode;      /* 0: broadcom mode; 1: marvell */
+        int  loopback;
+};
+
+struct nlm_hal_nae_config {
+        int fb_vc;
+        int rx_vc;
+        int frin_queue_base;
+        int frin_total_queue;
+        int num_ports;
+	uint32_t flags;
+	int rx_cal_slots;
+	int tx_cal_slots;
+	/* onchip descs per queue: value is taken from array for all 
+	   queues upto 0-17 */
+	int freein_fifo_onchip_num_descs[MAX_NAE_FREEIN_DESCS_QUEUE];
+	/* spill descs per queue, it will be added with the onchip size  */
+	int freein_fifo_spill_num_descs; 
+	uint64_t freein_spill_base;
+	uint64_t freein_spill_size;
+	struct nlm_hal_nae_port ports[MAX_NAE_PORTS_PERNODE];
+	uint32_t cntx2port[MAX_NAE_CONTEXTS_PERNODE];
+	uint32_t num_lanes[XLP_MAX_INTERLAKEN_IF];
+	uint32_t lane_rate[XLP_MAX_INTERLAKEN_IF];
+	/*egress fifo  */
+	uint32_t stg2fifo_base;
+	uint32_t ehfifo_base;
+	uint32_t froutfifo_base;
+	uint32_t msfifo_base;
+	uint32_t pktfifo_base;
+	uint32_t pktlenfifo_base;
+	/* NAE complex map */
+	uint32_t sgmii_complex_map;
+	uint32_t xaui_complex_map;
+	uint32_t higig_mode[MAX_NAE_CPLX_PER_NODE];
+	uint32_t xgmii_speed[MAX_NAE_CPLX_PER_NODE];
+	uint32_t rxaui_complex_map;
+	uint32_t ilk_complex_map;
+	/* total queues used = num_contexts */
+	uint32_t num_contexts;
+
+	/* I am the owner or not, who initialize the node */
+	int owned;
+	/* Freein fifo mask. Out of the max rx fifos, domain ownership
+	of rx-fifos. */
+	uint32_t freein_fifo_dom_mask;
+
+	/* vfbtable id offset, software freeback and hardware freebaack */
+	uint32_t vfbtbl_sw_offset;
+	uint32_t vfbtbl_sw_nentries;
+	uint32_t vfbtbl_hw_offset;
+	uint32_t vfbtbl_hw_nentries;
+
+	/* port fifo mode enabled/disabled */
+	unsigned int port_fifo_en;
+	
+	struct nlm_nae_shinfo shinfo[NLM_NAE_MAX_SHARED_DOMS  + 1]; /* 1 extra for the owner */
+	uint32_t msec_port_enable;
+	unsigned char sectag_offset[MAX_NAE_PORTS_PERNODE];
+	unsigned char sectag_len[MAX_NAE_PORTS_PERNODE];
+	unsigned char icv_len[MAX_NAE_PORTS_PERNODE];
+};
+
+typedef struct nlm_hal_nae_config * nlm_nae_config_ptr;
+
+struct nlm_node_config
+{
+        int valid;
+        int num_nodes;  /* Number of nodes */
+        struct nlm_hal_nae_config *nae_cfg[NLM_MAX_NODES];      /* NAE configuration */
+        struct fmn_cfg *fmn_cfg[NLM_MAX_NODES];
+};
+
+enum freq_config {
+	NLM_DEFAULT	= 0,
+	NLM_NAE,
+	NLM_RSA,
+	NLM_SAE,
+	NLM_DTRE,
+	NLM_CDE,
+};
+
+extern struct nlm_node_config nlm_node_cfg;
+
+enum if_type {
+        UNKNOWN_IF    = 0,
+        SGMII_IF      = 1,
+        XAUI_IF       = 2,
+        INTERLAKEN_IF = 3,
+        RXAUI_IF      = 6,
+};
+
+extern int nlm_hal_write_ucore_shared_mem(int node, unsigned int *data, int words);
+extern int nlm_config_vfbid_table(int node, uint32_t start, uint32_t num_entries, uint32_t *vfbid_tbl);
+extern uint32_t *cntx2port[];
+extern int nlm_hal_restart_ucore(int node, void *fdt);
+extern void nlm_hal_derive_cpu_to_freein_fifo_map(int node,
+                unsigned int phys_cpu_map,
+                unsigned int freein_fifo_mask, unsigned int *cpu_2_freein_fifo_map);
+extern void nlm_hal_modify_nae_ucore_sram_mem(int node, int ucoreid, unsigned int *data, 
+		int off, int words);
+extern void nlm_hal_read_nae_ucore_sram_mem(int node, int ucoreid, unsigned int *data, 
+		int off, int words);
+
+extern void nlm_hal_disable_xaui_flow_control(int node, int block);
+
+#endif
+#endif
diff --git a/arch/mips/include/asm/netlogic/interrupt.h b/arch/mips/include/asm/netlogic/interrupt.h
index a85aadb..84d27d4 100644
--- a/arch/mips/include/asm/netlogic/interrupt.h
+++ b/arch/mips/include/asm/netlogic/interrupt.h
@@ -1,45 +1,57 @@
-/*
- * Copyright 2003-2011 NetLogic Microsystems, Inc. (NetLogic). All rights
- * reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the NetLogic
- * license below:
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in
- *    the documentation and/or other materials provided with the
- *    distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY NETLOGIC ``AS IS'' AND ANY EXPRESS OR
- * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
- * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
 
 #ifndef _ASM_NLM_INTERRUPT_H
 #define _ASM_NLM_INTERRUPT_H
 
+#include <asm/netlogic/pic.h>
+
 /* Defines for the IRQ numbers */
 
-#define IRQ_IPI_SMP_FUNCTION	3
-#define IRQ_IPI_SMP_RESCHEDULE	4
-#define IRQ_MSGRING		6
-#define IRQ_TIMER		7
+#define IRQ_DUMMY_UART           2
+#define IRQ_IPI_SMP_FUNCTION     3
+#define IRQ_IPI_SMP_RESCHEDULE   4
+#define IRQ_REMOTE_DEBUG         5
+#define IRQ_MSGRING              6
+#define IRQ_TIMER                7
+#define IRQ_IPI_SMP_KGDB   		50
+#define IRQ_IPI_OPROFILE        51
+
+#define IRQ_IPI_CRF_MGMT_IPI	NLM_MANAGEMENT_IPI /* */
+#define IRQ_IPI_CRF_EVENTQ_IPI  NLM_EVENTQ_IPI
+
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY
+
+#define IRQ_IPI_NETRX           49
+#define SMP_NETRX_IPI           32
+
+#endif /* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
+
+
+#define SMP_CALL_KGDB_HOOK 	8
+#define SMP_OPROFILE_IPI        16
+
 
 #endif
diff --git a/arch/mips/include/asm/netlogic/io.h b/arch/mips/include/asm/netlogic/io.h
new file mode 100644
index 0000000..c6a7437
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/io.h
@@ -0,0 +1,48 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_NLM_IO_H
+#define _ASM_NLM_IO_H
+
+extern void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long max);
+extern void pci_iounmap(struct pci_dev *dev, void __iomem *);
+
+#define __raw_writeb(v,a)       (*(volatile unsigned char  *)(a) = (v))
+#define __raw_writew(v,a)       (*(volatile unsigned short *)(a) = (v))
+#define __raw_writel(v,a)       (*(volatile unsigned int   *)(a) = (v))
+
+#define __raw_readb(a)          (*(volatile unsigned char  *)(a))
+#define __raw_readw(a)          (*(volatile unsigned short *)(a))
+#define __raw_readl(a)          (*(volatile unsigned int   *)(a))
+
+#define ioread8(p)  ({ unsigned int __v = __raw_readb(p); __v; })
+#define ioread16(p) ({ unsigned int __v = le16_to_cpu(__raw_readw(p)); __v; })
+#define ioread32(p) ({ unsigned int __v = le32_to_cpu(__raw_readl(p)); __v; })
+
+#define iowrite8(v,p)   __raw_writeb(v, p)
+#define iowrite16(v,p)  __raw_writew(cpu_to_le16(v), p)
+#define iowrite32(v,p)  __raw_writel(cpu_to_le32(v), p)
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/iomap.h b/arch/mips/include/asm/netlogic/iomap.h
new file mode 100644
index 0000000..56ad07e
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/iomap.h
@@ -0,0 +1,294 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_RFI_IO_H
+#define _ASM_RFI_IO_H
+
+#if !defined(CONFIG_NLM_XLP)
+#define DEFAULT_NETLOGIC_IO_BASE 0xffffffffbef00000ULL
+#define NETLOGIC_IO_DDR2_CHN0_OFFSET       0x01000
+#define NETLOGIC_IO_DDR2_CHN1_OFFSET       0x02000
+#define NETLOGIC_IO_DDR2_CHN2_OFFSET       0x03000
+#define NETLOGIC_IO_DDR2_CHN3_OFFSET       0x04000
+#define NETLOGIC_IO_PIC_OFFSET             0x08000
+#define NETLOGIC_IO_UART_0_OFFSET          0x14000
+#define NETLOGIC_IO_UART_1_OFFSET          0x15100
+
+#else
+#define DEFAULT_NETLOGIC_IO_BASE 0xffffffffb8000000ULL
+#define NETLOGIC_IO_DDR2_CHN0_OFFSET       0x14000
+#define NETLOGIC_IO_DDR2_CHN1_OFFSET       0x15000
+#define NETLOGIC_IO_DDR2_CHN2_OFFSET       0x16000
+#define NETLOGIC_IO_DDR2_CHN3_OFFSET       0x17000
+#define NETLOGIC_IO_PIC_OFFSET             0x04000
+#define NETLOGIC_IO_UART_0_OFFSET          0x30100
+#define NETLOGIC_IO_UART_1_OFFSET          0x31100
+#endif /* CONFIG_NLM_XLP */
+
+#define NETLOGIC_IO_SIZE                   0x1000
+
+#define NETLOGIC_IO_BRIDGE_OFFSET          0x00000
+
+#define NETLOGIC_IO_RLD2_CHN0_OFFSET       0x05000
+#define NETLOGIC_IO_RLD2_CHN1_OFFSET       0x06000
+
+#define NETLOGIC_IO_SRAM_OFFSET            0x07000
+
+#define NETLOGIC_IO_PCIX_OFFSET            0x09000
+#define NETLOGIC_IO_HT_OFFSET              0x0A000
+
+#define NETLOGIC_IO_SECURITY_OFFSET        0x0B000
+
+#define NETLOGIC_IO_GMAC_0_OFFSET          0x0C000
+#define NETLOGIC_IO_GMAC_1_OFFSET          0x0D000
+#define NETLOGIC_IO_GMAC_2_OFFSET          0x0E000
+#define NETLOGIC_IO_GMAC_3_OFFSET          0x0F000
+
+#define NETLOGIC_IO_GMAC_4_OFFSET          0x20000
+#define NETLOGIC_IO_GMAC_5_OFFSET          0x21000
+#define NETLOGIC_IO_GMAC_6_OFFSET          0x22000
+#define NETLOGIC_IO_GMAC_7_OFFSET          0x23000
+
+#define NETLOGIC_IO_PCIE_0_OFFSET          0x1E000
+#define NETLOGIC_IO_PCIE_1_OFFSET          0x1F000
+#define NETLOGIC_IO_SRIO_0_OFFSET          0x1E000
+#define NETLOGIC_IO_SRIO_1_OFFSET          0x1F000
+
+#define NETLOGIC_IO_USB_0_OFFSET           0x24000
+#define NETLOGIC_IO_USB_1_OFFSET           0x25000
+
+#define NETLOGIC_IO_COMP_OFFSET            0x1D000
+
+#ifdef XLS
+#endif /* XLS */
+
+#define NETLOGIC_IO_SPI4_0_OFFSET          0x10000
+#define NETLOGIC_IO_XGMAC_0_OFFSET         0x11000
+#define NETLOGIC_IO_SPI4_1_OFFSET          0x12000
+#define NETLOGIC_IO_XGMAC_1_OFFSET         0x13000
+
+#define NETLOGIC_IO_I2C_0_OFFSET           0x16000
+#define NETLOGIC_IO_I2C_1_OFFSET           0x17000
+
+#define NETLOGIC_IO_GPIO_OFFSET            0x18000
+
+#define NETLOGIC_IO_FLASH_OFFSET           0x19000
+
+#define NETLOGIC_IO_TB_OFFSET           	  0x1C000
+
+#define NETLOGIC_CPLD_OFFSET               0xffffffffbd840000ULL
+
+/* Base Address (Virtual) of the PCI Config address space
+ * For now, choose 256M phys in kseg1 = 0xA0000000 + (1<<28)
+ * Config space spans 256 (num of buses) * 256 (num functions) * 256 bytes
+ * ie 1<<24 = 16M
+ */ 
+#define DEFAULT_PCI_CONFIG_BASE         0x18000000
+#define DEFAULT_HT_TYPE0_CFG_BASE       0x16000000
+#define DEFAULT_HT_TYPE1_CFG_BASE       0x17000000
+
+#ifndef __ASSEMBLY__
+
+#include <linux/types.h>
+#include <asm/byteorder.h>
+
+typedef volatile __u32 nlm_reg_t;
+extern unsigned long netlogic_io_base;
+
+#define netlogic_io_mmio(offset) ((nlm_reg_t *)(netlogic_io_base+(offset)))
+
+/* XLP_MERGE_TODO */
+#if defined(NLM_BRIDGE_WKAROUND)
+#include "nlm_rw_lock.h"
+extern nlm_rwlock_t *nlm_bridge_lock;
+extern int nlm_enable_br_wrkaround;
+
+static inline void nlm_preempt_enable(void)
+{
+    uint32_t status=0;
+    __asm__ volatile(
+#ifdef CONFIG_64BIT
+            "lw %0, 36($28)\n"
+#else
+            "lw %0, 20($28)\n"
+#endif
+            "addiu %0, %0, -1 \n"
+#ifdef CONFIG_64BIT
+            "sw %0, 36($28) \n"
+#else
+            "sw %0, 20($28) \n"
+#endif
+            :"=r"(status)
+            );    
+}
+
+static inline void nlm_preempt_disable(void)
+{
+    uint32_t status=0;
+    __asm__ volatile(
+#ifdef CONFIG_64BIT
+            "lw %0, 36($28)\n"
+#else
+            "lw %0, 20($28)\n"
+#endif
+            "addiu %0, %0, 1 \n"
+#ifdef CONFIG_64BIT
+            "sw %0, 36($28) \n"
+#else
+            "sw %0, 20($28) \n"
+#endif
+            :"=r"(status)
+            );    
+}
+
+static inline uint32_t nlm_br_read_lock(void)
+{
+    uint32_t ret = 0;
+	if(nlm_enable_br_wrkaround){
+         nlm_preempt_disable();
+		 ret = nlm_read_lock_irq_save(nlm_bridge_lock);
+         nlm_preempt_enable();
+    }
+	return ret;
+}
+static inline void nlm_br_read_unlock(unsigned int flags)
+{
+	if(nlm_enable_br_wrkaround){
+        nlm_preempt_disable();
+		nlm_read_unlock_irq_restore(nlm_bridge_lock, flags);
+        nlm_preempt_enable();
+    }
+}
+
+static inline uint32_t nlm_br_write_lock(void)
+{
+    uint32_t ret = 0;
+	if(nlm_enable_br_wrkaround){
+        nlm_preempt_disable();
+		ret = nlm_write_lock_irq_save(nlm_bridge_lock);
+        nlm_preempt_enable();
+    }
+	return ret;
+}
+
+static inline void nlm_br_write_unlock(unsigned int flags)
+{
+	if(nlm_enable_br_wrkaround){
+        nlm_preempt_disable();
+		nlm_write_unlock_irq_restore(nlm_bridge_lock, flags);
+        nlm_preempt_enable();
+    }
+}
+
+static inline uint32_t nlm_read_reg_locked(nlm_reg_t *base, 
+		unsigned int offset) 	
+{
+	unsigned int flags, val;
+
+	flags = nlm_br_read_lock();
+	val = (be32_to_cpu((base)[(offset)])); 
+	nlm_br_read_unlock(flags);
+
+	return val;
+}
+static inline uint32_t nlm_read_reg_le_locked(nlm_reg_t *base, 
+		unsigned int offset) 	
+{
+	unsigned int flags, val;
+	flags = nlm_br_read_lock();
+	val = (le32_to_cpu((base)[(offset)])); 
+	nlm_br_read_unlock(flags);
+
+	return val;
+}
+static inline void nlm_write_reg_locked(nlm_reg_t *base, 
+		 unsigned int offset,  unsigned int value)
+{
+	unsigned int flags;
+	flags = nlm_br_write_lock();
+	((base)[(offset)] = cpu_to_be32((value)));
+	nlm_br_write_unlock(flags);
+}
+
+static inline void nlm_write_reg_le_locked(nlm_reg_t *base, 
+		 unsigned int offset,  unsigned int value)
+{
+	unsigned int flags;
+	flags = nlm_br_write_lock();
+	((base)[(offset)] = cpu_to_le32((value)));
+	nlm_br_write_unlock(flags);
+}
+
+#define netlogic_read_reg(base, offset) nlm_read_reg_locked(base, offset)
+#define netlogic_write_reg(base, offset, value) \
+	nlm_write_reg_locked(base, offset, value)
+
+#define netlogic_read_reg_le32(base, offset) \
+	nlm_read_reg_le_locked(base, offset)
+#define netlogic_write_reg_le32(base, offset, value) \
+	nlm_write_reg_le_locked(base, offset, value)
+
+#else /* NLM_BRIDGE_WORKAROUND */
+
+static inline uint32_t nlm_br_read_lock(void) 
+{
+	return 0;
+}
+
+static inline void nlm_br_read_unlock(unsigned int flags)
+{
+}
+
+static inline uint32_t nlm_br_write_lock(void)
+{
+	return 0;
+}
+
+static inline void nlm_br_write_unlock(unsigned int flags)
+{
+}
+#ifdef CONFIG_CPU_LITTLE_ENDIAN
+
+#define netlogic_read_reg(base, offset) ((base)[(offset)])
+#define netlogic_write_reg(base, offset, value) ((base)[(offset)] = (value))
+
+#else
+
+#define netlogic_read_reg(base, offset) (be32_to_cpu((base)[(offset)]))
+#define netlogic_write_reg(base, offset, value) ((base)[(offset)] = cpu_to_be32((value)))
+
+#endif
+
+#define netlogic_read_reg_le32(base, offset) (le32_to_cpu((base)[(offset)]))
+#define netlogic_write_reg_le32(base, offset, value) \
+	((base)[(offset)] = cpu_to_le32((value)))
+
+#endif /* NLM_BRIDGE_WORKAROUND */
+
+extern void on_chip_init(void);
+
+#endif /* __ASSEMBLY__ */
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/mips-exts.h b/arch/mips/include/asm/netlogic/mips-exts.h
new file mode 100644
index 0000000..5b7e3f4
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/mips-exts.h
@@ -0,0 +1,424 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_NLM_MIPS_EXTS_H
+#define _ASM_NLM_MIPS_EXTS_H
+
+#define NETLOGIC_OSS_SEL_TLB_STATS 0
+#define NETLOGIC_OSS_SEL_UNUSED 1
+#define NETLOGIC_OSS_SEL_PAGEMASK 2
+#define NETLOGIC_OSS_SEL_VADDR 3
+#define NETLOGIC_OSS_SEL_PFN0 4
+#define NETLOGIC_OSS_SEL_PFN1 5
+#define NETLOGIC_OSS_SEL_K0 6
+#define NETLOGIC_OSS_SEL_K1 7
+
+#define OS_SCRATCH_REG0	22, 0
+#define OS_SCRATCH_REG1	22, 1
+#define OS_SCRATCH_REG2	22, 2
+#define OS_SCRATCH_REG3	22, 3
+#define OS_SCRATCH_REG4	22, 4
+#define OS_SCRATCH_REG5	22, 5
+#define OS_SCRATCH_REG6	22, 6
+#define OS_SCRATCH_REG7	22, 7
+
+#define OS_KGDB_SCRATCH_REG6	$22, 6
+#define OS_KGDB_SCRATCH_REG7	$22, 7
+
+#ifndef __ASSEMBLY__
+
+#include <linux/types.h>
+#include <asm/netlogic/interrupt.h>
+
+/* Scratch registers used */
+#define NLM_TLB_STATS_SCRATCH_REG_SEL  2
+#define NLM_HTLB_PMASK_SCRATCH_REG_SEL 3
+#define NLM_CRF_PERF0_SCRATCH_REG_SEL  NLM_PERF0_SCRATCH
+#define NLM_CRF_PERF1_SCRATCH_REG_SEL  NLM_PERF1_SCRATCH
+
+
+#define DMFC0_AT_EIRR 0x40214806
+#define DMFC0_AT_EIMR 0x40214807
+#define DMTC0_AT_EIRR 0x40a14806
+#define DMTC0_AT_EIMR 0x40a14807
+
+/* functions to write to and read from the extended
+ * cp0 registers.
+ * EIRR : Extended Interrupt Request Register
+ *        cp0 register 9 sel 6
+ *        bits 0...7 are same as cause register 8...15
+ * EIMR : Extended Interrupt Mask Register
+ *        cp0 register 9 sel 7
+ *        bits 0...7 are same as status register 8...15
+ */
+
+static inline __u64 read_64bit_cp0_eirr(void)
+{
+  __u32 high, low;
+
+  __asm__ __volatile__ (
+			".set push\n"
+			".set noreorder\n"
+			".set noat\n"
+			".set mips4\n"
+
+			".word 0x40214806  \n\t"
+			"nop               \n\t"
+			"dsra32 %0, $1, 0  \n\t"
+			"sll    %1, $1, 0  \n\t"
+
+			".set pop\n"
+
+			: "=r" (high), "=r" (low)
+			);
+
+  return ( ((__u64)high) << 32) | low;
+}
+
+static inline __u64 read_64bit_cp0_eimr(void)
+{
+  __u32 high, low;
+
+  __asm__ __volatile__ (
+			".set push\n"
+			".set noreorder\n"
+			".set noat\n"
+			".set mips4\n"
+
+			".word 0x40214807  \n\t"
+			"nop               \n\t"
+			"dsra32 %0, $1, 0  \n\t"
+			"sll    %1, $1, 0  \n\t"
+
+			".set pop\n"
+
+			: "=r" (high), "=r" (low)
+			);
+
+  return ( ((__u64)high) << 32) | low;
+}
+
+static inline void write_64bit_cp0_eirr(__u64 value)
+{
+  __u32 low, high;
+
+  high = value >> 32;
+  low  = value & 0xffffffff;
+
+	__asm__ __volatile__ (
+	".set push\n"
+	".set noreorder\n"
+	".set noat\n"
+	".set mips4\n\t"
+
+	"dsll32 $2, %1, 0  \n\t"
+	"dsll32 $1, %0, 0  \n\t"
+	"dsrl32 $2, $2, 0  \n\t"
+	"or     $1, $1, $2 \n\t"
+	".word  0x40a14806 \n\t"
+	"nop               \n\t"
+
+	".set pop\n"
+
+	:
+	: "r" (high), "r" (low)
+	: "$1", "$2");
+}
+
+static inline void write_64bit_cp0_eimr(__u64 value)
+{
+  __u32 low, high;
+
+  high = value >> 32;
+  low  = value & 0xffffffff;
+
+	__asm__ __volatile__ (
+	".set push\n"
+	".set noreorder\n"
+	".set noat\n"
+	".set mips4\n\t"
+
+	"dsll32 $2, %1, 0  \n\t"
+	"dsll32 $1, %0, 0  \n\t"
+	"dsrl32 $2, $2, 0  \n\t"
+	"or     $1, $1, $2 \n\t"
+	".word  0x40a14807 \n\t"
+	"nop               \n\t"
+
+	".set pop\n"
+
+	:
+	: "r" (high), "r" (low)
+	: "$1", "$2");
+}
+
+static __inline__ int ldadd_w(unsigned int value, volatile int *addr)
+{
+	unsigned long res;
+  __asm__ __volatile__(
+		       ".set push\n"
+		       ".set noreorder\n"
+		       "move $8, %2\n"
+		       "move $9, %3\n"
+		       //"ldaddw %2, %3\n"
+                       ".word 0x71280010\n"
+		       "move %0, $8\n"
+		       ".set pop\n"
+		       :"=r"(res), "+m"(*addr)
+		       : "r" (value), "r"((unsigned long)addr)
+		       : "$8", "$9"
+		       );
+  return res;
+}
+
+static __inline__ void ldadd_w_no_read(int value, volatile int *addr)
+{
+	unsigned long res;
+  __asm__ __volatile__(
+                       ".set push\n"
+                       ".set noreorder\n"
+                       "move $8, %2\n"
+                       "move $9, %3\n"
+                       //"ldaddw $8, $9\n"
+                       ".word 0x71280010\n"
+                       //"move %0, $8\n"
+                       ".set pop\n"
+                       :"=r"(res), "+m"(*addr)
+                       : "r" (value), "r"((unsigned long)addr)
+                       : "$8", "$9"
+                       );
+}
+
+static __inline__ unsigned int ldadd_wu(unsigned int value, volatile unsigned int *addr)
+{
+	unsigned long res;
+  __asm__ __volatile__(
+		       ".set push\n"
+		       ".set noreorder\n"
+		       "move $8, %2\n"
+		       "move $9, %3\n"
+		       //"ldaddwu $8, $9\n"
+                       ".word 0x71280011\n"
+		       "move %0, $8\n"
+		       ".set pop\n"
+		       :"=r"(res), "+m"(*addr)
+		       : "r"(value), "r"((unsigned long)addr)
+		       : "$8", "$9"
+		       );
+  return res;
+}
+
+static __inline__ void ldadd_wu_no_read(unsigned int value,
+					volatile unsigned int *addr)
+{
+	unsigned long res;
+  __asm__ __volatile__(
+                       ".set push\n"
+                       ".set noreorder\n"
+                       "move $8, %2\n"
+                       "move $9, %3\n"
+                       //"ldaddwu $8, $9\n"
+                       ".word 0x71280011\n"
+                       //"move %0, $8\n"
+                       ".set pop\n"
+                       :"=r"(res), "+m"(*addr)
+                       : "r"(value), "r"((unsigned long)addr)
+                       : "$8", "$9"
+                       );
+}
+
+#define netlogic_cpu_id()                                        \
+({int __id;                                                     \
+ __asm__ __volatile__ (                                         \
+		       ".set push\n"                            \
+		       ".set noreorder\n"                       \
+                       ".set mips32\n"                          \
+                       "mfc0 $8, $15, 1\n"                      \
+		       "andi $8, $8, 0x3ff\n"                   \
+		       "srl %0, $8, 1\n"                        \
+		       ".set pop\n"                             \
+		       : "=r" (__id) : : "$8");                 \
+ __id;})
+
+#define netlogic_thr_id()                                        \
+({int __id;                                                     \
+ __asm__ __volatile__ (                                         \
+		       ".set push\n"                            \
+		       ".set noreorder\n"                       \
+                       ".set mips32\n"                          \
+                       "mfc0 $8, $15, 1\n"                      \
+		       "andi %0, $8, 0x3\n"                     \
+		       ".set pop\n"                             \
+		       : "=r" (__id) : : "$8");                 \
+ __id;})
+
+static __inline__ int hard_smp_processor_id(void)
+{
+	int cpu;
+
+	__asm__ __volatile__ (
+		".set push\n"
+		".set noreorder\n"
+                ".set mips32\n"
+                "mfc0 $8, $15, 1\n"
+		"andi %0, $8, 0x3ff\n"
+		".set pop\n"
+		: "=&r"(cpu) : : "$8"
+		);
+
+	return cpu;
+}
+
+#define netlogic_cpu_to_thrid(cpu) (phys_proc_id[(cpu)] >> 2)
+#define netlogic_cpu_to_cpuid(cpu) (phys_proc_id[(cpu)] & 0x3)
+
+#define CPU_BLOCKID_IFU      0
+#define CPU_BLOCKID_ICU      1
+#define CPU_BLOCKID_IEU      2
+#define CPU_BLOCKID_LSU      3
+#define CPU_BLOCKID_MMU      4
+#define CPU_BLOCKID_PRF      5
+
+#define LSU_CERRLOG_REGID    9
+
+static __inline__ unsigned int read_32bit_nlm_ctrl_reg(int block, int reg)
+{
+  unsigned int __res;
+
+  __asm__ __volatile__(
+		       ".set\tpush\n\t"
+		       ".set\tnoreorder\n\t"
+		       "move $9, %1\n"
+/* 		       "mfcr\t$8, $9\n\t"          */
+		       ".word 0x71280018\n"
+		       "move %0, $8\n"
+		       ".set\tpop"
+		       : "=r" (__res) : "r"((block<<8)|reg)
+		       : "$8", "$9"
+		       );
+  return __res;
+}
+
+static __inline__ void write_32bit_nlm_ctrl_reg(int block, int reg, unsigned int value)
+{
+  __asm__ __volatile__(
+		       ".set\tpush\n\t"
+		       ".set\tnoreorder\n\t"
+		       "move $8, %0\n"
+		       "move $9, %1\n"
+/* 		       "mtcr\t$8, $9\n\t"  */
+		       ".word 0x71280019\n"
+		       ".set\tpop"
+		       :
+		       : "r" (value), "r"((block<<8)|reg)
+		       : "$8", "$9"
+		       );
+}
+
+static __inline__ unsigned long long read_64bit_nlm_ctrl_reg(int block, int reg)
+{
+	unsigned int high, low;
+
+	__asm__ __volatile__(
+		".set\tmips64\n\t"
+		"move    $9, %2\n"
+		/* "mfcr    $8, $9\n" */
+		".word   0x71280018\n"
+		"dsrl32  %0, $8, 0\n\t"
+		"dsll32  $8, $8, 0\n\t"
+		"dsrl32  %1, $8, 0\n\t"
+		".set mips0"
+		: "=r" (high), "=r"(low)
+		: "r"((block<<8)|reg)
+		: "$8", "$9"
+		);
+
+	return ( (((unsigned long long)high)<<32) | low);
+}
+
+static __inline__ void write_64bit_nlm_ctrl_reg(int block, int reg,unsigned long long value)
+{
+	__u32 low, high;
+	high = value >> 32;
+	low = value & 0xffffffff;
+
+	__asm__ __volatile__(
+		".set push\n"
+		".set noreorder\n"
+		".set mips4\n\t"
+		/* Set up "rs" */
+		"move $9, %0\n"
+
+		/* Store 64 bit value in "rt" */
+		"dsll32 $10, %1, 0  \n\t"
+		"dsll32 $8, %2, 0  \n\t"
+		"dsrl32 $8, $8, 0  \n\t"
+		"or     $8, $10, $8 \n\t"
+
+		".word 0x71280019\n" /* mtcr $8, $9 */
+
+		".set pop\n"
+
+		:  /* No outputs */
+		: "r"((block<<8)|reg), "r" (high), "r" (low)
+		: "$8", "$9", "$10"
+		);
+}
+
+typedef struct { volatile int value; } nlm_common_atomic_t;
+
+static __inline__ int nlm_common_test_and_set(nlm_common_atomic_t *lock)
+{
+  int oldval = 0;
+
+  __asm__ __volatile__ (".set push\n"
+			".set noreorder\n"
+			"move $9, %2\n"
+			"li $8, 1\n"
+			//"swapw $8, $9\n"
+			".word 0x71280014\n"
+			"move %1, $8\n"
+			".set pop\n"
+			: "+m" (lock->value), "=r" (oldval)
+			: "r" ((unsigned long)&lock->value)
+			: "$8", "$9"
+			);
+  return (oldval == 0 ? 1/*success*/ : 0/*failure*/);
+}
+
+#define nlm_write_os_scratch_2(val)	__write_64bit_c0_register($22, 2, val)
+#define nlm_read_os_scratch_2()	__read_64bit_c0_register($22, 2)
+
+#define nlm_write_os_scratch_3(val)	__write_64bit_c0_register($22, 3, val)
+#define nlm_read_os_scratch_3()	__read_64bit_c0_register($22, 3)
+#endif
+
+#ifdef CONFIG_CPU_XLP
+#define SET_MIPS64 .set mips64r2
+#else
+#define SET_MIPS64 .set mips64
+#endif
+
+#endif /* _ASM_NLM_MIPS_EXTS_H */
diff --git a/arch/mips/include/asm/netlogic/msgring.h b/arch/mips/include/asm/netlogic/msgring.h
new file mode 100644
index 0000000..27c2daa
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/msgring.h
@@ -0,0 +1,687 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_NLM_MSG_RING_H
+#define _ASM_NLM_MSG_RING_H
+
+#include <linux/types.h>
+
+#include <asm/asm.h>
+#include <asm/netlogic/debug.h>
+#include <asm/netlogic/mips-exts.h>
+
+#ifndef __STR
+#define __STR(x) #x
+#endif
+#ifndef STR
+#define STR(x) __STR(x)
+#endif
+
+#define find_msb_one_bit(source)                                \
+({ uint64_t __res;                                              \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\tnoreorder\n\t"					\
+        "dlco\t$8, %1\n\t"                                      \
+	".set\tpop"						\
+        : "=r" (__res): "r" (source): "$8"                      \
+        );                                                      \
+        __res;})
+
+#define read_32bit_cp2_register(source)                         \
+({ int __res;                                                   \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        "mfc2\t%0,"STR(source)"\n\t"                            \
+	".set\tpop"						\
+        : "=r" (__res));                                        \
+        __res;})
+
+#define write_32bit_cp2_register(register,value)                \
+        __asm__ __volatile__(                                   \
+        "mtc2\t%0,"STR(register)"\n\t"				\
+	"nop"							\
+        : : "r" (value));
+
+#define read_32bit_cp2_register_sel(source, sel)                \
+({ int __res;                                                   \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips32\n\t"                                       \
+        "mfc2\t%0,"STR(source)", %1\n\t"                        \
+	".set\tpop"						\
+        : "=r" (__res) : "i" (sel) );                           \
+        __res;})
+
+#define write_32bit_cp2_register_sel(reg, value, sel)           \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips32\n\t"                                       \
+        "mtc2\t%0,"STR(reg)", %1\n\t"                           \
+	".set\tpop"						\
+        : : "r" (value), "i" (sel) );
+
+#define MSGRNG_TX_BUF_REG $0
+#define MSGRNG_RX_BUF_REG $1
+
+#define MSGRNG_MSG_STATUS_REG $2
+#define MSGRNG_MSG_CONFIG_REG $3
+
+#define MSGRNG_MSG_BUCKSIZE_REG $4
+
+#define MSGRNG_CC_0_REG  $16
+#define MSGRNG_CC_1_REG  $17
+#define MSGRNG_CC_2_REG  $18
+#define MSGRNG_CC_3_REG  $19
+#define MSGRNG_CC_4_REG  $20
+#define MSGRNG_CC_5_REG  $21
+#define MSGRNG_CC_6_REG  $22
+#define MSGRNG_CC_7_REG  $23
+#define MSGRNG_CC_8_REG  $24
+#define MSGRNG_CC_9_REG  $25
+#define MSGRNG_CC_10_REG $26
+#define MSGRNG_CC_11_REG $27
+#define MSGRNG_CC_12_REG $28
+#define MSGRNG_CC_13_REG $29
+#define MSGRNG_CC_14_REG $30
+#define MSGRNG_CC_15_REG $31
+
+#define msgrng_read_status() read_32bit_cp2_register(MSGRNG_MSG_STATUS_REG)
+
+#define msgrng_read_config() read_32bit_cp2_register(MSGRNG_MSG_CONFIG_REG)
+#define msgrng_write_config(value) write_32bit_cp2_register(MSGRNG_MSG_CONFIG_REG, value)
+
+#define msgrng_read_bucksize(bucket) read_32bit_cp2_register_sel(MSGRNG_MSG_BUCKSIZE_REG, bucket)
+#define msgrng_write_bucksize(bucket, value) write_32bit_cp2_register_sel(MSGRNG_MSG_BUCKSIZE_REG, value, bucket)
+
+#define msgrng_read_cc(reg, pri) read_32bit_cp2_register_sel(reg, pri)
+#define msgrng_write_cc(reg, value, pri) write_32bit_cp2_register_sel(reg, value, pri)
+
+#ifndef _ABI64
+#define read_64bit_cp2_register_sel(source, sel)			\
+({									\
+	unsigned int high, low;						\
+									\
+		__asm__ __volatile__(					\
+			".set\tmips64\n\t"				\
+			"dmfc2\t$8, "STR(source)","STR(sel)"\n\t"		\
+			"dsrl32\t%0, $8, 0\n\t"			        \
+                        "dsll32\t$8, $8, 0\n\t"                         \
+                        "dsrl32\t%1, $8, 0\n\t"                         \
+			".set\tmips0"					\
+			: "=r" (high), "=r"(low): "i"(sel) : "$8");	\
+	( (((unsigned long long)high)<<32) | low);					\
+})
+
+#define write_64bit_cp2_register_sel(source, val, sel)			\
+do {									\
+     unsigned int high = val>>32;                                       \
+     unsigned int low  = val & 0xffffffff;                              \
+		__asm__ __volatile__(					\
+			".set\tmips64\n\t"				\
+                        "dsll32 $8, %1, 0\n"                            \
+                        "dsll32 $9, %0, 0\n"                            \
+                        "dsrl32 $8, $8, 0\n"                            \
+                        "or     $8, $8, $9\n"				\
+			"dmtc2\t$8, "STR(source)", %2\n\t"		\
+			".set\tmips0"					\
+			: : "r" (high), "r" (low), "i"(sel): "$8", "$9");		\
+} while (0)
+
+#else
+#define read_64bit_cp2_register(source)                         \
+({ unsigned long long __res;                                    \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        ".set\tmips64\n\t"                                      \
+        "dmfc2\t%0,"STR(source)"\n\t"                            \
+	".set\tpop"						\
+        : "=r" (__res));                                        \
+        __res;})
+
+#define write_64bit_cp2_register(register,value)                \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        "dmtc2\t%0,"STR(register)"\n\t"				\
+	"nop"							\
+	".set\tpop"						\
+        : : "r" (value));
+
+#define read_64bit_cp2_register_sel(source, sel)                \
+({ unsigned long long __res;                                    \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips64\n\t"                                       \
+        "dmfc2\t%0,"STR(source)", %1\n\t"                        \
+	".set\tpop"						\
+        : "=r" (__res) : "i" (sel) );                           \
+        __res;})
+
+#define write_64bit_cp2_register_sel(reg, value, sel)           \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips64\n\t"                                       \
+        "dmtc2\t%0,"STR(reg)", %1\n\t"                           \
+	".set\tpop"						\
+        : : "r" (value), "i" (sel) );
+#endif
+
+#define msgrng_load_rx_msg0() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 0)
+#define msgrng_load_rx_msg1() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 1)
+#define msgrng_load_rx_msg2() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 2)
+#define msgrng_load_rx_msg3() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 3)
+
+#define msgrng_load_tx_msg0(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 0)
+#define msgrng_load_tx_msg1(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 1)
+#define msgrng_load_tx_msg2(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 2)
+#define msgrng_load_tx_msg3(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 3)
+
+/* Station IDs */
+#define MSGRNG_STNID_CPU0  0x00
+#define MSGRNG_STNID_CPU1  0x08
+#define MSGRNG_STNID_CPU2  0x10
+#define MSGRNG_STNID_CPU3  0x18
+#define MSGRNG_STNID_CPU4  0x20
+#define MSGRNG_STNID_CPU5  0x28
+#define MSGRNG_STNID_CPU6  0x30
+#define MSGRNG_STNID_CPU7  0x38
+
+#define MSGRING_STNID_DEVICES 64
+#define MSGRNG_STNID_XGS0_TX 64
+#define MSGRNG_STNID_XMAC0_00_TX 64
+#define MSGRNG_STNID_XMAC0_01_TX 65
+#define MSGRNG_STNID_XMAC0_02_TX 66
+#define MSGRNG_STNID_XMAC0_03_TX 67
+#define MSGRNG_STNID_XMAC0_04_TX 68
+#define MSGRNG_STNID_XMAC0_05_TX 69
+#define MSGRNG_STNID_XMAC0_06_TX 70
+#define MSGRNG_STNID_XMAC0_07_TX 71
+#define MSGRNG_STNID_XMAC0_08_TX 72
+#define MSGRNG_STNID_XMAC0_09_TX 73
+#define MSGRNG_STNID_XMAC0_10_TX 74
+#define MSGRNG_STNID_XMAC0_11_TX 75
+#define MSGRNG_STNID_XMAC0_12_TX 76
+#define MSGRNG_STNID_XMAC0_13_TX 77
+#define MSGRNG_STNID_XMAC0_14_TX 78
+#define MSGRNG_STNID_XMAC0_15_TX 79
+
+#define MSGRNG_STNID_XGS1_TX 80
+#define MSGRNG_STNID_XMAC1_00_TX 80
+#define MSGRNG_STNID_XMAC1_01_TX 81
+#define MSGRNG_STNID_XMAC1_02_TX 82
+#define MSGRNG_STNID_XMAC1_03_TX 83
+#define MSGRNG_STNID_XMAC1_04_TX 84
+#define MSGRNG_STNID_XMAC1_05_TX 85
+#define MSGRNG_STNID_XMAC1_06_TX 86
+#define MSGRNG_STNID_XMAC1_07_TX 87
+#define MSGRNG_STNID_XMAC1_08_TX 88
+#define MSGRNG_STNID_XMAC1_09_TX 89
+#define MSGRNG_STNID_XMAC1_10_TX 90
+#define MSGRNG_STNID_XMAC1_11_TX 91
+#define MSGRNG_STNID_XMAC1_12_TX 92
+#define MSGRNG_STNID_XMAC1_13_TX 93
+#define MSGRNG_STNID_XMAC1_14_TX 94
+#define MSGRNG_STNID_XMAC1_15_TX 95
+
+#define MSGRNG_STNID_GMAC 96
+#define MSGRNG_STNID_GMACRFR_0  97
+#define MSGRNG_STNID_GMACTX0  98
+#define MSGRNG_STNID_GMACTX1  99
+#define MSGRNG_STNID_GMACTX2  100
+#define MSGRNG_STNID_GMACTX3  101
+#define MSGRNG_STNID_GMACRFR_1  103
+
+#define MSGRNG_STNID_DMA      104
+#define MSGRNG_STNID_DMA_0    104
+#define MSGRNG_STNID_DMA_1    105
+#define MSGRNG_STNID_DMA_2    106
+#define MSGRNG_STNID_DMA_3    107
+
+#define MSGRNG_STNID_XGS0FR 112
+#define MSGRNG_STNID_XMAC0RFR 113
+
+#define MSGRNG_STNID_XGS1FR 114
+#define MSGRNG_STNID_XMAC1RFR 115
+
+#define MSGRNG_STNID_SEC 120
+#define MSGRNG_STNID_SEC0 120
+#define MSGRNG_STNID_SEC1 121
+#define MSGRNG_STNID_SEC2 122
+#define MSGRNG_STNID_SEC3 123
+#define MSGRNG_STNID_PK0  124
+
+#define MSGRNG_STNID_GMAC1      80
+#define MSGRNG_STNID_GMAC1_FR   81
+#define MSGRNG_STNID_GMAC1_TX0  82
+#define MSGRNG_STNID_GMAC1_TX1  83
+#define MSGRNG_STNID_GMAC1_TX2  84
+#define MSGRNG_STNID_GMAC1_TX3  85
+#define MSGRNG_STNID_GMAC0      96
+#define MSGRNG_STNID_GMAC0_FR   97
+#define MSGRNG_STNID_GMAC0_TX0  98
+#define MSGRNG_STNID_GMAC0_TX1  99
+#define MSGRNG_STNID_GMAC0_TX2  100
+#define MSGRNG_STNID_GMAC0_TX3  101
+#define MSGRNG_STNID_CMP_0      108
+#define MSGRNG_STNID_CMP_1      109
+#define MSGRNG_STNID_CMP_2      110
+#define MSGRNG_STNID_CMP_3      111
+#define MSGRNG_STNID_PCIE_0     116
+#define MSGRNG_STNID_PCIE_1     117
+#define MSGRNG_STNID_PCIE_2     118
+#define MSGRNG_STNID_PCIE_3     119
+#define MSGRNG_STNID_XLS_PK0    121
+
+#define MSGRNG_CODE_DEVICE         0
+#define MSGRNG_CODE_MAC            MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_XGMAC          MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_SPI4           MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_SEC            MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_BOOT_WAKEUP    200
+
+static inline int msgrng_xgmac_stid_rfr(int id)
+{
+  return !id ? MSGRNG_STNID_XMAC0RFR : MSGRNG_STNID_XMAC1RFR;
+}
+
+static inline int msgrng_xgmac_stid_tx(int id)
+{
+  return !id ? MSGRNG_STNID_XMAC0_00_TX : MSGRNG_STNID_XMAC1_00_TX;
+}
+
+static inline int msgrng_gmac_stid_rfr(int id)
+{
+  if (id & 0x4)
+      return (MSGRNG_STNID_GMAC1_FR);
+  return (MSGRNG_STNID_GMACRFR_0);
+}
+
+static inline int msgrng_gmac_stid_rfr_split_mode(int id)
+{
+  return ((id>>1)?MSGRNG_STNID_GMACRFR_1:MSGRNG_STNID_GMACRFR_0);
+}
+
+static inline int msgrng_gmac_stid_tx(int id)
+{
+  if (id & 0x4)
+      return (MSGRNG_STNID_GMAC1_TX0 + (id & 0x3));
+  return (MSGRNG_STNID_GMACTX0 + id);
+}
+
+static inline int msgrng_gmac0_stid_rfr(int id)
+{
+  return (MSGRNG_STNID_GMAC0_FR);
+}
+static inline int msgrng_gmac0_stid_tx(int id)
+{
+  return (MSGRNG_STNID_GMAC0_TX0 + id);
+}
+static inline int msgrng_gmac1_stid_rfr(int id)
+{
+  return (MSGRNG_STNID_GMAC1_FR);
+}
+static inline int msgrng_gmac1_stid_tx(int id)
+{
+  return (MSGRNG_STNID_GMAC1_TX0 + (id & 0x3));
+}
+
+static inline void msgrng_send(unsigned int stid)
+{
+  __asm__ volatile (
+		    ".set push\n"
+		    ".set noreorder\n"
+		    "sync\n"
+		    //		    "msgsnd %0\n"
+		    "move  $8, %0\n"
+		    "c2    0x80001\n"
+		    ".set pop\n"
+		    : : "r" (stid) : "$8"
+		    );
+}
+
+static inline void msgrng_receive(unsigned int pri)
+{
+  __asm__ volatile (
+		    ".set push\n"
+		    ".set noreorder\n"
+		    //		    "msgld %0\n"
+		    "move $8, %0\n"
+		    "c2   0x80002\n"
+		    ".set pop\n"
+		    : : "r" (pri) : "$8"
+		    );
+}
+
+static inline void msgrng_wait(unsigned int mask)
+{
+  __asm__ volatile (
+		    ".set push\n"
+		    ".set noreorder\n"
+		    //		    "msgwait %0\n"
+		    "move $8, %0\n"
+		    /*to ensure msgwait picks up the right bucket */
+		    ""STR(PTR_ADDU)" $8, $8, $0\n"
+		    "c2   0x80003\n"
+		    ".set pop\n"
+		    : :"r" (mask) : "$8"
+		    );
+}
+
+#define msgrng_enable(flags)                \
+do {                                        \
+  preempt_disable(); \
+  __asm__ volatile (                        \
+		    ".set push\n\t"                 \
+		    ".set reorder\n\t"              \
+		    ".set noat\n\t"                 \
+		    "mfc0 %0, $12\n\t"              \
+		    "li  $8, 0x40000001\n\t"        \
+		    "or  $1, %0, $8\n\t"            \
+		    "xori $1, 1\n\t"                \
+		    ".set noreorder\n\t"            \
+		    "mtc0 $1, $12\n\t"              \
+		    ".set\tpop\n\t"                 \
+		    : "=r" (flags)                  \
+		    :                               \
+		    : "$8"                          \
+		    );                              \
+  preempt_enable(); \
+} while (0)
+
+#define msgrng_disable(flags) __asm__ volatile (    \
+                 "mtc0 %0, $12" : : "r" (flags))
+
+#define msgrng_flags_save(flags) msgrng_enable(flags)
+#define msgrng_flags_restore(flags) msgrng_disable(flags)
+
+struct msgrng_msg {
+  __u64 msg0;
+  __u64 msg1;
+  __u64 msg2;
+  __u64 msg3;
+};
+
+static inline void message_send_block_fast(int size, unsigned int code, unsigned int stid,
+                                         unsigned long long msg0, unsigned long long msg1,
+					 unsigned long long msg2, unsigned long long msg3)
+{
+  __asm__ __volatile__ (".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        "dmtc2 %1, "STR(MSGRNG_TX_BUF_REG)", 0\n"
+                        "dmtc2 %2, "STR(MSGRNG_TX_BUF_REG)", 1\n"
+                        "dmtc2 %3, "STR(MSGRNG_TX_BUF_REG)", 2\n"
+                        "dmtc2 %4, "STR(MSGRNG_TX_BUF_REG)", 3\n"
+		        "sync\n"
+                        "move $8, %0\n"
+                        "1: c2 0x80001\n"
+                        "mfc2 $8, "STR(MSGRNG_MSG_STATUS_REG)"\n"
+                        "andi $8, $8, 0x6\n"
+                        "bnez $8, 1b\n"
+                        "move $8, %0\n"
+                        ".set pop\n"
+                        :
+                        : "r"(((size-1)<<16)|(code<<8)|stid), "r" (msg0), "r" (msg1), "r"(msg2), "r"(msg3)
+                        : "$8"
+                        );
+}
+
+#define message_receive_fast(bucket, size, code, stid, msg0, msg1, msg2, msg3)      \
+        ( { unsigned int _status=0, _tmp=0;                     \
+           msgrng_receive(bucket);                              \
+           while ( (_status=msgrng_read_status()) & 0x08) ;     \
+           _tmp = _status & 0x30;                               \
+           if (likely(!_tmp)) {                                 \
+                 (size)=((_status & 0xc0)>>6)+1;                \
+                 (code)=(_status & 0xff00)>>8;                  \
+                 (stid)=(_status & 0x7f0000)>>16;               \
+                 (msg0)=msgrng_load_rx_msg0();                  \
+                 (msg1)=msgrng_load_rx_msg1();                  \
+                 (msg2)=msgrng_load_rx_msg2();                  \
+                 (msg3)=msgrng_load_rx_msg3();                  \
+                 _tmp=0;                                        \
+                }                                               \
+           _tmp;                                                \
+        } )
+
+static __inline__ int message_send(unsigned int size, unsigned int code,
+				   unsigned int stid, struct msgrng_msg *msg)
+{
+  unsigned int dest = 0;
+  unsigned long long status=0;
+  int i=0;
+
+  msgrng_load_tx_msg0(msg->msg0);
+  msgrng_load_tx_msg1(msg->msg1);
+  msgrng_load_tx_msg2(msg->msg2);
+  msgrng_load_tx_msg3(msg->msg3);
+
+  dest = ((size-1)<<16)|(code<<8)|(stid);
+
+  //dbg_msg("Sending msg<%Lx,%Lx,%Lx,%Lx> to dest = %x\n",
+    //msg->msg0, msg->msg1, msg->msg2, msg->msg3, dest);
+
+
+  for(i=0;i<16;i++) {
+  	msgrng_send(dest);
+	status = msgrng_read_status();
+//	dbg_msg("status = %Lx\n", status);
+
+	if (status & 0x6) {
+	  continue;
+	}
+	else break;
+	}
+    if (i==16) {
+	  if (dest == 0x61)
+		  //dbg_msg("Processor %x: Unable to send msg to %llx\n", processor_id(), dest);
+	  return status & 0x6;
+	}
+  return msgrng_read_status() & 0x06;
+}
+
+static __inline__ int message_send_retry(unsigned int size, unsigned int code,
+					 unsigned int stid,
+					 struct msgrng_msg *msg)
+{
+  int res = 0;
+  int retry = 0;
+
+  for(;;) {
+    res = message_send(size, code, stid, msg);
+    /* retry a pending fail */
+    if (res & 0x02) continue;
+    /* credit fail */
+    if (res & 0x04) retry++;
+    else break;
+    if (retry == 4) return res & 0x06;
+  }
+
+  return 0;
+}
+
+static __inline__ int message_receive(int pri, int *size, int *code, int *src_id,
+				      struct msgrng_msg *msg)
+{
+  int res = message_receive_fast(pri, *size, *code, *src_id, msg->msg0, msg->msg1, msg->msg2, msg->msg3);
+
+#ifdef MSGRING_DUMP_MESSAGES
+  if (!res) {
+    dbg_msg("Received msg <%llx, %llx, %llx, %llx> <%d,%d,%d>\n",
+	    msg->msg0, msg->msg1, msg->msg2, msg->msg3,
+	    *size, *code, *src_id);
+  }
+#endif
+
+  return res;
+}
+
+#define MSGRNG_STN_RX_QSIZE 256
+
+typedef unsigned short bucket_t;
+#define MAX_NUM_MSGRNG_STN_CC   128
+#define MAX_NUM_GMAC_STNS 8
+#define MAX_NUM_XGMAC_STNS 18
+#define NR_STNS_PER_CORE 8
+
+struct stn_cc {
+	bucket_t counters[16][8];
+};
+
+struct bucket_size {
+	bucket_t bucket[MAX_NUM_MSGRNG_STN_CC];
+};
+
+extern struct bucket_size bucket_sizes;
+
+extern struct stn_cc cc_table_cpu_0;
+extern struct stn_cc cc_table_cpu_1;
+extern struct stn_cc cc_table_cpu_2;
+extern struct stn_cc cc_table_cpu_3;
+extern struct stn_cc cc_table_cpu_4;
+extern struct stn_cc cc_table_cpu_5;
+extern struct stn_cc cc_table_cpu_6;
+extern struct stn_cc cc_table_cpu_7;
+extern struct stn_cc cc_table_xgs_0;
+extern struct stn_cc cc_table_xgs_1;
+extern struct stn_cc cc_table_gmac;
+extern struct stn_cc cc_table_dma;
+extern struct stn_cc cc_table_sec;
+
+extern struct bucket_size xls_bucket_sizes;
+extern struct stn_cc xls_cc_table_cpu_0;
+extern struct stn_cc xls_cc_table_cpu_1;
+extern struct stn_cc xls_cc_table_cpu_2;
+extern struct stn_cc xls_cc_table_cpu_3;
+extern struct stn_cc xls_cc_table_gmac0;
+extern struct stn_cc xls_cc_table_gmac1;
+extern struct stn_cc xls_cc_table_cmp;
+extern struct stn_cc xls_cc_table_pcie;
+extern struct stn_cc xls_cc_table_dma;
+extern struct stn_cc xls_cc_table_sec;
+
+extern struct bucket_size shared_bucket_sizes;
+
+extern struct stn_cc shared_cc_table_cpu_0;
+extern struct stn_cc shared_cc_table_cpu_1;
+extern struct stn_cc shared_cc_table_cpu_2;
+extern struct stn_cc shared_cc_table_cpu_3;
+extern struct stn_cc shared_cc_table_cpu_4;
+extern struct stn_cc shared_cc_table_cpu_5;
+extern struct stn_cc shared_cc_table_cpu_6;
+extern struct stn_cc shared_cc_table_cpu_7;
+extern struct stn_cc shared_cc_table_gmac;
+extern struct stn_cc shared_cc_table_dma;
+
+
+#define msgrng_access_save(lock, iflags, mflags) do {        \
+  spin_lock_irqsave(lock, iflags);                           \
+  msgrng_flags_save(mflags);                                 \
+ }while(0)
+
+#define msgrng_access_restore(lock, iflags, mflags) do {     \
+  msgrng_flags_restore(mflags);                              \
+  spin_unlock_irqrestore(lock, iflags);                      \
+ }while(0)
+
+#define msgrng_access_enable(mflags) do {   \
+  preempt_disable();                        \
+  msgrng_flags_save(mflags);                \
+} while(0)
+
+#define msgrng_access_disable(mflags) do {   \
+  msgrng_flags_restore(mflags);              \
+  preempt_enable();                          \
+} while(0)
+
+enum {
+  TX_STN_CPU_0,
+  TX_STN_CPU_1,
+  TX_STN_CPU_2,
+  TX_STN_CPU_3,
+  TX_STN_CPU_4,
+  TX_STN_CPU_5,
+  TX_STN_CPU_6,
+  TX_STN_CPU_7,
+  TX_STN_GMAC,
+  TX_STN_DMA,
+  TX_STN_XGS_0,
+  TX_STN_XGS_1,
+  TX_STN_SEC,
+  TX_STN_GMAC0,
+  TX_STN_GMAC1,
+  TX_STN_CMP,
+  TX_STN_PCIE,
+  TX_STN_INVALID,
+  MAX_TX_STNS
+};
+
+extern int register_msgring_handler(int major,
+				    void (*action)(int, int,int,int,struct msgrng_msg *, void *),
+				    void *dev_ctx);
+
+
+extern void nlm_common_msgring_cpu_init(void);
+
+extern void nlm_common_msgring_config(void);
+
+#define cpu_to_msgring_bucket(cpu) ((((cpu) >> 2)<<3)|((cpu) & 0x03))
+
+
+/* PR: We need to make the following entrities visible across the kernel */
+#define CPU_BASE_BUCKET(x)   (((x)>>2)<<3)
+
+#define THR_LO_BUCKETID (netlogic_thr_id() & 3)
+#define THR_HI_BUCKETID (THR_LO_BUCKETID + 4)
+
+#define THIS_THR_LO_BUCKET cpu_to_msgring_bucket(hard_smp_processor_id())
+#define THIS_THR_HI_BUCKET (THIS_THR_LO_BUCKET)
+
+#define THR_LO_BKT_STATUS_MASK (1U << THR_LO_BUCKETID)
+#define THR_HI_BKT_STATUS_MASK (1U << THR_HI_BUCKETID)
+
+struct msgrng_msg;
+
+struct tx_stn_handler {
+	void (*action)(int, int, int, int, struct msgrng_msg *, void *);
+	void *dev_id;
+};
+
+struct tx_stn {
+	struct tx_stn_handler handler;
+};
+
+extern struct tx_stn tx_stns[];
+extern int rxstn_to_txstn_map[];
+extern int xls_rxstn_to_txstn_map[];
+
+extern int rmik_queue_pkt_mem(uint32_t fbstid, uint64_t physaddr);
+extern void rmik_init_replenish_work(int);
+extern void nlm_nlm_common_drop_message_unowned(int fbid, uint64_t physaddr, int cop_en);
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/msidef.h b/arch/mips/include/asm/netlogic/msidef.h
new file mode 100644
index 0000000..df92e36
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/msidef.h
@@ -0,0 +1,73 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef ASM_NLM_MSIDEF_H
+#define ASM_NLM_MSIDEF_H
+
+/*
+ * Constants for Intel APIC based MSI messages.
+ * Adapted for the RMI XLR using identical defines
+ */
+
+/*
+ * Shifts for MSI data
+ */
+
+#define MSI_DATA_VECTOR_SHIFT		0
+#define  MSI_DATA_VECTOR_MASK		0x000000ff
+#define	 MSI_DATA_VECTOR(v)		(((v) << MSI_DATA_VECTOR_SHIFT) & MSI_DATA_VECTOR_MASK)
+
+#define MSI_DATA_DELIVERY_MODE_SHIFT	8
+#define  MSI_DATA_DELIVERY_FIXED	(0 << MSI_DATA_DELIVERY_MODE_SHIFT)
+#define  MSI_DATA_DELIVERY_LOWPRI	(1 << MSI_DATA_DELIVERY_MODE_SHIFT)
+
+#define MSI_DATA_LEVEL_SHIFT		14
+#define	 MSI_DATA_LEVEL_DEASSERT	(0 << MSI_DATA_LEVEL_SHIFT)
+#define	 MSI_DATA_LEVEL_ASSERT		(1 << MSI_DATA_LEVEL_SHIFT)
+
+#define MSI_DATA_TRIGGER_SHIFT		15
+#define  MSI_DATA_TRIGGER_EDGE		(0 << MSI_DATA_TRIGGER_SHIFT)
+#define  MSI_DATA_TRIGGER_LEVEL		(1 << MSI_DATA_TRIGGER_SHIFT)
+
+/*
+ * Shift/mask fields for msi address
+ */
+
+#define MSI_ADDR_BASE_HI		0
+#define MSI_ADDR_BASE_LO		0xfee00000
+
+#define MSI_ADDR_DEST_MODE_SHIFT	2
+#define  MSI_ADDR_DEST_MODE_PHYSICAL	(0 << MSI_ADDR_DEST_MODE_SHIFT)
+#define	 MSI_ADDR_DEST_MODE_LOGICAL	(1 << MSI_ADDR_DEST_MODE_SHIFT)
+
+#define MSI_ADDR_REDIRECTION_SHIFT	3
+#define  MSI_ADDR_REDIRECTION_CPU	(0 << MSI_ADDR_REDIRECTION_SHIFT) /* dedicated cpu */
+#define  MSI_ADDR_REDIRECTION_LOWPRI	(1 << MSI_ADDR_REDIRECTION_SHIFT) /* lowest priority */
+
+#define MSI_ADDR_DEST_ID_SHIFT		12
+#define	 MSI_ADDR_DEST_ID_MASK		0x00ffff0
+#define  MSI_ADDR_DEST_ID(dest)		(((dest) << MSI_ADDR_DEST_ID_SHIFT) & MSI_ADDR_DEST_ID_MASK)
+
+#endif /* ASM_NLM_MSIDEF_H */
diff --git a/arch/mips/include/asm/netlogic/nlm_rw_lock.h b/arch/mips/include/asm/netlogic/nlm_rw_lock.h
new file mode 100644
index 0000000..c331bf2
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/nlm_rw_lock.h
@@ -0,0 +1,216 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+#ifndef __NLM_RW_LOCK_H_
+#define __NLM_RW_LOCK_H_
+
+#define NLM_MAX_CPUS 32
+typedef struct {
+	volatile unsigned int lock;
+	unsigned int read_cpus[NLM_MAX_CPUS]; /* cpus that hold rd lock */
+	int write_cpu; /* CPU that is currently holding wr lock */
+} nlm_rwlock_t;
+
+#define nlm_sync() __asm__ __volatile__("sync": : :"memory")
+__asm__ (
+		".macro\tnlm_local_irq_save result\n\t"
+		".set\tpush\n\t"
+		".set\treorder\n\t"
+		".set\tnoat\n\t"
+		"mfc0\t\\result, $12\n\t"
+		"ori\t$1, \\result, 1\n\t"
+		"xori\t$1, 1\n\t"
+		".set\tnoreorder\n\t"
+		"mtc0\t$1, $12\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		".set\tpop\n\t"
+		".endm");
+
+__asm__(".macro\tnlm_local_irq_restore flags\n\t"
+		".set\tnoreorder\n\t"
+		".set\tnoat\n\t"
+		"mfc0\t$1, $12\n\t"
+		"andi\t\\flags, 1\n\t"
+		"ori\t$1, 1\n\t"
+		"xori\t$1, 1\n\t"
+		"or\t\\flags, $1\n\t"
+		"mtc0\t\\flags, $12\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		".set\tat\n\t"
+		".set\treorder\n\t"
+		".endm");
+
+
+#define nlm_local_irq_save(x)		\
+	__asm__ __volatile__(           \
+		"nlm_local_irq_save\t%0"                                    \
+		: "=r" (x)		\
+		: /* no inputs */	\
+		: "memory")
+
+
+#define nlm_local_irq_restore(flags)		\
+	do {                           		\
+		unsigned long __tmp1;  		\
+		__asm__ __volatile__(  		\
+		"nlm_local_irq_restore\t%0"        	\
+		: "=r" (__tmp1)                 \
+		: "0" (flags)                   \
+		: "memory");                    \
+	} while(0)
+
+
+#define nlm_processor_id() 				\
+	({ int __res;                                   \
+	 __asm__ __volatile__(                          \
+		 ".set\tmips32\n\t"                     \
+		 "mfc0\t%0, $15, 1\n\t"           	\
+		 "andi\t%0, 0x1f\n\t"			\
+		 ".set\tmips0\n\t"                      \
+		 : "=r" (__res));                       \
+	 __res;                                         \
+	 })
+
+
+static inline unsigned int nlm_read_lock_irq_save(nlm_rwlock_t *rw)
+{
+	unsigned int temp;
+	unsigned int cpu;
+	unsigned int flags;
+
+	nlm_local_irq_save(flags);
+	cpu = nlm_processor_id();
+
+		__asm__ __volatile__(
+		"	.set	noreorder	\n"
+		"1:	ll	%1, %2		\n"
+		"	bltz	%1, 2f		\n"
+		"	 addu	%1, 1		\n"
+		"	sc	%1, %0		\n"
+		"	beqz	%1, 1b		\n"
+		"	 nop			\n"
+		"	.subsection 2		\n"
+		"2:	ll	%1, %2		\n"
+		"	bltz	%1, 2b		\n"
+		"	 addu	%1, 1		\n"
+		"	b	1b		\n"
+		"	 nop			\n"
+		"	.previous		\n"
+		"	.set	reorder		\n"
+		: "=m" (rw->lock), "=&r" (temp)
+		: "m" (rw->lock)
+		: "memory");
+
+		rw->read_cpus[cpu] = 1;
+		nlm_sync();
+
+		return flags;
+}
+
+static inline void nlm_read_unlock_irq_restore(nlm_rwlock_t *rw, 
+			unsigned int flags)
+{
+	unsigned int temp;
+	unsigned int cpu;
+
+	cpu = nlm_processor_id();
+
+	nlm_sync();
+	__asm__ __volatile__(
+		"       .set    noreorder       			\n"
+		"1:     ll      %1, %2                                  \n"
+		"       sub     %1, 1                                   \n"
+		"       sc      %1, %0                                  \n"
+		"       beqz    %1, 2f                                  \n"
+		"        nop                                            \n"
+		"       .subsection 2                                   \n"
+		"2:     b       1b                                      \n"
+		"        nop                                            \n"
+		"       .previous                                       \n"
+		"       .set    reorder                                 \n"
+		: "=m" (rw->lock), "=&r" (temp)
+		: "m" (rw->lock)
+		: "memory");
+	rw->read_cpus[cpu] = 0;
+	nlm_local_irq_restore(flags);
+
+}
+
+static inline unsigned int nlm_write_lock_irq_save(nlm_rwlock_t *rw)
+{
+	unsigned int temp;
+	unsigned int cpu;
+	unsigned int flags;
+
+	nlm_local_irq_save(flags);
+	cpu = nlm_processor_id();
+
+	__asm__ __volatile__(
+		"       .set    noreorder       			\n"
+		"1:     ll      %1, %2                                  \n"
+		"       bnez    %1, 2f                                  \n"
+		"        lui    %1, 0x8000                              \n"
+		"       sc      %1, %0                                  \n"
+		"       beqz    %1, 2f                                  \n"
+		"        nop                                            \n"
+		"       .subsection 2                                   \n"
+		"2:     ll      %1, %2                                  \n"
+		"       bnez    %1, 2b                                  \n"
+		"        lui    %1, 0x8000                              \n"
+		"       b       1b                                      \n"
+		"        nop                                            \n"
+		"       .previous                                       \n"
+		"       .set    reorder                                 \n"
+		: "=m" (rw->lock), "=&r" (temp)
+		: "m" (rw->lock)
+		: "memory");
+
+	rw->write_cpu = cpu;
+	nlm_sync();
+	
+	return flags;
+
+}
+
+
+static inline void nlm_write_unlock_irq_restore(nlm_rwlock_t *rw, 
+						unsigned int flags)
+{
+	nlm_sync();
+
+	__asm__ __volatile__(
+		"       sw      $0, %0                                  \n"
+		: "=m" (rw->lock)
+		: "m" (rw->lock)
+		: "memory");
+	rw->write_cpu = -1;
+	nlm_local_irq_restore(flags);
+}
+
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/pic.h b/arch/mips/include/asm/netlogic/pic.h
new file mode 100644
index 0000000..177ec80
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/pic.h
@@ -0,0 +1,62 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_NLM_PIC_H
+#define _ASM_NLM_PIC_H
+
+#include <asm/netlogic/iomap.h>
+
+#ifndef __ASSEMBLY__
+struct pt_regs;
+extern void nlm_common_ipi_handler(int irq, struct pt_regs *regs);
+extern void nlm_common_msgring_int_handler(unsigned int irq, struct pt_regs *regs);
+
+struct pic_tmask { 
+	unsigned int mask; 
+	int set; 
+	int valid;
+};
+
+#endif
+
+#if defined(CONFIG_NLM_XLP)
+
+// can't do floating in the kernel, so use 64 as an approximation 
+#define PIC_CLKS_PER_SEC 133333333ULL
+#define PIC_CLKS_PER_USEC 133	//(PIC_CLKS_PER_SEC / 1000000)
+#define PIC_CLKS_PER_TIMER_TICK (PIC_CLKS_PER_SEC / HZ)
+
+#else
+// can't do floating in the kernel, so use 64 as an approximation 
+#define PIC_CLKS_PER_SEC 66666666ULL
+#define PIC_CLKS_PER_USEC 66	//(PIC_CLKS_PER_SEC / 1000000)
+#define PIC_CLKS_PER_TIMER_TICK (PIC_CLKS_PER_SEC / HZ)
+
+#include <asm/netlogic/xlr_pic.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+#endif /* CONFIG_NLM_XLP */
+
+#endif /* #ifndef _ASM_NLM_PIC_H */
+	
diff --git a/arch/mips/include/asm/netlogic/proc.h b/arch/mips/include/asm/netlogic/proc.h
new file mode 100644
index 0000000..da729e3
--- /dev/null
+++ b/arch/mips/include/asm/netlogic/proc.h
@@ -0,0 +1,46 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#ifndef _ASM_NLM_PROC_H
+#define _ASM_NLM_PROC_H
+
+#include <linux/types.h>
+
+static __inline__ int proc_pos_check(off_t * begin, int *len, off_t off,
+				     int count)
+{
+	off_t pos = *begin + *len;
+
+	if (pos < off) {
+		*len = 0;
+		*begin = pos;
+	}
+	if (pos > off + count)
+		return 0;
+
+	return 1;
+}
+
+#endif
diff --git a/arch/mips/include/asm/netlogic/xlp-hal/iomap.h b/arch/mips/include/asm/netlogic/xlp-hal/iomap.h
index 86cc339..7842468 100644
--- a/arch/mips/include/asm/netlogic/xlp-hal/iomap.h
+++ b/arch/mips/include/asm/netlogic/xlp-hal/iomap.h
@@ -40,7 +40,7 @@
 #define	XLP_IO_CLK			133333333
 
 #define XLP_PCIE_CFG_SIZE		0x1000		/* 4K */
-#define XLP_PCIE_DEV_BLK_SIZE		(8 * XLP_PCIE_CFG_SIZE)
+//#define XLP_PCIE_DEV_BLK_SIZE		(8 * XLP_PCIE_CFG_SIZE)
 #define XLP_PCIE_BUS_BLK_SIZE		(256 * XLP_PCIE_DEV_BLK_SIZE)
 #define XLP_IO_SIZE			(64 << 20)	/* ECFG space size */
 #define XLP_IO_PCI_HDRSZ		0x100
diff --git a/arch/mips/include/asm/smp.h b/arch/mips/include/asm/smp.h
index e33ea07..ed318ce 100644
--- a/arch/mips/include/asm/smp.h
+++ b/arch/mips/include/asm/smp.h
@@ -1,14 +1,10 @@
-/************************************************************************
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
 
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI:
-
- *****************************#RMI_1#************************************/
+*****************************#NETL_1#********************************/
 
 /*
  * This file is subject to the terms and conditions of the GNU General
@@ -25,7 +21,7 @@
 
 #include <linux/bitops.h>
 #include <linux/linkage.h>
-#ifndef CONFIG_RMI_PHOENIX
+#ifndef CONFIG_NLM_COMMON
 #include <linux/smp.h>
 #endif
 #include <linux/threads.h>
diff --git a/arch/mips/include/asm/stackframe.h b/arch/mips/include/asm/stackframe.h
index cb41af5..8b1940a 100644
--- a/arch/mips/include/asm/stackframe.h
+++ b/arch/mips/include/asm/stackframe.h
@@ -368,7 +368,7 @@
 		ori	a0, STATMASK
 		xori	a0, STATMASK
 		mtc0	a0, CP0_STATUS
-		li	v1, 0xff00
+		li	v1, 0x4000ff00
 		and	a0, v1
 		LONG_L	v0, PT_STATUS(sp)
 		nor	v1, $0, v1
diff --git a/arch/mips/include/asm/timex.h b/arch/mips/include/asm/timex.h
index d74d6fa..f155232 100644
--- a/arch/mips/include/asm/timex.h
+++ b/arch/mips/include/asm/timex.h
@@ -135,10 +135,10 @@ static inline int unsynchronized_tsc(void)
 	return !tsc_is_sync();
 }
 
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 #define ARCH_HAS_READ_CURRENT_TIMER	1
 extern int read_current_timer(unsigned long *timer_val);
-#endif /* CONFIG_RMI_PHOENIX */
+#endif /* CONFIG_NLM_COMMON */
 
 #endif /* __KERNEL__ */
 
diff --git a/arch/mips/kernel/Makefile b/arch/mips/kernel/Makefile
index 64b02c2..3276288 100644
--- a/arch/mips/kernel/Makefile
+++ b/arch/mips/kernel/Makefile
@@ -1,6 +1,7 @@
 #
 # Makefile for the Linux/MIPS kernel.
 #
+EXTRA_AFLAGS := $(AFLAGS) -DNLM_HAL_LINUX_KERNEL 
 
 extra-y		:= head.o vmlinux.lds
 
diff --git a/arch/mips/kernel/asm-offsets.c b/arch/mips/kernel/asm-offsets.c
index ec7c21e..0ddb129 100644
--- a/arch/mips/kernel/asm-offsets.c
+++ b/arch/mips/kernel/asm-offsets.c
@@ -73,12 +73,12 @@ void output_ptreg_defines(void)
 	OFFSET(PT_MTP, pt_regs, mtp);
 #endif /* CONFIG_CPU_CAVIUM_OCTEON */
 
-#ifdef XLP_MERGE_TODO /*CONFIG_RMI_XLP_SIM*/
+#ifdef XLP_MERGE_TODO /*CONFIG_NLM_XLP_SIM*/
 	OFFSET("#define PT_CRC_POLY_0 ", pt_regs, crc_poly_0);
 	OFFSET("#define PT_CRC_POLY_1 ", pt_regs, crc_poly_1);
 	OFFSET("#define PT_CRC_POLY_2 ", pt_regs, crc_poly_2);
 	OFFSET("#define PT_CRC_POLY_3 ", pt_regs, crc_poly_3);
-#endif /* CONFIG_RMI_XLP_SIM */
+#endif /* CONFIG_NLM_XLP_SIM */
 
 	DEFINE(PT_SIZE, sizeof(struct pt_regs));
 	BLANK();
@@ -342,6 +342,16 @@ void output_octeon_cop2_state_defines(void)
 }
 #endif
 
+#ifdef CONFIG_NLM_COMMON
+#include <asm/netlogic/sim.h>
+void output_psb_info_defines(void)
+{
+        COMMENT("RMI struct psb_info structure offsets");
+        OFFSET(PSB_CPU_FREQUENCY, psb_info, cpu_frequency);
+	BLANK();
+}
+#endif /* CONFIG_NLM_COMMON */
+
 #ifdef CONFIG_HIBERNATION
 void output_pbe_defines(void)
 {
diff --git a/arch/mips/kernel/cevt-r4k.c b/arch/mips/kernel/cevt-r4k.c
index 51095dd9..b7698ac 100644
--- a/arch/mips/kernel/cevt-r4k.c
+++ b/arch/mips/kernel/cevt-r4k.c
@@ -164,6 +164,7 @@ int c0_compare_int_usable(void)
 
 int __cpuinit r4k_clockevent_init(void)
 {
+	uint64_t mips_freq = mips_hpt_frequency;
 	unsigned int cpu = smp_processor_id();
 	struct clock_event_device *cd;
 	unsigned int irq;
diff --git a/arch/mips/kernel/genex.S b/arch/mips/kernel/genex.S
index 31fa856..e0327f8 100644
--- a/arch/mips/kernel/genex.S
+++ b/arch/mips/kernel/genex.S
@@ -415,6 +415,13 @@ NESTED(nmi_handler, PT_SIZE, sp)
 	KMODE
 	.endm
 
+#ifdef CONFIG_NLM_XLP
+	.macro	__build_clear_rixi
+	MFC0	t0, CP0_BADVADDR
+	PTR_S	t0, PT_BVADDR(sp)
+	STI
+	.endm
+#endif
 	.macro	__BUILD_silent exception
 	.endm
 
@@ -462,12 +469,19 @@ NESTED(nmi_handler, PT_SIZE, sp)
 	BUILD_HANDLER ades ade ade silent		/* #5  */
 	BUILD_HANDLER ibe be cli silent			/* #6  */
 	BUILD_HANDLER dbe be cli silent			/* #7  */
+#if defined(CONFIG_NLM_XLP) && defined (CONFIG_KGDB)
+	BUILD_HANDLER bp bp cli silent			/* #9  */
+#else
 	BUILD_HANDLER bp bp sti silent			/* #9  */
+#endif
 	BUILD_HANDLER ri ri sti silent			/* #10 */
 	BUILD_HANDLER cpu cpu sti silent		/* #11 */
 	BUILD_HANDLER ov ov sti silent			/* #12 */
 	BUILD_HANDLER tr tr sti silent			/* #13 */
 	BUILD_HANDLER fpe fpe fpe silent		/* #15 */
+#ifdef CONFIG_NLM_XLP
+	BUILD_HANDLER rixi rixi rixi silent		/* #16 */
+#endif
 	BUILD_HANDLER mdmx mdmx sti silent		/* #22 */
 #ifdef	CONFIG_HARDWARE_WATCHPOINTS
 	/*
diff --git a/arch/mips/kernel/head.S b/arch/mips/kernel/head.S
index 9916ef2..bdbcfe2 100644
--- a/arch/mips/kernel/head.S
+++ b/arch/mips/kernel/head.S
@@ -26,7 +26,7 @@
 #include <asm/mipsregs.h>
 #include <asm/stackframe.h>
 
-#include <asm/mach-rmi/kernel-entry-init.h>
+#include <asm/mach-netlogic/kernel-entry-init.h>
 #include <asm/mach-generic/kernel-entry-init.h>
 
 	/*
diff --git a/arch/mips/kernel/kgdb.c b/arch/mips/kernel/kgdb.c
index f800d32..df6f0a6 100644
--- a/arch/mips/kernel/kgdb.c
+++ b/arch/mips/kernel/kgdb.c
@@ -234,11 +234,11 @@ static void kgdb_call_nmi_hook(void *ignored)
 	kgdb_nmicallback(raw_smp_processor_id(), NULL);
 }
 
-#ifdef CONFIG_RMI_PHOENIX
-#include <asm/rmi/interrupt.h>
-spinlock_t rmi_kgdb_lock = SPIN_LOCK_UNLOCKED;
+#ifdef CONFIG_NLM_COMMON
+#include <asm/netlogic/interrupt.h>
+DEFINE_SPINLOCK(nlm_kgdb_lock);
 
-void rmi_kgdb_smp_hook(void)
+void nlm_kgdb_smp_hook(void)
 {
 	int i;
 	int cpu = smp_processor_id();
@@ -250,14 +250,14 @@ void rmi_kgdb_smp_hook(void)
 	if (!cpus)
 		return;
 
-	spin_lock_irqsave(&rmi_kgdb_lock, flags);
+	spin_lock_irqsave(&nlm_kgdb_lock, flags);
 	for (i = 0; i < NR_CPUS; i++)
-		if (cpu_online(i) && i != cpu)
-			core_send_ipi(i, SMP_CALL_KGDB_HOOK);
-	spin_unlock_irqrestore(&rmi_kgdb_lock, flags);
+//		if (cpu_online(i) && i != cpu)
+			//core_send_ipi(i, SMP_CALL_KGDB_HOOK);
+	spin_unlock_irqrestore(&nlm_kgdb_lock, flags);
 }
 
-void rmi_kgdb_call_nmi_hook(void)
+void nlm_kgdb_call_nmi_hook(void)
 {
 	kgdb_nmicallback(raw_smp_processor_id(), NULL);
 }
@@ -265,8 +265,8 @@ void rmi_kgdb_call_nmi_hook(void)
 
 void kgdb_roundup_cpus(unsigned long flags)
 {
-#ifdef CONFIG_RMI_PHOENIX
-	rmi_kgdb_smp_hook();
+#ifdef CONFIG_NLM_COMMON
+	nlm_kgdb_smp_hook();
 	return;
 #else
 	local_irq_enable();
@@ -329,16 +329,16 @@ void kgdb_arch_set_pc(struct pt_regs *regs, unsigned long pc)
 	regs->cp0_epc = pc;
 }
 
-extern void phoenix_flush_l1_icache_ipi(void *);
-extern void phoenix_flush_l1_caches_ipi(void *);
+extern void nlm_common_flush_l1_icache_ipi(void *);
+extern void nlm_common_flush_l1_caches_ipi(void *);
 
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 irqreturn_t xlr_kgdb_ipi_handler(int irq, struct pt_regs *regs)
 {
 	//int cpu = smp_processor_id();
 	kgdb_call_nmi_hook(NULL);
 
-	phoenix_flush_l1_caches_ipi(NULL);
+	nlm_common_flush_l1_caches_ipi(NULL);
 #if 0
 	if(g_xlr_kgdb[cpu]) {
 		g_xlr_kgdb[cpu] = 0;
@@ -444,8 +444,8 @@ static int kgdb_mips_notify(struct notifier_block *self, unsigned long cmd,
 			regs->cp0_epc += 4;
 
 	/* In SMP mode, __flush_cache_all does IPI */
-#ifdef CONFIG_RMI_PHOENIX
-	phoenix_flush_l1_icache_ipi(NULL);
+#ifdef CONFIG_NLM_COMMON
+	nlm_common_flush_l1_icache_ipi(NULL);
 #else
 	local_irq_enable();
 	__flush_cache_all();
diff --git a/arch/mips/kernel/proc.c b/arch/mips/kernel/proc.c
index 5d2a69c..e8890b4 100644
--- a/arch/mips/kernel/proc.c
+++ b/arch/mips/kernel/proc.c
@@ -14,6 +14,10 @@
 #include <asm/mipsregs.h>
 #include <asm/processor.h>
 #include <asm/prom.h>
+#ifdef CONFIG_NLM_XLP
+#include <asm/netlogic/hal/nlm_hal.h>
+#include <asm/netlogic/xlp8xx/cpu_control_macros.h>
+#endif
 
 unsigned int vced_count, vcei_count;
 
@@ -23,7 +27,9 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 	unsigned int version = cpu_data[n].processor_id;
 	unsigned int fp_vers = cpu_data[n].fpu_id;
 	char fmt [64];
-	int cpu,i;
+	int cpu __maybe_unused, i;
+	uint64_t freq;
+	const uint64_t mhz = 1000000;
 
 #ifdef CONFIG_SMP
 	if (!cpu_online(n))
@@ -40,7 +46,25 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 				   mips_get_machine_name());
 	}
 
+#ifdef CONFIG_NLM_XLP
+	seq_printf(m, "processor\t\t: %ld\n", n);
+	/* x86 has physical id in /proc, does not hurt to include this */
+	seq_printf(m, "physical id\t\t: %ld\n", (long int)cpu_logical_map(n));
+#else
 	seq_printf(m, "processor\t\t: %ld\n", n);
+#endif
+#ifdef CONFIG_NLM_XLP
+	/* workaround for compiler warning */
+	version = fp_vers = 0;
+
+        freq = nlm_hal_cpu_freq();
+        do_div(freq, mhz);
+	cpu = get_cpu();
+	seq_printf(m, "cpu model\t\t: %s %s @%lld MHz\n", __cpu_name[n],
+		   (cpu_data[n].options & MIPS_CPU_FPU ? "  FPU " : ""),
+		    freq);
+	put_cpu();
+#else
 	sprintf(fmt, "cpu model\t\t: %%s V%%d.%%d%s\n",
 		      cpu_data[n].options & MIPS_CPU_FPU ? "  FPU V%d.%d" : "");
 	cpu = get_cpu();
@@ -48,6 +72,7 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 		      (version >> 4) & 0x0f, version & 0x0f,
 		      (fp_vers >> 4) & 0x0f, fp_vers & 0x0f);
 	put_cpu();
+#endif
 	seq_printf(m, "BogoMIPS\t\t: %u.%02u\n",
 		      cpu_data[n].udelay_val / (500000/HZ),
 		      (cpu_data[n].udelay_val / (5000/HZ)) % 100);
diff --git a/arch/mips/kernel/ptrace.c b/arch/mips/kernel/ptrace.c
index c24f6ef..53b944b 100644
--- a/arch/mips/kernel/ptrace.c
+++ b/arch/mips/kernel/ptrace.c
@@ -1,14 +1,10 @@
-/************************************************************************
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
 
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI:
-
- *****************************#RMI_1#************************************/
+*****************************#NETL_1#********************************/
 
 /*
  * This file is subject to the terms and conditions of the GNU General Public
@@ -278,9 +274,9 @@ long arch_ptrace(struct task_struct *child, long request,
 	switch (request) {
 	/* when I and D space are separate, these will need to be fixed. */
 	case PTRACE_PEEKTEXT: /* read word at location addr. */
-#ifdef CONFIG_RMI_PHOENIX
-            __flush_cache_all();
-            /* Fall through */
+#ifdef CONFIG_NLM_COMMON
+		__flush_cache_all();
+		/* Fall through */
 #endif
 
 	case PTRACE_PEEKDATA:
@@ -413,9 +409,9 @@ long arch_ptrace(struct task_struct *child, long request,
 
 	/* when I and D space are separate, this will have to be fixed. */
 	case PTRACE_POKETEXT: /* write the word at location addr. */
-#ifdef CONFIG_RMI_PHOENIX
-        __flush_cache_all();
-        /* Fall through */
+#ifdef CONFIG_NLM_COMMON
+		__flush_cache_all();
+		/* Fall through */
 #endif
 	case PTRACE_POKEDATA:
 		ret = generic_ptrace_pokedata(child, addr, data);
diff --git a/arch/mips/kernel/r4k_switch.S b/arch/mips/kernel/r4k_switch.S
index f52376b..75abfe8 100644
--- a/arch/mips/kernel/r4k_switch.S
+++ b/arch/mips/kernel/r4k_switch.S
@@ -97,7 +97,7 @@
 	move	ra,t1
 #endif /* CONFIG_MIPS_MT_SMTC */
 	mfc0	t1, CP0_STATUS		/* Do we really need this? */
-	li	a3, 0xff01
+	li	a3, 0x4000ff01
 	and	t1, a3
 	LONG_L	a2, THREAD_STATUS(a1)
 	nor	a3, $0, a3
diff --git a/arch/mips/kernel/setup.c b/arch/mips/kernel/setup.c
index 6623401..9271dbd 100644
--- a/arch/mips/kernel/setup.c
+++ b/arch/mips/kernel/setup.c
@@ -1,14 +1,10 @@
-/************************************************************************
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
 
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI: 
-
-  *****************************#RMI_1#************************************/
+*****************************#NETL_1#********************************/
 
 /*
  * This file is subject to the terms and conditions of the GNU General Public
@@ -45,9 +41,9 @@
 #include <asm/smp-ops.h>
 #include <asm/prom.h>
 
-#include <asm/rmi/sim.h>
-#include <asm/rmi/debug.h>
-#include <asm/mach-rmi/mmu.h>
+#include <asm/netlogic/sim.h>
+#include <asm/netlogic/debug.h>
+#include <asm/mach-netlogic/mmu.h>
 
 struct cpuinfo_mips cpu_data[NR_CPUS] __read_mostly;
 
@@ -57,10 +53,10 @@ EXPORT_SYMBOL(cpu_data);
 struct screen_info screen_info;
 #endif
 
-#ifdef CONFIG_RMI_VMIPS
-extern unsigned long long rmi_vmips_highmem_start;
+#ifdef CONFIG_NLM_VMIPS
+extern unsigned long long nlm_vmips_highmem_start;
 #undef  HIGHMEM_START
-#define        HIGHMEM_START   (rmi_vmips_highmem_start)
+#define        HIGHMEM_START   (nlm_vmips_highmem_start)
 #endif
 
 
@@ -130,17 +126,6 @@ void __init add_memory_region(uint64_t start, uint64_t size, long type)
 	boot_mem_map.nr_map++;
 }
 
-#ifdef CONFIG_RMI_PHOENIX
-int avail_mem_above_4G;
-int force_usb __initdata = 0;
-static int __init xls_force_usb(char *p)
-{
-    force_usb = 1;
-	return 0;
-}
-early_param("forceusb", xls_force_usb);
-#endif
-
 static void __init print_memory_map(void)
 {
 	int i;
@@ -172,43 +157,6 @@ static void __init print_memory_map(void)
 	}
 }
 
-#if defined(CONFIG_RMI_PHOENIX)
-/* This routine is useful when USB is desired on
- * 64-Bit Linux with DRAM mapped >4G. On such systems,
- * since the XLS USB controller is 32-bit, USB is
- * disabled. Use command line option 'forceusb' to
- * enable it; This adjusts the mapped available mem 
- * to a max of till 0xFFFFFFFF.
- */
-static void __init tweak_avail_dram_map(void) {
-
-    int j=0;
-    int nrmap_ctr = (boot_mem_map.nr_map - 1);
-
-    avail_mem_above_4G = 0;
-
-    for (j=nrmap_ctr; j>=0; j--) {
-        if ((boot_mem_map.map[j].addr + boot_mem_map.map[j].size) 
-                > 0x100000000ULL) {
-            avail_mem_above_4G++;
-#ifdef CONFIG_64BIT
-            if (force_usb) {
-                printk(KERN_WARNING "[USB]:Re-adjusting Available DRAM map\n");
-                if (boot_mem_map.map[j].addr > 0x100000000ULL) {
-                    boot_mem_map.nr_map--;
-                }
-                else {
-                    /* Reclaim whatever we can... */
-                    boot_mem_map.map[j].size =
-                        0x100000000ULL - boot_mem_map.map[j].addr;
-                }
-            }
-#endif
-        }
-    }
-}
-#endif
-
 /*
  * Manage initrd
  */
@@ -600,11 +548,8 @@ static void __init arch_mem_init(char **cmdline_p)
 		pr_info("User-defined physical RAM map:\n");
 		print_memory_map();
 	}
-
-#ifdef CONFIG_RMI_PHOENIX
-	tweak_avail_dram_map();
-#endif
     
+	setup_mapped_kernel_tlbs(TRUE, TRUE);	
 	bootmem_init();
 /*
 	setup_mapped_kernel_tlbs(FALSE, TRUE);
diff --git a/arch/mips/kernel/time.c b/arch/mips/kernel/time.c
index 92f2f34..99d73b7 100644
--- a/arch/mips/kernel/time.c
+++ b/arch/mips/kernel/time.c
@@ -70,7 +70,6 @@ EXPORT_SYMBOL(perf_irq);
  */
 
 unsigned int mips_hpt_frequency;
-EXPORT_SYMBOL(mips_hpt_frequency);
 
 /*
  * This function exists in order to cause an error due to a duplicate
diff --git a/arch/mips/kernel/traps.c b/arch/mips/kernel/traps.c
index a75ae40..932db61 100644
--- a/arch/mips/kernel/traps.c
+++ b/arch/mips/kernel/traps.c
@@ -1,3 +1,12 @@
+/*-
+ * Copyright 2005-2013 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -57,6 +66,9 @@
 #include <asm/stacktrace.h>
 #include <asm/uasm.h>
 
+#ifdef CONFIG_NLM_XLP
+#include <asm/mach-netlogic/mmu.h>
+#endif
 extern void check_wait(void);
 extern asmlinkage void rollback_handle_int(void);
 extern asmlinkage void handle_int(void);
@@ -76,6 +88,9 @@ extern asmlinkage void handle_cpu(void);
 extern asmlinkage void handle_ov(void);
 extern asmlinkage void handle_tr(void);
 extern asmlinkage void handle_fpe(void);
+#ifdef CONFIG_NLM_XLP
+extern asmlinkage void handle_rixi(void);
+#endif
 extern asmlinkage void handle_mdmx(void);
 extern asmlinkage void handle_watch(void);
 extern asmlinkage void handle_mt(void);
@@ -90,6 +105,9 @@ void (*board_ejtag_handler_setup)(void);
 void (*board_bind_eic_interrupt)(int irq, int regset);
 void (*board_ebase_setup)(void);
 void __cpuinitdata(*board_cache_error_setup)(void);
+#ifdef CONFIG_NLM_XLP
+extern unsigned long nlm_common_ebase;
+#endif
 
 static void show_raw_backtrace(unsigned long reg29)
 {
@@ -594,6 +612,11 @@ static int simulate_llsc(struct pt_regs *regs, unsigned int opcode)
 	return -1;			/* Must be something else ... */
 }
 
+#ifdef CONFIG_NLM_XLP
+extern void nlm_cpu_stat_update_rdhwr(void);
+extern void nlm_cpu_stat_update_fp(void);
+#endif
+
 /*
  * Simulate trapping 'rdhwr' instructions to provide user accessible
  * registers not implemented in hardware.
@@ -627,6 +650,9 @@ static int simulate_rdhwr(struct pt_regs *regs, int rd, int rt)
 		return 0;
 	case 29:
 		regs->regs[rt] = ti->tp_value;
+#if defined(CONFIG_NLM_XLP)
+		nlm_cpu_stat_update_rdhwr();
+#endif
 		return 0;
 	default:
 		return -1;
@@ -724,6 +750,9 @@ asmlinkage void do_fpe(struct pt_regs *regs, unsigned long fcr31)
 		int sig;
 		void __user *fault_addr = NULL;
 
+#if defined(CONFIG_NLM_XLP)
+		nlm_cpu_stat_update_fp();
+#endif
 		/*
 		 * Unimplemented operation exception.  If we've got the full
 		 * software emulator on-board, let's use it...
@@ -772,6 +801,39 @@ asmlinkage void do_fpe(struct pt_regs *regs, unsigned long fcr31)
 	force_sig_info(SIGFPE, &info, current);
 }
 
+#ifdef CONFIG_NLM_XLP
+asmlinkage void do_rixi(struct pt_regs *regs)
+{
+	struct task_struct *tsk = current;
+	siginfo_t info;
+
+	/*
+	 * TODO: need notify_die() intimation ?
+	 */
+	die_if_kernel("rixi exception in kernel code", regs);
+
+	/*
+	 * TODO: is there a possibility of permissions (RX)
+	 *       changing along with the receipt of a RIXI
+	 *       exception ? If so, we will have to check
+	 *       the vm_flags of the vma correponding to the
+	 *       faulting address
+	 */
+
+	tsk->thread.cp0_badvaddr = regs->cp0_badvaddr;
+	/*
+	 * TODO: need to set appropriate code
+	 * 
+	 * tsk->thread.error_code = ;
+	 */
+
+	info.si_signo = SIGSEGV;
+	info.si_errno = 0;
+	info.si_addr = (void __user *) regs->cp0_epc;
+	force_sig_info(SIGSEGV, &info, tsk);
+}
+#endif
+
 static void do_trap_or_bp(struct pt_regs *regs, unsigned int code,
 	const char *str)
 {
@@ -972,6 +1034,10 @@ asmlinkage void do_ri(struct pt_regs *regs)
 	if (unlikely(status > 0)) {
 		regs->cp0_epc = old_epc;		/* Undo skip-over.  */
 		regs->regs[31] = old31;
+#ifdef CONFIG_NLM_XLP
+		printk("[%s]: killing with SIGILL\"%s\"\n", __FUNCTION__, current->comm);
+		show_regs(regs);
+#endif
 		force_sig(status, current);
 	}
 }
@@ -1485,6 +1551,9 @@ void __init *set_except_vector(int n, void *addr)
 #endif
 		u32 *buf = (u32 *)(ebase + 0x200);
 		unsigned int k0 = 26;
+#ifdef CONFIG_NLM_XLP
+		uasm_i_ehb(&buf);
+#endif /* CONFIG_NLM_XLP */
 		if ((handler & jump_mask) == ((ebase + 0x200) & jump_mask)) {
 			uasm_i_j(&buf, handler & ~jump_mask);
 			uasm_i_nop(&buf);
@@ -1658,6 +1727,9 @@ void __cpuinit per_cpu_trap_init(bool is_boot_cpu)
 	unsigned int cpu = smp_processor_id();
 	unsigned int status_set = ST0_CU0;
 	unsigned int hwrena = cpu_hwrena_impl_bits;
+#if defined(CONFIG_NLM_XLP) && (defined(CONFIG_64BIT)|| defined(CONFIG_RAPIDIO))
+        unsigned int pagegrain;
+#endif
 #ifdef CONFIG_MIPS_MT_SMTC
 	int secondaryTC = 0;
 	int bootTC = (cpu == 0);
@@ -1673,6 +1745,14 @@ void __cpuinit per_cpu_trap_init(bool is_boot_cpu)
 		secondaryTC = 1;
 #endif /* CONFIG_MIPS_MT_SMTC */
 
+#ifdef CONFIG_NLM_XLP
+#ifdef CONFIG_32BIT
+	/* Some firmware leaves the BEV flag set, clear it. */
+	clear_c0_status(ST0_CU1|ST0_CU2|ST0_CU3|ST0_BEV|ST0_KX);
+#else
+	clear_c0_status(ST0_CU1|ST0_CU2|ST0_CU3|ST0_BEV);
+#endif
+#endif
 	/*
 	 * Disable coprocessors and select 32-bit or 64-bit addressing
 	 * and the 16/32 or 32/32 FPR register model.  Reset the BEV
@@ -1681,15 +1761,29 @@ void __cpuinit per_cpu_trap_init(bool is_boot_cpu)
 	 */
 #ifdef CONFIG_64BIT
 	status_set |= ST0_FR|ST0_KX|ST0_SX|ST0_UX;
+#ifdef CONFIG_NLM_XLP
+	status_set |= ST0_CU0;
+#endif
 #endif
 	if (current_cpu_data.isa_level & MIPS_CPU_ISA_IV)
 		status_set |= ST0_XX;
 	if (cpu_has_dsp)
 		status_set |= ST0_MX;
 
+#ifdef CONFIG_NLM_ENABLE_COP2
+	/* Enable Cop2 Access */
+	status_set |= ST0_CU2;
+#endif
+
 	change_c0_status(ST0_CU|ST0_MX|ST0_RE|ST0_FR|ST0_BEV|ST0_TS|ST0_KX|ST0_SX|ST0_UX,
 			 status_set);
 
+#if defined(CONFIG_NLM_XLP) && (defined(CONFIG_64BIT) || defined(CONFIG_RAPIDIO))
+	pagegrain = read_c0_pagegrain();
+	pagegrain |= PG_ELPA;
+	write_c0_pagegrain(pagegrain);
+#endif
+
 	if (cpu_has_mips_r2)
 		hwrena |= 0x0000000f;
 
@@ -1718,6 +1812,11 @@ void __cpuinit per_cpu_trap_init(bool is_boot_cpu)
 		} else
 			set_c0_cause(CAUSEF_IV);
 	}
+#ifdef CONFIG_NLM_XLP
+	else {
+		clear_c0_cause(CAUSEF_IV);
+	}
+#endif
 
 	/*
 	 * Before R2 both interrupt numbers were fixed to 7, so on R2 only:
@@ -1752,9 +1851,15 @@ void __cpuinit per_cpu_trap_init(bool is_boot_cpu)
 #ifdef CONFIG_MIPS_MT_SMTC
 	if (bootTC) {
 #endif /* CONFIG_MIPS_MT_SMTC */
+#ifndef CONFIG_NLM_XLP
 		/* Boot CPU's cache setup in setup_arch(). */
 		if (!is_boot_cpu)
 			cpu_cache_init();
+#endif
+#ifdef CONFIG_NLM_XLP
+		cpu_cache_init();
+		mmu_init();
+#endif
 		tlb_init();
 #ifdef CONFIG_MIPS_MT_SMTC
 	} else if (!secondaryTC) {
@@ -1811,8 +1916,10 @@ __setup("rdhwr_noopt", set_rdhwr_noopt);
 void __init trap_init(void)
 {
 	extern char except_vec3_generic;
-	extern char except_vec4;
+#ifndef CONFIG_NLM_XLP
 	extern char except_vec3_r4000;
+#endif
+	extern char except_vec4;
 	unsigned long i;
 
 	check_wait();
@@ -1839,6 +1946,9 @@ void __init trap_init(void)
 
 	if (board_ebase_setup)
 		board_ebase_setup();
+#ifdef CONFIG_NLM_XLP
+	ebase = nlm_common_ebase;
+#endif
 	per_cpu_trap_init(true);
 
 	/*
@@ -1934,6 +2044,11 @@ void __init trap_init(void)
 	if (cpu_has_fpu && !cpu_has_nofpuex)
 		set_except_vector(15, handle_fpe);
 
+#ifdef CONFIG_NLM_XLP
+	if (kernel_uses_smartmips_rixi)
+		set_except_vector(16, handle_rixi);
+#endif
+
 	set_except_vector(22, handle_mdmx);
 
 	if (cpu_has_mcheck)
@@ -1947,6 +2062,7 @@ void __init trap_init(void)
 	if (board_cache_error_setup)
 		board_cache_error_setup();
 
+#ifndef CONFIG_NLM_XLP
 	if (cpu_has_vce)
 		/* Special exception: R4[04]00 uses also the divec space. */
 		set_handler(0x180, &except_vec3_r4000, 0x100);
@@ -1954,6 +2070,7 @@ void __init trap_init(void)
 		set_handler(0x180, &except_vec3_generic, 0x80);
 	else
 		set_handler(0x080, &except_vec3_generic, 0x80);
+#endif
 
 	local_flush_icache_range(ebase, ebase + 0x400);
 	flush_tlb_handlers();
diff --git a/arch/mips/math-emu/kernel_linkage.c b/arch/mips/math-emu/kernel_linkage.c
index ed460ac..8cf8d88 100644
--- a/arch/mips/math-emu/kernel_linkage.c
+++ b/arch/mips/math-emu/kernel_linkage.c
@@ -1,14 +1,10 @@
-/************************************************************************
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
 
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI: 
-
-  *****************************#RMI_1#************************************/
+*****************************#NETL_1#********************************/
 /*
  *  Kevin D. Kissell, kevink@mips and Carsten Langgaard, carstenl@mips.com
  *  Copyright (C) 2000 MIPS Technologies, Inc.  All rights reserved.
diff --git a/arch/mips/mm/c-phoenix.c b/arch/mips/mm/c-phoenix.c
index 92beed8..b8ed9f8 100644
--- a/arch/mips/mm/c-phoenix.c
+++ b/arch/mips/mm/c-phoenix.c
@@ -1,14 +1,10 @@
-/************************************************************************
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
 
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI: 
-
-  *****************************#RMI_1#************************************/
+*****************************#NETL_1#********************************/
 /*
  * Copyright (C) 1996 David S. Miller (dm@engr.sgi.com)
  * Copyright (C) 1997, 2001 Ralf Baechle (ralf@gnu.org)
@@ -39,14 +35,14 @@
 #include <linux/mm.h>
 #include <linux/module.h>
 
-#include <asm/rmi/debug.h>
+#include <asm/netlogic/debug.h>
 
 static unsigned int icache_linesz;
 static unsigned int icache_lines;
 
-#ifdef CONFIG_RMI_VMIPS
-extern void rmi_vmips_temp_xkphys_tlb_add(phys_t start, phys_t end, int *tlbs, int *tlbe);
-extern void rmi_vmips_wired_entry_remove(int index);
+#ifdef CONFIG_NLM_VMIPS
+extern void nlm_vmips_temp_xkphys_tlb_add(phys_t start, phys_t end, int *tlbs, int *tlbe);
+extern void nlm_vmips_wired_entry_remove(int index);
 #endif
 
 
@@ -65,7 +61,7 @@ extern void rmi_vmips_wired_entry_remove(int index);
 		       : : "i" (op), "r" (base));          \
   } while (0) 
 
-#ifdef CONFIG_RMI_XLP
+#ifdef CONFIG_NLM_XLP
 
 static __inline__ void pipeline_flush(void)
 {
@@ -98,7 +94,7 @@ static __inline__ void cacheop_sync_istream(void)
 	pipeline_flush();
 }
 
-#else /* !CONFIG_RMI_XLP */
+#else /* !CONFIG_NLM_XLP */
 
 static __inline__ void sync_istream(void)
 {
@@ -141,7 +137,7 @@ static __inline__ void cacheop_sync_istream(void)
   sync_istream();
 }
 
-#endif /* !CONFIG_RMI_XLP */
+#endif /* !CONFIG_NLM_XLP */
 
 #if 0
 #define optimize_thread_flush() do { \
@@ -151,20 +147,20 @@ static __inline__ void cacheop_sync_istream(void)
 #define optimize_thread_flush()
 #endif
 
-extern unsigned long phnx_ebase;
+extern unsigned long nlm_common_ebase;
 /*****************************************************************************************
  * 
  * These routines support Generic Kernel cache flush requirements
  *
  *****************************************************************************************/
-void phoenix_flush_dcache_page(struct page *page)
+void nlm_common_flush_dcache_page(struct page *page)
 {
   ClearPageDcacheDirty(page);    
 }
 
-EXPORT_SYMBOL(phoenix_flush_dcache_page);
+EXPORT_SYMBOL(nlm_common_flush_dcache_page);
 
-static void phoenix_local_flush_icache_range(unsigned long start, unsigned long end)
+static void nlm_common_local_flush_icache_range(unsigned long start, unsigned long end)
 {
   unsigned long addr;
   
@@ -187,20 +183,20 @@ struct flush_icache_range_args_paddr {
   phys_t end;
 };
 
-static void phoenix_flush_icache_range_ipi(void *info)
+static void nlm_common_flush_icache_range_ipi(void *info)
 {
   struct flush_icache_range_args *args = info;
 
   optimize_thread_flush();
 
-  phoenix_local_flush_icache_range(args->start, args->end);
+  nlm_common_local_flush_icache_range(args->start, args->end);
 }
 
-void phoenix_flush_icache_range(unsigned long start, unsigned long end)
+void nlm_common_flush_icache_range(unsigned long start, unsigned long end)
 {
   struct flush_icache_range_args args;
 
-#ifdef CONFIG_PHOENIX_VM_DEBUG
+#ifdef CONFIG_NLMCOMMON_VM_DEBUG
   dbg_msg("return address: ");
   print_symbol("ra[0]=%s\n", return_address());
 #endif
@@ -215,10 +211,10 @@ void phoenix_flush_icache_range(unsigned long start, unsigned long end)
    * This may require some changes to smp_call_function interface, for now just avoid 
    * redundant cache ops
    */
-  on_each_cpu(phoenix_flush_icache_range_ipi, &args, 1);
+  on_each_cpu(nlm_common_flush_icache_range_ipi, &args, 1);
 }
 
-static void phoenix_flush_cache_sigtramp_ipi(void *info)
+static void nlm_common_flush_cache_sigtramp_ipi(void *info)
 {
   unsigned long addr = (unsigned long)info;
 
@@ -229,9 +225,9 @@ static void phoenix_flush_cache_sigtramp_ipi(void *info)
   cacheop_sync_istream();
 }
 
-static void phoenix_flush_cache_sigtramp(unsigned long addr)
+static void nlm_common_flush_cache_sigtramp(unsigned long addr)
 {
-  on_each_cpu(phoenix_flush_cache_sigtramp_ipi, (void *) addr, 1);
+  on_each_cpu(nlm_common_flush_cache_sigtramp_ipi, (void *) addr, 1);
 }
 
 /*****************************************************************************************
@@ -241,7 +237,7 @@ static void phoenix_flush_cache_sigtramp(unsigned long addr)
  *
  *****************************************************************************************/
 
-static void phoenix_local_flush_icache(void)
+static void nlm_common_local_flush_icache(void)
 {
   int i=0;
   unsigned long base = CKSEG0;
@@ -258,7 +254,7 @@ static void phoenix_local_flush_icache(void)
 
 }
 
-static void phoenix_local_flush_dcache(void)
+static void nlm_common_local_flush_dcache(void)
 {
   int i=0;
   unsigned long base = CKSEG0;
@@ -279,33 +275,33 @@ static void phoenix_local_flush_dcache(void)
 }
 
 #ifdef CONFIG_KGDB
-void phoenix_flush_l1_icache_ipi(void *info)
+void nlm_common_flush_l1_icache_ipi(void *info)
 {
-	phoenix_local_flush_icache();
+	nlm_common_local_flush_icache();
 }
 #endif
 
 #ifdef CONFIG_KGDB
-void phoenix_flush_l1_caches_ipi(void *info)
+void nlm_common_flush_l1_caches_ipi(void *info)
 #else
-static void phoenix_flush_l1_caches_ipi(void *info)
+static void nlm_common_flush_l1_caches_ipi(void *info)
 #endif
 {
   optimize_thread_flush();
  
-  phoenix_local_flush_dcache();
-  phoenix_local_flush_icache();
+  nlm_common_local_flush_dcache();
+  nlm_common_local_flush_icache();
 }
 
-static void phoenix_flush_l1_caches(void)
+static void nlm_common_flush_l1_caches(void)
 {
   //dbg_msg("NASTY CACHE FLUSH: flushing L1 caches on all cpus!\n");
-  on_each_cpu(phoenix_flush_l1_caches_ipi, (void *)NULL, 1);
+  on_each_cpu(nlm_common_flush_l1_caches_ipi, (void *)NULL, 1);
 }
 
 /*****************************************************************************************/
 
-static void phoenix_noflush(void) { /* do nothing */ }
+static void nlm_common_noflush(void) { /* do nothing */ }
 
 static __init void probe_l1_cache(void)
 {
@@ -355,7 +351,7 @@ static __inline__ void install_cerr_handler(void)
 {
   extern char except_vec2_generic;
 
-  memcpy((void *)(phnx_ebase + 0x100), &except_vec2_generic, 0x80);
+  memcpy((void *)(nlm_common_ebase + 0x100), &except_vec2_generic, 0x80);
 }
 
 static void update_kseg0_coherency(void)
@@ -364,8 +360,8 @@ static void update_kseg0_coherency(void)
 
   if (attr != 0x3) {
 
-    phoenix_local_flush_dcache();
-    phoenix_local_flush_icache();
+    nlm_common_local_flush_dcache();
+    nlm_common_local_flush_icache();
 
     change_c0_config(CONF_CM_CMASK, 0x3);
 
@@ -389,9 +385,9 @@ void ld_mmu_phoenix(void)
 		/* flush the exception vector region to make sure 
 		 * not to execute bootloader's exception code 
 		 */
-		phoenix_local_flush_icache_range(phnx_ebase, phnx_ebase + 0x400);
+		nlm_common_local_flush_icache_range(nlm_common_ebase, nlm_common_ebase + 0x400);
 #endif
-		phoenix_local_flush_icache();
+		nlm_common_local_flush_icache();
 
 		update_kseg0_coherency();
 
@@ -405,55 +401,55 @@ void ld_mmu_phoenix(void)
 	/* When does this function get called? Looks like MIPS has some syscalls
 	 * to flush the caches. 
 	 */
-	__flush_cache_all = phoenix_flush_l1_caches;
+	__flush_cache_all = nlm_common_flush_l1_caches;
 
 	/* flush_cache_all: makes all kernel data coherent.
 	 * This gets called just before changing or removing
 	 * a mapping in the page-table-mapped kernel segment (kmap). 
 	 * Physical Cache -> do nothing
 	 */
-	flush_cache_all = phoenix_noflush;
+	flush_cache_all = nlm_common_noflush;
 
 	/* flush_icache_range: makes the range of addresses coherent w.r.t I-cache and D-cache 
 	 * This gets called after the instructions are written to memory
 	 * All addresses are valid kernel or mapped user-space virtual addresses
 	 */
-	flush_icache_range = phoenix_flush_icache_range;
+	flush_icache_range = nlm_common_flush_icache_range;
 
 	/* flush_cache_{mm, range, page}: make these memory locations, that may have been written
 	 *                                by a user process, coherent
 	 * These get called when virtual->physical translation of a user address space is about
 	 * to be changed. These are closely related to TLB coherency (flush_tlb_{mm, range, page})
 	 */
-	flush_cache_mm = (void (*)(struct mm_struct *))phoenix_noflush;
-	flush_cache_range = (void *) phoenix_noflush;
-	flush_cache_page = (void *) phoenix_noflush;
+	flush_cache_mm = (void (*)(struct mm_struct *))nlm_common_noflush;
+	flush_cache_range = (void *) nlm_common_noflush;
+	flush_cache_page = (void *) nlm_common_noflush;
 
 	/* flush_icache_page: flush_dcache_page + update_mmu_cache takes care of this
 	 * 
 	 */
-	flush_data_cache_page = (void *) phoenix_noflush;
+	flush_data_cache_page = (void *) nlm_common_noflush;
 
 	/* flush_cache_sigtramp: flush the single I-cache line with the proper fixup code
 	 */
-	flush_cache_sigtramp = phoenix_flush_cache_sigtramp;
+	flush_cache_sigtramp = nlm_common_flush_cache_sigtramp;
 
 	/* flush_icache_all: This should get called only for Virtuall Tagged I-Caches
 	 */
-	flush_icache_all = (void *)phoenix_noflush;
+	flush_icache_all = (void *)nlm_common_noflush;
 
-	local_flush_icache_range = phoenix_local_flush_icache_range;
-	local_flush_data_cache_page	= (void *)phoenix_noflush;
+	local_flush_icache_range = nlm_common_local_flush_icache_range;
+	local_flush_data_cache_page	= (void *)nlm_common_noflush;
 
-	__flush_cache_vmap = (void *)phoenix_noflush;
-	__flush_cache_vunmap = (void *)phoenix_noflush;
+	__flush_cache_vmap = (void *)nlm_common_noflush;
+	__flush_cache_vunmap = (void *)nlm_common_noflush;
 
 	install_cerr_handler();
 
 	build_clear_page();
 	build_copy_page();
 
-	phoenix_local_flush_icache();
+	nlm_common_local_flush_icache();
 
 	update_kseg0_coherency();
 }
@@ -522,19 +518,19 @@ static inline void cacheop_paddr(const unsigned int op, phys_t base)
 #define SETS_PER_WAY_MASK 0x7
 #define CACHELINE_SIZE_BITS 5
 
-static void phoenix_local_flush_icache_range_paddr(phys_t start, phys_t end)
+static void nlm_common_local_flush_icache_range_paddr(phys_t start, phys_t end)
 {
 	phys_t addr;
 #ifdef CONFIG_32BIT
 	unsigned long flags;
 	phys_t temp;
 #endif
-#ifdef CONFIG_RMI_VMIPS
+#ifdef CONFIG_NLM_VMIPS
 	int tlbs = 0, tlbe = 0;
-	rmi_vmips_temp_xkphys_tlb_add(start, end, &tlbs, &tlbe);
+	nlm_vmips_temp_xkphys_tlb_add(start, end, &tlbs, &tlbe);
 #endif
 
-#ifdef CONFIG_RMI_XLP
+#ifdef CONFIG_NLM_XLP
 	int sets_per_way, niter, i;
 	uint64_t mask;
 
@@ -552,7 +548,7 @@ static void phoenix_local_flush_icache_range_paddr(phys_t start, phys_t end)
     for (addr = (start & ~(phys_t)(icache_linesz - 1)); addr < end;
                     addr += icache_linesz) {
 		cacheop_paddr(Hit_Invalidate_I, addr);
-#ifdef CONFIG_RMI_XLP
+#ifdef CONFIG_NLM_XLP
 		for (i = 1; i < niter; ++i)
 			cacheop_paddr(Hit_Invalidate_I, (addr & ~(mask << PAGE_SHIFT)) | (i << PAGE_SHIFT));
 #endif
@@ -562,28 +558,28 @@ static void phoenix_local_flush_icache_range_paddr(phys_t start, phys_t end)
 	disable_KX(flags);
 #endif
 
-#ifdef CONFIG_RMI_VMIPS
+#ifdef CONFIG_NLM_VMIPS
 	for(;tlbe >= tlbs; tlbe--)
-        rmi_vmips_wired_entry_remove(tlbe); 
+        nlm_vmips_wired_entry_remove(tlbe); 
 
 #endif
 	cacheop_sync_istream();
 }
 
-static void phoenix_flush_icache_range_paddr_ipi(void *info)
+static void nlm_common_flush_icache_range_paddr_ipi(void *info)
 {
   struct flush_icache_range_args_paddr *args = info;
 
   optimize_thread_flush();
 
-  phoenix_local_flush_icache_range_paddr(args->start, args->end);
+  nlm_common_local_flush_icache_range_paddr(args->start, args->end);
 }
 
-void phoenix_flush_icache_range_paddr(phys_t start)
+void nlm_common_flush_icache_range_paddr(phys_t start)
 {
   struct flush_icache_range_args_paddr args;
 
-#ifdef CONFIG_PHOENIX_VM_DEBUG
+#ifdef CONFIG_NLMCOMMON_VM_DEBUG
   dbg_msg("return address: ");
   print_symbol("ra[0]=%s\n", (unsigned long) return_address());
 #endif
@@ -594,7 +590,7 @@ void phoenix_flush_icache_range_paddr(phys_t start)
    * This may require some changes to smp_call_function interface, for now just avoid 
    * redundant cache ops
    */
-  on_each_cpu(phoenix_flush_icache_range_paddr_ipi, &args, 1);
+  on_each_cpu(nlm_common_flush_icache_range_paddr_ipi, &args, 1);
 }
 
 
diff --git a/arch/mips/mm/cache.c b/arch/mips/mm/cache.c
index d1d564f..a3fc1e9 100644
--- a/arch/mips/mm/cache.c
+++ b/arch/mips/mm/cache.c
@@ -1,3 +1,11 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (Netlogic).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
+
+*****************************#NETL_1#********************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -118,12 +126,13 @@ void __flush_anon_page(struct page *page, unsigned long vmaddr)
 
 EXPORT_SYMBOL(__flush_anon_page);
 
+extern void nlm_common_flush_icache_range_paddr(phys_t start);
 void __update_cache(struct vm_area_struct *vma, unsigned long address,
 	pte_t pte)
 {
 	struct page *page;
 
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 	phys_t start;
 	//printk("[%s]: address = %lx, pte = %lx\n", __FUNCTION__, address, pte_val(pte));
 	if (!(vma->vm_flags & VM_EXEC)) return;
@@ -133,7 +142,7 @@ void __update_cache(struct vm_area_struct *vma, unsigned long address,
 	/*  if (addr)  */
 	/*    flush_icache_range(addr, addr+PAGE_SIZE); */
 	start = (phys_t)pte_pfn(pte);
-	phoenix_flush_icache_range_paddr(start << PAGE_SHIFT);
+	nlm_common_flush_icache_range_paddr(start << PAGE_SHIFT);
 	SetPageDcacheDirty(page);
 #else
 	unsigned long pfn, addr;
@@ -152,7 +161,7 @@ void __update_cache(struct vm_area_struct *vma, unsigned long address,
 #endif
 }
 
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 /* This variable needs to be initialized before setup_arch() if this is not
    initialized like below
    */
@@ -230,7 +239,7 @@ void __cpuinit cpu_cache_init(void)
 
 		tx39_cache_init();
 	}
-	if (cpu_has_phoenix_cache) {
+	if (cpu_has_nlm_cache) {
 		extern void __weak ld_mmu_phoenix(void);
 
 		ld_mmu_phoenix();
@@ -250,12 +259,12 @@ int __weak __uncached_access(struct file *file, unsigned long addr)
 	if (file->f_flags & O_DSYNC)
 		return 1;
 
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 	{
-		extern int phnx_get_pgprot(unsigned long address);
+		extern int nlm_common_get_pgprot(unsigned long address);
 	  	/* check the address region, return uncached pages for IO space and
 		   cached page for memory space. */
-		return phnx_get_pgprot(addr);
+		return nlm_common_get_pgprot(addr);
 	}
 #endif
 
diff --git a/arch/mips/mm/cex-gen.S b/arch/mips/mm/cex-gen.S
index 31f4b94..ef88f02 100644
--- a/arch/mips/mm/cex-gen.S
+++ b/arch/mips/mm/cex-gen.S
@@ -1,14 +1,10 @@
-/************************************************************************
- *
- * Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
- *
- * This is a derived work from software originally provided by the external
- * entity identified below. The licensing terms and warranties specified in
- * the header of the original work apply to this derived work.
- *
- * Contribution by RMI: 
- *
- ******************************#RMI_1#************************************/
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
+
+*****************************#NETL_1#********************************/
 
 /*
  * This file is subject to the terms and conditions of the GNU General Public
@@ -48,7 +44,7 @@
 	nop
 	nop
 	nop
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 
 	/* If some other cpu is already in the handler
 	 * just wait... */
@@ -70,7 +66,7 @@
 	PTR	0x737a0018
 	move	a1, k0
 	
-    j phoenix_cache_error
+    j nlm_cache_error
 	nop
 	/* should never get here */
 
diff --git a/arch/mips/mm/extable.c b/arch/mips/mm/extable.c
index fb29d08..9d25d2b 100644
--- a/arch/mips/mm/extable.c
+++ b/arch/mips/mm/extable.c
@@ -1,15 +1,3 @@
-/************************************************************************
-
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI: 
-
-  *****************************#RMI_1#************************************/
-
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -19,7 +7,6 @@
  */
 #include <linux/module.h>
 #include <linux/spinlock.h>
-#include <linux/kgdb.h>
 #include <asm/branch.h>
 #include <asm/uaccess.h>
 
@@ -33,14 +20,6 @@ int fixup_exception(struct pt_regs *regs)
 
 		return 1;
 	}
-#if 0
-#ifdef CONFIG_KGDB
-	if (atomic_read(&debugger_active) && kgdb_may_fault)
-		/* Restore our previous state. */
-		kgdb_fault_longjmp(kgdb_fault_jmp_regs);
-		/* Not reached. */
-#endif
-#endif
 
 	return 0;
 }
diff --git a/arch/mips/mm/ioremap.c b/arch/mips/mm/ioremap.c
index 4f77d61..38c3a68 100644
--- a/arch/mips/mm/ioremap.c
+++ b/arch/mips/mm/ioremap.c
@@ -1,14 +1,10 @@
-/************************************************************************
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
 
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI: 
-
-  *****************************#RMI_1#************************************/
+*****************************#NETL_1#********************************/
 
 /*
  * This file is subject to the terms and conditions of the GNU General Public
diff --git a/arch/mips/mm/tlb-r4k.c b/arch/mips/mm/tlb-r4k.c
index d57481d..cfabccd 100644
--- a/arch/mips/mm/tlb-r4k.c
+++ b/arch/mips/mm/tlb-r4k.c
@@ -1,14 +1,10 @@
-/************************************************************************
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
 
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI:
-
- *****************************#RMI_1#************************************/
+*****************************#NETL_1#********************************/
 
 /*
  * This file is subject to the terms and conditions of the GNU General Public
@@ -31,9 +27,9 @@
 #include <asm/mmu_context.h>
 #include <asm/pgtable.h>
 
-#ifdef CONFIG_RMI_PHOENIX
-#include <asm/rmi/mips-exts.h>
-#include <asm/mach-rmi/mmu.h>
+#ifdef CONFIG_NLM_COMMON
+#include <asm/netlogic/mips-exts.h>
+#include <asm/mach-netlogic/mmu.h>
 #endif
 
 
@@ -83,12 +79,12 @@ extern void build_tlb_refill_handler(void);
 
 #endif
 
-#ifdef CONFIG_RMI_VMIPS
+#ifdef CONFIG_NLM_VMIPS
 #define UNIQUE_VMIPS_ENTRYHI(idx)  ((1ULL << 63) + (1ULL << 40) + ((idx) << (PAGE_SHIFT + 1)) + ( 1 << 8))
-extern int rmi_vmips_max_wired_entries;
+extern int nlm_vmips_max_wired_entries;
 #endif
 
-#ifdef CONFIG_RMI_XLP
+#ifdef CONFIG_NLM_XLP
 
 #define disable_pgwalker(flags) \
 ({ flags = read_c0_config7(); \
@@ -125,7 +121,7 @@ void local_flush_tlb_all(void)
 	/* Blast 'em all away. */
 	while (entry < current_cpu_data.tlbsize) {
 		/* Make sure all entries differ. */
-#ifndef CONFIG_RMI_VMIPS
+#ifndef CONFIG_NLM_VMIPS
 		write_c0_entryhi(UNIQUE_ENTRYHI(entry));
 #else
         __write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(entry)));
@@ -196,7 +192,7 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 				if (idx < 0)
 					continue;
 				/* Make sure all entries differ. */
-#ifndef CONFIG_RMI_VMIPS
+#ifndef CONFIG_NLM_VMIPS
 				write_c0_entryhi(UNIQUE_ENTRYHI(idx));
 #else
 				__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
@@ -245,7 +241,7 @@ void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
 			if (idx < 0)
 				continue;
 			/* Make sure all entries differ. */
-#ifndef CONFIG_RMI_VMIPS
+#ifndef CONFIG_NLM_VMIPS
 			write_c0_entryhi(UNIQUE_ENTRYHI(idx));
 #else
 			__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
@@ -286,7 +282,7 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
 		if (idx < 0)
 			goto finish;
 		/* Make sure all entries differ. */
-#ifndef CONFIG_RMI_VMIPS
+#ifndef CONFIG_NLM_VMIPS
 		write_c0_entryhi(UNIQUE_ENTRYHI(idx));
 #else
 		__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
@@ -325,7 +321,7 @@ void local_flush_tlb_one(unsigned long page)
 	write_c0_entrylo1(0);
 	if (idx >= 0) {
 		/* Make sure all entries differ. */
-#ifndef CONFIG_RMI_VMIPS
+#ifndef CONFIG_NLM_VMIPS
 		write_c0_entryhi(UNIQUE_ENTRYHI(idx));
 #else
 		__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
@@ -513,7 +509,12 @@ static void __cpuinit probe_tlb(unsigned long config)
 	if (!((config >> 7) & 3))
 		panic("No TLB present");
 
+#if defined(CONFIG_NLM_XLP)
+	c->tlbsize = ((read_c0_config6() >> 16 ) & 0xffff) + 1;
+#else
 	c->tlbsize = ((reg >> 25) & 0x3f) + 1;
+#endif
+
 }
 
 static int __cpuinitdata ntlb;
@@ -525,20 +526,20 @@ static int __init set_ntlb(char *str)
 
 __setup("ntlb=", set_ntlb);
 
-#ifdef CONFIG_RMI_PHOENIX
-extern void phoenix_tlb_init(void);
+#ifdef CONFIG_NLM_COMMON
+extern void nlm_common_tlb_init(void);
 
-void rmi_tlb_stats_init(void)
+void nlm_tlb_stats_init(void)
 {
-	rmi_write_os_scratch_2(0ULL);
+	nlm_write_os_scratch_2(0ULL);
 }
 
 #ifdef CONFIG_HUGETLBFS
-void rmi_tlb_entrylo0_mask_init(void);
-void rmi_tlb_entrylo0_mask_init()
+void nlm_tlb_entrylo0_mask_init(void);
+void nlm_tlb_entrylo0_mask_init()
 {
 	unsigned long long mask = ~(((1ULL<<HUGETLB_PAGE_ORDER)-1)<<6);
-	rmi_write_os_scratch_3(mask);
+	nlm_write_os_scratch_3(mask);
 }
 #endif
 
@@ -555,9 +556,9 @@ void __cpuinit tlb_init(void)
 	 */
 	write_c0_pagemask(PM_DEFAULT_MASK);
 
-#if defined(CONFIG_RMI_VMIPS)
-	if(ntlb && ((current_cpu_data.tlbsize-ntlb) < rmi_vmips_max_wired_entries))
-		ntlb = current_cpu_data.tlbsize - rmi_vmips_max_wired_entries;
+#if defined(CONFIG_NLM_VMIPS)
+	if(ntlb && ((current_cpu_data.tlbsize-ntlb) < nlm_vmips_max_wired_entries))
+		ntlb = current_cpu_data.tlbsize - nlm_vmips_max_wired_entries;
 #endif
 
 	if (current_cpu_type() == CPU_R10000 ||
@@ -600,14 +601,11 @@ void __cpuinit tlb_init(void)
 			printk("Ignoring invalid argument ntlb=%d\n", ntlb);
 	}
 
-#ifdef CONFIG_RMI_PHOENIX
-
-	rmi_tlb_stats_init();
+#ifdef CONFIG_NLM_COMMON
+	nlm_tlb_stats_init();
 
 #ifdef CONFIG_HUGETLBFS
-
-	rmi_tlb_entrylo0_mask_init();
-
+	nlm_tlb_entrylo0_mask_init();
 #endif
 
 #endif
diff --git a/arch/mips/mm/tlbex.c b/arch/mips/mm/tlbex.c
index 59b62c0..4cabc96 100644
--- a/arch/mips/mm/tlbex.c
+++ b/arch/mips/mm/tlbex.c
@@ -57,6 +57,10 @@ struct tlb_reg_save {
 
 static struct tlb_reg_save handler_reg_save[NR_CPUS];
 
+#ifdef CONFIG_NLM_XLP
+#include <asm/netlogic/mips-exts.h>
+#endif
+
 static inline int r45k_bvahwbug(void)
 {
 	/* XXX: We should probe for the presence of this bug, but we don't. */
@@ -161,6 +165,18 @@ enum label_id {
 #ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
 	label_tlb_huge_update,
 #endif
+#ifdef CONFIG_NLM_XLP
+	label_nohpage_tlbs,
+	label_hpage_tlb_leave,
+	label_non_btlb_process,
+	label_read_entrylo1,
+	label_illegal_access_tlbl,
+	label_exl_refill_exception,
+	label_r4000_write_probe_fail,
+#ifdef CONFIG_HUGETLB_PAGE
+	label_r4000_write_huge_probe_fail,
+#endif
+#endif
 };
 
 UASM_L_LA(_second_part)
@@ -248,6 +264,19 @@ static void output_pgtable_bits_defines(void)
 	pr_debug("\n");
 }
 
+#ifdef CONFIG_NLM_XLP
+UASM_L_LA(_nohpage_tlbs)
+UASM_L_LA(_hpage_tlb_leave)
+UASM_L_LA(_non_btlb_process)
+UASM_L_LA(_read_entrylo1)
+UASM_L_LA(_illegal_access_tlbl)
+UASM_L_LA(_exl_refill_exception)
+UASM_L_LA(_r4000_write_probe_fail)
+#ifdef CONFIG_HUGETLB_PAGE
+UASM_L_LA(_r4000_write_huge_probe_fail)
+#endif
+#endif
+
 static inline void dump_handler(const char *symbol, const u32 *handler, int count)
 {
 	int i;
@@ -280,6 +309,8 @@ static inline void dump_handler(const char *symbol, const u32 *handler, int coun
 #define C0_ENTRYHI	10, 0
 #define C0_EPC		14, 0
 #define C0_XCONTEXT	20, 0
+#define C0_CONFIG6     16, 6
+#define C0_WIRED        6, 0
 
 #ifdef CONFIG_64BIT
 # define GET_CONTEXT(buf, reg) UASM_i_MFC0(buf, reg, C0_XCONTEXT)
@@ -295,12 +326,20 @@ static inline void dump_handler(const char *symbol, const u32 *handler, int coun
  * We deliberately chose a buffer size of 128, so we won't scribble
  * over anything important on overflow before we panic.
  */
+#if defined(CONFIG_MAPPED_KERNEL)
+static u32 tlb_handler[128];
+#else
 static u32 tlb_handler[128] __cpuinitdata;
+#endif
 
 /* simply assume worst case size for labels and relocs */
 static struct uasm_label labels[128] __cpuinitdata;
 static struct uasm_reloc relocs[128] __cpuinitdata;
 
+#ifdef CONFIG_64BIT
+static int check_for_high_segbits __cpuinitdata;
+#endif
+
 static int check_for_high_segbits __cpuinitdata;
 
 static unsigned int kscratch_used_mask __cpuinitdata;
@@ -452,7 +491,10 @@ static void __cpuinit build_r3000_tlb_refill_handler(void)
  * other one.To keep things simple, we first assume linear space,
  * then we relocate it to the final handler layout as needed.
  */
+
+#if !defined(CONFIG_MAPPED_KERNEL)
 static u32 final_handler[64] __cpuinitdata;
+#endif
 
 /*
  * Hazards
@@ -641,8 +683,17 @@ static void __cpuinit build_tlb_write_entry(u32 **p, struct uasm_label **l,
 static __cpuinit __maybe_unused void build_convert_pte_to_entrylo(u32 **p,
 								  unsigned int reg)
 {
-	if (cpu_has_rixi) {
-		UASM_i_ROTR(p, reg, reg, ilog2(_PAGE_GLOBAL));
+	if (kernel_uses_smartmips_rixi) {
+#ifdef CONFIG_NLM_XLP
+#ifdef CONFIG_64BIT_PHYS_ADDR
+		uasm_i_dsrl(p, reg, reg, ilog2(_PAGE_GLOBAL));
+#else
+		UASM_i_SRL(p, reg, reg, ilog2(_PAGE_GLOBAL));
+#endif
+#else /* CONFIG_NLM_XLP */
+		UASM_i_SRL(p, reg, reg, ilog2(_PAGE_NO_EXEC));
+		UASM_i_ROTR(p, reg, reg, ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));
+#endif /* CONFIG_NLM_XLP */
 	} else {
 #ifdef CONFIG_64BIT_PHYS_ADDR
 		uasm_i_dsrl_safe(p, reg, reg, ilog2(_PAGE_GLOBAL));
@@ -652,7 +703,7 @@ static __cpuinit __maybe_unused void build_convert_pte_to_entrylo(u32 **p,
 	}
 }
 
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
+#ifdef CONFIG_HUGETLB_PAGE
 
 static __cpuinit void build_restore_pagemask(u32 **p,
 					     struct uasm_reloc **r,
@@ -776,9 +827,25 @@ static __cpuinit void build_huge_handler_tail(u32 **p,
 	UASM_i_SW(p, pte, 0, ptr);
 #endif
 	build_huge_update_entries(p, pte, ptr);
+
+#ifdef CONFIG_NLM_XLP
+	/* Similar to no hugetlb case, checking probe result.
+	 * FIXME: this should not happen really.
+	 */
+	uasm_i_mfc0(p, ptr, C0_INDEX);
+
+	uasm_il_bltz(p, r, ptr, label_r4000_write_huge_probe_fail);
+	uasm_i_nop(p);
+
 	build_huge_tlb_write_entry(p, l, r, pte, tlb_indexed, 0);
+	uasm_l_r4000_write_huge_probe_fail(l, *p);
+
+	build_huge_tlb_write_entry(p, l, r, pte, tlb_random, 0);
+#else
+	build_huge_tlb_write_entry(p, l, r, pte, tlb_indexed, 0);
+#endif
 }
-#endif /* CONFIG_MIPS_HUGE_TLB_SUPPORT */
+#endif /* CONFIG_HUGETLB_PAGE */
 
 #ifdef CONFIG_64BIT
 /*
@@ -1044,10 +1111,18 @@ static void __cpuinit build_update_entries(u32 **p, unsigned int tmp,
 	if (cpu_has_64bits) {
 		uasm_i_ld(p, tmp, 0, ptep); /* get even pte */
 		uasm_i_ld(p, ptep, sizeof(pte_t), ptep); /* get odd pte */
-		if (cpu_has_rixi) {
-			UASM_i_ROTR(p, tmp, tmp, ilog2(_PAGE_GLOBAL));
+		if (kernel_uses_smartmips_rixi) {
+#ifdef CONFIG_NLM_XLP
+			uasm_i_dsrl_safe(p, tmp, tmp, ilog2(_PAGE_GLOBAL)); /* convert to entrylo0 */
+			UASM_i_MTC0(p, tmp, C0_ENTRYLO0); /* load it */
+			uasm_i_dsrl_safe(p, ptep, ptep, ilog2(_PAGE_GLOBAL)); /* convert to entrylo1 */
+#else /* CONFIG_NLM_XLP */
+			UASM_i_SRL(p, tmp, tmp, ilog2(_PAGE_NO_EXEC));
+			UASM_i_SRL(p, ptep, ptep, ilog2(_PAGE_NO_EXEC));
+			UASM_i_ROTR(p, tmp, tmp, ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));
 			UASM_i_MTC0(p, tmp, C0_ENTRYLO0); /* load it */
-			UASM_i_ROTR(p, ptep, ptep, ilog2(_PAGE_GLOBAL));
+			UASM_i_ROTR(p, ptep, ptep, ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));
+#endif /* CONFIG_NLM_XLP */
 		} else {
 			uasm_i_dsrl_safe(p, tmp, tmp, ilog2(_PAGE_GLOBAL)); /* convert to entrylo0 */
 			UASM_i_MTC0(p, tmp, C0_ENTRYLO0); /* load it */
@@ -1069,12 +1144,24 @@ static void __cpuinit build_update_entries(u32 **p, unsigned int tmp,
 	UASM_i_LW(p, ptep, sizeof(pte_t), ptep); /* get odd pte */
 	if (r45k_bvahwbug())
 		build_tlb_probe_entry(p);
-	if (cpu_has_rixi) {
-		UASM_i_ROTR(p, tmp, tmp, ilog2(_PAGE_GLOBAL));
+	if (kernel_uses_smartmips_rixi) {
+#ifdef CONFIG_NLM_XLP
+		UASM_i_SRL(p, tmp, tmp, ilog2(_PAGE_GLOBAL)); /* convert to entrylo0 */
+		if (r4k_250MHZhwbug())
+			UASM_i_MTC0(p, 0, C0_ENTRYLO0);
+		UASM_i_MTC0(p, tmp, C0_ENTRYLO0); /* load it */
+		UASM_i_SRL(p, ptep, ptep, ilog2(_PAGE_GLOBAL)); /* convert to entrylo1 */
+		if (r45k_bvahwbug())
+			uasm_i_mfc0(p, tmp, C0_INDEX);
+#else /* CONFIG_NLM_XLP */
+		UASM_i_SRL(p, tmp, tmp, ilog2(_PAGE_NO_EXEC));
+		UASM_i_SRL(p, ptep, ptep, ilog2(_PAGE_NO_EXEC));
+		UASM_i_ROTR(p, tmp, tmp, ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));
 		if (r4k_250MHZhwbug())
 			UASM_i_MTC0(p, 0, C0_ENTRYLO0);
 		UASM_i_MTC0(p, tmp, C0_ENTRYLO0); /* load it */
-		UASM_i_ROTR(p, ptep, ptep, ilog2(_PAGE_GLOBAL));
+		UASM_i_ROTR(p, ptep, ptep, ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));
+#endif /* CONFIG_NLM_XLP */
 	} else {
 		UASM_i_SRL(p, tmp, tmp, ilog2(_PAGE_GLOBAL)); /* convert to entrylo0 */
 		if (r4k_250MHZhwbug())
@@ -1207,7 +1294,7 @@ build_fast_tlb_refill_handler (u32 **p, struct uasm_label **l,
 	/* Adjust the context during the load latency. */
 	build_adjust_context(p, tmp);
 
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
+#ifdef CONFIG_HUGETLB_PAGE
 	uasm_il_bbit1(p, r, scratch, ilog2(_PAGE_HUGE), label_tlb_huge_update);
 	/*
 	 * The in the LWX case we don't want to do the load in the
@@ -1216,7 +1303,7 @@ build_fast_tlb_refill_handler (u32 **p, struct uasm_label **l,
 	 */
 	if (use_lwx_insns())
 		uasm_i_nop(p);
-#endif /* CONFIG_MIPS_HUGE_TLB_SUPPORT */
+#endif /* CONFIG_HUGETLB_PAGE */
 
 
 	/* build_update_entries */
@@ -1233,10 +1320,14 @@ build_fast_tlb_refill_handler (u32 **p, struct uasm_label **l,
 		UASM_i_LW(p, even, 0, ptr); /* get even pte */
 		UASM_i_LW(p, odd, sizeof(pte_t), ptr); /* get odd pte */
 	}
-	if (cpu_has_rixi) {
-		uasm_i_drotr(p, even, even, ilog2(_PAGE_GLOBAL));
+	if (kernel_uses_smartmips_rixi) {
+		uasm_i_dsrl_safe(p, even, even, ilog2(_PAGE_NO_EXEC));
+		uasm_i_dsrl_safe(p, odd, odd, ilog2(_PAGE_NO_EXEC));
+		uasm_i_drotr(p, even, even,
+			     ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));
 		UASM_i_MTC0(p, even, C0_ENTRYLO0); /* load it */
-		uasm_i_drotr(p, odd, odd, ilog2(_PAGE_GLOBAL));
+		uasm_i_drotr(p, odd, odd,
+			     ilog2(_PAGE_GLOBAL) - ilog2(_PAGE_NO_EXEC));
 	} else {
 		uasm_i_dsrl_safe(p, even, even, ilog2(_PAGE_GLOBAL));
 		UASM_i_MTC0(p, even, C0_ENTRYLO0); /* load it */
@@ -1278,15 +1369,19 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 	u32 *p = tlb_handler;
 	struct uasm_label *l = labels;
 	struct uasm_reloc *r = relocs;
+#if !defined(CONFIG_MAPPED_KERNEL)
 	u32 *f;
 	unsigned int final_len;
+#endif
 	struct mips_huge_tlb_info htlb_info __maybe_unused;
 	enum vmalloc64_mode vmalloc_mode __maybe_unused;
 
 	memset(tlb_handler, 0, sizeof(tlb_handler));
 	memset(labels, 0, sizeof(labels));
 	memset(relocs, 0, sizeof(relocs));
+#if !defined(CONFIG_MAPPED_KERNEL)
 	memset(final_handler, 0, sizeof(final_handler));
+#endif
 
 	if ((scratch_reg > 0 || scratchpad_available()) && use_bbit_insns()) {
 		htlb_info = build_fast_tlb_refill_handler(&p, &l, &r, K0, K1,
@@ -1313,13 +1408,19 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 			/* No need for uasm_i_nop */
 		}
 
+#ifdef CONFIG_NLM_XLP
+		uasm_i_dmfc0(&p, K0, OS_SCRATCH_REG2);
+		uasm_i_daddiu(&p, K0, K0, 1);
+		uasm_i_dmtc0(&p, K0, OS_SCRATCH_REG2);
+#endif
+
 #ifdef CONFIG_64BIT
 		build_get_pmde64(&p, &l, &r, K0, K1); /* get pmd in K1 */
 #else
 		build_get_pgde32(&p, K0, K1); /* get pgd in K1 */
 #endif
 
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
+#ifdef CONFIG_HUGETLB_PAGE
 		build_is_huge_pte(&p, &r, K0, K1, label_tlb_huge_update);
 #endif
 
@@ -1327,9 +1428,17 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 		build_update_entries(&p, K0, K1);
 		build_tlb_write_entry(&p, &l, &r, tlb_random);
 		uasm_l_leave(&l, p);
+#ifdef CONFIG_NLM_XLP
+		/* this is to avoid split of the table at eret instruction
+		   The code below does a split at 30th instruction.
+		 */
+		if ((p - tlb_handler) == 30) {
+			uasm_i_nop(&p);
+		}
+#endif
 		uasm_i_eret(&p); /* return from trap */
 	}
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
+#ifdef CONFIG_HUGETLB_PAGE
 	uasm_l_tlb_huge_update(&l, p);
 	build_huge_update_entries(&p, htlb_info.huge_pte, K1);
 	build_huge_tlb_write_entry(&p, &l, &r, K0, tlb_random,
@@ -1340,6 +1449,7 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 	build_get_pgd_vmalloc64(&p, &l, &r, K0, K1, vmalloc_mode);
 #endif
 
+#if !defined(CONFIG_MAPPED_KERNEL)
 	/*
 	 * Overflow check: For the 64bit handler, we need at least one
 	 * free instruction slot for the wrap-around branch. In worst
@@ -1374,7 +1484,7 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 		uasm_copy_handler(relocs, labels, tlb_handler, p, f);
 		final_len = p - tlb_handler;
 	} else {
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
+#if defined(CONFIG_HUGETLB_PAGE)
 		const enum label_id ls = label_tlb_huge_update;
 #else
 		const enum label_id ls = label_vmalloc;
@@ -1437,15 +1547,48 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 	}
 #endif /* CONFIG_64BIT */
 
+#endif /* !defined(CONFIG_MAPPED_KERNEL) */
+
 	uasm_resolve_relocs(relocs, labels);
+#if !defined(CONFIG_MAPPED_KERNEL)
 	pr_debug("Wrote TLB refill handler (%u instructions).\n",
 		 final_len);
 
 	memcpy((void *)ebase, final_handler, 0x100);
+#endif
 
 	dump_handler("r4000_tlb_refill", (u32 *)ebase, 64);
 }
 
+#if defined(CONFIG_MAPPED_KERNEL)
+
+static u32 tlb_handler_stub[32] __cpuinitdata;
+
+static void __cpuinit __attribute__((unused)) build_r4000_tlb_refill_handler_stub(void)
+{
+	u32 *p = tlb_handler_stub;
+
+	memset(tlb_handler_stub, 0, sizeof(tlb_handler_stub));
+	UASM_i_LA(&p, K0, (unsigned long) tlb_handler);
+	uasm_i_jr(&p, K0);
+	uasm_i_nop(&p);
+
+	/*
+	 * 32 instruction = 128 bytes
+	 */
+#ifdef CONFIG_64BIT
+	memcpy((void *)ebase + 0x80, tlb_handler_stub, 0x80); /* XTLB exception */
+#else
+	memcpy((void *)ebase, tlb_handler_stub, 0x80); /* TLB exception */
+#endif
+}
+
+#else
+
+static void __cpuinit __attribute__((unused)) build_r4000_tlb_refill_handler_stub(void) { }
+
+#endif /* defined(CONFIG_MAPPED_KERNEL) */
+
 /*
  * 128 instructions for the fastpath handler is generous and should
  * never be exceeded.
@@ -1592,7 +1735,7 @@ build_pte_present(u32 **p, struct uasm_reloc **r,
 {
 	int t = scratch >= 0 ? scratch : pte;
 
-	if (cpu_has_rixi) {
+	if (kernel_uses_smartmips_rixi) {
 		if (use_bbit_insns()) {
 			uasm_il_bbit0(p, r, pte, ilog2(_PAGE_PRESENT), lid);
 			uasm_i_nop(p);
@@ -1850,7 +1993,7 @@ build_r4000_tlbchange_handler_head(u32 **p, struct uasm_label **l,
 	build_get_pgde32(p, wr.r1, wr.r2); /* get pgd in ptr */
 #endif
 
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
+#ifdef CONFIG_HUGETLB_PAGE
 	/*
 	 * For huge tlb entries, pmd doesn't contain an address but
 	 * instead contains the tlb pte. Check the PAGE_HUGE bit and
@@ -1882,7 +2025,21 @@ build_r4000_tlbchange_handler_tail(u32 **p, struct uasm_label **l,
 	uasm_i_ori(p, ptr, ptr, sizeof(pte_t));
 	uasm_i_xori(p, ptr, ptr, sizeof(pte_t));
 	build_update_entries(p, tmp, ptr);
+#ifdef CONFIG_NLM_XLP
+	uasm_i_tlbp(p);
+	uasm_i_ehb(p);
+	uasm_i_mfc0(p, ptr, C0_INDEX);
+	uasm_il_bltz(p, r, ptr, label_r4000_write_probe_fail);
+	uasm_i_nop(p);
+#endif
 	build_tlb_write_entry(p, l, r, tlb_indexed);
+#ifdef CONFIG_NLM_XLP
+	uasm_il_b(p, r, label_leave);
+	uasm_i_nop(p);
+
+	uasm_l_r4000_write_probe_fail(l, *p);
+	build_tlb_write_entry(p, l, r, tlb_random);
+#endif
 	uasm_l_leave(l, *p);
 	build_restore_work_registers(p);
 	uasm_i_eret(p); /* return from trap */
@@ -1922,7 +2079,7 @@ static void __cpuinit build_r4000_tlb_load_handler(void)
 	if (m4kc_tlbp_war())
 		build_tlb_probe_entry(&p);
 
-	if (cpu_has_rixi) {
+	if (kernel_uses_smartmips_rixi) {
 		/*
 		 * If the page is not _PAGE_VALID, RI or XI could not
 		 * have triggered it.  Skip the expensive test..
@@ -1966,7 +2123,7 @@ static void __cpuinit build_r4000_tlb_load_handler(void)
 	build_make_valid(&p, &r, wr.r1, wr.r2);
 	build_r4000_tlbchange_handler_tail(&p, &l, &r, wr.r1, wr.r2);
 
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
+#ifdef CONFIG_HUGETLB_PAGE
 	/*
 	 * This is the entry point when build_r4000_tlbchange_handler_head
 	 * spots a huge page.
@@ -1976,7 +2133,7 @@ static void __cpuinit build_r4000_tlb_load_handler(void)
 	build_pte_present(&p, &r, wr.r1, wr.r2, wr.r3, label_nopage_tlbl);
 	build_tlb_probe_entry(&p);
 
-	if (cpu_has_rixi) {
+	if (kernel_uses_smartmips_rixi) {
 		/*
 		 * If the page is not _PAGE_VALID, RI or XI could not
 		 * have triggered it.  Skip the expensive test..
@@ -2066,7 +2223,7 @@ static void __cpuinit build_r4000_tlb_store_handler(void)
 	build_make_write(&p, &r, wr.r1, wr.r2);
 	build_r4000_tlbchange_handler_tail(&p, &l, &r, wr.r1, wr.r2);
 
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
+#ifdef CONFIG_HUGETLB_PAGE
 	/*
 	 * This is the entry point when
 	 * build_r4000_tlbchange_handler_head spots a huge page.
@@ -2121,7 +2278,7 @@ static void __cpuinit build_r4000_tlb_modify_handler(void)
 	build_make_write(&p, &r, wr.r1, wr.r2);
 	build_r4000_tlbchange_handler_tail(&p, &l, &r, wr.r1, wr.r2);
 
-#ifdef CONFIG_MIPS_HUGE_TLB_SUPPORT
+#ifdef CONFIG_HUGETLB_PAGE
 	/*
 	 * This is the entry point when
 	 * build_r4000_tlbchange_handler_head spots a huge page.
@@ -2220,6 +2377,9 @@ void __cpuinit build_tlb_refill_handler(void)
 		}
 		if (cpu_has_local_ebase)
 			build_r4000_tlb_refill_handler();
+#ifdef CONFIG_NLM_XLP
+		build_r4000_tlb_refill_handler_stub();
+#endif
 	}
 }
 
diff --git a/arch/mips/netlogic/Kconfig b/arch/mips/netlogic/Kconfig
index e0873a3..dfeba66 100644
--- a/arch/mips/netlogic/Kconfig
+++ b/arch/mips/netlogic/Kconfig
@@ -1,54 +1,203 @@
-if NLM_XLP_BOARD || NLM_XLR_BOARD
+config NLM_COMMON
+	bool 
+
+config NLM_XLR
+	bool
+
+config NLM_XLP
+	bool
+
+config NLMCOMMON_VM_DEBUG
+	bool "Debug VM System"
+	depends on NLM_COMMON
+	default n
+
+config NLMCOMMON_USERSEGV_DEBUG
+	bool "Debug User process SEGV crash"
+	depends on NLM_COMMON
+	default n
 
-if NLM_XLP_BOARD
-config DT_XLP_EVP
-	bool "Built-in device tree for XLP EVP boards"
+config NLMCOMMON_SMP_PREFIX
+	bool "Prefix the cpu number for every printk"
+	depends on NLM_COMMON
 	default y
+
+config NLMCOMMON_GLOBAL_TLB_SPLIT_ASID
+        bool "Enable Shared TLB in each CPU core"
+	depends on NLM_COMMON
+	default n
 	help
-	  Add an FDT blob for XLP EVP boards into the kernel.
-	  This DTB will be used if the firmware does not pass in a DTB
-	  pointer to the kernel.  The corresponding DTS file is at
-	  arch/mips/netlogic/dts/xlp_evp.dts
+		This option enables the sharing of TLBs by all the threads in core.
+		
 
-config DT_XLP_SVP
-	bool "Built-in device tree for XLP SVP boards"
+config NLMCOMMON_MAC
+	bool "Enable On-Chip Networking support"
+	depends on NLM_XLR
+	default y
+
+config NLMCOMMON_PCIX_GEN_DRIVER
+	bool
+
+config NLMCOMMON_IP_OVER_PCI
+        bool "Enable IP-Over-Pci Networking Support"
+        depends on NLM_XLR
+	select NLMCOMMON_PCIX_GEN_DRIVER
+        default n
+
+config NLMCOMMON_BOOT_OVER_PCI
+        bool "Enable Boot-Over-Pci Support"
+        depends on NLM_XLR
+	select NLMCOMMON_PCIX_GEN_DRIVER
+        default n
+
+config NLMCOMMON_CONSOLE_OVER_PCI 
+        bool "Enable Console Over PCI Support"
+        depends on NLM_XLR
+	select NLMCOMMON_PCIX_GEN_DRIVER
+        default n
+
+config NLMCOMMON_SPI4
+        bool 'Support for on-chip SPI4 interfaces'
+        depends on NLM_XLR
+        default y
+        help
+          With the Vitesse SPI4 daughter card, this driver will abstract the
+          20 SPI4 channels as Gigabit ethernet interfaces.
+
+config NLMCOMMON_PSB
+	bool "Enable support for ATX eval board bootloader"
+
+config NLMCOMMON_MSGRING_NAPI
+	bool "XLR/XLS message ring NAPI"
+	depends on NLM_XLR
 	default y
 	help
-	  Add an FDT blob for XLP VP boards into the kernel.
-	  This DTB will be used if the firmware does not pass in a DTB
-	  pointer to the kernel.  The corresponding DTS file is at
-	  arch/mips/netlogic/dts/xlp_svp.dts
+	  NAPI is a new driver API designed to reduce CPU and interrupt load
+	  when the driver is receiving lots of packets. This option enables 
+	  NAPI implementation for XLR/XLS message ring receive path.
 
-config NLM_MULTINODE
-	bool "Support for multi-chip boards"
-	depends on NLM_XLP_BOARD
-	default n
+	  See <file:Documentation/networking/NAPI_HOWTO.txt> for more
+	  information.
+
+	  If in doubt, say N.
+
+
+config NLMCOMMON_HW_BUFFER_MGMT
+	bool "Enable support for network buffer recycling via hardware"
+	depends on NLM_XLR
+	default y
 	help
-	  Add support for boards with 2 or 4 XLPs connected over ICI.
+	  Experimental addition to GMAC functionality allowing "recycling" of 
+          packet buffers by requesting HW to queue free elements upon Tx-complete 
+          back to the Rx free list.
+          This type of performance ehancement is important to forwarder-like
+          applications where fast path should stay as lean as possible.
+
+	  If in doubt, say N.
 
-if NLM_MULTINODE
-choice
-	prompt "Number of XLPs on the board"
-	default NLM_MULTINODE_2
+
+config NLMCOMMON_IP_FLOW_AFFINITY
+	bool "Enable support for IP flow affinity"
+	depends on NLM_XLR
+	default n
 	help
-	  In the multi-node case, specify the number of SoCs on the board.
+	  Experimental feature of GMAC driver guranteeing that IP flows are processed 
+          on logical CPUs corresponding to buckets assigned by packet classifier engine.
+          E.g. for XLR core #X, packets arriving to buckets 0 & 4 are processed by thread 0,
+          packets arriving to buckets 1 & 5 are processed by thread 1 and so on..
+          Such feature might be important for applications which require IP flows 
+          be seen on one logcal CPUs. Use of this feature involves performance cost.
+
+	  If in doubt, say N.
 
-config NLM_MULTINODE_2
-	bool "Dual-XLP board"
+config NLMCOMMON_IP_QUEUE_AFFINITY
+	bool "Enable multiprocess support for IP Queues"
+	depends on NLM_XLR && IP_NF_QUEUE
+	default n
 	help
-	  Support boards with upto two XLPs connected over ICI.
+	  Experimental feature extending IP Queues by allowing multiple user space 
+          processes to receive IP packets from the kernel. Client processes should come 
+          with CPU affinity set to single logical CPU and will get packets which are 
+          recieved and processed by network stack on that logical CPU.
+
+          Example:
+
+               Let's Process_1 has CPU affinity set to x
+               Let's Process_2 has CPU affinity set to y
+
+               Packet1 --> Interrupt on CPU x --> IP Queues --> Process_1
+               Packet1 --> Interrupt on CPU y --> IP Queues --> Process_2
+
+          This feature could be useful for packet processing architectures requiring user 
+          space handling of multiple IP flows.
+
+          If in doubt, say N.
 
-config NLM_MULTINODE_4
-	bool "Quad-XLP board"
+config MAPPED_KERNEL
+       bool "Mapped kernel" 
+       default y
+       help
+         Select this option if you want the kernel's code and data to 
+         be in mapped memory.  The kernel will be mapped using a 
+         single wired TLB entry, thus reducing the number of
+         available TLB entries by one.  Kernel modules will be able 
+         to use a more efficient calling convention.
+
+config PHYS_LOAD_ADDRESS
+       hex "Physical load address"
+       depends on MAPPED_KERNEL
+       default 0xffffffff84000000
+       help
+         The physical load address reflected as the program header
+         physical address in the kernel ELF image.
+
+config NLM_COMMON_LOAD_ADDRESS
+	hex "Netlogic Linux kernel start address"
+	depends on NLM_COMMON
+	default "0xffffffffc4000000"
+	help
+	  This is start address for the linux kernel. Default value
+          should be good for most of the applications unless specified 
+          explicitly: e.g. running Netlogic ToE requires kernel to be linked
+	  at address 0xffffffff86000000.
+ 
+config NLMCOMMON_PTP_SUPPORT
+	bool "1588PTP Support(enables prepad)"
+	depends on NLM_COMMON
+	default n
+	help
+	 Support for 1588 timing feature. Timestamps Rx/Tx packets. 
+         
+config NLM_VMIPS
+	bool "Virtual Mips support"
+	depends on NLM_COMMON
+	default n
 	help
-	  Support boards with upto four XLPs connected over ICI.
+	 The kseg0 and kseg1 unmapped access will become mapped. 
 
-endchoice
+config KSEG2_LOWMEM
+       bool "Mapped Lowmem"
+       depends on MAPPED_KERNEL && 64BIT
+       default y
 
-endif
-endif
+config NLM_NAS
+	bool "Enable NAS optimizations"
+	depends on NLM_COMMON
+	default n
+	help
+	  This options enables some optimizations done for XLS NAS solutions
 
-config NLM_COMMON
-	bool
+config READ_INHIBIT
+       bool "Enable Read Inhibit Semantics"
+       depends on NLM_XLP
+       default n
+
+config EXEC_INHIBIT
+       bool "Enable Exec Inhibit Semantics"
+       depends on NLM_XLP
+       default n
 
-endif
+config MIPS_XEN
+       bool "Enable Paravirtualization for Xen"
+       depends on NLM_XLP
+       default n
diff --git a/arch/mips/netlogic/Makefile b/arch/mips/netlogic/Makefile
index 7602d13..dbdb899 100644
--- a/arch/mips/netlogic/Makefile
+++ b/arch/mips/netlogic/Makefile
@@ -1,4 +1 @@
-obj-$(CONFIG_NLM_COMMON)	+=	common/
 obj-$(CONFIG_CPU_XLR)		+=	xlr/
-obj-$(CONFIG_CPU_XLP)		+=	xlp/
-obj-$(CONFIG_CPU_XLP)		+=	dts/
diff --git a/arch/mips/netlogic/boot/Makefile b/arch/mips/netlogic/boot/Makefile
new file mode 100644
index 0000000..3fceae5
--- /dev/null
+++ b/arch/mips/netlogic/boot/Makefile
@@ -0,0 +1,3 @@
+obj-y  = boot.o bootloader.o
+
+EXTRA_AFLAGS := $(CFLAGS)
diff --git a/arch/mips/netlogic/common/Makefile b/arch/mips/netlogic/common/Makefile
index 291372a..c4edf9f 100644
--- a/arch/mips/netlogic/common/Makefile
+++ b/arch/mips/netlogic/common/Makefile
@@ -1,3 +1,19 @@
-obj-y				+= irq.o time.o
-obj-$(CONFIG_SMP)		+= smp.o smpboot.o
+EXTRA_CFLAGS := $(CFLAGS) -DNLM_HAL_LINUX_KERNEL -Iarch/mips/include/asm/netlogic/hal
+obj-y :=   platform.o cpu_proc.o memory.o
 obj-$(CONFIG_EARLY_PRINTK)	+= earlycons.o
+
+obj-y 					+= msgring.o
+obj-y 					+= msgring_xls.o
+obj-y 					+= msgring_shared.o
+
+obj-$(CONFIG_NLM_XLP) 		+= nlm_hal.o
+
+obj-$(CONFIG_RAPIDIO)             	+= srio.o
+obj-$(CONFIG_NLMCOMMON_IP_OVER_PCI) 	+= dma.o
+obj-$(CONFIG_SMP)		+= smp.o smpboot.o
+
+EXTRA_AFLAGS := $(CFLAGS)
+
+clean-files += msgring.o msgring_xls.o msgring_shared.o
+clean-files += nlm_hal.o
+clean-files += srio.o dma.o smp.o platform.o cpu_proc.o
diff --git a/arch/mips/netlogic/common/cpu_proc.c b/arch/mips/netlogic/common/cpu_proc.c
new file mode 100644
index 0000000..6ef43ea
--- /dev/null
+++ b/arch/mips/netlogic/common/cpu_proc.c
@@ -0,0 +1,223 @@
+/***********************************************************************
+ * Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+ * reserved.
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ * *****************************#NETL_2#********************************/
+
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/poll.h>
+#include <linux/workqueue.h>
+#include <linux/proc_fs.h>
+#include <linux/cpumask.h>
+
+#include <asm/netlogic/proc.h>
+#include <asm/mach-netlogic/mmu.h>
+#include <asm/time.h>
+
+extern struct proc_dir_entry *nlm_root_proc;
+
+#ifndef CONFIG_BTLB_LOADER
+extern void nlm_update_tlb_stats(void *ignored);
+#endif
+
+struct xlr_cpu_stat {
+	unsigned long long msgring_pic_int;
+	unsigned long long msgring_int;
+	unsigned long long msgring_cycles;
+	unsigned long long fp_exp;
+	unsigned long long rdhwr_exp;
+};
+
+struct xlr_cpu_stat xlr_cpu_stats[32];
+__u64 xlr_cp2_exceptions[32];
+
+extern unsigned long long nlm_common_tlb_stats[];
+
+
+void netlogic_cpu_stat_update_rdhwr(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	xlr_cpu_stats[cpu].rdhwr_exp++;
+
+	preempt_enable();
+}
+
+void netlogic_cpu_stat_update_fp(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	xlr_cpu_stats[cpu].fp_exp++;
+
+	preempt_enable();
+}
+
+void netlogic_cpu_stat_update_msgring_int(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	xlr_cpu_stats[cpu].msgring_int++;
+
+	preempt_enable();
+}
+
+void netlogic_cpu_stat_update_msgring_cycles(__u32 cycles)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	xlr_cpu_stats[cpu].msgring_cycles += cycles;
+
+	preempt_enable();
+}
+
+void netlogic_cpu_stat_update_msgring_pic_int(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	xlr_cpu_stats[cpu].msgring_pic_int++;
+
+	preempt_enable();
+}
+
+static int xlr_cpu_proc_read(char *page, char **start, off_t off,
+			     int count, int *eof, void *data)
+{
+	int i = 0;
+	int len = 0;
+	off_t begin = 0;
+
+#ifndef CONFIG_BTLB_LOADER
+	/* Update the TLB stats from other CPUs */
+	on_each_cpu(nlm_update_tlb_stats, NULL, 1);
+#endif
+
+	len += sprintf(page + len, "CPU Frequency: %d HZ\n", (unsigned int)mips_hpt_frequency);
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	for(i=0;i<32;i++) {
+
+		if (!xlr_cp2_exceptions[i]) continue;
+
+			len += sprintf(page + len,
+				       "cop2_exp: %d %llx\n",
+				       i, (unsigned long long)xlr_cp2_exceptions[i]);
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;
+	}
+
+	for(i=0;i<32;i++) {
+
+		if (!xlr_cpu_stats[i].msgring_pic_int && !xlr_cpu_stats[i].msgring_int)
+			continue;
+
+			len += sprintf(page + len,
+				       "msgring: %d %llx %llx %llx\n",
+				       i, xlr_cpu_stats[i].msgring_pic_int,
+				       xlr_cpu_stats[i].msgring_int,
+				       xlr_cpu_stats[i].msgring_cycles);
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;
+	}
+
+	for(i=0;i<32;i++) {
+
+		if (!xlr_cpu_stats[i].fp_exp && !xlr_cpu_stats[i].rdhwr_exp)
+			continue;
+
+			len += sprintf(page + len,
+				       "cpu_exp: %d %llx %llx\n",
+				       i, xlr_cpu_stats[i].fp_exp,
+				       xlr_cpu_stats[i].rdhwr_exp);
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;
+	}
+
+	for (i = 0; i < 32; i++) {
+
+		if (!nlm_common_tlb_stats[i])
+			continue;
+
+		len += sprintf(page + len,
+			       "tlb: %d %llx \n",
+			       i, nlm_common_tlb_stats[i]);
+		if (!proc_pos_check(&begin, &len, off, count))
+			goto out;
+	}
+
+	*eof = 1;
+
+      out:
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;
+}
+
+static int nlm_cpu_proc_init(void)
+{
+	struct proc_dir_entry *entry;
+
+	entry = create_proc_read_entry("xlr_cpu", 0 /* def mode */ ,
+				       nlm_root_proc/* parent */ ,
+				       xlr_cpu_proc_read
+				       /* proc read function */ ,
+				       0	/* no client data */
+		);
+
+	if (!entry) {
+		printk("[%s]: Unable to create proc read entry for xlr_cpu!\n",
+		       __FUNCTION__);
+	}
+
+	return 0;
+}
+
+static void nlm_cpu_proc_exit(void)
+{
+}
+
+module_init(nlm_cpu_proc_init);
+module_exit(nlm_cpu_proc_exit);
diff --git a/arch/mips/netlogic/common/memory.c b/arch/mips/netlogic/common/memory.c
new file mode 100644
index 0000000..a7d5812
--- /dev/null
+++ b/arch/mips/netlogic/common/memory.c
@@ -0,0 +1,194 @@
+/***********************************************************************
+ * Copyright 2003-2010 Netlogic Microsystems (Netlogic). All rights
+ * reserved.
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ * *****************************#NETL_2#********************************/
+
+#include <linux/irqflags.h>
+#include <linux/module.h>
+#include <asm/mipsregs.h>
+#include <asm/page.h>
+#include <asm/mach-netlogic/mmu.h>
+
+/*
+ * the following structures and definitions are internal to this
+ * file and hence not defined in a header file
+ */
+typedef struct
+{
+	unsigned int size;
+	unsigned int mask;
+} tlbparam_t;
+
+tlbparam_t mipstlbs[] = 
+{ {  4 << 10,    0x0},
+  { 16 << 10,    0x3},
+  { 64 << 10,    0xf},
+  {256 << 10,   0x3f},
+  {  1 << 20,   0xff},
+  {  4 << 20,  0x3ff},
+  { 16 << 20,  0xfff},
+  { 64 << 20, 0x3fff},
+  {256 << 20, 0xffff},
+};
+
+#define NTLB (sizeof(mipstlbs)/sizeof(tlbparam_t))
+#define ULL unsigned long long
+#define PCIDEV_ADDRSPACE_START (0x3ULL << 30)
+
+static uint32_t align_size(uint32_t size)
+{
+	int i;
+
+	for (i = 0; (i < NTLB - 1) && (size > mipstlbs[i].size); ++i)
+		;
+	return mipstlbs[i].size;
+}
+
+static uint32_t tlb_mask(uint32_t size)
+{
+	int i;
+
+	size = align_size(size);
+
+	for (i = 0; i < NTLB && mipstlbs[i].size != size; ++i)
+		;
+	return mipstlbs[i].mask;
+}
+
+#define entrylo(paddr, attr) \
+	((((paddr & 0xffffffffffULL) >> 12) << 6) | (attr))
+
+
+/*
+ * External Function / APIs
+ */
+
+void setup_tlb(tlb_info_t *tlb)
+{
+	write_c0_pagemask(tlb_mask(tlb->pagesize) << 13);
+	write_c0_entryhi(tlb->vaddr & ~0x1fff);
+	write_c0_entrylo0(entrylo(tlb->paddr0, tlb->attr0));
+	write_c0_entrylo1(entrylo(tlb->paddr1, tlb->attr1));
+
+	if (tlb->wired) {
+		write_c0_index(read_c0_wired());
+		tlb_write_indexed();
+		write_c0_wired(read_c0_wired() + 1);
+	}
+	else {
+		tlb_write_random();
+	}
+}
+
+#ifdef CONFIG_MAPPED_KERNEL
+
+/*
+ * the following initialization is needed for 32-bit
+ * mapped kernels. It must be set 512 MB past the
+ * mapped start kseg2 address (0xc0000000).
+ * 0xc0000000 + 0x20000000(512MB) = 0xe0000000
+ */
+unsigned long __vmalloc_start = 0xe0000000;
+EXPORT_SYMBOL(__vmalloc_start);
+
+#endif
+
+#if defined(CONFIG_KSEG2_LOWMEM) && defined(CONFIG_KSEG2_LOWMEM)
+
+#include <asm/barrier.h>
+
+static volatile int max_low_pfn_set = 0;
+extern unsigned long max_low_pfn;
+
+void setup_mapped_kernel_tlbs(int firstpage, int primary_cpu)
+{
+	tlb_info_t tlb;
+
+    tlb.pagesize = LARGEST_TLBPAGE_SZ; /* we set up the largest pages */
+
+	/*
+	 * In NetLogic's Linux kernel, the second 256MB of physical
+	 * address space is reserved for device configuration and
+	 * is not mapped to DRAM (to imply memory as opposed to IO
+	 * device space). Hence the attribute of the second part of
+	 * the first wired entry is invalid, while the both part of
+	 * other wired entries are symmetric. We handle the above
+	 * difference through the following unseemly if condition
+	 */
+	if (firstpage) {
+		tlb.vaddr = XKSEG;
+		tlb.paddr1 = tlb.paddr0 = 0;
+		tlb.attr0 = ((_CACHE_CACHABLE_COW |_PAGE_DIRTY |  _PAGE_VALID | _PAGE_GLOBAL) >> ENTRYLO_PFN_SHIFT);
+		tlb.attr1 = _PAGE_GLOBAL >> ENTRYLO_PFN_SHIFT;
+		tlb.wired = TRUE;
+		setup_tlb(&tlb);
+	}
+	else {
+		/*
+		 * the primary cpu reads the memory map and records
+		 * the highest page frame number. Secondary cpus
+		 * must wait till the variable max_low_pfn is set
+		 */
+		if (!primary_cpu)
+			while (!max_low_pfn_set)
+				;
+
+		tlb.vaddr = XKSEG + 2 * LARGEST_TLBPAGE_SZ; 
+		tlb.paddr0 = 2 * LARGEST_TLBPAGE_SZ;
+		for (; tlb.paddr0 < (max_low_pfn << PAGE_SHIFT);
+			 tlb.paddr0 += 2 * tlb.pagesize, tlb.vaddr += 2 * tlb.pagesize) {
+			/*
+			 * Skip 3 - 3.5GB range (PCI device space)
+			 */
+			if (tlb.paddr0 == PCIDEV_ADDRSPACE_START)
+				continue;
+			tlb.paddr1 = tlb.paddr0 + tlb.pagesize;
+			tlb.attr1 = tlb.attr0 = ((_CACHE_CACHABLE_COW |_PAGE_DIRTY |  _PAGE_VALID | _PAGE_GLOBAL) >> ENTRYLO_PFN_SHIFT);
+			tlb.wired = TRUE;
+			setup_tlb(&tlb);
+		}
+		if (primary_cpu)
+			__vmalloc_start = tlb.vaddr;
+	}
+}
+
+unsigned long recalculate_max_low_pfn(unsigned long max_low_pfn)
+{
+	/* 
+	 * truncate max_low_pfn to 512MB boundary as largest tlb
+	 * pages are used to minimize the number of wired entries
+	 */
+	if ((max_low_pfn << PAGE_SHIFT) >= (2ULL * LARGEST_TLBPAGE_SZ))
+		max_low_pfn = PFN_DOWN((uint64_t)(max_low_pfn << PAGE_SHIFT) & ~((2ULL * LARGEST_TLBPAGE_SZ) - 1));
+	max_low_pfn_set = TRUE;
+	__sync();
+	
+	return max_low_pfn;
+}
+
+#else
+
+void setup_mapped_kernel_tlbs(int index, int secondary_cpu) { }
+unsigned long recalculate_max_low_pfn(unsigned long max_low_pfn) {return max_low_pfn;}
+
+#endif /* #if defined(CONFIG_KSEG2_LOWMEM) && defined(CONFIG_KSEG2_LOWMEM) */
diff --git a/arch/mips/netlogic/common/nlm_hal.c b/arch/mips/netlogic/common/nlm_hal.c
new file mode 100644
index 0000000..0c51f96
--- /dev/null
+++ b/arch/mips/netlogic/common/nlm_hal.c
@@ -0,0 +1,1584 @@
+
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * http://www.gnu.org/licenses/gpl-2.0.txt
+ * or the Broadcom license below:
+
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_4# */
+
+
+
+/**
+* @defgroup hal_overview Hardware Abstraction Layer APIs
+* @brief HAL is the lowest API layer provided in the XLP SDK.
+*
+* HAL APIs provide register level access, configuration, and initialization to HyperExec. HAL is primarily used to implement the HyperExec library, as well as to implement OS level features such as kernel drivers or BSPs. <br>
+*
+*/
+
+/**
+* @defgroup hal Generic Hardware Abstraction Layer APIs
+* @brief This section describes the generic and miscellaneous HAL APIs. <br>
+*
+* The generic HAL APIs provide the rudimentary functions for XLP register access.
+*
+* <b>Source:</b> libraries/hal/nlm_hal.c <br>
+* <b>Header:</b> hyperexec/srcs/drivers/hal/nlm_hal_fmn.h
+* @ingroup hal_overview
+*/
+
+/**
+* @defgroup hal_nae NAE Hardware Abstraction Layer APIs
+* @brief This section describes the NAE(Network Acceleration Engine) HAL APIs.<br>
+*
+* The NAE HAL APIs provide accses to all aspects of networking with the NAE, including NAE programming, POE programming, MAC programming, and external PHY access.
+*
+* <b>Source:</b> libraries/hal/nlm_hal.c <br>
+* <b>Header:</b> hyperexec/srcs/drivers/hal/nlm_hal.h
+* @ingroup hal_overview
+*/
+
+/**
+* @defgroup hal_sae SAE Hardware Abstraction Layer APIs
+* @brief This section describes the SAE(Security Acceleration Engine) HAL APIs <br>
+*
+* The SAE HAL APIs configure the SAE for application usage.
+*
+* <b>Source:</b> libraries/hal/nlm_hal.c <br>
+* <b>Header:</b> hyperexec/srcs/drivers/hal/nlm_hal_sae.h
+* @ingroup hal_overview
+*/
+
+/**
+* @defgroup hal_fmn FMN Hardware Abstraction Layer APIs
+* @brief This section describes the FMN(Fast Messaging Network) HAL APIs <br>
+*
+* The FMN HAL APIs configure and initialize the FMN (output queue carving and credits), as well as provide the fundamental messaging APIs.
+*
+* <b>Source:</b> libraries/hal/nlm_hal.c <br>
+* <b>Header:</b> hyperexec/srcs/drivers/hal/nlm_hal_fmn.h
+* @ingroup hal_overview
+*/
+#include "nlm_hal.h"
+#include "nlm_hal_fmn.h"
+#include "nlm_hal_nae.h"
+#include "nlm_hal_crypto.h"
+#include "nlm_hal_xlp_dev.h"
+#include "nlm_hal_sys.h"
+#if 0
+#include "libfdt.h"
+#include "fdt_helper.h"
+#endif
+
+/* These addresses are computed by the nlm_hal_init() */
+unsigned long xlp_io_base;
+unsigned long xlp_fmn_base[NLM_MAX_NODES];
+unsigned long xlp_nae_base[NLM_MAX_NODES];
+unsigned long xlp_sae_base[NLM_MAX_NODES];
+unsigned long xlp_rsa_base;
+unsigned long xlp_mac_base[NLM_MAX_NODES];
+unsigned long xlp_poe_base_pcie[NLM_MAX_NODES];
+unsigned long xlp_poe_base_pcim[NLM_MAX_NODES];
+unsigned long xlp_sys_base[NLM_MAX_NODES];
+unsigned long xlp_regex_base_pcie;
+unsigned long xlp_regex_base_pcim;
+
+struct nlm_node_config  nlm_node_cfg;
+
+static int reg_num_phys;
+void sgmii_scan_phys(int node);
+void  nlm_hal_sata_firmware_init(void);
+void register_phy(int node, int inf, int* hw_portid);
+
+static int mvl_get_phy_status(struct nlm_hal_ext_phy *phy, struct nlm_hal_mii_info* mii_info, int node);
+static void mvl_start_an(struct nlm_hal_ext_phy *phy, int node);
+static void mvl_init_phy(struct nlm_hal_ext_phy *phy, int node);
+
+static int  bcm_get_phy_status(struct nlm_hal_ext_phy *phy, struct nlm_hal_mii_info* mii_info, int node);
+static void bcm_start_an(struct nlm_hal_ext_phy *phy, int node);
+static void bcm_init_phy(struct nlm_hal_ext_phy *phy, int node);
+
+static int  xmc_get_phy_status(struct nlm_hal_ext_phy *phy, struct nlm_hal_mii_info* mii_info, int node);
+static void xmc_start_an(struct nlm_hal_ext_phy *phy, int node);
+static void xmc_init_phy(struct nlm_hal_ext_phy *phy, int node);
+
+void nlm_hal_init_ext_phy(int node, int inf);
+void nlm_hal_config_sgmii_if(int node, int inf);
+
+struct nlm_hal_ext_phy * get_phy_info(int inf);
+#define MAX_PHYS 18
+/*PHYs */
+struct nlm_hal_ext_phy  known_ext_phys[] = {
+		{"mvs103656", 0xc97, 0, 0, 0, mvl_get_phy_status, mvl_start_an, mvl_init_phy},
+		{"bcm5461s", 0x60c1, 0, 0, 0, bcm_get_phy_status, bcm_start_an, bcm_init_phy},
+		{"bcm5482", 0xbcb2, 0, 0, 0, xmc_get_phy_status, xmc_start_an, xmc_init_phy},
+		{"bcm5416", 0x5e74, 0, 0, 0, bcm_get_phy_status, bcm_start_an, bcm_init_phy},
+		{"", 0, 0, 0, 0, NULL, NULL, NULL}
+};
+
+static struct nlm_hal_ext_phy regs_ext_phys[MAX_PHYS];
+
+static __inline__ unsigned int power_on_reset_cfg(void)
+{
+	return nlh_read_cfg_reg32(0x18035104);
+}
+
+#define PCI_MEM_BAR_0 0x4
+#define PCIE_CONTROL_0 0x240
+
+#include <asm/netlogic/haldefs.h>
+#include <asm/netlogic/xlp-hal/iomap.h>
+#include <asm/netlogic/xlp-hal/xlp.h>
+#include <asm/netlogic/xlp-hal/pic.h>
+#include <asm/netlogic/xlp-hal/sys.h>
+
+/* These addresses are computed by the nlm_hal_init() */
+uint64_t nlm_io_base;
+uint64_t nlm_sys_base;
+uint64_t nlm_pic_base;
+
+/* Main initialization */
+void nlm_hal_init(void)
+{
+	nlm_io_base = CKSEG1ADDR(XLP_DEFAULT_IO_BASE);
+	nlm_sys_base = nlm_get_sys_regbase(0);	/* node 0 */
+	nlm_pic_base = nlm_get_pic_regbase(0);	/* node 0 */
+}
+/**
+* @brief nlm_hal_xlp_pcie_rc_init function is used to initialize the XLP PCIE controllers configured in RC mode.
+*
+* @return
+*  - Returns no value.
+*
+* @ingroup hal
+*
+*/
+__inline__ void nlm_hal_xlp_pcie_rc_init(void)
+{
+	int num_pcie = 4; /* Number of PCIe controllers */
+	unsigned long base = 0x18000000;
+	int dev = 1;
+	int pcie = 0;
+
+	unsigned int pciemode = (power_on_reset_cfg() >> 19) & 0xf;
+
+	for (pcie = 0; pcie < num_pcie; pcie++) {
+		unsigned long addr;
+		unsigned int val;
+
+		if (!(pciemode & (1 << pcie)))
+			continue;
+
+		addr = base + (dev << 15) + (pcie << 12);
+
+		val = nlm_hal_read_32bit_reg(addr, PCIE_CONTROL_0);
+		val |= (1 << 21); /* BAR mask enable */
+		nlm_hal_write_32bit_reg(addr, PCIE_CONTROL_0, val);
+
+		nlm_hal_write_32bit_reg(addr, PCI_MEM_BAR_0, 0x0);
+	}
+}
+
+/* PCI Enumeration */
+__inline__ void nlm_hal_enumerate_pci(void)
+{
+}
+
+#ifndef NLM_HAL_XLOADER
+/* Basic Reg access
+ */
+
+/**
+* @brief nlm_hal_read_16bit_reg function is used to read 16-bit registers (e.g. CPLD)
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+*
+* @return
+*  - 16bit register value
+*
+* @sa nlm_hal_write_16bit_reg, nlm_hal_read_32bit_reg, nlm_hal_write_32bit_reg, nlm_hal_read_64bit_reg, nlm_hal_write_64bit_reg??
+* @ingroup hal
+*
+*/
+__inline__ uint16_t nlm_hal_read_16bit_reg(uint64_t base, uint32_t index){
+    return nlh_read_cfg_reg16(base + (index << 1));
+}
+/**
+* @brief nlm_hal_write_16bit_reg function is used to write 16-bit registers (e.g. CPLD)
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+* @param [in] val Register value
+*
+* @return
+*  - none
+*
+* @sa nlm_hal_read_16bit_reg, nlm_hal_read_32bit_reg, nlm_hal_write_32bit_reg, nlm_hal_read_64bit_reg, nlm_hal_write_64bit_reg??
+* @ingroup hal
+*
+*/
+__inline__ void nlm_hal_write_16bit_reg(uint64_t base, uint32_t index, uint16_t val){
+    nlh_write_cfg_reg16(base +  (index << 1) , val);
+}
+
+/**
+* @brief nlm_hal_read_32bit_reg function is used to read 32bit registers
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+*
+* @return
+*  - 32bit register value
+*
+* @sa nlm_hal_write_32bit_reg, nlm_hal_read_64bit_reg, nlm_hal_write_64bit_reg
+* @ingroup hal
+*
+*/
+__inline__ uint32_t nlm_hal_read_32bit_reg(uint64_t base, int index)
+{
+	return nlh_read_cfg_reg32(base + (index << 2));
+}
+
+/**
+* @brief nlm_hal_write_32bit_reg function is used to write 32bit registers
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+* @param [in] val Register value
+*
+* @return
+*  - none
+*
+* @sa nlm_hal_read_32bit_reg, nlm_hal_read_64bit_reg, nlm_hal_write_64bit_reg
+* @ingroup hal
+*
+*/
+__inline__ void nlm_hal_write_32bit_reg(uint64_t base, int index, uint32_t val)
+{
+	nlh_write_cfg_reg32(base +  (index << 2) , val);
+}
+
+/**
+* @brief nlm_hal_read_64bit_reg function is used to read 64bit registers
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+*
+* @return
+*  - 64bit register value
+*
+* @sa nlm_hal_write_32bit_reg, nlm_hal_read_32bit_reg, nlm_hal_write_64bit_reg
+* @ingroup hal
+*
+*/
+__inline__ uint64_t nlm_hal_read_64bit_reg(uint64_t base, int index)
+{
+	return nlh_read_cfg_reg64(base + (index << 3));
+}
+/**
+* @brief nlm_hal_read_64bit_reg function is used to write 64bit registers
+*
+* @param [in] base Physical address where the register space starts
+* @param [in] index Register Index
+* @param [in] val Register value
+*
+* @return
+*  - none
+*
+* @sa nlm_hal_write_32bit_reg, nlm_hal_read_32bit_reg, nlm_hal_read_64bit_reg
+* @ingroup hal
+*
+*/
+__inline__ void nlm_hal_write_64bit_reg(uint64_t base, int index, uint64_t val)
+{
+	nlh_write_cfg_reg64(base +  (index << 3) , val);
+}
+#endif /*NLM_HAL_XLOADER*/
+/*
+ *    Generic Devices
+ */
+/**
+* @brief nlm_hal_get_dev_base function is used to get device base address
+*
+* @param [in] node Node ID
+* @param [in] bus Bus ID
+* @param [in] dev Device ID
+* @param [in] func Function ID
+*
+* @return
+*  - Physical address of the base address for a given (node, bus, device, function) combination
+*
+* @ingroup hal
+*
+*/
+__inline__ uint64_t nlm_hal_get_dev_base(int node, int bus, int dev, int func)
+{
+	uint64_t base = xlp_io_base & 0x1fffffff;
+
+	return (uint64_t)  (base +
+			    (bus << 20) +
+			    (dev << 15) +
+			    (node*8 << 15) +
+			    (func << 12));
+}
+
+/*
+ *     FMN
+ */
+/**
+* @brief nlm_hal_send_msg4 function is a non-blocking API used to send a three entry message to a mailbox. Does not retry the send message. Performs a sync before sending.
+*
+* @param [in] dst Destination Message Queue number
+* @param [in] code 8b SW code to send with the message
+* @param [in] data0 64b data value for the first message
+* @param [in] data1 64b data value for the second message
+* @param [in] data2 64b data value for the third message
+* @param [in] data3 64b data value for the fourth message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+*
+* @ingroup hal_fmn
+*
+*/
+__inline__ uint32_t nlm_hal_send_msg4(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1, uint64_t data2, uint64_t data3)
+{
+	return nlh_send_msg4(dst, code, data0, data1, data2, data3);
+}
+
+/**
+* @brief nlm_hal_send_msg3 function is a non-blocking API used to send a three entry message to a mailbox. Does not retry the send message. Performs a sync before sending.
+*
+* @param [in] dst Destination Message Queue number
+* @param [in] code 8b SW code to send with the message
+* @param [in] data0 64b data value for the first message
+* @param [in] data1 64b data value for the second message
+* @param [in] data2 64b data value for the third message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+*
+* @ingroup hal_fmn
+*
+*/
+__inline__ uint32_t nlm_hal_send_msg3(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1, uint64_t data2)
+{
+	return nlh_send_msg3(dst, code, data0, data1, data2);
+}
+
+/**
+* @brief nlm_hal_send_msg2 function is a non-blocking API used to send a two entry message to a mailbox. Will retry the message send 16 times. Performs a sync before sending.
+*
+* @param [in] dst Destination Message Queue number
+* @param [in] code 8b SW code to send with the message
+* @param [in] data0 64b data value for the first message
+* @param [in] data1 64b data value for the second message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+*
+* @ingroup hal_fmn
+*
+*/
+__inline__ uint32_t nlm_hal_send_msg2(uint32_t dst, uint32_t code, uint64_t data0, uint64_t data1)
+{
+	return nlh_send_msg2(dst, code, data0, data1);
+}
+/**
+* @brief nlm_hal_send_msg1 function is a non-blocking API used to send a single entry message to a mailbox. Will retry the message send 16 times. Performs a sync before sending.
+*
+* @param [in] dst Destination Message Queue number
+* @param [in] code 8b SW code to send with the message
+* @param [in] data0 64b data value for the single message
+*
+* @return
+*  - 0 on success, TxMsgStatus register on failure
+*
+* @ingroup hal_fmn
+*
+*/
+__inline__ uint32_t nlm_hal_send_msg1(uint32_t dst, uint32_t code, uint64_t data0)
+{
+	return nlh_send_msg1(dst, code, data0);
+}
+/**
+* @brief nlm_hal_recv_msg2 function is used to receive a two entry message from a VC of the CPU. Size should be used to determine how many of msg0-msg1 have valid data and if there were more messages available.
+*
+* @param [in] vc VC mailbox of the CPU (1 to 4)
+* @param [out] src_id Source Message Queue Number
+* @param [out] size # of messages that were in this received message (1 to 4)
+* @param [out] code 8b SW code of the received message
+* @param [out] msg0 64b data value for the first received message
+* @param [out] msg1 64b data value for the second received message
+*
+* @return
+*  - "0" on receive success, "-1" on failure
+*
+* @ingroup hal_fmn
+*
+*/
+__inline__ uint32_t nlm_hal_recv_msg2(uint32_t dst, uint32_t *src, uint32_t *size, uint32_t *code, uint64_t *data0, uint64_t *data1)
+{
+	return nlh_recv_msg2(dst, src, size, code, data0, data1);
+}
+/**
+* @brief nlm_hal_recv_msg1 function is used to receive a single entry message from a VC of the CPU. Size should be used to determine how other 64b messages were available with data.
+*
+* @param [in] dst VC mailbox of the CPU (1 to 4)
+* @param [out] src Source Message Queue Number
+* @param [out] size # of messages returned (1 to 4)
+* @param [out] code 8b SW code of the received message
+* @param [out] data0 64b data value for the received message
+*
+* @return
+*  - "0" on receive success, "-1" on failure
+*
+* @ingroup hal_fmn
+*
+*/
+__inline__ uint32_t nlm_hal_recv_msg1(uint32_t dst, uint32_t *src, uint32_t *size, uint32_t *code, uint64_t *data0)
+{
+	return nlh_recv_msg1(dst, src, size, code, data0);
+}
+
+__inline__ int nlm_hal_is_xlp_a0(void)
+{
+	/* XXX: read register to determine stepping */
+	return 1;
+}
+
+__inline__ int nlm_hal_is_xlp_le(void)
+{
+	unsigned int pwronrst = power_on_reset_cfg();
+	int little_endian = ((pwronrst & (1 << 5)) == 0);
+	return little_endian;
+}
+
+#define fdt32_to_cpu(x) be32_to_cpu(x)
+
+enum prop_type {
+        PROP_STR = 0,
+        PROP_CELL
+};
+
+int copy_fdt_prop(void *fdt, const char *path, const char *prop,
+			enum prop_type type, void *buf, int len)
+{
+	return 0;
+}
+
+int fdt_path_offset(const void *fdt, const char *path)
+{
+	return 0;
+}
+
+const void *fdt_getprop(const void *fdt, int nodeoffset,
+			const char *name, int *lenp)
+{
+	return 0;
+}
+
+
+/*
+ * @brief nlm_hal_get_fdt_freq function is used to read the frequency specified in the fdt file.
+ *
+ * @param [in]  pointer to the fdt file
+ * @param [in]  block for whych we need the frequency.
+ *
+ * @return
+ * actual frequency on success & "-1" if the frency is not specified in fdt file.
+ *
+ * @ingroup hal
+ *
+ **/
+int nlm_hal_get_fdt_freq(void *fdt, int type)
+{
+	int freq;
+	int ret = 250;  /* Set the default frequency to 250 */
+	char path_str[50];
+
+	sprintf(path_str,"/frequency-config");
+
+	switch(type)
+	{
+	case NLM_NAE:
+		if(copy_fdt_prop(fdt, path_str, "nae", PROP_CELL, &freq, sizeof(uint32_t)) < 0)
+			nlm_print("Unable to find the frequency in the FDT file for type:%d, \
+					using the default value\n", type);
+		else
+			ret = freq;
+#ifdef FREQ_DEBUG
+		nlm_print("nae frequency is %d\n", ret);
+#endif
+		break;
+	case NLM_RSA:
+		if(copy_fdt_prop(fdt, path_str, "rsa", PROP_CELL, &freq, sizeof(uint32_t)) < 0)
+			nlm_print("Unable to find the frequency in the FDT file for type:%d, \
+					using the default value\n", type);
+		else
+			ret = freq;
+#ifdef FREQ_DEBUG
+		nlm_print("rsa frequency is %d\n", ret);
+#endif
+		break;
+	case NLM_SAE:
+		if(copy_fdt_prop(fdt, path_str, "sae", PROP_CELL, &freq, sizeof(uint32_t)) < 0)
+			nlm_print("Unable to find the frequency in the FDT file for type:%d, \
+					using the default value\n", type);
+		else
+			ret = freq;
+#ifdef FREQ_DEBUG
+		nlm_print("sae frequency is %d\n", ret);
+#endif
+		break;
+	case NLM_DTRE:
+		if(copy_fdt_prop(fdt, path_str, "dtre", PROP_CELL, &freq, sizeof(uint32_t)) < 0)
+			nlm_print("Unable to find the frequency in the FDT file for type:%d, \
+					using the default value\n", type);
+		else
+			ret = freq;
+#ifdef FREQ_DEBUG
+		nlm_print("sae frequency is %d\n", ret);
+#endif
+		break;
+	case NLM_CDE:
+		if(copy_fdt_prop(fdt, path_str, "cde", PROP_CELL, &freq, sizeof(uint32_t)) < 0)
+			nlm_print("Unable to find the frequency in the FDT file for type:%d, \
+					using the default value\n", type);
+		else
+			ret = freq;
+#ifdef FREQ_DEBUG
+		nlm_print("sae frequency is %d\n", ret);
+#endif
+		break;
+	default:
+		{
+			nlm_print("Frequency not specified in the FDT file for type:%d", type);
+			ret = -1;
+		}
+	}
+	return ret;
+}
+
+/*
+ * Naming convention: NLM_HAL_XXX for external API
+ *                    NLH_XXX for internal naming of NL HAL
+ */
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/types.h>
+#include <linux/module.h>
+
+EXPORT_SYMBOL(xlp_io_base);
+EXPORT_SYMBOL(xlp_fmn_base);
+EXPORT_SYMBOL(xlp_nae_base);
+EXPORT_SYMBOL(xlp_mac_base);
+EXPORT_SYMBOL(xlp_sys_base);
+EXPORT_SYMBOL(xlp_sae_base);
+EXPORT_SYMBOL(xlp_rsa_base);
+EXPORT_SYMBOL(xlp_poe_base_pcie);
+EXPORT_SYMBOL(xlp_poe_base_pcim);
+
+EXPORT_SYMBOL(nlm_hal_init);
+EXPORT_SYMBOL(nlm_hal_read_32bit_reg);
+EXPORT_SYMBOL(nlm_hal_write_32bit_reg);
+EXPORT_SYMBOL(nlm_hal_send_msg1);
+EXPORT_SYMBOL(nlm_hal_recv_msg1);
+EXPORT_SYMBOL(nlm_hal_send_msg2);
+EXPORT_SYMBOL(nlm_hal_recv_msg2);
+EXPORT_SYMBOL(nlm_hal_send_msg3);
+EXPORT_SYMBOL(nlm_hal_send_msg4);
+int irt_irq_table[32][4];
+#else
+#include "nlm_hal_pic.h"
+/*
+   This is to map 160 irt entry to 64 interrupt vector
+   Each row has three elements
+   irq		shared     number of sharing
+   irq:  assigned irq number used in linux
+   shared:  0: this irq not shared,  1: this irq is shared
+   number of sharing:  if shared = 1,  this variable indicate number of irt line to shared the same irq
+   if shared = 0,  this should be 0.
+*/
+#define SHARED_IRQ	1
+#define NOT_SHARED	0
+
+int irt_irq_table[160][4]= {
+        {9,     1,      2,      0},     /*PICIRT_WD_0_INDEX         0	*/
+        {9,     1,      2,      0},     /*PICIRT_WD_1_INDEX         1	*/
+        {19,    1,      2,      0},     /*PICIRT_WD_NMI_0_INDEX     2	*/
+        {19,    1,      2,      0},     /*PICIRT_WD_NMI_1_INDEX     3	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_0_INDEX      4	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_1_INDEX      5	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_2_INDEX      6	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_3_INDEX      7	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_4_INDEX      8	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_5_INDEX      9	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_6_INDEX      10	*/
+        {10,    1,      8,      0},     /*PICIRT_TIMER_7_INDEX      11	*/
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(0),    12	*/
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(1),    13  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(2),    14  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(3),    15  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(4),    16  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(5),    17  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(6),    18  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(7),    19  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(8),    20  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(9),    21  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(10),   22  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(11),   23  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(12),   24  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(13),   25  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(14),   26  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(15),   27  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(16),   28  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(17),   29  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(18),   30  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(19),   31  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(20),   32  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(21),   33  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(22),   34  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(23),   35  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(24),   36  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(25),   37  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(26),   38  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(27),   39  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(28),   40  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(29),   41  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(30),   42  */
+        {59,    1,      32,     0},     /*PICIRT_MSG_Q_INDEX(31),   43  */
+        {49,    0,      0,      0},     /*PICIRT_MSG_0_INDEX,       44	*/
+        {48,    0,      0,      0},     /*PICIRT_MSG_1_INDEX,       45	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(0) 46  */
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(1) 47  */
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(2) 48	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(3) 49	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(4) 50	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(5) 51	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(6) 52	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(7) 53	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(8) 54	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(9) 55	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(10)56 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(11)57 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(12)58	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(13)59 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(14)60 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(15)61 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(16)62 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(17)63	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(18)64 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(19)65 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(20)66 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(21)67 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(22)68 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(23)69 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(24)70 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(25)71 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(26)72 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(27)73 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(28)74 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(29)75 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(30)76 	*/
+        {46,    1,      32,     0},     /*PICIRT_PCIE_MSIX_INDEX(31)77 	*/
+        {44,    0,      0,      0},     /*PICIRT_PCIE_LINK_INDEX(0) 78	*/
+        {43,    0,      0,      0},     /*PICIRT_PCIE_LINK_INDEX(1) 79	*/
+        {42,    0,      0,      0},     /*PICIRT_PCIE_LINK_INDEX(2) 80	*/
+        {41,    0,      0,      0},     /*PICIRT_PCIE_LINK_INDEX(3) 81	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(0)        82	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(1)        83	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(2)        84	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(3)        85	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(4)        86	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(5)        87	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(6)        88	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(7)        89	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(8)        90	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(9)        91	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(10)       92	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(11)       93	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(12)       94	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(13)       95	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(14)       96	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(15)       97	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(16)       98	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(17)       99	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(18)       100	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(19)       101	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(20)       102 */
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(21)       103	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(22)       104	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(23)       105	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(24)       106	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(25)       107	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(26)       108	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(27)       109	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(28)       110	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(29)       111	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(30)       112	*/
+        {58,    1,      32,     0},     /*PICIRT_NA_INDEX(31)       113	*/
+        {60,    0,      0,      0},     /*PICIRT_POE_INDEX          114	*/
+        {24,    1,      6,      0},     /*PICIRT_USB_INDEX(0)       115	*/
+        {25,    1,      6,      0},     /*PICIRT_USB_INDEX(1)       116	*/
+        {25,    1,      6,      0},     /*PICIRT_USB_INDEX(2)       117	*/
+        {24,    1,      6,      0},     /*PICIRT_USB_INDEX(3)       118	*/
+        {25,    1,      6,      0},     /*PICIRT_USB_INDEX(4)       119	*/
+        {25,    1,      6,      0},     /*PICIRT_USB_INDEX(5)       120	*/
+        {61,    0,      0,      0},     /*PICIRT_GDX_INDEX          121 */
+        {63,    0,      0,      0},     /*PICIRT_SEC_INDEX          122 */
+        {62,    0,      0,      0},     /*PICIRT_RSA_INDEX          123 */
+        {39,    1,      4,      0},     /*PICIRT_COMP_INDEX(0)      124 */
+        {39,    1,      4,      0},     /*PICIRT_COMP_INDEX(1)      125 */
+        {39,    1,      4,      0},     /*PICIRT_COMP_INDEX(2)      126 */
+        {39,    1,      4,      0},     /*PICIRT_COMP_INDEX(3)      127 */
+        {0,     0,      0,      0},     /*                          128 */
+        {37,    1,      3,      0},     /*PICIRT_ICC_0_INDEX        129  ICC - Inter Chip Coherency*/
+        {37,    1,      3,      0},     /*PICIRT_ICC_1_INDEX        130 */
+        {37,    1,      3,      0},     /*PICIRT_ICC_2_INDEX        131 */
+        {36,    0,      0,      0},     /*PICIRT_CAM_INDEX          132 */
+        {17,    0,      0,      0},     /*PICIRT_UART_0_INDEX       133 */
+        {18,    0,      0,      0},     /*PICIRT_UART_1_INDEX       134 */
+        {11,    1,      2,      0},     /*PICIRT_I2C_0_INDEX        135	*/
+        {11,    1,      2,      0},     /*PICIRT_I2C_1_INDEX        136	*/
+        {12,    1,      2,      0},     /*PICIRT_SYS_0              137	*/
+        {12,    1,      2,      0},     /*PICIRT_SYS_1              138	*/
+        {55,    0,      0,      0},     /*PICIRT_JTAG_INDEX         139	*/
+        {50,    0,      0,      0},     /*PICIRT_PIC                140	*/
+        {0,     0,      0,      0},     /*Reserved                  141	*/
+        {0,     0,      0,      0},     /*Reserved                  142	*/
+        {0,     0,      0,      0},     /*Reserved                  143 */
+        {0,     0,      0,      0},     /*Reserved        	    144	*/
+        {0,     0,      0,      0},     /*Reserved        	    145	*/
+        {13,    0,      0,      0},     /*PICIRT_GPIO_INDEX(0)      146	*/
+        {14,    0,      0,      0},     /*PICIRT_GPIO_INDEX(1)      147	*/
+        {15,    0,      0,      0},     /*PICIRT_GPIO_INDEX(2)      148	*/
+        {16,    0,      0,      0},     /*PICIRT_GPIO_INDEX(3)      149	*/
+        {20,    0,      0,      0},     /*PICIRT_NOR                150	*/
+        {21,    0,      0,      0},     /*PICIRT_NAND               151	*/
+        {22,    0,      0,      0},     /*PICIRT_SPI                152	*/
+        {23,    0,      0,      0},     /*PICIRT_MMC                153	*/
+        {54,    0,      0,      0},     /*PICIRT_NBU		    154	*/
+        {53,    0,      0,      0},     /*PICIRT_TCU                155	*/
+        {52,    0,      0,      0},     /*PICIRT_GCU                156	*/
+        {36,    1,      2,      0},     /*DDR3 DMC                  157 */
+        {36,    1,      2,      0},     /*DDR3 DMC		    158 */
+        {57,    0,      0,      0},     /*Trace Buffer	TCB	    159 */
+};
+
+
+/*
+  short find_irt_from_irq( int irq)
+
+  find irt number from irq
+  irq: input irq number,
+  return:  irt number,  if it is -1, indicate can't find irt line for irq number.
+*/
+int find_irt_from_irq( int irq)
+{
+        unsigned long long irt_pending0, irt_pending1, irt_pending2;
+        int base_irt, num_shared = 0, i,j;
+        uint64_t val;
+        uint64_t shared_mask;
+
+        if(irq <0 || irq >63)
+        {
+                return -1;
+        }
+        if(irq < 8)
+                return irq;
+
+        /*from base irt_irq_table, find base irt number, for shared irq, need figure out which is the*/
+        for ( i = 0; i < PIC_NUM_IRTS; i++)
+        {
+                if(irq == irt_irq_table[i][0])
+                {
+                        /* unshared irq*/
+                        if(irt_irq_table[i][1] == NOT_SHARED)
+                        {
+                                /* this is irt number we needed;*/
+                                return  i;
+                        }
+                        else if(irt_irq_table[i][1] == SHARED_IRQ)
+                        {
+                                /*if shared bit is 1,  this irq is shared by a number of irt line*/
+                                num_shared = irt_irq_table[i][2];
+                                break;
+                        }
+                }
+
+        }
+        base_irt = i;
+        if(num_shared == NOT_SHARED || base_irt == 160)
+                return -1;
+        /* for shared irq, need figure out which irt line produce this irq*/
+        /* we can determine it by look at the interrupt pending register*/
+
+        /*first scan col 4 of enabled field to see whether any IRT is enabled,*/
+        /*it could be just first time to register*/
+        for(j = 0; j < num_shared; j++)
+        {
+		shared_mask = (1ULL << num_shared) - 1;
+                if( irt_irq_table[base_irt][0] != irt_irq_table[base_irt + j][0])
+                        continue;
+
+                if(irt_irq_table[base_irt + j][3] == 1)
+                {
+                        val = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_IRT(base_irt + j));
+                        if(!(val & (1 << 31)))
+                        {
+                                /*this irt entry not enable yet*/
+                                return base_irt + j;
+
+                        }
+                        else
+                        {
+                                /*check pending register*/
+                                if(base_irt+j < 64)
+                                {
+                                        irt_pending0 = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_INT_PENDING0);
+                                        shared_mask  = shared_mask << base_irt;
+                                        irt_pending0 = irt_pending0 & shared_mask;
+                                        if(irt_pending0 & (1ULL << (base_irt + j)))
+                                                return (j + base_irt);
+                                }
+                                else if(base_irt + j >= 64 && base_irt + j < 128)
+                                {
+                                        irt_pending1 = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_INT_PENDING1);
+                                        shared_mask  = shared_mask << (base_irt - 64);
+                                        irt_pending1 = irt_pending1 & shared_mask;
+                                        if(irt_pending1 & (1ULL << (base_irt + j - 64)))
+                                                return (j + base_irt);
+
+                                }
+                                else if(base_irt+j > 128)
+                                {
+                                        irt_pending2 = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_INT_PENDING2);
+                                        shared_mask  = shared_mask << (base_irt - 128);
+                                        irt_pending2 = irt_pending2 & shared_mask;
+                                        if(irt_pending2 & (1ULL << (base_irt + j - 128)))
+                                                return (j + base_irt);
+                                }
+                        }
+                }
+        }
+
+        /*if we get here, means penging register is not set for all */
+        for(j = 0; j < num_shared ; j++)
+        {
+
+                if(irt_irq_table[base_irt+j][3] == 1)
+                        return (base_irt+j);
+        }
+        return -1;
+}
+
+
+int nlm_hal_request_shared_irq(int irt)
+{
+        uint64_t  val;
+
+        if(irt < 0 || irt > PIC_NUM_IRTS)
+                return -1;
+        irt_irq_table[irt][3] = 1;
+        val = nlm_hal_read_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt));
+        /* clear DB and DTE field */
+        val &= ~(0x3f << 20);
+        val |= (irt_irq_table[irt][0] << 20 | 1 << 31 | 1 << 28);
+        nlm_hal_write_pic_reg(nlm_hal_pic_offset(), PIC_IRT(irt),val);
+
+
+        return irt_irq_table[irt][0];
+}
+void nlm_hal_unrequest_shared_irq(int irt)
+{
+        if(irt < 0 || irt > PIC_NUM_IRTS)
+                return;
+        if(irt_irq_table[irt][3] == 1)
+                irt_irq_table[irt][3] = 0;
+        return;
+}
+
+
+unsigned long tlb_size_to_page_size(unsigned long size)
+{
+	if (size <= (4*1024)) return 4*1024;
+	if (size <= (16*1024)) return 16*1024;
+	if (size <= (64*1024)) return 64*1024;
+	if (size <= (256*1024)) return 256*1024;
+	if (size <= (1024*1024)) return 1024*1024;
+	if (size <= (4*1024*1024)) return 4*1024*1024;
+	if (size <= (16*1024*1024)) return 16*1024*1024;
+	if (size <= (64*1024*1024)) return 64*1024*1024;
+
+	return 256*1024*1024;
+}
+
+unsigned long tlb_size_to_mask(unsigned long size)
+{
+	if (size <= (4*1024)) return 0x0 << 13;
+	if (size <= (16*1024)) return 0x03 << 13;
+	if (size <= (64*1024)) return 0x0f << 13;
+	if (size <= (256*1024)) return 0x3f << 13;
+	if (size <= (1024*1024)) return 0xff << 13;
+	if (size <= (4*1024*1024)) return 0x3ff << 13;
+	if (size <= (16*1024*1024)) return 0xfff << 13;
+	if (size <= (64*1024*1024)) return 0x3fff << 13;
+
+	return 0xffff << 13;
+}
+#endif
+
+#ifdef PHY_DEBUG
+static void dump_phy_regs(int node, int inf)
+{
+}
+#endif
+
+/**
+* @brief nlm_hal_init_ext_phy function initializes the external PHY of an interface.
+*
+* @param [in] node Node number
+* @param [in] inf Interface number
+*
+* @return
+* 	- none
+*
+* @ingroup hal_nae
+*
+*/
+void nlm_hal_init_ext_phy(int node, int inf)
+{
+	struct nlm_hal_ext_phy *this_phy=NULL;
+	this_phy = get_phy_info(inf);
+	if(!this_phy)
+		return;
+	this_phy->ext_phy_init(this_phy, node);
+	return;
+}
+
+#if 0
+/* print various phy status registers */
+static void xmc_phy_status(struct nlm_hal_ext_phy *phy, int node)
+{
+	int status;
+	int bus = phy->ext_mdio_bus;
+	int phyaddr = phy->phy_addr;
+	int int_inf = phy->inf;
+
+	/*operating mode status reg */
+	nlm_hal_mdio_write(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr,  0x17, 0xf42);
+	status = nlm_hal_mdio_read(node, NLM_HAL_EXT_MDIO, bus, BLOCK_7, LANE_CFG, phyaddr,  0x15);
+	nlm_print("%s: operating mode status for phy %d = 0x%x \n", __func__, phyaddr, status);
+
+	status = nlm_hal_mdio_read(node, NLM_HAL_INT_MDIO, 0, BLOCK_7, LANE_CFG, int_inf, 0x1);
+	nlm_print("%s: nae %d  register 1= 0x%x \n", __func__, int_inf, status);
+
+
+}
+#else
+void xmc_phy_status(struct nlm_hal_ext_phy *phy, int node) {;}
+#endif
+
+/**
+* @brief xmc_init_phy function initializes an external BROADCOM 5482 PHY on the XMC board.
+*
+* @param[in] phy	:nlm_hal_ext_phy struct pointing to the BROADCOM PHY
+* @param [in] node Node number
+*
+* @return
+* 	- none
+*
+* @ingroup hal_nae
+*
+*/
+static void xmc_init_phy(struct nlm_hal_ext_phy *phy, int node)
+{
+	return;
+}
+
+/**
+* @brief bcm_init_phy function initializes an external BROADCOM PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the BROADCOM PHY
+* @param [in] node Node number
+*
+* @return
+* 	- none
+*
+* @ingroup hal_nae
+*
+*/
+static void bcm_init_phy(struct nlm_hal_ext_phy *phy, int node)
+{
+	return;
+}
+
+/**
+* @brief mvl_init_phy function initializes an external MARVELL PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the MARVELL PHY
+* @param [in] node Node number
+*
+* @return
+* 	- none
+*
+* @ingroup hal_nae
+*
+*/
+static void mvl_init_phy(struct nlm_hal_ext_phy *phy, int node)
+{
+}
+
+/**
+* @brief nlm_hal_ext_phy_an function enables auto-negotiation on an interface.
+*
+* @param [in] node Node number
+* @param [in] inf Interface on which to enable auto-negotiation
+*
+* @return
+* 	- none
+*
+* @ingroup hal_nae
+*
+*/
+void nlm_hal_ext_phy_an(int node, int inf)
+{
+	struct nlm_hal_ext_phy *this_phy=NULL;
+	this_phy = get_phy_info(inf);
+	if(!this_phy)
+		return;
+	this_phy->start_phy_an(this_phy, node);
+	return;
+}
+
+void nlm_hal_restart_an(int node, int inf)
+{
+}
+/**
+* @brief xmc_start_an function enables auto-negotiation on XMC board external BROADCOM PHY.
+*
+* @param[in] phy	:nlm_hal_ext_phy struct pointing to the BROADCOM PHY
+* @param [in] node Node number
+*
+* @return
+* 	- none
+*
+* @ingroup hal_nae
+*
+*/
+static void xmc_start_an(struct nlm_hal_ext_phy *phy, int node)
+{
+	return;
+}
+
+/**
+* @brief bcm_start_an function enables auto-negotiation on an external BROADCOM PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the BROADCOM PHY
+* @param [in] node Node number
+*
+* @return
+* 	- none
+*
+* @ingroup hal_nae
+*
+*/
+static void bcm_start_an(struct nlm_hal_ext_phy *phy, int node)
+{
+	return;
+}
+
+/**
+* @brief mvl_start_an function enables auto-negotiation on an external MARVELL PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the MARVELL PHY
+* @param [in] node Node number
+*
+* @return
+* 	- none
+*
+* @ingroup hal_nae
+*
+*/
+static void mvl_start_an(struct nlm_hal_ext_phy *phy, int node)
+{
+}
+
+int nlm_hal_status_ext_phy(int node, int inf, struct nlm_hal_mii_info* mii_info)
+{
+       struct nlm_hal_ext_phy *this_phy=NULL;
+       this_phy = get_phy_info(inf);
+       if(!this_phy)
+               return 0;
+       return this_phy->phy_get_status(this_phy, mii_info, node);
+}
+
+
+/**
+* @brief xmc_get_phy_status function returns the status of an interface from the XMC external BROADCOM PHY.
+*
+* @param[in] phy		:nlm_hal_ext_phy struct pointing to the BROADCOM PHY
+* @param[out] speed		:Link speed
+* @param[out] duplex	:Link duplex status
+* @param [in] node Node number
+*
+* @return
+* 	- 1 - Link up, 0 - Link Down
+*
+* @ingroup hal_nae
+*
+*/
+static int xmc_get_phy_status(struct nlm_hal_ext_phy *phy, struct nlm_hal_mii_info* mii_info, int node)
+{
+	return 0;
+}
+
+/**
+* @brief bcm_get_phy_status function returns the status of an interface from the external BROADCOM PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the BROADCOM PHY
+* @param [out] speed Link speed
+* @param [out] duplex Link duplex status
+* @param [in] node Node number
+*
+* @return
+* 	- 1 - Link up, 0 - Link Down
+*
+* @ingroup hal_nae
+*
+*/
+static int bcm_get_phy_status(struct nlm_hal_ext_phy *phy, struct nlm_hal_mii_info* mii_info, int node)
+{
+	return 0;
+}
+
+/**
+* @brief mvl_get_phy_status function returns the status of an interface from the external MARVELL PHY.
+*
+* @param [in] phy nlm_hal_ext_phy struct pointing to the MARVELL PHY
+* @param [out] speed Link speed
+* @param [out] duplex Link duplex status
+* @param [in] node Node number
+*
+* @return
+* 	- 1 - Link up, 0 - Link Down
+*
+* @ingroup hal_nae
+*
+*/
+static int mvl_get_phy_status(struct nlm_hal_ext_phy *phy, struct nlm_hal_mii_info* mii_info, int node)
+{
+		return 0;
+}
+
+/**
+* @brief get_phy_info function returns PHY information from the external PHY of an interface.
+*
+* @param [in] inf Interface number
+*
+* @return
+* 	- Pointer to external phy information structure
+* 	- NULL if no registered external phy exists for inf
+*
+* @ingroup hal_nae
+*
+*/
+struct nlm_hal_ext_phy* get_phy_info(int inf)
+{
+	struct nlm_hal_ext_phy *phy_info = NULL;
+	/*search through scanned and registered phys*/
+	int reg_idx=0;
+	for(; reg_idx<MAX_PHYS; reg_idx++){
+		if(regs_ext_phys[reg_idx].inf==inf){
+			phy_info = regs_ext_phys + reg_idx;
+			return phy_info;
+		}
+	}
+	/*nlm_print("Interface could not be initialised for inf=0x%x\n", inf); */
+	return NULL;
+}
+
+/**
+* @brief register_phy function registers external PHY information for an interface.
+*
+* @param [in] node Node number
+* @param [in] inf Interface number
+* @param [out] hw_portid PHY address of the external PHY attached to inf
+*
+* @return
+* 	- none
+*
+* @ingroup hal_nae
+*
+*/
+void register_phy(int node, int inf, int* hw_portid)
+{
+	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[node];
+	int i = 0;
+	int phy_addr, ext_mdio_bus;
+	for(i=0; nae_cfg->num_ports; i++){
+		if(nae_cfg->ports[i].hw_port_id == inf)
+		break;
+	}
+#ifdef CONFIG_N511
+        /* Hardcode here for now, rather than generating a new dts/dtb */
+        if (inf == 0x10) {
+          /* override dtb */
+          nae_cfg->ports[i].ext_phy_addr = 0x10;
+          nae_cfg->ports[i].ext_phy_bus = 0;
+        }
+        if (inf == 0x11) {
+          /* override dtb */
+          nae_cfg->ports[i].ext_phy_addr = 0x10;
+          nae_cfg->ports[i].ext_phy_bus = 1;
+        }
+#endif
+	phy_addr = nae_cfg->ports[i].ext_phy_addr;
+	ext_mdio_bus = nae_cfg->ports[i].ext_phy_bus;
+	/*nlm_print("register_phy with inf=0x%x phy_addr=0%x ext_mdio_bus=0x%x\n", inf, phy_addr, ext_mdio_bus); */
+
+	*hw_portid = phy_addr;
+	/* make a inf and hw_port id pair*/
+	for(i=0; i<reg_num_phys; i++){
+		if((*hw_portid) == regs_ext_phys[i].phy_addr){
+#ifdef CONFIG_N511
+                    if (ext_mdio_bus ==  regs_ext_phys[i].ext_mdio_bus) {
+                        regs_ext_phys[i].inf = inf;
+                        return;
+                    }
+#else
+			regs_ext_phys[i].inf = inf;
+			return;
+#endif
+		}
+	}
+	*hw_portid = -1;
+	nlm_print("Could not find the given interface\n");
+}
+
+/**
+* @brief sgmii_scan_phys function scans all possibel PHYs on the external MDIO busses and logs active ports.
+*
+* @param [in] node Node number
+*
+* @return
+* 	- none
+*
+* @ingroup hal_nae
+*
+*/
+void sgmii_scan_phys(int node)
+{
+}
+
+/* CDE SUPPORT
+ */
+/**
+* @brief nlm_hal_set_cde_freq function sets the frequency of the CDE block.
+*
+* @param [in] node Node number
+* @param [in] freq Frequency to set in MHz
+*
+* @return
+* 	- none
+*
+* @ingroup hal
+*
+*/
+void nlm_hal_set_cde_freq(int node, int freq)
+{
+}
+
+/* DTRE SUPPORT
+ */
+/**
+* @brief nlm_hal_set_dtre_freq function sets the frequency of the DTR block.
+*
+* @param [in] node Node number
+* @param [in] freq Frequency to set in MHz
+*
+* @return
+* 	- none
+*
+* @ingroup hal
+*
+*/
+void nlm_hal_set_dtre_freq(int node, int freq)
+{
+}
+
+/**
+* @brief nlm_hal_dtr_init function is used to enable DTR block on XLP.
+*
+* @return : none
+*
+* @ingroup hal
+*
+*/
+void nlm_hal_dtr_init(void *fdt)
+{
+    uint64_t base = nlm_hal_get_dev_base (XLP_DTR_NODE, XLP_DTR_BUS, XLP_DTR_DEVICE, XLP_DTR_FUNC);
+    int frequency = 0;
+    int node = 0;
+    /* Enable Master Control register */
+    nlm_hal_write_32bit_reg (base, XLP_DTR_MASTER_CONTROL_REG, 0x1);
+    /* Channel control registers */
+    nlm_hal_write_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_0, 0x3fe);
+    nlm_hal_write_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_1, 0x3fe);
+    nlm_hal_write_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_2, 0x3fe);
+    nlm_hal_write_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_3, 0x3fe);
+
+    frequency = nlm_hal_get_fdt_freq(fdt, NLM_DTRE);
+    nlm_hal_set_dtre_freq(node, frequency);
+
+#ifdef DUMP
+    nlm_print ("Base Register 0x%llx\n", (unsigned long long)base);
+    nlm_print ("Master control 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_MASTER_CONTROL_REG));
+    nlm_print ("Channel control0 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_0));
+    nlm_print ("Channel control1 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_1));
+    nlm_print ("Channel control2 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_2));
+    nlm_print ("Channel control3 0x%x\n", nlm_hal_read_32bit_reg (base, XLP_DTR_CHANNEL_CONTROL_REG_3));
+#endif
+}
+
+/* SAE SUPPORT
+ */
+/**
+* @brief nlm_hal_set_sae_freq function sets the frequency of the SAE block.
+*
+* @param [in] node Node number
+* @param [in] freq Frequency to set in MHz
+*
+* @return
+* 	- none
+*
+* @ingroup hal_sae
+*
+*/
+void nlm_hal_set_sae_freq(int node, int freq)
+{
+}
+
+
+int nlm_hal_get_chip_feature(void )
+{
+	int chip_features;
+	chip_features = INIT_DONE;
+	return chip_features;
+}
+
+void nlm_hal_set_rsa_freq(int node, int freq)
+{
+}
+
+
+
+void  nlm_hal_sata_firmware_init(void)
+{
+	volatile uint32_t readdata, i;
+
+	nlm_print(" Started AHCI Firmware Initialization.\n");
+
+	nlm_mdelay(1000);
+
+	readdata = rd_sata_glue_reg(XLP_HAL_SATA_CTL);
+
+	nlm_print ("Reseting PHYs.\n");
+	clear_sata_glue_reg(XLP_HAL_SATA_CTL, SATA_RST_N);
+	clear_sata_glue_reg(XLP_HAL_SATA_CTL, PHY3_RESET_N);
+	clear_sata_glue_reg(XLP_HAL_SATA_CTL, PHY2_RESET_N);
+	clear_sata_glue_reg(XLP_HAL_SATA_CTL, PHY1_RESET_N);
+	clear_sata_glue_reg(XLP_HAL_SATA_CTL, PHY0_RESET_N);
+	readdata = rd_sata_glue_reg(XLP_HAL_SATA_CTL);
+	nlm_mdelay(10);
+
+	set_sata_glue_reg(XLP_HAL_SATA_CTL, SATA_RST_N);
+	set_sata_glue_reg(XLP_HAL_SATA_CTL, PHY3_RESET_N);
+	set_sata_glue_reg(XLP_HAL_SATA_CTL, PHY2_RESET_N);
+	set_sata_glue_reg(XLP_HAL_SATA_CTL, PHY1_RESET_N);
+	set_sata_glue_reg(XLP_HAL_SATA_CTL, PHY0_RESET_N);
+
+	readdata = rd_sata_glue_reg(XLP_HAL_SATA_CTL);
+	wr_sata_glue_reg(XLP_HAL_SATA_CTL, readdata);
+	readdata = rd_sata_glue_reg(XLP_HAL_SATA_CTL);
+
+	nlm_print ("Waiting for PHYs to come up.\n");
+
+	i=0;
+	readdata = rd_sata_glue_reg(XLP_HAL_SATA_STATUS);
+	while ( ((readdata & 0x00F0) != 0x00F0) && (i < 30))
+	{
+		readdata = rd_sata_glue_reg(XLP_HAL_SATA_STATUS);
+		nlm_mdelay(10);
+		i++;
+	}
+
+	if (readdata  & P0_PHY_READY) nlm_print(" PHY0 is up.\n");
+	else nlm_print(" PHY0 is down.\n");
+	if (readdata  & P1_PHY_READY) nlm_print(" PHY1 is up.\n");
+	else nlm_print(" PHY1 is down.\n");
+	if (readdata  & P2_PHY_READY) nlm_print(" PHY2 is up.\n");
+	else nlm_print(" PHY2 is down.\n");
+	if (readdata  & P3_PHY_READY) nlm_print(" PHY3 is up.\n");
+	else nlm_print(" PHY3 is down.\n");
+
+	nlm_print(" AHCI Firmware Init  Done.\n");
+}
+
+void nlm_hal_sata_intr_setup(void)
+{
+	uint32_t val;
+
+	/* clear pending interrupts and then enable them */
+	val = rd_sata_glue_reg(XLP_HAL_SATA_INT);
+	nlm_mdelay(10);
+	wr_sata_glue_reg(XLP_HAL_SATA_INT, val);
+	nlm_mdelay(10);
+
+	val = rd_sata_glue_reg(XLP_HAL_SATA_INT_MASK);
+	nlm_mdelay(10);
+#if 1
+	wr_sata_glue_reg(XLP_HAL_SATA_INT_MASK, 0x1);
+#else
+	wr_sata_glue_reg(XLP_HAL_SATA_INT_MASK, val & 0x1BFF3);
+#endif
+}
+
+void nlm_hal_sata_intr_ack(void)
+{
+	uint32_t val = 0;
+
+	val = rd_sata_glue_reg(XLP_HAL_SATA_INT);
+	wr_sata_glue_reg(XLP_HAL_SATA_INT, val & 0x1BFF3);
+}
+
+void nlm_hal_sata_init(void)
+{
+	nlm_hal_sata_firmware_init();
+}
+
+uint32_t get_dom_owner_mask(void *fdt, int dom_id, char *module)
+{
+	char dom_node_str[32];
+	unsigned int *pval;
+	int nodeoffset;
+	int plen;
+	uint32_t flag;
+
+	sprintf(dom_node_str, "/doms/dom@%d/owner-config", dom_id);
+	nodeoffset = fdt_path_offset(fdt, dom_node_str);
+
+	if (nodeoffset >= 0)
+	{
+		pval = ((unsigned int *)fdt_getprop(fdt, nodeoffset, module, &plen));
+		if (pval != NULL) {
+			flag = fdt32_to_cpu(*(unsigned int *)pval);
+			/*nlm_print("owner flag for %s is %#x.\n", module, flag); */
+		}
+		else {
+			flag = 0;
+			/* nlm_print("ERROR: pval is NULL.\n"); */
+		}
+	}
+	else
+	{
+		flag = 0;
+		/* nlm_print("ERROR: unable to find nodeoffset.\n"); */
+	}
+
+	return flag;
+}
+
+
+void nlm_hal_set_rsa_cge(int node, int enable)
+{
+#define NLM_RSA_CFG_REG 0x40
+	uint32_t d32 = nlm_hal_read_rsa_reg(NLM_RSA_CFG_REG);
+	if(enable)
+		d32 |= 1<<9;
+	else
+		d32 &= ~(1<<9);
+	nlm_hal_write_rsa_reg(NLM_RSA_CFG_REG, d32);
+}
+
+#define NLM_SAE_ENGINE_SELECT_REG_0 0x41
+void nlm_hal_set_sae_engine_sel(int node)
+{
+}
+
+#define NLM_RSA_ENGINE_SELECT_REG_0 0x41
+void nlm_hal_set_rsa_engine_sel(void)
+{
+}
+
+void nlm_hal_get_crypto_vc_nums(int *vcbase, int *vclimit)
+{
+}
+
+void nlm_hal_get_rsa_vc_nums(int *vcbase, int *vclimit)
+{
+}
+
+#ifdef NLM_HAL_LINUX_KERNEL
+#include <linux/types.h>
+#include <linux/module.h>
+EXPORT_SYMBOL(nlm_hal_is_xlp_a0);
+EXPORT_SYMBOL(nlm_hal_is_xlp_le);
+EXPORT_SYMBOL(sgmii_scan_phys);
+EXPORT_SYMBOL(nlm_hal_get_dev_base);
+EXPORT_SYMBOL(nlm_hal_set_sae_freq);
+EXPORT_SYMBOL(nlm_hal_get_chip_feature);
+EXPORT_SYMBOL(nlm_hal_set_rsa_freq);
+EXPORT_SYMBOL(nlm_hal_set_dtre_freq);
+EXPORT_SYMBOL(nlm_hal_set_cde_freq);
+
+EXPORT_SYMBOL(nlm_node_cfg);
+
+EXPORT_SYMBOL(nlm_hal_init_ext_phy);
+EXPORT_SYMBOL(nlm_hal_ext_phy_an);
+EXPORT_SYMBOL(nlm_hal_status_ext_phy);
+EXPORT_SYMBOL(nlm_hal_restart_an);
+EXPORT_SYMBOL(register_phy);
+EXPORT_SYMBOL(get_dom_owner_mask);
+EXPORT_SYMBOL(nlm_hal_sata_init);
+EXPORT_SYMBOL(nlm_hal_sata_intr_setup);
+EXPORT_SYMBOL(nlm_hal_sata_intr_ack);
+EXPORT_SYMBOL(nlm_hal_get_fdt_freq);
+EXPORT_SYMBOL(get_phy_info);
+EXPORT_SYMBOL(copy_fdt_prop);
+
+EXPORT_SYMBOL(nlm_hal_set_rsa_cge);
+EXPORT_SYMBOL(nlm_hal_set_sae_engine_sel);
+EXPORT_SYMBOL(nlm_hal_set_rsa_engine_sel);
+EXPORT_SYMBOL(nlm_hal_get_crypto_vc_nums);
+EXPORT_SYMBOL(nlm_hal_get_rsa_vc_nums);
+#endif
diff --git a/arch/mips/netlogic/xlp/Makefile b/arch/mips/netlogic/xlp/Makefile
index a84d6ed..e6a575e 100644
--- a/arch/mips/netlogic/xlp/Makefile
+++ b/arch/mips/netlogic/xlp/Makefile
@@ -1,3 +1,12 @@
-obj-y				+= setup.o nlm_hal.o
+EXTRA_CFLAGS := -Werror
+EXTRA_CFLAGS := $(CFLAGS) -DNLM_HAL_LINUX_KERNEL -Iarch/mips/include/asm/netlogic/hal
+
+obj-y				:= setup.o platform.o
 obj-$(CONFIG_SMP)		+= wakeup.o
-obj-$(CONFIG_USB)		+= usb-init.o
+
+
+obj-y                   += config_net.o
+obj-y += irq.o time.o on_chip.o mmu.o
+obj-$(CONFIG_NLM_XLP) += platform-xlp.o
+obj-$(CONFIG_SMP)      += smp.o smpboot.o
+obj-$(CONFIG_KGDB)      += nmi.o
diff --git a/arch/mips/netlogic/xlp/irq.c b/arch/mips/netlogic/xlp/irq.c
new file mode 100644
index 0000000..f69fd51
--- /dev/null
+++ b/arch/mips/netlogic/xlp/irq.c
@@ -0,0 +1,609 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/pci.h>
+#include <linux/msi.h>
+#include <asm/errno.h>
+#include <asm/signal.h>
+#include <asm/ptrace.h>
+#include <asm/kgdb.h>
+#include <asm/mipsregs.h>
+
+#include <asm/netlogic/sim.h>
+#include <asm/netlogic/nlm_srio.h>
+#include <asm/netlogic/msidef.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/pic.h>
+#include <asm/netlogic/debug.h>
+#include <asm/thread_info.h>
+#include <linux/irq.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+/*
+ * These are the routines that handle all the low level interrupt stuff. 
+ * Actions handled here are: initialization of the interrupt map, requesting of
+ * interrupt lines by handlers, dispatching if interrupts to handlers, probing
+ * for interrupt lines 
+ */
+
+/* Externs */
+extern void nlm_common_timer_interrupt(struct pt_regs *regs, int irq);
+
+extern void *ht_config_base;
+extern int link0, link1;
+struct pic_tmask pic_tmask[PIC_NUM_IRTS];
+
+__u64 nlm_common_irq_mask;
+DEFINE_SPINLOCK(nlm_common_pic_lock);
+
+void dump_irt_entry(short no)
+{
+	nlm_reg_t reg;
+	pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+	reg = nlm_hal_read_pic_reg(mmio, PIC_IRT(no));
+	printk("%d:\t%d\t%d\t%d\t%d\n",no, reg>>31,(reg>>20)&0x3f, (reg>>16)&0x3, reg&0xffff);
+
+}
+
+void dumpall_irt_entry(void)
+{
+	short i;
+	printk("IRT:\tEn\tRVec\tDB\tDTE\n");
+	for (i = 0; i < PIC_NUM_IRTS; i++)
+	{
+		dump_irt_entry(i);
+	}
+}
+
+static unsigned int __maybe_unused pic_startup(unsigned int irq)
+{
+	pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+	unsigned long flags;
+	nlm_reg_t reg;
+	unsigned long irt;
+
+	irt = find_irt_from_irq(irq);
+	if(irt == -1)
+	{
+		printk("can't find irt for irq: %d\n",irq);
+		return -1;
+	}
+
+/* 	printk("[%s]: IN irq=%d\n", __func__, irq); */
+
+	spin_lock_irqsave(&nlm_common_pic_lock, flags);
+
+	/* What happens if this irq was previously not ack'ed? 
+	 * Assume, that doesn't happen?
+	 */
+	reg = nlm_hal_read_pic_reg(mmio, PIC_IRT(irt));
+	/* netlogic_write_reg(mmio, PIC_IRT_1_BASE + irq_to_irt(irq), reg | (1<<31)); */
+	/* By default all the interrupts are initialized as level senstive - fix for the PCMCIA flash */
+	nlm_hal_write_pic_reg(mmio, PIC_IRT(irt), reg|(1 << 28)|(1 << 31));
+	printk("[%s] Writing IRT reg %lu with IRQ %d\n", __FUNCTION__,irt, irq);
+
+	spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+
+	return 0;
+}
+
+static void __maybe_unused pic_unmask(unsigned int irq)
+{
+	pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+	unsigned long flags;
+	nlm_reg_t reg;
+/* 	printk("%s.%d: IN irq=%d\n", __func__, __LINE__, irq); */
+	unsigned long irt;
+
+	irt = find_irt_from_irq(irq);
+	if(irt == -1)
+	{
+		printk("can't find irt for irq: %d\n",irq);
+		return;
+	}
+
+	spin_lock_irqsave(&nlm_common_pic_lock, flags);
+
+	/* What happens if this irq was previously not ack'ed? 
+	 * Assume, that doesn't happen?
+	 */
+	reg = nlm_hal_read_pic_reg(mmio, PIC_IRT(irt));
+	/* netlogic_write_reg(mmio, PIC_IRT_1_BASE + irq_to_irt(irq), reg | (1<<31)); */
+	/* By default all the interrupts are initialized as level senstive - fix for the PCMCIA flash */
+	nlm_hal_write_pic_reg(mmio, PIC_IRT(irt), reg | (1 << 28) | (1 << 31));
+
+	spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+
+	return;
+}
+
+static void __maybe_unused pic_ack(unsigned int irq)
+{
+	unsigned long flags;
+	unsigned long irt;
+
+	irt = find_irt_from_irq(irq);
+	if(irt == -1)
+	{
+		printk("can't find irt for irq: %d\n",irq);
+		return;
+	}
+
+	/* If edge triggered IRQ, ack it immediately, else when the device
+	 * interrupt condition is cleared, we may lose interrupts 
+	 */
+	if (PIC_IRQ_IS_EDGE_TRIGGERED(irq)) {
+		spin_lock_irqsave(&nlm_common_pic_lock, flags);
+		nlm_hal_ack_pic(irt);
+		spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+	}
+}
+
+static void __maybe_unused pic_end(unsigned int irq)
+{
+	unsigned long flags;
+	unsigned long irt;
+
+	irt = find_irt_from_irq(irq);
+	if(irt == -1)
+	{
+		printk("can't find irt for irq: %d\n",irq);
+		return;
+	}
+
+	/* If level triggered, ack it after the device condition is cleared */
+	if (!PIC_IRQ_IS_EDGE_TRIGGERED(irq)) {
+		spin_lock_irqsave(&nlm_common_pic_lock, flags);
+		nlm_hal_ack_pic(irt);
+		spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+	}
+}
+
+static void __maybe_unused pic_shutdown(unsigned int irq)
+{
+	pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+	unsigned long flags;
+	nlm_reg_t reg;
+	unsigned long irt;
+
+	irt = find_irt_from_irq(irq);
+	if(irt == -1)
+	{
+		printk("can't find irt for irq: %d\n",irq);
+		return;
+	}
+
+	//dbg_msg("IN irq=%d\n", irq);
+
+	spin_lock_irqsave(&nlm_common_pic_lock, flags);
+
+	/* What happens if this irq is currently pending an ack? 
+	 * Assume, that doesn't happen?
+	 */
+	reg = nlm_hal_read_pic_reg(mmio, PIC_IRT(irt));
+	nlm_hal_write_pic_reg(mmio, PIC_IRT(irt), (reg & ~(1 << 31)));
+	printk("[%s] disable IRT %lu with IRQ %d\n", __FUNCTION__,PIC_IRT(irt), irq);
+
+	spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+}
+
+static int __maybe_unused pic_set_affinity(unsigned int irq, const struct cpumask *mask)
+{
+	pic_reg_t *mmio __maybe_unused = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+	unsigned long flags;
+	unsigned long irt;
+
+	irt = find_irt_from_irq(irq);
+	if(irt == -1)
+	{
+		printk("can't find irt for irq: %d\n",irq);
+		return -1;
+	}
+
+
+	spin_lock_irqsave(&nlm_common_pic_lock, flags);
+#ifdef XLP_MERGE_TODO
+	nlm_hal_write_pic_reg(mmio, PIC_IRT(nlm_hal_irq_to_irt(irq)),(uint32_t) (mask->bits[0]));
+	printk("[%s] Writing IRT reg %d with IRQ %d\n", __FUNCTION__,PIC_IRT(nlm_hal_irq_to_irt(irq)), (nlm_hal_irq_to_irt(irq)));
+#endif
+	spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+
+	return 0;
+}
+
+static struct irq_chip nlm_common_pic __maybe_unused = {
+	.name = "XLP-PIC",
+#if 0
+	.unmask = pic_unmask,
+	.mask = pic_shutdown,
+	.ack = pic_ack,
+	.end = pic_end,
+	.set_affinity = pic_set_affinity
+#endif
+};
+
+static void __maybe_unused rsvd_pic_handler_1_1(unsigned int irq)
+{
+	if(irq < PIC_IRQ_BASE)
+		return;
+  dbg_msg("Requesting a reserved irq (%d)??", irq);
+  return;
+}
+
+static void __maybe_unused rsvd_pic_handler_1(unsigned int irq)
+{
+	if(irq < PIC_IRQ_BASE)
+		return;
+  dbg_msg("handler called for a reserved irq (%d)\n", irq);
+}
+
+static int __maybe_unused rsvd_pic_handler_2(unsigned int irq, const struct cpumask *mask)
+{
+	if(irq < PIC_IRQ_BASE)
+		return -1;
+  dbg_msg("handler called for a reserved irq (%d)\n", irq);
+  return 0;
+}
+
+struct irq_chip nlm_common_rsvd_pic_irq_timer = {
+  .name     =          "Count-Compare",
+#if 0
+  .unmask	=          rsvd_pic_handler_1_1,
+  .mask		=          rsvd_pic_handler_1,
+  .ack          =          rsvd_pic_handler_1,
+  .end          =          rsvd_pic_handler_1,
+  .set_affinity =          rsvd_pic_handler_2
+#endif
+};
+
+struct irq_chip nlm_common_rsvd_pic = {
+	.name = "Netlogic-RSVD-PIC",
+#if 0
+	.unmask = rsvd_pic_handler_1_1,
+	.mask = rsvd_pic_handler_1,
+	.ack = rsvd_pic_handler_1,
+	.end = rsvd_pic_handler_1,
+	.set_affinity = rsvd_pic_handler_2
+#endif
+};
+
+static irqreturn_t nlm_common_rsvd_irq_handler(int irq, void *dev_id)
+{
+	if(irq == IRQ_TIMER) 
+		return IRQ_HANDLED;
+  dbg_msg("handler for reserved irq %d\n", irq);
+  return IRQ_NONE;
+}
+
+struct irqaction nlm_common_rsvd_action = {
+	.handler = nlm_common_rsvd_irq_handler,
+	.flags = 0,
+	//.mask = 0,
+	.name = "nlm_common_rsvd_action",
+	.dev_id = 0,
+	.next = 0
+};
+
+void __init init_nlm_common_irqs(void)
+{
+	int i;
+
+	for (i = 0; i < NR_IRQS; i++) {
+		//set_irq_chip(i, &nlm_common_pic);
+	}
+
+#ifdef CONFIG_REMOTE_DEBUG
+	//irq_desc[IRQ_REMOTE_DEBUG].chip = &nlm_common_rsvd_pic;
+	irq_desc[IRQ_REMOTE_DEBUG].action = nlm_common_rsvd_action;
+	nlm_common_irq_mask |= (1ULL << IRQ_REMOTE_DEBUG);
+#endif
+
+#ifdef CONFIG_SMP
+	//irq_desc[IRQ_IPI_SMP_FUNCTION].chip = &nlm_common_rsvd_pic;
+	irq_desc[IRQ_IPI_SMP_FUNCTION].action = &nlm_common_rsvd_action;
+
+	//irq_desc[IRQ_IPI_SMP_RESCHEDULE].chip = &nlm_common_rsvd_pic;
+	irq_desc[IRQ_IPI_SMP_RESCHEDULE].action = &nlm_common_rsvd_action;
+
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY
+	/* PR: New IPI added here for netrx balancing */
+	//irq_desc[IRQ_IPI_NETRX].chip = &nlm_common_rsvd_pic;
+	irq_desc[IRQ_IPI_NETRX].action = &nlm_common_rsvd_action;
+	nlm_common_irq_mask |= (1ULL << IRQ_IPI_NETRX);
+#endif				/* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
+
+	nlm_common_irq_mask |=
+	    ((1ULL << IRQ_IPI_SMP_FUNCTION) | (1ULL << IRQ_IPI_SMP_RESCHEDULE));
+#endif
+
+	/* msgring interrupt */
+	//irq_desc[IRQ_MSGRING].chip = &nlm_common_rsvd_pic;
+	irq_desc[IRQ_MSGRING].action = &nlm_common_rsvd_action;
+	nlm_common_irq_mask |= (1ULL << IRQ_MSGRING);
+
+	/* unmask all PIC related interrupts. If no handler is installed by the 
+	 * drivers, it'll just ack the interrupt and return 
+	 */
+	for (i = PIC_IRT_FIRST_IRQ; i <= PIC_IRT_LAST_IRQ(); i++)
+		nlm_common_irq_mask |= (1ULL << i);
+
+#ifdef CONFIG_OPROFILE
+	nlm_common_irq_mask |= (1ULL << IRQ_IPI_OPROFILE);
+#endif
+
+#ifdef CONFIG_KGDB
+	nlm_common_irq_mask |= (1ULL << IRQ_IPI_SMP_KGDB);
+#endif
+
+	nlm_common_irq_mask |= (1ULL << IRQ_TIMER);
+}
+
+#ifdef CONFIG_KGDB
+extern irqreturn_t xlr_kgdb_ipi_handler(int irq, struct pt_regs *regs);
+#endif
+#ifdef CONFIG_OPROFILE
+extern void nlm_common_oprofile_int_handler(int irq, void *dev_id,
+					 struct pt_regs *regs);
+#endif
+void do_nlm_common_IRQ(unsigned int irq, struct pt_regs *regs)
+{
+#ifdef CONFIG_SMP
+
+#ifdef CONFIG_NLMCOMMON_IP_FLOW_AFFINITY
+	if (irq == IRQ_IPI_SMP_FUNCTION || irq == IRQ_IPI_SMP_RESCHEDULE
+	    || irq == IRQ_IPI_NETRX) {
+#else
+	if (irq == IRQ_IPI_SMP_FUNCTION || irq == IRQ_IPI_SMP_RESCHEDULE) {
+#endif				/* CONFIG_NLMCOMMON_IP_FLOW_AFFINITY */
+		nlm_common_ipi_handler(irq, regs);
+		return;
+	}
+#endif
+
+	if (irq == IRQ_MSGRING) nlm_common_msgring_int_handler(irq, regs);
+
+#ifdef CONFIG_KGDB
+	else if (irq == IRQ_IPI_SMP_KGDB) {
+  }
+#endif
+#ifdef CONFIG_OPROFILE
+	else if (irq == IRQ_IPI_OPROFILE) {
+		if (netlogic_thr_id() != 0)
+			nlm_common_oprofile_int_handler(irq, NULL, regs);
+	}
+#endif
+  else do_IRQ(irq);
+}
+
+void __cpuinit nlm_smp_irq_init(void)
+{
+	/* set interrupt mask for non-zero cpus */
+	write_64bit_cp0_eimr(nlm_common_irq_mask | (1 << IRQ_TIMER));
+}
+
+/* 
+ * MSI hook-up routines for Netlogic Boards;
+ * Arch-dependent implementation called
+ * from generic msi.c routines.
+ */
+
+struct irq_chip nlm_common_pic_msi = {
+	.name = "Netlogic-PIC-MSI",
+#if 0
+	.startup = pic_startup,
+	.shutdown = pic_shutdown,
+	.ack = pic_ack,
+	.end = pic_end,
+	.set_affinity = pic_set_affinity
+#endif
+};
+
+void destroy_irq(unsigned int irq)
+{
+    /* no-op */
+}
+
+#ifdef CONFIG_PCI_MSI_XLR
+
+#if defined(CONFIG_NLM_XLP)
+static int get_irq_vector(struct pci_dev *dev)
+{
+	return nlm_hal_irt_to_irq(PIC_IRT_PCIE_LINK_INDEX(0));
+}
+#else
+static int get_irq_vector(struct pci_dev *dev)
+{
+
+    int irq = 0;
+
+	if (is_xls() && !is_xls2xx() && !is_xls_b0()) {
+		/* Currently, PCIE bridges not supported */
+		if (link0) {
+			if (dev->bus->number == 1)
+				irq = PIC_PCIE_LINK0_IRQ;
+			else
+				irq = PIC_PCIE_LINK1_IRQ;
+		} else if (link1) {
+			if (dev->bus->number == 1)
+				irq = PIC_PCIE_LINK1_IRQ;
+		}
+	} else if (is_xls2xx() || is_xls_b0()) {
+		switch (dev->bus->self->devfn) {
+		case 0x0:
+			irq = PIC_PCIE_LINK0_IRQ;
+			break;
+		case 0x8:
+			irq = PIC_PCIE_LINK1_IRQ;
+			break;
+		case 0x10:
+			if (is_xls_b0())
+				irq = PIC_PCIE_XLSB0_LINK2_IRQ;
+			else
+				irq = PIC_PCIE_LINK2_IRQ;
+			break;
+		case 0x18:
+			if (is_xls_b0())
+				irq = PIC_PCIE_XLSB0_LINK3_IRQ;
+			else
+				irq = PIC_PCIE_LINK3_IRQ;
+			break;
+		default:
+			break;
+		}
+	} else {
+		irq = PIC_HYPER_IRQ;
+	}
+
+	return irq;
+}
+#endif
+
+static int msi_compose_msg(struct pci_dev *pdev, unsigned int irq,
+			   struct msi_msg *msg)
+{
+
+	unsigned dest;
+
+	if (irq >= 0) {
+		dest = 0x00;
+		msg->address_hi = MSI_ADDR_BASE_HI;
+		msg->address_lo = MSI_ADDR_BASE_LO |
+		    MSI_ADDR_DEST_MODE_PHYSICAL |
+		    MSI_ADDR_REDIRECTION_CPU | MSI_ADDR_DEST_ID(dest);
+		msg->data = MSI_DATA_TRIGGER_EDGE |
+		    MSI_DATA_LEVEL_ASSERT |
+		    MSI_DATA_DELIVERY_FIXED | MSI_DATA_VECTOR(irq);
+	}
+	return irq;
+}
+
+void arch_teardown_msi_irq(unsigned int irq)
+{
+	destroy_irq(irq);
+}
+
+int arch_setup_msi_irq(struct pci_dev *dev, struct msi_desc *desc)
+{
+	struct msi_msg msg;
+	int irq, ret;
+
+	irq = get_irq_vector(dev);
+	if (irq < 0)
+		return irq;
+	set_irq_msi(irq, desc);
+	ret = msi_compose_msg(dev, irq, &msg);
+	if (ret < 0) {
+		destroy_irq(irq);
+		return ret;
+	}
+	write_msi_msg(irq, &msg);
+	irq_desc[irq].chip = &nlm_common_pic_msi;
+	nlm_common_irq_mask |= (1ULL << irq);
+	return irq;
+}
+#endif
+
+#if defined(CONFIG_NLM_XLP)
+static int xlp_perf_irq(void)
+{
+	return IRQ_HANDLED;
+}
+#endif
+
+void __init arch_init_irq(void)
+{
+#if defined(CONFIG_NLM_XLP)
+	extern int (*perf_irq)(void);
+
+	perf_irq = xlp_perf_irq;
+#endif
+
+#ifdef CONFIG_KGDB
+	if (kgdb_early_setup)
+		return;
+#endif
+
+	/* TODO:
+	 * Initialize the irq registers on the PIC to route
+	 * interrupts to appropriate pins
+	 */
+
+	/* Initialize the irq descriptors */
+	init_nlm_common_irqs();
+
+	write_64bit_cp0_eimr(nlm_common_irq_mask);
+
+	dumpall_irt_entry();
+}
+
+asmlinkage void plat_irq_dispatch(void)
+{
+	uint64_t eirr;
+	struct pt_regs *pt_regs = current_thread_info()->regs;
+	int i = 0;
+	eirr = read_64bit_cp0_eirr() & read_64bit_cp0_eimr();
+
+	if (!eirr)
+		return;
+
+	if (eirr & (1 << IRQ_TIMER)) {
+		nlm_common_timer_interrupt(pt_regs, IRQ_TIMER);
+		return;
+	}
+	/*TODO use dcltz: optimize below code */
+	for (i = 63; i != -1; i--) {
+		if (eirr & (1ULL << i))
+			break;
+	}
+	if (i == -1) {
+		printk("no interrupt !!\n");
+		return;
+	}
+	/*ack eirr */
+	write_64bit_cp0_eirr(1ULL << i);
+	do_nlm_common_IRQ(i, pt_regs);
+	return;
+}
+
+
+void pic_setup_threadmask(unsigned int irt, uint32_t mask)
+{
+#ifdef XLP_MERGE_TODO
+	nlm_reg_t *mmio = netlogic_io_mmio(NETLOGIC_IO_PIC_OFFSET);
+	pic_tmask[irt].mask = mask;
+	pic_tmask[irt].set = 1;
+	pic_tmask[irt].valid = 1;
+ 	netlogic_write_reg(mmio, PIC_IRT_0_BASE + irt, mask);
+	nlm_hal_write_pic_reg(mmio, PIC_IRT(nlm_hal_irq_to_irt(irq)),(uint32_t) (mask.bits[0]));
+#endif
+	return;
+}
+
diff --git a/arch/mips/netlogic/xlp/mmu.c b/arch/mips/netlogic/xlp/mmu.c
new file mode 100644
index 0000000..98a1b9f
--- /dev/null
+++ b/arch/mips/netlogic/xlp/mmu.c
@@ -0,0 +1,176 @@
+/***********************************************************************
+ * Copyright 2003-2010 Netlogic Microsystems (�~@~\Netlogic�~@~]). All rights
+ * reserved.
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ * THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ * *****************************#NETL_2#********************************/
+#include <asm/mipsregs.h>
+#include <asm/mach-netlogic/mmu.h>
+#include <asm/mach-netlogic/pgwalker.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/asm-offsets.h>
+#include <asm/page.h>
+#include <asm/pgtable.h>
+
+#define READ_INHIBIT (1 << 31)
+#define EXEC_INHIBIT (1 << 30)
+
+#define _PMD_T_LOG2 3
+
+static int __initdata tlb_config = (ENABLE_ETLB | ENABLE_128_TLB | ENABLE_PGWALKER);
+
+int __init disable_etlb(char *str)
+{
+	tlb_config &= ~ENABLE_ETLB;
+	return 1;
+}
+__setup("disable_etlb", disable_etlb);
+
+int __init disable_128tlb(char *str)
+{
+	tlb_config &= ~ENABLE_128_TLB;
+
+	return 1;
+}
+__setup("disable_128tlb", disable_128tlb);
+
+int __init disable_pgwalker(char *str)
+{
+	tlb_config &= ~ENABLE_PGWALKER;
+
+	return 1;
+}
+__setup("disable_pgwalker", disable_pgwalker);
+
+void mmu_init(void)
+{
+	write_c0_config6(read_c0_config6() | tlb_config);
+
+	/* 
+	 * Read back TLB entries after configuration
+	 */
+	current_cpu_data.tlbsize = (read_c0_config6() >> 16 ) & 0xffff;
+
+	/* 
+	 * shift right half the number of 1s in 
+	 * the pagemask and populate that value
+	 */
+	write_c0_config7(PM_DEFAULT_MASK >> (13 + (ffz(PM_DEFAULT_MASK >> 13) / 2)));
+#ifdef DEBUG
+	printk(KERN_INFO "( %s ): write_c0_config7 = %d\n", __FUNCTION__,
+		   read_c0_config7());
+#endif
+
+#ifdef CONFIG_EXEC_INHIBIT
+	pagegrain_write(pagegrain_read() | EXEC_INHIBIT);
+#endif
+
+#ifdef CONFIG_READ_INHIBIT
+	pagegrain_write(pagegrain_read() | READ_INHIBIT);
+#endif
+
+	pgwalker_init();
+	tlbstats_init();
+	entrylo0_mask_init();
+}
+
+/*
+ * Page Walker
+ */
+
+DEFINE_PER_CPU(unsigned long [NR_ADDR_SEGMENTS], pgd_bases);
+
+#ifdef CONFIG_64BIT
+static int pgtable_levels = PGD | PMD | PTE;
+#else
+static int pgtable_levels = PGD | PTE;
+#endif
+
+void pgwalker_init(void)
+{
+	unsigned int value;
+
+	if (read_c0_config6() & ENABLE_PGWALKER) {
+		/* 
+		 * hardware page levels information:
+		 * 
+		 * [15:8] no of top-most bits of vaddr used to form
+		 *        an index into the pgdirs table
+		 * [ 7:4] shift amount by which pfn (page frame number)
+		 *        needs to be left shifted for populating the
+		 *        entrylo0 and entrylo1 registers
+		 * [ 3:0] page table levels used. 32-bit kernels use 
+		 *        pgd and pte levels, while 64-bits kernels
+		 *        use pgd, pmd, and pte
+		 */
+		value  = ((ffs(NR_ADDR_SEGMENTS) - 1) & 0xff) << 8;
+		value |= ENTRYLO_PFN_SHIFT << 4;
+		value |= pgtable_levels;
+		pgw_register_write_w(PGW_MMU_INFO, value);
+
+#ifdef CONFIG_64BIT
+		pgw_register_write_d(PGW_PGD_BASES, (unsigned long long)&(__get_cpu_var(pgd_bases)[0]));
+#else
+		pgw_register_write_w(PGW_PGD_BASES, (unsigned int)&(__get_cpu_var(pgd_bases)[0]));
+#endif
+
+		/* PGD shift and mask information */
+		pgw_register_write_w(PGW_PGD_SHIFT, _PGDIR_SHIFT - _PGD_T_LOG2);
+		pgw_register_write_w(PGW_PGD_MASK, (_PTRS_PER_PGD - 1) << _PGD_T_LOG2);
+#ifdef CONFIG_64BIT
+		/*
+		 * MIPS Linux currently does not use 4-level page tables
+		 * and hence it is not necessary to fill in pud information
+		 *
+		 * So, just fill in the PMD shift and mask information 
+		 */
+		pgw_register_write_w(PGW_PMD_SHIFT, _PMD_SHIFT - _PMD_T_LOG2);
+		pgw_register_write_w(PGW_PMD_MASK, (_PTRS_PER_PMD - 1) << _PMD_T_LOG2);
+#endif
+
+		/* PTE shift and mask */
+		pgw_register_write_w(PGW_PTE_SHIFT, PAGE_SHIFT - _PTE_T_LOG2);
+		pgw_register_write_w(PGW_PTE_MASK, (_PTRS_PER_PTE - 1) << _PTE_T_LOG2);
+
+		get_cpu_var(pgd_bases)[VMALLOC_SEG] = (unsigned long) swapper_pg_dir;
+
+#ifdef XLP_MERGE_TODO
+#ifdef MODULE_START
+		__get_cpu_var(pgd_bases)[MODULE_SEG] = (unsigned long) module_pg_dir;
+#endif
+#endif
+		put_cpu_var(pgd_bases);
+
+		dump_pgwalker_config();
+		printk("Initialized Page Walker\n");
+	}
+}
+
+void dump_pgwalker_config(void)
+{
+	pgw_print_w(PGW_MMU_INFO);
+	pgw_print_w(PGW_PGD_SHIFT);
+	pgw_print_w(PGW_PGD_MASK);
+	pgw_print_w(PGW_PMD_SHIFT);
+	pgw_print_w(PGW_PMD_MASK);
+	pgw_print_w(PGW_PTE_SHIFT);
+	pgw_print_w(PGW_PTE_MASK);
+}
diff --git a/arch/mips/netlogic/xlp/nmi.S b/arch/mips/netlogic/xlp/nmi.S
new file mode 100644
index 0000000..26d2fa7
--- /dev/null
+++ b/arch/mips/netlogic/xlp/nmi.S
@@ -0,0 +1,105 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (�~@~\Netlogic�~@~]). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/init.h>
+
+#include <asm/asm.h>
+#include <asm/asmmacro.h>
+#include <asm/cacheops.h>
+#include <asm/irqflags.h>
+#include <asm/regdef.h>
+#include <asm/fpregdef.h>
+#include <asm/mipsregs.h>
+#include <asm/stackframe.h>
+#include <asm/war.h>
+#include <asm/page.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/interrupt.h>
+
+
+NESTED(nlm_except_vec_nmi, 0, sp)
+	.set push
+	.set noat
+	.set mips64
+	.set noreorder
+	MTC0	k0, OS_KGDB_SCRATCH_REG6
+	nop
+	nop
+	PTR_LA	k0, nlm_nmi_handler
+	jr       k0
+	nop
+	.set pop
+END(nlm_except_vec_nmi)
+
+
+	/* This nmi handler is currently only for taking oprofile samples
+	   on non-zero cpus
+	   */
+NESTED(nlm_nmi_handler, PT_SIZE,  sp)
+	.set	push
+	.set	noat
+	.set noreorder
+	.set 	mips64
+
+	/* Save K0 and K1 first */
+	/* K0 is already saved in nlm_except_vec_nmi */
+	MTC0	k1, OS_KGDB_SCRATCH_REG7
+	
+	/* Clear the  NMI and BEV bits */
+	MFC0	k0, CP0_STATUS
+	li 	k1, 0xffb7ffff
+	and	k0, k0, k1
+	MTC0	k0, CP0_STATUS
+
+	SAVE_ALL
+	CLI
+	TRACE_IRQS_OFF
+
+	li	a0, IRQ_IPI_SMP_KGDB
+	move	a1, sp
+	/* jal	do_nlm_common_IRQ */
+	/* nop */
+	jal	nlm_kgdb_call_nmi_hook
+	nop
+
+	RESTORE_ALL
+
+	/*
+	MFC0 	k0, $15, 1
+	andi	k0, 0x1f
+	sll	k0, 2
+	la	k1, nlm_cpus_in_nmi
+ 	PTR_ADDU	k1, k0
+	sw	zero, 0(k1)
+	*/
+
+	MFC0	k0, OS_KGDB_SCRATCH_REG6
+	MFC0	k1, OS_KGDB_SCRATCH_REG7
+	
+	.set mips3
+	eret
+
+	.set pop
+END(nlm_nmi_handler)
diff --git a/arch/mips/netlogic/xlp/on_chip.c b/arch/mips/netlogic/xlp/on_chip.c
new file mode 100644
index 0000000..f1823ed
--- /dev/null
+++ b/arch/mips/netlogic/xlp/on_chip.c
@@ -0,0 +1,820 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/module.h>
+#include <linux/timer.h>
+#include <linux/slab.h>
+
+#include <asm/netlogic/msgring.h>
+#include <asm/netlogic/iomap.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/debug.h>
+#include <asm/netlogic/xlr_user_mac.h>
+#include <asm/netlogic/sim.h>
+
+#include <asm/netlogic/hal/nlm_hal.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+
+unsigned long netlogic_io_base = (unsigned long)(DEFAULT_NETLOGIC_IO_BASE);
+EXPORT_SYMBOL(netlogic_io_base);
+extern int xlr_loader_support;
+extern int xlr_loader_sharedcore;
+extern int xlr_loader_own_gmac;
+extern int xlr_loader_own_dma;
+int msgring_timer_irq;
+
+#define MSGRNG_CC_INIT_CPU_DEST(conf, dest,cpu) \
+do { \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][0], 0 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][1], 1 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][2], 2 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][3], 3 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][4], 4 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][5], 5 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][6], 6 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][7], 7 ); \
+} while(0)
+
+/* Initialized CC for cpu 0 to send to all buckets at 0-7 cpus */
+#define MSGRNG_CC_INIT_CPU(conf, cpu) \
+do { \
+  MSGRNG_CC_INIT_CPU_DEST(conf,0,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,1,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,2,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,3,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,4,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,5,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,6,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,7,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,8,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,9,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,10,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,11,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,12,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,13,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,14,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,15,cpu); \
+} while (0)
+
+#define MSGRNG_BUCKETSIZE_INIT_CPU(conf, base) \
+do { \
+  msgrng_write_bucksize(0, conf##bucket_sizes.bucket[base+0]);         \
+  msgrng_write_bucksize(1, conf##bucket_sizes.bucket[base+1]);         \
+  msgrng_write_bucksize(2, conf##bucket_sizes.bucket[base+2]);  \
+  msgrng_write_bucksize(3, conf##bucket_sizes.bucket[base+3]);  \
+  msgrng_write_bucksize(4, conf##bucket_sizes.bucket[base+4]);  \
+  msgrng_write_bucksize(5, conf##bucket_sizes.bucket[base+5]);  \
+  msgrng_write_bucksize(6, conf##bucket_sizes.bucket[base+6]);  \
+  msgrng_write_bucksize(7, conf##bucket_sizes.bucket[base+7]);  \
+} while(0)
+
+#define XLR_MSG_TBL
+#define XLS_MSG_TBL  xls_
+#define SHARED_XLR_MSG_TBL shared_
+
+#define X_MSGRNG_BUCKETSIZE_INIT_CPU(x,y) MSGRNG_BUCKETSIZE_INIT_CPU(x,y)
+
+__u32  pop_bucket_mask[NR_CORES];
+__u32  pop_bucket_start[NR_CORES];
+__u32  pop_bucket_end[NR_CORES];
+__u32 cpu_to_bktmask[NR_CPUS];
+__u32 cpu_to_frstid[NR_CPUS];
+
+uint32_t hard_cpu_online_map = 0;
+uint32_t msgring_global_thread_mask = 0;
+
+/* make this a read/write spinlock */
+spinlock_t msgrng_lock;
+static nlm_common_atomic_t msgring_registered;
+
+int msgring_int_type;
+int msgring_int_en;
+int msgring_watermark_count;
+static __u32 msgring_thread_mask;
+
+extern int nlm_dev_own_bucket_list_get(int *start, int *end, int *mask);
+extern struct irq_chip nlm_common_rsvd_pic;
+extern struct irqaction nlm_common_rsvd_action;
+
+#ifdef CONFIG_NLMCOMMON_MSGRING_NAPI
+extern int nlm_msgring_napi;
+extern int xlr_napi_ready;
+extern void xlr_napi_rx_schedule(void);
+#endif				/* CONFIG_NLMCOMMON_MSGRING_NAPI */
+
+struct tx_stn tx_stns[MAX_TX_STNS];
+
+int rxstn_to_txstn_map[128] = {
+	[0 ... 7] = TX_STN_CPU_0,
+	[8 ... 15] = TX_STN_CPU_1,
+	[16 ... 23] = TX_STN_CPU_2,
+	[24 ... 31] = TX_STN_CPU_3,
+	[32 ... 39] = TX_STN_CPU_4,
+	[40 ... 47] = TX_STN_CPU_5,
+	[48 ... 55] = TX_STN_CPU_6,
+	[56 ... 63] = TX_STN_CPU_7,
+	[64 ... 95] = TX_STN_INVALID,
+	[96 ... 103] = TX_STN_GMAC,
+	[104 ... 107] = TX_STN_DMA,
+	[108 ... 111] = TX_STN_INVALID,
+	[112 ... 113] = TX_STN_XGS_0,
+	[114 ... 115] = TX_STN_XGS_1,
+	[116 ... 119] = TX_STN_INVALID,
+	[120 ... 127] = TX_STN_SEC
+};
+
+int xls_rxstn_to_txstn_map[128] = {
+        [0 ... 7] = TX_STN_CPU_0,
+        [8 ... 15] = TX_STN_CPU_1,
+	[16 ... 23] = TX_STN_CPU_2,
+	[24 ... 31] = TX_STN_CPU_3,
+        [32 ... 80] = TX_STN_INVALID,
+	[80 ... 87] = TX_STN_GMAC1,
+	[96 ... 103] = TX_STN_GMAC0,
+	[104 ... 107] = TX_STN_DMA,
+	[108 ... 111] = TX_STN_CMP,
+	[112 ... 115] = TX_STN_INVALID,
+	[116 ... 119] = TX_STN_PCIE,
+	[120 ... 121] = TX_STN_SEC,
+	[122 ... 127] = TX_STN_INVALID,
+};
+
+void dummy_handler(int bucket, int size, int code, int tx_stid,
+		   struct msgrng_msg *msg, void *dev_id)
+{
+	printk("[%s]: No Handler for message from stn_id=%d, bucket=%d, "
+	       "size=%d, msg0=%llx, dropping message\n",
+	       __FUNCTION__, tx_stid, bucket, size,
+	       (unsigned long long)msg->msg0);
+}
+
+struct tx_stn_handler tx_stn_handler_map[128] = {
+	[0 ... 127] = {dummy_handler, NULL},
+};
+
+void nlm_common_msgring_cpu_init(void)
+{
+	int id;
+	unsigned long flags;
+	int shared_msgring = 0;
+
+//	id = cpu_logical_map(get_cpu());
+	id = 0;
+
+	msgring_int_en = 1;
+
+	if (xlr_loader_support && xlr_loader_sharedcore) {
+		/* if support for loading apps on same core as Linux is enabled */
+		if (xlr_loader_own_gmac || xlr_loader_own_dma) {
+			/* pop should only the buckets matching with the thread
+			   on which linux is loaded */
+			shared_msgring = 1;
+			msgring_int_en = 0;
+			pop_bucket_start[id >> 2] = 0;
+			pop_bucket_mask[id >> 2] |= (1 << (id % 4));
+			if (pop_bucket_end[id >> 2] < (id % 4) + 1)
+				pop_bucket_end[id >> 2] = (id % 4) + 1;
+		} else if (xlr_hybrid_rmios_ipsec()) {
+			/* rmios will always send to the bucket 0 */
+			pop_bucket_start[id >> 2] = 0;
+			pop_bucket_mask[id >> 2] = 1;
+			pop_bucket_end[id >> 2] = 1;
+			put_cpu();
+			return;
+		} else {
+			/* all the stations are owned by apps, 
+			   linux should not poll for any bucket */
+			pop_bucket_start[id >> 2] = 0;
+			pop_bucket_mask[id >> 2] = 0;
+			pop_bucket_end[id >> 2] = 0;
+		}
+	} else if (xlr_hybrid_user_mac() || xlr_hybrid_user_mac_xgmac()) {
+		/* msgring interrupt should be disabled */
+		msgring_int_type = 0x0;
+
+		pop_bucket_start[id >> 2] = 0;
+		pop_bucket_end[id >> 2] = 4;
+		pop_bucket_mask[id >> 2] = 0xf;
+	} else {
+		/* all the stations are owned by linux */
+		pop_bucket_start[id >> 2] = 0;
+		pop_bucket_end[id >> 2] = 8;
+		pop_bucket_mask[id >> 2] = 0xff;
+	}
+
+	/* if not thead 0 */
+	if ((id & 0x03) != 0) {
+		put_cpu();
+		return;
+	}
+
+	prom_dbg_msg("Initializing message ring for cpu_%d\n", id);
+
+	msgrng_flags_save(flags);
+
+	/* Message Stations are shared among all threads in a cpu core
+	 * Assume, thread 0 on all cores are always active when more than
+	 * 1 thread is active in a core
+	 */
+	if (is_xls()) {
+		if (id == 0) {
+			X_MSGRNG_BUCKETSIZE_INIT_CPU(XLS_MSG_TBL, 0);
+			MSGRNG_CC_INIT_CPU(XLS_MSG_TBL, 0);
+		} else if (id == 4) {
+			X_MSGRNG_BUCKETSIZE_INIT_CPU(XLS_MSG_TBL, 8);
+			MSGRNG_CC_INIT_CPU(XLS_MSG_TBL, 1);
+		} else if (id == 8) {
+			X_MSGRNG_BUCKETSIZE_INIT_CPU(XLS_MSG_TBL, 16);
+			MSGRNG_CC_INIT_CPU(XLS_MSG_TBL, 2);
+		} else if (id == 12) {
+			X_MSGRNG_BUCKETSIZE_INIT_CPU(XLS_MSG_TBL, 24);
+			MSGRNG_CC_INIT_CPU(XLS_MSG_TBL, 3);
+		}
+	} else {
+		if (shared_msgring) {
+			if (id == 0) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     0);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 0);
+			} else if (id == 4) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     8);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 1);
+			} else if (id == 8) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     16);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 2);
+			} else if (id == 12) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     24);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 3);
+			} else if (id == 16) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     32);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 4);
+			} else if (id == 20) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     40);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 5);
+			} else if (id == 24) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     48);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 6);
+			} else if (id == 28) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     56);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 7);
+			}
+		} else {
+			if (id == 0) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 0);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 0);
+			} else if (id == 4) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 8);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 1);
+			} else if (id == 8) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 16);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 2);
+			} else if (id == 12) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 24);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 3);
+			} else if (id == 16) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 32);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 4);
+			} else if (id == 20) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 40);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 5);
+			} else if (id == 24) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 48);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 6);
+			} else if (id == 28) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 56);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 7);
+			}
+		}
+	}
+	msgrng_flags_restore(flags);
+	put_cpu();
+}
+
+void nlm_common_msgring_config(void)
+{
+
+#ifdef CONFIG_NLMCOMMON_MSGRING_NAPI
+	/* If we use NAPI then we enable queue non-empty interrupt */
+	msgring_int_type = nlm_msgring_napi ? 0x01 : 0x02;
+#else
+	msgring_int_type = 0x02;
+#endif				/* CONFIG_NLMCOMMON_MSGRING_NAPI */
+
+	msgring_watermark_count = 1;
+	msgring_thread_mask = 0x0f;
+
+/* 	printk("[%s]: int_type = 0x%x, pop_num_buckets=%d, pop_bucket_mask=%x" */
+/* 	       "watermark_count=%d, thread_mask=%x\n", __FUNCTION__, */
+/* 	       msgring_int_type, msgring_pop_num_buckets, msgring_pop_bucket_mask, */
+/* 	       msgring_watermark_count, msgring_thread_mask); */
+}
+
+void nlm_common_derive_cpu_to_bkt_map(void)
+{
+	int cpus_per_core[NR_CORES];
+	int stns_per_core[NR_CORES];
+	int num_cpus, cpus, cpu_off, from, i;
+	int bucket_mask[NR_CPUS_PER_CORE];
+	int fr_bucket[NR_CPUS_PER_CORE];
+	int core, bkt_idx, bkt_mask;
+
+#define GET_NEXT_SET_BIT_U8(val, rv) { \
+    if(val < ( 1 << rv)) \
+        rv = 0; \
+    for(i = rv; val != 0 && i <= 7; i++) { \
+        if(val & (1 << i)) { \
+            rv = i; \
+            break; \
+        } \
+    }  \
+    if( i >= 8) \
+        rv = 0; \
+}
+
+	memset(cpus_per_core, 0, sizeof(cpus_per_core));
+	memset(stns_per_core, 0, sizeof(stns_per_core));
+
+	for (i = 0; i < NR_CPUS; i++) {
+		if (!(hard_cpu_online_map & (1 << i)))
+			continue;
+		core = i / NR_CPUS_PER_CORE;
+		cpus_per_core[core]++;
+	}
+	for (core = 0; core < NR_CORES; core++) {
+		for (i = 0; i < NR_STNS_PER_CORE; i++) {
+			if (!(pop_bucket_mask[core] & (1 << i)))
+				continue;
+			stns_per_core[core]++;
+		}
+	}
+
+	for (core = 0; core < NR_CORES; core++) {
+		int filled_all = 0;
+		int rv = 0;
+		uint8_t fr_bucket_map = 0;
+		memset(bucket_mask, 0, sizeof(bucket_mask));
+		memset(fr_bucket, 0xff, sizeof(fr_bucket));
+
+        num_cpus = cpus_per_core[core];
+        if(num_cpus == 0)
+            continue;
+        for(cpus = 0, bkt_idx = 0, bkt_mask = pop_bucket_mask[core];
+                bkt_mask; bkt_mask = bkt_mask >> 1, bkt_idx++) {
+            if(!(bkt_mask & 0x01))
+                continue;
+            bucket_mask[cpus] |=  (1 << bkt_idx);
+			
+			if(((int)fr_bucket[cpus] != -1) && (fr_bucket[cpus] < NR_CPUS_PER_CORE))
+                fr_bucket_map &= (~(1 << fr_bucket[cpus]));
+            fr_bucket_map |= (1 << bkt_idx);
+			fr_bucket[cpus] = bkt_idx;
+
+			if((cpus + 1) == num_cpus)
+            	filled_all = 1;
+
+            cpus = (cpus + 1) % num_cpus;
+        }
+
+        /* fill the non filled cpus */
+		if(filled_all == 0) {
+	        for(from = 0; cpus < num_cpus; cpus++, from++) {
+    	        bucket_mask[cpus] = bucket_mask[from];
+       	 	}
+		}
+        cpu_off = core * NR_CPUS_PER_CORE;
+        for(from = 0, cpus = cpu_off;
+                cpus < cpu_off + NR_CPUS_PER_CORE; cpus++) {
+            if(!(hard_cpu_online_map & (1 << cpus)))
+                continue;
+            cpu_to_bktmask[cpus] = bucket_mask[from];
+			GET_NEXT_SET_BIT_U8(fr_bucket_map, rv);
+            cpu_to_frstid[cpus] = rv + (core * NR_STNS_PER_CORE);
+            from++;
+			rv++;
+        }
+    }
+#if 0
+	for (i = 0; i < NR_CPUS; i++)
+		printk("%d: bktmask=0x%x frstid=%d\n",
+		       i, cpu_to_bktmask[i], cpu_to_frstid[i]);
+#endif
+
+	return;
+}
+
+static int __init xlr_msgring_watermark_setup(char *str)
+{
+	if (*str == '=')
+		str++;
+
+	msgring_watermark_count = (int)simple_strtoul(str, NULL, 10);
+
+	return 1;
+}
+
+static int __init xlr_msgring_thread_mask_setup(char *str)
+{
+	if (*str == '=')
+		str++;
+
+	msgring_thread_mask = simple_strtoul(str, NULL, 16);
+	msgring_thread_mask &= 0x0f;
+
+	return 1;
+}
+
+static int __init xlr_complete_msgring_thread_mask_setup(char *str)
+{
+	if (*str == '=')
+		str++;
+	msgring_global_thread_mask = simple_strtoul(str, NULL, 16);
+	msgring_global_thread_mask &= 0xffffffff;
+	return 1;
+}
+
+__setup("xlr_msgring_watermark=", xlr_msgring_watermark_setup);
+__setup("xlr_msgring_thread_mask=", xlr_msgring_thread_mask_setup);
+__setup("xlr_complete_msgring_thread_mask=",
+	xlr_complete_msgring_thread_mask_setup);
+
+extern void netlogic_cpu_stat_update_msgring_int(void);
+extern void netlogic_cpu_stat_update_msgring_cycles(__u32 cycles);
+extern void netlogic_cpu_stat_update_msgring_pic_int(void);
+
+void msgring_process_rx_msgs(int start_bucket, int end_bucket,
+			     __u32 pop_bucket_mask)
+{
+	unsigned int bucket_empty_bm = 0;
+	int bucket = 0;
+	int size = 0, code = 0, rx_stid = 0;
+	struct msgrng_msg msg;
+	struct tx_stn_handler *handler = 0;
+	unsigned int status = 0;
+
+#ifdef CONFIG_NLMCOMMON_MSGRING_NAPI
+	if (xlr_napi_ready && in_irq()) {
+		xlr_napi_rx_schedule();
+		return;
+	}
+#endif				/* CONFIG_NLMCOMMON_MSGRING_NAPI */
+
+	/* First Drain all the high priority messages */
+	for (;;) {
+
+		bucket_empty_bm =
+		    (msgrng_read_status() >> 24) & pop_bucket_mask;
+
+		/* all buckets empty, break */
+		if (bucket_empty_bm == pop_bucket_mask)
+			break;
+
+		for (bucket = start_bucket; bucket < end_bucket; bucket++) {
+
+			if ((bucket_empty_bm & (1 << bucket)) ||	/* empty */
+			    !((1 << bucket) & pop_bucket_mask))	/* not in mask */
+				continue;
+
+			status =
+			    message_receive(bucket, &size, &code, &rx_stid,
+					    &msg);
+			if (status)
+				continue;
+
+			handler = &tx_stn_handler_map[rx_stid];
+			/* Handler is always present. If not actual, atleast 
+			 * dummy_handler
+			 */
+			(handler->action) (bucket, size, code, rx_stid, &msg,
+					   handler->dev_id);
+		}
+	}
+}
+
+#if !defined(CONFIG_NLMCOMMON_MAC) && !defined(CONFIG_NLM_XLP)
+__u64 xlr_cp2_exceptions[32];
+struct user_mac_data *user_mac;
+struct user_mac_kernal_data user_mac_krnl_data;
+struct xlr_user_mac_config xlr_user_mac;
+void netlogic_cpu_stat_update_msgring_int(void) { }
+void netlogic_cpu_stat_update_msgring_cycles(__u32 cycles) { }
+void netlogic_cpu_stat_update_msgring_pic_int(void) { }
+#endif /* CONFIG_NLMCOMMON_MAC */
+
+__u32 msgrng_msg_cycles = 0;
+void nlm_common_msgring_int_handler(unsigned int irq, struct pt_regs *regs)
+{
+	unsigned long mflags;
+	int core;
+	__u32 cycles = 0;
+
+	if (irq == IRQ_MSGRING) {
+		/* normal message ring interrupt */
+		xlr_inc_counter(MSGRNG_INT);
+		netlogic_cpu_stat_update_msgring_int();
+	} else {
+		netlogic_cpu_stat_update_msgring_pic_int();
+	}
+
+	irq_enter();
+
+	//dbg_msg("IN irq=%d\n", irq);
+
+	/* TODO: not necessary to disable preemption */
+	msgrng_flags_save(mflags);
+
+	cycles = read_c0_count();
+
+//	core = cpu_logical_map(smp_processor_id()) >> 2;
+	core = 0;
+	msgring_process_rx_msgs(pop_bucket_start[core], pop_bucket_end[core], pop_bucket_mask[core]);
+
+	netlogic_cpu_stat_update_msgring_cycles(read_c0_count() - cycles);
+
+	msgrng_flags_restore(mflags);
+
+	//dbg_msg("OUT irq=%d\n", irq);
+
+	/* Call the msg callback */
+	irq_exit();
+}
+
+static void enable_msgring_int(void *info)
+{
+	unsigned long flags = 0, mflags = 0;
+	unsigned int th_mask;
+	unsigned int core;
+	msgrng_access_save(&msgrng_lock, flags, mflags);
+
+	core = hard_smp_processor_id() & ~(0x3);
+	th_mask = (msgring_global_thread_mask >> core) & 0x0f;
+
+#if 0
+	printk
+	    ("[%s:%d] cpu_%d cpu_online_map=0x%04x msgring_global_mask=0x%08x "
+	     "th_mask=0x%02x intype=%d wm=%d\n", __FUNCTION__, __LINE__,
+	     hard_smp_processor_id(), hard_cpu_online_map,
+	     msgring_global_thread_mask, th_mask, msgring_int_type,
+	     msgring_watermark_count);
+#endif
+
+	/* enable the message ring interrupts */
+	msgrng_write_config((msgring_watermark_count << 24) |
+			    (IRQ_MSGRING << 16)
+			    | (th_mask << 8) | msgring_int_type);
+	msgrng_access_restore(&msgrng_lock, flags, mflags);
+}
+
+static void msgring_bkp_timer(unsigned long data)
+{
+	unsigned long flags;
+	struct timer_list *timer = (struct timer_list *)data;
+	local_irq_save(flags);
+	nlm_common_msgring_int_handler(-1,NULL);
+	local_irq_restore(flags);
+	mod_timer(timer, timer->expires+2);
+}
+
+static void enable_msgring_timer(void *data)
+{
+	struct timer_list *timer;
+	timer = kmalloc(sizeof(struct timer_list), GFP_KERNEL);
+	setup_timer(timer, msgring_bkp_timer, (unsigned long)timer);
+	timer->expires = jiffies + 2;
+	add_timer(timer);
+}
+
+extern spinlock_t nlm_common_pic_lock;
+int register_msgring_handler(int major,
+			     void (*action) (int, int, int, int,
+					     struct msgrng_msg *, void *),
+			     void *dev_id)
+{
+	struct tx_stn_handler *handler = 0;
+	int ret = 1;
+	int i,j,tx_stid;
+	unsigned long flags = 0;
+	cpumask_t timer_cpu_mask;
+
+	if (major >= MAX_TX_STNS || action == NULL) {
+		printk(KERN_ALERT "%s:%d  Invalid parameter: major=%d, "
+		       "MAX_TX_STN=%d action=%p",
+		       __FUNCTION__, __LINE__, major, MAX_TX_STNS, action);
+		return ret;
+	}
+
+	/* Check if the message station is valid, if not return error */
+	spin_lock_irqsave(&msgrng_lock, flags);
+
+	for (i = 0; i < 128; i++) {
+		if (is_xls())
+			tx_stid = xls_rxstn_to_txstn_map[i];
+		else
+			tx_stid = rxstn_to_txstn_map[i];
+		if (tx_stid == major) {
+			tx_stn_handler_map[i].action = action;
+			tx_stn_handler_map[i].dev_id = dev_id;
+		}
+	}
+
+	handler = &tx_stns[major].handler;
+
+	// dbg_msg("major=%d, action=%p, dev_id=%p\n", major, action, dev_id);
+	handler->action = action;
+	handler->dev_id = dev_id;
+
+	ret = 0;
+	spin_unlock_irqrestore(&msgrng_lock, flags);
+
+	if (!ret && nlm_common_test_and_set(&msgring_registered)) {
+		int i=0;
+
+		hard_cpu_online_map = 0;
+		for (i = 0; i < NR_CPUS; i++) {
+			//if (cpu_isset(i, hard_cpu_online_map))
+				hard_cpu_online_map |=
+//				    (1 << cpu_logical_map(i));
+					0;
+		}
+
+		/* derive the cpu to bucket map */
+		nlm_common_derive_cpu_to_bkt_map();
+
+
+		/* Configure PIC to deliver msgring interrupt for timeouts */
+		if (msgring_global_thread_mask == 0) {
+			for (i = 0; i < NR_CORES; i++) {
+				msgring_global_thread_mask |=
+				    (msgring_thread_mask << (i << 2));
+			}
+		}
+
+		msgring_global_thread_mask &= hard_cpu_online_map;
+
+		/* configure the msgring interrupt on all cpus */
+		if (msgring_int_en)
+			on_each_cpu(enable_msgring_int, 0, 1);
+
+/* 		printk("[%s]: cpu_online_map = %lx, hard_cpu_online_map=%x, " */
+/* 		       "msgring_global_thread_mask=%x\n", */
+/* 		       __FUNCTION__,  */
+/* 		       (unsigned long)cpu_online_map,  */
+/* 		       hard_cpu_online_map,  */
+/* 		       msgring_global_thread_mask); */
+
+		/* Schedule a messagering backup timer at every 2 jiffies on one 
+		   therad per core 
+		 */
+
+		cpus_clear(timer_cpu_mask);
+		for(i = 0; i < NR_CORES; i++) {
+			int core_mask;			
+			int phys_id, logical_id;
+			if(hard_cpu_online_map & (0xf<<(i*NR_CPUS_PER_CORE))){
+				core_mask = (hard_cpu_online_map>>(i*NR_CPUS_PER_CORE)) & 0xf;
+				for(j=0; j<NR_CPUS_PER_CORE; j++){
+					if(core_mask & (1<<j))
+						break;
+				}
+				phys_id = (i*NR_CPUS_PER_CORE) + j;
+				//logical_id = cpu_number_map(phys_id);
+				logical_id = 0;
+				cpu_set(logical_id, timer_cpu_mask);
+			}
+		}
+		preempt_disable();
+		smp_call_function_many(&timer_cpu_mask, enable_msgring_timer, NULL, 1);
+		preempt_enable();
+		//if(cpu_isset(cpu_number_map(hard_smp_processor_id()),timer_cpu_mask))
+			enable_msgring_timer(NULL);
+	}
+
+	return ret;
+}
+
+EXPORT_SYMBOL(register_msgring_handler);
+
+static void pic_init(void)
+{
+	nlm_reg_t *mmio = netlogic_io_mmio(NETLOGIC_IO_PIC_OFFSET);
+	int i = 0;
+	int level;
+	uint32_t thread_mask = (1 << hard_smp_processor_id());
+
+	for (i = 0; i < PIC_NUM_IRTS; i++) {
+
+		level = PIC_IRQ_IS_EDGE_TRIGGERED(i);
+
+		/* Bind all PIC irqs to boot cpu */
+		mmio = 0;	/* For compiler sake */
+		/* Use local scheduling and high polarity for all IRTs
+		 * Invalidate all IRTs, by default
+		 */
+		nlm_hal_pic_write_irt(i, 0, 0, 1, nlm_hal_irt_to_irq(i), 1, 0, thread_mask);
+	}
+}
+
+atomic_t nlm_common_counters[NR_CPUS][NLM_MAX_COUNTERS] __cacheline_aligned;
+
+static void nlm_usb_init (void)
+{
+	nlm_reg_t * gpio_mmio = netlogic_io_mmio(NETLOGIC_IO_GPIO_OFFSET);
+	nlm_reg_t * usb_mmio  = netlogic_io_mmio(NETLOGIC_IO_USB_1_OFFSET);
+
+   /* The NLM-Specific USB Block */
+   netlogic_write_reg(usb_mmio, 49, 0x10000000); //Clear Rogue Phy INTs
+   netlogic_write_reg(usb_mmio, 50, 0x1f000000);
+
+	if (is_xls1xx()) {
+		/* Enabling only 1 USB Port */
+		if (xlr_board_atx_viii()) {
+			/* LTE board has usb port #1 */
+			netlogic_write_reg(usb_mmio,  1, 0x05000500);
+		}
+		else {
+			/* enable usb port #0 */
+			netlogic_write_reg(usb_mmio,  1, 0x03000500);
+		}
+	}
+	else {
+   	netlogic_write_reg(usb_mmio,  1, 0x07000500);
+	}
+
+   {
+      volatile unsigned int value = gpio_mmio[21];
+      if ((value >> 22) & 0x01) {
+         printk("Detected USB Host mode..\n");
+         netlogic_write_reg(usb_mmio,  0, 0x02000000);
+      }
+      else {
+         printk("Detected USB Device mode..\n");
+         netlogic_write_reg(usb_mmio,  0, 0x01000000);
+      }
+   }
+}
+
+void on_chip_init(void)
+{
+	int i = 0, j = 0;
+
+	//cpu_logical_map(0)  = hard_smp_processor_id();
+
+	/* Set netlogic_io_base to the run time value */
+	spin_lock_init(&msgrng_lock);
+
+	msgring_registered.value = 0;
+
+#if defined(CONFIG_NLM_XLP)
+	nlm_hal_init();
+#endif
+
+	nlm_common_msgring_config();
+
+	pic_init(); 
+
+	/* XLP FMN code Not Yet ported! */
+#if !defined(CONFIG_NLM_XLP)
+	nlm_common_msgring_cpu_init();
+#endif
+
+
+
+	for (i = 0; i < NR_CPUS; i++)
+		for (j = 0; j < NLM_MAX_COUNTERS; j++)
+			atomic_set(&nlm_common_counters[i][j], 0);
+
+	if (is_xls())
+		nlm_usb_init();
+}
diff --git a/arch/mips/netlogic/xlp/platform-xlp.c b/arch/mips/netlogic/xlp/platform-xlp.c
new file mode 100644
index 0000000..4819ad7
--- /dev/null
+++ b/arch/mips/netlogic/xlp/platform-xlp.c
@@ -0,0 +1,290 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/dma-mapping.h>
+#include <linux/init.h>
+#include <linux/platform_device.h>
+#include <linux/serial.h>
+#include <linux/serial_8250.h>
+#include <linux/pci.h>
+
+#include <asm/time.h>
+#include <asm/netlogic/hal/nlm_hal_macros.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+
+#define XLP_SOC_PCI_DRIVER "XLP SoC Driver"
+
+#define PCI_NETL_VENDOR             0x184E
+
+#define PCI_DEVID_DEFAULT           0x1000
+#define PCI_DEVID_BASE              (PCI_DEVID_DEFAULT + 0x00)
+
+#define PCI_DEVID_OFF_SBU           0x01
+#define PCI_DEVID_OFF_ICI           0x02
+#define PCI_DEVID_OFF_PIC           0x03
+#define PCI_DEVID_OFF_PCIE          0x04
+#define PCI_DEVID_OFF_CAM           0x05
+#define PCI_DEVID_OFF_USB           0x06
+#define PCI_DEVID_OFF_EHCI          0x07
+#define PCI_DEVID_OFF_OHCI          0x08
+#define PCI_DEVID_OFF_NET           0x09
+
+#define PCI_DEVID_OFF_POE           0x0A
+#define PCI_DEVID_OFF_MSG           0x0B
+#define PCI_DEVID_OFF_GDX           0x0C
+#define PCI_DEVID_OFF_SEC           0x0D
+#define PCI_DEVID_OFF_RSA           0x0E
+#define PCI_DEVID_OFF_CMP           0x0F
+
+#define PCI_DEVID_OFF_UART          0x10
+#define PCI_DEVID_OFF_I2C           0x11
+#define PCI_DEVID_OFF_GPIO          0x12
+#define PCI_DEVID_OFF_SYS           0x13
+#define PCI_DEVID_OFF_JTAG          0x14
+#define PCI_DEVID_OFF_NOR           0x15
+#define PCI_DEVID_OFF_NAND          0x16
+#define PCI_DEVID_OFF_SPI           0x17
+#define PCI_DEVID_OFF_MMC           0x18
+#define PCI_DEVID_OFF_LAST          0x19
+
+#define PCI_MAX_DEVICES             (PCI_DEVID_OFF_LAST + 1)
+
+#define UART_CLK 133333333
+
+#define MAX_NUM_UARTS 3
+
+struct soc_dev {
+	const char *name;
+	void (*probe)(struct pci_dev *pdev, unsigned long pci_cfg_dev_base);
+};
+
+const char *pci_cfg_dev_regs[16] = {
+	[0] = "Dev Info 0",
+	[1] = "Dev Info 1",
+	[2] = "Dev Info 2",
+	[3] = "Dev Info 3",
+	[4] = "Dev Info 4",
+	[5] = "Dev Info 5",
+	[6] = "Dev Info 6",
+	[7] = "Dev Info 7",
+	[8] = "Dev Scratch 0",
+	[9] = "Dev Scratch 1",
+	[10] = "Dev Scratch 2",
+	[11] = "Dev Scratch 3",
+	[12] = "Dev Msg Stn Info",
+	[13] = "Dev IRT Info",
+	[14] = "uCode Engine Info",
+	[15] = "SBB BW Weight Entry Info"
+};
+
+static struct pci_device_id soc_pci_table[PCI_MAX_DEVICES] __devinitdata;
+
+static struct plat_serial8250_port uart_ports[MAX_NUM_UARTS] = {
+	[MAX_NUM_UARTS - 1] = { .flags = 0 } /* tenetlogicnating condition */
+};
+
+static void nlmc_hal_pci_cfg(int devfn, unsigned long pci_cfg_dev_base)
+{
+	int i = 0;
+	unsigned int *cfg_base = (unsigned int *)pci_cfg_dev_base;
+
+	cfg_base += (0xC0 >> 2);
+	for (i = 0; i < 16; i++) {
+		unsigned int value = cfg_base[i];
+
+		if (!value) continue;
+/* 		printk("[%s]: reg[%s] = %08x\n", __FUNCTION__, pci_cfg_dev_regs[i], value); */
+	}
+}
+
+static void xlp_sbu_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+}
+
+static void xlp_pic_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+}
+
+static void xlp_cms_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+}
+
+static void xlp_sys_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+}
+
+static void xlp_default_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+}
+
+static void xlp_uart_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+	static atomic_t num_uarts = ATOMIC_INIT(0);
+	int instance = atomic_inc_return(&num_uarts) - 1;
+
+	if (instance < 0 || instance >= (MAX_NUM_UARTS - 1)) {
+		printk("Request for Invalid uart port_%d\n", instance);
+		return ;
+	}
+
+ 	if (!instance) {
+		struct platform_device *uart = 0;
+
+		/* If this is the first instance of registration, create the platform device */
+
+		uart = platform_device_alloc("serial8250", PLAT8250_DEV_PLATFORM);
+		if (!uart) {
+			printk("Unable to allocate memory for UART platform device!\n");
+			return;
+		}
+
+		uart->dev.platform_data = &uart_ports[0];
+
+		if (platform_device_add(uart)) {
+			printk("Unable to register uart plaform device!\n");
+			return;
+		}
+		printk("Platform registered UART device\n");
+	}
+
+	uart_ports[instance].mapbase       = pci_cfg_dev_base + 0x100; /* skip PCI CFG header */
+	uart_ports[instance].membase       = (void __iomem *)uart_ports[instance].mapbase;
+	uart_ports[instance].irq           = PIC_UART_0_IRQ + instance;
+
+	uart_ports[instance].uartclk       = UART_CLK;
+	uart_ports[instance].iotype        = UPIO_MEM;
+	uart_ports[instance].flags         = ASYNC_BOOT_AUTOCONF | ASYNC_SKIP_TEST;
+	uart_ports[instance].type          = UPIO_PORT;
+	uart_ports[instance].regshift      = 2;
+
+	printk("Platform added UART port_%d (irq=%d, @%lx)\n", instance,
+	       uart_ports[instance].irq, (unsigned long)uart_ports[instance].mapbase);
+
+	nlmc_hal_pci_cfg(pdev->devfn, pci_cfg_dev_base);
+}
+
+static struct soc_dev soc_devices[PCI_MAX_DEVICES] = {
+	[PCI_DEVID_OFF_SBU]  = {.name = "South Bridge",                      .probe = xlp_sbu_probe},
+	[PCI_DEVID_OFF_PIC]  = {.name = "Programmable Interrupt Controller", .probe = xlp_pic_probe},
+	[PCI_DEVID_OFF_MSG]  = {.name = "Central Messaging Station",         .probe = xlp_cms_probe},
+	[PCI_DEVID_OFF_UART] = {.name = "UART",                              .probe = xlp_uart_probe},
+	[PCI_DEVID_OFF_SYS]  = {.name = "Sys",                               .probe = xlp_sys_probe},
+};
+
+static int __devinit soc_device_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
+{
+	unsigned long mmio_paddr = 0, mmio_size = 0;
+	void *mmio_vaddr = 0;
+	int irq;
+	int result;
+	int base_class, sub_class, prog_int;
+	int dev = (pdev->devfn >> 3) & 0x1f;
+
+	int dev_off = pdev->device - PCI_DEVID_BASE;
+	void (*probe)(struct pci_dev *, unsigned long);
+
+	int fn = (pdev->devfn & 0x7);
+	const int num_fns = 8;
+	const int pci_cfg_size = 0x1000;
+	unsigned long pci_cfg_dev_base = (unsigned long)(xlp_io_base + (dev * num_fns * pci_cfg_size)
+							 + (fn * pci_cfg_size));
+
+	base_class = (pdev->class >> 16) & 0xff;
+	sub_class = (pdev->class >> 8) & 0xff;
+	prog_int = (pdev->class >> 0) & 0xff;
+
+	result = pci_enable_device(pdev);
+	if (result) return result;
+
+	mmio_paddr = pci_resource_start(pdev, 0);
+	mmio_size = pci_resource_len(pdev, 0);
+	irq = pdev->irq;
+
+	if (mmio_paddr) {
+		result = pci_request_regions(pdev, XLP_SOC_PCI_DRIVER);
+		if (result) {
+			printk("[%s]: unable to pci_request_regions\n", __FUNCTION__);
+			return result;
+		}
+
+		mmio_vaddr = ioremap(mmio_paddr, mmio_size);
+		if (!mmio_vaddr) {
+			printk("[%s]: unable to ioremap\n", __FUNCTION__);
+			pci_release_regions(pdev);
+			return 1;
+		}
+	}
+
+	probe = soc_devices[dev_off].probe;
+	if (!probe) {
+		printk("No probe handler found for XLP device \"%s\"\n", soc_devices[dev_off].name);
+	}
+	else {
+		printk("Invoking probe handler for XLP device \"%s\"\n", soc_devices[dev_off].name);
+		probe(pdev, pci_cfg_dev_base);
+	}
+
+	return 0;
+}
+
+static struct pci_driver soc_driver = {
+	.name             = XLP_SOC_PCI_DRIVER,
+	.id_table         = soc_pci_table,
+	.probe            = soc_device_probe,
+};
+
+static int __init soc_device_init(void)
+{
+	int i = 0;
+
+	for (i = 0; i < PCI_MAX_DEVICES; i++) {
+		soc_pci_table[i].vendor        = PCI_NETL_VENDOR;
+		soc_pci_table[i].device        = PCI_DEVID_BASE + i;
+		soc_pci_table[i].subvendor     = PCI_ANY_ID;
+		soc_pci_table[i].subdevice        = PCI_ANY_ID;
+		soc_pci_table[i].driver_data   = 0;
+
+		if (soc_devices[i].name) continue;
+		soc_devices[i].name = "unrecognized";
+		soc_devices[i].probe = xlp_default_probe;
+	}
+	soc_pci_table[PCI_DEVID_OFF_LAST].vendor        = 0;
+	soc_pci_table[PCI_DEVID_OFF_LAST].device        = 0;
+	soc_pci_table[PCI_DEVID_OFF_LAST].subvendor     = 0;
+	soc_pci_table[PCI_DEVID_OFF_LAST].subdevice     = 0;
+	soc_pci_table[PCI_DEVID_OFF_LAST].driver_data   = 0;
+
+	return pci_register_driver(&soc_driver);
+}
+
+static void __init soc_device_exit(void)
+{
+	pci_unregister_driver(&soc_driver);
+}
+
+module_init(soc_device_init);
+module_exit(soc_device_exit);
+
+MODULE_DEVICE_TABLE(pci, soc_pci_table);
diff --git a/arch/mips/netlogic/xlp/setup.c b/arch/mips/netlogic/xlp/setup.c
index 1331b29..564eb7a 100644
--- a/arch/mips/netlogic/xlp/setup.c
+++ b/arch/mips/netlogic/xlp/setup.c
@@ -35,12 +35,15 @@
 #include <linux/kernel.h>
 #include <linux/serial_8250.h>
 #include <linux/pm.h>
+#include <linux/bootmem.h>
 
 #include <asm/reboot.h>
 #include <asm/time.h>
 #include <asm/bootinfo.h>
 
 #include <linux/of_fdt.h>
+#include <linux/of_platform.h>
+#include <linux/of_device.h>
 
 #include <asm/netlogic/haldefs.h>
 #include <asm/netlogic/common.h>
@@ -49,11 +52,127 @@
 #include <asm/netlogic/xlp-hal/xlp.h>
 #include <asm/netlogic/xlp-hal/sys.h>
 
+#include <asm/netlogic/sim.h>
+
+/* Certain macros for this file
+ */
+
+#define TRUE 					1
+#define FALSE 					0
+
+#define LOADER_UBOOT			1
+#define LOADER_OTHER			2
+
+#define GPIO_SWRESET_REG 		8
+
+#define DEFAULT_LINUX_CPU_MASK 	0x1
+#define DEFAULT_LOADER_MASK 	~DEFAULT_LINUX_CPU_MASK
+
+#define PER_CPU_THREAD_SIZE 	(THREAD_SIZE >> 2)
+#define TOTAL_THREAD_SIZE       (PER_CPU_THREAD_SIZE * (NR_CPUS - 1))
+
+#define BOOT_LOADER_REGION_SZ 	0x04000000
+#define LOADER_KSEG_END 		0x10000000
+
+/* used by the default memory map
+ */
+#define DEF_PHYMEM_START_ADDR 	0x100000
+#define DEF_PHYMEM_SIZE 		0x0ff00000
+
+#define LOADER_KSEG_DEFAULTS nlm_common_loader_kseg_start = NLM_LOADER_KSEG0_START;\
+		nlm_common_loader_kseg_size = NLM_LOADER_KSEG0_SIZE;
+
+#define LOADER_KUSEG_DEFAULTS   \
+		memset(kuseg_mem_map, 0, (sizeof(struct kuseg_mem_info) * 4));	\
+		use_kuseg_defaults(map);
+
+extern char _end;
+
+/* by default, do not assume u-boot */
+int loader_used = LOADER_OTHER; 
+
+/* Struct for temp. allocation
+ * of sp/gp for secondary CPUs 
+ */
+struct xlr_stack_pages {
+	unsigned long stack[(TOTAL_THREAD_SIZE)/sizeof(long)];
+};
+
+struct xlr_stack_pages xlr_stack_pages_temp
+__attribute__((__section__(".data.init_task"),
+	       __aligned__(THREAD_SIZE)));
+
+extern void prom_pre_boot_secondary_cpus(void *);
+
+struct proc_dir_entry *nlm_root_proc;
+EXPORT_SYMBOL(nlm_root_proc);
+
+/* used for command line parsing */
+uint32_t nlm_common_loader_kseg_start, nlm_common_loader_kseg_size;
+uint32_t nlm_common_loader_mask;
+/* Size of the shared memory b/w Linux userapp and rmios apps */
+uint32_t nlm_common_app_sh_mem_sz;
+unsigned long  nlm_common_app_shmem_start;
+
+/* xls chip family variables */
+int chip_is_xls6xx = 0;
+int chip_is_xls4xx = 0;
+int chip_is_xls2xx = 0;
+int chip_is_xls1xx = 0;
+int chip_is_xls = 0;
+int chip_is_xls_b0 = 0;
+int chip_is_xls6xx_b0 = 0;
+int chip_is_xls4xx_b0 = 0;
+EXPORT_SYMBOL(chip_is_xls6xx);
+EXPORT_SYMBOL(chip_is_xls4xx);
+EXPORT_SYMBOL(chip_is_xls2xx);
+EXPORT_SYMBOL(chip_is_xls1xx);
+EXPORT_SYMBOL(chip_is_xls);
+EXPORT_SYMBOL(chip_is_xls_b0);
+EXPORT_SYMBOL(chip_is_xls6xx_b0);
+EXPORT_SYMBOL(chip_is_xls4xx_b0);
+
+__u32 xlr_board_major_version = 0;
+__u32 xlr_board_minor_version = 0;
+
+struct psb_info prom_info_copy; /* Bootloader prom_info is saved here */
+int xlr_hybrid;
+int xlr_loader_support=0;
+int xlr_loader_sharedcore=0;
+int xlr_loader_own_gmac=0;
+int xlr_loader_own_dma=0;
+
+uint32_t xlr_linux_cpu_mask;
+int xlr_console_pci_con_dev = 0;
+int xlr_console_pci_con_baud = 0;
+int xlr_boot_over_nfs = 0;
+
 unsigned long nlm_common_ebase = 0x0;
+ 
+unsigned long long nlm_common_tlb_stats[NR_CPUS] __cacheline_aligned;
 
 /* default to uniprocessor */
 uint32_t nlm_coremask = 1, nlm_cpumask  = 1;
 int  nlm_threads_per_core = 1;
+extern u32 __dtb_start[];
+
+void prom_reconfigure_thr_resources(void)
+{
+}
+
+int nlm_common_get_pgprot(unsigned long address)
+{
+	return 0;
+}
+
+void plat_time_init(void)
+{
+}
+
+int valid_mmap_nlm_common_addr_range(unsigned long pfn)
+{
+	return 0;
+}
 
 static void nlm_linux_exit(void)
 {
@@ -70,6 +189,14 @@ void __init plat_mem_setup(void)
 	pm_power_off	= nlm_linux_exit;
 }
 
+#ifdef CONFIG_MAPPED_KERNEL
+#define secondary_cpus_bootup_func \
+	((unsigned long)prom_pre_boot_secondary_cpus - \
+	 (unsigned long)LOADADDR + (unsigned long)PHYSADDR)
+#else
+#define secondary_cpus_bootup_func prom_pre_boot_secondary_cpus
+#endif
+
 const char *get_system_type(void)
 {
 	return "Netlogic XLP Series";
@@ -82,8 +209,10 @@ void __init prom_free_prom_memory(void)
 
 void xlp_mmu_init(void)
 {
+	/* enable extended TLB and Large Fixed TLB */
 	write_c0_config6(read_c0_config6() | 0x24);
-	current_cpu_data.tlbsize = ((read_c0_config6() >> 16) & 0xffff) + 1;
+
+	/* set page mask of Fixed TLB in config7 */
 	write_c0_config7(PM_DEFAULT_MASK >>
 		(13 + (ffz(PM_DEFAULT_MASK >> 13) / 2)));
 }
@@ -92,6 +221,9 @@ void __init prom_init(void)
 {
 	void *fdtp;
 
+	xlp_mmu_init();
+	nlm_hal_init();
+
 	/*
 	 * If no FDT pointer is passed in, use the built-in FDT.
 	 * device_tree_init() does not handle CKSEG0 pointers in
@@ -101,13 +233,46 @@ void __init prom_init(void)
 	if (!fdtp)
 		fdtp = __dtb_start;
 	fdtp = phys_to_virt(__pa(fdtp));
-	xlp_mmu_init();
-	nlm_hal_init();
 	early_init_devtree(fdtp);
 
 	nlm_common_ebase = read_c0_ebase() & (~((1 << 12) - 1));
 #ifdef CONFIG_SMP
-	nlm_wakeup_secondary_cpus(0xffffffff);
+	/* update TLB size after waking up threads */
+	current_cpu_data.tlbsize = ((read_c0_config6() >> 16) & 0xffff) + 1;
+
 	register_smp_ops(&nlm_smp_ops);
 #endif
 }
+
+void __init device_tree_init(void)
+{
+	unsigned long base, size;
+
+	if (!initial_boot_params)
+		return;
+
+	base = virt_to_phys((void *)initial_boot_params);
+	size = be32_to_cpu(initial_boot_params->totalsize);
+
+	/* Before we do anything, lets reserve the dt blob */
+	reserve_bootmem(base, size, BOOTMEM_DEFAULT);
+
+	unflatten_device_tree();
+
+	/* free the space reserved for the dt blob */
+	free_bootmem(base, size);
+}
+
+static struct of_device_id __initdata xlp_ids[] = {
+	{ .compatible = "simple-bus", },
+	{},
+};
+
+int __init xlp8xx_ds_publish_devices(void)
+{
+	if (!of_have_populated_dt())
+		return 0;
+	return of_platform_bus_probe(NULL, xlp_ids, NULL);
+}
+
+device_initcall(xlp8xx_ds_publish_devices);
diff --git a/arch/mips/netlogic/xlp/smp.c b/arch/mips/netlogic/xlp/smp.c
new file mode 100644
index 0000000..f6fb4fe
--- /dev/null
+++ b/arch/mips/netlogic/xlp/smp.c
@@ -0,0 +1,237 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+
+#include <asm/mipsregs.h>
+#include <asm/mmu_context.h>
+#include <asm/atomic.h>
+//#include <asm/cpumask.h>
+
+#include <asm/netlogic/sim.h>
+#include <asm/netlogic/msgring.h>
+#include <asm/netlogic/mips-exts.h>
+#include <asm/netlogic/xlr_user_mac.h>
+
+#include <asm/asm.h>
+#include <asm/mipsregs.h>
+#include <asm/processor.h>
+
+#include <asm/mach-netlogic/mmu.h>
+
+extern int xlr_loader_support;
+extern volatile cpumask_t cpu_callin_map;
+extern void __init phoenix_smp_init(void); 
+extern void phoenix_smp_finish(void);
+
+extern void smp_tune_scheduling (void);
+extern void ptr_smp_boot(unsigned long, unsigned long, unsigned long);
+struct smp_boot_info smp_boot;
+extern void prom_reconfigure_thr_resources(void);
+extern uint32_t nlm_common_loader_mask;
+extern unsigned long nlm_common_ebase;
+
+
+int phys_proc_id[NR_CPUS]; /* cpuid+thrid of each logical CPU */
+cpumask_t phys_cpu_present_map;
+extern void asmlinkage smp_bootstrap(void);
+extern void core_send_ipi(int cpu, unsigned int action);
+
+void nlm_send_ipi_single(int cpu, unsigned int action)
+{
+    core_send_ipi(cpu, action);
+}
+
+void nlm_send_ipi_mask(const struct cpumask * mask, unsigned int action)
+{
+    int cpu;
+    for_each_cpu(cpu, mask){
+        core_send_ipi(cpu, action);
+    }
+}
+
+/*
+ * Code to run on secondary just after probing the CPU
+ */
+static void __cpuinit nlm_init_secondary(void)
+{
+    extern void nlm_smp_irq_init(void);
+
+    nlm_smp_irq_init();
+    /* Time init for this cpu is done in mips_clockevent_init() */
+}
+
+void nlm_smp_finish(void)
+{
+#if !defined(CONFIG_NLM_XLP)
+    phoenix_msgring_cpu_init();
+#endif
+}
+
+void nlm_cpus_done(void)
+{
+}
+
+/* Boot all other cpus in the system, initialize them, and
+   bring them into the boot fn */
+void nlm_boot_secondary(int logical_cpu, struct task_struct *idle)
+{
+	unsigned long gp = (unsigned long)task_thread_info(idle);
+	unsigned long sp = (unsigned long)__KSTK_TOS(idle);
+	int cpu = cpu_logical_map(logical_cpu);
+
+/* 	printk("[%s]: (PROM): waking up phys cpu# %d: address of boot_info=%p (addressof(ready)=%p)\n", */
+/* 	       __FUNCTION__, cpu, &(smp_boot.boot_info[cpu]), &((smp_boot.boot_info[cpu]).ready)); */
+  
+	smp_boot.boot_info[cpu].sp = sp;
+	smp_boot.boot_info[cpu].gp = gp;
+	smp_boot.boot_info[cpu].fn = (unsigned long)&smp_bootstrap;  
+	/* barrier */
+	__sync();
+	smp_boot.boot_info[cpu].ready = 1;
+  
+/* 	printk("[%s]: (PROM): sent a wakeup message to cpu %d\n", __FUNCTION__, cpu); */
+}
+
+extern void ptr_smp_boot(unsigned long, unsigned long, unsigned long);
+struct smp_boot_info smp_boot;
+extern void prom_reconfigure_thr_resources(void);
+extern uint32_t nlm_common_loader_mask;
+extern unsigned long nlm_common_ebase;
+
+unsigned int fast_syscall_cpumask_phy = 0x1;
+
+void __init nlm_smp_setup(void)
+{
+	int num_cpus = 1;
+	__u32 boot_cpu_online_map = 0, boot_cpu = 0x0;
+
+
+	extern __u32 ipi_3_counter_tx[NR_CPUS][NR_CPUS];
+	extern __u32 ipi_3_counter_rx[NR_CPUS];
+	int i=0, j=0;
+
+	boot_cpu = hard_smp_processor_id();
+
+	cpus_clear(phys_cpu_present_map);
+	/*	cpu_set(0, phys_cpu_present_map);
+	__cpu_number_map[0] = 0;
+	__cpu_logical_map[0] = 0;  
+	dev_tree_en fix , and also not required for the existing case also */
+
+//	cpus_clear(cpu_possible_map);
+	/* cpu_set(0, cpu_possible_map); */
+
+	/* Initialize the ipi debug stat variables */
+	for(i=0;i<NR_CPUS;i++) {
+		for(j=0;j<NR_CPUS;j++)
+			ipi_3_counter_tx[i][j] = 0;
+  
+		ipi_3_counter_rx[i] = 0;
+	}
+
+	if(xlr_loader_support) {
+		smp_boot.online_map &= ~nlm_common_loader_mask;
+	}
+
+	boot_cpu_online_map = smp_boot.online_map;
+	printk("(PROM) CPU present map: %x\n", boot_cpu_online_map);
+
+	/* 0th entry in the logical_map should be the bootcpu and all
+       others proceeds after that */
+	/* Fill the entries for boot cpu */
+	boot_cpu_online_map &= (~(1 << boot_cpu));
+	cpu_set(boot_cpu, phys_cpu_present_map);
+	__cpu_number_map[boot_cpu] = 0;
+	__cpu_logical_map[0] = boot_cpu;
+//	cpu_set(0, cpu_possible_map);
+
+	for(i = 0;i<NR_CPUS;i++) {
+		if (boot_cpu_online_map & (1<<i)) {
+			cpu_set(i, phys_cpu_present_map);
+			__cpu_number_map[i] = num_cpus;
+			__cpu_logical_map[num_cpus] = i;
+//			cpu_set(num_cpus, cpu_possible_map);
+			++num_cpus;
+		}
+	}
+
+
+	fast_syscall_cpumask_phy = (unsigned int)phys_cpu_present_map.bits[0];
+
+	printk("Phys CPU present map: %lx, possible map %lx\n", 
+	       (unsigned long)phys_cpu_present_map.bits[0], 
+	       (unsigned long)phys_cpu_present_map.bits[0]);
+
+	printk("Detected %i Slave CPU(s)\n", num_cpus);
+}
+
+void nlm_prepare_cpus(unsigned int max_cpus)
+{
+}
+
+
+struct plat_smp_ops nlm_smp_ops = {
+    .send_ipi_single    = nlm_send_ipi_single,
+    .send_ipi_mask      = nlm_send_ipi_mask,
+    .init_secondary     = nlm_init_secondary,
+    .smp_finish     = nlm_smp_finish,
+    .cpus_done      = nlm_cpus_done,
+    .boot_secondary     = nlm_boot_secondary,
+    .smp_setup      = nlm_smp_setup,
+    .prepare_cpus       = nlm_prepare_cpus,
+};
+
+
+
+void prom_boot_cpus_secondary(void *args)
+{
+	int cpu = hard_smp_processor_id();
+  
+	write_c0_ebase((uint32_t)nlm_common_ebase);
+	atomic_add((1<<cpu), (atomic_t *)&smp_boot.online_map);
+	for(;;) {
+		if (smp_boot.boot_info[cpu].ready) break;
+	}
+	__sync();
+
+	prom_reconfigure_thr_resources();
+
+        setup_mapped_kernel_tlbs(TRUE, FALSE);
+        setup_mapped_kernel_tlbs(FALSE, FALSE);
+
+	ptr_smp_boot(smp_boot.boot_info[cpu].fn, smp_boot.boot_info[cpu].sp, 
+		     smp_boot.boot_info[cpu].gp);
+}
+
+
+
+#ifdef CONFIG_NLM_XLP
+/* place holder for boot multiple cpu function */
+
+#endif //CONFIG_NLM_XLP
diff --git a/arch/mips/netlogic/xlp/time.c b/arch/mips/netlogic/xlp/time.c
new file mode 100644
index 0000000..a9bad30
--- /dev/null
+++ b/arch/mips/netlogic/xlp/time.c
@@ -0,0 +1,226 @@
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are peNLMtted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
+
+#include <linux/interrupt.h>
+#include <linux/sched.h>
+#include <linux/spinlock.h>
+
+#include <asm/irq.h>
+#include <asm/ptrace.h>
+#include <asm/addrspace.h>
+#include <asm/time.h>
+#include <asm/cpu.h>
+#include <asm/cpu-features.h>
+#include <asm/perfctr.h>
+#include <linux/oprofile.h>
+
+#include <linux/proc_fs.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+
+extern spinlock_t nlm_common_pic_lock;
+
+#if defined(CONFIG_PERFCTR) && defined(CONFIG_OPROFILE)
+#error "Cannot enable both VPERF and OProfile at the same time"
+#endif
+
+#ifndef CONFIG_NLMCOMMON_MAC
+void nlm_common_user_mac_update_time(void)
+{
+}
+void nlm_common_user_mac_update_ktime(void)
+{
+}
+#else
+extern void nlm_common_user_mac_update_time(void);
+extern void nlm_common_user_mac_update_ktime(void);
+#endif
+ 
+extern struct irq_chip nlm_common_rsvd_pic;
+extern struct irqaction nlm_common_rsvd_action;
+
+void save_epc(unsigned long *epc)
+{
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     "mfc0 %0, $14\n" ".set pop\n":"=r"(*epc));
+}
+
+#ifdef CONFIG_OPROFILE
+extern void nlm_common_oprofile_int_handler(int irq, void *dev_id,
+					 struct pt_regs *regs);
+#endif
+void nlm_common_timer_interrupt(struct pt_regs *regs, int irq)
+{
+	int cpu = smp_processor_id();
+
+#ifdef CONFIG_NLM_WATCHDOG
+        pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+
+	/* ack the watchdog */
+	/* Need to choose (?) the right heartbeat reg (0/1) and right chunk */
+	nlm_hal_write_pic_reg(mmio, PIC_WD_HEARTBEAT_0(0), 1 << cpu_logical_map(cpu));
+#endif
+
+#if defined (CONFIG_OPROFILE) || defined (CONFIG_PERFCTR_INTERRUPT_SUPPORT)
+    int cntr0, cntr1;
+    uint32_t ctrl0, ctrl1;
+	int    perfctr_overflow = 0;
+#endif
+
+#ifdef CONFIG_NLM_WATCHDOG
+	/* ack the watchdog */
+	netlogic_write_reg(mmio, 0x0c, 1 << cpu_logical_map(cpu));
+#endif
+
+	if (irq != IRQ_TIMER) {
+		printk("[%s]:cpu_%d: bad timer irq = %x\n", __FUNCTION__, cpu, irq);
+		BUG();
+	}
+
+#if defined (CONFIG_PERFCTR_INTERRUPT_SUPPORT) || defined (CONFIG_OPROFILE)
+    ctrl0 = __read_32bit_c0_register($25, 0);
+    ctrl1 = __read_32bit_c0_register($25, 2);
+    cntr0 = __read_32bit_c0_register($25, 1);
+    cntr1 = __read_32bit_c0_register($25, 3);
+
+    /* if interrupts are enabled for perf events, check if any counter has
+       overflowed. Then we know for sure that this is a perf event
+       */
+    if((ctrl0 & 0x10) || (ctrl1 & 0x10))
+            if((cntr0 < 0) || (cntr1 < 0))
+                perfctr_overflow = 1;
+    if(perfctr_overflow == 0)
+#endif
+    {
+        do_IRQ(irq);
+
+        if (cpu == 0) {
+            nlm_common_user_mac_update_time();
+	    nlm_common_user_mac_update_ktime();
+        }
+    }
+
+#if defined (CONFIG_PERFCTR_INTERRUPT_SUPPORT) || defined (CONFIG_OPROFILE)
+	if (perfctr_overflow) {
+#ifdef CONFIG_PERFCTR_INTERRUPT_SUPPORT
+		(*perfctr_ihandler) (instruction_pointer(regs));
+#endif
+    }
+#ifdef CONFIG_OPROFILE
+	if (perfctr_overflow) {
+		if(netlogic_thr_id() == 0) {
+			nlm_common_oprofile_int_handler (irq, NULL, regs);
+		}
+    }
+#endif
+#endif
+
+}
+
+/* PIC clock at 66Mhz takes more than 60 secs to come to 0 from max. So 32bit 
+   counter is sufficient
+   */
+#define PIC_FREE_RUNNING_TIMER_MAX_VAL 0xffffffff
+cycle_t xlr_hpt_read(void)
+{
+	uint32_t counter;
+	pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+	counter = (uint32_t) nlm_hal_read_pic_reg(mmio, PIC_TIMER_6_COUNTER);
+	return (cycle_t)(PIC_FREE_RUNNING_TIMER_MAX_VAL - counter);
+}
+
+int read_current_timer(unsigned long *timer_val)
+{
+	*timer_val = xlr_hpt_read();
+	return 0;
+}
+
+void nlm_common_timer_setup(void)
+{
+        pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+        unsigned long flags = 0;
+
+        spin_lock_irqsave(&nlm_common_pic_lock, flags);
+
+        /* Use PIC Timer 6 as a free running counter */
+        nlm_hal_write_pic_reg(mmio, PIC_TIMER_6_MAXVAL, 0xffffffffffffffffULL);
+
+	/* enable the timer */
+        nlm_hal_pic_update_control(1 << (10 + 6));
+
+        spin_unlock_irqrestore(&nlm_common_pic_lock, flags);
+        //do_gettimeoffset = xlr_gettimeoffset;
+
+}
+
+static int nlm_timer_proc_read(char *page, char **start, off_t off, int count,
+			       int *eof, void *data)
+{
+	int len = 0;
+
+	preempt_disable();
+	len += sprintf(page + len, "cpu = %d, eimr = 0x%016llx, status = 0x%x\n", 
+				   smp_processor_id(), 
+                   (unsigned long long)read_64bit_cp0_eimr(), read_c0_status());
+	preempt_enable();
+	*eof = 1;
+
+	return len;
+}
+
+extern struct proc_dir_entry *nlm_root_proc;
+struct proc_dir_entry *main_entry;
+struct proc_dir_entry *sub_entry;
+
+static int init_pic_timer_procfs(void)
+{
+	main_entry = proc_mkdir("nlm_timer", nlm_root_proc);
+	if (!main_entry) {
+		printk(KERN_ERR "unable to create /proc/nlm_timer\n");
+		return -ENOMEM;
+	}
+
+	sub_entry = create_proc_entry("debug", 0644, main_entry);
+
+	if (!sub_entry) {
+		remove_proc_entry("nlm_timer", nlm_root_proc);
+		return -ENOMEM;
+	}
+
+	sub_entry->read_proc = nlm_timer_proc_read;
+
+	printk("created nlm_timer proc fs entry\n");
+
+	return 0;
+}
+
+static void exit_pic_timer_procfs(void)
+{
+	remove_proc_entry("debug", main_entry);
+	remove_proc_entry("nlm_timer", nlm_root_proc);
+}
+
+module_init(init_pic_timer_procfs);
+module_exit(exit_pic_timer_procfs);
diff --git a/arch/mips/oprofile/Makefile b/arch/mips/oprofile/Makefile
index f52513b..04cd670 100644
--- a/arch/mips/oprofile/Makefile
+++ b/arch/mips/oprofile/Makefile
@@ -15,5 +15,5 @@ oprofile-$(CONFIG_CPU_MIPS64)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_R10000)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_SB1)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_RM9000)		+= op_model_rm9000.o
-oprofile-$(CONFIG_RMI_PHOENIX)		+= op_model_mips_xlr.o
+oprofile-$(CONFIG_NLM_COMMON)		+= op_model_mips_xlr.o
 oprofile-$(CONFIG_CPU_LOONGSON2)	+= op_model_loongson2.o
diff --git a/arch/mips/oprofile/common.c b/arch/mips/oprofile/common.c
index 8c73389..a8477db 100644
--- a/arch/mips/oprofile/common.c
+++ b/arch/mips/oprofile/common.c
@@ -1,14 +1,10 @@
-/************************************************************************
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems Inc. (“Netlogic”).
+This is a derived work from software originally provided by the external
+entity identified below. The licensing terms and warranties specified in
+the header of the original work apply to this derived work.
 
-  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
-
-  This is a derived work from software originally provided by the external
-  entity identified below. The licensing terms and warranties specified in
-  the header of the original work apply to this derived work.
-
-  Contribution by RMI:
-
- *****************************#RMI_1#************************************/
+*****************************#NETL_1#********************************/
 
 /*
  * This file is subject to the terms and conditions of the GNU General Public
diff --git a/arch/mips/pci/pci-xlp.c b/arch/mips/pci/pci-xlp.c
index 653d2db..062ef6a 100644
--- a/arch/mips/pci/pci-xlp.c
+++ b/arch/mips/pci/pci-xlp.c
@@ -1,101 +1,96 @@
-/*
- * Copyright (c) 2003-2012 Broadcom Corporation
- * All Rights Reserved
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the Broadcom
- * license below:
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in
- *    the documentation and/or other materials provided with the
- *    distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
- * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
- * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
 
 #include <linux/types.h>
 #include <linux/pci.h>
 #include <linux/kernel.h>
 #include <linux/init.h>
-#include <linux/msi.h>
 #include <linux/mm.h>
-#include <linux/irq.h>
-#include <linux/irqdesc.h>
 #include <linux/console.h>
 
 #include <asm/io.h>
 
 #include <asm/netlogic/interrupt.h>
-#include <asm/netlogic/haldefs.h>
-#include <asm/netlogic/common.h>
+#include <asm/netlogic/pci.h>
+#include <asm/netlogic/io.h>
+#include <asm/netlogic/iomap.h>
+#include <asm/netlogic/sim.h>
 
-#include <asm/netlogic/xlp-hal/iomap.h>
-#include <asm/netlogic/xlp-hal/pic.h>
-#include <asm/netlogic/xlp-hal/xlp.h>
-#include <asm/netlogic/xlp-hal/pcibus.h>
-#include <asm/netlogic/xlp-hal/bridge.h>
+extern int pci_probe_only;
 
 static void *pci_config_base;
+static void *pci_io_base;
+
+#define SWAP32(x)				\
+        (((x) & 0xff000000) >> 24) |		\
+        (((x) & 0x000000ff) << 24) |		\
+        (((x) & 0x0000ff00) << 8)  |		\
+        (((x) & 0x00ff0000) >> 8)
 
-#define pci_cfg_addr(bus, devfn, off) (((bus) << 20) | ((devfn) << 12) | (off))
+static void pcie_controller_init_done(void)
+{
+	/* XLP_MERGE_TODO */
+	printk("[%s]: PCIE Controller initialization to be done\n", __FUNCTION__);
+	return;
+}
 
-/* PCI ops */
-static inline u32 pci_cfg_read_32bit(struct pci_bus *bus, unsigned int devfn,
-	int where)
+static inline __u32 pci_cfg_read_32bit(__u32 addr)
 {
-	u32 data;
-	u32 *cfgaddr;
+	__u32 temp = 0;
+	__u32 *p = (__u32 *) (pci_config_base + (addr & ~3));
 
-	where &= ~3;
-	if (bus->number == 0 && PCI_SLOT(devfn) == 1 && where == 0x954)
-		return 0xffffffff;
+	temp = *p;
 
-	cfgaddr = (u32 *)(pci_config_base +
-			pci_cfg_addr(bus->number, devfn, where));
-	data = *cfgaddr;
-	return data;
+	return temp;
 }
 
-static inline void pci_cfg_write_32bit(struct pci_bus *bus, unsigned int devfn,
-	int where, u32 data)
+static inline void pci_cfg_write_32bit(__u32 addr, __u32 data)
 {
-	u32 *cfgaddr;
+        unsigned int *p = (unsigned int *)(pci_config_base + (addr & ~3));
 
-	cfgaddr = (u32 *)(pci_config_base +
-			pci_cfg_addr(bus->number, devfn, where & ~3));
-	*cfgaddr = data;
+	*p = data;
 }
 
-static int nlm_pcibios_read(struct pci_bus *bus, unsigned int devfn,
-	int where, int size, u32 *val)
+static int pci_bus_status = 0;
+#define pci_cfg_offset(bus, devfn, where) (((bus)<<16)+((devfn)<<8)+(where))
+#define pci_cfg_addr(bus, devfn, where) pci_cfg_offset((bus)->number,(devfn),where)
+
+static int xlp_pcibios_read(struct pci_bus *bus, unsigned int devfn,
+				int where, int size, u32 * val)
 {
-	u32 data;
+	__u32 data = 0;
 
 	if ((size == 2) && (where & 1))
 		return PCIBIOS_BAD_REGISTER_NUMBER;
 	else if ((size == 4) && (where & 3))
 		return PCIBIOS_BAD_REGISTER_NUMBER;
 
-	data = pci_cfg_read_32bit(bus, devfn, where);
+	if (pci_bus_status)
+		data = pci_cfg_read_32bit(pci_cfg_offset((bus->number), devfn, where));
+	else
+		data = 0xFFFFFFFF;
 
 	if (size == 1)
 		*val = (data >> ((where & 3) << 3)) & 0xff;
@@ -107,18 +102,21 @@ static int nlm_pcibios_read(struct pci_bus *bus, unsigned int devfn,
 	return PCIBIOS_SUCCESSFUL;
 }
 
-
-static int nlm_pcibios_write(struct pci_bus *bus, unsigned int devfn,
-		int where, int size, u32 val)
+static int xlp_pcibios_write(struct pci_bus *bus, unsigned int devfn,
+				 int where, int size, u32 val)
 {
-	u32 data;
+	__u32 cfgaddr = pci_cfg_offset((bus->number), devfn, where);
+	__u32 data = 0;
 
 	if ((size == 2) && (where & 1))
 		return PCIBIOS_BAD_REGISTER_NUMBER;
 	else if ((size == 4) && (where & 3))
 		return PCIBIOS_BAD_REGISTER_NUMBER;
 
-	data = pci_cfg_read_32bit(bus, devfn, where);
+	if (!pci_bus_status)
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+
+	data = pci_cfg_read_32bit(cfgaddr);
 
 	if (size == 1)
 		data = (data & ~(0xff << ((where & 3) << 3))) |
@@ -129,156 +127,109 @@ static int nlm_pcibios_write(struct pci_bus *bus, unsigned int devfn,
 	else
 		data = val;
 
-	pci_cfg_write_32bit(bus, devfn, where, data);
+	pci_cfg_write_32bit(cfgaddr, data);
 
 	return PCIBIOS_SUCCESSFUL;
 }
 
-struct pci_ops nlm_pci_ops = {
-	.read  = nlm_pcibios_read,
-	.write = nlm_pcibios_write
+static struct pci_ops xlp_pci_ops = {
+	.read  = xlp_pcibios_read,
+	.write = xlp_pcibios_write
 };
 
-static struct resource nlm_pci_mem_resource = {
-	.name		= "XLP PCI MEM",
-	.start		= 0xd0000000UL, /* 256MB PCI mem @ 0xd000_0000 */
-	.end		= 0xdfffffffUL,
-	.flags		= IORESOURCE_MEM,
+/*
+ * XLP PCIE Controller
+ */
+#define DEFAULT_XLP_PCI_CONFIG_BASE 0x1c000000UL
+static struct resource xlp_mem_resource = {
+	.name           = "XLP PCI MEM",
+	.start          = 0xd0000000UL,          /* 256MB PCI mem @ 0xd000_0000 */
+	.end            = 0xdfffffffUL,
+	.flags          = IORESOURCE_MEM,
 };
-
-static struct resource nlm_pci_io_resource = {
-	.name		= "XLP IO MEM",
-	.start		= 0x14000000UL, /* 64MB PCI IO @ 0x1000_0000 */
-	.end		= 0x17ffffffUL,
-	.flags		= IORESOURCE_IO,
+static struct resource xlp_io_resource = {
+	.name           = "XLP IO MEM",
+	.start          = 0x10000000UL,         /* 16MB PCI IO @ 0x1000_0000 */
+	.end            = 0x100fffffUL,
+	.flags          = IORESOURCE_IO,
 };
-
-struct pci_controller nlm_pci_controller = {
-	.index		= 0,
-	.pci_ops	= &nlm_pci_ops,
-	.mem_resource	= &nlm_pci_mem_resource,
-	.mem_offset	= 0x00000000UL,
-	.io_resource	= &nlm_pci_io_resource,
-	.io_offset	= 0x00000000UL,
+struct pci_controller xlp_controller = {
+	.index          = 0,
+	.pci_ops        = &xlp_pci_ops,
+	.mem_resource   = &xlp_mem_resource,
+	.io_resource    = &xlp_io_resource,
+	.io_offset      = 0x00000000UL,
+	.mem_offset     = 0x00000000UL
 };
 
-static struct pci_dev *xlp_get_pcie_link(const struct pci_dev *dev)
-{
-	struct pci_bus *bus, *p;
-
-	/* Find the bridge on bus 0 */
-	bus = dev->bus;
-	for (p = bus->parent; p && p->number != 0; p = p->parent)
-		bus = p;
-
-	return p ? bus->self : NULL;
-}
-
-static inline int nlm_pci_link_to_irq(int link)
-{
-	return PIC_PCIE_LINK_0_IRQ + link;
-}
-
 int __init pcibios_map_irq(const struct pci_dev *dev, u8 slot, u8 pin)
 {
-	struct pci_dev *lnkdev;
-	int lnkslot, lnkfunc;
-
-	/*
-	 * For XLP PCIe, there is an IRQ per Link, find out which
-	 * link the device is on to assign interrupts
-	*/
-	lnkdev = xlp_get_pcie_link(dev);
-	if (lnkdev == NULL)
-		return 0;
-	lnkfunc = PCI_FUNC(lnkdev->devfn);
-	lnkslot = PCI_SLOT(lnkdev->devfn);
-	return nlm_irq_to_xirq(lnkslot / 8, nlm_pci_link_to_irq(lnkfunc));
+	return 0;
 }
 
 /* Do platform specific device initialization at pci_enable_device() time */
 int pcibios_plat_dev_init(struct pci_dev *dev)
 {
-	return 0;
+        return 0;
 }
 
-/*
- * If big-endian, enable hardware byteswap on the PCIe bridges.
- * This will make both the SoC and PCIe devices behave consistently with
- * readl/writel.
- */
-#ifdef __BIG_ENDIAN
-static void xlp_config_pci_bswap(int node, int link)
-{
-	uint64_t nbubase, lnkbase;
-	u32 reg;
-
-	nbubase = nlm_get_bridge_regbase(node);
-	lnkbase = nlm_get_pcie_base(node, link);
-
-	/*
-	 *  Enable byte swap in hardware. Program each link's PCIe SWAP regions
-	 * from the link's address ranges.
-	 */
-	reg = nlm_read_bridge_reg(nbubase, BRIDGE_PCIEMEM_BASE0 + link);
-	nlm_write_pci_reg(lnkbase, PCIE_BYTE_SWAP_MEM_BASE, reg);
+/* Enabled by default */
+static int __initdata xlp_nopci = 0;
 
-	reg = nlm_read_bridge_reg(nbubase, BRIDGE_PCIEMEM_LIMIT0 + link);
-	nlm_write_pci_reg(lnkbase, PCIE_BYTE_SWAP_MEM_LIM, reg | 0xfff);
-
-	reg = nlm_read_bridge_reg(nbubase, BRIDGE_PCIEIO_BASE0 + link);
-	nlm_write_pci_reg(lnkbase, PCIE_BYTE_SWAP_IO_BASE, reg);
+static int __init xlp_nopci_setup(char *str)
+{
+	/* Disable PCI/X/E; disables HT also */
+	xlp_nopci = 1;
 
-	reg = nlm_read_bridge_reg(nbubase, BRIDGE_PCIEIO_LIMIT0 + link);
-	nlm_write_pci_reg(lnkbase, PCIE_BYTE_SWAP_IO_LIM, reg | 0xfff);
+	return 1;
 }
-#else
-/* Swap configuration not needed in little-endian mode */
-static inline void xlp_config_pci_bswap(int node, int link) {}
-#endif /* __BIG_ENDIAN */
+__setup("xlp_nopci", xlp_nopci_setup);
 
 static int __init pcibios_init(void)
 {
-	struct nlm_soc_info *nodep;
-	uint64_t pciebase;
-	int link, n;
-	u32 reg;
+	unsigned long phys = 0;
+	unsigned long size = 0;
 
-	/* Firmware assigns PCI resources */
-	pci_set_flags(PCI_PROBE_ONLY);
-	pci_config_base = ioremap(XLP_DEFAULT_PCI_ECFG_BASE, 64 << 20);
+	if (xlp_nopci) return 0;
 
-	/* Extend IO port for memory mapped io */
-	ioport_resource.start =	 0;
-	ioport_resource.end   = ~0;
+	/* Bootloader assigns PCI resources */
+	pci_probe_only = 1;
+
+	/* Map the PCIX CFG space */
+	pci_config_base = ioremap(DEFAULT_XLP_PCI_CONFIG_BASE, (32<<20));
+	if (!pci_config_base) {
+		printk("Unable to map PCI config space!\n");
+		return 1;
+	}
 
-	for (n = 0; n < NLM_NR_NODES; n++) {
-		nodep = nlm_get_node(n);
-		if (!nodep->coremask)
-			continue;	/* node does not exist */
-
-		for (link = 0; link < 4; link++) {
-			pciebase = nlm_get_pcie_base(n, link);
-			if (nlm_read_pci_reg(pciebase, 0) == 0xffffffff)
-				continue;
-			xlp_config_pci_bswap(n, link);
-
-			/* put in intpin and irq - u-boot does not */
-			reg = nlm_read_pci_reg(pciebase, 0xf);
-			reg &= ~0x1fu;
-			reg |= (1 << 8) | nlm_pci_link_to_irq(link);
-			nlm_write_pci_reg(pciebase, 0xf, reg);
-			pr_info("XLP PCIe: Link %d-%d initialized.\n", n, link);
-		}
+	phys = xlp_io_resource.start;
+	size = xlp_io_resource.end - xlp_io_resource.start + 1;
+
+	pci_io_base = ioremap(phys, size);
+	if (!pci_io_base) {
+		printk("[%s]: Unable to IO-Remap phys=%lx, size=%lx\n",
+		       __FUNCTION__, phys, size);
+	}
+	else {
+		printk("[%s]: IO-Remapped phys=%lx, size=%lx to vaddr=%p\n",
+		       __FUNCTION__, phys, size, pci_io_base);
 	}
 
-	set_io_port_base(CKSEG1);
-	nlm_pci_controller.io_map_base = CKSEG1;
+	/* IO Range for 16MB from where the MEM Range Ends */
+	ioport_resource.start =  0;
+	ioport_resource.end   = ~0;
 
-	register_pci_controller(&nlm_pci_controller);
-	pr_info("XLP PCIe Controller %pR%pR.\n", &nlm_pci_io_resource,
-		&nlm_pci_mem_resource);
+	printk("Registering XLP PCIE Controller. \n");
+	pcie_controller_init_done();
+	register_pci_controller(&xlp_controller);
 
+	pci_bus_status = 1;
 	return 0;
 }
+
 arch_initcall(pcibios_init);
+
+struct pci_fixup pcibios_fixups[] = {
+	{0}
+};
+
diff --git a/crypto/Makefile b/crypto/Makefile
index 768401b..1d3555a 100644
--- a/crypto/Makefile
+++ b/crypto/Makefile
@@ -90,7 +90,7 @@ obj-$(CONFIG_CRYPTO_RNG2) += rng.o
 obj-$(CONFIG_CRYPTO_RNG2) += krng.o
 obj-$(CONFIG_CRYPTO_ANSI_CPRNG) += ansi_cprng.o
 obj-$(CONFIG_CRYPTO_TEST) += tcrypt.o
-obj-$(CONFIG_PHOENIX_IPSEC_SEC_OFFLOAD) += phoenix_sec.o
+obj-$(CONFIG_NLMCOMMON_IPSEC_SEC_OFFLOAD) += nlm_common_sec.o
 obj-$(CONFIG_CRYPTO_GHASH) += ghash-generic.o
 obj-$(CONFIG_CRYPTO_USER_API) += af_alg.o
 obj-$(CONFIG_CRYPTO_USER_API_HASH) += algif_hash.o
diff --git a/drivers/char/Kconfig b/drivers/char/Kconfig
index 048855d..8420999 100644
--- a/drivers/char/Kconfig
+++ b/drivers/char/Kconfig
@@ -248,9 +248,9 @@ config NWFLASH
 
 source "drivers/char/hw_random/Kconfig"
 
-config PHOENIX_RMIOS_DEBUGGER
+config NETLOGIC_RMIOS_DEBUGGER
 	bool "RMIOS Debugger support"
-	depends on RMI_PHOENIX!=n
+	depends on NLM_PHOENIX!=n
 	default n
 	---help---
 	This module provides debugging facility for rmios images loaded on the
@@ -621,7 +621,7 @@ endmenu
 
 config RMICDE
 	tristate "RMI Compression/Decompression Engine"
-	depends on RMI_PHOENIX!=n
+	depends on NLM_PHOENIX!=n
 	default n
 	help
 	  The CDE allows deflate/inflate through hardware
diff --git a/drivers/char/Makefile b/drivers/char/Makefile
index 7ff1d0d..4605d90 100644
--- a/drivers/char/Makefile
+++ b/drivers/char/Makefile
@@ -2,6 +2,8 @@
 # Makefile for the kernel character device drivers.
 #
 
+EXTRA_CFLAGS := $(CFLAGS) -DNLM_HAL_LINUX_KERNEL 
+
 obj-y				+= mem.o random.o
 obj-$(CONFIG_TTY_PRINTK)	+= ttyprintk.o
 obj-y				+= misc.o
diff --git a/drivers/net/Kconfig b/drivers/net/Kconfig
index 89b26ea..04a0ea7 100644
--- a/drivers/net/Kconfig
+++ b/drivers/net/Kconfig
@@ -168,7 +168,7 @@ config NETCONSOLE
 	If you want to log kernel messages over the network, enable this.
 	See <file:Documentation/networking/netconsole.txt> for details.
 
-config RMI_VNET
+config NLM_VNET
 	bool "Virtual Networking for CRF"
 	---help---
 	This enables internal network for CRF domains using shared memory and
@@ -362,4 +362,13 @@ config VMXNET3
 
 source "drivers/net/hyperv/Kconfig"
 
+config XLP_NAE 
+	tristate "netlogic microsystems xlp nae mac driver"
+#	depends on m
+	---help---
+	  This driver supports netlogic xls/xlr/xlp soc network driver. 
+	  For more information on xls/xlr/xlp mac driver, please visit
+
+	  <http://support.netlogicmicro.com/support>
+
 endif # NETDEVICES
diff --git a/drivers/net/xlp_nae/Makefile b/drivers/net/xlp_nae/Makefile
new file mode 100644
index 0000000..8e25417
--- /dev/null
+++ b/drivers/net/xlp_nae/Makefile
@@ -0,0 +1,15 @@
+################################################################################
+
+#
+# Makefile for xlp_nae network driver
+#
+#EXTRA_CFLAGS := -Werror
+
+EXTRA_CFLAGS := -DNLM_HAL_LINUX_KERNEL -Iarch/mips/include/asm/netlogic/hal
+obj-m += nlm_xlp_nae.o
+#obj-$(CONFIG_XLP_NAE) += nlm_xlp_nae.o
+nlm_xlp_nae-objs := xlp_nae.o init_nae.o init_fmn.o ucore_loader.o xlp_hw.o 
+
+shared_sources:
+#       $(Q)echo "************ copying nlm_hal.c file ***************"
+#        $(Q)cp $(srctree)/arch/mips/include/asm/rmi/hal/nlm_hal.c .
diff --git a/drivers/net/xlp_nae/init_nae.c b/drivers/net/xlp_nae/init_nae.c
new file mode 100644
index 0000000..30eff0a
--- /dev/null
+++ b/drivers/net/xlp_nae/init_nae.c
@@ -0,0 +1,222 @@
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <asm/netlogic/hal/nlm_hal_nae.h>
+#include "reg.h"    
+#include "net_common.h"
+#include "common.h" 
+
+#define XLP_NAE_UCODE_IO_OFFSET		0x90000000d0010000ULL
+#define CODESIZE_PER_UCORE (4<<10)
+
+
+   /*
+    *  Incantation from Verification code(Anand's)
+    *  
+    *  (black magic follows ) 
+    */
+
+        /*
+         * reset netior softreset
+         * GMAC reset
+         * RX interface Credit 
+         */  
+#define read_gmac_reg(idx, reg) nlm_hal_read_mac_reg( ((idx&0xff)>>2), (idx& 0x3), reg)
+#define write_gmac_reg(idx, reg, val) nlm_hal_write_mac_reg( ((idx&0xff)>>2), (idx& 0x3), reg, val)
+int init_gmac(unsigned int  inf)
+{
+    unsigned int mac_cfg1 = 0 ;
+    unsigned int  mac_cfg2 = 0 ;
+    unsigned int netwk_inf  = 0; 
+//    log_dbg("init inf %d block %d\n", inf& 0x3, (inf&0xff)>>2);
+
+    mac_cfg1 = read_gmac_reg( inf  , INF_MAC_CONFIG1); 
+    mac_cfg2 = read_gmac_reg( inf, INF_MAC_CONFIG2);
+   netwk_inf  = read_gmac_reg( inf, INF_NETWK_INF_CTRL_REG);
+
+	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_SOFTRESET, 0);
+
+    //write_gmac_reg( XLP_NAE_NAE_IO_OFFSET(  );  
+    //Sofreset set bit 11 to 0 
+   
+    write_gmac_reg( inf , INF_NETWK_INF_CTRL_REG,  netwk_inf & 0xfffff7ff);
+
+
+    // TODO rewrite NAE registers 
+    // Donnt ask me some undocumented hack in Validation script
+
+    //RX interface  NETIOR interface credit counter
+	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_MISC_REG2_ADDR , 0x0421084 );
+	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_MISC_REG1_ADDR , 0x00fffff );
+	nlm_hal_write_nae_iface_reg( 0xf, NETIOR_MISC_REG1_ADDR , 0x0);
+
+    // set softreset
+    write_gmac_reg( inf , INF_MAC_CONFIG1, INF_SOFTRESET(1)|
+	                                       /*  INF_LOOP_BACK(1)|*/
+                                                 INF_RX_ENABLE(1)|
+                                                 INF_TX_ENABLE(1) );
+
+    mac_cfg1 = read_gmac_reg( inf, INF_MAC_CONFIG1);
+    write_gmac_reg( inf , INF_MAC_CONFIG2, mac_cfg2|
+                                                 INF_PREMBL_LEN(0x7)|
+                                                 INF_IFMODE(0x2)|
+                                                 INF_FULLDUP(1)
+                                    );
+
+    // reset softreset
+//    log_dbg("tst1 mac_cfg %x\n", mac_cfg1); 
+    write_gmac_reg( inf , INF_MAC_CONFIG1, mac_cfg1 & ~(INF_SOFTRESET(1)));
+
+    netwk_inf  = read_gmac_reg( inf, INF_NETWK_INF_CTRL_REG);
+
+    write_gmac_reg( inf , INF_NETWK_INF_CTRL_REG,  netwk_inf|
+                                                         STATS_EN(1)|
+                                                         TX_EN(1)|
+                                                        SPEED(0));
+
+/*
+    log_dbg("%d :inf %d MAC_CONFIG1: %x  val %x\n" , __LINE__, inf, 
+                                                       read_gmac_reg( 0 , INF_MAC_CONFIG1),                                        
+                                                     ( INF_SOFTRESET(1)|
+                                                       INF_LOOP_BACK(1)|
+                                                       INF_RX_ENABLE(1)|
+                                                       INF_TX_ENABLE(1) )); 
+
+*/
+	return 0;
+}
+/*
+*   (black magic ends)
+*/
+
+
+// make sure the pktmem is cache aligned (64 byte)
+// & the num_byts is multiple of 64
+// 
+ /* Free Queue Config
+     *  
+     *  20 queues (1000  - 1019 ) form the ingress free pool 
+     *  Size of the descriptor can be configured the following ways
+     *    a.Each Fifo has a unique size 
+     *    b. ALL Fifo desc will have the same size
+     *  RX_CONFIG has sets the necessary bits to set the size
+     *
+      Default size is Desc 256 Byte (NEED TO VERIFY)
+     *
+     * */
+
+
+  /* EGRESS -> IOR credit configuration 
+   *     
+   *
+   *
+   * */ 
+
+int init_tx_if_credit( uint32_t credit_val, uint32_t if_bmask)
+{
+int tx_config = 0;
+    
+    nlm_hal_write_nae_reg( TX_IORCRDT_INIT, credit_val);
+    tx_config = nlm_hal_read_nae_reg(TX_CONFIG);
+    //nlm_hal_write_nae_reg(TX_CONFIG, txconfig|1);
+    // need to toggle these bits for credits to be loaded
+    nlm_hal_write_nae_reg(TX_CONFIG, tx_config | ( TXINITIORCR(0x7ffff & if_bmask)));
+    nlm_hal_write_nae_reg(TX_CONFIG, tx_config & ~( TXINITIORCR(0x7ffff & if_bmask)));
+
+    return 0;
+}
+
+
+
+ /*
+  * uCore code 
+  * configure Interface to ucore
+  * Load ucode
+  * Reset Ucore
+  *
+  * */
+
+#if 1  //disable init_ucore for now
+#define     VAL_UCORE_RESET(x)              ((x&0xffff)<<8) 
+int init_ucore(uint32_t ucore_mask, int if_num)
+{
+    	uint32_t ucore_cfg = 0;
+	nlm_hal_write_nae_reg(UCORE_IFACE_MASK_CFG, 
+                          ucore_spray_config(if_num, ucore_mask, CMD_WRITE));
+/*	ucore_load_apps(ucore_mask);*/
+    	ucore_cfg = nlm_hal_read_nae_reg(RX_UCORE_CFG);
+    	nlm_hal_write_nae_reg(RX_UCORE_CFG, ucore_cfg & (~VAL_UCORE_RESET(ucore_mask)));
+
+    return 0;
+}
+#endif
+
+    /* Egress Config 
+     *      Configure Qvc to interface mapping
+     *       524 queue (476 - 999)
+     *       VFBID to Destination Station ID 
+     *       Credit Configuration between stages
+     *       Credit Configuration between interface N Egress bock 
+     *       Context(NAE parlance ,means Queue in FMN)Memory 
+     *          Setup to carve the Entry to Queue .
+     *       (Note Stage 1 configuration is obsolete .)
+     *       Trasmit Drr (reg 0x44 to 0x4d are  scheduler configuration)
+     *
+     *       Defaults:
+     *              Queue: 0 to 17 queue map to corresponding interface
+     *              VFBID: Dest Station ID = VFBID
+     *              Context memory setup : NOT CLEAR NO NUMBERS available 
+     *              Scheduler : round robin
+     * */
+                                    
+    /* 
+     *                      40 - 23b|15 - 13| 12 - 9|
+     *                      bar addr|block |interface
+     * */
+
+
+init_ingress(void)
+{
+    unsigned int rx_cfg = 0;
+
+    rx_cfg = nlm_hal_read_nae_reg(RX_CONFIG); 
+
+    //log_dbg("nae rxcfg %x txcfg %x\n", rx_cfg, tx_cfg); 
+    #define NAE_MAX_MESSAGE_SIZE(x)                 ((x&0x1)<<1)
+    #define RESET_MAX_MESSAGE_SIZE                   ~(0x1<<1) 
+    #define NAE_FRINDESCCLSIZE(x)                   ((x&0xff)<< 4 )
+    #define RESET_FRINDESCCLSIZE                   ~((0xff)<< 4) 
+    #define NAE_RX_STATUS_MASK(x)                   ((x&0x3f) << 24)
+    #define RESET_RX_STATUS_MASK                   ~((0x3f) << 24)
+    
+	nlm_hal_write_nae_reg( RX_CONFIG,(rx_cfg & 
+                                      RESET_MAX_MESSAGE_SIZE &
+                                      RESET_FRINDESCCLSIZE & 
+                                      RESET_RX_STATUS_MASK
+                                     ) |
+                                     NAE_RX_ENABLE|
+                                     NAE_MAX_MESSAGE_SIZE(0x3)|
+                                     NAE_RX_STATUS_MASK(0x3f)|
+                                     NAE_FRINDESCCLSIZE(4)
+                                    );
+
+}
+ /* Ingress Config 
+  *      20 queue (1000 - 1019)
+  *      RxConfig : set the Free in desc default 
+  *      Interface to context mapping
+  *      set valid active interface
+  *      calendar slots
+  *      parser configuration
+  *      Parser se
+  *
+  *
+  * */
+
+
+init_egress(void)
+{
+    uint32_t tx_cfg =  nlm_hal_read_nae_reg(TX_CONFIG);
+
+	nlm_hal_write_nae_reg( TX_CONFIG, tx_cfg|NAE_TX_ENABLE);
+
+}
diff --git a/drivers/net/xlp_nae/net_common.h b/drivers/net/xlp_nae/net_common.h
new file mode 100644
index 0000000..db7ce53
--- /dev/null
+++ b/drivers/net/xlp_nae/net_common.h
@@ -0,0 +1,170 @@
+#ifndef NET_COMMON_H
+#define NET_COMMON_H
+
+#define MAX_FMN_CODE            -1
+#define FMN_CREDIT_DEFAULT      8
+#define FMN_POE_CREDIT_DEFAULT      9
+#define MAX_FMN_ARRAY               50
+#define SUCCESS                 0
+#define FAIL                    -1
+#define CPU0_VC                 0
+
+#define CPU_Q_ID(cpu, tid, vid) (cpu<<4|tid<<2|vid)
+#define QID_2_CPU(qid)          ((qid & 0x7F)>> 4)
+#define QID_2_TID(qid)          ((qid & 0xc)>>2 )
+#define QID_2_QID(qid)          (qid & 0x3) 
+#define MAX_DEST_QID            50
+typedef struct fmn_credit_struct {
+   unsigned int   s_qid;
+   unsigned int   d_qid;
+   unsigned int   flag;
+   #define SET_UP_QUEUE         0x1
+   #define SET_UP_CREDITS       0x2
+   #define SET_UP_MULTI_DEST    0x4
+   #define SET_UP_MULTI_SRC     0x8
+   unsigned int   q_len;
+#define FMN_QLEN_USE_DEFAULT      0 
+   unsigned int   credit;
+} fmn_credit_type;
+extern int init_gmac(unsigned int inf);
+extern int init_tx_if_credit( /*uint32_t*/__u32 credit_val, unsigned int if_bmask);
+extern int init_ucore(uint32_t ucore_mask, int if_num);
+extern int init_ingress(void);
+extern int init_egress(void);
+extern int fmn_init(const fmn_credit_type *credit);
+extern void *xlp_init_buffer( size_t size, 
+                   size_t pbase ,
+                   uint64_t *vaddr_base
+                           );
+
+extern void *init_nae_free_pool(int num_queue, 
+                              unsigned char *pktmem , 
+                              int num_bytes, 
+                              int num_desc);
+extern void print_netreg(void);
+#define DBG        1
+#ifdef DBG
+    #define log_dbg     printk 
+    #define log_pkt     printk
+#else
+    #define log_dbg(...)
+    #define log_pkt(...)
+//    #define log_err(...) 
+#endif
+#define log_err     
+#define log_info   printk 
+
+#ifdef DBG
+static __inline__ void press_key_to_continue(void) {
+	log_dbg("press <enter> to continue...\n");
+/*	getchar();*/
+}
+#else 
+#define press_key_to_continue()
+#endif
+
+#define CPU_Q_ID(cpu, tid, vid) (cpu<<4|tid<<2|vid)
+//TO BE changed
+#define XKPHYS_UNCACHED 0x9000000000000000ULL
+#define XLP_NAE_IO_OFFSET        (XKPHYS_UNCACHED | 0xd000e000)
+
+
+#define OUTQ_ENABLE 0x8000000000000000ULL
+
+enum NAE_REG_CMD {
+	CMD_READ = 0,
+	CMD_WRITE
+};
+
+#define NAE_RX_ENABLE 0x1
+#define NAE_TX_ENABLE 0x1
+
+#define CPU_Q_ID(cpu, tid, vid) (cpu<<4|tid<<2|vid)
+struct xlp_msg {
+	uint64_t entry[4];
+};
+
+static __inline__ void msg_print(uint32_t size, uint32_t code, uint32_t dest, struct xlp_msg *msg) {
+	int i;
+	log_dbg("  size = %u\n"
+	       "  code = %u (0x%x)\n"
+	       "  dest = %u (0x%x)\n",
+	       size, code, code, dest, dest);
+	for (i = 0; i < size && size <= 4; ++i) {
+		log_dbg("  msg.entry%d = 0x%016llx\n",
+		       i, msg->entry[i]);
+	}
+}
+
+static __inline__ void poe_print(uint64_t msg0) {
+	log_dbg("POE nextfid  = %llu (0x%llx)\n"
+	       "    nextdist = %llu (0x%llx)\n"
+	       "    nextdest = %llu (0x%llx)\n"
+	       "    msgaddr  = 0x%llx\n"
+	       "    fid      = %llu (0x%llx)\n",
+	       (msg0 >> 48) & 0xffff, (msg0 >> 48) & 0xffff,
+	       (msg0 >> 44) & 0xf, (msg0 >> 44) & 0xf,
+	       (msg0 >> 32) & 0xfff, (msg0 >> 32) & 0xfff,
+	       (msg0 >> 16) & 0xffff,
+	       (msg0) & 0xffff, (msg0) & 0xffff);
+}
+
+static __inline__ void rx_print(uint64_t msg0) {
+	log_dbg("RX  context = %llu\n"
+	       "    length  = %llu (0x%llx)\n"
+	       "    address = 0x%010llx\n"
+	       "    unclass = %llu\n"
+	       "    err     = %llu\n"
+	       "    IPcksm  = %llu\n"
+	       "    TCPcksm = %llu\n"
+	       "    prepad  = %llu\n"
+	       "    p2p     = %llu\n",
+	       (msg0 >> 54) & 0x3ff,
+	       (msg0 >> 40) & 0x3fff, (msg0 >> 40) & 0x3fff,
+	       (msg0) & 0xffffffffc0ULL,
+	       (msg0 >> 5) & 0x1,
+	       (msg0 >> 4) & 0x1,
+	       (msg0 >> 3) & 0x1,
+	       (msg0 >> 2) & 0x1,
+	       (msg0 >> 1) & 0x1,
+	       (msg0) & 0x1);
+}
+
+static __inline__ void buf_print(unsigned char *buf, unsigned long len) {
+	unsigned long i;
+	for (i = 0; i < len; ++i) {
+		log_dbg(" %02x", buf[i]);
+		if (i % 8 == 7) log_dbg(" ");
+		if (i % 32 == 31) log_dbg("\n"); 
+	}
+	log_dbg("\n");
+}
+
+#define CRC_LEN 4
+#define BYTE_OFFSET 2
+
+#define NULL_VFBID 127
+
+static __inline__ uint64_t nae_tx_desc(unsigned int type,
+	unsigned int rdex, unsigned int fbid, unsigned int len, uint64_t addr) {
+	return ((uint64_t)(type & 0x3) << 62) |
+	       ((uint64_t)(rdex & 0x1) << 61) |
+	       ((uint64_t)(fbid & 0x7f) << 54) |
+	       ((uint64_t)(len & 0x3fff) << 40) |
+	       (addr&0xffffffffffULL);
+}
+
+static __inline__ void tx_print(uint64_t msg0) {
+	log_dbg("TX  type    = %llu\n"
+	       "    rdex    = %llu\n"
+	       "    vfbid   = %llu\n"
+	       "    length  = %llu (0x%llx)\n"
+	       "    address = 0x%010llx\n",
+	       ((msg0 >> 62) & 0x3),
+	       ((msg0 >> 61) & 0x1),
+	       ((msg0 >> 54) & 0x7f),
+	       ((msg0 >> 40) & 0x3fff), ((msg0 >> 40) & 0x3fff),
+	       (msg0) & 0xffffffffffULL);
+}
+
+#endif
diff --git a/drivers/net/xlp_nae/reg.h b/drivers/net/xlp_nae/reg.h
new file mode 100644
index 0000000..293c626
--- /dev/null
+++ b/drivers/net/xlp_nae/reg.h
@@ -0,0 +1,40 @@
+#ifndef REG_H
+#define REG_H
+
+// Reg info
+#define INF_MAC_CONFIG1                     0
+#define INF_MAC_CONFIG2                     1
+#define INF_NETWK_INF_CTRL_REG              0x7f
+
+#define NETIOR_MISC_REG1_ADDR       0x39
+/* BAR address          */
+
+#define NAE_BAR_ADDRESS             0
+#define NETIOR_SOFTRESET            0x3
+    //NETWORK INF CTRL REG(non of the values match PRM)
+#define SOFTRESET(x)                        (x<<11)
+#define STATS_EN(x)                         (x<<16)
+#define TX_EN(x)                            (x<<2)
+#define SPEED(x)                            (x&0x3)
+    //MAC_CONFIG1
+#define INF_SOFTRESET(x)                    (x<< 31)
+#define INF_LOOP_BACK(x)                    (x<< 8)
+#define INF_RX_ENABLE(x)                    (x<< 2)
+#define INF_TX_ENABLE(x)                    (0x1)
+    //MAC_CONFIG2
+
+#define INF_PREMBL_LEN(x)                   ((x & 0xf)<<12)
+#define INF_IFMODE(x)                       ((x & 0x3) << 8)
+#define INF_LENCHK(x)                       (((x & 0x1)) << 4)
+#define INF_PADCRCEN(x)                     ((x&0x1)<<2)
+#define INF_PADCRC(x)                       ((x&0x1)<<1)
+#define INF_FULLDUP(x)                      (x&0x1)
+#define NETIOR_MISC_REG2_ADDR               (0x3a)
+#define NAE_REG_ADDRS(r)              (NAE_BAR_ADDRESS&(0xffffff00000)|0x7<<13| ((r &0x3ff)<<2))
+#define NAE_REG_TX_CONFIG              0x11
+#define NAE_REG_TXIORCRDT_INIT         0x59
+#define TXINITIORCR(x)                 (x & 0x7ffff) << 8 
+
+
+
+#endif
diff --git a/drivers/net/xlp_nae/ucore_apps.c b/drivers/net/xlp_nae/ucore_apps.c
new file mode 100644
index 0000000..aad326d
--- /dev/null
+++ b/drivers/net/xlp_nae/ucore_apps.c
@@ -0,0 +1,77 @@
+#include "ucore_loader.h"
+
+uint32_t sample_array[] = {
+	0x0,
+	0x32,
+	0x3c1c0010,
+	0x279cf808,
+	0x3c020010,
+	0x2442f808,
+	0x3c030010,
+	0x2463f808,
+	0xac400000,
+	0x43082b,
+	0x1420fffd,
+	0x24420004,
+	0x3c1d0010,
+	0x27bdf9c0,
+	0x27a50020,
+	0x27a60028,
+	0xaca00000,
+	0xacc00000,
+	0xc000029,
+	0x2021,
+	0x1000ffff,
+	0x0,
+	0x3c020000,
+	0x8c4200fc,
+	0x27bdffe0,
+	0x2403ffff,
+	0xafbf001c,
+	0xafb10018,
+	0x10430009,
+	0xafb00014,
+	0x3c100000,
+	0x261000fc,
+	0x2411ffff,
+	0x40f809,
+	0x2610fffc,
+	0x8e020000,
+	0x1451fffc,
+	0x0,
+	0x8fbf001c,
+	0x8fb10018,
+	0x8fb00014,
+	0x3e00008,
+	0x27bd0020,
+	0x24030001,
+	0x1021,
+	0x34088004,
+	0x8d040000,
+	0x34088030,
+	0xad030000,
+	0x34088000,
+	0x800002b,
+	0xad020000,
+	0x0,
+	0x0,
+};
+#define sample_array_size 54
+ucore_array_info_t ucore_array_info[] = {
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size },
+	{ sample_array, sample_array_size }
+};
diff --git a/drivers/net/xlp_nae/ucore_loader.c b/drivers/net/xlp_nae/ucore_loader.c
new file mode 100644
index 0000000..3694b69
--- /dev/null
+++ b/drivers/net/xlp_nae/ucore_loader.c
@@ -0,0 +1,79 @@
+#include <linux/types.h>
+#include <linux/mm.h>
+#include <asm/netlogic/hal/nlm_hal_nae.h>
+#include "ucore_loader.h"
+#include "ucore_apps.c"
+
+ucore_array_info_t ucore_array_info[MAX_UCORE]; 
+#if 0
+void WRITE_NAE_UCODE(int ucore, uint32_t offset, uint32_t code) {
+	xlp_write_nae_ucode(ucore, offset, code);
+}
+#endif
+static __inline__ void ucore_load_app(int ucore, uint32_t **array, uint32_t array_size) {
+	int k = 0, j;
+	uint32_t offset, size, code;
+	uint32_t *p = *array;
+//printk("array: %x, point2array %x\n",array,p);
+	if ((ucore < 0) || (ucore >= MAX_UCORE) ||
+	    (p == NULL) || (array_size == 0)) {
+		return;
+	}
+
+	while (k < array_size) {
+		offset = p[k];
+		size   = p[k + 1];
+//	printk("k: %d offset %d size %d\n",k, offset, size);
+	
+	if(size >= array_size||size==0){
+		
+//		printk("array_size wrong\n");
+		return;
+	}
+		for (j = 0; j < size; ++j) {
+			code = p[k + 2 + j];
+			nlm_hal_write_ucode(ucore, offset, code);
+//			WRITE_NAE_UCODE(ucore, offset, code);
+//			 printk("writeUcode idx: %d ucore:%d offset:%d code: %x\n", (k+2+j),ucore,offset, code);
+			offset += 4;
+		}
+		k += (2 + size);
+	}
+}
+
+int ucore_load_apps(uint32_t mask)
+{
+	int i=0,j=0,k=0,t, count = 0;
+	uint32_t *array, asize, offset, size, code;
+	printk("ucore_load_apps\n");
+	asize  = ucore_array_info[i].array_size;
+	array = kmalloc(sizeof(uint32_t)*asize, GFP_KERNEL);
+	if(!array)
+	{
+		printk("kmalloc failed\n");
+		return 0;
+	}
+	for (i = 0; i < MAX_UCORE; ++i) {
+		if (!(mask & (1 << i))) {
+			continue;
+		}
+//		array = ucore_array_info[i].array;
+		asize  = ucore_array_info[i].array_size;
+
+		for(t = 0; t < asize; t++)
+		{
+			array[t] = ucore_array_info[i].array[t];
+//			printk("%x ",array[t]);
+		}
+
+		if ((array == NULL) || (asize == 0)) {
+			continue;
+		}
+//	printk("\n\nucore_load_app( %d, %x, %x, %d)\n", i, &array,array, asize);
+		ucore_load_app(i, &array, asize);
+		count++;
+	}
+	kfree(array);
+	return count;
+}
+
diff --git a/drivers/net/xlp_nae/ucore_loader.h b/drivers/net/xlp_nae/ucore_loader.h
new file mode 100644
index 0000000..aac8ee4
--- /dev/null
+++ b/drivers/net/xlp_nae/ucore_loader.h
@@ -0,0 +1,18 @@
+#ifndef __UCORE_LOADER_H__
+#define __UCORE_LOADER_H__
+
+#define MAX_UCORE 16
+
+typedef struct {
+	uint32_t *array;
+	uint32_t array_size;
+} ucore_array_info_t;
+
+
+/* This OS dependent function must be provided by the application. */
+//extern void WRITE_NAE_UCODE(int ucore, uint32_t offset, uint32_t code);
+
+/* This is the only function that should be called by the application. */ 
+extern int ucore_load_apps(uint32_t mask);
+
+#endif /* __UCORE_LOADER_H__ */
diff --git a/drivers/net/xlp_nae/xlp_hw.c b/drivers/net/xlp_nae/xlp_hw.c
new file mode 100644
index 0000000..bf45334
--- /dev/null
+++ b/drivers/net/xlp_nae/xlp_hw.c
@@ -0,0 +1,496 @@
+/*********************************************************************
+
+  Copyright 2003-2010 Netlogic Microsystem, Inc. (NLM). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#NLM_2#**********************************/
+
+#include <linux/types.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/mii.h>
+
+#include <asm/netlogic/xlr_mac.h>
+#include <asm/netlogic/hal/nlm_hal_nae.h>
+#include "xlp_nae.h"
+
+
+#define NLM_NUM_REG_DUMP 9 /* Register 0xa0 to 0xa8 */
+#define NLM_ETHTOOL_REG_LEN (NLM_NUM_REG_DUMP * 4)
+#define PHY_STATUS_RETRIES 25000
+
+#define DRV_NAME	"xlp_nae"
+#define DRV_VERSION     "0.1"
+
+static void nlm_xlp_mac_mii_write(struct dev_data *priv, int phyaddr, int regidx, unsigned int regval);
+static unsigned int nlm_xlp_mac_mii_read(struct dev_data *priv, int phyaddr, int regidx);
+void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag);
+static int xlp_enable_autoneg(struct net_device *dev, u32 adv);
+static int xlp_set_link_speed(struct net_device *dev, int speed, int duplex);
+
+static int xlp_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	int mii_status;
+
+	if ((priv->type == TYPE_XGMAC) || (priv->phy.mode == PHY_MODE_XAUI)){
+		cmd->supported = SUPPORTED_FIBRE|SUPPORTED_10000baseT_Full;
+		cmd->advertising = SUPPORTED_FIBRE|SUPPORTED_10000baseT_Full;
+		cmd->speed = SPEED_10000;
+		cmd->port = PORT_FIBRE;
+		cmd->duplex = DUPLEX_FULL;
+		cmd->phy_address = priv->port;
+		cmd->autoneg = AUTONEG_DISABLE;
+		cmd->maxtxpkt = 0;
+		cmd->maxrxpkt = 0;
+
+	}else{
+
+		cmd->supported = SUPPORTED_10baseT_Full | 
+			SUPPORTED_10baseT_Half | 
+			SUPPORTED_100baseT_Full | SUPPORTED_100baseT_Half |
+			SUPPORTED_1000baseT_Full | SUPPORTED_MII |
+			SUPPORTED_Autoneg | SUPPORTED_TP;
+
+		cmd->advertising = priv->advertising;
+
+		mii_status = nlm_xlp_mac_mii_read(priv, priv->phy.addr, MII_NCONFIG);
+		priv->speed = (mii_status >> 3) & 0x03;
+
+		cmd->speed = (priv->speed == xlp_mac_speed_1000) ? SPEED_1000 :
+		(priv->speed == xlp_mac_speed_100) ? SPEED_100: SPEED_10;
+
+		cmd->duplex = (mii_status >> 5) & 0x1;
+		cmd->port = PORT_TP;
+		cmd->phy_address = priv->port;
+		cmd->transceiver = XCVR_INTERNAL;
+		cmd->autoneg = (~(mii_status >> 14)) & 0x1;
+		cmd->maxtxpkt = 0;
+		cmd->maxrxpkt = 0;
+	}
+
+	return 0;
+}
+static int xlp_enable_autoneg(struct net_device *dev, u32 adv)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	int mii_status;
+	u32 adv1, adv2;
+    unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	nlm_xlp_mac_set_enable(priv, 0);
+	/* advertising for 10/100 Mbps */
+	adv1 = nlm_xlp_mac_mii_read(priv, priv->phy.addr, MII_ADVERTISE);
+	adv1 &= ~(ADVERTISE_ALL | ADVERTISE_100BASE4);
+	/* advertising for 1000 Mbps */
+	adv2 = nlm_xlp_mac_mii_read(priv, priv->phy.addr, 0x9);
+	adv2 &= ~(0x300);
+
+	if(adv & ADVERTISED_10baseT_Half)
+		adv1 |= ADVERTISE_10HALF;
+	if(adv & ADVERTISED_10baseT_Full)
+		adv1 |= ADVERTISE_10FULL;
+	if(adv & ADVERTISED_100baseT_Full)
+		adv1 |= ADVERTISE_100FULL;
+	if(adv & ADVERTISED_100baseT_Half)
+		adv1 |= ADVERTISE_100HALF;
+
+	if(adv & ADVERTISED_1000baseT_Full)
+		adv2 |= 0x200;
+	if(adv & ADVERTISED_1000baseT_Half)
+		adv2 |= 0x100;
+
+	/* Set the advertising parameters */
+	nlm_xlp_mac_mii_write(priv, priv->phy.addr, MII_ADVERTISE, adv1);
+	nlm_xlp_mac_mii_write(priv, priv->phy.addr, 0x9, adv2);
+
+	priv->advertising = adv1 | adv2;
+
+	mii_status = nlm_xlp_mac_mii_read(priv, priv->phy.addr, MII_BMCR);
+	/* enable autoneg and force restart autoneg */
+	mii_status |= (BMCR_ANENABLE | BMCR_ANRESTART);
+	nlm_xlp_mac_mii_write(priv, priv->phy.addr, MII_BMCR, mii_status);
+
+	nlm_xlp_mac_set_enable(priv, 1);
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+
+static int xlp_set_link_speed(struct net_device *dev, int speed, int duplex)
+{
+	u32 adv;
+	int ret =0;
+
+	switch(speed) {
+		case SPEED_10:
+			if ( duplex == DUPLEX_FULL )
+				adv = ADVERTISED_10baseT_Full;
+			else
+				adv = ADVERTISED_10baseT_Half;
+			break;
+		case SPEED_100:
+			if ( duplex == DUPLEX_FULL )
+				adv = ADVERTISED_100baseT_Full;
+			else
+				adv = ADVERTISED_100baseT_Half;
+			break;
+		case SPEED_1000:
+			if ( duplex == DUPLEX_FULL )
+				adv = ADVERTISED_1000baseT_Full;
+			else
+				adv = ADVERTISED_1000baseT_Half;
+			break;
+		default:
+			ret = -EINVAL;
+			return ret;
+	}
+	ret = xlp_enable_autoneg( dev,adv);
+	return ret;
+
+}
+
+static int xlp_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	int ret;
+	struct dev_data *priv = netdev_priv(dev);
+
+	if ((priv->type == TYPE_XGMAC) || (priv->phy.mode == PHY_MODE_XAUI)){
+		return -EIO;
+	}
+	if (cmd->autoneg == AUTONEG_ENABLE) {
+		ret = xlp_enable_autoneg(dev, cmd->advertising);
+	}else {
+		ret = xlp_set_link_speed(dev, cmd->speed, cmd->duplex);
+	}
+	return ret;
+}
+
+static void xlp_get_drvinfo(struct net_device *dev, 
+				struct ethtool_drvinfo *info)
+{
+	strcpy(info->driver, DRV_NAME);
+	strcpy(info->version, DRV_VERSION);
+}
+
+static int xlp_get_regs_len(struct net_device *dev) 
+{
+	return NLM_ETHTOOL_REG_LEN;
+}
+static void xlp_get_regs(struct net_device *dev,
+				struct ethtool_regs *regs, void *p)
+{
+	u32 *data = (u32 *)p;
+	int i;
+	struct dev_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	memset((void *)data, 0, NLM_ETHTOOL_REG_LEN);
+
+	spin_lock_irqsave(&priv->lock, flags);
+	for(i=0; i <= NLM_NUM_REG_DUMP; i++)
+		*(data + i) = nlm_hal_read_mac_reg(priv->block, priv->index,  R_TX_CONTROL + i);
+	spin_unlock_irqrestore(&priv->lock, flags);
+}
+static u32 xlp_get_msglevel(struct net_device *dev)
+{
+	return 0; //mac_debug;
+}
+static void xlp_set_msglevel(struct net_device *dev, u32 value)
+{
+//	mac_debug = value;
+}
+
+static int xlp_nway_reset(struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	int mii_status;
+	unsigned long flags;
+	int ret = -EINVAL;
+
+   if ((priv->type == TYPE_XGMAC) || (priv->phy.mode == PHY_MODE_XAUI))
+    return -EIO;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	mii_status = nlm_xlp_mac_mii_read(priv, priv->phy.addr, MII_BMCR);
+	if(mii_status & BMCR_ANENABLE)
+	{
+		nlm_xlp_mac_mii_write(priv, priv->phy.addr, 
+				MII_BMCR, BMCR_ANRESTART | mii_status);
+		ret = 0;
+	}
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return ret;
+}
+static u32 xlp_get_link(struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	int mii_status;
+	unsigned long flags;
+
+   if ((priv->type == TYPE_XGMAC) || (priv->phy.mode == PHY_MODE_XAUI))
+    return -EIO;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	mii_status = nlm_xlp_mac_mii_read(priv, priv->phy.addr, MII_BMSR);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	if(mii_status & BMSR_LSTATUS)
+		return 1;
+	return 0;
+}
+#define NLM_STATS_KEY_LEN  \
+		(sizeof(struct net_device_stats) / sizeof(unsigned long))
+static struct {
+	        const char string[ETH_GSTRING_LEN];
+} xlp_ethtool_stats_keys[NLM_STATS_KEY_LEN] = {
+	{ "rx_packets" },
+	{ "tx_packets" },
+	{ "rx_bytes" },
+	{ "tx_bytes" },
+	{ "rx_errors" },
+	{ "tx_errors" },
+	{ "rx_dropped" },
+	{ "tx_dropped" },
+	{ "multicast" },
+	{ "collisions" },
+	{ "rx_length_errors" },
+	{ "rx_over_errors" },
+	{ "rx_crc_errors" },
+	{ "rx_frame_errors" },
+	{ "rx_fifo_errors" },
+	{ "rx_missed_errors" },
+	{ "tx_aborted_errors" },
+	{ "tx_carrier_errors" },
+	{ "tx_fifo_errors" },
+	{ "tx_heartbeat_errors" },
+	{ "tx_window_errors" },
+	{ "rx_compressed" },
+	{ "tx_compressed" }
+};
+static int xlp_get_stats_count (struct net_device *dev)
+{
+	return NLM_STATS_KEY_LEN;
+}
+
+static void xlp_get_strings (struct net_device *dev, u32 stringset, u8 *buf)
+{
+	switch (stringset) {
+	case ETH_SS_STATS:
+		memcpy(buf, &xlp_ethtool_stats_keys, 
+				sizeof(xlp_ethtool_stats_keys));
+		break;
+	default:
+		printk(KERN_WARNING "%s: Invalid stringset %d\n", 
+				__FUNCTION__, stringset);
+		break;
+	}
+}
+
+
+/**********************************************************************
+ * xlp_get_mac_stats -  collect stats info from Mac stats register
+ * @dev   -  this is per device based function
+ * @stats -  net device stats structure
+ **********************************************************************/
+void xlp_get_mac_stats(struct net_device *dev, struct net_device_stats *stats)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	
+	stats->tx_errors = nlm_hal_read_mac_reg( priv->block, priv->index, TX_FCS_ERROR_COUNTER);
+	stats->rx_dropped = nlm_hal_read_mac_reg( priv->block, priv->index, RX_DROP_PACKET_COUNTER);
+	stats->tx_dropped = nlm_hal_read_mac_reg( priv->block, priv->index, TX_DROP_FRAME_COUNTER);
+	stats->multicast = nlm_hal_read_mac_reg( priv->block, priv->index, RX_MULTICAST_PACKET_COUNTER);
+	stats->collisions = nlm_hal_read_mac_reg( priv->block, priv->index, TX_TOTAL_COLLISION_COUNTER);
+	stats->rx_length_errors = nlm_hal_read_mac_reg( priv->block, priv->index, RX_FRAME_LENGTH_ERROR_COUNTER);
+	stats->rx_over_errors = nlm_hal_read_mac_reg( priv->block, priv->index, RX_DROP_PACKET_COUNTER);
+	stats->rx_crc_errors = nlm_hal_read_mac_reg( priv->block, priv->index, RX_FCS_ERROR_COUNTER);
+	stats->rx_frame_errors = nlm_hal_read_mac_reg( priv->block, priv->index, RX_ALIGNMENT_ERROR_COUNTER);
+	stats->rx_fifo_errors = nlm_hal_read_mac_reg( priv->block, priv->index,RX_DROP_PACKET_COUNTER);
+	stats->rx_missed_errors = nlm_hal_read_mac_reg( priv->block, priv->index,RX_CARRIER_SENSE_ERROR_COUNTER);
+	stats->rx_errors = (stats->rx_over_errors + stats->rx_crc_errors + stats->rx_frame_errors + stats->rx_fifo_errors +stats->rx_missed_errors);
+	stats->tx_aborted_errors = nlm_hal_read_mac_reg( priv->block, priv->index, TX_EXCESSIVE_COLLISION_PACKET_COUNTER);
+	stats->tx_carrier_errors = nlm_hal_read_mac_reg( priv->block, priv->index, TX_DROP_FRAME_COUNTER);
+	stats->tx_fifo_errors = nlm_hal_read_mac_reg( priv->block, priv->index, TX_DROP_FRAME_COUNTER);
+	return;
+}
+
+/**********************************************************************
+ * xlp_get_ethtool_stats -  part of ethtool_ops member function
+ * @dev   -  this is per device based function
+ * @stats -  net device stats structure
+ **********************************************************************/
+static void xlp_get_ethtool_stats (struct net_device *dev,
+			struct ethtool_stats *estats, u64 *stats)
+{
+	int i;
+	struct dev_data *priv = netdev_priv(dev);
+	unsigned long flags;
+	unsigned long *tmp_stats;
+	
+	spin_lock_irqsave(&priv->lock, flags);
+	
+	xlp_get_mac_stats(dev, &priv->stats);
+	
+	
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	tmp_stats = (unsigned long *)&priv->stats;
+	for(i=0; i < NLM_STATS_KEY_LEN; i++) {
+		*stats = (u64)*tmp_stats;
+		stats++;
+		tmp_stats++;
+	}
+}
+
+/**********************************************************************
+ *  nlm_xlp_mac_mii_read - Read mac mii phy register
+ *  
+ *  Input parameters: 
+ *  	   priv - priv structure
+ *  	   phyaddr - PHY's address
+ *  	   regidx = index of register to read
+ *  	   
+ *  Return value:
+ *  	   value read (16 bits), or 0xffffffff if an error occurred.
+ ********************************************************************* */
+static unsigned int nlm_xlp_mac_mii_read(struct dev_data *priv, int phyaddr, int regidx)
+{
+	int i;
+
+	/* setup the phy reg to be used */
+	nlm_hal_write_mac_reg(priv->block, priv->index, R_MII_MGMT_ADDRESS,(phyaddr << 8) | (regidx << 0));
+
+	/* Issue the read command */
+	nlm_hal_write_mac_reg(priv->block, priv->index, R_MII_MGMT_COMMAND,(1 << O_MII_MGMT_COMMAND__rstat));
+
+	/* poll for the read cycle to complete */
+	for (i = 0; i < PHY_STATUS_RETRIES; i++) {
+		if (nlm_hal_read_mac_reg(priv->block, priv->index, R_MII_MGMT_INDICATORS) == 0)
+			break;
+	}
+
+	/* clear the read cycle */
+	nlm_hal_write_mac_reg(priv->block, priv->index, R_MII_MGMT_COMMAND, 0);
+
+	if (i == PHY_STATUS_RETRIES) {
+		return 0xffffffff;
+	}
+
+	/* Read the data back */
+	return nlm_hal_read_mac_reg(priv->block, priv->index, R_MII_MGMT_STATUS);
+}
+
+/**********************************************************************
+ *  nlm_xlp_mac_mii_write -Write mac mii PHY register.
+ *  
+ *  Input parameters: 
+ *  	   priv - priv structure
+ *  	   phyaddr - PHY to use
+ *  	   regidx - register within the PHY
+ *  	   regval - data to write to register
+ *  	   
+ *  Return value:
+ *  	   nothing
+ ********************************************************************* */
+static void nlm_xlp_mac_mii_write(struct dev_data *priv, int phyaddr, int regidx, unsigned int regval)
+{
+	int i = 0;
+
+	nlm_hal_write_mac_reg(priv->block, priv->index, R_MII_MGMT_ADDRESS,(phyaddr << 8) | (regidx << 0));
+
+	/* Write the data which starts the write cycle */
+	nlm_hal_write_mac_reg(priv->block, priv->index, R_MII_MGMT_WRITE_DATA, regval);
+
+	/* poll for the write cycle to complete */
+	for (i = 0; i < PHY_STATUS_RETRIES; i++) {
+		if (nlm_hal_read_mac_reg(priv->block, priv->index, R_MII_MGMT_INDICATORS) == 0)
+			break;
+	}
+
+	return;
+}
+
+
+static struct ethtool_ops xlp_ethtool_ops= {
+        .get_settings           = xlp_get_settings,
+        .set_settings           = xlp_set_settings,
+        .get_drvinfo            = xlp_get_drvinfo,
+        .get_regs_len           = xlp_get_regs_len,
+        .get_regs               = xlp_get_regs,
+        .get_msglevel           = xlp_get_msglevel,
+        .set_msglevel           = xlp_set_msglevel,
+        .nway_reset             = xlp_nway_reset,
+        .get_link               = xlp_get_link,
+        .get_strings            = xlp_get_strings,
+        .get_stats_count        = xlp_get_stats_count,
+        .get_ethtool_stats      = xlp_get_ethtool_stats,
+};
+
+void xlp_set_ethtool_ops(struct net_device *netdev)
+{
+	SET_ETHTOOL_OPS(netdev, &xlp_ethtool_ops);
+}
+
+
+/**********************************************************************
+ **********************************************************************/
+void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag)
+{
+	uint32_t regval;
+	int tx_threshold = 512;
+
+	if (flag) {
+		regval = nlm_hal_read_mac_reg(priv->block, priv->index, R_TX_CONTROL);
+		regval &= ~(0x3fff);
+		regval |= (1 << O_TX_CONTROL__TxEnable) |
+			(tx_threshold << O_TX_CONTROL__TxThreshold);
+
+		nlm_hal_write_mac_reg(priv->block, priv->index, R_TX_CONTROL, regval);
+
+		regval = nlm_hal_read_mac_reg(priv->block, priv->index, R_RX_CONTROL);
+		regval |= 1 << O_RX_CONTROL__RxEnable;
+		if (priv->phy.serdes_addr != 0 && (priv->phy.mode & PHY_MODE_RGMII))
+			regval |= 1 << O_RX_CONTROL__RGMII;
+		nlm_hal_write_mac_reg(priv->block, priv->index, R_RX_CONTROL, regval);
+	} else {
+		regval = nlm_hal_read_mac_reg(priv->block, priv->index, R_TX_CONTROL);
+		regval &= ~((1 << O_TX_CONTROL__TxEnable) |
+			    (tx_threshold << O_TX_CONTROL__TxThreshold));
+
+		nlm_hal_write_mac_reg(priv->block, priv->index, R_TX_CONTROL, regval);
+
+		regval = nlm_hal_read_mac_reg(priv->block, priv->index, R_RX_CONTROL);
+		regval &= ~(1 << O_RX_CONTROL__RxEnable);
+		nlm_hal_write_mac_reg(priv->block, priv->index, R_RX_CONTROL, regval);
+	}
+}
diff --git a/drivers/net/xlp_nae/xlp_nae.c b/drivers/net/xlp_nae/xlp_nae.c
new file mode 100644
index 0000000..c64609c
--- /dev/null
+++ b/drivers/net/xlp_nae/xlp_nae.c
@@ -0,0 +1,1197 @@
+/********************************************************************
+
+  Copyright 2003-2010 Netlogic Microsystem, Inc. (NLM). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#NLM_2#**********************************/
+
+#include <linux/types.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/fs.h>
+#include <linux/errno.h>
+#include <linux/proc_fs.h>
+#include <linux/fcntl.h>
+#include <linux/mman.h>
+#include <linux/mm.h>
+#include <linux/pci.h>
+
+#include <asm/current.h>
+#include <asm/system.h> 
+#include <asm/uaccess.h> 
+
+#include <asm/netlogic/msgring.h>
+#include <asm/netlogic/xlr_mac.h>
+
+#include <asm/netlogic/hal/nlm_hal_fmn.h>
+#include <asm/netlogic/hal/nlm_hal_nae.h>
+#include <asm/netlogic/hal/nlm_hal_pic.h>
+#include "net_common.h"
+#include "fmn_credit.h"
+#include "ucore_loader.h"
+#include "common.h"
+#include "xlp_nae.h"
+
+#define XLP_SOC_MAC_DRIVER "XLP Mac Driver"
+#define MAX_NUM_MACS 1
+#define PCI_NETL_VENDOR			0xfecc
+#define PCI_DEVID_BASE			0
+#define PCI_DEVID_OFF_NET		0
+#define MAX_NUM_UARTS			2
+#define FREE_DEFAULT_SIZE		256
+#define NUM_FREE_DESC			18	
+#define NUM_FREEIN_QUEUE		18	
+#define MIN_FRIN_DESC_THRESHD		8	
+#define MAX_NET_INF             	18
+unsigned char icmp_pck[200] = {0x00,0x22,0x19,0x05,0xf0,0xb8,0x00,
+                      0xd0,0xd3,0x3a,0xbd,0x50,0x08,0x00,0x45,0x00,0x00,
+                      0x3c,0x92,0x42,0x00,0x00,0x7f,0x01,0x06,0xb4,0x0a,
+                      0x1a,0x72,0x18,0xc0,0xa8,0x65,0xf0,0x08,0x00,0x0b,
+                      0x12,0x04,0x00,0x3e,0x4a,0x61,0x62,0x63,0x64,0x65,
+                      0x66,0x67,0x68,0x69,0x6a,0x6b,0x6c,0x6d,0x6e,0x6f,
+                      0x70,0x71,0x72,0x73,0x74,0x75,0x76,0x77,0x61,0x62,
+                      0x63,0x64,0x65,0x66,0x67,0x68,0x69  };
+
+
+#define MSG_DST_FC_FAIL                 0x01
+#define MSG_INFLIGHT_MSG_EX             0x02
+#define MSG_TXQ_FULL                    0x04
+#define ICMP_LEN                     	74
+#define MAX_GMAC_PORT               	18
+
+unsigned char eth_hw_addr[18][6] = {
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xE1},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xE2},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xE3},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xE4},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xE5},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xE6},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xE7},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xE8},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xE9},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xEA},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xEB},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xEC},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xED},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xEE},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xEF},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xF1},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xF2},
+					{0xB6,0x75,0x8E,0xDC,0x2F,0xF3}
+				   };
+
+static struct pci_device_id soc_pci_table[] __devinitdata = {
+        {PCI_NETL_VENDOR, PCI_DEVID_BASE + PCI_DEVID_OFF_NET,
+         PCI_ANY_ID, PCI_ANY_ID, 0},
+        {}
+};
+
+extern int  xlp_with_mac_driver;
+extern void xlp_set_ethtool_ops(struct net_device *netdev);
+extern void xlp_get_mac_stats(struct net_device* dev, struct net_device_stats* stats);
+
+static int xlp_mac_proc_read(char *page, char **start, off_t off,int count, int *eof, void *data);
+static int nlm_xlp_nae_fill_rxfr(struct net_device *dev, unsigned int intf);
+static int  nlm_xlp_nae_open (struct net_device *dev);
+static int  nlm_xlp_nae_stop (struct net_device *dev);
+static int  nlm_xlp_nae_start_xmit (struct sk_buff *skb, struct net_device *dev);
+static void  nlm_xlp_set_multicast_list (struct net_device *dev);
+static int  nlm_xlp_nae_ioctl (struct net_device *dev, struct ifreq *rq, int cmd);
+static int  nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu);
+static void  nlm_xlp_nae_tx_timeout (struct net_device *dev);
+static irqreturn_t nlm_xlp_nae_int_handler(int irq, void * dev_id);
+static void nlm_xlp_msgring_handler(int bucket, int size, int code, int stid, struct msgrng_msg *msg, void* data);
+static void nlm_xlp_mac_timer(unsigned long data);
+static void  nlm_xlp_nae_rx(struct sk_buff* skb, struct net_device *dev);
+static struct net_device_stats *nlm_xlp_mac_get_stats(struct net_device *dev);
+
+static void  nlm_xlp_napi_poll(struct napi_struct *napi, int* budget);
+
+static struct net_device *dev_mac[MAX_GMAC_PORT];
+struct net_device *dev_mac_type[MAX_NET_TYPES][MAX_GMAC_PORT];
+
+
+extern struct proc_dir_entry *nlm_root_proc;
+static struct tasklet_struct mac_refill_task[MAX_GMAC_PORT];
+
+extern void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag);
+
+static const struct net_device_ops nlm_xlp_nae_ops = {
+	.ndo_open	= nlm_xlp_nae_open,
+	.ndo_stop	= nlm_xlp_nae_stop,
+	.ndo_start_xmit	= nlm_xlp_nae_start_xmit,
+	.ndo_set_multicast_list	= nlm_xlp_set_multicast_list,
+	.ndo_do_ioctl	= nlm_xlp_nae_ioctl,
+	.ndo_tx_timeout = nlm_xlp_nae_tx_timeout,
+	.ndo_change_mtu	= nlm_xlp_nae_change_mtu,
+	.ndo_set_mac_address	= eth_mac_addr,
+	.ndo_get_stats = nlm_xlp_mac_get_stats,
+};
+
+static __inline__ struct sk_buff *mac_get_skb_back_ptr(uint64_t addr)
+{
+        uint64_t *back_ptr =
+                (uint64_t *)(addr - CACHELINE_SIZE);
+//        printk("%s: addr = %llx,  back_ptr = %llx, skb = %llx\n", __FUNCTION__, addr, (uint64_t)back_ptr, *back_ptr);
+        /* this function should be used only for newly allocated packets. It assumes
+         * the first cacheline is for the back pointer related book keeping info
+         */
+        return (struct sk_buff *)(*back_ptr);
+}
+
+static __inline__ void mac_put_skb_back_ptr(struct sk_buff *skb)
+{
+        uint64_t *back_ptr = (uint64_t *)skb->data;
+
+        /* this function should be used only for newly allocated packets. It assumes
+         * the first cacheline is for the back pointer related book keeping info
+         */
+        skb_reserve(skb, CACHELINE_SIZE);
+        *back_ptr = (uint64_t)skb;
+//        printk("%s: skb->data=%llx, backptr:%llx  skb=%llx\n",__FUNCTION__, skb->data,*back_ptr, skb);
+}
+
+#define CACHELINE_ALIGNED_ADDR(addr) (((unsigned long)(addr)) & ~(CACHELINE_SIZE-1))
+
+/**********************************************************************
+ * cacheline_aligned_kmalloc -  64 bits cache aligned kmalloc 
+ * return -  buffer address
+ *
+ **********************************************************************/
+static __inline__ void *cacheline_aligned_kmalloc(int size, int gfp_mask)
+{
+        void *buf = kmalloc(size + CACHELINE_SIZE, gfp_mask);
+        if (buf)
+                buf =
+                        (void
+                         *)(CACHELINE_ALIGNED_ADDR((unsigned long)buf +
+                                                   CACHELINE_SIZE));
+        return buf;
+}
+
+/**********************************************************************
+ * nlm_xlp_alloc_skb -  64 bits cache aligned skb buffer allocate
+ * return - skb buffer address
+ *
+ **********************************************************************/
+static __inline__ struct sk_buff *nlm_xlp_alloc_skb(void)
+{
+        int offset = 0;
+        struct sk_buff *skb = __dev_alloc_skb(NLM_RX_BUF_SIZE, GFP_KERNEL);
+
+        if (!skb) {
+                return NULL;
+        }
+        /* align the data to the next cache line */
+        offset = ((unsigned long)skb->data + CACHELINE_SIZE) &
+                ~(CACHELINE_SIZE - 1);
+        skb_reserve(skb, (offset - (unsigned long)skb->data));
+
+        return skb;
+}
+
+
+/**********************************************************************
+ * nlm_xlp_free_skb -  change msg into skb buffer address, free it
+ * @msg - freeback msg that sent to cpu vc
+ *
+ **********************************************************************/
+static inline void nlm_xlp_free_skb(struct xlp_msg *msg)
+{
+	struct sk_buff *skb;
+	struct dev_data *priv;
+	int cpu = hard_smp_processor_id();
+	unsigned long tmp;
+	tmp = (unsigned long)(msg->entry[0] & 0xffffffffffULL);
+	skb = (struct sk_buff *)bus_to_virt(tmp);
+
+	if(!skb)
+		return;
+	/* Tx Complete */
+//	xlr_inc_counter(NETIF_TX_COMPLETE);
+
+	dbg_msg("skb = %p\n", skb);
+	/* release the skb and update statistics outside the spinlock */
+	priv = netdev_priv(skb->dev);
+	priv->stats.tx_packets++;
+	priv->stats.tx_bytes += skb->len;
+	priv->cpu_stats[cpu].txc_packets++;
+
+
+	netif_tx_wake_all_queues(skb->dev);
+	//nlm_netif_queue_tx_complete(skb->dev);
+
+	dev_kfree_skb_any(skb);
+}
+/**********************************************************************
+ * mac_refill_frin_desc -  refill rx freein buffer for a device
+ * @dev -  this is per device based function
+ *
+ **********************************************************************/
+static  int mac_refill_frin_desc(struct net_device *dev)
+{
+	struct dev_data* priv = netdev_priv(dev);
+        int ret = 0, mflags = 0, i, code;
+        struct xlp_msg msg;
+	struct sk_buff * skb;
+	uint64_t *idx_ptr;
+
+	for(i=1; i <= MIN_FRIN_DESC_THRESHD*2; i++)
+	{
+		 skb = nlm_xlp_alloc_skb();
+		if(!skb)
+		{
+			printk("[%s] alloc skb failed\n",__FUNCTION__);
+			return -ENOMEM;
+		}
+
+        	skb->dev = dev;
+
+        	/* Send the free Rx desc to the MAC */
+		mac_put_skb_back_ptr(skb);
+        	code = 0;
+		idx_ptr = (uint64_t*)((unsigned long)skb->data-20);
+		*idx_ptr = i;
+
+		msgrng_access_enable(mflags);
+        	msg.entry[0] = (unsigned long long)virt_to_bus(skb->data) & 0xffffffffffULL;
+        	msg.entry[1]= msg.entry[2] = msg.entry[3] = 0;
+
+        	/* Send the packet to nae rx  */
+		__sync();
+retry_send:
+                if (ret = nlm_hal_send_msg1( priv->nae_rx_qid, code, msg.entry[0])){
+                        if(ret & MSG_DST_FC_FAIL)
+                                printk("TX message destination flow control credit fail\n");
+                        else if(ret & MSG_INFLIGHT_MSG_EX)
+                                goto retry_send;
+                        else if(ret & MSG_TXQ_FULL)
+                                printk("TX message Q fulll\n");
+                        dev_kfree_skb(skb);
+                        msgrng_access_disable(mflags);
+                        break;
+                }
+
+		msgrng_access_disable(mflags);
+		priv->num_desc++;
+/*
+ *		 printk("mac_%d: Sending freein %llx  to vc %d, num %d\n",priv->port, msg.entry[0], priv->nae_rx_qid, (int)priv->num_desc);
+*/
+	}
+
+        return ret;
+}
+
+/**********************************************************************
+ * nlm_xlp_nae_fill_rxfr -  create rx freein buffer for one interface
+ * @dev  -  this is per device based function
+ * @intf -  interface number
+ **********************************************************************/
+static int nlm_xlp_nae_fill_rxfr(struct net_device *dev, unsigned int intf)
+{
+        struct dev_data *priv = netdev_priv(dev);
+        struct sk_buff *skb = 0;
+        unsigned long mflags;
+        int i,code;
+        int ret = 1;
+        struct xlp_msg msg = { {0, 0, 0, 0} };
+	uint64_t* idx_ptr;
+
+	for (i = 1; i <= NUM_FREEIN_QUEUE ; i++) {
+		skb = nlm_xlp_alloc_skb();
+		if (!skb) {
+			printk("[%s] alloc skb failed\n",__FUNCTION__);
+			return -ENOMEM;
+		}
+
+		skb->dev = dev_mac[intf];
+
+		/* Send the free Rx desc*/
+		msgrng_access_enable(mflags);
+		mac_put_skb_back_ptr(skb);
+
+		code = 0;
+		idx_ptr = (uint64_t*)((uint64_t)skb->data-20);
+		*idx_ptr = i;
+
+		msg.entry[0] = (unsigned long long)virt_to_bus(skb->data) & 0xffffffffffULL;
+		msg.entry[1]= msg.entry[2] = msg.entry[3] = 0;
+retry_send:
+                if (ret = nlm_hal_send_msg1( priv->nae_rx_qid,
+                                        code,
+                                        msg.entry[0])){
+                        if(ret & MSG_DST_FC_FAIL)
+                                printk("TX message destination flow control credit fail\n");
+                        else if(ret & MSG_INFLIGHT_MSG_EX)
+                                goto retry_send;
+                        else if(ret & MSG_TXQ_FULL)
+                                printk("TX message Q fulll\n");
+                        dev_kfree_skb(skb);
+                        msgrng_access_disable(mflags);
+                        break;
+                }
+
+	
+		
+		msgrng_access_disable(mflags);
+		priv->num_desc++;
+/*
+ * 	printk("[%s] intf %d  freein %d    %llx  num_desc: %d\n", __FUNCTION__,intf, i, msg.entry[0],(int)priv->num_desc);
+*/
+        }
+
+        return ret;
+}
+
+static int __devinit mac_pci_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
+{
+        int result = 0;
+
+        /*static atmoic_t int  num_macs = ATOMIC_INIT(0);*/
+        static int  num_macs = 1; 
+        int instance = atomic_inc_return(&num_macs) - 1;
+
+        if (instance < 0 || instance >= (MAX_NUM_UARTS - 1)) {
+                printk("Found an Invalid mac pci device instance_%d!\n", instance);
+                return -1 ;
+        }
+        result = pci_enable_device(pdev);
+	return result;
+
+}
+
+/**********************************************************************
+ * nlm_xlp_nae_init -  xlp_nae device driver init function
+ * @dev  -  this is per device based function
+ * 
+ **********************************************************************/
+
+static void nlm_xlp_nae_init(void)
+{
+	struct net_device *dev = NULL;
+	struct dev_data *tp;
+	int i;
+	unsigned long mflags;
+	struct proc_dir_entry *entry;
+
+/*
+ 	if(xlp_with_mac_driver == 0)
+	{
+		printk("NET: [%s] driver init is diabled. xlp_with_mac_driver=0\n",__FUNCTION__);
+		return;
+	}
+*/
+	//initial base address for nae, gmac, fmn ...
+	nlm_hal_init();
+
+	//initial 18 gmac block	
+        for(i = 0; i < MAX_NET_INF; i++)
+	{
+		init_gmac(i);
+	}
+
+	//init fmn
+	fmn_init(g_credit);
+
+	msgrng_access_enable(mflags);
+
+	//init tx if credit	
+	init_tx_if_credit( 0, 0x7FFFF );
+
+	for (i = 0; i < MAX_NET_INF; i++ )
+	{
+		init_ucore(0xffffUL, i);
+	}
+
+	ucore_load_apps(0xffffUL);	
+
+	// init egress and igress interface
+	init_ingress();
+	init_egress();
+
+	for(i = 0; i< MAX_GMAC_PORT; i++)
+	{
+		dev = alloc_etherdev(sizeof(*tp));
+		if(!dev)
+			return ;
+
+		ether_setup(dev);
+
+        	tp = netdev_priv(dev);
+		tp->dev 	= dev;
+		dev->netdev_ops = &nlm_xlp_nae_ops;
+		//set ethtool_ops which is inside xlp_ethtool.c file
+		xlp_set_ethtool_ops(dev);
+
+		netif_napi_add(dev, &tp->napi, nlm_xlp_napi_poll, 16);
+
+//		random_ether_addr(dev->dev_addr);  
+		dev->dev_addr = eth_hw_addr[i];  
+		tp->port	= i;
+		tp->inited	= 0;
+		tp->block 	=(i&0xff)>>2;
+		tp->index 	= i&0x3;
+		tp->nae_tx_qid 	= XLP_NET_TX_VC_BASE+i;
+		tp->nae_rx_qid 	= XLP_NET_RX_VC_BASE+i;
+		register_netdev(dev);
+
+		dev_mac_type[tp->type][tp->port] = dev;
+		dev_mac[i] = dev;
+
+	}
+
+	entry = create_proc_read_entry("nlm_mac_stats", 0 /* def mode */ ,
+				       nlm_root_proc /* parent */ ,
+				       xlp_mac_proc_read /* proc read function */ ,
+				       0	/* no client data */
+					);
+	if (!entry) {
+		printk("[%s]: Unable to create proc read entry for xlp_mac!\n",
+		       __FUNCTION__);
+	}
+	
+	if(register_msgring_handler( 0 /*TX_STN_GMAC08*/, nlm_xlp_msgring_handler, NULL))
+	{
+		panic("can't register msgring handler for TX_STN_GMAC0");
+	}
+
+}
+
+/**********************************************************************
+ * nlm_xlp_nae_open -  called when bring up a device interface
+ * @dev  -  this is per device based function
+ * 
+ **********************************************************************/
+
+static int  nlm_xlp_nae_open (struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	int port = priv->port;
+	int ret  = 0, i;
+	int irq  = irt_irq_table[PIC_IRT_NA_INDEX(port)][0];
+
+	if(priv->inited)
+		return ret;
+
+	nlm_xlp_nae_fill_rxfr(dev,  port );
+
+	if(request_irq( irq, nlm_xlp_nae_int_handler, IRQF_SHARED,dev->name, dev)){
+		ret = -EBUSY;
+		printk("can't get mac interrupt line (%d)\n",dev->irq);
+	}
+	dump_irt_entry(PIC_IRT_NA_INDEX(port));
+	printk("PIC_CTRL: %x\n", nlm_hal_read_pic_reg((pic_reg_t*)XLP_IO_PIC_OFFSET, PIC_CTRL ));	
+	printk("PIC_STATUS: %x\n", nlm_hal_read_pic_reg((pic_reg_t*)XLP_IO_PIC_OFFSET,PIC_STATUS ));	
+	printk("PIC_INT_PENDING0: %x\n", nlm_hal_read_pic_reg((pic_reg_t*)XLP_IO_PIC_OFFSET, PIC_INT_PENDING0 ));	
+	printk("PIC_INT_PENDING1: %x\n", nlm_hal_read_pic_reg((pic_reg_t*)XLP_IO_PIC_OFFSET, PIC_INT_PENDING1 ));	
+	printk("PIC_INT_PENDING2: %x\n", nlm_hal_read_pic_reg((pic_reg_t*)XLP_IO_PIC_OFFSET, PIC_INT_PENDING2 ));	
+	printk("PIC_IPI_CTL: %x\n", nlm_hal_read_pic_reg((pic_reg_t*)XLP_IO_PIC_OFFSET,PIC_IPI_CTL ));	
+	/* set timer to test rx routine */
+	init_timer(&priv->link_timer);
+	priv->link_timer.expires = jiffies + HZ/100 ;
+	priv->link_timer.data    = (unsigned long) priv->port;
+	priv->link_timer.function = &nlm_xlp_mac_timer;
+	priv->phy_oldlinkstat = -1;
+/*
+	add_timer(&priv->link_timer);
+*/
+//	napi_enable(&priv->napi);
+
+
+//	nlm_xlp_mac_set_enable(priv, 1);
+
+	priv->stats.tx_packets	= 0;
+	priv->stats.tx_errors	= 0;
+	priv->stats.tx_bytes	= 0;
+	priv->stats.tx_dropped	= 0;
+	priv->stats.rx_packets	= 0;
+	priv->stats.rx_errors	= 0;
+	priv->stats.rx_bytes	= 0;
+	priv->stats.rx_dropped	= 0;
+	priv->stats.multicast	= 0;
+	priv->stats.collisions	= 0;
+
+	for(i = 0; i < 8; i++)
+	{
+		priv->cpu_stats[i].tx_packets	= 0;
+		priv->cpu_stats[i].txc_packets	= 0;
+		priv->cpu_stats[i].rx_packets	= 0;
+		priv->cpu_stats[i].interrupts	= 0;
+
+	}
+	tasklet_init(&mac_refill_task[port],mac_refill_frin_desc,(unsigned long) dev);
+	priv->inited = 1;	
+
+	return 0;
+}
+
+/**********************************************************************
+ * nlm_xlp_nae_stop -  called when bring down the interface
+ * @dev  -  this is per device based function
+ * 
+ **********************************************************************/
+static int  nlm_xlp_nae_stop (struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+
+	spin_lock_irq(&priv->lock);
+	nlm_xlp_mac_set_enable(priv, 0);
+
+	del_timer_sync(&priv->link_timer);
+	netif_tx_stop_all_queues(dev);
+
+	napi_disable(&priv->napi);	
+	spin_unlock_irq(&priv->lock);
+	return 0;
+}
+
+
+/**********************************************************************
+ * nlm_xlp_nae_start_xmit -  transmit a packet from buffer
+ * @dev  -  this is per device based function
+ * @skb  -  data buffer to send
+ **********************************************************************/
+static int nlm_xlp_nae_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	int port = priv->port;
+	unsigned long mflags = 0;
+	int cpu = 0, ret = 0;
+	struct xlp_msg msg =  { {0, 0, 0, 0} };
+	
+	if(!skb)
+	{
+		printk("[%s] skb is NULL\n",__FUNCTION__);
+		return -1;
+	}
+	if(skb->len == 0)
+	{
+		printk("[%s] skb empty packet\n",__FUNCTION__);
+//		skb->len = 0x4e;
+		return -1;
+	}
+	mac_put_skb_back_ptr(skb);
+	msg.entry[0] = nae_tx_desc(P2D_NEOP, 0, CPU_Q_ID( 0, 0, 1), 0, virt_to_bus(skb));
+	msg.entry[1] = nae_tx_desc(P2D_EOP,
+							 0,
+							 NULL_VFBID,
+							 skb->len,
+							 virt_to_bus(skb->data+(port&0xf)));
+
+	msg.entry[2] = msg.entry[3] = 0;
+
+//	log_info("port:%d send %d skb %llx skb->data %llx len %d to qid %d \n", priv->port,(int)priv->stats.tx_packets, (uint64_t)skb, (uint64_t)skb->data,skb->len, nae_tx_qid);
+
+	__sync(); 
+	msgrng_access_enable(mflags);
+retry_send:
+        if (ret = nlm_hal_send_msg2( priv->nae_tx_qid,
+                           0,
+                           msg.entry[0],
+                           msg.entry[1]))
+        {
+                if(ret & MSG_DST_FC_FAIL)
+                        printk("TX message destination flow control credit fail\n");
+                else if(ret & MSG_INFLIGHT_MSG_EX)
+                        goto retry_send;
+                else if(ret & MSG_TXQ_FULL)
+                        printk("TX message Q fulll\n");
+                priv->stats.tx_errors++;
+                msgrng_access_disable(mflags);
+                return NETDEV_TX_BUSY;
+        }
+
+	msgrng_access_disable(mflags);
+	dev->trans_start = jiffies;
+
+    	priv->stats.tx_bytes += skb->len;
+    	priv->stats.tx_packets++;
+    	priv->cpu_stats[cpu].tx_packets++;
+
+	if(priv->num_desc <= MIN_FRIN_DESC_THRESHD)
+	{ 
+		netif_stop_queue(dev);
+	}
+    	return NETDEV_TX_OK;
+}
+
+
+static void  nlm_xlp_set_multicast_list (struct net_device *dev)
+{
+	if (dev->flags & IFF_ALLMULTI) {
+		/* 
+		 * Enable ALL multicasts.  Do this by inverting the 
+		 * multicast enable bit. 
+		 */
+		return;
+	}
+	return;
+}
+
+static int  nlm_xlp_nae_ioctl (struct net_device *dev, struct ifreq *rq, int cmd)
+{
+	int rc = 0;
+	switch (cmd) {
+	default:
+		rc = -EOPNOTSUPP;
+		break;
+	}
+
+	return rc;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static int nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	if ((new_mtu > 1500) || (new_mtu < 64)) {
+		return -EINVAL;
+	}
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	dev->mtu = new_mtu;
+
+	if (netif_running(dev)) {
+		/* Disable MAC TX/RX */
+		nlm_xlp_mac_set_enable(priv, 0);
+
+		/* Flush RX FR IN */
+		/* Flush TX IN */
+		nlm_xlp_mac_set_enable(priv, 1);
+	}
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return 0;
+}
+
+/**********************************************************************
+ * nlm_xlp_mac_get_stats - wrap function for xlp_get_mac_stats
+ * @dev   -  this is per device based function
+ **********************************************************************/
+static struct net_device_stats *nlm_xlp_mac_get_stats(struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	xlp_get_mac_stats(dev, &priv->stats);
+
+	/* XXX update other stats here */
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return &priv->stats;
+}
+
+/**********************************************************************
+ * nlm_xlp_nae_tx_timeout -  called when transmiter timeout
+ * @dev  -  this is per device based function
+ * 
+ **********************************************************************/
+static void  nlm_xlp_nae_tx_timeout (struct net_device *dev)
+{
+	struct dev_data *priv = netdev_priv(dev);
+
+	spin_lock_irq(&priv->lock);
+
+	priv->stats.tx_errors++;
+
+	spin_unlock_irq(&priv->lock);
+
+	netif_tx_wake_all_queues(dev);
+
+	printk(KERN_WARNING "%s: Transmit timed out\n", dev->name);
+	return;
+}
+
+/**********************************************************************
+ * nlm_xlp_nae_rx -  main receive function
+ * @skb  -  skb buffer address
+ * @dev  -  this device 
+ * 
+ **********************************************************************/
+static void  nlm_xlp_nae_rx(struct sk_buff* skb, struct net_device *dev)
+{
+	unsigned long mflags;
+	struct dev_data * priv = netdev_priv(dev);
+	unsigned int len, size,src_id, code, src;
+	unsigned char* buf;
+	uint64_t addr , vaddr;
+	uint32_t rx_status = 0;
+	struct xlp_msg fr_msg =  {{0, 0, 0, 0}} ;
+	struct xlp_msg rx_msg =  {{0, 0, 0, 0}} ;
+	unsigned short port;
+
+	int cpu_qid = CPU_Q_ID( 0, 0, 0); /* core0 thread0 vc0 */
+	int cpu = 0;
+	
+	priv->cpu_stats[cpu].interrupts++;
+
+    	msgrng_access_enable(mflags);
+
+
+	// process packet message at cpu vc 1
+	if (nlm_hal_recv_msg1(1,
+			  &src_id,
+			  &size,
+			  &code,
+			  &fr_msg.entry[0])){
+		rx_print(fr_msg.entry[0]);
+		printk("port: %d got src_id: %d fr_msg %llx \n\n",priv->port, src_id, fr_msg.entry[0]);
+  		addr = (fr_msg.entry[0]) & 0xffffffffffULL;
+		len = (fr_msg.entry[0] >> 40) & 0x3fff;
+		if(addr && (len==0))
+		{
+			skb = (struct sk_buff *)bus_to_virt(addr);
+//			log_dbg("\nTX: port %d free addr:0x%llx \n",priv->port,(uint64_t)bus_to_virt(addr));
+			if(skb)
+			{
+				priv->stats.rx_packets++;
+				if(priv->stats.rx_packets % MIN_FRIN_DESC_THRESHD == 15)
+				{
+					netif_tx_wake_all_queues(dev);
+				}
+				dev_kfree_skb_any(skb);
+			}
+    		}
+		else if(addr == 0) 
+		{
+			//case tx queue is stopped 
+			netif_tx_wake_all_queues(dev);
+		}
+	}
+	// process packet message at cpu vc 0
+	if (rx_status = nlm_hal_recv_msg2(cpu_qid,
+                                &src_id,
+                               	&size,
+                               	&code,
+                               	&rx_msg.entry[0],
+                               	&rx_msg.entry[1])) 
+	{
+               if(rx_status & 0x01)
+                {
+                        priv->stats.rx_errors++;
+                        printk("[%s] RX Load msg failed\n",__FUNCTION__);
+                	msgrng_access_disable(mflags);
+                	return;
+                }
+                else if(rx_status & 0x02)
+                {
+                        priv->stats.rx_errors++;
+                        printk("[%s] RX pop msg request failed\n",__FUNCTION__);
+                	msgrng_access_disable(mflags);
+                	return;
+                }
+                else if(rx_status>>28)
+                {
+                        printk("[%s] RX queue %x empty, no msg\n",__FUNCTION__,(rx_status>>28));
+                        netif_tx_wake_all_queues(dev);
+                	msgrng_access_disable(mflags);
+                        goto fill_desc;
+                }
+	}
+	msgrng_access_disable(mflags);
+
+	addr = (rx_msg.entry[1]) & 0xfffffffff0ULL;
+    	len = (rx_msg.entry[1] >> 40) & 0x3fff;
+    
+	//update dev and port to be accurate	
+	port = rx_msg.entry[1]  & 0x0f;
+	dev = dev_mac[port];
+	priv = netdev_priv(dev);
+	if(!len || addr == 0) 
+	{
+		if( priv->num_desc < MIN_FRIN_DESC_THRESHD)
+			tasklet_schedule(&mac_refill_task[priv->port]);
+		//goto fill_desc;
+		return;
+	}
+	vaddr = (uint64_t)bus_to_virt(addr);
+    	buf = (unsigned char *)vaddr;
+//	log_dbg("RX: port:%d src_id: %d recv buf: 0x%llx len:%d addr:0x%010llx  \n",priv->port,src_id,(uint64_t)buf, len, vaddr);
+
+	if(len  - BYTE_OFFSET -MAC_CRC_LEN - MAC_PREPAD< 0)
+	{
+		//
+		priv->stats.rx_errors++;
+		priv->stats.rx_dropped++;
+		printk("[%s] wrong packet len %d, drop it!",__FUNCTION__,len);
+		return ;
+	}
+	else
+	{
+		len = len  - BYTE_OFFSET -MAC_CRC_LEN - MAC_PREPAD;
+	
+		if(len >=2048)
+		{
+			priv->stats.rx_errors++;
+			priv->stats.rx_dropped++;
+			printk("[%s] packet too long %d, drop it!\n",__FUNCTION__,len);
+			return ;
+		}	
+       }
+	skb = mac_get_skb_back_ptr(vaddr);
+        if (skb) {
+			src = *((unsigned long *)(skb->data-20));
+//			skb_reserve(skb, MAC_PREPAD+BYTE_OFFSET );
+//			printk("%s : addr :%llx  len:%d  skb: %llx src: %d  num_desc: %d\n", __FUNCTION__, addr, len, (uint64_t)skb,src,(int) priv->num_desc);
+			skb_put(skb, len);
+			skb->dev = dev_mac[port];
+			skb->protocol = eth_type_trans(skb, dev_mac[port]);
+//			printk("\n[%s] port: %d  dev %llx  protocol %d\n",__FUNCTION__, priv->port, (uint64_t)dev_mac[port], skb->protocol);
+			skb->dev->last_rx = jiffies;
+//		netif_receive_skb(skb);
+		netif_rx (skb);
+           	priv->stats.rx_bytes += len;
+            	priv->stats.rx_packets++;
+		priv->cpu_stats[cpu].rx_packets++;
+		priv->num_desc--;
+        } 
+	else if(!skb)
+	{
+		priv->stats.rx_errors++;
+		priv->stats.rx_dropped++;
+		printk("[%s] wrong skb addr %llx, drop it!",__FUNCTION__,(uint64_t)skb);
+		return;
+	}
+
+fill_desc:
+	if(priv->num_desc < MIN_FRIN_DESC_THRESHD)
+	{
+		tasklet_schedule(&mac_refill_task[priv->port]);
+	}
+
+	return;
+
+}
+
+/**********************************************************************
+ * nlm_xlp_nae_int_handler -  interrupt handler
+ * @irq     -  irq number
+ * @dev_id  -  this device 
+ * 
+ **********************************************************************/
+static irqreturn_t nlm_xlp_nae_int_handler(int irq, void * dev_id)
+{
+	if(!dev_id)
+	{
+		printk("[%s]: NULL dev_id \n", __FUNCTION__ );
+		return IRQ_HANDLED;
+	}
+	struct net_device * dev = (struct net_device*)dev_id;
+    	struct dev_data *priv = netdev_priv(dev);
+	int i;
+	
+	i = find_irt_from_irq(irq);
+
+	nlm_xlp_nae_rx(priv->skb, dev);
+
+	return IRQ_HANDLED;
+}
+
+/**********************************************************************
+ * nlm_xlp_msgring_handler -  message ring interrupt handler
+ * @irq     -  irq number
+ * @dev_id  -  this device 
+ * 
+ **********************************************************************/
+static void nlm_xlp_msgring_handler(int vc, int size, int code, int stid, struct msgrng_msg *msg, void* data)
+{
+	printk("%s : stid:%d \n", __FUNCTION__,stid );
+}
+
+/**********************************************************************
+ * xlp_mac_proc_read -  proc file system read routine
+ * @page     -  buffer address
+ * @dev_id  -  this device 
+ * 
+ **********************************************************************/
+static int xlp_mac_proc_read(char *page, char **start, off_t off,
+			     int count, int *eof, void *data)
+{
+	int len = 0;
+	off_t begin = 0;
+	int i = 0, cpu = 0;
+	struct net_device *dev = 0;
+	struct dev_data *priv = 0;
+
+
+	for(i=0; i< MAX_GMAC_PORT; i++) {
+		dev = dev_mac[i];
+		if(dev == 0)
+			continue;
+
+		priv = netdev_priv(dev);
+		
+
+		len += sprintf(page + len,
+			       "per port:  %d %lx %lx %lx %lx\n",
+			       i,
+			       priv->stats.rx_packets, priv->stats.rx_bytes,
+			       priv->stats.tx_packets, priv->stats.tx_bytes);
+	}
+	for(cpu=0;cpu<8;cpu++) {
+			len += sprintf(page + len, "per cpu:  %d %lx %lx %lx %lx\n", 
+				        cpu,
+				       priv->cpu_stats[cpu].tx_packets,
+				       priv->cpu_stats[cpu].txc_packets,
+				       priv->cpu_stats[cpu].rx_packets,
+				       priv->cpu_stats[cpu].interrupts);
+		}
+
+	*eof = 1;
+
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;	
+}
+
+
+/**********************************************************************
+ * nlm_xlp_mac_timer - interrupt handler routine
+ * @data - parameter passed in when timer interrupt handler is called.
+ **********************************************************************/
+static void nlm_xlp_mac_timer(unsigned long data)
+{
+	unsigned port = data;
+        struct net_device *dev = (struct net_device *)dev_mac[port];
+        struct dev_data *priv = netdev_priv(dev);
+        int next_tick = HZ;
+
+        spin_lock_irq(&priv->lock);
+	nlm_xlp_nae_rx(priv->skb, dev);
+        spin_unlock_irq(&priv->lock);
+        priv->link_timer.expires = jiffies + next_tick/10;
+        add_timer(&priv->link_timer);
+}
+
+/**********************************************************************
+ * nlm_xlp_napi_poll - net device napi callback handler
+ * @napi - structure for parameter
+ * @budget - max number buffer can be processed per call.
+ **********************************************************************/
+static void  nlm_xlp_napi_poll(struct napi_struct *napi, int* budget)
+{
+	unsigned long mflags;
+	struct net_device * dev = napi->dev;
+	struct dev_data * priv = netdev_priv(dev);
+	unsigned int len, size,src_id, code, src;
+	unsigned char* buf;
+	uint64_t addr , vaddr;
+	uint32_t rx_status = 0;
+	struct xlp_msg fr_msg =  {{0, 0, 0, 0}} ;
+	struct xlp_msg rx_msg =  {{0, 0, 0, 0}} ;
+	struct sk_buff* skb;
+
+	int cpu_qid = CPU_Q_ID( 0, 0, 0); /* core0 thread0 vc0 */
+	int cpu = 0;
+	printk("[%s] \n", __FUNCTION__);
+	
+	priv->cpu_stats[cpu].interrupts++;
+
+    	msgrng_access_enable(mflags);
+
+
+	// process packet message at cpu vc 1
+	if (nlm_hal_recv_msg1(1,
+			  &src_id,
+			  &size,
+			  &code,
+			  &fr_msg.entry[0])){
+		rx_print(fr_msg.entry[0]);
+//		printk("got a fr_msg \n\n");
+  		addr = (fr_msg.entry[0]) & 0xffffffffffULL;
+		len = (fr_msg.entry[0] >> 40) & 0x3fff;
+		if(addr && (len==0))
+		{
+			skb = (struct sk_buff *)bus_to_virt(addr);
+//			log_dbg("\nfree addr:0x%010llx \n",(uint64_t)bus_to_virt(addr));
+			if(skb)
+			{
+				priv->stats.rx_packets++;
+				if(priv->stats.rx_packets % MIN_FRIN_DESC_THRESHD == 15)
+				{
+					netif_tx_wake_all_queues(dev);
+				}
+				dev_kfree_skb_any(skb);
+			}
+  	  	}
+		else if(addr == 0) 
+		{
+			//case tx queue is stopped 
+			netif_tx_wake_all_queues(dev);
+		}
+     	}
+	// process packet message at cpu vc 0
+	if (!nlm_hal_recv_msg2(cpu_qid,
+                                  &src_id,
+                               	&size,
+                               	&code,
+                               	&rx_msg.entry[0],
+                               	&rx_msg.entry[1])) 
+	{
+	        rx_status = xlp_read_rx_status();
+		if(rx_status == 0)
+		{
+			netif_tx_wake_all_queues(dev);
+			return;
+		}
+        	if (!((rx_status >> 28) & (1 << cpu_qid))) {
+             		priv->stats.rx_errors++;
+                	return;
+		}
+	}
+	msgrng_access_disable(mflags);
+
+	addr = (rx_msg.entry[1]) & 0xffffffffffULL;
+    	len = (rx_msg.entry[1] >> 40) & 0x3fff;
+	if(!len || addr == 0) 
+	{
+		if( priv->num_desc < MIN_FRIN_DESC_THRESHD)
+			tasklet_schedule(&mac_refill_task);
+		return;
+	}
+	vaddr = (uint64_t)bus_to_virt(addr);
+    	buf = (unsigned char *)vaddr;
+	log_dbg("recv buf: 0x%llx len:%d addr:0x%llx  \n",(uint64_t)buf, len, vaddr);
+
+	if(len  - BYTE_OFFSET -MAC_CRC_LEN - MAC_PREPAD< 0)
+	{
+		//
+		priv->stats.rx_errors++;
+		priv->stats.rx_dropped++;
+		printk("[%s] wrong packet len %d, drop it!",__FUNCTION__,len);
+		return ;
+	}
+	else
+	{
+		len = len  - BYTE_OFFSET -MAC_CRC_LEN - MAC_PREPAD;
+	
+		if(len >=2048)
+		{
+		priv->stats.rx_errors++;
+			priv->stats.rx_dropped++;
+			printk("[%s] packet too long %d, drop it!\n",__FUNCTION__,len);
+			return ;
+		}	
+       }
+	skb = mac_get_skb_back_ptr(vaddr);
+        if (skb) {
+			src = *((unsigned long *)(skb->data-20));
+//			skb_reserve(skb, MAC_PREPAD+BYTE_OFFSET );
+//			printk("%s : addr :%llx  len:%d  skb: %llx src: %d  num_desc: %d\n", __FUNCTION__, addr, len, (uint64_t)skb,src, (int)priv->num_desc);
+			skb_put(skb, len);
+			skb->dev = dev;
+			skb->protocol = eth_type_trans(skb, dev);
+//	printk("\n[%s] port: %d  dev %llx  protocol %d\n",__FUNCTION__, priv->port, (uint64_t)dev, skb->protocol);
+			skb->dev->last_rx = jiffies;
+			netif_receive_skb(skb);
+			priv->stats.rx_bytes += len;
+			priv->stats.rx_packets++;
+			priv->cpu_stats[cpu].rx_packets++;
+        } 
+	else if(!skb)
+	{
+		priv->stats.rx_errors++;
+		priv->stats.rx_dropped++;
+		printk("[%s] wrong skb addr %llx, drop it!",__FUNCTION__,(uint64_t)skb);
+		return;
+	}
+	if( -- priv->num_desc < MIN_FRIN_DESC_THRESHD)
+	{
+		tasklet_schedule(&mac_refill_task);
+	}
+
+	return;
+}
+
+
+/**********************************************************************
+ * nlm_xlp_remove - driver remove routine
+ * @pdev - pci device.
+ **********************************************************************/
+static void nlm_xlp_remove(struct pci_dev *pdev)
+{
+	int i;
+	struct net_device *dev;
+        struct dev_data *priv; 
+
+	for (i = 0; i < MAX_GMAC_PORT; i++)
+	{
+		dev = dev_mac[i];
+        	priv = netdev_priv(dev);
+		netif_napi_del(&priv->napi);
+		unregister_netdev(dev);
+		free_netdev(dev);
+	}
+
+	remove_proc_entry("nlm_mac_stats", nlm_root_proc /* parent dir*/ );
+
+}
+
+static struct pci_driver soc_driver = {
+	.name             = XLP_SOC_MAC_DRIVER,
+	.id_table         = soc_pci_table,
+	.probe            = mac_pci_probe,
+	.remove		  = nlm_xlp_remove,
+};
+
+static int __init nlm_xlp_mac_init(void)
+{
+
+	nlm_xlp_nae_init();
+
+    	return pci_register_driver(&soc_driver);
+}
+
+static void __exit nlm_xlp_mac_exit(void)
+{
+	pci_unregister_driver(&soc_driver);
+}
+
+module_init(nlm_xlp_mac_init);
+module_exit(nlm_xlp_mac_exit);
+
+MODULE_AUTHOR("Netlogic Microsystems");
+MODULE_DESCRIPTION("Netlogic XLP SoC Network driver ");
+MODULE_LICENSE("GPL"); 
+MODULE_VERSION("0.1"); 
diff --git a/drivers/net/xlp_nae/xlp_nae.h b/drivers/net/xlp_nae/xlp_nae.h
new file mode 100644
index 0000000..b4c18e5
--- /dev/null
+++ b/drivers/net/xlp_nae/xlp_nae.h
@@ -0,0 +1,60 @@
+#ifndef _XLP_NAE_H
+#define _XLP_NAE_H
+
+#define MAX_CPUS	8
+
+struct cpu_stat {
+        unsigned long tx_packets;
+        unsigned long txc_packets;
+        unsigned long rx_packets;
+        unsigned long interrupts;
+};
+
+typedef enum { xlp_mac_speed_10, xlp_mac_speed_100,
+               xlp_mac_speed_1000, xlp_mac_speed_rsvd
+} xlp_mac_speed_t;
+
+typedef enum { xlp_mac_duplex_auto, xlp_mac_duplex_half,
+               xlp_mac_duplex_full
+} xlp_mac_duplex_t;
+
+typedef enum { xlp_mac_fc_auto, xlp_mac_fc_disabled, xlp_mac_fc_frame,
+               xlp_mac_fc_collision, xlp_mac_fc_carrier
+} xlp_mac_fc_t;
+
+struct phy_info {
+        int addr;
+        int mode;
+        uint32_t *mii_addr;
+        uint32_t *pcs_addr;
+        uint32_t *serdes_addr;
+};
+
+struct dev_data
+{
+        struct net_device *dev;
+        struct net_device_stats stats;
+        struct cpu_stat cpu_stats[MAX_CPUS];
+        struct timer_list link_timer;
+        struct napi_struct napi;
+        spinlock_t lock;
+        unsigned short port;
+	unsigned short inited;
+        unsigned short block;
+        unsigned short index;
+        unsigned short type;
+        struct sk_buff* skb;
+        int phy_oldlinkstat;
+        unsigned long num_desc;
+        __u8 hwaddr[6];
+
+        xlp_mac_speed_t speed;  /* current speed */
+        xlp_mac_duplex_t duplex;        /* current duplex */
+        xlp_mac_fc_t flow_ctrl; /* current flow control setting */
+        int advertising;
+        struct phy_info phy;
+        int nae_rx_qid;
+        int nae_tx_qid;
+};
+
+#endif
diff --git a/drivers/pci/proc.c b/drivers/pci/proc.c
index 6de04b6..838ecd0 100644
--- a/drivers/pci/proc.c
+++ b/drivers/pci/proc.c
@@ -403,7 +403,7 @@ int pci_proc_attach_device(struct pci_dev *dev)
 		return -EACCES;
 
 	if (!bus->procdir) {
-#ifdef CONFIG_RMI_PHOENIX
+#ifdef CONFIG_NLM_COMMON
 		/* 
 		   create /proc entries in "%02x" format at all times.
 		   Otherwise, for HT, it will be created in "%04x:%02x" format
diff --git a/drivers/watchdog/Kconfig b/drivers/watchdog/Kconfig
index 3d8afac..20ef23d 100644
--- a/drivers/watchdog/Kconfig
+++ b/drivers/watchdog/Kconfig
@@ -1104,9 +1104,9 @@ config LANTIQ_WDT
 	help
 	  Hardware driver for the Lantiq SoC Watchdog Timer.
 
-config RMI_WATCHDOG
+config NLM_WATCHDOG
         tristate "RMI XL* Hardware Watchdog"
-        depends on WATCHDOG && RMI_PHOENIX
+        depends on WATCHDOG && NLM_PHOENIX
         help
           Hardware driver for the XL* watchdog. This is a watchdog timer
           that will reboot the machine after a 60 second timer expired
diff --git a/drivers/watchdog/Makefile b/drivers/watchdog/Makefile
index a300b94..8cf251c 100644
--- a/drivers/watchdog/Makefile
+++ b/drivers/watchdog/Makefile
@@ -131,6 +131,7 @@ obj-$(CONFIG_PNX833X_WDT) += pnx833x_wdt.o
 obj-$(CONFIG_SIBYTE_WDOG) += sb_wdog.o
 obj-$(CONFIG_AR7_WDT) += ar7_wdt.o
 obj-$(CONFIG_TXX9_WDT) += txx9wdt.o
+obj-$(CONFIG_NLM_WATCHDOG) += nlm_common_wdt.o
 obj-$(CONFIG_OCTEON_WDT) += octeon-wdt.o
 octeon-wdt-y := octeon-wdt-main.o octeon-wdt-nmi.o
 obj-$(CONFIG_LANTIQ_WDT) += lantiq_wdt.o
diff --git a/include/linux/memblk.h b/include/linux/memblk.h
index 421642b..3279c83 100644
--- a/include/linux/memblk.h
+++ b/include/linux/memblk.h
@@ -1,32 +1,27 @@
-/*********************************************************************
-
-  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
-  reserved.
-
-  Redistribution and use in source and binary forms, with or without 
-  modification, are permitted provided that the following conditions
-  are met:
-
-  1. Redistributions of source code must retain the above copyright
-  notice, this list of conditions and the following disclaimer.
-  2. Redistributions in binary form must reproduce the above copyright
-  notice, this list of conditions and the following disclaimer in
-  the documentation and/or other materials provided with the
-  distribution.
-
-  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
-  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE 
-  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
-  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
-  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
-  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
-  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
-  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
-  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
-  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
-  THE POSSIBILITY OF SUCH DAMAGE. 
-
-  *****************************#RMI_2#**********************************/
+/***********************************************************************
+Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#NETL_2#********************************/
 
 #include <linux/list.h>
 
diff --git a/include/linux/oprofile.h b/include/linux/oprofile.h
index c5e16b2..8a3342e 100644
--- a/include/linux/oprofile.h
+++ b/include/linux/oprofile.h
@@ -177,7 +177,7 @@ void oprofile_put_buff(unsigned long *buf, unsigned int start,
 unsigned long oprofile_get_cpu_buffer_size(void);
 void oprofile_cpu_buffer_inc_smpl_lost(void);
  
-void phoenix_oprofile_int_handler(int irq, void * dev_id, struct pt_regs *regs);
+void nlm_common_oprofile_int_handler(int irq, void * dev_id, struct pt_regs *regs);
 
 /* cpu buffer functions */
 
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index 1c1738c..d3fc483 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -1063,6 +1063,10 @@ int pskb_expand_head(struct sk_buff *skb, int nhead, int ntail,
 	int size = nhead + skb_end_offset(skb) + ntail;
 	long off;
 
+#if defined (CONFIG_NLM_XLP) && defined (CONFIG_64BIT)
+	gfp_mask |= GFP_DMA;
+#endif
+
 	BUG_ON(nhead < 0);
 
 	if (skb_shared(skb))
-- 
1.8.4.93.g57e4c17

