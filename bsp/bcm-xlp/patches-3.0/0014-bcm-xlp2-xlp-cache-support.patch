From 6d3caf2f9a46152c630172d53e62588898056a50 Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Wed, 12 Feb 2014 19:43:30 +0800
Subject: [PATCH 14/58] bcm-xlp2: xlp cache support

Based on SDK 3.0 (2013-10-29)

Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 arch/mips/mm/Makefile       |    2 +
 arch/mips/mm/c-netlogic.c   |  658 +++++++++++++++++++++++++++++++++++++++++++
 arch/mips/mm/cache.c        |    5 +
 arch/mips/mm/cex-netlogic.S |   51 ++++
 4 files changed, 716 insertions(+)

diff --git a/arch/mips/mm/Makefile b/arch/mips/mm/Makefile
index e87aae1..477e880 100644
--- a/arch/mips/mm/Makefile
+++ b/arch/mips/mm/Makefile
@@ -17,6 +17,8 @@ obj-$(CONFIG_CPU_R8000)		+= c-r4k.o cex-gen.o tlb-r8k.o
 obj-$(CONFIG_CPU_SB1)		+= c-r4k.o cerr-sb1.o cex-sb1.o tlb-r4k.o
 obj-$(CONFIG_CPU_TX39XX)	+= c-tx39.o tlb-r3k.o
 obj-$(CONFIG_CPU_CAVIUM_OCTEON) += c-octeon.o cex-oct.o tlb-r4k.o
+obj-$(CONFIG_CPU_XLR)		+= c-netlogic.o tlb-r4k.o cex-netlogic.o
+obj-$(CONFIG_CPU_XLP)		+= c-netlogic.o tlb-r4k.o cex-netlogic.o
 
 obj-$(CONFIG_IP22_CPU_SCACHE)	+= sc-ip22.o
 obj-$(CONFIG_R5000_CPU_SCACHE)	+= sc-r5k.o
diff --git a/arch/mips/mm/c-netlogic.c b/arch/mips/mm/c-netlogic.c
new file mode 100644
index 0000000..658cf4d
--- /dev/null
+++ b/arch/mips/mm/c-netlogic.c
@@ -0,0 +1,658 @@
+/*
+ * Copyright (C) 1996 David S. Miller (dm@engr.sgi.com)
+ * Copyright (C) 1997, 2001 Ralf Baechle (ralf@gnu.org)
+ * Copyright (C) 2011 Netlogic Microsystems.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
+ */
+#include <linux/init.h>
+#include <asm/asm.h>
+#include <asm/mmu_context.h>
+#include <asm/bootinfo.h>
+#include <asm/cacheops.h>
+#include <asm/cpu.h>
+#include <asm/page.h>
+#include <asm/uaccess.h>
+#include <asm/r4kcache.h>
+#include <asm/traps.h>
+
+#include <linux/bug.h>
+#include <linux/smp.h>
+#include <linux/kallsyms.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+
+#ifdef CONFIG_KVM
+#include <asm/netlogic/mips-extns.h>
+#include <asm/netlogic/haldefs.h>
+#include <asm/netlogic/common.h>
+#include <asm/netlogic/xlp-hal/iomap.h>
+#include <asm/netlogic/xlp-hal/xlp.h>
+#include <asm/netlogic/xlp-hal/sys.h>
+#include <asm/netlogic/xlp-hal/pic.h>
+#include <asm/netlogic/xlp-hal/pcibus.h>
+#include <asm/netlogic/xlp-hal/bridge.h>
+#endif
+
+#ifdef CONFIG_CPU_XLP
+#include <asm/netlogic/xlp-hal/xlp.h>
+#include <asm/netlogic/xlp-hal/cpucontrol.h>
+#endif
+
+#ifdef CONFIG_CPU_XLR
+static inline void sync_istream(void)
+{
+	__asm__ __volatile__ (
+		"	.set	push\n"
+		"	.set	noreorder\n"
+		"	nop;nop;nop;nop;nop\n"
+		"	nop;nop;nop;nop;nop\n"
+		"	.set	pop\n"
+	);
+}
+
+static inline void cacheop_hazard(void)
+{
+	__asm__ __volatile__ (
+		"	.set	push\n"
+		"	.set	noreorder\n"
+		"	nop;nop;nop;nop\n"
+		"	nop;nop;nop;nop\n"
+		"	.set	pop\n"
+	);
+}
+
+static inline void cacheop_sync_istream(void)
+{
+	cacheop_hazard();
+	sync_istream();
+}
+
+static inline void nlm_flush_l1_dcache(void)
+{
+	blast_dcache32();
+	cacheop_hazard();
+}
+
+#else /* !CONFIG_CPU_XLR */
+static inline void sync_istream(void)
+{
+	instruction_hazard();
+}
+
+static inline void cacheop_hazard(void)
+{
+	instruction_hazard();
+}
+
+static inline void cacheop_sync_istream(void)
+{
+	instruction_hazard();
+}
+
+#endif /* CONFIG_CPU_XLR */
+
+static inline void nlm_flush_l1_icache(void)
+{
+	blast_icache32();
+	cacheop_sync_istream();
+}
+
+static inline void nlm_flush_l1_icache_page(void *addr)
+{
+	blast_icache32();
+	cacheop_sync_istream();
+}
+
+#ifdef CONFIG_CPU_XLP
+/* XLP  errata E28_CPU */
+static inline void nlm_flush_l1_dcache_line(uint32_t line)
+{
+	__asm__ __volatile__ (
+		"       .set push\n"
+		"       .set noat\n"
+		"       .set noreorder\n"
+		"       li $8, "STR(LSU_DEBUG_DATA0)"\n"
+		"       mtcr $0, $8\n"
+		"       li $9, "STR(LSU_DEBUG_ADDR)"\n"
+		"       ori %0, %0, 0x1\n"
+		"       mtcr %0, $9\n"
+		"1:\n"
+		"       mfcr $8, $9\n"
+		"       andi $8, $8, 0x1\n"
+		"       bnez $8, 1b\n"
+		"       nop\n"
+		"       .set pop\n"
+		: : "r"(line) : "$8" , "$9");
+}
+
+static inline void nlm_flush_l1_dcache_hack(void)
+{
+	uint32_t index, line, max;
+	uint32_t cpu = read_c0_ebase() & 0x7f;
+	uint32_t thread = cpu & 0x3;
+
+	max = (thread + 1) * current_cpu_data.dcache.sets;
+	index = thread * current_cpu_data.dcache.sets;
+
+	for (; index < max; index++) {
+
+		line = (index << 5) | (1<<1);
+		nlm_flush_l1_dcache_line(line);
+		line = (1 << 2) | (index << 5) | (1<<1);
+		nlm_flush_l1_dcache_line(line);
+
+		line = (index << 5) | (1<<1) | (0x1 << 14);
+		nlm_flush_l1_dcache_line(line);
+		line = (1 << 2) | (index << 5) | (1<<1) | (0x1 << 14);
+		nlm_flush_l1_dcache_line(line);
+	}
+}
+
+static inline void nlm_flush_l1_dcache(void)
+{
+	if (cpu_is_xlpii())
+		blast_dcache32();
+	else
+		nlm_flush_l1_dcache_hack();
+
+	cacheop_hazard();
+}
+
+static inline void nlm_flush_l1_dcache_page(void *addr)
+{
+	if (cpu_is_xlpii())
+		blast_dcache32();
+	else
+		nlm_flush_l1_dcache_hack();
+
+	cacheop_hazard();
+}
+
+static inline void nlm_flush_l1_dcache_range(unsigned long vaddr, int size)
+{
+	if (cpu_is_xlpii())
+		blast_dcache32();
+	else
+		nlm_flush_l1_dcache_hack();
+
+	cacheop_hazard();
+}
+
+struct flush_cache_page_args {
+	struct vm_area_struct *vma;
+	unsigned long addr;
+	unsigned long pfn;
+};
+
+static inline int has_valid_asid(const struct mm_struct *mm)
+{
+	return cpu_context(smp_processor_id(), mm);
+}
+
+static void local_nlm_flush_cache_mm(void *args)
+{
+	struct mm_struct *mm = args;
+
+	if (!has_valid_asid(mm))
+		return;
+
+	nlm_flush_l1_dcache();
+}
+
+static void nlm_flush_cache_mm(struct mm_struct *mm)
+{
+	if (!cpu_has_dc_aliases)
+		return;
+
+	on_each_cpu(local_nlm_flush_cache_mm, mm, 1);
+}
+
+static inline void local_nlm_flush_cache_range(void *args)
+{
+	struct vm_area_struct *vma = args;
+	int exec = vma->vm_flags & VM_EXEC;
+
+	if (!(has_valid_asid(vma->vm_mm)))
+		return;
+
+	nlm_flush_l1_dcache();
+
+	if (exec)
+		nlm_flush_l1_icache();
+
+}
+
+static void nlm_flush_cache_range(struct vm_area_struct *vma,
+					unsigned long start, unsigned long end)
+{
+	int exec = vma->vm_flags & VM_EXEC;
+
+	if (cpu_has_dc_aliases || (exec && !cpu_has_ic_fills_f_dc))
+		on_each_cpu(local_nlm_flush_cache_range, vma, 1);
+}
+
+static inline void local_nlm_flush_cache_page(void *args)
+{
+	struct flush_cache_page_args *fcp_args = args;
+	unsigned long addr = fcp_args->addr;
+	struct vm_area_struct *vma = fcp_args->vma;
+	int exec = vma->vm_flags & VM_EXEC;
+	struct mm_struct *mm = vma->vm_mm;
+
+	if (!has_valid_asid(mm))
+		return;
+
+	addr &= PAGE_MASK;
+
+	nlm_flush_l1_dcache_page((void *)addr);
+
+	if (exec)
+		nlm_flush_l1_icache_page((void *)addr);
+}
+
+static void nlm_flush_cache_page(struct vm_area_struct *vma,
+				unsigned long addr, unsigned long pfn)
+{
+	struct flush_cache_page_args args;
+
+	args.vma = vma;
+	args.addr = addr;
+	args.pfn = pfn;
+
+	on_each_cpu(local_nlm_flush_cache_page, &args, 1);
+}
+
+static void local_nlm_flush_dcache_page(void *addr)
+{
+	nlm_flush_l1_dcache_page(addr);
+}
+
+static void nlm_flush_dcache_page(unsigned long addr)
+{
+	on_each_cpu(local_nlm_flush_dcache_page, (void *)addr, 1);
+}
+
+static void nlm_flush_cache_vmap(void)
+{
+
+	nlm_flush_l1_dcache();
+}
+
+static void nlm_flush_cache_vunmap(void)
+{
+	nlm_flush_l1_dcache();
+}
+
+struct flush_kernel_vmap_range_args {
+	unsigned long vaddr;
+	int     size;
+};
+
+static inline void local_nlm_flush_cache_vmap_range(void *args)
+{
+	struct flush_kernel_vmap_range_args *vmra = args;
+	unsigned long vaddr = vmra->vaddr;
+	int size = vmra->size;
+
+	nlm_flush_l1_dcache_range(vaddr, size);
+}
+
+static void nlm_flush_cache_vmap_range(unsigned long vaddr, int size)
+{
+	struct flush_kernel_vmap_range_args args;
+
+	args.vaddr = (unsigned long) vaddr;
+	args.size = size;
+
+	on_each_cpu(local_nlm_flush_cache_vmap_range, &args, 1);
+}
+#endif /* CONFIG_CPU_XLP */
+
+/*
+ * These routines support Generic Kernel cache flush requirements
+ */
+
+static void nlm_local_flush_icache_range(unsigned long start, unsigned long end)
+{
+	unsigned long addr;
+	int icache_linesz = cpu_icache_line_size();
+
+	start &= ~((unsigned long)(icache_linesz - 1));
+	for (addr = start; addr < end; addr += icache_linesz)
+		protected_flush_icache_line(addr);
+	cacheop_sync_istream();
+}
+
+struct flush_icache_range_args {
+	unsigned long start;
+	unsigned long end;
+};
+
+static void nlm_flush_icache_range_ipi(void *info)
+{
+	struct flush_icache_range_args *args = info;
+
+	nlm_local_flush_icache_range(args->start, args->end);
+}
+
+void nlm_flush_icache_range(unsigned long start, unsigned long end)
+{
+	struct flush_icache_range_args args;
+
+	args.start = start;
+	args.end = end;
+	on_each_cpu(nlm_flush_icache_range_ipi, &args, 1);
+}
+
+static void nlm_flush_cache_sigtramp_ipi(void *info)
+{
+	unsigned long addr = (unsigned long)info;
+
+	addr = addr & ~(cpu_icache_line_size() - 1);
+	protected_flush_icache_line(addr);
+	cacheop_sync_istream();
+}
+
+static void nlm_flush_cache_sigtramp(unsigned long addr)
+{
+	on_each_cpu(nlm_flush_cache_sigtramp_ipi, (void *)addr, 1);
+}
+
+static void nlm_flush_l1_caches_ipi(void *info)
+{
+	nlm_flush_l1_dcache();
+	nlm_flush_l1_icache();
+}
+
+static void nlm_flush_l1_caches(void)
+{
+	on_each_cpu(nlm_flush_l1_caches_ipi, (void *)NULL, 1);
+}
+
+static void nlm_noflush(void)
+{
+}
+
+static __cpuinit void probe_l1_cache(void)
+{
+	struct cpuinfo_mips *c = &current_cpu_data;
+	unsigned int config1 = read_c0_config1();
+	int lsize, icache_size, dcache_size;
+
+	lsize = (config1 >> 19) & 7;
+	if (lsize != 0)
+		c->icache.linesz = 2 << lsize;
+	else
+		c->icache.linesz = lsize;
+	c->icache.sets = 64 << ((config1 >> 22) & 7);
+	c->icache.ways = 1 + ((config1 >> 16) & 7);
+
+	icache_size = c->icache.sets *
+		c->icache.ways * c->icache.linesz;
+	c->icache.waybit = ffs(icache_size/c->icache.ways) - 1;
+	c->icache.waysize = icache_size / c->icache.ways;
+
+	c->dcache.flags = 0;
+
+	lsize = (config1 >> 10) & 7;
+	if (lsize != 0)
+		c->dcache.linesz = 2 << lsize;
+	else
+		c->dcache.linesz = lsize;
+	c->dcache.sets = 64 << ((config1 >> 13) & 7);
+	c->dcache.ways = 1 + ((config1 >> 7) & 7);
+
+	dcache_size = c->dcache.sets *
+		c->dcache.ways * c->dcache.linesz;
+	c->dcache.waybit = ffs(dcache_size/c->dcache.ways) - 1;
+	c->dcache.waysize = dcache_size / c->dcache.ways;
+
+#ifdef CONFIG_CPU_XLR
+	c->dcache.flags |= MIPS_CACHE_PINDEX;
+#else
+	if (c->dcache.waysize > PAGE_SIZE)
+		c->dcache.flags |= MIPS_CACHE_ALIASES;
+	if (c->icache.waysize > PAGE_SIZE)
+		c->icache.flags |= MIPS_CACHE_ALIASES;
+#endif
+
+	if (smp_processor_id() == 0) {
+		pr_info("Primary instruction cache %dkB, %d-way, linesize"
+			" %d bytes.\n", icache_size >> 10, c->icache.ways,
+			c->icache.linesz);
+		pr_info("Primary data cache %dkB %d-way, %s, %s, linesize %d bytes.\n",
+			dcache_size >> 10, c->dcache.ways,
+			(c->dcache.flags & MIPS_CACHE_PINDEX) ? "PIPT" : "VIPT",
+			(c->dcache.flags & MIPS_CACHE_ALIASES) ?
+			"cache aliases" : "no aliases",
+			c->dcache.linesz);
+	}
+}
+
+static void coherency_setup(void)
+{
+	int cca = 3;
+
+	_page_cachable_default = cca << _CACHE_SHIFT;
+	change_c0_config(CONF_CM_CMASK, cca);
+}
+
+static void __cpuinit cache_error_setup(void)
+{
+	extern char except_vec2_nlm;
+
+	set_uncached_handler(0x100, &except_vec2_nlm, 0x80);
+}
+
+void __cpuinit nlm_cache_init(void)
+{
+	/* update cpu_data */
+	probe_l1_cache();
+	if (smp_processor_id() != 0) {
+		nlm_flush_l1_icache();
+		coherency_setup();
+		return;
+	}
+
+	shm_align_mask = max_t(unsigned long,
+				current_cpu_data.dcache.waysize - 1,
+				PAGE_SIZE - 1);
+
+	/*
+	 * When does this function get called? Looks like MIPS has some syscalls
+	 * to flush the caches.
+	 */
+	__flush_cache_all = nlm_flush_l1_caches;
+
+	/* flush_icache_range: makes the range of addresses coherent w.r.t
+	 * I-cache and D-cache. This gets called after the instructions are
+	 * written to memory. All addresses are valid kernel or mapped
+	 * user-space virtual addresses
+	 */
+	flush_icache_range = nlm_flush_icache_range;
+
+	/* flush_cache_{mm, range, page}: make these memory locations, that
+	 * may have been written by a user process, coherent. These get called
+	 * when virtual->physical translation of a user address space is about
+	 * to be changed. These are closely related to TLB coherency
+	 * (flush_tlb_{mm, range, page})
+	 */
+#ifdef CONFIG_CPU_XLP
+	if (cpu_has_dc_aliases) {
+		flush_cache_mm = nlm_flush_cache_mm;
+		flush_cache_range = nlm_flush_cache_range;
+		flush_cache_page = nlm_flush_cache_page;
+
+		/*
+		 * flush_icache_page: flush_dcache_page + update_mmu_cache
+		 * takes care of this
+		 */
+		flush_data_cache_page = nlm_flush_dcache_page;
+
+		/* flush_cache_all: makes all kernel data coherent.
+		 * This gets called just before changing or removing
+		 * a mapping in the page-table-mapped kernel segment (kmap).
+		 * Physical Cache -> do nothing
+		 */
+		flush_cache_all = nlm_flush_l1_caches;
+
+		local_flush_data_cache_page	= local_nlm_flush_dcache_page;
+
+		__flush_cache_vmap = nlm_flush_cache_vmap;
+		__flush_cache_vunmap = nlm_flush_cache_vunmap;
+
+		__flush_kernel_vmap_range = nlm_flush_cache_vmap_range;
+	} else
+#endif
+	{
+		flush_cache_mm = (void (*)(struct mm_struct *))nlm_noflush;
+		flush_cache_range = (void *) nlm_noflush;
+		flush_cache_page = (void *) nlm_noflush;
+
+		/*
+		 * flush_icache_page: flush_dcache_page + update_mmu_cache
+		 * takes care of this
+		 */
+		flush_data_cache_page = (void *) nlm_noflush;
+
+		/* flush_cache_all: makes all kernel data coherent.
+		 * This gets called just before changing or removing
+		 * a mapping in the page-table-mapped kernel segment (kmap).
+		 * Physical Cache -> do nothing
+		 */
+		flush_cache_all = nlm_noflush;
+
+		local_flush_data_cache_page	= (void *)nlm_noflush;
+
+		__flush_cache_vmap = (void *)nlm_noflush;
+		__flush_cache_vunmap = (void *)nlm_noflush;
+
+		__flush_kernel_vmap_range = (void *)nlm_noflush;
+	}
+
+	/*
+	 * flush_cache_sigtramp: flush the single I-cache line with the proper
+	 * fixup code
+	 */
+	flush_cache_sigtramp = nlm_flush_cache_sigtramp;
+
+	/*
+	 * flush_icache_all: This should get called only for Virtuall Tagged
+	 * I-Caches
+	 */
+	flush_icache_all = (void *)nlm_noflush;
+
+	local_flush_icache_range = nlm_local_flush_icache_range;
+
+	/* memcpy((void *)(nlm_common_ebase + 0x100), &except_vec2_generic, 0x80); */
+
+	build_clear_page();
+	build_copy_page();
+
+	nlm_flush_l1_icache();
+	coherency_setup();
+	board_cache_error_setup = cache_error_setup;
+}
+
+#ifdef CONFIG_KVM
+
+static DEFINE_SPINLOCK(nlm_l3_lock);
+
+static void nlm_flush_l3(int node, unsigned long start, unsigned long size)
+{
+	unsigned long address, flags;
+	uint64_t bridge_base;
+	int nbu_disable;
+	struct nlm_soc_info *nodep;
+
+	nodep = nlm_get_node(node);
+
+#if 0
+	/* This is for emulator */
+	nbu_disable = 0xfe;
+#else
+	nbu_disable = nlm_read_sys_reg(nodep->sysbase, 0x26);
+#endif
+	bridge_base = nlm_get_bridge_regbase(node);
+
+	spin_lock_irqsave(&nlm_l3_lock, flags);
+	for (address = start; address < (start + size); address += 64) {
+		int i;
+
+		nlm_write_bridge_reg(bridge_base, 0xE9 - 0x40, address & 0xffffffff);
+		nlm_write_bridge_reg(bridge_base, 0xEA - 0x40, (address >> 32) | (0 << 31)); /* address */
+		for (i = 0; i < 8; i++) {
+			uint32_t val;
+
+			if (nbu_disable & (1 << i))
+				continue; /* nbu is disabled */
+
+			nlm_write_bridge_reg(bridge_base, 0x103 - 0x40, i);
+			nlm_write_bridge_reg(bridge_base, 0xEB - 0x40, 0x1);
+			do {
+				val = nlm_read_bridge_reg(bridge_base, 0xEB - 0x40);
+			} while (val != 0x3);
+		}
+	}
+	spin_unlock_irqrestore(&nlm_l3_lock, flags);
+}
+
+struct nlm_l2_flush_t {
+	unsigned long start;
+	unsigned long size;
+};
+
+static void local_nlm_flush_l2(void *args)
+{
+	struct nlm_l2_flush_t *flush;
+	unsigned long start, size, address;
+	unsigned long base = 0x9800000000000000ULL;
+
+	if ((hard_smp_processor_id() & 0x3) != 0)
+		return;
+
+	flush = (struct nlm_l2_flush_t *)args;
+	start = flush->start;
+	size  = flush->size;
+
+	for (address = start; address < (start + size); address += 64) {
+		cache_op(Hit_Writeback_Inv_SD, base + address);
+	}
+}
+
+/*
+ * For address "addr", poke the page table and find the physical address.
+ * Flush all the entries covered by that physical page.
+ */
+void nlm_flush_cache_L2L3 (unsigned long start_paddr, unsigned long size)
+{
+	struct nlm_l2_flush_t flush;
+	int n;
+
+	/* flush L2 */
+	flush.start = start_paddr;
+	flush.size  = size;
+	on_each_cpu(local_nlm_flush_l2, (void *)&flush, 1);
+
+	/* flush L3 */
+	for (n = 0; n < NLM_NR_NODES; n++) {
+		if (xlp9xx_get_socbus(n) == 0)
+			break;
+		nlm_flush_l3(n, start_paddr, size);
+	}
+}
+
+#endif
diff --git a/arch/mips/mm/cache.c b/arch/mips/mm/cache.c
index 5aeb3eb..2622741 100644
--- a/arch/mips/mm/cache.c
+++ b/arch/mips/mm/cache.c
@@ -215,6 +215,11 @@ void __cpuinit cpu_cache_init(void)
 
 		octeon_cache_init();
 	}
+	if (cpu_has_netlogic_cache) {
+		extern void __weak nlm_cache_init(void);
+
+		nlm_cache_init();
+	}
 
 	setup_protection_map();
 }
diff --git a/arch/mips/mm/cex-netlogic.S b/arch/mips/mm/cex-netlogic.S
new file mode 100644
index 0000000..2346964
--- /dev/null
+++ b/arch/mips/mm/cex-netlogic.S
@@ -0,0 +1,51 @@
+/*
+ * Copyright (c) 2013 Broadcom Corporation
+ *
+ * Based on cex-gen.S
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1995 - 1999 Ralf Baechle
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ *
+ * Cache error handler
+ */
+#include <asm/asm.h>
+#include <asm/regdef.h>
+#include <asm/mipsregs.h>
+#include <asm/stackframe.h>
+
+LEAF(except_vec2_nlm)
+	.set	noreorder
+	.set	noat
+	/*
+	 * If this is not a hardware problems but an address error from
+	 * the Bridge, which comes in as cache error, we need to dump
+	 * information
+	 */
+	j	nlm_handle_cache_err	/* this would remain in KSEG1 */	
+	nop
+END(except_vec2_nlm)
+
+LEAF(nlm_handle_cache_err)
+	.set    push
+        .set    noreorder
+        .set    noat
+
+	/* Try to leave a good crash dump before you die */
+	mfc0	k0, CP0_STATUS
+	li	k1, ST0_IE | ST0_ERL
+	or	k0, k1
+	xor	k0, k1
+	mtc0	k0, CP0_STATUS
+
+	SAVE_ALL
+	move	a0, sp
+	PTR_LA	a1, nlm_cache_error
+	jalr	a1
+	nop
+
+	.set pop
+END(nlm_handle_cache_err)
-- 
1.7.9.5

