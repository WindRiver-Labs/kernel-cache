From b351ae669911f5495a20a8f53b54fea2b3da3e67 Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Fri, 14 Feb 2014 17:59:46 +0800
Subject: [PATCH 40/58] bcm-xlp2: add the sae driver

Based on SDK 3.0 (2013-10-29)

Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 drivers/netlogic/sae/Makefile             |   17 +
 drivers/netlogic/sae/cryptosoc_lib.c      |    1 +
 drivers/netlogic/sae/cryptosoc_lib_ifc.h  |   81 ++
 drivers/netlogic/sae/cryptosoc_lib_priv.h |   51 +
 drivers/netlogic/sae/nlm_aead.c           | 2066 +++++++++++++++++++++++++++++
 drivers/netlogic/sae/nlm_async.h          |   82 ++
 drivers/netlogic/sae/nlm_auth.c           |  677 ++++++++++
 drivers/netlogic/sae/nlm_crypto.c         |  484 +++++++
 drivers/netlogic/sae/nlm_enc.c            |  504 +++++++
 9 files changed, 3963 insertions(+)

diff --git a/drivers/netlogic/sae/Makefile b/drivers/netlogic/sae/Makefile
new file mode 100644
index 0000000..4447a1a
--- /dev/null
+++ b/drivers/netlogic/sae/Makefile
@@ -0,0 +1,17 @@
+#-I$(SDK_ROOT)/linux-userspace/kmod/sae/
+EXTRA_CFLAGS := -DCONFIG_XLP_FMN_SUPPORT -DNLM_HAL_LINUX_KERNEL -Wno-maybe-uninitialized
+EXTRA_CFLAGS += -Wno-parentheses -Wno-uninitialized
+EXTRA_CFLAGS += -Iarch/mips/netlogic/lib/libfdt
+EXTRA_CFLAGS += -Iarch/mips/netlogic/lib/libfdt/contrib
+EXTRA_CFLAGS += -Iarch/mips/netlogic/lib/netlib/include
+EXTRA_CFLAGS += -Iarch/mips/netlogic/lib/fmnlib
+EXTRA_CFLAGS += -Iarch/mips/netlogic/lib/syslib/include
+EXTRA_CFLAGS += -Iarch/mips/netlogic/lib/seclib
+EXTRA_CFLAGS += -Idrivers/netlogic/sae
+
+obj-$(CONFIG_XLP_SAE) 	+= sae.o
+sae-objs	= cryptosoc_lib.o
+sae-objs 	+= nlm_enc.o
+sae-objs 	+= nlm_crypto.o 
+sae-objs        += nlm_auth.o 
+sae-objs        += nlm_aead.o
diff --git a/drivers/netlogic/sae/cryptosoc_lib.c b/drivers/netlogic/sae/cryptosoc_lib.c
new file mode 120000
index 0000000..ca7ad3a
--- /dev/null
+++ b/drivers/netlogic/sae/cryptosoc_lib.c
@@ -0,0 +1 @@
+../../../arch/mips/netlogic/lib/seclib/cryptosoc_lib.c
\ No newline at end of file
diff --git a/drivers/netlogic/sae/cryptosoc_lib_ifc.h b/drivers/netlogic/sae/cryptosoc_lib_ifc.h
new file mode 100644
index 0000000..90fc20e
--- /dev/null
+++ b/drivers/netlogic/sae/cryptosoc_lib_ifc.h
@@ -0,0 +1,81 @@
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_2# */
+
+#ifndef _SAESOC_LIB_IFC_H
+#define _SAESOC_LIB_IFC_H
+
+extern void *nlm_crypto_vbase;
+extern _uint64_t nlm_crypto_pbase;
+
+
+/* This app is going to support on all the processor varients */
+#define SAESOC_PTYPE_GEN_ALL_SUPPORT 1
+
+#ifndef SAESOC_PTYPE_GEN_ALL_SUPPORT
+/* Otherwise declare the specific ones here */
+#define SAESOC_PTYPE_GEN2_SUPPORT 1
+#define SAESOC_PTYPE_GEN1_SUPPORT 1
+#define RSASOC_PTYPE_GEN1_SUPPORT 1
+#endif
+
+/* Application specific private size for lib-params, 
+*  session & data descriptors */
+#define SAESOC_SESSION_DESC_APP_PRIV_SZ 64
+#define SAESOC_DATA_DESC_APP_PRIV_SZ	64
+#define RSASOC_REQ_DESC_APP_PRIV_SZ     64
+#define ECCSOC_REQ_DESC_APP_PRIV_SZ             64
+
+#define CRYPTOSOC_MAX_PENDING_REQS_PER_CTX 64
+#define CRYPTOSOC_CTX_APP_PRIV_SZ       64
+
+static inline _uint64_t cryptosoc_virt_to_phys(unsigned long vaddr) 
+{
+	return virt_to_phys((void *)vaddr);
+}
+
+
+static inline unsigned long cryptosoc_phys_to_virt(_uint64_t paddr) 
+{
+	return (unsigned long) phys_to_virt(paddr);
+}
+
+#ifdef NLM_LINUXU
+extern void *contig_mem_align(size_t align, size_t size);
+extern void *contig_mem_free(void *ptr);
+#define crypto_malign(align, size) contig_mem_align(align, size)
+#define crypto_mfree(p) contig_mem_free(p)
+#else
+extern void *contig_malign(size_t align, size_t size);
+extern void contig_free(void *ptr);
+#define crypto_malign(align, size) contig_malign(align, size)
+#define crypto_mfree(p) contig_free(p)
+#endif
+
+/* see crypto_app_lib_init() also */
+#endif
diff --git a/drivers/netlogic/sae/cryptosoc_lib_priv.h b/drivers/netlogic/sae/cryptosoc_lib_priv.h
new file mode 100644
index 0000000..b6828ae
--- /dev/null
+++ b/drivers/netlogic/sae/cryptosoc_lib_priv.h
@@ -0,0 +1,51 @@
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * http://www.gnu.org/licenses/gpl-2.0.txt  
+ * or the Broadcom license below:
+
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_4# */
+
+#ifndef _CRYPTOSOC_LIB_PRIV_H
+#define _CRYPTOSOC_LIB_PRIV_H
+
+static inline int crypto_ctxt_shrd_wait_for_response(int fd)
+{
+	return CRYPTOSOC_OK;
+}
+
+
+extern int crypto_ctxt_alloc(struct cryptosoc_ctx *ctx);
+extern int crypto_ctxt_free(struct cryptosoc_ctx *ctx);
+extern int crypto_get_soc_vc_numbers(enum cryptosoc_soc_type soc, int *basevc, int *lmtvc);
+extern int cryptosoc_lib_priv_init(void);
+extern int cryptosoc_lib_priv_finish(void);
+
+#endif
diff --git a/drivers/netlogic/sae/nlm_aead.c b/drivers/netlogic/sae/nlm_aead.c
new file mode 100644
index 0000000..8d65d59
--- /dev/null
+++ b/drivers/netlogic/sae/nlm_aead.c
@@ -0,0 +1,2066 @@
+/*-
+ * Copyright 2003-2012 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
+
+/* This software is available to you under the terms of the GNU General Public
+ * License (GPL) Version 2, available from the file 
+ * http://www.gnu.org/licenses/gpl-2.0.txt
+*/
+
+#include <linux/rtnetlink.h>
+#include <crypto/algapi.h>
+#include <crypto/aes.h>
+#include <crypto/des.h>
+#include <crypto/ctr.h>
+#include <crypto/sha.h>
+#include <crypto/aead.h>
+#include <crypto/authenc.h>
+#include <crypto/algapi.h>
+
+#include <nlm_hal_fmn.h>
+#include "saesoc_lib.h"
+#include "nlm_async.h"
+#include <nlm_xlp.h>
+#include <linux/module.h>
+#include <nlm_msgring.h>
+
+
+
+#undef NLM_CRYPTO_DEBUG
+#define Message(a, b...) //printk("[%s @ %d] "a"\n",__FUNCTION__,__LINE__, ##b)
+
+#define XLP_CRYPT_PRIORITY      310
+
+#define XCBC_DIGEST_SIZE        16
+#define MD5_DIGEST_SIZE         16
+#define MD5_BLOCK_SIZE          64
+
+#define GCM_RFC4106_IV_SIZE 8
+#define GCM_RFC4106_NONCE_SIZE 4
+#define GCM_RFC4106_DIGEST_SIZE 16
+
+#define CCM_RFC4309_NONCE_SIZE 3
+#define CCM_RFC4309_IV_SIZE 8
+#define CCM_RFC4309_DIGEST_SIZE 16
+
+/*
+ 						CTRL DESC MEMORY LAYOUT
+	 ------------------------------------------------------------------------------------
+	|  64 bytes	 | struct nlm_aead_ctx	  | 64bytes for   | struct nlm_aead_ctx     |
+	|  for alignment | 			  | for alignment | (used only for 3des)    |
+	 ------------------------------------------------------------------------------------
+*/
+
+struct nlm_aead_ctx
+{
+	struct saesoc_session_desc enc_s_desc;
+	unsigned long long key[20];
+	struct saesoc_session_desc dec_s_desc;
+	unsigned long long d_key[20];
+	struct saesoc_session_init_params initp;
+	uint8_t iv_buf[16];
+	uint32_t iv_len;
+	uint16_t stat;
+	struct crypto_aead  * fallback;
+};
+
+#define MAX_FRAGS		18	
+#define CTRL_DESC_SIZE		(sizeof(struct nlm_aead_ctx) + 128)
+#define DES3_CTRL_DESC_SIZE	(2*CTRL_DESC_SIZE + 2*64)	//Allocate 2 separate control desc for encryption and decryption
+#define CACHE_ALIGN		64
+#define IV_AEAD_PADDING         128 
+#define TAG_LEN			64
+
+#define PACKET_DESC_SIZE        (128 + sizeof(struct saesoc_data_desc) + (MAX_FRAGS*8) + sizeof(struct nlm_async_crypto) + TAG_LEN + IV_AEAD_PADDING + 128)
+#define NLM_CRYPTO_DATA_DESC(addr)  (struct saesoc_data_desc *) (((unsigned long)addr + 63) & ~0x3fUL)
+#define NLM_ASYNC_PTR_PARAM_OFFSET(addr)        (((unsigned long)addr +  sizeof(struct saesoc_data_desc) + (MAX_FRAGS*8) + 64 + 63) & ~0x3fUL)
+#define NLM_HASH_OFFSET(addr)			((unsigned long)addr + (PACKET_DESC_SIZE - TAG_LEN))
+#define NLM_IV_OFFSET(addr)			((unsigned long)addr + (PACKET_DESC_SIZE - TAG_LEN - IV_AEAD_PADDING ))
+
+
+#define XLP_CRYPT_PRIORITY	310
+
+#define NETL_OP_ENCRYPT 1
+#define NETL_OP_DECRYPT 0
+
+#define PKT_DESC_OFF 64
+
+extern struct nlm_crypto_stat crypto_stat[MAX_CPU];
+
+
+/*
+   All extern declaration goes here.
+ */
+
+static int no_of_alg_registered = 0;
+
+#ifdef NLM_CRYPTO_DEBUG
+static void print_buf(unsigned char *msg, unsigned char *buf, int len)
+{
+#define TMP_BUF		50
+	char tmp_buf[TMP_BUF + 1];
+	int i, index = 0;
+
+	printk("**********%s************\n",msg);
+	for(i=0; i<len; i++){
+		sprintf(&tmp_buf[index*2], "%02x", buf[i]);
+		index++;
+		if(index == (TMP_BUF/2)){
+			tmp_buf[index*2] = '\0';
+			printk("[%s]\n",tmp_buf);
+			index = 0;
+		}
+	}
+	if(index){
+		tmp_buf[index*2] = '\0';
+		printk("[%s]\n",tmp_buf);
+	}
+}
+#endif
+static struct nlm_aead_ctx *nlm_crypto_aead_ctx(struct crypto_aead *tfm)
+{
+
+	return (struct nlm_aead_ctx *)(((unsigned long)((uint8_t *)crypto_aead_ctx(tfm) + 64)) & ~(0x3fUL));
+}
+
+static struct nlm_aead_ctx *nlm_crypto_tfm_ctx(struct crypto_tfm *tfm)
+{
+	return (struct nlm_aead_ctx *)(((unsigned long)((uint8_t *)crypto_tfm_ctx(tfm) + 64)) & ~(0x3fUL));
+}
+
+
+
+static int aead_setauthsize(struct crypto_aead *tfm, unsigned int authsize)
+{
+	struct aead_tfm *crt = crypto_aead_crt(tfm);
+	crt->authsize = authsize;
+	return 0;
+}
+
+static void aead_session_cleanup(struct crypto_tfm *tfm)
+{
+}
+static int aead_cra_cbc_init(struct crypto_tfm *tfm)
+{
+	tfm->crt_aead.reqsize = PACKET_DESC_SIZE; 
+	return 0;
+}
+
+static int aead_cra_init_ccm(struct crypto_tfm *tfm)
+{
+	struct nlm_aead_ctx *nlm_ctx = (struct nlm_aead_ctx *)nlm_crypto_tfm_ctx(tfm);
+	tfm->crt_aead.reqsize = PACKET_DESC_SIZE; 
+	nlm_ctx->fallback = crypto_alloc_aead("rfc4309(ccm(aes-generic))",CRYPTO_ALG_TYPE_AEAD ,0) ;
+	return 0;
+}
+static int aead_cra_init_gcm(struct crypto_tfm *tfm)
+{
+	struct nlm_aead_ctx *nlm_ctx = (struct nlm_aead_ctx *)nlm_crypto_tfm_ctx(tfm);
+	tfm->crt_aead.reqsize = PACKET_DESC_SIZE; 
+	nlm_ctx->fallback = crypto_alloc_aead("rfc4106(gcm(aes-generic))",CRYPTO_ALG_TYPE_AEAD ,0) ;
+	return 0;
+}
+static int aead_cra_init(struct crypto_tfm *tfm)
+{
+	tfm->crt_aead.reqsize = PACKET_DESC_SIZE; 
+	return 0;
+}
+static int get_cipher_auth_keylen(const u8 *key, unsigned int keylen, int *cipher_keylen,
+			     int *auth_keylen)
+{
+	struct rtattr *rta = (struct rtattr *) key;
+	struct crypto_authenc_key_param *param;
+
+	if (!RTA_OK(rta, keylen)) {
+		goto badkey;
+	}
+
+	if (rta->rta_type != CRYPTO_AUTHENC_KEYA_PARAM) {
+		goto badkey;
+	}
+	if (RTA_PAYLOAD(rta) < sizeof (struct crypto_authenc_key_param)) {
+		goto badkey;
+	}
+
+	param = RTA_DATA(rta);
+	*cipher_keylen = be32_to_cpu(param->enckeylen);
+
+	key += RTA_ALIGN(rta->rta_len);
+	keylen -= RTA_ALIGN(rta->rta_len);
+
+	if (keylen < *cipher_keylen)
+		goto badkey;
+
+	*auth_keylen = keylen - *cipher_keylen;
+
+	return 0;
+badkey:
+	return -EINVAL;
+}
+
+static int get_cipher_aes_algid(unsigned int cipher_keylen)
+{
+
+	switch (cipher_keylen) {
+	case 16:
+		return SAESOC_CIPHER_TYPE_AES_128;
+		break;
+	case 24:
+		return SAESOC_CIPHER_TYPE_AES_192;
+		break;
+	case 32:
+		return SAESOC_CIPHER_TYPE_AES_256;
+		break;
+	default:
+		printk(KERN_WARNING "[%s]: Cannot handle keylen = %d\n",
+		       __FUNCTION__, cipher_keylen);
+		return -EINVAL;
+	}
+}
+
+
+static int get_auth_aes_algid(unsigned int hash_keylen)
+{
+
+	switch (hash_keylen) {
+	case 16:
+		return SAESOC_HASH_TYPE_AES_128;
+		break;
+	case 24:
+		return SAESOC_HASH_TYPE_AES_192;
+		break;
+	case 32:
+		return SAESOC_HASH_TYPE_AES_256;
+		break;
+	default:
+		printk(KERN_WARNING "[%s]: Cannot handle keylen = %d\n",
+		       __FUNCTION__, hash_keylen);
+	    return -EINVAL;
+	}
+}
+/*
+   All Setkey goes here.
+ */
+
+static int xlp_aes_cbc_setkey( struct crypto_aead *tfm, uint8_t *key, unsigned int keylen,
+				int hash_type, int hash_mode,uint16_t h_stat , int expected_keylen)
+{ 
+	struct nlm_aead_ctx *ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	struct saesoc_session_init_params *initp = &ctx->initp;
+	unsigned int cipher_keylen=0, auth_keylen=0;
+	int ret;
+	int cipher_alg;
+	uint8_t auth_key[128];
+	uint8_t *cipher_key;
+	struct rtattr *rta = (struct rtattr *)key;
+	int nsdescs ;
+	struct saesoc_session_desc *s_desc ;
+
+	if ((ret = get_cipher_auth_keylen(key, keylen, &cipher_keylen,
+					  &auth_keylen)) < 0) {
+		crypto_aead_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+		printk("ERR: Bad key len\n");
+		return ret;
+	}
+
+	cipher_alg = get_cipher_aes_algid(cipher_keylen);
+	ctx->stat = cipher_alg - 1;
+	ctx->stat = ctx->stat | (h_stat << 8);
+	if (cipher_alg < 0) {
+		crypto_aead_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+		printk("ERR: Bad aes key len\n");
+		return -EINVAL;
+	}
+
+	key += RTA_ALIGN(rta->rta_len);
+	cipher_key = key + auth_keylen;
+	memcpy(auth_key, key, auth_keylen);
+	if(expected_keylen > auth_keylen)
+		memset(auth_key + auth_keylen, 0,  expected_keylen - auth_keylen);
+
+	ctx->iv_len = 16;
+
+	auth_keylen = expected_keylen;
+
+
+	/* assoc | iv | payload 
+	  |----auth offset
+	         |------iv offset
+		      |--->cipher offset 
+		      */
+
+	initp->cipher.type = cipher_alg;
+        initp->cipher.mode = SAESOC_CIPHER_MODE_CBC;	
+	initp->cipher.iv_offset = 8;
+	initp->cipher.iv_mode = 0;
+	initp->cipher.key = (char *)cipher_key;
+	initp->cipher.key_len = cipher_keylen;
+	initp->cipher.cfb_mask = 0;
+	initp->cipher.flags = SAESOC_CF_ENCRYPT;
+	initp->hash.type = hash_type;
+	initp->hash.mode = hash_mode;
+	initp->hash.iv_offset = 0;
+	initp->hash.key = auth_key;
+	initp->hash.key_len = auth_keylen;
+	initp->hash.mute_mask_sel = 0;
+	initp->hash.tag_len = saesoc_gen1_tag_len[hash_type] / 8;
+	initp->hash.tagin_offset = 0;
+	initp->hash.aad_offset = 0;
+	initp->hash.addl_hash_len = 0; /* iv len */ 
+	//initp->hash.add_len = 24; /* iv len */ 
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC | SAESOC_HF_HASHINP_IS_CIPHEROUT;
+	if (initp->hash.mode == SAESOC_HASH_MODE_HMAC)
+		initp->hash.flags |= SAESOC_HF_HMAC_KEY_PAD_EN;
+	initp->payload_offset = 8 + 16 ; /* assoc len + ivlen */
+	initp->flags = SAESOC_IF_DATA_OUT_L3_ALLOC;
+
+	nsdescs = saesoc_calc_sdesc_cnt(&ctx->initp,NULL);
+	s_desc = &ctx->enc_s_desc;
+
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+	initp->cipher.flags = 0;
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC; 
+	if (initp->hash.mode == SAESOC_HASH_MODE_HMAC)
+		initp->hash.flags |= SAESOC_HF_HMAC_KEY_PAD_EN;
+
+	s_desc = &ctx->dec_s_desc;
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+	return ret;
+}
+
+static int  xlp_3des_setkey(struct crypto_aead *tfm, u8 *key, unsigned int keylen, int hash_type, int hash_mode,uint16_t h_stat, int expected_keylen )
+{
+	struct nlm_aead_ctx *ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	struct saesoc_session_init_params *initp = &ctx->initp;
+        unsigned int cipher_keylen=0, auth_keylen=0;
+        int ret;
+	uint8_t auth_key[128];
+	struct rtattr *rta = (struct rtattr *)key;
+	uint8_t *cipher_key;
+	int nsdescs ;
+	struct saesoc_session_desc *s_desc ;
+
+        if ((ret = get_cipher_auth_keylen(key, keylen, &cipher_keylen,
+                                          &auth_keylen)) < 0) {
+                crypto_aead_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+                printk("ERR: Bad key len\n");
+                return ret;
+        }
+	ctx->stat = TDES_CBC_STAT | h_stat << 8;;
+	key += RTA_ALIGN(rta->rta_len);
+	memcpy(auth_key, key, auth_keylen);
+	cipher_key = key + auth_keylen;
+	if ( expected_keylen > auth_keylen)
+		memset(auth_key + auth_keylen, 0,   expected_keylen -  auth_keylen);
+	
+	ctx->iv_len = 8;
+	auth_keylen = expected_keylen;
+
+
+	/* assoc | iv | payload 
+	  |----auth offset
+	         |------iv offset
+		      |--->cipher offset 
+		      */
+
+	initp->cipher.type = SAESOC_CIPHER_TYPE_TDES;
+        initp->cipher.mode = SAESOC_CIPHER_MODE_CBC;	
+	initp->cipher.iv_offset = 8;
+	initp->cipher.iv_mode = 0;
+	initp->cipher.key = (char *)cipher_key;
+	initp->cipher.key_len = cipher_keylen;
+	initp->cipher.cfb_mask = 0;
+	initp->cipher.flags = SAESOC_CF_ENCRYPT;
+	initp->hash.type = hash_type;
+	initp->hash.mode = hash_mode;
+	initp->hash.iv_offset = 0;
+	initp->hash.key = auth_key;
+	initp->hash.key_len = auth_keylen;
+	initp->hash.mute_mask_sel = 0;
+	initp->hash.tag_len = saesoc_gen1_tag_len[hash_type] / 8;
+	initp->hash.tagin_offset = 0;
+	initp->hash.aad_offset = 0;
+	initp->hash.addl_hash_len = 0; /* iv len */ 
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC | SAESOC_HF_HASHINP_IS_CIPHEROUT;
+	if (initp->hash.mode == SAESOC_HASH_MODE_HMAC)
+		initp->hash.flags |= SAESOC_HF_HMAC_KEY_PAD_EN;
+	initp->payload_offset = 8 + 8 ; /* assoc len + ivlen */
+	initp->flags = SAESOC_IF_DATA_OUT_L3_ALLOC;
+
+	nsdescs = saesoc_calc_sdesc_cnt(&ctx->initp,NULL);
+	s_desc = &ctx->enc_s_desc;
+
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+	initp->cipher.flags = 0;
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC; 
+	if (initp->hash.mode == SAESOC_HASH_MODE_HMAC)
+		initp->hash.flags |= SAESOC_HF_HMAC_KEY_PAD_EN;
+
+	s_desc = &ctx->dec_s_desc;
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+
+        return ret;
+}
+static int xlp_des_setkey( struct crypto_aead *tfm, uint8_t  *key, unsigned int keylen, int hash_type, int hash_mode, uint16_t h_stat, int expected_keylen)
+{
+	struct nlm_aead_ctx *ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	struct saesoc_session_init_params *initp = &ctx->initp;
+        unsigned int cipher_keylen=0, auth_keylen=0;
+        int ret;
+	uint8_t auth_key[128];
+	struct rtattr *rta = (struct rtattr *)key;
+	uint8_t *cipher_key;
+	int nsdescs ;
+	struct saesoc_session_desc *s_desc ;
+	ctx->stat = DES_CBC_STAT | h_stat << 8;
+	
+
+        if ((ret = get_cipher_auth_keylen(key, keylen, &cipher_keylen,
+                                          &auth_keylen)) < 0) {
+                crypto_aead_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+                printk("ERR: Bad key len\n");
+                return ret;
+        }
+	key += RTA_ALIGN(rta->rta_len);
+	memcpy(auth_key, key, auth_keylen);
+	cipher_key = key + auth_keylen;
+	if ( expected_keylen > auth_keylen)
+		memset(auth_key + auth_keylen, 0,  expected_keylen - auth_keylen);
+	
+	ctx->iv_len = 8;
+
+	auth_keylen = expected_keylen;
+
+	/* assoc | iv | payload 
+	  |----auth offset
+	         |------iv offset
+		      |--->cipher offset 
+		      */
+
+	initp->cipher.type = SAESOC_CIPHER_TYPE_DES;
+        initp->cipher.mode = SAESOC_CIPHER_MODE_CBC;	
+	initp->cipher.iv_offset = 8;
+	initp->cipher.iv_mode = 0;
+	initp->cipher.key = (char *)cipher_key;
+	initp->cipher.key_len = cipher_keylen;
+	initp->cipher.cfb_mask = 0;
+	initp->cipher.flags = SAESOC_CF_ENCRYPT;
+	initp->hash.type = hash_type;
+	initp->hash.mode = hash_mode;
+	initp->hash.iv_offset = 0;
+	initp->hash.key = auth_key;
+	initp->hash.key_len = auth_keylen;
+	initp->hash.mute_mask_sel = 0;
+	initp->hash.tag_len = saesoc_gen1_tag_len[hash_type] / 8;
+	initp->hash.tagin_offset = 0;
+	initp->hash.aad_offset = 0;
+	initp->hash.addl_hash_len = 0; /* iv len */ 
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC | SAESOC_HF_HASHINP_IS_CIPHEROUT;
+	if (initp->hash.mode == SAESOC_HASH_MODE_HMAC)
+		initp->hash.flags |= SAESOC_HF_HMAC_KEY_PAD_EN;
+	initp->payload_offset = 8 + 8 ; /* assoc len + ivlen */
+	initp->flags = SAESOC_IF_DATA_OUT_L3_ALLOC;
+
+	nsdescs = saesoc_calc_sdesc_cnt(&ctx->initp,NULL);
+	s_desc = &ctx->enc_s_desc;
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+	initp->cipher.flags = 0;
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC; 
+	if (initp->hash.mode == SAESOC_HASH_MODE_HMAC)
+		initp->hash.flags |= SAESOC_HF_HMAC_KEY_PAD_EN;
+
+	s_desc = &ctx->dec_s_desc;
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+        return ret;
+
+
+}
+extern struct cryptosoc_lib_params lparam;
+static int aead_gcm_rfc4106_setkey( struct crypto_aead *tfm, const u8 *key,
+						unsigned int keylen)
+{
+	struct nlm_aead_ctx *ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	struct saesoc_session_init_params *initp = &ctx->initp;
+	int cipher_alg;
+	unsigned int cipher_keylen=0;
+	int auth_alg;
+	int ret = 0;
+	struct saesoc_session_desc *s_desc = &ctx->enc_s_desc;
+	int assoc_len = 8;
+	int nsdescs ;
+
+	if (keylen < GCM_RFC4106_NONCE_SIZE)
+                return -EINVAL;
+	cipher_keylen = keylen - GCM_RFC4106_NONCE_SIZE;
+	cipher_alg = get_cipher_aes_algid(cipher_keylen);
+	ctx->stat = cipher_alg - 1;
+	ctx->stat = ctx->stat | (GCM_STAT << 8);
+
+	if (cipher_alg < 0) {
+		crypto_aead_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+		//sandip: check return val
+		printk("ERR: Bad aes key len\n");
+		return -EINVAL;
+	}
+	auth_alg = get_auth_aes_algid(cipher_keylen);
+	if ( auth_alg < 0) {
+		crypto_aead_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+		printk("ERR: Bad aes key len\n");
+		return -EINVAL;
+	}
+	ctx->iv_len = 8;
+	/*iv | assoc| payload 
+             |------> auth offset
+                    |---->cipher_off */
+	initp->cipher.type = cipher_alg;
+        initp->cipher.mode = SAESOC_CIPHER_MODE_GCM;	
+	initp->cipher.iv_offset = 0;
+	initp->cipher.iv_mode = 0;
+	initp->cipher.key = (char *)key;
+	initp->cipher.key_len = keylen;
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2)
+		initp->cipher.key_len = cipher_keylen;
+	initp->cipher.cfb_mask = 0;
+	initp->cipher.flags = SAESOC_CF_ENCRYPT;
+	initp->hash.type = auth_alg;
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2)
+		initp->hash.type = SAESOC_HASH_TYPE_GHASH;
+	initp->hash.mode = SAESOC_HASH_MODE_GCM;
+	initp->hash.iv_offset = 0;
+	initp->hash.key = (char *)key;
+	initp->hash.key_len = keylen;
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2)
+		initp->hash.key_len = cipher_keylen;
+	initp->hash.mute_mask_sel = 0;
+	initp->hash.tag_len = 128 / 8;
+	initp->hash.tagin_offset = 0;
+	initp->hash.aad_offset = 16; /* auth offset */
+	/* req->assoclen */
+	initp->hash.addl_hash_len = 0;
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC;
+	initp->payload_offset = 16 + assoc_len;
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2)
+		initp->payload_offset = 16 + 16;
+	initp->flags = SAESOC_IF_DATA_OUT_L3_ALLOC;
+
+	nsdescs = saesoc_calc_sdesc_cnt(&ctx->initp,NULL);
+	s_desc = &ctx->enc_s_desc;
+
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2) {
+		initp->hash.flags |= SAESOC_HF_TAGOUT_EOP |
+			SAESOC_HF_HASHINP_IS_CIPHEROUT;
+	}
+
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+	initp->cipher.flags = 0;
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC | SAESOC_HF_HASHINP_IS_CIPHEROUT;
+
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2)
+		initp->hash.flags = SAESOC_HF_TAGOUT_EOP | SAESOC_HF_HASH_L3_ALLOC;
+
+	s_desc = &ctx->dec_s_desc;
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+	
+	/*copy by nonce*/
+	memcpy(ctx->iv_buf, key + cipher_keylen, GCM_RFC4106_NONCE_SIZE);
+	crypto_aead_setkey(ctx->fallback, key, keylen);
+
+	return ret ;
+
+}
+static int aead_ccm_rfc4309_setkey(struct crypto_aead *tfm, const u8 *key, 
+				   unsigned int keylen)
+{
+	struct nlm_aead_ctx *ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	struct saesoc_session_init_params *initp = &ctx->initp;
+	unsigned int cipher_keylen=0;
+	int nonce_len = CCM_RFC4309_NONCE_SIZE;
+	int cipher_alg;
+	int auth_alg;
+	struct saesoc_session_desc *s_desc = &ctx->enc_s_desc;
+	int nsdescs ;
+	if (keylen < CCM_RFC4309_NONCE_SIZE)
+                return -EINVAL;
+
+	cipher_keylen = keylen - nonce_len;
+	cipher_alg = get_cipher_aes_algid(cipher_keylen);
+	if (cipher_alg < 0) {
+		crypto_aead_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+		printk("ERR: Bad aes key len\n");
+		return -EINVAL;
+	}
+	ctx->stat = cipher_alg - 1;
+	ctx->stat = ctx->stat | (CCM_STAT << 8);
+
+	auth_alg = get_auth_aes_algid(cipher_keylen);
+	if ( auth_alg < 0) {
+		crypto_aead_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+		printk("ERR: Bad aes key len\n");
+		return -EINVAL;
+	}
+	
+	ctx->iv_len = 8;
+
+	/* | en_iv| auth_iv |[2byte for assoc len storage] | assoc [blcok aligned with zero | 
+	   | ---iv offset
+                  |----auth offset
+		                                                                             |----cipher offset
+		  */
+	initp->cipher.type = cipher_alg;
+        initp->cipher.mode = SAESOC_CIPHER_MODE_CCM;	
+	initp->cipher.iv_offset = 0;
+	initp->cipher.iv_mode = 0;
+	initp->cipher.key = (char *)key;
+	initp->cipher.key_len = cipher_keylen;
+	initp->cipher.cfb_mask = 0;
+	initp->cipher.flags = SAESOC_CF_ENCRYPT;
+	initp->hash.type = auth_alg;
+	initp->hash.mode = SAESOC_HASH_MODE_CCM;
+	initp->hash.iv_offset = 16;
+	initp->hash.key = (char *)key;
+	initp->hash.key_len = cipher_keylen;
+	initp->hash.mute_mask_sel = 0;
+	initp->hash.tag_len = 128 / 8;
+	initp->hash.tagin_offset = 0;
+	initp->hash.addl_hash_len = 0; 
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC;
+	initp->payload_offset = 16 + 16 + 16; /* env IV, auth IV, 2 extra for assoc len storage + assoc + zero*/
+	initp->flags = SAESOC_IF_DATA_OUT_L3_ALLOC;
+	
+	initp->hash.aad_offset = 16; /* auth offset */
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2) {
+		initp->hash.flags |= SAESOC_HF_TAGOUT_EOP;
+		initp->hash.aad_offset = 34; /* auth offset */
+	}
+
+	nsdescs = saesoc_calc_sdesc_cnt(&ctx->initp,NULL);
+	s_desc = &ctx->enc_s_desc;
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+	initp->cipher.flags = 0;
+
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC;
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2)
+		initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC | SAESOC_HF_HASHINP_IS_CIPHEROUT;
+
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2)
+		initp->hash.flags |= SAESOC_HF_TAGOUT_EOP;
+
+	s_desc = &ctx->dec_s_desc;
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+	/*copy by nonce*/
+	memcpy(ctx->iv_buf, key + cipher_keylen, nonce_len);
+	crypto_aead_setkey(ctx->fallback, key, keylen);
+	return 0;
+}
+
+
+static int xlp_aes_ctr_setkey( struct crypto_aead *tfm, u8 *key,
+					unsigned int keylen, int hash_type, int hash_mode, uint16_t h_stat, int expected_keylen)
+{
+	struct nlm_aead_ctx *ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	struct saesoc_session_init_params *initp = &ctx->initp;
+	unsigned int cipher_keylen=0, auth_keylen=0;
+	int ret;
+	int nonce_len = CTR_RFC3686_NONCE_SIZE;
+	int cipher_alg;
+	uint8_t auth_key[128];
+	uint8_t *cipher_key;
+	struct rtattr *rta = (struct rtattr *)key;
+	int nsdescs ;
+	struct saesoc_session_desc *s_desc ;
+
+	if ((ret = get_cipher_auth_keylen(key, keylen, &cipher_keylen,
+					  &auth_keylen)) < 0) {
+		crypto_aead_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+		printk("ERR: Bad key len\n");
+		return ret;
+	}
+
+	cipher_keylen -= nonce_len;
+
+	cipher_alg = get_cipher_aes_algid(cipher_keylen);
+	if (cipher_alg < 0) {
+		crypto_aead_set_flags(tfm, CRYPTO_TFM_RES_BAD_KEY_LEN);
+		//sandip: check return val
+		printk("ERR: Bad aes key len\n");
+		return -EINVAL;
+	}
+	ctx->stat = cipher_alg - 1 + 3;
+	ctx->stat = ctx->stat | (h_stat << 8);
+	key += RTA_ALIGN(rta->rta_len);
+	memcpy(auth_key, key, auth_keylen);
+	cipher_key = key + auth_keylen;
+	memcpy(ctx->iv_buf,key+auth_keylen+cipher_keylen, nonce_len);
+
+	if ( expected_keylen > auth_keylen)
+		memset(auth_key + auth_keylen, 0,  expected_keylen - auth_keylen);
+	ctx->iv_len = 8;
+
+	auth_keylen = expected_keylen;
+
+	/* iv | assoc | iv[nonce ... 12][means 8]| payload 
+	   |----->iv offset
+	      |----auth offset
+	                                         |--> cipher offset */ 
+
+	initp->cipher.type = cipher_alg;
+        initp->cipher.mode = SAESOC_CIPHER_MODE_CTR;	
+	initp->cipher.iv_offset = 0;
+	initp->cipher.iv_mode = 0;
+	initp->cipher.key = (char *)cipher_key;
+	initp->cipher.key_len = cipher_keylen;
+	initp->cipher.cfb_mask = 0;
+	initp->cipher.flags = SAESOC_CF_ENCRYPT;
+	initp->hash.type = hash_type;
+	initp->hash.mode = hash_mode;
+	initp->hash.iv_offset = 0;
+	initp->hash.key = auth_key;
+	initp->hash.key_len = auth_keylen;
+	initp->hash.mute_mask_sel = 0;
+	initp->hash.tag_len = saesoc_gen1_tag_len[hash_type] / 8;
+	initp->hash.tagin_offset = 0;
+	initp->hash.aad_offset = CTR_RFC3686_BLOCK_SIZE;
+	//initp->hash.addl_hash_len =  CTR_RFC3686_IV_SIZE; /* iv len */ 
+	initp->hash.addl_hash_len =  0; /* iv len */ 
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC | SAESOC_HF_HASHINP_IS_CIPHEROUT;
+	if (initp->hash.mode == SAESOC_HASH_MODE_HMAC)
+		initp->hash.flags |= SAESOC_HF_HMAC_KEY_PAD_EN;
+	initp->payload_offset = CTR_RFC3686_BLOCK_SIZE + 8 + CTR_RFC3686_IV_SIZE;  
+	initp->flags = SAESOC_IF_DATA_OUT_L3_ALLOC;
+
+	nsdescs = saesoc_calc_sdesc_cnt(&ctx->initp,NULL);
+	s_desc = &ctx->enc_s_desc;
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+	initp->cipher.flags = 0;
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC;
+	if (initp->hash.mode == SAESOC_HASH_MODE_HMAC)
+		initp->hash.flags |= SAESOC_HF_HMAC_KEY_PAD_EN;
+
+	s_desc = &ctx->dec_s_desc;
+
+	if(saesoc_new_session(&ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+
+
+	return ret;
+}
+static int xlp_aes_cbc_hmac_sha256_setkey( struct crypto_aead *tfm, const u8 *key, unsigned int keylen)
+{
+	return xlp_aes_cbc_setkey(tfm, (uint8_t *)key, keylen,SAESOC_HASH_TYPE_SHA_256, SAESOC_HASH_MODE_HMAC ,H_SHA256_STAT,64);
+
+}
+
+static int xlp_aes_cbc_hmac_sha1_setkey(struct crypto_aead *tfm, const u8 *key, unsigned int keylen)
+{
+	return xlp_aes_cbc_setkey(tfm, (uint8_t *)key, keylen,SAESOC_HASH_TYPE_SHA_1, SAESOC_HASH_MODE_HMAC,H_SHA1_STAT,64);
+}
+
+static int xlp_aes_cbc_aes_xcbc_mac_setkey(struct crypto_aead *tfm, const u8 *key, unsigned int keylen)
+{
+	return xlp_aes_cbc_setkey(tfm, (uint8_t *)key, keylen,SAESOC_HASH_TYPE_AES_128,SAESOC_HASH_MODE_XCBC,AES128_XCBC_STAT,16);
+}
+
+static int xlp_aes_cbc_hmac_md5_setkey(struct crypto_aead *tfm, const u8 *key, unsigned int keylen)
+{
+	return xlp_aes_cbc_setkey(tfm, (uint8_t *)key, keylen,SAESOC_HASH_TYPE_MD5, SAESOC_HASH_MODE_HMAC ,MD5_STAT,64);
+}
+
+static int xlp_3des_cbc_hmac_sha256_setkey(struct crypto_aead *tfm, const u8 *key,
+                                        unsigned int keylen)
+{
+	return xlp_3des_setkey(tfm,(uint8_t *)key,keylen,SAESOC_HASH_TYPE_SHA_256, SAESOC_HASH_MODE_HMAC ,H_SHA256_STAT,64);
+        
+}
+static int xlp_3des_cbc_hmac_sha1_setkey(struct crypto_aead *tfm, const u8 *key,
+                                        unsigned int keylen)
+{
+	return xlp_3des_setkey(tfm,(uint8_t *)key,keylen,SAESOC_HASH_TYPE_SHA_1, SAESOC_HASH_MODE_HMAC,H_SHA1_STAT,64);
+}
+static int xlp_3des_cbc_aes_xcbc_mac_setkey(struct crypto_aead *tfm, const u8 *key,
+                                        unsigned int keylen)
+{
+	return xlp_3des_setkey(tfm,(uint8_t *)key,keylen,SAESOC_HASH_TYPE_AES_128,SAESOC_HASH_MODE_XCBC,AES128_XCBC_STAT,16);
+}
+
+static int xlp_3des_cbc_hmac_md5_setkey(struct crypto_aead *tfm, const u8 *key,
+                                        unsigned int keylen)
+{
+	return xlp_3des_setkey(tfm,(uint8_t *)key,keylen,SAESOC_HASH_TYPE_MD5, SAESOC_HASH_MODE_HMAC,MD5_STAT,64);
+
+}
+static int xlp_des_cbc_hmac_sha1_setkey(struct crypto_aead *tfm, const u8 *key,
+						 unsigned int keylen)
+{
+	return xlp_des_setkey(tfm,(uint8_t *)key,keylen, SAESOC_HASH_TYPE_SHA_1, SAESOC_HASH_MODE_HMAC,H_SHA1_STAT,64);
+
+}
+static int xlp_des_cbc_hmac_sha256_setkey(struct crypto_aead *tfm, const u8 *key,
+							unsigned int keylen)
+{
+	return xlp_des_setkey(tfm,(uint8_t *)key,keylen, SAESOC_HASH_TYPE_SHA_256, SAESOC_HASH_MODE_HMAC,H_SHA256_STAT,64);
+
+}
+static int xlp_des_cbc_aes_xcbc_mac_setkey( struct crypto_aead *tfm, const u8 *key,
+					unsigned int keylen)
+{
+	return xlp_des_setkey(tfm,(uint8_t *)key,keylen,SAESOC_HASH_TYPE_AES_128,SAESOC_HASH_MODE_XCBC,AES128_XCBC_STAT,16);
+}
+static int xlp_des_cbc_hmac_md5_setkey( struct crypto_aead *tfm, const u8 *key,
+						unsigned int keylen)
+{
+	return xlp_des_setkey(tfm,(uint8_t *)key,keylen,SAESOC_HASH_TYPE_MD5, SAESOC_HASH_MODE_HMAC,MD5_STAT,64);
+
+}
+static  int xlp_aes_ctr_hmac_sha256_setkey ( struct crypto_aead *tfm, const u8 *key,
+					unsigned int keylen)
+{
+	return xlp_aes_ctr_setkey(tfm, (uint8_t *)key, keylen,SAESOC_HASH_TYPE_SHA_256, SAESOC_HASH_MODE_HMAC,H_SHA256_STAT,64);
+}
+static  int xlp_aes_ctr_hmac_sha1_setkey ( struct crypto_aead *tfm, const u8 *key,
+					unsigned int keylen)
+{
+	return xlp_aes_ctr_setkey(tfm, (uint8_t *)key, keylen,SAESOC_HASH_TYPE_SHA_1, SAESOC_HASH_MODE_HMAC ,H_SHA1_STAT,64);
+
+}
+static  int xlp_aes_ctr_aes_xcbc_mac_setkey ( struct crypto_aead *tfm, const u8 *key,
+					unsigned int keylen)
+{
+	return xlp_aes_ctr_setkey(tfm, (uint8_t *)key, keylen,SAESOC_HASH_TYPE_AES_128,SAESOC_HASH_MODE_XCBC,AES128_XCBC_STAT,16);
+}
+
+static int xlp_aes_ctr_hmac_md5_setkey(struct crypto_aead *tfm, const u8 *key,
+					unsigned int keylen)
+{
+	return xlp_aes_ctr_setkey(tfm, (uint8_t *)key, keylen,SAESOC_HASH_TYPE_MD5,SAESOC_HASH_MODE_HMAC,MD5_STAT,64);
+}
+
+//returns nr_aad_frags... -1 for error
+unsigned int fill_aead_aad(struct saesoc_data_desc   *d_desc, struct aead_request *req, unsigned int aad_len,int seg,int max_frags)
+{
+	struct scatterlist *sg;
+	struct scatter_walk walk;
+	int len;
+	uint8_t *virt;
+	int rv = 0;
+	
+	for (sg = req->assoc; aad_len > 0; sg = scatterwalk_sg_next(sg) ) {
+
+		len = min(aad_len, sg->length);
+		scatterwalk_start(&walk, sg);
+		//virt = scatterwalk_map(&walk, 1);
+		virt = page_address(scatterwalk_page(&walk)) + offset_in_page(walk.offset);
+		if ( len > 0)
+		rv = saesoc_add_frags(d_desc,virt,len,virt,len);
+		aad_len -= len;
+	}
+	return seg;
+}
+		
+/*
+   Generic Encrypt / Decrypt Function
+ */
+//op is either encrypt or decrypt
+
+static void aead_request_callback(struct nlm_async_crypto *async, uint64_t msg1)
+{
+	struct crypto_async_request *base = (struct crypto_async_request *)async->args;
+	int err = 0;
+
+	if (msg1 & 0x7ff80) {
+		printk("\n Error: entry1 is %llx",msg1);
+		err = -EIO;
+		base->complete(base, err);
+		return;
+	}
+	if (async->op){
+		scatterwalk_map_and_copy(async->hash_addr, async->dst, async->bytes, async->authsize, 1);
+	}else{
+		char authtag[64];
+		scatterwalk_map_and_copy(authtag, async->src, async->bytes-async->authsize, async->authsize, 0);
+		if(memcmp(authtag, async->hash_addr, async->authsize)){
+			err = -EBADMSG;
+		}
+	}
+#if 0
+	int cpu = hard_smp_processor_id();
+	int enc = async->stat & 0xff;
+	int auth = (async->stat >> 8 ) & 0xff;
+	crypto_stat[cpu].enc[enc]++;
+	crypto_stat[cpu].auth[auth]++;	
+	crypto_stat[cpu].enc_tbytes[enc] += async->bytes;
+	crypto_stat[cpu].auth_tbytes[auth] += async->bytes;
+#endif
+	if ( async->ddesc)
+		kfree(async->ddesc);
+	base->complete(base, err);
+	return;
+}
+
+static int aead_crypt(struct aead_request *req, unsigned int op)
+{
+	struct saesoc_data_desc    *d_desc = NLM_CRYPTO_DATA_DESC(aead_request_ctx(req));
+	struct crypto_aead *tfm = crypto_aead_reqtfm(req);
+	struct crypto_alg *alg = tfm->base.__crt_alg;
+	struct aead_alg *aead= &alg->cra_aead;
+	struct nlm_aead_ctx *ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	unsigned int cipher_len;
+	struct saesoc_session_desc *s_desc ;
+	int ivsize;
+	struct nlm_async_crypto *async =  (struct nlm_async_crypto *)NLM_ASYNC_PTR_PARAM_OFFSET(aead_request_ctx(req));
+	uint8_t *hash_addr;
+	int fb_vc; 
+	unsigned int authsize,maxauthsize;
+	unsigned long msgrng_flags;
+	unsigned int max_frags  = MAX_FRAGS;
+	int node_sae_base;
+	int node;
+	struct saesoc_extra_req_send_params mparam;
+
+	ivsize = crypto_aead_ivsize(crypto_aead_reqtfm(req));
+
+	authsize = crypto_aead_authsize(tfm);
+	maxauthsize= aead->maxauthsize;
+	async->ddesc = NULL;
+	async->src = req->src;
+	async->dst = req->dst;
+	if ( op )
+		s_desc = &ctx->enc_s_desc; 
+	else
+		s_desc = &ctx->dec_s_desc;
+	saesoc_new_data_desc(s_desc, &d_desc, MAX_FRAGS , NULL);
+
+	hash_addr = (uint8_t *)NLM_HASH_OFFSET(aead_request_ctx(req));
+
+	//check if it should be aip->tag_len or can be taken from tfm
+	cipher_len = op ? req->cryptlen:req->cryptlen - authsize;
+	saesoc_set_aad_len(d_desc,req->assoclen + ivsize);
+	fill_aead_aad(d_desc, req, req->assoclen,0,max_frags);
+	if (ivsize) 
+		saesoc_add_frags(d_desc,req->iv,ivsize,req->iv,ivsize);
+	d_desc = fill_src_dst_sg(s_desc,d_desc,async,req->src,req->dst,&max_frags,cipher_len);
+
+	saesoc_set_payload_len(d_desc,cipher_len);
+	saesoc_set_tag_dstaddr(d_desc,hash_addr);
+	preempt_disable();
+
+	async->callback =  aead_request_callback;
+	async->args = (void *)&req->base; 
+	async->op  = op;
+	async->hash_addr = hash_addr;
+	async->authsize = authsize;
+	async->stat = ctx->stat; 
+	async->bytes = req->cryptlen; 
+	mparam.async_rsp_arg = (uint64_t)async;
+	mparam.arc4_load_state = 0;
+
+	//construct pkt, send to engine and receive reply
+	msgrng_access_enable(msgrng_flags);
+	fb_vc = crypto_get_fb_vc(&node);
+	node_sae_base = (node << NODE_BASE_SHIFT_BIT) | crypto_vc_base;
+
+	if (saesoc_process_request(NULL,d_desc,node_sae_base,fb_vc,0,1,&mparam,NULL) != 0 ) {
+		msgrng_access_disable(msgrng_flags);
+		preempt_enable();
+		return -EAGAIN;
+	}
+
+	msgrng_access_disable(msgrng_flags);
+	preempt_enable();
+
+	return -EINPROGRESS;
+
+
+}
+static int aead_crypt_gcm(struct aead_request *req, unsigned int op)
+{
+	struct saesoc_data_desc    *d_desc = NLM_CRYPTO_DATA_DESC(aead_request_ctx(req));
+	struct nlm_async_crypto *async =  (struct nlm_async_crypto *)NLM_ASYNC_PTR_PARAM_OFFSET(aead_request_ctx(req));
+	struct crypto_aead *tfm = crypto_aead_reqtfm(req);
+	unsigned long msgrng_flags;
+	unsigned int max_frags  = MAX_FRAGS;
+	int node_sae_base;
+	int node;
+	int fb_vc; 
+	struct saesoc_extra_req_send_params mparam;
+	unsigned int authsize,maxauthsize;
+	char * hash_addr = (uint8_t *)NLM_HASH_OFFSET(aead_request_ctx(req));
+	struct nlm_aead_ctx *ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	char * iv = (uint8_t *)NLM_IV_OFFSET(aead_request_ctx(req)); 
+	uint8_t *tmp_iv = iv;
+	unsigned int cipher_len;
+	struct crypto_alg *alg = tfm->base.__crt_alg;
+	struct aead_alg *aead= &alg->cra_aead;
+	struct saesoc_session_desc *s_desc ;
+	int rem;
+
+	authsize = crypto_aead_authsize(tfm);
+	maxauthsize= aead->maxauthsize;
+	async->ddesc = NULL; 
+	async->src = req->src;
+	async->dst = req->dst; 
+	if ( op )
+		s_desc = &ctx->enc_s_desc;
+	else
+		s_desc = &ctx->dec_s_desc;
+	saesoc_new_data_desc(s_desc, &d_desc, MAX_FRAGS , NULL);
+
+
+	if ( (op &&  (req->cryptlen == 0 )) || (!op && req->cryptlen <= aead->maxauthsize) ||
+			(req->assoclen != 8))
+	{
+		int ret =0;
+		ret = crypto_aead_setauthsize(ctx->fallback, authsize);
+		aead_request_set_tfm(req, ctx->fallback);
+		if ( op )
+		ret = crypto_aead_encrypt(req);
+		else 
+		ret = crypto_aead_decrypt(req);
+		aead_request_set_tfm(req,tfm);
+		
+		return ret;
+	}
+	
+	/*Copy nonce*/
+	memcpy(tmp_iv,  ctx->iv_buf, GCM_RFC4106_NONCE_SIZE);
+	tmp_iv += GCM_RFC4106_NONCE_SIZE;
+
+	/*Copy IV*/
+	memcpy(tmp_iv, req->iv, GCM_RFC4106_IV_SIZE);
+	tmp_iv += GCM_RFC4106_IV_SIZE;
+
+	/*Set counter*/
+	*((uint32_t*)tmp_iv) = cpu_to_be32((uint32_t)1);
+
+	saesoc_add_frags(d_desc,iv,16,iv,16);
+
+	cipher_len = op ? req->cryptlen: req->cryptlen - authsize;
+
+	saesoc_set_aad_len(d_desc,req->assoclen);
+	
+	fill_aead_aad(d_desc, req, req->assoclen,0,max_frags);
+
+	//frag for aad padding
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2) {
+		int rem;
+		rem = req->assoclen % 16;
+		
+		if (rem) {
+			rem = 16 - rem;
+			saesoc_add_frags(d_desc,iv + 16,rem,iv + 16,rem);
+		}
+	}
+
+	d_desc = fill_src_dst_sg(s_desc,d_desc,async,req->src,req->dst,&max_frags,cipher_len);
+	//Frag for 
+	//1. cipher padding to block size
+	//2. (aadlen + payloadlen = 16 bytes)
+	//3. hash output = 16 bytes.
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2) {
+		rem = cipher_len % 16;
+		if (rem)
+			rem = 16 - rem;
+		saesoc_add_frags(d_desc,iv + 48,32 + rem,iv + 48,32 + rem);
+	}
+	saesoc_set_payload_len(d_desc,cipher_len);
+	saesoc_set_tag_dstaddr(d_desc,hash_addr);
+
+	preempt_disable();
+	async->callback =  aead_request_callback;
+	async->args = (void *)&req->base; 
+	async->op  = op;
+	async->hash_addr = hash_addr;
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2) {
+		if (op)
+			async->hash_addr = iv + 48 + rem;
+		else
+			async->hash_addr = iv + 48;
+	}
+	async->authsize = authsize;
+	async->stat = ctx->stat; 
+	async->bytes = req->cryptlen; 
+	mparam.async_rsp_arg = (uint64_t)async;
+	mparam.arc4_load_state = 0;
+
+	//construct pkt, send to engine and receive reply
+	msgrng_access_enable(msgrng_flags);
+	fb_vc = crypto_get_fb_vc(&node);
+	node_sae_base = (node << NODE_BASE_SHIFT_BIT) | crypto_vc_base;
+
+	if (saesoc_process_request(NULL,d_desc,node_sae_base,fb_vc,0,1,&mparam,NULL) != 0 ) {
+		msgrng_access_disable(msgrng_flags);
+		preempt_enable();
+		return -EAGAIN;
+	}
+	msgrng_access_disable(msgrng_flags);
+	preempt_enable();
+
+	return -EINPROGRESS;
+
+}
+
+
+static int aead_crypt_ccm(struct aead_request *req, unsigned int op)
+{
+	struct saesoc_data_desc    *d_desc = NLM_CRYPTO_DATA_DESC(aead_request_ctx(req));
+	struct nlm_async_crypto *async =  (struct nlm_async_crypto *)NLM_ASYNC_PTR_PARAM_OFFSET(aead_request_ctx(req));
+	struct crypto_aead *tfm = crypto_aead_reqtfm(req);
+	struct crypto_alg *alg = tfm->base.__crt_alg;
+	struct aead_alg *aead= &alg->cra_aead;
+	struct nlm_aead_ctx *ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	unsigned int cipher_off, auth_off;
+	unsigned int auth_len, cipher_len;
+	uint8_t *hash_addr;
+	int fb_vc; 
+	unsigned int authsize,maxauthsize;
+	char * iv = (uint8_t *)NLM_IV_OFFSET(aead_request_ctx(req));
+	int iv_size = 16;
+	uint8_t *auth_iv = (uint8_t *)iv + iv_size;
+	unsigned int auth_iv_frag_len = iv_size; 
+	unsigned int extralen = 0, cipher_extralen =0;
+	uint8_t *tmp_iv = &iv[1];
+	unsigned long msgrng_flags;
+	unsigned int max_frags  = MAX_FRAGS;
+	int node_sae_base;
+	int node;
+	struct saesoc_extra_req_send_params mparam;
+	struct saesoc_session_desc *s_desc ;
+
+	hash_addr = (uint8_t *)NLM_HASH_OFFSET(aead_request_ctx(req));
+
+	authsize = crypto_aead_authsize(tfm);
+	maxauthsize= aead->maxauthsize;
+	async->ddesc = NULL;
+	async->src = req->src;
+	async->dst = req->dst;
+
+	if ( op )
+		s_desc = &ctx->enc_s_desc;
+	else
+		s_desc = &ctx->dec_s_desc;
+
+	saesoc_new_data_desc(s_desc, &d_desc, MAX_FRAGS , NULL);
+
+	if ( (op &&  (req->cryptlen == 0 )) || (!op && req->cryptlen <= aead->maxauthsize) || (req->assoclen != 8))
+	{
+		int ret =0;
+		ret = crypto_aead_setauthsize(ctx->fallback, authsize);
+		aead_request_set_tfm(req, ctx->fallback);
+		if ( op )
+		ret = crypto_aead_encrypt(req);
+		else 
+		ret = crypto_aead_decrypt(req);
+		aead_request_set_tfm(req,tfm);
+		
+		return ret;
+	}
+	
+		
+	/*Copy nonce*/
+	memcpy(tmp_iv,  &ctx->iv_buf, CCM_RFC4309_NONCE_SIZE);
+	tmp_iv += CCM_RFC4309_NONCE_SIZE;
+
+	/*Copy IV*/
+	memcpy(tmp_iv, req->iv, CCM_RFC4309_IV_SIZE);
+	tmp_iv += CCM_RFC4309_IV_SIZE;
+
+	/*Set counter*/
+	*((uint32_t*)tmp_iv) = (uint32_t)0;
+
+	memcpy(auth_iv,iv,iv_size);
+
+	/* Encryption iv  7            Reserved (always zero)
+	   6            Reserved (always zero)
+	   5 ... 3      Zero
+	   2 ... 0      L' ( L -1 ) ( Length of the counter ) */
+
+	iv[0] = 3;
+
+	cipher_len = op ? req->cryptlen: req->cryptlen - authsize;
+
+
+	/*Setup ENCRYPTION IV*/
+
+	/*	7            Reserved (always zero)
+		6            Adata
+		5 ... 3      M' ( (tag_len -2) /2)
+		2 ... 0      L' */
+
+	auth_iv[0] = ((req->assoclen?1 : 0 ) << 6 )| ((authsize - 2 )/2) << 3 | 3;
+	/*Setup AUTH IV*/
+	*(uint32_t*)&auth_iv[12] |= cpu_to_be32((uint32_t )cipher_len);
+	*(short*)(auth_iv + 16) = cpu_to_be16((short)req->assoclen);
+
+	if ( req->assoclen ) {
+		extralen = req->assoclen;
+		extralen += 2;
+		extralen = extralen % 16;
+		auth_iv_frag_len = 18;
+		if ( extralen ) {
+			extralen = AES_BLOCK_SIZE - extralen;
+			memset(auth_iv + auth_iv_frag_len,0,extralen);
+		}
+	}
+
+	saesoc_add_frags(d_desc,iv,16,iv,16);
+	saesoc_add_frags(d_desc,auth_iv,auth_iv_frag_len,auth_iv,auth_iv_frag_len);
+
+	fill_aead_aad(d_desc, req, req->assoclen,0,max_frags);
+
+
+	saesoc_add_frags(d_desc,auth_iv+ auth_iv_frag_len, extralen, auth_iv + auth_iv_frag_len, extralen);
+
+
+	auth_len = cipher_off + cipher_len + cipher_extralen - auth_off; 
+
+	cipher_extralen = cipher_len % 16;
+
+	d_desc= fill_src_dst_sg(s_desc,d_desc,async,req->src,req->dst,&max_frags,cipher_len);
+
+	if ( cipher_extralen ) {
+		cipher_extralen = AES_BLOCK_SIZE - cipher_extralen;
+		memset(auth_iv + 38,0,cipher_extralen);
+		if (op)
+		saesoc_add_frags(d_desc,(auth_iv+38),cipher_extralen,(auth_iv+38),cipher_extralen);
+	}
+
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2)
+		saesoc_add_frags(d_desc,hash_addr,16,hash_addr,16);
+
+	/* add all those extra bytes for auth excluding assoc */
+	
+	saesoc_set_aad_len(d_desc,req->assoclen + cipher_extralen +  2 + 6 );
+        if (cryptosoc_ptype_gen == CRYPTOSOC_PTYPE_IS_GEN2)
+		saesoc_set_aad_len(d_desc,req->assoclen);
+
+	saesoc_set_payload_len(d_desc,cipher_len);
+	saesoc_set_tag_dstaddr(d_desc,hash_addr);
+
+
+	preempt_disable();
+	async->callback =  aead_request_callback;
+	async->args = (void *)&req->base; 
+	async->op  = op;
+	async->hash_addr = hash_addr;
+	async->authsize = authsize;
+	async->stat = ctx->stat; 
+	async->bytes = req->cryptlen; 
+	mparam.async_rsp_arg = (uint64_t)async;
+	mparam.arc4_load_state = 0;
+
+	//construct pkt, send to engine and receive reply
+	msgrng_access_enable(msgrng_flags);
+	fb_vc = crypto_get_fb_vc(&node);
+	node_sae_base = (node << NODE_BASE_SHIFT_BIT) | crypto_vc_base;
+
+	if (saesoc_process_request(NULL,d_desc,node_sae_base,fb_vc,0,1,&mparam,NULL) != 0 ) {
+		msgrng_access_disable(msgrng_flags);
+		preempt_enable();
+		return -EAGAIN;
+	}
+	msgrng_access_disable(msgrng_flags);
+	preempt_enable();
+
+	return -EINPROGRESS;
+}
+static int aead_crypt_ctr(struct aead_request *req, unsigned int op)
+{
+	struct crypto_aead *tfm = crypto_aead_reqtfm(req);
+	struct crypto_alg *alg = tfm->base.__crt_alg;
+	struct aead_alg *aead= &alg->cra_aead;
+	struct nlm_aead_ctx *ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	struct saesoc_data_desc    *d_desc = NLM_CRYPTO_DATA_DESC(aead_request_ctx(req));
+	unsigned int cipher_len;
+	int ivsize;
+	void  * addr = aead_request_ctx(req);
+	struct nlm_async_crypto *async =  (struct nlm_async_crypto *)NLM_ASYNC_PTR_PARAM_OFFSET(aead_request_ctx(req));
+	uint8_t *hash_addr;
+	int fb_vc; 
+	unsigned int authsize,maxauthsize;
+	uint8_t *iv = NULL; 
+	unsigned long msgrng_flags;
+	unsigned int max_frags  = MAX_FRAGS;
+	int node_sae_base;
+	int node;
+	struct saesoc_extra_req_send_params mparam;
+	struct saesoc_session_desc *s_desc ;
+	async->ddesc = NULL;
+	if ( op )
+		s_desc = &ctx->enc_s_desc;
+	else
+		s_desc = &ctx->dec_s_desc;
+
+	authsize = crypto_aead_authsize(tfm);
+	maxauthsize= aead->maxauthsize;
+	async->ddesc = NULL;
+	async->src = req->src;
+	async->dst = req->dst;
+	saesoc_new_data_desc(s_desc, &d_desc, MAX_FRAGS , NULL);
+
+	iv = (uint8_t *)NLM_IV_OFFSET(addr);
+	if ( !op ) {
+		 uint8_t *tmp_iv = iv;
+		/*Copy nonce*/
+		memcpy(tmp_iv,  ctx->iv_buf, CTR_RFC3686_NONCE_SIZE);
+		tmp_iv += CTR_RFC3686_NONCE_SIZE;
+
+		memcpy(tmp_iv, req->iv, CTR_RFC3686_IV_SIZE);
+		tmp_iv += CTR_RFC3686_IV_SIZE;
+
+		/*Set counter*/
+		*((uint32_t *)tmp_iv) = cpu_to_be32((uint32_t)1);
+	}
+
+	hash_addr = (uint8_t *)NLM_HASH_OFFSET(addr);
+
+	ivsize = crypto_aead_ivsize(crypto_aead_reqtfm(req));
+	cipher_len = op ? req->cryptlen:req->cryptlen - authsize;
+
+	saesoc_add_frags(d_desc,iv,CTR_RFC3686_BLOCK_SIZE,iv,CTR_RFC3686_BLOCK_SIZE);
+	saesoc_set_aad_len(d_desc,req->assoclen + CTR_RFC3686_IV_SIZE);
+	fill_aead_aad(d_desc, req, req->assoclen,0,max_frags);
+
+	saesoc_add_frags(d_desc,iv + CTR_RFC3686_NONCE_SIZE,ivsize,iv+CTR_RFC3686_NONCE_SIZE,ivsize);
+
+	d_desc = fill_src_dst_sg(s_desc,d_desc,async,req->src,req->dst,&max_frags,cipher_len);
+
+	saesoc_set_tag_dstaddr(d_desc,hash_addr);
+	saesoc_set_payload_len(d_desc,cipher_len);
+
+
+
+	preempt_disable();
+	async->callback =  aead_request_callback;
+	async->args = (void *)&req->base; 
+	async->op  = op;
+	async->hash_addr = hash_addr;
+	async->authsize = authsize;
+	async->stat = ctx->stat;
+	async->bytes = req->cryptlen;
+	mparam.async_rsp_arg = (uint64_t)async;
+	mparam.arc4_load_state = 0;
+
+
+	//construct pkt, send to engine and receive reply
+	msgrng_access_enable(msgrng_flags);
+	fb_vc = crypto_get_fb_vc(&node);
+	node_sae_base = (node << NODE_BASE_SHIFT_BIT) | crypto_vc_base;
+
+	if (saesoc_process_request(NULL,d_desc,node_sae_base,fb_vc,0,1,&mparam,NULL) != 0 ) {
+		msgrng_access_disable(msgrng_flags);
+		preempt_enable();
+		return -EAGAIN;
+	}
+	msgrng_access_disable(msgrng_flags);
+	preempt_enable();
+	//construct pkt, send to engine and receive reply
+	return -EINPROGRESS;
+}
+
+/*
+ *  All Encrypt Functions goes here.
+ */
+static int 
+xlp_aes_cbc_encrypt(struct aead_request *req)
+{
+	return aead_crypt(req, NETL_OP_ENCRYPT);
+}
+
+static int
+xlp_3des_cbc_encrypt(struct aead_request *req)
+{
+	 return aead_crypt(req, NETL_OP_ENCRYPT);
+}
+static int 
+xlp_des_cbc_encrypt(struct aead_request *req)
+{
+	return aead_crypt(req, NETL_OP_ENCRYPT);
+}
+static int
+xlp_aes_gcm_encrypt(struct aead_request *req)
+{
+	return aead_crypt_gcm(req, NETL_OP_ENCRYPT);
+}
+static int
+xlp_aes_ccm_encrypt(struct aead_request *req)
+{
+	return aead_crypt_ccm(req, NETL_OP_ENCRYPT);
+}
+
+static int 
+xlp_aes_ctr_encrypt(struct aead_request *req)
+{
+	return aead_crypt_ctr(req, NETL_OP_ENCRYPT);
+}
+
+/*
+ *  All Decrypt Functions goes here.
+ */
+static int xlp_aes_cbc_decrypt(struct aead_request *req)
+{
+	return aead_crypt(req, NETL_OP_DECRYPT);
+}
+
+static int xlp_3des_cbc_decrypt( struct aead_request *req)
+{
+	return aead_crypt(req, NETL_OP_DECRYPT);
+}
+static int xlp_des_cbc_decrypt(struct aead_request *req)
+{
+	return aead_crypt(req, NETL_OP_DECRYPT);
+}
+static int xlp_aes_gcm_decrypt(struct aead_request *req)
+{
+	return aead_crypt_gcm(req, NETL_OP_DECRYPT);
+}
+static int xlp_aes_ccm_decrypt(struct aead_request *req)
+{
+	return aead_crypt_ccm(req, NETL_OP_DECRYPT);
+}
+static int xlp_aes_ctr_decrypt(struct aead_request *req)
+{
+	return aead_crypt_ctr(req, NETL_OP_DECRYPT);
+} 
+/*
+ *  All Givencrypt Functions goes here.
+ */
+int xlp_aes_cbc_givencrypt(struct aead_givcrypt_request *req)
+{
+	struct crypto_aead *tfm = crypto_aead_reqtfm(&req->areq);
+	struct nlm_aead_ctx *nlm_ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+
+	//TODO: Get the IV from random pool
+	memcpy(req->giv, nlm_ctx->iv_buf, nlm_ctx->iv_len);
+	*(uint64_t *)req->giv += cpu_to_be64(req->seq);
+	memcpy(req->areq.iv, req->giv, nlm_ctx->iv_len);
+
+	return xlp_aes_cbc_encrypt(&req->areq);
+}
+
+static int xlp_3des_cbc_givencrypt(struct aead_givcrypt_request *req)
+{
+	struct crypto_aead *tfm = crypto_aead_reqtfm(&req->areq);
+	struct nlm_aead_ctx *nlm_ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+
+	memcpy(req->giv, nlm_ctx->iv_buf, nlm_ctx->iv_len);
+	*(uint64_t *)req->giv += cpu_to_be64(req->seq);
+	memcpy(req->areq.iv, req->giv, nlm_ctx->iv_len);
+
+	return xlp_3des_cbc_encrypt(&req->areq);
+
+}
+static int xlp_des_cbc_givencrypt(struct aead_givcrypt_request *req)
+{
+	struct crypto_aead *tfm = crypto_aead_reqtfm(&req->areq);
+	struct nlm_aead_ctx *nlm_ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	
+	memcpy(req->giv, nlm_ctx->iv_buf, nlm_ctx->iv_len);
+	*(uint64_t *)req->giv += cpu_to_be64(req->seq);
+	memcpy(req->areq.iv, req->giv, nlm_ctx->iv_len);
+
+	return xlp_des_cbc_encrypt(&req->areq);
+}
+
+static int xlp_aes_gcm_givencrypt(struct aead_givcrypt_request *req)
+{
+	struct crypto_aead *tfm = crypto_aead_reqtfm(&req->areq);
+	struct nlm_aead_ctx *nlm_ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	struct aead_request *areq = &req->areq;
+	char * req_iv = areq->iv;
+	int ret;
+
+	memcpy(req->giv, nlm_ctx->iv_buf + GCM_RFC4106_NONCE_SIZE,nlm_ctx->iv_len);
+	*(uint64_t *)req->giv += cpu_to_be64(req->seq);
+
+	areq->iv = req->giv;
+	ret = xlp_aes_gcm_encrypt(&req->areq);
+	areq->iv = req_iv;
+	return ret;
+
+}
+static int xlp_aes_ccm_givencrypt(struct aead_givcrypt_request *req)
+{
+	struct crypto_aead *tfm = crypto_aead_reqtfm(&req->areq);
+	struct nlm_aead_ctx *nlm_ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	struct aead_request *areq = &req->areq;
+	char * req_iv = areq->iv;
+	int ret;
+
+	memcpy(req->giv, nlm_ctx->iv_buf + CCM_RFC4309_NONCE_SIZE, nlm_ctx->iv_len);
+	*(uint64_t *)req->giv += cpu_to_be64(req->seq);
+
+	areq->iv = req->giv;
+	ret = xlp_aes_ccm_encrypt(&req->areq);
+	areq->iv = req_iv;
+	return ret;
+
+}
+int xlp_aes_ctr_givencrypt(struct aead_givcrypt_request *req)
+{
+	struct crypto_aead *tfm = crypto_aead_reqtfm(&req->areq);
+	struct nlm_aead_ctx *nlm_ctx = (struct nlm_aead_ctx *)nlm_crypto_aead_ctx(tfm);
+	void *iv = (uint8_t *)NLM_IV_OFFSET(aead_request_ctx(&req->areq));
+	memcpy(req->giv, nlm_ctx->iv_buf+CTR_RFC3686_NONCE_SIZE, nlm_ctx->iv_len);
+	*(uint64_t *)req->giv += cpu_to_be64(req->seq);
+
+	memcpy(iv,  nlm_ctx->iv_buf, CTR_RFC3686_NONCE_SIZE);
+	iv += CTR_RFC3686_NONCE_SIZE;
+
+	 /*Copy IV*/
+	memcpy(iv, req->giv, CTR_RFC3686_IV_SIZE);
+	iv += CTR_RFC3686_IV_SIZE;
+
+	/*Set counter*/
+	*((uint32_t *)iv) = cpu_to_be32((uint32_t)1);
+	
+	return xlp_aes_ctr_encrypt(&req->areq);
+}
+/* commented out to avoid the search time */
+static struct crypto_alg xlp_aes_cbc_hmac_sha256_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(hmac(sha256),cbc(aes))",
+	.cra_driver_name = "authenc-hmac-sha256-cbc-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = AES_BLOCK_SIZE,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC ,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_aead_type,
+	.cra_init = aead_cra_cbc_init,
+	.cra_exit = aead_session_cleanup,
+	.cra_aead = {
+		     .setkey = xlp_aes_cbc_hmac_sha256_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_aes_cbc_encrypt,
+		     .decrypt = xlp_aes_cbc_decrypt,
+		     .givencrypt = xlp_aes_cbc_givencrypt,
+		     .ivsize = AES_BLOCK_SIZE,
+		     .maxauthsize = SHA256_DIGEST_SIZE,
+		     }
+};
+/* commented out to avoid the search time */
+static struct crypto_alg xlp_aes_cbc_hmac_sha1_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(hmac(sha1),cbc(aes))",
+	.cra_driver_name = "authenc-hmac-sha1-cbc-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = AES_BLOCK_SIZE,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC ,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_aead_type,
+	.cra_init = aead_cra_cbc_init,
+	.cra_exit = aead_session_cleanup,
+	.cra_aead = {
+		     .setkey = xlp_aes_cbc_hmac_sha1_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_aes_cbc_encrypt,
+		     .decrypt = xlp_aes_cbc_decrypt,
+		     .givencrypt = xlp_aes_cbc_givencrypt,
+		     .geniv = "<built-in>",
+		     .ivsize = AES_BLOCK_SIZE,
+		     .maxauthsize = SHA1_DIGEST_SIZE,
+		     }
+};
+
+static struct crypto_alg xlp_aes_cbc_aes_xcbc_mac_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(xcbc(aes),cbc(aes))",
+	.cra_driver_name = "authenc-xcbc-mac-aes-cbc-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = AES_BLOCK_SIZE,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC ,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_aead_type,
+	.cra_init = aead_cra_cbc_init,
+	.cra_exit = aead_session_cleanup,
+	.cra_aead = {
+		     .setkey = xlp_aes_cbc_aes_xcbc_mac_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_aes_cbc_encrypt,
+		     .decrypt = xlp_aes_cbc_decrypt,
+		     .givencrypt = xlp_aes_cbc_givencrypt,
+		     .geniv = "<built-in>",
+		     .ivsize = AES_BLOCK_SIZE,
+		     .maxauthsize = XCBC_DIGEST_SIZE,
+		     }
+};
+
+static struct crypto_alg xlp_aes_cbc_hmac_md5_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(hmac(md5),cbc(aes))",
+	.cra_driver_name = "authenc-hmac-md5-cbc-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = AES_BLOCK_SIZE,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC ,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_aead_type,
+	.cra_init = aead_cra_cbc_init,
+	.cra_exit = aead_session_cleanup,
+	.cra_aead = {
+		     .setkey = xlp_aes_cbc_hmac_md5_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_aes_cbc_encrypt,
+		     .decrypt = xlp_aes_cbc_decrypt,
+		     .givencrypt = xlp_aes_cbc_givencrypt,
+		     .geniv = "<built-in>",
+		     .ivsize = AES_BLOCK_SIZE,
+		     .maxauthsize = MD5_DIGEST_SIZE,
+		     }
+};
+
+static struct crypto_alg xlp_3des_cbc_hmac_sha256_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(hmac(sha256),cbc(des3_ede))",
+	.cra_driver_name = "authenc-hmac-sha256-cbc-des3-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = DES3_EDE_BLOCK_SIZE,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,
+	.cra_ctxsize = DES3_CTRL_DESC_SIZE,
+	.cra_type = &crypto_aead_type,
+	.cra_init = aead_cra_init,
+	.cra_exit = aead_session_cleanup,
+	.cra_aead = {
+		     .setkey = xlp_3des_cbc_hmac_sha256_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_3des_cbc_encrypt,
+		     .decrypt = xlp_3des_cbc_decrypt,
+		     .givencrypt = xlp_3des_cbc_givencrypt,
+		     .geniv = "<built-in>",
+		     .ivsize = DES3_EDE_BLOCK_SIZE,
+		     .maxauthsize = SHA256_DIGEST_SIZE,
+		     }
+};
+
+static struct crypto_alg xlp_3des_cbc_hmac_sha1_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(hmac(sha1),cbc(des3_ede))",
+	.cra_driver_name = "authenc-hmac-sha1-cbc-des3-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = DES3_EDE_BLOCK_SIZE,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,
+	.cra_ctxsize = DES3_CTRL_DESC_SIZE,
+	.cra_type = &crypto_aead_type,
+	.cra_init = aead_cra_init,
+	.cra_exit = aead_session_cleanup,
+	.cra_aead = {
+		     .setkey = xlp_3des_cbc_hmac_sha1_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_3des_cbc_encrypt,
+		     .decrypt = xlp_3des_cbc_decrypt,
+		     .givencrypt = xlp_3des_cbc_givencrypt,
+		     .geniv = "<built-in>",
+		     .ivsize = DES3_EDE_BLOCK_SIZE,
+		     .maxauthsize = SHA1_DIGEST_SIZE,
+		     }
+};
+
+static struct crypto_alg xlp_3des_cbc_aes_xcbc_mac_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(xcbc(aes),cbc(des3_ede))",
+	.cra_driver_name = "authenc-aes-xcbc-cbc-des3-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = DES3_EDE_BLOCK_SIZE,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,
+	.cra_ctxsize = DES3_CTRL_DESC_SIZE,
+	.cra_type = &crypto_aead_type,
+	.cra_exit = aead_session_cleanup,
+	.cra_init = aead_cra_init,
+	.cra_aead = {
+		     .setkey = xlp_3des_cbc_aes_xcbc_mac_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_3des_cbc_encrypt,
+		     .decrypt = xlp_3des_cbc_decrypt,
+		     .givencrypt = xlp_3des_cbc_givencrypt,
+		     .geniv = "<built-in>",
+		     .ivsize = DES3_EDE_BLOCK_SIZE,
+		     .maxauthsize = XCBC_DIGEST_SIZE,
+		     }
+};
+
+static struct crypto_alg xlp_3des_cbc_hmac_md5_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(hmac(md5),cbc(des3_ede))",
+	.cra_driver_name = "authenc-hmac-md5-cbc-des3-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = DES3_EDE_BLOCK_SIZE,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,
+	.cra_ctxsize = DES3_CTRL_DESC_SIZE, 
+	.cra_type = &crypto_aead_type,
+	.cra_init = aead_cra_init,
+	.cra_exit = aead_session_cleanup,
+	.cra_aead = {
+		     .setkey = xlp_3des_cbc_hmac_md5_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_3des_cbc_encrypt,
+		     .decrypt = xlp_3des_cbc_decrypt,
+		     .givencrypt = xlp_3des_cbc_givencrypt,
+		     .geniv = "<built-in>",
+		     .ivsize = DES3_EDE_BLOCK_SIZE,
+		     .maxauthsize = MD5_DIGEST_SIZE,
+		     }
+};
+
+static struct crypto_alg xlp_des_cbc_hmac_sha256_cipher_auth = {
+        /* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+        .cra_name = "authenc(hmac(sha256),cbc(des))",
+        .cra_driver_name = "authenc-hmac-sha256-cbc-des-xlp",
+        .cra_priority = XLP_CRYPT_PRIORITY,
+        .cra_blocksize = DES_BLOCK_SIZE,
+	.cra_alignmask = 0,
+        .cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,
+        .cra_ctxsize = CTRL_DESC_SIZE,
+        .cra_type = &crypto_aead_type,
+        .cra_init = aead_cra_cbc_init,
+        .cra_exit = aead_session_cleanup,
+        .cra_aead = {
+                     .setkey = xlp_des_cbc_hmac_sha256_setkey,
+                     .setauthsize = aead_setauthsize,
+                     .encrypt = xlp_des_cbc_encrypt,
+                     .decrypt = xlp_des_cbc_decrypt,
+                     .givencrypt = xlp_des_cbc_givencrypt,
+                     .geniv = "<built-in>",
+                     .ivsize = DES_BLOCK_SIZE,
+                     .maxauthsize = SHA256_DIGEST_SIZE,
+                     }
+};
+static struct crypto_alg xlp_des_cbc_hmac_sha1_cipher_auth = {
+        /* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+        .cra_name = "authenc(hmac(sha1),cbc(des))",
+        .cra_driver_name = "authenc-hmac-sha1-cbc-des-xlp",
+        .cra_priority = XLP_CRYPT_PRIORITY,
+        .cra_blocksize = DES_BLOCK_SIZE,
+	.cra_alignmask = 0,
+        .cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,
+        .cra_ctxsize = CTRL_DESC_SIZE,
+        .cra_type = &crypto_aead_type,
+        .cra_exit = aead_session_cleanup,
+        .cra_init = aead_cra_cbc_init,
+        .cra_aead = {
+                     .setkey = xlp_des_cbc_hmac_sha1_setkey,
+                     .setauthsize = aead_setauthsize,
+                     .encrypt = xlp_des_cbc_encrypt,
+                     .decrypt = xlp_des_cbc_decrypt,
+                     .givencrypt = xlp_des_cbc_givencrypt,
+                     .geniv = "<built-in>",
+                     .ivsize = DES_BLOCK_SIZE,
+                     .maxauthsize = SHA1_DIGEST_SIZE,
+                     }
+};
+
+static struct crypto_alg xlp_des_cbc_aes_xcbc_mac_cipher_auth = {
+        /* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+        .cra_name = "authenc(xcbc(aes),cbc(des))",
+        .cra_driver_name = "authenc-xcbc-mac-aes-cbc-des-xlp",
+        .cra_priority = XLP_CRYPT_PRIORITY,
+        .cra_blocksize = DES_BLOCK_SIZE,
+        .cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,
+        .cra_ctxsize = CTRL_DESC_SIZE,
+        .cra_type = &crypto_aead_type,
+        .cra_init = aead_cra_cbc_init,
+        .cra_exit = aead_session_cleanup,
+        .cra_aead = {
+                     .setkey = xlp_des_cbc_aes_xcbc_mac_setkey,
+                     .setauthsize = aead_setauthsize,
+                     .encrypt = xlp_des_cbc_encrypt,
+                     .decrypt = xlp_des_cbc_decrypt,
+                     .givencrypt = xlp_des_cbc_givencrypt,
+                     .geniv = "<built-in>",
+                     .ivsize = DES_BLOCK_SIZE,
+                     .maxauthsize = MD5_DIGEST_SIZE,
+                     }
+};
+static struct crypto_alg xlp_des_cbc_hmac_md5_cipher_auth = {
+        /* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+        .cra_name = "authenc(hmac(md5),cbc(des))",
+        .cra_driver_name = "authenc-hmac-md5-cbc-des-xlp",
+        .cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_alignmask = 0,
+        .cra_blocksize = DES_BLOCK_SIZE,
+        .cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,
+        .cra_ctxsize = CTRL_DESC_SIZE,
+        .cra_type = &crypto_aead_type,
+        .cra_init = aead_cra_cbc_init,
+        .cra_exit = aead_session_cleanup,
+        .cra_aead = {
+                     .setkey = xlp_des_cbc_hmac_md5_setkey,
+                     .setauthsize = aead_setauthsize,
+                     .encrypt = xlp_des_cbc_encrypt,
+                     .decrypt = xlp_des_cbc_decrypt,
+                     .givencrypt = xlp_des_cbc_givencrypt,
+                     .geniv = "<built-in>",
+                     .ivsize = DES_BLOCK_SIZE,
+                     .maxauthsize = MD5_DIGEST_SIZE,
+                     }
+};
+static struct crypto_alg xlp_aes_gcm_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "rfc4106(gcm(aes))",
+	.cra_driver_name = "rfc4106-gcm-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = AES_BLOCK_SIZE,
+	.cra_alignmask = 0,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,
+	.cra_type = &crypto_aead_type,
+	.cra_exit = aead_session_cleanup,
+        .cra_ctxsize = CTRL_DESC_SIZE,
+        .cra_init = aead_cra_init_gcm,
+	.cra_aead = {
+		.setkey = aead_gcm_rfc4106_setkey,
+		.setauthsize = aead_setauthsize,
+		.encrypt = xlp_aes_gcm_encrypt,
+		.decrypt = xlp_aes_gcm_decrypt,
+		.givencrypt = xlp_aes_gcm_givencrypt,
+		.geniv = "seqiv", 
+		.ivsize = GCM_RFC4106_IV_SIZE,
+		.maxauthsize = GCM_RFC4106_DIGEST_SIZE,
+	}
+};
+static struct crypto_alg xlp_aes_ccm_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "rfc4309(ccm(aes))",
+	.cra_driver_name = "rfc4309-ccm-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = AES_BLOCK_SIZE,
+	.cra_alignmask = 0,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC,
+	.cra_type = &crypto_aead_type,
+        .cra_ctxsize = CTRL_DESC_SIZE,
+        .cra_init = aead_cra_init_ccm,
+	.cra_aead = {
+		.setkey = aead_ccm_rfc4309_setkey,
+		.setauthsize = aead_setauthsize,
+		.encrypt = xlp_aes_ccm_encrypt,
+		.decrypt = xlp_aes_ccm_decrypt,
+		.givencrypt = xlp_aes_ccm_givencrypt,
+		.geniv = "seqiv", 
+		.ivsize = CCM_RFC4309_IV_SIZE,
+		.maxauthsize = CCM_RFC4309_DIGEST_SIZE,
+	}
+};
+
+static struct crypto_alg xlp_aes_ctr_hmac_sha256_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(hmac(sha256),rfc3686(ctr(aes)))",
+	.cra_driver_name = "authenc-hmac-sha256-ctr-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = 1,
+	.cra_alignmask = 0,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC ,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_aead_type,
+	.cra_init = aead_cra_init,
+	.cra_exit = aead_session_cleanup,
+	.cra_aead = {
+		     .setkey = xlp_aes_ctr_hmac_sha256_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_aes_ctr_encrypt,
+		     .decrypt = xlp_aes_ctr_decrypt,
+		     .givencrypt = xlp_aes_ctr_givencrypt,
+		     .geniv = "seqiv", 
+		     .ivsize = CTR_RFC3686_IV_SIZE,
+		     .maxauthsize = SHA256_DIGEST_SIZE,
+		     }
+};
+
+static struct crypto_alg xlp_aes_ctr_hmac_sha1_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(hmac(sha1),rfc3686(ctr(aes)))",
+	.cra_driver_name = "authenc-hmac-sha1-ctr-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = 1,
+	.cra_alignmask = 0,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC ,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_aead_type,
+	.cra_init = aead_cra_init,
+	.cra_exit = aead_session_cleanup,
+	.cra_aead = {
+		     .setkey = xlp_aes_ctr_hmac_sha1_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_aes_ctr_encrypt,
+		     .decrypt = xlp_aes_ctr_decrypt,
+		     .givencrypt = xlp_aes_ctr_givencrypt,
+		     .geniv = "seqiv", 
+		     .ivsize = CTR_RFC3686_IV_SIZE,
+		     .maxauthsize = SHA1_DIGEST_SIZE,
+		     }
+};
+static struct crypto_alg xlp_aes_ctr_aes_xcbc_mac_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(xcbc(aes),rfc3686(ctr(aes)))",
+	.cra_driver_name = "authenc-aes-xcbc-mac-ctr-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = 1,
+	.cra_alignmask = 0,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC ,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_aead_type,
+	.cra_init = aead_cra_init,
+	.cra_aead = {
+		     .setkey = xlp_aes_ctr_aes_xcbc_mac_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_aes_ctr_encrypt,
+		     .decrypt = xlp_aes_ctr_decrypt,
+		     .givencrypt = xlp_aes_ctr_givencrypt,
+		     .geniv = "seqiv", 
+		     .ivsize = CTR_RFC3686_IV_SIZE,
+		     .maxauthsize = XCBC_DIGEST_SIZE,
+		     }
+};
+
+static struct crypto_alg xlp_aes_ctr_hmac_md5_cipher_auth = {
+	/* AEAD algorithms.  These use a single-pass ipsec_esp descriptor */
+	.cra_name = "authenc(hmac(md5),rfc3686(ctr(aes)))",
+	.cra_driver_name = "authenc-hmac-sha1-ctr-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_blocksize = 1,
+	.cra_alignmask = 0,
+	.cra_flags = CRYPTO_ALG_TYPE_AEAD | CRYPTO_ALG_ASYNC ,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_aead_type,
+	.cra_init = aead_cra_init,
+	.cra_aead = {
+		     .setkey = xlp_aes_ctr_hmac_md5_setkey,
+		     .setauthsize = aead_setauthsize,
+		     .encrypt = xlp_aes_ctr_encrypt,
+		     .decrypt = xlp_aes_ctr_decrypt,
+		     .givencrypt = xlp_aes_ctr_givencrypt,
+		     .geniv = "seqiv", 
+		     .ivsize = CTR_RFC3686_IV_SIZE,
+		     .maxauthsize = MD5_DIGEST_SIZE,
+		     }
+};
+int xlp_aead_alg_init(void)
+{
+	int ret = 0;
+	if ((ret = crypto_register_alg(&xlp_aes_cbc_hmac_sha256_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+
+	if ((ret = crypto_register_alg(&xlp_aes_cbc_hmac_sha1_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+
+	if ((ret = crypto_register_alg(&xlp_aes_cbc_aes_xcbc_mac_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+
+	if ((ret = crypto_register_alg(&xlp_aes_cbc_hmac_md5_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+
+	if ((ret = crypto_register_alg(&xlp_3des_cbc_hmac_md5_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+
+	if ((ret = crypto_register_alg(&xlp_3des_cbc_hmac_sha256_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+
+	if ((ret = crypto_register_alg(&xlp_3des_cbc_hmac_sha1_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+
+	if ((ret = crypto_register_alg(&xlp_3des_cbc_aes_xcbc_mac_cipher_auth)))
+		goto end;
+
+	no_of_alg_registered++;
+	if (( ret = crypto_register_alg(&xlp_des_cbc_hmac_md5_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+	if ( (ret = crypto_register_alg(&xlp_des_cbc_hmac_sha256_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+	if ((ret =  crypto_register_alg(&xlp_des_cbc_hmac_sha1_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+	if ((ret =  crypto_register_alg(&xlp_des_cbc_aes_xcbc_mac_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+	if((ret = crypto_register_alg(&xlp_aes_gcm_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+	if ((ret = crypto_register_alg(&xlp_aes_ccm_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+
+	if ((ret = crypto_register_alg(&xlp_aes_ctr_hmac_sha1_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+
+	if ((ret = crypto_register_alg(&xlp_aes_ctr_hmac_sha256_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+
+	if ((ret = crypto_register_alg(&xlp_aes_ctr_aes_xcbc_mac_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+
+	if ((ret = crypto_register_alg(&xlp_aes_ctr_hmac_md5_cipher_auth)))
+		goto end;
+	no_of_alg_registered++;
+end:
+	return no_of_alg_registered;
+} 
+
+	void
+xlp_aead_alg_fini(void)
+{
+	crypto_unregister_alg(&xlp_aes_ctr_hmac_md5_cipher_auth);
+	crypto_unregister_alg(&xlp_aes_ctr_aes_xcbc_mac_cipher_auth);
+	crypto_unregister_alg(&xlp_aes_ctr_hmac_sha256_cipher_auth);
+	crypto_unregister_alg(&xlp_aes_ctr_hmac_sha1_cipher_auth);
+	crypto_unregister_alg(&xlp_aes_ccm_cipher_auth);
+	crypto_unregister_alg(&xlp_aes_gcm_cipher_auth);
+	crypto_unregister_alg(&xlp_des_cbc_aes_xcbc_mac_cipher_auth);
+	crypto_unregister_alg(&xlp_des_cbc_hmac_sha1_cipher_auth);
+	crypto_unregister_alg(&xlp_des_cbc_hmac_sha256_cipher_auth);
+	crypto_unregister_alg(&xlp_des_cbc_hmac_md5_cipher_auth);
+	crypto_unregister_alg(&xlp_3des_cbc_aes_xcbc_mac_cipher_auth);
+	crypto_unregister_alg(&xlp_3des_cbc_hmac_sha1_cipher_auth);
+	crypto_unregister_alg(&xlp_3des_cbc_hmac_sha256_cipher_auth);
+	crypto_unregister_alg(&xlp_3des_cbc_hmac_md5_cipher_auth);
+	crypto_unregister_alg(&xlp_aes_cbc_hmac_md5_cipher_auth);
+	crypto_unregister_alg(&xlp_aes_cbc_aes_xcbc_mac_cipher_auth);
+	crypto_unregister_alg(&xlp_aes_cbc_hmac_sha1_cipher_auth);
+	crypto_unregister_alg(&xlp_aes_cbc_hmac_sha256_cipher_auth);
+}
+
+EXPORT_SYMBOL(xlp_aead_alg_init);
+EXPORT_SYMBOL(xlp_aead_alg_fini);
diff --git a/drivers/netlogic/sae/nlm_async.h b/drivers/netlogic/sae/nlm_async.h
new file mode 100644
index 0000000..0f6a894
--- /dev/null
+++ b/drivers/netlogic/sae/nlm_async.h
@@ -0,0 +1,82 @@
+/*-
+ * Copyright 2003-2012 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
+
+/* This software is available to you under the terms of the GNU General Public
+ * License (GPL) Version 2, available from the file 
+ * http://www.gnu.org/licenses/gpl-2.0.txt
+*/
+
+#ifndef __NLM_ASYNC_H
+#define __NLM_ASYNC_H
+
+#include <crypto/scatterwalk.h>
+#include <linux/byteorder/generic.h>
+
+struct nlm_async_crypto;
+#define MAX_CPU 128
+#define NODE_ID_SHIFT_BIT 5
+#define NODE_BASE_SHIFT_BIT 10
+
+extern int crypto_get_fb_vc(int * node);
+
+struct nlm_async_crypto
+{
+	void (*callback) (struct nlm_async_crypto *args, uint64_t entry1);
+	void *args;
+	int op;
+	int authsize;
+	uint8_t *hash_addr;
+	uint8_t * ddesc;
+	struct scatterlist * src;
+	struct scatterlist * dst;
+	uint16_t stat;
+	uint32_t bytes;
+};
+
+enum enc_stat {
+	DES_CBC_STAT = 0 ,
+	TDES_CBC_STAT ,
+	AES128_CBC_STAT ,
+	AES192_CBC_STAT ,
+	AES256_CBC_STAT, 
+	AES128_CTR_STAT,
+	AES192_CTR_STAT,
+	AES256_CTR_STAT,
+	ENC_MAX_STAT
+};
+enum {
+	MD5_STAT,
+	H_SHA1_STAT,
+	H_SHA256_STAT,
+	AES128_XCBC_STAT,
+	AES192_XCBC_STAT,
+	AES256_XCBC_STAT,
+	GCM_STAT,
+	CCM_STAT,
+	AUTH_MAX_STAT
+};
+
+struct nlm_crypto_stat
+{
+	uint64_t enc[ENC_MAX_STAT];
+	uint64_t enc_tbytes[ENC_MAX_STAT];
+	uint64_t auth[AUTH_MAX_STAT];
+	uint64_t auth_tbytes[AUTH_MAX_STAT];
+};
+
+extern int crypto_vc_base;
+extern int crypto_vc_limit;
+extern int nlm_crypto_sae_num_seg_reqd(void *data, unsigned int buflen);
+extern int nlm_crypto_calc_rem_len(struct scatterlist *sg, unsigned int cipher_len);
+
+extern struct saesoc_data_desc    * fill_src_dst_sg(struct saesoc_session_desc *s_desc,
+		struct saesoc_data_desc    *d_desc,struct nlm_async_crypto *async, 
+		struct scatterlist *src_sg,         struct scatterlist * dst_sg,
+		unsigned int * nfrags,unsigned int cipher_len);
+#endif
diff --git a/drivers/netlogic/sae/nlm_auth.c b/drivers/netlogic/sae/nlm_auth.c
new file mode 100644
index 0000000..40b147d
--- /dev/null
+++ b/drivers/netlogic/sae/nlm_auth.c
@@ -0,0 +1,677 @@
+/*-
+ * Copyright 2003-2012 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
+
+/* This software is available to you under the terms of the GNU General Public
+ * License (GPL) Version 2, available from the file 
+ * http://www.gnu.org/licenses/gpl-2.0.txt
+*/
+
+#include <crypto/sha.h>
+#include <nlm_hal_fmn.h>
+#include <crypto/aes.h>
+#include <crypto/internal/hash.h>
+#include "saesoc_lib.h"
+#include "nlm_async.h"
+//#include <asm/netlogic/msgring.h>
+#include <crypto/scatterwalk.h>
+#include <nlm_xlp.h>
+#include <linux/module.h>
+#include <nlm_msgring.h>
+
+
+#include <linux/proc_fs.h>
+#include <nlm_hal_fmn.h>
+#include <nlm_hal_macros.h>
+#include <linux/module.h>
+#include <nlm_hal.h>
+#include <nlm_xlp.h>
+#include <linux/crypto.h>
+#include <nlm_msgring.h>
+#include "saesoc_lib.h"
+#include "nlm_async.h"
+
+#define XLP_AUTH_PRIORITY      300
+#define XLP_HMAC_PRIORITY      300
+
+#define XCBC_DIGEST_SIZE	16
+
+#define MD5_DIGEST_SIZE		16
+#define MD5_BLOCK_SIZE		64
+
+#undef NLM_CRYPTO_DEBUG
+
+
+#ifdef NLM_CRYPTO_DEBUG
+extern void hex_dump(char * description,unsigned char *in, int num);
+#endif
+
+struct nlm_auth_ctx
+{
+	struct saesoc_session_desc s_desc;
+	unsigned long long key[16];
+	struct saesoc_session_init_params initp;
+	uint16_t stat;
+	uint8_t hashed_key[128]; // can be replace by a local varibale */
+
+	struct crypto_ahash * fallback_tfm;
+	/*Don't change the order of this strucutre*/
+};
+
+#define MAX_FRAGS               18
+#define CTRL_DESC_SIZE          (sizeof(struct nlm_auth_ctx) + 64)
+
+struct app_data_priv 
+{
+	uint32_t total_len;
+	unsigned int nfrags;
+	struct ahash_request * fallback_req;
+};
+
+
+#define PACKET_DESC_SIZE   (64+sizeof(struct saesoc_data_desc) + sizeof(struct app_data_priv) + (MAX_FRAGS*8) + sizeof(struct nlm_async_crypto) + 128 ) /* should be less than PAGE_SIZE/8 */ 
+#define NLM_CRYPTO_DATA_DESC(addr)       (((unsigned long)addr + 64) & ~0x3fUL)
+#define NLM_ASYNC_PTR_PARAM_OFFSET(addr)        ((unsigned long)(addr + 64 + sizeof(struct saesoc_data_desc) + sizeof(struct app_data_priv) + (MAX_FRAGS*8) + 64) & ~0x3fUL)
+#define NLM_CRYPTO_CTRL_DESC(addr ) ( ((unsigned long)addr + 64) & ~(0x3fUL))
+/*
+   All extern declaration goes here.
+ */
+extern struct nlm_crypto_stat crypto_stat[MAX_CPU];
+
+
+static void auth_request_callback(struct nlm_async_crypto *async, uint64_t msg1);
+static inline void print_info(const char *func)
+{
+	extern void dump_stack(void);
+	printk("\n********[%s function called]**********\n",func);
+	dump_stack();
+	printk("\n*********[%s Dumpstack ends]***********\n\n\n",func);
+	return;
+}
+static struct nlm_auth_ctx * ctrl_desc_crypto_ahash_ctx(struct crypto_ahash * ahash)
+{
+	struct crypto_tfm * tfm = crypto_ahash_tfm(ahash);
+	struct nlm_auth_ctx * ctx = (struct nlm_auth_ctx * )NLM_CRYPTO_CTRL_DESC(crypto_tfm_ctx(tfm));
+	return ctx;
+}
+
+
+static struct nlm_auth_ctx * ctrl_desc_req_ahash_ctx(struct ahash_request * req) 
+{
+	struct crypto_ahash * ahash = crypto_ahash_reqtfm(req);
+	return ctrl_desc_crypto_ahash_ctx(ahash);
+}
+static int
+xlp_cra_xcbc_init(struct crypto_tfm *tfm)
+{
+	struct nlm_auth_ctx * nlm_ctx  = (struct nlm_auth_ctx *)NLM_CRYPTO_CTRL_DESC(crypto_tfm_ctx(tfm));
+	nlm_ctx->fallback_tfm = crypto_alloc_ahash("xcbc(aes-generic)",CRYPTO_ALG_TYPE_AHASH ,0 );
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),PACKET_DESC_SIZE);
+	return 0;
+}
+static int
+xlp_cra_hmac_sha1_init(struct crypto_tfm *tfm)
+{
+	struct nlm_auth_ctx * nlm_ctx  = (struct nlm_auth_ctx *)NLM_CRYPTO_CTRL_DESC(crypto_tfm_ctx(tfm));
+	nlm_ctx->fallback_tfm = crypto_alloc_ahash("hmac(sha1-generic)",CRYPTO_ALG_TYPE_AHASH ,0 );
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),PACKET_DESC_SIZE);
+	return 0;
+}
+static int
+xlp_cra_hmac_sha256_init(struct crypto_tfm *tfm)
+{
+	struct nlm_auth_ctx * nlm_ctx  = (struct nlm_auth_ctx *)NLM_CRYPTO_CTRL_DESC(crypto_tfm_ctx(tfm));
+	nlm_ctx->fallback_tfm = crypto_alloc_ahash("hmac(sha256-generic)",CRYPTO_ALG_TYPE_AHASH ,0 );
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),PACKET_DESC_SIZE);
+	return 0;
+}
+
+static int
+xlp_cra_md5_init(struct crypto_tfm *tfm)
+{
+	struct nlm_auth_ctx * nlm_ctx  = (struct nlm_auth_ctx *)NLM_CRYPTO_CTRL_DESC(crypto_tfm_ctx(tfm));
+	nlm_ctx->fallback_tfm = crypto_alloc_ahash("hmac(md5-generic)",CRYPTO_ALG_TYPE_AHASH ,0 );
+	crypto_ahash_set_reqsize(__crypto_ahash_cast(tfm),PACKET_DESC_SIZE);
+	return 0;
+}
+static int
+xlp_auth_init(struct ahash_request *areq)
+{
+
+	struct saesoc_data_desc    *d_desc = (struct saesoc_data_desc    *)NLM_CRYPTO_DATA_DESC(ahash_request_ctx(areq));
+	struct app_data_priv * d_priv = (struct app_data_priv *)((unsigned long)d_desc + sizeof(struct saesoc_data_desc)+(MAX_FRAGS*16)) ;
+	struct nlm_auth_ctx  * auth_ctx   = ctrl_desc_req_ahash_ctx(areq);	
+
+	saesoc_new_data_desc(&auth_ctx->s_desc, &d_desc, MAX_FRAGS , NULL);
+	d_priv->total_len = 0;
+	d_priv->fallback_req = NULL;
+	d_priv->nfrags = MAX_FRAGS;
+	return 0;
+}
+extern 
+int nlm_crypto_calc_rem_len(struct scatterlist *sg, unsigned int cipher_len);
+static int
+xlp_auth_update(struct ahash_request *areq)
+{
+	struct saesoc_data_desc    *d_desc = (struct saesoc_data_desc    *)NLM_CRYPTO_DATA_DESC(ahash_request_ctx(areq));
+	struct app_data_priv * d_priv = (struct app_data_priv *)((unsigned long)d_desc + sizeof(struct saesoc_data_desc)+(MAX_FRAGS*16)) ;
+	struct nlm_async_crypto * async =  (struct nlm_async_crypto *)NLM_ASYNC_PTR_PARAM_OFFSET((unsigned long)d_desc);
+	struct nlm_auth_ctx  * auth_ctx   = ctrl_desc_req_ahash_ctx(areq);	
+	struct saesoc_session_desc *s_desc = &auth_ctx->s_desc;
+	unsigned int nfrags = d_priv->nfrags;
+
+	if ( areq->nbytes == 0 ) 
+		return 0;
+	fill_src_dst_sg(s_desc,d_desc,async,areq->src,areq->src,&nfrags,areq->nbytes);
+	d_priv->nfrags = nfrags;
+
+	d_priv->total_len += areq->nbytes;
+	return 0;
+}
+
+static int
+xlp_auth_final(struct ahash_request *areq)
+{
+
+	struct saesoc_data_desc    *d_desc = (struct saesoc_data_desc    *)NLM_CRYPTO_DATA_DESC(ahash_request_ctx(areq));
+	struct app_data_priv * d_priv = (struct app_data_priv *)((unsigned long)d_desc + sizeof(struct saesoc_data_desc)+(MAX_FRAGS*16)) ;
+	struct nlm_auth_ctx  * auth_ctx   = ctrl_desc_req_ahash_ctx(areq);	
+	int fb_vc ;
+	unsigned long msgrng_flags;
+	int node_sae_base;
+	int node;
+	struct nlm_async_crypto * async =  (struct nlm_async_crypto *)NLM_ASYNC_PTR_PARAM_OFFSET((unsigned long)d_desc);
+	struct saesoc_extra_req_send_params mparam;
+
+	if ( d_priv->total_len == 0 )  { 
+
+
+		d_priv->fallback_req = ahash_request_alloc(auth_ctx->fallback_tfm,GFP_KERNEL);
+		d_priv->fallback_req->nbytes = areq->nbytes;
+		d_priv->fallback_req->src = areq->src;
+		d_priv->fallback_req->result = areq->result;
+		d_priv->fallback_req->base.flags =  areq->base.flags;
+		
+		crypto_ahash_init(d_priv->fallback_req);
+		crypto_ahash_final(d_priv->fallback_req);
+		kfree(d_priv->fallback_req);
+		d_priv->fallback_req = NULL;
+		return 0;
+	}
+
+	saesoc_set_payload_len(d_desc,d_priv->total_len);
+	saesoc_set_tag_dstaddr(d_desc,areq->result);
+	async->ddesc = NULL;
+		
+	preempt_disable();
+	async->callback =  auth_request_callback;
+	async->args = (void *)&areq->base; 
+	async->hash_addr = areq->result;
+	async->stat = auth_ctx->stat; 
+	async->bytes = d_priv->total_len ; 
+
+
+	mparam.async_rsp_arg = (uint64_t)async;
+	mparam.arc4_load_state = 0;
+
+	msgrng_access_enable(msgrng_flags);
+	fb_vc = crypto_get_fb_vc(&node);
+	node_sae_base = (node << NODE_BASE_SHIFT_BIT) | crypto_vc_base;
+	if ( saesoc_process_request(NULL,d_desc,node_sae_base,fb_vc,0,1,&mparam,NULL) !=  CRYPTOSOC_OK ) {
+		msgrng_access_disable(msgrng_flags);
+		preempt_enable();
+		return -EAGAIN; 
+	}
+
+	msgrng_access_disable(msgrng_flags);
+
+ 	return -EINPROGRESS;
+
+}
+static void auth_request_callback(struct nlm_async_crypto *async, uint64_t msg1)
+{
+	struct crypto_async_request *base = (struct crypto_async_request *)async->args;
+	int err = 0;
+
+	if (msg1 & 0x7ff80) {
+		printk("\n Error: entry1 is %llx",msg1);
+		err = -EIO;
+		base->complete(base, err);
+		return ;
+	}
+#if 0
+	int cpu = hard_smp_processor_id();
+	int stat = async->stat & 0xff;
+	crypto_stat[cpu].auth[stat] ++;
+	crypto_stat[cpu].auth_tbytes[stat] += async->bytes;
+#endif
+
+	if ( async->ddesc)
+		kfree(async->ddesc);
+	base->complete(base, err);
+	return;
+}
+
+/*
+   All Setkey goes here.
+ */
+
+static int
+crypto_get_sync_fb_vc(int * node)
+{
+    int cpu;
+    int node_id;
+    extern int ipsec_sync_vc ;
+
+    cpu = hard_smp_processor_id();      //processor_id();
+    node_id = (cpu >> NODE_ID_SHIFT_BIT);
+    cpu = (node_id << NODE_BASE_SHIFT_BIT) | (((cpu & 0x1f) * 4) + ipsec_sync_vc);
+    *node = node_id;
+
+    return cpu;
+}
+int hash_key(int type, int mode, const uint8_t * key, unsigned int keylen, uint8_t * new_key)
+{
+	struct saesoc_session_init_params initp;
+	int fb_vc;
+	int node ;
+	int node_sae_base;
+	uint64_t entry0 = 0, entry1;
+	unsigned long msgrng_flags;
+	int src,size,code,timeout,nsdescs;
+	char * tmp;
+	struct saesoc_session_desc *s_desc;
+	struct saesoc_extra_req_send_params mparam;
+	struct saesoc_data_desc    *d_desc;
+    	extern int ipsec_sync_vc ;
+
+	initp.cipher.type = SAESOC_CIPHER_BYPASS;
+	initp.cipher.key_len = 0;
+	initp.cipher.iv_offset = 0;
+	initp.hash.type = type;
+	initp.hash.mode = mode;
+	initp.hash.iv_offset = 0;
+	initp.hash.iv_mode = 0;
+	initp.hash.key = NULL;
+	initp.hash.key_len = 0;
+	initp.hash.mute_mask_sel = 0;
+	initp.hash.tag_len = saesoc_gen1_tag_len[type] / 8; 
+	initp.hash.tagin_offset = 0;
+	initp.hash.aad_offset =0;
+	initp.hash.addl_hash_len = 0;
+	initp.hash.flags = SAESOC_HF_HASH_L3_ALLOC;
+	initp.payload_offset = 0;
+	initp.flags = SAESOC_IF_DATA_OUT_L3_ALLOC;
+	initp.flags |= SAESOC_HF_HMAC_KEY_PAD_EN;
+
+	nsdescs = saesoc_calc_sdesc_cnt(&initp,NULL);
+	tmp = kmalloc(  sizeof(struct saesoc_session_desc) + (nsdescs * sizeof(_uint64_t))+ 64 + sizeof(struct saesoc_data_desc) + (6 * sizeof(_uint64_t) + 64 + keylen),GFP_KERNEL );
+	s_desc = (struct saesoc_session_desc *)(((unsigned long )tmp + 64UL ) &  ~(0x3fUL));
+	d_desc = (struct saesoc_data_desc    *)(((unsigned long )s_desc + sizeof(struct saesoc_session_desc) + (nsdescs * sizeof(_uint64_t)) + 64UL) & ~(0x3fUL));
+
+	if(saesoc_new_session(&initp,&s_desc,nsdescs, NULL) < 0)
+		printk("%s,%d Error \n", __FUNCTION__, __LINE__);
+
+	if(saesoc_new_data_desc(s_desc, &d_desc, 6,NULL) < 0) 
+		printk("%s,%d Error \n", __FUNCTION__, __LINE__);
+	saesoc_add_frags(d_desc, (char *)key,keylen,(char *)key,keylen);
+	saesoc_set_tag_dstaddr(d_desc,new_key);
+	saesoc_set_payload_len(d_desc, keylen); 
+
+	msgrng_access_enable(msgrng_flags);
+        fb_vc = crypto_get_sync_fb_vc(&node);
+
+	mparam.async_rsp_arg = 0xdeadbeef;
+	mparam.arc4_load_state = 0;
+        //construct pkt, send to engine and receive reply
+	node_sae_base = (node << NODE_BASE_SHIFT_BIT) | crypto_vc_base;
+	saesoc_process_request(NULL,d_desc,node_sae_base,fb_vc,0,9000,&mparam,NULL);
+
+        timeout = 0;
+        do {
+                timeout++;
+                xlp_message_receive_2(ipsec_sync_vc, &src, &size, &code, &entry0, &entry1);
+
+        } while(entry0 != 0xdeadbeef && timeout < 0xfffffUL) ;
+	kfree(tmp);
+	msgrng_access_disable(msgrng_flags);
+	return 0;
+
+	
+
+}
+
+static int auth_setkey(struct crypto_ahash *tfm, const u8 * key, unsigned int keylen, int blocksize,int type, int stat)
+{
+	struct nlm_auth_ctx * nlm_ctx = ctrl_desc_crypto_ahash_ctx(tfm);
+	struct saesoc_session_init_params * initp = &nlm_ctx->initp;
+	int nsdescs;
+	char * final_key = (char *)key;
+	int final_keylen = keylen;
+	struct saesoc_session_desc *s_desc = &nlm_ctx->s_desc;
+
+
+	nlm_ctx->stat = stat;
+	if ( keylen > blocksize ) {
+
+		hash_key(type,0,key,keylen,&nlm_ctx->hashed_key[0]);
+		crypto_ahash_setkey(nlm_ctx->fallback_tfm,nlm_ctx->hashed_key,64);
+		final_key = &nlm_ctx->hashed_key[0];
+		final_keylen = blocksize;
+	}
+	else
+		crypto_ahash_setkey(nlm_ctx->fallback_tfm,key,keylen);
+
+	if ( keylen == blocksize ) {
+		initp->hash.key = final_key;
+		initp->hash.key_len = final_keylen;
+	}
+	if( keylen < blocksize ) {
+		memset(&nlm_ctx->hashed_key[0],0,blocksize);
+		memcpy(&nlm_ctx->hashed_key[0],key,keylen);
+		initp->hash.key =&nlm_ctx->hashed_key[0];
+		initp->hash.key_len = blocksize ;
+	}
+
+	initp->cipher.type = SAESOC_CIPHER_BYPASS;
+	initp->cipher.key_len = 0;
+	initp->hash.type = type;
+	initp->hash.mode = SAESOC_HASH_MODE_HMAC;
+	initp->hash.iv_offset = 0;
+	initp->hash.mute_mask_sel = 0;
+	initp->hash.tag_len = saesoc_gen1_tag_len[type] / 8;
+	initp->hash.tagin_offset = 0;
+	initp->hash.aad_offset =0;
+	initp->hash.addl_hash_len = 0;
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC;
+	initp->hash.key_len = blocksize;
+	initp->hash.flags |= SAESOC_HF_HMAC_KEY_PAD_EN;
+	initp->payload_offset = 0;
+	initp->flags = SAESOC_IF_DATA_OUT_L3_ALLOC;
+
+	nsdescs = saesoc_calc_sdesc_cnt(&nlm_ctx->initp,NULL);
+
+	if(  ((unsigned long)nlm_ctx + sizeof(struct saesoc_session_desc) + (nsdescs * sizeof(_uint64_t))) > (unsigned long)&nlm_ctx->initp) {
+		printk("MEMORY OVERFLOW\n"); 
+		return -1;
+	}
+
+
+	if(saesoc_new_session(&nlm_ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		printk("%s,%d Error \n", __FUNCTION__, __LINE__);
+
+
+	nlm_ctx->stat = H_SHA1_STAT;
+
+	return 0;
+	 
+	
+}
+
+
+
+static int xlp_auth_aes_xcbc_setkey(struct crypto_ahash *tfm, const u8 * key, unsigned int keylen)
+{
+	struct nlm_auth_ctx * nlm_ctx = ctrl_desc_crypto_ahash_ctx(tfm);
+	uint32_t hash_alg = SAESOC_HASH_TYPE_AES_128;
+	struct saesoc_session_init_params * initp = &nlm_ctx->initp;
+	struct saesoc_session_desc *s_desc = &nlm_ctx->s_desc;
+	int nsdescs;
+
+        switch (keylen) {
+        case 16:
+                hash_alg = SAESOC_HASH_TYPE_AES_128;
+		nlm_ctx->stat = AES128_XCBC_STAT;
+                break;
+        case 24:
+                hash_alg = SAESOC_HASH_TYPE_AES_192;
+		nlm_ctx->stat = AES192_XCBC_STAT;
+                break;
+        case 32:
+                hash_alg = SAESOC_HASH_TYPE_AES_256;
+		nlm_ctx->stat = AES256_XCBC_STAT;
+                break;
+        default:
+                printk(KERN_WARNING "[%s]: Cannot handle keylen = %d\n",
+                       __FUNCTION__, keylen);
+	}
+
+	/*setup ctrl descriptor*/
+
+	initp->hash.key = (char *)key;
+	initp->hash.key_len = keylen ;
+	initp->cipher.type = SAESOC_CIPHER_BYPASS;
+	initp->cipher.key_len = 0;
+	initp->hash.type = hash_alg;
+	initp->hash.mode = SAESOC_HASH_MODE_XCBC;
+	initp->hash.iv_offset = 0;
+	initp->hash.mute_mask_sel = 0;
+	initp->hash.tag_len = saesoc_gen1_tag_len[hash_alg] / 8;
+	initp->hash.tagin_offset = 0;
+	initp->hash.aad_offset =0;
+	initp->hash.addl_hash_len = 0;
+	initp->hash.flags = SAESOC_HF_HASH_L3_ALLOC;
+	initp->payload_offset = 0;
+	initp->flags = SAESOC_IF_DATA_OUT_L3_ALLOC;
+
+	nsdescs = saesoc_calc_sdesc_cnt(&nlm_ctx->initp,NULL);
+
+	if(saesoc_new_session(&nlm_ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		printk("%s,%d Error \n", __FUNCTION__, __LINE__);
+
+	
+	crypto_ahash_setkey(nlm_ctx->fallback_tfm,key,keylen);
+
+	
+	return 0;
+	
+}
+
+
+static int
+xlp_auth_hmac_md5_setkey(struct crypto_ahash *tfm, const u8 * key, unsigned int keylen)
+{
+	return auth_setkey(tfm,key,keylen,MD5_BLOCK_SIZE,SAESOC_HASH_TYPE_MD5,MD5_STAT);
+}
+static int
+xlp_auth_hmac_sha256_setkey(struct crypto_ahash *tfm, const u8 * key, unsigned int keylen)
+{
+	return auth_setkey(tfm,key,keylen,SHA256_BLOCK_SIZE,SAESOC_HASH_TYPE_SHA_256,H_SHA256_STAT);
+}
+
+static int
+xlp_auth_hmac_sha1_setkey(struct crypto_ahash *tfm, const u8 * key, unsigned int keylen)
+{
+	return auth_setkey(tfm,key,keylen,SHA1_BLOCK_SIZE,SAESOC_HASH_TYPE_SHA_1,H_SHA1_STAT);
+}
+
+static int xlp_auth_digest(struct ahash_request *areq)
+{
+	struct saesoc_data_desc    *d_desc = (struct saesoc_data_desc    *)NLM_CRYPTO_DATA_DESC(ahash_request_ctx(areq));
+	struct app_data_priv * d_priv = (struct app_data_priv *)((unsigned long)d_desc + sizeof(struct saesoc_data_desc)+(MAX_FRAGS*16)) ;
+	int fb_vc ;
+	unsigned long msgrng_flags;
+	int node_sae_base;
+	int node;
+	struct nlm_async_crypto * async =  (struct nlm_async_crypto *)NLM_ASYNC_PTR_PARAM_OFFSET((unsigned long)d_desc);
+	struct saesoc_extra_req_send_params mparam;
+	struct nlm_auth_ctx  * auth_ctx   = ctrl_desc_req_ahash_ctx(areq);	
+	struct saesoc_session_desc *s_desc = &auth_ctx->s_desc;
+	unsigned int nfrags = MAX_FRAGS;
+
+	if ( areq->nbytes == 0 )  { 
+
+
+		d_priv->fallback_req = ahash_request_alloc(auth_ctx->fallback_tfm,GFP_KERNEL);
+		d_priv->fallback_req->nbytes = areq->nbytes;
+		d_priv->fallback_req->src = areq->src;
+		d_priv->fallback_req->result = areq->result;
+		d_priv->fallback_req->base.flags =  areq->base.flags;
+		
+		crypto_ahash_init(d_priv->fallback_req);
+		crypto_ahash_final(d_priv->fallback_req);
+		kfree(d_priv->fallback_req);
+		d_priv->fallback_req = NULL;
+		return 0;
+	}
+	saesoc_new_data_desc(&auth_ctx->s_desc, &d_desc, MAX_FRAGS , NULL);
+	async->ddesc = NULL;
+
+	d_desc= fill_src_dst_sg(s_desc,d_desc,async,areq->src,areq->src,&nfrags,areq->nbytes);
+	saesoc_set_payload_len(d_desc,areq->nbytes);
+	saesoc_set_tag_dstaddr(d_desc,areq->result);
+
+	preempt_disable();
+	async->callback =  auth_request_callback;
+	async->args = (void *)&areq->base; 
+	async->hash_addr = areq->result;
+	async->stat = auth_ctx->stat; 
+	async->bytes = areq->nbytes ; 
+
+	mparam.async_rsp_arg = (uint64_t)async;
+	mparam.arc4_load_state = 0;
+
+	msgrng_access_enable(msgrng_flags);
+	fb_vc = crypto_get_fb_vc(&node);
+	node_sae_base = (node << NODE_BASE_SHIFT_BIT) | crypto_vc_base;
+	if ( saesoc_process_request(NULL,d_desc,node_sae_base,fb_vc,0,1,&mparam,NULL) !=  CRYPTOSOC_OK ) {
+		msgrng_access_disable(msgrng_flags);
+		preempt_enable();
+		return -EAGAIN; 
+	}
+	msgrng_access_disable(msgrng_flags);
+	preempt_enable();
+
+ 	return -EINPROGRESS;
+}
+
+static struct ahash_alg xcbc_mac_alg = {
+	.init = xlp_auth_init,
+	.update = xlp_auth_update,
+	.final = xlp_auth_final,
+	.setkey = xlp_auth_aes_xcbc_setkey,
+	.digest = xlp_auth_digest,
+	.halg = {
+		.digestsize = XCBC_DIGEST_SIZE, 
+		.base = {
+		 .cra_name = "xcbc(aes)",
+		 .cra_driver_name = "xcbc-aes-xlp",
+		 .cra_priority = XLP_HMAC_PRIORITY,
+		 .cra_flags = CRYPTO_ALG_TYPE_AHASH,
+		 .cra_blocksize = AES_BLOCK_SIZE,
+		 .cra_module = THIS_MODULE,
+		 .cra_ctxsize = CTRL_DESC_SIZE, 
+		 .cra_init = xlp_cra_xcbc_init,
+		 }
+	}
+};
+
+static struct ahash_alg sha256_hmac_alg = {
+	.init = xlp_auth_init,
+	.update = xlp_auth_update,
+	.final = xlp_auth_final,
+	.setkey = xlp_auth_hmac_sha256_setkey,
+	.digest = xlp_auth_digest,
+	.halg = {
+	.digestsize = SHA256_DIGEST_SIZE,
+	.base = {
+		 .cra_name = "hmac(sha256)",
+		 .cra_driver_name = "hmac-sha256-xlp",
+		 .cra_priority = XLP_HMAC_PRIORITY,
+		 .cra_flags = CRYPTO_ALG_TYPE_AHASH,
+		 .cra_blocksize = SHA256_BLOCK_SIZE,
+		 .cra_module = THIS_MODULE,
+		 .cra_ctxsize = CTRL_DESC_SIZE, 
+		 .cra_init = xlp_cra_hmac_sha256_init,
+		 }
+	}
+};
+
+static struct ahash_alg md5_hmac_alg = {
+	.init = xlp_auth_init,
+	.update = xlp_auth_update,
+	.final = xlp_auth_final,
+	.setkey = xlp_auth_hmac_md5_setkey,
+	.digest = xlp_auth_digest,
+	.halg = {
+	.digestsize = MD5_DIGEST_SIZE,
+	.base = {
+		 .cra_name = "hmac(md5)",
+		 .cra_driver_name = "hmac-md5-xlp",
+		 .cra_priority = XLP_HMAC_PRIORITY,
+		 .cra_flags = CRYPTO_ALG_TYPE_AHASH,
+		 .cra_blocksize = MD5_BLOCK_SIZE,
+		 .cra_module = THIS_MODULE,
+		 .cra_ctxsize = CTRL_DESC_SIZE, 
+		 .cra_init = xlp_cra_md5_init,
+		 }
+	}
+};
+static struct ahash_alg sha1_hmac_alg = {
+	.init = xlp_auth_init,
+	.update = xlp_auth_update,
+	.final = xlp_auth_final,
+	.setkey = xlp_auth_hmac_sha1_setkey,
+	.digest = xlp_auth_digest,
+	.halg = {
+	.digestsize = SHA1_DIGEST_SIZE,
+	.base = {
+		 .cra_name = "hmac(sha1)",
+		 .cra_driver_name = "hmac-sha1-xlp",
+		 .cra_priority = XLP_HMAC_PRIORITY,
+		 .cra_flags = CRYPTO_ALG_TYPE_AHASH,
+		 .cra_blocksize = SHA1_BLOCK_SIZE,
+		 .cra_module = THIS_MODULE,
+		 .cra_ctxsize = CTRL_DESC_SIZE, 
+		 .cra_init = xlp_cra_hmac_sha1_init,
+		 }
+	}
+};
+
+int
+xlp_auth_alg_init(void)
+{
+	int rc = -ENODEV;
+	int no_of_alg_registered = 0;
+
+	rc = crypto_register_ahash(&sha1_hmac_alg);
+	if (rc)
+		goto out;
+	no_of_alg_registered++;
+	rc = crypto_register_ahash(&sha256_hmac_alg);
+	if (rc)
+		goto out;
+	no_of_alg_registered++;
+	rc = crypto_register_ahash(&md5_hmac_alg);
+	if (rc)
+		goto out;
+	no_of_alg_registered++;
+	rc = crypto_register_ahash(&xcbc_mac_alg);
+	if (rc)
+		goto out;
+	no_of_alg_registered++; 
+	//printk("Some of the FIPS test failed as the maximum key length supported is 64 bytes.\n");
+
+	printk(KERN_NOTICE "Using XLP hardware for SHA/MD5 algorithms.\n");
+out:
+
+	return 0;
+
+}
+
+void
+xlp_auth_alg_fini(void)
+{
+	crypto_unregister_ahash(&xcbc_mac_alg);
+	crypto_unregister_ahash(&md5_hmac_alg);
+	crypto_unregister_ahash(&sha256_hmac_alg);
+	crypto_unregister_ahash(&sha1_hmac_alg);
+}
+
+EXPORT_SYMBOL(xlp_auth_alg_init);
+EXPORT_SYMBOL(xlp_auth_alg_fini);
diff --git a/drivers/netlogic/sae/nlm_crypto.c b/drivers/netlogic/sae/nlm_crypto.c
new file mode 100644
index 0000000..8dda388
--- /dev/null
+++ b/drivers/netlogic/sae/nlm_crypto.c
@@ -0,0 +1,484 @@
+/*-
+ * Copyright 2003-2012 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
+/*
+ * This software is available to you under the terms of the GNU General Public
+ * License (GPL) Version 2, available from the file 
+ * http://www.gnu.org/licenses/gpl-2.0.txt
+ */
+#include <linux/proc_fs.h>
+#include <nlm_hal_fmn.h>
+#include <nlm_hal_macros.h>
+#include <linux/module.h>
+#include <nlm_hal.h>
+#include <nlm_xlp.h>
+#include <linux/crypto.h>
+#include <nlm_msgring.h>
+#include "saesoc_lib.h"
+#include "nlm_async.h"
+
+
+
+#ifdef TRACING
+#define TRACE_TEXT(str) printk(str);
+#define TRACE_RET printk(")")
+#else				/* !TRACING */
+#define TRACE_TEXT(str) ((void) 0)
+#define TRACE_RET ((void) 0)
+#endif				/* TRACING */
+#undef NLM_CRYPTO_DEBUG
+#define NETL_OP_ENCRYPT 1
+#define NETL_OP_DECRYPT 0
+int cryptosoc_lib_priv_init(void)
+{
+	return 0;
+}
+int cryptosoc_lib_priv_finish(void){
+	return 0;
+}
+int crypto_get_soc_vc_numbers(enum cryptosoc_soc_type soc, int *base_vc, int *lmt_vc)
+{
+	if ( soc == CRYPTOSOC_SAE )
+		nlm_hal_get_crypto_vc_nums(base_vc,lmt_vc);
+	return 0;
+}
+
+
+
+/**
+ * @defgroup crypto Crypto API
+ * @brief Description about the crypto apis
+ */
+
+#define printf(a, b...) printk(KERN_ERR a, ##b)
+
+#define xtract_bits(x, bitpos, numofbits) ((x) >> (bitpos) & ((1ULL << (numofbits)) - 1))
+
+extern struct proc_dir_entry *nlm_root_proc;
+extern int xlp_aead_alg_init(void);
+extern void xlp_aead_alg_fini(void);
+extern int xlp_crypt_alg_init(void);
+extern void xlp_crypt_alg_fini(void);
+extern int xlp_auth_alg_init(void);
+extern void xlp_auth_alg_fini(void);
+static void  xlp_sae_cleanup(void);
+
+static int xlp_sae_major;
+static int xlp_sae_open(struct inode *, struct file *);
+static int xlp_sae_release(struct inode *, struct file *);
+
+struct nlm_crypto_stat crypto_stat[MAX_CPU];
+int crypto_vc_base;
+int crypto_vc_limit;
+int nlm_crypto_chip_features = 0 ;
+
+#define NLM_CRYPTO_MAX_STR_LEN 200
+
+int alloc_data_desc( struct nlm_async_crypto * async,struct saesoc_data_desc  ** d_desc,struct saesoc_session_desc *s_desc, int max_frags)
+{
+	uint8_t * new_data_desc = NULL;
+
+	if ( async->ddesc ) {
+		kfree(async->ddesc);
+	}
+
+	async->ddesc = kmalloc((sizeof (struct saesoc_data_desc) + ( max_frags * 8 )+ 64),GFP_KERNEL);
+
+	new_data_desc = (uint8_t * )(((unsigned long)async->ddesc + 64) & ~0x3fUL);
+
+	*d_desc = (struct saesoc_data_desc  *)new_data_desc;
+
+	
+	return 1;
+}
+
+int nlm_crypto_sae_num_seg_reqd(void *data, unsigned int buflen)
+{
+	return saesoc_calc_frags_desc_cnt(NULL,data,buflen,data,buflen);
+}
+
+int nlm_crypto_calc_rem_len(struct scatterlist *sg, unsigned int cipher_len)
+{
+	int len,seg = 0;
+	for (;cipher_len > 0;sg = scatterwalk_sg_next(sg)){
+		len = min(cipher_len, sg->length);
+		seg += nlm_crypto_sae_num_seg_reqd(sg,len);
+		cipher_len -= len;
+	}
+	return seg;
+}
+
+struct saesoc_data_desc  *  fill_src_dst_sg(struct saesoc_session_desc *s_desc,
+		struct saesoc_data_desc    *d_desc ,struct nlm_async_crypto *async, 
+		struct scatterlist *src_sg,         struct scatterlist * dst_sg,
+		unsigned int * nfrags, unsigned int cipher_len)
+{
+	struct scatterlist *sg, *sg_s,*sg_d;
+	unsigned int len;
+	uint8_t *virt = NULL, *src, *dst;
+	int rv = 0;
+	unsigned long dest_paddr, src_paddr;
+	struct scatter_walk walk;
+	unsigned int max_frags = *nfrags;
+	
+
+	if (src_sg == dst_sg ) {
+		for( sg = src_sg; sg != NULL ; sg = scatterwalk_sg_next(sg)) {
+			len = min(cipher_len, sg->length);
+			scatterwalk_start(&walk, sg);
+			src_paddr = page_to_phys(scatterwalk_page(&walk)) + offset_in_page(walk.offset);
+			virt = phys_to_virt(src_paddr);
+			if ( cipher_len > 0 ) {
+				struct saesoc_data_desc * ddesc_new;
+				rv = saesoc_add_frags(d_desc,virt,len,virt,len);
+				if ( rv != CRYPTOSOC_OK ) {
+					rv = nlm_crypto_calc_rem_len(sg,cipher_len);
+				        rv = rv + max_frags + 4 + 2 /* ccm extra cipher len */; 
+					alloc_data_desc(async,&ddesc_new, s_desc,rv);
+					* nfrags = rv + max_frags;
+					saesoc_copy_ddesc(d_desc,&ddesc_new,rv,NULL);
+					d_desc = ddesc_new;
+					saesoc_add_frags(d_desc,virt,len,virt,len);
+
+				}
+			}
+			cipher_len -= len;
+		}
+		return d_desc;
+	}
+	else
+	{
+		struct scatter_walk walk1,walk2;
+
+
+		for( sg_s = src_sg, sg_d = dst_sg; 
+				sg_s != NULL && sg_d != NULL; 
+				sg_s = scatterwalk_sg_next(sg_s),
+				sg_d = scatterwalk_sg_next(sg_d)) {
+		scatterwalk_start(&walk1, sg_s);
+		scatterwalk_start(&walk2, sg_d);
+		src_paddr = page_to_phys(scatterwalk_page(&walk1)) + offset_in_page(walk1.offset);
+		src = phys_to_virt(src_paddr);
+		dest_paddr = page_to_phys(scatterwalk_page(&walk2)) + offset_in_page(walk2.offset);
+		dst = phys_to_virt(dest_paddr);
+
+		len = min(cipher_len, sg_s->length);
+		saesoc_add_frags(d_desc,src,len,dst,len);
+		cipher_len -= len;
+		}
+
+
+		
+	}
+	return d_desc;
+}
+
+
+
+    static void
+reset_crypto_stats(void)
+{
+    int i, j;
+    for (i = 0; i < MAX_CPU; i++) {
+	for (j = 0; j < ENC_MAX_STAT; j++) {
+		crypto_stat[i].enc[j] = 0;
+		crypto_stat[i].enc_tbytes[j] = 0;
+	}
+	for (j = 0; j < AUTH_MAX_STAT; j++) {
+		crypto_stat[i].auth[j] = 0;
+		crypto_stat[i].auth_tbytes[j] = 0;
+	}
+		
+    }
+
+}
+
+int
+crypto_get_fb_vc(int * node)
+{
+    int cpu;
+    int node_id = 0;
+    extern int ipsec_async_vc;
+
+
+    cpu = hard_smp_processor_id();	//processor_id();
+    node_id = (cpu >> NODE_ID_SHIFT_BIT);
+    cpu = (node_id << NODE_BASE_SHIFT_BIT) | (((cpu & 0x1f) * 4) + ipsec_async_vc);
+    *node = node_id;
+
+    return cpu;
+}
+
+static const struct file_operations xlp_sae_fops = {
+    .owner = THIS_MODULE,
+    .open = xlp_sae_open,
+    .release = xlp_sae_release,
+};
+
+/* Note that nobody ever sets xlp_sae_busy... */
+    static int
+xlp_sae_open(struct inode *inode, struct file *file)
+{
+    TRACE_TEXT("(xlp_sae_open");
+    return 0;
+}
+
+    static int
+xlp_sae_release(struct inode *inode, struct file *file)
+{
+    TRACE_TEXT("(xlp_sae_release");
+
+    return 0;
+}
+
+    static void
+nlm_xlp_sae_msgring_handler(uint32_t vc, uint32_t src_id,
+	uint32_t size, uint32_t code,
+	uint64_t msg0, uint64_t msg1,
+	uint64_t msg2, uint64_t msg3, void *data)
+{
+	struct nlm_async_crypto *async = (struct nlm_async_crypto *)(unsigned long )msg0;
+	if(async)	
+		async->callback(async, msg1);
+}
+#if 0
+static int
+nlm_crypto_read_stats_proc(char *page, char **start, off_t off, int count,
+                       int *eof, void *data)
+{
+        int len = 0;
+	int i,j;
+	off_t begin = 0;
+	uint64_t enc_tp[ENC_MAX_STAT];
+	uint64_t auth_tp[AUTH_MAX_STAT];
+	uint64_t enc_tb[ENC_MAX_STAT];
+	uint64_t auth_tb[AUTH_MAX_STAT];
+
+	len += sprintf(page + len, "\t\tPkt\t\tTotal Bytes\n");
+
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+	for(j =0 ;j <= ENC_MAX_STAT ; j++) {
+		enc_tp[j] = 0;	
+		enc_tb[j] = 0;
+		for(i = 0; i < MAX_CPU; i++)  {
+			enc_tp[j] = enc_tp[j] + crypto_stat[i].enc[j];
+			enc_tb[j] = enc_tb[j] + crypto_stat[i].enc_tbytes[j];
+		}
+			
+	}
+
+	len += sprintf(page + len,"DES-CBC\t\t%lld\t\t%lld\nTDES-CBC\t%lld\t\t%lld\nAES128-CBC\t%lld\t\t%lld\n",
+			enc_tp[DES_CBC_STAT],enc_tb[DES_CBC_STAT],enc_tp[TDES_CBC_STAT],enc_tb[TDES_CBC_STAT],
+			enc_tp[AES128_CBC_STAT],enc_tb[AES128_CBC_STAT]);
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	len += sprintf(page + len,"AES192-CBC\t%lld\t\t%lld\nAES256-CBC\t%lld\t\t%lld\nAES128-CTR\t%lld\t\t%lld\n",
+		enc_tp[AES192_CBC_STAT],enc_tb[AES192_CBC_STAT],enc_tp[AES256_CBC_STAT],enc_tb[AES256_CBC_STAT],
+		enc_tp[AES128_CTR_STAT],enc_tb[AES128_CTR_STAT]);
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	len += sprintf(page + len,"AES192-CTR\t%lld\t\t%lld\nAES256-CTR\t%lld\t\t%lld\n",
+		enc_tp[AES192_CTR_STAT],enc_tb[AES192_CTR_STAT],enc_tp[AES256_CTR_STAT],enc_tb[AES256_CTR_STAT]);
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	for(j =0 ;j < AUTH_MAX_STAT; j++) {
+		auth_tp[j] = 0;
+		auth_tb[j] = 0;
+		for(i = 0; i < MAX_CPU; i++) { 
+			auth_tp[j] +=  crypto_stat[i].auth[j];
+			auth_tb[j] += crypto_stat[i].auth_tbytes[j];
+		}
+	}
+
+	len  += sprintf(page + len,"MD5\t\t%lld\t\t%lld\nH-SHA1\t\t%lld\t\t%lld\nH-SHA256\t%lld\t\t%lld\n",
+				    auth_tp[MD5_STAT],auth_tb[MD5_STAT],auth_tp[H_SHA1_STAT],auth_tb[H_SHA1_STAT],auth_tp[H_SHA256_STAT],auth_tb[H_SHA256_STAT]);
+	if (!proc_pos_check(&begin, &len, off, count))
+		 goto out;
+
+	len  += sprintf(page + len,"AES128-XCBC\t%lld\t\t%lld\nAES198-XCBC\t%lld\t\t%lld\nAES256-XCBC\t%lld\t\t%lld\n",
+		auth_tp[AES128_XCBC_STAT],auth_tb[AES128_XCBC_STAT],auth_tp[AES192_XCBC_STAT],auth_tb[AES192_XCBC_STAT],auth_tp[AES256_XCBC_STAT],auth_tb[AES256_XCBC_STAT]);
+
+	if (!proc_pos_check(&begin, &len, off, count))
+		 goto out;
+
+	len  += sprintf(page + len,"GCM\t\t%lld\t\t%lld\nCCM\t\t%lld\t\t%lld\n",auth_tp[GCM_STAT],auth_tb[GCM_STAT],auth_tp[CCM_STAT],auth_tb[CCM_STAT]);
+
+	if (!proc_pos_check(&begin, &len, off, count))
+		 goto out;
+
+        *eof = 1;
+
+      out:
+        *start = page + (off - begin);
+        len -= (off - begin);
+        if (len > count)
+                len = count;
+        if (len < 0)
+                len = 0;
+
+        return len;
+
+}
+#endif
+int nlm_crypto_clear_stat_proc(struct file *file, const char __user *buffer, 
+		unsigned long count, void *data)
+{
+	char buf[16];
+	unsigned long val;
+
+	copy_from_user(buf, buffer, count);
+	val =  simple_strtol(buf, NULL, 0);	
+
+	if ( val  == 1)
+    		reset_crypto_stats();
+
+	return 1;
+
+}
+int
+nlm_crypto_init(void)
+{
+    int ret = 0;
+#if 0
+    struct proc_dir_entry *entry = NULL;
+    struct proc_dir_entry *clear_entry  = NULL;
+
+    entry = create_proc_read_entry("crypto_stats", 0, nlm_root_proc,
+		    nlm_crypto_read_stats_proc,
+		    0);
+
+    if(entry == NULL) {
+	    printk("%s:%d failed creating proc stats entry.\n",
+			    __FUNCTION__, __LINE__);
+	    ret = -EINVAL;
+    }
+
+    clear_entry = create_proc_entry("clear_crypto_stats", S_IFREG|S_IRUGO|S_IWUSR,nlm_root_proc);
+
+    if ( clear_entry != NULL ) {
+	   clear_entry->write_proc = nlm_crypto_clear_stat_proc;
+    }
+
+#endif
+   crypto_get_soc_vc_numbers(CRYPTOSOC_SAE,&crypto_vc_base, &crypto_vc_limit); 
+   printf("crypto vc base %d\n",crypto_vc_base);
+
+    if (register_xlp_msgring_handler
+		    (XLP_MSG_HANDLE_CRYPTO, nlm_xlp_sae_msgring_handler, NULL)) {
+	    panic("can't register msgring handler for TX_STN_GMAC0");
+    }
+    reset_crypto_stats();
+
+
+
+    return ret;
+}
+static void  init_sae(void)
+{
+	extern void *fdt;
+	int freq;
+	int node;
+
+	freq = nlm_hal_get_fdt_freq(fdt, NLM_SAE);
+
+	for_each_node(node) {
+
+		nlm_hal_set_sae_freq(node, freq);
+		nlm_hal_set_sae_engine_sel(node);
+	}
+
+}
+
+
+void *mem_alloc(size_t align, size_t size)
+{
+	printf("%s called free \n", __FUNCTION__);
+	return NULL;
+}
+
+void mem_free(void *addr) 
+{
+	printf("%s called free \n", __FUNCTION__);
+}
+
+struct cryptosoc_lib_params lparam;
+
+#if 0
+int nlm_hal_get_sae_chip_feature()
+{
+	return 0;
+}
+#endif
+
+static int __init xlp_sae_init(void)
+{
+    extern int ipsec_sync_vc;
+    extern int ipsec_async_vc;
+
+    printk(KERN_ERR ",\n XLP SAE/Crypto Initialization \n");
+    printk("ipsec_sync_vc %d ipsec_async_vc %d\n",ipsec_sync_vc,ipsec_async_vc);
+    if (is_nlm_xlp9xx())
+        cryptosoc_ptype_gen = CRYPTOSOC_PTYPE_IS_GEN2;
+    else
+        cryptosoc_ptype_gen = CRYPTOSOC_PTYPE_IS_GEN1;
+
+    xlp_sae_major = register_chrdev(0, "NLM_XLP_SAE", &xlp_sae_fops);
+    if (xlp_sae_major < 0) {
+	printk(KERN_ERR "XLP_SAE - cannot register device\n");
+	return xlp_sae_major;
+    }
+    //  printk (KERN_ERR ",XLP SAE MAJOR %d\n", xlp_sae_major);
+    if ( (ipsec_async_vc == -1) && (ipsec_sync_vc == -1) )  {
+	printk(KERN_ERR "XLP_SAE - cannot be loaeded,Please set ipsec-async-vc and ipsec-sync-vc in the dts file\n");
+    	return -1;
+    }
+    nlm_crypto_init();
+    init_sae();
+    //nlm_crypto_chip_features = nlm_hal_get_sae_chip_feature();
+    /* Initialize the library */
+    if(cryptosoc_lib_init(&lparam, &mem_alloc, &mem_free, NULL) < 0) {
+	    printf("%s,%d Error \n", __FUNCTION__, __LINE__);
+	    return 0;
+    }
+
+    if(ipsec_async_vc != -1){
+    	xlp_crypt_alg_init();
+    	xlp_aead_alg_init();
+    }else{
+	printk(KERN_ERR "Cannot perform aead/enc operation, Please set ipsec-async-vc in the dts file\n");
+    }
+    if(ipsec_sync_vc != -1){
+    	xlp_auth_alg_init();
+	    ;
+    }else{
+	printk(KERN_ERR "Cannot perform auth operation, Please exclude ipsec_sync_vc from the node-vc-mask in dts\n");	
+	return 0;
+    }
+
+    return 0;
+}
+
+    static void  __exit
+xlp_sae_cleanup(void)
+{
+    xlp_crypt_alg_fini();
+    xlp_auth_alg_fini();
+    xlp_aead_alg_fini();
+    unregister_chrdev(xlp_sae_major, "NLM_XLP_SAE");
+    return ;
+}
+
+module_init(xlp_sae_init);
+module_exit(xlp_sae_cleanup);
+MODULE_DESCRIPTION("XLP Hardware crypto support for AES/DES/3DES/SHA/MD5 .");
+MODULE_LICENSE("GPL");
+MODULE_VERSION("0.1");
diff --git a/drivers/netlogic/sae/nlm_enc.c b/drivers/netlogic/sae/nlm_enc.c
new file mode 100644
index 0000000..0afefb1
--- /dev/null
+++ b/drivers/netlogic/sae/nlm_enc.c
@@ -0,0 +1,504 @@
+/*-
+ * Copyright 2003-2012 Broadcom Corporation
+ *
+ * This is a derived work from software originally provided by the entity or
+ * entities identified below. The licensing terms, warranty terms and other
+ * terms specified in the header of the original work apply to this derived work
+ *
+ * #BRCM_1# */
+
+/* This software is available to you under the terms of the GNU General Public
+ * License (GPL) Version 2, available from the file 
+ * http://www.gnu.org/licenses/gpl-2.0.txt
+*/
+
+#include <linux/crypto.h>
+#include <crypto/aes.h>
+#include <crypto/des.h>
+#include <crypto/ctr.h>
+#include <nlm_hal_fmn.h>
+#include <linux/module.h>
+
+#include <nlm_xlp.h>
+#include <nlm_msgring.h>
+#include "saesoc_lib.h"
+#include "nlm_async.h"
+#undef NLM_CRYPTO_DEBUG
+
+
+#define XLP_CRYPT_PRIORITY	300
+
+
+
+struct nlm_enc_ctx {
+	struct saesoc_session_desc enc_s_desc;
+	/* max key length is 256 bits */
+	unsigned long long key[16];
+	struct saesoc_session_desc dec_s_desc;
+	/* max key length is 256 bits */
+	unsigned long long dec_key[16];
+	struct saesoc_session_init_params initp;
+	/* to be removed*/
+	uint16_t stat;
+	char nonce[4];
+};
+/* mem utilisation of CTX_SIZE */
+#define MAX_FRAGS               18 
+#define CTRL_DESC_SIZE          (sizeof(struct nlm_enc_ctx) + 64)
+#define IV_SIZE  	 	64	
+
+
+/* mem utilisation of req mem */
+
+
+/* mem utilisation of req mem */
+
+#define PACKET_DESC_SIZE        (128 + sizeof(struct saesoc_data_desc) + (MAX_FRAGS*8) + sizeof(struct nlm_async_crypto) + IV_SIZE + 64)
+#define NLM_CRYPTO_DATA_DESC(addr)  (struct saesoc_data_desc *) (((unsigned long)addr + 64) & ~0x3fUL)
+#define NLM_ASYNC_PTR_PARAM_OFFSET(addr)        (((unsigned long)addr +  sizeof(struct saesoc_data_desc) + (MAX_FRAGS*8) + 128) & ~0x3fUL)
+#define NLM_IV_OFFSET(addr)			((unsigned long)addr + (PACKET_DESC_SIZE - IV_SIZE))
+
+static int no_of_alg_registered = 0;
+
+extern struct nlm_crypto_stat crypto_stat[MAX_CPU];
+
+static int enc_cra_init(struct crypto_tfm *tfm)
+{ 
+	tfm->crt_ablkcipher.reqsize = PACKET_DESC_SIZE; //reqsize of 512 bytes for packet desc
+	return 0;
+}
+
+static struct nlm_enc_ctx * nlm_crypto_ablkcipher_ctx(struct crypto_ablkcipher *tfm)
+{
+	return (struct  nlm_enc_ctx *)(((unsigned long)((uint8_t *)crypto_ablkcipher_ctx(tfm) + 64 )) & ~(0x3fUL));
+} 
+static int
+xlp_setkey(struct crypto_ablkcipher *tfm, uint16_t stat)
+{
+
+
+	struct nlm_enc_ctx *nlm_ctx = nlm_crypto_ablkcipher_ctx(tfm); 
+	int nsdescs = saesoc_calc_sdesc_cnt(&nlm_ctx->initp,NULL);
+	struct saesoc_session_desc *s_desc = &nlm_ctx->enc_s_desc;
+	nlm_ctx->stat = stat;
+
+	if(saesoc_new_session(&nlm_ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+	nlm_ctx->initp.cipher.flags = 0;
+
+	s_desc = &nlm_ctx->dec_s_desc;
+
+	if(saesoc_new_session(&nlm_ctx->initp,&s_desc,nsdescs, NULL) < 0)
+		 printk("%s,%d Error \n", __FUNCTION__, __LINE__); 
+
+	return 0;
+}
+
+static int
+xlp_des3_setkey(struct crypto_ablkcipher *tfm, const u8 * in_key, unsigned int len)
+{
+	u32 flags = 0;
+	struct nlm_enc_ctx *nlm_ctx = nlm_crypto_ablkcipher_ctx(tfm); 
+	struct saesoc_session_init_params * initp = &nlm_ctx->initp;
+        initp->cipher.mode = SAESOC_CIPHER_MODE_CBC;	
+	initp->cipher.iv_offset = 0;
+	initp->cipher.iv_mode = 0;
+	initp->cipher.key = (char *)in_key;
+	initp->cipher.key_len = len;
+	initp->cipher.cfb_mask = 0;
+	initp->cipher.flags = SAESOC_CF_ENCRYPT;
+	initp->hash.type = SAESOC_HASH_BYPASS;
+	initp->hash.key_len = 0;
+	initp->payload_offset = DES_BLOCK_SIZE; 
+	initp->flags = SAESOC_IF_DATA_OUT_L3_ALLOC;
+
+	switch (len) {
+	case DES3_EDE_KEY_SIZE:
+		initp->cipher.type = SAESOC_CIPHER_TYPE_TDES;
+		break;
+	default:
+		printk(KERN_WARNING "[%s]: Cannot handle keylen = %d\n",
+		       __FUNCTION__, len);
+		flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;
+		crypto_ablkcipher_set_flags(tfm,flags);
+		return -EINVAL;
+	}
+	xlp_setkey(tfm,TDES_CBC_STAT);
+	return 0;
+}
+
+static int
+xlp_des_setkey(struct crypto_ablkcipher *tfm, const u8 * in_key, unsigned int len)
+{
+	u32 flags = 0;
+	struct nlm_enc_ctx *nlm_ctx = nlm_crypto_ablkcipher_ctx(tfm); 
+	struct saesoc_session_init_params * initp = &nlm_ctx->initp;
+        initp->cipher.mode = SAESOC_CIPHER_MODE_CBC;	
+	initp->cipher.iv_offset = 0;
+	initp->cipher.iv_mode = 0;
+	initp->cipher.key = (char *)in_key;
+	initp->cipher.key_len = len;
+	initp->cipher.cfb_mask = 0;
+	initp->cipher.flags = SAESOC_CF_ENCRYPT;
+	initp->hash.type = SAESOC_HASH_BYPASS;
+	initp->hash.key_len = 0;
+	initp->payload_offset = DES_BLOCK_SIZE; 
+	initp->flags = SAESOC_IF_DATA_OUT_L3_ALLOC;
+
+	switch (len) {
+	case DES_KEY_SIZE:
+		initp->cipher.type = SAESOC_CIPHER_TYPE_DES;
+		break;
+	default:
+		printk(KERN_WARNING "[%s]: Cannot handle keylen = %d\n",
+		       __FUNCTION__, len);
+		flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;
+		crypto_ablkcipher_set_flags(tfm, flags);
+		return -EINVAL;
+	}
+	return xlp_setkey(tfm,DES_CBC_STAT);
+}
+static int
+xlp_aes_setkey(struct crypto_ablkcipher *tfm, const u8 *in_key, 
+		unsigned int len, uint32_t mode, int iv_size)
+{
+
+	struct nlm_enc_ctx *nlm_ctx = nlm_crypto_ablkcipher_ctx(tfm); 
+	struct saesoc_session_init_params * initp = &nlm_ctx->initp;
+	uint16_t stat;
+	u32 flags = 0;
+        initp->cipher.mode = mode;	
+	initp->cipher.iv_offset = 0;
+	initp->cipher.iv_mode = 0;
+	initp->cipher.key = (char *)in_key;
+	initp->cipher.key_len = len;
+	initp->cipher.cfb_mask = 0;
+	initp->cipher.flags = SAESOC_CF_ENCRYPT;
+	initp->hash.type = SAESOC_HASH_BYPASS;
+	initp->hash.key_len = 0;
+	initp->payload_offset = iv_size; 
+	initp->flags = SAESOC_IF_DATA_OUT_L3_ALLOC ;
+
+
+
+	switch (len) {
+	case 16:
+		initp->cipher.type = SAESOC_CIPHER_TYPE_AES_128;
+		stat = AES128_CBC_STAT;
+		break;
+	case 24:
+		initp->cipher.type = SAESOC_CIPHER_TYPE_AES_192;
+		stat = AES192_CBC_STAT;
+		break;
+	case 32:
+		initp->cipher.type = SAESOC_CIPHER_TYPE_AES_256;
+		stat = AES256_CBC_STAT;
+		break;
+	default:
+		printk(KERN_WARNING "[%s]: Cannot handle keylen = %d\n",
+		       __FUNCTION__, len);
+		flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;
+		crypto_ablkcipher_set_flags(tfm,flags);
+		return -EINVAL;
+	}
+	if ( mode == SAESOC_CIPHER_MODE_CTR )
+		stat += 3;
+
+	return xlp_setkey(tfm, stat);
+}
+
+static int xlp_cbc_aes_setkey(struct crypto_ablkcipher *tfm, const u8 *key,
+					unsigned int keylen)
+{
+	return xlp_aes_setkey(tfm,key,keylen,SAESOC_CIPHER_MODE_CBC,AES_BLOCK_SIZE);
+}
+static int xlp_ctr_rfc3686_setkey(struct crypto_ablkcipher *tfm, const u8 *key,
+                                 unsigned int keylen)
+{
+
+        int err;
+	struct nlm_enc_ctx  *nlm_ctx = ( struct nlm_enc_ctx  * )nlm_crypto_ablkcipher_ctx(tfm);
+	unsigned char  *nonce = &(nlm_ctx->nonce[0]); 
+
+        if (keylen < CTR_RFC3686_NONCE_SIZE)
+                return -EINVAL;
+        memcpy(nonce, key + (keylen - CTR_RFC3686_NONCE_SIZE),
+               CTR_RFC3686_NONCE_SIZE);
+        keylen -= CTR_RFC3686_NONCE_SIZE;
+        err = xlp_aes_setkey(tfm, key, keylen,SAESOC_CIPHER_MODE_CTR,AES_BLOCK_SIZE);
+
+        return err;
+}
+void enc_request_callback(struct nlm_async_crypto *async, uint64_t msg1 )
+{
+	struct crypto_async_request * base = (struct crypto_async_request *)async->args; 
+	int err =0;
+#ifdef NOT_IMPLEMETNERED
+	int cpu = hard_smp_processor_id();
+	int stat = async->stat;
+#endif
+
+	if (msg1 & 0x7ff80) {
+		printk("\n Error: entry1 is %llx",msg1);
+		err = -EIO;
+		base->complete(base, err);
+		return;
+	}
+#ifdef NOT_IMPLEMETNERED
+	crypto_stat[cpu].enc[stat]++;
+	crypto_stat[cpu].enc_tbytes[stat]+= async->bytes;
+#endif
+	if ( async->ddesc)
+		kfree(async->ddesc);
+	base->complete(base, err);
+}
+
+static int
+xlp_crypt(struct ablkcipher_request *req, unsigned int enc, int iv_size, uint16_t stat)
+{
+
+
+	struct saesoc_data_desc	   *d_desc = NLM_CRYPTO_DATA_DESC(ablkcipher_request_ctx(req));
+	unsigned int cipher_len = req->nbytes;
+	struct nlm_async_crypto * async =  (struct nlm_async_crypto *)NLM_ASYNC_PTR_PARAM_OFFSET(ablkcipher_request_ctx(req));
+	struct saesoc_extra_req_send_params mparam;
+	int fb_vc;
+	int node ;
+	unsigned long msgrng_flags;
+	int node_sae_base;
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
+	struct nlm_enc_ctx *nlm_ctx = nlm_crypto_ablkcipher_ctx(tfm); 
+	struct saesoc_session_desc *s_desc;
+	int max_frags = MAX_FRAGS;
+	if ( enc )
+		s_desc = &nlm_ctx->enc_s_desc;
+	else
+		s_desc = &nlm_ctx->dec_s_desc; 
+
+	async->ddesc = NULL;
+	saesoc_add_frags(d_desc,req->info,iv_size,req->info,iv_size);
+
+
+	cipher_len = req->nbytes;
+
+	d_desc = fill_src_dst_sg(s_desc,d_desc,async,req->src, req->dst,&max_frags,cipher_len);
+
+	saesoc_set_payload_len(d_desc,cipher_len);
+
+	preempt_disable();
+	async->callback = &enc_request_callback;
+	async->args = &req->base;
+	async->stat = stat; 
+	async->bytes = req->nbytes; 
+	mparam.async_rsp_arg = (uint64_t)async;
+	mparam.arc4_load_state = 0;
+
+	mb();
+	msgrng_access_enable(msgrng_flags);
+	fb_vc = crypto_get_fb_vc(&node); 
+	node_sae_base = (node << NODE_BASE_SHIFT_BIT) | crypto_vc_base;
+	saesoc_process_request(NULL,d_desc,node_sae_base,fb_vc,0,1,&mparam,NULL);
+	msgrng_access_disable(msgrng_flags);
+	preempt_enable();
+	return -EINPROGRESS; 
+}
+static int
+xlp_cbc_decrypt( struct ablkcipher_request *req )
+{
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
+	struct nlm_enc_ctx *nlm_ctx = nlm_crypto_ablkcipher_ctx(tfm); 
+	struct saesoc_session_desc *s_desc = &nlm_ctx->dec_s_desc;
+	struct saesoc_data_desc	   *d_desc = NLM_CRYPTO_DATA_DESC(ablkcipher_request_ctx(req));
+	int iv_size = crypto_ablkcipher_ivsize(tfm);
+	saesoc_new_data_desc(s_desc, &d_desc, MAX_FRAGS , NULL);
+	return xlp_crypt(req, 0, iv_size,nlm_ctx->stat);
+}
+
+static int
+xlp_cbc_encrypt( struct ablkcipher_request *req )
+{
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
+	struct nlm_enc_ctx *nlm_ctx = nlm_crypto_ablkcipher_ctx(tfm); 
+	struct saesoc_session_desc *s_desc = &nlm_ctx->enc_s_desc;
+	struct saesoc_data_desc	   *d_desc = NLM_CRYPTO_DATA_DESC(ablkcipher_request_ctx(req));
+	int iv_size = crypto_ablkcipher_ivsize(tfm);
+	saesoc_new_data_desc(s_desc, &d_desc, MAX_FRAGS , NULL);
+	return xlp_crypt(req, 1, iv_size, nlm_ctx->stat);
+}
+static int crypto_rfc3686_crypt(struct ablkcipher_request *req,
+		unsigned int enc )
+{
+	struct crypto_ablkcipher *tfm = crypto_ablkcipher_reqtfm(req);
+	struct nlm_enc_ctx  *nlm_ctx = ( struct nlm_enc_ctx  * )nlm_crypto_ablkcipher_ctx(tfm);
+	u8 *iv = (uint8_t *)NLM_IV_OFFSET(ablkcipher_request_ctx(req));
+	int ret = 0;
+	struct saesoc_session_desc *s_desc;
+	struct saesoc_data_desc	   *d_desc;
+	u8 *info = req->info;
+	unsigned char * nonce = &(nlm_ctx->nonce[0]); 
+
+	if ( enc)
+		s_desc = &nlm_ctx->enc_s_desc;
+	else
+		s_desc = &nlm_ctx->dec_s_desc;
+	d_desc = NLM_CRYPTO_DATA_DESC(ablkcipher_request_ctx(req));
+	saesoc_new_data_desc(s_desc, &d_desc, MAX_FRAGS , NULL);
+
+	/*  uniqueness is maintained by the req->info */
+
+	memcpy(iv, nonce, CTR_RFC3686_NONCE_SIZE);
+	memcpy(iv + CTR_RFC3686_NONCE_SIZE, info, CTR_RFC3686_IV_SIZE);
+
+	*(__be32 *)(iv + CTR_RFC3686_NONCE_SIZE + CTR_RFC3686_IV_SIZE) =
+				cpu_to_be32(1);
+	req->info = iv;
+	ret = xlp_crypt(req, enc, 16,nlm_ctx->stat);
+	req->info = info;
+	return ret;
+}
+
+static int
+xlp_ctr_rfc3686_decrypt( struct ablkcipher_request *req)
+{
+	return crypto_rfc3686_crypt(req, 0);
+}
+
+static int
+xlp_ctr_rfc3686_encrypt(struct ablkcipher_request *req)
+{
+	return crypto_rfc3686_crypt(req,1);
+}
+static struct crypto_alg xlp_cbc_aes_alg = {
+	.cra_name = "cbc(aes)",
+	.cra_driver_name = "cbc-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER|CRYPTO_ALG_ASYNC,
+	.cra_blocksize = AES_BLOCK_SIZE,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_ablkcipher_type,
+	.cra_module = THIS_MODULE,
+	.cra_init = enc_cra_init,
+	.cra_list = LIST_HEAD_INIT(xlp_cbc_aes_alg.cra_list),
+	.cra_u = {
+		.ablkcipher = {
+			.min_keysize = AES_MIN_KEY_SIZE,
+			.max_keysize = AES_MAX_KEY_SIZE,
+			.setkey = xlp_cbc_aes_setkey,
+			.encrypt = xlp_cbc_encrypt,
+			.decrypt = xlp_cbc_decrypt,
+			.ivsize = AES_BLOCK_SIZE,
+			.geniv          = "eseqiv",
+		}
+	}
+};
+static struct crypto_alg xlp_cbc_des_alg = {
+	.cra_name = "cbc(des)",
+	.cra_driver_name = "cbc-des-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER | CRYPTO_ALG_ASYNC,
+	.cra_blocksize = DES_BLOCK_SIZE,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_ablkcipher_type,
+	.cra_module = THIS_MODULE,
+	.cra_init = enc_cra_init,
+	.cra_list = LIST_HEAD_INIT(xlp_cbc_des_alg.cra_list),
+	.cra_u = {
+		.ablkcipher = {
+			.min_keysize = DES_KEY_SIZE,
+			.max_keysize = DES_KEY_SIZE,
+			.setkey = xlp_des_setkey,
+			.encrypt = xlp_cbc_encrypt,
+			.decrypt = xlp_cbc_decrypt,
+			.ivsize = DES_BLOCK_SIZE,
+			.geniv          = "eseqiv",
+		}
+	}
+};
+
+static struct crypto_alg xlp_cbc_des3_alg = {
+	.cra_name = "cbc(des3_ede)",
+	.cra_driver_name = "cbc-des3-ede-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER|CRYPTO_ALG_ASYNC,
+	.cra_blocksize = DES3_EDE_BLOCK_SIZE,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_ablkcipher_type,
+	.cra_module = THIS_MODULE,
+	.cra_init = enc_cra_init,
+	.cra_list = LIST_HEAD_INIT(xlp_cbc_des3_alg.cra_list),
+	.cra_u = {
+		.ablkcipher = {
+			.min_keysize = DES3_EDE_KEY_SIZE,
+			.max_keysize = DES3_EDE_KEY_SIZE,
+			.setkey = xlp_des3_setkey,
+			.encrypt = xlp_cbc_encrypt,
+			.decrypt = xlp_cbc_decrypt,
+			.ivsize = DES3_EDE_BLOCK_SIZE,
+			.geniv          = "eseqiv",
+		}
+	}
+};
+
+static struct crypto_alg xlp_ctr_aes_alg = {
+	.cra_name = "rfc3686(ctr(aes))",
+	.cra_driver_name = "rfc3686-ctr-aes-xlp",
+	.cra_priority = XLP_CRYPT_PRIORITY,
+	.cra_flags = CRYPTO_ALG_TYPE_ABLKCIPHER|CRYPTO_ALG_ASYNC,
+	.cra_blocksize = 1,
+	.cra_ctxsize = CTRL_DESC_SIZE,
+	.cra_type = &crypto_ablkcipher_type,
+	.cra_module = THIS_MODULE,
+	.cra_init = enc_cra_init,
+	.cra_list = LIST_HEAD_INIT(xlp_ctr_aes_alg.cra_list),
+	.cra_u = {
+		.ablkcipher = {
+			.min_keysize = AES_MIN_KEY_SIZE,
+			.max_keysize = AES_MAX_KEY_SIZE,
+			.setkey = xlp_ctr_rfc3686_setkey,
+			.encrypt = xlp_ctr_rfc3686_encrypt,
+			.decrypt = xlp_ctr_rfc3686_decrypt,
+			.ivsize = CTR_RFC3686_IV_SIZE,
+			.geniv = "seqiv",
+		}
+	}
+};
+int xlp_crypt_alg_init(void)
+{
+	int ret = 0;
+	ret = crypto_register_alg(&xlp_cbc_des3_alg);
+	if (ret) {
+		goto end;
+	}
+	no_of_alg_registered++;
+	ret = crypto_register_alg(&xlp_cbc_des_alg);
+	if (ret) {
+		goto end;
+	}
+	no_of_alg_registered++;
+	ret = crypto_register_alg(&xlp_cbc_aes_alg);
+	if (ret) {
+		goto end;
+	}
+	no_of_alg_registered++;
+	ret = crypto_register_alg(&xlp_ctr_aes_alg);
+	if (ret) {
+		goto end;
+	}
+	no_of_alg_registered++;
+	printk(KERN_NOTICE "Using XLP hardware for AES, DES, 3DES algorithms.\n");
+end:
+	return 0;
+}
+
+int
+xlp_crypt_alg_fini(void) {
+	crypto_unregister_alg(&xlp_cbc_des3_alg);
+	crypto_unregister_alg(&xlp_cbc_des_alg);
+	crypto_unregister_alg(&xlp_cbc_aes_alg);
+	crypto_unregister_alg(&xlp_ctr_aes_alg);
+	return 0;
+}
+
+EXPORT_SYMBOL(xlp_crypt_alg_init);
+EXPORT_SYMBOL(xlp_crypt_alg_fini);
-- 
1.7.9.5

