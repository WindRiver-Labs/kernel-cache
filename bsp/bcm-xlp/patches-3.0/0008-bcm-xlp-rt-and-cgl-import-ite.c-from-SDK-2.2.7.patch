From 60057b3474a296d30a55f11729ac8df5d8a82587 Mon Sep 17 00:00:00 2001
From: Yanjiang Jin <yanjiang.jin@windriver.com>
Date: Thu, 14 Aug 2014 13:27:41 +0800
Subject: [PATCH 8/8] bcm-xlp: rt and cgl: import ite.c from SDK 2.2.7

This makes interrupts can work well on SMP mode.

Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/include/asm/netlogic/xlp-hal/pic.h |  80 +++-
 arch/mips/netlogic/common/Makefile           |   1 +
 arch/mips/netlogic/common/irq.c              |  52 ++-
 arch/mips/netlogic/common/ite.c              | 538 +++++++++++++++++++++++++++
 4 files changed, 666 insertions(+), 5 deletions(-)
 create mode 100644 arch/mips/netlogic/common/ite.c

diff --git a/arch/mips/include/asm/netlogic/xlp-hal/pic.h b/arch/mips/include/asm/netlogic/xlp-hal/pic.h
index b1df770..03faaac 100644
--- a/arch/mips/include/asm/netlogic/xlp-hal/pic.h
+++ b/arch/mips/include/asm/netlogic/xlp-hal/pic.h
@@ -152,6 +152,9 @@
 #define PIC_IRT0                0x74
 #define PIC_IRT(i)              (PIC_IRT0 + ((i) * 2))
 
+#define PIC_MEMACCESS		0x12
+#define PIC_ITEPOINTER(i)	(0x54 + (i) * 2)
+
 #define PIC_9XX_PENDING_0	0x6
 #define PIC_9XX_PENDING_1	0x8
 #define PIC_9XX_PENDING_2	0xa
@@ -219,11 +222,38 @@
 #define PIC_IRT_PCIE_LINK_INDEX(num)	((num) + PIC_IRT_PCIE_LINK_0_INDEX)
 
 #define PIC_XLP9XX_IRT_PCIE_LINK_0_INDEX	191
-#define PIC_XLP9XX_IRT_PCIE_LINK_INDEX(num) \
-	((num) + PIC_XLP9XX_IRT_PCIE_LINK_0_INDEX)
 
 #define PIC_CLOCK_TIMER			7
 
+#define NLM_MAX_NODES			4
+#define NLM_MAX_CPU_PER_NODE		64
+#define XLP_2XX_ITE_ENTRIES		8
+#define XLP_9XX_ITE_ENTRIES		64
+#define XLP_9XX_ITEPTR_ENTRIES		16
+#define xlp_ite_cpu_set(base, cpu, ite) xlp_ite_cpu_op(base, cpu, ite, 1)
+#define xlp_ite_cpu_clear(base, cpu, ite) xlp_ite_cpu_op(base, cpu, ite, 0)
+
+#define XLP_2XX_IRTENT_ENABLE	(1ULL << 31)
+#define XLP_2XX_IRTENT_NMI		(1ULL << 29)
+#define XLP_2XX_IRTENT_SCH_LCL	(1ULL << 28)
+#define XLP_2XX_IRTENT_RVEC(x)	(((x) & 0x3fULL) << 20)
+#define XLP_2XX_IRTENT_DT		(1ULL << 19)
+#define XLP_2XX_IRTENT_DB(x)	((x & 7) << 16)
+#define XLP_2XX_IRTENT_DTE(x)	((x) & 0xffff)
+
+#define XLP_9XX_IRTENT_ENABLE	(1ULL << 22)
+#define XLP_9XX_IRTENT_NMI		(1ULL << 23)
+#define XLP_9XX_IRTENT_SCH_LCL	(1ULL)
+#define XLP_9XX_IRTENT_RVEC(x)	(((x) & 0x3fULL) << 24)
+#define XLP_9XX_IRTENT_DT		(1ULL << 21)
+#define XLP_9XX_IRTPOINTERENT_DB(x)	((x & 15) << 16)
+#define XLP_IRTENT_DTE(x)	((x) & 0xffff)
+extern int xlp_span_multiple_nodes(const struct cpumask *mask);
+extern void constrict_mask_to_node(u8 node, struct cpumask *dst,
+					const struct cpumask *src);
+extern void xlp_set_cpumask_on_node(int node, uint64_t base, int irq,
+				int irt, const struct cpumask *m);
+
 #if !defined(LOCORE) && !defined(__ASSEMBLY__)
 
 /*
@@ -258,6 +288,20 @@ nlm_9xx_pic_write_irt(uint64_t base, int irt_num, int en, int nmi,
 }
 
 static inline void
+nlm_9xx_pic_write_irt_ite(uint64_t base, int irt_num, int en, int nmi,
+	int sch, int vec, int dt, int db, int iteptr)
+{
+	uint64_t val;
+
+	val = (((uint64_t)en & 0x1) << 22) | ((nmi & 0x1) << 23) |
+			((0 /*mc*/) << 20) | ((vec & 0x3f) << 24) |
+			((dt & 0x1) << 21) | (iteptr << 16) | sch;
+
+	nlm_write_pic_reg(base, PIC_9XX_IRT(irt_num), val);
+}
+
+
+static inline void
 nlm_pic_write_irt(uint64_t base, int irt_num, int en, int nmi,
 	int sch, int vec, int dt, int db, int dte)
 {
@@ -272,6 +316,19 @@ nlm_pic_write_irt(uint64_t base, int irt_num, int en, int nmi,
 }
 
 static inline void
+nlm_pic_write_irt_ite(uint64_t base, int irt_num, int en, int nmi,
+	int sch, int vec, int dt, int db, int dte)
+{
+	uint64_t val;
+
+	val = (((uint64_t)en & 0x1) << 31) | ((nmi & 0x1) << 29) |
+			((sch & 0x1) << 28) | ((vec & 0x3f) << 20) |
+			((dt & 0x1) << 19) | ((dte & 0x7) << 16);
+
+	nlm_write_pic_reg(base, PIC_IRT(irt_num), val);
+}
+
+static inline void
 nlm_pic_write_irt_direct(uint64_t base, int irt_num, int en, int nmi,
 	int sch, int vec, int cpu)
 {
@@ -284,6 +341,19 @@ nlm_pic_write_irt_direct(uint64_t base, int irt_num, int en, int nmi,
 			1 << (cpu & 0xf));	/* thread mask */
 }
 
+static inline void
+nlm_pic_write_irt_direct_ite(uint64_t base, int irt_num, int en, int nmi,
+	int sch, int vec, int ite)
+{
+	if (cpu_is_xlp9xx())
+		nlm_9xx_pic_write_irt_ite(base, irt_num, en, nmi, sch, vec,
+							0, 0, ite);
+	else
+		nlm_pic_write_irt_ite(base, irt_num, en, nmi, sch, vec, 0,
+			0, ite);
+}
+
+
 static inline uint64_t
 nlm_pic_read_timer(uint64_t base, int timer)
 {
@@ -379,6 +449,12 @@ nlm_pic_init_irt(uint64_t base, int irt, int irq, int hwt, int en)
 	nlm_pic_write_irt_direct(base, irt, en, 0, 0, irq, hwt);
 }
 
+static inline void
+nlm_pic_init_irt_ite(uint64_t base, int irt, int irq, int ite, int en)
+{
+	nlm_pic_write_irt_direct_ite(base, irt, en, 0, 1, irq, ite);
+}
+
 int nlm_irq_to_irt(int irq);
 
 #endif /* __ASSEMBLY__ */
diff --git a/arch/mips/netlogic/common/Makefile b/arch/mips/netlogic/common/Makefile
index 97a715a..7d9726d 100644
--- a/arch/mips/netlogic/common/Makefile
+++ b/arch/mips/netlogic/common/Makefile
@@ -1,3 +1,4 @@
+obj-y				+= ite.o #zjy add
 obj-y				+= irq.o time.o reset.o memory.o io.o
 obj-y				+= nlm_fs_tbl.o	nlm_fs_handler.o
 obj-y				+= nlm-dma.o
diff --git a/arch/mips/netlogic/common/irq.c b/arch/mips/netlogic/common/irq.c
index 4d7b30e..963fd8b 100644
--- a/arch/mips/netlogic/common/irq.c
+++ b/arch/mips/netlogic/common/irq.c
@@ -131,12 +131,55 @@ static void xlp_pic_unmask(struct irq_data *d)
 	nlm_pic_ack(pd->node->picbase, pd->irt);
 }
 
+/*
+ * Set affinity for the intx for chips
+ *
+ * When an interrupt is setup, its EIMR bit is set in all online cpus. That is,
+ * any cpu _can_ receive that interrupt. But it is the IRT entry that decides
+ * whether to send that interrupt (i.e, whether to set EIRR bit or not) to any
+ * particular CPU.
+ *
+ * IRT has two modes to decide the target CPUs for one interrupt.
+ * Method 1 : Using IRT table entry bits DT and DTE
+ * If DT==1, this interrupt can be routed to a max of 16 CPUs (well, hw threads)
+ * If DT==1, there is one more level of indirection called DTE. Each DTE entry
+ * has 128 bits and there are a total of 8 DTE entries. Each DTE entry contains
+ * the bitmask of target CPU for an interrupt. One of them is chosen based
+ * on the specified cpumask.
+ *
+ * The actual bitmask can be different from the specified bitmask based
+ * on the logic of xlp_closest_match_cpumask()
+ */
+static int xlp_pic_set_affinity(struct irq_data *d,
+			const struct cpumask *dest, bool force)
+{
+	struct cpumask m;
+	unsigned long flags;
+	struct nlm_pic_irq *pd = irq_data_get_irq_handler_data(d);
+	int node = pd->node - nlm_nodes;
+
+	if (xlp_span_multiple_nodes(dest) != 0) {
+		/* this is the policy for MSI. Change later TODO */
+		constrict_mask_to_node(node, &m, dest);
+	} else {
+		cpumask_copy(&m, dest);
+	}
+	raw_spin_lock_irqsave(&pd->node->piclock, flags);
+	/* Note : node == 0 passed for link_irq*/
+	xlp_set_cpumask_on_node(node, pd->node->picbase,
+		pd->picirq, pd->irt, &m);
+	raw_spin_unlock_irqrestore(&pd->node->piclock, flags);
+
+	return 0;
+}
+
 static struct irq_chip xlp_pic = {
 	.name		= "XLP-PIC",
 	.irq_enable	= xlp_pic_enable,
 	.irq_disable	= xlp_pic_disable,
 	.irq_mask_ack	= xlp_pic_mask_ack,
 	.irq_unmask	= xlp_pic_unmask,
+	.irq_set_affinity = xlp_pic_set_affinity,
 };
 
 static void cpuintr_disable(struct irq_data *d)
@@ -215,7 +258,8 @@ void nlm_set_pic_extra_ack(int node, int irq, void (*xack)(struct irq_data *))
 static void nlm_init_node_irqs(int node)
 {
 	struct nlm_soc_info *nodep;
-	int i, irt;
+	int i, irt, ite;
+	extern void xlp_pic_init(uint64_t base);
 
 	pr_info("Init IRQ for node %d\n", node);
 	nodep = nlm_get_node(node);
@@ -228,10 +272,12 @@ static void nlm_init_node_irqs(int node)
 		if (irt == -2)		/* not a direct PIC irq */
 			continue;
 
-		nlm_pic_init_irt(nodep->picbase, irt, i,
-				node * nlm_threads_per_node(), 0);
+		ite = cpu_is_xlp9xx() ? 8 : 5;
+		nlm_pic_init_irt_ite(nodep->picbase, irt, i,
+				ite, 0);
 		nlm_setup_pic_irq(node, i, i, irt);
 	}
+	xlp_pic_init(nodep->picbase);
 }
 
 void nlm_smp_irq_init(int hwcpuid)
diff --git a/arch/mips/netlogic/common/ite.c b/arch/mips/netlogic/common/ite.c
new file mode 100644
index 0000000..4999857
--- /dev/null
+++ b/arch/mips/netlogic/common/ite.c
@@ -0,0 +1,538 @@
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_2# */
+
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/timer.h>
+#include <linux/cpumask.h>
+#include <linux/nodemask.h>
+#include <linux/netdevice.h>
+
+#include <asm/netlogic/mips-extns.h>
+#include <asm/netlogic/interrupt.h>
+#include <asm/netlogic/haldefs.h>
+#include <asm/netlogic/common.h>
+
+#if defined(CONFIG_CPU_XLP)
+#include <asm/netlogic/xlp-hal/iomap.h>
+#include <asm/netlogic/xlp-hal/xlp.h>
+#include <asm/netlogic/xlp-hal/pic.h>
+#elif defined(CONFIG_CPU_XLR)
+#include <asm/netlogic/xlr/iomap.h>
+#include <asm/netlogic/xlr/pic.h>
+#include <asm/netlogic/xlr/fmn.h>
+#endif
+/*
+ * xlp_ites[node][0-3] = {0x1, 0xffffffff, 0x0000ffff, 0xffff0000};//local only
+ */
+static struct cpumask xlp_ites[NLM_MAX_NODES][XLP_9XX_ITE_ENTRIES];
+static DEFINE_SPINLOCK(xlp_ites_lock);
+
+/* Modifications below to read actual programmed values
+ * instead of just dumping table */
+void dump_all_ites(uint64_t base)
+{
+	u8 node, i;
+	u32 ite3, ite2, ite1, ite0;
+	u64 tmp, reg, val;
+	char buf[140];
+	unsigned long flags;
+
+	for_each_online_node(node) {
+		if (!cpu_is_xlp9xx()) {
+			for (i = 0; i < XLP_2XX_ITE_ENTRIES; i++) {
+				cpumask_scnprintf(buf, 140, &xlp_ites[node][i]);
+				spin_lock_irqsave(&xlp_ites_lock, flags);
+				reg = PIC_ITE0_N2_N3 + 4 * i;
+				tmp = nlm_read_pic_reg(base, reg);
+				ite3 = tmp >> 32;
+				ite2 = tmp & 0xffffffffULL;
+				reg = PIC_ITE0_N0_N1 + 4 * i;
+				tmp = nlm_read_pic_reg(base, reg);
+				ite1 = tmp >> 32;
+				ite0 = tmp & 0xffffffffULL;
+				spin_unlock_irqrestore(&xlp_ites_lock, flags);
+			}
+		} else {
+			for (i = 0; i < XLP_9XX_ITE_ENTRIES; i++) {
+				cpumask_scnprintf(
+				buf, 140, &xlp_ites[node][i]);
+				spin_lock_irqsave(&xlp_ites_lock, flags);
+				reg = PIC_MEMACCESS;
+				val = 0;
+				val |= ((u64)i << 48) | (1ULL << 61);
+				nlm_write_pic_reg(base, reg, val);
+				val = nlm_read_pic_reg(base, reg);
+				tmp = val & 0xffffffffffULL;
+				val = (1UL << 56);
+				val |= ((u64)i << 48) | (1ULL << 61);
+				nlm_write_pic_reg(base, reg, val);
+				val = nlm_read_pic_reg(base, reg);
+				val &= 0xffffffULL;
+				tmp |= (val << 40);
+				ite0 = tmp & 0xffffffffULL;
+				ite1 = (tmp >> 32) & 0xffffffffULL;
+				ite2 = ite3 = 0;
+				spin_unlock_irqrestore(&xlp_ites_lock, flags);
+			}
+		}
+	}
+
+	return;
+}
+
+
+/* This function sets the given ITE's cpu bit on node node.
+ *
+ * @node	: node on which ITE is to be set
+ * @cpu		: target cpu id
+ * @ite		: ITE index
+ * @bitval	: 0 to clear, 1 to set
+ */
+void xlp_ite_cpu_op(uint64_t base, u8 cpu, u8 ite, u8 bitval)
+{
+	unsigned long flags;
+	u64 val, reg;
+	u8 bit;
+
+	/* No param checking, must be checked before calling.
+	 * Target cpu id decices whether to use THREADEN01 or THREADEN23
+	 * i.e., if target cpu < 64, use THREADEN01 as base else THREADEN23 */
+	if (!cpu_is_xlp9xx()) {
+		reg = (cpu < 64) ? PIC_ITE_N0_N1(ite) :
+						PIC_ITE_N2_N3(ite);
+		bit = cpu % 64;
+		spin_lock_irqsave(&xlp_ites_lock, flags);
+		val = nlm_read_pic_reg(base, reg);
+		val = (bitval == 0) ?
+			(val & ~(1ULL << bit)) :
+			(val | (1ULL << bit));
+		nlm_write_pic_reg(base, reg, val);
+		spin_unlock_irqrestore(&xlp_ites_lock, flags);
+	} else {
+		reg = PIC_MEMACCESS;
+		val = (cpu < 40) ? 0 : (1ULL << 56);
+		val |= ((u64)ite << 48) | (1ULL << 61);
+		spin_lock_irqsave(&xlp_ites_lock, flags);
+		nlm_write_pic_reg(base, reg, val);
+		mb();
+		val = nlm_read_pic_reg(base, reg);
+		bit = (cpu < 40) ? cpu : (cpu - 40);
+		val = (bitval == 0) ?
+			(val & ~(1ULL << bit)) :
+			(val | (1ULL << bit));
+		val &= 0xffffffffffULL;
+		val |= (1ULL << 63) | (1ULL << 61);
+		val |= (cpu < 40) ? 0 : (1ULL << 56);
+		val |= ((u64)ite << 48);
+		nlm_write_pic_reg(base, reg, val);
+		mb();
+		val = (cpu < 40) ? 0 : (1ULL << 56);
+		val |= ((u64)ite << 48) | (1ULL << 61);
+		nlm_write_pic_reg(base, reg, val);
+		mb();
+		val = nlm_read_pic_reg(base, reg);
+		spin_unlock_irqrestore(&xlp_ites_lock, flags);
+	}
+}
+extern struct cpumask nlm_cpumask;
+/* This function would program ITE values on node given by the cpumask
+ * @cpumask	: cpumask to program on ITE
+ * @node	: node on which ITE should be programmed
+ * @ite		: ITE to program
+ * @scope	: program ITE only on the given node (0) or all nodes (1)
+ */
+void xlp_cpumask_to_node_ite(const struct cpumask *m,
+				uint64_t base, u8 ite, u8 scope)
+{
+	__label__ prog_all;
+	struct cpumask t;
+	int cpu = 0, last;
+
+	if (scope != 0)
+		goto prog_all;
+
+	/* When the scope is 0, program node ITEs with target as
+	 * local cpus only */
+	last = cpu + NLM_MAX_CPU_PER_NODE - 1;
+	if (last >= NR_CPUS)
+		return;
+	cpumask_and(&t, m, &nlm_cpumask);
+	for (; cpu <= last; cpu++)
+		cpumask_test_cpu(cpu, &t) ?
+			xlp_ite_cpu_set(base, cpu, ite) :
+			xlp_ite_cpu_clear(base, cpu, ite);
+	return;
+prog_all:
+	/* Here we program the specified ITE in all nodes with the cpumask
+	 * passed. */
+	/* TBD TODO */
+	return;
+}
+
+/* Once all CPUs are up, walk through the node mask and program all
+ * ITEs in the PICs */
+void xlp_prog_all_node_ites(uint64_t base)
+{
+	u8 i, node;
+
+	for_each_online_node(node) {
+		if (!cpu_is_xlp9xx()) {
+			/* 4 is the ITE that redirects int.s to all cpus */
+			for (i = 0; i < XLP_2XX_ITE_ENTRIES; i++)
+				xlp_cpumask_to_node_ite(&xlp_ites[node][i],
+					base, i, (i == 4));
+		} else {
+			/* 4 is the ITE that redirects int.s to all cpus */
+			for (i = 0; i < XLP_9XX_ITE_ENTRIES; i++)
+				xlp_cpumask_to_node_ite(&xlp_ites[node][i],
+					base, i, (i == 4));
+			for (i = 0; i < XLP_9XX_ITEPTR_ENTRIES; i++)
+				nlm_write_pic_reg(base,  PIC_ITEPOINTER(i), i);
+		}
+	}
+	dump_all_ites(base);
+}
+
+/* Checks if a mask spans multiple nodes
+ *
+ * @mask	: cpumask to check for multiple node span
+ */
+int xlp_span_multiple_nodes(const struct cpumask *mask)
+{
+	int l, f;
+	f = cpumask_first(mask);
+	l = find_last_bit(cpumask_bits(mask), NR_CPUS);
+	if ((f/NLM_MAX_CPU_PER_NODE) != (l/NLM_MAX_CPU_PER_NODE))
+		return -EINVAL;
+	return 0;
+}
+
+/*
+ * In XLP cpu mask for setting affinity of an interrupt cannot span multiple
+ * nodes. Although this is not a h/w restriction, the effort to implement
+ * this feature does not justify the potential benefit; not only that handling
+ * non local interrupts are slightly slower, it could be expensive in terms of
+ * memory access and other resource utilization
+ *
+ * @node	: node to which mask `mask` to be restricted
+ * @src		: mask to restrict
+ * @dst		: restricted mask (result)
+ */
+void constrict_mask_to_node(u8 node, struct cpumask *dst,
+				const struct cpumask *src)
+{
+	int i;
+
+	cpumask_clear(dst);
+	for (i = NLM_MAX_CPU_PER_NODE * node;
+		i < (NLM_MAX_CPU_PER_NODE * (node + 1)); i++)
+		cpumask_set_cpu(i, dst);
+	cpumask_and(dst, dst, &nlm_cpumask);
+	cpumask_and(dst, dst, src);
+	return;
+}
+
+
+/*
+ * This function returns closest match cpumask among the supported bitmasks
+ * in XLP
+ * Logic is moot, need to improve it later.
+ *
+ * @m	: user supplied cpumask
+ */
+static int xlp_closest_match_cpumask(u8 node, const struct cpumask *m)
+{
+	int i;
+	char buf[72];
+	struct cpumask t, a;
+	int ite_count;
+	/* m will be a logical cpu mask.
+	 * If all threads are enabled, this will
+	 * match the physical cpu mask.
+	 * If not, this won't match and this function
+	 * won't work, however the fall-back is to route
+	 * interrupts to all CPUs so the system will still work,
+	 * just not necessarily with the desired affinity.
+	 * So we have to convert the logical cpu mask to a
+	 * physical mask first. */
+	cpumask_scnprintf(buf, 72, m);
+	cpumask_clear(&a);
+	for_each_cpu(i, m)
+		cpumask_set_cpu(cpu_logical_map(i), &a);
+	cpumask_and(&a, &a, &nlm_cpumask);
+	constrict_mask_to_node(node, &t, &a);
+	cpumask_clear(&a);
+
+	if (cpu_is_xlp9xx())
+		ite_count = XLP_9XX_ITEPTR_ENTRIES;
+	else
+		ite_count = XLP_2XX_ITE_ENTRIES;
+
+	for (i = 0; i < ite_count; i++) {
+		cpumask_and(&a, &xlp_ites[node][i], &nlm_cpumask);
+		if (cpumask_equal(&t, &a)) {
+			cpumask_scnprintf(buf, 72, m);
+			if (i == 4)
+				continue;
+			return i;
+		}
+	}
+	cpumask_scnprintf(buf, 72, m);
+	cpumask_scnprintf(buf, 72, &t);
+	return 1; /* if no match, point to all local cpus */
+}
+
+/*
+ * This function programs the ITE on the IRT entry
+ * on all online nodes
+ * @m	: CPU mask resulting from xlp_closest_match_cpumask()
+ * call
+ */
+void xlp_set_cpumask_on_node(int node, uint64_t base, int irq,
+				int irt, const struct cpumask *m)
+{
+	u8 ite;
+	u64 val;
+
+	ite = xlp_closest_match_cpumask(node, m);
+	if (!cpu_is_xlp9xx()) {
+		/* xlp_pic_init() has set default values.
+		 * Override them */
+		val = XLP_2XX_IRTENT_ENABLE |
+			XLP_2XX_IRTENT_SCH_LCL |
+			XLP_2XX_IRTENT_RVEC(irq) |
+			XLP_2XX_IRTENT_DB(ite);
+		nlm_write_pic_reg(base, PIC_IRT(irt), val);
+	} else {
+		val = XLP_9XX_IRTENT_ENABLE |
+			XLP_9XX_IRTENT_RVEC(irq) |
+			XLP_9XX_IRTPOINTERENT_DB(ite) |
+			XLP_9XX_IRTENT_SCH_LCL;
+		nlm_write_pic_reg(base, PIC_9XX_IRT(irt), val);
+	}
+
+	return;
+}
+
+
+/* helper function to create cpumask from unsigned long
+ * Easiest way is to create it directly using bitmap_copy.
+ * For some reason, this was not successful.
+ *
+ * @m	: cpumask pointer to populate. Lower 32 bits must be 0
+ * @u	: u32 variable pointer with bitmask
+ */
+void u32_to_cpumask(struct cpumask *m, u32 bm)
+{
+	u8 bit = 0;
+
+	/* should not clear the mask passed */
+	for (; bit < sizeof(u32) * BITS_PER_BYTE; bit++) {
+		if (bm & (1 << bit))
+			cpumask_set_cpu(bit, m);
+		else
+			cpumask_clear_cpu(bit, m);
+	}
+}
+
+void u64_to_cpumask(struct cpumask *m, u64 bm)
+{
+	u8 bit = 0;
+
+	/* should not clear the mask passed */
+	for (; bit < sizeof(u64) * BITS_PER_BYTE; bit++) {
+		if (bm & (1ULL << bit))
+			cpumask_set_cpu(bit, m);
+		else
+			cpumask_clear_cpu(bit, m);
+	}
+}
+/*
+ * Initializes PIC ITE entries PRM 9.5.6.26
+ * XLP restricts CPU affinity to 8 groups. Though configurable, they are
+ * programmed to have the following patterns.
+ * 0 =>	Only 0th cpu on the node
+ * 1 => All local threads in node; mask = (0xffffffff) on node
+ * 2 => cpu0-15 on node; mask = 0x0000ffff & online_cpu_mask on nodes
+ * 3 => cpu15-31 on node; mask = 0xffff0000 & online_cpu_mask on node
+ * 4 => All cpus on all nodes; i.e.,
+ * mask = (0xffffffff_ffffffff_ffffffff_ffffffff & physical online cpu map)
+ * These are programmer defined groups and can be changed as warranted.
+ * Added 5 => CPUs 0-11
+ * Added 6 => CPUs 0-7
+ * Added 7 => CPUs 0-3
+ * Actual programmed value will take into consideration cpu_online_mask.
+ *
+ * There is a major issue that needs addressing when run in multi node mode
+ * Number of nodes must be determined and programmed correctly, if a bit in ITE
+ * is programmed without physical thread being present, when interrupt is
+ * dispatched to that CPU under global scheme, system would hang. Thus this
+ * scenario should be avoided. That is why nlm_cpumask is used
+ *
+ * This function simply initializes the xlp_ites entries with proposed
+ * CPUmasks.  */
+static void xlp_ites_init(void)
+{
+	u64 bm = 0x1;
+	u8 node;
+	struct cpumask m;
+
+	cpumask_clear(&m);
+	for_each_online_node(node) {
+	/* Simply set the static pattern in all */
+		bm = 1;
+		u32_to_cpumask(&xlp_ites[node][0], bm);
+		/* directs to specified cpus of node*/
+		cpumask_shift_left(&xlp_ites[node][0],
+			&xlp_ites[node][0],
+			NLM_MAX_CPU_PER_NODE * node);
+
+		bm = 0xffffffff;
+		u32_to_cpumask(&xlp_ites[node][1], bm);
+		/* directs to specified cpus of node*/
+		cpumask_shift_left(&xlp_ites[node][1],
+				&xlp_ites[node][1],
+				NLM_MAX_CPU_PER_NODE * node);
+		if (!cpu_is_xlp9xx())
+			cpumask_or(&m, &m, &xlp_ites[node][1]);
+
+		bm = 0x0000ffff;
+		u32_to_cpumask(&xlp_ites[node][2], bm);
+		/* directs to specified cpus of node*/
+		cpumask_shift_left(&xlp_ites[node][2],
+				&xlp_ites[node][2],
+				NLM_MAX_CPU_PER_NODE * node);
+
+		bm = 0xffff0000;
+		u32_to_cpumask(&xlp_ites[node][3], bm);
+		/* directs to specified cpus of node*/
+		cpumask_shift_left(&xlp_ites[node][3],
+				&xlp_ites[node][3],
+				NLM_MAX_CPU_PER_NODE * node);
+
+		bm = 0x000000ff;
+		u32_to_cpumask(&xlp_ites[node][5], bm);
+		/* directs to specified cpus of node*/
+		cpumask_shift_left(&xlp_ites[node][5],
+				&xlp_ites[node][5],
+				NLM_MAX_CPU_PER_NODE * node);
+
+		bm = 0x000000f0;
+		u32_to_cpumask(&xlp_ites[node][6], bm);
+		/* directs to specified cpus of node*/
+		cpumask_shift_left(&xlp_ites[node][6],
+			&xlp_ites[node][6],
+			NLM_MAX_CPU_PER_NODE * node);
+
+		bm = 0x0000000f;
+		/* directs to specified cpus of node*/
+		u32_to_cpumask(&xlp_ites[node][7], bm);
+		cpumask_shift_left(&xlp_ites[node][7],
+			&xlp_ites[node][7],
+			NLM_MAX_CPU_PER_NODE * node);
+
+		if (cpu_is_xlp9xx()) {
+			bm = 0xffffffffffffffffULL;
+			u64_to_cpumask(&xlp_ites[node][8], bm);
+			/* directs to specified cpus of node*/
+			cpumask_shift_left(&xlp_ites[node][8],
+			&xlp_ites[node][8],
+			NLM_MAX_CPU_PER_NODE * node);
+			cpumask_or(&m, &m, &xlp_ites[node][8]);
+			bm = 0xffffffff00000000ULL;
+			u64_to_cpumask(&xlp_ites[node][9], bm);
+			/* directs to specified cpus of node*/
+			cpumask_shift_left(&xlp_ites[node][9],
+				&xlp_ites[node][9],
+				NLM_MAX_CPU_PER_NODE * node);
+
+			bm = 0xffff00000000ULL;
+			u64_to_cpumask(&xlp_ites[node][10], bm);
+			/* directs to specified cpus of node */
+			cpumask_shift_left(&xlp_ites[node][10],
+				&xlp_ites[node][10],
+				 NLM_MAX_CPU_PER_NODE * node);
+
+			bm = 0xffff000000000000ULL;
+			u64_to_cpumask(&xlp_ites[node][11], bm);
+			/* directs to specified cpus of node*/
+			cpumask_shift_left(&xlp_ites[node][11],
+				&xlp_ites[node][11],
+				NLM_MAX_CPU_PER_NODE * node);
+
+			bm = 0xff00000000ULL;
+			u64_to_cpumask(&xlp_ites[node][12], bm);
+			/* directs to specified cpus of node*/
+			cpumask_shift_left(&xlp_ites[node][12],
+				&xlp_ites[node][12],
+				NLM_MAX_CPU_PER_NODE * node);
+
+			bm = 0xf000000000ULL;
+			u64_to_cpumask(&xlp_ites[node][13], bm);
+			/* directs to specified cpus of node*/
+			cpumask_shift_left(&xlp_ites[node][13],
+				&xlp_ites[node][13],
+				NLM_MAX_CPU_PER_NODE * node);
+
+			bm = 0xf00000000ULL;
+			u64_to_cpumask(&xlp_ites[node][14], bm);
+			/* directs to specified cpus of node*/
+			cpumask_shift_left(&xlp_ites[node][14],
+				&xlp_ites[node][14],
+				NLM_MAX_CPU_PER_NODE * node);
+
+			bm = 0x100000000ULL;
+			u64_to_cpumask(&xlp_ites[node][15], bm);
+			/* directs to specified cpus of node*/
+			cpumask_shift_left(&xlp_ites[node][15],
+				&xlp_ites[node][15],
+				NLM_MAX_CPU_PER_NODE * node);
+		}
+	}
+	for_each_online_node(node) {
+		cpumask_copy(&xlp_ites[node][4], &m);
+	}
+}
+
+/* Initializes the PIC
+ * Mainly sets up the IRT entries default values
+ * called from on_chip.c:pic_init()
+ * */
+void xlp_pic_init(uint64_t base)
+{
+	xlp_ites_init();
+	xlp_prog_all_node_ites(base);
+}
+
-- 
1.9.1

