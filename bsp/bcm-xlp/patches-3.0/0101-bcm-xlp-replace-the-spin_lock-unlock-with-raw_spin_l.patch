From d69087d561e63343dd3cf41b6d62b733dd0ba402 Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Wed, 19 Mar 2014 15:43:15 +0800
Subject: [PATCH 1/4] bcm-xlp: replace the spin_lock/unlock with
 raw_spin_lock/unlock

If use the old one we may got the following errors:

BUG: sleeping function called from invalid context at kernel/rtmutex.c:658
in_atomic(): 1, irqs_disabled(): 1, pid: 0, name: swapper/19
Call Trace:
[<ffffffffc17defa0>] dump_stack+0x1c/0x50
[<ffffffffc11314d8>] __might_sleep+0xf0/0x118
[<ffffffffc17ea890>] rt_spin_lock+0x38/0x100
......
......

Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 arch/mips/include/asm/mach-netlogic/multi-node.h |    2 +-
 arch/mips/mm/c-netlogic.c                        |    6 +--
 arch/mips/netlogic/common/irq.c                  |    9 ++--
 arch/mips/netlogic/kvm/kvm_uart.c                |    6 +--
 arch/mips/netlogic/lib/fmnlib/nlm_msgring.h      |    4 +-
 arch/mips/netlogic/xlp/nlm_hal.c                 |    2 +-
 arch/mips/netlogic/xlr/setup.c                   |    2 +-
 arch/mips/pci/msi-xlp.c                          |   24 +++++-----
 drivers/gpio/gpio-xlp.c                          |   20 ++++-----
 drivers/netlogic/cmem/cmem.c                     |   32 ++++++-------
 drivers/netlogic/dtre/nlm_adma.c                 |   22 ++++-----
 drivers/netlogic/dtre/nlm_adma.h                 |    4 +-
 drivers/netlogic/nae/xlpge.h                     |    4 +-
 drivers/netlogic/nae/xlpge_ethtool.c             |   24 +++++-----
 drivers/netlogic/nae/xlpge_nae.c                 |   26 +++++------
 drivers/netlogic/nae/xlpge_rx.c                  |   30 ++++++-------
 drivers/netlogic/netl7driver/netl7driver.c       |   18 ++++----
 drivers/netlogic/nlmcrypto/cryptodrv.c           |   52 +++++++++++-----------
 drivers/netlogic/pkt_pool_mem/pkt_pool_mem.c     |    4 +-
 drivers/netlogic/soc_interface/on_chip.c         |   26 +++++------
 20 files changed, 159 insertions(+), 158 deletions(-)

diff --git a/arch/mips/include/asm/mach-netlogic/multi-node.h b/arch/mips/include/asm/mach-netlogic/multi-node.h
index 0558e0b..52ce60b 100644
--- a/arch/mips/include/asm/mach-netlogic/multi-node.h
+++ b/arch/mips/include/asm/mach-netlogic/multi-node.h
@@ -64,7 +64,7 @@ struct nlm_soc_info {
 	uint64_t	irqmask;	/* EIMR for the node */
 	uint64_t	sysbase;	/* only for XLP - sys block base */
 	uint64_t	picbase;	/* PIC block base */
-	spinlock_t	piclock;	/* lock for PIC access */
+	raw_spinlock_t	piclock;	/* lock for PIC access */
 	cpumask_t 	cpumask;	/* logical cpu mask for node */
 	unsigned int	socbus;
 };
diff --git a/arch/mips/mm/c-netlogic.c b/arch/mips/mm/c-netlogic.c
index c7fc68f..187f6fc 100644
--- a/arch/mips/mm/c-netlogic.c
+++ b/arch/mips/mm/c-netlogic.c
@@ -656,7 +656,7 @@ void __cpuinit nlm_cache_init(void)
 
 #ifdef CONFIG_KVM
 
-static DEFINE_SPINLOCK(nlm_l3_lock);
+static DEFINE_RAW_SPINLOCK(nlm_l3_lock);
 
 static void nlm_flush_l3(int node, unsigned long start, unsigned long size)
 {
@@ -675,7 +675,7 @@ static void nlm_flush_l3(int node, unsigned long start, unsigned long size)
 #endif
 	bridge_base = nlm_get_bridge_regbase(node);
 
-	spin_lock_irqsave(&nlm_l3_lock, flags);
+	raw_spin_lock_irqsave(&nlm_l3_lock, flags);
 	for (address = start; address < (start + size); address += 64) {
 		int i;
 
@@ -694,7 +694,7 @@ static void nlm_flush_l3(int node, unsigned long start, unsigned long size)
 			} while (val != 0x3);
 		}
 	}
-	spin_unlock_irqrestore(&nlm_l3_lock, flags);
+	raw_spin_unlock_irqrestore(&nlm_l3_lock, flags);
 }
 
 struct nlm_l2_flush_t {
diff --git a/arch/mips/netlogic/common/irq.c b/arch/mips/netlogic/common/irq.c
index 28c4563..fb8800a 100644
--- a/arch/mips/netlogic/common/irq.c
+++ b/arch/mips/netlogic/common/irq.c
@@ -91,9 +91,9 @@ static void xlp_pic_enable(struct irq_data *d)
 	struct nlm_pic_irq *pd = irq_data_get_irq_handler_data(d);
 
 	BUG_ON(!pd);
-	spin_lock_irqsave(&pd->node->piclock, flags);
+	raw_spin_lock_irqsave(&pd->node->piclock, flags);
 	nlm_pic_enable_irt(pd->node->picbase, pd->irt);
-	spin_unlock_irqrestore(&pd->node->piclock, flags);
+	raw_spin_unlock_irqrestore(&pd->node->piclock, flags);
 }
 
 static void xlp_pic_disable(struct irq_data *d)
@@ -102,9 +102,9 @@ static void xlp_pic_disable(struct irq_data *d)
 	unsigned long flags;
 
 	BUG_ON(!pd);
-	spin_lock_irqsave(&pd->node->piclock, flags);
+	raw_spin_lock_irqsave(&pd->node->piclock, flags);
 	nlm_pic_disable_irt(pd->node->picbase, pd->irt);
-	spin_unlock_irqrestore(&pd->node->piclock, flags);
+	raw_spin_unlock_irqrestore(&pd->node->piclock, flags);
 }
 
 static void xlp_pic_mask_ack(struct irq_data *d)
@@ -165,6 +165,7 @@ struct irq_chip nlm_cpu_intr = {
 	.irq_mask	= cpuintr_disable,
 	.irq_ack	= cpuintr_ack,
 	.irq_eoi	= cpuintr_enable,
+	.flags		= IRQF_NO_THREAD,
 };
 
 static void __init nlm_init_percpu_irqs(void)
diff --git a/arch/mips/netlogic/kvm/kvm_uart.c b/arch/mips/netlogic/kvm/kvm_uart.c
index 2a7da73..75da7e4 100644
--- a/arch/mips/netlogic/kvm/kvm_uart.c
+++ b/arch/mips/netlogic/kvm/kvm_uart.c
@@ -69,7 +69,7 @@ void kvm_handle_pcie_uart(struct pt_regs *regs, unsigned long write,
 	unsigned int rindex = address >> 2, unhandled = 0;
 	struct kvm_arch *arch = kvm_get_arch(regs);
 
-	spin_lock(&arch->uart.lock);
+	raw_spin_lock(&arch->uart.lock);
 
 	if (rindex == 0x0 || rindex == 0x2 || rindex == 0x3d) {
 		if (!write)
@@ -104,7 +104,7 @@ void kvm_handle_pcie_uart(struct pt_regs *regs, unsigned long write,
 				}
 
 				/* Quit the guest and go to QEMU for real print */
-				spin_unlock(&arch->uart.lock);
+				raw_spin_unlock(&arch->uart.lock);
 
 #if 1
 				/* Huge amount of guest output in a short period of time
@@ -210,7 +210,7 @@ void kvm_handle_pcie_uart(struct pt_regs *regs, unsigned long write,
 	} else
 		unhandled = 1;
 
-	spin_unlock(&arch->uart.lock);
+	raw_spin_unlock(&arch->uart.lock);
 
 	if (unhandled)
 		unhandled_exception(__FUNCTION__, address, regs->cp0_epc, write);
diff --git a/arch/mips/netlogic/lib/fmnlib/nlm_msgring.h b/arch/mips/netlogic/lib/fmnlib/nlm_msgring.h
index 3d94e70..68d5625 100644
--- a/arch/mips/netlogic/lib/fmnlib/nlm_msgring.h
+++ b/arch/mips/netlogic/lib/fmnlib/nlm_msgring.h
@@ -76,13 +76,13 @@ do {                                        \
 #else
 
 #define msgrng_access_save(lock, iflags, mflags) do {        \
-  spin_lock_irqsave(lock, iflags);                           \
+  raw_spin_lock_irqsave(lock, iflags);                           \
   msgrng_flags_save(mflags);                                 \
  }while(0)
 
 #define msgrng_access_restore(lock, iflags, mflags) do {     \
   msgrng_flags_restore(mflags);                              \
-  spin_unlock_irqrestore(lock, iflags);                      \
+  raw_spin_unlock_irqrestore(lock, iflags);                      \
  }while(0)
 
 #define msgrng_access_enable(mflags) do {   \
diff --git a/arch/mips/netlogic/xlp/nlm_hal.c b/arch/mips/netlogic/xlp/nlm_hal.c
index 7093d8b..490f5a2 100644
--- a/arch/mips/netlogic/xlp/nlm_hal.c
+++ b/arch/mips/netlogic/xlp/nlm_hal.c
@@ -61,7 +61,7 @@ void nlm_node_init(int node)
 		nodep->socbus = xlp9xx_get_socbus(node);
 	else
 		nodep->socbus = 0;
-	spin_lock_init(&nodep->piclock);
+	raw_spin_lock_init(&nodep->piclock);
 }
 
 int nlm_irq_to_irt(int irq)
diff --git a/arch/mips/netlogic/xlr/setup.c b/arch/mips/netlogic/xlr/setup.c
index 6e5e000..c3a5aec 100644
--- a/arch/mips/netlogic/xlr/setup.c
+++ b/arch/mips/netlogic/xlr/setup.c
@@ -192,7 +192,7 @@ static void nlm_init_node(void)
 	nodep = nlm_current_node();
 	nodep->picbase = nlm_mmio_base(NETLOGIC_IO_PIC_OFFSET);
 	nodep->ebase = read_c0_ebase() & (~((1 << 12) - 1));
-	spin_lock_init(&nodep->piclock);
+	raw_spin_lock_init(&nodep->piclock);
 }
 
 void __init prom_init(void)
diff --git a/arch/mips/pci/msi-xlp.c b/arch/mips/pci/msi-xlp.c
index 42b500a..e37f85f 100644
--- a/arch/mips/pci/msi-xlp.c
+++ b/arch/mips/pci/msi-xlp.c
@@ -106,7 +106,7 @@ struct xlp_msi_data {
 	uint32_t	msi_enabled_mask;
 	uint32_t	msi_alloc_mask;
 	uint32_t	msix_alloc_mask;
-	spinlock_t	msi_lock;
+	raw_spinlock_t	msi_lock;
 };
 
 /*
@@ -127,10 +127,10 @@ static void xlp_msi_enable(struct irq_data *d)
 	int vec;
 
 	vec = nlm_irq_msivec(d->irq);
-	spin_lock_irqsave(&md->msi_lock, flags);
+	raw_spin_lock_irqsave(&md->msi_lock, flags);
 	md->msi_enabled_mask |= 1u << vec;
 	nlm_write_reg(md->lnkbase, PCIE_MSI_EN, md->msi_enabled_mask);
-	spin_unlock_irqrestore(&md->msi_lock, flags);
+	raw_spin_unlock_irqrestore(&md->msi_lock, flags);
 }
 
 static void xlp_msi_disable(struct irq_data *d)
@@ -140,10 +140,10 @@ static void xlp_msi_disable(struct irq_data *d)
 	int vec;
 
 	vec = nlm_irq_msivec(d->irq);
-	spin_lock_irqsave(&md->msi_lock, flags);
+	raw_spin_lock_irqsave(&md->msi_lock, flags);
 	md->msi_enabled_mask &= ~(1u << vec);
 	nlm_write_reg(md->lnkbase, PCIE_MSI_EN, md->msi_enabled_mask);
-	spin_unlock_irqrestore(&md->msi_lock, flags);
+	raw_spin_unlock_irqrestore(&md->msi_lock, flags);
 }
 
 static void xlp_msi_mask_ack(struct irq_data *d)
@@ -272,7 +272,7 @@ static int xlp_setup_msi(uint64_t lnkbase, int node, int link,
 	md = irq_get_handler_data(xirq);
 	msiaddr = MSI_LINK_ADDR(node, link);
 
-	spin_lock_irqsave(&md->msi_lock, flags);
+	raw_spin_lock_irqsave(&md->msi_lock, flags);
 	if (md->msi_alloc_mask == 0) {
 		/* switch the link IRQ to MSI range */
 		xlp_config_link_msi(lnkbase, lirq, msiaddr);
@@ -285,11 +285,11 @@ static int xlp_setup_msi(uint64_t lnkbase, int node, int link,
 	/* allocate a MSI vec, and tell the bridge about it */
 	msivec = fls(md->msi_alloc_mask);
 	if (msivec == XLP_MSIVEC_PER_LINK) {
-		spin_unlock_irqrestore(&md->msi_lock, flags);
+		raw_spin_unlock_irqrestore(&md->msi_lock, flags);
 		return -ENOMEM;
 	}
 	md->msi_alloc_mask |= (1u << msivec);
-	spin_unlock_irqrestore(&md->msi_lock, flags);
+	raw_spin_unlock_irqrestore(&md->msi_lock, flags);
 
 	msg.address_hi = msiaddr >> 32;
 	msg.address_lo = msiaddr & 0xffffffff;
@@ -360,7 +360,7 @@ static int xlp_setup_msix(uint64_t lnkbase, int node, int link,
 	md = irq_get_handler_data(xirq);
 	msixaddr = MSIX_LINK_ADDR(node, link);
 
-	spin_lock_irqsave(&md->msi_lock, flags);
+	raw_spin_lock_irqsave(&md->msi_lock, flags);
 	/* switch the PCIe link to MSI-X mode at the first alloc */
 	if (md->msix_alloc_mask == 0)
 		xlp_config_link_msix(lnkbase, lirq, msixaddr);
@@ -368,11 +368,11 @@ static int xlp_setup_msix(uint64_t lnkbase, int node, int link,
 	/* allocate a MSI-X vec, and tell the bridge about it */
 	t = fls(md->msix_alloc_mask);
 	if (t == XLP_MSIXVEC_PER_LINK) {
-		spin_unlock_irqrestore(&md->msi_lock, flags);
+		raw_spin_unlock_irqrestore(&md->msi_lock, flags);
 		return -ENOMEM;
 	}
 	md->msix_alloc_mask |= (1u << t);
-	spin_unlock_irqrestore(&md->msi_lock, flags);
+	raw_spin_unlock_irqrestore(&md->msi_lock, flags);
 
 	xirq += t;
 	msixvec = nlm_irq_msixvec(xirq);
@@ -423,7 +423,7 @@ void __init xlp_init_node_msi_irqs(int node, int link)
 
 	/* Alloc an MSI block for the link */
 	md = kzalloc(sizeof(*md), GFP_KERNEL);
-	spin_lock_init(&md->msi_lock);
+	raw_spin_lock_init(&md->msi_lock);
 	md->msi_enabled_mask = 0;
 	md->msi_alloc_mask = 0;
 	md->msix_alloc_mask = 0;
diff --git a/drivers/gpio/gpio-xlp.c b/drivers/gpio/gpio-xlp.c
index 5c2fa10..ed4a848 100644
--- a/drivers/gpio/gpio-xlp.c
+++ b/drivers/gpio/gpio-xlp.c
@@ -100,7 +100,7 @@ struct xlp_gpio_priv {
 	u32 gpio_padsmpl;
 	u32 prid;
 	struct irq_domain *domain;
-	spinlock_t spin_lock;
+	raw_spinlock_t raw_spin_lock;
 };
 
 static inline u32 xlp_gpio_get_reg(struct xlp_gpio_priv *priv, int reg,
@@ -137,12 +137,12 @@ static void xlp_gpio_enable(struct irq_data *d)
 	int intr_enable_reg = priv->intr_enable_reg;
 	unsigned long flags;
 
-	spin_lock_irqsave(&priv->spin_lock, flags);
+	raw_spin_lock_irqsave(&priv->raw_spin_lock, flags);
 	xlp_gpio_set_reg(priv, intr_enable_reg, g_pin, 1);
 	__set_bit(g_pin, priv->gpio_enabled_mask);
 	xlp_gpio_set_reg(priv, priv->intr_polarity_reg, g_pin, 1);
 	xlp_gpio_set_reg(priv, priv->intr_type_reg, g_pin, 0);
-	spin_unlock_irqrestore(&priv->spin_lock, flags);
+	raw_spin_unlock_irqrestore(&priv->raw_spin_lock, flags);
 }
 
 static void xlp_gpio_disable(struct irq_data *d)
@@ -152,10 +152,10 @@ static void xlp_gpio_disable(struct irq_data *d)
 	int g_pin = d->hwirq;
 	unsigned long flags;
 
-	spin_lock_irqsave(&priv->spin_lock, flags);
+	raw_spin_lock_irqsave(&priv->raw_spin_lock, flags);
 	xlp_gpio_set_reg(priv, intr_enable_reg, g_pin, 0);
 	__clear_bit(g_pin, priv->gpio_enabled_mask);
-	spin_unlock_irqrestore(&priv->spin_lock, flags);
+	raw_spin_unlock_irqrestore(&priv->raw_spin_lock, flags);
 }
 
 static void xlp_gpio_mask_ack(struct irq_data *d)
@@ -165,9 +165,9 @@ static void xlp_gpio_mask_ack(struct irq_data *d)
 	int g_pin = d->hwirq;
 	unsigned long flags;
 
-	spin_lock_irqsave(&priv->spin_lock, flags);
+	raw_spin_lock_irqsave(&priv->raw_spin_lock, flags);
 	xlp_gpio_set_reg(priv, intr_enable_reg, g_pin, 0);
-	spin_unlock_irqrestore(&priv->spin_lock, flags);
+	raw_spin_unlock_irqrestore(&priv->raw_spin_lock, flags);
 
 	xlp_gpio_set_reg(priv, priv->intr_status_reg, g_pin, 1);
 }
@@ -179,9 +179,9 @@ static void xlp_gpio_unmask(struct irq_data *d)
 	int g_pin = d->hwirq;
 	unsigned long flags;
 
-	spin_lock_irqsave(&priv->spin_lock, flags);
+	raw_spin_lock_irqsave(&priv->raw_spin_lock, flags);
 	xlp_gpio_set_reg(priv, intr_enable_reg, g_pin, 1);
-	spin_unlock_irqrestore(&priv->spin_lock, flags);
+	raw_spin_unlock_irqrestore(&priv->raw_spin_lock, flags);
 }
 
 static struct irq_chip xlp_gpio_irq_chip = {
@@ -341,7 +341,7 @@ static int xlp_gpio_probe(struct platform_device *pdev)
 	gc->get = xlp_gpio_get;
 	gc->owner = THIS_MODULE;
 
-	spin_lock_init(&priv->spin_lock);
+	raw_spin_lock_init(&priv->raw_spin_lock);
 	pr_info("Node %d: registering %d XLP GPIOs\n", node, gc->ngpio);
 	if (gpiochip_add(gc) < 0)
 		return -EINVAL;
diff --git a/drivers/netlogic/cmem/cmem.c b/drivers/netlogic/cmem/cmem.c
index fb18dfa..61a87c3 100644
--- a/drivers/netlogic/cmem/cmem.c
+++ b/drivers/netlogic/cmem/cmem.c
@@ -64,14 +64,14 @@ struct file_priv_data {
 	atomic_t nallocs;
 #endif
 	struct hlist_head       mhash_head[MMINFO_HASH_SIZE];
-	spinlock_t            	hlock[MMINFO_HASH_SIZE];
+	raw_spinlock_t      	hlock[MMINFO_HASH_SIZE];
 
 };
 
 /* vinfo and pinfo keeps track of the pages */
 struct pinfo {
 	struct page *page; /* pages app-page-size aligned */
-	spinlock_t lock; /* protect for this page */
+	raw_spinlock_t lock; /* protect for this page */
 };
 
 struct vaddr_info {
@@ -141,14 +141,14 @@ static inline int list_add_vinfo(struct file_priv_data *fpriv,
 
 	hash = calc_hash((unsigned long)mm) %  MMINFO_HASH_SIZE;
 
-	spin_lock(&fpriv->hlock[hash]);
+	raw_spin_lock(&fpriv->hlock[hash]);
 	mminfo = list_find_mminfo(fpriv, mm, hash);
-	spin_unlock(&fpriv->hlock[hash]);
+	raw_spin_unlock(&fpriv->hlock[hash]);
 	if(!mminfo) {
 		mminfo = kmalloc(sizeof(struct mm_info), GFP_KERNEL);
 		if(!mminfo) {
 			printk("Error : no mem in %s\n", __FUNCTION__);
-			spin_unlock(&fpriv->hlock[hash]);
+			raw_spin_unlock(&fpriv->hlock[hash]);
 			return -ENOMEM;
 		}
 		INIT_HLIST_NODE(&mminfo->mnode);
@@ -158,7 +158,7 @@ static inline int list_add_vinfo(struct file_priv_data *fpriv,
 		mminfo->hash = hash;
 		mminfo->status = 0;
 		/* check whether it is already added or not */
-		spin_lock(&fpriv->hlock[hash]);
+		raw_spin_lock(&fpriv->hlock[hash]);
 		if((tmp = list_find_mminfo(fpriv, mm, hash)) == NULL) {
 			hlist_add_head(&mminfo->mnode, &fpriv->mhash_head[hash]);
 			DBG_NALLOCS_INC(&fpriv->nallocs);
@@ -166,14 +166,14 @@ static inline int list_add_vinfo(struct file_priv_data *fpriv,
 			kfree(mminfo);
 			mminfo = tmp;
 		}
-		spin_unlock(&fpriv->hlock[hash]);
+		raw_spin_unlock(&fpriv->hlock[hash]);
 	} 
 
 	vinfo->mminfo = (void *)mminfo;
 
-	spin_lock(&fpriv->hlock[hash]);
+	raw_spin_lock(&fpriv->hlock[hash]);
 	hlist_add_head(&vinfo->node, &mminfo->vhead);
-	spin_unlock(&fpriv->hlock[hash]);
+	raw_spin_unlock(&fpriv->hlock[hash]);
 
 	return 0;
 }
@@ -188,14 +188,14 @@ static inline void list_del_vinfo(struct file_priv_data *fpriv, struct vaddr_inf
 	}
 	hash = mminfo->hash;
 	
-	spin_lock(&fpriv->hlock[hash]);
+	raw_spin_lock(&fpriv->hlock[hash]);
 	__hlist_del(&vinfo->node); 
 	mminfo->refcnt--;
 	if(mminfo->refcnt == 0)
 		__hlist_del(&mminfo->mnode); 
 	else
 		mminfo = NULL;
-	spin_unlock(&fpriv->hlock[hash]);
+	raw_spin_unlock(&fpriv->hlock[hash]);
 	if(mminfo) {
 		kfree(mminfo);
 		DBG_NALLOCS_DEC(&fpriv->nallocs);
@@ -377,15 +377,15 @@ static inline int nlm_cmem_unmap_pinfo_entry(struct file_priv_data *fpriv,
 			/* If fault handler is accessing this page and allocated a new page for this index
 			This should not be the case. Lock is taken just for protection of the page  
 			 */
-			spin_lock(&vinfo->pinfo[page_idx].lock);
+			raw_spin_lock(&vinfo->pinfo[page_idx].lock);
 			
 			if((page = vinfo->pinfo[page_idx].page) == NULL) {
-				spin_unlock(&vinfo->pinfo[page_idx].lock);
+				raw_spin_unlock(&vinfo->pinfo[page_idx].lock);
 				continue;
 			}
 			vinfo->pinfo[page_idx].page = NULL;
 			
-			spin_unlock(&vinfo->pinfo[page_idx].lock);
+			raw_spin_unlock(&vinfo->pinfo[page_idx].lock);
 			
 			DBG_NALLOCS_DEC(&fpriv->nallocs); 
 			free_pages((unsigned long)page_address(page), app_pageorder);
@@ -835,7 +835,7 @@ static int nlm_cmem_vma_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 	   for example cpu is accessing a invalid memory which is going to be freed soon ). 
 	   So we need to take lock till we done with the page
 	 */
-	spin_lock(&vinfo->pinfo[off].lock);
+	raw_spin_lock(&vinfo->pinfo[off].lock);
 	if((page = vinfo->pinfo[off].page) == NULL)  {
 		Message("%s %d page null\n", __FUNCTION__, __LINE__);
 		page = alloc_pages(GFP_KERNEL, app_pageorder);
@@ -883,7 +883,7 @@ static int nlm_cmem_vma_fault(struct vm_area_struct *vma, struct vm_fault *vmf)
 	flush_tlb_range(vma, start, start + app_pagesize); 
 	rv =  VM_FAULT_NOPAGE;
 err_exit:
-	spin_unlock(&vinfo->pinfo[off].lock);
+	raw_spin_unlock(&vinfo->pinfo[off].lock);
 	return rv;
 }
 	
diff --git a/drivers/netlogic/dtre/nlm_adma.c b/drivers/netlogic/dtre/nlm_adma.c
index b57e838..4de75ce 100644
--- a/drivers/netlogic/dtre/nlm_adma.c
+++ b/drivers/netlogic/dtre/nlm_adma.c
@@ -446,7 +446,7 @@ static dma_cookie_t nlm_tx_submit (struct dma_async_tx_descriptor *tx)
 	/* nlm_dtre_min_vc is updated in probe function */
 	vc_id = nlm_dtre_min_vc + chan->chan_num;
 
-	spin_lock_bh(&chan->lock);
+	raw_spin_lock_bh(&chan->lock);
 	cookie = nlm_desc_assign_cookie(chan, nlm_tx);
 
 	optype = nlm_tx->optype;
@@ -465,7 +465,7 @@ static dma_cookie_t nlm_tx_submit (struct dma_async_tx_descriptor *tx)
 
 	chan->pending_idx = (chan->pending_idx + 1) & DTRE_MAX_TX_Q_MASK;
 
-	spin_unlock_bh(&chan->lock);
+	raw_spin_unlock_bh(&chan->lock);
 
 	/* handle size restrictions first, in case of 
 	   DMA_MEMSET and DMA_MEMCPY */
@@ -653,26 +653,26 @@ static struct nlm_tx_desc *alloc_tx_desc(struct nlm_adma_chan *chan)
 {
 	struct nlm_tx_desc *ptr;
 
-	spin_lock_bh(&chan->lock);
+	raw_spin_lock_bh(&chan->lock);
 	ptr = chan->desc_pool_head.next;
 	if(ptr != NULL) {
 		chan->desc_pool_head.next = ptr->next;
 		ptr->next = NULL;
 		chan->alloc_desc++;
-		spin_unlock_bh(&chan->lock);
+		raw_spin_unlock_bh(&chan->lock);
 		return ptr;
 	} else {
 		/* dynamic allocation */
 		ptr = cacheline_aligned_kzalloc(sizeof(struct nlm_tx_desc), GFP_KERNEL);
 		if(!ptr) {
-			spin_unlock_bh(&chan->lock);
+			raw_spin_unlock_bh(&chan->lock);
 			panic("OUT OF TX descriptors");
 		}
 		dma_async_tx_descriptor_init(&ptr->async_tx, &chan->common);
 		ptr->async_tx.tx_submit = nlm_tx_submit;
 		ptr->chan = (void *)chan;
 		chan->alloc_desc++;
-		spin_unlock_bh(&chan->lock);
+		raw_spin_unlock_bh(&chan->lock);
 		return ptr;
 	}
 
@@ -681,18 +681,18 @@ static struct nlm_tx_desc *alloc_tx_desc(struct nlm_adma_chan *chan)
 
 static void process_completed_tx(struct nlm_adma_chan * nlm_chan)
 {
-	spin_lock_bh(&nlm_chan->lock);
+	raw_spin_lock_bh(&nlm_chan->lock);
 	__process_completed_tx(nlm_chan);
-	spin_unlock_bh(&nlm_chan->lock);
+	raw_spin_unlock_bh(&nlm_chan->lock);
 }
 
 static void nlm_adma_tasklet(unsigned long data)
 {
 	struct nlm_adma_chan *nlm_chan = (struct nlm_adma_chan *) data;
 
-	spin_lock(&nlm_chan->lock);
+	raw_spin_lock(&nlm_chan->lock);
 	__process_completed_tx(nlm_chan);
-	spin_unlock(&nlm_chan->lock);
+	raw_spin_unlock(&nlm_chan->lock);
 }
 
 static void nlm_adma_free_chan_resources(struct dma_chan *chan)
@@ -1533,7 +1533,7 @@ static int nlm_adma_probe(struct platform_device *pdev)
 
 		nlm_chan->chan_num = loop;
 		nlm_chan->device = adev;
-		spin_lock_init(&nlm_chan->lock);
+		raw_spin_lock_init(&nlm_chan->lock);
 		nlm_chan->common.device = dma_dev;
 		list_add_tail(&nlm_chan->common.device_node, &dma_dev->channels);
 
diff --git a/drivers/netlogic/dtre/nlm_adma.h b/drivers/netlogic/dtre/nlm_adma.h
index 77e73e2..a0b377f 100644
--- a/drivers/netlogic/dtre/nlm_adma.h
+++ b/drivers/netlogic/dtre/nlm_adma.h
@@ -64,7 +64,7 @@
 struct nlm_adma_device {
 	struct platform_device *pdev;
 	struct dma_device common;
-	spinlock_t lock;
+	raw_spinlock_t lock;
 };
 
 struct nlm_hw_desc {
@@ -95,7 +95,7 @@ struct nlm_tx_desc {
 struct nlm_adma_chan {
 	int chan_num; /* channel number */
 	dma_cookie_t completed_cookie;
-	spinlock_t lock; /* protects the descriptor slot pool */
+	raw_spinlock_t lock; /* protects the descriptor slot pool */
 	struct nlm_adma_device *device;
 	struct dma_chan common;
 	struct nlm_tx_desc desc_pool_head; /* Free TX descriptors are linked here */
diff --git a/drivers/netlogic/nae/xlpge.h b/drivers/netlogic/nae/xlpge.h
index 4e58aae..fed9a18 100644
--- a/drivers/netlogic/nae/xlpge.h
+++ b/drivers/netlogic/nae/xlpge.h
@@ -251,7 +251,7 @@ struct active_flow_list
 {
 	volatile int index_to_flow_meta_info[NLM_UCORE_SHARED_TABLE_SIZE];
 	volatile uint64_t cpu_data_rate;
-	spinlock_t lock;
+	raw_spinlock_t lock;
 	volatile uint64_t nr_active_flows;
 	volatile uint64_t nr_flow_created;
 	volatile uint64_t nr_flow_processed;
@@ -268,7 +268,7 @@ struct dev_data
 	struct napi_struct napi;
 	nae_t* nae;
 	net_port_t *nae_port;
-	spinlock_t lock;
+	raw_spinlock_t lock;
 	unsigned short port;
 	unsigned short inited;
 	unsigned short node;
diff --git a/drivers/netlogic/nae/xlpge_ethtool.c b/drivers/netlogic/nae/xlpge_ethtool.c
index 418c36b..3d23dc3 100644
--- a/drivers/netlogic/nae/xlpge_ethtool.c
+++ b/drivers/netlogic/nae/xlpge_ethtool.c
@@ -164,14 +164,14 @@ static int xlp_get_eeprom(struct net_device *dev,
 
 	nlm_eeprom = get_nlm_eeprom();
 
-	spin_lock_irqsave(&priv->lock, flags);
+	raw_spin_lock_irqsave(&priv->lock, flags);
 
 	eeprom_dump(nlm_eeprom, buff, eeprom->offset,eeprom->len);
 
 	for(i = 0; i < eeprom->len; i++)
 		temp[i] = buff[i];
 
-	spin_unlock_irqrestore(&priv->lock, flags);
+	raw_spin_unlock_irqrestore(&priv->lock, flags);
 
 	return 0;
 }
@@ -188,14 +188,14 @@ static int xlp_set_eeprom(struct net_device *dev,
 
 	eeprom_get_mac_addr(nlm_eeprom, data, 0);
 
-	spin_lock_irqsave(&priv->lock, flags);
+	raw_spin_lock_irqsave(&priv->lock, flags);
 
 	if (eeprom->magic == 0xAA) {
 		data[eeprom->offset] = *temp;
 		eeprom_set_mac_addr(nlm_eeprom, data, 0);
 	}
 
-	spin_unlock_irqrestore(&priv->lock, flags);
+	raw_spin_unlock_irqrestore(&priv->lock, flags);
 
 	return 0;
 }
@@ -243,7 +243,7 @@ static void xlp_get_regs(struct net_device *dev,
 
 	memset((void *)data, 0, NLM_ETHTOOL_REG_LEN);
 
-	spin_lock_irqsave(&priv->lock, flags);
+	raw_spin_lock_irqsave(&priv->lock, flags);
 //TODO:
 #if 0
 	for(i=0; i <= NLM_NUM_REG_DUMP; i++)
@@ -251,7 +251,7 @@ static void xlp_get_regs(struct net_device *dev,
 					priv->index, R_TX_CONTROL + i);
 #endif
 
-	spin_unlock_irqrestore(&priv->lock, flags);
+	raw_spin_unlock_irqrestore(&priv->lock, flags);
 }
 
 static u32 xlp_get_msglevel(struct net_device *dev)
@@ -274,7 +274,7 @@ static int xlp_nway_reset(struct net_device *dev)
 	if (priv->type != SGMII_IF)
 		return -EIO;
 
-	spin_lock_irqsave(&priv->lock, flags);
+	raw_spin_lock_irqsave(&priv->lock, flags);
 
 	mii_status = nlm_xlp_mac_mii_read(priv, MII_BMCR);
 	if (mii_status & BMCR_ANENABLE) {
@@ -283,7 +283,7 @@ static int xlp_nway_reset(struct net_device *dev)
 		ret = 0;
 	}
 
-	spin_unlock_irqrestore(&priv->lock, flags);
+	raw_spin_unlock_irqrestore(&priv->lock, flags);
 
 	return ret;
 }
@@ -296,10 +296,10 @@ static u32 xlp_get_link(struct net_device *dev)
 	if (priv->type != SGMII_IF)
 		return -EIO;
 
-	spin_lock_irqsave(&priv->lock, flags);
+	raw_spin_lock_irqsave(&priv->lock, flags);
 	//nlm_hal_status_ext_phy( priv->node, priv->phy.addr, &mii_info);
 
-	spin_unlock_irqrestore(&priv->lock, flags);
+	raw_spin_unlock_irqrestore(&priv->lock, flags);
 
 	if(mii_info.link_stat==1)
                 return 1;
@@ -420,12 +420,12 @@ static void xlp_get_ethtool_stats (struct net_device *dev,
 	ulong *tmp_stats;
 	int i;
 
-	spin_lock_irqsave(&priv->lock, flags);
+	raw_spin_lock_irqsave(&priv->lock, flags);
 
 //TODO:
 	//xlp_get_mac_stats(dev, &priv->stats);
 
-	spin_unlock_irqrestore(&priv->lock, flags);
+	raw_spin_unlock_irqrestore(&priv->lock, flags);
 
 	tmp_stats = (ulong *)&priv->stats;
 	for(i = 0; i < NLM_STATS_KEY_LEN; i++) {
diff --git a/drivers/netlogic/nae/xlpge_nae.c b/drivers/netlogic/nae/xlpge_nae.c
index d66923d..566528f 100644
--- a/drivers/netlogic/nae/xlpge_nae.c
+++ b/drivers/netlogic/nae/xlpge_nae.c
@@ -996,12 +996,12 @@ static int  nlm_xlp_nae_open (struct net_device *dev)
 
 
 	if (priv->inited) {
-		spin_lock_irq(&priv->lock);
+		raw_spin_lock_irq(&priv->lock);
 		if(nae_cfg->owned)
 			netsoc_open_port(nae_cfg, priv->port);
 			//nlm_xlp_mac_set_enable(priv, 1);
 		netif_tx_wake_all_queues(dev);
-		spin_unlock_irq(&priv->lock);
+		raw_spin_unlock_irq(&priv->lock);
 		return 0;
 	}
 
@@ -1010,7 +1010,7 @@ static int  nlm_xlp_nae_open (struct net_device *dev)
 		int port = priv->port;
 		irq  = irt_irq_table[PIC_IRT_NA_INDEX(port)][0];
 		if (request_irq( irq, nlm_xlp_nae_int_handler,
-			IRQF_SHARED, dev->name, dev)) {
+			IRQF_SHARED | IRQF_NO_THREAD, dev->name, dev)) {
 			ret = -EBUSY;
 			printk("can't get mac interrupt line (%d)\n",dev->irq);
 		}
@@ -1054,7 +1054,7 @@ static int  nlm_xlp_nae_stop (struct net_device *dev)
 	struct dev_data *priv = netdev_priv(dev);
 	nae_t* nae_cfg = priv->nae;
 
-	spin_lock_irq(&priv->lock);
+	raw_spin_lock_irq(&priv->lock);
 
 	if (nae_cfg->owned){
 		//nlm_xlp_mac_set_enable(priv, 0);
@@ -1062,7 +1062,7 @@ static int  nlm_xlp_nae_stop (struct net_device *dev)
 	priv->inited = 0;
 	netif_tx_stop_all_queues(dev);
 
-	spin_unlock_irq(&priv->lock);
+	raw_spin_unlock_irq(&priv->lock);
 	return 0;
 }
 
@@ -1202,7 +1202,7 @@ static int nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu)
 		return -EINVAL;
 	}
 
-	spin_lock_irqsave(&priv->lock, flags);
+	raw_spin_lock_irqsave(&priv->lock, flags);
 
 	len = new_mtu + ETH_HLEN + ETH_FCS_LEN + SMP_CACHE_BYTES;
 	local_mtu = len & ~(SMP_CACHE_BYTES - 1);
@@ -1222,7 +1222,7 @@ static int nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu)
 		//	priv->phy.addr, local_mtu);
 	}
 	else {
-		spin_unlock_irqrestore(&priv->lock, flags);
+		raw_spin_unlock_irqrestore(&priv->lock, flags);
 		return -1;
 	}
 
@@ -1237,7 +1237,7 @@ static int nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu)
 
 	}
 
-	spin_unlock_irqrestore(&priv->lock, flags);
+	raw_spin_unlock_irqrestore(&priv->lock, flags);
 	return 0;
 }
 
@@ -1250,12 +1250,12 @@ static struct net_device_stats *nlm_xlp_mac_get_stats(struct net_device *dev)
 	struct dev_data *priv = netdev_priv(dev);
 	ulong flags;
 
-	spin_lock_irqsave(&priv->lock, flags);
+	raw_spin_lock_irqsave(&priv->lock, flags);
 
 	xlp_get_mac_stats(dev, &priv->stats);
 
 	/* XXX update other stats here */
-	spin_unlock_irqrestore(&priv->lock, flags);
+	raw_spin_unlock_irqrestore(&priv->lock, flags);
 
 	return &priv->stats;
 }
@@ -1269,11 +1269,11 @@ static void  nlm_xlp_nae_tx_timeout (struct net_device *dev)
 {
 	struct dev_data *priv = netdev_priv(dev);
 
-	spin_lock_irq(&priv->lock);
+	raw_spin_lock_irq(&priv->lock);
 
 	priv->stats.tx_errors++;
 
-	spin_unlock_irq(&priv->lock);
+	raw_spin_unlock_irq(&priv->lock);
 
 	netif_tx_wake_all_queues(dev);
 
@@ -1377,7 +1377,7 @@ static int nlm_per_port_nae_init(nae_t* nae_cfg, int port, int maxnae)
 	dev->tx_queue_len = 0;
 
 	priv = netdev_priv(dev);
-	spin_lock_init(&priv->lock);
+	raw_spin_lock_init(&priv->lock);
 	priv->dev = dev;
 	priv->nae = nae_cfg;
 	priv->nae_port = get_net_port(nae_cfg, port);
diff --git a/drivers/netlogic/nae/xlpge_rx.c b/drivers/netlogic/nae/xlpge_rx.c
index e70c0a9..6b26515 100644
--- a/drivers/netlogic/nae/xlpge_rx.c
+++ b/drivers/netlogic/nae/xlpge_rx.c
@@ -122,7 +122,7 @@ static void dump_cpu_active_flow_info(int cpu, struct seq_file *m, int weight)
 	if (!nlm_active_flow_list || !nlm_flow_meta_info)
 		return;
 
-	spin_lock_irqsave(&afl->lock, mflags);
+	raw_spin_lock_irqsave(&afl->lock, mflags);
 	seq_printf(m, "Cpu%d ==> WeightInUcore %d ActiveFlows %llu, "
 		      "FlowCreated %llu, FlowProcessed %llu\n", cpu, weight,
 			(unsigned long long)afl->nr_active_flows,
@@ -130,7 +130,7 @@ static void dump_cpu_active_flow_info(int cpu, struct seq_file *m, int weight)
 			(unsigned long long)afl->nr_flow_processed);
 	afl->nr_flow_created = 0;
 	afl->nr_flow_processed = 0;
-	spin_unlock_irqrestore(&afl->lock, mflags);
+	raw_spin_unlock_irqrestore(&afl->lock, mflags);
 	return;
 }
 
@@ -169,7 +169,7 @@ static void nlm_remove_inactive_flow(int cpu)
 	int index;
 	int i = 0, j = 0;
 
-	spin_lock_irqsave(&afl->lock, mflags);
+	raw_spin_lock_irqsave(&afl->lock, mflags);
 	for (i = 0; i < afl->nr_active_flows; i++) {
 		index = afl->index_to_flow_meta_info[i];
 		fmi = nlm_flow_meta_info + index;
@@ -209,7 +209,7 @@ static void nlm_remove_inactive_flow(int cpu)
 		}
 		mb();
 	}
-	spin_unlock_irqrestore(&afl->lock, mflags);
+	raw_spin_unlock_irqrestore(&afl->lock, mflags);
 }
 
 static void setup_search_path(void)
@@ -348,7 +348,7 @@ static void nlm_load_balance_timer_func(unsigned long arg)
 			Message("NR_ACTIVE_FLOWS %ld", afl->nr_active_flows);
 
 restart:
-			spin_lock_irqsave(&afl->lock, mflags);
+			raw_spin_lock_irqsave(&afl->lock, mflags);
 			for (j = 0; j < afl->nr_active_flows; j++) {
 				fmi = nlm_flow_meta_info +
 					afl->index_to_flow_meta_info[j];
@@ -359,7 +359,7 @@ restart:
 
 				if (fmi->cpu_owner !=
 					nlm_load_balance_search_cpu[cpu][i]) {
-					spin_unlock_irqrestore(&afl->lock, mflags);
+					raw_spin_unlock_irqrestore(&afl->lock, mflags);
 					Message("Flow is borrowed by cpu %lld\n",
 						fmi->cpu_owner);
 					goto restart;
@@ -380,9 +380,9 @@ restart:
 					afl->index_to_flow_meta_info[j] = 0;
 				j--;
 				afl->nr_active_flows--;
-				spin_unlock_irqrestore(&afl->lock, mflags);
+				raw_spin_unlock_irqrestore(&afl->lock, mflags);
 
-				spin_lock_irqsave(&myafl->lock, mflags);
+				raw_spin_lock_irqsave(&myafl->lock, mflags);
 				/* Create a new entry for this FMI in 
 				 * ACTIVE_FLOW_LIST. Change the u-core shared
 				 * memroy once all data structures are in place.
@@ -391,7 +391,7 @@ restart:
 				myafl->index_to_flow_meta_info[k] = idx_to_fmi;
 				myafl->nr_active_flows++;
 				mb();
-				spin_unlock_irqrestore(&myafl->lock, mflags);
+				raw_spin_unlock_irqrestore(&myafl->lock, mflags);
 
 				/*Update ucore shared memory*/
 				lcpu = __cpu_number_map[cpu];
@@ -405,9 +405,9 @@ restart:
 				*(ucore_shared_data + idx_to_fmi) = 
 					__cpu_number_map[cpu];
 
-				spin_lock_irqsave(&afl->lock, mflags);
+				raw_spin_lock_irqsave(&afl->lock, mflags);
 			}
-			spin_unlock_irqrestore(&afl->lock, mflags);
+			raw_spin_unlock_irqrestore(&afl->lock, mflags);
 		}
 	}
 	if (!myafl->nr_active_flows)
@@ -467,7 +467,7 @@ void nlm_init_load_balance(void)
 
 	/*Init per cpu flow lock*/
 	for (i = 0; i < NUM_LOAD_BALANCE_CPU; i++)
-		spin_lock_init(&((nlm_active_flow_list + i)->lock));
+		raw_spin_lock_init(&((nlm_active_flow_list + i)->lock));
 
 	/*Set owner field to -1*/
 	for (i = 0; i < NLM_UCORE_SHARED_TABLE_SIZE; i++)
@@ -574,12 +574,12 @@ static inline void nlm_update_flow_stats(unsigned int *prepad,
 	if (unlikely(fmi->cpu_owner == -1)) {
 		/*New flow, Create an entry in active flow list*/
 		local_irq_save(mflags);
-		if (!spin_trylock(&afl->lock)) {
+		if (!raw_spin_trylock(&afl->lock)) {
 			local_irq_restore(mflags);
 			return;
 		}
 		if (fmi->cpu_owner != -1) {
-			spin_unlock(&afl->lock);
+			raw_spin_unlock(&afl->lock);
 			local_irq_restore(mflags);
 			return; 
 		}
@@ -593,7 +593,7 @@ static inline void nlm_update_flow_stats(unsigned int *prepad,
 		mb();
 		afl->nr_active_flows++;
 		afl->nr_flow_created++;
-		spin_unlock(&afl->lock);
+		raw_spin_unlock(&afl->lock);
 		local_irq_restore(mflags);
 	}
 	fmi->total_bytes_rcvd += len;
diff --git a/drivers/netlogic/netl7driver/netl7driver.c b/drivers/netlogic/netl7driver/netl7driver.c
index 0b9b88d..93f9400 100755
--- a/drivers/netlogic/netl7driver/netl7driver.c
+++ b/drivers/netlogic/netl7driver/netl7driver.c
@@ -115,7 +115,7 @@ struct nlm_device
   u32 regmap_size;
   u32 sysmem_size;
   u32 packetmem_size;
-  spinlock_t lock;
+  raw_spinlock_t lock;
 };
 
 /* A list of all the devices discovered on the system 
@@ -198,7 +198,7 @@ nlm_pci_probe (struct pci_dev *nlm_dev, const struct pci_device_id *nlm_id)
   device_list[dev_id].regmap_base = pci_resource_start (nlm_dev, 0);
   device_list[dev_id].regmap_size = pci_resource_len (nlm_dev, 0);
   device_list[dev_id].proc_entry = NULL;
-  spin_lock_init (&device_list[dev_id].lock);
+  raw_spin_lock_init (&device_list[dev_id].lock);
 
   if (type == NLM_DEVICE_FAMOS)
     {
@@ -220,7 +220,7 @@ nlm_pci_probe (struct pci_dev *nlm_dev, const struct pci_device_id *nlm_id)
           device_list[dev_id].regmap_base = regmap_base;
           device_list[dev_id].regmap_size = regmap_size;
           device_list[dev_id].proc_entry = NULL;
-          spin_lock_init (&device_list[dev_id].lock);
+          raw_spin_lock_init (&device_list[dev_id].lock);
         }
     }
   else if  (type == NLM_DEVICE_XAUIEX2)
@@ -243,7 +243,7 @@ nlm_pci_probe (struct pci_dev *nlm_dev, const struct pci_device_id *nlm_id)
       device_list[dev_id].regmap_base = regmap_base;
       device_list[dev_id].regmap_size = regmap_size;
       device_list[dev_id].proc_entry = NULL;
-      spin_lock_init (&device_list[dev_id].lock);
+      raw_spin_lock_init (&device_list[dev_id].lock);
     }
   
   /* enable bus mastering */
@@ -429,7 +429,7 @@ nlm_device_open (struct inode *inode, struct file *file)
          For cat on the /proc device, just let them happen */
       unsigned long flags;
       /*NLM_INFO (":open The file reference count is %ld\n", file->f_count.counter);*/
-      spin_lock_irqsave (&dev->lock, flags);
+      raw_spin_lock_irqsave (&dev->lock, flags);
 #ifndef MP_SUPPORT
       if (dev->owner_pid == 0)
         dev->owner_pid = current->pid;
@@ -439,12 +439,12 @@ nlm_device_open (struct inode *inode, struct file *file)
         }
       else
         {
-          spin_unlock_irqrestore (&dev->lock, flags);
+          raw_spin_unlock_irqrestore (&dev->lock, flags);
           return -EBUSY;
         }
 #endif
       file->private_data = dev;
-      spin_unlock_irqrestore (&dev->lock, flags);
+      raw_spin_unlock_irqrestore (&dev->lock, flags);
       
       /* Note! we cannot use single open, when the
          file has been opened with write, as we
@@ -642,9 +642,9 @@ nlm_device_close (struct inode *inode, struct file *file)
     {
 #ifndef MP_SUPPORT
       unsigned long flags;
-      spin_lock_irqsave (&dev->lock, flags);
+      raw_spin_lock_irqsave (&dev->lock, flags);
       dev->owner_pid = 0;
-      spin_unlock_irqrestore (&dev->lock, flags);
+      raw_spin_unlock_irqrestore (&dev->lock, flags);
 #endif
       return 0;
     }
diff --git a/drivers/netlogic/nlmcrypto/cryptodrv.c b/drivers/netlogic/nlmcrypto/cryptodrv.c
index 209a2c3..bac9929 100644
--- a/drivers/netlogic/nlmcrypto/cryptodrv.c
+++ b/drivers/netlogic/nlmcrypto/cryptodrv.c
@@ -57,7 +57,7 @@ static atomic_t nfiles_opened = { 0 };
 /* */
 struct file_priv_data {
 	struct hlist_head       hctxt;
-	spinlock_t		hlock;
+	raw_spinlock_t		hlock;
 };
 
 /* Pages for handling the msgring responses to the userspace apps */
@@ -66,7 +66,7 @@ static unsigned int page_refcnt[NLM_CRYPTO_MAX_CTXT_PAGES];
 struct hlist_head   pctxt_head[NLM_CRYPTO_MAX_CTXT_PAGES];
 static int rsp_desc_page_order = 2;
 static int num_rsp_descs_per_page = 0;
-static spinlock_t plock;
+static raw_spinlock_t plock;
 static unsigned long page_size = 0;
 static unsigned long long page_alloc_map = 0x0ULL;
 static unsigned long long pctxt_full_map = 0x0ULL;
@@ -105,7 +105,7 @@ static inline struct cryptosoc_rsp *get_rsp_from_index(unsigned int index, int f
 	Message("%s in, index %d pidx %d page %lx\n", __FUNCTION__,
 			index, page_idx, (unsigned long)page_address(page_ptr[page_idx]));
 
-	spin_lock_irqsave(&plock, flags);
+	raw_spin_lock_irqsave(&plock, flags);
 	if((page = page_ptr[page_idx])) {
 		index = index % num_rsp_descs_per_page;
 		rsp = (struct cryptosoc_rsp *)((unsigned long)page_address(page) + 
@@ -114,7 +114,7 @@ static inline struct cryptosoc_rsp *get_rsp_from_index(unsigned int index, int f
 		if(from_intr) 
 			atomic_inc(&rsp->used_by_intr);
 	}
-	spin_unlock_irqrestore(&plock, flags);
+	raw_spin_unlock_irqrestore(&plock, flags);
 	return rsp;
 }
 
@@ -128,10 +128,10 @@ static inline struct cryptosoc_rsp *_alloc_rsp_desc(struct file_priv_data *fpriv
 	rsp->owner = current->pid;
 
 	/* Add the entry in the file list */
-	spin_lock(&fpriv->hlock);
+	raw_spin_lock(&fpriv->hlock);
 	INIT_HLIST_NODE(node);
 	hlist_add_head(node, &fpriv->hctxt);
-	spin_unlock(&fpriv->hlock);
+	raw_spin_unlock(&fpriv->hlock);
 
 	Message("%s out, rsp %lx sessionid %d index %d\n", 
 		__FUNCTION__, (unsigned long)rsp, rsp->sessionid, rsp->index);
@@ -150,13 +150,13 @@ static struct cryptosoc_rsp *create_new_rsp_desc(struct file_priv_data *fpriv)
 	unsigned long flags;
 
 recheck:
-	spin_lock_irqsave(&plock, flags);
+	raw_spin_lock_irqsave(&plock, flags);
 	page_idx = get_page_free_index();
 	if(!page_idx) {
-		spin_unlock_irqrestore(&plock, flags);
+		raw_spin_unlock_irqrestore(&plock, flags);
 		return NULL;
 	}
-	spin_unlock_irqrestore(&plock, flags);
+	raw_spin_unlock_irqrestore(&plock, flags);
 
 	/* subtract one for the array/bitmap index */
 	page_idx--;
@@ -193,7 +193,7 @@ recheck:
 	}
 	
 	/* if already allocated by some one */
-	spin_lock_irqsave(&plock,flags);
+	raw_spin_lock_irqsave(&plock,flags);
 	if(!page_ptr[page_idx]) {
 		page_ptr[page_idx] = page;
 		pctxt_head[page_idx].first = thead.first;
@@ -204,7 +204,7 @@ recheck:
 	}
 	
 	if(hlist_empty(&pctxt_head[page_idx])) {
-		spin_unlock_irqrestore(&plock, flags);
+		raw_spin_unlock_irqrestore(&plock, flags);
 		if(page)
 			free_pages((unsigned long)page_address(page), rsp_desc_page_order); 
 		goto recheck;
@@ -216,7 +216,7 @@ recheck:
 		pctxt_full_map |= (1ULL << page_idx);
 
 	page_refcnt[page_idx]++;
-	spin_unlock_irqrestore(&plock, flags);
+	raw_spin_unlock_irqrestore(&plock, flags);
 
 	return _alloc_rsp_desc(fpriv, node);
 }
@@ -231,11 +231,11 @@ static struct cryptosoc_rsp *alloc_rsp_desc(struct file_priv_data *fpriv)
 			page_alloc_map, pctxt_full_map);
 
 	/* Remove the entry from the main page list */
-	spin_lock_irqsave(&plock, flags);
+	raw_spin_lock_irqsave(&plock, flags);
 	/* if all are full */
 	page_idx = get_pctxt_free_index();
 	if(!page_idx) {
-		spin_unlock_irqrestore(&plock, flags);
+		raw_spin_unlock_irqrestore(&plock, flags);
 		return NULL;
 	}
 
@@ -244,7 +244,7 @@ static struct cryptosoc_rsp *alloc_rsp_desc(struct file_priv_data *fpriv)
 
 	/* if not been allocated */
 	if(page_ptr[page_idx] == NULL) {
-		spin_unlock_irqrestore(&plock, flags);
+		raw_spin_unlock_irqrestore(&plock, flags);
 		return create_new_rsp_desc(fpriv);
 	}		
 
@@ -254,7 +254,7 @@ static struct cryptosoc_rsp *alloc_rsp_desc(struct file_priv_data *fpriv)
 		pctxt_full_map |= (1ULL << page_idx);
 
 	page_refcnt[page_idx]++;
-	spin_unlock_irqrestore(&plock, flags);
+	raw_spin_unlock_irqrestore(&plock, flags);
 	
 	return _alloc_rsp_desc(fpriv, node);
 }
@@ -288,18 +288,18 @@ static void free_rsp_desc(struct file_priv_data *fpriv, unsigned int index, int
 
 	/* if it is used by the intr */
 check_again:
-	spin_lock_irqsave(&plock, flags);
+	raw_spin_lock_irqsave(&plock, flags);
 	if(atomic_read(&rsp->used_by_intr)) {
-		spin_unlock_irqrestore(&plock, flags);
+		raw_spin_unlock_irqrestore(&plock, flags);
 		schedule_timeout(1);
 		goto check_again;
 	}
-	spin_unlock_irqrestore(&plock, flags);
+	raw_spin_unlock_irqrestore(&plock, flags);
 		
-	spin_lock(&fpriv->hlock);
+	raw_spin_lock(&fpriv->hlock);
 	node = (struct hlist_node *)rsp->priv_data;
 	__hlist_del(node);
-	spin_unlock(&fpriv->hlock);
+	raw_spin_unlock(&fpriv->hlock);
 
 	if(rsp->fdctxt) {
 		eventfd_ctx_put((struct eventfd_ctx *)rsp->fdctxt);
@@ -309,7 +309,7 @@ check_again:
  	page_idx = GET_PAGE_INDEX(rsp->index);
 	page = page_ptr[page_idx];
 
-	spin_lock_irqsave(&plock, flags);
+	raw_spin_lock_irqsave(&plock, flags);
 	page_refcnt[page_idx]--;
 	if(!page_refcnt[page_idx]) {
 		page_ptr[page_idx] = NULL;
@@ -323,7 +323,7 @@ check_again:
 		hlist_add_head(node, &pctxt_head[page_idx]);
 	}
 	pctxt_full_map &= (~(1ULL << page_idx));
-	spin_unlock_irqrestore(&plock, flags);
+	raw_spin_unlock_irqrestore(&plock, flags);
 
 	if(page) {
 		free_pages((unsigned long)page_address(page), rsp_desc_page_order); 
@@ -477,13 +477,13 @@ static int crypto_driver_release(struct inode *inode, struct file *filp)
 	Message("%s in \n", __FUNCTION__);
 	if(fpriv) {
 		while(1) {
-			spin_lock(&fpriv->hlock);
+			raw_spin_lock(&fpriv->hlock);
 			if(hlist_empty(&fpriv->hctxt)) {
-				spin_unlock(&fpriv->hlock);
+				raw_spin_unlock(&fpriv->hlock);
 				break;
 			}
 			node = fpriv->hctxt.first;
-			spin_unlock(&fpriv->hlock);
+			raw_spin_unlock(&fpriv->hlock);
 			rsp = ( struct cryptosoc_rsp *) ((unsigned long)node -
 					((unsigned long)(&((struct cryptosoc_rsp *)0)->priv_data)));
 			Message("%s Calling for rsp %lx index %d\n", __FUNCTION__, (unsigned long)rsp, rsp->index);
diff --git a/drivers/netlogic/pkt_pool_mem/pkt_pool_mem.c b/drivers/netlogic/pkt_pool_mem/pkt_pool_mem.c
index bd257a3..08be5c1 100644
--- a/drivers/netlogic/pkt_pool_mem/pkt_pool_mem.c
+++ b/drivers/netlogic/pkt_pool_mem/pkt_pool_mem.c
@@ -178,7 +178,7 @@ static long pktmem_ioctl (struct file *fptr, unsigned int cmd, unsigned long dp)
 #ifdef PKTMEM_DEBUG
 	printk("pktmem: icoctl enter, cmd %d.\n", cmd);
 #endif
-	spin_lock(&ioctl_lock);
+	raw_spin_lock(&ioctl_lock);
 	dptr = &data;
 	rc = 0;
 
@@ -213,7 +213,7 @@ static long pktmem_ioctl (struct file *fptr, unsigned int cmd, unsigned long dp)
 
 	copy_to_user(dp, dptr, sizeof(brcm_devmem_ioctl_t));
 
-	spin_unlock(&ioctl_lock);
+	raw_spin_unlock(&ioctl_lock);
 	return rc;
 }
 
diff --git a/drivers/netlogic/soc_interface/on_chip.c b/drivers/netlogic/soc_interface/on_chip.c
index 17c8c3c..a964029 100644
--- a/drivers/netlogic/soc_interface/on_chip.c
+++ b/drivers/netlogic/soc_interface/on_chip.c
@@ -88,8 +88,8 @@ typedef int (*intr_vchandler)(int vc);
 static intr_vchandler xlp_intr_vc_handler;
 unsigned int intr_vc_mask[NR_CPUS];
 
-/* make this a read/write spinlock */
-spinlock_t msgrng_lock;
+/* make this a read/write raw_spinlock */
+raw_spinlock_t msgrng_lock;
 static nlm_common_atomic_t msgring_registered;
 
 struct msgstn_handler {
@@ -768,9 +768,9 @@ int nlm_xlp_register_intr_vc(int cpu, int vc)
 	node = cpu / 32;
 	nlm_hal_enable_vc_intr(node, (cpu*4 + vc) & 0x7f);
 
-	spin_lock_irqsave(&msgrng_lock, flags);
+	raw_spin_lock_irqsave(&msgrng_lock, flags);
 	intr_vc_mask[cpu] |= (1 << vc);
-	spin_unlock_irqrestore(&msgrng_lock, flags);
+	raw_spin_unlock_irqrestore(&msgrng_lock, flags);
 
 	/*printk("%s in, cpu %d intr_vc_mask %x\n", __FUNCTION__, cpu, intr_vc_mask[cpu]);*/
 	return 0;
@@ -786,9 +786,9 @@ int nlm_xlp_unregister_intr_vc(int cpu, int vc)
 		return -1;
 	}
 
-	spin_lock_irqsave(&msgrng_lock, flags);
+	raw_spin_lock_irqsave(&msgrng_lock, flags);
 	intr_vc_mask[cpu] &= (~(1 << vc));
-	spin_unlock_irqrestore(&msgrng_lock, flags);
+	raw_spin_unlock_irqrestore(&msgrng_lock, flags);
 	return 0;
 }
 EXPORT_SYMBOL(nlm_xlp_unregister_intr_vc);
@@ -967,7 +967,7 @@ int register_xlp_msgring_handler(int major,
 	}
 
 	/* Check if the message station is valid, if not return error */
-	spin_lock_irqsave(&msgrng_lock, flags);
+	raw_spin_lock_irqsave(&msgrng_lock, flags);
 
 	if(!xlp_fmn_init_done)
 		xlp_fmn_init_done = 1;
@@ -975,10 +975,10 @@ int register_xlp_msgring_handler(int major,
 	if (is_nlm_xlp8xx_ax()) {
 		if(msg_handler_timer_enabled == 0) {
 			msg_handler_timer_enabled = 1;
-			spin_unlock_irqrestore(&msgrng_lock, flags);
+			raw_spin_unlock_irqrestore(&msgrng_lock, flags);
 			// init_msg_bkp_timer(0);	Not required, taken care by on_each_cpu()
 			on_each_cpu(init_msg_bkp_timer, 0, 1);
-			spin_lock_irqsave(&msgrng_lock, flags);
+			raw_spin_lock_irqsave(&msgrng_lock, flags);
 		}
 	}
 
@@ -988,7 +988,7 @@ int register_xlp_msgring_handler(int major,
 	ret = 0;
 	msgring_registered.value = 1;
 
-	spin_unlock_irqrestore(&msgrng_lock, flags);
+	raw_spin_unlock_irqrestore(&msgrng_lock, flags);
 
 	return ret;
 }
@@ -1005,14 +1005,14 @@ int unregister_xlp_msgring_handler(int major, void *dev_id)
 		       XLP_MAX_TX_STNS);
 		return -1;
 	}
-	spin_lock_irqsave(&msgrng_lock, flags);
+	raw_spin_lock_irqsave(&msgrng_lock, flags);
 	if(msg_handler_map[major].dev_id == dev_id){
 		msg_handler_map[major].action = dummy_handler;
 		msg_handler_map[major].dev_id = NULL;
 		msg_handler_map[major].napi_final = NULL;
 		msg_handler_map[major].napi_final_arg = NULL;
 	}
-	spin_unlock_irqrestore(&msgrng_lock, flags);
+	raw_spin_unlock_irqrestore(&msgrng_lock, flags);
 	return 0;
 }
 
@@ -1511,7 +1511,7 @@ static int __init on_chip_init(void)
 
 	/* Set netlogic_io_base to the run time value */
 #ifdef CONFIG_XLP_FMN_SUPPORT
-	spin_lock_init(&msgrng_lock);
+	raw_spin_lock_init(&msgrng_lock);
 
 	msgring_registered.value = 0;
 #endif
-- 
1.7.9.5

