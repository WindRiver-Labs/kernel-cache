From be0526657941550bc3801d7d52735b2106532fe8 Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Fri, 14 Feb 2014 20:34:25 +0800
Subject: [PATCH 51/58] bcm-xlp2: Support for NAND on Netlogic XLP SoC

Based on SDK 3.0 (2013-10-29)

Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 drivers/mtd/nand/Kconfig       |   27 ++
 drivers/mtd/nand/Makefile      |    2 +
 drivers/mtd/nand/nand_ids.c    |    2 +
 drivers/mtd/nand/spinand_lld.c |  962 ++++++++++++++++++++++++++++++++++++++++
 drivers/mtd/nand/xlp_nand.c    |  831 ++++++++++++++++++++++++++++++++++
 include/linux/mtd/spinand.h    |  103 +++++
 6 files changed, 1927 insertions(+)

diff --git a/drivers/mtd/nand/Kconfig b/drivers/mtd/nand/Kconfig
index 50543f1..4e927c3 100644
--- a/drivers/mtd/nand/Kconfig
+++ b/drivers/mtd/nand/Kconfig
@@ -544,4 +544,31 @@ config MTD_NAND_XWAY
 	  Enables support for NAND Flash chips on Lantiq XWAY SoCs. NAND is attached
 	  to the External Bus Unit (EBU).
 
+config MTD_NAND_XLP
+	tristate "Support for NAND on Netlogic XLP SoC"
+	depends on CPU_XLP
+	help
+	  Enables support for NAND Flash driver on Netlogic XLP SoCs.
+
+	  If you have Netlogic XLP 8xx, 3xx or 2xx boards,
+	  say yes here.
+
+	  If unsure, say N.
+
+config MTD_SNAND_MT29F
+	tristate "SPINAND Device Support for Micron"
+	depends on MTD
+	help
+	  This enables support for accessing Micron SPI NAND flash
+	  devices.
+	  If you have Micron SPI NAND chip say yes.
+
+	  If unsure, say no here.
+
+config MTD_SPINAND_ONDIEECC
+	bool "Use SPINAND internal ECC"
+	help
+	  Internel ECC.
+	  Enables Hardware ECC support for Micron SPI NAND.
+
 endif # MTD_NAND
diff --git a/drivers/mtd/nand/Makefile b/drivers/mtd/nand/Makefile
index bb81891..90fd79e 100644
--- a/drivers/mtd/nand/Makefile
+++ b/drivers/mtd/nand/Makefile
@@ -50,5 +50,7 @@ obj-$(CONFIG_MTD_NAND_JZ4740)		+= jz4740_nand.o
 obj-$(CONFIG_MTD_NAND_GPMI_NAND)	+= gpmi-nand/
 obj-$(CONFIG_MTD_NAND_XWAY)		+= xway_nand.o
 obj-$(CONFIG_MTD_NAND_BCM47XXNFLASH)	+= bcm47xxnflash/
+obj-$(CONFIG_MTD_NAND_XLP)		+= xlp_nand.o
+obj-$(CONFIG_MTD_SNAND_MT29F)		+= spinand_lld.o
 
 nand-objs := nand_base.o nand_bbt.o
diff --git a/drivers/mtd/nand/nand_ids.c b/drivers/mtd/nand/nand_ids.c
index 683813a..5241e89 100644
--- a/drivers/mtd/nand/nand_ids.c
+++ b/drivers/mtd/nand/nand_ids.c
@@ -98,6 +98,8 @@ struct nand_flash_dev nand_flash_ids[] = {
 	EXTENDED_ID_NAND("NAND 128MiB 1,8V 16-bit", 0xB1, 128, LP_OPTIONS16),
 	EXTENDED_ID_NAND("NAND 128MiB 3,3V 16-bit", 0xC1, 128, LP_OPTIONS16),
 	EXTENDED_ID_NAND("NAND 128MiB 1,8V 16-bit", 0xAD, 128, LP_OPTIONS16),
+	EXTENDED_ID_NAND("NAND 128MiB 3,3V 8-bit", 0x11, 128, LP_OPTIONS),
+	EXTENDED_ID_NAND("NAND 128MiB 3,3V 8-bit", 0x12, 128, LP_OPTIONS),
 
 	/* 2 Gigabit */
 	EXTENDED_ID_NAND("NAND 256MiB 1,8V 8-bit",  0xAA, 256, LP_OPTIONS),
diff --git a/drivers/mtd/nand/spinand_lld.c b/drivers/mtd/nand/spinand_lld.c
new file mode 100644
index 0000000..0458a69
--- /dev/null
+++ b/drivers/mtd/nand/spinand_lld.c
@@ -0,0 +1,962 @@
+/*
+ * Copyright (c) 2003-2013 Broadcom Corporation
+ *
+ * Copyright (c) 2009-2010 Micron Technology, Inc.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/module.h>
+#include <linux/delay.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/partitions.h>
+#include <linux/mtd/nand.h>
+#include <linux/spi/spi.h>
+#include <linux/mtd/spinand.h>
+
+#define BUFSIZE (10 * 64 * 2048)
+#define CACHE_BUF 2112
+/*
+ * OOB area specification layout:  Total 32 available free bytes.
+ */
+#ifdef CONFIG_MTD_SPINAND_ONDIEECC
+static int enable_hw_ecc;
+static int enable_read_hw_ecc;
+
+static inline struct spinand_state *mtd_to_state(struct mtd_info *mtd)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct spinand_info *info = (struct spinand_info *)chip->priv;
+	struct spinand_state *state = (struct spinand_state *)info->priv;
+
+	return state;
+}
+
+static struct nand_ecclayout spinand_oob_64 = {
+	.eccbytes = 24,
+	.eccpos = {
+		1, 2, 3, 4, 5, 6,
+		17, 18, 19, 20, 21, 22,
+		33, 34, 35, 36, 37, 38,
+		49, 50, 51, 52, 53, 54, },
+	.oobavail = 32,
+	.oobfree = {
+		{.offset = 8,
+			.length = 8},
+		{.offset = 24,
+			.length = 8},
+		{.offset = 40,
+			.length = 8},
+		{.offset = 56,
+			.length = 8},
+	}
+};
+#endif
+
+/*
+ * spinand_cmd - to process a command to send to the SPI Nand
+ * Description:
+ *    Set up the command buffer to send to the SPI controller.
+ *    The command buffer has to initialized to 0.
+ */
+
+static int spinand_cmd(struct spi_device *spi, struct spinand_cmd *cmd)
+{
+	struct spi_message message;
+	struct spi_transfer x[4];
+	u8 dummy = 0xff;
+
+	spi_message_init(&message);
+	memset(x, 0, sizeof(x));
+
+	x[0].len = 1;
+	x[0].tx_buf = &cmd->cmd;
+	spi_message_add_tail(&x[0], &message);
+
+	if (cmd->n_addr) {
+		x[1].len = cmd->n_addr;
+		x[1].tx_buf = cmd->addr;
+		spi_message_add_tail(&x[1], &message);
+	}
+
+	if (cmd->n_dummy) {
+		x[2].len = cmd->n_dummy;
+		x[2].tx_buf = &dummy;
+		spi_message_add_tail(&x[2], &message);
+	}
+
+	if (cmd->n_tx) {
+		x[3].len = cmd->n_tx;
+		x[3].tx_buf = cmd->tx_buf;
+		spi_message_add_tail(&x[3], &message);
+	}
+
+	if (cmd->n_rx) {
+		x[3].len = cmd->n_rx;
+		x[3].rx_buf = cmd->rx_buf;
+		spi_message_add_tail(&x[3], &message);
+	}
+
+	return spi_sync(spi, &message);
+}
+
+/*
+ * spinand_read_id- Read SPI Nand ID
+ * Description:
+ *    Read ID: read two ID bytes from the SPI Nand device
+ */
+static int spinand_read_id(struct spi_device *spi_nand, u8 *id)
+{
+	int retval;
+	u8 nand_id[3];
+	struct spinand_cmd cmd = {0};
+
+	cmd.cmd = CMD_READ_ID;
+	cmd.n_rx = 3;
+	cmd.rx_buf = &nand_id[0];
+
+	retval = spinand_cmd(spi_nand, &cmd);
+	if (retval < 0) {
+		dev_err(&spi_nand->dev, "error %d reading id\n", retval);
+		return retval;
+	}
+	id[0] = nand_id[1];
+	id[1] = nand_id[2];
+	return retval;
+}
+
+/*
+ * spinand_read_status- send command 0xf to the SPI Nand status register
+ * Description:
+ *    After read, write, or erase, the Nand device is expected to set the
+ *    busy status.
+ *    This function is to allow reading the status of the command: read,
+ *    write, and erase.
+ *    Once the status turns to be ready, the other status bits also are
+ *    valid status bits.
+ */
+static int spinand_read_status(struct spi_device *spi_nand, uint8_t *status)
+{
+	struct spinand_cmd cmd = {0};
+	int ret;
+
+	cmd.cmd = CMD_READ_REG;
+	cmd.n_addr = 1;
+	cmd.addr[0] = REG_STATUS;
+	cmd.n_rx = 1;
+	cmd.rx_buf = status;
+
+	ret = spinand_cmd(spi_nand, &cmd);
+	if (ret < 0)
+		dev_err(&spi_nand->dev, "err: %d read status register\n", ret);
+
+	return ret;
+}
+
+/*
+ * Read status register until ready, or timeout occurs.
+ * Returns non-zero in case of error.
+ */
+#define MAX_WAIT_JIFFIES  (40 * HZ)
+static int wait_till_ready(struct spi_device *spi_nand)
+{
+	unsigned long deadline;
+	int retval;
+	u8 stat = 0;
+
+	deadline = jiffies + MAX_WAIT_JIFFIES;
+	do {
+		retval = spinand_read_status(spi_nand, &stat);
+		if (retval < 0)
+			break;
+		else if (!(stat & 0x1))
+			return 0;
+
+		cond_resched();
+	} while (!time_after_eq(jiffies, deadline));
+
+	return retval;
+}
+/**
+ * spinand_get_otp- send command 0xf to read the SPI Nand OTP register
+ * Description:
+ *   There is one bit( bit 0x10 ) to set or to clear the internal ECC.
+ *   Enable chip internal ECC, set the bit to 1
+ *   Disable chip internal ECC, clear the bit to 0
+ */
+static int spinand_get_otp(struct spi_device *spi_nand, u8 *otp)
+{
+	struct spinand_cmd cmd = {0};
+	int retval;
+
+	cmd.cmd = CMD_READ_REG;
+	cmd.n_addr = 1;
+	cmd.addr[0] = REG_OTP;
+	cmd.n_rx = 1;
+	cmd.rx_buf = otp;
+
+	retval = spinand_cmd(spi_nand, &cmd);
+	if (retval < 0)
+		dev_err(&spi_nand->dev, "error %d get otp\n", retval);
+	return retval;
+}
+
+/**
+ * spinand_set_otp- send command 0x1f to write the SPI Nand OTP register
+ * Description:
+ *   There is one bit( bit 0x10 ) to set or to clear the internal ECC.
+ *   Enable chip internal ECC, set the bit to 1
+ *   Disable chip internal ECC, clear the bit to 0
+ */
+static int spinand_set_otp(struct spi_device *spi_nand, u8 *otp)
+{
+	int retval;
+	struct spinand_cmd cmd = {0};
+
+	cmd.cmd = CMD_WRITE_REG,
+	cmd.n_addr = 1,
+	cmd.addr[0] = REG_OTP,
+	cmd.n_tx = 1,
+	cmd.tx_buf = otp,
+
+	retval = spinand_cmd(spi_nand, &cmd);
+	if (retval < 0)
+		dev_err(&spi_nand->dev, "error %d set otp\n", retval);
+
+	return retval;
+}
+
+#ifdef CONFIG_MTD_SPINAND_ONDIEECC
+/**
+ * spinand_enable_ecc- send command 0x1f to write the SPI Nand OTP register
+ * Description:
+ *   There is one bit( bit 0x10 ) to set or to clear the internal ECC.
+ *   Enable chip internal ECC, set the bit to 1
+ *   Disable chip internal ECC, clear the bit to 0
+ */
+static int spinand_enable_ecc(struct spi_device *spi_nand)
+{
+	int retval;
+	u8 otp = 0;
+
+	retval = spinand_get_otp(spi_nand, &otp);
+	if (retval < 0)
+		return retval;
+
+	if ((otp & OTP_ECC_MASK) == OTP_ECC_MASK) {
+		return 0;
+	} else {
+		otp |= OTP_ECC_MASK;
+		retval = spinand_set_otp(spi_nand, &otp);
+		if (retval < 0)
+			return retval;
+		return spinand_get_otp(spi_nand, &otp);
+	}
+}
+#endif
+
+static int spinand_disable_ecc(struct spi_device *spi_nand)
+{
+	int retval;
+	u8 otp = 0;
+
+	retval = spinand_get_otp(spi_nand, &otp);
+	if (retval < 0)
+		return retval;
+
+	if ((otp & OTP_ECC_MASK) == OTP_ECC_MASK) {
+		otp &= ~OTP_ECC_MASK;
+		retval = spinand_set_otp(spi_nand, &otp);
+		if (retval < 0)
+			return retval;
+		return spinand_get_otp(spi_nand, &otp);
+	} else
+		return 0;
+}
+
+/**
+ * spinand_write_enable- send command 0x06 to enable write or erase the
+ * Nand cells
+ * Description:
+ *   Before write and erase the Nand cells, the write enable has to be set.
+ *   After the write or erase, the write enable bit is automatically
+ *   cleared (status register bit 2)
+ *   Set the bit 2 of the status register has the same effect
+ */
+static int spinand_write_enable(struct spi_device *spi_nand)
+{
+	struct spinand_cmd cmd = {0};
+
+	cmd.cmd = CMD_WR_ENABLE;
+	return spinand_cmd(spi_nand, &cmd);
+}
+
+static int spinand_read_page_to_cache(struct spi_device *spi_nand, u16 page_id)
+{
+	struct spinand_cmd cmd = {0};
+	u16 row;
+
+	row = page_id;
+	cmd.cmd = CMD_READ;
+	cmd.n_addr = 3;
+	cmd.addr[1] = (u8)((row & 0xff00) >> 8);
+	cmd.addr[2] = (u8)(row & 0x00ff);
+
+	return spinand_cmd(spi_nand, &cmd);
+}
+
+/*
+ * spinand_read_from_cache- send command 0x03 to read out the data from the
+ * cache register(2112 bytes max)
+ * Description:
+ *   The read can specify 1 to 2112 bytes of data read at the corresponding
+ *   locations.
+ *   No tRd delay.
+ */
+static int spinand_read_from_cache(struct spi_device *spi_nand, u16 page_id,
+		u16 byte_id, u16 len, u8 *rbuf)
+{
+	struct spinand_cmd cmd = {0};
+	u16 column;
+
+	column = byte_id;
+	cmd.cmd = CMD_READ_RDM;
+	cmd.n_addr = 3;
+	cmd.addr[0] = (u8)((column & 0xff00) >> 8);
+	cmd.addr[0] |= (u8)(((page_id >> 6) & 0x1) << 4);
+	cmd.addr[1] = (u8)(column & 0x00ff);
+	cmd.addr[2] = (u8)(0xff);
+	cmd.n_dummy = 0;
+	cmd.n_rx = len;
+	cmd.rx_buf = rbuf;
+
+	return spinand_cmd(spi_nand, &cmd);
+}
+
+/*
+ * spinand_read_page-to read a page with:
+ * @page_id: the physical page number
+ * @offset:  the location from 0 to 2111
+ * @len:     number of bytes to read
+ * @rbuf:    read buffer to hold @len bytes
+ *
+ * Description:
+ *   The read includes two commands to the Nand: 0x13 and 0x03 commands
+ *   Poll to read status to wait for tRD time.
+ */
+static int spinand_read_page(struct spi_device *spi_nand, u16 page_id,
+		u16 offset, u16 len, u8 *rbuf)
+{
+	int ret;
+	u8 status = 0;
+
+#ifdef CONFIG_MTD_SPINAND_ONDIEECC
+	if (enable_read_hw_ecc) {
+		if (spinand_enable_ecc(spi_nand) < 0)
+			dev_err(&spi_nand->dev, "enable HW ECC failed!");
+	}
+#endif
+	ret = spinand_read_page_to_cache(spi_nand, page_id);
+	if (ret < 0)
+		return ret;
+
+	if (wait_till_ready(spi_nand))
+		dev_err(&spi_nand->dev, "WAIT timedout!!!\n");
+
+	while (1) {
+		ret = spinand_read_status(spi_nand, &status);
+		if (ret < 0) {
+			dev_err(&spi_nand->dev,
+					"err %d read status register\n", ret);
+			return ret;
+		}
+
+		if ((status & STATUS_OIP_MASK) == STATUS_READY) {
+			if ((status & STATUS_ECC_MASK) == STATUS_ECC_ERROR) {
+				dev_err(&spi_nand->dev, "ecc error, page=%d\n",
+						page_id);
+				return 0;
+			}
+			break;
+		}
+	}
+
+	ret = spinand_read_from_cache(spi_nand, page_id, offset, len, rbuf);
+	if (ret < 0) {
+		dev_err(&spi_nand->dev, "read from cache failed!!\n");
+		return ret;
+	}
+
+#ifdef CONFIG_MTD_SPINAND_ONDIEECC
+	if (enable_read_hw_ecc) {
+		ret = spinand_disable_ecc(spi_nand);
+		if (ret < 0) {
+			dev_err(&spi_nand->dev, "disable ecc failed!!\n");
+			return ret;
+		}
+		enable_read_hw_ecc = 0;
+	}
+#endif
+	return ret;
+}
+
+/*
+ * spinand_program_data_to_cache--to write a page to cache with:
+ * @byte_id: the location to write to the cache
+ * @len:     number of bytes to write
+ * @rbuf:    read buffer to hold @len bytes
+ *
+ * Description:
+ *   The write command used here is 0x84--indicating that the cache is
+ *   not cleared first.
+ *   Since it is writing the data to cache, there is no tPROG time.
+ */
+static int spinand_program_data_to_cache(struct spi_device *spi_nand,
+		u16 page_id, u16 byte_id, u16 len, u8 *wbuf)
+{
+	struct spinand_cmd cmd = {0};
+	u16 column;
+
+	column = byte_id;
+	cmd.cmd = CMD_PROG_PAGE_CLRCACHE;
+	cmd.n_addr = 2;
+	cmd.addr[0] = (u8)((column & 0xff00) >> 8);
+	cmd.addr[0] |= (u8)(((page_id >> 6) & 0x1) << 4);
+	cmd.addr[1] = (u8)(column & 0x00ff);
+	cmd.n_tx = len;
+	cmd.tx_buf = wbuf;
+
+	return spinand_cmd(spi_nand, &cmd);
+}
+
+/**
+ * spinand_program_execute--to write a page from cache to the Nand array with
+ * @page_id: the physical page location to write the page.
+ *
+ * Description:
+ *   The write command used here is 0x10--indicating the cache is writing to
+ *   the Nand array.
+ *   Need to wait for tPROG time to finish the transaction.
+ */
+static int spinand_program_execute(struct spi_device *spi_nand, u16 page_id)
+{
+	struct spinand_cmd cmd = {0};
+	u16 row;
+
+	row = page_id;
+	cmd.cmd = CMD_PROG_PAGE_EXC;
+	cmd.n_addr = 3;
+	cmd.addr[1] = (u8)((row & 0xff00) >> 8);
+	cmd.addr[2] = (u8)(row & 0x00ff);
+
+	return spinand_cmd(spi_nand, &cmd);
+}
+
+/**
+ * spinand_program_page--to write a page with:
+ * @page_id: the physical page location to write the page.
+ * @offset:  the location from the cache starting from 0 to 2111
+ * @len:     the number of bytes to write
+ * @wbuf:    the buffer to hold the number of bytes
+ *
+ * Description:
+ *   The commands used here are 0x06, 0x84, and 0x10--indicating that
+ *   the write enable is first sent, the write cache command, and the
+ *   write execute command.
+ *   Poll to wait for the tPROG time to finish the transaction.
+ */
+static int spinand_program_page(struct spi_device *spi_nand,
+		u16 page_id, u16 offset, u16 len, u8 *buf)
+{
+	int retval;
+	u8 status = 0;
+	uint8_t *wbuf;
+#ifdef CONFIG_MTD_SPINAND_ONDIEECC
+	unsigned int i, j;
+
+	enable_read_hw_ecc = 0;
+	wbuf = devm_kzalloc(&spi_nand->dev, CACHE_BUF, GFP_KERNEL);
+	spinand_read_page(spi_nand, page_id, 0, CACHE_BUF, wbuf);
+
+	for (i = offset, j = 0; i < len; i++, j++)
+		wbuf[i] &= buf[j];
+
+	if (enable_hw_ecc) {
+		retval = spinand_enable_ecc(spi_nand);
+		if (retval < 0) {
+			dev_err(&spi_nand->dev, "enable ecc failed!!\n");
+			return retval;
+		}
+	}
+#else
+	wbuf = buf;
+#endif
+	retval = spinand_write_enable(spi_nand);
+	if (retval < 0) {
+		dev_err(&spi_nand->dev, "write enable failed!!\n");
+		return retval;
+	}
+	if (wait_till_ready(spi_nand))
+		dev_err(&spi_nand->dev, "wait timedout!!!\n");
+
+	retval = spinand_program_data_to_cache(spi_nand, page_id,
+			offset, len, wbuf);
+	if (retval < 0)
+		return retval;
+	retval = spinand_program_execute(spi_nand, page_id);
+	if (retval < 0)
+		return retval;
+	while (1) {
+		retval = spinand_read_status(spi_nand, &status);
+		if (retval < 0) {
+			dev_err(&spi_nand->dev,
+					"error %d reading status register\n",
+					retval);
+			return retval;
+		}
+
+		if ((status & STATUS_OIP_MASK) == STATUS_READY) {
+			if ((status & STATUS_P_FAIL_MASK) == STATUS_P_FAIL) {
+				dev_err(&spi_nand->dev,
+					"program error, page %d\n", page_id);
+				return -1;
+			} else
+				break;
+		}
+	}
+#ifdef CONFIG_MTD_SPINAND_ONDIEECC
+	if (enable_hw_ecc) {
+		retval = spinand_disable_ecc(spi_nand);
+		if (retval < 0) {
+			dev_err(&spi_nand->dev, "disable ecc failed!!\n");
+			return retval;
+		}
+		enable_hw_ecc = 0;
+	}
+#endif
+
+	return 0;
+}
+
+/**
+ * spinand_erase_block_erase--to erase a page with:
+ * @block_id: the physical block location to erase.
+ *
+ * Description:
+ *   The command used here is 0xd8--indicating an erase command to erase
+ *   one block--64 pages
+ *   Need to wait for tERS.
+ */
+static int spinand_erase_block_erase(struct spi_device *spi_nand, u16 block_id)
+{
+	struct spinand_cmd cmd = {0};
+	u16 row;
+
+	row = block_id;
+	cmd.cmd = CMD_ERASE_BLK;
+	cmd.n_addr = 3;
+	cmd.addr[1] = (u8)((row & 0xff00) >> 8);
+	cmd.addr[2] = (u8)(row & 0x00ff);
+
+	return spinand_cmd(spi_nand, &cmd);
+}
+
+/**
+ * spinand_erase_block--to erase a page with:
+ * @block_id: the physical block location to erase.
+ *
+ * Description:
+ *   The commands used here are 0x06 and 0xd8--indicating an erase
+ *   command to erase one block--64 pages
+ *   It will first to enable the write enable bit (0x06 command),
+ *   and then send the 0xd8 erase command
+ *   Poll to wait for the tERS time to complete the tranaction.
+ */
+static int spinand_erase_block(struct spi_device *spi_nand, u16 block_id)
+{
+	int retval;
+	u8 status = 0;
+
+	retval = spinand_write_enable(spi_nand);
+	if (wait_till_ready(spi_nand))
+		dev_err(&spi_nand->dev, "wait timedout!!!\n");
+
+	retval = spinand_erase_block_erase(spi_nand, block_id);
+	while (1) {
+		retval = spinand_read_status(spi_nand, &status);
+		if (retval < 0) {
+			dev_err(&spi_nand->dev,
+					"error %d reading status register\n",
+					(int) retval);
+			return retval;
+		}
+
+		if ((status & STATUS_OIP_MASK) == STATUS_READY) {
+			if ((status & STATUS_E_FAIL_MASK) == STATUS_E_FAIL) {
+				dev_err(&spi_nand->dev,
+					"erase error, block %d\n", block_id);
+				return -1;
+			} else
+				break;
+		}
+	}
+	return 0;
+}
+
+#ifdef CONFIG_MTD_SPINAND_ONDIEECC
+static int spinand_write_page_hwecc(struct mtd_info *mtd,
+		struct nand_chip *chip, const uint8_t *buf, int oob_required)
+{
+	const uint8_t *p = buf;
+	int eccsize = chip->ecc.size;
+	int eccsteps = chip->ecc.steps;
+
+	enable_hw_ecc = 1;
+	chip->write_buf(mtd, p, eccsize * eccsteps);
+	return 0;
+}
+
+static int spinand_read_page_hwecc(struct mtd_info *mtd, struct nand_chip *chip,
+		uint8_t *buf, int oob_required, int page)
+{
+	u8 retval, status;
+	uint8_t *p = buf;
+	int eccsize = chip->ecc.size;
+	int eccsteps = chip->ecc.steps;
+	struct spinand_info *info = (struct spinand_info *)chip->priv;
+
+	enable_read_hw_ecc = 1;
+
+	chip->read_buf(mtd, p, eccsize * eccsteps);
+	if (oob_required)
+		chip->read_buf(mtd, chip->oob_poi, mtd->oobsize);
+
+	while (1) {
+		retval = spinand_read_status(info->spi, &status);
+		if ((status & STATUS_OIP_MASK) == STATUS_READY) {
+			if ((status & STATUS_ECC_MASK) == STATUS_ECC_ERROR) {
+				pr_info("spinand: ECC error\n");
+				mtd->ecc_stats.failed++;
+			} else if ((status & STATUS_ECC_MASK) ==
+					STATUS_ECC_1BIT_CORRECTED)
+				mtd->ecc_stats.corrected++;
+			break;
+		}
+	}
+	return 0;
+
+}
+#endif
+
+static void spinand_select_chip(struct mtd_info *mtd, int dev)
+{
+}
+
+static uint8_t spinand_read_byte(struct mtd_info *mtd)
+{
+	struct spinand_state *state = mtd_to_state(mtd);
+	u8 data;
+
+	data = state->buf[state->buf_ptr];
+	state->buf_ptr++;
+	return data;
+}
+
+
+static int spinand_wait(struct mtd_info *mtd, struct nand_chip *chip)
+{
+	struct spinand_info *info = (struct spinand_info *)chip->priv;
+
+	unsigned long timeo = jiffies;
+	int retval, state = chip->state;
+	u8 status;
+
+	if (state == FL_ERASING)
+		timeo += (HZ * 400) / 1000;
+	else
+		timeo += (HZ * 20) / 1000;
+
+	while (time_before(jiffies, timeo)) {
+		retval = spinand_read_status(info->spi, &status);
+		if ((status & STATUS_OIP_MASK) == STATUS_READY)
+			return 0;
+
+		cond_resched();
+	}
+	return 0;
+}
+
+static void spinand_write_buf(struct mtd_info *mtd, const uint8_t *buf, int len)
+{
+
+	struct spinand_state *state = mtd_to_state(mtd);
+	memcpy(state->buf + state->buf_ptr, buf, len);
+	state->buf_ptr += len;
+}
+
+static void spinand_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	struct spinand_state *state = mtd_to_state(mtd);
+	memcpy(buf, state->buf + state->buf_ptr, len);
+	state->buf_ptr += len;
+}
+
+/*
+ * spinand_reset- send RESET command "0xff" to the Nand device.
+ */
+static void spinand_reset(struct spi_device *spi_nand)
+{
+	struct spinand_cmd cmd = {0};
+
+	cmd.cmd = CMD_RESET;
+
+	if (spinand_cmd(spi_nand, &cmd) < 0)
+		pr_info("spinand reset failed!\n");
+
+	/* elapse 1ms before issuing any other command */
+	udelay(1000);
+
+	if (wait_till_ready(spi_nand))
+		dev_err(&spi_nand->dev, "wait timedout!\n");
+}
+
+static void spinand_cmdfunc(struct mtd_info *mtd, unsigned int command,
+		int column, int page)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct spinand_info *info = (struct spinand_info *)chip->priv;
+	struct spinand_state *state = (struct spinand_state *)info->priv;
+
+	switch (command) {
+	/*
+	 * READ0 - read in first  0x800 bytes
+	 */
+	case NAND_CMD_READ1:
+	case NAND_CMD_READ0:
+		state->buf_ptr = 0;
+		spinand_read_page(info->spi, page, 0x0, 0x840, state->buf);
+		break;
+	/* READOOB reads only the OOB because no ECC is performed. */
+	case NAND_CMD_READOOB:
+		state->buf_ptr = 0;
+		spinand_read_page(info->spi, page, 0x800, 0x40, state->buf);
+		break;
+	case NAND_CMD_RNDOUT:
+		state->buf_ptr = column;
+		break;
+	case NAND_CMD_READID:
+		state->buf_ptr = 0;
+		spinand_read_id(info->spi, (u8 *)state->buf);
+		break;
+	case NAND_CMD_PARAM:
+		state->buf_ptr = 0;
+		break;
+	/* ERASE1 stores the block and page address */
+	case NAND_CMD_ERASE1:
+		spinand_erase_block(info->spi, page);
+		break;
+	/* ERASE2 uses the block and page address from ERASE1 */
+	case NAND_CMD_ERASE2:
+		break;
+	/* SEQIN sets up the addr buffer and all registers except the length */
+	case NAND_CMD_SEQIN:
+		state->col = column;
+		state->row = page;
+		state->buf_ptr = 0;
+		break;
+	/* PAGEPROG reuses all of the setup from SEQIN and adds the length */
+	case NAND_CMD_PAGEPROG:
+		spinand_program_page(info->spi, state->row, state->col,
+				state->buf_ptr, state->buf);
+		break;
+	case NAND_CMD_STATUS:
+		spinand_get_otp(info->spi, state->buf);
+		if (!(state->buf[0] & 0x80))
+			state->buf[0] = 0x80;
+		state->buf_ptr = 0;
+		break;
+	/* RESET command */
+	case NAND_CMD_RESET:
+		if (wait_till_ready(info->spi))
+			dev_err(&info->spi->dev, "WAIT timedout!!!\n");
+		/* a minimum of 250us must elapse before issuing RESET cmd*/
+		udelay(250);
+		spinand_reset(info->spi);
+		break;
+	default:
+		dev_err(&mtd->dev, "Unknown CMD: 0x%x\n", command);
+	}
+}
+
+/**
+ * spinand_lock_block- send write register 0x1f command to the Nand device
+ *
+ * Description:
+ *    After power up, all the Nand blocks are locked.  This function allows
+ *    one to unlock the blocks, and so it can be written or erased.
+ */
+static int spinand_lock_block(struct spi_device *spi_nand, u8 lock)
+{
+	struct spinand_cmd cmd = {0};
+	int ret;
+	u8 otp = 0;
+
+	ret = spinand_get_otp(spi_nand, &otp);
+
+	cmd.cmd = CMD_WRITE_REG;
+	cmd.n_addr = 1;
+	cmd.addr[0] = REG_BLOCK_LOCK;
+	cmd.n_tx = 1;
+	cmd.tx_buf = &lock;
+
+	ret = spinand_cmd(spi_nand, &cmd);
+	if (ret < 0)
+		dev_err(&spi_nand->dev, "error %d lock block\n", ret);
+
+	return ret;
+}
+/*
+ * spinand_probe - [spinand Interface]
+ * @spi_nand: registered device driver.
+ *
+ * Description:
+ *   To set up the device driver parameters to make the device available.
+ */
+static int spinand_probe(struct spi_device *spi_nand)
+{
+	struct mtd_info *mtd;
+	struct nand_chip *chip;
+	struct spinand_info *info;
+	struct spinand_state *state;
+	struct mtd_part_parser_data ppdata;
+
+	info  = devm_kzalloc(&spi_nand->dev, sizeof(struct spinand_info),
+			GFP_KERNEL);
+	if (!info)
+		return -ENOMEM;
+
+	info->spi = spi_nand;
+
+	spinand_lock_block(spi_nand, BL_ALL_UNLOCKED);
+
+	state = devm_kzalloc(&spi_nand->dev, sizeof(struct spinand_state),
+			GFP_KERNEL);
+	if (!state)
+		return -ENOMEM;
+
+	info->priv	= state;
+	state->buf_ptr	= 0;
+	state->buf	= devm_kzalloc(&spi_nand->dev, BUFSIZE, GFP_KERNEL);
+	if (!state->buf)
+		return -ENOMEM;
+
+	chip = devm_kzalloc(&spi_nand->dev, sizeof(struct nand_chip),
+			GFP_KERNEL);
+	if (!chip)
+		return -ENOMEM;
+
+#ifdef CONFIG_MTD_SPINAND_ONDIEECC
+	chip->ecc.mode	= NAND_ECC_HW;
+	chip->ecc.size	= 0x200;
+	chip->ecc.bytes	= 0x6;
+	chip->ecc.steps	= 0x4;
+
+	chip->ecc.strength = 1;
+	chip->ecc.total	= chip->ecc.steps * chip->ecc.bytes;
+	chip->ecc.layout = &spinand_oob_64;
+	chip->ecc.read_page = spinand_read_page_hwecc;
+	chip->ecc.write_page = spinand_write_page_hwecc;
+#else
+	chip->ecc.mode	= NAND_ECC_SOFT;
+	if (spinand_disable_ecc(spi_nand) < 0)
+		pr_info("%s: disable ecc failed!\n", __func__);
+#endif
+
+	chip->priv	= info;
+	chip->read_buf	= spinand_read_buf;
+	chip->write_buf	= spinand_write_buf;
+	chip->read_byte	= spinand_read_byte;
+	chip->cmdfunc	= spinand_cmdfunc;
+	chip->waitfunc	= spinand_wait;
+	chip->options	|= NAND_CACHEPRG;
+	chip->select_chip = spinand_select_chip;
+
+	mtd = devm_kzalloc(&spi_nand->dev, sizeof(struct mtd_info), GFP_KERNEL);
+	if (!mtd)
+		return -ENOMEM;
+
+	dev_set_drvdata(&spi_nand->dev, mtd);
+
+	mtd->priv = chip;
+	mtd->name = dev_name(&spi_nand->dev);
+	mtd->owner = THIS_MODULE;
+	mtd->oobsize = 64;
+
+	if (nand_scan(mtd, 1))
+		return -ENXIO;
+
+	ppdata.of_node = spi_nand->dev.of_node;
+	return mtd_device_parse_register(mtd, NULL, &ppdata, NULL, 0);
+}
+
+/*
+ * spinand_remove: Remove the device driver
+ * @spi: the spi device.
+ *
+ * Description:
+ *   To remove the device driver parameters and free up allocated memories.
+ */
+static int spinand_remove(struct spi_device *spi)
+{
+	mtd_device_unregister(dev_get_drvdata(&spi->dev));
+
+	return 0;
+}
+
+static const struct of_device_id spinand_dt[] = {
+	{ .compatible = "spinand,mt29f", },
+};
+
+/*
+ * Device name structure description
+ */
+static struct spi_driver spinand_driver = {
+	.driver = {
+		.name		= "mt29f",
+		.bus		= &spi_bus_type,
+		.owner		= THIS_MODULE,
+		.of_match_table	= spinand_dt,
+	},
+	.probe		= spinand_probe,
+	.remove		= spinand_remove,
+};
+
+/*
+ * Device driver registration
+ */
+static int __init spinand_init(void)
+{
+	return spi_register_driver(&spinand_driver);
+}
+
+/*
+ * unregister Device driver.
+ */
+static void __exit spinand_exit(void)
+{
+	spi_unregister_driver(&spinand_driver);
+}
+module_init(spinand_init);
+module_exit(spinand_exit);
+
+MODULE_DESCRIPTION("SPI NAND driver for Micron");
+MODULE_AUTHOR("Henry Pan <hspan@micron.com>, Kamlakant Patel <kamlakant.patel@broadcom.com>");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/mtd/nand/xlp_nand.c b/drivers/mtd/nand/xlp_nand.c
new file mode 100644
index 0000000..e5607a6
--- /dev/null
+++ b/drivers/mtd/nand/xlp_nand.c
@@ -0,0 +1,831 @@
+/*
+ * Copyright (c) 2003-2013 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the Broadcom
+ * license below:
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/partitions.h>
+#include <linux/dma-mapping.h>
+#include <linux/of_mtd.h>
+#include <linux/of_irq.h>
+#include <linux/interrupt.h>
+
+#define NAND_CMD		0x40
+#define NAND_CTRL		0x41
+#define NAND_STATUS		0x42
+#define NAND_INTMASK		0x43
+#define NAND_INT_STATUS		0x44
+#define	NAND_ECC_CTRL		0x45
+#define NAND_ECC_OFFSET		0x46
+#define NAND_ADDR0_L		0x47
+#define NAND_ADDR0_H		0x49
+#define NAND_ADDR1_L		0x48
+#define NAND_ADDR1_H		0x4A
+#define NAND_SPARE_SIZE		0x4C
+#define NAND_DMA_ADDR_L		0x59
+#define NAND_DMA_CNT		0x5A
+#define NAND_DMA_CTRL		0x5B
+#define NAND_MEMCTRL		0x60
+#define NAND_DATA_SIZE		0x61
+#define NAND_READ_STATUS	0x62
+#define NAND_TIME_SEQ0		0x63
+#define NAND_TIMINGS_ASYN	0x64
+#define NAND_TIMINGS_SYN	0x65
+#define NAND_FIFO_DATA		0x66
+#define NAND_TIME_MODE		0x67
+#define NAND_DMA_ADDR_H		0x68
+#define NAND_FIFO_INIT		0x6C
+#define NAND_GENERIC_SEQ	0x6D
+#define NAND_FIFO_STATE		0x6E
+#define NAND_TIME_SEQ1		0x6F
+#define NAND_SYSCTRL		0x80
+#define NAND_RYBYSEL		0x81
+				/*CMD 3		CMD 2		CMD 1	  SEQ */
+#define NAND_RESET_CMD		((0x0 << 24) | (0x0 << 16) | (0xFF << 8) | 0x0)
+#define NAND_READ_PARAMETER_CMD	((0x0 << 24) | (0x0 << 16) | (0xEC << 8) | 0x22)
+#define NAND_READ_ID_CMD	((0x0 << 24) | (0x0 << 16) | (0x90 << 8) | 0x21)
+#define NAND_READ_PAGE_CMD	((0x0 << 24) | (0x30 << 16) | (0x0 << 8) | 0x2a)
+#define NAND_ERASE_BLOCK_CMD	((0x0 << 24) | (0xD0 << 16) | (0x60 << 8) | 0xe)
+#define NAND_PAGE_PROGRAM_CMD	((0x0 << 24) | (0x10 << 16) | (0x80 << 8) | 0xc)
+#define NAND_READ_STATUS_CMD	((0x0 << 24) | (0x0 << 16) | (0x70 << 8) | 0x24)
+
+#define NAND_CMD_DMA_FLAG		(1 << 6)
+#define NAND_CMD_ADDR1_FLAG		(1 << 7)
+#define NAND_CTRL_GINTR_EN		(1 << 4)
+#define NAND_CTRL_X16_FLAG		(1 << 12)
+#define NAND_CTRL_CUSTOM_XFER_FLAG	(1 << 11)
+
+#define NAND_CTRL_PAGE_SIZE(size)	(size << 8)
+#define NAND_CTRL_BLOCK_SIZE(size)	(size << 6)
+#define NAND_CTRL_ADDR_CYCLE(cyc)	(cyc << 0)
+#define NAND_CTRL_ECC_EN(en)		(en << 5)
+
+/*Sync mode WE High->RE Low*/
+#define NAND_TIME_SEQ0_TWHR(x)		(x << 24)
+/*ASync mode RE High->WE Low*/
+#define NAND_TIME_SEQ0_TRHW(x)		(x << 16)
+/*Async ALE->Data start*/
+#define NAND_TIME_SEQ0_TADL(x)		(x << 8)
+/*Chance column setup*/
+#define NAND_TIME_SEQ0_TCCS(x)		(x << 0)
+/*TRR time peroid*/
+#define NAND_TIME_SEQ1_TRR(x)		(x << 9)
+/*Busy time peroid for async->sync*/
+#define NAND_TIME_SEQ1_TWB(x)		(x << 0)
+/*RE/WE high hold time*/
+#define NAND_TIME_ASYN_TRWH(x)		(x << 4)
+/*RE/WE pulse width*/
+#define NAND_TIME_ASYN_TRWP(x)		(x << 0)
+
+#define BUF_SIZE	(16 * 1024)
+#define NAND_DEV_CS	1
+
+static u64 xlp_dev_dma_mask = DMA_BIT_MASK(32);
+
+/* The oobsize is the area visible to software, and software will read/write
+ * in this region. If hardware ecc is enabled, since our implementation of
+ * write_page does not calculate hardware ECC, the hardware ECC area should
+ * not be overwritten by software.
+ *
+ * In this particular case, let us force the oobsize to be 0xc. The hardware
+ * will use the area in from spare area offset 0xc to the end of spare area.
+ *
+ * Why 0xc? This is the minimum space the hardware ECC will not occupy based
+ * on the calculation in onfi_init.
+ */
+
+#define XLP_HWECC_OOBSIZE       0xc
+
+struct xlp_nand_data {
+	struct nand_chip	chip;
+	struct mtd_info		mtd;
+	struct completion	cmd_complete;
+	void __iomem		*io_base;
+	int			hwecc;
+};
+
+struct nand_state {
+	int col_cyc;
+	int row_cyc;
+	int page_size;
+	int block_size;
+	int pages_per_block;
+	int spare_size;
+	int cs;
+	int buf_ptr;
+	u8  *buf;
+	u32 last_cmd;
+	dma_addr_t buf_dma;
+};
+
+struct nand_info {
+	int node;
+	struct nand_state *nand_state;
+};
+
+static inline int xlp_nand_read_reg(struct xlp_nand_data *data,
+		int regidx)
+{
+	return readl(data->io_base + (regidx << 2));
+}
+
+static inline void xlp_nand_write_reg(struct xlp_nand_data *data,
+		int regidx, u32 val)
+{
+	writel(val, data->io_base + (regidx << 2));
+}
+
+static int xlp_dma_wait(struct xlp_nand_data *data, int cs)
+{
+	int timeout = 0xfffff;
+	while ((!(xlp_nand_read_reg(data, NAND_STATUS) & (1 << cs))) ||
+		(!(xlp_nand_read_reg(data, NAND_DMA_CTRL) & 0x01))) {
+
+		timeout--;
+		if (timeout == 0) {
+			pr_info("DMA timed out NAND_STATUS:%x\n",
+					xlp_nand_read_reg(data, NAND_STATUS));
+			return -1;
+		}
+	}
+	return 0;
+}
+
+static void xlp_onfi_init(struct nand_chip *chip)
+{
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+	u8 *param_ptr = state->buf;
+	u32 val, spare_bytes_per_512;
+	int page_val;
+	int block_val;
+	int addr_cyc, addr_val;
+	int ecc_bytes;
+	int ecc_bits;
+	int ecc_val;
+	int ecc_offset;
+	int i;
+
+	struct xlp_nand_data *data = container_of(chip,
+					struct xlp_nand_data, chip);
+
+	state->page_size = ((param_ptr[80] << 0) |
+			    (param_ptr[81] << 8) |
+			    (param_ptr[82] << 16) |
+			    (param_ptr[83] << 24));
+
+	switch (state->page_size) {
+	case 256:
+		page_val = 0;
+		break;
+	case 512:
+		page_val = 1;
+		break;
+	case 1024:
+		page_val = 2;
+		break;
+	case 2048:
+		page_val = 3;
+		break;
+	case 4096:
+		page_val = 4;
+		break;
+	case 8192:
+		page_val = 5;
+		break;
+	case 16384:
+		page_val = 6;
+		break;
+	default:
+		page_val = 7;
+	}
+
+	state->pages_per_block = ((param_ptr[92] << 0) |
+				  (param_ptr[93] << 8) |
+				  (param_ptr[94] << 16) |
+				  (param_ptr[95] << 24));
+
+	state->block_size = state->pages_per_block * state->page_size;
+
+	switch (state->pages_per_block) {
+	case 32:
+		block_val = 0;
+		break;
+	case 64:
+		block_val = 1;
+		break;
+	case 128:
+		block_val = 2;
+		break;
+	case 256:
+		block_val = 3;
+		break;
+	default:
+		block_val = -1;
+	}
+
+	addr_cyc = param_ptr[101];
+	state->row_cyc = (addr_cyc & 0xf);
+	state->col_cyc = ((addr_cyc >> 4) & 0xf);
+	addr_val = state->row_cyc + state->col_cyc;
+
+	state->spare_size = ((unsigned int)(param_ptr[84] << 0) |
+				(unsigned int)(param_ptr[85] << 8));
+
+	spare_bytes_per_512 = state->spare_size/(state->page_size/512);
+
+	if (spare_bytes_per_512 <= 4) {
+		ecc_bytes = 0;
+		ecc_bits  = 0;
+		ecc_val   = 0;
+	} else if (spare_bytes_per_512 <= 8) {
+		ecc_bytes = 4;
+		ecc_bits  = 2;
+		ecc_val   = 0;
+	} else if (spare_bytes_per_512 <= 16) {
+		ecc_bytes = 13;
+		ecc_bits  = 8;
+		ecc_val   = 3;
+	} else if (spare_bytes_per_512 <= 24) {
+		ecc_bytes = 20;
+		ecc_bits  = 12;
+		ecc_val   = 5;
+	} else {
+		ecc_bytes = 23;
+		ecc_bits  = 14;
+		ecc_val   = 6;
+	}
+	ecc_offset = state->spare_size - ((state->page_size/512) * ecc_bytes);
+
+	if (data->hwecc) {
+		xlp_nand_write_reg(data, NAND_ECC_CTRL, ecc_val << 5);
+		xlp_nand_write_reg(data, NAND_ECC_OFFSET,
+				state->page_size + ecc_offset);
+
+		if (ecc_offset < XLP_HWECC_OOBSIZE)
+			pr_info("%s: OOBSIZE is small for nand!\n", __func__);
+
+		xlp_nand_write_reg(data, NAND_SPARE_SIZE, XLP_HWECC_OOBSIZE);
+
+		val = xlp_nand_read_reg(data, NAND_CTRL);
+		val |= NAND_CTRL_ECC_EN(1);
+
+		chip->ecc.size = 512;
+		chip->ecc.strength = 2;
+		chip->ecc.bytes = ecc_bytes;
+		chip->ecc.steps	= state->page_size / 512;
+		chip->ecc.total	= chip->ecc.steps * chip->ecc.bytes;
+		chip->ecc.layout = kzalloc(sizeof(struct nand_ecclayout),
+					GFP_KERNEL);
+		if (!chip->ecc.layout)
+			return;
+		chip->ecc.layout->eccbytes = ecc_bytes;
+
+		for (i = 0; i < ecc_bytes; i++)
+			chip->ecc.layout->eccpos[i] = ecc_offset + i;
+
+		chip->ecc.layout->oobfree[0].offset = 2;
+		chip->ecc.layout->oobfree[0].length = XLP_HWECC_OOBSIZE - 2;
+	} else {
+		xlp_nand_write_reg(data, NAND_SPARE_SIZE, state->spare_size);
+		val = xlp_nand_read_reg(data, NAND_CTRL);
+		val &= ~NAND_CTRL_ECC_EN(1);
+	}
+
+	val |= NAND_CTRL_PAGE_SIZE(page_val) |
+		NAND_CTRL_BLOCK_SIZE(block_val)	|
+		NAND_CTRL_ADDR_CYCLE(addr_val);
+	xlp_nand_write_reg(data, NAND_CTRL, val);
+}
+
+static void xlp_nand_send_cmd(struct xlp_nand_data *data,
+			struct nand_state *state,
+			unsigned int cmd,
+			int page_addr, int column, int len)
+{
+	unsigned long val;
+
+	xlp_nand_write_reg(data, NAND_DATA_SIZE, len);
+	xlp_nand_write_reg(data, NAND_DMA_CNT, len);
+
+	val = (page_addr >> (32 - (state->col_cyc * 8)));
+	xlp_nand_write_reg(data, NAND_ADDR0_H, val);
+
+	val = ((page_addr << (state->col_cyc * 8)) | column);
+	xlp_nand_write_reg(data, NAND_ADDR0_L, val);
+
+	val = state->buf_dma + state->buf_ptr;
+	xlp_nand_write_reg(data, NAND_DMA_ADDR_L, val);
+	xlp_nand_write_reg(data, NAND_DMA_ADDR_H, (val >> 32));
+
+	if ((cmd == NAND_READ_PAGE_CMD) ||
+	    (cmd == NAND_READ_ID_CMD) ||
+	    (cmd == NAND_READ_PARAMETER_CMD)) {
+
+		xlp_nand_write_reg(data, NAND_DMA_CTRL,
+				(1 << 7) | (1 << 6) | (5 << 2));
+	} else
+		xlp_nand_write_reg(data, NAND_DMA_CTRL,
+				(1 << 7) | (0 << 6) | (5 << 2));
+}
+
+static void xlp_send_cmd(struct mtd_info *mtd,
+		unsigned int cmd,
+		int column,
+		int page_addr,
+		int len)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+	unsigned long val;
+	int column2, len2;
+	int timeout;
+
+	struct xlp_nand_data *data = container_of(mtd,
+					struct xlp_nand_data, mtd);
+
+	/* Enable CEIE interrupt */
+	xlp_nand_write_reg(data, NAND_INTMASK, 0x2);
+	xlp_nand_write_reg(data, NAND_INT_STATUS, 0x0);
+
+	/* The hardware ECC will be generated if the size is mtd->writesize.
+	 * So if the write data is more than mtd->writesize,
+	 * let us break it into two.
+	 * hardware ECC will be disabled for the second part.
+	 */
+	if ((column + len) > mtd->writesize) {
+		if (mtd->writesize > 0) {
+			column2 = mtd->writesize;
+			len2 = column + len - mtd->writesize;
+			len = mtd->writesize - column;
+		} else {
+			column2 = column;
+			len2 = len;
+			len = 0;
+		}
+	} else {
+		column2 = 0;
+		len2 = 0;
+	}
+
+	if (len > 0) {
+		xlp_nand_send_cmd(data, state, cmd, page_addr, column, len);
+		xlp_nand_write_reg(data, NAND_CMD, cmd | NAND_CMD_DMA_FLAG);
+		xlp_dma_wait(data, state->cs);
+	}
+
+	if (len2 > 0) {
+		xlp_nand_send_cmd(data, state, cmd, page_addr, column, len2);
+
+		val = xlp_nand_read_reg(data, NAND_CTRL);
+		xlp_nand_write_reg(data, NAND_CTRL,
+				(val & ~NAND_CTRL_ECC_EN(1)));
+		xlp_nand_write_reg(data, NAND_CMD, cmd | NAND_CMD_DMA_FLAG);
+		xlp_dma_wait(data, state->cs);
+		if (data->hwecc) {
+			val = xlp_nand_read_reg(data, NAND_CTRL);
+			xlp_nand_write_reg(data, NAND_CTRL,
+					(val | NAND_CTRL_ECC_EN(1)));
+		}
+	}
+
+	if (cmd == NAND_CMD_PAGEPROG || cmd == NAND_CMD_READ0 ||
+			cmd == NAND_CMD_READOOB) {
+		timeout = wait_for_completion_timeout(&data->cmd_complete,
+				msecs_to_jiffies(1000));
+		if (timeout)
+			pr_err("xfer timedout!!!\n");
+	}
+
+	state->last_cmd = cmd;
+}
+
+static void xlp_nand_cmdfunc(struct mtd_info *mtd,
+		unsigned int command,
+		int column,
+		int page_addr)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+	static int column_prog;
+	static int page_prog;
+	int len = 0, status;
+	uint32_t val;
+
+	struct xlp_nand_data *data = container_of(mtd,
+					struct xlp_nand_data, mtd);
+
+	init_completion(&data->cmd_complete);
+
+	if (state->cs < 0)
+		return;
+
+	switch (command) {
+	/*
+	 * READ0 - read in first  256 bytes
+	 * READ1 - read in second 256 bytes
+	 */
+	case NAND_CMD_READ1:
+		column += 256;
+	case NAND_CMD_READ0:
+		state->buf_ptr = 0;
+		xlp_send_cmd(mtd,
+				NAND_READ_PAGE_CMD,
+				column,
+				page_addr,
+				mtd->writesize);
+		state->buf_ptr += mtd->writesize;
+		xlp_send_cmd(mtd,
+				NAND_READ_PAGE_CMD,
+				(mtd->writesize + column),
+				page_addr,
+				(mtd->oobsize - column));
+		state->buf_ptr = 0;
+		break;
+		/* READOOB reads only the OOB because no ECC is performed. */
+	case NAND_CMD_READOOB:
+		state->buf_ptr = 0;
+		xlp_send_cmd(mtd,
+				NAND_READ_PAGE_CMD,
+				(mtd->writesize + column),
+				page_addr,
+				(mtd->oobsize - column));
+		state->buf_ptr = 0;
+		break;
+		/* READID must read all 5 possible bytes while CEB is active */
+	case NAND_CMD_READID:
+		state->buf_ptr = 0;
+		xlp_send_cmd(mtd, NAND_READ_ID_CMD, column, 0, 8);
+		state->buf_ptr = 0;
+		break;
+	case NAND_CMD_PARAM:
+		state->buf_ptr = 0;
+		xlp_send_cmd(mtd, NAND_READ_PARAMETER_CMD, 0, 0, 1024);
+		xlp_onfi_init(chip);
+		break;
+		/* ERASE1 stores the block and page address */
+	case NAND_CMD_ERASE1:
+		val = (page_addr >> (32 - (state->col_cyc*8)));
+		xlp_nand_write_reg(data, NAND_ADDR1_L, val);
+		val = ((page_addr << (state->col_cyc * 8)));
+		xlp_nand_write_reg(data, NAND_ADDR0_L, val);
+		break;
+		/* ERASE2 uses the block and page address from ERASE1 */
+	case NAND_CMD_ERASE2:
+		xlp_nand_write_reg(data, NAND_CMD, NAND_ERASE_BLOCK_CMD);
+		state->last_cmd = NAND_ERASE_BLOCK_CMD;
+		status = chip->waitfunc(mtd, chip);
+		if (status & 0x01)
+			pr_debug("%s: error status = 0x%08x\n",
+					__func__, status);
+		break;
+		/* SEQIN sets up the addr buffer and all registers except
+		 * the length */
+	case NAND_CMD_SEQIN:
+		column_prog  = column;
+		page_prog = page_addr;
+		state->buf_ptr = 0;
+		break;
+		/* PAGEPROG reuses all of the setup from SEQIN and adds
+		 * the length */
+	case NAND_CMD_PAGEPROG:
+		len = state->buf_ptr;
+		state->buf_ptr = 0;
+		xlp_send_cmd(mtd,
+				NAND_PAGE_PROGRAM_CMD,
+				column_prog,
+				page_prog,
+				len);
+		status = chip->waitfunc(mtd, chip);
+		if (status & 0x01)
+			pr_debug("%s: error status = 0x%08x\n",
+					__func__, status);
+		break;
+
+	case NAND_CMD_STATUS:
+		xlp_nand_write_reg(data, NAND_CMD, NAND_READ_STATUS_CMD);
+		state->last_cmd = NAND_READ_STATUS_CMD;
+		break;
+		/* RESET command */
+	case NAND_CMD_RESET:
+		xlp_nand_write_reg(data, NAND_CMD, NAND_RESET_CMD);
+		state->last_cmd = NAND_RESET_CMD;
+		status = chip->waitfunc(mtd, chip);
+		if (status & 0x01)
+			pr_debug("%s: error status = 0x%08x\n",
+					__func__, status);
+		break;
+
+	default:
+		pr_info("%s: unsupported command 0x%x\n", __func__, command);
+	}
+}
+
+static void xlp_select_chip(struct mtd_info *mtd, int dev)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+
+	struct xlp_nand_data *data = container_of(mtd,
+			struct xlp_nand_data, mtd);
+
+	if ((dev >= 0) && (dev < 8)) {
+		state->cs = dev + NAND_DEV_CS;
+		xlp_nand_write_reg(data, NAND_MEMCTRL, state->cs);
+	} else {
+		state->cs = -1;
+	}
+}
+
+static uint8_t xlp_nand_read_byte(struct mtd_info *mtd)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+
+	struct xlp_nand_data *data = container_of(mtd,
+					struct xlp_nand_data, mtd);
+	uint32_t status;
+
+	if (state->cs < 0)
+		return 0;
+
+	if (state->last_cmd == NAND_READ_STATUS_CMD) {
+		status = xlp_nand_read_reg(data, NAND_READ_STATUS);
+		return status;
+	} else {
+		status = state->buf[state->buf_ptr];
+		state->buf_ptr = (state->buf_ptr + 1) % BUF_SIZE;
+		return status;
+	}
+}
+
+static void xlp_nand_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+	int i;
+
+	if (state->cs < 0)
+		return;
+
+	for (i = 0; i < len; i++) {
+		buf[i] = state->buf[state->buf_ptr];
+		state->buf_ptr = (state->buf_ptr + 1) % BUF_SIZE;
+	}
+}
+
+static void xlp_nand_write_buf(struct mtd_info *mtd, const u8 *buf, int len)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+	int i = 0;
+
+	if (state->cs < 0)
+		return;
+
+	while (len > 0) {
+		state->buf[state->buf_ptr] = buf[i++];
+		len--;
+		state->buf_ptr = (state->buf_ptr + 1) % BUF_SIZE;
+	}
+}
+
+static int xlp_nand_read_page(struct mtd_info *mtd, struct nand_chip *chip,
+		uint8_t *buf, int oob, int page)
+{
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+
+	if (state->cs < 0)
+		return -1;
+
+	if (oob)
+		xlp_nand_read_buf(mtd, chip->oob_poi, mtd->oobsize);
+	else
+		xlp_nand_read_buf(mtd, buf, mtd->writesize);
+
+	return 0;
+}
+
+static int xlp_nand_write_page(struct mtd_info *mtd, struct nand_chip *chip,
+			const uint8_t *buf, int oob)
+{
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+
+	if (state->cs < 0)
+		return 0;
+
+	if (oob)
+		xlp_nand_write_buf(mtd, chip->oob_poi, mtd->oobsize);
+	else
+		xlp_nand_write_buf(mtd, buf, mtd->writesize);
+
+	return 0;
+}
+
+static irqreturn_t xlp_nand_interrupt(int irq, void *dev_id)
+{
+	struct xlp_nand_data *data = dev_id;
+	int stat;
+
+	stat = xlp_nand_read_reg(data, NAND_INT_STATUS);
+	/* Clear all interrupts and Disable the interrupt */
+	xlp_nand_write_reg(data, NAND_INT_STATUS, 0x0);
+	xlp_nand_write_reg(data, NAND_INTMASK, 0x0);
+
+	complete(&data->cmd_complete);
+
+	return IRQ_HANDLED;
+}
+/*
+ * Probe for the NAND device.
+ */
+static int xlp_nand_probe(struct platform_device *pdev)
+{
+	struct xlp_nand_data *data = NULL;
+	struct nand_info *info = NULL;
+	struct nand_state *state = NULL;
+	struct mtd_part_parser_data ppdata;
+	struct resource *res;
+	uint32_t val;
+	const __be32 *prop;
+	int irq, ecc_mode, ret = 0;
+
+	data = devm_kzalloc(&pdev->dev, sizeof(struct xlp_nand_data), GFP_KERNEL);
+	if (!data) {
+		dev_err(&pdev->dev, "failed to get device structure.\n");
+		return -ENOMEM;
+	}
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		pr_info("couldn't get resource !!\n");
+		return -ENOMEM;
+	}
+
+	info = devm_kzalloc(&pdev->dev, sizeof(struct nand_info), GFP_KERNEL);
+	if (!info)
+		return -ENOMEM;
+
+	info->nand_state = devm_kzalloc(&pdev->dev, sizeof(struct nand_state), GFP_KERNEL);
+	if (!info->nand_state)
+		return -ENOMEM;
+
+	data->io_base = devm_request_and_ioremap(&pdev->dev, res);
+	if (!data->io_base) {
+		dev_err(&pdev->dev, "ioremap failed!!\n");
+		return -ENOMEM;
+	}
+
+	pdev->dev.dma_mask = &xlp_dev_dma_mask;
+	pdev->dev.coherent_dma_mask = DMA_BIT_MASK(32);
+
+	state		= info->nand_state;
+	state->last_cmd	= 0;
+	state->cs	= 0;
+	state->buf_ptr	= 0;
+	state->buf	= dmam_alloc_coherent(&pdev->dev, BUF_SIZE,
+				&(state->buf_dma), GFP_KERNEL);
+	if (!state->buf) {
+		pr_info("%s: dma_alloc_coherent failed!!\n", __func__);
+		return -ENXIO;
+	}
+
+	data->chip.priv	= (void *)info;
+
+	data->mtd.priv	= &data->chip;
+	data->mtd.owner	= THIS_MODULE;
+	data->mtd.name	= dev_name(&pdev->dev);
+
+	data->chip.chip_delay	= 20;
+	data->chip.IO_ADDR_R	= data->io_base;
+	data->chip.IO_ADDR_W	= data->io_base;
+	data->chip.read_byte	= xlp_nand_read_byte;
+	data->chip.read_buf	= xlp_nand_read_buf;
+	data->chip.write_buf	= xlp_nand_write_buf;
+	data->chip.cmdfunc	= xlp_nand_cmdfunc;
+	data->chip.select_chip	= xlp_select_chip;
+	data->chip.options	= NAND_SKIP_BBTSCAN;
+
+	xlp_nand_write_reg(data, NAND_CTRL, NAND_CTRL_CUSTOM_XFER_FLAG |
+			NAND_CTRL_GINTR_EN);
+	val = (NAND_TIME_SEQ0_TWHR(7) |
+	       NAND_TIME_SEQ0_TRHW(7) |
+	       NAND_TIME_SEQ0_TADL(7) |
+	       NAND_TIME_SEQ0_TCCS(7));
+	xlp_nand_write_reg(data, NAND_TIME_SEQ0, val);
+
+	val = NAND_TIME_ASYN_TRWH(8) | NAND_TIME_ASYN_TRWP(8);
+	xlp_nand_write_reg(data, NAND_TIMINGS_ASYN, val);
+
+	ecc_mode = of_get_nand_ecc_mode(pdev->dev.of_node);
+	data->chip.ecc.mode = ecc_mode < 0 ? NAND_ECC_SOFT : ecc_mode;
+	data->hwecc = ecc_mode == NAND_ECC_HW ? 1 : 0;
+
+	if (data->hwecc)
+		data->mtd.oobsize = XLP_HWECC_OOBSIZE;
+	else
+		data->mtd.oobsize = 64;
+
+	data->chip.ecc.read_page  = xlp_nand_read_page;
+	data->chip.ecc.write_page = xlp_nand_write_page;
+
+	prop = of_get_property(pdev->dev.of_node, "interrupts", NULL);
+	if (prop == NULL) {
+		dev_err(&pdev->dev, "No \"interrupts\" property!\n");
+		return -ENXIO;
+	}
+	irq = be32_to_cpu(*prop);
+	if (!irq) {
+		dev_err(&pdev->dev, "no irq!\n");
+		return -ENXIO;
+	}
+
+	ret = devm_request_irq(&pdev->dev, irq, xlp_nand_interrupt, 0,
+			pdev->name, data);
+	if (ret) {
+		dev_err(&pdev->dev, "request_irq failed!!\n");
+		return ret;
+	}
+
+	platform_set_drvdata(pdev, data);
+
+	if (nand_scan(&data->mtd, 1))
+		return -ENXIO;
+
+	ppdata.of_node = pdev->dev.of_node;
+	ret = mtd_device_parse_register(&data->mtd, NULL, &ppdata, NULL, 0);
+
+	if (!ret)
+		return ret;
+
+	nand_release(&data->mtd);
+
+	return ret;
+}
+
+static int xlp_nand_remove(struct platform_device *pdev)
+{
+	struct xlp_nand_data *data = platform_get_drvdata(pdev);
+	nand_release(&data->mtd);
+	kfree(data);
+	return 0;
+
+}
+static const struct of_device_id xlp_nand_dt[] = {
+	{ .compatible = "netlogic,xlp-nand" },
+};
+
+static struct platform_driver xlp_nand_driver = {
+	.probe	= xlp_nand_probe,
+	.remove	= xlp_nand_remove,
+	.driver	= {
+		.name		= "xlp-nand",
+		.owner		= THIS_MODULE,
+		.of_match_table = xlp_nand_dt,
+	},
+};
+module_platform_driver(xlp_nand_driver);
+
+MODULE_AUTHOR("Kamlakant Patel <kamlakant.patel@broadcom.com>");
+MODULE_DESCRIPTION("Netlogic XLP NAND Flash Controller driver");
+MODULE_LICENSE("GPL v2");
diff --git a/include/linux/mtd/spinand.h b/include/linux/mtd/spinand.h
new file mode 100644
index 0000000..bb2b6fd
--- /dev/null
+++ b/include/linux/mtd/spinand.h
@@ -0,0 +1,103 @@
+/*-
+ * Copyright 2013 Broadcom Corporation
+ *
+ * Copyright (c) 2009-2010 Micron Technology, Inc.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * Henry Pan <hspan@micron.com>
+ *
+ * based on nand.h
+ */
+#ifndef __LINUX_MTD_SPI_NAND_H
+#define __LINUX_MTD_SPI_NAND_H
+
+#include <linux/wait.h>
+#include <linux/spinlock.h>
+#include <linux/mtd/mtd.h>
+
+/* cmd */
+#define CMD_READ			0x13
+#define CMD_READ_RDM			0x03
+#define CMD_PROG_PAGE_CLRCACHE		0x02
+#define CMD_PROG_PAGE			0x84
+#define CMD_PROG_PAGE_EXC		0x10
+#define CMD_ERASE_BLK			0xd8
+#define CMD_WR_ENABLE			0x06
+#define CMD_WR_DISABLE			0x04
+#define CMD_READ_ID			0x9f
+#define CMD_RESET			0xff
+#define CMD_READ_REG			0x0f
+#define CMD_WRITE_REG			0x1f
+
+/* feature/ status reg */
+#define REG_BLOCK_LOCK			0xa0
+#define REG_OTP				0xb0
+#define REG_STATUS			0xc0/* timing */
+
+/* status */
+#define STATUS_OIP_MASK			0x01
+#define STATUS_READY			(0 << 0)
+#define STATUS_BUSY			(1 << 0)
+
+#define STATUS_E_FAIL_MASK		0x04
+#define STATUS_E_FAIL			(1 << 2)
+
+#define STATUS_P_FAIL_MASK		0x08
+#define STATUS_P_FAIL			(1 << 3)
+
+#define STATUS_ECC_MASK			0x30
+#define STATUS_ECC_1BIT_CORRECTED	(1 << 4)
+#define STATUS_ECC_ERROR		(2 << 4)
+#define STATUS_ECC_RESERVED		(3 << 4)
+
+/*ECC enable defines*/
+#define OTP_ECC_MASK			0x10
+#define OTP_ECC_OFF			0
+#define OTP_ECC_ON			1
+
+/* block lock */
+#define BL_ALL_LOCKED      0x38
+#define BL_1_2_LOCKED      0x30
+#define BL_1_4_LOCKED      0x28
+#define BL_1_8_LOCKED      0x20
+#define BL_1_16_LOCKED     0x18
+#define BL_1_32_LOCKED     0x10
+#define BL_1_64_LOCKED     0x08
+#define BL_ALL_UNLOCKED    0
+
+struct spinand_info {
+	struct nand_ecclayout *ecclayout;
+	struct spi_device *spi;
+	void *priv;
+};
+
+struct spinand_state {
+	uint32_t	col;
+	uint32_t	row;
+	int		buf_ptr;
+	u8		*buf;
+};
+
+struct spinand_cmd {
+	u8		cmd;
+	u32		n_addr;		/* Number of address */
+	u8		addr[3];	/* Reg Offset */
+	u32		n_dummy;	/* Dummy use */
+	u32		n_tx;		/* Number of tx bytes */
+	u8		*tx_buf;	/* Tx buf */
+	u32		n_rx;		/* Number of rx bytes */
+	u8		*rx_buf;	/* Rx buf */
+};
+
+extern int spinand_mtd(struct mtd_info *mtd);
+extern void spinand_mtd_release(struct mtd_info *mtd);
+
+#endif /* __LINUX_MTD_SPI_NAND_H */
-- 
1.7.9.5

