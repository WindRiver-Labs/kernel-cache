From 6976e111fa2066f48b975ba60507a4f4dae60bab Mon Sep 17 00:00:00 2001
From: Om Narasimhan <omn@broadcom.com>
Date: Thu, 4 Oct 2012 11:35:31 -0700
Subject: [PATCH 603/761] PCI: Implements multiple MSIs per device

x86 and many other h/w architectures restricts the number of MSI that a device
can request to a maximum of 1. XLP does not have this limitation, but linux
kernel traditionally did not honor such requests by device drivers. This patch
implements necessary infrastructure so that such calls will succeed in XLP.

Based on Broadcom SDK 2.3.

Signed-off-by: Om Narasimhan <omn@broadcom.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/netlogic/xlp/msi.c |   73 ++++++++++++++++++++++++------------------
 drivers/pci/msi.c            |   56 ++++++++++++++++++++------------
 2 files changed, 76 insertions(+), 53 deletions(-)

diff --git a/arch/mips/netlogic/xlp/msi.c b/arch/mips/netlogic/xlp/msi.c
index 1c00684..b50574f 100644
--- a/arch/mips/netlogic/xlp/msi.c
+++ b/arch/mips/netlogic/xlp/msi.c
@@ -102,24 +102,23 @@ static int xlp_msi_compose_msg(struct pci_dev *pdev, struct msi_desc *desc,
  *
  * On XLP, we can have more than one MSI per device. But no device requests it
  * because of possible x86 influence (one MSI per device limitation).
- * We enforce this limitation as well.
+ * We honor multiple MSIs per device should such a request is made.
  */
-int xlp_setup_msi_irq(struct pci_dev *dev, struct msi_desc *desc, int nvec)
+int xlp_setup_msi_irq(struct pci_dev *dev, int nvec)
 {
 	__label__ setup_end;
 	__label__ setup_fail;
 	struct msi_msg msg;
-	int ret, bit, base_msi;
+	int ret, bit, base_msi, idx, new_irq = -1;
+	u32 old_bitmap, old_irq, old_count;
 	unsigned long flags;
 	struct xlp_nodefn_struct nfn;
+	struct msi_desc *desc;
 
 	if (xlp_ctrl_fn_from_dev(dev, &nfn) < 0) {
 		return -EFAULT;
 	}
 	base_msi = XLP_MSI_IRQ_START(nfn.node, nfn.fn);
-	if (nvec != 1) {	/* This condition to be removed TBD */
-		return -EINVAL;
-	}
 	spin_lock_irqsave(&xlp_msi_lock, flags);
 	ret = xlp_get_ctrl_intmode(nfn.node, nfn.fn);
 	if ((ret == XLP_INTMODE_MSIX ) || (ret == XLP_INTMODE_INTX)) {
@@ -130,31 +129,46 @@ int xlp_setup_msi_irq(struct pci_dev *dev, struct msi_desc *desc, int nvec)
 	 * Please note that the usage is different from that of MSIX allocation
 	 * where we have the luxury of 1 irt entry per MSIX. Here we have to
 	 * multiplex in software */
-	if (msi_vec[nfn.node][nfn.fn].bitmap == 0) {
-		bit = 0;
-	} else {
-		bit = ffz(msi_vec[nfn.node][nfn.fn].bitmap);
-	}
-	if (bit > (XLP_MSI_PER_SLOT - 1)) {
-		ret = -ENOSPC;
-		goto setup_end;
-	}
-	msi_vec[nfn.node][nfn.fn].bitmap |= (1ULL << bit);
-	msi_vec[nfn.node][nfn.fn].count++;
-	base_msi += bit;
-	irq_set_msi_desc(base_msi, desc);
-	ret = xlp_msi_compose_msg(dev, desc, base_msi, &msg);
-	if (ret < 0) {
-		goto setup_fail;
+	old_irq = dev->irq;
+	old_bitmap = msi_vec[nfn.node][nfn.fn].bitmap;
+	old_count = msi_vec[nfn.node][nfn.fn].count;
+
+	bit = idx = 0;
+	list_for_each_entry(desc, &dev->msi_list, list) {
+		if (msi_vec[nfn.node][nfn.fn].bitmap == 0) {
+			bit = 0;
+		} else {
+			bit = ffz(msi_vec[nfn.node][nfn.fn].bitmap);
+		}
+		if (bit > (XLP_MSI_PER_SLOT - 1)) {
+			ret = -ENOSPC;
+			dev_err(&dev->dev, "No more MSI vectors to allocate\n");
+			if (idx > 0) {
+				ret = idx;
+			}
+			goto setup_fail;
+		}
+		/* Get a vector for allocated bit `bit` */
+		msi_vec[nfn.node][nfn.fn].bitmap |= (1ULL << bit);
+		msi_vec[nfn.node][nfn.fn].count++;
+		irq_set_msi_desc(base_msi + bit, desc);
+		if (new_irq == -1) new_irq = base_msi + bit;
+		ret = xlp_msi_compose_msg(dev, desc, base_msi + bit, &msg);
+		if (ret < 0) {
+			goto setup_fail;
+		}
+		write_msi_msg(base_msi, &msg);
+		idx++;
 	}
-	write_msi_msg(base_msi, &msg);
 	ret = xlp_set_ctrl_intmode(nfn.node, nfn.fn, XLP_INTMODE_MSI);
 	if (ret == 0) {	/* success */
+		dev->irq = new_irq;
 		goto setup_end;	/* All done */
 	}
 setup_fail:
-	msi_vec[nfn.node][nfn.fn].bitmap &= ~(1ULL << bit);
-	msi_vec[nfn.node][nfn.fn].count--;
+	dev->irq = old_irq;
+	msi_vec[nfn.node][nfn.fn].bitmap = old_bitmap;
+	msi_vec[nfn.node][nfn.fn].count = old_count;
 setup_end:
 	spin_unlock_irqrestore(&xlp_msi_lock, flags);
 	return ret;
@@ -240,7 +254,6 @@ setup_end:
 
 int arch_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 {
-	struct msi_desc *entry;
 	int ret;
 
 	if (nvec == 0) {
@@ -252,11 +265,7 @@ int arch_setup_msi_irqs(struct pci_dev *dev, int nvec, int type)
 	 * in dev->msi_list. That means, we cannot setup more than one
 	 * MSI, even if architecture allows it.  */
 	if (type == PCI_CAP_ID_MSI) {
-		if (nvec > 1) {
-			return -EINVAL;
-		}
-		entry = list_first_entry(&dev->msi_list, struct msi_desc, list);
-		ret = xlp_setup_msi_irq(dev, entry, nvec);
+		ret = xlp_setup_msi_irq(dev, nvec);
 	} else if (type == PCI_CAP_ID_MSIX) {
 	/* MSI-X has nvec entries allocated
 	 * if nvec is greater than max number vectors that can be allocated,
@@ -309,7 +318,7 @@ static unsigned int nlm_msi_startup(struct irq_data *data)
 	return xlp_irq_startup(pic, irq % XLP_IRQS_PER_NODE);
 }
 
-static int nlm_msi_set_affinity(struct irq_data *data, const struct cpumask *mask, bool force)
+	static int nlm_msi_set_affinity(struct irq_data *data, const struct cpumask *mask, bool force)
 {
 	struct cpumask m;
 	unsigned int msi = data->irq;
diff --git a/drivers/pci/msi.c b/drivers/pci/msi.c
index a825d78..3312263 100644
--- a/drivers/pci/msi.c
+++ b/drivers/pci/msi.c
@@ -365,7 +365,10 @@ static void free_msi_irqs(struct pci_dev *dev)
 	}
 }
 
-static struct msi_desc *alloc_msi_entry(struct pci_dev *dev)
+#ifndef CONFIG_NLM_XLP
+static
+#endif
+struct msi_desc *alloc_msi_entry(struct pci_dev *dev)
 {
 	struct msi_desc *desc = kzalloc(sizeof(*desc), GFP_KERNEL);
 	if (!desc)
@@ -549,31 +552,42 @@ static int msi_capability_init(struct pci_dev *dev, int nvec)
 	int pos, ret;
 	u16 control;
 	unsigned mask;
+	int ct = 0, nvecs = nvec;
 
+#ifndef CONFIG_NLM_XLP
+	nvecs = 1;	/* Other arch. might not support nvec > 1 */
+#else
+	if(nvec && ((nvec & (nvec - 1)) != 0)) {
+		/* nvec must be a power of two */
+		return -EINVAL;
+	}
+#endif
 	pos = pci_find_capability(dev, PCI_CAP_ID_MSI);
 	msi_set_enable(dev, pos, 0);	/* Disable MSI during set up */
 
-	pci_read_config_word(dev, msi_control_reg(pos), &control);
-	/* MSI Entry Initialization */
-	entry = alloc_msi_entry(dev);
-	if (!entry)
-		return -ENOMEM;
+	for (ct = 0; ct < nvecs; ct++) {
+		pci_read_config_word(dev, msi_control_reg(pos), &control);
+		/* MSI Entry Initialization */
+		entry = alloc_msi_entry(dev);
+		if (!entry)
+			return -ENOMEM;
+
+		entry->msi_attrib.is_msix	= 0;
+		entry->msi_attrib.is_64		= is_64bit_address(control);
+		entry->msi_attrib.entry_nr	= ct;
+		entry->msi_attrib.maskbit	= is_mask_bit_support(control);
+		entry->msi_attrib.default_irq	= dev->irq + ct;/* Save IOAPIC IRQ */
+		entry->msi_attrib.pos		= pos;
 
-	entry->msi_attrib.is_msix	= 0;
-	entry->msi_attrib.is_64		= is_64bit_address(control);
-	entry->msi_attrib.entry_nr	= 0;
-	entry->msi_attrib.maskbit	= is_mask_bit_support(control);
-	entry->msi_attrib.default_irq	= dev->irq;	/* Save IOAPIC IRQ */
-	entry->msi_attrib.pos		= pos;
-
-	entry->mask_pos = msi_mask_reg(pos, entry->msi_attrib.is_64);
-	/* All MSIs are unmasked by default, Mask them all */
-	if (entry->msi_attrib.maskbit)
-		pci_read_config_dword(dev, entry->mask_pos, &entry->masked);
-	mask = msi_capable_mask(control);
-	msi_mask_irq(entry, mask, mask);
-
-	list_add_tail(&entry->list, &dev->msi_list);
+		entry->mask_pos = msi_mask_reg(pos, entry->msi_attrib.is_64);
+		/* All MSIs are unmasked by default, Mask them all */
+		if (entry->msi_attrib.maskbit)
+			pci_read_config_dword(dev, entry->mask_pos, &entry->masked);
+		mask = msi_capable_mask(control);
+		msi_mask_irq(entry, mask, mask);
+
+		list_add_tail(&entry->list, &dev->msi_list);
+	}
 
 	/* Configure MSI capability structure */
 	ret = arch_setup_msi_irqs(dev, nvec, PCI_CAP_ID_MSI);
-- 
1.7.10.4

