From 8a9bc57ee55839a88dc2b0ef709c95ce660605d9 Mon Sep 17 00:00:00 2001
From: Yanjiang Jin <yanjiang.jin@windriver.com>
Date: Thu, 25 Apr 2013 13:07:49 +0800
Subject: [PATCH 002/762] import of RMI XLP svn branch

Import of RMI XLP svn branch
@ r2449 e38a0ec8-7566-4368-984d-d703fc0d8259

Based on Broadcom SDK 2.3.

Signed-off-by: Venu Vadapalli <vvadapalli@netlogicmicro.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/Kconfig                                  |   78 +-
 arch/mips/Makefile                                 |   70 +-
 arch/mips/include/asm/abi.h                        |    1 +
 arch/mips/include/asm/addrspace.h                  |    4 +
 arch/mips/include/asm/asmmacro.h                   |   25 +
 arch/mips/include/asm/atomic.h                     |   18 +
 arch/mips/include/asm/bitops.h                     |   20 +
 arch/mips/include/asm/bootinfo.h                   |   34 +-
 arch/mips/include/asm/cacheflush.h                 |   22 +-
 arch/mips/include/asm/cpu-features.h               |    3 +
 arch/mips/include/asm/cpu.h                        |    1 +
 arch/mips/include/asm/dma.h                        |    4 +
 arch/mips/include/asm/hazards.h                    |    2 +
 arch/mips/include/asm/irqflags.h                   |   34 +
 arch/mips/include/asm/mach-generic/spaces.h        |   20 +-
 .../include/asm/mach-rmi/cpu-feature-overrides.h   |    7 +
 arch/mips/include/asm/mach-rmi/kernel-entry-init.h |   57 +
 arch/mips/include/asm/mach-rmi/mmu.h               |   64 +
 arch/mips/include/asm/mach-rmi/pgtable-xlp.h       |   59 +
 arch/mips/include/asm/mach-rmi/pgwalker.h          |   36 +
 arch/mips/include/asm/mach-rmi/spaces.h            |   20 +
 arch/mips/include/asm/mach-rmi/war.h               |   25 +
 arch/mips/include/asm/mach-rmi/xlp-mmu.h           |   35 +
 arch/mips/include/asm/mipsregs.h                   |   24 +
 arch/mips/include/asm/mman.h                       |    6 +
 arch/mips/include/asm/mmu_context.h                |   25 +
 arch/mips/include/asm/module.h                     |   16 +
 arch/mips/include/asm/msi.h                        |   28 +
 arch/mips/include/asm/page.h                       |   45 +-
 arch/mips/include/asm/perfctr.h                    |  241 +
 arch/mips/include/asm/pgtable-32.h                 |    5 +
 arch/mips/include/asm/pgtable-64.h                 |   11 +-
 arch/mips/include/asm/pgtable-bits.h               |    6 +
 arch/mips/include/asm/pgtable.h                    |    7 +
 arch/mips/include/asm/processor.h                  |   13 +-
 arch/mips/include/asm/ptrace.h                     |    1 +
 arch/mips/include/asm/rio.h                        |   15 +
 arch/mips/include/asm/rmi/64bit.h                  |   85 +
 arch/mips/include/asm/rmi/atx_cpld.h               |   64 +
 arch/mips/include/asm/rmi/config_net.h             |  118 +
 arch/mips/include/asm/rmi/debug.h                  |  117 +
 arch/mips/include/asm/rmi/devices.h                |   46 +
 arch/mips/include/asm/rmi/global_shmem.h           |   48 +
 arch/mips/include/asm/rmi/gpio.h                   |   77 +
 arch/mips/include/asm/rmi/interrupt.h              |   62 +
 arch/mips/include/asm/rmi/io.h                     |   53 +
 arch/mips/include/asm/rmi/iomap.h                  |  299 ++
 arch/mips/include/asm/rmi/linux_crf.h              |   80 +
 arch/mips/include/asm/rmi/memory-exclusion.h       |   38 +
 arch/mips/include/asm/rmi/mips-exts.h              |  413 ++
 arch/mips/include/asm/rmi/msgring.h                |  692 +++
 arch/mips/include/asm/rmi/msidef.h                 |   73 +
 arch/mips/include/asm/rmi/pci.h                    |   38 +
 arch/mips/include/asm/rmi/perf_ctr.h               |   72 +
 arch/mips/include/asm/rmi/phnx_cde.h               |  170 +
 arch/mips/include/asm/rmi/phnx_loader.h            |  175 +
 arch/mips/include/asm/rmi/phnx_tb.h                |   97 +
 arch/mips/include/asm/rmi/phnx_user_mac.h          |   61 +
 arch/mips/include/asm/rmi/phoenix_flash_pcmcia.h   |  116 +
 arch/mips/include/asm/rmi/phoenix_ide.h            |   62 +
 arch/mips/include/asm/rmi/phoenix_mac.h            | 1163 +++++
 arch/mips/include/asm/rmi/phoenix_rmios_debugger.h |   53 +
 arch/mips/include/asm/rmi/phoenix_sec.h            |  772 +++
 arch/mips/include/asm/rmi/phoenix_shim_drv.h       |  510 ++
 arch/mips/include/asm/rmi/phoenix_uart.h           |   52 +
 arch/mips/include/asm/rmi/pic.h                    |   67 +
 arch/mips/include/asm/rmi/proc.h                   |   51 +
 arch/mips/include/asm/rmi/rmi_pcix_gen_dev.h       |  124 +
 arch/mips/include/asm/rmi/rmi_pcix_gen_host.h      |  130 +
 arch/mips/include/asm/rmi/rmi_rw_lock.h            |  221 +
 arch/mips/include/asm/rmi/rmi_srio.h               |  343 ++
 arch/mips/include/asm/rmi/rmi_uaccess_fs.h         |   60 +
 arch/mips/include/asm/rmi/rmicrf/api.h             |   88 +
 arch/mips/include/asm/rmi/rmicrf/bootinfo.h        |  121 +
 arch/mips/include/asm/rmi/rmicrf/byteorder.h       |   73 +
 arch/mips/include/asm/rmi/rmicrf/clpool.h          |   81 +
 arch/mips/include/asm/rmi/rmicrf/config.h          |  157 +
 arch/mips/include/asm/rmi/rmicrf/crflib.h          |  217 +
 arch/mips/include/asm/rmi/rmicrf/errcode.h         |   57 +
 arch/mips/include/asm/rmi/rmicrf/eventdefs.h       |  151 +
 arch/mips/include/asm/rmi/rmicrf/frame.h           |   90 +
 arch/mips/include/asm/rmi/rmicrf/linux.h           |  142 +
 arch/mips/include/asm/rmi/rmicrf/oscalls.h         |  208 +
 arch/mips/include/asm/rmi/rmicrf/pcpu.h            |   85 +
 arch/mips/include/asm/rmi/rmicrf/rmios.h           |   67 +
 arch/mips/include/asm/rmi/rmicrf/types.h           |  379 ++
 arch/mips/include/asm/rmi/rmidev/asm.h             |  105 +
 arch/mips/include/asm/rmi/rmidev/atomic.h          |  168 +
 arch/mips/include/asm/rmi/rmidev/bridge.h          |  105 +
 arch/mips/include/asm/rmi/rmidev/flash.h           |   20 +
 arch/mips/include/asm/rmi/rmidev/fmn.h             |  163 +
 arch/mips/include/asm/rmi/rmidev/gpio.h            |  135 +
 arch/mips/include/asm/rmi/rmidev/iomap.h           |  108 +
 arch/mips/include/asm/rmi/rmidev/pic.h             |  142 +
 arch/mips/include/asm/rmi/rmidev/platform.h        |  144 +
 arch/mips/include/asm/rmi/rmidev/rmichip.h         |   76 +
 arch/mips/include/asm/rmi/rmidev/uart.h            |   66 +
 arch/mips/include/asm/rmi/rmidev/xlrcr.h           |   89 +
 arch/mips/include/asm/rmi/rmidev/xlrextns.h        |  127 +
 arch/mips/include/asm/rmi/rmidev/xlrio.h           |  154 +
 arch/mips/include/asm/rmi/rmidev/xlrregs.h         |  414 ++
 arch/mips/include/asm/rmi/sim.h                    |  453 ++
 arch/mips/include/asm/rmi/utils.h                  |   88 +
 arch/mips/include/asm/rmi/xgmac_mdio.h             |  119 +
 arch/mips/include/asm/rmi/xlr_pcix_boot.h          |   42 +
 arch/mips/include/asm/rmi/xlr_virt_uart.h          |   68 +
 arch/mips/include/asm/smp.h                        |   15 +
 arch/mips/include/asm/timex.h                      |    5 +
 arch/mips/include/asm/unistd.h                     |   42 +-
 arch/mips/include/asm/xlr_macros.h                 |  117 +
 arch/mips/kernel/Makefile                          |    4 +
 arch/mips/kernel/asm-offsets.c                     |   18 +
 arch/mips/kernel/binfmt_elfo32.c                   |   40 +-
 arch/mips/kernel/genex.S                           |    4 +
 arch/mips/kernel/head.S                            |   46 +-
 arch/mips/kernel/kgdb.c                            |   59 +
 arch/mips/kernel/process.c                         |   25 +-
 arch/mips/kernel/ptrace.c                          |   24 +-
 arch/mips/kernel/rio.c                             |   49 +
 arch/mips/kernel/scall32-o32.S                     |   42 +
 arch/mips/kernel/scall64-64.S                      |   28 +-
 arch/mips/kernel/scall64-n32.S                     |   20 +-
 arch/mips/kernel/scall64-o32.S                     |   34 +-
 arch/mips/kernel/setup.c                           |   96 +-
 arch/mips/kernel/smp.c                             |   16 +-
 arch/mips/kernel/sync-r4k.c                        |   23 +
 arch/mips/kernel/syscall.c                         |   79 +-
 arch/mips/kernel/traps.c                           |   66 +-
 arch/mips/kernel/unaligned.c                       |   12 +-
 arch/mips/kernel/vmlinux.lds.S                     |   13 +
 arch/mips/kernel/xlr_fast_sys_call_handler.S       |  497 ++
 arch/mips/lib/Makefile                             |    6 +-
 arch/mips/lib/csum_partial_rminas.S                |  798 +++
 arch/mips/lib/delay.c                              |   57 +
 arch/mips/math-emu/cp1emu.c                        |   36 +-
 arch/mips/math-emu/kernel_linkage.c                |  211 +
 arch/mips/mm/Makefile                              |    4 +
 arch/mips/mm/c-phoenix.c                           |  600 +++
 arch/mips/mm/cache.c                               |   36 +
 arch/mips/mm/cerr-phoenix.c                        |  167 +
 arch/mips/mm/cex-gen.S                             |   39 +
 arch/mips/mm/extable.c                             |   21 +
 arch/mips/mm/ioremap.c                             |   18 +-
 arch/mips/mm/pg-phoenix.c                          |  136 +
 arch/mips/mm/pgtable-64.c                          |   20 +
 arch/mips/mm/tlb-phnx.c                            |  140 +
 arch/mips/mm/tlb-phoenix.c                         |  465 ++
 arch/mips/mm/tlb-r4k.c                             |  276 +-
 arch/mips/mm/tlbex-fault.S                         |    3 +
 arch/mips/mm/tlbex.c                               |   64 +-
 arch/mips/oprofile/Makefile                        |    1 +
 arch/mips/oprofile/common.c                        |   18 +-
 arch/mips/oprofile/op_impl.h                       |   14 +-
 arch/mips/oprofile/op_model_mips_xlr.c             |  362 ++
 arch/mips/pci/Makefile                             |    2 +
 arch/mips/pci/pci-phoenix.c                        |  759 +++
 arch/mips/pci/pci-xlp.c                            |  241 +
 arch/mips/rmi/Kconfig                              |  199 +
 arch/mips/rmi/boot/Makefile                        |    3 +
 arch/mips/rmi/boot/Makefile.standalone             |   36 +
 arch/mips/rmi/boot/boot.S                          |   69 +
 arch/mips/rmi/boot/bootloader.c                    |  138 +
 arch/mips/rmi/boot/bootloader.h                    |   46 +
 arch/mips/rmi/boot/ld.script.standalone            |   16 +
 arch/mips/rmi/mm/Makefile                          |    1 +
 arch/mips/rmi/mm/memory.c                          |  167 +
 arch/mips/rmi/phoenix/Makefile.msgring             |   25 +
 arch/mips/rmi/phoenix/Makefile.msgring.shared      |   23 +
 arch/mips/rmi/phoenix/Makefile.msgring.xls         |   24 +
 arch/mips/rmi/phoenix/cpu_proc.c                   |  203 +
 arch/mips/rmi/phoenix/dma.c                        |  607 +++
 arch/mips/rmi/phoenix/irq.c                        |  759 +++
 arch/mips/rmi/phoenix/msgring.cfg                  | 1280 +++++
 arch/mips/rmi/phoenix/msgring.l                    |   44 +
 arch/mips/rmi/phoenix/msgring.y                    |  544 ++
 arch/mips/rmi/phoenix/msgring_ike.cfg              | 1258 +++++
 arch/mips/rmi/phoenix/msgring_ike_xls.cfg          |  592 +++
 arch/mips/rmi/phoenix/msgring_openssl.cfg          | 1311 +++++
 arch/mips/rmi/phoenix/msgring_shared.cfg           |  487 ++
 arch/mips/rmi/phoenix/msgring_shared.l             |   44 +
 arch/mips/rmi/phoenix/msgring_shared.y             |  544 ++
 arch/mips/rmi/phoenix/msgring_xls.cfg              |  587 +++
 arch/mips/rmi/phoenix/msgring_xls.l                |   44 +
 arch/mips/rmi/phoenix/msgring_xls.y                |  539 ++
 arch/mips/rmi/phoenix/on_chip.c                    |  857 ++++
 arch/mips/rmi/phoenix/platform.c                   |  120 +
 arch/mips/rmi/phoenix/rmi_srio.c                   | 2228 ++++++++
 arch/mips/rmi/phoenix/smp.c                        |  170 +
 arch/mips/rmi/phoenix/time.c                       |  282 +
 arch/mips/rmi/ptr/Makefile                         |   11 +
 arch/mips/rmi/ptr/config_net.c                     |  562 ++
 arch/mips/rmi/ptr/dbg_io.c                         |   46 +
 arch/mips/rmi/ptr/loader/Makefile                  |    5 +
 arch/mips/rmi/ptr/loader/console.c                 |   74 +
 arch/mips/rmi/ptr/loader/entry.S                   |  139 +
 arch/mips/rmi/ptr/loader/fifo.h                    |   95 +
 arch/mips/rmi/ptr/loader/loader.c                  |  580 +++
 arch/mips/rmi/ptr/loader/reload_irq_handler.S      |   80 +
 arch/mips/rmi/ptr/loader/traps.c                   |  217 +
 arch/mips/rmi/ptr/loader/uart.c                    |  328 ++
 arch/mips/rmi/ptr/loader/uart.h                    |   75 +
 arch/mips/rmi/ptr/loader/xlr_boot_lib.h            |  403 ++
 arch/mips/rmi/ptr/loader/xlr_lib_launch.c          |  539 ++
 arch/mips/rmi/ptr/loader/xlr_lib_platform.h        |   93 +
 arch/mips/rmi/ptr/loader/xlr_rmios_stackframe.h    |  190 +
 arch/mips/rmi/ptr/nmi.S                            |   80 +
 arch/mips/rmi/ptr/platform-xlp.c                   |  294 ++
 arch/mips/rmi/ptr/platform.c                       |  245 +
 arch/mips/rmi/ptr/rmicrf/Makefile                  |    8 +
 arch/mips/rmi/ptr/rmicrf/Makefile.sync             |   41 +
 arch/mips/rmi/ptr/rmicrf/clpool.c                  |  487 ++
 arch/mips/rmi/ptr/rmicrf/dtb/Makefile              |    5 +
 arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree.c         | 1011 ++++
 arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree.h         |  113 +
 arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_env.h     |   66 +
 arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_misc.c    |   73 +
 arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_utils.c   |  814 +++
 arch/mips/rmi/ptr/rmicrf/dtb/ops.h                 |  192 +
 arch/mips/rmi/ptr/rmicrf/dtb/page.h                |   34 +
 arch/mips/rmi/ptr/rmicrf/dtb/simple_alloc.c        |  150 +
 arch/mips/rmi/ptr/rmicrf/dtb/types.h               |   32 +
 arch/mips/rmi/ptr/rmicrf/entry-linux.c             |  103 +
 arch/mips/rmi/ptr/rmicrf/entry.c                   |  369 ++
 arch/mips/rmi/ptr/rmicrf/event_handle.c            |  246 +
 arch/mips/rmi/ptr/rmicrf/eventq.c                  |  123 +
 arch/mips/rmi/ptr/rmicrf/fifo.c                    |  359 ++
 arch/mips/rmi/ptr/rmicrf/fmn.c                     |   90 +
 arch/mips/rmi/ptr/rmicrf/memcpy.c                  |   94 +
 arch/mips/rmi/ptr/rmicrf/mutex.c                   |  119 +
 arch/mips/rmi/ptr/rmicrf/processor.c               |  281 +
 arch/mips/rmi/ptr/rmicrf/rmik_utils.c              |  486 ++
 arch/mips/rmi/ptr/rmicrf/utils.c                   |   42 +
 arch/mips/rmi/ptr/setup.c                          | 1653 ++++++
 arch/mips/rmi/ptr/smp.c                            |  241 +
 arch/mips/rmi/ptr/smpboot.S                        |   73 +
 arch/mips/rmi/xlp/Makefile                         |    1 +
 arch/mips/rmi/xlp/mmu.c                            |  150 +
 arch/mips/rmi/xlr/Makefile                         |    1 +
 arch/mips/rmi/xlr/mmu.c                            |    7 +
 crypto/Makefile                                    |    1 +
 crypto/phoenix_sec.c                               |  224 +
 drivers/Makefile                                   |    2 +
 drivers/block/sbull.c                              |  357 ++
 drivers/char/Kconfig                               |   19 +
 drivers/char/Makefile                              |    5 +
 drivers/char/hw_random/Kconfig                     |    7 +-
 drivers/char/hw_random/Makefile                    |    1 +
 drivers/char/hw_random/xlr-rng.c                   |   85 +
 drivers/char/mem.c                                 |   10 +
 drivers/char/phnx_cde.c                            |  797 +++
 drivers/char/phnx_loader.c                         |  629 +++
 drivers/char/phnx_msgring.c                        |  742 +++
 drivers/char/phnx_msgring_debugger.c               |   86 +
 drivers/char/phnx_tb.c                             |  325 ++
 drivers/char/phoenix_rmios_debugger.c              |  332 ++
 drivers/char/random.c                              |   36 +
 drivers/char/rmi_pcix_gen_dev.c                    |  282 +
 drivers/char/rmi_pcix_gen_host.c                   |  518 ++
 drivers/char/rmicrf/Makefile                       |    5 +
 drivers/char/rmicrf/crfdev.c                       |  220 +
 drivers/char/rmicrf/vuart.c                        |  502 ++
 drivers/char/xlr_pcix_console_dev.c                |  464 ++
 drivers/char/xlr_pcix_console_host.c               |  481 ++
 drivers/char/xlr_virtual_uart.c                    |  396 ++
 drivers/crypto/Kconfig                             |   11 +
 drivers/crypto/rmi/Makefile                        |    2 +
 drivers/crypto/rmi/ecc_ucode_data.h                |  363 ++
 drivers/crypto/rmi/rmi_auth.c                      |  459 ++
 drivers/crypto/rmi/rmi_enc.c                       |  822 +++
 drivers/crypto/rmi/rmi_state_info.h                |  115 +
 drivers/crypto/rmi/rmisec.c                        | 2400 +++++++++
 drivers/i2c/algos/Kconfig                          |    9 +
 drivers/i2c/algos/Makefile                         |    1 +
 drivers/i2c/algos/i2c-algo-palm.c                  |  325 ++
 drivers/i2c/algos/i2c-algo-palm.h                  |   58 +
 drivers/i2c/busses/Kconfig                         |   11 +
 drivers/i2c/busses/Makefile                        |    1 +
 drivers/i2c/busses/i2c-bk3220.c                    |  144 +
 drivers/i2c/chips/ds1374-rtc.c                     |  533 ++
 drivers/i2c/chips/max6602.c                        |  345 ++
 drivers/i2c/chips/max6657.c                        |  329 ++
 drivers/i2c/i2c-core.c                             |   23 +
 drivers/ide/Kconfig                                |    5 +
 drivers/ide/ide-dma-sff.c                          |   32 +
 drivers/ide/ide-io-std.c                           |   45 +
 drivers/ide/pdc202xx_new.c                         |   58 +
 drivers/ide/phoenix_ide.c                          |  526 ++
 drivers/mtd/maps/Kconfig                           |    6 +
 drivers/mtd/maps/Makefile                          |    1 +
 drivers/mtd/maps/xlr-flash.c                       |  100 +
 drivers/mtd/nand/nand_base.c                       |   22 +
 drivers/mtd/nand/xls_nand.c                        |  281 +
 drivers/mtd/nand/xls_nand.h                        |   41 +
 drivers/net/Kconfig                                |    6 +
 drivers/net/kgdboe.c                               |  220 +
 drivers/net/phoenix_mac.c                          | 4560 +++++++++++++++++
 drivers/net/phoenix_rmik.c                         |  706 +++
 drivers/net/phoenix_user_mac.c                     | 1212 +++++
 drivers/net/rmi_ptp1588/Makefile                   |    8 +
 drivers/net/rmi_ptp1588/ptp_common.h               |   35 +
 drivers/net/rmi_ptp1588/ptp_main.c                 |  358 ++
 drivers/net/rmi_ptp1588/ptp_mod.h                  |   33 +
 drivers/net/rmi_rionet.c                           |  615 +++
 drivers/net/rmi_spi4/Makefile                      |    9 +
 drivers/net/rmi_spi4/meigsii_reg.h                 |  463 ++
 drivers/net/rmi_spi4/os_layer.c                    |   97 +
 drivers/net/rmi_spi4/os_layer.h                    |   51 +
 drivers/net/rmi_spi4/rmi_spi4.c                    |  864 ++++
 drivers/net/rmi_spi4/rmi_spi4.h                    |  232 +
 drivers/net/rmi_spi4/rmi_spi4_config.h             |  141 +
 drivers/net/rmi_spi4/rmi_vits_driver.c             |  282 +
 drivers/net/rmi_spi4/rmi_vits_driver.h             |   52 +
 drivers/net/rmi_spi4/rmi_vits_eth.c                | 1225 +++++
 drivers/net/rmi_spi4/rmi_vits_eth.h                |  154 +
 drivers/net/rmi_spi4/rmi_vits_wrapper.c            |  103 +
 drivers/net/rmi_spi4/rmi_vits_wrapper.h            |   46 +
 drivers/net/rmi_spi4/vitesse_common.h              |  283 +
 drivers/net/rmi_spi4/vitesse_highlevel.c           | 5367 ++++++++++++++++++++
 drivers/net/rmi_spi4/vitesse_highlevel.h           | 1388 +++++
 drivers/net/rmi_spi4/vitesse_io.c                  |  233 +
 drivers/net/rmi_spi4/vitesse_io.h                  |   81 +
 drivers/net/rmi_spi4/vitesse_phy_ctrl.c            |  444 ++
 drivers/net/rmi_spi4/vitesse_phy_ctrl.h            |  296 ++
 drivers/net/rmi_vnet.c                             |  670 +++
 drivers/net/rmi_vnet.h                             |   90 +
 drivers/net/xlr_ip_over_pci_dev.c                  |  615 +++
 drivers/net/xlr_ip_over_pci_host.c                 |  708 +++
 drivers/net/xlr_pcix_boot.c                        |  335 ++
 drivers/oprofile/oprof.c                           |    7 +
 drivers/oprofile/oprofile_files.c                  |    4 +-
 drivers/pci/Makefile                               |    1 +
 drivers/pci/pci.h                                  |    2 +-
 drivers/pci/probe.c                                |   32 +
 drivers/pci/proc.c                                 |    8 +
 drivers/pci/quirks.c                               |    2 +-
 drivers/perfctr/Kconfig                            |   64 +
 drivers/perfctr/Makefile                           |   25 +
 drivers/perfctr/compat.h                           |   51 +
 drivers/perfctr/cpumask.h                          |   90 +
 drivers/perfctr/dummy-syscalls.c                   |   73 +
 drivers/perfctr/init.c                             |  198 +
 drivers/perfctr/mips.c                             |  838 +++
 drivers/perfctr/mips.h                             |   48 +
 drivers/perfctr/mips_tests.c                       |  221 +
 drivers/perfctr/mips_tests.h                       |   24 +
 drivers/perfctr/pmc.h                              |   38 +
 drivers/perfctr/version.h                          |   13 +
 drivers/perfctr/virtual.c                          | 1360 +++++
 drivers/perfctr/virtual.h                          |   25 +
 drivers/rapidio/switches/tsi578.c                  |   71 +
 drivers/usb/core/usb.c                             |   21 +
 drivers/usb/host/ehci-hcd.c                        |   28 +
 drivers/usb/host/ohci-hcd.c                        |   27 +
 drivers/watchdog/Kconfig                           |    8 +
 drivers/watchdog/phoenix_wdt.c                     |  301 ++
 fs/Makefile                                        |    1 +
 fs/coredump_elf.c                                  |  679 +++
 fs/dcookies.c                                      |   40 +
 include/asm-generic/kgdb.h                         |   46 +
 include/linux/crypto.h                             |    7 +
 include/linux/dwarf2-defs.h                        |  515 ++
 include/linux/dwarf2-lang.h                        |  312 ++
 include/linux/dwarf2.h                             |  787 +++
 include/linux/i2c-algo-palm.h                      |   53 +
 include/linux/i2c.h                                |   13 +
 include/linux/libata.h                             |    2 +-
 include/linux/linkage.h                            |    6 +-
 include/linux/memblk.h                             |   55 +
 include/linux/mm.h                                 |    5 +
 include/linux/mtd/map.h                            |   34 +
 include/linux/oprofile.h                           |    2 +
 include/linux/pci.h                                |   16 +-
 include/linux/perfctr.h                            |  202 +
 include/linux/phnx_tb.h                            |  172 +
 include/linux/serial_8250.h                        |   13 +
 include/linux/skbuff.h                             |    8 +
 include/linux/smp.h                                |    1 -
 include/linux/syscalls.h                           |   11 +
 include/user-mips/perfctr/unistd.h                 |   41 +
 include/user/rmi/phnx_loader.h                     |  153 +
 include/user/rmi/phnx_mmap.h                       |   43 +
 include/user/rmi/phnx_msgring.h                    |   56 +
 include/user/rmi/phnx_user_mac.h                   |  138 +
 init/Kconfig                                       |    4 +-
 init/main.c                                        |   13 +
 kernel/exit.c                                      |   19 +
 kernel/pid.c                                       |   24 +-
 kernel/ptrace.c                                    |    3 +-
 kernel/sys_ni.c                                    |    1 +
 kernel/timer.c                                     |   16 +
 mm/memory.c                                        |   67 +
 net/core/dev.c                                     |   25 +
 net/core/skbuff.c                                  |    5 +
 net/ipv4/af_inet.c                                 |    5 +-
 net/ipv4/netfilter/ip_queue.c                      |   60 +
 395 files changed, 85674 insertions(+), 156 deletions(-)
 create mode 100644 arch/mips/include/asm/mach-rmi/cpu-feature-overrides.h
 create mode 100644 arch/mips/include/asm/mach-rmi/kernel-entry-init.h
 create mode 100644 arch/mips/include/asm/mach-rmi/mmu.h
 create mode 100644 arch/mips/include/asm/mach-rmi/pgtable-xlp.h
 create mode 100644 arch/mips/include/asm/mach-rmi/pgwalker.h
 create mode 100644 arch/mips/include/asm/mach-rmi/spaces.h
 create mode 100644 arch/mips/include/asm/mach-rmi/war.h
 create mode 100644 arch/mips/include/asm/mach-rmi/xlp-mmu.h
 create mode 100644 arch/mips/include/asm/msi.h
 create mode 100644 arch/mips/include/asm/perfctr.h
 create mode 100644 arch/mips/include/asm/rio.h
 create mode 100644 arch/mips/include/asm/rmi/64bit.h
 create mode 100644 arch/mips/include/asm/rmi/atx_cpld.h
 create mode 100644 arch/mips/include/asm/rmi/config_net.h
 create mode 100644 arch/mips/include/asm/rmi/debug.h
 create mode 100644 arch/mips/include/asm/rmi/devices.h
 create mode 100644 arch/mips/include/asm/rmi/global_shmem.h
 create mode 100644 arch/mips/include/asm/rmi/gpio.h
 create mode 100644 arch/mips/include/asm/rmi/interrupt.h
 create mode 100644 arch/mips/include/asm/rmi/io.h
 create mode 100644 arch/mips/include/asm/rmi/iomap.h
 create mode 100644 arch/mips/include/asm/rmi/linux_crf.h
 create mode 100644 arch/mips/include/asm/rmi/memory-exclusion.h
 create mode 100644 arch/mips/include/asm/rmi/mips-exts.h
 create mode 100644 arch/mips/include/asm/rmi/msgring.h
 create mode 100644 arch/mips/include/asm/rmi/msidef.h
 create mode 100644 arch/mips/include/asm/rmi/pci.h
 create mode 100644 arch/mips/include/asm/rmi/perf_ctr.h
 create mode 100644 arch/mips/include/asm/rmi/phnx_cde.h
 create mode 100644 arch/mips/include/asm/rmi/phnx_loader.h
 create mode 100644 arch/mips/include/asm/rmi/phnx_tb.h
 create mode 100644 arch/mips/include/asm/rmi/phnx_user_mac.h
 create mode 100644 arch/mips/include/asm/rmi/phoenix_flash_pcmcia.h
 create mode 100644 arch/mips/include/asm/rmi/phoenix_ide.h
 create mode 100644 arch/mips/include/asm/rmi/phoenix_mac.h
 create mode 100644 arch/mips/include/asm/rmi/phoenix_rmios_debugger.h
 create mode 100644 arch/mips/include/asm/rmi/phoenix_sec.h
 create mode 100644 arch/mips/include/asm/rmi/phoenix_shim_drv.h
 create mode 100644 arch/mips/include/asm/rmi/phoenix_uart.h
 create mode 100644 arch/mips/include/asm/rmi/pic.h
 create mode 100644 arch/mips/include/asm/rmi/proc.h
 create mode 100644 arch/mips/include/asm/rmi/rmi_pcix_gen_dev.h
 create mode 100644 arch/mips/include/asm/rmi/rmi_pcix_gen_host.h
 create mode 100644 arch/mips/include/asm/rmi/rmi_rw_lock.h
 create mode 100644 arch/mips/include/asm/rmi/rmi_srio.h
 create mode 100644 arch/mips/include/asm/rmi/rmi_uaccess_fs.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/api.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/bootinfo.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/byteorder.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/clpool.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/config.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/crflib.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/errcode.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/eventdefs.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/frame.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/linux.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/oscalls.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/pcpu.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/rmios.h
 create mode 100644 arch/mips/include/asm/rmi/rmicrf/types.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/asm.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/atomic.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/bridge.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/flash.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/fmn.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/gpio.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/iomap.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/pic.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/platform.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/rmichip.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/uart.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/xlrcr.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/xlrextns.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/xlrio.h
 create mode 100644 arch/mips/include/asm/rmi/rmidev/xlrregs.h
 create mode 100644 arch/mips/include/asm/rmi/sim.h
 create mode 100644 arch/mips/include/asm/rmi/utils.h
 create mode 100644 arch/mips/include/asm/rmi/xgmac_mdio.h
 create mode 100644 arch/mips/include/asm/rmi/xlr_pcix_boot.h
 create mode 100644 arch/mips/include/asm/rmi/xlr_virt_uart.h
 create mode 100644 arch/mips/include/asm/xlr_macros.h
 create mode 100644 arch/mips/kernel/rio.c
 create mode 100644 arch/mips/kernel/xlr_fast_sys_call_handler.S
 create mode 100644 arch/mips/lib/csum_partial_rminas.S
 create mode 100644 arch/mips/mm/c-phoenix.c
 create mode 100644 arch/mips/mm/cerr-phoenix.c
 create mode 100644 arch/mips/mm/pg-phoenix.c
 create mode 100644 arch/mips/mm/tlb-phnx.c
 create mode 100644 arch/mips/mm/tlb-phoenix.c
 create mode 100644 arch/mips/oprofile/op_model_mips_xlr.c
 create mode 100644 arch/mips/pci/pci-phoenix.c
 create mode 100644 arch/mips/pci/pci-xlp.c
 create mode 100644 arch/mips/rmi/Kconfig
 create mode 100644 arch/mips/rmi/boot/Makefile
 create mode 100644 arch/mips/rmi/boot/Makefile.standalone
 create mode 100644 arch/mips/rmi/boot/boot.S
 create mode 100644 arch/mips/rmi/boot/bootloader.c
 create mode 100644 arch/mips/rmi/boot/bootloader.h
 create mode 100644 arch/mips/rmi/boot/ld.script.standalone
 create mode 100644 arch/mips/rmi/mm/Makefile
 create mode 100644 arch/mips/rmi/mm/memory.c
 create mode 100644 arch/mips/rmi/phoenix/Makefile.msgring
 create mode 100644 arch/mips/rmi/phoenix/Makefile.msgring.shared
 create mode 100644 arch/mips/rmi/phoenix/Makefile.msgring.xls
 create mode 100644 arch/mips/rmi/phoenix/cpu_proc.c
 create mode 100644 arch/mips/rmi/phoenix/dma.c
 create mode 100644 arch/mips/rmi/phoenix/irq.c
 create mode 100644 arch/mips/rmi/phoenix/msgring.cfg
 create mode 100644 arch/mips/rmi/phoenix/msgring.l
 create mode 100644 arch/mips/rmi/phoenix/msgring.y
 create mode 100644 arch/mips/rmi/phoenix/msgring_ike.cfg
 create mode 100644 arch/mips/rmi/phoenix/msgring_ike_xls.cfg
 create mode 100644 arch/mips/rmi/phoenix/msgring_openssl.cfg
 create mode 100644 arch/mips/rmi/phoenix/msgring_shared.cfg
 create mode 100644 arch/mips/rmi/phoenix/msgring_shared.l
 create mode 100644 arch/mips/rmi/phoenix/msgring_shared.y
 create mode 100644 arch/mips/rmi/phoenix/msgring_xls.cfg
 create mode 100644 arch/mips/rmi/phoenix/msgring_xls.l
 create mode 100644 arch/mips/rmi/phoenix/msgring_xls.y
 create mode 100644 arch/mips/rmi/phoenix/on_chip.c
 create mode 100644 arch/mips/rmi/phoenix/platform.c
 create mode 100644 arch/mips/rmi/phoenix/rmi_srio.c
 create mode 100644 arch/mips/rmi/phoenix/smp.c
 create mode 100644 arch/mips/rmi/phoenix/time.c
 create mode 100644 arch/mips/rmi/ptr/Makefile
 create mode 100644 arch/mips/rmi/ptr/config_net.c
 create mode 100644 arch/mips/rmi/ptr/dbg_io.c
 create mode 100644 arch/mips/rmi/ptr/loader/Makefile
 create mode 100644 arch/mips/rmi/ptr/loader/console.c
 create mode 100644 arch/mips/rmi/ptr/loader/entry.S
 create mode 100644 arch/mips/rmi/ptr/loader/fifo.h
 create mode 100644 arch/mips/rmi/ptr/loader/loader.c
 create mode 100644 arch/mips/rmi/ptr/loader/reload_irq_handler.S
 create mode 100644 arch/mips/rmi/ptr/loader/traps.c
 create mode 100644 arch/mips/rmi/ptr/loader/uart.c
 create mode 100644 arch/mips/rmi/ptr/loader/uart.h
 create mode 100644 arch/mips/rmi/ptr/loader/xlr_boot_lib.h
 create mode 100644 arch/mips/rmi/ptr/loader/xlr_lib_launch.c
 create mode 100644 arch/mips/rmi/ptr/loader/xlr_lib_platform.h
 create mode 100644 arch/mips/rmi/ptr/loader/xlr_rmios_stackframe.h
 create mode 100644 arch/mips/rmi/ptr/nmi.S
 create mode 100644 arch/mips/rmi/ptr/platform-xlp.c
 create mode 100644 arch/mips/rmi/ptr/platform.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/Makefile
 create mode 100644 arch/mips/rmi/ptr/rmicrf/Makefile.sync
 create mode 100644 arch/mips/rmi/ptr/rmicrf/clpool.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/dtb/Makefile
 create mode 100644 arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree.h
 create mode 100644 arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_env.h
 create mode 100644 arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_misc.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_utils.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/dtb/ops.h
 create mode 100644 arch/mips/rmi/ptr/rmicrf/dtb/page.h
 create mode 100644 arch/mips/rmi/ptr/rmicrf/dtb/simple_alloc.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/dtb/types.h
 create mode 100644 arch/mips/rmi/ptr/rmicrf/entry-linux.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/entry.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/event_handle.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/eventq.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/fifo.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/fmn.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/memcpy.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/mutex.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/processor.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/rmik_utils.c
 create mode 100644 arch/mips/rmi/ptr/rmicrf/utils.c
 create mode 100644 arch/mips/rmi/ptr/setup.c
 create mode 100644 arch/mips/rmi/ptr/smp.c
 create mode 100644 arch/mips/rmi/ptr/smpboot.S
 create mode 100644 arch/mips/rmi/xlp/Makefile
 create mode 100644 arch/mips/rmi/xlp/mmu.c
 create mode 100644 arch/mips/rmi/xlr/Makefile
 create mode 100644 arch/mips/rmi/xlr/mmu.c
 create mode 100644 crypto/phoenix_sec.c
 create mode 100644 drivers/block/sbull.c
 create mode 100644 drivers/char/hw_random/xlr-rng.c
 create mode 100644 drivers/char/phnx_cde.c
 create mode 100644 drivers/char/phnx_loader.c
 create mode 100644 drivers/char/phnx_msgring.c
 create mode 100644 drivers/char/phnx_msgring_debugger.c
 create mode 100644 drivers/char/phnx_tb.c
 create mode 100644 drivers/char/phoenix_rmios_debugger.c
 create mode 100644 drivers/char/rmi_pcix_gen_dev.c
 create mode 100644 drivers/char/rmi_pcix_gen_host.c
 create mode 100644 drivers/char/rmicrf/Makefile
 create mode 100644 drivers/char/rmicrf/crfdev.c
 create mode 100644 drivers/char/rmicrf/vuart.c
 create mode 100644 drivers/char/xlr_pcix_console_dev.c
 create mode 100644 drivers/char/xlr_pcix_console_host.c
 create mode 100644 drivers/char/xlr_virtual_uart.c
 create mode 100644 drivers/crypto/rmi/Makefile
 create mode 100644 drivers/crypto/rmi/ecc_ucode_data.h
 create mode 100644 drivers/crypto/rmi/rmi_auth.c
 create mode 100644 drivers/crypto/rmi/rmi_enc.c
 create mode 100644 drivers/crypto/rmi/rmi_state_info.h
 create mode 100644 drivers/crypto/rmi/rmisec.c
 create mode 100644 drivers/i2c/algos/i2c-algo-palm.c
 create mode 100644 drivers/i2c/algos/i2c-algo-palm.h
 create mode 100644 drivers/i2c/busses/i2c-bk3220.c
 create mode 100644 drivers/i2c/chips/ds1374-rtc.c
 create mode 100644 drivers/i2c/chips/max6602.c
 create mode 100644 drivers/i2c/chips/max6657.c
 create mode 100644 drivers/ide/phoenix_ide.c
 create mode 100644 drivers/mtd/maps/xlr-flash.c
 create mode 100644 drivers/mtd/nand/xls_nand.c
 create mode 100644 drivers/mtd/nand/xls_nand.h
 create mode 100644 drivers/net/kgdboe.c
 create mode 100644 drivers/net/phoenix_mac.c
 create mode 100644 drivers/net/phoenix_rmik.c
 create mode 100644 drivers/net/phoenix_user_mac.c
 create mode 100644 drivers/net/rmi_ptp1588/Makefile
 create mode 100644 drivers/net/rmi_ptp1588/ptp_common.h
 create mode 100644 drivers/net/rmi_ptp1588/ptp_main.c
 create mode 100644 drivers/net/rmi_ptp1588/ptp_mod.h
 create mode 100644 drivers/net/rmi_rionet.c
 create mode 100644 drivers/net/rmi_spi4/Makefile
 create mode 100644 drivers/net/rmi_spi4/meigsii_reg.h
 create mode 100644 drivers/net/rmi_spi4/os_layer.c
 create mode 100644 drivers/net/rmi_spi4/os_layer.h
 create mode 100644 drivers/net/rmi_spi4/rmi_spi4.c
 create mode 100644 drivers/net/rmi_spi4/rmi_spi4.h
 create mode 100644 drivers/net/rmi_spi4/rmi_spi4_config.h
 create mode 100644 drivers/net/rmi_spi4/rmi_vits_driver.c
 create mode 100644 drivers/net/rmi_spi4/rmi_vits_driver.h
 create mode 100644 drivers/net/rmi_spi4/rmi_vits_eth.c
 create mode 100644 drivers/net/rmi_spi4/rmi_vits_eth.h
 create mode 100644 drivers/net/rmi_spi4/rmi_vits_wrapper.c
 create mode 100644 drivers/net/rmi_spi4/rmi_vits_wrapper.h
 create mode 100644 drivers/net/rmi_spi4/vitesse_common.h
 create mode 100644 drivers/net/rmi_spi4/vitesse_highlevel.c
 create mode 100644 drivers/net/rmi_spi4/vitesse_highlevel.h
 create mode 100644 drivers/net/rmi_spi4/vitesse_io.c
 create mode 100644 drivers/net/rmi_spi4/vitesse_io.h
 create mode 100644 drivers/net/rmi_spi4/vitesse_phy_ctrl.c
 create mode 100644 drivers/net/rmi_spi4/vitesse_phy_ctrl.h
 create mode 100644 drivers/net/rmi_vnet.c
 create mode 100644 drivers/net/rmi_vnet.h
 create mode 100644 drivers/net/xlr_ip_over_pci_dev.c
 create mode 100644 drivers/net/xlr_ip_over_pci_host.c
 create mode 100644 drivers/net/xlr_pcix_boot.c
 create mode 100644 drivers/perfctr/Kconfig
 create mode 100644 drivers/perfctr/Makefile
 create mode 100644 drivers/perfctr/compat.h
 create mode 100644 drivers/perfctr/cpumask.h
 create mode 100644 drivers/perfctr/dummy-syscalls.c
 create mode 100644 drivers/perfctr/init.c
 create mode 100644 drivers/perfctr/mips.c
 create mode 100644 drivers/perfctr/mips.h
 create mode 100644 drivers/perfctr/mips_tests.c
 create mode 100644 drivers/perfctr/mips_tests.h
 create mode 100644 drivers/perfctr/pmc.h
 create mode 100644 drivers/perfctr/version.h
 create mode 100644 drivers/perfctr/virtual.c
 create mode 100644 drivers/perfctr/virtual.h
 create mode 100644 drivers/rapidio/switches/tsi578.c
 create mode 100644 drivers/watchdog/phoenix_wdt.c
 create mode 100644 fs/coredump_elf.c
 create mode 100644 include/asm-generic/kgdb.h
 create mode 100644 include/linux/dwarf2-defs.h
 create mode 100644 include/linux/dwarf2-lang.h
 create mode 100644 include/linux/dwarf2.h
 create mode 100644 include/linux/i2c-algo-palm.h
 create mode 100644 include/linux/memblk.h
 create mode 100644 include/linux/perfctr.h
 create mode 100644 include/linux/phnx_tb.h
 create mode 100644 include/user-mips/perfctr/unistd.h
 create mode 100644 include/user/rmi/phnx_loader.h
 create mode 100644 include/user/rmi/phnx_mmap.h
 create mode 100644 include/user/rmi/phnx_msgring.h
 create mode 100644 include/user/rmi/phnx_user_mac.h

diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig
index 60e3b02..be341ac 100644
--- a/arch/mips/Kconfig
+++ b/arch/mips/Kconfig
@@ -714,6 +714,33 @@ config WR_PPMC
 	  This enables support for the Wind River MIPS32 4KC PPMC evaluation
 	  board, which is based on GT64120 bridge chip.
 
+config RMI_PTR
+	bool "Support for RMI ATX board"
+	depends on EXPERIMENTAL
+	select SMP
+	select BOOT_ELF32
+	select RMI_PHOENIX
+	select RMI_XLR
+	select SYS_HAS_CPU_XLR
+	select SYS_SUPPORTS_SMP
+	select HW_HAS_PCI
+	select SWAP_IO_SPACE
+	select SYS_SUPPORTS_32BIT_KERNEL
+    	select SYS_SUPPORTS_64BIT_KERNEL
+	select 64BIT_PHYS_ADDR
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select DMA_COHERENT
+	select CEVT_R4K
+	select CSRC_R4K
+	select IRQ_CPU
+	select ZONE_DMA if 64BIT
+	select SYNC_R4K
+	select SYS_HAS_EARLY_PRINTK
+	help
+	  This board is based on RMI XLR processor. 
+	  Say Y here to support this machine type
+
 config CAVIUM_OCTEON_SIMULATOR
 	bool "Cavium Networks Octeon Simulator"
 	select CEVT_R4K
@@ -729,6 +756,34 @@ config CAVIUM_OCTEON_SIMULATOR
 	  Octeon Processor. It supports simulating Octeon processors on x86
 	  hardware.
 
+config RMI_XLP_SIM
+	bool "Support for RMI XLP Simulator"
+	depends on EXPERIMENTAL
+	select SMP
+	select BOOT_ELF32
+	select RMI_PHOENIX
+	select RMI_XLP
+	select SYS_HAS_CPU_XLP
+	select SYS_SUPPORTS_SMP
+	select HW_HAS_PCI
+	select SWAP_IO_SPACE
+	select SYS_SUPPORTS_32BIT_KERNEL
+    	select SYS_SUPPORTS_64BIT_KERNEL
+	select 64BIT_PHYS_ADDR
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_LITTLE_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select DMA_COHERENT
+	select CEVT_R4K
+	select CSRC_R4K
+	select IRQ_CPU
+	select ZONE_DMA if 64BIT
+	select SYNC_R4K
+	select SYS_HAS_EARLY_PRINTK
+	help
+	  This board is based on RMI XLP Processor.
+	  Say Y here to support this machine type
+
 config CAVIUM_OCTEON_REFERENCE_BOARD
 	bool "Cavium Networks Octeon reference board"
 	select CEVT_R4K
@@ -816,6 +871,15 @@ config NLM_XLP_BOARD
 
 endchoice
 
+config RAPIDIO
+	bool "RapidIO support"
+	depends on RMI_XLR
+	help
+	  If you say Y here, the kernel will include drivers and
+	  infrastructure code to support RapidIO interconnect devices.
+
+source "drivers/rapidio/Kconfig"
+
 source "arch/mips/alchemy/Kconfig"
 source "arch/mips/ath79/Kconfig"
 source "arch/mips/bcm47xx/Kconfig"
@@ -871,6 +935,11 @@ config SCHED_OMIT_FRAME_POINTER
 	bool
 	default y
 
+config GENERIC_HARDIRQS_NO__DO_IRQ
+# XLP_MERGE_TODO
+	default  n if RMI_PTR || RMI_XLP_SIM
+	def_bool y
+
 #
 # Select some configuration options automatically based on user selections.
 #
@@ -1625,6 +1694,9 @@ config SYS_HAS_CPU_RM9000
 config SYS_HAS_CPU_SB1
 	bool
 
+config SYS_HAS_CPU_PHOENIX
+	bool
+
 config SYS_HAS_CPU_CAVIUM_OCTEON
 	bool
 
@@ -1681,7 +1753,7 @@ config CPU_MIPSR1
 
 config CPU_MIPSR2
 	bool
-	default y if CPU_MIPS32_R2 || CPU_MIPS64_R2 || CPU_CAVIUM_OCTEON
+	default y if CPU_MIPS32_R2 || CPU_MIPS64_R2 || CPU_CAVIUM_OCTEON || CPU_XLP
 
 config SYS_SUPPORTS_32BIT_KERNEL
 	bool
@@ -1701,7 +1773,7 @@ config CPU_SUPPORTS_UNCACHED_ACCELERATED
 	bool
 config MIPS_PGD_C0_CONTEXT
 	bool
-	default y if 64BIT && CPU_MIPSR2
+	default y if 64BIT && CPU_MIPSR2 && !CPU_XLP
 
 #
 # Set to y for ptrace access to watch registers.
@@ -2013,7 +2085,9 @@ config SB1_PASS_2_1_WORKAROUNDS
 	default y
 
 config 64BIT_PHYS_ADDR
+	select PHYS_ADDR_T_64BIT
 	bool
+	default y
 
 config ARCH_PHYS_ADDR_T_64BIT
        def_bool 64BIT_PHYS_ADDR
diff --git a/arch/mips/Makefile b/arch/mips/Makefile
index 5c1e75d..a200909 100644
--- a/arch/mips/Makefile
+++ b/arch/mips/Makefile
@@ -42,6 +42,10 @@ tool-archpref		= $(64bit-tool-archpref)
 UTS_MACHINE		:= mips64
 endif
 
+ifdef CONFIG_CROSSCOMPILE
+CROSS_COMPILE		:= $(tool-archpref)
+endif
+
 ifneq ($(SUBARCH),$(ARCH))
   ifeq ($(CROSS_COMPILE),)
     CROSS_COMPILE := $(call cc-cross-prefix, $(tool-archpref)-linux-  $(tool-archpref)-linux-gnu-  $(tool-archpref)-unknown-linux-gnu-)
@@ -90,8 +94,12 @@ all-$(CONFIG_SYS_SUPPORTS_ZBOOT)+= vmlinuz
 cflags-y			+= -G 0 -mno-abicalls -fno-pic -pipe
 cflags-y			+= -msoft-float
 LDFLAGS_vmlinux			+= -G 0 -static -n -nostdlib
+
+ifndef CONFIG_MAPPED_KERNEL
+MODFLAGS			+= -mlong-calls
 KBUILD_AFLAGS_MODULE		+= -mlong-calls
 KBUILD_CFLAGS_MODULE		+= -mlong-calls
+endif
 
 cflags-y += -ffreestanding
 
@@ -159,6 +167,8 @@ endif
 cflags-$(CONFIG_CAVIUM_CN63XXP1) += -Wa,-mfix-cn63xxp1
 cflags-$(CONFIG_CPU_BMIPS)	+= -march=mips32 -Wa,-mips32 -Wa,--trap
 
+cflags-$(CONFIG_CPU_XLR)    += $(call cc-option,-march=xlr) -Wa,--trap
+cflags-$(CONFIG_CPU_XLP)    += $(call cc-option,-march=xlp) -Wa,--trap
 cflags-$(CONFIG_CPU_R4000_WORKAROUNDS)	+= $(call cc-option,-mfix-r4000,)
 cflags-$(CONFIG_CPU_R4400_WORKAROUNDS)	+= $(call cc-option,-mfix-r4400,)
 cflags-$(CONFIG_CPU_DADDI_WORKAROUNDS)	+= $(call cc-option,-mno-daddi,)
@@ -192,7 +202,38 @@ endif
 #
 include $(srctree)/arch/mips/Kbuild.platforms
 
-cflags-y			+= -I$(srctree)/arch/mips/include/asm/mach-generic
+#
+# RMI SOC Common (phoenix)
+core-$(CONFIG_RMI_PHOENIX)      	+= arch/mips/rmi/phoenix/
+core-$(CONFIG_RMI_PHOENIX) 		+= arch/mips/rmi/mm/
+cflags-$(CONFIG_RMI_PHOENIX)    	+= -DXLS -I$(srctree)/arch/mips/include/asm/mach-rmi
+cflags-$(CONFIG_RMI_PHOENIX)    	+= -I$(srctree)/arch/mips/include/asm/rmi
+
+#
+# RMI XLR/XLS SoC, Simulator and boards
+#
+core-$(CONFIG_RMI_XLR)      		+= arch/mips/rmi/xlr/
+core-$(CONFIG_RMI_PTR) 		+= arch/mips/rmi/ptr/
+cflags-$(CONFIG_CRYPTO_XLR)		+= -Idrivers/crypto/rmi/common
+cflags-$(CONFIG_RMI_XLR)    		+= -DRMI_BRIDGE_WKAROUND
+# This address is now configured via kernel configuration file
+load-$(CONFIG_RMI_PTR)          	+= $(CONFIG_RMI_PHOENIX_LOAD_ADDRESS)
+
+#
+# RMI XLP Soc, Simulator and boards
+#
+core-$(CONFIG_RMI_XLP) 		+= arch/mips/rmi/xlp/
+core-$(CONFIG_RMI_XLP_SIM)          	+= arch/mips/rmi/ptr/
+cflags-$(CONFIG_RMI_XLP_SIM)        	+= -DXLP_SIM=1
+cflags-$(CONFIG_RMI_XLP)    		+= -DXLS -I$(srctree)/arch/mips/include/asm/rmi/xlp_common/
+# This address is now configured via kernel configuration file
+load-$(CONFIG_RMI_XLP_SIM)      += $(CONFIG_RMI_PHOENIX_LOAD_ADDRESS)
+
+#
+# Generic MIPS headers
+#
+cflags-y                        += -I$(srctree)/arch/mips/include/asm/mach-generic
+
 drivers-$(CONFIG_PCI)		+= arch/mips/pci/
 
 #
@@ -224,6 +265,12 @@ KBUILD_CPPFLAGS += -D"DATAOFFSET=$(if $(dataoffset-y),$(dataoffset-y),0)"
 
 LDFLAGS			+= -m $(ld-emul)
 
+ifdef CONFIG_CPU_LITTLE_ENDIAN
+AFLAGS += -EL
+CFLAGS += -EL
+LDFLAGS += -EL
+endif
+
 ifdef CONFIG_MIPS
 CHECKFLAGS += $(shell $(CC) $(KBUILD_CFLAGS) -dM -E -x c /dev/null | \
 	egrep -vw '__GNUC_(|MINOR_|PATCHLEVEL_)_' | \
@@ -235,6 +282,27 @@ endif
 
 OBJCOPYFLAGS		+= --remove-section=.reginfo
 
+ifdef CONFIG_MAPPED_KERNEL
+PHYS_LOAD_ADDRESS = -D"PHYSADDR=$(CONFIG_PHYS_LOAD_ADDRESS)"
+endif
+
+#
+# Choosing incompatible machines durings configuration will result in
+# error messages during linking.  Select a default linkscript if
+# none has been choosen above.
+#
+
+
+CPPFLAGS_vmlinux.lds := \
+	$(CFLAGS) \
+	-D"LOADADDR=$(load-y)" $(PHYS_LOAD_ADDRESS) \
+	-D"JIFFIES=$(JIFFIES)" \
+	-D"DATAOFFSET=$(if $(dataoffset-y),$(dataoffset-y),0)"
+
+ifdef CONFIG_MAPPED_KERNEL
+KBUILD_CFLAGS += -D"LOADADDR=$(load-y)" $(PHYS_LOAD_ADDRESS)
+endif
+
 head-y := arch/mips/kernel/head.o arch/mips/kernel/init_task.o
 
 libs-y			+= arch/mips/lib/
diff --git a/arch/mips/include/asm/abi.h b/arch/mips/include/asm/abi.h
index 9252d9b..ae3dfd1 100644
--- a/arch/mips/include/asm/abi.h
+++ b/arch/mips/include/asm/abi.h
@@ -22,6 +22,7 @@ struct mips_abi {
 	                       sigset_t *set, siginfo_t *info);
 	const unsigned long	rt_signal_return_offset;
 	const unsigned long	restart;
+	int (* uses_siginfo)(struct k_sigaction *ka);
 };
 
 #endif /* _ASM_ABI_H */
diff --git a/arch/mips/include/asm/addrspace.h b/arch/mips/include/asm/addrspace.h
index 569f80a..7cf85bd 100644
--- a/arch/mips/include/asm/addrspace.h
+++ b/arch/mips/include/asm/addrspace.h
@@ -134,7 +134,11 @@
  * the region, 3 bits for the CCA mode.  This leaves 59 bits of which the
  * R8000 implements most with its 48-bit physical address space.
  */
+#if defined(CONFIG_CPU_XLR) || defined(CONFIG_CPU_XLP)
+#define TO_PHYS_MASK	_CONST64_(0x000000ffffffffff)	/* 2^^40 - 1 */
+#else
 #define TO_PHYS_MASK	_CONST64_(0x07ffffffffffffff)	/* 2^^59 - 1 */
+#endif
 
 #ifndef CONFIG_CPU_R8000
 
diff --git a/arch/mips/include/asm/asmmacro.h b/arch/mips/include/asm/asmmacro.h
index 6c8342a..3d41593 100644
--- a/arch/mips/include/asm/asmmacro.h
+++ b/arch/mips/include/asm/asmmacro.h
@@ -20,6 +20,27 @@
 #include <asm/mipsmtregs.h>
 #endif
 
+#ifdef CONFIG_PREEMPT
+
+.macro __preempt_disable
+lw  t0, TI_PRE_COUNT($28);
+addiu t0, 1;
+sw t0, TI_PRE_COUNT($28);
+.endm
+
+	.macro __preempt_enable
+lw  t0, TI_PRE_COUNT($28)
+	subu t0, 1
+sw t0, TI_PRE_COUNT($28)
+	.endm
+
+#else
+
+#define __preempt_disable
+#define __preempt_enable
+
+#endif
+
 #ifdef CONFIG_MIPS_MT_SMTC
 	.macro	local_irq_enable reg=t0
 	mfc0	\reg, CP0_TCSTATUS
@@ -47,17 +68,21 @@
 	.endm
 #else
 	.macro	local_irq_enable reg=t0
+	__preempt_disable
 	mfc0	\reg, CP0_STATUS
 	ori	\reg, \reg, 1
 	mtc0	\reg, CP0_STATUS
+	__preempt_enable
 	irq_enable_hazard
 	.endm
 
 	.macro	local_irq_disable reg=t0
+	__preempt_disable
 	mfc0	\reg, CP0_STATUS
 	ori	\reg, \reg, 1
 	xori	\reg, \reg, 1
 	mtc0	\reg, CP0_STATUS
+	__preempt_enable
 	irq_disable_hazard
 	.endm
 #endif /* CONFIG_MIPS_MT_SMTC */
diff --git a/arch/mips/include/asm/atomic.h b/arch/mips/include/asm/atomic.h
index 3f4c5cb..c387c16 100644
--- a/arch/mips/include/asm/atomic.h
+++ b/arch/mips/include/asm/atomic.h
@@ -49,6 +49,9 @@
  */
 static __inline__ void atomic_add(int i, atomic_t * v)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	ldadd_w_no_read(i, &v->counter);
+#else
 	if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
@@ -81,6 +84,7 @@ static __inline__ void atomic_add(int i, atomic_t * v)
 		v->counter += i;
 		raw_local_irq_restore(flags);
 	}
+#endif
 }
 
 /*
@@ -92,6 +96,9 @@ static __inline__ void atomic_add(int i, atomic_t * v)
  */
 static __inline__ void atomic_sub(int i, atomic_t * v)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	ldadd_w_no_read(-i,&v->counter);
+#else
 	if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
@@ -124,6 +131,7 @@ static __inline__ void atomic_sub(int i, atomic_t * v)
 		v->counter -= i;
 		raw_local_irq_restore(flags);
 	}
+#endif
 }
 
 /*
@@ -135,6 +143,10 @@ static __inline__ int atomic_add_return(int i, atomic_t * v)
 
 	smp_mb__before_llsc();
 
+#ifdef CONFIG_RMI_PHOENIX
+	result = ldadd_w(i, &v->counter);
+	result += i;
+#else
 	if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
@@ -174,6 +186,7 @@ static __inline__ int atomic_add_return(int i, atomic_t * v)
 		v->counter = result;
 		raw_local_irq_restore(flags);
 	}
+#endif
 
 	smp_llsc_mb();
 
@@ -186,6 +199,10 @@ static __inline__ int atomic_sub_return(int i, atomic_t * v)
 
 	smp_mb__before_llsc();
 
+#ifdef CONFIG_RMI_PHOENIX
+	result = ldadd_w(-i, &v->counter);
+	result -= i;
+#else
 	if (kernel_uses_llsc && R10000_LLSC_WAR) {
 		int temp;
 
@@ -227,6 +244,7 @@ static __inline__ int atomic_sub_return(int i, atomic_t * v)
 		v->counter = result;
 		raw_local_irq_restore(flags);
 	}
+#endif
 
 	smp_llsc_mb();
 
diff --git a/arch/mips/include/asm/bitops.h b/arch/mips/include/asm/bitops.h
index 2e1ad4c..9efca72 100644
--- a/arch/mips/include/asm/bitops.h
+++ b/arch/mips/include/asm/bitops.h
@@ -615,6 +615,14 @@ static inline unsigned long __ffs(unsigned long word)
 static inline int fls(int x)
 {
 	int r;
+#if defined(CONFIG_CPU_XLR) || defined(CONFIG_CPU_XLP)
+	__asm__("       .set push                       \n"
+		"       .set mips32                     \n"
+		"       clz %0, %1                      \n"
+		"       .set pop                        \n"
+		: "=r" (x) : "r" (x));
+	return 32 - x;
+#endif
 
 	if (__builtin_constant_p(cpu_has_clo_clz) && cpu_has_clo_clz) {
 		__asm__("clz %0, %1" : "=r" (x) : "r" (x));
@@ -648,7 +656,19 @@ static inline int fls(int x)
 	return r;
 }
 
+#if defined(CONFIG_64BIT) && (defined(CONFIG_CPU_XLR) || defined(CONFIG_CPU_XLP))
+static __always_inline int fls64(__u64 word)
+{
+	__asm__("       .set push               \n"
+		"       .set mips64             \n"
+		"       dclz %0, %1             \n"
+		"       .set pop                \n"
+		: "=r" (word) : "r" (word));
+	return 64 - word;
+}
+#else
 #include <asm-generic/bitops/fls64.h>
+#endif
 
 /*
  * ffs - find first bit set.
diff --git a/arch/mips/include/asm/bootinfo.h b/arch/mips/include/asm/bootinfo.h
index 7a51d87..5f35b7f 100644
--- a/arch/mips/include/asm/bootinfo.h
+++ b/arch/mips/include/asm/bootinfo.h
@@ -1,3 +1,14 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file COPYING in the main directory of this archive
@@ -58,6 +69,9 @@
 #define	MACH_MIKROTIK_RB532	0	/* Mikrotik RouterBoard 532 	*/
 #define MACH_MIKROTIK_RB532A	1	/* Mikrotik RouterBoard 532A 	*/
 
+#define MACH_GROUP_RMI         23
+#define MACH_PTR                0
+
 /*
  * Valid machtype for Loongson family
  */
@@ -77,6 +91,12 @@
 #define  MACH_INGENIC_JZ4730	0	/* JZ4730 SOC		*/
 #define  MACH_INGENIC_JZ4740	1	/* JZ4740 SOC		*/
 
+#ifdef CONFIG_RMI_PHOENIX
+#define CL_SIZE			(2048)
+#else
+#define CL_SIZE			COMMAND_LINE_SIZE
+#endif
+
 extern char *system_type;
 const char *get_system_type(void);
 
@@ -95,15 +115,15 @@ extern unsigned long mips_machtype;
 struct boot_mem_map {
 	int nr_map;
 	struct boot_mem_map_entry {
-		phys_t addr;	/* start of memory segment */
-		phys_t size;	/* size of memory segment */
-		long type;		/* type of memory segment */
+		uint64_t addr;	/* start of memory segment */
+		uint64_t size;	/* size of memory segment */
+		uint32_t type;		/* type of memory segment */
 	} map[BOOT_MEM_MAP_MAX];
 };
 
 extern struct boot_mem_map boot_mem_map;
 
-extern void add_memory_region(phys_t start, phys_t size, long type);
+extern void add_memory_region(uint64_t start, uint64_t size, long type);
 
 extern void prom_init(void);
 extern void prom_free_prom_memory(void);
@@ -138,4 +158,10 @@ static inline void plat_swiotlb_setup(void) {}
 
 #endif /* CONFIG_SWIOTLB */
 
+#define MAX_EXCLUDE 16
+struct boot_mem_map_exclude_region {
+	uint64_t start;
+	uint64_t end;
+};
+
 #endif /* _ASM_BOOTINFO_H */
diff --git a/arch/mips/include/asm/cacheflush.h b/arch/mips/include/asm/cacheflush.h
index 69468de..541b6f5 100644
--- a/arch/mips/include/asm/cacheflush.h
+++ b/arch/mips/include/asm/cacheflush.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -41,9 +53,13 @@ extern void __flush_dcache_page(struct page *page);
 #define ARCH_IMPLEMENTS_FLUSH_DCACHE_PAGE 1
 static inline void flush_dcache_page(struct page *page)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	extern void phoenix_flush_dcache_page(struct page *page);
+	phoenix_flush_dcache_page(page);
+#else
 	if (cpu_has_dc_aliases || !cpu_has_ic_fills_f_dc)
 		__flush_dcache_page(page);
-
+#endif
 }
 
 #define flush_dcache_mmap_lock(mapping)		do { } while (0)
@@ -107,6 +123,10 @@ extern void (*flush_data_cache_page)(unsigned long addr);
 	set_bit(PG_dcache_dirty, &(page)->flags)
 #define ClearPageDcacheDirty(page)	\
 	clear_bit(PG_dcache_dirty, &(page)->flags)
+#ifdef CONFIG_RMI_PHOENIX
+#define TestPageDcacheDirty(page)	\
+	test_bit(PG_dcache_dirty, &(page)->flags)
+#endif
 
 /* Run kernel code uncached, useful for cache probing functions. */
 unsigned long run_uncached(void *func);
diff --git a/arch/mips/include/asm/cpu-features.h b/arch/mips/include/asm/cpu-features.h
index ca400f7..4dd7cef 100644
--- a/arch/mips/include/asm/cpu-features.h
+++ b/arch/mips/include/asm/cpu-features.h
@@ -41,6 +41,9 @@
 #ifndef cpu_has_octeon_cache
 #define cpu_has_octeon_cache	0
 #endif
+#ifndef cpu_has_phoenix_cache
+#define cpu_has_phoenix_cache  (cpu_data[0].options & MIPS_CPU_PHOENIX_CACHE)
+#endif
 #ifndef cpu_has_fpu
 #define cpu_has_fpu		(current_cpu_data.options & MIPS_CPU_FPU)
 #define raw_cpu_has_fpu		(raw_current_cpu_data.options & MIPS_CPU_FPU)
diff --git a/arch/mips/include/asm/cpu.h b/arch/mips/include/asm/cpu.h
index 5026a1e..77364cc 100644
--- a/arch/mips/include/asm/cpu.h
+++ b/arch/mips/include/asm/cpu.h
@@ -318,6 +318,7 @@ enum cpu_type_enum {
 #define MIPS_CPU_VINT		0x00080000 /* CPU supports MIPSR2 vectored interrupts */
 #define MIPS_CPU_VEIC		0x00100000 /* CPU supports MIPSR2 external interrupt controller mode */
 #define MIPS_CPU_ULRI		0x00200000 /* CPU has ULRI feature */
+#define MIPS_CPU_PHOENIX_CACHE	0x00400000 
 
 /*
  * CPU ASE encodings
diff --git a/arch/mips/include/asm/dma.h b/arch/mips/include/asm/dma.h
index f5097f6..f482a6a 100644
--- a/arch/mips/include/asm/dma.h
+++ b/arch/mips/include/asm/dma.h
@@ -87,8 +87,12 @@
 /* don't care; ISA bus master won't work, ISA slave DMA supports 32bit addr */
 #define MAX_DMA_ADDRESS		PAGE_OFFSET
 #else
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+#define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x80000000)
+#else
 #define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x01000000)
 #endif
+#endif
 #define MAX_DMA_PFN		PFN_DOWN(virt_to_phys((void *)MAX_DMA_ADDRESS))
 
 #ifndef MAX_DMA32_PFN
diff --git a/arch/mips/include/asm/hazards.h b/arch/mips/include/asm/hazards.h
index b4c20e4..dde182b 100644
--- a/arch/mips/include/asm/hazards.h
+++ b/arch/mips/include/asm/hazards.h
@@ -235,6 +235,8 @@ ASMMACRO(irq_disable_hazard,
 ASMMACRO(back_to_back_c0_hazard,
 	 _ssnop; _ssnop; _ssnop;
 	)
+ASMMACRO(tlbw_eret_hazard,
+	)
 #define instruction_hazard() do { } while (0)
 
 #endif
diff --git a/arch/mips/include/asm/irqflags.h b/arch/mips/include/asm/irqflags.h
index 309cbcd..33b1a0e 100644
--- a/arch/mips/include/asm/irqflags.h
+++ b/arch/mips/include/asm/irqflags.h
@@ -15,6 +15,32 @@
 
 #include <linux/compiler.h>
 #include <asm/hazards.h>
+#include <asm/mipsregs.h>
+
+#ifdef CONFIG_64BIT
+#define TI_PREEMPT_COUNT 36
+#else
+#define TI_PREEMPT_COUNT 20
+#endif
+
+#ifdef CONFIG_PREEMPT
+
+#define __preempt_disable \
+	"lw  $1, "STR(TI_PREEMPT_COUNT)"($28) \n" \
+	"addiu $1, 1 \n" \
+	"sw $1, "STR(TI_PREEMPT_COUNT)"($28) \n"
+
+#define __preempt_enable \
+	"lw  $1, "STR(TI_PREEMPT_COUNT)"($28) \n" \
+	"subu $1, 1 \n" \
+	"sw $1, "STR(TI_PREEMPT_COUNT)"($28) \n"
+
+#else
+
+#define __preempt_disable
+#define __preempt_enable
+
+#endif
 
 __asm__(
 	"	.macro	arch_local_irq_enable				\n"
@@ -29,10 +55,12 @@ __asm__(
 #elif defined(CONFIG_CPU_MIPSR2)
 	"	ei							\n"
 #else
+	__preempt_disable
 	"	mfc0	$1,$12						\n"
 	"	ori	$1,0x1f						\n"
 	"	xori	$1,0x1e						\n"
 	"	mtc0	$1,$12						\n"
+	__preempt_enable
 #endif
 	"	irq_enable_hazard					\n"
 	"	.set	pop						\n"
@@ -87,11 +115,13 @@ __asm__(
 #elif defined(CONFIG_CPU_MIPSR2)
 	"	di							\n"
 #else
+	__preempt_disable
 	"	mfc0	$1,$12						\n"
 	"	ori	$1,0x1f						\n"
 	"	xori	$1,0x1f						\n"
 	"	.set	noreorder					\n"
 	"	mtc0	$1,$12						\n"
+	__preempt_enable
 #endif
 	"	irq_disable_hazard					\n"
 	"	.set	pop						\n"
@@ -140,11 +170,13 @@ __asm__(
 	"	di	\\result					\n"
 	"	andi	\\result, 1					\n"
 #else
+	__preempt_disable
 	"	mfc0	\\result, $12					\n"
 	"	ori	$1, \\result, 0x1f				\n"
 	"	xori	$1, 0x1f					\n"
 	"	.set	noreorder					\n"
 	"	mtc0	$1, $12						\n"
+	__preempt_enable
 #endif
 	"	irq_disable_hazard					\n"
 	"	.set	pop						\n"
@@ -189,12 +221,14 @@ __asm__(
 	"	ins	$1, \\flags, 0, 1				\n"
 	"	mtc0	$1, $12						\n"
 #else
+	__preempt_disable
 	"	mfc0	$1, $12						\n"
 	"	andi	\\flags, 1					\n"
 	"	ori	$1, 0x1f					\n"
 	"	xori	$1, 0x1f					\n"
 	"	or	\\flags, $1					\n"
 	"	mtc0	\\flags, $12					\n"
+	__preempt_enable
 #endif
 	"	irq_disable_hazard					\n"
 	"	.set	pop						\n"
diff --git a/arch/mips/include/asm/mach-generic/spaces.h b/arch/mips/include/asm/mach-generic/spaces.h
index d7a9efd..c71f674 100644
--- a/arch/mips/include/asm/mach-generic/spaces.h
+++ b/arch/mips/include/asm/mach-generic/spaces.h
@@ -41,11 +41,25 @@
 #ifdef CONFIG_64BIT
 
 #ifndef CAC_BASE
+
 #ifdef CONFIG_DMA_NONCOHERENT
-#define CAC_BASE		_AC(0x9800000000000000, UL)
+#define CAC_BASE                _AC(0x9800000000000000, UL)
+#else /* !CONFIG_DMA_NONCOHERENT */
+
+#if defined(CONFIG_MAPPED_KERNEL) && defined(CONFIG_KSEG2_LOWMEM)
+#define CAC_BASE                XKSEG
+#else /* !CONFIG_MAPPED_KERNEL */
+#define CAC_BASE                _AC(0xa800000000000000, UL)
+#endif /* CONFIG_MAPPED_KERNEL */
+
+#endif /* CONFIG_DMA_NONCOHERENT */
+
+#endif /* CAC_BASE */
+
+#if defined(CONFIG_MAPPED_KERNEL)  && defined(CONFIG_KSEG2_LOWMEM)
+#define PAGE_OFFSET	XKSEG
 #else
-#define CAC_BASE		_AC(0xa800000000000000, UL)
-#endif
+#define PAGE_OFFSET	_AC(0xa800000000000000, UL)
 #endif
 
 #ifndef IO_BASE
diff --git a/arch/mips/include/asm/mach-rmi/cpu-feature-overrides.h b/arch/mips/include/asm/mach-rmi/cpu-feature-overrides.h
new file mode 100644
index 0000000..2178ae8
--- /dev/null
+++ b/arch/mips/include/asm/mach-rmi/cpu-feature-overrides.h
@@ -0,0 +1,7 @@
+
+#ifndef __ASM_MACH_RMI_CPU_FEATURE_OVERRIDES_H
+#define __ASM_MACH_RMI_CPU_FEATURE_OVERRIDES_H
+
+#define kernel_uses_smartmips_rixi (cpu_data[0].cputype == CPU_XLP)
+
+#endif  /* __ASM_MACH_RMI_CPU_FEATURE_OVERRIDES_H */
diff --git a/arch/mips/include/asm/mach-rmi/kernel-entry-init.h b/arch/mips/include/asm/mach-rmi/kernel-entry-init.h
new file mode 100644
index 0000000..d9991f7
--- /dev/null
+++ b/arch/mips/include/asm/mach-rmi/kernel-entry-init.h
@@ -0,0 +1,57 @@
+#ifndef __ASM_MACH_RMI_KERNEL_ENTRY_H
+#define __ASM_MACH_RMI_KERNEL_ENTRY_H
+
+/* XLP_MERGE_TODO */
+#if !defined(CKSSEG)
+#define CKSSEG			0xffffffffc0000000
+#endif
+
+#ifdef CONFIG_64BIT
+#define LA dla
+#define MTC0 dmtc0
+#define SW sd
+#else
+#define LA la
+#define MTC0 mtc0
+#define SW sw
+#endif
+
+#ifdef CONFIG_CPU_XLP
+#define JRHB jr.hb 
+#define EHB ehb
+#else
+#define JRHB jr
+#define EHB 
+#endif
+
+	/*
+	 * inputs are the text nasid in t1, data nasid in t2.
+	 */
+	.macro MAPPED_KERNEL_SETUP_TLB
+#ifdef CONFIG_MAPPED_KERNEL
+	/*
+	 * Drop in 0xffffffffc0000000 in tlbhi, 0+VG in tlblo_0,
+	 * 0+DVG in tlblo_1.
+	 */
+	dli	    t3, CKSSEG
+	dmtc0	t3, CP0_ENTRYHI
+	li      t1, 0x1f
+	MTC0	t1, CP0_ENTRYLO0	# physaddr, VG, cach exlwr
+	li	    t2, 0x1
+	MTC0	t2, CP0_ENTRYLO1	# physaddr, DVG, cach exlwr
+	li	    t1, 0x1fffe000		# MAPPED_KERN_TLBMASK, TLBPGMASK_256M
+	mtc0	t1, CP0_PAGEMASK
+    mtc0    zero, CP0_INDEX
+	tlbwi
+	li      t0, 1
+    mtc0	t0, CP0_WIRED
+	EHB
+    LA      v0, mapped_space
+	JRHB    v0
+mapped_space:
+#else
+	mtc0	zero, CP0_WIRED
+#endif
+	.endm
+
+#endif /* __ASM_MACH_RMI_KERNEL_ENTRY_H */
diff --git a/arch/mips/include/asm/mach-rmi/mmu.h b/arch/mips/include/asm/mach-rmi/mmu.h
new file mode 100644
index 0000000..302e073
--- /dev/null
+++ b/arch/mips/include/asm/mach-rmi/mmu.h
@@ -0,0 +1,64 @@
+#ifndef _ASM_MACH_RMI_MMU_H
+#define _ASM_MACH_RMI_MMU_H
+
+#include <linux/smp.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/page.h>
+#include <asm/pgtable-bits.h>
+
+#ifdef CONFIG_RMI_XLP
+#include <asm/mach-rmi/xlp-mmu.h>
+#endif
+
+#define ENTRYLO_PFN_SHIFT 6
+
+#ifndef __ASSEMBLY__
+
+#define SMALLEST_TLBPAGE_SZ (4UL << 10)
+#define LARGEST_TLBPAGE_SZ  (256UL << 20)
+
+#define TRUE 1
+#define FALSE 0
+
+typedef struct
+{
+	unsigned long vaddr;
+	uint64_t paddr0;
+	uint64_t paddr1;
+	uint32_t pagesize;
+	uint32_t attr0;
+	uint32_t attr1;
+	int wired;
+} tlb_info_t;
+
+#ifdef CONFIG_MAPPED_KERNEL
+extern unsigned long __vmalloc_start;
+#endif
+extern unsigned long long phnx_tlb_stats[];
+
+extern void mmu_init(void);
+extern void setup_tlb(tlb_info_t *tlb);
+
+/*
+ * the following needs an used argument to confirm to the 
+ * prototype of functions passed to on_each_cpu()
+ */
+static inline void rmi_update_tlb_stats(void *arg)
+{
+	phnx_tlb_stats[smp_processor_id()] = rmi_read_os_scratch_2();
+}
+
+#define tlbstats_init() rmi_write_os_scratch_2(0ULL)
+
+#ifdef CONFIG_HUGETLBFS
+#define entrylo0_mask_init() \
+rmi_write_os_scratch_3(~(((1ULL << HUGETLB_PAGE_ORDER) - 1) << ENTRYLO_PFN_SHIFT))
+#else
+#define entrylo0_mask_init()
+#endif
+
+extern void setup_mapped_kernel_tlbs(int index, int secondary_cpu);
+extern unsigned long recalculate_max_low_pfn(unsigned long max_low_pfn);
+
+#endif /* __ASSEMBLY__ */
+#endif
diff --git a/arch/mips/include/asm/mach-rmi/pgtable-xlp.h b/arch/mips/include/asm/mach-rmi/pgtable-xlp.h
new file mode 100644
index 0000000..0f1f006
--- /dev/null
+++ b/arch/mips/include/asm/mach-rmi/pgtable-xlp.h
@@ -0,0 +1,59 @@
+#ifndef _ASM_MACH_RMI_PGTABLE_BITS_XLP_H
+#define _ASM_MACH_RMI_PGTABLE_BITS_XLP_H
+
+#define PAGE_NONE        __pgprot(_PAGE_PRESENT | \
+                                  _PAGE_RI | _PAGE_XI | \
+                                  _CACHE_CACHABLE_NONCOHERENT)
+#define PAGE_READONLY    __pgprot(_PAGE_PRESENT | _PAGE_READ | \
+                                  _PAGE_XI | \
+                                   PAGE_CACHABLE_DEFAULT)
+#define PAGE_WRITEONLY   __pgprot(_PAGE_PRESENT | _PAGE_READ | _PAGE_WRITE | \
+                                  _PAGE_RI | _PAGE_XI | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_WRITE_READ  __pgprot(_PAGE_PRESENT | _PAGE_READ | _PAGE_WRITE | \
+                                  _PAGE_XI | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_EXECONLY    __pgprot(_PAGE_PRESENT | _PAGE_READ | \
+                                  _PAGE_RI | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_EXEC_READ   __pgprot(_PAGE_PRESENT | _PAGE_READ | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_EXEC_WRITE  __pgprot(_PAGE_PRESENT | _PAGE_READ | _PAGE_WRITE | \
+                                  _PAGE_RI | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_ALL         __pgprot(_PAGE_PRESENT | _PAGE_READ | _PAGE_WRITE | \
+                                  PAGE_CACHABLE_DEFAULT)
+#define PAGE_COPY        __pgprot(_PAGE_PRESENT | _PAGE_READ | \
+                                  _PAGE_RI | _PAGE_XI | \
+                                   PAGE_CACHABLE_DEFAULT)
+
+#define PAGE_COPY_READ      PAGE_READONLY
+#define PAGE_EXEC_COPY      PAGE_EXECONLY
+#define PAGE_EXEC_COPY_READ PAGE_EXEC_READ
+
+/*
+ * FIXME: What do we do with kernel pages ? These are primarily 
+ *        used for modules.
+ */
+#define PAGE_KERNEL	__pgprot(_PAGE_PRESENT | __READABLE | __WRITEABLE | \
+			_PAGE_GLOBAL | PAGE_CACHABLE_DEFAULT)
+
+#define __P000	PAGE_NONE
+#define __P001	PAGE_READONLY
+#define __P010	PAGE_COPY
+#define __P011	PAGE_COPY_READ
+#define __P100	PAGE_EXECONLY
+#define __P101	PAGE_EXEC_READ
+#define __P110	PAGE_EXEC_COPY
+#define __P111	PAGE_EXEC_COPY_READ
+
+#define __S000	PAGE_NONE
+#define __S001	PAGE_READONLY
+#define __S010	PAGE_WRITEONLY
+#define __S011	PAGE_WRITE_READ
+#define __S100	PAGE_EXECONLY
+#define __S101	PAGE_EXEC_READ
+#define __S110	PAGE_EXEC_WRITE
+#define __S111	PAGE_ALL
+
+#endif
diff --git a/arch/mips/include/asm/mach-rmi/pgwalker.h b/arch/mips/include/asm/mach-rmi/pgwalker.h
new file mode 100644
index 0000000..8dd8087
--- /dev/null
+++ b/arch/mips/include/asm/mach-rmi/pgwalker.h
@@ -0,0 +1,36 @@
+#ifndef _ASM_MACH_RMI_PGWALKER_H
+#define _ASM_MACH_RMI_PGWALKER_H
+
+#include <linux/percpu.h>
+
+#define PGW_REGS_BLOCK 4
+
+enum {
+	PGW_MMU_INFO = 0x10,
+	PGW_PGD_BASES,
+	PGW_PGD_SHIFT,
+	PGW_PGD_MASK,
+	PGW_PUD_SHIFT,
+	PGW_PUD_MASK,
+	PGW_PMD_SHIFT,
+	PGW_PMD_MASK,
+	PGW_PTE_SHIFT,
+	PGW_PTE_MASK
+};
+
+#define PGD 0x8
+#define PUD 0x4
+#define PMD 0x2
+#define PTE 0x1
+
+#define pgw_register_write_w(reg, value) write_32bit_phnx_ctrl_reg(PGW_REGS_BLOCK, reg, value)
+#define pgw_register_write_d(reg, value) write_64bit_phnx_ctrl_reg(PGW_REGS_BLOCK, reg, value)
+#define pgw_register_read_w(reg) read_32bit_phnx_ctrl_reg(PGW_REGS_BLOCK, reg)
+#define pgw_register_read_d(reg) read_64bit_phnx_ctrl_reg(PGW_REGS_BLOCK, reg)
+
+#define pgw_print_w(reg) printk(KERN_INFO #reg " = 0x%x\n", pgw_register_read_w(reg))
+
+extern void pgwalker_init(void);
+extern void dump_pgwalker_config(void);
+
+#endif
diff --git a/arch/mips/include/asm/mach-rmi/spaces.h b/arch/mips/include/asm/mach-rmi/spaces.h
new file mode 100644
index 0000000..e2badcd
--- /dev/null
+++ b/arch/mips/include/asm/mach-rmi/spaces.h
@@ -0,0 +1,20 @@
+#ifndef __RMI_SPACES_H__
+#define __RMI_SPACES_H__
+
+#ifndef __ASSEMBLY__
+#ifdef CONFIG_RMI_VMIPS
+extern unsigned long rmi_vmips_phys_offset;
+#define PHYS_OFFSET rmi_vmips_phys_offset
+
+extern unsigned long long rmi_vmips_highmem_start;
+#define        HIGHMEM_START   (rmi_vmips_highmem_start)
+
+#define PAGE_OFFSET (CAC_BASE)
+
+#endif
+#endif
+
+#include <asm/mach-generic/spaces.h>
+
+
+#endif
diff --git a/arch/mips/include/asm/mach-rmi/war.h b/arch/mips/include/asm/mach-rmi/war.h
new file mode 100644
index 0000000..84e0c3e
--- /dev/null
+++ b/arch/mips/include/asm/mach-rmi/war.h
@@ -0,0 +1,25 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2002, 2004, 2007 by Ralf Baechle <ralf@linux-mips.org>
+ */
+#ifndef __ASM_MIPS_MACH_RMI_WAR_H
+#define __ASM_MIPS_MACH_RMI_WAR_H
+
+#define R4600_V1_INDEX_ICACHEOP_WAR	0
+#define R4600_V1_HIT_CACHEOP_WAR	0
+#define R4600_V2_HIT_CACHEOP_WAR	0
+#define R5432_CP0_INTERRUPT_WAR		0
+#define BCM1250_M3_WAR			0
+#define SIBYTE_1956_WAR			0
+#define MIPS4K_ICACHE_REFILL_WAR	0
+#define MIPS_CACHE_SYNC_WAR		0
+#define TX49XX_ICACHE_INDEX_INV_WAR	0
+#define RM9000_CDEX_SMP_WAR		0
+#define ICACHE_REFILLS_WORKAROUND_WAR	0
+#define R10000_LLSC_WAR			0
+#define MIPS34K_MISSED_ITLB_WAR		0
+
+#endif /* __ASM_MIPS_MACH_RMI_WAR_H */
diff --git a/arch/mips/include/asm/mach-rmi/xlp-mmu.h b/arch/mips/include/asm/mach-rmi/xlp-mmu.h
new file mode 100644
index 0000000..7f38ea5
--- /dev/null
+++ b/arch/mips/include/asm/mach-rmi/xlp-mmu.h
@@ -0,0 +1,35 @@
+#ifndef _ASM_MACH_RMI_XLP_MMU_H
+#define _ASM_MACH_RMI_XLP_MMU_H
+
+#include <linux/percpu.h>
+
+/* 
+ * These numbers correspond to Cop0 Config6 reg 
+ * bit positions 
+ */
+#define ENABLE_ETLB        0x4
+#define ENABLE_128_TLB     0x20
+#define ENABLE_PGWALKER    0x8
+
+#define USER_SEG 0
+
+#ifdef CONFIG_64BIT
+#define NR_ADDR_SEGMENTS 8  /* MUST be a power of 2 */
+#define MODULE_SEG 7
+#define VMALLOC_SEG 6
+#else /* CONFIG_32BIT */
+#define NR_ADDR_SEGMENTS 2 /* MUST be a power of 2 */
+#define VMALLOC_SEG 1
+#endif /* CONFIG_64BIT */
+
+extern DEFINE_PER_CPU(unsigned long [NR_ADDR_SEGMENTS], pgd_bases);
+
+static inline void setup_user_pgd(pgd_t *pgd)
+{
+	if (read_c0_config6() & ENABLE_PGWALKER) {
+		get_cpu_var(pgd_bases)[USER_SEG] = (unsigned long) pgd;
+		put_cpu_var(pgd_bases);
+	}
+};
+
+#endif
diff --git a/arch/mips/include/asm/mipsregs.h b/arch/mips/include/asm/mipsregs.h
index d3ea319..ce12e3b 100644
--- a/arch/mips/include/asm/mipsregs.h
+++ b/arch/mips/include/asm/mipsregs.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -16,6 +28,7 @@
 #include <linux/linkage.h>
 #include <asm/hazards.h>
 #include <asm/war.h>
+#include <asm/rmi/mips-exts.h>
 
 /*
  * The following macros are especially useful for __asm__
@@ -871,7 +884,18 @@ do {									\
 #define write_c0_count3(val)	__write_32bit_c0_register($9, 7, val)
 
 #define read_c0_entryhi()	__read_ulong_c0_register($10, 0)
+#if defined(CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID)
+extern unsigned int rmi_shtlb;
+#define write_c0_entryhi(val)   \
+	if(rmi_shtlb) \
+		__write_ulong_c0_register($10, 0, (((val) & ~0xc0)|(phoenix_thr_id()<<6))); \
+	else \
+		__write_ulong_c0_register($10, 0, val);
+#elif defined(CONFIG_PHOENIX_GLOBAL_TLB_GLOBAL_ASID)
+#define write_c0_entryhi(val)   __write_ulong_c0_register($10, 0, (((val) & ~0xc0)|(phoenix_thr_id()<<6)))
+#else
 #define write_c0_entryhi(val)	__write_ulong_c0_register($10, 0, val)
+#endif
 
 #define read_c0_compare()	__read_32bit_c0_register($11, 0)
 #define write_c0_compare(val)	__write_32bit_c0_register($11, 0, val)
diff --git a/arch/mips/include/asm/mman.h b/arch/mips/include/asm/mman.h
index 46d3da0..4730bf1 100644
--- a/arch/mips/include/asm/mman.h
+++ b/arch/mips/include/asm/mman.h
@@ -87,4 +87,10 @@
 /* compatibility flags */
 #define MAP_FILE	0
 
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+#define arch_mmap_check(addr,len,flags)	mips_mmap_check(addr,len,flags)
+int mips_mmap_check(unsigned long addr, unsigned long len,
+		unsigned long flags);
+#endif
+
 #endif /* _ASM_MMAN_H */
diff --git a/arch/mips/include/asm/mmu_context.h b/arch/mips/include/asm/mmu_context.h
index 9b02cfb..9482ac4 100644
--- a/arch/mips/include/asm/mmu_context.h
+++ b/arch/mips/include/asm/mmu_context.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * Switch a MMU context.
  *
@@ -39,6 +51,12 @@ extern void tlbmiss_handler_setup_pgd(unsigned long pgd);
 
 #else /* CONFIG_MIPS_PGD_C0_CONTEXT: using  pgd_current*/
 
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/debug.h>
+#include <asm/mach-rmi/mmu.h>
+#endif
+
 /*
  * For the fast tlb miss handlers, we keep a per cpu array of pointers
  * to the current pgd for each processor. Also, the proc. id is stuffed
@@ -87,8 +105,15 @@ extern unsigned long smtc_asid_mask;
 /* End SMTC/34K debug hack */
 #else /* FIXME: not correct for R6000 */
 
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+#define ASID_INC    0x1
+extern unsigned long rmi_asid_mask;
+#define ASID_MASK   rmi_asid_mask
+#else
+
 #define ASID_INC	0x1
 #define ASID_MASK	0xff
+#endif
 
 #endif
 
diff --git a/arch/mips/include/asm/module.h b/arch/mips/include/asm/module.h
index 7467d1d..37e16d0 100644
--- a/arch/mips/include/asm/module.h
+++ b/arch/mips/include/asm/module.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
 #ifndef _ASM_MODULE_H
 #define _ASM_MODULE_H
 
@@ -116,6 +128,10 @@ search_module_dbetables(unsigned long addr)
 #define MODULE_PROC_FAMILY "RM9000 "
 #elif defined CONFIG_CPU_SB1
 #define MODULE_PROC_FAMILY "SB1 "
+#elif defined CONFIG_CPU_XLR
+#define MODULE_PROC_FAMILY "XLR "
+#elif defined CONFIG_CPU_XLP
+#define MODULE_PROC_FAMILY "XLP "
 #elif defined CONFIG_CPU_LOONGSON2
 #define MODULE_PROC_FAMILY "LOONGSON2 "
 #elif defined CONFIG_CPU_CAVIUM_OCTEON
diff --git a/arch/mips/include/asm/msi.h b/arch/mips/include/asm/msi.h
new file mode 100644
index 0000000..06dec3f
--- /dev/null
+++ b/arch/mips/include/asm/msi.h
@@ -0,0 +1,28 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: Defines for MSI support for RMI Eval Board
+
+  *****************************#RMI_1#************************************/
+
+/*
+ * Copyright (C) 2003-2004 Intel
+ * Copyright (C) Tom Long Nguyen (tom.l.nguyen@intel.com)
+ */
+
+#ifndef ASM_MSI_H
+#define ASM_MSI_H
+
+#define NR_VECTORS              128
+#define NR_IRQ_VECTORS          NR_IRQS
+#define FIRST_DEVICE_VECTOR     0x00
+
+#define LAST_DEVICE_VECTOR		232
+#define MSI_TARGET_CPU_SHIFT	12
+
+#endif /* ASM_MSI_H */
diff --git a/arch/mips/include/asm/page.h b/arch/mips/include/asm/page.h
index da9bd7d..3bb9a49 100644
--- a/arch/mips/include/asm/page.h
+++ b/arch/mips/include/asm/page.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -76,15 +88,35 @@ struct page;
 static inline void clear_user_page(void *addr, unsigned long vaddr,
 	struct page *page)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	extern void phoenix_flush_dcache_page(struct page *page);
+#else
 	extern void (*flush_data_cache_page)(unsigned long addr);
+#endif
 
 	clear_page(addr);
+#ifdef CONFIG_RMI_PHOENIX
+	phoenix_flush_dcache_page(page);
+#else
 	if (pages_do_alias((unsigned long) addr, vaddr & PAGE_MASK))
 		flush_data_cache_page((unsigned long)addr);
+#endif
 }
 
+#ifdef CONFIG_RMI_PHOENIX
+static inline void copy_user_page(void *vto, void *vfrom, unsigned long vaddr,
+		    struct page *to)
+{
+	extern void phoenix_flush_dcache_page(struct page *page);
+
+	copy_page(vto, vfrom);
+	phoenix_flush_dcache_page(to);
+}
+#else
 extern void copy_user_page(void *vto, void *vfrom, unsigned long vaddr,
 	struct page *to);
+#endif
+
 struct vm_area_struct;
 extern void copy_user_highpage(struct page *to, struct page *from,
 	unsigned long vaddr, struct vm_area_struct *vma);
@@ -169,7 +201,13 @@ typedef struct { unsigned long pgprot; } pgprot_t;
  * https://patchwork.linux-mips.org/patch/1541/
  */
 
-#define __pa_symbol(x)	__pa(RELOC_HIDE((unsigned long)(x), 0))
+#ifndef __ASSEMBLY__
+#ifdef CONFIG_MAPPED_KERNEL
+#define __pa_symbol(x) (RELOC_HIDE((unsigned long)(x), 0) - (unsigned long)LOADADDR + ((unsigned long)PHYSADDR & 0x7fffffffUL))
+#else
+#define __pa_symbol(x) __pa(RELOC_HIDE((unsigned long)(x), 0))
+#endif
+#endif
 
 #define pfn_to_kaddr(pfn)	__va((pfn) << PAGE_SHIFT)
 
@@ -204,8 +242,9 @@ typedef struct { unsigned long pgprot; } pgprot_t;
 #define virt_to_page(kaddr)	pfn_to_page(PFN_DOWN(virt_to_phys(kaddr)))
 #define virt_addr_valid(kaddr)	pfn_valid(PFN_DOWN(virt_to_phys(kaddr)))
 
-#define VM_DATA_DEFAULT_FLAGS	(VM_READ | VM_WRITE | VM_EXEC | \
-				 VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
+#define VM_DATA_DEFAULT_FLAGS (VM_READ | VM_WRITE | \
+    ((current->personality & READ_IMPLIES_EXEC) ? VM_EXEC : 0 ) | \
+         VM_MAYREAD | VM_MAYWRITE | VM_MAYEXEC)
 
 #define UNCAC_ADDR(addr)	((addr) - PAGE_OFFSET + UNCAC_BASE + 	\
 								PHYS_OFFSET)
diff --git a/arch/mips/include/asm/perfctr.h b/arch/mips/include/asm/perfctr.h
new file mode 100644
index 0000000..c185842
--- /dev/null
+++ b/arch/mips/include/asm/perfctr.h
@@ -0,0 +1,241 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/* $Id: perfctr.h,v 1.1.2.5 2006-09-28 01:24:19 nphilips Exp $
+ * MIPS_XLR Performance-Monitoring Counters driver
+ *
+ * Copyright (C) 2005  Prasad Boddupalli
+ */
+#ifndef _ASM_MIPS_PERFCTR_H
+#define _ASM_MIPS_PERFCTR_H
+
+#define PERFCTR_PAGE_SIZE 4096
+
+/* perfctr_info.cpu_type values */
+#define MIPS_GENERIC	0
+#define MIPS_XLR        1
+
+// Architecture-specific container for counter values.
+// Used in the kernel/user API, but not by low-level drivers.
+struct perfctr_sum_ctrs {
+	unsigned long long tsc;
+	unsigned long long pmc[2];	// just two perf registers
+};
+
+// architecture-specific container for control data.
+// used in both kernel/user API and by low-level drivers
+struct perfctr_cpu_control {
+	unsigned int tsc_on;		// initialize on perfctr_cpu_init()?
+	unsigned int nractrs;		/* # of a-mode counters (max(0,2)?) */
+	unsigned int nrictrs;		/* # of i-mode counters */
+
+    // We already have the control registers in the eventsel field
+	// of the struct {} pmc[]. We might not need the following
+	// registers 
+
+	/* struct {
+		unsigned int perfctrl0;
+		unsigned int perfctrl1;
+	} mips; */
+
+	unsigned int _reserved1;
+	unsigned int _reserved2;
+	unsigned int _reserved3;
+	unsigned int _reserved4;
+
+	struct {
+		unsigned int map;	/* physical counter to use */
+		unsigned int ctrl_reg;
+		int ireset;		/* [0,0x7fffffff], for i-mode counters */
+	} pmc[2];
+};
+
+struct perfctr_cpu_state {
+	unsigned int cstatus;
+
+	// k1 is opaque in the user ABI
+	struct {
+		unsigned int id;
+		int isuspend_cpu;
+	} k1;
+
+	// tsc fields must be inlined. Placing them in a sub-struct might 
+	// cause unwanted internal padding
+	unsigned int tsc_start;
+	unsigned long long tsc_sum;
+
+	struct {
+		unsigned int map;
+		unsigned int start;
+		unsigned long long sum;
+	} pmc[2];
+
+#ifdef __KERNEL__
+	struct perfctr_cpu_control control;
+#endif
+};
+
+/* cstatus is a re-encoding of control.tsc_on/nractrs/nrictrs
+   which should have less overhead in most cases */
+/* XXX: mips driver internally also uses cstatus&(1<<30) */
+
+// construct a cstatus value. 
+static inline
+unsigned int perfctr_mk_cstatus(unsigned int tsc_on, unsigned int nractrs,
+				unsigned int nrictrs)
+{
+	return ((tsc_on<<31) | (nrictrs<<16) | ((nractrs+nrictrs)<<8) | nractrs);
+}
+
+// check if any part (tsc_on, nractrs, nrictrs) of the cstatus is non-zero
+static inline unsigned int perfctr_cstatus_enabled(unsigned int cstatus)
+{
+	return cstatus;
+}
+
+// check if the tsc_on part of the cstatus is non-zero
+static inline int perfctr_cstatus_has_tsc(unsigned int cstatus)
+{
+	return ((int)cstatus < 0);	/* test and jump on sign */
+}
+
+// retrieve nractrs field
+static inline unsigned int perfctr_cstatus_nractrs(unsigned int cstatus)
+{
+	return (cstatus & 0x7F);		/* and with imm8 */
+}
+
+// retrieve nractrs+nrictrs from the cstatus
+static inline unsigned int perfctr_cstatus_nrctrs(unsigned int cstatus)
+{
+	return ((cstatus >> 8) & 0x7F);
+}
+
+// check if the nrictrs part of cstatus is non-zero
+static inline unsigned int perfctr_cstatus_has_ictrs(unsigned int cstatus)
+{
+	return (cstatus & (0x7F << 16));
+}
+
+/*
+ * 'struct siginfo' support for perfctr overflow signals.
+ * In unbuffered mode, si_code is set to SI_PMC_OVF and a bitmask
+ * describing which perfctrs overflowed is put in si_pmc_ovf_mask.
+ * A bitmask is used since more than one perfctr can have overflowed
+ * by the time the interrupt handler runs.
+ *
+ * glibc's <signal.h> doesn't seem to define __SI_FAULT or __SI_CODE(),
+ * and including <asm/siginfo.h> as well may cause redefinition errors,
+ * so the user and kernel values are different #defines here.
+ */
+#ifdef __KERNEL__
+#define SI_PMC_OVF	(__SI_FAULT|'P')
+#else
+#define SI_PMC_OVF	('P')
+#endif
+#define si_pmc_ovf_mask	_sifields._pad[0] /* XXX: use an unsigned field later */
+
+/* version number for user-visible CPU-specific data */
+#define PERFCTR_CPU_VERSION	0	/* XXX: not yet cast in stone */
+
+#ifdef __KERNEL__
+
+#ifdef CONFIG_PERFCTR
+
+/* Driver init/exit. */
+extern int perfctr_cpu_init(void);
+extern void perfctr_cpu_exit(void);
+
+/* CPU type name. */
+extern char *perfctr_cpu_name;
+
+/* Hardware reservation. */
+extern const char *perfctr_cpu_reserve(const char *service);
+extern void perfctr_cpu_release(const char *service);
+
+/* PRE: state has no running interrupt-mode counters.
+   Check that the new control data is valid.
+   Update the driver's private control data.
+   Returns a negative error code if the control data is invalid.
+*/
+extern int perfctr_cpu_update_control(struct perfctr_cpu_state *state, int is_global);
+
+
+/* Read a-mode counters. Subtract from start and accumulate into sums.
+   Must be called with preemption disabled. */
+extern void perfctr_cpu_suspend(struct perfctr_cpu_state *state);
+
+/* Write control registers. Read a-mode counters into start.
+   Must be called with preemption disabled. */
+extern void perfctr_cpu_resume(struct perfctr_cpu_state *state);
+
+/* Perform an efficient combined suspend/resume operation.
+   Must be called with preemption disabled. */
+extern void perfctr_cpu_sample(struct perfctr_cpu_state *state);
+
+/* The type of a perfctr overflow interrupt handler.
+   It will be called in IRQ context, with preemption disabled. */
+typedef void (*perfctr_ihandler_t)(unsigned long pc);
+
+unsigned int read_pmc (unsigned int);
+void write_pmc (unsigned int, unsigned int);
+void write_pmctrl (unsigned int, unsigned int);
+
+/* Operations related to overflow interrupt handling. */
+
+#ifdef CONFIG_PERFCTR_INTERRUPT_SUPPORT
+extern void perfctr_cpu_set_ihandler(perfctr_ihandler_t);
+extern void perfctr_cpu_ireload(struct perfctr_cpu_state*);
+extern unsigned int perfctr_cpu_identify_overflow(struct perfctr_cpu_state*);
+#else
+static inline void perfctr_cpu_set_ihandler(perfctr_ihandler_t x) { }
+#endif
+
+static inline int perfctr_cpu_has_pending_interrupt(const struct perfctr_cpu_state *state)
+{
+	return 0;
+}
+
+extern perfctr_ihandler_t perfctr_ihandler;
+
+#endif	/* CONFIG_PERFCTR */
+
+#endif	/* __KERNEL__ */
+
+#define MIPS_XLR_DOM_KERNEL		0x2
+#define MIPS_XLR_DOM_SUP		0x4
+#define MIPS_XLR_DOM_USR		0x8
+
+#define MIPS_XLR_SET_EVNTCNT_MODE(x, mode)		x |= mode
+#define MIPS_XLR_UNSET_EVNTCNT_MODE(x, mode)	x &= ~mode
+
+#define MIPS_XLR_OVF_BIT                0x10
+#define MIPS_XLR_OVF_PMI_EABLE(x)		x |= MIPS_XLR_OVF_BIT
+#define MIPS_XLR_OVF_PMI_DABLE(x)		x &= ~MIPS_XLR_OVF_BIT
+#define MIPS_XLR_IS_OVF_PMI(x)			(x & MIPS_XLR_OVF_BIT)
+
+#define MIPS_XLR_EVNTSEL_MASK			0x3f
+#define MIPS_XLR_EVNTSEL_SHIFT			5
+#define MIPS_XLR_SET_EVNT(x, event)		\
+		x |= ((event & MIPS_XLR_EVNTSEL_MASK) << MIPS_XLR_EVNTSEL_SHIFT)
+#define MIPS_XLR_GET_EVNT(x)	\
+		((x >> MIPS_XLR_EVNTSEL_SHIFT) & MIPS_XLR_EVNTSEL_MASK)
+
+#define MIPS_XLR_THREADID_MASK				0x03
+#define MIPS_XLR_THREADID_SHIFT				11
+#define MIPS_XLR_SET_THREADID(x, tid)		\
+		x |= ((tid & MIPS_XLR_THREADID_MASK) << MIPS_XLR_THREADID_SHIFT)
+
+#define MIPS_XLR_SET_CNT_ALL_THREADS(x)		x |= 0x2000
+#define MIPS_XLR_UNSET_CNT_ALL_THREADS(x)	x &= ~0x2000
+
+#endif	/* _ASM_MIPS_PERFCTR_H */
diff --git a/arch/mips/include/asm/pgtable-32.h b/arch/mips/include/asm/pgtable-32.h
index 5d56bb2..1fd07e5 100644
--- a/arch/mips/include/asm/pgtable-32.h
+++ b/arch/mips/include/asm/pgtable-32.h
@@ -47,7 +47,12 @@
 #define USER_PTRS_PER_PGD	(0x80000000UL/PGDIR_SIZE)
 #define FIRST_USER_ADDRESS	0
 
+#ifdef CONFIG_MAPPED_KERNEL
+extern unsigned long __vmalloc_start;
+#define VMALLOC_START     __vmalloc_start
+#else
 #define VMALLOC_START     MAP_BASE
+#endif
 
 #define PKMAP_BASE		(0xfe000000UL)
 
diff --git a/arch/mips/include/asm/pgtable-64.h b/arch/mips/include/asm/pgtable-64.h
index 55908fd..ec84360 100644
--- a/arch/mips/include/asm/pgtable-64.h
+++ b/arch/mips/include/asm/pgtable-64.h
@@ -125,12 +125,19 @@
  * the first couple of pages so NULL pointer dereferences will still
  * reliably trap.
  */
+#if defined(CONFIG_MAPPED_KERNEL) && defined(CONFIG_KSEG2_LOWMEM)
+#define VMALLOC_START		0xe0000000
+#else
 #define VMALLOC_START		(MAP_BASE + (2 * PAGE_SIZE))
+#endif
+
 #define VMALLOC_END	\
-	(MAP_BASE + \
+	(VMALLOC_START + \
 	 min(PTRS_PER_PGD * PTRS_PER_PMD * PTRS_PER_PTE * PAGE_SIZE, \
 	     (1UL << cpu_vmbits)) - (1UL << 32))
 
+#ifndef CONFIG_MAPPED_KERNEL
+
 #if defined(CONFIG_MODULES) && defined(KBUILD_64BIT_SYM32) && \
 	VMALLOC_START != CKSSEG
 /* Load modules into 32bit-compatible segment. */
@@ -138,6 +145,8 @@
 #define MODULE_END	(FIXADDR_START-2*PAGE_SIZE)
 #endif
 
+#endif /* CONFIG_MAPPED_KERNEL */
+
 #define pte_ERROR(e) \
 	printk("%s:%d: bad pte %016lx.\n", __FILE__, __LINE__, pte_val(e))
 #ifndef __PAGETABLE_PMD_FOLDED
diff --git a/arch/mips/include/asm/pgtable-bits.h b/arch/mips/include/asm/pgtable-bits.h
index e9fe7e9..e022c27 100644
--- a/arch/mips/include/asm/pgtable-bits.h
+++ b/arch/mips/include/asm/pgtable-bits.h
@@ -192,6 +192,12 @@ static inline uint64_t pte_to_entrylo(unsigned long pte_val)
 #define _CACHE_CACHABLE_NONCOHERENT (5<<_CACHE_SHIFT)
 #define _CACHE_UNCACHED_ACCELERATED (7<<_CACHE_SHIFT)
 
+#elif defined(CONFIG_CPU_XLR) || defined(CONFIG_CPU_XLP)
+
+#define _CACHE_UNCACHED             (2<<9)
+#define _CACHE_CACHABLE_COW         (3<<9)
+#define _CACHE_CACHABLE_NONCOHERENT (3<<9)
+
 #elif defined(CONFIG_CPU_RM9000)
 
 #define _CACHE_WT		    (0<<_CACHE_SHIFT)
diff --git a/arch/mips/include/asm/pgtable.h b/arch/mips/include/asm/pgtable.h
index b2202a6..52ef1bd 100644
--- a/arch/mips/include/asm/pgtable.h
+++ b/arch/mips/include/asm/pgtable.h
@@ -137,6 +137,8 @@ static inline void pte_clear(struct mm_struct *mm, unsigned long addr, pte_t *pt
 
 #define pte_none(pte)		(!(pte_val(pte) & ~_PAGE_GLOBAL))
 #define pte_present(pte)	(pte_val(pte) & _PAGE_PRESENT)
+/* Just for compilation! */
+#define pte_user(pte)           (pte_val(pte) & _PAGE_PRESENT)
 
 /*
  * Certain architectures need to do special things when pte's
@@ -145,6 +147,10 @@ static inline void pte_clear(struct mm_struct *mm, unsigned long addr, pte_t *pt
  */
 static inline void set_pte(pte_t *ptep, pte_t pteval)
 {
+#ifdef CONFIG_PHOENIX_VM_DEBUG
+	printk("[%s]: ptep=%lx, pteval=%lx\n", __FUNCTION__,
+			(unsigned long)ptep, pte_val(pteval));
+#endif
 	*ptep = pteval;
 #if !defined(CONFIG_CPU_R3000) && !defined(CONFIG_CPU_TX39XX)
 	if (pte_val(pteval) & _PAGE_GLOBAL) {
@@ -362,6 +368,7 @@ static inline pte_t pte_modify(pte_t pte, pgprot_t newprot)
 #endif
 
 
+struct vm_area_struct;
 extern void __update_tlb(struct vm_area_struct *vma, unsigned long address,
 	pte_t pte);
 extern void __update_cache(struct vm_area_struct *vma, unsigned long address,
diff --git a/arch/mips/include/asm/processor.h b/arch/mips/include/asm/processor.h
index 20e9dcf..cf640c6 100644
--- a/arch/mips/include/asm/processor.h
+++ b/arch/mips/include/asm/processor.h
@@ -47,8 +47,11 @@ extern unsigned int vced_count, vcei_count;
 /*
  * User space process size: 2GB. This is hardcoded into a few places,
  * so don't change it unless you know what you are doing.
+ *
+ * XLP_MERGE_TODO: changed TASK_SIZE from 0x7fff8000UL to 0x7fff8000UL
+ * to fix page alignment of initial stack (vm_start) for 64KB pages
  */
-#define TASK_SIZE	0x7fff8000UL
+#define TASK_SIZE	0x7fff0000UL
 
 #ifdef __KERNEL__
 #define STACK_TOP_MAX	TASK_SIZE
@@ -65,8 +68,11 @@ extern unsigned int vced_count, vcei_count;
  * is limited to 1TB by the R4000 architecture; R10000 and better can
  * support 16TB; the architectural reserve for future expansion is
  * 8192EB ...
+ *
+ * XLP_MERGE_TODO: changed TASK_SIZE32 from 0x7fff8000UL to 0x7fff8000UL
+ * to fix page alignment of initial stack (vm_start) for 64KB pages
  */
-#define TASK_SIZE32	0x7fff8000UL
+#define TASK_SIZE32	0x7fff0000UL
 #define TASK_SIZE64	0x10000000000UL
 #define TASK_SIZE (test_thread_flag(TIF_32BIT_ADDR) ? TASK_SIZE32 : TASK_SIZE64)
 
@@ -228,6 +234,9 @@ struct thread_struct {
 	unsigned long error_code;
 	unsigned long irix_trampoline;  /* Wheee... */
 	unsigned long irix_oldctx;
+#ifdef CONFIG_PERFCTR_VIRTUAL
+	struct vperfctr *perfctr;
+#endif
 #ifdef CONFIG_CPU_CAVIUM_OCTEON
     struct octeon_cop2_state cp2 __attribute__ ((__aligned__(128)));
     struct octeon_cvmseg_state cvmseg __attribute__ ((__aligned__(128)));
diff --git a/arch/mips/include/asm/ptrace.h b/arch/mips/include/asm/ptrace.h
index 4b7f525..dfe6e2b 100644
--- a/arch/mips/include/asm/ptrace.h
+++ b/arch/mips/include/asm/ptrace.h
@@ -118,6 +118,7 @@ struct pt_watch_regs {
 #include <linux/linkage.h>
 #include <linux/types.h>
 #include <asm/isadep.h>
+#include <asm/kdebug.h>
 
 struct task_struct;
 
diff --git a/arch/mips/include/asm/rio.h b/arch/mips/include/asm/rio.h
new file mode 100644
index 0000000..a7e56fc
--- /dev/null
+++ b/arch/mips/include/asm/rio.h
@@ -0,0 +1,15 @@
+/*
+ * RapidIO architecture support
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#ifndef ASM_MIOS_RIO_H
+#define ASM_MIPS_RIO_H
+
+extern void platform_rio_init(void);
+
+#endif				/* ASM_PPC_MIPS_H */
diff --git a/arch/mips/include/asm/rmi/64bit.h b/arch/mips/include/asm/rmi/64bit.h
new file mode 100644
index 0000000..b8d825f
--- /dev/null
+++ b/arch/mips/include/asm/rmi/64bit.h
@@ -0,0 +1,85 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_64BIT_H
+#define _ASM_RMI_64BIT_H
+
+#include <linux/types.h>
+#include <asm/system.h>
+
+/* Implement 64bit read and write operations */
+
+static inline void out64(u64 val, unsigned long addr)
+{
+  u32 low, high, tmp;
+  unsigned long flags=0;
+
+  high = val >> 32;
+  low = val & 0xffffffff;
+  local_irq_save(flags);
+  __asm__ __volatile__ (
+			".set push\t\t\t# out64n"
+			".set noreorder\n"
+			".set noat\n"
+			".set mips4\n"
+			"   dsll32 %0, %2, 0   \n"
+			"   dsll32 $1, %1, 0   \n"
+			"   dsrl32 %0, %0, 0   \n"
+			"   or     $1, $1, %0  \n"
+			"   sd $1, (%3)\n"
+			".set pop\n"
+			: "=&r" (tmp)
+			: "r" (high), "r" (low), "r" (addr));
+  local_irq_restore(flags);
+}
+
+static inline u64 in64(unsigned long addr)
+{
+  unsigned long flags;
+  u32 low, high;
+
+  local_irq_save(flags);
+  __asm__ __volatile__ (
+			".set push\t\t\t# in64\n"
+			".set noreorder\n"
+			".set noat     \n"
+			".set mips4    \n"
+			"  ld     %1, (%2)\n"
+			"  dsra32 %0, %1, 0\n"
+			"  sll    %1, %1, 0\n"
+			".set pop\n"
+			: "=r" (high), "=r" (low)
+			: "r" (addr));
+  local_irq_restore(flags);
+
+  return (((u64)high) << 32) | low;
+}
+
+#endif 
diff --git a/arch/mips/include/asm/rmi/atx_cpld.h b/arch/mips/include/asm/rmi/atx_cpld.h
new file mode 100644
index 0000000..aa3f8d5
--- /dev/null
+++ b/arch/mips/include/asm/rmi/atx_cpld.h
@@ -0,0 +1,64 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_ATX_CPLD_H
+#define _ASM_RMI_ATX_CPLD_H
+
+/*
+	 * bit_0 : xgs0 phy reset
+	 * bit_1 : xgs1 phy reset
+	 * bit_2 : HT reset
+	 * bit_3 : RTC reset
+	 * bit_4 : gmac phy soft reset
+	 * bit_5 : gmac phy hard reset
+	 * bit_6 : board reset
+	 * bit_7 : reserved
+*/
+#define ATX_CPLD_RESET_1   2
+
+/*
+ *  bit_0_2 : reserved
+ *  bit_3 : turn off xpak_0 tx
+ *  bit_4 : turn off xpak_1 tx
+ *  bit_5 : HT stop (active low)
+ *  bit_6 : flash program enable
+ *  bit_7 : compact flash io mode
+ */
+#define ATX_CPLD_MISC_CTRL 8
+
+/*
+ * bit_0 : reset tcam 
+ * bit_1 : reset xpak_0 module
+ * bit_2 : reset xpak_1 module
+ * bit_3_7 : reserved
+ */
+#define ATX_CPLD_RESET_2   9
+
+#endif /* _ASM_RMI_ATX_CPLD_H */
diff --git a/arch/mips/include/asm/rmi/config_net.h b/arch/mips/include/asm/rmi/config_net.h
new file mode 100644
index 0000000..460eb77
--- /dev/null
+++ b/arch/mips/include/asm/rmi/config_net.h
@@ -0,0 +1,118 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_NET_H
+#define _ASM_RMI_NET_H
+
+#include <asm/rmi/msgring.h>
+
+#define PHOENIX_MAX_GMACS 8
+#define PHOENIX_MAX_XGMACS 2
+#define PHOENIX_MAX_XAUIS 2
+
+#define PHOENIX_GMAC_PORTS_PER_CTRL 4
+
+#define PHOENIX_MAX_MACS (PHOENIX_MAX_GMACS + PHOENIX_MAX_XGMACS)
+
+enum config_flags { PHNX_PORT_INIT = 1, 
+					PHNX_PORT_ATTACH = 2, 
+					PHNX_INT_ATTACH = 4, 
+					PHNX_MSGRNG_OWN = 8, 
+					PHNX_PORT_EN = 0x10 };
+
+#define PORT_OWN_LINUX  ( PHNX_PORT_INIT | PHNX_PORT_ATTACH | PHNX_INT_ATTACH | PHNX_MSGRNG_OWN | PHNX_PORT_EN )
+
+/* 	PORT_INIT  : GMAC/XGMAC IP initialization will be done. 
+	Port will be disabled after the initialization. 
+	Glue logic(spill, packet descriptors will not be initialized 
+
+	PORT_ATTACH : Eth interface will be attached to Linux 
+
+	INT_ATTACH : GMAC/XGMAC MDIO interrupt will be attached to Linux
+
+	MSGRNG_OWN : Glue logic(spill, packet descriptors will be initialized by linux
+
+	PORT_EN : Option to enable the port
+*/
+
+
+struct port_cfg {
+	/* port number */
+	int instance;
+
+	/* See enum config_flags */
+	uint32_t cfg_flag;
+
+	/* Interrupt Request number */
+	int irqno; 
+
+	/* number of descriptors configured */
+	int num_desc; 
+
+	/* pointer to the bucket config */
+	bucket_t *bucket;
+
+	/* pointer to the credit config */
+	struct stn_cc *credit;
+
+	/* driver should configure the pde */
+	int config_pde;
+
+	unsigned long mmio_addr; /* config address */
+	uint32_t phy_addr; /* phy id */
+	int phy_mode; /* sgmii or rgmii */
+	unsigned long mii_addr; /* mdio addr */
+	unsigned long pcs_addr; /* only for sgmii ports */
+	unsigned long serdes_addr; /* only for sgmii ports */
+};
+
+struct net_device_cfg {
+	struct port_cfg gmac_port[PHOENIX_MAX_GMACS];
+	int xgs_type[PHOENIX_MAX_XGMACS];
+	struct port_cfg xgs_port[PHOENIX_MAX_XGMACS];
+};
+
+
+enum net_types { TYPE_GMAC = 0, TYPE_XGMAC, TYPE_SPI4, MAX_NET_TYPES };
+enum phy_modes { PHY_MODE_SGMII	= 1, PHY_MODE_RGMII = 2, 
+    PHY_MODE_SELECTABLE = 4, PHY_MODE_XAUI=8};
+
+extern int phnx_get_phy_info(int instance, int mode, unsigned long *mii_addr, 
+					unsigned long *pcs_addr, unsigned long *serdes_addr);
+
+#define PORT_INIT(x) (x & PHNX_PORT_INIT)
+#define PORT_ATTACH(x) (x & PHNX_PORT_ATTACH)
+#define PORT_INT_ATTACH(x) (x & PHNX_INT_ATTACH)
+#define MSGRNG_OWN(x) (x & PHNX_MSGRNG_OWN)
+#define PORT_EN(x) (x & PHNX_PORT_EN)
+
+#endif
+
+
diff --git a/arch/mips/include/asm/rmi/debug.h b/arch/mips/include/asm/rmi/debug.h
new file mode 100644
index 0000000..1a3a7b7
--- /dev/null
+++ b/arch/mips/include/asm/rmi/debug.h
@@ -0,0 +1,117 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_DEBUG_H
+#define _ASM_RMI_DEBUG_H
+
+/*Enable below macro to enable net stats. */
+//#define CONFIG_RMI_STATS
+extern void prom_printf(char *fmt, ...);
+#include <linux/threads.h>
+#include <asm/atomic.h>
+
+enum {
+  //cacheline 0
+  MSGRNG_INT,
+  MSGRNG_PIC_INT,
+  MSGRNG_MSG,
+  MSGRNG_EXIT_STATUS,
+  MSGRNG_MSG_CYCLES,
+  //cacheline 1
+  NETIF_TX = 8,
+  NETIF_RX,
+  NETIF_TX_COMPLETE,
+  NETIF_TX_COMPLETE_TX,
+  NETIF_RX_CYCLES,
+  NETIF_TX_COMPLETE_CYCLES,
+  NETIF_TX_CYCLES,
+  NETIF_TIMER_START_Q,
+  //NETIF_REG_FRIN,
+  //NETIF_INT_REG,
+  //cacheline 2
+  REPLENISH_ENTER = 16,
+  REPLENISH_ENTER_COUNT,
+  REPLENISH_CPU,
+  REPLENISH_FRIN,
+  REPLENISH_CYCLES,
+  NETIF_STACK_TX,
+  NETIF_START_Q,
+  NETIF_STOP_Q,
+  //cacheline 3
+  USER_MAC_START = 24,
+  USER_MAC_INT   = 24,
+  USER_MAC_TX_COMPLETE,
+  USER_MAC_RX,
+  USER_MAC_POLL,
+  USER_MAC_TX,
+  USER_MAC_TX_FAIL,
+  USER_MAC_TX_COUNT,
+  USER_MAC_FRIN,
+  //cacheline 4
+  USER_MAC_TX_FAIL_GMAC_CREDITS = 32,
+  USER_MAC_DO_PAGE_FAULT,
+  USER_MAC_UPDATE_TLB,
+  USER_MAC_UPDATE_TLB_PFN0,
+  USER_MAC_UPDATE_TLB_PFN1,
+  
+  PHNX_MAX_COUNTERS = 40
+};
+extern atomic_t phnx_counters[NR_CPUS][PHNX_MAX_COUNTERS];
+extern __u32 msgrng_msg_cycles;
+
+#ifdef CONFIG_RMI_STATS 
+#define phnx_inc_counter(x) atomic_inc(&phnx_counters[0][(x)])
+#define phnx_dec_counter(x) atomic_dec(&phnx_counters[0][(x)])
+#define phnx_set_counter(x, value) atomic_set(&phnx_counters[0][(x)], (value))
+#define phnx_get_counter(x) atomic_read(&phnx_counters[0][(x)])
+#else
+#define phnx_inc_counter(x) //atomic_inc(&phnx_counters[0][(x)])
+#define phnx_dec_counter(x) //atomic_dec(&phnx_counters[0][(x)])
+#define phnx_set_counter(x, value) //atomic_set(&phnx_counters[0][(x)], (value))
+#define phnx_get_counter(x) //atomic_read(&phnx_counters[0][(x)])
+#endif
+#if 0
+#define dbg_msg(fmt, args...) printk("[%s@%d|%s]: cpu_%d: " fmt, \
+                               __FILE__, __LINE__, __FUNCTION__,  smp_processor_id(), ##args)
+
+#define dbg_panic(fmt, args...) panic("[%s@%d|:%s]: cpu_%d: " fmt, \
+                               __FILE__, __LINE__, __FUNCTION__, smp_processor_id(), ##args)
+
+#define prom_dbg_msg(fmt, args...) prom_printf("[%s@%d|%s]: cpu_%d: " fmt, \
+                               __FILE__, __LINE__, __FUNCTION__,  smp_processor_id(), ##args)
+#else
+#define dbg_msg(fmt, args...)
+
+#define dbg_panic(fmt, args...) panic(fmt, ##args)
+
+#define prom_dbg_msg(fmt, args...) printk(fmt, ##args)
+#endif
+
+#endif
diff --git a/arch/mips/include/asm/rmi/devices.h b/arch/mips/include/asm/rmi/devices.h
new file mode 100644
index 0000000..d57c77b
--- /dev/null
+++ b/arch/mips/include/asm/rmi/devices.h
@@ -0,0 +1,46 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_DEVICES_H
+#define _ASM_RMI_DEVICES_H
+
+#define XLR_VIRT_UART_MAJOR       239
+#define XLR_TB_MAJOR              240
+#define XLR_USER_MAC_MAJOR        241
+#define XLR_CRYPTO_MAJOR          242
+
+#define BTLBDEV_MAJOR             243
+
+#define XLR_MSGRING_SHM_MAJOR     244
+#define XLR_APP_LOADER_MAJOR      245
+#define XLR_CONSOLE_OVER_PCI_MAJOR	  246
+#define XLR_DEBUGGER_MAJOR              247
+
+#endif
diff --git a/arch/mips/include/asm/rmi/global_shmem.h b/arch/mips/include/asm/rmi/global_shmem.h
new file mode 100644
index 0000000..900fde9
--- /dev/null
+++ b/arch/mips/include/asm/rmi/global_shmem.h
@@ -0,0 +1,48 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+#ifndef __GLOBAL_SHMEM_H_
+#define __GLOBAL_SHMEM_H_
+
+
+/* Apps should check this size and then use boot1_info->global_shmem_addr */
+#define GLOBAL_SHMEM_SIZE       0x1000
+
+
+/* Apps should use the boot1_info->global_shmem_addr + the offsets defined
+   here.
+ */
+#define BRIDGE_WKAROUND_AREA_OFFSET	0
+#define BRIDGE_WKAROUND_AREA_SIZE	32
+
+
+
+
+#endif
diff --git a/arch/mips/include/asm/rmi/gpio.h b/arch/mips/include/asm/rmi/gpio.h
new file mode 100644
index 0000000..d3b72de
--- /dev/null
+++ b/arch/mips/include/asm/rmi/gpio.h
@@ -0,0 +1,77 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_GPIO_H
+#define _ASM_RMI_GPIO_H
+
+#include <asm/rmi/iomap.h>
+
+#define PHOENIX_GPIO_INT_EN_REG 0
+#define PHOENIX_GPIO_INPUT_INVERSION_REG 1
+#define PHOENIX_GPIO_IO_DIR_REG 2
+#define PHOENIX_GPIO_IO_DATA_WR_REG 3
+#define PHOENIX_GPIO_IO_DATA_RD_REG 4
+
+#define PHOENIX_GPIO_SWRESET_REG 8
+
+#define PHOENIX_GPIO_DRAM1_CNTRL_REG 9
+#define PHOENIX_GPIO_DRAM1_RATIO_REG 10
+#define PHOENIX_GPIO_DRAM1_RESET_REG 11
+#define PHOENIX_GPIO_DRAM1_STATUS_REG 12
+
+#define PHOENIX_GPIO_DRAM2_CNTRL_REG 13
+#define PHOENIX_GPIO_DRAM2_RATIO_REG 14
+#define PHOENIX_GPIO_DRAM2_RESET_REG 15
+#define PHOENIX_GPIO_DRAM2_STATUS_REG 16
+
+#define PHOENIX_GPIO_PWRON_RESET_CFG_REG 21
+
+#define PHOENIX_GPIO_BIST_ALL_GO_STATUS_REG 24
+#define PHOENIX_GPIO_BIST_CPU_GO_STATUS_REG 25
+#define PHOENIX_GPIO_BIST_DEV_GO_STATUS_REG 26
+
+#define PHOENIX_GPIO_FUSE_BANK_REG 35
+
+#define PHOENIX_GPIO_CPU_RESET_REG 40
+
+#define PHOENIX_GPIO_RNG_REG 43
+
+#define PHOENIX_PWRON_RESET_PCMCIA_BOOT 17
+
+#define PHOENIX_GPIO_LED_BITMAP 0x1700000
+#define PHOENIX_GPIO_LED_0_SHIFT 20
+#define PHOENIX_GPIO_LED_1_SHIFT 24
+
+#define PHOENIX_GPIO_LED_OUTPUT_CODE_RESET 0x01
+#define PHOENIX_GPIO_LED_OUTPUT_CODE_HARD_RESET 0x02
+#define PHOENIX_GPIO_LED_OUTPUT_CODE_SOFT_RESET 0x03
+#define PHOENIX_GPIO_LED_OUTPUT_CODE_MAIN 0x04
+
+#endif
diff --git a/arch/mips/include/asm/rmi/interrupt.h b/arch/mips/include/asm/rmi/interrupt.h
new file mode 100644
index 0000000..9cfce6b
--- /dev/null
+++ b/arch/mips/include/asm/rmi/interrupt.h
@@ -0,0 +1,62 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_INTERRUPT_H
+#define _ASM_RMI_INTERRUPT_H
+
+#include <asm/rmi/rmicrf/config.h>
+
+/* Defines for the IRQ numbers */
+
+#define IRQ_DUMMY_UART           2
+#define IRQ_IPI_SMP_FUNCTION     3
+#define IRQ_IPI_SMP_RESCHEDULE   4
+#define IRQ_REMOTE_DEBUG         5
+#define IRQ_MSGRING              6
+#define IRQ_TIMER                7
+#define IRQ_IPI_SMP_KGDB   		50
+#define IRQ_IPI_OPROFILE        51
+
+#define IRQ_IPI_CRF_MGMT_IPI	RMI_MANAGEMENT_IPI /* */
+#define IRQ_IPI_CRF_EVENTQ_IPI  RMI_EVENTQ_IPI
+
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+
+#define IRQ_IPI_NETRX           49
+#define SMP_NETRX_IPI           32
+
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
+
+#define SMP_CALL_KGDB_HOOK 	8
+#define SMP_OPROFILE_IPI        16
+
+
+#endif
diff --git a/arch/mips/include/asm/rmi/io.h b/arch/mips/include/asm/rmi/io.h
new file mode 100644
index 0000000..d0ab8cb
--- /dev/null
+++ b/arch/mips/include/asm/rmi/io.h
@@ -0,0 +1,53 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_IO_H
+#define _ASM_RMI_IO_H
+
+extern void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long max);
+extern void pci_iounmap(struct pci_dev *dev, void __iomem *);
+
+#define __raw_writeb(v,a)       (*(volatile unsigned char  *)(a) = (v))
+#define __raw_writew(v,a)       (*(volatile unsigned short *)(a) = (v))
+#define __raw_writel(v,a)       (*(volatile unsigned int   *)(a) = (v))
+
+#define __raw_readb(a)          (*(volatile unsigned char  *)(a))
+#define __raw_readw(a)          (*(volatile unsigned short *)(a))
+#define __raw_readl(a)          (*(volatile unsigned int   *)(a))
+
+#define ioread8(p)  ({ unsigned int __v = __raw_readb(p); __v; })
+#define ioread16(p) ({ unsigned int __v = le16_to_cpu(__raw_readw(p)); __v; })
+#define ioread32(p) ({ unsigned int __v = le32_to_cpu(__raw_readl(p)); __v; })
+
+#define iowrite8(v,p)   __raw_writeb(v, p)
+#define iowrite16(v,p)  __raw_writew(cpu_to_le16(v), p)
+#define iowrite32(v,p)  __raw_writel(cpu_to_le32(v), p)
+
+#endif
diff --git a/arch/mips/include/asm/rmi/iomap.h b/arch/mips/include/asm/rmi/iomap.h
new file mode 100644
index 0000000..19b4f72
--- /dev/null
+++ b/arch/mips/include/asm/rmi/iomap.h
@@ -0,0 +1,299 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RFI_IO_H
+#define _ASM_RFI_IO_H
+
+#if !defined(CONFIG_RMI_XLP)
+#define DEFAULT_PHOENIX_IO_BASE 0xffffffffbef00000ULL
+#define PHOENIX_IO_DDR2_CHN0_OFFSET       0x01000
+#define PHOENIX_IO_DDR2_CHN1_OFFSET       0x02000
+#define PHOENIX_IO_DDR2_CHN2_OFFSET       0x03000
+#define PHOENIX_IO_DDR2_CHN3_OFFSET       0x04000
+#define PHOENIX_IO_PIC_OFFSET             0x08000
+#define PHOENIX_IO_UART_0_OFFSET          0x14000
+#define PHOENIX_IO_UART_1_OFFSET          0x15100
+
+#else
+#define DEFAULT_PHOENIX_IO_BASE 0xffffffffb8000000ULL
+#define PHOENIX_IO_DDR2_CHN0_OFFSET       0x14000
+#define PHOENIX_IO_DDR2_CHN1_OFFSET       0x15000
+#define PHOENIX_IO_DDR2_CHN2_OFFSET       0x16000
+#define PHOENIX_IO_DDR2_CHN3_OFFSET       0x17000
+#define PHOENIX_IO_PIC_OFFSET             0x04000
+#define PHOENIX_IO_UART_0_OFFSET          0x30100
+#define PHOENIX_IO_UART_1_OFFSET          0x31100
+#endif /* CONFIG_RMI_XLP */
+
+#define PHOENIX_IO_SIZE                   0x1000
+
+#define PHOENIX_IO_BRIDGE_OFFSET          0x00000
+
+#define PHOENIX_IO_RLD2_CHN0_OFFSET       0x05000
+#define PHOENIX_IO_RLD2_CHN1_OFFSET       0x06000
+
+#define PHOENIX_IO_SRAM_OFFSET            0x07000
+
+#define PHOENIX_IO_PCIX_OFFSET            0x09000
+#define PHOENIX_IO_HT_OFFSET              0x0A000
+
+#define PHOENIX_IO_SECURITY_OFFSET        0x0B000
+
+#define PHOENIX_IO_GMAC_0_OFFSET          0x0C000
+#define PHOENIX_IO_GMAC_1_OFFSET          0x0D000
+#define PHOENIX_IO_GMAC_2_OFFSET          0x0E000
+#define PHOENIX_IO_GMAC_3_OFFSET          0x0F000
+
+#ifdef XLS
+#define PHOENIX_IO_GMAC_4_OFFSET          0x20000
+#define PHOENIX_IO_GMAC_5_OFFSET          0x21000
+#define PHOENIX_IO_GMAC_6_OFFSET          0x22000
+#define PHOENIX_IO_GMAC_7_OFFSET          0x23000
+
+#define PHOENIX_IO_PCIE_0_OFFSET          0x1E000
+#define PHOENIX_IO_PCIE_1_OFFSET          0x1F000
+#define PHOENIX_IO_SRIO_0_OFFSET          0x1E000
+#define PHOENIX_IO_SRIO_1_OFFSET          0x1F000
+
+#define PHOENIX_IO_USB_0_OFFSET           0x24000
+#define PHOENIX_IO_USB_1_OFFSET           0x25000
+
+#define PHOENIX_IO_COMP_OFFSET            0x1D000
+
+#endif /* XLS */
+
+#define PHOENIX_IO_SPI4_0_OFFSET          0x10000
+#define PHOENIX_IO_XGMAC_0_OFFSET         0x11000
+#define PHOENIX_IO_SPI4_1_OFFSET          0x12000
+#define PHOENIX_IO_XGMAC_1_OFFSET         0x13000
+
+#define PHOENIX_IO_I2C_0_OFFSET           0x16000
+#define PHOENIX_IO_I2C_1_OFFSET           0x17000
+
+#define PHOENIX_IO_GPIO_OFFSET            0x18000
+
+#define PHOENIX_IO_FLASH_OFFSET           0x19000
+
+#define PHOENIX_IO_TB_OFFSET           	  0x1C000
+
+#define PHOENIX_CPLD_OFFSET               0xffffffffbd840000ULL
+
+/* Base Address (Virtual) of the PCI Config address space
+ * For now, choose 256M phys in kseg1 = 0xA0000000 + (1<<28)
+ * Config space spans 256 (num of buses) * 256 (num functions) * 256 bytes
+ * ie 1<<24 = 16M
+ */ 
+#define DEFAULT_PCI_CONFIG_BASE         0x18000000
+#define DEFAULT_HT_TYPE0_CFG_BASE       0x16000000
+#define DEFAULT_HT_TYPE1_CFG_BASE       0x17000000
+
+#ifndef __ASSEMBLY__
+
+#include <linux/types.h>
+#include <asm/byteorder.h>
+
+typedef volatile __u32 phoenix_reg_t;
+extern unsigned long phoenix_io_base;
+
+#define phoenix_io_mmio(offset) ((phoenix_reg_t *)(phoenix_io_base+(offset)))
+
+/* XLP_MERGE_TODO */
+#if defined(RMI_BRIDGE_WKAROUND)
+#include "rmi_rw_lock.h"
+extern rmi_rwlock_t *rmi_bridge_lock;
+extern int rmi_enable_br_wrkaround;
+
+static inline void rmi_preempt_enable(void)
+{
+    uint32_t status=0;
+    __asm__ volatile(
+#ifdef CONFIG_64BIT
+            "lw %0, 36($28)\n"
+#else
+            "lw %0, 20($28)\n"
+#endif
+            "addiu %0, %0, -1 \n"
+#ifdef CONFIG_64BIT
+            "sw %0, 36($28) \n"
+#else
+            "sw %0, 20($28) \n"
+#endif
+            :"=r"(status)
+            );    
+}
+
+static inline void rmi_preempt_disable(void)
+{
+    uint32_t status=0;
+    __asm__ volatile(
+#ifdef CONFIG_64BIT
+            "lw %0, 36($28)\n"
+#else
+            "lw %0, 20($28)\n"
+#endif
+            "addiu %0, %0, 1 \n"
+#ifdef CONFIG_64BIT
+            "sw %0, 36($28) \n"
+#else
+            "sw %0, 20($28) \n"
+#endif
+            :"=r"(status)
+            );    
+}
+
+static inline uint32_t rmi_br_read_lock(void)
+{
+    uint32_t ret = 0;
+	if(rmi_enable_br_wrkaround){
+         rmi_preempt_disable();
+		 ret = rmi_read_lock_irq_save(rmi_bridge_lock);
+         rmi_preempt_enable();
+    }
+	return ret;
+}
+static inline void rmi_br_read_unlock(unsigned int flags)
+{
+	if(rmi_enable_br_wrkaround){
+        rmi_preempt_disable();
+		rmi_read_unlock_irq_restore(rmi_bridge_lock, flags);
+        rmi_preempt_enable();
+    }
+}
+
+static inline uint32_t rmi_br_write_lock(void)
+{
+    uint32_t ret = 0;
+	if(rmi_enable_br_wrkaround){
+        rmi_preempt_disable();
+		ret = rmi_write_lock_irq_save(rmi_bridge_lock);
+        rmi_preempt_enable();
+    }
+	return ret;
+}
+
+static inline void rmi_br_write_unlock(unsigned int flags)
+{
+	if(rmi_enable_br_wrkaround){
+        rmi_preempt_disable();
+		rmi_write_unlock_irq_restore(rmi_bridge_lock, flags);
+        rmi_preempt_enable();
+    }
+}
+
+static inline uint32_t rmi_read_reg_locked(phoenix_reg_t *base, 
+		unsigned int offset) 	
+{
+	unsigned int flags, val;
+
+	flags = rmi_br_read_lock();
+	val = (be32_to_cpu((base)[(offset)])); 
+	rmi_br_read_unlock(flags);
+
+	return val;
+}
+static inline uint32_t rmi_read_reg_le_locked(phoenix_reg_t *base, 
+		unsigned int offset) 	
+{
+	unsigned int flags, val;
+	flags = rmi_br_read_lock();
+	val = (le32_to_cpu((base)[(offset)])); 
+	rmi_br_read_unlock(flags);
+
+	return val;
+}
+static inline void rmi_write_reg_locked(phoenix_reg_t *base, 
+		 unsigned int offset,  unsigned int value)
+{
+	unsigned int flags;
+	flags = rmi_br_write_lock();
+	((base)[(offset)] = cpu_to_be32((value)));
+	rmi_br_write_unlock(flags);
+}
+
+static inline void rmi_write_reg_le_locked(phoenix_reg_t *base, 
+		 unsigned int offset,  unsigned int value)
+{
+	unsigned int flags;
+	flags = rmi_br_write_lock();
+	((base)[(offset)] = cpu_to_le32((value)));
+	rmi_br_write_unlock(flags);
+}
+
+#define phoenix_read_reg(base, offset) rmi_read_reg_locked(base, offset)
+#define phoenix_write_reg(base, offset, value) \
+	rmi_write_reg_locked(base, offset, value)
+
+#define phoenix_read_reg_le32(base, offset) \
+	rmi_read_reg_le_locked(base, offset)
+#define phoenix_write_reg_le32(base, offset, value) \
+	rmi_write_reg_le_locked(base, offset, value)
+
+#else /* RMI_BRIDGE_WORKAROUND */
+
+static inline uint32_t rmi_br_read_lock(void) 
+{
+	return 0;
+}
+
+static inline void rmi_br_read_unlock(unsigned int flags)
+{
+}
+
+static inline uint32_t rmi_br_write_lock(void)
+{
+	return 0;
+}
+
+static inline void rmi_br_write_unlock(unsigned int flags)
+{
+}
+#ifdef CONFIG_CPU_LITTLE_ENDIAN
+
+#define phoenix_read_reg(base, offset) ((base)[(offset)])
+#define phoenix_write_reg(base, offset, value) ((base)[(offset)] = (value))
+
+#else
+
+#define phoenix_read_reg(base, offset) (be32_to_cpu((base)[(offset)]))
+#define phoenix_write_reg(base, offset, value) ((base)[(offset)] = cpu_to_be32((value)))
+
+#endif
+
+#define phoenix_read_reg_le32(base, offset) (le32_to_cpu((base)[(offset)]))
+#define phoenix_write_reg_le32(base, offset, value) \
+	((base)[(offset)] = cpu_to_le32((value)))
+
+#endif /* RMI_BRIDGE_WORKAROUND */
+
+extern void on_chip_init(void);
+
+#endif /* __ASSEMBLY__ */
+
+#endif
diff --git a/arch/mips/include/asm/rmi/linux_crf.h b/arch/mips/include/asm/rmi/linux_crf.h
new file mode 100644
index 0000000..02049f4
--- /dev/null
+++ b/arch/mips/include/asm/rmi/linux_crf.h
@@ -0,0 +1,80 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMICRF_LINUX_H
+#define _RMICRF_LINUX_H
+#include <asm/rmi/msgring.h>
+
+extern void fdt_parse_args(void);
+extern int fdt_get_core_tlb_size(int core);
+extern int fdt_add_console_string(char *cmdline);
+extern int fdt_get_pic_timer_map(unsigned int *timer_list, int max);
+extern int fdt_get_gmac_pde_reginfo(int id, uint64_t *);
+extern int fdt_get_xgmac_pde_reginfo(int id, uint64_t *);
+extern int fdt_get_spi4_pde_reginfo(int id, uint64_t *);
+extern uint64_t fdt_get_heap_size(void);
+extern int fdt_get_uart_status(int uartno);
+extern uint64_t fdt_get_vuart_fifo_addr(int tx, int instance);
+extern int fdt_get_msgring_int_status(int core, uint32_t *en);
+extern int fdt_get_core_bucket_conf(int core, char buckets[], int bklen, char credits[][8], int crlen);
+extern int fdt_get_bucketmask(uint64_t *);
+extern int fdt_get_sae_bucket_conf(char buckets[], int bklen, char credits[][8], int crlen);
+extern int fdt_get_cde_bucket_conf(char buckets[], int bklen, char credits[][8], int crlen);
+extern int fdt_get_sae_enabled(void);
+extern int fdt_get_cde_enabled(void);
+
+extern void *rmi_get_usermac_addr(int size);
+extern uint32_t dev_tree_en;
+extern uint32_t rmik_en;
+extern uint32_t rmik_cpu_msgring_int_mask[];
+
+extern void rmik_wakeup_cpus(void *fn, void *args, uint32_t cpu_mask);
+extern void config_net_init(void);
+extern void rmik_init(char *g_argv[], int *argc, char *g_envp[]);
+extern void rmik_cpu_to_cpu_msgring_handler(int bucket, int size, int code,
+				    int stid, struct msgrng_msg *msg,
+				    void *data /* ignored */ );
+extern void rmik_config_pde(int type, int instance, phoenix_reg_t *mmio);
+extern void rmik_eventq_ipi_handler(void);
+extern void rmik_cpu_to_cpu_pkt_msgring_handler(int size, struct msgrng_msg *msg);
+extern void rmik_vmips_init(void);
+extern void rmik_phoenix_msgring_cpu_init(void);
+extern int rmik_own_bucket_list_get(int *start, int *end, int *mask);
+extern int rmik_derive_msgring_int_mask(void);
+extern void rmik_register_net_events(void);
+extern int rmik_get_free_running_timer(void);
+extern void (*rmi_vnet_pkt_event_handler)(int len, void *msg);
+extern uint64_t rmik_get_pde_bktmap(int type, int instance);
+#endif
diff --git a/arch/mips/include/asm/rmi/memory-exclusion.h b/arch/mips/include/asm/rmi/memory-exclusion.h
new file mode 100644
index 0000000..3a6730e
--- /dev/null
+++ b/arch/mips/include/asm/rmi/memory-exclusion.h
@@ -0,0 +1,38 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_2#**********************************/
+
+#ifndef PHNX_MEMORY_EXCLUSION
+#define PHNX_MEMORY_EXCLUSION
+
+#define PHNX_RMIOS_TCPIP_START  (8<<20)
+#define PHNX_RMIOS_TCPIP_END    (96<<20)
+
+#define PHNX_RMIOS_IPSEC_START  (1<<20)
+#define PHNX_RMIOS_IPSEC_END    (51<<20)
+
+#define PHNX_RMIOS_LIB_START    (16<<20)
+#define PHNX_RMIOS_LIB_END	(51<<20)
+
+#endif
diff --git a/arch/mips/include/asm/rmi/mips-exts.h b/arch/mips/include/asm/rmi/mips-exts.h
new file mode 100644
index 0000000..b705cf2
--- /dev/null
+++ b/arch/mips/include/asm/rmi/mips-exts.h
@@ -0,0 +1,413 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_MIPS_EXTS_H
+#define _ASM_RMI_MIPS_EXTS_H
+
+#define PHOENIX_OSS_SEL_TLB_STATS 0
+#define PHOENIX_OSS_SEL_UNUSED 1
+#define PHOENIX_OSS_SEL_PAGEMASK 2
+#define PHOENIX_OSS_SEL_VADDR 3
+#define PHOENIX_OSS_SEL_PFN0 4
+#define PHOENIX_OSS_SEL_PFN1 5
+#define PHOENIX_OSS_SEL_K0 6
+#define PHOENIX_OSS_SEL_K1 7
+
+#define OS_SCRATCH_REG0	22, 0
+#define OS_SCRATCH_REG1	22, 1
+#define OS_SCRATCH_REG2	22, 2
+#define OS_SCRATCH_REG3	22, 3
+#define OS_SCRATCH_REG4	22, 4
+#define OS_SCRATCH_REG5	22, 5
+#define OS_SCRATCH_REG6	22, 6
+#define OS_SCRATCH_REG7	22, 7
+
+#define OS_KGDB_SCRATCH_REG6	$22, 6
+#define OS_KGDB_SCRATCH_REG7	$22, 7
+
+#ifndef __ASSEMBLY__
+
+#include <linux/types.h>
+#include <asm/rmi/interrupt.h>
+#include <asm/rmi/rmicrf/config.h>
+
+/* Scratch registers used */
+#define RMI_TLB_STATS_SCRATCH_REG_SEL  2
+#define RMI_HTLB_PMASK_SCRATCH_REG_SEL 3
+#define RMI_CRF_PERF0_SCRATCH_REG_SEL  RMI_PERF0_SCRATCH
+#define RMI_CRF_PERF1_SCRATCH_REG_SEL  RMI_PERF1_SCRATCH
+
+
+#define DMFC0_AT_EIRR 0x40214806
+#define DMFC0_AT_EIMR 0x40214807
+#define DMTC0_AT_EIRR 0x40a14806
+#define DMTC0_AT_EIMR 0x40a14807
+
+/* functions to write to and read from the extended
+ * cp0 registers.
+ * EIRR : Extended Interrupt Request Register
+ *        cp0 register 9 sel 6
+ *        bits 0...7 are same as cause register 8...15
+ * EIMR : Extended Interrupt Mask Register
+ *        cp0 register 9 sel 7
+ *        bits 0...7 are same as status register 8...15
+ */
+
+static inline __u64 read_64bit_cp0_eirr(void)
+{
+  __u32 high, low;
+
+  __asm__ __volatile__ (
+			".set push\n"
+			".set noreorder\n"
+			".set noat\n"
+			".set mips4\n"
+
+			".word 0x40214806  \n\t"
+			"nop               \n\t"
+			"dsra32 %0, $1, 0  \n\t"
+			"sll    %1, $1, 0  \n\t"
+
+			".set pop\n"
+
+			: "=r" (high), "=r" (low)
+			);
+
+  return ( ((__u64)high) << 32) | low;
+}
+
+static inline __u64 read_64bit_cp0_eimr(void)
+{
+  __u32 high, low;
+
+  __asm__ __volatile__ (
+			".set push\n"
+			".set noreorder\n"
+			".set noat\n"
+			".set mips4\n"
+
+			".word 0x40214807  \n\t"
+			"nop               \n\t"
+			"dsra32 %0, $1, 0  \n\t"
+			"sll    %1, $1, 0  \n\t"
+
+			".set pop\n"
+
+			: "=r" (high), "=r" (low)
+			);
+
+  return ( ((__u64)high) << 32) | low;
+}
+
+static inline void write_64bit_cp0_eirr(__u64 value)
+{
+  __u32 low, high;
+
+  high = value >> 32;
+  low  = value & 0xffffffff;
+
+	__asm__ __volatile__ (
+	".set push\n"
+	".set noreorder\n"
+	".set noat\n"
+	".set mips4\n\t"
+
+	"dsll32 $2, %1, 0  \n\t"
+	"dsll32 $1, %0, 0  \n\t"
+	"dsrl32 $2, $2, 0  \n\t"
+	"or     $1, $1, $2 \n\t"
+	".word  0x40a14806 \n\t"
+	"nop               \n\t"
+
+	".set pop\n"
+
+	:
+	: "r" (high), "r" (low)
+	: "$1", "$2");
+}
+
+static inline void write_64bit_cp0_eimr(__u64 value)
+{
+  __u32 low, high;
+
+  high = value >> 32;
+  low  = value & 0xffffffff;
+
+	__asm__ __volatile__ (
+	".set push\n"
+	".set noreorder\n"
+	".set noat\n"
+	".set mips4\n\t"
+
+	"dsll32 $2, %1, 0  \n\t"
+	"dsll32 $1, %0, 0  \n\t"
+	"dsrl32 $2, $2, 0  \n\t"
+	"or     $1, $1, $2 \n\t"
+	".word  0x40a14807 \n\t"
+	"nop               \n\t"
+
+	".set pop\n"
+
+	:
+	: "r" (high), "r" (low)
+	: "$1", "$2");
+}
+
+static __inline__ int ldadd_w(unsigned int value, volatile int *addr)
+{
+	unsigned long res;
+  __asm__ __volatile__(
+		       ".set push\n"
+		       ".set noreorder\n"
+		       "move $8, %2\n"
+		       "move $9, %3\n"
+		       //"ldaddw %2, %3\n"
+                       ".word 0x71280010\n"
+		       "move %0, $8\n"
+		       ".set pop\n"
+		       :"=r"(res), "+m"(*addr)
+		       : "r" (value), "r"((unsigned long)addr)
+		       : "$8", "$9"
+		       );
+  return res;
+}
+
+static __inline__ void ldadd_w_no_read(int value, volatile int *addr)
+{
+	unsigned long res;
+  __asm__ __volatile__(
+                       ".set push\n"
+                       ".set noreorder\n"
+                       "move $8, %2\n"
+                       "move $9, %3\n"
+                       //"ldaddw $8, $9\n"
+                       ".word 0x71280010\n"
+                       //"move %0, $8\n"
+                       ".set pop\n"
+                       :"=r"(res), "+m"(*addr)
+                       : "r" (value), "r"((unsigned long)addr)
+                       : "$8", "$9"
+                       );
+}
+
+static __inline__ unsigned int ldadd_wu(unsigned int value, volatile unsigned int *addr)
+{
+	unsigned long res;
+  __asm__ __volatile__(
+		       ".set push\n"
+		       ".set noreorder\n"
+		       "move $8, %2\n"
+		       "move $9, %3\n"
+		       //"ldaddwu $8, $9\n"
+                       ".word 0x71280011\n"
+		       "move %0, $8\n"
+		       ".set pop\n"
+		       :"=r"(res), "+m"(*addr)
+		       : "r"(value), "r"((unsigned long)addr)
+		       : "$8", "$9"
+		       );
+  return res;
+}
+
+static __inline__ void ldadd_wu_no_read(unsigned int value,
+					volatile unsigned int *addr)
+{
+	unsigned long res;
+  __asm__ __volatile__(
+                       ".set push\n"
+                       ".set noreorder\n"
+                       "move $8, %2\n"
+                       "move $9, %3\n"
+                       //"ldaddwu $8, $9\n"
+                       ".word 0x71280011\n"
+                       //"move %0, $8\n"
+                       ".set pop\n"
+                       :"=r"(res), "+m"(*addr)
+                       : "r"(value), "r"((unsigned long)addr)
+                       : "$8", "$9"
+                       );
+}
+
+#define phoenix_cpu_id()                                        \
+({int __id;                                                     \
+ __asm__ __volatile__ (                                         \
+		       ".set push\n"                            \
+		       ".set noreorder\n"                       \
+                       ".set mips32\n"                          \
+                       "mfc0 $8, $15, 1\n"                      \
+		       "andi $8, $8, 0x3ff\n"                   \
+		       "srl %0, $8, 1\n"                        \
+		       ".set pop\n"                             \
+		       : "=r" (__id) : : "$8");                 \
+ __id;})
+
+#define phoenix_thr_id()                                        \
+({int __id;                                                     \
+ __asm__ __volatile__ (                                         \
+		       ".set push\n"                            \
+		       ".set noreorder\n"                       \
+                       ".set mips32\n"                          \
+                       "mfc0 $8, $15, 1\n"                      \
+		       "andi %0, $8, 0x3\n"                     \
+		       ".set pop\n"                             \
+		       : "=r" (__id) : : "$8");                 \
+ __id;})
+
+#define phoenix_cpu_to_thrid(cpu) (phys_proc_id[(cpu)] >> 2)
+#define phoenix_cpu_to_cpuid(cpu) (phys_proc_id[(cpu)] & 0x3)
+
+#define CPU_BLOCKID_IFU      0
+#define CPU_BLOCKID_ICU      1
+#define CPU_BLOCKID_IEU      2
+#define CPU_BLOCKID_LSU      3
+#define CPU_BLOCKID_MMU      4
+#define CPU_BLOCKID_PRF      5
+
+#define LSU_CERRLOG_REGID    9
+
+static __inline__ unsigned int read_32bit_phnx_ctrl_reg(int block, int reg)
+{
+  unsigned int __res;
+
+  __asm__ __volatile__(
+		       ".set\tpush\n\t"
+		       ".set\tnoreorder\n\t"
+		       "move $9, %1\n"
+/* 		       "mfcr\t$8, $9\n\t"          */
+		       ".word 0x71280018\n"
+		       "move %0, $8\n"
+		       ".set\tpop"
+		       : "=r" (__res) : "r"((block<<8)|reg)
+		       : "$8", "$9"
+		       );
+  return __res;
+}
+
+static __inline__ void write_32bit_phnx_ctrl_reg(int block, int reg, unsigned int value)
+{
+  __asm__ __volatile__(
+		       ".set\tpush\n\t"
+		       ".set\tnoreorder\n\t"
+		       "move $8, %0\n"
+		       "move $9, %1\n"
+/* 		       "mtcr\t$8, $9\n\t"  */
+		       ".word 0x71280019\n"
+		       ".set\tpop"
+		       :
+		       : "r" (value), "r"((block<<8)|reg)
+		       : "$8", "$9"
+		       );
+}
+
+static __inline__ unsigned long long read_64bit_phnx_ctrl_reg(int block, int reg)
+{
+	unsigned int high, low;
+
+	__asm__ __volatile__(
+		".set\tmips64\n\t"
+		"move    $9, %2\n"
+		/* "mfcr    $8, $9\n" */
+		".word   0x71280018\n"
+		"dsrl32  %0, $8, 0\n\t"
+		"dsll32  $8, $8, 0\n\t"
+		"dsrl32  %1, $8, 0\n\t"
+		".set mips0"
+		: "=r" (high), "=r"(low)
+		: "r"((block<<8)|reg)
+		: "$8", "$9"
+		);
+
+	return ( (((unsigned long long)high)<<32) | low);
+}
+
+static __inline__ void write_64bit_phnx_ctrl_reg(int block, int reg,unsigned long long value)
+{
+	__u32 low, high;
+	high = value >> 32;
+	low = value & 0xffffffff;
+
+	__asm__ __volatile__(
+		".set push\n"
+		".set noreorder\n"
+		".set mips4\n\t"
+		/* Set up "rs" */
+		"move $9, %0\n"
+
+		/* Store 64 bit value in "rt" */
+		"dsll32 $10, %1, 0  \n\t"
+		"dsll32 $8, %2, 0  \n\t"
+		"dsrl32 $8, $8, 0  \n\t"
+		"or     $8, $10, $8 \n\t"
+
+		".word 0x71280019\n" /* mtcr $8, $9 */
+
+		".set pop\n"
+
+		:  /* No outputs */
+		: "r"((block<<8)|reg), "r" (high), "r" (low)
+		: "$8", "$9", "$10"
+		);
+}
+
+typedef struct { volatile int value; } phnx_atomic_t;
+
+static __inline__ int phnx_test_and_set(phnx_atomic_t *lock)
+{
+  int oldval = 0;
+
+  __asm__ __volatile__ (".set push\n"
+			".set noreorder\n"
+			"move $9, %2\n"
+			"li $8, 1\n"
+			//"swapw $8, $9\n"
+			".word 0x71280014\n"
+			"move %1, $8\n"
+			".set pop\n"
+			: "+m" (lock->value), "=r" (oldval)
+			: "r" ((unsigned long)&lock->value)
+			: "$8", "$9"
+			);
+  return (oldval == 0 ? 1/*success*/ : 0/*failure*/);
+}
+
+#define rmi_write_os_scratch_2(val)	__write_64bit_c0_register($22, 2, val)
+#define rmi_read_os_scratch_2()	__read_64bit_c0_register($22, 2)
+
+#define rmi_write_os_scratch_3(val)	__write_64bit_c0_register($22, 3, val)
+#define rmi_read_os_scratch_3()	__read_64bit_c0_register($22, 3)
+#endif
+
+#ifdef CONFIG_CPU_XLP
+#define SET_MIPS64 .set mips64r2
+#else
+#define SET_MIPS64 .set mips64
+#endif
+
+#endif /* _ASM_RMI_MIPS_EXTS_H */
diff --git a/arch/mips/include/asm/rmi/msgring.h b/arch/mips/include/asm/rmi/msgring.h
new file mode 100644
index 0000000..3bd62fd
--- /dev/null
+++ b/arch/mips/include/asm/rmi/msgring.h
@@ -0,0 +1,692 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_MSG_RING_H
+#define _ASM_RMI_MSG_RING_H
+
+#include <linux/types.h>
+
+#include <asm/asm.h>
+#include <asm/rmi/debug.h>
+#include <asm/rmi/mips-exts.h>
+
+#ifndef __STR
+#define __STR(x) #x
+#endif
+#ifndef STR
+#define STR(x) __STR(x)
+#endif
+
+#define find_msb_one_bit(source)                                \
+({ uint64_t __res;                                              \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\tnoreorder\n\t"					\
+        "dlco\t$8, %1\n\t"                                      \
+	".set\tpop"						\
+        : "=r" (__res): "r" (source): "$8"                      \
+        );                                                      \
+        __res;})
+
+#define read_32bit_cp2_register(source)                         \
+({ int __res;                                                   \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        "mfc2\t%0,"STR(source)"\n\t"                            \
+	".set\tpop"						\
+        : "=r" (__res));                                        \
+        __res;})
+
+#define write_32bit_cp2_register(register,value)                \
+        __asm__ __volatile__(                                   \
+        "mtc2\t%0,"STR(register)"\n\t"				\
+	"nop"							\
+        : : "r" (value));
+
+#define read_32bit_cp2_register_sel(source, sel)                \
+({ int __res;                                                   \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips32\n\t"                                       \
+        "mfc2\t%0,"STR(source)", %1\n\t"                        \
+	".set\tpop"						\
+        : "=r" (__res) : "i" (sel) );                           \
+        __res;})
+
+#define write_32bit_cp2_register_sel(reg, value, sel)           \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips32\n\t"                                       \
+        "mtc2\t%0,"STR(reg)", %1\n\t"                           \
+	".set\tpop"						\
+        : : "r" (value), "i" (sel) );
+
+#define MSGRNG_TX_BUF_REG $0
+#define MSGRNG_RX_BUF_REG $1
+
+#define MSGRNG_MSG_STATUS_REG $2
+#define MSGRNG_MSG_CONFIG_REG $3
+
+#define MSGRNG_MSG_BUCKSIZE_REG $4
+
+#define MSGRNG_CC_0_REG  $16
+#define MSGRNG_CC_1_REG  $17
+#define MSGRNG_CC_2_REG  $18
+#define MSGRNG_CC_3_REG  $19
+#define MSGRNG_CC_4_REG  $20
+#define MSGRNG_CC_5_REG  $21
+#define MSGRNG_CC_6_REG  $22
+#define MSGRNG_CC_7_REG  $23
+#define MSGRNG_CC_8_REG  $24
+#define MSGRNG_CC_9_REG  $25
+#define MSGRNG_CC_10_REG $26
+#define MSGRNG_CC_11_REG $27
+#define MSGRNG_CC_12_REG $28
+#define MSGRNG_CC_13_REG $29
+#define MSGRNG_CC_14_REG $30
+#define MSGRNG_CC_15_REG $31
+
+#define msgrng_read_status() read_32bit_cp2_register(MSGRNG_MSG_STATUS_REG)
+
+#define msgrng_read_config() read_32bit_cp2_register(MSGRNG_MSG_CONFIG_REG)
+#define msgrng_write_config(value) write_32bit_cp2_register(MSGRNG_MSG_CONFIG_REG, value)
+
+#define msgrng_read_bucksize(bucket) read_32bit_cp2_register_sel(MSGRNG_MSG_BUCKSIZE_REG, bucket)
+#define msgrng_write_bucksize(bucket, value) write_32bit_cp2_register_sel(MSGRNG_MSG_BUCKSIZE_REG, value, bucket)
+
+#define msgrng_read_cc(reg, pri) read_32bit_cp2_register_sel(reg, pri)
+#define msgrng_write_cc(reg, value, pri) write_32bit_cp2_register_sel(reg, value, pri)
+
+#ifndef _ABI64
+#define read_64bit_cp2_register_sel(source, sel)			\
+({									\
+	unsigned int high, low;						\
+									\
+		__asm__ __volatile__(					\
+			".set\tmips64\n\t"				\
+			"dmfc2\t$8, "STR(source)","STR(sel)"\n\t"		\
+			"dsrl32\t%0, $8, 0\n\t"			        \
+                        "dsll32\t$8, $8, 0\n\t"                         \
+                        "dsrl32\t%1, $8, 0\n\t"                         \
+			".set\tmips0"					\
+			: "=r" (high), "=r"(low): "i"(sel) : "$8");	\
+	( (((unsigned long long)high)<<32) | low);					\
+})
+
+#define write_64bit_cp2_register_sel(source, val, sel)			\
+do {									\
+     unsigned int high = val>>32;                                       \
+     unsigned int low  = val & 0xffffffff;                              \
+		__asm__ __volatile__(					\
+			".set\tmips64\n\t"				\
+                        "dsll32 $8, %1, 0\n"                            \
+                        "dsll32 $9, %0, 0\n"                            \
+                        "dsrl32 $8, $8, 0\n"                            \
+                        "or     $8, $8, $9\n"				\
+			"dmtc2\t$8, "STR(source)", %2\n\t"		\
+			".set\tmips0"					\
+			: : "r" (high), "r" (low), "i"(sel): "$8", "$9");		\
+} while (0)
+
+#else
+#define read_64bit_cp2_register(source)                         \
+({ unsigned long long __res;                                    \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        ".set\tmips64\n\t"                                      \
+        "dmfc2\t%0,"STR(source)"\n\t"                            \
+	".set\tpop"						\
+        : "=r" (__res));                                        \
+        __res;})
+
+#define write_64bit_cp2_register(register,value)                \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+	".set\treorder\n\t"					\
+        "dmtc2\t%0,"STR(register)"\n\t"				\
+	"nop"							\
+	".set\tpop"						\
+        : : "r" (value));
+
+#define read_64bit_cp2_register_sel(source, sel)                \
+({ unsigned long long __res;                                    \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips64\n\t"                                       \
+        "dmfc2\t%0,"STR(source)", %1\n\t"                        \
+	".set\tpop"						\
+        : "=r" (__res) : "i" (sel) );                           \
+        __res;})
+
+#define write_64bit_cp2_register_sel(reg, value, sel)           \
+        __asm__ __volatile__(                                   \
+	".set\tpush\n\t"					\
+        ".set mips64\n\t"                                       \
+        "dmtc2\t%0,"STR(reg)", %1\n\t"                           \
+	".set\tpop"						\
+        : : "r" (value), "i" (sel) );
+#endif
+
+#define msgrng_load_rx_msg0() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 0)
+#define msgrng_load_rx_msg1() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 1)
+#define msgrng_load_rx_msg2() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 2)
+#define msgrng_load_rx_msg3() read_64bit_cp2_register_sel(MSGRNG_RX_BUF_REG, 3)
+
+#define msgrng_load_tx_msg0(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 0)
+#define msgrng_load_tx_msg1(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 1)
+#define msgrng_load_tx_msg2(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 2)
+#define msgrng_load_tx_msg3(value) write_64bit_cp2_register_sel(MSGRNG_TX_BUF_REG, value, 3)
+
+/* Station IDs */
+#define MSGRNG_STNID_CPU0  0x00
+#define MSGRNG_STNID_CPU1  0x08
+#define MSGRNG_STNID_CPU2  0x10
+#define MSGRNG_STNID_CPU3  0x18
+#define MSGRNG_STNID_CPU4  0x20
+#define MSGRNG_STNID_CPU5  0x28
+#define MSGRNG_STNID_CPU6  0x30
+#define MSGRNG_STNID_CPU7  0x38
+
+#define MSGRING_STNID_DEVICES 64
+#define MSGRNG_STNID_XGS0_TX 64
+#define MSGRNG_STNID_XMAC0_00_TX 64
+#define MSGRNG_STNID_XMAC0_01_TX 65
+#define MSGRNG_STNID_XMAC0_02_TX 66
+#define MSGRNG_STNID_XMAC0_03_TX 67
+#define MSGRNG_STNID_XMAC0_04_TX 68
+#define MSGRNG_STNID_XMAC0_05_TX 69
+#define MSGRNG_STNID_XMAC0_06_TX 70
+#define MSGRNG_STNID_XMAC0_07_TX 71
+#define MSGRNG_STNID_XMAC0_08_TX 72
+#define MSGRNG_STNID_XMAC0_09_TX 73
+#define MSGRNG_STNID_XMAC0_10_TX 74
+#define MSGRNG_STNID_XMAC0_11_TX 75
+#define MSGRNG_STNID_XMAC0_12_TX 76
+#define MSGRNG_STNID_XMAC0_13_TX 77
+#define MSGRNG_STNID_XMAC0_14_TX 78
+#define MSGRNG_STNID_XMAC0_15_TX 79
+
+#define MSGRNG_STNID_XGS1_TX 80
+#define MSGRNG_STNID_XMAC1_00_TX 80
+#define MSGRNG_STNID_XMAC1_01_TX 81
+#define MSGRNG_STNID_XMAC1_02_TX 82
+#define MSGRNG_STNID_XMAC1_03_TX 83
+#define MSGRNG_STNID_XMAC1_04_TX 84
+#define MSGRNG_STNID_XMAC1_05_TX 85
+#define MSGRNG_STNID_XMAC1_06_TX 86
+#define MSGRNG_STNID_XMAC1_07_TX 87
+#define MSGRNG_STNID_XMAC1_08_TX 88
+#define MSGRNG_STNID_XMAC1_09_TX 89
+#define MSGRNG_STNID_XMAC1_10_TX 90
+#define MSGRNG_STNID_XMAC1_11_TX 91
+#define MSGRNG_STNID_XMAC1_12_TX 92
+#define MSGRNG_STNID_XMAC1_13_TX 93
+#define MSGRNG_STNID_XMAC1_14_TX 94
+#define MSGRNG_STNID_XMAC1_15_TX 95
+
+#define MSGRNG_STNID_GMAC 96
+#define MSGRNG_STNID_GMACRFR_0  97
+#define MSGRNG_STNID_GMACTX0  98
+#define MSGRNG_STNID_GMACTX1  99
+#define MSGRNG_STNID_GMACTX2  100
+#define MSGRNG_STNID_GMACTX3  101
+#define MSGRNG_STNID_GMACRFR_1  103
+
+#define MSGRNG_STNID_DMA      104
+#define MSGRNG_STNID_DMA_0    104
+#define MSGRNG_STNID_DMA_1    105
+#define MSGRNG_STNID_DMA_2    106
+#define MSGRNG_STNID_DMA_3    107
+
+#define MSGRNG_STNID_XGS0FR 112
+#define MSGRNG_STNID_XMAC0RFR 113
+
+#define MSGRNG_STNID_XGS1FR 114
+#define MSGRNG_STNID_XMAC1RFR 115
+
+#define MSGRNG_STNID_SEC 120
+#define MSGRNG_STNID_SEC0 120
+#define MSGRNG_STNID_SEC1 121
+#define MSGRNG_STNID_SEC2 122
+#define MSGRNG_STNID_SEC3 123
+#define MSGRNG_STNID_PK0  124
+
+#define MSGRNG_STNID_GMAC1      80
+#define MSGRNG_STNID_GMAC1_FR   81
+#define MSGRNG_STNID_GMAC1_TX0  82
+#define MSGRNG_STNID_GMAC1_TX1  83
+#define MSGRNG_STNID_GMAC1_TX2  84
+#define MSGRNG_STNID_GMAC1_TX3  85
+#define MSGRNG_STNID_GMAC0      96
+#define MSGRNG_STNID_GMAC0_FR   97
+#define MSGRNG_STNID_GMAC0_TX0  98
+#define MSGRNG_STNID_GMAC0_TX1  99
+#define MSGRNG_STNID_GMAC0_TX2  100
+#define MSGRNG_STNID_GMAC0_TX3  101
+#define MSGRNG_STNID_CMP_0      108
+#define MSGRNG_STNID_CMP_1      109
+#define MSGRNG_STNID_CMP_2      110
+#define MSGRNG_STNID_CMP_3      111
+#define MSGRNG_STNID_PCIE_0     116
+#define MSGRNG_STNID_PCIE_1     117
+#define MSGRNG_STNID_PCIE_2     118
+#define MSGRNG_STNID_PCIE_3     119
+#define MSGRNG_STNID_XLS_PK0    121
+
+#define MSGRNG_CODE_DEVICE         0
+#define MSGRNG_CODE_MAC            MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_XGMAC          MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_SPI4           MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_SEC            MSGRNG_CODE_DEVICE
+#define MSGRNG_CODE_BOOT_WAKEUP    200
+
+static inline int msgrng_xgmac_stid_rfr(int id)
+{
+  return !id ? MSGRNG_STNID_XMAC0RFR : MSGRNG_STNID_XMAC1RFR;
+}
+
+static inline int msgrng_xgmac_stid_tx(int id)
+{
+  return !id ? MSGRNG_STNID_XMAC0_00_TX : MSGRNG_STNID_XMAC1_00_TX;
+}
+
+static inline int msgrng_gmac_stid_rfr(int id)
+{
+  if (id & 0x4)
+      return (MSGRNG_STNID_GMAC1_FR);
+  return (MSGRNG_STNID_GMACRFR_0);
+}
+
+static inline int msgrng_gmac_stid_rfr_split_mode(int id)
+{
+  return ((id>>1)?MSGRNG_STNID_GMACRFR_1:MSGRNG_STNID_GMACRFR_0);
+}
+
+static inline int msgrng_gmac_stid_tx(int id)
+{
+  if (id & 0x4)
+      return (MSGRNG_STNID_GMAC1_TX0 + (id & 0x3));
+  return (MSGRNG_STNID_GMACTX0 + id);
+}
+
+static inline int msgrng_gmac0_stid_rfr(int id)
+{
+  return (MSGRNG_STNID_GMAC0_FR);
+}
+static inline int msgrng_gmac0_stid_tx(int id)
+{
+  return (MSGRNG_STNID_GMAC0_TX0 + id);
+}
+static inline int msgrng_gmac1_stid_rfr(int id)
+{
+  return (MSGRNG_STNID_GMAC1_FR);
+}
+static inline int msgrng_gmac1_stid_tx(int id)
+{
+  return (MSGRNG_STNID_GMAC1_TX0 + (id & 0x3));
+}
+
+static inline void msgrng_send(unsigned int stid)
+{
+  __asm__ volatile (
+		    ".set push\n"
+		    ".set noreorder\n"
+		    "sync\n"
+		    //		    "msgsnd %0\n"
+		    "move  $8, %0\n"
+		    "c2    0x80001\n"
+		    ".set pop\n"
+		    : : "r" (stid) : "$8"
+		    );
+}
+
+static inline void msgrng_receive(unsigned int pri)
+{
+  __asm__ volatile (
+		    ".set push\n"
+		    ".set noreorder\n"
+		    //		    "msgld %0\n"
+		    "move $8, %0\n"
+		    "c2   0x80002\n"
+		    ".set pop\n"
+		    : : "r" (pri) : "$8"
+		    );
+}
+
+static inline void msgrng_wait(unsigned int mask)
+{
+  __asm__ volatile (
+		    ".set push\n"
+		    ".set noreorder\n"
+		    //		    "msgwait %0\n"
+		    "move $8, %0\n"
+		    /*to ensure msgwait picks up the right bucket */
+		    ""STR(PTR_ADDU)" $8, $8, $0\n"
+		    "c2   0x80003\n"
+		    ".set pop\n"
+		    : :"r" (mask) : "$8"
+		    );
+}
+
+#define msgrng_enable(flags)                \
+do {                                        \
+  preempt_disable(); \
+  __asm__ volatile (                        \
+		    ".set push\n\t"                 \
+		    ".set reorder\n\t"              \
+		    ".set noat\n\t"                 \
+		    "mfc0 %0, $12\n\t"              \
+		    "li  $8, 0x40000001\n\t"        \
+		    "or  $1, %0, $8\n\t"            \
+		    "xori $1, 1\n\t"                \
+		    ".set noreorder\n\t"            \
+		    "mtc0 $1, $12\n\t"              \
+		    ".set\tpop\n\t"                 \
+		    : "=r" (flags)                  \
+		    :                               \
+		    : "$8"                          \
+		    );                              \
+  preempt_enable(); \
+} while (0)
+
+#define msgrng_disable(flags) __asm__ volatile (    \
+                 "mtc0 %0, $12" : : "r" (flags))
+
+#define msgrng_flags_save(flags) msgrng_enable(flags)
+#define msgrng_flags_restore(flags) msgrng_disable(flags)
+
+struct msgrng_msg {
+  __u64 msg0;
+  __u64 msg1;
+  __u64 msg2;
+  __u64 msg3;
+};
+
+static inline void message_send_block_fast(int size, unsigned int code, unsigned int stid,
+                                         unsigned long long msg0, unsigned long long msg1,
+					 unsigned long long msg2, unsigned long long msg3)
+{
+  __asm__ __volatile__ (".set push\n"
+                        ".set noreorder\n"
+                        ".set mips64\n"
+                        "dmtc2 %1, "STR(MSGRNG_TX_BUF_REG)", 0\n"
+                        "dmtc2 %2, "STR(MSGRNG_TX_BUF_REG)", 1\n"
+                        "dmtc2 %3, "STR(MSGRNG_TX_BUF_REG)", 2\n"
+                        "dmtc2 %4, "STR(MSGRNG_TX_BUF_REG)", 3\n"
+		        "sync\n"
+                        "move $8, %0\n"
+                        "1: c2 0x80001\n"
+                        "mfc2 $8, "STR(MSGRNG_MSG_STATUS_REG)"\n"
+                        "andi $8, $8, 0x6\n"
+                        "bnez $8, 1b\n"
+                        "move $8, %0\n"
+                        ".set pop\n"
+                        :
+                        : "r"(((size-1)<<16)|(code<<8)|stid), "r" (msg0), "r" (msg1), "r"(msg2), "r"(msg3)
+                        : "$8"
+                        );
+}
+
+#define message_receive_fast(bucket, size, code, stid, msg0, msg1, msg2, msg3)      \
+        ( { unsigned int _status=0, _tmp=0;                     \
+           msgrng_receive(bucket);                              \
+           while ( (_status=msgrng_read_status()) & 0x08) ;     \
+           _tmp = _status & 0x30;                               \
+           if (likely(!_tmp)) {                                 \
+                 (size)=((_status & 0xc0)>>6)+1;                \
+                 (code)=(_status & 0xff00)>>8;                  \
+                 (stid)=(_status & 0x7f0000)>>16;               \
+                 (msg0)=msgrng_load_rx_msg0();                  \
+                 (msg1)=msgrng_load_rx_msg1();                  \
+                 (msg2)=msgrng_load_rx_msg2();                  \
+                 (msg3)=msgrng_load_rx_msg3();                  \
+                 _tmp=0;                                        \
+                }                                               \
+           _tmp;                                                \
+        } )
+
+static __inline__ int message_send(unsigned int size, unsigned int code,
+				   unsigned int stid, struct msgrng_msg *msg)
+{
+  unsigned int dest = 0;
+  unsigned long long status=0;
+  int i=0;
+
+  msgrng_load_tx_msg0(msg->msg0);
+  msgrng_load_tx_msg1(msg->msg1);
+  msgrng_load_tx_msg2(msg->msg2);
+  msgrng_load_tx_msg3(msg->msg3);
+
+  dest = ((size-1)<<16)|(code<<8)|(stid);
+
+  //dbg_msg("Sending msg<%Lx,%Lx,%Lx,%Lx> to dest = %x\n",
+    //msg->msg0, msg->msg1, msg->msg2, msg->msg3, dest);
+
+
+  for(i=0;i<16;i++) {
+  	msgrng_send(dest);
+	status = msgrng_read_status();
+//	dbg_msg("status = %Lx\n", status);
+
+	if (status & 0x6) {
+	  continue;
+	}
+	else break;
+	}
+    if (i==16) {
+	  if (dest == 0x61)
+		  //dbg_msg("Processor %x: Unable to send msg to %llx\n", processor_id(), dest);
+	  return status & 0x6;
+	}
+  return msgrng_read_status() & 0x06;
+}
+
+static __inline__ int message_send_retry(unsigned int size, unsigned int code,
+					 unsigned int stid,
+					 struct msgrng_msg *msg)
+{
+  int res = 0;
+  int retry = 0;
+
+  for(;;) {
+    res = message_send(size, code, stid, msg);
+    /* retry a pending fail */
+    if (res & 0x02) continue;
+    /* credit fail */
+    if (res & 0x04) retry++;
+    else break;
+    if (retry == 4) return res & 0x06;
+  }
+
+  return 0;
+}
+
+static __inline__ int message_receive(int pri, int *size, int *code, int *src_id,
+				      struct msgrng_msg *msg)
+{
+  int res = message_receive_fast(pri, *size, *code, *src_id, msg->msg0, msg->msg1, msg->msg2, msg->msg3);
+
+#ifdef MSGRING_DUMP_MESSAGES
+  if (!res) {
+    dbg_msg("Received msg <%llx, %llx, %llx, %llx> <%d,%d,%d>\n",
+	    msg->msg0, msg->msg1, msg->msg2, msg->msg3,
+	    *size, *code, *src_id);
+  }
+#endif
+
+  return res;
+}
+
+#define MSGRNG_STN_RX_QSIZE 256
+
+typedef unsigned short bucket_t;
+#define MAX_NUM_MSGRNG_STN_CC   128
+#define MAX_NUM_GMAC_STNS 8
+#define MAX_NUM_XGMAC_STNS 18
+#define NR_STNS_PER_CORE 8
+
+struct stn_cc {
+	bucket_t counters[16][8];
+};
+
+struct bucket_size {
+	bucket_t bucket[MAX_NUM_MSGRNG_STN_CC];
+};
+
+extern struct bucket_size bucket_sizes;
+
+extern struct stn_cc cc_table_cpu_0;
+extern struct stn_cc cc_table_cpu_1;
+extern struct stn_cc cc_table_cpu_2;
+extern struct stn_cc cc_table_cpu_3;
+extern struct stn_cc cc_table_cpu_4;
+extern struct stn_cc cc_table_cpu_5;
+extern struct stn_cc cc_table_cpu_6;
+extern struct stn_cc cc_table_cpu_7;
+extern struct stn_cc cc_table_xgs_0;
+extern struct stn_cc cc_table_xgs_1;
+extern struct stn_cc cc_table_gmac;
+extern struct stn_cc cc_table_dma;
+extern struct stn_cc cc_table_sec;
+
+extern struct bucket_size xls_bucket_sizes;
+extern struct stn_cc xls_cc_table_cpu_0;
+extern struct stn_cc xls_cc_table_cpu_1;
+extern struct stn_cc xls_cc_table_cpu_2;
+extern struct stn_cc xls_cc_table_cpu_3;
+extern struct stn_cc xls_cc_table_gmac0;
+extern struct stn_cc xls_cc_table_gmac1;
+extern struct stn_cc xls_cc_table_cmp;
+extern struct stn_cc xls_cc_table_pcie;
+extern struct stn_cc xls_cc_table_dma;
+extern struct stn_cc xls_cc_table_sec;
+
+extern struct bucket_size shared_bucket_sizes;
+
+extern struct stn_cc shared_cc_table_cpu_0;
+extern struct stn_cc shared_cc_table_cpu_1;
+extern struct stn_cc shared_cc_table_cpu_2;
+extern struct stn_cc shared_cc_table_cpu_3;
+extern struct stn_cc shared_cc_table_cpu_4;
+extern struct stn_cc shared_cc_table_cpu_5;
+extern struct stn_cc shared_cc_table_cpu_6;
+extern struct stn_cc shared_cc_table_cpu_7;
+extern struct stn_cc shared_cc_table_gmac;
+extern struct stn_cc shared_cc_table_dma;
+
+
+#define msgrng_access_save(lock, iflags, mflags) do {        \
+  spin_lock_irqsave(lock, iflags);                           \
+  msgrng_flags_save(mflags);                                 \
+ }while(0)
+
+#define msgrng_access_restore(lock, iflags, mflags) do {     \
+  msgrng_flags_restore(mflags);                              \
+  spin_unlock_irqrestore(lock, iflags);                      \
+ }while(0)
+
+#define msgrng_access_enable(mflags) do {   \
+  preempt_disable();                        \
+  msgrng_flags_save(mflags);                \
+} while(0)
+
+#define msgrng_access_disable(mflags) do {   \
+  msgrng_flags_restore(mflags);              \
+  preempt_enable();                          \
+} while(0)
+
+enum {
+  TX_STN_CPU_0,
+  TX_STN_CPU_1,
+  TX_STN_CPU_2,
+  TX_STN_CPU_3,
+  TX_STN_CPU_4,
+  TX_STN_CPU_5,
+  TX_STN_CPU_6,
+  TX_STN_CPU_7,
+  TX_STN_GMAC,
+  TX_STN_DMA,
+  TX_STN_XGS_0,
+  TX_STN_XGS_1,
+  TX_STN_SEC,
+  TX_STN_GMAC0,
+  TX_STN_GMAC1,
+  TX_STN_CMP,
+  TX_STN_PCIE,
+  TX_STN_INVALID,
+  MAX_TX_STNS
+};
+
+extern int register_msgring_handler(int major,
+				    void (*action)(int, int,int,int,struct msgrng_msg *, void *),
+				    void *dev_ctx);
+
+
+extern void phoenix_msgring_cpu_init(void);
+
+extern void phnx_msgring_config(void);
+
+#define cpu_to_msgring_bucket(cpu) ((((cpu) >> 2)<<3)|((cpu) & 0x03))
+
+
+/* PR: We need to make the following entrities visible across the kernel */
+#define CPU_BASE_BUCKET(x)   (((x)>>2)<<3)
+
+#define THR_LO_BUCKETID (phoenix_thr_id() & 3)
+#define THR_HI_BUCKETID (THR_LO_BUCKETID + 4)
+
+#define THIS_THR_LO_BUCKET cpu_to_msgring_bucket(hard_smp_processor_id())
+#define THIS_THR_HI_BUCKET (THIS_THR_LO_BUCKET)
+
+#define THR_LO_BKT_STATUS_MASK (1U << THR_LO_BUCKETID)
+#define THR_HI_BKT_STATUS_MASK (1U << THR_HI_BUCKETID)
+
+struct msgrng_msg;
+
+struct tx_stn_handler {
+	void (*action)(int, int, int, int, struct msgrng_msg *, void *);
+	void *dev_id;
+};
+
+struct tx_stn {
+	struct tx_stn_handler handler;
+};
+
+extern struct tx_stn tx_stns[];
+extern int rxstn_to_txstn_map[];
+extern int xls_rxstn_to_txstn_map[];
+
+extern int rmik_queue_pkt_mem(uint32_t fbstid, uint64_t physaddr);
+extern void rmik_init_replenish_work(int);
+extern void rmi_phnx_drop_message_unowned(int fbid, uint64_t physaddr, int cop_en);
+
+#endif
diff --git a/arch/mips/include/asm/rmi/msidef.h b/arch/mips/include/asm/rmi/msidef.h
new file mode 100644
index 0000000..b34353f
--- /dev/null
+++ b/arch/mips/include/asm/rmi/msidef.h
@@ -0,0 +1,73 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_2#**********************************/
+
+#ifndef ASM_RMI_MSIDEF_H
+#define ASM_RMI_MSIDEF_H
+
+/*
+ * Constants for Intel APIC based MSI messages.
+ * Adapted for the RMI XLR using identical defines
+ */
+
+/*
+ * Shifts for MSI data
+ */
+
+#define MSI_DATA_VECTOR_SHIFT		0
+#define  MSI_DATA_VECTOR_MASK		0x000000ff
+#define	 MSI_DATA_VECTOR(v)		(((v) << MSI_DATA_VECTOR_SHIFT) & MSI_DATA_VECTOR_MASK)
+
+#define MSI_DATA_DELIVERY_MODE_SHIFT	8
+#define  MSI_DATA_DELIVERY_FIXED	(0 << MSI_DATA_DELIVERY_MODE_SHIFT)
+#define  MSI_DATA_DELIVERY_LOWPRI	(1 << MSI_DATA_DELIVERY_MODE_SHIFT)
+
+#define MSI_DATA_LEVEL_SHIFT		14
+#define	 MSI_DATA_LEVEL_DEASSERT	(0 << MSI_DATA_LEVEL_SHIFT)
+#define	 MSI_DATA_LEVEL_ASSERT		(1 << MSI_DATA_LEVEL_SHIFT)
+
+#define MSI_DATA_TRIGGER_SHIFT		15
+#define  MSI_DATA_TRIGGER_EDGE		(0 << MSI_DATA_TRIGGER_SHIFT)
+#define  MSI_DATA_TRIGGER_LEVEL		(1 << MSI_DATA_TRIGGER_SHIFT)
+
+/*
+ * Shift/mask fields for msi address
+ */
+
+#define MSI_ADDR_BASE_HI		0
+#define MSI_ADDR_BASE_LO		0xfee00000
+
+#define MSI_ADDR_DEST_MODE_SHIFT	2
+#define  MSI_ADDR_DEST_MODE_PHYSICAL	(0 << MSI_ADDR_DEST_MODE_SHIFT)
+#define	 MSI_ADDR_DEST_MODE_LOGICAL	(1 << MSI_ADDR_DEST_MODE_SHIFT)
+
+#define MSI_ADDR_REDIRECTION_SHIFT	3
+#define  MSI_ADDR_REDIRECTION_CPU	(0 << MSI_ADDR_REDIRECTION_SHIFT) /* dedicated cpu */
+#define  MSI_ADDR_REDIRECTION_LOWPRI	(1 << MSI_ADDR_REDIRECTION_SHIFT) /* lowest priority */
+
+#define MSI_ADDR_DEST_ID_SHIFT		12
+#define	 MSI_ADDR_DEST_ID_MASK		0x00ffff0
+#define  MSI_ADDR_DEST_ID(dest)		(((dest) << MSI_ADDR_DEST_ID_SHIFT) & MSI_ADDR_DEST_ID_MASK)
+
+#endif /* ASM_RMI_MSIDEF_H */
diff --git a/arch/mips/include/asm/rmi/pci.h b/arch/mips/include/asm/rmi/pci.h
new file mode 100644
index 0000000..c97ce1c
--- /dev/null
+++ b/arch/mips/include/asm/rmi/pci.h
@@ -0,0 +1,38 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_PCI_H
+#define _ASM_RMI_PCI_H
+
+#define RMI_PCI_VENDOR_ID            0xfecc
+#define RMI_PCI_UART_DEV_ID          2
+#define RMI_PCI_DUMMY_MAC_DEV_ID     16
+
+#endif
diff --git a/arch/mips/include/asm/rmi/perf_ctr.h b/arch/mips/include/asm/rmi/perf_ctr.h
new file mode 100644
index 0000000..8371148
--- /dev/null
+++ b/arch/mips/include/asm/rmi/perf_ctr.h
@@ -0,0 +1,72 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef __ASM_RMI_PERF_CTR_H
+#define __ASM_RMI_PERF_CTR_H
+
+#include <asm/mipsregs.h>
+
+#define CP0_PERF_CTR  $25
+
+/* Subset of perf ctr events */
+
+#define PERF_CTR_INSTR_FETCHED           0
+#define PERF_CTR_ICACHE_MISSES           1
+#define PERF_CTR_SLEEP_CYCLES           12
+#define PERF_CTR_INSTR_RETIRED          17
+#define PERF_CTR_BRJMP_INSTR            20
+#define PERF_CTR_BRJMP_FLUSH            21
+#define PERF_CTR_REPLAYFLUSH            27
+#define PERF_CTR_REPLAYFLUSH_LDUSE      28
+#define PERF_CTR_L1_HIT                 38
+#define PERF_CTR_L1_REF                 39
+#define PERF_CTR_SNOOP_UPGRADE_FAIL     47
+#define PERF_CTR_SNOOP_TRANSFERS        48
+#define PERF_CTR_SNOOP_HITS             49
+#define PERF_CTR_SNOOP_OPS              50
+#define PERF_CTR_CYCLES                 63
+
+/* 2 sets of counters are supported across all threads of a core */
+#define PERF_CTR_EVENT0        0
+#define PERF_CTR_EVENT0_VALUE  1
+#define PERF_CTR_EVENT1        2
+#define PERF_CTR_EVENT1_VALUE  3
+
+#define PERF_CTR_DEFAULT 0x0f /* disable int, enable counting in all modes */
+
+#define perf_ctr_start(ctr, event, global, thr) __write_32bit_c0_register($25, ctr, ((PERF_CTR_DEFAULT)|((global)<<13)|((thr)<<11)|((event)<<5)) ) 
+
+#define perf_ctr_stop(ctr) __write_32bit_c0_register($25, ctr, 0)
+
+#define perf_ctr_reset(ctr) __write_32bit_c0_register($25, ctr, 0)
+
+#define perf_ctr_read(ctr) __read_32bit_c0_register($25, ctr)
+
+#endif /* __ASM_RMI_PERF_CTR_H */
diff --git a/arch/mips/include/asm/rmi/phnx_cde.h b/arch/mips/include/asm/rmi/phnx_cde.h
new file mode 100644
index 0000000..3b80e29
--- /dev/null
+++ b/arch/mips/include/asm/rmi/phnx_cde.h
@@ -0,0 +1,170 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_2#**********************************/
+
+#ifndef _PHNX_CDE_H
+#define _PHNX_CDE_H
+
+#include <asm/rmi/msgring.h>
+#include <asm/io.h>   // virt_to_phys
+
+#define CMP_REG_CNFG_MSG_CREDIT_SEL 14
+#define CMP_REG_CTRL_REG         0
+#define CMP_REG_DMA_CREDITS_REG  1
+#define CMP_REG_SPILL_ADDR0_REG  2
+#define CMP_REG_SPILL_ADDR1_REG  3
+#define CMP_REG_SPILL_SIZE_REG   4
+#define CMP_REG_SPILL_BYTES_REG  5
+#define CMP_REG_CRC_ADLER_SPILL  6
+#define CMP_REG_SCRATCH_PAGE     7
+#define CMP_REG_INTERRUPT_VEC    8
+#define CMP_REG_INTERRUPT_MASK   9
+#define CMP_REG_FREE_DESC_THRES  10
+#define CMP_REG_DESC_FIFO_COUNT  11
+#define CMP_REG_RESET_REG        12
+#define CMP_REG_ERROR_RESET_MASK 13
+#define CMP_REG_READ_ERROR_LIST0 14
+#define CMP_REG_READ_ERROR_LIST1 15
+
+//defines needed to be declared
+#define CMP_MSG_BUCKET0_SIZE 0x320
+#define CMP_MSG_BUCKET1_SIZE 0x321
+
+
+static inline uint32_t cmp_read_reg(int reg)
+{
+  phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_COMP_OFFSET);
+
+  return phoenix_read_reg(mmio, reg);
+}
+
+static inline void cmp_write_reg(int reg, uint32_t value)
+{
+  phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_COMP_OFFSET);
+
+  phoenix_write_reg(mmio, reg, value);
+}
+
+static __inline__ int make_fd_msg(struct msgrng_msg *msg, void *free_addr)
+{
+  int stid = MSGRNG_STNID_CMP_0;
+
+  msg->msg0 = ( ((uint64_t)virt_to_phys(free_addr) & 0xffffffffffULL)
+                );
+  return stid;
+}
+
+static __inline__ int make_cmp_msg(struct msgrng_msg *msg, int rtn_bkt,
+				   int op, int length, void *src_addr)
+{
+  int stid = MSGRNG_STNID_CMP_1;
+  
+  msg->msg0 = ( ((uint64_t) op << 60)  | 
+                ((uint64_t) rtn_bkt << 54) |
+                ((uint64_t) length << 40) |
+                ((uint64_t) virt_to_phys(src_addr) & 0xffffffffffULL)
+                );
+  return stid;
+}
+
+
+static __inline__ uint64_t make_src_desc(int eof, int type, int sod, int sob, int save,
+					 int restore, int eob, int length, void *src_addr)
+{
+  uint64_t src_desc = 0;
+  src_desc = (  ((uint64_t) eof << 63) | 
+                ((uint64_t) type << 61) |
+                ((uint64_t) sod << 60) |
+                ((uint64_t) sob << 59) |
+                ((uint64_t) save << 58) |
+                ((uint64_t) restore << 57) |
+                ((uint64_t) eob << 56) |
+                ((uint64_t) length << 40) |
+                ((uint64_t) virt_to_phys(src_addr) & 0xffffffffffULL)
+                );
+  return src_desc;
+}
+
+static __inline__ uint64_t get_dest_desc(uint64_t dest_addr)
+{
+  uint64_t *desc;
+  desc = phys_to_virt(dest_addr);
+  return *desc;
+}
+
+static __inline__ int read_cmp_msg(char *buffer, uint64_t payload) 
+{
+  uint64_t i,j,num_bytes;
+  int offset = 0;
+  uint64_t *desc, dest_addr;
+  int num_desc = (payload >> 40) & 0x3fff;
+  char * tmp_ptr;
+
+  //  printk("num_desc = %d\n", num_desc);
+
+  for (i = 0; i < num_desc; i++) {
+    desc = phys_to_virt(payload & 0xffffffffffUll) + i*8; //64 byte descriptors //dliao: why i*8??
+
+    num_bytes = (*desc >> 40) & 0xffff;
+
+    //    printk("num_bytes = %lld\n", num_bytes);
+
+    dest_addr = *desc & 0xffffffffffUll;
+
+    tmp_ptr = (char *) phys_to_virt(dest_addr & 0xffffffffffUll);
+
+    for (j = 0; j < num_bytes; j++) {
+      buffer[offset+j] = tmp_ptr[j];
+      //   buffer[offset + j] = phys_to_virt(dest_addr & 0xffffffffff)+j;
+    }
+
+    offset = offset + num_bytes;
+  }
+
+  return offset;
+}
+
+
+#ifndef CDE_MAJOR
+#define CDE_MAJOR 0   /* dynamic major by default */
+#endif
+
+
+/*
+ * Split minors in two parts
+ */
+#define TYPE(minor)	(((minor) >> 4) & 0xf)	/* high nibble */
+#define NUM(minor)	((minor) & 0xf)		/* low  nibble */
+
+
+#define CDE_IOC_MAGIC  'k'
+#define CDE_IOCINFLATE _IO(CDE_IOC_MAGIC, 0)
+#define CDE_IOCDEFLATE _IO(CDE_IOC_MAGIC, 1)
+#define CDE_IOC_MAXNR  1
+
+#define CDE_INFLATE 0
+#define CDE_DEFLATE 1
+
+
+#endif /* _PHNX_CDE_H_ */
diff --git a/arch/mips/include/asm/rmi/phnx_loader.h b/arch/mips/include/asm/rmi/phnx_loader.h
new file mode 100644
index 0000000..ed4ceb4
--- /dev/null
+++ b/arch/mips/include/asm/rmi/phnx_loader.h
@@ -0,0 +1,175 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_PHNX_LOADER_H
+#define _ASM_RMI_PHNX_LOADER_H
+#include <linux/list.h>
+#include <asm/rmi/memory-exclusion.h>
+
+#define PHNX_LOADER_KSEG0_VIRT_START         0x60000000
+#define PHNX_LOADER_KSEG0_START         0x0c000000
+#define PHNX_LOADER_KSEG0_SIZE         0x04000000
+
+#define PHNX_LOADER_KUSEG_VIRT_START         0x20000000
+#define PHNX_LOADER_KUSEG_PHYS_START         0x20000000ULL
+#define PHNX_LOADER_KUSEG_PHYS_SIZE          0xf000000ULL /* for 512 MB boards*/
+
+/* the below macros go together */
+#define PHNX_LOADER_PHYS_SIZE          (512<<20)
+#define PHNX_LOADER_PMASK_SIZE         (PHNX_LOADER_PHYS_SIZE >> 1)
+#define PHNX_LOADER_PMASK_SIZE_256MB   0xffff
+
+#define PHNX_LOADER_IPI_VECTOR 51
+
+
+#if (_MIPS_SIM == _MIPS_SIM_ABI64)
+#define PTR2U64(x) (unsigned long)(x)
+#define U642PTR(x) (void *)((unsigned long)(x))
+#else
+// preserve sign-extension
+#define PTR2U64(x) (int)(x)
+#define U642PTR(x) (void *)((int)(x))
+#endif
+
+#define NUM_WORDS 2048
+
+#define XLR_THREAD_SIZE (NUM_WORDS * sizeof(long))
+
+#define PHNX_APP_SHMEM_MAX_SZ (512*1024*1024)
+#ifndef __ASSEMBLY__
+
+struct xlr_thread_info {
+	unsigned long stack[NUM_WORDS];
+};
+extern struct xlr_thread_info xlrthreads_info[];
+
+#endif
+
+#define PSB_MEM_MAP_MAX 32
+#define PSB_IO_MAP_MAX 32
+
+struct psb_mem_map {
+	int nr_map;
+	struct psb_mem_map_entry {
+		uint64_t addr;  /* start of memory segment */
+		uint64_t size;  /* size of memory segment */
+		uint32_t type;      /* type of memory segment */
+	} map[PSB_MEM_MAP_MAX];
+};
+
+struct psb_io_map {
+	int nr_map;
+	struct psb_io_map_entry {
+		uint64_t addr;  /* start of IO segment */
+		uint64_t size;  /* size of IO segment */
+		long type;      /* type of IO segment */
+	} map[PSB_IO_MAP_MAX];
+};
+
+struct r_exception_region {
+	    unsigned int data[1024];
+};
+
+#define PKT_DATA_LEN 1592
+#define PKT_SEC_AUTH_LEN 32
+#define PKT_SEC_CTRL_DESC_LEN 128
+#define PKT_SEC_PKT_DESC_LEN 32
+
+
+struct packet {
+	/* New cacheline */
+	uint8_t data[PKT_DATA_LEN];
+	uint32_t len;
+	uint32_t seq_num;
+	/* New cacheline */
+	uint8_t sec_ctrl_desc[PKT_SEC_CTRL_DESC_LEN];
+	/* New cacheline */
+	uint8_t sec_pkt_desc[PKT_SEC_PKT_DESC_LEN];
+	/* New cacheline */
+	uint8_t sec_auth[PKT_SEC_AUTH_LEN];
+	/* New cacheline */
+	uint16_t sec_cksum;
+	uint8_t sec_cksum_padding[30];
+	/* New cacheline */
+	uint32_t sec_error;
+	uint32_t sec_op_timestamp;
+	struct list_head sec_tx_list;
+	uint16_t sec_ctrl_desc_size;
+	uint8_t padding[14];
+	/* New cacheline */
+} __attribute__ ((aligned(32)));
+
+#define dprintk(fmt, args...) //printk(fmt, ##args)
+#define eprintk(fmt, args...) printk(fmt, ##args)
+
+#define MAX_LOADER_MEMORY_ENTRY 128
+
+#define XLR_MAX_THRDS 32
+
+#define MEM_ALLOC_REQUEST 1
+#define MEM_ALLOC_FAILED 2
+#define MEM_ALLOC_DONE 3
+#define MAX_NUM_KUSEG_BLOCKS 4
+
+struct phnx_loader_alloc_memory
+{
+	void *ptr;
+	size_t size;
+	int status;
+};
+
+struct phnx_loader_free_memory
+{
+	void *ptr;
+};
+
+struct xlr_rmios_pt_regs {
+	unsigned long long pad0[6];
+
+	unsigned long long regs[32];
+
+	unsigned long long cp0_status;
+	unsigned long long hi;
+	unsigned long long lo;
+
+	/*
+	 * saved cp0 registers
+	 */
+	unsigned long long cp0_badvaddr;
+	unsigned long long cp0_cause;
+	unsigned long long cp0_epc;
+};
+
+struct kuseg_mem_info {
+	uint64_t size;
+	uint64_t start_addr;
+};
+
+#endif
diff --git a/arch/mips/include/asm/rmi/phnx_tb.h b/arch/mips/include/asm/rmi/phnx_tb.h
new file mode 100644
index 0000000..46d3da8
--- /dev/null
+++ b/arch/mips/include/asm/rmi/phnx_tb.h
@@ -0,0 +1,97 @@
+/*********************************************************************
+
+Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions
+are met:
+
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+
+*****************************#RMI_2#**********************************/
+#ifndef _RMI_PHOENIX_TB_H
+#define _RMI_PHOENIX_TB_H
+
+#include <linux/types.h>
+#include <asm/rmi/iomap.h>
+#include <linux/phnx_tb.h>
+
+#define TB_REG_SIZE				4
+#define TB_NO_RDDATA_REGS		4
+#define TB_MAX_ENTRIES			256
+#define TB_ENTRY_SIZE		(TB_NO_RDDATA_REGS * TB_REG_SIZE)
+#define TB_SIZE				(TB_MAX_ENTRIES * TB_ENTRY_SIZE)
+
+/* ---------------------------------------------------------------------------- */
+/*                             RD/WR macros                                     */
+/* ---------------------------------------------------------------------------- */
+
+static inline unsigned int tb_read_reg_be32(unsigned int reg)
+{
+    phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_TB_OFFSET);
+    return phoenix_read_reg(mmio, reg);
+}
+
+static inline void tb_write_reg_be32 (unsigned int reg, unsigned int value)
+{
+    phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_TB_OFFSET);
+    phoenix_write_reg(mmio, reg, value);
+}
+
+static inline unsigned int tb_read_reg_le32 (unsigned int reg)
+{
+    phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_TB_OFFSET);
+    return phoenix_read_reg_le32(mmio, reg);
+}
+
+static inline void tb_write_reg_le32 (unsigned int reg, unsigned int value)
+{
+    phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_TB_OFFSET);
+    phoenix_write_reg_le32(mmio, reg, value);
+}
+
+#define tb_read_status_reg() tb_read_reg_be32(TB_STATUS_REG)
+#define tb_read_ctrl_reg() tb_read_reg_be32(TB_CTRL_REG)
+
+#define tb_read_reqmatch_reg(i) tb_read_reg_be32 (TB_REQMATCH_REGS + i)
+#define tb_read_raddr_reg(i) tb_read_reg_be32 (TB_RADDR_REGS + i)
+#define tb_read_rddata_reg(i) tb_read_reg_be32 (TB_RDDATA_REGS + i)
+
+#define tb_write_ctrl_reg(val) tb_write_reg_be32 (TB_CTRL_REG, val)
+#define tb_write_reqmatch_reg(i, val) tb_write_reg_be32 ((TB_REQMATCH_REGS+i), val)
+#define tb_write_raddr_reg(i, val) tb_write_reg_be32 ((TB_RADDR_REGS+i), val)
+
+#define tb_reinit(void) {tb_write_reg_be32(TB_INIT_REG, 0x0);tb_write_reg_be32(TB_INIT_REG, 0x1);}
+#define tb_pop_entry(void) tb_write_reg_be32(TB_ACCESS_REG, 0)
+#define disable_tb()    tb_write_reg_be32(TB_CTRL_REG, 0x01000000)
+
+typedef struct _tb_dev_t {
+	unsigned int	size;
+//	unsigned char   data[TB_SIZE];
+	unsigned char   *data;
+} tb_dev_t;
+
+ssize_t	tb_read (struct file *, char *, size_t, loff_t *);
+int		tb_open (struct inode *, struct file *);
+int		tb_ioctl (struct inode *, struct file *, unsigned int, unsigned long);
+int		tb_release (struct inode *, struct file *);
+
+#endif
diff --git a/arch/mips/include/asm/rmi/phnx_user_mac.h b/arch/mips/include/asm/rmi/phnx_user_mac.h
new file mode 100644
index 0000000..15990ae
--- /dev/null
+++ b/arch/mips/include/asm/rmi/phnx_user_mac.h
@@ -0,0 +1,61 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_PHNX_USER_MAC_H
+#define _ASM_RMI_PHNX_USER_MAC_H
+
+#define PHNX_USER_MAC_MMAP_VIRT_START 0x60000000
+#define PHNX_USER_MAC_SIZE            0x800000
+
+#ifndef __ASSEMBLY__
+#include <asm/rmi/sim.h>
+
+extern void phoenix_user_mac_update_time(void);
+
+struct xlr_user_mac_config {
+	int l4_extract;
+	int fast_syscall;
+};
+
+extern struct xlr_user_mac_config xlr_user_mac;
+
+static __inline__ int xlr_user_mac_l4_extract(void)
+{
+	return xlr_hybrid_user_mac() ? xlr_user_mac.l4_extract  : 0;
+}
+
+static __inline__ int xlr_user_mac_fast_syscall(void)
+{
+	return xlr_hybrid_user_mac() && (xlr_user_mac.fast_syscall == 1);
+}
+
+#endif
+
+#endif
diff --git a/arch/mips/include/asm/rmi/phoenix_flash_pcmcia.h b/arch/mips/include/asm/rmi/phoenix_flash_pcmcia.h
new file mode 100644
index 0000000..4398655
--- /dev/null
+++ b/arch/mips/include/asm/rmi/phoenix_flash_pcmcia.h
@@ -0,0 +1,116 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _FLASH_PCMCIA_H_
+#define _FLASH_PCMCIA_H_
+
+#define R_FLASH_PCMCIA_BASE_ADDR                    0x0
+#define   O_BASE_ADDR__base_addr                    0
+#define   W_BASE_ADDR__base_addr                    16
+#define R_FLASH_PCMCIA_BASE_ADDR_MASK               0x1
+#define   O_BASE_ADDR_MASK__base_amask              0
+#define   W_BASE_ADDR_MASK__base_amask              16
+#define R_FLASH_PCMCIA_DEV_PARM                     0x2
+#define   O_DEV_PARM__burst_mode_en                 0
+#define   O_DEV_PARM__burst_mode                    1
+#define   W_DEV_PARM__burst_mode                    3
+#define   O_DEV_PARM__wait_en                       4
+#define   O_DEV_PARM__wait_pol                      5
+#define   O_DEV_PARM__mx_addr                       6
+#define   O_DEV_PARM__dwidth                        7
+#define   W_DEV_PARM__dwidth                        2
+#define   O_DEV_PARM__pcmcia_en                     9
+#define   O_DEV_PARM__genif_en                      10
+#define   O_DEV_PARM__genparity_en                  11
+#define   O_DEV_PARM__genparity_type                12
+#define   O_DEV_PARM__adv_type                      13
+#define R_FLASH_TIMING_PARM_0                       0x3
+#define   O_FLASH_TIMING_PARM_0__ale_width          0
+#define   W_FLASH_TIMING_PARM_0__ale_width          3
+#define   O_FLASH_TIMING_PARM_0__ale_to_cs          3
+#define   W_FLASH_TIMING_PARM_0__ale_to_cs          3
+#define   O_FLASH_TIMING_PARM_0__cs_width           6
+#define   W_FLASH_TIMING_PARM_0__cs_width           5
+#define   O_FLASH_TIMING_PARM_0__wait_to_data       11
+#define   W_FLASH_TIMING_PARM_0__wait_to_data       5
+#define   O_FLASH_TIMING_PARM_0__cs_to_oe           16
+#define   W_FLASH_TIMING_PARM_0__cs_to_oe           3
+#define   O_FLASH_TIMING_PARM_0__cs_to_we           19
+#define   W_FLASH_TIMING_PARM_0__cs_to_we           3
+#define   O_FLASH_TIMING_PARM_0__oe_to_cs           22
+#define   W_FLASH_TIMING_PARM_0__oe_to_cs           2
+#define   O_FLASH_TIMING_PARM_0__we_to_cs           24
+#define   W_FLASH_TIMING_PARM_0__we_to_cs           4
+#define   O_FLASH_TIMING_PARM_0__cs_to_cs           28
+#define   W_FLASH_TIMING_PARM_0__cs_to_cs           4
+#define R_FLASH_TIMING_PARM_1                       0x4
+#define   O_FLASH_TIMING_PARM_1__oe_width           0
+#define   W_FLASH_TIMING_PARM_1__oe_width           6
+#define   O_FLASH_TIMING_PARM_1__we_width           6
+#define   W_FLASH_TIMING_PARM_1__we_width           6
+#define   O_FLASH_TIMING_PARM_1__wait_timeout       12
+#define   W_FLASH_TIMING_PARM_1__wait_timeout       15
+#define R_PCMCIA_CONFIG                             0x5
+#define   O_PCMCIA_CONFIG__pcmcia_en                0
+#define   O_PCMCIA_CONFIG__reg_access               1
+#define   O_PCMCIA_CONFIG__reset                    2
+#define   O_PCMCIA_CONFIG__cdmask                   4
+#define   O_PCMCIA_CONFIG__wpmask                   5
+#define   O_PCMCIA_CONFIG__rdymask                  6
+#define   O_PCMCIA_CONFIG__rybymask                 7
+#define R_PCMCIA_STATUS                             0x6
+#define   O_PCMCIA_STATUS__bvd1_sts                 0
+#define   O_PCMCIA_STATUS__bvd2_sts                 1
+#define   O_PCMCIA_STATUS__cd1_sts                  2
+#define   O_PCMCIA_STATUS__cd2_sts                  3
+#define   O_PCMCIA_STATUS__vs1_sts                  4
+#define   O_PCMCIA_STATUS__vs2_sts                  5
+#define   O_PCMCIA_STATUS__wp_sts                   6
+#define   O_PCMCIA_STATUS__rdy_sts                  7
+#define   O_PCMCIA_STATUS__ryby_sts                 8
+#define   O_PCMCIA_STATUS__cd_intr                  9
+#define   O_PCMCIA_STATUS__wp_intr                  10
+#define   O_PCMCIA_STATUS__rdy_intr                 11
+#define   O_PCMCIA_STATUS__illegal_addr_intrpt      12
+#define   O_PCMCIA_STATUS__mutl_cs_intrpt           13
+#define   O_PCMCIA_STATUS__wait_timeout_intrpt      14
+#define   O_PCMCIA_STATUS__ryby_intrpt              16
+#define   O_PCMCIA_STATUS__werr_intrpt              17
+#define   O_PCMCIA_STATUS__illegal_pcmcia_intrpt    18
+#define R_GENERIC_REGION_STATUS                     0x7
+#define   O_GENERIC_REGION_STATUS__cs_err_intrpt    0
+#define   W_GENERIC_REGION_STATUS__cs_err_intrpt    8
+#define R_GENERIC_ERROR_ADDR                        0x8
+#define   O_GENERIC_ERROR_ADDR__err_addr            0
+#define   W_GENERIC_ERROR_ADDR__err_addr            32
+
+
+#endif /* _FLASH_PCMCIA_H_ */
+
diff --git a/arch/mips/include/asm/rmi/phoenix_ide.h b/arch/mips/include/asm/rmi/phoenix_ide.h
new file mode 100644
index 0000000..1100bf0
--- /dev/null
+++ b/arch/mips/include/asm/rmi/phoenix_ide.h
@@ -0,0 +1,62 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef __ASM_PHOENIX_H
+#define __ASM_PHOENIX_H
+
+
+#define  CONFIG_PHOENIX 1
+
+#ifdef CONFIG_PHOENIX
+#define PHOENIX_BOARD_NAME "PHOENIX -ATX1"
+#define PHOENIX_HAVE_PCMCIA 0
+#define PHOENIX_HAVE_IDE    1
+#endif
+
+
+#ifdef PHOENIX_HAVE_IDE
+#define IDE_CS          6
+#define IDE_PHYS        0x1D000000
+#define K_GPIO_GB_IDE   4
+#define K_GPIO_PC_READY 11 
+#define K_INT_GPIO_0    32 
+#define K_INT_GB_IDE    (K_INT_GPIO_0 + K_GPIO_GB_IDE)
+#endif
+
+#ifdef PHOENIX_HAVE_PCMCIA
+#define PCMCIA_CS       4
+#define PCMCIA_PHYS     0x11000000
+#define K_INT_PC_READY  (K_INT_GPIO_0 + K_GPIO_PC_READY)
+#endif
+
+
+#define IOADDR(a) (UNCAC_BASE + (a))
+
+#endif /* __ASM_PHOENIX_H */
diff --git a/arch/mips/include/asm/rmi/phoenix_mac.h b/arch/mips/include/asm/rmi/phoenix_mac.h
new file mode 100644
index 0000000..791f8b8
--- /dev/null
+++ b/arch/mips/include/asm/rmi/phoenix_mac.h
@@ -0,0 +1,1163 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_MAC_H
+#define _ASM_RMI_MAC_H
+
+#include <linux/types.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/iomap.h>
+#include <linux/skbuff.h>
+#include <asm/rmi/phoenix_sec.h>
+#include <asm/rmi/config_net.h>
+
+#define IPSEC_PACKET_PAYLOAD_SIZE 1696
+#define PHXSEC_HMAC_LENGTH 64
+#define SKBUF_HEAD (32 * 2)    // 2 cachelines reserved before payload
+
+//#define MAC_SPLIT_MODE
+
+#define MAC_SPACING                 0x400
+#define XGMAC_SPACING               0x400
+
+/* PE-MCXMAC register and bit field definitions */
+#define R_MAC_CONFIG_1                                              0x00
+#define   O_MAC_CONFIG_1__srst                                      31
+#define   O_MAC_CONFIG_1__simr                                      30
+#define   O_MAC_CONFIG_1__hrrmc                                     18
+#define   W_MAC_CONFIG_1__hrtmc                                      2
+#define   O_MAC_CONFIG_1__hrrfn                                     16
+#define   W_MAC_CONFIG_1__hrtfn                                      2
+#define   O_MAC_CONFIG_1__intlb                                      8
+#define   O_MAC_CONFIG_1__rxfc                                       5
+#define   O_MAC_CONFIG_1__txfc                                       4
+#define   O_MAC_CONFIG_1__srxen                                      3
+#define   O_MAC_CONFIG_1__rxen                                       2
+#define   O_MAC_CONFIG_1__stxen                                      1
+#define   O_MAC_CONFIG_1__txen                                       0
+#define R_MAC_CONFIG_2                                              0x01
+#define   O_MAC_CONFIG_2__prlen                                     12
+#define   W_MAC_CONFIG_2__prlen                                      4
+#define   O_MAC_CONFIG_2__speed                                      8
+#define   W_MAC_CONFIG_2__speed                                      2
+#define   O_MAC_CONFIG_2__hugen                                      5
+#define   O_MAC_CONFIG_2__flchk                                      4
+#define   O_MAC_CONFIG_2__crce                                       1
+#define   O_MAC_CONFIG_2__fulld                                      0
+#define R_IPG_IFG                                                   0x02
+#define   O_IPG_IFG__ipgr1                                          24
+#define   W_IPG_IFG__ipgr1                                           7
+#define   O_IPG_IFG__ipgr2                                          16
+#define   W_IPG_IFG__ipgr2                                           7
+#define   O_IPG_IFG__mifg                                            8
+#define   W_IPG_IFG__mifg                                            8
+#define   O_IPG_IFG__ipgt                                            0
+#define   W_IPG_IFG__ipgt                                            7
+#define R_HALF_DUPLEX                                               0x03
+#define   O_HALF_DUPLEX__abebt                                      24
+#define   W_HALF_DUPLEX__abebt                                       4
+#define   O_HALF_DUPLEX__abebe                                      19
+#define   O_HALF_DUPLEX__bpnb                                       18
+#define   O_HALF_DUPLEX__nobo                                       17
+#define   O_HALF_DUPLEX__edxsdfr                                    16
+#define   O_HALF_DUPLEX__retry                                      12
+#define   W_HALF_DUPLEX__retry                                       4
+#define   O_HALF_DUPLEX__lcol                                        0
+#define   W_HALF_DUPLEX__lcol                                       10
+#define R_MAXIMUM_FRAME_LENGTH                                      0x04
+#define   O_MAXIMUM_FRAME_LENGTH__maxf                               0
+#define   W_MAXIMUM_FRAME_LENGTH__maxf                              16
+#define R_TEST                                                      0x07
+#define   O_TEST__mbof                                               3
+#define   O_TEST__rthdf                                              2
+#define   O_TEST__tpause                                             1
+#define   O_TEST__sstct                                              0
+#define R_MII_MGMT_CONFIG                                           0x08
+#define   O_MII_MGMT_CONFIG__scinc                                   5
+#define   O_MII_MGMT_CONFIG__spre                                    4
+#define   O_MII_MGMT_CONFIG__clks                                    3
+#define   W_MII_MGMT_CONFIG__clks                                    3
+#define R_MII_MGMT_COMMAND                                          0x09
+#define   O_MII_MGMT_COMMAND__scan                                   1
+#define   O_MII_MGMT_COMMAND__rstat                                  0
+#define R_MII_MGMT_ADDRESS                                          0x0A
+#define   O_MII_MGMT_ADDRESS__fiad                                   8
+#define   W_MII_MGMT_ADDRESS__fiad                                   5
+#define   O_MII_MGMT_ADDRESS__fgad                                   5
+#define   W_MII_MGMT_ADDRESS__fgad                                   0
+#define R_MII_MGMT_WRITE_DATA                                       0x0B
+#define   O_MII_MGMT_WRITE_DATA__ctld                                0
+#define   W_MII_MGMT_WRITE_DATA__ctld                               16
+#define R_MII_MGMT_STATUS                                           0x0C
+#define R_MII_MGMT_INDICATORS                                       0x0D
+#define   O_MII_MGMT_INDICATORS__nvalid                              2
+#define   O_MII_MGMT_INDICATORS__scan                                1
+#define   O_MII_MGMT_INDICATORS__busy                                0
+#define R_INTERFACE_CONTROL                                         0x0E
+#define   O_INTERFACE_CONTROL__hrstint                              31
+#define   O_INTERFACE_CONTROL__tbimode                              27
+#define   O_INTERFACE_CONTROL__ghdmode                              26
+#define   O_INTERFACE_CONTROL__lhdmode                              25
+#define   O_INTERFACE_CONTROL__phymod                               24
+#define   O_INTERFACE_CONTROL__hrrmi                                23
+#define   O_INTERFACE_CONTROL__rspd                                 16
+#define   O_INTERFACE_CONTROL__hr100                                15
+#define   O_INTERFACE_CONTROL__frcq                                 10
+#define   O_INTERFACE_CONTROL__nocfr                                 9
+#define   O_INTERFACE_CONTROL__dlfct                                 8
+#define   O_INTERFACE_CONTROL__enjab                                 0
+#define R_INTERFACE_STATUS                                         0x0F
+#define   O_INTERFACE_STATUS__xsdfr                                  9
+#define   O_INTERFACE_STATUS__ssrr                                   8
+#define   W_INTERFACE_STATUS__ssrr                                   5
+#define   O_INTERFACE_STATUS__miilf                                  3
+#define   O_INTERFACE_STATUS__locar                                  2
+#define   O_INTERFACE_STATUS__sqerr                                  1
+#define   O_INTERFACE_STATUS__jabber                                 0
+#define R_STATION_ADDRESS_LS                                       0x10
+#define R_STATION_ADDRESS_MS                                       0x11
+
+/* A-XGMAC register and bit field definitions */
+#define R_XGMAC_CONFIG_0    0x00
+#define   O_XGMAC_CONFIG_0__hstmacrst               31
+#define   O_XGMAC_CONFIG_0__hstrstrctl              23
+#define   O_XGMAC_CONFIG_0__hstrstrfn               22
+#define   O_XGMAC_CONFIG_0__hstrsttctl              18
+#define   O_XGMAC_CONFIG_0__hstrsttfn               17
+#define   O_XGMAC_CONFIG_0__hstrstmiim              16
+#define   O_XGMAC_CONFIG_0__hstloopback             8
+#define R_XGMAC_CONFIG_1    0x01
+#define   O_XGMAC_CONFIG_1__hsttctlen               31
+#define   O_XGMAC_CONFIG_1__hsttfen                 30
+#define   O_XGMAC_CONFIG_1__hstrctlen               29
+#define   O_XGMAC_CONFIG_1__hstrfen                 28
+#define   O_XGMAC_CONFIG_1__tfen                    26
+#define   O_XGMAC_CONFIG_1__rfen                    24
+#define   O_XGMAC_CONFIG_1__hstrctlshrtp            12
+#define   O_XGMAC_CONFIG_1__hstdlyfcstx             10
+#define   W_XGMAC_CONFIG_1__hstdlyfcstx              2
+#define   O_XGMAC_CONFIG_1__hstdlyfcsrx              8
+#define   W_XGMAC_CONFIG_1__hstdlyfcsrx              2
+#define   O_XGMAC_CONFIG_1__hstppen                  7
+#define   O_XGMAC_CONFIG_1__hstbytswp                6
+#define   O_XGMAC_CONFIG_1__hstdrplt64               5
+#define   O_XGMAC_CONFIG_1__hstprmscrx               4
+#define   O_XGMAC_CONFIG_1__hstlenchk                3
+#define   O_XGMAC_CONFIG_1__hstgenfcs                2
+#define   O_XGMAC_CONFIG_1__hstpadmode               0
+#define   W_XGMAC_CONFIG_1__hstpadmode               2
+#define R_XGMAC_CONFIG_2    0x02
+#define   O_XGMAC_CONFIG_2__hsttctlfrcp             31
+#define   O_XGMAC_CONFIG_2__hstmlnkflth             27
+#define   O_XGMAC_CONFIG_2__hstalnkflth             26
+#define   O_XGMAC_CONFIG_2__rflnkflt                24
+#define   W_XGMAC_CONFIG_2__rflnkflt                 2                          
+#define   O_XGMAC_CONFIG_2__hstipgextmod            16
+#define   W_XGMAC_CONFIG_2__hstipgextmod             5
+#define   O_XGMAC_CONFIG_2__hstrctlfrcp             15
+#define   O_XGMAC_CONFIG_2__hstipgexten              5
+#define   O_XGMAC_CONFIG_2__hstmipgext               0
+#define   W_XGMAC_CONFIG_2__hstmipgext               5
+#define R_XGMAC_CONFIG_3    0x03
+#define   O_XGMAC_CONFIG_3__hstfltrfrm              31
+#define   W_XGMAC_CONFIG_3__hstfltrfrm              16
+#define   O_XGMAC_CONFIG_3__hstfltrfrmdc            15
+#define   W_XGMAC_CONFIG_3__hstfltrfrmdc            16
+#define R_XGMAC_STATION_ADDRESS_LS      0x04
+#define   O_XGMAC_STATION_ADDRESS_LS__hstmacadr0    0
+#define   W_XGMAC_STATION_ADDRESS_LS__hstmacadr0    32
+#define R_XGMAC_STATION_ADDRESS_MS      0x05
+#define R_XGMAC_MAX_FRAME_LEN           0x08
+#define   O_XGMAC_MAX_FRAME_LEN__hstmxfrmwctx       16
+#define   W_XGMAC_MAX_FRAME_LEN__hstmxfrmwctx       14
+#define   O_XGMAC_MAX_FRAME_LEN__hstmxfrmbcrx        0
+#define   W_XGMAC_MAX_FRAME_LEN__hstmxfrmbcrx       16
+#define R_XGMAC_REV_LEVEL               0x0B
+#define   O_XGMAC_REV_LEVEL__revlvl                  0
+#define   W_XGMAC_REV_LEVEL__revlvl                 15
+#define R_XGMAC_MIIM_COMMAND            0x10
+#define   O_XGMAC_MIIM_COMMAND__hstldcmd             3
+#define   O_XGMAC_MIIM_COMMAND__hstmiimcmd           0
+#define   W_XGMAC_MIIM_COMMAND__hstmiimcmd           3
+#define R_XGMAC_MIIM_FILED              0x11
+#define   O_XGMAC_MIIM_FILED__hststfield            30
+#define   W_XGMAC_MIIM_FILED__hststfield             2
+#define   O_XGMAC_MIIM_FILED__hstopfield            28
+#define   W_XGMAC_MIIM_FILED__hstopfield             2
+#define   O_XGMAC_MIIM_FILED__hstphyadx             23
+#define   W_XGMAC_MIIM_FILED__hstphyadx              5
+#define   O_XGMAC_MIIM_FILED__hstregadx             18
+#define   W_XGMAC_MIIM_FILED__hstregadx              5
+#define   O_XGMAC_MIIM_FILED__hsttafield            16
+#define   W_XGMAC_MIIM_FILED__hsttafield             2
+#define   O_XGMAC_MIIM_FILED__miimrddat              0
+#define   W_XGMAC_MIIM_FILED__miimrddat             16
+#define R_XGMAC_MIIM_CONFIG             0x12
+#define   O_XGMAC_MIIM_CONFIG__hstnopram             7
+#define   O_XGMAC_MIIM_CONFIG__hstclkdiv             0
+#define   W_XGMAC_MIIM_CONFIG__hstclkdiv             7
+#define R_XGMAC_MIIM_LINK_FAIL_VECTOR   0x13
+#define   O_XGMAC_MIIM_LINK_FAIL_VECTOR__miimlfvec   0
+#define   W_XGMAC_MIIM_LINK_FAIL_VECTOR__miimlfvec  32
+#define R_XGMAC_MIIM_INDICATOR          0x14
+#define   O_XGMAC_MIIM_INDICATOR__miimphylf          4
+#define   O_XGMAC_MIIM_INDICATOR__miimmoncplt        3
+#define   O_XGMAC_MIIM_INDICATOR__miimmonvld         2
+#define   O_XGMAC_MIIM_INDICATOR__miimmon            1
+#define   O_XGMAC_MIIM_INDICATOR__miimbusy           0
+
+/* Glue logic register and bit field definitions */
+#define R_MAC_ADDR0                                                 0x50
+#define R_MAC_ADDR1                                                 0x52
+#define R_MAC_ADDR2                                                 0x54
+#define R_MAC_ADDR3                                                 0x56
+#define R_MAC_ADDR_MASK2                                            0x58
+#define R_MAC_ADDR_MASK3                                            0x5A
+#define R_MAC_FILTER_CONFIG                                         0x5C
+#define   O_MAC_FILTER_CONFIG__BROADCAST_EN                         10
+#define   O_MAC_FILTER_CONFIG__PAUSE_FRAME_EN                       9
+#define   O_MAC_FILTER_CONFIG__ALL_MCAST_EN                         8
+#define   O_MAC_FILTER_CONFIG__ALL_UCAST_EN                         7
+#define   O_MAC_FILTER_CONFIG__HASH_MCAST_EN                        6
+#define   O_MAC_FILTER_CONFIG__HASH_UCAST_EN                        5
+#define   O_MAC_FILTER_CONFIG__ADDR_MATCH_DISC                      4
+#define   O_MAC_FILTER_CONFIG__MAC_ADDR3_VALID                      3
+#define   O_MAC_FILTER_CONFIG__MAC_ADDR2_VALID                      2
+#define   O_MAC_FILTER_CONFIG__MAC_ADDR1_VALID                      1
+#define   O_MAC_FILTER_CONFIG__MAC_ADDR0_VALID                      0
+#define R_HASH_TABLE_VECTOR                                         0x30
+#define R_TX_CONTROL                                                 0x0A0
+#define   O_TX_CONTROL__Tx15Halt                                     31
+#define   O_TX_CONTROL__Tx14Halt                                     30
+#define   O_TX_CONTROL__Tx13Halt                                     29
+#define   O_TX_CONTROL__Tx12Halt                                     28
+#define   O_TX_CONTROL__Tx11Halt                                     27
+#define   O_TX_CONTROL__Tx10Halt                                     26
+#define   O_TX_CONTROL__Tx9Halt                                      25
+#define   O_TX_CONTROL__Tx8Halt                                      24
+#define   O_TX_CONTROL__Tx7Halt                                      23
+#define   O_TX_CONTROL__Tx6Halt                                      22
+#define   O_TX_CONTROL__Tx5Halt                                      21
+#define   O_TX_CONTROL__Tx4Halt                                      20
+#define   O_TX_CONTROL__Tx3Halt                                      19
+#define   O_TX_CONTROL__Tx2Halt                                      18
+#define   O_TX_CONTROL__Tx1Halt                                      17
+#define   O_TX_CONTROL__Tx0Halt                                      16
+#define   O_TX_CONTROL__TxIdle                                       15
+#define   O_TX_CONTROL__TxEnable                                     14
+#define   O_TX_CONTROL__TxThreshold                                  0
+#define   W_TX_CONTROL__TxThreshold                                  14
+#define R_RX_CONTROL                                                 0x0A1
+#define   O_RX_1588_TS                                               11
+#define   O_RX_CONTROL__RGMII                                        10
+#define   O_RX_CONTROL__RxHalt                                       1
+#define   O_RX_CONTROL__RxEnable                                     0
+#define R_DESC_PACK_CTRL                                            0x0A2
+#define   O_DESC_PACK_CTRL__ByteOffset                              17
+#define   W_DESC_PACK_CTRL__ByteOffset                              3
+#define   O_DESC_PACK_CTRL__PrePadEnable                            16
+#define   O_DESC_PACK_CTRL__MaxEntry                                14
+#define   W_DESC_PACK_CTRL__MaxEntry                                2
+#define   O_DESC_PACK_CTRL__RegularSize                             0
+#define   W_DESC_PACK_CTRL__RegularSize                             14
+#define R_STATCTRL                                                  0x0A3
+#define   O_STATCTRL__OverFlowEn                                    4
+#define   O_STATCTRL__GIG                                           3
+#define   O_STATCTRL__Sten                                          2
+#define   O_STATCTRL__ClrCnt                                        1
+#define   O_STATCTRL__AutoZ                                         0
+#define R_L2ALLOCCTRL                                               0x0A4
+#define   O_L2ALLOCCTRL__TxL2Allocate                               9
+#define   W_L2ALLOCCTRL__TxL2Allocate                               9
+#define   O_L2ALLOCCTRL__RxL2Allocate                               0
+#define   W_L2ALLOCCTRL__RxL2Allocate                               9
+#define R_INTMASK                                                   0x0A5
+#define   O_INTMASK__Spi4TxError                                     28
+#define   O_INTMASK__Spi4RxError                                     27
+#define   O_INTMASK__RGMIIHalfDupCollision                           27
+#define   O_INTMASK__Abort                                           26
+#define   O_INTMASK__Underrun                                        25
+#define   O_INTMASK__DiscardPacket                                   24
+#define   O_INTMASK__AsyncFifoFull                                   23
+#define   O_INTMASK__TagFull                                         22
+#define   O_INTMASK__Class3Full                                      21
+#define   O_INTMASK__C3EarlyFull                                     20
+#define   O_INTMASK__Class2Full                                      19
+#define   O_INTMASK__C2EarlyFull                                     18
+#define   O_INTMASK__Class1Full                                      17
+#define   O_INTMASK__C1EarlyFull                                     16
+#define   O_INTMASK__Class0Full                                      15
+#define   O_INTMASK__C0EarlyFull                                     14
+#define   O_INTMASK__RxDataFull                                      13
+#define   O_INTMASK__RxEarlyFull                                     12
+#define   O_INTMASK__RFreeEmpty                                      9
+#define   O_INTMASK__RFEarlyEmpty                                    8
+#define   O_INTMASK__P2PSpillEcc                                     7
+#define   O_INTMASK__FreeDescFull                                    5
+#define   O_INTMASK__FreeEarlyFull                                   4
+#define   O_INTMASK__TxFetchError                                    3
+#define   O_INTMASK__StatCarry                                       2
+#define   O_INTMASK__MDInt                                           1
+#define   O_INTMASK__TxIllegal                                       0
+#define R_INTREG                                                    0x0A6
+#define   O_INTREG__Spi4TxError                                     28
+#define   O_INTREG__Spi4RxError                                     27
+#define   O_INTREG__RGMIIHalfDupCollision                           27
+#define   O_INTREG__Abort                                           26
+#define   O_INTREG__Underrun                                        25
+#define   O_INTREG__DiscardPacket                                   24
+#define   O_INTREG__AsyncFifoFull                                   23
+#define   O_INTREG__TagFull                                         22
+#define   O_INTREG__Class3Full                                      21
+#define   O_INTREG__C3EarlyFull                                     20
+#define   O_INTREG__Class2Full                                      19
+#define   O_INTREG__C2EarlyFull                                     18
+#define   O_INTREG__Class1Full                                      17
+#define   O_INTREG__C1EarlyFull                                     16
+#define   O_INTREG__Class0Full                                      15
+#define   O_INTREG__C0EarlyFull                                     14
+#define   O_INTREG__RxDataFull                                      13
+#define   O_INTREG__RxEarlyFull                                     12
+#define   O_INTREG__RFreeEmpty                                      9
+#define   O_INTREG__RFEarlyEmpty                                    8
+#define   O_INTREG__P2PSpillEcc                                     7
+#define   O_INTREG__FreeDescFull                                    5
+#define   O_INTREG__FreeEarlyFull                                   4
+#define   O_INTREG__TxFetchError                                    3
+#define   O_INTREG__StatCarry                                       2
+#define   O_INTREG__MDInt                                           1
+#define   O_INTREG__TxIllegal                                       0
+#define R_TXRETRY                                                   0x0A7
+#define   O_TXRETRY__CollisionRetry                                 6
+#define   O_TXRETRY__BusErrorRetry                                  5
+#define   O_TXRETRY__UnderRunRetry                                  4
+#define   O_TXRETRY__Retries                                        0
+#define   W_TXRETRY__Retries                                        4
+#define R_CORECONTROL                                               0x0A8
+#define   O_CORECONTROL__ErrorThread                                4
+#define   W_CORECONTROL__ErrorThread                                7
+#define   O_CORECONTROL__Shutdown                                   2
+#define   O_CORECONTROL__Speed                                      0
+#define   W_CORECONTROL__Speed                                      2
+#define R_BYTEOFFSET0                                               0x0A9
+#define R_BYTEOFFSET1                                               0x0AA
+#define R_L2TYPE_0                                                  0x0F0
+#define   O_L2TYPE__ExtraHdrProtoSize                               26
+#define   W_L2TYPE__ExtraHdrProtoSize                               5
+#define   O_L2TYPE__ExtraHdrProtoOffset                             20
+#define   W_L2TYPE__ExtraHdrProtoOffset                             6
+#define   O_L2TYPE__ExtraHeaderSize                                 14
+#define   W_L2TYPE__ExtraHeaderSize                                 6
+#define   O_L2TYPE__ProtoOffset                                     8
+#define   W_L2TYPE__ProtoOffset                                     6
+#define   O_L2TYPE__L2HdrOffset                                     2
+#define   W_L2TYPE__L2HdrOffset                                     6
+#define   O_L2TYPE__L2Proto                                         0
+#define   W_L2TYPE__L2Proto                                         2
+#define R_L2TYPE_1                                                  0xF0
+#define R_L2TYPE_2                                                  0xF0
+#define R_L2TYPE_3                                                  0xF0
+#define R_PARSERCONFIGREG                                           0x100
+#define   O_PARSERCONFIGREG__CRCHashPoly                            8
+#define   W_PARSERCONFIGREG__CRCHashPoly                            7
+#define   O_PARSERCONFIGREG__PrePadOffset                           4
+#define   W_PARSERCONFIGREG__PrePadOffset                           4
+#define   O_PARSERCONFIGREG__UseCAM                                 2
+#define   O_PARSERCONFIGREG__UseHASH                                1
+#define   O_PARSERCONFIGREG__UseProto                               0
+#define R_L3CTABLE                                                  0x140
+#define   O_L3CTABLE__Offset0                                       25
+#define   W_L3CTABLE__Offset0                                       7
+#define   O_L3CTABLE__Len0                                          21
+#define   W_L3CTABLE__Len0                                          4
+#define   O_L3CTABLE__Offset1                                       14
+#define   W_L3CTABLE__Offset1                                       7
+#define   O_L3CTABLE__Len1                                          10
+#define   W_L3CTABLE__Len1                                          4
+#define   O_L3CTABLE__Offset2                                       4
+#define   W_L3CTABLE__Offset2                                       6
+#define   O_L3CTABLE__Len2                                          0
+#define   W_L3CTABLE__Len2                                          4
+#define   O_L3CTABLE__L3HdrOffset                                   26
+#define   W_L3CTABLE__L3HdrOffset                                   6
+#define   O_L3CTABLE__L4ProtoOffset                                 20
+#define   W_L3CTABLE__L4ProtoOffset                                 6
+#define   O_L3CTABLE__IPChksumCompute                               19
+#define   O_L3CTABLE__L4Classify                                    18
+#define   O_L3CTABLE__L2Proto                                       16
+#define   W_L3CTABLE__L2Proto                                       2
+#define   O_L3CTABLE__L3ProtoKey                                    0
+#define   W_L3CTABLE__L3ProtoKey                                    16
+#define R_L4CTABLE                                                  0x160
+#define   O_L4CTABLE__Offset0                                       21
+#define   W_L4CTABLE__Offset0                                       6
+#define   O_L4CTABLE__Len0                                          17
+#define   W_L4CTABLE__Len0                                          4
+#define   O_L4CTABLE__Offset1                                       11
+#define   W_L4CTABLE__Offset1                                       6
+#define   O_L4CTABLE__Len1                                          7
+#define   W_L4CTABLE__Len1                                          4
+#define   O_L4CTABLE__TCPChksumEnable                               0
+#define R_CAM4X128TABLE                                             0x172
+#define   O_CAM4X128TABLE__ClassId                                  7
+#define   W_CAM4X128TABLE__ClassId                                  2
+#define   O_CAM4X128TABLE__BucketId                                 1
+#define   W_CAM4X128TABLE__BucketId                                 6
+#define   O_CAM4X128TABLE__UseBucket                                0
+#define R_CAM4X128KEY                                               0x180
+#define R_TRANSLATETABLE                                            0x1A0
+#define R_DMACR0                                                    0x200
+#define   O_DMACR0__Data0WrMaxCr                                    27
+#define   W_DMACR0__Data0WrMaxCr                                    3
+#define   O_DMACR0__Data0RdMaxCr                                    24
+#define   W_DMACR0__Data0RdMaxCr                                    3
+#define   O_DMACR0__Data1WrMaxCr                                    21
+#define   W_DMACR0__Data1WrMaxCr                                    3
+#define   O_DMACR0__Data1RdMaxCr                                    18
+#define   W_DMACR0__Data1RdMaxCr                                    3
+#define   O_DMACR0__Data2WrMaxCr                                    15
+#define   W_DMACR0__Data2WrMaxCr                                    3
+#define   O_DMACR0__Data2RdMaxCr                                    12
+#define   W_DMACR0__Data2RdMaxCr                                    3
+#define   O_DMACR0__Data3WrMaxCr                                    9
+#define   W_DMACR0__Data3WrMaxCr                                    3
+#define   O_DMACR0__Data3RdMaxCr                                    6
+#define   W_DMACR0__Data3RdMaxCr                                    3
+#define   O_DMACR0__Data4WrMaxCr                                    3
+#define   W_DMACR0__Data4WrMaxCr                                    3
+#define   O_DMACR0__Data4RdMaxCr                                    0
+#define   W_DMACR0__Data4RdMaxCr                                    3
+#define R_DMACR1                                                    0x201
+#define   O_DMACR1__Data5WrMaxCr                                    27
+#define   W_DMACR1__Data5WrMaxCr                                    3
+#define   O_DMACR1__Data5RdMaxCr                                    24
+#define   W_DMACR1__Data5RdMaxCr                                    3
+#define   O_DMACR1__Data6WrMaxCr                                    21
+#define   W_DMACR1__Data6WrMaxCr                                    3
+#define   O_DMACR1__Data6RdMaxCr                                    18
+#define   W_DMACR1__Data6RdMaxCr                                    3
+#define   O_DMACR1__Data7WrMaxCr                                    15
+#define   W_DMACR1__Data7WrMaxCr                                    3
+#define   O_DMACR1__Data7RdMaxCr                                    12
+#define   W_DMACR1__Data7RdMaxCr                                    3
+#define   O_DMACR1__Data8WrMaxCr                                    9
+#define   W_DMACR1__Data8WrMaxCr                                    3
+#define   O_DMACR1__Data8RdMaxCr                                    6
+#define   W_DMACR1__Data8RdMaxCr                                    3
+#define   O_DMACR1__Data9WrMaxCr                                    3
+#define   W_DMACR1__Data9WrMaxCr                                    3
+#define   O_DMACR1__Data9RdMaxCr                                    0
+#define   W_DMACR1__Data9RdMaxCr                                    3
+#define R_DMACR2                                                    0x202
+#define   O_DMACR2__Data10WrMaxCr                                   27
+#define   W_DMACR2__Data10WrMaxCr                                   3
+#define   O_DMACR2__Data10RdMaxCr                                   24
+#define   W_DMACR2__Data10RdMaxCr                                   3
+#define   O_DMACR2__Data11WrMaxCr                                   21
+#define   W_DMACR2__Data11WrMaxCr                                   3
+#define   O_DMACR2__Data11RdMaxCr                                   18
+#define   W_DMACR2__Data11RdMaxCr                                   3
+#define   O_DMACR2__Data12WrMaxCr                                   15
+#define   W_DMACR2__Data12WrMaxCr                                   3
+#define   O_DMACR2__Data12RdMaxCr                                   12
+#define   W_DMACR2__Data12RdMaxCr                                   3
+#define   O_DMACR2__Data13WrMaxCr                                   9
+#define   W_DMACR2__Data13WrMaxCr                                   3
+#define   O_DMACR2__Data13RdMaxCr                                   6
+#define   W_DMACR2__Data13RdMaxCr                                   3
+#define   O_DMACR2__Data14WrMaxCr                                   3
+#define   W_DMACR2__Data14WrMaxCr                                   3
+#define   O_DMACR2__Data14RdMaxCr                                   0
+#define   W_DMACR2__Data14RdMaxCr                                   3
+#define R_DMACR3                                                    0x203
+#define   O_DMACR3__Data15WrMaxCr                                   27
+#define   W_DMACR3__Data15WrMaxCr                                   3
+#define   O_DMACR3__Data15RdMaxCr                                   24
+#define   W_DMACR3__Data15RdMaxCr                                   3
+#define   O_DMACR3__SpClassWrMaxCr                                  21
+#define   W_DMACR3__SpClassWrMaxCr                                  3
+#define   O_DMACR3__SpClassRdMaxCr                                  18
+#define   W_DMACR3__SpClassRdMaxCr                                  3
+#define   O_DMACR3__JumFrInWrMaxCr                                  15
+#define   W_DMACR3__JumFrInWrMaxCr                                  3
+#define   O_DMACR3__JumFrInRdMaxCr                                  12
+#define   W_DMACR3__JumFrInRdMaxCr                                  3
+#define   O_DMACR3__RegFrInWrMaxCr                                  9
+#define   W_DMACR3__RegFrInWrMaxCr                                  3
+#define   O_DMACR3__RegFrInRdMaxCr                                  6
+#define   W_DMACR3__RegFrInRdMaxCr                                  3
+#define   O_DMACR3__FrOutWrMaxCr                                    3
+#define   W_DMACR3__FrOutWrMaxCr                                    3
+#define   O_DMACR3__FrOutRdMaxCr                                    0
+#define   W_DMACR3__FrOutRdMaxCr                                    3
+#define R_REG_FRIN_SPILL_MEM_START_0                                0x204
+#define   O_REG_FRIN_SPILL_MEM_START_0__RegFrInSpillMemStart0        0
+#define   W_REG_FRIN_SPILL_MEM_START_0__RegFrInSpillMemStart0       32
+#define R_REG_FRIN_SPILL_MEM_START_1                                0x205
+#define   O_REG_FRIN_SPILL_MEM_START_1__RegFrInSpillMemStart1        0
+#define   W_REG_FRIN_SPILL_MEM_START_1__RegFrInSpillMemStart1        3
+#define R_REG_FRIN_SPILL_MEM_SIZE                                   0x206
+#define   O_REG_FRIN_SPILL_MEM_SIZE__RegFrInSpillMemSize             0
+#define   W_REG_FRIN_SPILL_MEM_SIZE__RegFrInSpillMemSize            32
+#define R_FROUT_SPILL_MEM_START_0                                   0x207
+#define   O_FROUT_SPILL_MEM_START_0__FrOutSpillMemStart0             0
+#define   W_FROUT_SPILL_MEM_START_0__FrOutSpillMemStart0            32
+#define R_FROUT_SPILL_MEM_START_1                                   0x208
+#define   O_FROUT_SPILL_MEM_START_1__FrOutSpillMemStart1             0
+#define   W_FROUT_SPILL_MEM_START_1__FrOutSpillMemStart1             3
+#define R_FROUT_SPILL_MEM_SIZE                                      0x209
+#define   O_FROUT_SPILL_MEM_SIZE__FrOutSpillMemSize                  0
+#define   W_FROUT_SPILL_MEM_SIZE__FrOutSpillMemSize                 32
+#define R_CLASS0_SPILL_MEM_START_0                                  0x20A
+#define   O_CLASS0_SPILL_MEM_START_0__Class0SpillMemStart0           0
+#define   W_CLASS0_SPILL_MEM_START_0__Class0SpillMemStart0          32
+#define R_CLASS0_SPILL_MEM_START_1                                  0x20B
+#define   O_CLASS0_SPILL_MEM_START_1__Class0SpillMemStart1           0
+#define   W_CLASS0_SPILL_MEM_START_1__Class0SpillMemStart1           3
+#define R_CLASS0_SPILL_MEM_SIZE                                     0x20C
+#define   O_CLASS0_SPILL_MEM_SIZE__Class0SpillMemSize                0
+#define   W_CLASS0_SPILL_MEM_SIZE__Class0SpillMemSize               32
+#define R_JUMFRIN_SPILL_MEM_START_0                                 0x20D
+#define   O_JUMFRIN_SPILL_MEM_START_0__JumFrInSpillMemStar0          0
+#define   W_JUMFRIN_SPILL_MEM_START_0__JumFrInSpillMemStar0         32
+#define R_JUMFRIN_SPILL_MEM_START_1                                 0x20E
+#define   O_JUMFRIN_SPILL_MEM_START_1__JumFrInSpillMemStart1         0
+#define   W_JUMFRIN_SPILL_MEM_START_1__JumFrInSpillMemStart1         3
+#define R_JUMFRIN_SPILL_MEM_SIZE                                    0x20F
+#define   O_JUMFRIN_SPILL_MEM_SIZE__JumFrInSpillMemSize              0
+#define   W_JUMFRIN_SPILL_MEM_SIZE__JumFrInSpillMemSize             32
+#define R_CLASS1_SPILL_MEM_START_0                                  0x210
+#define   O_CLASS1_SPILL_MEM_START_0__Class1SpillMemStart0           0
+#define   W_CLASS1_SPILL_MEM_START_0__Class1SpillMemStart0          32
+#define R_CLASS1_SPILL_MEM_START_1                                  0x211
+#define   O_CLASS1_SPILL_MEM_START_1__Class1SpillMemStart1           0
+#define   W_CLASS1_SPILL_MEM_START_1__Class1SpillMemStart1           3
+#define R_CLASS1_SPILL_MEM_SIZE                                     0x212
+#define   O_CLASS1_SPILL_MEM_SIZE__Class1SpillMemSize                0
+#define   W_CLASS1_SPILL_MEM_SIZE__Class1SpillMemSize               32
+#define R_CLASS2_SPILL_MEM_START_0                                  0x213
+#define   O_CLASS2_SPILL_MEM_START_0__Class2SpillMemStart0           0
+#define   W_CLASS2_SPILL_MEM_START_0__Class2SpillMemStart0          32
+#define R_CLASS2_SPILL_MEM_START_1                                  0x214
+#define   O_CLASS2_SPILL_MEM_START_1__Class2SpillMemStart1           0
+#define   W_CLASS2_SPILL_MEM_START_1__Class2SpillMemStart1           3
+#define R_CLASS2_SPILL_MEM_SIZE                                     0x215
+#define   O_CLASS2_SPILL_MEM_SIZE__Class2SpillMemSize                0
+#define   W_CLASS2_SPILL_MEM_SIZE__Class2SpillMemSize               32
+#define R_CLASS3_SPILL_MEM_START_0                                  0x216
+#define   O_CLASS3_SPILL_MEM_START_0__Class3SpillMemStart0           0
+#define   W_CLASS3_SPILL_MEM_START_0__Class3SpillMemStart0          32
+#define R_CLASS3_SPILL_MEM_START_1                                  0x217
+#define   O_CLASS3_SPILL_MEM_START_1__Class3SpillMemStart1           0
+#define   W_CLASS3_SPILL_MEM_START_1__Class3SpillMemStart1           3
+#define R_CLASS3_SPILL_MEM_SIZE                                     0x218
+#define   O_CLASS3_SPILL_MEM_SIZE__Class3SpillMemSize                0
+#define   W_CLASS3_SPILL_MEM_SIZE__Class3SpillMemSize               32
+#define R_REG_FRIN1_SPILL_MEM_START_0                               0x219
+#define R_REG_FRIN1_SPILL_MEM_START_1                               0x21a
+#define R_REG_FRIN1_SPILL_MEM_SIZE                                  0x21b
+#define R_SPIHNGY0                                                  0x219
+#define   O_SPIHNGY0__EG_HNGY_THRESH_0                              24
+#define   W_SPIHNGY0__EG_HNGY_THRESH_0                              7
+#define   O_SPIHNGY0__EG_HNGY_THRESH_1                              16
+#define   W_SPIHNGY0__EG_HNGY_THRESH_1                              7
+#define   O_SPIHNGY0__EG_HNGY_THRESH_2                              8
+#define   W_SPIHNGY0__EG_HNGY_THRESH_2                              7
+#define   O_SPIHNGY0__EG_HNGY_THRESH_3                              0
+#define   W_SPIHNGY0__EG_HNGY_THRESH_3                              7
+#define R_SPIHNGY1                                                  0x21A
+#define   O_SPIHNGY1__EG_HNGY_THRESH_4                              24
+#define   W_SPIHNGY1__EG_HNGY_THRESH_4                              7
+#define   O_SPIHNGY1__EG_HNGY_THRESH_5                              16
+#define   W_SPIHNGY1__EG_HNGY_THRESH_5                              7
+#define   O_SPIHNGY1__EG_HNGY_THRESH_6                              8
+#define   W_SPIHNGY1__EG_HNGY_THRESH_6                              7
+#define   O_SPIHNGY1__EG_HNGY_THRESH_7                              0
+#define   W_SPIHNGY1__EG_HNGY_THRESH_7                              7
+#define R_SPIHNGY2                                                  0x21B
+#define   O_SPIHNGY2__EG_HNGY_THRESH_8                              24
+#define   W_SPIHNGY2__EG_HNGY_THRESH_8                              7
+#define   O_SPIHNGY2__EG_HNGY_THRESH_9                              16
+#define   W_SPIHNGY2__EG_HNGY_THRESH_9                              7
+#define   O_SPIHNGY2__EG_HNGY_THRESH_10                             8
+#define   W_SPIHNGY2__EG_HNGY_THRESH_10                             7
+#define   O_SPIHNGY2__EG_HNGY_THRESH_11                             0
+#define   W_SPIHNGY2__EG_HNGY_THRESH_11                             7
+#define R_SPIHNGY3                                                  0x21C
+#define   O_SPIHNGY3__EG_HNGY_THRESH_12                             24
+#define   W_SPIHNGY3__EG_HNGY_THRESH_12                             7
+#define   O_SPIHNGY3__EG_HNGY_THRESH_13                             16
+#define   W_SPIHNGY3__EG_HNGY_THRESH_13                             7
+#define   O_SPIHNGY3__EG_HNGY_THRESH_14                             8
+#define   W_SPIHNGY3__EG_HNGY_THRESH_14                             7
+#define   O_SPIHNGY3__EG_HNGY_THRESH_15                             0
+#define   W_SPIHNGY3__EG_HNGY_THRESH_15                             7
+#define R_SPISTRV0                                                  0x21D
+#define   O_SPISTRV0__EG_STRV_THRESH_0                              24
+#define   W_SPISTRV0__EG_STRV_THRESH_0                              7
+#define   O_SPISTRV0__EG_STRV_THRESH_1                              16
+#define   W_SPISTRV0__EG_STRV_THRESH_1                              7
+#define   O_SPISTRV0__EG_STRV_THRESH_2                              8
+#define   W_SPISTRV0__EG_STRV_THRESH_2                              7
+#define   O_SPISTRV0__EG_STRV_THRESH_3                              0
+#define   W_SPISTRV0__EG_STRV_THRESH_3                              7
+#define R_SPISTRV1                                                  0x21E
+#define   O_SPISTRV1__EG_STRV_THRESH_4                              24
+#define   W_SPISTRV1__EG_STRV_THRESH_4                              7
+#define   O_SPISTRV1__EG_STRV_THRESH_5                              16
+#define   W_SPISTRV1__EG_STRV_THRESH_5                              7
+#define   O_SPISTRV1__EG_STRV_THRESH_6                              8
+#define   W_SPISTRV1__EG_STRV_THRESH_6                              7
+#define   O_SPISTRV1__EG_STRV_THRESH_7                              0
+#define   W_SPISTRV1__EG_STRV_THRESH_7                              7
+#define R_SPISTRV2                                                  0x21F
+#define   O_SPISTRV2__EG_STRV_THRESH_8                              24
+#define   W_SPISTRV2__EG_STRV_THRESH_8                              7
+#define   O_SPISTRV2__EG_STRV_THRESH_9                              16
+#define   W_SPISTRV2__EG_STRV_THRESH_9                              7
+#define   O_SPISTRV2__EG_STRV_THRESH_10                             8
+#define   W_SPISTRV2__EG_STRV_THRESH_10                             7
+#define   O_SPISTRV2__EG_STRV_THRESH_11                             0
+#define   W_SPISTRV2__EG_STRV_THRESH_11                             7
+#define R_SPISTRV3                                                  0x220
+#define   O_SPISTRV3__EG_STRV_THRESH_12                             24
+#define   W_SPISTRV3__EG_STRV_THRESH_12                             7
+#define   O_SPISTRV3__EG_STRV_THRESH_13                             16
+#define   W_SPISTRV3__EG_STRV_THRESH_13                             7
+#define   O_SPISTRV3__EG_STRV_THRESH_14                             8
+#define   W_SPISTRV3__EG_STRV_THRESH_14                             7
+#define   O_SPISTRV3__EG_STRV_THRESH_15                             0
+#define   W_SPISTRV3__EG_STRV_THRESH_15                             7
+#define R_TXDATAFIFO0                                               0x221
+#define   O_TXDATAFIFO0__Tx0DataFifoStart                           24
+#define   W_TXDATAFIFO0__Tx0DataFifoStart                           7
+#define   O_TXDATAFIFO0__Tx0DataFifoSize                            16
+#define   W_TXDATAFIFO0__Tx0DataFifoSize                            7
+#define   O_TXDATAFIFO0__Tx1DataFifoStart                           8
+#define   W_TXDATAFIFO0__Tx1DataFifoStart                           7
+#define   O_TXDATAFIFO0__Tx1DataFifoSize                            0
+#define   W_TXDATAFIFO0__Tx1DataFifoSize                            7
+#define R_TXDATAFIFO1                                               0x222
+#define   O_TXDATAFIFO1__Tx2DataFifoStart                           24
+#define   W_TXDATAFIFO1__Tx2DataFifoStart                           7
+#define   O_TXDATAFIFO1__Tx2DataFifoSize                            16
+#define   W_TXDATAFIFO1__Tx2DataFifoSize                            7
+#define   O_TXDATAFIFO1__Tx3DataFifoStart                           8
+#define   W_TXDATAFIFO1__Tx3DataFifoStart                           7
+#define   O_TXDATAFIFO1__Tx3DataFifoSize                            0
+#define   W_TXDATAFIFO1__Tx3DataFifoSize                            7
+#define R_TXDATAFIFO2                                               0x223
+#define   O_TXDATAFIFO2__Tx4DataFifoStart                           24
+#define   W_TXDATAFIFO2__Tx4DataFifoStart                           7
+#define   O_TXDATAFIFO2__Tx4DataFifoSize                            16
+#define   W_TXDATAFIFO2__Tx4DataFifoSize                            7
+#define   O_TXDATAFIFO2__Tx5DataFifoStart                           8
+#define   W_TXDATAFIFO2__Tx5DataFifoStart                           7
+#define   O_TXDATAFIFO2__Tx5DataFifoSize                            0
+#define   W_TXDATAFIFO2__Tx5DataFifoSize                            7
+#define R_TXDATAFIFO3                                               0x224
+#define   O_TXDATAFIFO3__Tx6DataFifoStart                           24
+#define   W_TXDATAFIFO3__Tx6DataFifoStart                           7
+#define   O_TXDATAFIFO3__Tx6DataFifoSize                            16
+#define   W_TXDATAFIFO3__Tx6DataFifoSize                            7
+#define   O_TXDATAFIFO3__Tx7DataFifoStart                           8
+#define   W_TXDATAFIFO3__Tx7DataFifoStart                           7
+#define   O_TXDATAFIFO3__Tx7DataFifoSize                            0
+#define   W_TXDATAFIFO3__Tx7DataFifoSize                            7
+#define R_TXDATAFIFO4                                               0x225
+#define   O_TXDATAFIFO4__Tx8DataFifoStart                           24
+#define   W_TXDATAFIFO4__Tx8DataFifoStart                           7
+#define   O_TXDATAFIFO4__Tx8DataFifoSize                            16
+#define   W_TXDATAFIFO4__Tx8DataFifoSize                            7
+#define   O_TXDATAFIFO4__Tx9DataFifoStart                           8
+#define   W_TXDATAFIFO4__Tx9DataFifoStart                           7
+#define   O_TXDATAFIFO4__Tx9DataFifoSize                            0
+#define   W_TXDATAFIFO4__Tx9DataFifoSize                            7
+#define R_TXDATAFIFO5                                               0x226
+#define   O_TXDATAFIFO5__Tx10DataFifoStart                          24
+#define   W_TXDATAFIFO5__Tx10DataFifoStart                          7
+#define   O_TXDATAFIFO5__Tx10DataFifoSize                           16
+#define   W_TXDATAFIFO5__Tx10DataFifoSize                           7
+#define   O_TXDATAFIFO5__Tx11DataFifoStart                          8
+#define   W_TXDATAFIFO5__Tx11DataFifoStart                          7
+#define   O_TXDATAFIFO5__Tx11DataFifoSize                           0
+#define   W_TXDATAFIFO5__Tx11DataFifoSize                           7
+#define R_TXDATAFIFO6                                               0x227
+#define   O_TXDATAFIFO6__Tx12DataFifoStart                          24
+#define   W_TXDATAFIFO6__Tx12DataFifoStart                          7
+#define   O_TXDATAFIFO6__Tx12DataFifoSize                           16
+#define   W_TXDATAFIFO6__Tx12DataFifoSize                           7
+#define   O_TXDATAFIFO6__Tx13DataFifoStart                          8
+#define   W_TXDATAFIFO6__Tx13DataFifoStart                          7
+#define   O_TXDATAFIFO6__Tx13DataFifoSize                           0
+#define   W_TXDATAFIFO6__Tx13DataFifoSize                           7
+#define R_TXDATAFIFO7                                               0x228
+#define   O_TXDATAFIFO7__Tx14DataFifoStart                          24
+#define   W_TXDATAFIFO7__Tx14DataFifoStart                          7
+#define   O_TXDATAFIFO7__Tx14DataFifoSize                           16
+#define   W_TXDATAFIFO7__Tx14DataFifoSize                           7
+#define   O_TXDATAFIFO7__Tx15DataFifoStart                          8
+#define   W_TXDATAFIFO7__Tx15DataFifoStart                          7
+#define   O_TXDATAFIFO7__Tx15DataFifoSize                           0
+#define   W_TXDATAFIFO7__Tx15DataFifoSize                           7
+#define R_RXDATAFIFO0                                               0x229
+#define   O_RXDATAFIFO0__Rx0DataFifoStart                           24
+#define   W_RXDATAFIFO0__Rx0DataFifoStart                           7
+#define   O_RXDATAFIFO0__Rx0DataFifoSize                            16
+#define   W_RXDATAFIFO0__Rx0DataFifoSize                            7
+#define   O_RXDATAFIFO0__Rx1DataFifoStart                           8
+#define   W_RXDATAFIFO0__Rx1DataFifoStart                           7
+#define   O_RXDATAFIFO0__Rx1DataFifoSize                            0
+#define   W_RXDATAFIFO0__Rx1DataFifoSize                            7
+#define R_RXDATAFIFO1                                               0x22A
+#define   O_RXDATAFIFO1__Rx2DataFifoStart                           24
+#define   W_RXDATAFIFO1__Rx2DataFifoStart                           7
+#define   O_RXDATAFIFO1__Rx2DataFifoSize                            16
+#define   W_RXDATAFIFO1__Rx2DataFifoSize                            7
+#define   O_RXDATAFIFO1__Rx3DataFifoStart                           8
+#define   W_RXDATAFIFO1__Rx3DataFifoStart                           7
+#define   O_RXDATAFIFO1__Rx3DataFifoSize                            0
+#define   W_RXDATAFIFO1__Rx3DataFifoSize                            7
+#define R_RXDATAFIFO2                                               0x22B
+#define   O_RXDATAFIFO2__Rx4DataFifoStart                           24
+#define   W_RXDATAFIFO2__Rx4DataFifoStart                           7
+#define   O_RXDATAFIFO2__Rx4DataFifoSize                            16
+#define   W_RXDATAFIFO2__Rx4DataFifoSize                            7
+#define   O_RXDATAFIFO2__Rx5DataFifoStart                           8
+#define   W_RXDATAFIFO2__Rx5DataFifoStart                           7
+#define   O_RXDATAFIFO2__Rx5DataFifoSize                            0
+#define   W_RXDATAFIFO2__Rx5DataFifoSize                            7
+#define R_RXDATAFIFO3                                               0x22C
+#define   O_RXDATAFIFO3__Rx6DataFifoStart                           24
+#define   W_RXDATAFIFO3__Rx6DataFifoStart                           7
+#define   O_RXDATAFIFO3__Rx6DataFifoSize                            16
+#define   W_RXDATAFIFO3__Rx6DataFifoSize                            7
+#define   O_RXDATAFIFO3__Rx7DataFifoStart                           8
+#define   W_RXDATAFIFO3__Rx7DataFifoStart                           7
+#define   O_RXDATAFIFO3__Rx7DataFifoSize                            0
+#define   W_RXDATAFIFO3__Rx7DataFifoSize                            7
+#define R_RXDATAFIFO4                                               0x22D
+#define   O_RXDATAFIFO4__Rx8DataFifoStart                           24
+#define   W_RXDATAFIFO4__Rx8DataFifoStart                           7
+#define   O_RXDATAFIFO4__Rx8DataFifoSize                            16
+#define   W_RXDATAFIFO4__Rx8DataFifoSize                            7
+#define   O_RXDATAFIFO4__Rx9DataFifoStart                           8
+#define   W_RXDATAFIFO4__Rx9DataFifoStart                           7
+#define   O_RXDATAFIFO4__Rx9DataFifoSize                            0
+#define   W_RXDATAFIFO4__Rx9DataFifoSize                            7
+#define R_RXDATAFIFO5                                               0x22E
+#define   O_RXDATAFIFO5__Rx10DataFifoStart                          24
+#define   W_RXDATAFIFO5__Rx10DataFifoStart                          7
+#define   O_RXDATAFIFO5__Rx10DataFifoSize                           16
+#define   W_RXDATAFIFO5__Rx10DataFifoSize                           7
+#define   O_RXDATAFIFO5__Rx11DataFifoStart                          8
+#define   W_RXDATAFIFO5__Rx11DataFifoStart                          7
+#define   O_RXDATAFIFO5__Rx11DataFifoSize                           0
+#define   W_RXDATAFIFO5__Rx11DataFifoSize                           7
+#define R_RXDATAFIFO6                                               0x22F
+#define   O_RXDATAFIFO6__Rx12DataFifoStart                          24
+#define   W_RXDATAFIFO6__Rx12DataFifoStart                          7
+#define   O_RXDATAFIFO6__Rx12DataFifoSize                           16
+#define   W_RXDATAFIFO6__Rx12DataFifoSize                           7
+#define   O_RXDATAFIFO6__Rx13DataFifoStart                          8
+#define   W_RXDATAFIFO6__Rx13DataFifoStart                          7
+#define   O_RXDATAFIFO6__Rx13DataFifoSize                           0
+#define   W_RXDATAFIFO6__Rx13DataFifoSize                           7
+#define R_RXDATAFIFO7                                               0x230
+#define   O_RXDATAFIFO7__Rx14DataFifoStart                          24
+#define   W_RXDATAFIFO7__Rx14DataFifoStart                          7
+#define   O_RXDATAFIFO7__Rx14DataFifoSize                           16
+#define   W_RXDATAFIFO7__Rx14DataFifoSize                           7
+#define   O_RXDATAFIFO7__Rx15DataFifoStart                          8
+#define   W_RXDATAFIFO7__Rx15DataFifoStart                          7
+#define   O_RXDATAFIFO7__Rx15DataFifoSize                           0
+#define   W_RXDATAFIFO7__Rx15DataFifoSize                           7
+#define R_XGMACPADCALIBRATION                                       0x231
+#define R_FREEQCARVE                                                0x233
+#define R_SPI4STATICDELAY0                                          0x240
+#define   O_SPI4STATICDELAY0__DataLine7                             28
+#define   W_SPI4STATICDELAY0__DataLine7                             4
+#define   O_SPI4STATICDELAY0__DataLine6                             24
+#define   W_SPI4STATICDELAY0__DataLine6                             4
+#define   O_SPI4STATICDELAY0__DataLine5                             20
+#define   W_SPI4STATICDELAY0__DataLine5                             4
+#define   O_SPI4STATICDELAY0__DataLine4                             16
+#define   W_SPI4STATICDELAY0__DataLine4                             4
+#define   O_SPI4STATICDELAY0__DataLine3                             12
+#define   W_SPI4STATICDELAY0__DataLine3                             4
+#define   O_SPI4STATICDELAY0__DataLine2                             8
+#define   W_SPI4STATICDELAY0__DataLine2                             4
+#define   O_SPI4STATICDELAY0__DataLine1                             4
+#define   W_SPI4STATICDELAY0__DataLine1                             4
+#define   O_SPI4STATICDELAY0__DataLine0                             0
+#define   W_SPI4STATICDELAY0__DataLine0                             4
+#define R_SPI4STATICDELAY1                                          0x241
+#define   O_SPI4STATICDELAY1__DataLine15                            28
+#define   W_SPI4STATICDELAY1__DataLine15                            4
+#define   O_SPI4STATICDELAY1__DataLine14                            24
+#define   W_SPI4STATICDELAY1__DataLine14                            4
+#define   O_SPI4STATICDELAY1__DataLine13                            20
+#define   W_SPI4STATICDELAY1__DataLine13                            4
+#define   O_SPI4STATICDELAY1__DataLine12                            16
+#define   W_SPI4STATICDELAY1__DataLine12                            4
+#define   O_SPI4STATICDELAY1__DataLine11                            12
+#define   W_SPI4STATICDELAY1__DataLine11                            4
+#define   O_SPI4STATICDELAY1__DataLine10                            8
+#define   W_SPI4STATICDELAY1__DataLine10                            4
+#define   O_SPI4STATICDELAY1__DataLine9                             4
+#define   W_SPI4STATICDELAY1__DataLine9                             4
+#define   O_SPI4STATICDELAY1__DataLine8                             0
+#define   W_SPI4STATICDELAY1__DataLine8                             4
+#define R_SPI4STATICDELAY2                                          0x242
+#define   O_SPI4STATICDELAY0__TxStat1                               8
+#define   W_SPI4STATICDELAY0__TxStat1                               4
+#define   O_SPI4STATICDELAY0__TxStat0                               4
+#define   W_SPI4STATICDELAY0__TxStat0                               4
+#define   O_SPI4STATICDELAY0__RxControl                             0
+#define   W_SPI4STATICDELAY0__RxControl                             4
+#define R_SPI4CONTROL                                               0x243
+#define   O_SPI4CONTROL__StaticDelay                                2
+#define   O_SPI4CONTROL__LVDS_LVTTL                                 1
+#define   O_SPI4CONTROL__SPI4Enable                                 0
+#define R_CLASSWATERMARKS                                           0x244
+#define   O_CLASSWATERMARKS__Class0Watermark                        24
+#define   W_CLASSWATERMARKS__Class0Watermark                        5
+#define   O_CLASSWATERMARKS__Class1Watermark                        16
+#define   W_CLASSWATERMARKS__Class1Watermark                        5
+#define   O_CLASSWATERMARKS__Class3Watermark                        0
+#define   W_CLASSWATERMARKS__Class3Watermark                        5
+#define R_RXWATERMARKS1                                              0x245
+#define   O_RXWATERMARKS__Rx0DataWatermark                          24
+#define   W_RXWATERMARKS__Rx0DataWatermark                          7
+#define   O_RXWATERMARKS__Rx1DataWatermark                          16
+#define   W_RXWATERMARKS__Rx1DataWatermark                          7
+#define   O_RXWATERMARKS__Rx3DataWatermark                          0
+#define   W_RXWATERMARKS__Rx3DataWatermark                          7
+#define R_RXWATERMARKS2                                              0x246
+#define   O_RXWATERMARKS__Rx4DataWatermark                          24
+#define   W_RXWATERMARKS__Rx4DataWatermark                          7
+#define   O_RXWATERMARKS__Rx5DataWatermark                          16
+#define   W_RXWATERMARKS__Rx5DataWatermark                          7
+#define   O_RXWATERMARKS__Rx6DataWatermark                          8
+#define   W_RXWATERMARKS__Rx6DataWatermark                          7
+#define   O_RXWATERMARKS__Rx7DataWatermark                          0
+#define   W_RXWATERMARKS__Rx7DataWatermark                          7
+#define R_RXWATERMARKS3                                              0x247
+#define   O_RXWATERMARKS__Rx8DataWatermark                          24
+#define   W_RXWATERMARKS__Rx8DataWatermark                          7
+#define   O_RXWATERMARKS__Rx9DataWatermark                          16
+#define   W_RXWATERMARKS__Rx9DataWatermark                          7
+#define   O_RXWATERMARKS__Rx10DataWatermark                         8
+#define   W_RXWATERMARKS__Rx10DataWatermark                         7
+#define   O_RXWATERMARKS__Rx11DataWatermark                         0
+#define   W_RXWATERMARKS__Rx11DataWatermark                         7
+#define R_RXWATERMARKS4                                              0x248
+#define   O_RXWATERMARKS__Rx12DataWatermark                         24
+#define   W_RXWATERMARKS__Rx12DataWatermark                         7
+#define   O_RXWATERMARKS__Rx13DataWatermark                         16
+#define   W_RXWATERMARKS__Rx13DataWatermark                         7
+#define   O_RXWATERMARKS__Rx14DataWatermark                         8
+#define   W_RXWATERMARKS__Rx14DataWatermark                         7
+#define   O_RXWATERMARKS__Rx15DataWatermark                         0
+#define   W_RXWATERMARKS__Rx15DataWatermark                         7
+#define R_FREEWATERMARKS                                            0x249
+#define   O_FREEWATERMARKS__FreeOutWatermark                        16
+#define   W_FREEWATERMARKS__FreeOutWatermark                        16
+#define   O_FREEWATERMARKS__JumFrWatermark                          8
+#define   W_FREEWATERMARKS__JumFrWatermark                          7
+#define   O_FREEWATERMARKS__RegFrWatermark                          0
+#define   W_FREEWATERMARKS__RegFrWatermark                          7
+#define R_EGRESSFIFOCARVINGSLOTS                                    0x24a
+
+
+#define CTRL_RES0           0
+#define CTRL_RES1           1
+#define CTRL_REG_FREE       2
+#define CTRL_CONT           4
+#define CTRL_EOP            5
+#define CTRL_START          6
+#define CTRL_SNGL           7
+
+#define CTRL_B0_NOT_EOP     0
+#define CTRL_B0_EOP         1
+
+#define R_ROUND_ROBIN_TABLE                 0
+#define R_PDE_CLASS_0                       0x300
+#define R_PDE_CLASS_1                       0x302
+#define R_PDE_CLASS_2                       0x304
+#define R_PDE_CLASS_3                       0x306
+
+#define R_MSG_TX_THRESHOLD                  0x308
+
+#define R_GMAC_RFR0_BUCKET_SIZE              0x321
+#define R_GMAC_TX0_BUCKET_SIZE              0x322
+#define R_GMAC_TX1_BUCKET_SIZE              0x323
+#define R_GMAC_TX2_BUCKET_SIZE              0x324
+#define R_GMAC_TX3_BUCKET_SIZE              0x325
+#define R_GMAC_RFR1_BUCKET_SIZE              0x327
+
+#define R_XGS_TX0_BUCKET_SIZE               0x320
+#define R_XGS_TX1_BUCKET_SIZE               0x321
+#define R_XGS_TX2_BUCKET_SIZE               0x322
+#define R_XGS_TX3_BUCKET_SIZE               0x323
+#define R_XGS_TX4_BUCKET_SIZE               0x324
+#define R_XGS_TX5_BUCKET_SIZE               0x325
+#define R_XGS_TX6_BUCKET_SIZE               0x326
+#define R_XGS_TX7_BUCKET_SIZE               0x327
+#define R_XGS_TX8_BUCKET_SIZE               0x328
+#define R_XGS_TX9_BUCKET_SIZE               0x329
+#define R_XGS_TX10_BUCKET_SIZE              0x32A
+#define R_XGS_TX11_BUCKET_SIZE              0x32B
+#define R_XGS_TX12_BUCKET_SIZE              0x32C
+#define R_XGS_TX13_BUCKET_SIZE              0x32D
+#define R_XGS_TX14_BUCKET_SIZE              0x32E
+#define R_XGS_TX15_BUCKET_SIZE              0x32F
+#define R_XGS_RFR_BUCKET_SIZE               0x331
+
+#define R_CC_CPU0_0                         0x380
+#define R_CC_CPU1_0                         0x388
+#define R_CC_CPU2_0                         0x390
+#define R_CC_CPU3_0                         0x398
+#define R_CC_CPU4_0                         0x3a0
+#define R_CC_CPU5_0                         0x3a8
+#define R_CC_CPU6_0                         0x3b0
+#define R_CC_CPU7_0                         0x3b8
+
+/* frame sizes need to be cacheline aligned */
+#define MAC_MAX_FRAME_SIZE          1600
+#define MAC_SKB_BACK_PTR_SIZE   SMP_CACHE_BYTES
+
+
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+#define MAC_PREPAD             32
+#else 
+#define MAC_PREPAD             0 
+#endif 
+
+#define BYTE_OFFSET             2
+#define PHNX_RX_BUF_SIZE (MAC_MAX_FRAME_SIZE+BYTE_OFFSET+MAC_PREPAD+MAC_SKB_BACK_PTR_SIZE+SMP_CACHE_BYTES)
+#define MAC_CRC_LEN             4
+
+
+enum {
+        SGMII_SPEED_10   = 0x00000000,
+        SGMII_SPEED_100  = 0x02000000,
+        SGMII_SPEED_1000 = 0x04000000,
+};
+
+enum tsv_rsv_reg{
+  TX_RX_64_BYTE_FRAME = 0x20,
+  TX_RX_64_127_BYTE_FRAME,
+  TX_RX_128_255_BYTE_FRAME,
+  TX_RX_256_511_BYTE_FRAME,
+  TX_RX_512_1023_BYTE_FRAME,
+  TX_RX_1024_1518_BYTE_FRAME,
+  TX_RX_1519_1522_VLAN_BYTE_FRAME,
+
+  RX_BYTE_COUNTER = 0x27,
+  RX_PACKET_COUNTER,
+  RX_FCS_ERROR_COUNTER,
+  RX_MULTICAST_PACKET_COUNTER,
+  RX_BROADCAST_PACKET_COUNTER,
+  RX_CONTROL_FRAME_PACKET_COUNTER,
+  RX_PAUSE_FRAME_PACKET_COUNTER,
+  RX_UNKNOWN_OP_CODE_COUNTER,
+  RX_ALIGNMENT_ERROR_COUNTER,
+  RX_FRAME_LENGTH_ERROR_COUNTER,
+  RX_CODE_ERROR_COUNTER,
+  RX_CARRIER_SENSE_ERROR_COUNTER,
+  RX_UNDERSIZE_PACKET_COUNTER,
+  RX_OVERSIZE_PACKET_COUNTER,
+  RX_FRAGMENTS_COUNTER,
+  RX_JABBER_COUNTER,
+  RX_DROP_PACKET_COUNTER,
+
+  TX_BYTE_COUNTER   = 0x38,
+  TX_PACKET_COUNTER,
+  TX_MULTICAST_PACKET_COUNTER,
+  TX_BROADCAST_PACKET_COUNTER,
+  TX_PAUSE_CONTROL_FRAME_COUNTER,
+  TX_DEFERRAL_PACKET_COUNTER,
+  TX_EXCESSIVE_DEFERRAL_PACKET_COUNTER,
+  TX_SINGLE_COLLISION_PACKET_COUNTER,
+  TX_MULTI_COLLISION_PACKET_COUNTER,
+  TX_LATE_COLLISION_PACKET_COUNTER,
+  TX_EXCESSIVE_COLLISION_PACKET_COUNTER,
+  TX_TOTAL_COLLISION_COUNTER,
+  TX_PAUSE_FRAME_HONERED_COUNTER,
+  TX_DROP_FRAME_COUNTER,
+  TX_JABBER_FRAME_COUNTER,
+  TX_FCS_ERROR_COUNTER,
+  TX_CONTROL_FRAME_COUNTER,
+  TX_OVERSIZE_FRAME_COUNTER,
+  TX_UNDERSIZE_FRAME_COUNTER,
+  TX_FRAGMENT_FRAME_COUNTER,
+
+  CARRY_REG_1 = 0x4c,
+  CARRY_REG_2 = 0x4d,
+};
+
+struct size_1_desc {
+  uint64_t entry0;
+};
+
+struct size_2_desc {
+  uint64_t entry0;
+  uint64_t entry1;
+};
+
+struct size_3_desc {
+  uint64_t entry0;
+  uint64_t entry1;
+  uint64_t entry2;
+};
+
+struct size_4_desc {
+  uint64_t entry0;
+  uint64_t entry1;
+  uint64_t entry2;
+  uint64_t entry3;
+};
+
+struct fr_desc {
+  struct size_1_desc d1;
+};
+
+union rx_tx_desc {
+  struct size_1_desc d1;
+};
+
+static inline int mac_make_desc_rfr(struct msgrng_msg *msg, int id, int type,
+				    unsigned long addr)
+{
+  int stid = 0;
+  
+  if (type == TYPE_XGMAC) stid = msgrng_xgmac_stid_rfr(id);
+  else  {
+#ifdef MAC_SPLIT_MODE
+    stid =  msgrng_gmac_stid_rfr_split_mode(id);
+#else
+    stid = msgrng_gmac_stid_rfr(id);
+#endif 
+  }
+  msg->msg0 = (((uint64_t)CTRL_REG_FREE << 61) | 
+	       ((uint64_t)stid<<52) | 
+	       (uint64_t)addr);
+  msg->msg1 = msg->msg2 = msg->msg3 = 0;
+  return stid;
+}
+
+
+
+static inline int
+msgrng_stid_rfr(int id, int type)
+{
+    int stid = 0;
+
+  if (type == TYPE_XGMAC) 
+    stid = msgrng_xgmac_stid_rfr(id);
+    else  {
+        if (id < 4) {
+#ifdef MAC_SPLIT_MODE
+            stid =  msgrng_gmac_stid_rfr_split_mode(id);
+#else
+            stid = msgrng_gmac_stid_rfr(id);
+#endif 
+        }
+        else
+            stid = msgrng_gmac1_stid_rfr(id);
+    }
+  return stid;
+}
+
+
+
+static inline int mac_make_desc_b0_rfr(struct msgrng_msg *msg, int id, int type,
+        unsigned long addr)
+{
+    int stid = msgrng_stid_rfr(id, type);
+
+    msg->msg0 = (uint64_t)addr & 0xffffffffe0ULL;
+    msg->msg1 = msg->msg2 = msg->msg3 = 0;
+
+    return stid;
+}
+
+#define MAC_TX_DESC_ALIGNMENT (SMP_CACHE_BYTES - 1)
+static inline int mac_make_desc_tx(struct msgrng_msg *msg, int id, int type,
+        unsigned long addr, int len)
+{
+    int tx_stid = 0;
+    int fr_stid = 0;
+    int desc_offset = addr & MAC_TX_DESC_ALIGNMENT;
+
+    if (type == TYPE_XGMAC) {
+        tx_stid = msgrng_xgmac_stid_tx(id);
+        fr_stid = 0;
+    }
+    else {
+        int cpu = phoenix_cpu_id();
+        if (id < 4)
+            tx_stid = msgrng_gmac_stid_tx(id);
+        else
+            tx_stid = msgrng_gmac1_stid_tx(id);
+        fr_stid = (cpu << 3) + phoenix_thr_id();
+    }
+
+    msg->msg0 = ( ((uint64_t)CTRL_SNGL << 61) | 
+            ((uint64_t)desc_offset << 40) | 
+            ((uint64_t)tx_stid << 52) |
+            ((uint64_t)addr & ~MAC_TX_DESC_ALIGNMENT)
+            );
+    msg->msg1 = ( ( (uint64_t)CTRL_EOP << 61) |  
+            ( ((uint64_t)fr_stid) << 54) | 
+            ( (uint64_t)len << 40)
+            );
+
+    msg->msg2 = msg->msg3 = 0;
+
+    return tx_stid;
+}
+
+extern __u8 phoenix_base_mac_addr[];
+/*
+ * Structure of an rmios ipsec packet
+ */
+typedef struct tagIPSEC_PACKET {
+    // cacheline-aligned portion
+    PacketDescriptor_t packet_desc; // multiple of 32 (32)
+    PacketDescriptor_t particle_desc;// second particle (GCM)
+    unsigned char auth_dest[PHXSEC_HMAC_LENGTH];    // multiple of 32 (32)
+    unsigned char packet_data[IPSEC_PACKET_PAYLOAD_SIZE];
+    // end of cacheline-aligned portion
+    int src_id;
+} IPSEC_PACKET ____cacheline_aligned;
+
+#endif
diff --git a/arch/mips/include/asm/rmi/phoenix_rmios_debugger.h b/arch/mips/include/asm/rmi/phoenix_rmios_debugger.h
new file mode 100644
index 0000000..b5d38e3
--- /dev/null
+++ b/arch/mips/include/asm/rmi/phoenix_rmios_debugger.h
@@ -0,0 +1,53 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#define PHNX_DEB_DEV_NAME  "phnxdeb"
+
+#define PHNX_RMIOS_DEBUGGER_WRITE                   0xaa10
+#define PHNX_RMIOS_DEBUGGER_READ                    0xaa11
+#define PHNX_RMIOS_DEBUGGER_TX_MEM_WRITE            0xaa12
+#define PHNX_RMIOS_DEBUGGER_TX_MEM_READ             0xaa13
+#define PHNX_RMIOS_DEBUGGER_RX_MEM_WRITE            0xaa14
+#define PHNX_RMIOS_DEBUGGER_RX_MEM_READ             0xaa15
+#define PHNX_RMIOS_DEBUGGER_MEM_READ                0xaa16
+#define PHNX_RMIOS_DEBUGGER_MEM_WRITE               0xaa17
+#define PHNX_RMIOS_DEBUGGER_PIC_IPI                 0xaa18
+#define LINUX_RMIOS_SHARED_BASE                     0x00040000UL
+#define LINUX_RMIOS_VCPU                            32
+#define LINUX_RMIOS_TX_BUF_SIZE                     1600
+#define LINUX_RMIOS_RX_BUF_SIZE                     256
+#define LINUX_RMIOS_RX_BUF_BASE            LINUX_RMIOS_SHARED_BASE
+#define LINUX_RMIOS_TX_BUF_BASE            (LINUX_RMIOS_RX_BUF_BASE + (LINUX_RMIOS_RX_BUF_SIZE * LINUX_RMIOS_VCPU))
+#define LINUX_RMIOS_CPU_ONLINE_MAP_LOCK    (LINUX_RMIOS_TX_BUF_BASE + (LINUX_RMIOS_TX_BUF_SIZE * LINUX_RMIOS_VCPU))
+#define LINUX_RMIOS_CPU_ONLINE_MAP_LOCK_INIT_DONE  (LINUX_RMIOS_CPU_ONLINE_MAP_LOCK + CACHE_LINE_SIZE)
+#define LINUX_RMIOS_CPU_ONLINE_MAP         (LINUX_RMIOS_CPU_ONLINE_MAP_LOCK_INIT_DONE + CACHE_LINE_SIZE)
+
+#define LOCK_INIT_DONE                              0x900ddeed
+
diff --git a/arch/mips/include/asm/rmi/phoenix_sec.h b/arch/mips/include/asm/rmi/phoenix_sec.h
new file mode 100644
index 0000000..de811b2
--- /dev/null
+++ b/arch/mips/include/asm/rmi/phoenix_sec.h
@@ -0,0 +1,772 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _PHONIEX_SEC_H
+#define _PHOENIX_SEC_H
+
+#include <linux/types.h>
+#include <asm/rmi/msgring.h>
+
+enum sec_pipe_config {
+
+  SEC_PIPE_CIPHER_KEY0_L0            = 0x00,
+  SEC_PIPE_CIPHER_KEY0_HI,
+  SEC_PIPE_CIPHER_KEY1_LO,
+  SEC_PIPE_CIPHER_KEY1_HI,
+  SEC_PIPE_CIPHER_KEY2_LO,
+  SEC_PIPE_CIPHER_KEY2_HI,
+  SEC_PIPE_CIPHER_KEY3_LO,
+  SEC_PIPE_CIPHER_KEY3_HI,
+  SEC_PIPE_HMAC_KEY0_LO,
+  SEC_PIPE_HMAC_KEY0_HI,
+  SEC_PIPE_HMAC_KEY1_LO,
+  SEC_PIPE_HMAC_KEY1_HI,
+  SEC_PIPE_HMAC_KEY2_LO,
+  SEC_PIPE_HMAC_KEY2_HI,
+  SEC_PIPE_HMAC_KEY3_LO,
+  SEC_PIPE_HMAC_KEY3_HI,
+  SEC_PIPE_HMAC_KEY4_LO,
+  SEC_PIPE_HMAC_KEY4_HI,
+  SEC_PIPE_HMAC_KEY5_LO,
+  SEC_PIPE_HMAC_KEY5_HI,
+  SEC_PIPE_HMAC_KEY6_LO,
+  SEC_PIPE_HMAC_KEY6_HI,
+  SEC_PIPE_HMAC_KEY7_LO,
+  SEC_PIPE_HMAC_KEY7_HI,
+  SEC_PIPE_NCFBM_LO,
+  SEC_PIPE_NCFBM_HI,
+  SEC_PIPE_INSTR_LO,
+  SEC_PIPE_INSTR_HI,
+  SEC_PIPE_RSVD0,
+  SEC_PIPE_RSVD1,
+  SEC_PIPE_RSVD2,
+  SEC_PIPE_RSVD3,
+
+  SEC_PIPE_DF_PTRS0,
+  SEC_PIPE_DF_PTRS1,
+  SEC_PIPE_DF_PTRS2,
+  SEC_PIPE_DF_PTRS3,
+  SEC_PIPE_DF_PTRS4,
+  SEC_PIPE_DF_PTRS5,
+  SEC_PIPE_DF_PTRS6,
+  SEC_PIPE_DF_PTRS7,
+
+  SEC_PIPE_DU_DATA_IN_LO,
+  SEC_PIPE_DU_DATA_IN_HI,
+  SEC_PIPE_DU_DATA_IN_CTRL,
+  SEC_PIPE_DU_DATA_OUT_LO,
+  SEC_PIPE_DU_DATA_OUT_HI,
+  SEC_PIPE_DU_DATA_OUT_CTRL,
+
+  SEC_PIPE_STATE0,
+  SEC_PIPE_STATE1,
+  SEC_PIPE_STATE2,
+  SEC_PIPE_STATE3,
+  SEC_PIPE_STATE4,
+  SEC_PIPE_INCLUDE_MASK0,
+  SEC_PIPE_INCLUDE_MASK1,
+  SEC_PIPE_INCLUDE_MASK2,
+  SEC_PIPE_INCLUDE_MASK3,
+  SEC_PIPE_INCLUDE_MASK4,
+  SEC_PIPE_EXCLUDE_MASK0,
+  SEC_PIPE_EXCLUDE_MASK1,
+  SEC_PIPE_EXCLUDE_MASK2,
+  SEC_PIPE_EXCLUDE_MASK3,
+  SEC_PIPE_EXCLUDE_MASK4,
+};
+
+enum sec_pipe_base_config {
+  
+  SEC_PIPE0_BASE = 0x00,
+  SEC_PIPE1_BASE = 0x40,
+  SEC_PIPE2_BASE = 0x80,
+  SEC_PIPE3_BASE = 0xc0
+
+};
+
+enum sec_rsa_config {
+  
+  SEC_RSA_PIPE0_DU_DATA_IN_LO = 0x100,
+  SEC_RSA_PIPE0_DU_DATA_IN_HI,
+  SEC_RSA_PIPE0_DU_DATA_IN_CTRL,
+  SEC_RSA_PIPE0_DU_DATA_OUT_LO,
+  SEC_RSA_PIPE0_DU_DATA_OUT_HI,
+  SEC_RSA_PIPE0_DU_DATA_OUT_CTRL,
+  SEC_RSA_RSVD0,
+  SEC_RSA_RSVD1,
+
+  SEC_RSA_PIPE0_STATE0,
+  SEC_RSA_PIPE0_STATE1,
+  SEC_RSA_PIPE0_STATE2,
+  SEC_RSA_PIPE0_INCLUDE_MASK0,
+  SEC_RSA_PIPE0_INCLUDE_MASK1,
+  SEC_RSA_PIPE0_INCLUDE_MASK2,
+  SEC_RSA_PIPE0_EXCLUDE_MASK0,
+  SEC_RSA_PIPE0_EXCLUDE_MASK1,
+  SEC_RSA_PIPE0_EXCLUDE_MASK2,
+  SEC_RSA_PIPE0_EVENT_CTR
+
+};
+
+enum sec_config {
+  
+  SEC_DMA_CREDIT = 0x140,
+  SEC_CONFIG1,
+  SEC_CONFIG2,
+  SEC_CONFIG3,  
+
+};
+
+enum sec_debug_config {
+  
+  SEC_DW0_DESCRIPTOR0_LO  = 0x180,
+  SEC_DW0_DESCRIPTOR0_HI,
+  SEC_DW0_DESCRIPTOR1_LO,
+  SEC_DW0_DESCRIPTOR1_HI,
+  SEC_DW1_DESCRIPTOR0_LO,
+  SEC_DW1_DESCRIPTOR0_HI,
+  SEC_DW1_DESCRIPTOR1_LO,
+  SEC_DW1_DESCRIPTOR1_HI,
+  SEC_DW2_DESCRIPTOR0_LO,
+  SEC_DW2_DESCRIPTOR0_HI,
+  SEC_DW2_DESCRIPTOR1_LO,
+  SEC_DW2_DESCRIPTOR1_HI,
+  SEC_DW3_DESCRIPTOR0_LO,
+  SEC_DW3_DESCRIPTOR0_HI,
+  SEC_DW3_DESCRIPTOR1_LO,
+  SEC_DW3_DESCRIPTOR1_HI,
+
+  SEC_STATE0,
+  SEC_STATE1,  
+  SEC_STATE2,
+  SEC_INCLUDE_MASK0,
+  SEC_INCLUDE_MASK1,
+  SEC_INCLUDE_MASK2,
+  SEC_EXCLUDE_MASK0,
+  SEC_EXCLUDE_MASK1,
+  SEC_EXCLUDE_MASK2,
+  SEC_EVENT_CTR
+
+};
+
+//enum sec_perf_config {
+  
+//  SEC_PERF0  = 0x1c0
+
+//};
+
+enum sec_msgring_bucket_config {
+
+  SEC_BIU_CREDITS = 0x308,
+  
+  SEC_MSG_BUCKET0_SIZE = 0x320,
+  SEC_MSG_BUCKET1_SIZE,
+  SEC_MSG_BUCKET2_SIZE,
+  SEC_MSG_BUCKET3_SIZE,
+  SEC_MSG_BUCKET4_SIZE,
+  SEC_MSG_BUCKET5_SIZE,
+  SEC_MSG_BUCKET6_SIZE,
+  SEC_MSG_BUCKET7_SIZE,
+};
+
+enum sec_msgring_credit_config {
+
+  SEC_CC_CPU0_0                        = 0x380,
+  SEC_CC_CPU1_0                        = 0x388,
+  SEC_CC_CPU2_0                        = 0x390,
+  SEC_CC_CPU3_0                        = 0x398,
+  SEC_CC_CPU4_0                        = 0x3a0,
+  SEC_CC_CPU5_0                        = 0x3a8,
+  SEC_CC_CPU6_0                        = 0x3b0,
+  SEC_CC_CPU7_0                        = 0x3b8
+
+};
+
+enum sec_engine_id {
+  SEC_PIPE0,
+  SEC_PIPE1,
+  SEC_PIPE2,
+  SEC_PIPE3,
+  SEC_RSA
+};
+
+enum sec_cipher {
+  SEC_AES256_MODE_HMAC,
+  SEC_AES256_MODE,
+  SEC_AES256_HMAC,
+  SEC_AES256,
+  SEC_AES192_MODE_HMAC,
+  SEC_AES192_MODE,
+  SEC_AES192_HMAC,
+  SEC_AES192,
+  SEC_AES128_MODE_HMAC,
+  SEC_AES128_MODE,
+  SEC_AES128_HMAC,
+  SEC_AES128,
+  SEC_DES_HMAC,
+  SEC_DES,
+  SEC_3DES,
+  SEC_3DES_HMAC,
+  SEC_HMAC
+};
+
+enum sec_msgrng_msg_ctrl_config {
+  SEC_EOP=5,
+  SEC_SOP=6,
+};
+
+/*
+ * Security block data and control exchange
+ *
+ * A 2-word message ring descriptor is used to pass a pointer to the control descriptor data structure
+ * and a pointer to the packet descriptor data structure:
+ *
+ *  63  61 60    54      53      52    48 47            45 44    40 39                                                     5 4      0
+ *  ---------------------------------------------------------------------------------------------------------------------------------
+ * | Ctrl | FREEBACKID | IF_L2ALLOC | UNUSED | Control Length | UNUSED | 35 MSB of address of control descriptor data structure | UNUSED |
+ *  ---------------------------------------------------------------------------------------------------------------------------------
+ *    3       7          1          5             3           5                              35                                 5
+ *
+ *  63  61 60    54     53          52             51        50    46      45       44    40 39                                                    5 4      0
+ *  ---------------------------------------------------------------------------------------------------------------------------------------------------------
+ * | Ctrl | FREEBACKID | WRB_COH | WRB_L2ALLOC | DF_PTR_L2ALLOC | UNUSED | Data Length | UNUSED | 35 MSB of address of packet descriptor data structure | UNUSED |
+ *  ---------------------------------------------------------------------------------------------------------------------------------------------------------
+ *    3       7         1          1               1            5           1          5                                35                              5
+ *
+ * Addresses assumed to be cache-line aligned, i.e., Address[4:0] ignored (using 5'h00 instead)
+ *
+ * Control length is the number of control cachelines to be read so user needs to round up
+ * the control length to closest integer multiple of 32 bytes. Note that at present (03/18/04)
+ * the longest (sensical) ctrl structure is <= 128 bytes.
+ *
+ * The packet descriptor data structure size is fixed at 1 cacheline (32 bytes).
+ * This effectively makes "Data Length" a Load/NoLoad bit. NoLoad causes an abort.
+ *
+ *
+ * Upon completion of operation, the security block returns a 2-word free descriptor
+ * in the following format:
+ *
+ *  63  61 60            54 53   52 51       49   48   47               40 39                                                  0
+ *  ----------------------------------------------------------------------------------------------------------------------------
+ * | Ctrl | Destination Id | 2'b00 | Desc Ctrl | 1'b0 | Instruction Error |    Address of control descriptor data structure     |
+ *  ----------------------------------------------------------------------------------------------------------------------------
+ * | Ctrl | Destination Id | 2'b00 | Desc Ctrl | 1'b0 |     Data Error    |    Address of packet descriptor data structure      |
+ *  ----------------------------------------------------------------------------------------------------------------------------
+ *
+ * The Instruction and Data Error codes are enumerated in the 
+ * ControlDescriptor and PacketDescriptor sections below
+ *
+ *
+ *                                              /----------------------------------------\
+ *                                              |                                        |
+ *                                              |   ControlDescriptor_s datastructure    |
+ *                                              |                                        |
+ *                                              \----------------------------------------/
+ *
+ *
+ *       ControlDescriptor_t.Instruction
+ *       -------------------------------
+ *
+ *   63        37   36   35   34    32 31  29 28         27 26           24
+ *  ------------------------------------------------------------------------
+ * ||   UNUSED   || V || E/D | Cipher | Mode | Init_Cipher | Cipher_Offset ||   ... CONT ...
+ *  ------------------------------------------------------------------------
+ *        28        1     1      3       3          2              3        
+ *               <CTRL><--------------------CIPHER----------------------->
+ *
+ *
+ *     23   22  21      20     19         18     17        16    15   14 13           2 1         0
+ *  -----------------------------------------------------------------------------------------------
+ * || HMAC | Hash | Init_Hash | Hash_Offset | Hash_Src || CkSum |  N/U  | CkSum_Offset | CkSum_Src ||
+ *  -----------------------------------------------------------------------------------------------
+ *     1      2         1            2            1         1       2         12            2
+ *   <-----------------------HASH--------------------->  <-----------CHECKSUM-------------------->
+ *
+ *
+ *
+ *      CTRL.V                 =        1'b0       Instruction invalid
+ *                                      1'b1       Instruction valid
+ *      CIPHER.E/D             =        1'b0       Decrypt
+ *                                      1'b1       Encrypt
+ *             Cipher          =        3'b000     Bypass
+ *                                      3'b001     DES
+ *                                      3'b010     3DES
+ *                                      3'b011     AES 128-bit key
+ *                                      3'b100     AES 192-bit key
+ *                                      3'b101     AES 256-bit key
+ *                                      Remainder  UNDEFINED
+ *             Mode            =        3'b000     ECB
+ *                                      3'b001     CBC
+ *                                      3'b010     CFB (AES only, otherwise undefined)
+ *                                      3'b011     OFB (AES only, otherwise undefined)
+ *                                      3'b100     CTR (AES only, otherwise undefined)
+ *                                      Remainder  UNDEFINED
+ *             Init_Cipher     =        2'b00      Preserve old IV/(Keys,NonceCFBMask)
+ *                                      2'b01      Load new IV use old Keys,NonceCFBMask
+ *                                      2'b10      Load new Keys,NonceCFBMask use old IV (?)
+ *                                      2'b11      Load new IV/(Keys,NonceCFBMask)
+ *             Cipher_Offset   =                   Nb of words between the first data segment 
+ *                                                 and word on which to start cipher operation
+ *                                                 (64 BIT WORDS !!!)
+ *        HASH.HMAC            =        1'b0       Hash without HMAC
+ *                                      1'b1       Hash with HMAC 
+ *             Hash            =        2'b00      Hash NOP
+ *                                      2'b01      MD5
+ *                                      2'b10      SHA-1
+ *                                      2'b11      SHA-256
+ *             Init_Hash       =        1'b0       Preserve old key HMAC key stored in ID registers (moot if HASH.HMAC == 0)
+ *                                      1'b1       Load new HMAC key from memory ctrl section to ID registers
+ *             Hash_Offset     =                   Nb of words between the first data segment
+ *                                                 and word on which to start hashing 
+ *                                                 (64 bit words)
+ *             Hash_Src        =        1'b0       DMA channel
+ *                                      1'b1       Cipher if word count exceeded Cipher_Offset; 
+ *                                                 DMA channel otherwise
+ *    CHECKSUM.CkSum           =        1'b0       CkSum NOP
+ *                                      1'b1       INTERNET_CHECKSUM
+ *             N/U             =        2'bx       Field not used
+ *             CkSum_Offset    =                   Nb of words between the first data segment 
+ *                                                 and word on which to start 
+ *                                                 checksum calculation (32 BIT WORDS !!!)
+ *             CkSum_Src       =        2'b00      DMA channel if word count exceeded CkSum_Offset
+ *                                      2'b01      Cipher if word count exceeded CkSum_Offset,
+ *                                      2'b10      UNDEFINED
+ *                                      2'b11      UNDEFINED
+ *
+ *
+ *             OLD !!!
+ *             CkSum_Src       =        2'b00      0
+ *                                      2'b01      Cipher if word count exceeded CkSum_Offset,
+ *                                                 0 otherwise
+ *                                      2'b10      DMA channel if word count exceeded 
+ *                                                 CkSum_Offset, 0 otherwise
+ *                                      2'b11      UNDEFINED
+ *
+ *
+ *       ControlDescriptor_t.cipherHashInfo.infoAES256ModeHMAC
+ *       -----------------------------------------------------
+ *  
+ *  -----------------------------------------------------------------
+ * ||63              AES Key0                                      0||
+ *  -----------------------------------------------------------------
+ *                   .
+ *                   .
+ *                   .
+ *  -----------------------------------------------------------------
+ * ||63              AES Key3                                      0||
+ *  -----------------------------------------------------------------
+ *                   .
+ *                   .
+ *                   .
+ *  -----------------------------------------------------------------
+ * ||63              HMAC Key0                                      0||
+ *  -----------------------------------------------------------------
+ *                   .
+ *                   .
+ *                   .
+ *  -----------------------------------------------------------------
+ * ||63              HMAC Key7                                      0||
+ *  -----------------------------------------------------------------
+ *
+ *   63        40  39                   8  7                       0
+ *  -----------------------------------------------------------------
+ * ||   UNUSED   || Nonce (AES/CTR only) || CFB_Mask (AES/CFB only) ||
+ *  -----------------------------------------------------------------
+ *        24                 32                       8
+ *
+ */
+
+
+/*                                              /--------------------------------------------\
+ *                                              |                                            |
+ *                                              |    New PacketDescriptor_s datastructure    |
+ *                                              |                                            |
+ *                                              \--------------------------------------------/
+ *
+ *
+ *       PacketDescriptor_t.srcLengthIVOffUseIVNext
+ *       ------------------------------------------
+ *
+ *           63           62      61             59    58        57    56       54  53           43  42    40  39                  5  4      3  2                      0
+ *  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ * || Load HMAC key || Pad Hash || Hash Byte Count || Next || Use IV || IV Offset || Packet length || UNUSED || Segment src address || UNUSED || Global src data offset || 
+ *  ---------------------------------------------------------------------------------------------------------------------------------------------------------------------
+ *           1            1           3                1        1          3              11            3             35                 2                 3
+ *
+ *
+ *             Load HMAC key           =        1'b0       Preserve old HMAC key stored in Auth engine (moot if HASH.HMAC == 0)
+ *                                              1'b1       Load HMAC key from ID registers at beginning of op
+ *             Pad Hash                =        1'b0       HASH will assume the data was padded to be a multiple
+ *                                                         of 512 bits in length and that the last 64 bit word
+ *                                                         expresses the total datalength in bits seen by HASH engine
+ *                                              1'b1       The data was not padded to be a multiple of 512 bits in length;
+ *                                                         The Hash engine will do its own padding to generate the correct digest.
+ *             Hash Byte Count                             Number of BYTES on last 64-bit data word to use in digest calculation RELEVANT ONLY IF Pad Hash IS SET
+ *                                              3'b000     Use all 8
+ *                                              3'b001     Use first (MS) byte only (0-out rest), i.e., 0xddXXXXXXXXXXXXXX
+ *                                              3'b010     Use first 2 bytes only (0-out rest), i.e., 0xddddXXXXXXXXXXXX     ... etc
+ *             Next                    =        1'b0       Finish (return msg descriptor) at end of operation
+ *                                              1'b1       Grab the next PacketDescriptor (i.e. next cache-line) - NOT YET IMPLEMENTED !!!
+ *             Use IV                  =        1'b0       Use old IV
+ *                                              1'b1       Use data @ Segment_address + IV_Offset as IV
+ *             IV Offset               =                   Offset IN NB OF 8 BYTE WORDS from beginning of packet
+ *                                                         (i.e. (Potentially shifted) Segment address) to cipher IV
+ *             Packet length           =                   Nb double words to stream in (Including Segment address->CP/IV/Auth/CkSum offsets)
+ *                                                         This is the total amount of data (x8 in bytes) read    (+1 dword if "Global src data offset" != 0)
+ *                                                         This is the total amount of data (x8 in bytes) written (+1 dword if "Global dst data offset" != 0)
+ *                                                         (0-7); allows realignment of byte-aligned, non-double-word aligned data
+ *                                                         If Packet length == 11'h7ff and (Global src data offset != 0 or Global dst data offset != 0)
+ *                                                         the operation is aborted (no mem writes occur)
+ *             Segment src address     =                   35 MSB of pointer to src data (i.e., cache-line aligned)
+ *             Global src data offset  =                   Nb BYTES to right-shift data by before presenting it to engines
+ *                                                         (0-7); allows realignment of byte-aligned, non-double-word aligned data
+ *
+ *       PacketDescriptor_t.dstLLWMask
+ *       -----------------------------
+ *
+ *   63    60  59                 58  57    40  39                 5  4      3  2                      0
+ *  -----------------------------------------------------------------------------------------------------
+ * || UNUSED || Last long word mask || UNUSED || Cipher dst address || UNUSED || Global dst data offset ||
+ *  -----------------------------------------------------------------------------------------------------
+ *      4                2               18              35              2                 3
+ *
+ *
+ *             Last long word mask     =   2'b00      Give last 128 bit word to AES/HAMC/CKSUM engines as is
+ *                                         2'b11      Mask (zero-out) 32 least significant bits
+ *                                         2'b10      Mask 64 LSBs
+ *                                         2'b01      Mask 96 LSBs
+ *             Cipher dst address      =              35 MSB of pointer to dst location (i.e., cache-line aligned)
+ *             Global dst data offset  =              Nb BYTES to left-shift (double-word boundary aligned) data by before writing it to memory
+ *
+ * Upon completion of operation, the Sec block returns a 2-word free descriptor
+ * in the following format:
+ *
+ *  63  61 60            54 53   52 51       49  48          40 39             0
+ *  ----------------------------------------------------------------------------
+ * | Ctrl | Destination Id | 2'b00 | Desc Ctrl | Control Error | Source Address |
+ *  ----------------------------------------------------------------------------
+ * | Ctrl | Destination Id | 2'b00 | Desc Ctrl |   Data Error  | Dest Address   |
+ *  ----------------------------------------------------------------------------
+ *
+ * The Control and Data Error codes are enumerated below
+ *
+
+*
+ * Component strcts and unions defining CipherHashInfo_u
+ */
+
+/* All AES256 possibilities */
+ /* AES256, (CTR or CFB),    HMAC (MD5, SHA-1, SHA-256)      - 104 bytes */
+typedef struct AES256ModeHMAC_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             cipherKey2;
+  uint64_t             cipherKey3;
+  uint64_t             hmacKey0;
+  uint64_t             hmacKey1;
+  uint64_t             hmacKey2;
+  uint64_t             hmacKey3;
+  uint64_t             hmacKey4;
+  uint64_t             hmacKey5;
+  uint64_t             hmacKey6;
+  uint64_t             hmacKey7;
+  uint64_t             nonceCFBMask;
+} AES256ModeHMAC_t, *AES256ModeHMAC_pt;
+
+/* AES256, (CTR or CFB),    Non-HMAC (MD5, SHA-1, SHA-256)  - 40  bytes */
+typedef struct AES256Mode_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             cipherKey2;
+  uint64_t             cipherKey3;
+  uint64_t             nonceCFBMask;
+} AES256Mode_t, *AES256Mode_pt;
+
+/* AES256, (ECB, CBC, OFB), HMAC (MD5, SHA-1, SHA-256)      - 96  bytes */
+typedef struct AES256HMAC_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             cipherKey2;
+  uint64_t             cipherKey3;
+  uint64_t             hmacKey0;
+  uint64_t             hmacKey1;
+  uint64_t             hmacKey2;
+  uint64_t             hmacKey3;
+  uint64_t             hmacKey4;
+  uint64_t             hmacKey5;
+  uint64_t             hmacKey6;
+  uint64_t             hmacKey7;
+} AES256HMAC_t, *AES256HMAC_pt;
+
+/* AES256, (ECB, CBC, OFB), Non-HMAC (MD5, SHA-1, SHA-256)  - 32  bytes */
+typedef struct AES256_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             cipherKey2;
+  uint64_t             cipherKey3;
+} AES256_t, *AES256_pt;
+
+
+/* All AES192 possibilities */
+
+/* AES192, (CTR or CFB),    HMAC (MD5, SHA-1, SHA-192)      - 96  bytes */
+typedef struct AES192ModeHMAC_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             cipherKey2;
+  uint64_t             hmacKey0;
+  uint64_t             hmacKey1;
+  uint64_t             hmacKey2;
+  uint64_t             hmacKey3;
+  uint64_t             hmacKey4;
+  uint64_t             hmacKey5;
+  uint64_t             hmacKey6;
+  uint64_t             hmacKey7;
+  uint64_t             nonceCFBMask;
+} AES192ModeHMAC_t, *AES192ModeHMAC_pt;
+
+/* AES192, (CTR or CFB),    Non-HMAC (MD5, SHA-1, SHA-192)  - 32  bytes */
+typedef struct AES192Mode_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             cipherKey2;
+  uint64_t             nonceCFBMask;
+} AES192Mode_t, *AES192Mode_pt;
+
+/* AES192, (ECB, CBC, OFB), HMAC (MD5, SHA-1, SHA-192)      - 88  bytes */
+typedef struct AES192HMAC_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             cipherKey2;
+  uint64_t             hmacKey0;
+  uint64_t             hmacKey1;
+  uint64_t             hmacKey2;
+  uint64_t             hmacKey3;
+  uint64_t             hmacKey4;
+  uint64_t             hmacKey5;
+  uint64_t             hmacKey6;
+  uint64_t             hmacKey7;
+} AES192HMAC_t, *AES192HMAC_pt;
+
+/* AES192, (ECB, CBC, OFB), Non-HMAC (MD5, SHA-1, SHA-192)  - 24  bytes */
+typedef struct AES192_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             cipherKey2;
+} AES192_t, *AES192_pt;
+
+
+/* All AES128 possibilities */
+
+/* AES128, (CTR or CFB),    HMAC (MD5, SHA-1, SHA-128)      - 88  bytes */
+typedef struct AES128ModeHMAC_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             hmacKey0;
+  uint64_t             hmacKey1;
+  uint64_t             hmacKey2;
+  uint64_t             hmacKey3;
+  uint64_t             hmacKey4;
+  uint64_t             hmacKey5;
+  uint64_t             hmacKey6;
+  uint64_t             hmacKey7;
+  uint64_t             nonceCFBMask;
+} AES128ModeHMAC_t, *AES128ModeHMAC_pt;
+
+/* AES128, (CTR or CFB),    Non-HMAC (MD5, SHA-1, SHA-128)  - 24  bytes */
+typedef struct AES128Mode_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             nonceCFBMask;
+} AES128Mode_t, *AES128Mode_pt;
+
+/* AES128, (ECB, CBC, OFB), HMAC (MD5, SHA-1, SHA-128)      - 80  bytes */
+typedef struct AES128HMAC_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             hmacKey0;
+  uint64_t             hmacKey1;
+  uint64_t             hmacKey2;
+  uint64_t             hmacKey3;
+  uint64_t             hmacKey4;
+  uint64_t             hmacKey5;
+  uint64_t             hmacKey6;
+  uint64_t             hmacKey7;
+} AES128HMAC_t, *AES128HMAC_pt;
+
+/* AES128, (ECB, CBC, OFB), Non-HMAC (MD5, SHA-1, SHA-128)  - 16  bytes */
+typedef struct AES128_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+} AES128_t, *AES128_pt;
+
+
+/* All DES possibilities */
+
+/* DES, (ECB, CBC), HMAC (MD5, SHA-1, SHA-128)              - 72  bytes */
+typedef struct DESHMAC_s {
+  uint64_t             cipherKey0;
+  uint64_t             hmacKey0;
+  uint64_t             hmacKey1;
+  uint64_t             hmacKey2;
+  uint64_t             hmacKey3;
+  uint64_t             hmacKey4;
+  uint64_t             hmacKey5;
+  uint64_t             hmacKey6;
+  uint64_t             hmacKey7;
+} DESHMAC_t, *DESHMAC_pt;
+
+/* DES, (ECB, CBC), Non-HMAC (MD5, SHA-1, SHA-128)          - 9   bytes */
+typedef struct DES_s {
+  uint64_t             cipherKey0;
+} DES_t, *DES_pt;
+
+
+/* All 3DES possibilities */
+
+/* 3DES, (ECB, CBC), HMAC (MD5, SHA-1, SHA-128)             - 88  bytes */
+typedef struct TriDESHMAC_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             cipherKey2;
+  uint64_t             hmacKey0;
+  uint64_t             hmacKey1;
+  uint64_t             hmacKey2;
+  uint64_t             hmacKey3;
+  uint64_t             hmacKey4;
+  uint64_t             hmacKey5;
+  uint64_t             hmacKey6;
+  uint64_t             hmacKey7;
+} TriDESHMAC_t, *TriDESHMAC_pt;
+
+/* 3DES, (ECB, CBC), Non-HMAC (MD5, SHA-1, SHA-128)         - 24  bytes */
+typedef struct TriDES_s {
+  uint64_t             cipherKey0;
+  uint64_t             cipherKey1;
+  uint64_t             cipherKey2;
+} TriDES_t, *TriDES_pt;
+
+
+/* HMAC only - no cipher */
+
+/* HMAC (MD5, SHA-1, SHA-128)                               - 64  bytes */
+typedef struct HMAC_s {
+  uint64_t             hmacKey0;
+  uint64_t             hmacKey1;
+  uint64_t             hmacKey2;
+  uint64_t             hmacKey3;
+  uint64_t             hmacKey4;
+  uint64_t             hmacKey5;
+  uint64_t             hmacKey6;
+  uint64_t             hmacKey7;
+} HMAC_t, *HMAC_pt;
+
+typedef union CipherHashInfo_u {
+  AES256ModeHMAC_t     infoAES256ModeHMAC;
+  AES256Mode_t         infoAES256Mode;
+  AES256HMAC_t         infoAES256HMAC;
+  AES256_t             infoAES256;
+  AES192ModeHMAC_t     infoAES192ModeHMAC;
+  AES192Mode_t         infoAES192Mode;
+  AES192HMAC_t         infoAES192HMAC;
+  AES192_t             infoAES192;
+  AES128ModeHMAC_t     infoAES128ModeHMAC;
+  AES128Mode_t         infoAES128Mode;
+  AES128HMAC_t         infoAES128HMAC;
+  AES128_t             infoAES128;
+  DESHMAC_t            infoDESHMAC;
+  DES_t                infoDES;
+  TriDESHMAC_t         info3DESHMAC;
+  TriDES_t             info3DES;
+  HMAC_t               infoHMAC;
+  uint64_t             infoDwords[12];
+} CipherHashInfo_t, *CipherHashInfo_pt;
+
+/*
+ * This defines the security control descriptor format
+ */
+typedef struct ControlDescriptor_s {
+  uint64_t            instruction;
+  CipherHashInfo_t    cipherHashInfo;
+} ControlDescriptor_t, *ControlDescriptor_pt;
+
+/*
+ * This defines the security data descriptor format
+ */
+typedef struct PacketDescriptor_s {
+  uint64_t             srcLengthIVOffUseIVNext;
+  uint64_t             dstLLWMask;
+  uint64_t             authDst;
+  uint64_t             ckSumDst;
+} PacketDescriptor_t, *PacketDescriptor_pt;
+
+#define SEC_CTRL_ERR_NONE                    0x000
+#define SEC_CTRL_ERR_UNKNOWN_CIPHER_OP       0x001
+#define SEC_CTRL_ERR_ILLEGAL_MODE            0x002
+#define SEC_CTRL_ERR_UNSUPP_CKSUM_SRC        0x004
+#define SEC_CTRL_ERR_FORBIDDEN_CFB_MASK      0x008
+#define SEC_CTRL_ERR_UNKNOWN_CTRL_OP         0x010
+#define SEC_CTRL_ERR_DATA_READ               0x080
+#define SEC_CTRL_ERR_DESC_CTRL_FIELD         0x100
+
+#define SEC_PKT_ERR_NONE                     0x000
+#define SEC_PKT_ERR_INSUFF_DATA_TO_CIPHER    0x001
+#define SEC_PKT_ERR_ILLEGAL_IV_LOCATION      0x002
+#define SEC_PKT_ERR_ILLEGAL_WORDCOUNT_AES    0x004
+#define SEC_PKT_ERR_ILLEGAL_PAD_BYTECOUNT_SPEC 00x8
+#define SEC_PKT_ERR_INSUFF_DATA_TO_CKSUM       0x010
+#define SEC_PKT_ERR_UNKNOWN_DATA_OP            0x020
+#define SEC_PKT_ERR_INSUFF_DATA_TO_AUTH        0x040
+#define SEC_PKT_ERR_DATA_READ                  0x080
+
+#define HASH_NOP    0
+#define HASH_MD5    1
+#define HASH_SHA1   2
+#define HASH_SHA256 3
+
+static __inline__ int make_sec_desc(struct msgrng_msg *msg, void *ctrl_addr, int ctrl_len, void *data_addr)
+{
+  int stid = MSGRNG_STNID_SEC0;
+  msg->msg0 = ( ((uint64_t)SEC_SOP<<61)  | 
+		((uint64_t)4<<54) |
+		((uint64_t)ctrl_len<<45) |
+		((uint64_t)virt_to_phys(ctrl_addr) & 0xffffffffe0ULL)
+		);
+  msg->msg1 = ( ((uint64_t)SEC_EOP<<61)  | 
+		((uint64_t)4<<54) |
+		((uint64_t)1<<45) |
+		((uint64_t)virt_to_phys(data_addr) & 0xffffffffe0ULL)
+		);
+  msg->msg2 = msg->msg3 = 0;
+
+  return stid;
+}
+
+#endif
diff --git a/arch/mips/include/asm/rmi/phoenix_shim_drv.h b/arch/mips/include/asm/rmi/phoenix_shim_drv.h
new file mode 100644
index 0000000..28f8545
--- /dev/null
+++ b/arch/mips/include/asm/rmi/phoenix_shim_drv.h
@@ -0,0 +1,510 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _SHIM_H_
+#define _SHIM_H_
+
+#define DEBUG   1
+
+extern int debug_var;
+
+#ifdef DEBUG
+#define debug(level, fmt, args...) \
+	if (debug_var&level) printk(KERN_INFO fmt, ## args)
+#else
+#define debug(fmt, args...)
+#endif
+#define DEBUG_TRACE     0x8000
+#define DEBUG_INFO      0x4000
+#define DEBUG_TX_FSM    0x2000
+#define DEBUG_RX_FSM    0x1000
+#define DEBUG_REG_WRITE 0x0800
+#define DEBUG_ENTRY     0x0400
+#define DEBUG_EXIT      0x0200
+#define DEBUG_DSCR      0x0100
+#define DEBUG_ERROR     0x0080
+
+#define ENTRY_LO(v) ((uint32_t)(v&0xffffffff))
+#define ENTRY_HI(v) ((uint32_t)((v>>32)&0xffffffff))
+
+#define SHIM_OK     0
+#define SHIM_ERROR  -1
+
+/**********************************************************************
+ *  DMA Descriptor structure
+ ********************************************************************* */
+
+typedef struct shimdscr_s {
+	uint64_t  dscr_a;
+	uint64_t  dscr_b;
+} shimdscr_t;
+
+typedef unsigned long paddr_t;
+typedef unsigned long vaddr_t;
+typedef unsigned long shim_port_t;
+
+/**********************************************************************
+ *  DMA Controller structure
+ ********************************************************************* */
+
+typedef struct shim_cb_s {
+    int             shim_macnum;
+	int             shim_channel;	/* channel number */
+	int		        shim_txdir;     /* direction (1=transmit) */
+	int		        shim_maxdescr;	/* total # of descriptors in ring */
+	shim_port_t     shim_config0;	/* DMA config register 0 */
+	shim_port_t     shim_config1;	/* DMA config register 1 */
+	shim_port_t     shim_dscrbase;	/* Descriptor base address */
+	shim_port_t     shim_dscrcnt;   /* Descriptor count register */
+	shim_port_t     shim_curdscr;	/* current descriptor address */
+	shim_port_t     shim_dscraddcnt;/* Descriptor add count register */
+
+    /* This stuff is for maintenance of the ring */
+	
+	shimdscr_t     *shim_dscrtable;	/* base of descriptor table */
+	shimdscr_t     *shim_dscrtable_end; /* end of descriptor table */
+
+    struct packet **shim_ctxtable;
+
+    paddr_t         shim_dscrtable_phys; /* and also the phys addr */
+    shimdscr_t     *shim_addptr;  /* next dscr for sw to add */
+    shimdscr_t     *shim_remptr;  /* next dscr for sw to remove */
+    int             fsm_state;
+    int             shim_ready;    /* Activated by driver */
+    int             rcv_buf_full;   /* When set do not issue msgld */
+} shim_cb_t;
+
+#define SHIM_READCSR(t)    (*(uint64_t*)(t))
+#define SHIM_WRITECSR(t,v) (*(uint64_t*)(t) = v)
+#define SHIM_NEXTBUF(d,f) ((((d)->f+1) == (d)->shim_dscrtable_end) ? \
+              (d)->shim_dscrtable : (d)->f+1)
+#define SHIM_MAC_TYPE(macnum) ((macnum < MAC_MAX_GMAC) ? GMAC : XGMAC)
+#define SHIM_MAC_ID(macnum)   ((macnum < MAC_MAX_GMAC) ? macnum :\
+                             (macnum - MAC_MAX_GMAC))
+#define SHIM_GET_CB(macnum, txrx, chan) &shim_cb[macnum][txrx][chan]
+#define SHIM_CURDSCR(p) ((shimdscr_t *)(uint32_t)\
+                SHIM_READCSR(p->shim_curdscr))
+
+
+
+#define SHIM_ST_INVALID     -1
+#define SHIM_TR_INVALID     -1
+#define SHIM_EV_INVALID     -1
+
+/*
+ *  Finite State machine States
+ *
+ *  Count of non-terminal states.  The generated states INVALID and DONE
+ *  are terminal, but INIT is not  :-).
+ */
+#define SHIM_TX_STATE_CT 3 
+#define SHIM_TX_EVENT_CT 5
+typedef enum {
+    SHIM_ST_TX_INIT,
+    SHIM_ST_TX_ACTIVE,
+    SHIM_ST_TX_PAUSE,  
+} te_shim_tx_state;
+
+typedef enum {
+    SHIM_EV_TX_RESET,     
+    SHIM_EV_TX_CPU_PAUSE_EN,    
+    SHIM_EV_TX_CPU_RESUME,
+    SHIM_EV_TX_DSCR_CNT,
+    SHIM_EV_TX_ADD_DSCR_CNT,
+} te_shim_tx_event;
+
+#define SHIM_RX_STATE_CT 2
+#define SHIM_RX_EVENT_CT 4
+
+typedef enum {
+    SHIM_ST_RX_INIT,
+    SHIM_ST_RX_ACTIVE,
+} te_shim_rx_state;
+
+typedef enum {
+    SHIM_EV_RX_RESET,     
+    SHIM_EV_RX_DSCR_CNT,
+    SHIM_EV_RX_DSCR_ADD_CNT,
+    SHIM_EV_RX_PKT_FROM_MSGRNG
+} te_shim_rx_event;
+
+
+/*
+ *  Run the FSM.  Will return SHIM_ST_DONE or SHIM_ST_INVALID
+ */
+int shim_run_rx_fsm(shim_cb_t *shim_cb_p, int trans_evt);
+int shim_run_tx_fsm(shim_cb_t *shim_cb_p, int trans_evt);
+
+        
+/*
+ * Cast to 64-bit number.  Presumably the syntax is different in 
+ * assembly language.
+ *
+ * Note: you'll need to define uint32_t and uint64_t in your headers.
+ */
+
+#if !defined(__ASSEMBLER__)
+#define _SHIM_MAKE64(x) ((uint64_t)(x))
+#define _SHIM_MAKE32(x) ((uint32_t)(x))
+#else
+#define _SHIM_MAKE64(x) (x)
+#define _SHIM_MAKE32(x) (x)
+#endif
+
+
+/*
+ * Make a mask for 1 bit at position 'n'
+ */
+
+#define _SHIM_MAKEMASK1(n) (_SHIM_MAKE64(1) << _SHIM_MAKE64(n))
+#define _SHIM_MAKEMASK1_32(n) (_SHIM_MAKE32(1) << _SHIM_MAKE32(n))
+
+/*
+ * Make a mask for 'v' bits at position 'n'
+ */
+
+#define _SHIM_MAKEMASK(v,n) (_SHIM_MAKE64((_SHIM_MAKE64(1)<<(v))-1) << _SHIM_MAKE64(n))
+#define _SHIM_MAKEMASK_32(v,n) (_SHIM_MAKE32((_SHIM_MAKE32(1)<<(v))-1) << _SHIM_MAKE32(n))
+
+/*
+ * Make a value at 'v' at bit position 'n'
+ */
+
+#define _SHIM_MAKEVALUE(v,n) (_SHIM_MAKE64(v) << _SHIM_MAKE64(n))
+#define _SHIM_MAKEVALUE_32(v,n) (_SHIM_MAKE32(v) << _SHIM_MAKE32(n))
+
+#define _SHIM_GETVALUE(v,n,m) ((_SHIM_MAKE64(v) & _SHIM_MAKE64(m)) >> _SHIM_MAKE64(n))
+#define _SHIM_GETVALUE_32(v,n,m) ((_SHIM_MAKE32(v) & _SHIM_MAKE32(m)) >> _SHIM_MAKE32(n))
+
+/*
+ * Macros to read/write on-chip registers
+ * XXX should we do the PHYS_TO_K1 here?
+ */
+
+
+#if !defined(__ASSEMBLER__)
+#define SHIMWRITECSR(csr,val) *((volatile uint64_t *) PHYS_TO_K1(csr)) = (val)
+#define SHIMREADCSR(csr) (*((volatile uint64_t *) PHYS_TO_K1(csr)))
+#endif /* __ASSEMBLER__ */
+
+
+/*  *********************************************************************
+    *  SHIM Registers
+    ********************************************************************* */
+
+/* 
+ * Ethernet Configuration Register 0  
+ * Registers: DMA_CONFIG0_MAC_x_RX_CH_0 
+ * Registers: DMA_CONFIG0_MAC_x_TX_CH_0
+ */
+
+
+#define M_SHIM_DROP                  _SHIM_MAKEMASK1(0)
+#define M_SHIM_CHAIN_SEL             _SHIM_MAKEMASK1(1)
+#define M_SHIM_RESERVED1             _SHIM_MAKEMASK1(2)
+#define M_SHIM_EOP_INT_EN            _SHIM_MAKEMASK1(3)
+#define M_SHIM_HWM_INT_EN            _SHIM_MAKEMASK1(4)
+#define M_SHIM_LWM_INT_EN            _SHIM_MAKEMASK1(5)
+#define M_SHIM_TBX_EN                _SHIM_MAKEMASK1(6)
+#define M_SHIM_TDX_EN                _SHIM_MAKEMASK1(7)
+
+#define S_SHIM_INT_PKTCNT            _SHIM_MAKE64(8)
+#define M_SHIM_INT_PKTCNT            _SHIM_MAKEMASK(8,S_SHIM_INT_PKTCNT)
+#define V_SHIM_INT_PKTCNT(x)         _SHIM_MAKEVALUE(x,S_SHIM_INT_PKTCNT)
+#define G_SHIM_INT_PKTCNT(x)         _SHIM_GETVALUE(x,S_SHIM_INT_PKTCNT,M_SHIM_INT_PKTCNT)
+
+#define S_SHIM_RINGSZ                _SHIM_MAKE64(16)
+#define M_SHIM_RINGSZ                _SHIM_MAKEMASK(16,S_SHIM_RINGSZ)
+#define V_SHIM_RINGSZ(x)             _SHIM_MAKEVALUE(x,S_SHIM_RINGSZ)
+#define G_SHIM_RINGSZ(x)             _SHIM_GETVALUE(x,S_SHIM_RINGSZ,M_SHIM_RINGSZ)
+
+#define S_SHIM_HIGH_WATERMARK        _SHIM_MAKE64(32)
+#define M_SHIM_HIGH_WATERMARK        _SHIM_MAKEMASK(16,S_SHIM_HIGH_WATERMARK)
+#define V_SHIM_HIGH_WATERMARK(x)     _SHIM_MAKEVALUE(x,S_SHIM_HIGH_WATERMARK)
+#define G_SHIM_HIGH_WATERMARK(x)     _SHIM_GETVALUE(x,S_SHIM_HIGH_WATERMARK,M_SHIM_HIGH_WATERMARK)
+
+#define S_SHIM_LOW_WATERMARK         _SHIM_MAKE64(48)
+#define M_SHIM_LOW_WATERMARK         _SHIM_MAKEMASK(16,S_SHIM_LOW_WATERMARK)
+#define V_SHIM_LOW_WATERMARK(x)      _SHIM_MAKEVALUE(x,S_SHIM_LOW_WATERMARK)
+#define G_SHIM_LOW_WATERMARK(x)      _SHIM_GETVALUE(x,S_SHIM_LOW_WATERMARK,M_SHIM_LOW_WATERMARK)
+
+/*
+ * Ethernet Configuration Register 1 
+ * Registers: DMA_CONFIG1_MAC_x_RX_CH_0 
+ * Registers: DMA_CONFIG1_SHIM_x_TX_CH_0
+ */
+
+#define M_SHIM_HDR_CF_EN             _SHIM_MAKEMASK1(0)
+#define M_SHIM_ASIC_XFR_EN           _SHIM_MAKEMASK1(1)
+#define M_SHIM_PRE_ADDR_EN           _SHIM_MAKEMASK1(2)
+#define M_SHIM_FLOW_CTL_EN           _SHIM_MAKEMASK1(3)
+#define M_SHIM_NO_DSCR_UPDT          _SHIM_MAKEMASK1(4)
+#define M_SHIM_L2CA		    _SHIM_MAKEMASK1(5)
+#define M_SHIM_CPU_PAUSE_EN		    _SHIM_MAKEMASK1(6)
+
+#define M_SHIM_MBZ1                  _SHIM_MAKEMASK(6,15)
+
+#define S_SHIM_HDR_SIZE              _SHIM_MAKE64(21)
+#define M_SHIM_HDR_SIZE              _SHIM_MAKEMASK(9,S_SHIM_HDR_SIZE)
+#define V_SHIM_HDR_SIZE(x)           _SHIM_MAKEVALUE(x,S_SHIM_HDR_SIZE)
+#define G_SHIM_HDR_SIZE(x)           _SHIM_GETVALUE(x,S_SHIM_HDR_SIZE,M_SHIM_HDR_SIZE)
+
+#define M_SHIM_MBZ2                  _SHIM_MAKEMASK(5,32)
+
+#define S_SHIM_ASICXFR_SIZE          _SHIM_MAKE64(37)
+#define M_SHIM_ASICXFR_SIZE          _SHIM_MAKEMASK(9,S_SHIM_ASICXFR_SIZE)
+#define V_SHIM_ASICXFR_SIZE(x)       _SHIM_MAKEVALUE(x,S_SHIM_ASICXFR_SIZE)
+#define G_SHIM_ASICXFR_SIZE(x)       _SHIM_GETVALUE(x,S_SHIM_ASICXFR_SIZE,M_SHIM_ASICXFR_SIZE)
+
+#define S_SHIM_INT_TIMEOUT           _SHIM_MAKE64(48)
+#define M_SHIM_INT_TIMEOUT           _SHIM_MAKEMASK(16,S_SHIM_INT_TIMEOUT)
+#define V_SHIM_INT_TIMEOUT(x)        _SHIM_MAKEVALUE(x,S_SHIM_INT_TIMEOUT)
+#define G_SHIM_INT_TIMEOUT(x)        _SHIM_GETVALUE(x,S_SHIM_INT_TIMEOUT,M_SHIM_INT_TIMEOUT)
+
+/*
+ * Ethernet Descriptor base address 
+ */
+
+#define M_SHIM_DSCRBASE_MBZ          _SHIM_MAKEMASK(4,0)
+#define M_SHIM_DSCRBASE              _SHIM_MAKEMASK(36,4)
+
+
+/* 
+ * Current Descriptor Address Register 
+ */
+
+#define S_SHIM_CURDSCR_ADDR          _SHIM_MAKE64(0)
+#define M_SHIM_CURDSCR_ADDR          _SHIM_MAKEMASK(40,S_SHIM_CURDSCR_ADDR)
+#define S_SHIM_CURDSCR_COUNT         _SHIM_MAKE64(0)
+#define M_SHIM_CURDSCR_COUNT         _SHIM_MAKEMASK(16,S_SHIM_CURDSCR_COUNT)
+
+#define M_SHIM_CURDSCR_ADD_COUNT     M_SHIM_CURDSCR_COUNT
+
+/*  ********************************************************************* 
+    * Ethernet, MAC is not used
+    ********************************************************************* */
+
+#define A_MAC_BASE_0               0 
+
+#define MAC_SPACING                 0x1000
+#define SHIM_TXRX_SPACING        0x0400
+#define SHIM_CHANNEL_SPACING     0x0100
+#define SHIM_RX                      0
+#define SHIM_TX                      1
+#define MAX_SHIM_TXRX                2
+#define MAC_NUM_SHIMCHAN         2           /* channels per direction */
+
+#define MAC_NUM_PORTS               6
+#define MAC_MAX_GMAC                4
+
+#define A_MAC_CHANNEL_BASE(macnum)                  \
+            (A_MAC_BASE_0 +                         \
+             MAC_SPACING*(macnum))
+
+#define R_SHIM_CHANNELS      0x800 /* Relative to A_MAC_CHANNEL_BASE */
+
+#define A_SHIM_CHANNEL_BASE(macnum,txrx,chan)    \
+             ((A_MAC_CHANNEL_BASE(macnum)) +        \
+             R_SHIM_CHANNELS +                   \
+             (SHIM_TXRX_SPACING*(txrx)) +        \
+             (SHIM_CHANNEL_SPACING*(chan)))
+
+#define R_SHIM_CHANNEL_BASE(txrx,chan)    \
+             (R_SHIM_CHANNELS +                   \
+             (SHIM_TXRX_SPACING*(txrx)) +        \
+             (SHIM_CHANNEL_SPACING*(chan)))
+
+#define A_SHIM_REGISTER(macnum,txrx,chan,reg)           \
+            (A_SHIM_CHANNEL_BASE(macnum,txrx,chan) +    \
+            (reg))
+
+#define R_SHIM_REGISTER(txrx,chan,reg)           \
+            (R_SHIM_CHANNEL_BASE(txrx,chan) +    \
+            (reg))
+
+#define I_SHIM_REGISTER(macnum,txrx,chan,reg)\
+            ((A_SHIM_CHANNEL_BASE(macnum,txrx,chan) +    \
+            (reg))/sizeof(unsigned long long int))
+/* 
+ * SHIM channel registers, relative to A_SHIM_CHANNEL_BASE
+ */
+
+#define R_SHIM_CONFIG0               0x00000000
+#define R_SHIM_CONFIG1               0x00000008
+#define R_SHIM_DSCR_BASE             0x00000010
+#define R_SHIM_DSCR_CNT              0x00000018
+#define R_SHIM_CUR_DSCRA             0x00000020
+#define R_SHIM_CUR_DSCRB             0x00000028
+#define R_SHIM_CUR_DSCRADDR          0x00000030
+#define R_SHIM_DSCR_ADD_CNT          0x00000038
+
+
+/*  *********************************************************************
+    *  DMA Descriptors
+    ********************************************************************* */
+
+/*
+ * Descriptor doubleword "A"  (Table 7-12)
+ */
+
+#define S_SHIM_DSCRA_OFFSET          _SHIM_MAKE64(0)
+#define M_SHIM_DSCRA_OFFSET          _SHIM_MAKEMASK(5,S_SHIM_DSCRA_OFFSET)
+
+/* Note: Don't shift the address over, just mask it with the mask below */
+#define S_SHIM_DSCRA_A_ADDR          _SHIM_MAKE64(5)
+#define M_SHIM_DSCRA_A_ADDR          _SHIM_MAKEMASK(35,S_SHIM_DSCRA_A_ADDR)
+
+#define M_SHIM_DSCRA_A_ADDR_OFFSET   (M_SHIM_DSCRA_OFFSET | M_SHIM_DSCRA_A_ADDR)
+
+#define S_SHIM_DSCRA_A_ADDR_UA        _SHIM_MAKE64(0)
+#define M_SHIM_DSCRA_A_ADDR_UA        _SHIM_MAKEMASK(40,S_SHIM_DSCRA_A_ADDR_UA)
+
+#define S_SHIM_DSCRA_A_SIZE          _SHIM_MAKE64(40)
+#define M_SHIM_DSCRA_A_SIZE          _SHIM_MAKEMASK(9,S_SHIM_DSCRA_A_SIZE)
+#define V_SHIM_DSCRA_A_SIZE(x)       _SHIM_MAKEVALUE(x,S_SHIM_DSCRA_A_SIZE)
+#define G_SHIM_DSCRA_A_SIZE(x)       _SHIM_GETVALUE(x,S_SHIM_DSCRA_A_SIZE,M_SHIM_DSCRA_A_SIZE)
+
+#define M_SHIM_DSCRA_INTERRUPT       _SHIM_MAKEMASK1(49)
+#define M_SHIM_DSCRA_OFFSETB	    _SHIM_MAKEMASK1(50)
+
+#define S_SHIM_DSCRA_STATUS          _SHIM_MAKE64(51)
+#define M_SHIM_DSCRA_STATUS          _SHIM_MAKEMASK(13,S_SHIM_DSCRA_STATUS)
+#define V_SHIM_DSCRA_STATUS(x)       _SHIM_MAKEVALUE(x,S_SHIM_DSCRA_STATUS)
+#define G_SHIM_DSCRA_STATUS(x)       _SHIM_GETVALUE(x,S_SHIM_DSCRA_STATUS,M_SHIM_DSCRA_STATUS)
+
+/*
+ * Descriptor doubleword "B"  (Table 7-13)
+ */
+
+
+#define S_SHIM_DSCRB_OPTIONS         _SHIM_MAKE64(0)
+#define M_SHIM_DSCRB_OPTIONS         _SHIM_MAKEMASK(4,S_SHIM_DSCRB_OPTIONS)
+#define V_SHIM_DSCRB_OPTIONS(x)      _SHIM_MAKEVALUE(x,S_SHIM_DSCRB_OPTIONS)
+#define G_SHIM_DSCRB_OPTIONS(x)      _SHIM_GETVALUE(x,S_SHIM_DSCRB_OPTIONS,M_SHIM_DSCRB_OPTIONS)
+
+#define R_SHIM_DSCRB_ADDR            _SHIM_MAKE64(0x10)
+
+/* Note: Don't shift the address over, just mask it with the mask below */
+#define S_SHIM_DSCRB_B_ADDR          _SHIM_MAKE64(5)
+#define M_SHIM_DSCRB_B_ADDR          _SHIM_MAKEMASK(35,S_SHIM_DSCRB_B_ADDR)
+
+#define S_SHIM_DSCRB_B_SIZE          _SHIM_MAKE64(40)
+#define M_SHIM_DSCRB_B_SIZE          _SHIM_MAKEMASK(9,S_SHIM_DSCRB_B_SIZE)
+#define V_SHIM_DSCRB_B_SIZE(x)       _SHIM_MAKEVALUE(x,S_SHIM_DSCRB_B_SIZE)
+#define G_SHIM_DSCRB_B_SIZE(x)       _SHIM_GETVALUE(x,S_SHIM_DSCRB_B_SIZE,M_SHIM_DSCRB_B_SIZE)
+
+#define M_SHIM_DSCRB_B_VALID         _SHIM_MAKEMASK1(49)
+
+#define S_SHIM_DSCRB_PKT_SIZE        _SHIM_MAKE64(50)
+#define M_SHIM_DSCRB_PKT_SIZE        _SHIM_MAKEMASK(14,S_SHIM_DSCRB_PKT_SIZE)
+#define V_SHIM_DSCRB_PKT_SIZE(x)     _SHIM_MAKEVALUE(x,S_SHIM_DSCRB_PKT_SIZE)
+#define G_SHIM_DSCRB_PKT_SIZE(x)     _SHIM_GETVALUE(x,S_SHIM_DSCRB_PKT_SIZE,M_SHIM_DSCRB_PKT_SIZE)
+
+/* 
+ * Ethernet Descriptor Status Bits (Table 7-15)
+ */
+
+#define M_SHIM_ETHRX_BADIP4CS        _SHIM_MAKEMASK1(51)
+#define M_SHIM_ETHRX_DSCRERR	    _SHIM_MAKEMASK1(52)
+
+#define S_SHIM_ETHRX_RXCH            53
+#define M_SHIM_ETHRX_RXCH            _SHIM_MAKEMASK(2,S_SHIM_ETHRX_RXCH)
+#define V_SHIM_ETHRX_RXCH(x)         _SHIM_MAKEVALUE(x,S_SHIM_ETHRX_RXCH)
+#define G_SHIM_ETHRX_RXCH(x)         _SHIM_GETVALUE(x,S_SHIM_ETHRX_RXCH,M_SHIM_ETHRX_RXCH)
+
+#define S_SHIM_ETHRX_PKTTYPE         55
+#define M_SHIM_ETHRX_PKTTYPE         _SHIM_MAKEMASK(3,S_SHIM_ETHRX_PKTTYPE)
+#define V_SHIM_ETHRX_PKTTYPE(x)      _SHIM_MAKEVALUE(x,S_SHIM_ETHRX_PKTTYPE)
+#define G_SHIM_ETHRX_PKTTYPE(x)      _SHIM_GETVALUE(x,S_SHIM_ETHRX_PKTTYPE,M_SHIM_ETHRX_PKTTYPE)
+
+#define K_SHIM_ETHRX_PKTTYPE_IPV4    0
+#define K_SHIM_ETHRX_PKTTYPE_ARPV4   1
+#define K_SHIM_ETHRX_PKTTYPE_802     2
+#define K_SHIM_ETHRX_PKTTYPE_OTHER   3
+#define K_SHIM_ETHRX_PKTTYPE_USER0   4
+#define K_SHIM_ETHRX_PKTTYPE_USER1   5
+#define K_SHIM_ETHRX_PKTTYPE_USER2   6
+#define K_SHIM_ETHRX_PKTTYPE_USER3   7
+
+#define M_SHIM_ETHRX_MATCH_EXACT     _SHIM_MAKEMASK1(58)
+#define M_SHIM_ETHRX_MATCH_HASH      _SHIM_MAKEMASK1(59)
+#define M_SHIM_ETHRX_BCAST           _SHIM_MAKEMASK1(60)
+#define M_SHIM_ETHRX_MCAST           _SHIM_MAKEMASK1(61)
+#define M_SHIM_ETHRX_BAD	            _SHIM_MAKEMASK1(62)
+#define M_SHIM_ETHRX_SOP             _SHIM_MAKEMASK1(63)
+
+/*
+ * Ethernet Transmit Status Bits (Table 7-16)
+ */
+
+#define M_SHIM_ETHTX_SOP	    	    _SHIM_MAKEMASK1(63)
+
+/* 
+ * Ethernet Transmit Options (Table 7-17)
+ */
+
+#define K_SHIM_ETHTX_NOTSOP          _SHIM_MAKE64(0x00)
+#define K_SHIM_ETHTX_APPENDCRC       _SHIM_MAKE64(0x01)
+#define K_SHIM_ETHTX_REPLACECRC      _SHIM_MAKE64(0x02)
+#define K_SHIM_ETHTX_APPENDCRC_APPENDPAD _SHIM_MAKE64(0x03)
+#define K_SHIM_ETHTX_APPENDVLAN_REPLACECRC _SHIM_MAKE64(0x04)
+#define K_SHIM_ETHTX_REMOVEVLAN_REPLACECRC _SHIM_MAKE64(0x05)
+#define K_SHIM_ETHTX_REPLACEVLAN_REPLACECRC _SHIM_MAKE64(0x6)
+#define K_SHIM_ETHTX_NOMODS          _SHIM_MAKE64(0x07)
+#define K_SHIM_ETHTX_RESERVED1       _SHIM_MAKE64(0x08)
+#define K_SHIM_ETHTX_REPLACESADDR_APPENDCRC _SHIM_MAKE64(0x09)
+#define K_SHIM_ETHTX_REPLACESADDR_REPLACECRC _SHIM_MAKE64(0x0A)
+#define K_SHIM_ETHTX_REPLACESADDR_APPENDCRC_APPENDPAD _SHIM_MAKE64(0x0B)
+#define K_SHIM_ETHTX_REPLACESADDR_APPENDVLAN_REPLACECRC _SHIM_MAKE64(0x0C)
+#define K_SHIM_ETHTX_REPLACESADDR_REMOVEVLAN_REPLACECRC _SHIM_MAKE64(0x0D)
+#define K_SHIM_ETHTX_REPLACESADDR_REPLACEVLAN_REPLACECRC _SHIM_MAKE64(0x0E)
+#define K_SHIM_ETHTX_RESERVED2       _SHIM_MAKE64(0x0F)
+
+#define S_MAC_RX_CH0                _SHIM_MAKE64(0)
+#define S_MAC_RX_CH1                _SHIM_MAKE64(8)
+#define S_MAC_TX_CH0                _SHIM_MAKE64(16)
+#define S_MAC_TX_CH1                _SHIM_MAKE64(24)
+
+#define M_MAC_INT_CHANNEL           _SHIM_MAKEMASK(8,0)
+#define R_MAC_ENABLE                    0x00000400
+#define R_MAC_STATUS                    0x00000408
+#define R_MAC_ETHERNET_ADDR             0x00000208
+        
+extern shim_cb_t shim_cb[MAC_NUM_PORTS][MAX_SHIM_TXRX][MAC_NUM_SHIMCHAN];
+/* Register file holding all register values, in a fixed location */
+extern uint64_t reg_file[MAC_SPACING * MAC_NUM_PORTS];
+int shim_handle_rx_pkt_from_msgrng(shim_cb_t *shim_cb_p);
+int shim_handle_reset(shim_cb_t *shim_cb_p);
+int shim_handle_tx_dscr_cnt(shim_cb_t *shim_cb_p);
+int shim_handle_tx_cpu_pause_en(shim_cb_t *shim_cb_p);
+int shim_handle_tx_resume(shim_cb_t *shim_cb_p);
+
+
+#endif /* _SHIM_H_ */
diff --git a/arch/mips/include/asm/rmi/phoenix_uart.h b/arch/mips/include/asm/rmi/phoenix_uart.h
new file mode 100644
index 0000000..308822e
--- /dev/null
+++ b/arch/mips/include/asm/rmi/phoenix_uart.h
@@ -0,0 +1,52 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _UART_H
+#define _UART_H
+
+#include <asm/rmi/iomap.h>
+
+#define UART_RHR 0
+#define UART_THR 0
+#define UART_IER 1
+#define UART_IIR 2
+#define UART_FCR 2
+#define UART_LCR 3
+#define UART_MCR 4
+#define UART_LSR 5
+#define UART_MSR 6
+
+#define UART_DLB_1 0
+#define UART_DLB_2 1
+
+#define UART_DEBUG_1 8
+#define UART_DEBUG_2 9
+
+#endif
diff --git a/arch/mips/include/asm/rmi/pic.h b/arch/mips/include/asm/rmi/pic.h
new file mode 100644
index 0000000..8e7bd44
--- /dev/null
+++ b/arch/mips/include/asm/rmi/pic.h
@@ -0,0 +1,67 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_PIC_H
+#define _ASM_RMI_PIC_H
+
+#include <asm/rmi/iomap.h>
+
+#ifndef __ASSEMBLY__
+struct pt_regs;
+extern void phoenix_ipi_handler(int irq, struct pt_regs *regs);
+extern void phnx_msgring_int_handler(unsigned int irq, struct pt_regs *regs);
+
+struct pic_tmask { 
+	unsigned int mask; 
+	int set; 
+	int valid;
+};
+
+#endif
+
+#if defined(CONFIG_RMI_XLP)
+
+// can't do floating in the kernel, so use 64 as an approximation 
+#define PIC_CLKS_PER_SEC 133333333ULL
+#define PIC_CLKS_PER_USEC 133	//(PIC_CLKS_PER_SEC / 1000000)
+#define PIC_CLKS_PER_TIMER_TICK (PIC_CLKS_PER_SEC / HZ)
+#include <asm/rmi/xlp_common/xlp_pic.h>
+
+#else
+// can't do floating in the kernel, so use 64 as an approximation 
+#define PIC_CLKS_PER_SEC 66666666ULL
+#define PIC_CLKS_PER_USEC 66	//(PIC_CLKS_PER_SEC / 1000000)
+#define PIC_CLKS_PER_TIMER_TICK (PIC_CLKS_PER_SEC / HZ)
+
+#include <asm/rmi/xlr_pic.h>
+#endif /* CONFIG_RMI_XLP */
+
+#endif /* #ifndef _ASM_RMI_PIC_H */
+	
diff --git a/arch/mips/include/asm/rmi/proc.h b/arch/mips/include/asm/rmi/proc.h
new file mode 100644
index 0000000..8e988ee
--- /dev/null
+++ b/arch/mips/include/asm/rmi/proc.h
@@ -0,0 +1,51 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_PROC_H
+#define _ASM_RMI_PROC_H
+
+#include <linux/types.h>
+
+static __inline__ int proc_pos_check(off_t * begin, int *len, off_t off,
+				     int count)
+{
+	off_t pos = *begin + *len;
+
+	if (pos < off) {
+		*len = 0;
+		*begin = pos;
+	}
+	if (pos > off + count)
+		return 0;
+
+	return 1;
+}
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmi_pcix_gen_dev.h b/arch/mips/include/asm/rmi/rmi_pcix_gen_dev.h
new file mode 100644
index 0000000..859038d
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmi_pcix_gen_dev.h
@@ -0,0 +1,124 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef __PHNX_PCIX_DEVICE_H__
+#define __PHNX_PCIX_DEVICE_H__
+
+#include <asm/types.h>
+#include <linux/cache.h>
+
+#ifdef PHOENIX_LITTLE_ENDIAN
+#define PCIX_REG_BASE 64
+#else
+#define PCIX_REG_BASE (512 + 64)
+#endif
+
+/*Define this macro if device supports MAILBOX interrupt.*/
+//#define XLR_MAILBOX_IS_SUPPORTED 1
+
+/*Define this macro if host is MSI capable.*/
+//#define XLR_MSI_IS_SUPPORTED 1
+
+#define XLR_PCI_HOST_MODE 0x1
+#define XLR_PCI_DEV_MODE 0x2
+#define PCIX_INTRPT_CONTROL_REG ( PCIX_REG_BASE + 15)
+#define PCIX_PHOENIX_CONTROL_REG ( PCIX_REG_BASE + 14)
+#define PCIX_INTRPT_STATUS_REG ( PCIX_REG_BASE + 16)
+#define PCIX_HOST_MODE_CTRL_STATUS_REG ( PCIX_REG_BASE + 35)
+#define PCIX_DEVICE_MODE_ADDR_MAPPER ( PCIX_REG_BASE + 36)
+#define PCIX_DEVMODE_TBL_BAR0_REG                   (PCIX_REG_BASE + 44)
+#define PCIX_DEVMODE_TBL_BAR1_REG                   (PCIX_REG_BASE + 45)
+#define PCIX_DEVMODE_TBL_BAR2_REG                   (PCIX_REG_BASE + 46)
+#define PCIX_DEVMODE_TBL_BAR3_REG                   (PCIX_REG_BASE + 47)
+
+#define PHNX_MAX_IRQS_SUPPORTED 16
+
+#define phnx_host_to_pci(addr) ((uint64_t)(addr) | 0x8000000000UL)
+
+#define CACHELINE_ALIGNED_ADDR(addr) \
+			(((unsigned long)(addr)) & ~(SMP_CACHE_BYTES-1))
+
+
+int xlr_get_pci_mode(void);
+void phnx_interrupt_host(void);
+// DEVICE SIDE
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+typedef int (*mailbox_handler)(void *, struct pt_regs *);
+int phnx_request_mailbox_handler(mailbox_handler, void *, int *);
+int phnx_disable_mailbox_intr(int *);
+int phnx_enable_mailbox_intr(int *);
+int phnx_free_mailbox_handler(int *);
+#endif
+
+
+/*****************************************************************************************************************/
+/**********************************SHARED    MEMORY***************************************************************/
+/*****************************************************************************************************************/
+// DURING BOOT ONLY
+
+#define PHNX_BOOT_SHARED_MEM_BASE 0x1000
+#define PHNX_BOOT_SHARED_MEM_SIZE (32 * 1024 * 1024)
+
+
+// AFTER BOOTIN WHOLE SHARED MEMORY IS CLAIMED BY THE GENERIC PCI DRIVER 
+#define PHNX_GENERIC_SHARED_MEM_BASE (20*1024*1024)
+#define PHNX_GENERIC_SHARED_MEM_SIZE (10*1024*1024)
+
+#define PHNX_PCIX_SHARED_MEM_START (0x8000000+PHNX_GENERIC_SHARED_MEM_BASE)
+#define PHNX_PCIX_SHARED_MEM_END (PHNX_PCIX_SHARED_MEM_START+PHNX_GENERIC_SHARED_MEM_SIZE)
+// All The Shared Address must be unique for each driver. Confliction of Address Space can cause unpredictable result. Shared Space Must be in sync with that of host driver.
+
+
+// SHARED SPACE BETWEEN MAC DRIVERS
+#define PHNX_MAC_SHARED_MEM_BASE PHNX_GENERIC_SHARED_MEM_BASE
+#define PHNX_MAC_SHARED_MEM_SIZE (1 * 1024 * 1024)
+
+
+// SHARED SPACE BETWEEN CONSOLE DRIVERS
+#define PHNX_CONSOLE_OVER_PCI_SHARED_MEM_BASE \
+	         (PHNX_MAC_SHARED_MEM_BASE + PHNX_MAC_SHARED_MEM_SIZE)
+#define PHNX_CONSOLE_OVER_PCI_SHARED_MEM_SIZE (9 * 1024)
+
+// SHARED space for DMA
+#define PHNX_DMA_MEM_BASE \
+			(PHNX_CONSOLE_OVER_PCI_SHARED_MEM_BASE + \
+	 		PHNX_CONSOLE_OVER_PCI_SHARED_MEM_SIZE)
+#define PHNX_DMA_MEM_SIZE 1024
+
+// SHARED SPACE BETWEEN IP OVER PCI DRIVER...
+#define PHNX_IP_OVER_PCI_MEM_BASE \
+			(PHNX_DMA_MEM_BASE + PHNX_DMA_MEM_SIZE)
+#define PHNX_IP_OVER_PCI_MEM_SIZE (8*512+8*512+1024) 
+
+// SHARED SPACE BETWEEN SECURITY DRIVER... xxxx
+//
+//
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmi_pcix_gen_host.h b/arch/mips/include/asm/rmi/rmi_pcix_gen_host.h
new file mode 100644
index 0000000..29bfeae
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmi_pcix_gen_host.h
@@ -0,0 +1,130 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef __PHNX_PCIX_DEVICE_H__
+#define __PHNX_PCIX_DEVICE_H__
+
+#include <asm/types.h>
+#include <linux/cache.h>
+
+/*Define this macro if device supports MAILBOX interrupt.*/
+//#define XLR_MAILBOX_IS_SUPPORTED 1
+
+/*Define this macro if host is MSI capable.*/
+//#define XLR_MSI_IS_SUPPORTED 1
+
+#ifdef CONFIG_RMI_PHOENIX
+#ifdef PHOENIX_LITTLE_ENDIAN
+#define PCIX_REG_BASE 64
+#else
+#define PCIX_REG_BASE (512 + 64)
+#endif
+#define PCIX_HOST_MODE_CTRL_STATUS_REG ( PCIX_REG_BASE + 35)
+#endif
+
+#define XLR_PCI_HOST_MODE 0x1
+#define XLR_PCI_DEV_MODE 0x2
+
+#define phnx_host_to_pci(addr) ((uint64_t)(addr) | 0x8000000000UL)
+
+#define CACHELINE_ALIGNED_ADDR(addr) \
+			(((unsigned long)(addr)) & ~(SMP_CACHE_BYTES-1))
+
+#ifndef CONFIG_RMI_PHOENIX
+#ifdef XLR_MSI_IS_SUPPORTED
+typedef int (*msi_handler)(void *, struct pt_regs *);
+#endif
+#endif
+
+// HOST SIDE
+#ifndef CONFIG_RMI_PHOENIX
+#ifdef XLR_MSI_IS_SUPPORTED
+int phnx_request_msi_handler(msi_handler,void *,int *);
+void phnx_free_msi_handler(int *);
+int phnx_enable_msi(int *);
+int phnx_disable_msi(int *);
+void phnx_interrupt_host(void);
+#endif
+#endif
+
+#ifdef CONFIG_RMI_PHOENIX
+int rmi_get_pci_mode(void);
+#endif
+
+unsigned long phnx_get_shared_mem_base(void);
+unsigned int phnx_pci_readl(unsigned int *);
+u8 phnx_pci_readb(u8 *);
+void rmi_phnx_interrupt_device(void);
+
+
+
+
+/*****************************************************************************************************************/
+/**********************************SHARED    MEMORY***************************************************************/
+/*****************************************************************************************************************/
+// DURING BOOT ONLY
+
+#define PHNX_BOOT_SHARED_MEM_BASE 0x1000
+#define PHNX_BOOT_SHARED_MEM_SIZE (32 * 1024 * 1024)
+
+
+// AFTER BOOTIN WHOLE SHARED MEMORY IS CLAIMED BY THE GENERIC PCI DRIVER 
+#define PHNX_GENERIC_SHARED_MEM_BASE (20*1024*1024)
+#define PHNX_GENERIC_SHARED_MEM_SIZE (10* 1024 * 1024)
+
+// All The Shared Address must be unique for each driver. Confliction of Address Space can cause unpredictable result.
+
+
+// SHARED SPACE BETWEEN MAC DRIVERS
+#define PHNX_MAC_SHARED_MEM_BASE PHNX_GENERIC_SHARED_MEM_BASE
+#define PHNX_MAC_SHARED_MEM_SIZE (1 * 1024 * 1024)
+
+
+// SHARED SPACE BETWEEN CONSOLE DRIVERS
+#define PHNX_CONSOLE_OVER_PCI_SHARED_MEM_BASE \
+	         (PHNX_MAC_SHARED_MEM_BASE + PHNX_MAC_SHARED_MEM_SIZE)
+#define PHNX_CONSOLE_OVER_PCI_SHARED_MEM_SIZE (9 * 1024)
+
+// SHARED space for DMA
+#define PHNX_DMA_MEM_BASE \
+			(PHNX_CONSOLE_OVER_PCI_SHARED_MEM_BASE + \
+	 		PHNX_CONSOLE_OVER_PCI_SHARED_MEM_SIZE)
+#define PHNX_DMA_MEM_SIZE 1024
+
+// SHARED SPACE BETWEEN IP OVER PCI DRIVER...
+#define PHNX_IP_OVER_PCI_MEM_BASE \
+			(PHNX_DMA_MEM_BASE + PHNX_DMA_MEM_SIZE)
+#define PHNX_IP_OVER_PCI_MEM_SIZE (8*512+8*512+1024) 
+
+// SHARED SPACE BETWEEN SECURITY DRIVER... xxxx
+//
+//
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmi_rw_lock.h b/arch/mips/include/asm/rmi/rmi_rw_lock.h
new file mode 100644
index 0000000..e108bff
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmi_rw_lock.h
@@ -0,0 +1,221 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+#ifndef __RMI_RW_LOCK_H_
+#define __RMI_RW_LOCK_H_
+
+#define RMI_MAX_CPUS 32
+typedef struct {
+	volatile unsigned int lock;
+	unsigned int read_cpus[RMI_MAX_CPUS]; /* cpus that hold rd lock */
+	int write_cpu; /* CPU that is currently holding wr lock */
+} rmi_rwlock_t;
+
+#define rmi_sync() __asm__ __volatile__("sync": : :"memory")
+__asm__ (
+		".macro\trmi_local_irq_save result\n\t"
+		".set\tpush\n\t"
+		".set\treorder\n\t"
+		".set\tnoat\n\t"
+		"mfc0\t\\result, $12\n\t"
+		"ori\t$1, \\result, 1\n\t"
+		"xori\t$1, 1\n\t"
+		".set\tnoreorder\n\t"
+		"mtc0\t$1, $12\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		".set\tpop\n\t"
+		".endm");
+
+__asm__(".macro\trmi_local_irq_restore flags\n\t"
+		".set\tnoreorder\n\t"
+		".set\tnoat\n\t"
+		"mfc0\t$1, $12\n\t"
+		"andi\t\\flags, 1\n\t"
+		"ori\t$1, 1\n\t"
+		"xori\t$1, 1\n\t"
+		"or\t\\flags, $1\n\t"
+		"mtc0\t\\flags, $12\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		"sll\t$0, $0, 1\t\t\t# nop\n\t"
+		".set\tat\n\t"
+		".set\treorder\n\t"
+		".endm");
+
+
+#define rmi_local_irq_save(x)		\
+	__asm__ __volatile__(           \
+		"rmi_local_irq_save\t%0"                                    \
+		: "=r" (x)		\
+		: /* no inputs */	\
+		: "memory")
+
+
+#define rmi_local_irq_restore(flags)		\
+	do {                           		\
+		unsigned long __tmp1;  		\
+		__asm__ __volatile__(  		\
+		"rmi_local_irq_restore\t%0"        	\
+		: "=r" (__tmp1)                 \
+		: "0" (flags)                   \
+		: "memory");                    \
+	} while(0)
+
+
+#define rmi_processor_id() 				\
+	({ int __res;                                   \
+	 __asm__ __volatile__(                          \
+		 ".set\tmips32\n\t"                     \
+		 "mfc0\t%0, $15, 1\n\t"           	\
+		 "andi\t%0, 0x1f\n\t"			\
+		 ".set\tmips0\n\t"                      \
+		 : "=r" (__res));                       \
+	 __res;                                         \
+	 })
+
+
+static inline unsigned int rmi_read_lock_irq_save(rmi_rwlock_t *rw)
+{
+	unsigned int temp;
+	unsigned int cpu;
+	unsigned int flags;
+
+	rmi_local_irq_save(flags);
+	cpu = rmi_processor_id();
+
+		__asm__ __volatile__(
+		"	.set	noreorder	\n"
+		"1:	ll	%1, %2		\n"
+		"	bltz	%1, 2f		\n"
+		"	 addu	%1, 1		\n"
+		"	sc	%1, %0		\n"
+		"	beqz	%1, 1b		\n"
+		"	 nop			\n"
+		"	.subsection 2		\n"
+		"2:	ll	%1, %2		\n"
+		"	bltz	%1, 2b		\n"
+		"	 addu	%1, 1		\n"
+		"	b	1b		\n"
+		"	 nop			\n"
+		"	.previous		\n"
+		"	.set	reorder		\n"
+		: "=m" (rw->lock), "=&r" (temp)
+		: "m" (rw->lock)
+		: "memory");
+
+		rw->read_cpus[cpu] = 1;
+		rmi_sync();
+
+		return flags;
+}
+
+static inline void rmi_read_unlock_irq_restore(rmi_rwlock_t *rw, 
+			unsigned int flags)
+{
+	unsigned int temp;
+	unsigned int cpu;
+
+	cpu = rmi_processor_id();
+
+	rmi_sync();
+	__asm__ __volatile__(
+		"       .set    noreorder       			\n"
+		"1:     ll      %1, %2                                  \n"
+		"       sub     %1, 1                                   \n"
+		"       sc      %1, %0                                  \n"
+		"       beqz    %1, 2f                                  \n"
+		"        nop                                            \n"
+		"       .subsection 2                                   \n"
+		"2:     b       1b                                      \n"
+		"        nop                                            \n"
+		"       .previous                                       \n"
+		"       .set    reorder                                 \n"
+		: "=m" (rw->lock), "=&r" (temp)
+		: "m" (rw->lock)
+		: "memory");
+	rw->read_cpus[cpu] = 0;
+	rmi_local_irq_restore(flags);
+
+}
+
+static inline unsigned int rmi_write_lock_irq_save(rmi_rwlock_t *rw)
+{
+	unsigned int temp;
+	unsigned int cpu;
+	unsigned int flags;
+
+	rmi_local_irq_save(flags);
+	cpu = rmi_processor_id();
+
+	__asm__ __volatile__(
+		"       .set    noreorder       			\n"
+		"1:     ll      %1, %2                                  \n"
+		"       bnez    %1, 2f                                  \n"
+		"        lui    %1, 0x8000                              \n"
+		"       sc      %1, %0                                  \n"
+		"       beqz    %1, 2f                                  \n"
+		"        nop                                            \n"
+		"       .subsection 2                                   \n"
+		"2:     ll      %1, %2                                  \n"
+		"       bnez    %1, 2b                                  \n"
+		"        lui    %1, 0x8000                              \n"
+		"       b       1b                                      \n"
+		"        nop                                            \n"
+		"       .previous                                       \n"
+		"       .set    reorder                                 \n"
+		: "=m" (rw->lock), "=&r" (temp)
+		: "m" (rw->lock)
+		: "memory");
+
+	rw->write_cpu = cpu;
+	rmi_sync();
+	
+	return flags;
+
+}
+
+
+static inline void rmi_write_unlock_irq_restore(rmi_rwlock_t *rw, 
+						unsigned int flags)
+{
+	rmi_sync();
+
+	__asm__ __volatile__(
+		"       sw      $0, %0                                  \n"
+		: "=m" (rw->lock)
+		: "m" (rw->lock)
+		: "memory");
+	rw->write_cpu = -1;
+	rmi_local_irq_restore(flags);
+}
+
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmi_srio.h b/arch/mips/include/asm/rmi/rmi_srio.h
new file mode 100644
index 0000000..b73a80c
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmi_srio.h
@@ -0,0 +1,343 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+/*
+ * XLS RapidIO definitions
+ */
+
+#ifndef __XLS_SRIO_H__
+#define __XLS_SRIO_H__
+
+#include <asm/rmi/sim.h>
+
+static inline int is_xlsb0_srio(void) 
+{
+    unsigned int gpio_srio = 0;
+    uint32_t *gpio_mmio = (uint32_t *)
+                            (DEFAULT_PHOENIX_IO_BASE + PHOENIX_IO_GPIO_OFFSET);
+
+    if (xlr_board_atx_xi() || xlr_board_atx_xii()) {
+        gpio_srio = ((phoenix_read_reg(gpio_mmio,21) >> 26) & 0x3);
+        if (gpio_srio) {
+            return 1;
+        }
+        else {
+            return 0;
+        }
+    }
+    return 0;
+}
+
+#define RIO_OPS_LOCAL_CONFIG_READ(i) \
+        static int rmi_local_config_read_##i(struct rio_mport *mport, int pindex, u32 offset,int len, \
+                    u32 *data) \
+        { \
+            return rmi_local_config_read(rio_controller[i], pindex, offset, len, data);\
+        }
+
+#define RIO_OPS_LOCAL_CONFIG_WRITE(i) \
+static int rmi_local_config_write_##i(struct rio_mport *mport, int pindex, u32 offset,int len, u32 data)\
+{ \
+  return rmi_local_config_write(rio_controller[i], pindex, offset, len, data);\
+}
+
+#define RIO_OPS_CONFIG_READ(i) \
+static int rmi_rio_config_read_##i(struct rio_mport *mport, int index, u16 destid, u8 hopcount,\
+                                     u32 offset,int len, u32 *val) \
+{ \
+    return rmi_rio_config_read(rio_controller[i], index, destid, hopcount,\
+                        offset, len, val);\
+}
+
+#define RIO_OPS_CONFIG_WRITE(i) \
+static int rmi_rio_config_write_##i(struct rio_mport *mport, int index, u16 destid, u8 hopcount, \
+                                    u32 offset,int len, u32 val)\
+{\
+    return rmi_rio_config_write(rio_controller[i], index, destid, \
+                            hopcount, offset, len, val);\
+}
+
+#define RIO_OPS_DOORBELL_SEND(i)\
+static int rmi_rio_doorbell_send_##i(struct rio_mport *mport, int index, u16 destid, u16 data)\
+{\
+    return rmi_rio_doorbell_send(rio_controller[i], index, destid, data);\
+}
+
+void rmi_rio_setup(void);
+
+#define SRIO_IRQ(irq) (PIC_SRIO_LINK0_IRQ+irq)
+#define SRIO_CFG_BIT 21
+
+#define SRIO_X1_MODE 1
+#define SRIO_X4_MODE 2
+
+#define MAX_SRIO_PORTS 4
+#define MIN_SRIO_PORTS 1
+
+#define RMI_SRIO_MEM_SIZE (16<<20)
+
+/*BE space starts @ 0x14000000*/
+#define RMI_SRIO_MEM_0 ((256<<20) + (64<<20))
+#define RMI_SRIO_MEM_1 (RMI_SRIO_MEM_0 + RMI_SRIO_MEM_SIZE) 
+#define RMI_SRIO_MEM_2 (RMI_SRIO_MEM_1 + RMI_SRIO_MEM_SIZE) 
+#define RMI_SRIO_MEM_3 (RMI_SRIO_MEM_2 + RMI_SRIO_MEM_SIZE) 
+
+#define MAX_TQ_ENTRY 256
+#define MAX_SQ_ENTRY MAX_TQ_ENTRY 
+
+#define SIZE_OF_TQ_ENTRY 24
+#define SIZE_OF_SQ_ENTRY (16<<1)
+
+#define MAX_TRANSACTION_Q   2
+#define MAX_STATUS_Q        MAX_TRANSACTION_Q 
+
+#define MAX_MAILBOX_Q       4
+#define MAX_FREEL_Q         MAX_MAILBOX_Q 
+#define MAX_MAILBOX_ENTRY   128
+#define MAX_FREEL_ENTRY     MAX_MAILBOX_ENTRY   
+#define SIZE_OF_MQ_ENTRY    (16<<1)
+#define SIZE_OF_FQ_ENTRY    (8)
+
+/***************************************/
+/**Glue logic Register Goes here**/
+/***************************************/
+#define SRIO_CTRL 0x0
+#define SRIO_PHY_CTRL0  0x1
+#define SRIO_PHY_CTRL1  0x2
+#define SRIO_PHY0_CTRL  0x3
+#define SRIO_PHY1_CTRL  0x4
+#define SRIO_PHY2_CTRL  0x5
+#define SRIO_PHY3_CTRL  0x6
+#define SRIO_COHERENT_MEM_BASE 0x8
+#define SRIO_COHERENT_MEM_LIMIT 0x9
+#define SRIO_REG_L2ALLOC_MEM_BASE 0x10
+#define SRIO_REG_L2ALLOC_MEM_LIMIT 0x11
+#define SRIO_REG_READEX_MEM_BASE 0x12
+#define SRIO_REG_READEX_MEM_LIMIT 0x13
+#define SRIO_REG_PHY_CR_CMD 0x16
+#define SRIO_REG_PHY_CR_WR_DATA 0x17
+#define SRIO_REG_PHY_CR_RESP 0x18
+#define SRIO_REG_PHY_CR_RD_DATA 0x19
+/***************************************/
+/**Glue logic Register Ends here**/
+/***************************************/
+
+/***************************************/
+/**Extended Feature Register Goes here**/
+/***************************************/
+#define P0_EAS_CSR 0x158
+
+#define P0_CTRL_CSR 0x15c
+    /*BIT Fields*/
+    #define OUTPUT_PORT_EN  22
+    #define INPUT_PORT_EN   21
+    #define MULTI_EVENT_EN  12
+
+/***************************************/
+/**Extended Feature Register Ends here**/
+/***************************************/
+
+/***************************************/
+/*Jennic Controller registers goes here*/
+/***************************************/
+
+/*Transaction Types goes here*/
+#define TYPE_MAINTAIN_READ      13
+#define TYPE_MAINTAIN_WRITE     14
+#define TYPE_MESSAGE            16
+#define TYPE_DOORBELL           17
+
+/*Transaction Types ends here*/
+
+/*Implementation defined registers starts*/
+#define MASTER_INTR_STATUS_REG 0x10000
+    #define MISR_DF     (1<<3)
+    #define MISR_MQ3    (1<<6)
+    #define MISR_SQ     (1<<9)
+    #define MISR_GEN    (1<<11)
+#define MASTER_INTR_ENABLE_REG 0x10004
+    /*BIT Fields*/
+    #define MIER_DF     3
+    #define MIER_MQ3    6
+    #define MIER_SQ     9
+    #define MIER_GEN    11
+#define GENERAL_INTR_STATUS_REG 0x10010
+    /*BIT Fields*/
+    #define GISR_PERR   (1<<2)
+    #define GISR_DEC    (1<<5)
+    #define GISR_MQWE   (1<<7)
+    #define GISR_SQWE   (1<<8)
+#define GENERAL_INTR_ENABLE_REG 0x10014
+    /*BIT Fields*/
+    #define GIER_PERR   2
+    #define GIER_DEC    5    
+    #define GIER_MQWE   7
+    #define GIER_SQWE   8
+#define DMA_ERR_CAP_HIGH    0x10030
+#define DMA_ERR_CAP_LOW     0x10034
+#define DMA_ERR_CAP_INFO    0x10038
+/*Transaction Q Registers*/
+#define TRANSACTION_QUEUE_START(n)  (0x20000+0x20*(n))
+#define TRANSACTION_QUEUE_END(n)    (0x20004+0x20*(n))
+#define TRANSACTION_QUEUE_HEAD(n)   (0x20008+0x20*(n))
+#define TRANSACTION_QUEUE_TAIL(n)   (0x2000c+0x20*(n))
+    /*BIT Fields*/
+    #define TQ_LOCK 0
+    #define TQ_FULL 1
+#define TRANSACTION_QUEUE_UPTR(n)   (0x20010+0x20*(n))
+#define TRANSACTION_QUEUE_CTRL_1    (0x20200)
+    /*BIT Fields*/
+    #define CONFIGURE_TQUEUE(n)      (16+n)
+    #define ENABLE_QUEUE            11
+#define TRANSACTION_QUEUE_CTRL_2    (0x20204)
+#define TRANSACTION_QUEUE_STAT      (0x20208)
+#define TRANSACTION_QUEUE_IER       (0x2020c)
+    /*BIT Fields*/
+    #define IN_ENABLE(n)            (16+n)
+
+/*Maintenance Transactions Fields starts*/
+/*word-0*/
+#define MAINT_DEST_ID 16
+#define MAINT_DID_SIZE 7
+/*word-1*/
+#define MAINT_TRANS_SIZE 2
+#define MAINT_TRANS_DEFAULT_BITS 0
+/*word-2*/
+/*word-3*/
+#define MAINT_HOP_COUNT     22
+#define MAINT_REG_OFFSET    0
+/*word-4*/
+/*word-5*/
+/*word-6*/
+
+/*Maintenance Transactions Fields ends*/
+
+/*Message Transactions Fields starts*/
+/*word-0*/
+#define MSG_DEST_ID 16
+#define MSG_DID_SIZE 7
+/*word-1*/
+#define MSG_TRAN_SIZE       3
+#define MSG_MAILBOX_NUMBER  24
+#define MSG_SEG_SIZE        16
+/*Message Transactions Fields ends*/
+
+/*Door bell Transactions Fields starts*/
+/*word-0*/
+#define DBELL_DEST_ID 16
+#define DBELL_DID_SIZE 7
+/*word-1*/
+#define DBELL_INFO  16
+/*Door bell Transactions Fields ends*/
+
+/*Status Q Registers Starts*/
+#define STATUS_QUEUE_START(n)   (0x20400+0x20*(n))
+#define STATUS_QUEUE_END(n)     (0x20404+0x20*(n))
+#define STATUS_QUEUE_HEAD(n)    (0x20408+0x20*(n))
+    /*Bit Fields */
+    #define  SQ_EMPTY 1
+#define STATUS_QUEUE_TAIL(n)    (0x2040c+0x20*(n))
+#define STATUS_QUEUE_UPTR(n)    (0x20410+0x20*(n))
+#define STATUS_QUEUE_CTRL       (0x20600)
+    /*BIT Fields*/
+    #define CONFIGURE_SQUEUE(n)      (16+n)
+#define STATUS_QUEUE_STAT       (0x20608)
+#define STATUS_QUEUE_IER        (0x2060c)
+    /*BIT Fields*/
+    #define NNE_INTR(n)         (n)
+/*Status Q Registers Ends*/
+
+/*Free list Q Registers Starts*/
+#define FREEL_QUEUE_START(n)       (0x20a00+0x20*(n))
+#define FREEL_QUEUE_END(n)         (0x20a04+0x20*(n))
+#define FREEL_QUEUE_HEAD(n)        (0x20a08+0x20*(n))
+#define FREEL_QUEUE_TAIL(n)        (0x20a0c+0x20*(n))
+#define FREEL_QUEUE_UPTR(n)        (0x20a10+0x20*(n))
+    /*Bit fields*/
+    #define FQ_LOCK     0
+    #define FQ_FULL     1
+#define FREEL_BUF_SIZE(n)          (0x20a14+0x20*(n))
+    /*BIT fields*/
+    #define FL_BUF_SIZE            3
+#define FREEL_CONTROL_REG          (0x20c00)
+    /*Bit fields*/
+    #define CONFIGURE_FLQUEUE(n)    (n+16)
+#define FREEL_STATUS_REG           (0x20c08)
+#define FREEL_INT_EN               (0x20c0c)
+/*Free list Q Registers Ends*/
+
+/*Mailbox Q Registers Starts*/
+#define MAILBOX_QUEUE_START(n)  (0x21000+0x20*(n))
+#define MAILBOX_QUEUE_END(n)    (0x21004+0x20*(n))
+#define MAILBOX_QUEUE_HEAD(n)  (0x21008+0x20*(n))
+    /*Bit fields*/
+    #define MQ_EMPTY    1
+#define MAILBOX_QUEUE_TAIL(n)    (0x2100c+0x20*(n))
+#define MAILBOX_QUEUE_UPTR(n)    (0x21010+0x20*(n))
+
+#define MAILBOX_CONTROL_1   0x21800
+    /*BIT Fields*/
+    #define CONFIGURE_MQUEUE(n) (n)
+#define MAILBOX_CONTROL_2   0x21804
+#define MAILBOX_CONTROL_3   0x21808
+    /*BIT Fields*/
+    #define HIGH_MAILB_NO   (6)
+
+#define MAILBOX_STATUS_1    0x21820
+#define MAILBOX_STATUS_2    0x21824
+#define MAILBOX_STATUS_3    0x21828
+#define MAILBOX_STATUS_4    0x2182c
+
+#define MAILBOX_INT_EN_1    0x21830
+#define MAILBOX_INT_EN_2    0x21834
+#define MAILBOX_INT_EN_3    0x21838
+#define MAILBOX_INT_EN_4    0x2183c
+
+/*Mailbox Q Registers Ends*/
+
+/*Door Bell Registers Starts*/
+#define DOORBELL_INFO       0x20804
+    /*Bit fields*/
+    #define DFIFO_NUM       16 
+#define DOORBELL_INTR       0x2080c
+    /*Bit fields*/
+    #define DB_NNE          0
+#define DOORBELL_READ       0x20810
+    /*Bit fields*/
+    #define DB_SRCID        16
+/*Door Bell Registers Ends*/
+
+/*Implementation defined registers ends*/
+
+
+/***************************************/
+/*Jennic Controller registers ends here*/
+/***************************************/
+
+#endif				/* __XLS_SRIO_H__ */
diff --git a/arch/mips/include/asm/rmi/rmi_uaccess_fs.h b/arch/mips/include/asm/rmi/rmi_uaccess_fs.h
new file mode 100644
index 0000000..fe6133b
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmi_uaccess_fs.h
@@ -0,0 +1,60 @@
+#ifndef _ASM_RMI_RMI_UACCESS_H
+#define _ASM_RMI_RMI_UACCESS_H
+
+#define RMI_UACCESS_FS_UNUSED             0
+#define RMI_UACCESS_FS_MSGSND             1
+#define RMI_UACCESS_FS_MSGRCV             2
+#define RMI_UACCESS_FS_C0_COUNT           3
+#define RMI_UACCESS_FS_MEM_READ           4
+#define RMI_UACCESS_FS_MEM_WRITE          5
+#define RMI_UACCESS_FS_MSGINT             6
+#define RMI_UACCESS_FS_READ_COP           7
+#define RMI_UACCESS_FS_PERFCTR_START      8
+#define RMI_UACCESS_FS_PERFCTR_STOP       9
+#define RMI_UACCESS_FS_READ_CPUMASKS      10
+#define RMI_UACCESS_FS_READ_PROCID        11
+#define RMI_UACCESS_FS_PROMINFO           12
+#define RMI_UACCESS_FS_READ_TIMER         13
+#define RMI_UACCESS_FS_HARD_CPUID         14
+#define RMI_UACCESS_FS_ENDIANESS          15
+#define RMI_UACCESS_FS_REVERSE_ENDIANESS  16
+#define RMI_UACCESS_FS_USPACE_64BIT_INS   17
+#define RMI_UACCESS_FS_CPU_MAX_FREQ       18
+#if defined(CONFIG_RMI_XLP)
+#define RMI_UACCESS_FS_MEM_READ64         19
+#define RMI_UACCESS_FS_MEM_WRITE64        20
+#define RMI_UACCESS_FS_MEM_READ32         21
+#define RMI_UACCESS_FS_MEM_WRITE32        22
+#define RMI_UACCESS_FS_MSGSND3            23
+#endif /* CONFIG_RMI_XLP */
+#ifndef __ASSEMBLY__
+#if defined(CONFIG_RMI_XLP)
+extern void rmi_uaccess_fs_msgsnd(void);
+extern void rmi_uaccess_fs_msgrcv(void);
+extern void rmi_uaccess_fs_mem_read32(void);
+extern void rmi_uaccess_fs_mem_write32(void);
+extern void rmi_uaccess_fs_mem_read64(void);
+extern void rmi_uaccess_fs_mem_write64(void);
+extern void rmi_uaccess_fs_msgsnd3(void);
+#endif /* CONFIG_RMI_XLP */
+extern void xlr_fast_syscall_msgsnd(void);
+extern void xlr_fast_syscall_msgld(void);
+extern void xlr_fast_syscall_c0_count(void);
+extern void xlr_fast_syscall_processorId(void);
+extern void xlr_fast_syscall_iomem_read(void);
+extern void xlr_fast_syscall_iomem_write(void);
+extern void xlr_fast_syscall_msg_read(void);
+extern void xlr_fast_syscall_perf_ctr_start(void);
+extern void xlr_fast_syscall_perf_ctr_stop(void);
+extern void xlr_fast_syscall_get_cpumasks(void);
+extern void xlr_fast_syscall_prominfo(void);
+extern void rmi_uaccess_fs_read_timer(void);
+extern void rmi_uaccess_fs_read_timer(void);
+extern void rmi_uaccess_fs_hard_cpuid(void);
+extern void rmi_uaccess_fs_is_big_endian(void);
+extern void rmi_uaccess_fs_is_endian_reversed(void);
+extern void rmi_uaccess_fs_uspace_64bit_ins_enabled(void);
+extern void rmi_uaccess_fs_cpu_max_freq(void);
+#endif
+
+#endif /* _ASM_RMI_RMI_UACCESS_H */
diff --git a/arch/mips/include/asm/rmi/rmicrf/api.h b/arch/mips/include/asm/rmi/rmicrf/api.h
new file mode 100644
index 0000000..f25caea
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/api.h
@@ -0,0 +1,88 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef  _RMICRF_API_H
+#define  _RMICRF_API_H
+
+#include <rmicrf/types.h>
+
+/**
+* @file_name api.h
+* @author RMICORP 
+* @brief Externally available kernel API for the user 
+*/
+
+/*
+ * Chip Resource Manager API - provided by entry points to the RMI Kernel 
+ */
+rmi_physaddr_t rmi_mem_alloc(int type, uint64_t size, uint64_t align);
+int rmi_mem_reserve(rmi_physaddr_t paddr, uint64_t size);
+void rmi_mem_free(rmi_physaddr_t addr);
+
+/* Resource API */
+int rmi_resource_getref(const char *name, rmi_resource_t *res, struct rmi_resource *res_data);
+int rmi_resource_putref(rmi_resource_t res);
+int rmi_resource_allocate(const char *name, rmi_dom_t domain);
+int rmi_resource_free(const char *name);
+int rmi_resource_delete(const char *name);
+
+/* Domain API */
+rmi_dom_t rmi_domain_create(const char *name);
+int rmi_domain_start(rmi_dom_t domain);
+int rmi_domain_stop(rmi_dom_t domain);
+int rmi_domain_delete(rmi_dom_t domain);
+
+/* Communication and Synchronization API */
+int rmi_mutex_create(rmi_resource_t parent, const char *name, uint32_t flags);
+int rmi_fifo_create(rmi_resource_t parent, const char *name, 
+		    int entrysize, int nentries, uint32_t flags);
+int rmi_fmnq_create(rmi_resource_t parent, const char *name, int bucket, uint32_t flags);
+int rmi_memseg_create(rmi_resource_t parent, const char *name, rmi_addr_t vaddr, 
+		      uint64_t size, rmi_physaddr_t allocstart, uint64_t allocend, 
+		      uint32_t pagesize, uint32_t flags);
+int rmi_device_create(rmi_resource_t parent, const char *name, rmi_addr_t obj, uint32_t flags);
+int rmi_vresource_create(rmi_resource_t parent, const char *name, rmi_resource_t res);
+
+/* Properties */
+int rmi_set_property(rmi_resource_t res, const char *name, int type, 
+		     const void *val, int len);
+int rmi_get_property(rmi_resource_t res, const char *name, struct rmi_property *prop_data, 
+		     void *val, int len);
+int rmi_del_property(rmi_resource_t res, const char *name);
+int rmi_get_propnames(rmi_resource_t res, void *buf, int len);
+int rmi_print_buffer(const char *buf, int len);
+
+#endif
+
diff --git a/arch/mips/include/asm/rmi/rmicrf/bootinfo.h b/arch/mips/include/asm/rmi/rmicrf/bootinfo.h
new file mode 100644
index 0000000..4fce154
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/bootinfo.h
@@ -0,0 +1,121 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+
+#ifndef _RMICRF_BOOTINFO_H
+#define _RMICRF_BOOTINFO_H
+
+/* for the uintnn_t types */
+#include <rmicrf/types.h>
+#include <rmidev/platform.h>
+
+/*
+ *  This is from the bootloader API - which is not yet stable
+ */
+#define RMI_BOOT1_INFO_VERSION 0x0001
+#define PSB_ADDR_MAP_MAX 32
+
+/* The PHYS_MEMORY, some areas are RAM and some areas are ROM */
+#ifndef RMICRF_VXWORKS
+enum {
+	BOOT_MEM_RAM      =  1,
+	BOOT_MEM_ROM_DATA =  2,
+	BOOT_MEM_RESERVED =  3
+};
+#endif
+
+/* There could be a number of them */
+struct psb_addr_map {
+    int nr_map;
+    struct psb_addr_map_entry {
+        uint64_t addr;  /* start of memory segment */
+        uint64_t size;  /* size of memory segment */
+        long type;  /* type of memory segment */
+    } map[PSB_ADDR_MAP_MAX];
+};
+
+
+struct rmi_boot_info {
+	uint64_t boot_level;
+	uint64_t io_base;
+	uint64_t output_device;
+	uint64_t uart_print;
+	uint64_t led_output;
+	uint64_t init;
+	uint64_t exit;
+	uint64_t warm_reset;
+	uint64_t wakeup;
+	uint64_t rmi_cpu_online_map;
+	uint64_t master_reentry_sp;
+	uint64_t master_reentry_gp;
+	uint64_t master_reentry_fn;
+	uint64_t slave_reentry_fn;
+	uint64_t magic_dword;
+	uint64_t uart_putchar;  
+	uint64_t size;
+	uint64_t uart_getchar;
+	uint64_t nmi_handler;
+	uint64_t psb_version;
+	uint64_t mac_addr;
+	uint64_t cpu_frequency;
+	uint64_t board_version;
+	uint64_t malloc;
+	uint64_t free;
+	uint64_t global_shmem_addr;
+	uint64_t global_shmem_size;
+	uint64_t psb_os_cpu_map;
+	uint64_t userapp_cpu_map;
+	uint64_t wakeup_os;
+	uint64_t psb_mem_map;
+        uint64_t board_major_version;
+        uint64_t board_minor_version;
+        uint64_t board_manf_revision;
+        uint64_t board_serial_number;
+        uint64_t psb_physaddr_map;
+        uint64_t xlr_loaderip_config;
+	uint64_t bldr_envp;
+	uint64_t avail_mem_map;
+};
+
+enum rmi_bootarea_index {
+	RMI_BAREA_DOM_INDEX = 0, RMI_BAREA_ARG_INDEX = 1, 
+	RMI_BAREA_FDT_INDEX = 2, RMI_BAREA_FDT_SZ_INDEX = 3,
+	RMI_BAREA_OS_ENTRY_INDEX = 4, RMI_BAREA_PCPU_INDEX = 5,
+	RMI_BAREA_PCPU_SZ_INDEX = 6, RMI_BAREA_VERSION_INDEX  = 7,
+	RMI_BAREA_MAGIC_INDEX = 23, RMI_BAREA_BINFO_INDEX = 24 
+};
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmicrf/byteorder.h b/arch/mips/include/asm/rmi/rmicrf/byteorder.h
new file mode 100644
index 0000000..00c2c83
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/byteorder.h
@@ -0,0 +1,73 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMICRF_BYTEORDER_H
+#define _RMICRF_BYTEORDER_H
+
+#define swap16(x)   ( ((x & 0x00FF) << 8) | \
+                      ((x & 0xFF00) >> 8) )
+#define swap32(x)   ( ((x & 0x000000FF) << 24) | \
+                      ((x & 0x0000FF00) <<  8) | \
+                      ((x & 0x00FF0000) >>  8) | \
+                      ((x & 0xFF000000) >> 24)   \
+                    )
+#define swap64(x)   ( (__uint64_t)((x & 0x000000FF) << 56) | \
+                      (__uint64_t)((x & 0x0000FF00) << 40) | \
+                      (__uint64_t)((x & 0x00FF0000) << 24) | \
+                      (__uint64_t)((x & 0xFF000000) <<  8) | \
+                      ((x & (__uint64_t)0xFF << 32) >>  8) | \
+                      ((x & (__uint64_t)0xFF << 40) >> 24) | \
+                      ((x & (__uint64_t)0xFF << 48) >> 40) | \
+                      ((x & (__uint64_t)0xFF << 56) >> 56)   \
+                    )
+
+#if defined (__MIPSEB__)
+#define cpu_to_be16(x)		(x)
+#define cpu_to_be32(x) 		(x)
+#define cpu_to_be64(x) 		(x)
+#define cpu_to_le16(x)          swap16((x))
+#define cpu_to_le32(x)          swap32((x))
+#define cpu_to_le64(x)          swap64((x))
+#define be16_to_cpu(x)		(x)
+#define be32_to_cpu(x)		(x)
+#define be64_to_cpu(x)		(x)
+#define le16_to_cpu(x)          swap16((x))
+#define le32_to_cpu(x)          swap32((x))
+#define le64_to_cpu(x)          swap64((x))
+#elif defined (__MIPSEL__)
+#  error "Well - you need to write the swapping routines"
+#endif
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmicrf/clpool.h b/arch/mips/include/asm/rmi/rmicrf/clpool.h
new file mode 100644
index 0000000..66bc294
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/clpool.h
@@ -0,0 +1,81 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef  _RMICRF_CLPOOL_H
+#define  _RMICRF_CLPOOL_H
+
+#include <rmicrf/crflib.h>
+
+#define RMI_MAX_CL_POOLS_PER_DOMAIN     8
+#define SLAB_ALIGN                      32      
+#define RMI_CL_POOL_NAMELEN             12
+
+/*
+* @brief  Cluster pool related structures and library calls
+* As the below structure is shared, makesure it is aligned properly
+*/
+
+struct rmi_cluster {
+	char name[RMI_MAX_NAMELEN];
+	uint32_t poolid; /* index to the internal table */
+	uint32_t flags;		/* flags */
+	uint64_t res;  	/* resource pointer */
+	uint64_t   paddr; 	/* paddr of this pool */
+	uint64_t   start;       	/**< Start address of first available item. */
+	uint32_t available; 	/* available count*/
+	uint32_t nextavail; 	/* next available */
+	uint32_t unit_size;  /* unit size of this cluster  */
+	uint32_t num_units;       /* Total units */
+	uint32_t datasize; /* data size of this pool */
+	uint32_t size;		/* tot size (datasize + control info) */
+	struct rmi_mutex clusterlock;
+};
+
+extern int rmi_clpool_create(const char *name, uint32_t num_units, 
+		uint32_t unit_size , int flags);
+extern int rmi_clpool_delete(const char *name);
+
+extern struct rmi_cluster *rmi_clpool_getref(int dom, const char *name);
+extern int rmi_clpool_putref(struct rmi_cluster *cluster);
+
+extern void *rmi_cluster_alloc(struct rmi_cluster *cluster, int flags);
+extern void rmi_cluster_free(struct rmi_cluster *cluster, void *obj);
+
+/* Pool specifications */
+#define RMI_PKT_POOL_NAME "pktpool"
+#define RMI_PKT_POOL_UNIT_SIZE 1600
+
+#endif
+
diff --git a/arch/mips/include/asm/rmi/rmicrf/config.h b/arch/mips/include/asm/rmi/rmicrf/config.h
new file mode 100644
index 0000000..f6c2118
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/config.h
@@ -0,0 +1,157 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMICRF_CONFIG_H
+#define _RMICRF_CONFIG_H
+
+/* Currently chosen so that we can have the hash table size of 1024 */
+#ifndef RMI_MAX_RESOURCES
+#define RMI_MAX_RESOURCES 650
+#endif
+
+#ifndef RMI_RESOURCE_HASH_BITS
+#define RMI_RESOURCE_HASH_BITS 10
+#endif
+
+#ifndef RMI_MAX_NAMELEN
+#define RMI_MAX_NAMELEN 32
+#endif
+
+#ifndef RMI_MAX_DOMAINS
+#define RMI_MAX_DOMAINS 34
+#endif
+
+#ifndef RMI_MAX_CPUS
+#define RMI_MAX_CPUS 32
+#endif
+
+#ifndef RMI_MAX_CORES
+#define RMI_MAX_CORES 8
+#endif
+
+#ifndef RMI_CPUS_PER_CORE
+#define RMI_CPUS_PER_CORE 4
+#endif
+
+#ifndef RMI_TLBS_PER_CORE
+#define RMI_TLBS_PER_CORE 64
+#endif
+
+#ifndef RMI_MSGRNG_MAX_RETRIES
+#define RMI_MSGRNG_MAX_RETRIES 10000
+#endif
+
+#ifndef RMI_MSGRNG_MAX_STATIONS
+#define RMI_MSGRNG_MAX_STATIONS 128
+#endif
+
+#ifndef RMI_MSGRNG_CORE_STATIONS
+#define RMI_MSGRNG_CORE_STATIONS 8
+#endif
+
+#ifndef RMI_MSGRNG_GMAC_STATIONS
+#define RMI_MSGRNG_GMAC_STATIONS 8
+#endif
+
+#ifndef RMI_MSGRNG_XGMAC_STATIONS
+#define RMI_MSGRNG_XGMAC_STATIONS 18
+#endif
+
+#ifndef RMI_MAX_GMACS
+#define RMI_MAX_GMACS 8
+#endif
+
+#ifndef RMI_MAX_PIC_TIMERS
+#define RMI_MAX_PIC_TIMERS 8
+#endif
+
+#define RMI_DEF_L2C_LINE_SZ 32
+#define RMI_DEF_L2C_NUM_WAYS 8
+#define RMI_DEF_PIC_NUM_IRTS 32
+
+#ifndef RMI_GMAC_PORTS_PER_CTRL
+#define RMI_GMAC_PORTS_PER_CTRL    4
+#endif
+
+#ifndef RMI_MAX_XGS
+#define RMI_MAX_XGS 2
+#endif 
+
+/* maximum segment per domain */
+#define RMI_DOMAIN_MAXMEMSEGS   	16
+
+/* standard size for the EBASE page */
+#define XLR_EBASE_SIZE                  (4*1024)
+
+/* Per domain memory - boot info, FDT, args*/
+#define RMI_DOMMEM_SIZE			(12*1024)
+
+/* Size of the argument passing area */
+#define RMI_PCPU_MAXARG			512
+
+/* As we are using domain.resname, */
+#define RMI_MAX_DOMNAME_LEN ( RMI_MAX_NAMELEN - 20 )
+
+#define RMI_RMIK_MAGIC 0xfee1900dULL
+
+/* rmios ,linux executables */
+#define RMI_MAX_EXEC_FILE_SIZE (20 * 1024 * 1024)
+
+/* pde, msgconfig etc */
+#define RMI_MAX_CFG_FILE_SIZE   (4 * 1024 * 1024) 
+
+/* Pde will be passed as regs info */
+#define RMI_MAX_PDE_REGS_INFO 350
+
+/* default fifo sizes */
+#define RMI_EVENTQ_FIFO_SIZE 1024
+#define RMI_VUART_FIFO_SZ 8192
+#define RMI_LOG_FIFO_SZ 4096
+
+/* ipi numberes used by crf */
+#define RMI_MANAGEMENT_IPI              45
+#define RMI_EVENTQ_IPI       			46
+
+/* scratch register usage , 0 is reserved for boot info
+   Should not change.  as it is used by bootloader also */
+#define RMI_BOOT_INFO_SCRATCH			0
+#define RMI_PERF0_SCRATCH				4
+#define RMI_PERF1_SCRATCH				5
+
+#define	RMI_IRQ_CNT_CMP					7
+
+#define RMI_FREE_RUNNING_PIC_TIMERID			7
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmicrf/crflib.h b/arch/mips/include/asm/rmi/rmicrf/crflib.h
new file mode 100644
index 0000000..262a53e
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/crflib.h
@@ -0,0 +1,217 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef  _RMICRF_CRFLIB_H
+#define  _RMICRF_CRFLIB_H
+
+#include <rmicrf/api.h>
+#include <rmicrf/errcode.h>
+#include <rmidev/atomic.h>
+
+/*
+ * FIFO operations 
+ */
+uint32_t rmi_fifo_send(struct rmi_fifo *q, const char *buf, int num_entries);
+uint32_t rmi_fifo_recv(struct rmi_fifo *q, char *buf, int num_entries);
+uint32_t rmi_fifo_sendmsg(struct rmi_fifo *q, int type, int len, const void *value);
+uint32_t rmi_fifo_recvmsg(struct rmi_fifo *q, int *type, int *len, void *value);
+
+/*
+ * Message queue operations
+ */
+uint32_t rmi_fmnq_send(struct rmi_fmnq *q, int code, int size, const uint64_t *msg);
+uint32_t rmi_fmnq_recv(struct rmi_fmnq *q, int *code, int *size, int *stnid, uint64_t *msg);
+
+/* 
+ * Mutex operations
+ */
+void rmi_mutex_init(struct rmi_mutex *m, uint32_t flags);
+void rmi_mutex_lock(struct rmi_mutex *m);
+void rmi_mutex_unlock(struct rmi_mutex *m);
+
+/* 
+ * Event queue
+ */
+int rmi_send_event(rmi_dom_t domain, int type, int len, const uint64_t *msg);
+int rmi_get_event(int *type, int *len, uint64_t *msg);
+int rmi_get_event_recipients(char *rname, uint64_t *dom_map);
+
+/*
+ * Domain functions
+ */
+extern struct rmi_domain *rmi_this_domain;
+struct rmi_eventq *rmi_get_eventq(rmi_dom_t domain);
+
+/*
+ * Memory functions
+ */
+rmi_physaddr_t rmi_mseg_physaddr_get(const char *msegname);
+
+/*
+* tlb/cache functions
+*/
+extern int rmi_add_wired_tlb_entry(uint64_t entryhi, uint64_t physlo0, 
+		uint64_t physlo1, uint32_t pagesz, uint32_t attr);
+extern void rmi_delete_wired_tlb_entry(int wired_idx);
+extern void rmi_flush_icache_all(void);
+
+
+/*
+ * Convenience funcitons 
+ */
+static inline int rmi_resource_lookup(const char *name, struct rmi_resource *res_data)
+{
+	return rmi_resource_getref(name, NULL, res_data);
+}
+
+/*
+ * Property access convenience functions
+ */
+static inline int rmi_get_int_property(rmi_resource_t res, const char *name, int *value)
+{
+	int rv = rmi_get_property(res, name, NULL, value, sizeof(*value));
+
+	if (rv < 0)
+		return rv;
+
+	if (rv != sizeof(*value))
+		return -RMI_EINVAL;
+	
+	return rv;
+}
+	
+static inline int rmi_get_u32_property(rmi_resource_t res, const char *name, uint32_t *value)
+{
+	int rv = rmi_get_property(res, name, NULL, value, sizeof(*value));
+
+	if (rv < 0)
+		return rv;
+
+	if (rv != sizeof(*value))
+		return -RMI_EINVAL;
+	
+	return rv;
+}	
+
+static inline int rmi_get_addr_property(rmi_resource_t res, const char *name, rmi_addr_t *value)
+{
+	int rv = rmi_get_property(res, name, NULL, value, sizeof(*value));
+
+	if (rv < 0)
+		return rv;
+
+	if (rv != sizeof(*value))
+		return -RMI_EINVAL;
+	
+	return rv;
+}	
+
+static inline int rmi_get_addr32_property(rmi_resource_t res, const char *name, uint32_t *value)
+{
+	int rv = rmi_get_property(res, name, NULL, value, sizeof(*value));
+
+	if (rv < 0)
+		return rv;
+
+	if (rv != sizeof(*value))
+		return -RMI_EINVAL;
+	
+	return rv;
+}	
+
+static inline int rmi_get_string_property(rmi_resource_t res, const char *name, char *value, int len)
+{
+	return rmi_get_property(res, name, NULL, value, len);
+}	
+
+/*
+ * Set property helper functions 
+ */
+static inline int rmi_set_int_property(rmi_resource_t res, const char *name, int value)
+{
+	return rmi_set_property(res, name, RMI_PROPERTY_INT, &value, sizeof(value));
+}
+
+static inline int rmi_set_u32_property(rmi_resource_t res, const char *name, uint32_t value)
+{
+	return rmi_set_property(res, name, RMI_PROPERTY_UINT, &value, sizeof(value));
+}
+
+static inline int rmi_set_addr_property(rmi_resource_t res, const char *name, rmi_addr_t value)
+{
+	return rmi_set_property(res, name, RMI_PROPERTY_ADDR, &value, sizeof(value));
+}
+
+static inline int rmi_set_addr32_property(rmi_resource_t res, const char *name, uint32_t value)
+{
+	return rmi_set_property(res, name, RMI_PROPERTY_ADDR, &value, sizeof(value));
+}
+
+static inline int rmi_set_string_property(rmi_resource_t res, const char *name, const char *str)
+{
+	extern size_t strlen(const char *);
+	return rmi_set_property(res, name, RMI_PROPERTY_STRING, str, strlen(str)+1);
+}
+
+static inline rmi_physaddr_t rmi_memseg_physaddr_get(const char *msegname)
+{
+    struct rmi_resource res;
+    struct rmi_memseg *mseg;
+    if(rmi_resource_lookup(msegname, &res) < 0)
+        return -1;
+	mseg = rmi_addr_to_ptr(res.obj);
+    return mseg->allocstart;
+}
+
+int rmi_get_domain(rmi_dom_t dom, struct rmi_domain *domain);
+int rmi_get_logbuf(char *buf, uint32_t len);
+int rmi_clear_logbuf(void);
+
+#define rmicrf_early_print(fmt, args...) ({             \
+		char early_pbuf[100];                         \
+		int early_len;									\
+		early_len = snprintf(early_pbuf, sizeof(early_pbuf), fmt, ## args);     \
+		rmi_print_buffer(early_pbuf, early_len); 		\
+})
+
+/*
+* @brief  Port types across all domains.
+*/
+
+enum rmi_port_types { RMI_GMAC0 = 0, RMI_GMAC1, RMI_XGS0, RMI_XGS1 } ;
+
+
+#endif
+
diff --git a/arch/mips/include/asm/rmi/rmicrf/errcode.h b/arch/mips/include/asm/rmi/rmicrf/errcode.h
new file mode 100644
index 0000000..54d0da6
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/errcode.h
@@ -0,0 +1,57 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMICRF_ERRCODE_H
+#define _RMICRF_ERRCODE_H
+
+/* 
+ * Be POSIX compliant where possible
+ */
+#define RMI_EPERM	1  /* Operation not permitted */
+#define RMI_ENOENT	2  /* Object look up failed */
+#define RMI_EIO		5  /* IO error */
+#define RMI_ENXIO	6  /* IO error, device not configured */
+#define RMI_ENOEXEC	8
+#define RMI_ENOMEM   	12  /* Out of memory */
+#define RMI_EACCES   	13  /* Access Denied, already allocated */
+#define RMI_EBUSY       16  /* Device or resource busy */
+#define RMI_EEXIST   	17  /* Does not exist */
+#define RMI_EINVAL   	22  /* Invalid argument */
+#define RMI_ETIMEDOUT	60  /* Operation timed out */
+#define RMI_EDRIVER   	128 /* IOCTL failed */
+
+void rmi_log_error(const char *fmt, ...);
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmicrf/eventdefs.h b/arch/mips/include/asm/rmi/rmicrf/eventdefs.h
new file mode 100644
index 0000000..6e6c63d
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/eventdefs.h
@@ -0,0 +1,151 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef  _RMICRF_EVENTDEFS_H
+#define  _RMICRF_EVENTDEFS_H
+
+#include <rmicrf/crflib.h>
+
+#define RMI_ETH_DATA_LEN    1500
+/**
+*
+* @brief  Event queue type information enum values
+*/
+enum rmi_event_qtype_t 			{ RMI_EVENT_DOM_CTRL = 0x1, 
+					  RMI_EVENT_VETH_INFO, 
+					  RMI_EVENT_VNET,
+					  RMI_EVENT_CL_POOL_INFO,
+					  RMI_EVENT_PKT_FW
+					  }; 
+
+/* 
+ * Eventq can be on FMN or fifo, As FMN each message is a uint64_t 
+ * the below data structures should be aligned to 64.
+ */
+enum rmi_event_dom_ctrl_msg_type_t 	{ RMI_EVENT_MSG_STOP_DOM = 0x1 };
+
+/*
+ * Message type for virtual gmac/xgmac/spi4 interface/arp info
+ */
+enum rmi_event_veth_msg_type_t		{ RMI_EVENT_MSG_IFC_UP = 0x1 , 
+					RMI_EVENT_MSG_IFC_DOWN, 
+					RMI_EVENT_MSG_IFC_ARP_ADD, 
+					RMI_EVENT_MSG_IFC_ARP_DEL
+					};
+/*
+ * Message types for virtual networking between domains
+ */
+enum rmi_event_vnet_msg_type_t		{ RMI_EVENT_VNET_PKT = 0x1 };
+
+/*
+ * Cluster pool error message types
+ */
+enum rmi_event_cl_pool_msg_type_t 	{ RMI_EVENT_MSG_CL_POOL_NOT_FOUND = 0x01, 
+					RMI_EVENT_MSG_CL_POOL_EMPTY
+					};
+/*
+ * Event message for dom_ctrl/veth/vnet and cl pool types.
+ */
+struct rmi_event_simple_msg {
+	uint32_t msgtype; /* any of dom_ctrl, veth, vnet or clpool type  */
+	uint32_t domid;   /* sender domainid */
+	uint64_t arg;     /* should be from unmapped/shared space */
+};
+
+
+/**
+*
+* @Used for CPU to CPU packet forward
+*/
+struct rmi_event_packet_fw_msg {
+	struct {
+		uint64_t	ptype 	: 3, /* type of rmi_port_type */
+				fbstid	: 8; /* Freeback station id */
+	} fwinfo;
+
+	union {
+		/* This is inline with the rx descriptor format coming out from the 
+		 *  network accelerator 
+		 * The physaddr(32 bit aligned, upper 5 bits are zero ) should be OR-ed with the fwport
+		 */
+		uint64_t 	rx_desc;
+#if defined (__MIPSEB__)
+		struct {
+			uint64_t	dummy    : 10,
+					length	 : 14, /* length of the packet */
+					physaddr : 35, /* physical address of the packet */
+					fwport	 : 5; /* forward port */
+		} fields;
+#else
+		struct {
+			uint64_t 	fwport	 : 5, /* forward port */
+					physaddr : 35, /* physical address of the packet */ 
+					length	 : 14, /* length of the packet */
+					dummy	 : 10;
+		} fields;
+#endif
+	} pktinfo;
+};
+
+/* formt should be resname,count,ipaddr,macaddr,ipaddr,macaddr...*/
+struct rmi_event_eth_ifc_msg {
+	uint32_t ptype; /* rmi_port_types */
+	uint32_t port; /* port number */
+	uint32_t count; /*  number of data units */
+	uint32_t pad1;
+	uint64_t data[1]; /* Count number of data units follows */
+};
+
+/*
+ * Used for vnet application
+ */
+struct rmi_event_vnet_msg {
+	uint64_t datalen;      /* packet datalen */
+	uint8_t  data[RMI_ETH_DATA_LEN]; /* packet data */
+};
+
+
+static inline int rmi_send_pool_event(int dom, int msgtype, uint64_t name_ptr)
+{
+	struct rmi_event_simple_msg clmsg;
+	clmsg.msgtype = msgtype;
+	clmsg.domid = rmi_this_domain->id; /* sending domain */
+	clmsg.arg = name_ptr;
+	return rmi_send_event(dom, RMI_EVENT_CL_POOL_INFO, sizeof(clmsg), 
+			rmi_addr_to_ptr(&clmsg));
+}
+
+#endif
+
diff --git a/arch/mips/include/asm/rmi/rmicrf/frame.h b/arch/mips/include/asm/rmi/rmicrf/frame.h
new file mode 100644
index 0000000..41dde3d
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/frame.h
@@ -0,0 +1,90 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMICRF_FRAME_H
+#define _RMICRF_FRAME_H
+
+/* TODO change from xlr to RMI */
+#define XLR_TF_ZERO		0
+#define XLR_TF_AT		1
+#define XLR_TF_V0		2
+#define XLR_TF_V1		3
+#define XLR_TF_A0		4
+#define XLR_TF_A1		5
+#define XLR_TF_A2		6
+#define XLR_TF_A3		7
+#define XLR_TF_T0		8
+#define XLR_TF_T1		9
+#define XLR_TF_T2		10
+#define XLR_TF_T3		11
+#define XLR_TF_T4		12
+#define XLR_TF_T5		13
+#define XLR_TF_T6		14
+#define XLR_TF_T7		15
+#define XLR_TF_S0		16
+#define XLR_TF_S1		17
+#define XLR_TF_S2		18
+#define XLR_TF_S3		19
+#define XLR_TF_S4		20
+#define XLR_TF_S5		21
+#define XLR_TF_S6		22
+#define XLR_TF_S7		23
+#define XLR_TF_T8		24
+#define XLR_TF_T9		25
+#define XLR_TF_K0		26
+#define XLR_TF_K1		27
+#define XLR_TF_GP		28
+#define XLR_TF_SP		29
+#define XLR_TF_FP		30
+#define XLR_TF_RA		31
+#define XLR_TF_C0_STATUS	32
+#define XLR_TF_C0_CAUSE		33
+#define XLR_TF_C0_EPC		34
+#define XLR_TF_C0_BADVADDR	35
+
+
+/* FIXME this is O64  - simple callframe */
+#define XLR_CALLFRAME_SZ   (8 * (4 + 2))
+#define XLR_CALLFRAME_A0    0
+#define XLR_CALLFRAME_A1    (8 * 1)
+#define XLR_CALLFRAME_A2    (8 * 2)
+#define XLR_CALLFRAME_A3    (8 * 3)
+#define XLR_CALLFRAME_SP    (8 * 4)
+#define XLR_CALLFRAME_RA    (8 * 5)
+
+/* COP0, COP2, KX */
+#define XLR_DEF_CRF_STATUS 0x50000080 
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmicrf/linux.h b/arch/mips/include/asm/rmi/rmicrf/linux.h
new file mode 100644
index 0000000..86d5061
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/linux.h
@@ -0,0 +1,142 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMICRF_IOCTL_H
+#define _RMICRF_IOCTL_H
+
+#include <rmicrf/types.h>
+#include <rmicrf/pcpu.h>
+#include <rmicrf/oscalls.h>
+
+#define RMICRF_IOC 'r'
+
+#define RMICRF_IOC_MEM_ALLOC  	     _IOWR(RMICRF_IOC, RMI_MEM_ALLOC, struct rmi_mem_alloc_args)
+#define RMICRF_IOC_MEM_RESERVE 	     _IOWR(RMICRF_IOC, RMI_MEM_RESERVE, struct rmi_mem_reserve_args)
+#define RMICRF_IOC_MEM_FREE   	     _IOWR(RMICRF_IOC, RMI_MEM_FREE, struct rmi_mem_free_args)
+
+#define RMICRF_IOC_RESOURCE_LOOKUP     	_IOWR(RMICRF_IOC, RMI_RESOURCE_LOOKUP, struct rmi_resource_lookup_args)
+#define RMICRF_IOC_RESOURCE_GETREF   		_IOWR(RMICRF_IOC, RMI_RESOURCE_GETREF, struct rmi_resource_getref_args)
+#define RMICRF_IOC_RESOURCE_ALLOCATE   	_IOWR(RMICRF_IOC, RMI_RESOURCE_ALLOCATE, struct rmi_resource_allocate_args)
+#define RMICRF_IOC_RESOURCE_FREE       	_IOWR(RMICRF_IOC, RMI_RESOURCE_FREE, struct rmi_resource_free_args)
+#define RMICRF_IOC_RESOURCE_PUTREF 		_IOWR(RMICRF_IOC, RMI_RESOURCE_PUTREF, struct rmi_resource_putref_args)
+#define RMICRF_IOC_RESOURCE_DELETE     _IOWR(RMICRF_IOC, RMI_RESOURCE_DELETE, struct rmi_resource_delete_args)
+
+#define RMICRF_IOC_DOMAIN_CREATE       _IOWR(RMICRF_IOC, RMI_DOMAIN_CREATE, struct rmi_domain_create_args)
+#define RMICRF_IOC_DOMAIN_START        _IOWR(RMICRF_IOC, RMI_DOMAIN_START, struct rmi_domain_start_args)
+#define RMICRF_IOC_DOMAIN_STOP        _IOWR(RMICRF_IOC, RMI_DOMAIN_STOP, struct rmi_domain_stop_args)
+#define RMICRF_IOC_DOMAIN_DELETE        _IOWR(RMICRF_IOC, RMI_DOMAIN_DELETE, struct rmi_domain_delete_args)
+
+#define RMICRF_IOC_MUTEX_CREATE        _IOWR(RMICRF_IOC, RMI_MUTEX_CREATE, struct rmi_mutex_create_args)
+#define RMICRF_IOC_FIFO_CREATE         _IOWR(RMICRF_IOC, RMI_FIFO_CREATE, struct rmi_fifo_create_args)
+#define RMICRF_IOC_FMNQ_CREATE   _IOWR(RMICRF_IOC, RMI_FMNQ_CREATE, struct rmi_fmnq_create_args)
+#define RMICRF_IOC_MEMSEG_CREATE       _IOWR(RMICRF_IOC, RMI_MEMSEG_CREATE, struct rmi_memseg_create_args)
+#define RMICRF_IOC_DEVICE_CREATE       _IOWR(RMICRF_IOC, RMI_DEVICE_CREATE, struct rmi_device_create_args)
+#define RMICRF_IOC_VRESOURCE_CREATE    	_IOWR(RMICRF_IOC, RMI_VRESOURCE_CREATE, struct rmi_vresource_create_args)
+
+#define RMICRF_IOC_DEL_PROPERTY        _IOWR(RMICRF_IOC, RMI_DEL_PROPERTY, struct rmi_del_property_args)
+
+/* This have variable size argument */
+#define RMICRF_IOC_GET_PROPERTY(rqlen) _IOC(_IOC_READ|_IOC_WRITE, RMICRF_IOC, RMI_GET_PROPERTY, rqlen)
+#define RMICRF_IOC_SET_PROPERTY(rqlen) _IOC(_IOC_READ|_IOC_WRITE, RMICRF_IOC, RMI_SET_PROPERTY, rqlen)
+#define RMICRF_IOC_GET_PROPNAMES(rqlen) _IOC(_IOC_READ|_IOC_WRITE, RMICRF_IOC, RMI_GET_PROPNAMES, rqlen)
+#define RMICRF_IOC_PRINT_BUFFER(rqlen) _IOC(_IOC_READ|_IOC_WRITE, RMICRF_IOC, RMI_PRINT_BUFFER, rqlen)
+
+/*
+ * Additional functions provided by the driver
+ */
+#define RMI_KERNEL_DEV_NAME "rmicrf"
+
+struct rmi_get_domain_args {
+	uint32_t rv;
+	rmi_dom_t dom;
+	struct rmi_domain copy;
+};
+
+#define RMICRF_IOC_GET_DOMAIN        _IOWR(RMICRF_IOC, 0x80, struct rmi_get_domain_args)
+int rmi_get_domain (rmi_dom_t dom, struct rmi_domain *copy);
+
+struct rmi_logbuf_args {
+	uint32_t rv;
+	uint32_t len;
+	rmi_addr_t buf;
+};
+
+/* Logbuf related */
+#define RMICRF_IOC_GET_LOGBUF          _IOWR(RMICRF_IOC, 0x81, struct rmi_logbuf_args)
+#define RMICRF_IOC_CLR_LOGBUF          _IOWR(RMICRF_IOC, 0x82, struct rmi_logbuf_args)
+int rmi_get_logbuf(char *buf, uint32_t len);
+int rmi_clear_logbuf(void);
+
+#ifdef __KERNEL__
+/*
+ * Linux kernel - globals and support functions 
+ */
+
+extern void (*rmi_rmik_entry)(int callnum);
+extern uint64_t *rmi_kernel_args;
+int rmi_kernel_call(int callnum, int size, void __user *inargs);
+
+static inline void rmi_enter_kernel(int callnum)
+{
+        unsigned long flags;
+
+        local_irq_save(flags);
+        (*rmi_rmik_entry)(callnum);
+        local_irq_restore(flags);
+}
+
+static inline void *rmi_get_pcpumem(int cpuid)
+{
+    extern struct rmi_pcpu_info *rmi_pcpu_info;
+    extern int rmi_pcpu_info_size;
+    struct rmi_pcpu_info *tmp;
+    tmp = rmi_addr_to_ptr(((rmi_ptr_to_addr(rmi_pcpu_info)) + (rmi_pcpu_info_size * cpuid)));
+    return rmi_addr_to_ptr(tmp->data_area);
+}
+
+static inline void *rmi_get_pcpuinfo(int cpuid)
+{
+    extern struct rmi_pcpu_info *rmi_pcpu_info;
+    extern int rmi_pcpu_info_size;
+    struct rmi_pcpu_info *tmp;
+    tmp = rmi_addr_to_ptr(((rmi_ptr_to_addr(rmi_pcpu_info)) + (rmi_pcpu_info_size * cpuid)));
+    return tmp;
+}
+
+
+
+#endif
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmicrf/oscalls.h b/arch/mips/include/asm/rmi/rmicrf/oscalls.h
new file mode 100644
index 0000000..6415e58
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/oscalls.h
@@ -0,0 +1,208 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMICRF_OSCALLS_H
+#define _RMICRF_OSCALLS_H
+
+struct rmi_mem_alloc_args {
+		rmi_physaddr_t rv;
+		uint32_t type;
+		uint64_t size;
+		uint64_t align;
+};
+
+struct rmi_mem_reserve_args {
+		uint32_t rv;
+		rmi_physaddr_t paddr;
+		uint64_t size;
+};
+
+struct rmi_mem_free_args {
+		rmi_physaddr_t addr;
+};
+
+struct rmi_resource_getref_args {
+		uint32_t rv;
+		char name[RMI_MAX_NAMELEN];
+		rmi_addr_t res;
+		struct rmi_resource res_data;
+};
+
+struct rmi_resource_putref_args {
+		uint32_t rv;
+		rmi_addr_t res;
+};
+
+struct rmi_resource_allocate_args {
+		uint32_t rv;
+		char name[RMI_MAX_NAMELEN];
+		rmi_dom_t domain;
+};
+
+struct rmi_resource_free_args {
+		uint32_t rv;
+		char name[RMI_MAX_NAMELEN];
+};
+
+struct rmi_resource_delete_args {
+		uint32_t rv;
+		char name[RMI_MAX_NAMELEN];
+};
+
+struct rmi_domain_create_args {
+		rmi_dom_t rv;
+		char name[RMI_MAX_NAMELEN];
+};
+
+struct rmi_domain_start_args {
+		uint32_t rv;
+		rmi_dom_t domain;
+};
+
+struct rmi_domain_stop_args {
+		uint32_t rv;
+		rmi_dom_t domain;
+};
+
+struct rmi_domain_delete_args {
+		uint32_t rv;
+		rmi_dom_t domain;
+};
+
+struct rmi_mutex_create_args {
+		uint32_t rv;
+		rmi_addr_t parent;
+		char name[RMI_MAX_NAMELEN];
+		uint32_t flags;
+};
+
+struct rmi_fifo_create_args {
+		uint32_t rv;
+		rmi_addr_t parent;
+		char name[RMI_MAX_NAMELEN];
+		uint32_t entrysize;
+		uint32_t nentries;
+		uint32_t flags;
+};
+
+struct rmi_fmnq_create_args {
+		uint32_t rv;
+		rmi_addr_t parent;
+		char name[RMI_MAX_NAMELEN];
+		uint32_t bucket;
+		uint32_t flags;
+};
+
+struct rmi_memseg_create_args {
+		uint32_t rv;
+		rmi_addr_t parent;
+		char name[RMI_MAX_NAMELEN];
+		rmi_addr_t vaddr;
+		uint64_t size;
+		rmi_physaddr_t allocstart;
+		rmi_physaddr_t allocend;
+		uint32_t pagesize;
+		uint32_t flags;
+};
+
+struct rmi_device_create_args {
+		uint32_t rv;
+		rmi_addr_t parent;
+		char name[RMI_MAX_NAMELEN];
+		rmi_addr_t obj;
+		uint32_t flags;
+};
+
+struct rmi_vresource_create_args {
+		uint32_t rv;
+		rmi_addr_t parent;
+		char name[RMI_MAX_NAMELEN];
+		rmi_addr_t res;
+};
+
+struct rmi_set_property_args {
+		uint32_t rv;
+		rmi_addr_t res;
+		char name[RMI_MAX_NAMELEN];
+		uint32_t type;
+		uint32_t  len;
+		char      val[1];
+};
+
+struct rmi_get_property_args {
+		uint32_t rv;
+		rmi_addr_t res;
+		char name[RMI_MAX_NAMELEN];
+		struct rmi_property prop_data;
+		uint32_t len;
+        	char val[1];
+};
+
+struct rmi_del_property_args {
+		uint32_t rv;
+		rmi_addr_t res;
+		char name[RMI_MAX_NAMELEN];
+};
+
+struct rmi_get_propnames_args {
+		uint32_t rv;
+		rmi_addr_t res;
+		uint32_t  len;
+		char      val[1];
+};
+
+struct rmi_print_buffer_args {
+		uint32_t rv;
+		uint32_t  len;
+		char      buf[1];
+};
+
+static inline void rmi_set_isnull_arg(void *loc, void *ptr)
+{
+	uint32_t  *uloc = loc;
+	if (ptr)
+		*uloc = 1;
+	else
+		*uloc = 0;
+}
+
+static inline int rmi_isnull_arg(void *loc)
+{
+	uint32_t  *uloc = loc;
+
+	return *uloc == 0;
+}
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmicrf/pcpu.h b/arch/mips/include/asm/rmi/rmicrf/pcpu.h
new file mode 100644
index 0000000..75070f1
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/pcpu.h
@@ -0,0 +1,85 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMICRF_PCPU_H
+#define _RMICRF_PCPU_H
+
+#ifndef __ASSEMBLY__
+
+
+/*
+ * Per CPU structure maintained by CRF
+ * See below macros when you modify this structure.
+ */
+
+struct rmi_pcpu_info {
+        uint64_t    data_area;    /*!< @brief  pointer to percpu data */
+        uint32_t    state;	  /*!< @brief  state - see above */
+		uint32_t	dummy;    /* For alignment */
+        uint64_t    nmi_handler;  /*!< @brief  current nmi handler */
+		uint64_t 	nmi_lock; /*!< @brief  percpu nmi lock  */
+		uint64_t	sp;/*!< @brief  percpu stack ptr */
+		uint64_t	trapframe; /*!< @brief  percpu trap frame */
+		uint64_t	nmiframe;/*!< @brief  percpu nmi frame, saved in nmi handler */
+		uint64_t	perfframe;/*!< @brief  percpu performance monitoring  ptr */
+		uint64_t	dbgframe; /*!< @brief  percpu debug  ptr */
+		uint64_t	res;	/*!< @brief  future use */
+}  __attribute__((packed, aligned(8)));;
+
+#endif  /* __ASSEMBLY__*/
+
+/* memory needed by the rmi kernel for teach cpu */
+#define XLR_PCPU_AREA_SIZE   		(8*1024)
+#define XLR_EXCEPTION_FRAME_SZ		400
+
+/* Offsets from the pcpu data area */
+#define XLR_EXCEPTION_FRAME_OFFSET      (XLR_PCPU_AREA_SIZE-XLR_EXCEPTION_FRAME_SZ)
+#define XLR_NMI_EXCEPTION_FRAME_OFFSET  (XLR_PCPU_AREA_SIZE-800)
+#define XLR_PERFMON_DATA_OFFSET 	    (XLR_PCPU_AREA_SIZE-928) 
+#define XLR_DEBUG_DATA_OFFSET 		    (XLR_PCPU_AREA_SIZE-1056) 
+#define XLR_SP_OFFSET           		(XLR_DEBUG_DATA_OFFSET-XLR_CALLFRAME_SZ) 
+
+#define RMI_PCPU_INFO_DATA_OFF 			0
+#define RMI_PCPU_INFO_STATE_OFF 		8
+#define RMI_PCPU_INFO_NMI_HANDLER_OFF 	16
+#define RMI_PCPU_INFO_NMI_LOCK_OFF 		24
+#define RMI_PCPU_INFO_SP_OFF 			32
+#define RMI_PCPU_INFO_TRAPFRAME_OFF 	40
+#define RMI_PCPU_INFO_NMIFRAME_OFF 		48
+#define RMI_PCPU_INFO_PERFFRAME_OFF 	56
+#define RMI_PCPU_INFO_DBGFRAME_OFF	 	64
+#define RMI_PCPU_INFO_SZ  				80
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmicrf/rmios.h b/arch/mips/include/asm/rmi/rmicrf/rmios.h
new file mode 100644
index 0000000..89510ee
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/rmios.h
@@ -0,0 +1,67 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMICRF_RMIOS_H
+#define _RMICRF_RMIOS_H
+
+#include <rmicrf/pcpu.h>
+extern void (*rmi_rmik_entry)(int callnum);
+extern struct rmi_pcpu_info *rmi_pcpu_info;
+
+static inline void rmi_enter_kernel(int callnum)
+{
+        (*rmi_rmik_entry)(callnum);
+}
+
+static inline void *rmi_get_pcpumem(int cpuid)
+{
+    extern struct rmi_pcpu_info *rmi_pcpu_info;
+    extern int rmi_pcpu_info_size;
+    struct rmi_pcpu_info *tmp;
+    tmp = rmi_addr_to_ptr(((rmi_ptr_to_addr(rmi_pcpu_info)) + (rmi_pcpu_info_size * cpuid)));
+    return rmi_addr_to_ptr(tmp->data_area);
+}
+
+static inline void *rmi_get_pcpuinfo(int cpuid)
+{
+    extern struct rmi_pcpu_info *rmi_pcpu_info;
+    extern int rmi_pcpu_info_size;
+    struct rmi_pcpu_info *tmp;
+    tmp = rmi_addr_to_ptr(((rmi_ptr_to_addr(rmi_pcpu_info)) + (rmi_pcpu_info_size * cpuid)));
+    return tmp;
+}
+
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmicrf/types.h b/arch/mips/include/asm/rmi/rmicrf/types.h
new file mode 100644
index 0000000..7f0056b
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmicrf/types.h
@@ -0,0 +1,379 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMICRF_TYPES_H
+#define _RMICRF_TYPES_H
+
+#include <rmicrf/config.h>
+#include <rmidev/platform.h>
+
+/**
+* @file_name  rmicrf/types.h
+* @brief Types and structure declarations for CRF
+*/
+
+/*
+ * @brief Version of the file 
+ * @ sizeof int , LSB 2 bytes are the normal version
+ *   and the upper 2 bytes are the compatibilty version
+*/
+#define RMICRF_COMPAT_ID_OFF 16
+#define RMICRF_REL_ID_OFF 0
+#define RMICRF_VERSION_ID_MASK 0xffff
+#define RMICRF_VERSION ((2 << RMICRF_COMPAT_ID_OFF) | (3 << RMICRF_REL_ID_OFF))
+
+/**
+* @addtogroup crf_domain
+*/
+/* @{ */
+typedef uint32_t rmi_dom_t;        /*!< @brief CRF type for Domain IDs */
+/* @} */
+
+/**
+* @brief CRF Kernel call numbers 
+* 
+* Each kernel entry point to the CRF has a unique number, and argument convention.  
+* The numbers are from 1..RMI_CALL_MAX, and number 0 is reserverd.
+*/
+enum rmi_calls_t {
+		RMI_MEM_ALLOC = 1,
+		RMI_MEM_REALLOC,   /* unused */
+		RMI_MEM_RESERVE,
+		RMI_MEM_FREE,
+
+		RMI_RESOURCE_GETREF,
+		RMI_RESOURCE_PUTREF,
+		RMI_RESOURCE_ALLOCATE,
+		RMI_RESOURCE_FREE,
+		RMI_RESOURCE_DELETE,
+
+		RMI_DOMAIN_CREATE,
+		RMI_DOMAIN_START,
+		RMI_DOMAIN_STOP,
+		RMI_DOMAIN_DELETE,
+
+		RMI_VRESOURCE_CREATE,
+		RMI_MUTEX_CREATE,
+		RMI_FIFO_CREATE,
+		RMI_FMNQ_CREATE,
+		RMI_MEMSEG_CREATE,
+		RMI_DEVICE_CREATE,
+
+		RMI_GET_PROPERTY,
+		RMI_SET_PROPERTY,
+		RMI_DEL_PROPERTY,
+		RMI_GET_PROPNAMES,
+		RMI_PRINT_BUFFER,
+		
+		RMI_CALL_MAX /* dont add below */
+};
+
+/**
+* @addtogroup crf_resource
+* @brief Resource flag enumeration values
+*/
+/* @{ */
+enum rmi_res_flags {
+		/* 
+		 * common for all resources 
+		 */
+		RMI_RES_EXCLUSIVE = 0x0001,  /*!< @brief Can be owned by only one domain */
+		RMI_RES_SHARED = 0x0002,     /*!< @brief Can be owned by multiple domains */
+		RMI_RES_ALLOCABLE = 0x0004,  /*!< @brief Can be allocated */
+		RMI_RES_PERMANENT = 0x0008,  /*!< @brief the resource is permanent */
+		RMI_RES_RETAIN    = 0x0010,  /*!< @brief the explicit create and delete */
+		/*
+		 * Mem segment flags 
+		 */
+		RMI_M_RDONLY   = 0x10000,   /*!< @brief Read Only */
+		RMI_M_EXECUTE  = 0x20000,   /*!< @brief Executable */
+		RMI_M_RDWR     = 0x40000,   /*!< @brief Read Write */
+		RMI_M_SHR      = 0x80000,   /*!< @brief Shared segment */
+		RMI_M_VADDR_VALID = 0x100000, /*!< @brief virtual address is valid */ 
+		RMI_M_PADDR_VALID = 0x200000,  /*!< @brief physical address is valid */
+		RMI_M_ALLOC_UNMAPPED    = 0x1000000, /*!< @brief config, alloc from unmapped space */
+		RMI_M_ALLOC_MAPPED      = 0x2000000,/*!< @brief config, alloc from mapped space  */
+		RMI_M_ALLOC_MAPPED_DMA  = 0x4000000,/*!< @brief config, alloc from DMA space */
+		/*
+		 * Mutex flags 
+		 */
+		RMI_MUTEX_LOCKED = 0x10000,  /*!< @brief Mutex to be created locked */
+		RMI_MUTEX_UNLOCKED = 0x20000 /*!< @brief Mutex to be created unlocked */
+};
+
+/*  Default flags for devices and memory */
+
+#define RMI_RES_DEV_FLAGS	(RMI_RES_EXCLUSIVE | RMI_RES_ALLOCABLE)
+#define RMI_RES_MEM_FLAGS	(RMI_RES_SHARED | RMI_RES_ALLOCABLE)
+#define RMI_RES_FLAG_EXTRACT(x) ((x) & 0x0000ffff)
+
+#define RMI_MALLOC_ANY		(RMI_MALLOC_UNMAPPED | RMI_MALLOC_MAPPED)
+#define RMI_M_ADDR_VALID	(RMI_M_VADDR_VALID | RMI_M_PADDR_VALID)
+#define RMI_M_ALLOC_ANY		(RMI_M_ALLOC_UNMAPPED | RMI_M_ALLOC_MAPPED | RMI_M_ALLOC_MAPPED_DMA)
+/* @} */
+
+/* simple lock to be used to protect data stuctures */
+enum lock_init_values { RMI_LOCK_LOCKED = 1, RMI_LOCK_UNLOCKED = 0 };
+typedef struct { uint32_t value; } rmi_lock_t;
+
+
+/*
+* Simple doubly-linked list type 
+* 
+* This is used by various internal data structures which are parts of CRF
+* maintained lists.
+*/
+struct rmi_list {
+#if defined(RMICRF_NEWLIB) 
+	struct rmi_list *prev;
+	struct rmi_list *next;
+#else
+	uint32_t prev;
+	uint32_t next;
+#endif
+};
+
+/*
+ *  Operations on rmi_list
+ */
+void rmi_list_init(struct rmi_list *head);
+void rmi_list_clear(struct rmi_list *head);
+void rmi_list_append(struct rmi_list *head, struct rmi_list *entry);
+void rmi_list_prepend(struct rmi_list *head, struct rmi_list *entry);
+void rmi_list_delete(struct rmi_list *head, struct rmi_list *entry);
+
+/**
+* @addtogroup crf_memory
+*/
+/* @{ */
+enum rmi_malloc_types_t { 
+	RMI_MALLOC_UNMAPPED = 1, /*!< @brief Allocate from KSEG0 memory */
+	RMI_MALLOC_MAPPED = 2,    /*!< @brief Allocate from other memory */
+	RMI_MALLOC_MAPPED_DMA = 6
+};
+/* @} */
+
+/**
+* @addtogroup crf_resource
+*/
+/* @{ */
+enum rmi_resource_type { RMI_DEVICE = 1,  /*!< @brief Device Resource */
+			 RMI_VRESOURCE,   /*!< @brief Virtual Resource */
+			 RMI_DOMAIN,      /*!< @brief Domain */
+			 RMI_MUTEX,       /*!< @brief Lock */
+			 RMI_FMNQ,        /*!< @brief FMN Queue */
+		         RMI_FIFO,        /*!< @brief FIFO in shared memory */
+			 RMI_MEMSEG,      /*!< @brief Shared Memory segment */
+			 RMI_MAX_TYPES    /* this should be last */
+};
+/* @} */
+
+/**
+* @brief Resource structure declaration
+*
+* @ingroup crf_resource crf_communicate
+*/
+struct rmi_resource {
+	uint32_t       type;    /*!< @brief should be one of resource_type_t */
+	uint32_t       flags;   /*!< @brief type flags */			
+	rmi_dom_t      domain;  /*!< @brief domain owning resource */		
+	rmi_lock_t      lock;   /*!< @brief lock for this struct */
+	char           name[RMI_MAX_NAMELEN];   /*!< @brief name size fixed for now */
+	rmi_addr_t     obj;     /*!< @brief pointer to the object description */     
+	uint32_t       refcnt;  /*!< @brief ATOMIC - reference count */     
+	rmi_addr_t	parent;  /*!< @brief parent resource */      
+	struct rmi_list child;	/*!< @brief Child resource nodes */		
+	struct rmi_list sibs;   /*!< @brief Siblings of the main resource */      
+	struct rmi_list property_list;   /*!< @brief Property list of the main resource */ 
+	struct rmi_list  domain_entry;   /*!< @brief PRIVATE */         
+};
+
+typedef struct rmi_resource * rmi_resource_t;
+
+
+/**
+* @ingroup crf_communicate
+* @brief CRF Shared Mutex
+*
+* The shared mutex can be used to control access to shared resources.
+* The order of the parameters is important. Add the parameters only 
+* in the bottom . 
+*/
+struct rmi_mutex {
+	rmi_lock_t lock;         /*!< @brief 0 unlocked, 1 locked */
+	uint16_t   cpu;       	 /*!< @brief cpu which has the lock */
+	uint16_t   domain;       /*!< @brief domain which has the lock */
+	uint32_t   spincount;    /*!< @brief stats */ 
+	uint32_t   flags; 	/*!< @brief type flags */
+};
+
+/**
+* @ingroup crf_communicate
+* @brief Shared memory segment
+*
+* A memory segment allocated by a domain can be shared by creating a shared
+* memory resource.
+*/
+struct rmi_memseg
+{
+	rmi_addr_t	vaddr;        /*!< @brief Virtual Address */
+	uint64_t	size;         /*!< @brief Size of the segment */
+	/* mapping information */
+	rmi_physaddr_t  allocstart;   /*!< @brief Physical Address start */
+	rmi_physaddr_t  allocend;     /*!< @brief Physical Address end  */
+	uint32_t	pagesize;     /*!< @brief Page size used for mapping */
+	uint32_t	flags;		/*!< @brief type flags */
+};
+
+/*
+* Domain status information enum values
+*/
+enum rmi_domain_state_t { RMI_D_RESET = 0, RMI_D_STARTED, RMI_D_RUNNING, RMI_D_STOPPED  };
+
+/*
+* Node status information enum values
+*/
+enum rmi_domain_mode_t { RMI_D_BUDDY = 0, RMI_D_MASTER = 1 };
+
+/**
+ * @ingroup crf_communicate
+ * @brief Event queue for a domain
+ *
+ * Each domain will have an event queue associated with it, the eventq can be 
+ * based on either FIFO or FMNQ, and it will be used to send application defined
+ * events to a domain.
+ */
+struct rmi_eventq {
+	uint32_t   type;         /*!< @brief Type of Event Queue, FMN or FIFO */
+	uint32_t   notify_ipi;  /*!< @brief IPI used for notification, -1 for none */
+	uint32_t   notify_cpu;  /*!< @brief CPU to which notification is send */
+	uint32_t   flags; /*!< @brief type flags */
+	rmi_addr_t transport;   /*!< @brief resource of transport */
+	rmi_addr_t transportref; /*!< @brief transport object reference */
+};
+
+/**
+* @ingroup crf_domain
+* @brief CRF domain structure
+*
+* The structure maintains the CRF domain information.
+*/
+struct rmi_domain {
+	rmi_dom_t       id;        /*!< @brief Unique identification number */
+	uint32_t        state;     /*!< @brief Current status of the domain either running or stopped */ 
+	char            name[RMI_MAX_NAMELEN]; /*!< @brief the domain name string */
+	rmi_lock_t     	lock;      /*!< @brief  Lock in making the domain info atomic */
+	uint32_t	mastercpu; /*!< @brief  Cpu on which the domain being launched */
+	uint32_t 	cpu_map;   /*!< @brief  All the cpus on which the domain is launched */
+	uint32_t        pad;
+	uint64_t 	ebase;     /*!< @brief  Exceptions Base */
+	uint64_t 	tlbsz;     /*!< @obsoleted */
+	uint64_t 	memlist;   /*!< @obsoleted */
+	uint32_t 	mementries;/*!< @obsoleted */
+	uint32_t        mode;      /*!< @brief  Buddy mode or master mode indicator */
+	struct rmi_eventq eventq;  /*!< @brief  Event queue structure */
+	struct rmi_list  resource_list;   /*!< @brief  Resources allocated to the domain */
+};
+
+/**
+* @ingroup crf_communicate
+* @brief FMN based message queue
+*                      
+* The rmi_fmnq is a queue that uses FMN to send messages, this can be created and
+* registered with the CRF.
+*/
+struct rmi_fmnq {
+	uint32_t        bucket;           /*!< @brief bucket used by this queue */
+	uint32_t	stat_fail_credit;
+	uint32_t	stat_fail_thread;
+	uint32_t	stat_fail_pending;
+	uint32_t	stat_fail_empty;
+	uint32_t	flags;
+};
+
+/*
+* @ingroup crf_communicate
+* @brief Simple memory based FIFO
+*
+* Simple memory based FIFO to which can be created and registered with CRF. This
+* can be used to send messages between domains.
+*/
+struct rmi_fifo {
+	uint32_t	head;          /*!< @brief head pointer */
+	uint32_t	tail;          /*!< @brief tail pointer */
+	uint32_t	nentries;      /*!< @brief number of entries allocated */
+	uint32_t	entrysize;     /*!< @brief size of an entry */
+	struct rmi_mutex lock;         /*!< @brief lock for the structure */
+	uint32_t	stat_full_events;
+	uint32_t	stat_data_events;
+	uint32_t	flags;
+	uint64_t	data[1];       /*!< @brief queue data starts here */
+};
+
+/* Fixed domain IDs*/
+#define  RMI_DOMAIN_NONE    0
+#define  RMI_DOMAIN_REMOVED 1
+
+/**
+* @addtogroup crf_resource
+* @brief Basic types used in properties
+*/
+/* @{ */
+enum rmi_property_types  {
+	RMI_PROPERTY_INT,
+	RMI_PROPERTY_UINT, 
+	RMI_PROPERTY_STRING, 
+	RMI_PROPERTY_ADDR,
+	RMI_PROPERTY_BIN,
+	RMI_PROPERTY_BIN32,
+	RMI_PROPERTY_BIN64,
+	RMI_PROPERTY_MAX,  /* end marker */
+};
+/* @} */
+
+/**
+* @ingroup crf_resource
+* @brief Property structure declaration
+*
+* Property will have name, type, size and list as its elements.
+*/
+struct rmi_property {
+	uint32_t type;                    /*!< @brief  Type of the property */
+	char     name[RMI_MAX_NAMELEN];   /*!< @brief  property name string */
+	uint32_t size;                    /*!< @brief  size of the property value */
+	struct   rmi_list list;           /*!< @brief  property list */
+};
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/asm.h b/arch/mips/include/asm/rmi/rmidev/asm.h
new file mode 100644
index 0000000..3956596
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/asm.h
@@ -0,0 +1,105 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+#ifndef _RMIDEV_ASM_H_
+#define	_RMIDEV_ASM_H_
+
+/**
+* @file_name asm.h
+* @author RMICORP
+* @brief Basic definitions for CPU operations 
+*/
+
+/* register names used in assembly code */
+#define zero	$0
+#define v0	$2
+#define v1	$3
+#define a0	$4 
+#define a1	$5
+#define a2	$6
+#define a3	$7
+#define t0	$8 
+#define t1	$9
+#define t2 	$10
+#define t3	$11
+#define t4	$12
+#define t5	$13
+#define t6	$14
+#define t7	$15
+#define s0	$16
+#define s1	$17
+#define s2	$18
+#define s3	$19
+#define s4	$20
+#define s5	$21
+#define s6	$22
+#define s7	$23
+#define t8	$24
+#define t9	$25
+#define k0	$26
+#define k1	$27
+#define	gp	$28
+#define sp	$29
+#define s8	$30
+#define ra	$31
+
+
+#define	XLR_C0_INDEX		$0
+#define	XLR_C0_RANDOM		$1
+#define	XLR_C0_ENTRYLO0		$2
+#define	XLR_C0_ENTRYLO1		$3
+#define	XLR_C0_CONTEXT		$4
+#define	XLR_C0_PAGEMASK		$5
+#define	XLR_C0_WIRED		$6
+#define	XLR_C0_BADVADDR		$8
+#define	XLR_C0_COUNT		$9
+#define	XLR_C0_ENTRYHI		$10
+#define	XLR_C0_COMPARE		$11
+#define	XLR_C0_STATUS		$12
+#define	XLR_C0_CAUSE		$13
+#define	XLR_C0_EPC		$14
+#define	XLR_C0_PRID		$15
+#define	XLR_C0_EBASE		$15
+#define	XLR_C0_CONFIG		$16
+#define	XLR_C0_WATCHLO		$18
+#define	XLR_C0_WATCHHI		$19
+#define	XLR_C0_XCONTEXT		$20
+#define	XLR_C0_SCRATCH		$22
+#define	XLR_C0_DEBUG		$23
+#define	XLR_C0_DEPC		$24
+#define	XLR_C0_PERFCNT		$25
+#define	XLR_C0_TAGLO		$28
+#define	XLR_C0_DATALO		$28
+#define	XLR_C0_TAGHI		$29
+#define	XLR_C0_DATAHI		$29
+#define	XLR_C0_ERROREPC		$30
+#define	XLR_C0_DESAVE		$31
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/atomic.h b/arch/mips/include/asm/rmi/rmidev/atomic.h
new file mode 100644
index 0000000..bad563b
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/atomic.h
@@ -0,0 +1,168 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMIK_ATOMIC_H
+#define _RMIK_ATOMIC_H
+
+/* 
+ * XLR Atomic Operations 
+ */
+static __inline__ void xlr_atomic_add_u32(uint32_t value, uint32_t *addr)
+{
+	uint32_t temp;
+	__asm__ __volatile__(
+		" .set	push      \n\t"
+		" .set	noreorder \n\t"
+		"1:ll    %0, %3   \n\t"
+		"  addu  %0, %2   \n\t"
+		"  sc    %0, %1	  \n\t"
+		"  beqz  %0, 1b   \n\t"
+		"  nop            \n\t"
+		" .set   pop      \n"
+		: "=&r" (temp), "=m" (*addr)
+		: "r" (value), "m" (*addr)
+		: "memory");
+		return;
+
+}
+
+
+static __inline__ void xlr_atomic_sub_u32(uint32_t value, uint32_t *addr)
+{
+	uint32_t temp;
+	__asm__ __volatile__(
+		" .set	push      \n\t"
+		" .set	noreorder \n\t"
+		"1:ll    %0, %3   \n\t"
+		"  subu  %0, %2   \n\t"
+		"  sc    %0, %1	  \n\t"
+		"  beqz  %0, 1b   \n\t"
+		"  nop            \n\t"
+		" .set   pop      \n"
+		: "=&r" (temp), "=m" (*addr)
+		: "r" (value), "m" (*addr)
+		: "memory");
+		return;
+
+}
+
+static __inline__ void xlr_atomic_bit_set_u32(uint32_t pos, uint32_t *addr)
+{
+	uint32_t temp, temp1;
+	__asm__ __volatile__(
+		" .set	push      \n\t"
+		" .set	noreorder \n\t"
+		"1:ll    %0, %4   \n\t"
+		"  li	 %1, 1	  \n\t"
+		"  sll   %1, %3   \n\t"
+		"  or    %0, %1   \n\t"
+		"  sc    %0, %2	  \n\t"
+		"  beqz  %0, 1b   \n\t"
+		"  nop            \n\t"
+		" .set   pop      \n"
+		: "=&r" (temp), "=&r" (temp1), "=m" (*addr)
+		: "r" (pos), "m" (*addr)
+		: "memory");
+		return;
+
+}
+
+static __inline__ void xlr_atomic_bit_clear_u32(uint32_t pos, uint32_t *addr)
+{
+	uint32_t temp, temp1;
+	__asm__ __volatile__(
+		" .set	push      \n\t"
+		" .set	noreorder \n\t"
+		"1:ll    %0, %4   \n\t"
+		"  li    %1, 1    \n\t"
+		"  sll   %1, %3   \n\t"
+		"  nor   %1, %1, $0   \n\t"
+		"  and   %0, %0, %1   \n\t"
+		"  sc    %0, %2	  \n\t"
+		"  beqz  %0, 1b   \n\t"
+		"  nop            \n\t"
+		" .set   pop      \n"
+		: "=&r" (temp), "=&r" (temp1), "=m" (*addr)
+		: "r" (pos), "m" (*addr)
+		: "memory");
+		return;
+
+}
+
+static __inline__ void xlr_atomic_bit_set_u64(uint32_t pos, uint64_t *addr)
+{
+	__asm__ __volatile__(
+		" .set	push      \n\t"
+		" .set	noreorder \n\t"
+		" .set mips64     \n\t"
+		"1:lld   $8, %2   \n\t"
+		"  li    $9, 1    \n\t"
+		"  dsllv $9, $9, %1   \n\t"
+		"  or    $8, $9   \n\t"
+		"  scd   $8, %0	  \n\t"
+		"  beqz  $8, 1b   \n\t"
+		"  nop            \n\t"
+		" .set   pop      \n"
+		: "=m" (*addr)
+		: "r" (pos), "m" (*addr)
+		: "$8", "$9", "memory");
+		return;
+
+}
+
+static __inline__ void xlr_atomic_bit_clear_u64(uint32_t pos, uint64_t *addr)
+{
+	__asm__ __volatile__(
+		" .set	push      \n\t"
+		" .set	noreorder \n\t"
+		" .set mips64     \n\t"
+		"1:lld   $8, %2   \n\t"
+		"  li    $9, 1    \n\t"
+		"  dsllv $9, $9, %1   \n\t"
+		"  nor   $9, $9, $0   \n\t"
+		"  and   $8, $8, $9   \n\t"
+		"  scd   $8, %2	  \n\t"
+		"  beqz  $8, 1b   \n\t"
+		"  nop            \n\t"
+		" .set   pop      \n"
+		: "=m" (*addr)
+		: "r" (pos), "m" (*addr)
+		: "$8", "$9", "memory");
+		return;
+
+}
+
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/bridge.h b/arch/mips/include/asm/rmi/rmidev/bridge.h
new file mode 100644
index 0000000..033dcbe
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/bridge.h
@@ -0,0 +1,105 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+#ifndef __XLR_BRIDGE_H__
+#define __XLR_BRIDGE_H__
+
+#define XLR_BRIDGE_DRAM_0_BAR		0
+#define XLR_BRIDGE_DRAM_1_BAR		1
+#define XLR_BRIDGE_DRAM_2_BAR		2
+#define XLR_BRIDGE_DRAM_3_BAR		3
+#define XLR_BRIDGE_DRAM_4_BAR		4
+#define XLR_BRIDGE_DRAM_5_BAR		5
+#define XLR_BRIDGE_DRAM_6_BAR		6
+#define XLR_BRIDGE_DRAM_7_BAR		7
+#define XLR_BRIDGE_DRAM_CHN_0_MTR_0_BAR	8
+#define XLR_BRIDGE_DRAM_CHN_0_MTR_1_BAR	9
+#define XLR_BRIDGE_DRAM_CHN_0_MTR_2_BAR	10
+#define XLR_BRIDGE_DRAM_CHN_0_MTR_3_BAR	11
+#define XLR_BRIDGE_DRAM_CHN_0_MTR_4_BAR	12
+#define XLR_BRIDGE_DRAM_CHN_0_MTR_5_BAR	13
+#define XLR_BRIDGE_DRAM_CHN_0_MTR_6_BAR	14
+#define XLR_BRIDGE_DRAM_CHN_0_MTR_7_BAR	15
+#define XLR_BRIDGE_DRAM_CHN_1_MTR_0_BAR	16
+#define XLR_BRIDGE_DRAM_CHN_1_MTR_1_BAR	17
+#define XLR_BRIDGE_DRAM_CHN_1_MTR_2_BAR	18
+#define XLR_BRIDGE_DRAM_CHN_1_MTR_3_BAR	19
+#define XLR_BRIDGE_DRAM_CHN_1_MTR_4_BAR	20
+#define XLR_BRIDGE_DRAM_CHN_1_MTR_5_BAR	21
+#define XLR_BRIDGE_DRAM_CHN_1_MTR_6_BAR	22
+#define XLR_BRIDGE_DRAM_CHN_1_MTR_7_BAR	23
+#define XLR_BRIDGE_CFG_BAR		24
+#define XLR_BRIDGE_PHNX_IO_BAR		25
+#define XLR_BRIDGE_FLASH_BAR		26
+#define XLR_BRIDGE_SRAM_BAR		27
+#define XLR_BRIDGE_HTMEM_BAR		28
+#define XLR_BRIDGE_HTINT_BAR		29
+#define XLR_BRIDGE_HTPIC_BAR		30
+#define XLR_BRIDGE_HTSM_BAR		31
+#define XLR_BRIDGE_HTIO_BAR		32
+#define XLR_BRIDGE_HTCFG_BAR		33
+#define XLR_BRIDGE_PCIXCFG_BAR		34
+#define XLR_BRIDGE_PCIXMEM_BAR		35
+#define XLR_BRIDGE_PCIXIO_BAR		36
+#define XLR_BRIDGE_DEVICE_MASK		37
+#define XLR_BRIDGE_AERR_INTR_LOG1	38
+#define XLR_BRIDGE_AERR_INTR_LOG2	39
+#define XLR_BRIDGE_AERR_INTR_LOG3	40
+#define XLR_BRIDGE_AERR_DEV_STAT	41
+#define XLR_BRIDGE_AERR1_LOG1		42
+#define XLR_BRIDGE_AERR1_LOG2		43
+#define XLR_BRIDGE_AERR1_LOG3		44
+#define XLR_BRIDGE_AERR1_DEV_STAT	45
+#define XLR_BRIDGE_AERR_INTR_EN		46
+#define XLR_BRIDGE_AERR_UPG		47
+#define XLR_BRIDGE_AERR_CLEAR		48
+#define XLR_BRIDGE_AERR1_CLEAR		49
+#define XLR_BRIDGE_SBE_COUNTS		50
+#define XLR_BRIDGE_DBE_COUNTS		51
+#define XLR_BRIDGE_BITERR_INT_EN	52
+
+#define XLR_BRIDGE_SYS2IO_CREDITS	53
+#define XLR_BRIDGE_EVNT_CNT_CTRL1	54
+#define XLR_BRIDGE_EVNT_COUNTER1	55
+#define XLR_BRIDGE_EVNT_CNT_CTRL2	56
+#define XLR_BRIDGE_EVNT_COUNTER2	57
+#define XLR_BRIDGE_RESERVED1		58
+
+#define XLR_BRIDGE_DEFEATURE		59
+#define XLR_BRIDGE_SCRATCH0		60
+#define XLR_BRIDGE_SCRATCH1		61
+#define XLR_BRIDGE_SCRATCH2		62
+#define XLR_BRIDGE_SCRATCH3		63
+
+#define XLR_BRIDGE_PHNX_IO_RESET_VADDR  0xbef00000
+#define XLR_BRIDGE_PHNX_IO_REMAP_VADDR  XLR_BRIDGE_PHNX_IO_RESET_VADDR
+#define XLR_BRIDGE_PHNX_IO_REMAP_VAL    0x1ef00000
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/flash.h b/arch/mips/include/asm/rmi/rmidev/flash.h
new file mode 100644
index 0000000..f8e3e74
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/flash.h
@@ -0,0 +1,20 @@
+#ifndef __FLASH_H__
+#define __FLASH_H__
+
+#define  XLR_CS_BOOT_FLASH               0
+#define  XLR_CS_PCMCIA                   6
+
+#define  XLR_FLASH_CSBASE_ADDR(cs)       (cs)
+#define  XLR_FLASH_CSADDR_MASK(cs)       (0x10 + (cs))
+#define  XLR_FLASH_CSDEV_PARM(cs)        (0x20 + (cs))
+#define  XLR_FLASH_CSTIME_PARMA(cs)      (0x30 + (cs))
+#define  XLR_FLASH_CSTIME_PARMB(cs)      (0x40 + (cs))
+
+#define  XLR_FLASH_INT_MASK               0x50
+#define  XLR_FLASH_INT_STATUS             0x60
+#define  XLR_FLASH_ERROR_STATUS           0x70
+#define  XLR_FLASH_ERROR_ADDR             0x80
+
+#define  XLR_NAND_CLE(cs)                 (0x90 + (cs))
+#define  XLR_NAND_ALE(cs)                 (0xa0 + (cs))
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/fmn.h b/arch/mips/include/asm/rmi/rmidev/fmn.h
new file mode 100644
index 0000000..a44f8b0
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/fmn.h
@@ -0,0 +1,163 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMIDEV_FMN_H
+#define _RMIDEV_FMN_H
+
+/**
+* @file_name fmn.h
+* @author RMICORP
+* @brief Basic definitions for FMN Device IO operations 
+*/
+
+#define xlr_mfc2(reg, sel)                            \
+({ unsigned int __rv;                                           \
+        __asm__ __volatile__(                                   \
+        ".set\tpush\n\t"                                        \
+        ".set mips64\n\t"                                       \
+        "mfc2\t%0,$%1,%2\n\t"                                   \
+        ".set\tpop"                                             \
+        : "=r" (__rv) : "i" (reg), "i" (sel) );                 \
+        __rv;})
+
+#define xlr_mtc2(reg,  sel, value)                   \
+        __asm__ __volatile__(                                   \
+        ".set\tpush\n\t"                                        \
+        ".set mips64\n\t"                                       \
+        "mtc2\t%0,$%1,%2\n\t"                                   \
+        ".set\tpop"                                             \
+        : : "r" (value), "i" (reg), "i" (sel) );
+
+#if (__mips == 64)
+#define xlr_dmfc2(reg, sel)                            \
+({ unsigned long long __rv;                                           \
+        __asm__ __volatile__(                                   \
+        ".set\tpush\n\t"                                        \
+        ".set mips64\n\t"                                       \
+        "dmfc2\t%0,$%1,%2\n\t"                                   \
+        ".set\tpop"                                             \
+        : "=r" (__rv) : "i" (reg), "i" (sel) );                 \
+        __rv;})
+
+#define xlr_dmtc2(reg,  sel, value)                   \
+        __asm__ __volatile__(                                   \
+        ".set\tpush\n\t"                                        \
+        ".set mips64\n\t"                                       \
+        "dmtc2\t%0,$%1,%2\n\t"                                   \
+        ".set\tpop"                                             \
+        : : "r" (value), "i" (reg), "i" (sel) );
+#else  /* MIPS 32 implementation */
+
+#define xlr_dmfc2(reg, sel)                            \
+   ({ unsigned int __high, __low;                               \
+        __asm__ __volatile__(                                   \
+        ".set mips64\n\t"                                       \
+        "dmfc2\t $8, $%2, %3\n\t"                               \
+        "dsrl32\t%0, $8, 0\n\t"                                 \
+        "dsll32\t$8, $8, 0\n\t"                                 \
+        "dsrl32\t%1, $8, 0\n\t"                                 \
+        ".set\tmips0"                                           \
+        : "=r"(__high), "=r"(__low): "i"(reg), "i"(sel): "$8" );\
+        (((unsigned long long)__high << 32) | __low);})
+
+#define xlr_dmtc2(reg, sel, value)                    \
+ do{                                                            \
+       unsigned int __high = value>>32;                         \
+       unsigned int __low = value & 0xffffffff;                 \
+        __asm__ __volatile__(                                   \
+        ".set mips64\n\t"                                       \
+        "dsll32\t$8, %1, 0\n\t"                                 \
+        "dsll32\t$9, %0, 0\n\t"                                 \
+        "dsrl32\t$8, $8, 0\n\t"                                 \
+        "or\t    $8, $8, $9\n\t"                                \
+        "dmtc2\t $8, $%2, %3\n\t"                               \
+        ".set\tmips0"                                           \
+        :: "r"(__high), "r"(__low),                             \
+           "i"(reg), "i"(sel)                                   \
+        :"$8", "$9");                                           \
+   } while(0)
+#endif /* (__mips == 64) */
+
+#define xlr_msgsnd(size, code, stid)                            \
+({ unsigned int rv, tmp;                                        \
+        __asm__ __volatile__(                                   \
+        ".set   push         \n\t"                              \
+        ".set noreorder      \n\t"                              \
+/*	    "msgsnd  %2          \n\t"                              */ \
+		"move $8, %2		 \n\t"								\
+		"c2	  0x80001		\n\t"								\
+        "1: mfc2    %1, $2      \n\t"                           \
+		"andi	%0, %1, 0x2	 \n\t"								\
+		"bne 	%0, $0, 1b		\n\t"							\
+		"nop				\n\t"								\
+        ".set   pop"                                            \
+        : "=r"(tmp), "=r" (rv) : "r" ((size<<16)|(code<<8)|(stid)) : "$8"  \
+        );						        \
+        rv;})
+
+/* FIXME - TODO - check possible infinite loops below */
+#define xlr_msgld(bucket)                                       \
+({ unsigned int rv, tmp;					\
+        __asm__ __volatile__(                                   \
+        ".set    push        \n\t"                              \
+        ".set    noreorder   \n\t"                              \
+/*     	"1:msgld   %2          \n\t"                   		*/ \
+		"move $8, %2			\n\t"							\
+		"c2 0x80002			\n\t"							\
+        "1:mfc2    %1, $2      \n\t"    						\
+		"andi    %0, %1, 0x08    \n\t"                              \
+        "bne     %0, $0, 1b  \n\t"                              \
+		"nop      \n\t"                              \
+        ".set     pop"                                          \
+        : "=r" (tmp), "=r"(rv) : "r" (bucket) : "$8"			\
+        );						        \
+	rv;})
+
+static inline void xlr_msgwait(uint32_t bmask)
+{
+	__asm__ volatile (
+		".set push\n"
+		".set noreorder\n"
+		"addu %0,%0,0\n"
+		"msgwait %0\n"
+		".set pop\n"
+		: :"r" (bmask)
+		);
+}
+
+int xlr_fmn_send(int bucket, int size, int code, uint64_t *msg);
+int xlr_fmn_recv(int bucket, int *size, int *code, int *stnid, uint64_t *msg);
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/gpio.h b/arch/mips/include/asm/rmi/rmidev/gpio.h
new file mode 100644
index 0000000..0c0f59d
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/gpio.h
@@ -0,0 +1,135 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+#ifndef _RMIDEV_GPIO_H__
+#define _RMIDEV_GPIO_H__
+
+/**
+* @file_name gpio.h
+* @author RMICORP
+* @brief Basic definitions for GPIO Device IO operations 
+*/
+
+#define XLR_GPIO_INT_EN_REG 0
+#define XLR_GPIO_INPUT_INVERSION_REG 1
+#define XLR_GPIO_IO_DIR_REG 2
+#define XLR_GPIO_IO_DATA_WR_REG 3
+#define XLR_GPIO_IO_DATA_RD_REG 4
+
+#define XLR_GPIO_SWRESET_REG 8
+
+#define XLR_GPIO_DRAM1_CNTRL_REG 9
+#define XLR_GPIO_DRAM1_RATIO_REG 10
+#define XLR_GPIO_DRAM1_RESET_REG 11
+#define XLR_GPIO_DRAM1_STATUS_REG 12
+
+#define XLR_GPIO_DRAM2_CNTRL_REG 13
+#define XLR_GPIO_DRAM2_RATIO_REG 14
+#define XLR_GPIO_DRAM2_RESET_REG 15
+#define XLR_GPIO_DRAM2_STATUS_REG 16
+
+#define XLR_GPIO_QDR_PLL_CNTRL_REG 17
+#define XLR_GPIO_QDR_PLL_RATIO_REG 18
+#define XLR_GPIO_QDR_PLL_RESET_REG 19
+#define XLR_GPIO_QDR_PLL_STATUS_REG 20
+
+#define XLR_GPIO_PWRON_RESET_CFG_REG 21
+
+#define XLR_GPIO_BIST_ALL_GO_STATUS_REG 24
+#define XLR_GPIO_BIST_CPU_GO_STATUS_REG 25
+#define XLR_GPIO_BIST_DEV_GO_STATUS_REG 26
+
+#define XLR_GPIO_FUSEBANK_REG 35
+
+#define XLR_GPIO_CPU_RESET_REG 40
+
+#define XLR_GPIO_PWRON_RESET_PCMCIA_BOOT 17
+
+#define XLR_GPIO_LED_BITMAP 0x1700000
+#define XLR_GPIO_LED_0_SHIFT 20
+#define XLR_GPIO_LED_1_SHIFT 24
+
+#define XLR_GPIO_LED_OUTPUT_CODE_RESET 0x01
+#define XLR_GPIO_LED_OUTPUT_CODE_HARD_RESET 0x02
+#define XLR_GPIO_LED_OUTPUT_CODE_SOFT_RESET 0x03
+#define XLR_GPIO_LED_OUTPUT_CODE_MAIN 0x04
+
+#define XLR_GPIO_RUN_BIST_BIT 0x00100000
+
+#define	XLR_GPIO_INT_EN      0
+#define	XLR_GPIO_IN_INV      1
+#define	XLR_GPIO_DIR         2
+#define	XLR_GPIO_WRITE       3
+#define	XLR_GPIO_READ        4
+#define	XLR_GPIO_INT_CLR     5
+#define	XLR_GPIO_INT_STATUS  6
+#define	XLR_GPIO_INT_TYPE    7
+#define	XLR_GPIO_RESET       8
+#define	XLR_GPIO_DRAMAB_PLL_EN       9
+#define	XLR_GPIO_DRAMAB_PLL_RATIO    10
+#define	XLR_GPIO_DRAMAB_PLL_RESET    11
+#define	XLR_GPIO_DRAMAB_PLL_STATUS   12
+#define	XLR_GPIO_DRAMCD_PLL_EN       13
+#define	XLR_GPIO_DRAMCD_PLL_RATIO    14
+#define	XLR_GPIO_DRAMCD_PLL_RESET    15
+#define	XLR_GPIO_DRAMCD_PLL_STATUS   16
+#define	XLR_GPIO_QDR_PLL_EN          17
+#define	XLR_GPIO_QDR_PLL_RATIO       18
+#define	XLR_GPIO_QDR_PLL_RESET       19
+#define	XLR_GPIO_QDR_PLL_STATUS      20
+#define	XLR_GPIO_RESET_CFG           21
+#define	XLR_GPIO_THERMAL_FSM_EN      22
+#define	XLR_GPIO_SHIFT_PATTERN       23
+#define	XLR_GPIO_BIST_STATUS_0       24
+#define	XLR_GPIO_BIST_STATUS_1       25
+#define	XLR_GPIO_BIST_STATUS_2       26
+#define	XLR_GPIO_L1DATA_SENSE_AMP    27
+#define	XLR_GPIO_L1TAG_SENSE_AMP     28
+#define	XLR_GPIO_L2DATA_SENSE_AMP    29
+#define	XLR_GPIO_L2TAG_SENSE_AMP     30
+#define	XLR_GPIO_L2U_3CYCLE          31
+#define	XLR_GPIO_CLOCK_DLYS_0        32
+#define	XLR_GPIO_CLOCK_DLYS_1        33
+#define	XLR_GPIO_CLK_DLYS_2          34
+#define	XLR_GPIO_RESERVED_0          35
+#define	XLR_GPIO_HT_CLK_EN   36
+#define	XLR_GPIO_INT_MAP     37
+#define	XLR_GPIO_EXT_INT     38
+#define	XLR_GPIO_RESERVED_1  39
+#define	XLR_GPIO_CPU_RST     40
+#define	XLR_GPIO_LOW_PWR_DIS 41
+#define	XLR_GPIO_SLOW_CLOCK  42
+#define	XLR_GPIO_RANDOM      43
+#define	XLR_GPIO_HT_CLK_DIV  44
+#define	XLR_GPIO_CPU_CLK_DIS   45
+#define	XLR_GPIO_PCIX_PLL_DIS  46
+#define	XLR_GPIO_PCIX_DLY      47
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/iomap.h b/arch/mips/include/asm/rmi/rmidev/iomap.h
new file mode 100644
index 0000000..6f7ba26
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/iomap.h
@@ -0,0 +1,108 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMIDEV_IOMAP_H
+#define _RMIDEV_IOMAP_H
+
+/**
+* @file_name iomap.h
+* @author RMICORP
+* @brief Basic definitions RMI CHIP Device IO BASEs 
+*/
+
+#define XLR_CPLD_BASE_ADDR            0xbd840000
+#define XLR_DEFAULT_IO_BASE           0xffffffffbef00000ULL
+
+
+#define XLR_IO_BRIDGE_OFFSET          0x00000
+
+#define XLR_IO_DDR2_CHN0_OFFSET       0x01000
+#define XLR_IO_DDR2_CHN1_OFFSET       0x02000
+#define XLR_IO_DDR2_CHN2_OFFSET       0x03000
+#define XLR_IO_DDR2_CHN3_OFFSET       0x04000
+
+#define XLR_IO_RLD2_CHN0_OFFSET       0x05000
+#define XLR_IO_RLD2_CHN1_OFFSET       0x06000
+
+#define XLR_IO_SRAM_OFFSET            0x07000
+
+#define XLR_IO_PIC_OFFSET             0x08000
+#define XLR_IO_PCIX_OFFSET            0x09000
+#define XLR_IO_HT_OFFSET              0x0A000
+
+#define XLR_IO_SECURITY_OFFSET        0x0B000
+
+#define XLR_IO_GMAC_0_OFFSET          0x0C000
+#define XLR_IO_GMAC_1_OFFSET          0x0D000
+#define XLR_IO_GMAC_2_OFFSET          0x0E000
+#define XLR_IO_GMAC_3_OFFSET          0x0F000
+
+#define XLR_IO_SPI4_0_OFFSET          0x10000
+#define XLR_IO_XGMAC_0_OFFSET         0x11000
+#define XLR_IO_SPI4_1_OFFSET          0x12000
+#define XLR_IO_XGMAC_1_OFFSET         0x13000
+
+#define XLR_IO_UART_0_OFFSET          0x14000
+#define XLR_IO_UART_1_OFFSET          0x15000
+
+#define XLR_IO_I2C_0_OFFSET           0x16000
+#define XLR_IO_I2C_1_OFFSET           0x17000
+
+#define XLR_IO_GPIO_OFFSET            0x18000
+
+#define XLR_IO_FLASH_OFFSET           0x19000
+
+#define XLR_IO_DMA_OFFSET             0x1a000
+
+#define XLR_IO_TB_OFFSET              0x1c000
+
+#define XLR_IO_L2_OFFSET              0x1b000
+
+#define XLR_IO_GMAC_4_OFFSET          0x20000
+#define XLR_IO_GMAC_5_OFFSET          0x21000
+#define XLR_IO_GMAC_6_OFFSET          0x22000
+#define XLR_IO_GMAC_7_OFFSET          0x23000
+
+#define XLR_IO_PCIE_0_OFFSET          0x1E000
+#define XLR_IO_PCIE_1_OFFSET          0x1F000
+
+#define XLR_IO_USB_0_OFFSET           0x24000
+#define XLR_IO_USB_1_OFFSET           0x25000
+
+#define XLR_IO_COMP_OFFSET            0x1d000
+
+#define XLR_CPLD_OFFSET               0xffffffffbd840000ULL
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/pic.h b/arch/mips/include/asm/rmi/rmidev/pic.h
new file mode 100644
index 0000000..67f250a
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/pic.h
@@ -0,0 +1,142 @@
+/***********************************************************************
+
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+
+*****************************#RMI_3#***********************************/
+
+#ifndef _RMIDEV_PIC_H
+#define _RMIDEV_PIC_H
+
+/**
+* @file_name pic.h
+* @author RMICORP
+* @brief Basic declarations and definitions PIC operation 
+*/
+
+#include <rmidev/iomap.h>
+#include <rmidev/xlrio.h>
+
+#define XLR_PIC_IRT_WD_INDEX     	   0
+#define XLR_PIC_IRT_TIMER_INDEX(timer)     (1+(timer))
+
+#define XLR_PIC_SYS_TIMER_MAXVAL_0_BASE 0x100
+#define XLR_PIC_SYS_TIMER_MAXVAL_1_BASE 0x110
+#define XLR_PIC_SYS_TIMER_0_BASE        0x120
+#define XLR_PIC_SYS_TIMER_1_BASE        0x130
+
+#define XLR_PIC_CTRL                     0x00
+#define XLR_PIC_IPI                      0x04
+#define XLR_PIC_INT_ACK                  0x06
+
+#define XLR_WD_MAXVAL_0                 0x08
+#define XLR_WD_MAXVAL_1 		0x09
+#define XLR_WD_MASK_0    		0x0a
+#define XLR_WD_MASK_1    		0x0b
+#define XLR_WD_HEARBEAT_0 		0x0c
+#define XLR_WD_HEARBEAT_1 		0x0d
+
+#define XLR_PIC_IRT_0_BASE 		0x40
+#define XLR_PIC_IRT_1_BASE 		0x80
+
+#define XLR_PIC_IRT_ENTRY0(index)     	(XLR_PIC_IRT_0_BASE   + (index))
+#define XLR_PIC_IRT_ENTRY1(index)     	(XLR_PIC_IRT_1_BASE   + (index))
+
+#define PIC_TIMER_MAXVAL_0(timer)        (XLR_PIC_SYS_TIMER_MAXVAL_0_BASE + (timer))
+#define PIC_TIMER_MAXVAL_1(timer)        (XLR_PIC_SYS_TIMER_MAXVAL_1_BASE + (timer))
+#define PIC_TIMER_COUNTER_0(timer)       (XLR_PIC_SYS_TIMER_0_BASE + (timer))
+#define PIC_TIMER_COUNTER_1(timer)       (XLR_PIC_SYS_TIMER_1_BASE + (timer))
+
+/**
+* @brief Interrupt trigger types
+*/
+enum xlr_intr_trigger_type    { XLR_INTR_EDGE_TRIGGER=0, XLR_INTR_LEVEL_TRIGGER };
+
+/**
+* @brief Interrupt Scheduling types
+*/
+enum xlr_intr_scheduling_type { XLR_INTR_GLOBAL_SCHEDULING=0, XLR_INTR_LOCAL_SCHEDULING };
+
+static inline void xlr_send_ipi(int cpu, int vector)
+{
+	int thread = cpu & 0x3;
+        int core = (cpu >> 2) & 0x7;
+ 
+	uint32_t val = (core<<20) | (thread<<16) | vector;
+	xlr_write_reg(xlr_io_base + XLR_IO_PIC_OFFSET, XLR_PIC_IPI, val);
+}
+
+static inline void xlr_send_nmi_ipi(int cpu, int vector)
+{
+	int thread = cpu & 0x3;
+        int core = (cpu >> 2) & 0x7;
+ 
+	uint32_t val = (core<<20) | (thread<<16) | (1<<8) | vector;
+	xlr_write_reg(xlr_io_base + XLR_IO_PIC_OFFSET, XLR_PIC_IPI, val);
+}
+
+static inline void xlr_broadcast_ipi(int vector, int nmi)
+{
+        uint32_t val = (nmi << 8) | (1 << 7) | vector;
+        xlr_write_reg(xlr_io_base + XLR_IO_PIC_OFFSET, XLR_PIC_IPI, val);
+}
+
+static inline void xlr_setup_interrupt(int intr, int vector, uint32_t cpumask,
+			int scheduling, int nmi, int polarity, int trigger)
+{
+	uint32_t  val = (1U<<31) | (trigger<30) | (polarity<<29) |
+					 (nmi<<7) | (scheduling<<6) | vector;
+
+        xlr_write_reg(xlr_io_base + XLR_IO_PIC_OFFSET, 
+				XLR_PIC_IRT_ENTRY0(intr), cpumask);
+        xlr_write_reg(xlr_io_base + XLR_IO_PIC_OFFSET,
+				 XLR_PIC_IRT_ENTRY1(intr), val);
+}
+
+static inline void xlr_setup_timer(int timer, uint64_t value)
+{
+	/* TODO */
+}
+
+static inline void xlr_pic_ack_interrupt(int intr)
+{
+}
+	/* TODO */
+
+
+extern void rmi_pic_update_ctrl(int timerid, int en);
+extern void rmi_pic_ctrl_lock_init(void);
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/platform.h b/arch/mips/include/asm/rmi/rmidev/platform.h
new file mode 100644
index 0000000..aefc0c0
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/platform.h
@@ -0,0 +1,144 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMIDEV_TYPES_H
+#define _RMIDEV_TYPES_H
+
+/**
+* @file_name platform.h
+* @author RMICORP
+* @brief Basic type declarations based on the platform
+*/
+
+#if defined(__KERNEL__)	       /* Linux kernel */
+#define RMICRF_LINUXK
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#elif defined(RMIOS)	   /* Compile with RMIOS lib */
+#define RMICRF_RMIOS
+#include <types.h>
+#include <byteorder.h>
+#include "stdio.h"
+#include "string.h"
+#include "assert.h"
+#elif defined(VXWORKS)            /* vxworks lib */
+#define RMICRF_VXWORKS
+#include "stdio.h"
+#include <bootloader_include/types.h>
+#include "rmicrf/byteorder.h"
+#define inline __inline__
+#include <assert.h>
+#elif defined(LINUX)		  /* Linux userspace */
+#define RMICRF_LINUXU
+#include <sys/types.h>
+#include <stdint.h>
+#else
+/* newlib compilation with standalone */
+#include <sys/types.h>
+#define RMICRF_NEWLIB
+#include "stdio.h"
+#include "string.h"
+#include "assert.h"
+#include "rmicrf/byteorder.h"
+
+typedef __uint64_t uint64_t;
+typedef __uint32_t uint32_t;
+typedef __uint16_t uint16_t;
+typedef unsigned char  uint8_t;
+typedef signed char int8_t;
+typedef unsigned char u_int8_t;
+typedef short int16_t;
+typedef unsigned short u_int16_t;
+typedef int int32_t;
+typedef unsigned int u_int32_t;
+typedef long long int64_t;
+typedef unsigned long long u_int64_t;
+#endif
+
+/* Memory allocation and common functions for platforms */
+#ifdef RMICRF_NEWLIB
+extern void *rmi_malloc(size_t size);
+#define os_malloc	rmi_malloc
+#endif
+
+#if defined(RMICRF_LINUXK)	       /* Linux kernel */
+#define assert(x)	BUG_ON(!(x))
+#define printf		printk
+#define os_malloc(size) kmalloc(size, GFP_KERNEL)
+#endif
+
+#if defined(RMICRF_RMIOS)
+#define os_malloc	smp_malloc
+#endif
+
+/* RMI specific and commonly used macros and types */
+typedef uint64_t rmi_physaddr_t;
+typedef uint64_t rmi_addr_t;
+
+/* frequently required casting - static type check */
+#define rmi_addr_to_ptr(x)   ((void *)(long)(x))
+#define rmi_ptr_to_addr(x)   ((rmi_addr_t)(long)(x))
+#define rmi_ptr_to_u64(x)    ((uint64_t)(long)(x))
+#define rmi_u64_to_ptr(x)    ((void *)(long)(x))
+#define rmi_u32_to_ptr(x)    ((void *)(long)(int)(x))
+
+/* alignment */
+#define   rmi_align(x, y)     ((x) & (~((y)-1)))
+#define   rmi_roundup(x, y)   (rmi_align((x)+(y)-1, (y)))
+
+static inline rmi_physaddr_t rmi_kseg0_to_phys(rmi_addr_t addr)
+{
+	return  addr & 0x1fffffff;
+}
+
+static inline rmi_addr_t rmi_phys_to_kseg0(rmi_physaddr_t paddr)
+{
+	return  paddr | 0xffffffff80000000ULL;
+}
+
+static inline rmi_addr_t rmi_phys_to_kseg1(rmi_physaddr_t paddr)
+{
+        return  paddr | 0xffffffffA0000000ULL;
+}
+
+static inline int rmi_isfixmapped_addr(rmi_addr_t addr)
+{
+	return (addr >= 0xffffffff80000000ULL  &&
+		addr < 0xffffffffc0000000ULL);
+}
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/rmichip.h b/arch/mips/include/asm/rmi/rmidev/rmichip.h
new file mode 100644
index 0000000..74713e9
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/rmichip.h
@@ -0,0 +1,76 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMIDEV_CHIP_H
+#define _RMIDEV_CHIP_H
+
+/**
+* @file_name rmichip.h
+* @author RMICORP
+* @brief Basic definitions in RMI CHIP variances 
+*/
+
+/* chip versions */
+#define RMI_CHIP_XLR308		0x06
+#define RMI_CHIP_XLR532		0x09
+
+#define RMI_CHIP_XLR508_CHIP_XLR308_REV_GT4 0x07
+#define RMI_CHIP_XLR516_CHIP_XLR532_REV_GT4 0x08
+#define RMI_CHIP_XLR716_CHIP_XLR516_REV_GT4 0x0a
+#define RMI_CHIP_XLR732_CHIP_XLR508_REV_GT4 0x0b
+
+#define RMI_CHIP_XLR732 0x00
+#define RMI_CHIP_XLR716 0x02
+
+#define RMI_CHIP_XLS608 	0x80
+#define RMI_CHIP_XLS408		0x88
+#define RMI_CHIP_XLS404		0x8c
+#define RMI_CHIP_XLS208		0x8e
+#define RMI_CHIP_XLS204		0x8f
+#define RMI_CHIP_XLS108		0xce
+#define RMI_CHIP_XLS104		0xcf
+
+#define RMI_CHIP_XLS616_B0	0x40
+#define RMI_CHIP_XLS608_B0	0x4a
+#define RMI_CHIP_XLS416_B0	0x44
+#define RMI_CHIP_XLS412_B0	0x4c
+#define RMI_CHIP_XLS408_B0	0x4e
+#define RMI_CHIP_XLS404_B0	0x4f		
+
+
+
+enum rmi_chip_families {  RMI_CHIP_FAMILY_IS_XLR = 1, RMI_CHIP_FAMILY_IS_XLS = 2 };
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/uart.h b/arch/mips/include/asm/rmi/rmidev/uart.h
new file mode 100644
index 0000000..be2f521
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/uart.h
@@ -0,0 +1,66 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMIDEV_UART_H
+#define _RMIDEV_UART_H
+
+/**
+* @file_name uart.h
+* @author RMICORP
+* @brief Basic definitions in UART operations
+*/
+
+#define XLR_UART_RHR 0
+#define XLR_UART_THR 0
+#define XLR_UART_IER 1
+#define XLR_UART_IIR 2
+#define XLR_UART_FCR 2
+#define XLR_UART_LCR 3
+#define XLR_UART_MCR 4
+#define XLR_UART_LSR 5
+#define XLR_UART_MSR 6
+
+#define XLR_UART_DLB_1 0
+#define XLR_UART_DLB_2 1
+
+#define XLR_UART_DEBUG_1 8
+#define XLR_UART_DEBUG_2 9
+
+// baud rate divisors
+#define UART_BASE_BAUD (66000000 / 16)
+#define UART_BAUD_DEVISOR(baud) (UART_BASE_BAUD / baud)
+#define UART_DEFAULT_BAUD  38400
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/xlrcr.h b/arch/mips/include/asm/rmi/rmidev/xlrcr.h
new file mode 100644
index 0000000..01db0d1
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/xlrcr.h
@@ -0,0 +1,89 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+
+#ifndef _XLRCR_H
+#define _XLRCR_H
+
+/*
+ * XLR CPU Control Registers, these are per-core and can be accessed
+ * using the mtcr and mfcr intstructions
+ */
+
+#define XLR_CPU_BLOCKID_IFU      0
+#define XLR_CPU_BLOCKID_ICU      1
+#define XLR_CPU_BLOCKID_IEU      2
+#define XLR_CPU_BLOCKID_LSU      3
+#define XLR_CPU_BLOCKID_MMU      4
+#define XLR_CPU_BLOCKID_PRF      5
+
+#define XLR_IFU_THR_EN_REGID             0
+#define XLR_IFU_THR_SLEEP_REGID          1
+#define XLR_IFU_THR_SCHED_POLICY_REGID   2
+#define XLR_IFU_THR_SCHED_COUNTER_REGID  3
+#define XLR_IFU_BHR_PROG_MASK_REGID      4
+#define XLR_IFU_DISABLE_SB_SLEEP_REGID   5
+#define XLR_IFU_DEFEATURE_REGID          6
+#define XLR_IFU_SLEEP_STATE_REGID        16
+#define XLR_IFU_BHR_REGID                17
+#define XLR_IFU_IPG_0_REGID              20
+#define XLR_IFU_IPG_1_REGID              21
+#define XLR_IFU_IPG_2_REGID              22
+#define XLR_IFU_IPG_3_REGID              23
+#define XLR_IFU_RAS_0_REGID              24
+#define XLR_IFU_RAS_1_REGID              25
+#define XLR_IFU_RAS_2_REGID              26
+#define XLR_IFU_RAS_3_REGID              27
+#define XLR_IFU_RAS_4_REGID              28
+#define XLR_IFU_RAS_5_REGID              29
+#define XLR_IFU_RAS_6_REGID              30
+#define XLR_IFU_RAS_7_REGID              31
+#define XLR_IFU_BHT_0_31_REGID           64
+#define XLR_IFU_BHT_2016_2047_REGID      127
+
+#define XLR_LSU_CFG0_REGID       0
+#define XLR_LSU_CFG1_REGID       1
+#define XLR_LSU_CFG2_REGID       2
+#define XLR_LSU_CFG3_REGID       3
+#define XLR_LSU_CFG4_REGID       4
+#define XLR_LSU_STAT_REGID       5
+#define XLR_LSU_DEF_REGID        6
+#define XLR_LSU_DBG0_REGID       7
+#define XLR_LSU_DBG1_REGID       8
+#define XLR_LSU_CERRLOG_REGID    9
+#define XLR_LSU_CERROVF_REGID    10
+#define XLR_LSU_CERRINT_REGID    11
+
+#define XLR_IEU_DEFEATURE_REGID 0
+
+#define XLR_ICU_DEFEATURE_REGID 0
+
+#define XLR_MMU_SETUP_REGID 0
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/xlrextns.h b/arch/mips/include/asm/rmi/rmidev/xlrextns.h
new file mode 100644
index 0000000..467c130
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/xlrextns.h
@@ -0,0 +1,127 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+#ifndef _RMIDEV_XLREXTNS_H
+#define _RMIDEV_XLREXTNS_H
+
+/**
+* @file_name xlrextns.h
+* @author RMICORP
+* @brief Extended declarations and definitions for CPU operations 
+*
+* Extended access interface routines for CPU operations.
+*
+*/
+
+#include <rmidev/platform.h>
+
+static __inline__ int32_t xlr_swapw(int32_t *loc, int32_t val)
+{
+   int32_t oldval = 0;
+
+  __asm__ __volatile__ (
+	  ".set push\n"
+	  ".set noreorder\n"
+	  "move $9, %2\n"
+	  "move $8, %3\n"
+	  ".word 0x71280014\n"   /* "swapw $8, $9\n" */
+	  "move %1, $8\n"
+	  ".set pop\n"
+	  : "+m" (*loc), "=r" (oldval)
+	  : "r" (loc), "r" (val)
+	  : "$8", "$9" );
+
+  return oldval;
+}
+
+static __inline__ uint32_t xlr_swapwu(int32_t *loc, uint32_t val)
+{
+  uint32_t oldval;
+
+  __asm__ __volatile__ (
+	  ".set push\n"
+	  ".set noreorder\n"
+	  "move $9, %2\n"
+	  "move $8, %3\n"
+	  ".word 0x71280015\n"   /* "swapwu $8, $9\n" */
+	  "move %1, $8\n"
+	  ".set pop\n"
+	  : "+m" (*loc), "=r" (oldval)
+	  : "r" (loc), "r" (val)
+	  : "$8", "$9" );
+
+  return oldval;
+}
+
+#if (__mips == 64)
+static __inline__ uint64_t xlr_swapd(int32_t *loc, uint64_t val)
+{
+  uint64_t oldval;
+
+  __asm__ __volatile__ (
+	  ".set push\n"
+	  ".set noreorder\n"
+	  "move $9, %2\n"
+	  "move $8, %3\n"
+	  ".word 0x71280014\n"   /* "swapw $8, $9\n" */
+	  "move %1, $8\n"
+	  ".set pop\n"
+	  : "+m" (*loc), "=r" (oldval)
+	  : "r" (loc), "r" (val)
+	  : "$8", "$9" );
+
+  return oldval;
+}
+
+#endif
+static __inline__  uint64_t xlr_mfcr(uint32_t reg)
+{
+	uint32_t val;
+
+	__asm__ __volatile__ (
+		"move   $8, %1\n"
+		".word  0x71090018\n"
+		"move   %0, $9\n"
+		: "=r"(val)
+		: "r"(reg) : "$8", "$9");
+
+	return val;
+}
+
+static __inline__  void xlr_mtcr(uint32_t reg, uint64_t val)
+{
+	__asm__ __volatile__ (
+		"move   $8, %1\n"
+		"move   $9, %0\n"
+		".word  0x71090019\n"
+		::"r"(val), "r"(reg)
+		: "$8", "$9");
+}
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/xlrio.h b/arch/mips/include/asm/rmi/rmidev/xlrio.h
new file mode 100644
index 0000000..c918e2d
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/xlrio.h
@@ -0,0 +1,154 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files. 
+
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the distribution:
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+********************************#RMI_3#********************************/
+#ifndef _RMIDEV_XLRIO_H
+#define _RMIDEV_XLRIO_H
+
+/**
+* @file_name xlrio.h
+* @author RMICORP
+* @brief Basic Input and Output interface for registers
+*/
+
+#ifndef be32_to_cpu
+#warning "xlrio.h needs byteorder macros included before it"
+#endif
+
+extern uint32_t xlr_io_base;
+static __inline__ uint32_t xlr_read_reg(uint32_t base, int reg)
+{
+	volatile uint32_t *baseaddr = (uint32_t *)(long)(int)base;
+	uint32_t val = baseaddr[reg];
+	return be32_to_cpu(val);
+}
+
+static __inline__ void xlr_write_reg(uint32_t base, int reg, uint32_t value)
+{
+	volatile uint32_t *baseaddr = (uint32_t *)(long)(int)(base);
+	baseaddr[reg] = cpu_to_be32(value);
+}
+
+/* Below routines are used for Pcie-Dlink driver */
+static __inline void xlr_write_word_uncached(uint64_t physaddr, uint32_t value)
+{
+	__asm__ __volatile__ ("sw   %0, 0(%1)\n" 
+		 : : "r"(value), "r"(physaddr| 0x9000000000000000ULL));
+}
+
+static __inline void xlr_write_short_uncached(uint64_t physaddr, uint16_t value)
+{
+	__asm__ __volatile__ ("sh   %0, 0(%1)\n" 
+		 : : "r"(value), "r"(physaddr| 0x9000000000000000ULL));
+}
+
+static __inline void xlr_write_byte_uncached(uint64_t physaddr, uint8_t value)
+{
+	__asm__ __volatile__ ("sb   %0, 0(%1)\n" 
+		 : : "r"(value), "r"(physaddr| 0x9000000000000000ULL));
+}
+
+static __inline void xlr_write_word_cached(uint64_t physaddr, uint32_t value)
+{
+	__asm__ __volatile__ ("sw   %0, 0(%1)\n" 
+		 : : "r"(value), "r"(physaddr| 0x9800000000000000ULL));
+}
+
+static __inline void xlr_write_short_cached(uint64_t physaddr, uint16_t value)
+{
+	__asm__ __volatile__ ("sh   %0, 0(%1)\n" 
+		 : : "r"(value), "r"(physaddr| 0x9800000000000000ULL));
+}
+
+static __inline void xlr_write_byte_cached(uint64_t physaddr, uint8_t value)
+{
+	__asm__ __volatile__ ("sb   %0, 0(%1)\n" 
+		 : : "r"(value), "r"(physaddr| 0x9800000000000000ULL));
+}
+
+static __inline uint32_t xlr_read_word_uncached(uint64_t physaddr)
+{
+	uint32_t value;
+	__asm__ __volatile__ ("lw   %0, 0(%1)\n" 
+		 	      : "=r"(value)
+			      : "r"(physaddr| 0x9000000000000000ULL));
+	return value;
+}
+
+static __inline uint16_t xlr_read_short_uncached(uint64_t physaddr)
+{
+	uint16_t value;
+	__asm__ __volatile__ ("lh   %0, 0(%1)\n" 
+		 	      : "=r"(value)
+			      : "r"(physaddr| 0x9000000000000000ULL));
+	return value;
+}
+
+static __inline uint8_t xlr_read_byte_uncached(uint64_t physaddr)
+{
+	uint8_t value;
+	__asm__ __volatile__ ("lb   %0, 0(%1)\n" 
+		 	      : "=r"(value)
+			      : "r"(physaddr| 0x9000000000000000ULL));
+	return value;
+}
+
+static __inline uint32_t xlr_read_word_cached(uint64_t physaddr)
+{
+	uint32_t value;
+	__asm__ __volatile__ ("lw   %0, 0(%1)\n" 
+		 	      : "=r"(value)
+			      : "r"(physaddr| 0x9800000000000000ULL));
+	return value;
+}
+
+static __inline uint16_t xlr_read_short_cached(uint64_t physaddr)
+{
+	uint16_t value;
+	__asm__ __volatile__ ("lh   %0, 0(%1)\n" 
+		 	      : "=r"(value)
+			      : "r"(physaddr| 0x9800000000000000ULL));
+	return value;
+}
+
+static __inline uint8_t xlr_read_byte_cached(uint64_t physaddr)
+{
+	uint8_t value;
+	__asm__ __volatile__ ("lb   %0, 0(%1)\n" 
+		 	      : "=r"(value)
+			      : "r"(physaddr| 0x9800000000000000ULL));
+	return value;
+}
+
+#endif
diff --git a/arch/mips/include/asm/rmi/rmidev/xlrregs.h b/arch/mips/include/asm/rmi/rmidev/xlrregs.h
new file mode 100644
index 0000000..44e12b5
--- /dev/null
+++ b/arch/mips/include/asm/rmi/rmidev/xlrregs.h
@@ -0,0 +1,414 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED, unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+#ifndef _RMIDEV_XLRREGS_H
+#define _RMIDEV_XLRREGS_H
+
+/**
+* @file_name xlrregs.h
+* @author RMICORP
+* @brief Basic declarations and definitions for CPU operations 
+*
+* Register indexes and basic access interface routines for CPU operations.
+*
+*/
+
+#include <rmidev/platform.h>
+
+#define	XLR_C0_INDEX		0
+#define	XLR_C0_RANDOM		1
+#define	XLR_C0_ENTRYLO0		2
+#define	XLR_C0_ENTRYLO1		3
+#define	XLR_C0_CONTEXT		4
+#define	XLR_C0_PAGEMASK		5
+#define	XLR_C0_WIRED		6
+#define	XLR_C0_BADVADDR		8
+#define	XLR_C0_COUNT		9
+#define	XLR_C0_ENTRYHI		10
+#define	XLR_C0_COMPARE		11
+#define	XLR_C0_STATUS		12
+#define	XLR_C0_CAUSE		13
+#define	XLR_C0_EPC		14
+#define	XLR_C0_PRID		15
+#define	XLR_C0_EBASE		15
+#define	XLR_C0_CONFIG		16
+#define	XLR_C0_WATCHLO		18
+#define	XLR_C0_WATCHHI		19
+#define	XLR_C0_XCONTEXT		20
+#define	XLR_C0_SCRATCH		22
+#define	XLR_C0_DEBUG		23
+#define	XLR_C0_DEPC		24
+#define	XLR_C0_PERFCNT		25
+#define	XLR_C0_TAGLO		28
+#define	XLR_C0_DATALO		28
+#define	XLR_C0_TAGHI		29
+#define	XLR_C0_DATAHI		29
+#define	XLR_C0_ERROREPC		30
+#define	XLR_C0_DESAVE		31
+
+/*
+ * Register names for the o32 and o64 ABI
+ */
+#define XLR_REG_ZERO		0
+#define XLR_REG_AT		1
+#define XLR_REG_V0		2
+#define XLR_REG_V1		3
+#define XLR_REG_A0		4
+#define XLR_REG_A1		5
+#define XLR_REG_A2		6
+#define XLR_REG_A3		7
+#define XLR_REG_T0		8
+#define XLR_REG_T1		9
+#define XLR_REG_T2		10
+#define XLR_REG_T3		11
+#define XLR_REG_T4		12
+#define XLR_REG_T5		13
+#define XLR_REG_T6		14
+#define XLR_REG_T7		15
+#define XLR_REG_S0		16
+#define XLR_REG_S1		17
+#define XLR_REG_S2		18
+#define XLR_REG_S3		19
+#define XLR_REG_S4		20
+#define XLR_REG_S5		21
+#define XLR_REG_S6		22
+#define XLR_REG_S7		23
+#define XLR_REG_T8		24
+#define XLR_REG_T9		25
+#define XLR_REG_K0		26
+#define XLR_REG_K1		27
+#define XLR_REG_GP		28
+#define XLR_REG_SP		29
+#define XLR_REG_FP		30
+#define XLR_REG_RA		31
+
+#define xlr_memory_barrier()			\
+	__asm__ __volatile__(			\
+		".set	push\n\t"		\
+		".set	noreorder\n\t"		\
+		" sync\n\t"			\
+		".set	pop"			\
+		::: "memory")
+
+#define xlr_mfc0(reg, sel)                                      \
+({ uint32_t __rv;                                             \
+        __asm__ __volatile__(                                   \
+        ".set\tpush\n\t"                                        \
+        ".set\tnoreorder\n\t"                                   \
+        ".set\tmips64\n\t"                                      \
+        "mfc0\t%0,$%1,%2\n\t"                                   \
+        ".set\tpop"                                             \
+        : "=r" (__rv) : "i" (reg), "i" (sel) );                 \
+        __rv;})
+
+#define xlr_mtc0(reg,  sel, value)                              \
+        __asm__ __volatile__(                                   \
+        ".set\tpush\n\t"                                        \
+        ".set mips32\n\t"                                       \
+        ".set\tmips64\n\t"                                      \
+        "mtc0\t%0,$%1,%2\n\t"                                   \
+        ".set\tpop"                                             \
+        : : "r" (value), "i" (reg), "i" (sel) );
+
+
+#if (__mips == 64)
+#define xlr_dmfc0(reg, sel)                                     \
+({ uint64_t __rv;                                               \
+        __asm__ __volatile__(                                   \
+        ".set\tpush\n\t"                                        \
+        ".set\tnoreorder\n\t"                                   \
+        ".set mips64\n\t"                                       \
+        "dmfc0\t%0,$%1,%2\n\t"                                  \
+        ".set\tpop"                                             \
+        : "=r" (__rv) : "i" (reg), "i" (sel) );                 \
+        __rv;})
+
+#define xlr_dmtc0(reg,  sel, value)				\
+        __asm__ __volatile__(                                   \
+        ".set\tpush\n\t"                                        \
+        ".set mips64\n\t"                                       \
+        "dmtc0\t%0,$%1,%2\n\t"                                   \
+        ".set\tpop"                                             \
+        : : "r" (value), "i" (reg), "i" (sel) );
+
+#else
+#define xlr_dmfc0(reg, sel)					\
+   ({ unsigned int __high, __low;                               \
+        __asm__ __volatile__(                                   \
+        ".set\tpush\n\t"                                        \
+        ".set\tnoreorder\n\t"                                   \
+        ".set mips64\n\t"                                       \
+        "dmfc0\t $8, $%2, %3\n\t"                               \
+        "dsrl32\t%0, $8, 0\n\t"                                 \
+        "dsll32\t$8, $8, 0\n\t"                                 \
+        "dsrl32\t%1, $8, 0\n\t"                                 \
+        ".set\tpop"                                             \
+        : "=r"(__high), "=r"(__low): "i"(reg), "i"(sel): "$8" );\
+        (((unsigned long long)__high << 32) | __low);})
+
+#define xlr_dmtc0(reg, sel, value)				\
+ do{                                                            \
+       unsigned int __high = val>>32;                           \
+       unsigned int __low = val & 0xffffffff;                   \
+        __asm__ __volatile__(                                   \
+        ".set\tpush\n\t"                                        \
+        ".set\tnoreorder\n\t"                                   \
+        ".set mips64\n\t"                                       \
+        "dsll32\t$8, %1, 0\n\t"                                 \
+        "dsll32\t$9, %0, 0\n\t"                                 \
+        "or\t    $8, $8, $9\n\t"                                \
+        "dmtc0\t $8, $%2, %3\n\t"                               \
+        ".set\tpop"                                             \
+        :: "r"(__high), "r"(__low),  "i"(reg), "i"(sel):"$8", "$9");\
+   } while(0)
+#endif /* (__mips == 64) */
+
+#define XLR_DEFINE_ACCESSORS32(name, reg, sel) 			\
+static inline uint32_t xlr_read_c0_##name(void)	       	\
+{								\
+	return xlr_mfc0(reg, sel);				\
+}								\
+static inline void xlr_write_c0_##name(uint32_t val)		\
+{								\
+	xlr_mtc0(reg, sel, val);				\
+} struct __hack
+
+/* struct __hack above swallows a semicolon - otherwise the macro
+ * usage below cannot have the terminating semicolon */
+
+#define XLR_DEFINE_ACCESSORS64(name, reg, sel) 			\
+static inline uint64_t xlr_read_c0_##name(void)	       	\
+{								\
+	return xlr_dmfc0(reg, sel);				\
+}								\
+static inline void xlr_write_c0_##name(uint64_t val)		\
+{								\
+	xlr_dmtc0(reg, sel, val);				\
+} struct __hack
+
+XLR_DEFINE_ACCESSORS32(index, 0, 0);
+XLR_DEFINE_ACCESSORS32(random, 1, 0);
+XLR_DEFINE_ACCESSORS64(entrylo0, 2, 0);
+XLR_DEFINE_ACCESSORS64(entrylo1, 3, 0);
+XLR_DEFINE_ACCESSORS64(context, 4, 0);
+XLR_DEFINE_ACCESSORS32(pagemask, 5, 0);
+XLR_DEFINE_ACCESSORS32(wired, 6, 0);
+XLR_DEFINE_ACCESSORS64(badvaddr, 8, 0);
+XLR_DEFINE_ACCESSORS32(count, 9, 0);
+XLR_DEFINE_ACCESSORS64(eirr, 9, 6);
+XLR_DEFINE_ACCESSORS64(eimr, 9, 7);
+XLR_DEFINE_ACCESSORS64(entryhi, 10, 0);
+XLR_DEFINE_ACCESSORS32(compare, 11, 0);
+XLR_DEFINE_ACCESSORS32(status, 12, 0);
+XLR_DEFINE_ACCESSORS32(cause, 13, 0);
+XLR_DEFINE_ACCESSORS64(epc, 14, 0);
+XLR_DEFINE_ACCESSORS32(prid, 15, 0);
+XLR_DEFINE_ACCESSORS32(ebase, 15, 1);
+XLR_DEFINE_ACCESSORS32(config0, 16, 0);
+XLR_DEFINE_ACCESSORS32(config1, 16, 1);
+XLR_DEFINE_ACCESSORS32(config2, 16, 2);
+XLR_DEFINE_ACCESSORS32(config3, 16, 3);
+XLR_DEFINE_ACCESSORS32(config7, 16, 7);
+XLR_DEFINE_ACCESSORS64(watchlo0, 18, 0);
+XLR_DEFINE_ACCESSORS32(watchhi0, 19, 0);
+XLR_DEFINE_ACCESSORS64(xcontext, 20, 0);
+XLR_DEFINE_ACCESSORS64(scratch0, 22, 0);
+XLR_DEFINE_ACCESSORS64(scratch1, 22, 1);
+XLR_DEFINE_ACCESSORS64(scratch2, 22, 2);
+XLR_DEFINE_ACCESSORS64(scratch3, 22, 3);
+XLR_DEFINE_ACCESSORS64(scratch4, 22, 4);
+XLR_DEFINE_ACCESSORS64(scratch5, 22, 5);
+XLR_DEFINE_ACCESSORS64(scratch6, 22, 6);
+XLR_DEFINE_ACCESSORS64(scratch7, 22, 7);
+XLR_DEFINE_ACCESSORS32(debug, 23, 0);
+XLR_DEFINE_ACCESSORS32(depc, 24, 0);
+XLR_DEFINE_ACCESSORS32(perfcntrctl0, 25, 0);
+XLR_DEFINE_ACCESSORS32(perfcntr0, 25, 1);
+XLR_DEFINE_ACCESSORS32(perfcntrctl1, 25, 2);
+XLR_DEFINE_ACCESSORS32(perfcntr1, 25, 3);
+XLR_DEFINE_ACCESSORS64(taglo0, 28, 0);
+XLR_DEFINE_ACCESSORS64(taglo2, 28, 2);
+XLR_DEFINE_ACCESSORS64(taghi0, 29, 0);
+XLR_DEFINE_ACCESSORS64(taghi2, 29, 2);
+XLR_DEFINE_ACCESSORS64(errorepc, 30, 0);
+XLR_DEFINE_ACCESSORS64(desave, 31, 0);
+
+static inline int xlr_get_cpuid(void)
+{
+	return xlr_read_c0_ebase() & 0x1f; 
+}
+
+static inline int xlr_get_threadid(void)
+{
+	return xlr_read_c0_ebase() & 0x3;
+}
+
+static inline int xlr_get_coreid(void)
+{
+	return (xlr_read_c0_ebase() >> 2) & 0x7;
+}
+
+static inline void xlr_write_tlb_probe(void)
+{
+        __asm__ __volatile__(".set push   \n"
+                             ".set noreorder\n"
+                             "tlbp        \n"
+                             ".set pop");
+}
+
+static inline void xlr_write_tlb_indexed(void)
+{
+        __asm__ __volatile__(".set push   \n"
+                             ".set noreorder\n"
+                             "tlbwi        \n"
+                             ".set pop");
+}
+
+static inline void xlr_wait(void)
+{
+        __asm__ __volatile__(".set push   \n"
+                             ".set noreorder\n"
+                             "wait        \n"
+                             ".set pop");
+}
+
+
+
+#define XLR_KUSEG_START                0x0
+#define XLR_KSEG0_START                0x80000000
+#define XLR_KSEG0_END                  0x9fffffff
+#define XLR_KSEG1_START                0xa0000000
+#define XLR_KSEG1_END                  0xbfffffff
+#define XLR_KSEG2_START                0xc0000000
+#define XLR_KSEG3_START                0xe0000000
+#define XLR_KSEG3_END                  0xffffffff
+#define XLR_MAX_MEM_ADDR               0xbe000000
+#define XLR_RESERVED_ADDR              0xbfc80000
+
+#define XLR_PHYS_MASK                  0x1fffffff
+
+#define XLR_PHYS_KSEG0_END 					0x1fffffff
+#define XLR_PHYS_DMA_END 					(2048UL << 20)
+
+#define XLR_XKPHYS_CACHED   0x9800000000000000ULL
+#define XLR_XKPHYS_UNCACHED 0x9000000000000000ULL
+
+
+#define XLR_MSGRNG_CC_0_REG 16
+#define XLR_MSGRNG_CC_1_REG 17
+#define XLR_MSGRNG_CC_2_REG 18
+#define XLR_MSGRNG_CC_3_REG 19
+#define XLR_MSGRNG_CC_4_REG 20
+#define XLR_MSGRNG_CC_5_REG 21
+#define XLR_MSGRNG_CC_6_REG 22
+#define XLR_MSGRNG_CC_7_REG 23
+#define XLR_MSGRNG_CC_8_REG 24
+#define XLR_MSGRNG_CC_9_REG 25
+#define XLR_MSGRNG_CC_10_REG 26
+#define XLR_MSGRNG_CC_11_REG 27
+#define XLR_MSGRNG_CC_12_REG 28
+#define XLR_MSGRNG_CC_13_REG 29
+#define XLR_MSGRNG_CC_14_REG 30
+#define XLR_MSGRNG_CC_15_REG 31
+
+#define XLR_MSGRNG_CC_INIT_CPU_DEST(dest, conf) \
+do { \
+     xlr_mtc2(XLR_MSGRNG_CC_##dest##_REG, 0, conf[0] ); \
+     xlr_mtc2(XLR_MSGRNG_CC_##dest##_REG, 1, conf[1] ); \
+     xlr_mtc2(XLR_MSGRNG_CC_##dest##_REG, 2, conf[2] ); \
+     xlr_mtc2(XLR_MSGRNG_CC_##dest##_REG, 3, conf[3] ); \
+     xlr_mtc2(XLR_MSGRNG_CC_##dest##_REG, 4, conf[4] ); \
+     xlr_mtc2(XLR_MSGRNG_CC_##dest##_REG, 5, conf[5] ); \
+     xlr_mtc2(XLR_MSGRNG_CC_##dest##_REG, 6, conf[6] ); \
+     xlr_mtc2(XLR_MSGRNG_CC_##dest##_REG, 7, conf[7] ); \
+} while(0)
+
+
+#define XLR_MSGRNG_CC_GET_CPU_DEST(dest, conf) \
+do { \
+     conf[0] = xlr_mfc2(XLR_MSGRNG_CC_##dest##_REG, 0); \
+     conf[1] = xlr_mfc2(XLR_MSGRNG_CC_##dest##_REG, 1 ); \
+     conf[2] = xlr_mfc2(XLR_MSGRNG_CC_##dest##_REG, 2 ); \
+     conf[3] = xlr_mfc2(XLR_MSGRNG_CC_##dest##_REG, 3 ); \
+     conf[4] = xlr_mfc2(XLR_MSGRNG_CC_##dest##_REG, 4 ); \
+     conf[5] = xlr_mfc2(XLR_MSGRNG_CC_##dest##_REG, 5 ); \
+     conf[6] = xlr_mfc2(XLR_MSGRNG_CC_##dest##_REG, 6 ); \
+     conf[7] = xlr_mfc2(XLR_MSGRNG_CC_##dest##_REG, 7 ); \
+} while(0)
+
+#define xlr_clz(source)    \
+	({ unsigned int __res;                    \
+	 __asm__ __volatile__(                 \
+		 ".set\tpush\n\t"                  \
+		 ".set\tnoreorder\n\t"             \
+		 ".set\tmips32\n\t"                \
+		 "move\t$8,%1\n\t"                 \
+		 "clz\t%0,$8\n\t"                  \
+		 ".set\tpop"                       \
+		 : "=r"(__res): "r"(source): "$8");   \
+	 __res;})
+
+#define xlr_clo(source)   \
+	({ unsigned int __res;                    \
+	 __asm__ __volatile__(                 \
+		 ".set\tpush\n\t"                  \
+		 ".set\tnoreorder\n\t"             \
+		 ".set\tmips32\n\t"                \
+		 "move\t$8,%1\n\t"                 \
+		 "clo\t%0,$8\n\t"                  \
+		 ".set\tpop"                       \
+		 : "=r"(__res): "r"(source): "$8" );      \
+	 __res;})
+
+#define xlr_dclz(source)    \
+	({ unsigned int __res;                    \
+	 __asm__ __volatile__(                 \
+		 ".set\tpush\n\t"                  \
+		 ".set\tnoreorder\n\t"             \
+		 ".set\tmips32\n\t"                \
+		 "move\t$8,%1\n\t"                 \
+		 "dclz\t%0,$8\n\t"                 \
+		 ".set\tpop"                       \
+		 : "=r"(__res): "r"(source): "$8" );      \
+	 __res;})
+
+#define xlr_dclo(source)    \
+	({ unsigned int __res;                    \
+	 __asm__ __volatile__(                 \
+		 ".set\tpush\n\t"                  \
+		 ".set\tnoreorder\n\t"             \
+		 ".set\tmips32\n\t"                \
+		 "move\t$8,%1\n\t"                 \
+		 "dclo\t%0,$8\n\t"                 \
+		 ".set\tpop"                       \
+		 : "=r"(__res): "r"(source): "$8" );      \
+	 __res;})
+
+#endif
diff --git a/arch/mips/include/asm/rmi/sim.h b/arch/mips/include/asm/rmi/sim.h
new file mode 100644
index 0000000..e4bf509
--- /dev/null
+++ b/arch/mips/include/asm/rmi/sim.h
@@ -0,0 +1,453 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_SIM_H
+#define _ASM_SIM_H
+
+#include <linux/types.h>
+#include <asm/cpu.h>
+#include <asm/mipsregs.h>
+#define PSB_INFO_VERSION 0x0001
+
+struct psb_info {
+	uint64_t boot_level;
+	uint64_t io_base;
+	uint64_t output_device;
+	uint64_t uart_print;
+	uint64_t led_output;
+	uint64_t init;
+	uint64_t exit;
+	uint64_t warm_reset;
+	uint64_t wakeup;
+	uint64_t rmi_cpu_online_map;
+	uint64_t master_reentry_sp;
+	uint64_t master_reentry_gp;
+	uint64_t master_reentry_fn;
+	uint64_t slave_reentry_fn;
+	uint64_t magic_dword;
+	uint64_t uart_putchar;
+	uint64_t size;
+	uint64_t uart_getchar;
+	uint64_t nmi_handler;
+	uint64_t psb_version;
+	uint64_t mac_addr;
+	uint64_t cpu_frequency;
+	uint64_t board_version;
+	uint64_t malloc;
+	uint64_t free;
+	uint64_t global_shmem_addr;
+	uint64_t global_shmem_size;
+	uint64_t psb_os_cpu_map;
+	uint64_t userapp_cpu_map;
+	uint64_t wakeup_os;
+	uint64_t psb_mem_map;
+	uint64_t board_major_version;
+	uint64_t board_minor_version;
+	uint64_t board_manf_revision;
+	uint64_t board_serial_number;
+	uint64_t psb_physaddr_map;
+	uint64_t xlr_loaderip_config;
+	uint64_t bldr_envp;
+	uint64_t avail_mem_map;
+};
+
+
+enum {
+        PHOENIX_IO_SPACE = 0x10,
+        PCIX_IO_SPACE,
+        PCIX_CFG_SPACE,
+        PCIX_MEMORY_SPACE,
+        HT_IO_SPACE,
+        HT_CFG_SPACE,
+        HT_MEMORY_SPACE,
+        SRAM_SPACE,
+        FLASH_CONTROLLER_SPACE
+};
+
+extern struct psb_info *prom_info;
+
+#define MAX_ENV_BUF 0x00020000 // 128 KB = One sector of Intel flash.
+struct environment
+{
+        unsigned int crc;
+        unsigned char envbuf[MAX_ENV_BUF - 20]; // 4 bytes for CRC and 16 bytes reserved.
+        unsigned char reserved[16];
+};
+
+#define RMI_PHOENIX_BOARD_ARIZONA_I   1
+#define RMI_PHOENIX_BOARD_ARIZONA_II  2
+#define RMI_PHOENIX_BOARD_ARIZONA_III 3
+#define RMI_PHOENIX_BOARD_ARIZONA_IV  4
+#define RMI_PHOENIX_BOARD_ARIZONA_V   5
+#define RMI_PHOENIX_BOARD_ARIZONA_VI   6  /* XLS boards */
+#define RMI_PHOENIX_BOARD_ARIZONA_VII 7 /*XLS 2xx boards*/
+#define RMI_PHOENIX_BOARD_ARIZONA_VIII 8 /*XLS LTE boards*/
+#define RMI_PHOENIX_BOARD_ARIZONA_XI 11
+#define RMI_PHOENIX_BOARD_ARIZONA_XII  12
+
+struct smp_boot_info_percpu {
+  volatile unsigned long ready;
+  volatile unsigned long sp;
+  volatile unsigned long gp;
+  volatile unsigned long fn;
+};
+
+struct smp_boot_info {
+  struct smp_boot_info_percpu boot_info[32];
+  __u32 online_map;
+};
+
+extern struct smp_boot_info smp_boot;
+extern void prom_boot_cpus_secondary(void *);
+
+extern __u32 xlr_board_major_version;
+extern __u32 xlr_board_minor_version;
+
+#define XLR_REVISION_A0 0xc0000
+#define XLR_REVISION_A1 0xc0001
+#define XLR_REVISION_B0 0xc0002
+#define XLR_REVISION_B1 0xc0003
+#define XLR_REVISION_B2 0xc0004
+#define XLR_REVISION_C0 0xc0005
+#define XLR_REVISION_C1 0xc0006
+#define XLR_REVISION_C2 0xc0007
+#define XLR_REVISION_C3 0xc0008
+#define XLR_REVISION_C4 0xc0009
+
+#define XLP_REVISION_A0 0xc0010
+
+static __inline__ unsigned int xlr_revision(void)
+{
+	return read_c0_prid() & 0xff00ff;
+}
+
+static __inline__ int xlr_revision_a0(void)
+{
+	return xlr_revision() == XLR_REVISION_A0;
+}
+
+static __inline__ int xlr_revision_b0(void)
+{
+	return xlr_revision() == XLR_REVISION_B0;
+}
+
+static __inline__ int xlr_revision_b1(void)
+{
+        return xlr_revision() == XLR_REVISION_B1;
+}
+
+static __inline__ int xlr_revision_c(void)
+{
+    uint32_t prid = read_c0_prid();
+    if(prid>=XLR_REVISION_C0 && prid<=XLR_REVISION_C4)
+        return 1;        
+    return 0; 
+}
+
+static __inline__ int xlr_board_atx_i(void)
+{
+	return xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_I;
+}
+
+static __inline__ int xlr_board_atx_ii(void)
+{
+	return xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_II;
+}
+
+static __inline__ int xlr_board_atx_ii_b(void)
+{
+	return (xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_II)
+		&& (xlr_board_minor_version == 1);
+}
+
+static __inline__ int xlr_board_atx_iii(void)
+{
+	return xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_III;
+}
+
+static __inline__ int xlr_board_atx_iv(void)
+{
+	return (xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_IV)
+		&& (xlr_board_minor_version == 0);
+}
+
+static __inline__ int xlr_board_atx_iv_b(void)
+{
+	return (xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_IV)
+		&& (xlr_board_minor_version == 1);
+}
+
+static __inline__ int xlr_board_atx_v(void)
+{
+	return xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_V;
+}
+
+static __inline__ int xlr_board_atx_iii_256(void)
+{
+	return (xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_III)
+		&& (xlr_board_minor_version == 0);
+}
+
+static __inline__ int xlr_board_atx_iii_512(void)
+{
+	return (xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_III)
+		&& (xlr_board_minor_version == 1);
+}
+
+static __inline__ int xlr_board_atx_v_512(void)
+{
+	return (xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_V)
+		&& (xlr_board_minor_version == 1);
+}
+
+static __inline__ int xlr_board_atx_vi(void)
+{
+	return (xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_VI);
+}
+
+static __inline__ int xlr_board_atx_vii(void)
+{
+	return (xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_VII);
+}
+
+static __inline__ int xlr_board_atx_viii(void)
+{
+	return (xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_VIII);
+}
+
+static __inline__ int xlr_board_atx_xi(void)
+{
+	return (xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_XI);
+}
+
+static __inline__ int xlr_board_atx_xii(void)
+{
+	return (xlr_board_major_version == RMI_PHOENIX_BOARD_ARIZONA_XII);
+}
+
+static __inline__ int xlr_board_atx_xaui_rework(void)
+{
+	if ((xlr_board_atx_xi() || xlr_board_atx_xii()) &&
+			(xlr_board_minor_version == 4))
+		return 1;
+	else
+		return 0;
+}
+
+
+#define XLR_HYBRID_NONE              0
+#define XLR_HYBRID_USER_MAC          1
+#define XLR_HYBRID_RMIOS_IPSEC       2
+#define XLR_HYBRID_RMIOS_TCPIP_STACK 3
+#define XLR_HYBRID_USER_MAC_GMAC     4
+#define XLR_HYBRID_USER_MAC_XGMAC    5
+#define XLR_HYBRID_USER_MAC_SPI4     6
+#define XLR_HYBRID_USER_MAC_GMAC_XGMAC    7
+#define XLR_HYBRID_USER_MAC_GMAC_SPI4     8
+
+extern int xlr_hybrid;
+
+static __inline__ int xlr_hybrid_user_mac(void)
+{
+	return xlr_hybrid == XLR_HYBRID_USER_MAC;
+}
+
+static __inline__ int xlr_hybrid_user_mac_xgmac(void)
+{
+	return (xlr_hybrid == XLR_HYBRID_USER_MAC_XGMAC || 
+		xlr_hybrid == XLR_HYBRID_USER_MAC_SPI4);
+}
+
+static __inline__ int xlr_hybrid_rmios_tcpip_stack(void)
+{
+        return xlr_hybrid == XLR_HYBRID_RMIOS_TCPIP_STACK;
+}
+
+static __inline__ int xlr_hybrid_rmios_ipsec(void)
+{
+	return xlr_hybrid == XLR_HYBRID_RMIOS_IPSEC;
+}
+
+static __inline__ int xlr_hybrid_none(void)
+{
+	return xlr_hybrid == XLR_HYBRID_NONE;
+}
+
+struct boot_mem_map_entry *psb_get_physaddr_base_address(unsigned long type);
+
+
+#define CHIP_PROCESSOR_ID_XLS_608   0x80
+#define CHIP_PROCESSOR_ID_XLS_408   0x88
+#define CHIP_PROCESSOR_ID_XLS_404   0x8c
+#define CHIP_PROCESSOR_ID_XLS_208   0x8e
+#define CHIP_PROCESSOR_ID_XLS_204   0x8f
+#define CHIP_PROCESSOR_ID_XLS_108   0xce
+#define CHIP_PROCESSOR_ID_XLS_104   0xcf
+
+/* Defines for XLS B0*/
+#define CHIP_PROCESSOR_ID_XLS_616_B0   0x40
+#define CHIP_PROCESSOR_ID_XLS_608_B0   0x4a
+#define CHIP_PROCESSOR_ID_XLS_416_B0   0x44
+#define CHIP_PROCESSOR_ID_XLS_412_B0   0x4c
+#define CHIP_PROCESSOR_ID_XLS_408_B0   0x4e
+#define CHIP_PROCESSOR_ID_XLS_404_B0   0x4f
+
+#define CHIP_PROCESSOR_ID_XLR_B_308   0x06
+#define CHIP_PROCESSOR_ID_XLR_B_508   0x07
+#define CHIP_PROCESSOR_ID_XLR_B_516   0x08
+#define CHIP_PROCESSOR_ID_XLR_B_532   0x09
+#define CHIP_PROCESSOR_ID_XLR_B_716   0x0a
+#define CHIP_PROCESSOR_ID_XLR_B_732   0x0b
+
+#define CHIP_PROCESSOR_ID_XLR_C_308   0x0F
+#define CHIP_PROCESSOR_ID_XLR_C_508   0x0b
+#define CHIP_PROCESSOR_ID_XLR_C_516   0x0a
+#define CHIP_PROCESSOR_ID_XLR_C_532   0x08
+#define CHIP_PROCESSOR_ID_XLR_C_716   0x02
+
+#if defined(CONFIG_RMI_XLP)
+/* Fake Values for bring-up */
+#define CHIP_PROCESSOR_ID_XLP_A_832   0x00
+#define CHIP_PROCESSOR_ID_XLR_C_732   0xff
+#else
+/* Real Values */
+#define CHIP_PROCESSOR_ID_XLP_A_832   0x90
+#define CHIP_PROCESSOR_ID_XLR_C_732   0x00
+#endif
+
+/*  fill the xls chip family types 
+ */
+extern int chip_is_xls6xx;
+extern int chip_is_xls4xx;
+extern int chip_is_xls2xx;
+extern int chip_is_xls1xx;
+extern int chip_is_xls;
+extern int chip_is_xls_b0;
+extern int chip_is_xls6xx_b0;
+extern int chip_is_xls4xx_b0;
+
+static __inline__ void set_xls_chip_family_types(void)
+{
+	int processor_id = ((read_c0_prid() & 0xff00) >> 8);
+	chip_is_xls = 1;
+	switch (processor_id) {
+        case CHIP_PROCESSOR_ID_XLS_608: 
+		{
+			chip_is_xls6xx = 1;
+			break;
+		}
+        case CHIP_PROCESSOR_ID_XLS_408:
+        case CHIP_PROCESSOR_ID_XLS_404:
+		{
+			chip_is_xls4xx = 1;
+			break;
+		}
+        case CHIP_PROCESSOR_ID_XLS_208:
+        case CHIP_PROCESSOR_ID_XLS_204:
+		{
+			chip_is_xls2xx = 1;
+			break;
+		}
+        case CHIP_PROCESSOR_ID_XLS_108:
+        case CHIP_PROCESSOR_ID_XLS_104:
+		{
+			chip_is_xls1xx = 1;
+			break;
+		}
+        case CHIP_PROCESSOR_ID_XLS_616_B0:
+        case CHIP_PROCESSOR_ID_XLS_608_B0:
+		{
+			chip_is_xls_b0 = 1;
+			chip_is_xls6xx_b0 = 1;
+			break;
+		}
+        case CHIP_PROCESSOR_ID_XLS_416_B0:
+        case CHIP_PROCESSOR_ID_XLS_412_B0:
+        case CHIP_PROCESSOR_ID_XLS_408_B0:
+        case CHIP_PROCESSOR_ID_XLS_404_B0:
+		{
+			chip_is_xls_b0 = 1;
+			chip_is_xls4xx_b0 = 1;
+			break;
+		}
+        default:
+			chip_is_xls = 0;
+	}
+	return;
+}
+
+static __inline__ int is_xls(void)
+{
+	return chip_is_xls;
+}
+
+static __inline__ int is_xls2xx(void)
+{
+	return chip_is_xls2xx;
+}
+
+static __inline__ int is_xls1xx(void)
+{
+	return chip_is_xls1xx;
+}
+
+static __inline__ int is_xls4xx(void)
+{
+	return chip_is_xls4xx;
+}
+
+static __inline__ int is_xls6xx(void)
+{
+	return chip_is_xls6xx;
+}
+
+static __inline__ int is_xls_b0_4xx(void)
+{
+	return chip_is_xls4xx_b0;
+}
+
+static __inline__ int is_xls_b0_6xx(void)
+{
+	return chip_is_xls6xx_b0;
+}
+
+static __inline__ int is_xls_b0(void)
+{
+	return chip_is_xls_b0;
+}
+
+
+
+#define NR_CORES 8
+#define NR_CPUS_PER_CORE 4
+#define RMI_MAX_ARGS 64
+#define RMI_MAX_ENVS 32
+
+#endif /* _ASM_SIM_H */
diff --git a/arch/mips/include/asm/rmi/utils.h b/arch/mips/include/asm/rmi/utils.h
new file mode 100644
index 0000000..bed94fe
--- /dev/null
+++ b/arch/mips/include/asm/rmi/utils.h
@@ -0,0 +1,88 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifdef CONFIG_64BIT
+#define LLX_FMT "lx"
+#define LLD_FMT "ld"
+#define LLU_FMT "lu"
+#else
+#define LLX_FMT "llx"
+#define LLD_FMT "lld"
+#define LLU_FMT "llu"
+#endif
+
+#define find_32bit_1st_one_bit(source)    \
+({ unsigned int __res;                    \
+    __asm__ __volatile__(                 \
+	".set\tpush\n\t"                  \
+	".set\tnoreorder\n\t"             \
+        ".set\tmips32\n\t"                \
+	"move\t$8,%1\n\t"                 \
+	"clz\t%0,$8\n\t"                  \
+	".set\tpop"                       \
+	: "=r"(__res): "r"(source): "$8");   \
+    __res;})
+
+#define find_32bit_1st_zero_bit(source)   \
+({ unsigned int __res;                    \
+    __asm__ __volatile__(                 \
+	".set\tpush\n\t"                  \
+	".set\tnoreorder\n\t"             \
+        ".set\tmips32\n\t"                \
+	"move\t$8,%1\n\t"                 \
+	"clo\t%0,$8\n\t"                  \
+	".set\tpop"                       \
+	: "=r"(__res): "r"(source): "$8" );      \
+    __res;})
+
+#define find_64bit_1st_one_bit(source)    \
+({ unsigned int __res;                    \
+    __asm__ __volatile__(                 \
+	".set\tpush\n\t"                  \
+	".set\tnoreorder\n\t"             \
+        ".set\tmips32\n\t"                \
+	"move\t$8,%1\n\t"                 \
+	"dclz\t%0,$8\n\t"                 \
+	".set\tpop"                       \
+	: "=r"(__res): "r"(source): "$8" );      \
+    __res;})
+
+#define find_64bit_1st_zero_bit(source)    \
+({ unsigned int __res;                    \
+    __asm__ __volatile__(                 \
+	".set\tpush\n\t"                  \
+	".set\tnoreorder\n\t"             \
+        ".set\tmips32\n\t"                \
+	"move\t$8,%1\n\t"                 \
+	"dclo\t%0,$8\n\t"                 \
+	".set\tpop"                       \
+	: "=r"(__res): "r"(source): "$8" );      \
+    __res;})
+
diff --git a/arch/mips/include/asm/rmi/xgmac_mdio.h b/arch/mips/include/asm/rmi/xgmac_mdio.h
new file mode 100644
index 0000000..438b7de
--- /dev/null
+++ b/arch/mips/include/asm/rmi/xgmac_mdio.h
@@ -0,0 +1,119 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+// MDIO Low level Access routines
+// All Phy's accessed from GMAC0 base
+
+#ifndef _XGMAC_MDIO
+#define _XGMAC_MDIO
+
+static inline int xmdio_read  (volatile unsigned int *_mmio,
+		uint32_t phy_addr, uint32_t address) ;
+static inline void xmdio_write (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t address, uint32_t data) ;
+static inline void xmdio_address (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t dev_ad, uint32_t address) ;
+
+// function prototypes
+static inline int xmdio_read  (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t address) {
+	uint32_t st_field = 0x0 ;
+	uint32_t op_type  = 0x3 ; // read operation
+	uint32_t ta_field = 0x2 ; // ta field
+	uint32_t data = 0 ;
+
+        xmdio_address (_mmio, phy_addr, 5, address) ;
+	_mmio [0x11] =  ( ( st_field & 0x3    ) << 30 ) |
+		( ( op_type  & 0x3    ) << 28 ) | 
+		( ( phy_addr & 0x1F   ) << 23 ) | 
+		( ( 5  & 0x1F   ) << 18 ) | 
+		( ( ta_field & 0x3    ) << 16 ) | 
+		( ( data     & 0xffff ) <<  0 ) ;
+
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x1 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+
+	// wait for write cycle to complete
+	while (_mmio [0x14] & 0x1) {
+	} ; 
+
+	data = _mmio [0x11] & 0xffff ;
+	return (data);
+}
+ 
+static inline void xmdio_write (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t address, uint32_t data) {
+	uint32_t st_field = 0x0 ;
+	uint32_t op_type  = 0x1 ; // write operation
+	uint32_t ta_field = 0x2 ; // ta field
+
+        xmdio_address ( _mmio, phy_addr, 5, address) ;
+	_mmio [0x11] =  ( ( st_field & 0x3    ) << 30 ) |
+		( ( op_type  & 0x3    ) << 28 ) | 
+		( ( phy_addr & 0x1F   ) << 23 ) | 
+		( ( 5  & 0x1F   ) << 18 ) | 
+		( ( ta_field & 0x3    ) << 16 ) | 
+		( ( data     & 0xffff ) <<  0 ) ;
+
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x1 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+
+	// wait for write cycle to complete
+	while (_mmio [0x14] & 0x1) {
+	} ; 
+
+}
+
+static inline void xmdio_address (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t dev_ad, uint32_t address) {
+	uint32_t st_field = 0x0 ;
+	uint32_t op_type  = 0x0 ; // address operation
+	uint32_t ta_field = 0x2 ; // ta field
+
+	_mmio [0x11] =  ( ( st_field & 0x3    ) << 30 ) |
+		( ( op_type  & 0x3    ) << 28 ) | 
+		( ( phy_addr & 0x1F   ) << 23 ) | 
+		( ( dev_ad  & 0x1F   ) << 18 ) | 
+		( ( ta_field & 0x3    ) << 16 ) | 
+		( ( address  & 0xffff ) <<  0 ) ;
+
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x1 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+
+	// wait for dev_ad cycle to complete
+	while (_mmio [0x14] & 0x1) {
+	} ; 
+
+}
+ 
+#endif
diff --git a/arch/mips/include/asm/rmi/xlr_pcix_boot.h b/arch/mips/include/asm/rmi/xlr_pcix_boot.h
new file mode 100644
index 0000000..8dc3056
--- /dev/null
+++ b/arch/mips/include/asm/rmi/xlr_pcix_boot.h
@@ -0,0 +1,42 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef __PCIX_BOOT_H__
+#define __PCIX_BOOT_H__
+
+#define PCIX_BOOT_FILE_START    (2<<20)
+#define PCIX_BOOT_ARG_CNT_OFF   0x100 /* Number of args */
+#define PCIX_BOOT_ARGS_LEN_OFF  0x104 /* Total length of the args */
+#define PCIX_BOOT_ARGS_OFF      0x108 /*  args string */
+#define PCIX_BOOT_MAGIC         0xa5a5a5a5
+
+
+#endif
+
diff --git a/arch/mips/include/asm/rmi/xlr_virt_uart.h b/arch/mips/include/asm/rmi/xlr_virt_uart.h
new file mode 100644
index 0000000..8bbc4e0
--- /dev/null
+++ b/arch/mips/include/asm/rmi/xlr_virt_uart.h
@@ -0,0 +1,68 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_XLR_VIRT_UART_H
+#define _ASM_XLR_VIRT_UART_H
+
+typedef struct test{
+        volatile unsigned char *tx_fifo;
+        volatile unsigned int *tx_pro;
+        volatile unsigned int  *tx_con;
+        volatile unsigned char *rx_fifo;
+        volatile unsigned int *rx_pro;
+        volatile unsigned int *rx_con;
+        volatile int *status;
+}virt_uart_struct;
+
+typedef struct outbyte_struct{
+      volatile unsigned char *rx_fifo;
+      volatile unsigned int *rx_pro;
+      volatile unsigned int  *rx_con;
+      volatile unsigned char *tx_fifo;
+      volatile unsigned int *tx_pro;
+      volatile unsigned int *tx_con;
+      volatile int *status;
+}virt_uart;
+
+#define USER_CMD_SIZE 			  (1*1024)
+#define USER_RESULT_SIZE 		  (7*1024)
+#define DELAY_TIME                         2
+#define VIRTUAL_UART_CONSOLE      	  "virt_uart"
+#define VIRTUAL_UART_CONSOLE_MAJOR        XLR_VIRT_UART_MAJOR
+#define VIRTUAL_UART_CONSOLE_MINOR        200
+#define VIRTUAL_UART_NR                   32
+#define VIRT_UART_OPENED 		  0xeadbeef
+#ifdef CONFIG_64BIT
+#define VIRT_UART_BUF_START               ((48<<20) | 0xffffffff80000000ULL)
+#else
+#define VIRT_UART_BUF_START               ((48<<20) | 0x80000000)
+#endif
+#endif
+
diff --git a/arch/mips/include/asm/smp.h b/arch/mips/include/asm/smp.h
index d4fb4d8..e33ea07 100644
--- a/arch/mips/include/asm/smp.h
+++ b/arch/mips/include/asm/smp.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General
  * Public License.  See the file "COPYING" in the main directory of this
@@ -13,7 +25,9 @@
 
 #include <linux/bitops.h>
 #include <linux/linkage.h>
+#ifndef CONFIG_RMI_PHOENIX
 #include <linux/smp.h>
+#endif
 #include <linux/threads.h>
 #include <linux/cpumask.h>
 
@@ -44,6 +58,7 @@ extern int __cpu_logical_map[NR_CPUS];
 extern volatile cpumask_t cpu_callin_map;
 
 extern void asmlinkage smp_bootstrap(void);
+extern void core_send_ipi(int cpu, unsigned int action);
 
 /*
  * this function sends a 'reschedule' IPI to another CPU.
diff --git a/arch/mips/include/asm/timex.h b/arch/mips/include/asm/timex.h
index 6c15097..d74d6fa 100644
--- a/arch/mips/include/asm/timex.h
+++ b/arch/mips/include/asm/timex.h
@@ -135,6 +135,11 @@ static inline int unsynchronized_tsc(void)
 	return !tsc_is_sync();
 }
 
+#ifdef CONFIG_RMI_PHOENIX
+#define ARCH_HAS_READ_CURRENT_TIMER	1
+extern int read_current_timer(unsigned long *timer_val);
+#endif /* CONFIG_RMI_PHOENIX */
+
 #endif /* __KERNEL__ */
 
 #endif /*  _ASM_TIMEX_H */
diff --git a/arch/mips/include/asm/unistd.h b/arch/mips/include/asm/unistd.h
index ba58a32..b2bca5d 100644
--- a/arch/mips/include/asm/unistd.h
+++ b/arch/mips/include/asm/unistd.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -368,16 +380,22 @@
 #define __NR_process_vm_readv		(__NR_Linux + 345)
 #define __NR_process_vm_writev		(__NR_Linux + 346)
 #define __NR_msa			(__NR_Linux + 347)
+#define __NR_vperfctr                   (__NR_Linux + 348)
+#define __NR_vperfctr_open              (__NR_vperfctr + 0)
+#define __NR_vperfctr_control           (__NR_vperfctr + 1)
+#define __NR_vperfctr_unlink            (__NR_vperfctr + 2)
+#define __NR_vperfctr_iresume           (__NR_vperfctr + 3)
+#define __NR_vperfctr_read              (__NR_vperfctr + 4)
 
 /*
  * Offset of the last Linux o32 flavoured syscall
  */
-#define __NR_Linux_syscalls		347
+#define __NR_Linux_syscalls		353
 
 #endif /* _MIPS_SIM == _MIPS_SIM_ABI32 */
 
 #define __NR_O32_Linux			4000
-#define __NR_O32_Linux_syscalls		347
+#define __NR_O32_Linux_syscalls		353
 
 #if _MIPS_SIM == _MIPS_SIM_ABI64
 
@@ -692,16 +710,22 @@
 #define __NR_process_vm_readv		(__NR_Linux + 304)
 #define __NR_process_vm_writev		(__NR_Linux + 305)
 #define __NR_msa			(__NR_Linux + 306)
+#define __NR_vperfctr                   (__NR_Linux + 307)
+#define __NR_vperfctr_open              (__NR_vperfctr + 0)
+#define __NR_vperfctr_control           (__NR_vperfctr + 1)
+#define __NR_vperfctr_unlink            (__NR_vperfctr + 2)
+#define __NR_vperfctr_iresume           (__NR_vperfctr + 3)
+#define __NR_vperfctr_read              (__NR_vperfctr + 4)
 
 /*
  * Offset of the last Linux 64-bit flavoured syscall
  */
-#define __NR_Linux_syscalls		306
+#define __NR_Linux_syscalls		312
 
 #endif /* _MIPS_SIM == _MIPS_SIM_ABI64 */
 
 #define __NR_64_Linux			5000
-#define __NR_64_Linux_syscalls		306
+#define __NR_64_Linux_syscalls		312
 
 #if _MIPS_SIM == _MIPS_SIM_NABI32
 
@@ -1021,16 +1045,22 @@
 #define __NR_process_vm_readv		(__NR_Linux + 309)
 #define __NR_process_vm_writev		(__NR_Linux + 310)
 #define __NR_msa			(__NR_Linux + 311)
+#define __NR_vperfctr                   (__NR_Linux + 312)
+#define __NR_vperfctr_open              (__NR_vperfctr + 0)
+#define __NR_vperfctr_control           (__NR_vperfctr + 1)
+#define __NR_vperfctr_unlink            (__NR_vperfctr + 2)
+#define __NR_vperfctr_iresume           (__NR_vperfctr + 3)
+#define __NR_vperfctr_read              (__NR_vperfctr + 4)
 
 /*
  * Offset of the last N32 flavoured syscall
  */
-#define __NR_Linux_syscalls		311
+#define __NR_Linux_syscalls		317
 
 #endif /* _MIPS_SIM == _MIPS_SIM_NABI32 */
 
 #define __NR_N32_Linux			6000
-#define __NR_N32_Linux_syscalls		311
+#define __NR_N32_Linux_syscalls		317
 
 #ifdef __KERNEL__
 
diff --git a/arch/mips/include/asm/xlr_macros.h b/arch/mips/include/asm/xlr_macros.h
new file mode 100644
index 0000000..9d87855
--- /dev/null
+++ b/arch/mips/include/asm/xlr_macros.h
@@ -0,0 +1,117 @@
+#ifndef _XLR_MACROS_H
+#define _XLR_MACROS_H
+
+#ifndef __ASSEMBLY__
+
+#ifdef CONFIG_32BIT
+#define XKPHYS        0x8000000000000000ULL
+#endif
+
+#define CCA_UNCACHED  0x1000000000000000ULL
+#define CCA_CACHED    0x1800000000000000ULL
+
+#define enable_KX(flags)   \
+  preempt_disable();       \
+ __asm__ __volatile__ (    \
+	".set push\n"          \
+	".set noat\n"          \
+	".set noreorder\n"     \
+	"mfc0 %0, $12\n\t"     \
+	"ori $1, %0, 0x81\n\t" \
+	"xori $1, 1\n\t"       \
+	"mtc0 $1, $12\n"       \
+    ".set pop\n"           \
+    : "=r"(flags) );       \
+  preempt_enable();
+	
+#define disable_KX(flags)  \
+ __asm__ __volatile__ (    \
+	".set push\n"          \
+	"mtc0 %0, $12\n"       \
+    ".set pop\n"           \
+    :                      \
+    : "r"(flags))
+
+static __inline__ uint8_t lb_40bit_phys(uint64_t phys, uint64_t cca)
+{
+	uint32_t lsw, msw;
+	uint8_t value;
+	unsigned long flags;
+
+	phys &= 0xffffffffffULL;
+	phys |= (XKPHYS | cca);
+	lsw = (uint32_t) phys & 0xffffffff;
+	msw = (uint32_t) (phys >> 32);
+
+	enable_KX(flags);
+	__asm__ __volatile__(
+		".set push\n"
+        ".set noreorder\n"
+        ".set mips64\n"
+		".set noat\n"
+		"dsll32 $1, %2, 0\n"
+		"dsll32 %1, 0\n"
+		"dsrl32 %1, 0\n"
+        "or $1, $1, %1\n"
+        "lb %0, 0($1) \n"
+		".set at\n"
+        ".set pop\n"
+        : "=r"(value)
+        : "r"(lsw), "r"(msw)
+
+		: "$1"
+		);
+	disable_KX(flags);
+
+	return value;
+}
+static __inline__ uint8_t lb_40bit_phys_uncached(uint64_t phys)
+{
+        return lb_40bit_phys(phys, CCA_UNCACHED);
+}
+static __inline__ uint8_t lb_40bit_phys_cached(uint64_t phys)
+{
+        return lb_40bit_phys(phys, CCA_CACHED);
+}
+
+static __inline__ void sb_40bit_phys(uint64_t phys, uint64_t cca, uint8_t value)
+{
+	uint32_t lsw, msw;
+	unsigned long flags;
+
+	phys &= 0xffffffffffULL;
+	phys |= (XKPHYS | cca);
+	lsw = (uint32_t) phys & 0xffffffff;
+	msw = (uint32_t) (phys >> 32);
+	
+	enable_KX(flags);
+	__asm__ __volatile__(
+		".set push\n"
+        ".set noreorder\n"
+        ".set mips64\n"
+		".set noat\n"
+		"dsll32 $1, %2, 0\n"
+		"dsll32 %1, 0\n"
+		"dsrl32 %1, 0\n"
+        "or $1, $1, %1\n"
+        "sb %0, 0($1) \n"
+		".set at\n"
+        ".set pop\n"
+		:
+        : "r"(value), "r"(lsw), "r"(msw)
+		: "$1"
+		);
+	disable_KX(flags);
+}
+static __inline__ void sb_40bit_phys_uncached(uint64_t phys, uint8_t value)
+{
+      sb_40bit_phys(phys, CCA_UNCACHED, value);
+}
+static __inline__ void sb_40bit_phys_cached(uint64_t phys, uint8_t value)
+{
+      sb_40bit_phys(phys, CCA_CACHED, value);
+}
+
+#endif
+
+#endif
diff --git a/arch/mips/kernel/Makefile b/arch/mips/kernel/Makefile
index d3d6fa9..4d9f61c 100644
--- a/arch/mips/kernel/Makefile
+++ b/arch/mips/kernel/Makefile
@@ -102,6 +102,10 @@ obj-$(CONFIG_EARLY_PRINTK)	+= early_printk.o
 obj-$(CONFIG_SPINLOCK_TEST)	+= spinlock_test.o
 obj-$(CONFIG_MIPS_MACHINE)	+= mips_machine.o
 
+obj-$(CONFIG_RAPIDIO)		+= rio.o
+
+KBUILD_CFLAGS 			+= -I$(srctree)/arch/mips/mm/
+
 obj-$(CONFIG_OF)		+= prom.o
 
 CFLAGS_cpu-bugs64.o	= $(shell if $(CC) $(KBUILD_CFLAGS) -Wa,-mdaddi -c -o /dev/null -x c /dev/null >/dev/null 2>&1; then echo "-DHAVE_AS_SET_DADDI"; fi)
diff --git a/arch/mips/kernel/asm-offsets.c b/arch/mips/kernel/asm-offsets.c
index 6b30fb2..420565e 100644
--- a/arch/mips/kernel/asm-offsets.c
+++ b/arch/mips/kernel/asm-offsets.c
@@ -69,6 +69,14 @@ void output_ptreg_defines(void)
 	OFFSET(PT_MPL, pt_regs, mpl);
 	OFFSET(PT_MTP, pt_regs, mtp);
 #endif /* CONFIG_CPU_CAVIUM_OCTEON */
+
+#ifdef XLP_MERGE_TODO /*CONFIG_RMI_XLP_SIM*/
+	OFFSET("#define PT_CRC_POLY_0 ", pt_regs, crc_poly_0);
+	OFFSET("#define PT_CRC_POLY_1 ", pt_regs, crc_poly_1);
+	OFFSET("#define PT_CRC_POLY_2 ", pt_regs, crc_poly_2);
+	OFFSET("#define PT_CRC_POLY_3 ", pt_regs, crc_poly_3);
+#endif /* CONFIG_RMI_XLP_SIM */
+
 	DEFINE(PT_SIZE, sizeof(struct pt_regs));
 	BLANK();
 }
@@ -328,6 +336,16 @@ void output_octeon_cop2_state_defines(void)
 }
 #endif
 
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/sim.h>
+void output_psb_info_defines(void)
+{
+        COMMENT("RMI struct psb_info structure offsets");
+        OFFSET(PSB_CPU_FREQUENCY, psb_info, cpu_frequency);
+	BLANK();
+}
+#endif /* CONFIG_RMI_PHOENIX */
+
 #ifdef CONFIG_HIBERNATION
 void output_pbe_defines(void)
 {
diff --git a/arch/mips/kernel/binfmt_elfo32.c b/arch/mips/kernel/binfmt_elfo32.c
index a60a5ff..30ec237 100644
--- a/arch/mips/kernel/binfmt_elfo32.c
+++ b/arch/mips/kernel/binfmt_elfo32.c
@@ -48,7 +48,11 @@ typedef elf_fpreg_t elf_fpregset_t[ELF_NFPREG];
 	__res;								\
 })
 
-#define TASK32_SIZE		0x7fff8000UL
+/*
+ * XLP_MERGE_TODO: changed TASK_SIZE from 0x7fff8000UL to 0x7fff8000UL
+ * to fix page alignment of initial stack (vm_start) for 64KB pages
+ */
+#define TASK32_SIZE		0x7fff0000UL
 #undef ELF_ET_DYN_BASE
 #define ELF_ET_DYN_BASE         (TASK32_SIZE / 3 * 2)
 
@@ -70,6 +74,11 @@ extern void elf32_core_copy_regs(elf_gregset_t grp, struct pt_regs *regs);
 	__res;								\
 })
 
+#include <asm/elf.h>
+#undef ELF_CORE_COPY_REGS
+void elf32_core_copy_regs(elf_gregset_t grp, struct pt_regs *regs);
+#define ELF_CORE_COPY_REGS(_dest,_regs) elf32_core_copy_regs(_dest,_regs);
+
 #include <linux/module.h>
 #include <linux/elfcore.h>
 #include <linux/compat.h>
@@ -149,23 +158,30 @@ static struct compat_timeval ns_to_timeval_compat(const s64 nsec)
 }
 #endif
 
+int elf32_dump_task_regs (struct task_struct *tsk, elf_gregset_t *regs)
+{
+	elf32_core_copy_regs(*regs, task_pt_regs(tsk));
+	return 1;
+}
+
+#define COMPAT_REG_BASE 6
 void elf32_core_copy_regs(elf_gregset_t grp, struct pt_regs *regs)
 {
 	int i;
 
-	for (i = 0; i < EF_R0; i++)
+	for (i = 0; i < COMPAT_REG_BASE; i++)
 		grp[i] = 0;
-	grp[EF_R0] = 0;
+	grp[COMPAT_REG_BASE] = 0;
 	for (i = 1; i <= 31; i++)
-		grp[EF_R0 + i] = (elf_greg_t) regs->regs[i];
-	grp[EF_R26] = 0;
-	grp[EF_R27] = 0;
-	grp[EF_LO] = (elf_greg_t) regs->lo;
-	grp[EF_HI] = (elf_greg_t) regs->hi;
-	grp[EF_CP0_EPC] = (elf_greg_t) regs->cp0_epc;
-	grp[EF_CP0_BADVADDR] = (elf_greg_t) regs->cp0_badvaddr;
-	grp[EF_CP0_STATUS] = (elf_greg_t) regs->cp0_status;
-	grp[EF_CP0_CAUSE] = (elf_greg_t) regs->cp0_cause;
+		grp[COMPAT_REG_BASE + i] = (elf_greg_t) regs->regs[i];
+	grp[EF_R26 + COMPAT_REG_BASE] = 0;
+	grp[EF_R27 + COMPAT_REG_BASE] = 0;
+	grp[EF_LO + COMPAT_REG_BASE] = (elf_greg_t) regs->lo;
+	grp[EF_HI + COMPAT_REG_BASE] = (elf_greg_t) regs->hi;
+	grp[EF_CP0_EPC + COMPAT_REG_BASE] = (elf_greg_t) regs->cp0_epc;
+	grp[EF_CP0_BADVADDR + COMPAT_REG_BASE] = (elf_greg_t) regs->cp0_badvaddr;
+	grp[EF_CP0_STATUS + COMPAT_REG_BASE] = (elf_greg_t) regs->cp0_status;
+	grp[EF_CP0_CAUSE + COMPAT_REG_BASE] = (elf_greg_t) regs->cp0_cause;
 #ifdef EF_UNUSED0
 	grp[EF_UNUSED0] = 0;
 #endif
diff --git a/arch/mips/kernel/genex.S b/arch/mips/kernel/genex.S
index 8882e57..dd0275f 100644
--- a/arch/mips/kernel/genex.S
+++ b/arch/mips/kernel/genex.S
@@ -450,7 +450,11 @@ NESTED(nmi_handler, PT_SIZE, sp)
 	BUILD_HANDLER ades ade ade silent		/* #5  */
 	BUILD_HANDLER ibe be cli silent			/* #6  */
 	BUILD_HANDLER dbe be cli silent			/* #7  */
+#if defined(CONFIG_RMI_PHOENIX) && defined (CONFIG_KGDB)
+	BUILD_HANDLER bp bp cli silent			/* #9  */
+#else
 	BUILD_HANDLER bp bp sti silent			/* #9  */
+#endif
 	BUILD_HANDLER ri ri sti silent			/* #10 */
 	BUILD_HANDLER cpu cpu sti silent		/* #11 */
 	BUILD_HANDLER ov ov sti silent			/* #12 */
diff --git a/arch/mips/kernel/head.S b/arch/mips/kernel/head.S
index ea695d9..8ea21b0 100644
--- a/arch/mips/kernel/head.S
+++ b/arch/mips/kernel/head.S
@@ -26,47 +26,9 @@
 #include <asm/mipsregs.h>
 #include <asm/stackframe.h>
 
-#include <kernel-entry-init.h>
-
-	/*
-	 * inputs are the text nasid in t1, data nasid in t2.
-	 */
-	.macro MAPPED_KERNEL_SETUP_TLB
-#ifdef CONFIG_MAPPED_KERNEL
-	/*
-	 * This needs to read the nasid - assume 0 for now.
-	 * Drop in 0xffffffffc0000000 in tlbhi, 0+VG in tlblo_0,
-	 * 0+DVG in tlblo_1.
-	 */
-	dli	t0, 0xffffffffc0000000
-	dmtc0	t0, CP0_ENTRYHI
-	li	t0, 0x1c000		# Offset of text into node memory
-	dsll	t1, NASID_SHFT		# Shift text nasid into place
-	dsll	t2, NASID_SHFT		# Same for data nasid
-	or	t1, t1, t0		# Physical load address of kernel text
-	or	t2, t2, t0		# Physical load address of kernel data
-	dsrl	t1, 12			# 4K pfn
-	dsrl	t2, 12			# 4K pfn
-	dsll	t1, 6			# Get pfn into place
-	dsll	t2, 6			# Get pfn into place
-	li	t0, ((_PAGE_GLOBAL|_PAGE_VALID| _CACHE_CACHABLE_COW) >> 6)
-	or	t0, t0, t1
-	mtc0	t0, CP0_ENTRYLO0	# physaddr, VG, cach exlwr
-	li	t0, ((_PAGE_GLOBAL|_PAGE_VALID| _PAGE_DIRTY|_CACHE_CACHABLE_COW) >> 6)
-	or	t0, t0, t2
-	mtc0	t0, CP0_ENTRYLO1	# physaddr, DVG, cach exlwr
-	li	t0, 0x1ffe000		# MAPPED_KERN_TLBMASK, TLBPGMASK_16M
-	mtc0	t0, CP0_PAGEMASK
-	li	t0, 0			# KMAP_INX
-	mtc0	t0, CP0_INDEX
-	li	t0, 1
-	mtc0	t0, CP0_WIRED
-	tlbwi
-#else
-	mtc0	zero, CP0_WIRED
-#endif
-	.endm
-
+#include <asm/mach-rmi/kernel-entry-init.h>
+#include <asm/mach-generic/kernel-entry-init.h>
+		
 	/*
 	 * For the moment disable interrupts, mark the kernel mode and
 	 * set ST0_KX so that the CPU does not spit fire when using
@@ -145,6 +107,8 @@ FEXPORT(__kernel_entry)
 
 NESTED(kernel_entry, 16, sp)			# kernel entry point
 
+	MAPPED_KERNEL_SETUP_TLB
+
 	kernel_entry_setup			# cpu specific setup
 
 	setup_c0_status_pri
diff --git a/arch/mips/kernel/kgdb.c b/arch/mips/kernel/kgdb.c
index e11dec6..f800d32 100644
--- a/arch/mips/kernel/kgdb.c
+++ b/arch/mips/kernel/kgdb.c
@@ -234,11 +234,45 @@ static void kgdb_call_nmi_hook(void *ignored)
 	kgdb_nmicallback(raw_smp_processor_id(), NULL);
 }
 
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/interrupt.h>
+spinlock_t rmi_kgdb_lock = SPIN_LOCK_UNLOCKED;
+
+void rmi_kgdb_smp_hook(void)
+{
+	int i;
+	int cpu = smp_processor_id();
+	int cpus = num_online_cpus() - 1;
+	unsigned long flags;
+
+	BUG_ON(!cpu_online(cpu));
+
+	if (!cpus)
+		return;
+
+	spin_lock_irqsave(&rmi_kgdb_lock, flags);
+	for (i = 0; i < NR_CPUS; i++)
+		if (cpu_online(i) && i != cpu)
+			core_send_ipi(i, SMP_CALL_KGDB_HOOK);
+	spin_unlock_irqrestore(&rmi_kgdb_lock, flags);
+}
+
+void rmi_kgdb_call_nmi_hook(void)
+{
+	kgdb_nmicallback(raw_smp_processor_id(), NULL);
+}
+#endif
+
 void kgdb_roundup_cpus(unsigned long flags)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_kgdb_smp_hook();
+	return;
+#else
 	local_irq_enable();
 	smp_call_function(kgdb_call_nmi_hook, NULL, 0);
 	local_irq_disable();
+#endif
 }
 
 static int compute_signal(int tt)
@@ -295,6 +329,27 @@ void kgdb_arch_set_pc(struct pt_regs *regs, unsigned long pc)
 	regs->cp0_epc = pc;
 }
 
+extern void phoenix_flush_l1_icache_ipi(void *);
+extern void phoenix_flush_l1_caches_ipi(void *);
+
+#ifdef CONFIG_RMI_PHOENIX
+irqreturn_t xlr_kgdb_ipi_handler(int irq, struct pt_regs *regs)
+{
+	//int cpu = smp_processor_id();
+	kgdb_call_nmi_hook(NULL);
+
+	phoenix_flush_l1_caches_ipi(NULL);
+#if 0
+	if(g_xlr_kgdb[cpu]) {
+		g_xlr_kgdb[cpu] = 0;
+		kgdb_call_nmi_hook(NULL);
+	}
+#endif
+
+	return IRQ_HANDLED;
+}
+#endif
+
 /*
  * Calls linux_debug_hook before the kernel dies. If KGDB is enabled,
  * then try to fall into the debugger
@@ -389,8 +444,12 @@ static int kgdb_mips_notify(struct notifier_block *self, unsigned long cmd,
 			regs->cp0_epc += 4;
 
 	/* In SMP mode, __flush_cache_all does IPI */
+#ifdef CONFIG_RMI_PHOENIX
+	phoenix_flush_l1_icache_ipi(NULL);
+#else
 	local_irq_enable();
 	__flush_cache_all();
+#endif
 
 	return NOTIFY_STOP;
 }
diff --git a/arch/mips/kernel/process.c b/arch/mips/kernel/process.c
index d8ad904..a46e1b0 100644
--- a/arch/mips/kernel/process.c
+++ b/arch/mips/kernel/process.c
@@ -1,3 +1,14 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -23,6 +34,7 @@
 #include <linux/user.h>
 #include <linux/init.h>
 #include <linux/completion.h>
+#include <linux/perfctr.h>
 #include <linux/kallsyms.h>
 #include <linux/random.h>
 #include <trace/sched.h>
@@ -107,6 +119,11 @@ void start_thread(struct pt_regs * regs, unsigned long pc, unsigned long sp)
 
 void exit_thread(void)
 {
+	#ifdef CONFIG_PERFCTR
+	struct task_struct *tsk = current;
+
+	perfctr_exit_thread(&tsk->thread);
+	#endif
 }
 
 void flush_thread(void)
@@ -119,8 +136,8 @@ int copy_thread(unsigned long clone_flags, unsigned long usp,
 	struct thread_info *ti = task_thread_info(p);
 	struct pt_regs *childregs;
 	unsigned long childksp;
-	p->set_child_tid = p->clear_child_tid = NULL;
 
+	p->set_child_tid = p->clear_child_tid = NULL;
 	childksp = (unsigned long)task_stack_page(p) + THREAD_SIZE - 32;
 
 	preempt_disable();
@@ -176,6 +193,11 @@ int copy_thread(unsigned long clone_flags, unsigned long usp,
 	if (clone_flags & CLONE_SETTLS)
 		ti->tp_value = regs->regs[7];
 
+#ifdef CONFIG_PERFCTR
+	perfctr_copy_task(p, regs);
+#endif
+
+
 	return 0;
 }
 
@@ -204,6 +226,7 @@ void elf_dump_regs(elf_greg_t *gp, struct pt_regs *regs)
 	gp[EF_CP0_BADVADDR] = regs->cp0_badvaddr;
 	gp[EF_CP0_STATUS] = regs->cp0_status;
 	gp[EF_CP0_CAUSE] = regs->cp0_cause;
+
 #ifdef EF_UNUSED0
 	gp[EF_UNUSED0] = 0;
 #endif
diff --git a/arch/mips/kernel/ptrace.c b/arch/mips/kernel/ptrace.c
index 5729343..b95f896 100644
--- a/arch/mips/kernel/ptrace.c
+++ b/arch/mips/kernel/ptrace.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -38,6 +50,7 @@
 #include <asm/uaccess.h>
 #include <asm/bootinfo.h>
 #include <asm/reg.h>
+#include <asm/cacheflush.h>
 
 DEFINE_TRACE(syscall_entry);
 DEFINE_TRACE(syscall_exit);
@@ -268,7 +281,12 @@ long arch_ptrace(struct task_struct *child, long request,
 
 	switch (request) {
 	/* when I and D space are separate, these will need to be fixed. */
-	case PTRACE_PEEKTEXT: /* read word at location addr. */
+        case PTRACE_PEEKTEXT: /* read word at location addr. */
+#ifdef CONFIG_RMI_PHOENIX
+            __flush_cache_all();
+            /* Fall through */
+#endif
+
 	case PTRACE_PEEKDATA:
 		ret = generic_ptrace_peekdata(child, addr, data);
 		break;
@@ -399,6 +417,10 @@ long arch_ptrace(struct task_struct *child, long request,
 
 	/* when I and D space are separate, this will have to be fixed. */
 	case PTRACE_POKETEXT: /* write the word at location addr. */
+#ifdef CONFIG_RMI_PHOENIX
+        __flush_cache_all();
+        /* Fall through */
+#endif
 	case PTRACE_POKEDATA:
 		ret = generic_ptrace_pokedata(child, addr, data);
 		break;
diff --git a/arch/mips/kernel/rio.c b/arch/mips/kernel/rio.c
new file mode 100644
index 0000000..7a0da7b
--- /dev/null
+++ b/arch/mips/kernel/rio.c
@@ -0,0 +1,49 @@
+/*
+ * RapidIO MIPS support
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/rio.h>
+
+#include <asm/rio.h>
+
+/**
+ * platform_rio_init - Do platform specific RIO init
+ *
+ * Any platform specific initialization of RapdIO
+ * hardware is done here as well as registration
+ * of any active master ports in the system.
+ */
+void __attribute__ ((weak))
+    platform_rio_init(void)
+{
+	printk(KERN_WARNING "RIO: No platform_rio_init() present\n");
+}
+
+/**
+ * mips_rio_init - Do MIPS RIO init
+ *
+ * Calls platform-specific RIO init code and then calls
+ * rio_init_mports() to initialize any master ports that
+ * have been registered with the RIO subsystem.
+ */
+static int __init mips_rio_init(void)
+{
+	printk(KERN_INFO "RIO: RapidIO init\n");
+
+	/* Platform specific initialization */
+	platform_rio_init();
+
+	/* Enumerate all registered ports */
+	rio_init_mports();
+
+	return 0;
+}
+
+subsys_initcall(mips_rio_init);
diff --git a/arch/mips/kernel/scall32-o32.S b/arch/mips/kernel/scall32-o32.S
index cd57433..9e9efcc 100644
--- a/arch/mips/kernel/scall32-o32.S
+++ b/arch/mips/kernel/scall32-o32.S
@@ -1,3 +1,15 @@
+/************************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+ *
+ * This is a derived work from software originally provided by the external
+ * entity identified below. The licensing terms and warranties specified in
+ * the header of the original work apply to this derived work.
+ *
+ * Contribution by RMI:
+ *
+ ******************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -27,6 +39,30 @@
 
 	.align  5
 NESTED(handle_sys, PT_SIZE, sp)
+#ifdef CONFIG_32BIT
+#ifdef CONFIG_RMI_PHOENIX
+	.set push
+	.set mips64
+    /* XLR Specific fast system calls */
+	mfc0	k1, CP0_EPC
+	lw	k0, 0(k1)
+	dsll32	k0, k0, 0
+	dsrl32  k0, k0, 6
+	beqz	k0, 1f
+	nop
+	sll	k0, k0, 2
+	lw	k1, xlr_fast_sys_call_table(k0)
+	jr	k1
+	nop
+	/* should never come here */
+2:	wait
+	b	2b
+	nop
+	.set pop
+1:
+#endif
+#endif
+
 	.set	noat
 	SAVE_SOME
 	TRACE_IRQS_ON_RELOAD
@@ -601,6 +637,12 @@ einval:	li	v0, -ENOSYS
 #else
 	sys	sys_msa			2
 #endif
+	/* RMI Added syscalls */
+	sys     sys_vperfctr_open	2 /* 4348 */
+	sys     sys_vperfctr_control	3
+	sys     sys_vperfctr_unlink     1
+	sys     sys_vperfctr_iresume    1
+	sys     sys_vperfctr_read       4
 	.endm
 
 	/* We pre-compute the number of _instruction_ bytes needed to
diff --git a/arch/mips/kernel/scall64-64.S b/arch/mips/kernel/scall64-64.S
index 2d372d2..df34ad9 100644
--- a/arch/mips/kernel/scall64-64.S
+++ b/arch/mips/kernel/scall64-64.S
@@ -1,3 +1,16 @@
+/************************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+ *
+ * This is a derived work from software originally provided by the external
+ * entity identified below. The licensing terms and warranties specified
+ * in
+ * the header of the original work apply to this derived work.
+ *
+ * Contribution by RMI:
+ *
+ ******************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -416,9 +429,18 @@ EXPORT(sys_call_table)
 	PTR	sys_signalfd4
 	PTR	sys_eventfd2
 	PTR	sys_epoll_create1		/* 5285 */
-	PTR	sys_dup3
-	PTR	sys_pipe2
-	PTR	sys_inotify_init1
+    PTR	sys_dup3
+    PTR	sys_pipe2
+    PTR	sys_inotify_init1
+
+    /* RMI specific syscalls */
+    PTR     sys_vperfctr_open
+    PTR     sys_vperfctr_control /* 5290 */
+    PTR     sys_vperfctr_unlink
+    PTR     sys_vperfctr_iresume
+    PTR     sys_vperfctr_read
+
+
 	PTR	sys_preadv
 	PTR	sys_pwritev			/* 5290 */
 	PTR	sys_rt_tgsigqueueinfo
diff --git a/arch/mips/kernel/scall64-n32.S b/arch/mips/kernel/scall64-n32.S
index 6c5cca3..b76cca9 100644
--- a/arch/mips/kernel/scall64-n32.S
+++ b/arch/mips/kernel/scall64-n32.S
@@ -1,3 +1,16 @@
+/************************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+ *
+ * This is a derived work from software originally provided by the external
+ * entity identified below. The licensing terms and warranties specified
+ * in
+ * the header of the original work apply to this derived work.
+ *
+ * Contribution by RMI:
+ *
+ ******************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -332,7 +345,7 @@ EXPORT(sysn32_call_table)
 	PTR	compat_sys_io_submit
 	PTR	sys_io_cancel
 	PTR	sys_exit_group			/* 6205 */
-	PTR	sys_lookup_dcookie
+	PTR	compat_sys_lookup_dcookie
 	PTR	sys_epoll_create
 	PTR	sys_epoll_ctl
 	PTR	sys_epoll_wait
@@ -438,4 +451,9 @@ EXPORT(sysn32_call_table)
 	PTR	compat_sys_process_vm_readv
 	PTR	compat_sys_process_vm_writev	/* 6310 */
 	PTR	sys_msa
+    	PTR 	sys_vperfctr_open               /* 6312 */
+    	PTR 	sys_vperfctr_control
+    	PTR 	sys_vperfctr_unlink
+    	PTR 	sys_vperfctr_iresume
+    	PTR 	sys_vperfctr_read
 	.size	sysn32_call_table,.-sysn32_call_table
diff --git a/arch/mips/kernel/scall64-o32.S b/arch/mips/kernel/scall64-o32.S
index bef32e7..3c3eb23 100644
--- a/arch/mips/kernel/scall64-o32.S
+++ b/arch/mips/kernel/scall64-o32.S
@@ -27,6 +27,32 @@
 
 	.align  5
 NESTED(handle_sys, PT_SIZE, sp)
+#ifdef CONFIG_64BIT
+#ifdef CONFIG_RMI_PHOENIX 
+	.set push
+	.set	noat
+	.set mips64
+    	/* XLR Specific fast system calls */
+	dmfc0	k1, CP0_EPC
+	lw	k0, 0(k1)
+	dsll32	k0, k0, 0
+	dsrl32  k0, k0, 6
+	beqz	k0, 1f
+	nop
+	sll	k0, k0, 3
+	PTR_LA  k1, xlr_fast_sys_call_table
+	PTR_ADDU k1,k0,k1
+	ld	k1, 0(k1)
+	jr	k1
+	nop
+	/* should never come here */
+2:	wait
+	b	2b
+	nop
+1:		
+	.set pop
+#endif
+#endif
 	.set	noat
 	SAVE_SOME
 	TRACE_IRQS_ON_RELOAD
@@ -453,7 +479,7 @@ EXPORT(syso32_call_table)
 	PTR	compat_sys_io_submit
 	PTR	sys_io_cancel			/* 4245 */
 	PTR	sys_exit_group
-	PTR	sys32_lookup_dcookie
+	PTR	compat_sys_lookup_dcookie
 	PTR	sys_epoll_create
 	PTR	sys_epoll_ctl
 	PTR	sys_epoll_wait			/* 4250 */
@@ -554,4 +580,10 @@ EXPORT(syso32_call_table)
 	PTR	compat_sys_process_vm_readv	/* 4345 */
 	PTR	compat_sys_process_vm_writev
 	PTR	sys_msa
+	/* RMI Added syscalls */
+	PTR	sys_vperfctr_open       /* 4348 */
+	PTR 	sys_vperfctr_control
+	PTR 	sys_vperfctr_unlink
+	PTR 	sys_vperfctr_iresume
+	PTR 	sys_vperfctr_read
 	.size	syso32_call_table,.-syso32_call_table
diff --git a/arch/mips/kernel/setup.c b/arch/mips/kernel/setup.c
index c504b21..c9d013f 100644
--- a/arch/mips/kernel/setup.c
+++ b/arch/mips/kernel/setup.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -33,6 +45,10 @@
 #include <asm/smp-ops.h>
 #include <asm/prom.h>
 
+#include <asm/rmi/sim.h>
+#include <asm/rmi/debug.h>
+#include <asm/mach-rmi/mmu.h>
+
 struct cpuinfo_mips cpu_data[NR_CPUS] __read_mostly;
 
 EXPORT_SYMBOL(cpu_data);
@@ -41,6 +57,13 @@ EXPORT_SYMBOL(cpu_data);
 struct screen_info screen_info;
 #endif
 
+#ifdef CONFIG_RMI_VMIPS
+extern unsigned long long rmi_vmips_highmem_start;
+#undef  HIGHMEM_START
+#define        HIGHMEM_START   (rmi_vmips_highmem_start)
+#endif
+
+
 /*
  * Despite it's name this variable is even if we don't have PCI
  */
@@ -76,7 +99,7 @@ EXPORT_SYMBOL(mips_io_port_base);
 static struct resource code_resource = { .name = "Kernel code", };
 static struct resource data_resource = { .name = "Kernel data", };
 
-void __init add_memory_region(phys_t start, phys_t size, long type)
+void __init add_memory_region(uint64_t start, uint64_t size, long type)
 {
 	int x = boot_mem_map.nr_map;
 	struct boot_mem_map_entry *prev = boot_mem_map.map + x - 1;
@@ -107,11 +130,21 @@ void __init add_memory_region(phys_t start, phys_t size, long type)
 	boot_mem_map.nr_map++;
 }
 
+#ifdef CONFIG_RMI_PHOENIX
+int avail_mem_above_4G;
+int force_usb __initdata = 0;
+static int __init xls_force_usb(char *p)
+{
+    force_usb = 1;
+	return 0;
+}
+early_param("forceusb", xls_force_usb);
+#endif
+
 static void __init print_memory_map(void)
 {
 	int i;
 	const int field = 2 * sizeof(unsigned long);
-
 	for (i = 0; i < boot_mem_map.nr_map; i++) {
 		printk(KERN_INFO " memory: %0*Lx @ %0*Lx ",
 		       field, (unsigned long long) boot_mem_map.map[i].size,
@@ -131,12 +164,50 @@ static void __init print_memory_map(void)
 			printk(KERN_CONT "(reserved)\n");
 			break;
 		default:
-			printk(KERN_CONT "type %lu\n", boot_mem_map.map[i].type);
+			printk(KERN_CONT "type %llu\n", 
+                        (unsigned long long)boot_mem_map.map[i].type);
 			break;
 		}
 	}
 }
 
+#if defined(CONFIG_RMI_PHOENIX)
+/* This routine is useful when USB is desired on
+ * 64-Bit Linux with DRAM mapped >4G. On such systems,
+ * since the XLS USB controller is 32-bit, USB is
+ * disabled. Use command line option 'forceusb' to
+ * enable it; This adjusts the mapped available mem 
+ * to a max of till 0xFFFFFFFF.
+ */
+static void __init tweak_avail_dram_map(void) {
+
+    int j=0;
+    int nrmap_ctr = (boot_mem_map.nr_map - 1);
+
+    avail_mem_above_4G = 0;
+
+    for (j=nrmap_ctr; j>=0; j--) {
+        if ((boot_mem_map.map[j].addr + boot_mem_map.map[j].size) 
+                > 0x100000000ULL) {
+            avail_mem_above_4G++;
+#ifdef CONFIG_64BIT
+            if (force_usb) {
+                printk(KERN_WARNING "[USB]:Re-adjusting Available DRAM map\n");
+                if (boot_mem_map.map[j].addr > 0x100000000ULL) {
+                    boot_mem_map.nr_map--;
+                }
+                else {
+                    /* Reclaim whatever we can... */
+                    boot_mem_map.map[j].size =
+                        0x100000000ULL - boot_mem_map.map[j].addr;
+                }
+            }
+#endif
+        }
+    }
+}
+#endif
+
 /*
  * Manage initrd
  */
@@ -325,6 +396,14 @@ static void __init bootmem_init(void)
 		max_low_pfn = PFN_DOWN(HIGHMEM_START);
 	}
 
+#ifdef CONFIG_NLM_XLP
+	max_low_pfn = recalculate_max_low_pfn(max_low_pfn);
+
+#ifdef DEBUG_MAPPED_KERNEL
+	printk("max_low_pfn = 0x%lx\n", max_low_pfn);
+#endif
+#endif
+
 	/*
 	 * Initialize the boot-time allocator with low memory only.
 	 */
@@ -521,7 +600,17 @@ static void __init arch_mem_init(char **cmdline_p)
 		print_memory_map();
 	}
 
+#ifdef CONFIG_RMI_PHOENIX
+	tweak_avail_dram_map();
+#endif
+    
+/*
+	setup_mapped_kernel_tlbs(TRUE, TRUE);
+*/
 	bootmem_init();
+/*
+	setup_mapped_kernel_tlbs(FALSE, TRUE);
+*/
 	device_tree_init();
 	sparse_init();
 	plat_swiotlb_setup();
@@ -586,7 +675,6 @@ void __init setup_arch(char **cmdline_p)
 {
 	cpu_probe();
 	prom_init();
-
 #ifdef CONFIG_EARLY_PRINTK
 	setup_early_printk();
 #endif
diff --git a/arch/mips/kernel/smp.c b/arch/mips/kernel/smp.c
index f10f5f4..f6eb58e 100644
--- a/arch/mips/kernel/smp.c
+++ b/arch/mips/kernel/smp.c
@@ -98,7 +98,7 @@ __cpuinit void register_smp_ops(struct plat_smp_ops *ops)
  */
 asmlinkage __cpuinit void start_secondary(void)
 {
-	unsigned int cpu;
+	unsigned int cpu = smp_processor_id();
 
 #ifdef CONFIG_MIPS_MT_SMTC
 	/* Only do cpu_probe for first TC of CPU */
@@ -107,14 +107,16 @@ asmlinkage __cpuinit void start_secondary(void)
 	cpu_probe();
 	cpu_report();
 	per_cpu_trap_init();
-	mips_clockevent_init();
+	if (mips_clockevent_init() != 0) {
+		printk("[%s]: unable to setup timer interrupt!!\n", __FUNCTION__);
+	}
 	mp_ops->init_secondary();
 
 	/*
 	 * XXX parity protection should be folded in here when it's converted
 	 * to an option instead of something based on .cputype
 	 */
-
+	local_irq_enable();
 	calibrate_delay();
 	preempt_disable();
 	cpu = smp_processor_id();
@@ -132,6 +134,9 @@ asmlinkage __cpuinit void start_secondary(void)
 	cpu_idle();
 }
 
+#include <asm/rmi/debug.h>
+#include <asm/rmi/mips-exts.h>
+
 /*
  * Call into both interrupt handlers, as we share the IPI for them
  */
@@ -274,6 +279,11 @@ int setup_profiling_timer(unsigned int multiplier)
 
 static void flush_tlb_all_ipi(void *info)
 {
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+#include <asm/rmi/mips-exts.h>
+	if((rmi_asid_mask == 0x3f) && phoenix_thr_id())
+		return;
+#endif
 	local_flush_tlb_all();
 }
 
diff --git a/arch/mips/kernel/sync-r4k.c b/arch/mips/kernel/sync-r4k.c
index 99f913c..caf9d71 100644
--- a/arch/mips/kernel/sync-r4k.c
+++ b/arch/mips/kernel/sync-r4k.c
@@ -28,6 +28,10 @@ static atomic_t __cpuinitdata count_reference = ATOMIC_INIT(0);
 #define COUNTON	100
 #define NR_LOOPS 5
 
+#ifdef CONFIG_RMI_PHOENIX
+unsigned int count_after_sync[NR_CPUS];
+#endif
+
 void __cpuinit synchronise_count_master(void)
 {
 	int i;
@@ -83,8 +87,16 @@ void __cpuinit synchronise_count_master(void)
 		/*
 		 * Everyone initialises count in the last loop:
 		 */
+#ifdef CONFIG_RMI_PHOENIX
+		if (i == NR_LOOPS-1) {
+			write_c0_count(initcount);
+			count_after_sync[0] = read_c0_count();
+			smp_wmb();
+		}
+#else
 		if (i == NR_LOOPS-1)
 			write_c0_count(initcount);
+#endif
 
 		/*
 		 * Wait for all slaves to leave the synchronization point:
@@ -114,6 +126,9 @@ void __cpuinit synchronise_count_slave(void)
 	unsigned long flags;
 	unsigned int initcount;
 	int ncpus;
+#ifdef CONFIG_RMI_PHOENIX
+	int cpu = smp_processor_id();
+#endif
 
 #ifdef CONFIG_MIPS_MT_SMTC
 	/*
@@ -145,8 +160,16 @@ void __cpuinit synchronise_count_slave(void)
 		/*
 		 * Everyone initialises count in the last loop:
 		 */
+#ifdef CONFIG_RMI_PHOENIX
+		if (i == NR_LOOPS-1) {
+			write_c0_count(initcount);
+			count_after_sync[cpu] = read_c0_count();
+			smp_wmb();
+		}
+#else
 		if (i == NR_LOOPS-1)
 			write_c0_count(initcount);
+#endif
 
 		atomic_inc(&count_count_stop);
 		while (atomic_read(&count_count_stop) != ncpus)
diff --git a/arch/mips/kernel/syscall.c b/arch/mips/kernel/syscall.c
index 6736233..428b89f 100644
--- a/arch/mips/kernel/syscall.c
+++ b/arch/mips/kernel/syscall.c
@@ -1,3 +1,14 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -44,6 +55,47 @@
 #include <asm/uaccess.h>
 #include <asm/switch_to.h>
 
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/rmi_uaccess_fs.h>
+
+#if defined(CONFIG_RMI_XLP)
+#define xlr_fast_syscall_msgsnd rmi_uaccess_fs_msgsnd
+#define xlr_fast_syscall_msgld  rmi_uaccess_fs_msgrcv
+#endif /* CONFIG_RMI_XLP */
+
+static void xlr_fast_syscall_unused(void) {}
+unsigned long xlr_fast_sys_call_table[] = {
+	[RMI_UACCESS_FS_UNUSED] = (unsigned long)xlr_fast_syscall_unused,
+	[RMI_UACCESS_FS_MSGSND] = (unsigned long)xlr_fast_syscall_msgsnd,
+	[RMI_UACCESS_FS_MSGRCV] = (unsigned long)xlr_fast_syscall_msgld,
+	[RMI_UACCESS_FS_C0_COUNT] = (unsigned long)xlr_fast_syscall_c0_count,
+	[RMI_UACCESS_FS_MEM_READ] = (unsigned long)xlr_fast_syscall_iomem_read,
+	[RMI_UACCESS_FS_MEM_WRITE] = (unsigned long)xlr_fast_syscall_iomem_write,
+	[RMI_UACCESS_FS_MSGINT] = (unsigned long)xlr_fast_syscall_unused,
+	[RMI_UACCESS_FS_READ_COP] = (unsigned long)xlr_fast_syscall_msg_read,
+	[RMI_UACCESS_FS_PERFCTR_START] = (unsigned long)xlr_fast_syscall_perf_ctr_start,
+	[RMI_UACCESS_FS_PERFCTR_STOP] = (unsigned long)xlr_fast_syscall_perf_ctr_stop,
+	[RMI_UACCESS_FS_READ_CPUMASKS] = (unsigned long)xlr_fast_syscall_get_cpumasks,
+	[RMI_UACCESS_FS_READ_PROCID] = (unsigned long)xlr_fast_syscall_processorId,
+	[RMI_UACCESS_FS_PROMINFO] = (unsigned long)xlr_fast_syscall_prominfo,
+	[RMI_UACCESS_FS_READ_TIMER] = (unsigned long)rmi_uaccess_fs_read_timer,
+	[RMI_UACCESS_FS_HARD_CPUID] = (unsigned long)rmi_uaccess_fs_hard_cpuid,
+	[RMI_UACCESS_FS_ENDIANESS] = (unsigned long)rmi_uaccess_fs_is_big_endian,
+	[RMI_UACCESS_FS_REVERSE_ENDIANESS] = (unsigned long)rmi_uaccess_fs_is_endian_reversed,
+	[RMI_UACCESS_FS_USPACE_64BIT_INS] = (unsigned long)rmi_uaccess_fs_uspace_64bit_ins_enabled,
+	[RMI_UACCESS_FS_CPU_MAX_FREQ] = (unsigned long)rmi_uaccess_fs_cpu_max_freq,
+#if defined(CONFIG_RMI_XLP)
+	[RMI_UACCESS_FS_MEM_READ64] = (unsigned long)rmi_uaccess_fs_mem_read64,
+	[RMI_UACCESS_FS_MEM_WRITE64] = (unsigned long)rmi_uaccess_fs_mem_write64,
+	[RMI_UACCESS_FS_MEM_READ32] = (unsigned long)rmi_uaccess_fs_mem_read32,
+	[RMI_UACCESS_FS_MEM_WRITE32] = (unsigned long)rmi_uaccess_fs_mem_write32,
+	[RMI_UACCESS_FS_MSGSND3] = (unsigned long)rmi_uaccess_fs_msgsnd3,
+#endif /* CONFIG_RMI_XLP */
+	0
+};
+
+#endif
+
 /*
  * For historic reasons the pipe(2) syscall on MIPS has an unusual calling
  * convention.  It returns results in registers $v0 / $v1 which means there
@@ -67,6 +119,24 @@ out:
 	return res;
 }
 
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+int mips_mmap_check(unsigned long addr, unsigned long len,
+		    unsigned long flags)
+{
+	int app_is_32bit = test_thread_flag(TIF_32BIT_ADDR);
+
+	if(app_is_32bit){
+		if(len >= TASK_SIZE32){
+			return -EINVAL;
+		}
+		if ((flags & MAP_FIXED) && addr > (TASK_SIZE32 - len)){
+			return -EINVAL;
+		}
+	}
+	return 0;
+}
+#endif
+
 SYSCALL_DEFINE6(mips_mmap, unsigned long, addr, unsigned long, len,
 	unsigned long, prot, unsigned long, flags, unsigned long,
 	fd, off_t, offset)
@@ -154,13 +224,20 @@ out:
 	return error;
 }
 
+void sys_rmi_phoenix_dummy(void)
+{	
+	printk("Unexpected Dummy System Call!\n");
+	BUG();
+}
+
 SYSCALL_DEFINE1(set_thread_area, unsigned long, addr)
 {
 	struct thread_info *ti = task_thread_info(current);
 
 	ti->tp_value = addr;
-	if (cpu_has_userlocal)
+	if (cpu_has_userlocal) {
 		write_c0_userlocal(addr);
+	}
 
 	return 0;
 }
diff --git a/arch/mips/kernel/traps.c b/arch/mips/kernel/traps.c
index a72dc17..7645e40 100644
--- a/arch/mips/kernel/traps.c
+++ b/arch/mips/kernel/traps.c
@@ -1,3 +1,14 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -61,6 +72,12 @@
 DEFINE_TRACE(trap_entry);
 DEFINE_TRACE(trap_exit);
 
+#ifndef CONFIG_RMI_PHOENIX
+static void mmu_init(void) { }
+#else
+#include <asm/mach-rmi/mmu.h>
+#endif
+
 extern void check_wait(void);
 extern asmlinkage void r4k_wait(void);
 extern asmlinkage void rollback_handle_int(void);
@@ -99,6 +116,9 @@ void (*board_ejtag_handler_setup)(void);
 void (*board_bind_eic_interrupt)(int irq, int regset);
 void (*board_ebase_setup)(void);
 
+#ifdef CONFIG_RMI_PHOENIX
+extern unsigned long phnx_ebase;
+#endif
 
 static void show_raw_backtrace(unsigned long reg29)
 {
@@ -245,7 +265,6 @@ static void __show_regs(const struct pt_regs *regs)
 	const int field = 2 * sizeof(unsigned long);
 	unsigned int cause = regs->cp0_cause;
 	int i;
-
 	printk("Cpu %d\n", smp_processor_id());
 
 	/*
@@ -604,6 +623,9 @@ static int simulate_llsc(struct pt_regs *regs, unsigned int opcode)
 	return -1;			/* Must be something else ... */
 }
 
+extern void phoenix_cpu_stat_update_rdhwr(void);
+extern void phoenix_cpu_stat_update_fp(void);
+
 /*
  * Simulate trapping 'rdhwr' instructions to provide user accessible
  * registers not implemented in hardware.
@@ -618,6 +640,7 @@ static int simulate_rdhwr(struct pt_regs *regs, unsigned int opcode)
 		perf_sw_event(PERF_COUNT_SW_EMULATION_FAULTS,
 				1, regs, 0);
 		switch (rd) {
+
 		case 0:		/* CPU number */
 			regs->regs[rt] = smp_processor_id();
 			return 0;
@@ -640,6 +663,9 @@ static int simulate_rdhwr(struct pt_regs *regs, unsigned int opcode)
 			return 0;
 		case 29:
 			regs->regs[rt] = ti->tp_value;
+#if defined(CONFIG_RMI_PHOENIX)
+			phoenix_cpu_stat_update_rdhwr();
+#endif
 			return 0;
 		default:
 			return -1;
@@ -715,6 +741,9 @@ asmlinkage void do_fpe(struct pt_regs *regs, unsigned long fcr31)
 		int sig;
 		void __user *fault_addr = NULL;
 
+#if defined(CONFIG_RMI_PHOENIX)
+				phoenix_cpu_stat_update_fp();
+#endif
 		/*
 		 * Unimplemented operation exception.  If we've got the full
 		 * software emulator on-board, let's use it...
@@ -919,6 +948,8 @@ asmlinkage void do_ri(struct pt_regs *regs)
 
 	if (unlikely(status > 0)) {
 		regs->cp0_epc = old_epc;		/* Undo skip-over.  */
+		printk("[%s]: killing with SIGILL\"%s\"\n", __FUNCTION__, current->comm);
+		show_regs(regs);
 		force_sig(status, current);
 	}
 }
@@ -1555,6 +1586,12 @@ void __cpuinit per_cpu_trap_init(void)
 		secondaryTC = 1;
 #endif /* CONFIG_MIPS_MT_SMTC */
 
+#ifdef CONFIG_32BIT
+	/* Some firmware leaves the BEV flag set, clear it. */
+	clear_c0_status(ST0_CU1|ST0_CU2|ST0_CU3|ST0_BEV|ST0_KX);
+#else
+	clear_c0_status(ST0_CU1|ST0_CU2|ST0_CU3|ST0_BEV);
+#endif
 	/*
 	 * Disable coprocessors and select 32-bit or 64-bit addressing
 	 * and the 16/32 or 32/32 FPR register model.  Reset the BEV
@@ -1562,7 +1599,7 @@ void __cpuinit per_cpu_trap_init(void)
 	 * IP27).  Set XX for ISA IV code to work.
 	 */
 #ifdef CONFIG_64BIT
-	status_set |= ST0_FR|ST0_KX|ST0_SX|ST0_UX;
+	status_set |= ST0_CU0|ST0_FR|ST0_KX|ST0_SX|ST0_UX;
 #endif
 	if (current_cpu_data.isa_level == MIPS_CPU_ISA_IV)
 		status_set |= ST0_XX;
@@ -1600,6 +1637,9 @@ void __cpuinit per_cpu_trap_init(void)
 		} else
 			set_c0_cause(CAUSEF_IV);
 	}
+	else {
+		clear_c0_cause(CAUSEF_IV);
+	}
 
 	/*
 	 * Before R2 both interrupt numbers were fixed to 7, so on R2 only:
@@ -1634,8 +1674,10 @@ void __cpuinit per_cpu_trap_init(void)
 #ifdef CONFIG_MIPS_MT_SMTC
 	if (bootTC) {
 #endif /* CONFIG_MIPS_MT_SMTC */
-		cpu_cache_init();
-		tlb_init();
+
+	cpu_cache_init();
+	mmu_init();
+	tlb_init();
 #ifdef CONFIG_MIPS_MT_SMTC
 	} else if (!secondaryTC) {
 		/*
@@ -1686,7 +1728,10 @@ __setup("rdhwr_noopt", set_rdhwr_noopt);
 
 void __init trap_init(void)
 {
-	extern char except_vec3_generic, except_vec3_r4000;
+	extern char except_vec3_generic;
+#ifndef CONFIG_RMI_PHOENIX
+	extern char except_vec3_r4000;
+#endif
 	extern char except_vec4;
 	unsigned long i;
 	int rollback;
@@ -1711,6 +1756,11 @@ void __init trap_init(void)
 
 	if (board_ebase_setup)
 		board_ebase_setup();
+
+#ifdef CONFIG_RMI_PHOENIX
+	ebase = phnx_ebase;
+#endif
+
 	per_cpu_trap_init();
 
 	/*
@@ -1724,14 +1774,18 @@ void __init trap_init(void)
 	 * Setup default vectors
 	 */
 	for (i = 0; i <= 31; i++)
+	{
 		set_except_vector(i, handle_reserved);
+	}
 
 	/*
 	 * Copy the EJTAG debug exception vector handler code to it's final
 	 * destination.
 	 */
 	if (cpu_has_ejtag && board_ejtag_handler_setup)
+	{
 		board_ejtag_handler_setup();
+	}
 
 	/*
 	 * Only some CPUs have the watch exceptions.
@@ -1815,6 +1869,7 @@ void __init trap_init(void)
 
 	set_except_vector(26, handle_dsp);
 
+#ifndef CONFIG_RMI_PHOENIX
 	if (cpu_has_vce)
 		/* Special exception: R4[04]00 uses also the divec space. */
 		memcpy((void *)(ebase + 0x180), &except_vec3_r4000, 0x100);
@@ -1822,6 +1877,7 @@ void __init trap_init(void)
 		memcpy((void *)(ebase + 0x180), &except_vec3_generic, 0x80);
 	else
 		memcpy((void *)(ebase + 0x080), &except_vec3_generic, 0x80);
+#endif
 
 	local_flush_icache_range(ebase, ebase + 0x400);
 	flush_tlb_handlers();
diff --git a/arch/mips/kernel/unaligned.c b/arch/mips/kernel/unaligned.c
index 554f4f7..c816a13 100644
--- a/arch/mips/kernel/unaligned.c
+++ b/arch/mips/kernel/unaligned.c
@@ -99,8 +99,14 @@ enum {
 static u32 unaligned_instructions;
 static u32 unaligned_action;
 #else
+
+#ifdef CONFIG_RMI_PHOENIX
+#define unaligned_action UNALIGNED_ACTION_SHOW
+#else
 #define unaligned_action UNALIGNED_ACTION_QUIET
 #endif
+
+#endif
 extern void show_registers(struct pt_regs *regs);
 
 static void emulate_load_store_insn(struct pt_regs *regs,
@@ -529,8 +535,12 @@ asmlinkage void do_ade(struct pt_regs *regs)
 		goto sigbus;
 	if (unaligned_action == UNALIGNED_ACTION_SIGNAL)
 		goto sigbus;
-	else if (unaligned_action == UNALIGNED_ACTION_SHOW)
+	else if (unaligned_action == UNALIGNED_ACTION_SHOW) {
+		printk("[%s]: Killing process (%s) which is using ualigned accesses!\n",
+		       __FUNCTION__, current->comm);
 		show_registers(regs);
+		goto sigbus;
+	}
 
 	/*
 	 * Do branch emulation only if we didn't forward the exception.
diff --git a/arch/mips/kernel/vmlinux.lds.S b/arch/mips/kernel/vmlinux.lds.S
index df243a6..0fc4072 100644
--- a/arch/mips/kernel/vmlinux.lds.S
+++ b/arch/mips/kernel/vmlinux.lds.S
@@ -6,12 +6,24 @@
 #undef mips
 #define mips mips
 OUTPUT_ARCH(mips)
+
+#ifdef PHYSADDR
+ENTRY(phys_entry)
+#define AT_LOCATION AT(PHYSADDR)
+#else
 ENTRY(kernel_entry)
+#define AT_LOCATION
+#endif
+
 PHDRS {
 	text PT_LOAD FLAGS(7);	/* RWX */
 	note PT_NOTE FLAGS(4);	/* R__ */
 }
 
+#ifdef PHYSADDR
+phys_entry = kernel_entry - LOADADDR + PHYSADDR;
+#endif
+
 #ifdef CONFIG_32BIT
 	#ifdef CONFIG_CPU_LITTLE_ENDIAN
 		jiffies  = jiffies_64;
@@ -39,6 +51,7 @@ SECTIONS
 	/* . = 0xa800000000300000; */
 	. = 0xffffffff80300000;
 #endif
+
 	. = VMLINUX_LOAD_ADDRESS;
 	/* read-only */
 	_text = .;	/* Text and read-only data */
diff --git a/arch/mips/kernel/xlr_fast_sys_call_handler.S b/arch/mips/kernel/xlr_fast_sys_call_handler.S
new file mode 100644
index 0000000..718c46b
--- /dev/null
+++ b/arch/mips/kernel/xlr_fast_sys_call_handler.S
@@ -0,0 +1,497 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+
+#include <asm/addrspace.h>
+#include <asm/asm.h>
+#include <asm/mipsregs.h>
+#include <asm/regdef.h>
+#include <asm/stackframe.h>
+#include <asm/rmi/perf_ctr.h>
+#include <asm/rmi/interrupt.h>
+#include <asm/rmi/rmi_uaccess_fs.h>
+#include <asm/asm-offsets.h>
+
+#ifdef CONFIG_32BIT
+	#define T0 t0
+	#define T1 t1
+	#define T2 t2
+	#define T3 t3
+	#define T4 t4
+	#define T5 t5
+	#define T6 t6
+	#define T7 t7
+#else
+	#define T0 ta0
+	#define T1 ta1
+	#define T2 ta2
+	#define T3 ta3
+	#define T4 t0
+	#define T5 t1
+	#define T6 t2
+	#define T7 t3
+#endif
+	.text
+	.set	push
+	.set	noreorder
+	.set	mips64
+	.align	5
+
+.macro	fs_eret
+	/* skip the syscall instruction */
+	MFC0    k0, CP0_EPC
+	PTR_ADDIU   k0, 4
+	MTC0    k0, CP0_EPC
+	eret
+.endm
+
+#if defined(CONFIG_RMI_XLP)
+#include <asm/rmi/xlp_common/xlp_msgring.h>
+
+	.set	arch=xlp
+
+NESTED(rmi_uaccess_fs_msgsnd3, PT_SIZE, sp)
+	/* msgsnd arg0 is in (t1, t2) */
+	dsll32  k0, T1, 0
+	dsll32	k1, T2, 0
+	dsrl32	T2, k1, 0
+	or      T1, k0, T2
+	dmtc2	T1, XLP_TX_BUF_REG, 0
+
+	/* msgsnd arg1 is in (t3, t4) */
+	dsll32  k0, T3, 0
+	dsll32	k1, T4, 0
+	dsrl32	T4, k1, 0
+	or      T3, k0, T4
+	dmtc2   T3, XLP_TX_BUF_REG, 1
+
+	/* msgsnd arg1 is in (t5, t6) */
+	dsll32  k0, T5, 0
+	dsll32	k1, T6, 0
+	dsrl32	T6, k1, 0
+	or      T5, k0, T6
+	dmtc2   T5, XLP_TX_BUF_REG, 2
+
+	sync
+
+	/* msgsnd dst is in t0, status returned in t1 */
+1:	msgsnds	T1, T0
+	beqz	T1, 1b /* comment out the branch              */
+	nop            /* for non-blocking msgsnd fastsyscall */
+
+	fs_eret
+END(rmi_uaccess_fs_msgsnd3)
+
+NESTED(rmi_uaccess_fs_msgsnd, PT_SIZE, sp)
+	/* msgsnd arg0 is in (t1, t2) */
+	dsll32  k0, T1, 0
+	dsll32	k1, T2, 0
+	dsrl32	T2, k1, 0
+	or      T1, k0, T2
+	dmtc2	T1, XLP_TX_BUF_REG, 0
+
+	/* msgsnd arg1 is in (t3, t4) */
+	dsll32  k0, T3, 0
+	dsll32	k1, T4, 0
+	dsrl32	T4, k1, 0
+	or      T3, k0, T4
+	dmtc2   T3, XLP_TX_BUF_REG, 1
+
+	sync
+
+	/* msgsnd dst is in t0, status returned in t1 */
+1:	msgsnds	T1, T0
+	beqz	T1, 1b /* comment out the branch              */
+	nop            /* for non-blocking msgsnd fastsyscall */
+
+	fs_eret
+END(rmi_uaccess_fs_msgsnd)
+
+NESTED(rmi_uaccess_fs_msgrcv, PT_SIZE, sp)
+	/* msgld vc is in t0, status returned in k0 */
+	msglds	k0, T0
+	beqz	k0, 1f
+	move	T0, k0
+
+	/* msgld status  t0       *
+	 * arg0          (t1, t2) *
+	 * msg_rxstatus  t3       *
+	 * arg1          (t4, t5) */
+	mfc2	T3, XLP_MSG_RXSTATUS_REG
+	dmfc2	T2, XLP_RX_BUF_REG, 0
+	dmfc2   T5, XLP_RX_BUF_REG, 1
+	dsra32  T1, T2, 0
+	dsra32  T4, T5, 0
+1:
+	fs_eret
+END(rmi_uaccess_fs_msgrcv)
+
+NESTED(rmi_uaccess_fs_mem_read64, PT_SIZE, sp)
+	/* address is in (t0, t1) */
+	dsll32  k0, T0, 0
+	dsll32	k1, T1, 0
+	dsrl32	T1, k1, 0
+	or      T0, k0, T1
+
+	/* data is in (t2, t3) */
+	ld	T3, (T0)
+	dsra32	T2, T3, 0
+
+	fs_eret
+END(rmi_uaccess_fs_mem_read64)
+
+NESTED(rmi_uaccess_fs_mem_write64, PT_SIZE, sp)
+	/* address is in (t0, t1) */
+	dsll32  k0, T0, 0
+	dsll32	k1, T1, 0
+	dsrl32	T1, k1, 0
+	or      T0, k0, T1
+
+	/* data is in (t2, t3) */
+	dsll32  k0, T2, 0
+	dsll32	k1, T3, 0
+	dsrl32	T3, k1, 0
+	or      T1, k0, T3
+
+	sd	T1, (T0)
+
+	fs_eret
+END(rmi_uaccess_fs_mem_write64)
+
+NESTED(rmi_uaccess_fs_mem_read32, PT_SIZE, sp)
+	/* address is in (t0, t1) */
+	dsll32  k0, T0, 0
+	dsll32	k1, T1, 0
+	dsrl32	T1, k1, 0
+	or      T0, k0, T1
+
+	/* data is in t2 */
+	lw	T2, (T0)
+
+	fs_eret
+END(rmi_uaccess_fs_mem_read32)
+
+NESTED(rmi_uaccess_fs_mem_write32, PT_SIZE, sp)
+	/* address is in (t0, t1) */
+	dsll32  k0, T0, 0
+	dsll32	k1, T1, 0
+	dsrl32	T1, k1, 0
+	or      T0, k0, T1
+
+	/* data is in t2 */
+	sw	T2, (T0)
+
+	fs_eret
+END(rmi_uaccess_fs_mem_write32)
+
+#endif /* CONFIG_RMI_XLP */
+
+	NESTED(xlr_fast_syscall_msgsnd, PT_SIZE, sp)
+
+	/* msgsnd arg0 is in (t1, t2) */
+	dsll32  k0, T1, 0
+	dsll32	k1, T2, 0
+	dsrl32	T2, k1, 0
+	or      T1, k0, T2
+	dmtc2	T1, $0, 0
+
+	/* msgsnd arg1 is in (t3, t4) */
+	dsll32  k0, T3, 0
+	dsll32	k1, T4, 0
+	dsrl32	T4, k1, 0
+	or      T3, k0, T4
+	dmtc2   T3, $0, 1
+
+	/* msgsnd dst is in t0 */
+1:	c2	0x80001
+	mfc2	T1, $2
+	andi	T1, T1, 0x06
+	bnez	T1, 1b
+	nop
+
+	/* skip the syscall instruction */
+	MFC0	k0, CP0_EPC
+	PTR_ADDIU	k0, 4
+	MTC0	k0, CP0_EPC
+	eret
+	END(xlr_fast_syscall_msgsnd)
+
+	NESTED(xlr_fast_syscall_msgld, PT_SIZE, sp)
+	/* t0 has the bucket arg */
+	c2	0x80002
+1:	mfc2	T3, $2
+	andi	k0, T3, 0x08
+	bnez	k0, 1b
+	nop
+	andi    T0, T3, 0x30
+	bnez	T0, 2f
+	nop
+	dmfc2	T2, $1, 0
+	dmfc2   T5, $1, 1
+	nop
+	dsra32  T1, T2, 0
+	dsra32  T4, T5, 0
+2:
+
+	/* move    t0, k0 */
+
+	/* skip the syscall instruction */
+	MFC0	k0, CP0_EPC
+	PTR_ADDIU	k0, 4
+	MTC0	k0, CP0_EPC
+	eret
+	END(xlr_fast_syscall_msgld)
+
+	NESTED(xlr_fast_syscall_c0_count, PT_SIZE, sp)
+
+	mfc0    T0, $9, 0
+
+	/* skip the syscall instruction */
+	MFC0	k0, CP0_EPC
+	PTR_ADDIU	k0, 4
+	MTC0	k0, CP0_EPC
+	eret
+
+	END(xlr_fast_syscall_c0_count)
+
+	NESTED(xlr_fast_syscall_iomem_read, PT_SIZE, sp)
+
+	/* t0 has the address */
+	lw      T1, (T0)
+
+	/* skip the syscall instruction */
+	MFC0    k0, CP0_EPC
+	PTR_ADDIU   k0, 4
+	MTC0    k0, CP0_EPC
+	eret
+
+	END(xlr_fast_syscall_iomem_read)
+
+	NESTED(xlr_fast_syscall_iomem_write, PT_SIZE, sp)
+
+	/* t0 has the address, t1 has the data */
+	sw      T1, (T0)
+
+	/* skip the syscall instruction */
+	MFC0    k0, CP0_EPC
+	PTR_ADDIU   k0, 4
+	MTC0    k0, CP0_EPC
+	eret
+
+	END(xlr_fast_syscall_iomem_write)
+
+
+	NESTED(xlr_fast_syscall_msg_write, PT_SIZE, sp)
+
+	/* disable the message ring interrupts and enable 64 bits operations */
+	mfc0    k0, CP0_STATUS
+	li      k1, 1
+	dsll    k1, k1, 30
+	or      k0, k0, k1
+	li      k1, 1
+	dsll    k1, k1, 23
+	or      k0, k0, k1
+	mtc0    k0, CP0_STATUS
+	bnez	T1, 1f
+	nop
+	mtc2    T1, $3, 0
+1:
+
+	/* skip the syscall instruction */
+	MFC0    k0, CP0_EPC
+	PTR_ADDIU   k0, 4
+	MTC0    k0, CP0_EPC
+	eret
+
+	END(xlr_fast_syscall_msg_write)
+
+
+	NESTED(xlr_fast_syscall_msg_read, PT_SIZE, sp)
+
+	/* read C0 and C2 registers */
+	mfc0    T0, CP0_STATUS
+	mfc2    T1, $2, 0
+	mfc2    T2, $2, 1
+	mfc2    T3, $3, 0
+	mfc2    T4, $3, 1
+
+	/* skip the syscall instruction */
+	MFC0    k0, CP0_EPC
+	PTR_ADDIU   k0, 4
+	MTC0    k0, CP0_EPC
+	eret
+
+	END(xlr_fast_syscall_msg_read)
+
+	NESTED(xlr_fast_syscall_perf_ctr_start, PT_SIZE, sp)
+
+	mtc0    $0, CP0_PERF_CTR, PERF_CTR_EVENT0_VALUE
+	mtc0    $0, CP0_PERF_CTR, PERF_CTR_EVENT1_VALUE
+	mtc0    T0, CP0_PERF_CTR, PERF_CTR_EVENT0
+	mtc0    T1, CP0_PERF_CTR, PERF_CTR_EVENT1
+
+	/* skip the syscall instruction */
+	MFC0    k0, CP0_EPC
+	PTR_ADDIU   k0, 4
+	MTC0    k0, CP0_EPC
+	eret
+
+	END(xlr_fast_syscall_perf_ctr_start)
+
+	NESTED(xlr_fast_syscall_perf_ctr_stop, PT_SIZE, sp)
+
+	mtc0    T0, CP0_PERF_CTR, PERF_CTR_EVENT0
+	mtc0    T0, CP0_PERF_CTR, PERF_CTR_EVENT1
+	mfc0    T1, CP0_PERF_CTR, PERF_CTR_EVENT0_VALUE
+	mfc0    T2, CP0_PERF_CTR, PERF_CTR_EVENT1_VALUE
+
+	/* skip the syscall instruction */
+	MFC0    k0, CP0_EPC
+	PTR_ADDIU   k0, 4
+	MTC0    k0, CP0_EPC
+	eret
+
+	END(xlr_fast_syscall_perf_ctr_stop)
+
+
+	NESTED(xlr_fast_syscall_get_cpumasks, PT_SIZE, sp)
+
+		.word 0x40088007
+		move k0, T0
+		srl  T0, T0, 4
+		andi T0, T0, 0x3f
+		sll  T0, T0, 2
+		andi k0, k0, 0x0f
+		or T0, T0, k0
+
+		PTR_LA k0, fast_syscall_cpumask_phy		;
+		lw T1, (k0)
+
+		/* skip the syscall instruction */
+		MFC0	k0, CP0_EPC
+		PTR_ADDIU	k0, 4
+		MTC0	k0, CP0_EPC
+
+		eret
+
+	END(xlr_fast_syscall_get_cpumasks)
+
+
+	NESTED(xlr_fast_syscall_processorId, PT_SIZE, sp)
+
+	mfc0    T1, $15, 0
+
+	/* skip the syscall instruction */
+	MFC0	k0, CP0_EPC
+	PTR_ADDIU	k0, 4
+	MTC0	k0, CP0_EPC
+	eret
+
+	END(xlr_fast_syscall_processorId)
+
+	NESTED(xlr_fast_syscall_prominfo, PT_SIZE, sp)
+
+	PTR_LA	k0, prom_info_copy
+	move	k1, T0
+	sll	k1, k1, 3
+	addu	k0, k0, k1
+	lw	T1, (k0)
+	lw	T2, 4(k0)
+
+	/* skip the syscall instruction */
+	MFC0    k0, CP0_EPC
+	PTR_ADDIU       k0, 4
+	MTC0    k0, CP0_EPC
+	eret
+
+	END(xlr_fast_syscall_prominfo)
+
+	NESTED(rmi_uaccess_fs_read_timer, PT_SIZE, sp)
+
+#if defined(CONFIG_RMI_XLP)
+#include <asm/rmi/xlp_common/xlp_pic.h>
+	dli	k0, ASM_XLP_IO_PIC_OFFSET + (PIC_TIMER_6_COUNTER << 3)
+	ld	k1, 0(k0)
+	dsrl32	$9, k1, 0
+	dsll32  $8, k1, 0
+	dsrl32  $8, T0, 0
+#else
+	dli	k0, 0xffffffffbef00000 + PHOENIX_IO_PIC_OFFSET + (PIC_TIMER_6_COUNTER_0 << 2)
+	lw	$8, 0(k0)
+	dli	k0, 0xffffffffbef00000 + PHOENIX_IO_PIC_OFFSET + (PIC_TIMER_6_COUNTER_1 << 2)
+	lw	$9, 0(k0)
+#endif
+	fs_eret
+
+	END(rmi_uaccess_fs_read_timer)
+
+	NESTED(rmi_uaccess_fs_hard_cpuid, PT_SIZE, sp)
+
+	mfc0	T0, $15, 1
+	andi	T0, T0, 0x3ff
+
+	fs_eret
+
+	END(rmi_uaccess_fs_hard_cpuid)
+
+	NESTED(rmi_uaccess_fs_is_big_endian, PT_SIZE, sp)
+	mfc0	T0, $16, 0
+	andi	T0, T0, 0x8000
+
+	fs_eret
+	END(rmi_uaccess_fs_is_big_endian)
+
+	NESTED(rmi_uaccess_fs_is_endian_reversed, PT_SIZE, sp)
+	mfc0	T0, $12, 0
+	li	k1, 0x2000000
+	and	T0, T0, k1
+
+	fs_eret
+	END(rmi_uaccess_fs_is_endian_reversed)
+
+	NESTED(rmi_uaccess_fs_uspace_64bit_ins_enabled, PT_SIZE, sp)
+	mfc0	T0, $12, 0
+	li	k1, 0x800000
+	and	T0, T0, k1
+
+	fs_eret
+	END(rmi_uaccess_fs_uspace_64bit_ins_enabled)
+
+	/* {hi=T1, lo=T0} rmi_uaccess_fs_cpu_max_freq(void) */
+	NESTED(rmi_uaccess_fs_cpu_max_freq, PT_SIZE, sp)
+	PTR_LA k0, prom_info_copy
+	ld     k1, PSB_CPU_FREQUENCY(k0)
+	dsrl32 T1, k1, 0
+	dsll32 k1, k1, 0
+	dsrl32 T0, k1, 0
+
+	fs_eret
+	END(rmi_uaccess_fs_cpu_max_freq)
+	.set pop
diff --git a/arch/mips/lib/Makefile b/arch/mips/lib/Makefile
index 2a7c74f..0be9589 100644
--- a/arch/mips/lib/Makefile
+++ b/arch/mips/lib/Makefile
@@ -1,9 +1,13 @@
 #
 # Makefile for MIPS-specific library files..
 #
-
+ifdef CONFIG_RMI_NAS
+lib-y	+= csum_partial_rminas.o delay.o memcpy.o memcpy-inatomic.o memset.o \
+	   strlen_user.o strncpy_user.o strnlen_user.o uncached.o
+else
 lib-y	+= csum_partial.o delay.o memcpy.o memcpy-inatomic.o memset.o \
 	   strlen_user.o strncpy_user.o strnlen_user.o uncached.o
+endif
 
 obj-y			+= iomap.o
 obj-$(CONFIG_PCI)	+= iomap-pci.o
diff --git a/arch/mips/lib/csum_partial_rminas.S b/arch/mips/lib/csum_partial_rminas.S
new file mode 100644
index 0000000..c881a9e
--- /dev/null
+++ b/arch/mips/lib/csum_partial_rminas.S
@@ -0,0 +1,798 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Quick'n'dirty IP checksum ...
+ *
+ * Copyright (C) 1998, 1999 Ralf Baechle
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ * Copyright (C) 2007  Maciej W. Rozycki
+ */
+#include <linux/errno.h>
+#include <asm/asm.h>
+#include <asm/asm-offsets.h>
+#include <asm/regdef.h>
+
+#ifdef CONFIG_64BIT
+/*
+ * As we are sharing code base with the mips32 tree (which use the o32 ABI
+ * register definitions). We need to redefine the register definitions from
+ * the n64 ABI register naming to the o32 ABI register naming.
+ */
+#undef t0
+#undef t1
+#undef t2
+#undef t3
+#define t0	$8
+#define t1	$9
+#define t2	$10
+#define t3	$11
+#define t4	$12
+#define t5	$13
+#define t6	$14
+#define t7	$15
+
+#define USE_DOUBLE
+#endif
+
+#ifdef USE_DOUBLE
+
+#define LOAD   ld
+#define LOAD32 lwu
+#define ADD    daddu
+#define NBYTES 8
+
+#else
+
+#define LOAD   lw
+#define LOAD32 lw
+#define ADD    addu
+#define NBYTES 4
+
+#endif /* USE_DOUBLE */
+
+#define UNIT(unit)  ((unit)*NBYTES)
+
+#define ADDC(sum,reg)						\
+	.set	push;						\
+	.set	noat;						\
+	ADD	sum, reg;					\
+	sltu	v1, sum, reg;					\
+	ADD	sum, v1;					\
+	.set	pop
+
+#define ADDC32(sum,reg)						\
+	.set	push;						\
+	.set	noat;						\
+	addu	sum, reg;					\
+	sltu	v1, sum, reg;					\
+	addu	sum, v1;					\
+	.set	pop
+
+#define CSUM_BIGCHUNK1(src, offset, sum, _t0, _t1, _t2, _t3)	\
+	LOAD	_t0, (offset + UNIT(0))(src);			\
+	LOAD	_t1, (offset + UNIT(1))(src);			\
+	LOAD	_t2, (offset + UNIT(2))(src); 			\
+	LOAD	_t3, (offset + UNIT(3))(src); 			\
+	ADDC(sum, _t0);						\
+	ADDC(sum, _t1);						\
+	ADDC(sum, _t2);						\
+	ADDC(sum, _t3)
+
+#ifdef USE_DOUBLE
+#define CSUM_BIGCHUNK(src, offset, sum, _t0, _t1, _t2, _t3)	\
+	CSUM_BIGCHUNK1(src, offset, sum, _t0, _t1, _t2, _t3)
+#else
+#define CSUM_BIGCHUNK(src, offset, sum, _t0, _t1, _t2, _t3)	\
+	CSUM_BIGCHUNK1(src, offset, sum, _t0, _t1, _t2, _t3);	\
+	CSUM_BIGCHUNK1(src, offset + 0x10, sum, _t0, _t1, _t2, _t3)
+#endif
+
+/*
+ * a0: source address
+ * a1: length of the area to checksum
+ * a2: partial checksum
+ */
+
+#define src a0
+#define sum v0
+
+	.text
+	.set	noreorder
+	.align	5
+LEAF(csum_partial)
+	move	sum, zero
+	move	t7, zero
+
+	sltiu	t8, a1, 0x8
+	bnez	t8, .Lsmall_csumcpy		/* < 8 bytes to copy */
+	 move	t2, a1
+
+	andi	t7, src, 0x1			/* odd buffer? */
+	PREF(	0, 0*32(src) )
+	PREF(	0, 1*32(src) )
+	PREF(	0, 2*32(src) )
+	PREF(	0, 3*32(src) )
+
+.Lhword_align:
+	beqz	t7, .Lword_align
+	 andi	t8, src, 0x2
+
+	lbu	t0, (src)
+	LONG_SUBU	a1, a1, 0x1
+#ifdef __MIPSEL__
+	sll	t0, t0, 8
+#endif
+	ADDC(sum, t0)
+	PTR_ADDU	src, src, 0x1
+	andi	t8, src, 0x2
+
+.Lword_align:
+	beqz	t8, .Ldword_align
+	 sltiu	t8, a1, 56
+
+	lhu	t0, (src)
+	LONG_SUBU	a1, a1, 0x2
+	ADDC(sum, t0)
+	sltiu	t8, a1, 56
+	PTR_ADDU	src, src, 0x2
+
+.Ldword_align:
+	bnez	t8, .Ldo_end_words
+	 move	t8, a1
+
+	andi	t8, src, 0x4
+	beqz	t8, .Lqword_align
+	 andi	t8, src, 0x8
+
+	LOAD32	t0, 0x00(src)
+	LONG_SUBU	a1, a1, 0x4
+	ADDC(sum, t0)
+	PTR_ADDU	src, src, 0x4
+	andi	t8, src, 0x8
+
+.Lqword_align:
+	beqz	t8, .Loword_align
+	 andi	t8, src, 0x10
+
+#ifdef USE_DOUBLE
+	ld	t0, 0x00(src)
+	LONG_SUBU	a1, a1, 0x8
+	ADDC(sum, t0)
+#else
+	lw	t0, 0x00(src)
+	lw	t1, 0x04(src)
+	LONG_SUBU	a1, a1, 0x8
+	ADDC(sum, t0)
+	ADDC(sum, t1)
+#endif
+	PTR_ADDU	src, src, 0x8
+	andi	t8, src, 0x10
+
+.Loword_align:
+	beqz	t8, .Lbegin_movement
+	 LONG_SRL	t8, a1, 0x7
+
+#ifdef USE_DOUBLE
+	ld	t0, 0x00(src)
+	ld	t1, 0x08(src)
+	ADDC(sum, t0)
+	ADDC(sum, t1)
+#else
+	CSUM_BIGCHUNK1(src, 0x00, sum, t0, t1, t3, t4)
+#endif
+	LONG_SUBU	a1, a1, 0x10
+	PTR_ADDU	src, src, 0x10
+	LONG_SRL	t8, a1, 0x7
+
+.Lbegin_movement:
+	beqz	t8, 1f
+	 andi	t2, a1, 0x40
+
+.Lmove_128bytes:
+	PREF(	0, 4*32(src) )
+	PREF(	0, 5*32(src) )
+	PREF(	0, 6*32(src) )
+	PREF(	0, 7*32(src) )
+	CSUM_BIGCHUNK(src, 0x00, sum, t0, t1, t3, t4)
+	CSUM_BIGCHUNK(src, 0x20, sum, t0, t1, t3, t4)
+	CSUM_BIGCHUNK(src, 0x40, sum, t0, t1, t3, t4)
+	CSUM_BIGCHUNK(src, 0x60, sum, t0, t1, t3, t4)
+	LONG_SUBU	t8, t8, 0x01
+	.set	reorder				/* DADDI_WAR */
+	PTR_ADDU	src, src, 0x80
+	bnez	t8, .Lmove_128bytes
+	.set	noreorder
+
+1:
+	beqz	t2, 1f
+	 andi	t2, a1, 0x20
+
+.Lmove_64bytes:
+	CSUM_BIGCHUNK(src, 0x00, sum, t0, t1, t3, t4)
+	CSUM_BIGCHUNK(src, 0x20, sum, t0, t1, t3, t4)
+	PTR_ADDU	src, src, 0x40
+
+1:
+	beqz	t2, .Ldo_end_words
+	 andi	t8, a1, 0x1c
+
+.Lmove_32bytes:
+	CSUM_BIGCHUNK(src, 0x00, sum, t0, t1, t3, t4)
+	andi	t8, a1, 0x1c
+	PTR_ADDU	src, src, 0x20
+
+.Ldo_end_words:
+	beqz	t8, .Lsmall_csumcpy
+	 andi	t2, a1, 0x3
+	LONG_SRL	t8, t8, 0x2
+
+.Lend_words:
+	LOAD32	t0, (src)
+	LONG_SUBU	t8, t8, 0x1
+	ADDC(sum, t0)
+	.set	reorder				/* DADDI_WAR */
+	PTR_ADDU	src, src, 0x4
+	bnez	t8, .Lend_words
+	.set	noreorder
+
+/* unknown src alignment and < 8 bytes to go  */
+.Lsmall_csumcpy:
+	move	a1, t2
+
+	andi	t0, a1, 4
+	beqz	t0, 1f
+	 andi	t0, a1, 2
+
+	/* Still a full word to go  */
+	ulw	t1, (src)
+	PTR_ADDIU	src, 4
+#ifdef USE_DOUBLE
+	dsll	t1, t1, 32			/* clear lower 32bit */
+#endif
+	ADDC(sum, t1)
+
+1:	move	t1, zero
+	beqz	t0, 1f
+	 andi	t0, a1, 1
+
+	/* Still a halfword to go  */
+	ulhu	t1, (src)
+	PTR_ADDIU	src, 2
+
+1:	beqz	t0, 1f
+	 sll	t1, t1, 16
+
+	lbu	t2, (src)
+	 nop
+
+#ifdef __MIPSEB__
+	sll	t2, t2, 8
+#endif
+	or	t1, t2
+
+1:	ADDC(sum, t1)
+
+	/* fold checksum */
+	.set	push
+	.set	noat
+#ifdef USE_DOUBLE
+	dsll32	v1, sum, 0
+	daddu	sum, v1
+	sltu	v1, sum, v1
+	dsra32	sum, sum, 0
+	addu	sum, v1
+#endif
+	sll	v1, sum, 16
+	addu	sum, v1
+	sltu	v1, sum, v1
+	srl	sum, sum, 16
+	addu	sum, v1
+
+	/* odd buffer alignment? */
+	beqz	t7, 1f
+	 nop
+	sll	v1, sum, 8
+	srl	sum, sum, 8
+	or	sum, v1
+	andi	sum, 0xffff
+	.set	pop
+1:
+	.set	reorder
+	/* Add the passed partial csum.  */
+	ADDC32(sum, a2)
+	jr	ra
+	.set	noreorder
+	END(csum_partial)
+
+
+/*
+ * checksum and copy routines based on memcpy.S
+ *
+ *	csum_partial_copy_nocheck(src, dst, len, sum)
+ *	__csum_partial_copy_user(src, dst, len, sum, errp)
+ *
+ * See "Spec" in memcpy.S for details.  Unlike __copy_user, all
+ * function in this file use the standard calling convention.
+ */
+
+#define src a0
+#define dst a1
+#define len a2
+#define psum a3
+#define sum v0
+#define odd t8
+#define errptr t9
+
+/*
+ * The exception handler for loads requires that:
+ *  1- AT contain the address of the byte just past the end of the source
+ *     of the copy,
+ *  2- src_entry <= src < AT, and
+ *  3- (dst - src) == (dst_entry - src_entry),
+ * The _entry suffix denotes values when __copy_user was called.
+ *
+ * (1) is set up up by __csum_partial_copy_from_user and maintained by
+ *	not writing AT in __csum_partial_copy
+ * (2) is met by incrementing src by the number of bytes copied
+ * (3) is met by not doing loads between a pair of increments of dst and src
+ *
+ * The exception handlers for stores stores -EFAULT to errptr and return.
+ * These handlers do not need to overwrite any data.
+ */
+
+#define EXC(inst_reg,addr,handler)		\
+9:	inst_reg, addr;				\
+	.section __ex_table,"a";		\
+	PTR	9b, handler;			\
+	.previous
+
+#ifdef USE_DOUBLE
+
+#define LOAD   ld
+#define LOADL  ldl
+#define LOADR  ldr
+#define STOREL sdl
+#define STORER sdr
+#define STORE  sd
+#define ADD    daddu
+#define SUB    dsubu
+#define SRL    dsrl
+#define SLL    dsll
+#define SLLV   dsllv
+#define SRLV   dsrlv
+#define NBYTES 8
+#define LOG_NBYTES 3
+
+#else
+
+#define LOAD   lw
+#define LOADL  lwl
+#define LOADR  lwr
+#define STOREL swl
+#define STORER swr
+#define STORE  sw
+#define ADD    addu
+#define SUB    subu
+#define SRL    srl
+#define SLL    sll
+#define SLLV   sllv
+#define SRLV   srlv
+#define NBYTES 4
+#define LOG_NBYTES 2
+
+#endif /* USE_DOUBLE */
+
+#ifdef CONFIG_CPU_LITTLE_ENDIAN
+#define LDFIRST LOADR
+#define LDREST  LOADL
+#define STFIRST STORER
+#define STREST  STOREL
+#define SHIFT_DISCARD SLLV
+#define SHIFT_DISCARD_REVERT SRLV
+#else
+#define LDFIRST LOADL
+#define LDREST  LOADR
+#define STFIRST STOREL
+#define STREST  STORER
+#define SHIFT_DISCARD SRLV
+#define SHIFT_DISCARD_REVERT SLLV
+#endif
+
+#define FIRST(unit) ((unit)*NBYTES)
+#define REST(unit)  (FIRST(unit)+NBYTES-1)
+
+#define ADDRMASK (NBYTES-1)
+
+#ifndef CONFIG_CPU_DADDI_WORKAROUNDS
+	.set	noat
+#else
+	.set	at=v1
+#endif
+
+LEAF(__csum_partial_copy_user)
+	PTR_ADDU	AT, src, len	/* See (1) above. */
+#ifdef CONFIG_64BIT
+	move	errptr, a4
+#else
+	lw	errptr, 16(sp)
+#endif
+FEXPORT(csum_partial_copy_nocheck)
+	move	sum, zero
+	move	odd, zero
+	/*
+	 * Note: dst & src may be unaligned, len may be 0
+	 * Temps
+	 */
+	/*
+	 * The "issue break"s below are very approximate.
+	 * Issue delays for dcache fills will perturb the schedule, as will
+	 * load queue full replay traps, etc.
+	 *
+	 * If len < NBYTES use byte operations.
+	 */
+	sltu	t2, len, NBYTES
+	and	t1, dst, ADDRMASK
+	bnez	t2, .Lcopy_bytes_checklen
+	 and	t0, src, ADDRMASK
+	andi	odd, dst, 0x1			/* odd buffer? */
+	PREF(	0, 0*32(src) )
+	PREF(	0, 1*32(src) )
+	PREF(	1, 0*32(dst) )
+	PREF(	1, 1*32(dst) )
+	bnez	t1, .Ldst_unaligned
+	 nop
+	bnez	t0, .Lsrc_unaligned_dst_aligned
+	/*
+	 * use delay slot for fall-through
+	 * src and dst are aligned; need to compute rem
+	 */
+.Lboth_aligned:
+	 SRL	t0, len, LOG_NBYTES+3    # +3 for 8 units/iter
+	beqz	t0, .Lcleanup_both_aligned # len < 8*NBYTES
+	 nop
+	PREF(	0, 2*32(src) )
+	PREF(	0, 3*32(src) )
+	PREF(	1, 2*32(dst) )
+	PREF(	1, 3*32(dst) )
+	SUB	len, 8*NBYTES		# subtract here for bgez loop
+	.align	4
+1:
+EXC(	LOAD	t0, UNIT(0)(src),	.Ll_exc)
+EXC(	LOAD	t1, UNIT(1)(src),	.Ll_exc_copy)
+EXC(	LOAD	t2, UNIT(2)(src),	.Ll_exc_copy)
+EXC(	LOAD	t3, UNIT(3)(src),	.Ll_exc_copy)
+EXC(	LOAD	t4, UNIT(4)(src),	.Ll_exc_copy)
+EXC(	LOAD	t5, UNIT(5)(src),	.Ll_exc_copy)
+EXC(	LOAD	t6, UNIT(6)(src),	.Ll_exc_copy)
+EXC(	LOAD	t7, UNIT(7)(src),	.Ll_exc_copy)
+	SUB	len, len, 8*NBYTES
+	ADD	src, src, 8*NBYTES
+EXC(	STORE	t0, UNIT(0)(dst),	.Ls_exc)
+	ADDC(sum, t0)
+EXC(	STORE	t1, UNIT(1)(dst),	.Ls_exc)
+	ADDC(sum, t1)
+EXC(	STORE	t2, UNIT(2)(dst),	.Ls_exc)
+	ADDC(sum, t2)
+EXC(	STORE	t3, UNIT(3)(dst),	.Ls_exc)
+	ADDC(sum, t3)
+EXC(	STORE	t4, UNIT(4)(dst),	.Ls_exc)
+	ADDC(sum, t4)
+EXC(	STORE	t5, UNIT(5)(dst),	.Ls_exc)
+	ADDC(sum, t5)
+EXC(	STORE	t6, UNIT(6)(dst),	.Ls_exc)
+	ADDC(sum, t6)
+EXC(	STORE	t7, UNIT(7)(dst),	.Ls_exc)
+	ADDC(sum, t7)
+	PREF(	0, 4*32(src) )
+	PREF(	0, 5*32(src) )
+	PREF(	1, 6*32(dst) )
+	PREF(	1, 7*32(dst) )
+	.set	reorder				/* DADDI_WAR */
+	ADD	dst, dst, 8*NBYTES
+	bgez	len, 1b
+	.set	noreorder
+	ADD	len, 8*NBYTES		# revert len (see above)
+
+	/*
+	 * len == the number of bytes left to copy < 8*NBYTES
+	 */
+.Lcleanup_both_aligned:
+#define rem t7
+	beqz	len, .Ldone
+	 sltu	t0, len, 4*NBYTES
+	bnez	t0, .Lless_than_4units
+	 and	rem, len, (NBYTES-1)	# rem = len % NBYTES
+	/*
+	 * len >= 4*NBYTES
+	 */
+EXC(	LOAD	t0, UNIT(0)(src),	.Ll_exc)
+EXC(	LOAD	t1, UNIT(1)(src),	.Ll_exc_copy)
+EXC(	LOAD	t2, UNIT(2)(src),	.Ll_exc_copy)
+EXC(	LOAD	t3, UNIT(3)(src),	.Ll_exc_copy)
+	SUB	len, len, 4*NBYTES
+	ADD	src, src, 4*NBYTES
+EXC(	STORE	t0, UNIT(0)(dst),	.Ls_exc)
+	ADDC(sum, t0)
+EXC(	STORE	t1, UNIT(1)(dst),	.Ls_exc)
+	ADDC(sum, t1)
+EXC(	STORE	t2, UNIT(2)(dst),	.Ls_exc)
+	ADDC(sum, t2)
+EXC(	STORE	t3, UNIT(3)(dst),	.Ls_exc)
+	ADDC(sum, t3)
+	.set	reorder				/* DADDI_WAR */
+	ADD	dst, dst, 4*NBYTES
+	beqz	len, .Ldone
+	.set	noreorder
+.Lless_than_4units:
+	/*
+	 * rem = len % NBYTES
+	 */
+	beq	rem, len, .Lcopy_bytes
+	 nop
+1:
+EXC(	LOAD	t0, 0(src),		.Ll_exc)
+	ADD	src, src, NBYTES
+	SUB	len, len, NBYTES
+EXC(	STORE	t0, 0(dst),		.Ls_exc)
+	ADDC(sum, t0)
+	.set	reorder				/* DADDI_WAR */
+	ADD	dst, dst, NBYTES
+	bne	rem, len, 1b
+	.set	noreorder
+
+	/*
+	 * src and dst are aligned, need to copy rem bytes (rem < NBYTES)
+	 * A loop would do only a byte at a time with possible branch
+	 * mispredicts.  Can't do an explicit LOAD dst,mask,or,STORE
+	 * because can't assume read-access to dst.  Instead, use
+	 * STREST dst, which doesn't require read access to dst.
+	 *
+	 * This code should perform better than a simple loop on modern,
+	 * wide-issue mips processors because the code has fewer branches and
+	 * more instruction-level parallelism.
+	 */
+#define bits t2
+	beqz	len, .Ldone
+	 ADD	t1, dst, len	# t1 is just past last byte of dst
+	li	bits, 8*NBYTES
+	SLL	rem, len, 3	# rem = number of bits to keep
+EXC(	LOAD	t0, 0(src),		.Ll_exc)
+	SUB	bits, bits, rem	# bits = number of bits to discard
+	SHIFT_DISCARD t0, t0, bits
+EXC(	STREST	t0, -1(t1),		.Ls_exc)
+	SHIFT_DISCARD_REVERT t0, t0, bits
+	.set reorder
+	ADDC(sum, t0)
+	b	.Ldone
+	.set noreorder
+.Ldst_unaligned:
+	/*
+	 * dst is unaligned
+	 * t0 = src & ADDRMASK
+	 * t1 = dst & ADDRMASK; T1 > 0
+	 * len >= NBYTES
+	 *
+	 * Copy enough bytes to align dst
+	 * Set match = (src and dst have same alignment)
+	 */
+#define match rem
+EXC(	LDFIRST	t3, FIRST(0)(src),	.Ll_exc)
+	ADD	t2, zero, NBYTES
+EXC(	LDREST	t3, REST(0)(src),	.Ll_exc_copy)
+	SUB	t2, t2, t1	# t2 = number of bytes copied
+	xor	match, t0, t1
+EXC(	STFIRST t3, FIRST(0)(dst),	.Ls_exc)
+	SLL	t4, t1, 3		# t4 = number of bits to discard
+	SHIFT_DISCARD t3, t3, t4
+	/* no SHIFT_DISCARD_REVERT to handle odd buffer properly */
+	ADDC(sum, t3)
+	beq	len, t2, .Ldone
+	 SUB	len, len, t2
+	ADD	dst, dst, t2
+	beqz	match, .Lboth_aligned
+	 ADD	src, src, t2
+
+.Lsrc_unaligned_dst_aligned:
+	SRL	t0, len, LOG_NBYTES+2    # +2 for 4 units/iter
+	PREF(	0, 2*32(src) )
+	PREF(	0, 3*32(src) )
+	beqz	t0, .Lcleanup_src_unaligned
+	 and	rem, len, (4*NBYTES-1)   # rem = len % 4*NBYTES
+	PREF(	1, 2*32(dst) )
+	PREF(	1, 3*32(dst) )
+1:
+/*
+ * Avoid consecutive LD*'s to the same register since some mips
+ * implementations can't issue them in the same cycle.
+ * It's OK to load FIRST(N+1) before REST(N) because the two addresses
+ * are to the same unit (unless src is aligned, but it's not).
+ */
+EXC(	LDFIRST	t0, FIRST(0)(src),	.Ll_exc)
+EXC(	LDFIRST	t1, FIRST(1)(src),	.Ll_exc_copy)
+	SUB     len, len, 4*NBYTES
+EXC(	LDREST	t0, REST(0)(src),	.Ll_exc_copy)
+EXC(	LDREST	t1, REST(1)(src),	.Ll_exc_copy)
+EXC(	LDFIRST	t2, FIRST(2)(src),	.Ll_exc_copy)
+EXC(	LDFIRST	t3, FIRST(3)(src),	.Ll_exc_copy)
+EXC(	LDREST	t2, REST(2)(src),	.Ll_exc_copy)
+EXC(	LDREST	t3, REST(3)(src),	.Ll_exc_copy)
+	ADD	src, src, 4*NBYTES
+	PREF(   0, 4*32(src) )          # 0 is PREF_LOAD  (not streamed)
+	PREF(   0, 5*32(src) )          # 0 is PREF_LOAD  (not streamed)
+
+#ifdef CONFIG_CPU_SB1
+	nop				# improves slotting
+#endif
+EXC(	STORE	t0, UNIT(0)(dst),	.Ls_exc)
+	ADDC(sum, t0)
+EXC(	STORE	t1, UNIT(1)(dst),	.Ls_exc)
+	ADDC(sum, t1)
+EXC(	STORE	t2, UNIT(2)(dst),	.Ls_exc)
+	ADDC(sum, t2)
+EXC(	STORE	t3, UNIT(3)(dst),	.Ls_exc)
+	ADDC(sum, t3)
+	PREF(   1, 6*32(dst) )          # 1 is PREF_STORE (not streamed)
+	PREF(   1, 7*32(dst) )          # 1 is PREF_STORE (not streamed)
+	.set	reorder				/* DADDI_WAR */
+	ADD	dst, dst, 4*NBYTES
+	bne	len, rem, 1b
+	.set	noreorder
+
+.Lcleanup_src_unaligned:
+	beqz	len, .Ldone
+	 and	rem, len, NBYTES-1  # rem = len % NBYTES
+	beq	rem, len, .Lcopy_bytes
+	 nop
+1:
+EXC(	LDFIRST t0, FIRST(0)(src),	.Ll_exc)
+EXC(	LDREST	t0, REST(0)(src),	.Ll_exc_copy)
+	ADD	src, src, NBYTES
+	SUB	len, len, NBYTES
+EXC(	STORE	t0, 0(dst),		.Ls_exc)
+	ADDC(sum, t0)
+	.set	reorder				/* DADDI_WAR */
+	ADD	dst, dst, NBYTES
+	bne	len, rem, 1b
+	.set	noreorder
+
+.Lcopy_bytes_checklen:
+	beqz	len, .Ldone
+	 nop
+.Lcopy_bytes:
+	/* 0 < len < NBYTES  */
+#ifdef CONFIG_CPU_LITTLE_ENDIAN
+#define SHIFT_START 0
+#define SHIFT_INC 8
+#else
+#define SHIFT_START 8*(NBYTES-1)
+#define SHIFT_INC -8
+#endif
+	move	t2, zero	# partial word
+	li	t3, SHIFT_START	# shift
+/* use .Ll_exc_copy here to return correct sum on fault */
+#define COPY_BYTE(N)			\
+EXC(	lbu	t0, N(src), .Ll_exc_copy);	\
+	SUB	len, len, 1;		\
+EXC(	sb	t0, N(dst), .Ls_exc);	\
+	SLLV	t0, t0, t3;		\
+	addu	t3, SHIFT_INC;		\
+	beqz	len, .Lcopy_bytes_done;	\
+	 or	t2, t0
+
+	COPY_BYTE(0)
+	COPY_BYTE(1)
+#ifdef USE_DOUBLE
+	COPY_BYTE(2)
+	COPY_BYTE(3)
+	COPY_BYTE(4)
+	COPY_BYTE(5)
+#endif
+EXC(	lbu	t0, NBYTES-2(src), .Ll_exc_copy)
+	SUB	len, len, 1
+EXC(	sb	t0, NBYTES-2(dst), .Ls_exc)
+	SLLV	t0, t0, t3
+	or	t2, t0
+.Lcopy_bytes_done:
+	ADDC(sum, t2)
+.Ldone:
+	/* fold checksum */
+	.set	push
+	.set	noat
+#ifdef USE_DOUBLE
+	dsll32	v1, sum, 0
+	daddu	sum, v1
+	sltu	v1, sum, v1
+	dsra32	sum, sum, 0
+	addu	sum, v1
+#endif
+	sll	v1, sum, 16
+	addu	sum, v1
+	sltu	v1, sum, v1
+	srl	sum, sum, 16
+	addu	sum, v1
+
+	/* odd buffer alignment? */
+	beqz	odd, 1f
+	 nop
+	sll	v1, sum, 8
+	srl	sum, sum, 8
+	or	sum, v1
+	andi	sum, 0xffff
+	.set	pop
+1:
+	.set reorder
+	ADDC32(sum, psum)
+	jr	ra
+	.set noreorder
+
+.Ll_exc_copy:
+	/*
+	 * Copy bytes from src until faulting load address (or until a
+	 * lb faults)
+	 *
+	 * When reached by a faulting LDFIRST/LDREST, THREAD_BUADDR($28)
+	 * may be more than a byte beyond the last address.
+	 * Hence, the lb below may get an exception.
+	 *
+	 * Assumes src < THREAD_BUADDR($28)
+	 */
+	LOAD	t0, TI_TASK($28)
+	 li	t2, SHIFT_START
+	LOAD	t0, THREAD_BUADDR(t0)
+1:
+EXC(	lbu	t1, 0(src),	.Ll_exc)
+	ADD	src, src, 1
+	sb	t1, 0(dst)	# can't fault -- we're copy_from_user
+	SLLV	t1, t1, t2
+	addu	t2, SHIFT_INC
+	ADDC(sum, t1)
+	.set	reorder				/* DADDI_WAR */
+	ADD	dst, dst, 1
+	bne	src, t0, 1b
+	.set	noreorder
+.Ll_exc:
+	LOAD	t0, TI_TASK($28)
+	 nop
+	LOAD	t0, THREAD_BUADDR(t0)	# t0 is just past last good address
+	 nop
+	SUB	len, AT, t0		# len number of uncopied bytes
+	/*
+	 * Here's where we rely on src and dst being incremented in tandem,
+	 *   See (3) above.
+	 * dst += (fault addr - src) to put dst at first byte to clear
+	 */
+	ADD	dst, t0			# compute start address in a1
+	SUB	dst, src
+	/*
+	 * Clear len bytes starting at dst.  Can't call __bzero because it
+	 * might modify len.  An inefficient loop for these rare times...
+	 */
+	.set	reorder				/* DADDI_WAR */
+	SUB	src, len, 1
+	beqz	len, .Ldone
+	.set	noreorder
+1:	sb	zero, 0(dst)
+	ADD	dst, dst, 1
+	.set	push
+	.set	noat
+#ifndef CONFIG_CPU_DADDI_WORKAROUNDS
+	bnez	src, 1b
+	 SUB	src, src, 1
+#else
+	li	v1, 1
+	bnez	src, 1b
+	 SUB	src, src, v1
+#endif
+	li	v1, -EFAULT
+	b	.Ldone
+	 sw	v1, (errptr)
+
+.Ls_exc:
+	li	v0, -1 /* invalid checksum */
+	li	v1, -EFAULT
+	jr	ra
+	 sw	v1, (errptr)
+	.set	pop
+	END(__csum_partial_copy_user)
diff --git a/arch/mips/lib/delay.c b/arch/mips/lib/delay.c
index 5995969..5a41f83 100644
--- a/arch/mips/lib/delay.c
+++ b/arch/mips/lib/delay.c
@@ -15,6 +15,62 @@
 #include <asm/compiler.h>
 #include <asm/war.h>
 
+#ifdef CONFIG_RMI_PHOENIX
+
+extern u64 xlr_hpt_read(void);
+inline void __delay(unsigned int loops)
+{
+	uint32_t initial_count,curr_count;
+	uint32_t delta;
+
+	delta = loops; 
+
+	initial_count = xlr_hpt_read();
+        while (1) {
+		curr_count = xlr_hpt_read();
+		if ((uint32_t)(curr_count - initial_count) > delta)
+			return;
+	}
+}
+EXPORT_SYMBOL(__delay);
+
+inline void __udelay(unsigned long us)
+{
+	uint32_t initial_count,curr_count;
+	uint32_t delta;
+
+	delta = us * 66; /* clock runs at 66.6MHz speed */
+			    /* cant do floating point ops here */
+
+	initial_count = xlr_hpt_read();
+        while (1) {
+		curr_count = xlr_hpt_read();
+		if ((uint32_t)(curr_count - initial_count) > delta)
+			return;
+	}
+}
+EXPORT_SYMBOL(__udelay);
+
+inline void __ndelay(unsigned long ns)
+{
+	uint32_t initial_count,curr_count;
+	uint32_t delta;
+
+	/* clock runs at 66.6MHz speed
+	the minimum delay we have have is 1/66.67 = ~15 nsec */
+	delta = (ns >> 4) +1;
+
+	initial_count = xlr_hpt_read();
+        while (1) {
+		curr_count = xlr_hpt_read();
+		if ((uint32_t)(curr_count - initial_count) > delta)
+			return;
+	}
+}
+EXPORT_SYMBOL(__ndelay);
+
+#else
+
 inline void __delay(unsigned int loops)
 {
 	__asm__ __volatile__ (
@@ -54,3 +110,4 @@ void __ndelay(unsigned long ns)
 	__delay((ns * 0x00000005ull * HZ * lpj) >> 32);
 }
 EXPORT_SYMBOL(__ndelay);
+#endif
diff --git a/arch/mips/math-emu/cp1emu.c b/arch/mips/math-emu/cp1emu.c
index a03bf00..bffaf80 100644
--- a/arch/mips/math-emu/cp1emu.c
+++ b/arch/mips/math-emu/cp1emu.c
@@ -1,3 +1,14 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
 /*
  * cp1emu.c: a MIPS coprocessor 1 (fpu) instruction emulator
  *
@@ -661,6 +672,10 @@ static int fpux_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 		u32 __user *va;
 		u32 val;
 
+#ifdef CONFIG_PROFILE_MATHEMU
+		fpuemuprivate.stats.s_format.total++;
+		fpuemuprivate.stats.s_format.ops[MIPSInst_FUNC(ir)]++;
+#endif
 		switch (MIPSInst_FUNC(ir)) {
 		case lwxc1_op:
 			va = (void __user *) (xcp->regs[MIPSInst_FR(ir)] +
@@ -750,6 +765,10 @@ static int fpux_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 		u64 __user *va;
 		u64 val;
 
+#ifdef CONFIG_PROFILE_MATHEMU
+		fpuemuprivate.stats.d_format.total++;
+		fpuemuprivate.stats.d_format.ops[MIPSInst_FUNC(ir)]++;
+#endif
 		switch (MIPSInst_FUNC(ir)) {
 		case ldxc1_op:
 			va = (void __user *) (xcp->regs[MIPSInst_FR(ir)] +
@@ -857,6 +876,10 @@ static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 			ieee754sp(*u) (ieee754sp);
 		} handler;
 
+#ifdef CONFIG_PROFILE_MATHEMU
+		fpuemuprivate.stats.s_format.total++;
+		fpuemuprivate.stats.s_format.ops[MIPSInst_FUNC(ir)]++;
+#endif
 		switch (MIPSInst_FUNC(ir)) {
 			/* binary ops */
 		case fadd_op:
@@ -1042,6 +1065,10 @@ static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 			ieee754dp(*u) (ieee754dp);
 		} handler;
 
+#ifdef CONFIG_PROFILE_MATHEMU
+		fpuemuprivate.stats.d_format.total++;
+		fpuemuprivate.stats.d_format.ops[MIPSInst_FUNC(ir)]++;
+#endif
 		switch (MIPSInst_FUNC(ir)) {
 			/* binary ops */
 		case fadd_op:
@@ -1214,7 +1241,10 @@ static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 
 	case w_fmt:{
 		ieee754sp fs;
-
+#ifdef CONFIG_PROFILE_MATHEMU
+		fpuemuprivate.stats.w_format.total++;
+		fpuemuprivate.stats.w_format.ops[MIPSInst_FUNC(ir)]++;
+#endif
 		switch (MIPSInst_FUNC(ir)) {
 		case fcvts_op:
 			/* convert word to single precision real */
@@ -1236,6 +1266,10 @@ static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 
 #if defined(__mips64)
 	case l_fmt:{
+#ifdef CONFIG_PROFILE_MATHEMU
+		fpuemuprivate.stats.l_format.total++;
+		fpuemuprivate.stats.l_format.ops[MIPSInst_FUNC(ir)]++;
+#endif
 		switch (MIPSInst_FUNC(ir)) {
 		case fcvts_op:
 			/* convert long to single precision real */
diff --git a/arch/mips/math-emu/kernel_linkage.c b/arch/mips/math-emu/kernel_linkage.c
index 52e6c58..ed460ac 100644
--- a/arch/mips/math-emu/kernel_linkage.c
+++ b/arch/mips/math-emu/kernel_linkage.c
@@ -1,3 +1,14 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
 /*
  *  Kevin D. Kissell, kevink@mips and Carsten Langgaard, carstenl@mips.com
  *  Copyright (C) 2000 MIPS Technologies, Inc.  All rights reserved.
@@ -29,6 +40,198 @@
 
 #define SIGNALLING_NAN 0x7ff800007ff80000LL
 
+#ifdef CONFIG_PROFILE_MATHEMU
+
+#include <asm/inst.h>
+#include <linux/proc_fs.h>
+
+#define FPUEMU_PROC_ENT "fpuemu"
+static struct proc_dir_entry *proc_ent;
+
+/*
+ * func field of cop1 instructions using d, s or w format.
+ */
+static char *cop1_sdw_func_names[] = {
+  "fadd_op",     /* 0x00 */
+  "fsub_op",     /* 0x01 */
+  "fmul_op",     /* 0x02 */
+  "fdiv_op",     /* 0x03 */
+  "fsqrt_op",    /* 0x04 */
+  "fabs_op",     /* 0x05 */
+  "fmov_op",     /* 0x06 */
+  "fneg_op",     /* 0x07 */
+  "froundl_op",  /* 0x08 */
+  "ftruncl_op",  /* 0x09 */
+  "fceill_op",   /* 0x0a */
+  "ffloorl_op",  /* 0x0b */
+  "fround_op",   /* 0x0c */
+  "ftrunc_op",   /* 0x0d */
+  "fceil_op",    /* 0x0e */
+  "ffloor_op",   /* 0x0f */
+  NULL,          /* 0x10 */
+  "fmovc_op",    /* 0x11 */
+  "fmovz_op",    /* 0x12 */
+  "fmovn_op",    /* 0x13 */
+  NULL,          /* 0x14 */
+  "frecip_op",   /* 0x15 */
+  "frsqrt_op",   /* 0x16 */
+  NULL,          /* 0x17 */
+  NULL,          /* 0x18 */
+  NULL,          /* 0x19 */
+  NULL,          /* 0x1a */
+  NULL,          /* 0x1b */
+  NULL,          /* 0x1c */
+  NULL,          /* 0x1d */
+  NULL,          /* 0x1e */
+  NULL,          /* 0x1f */
+  "fcvts_op",    /* 0x20 */
+  "fcvtd_op",    /* 0x21 */
+  "fcvte_op",    /* 0x22 */
+  NULL,          /* 0x23 */
+  "fcvtw_op",    /* 0x24 */
+  "fcvtl_op",    /* 0x25 */
+  NULL,          /* 0x26 */
+  NULL,          /* 0x27 */
+  NULL,          /* 0x28 */
+  NULL,          /* 0x29 */
+  NULL,          /* 0x2a */
+  NULL,          /* 0x2b */
+  NULL,          /* 0x2c */
+  NULL,          /* 0x2d */
+  NULL,          /* 0x2e */
+  NULL,          /* 0x2f */
+  "fcmp_op"      /* 0x30 */
+};
+
+static int proc_read(char *buf , char **start, off_t offset,
+                        int len, int *eof, void *data)
+{
+  char *p = buf;
+
+  //printk("proc_read entered %p %p %d %d %p %p\n", buf, start, offset, len, eof, data);  
+  p += sprintf(p, "%s\n", "FPUEMU Statistics:");
+  p += sprintf(p, "emulated: %d\n", fpuemuprivate.stats.emulated);
+  p += sprintf(p, "loads: %d\n", fpuemuprivate.stats.loads);
+  p += sprintf(p, "stores: %d\n", fpuemuprivate.stats.stores);
+  p += sprintf(p, "cp1ops: %d\n", fpuemuprivate.stats.cp1ops);
+  p += sprintf(p, "cp1xops: %d\n", fpuemuprivate.stats.cp1xops);
+  p += sprintf(p, "errors: %d\n", fpuemuprivate.stats.errors);
+
+  p += sprintf(p, "format totals:\n");
+  p += sprintf(p, "\ts_fmt: %d\n", fpuemuprivate.stats.s_format.total);
+  if (fpuemuprivate.stats.s_format.total > 0) {
+    int i, j;
+    p += sprintf(p, "\tfunctions:");
+    for (i = 0; i < 8; i++) {
+      p += sprintf(p, "\n\t");
+      for (j = 0; j < 8; j++) {
+	p += sprintf(p,"%d ",
+		     fpuemuprivate.stats.s_format.ops[i*8 + j]);
+      }
+    }
+    p += sprintf(p, "\n");
+  }
+  p += sprintf(p, "\td_fmt: %d\n", fpuemuprivate.stats.d_format.total);
+  if (fpuemuprivate.stats.d_format.total > 0) {
+    int i, j;
+    p += sprintf(p, "\tfunctions:");
+    for (i = 0; i < 8; i++) {
+      p += sprintf(p, "\n\t");
+      for (j = 0; j < 8; j++) {
+	p += sprintf(p,"%d ",
+		     fpuemuprivate.stats.d_format.ops[i*8 + j]);
+      }
+    }
+    p += sprintf(p, "\n");
+  }
+  p += sprintf(p, "\tw_fmt: %d\n", fpuemuprivate.stats.w_format.total);
+  if (fpuemuprivate.stats.w_format.total > 0) {
+    int i, j;
+    p += sprintf(p, "\tfunctions:");
+    for (i = 0; i < 8; i++) {
+      p += sprintf(p, "\n\t");
+      for (j = 0; j < 8; j++) {
+	p += sprintf(p,"%d ",
+		     fpuemuprivate.stats.w_format.ops[i*8 + j]);
+      }
+    }
+    p += sprintf(p, "\n");
+  }
+  p += sprintf(p, "\tl_fmt: %d\n", fpuemuprivate.stats.l_format.total);
+  if (fpuemuprivate.stats.l_format.total > 0) {
+    int i, j;
+    p += sprintf(p, "\tfunctions:");
+    for (i = 0; i < 8; i++) {
+      p += sprintf(p, "\n\t");
+      for (j = 0; j < 8; j++) {
+	p += sprintf(p,"%d ",
+		     fpuemuprivate.stats.l_format.ops[i*8 + j]);
+      }
+    }
+    p += sprintf(p, "\n");
+  }
+  
+  if (fpuemuprivate.stats.s_format.total > 0) {
+    int i, fcmp_total;
+    p += sprintf(p, "\nSingle precision:\ttotal %d\n",
+		 fpuemuprivate.stats.s_format.total);
+    for (i = fadd_op; i < fcmp_op; i++)
+      if (fpuemuprivate.stats.s_format.ops[i] > 0)
+	p += sprintf(p, "\t%s:\t%d\n", cop1_sdw_func_names[i],
+		     fpuemuprivate.stats.s_format.ops[i]);
+    for (i = fcmp_op, fcmp_total = 0; i < 0x40; i++)
+      fcmp_total += fpuemuprivate.stats.s_format.ops[i];
+    if (fcmp_total > 0)
+      p += sprintf(p, "\t%s:\t%d (all compare ops combined)\n",
+		   cop1_sdw_func_names[fcmp_op], fcmp_total);
+    p += sprintf(p, "\n");
+  }
+
+  if (fpuemuprivate.stats.d_format.total > 0) {
+    int i, fcmp_total;
+    p += sprintf(p, "\nDouble precision:\ttotal %d\n",
+		 fpuemuprivate.stats.d_format.total);
+    for (i = fadd_op; i < fcmp_op; i++)
+      if (fpuemuprivate.stats.d_format.ops[i] > 0)
+	p += sprintf(p, "\t%s:\t%d\n", cop1_sdw_func_names[i],
+		     fpuemuprivate.stats.d_format.ops[i]);
+    for (i = fcmp_op, fcmp_total = 0; i < 0x40; i++)
+      fcmp_total += fpuemuprivate.stats.d_format.ops[i];
+    if (fcmp_total > 0)
+      p += sprintf(p, "\t%s:\t%d (all compare ops combined)\n",
+		   cop1_sdw_func_names[fcmp_op], fcmp_total);
+    p += sprintf(p, "\n");
+  }
+
+  if (fpuemuprivate.stats.w_format.total > 0) {
+    int i, fcmp_total;
+    p += sprintf(p, "\nw format:\ttotal %d\n",
+		 fpuemuprivate.stats.w_format.total);
+    for (i = fadd_op; i < fcmp_op; i++)
+      if (fpuemuprivate.stats.w_format.ops[i] > 0)
+	p += sprintf(p, "\t%s:\t%d\n", cop1_sdw_func_names[i],
+		     fpuemuprivate.stats.w_format.ops[i]);
+    for (i = fcmp_op, fcmp_total = 0; i < 0x40; i++)
+      fcmp_total += fpuemuprivate.stats.w_format.ops[i];
+    if (fcmp_total > 0)
+      p += sprintf(p, "\t%s:\t%d (all compare ops combined)\n",
+		   cop1_sdw_func_names[fcmp_op], fcmp_total);
+    p += sprintf(p, "\n");
+  }
+
+  *eof = 1;
+  return p - buf;
+}
+
+static int proc_write(struct file *file, const char *user_buffer,
+                         unsigned long count, void *data)
+{
+  printk("FPUEMU: clearing stats\n");
+  memset(&fpuemuprivate.stats, '\0', sizeof(fpuemuprivate.stats));
+  return count;
+}
+#endif
+
 void fpu_emulator_init_fpu(void)
 {
 	static int first = 1;
@@ -37,6 +240,14 @@ void fpu_emulator_init_fpu(void)
 	if (first) {
 		first = 0;
 		printk("Algorithmics/MIPS FPU Emulator v1.5\n");
+#ifdef CONFIG_PROFILE_MATHEMU
+		proc_ent = create_proc_entry(FPUEMU_PROC_ENT, S_IWUSR | S_IRUGO,
+					     &proc_root);
+		if (proc_ent) {
+		  proc_ent->read_proc = proc_read;
+		  proc_ent->write_proc = proc_write;
+		}
+#endif
 	}
 
 	current->thread.fpu.fcr31 = 0;
diff --git a/arch/mips/mm/Makefile b/arch/mips/mm/Makefile
index 4aa2028..dc14304 100644
--- a/arch/mips/mm/Makefile
+++ b/arch/mips/mm/Makefile
@@ -37,3 +37,7 @@ obj-$(CONFIG_IP22_CPU_SCACHE)	+= sc-ip22.o
 obj-$(CONFIG_R5000_CPU_SCACHE)  += sc-r5k.o
 obj-$(CONFIG_RM7000_CPU_SCACHE)	+= sc-rm7k.o
 obj-$(CONFIG_MIPS_CPU_SCACHE)	+= sc-mips.o
+obj-$(CONFIG_HUGETLB_PAGE)	+= hugetlbpage.o 
+
+#EXTRA_CFLAGS += -Werror
+
diff --git a/arch/mips/mm/c-phoenix.c b/arch/mips/mm/c-phoenix.c
new file mode 100644
index 0000000..92beed8
--- /dev/null
+++ b/arch/mips/mm/c-phoenix.c
@@ -0,0 +1,600 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+/*
+ * Copyright (C) 1996 David S. Miller (dm@engr.sgi.com)
+ * Copyright (C) 1997, 2001 Ralf Baechle (ralf@gnu.org)
+ * 
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
+ */ 
+#include <linux/init.h>
+#include <asm/asm.h>
+#include <asm/mmu_context.h>
+#include <asm/bootinfo.h>
+#include <asm/cacheops.h>
+#include <asm/cpu.h>
+#include <asm/uaccess.h>
+#include <linux/smp.h>
+#include <linux/kallsyms.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+
+#include <asm/rmi/debug.h>
+
+static unsigned int icache_linesz;
+static unsigned int icache_lines;
+
+#ifdef CONFIG_RMI_VMIPS
+extern void rmi_vmips_temp_xkphys_tlb_add(phys_t start, phys_t end, int *tlbs, int *tlbe);
+extern void rmi_vmips_wired_entry_remove(int index);
+#endif
+
+
+#define cacheop(op, base) __asm__ __volatile__ (".set push\n.set mips4\ncache %0, 0(%1)\n.set pop\n" : : "i"(op), "r"(base))
+
+#define cacheop_extable(op, base) do {                    \
+  __asm__ __volatile__(                                    \
+		       "    .set push                \n"   \
+		       "    .set noreorder           \n"   \
+		       "    .set mips4               \n"   \
+		       "1:  cache %0, 0(%1)           \n"  \
+		       "2:  .set pop                 \n"   \
+		       "    .section __ex_table,\"a\"\n"   \
+		            STR(PTR)"\t1b, 2b\n\t"        \
+		       "     .previous               \n"   \
+		       : : "i" (op), "r" (base));          \
+  } while (0) 
+
+#ifdef CONFIG_RMI_XLP
+
+static __inline__ void pipeline_flush(void)
+{
+	__asm__ __volatile__ (
+		".set push         \n"
+		".set arch=xlp     \n"
+		"dla      $8, 1f    \n"
+		"jr.hb   $8        \n"
+		"nop               \n"
+		"1: nop            \n"
+		".set pop          \n"
+		:
+		:
+		: "$8"
+		);
+}
+
+static __inline__ void sync_istream(void)
+{
+	pipeline_flush();
+}
+
+static __inline__ void cacheop_hazard(void)
+{
+	pipeline_flush();
+}
+
+static __inline__ void cacheop_sync_istream(void)
+{
+	pipeline_flush();
+}
+
+#else /* !CONFIG_RMI_XLP */
+
+static __inline__ void sync_istream(void)
+{
+  __asm__ __volatile__ (                                     
+                       ".set push                     \n"    
+                       ".set noreorder                \n"    
+		       //                       " la     $8, 1f                \n"    
+                       //" mtc0   $8, $14               \n"    
+                       //"eret                          \n"    
+		       //"1:nop                         \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+		       "nop                           \n"
+                       ".set pop                      \n"    
+                       : : : "$8"
+		       );
+}
+
+static __inline__ void cacheop_hazard(void)
+{
+  __asm__ __volatile__ (                                     
+                       ".set push                     \n"    
+                       ".set noreorder                \n"    
+                       " nop;nop;nop;nop              \n"    
+                       " nop;nop;nop;nop              \n"    
+                       ".set pop                      \n"    
+                       );  
+}
+
+static __inline__ void cacheop_sync_istream(void)
+{
+  cacheop_hazard();
+  sync_istream();
+}
+
+#endif /* !CONFIG_RMI_XLP */
+
+#if 0
+#define optimize_thread_flush() do { \
+  if ( (cpu_logical_map(smp_processor_id()) & 0x03) != 0) return; \
+} while(0) 
+#else
+#define optimize_thread_flush()
+#endif
+
+extern unsigned long phnx_ebase;
+/*****************************************************************************************
+ * 
+ * These routines support Generic Kernel cache flush requirements
+ *
+ *****************************************************************************************/
+void phoenix_flush_dcache_page(struct page *page)
+{
+  ClearPageDcacheDirty(page);    
+}
+
+EXPORT_SYMBOL(phoenix_flush_dcache_page);
+
+static void phoenix_local_flush_icache_range(unsigned long start, unsigned long end)
+{
+  unsigned long addr;
+  
+  //dbg_msg("flush icache range, start=%lx, end=%lx\n", start, end);
+
+  for(addr = (start & ~((unsigned long)(icache_linesz - 1))); addr < end; 
+            addr += icache_linesz) {
+    cacheop_extable(Hit_Invalidate_I, addr);
+  }
+
+  cacheop_sync_istream();
+}
+
+struct flush_icache_range_args {
+  unsigned long start;
+  unsigned long end;
+};
+struct flush_icache_range_args_paddr {
+  phys_t start;
+  phys_t end;
+};
+
+static void phoenix_flush_icache_range_ipi(void *info)
+{
+  struct flush_icache_range_args *args = info;
+
+  optimize_thread_flush();
+
+  phoenix_local_flush_icache_range(args->start, args->end);
+}
+
+void phoenix_flush_icache_range(unsigned long start, unsigned long end)
+{
+  struct flush_icache_range_args args;
+
+#ifdef CONFIG_PHOENIX_VM_DEBUG
+  dbg_msg("return address: ");
+  print_symbol("ra[0]=%s\n", return_address());
+#endif
+  
+  if ((end - start) > PAGE_SIZE) {
+    dbg_msg("flushing more than page size of icache addresses starting @ %lx\n", start);
+  }
+  
+  args.start = start;
+  args.end = end;
+  /* TODO: don't even send ipi to non-zero thread ids 
+   * This may require some changes to smp_call_function interface, for now just avoid 
+   * redundant cache ops
+   */
+  on_each_cpu(phoenix_flush_icache_range_ipi, &args, 1);
+}
+
+static void phoenix_flush_cache_sigtramp_ipi(void *info)
+{
+  unsigned long addr = (unsigned long)info;
+
+  optimize_thread_flush();
+
+  addr = addr & ~(icache_linesz - 1);
+  cacheop_extable(Hit_Invalidate_I, addr );
+  cacheop_sync_istream();
+}
+
+static void phoenix_flush_cache_sigtramp(unsigned long addr)
+{
+  on_each_cpu(phoenix_flush_cache_sigtramp_ipi, (void *) addr, 1);
+}
+
+/*****************************************************************************************
+ * 
+ * These routines support MIPS specific cache flush requirements.
+ * These are called only during bootup or special system calls 
+ *
+ *****************************************************************************************/
+
+static void phoenix_local_flush_icache(void)
+{
+  int i=0;
+  unsigned long base = CKSEG0;
+
+  //dbg_msg("flushing the whole damn local I-cache\n");
+
+  /* Index Invalidate all the lines and the ways */
+  for(i=0;i<icache_lines;i++) {
+    cacheop(Index_Invalidate_I, base);
+    base += icache_linesz;
+  }
+
+  cacheop_sync_istream(); 
+
+}
+
+static void phoenix_local_flush_dcache(void)
+{
+  int i=0;
+  unsigned long base = CKSEG0;
+  unsigned int lines;
+
+  //dbg_msg("flushing the whole damn local D-cache\n");
+
+  lines = current_cpu_data.dcache.ways * current_cpu_data.dcache.sets;
+  
+  /* Index Invalidate all the lines and the ways */  
+  for(i=0;i<lines;i++) {
+    cacheop(Index_Writeback_Inv_D, base);
+    base += current_cpu_data.dcache.linesz;
+  }
+
+  cacheop_hazard(); 
+
+}
+
+#ifdef CONFIG_KGDB
+void phoenix_flush_l1_icache_ipi(void *info)
+{
+	phoenix_local_flush_icache();
+}
+#endif
+
+#ifdef CONFIG_KGDB
+void phoenix_flush_l1_caches_ipi(void *info)
+#else
+static void phoenix_flush_l1_caches_ipi(void *info)
+#endif
+{
+  optimize_thread_flush();
+ 
+  phoenix_local_flush_dcache();
+  phoenix_local_flush_icache();
+}
+
+static void phoenix_flush_l1_caches(void)
+{
+  //dbg_msg("NASTY CACHE FLUSH: flushing L1 caches on all cpus!\n");
+  on_each_cpu(phoenix_flush_l1_caches_ipi, (void *)NULL, 1);
+}
+
+/*****************************************************************************************/
+
+static void phoenix_noflush(void) { /* do nothing */ }
+
+static __init void probe_l1_cache(void)
+{
+  struct cpuinfo_mips *c = &current_cpu_data;
+  unsigned int config1 = read_c0_config1();
+  int lsize = 0;
+  int icache_size=0, dcache_size=0;
+
+  if ((lsize = ((config1 >> 19) & 7)))
+    c->icache.linesz = 2 << lsize;
+  else
+    c->icache.linesz = lsize;
+  c->icache.sets = 64 << ((config1 >> 22) & 7);
+  c->icache.ways = 1 + ((config1 >> 16) & 7);
+
+  icache_size = c->icache.sets *
+    c->icache.ways *
+    c->icache.linesz;
+  c->icache.waybit = ffs(icache_size/c->icache.ways) - 1;
+
+  c->dcache.flags = 0;
+
+  if ((lsize = ((config1 >> 10) & 7)))
+    c->dcache.linesz = 2 << lsize;
+  else
+    c->dcache.linesz= lsize;
+  c->dcache.sets = 64 << ((config1 >> 13) & 7);
+  c->dcache.ways = 1 + ((config1 >> 7) & 7);
+
+  dcache_size = c->dcache.sets *
+    c->dcache.ways *
+    c->dcache.linesz;
+  c->dcache.waybit = ffs(dcache_size/c->dcache.ways) - 1;
+
+  if (smp_processor_id()==0) {
+    printk("Primary instruction cache %dkB, %d-way, linesize %d bytes.\n",
+	   icache_size >> 10,
+	   c->icache.ways, c->icache.linesz);
+    
+    printk("Primary data cache %dkB %d-way, linesize %d bytes.\n",
+	   dcache_size >> 10, c->dcache.ways, c->dcache.linesz);
+  }
+
+}
+
+static __inline__ void install_cerr_handler(void)
+{
+  extern char except_vec2_generic;
+
+  memcpy((void *)(phnx_ebase + 0x100), &except_vec2_generic, 0x80);
+}
+
+static void update_kseg0_coherency(void)
+{
+  int attr = read_c0_config() & CONF_CM_CMASK;
+
+  if (attr != 0x3) {
+
+    phoenix_local_flush_dcache();
+    phoenix_local_flush_icache();
+
+    change_c0_config(CONF_CM_CMASK, 0x3);
+
+    sync_istream();
+  }
+  _page_cachable_default = (0x3 << _CACHE_SHIFT);
+
+}
+
+void ld_mmu_phoenix(void)
+{
+	extern void build_clear_page(void);
+	extern void build_copy_page(void);
+	/* update cpu_data */
+
+	probe_l1_cache();
+
+	if (smp_processor_id()) {  
+
+#if 0
+		/* flush the exception vector region to make sure 
+		 * not to execute bootloader's exception code 
+		 */
+		phoenix_local_flush_icache_range(phnx_ebase, phnx_ebase + 0x400);
+#endif
+		phoenix_local_flush_icache();
+
+		update_kseg0_coherency();
+
+		return;
+	}
+
+	/* These values are assumed to be the same for all cores */
+	icache_lines = current_cpu_data.icache.ways * current_cpu_data.icache.sets;
+	icache_linesz = current_cpu_data.icache.linesz;
+
+	/* When does this function get called? Looks like MIPS has some syscalls
+	 * to flush the caches. 
+	 */
+	__flush_cache_all = phoenix_flush_l1_caches;
+
+	/* flush_cache_all: makes all kernel data coherent.
+	 * This gets called just before changing or removing
+	 * a mapping in the page-table-mapped kernel segment (kmap). 
+	 * Physical Cache -> do nothing
+	 */
+	flush_cache_all = phoenix_noflush;
+
+	/* flush_icache_range: makes the range of addresses coherent w.r.t I-cache and D-cache 
+	 * This gets called after the instructions are written to memory
+	 * All addresses are valid kernel or mapped user-space virtual addresses
+	 */
+	flush_icache_range = phoenix_flush_icache_range;
+
+	/* flush_cache_{mm, range, page}: make these memory locations, that may have been written
+	 *                                by a user process, coherent
+	 * These get called when virtual->physical translation of a user address space is about
+	 * to be changed. These are closely related to TLB coherency (flush_tlb_{mm, range, page})
+	 */
+	flush_cache_mm = (void (*)(struct mm_struct *))phoenix_noflush;
+	flush_cache_range = (void *) phoenix_noflush;
+	flush_cache_page = (void *) phoenix_noflush;
+
+	/* flush_icache_page: flush_dcache_page + update_mmu_cache takes care of this
+	 * 
+	 */
+	flush_data_cache_page = (void *) phoenix_noflush;
+
+	/* flush_cache_sigtramp: flush the single I-cache line with the proper fixup code
+	 */
+	flush_cache_sigtramp = phoenix_flush_cache_sigtramp;
+
+	/* flush_icache_all: This should get called only for Virtuall Tagged I-Caches
+	 */
+	flush_icache_all = (void *)phoenix_noflush;
+
+	local_flush_icache_range = phoenix_local_flush_icache_range;
+	local_flush_data_cache_page	= (void *)phoenix_noflush;
+
+	__flush_cache_vmap = (void *)phoenix_noflush;
+	__flush_cache_vunmap = (void *)phoenix_noflush;
+
+	install_cerr_handler();
+
+	build_clear_page();
+	build_copy_page();
+
+	phoenix_local_flush_icache();
+
+	update_kseg0_coherency();
+}
+
+#ifdef CONFIG_64BIT
+#define cacheop_paddr(op, base) __asm__ __volatile__ ( \
+                         ".set push\n"           \
+                         ".set noreorder\n"      \
+                         ".set mips64\n"          \
+                         "dli $8, 0x9800000000000000\n"              \
+                         "daddu $8, $8, %1\n"       \
+                         "cache %0, 0($8)\n"     \
+                         ".set pop\n"            \
+                         : : "i"(op), "r"(base) : "$8")
+
+#else
+static inline void cacheop_paddr(const unsigned int op, phys_t base)
+{
+	uint64_t temp_msb, temp_lsb;
+	phys_t temp1;
+
+	temp_msb = (uint64_t)(base >> 32);
+	temp_lsb = (uint64_t)(base & 0xffffffff);
+
+	__asm__ volatile(
+		".set push\n"
+		".set noreorder\n"
+		".set mips64\n"
+		"dli $8,0x9800000000000000\n"
+		"dsll32 %0, %2,0\n"
+		"or %0,%0,%3\n"
+		"daddu $8, $8, %0\n"  
+		"cache %1, 0($8)\n"
+		".set pop\n"
+		".set reorder\n"
+		: "=&r"(temp1)
+		: "i"(Hit_Invalidate_I), "r"(temp_msb) , "r"(temp_lsb)
+		:"$8"
+		);
+}
+#endif
+
+#define enable_KX(flags)   \
+ preempt_disable(); \
+ __asm__ __volatile__ (          \
+	".set push\n"              \
+	".set noat\n"               \
+	".set noreorder\n"     \
+	"mfc0 %0, $12\n\t"             \
+	"ori $1, %0, 0x81\n\t"   \
+	"xori $1, 1\n\t"      \
+	"mtc0 $1, $12\n"       \
+        ".set pop\n"          \
+        : "=r"(flags) ); \
+  preempt_enable();
+	
+#define disable_KX(flags)   \
+ __asm__ __volatile__ (          \
+	".set push\n"              \
+	"mtc0 %0, $12\n"       \
+        ".set pop\n"          \
+        : : "r"(flags) )
+	
+
+#define SETS_PER_WAY_SHIFT 22
+#define SETS_PER_WAY_MASK 0x7
+#define CACHELINE_SIZE_BITS 5
+
+static void phoenix_local_flush_icache_range_paddr(phys_t start, phys_t end)
+{
+	phys_t addr;
+#ifdef CONFIG_32BIT
+	unsigned long flags;
+	phys_t temp;
+#endif
+#ifdef CONFIG_RMI_VMIPS
+	int tlbs = 0, tlbe = 0;
+	rmi_vmips_temp_xkphys_tlb_add(start, end, &tlbs, &tlbe);
+#endif
+
+#ifdef CONFIG_RMI_XLP
+	int sets_per_way, niter, i;
+	uint64_t mask;
+
+	sets_per_way = (read_c0_config1() >> SETS_PER_WAY_SHIFT) & SETS_PER_WAY_MASK;
+	niter = sets_per_way + 6 + CACHELINE_SIZE_BITS - PAGE_SHIFT;
+	if (niter < 0)
+		niter = 0;
+	niter = 1 << niter;
+	mask = niter - 1;
+#endif
+
+#ifdef CONFIG_32BIT
+	enable_KX(flags);
+#endif
+    for (addr = (start & ~(phys_t)(icache_linesz - 1)); addr < end;
+                    addr += icache_linesz) {
+		cacheop_paddr(Hit_Invalidate_I, addr);
+#ifdef CONFIG_RMI_XLP
+		for (i = 1; i < niter; ++i)
+			cacheop_paddr(Hit_Invalidate_I, (addr & ~(mask << PAGE_SHIFT)) | (i << PAGE_SHIFT));
+#endif
+    }
+
+#ifdef CONFIG_32BIT
+	disable_KX(flags);
+#endif
+
+#ifdef CONFIG_RMI_VMIPS
+	for(;tlbe >= tlbs; tlbe--)
+        rmi_vmips_wired_entry_remove(tlbe); 
+
+#endif
+	cacheop_sync_istream();
+}
+
+static void phoenix_flush_icache_range_paddr_ipi(void *info)
+{
+  struct flush_icache_range_args_paddr *args = info;
+
+  optimize_thread_flush();
+
+  phoenix_local_flush_icache_range_paddr(args->start, args->end);
+}
+
+void phoenix_flush_icache_range_paddr(phys_t start)
+{
+  struct flush_icache_range_args_paddr args;
+
+#ifdef CONFIG_PHOENIX_VM_DEBUG
+  dbg_msg("return address: ");
+  print_symbol("ra[0]=%s\n", (unsigned long) return_address());
+#endif
+  
+  args.start = start;
+  args.end = start + PAGE_SIZE;
+  /* TODO: don't even send ipi to non-zero thread ids 
+   * This may require some changes to smp_call_function interface, for now just avoid 
+   * redundant cache ops
+   */
+  on_each_cpu(phoenix_flush_icache_range_paddr_ipi, &args, 1);
+}
+
+
diff --git a/arch/mips/mm/cache.c b/arch/mips/mm/cache.c
index 829320c..d1d564f 100644
--- a/arch/mips/mm/cache.c
+++ b/arch/mips/mm/cache.c
@@ -122,6 +122,20 @@ void __update_cache(struct vm_area_struct *vma, unsigned long address,
 	pte_t pte)
 {
 	struct page *page;
+
+#ifdef CONFIG_RMI_PHOENIX
+	phys_t start;
+	//printk("[%s]: address = %lx, pte = %lx\n", __FUNCTION__, address, pte_val(pte));
+	if (!(vma->vm_flags & VM_EXEC)) return;
+	page = pte_page(pte);
+	/*  addr = (unsigned long)page_address(page); */
+	if (TestPageDcacheDirty(page)) return;
+	/*  if (addr)  */
+	/*    flush_icache_range(addr, addr+PAGE_SIZE); */
+	start = (phys_t)pte_pfn(pte);
+	phoenix_flush_icache_range_paddr(start << PAGE_SHIFT);
+	SetPageDcacheDirty(page);
+#else
 	unsigned long pfn, addr;
 	int exec = (vma->vm_flags & VM_EXEC) && !cpu_has_ic_fills_f_dc;
 
@@ -135,9 +149,17 @@ void __update_cache(struct vm_area_struct *vma, unsigned long address,
 			flush_data_cache_page(addr);
 		ClearPageDcacheDirty(page);
 	}
+#endif
 }
 
+#ifdef CONFIG_RMI_PHOENIX
+/* This variable needs to be initialized before setup_arch() if this is not
+   initialized like below
+   */
+unsigned long _page_cachable_default = (0x3 << _CACHE_SHIFT);
+#else
 unsigned long _page_cachable_default;
+#endif
 EXPORT_SYMBOL(_page_cachable_default);
 
 static inline void setup_protection_map(void)
@@ -208,6 +230,11 @@ void __cpuinit cpu_cache_init(void)
 
 		tx39_cache_init();
 	}
+	if (cpu_has_phoenix_cache) {
+		extern void __weak ld_mmu_phoenix(void);
+
+		ld_mmu_phoenix();
+	}
 
 	if (cpu_has_octeon_cache) {
 		extern void __weak octeon_cache_init(void);
@@ -223,5 +250,14 @@ int __weak __uncached_access(struct file *file, unsigned long addr)
 	if (file->f_flags & O_DSYNC)
 		return 1;
 
+#ifdef CONFIG_RMI_PHOENIX
+	{
+		extern int phnx_get_pgprot(unsigned long address);
+	  	/* check the address region, return uncached pages for IO space and
+		   cached page for memory space. */
+		return phnx_get_pgprot(addr);
+	}
+#endif
+
 	return addr >= __pa(high_memory);
 }
diff --git a/arch/mips/mm/cerr-phoenix.c b/arch/mips/mm/cerr-phoenix.c
new file mode 100644
index 0000000..1ab4bed
--- /dev/null
+++ b/arch/mips/mm/cerr-phoenix.c
@@ -0,0 +1,167 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/smp.h>
+
+#include <asm/rmi/iomap.h>
+
+unsigned char xlr_cerr_stack[8192];
+
+/* generic MIPS cache error handler */
+extern void cache_parity_error(void);
+
+static __inline__ void cerr_cpu_halt(void)
+{
+	for(;;) {
+		__asm__ __volatile__(".set mips64\n"
+				     "1: wait \n"
+				     "   b 1b\n"
+				     "   nop\n"
+			);
+	}
+}
+
+#define UART_RHR 0
+#define UART_THR 0
+#define UART_IER 1
+#define UART_IIR 2
+#define UART_FCR 2
+#define UART_LCR 3
+#define UART_MCR 4
+#define UART_LSR 5
+#define UART_MSR 6
+static void xlr_cerr_outbyte(char ch)
+{
+	volatile uint32_t *mmio = phoenix_io_mmio(PHOENIX_IO_UART_0_OFFSET);
+	int lsr;
+	for (;;) {
+
+		lsr = be32_to_cpu(mmio[UART_LSR]);
+
+		/* Tx Fifo empty */
+		if (lsr & 0x20) {
+			mmio[UART_THR] = cpu_to_be32((int)ch);
+			break;
+		}
+	}
+}
+
+volatile int xlr_cerr_lock;
+static char cerr_printk_buf[1024];
+static void xlr_cerr_printk(const char *fmt, ...)
+{
+	va_list args;
+	int len;
+	int i = 0;
+
+	va_start(args, fmt);
+	len = vsnprintf(cerr_printk_buf, sizeof(cerr_printk_buf), fmt, args);
+	va_end(args);
+	  
+	for (i=0; i<=len; i++) {
+		if (cerr_printk_buf[i] == 0)
+			continue;
+		if (cerr_printk_buf[i] == '\n')
+			xlr_cerr_outbyte('\r');
+		xlr_cerr_outbyte(cerr_printk_buf[i]);
+	}
+
+}
+
+
+static char *bridge_aerr_intr_devstat[] = {
+	[0] = "cpu 0",
+	[1] = "cpu 1",
+	[2] = "cpu 2",
+	[3] = "cpu 3",
+	[4] = "cpu 4",
+	[5] = "cpu 5",
+	[6] = "cpu 6",
+	[7] = "cpu 7",
+	
+	[8] = "L2",
+	[9] = "XGS 0",
+	[10] = "XGS 1",
+	[11] = "GMAC",
+	[12] = "SEC",
+	[13] = "PCIX",
+	[14] = "HT",
+	[15] = "DMA",
+};
+/* On Phoenix, errors reported by bridge (like misconfigured BARS etc) are also
+ * reported as cache errors. Need to check if it is really a cache error or a "bus error"
+ * and take action appropriately.
+ * For now, treat it as a cache error 
+ */
+asmlinkage void phoenix_cache_error(struct pt_regs *regs)
+{
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_BRIDGE_OFFSET);
+	__u64 cerr_cpu_log = 0;
+	__u32 tmp = 0;
+	int i=0;
+
+	/* TODO: cache error on xlr could also be because of access to a physical address region that is
+	 * not mapped to any device in the bridge
+	 * We should detect that condition by reading the bridge registers and if a process is doing
+	 * the access, the process should be SEGFAULTED. If kernel is doing it, all bets are off, so
+	 * we should dump the stack and die
+	 * For Now, just halt the cpu
+	 */
+	local_irq_disable();
+
+	/* let the first cpu in */
+	while (xlr_cerr_lock) ;
+	xlr_cerr_lock = 1;
+
+	xlr_cerr_printk("*********************************************\n");
+	xlr_cerr_printk("cpu_%d received a bus/cache error\n", hard_smp_processor_id());
+	xlr_cerr_printk("*********************************************\n");
+
+	xlr_cerr_printk("Bridge: Phys Addr = 0x%010llx, Device_AERR = 0x%08x\n",
+			( ((__u64)phoenix_read_reg(mmio, 39)<<5) | ((__u64)phoenix_read_reg(mmio, 40)<<37) ),
+			phoenix_read_reg(mmio, 41));
+	xlr_cerr_printk("Bridge: The devices reporting AERR are:\n");
+	tmp = phoenix_read_reg(mmio, 41);
+	for(i=0;i<16;i++) {
+		if (tmp & (1<<i)) xlr_cerr_printk("\t%s\n", bridge_aerr_intr_devstat[i]);
+	}
+
+	cerr_cpu_log = read_64bit_phnx_ctrl_reg(CPU_BLOCKID_LSU, LSU_CERRLOG_REGID);
+	xlr_cerr_printk("CPU: (XLR specific) Cache Error log = 0x%016llx, Phy Addr = 0x%010llx\n",
+			cerr_cpu_log, ((cerr_cpu_log >> 10) & 0xffffffffffULL) << 3);
+
+	xlr_cerr_printk("CPU: epc = 0x%lx, errorepc = 0x%lx, cacheerr = 0x%08x\n",
+			read_c0_epc(), read_c0_errorepc(), read_c0_cacheerr());
+
+	xlr_cerr_printk("Can not handle bus/cache error - Halting cpu\n");
+
+	cerr_cpu_halt();
+}
+
diff --git a/arch/mips/mm/cex-gen.S b/arch/mips/mm/cex-gen.S
index e743622..31f4b94 100644
--- a/arch/mips/mm/cex-gen.S
+++ b/arch/mips/mm/cex-gen.S
@@ -1,3 +1,15 @@
+/************************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+ *
+ * This is a derived work from software originally provided by the external
+ * entity identified below. The licensing terms and warranties specified in
+ * the header of the original work apply to this derived work.
+ *
+ * Contribution by RMI: 
+ *
+ ******************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -36,7 +48,34 @@
 	nop
 	nop
 	nop
+#ifdef CONFIG_RMI_PHOENIX
+
+	/* If some other cpu is already in the handler
+	 * just wait... */
+	PTR_LA	k0, xlr_cerr_lock
+1:	lw	k1, 0(k0)
+	bnez	k1, 1b
+	nop
+	
+	/* switch stack to a new one */
+	PTR_LA	sp, xlr_cerr_stack
+	li	k1, 8192 - 64
+	PTR_ADDU	sp, sp, k1
+	
+	/* set up first argument - pt_regs */
+	move	a0, sp
+	/* read the cache error log reg in the cpu */
+	li	k1, 0x309
+	/*mfcr	k0, k1*/
+	PTR	0x737a0018
+	move	a1, k0
+	
+    j phoenix_cache_error
+	nop
+	/* should never get here */
 
+#else
 	j	cache_parity_error
 	nop
+#endif
 	END(except_vec2_generic)
diff --git a/arch/mips/mm/extable.c b/arch/mips/mm/extable.c
index 9d25d2b..fb29d08 100644
--- a/arch/mips/mm/extable.c
+++ b/arch/mips/mm/extable.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -7,6 +19,7 @@
  */
 #include <linux/module.h>
 #include <linux/spinlock.h>
+#include <linux/kgdb.h>
 #include <asm/branch.h>
 #include <asm/uaccess.h>
 
@@ -20,6 +33,14 @@ int fixup_exception(struct pt_regs *regs)
 
 		return 1;
 	}
+#if 0
+#ifdef CONFIG_KGDB
+	if (atomic_read(&debugger_active) && kgdb_may_fault)
+		/* Restore our previous state. */
+		kgdb_fault_longjmp(kgdb_fault_jmp_regs);
+		/* Not reached. */
+#endif
+#endif
 
 	return 0;
 }
diff --git a/arch/mips/mm/ioremap.c b/arch/mips/mm/ioremap.c
index cacfd31..4f77d61 100644
--- a/arch/mips/mm/ioremap.c
+++ b/arch/mips/mm/ioremap.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -111,7 +123,11 @@ static int remap_area_pages(unsigned long address, phys_t phys_addr,
  * caller shouldn't need to know that small detail.
  */
 
-#define IS_LOW512(addr) (!((phys_t)(addr) & (phys_t) ~0x1fffffffULL))
+#ifdef CONFIG_64BIT_PHYS_ADDR
+#define IS_LOW512(addr) (!((phys_t)(addr) & ~0x1fffffffULL))
+#else
+#define IS_LOW512(addr) (!((phys_t)(addr) & ~0x1fffffffUL))
+#endif
 
 void __iomem * __ioremap(phys_t phys_addr, phys_t size, unsigned long flags)
 {
diff --git a/arch/mips/mm/pg-phoenix.c b/arch/mips/mm/pg-phoenix.c
new file mode 100644
index 0000000..6a1634e
--- /dev/null
+++ b/arch/mips/mm/pg-phoenix.c
@@ -0,0 +1,136 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/*
+ * Copyright (C) 1996 David S. Miller (dm@engr.sgi.com)
+ * Copyright (C) 1997, 2001 Ralf Baechle (ralf@gnu.org)
+ * Copyright (C) 2002 
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
+ */ 
+
+#include <linux/smp.h>
+
+#include <asm/asm.h>
+#include <asm/page.h>
+#include <asm/bug.h>
+#include <asm/system.h>
+
+/* These are the functions hooked by the memory management function pointers */
+void clear_page(void *page)
+{
+#ifdef CONFIG_PHOENIX_VM_DEBUG
+  printk("[%s]: page = %lx\n", __FUNCTION__, (unsigned long)page);
+#endif
+  __asm__ __volatile__(
+		       ".set push                  \n"
+		       ".set noreorder             \n"
+		       ".set noat                  \n"
+		       ".set mips4                 \n"
+
+		       STR(LONG_ADDIU) "\t$1, $0, 1		\n"
+		       STR(LONG_SLL)"\t$1, %1		\n"
+		       /* store the address of last cacheline in $1 */
+		       STR(LONG_ADDU) "\t$1, %0, $1  \n"  
+
+		       /* pref with prep_for_store and zero the cacheline */
+		       "1:   pref      30,  0(%0)  \n"
+
+		       "     sd        $0,  0(%0)  \n"  
+		       "     sd        $0,  8(%0)  \n"
+		       "     sd        $0, 16(%0)  \n"
+		       "     sd        $0, 24(%0)  \n"
+
+		       /* loop till the last cacheline */
+		       STR(LONG_ADDIU)"\t%0, %0, 32  \n"  
+		       "     bne       %0, $1, 1b  \n"
+		       "     nop                   \n"
+
+		       ".set pop                   \n"
+		       :
+		       :"r" (page), "I" (PAGE_SHIFT)
+		       :"$1","memory");
+}
+
+void copy_page(void *to, void *from)
+{
+  __asm__ __volatile__(
+		       ".set push                  \n"
+		       ".set noreorder             \n"
+		       ".set noat                  \n"
+		       ".set mips64                 \n"
+
+		       STR(LONG_ADDIU) "\t$1, $0, 1		\n"
+		       STR(PTR_SLL) "\t $1, %2		\n"
+		       /* store the address of last cacheline in $1 */
+		       STR(LONG_ADDU)"\t$1, %1, $1  \n"  
+
+		       /* pref with prep_for_store the current cacheline */
+		       /* the stores should merge into this pref cacheline */
+		       "1:   pref      30,   0(%0)  \n"
+
+		       /* pref the next cacheline "from" */
+		       "     pref      0,    32(%1)  \n"
+
+		       /* copy the cacheline */
+#ifdef CONFIG_32BIT
+ 		       "2:   lw        $8,   0(%1)  \n"
+		       "     lw        $9,   4(%1)  \n"
+		       "     lw        $10,  8(%1)  \n"
+		       "     lw        $11,  12(%1)  \n"
+		       "     sw        $8,   0(%0)  \n"
+		       "     sw        $9,   4(%0)  \n"
+		       "     sw        $10,  8(%0)  \n"
+		       "     sw        $11,  12(%0)  \n"
+ 		       "     lw        $8,   16(%1)  \n"
+		       "     lw        $9,   20(%1)  \n"
+		       "     lw        $10,  24(%1)  \n"
+		       "     lw        $11,  28(%1)  \n"
+		       "     sw        $8,   16(%0)  \n"
+		       "     sw        $9,   20(%0)  \n"
+		       "     sw        $10,  24(%0)  \n"
+		       "     sw        $11,  28(%0)  \n"
+#else
+ 		       "2:   ld        $8,   0(%1)  \n"
+		       "     ld        $9,   8(%1)  \n"
+		       "     ld        $10,  16(%1)  \n"
+		       "     ld        $11,  24(%1)  \n"
+		       "     sd        $8,   0(%0)  \n"
+		       "     sd        $9,   8(%0)  \n"
+		       "     sd        $10,  16(%0)  \n"
+		       "     sd        $11,  24(%0)  \n"
+#endif
+
+		       /* loop till the last cacheline */		       
+		       STR(LONG_ADDIU)"\t%1, %1, 32  \n"
+		       STR(LONG_ADDIU)"\t%0, %0, 32  \n"  
+		       "     bne       %1, $1, 1b  \n"
+		       "     nop                   \n"
+
+		       ".set pop                   \n"
+
+		       :
+		       :"r" (to), "r"(from), "I" (PAGE_SHIFT)
+		       :"$1","$8", "$9", "$10", "$11", "memory");
+}
diff --git a/arch/mips/mm/pgtable-64.c b/arch/mips/mm/pgtable-64.c
index cda4e30..7d2363c 100644
--- a/arch/mips/mm/pgtable-64.c
+++ b/arch/mips/mm/pgtable-64.c
@@ -65,6 +65,12 @@ void __init pagetable_init(void)
 {
 	unsigned long vaddr;
 	pgd_t *pgd_base;
+#ifdef CONFIG_HIGHMEM
+        pgd_t *pgd;
+        pud_t *pud;
+        pmd_t *pmd;
+        pte_t *pte;
+#endif
 
 	/* Initialize the entire pgd.  */
 	pgd_init((unsigned long)swapper_pg_dir);
@@ -77,4 +83,18 @@ void __init pagetable_init(void)
 	 */
 	vaddr = __fix_to_virt(__end_of_fixed_addresses - 1) & PMD_MASK;
 	fixrange_init(vaddr, vaddr + FIXADDR_SIZE, pgd_base);
+
+#ifdef CONFIG_HIGHMEM
+        /*
+         * Permanent kmaps:
+         */
+        vaddr = PKMAP_BASE;
+        fixrange_init(vaddr, vaddr + PAGE_SIZE*LAST_PKMAP, pgd_base);
+
+        pgd = swapper_pg_dir + __pgd_offset(vaddr);
+        pud = pud_offset(pgd, vaddr);
+        pmd = pmd_offset(pud, vaddr);
+        pte = pte_offset_kernel(pmd, vaddr);
+        pkmap_page_table = pte;
+#endif
 }
diff --git a/arch/mips/mm/tlb-phnx.c b/arch/mips/mm/tlb-phnx.c
new file mode 100644
index 0000000..4ccfaad
--- /dev/null
+++ b/arch/mips/mm/tlb-phnx.c
@@ -0,0 +1,140 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/sched.h>
+
+#define UNIQUE_ENTRYHI(idx)  ((1ULL << 63) + (1ULL << 40) + ((idx) << (PAGE_SHIFT + 1)) + ( 1 << 8))
+#define ENTER_CRITICAL(flags) local_irq_save(flags)
+#define EXIT_CRITICAL(flags) local_irq_restore(flags)
+extern void local_flush_tlb_all(void);
+
+int rmi_vmips_wired_entry_add(unsigned long entrylo0, unsigned long entrylo1,
+	uint64_t entryhi, unsigned long pagemask)
+{
+	unsigned long flags;
+	unsigned long wired;
+	unsigned long old_pagemask;
+	unsigned long old_ctx;
+
+	ENTER_CRITICAL(flags);
+	/* Save old context and create impossible VPN2 value */
+	old_ctx = read_c0_entryhi();
+	old_pagemask = read_c0_pagemask();
+	wired = read_c0_wired();
+	write_c0_wired(wired + 1);
+	write_c0_index(wired);
+	tlbw_use_hazard();	/* What is the hazard here? */
+	write_c0_pagemask(pagemask);
+	__write_64bit_c0_register($10, 0, entryhi);
+	write_c0_entrylo0(entrylo0);
+	write_c0_entrylo1(entrylo1);
+	mtc0_tlbw_hazard();
+	tlb_write_indexed();
+	tlbw_use_hazard();
+
+	write_c0_entryhi(old_ctx);
+	tlbw_use_hazard();	/* What is the hazard here? */
+	write_c0_pagemask(old_pagemask);
+	local_flush_tlb_all();
+	EXIT_CRITICAL(flags);
+	return wired;
+}
+
+void rmi_vmips_wired_entry_remove(int index)
+{
+	unsigned long flags;
+	unsigned long wired;
+	unsigned long old_pagemask;
+	unsigned long old_ctx;
+
+	ENTER_CRITICAL(flags);
+	/* Save old context and create impossible VPN2 value */
+	old_ctx = read_c0_entryhi();
+	old_pagemask = read_c0_pagemask();
+	write_c0_pagemask(0);
+	__write_64bit_c0_register($10, 0, UNIQUE_ENTRYHI(index));
+	write_c0_entrylo0(0);
+	write_c0_entrylo1(0);
+	wired = read_c0_wired();
+	if(index == (wired - 1))
+        write_c0_wired(wired - 1);
+    write_c0_index(index);
+	mtc0_tlbw_hazard();
+	tlb_write_indexed();
+	tlbw_use_hazard();
+	write_c0_entryhi(old_ctx);
+	tlbw_use_hazard();	/* What is the hazard here? */
+	write_c0_pagemask(old_pagemask);
+	local_flush_tlb_all();
+	EXIT_CRITICAL(flags);
+}
+
+
+void rmi_vmips_wired_entry_read(int index, uint64_t *entryhi, 
+		unsigned long *entrylo0, unsigned long *entrylo1)
+{
+	unsigned long flags;
+	ENTER_CRITICAL(flags);
+
+    write_c0_index(index);
+	tlb_read();
+	tlb_probe_hazard();
+	if(entryhi)
+		*entryhi = __read_64bit_c0_register($10, 0);
+
+	if(entrylo0)
+		*entrylo0 = read_c0_entrylo0();
+
+	if(entrylo1)
+		*entrylo1 = read_c0_entrylo1();
+
+	EXIT_CRITICAL(flags);
+	return;
+}
+
+/* Cacheble + Dirty + Valid + Global */
+#define TLB_ENTRY_CACHEBLE ((3 << 3) | (1 << 2) | (1 << 1) | ( 1 << 0)) 
+#define   rmi_align(x, y)     ((x) & (~((y)-1)))
+void rmi_vmips_temp_xkphys_tlb_add(phys_t start, phys_t end, int *tlbs, int *tlbe)
+{
+	uint32_t pagesize = 256 * 1024 * 1024;
+	uint64_t entryhi = 0x9800000000000000ULL;
+	phys_t aligned_start;
+
+	*tlbs = *tlbe = read_c0_wired();
+	
+	aligned_start = rmi_align(start, pagesize);
+	entryhi += aligned_start;
+	for(; aligned_start < end; aligned_start += (2 * pagesize), entryhi += ((2 * pagesize))) {
+		uint64_t entrylo0 = ((( aligned_start & 0xffffffffffULL) >> 12) << 6) | TLB_ENTRY_CACHEBLE;
+		uint64_t entrylo1 = ((( (aligned_start + pagesize) & 0xffffffffffULL) >> 12) << 6) | TLB_ENTRY_CACHEBLE;
+		*tlbe = rmi_vmips_wired_entry_add(entrylo0, entrylo1, entryhi, 0x1fffe000);
+	}
+}
diff --git a/arch/mips/mm/tlb-phoenix.c b/arch/mips/mm/tlb-phoenix.c
new file mode 100644
index 0000000..77cf7d1
--- /dev/null
+++ b/arch/mips/mm/tlb-phoenix.c
@@ -0,0 +1,465 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/*
+ * Copyright (C) 1996 David S. Miller (dm@engr.sgi.com)
+ * Copyright (C) 1997, 2001 Ralf Baechle (ralf@gnu.org)
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
+ */ 
+
+#include <asm/mmu_context.h>
+#include <asm/bootinfo.h>
+#include <asm/cpu.h>
+#include <linux/highmem.h>
+
+#include <asm/io.h>
+#include <linux/ioport.h>
+#include <linux/init.h>
+
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/phnx_mmap.h>
+#include <asm/rmi/sim.h>
+
+#ifdef CONFIG_PHOENIX_VM_DEBUG
+#define DEBUG_TLB
+#endif
+
+extern char except_vec0_r4000[];
+extern char except_vec0_phoenix[];
+extern unsigned long phnx_ebase;
+
+/* Dump the current entry* and pagemask registers */
+static inline void dump_cur_tlb_regs(void)
+{
+  unsigned int entryhihi, entryhilo, entrylo0hi, entrylo0lo, entrylo1hi;
+  unsigned int entrylo1lo, pagemask;
+
+  __asm__ __volatile__ (
+			".set push             \n"
+			".set noreorder        \n"
+			".set mips64           \n"
+			".set noat             \n"
+			"     tlbr             \n"
+			"     dmfc0  $1, $10   \n"
+			"     dsrl32 %0, $1, 0 \n"
+			"     sra    %1, $1, 0 \n"
+			"     dmfc0  $1, $2    \n"
+			"     dsrl32 %2, $1, 0 \n"
+			"     sra    %3, $1, 0 \n"
+			"     dmfc0  $1, $3    \n"
+			"     dsrl32 %4, $1, 0 \n"
+			"     sra    %5, $1, 0 \n"
+			"     mfc0   %6, $5    \n"
+			".set pop              \n"
+			: "=r" (entryhihi),
+			"=r" (entryhilo),
+			"=r" (entrylo0hi),
+			"=r" (entrylo0lo),
+			"=r" (entrylo1hi),
+			"=r" (entrylo1lo),
+			"=r" (pagemask));
+  printk("%08X%08X %08X%08X %08X%08X %08X",
+	 entryhihi, entryhilo,
+	 entrylo0hi, entrylo0lo,
+	 entrylo1hi, entrylo1lo,
+	 pagemask);
+}
+
+void phoenix_dump_tlb(void)
+{
+  int entry;
+  printk("Current TLB registers state:\n"
+	 "      EntryHi       EntryLo0          EntryLo1     PageMask  Index\n"
+	 "--------------------------------------------------------------------\n");
+  dump_cur_tlb_regs();
+  printk(" %08X\n", read_c0_index());
+  printk("\n\nFull TLB Dump:\n"
+	 "Idx      EntryHi       EntryLo0          EntryLo1     PageMask\n"
+	 "--------------------------------------------------------------\n");
+  for (entry = 0; entry < current_cpu_data.tlbsize; entry++) {
+    write_c0_index(entry);
+    printk("\n%02i ", entry);
+    __asm__ __volatile__ (
+			  ".set push             \n"
+			  ".set mips64           \n"
+			  "     tlbr             \n"
+			  ".set pop              \n");
+    dump_cur_tlb_regs();
+  }
+  printk("\n");
+}
+
+void local_flush_tlb_all(void)
+{
+  unsigned long flags;
+  unsigned long old_ctx;
+  int entry;
+
+  local_irq_save(flags);
+  /* Save old context and create impossible VPN2 value */
+  old_ctx = (read_c0_entryhi() & 0xff);
+  write_c0_entrylo0(0);
+  write_c0_entrylo1(0);
+
+  entry = read_c0_wired();
+  for (; entry < current_cpu_data.tlbsize; entry++) {
+    write_c0_entryhi(KSEG0 + (PAGE_SIZE << 1) * entry);
+    write_c0_index(entry);
+    tlb_write_indexed();
+  }
+  reload_context(old_ctx);
+  local_irq_restore(flags);	
+}
+
+/*
+ * Use a bogus region of memory (starting at 0) to sanitize the TLB's.  
+ * Use increments of the maximum page size (16MB), and check for duplicate
+ * entries before doing a given write.  Then, when we're safe from collisions
+ * with the firmware, go back and give all the entries invalid addresses with
+ * the normal flush routine.
+ */
+void phoenix_sanitize_tlb(void)
+{
+  int entry;
+  long addr = 0;
+
+  long inc = 1<<24;  /* 16MB */
+
+  /* Initialize the Page Mask Register */
+  write_c0_pagemask(0);
+
+  /* Save old context and create impossible VPN2 value */
+  write_c0_entrylo0(0);
+  write_c0_entrylo1(0);
+  for (entry = 0; entry < current_cpu_data.tlbsize; entry++) {
+    do {
+      addr += inc;
+      write_c0_entryhi(addr);
+      tlb_probe();
+    } while ((int)(read_c0_index()) >= 0);
+    write_c0_index(entry);
+    tlb_write_indexed();
+  }
+  /* Now that we know we're safe from collisions, we can safely flush
+     the TLB with the "normal" routine. */
+  local_flush_tlb_all();
+}
+
+void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
+			   unsigned long end)
+{
+  struct mm_struct *mm = vma->vm_mm;
+  unsigned long flags;
+  int cpu;
+
+  local_irq_save(flags);
+  cpu = smp_processor_id();
+  if(cpu_context(cpu, mm) != 0) {
+    int size;
+    size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
+    size = (size + 1) >> 1;
+    if(size <= (current_cpu_data.tlbsize/2)) {
+      int oldpid = (read_c0_entryhi() & 0xff);
+      int newpid = (cpu_context(cpu, mm) & 0xff);
+
+      start &= (PAGE_MASK << 1);
+      end += ((PAGE_SIZE << 1) - 1);
+      end &= (PAGE_MASK << 1);
+      while(start < end) {
+	int idx;
+
+	write_c0_entryhi(start | newpid);
+	start += (PAGE_SIZE << 1);
+	tlb_probe();
+	idx = read_c0_index();
+	write_c0_entrylo0(0);
+	write_c0_entrylo1(0);
+	write_c0_entryhi(KSEG0 + (idx << (PAGE_SHIFT+1)));
+	if(idx < 0)
+	  continue;
+	tlb_write_indexed();
+      }
+      reload_context(oldpid);
+    } else {
+      get_new_mmu_context(mm, cpu);
+      if (mm == current->active_mm)
+	reload_context(cpu_context(cpu, mm));
+    }
+  }
+  local_irq_restore(flags);
+}
+
+void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
+{
+  unsigned long flags;
+  int size;
+
+  size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
+  size = (size + 1) >> 1;
+
+  local_irq_save(flags);
+  if (size <= (current_cpu_data.tlbsize/2)) {
+    int pid = read_c0_entryhi();
+
+    start &= (PAGE_MASK << 1);
+    end += ((PAGE_SIZE << 1) - 1);
+    end &= (PAGE_MASK << 1);
+
+    while (start < end) {
+      int idx;
+
+      write_c0_entryhi(start);
+      start += (PAGE_SIZE << 1);
+      tlb_probe();
+      idx = read_c0_index();
+      write_c0_entrylo0(0);
+      write_c0_entrylo1(0);
+      write_c0_entryhi(KSEG0 + (idx << (PAGE_SHIFT+1)));
+      if (idx < 0)
+	continue;
+      tlb_write_indexed();
+    }
+    reload_context(pid);
+  } else {
+    local_flush_tlb_all();
+  }
+  local_irq_restore(flags);
+}
+
+void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
+{
+  unsigned long flags;
+  int cpu;
+
+  local_irq_save(flags);
+  cpu = smp_processor_id();
+  if (cpu_context(cpu, vma->vm_mm) != 0) {
+    int oldpid, newpid, idx;
+#ifdef DEBUG_TLB
+    printk("[tlbpage<%ld,%08lx>]\n", cpu_context(cpu, vma->vm_mm), page);
+#endif
+    newpid = (cpu_context(cpu, vma->vm_mm) & 0xff);
+    page &= (PAGE_MASK << 1);
+    oldpid = (read_c0_entryhi() & 0xff);
+    write_c0_entryhi(page | newpid);
+    tlb_probe();
+    idx = read_c0_index();
+    write_c0_entrylo0(0);
+    write_c0_entrylo1(0);
+    if(idx < 0)
+      goto finish;
+    /* Make sure all entries differ. */  
+    write_c0_entryhi(KSEG0+(idx<<(PAGE_SHIFT+1)));
+    tlb_write_indexed();
+  finish:
+    reload_context(oldpid);
+  }
+  local_irq_restore(flags);
+}
+
+/*
+ * This one is only used for pages with the global bit set so we don't care
+ * much about the ASID.
+ */
+void local_flush_tlb_one(unsigned long page)
+{
+	unsigned long flags;
+	int oldpid, idx;
+
+	local_irq_save(flags);
+	page &= (PAGE_MASK << 1);
+	oldpid = read_c0_entryhi() & ASID_MASK;
+	write_c0_entryhi(page);
+	tlb_probe();
+	idx = read_c0_index();
+	write_c0_entrylo0(0);
+	write_c0_entrylo1(0);
+	if (idx >= 0) {
+		/* Make sure all entries differ. */
+		write_c0_entryhi(KSEG0+(idx<<(PAGE_SHIFT+1)));
+		tlb_write_indexed();
+	}
+	reload_context(oldpid);
+
+	local_irq_restore(flags);
+}
+
+/* All entries common to a mm share an asid.  To effectively flush
+   these entries, we just bump the asid. */
+void local_flush_tlb_mm(struct mm_struct *mm)
+{
+  unsigned long flags;
+  int cpu;
+  local_irq_save(flags);
+  cpu = smp_processor_id();
+  if (cpu_context(cpu, mm) != 0) {
+    get_new_mmu_context(mm, smp_processor_id());
+    if (mm == current->active_mm) {
+      reload_context(cpu_context(cpu, mm) & 0xff);
+    }
+  }
+  local_irq_restore(flags);
+}
+
+static int user_mac_bigtlb(struct vm_area_struct *vma, unsigned long pfn0, 
+			   unsigned long pfn1, int pid, int idx)
+{  
+  return 0;
+}
+
+void __update_tlb(struct vm_area_struct *vma, unsigned long address,
+		  pte_t pte)
+{
+  unsigned long flags;
+  pgd_t *pgdp;
+  pmd_t *pmdp;
+  pte_t *ptep;
+  int idx, pid;
+  unsigned long pfn0, pfn1;
+#ifdef DEBUG_TLB
+  int cpu = smp_processor_id();
+#endif
+
+  /*
+   * Handle debugger faulting in for debugee.
+   */
+  if (current->active_mm != vma->vm_mm)
+    return;
+
+  local_irq_save(flags);
+
+  phnx_inc_counter(USER_MAC_UPDATE_TLB);
+
+  pid = read_c0_entryhi() & 0xff;
+
+#ifdef DEBUG_TLB
+  if((pid != (cpu_context(cpu, vma->vm_mm) & 0xff)) 
+     || (cpu_context(cpu, vma->vm_mm) == 0)) {
+    printk("update_mmu_cache: Wheee, bogus tlbpid mmpid=%d tlbpid=%d\n",
+	   (int) (cpu_context(cpu, vma->vm_mm) & 0xff), pid);
+  }
+#endif
+
+  address &= (PAGE_MASK << 1);
+  write_c0_entryhi(address | (pid));
+  pgdp = pgd_offset(vma->vm_mm, address);
+  tlb_probe();
+  pmdp = pmd_offset(pgdp, address);
+  idx = read_c0_index();
+  ptep = pte_offset_map(pmdp, address);
+#ifdef DEBUG_TLB  
+  printk("[%s]: idx = %d, address = %lx, pte = %lx, pte+1=%lx, ptep=%lx\n", 
+	 __FUNCTION__, idx, address, pte_val(*ptep), pte_val(*(ptep+1)), 
+	 (unsigned long)ptep);
+#endif  
+  pfn0 = pte_pfn(*ptep);
+  pfn1 = pte_pfn(*(ptep+1));
+  phnx_set_counter(USER_MAC_UPDATE_TLB_PFN0, pte_val(*ptep));
+  phnx_set_counter(USER_MAC_UPDATE_TLB_PFN1, pte_val(*(ptep+1)));
+  if (!user_mac_bigtlb(vma, pfn0, pfn1, pid, idx)) {
+    write_c0_entrylo0(pte_val(*ptep++) >> 6);
+    write_c0_entrylo1(pte_val(*ptep) >> 6);
+    write_c0_entryhi(address | (pid));
+    if(idx < 0) {
+      tlb_write_random();
+    } else {
+      tlb_write_indexed();
+    }
+  }
+  local_irq_restore(flags);
+}
+
+unsigned long long phnx_tlb_stats[32] __cacheline_aligned;
+
+/*
+ * This is called from loadmmu.c.  We have to set up all the
+ * memory management function pointers, as well as initialize
+ * the caches and tlbs
+ */
+void tlb_init(void)
+{
+  u32 config1;
+
+  config1 = read_c0_config1();
+  current_cpu_data.tlbsize = ((config1 >> 25) & 0x3f) + 1;
+
+  phoenix_sanitize_tlb();
+
+  {
+    unsigned long virt_start = (unsigned long)PHNX_MMAP_VIRT_START & 0xffffffff;
+    unsigned long phys_start = (unsigned long)PHNX_MMAP_PHYS_START & 0xffffffff;
+    unsigned long phys_pmask_size = (unsigned long)PHNX_MMAP_PMASK_SIZE & 0xffffffff;
+
+    /* update scratch regs to be used in tlb refill */
+    __asm__ __volatile__ (".set push\n"
+			  ".set mips64\n"
+			  ".set noreorder\n"
+			  "dmtc0 %0, $22, "STR(PHOENIX_OSS_SEL_TLB_STATS)"\n"
+			  "dmtc0 %2, $22, "STR(PHOENIX_OSS_SEL_PAGEMASK)"\n"
+			  "dmtc0 %3, $22, "STR(PHOENIX_OSS_SEL_VADDR)"\n"
+			  "dmtc0 %4, $22, "STR(PHOENIX_OSS_SEL_PFN0)"\n"
+			  "dmtc0 %5, $22, "STR(PHOENIX_OSS_SEL_PFN1)"\n"
+			  ".set pop\n"
+			  : 
+			  : "r"(&phnx_tlb_stats[hard_smp_processor_id()]),
+			  "r"(PHNX_MMAP_PMASK_SIZE_256MB << 13),
+			  "r"(virt_start),
+			  "r"( phys_start >> 12),
+			  "r"( (phys_start + phys_pmask_size) >> 12)
+			  );
+  }
+
+  if (smp_processor_id()) return;
+
+  /* Set up the TLB Refill handler */
+  memcpy((void *)phnx_ebase, except_vec0_r4000, 0x80);
+}
+
+static int __init user_mac_tlb_init(void)
+{
+  void *vaddr = 0;
+  unsigned long phys_start = PHNX_MMAP_PHYS_START;
+  unsigned long phys_size = PHNX_MMAP_PHYS_SIZE;
+
+  if (!xlr_hybrid_user_mac() && !xlr_hybrid_user_mac_xgmac()) return 0;
+
+  if (!request_mem_region(phys_start, phys_size, "user_mac_private")) {
+    printk("[%s]: request_mem_region failed for phys_start=%lx, phys_size=%lx\n",
+	   __FUNCTION__, phys_start, phys_size);
+  }
+
+  vaddr = ioremap(phys_start, phys_size);
+
+/*   printk("[%s]: vaddr = %p\n", __FUNCTION__, vaddr); */
+/*   printk("[%s]: phnx_counters[0][USER_MAC_UPDATE_TLB]=%p\n",  */
+/* 	 __FUNCTION__, &phnx_counters[0][USER_MAC_UPDATE_TLB]); */
+
+/*   printk("[%s]: phnx_tlb_stats = %p\n", __FUNCTION__, phnx_tlb_stats); */
+
+  return 0;
+}
+
+arch_initcall(user_mac_tlb_init);
+
diff --git a/arch/mips/mm/tlb-r4k.c b/arch/mips/mm/tlb-r4k.c
index d2572cb..d3b484a 100644
--- a/arch/mips/mm/tlb-r4k.c
+++ b/arch/mips/mm/tlb-r4k.c
@@ -1,9 +1,21 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
  * for more details.
  *
- * Copyright (C) 1996 David S. Miller (davem@davemloft.net)
+ * Copyright (C) 1996 David S. Miller (dm@engr.sgi.com)
  * Copyright (C) 1997, 1998, 1999, 2000 Ralf Baechle ralf@gnu.org
  * Carsten Langgaard, carstenl@mips.com
  * Copyright (C) 2002 MIPS Technologies, Inc.  All rights reserved.
@@ -18,7 +30,12 @@
 #include <asm/bootinfo.h>
 #include <asm/mmu_context.h>
 #include <asm/pgtable.h>
-#include <asm/tlbmisc.h>
+
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/mips-exts.h>
+#include <asm/mach-rmi/mmu.h>
+#endif
+
 
 extern void build_tlb_refill_handler(void);
 
@@ -66,13 +83,34 @@ extern void build_tlb_refill_handler(void);
 
 #endif
 
+#ifdef CONFIG_RMI_VMIPS
+#define UNIQUE_VMIPS_ENTRYHI(idx)  ((1ULL << 63) + (1ULL << 40) + ((idx) << (PAGE_SHIFT + 1)) + ( 1 << 8))
+extern int rmi_vmips_max_wired_entries;
+#endif
+
+#ifdef CONFIG_RMI_XLP
+
+#define disable_pgwalker(flags) \
+({ flags = read_c0_config7(); \
+   write_c0_config7(read_c0_config7() & ~ENABLE_PGWALKER); })
+#define enable_pgwalker(flags) \
+({ write_c0_config7(read_c0_config7() | (flags & ENABLE_PGWALKER)); })
+
+#else
+
+#define disable_pgwalker(flags) {}
+#define enable_pgwalker(flags) {}
+
+#endif
+
 void local_flush_tlb_all(void)
 {
-	unsigned long flags;
+	unsigned long flags, config7_flags __maybe_unused;
 	unsigned long old_ctx;
 	int entry;
 
 	ENTER_CRITICAL(flags);
+	disable_pgwalker(config7_flags);
 	/* Save old context and create impossible VPN2 value */
 	old_ctx = read_c0_entryhi();
 	write_c0_entrylo0(0);
@@ -80,10 +118,18 @@ void local_flush_tlb_all(void)
 
 	entry = read_c0_wired();
 
+#if defined(CONFIG_MAPPED_KERNEL)
+	if (!entry) printk("[%s] flushing entry=%d in MAPPED_KERNEL mode!\n",
+			   __FUNCTION__, entry);
+#endif
 	/* Blast 'em all away. */
 	while (entry < current_cpu_data.tlbsize) {
 		/* Make sure all entries differ. */
+#ifndef CONFIG_RMI_VMIPS
 		write_c0_entryhi(UNIQUE_ENTRYHI(entry));
+#else
+        __write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(entry)));
+#endif
 		write_c0_index(entry);
 		mtc0_tlbw_hazard();
 		tlb_write_indexed();
@@ -92,6 +138,7 @@ void local_flush_tlb_all(void)
 	tlbw_use_hazard();
 	write_c0_entryhi(old_ctx);
 	FLUSH_ITLB;
+	enable_pgwalker(config7_flags);
 	EXIT_CRITICAL(flags);
 }
 
@@ -100,15 +147,17 @@ void local_flush_tlb_all(void)
 void local_flush_tlb_mm(struct mm_struct *mm)
 {
 	int cpu;
+	unsigned long config7_flags __maybe_unused;
 
 	preempt_disable();
 
 	cpu = smp_processor_id();
 
+	disable_pgwalker(config7_flags);
 	if (cpu_context(cpu, mm) != 0) {
 		drop_mmu_context(mm, cpu);
 	}
-
+	enable_pgwalker(config7_flags);
 	preempt_enable();
 }
 
@@ -120,30 +169,24 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 
 	if (cpu_context(cpu, mm) != 0) {
 		unsigned long size, flags;
-		int huge = is_vm_hugetlb_page(vma);
+		unsigned long config7_flags __maybe_unused;
 
 		ENTER_CRITICAL(flags);
-		if (huge) {
-			start = round_down(start, HPAGE_SIZE);
-			end = round_up(end, HPAGE_SIZE);
-			size = (end - start) >> HPAGE_SHIFT;
-		} else {
-			start = round_down(start, PAGE_SIZE << 1);
-			end = round_up(end, PAGE_SIZE << 1);
-			size = (end - start) >> (PAGE_SHIFT + 1);
-		}
+		disable_pgwalker(config7_flags);
+		size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
+		size = (size + 1) >> 1;
 		if (size <= current_cpu_data.tlbsize/2) {
 			int oldpid = read_c0_entryhi();
 			int newpid = cpu_asid(cpu, mm);
 
+			start &= (PAGE_MASK << 1);
+			end += ((PAGE_SIZE << 1) - 1);
+			end &= (PAGE_MASK << 1);
 			while (start < end) {
 				int idx;
 
 				write_c0_entryhi(start | newpid);
-				if (huge)
-					start += HPAGE_SIZE;
-				else
-					start += (PAGE_SIZE << 1);
+				start += (PAGE_SIZE << 1);
 				mtc0_tlbw_hazard();
 				tlb_probe();
 				tlb_probe_hazard();
@@ -153,7 +196,11 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 				if (idx < 0)
 					continue;
 				/* Make sure all entries differ. */
+#ifndef CONFIG_RMI_VMIPS
 				write_c0_entryhi(UNIQUE_ENTRYHI(idx));
+#else
+				__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
+#endif
 				mtc0_tlbw_hazard();
 				tlb_write_indexed();
 			}
@@ -163,6 +210,7 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 			drop_mmu_context(mm, cpu);
 		}
 		FLUSH_ITLB;
+		enable_pgwalker(config7_flags);
 		EXIT_CRITICAL(flags);
 	}
 }
@@ -170,8 +218,10 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
 {
 	unsigned long size, flags;
+	unsigned long config7_flags __maybe_unused;
 
 	ENTER_CRITICAL(flags);
+	disable_pgwalker(config7_flags);
 	size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
 	size = (size + 1) >> 1;
 	if (size <= current_cpu_data.tlbsize / 2) {
@@ -195,7 +245,11 @@ void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
 			if (idx < 0)
 				continue;
 			/* Make sure all entries differ. */
+#ifndef CONFIG_RMI_VMIPS
 			write_c0_entryhi(UNIQUE_ENTRYHI(idx));
+#else
+			__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
+#endif
 			mtc0_tlbw_hazard();
 			tlb_write_indexed();
 		}
@@ -205,6 +259,7 @@ void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
 		local_flush_tlb_all();
 	}
 	FLUSH_ITLB;
+	enable_pgwalker(config7_flags);
 	EXIT_CRITICAL(flags);
 }
 
@@ -213,12 +268,13 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
 	int cpu = smp_processor_id();
 
 	if (cpu_context(cpu, vma->vm_mm) != 0) {
-		unsigned long flags;
+		unsigned long flags, config7_flags __maybe_unused;
 		int oldpid, newpid, idx;
 
 		newpid = cpu_asid(cpu, vma->vm_mm);
 		page &= (PAGE_MASK << 1);
 		ENTER_CRITICAL(flags);
+		disable_pgwalker(config7_flags);
 		oldpid = read_c0_entryhi();
 		write_c0_entryhi(page | newpid);
 		mtc0_tlbw_hazard();
@@ -230,7 +286,11 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
 		if (idx < 0)
 			goto finish;
 		/* Make sure all entries differ. */
+#ifndef CONFIG_RMI_VMIPS
 		write_c0_entryhi(UNIQUE_ENTRYHI(idx));
+#else
+		__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
+#endif
 		mtc0_tlbw_hazard();
 		tlb_write_indexed();
 		tlbw_use_hazard();
@@ -238,6 +298,7 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
 	finish:
 		write_c0_entryhi(oldpid);
 		FLUSH_ITLB_VM(vma);
+		enable_pgwalker(config7_flags);
 		EXIT_CRITICAL(flags);
 	}
 }
@@ -248,10 +309,11 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
  */
 void local_flush_tlb_one(unsigned long page)
 {
-	unsigned long flags;
+	unsigned long flags, config7_flags __maybe_unused;
 	int oldpid, idx;
 
 	ENTER_CRITICAL(flags);
+	disable_pgwalker(config7_flags);
 	oldpid = read_c0_entryhi();
 	page &= (PAGE_MASK << 1);
 	write_c0_entryhi(page);
@@ -263,13 +325,18 @@ void local_flush_tlb_one(unsigned long page)
 	write_c0_entrylo1(0);
 	if (idx >= 0) {
 		/* Make sure all entries differ. */
+#ifndef CONFIG_RMI_VMIPS
 		write_c0_entryhi(UNIQUE_ENTRYHI(idx));
+#else
+		__write_64bit_c0_register($10, 0, (UNIQUE_VMIPS_ENTRYHI(idx)));
+#endif
 		mtc0_tlbw_hazard();
 		tlb_write_indexed();
 		tlbw_use_hazard();
 	}
 	write_c0_entryhi(oldpid);
 	FLUSH_ITLB;
+	enable_pgwalker(config7_flags);
 	EXIT_CRITICAL(flags);
 }
 
@@ -345,8 +412,42 @@ void __update_tlb(struct vm_area_struct * vma, unsigned long address, pte_t pte)
 	EXIT_CRITICAL(flags);
 }
 
-void add_wired_entry(unsigned long entrylo0, unsigned long entrylo1,
-		     unsigned long entryhi, unsigned long pagemask)
+#if 0
+static void r4k_update_mmu_cache_hwbug(struct vm_area_struct * vma,
+				       unsigned long address, pte_t pte)
+{
+	unsigned long flags;
+	unsigned int asid;
+	pgd_t *pgdp;
+	pmd_t *pmdp;
+	pte_t *ptep;
+	int idx;
+
+	ENTER_CRITICAL(flags);
+	address &= (PAGE_MASK << 1);
+	asid = read_c0_entryhi() & ASID_MASK;
+	write_c0_entryhi(address | asid);
+	pgdp = pgd_offset(vma->vm_mm, address);
+	mtc0_tlbw_hazard();
+	tlb_probe();
+	tlb_probe_hazard();
+	pmdp = pmd_offset(pgdp, address);
+	idx = read_c0_index();
+	ptep = pte_offset_map(pmdp, address);
+	write_c0_entrylo0(pte_val(*ptep++) >> 6);
+	write_c0_entrylo1(pte_val(*ptep) >> 6);
+	mtc0_tlbw_hazard();
+	if (idx < 0)
+		tlb_write_random();
+	else
+		tlb_write_indexed();
+	tlbw_use_hazard();
+	EXIT_CRITICAL(flags);
+}
+#endif
+
+void __init add_wired_entry(unsigned long entrylo0, unsigned long entrylo1,
+	unsigned long entryhi, unsigned long pagemask)
 {
 	unsigned long flags;
 	unsigned long wired;
@@ -376,6 +477,79 @@ void add_wired_entry(unsigned long entrylo0, unsigned long entrylo1,
 	EXIT_CRITICAL(flags);
 }
 
+/*
+ * Used for loading TLB entries before trap_init() has started, when we
+ * don't actually want to add a wired entry which remains throughout the
+ * lifetime of the system
+ */
+
+static int temp_tlb_entry __cpuinitdata;
+
+__init int add_temporary_entry(unsigned long entrylo0, unsigned long entrylo1,
+			       unsigned long entryhi, unsigned long pagemask)
+{
+	int ret = 0;
+	unsigned long flags;
+	unsigned long wired;
+	unsigned long old_pagemask;
+	unsigned long old_ctx;
+
+	ENTER_CRITICAL(flags);
+	/* Save old context and create impossible VPN2 value */
+	old_ctx = read_c0_entryhi();
+	old_pagemask = read_c0_pagemask();
+	wired = read_c0_wired();
+	if (--temp_tlb_entry < wired) {
+		printk(KERN_WARNING
+		       "No TLB space left for add_temporary_entry\n");
+		ret = -ENOSPC;
+		goto out;
+	}
+
+	write_c0_index(temp_tlb_entry);
+	write_c0_pagemask(pagemask);
+	write_c0_entryhi(entryhi);
+	write_c0_entrylo0(entrylo0);
+	write_c0_entrylo1(entrylo1);
+	mtc0_tlbw_hazard();
+	tlb_write_indexed();
+	tlbw_use_hazard();
+
+	write_c0_entryhi(old_ctx);
+	write_c0_pagemask(old_pagemask);
+out:
+	EXIT_CRITICAL(flags);
+	return ret;
+}
+
+static void __cpuinit probe_tlb(unsigned long config)
+{
+	struct cpuinfo_mips *c = &current_cpu_data;
+	unsigned int reg;
+
+	/*
+	 * If this isn't a MIPS32 / MIPS64 compliant CPU.  Config 1 register
+	 * is not supported, we assume R4k style.  Cpu probing already figured
+	 * out the number of tlb entries.
+	 */
+	if ((c->processor_id & 0xff0000) == PRID_COMP_LEGACY)
+		return;
+#ifdef CONFIG_MIPS_MT_SMTC
+	/*
+	 * If TLB is shared in SMTC system, total size already
+	 * has been calculated and written into cpu_data tlbsize
+	 */
+	if((smtc_status & SMTC_TLB_SHARED) == SMTC_TLB_SHARED)
+		return;
+#endif /* CONFIG_MIPS_MT_SMTC */
+
+	reg = read_c0_config1();
+	if (!((config >> 7) & 3))
+		panic("No TLB present");
+
+	c->tlbsize = ((reg >> 25) & 0x3f) + 1;
+}
+
 static int __cpuinitdata ntlb;
 static int __init set_ntlb(char *str)
 {
@@ -385,8 +559,29 @@ static int __init set_ntlb(char *str)
 
 __setup("ntlb=", set_ntlb);
 
+#ifdef CONFIG_RMI_PHOENIX
+extern void phoenix_tlb_init(void);
+
+void rmi_tlb_stats_init(void)
+{
+	rmi_write_os_scratch_2(0ULL);
+}
+
+#ifdef CONFIG_HUGETLBFS
+void rmi_tlb_entrylo0_mask_init(void);
+void rmi_tlb_entrylo0_mask_init()
+{
+	unsigned long long mask = ~(((1ULL<<HUGETLB_PAGE_ORDER)-1)<<6);
+	rmi_write_os_scratch_3(mask);
+}
+#endif
+
+#endif
+
 void __cpuinit tlb_init(void)
 {
+	unsigned int config = read_c0_config();
+
 	/*
 	 * You should never change this register:
 	 *   - On R4600 1.7 the tlbp never hits for pages smaller than
@@ -394,24 +589,25 @@ void __cpuinit tlb_init(void)
 	 *   - The entire mm handling assumes the c0_pagemask register to
 	 *     be set to fixed-size pages.
 	 */
+	probe_tlb(config);
 	write_c0_pagemask(PM_DEFAULT_MASK);
-	write_c0_wired(0);
+
+#if defined(CONFIG_RMI_VMIPS)
+	if(ntlb && ((current_cpu_data.tlbsize-ntlb) < rmi_vmips_max_wired_entries))
+		ntlb = current_cpu_data.tlbsize - rmi_vmips_max_wired_entries;
+#endif
+
 	if (current_cpu_type() == CPU_R10000 ||
 	    current_cpu_type() == CPU_R12000 ||
 	    current_cpu_type() == CPU_R14000)
 		write_c0_framemask(0);
 
-	if (kernel_uses_smartmips_rixi) {
-		/*
-		 * Enable the no read, no exec bits, and enable large virtual
-		 * address.
-		 */
-		u32 pg = PG_RIE | PG_XIE;
-#ifdef CONFIG_64BIT
-		pg |= PG_ELPA;
+#if !defined(CONFIG_MAPPED_KERNEL)
+	write_c0_wired(0);
+	write_c0_framemask(0);
 #endif
-		write_c0_pagegrain(pg);
-	}
+
+	temp_tlb_entry = current_cpu_data.tlbsize - 1;
 
         /* From this point on the ARC firmware is dead.  */
 	local_flush_tlb_all();
@@ -428,5 +624,17 @@ void __cpuinit tlb_init(void)
 			printk("Ignoring invalid argument ntlb=%d\n", ntlb);
 	}
 
-	build_tlb_refill_handler();
+#ifdef CONFIG_RMI_PHOENIX
+
+	rmi_tlb_stats_init();
+
+#ifdef CONFIG_HUGETLBFS
+
+	rmi_tlb_entrylo0_mask_init();
+
+#endif
+
+#endif
+
+    build_tlb_refill_handler();
 }
diff --git a/arch/mips/mm/tlbex-fault.S b/arch/mips/mm/tlbex-fault.S
index e99eaa1..54c0f93 100644
--- a/arch/mips/mm/tlbex-fault.S
+++ b/arch/mips/mm/tlbex-fault.S
@@ -26,3 +26,6 @@
 
 	tlb_do_page_fault 0
 	tlb_do_page_fault 1
+#if defined(CONFIG_READ_INHIBIT) || defined(CONFIG_EXEC_INHIBIT)
+	tlb_do_page_fault 2
+#endif
diff --git a/arch/mips/mm/tlbex.c b/arch/mips/mm/tlbex.c
index b69f80f..392cd70 100644
--- a/arch/mips/mm/tlbex.c
+++ b/arch/mips/mm/tlbex.c
@@ -226,7 +226,11 @@ static inline void dump_handler(const u32 *handler, int count)
  * We deliberately chose a buffer size of 128, so we won't scribble
  * over anything important on overflow before we panic.
  */
-static u32 tlb_handler[128] __cpuinitdata;
+#if defined(CONFIG_MAPPED_KERNEL)
+static u32 tlb_handler[128];
+#else
+static u32 tlb_handler[128] __cpuinitdata ;
+#endif
 
 /* simply assume worst case size for labels and relocs */
 static struct uasm_label labels[128] __cpuinitdata;
@@ -387,7 +391,10 @@ static void __cpuinit build_r3000_tlb_refill_handler(void)
  * other one.To keep things simple, we first assume linear space,
  * then we relocate it to the final handler layout as needed.
  */
+
+#if !defined(CONFIG_MAPPED_KERNEL)
 static u32 final_handler[64] __cpuinitdata;
+#endif
 
 /*
  * Hazards
@@ -487,6 +494,7 @@ static void __cpuinit build_tlb_write_entry(u32 **p, struct uasm_label **l,
 	case CPU_TX49XX:
 	case CPU_PR4450:
 	case CPU_XLR:
+	case CPU_XLP:
 		uasm_i_nop(p);
 		tlbw(p);
 		break;
@@ -1231,15 +1239,19 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 	u32 *p = tlb_handler;
 	struct uasm_label *l = labels;
 	struct uasm_reloc *r = relocs;
-	u32 *f;
-	unsigned int final_len;
+	unsigned int final_len = 0;
 	struct mips_huge_tlb_info htlb_info __maybe_unused;
 	enum vmalloc64_mode vmalloc_mode __maybe_unused;
 
+#if !defined(CONFIG_MAPPED_KERNEL)
+	u32 *f;
+
+	memset(final_handler, 0, sizeof(final_handler));
+#endif
+
 	memset(tlb_handler, 0, sizeof(tlb_handler));
 	memset(labels, 0, sizeof(labels));
 	memset(relocs, 0, sizeof(relocs));
-	memset(final_handler, 0, sizeof(final_handler));
 
 	if ((scratch_reg > 0 || scratchpad_available()) && use_bbit_insns()) {
 		htlb_info = build_fast_tlb_refill_handler(&p, &l, &r, K0, K1,
@@ -1293,6 +1305,7 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 	build_get_pgd_vmalloc64(&p, &l, &r, K0, K1, vmalloc_mode);
 #endif
 
+#if !defined(CONFIG_MAPPED_KERNEL)
 	/*
 	 * Overflow check: For the 64bit handler, we need at least one
 	 * free instruction slot for the wrap-around branch. In worst
@@ -1390,15 +1403,58 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 	}
 #endif /* CONFIG_64BIT */
 
+#endif /* !defined(CONFIG_MAPPED_KERNEL) */
+
 	uasm_resolve_relocs(relocs, labels);
 	pr_debug("Wrote TLB refill handler (%u instructions).\n",
 		 final_len);
 
+#if !defined(CONFIG_MAPPED_KERNEL)
 	memcpy((void *)ebase, final_handler, 0x100);
+#endif
 
 	dump_handler((u32 *)ebase, 64);
 }
 
+#if defined(CONFIG_MAPPED_KERNEL)
+
+static u32 tlb_handler_stub[32] __cpuinitdata;
+
+static void __cpuinit __attribute__((unused)) build_r4000_tlb_refill_handler_stub(void)
+{
+	u32 *p = tlb_handler_stub;
+
+	memset(tlb_handler_stub, 0, sizeof(tlb_handler_stub));
+	UASM_i_LA(&p, K0, (unsigned long) tlb_handler);
+	uasm_i_jr(&p, K0);
+	uasm_i_nop(&p);
+
+	/*
+	 * 32 instruction = 128 bytes
+	 */
+#ifdef CONFIG_64BIT
+	memcpy((void *)ebase + 0x80, tlb_handler_stub, 0x80); /* XTLB exception */
+#else
+	memcpy((void *)ebase, tlb_handler_stub, 0x80); /* TLB exception */
+#endif
+}
+
+#else
+
+static void __cpuinit __attribute__((unused)) build_r4000_tlb_refill_handler_stub(void) { }
+
+#endif /* defined(CONFIG_MAPPED_KERNEL) */
+
+/*
+ * TLB load/store/modify handlers.
+ *
+ * Only the fastpath gets synthesized at runtime, the slowpath for
+ * do_page_fault remains normal asm.
+ */
+extern void tlb_do_page_fault_0(void);
+extern void tlb_do_page_fault_1(void);
+extern void tlb_do_page_fault_2(void);
+
 /*
  * 128 instructions for the fastpath handler is generous and should
  * never be exceeded.
diff --git a/arch/mips/oprofile/Makefile b/arch/mips/oprofile/Makefile
index 29f2f13..f52513b 100644
--- a/arch/mips/oprofile/Makefile
+++ b/arch/mips/oprofile/Makefile
@@ -15,4 +15,5 @@ oprofile-$(CONFIG_CPU_MIPS64)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_R10000)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_SB1)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_RM9000)		+= op_model_rm9000.o
+oprofile-$(CONFIG_RMI_PHOENIX)		+= op_model_mips_xlr.o
 oprofile-$(CONFIG_CPU_LOONGSON2)	+= op_model_loongson2.o
diff --git a/arch/mips/oprofile/common.c b/arch/mips/oprofile/common.c
index d1f2d4c..8c73389 100644
--- a/arch/mips/oprofile/common.c
+++ b/arch/mips/oprofile/common.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General Public
  * License.  See the file "COPYING" in the main directory of this archive
@@ -18,7 +30,7 @@
 extern struct op_mips_model op_model_mipsxx_ops __weak;
 extern struct op_mips_model op_model_rm9000_ops __weak;
 extern struct op_mips_model op_model_loongson2_ops __weak;
-
+extern struct op_mips_model op_model_phoenix __attribute__((weak));
 static struct op_mips_model *model;
 
 static struct op_counter_config ctr[20];
@@ -77,6 +89,10 @@ int __init oprofile_arch_init(struct oprofile_operations *ops)
 	int res;
 
 	switch (current_cpu_type()) {
+	case CPU_XLR:
+	case CPU_XLP:
+		lmodel = &op_model_phoenix;
+		break;
 	case CPU_5KC:
 	case CPU_20KC:
 	case CPU_24K:
diff --git a/arch/mips/oprofile/op_impl.h b/arch/mips/oprofile/op_impl.h
index 7c2da27..ba38803 100644
--- a/arch/mips/oprofile/op_impl.h
+++ b/arch/mips/oprofile/op_impl.h
@@ -1,4 +1,16 @@
-/**
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/*
  * @file arch/alpha/oprofile/op_impl.h
  *
  * @remark Copyright 2002 OProfile authors
diff --git a/arch/mips/oprofile/op_model_mips_xlr.c b/arch/mips/oprofile/op_model_mips_xlr.c
new file mode 100644
index 0000000..0931191
--- /dev/null
+++ b/arch/mips/oprofile/op_model_mips_xlr.c
@@ -0,0 +1,362 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/init.h>
+#include <linux/oprofile.h>
+#include <linux/interrupt.h>
+#include <linux/smp.h>
+#include <asm/mipsregs.h>
+
+#include "op_impl.h"
+
+#define PHOENIX_PMC_EVENT_MASK			0x3f
+#define PHOENIX_PMC_EVENT(event) 		\
+				((event & PHOENIX_PMC_EVENT_MASK) << 5)
+#define PHOENIX_PMC_DOM_EXL       		(1U << 0)
+#define PHOENIX_PMC_DOM_KERNEL			(1U << 1)
+#define PHOENIX_PMC_DOM_USR			(1U << 3)
+#define PHOENIX_PMC_ENABLE_INT          (1U << 4)
+#define PHOENIX_PMC_THREAD_ID_MASK		0x03
+#define PHOENIX_PMC_THREAD_ID(tid)      	\
+				((tid & PHOENIX_PMC_THREAD_ID_MASK) << 11)
+#define PHOENIX_PMC_COUNT_ALL_THREADS	(1U << 13)
+
+#define XLR_MAX_PERF_COUNTERS 2
+#define XLR_MAX_CPU_CORES 8
+#define XLR_MAX_CPUS 32
+
+extern struct op_mips_model op_model_phoenix;
+
+static struct phoenix_register_config {
+	unsigned int control[XLR_MAX_PERF_COUNTERS];
+	unsigned int reset_counter[XLR_MAX_PERF_COUNTERS];
+}reg;
+
+/* Compute all of the registers in preparation for enabling profiling.  */
+volatile int phnx_perf_core_setup[XLR_MAX_CPU_CORES];
+spinlock_t phnx_perf_lock = SPIN_LOCK_UNLOCKED;
+int g_stop_pmc[XLR_MAX_CPUS];
+
+/* 
+ * Per core Performance counter overflow mask. This 
+ * mask is set to 0xF by the perf counter "owner" 
+ * when a performance event counter overflows. This 
+ * is used by other threads in the core to call 
+ * oprofile_add_sample
+ */
+
+volatile int phnx_pc_of_mask1[XLR_MAX_CPUS];
+volatile int phnx_pc_of_mask2[XLR_MAX_CPUS];
+
+/* Check if this thread is the owner for PerfCounters in this core */
+int phnx_pmc_owner(void)
+{
+	int cpu_id ;
+	unsigned long flags;
+
+	/* Allow only one thread in each core to set perfcounter events */
+	spin_lock_irqsave(&phnx_perf_lock, flags);
+	cpu_id = phoenix_cpu_id();
+	if(phnx_perf_core_setup[cpu_id] == hard_smp_processor_id()) {
+		spin_unlock_irqrestore(&phnx_perf_lock, flags);
+		return 1;
+	}
+	spin_unlock_irqrestore(&phnx_perf_lock, flags);
+	return 0;
+}
+/* To be called only from perf interrup handler */
+int phnx_pmc_owner_nolock(void)
+{
+	int cpu_id, h_id ;
+	cpu_id = phoenix_cpu_id();
+	h_id = hard_smp_processor_id();
+
+	if(phnx_perf_core_setup[cpu_id] == h_id) {
+		return 1;
+	}
+	return 0;
+
+}
+
+/* 
+ * Check if perfcounters is already owned 
+ * by some other thread in this core 
+ */
+
+static int phnx_pmc_owned(void)
+{
+	int cpu_id ;
+	unsigned long flags;
+	int thr_id;
+
+	/* Allow only thread0 in each core to set perfcounter events */
+	spin_lock_irqsave(&phnx_perf_lock, flags);
+	thr_id = phoenix_thr_id();
+	if(thr_id) {
+		spin_unlock_irqrestore(&phnx_perf_lock, flags);
+		return 1;
+	}
+	cpu_id = phoenix_cpu_id();
+	if(phnx_perf_core_setup[cpu_id] == -1) {
+		phnx_perf_core_setup[cpu_id] = hard_smp_processor_id();
+		spin_unlock_irqrestore(&phnx_perf_lock, flags);
+		return 0;
+	}
+	if(phnx_perf_core_setup[cpu_id] == hard_smp_processor_id()) {
+		spin_unlock_irqrestore(&phnx_perf_lock, flags);
+		return 0;
+	}
+	spin_unlock_irqrestore(&phnx_perf_lock, flags);
+	return 1;
+}
+static void phoenix_reg_setup(struct op_counter_config *ctr)
+{
+	unsigned int counters = op_model_phoenix.num_counters;
+	int i;
+	unsigned long flags;
+
+	/* Compute the performance counter control word.  */
+	local_irq_save(flags);
+	for(i=0; i < counters; i++) {
+		reg.control[i] = 0;
+		reg.reset_counter[i] = 0;
+
+		if (!ctr[i].enabled)
+			continue;
+
+		reg.control[i] = PHOENIX_PMC_EVENT(ctr[i].event) | 
+			PHOENIX_PMC_ENABLE_INT | 
+			PHOENIX_PMC_COUNT_ALL_THREADS;
+		if (ctr[i].kernel)
+			reg.control[i] |= PHOENIX_PMC_DOM_KERNEL;
+		if (ctr[i].user)
+			reg.control[i] |= PHOENIX_PMC_DOM_USR;
+		if (ctr[i].exl)
+			reg.control[i] |= PHOENIX_PMC_DOM_EXL;
+
+		reg.reset_counter[i] = 0x80000000 - ctr[i].count;
+	}
+	wmb();
+	local_irq_restore(flags);
+}
+
+/* Program all of the registers in preparation for enabling profiling.  */
+
+static void phoenix_cpu_setup (void *args)
+{
+	unsigned long flags;
+	/* 
+	 * Check if some other thread has already taken 
+	 * the ownership of setting perf counters. If not,
+	 * set the ownership
+	 */
+	if(phnx_pmc_owned())
+		return;
+
+	local_irq_save(flags);
+	__write_32bit_c0_register($25, 1, reg.reset_counter[0]);
+	__write_32bit_c0_register($25, 3, reg.reset_counter[1]);
+	local_irq_restore(flags);
+}
+
+static void phoenix_cpu_start(void *args)
+{
+	int core_start = phoenix_cpu_id() * 4;
+	int i;
+	unsigned long flags;
+
+	if(phnx_pmc_owned()) {
+		return;
+	}
+	/* Start all counters on current CPU */
+	local_irq_save(flags);
+
+	__write_32bit_c0_register($25, 0, reg.control[0]);
+	__write_32bit_c0_register($25, 2, reg.control[1]);
+
+	for(i=0; i < 4; i++)
+		g_stop_pmc[core_start + i] = 0;
+	wmb();
+	local_irq_restore(flags);
+}
+
+static void phoenix_cpu_stop(void *args)
+{
+	int cpu_id = phoenix_cpu_id();
+	int core_start = cpu_id * 4;
+	int i;
+	unsigned long flags;
+
+	local_irq_save(flags);
+	g_stop_pmc[hard_smp_processor_id()] = 1;
+	local_irq_restore(flags);
+
+	if(phnx_pmc_owned())
+		return;
+	/* Stop all counters on current CPU */
+	local_irq_save(flags);
+	__write_32bit_c0_register($25, 0, 0);
+	__write_32bit_c0_register($25, 2, 0);
+	for(i=0; i < 4; i++) {
+		phnx_pc_of_mask1[core_start + i] = 0;
+		phnx_pc_of_mask2[core_start + i] = 0;
+	}
+	local_irq_restore(flags);
+}
+
+/* 
+ * This handler is called from count compare timer 
+ * interrupt as the perf counter overflow interrupt 
+ * shares the same count compare IRQ.
+ */
+
+void phoenix_oprofile_int_handler(int irq, void * dev_id,
+	struct pt_regs *regs)
+{
+	uint32_t counter1, counter2;
+	uint32_t control1, control2;
+	int i;
+	int cpu_id = phoenix_cpu_id() * 4; /* 0, 4, 8 ... 28 */
+	int h_id = hard_smp_processor_id();/* 0, 1, 2, 3, 4, .....31 */
+	int ret, lcpu;
+	int sample1_taken=0;
+	int sample2_taken=0;
+
+	if(g_stop_pmc[h_id])
+		return;
+
+	if(((ret = phnx_pmc_owner_nolock()) == 0)) {
+		/* if any counter overflow occured on this core.... */
+		if(phnx_pc_of_mask1[h_id]) {
+			oprofile_add_sample(regs, 0);
+		}
+		if(phnx_pc_of_mask2[h_id]) {
+			oprofile_add_sample(regs, 1);
+		}
+		return;
+	}
+
+	control1 = __read_32bit_c0_register ($25, 0);
+	control2 = __read_32bit_c0_register ($25, 2);
+
+
+	counter1 = __read_32bit_c0_register ($25, 1);
+	counter2 = __read_32bit_c0_register ($25, 3);
+
+	if (((int)counter1) < 0) {
+		__write_32bit_c0_register($25, 0, 0);
+		oprofile_add_sample(regs, 0);
+		counter1 = reg.reset_counter[0];
+		sample1_taken = 1;
+
+		for(i=0; i < 4; i++)
+			phnx_pc_of_mask1[cpu_id + i] = 1;
+		wmb();
+		for(i=1; i < 4; i++) {
+			lcpu = cpu_number_map(cpu_id+i);
+			if(lcpu && cpu_isset(lcpu, cpu_online_map)) {
+				core_send_ipi(lcpu, SMP_OPROFILE_IPI);
+			}
+		}
+	}
+	if (((int)counter2) < 0) {
+		__write_32bit_c0_register($25, 2, 0);
+		oprofile_add_sample(regs, 1);
+		counter2 = reg.reset_counter[1];
+		sample2_taken = 1;
+
+		for(i=0; i < 4; i++)
+			phnx_pc_of_mask2[cpu_id + i] = 1;
+		wmb();
+		for(i=1; i < 4; i++) {
+			lcpu = cpu_number_map(cpu_id+i);
+			if(lcpu && cpu_isset(lcpu, cpu_online_map)) {
+				core_send_ipi(lcpu, SMP_OPROFILE_IPI);
+			}
+		}
+	}
+
+	if(sample1_taken) {
+		__write_32bit_c0_register($25, 1, counter1);
+		__write_32bit_c0_register($25, 0, reg.control[0]);
+	}
+	if(sample2_taken) {
+		__write_32bit_c0_register($25, 3, counter2);
+		__write_32bit_c0_register($25, 2, reg.control[1]);
+	}
+
+	return ;
+}
+
+static void phnx_reset_perf_counters(void)
+{
+	__write_32bit_c0_register($25, 0, 0);
+	__write_32bit_c0_register($25, 1, 0);
+
+	__write_32bit_c0_register($25, 2, 0);
+	__write_32bit_c0_register($25, 3, 0);
+
+}
+
+static int __init phoenix_init(void)
+{
+	int i;
+
+	for(i=0; i < XLR_MAX_CPU_CORES; i++)
+		phnx_perf_core_setup[i] = -1;
+
+	for(i=0; i < XLR_MAX_CPUS; i++)
+		g_stop_pmc[i] = 1;
+	phnx_reset_perf_counters();
+
+	return 0;
+}
+
+static void phoenix_exit(void)
+{
+	phnx_reset_perf_counters();
+	return;
+}
+
+
+/*
+ * The following is assigned to the variable 
+ * 'lmodel' in oprofile_arch_init()
+ */
+struct op_mips_model op_model_phoenix = {
+	.reg_setup	= phoenix_reg_setup,
+	.cpu_setup	= phoenix_cpu_setup,
+	.init		= phoenix_init,
+	.exit		= phoenix_exit,
+	.cpu_start	= phoenix_cpu_start,
+	.cpu_stop	= phoenix_cpu_stop,
+	.cpu_type	= "mips/phoenix",
+	.num_counters	= XLR_MAX_PERF_COUNTERS,
+};
diff --git a/arch/mips/pci/Makefile b/arch/mips/pci/Makefile
index c3ac4b0..8895b5a 100644
--- a/arch/mips/pci/Makefile
+++ b/arch/mips/pci/Makefile
@@ -53,6 +53,8 @@ obj-$(CONFIG_TOSHIBA_RBTX4927)	+= fixup-rbtx4927.o
 obj-$(CONFIG_TOSHIBA_RBTX4938)	+= fixup-rbtx4938.o
 obj-$(CONFIG_VICTOR_MPC30X)	+= fixup-mpc30x.o
 obj-$(CONFIG_ZAO_CAPCELLA)	+= fixup-capcella.o
+obj-$(CONFIG_RMI_XLR)  	+= pci-phoenix.o
+obj-$(CONFIG_RMI_XLP)  	+= pci-xlp.o
 obj-$(CONFIG_WR_PPMC)		+= fixup-wrppmc.o
 obj-$(CONFIG_MIKROTIK_RB532)	+= pci-rc32434.o ops-rc32434.o fixup-rc32434.o
 obj-$(CONFIG_CPU_CAVIUM_OCTEON)	+= pci-octeon.o pcie-octeon.o
diff --git a/arch/mips/pci/pci-phoenix.c b/arch/mips/pci/pci-phoenix.c
new file mode 100644
index 0000000..347b2e3
--- /dev/null
+++ b/arch/mips/pci/pci-phoenix.c
@@ -0,0 +1,759 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/types.h>
+#include <linux/pci.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/mm.h>
+#include <linux/console.h>
+#include <linux/ide.h>
+
+#include <asm/io.h>
+
+#include <asm/rmi/interrupt.h>
+#include <asm/rmi/pci.h>
+#include <asm/rmi/io.h>         
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/rmi_srio.h>
+
+#define  PCI_HT_LCTR_INIT   0x0020  /* Initialization Complete  */
+#define  PCIE_LINK_STATE    0x4000  /* Bit 14, Datalink Status  */
+
+#define LSU_CFG0_REGID       0
+#define LSU_CERRLOG_REGID    9
+#define LSU_CERROVF_REGID    10
+#define LSU_CERRINT_REGID    11
+
+
+#define pci_cfg_offset(bus,devfn,where) (((bus)<<16)+((devfn)<<8)+(where))
+#define pci_cfg_addr(bus,devfn,where) pci_cfg_offset((bus)->number,(devfn),where)
+int  pci_start_busno;
+static int  pci_bus_status;
+static int  pci_start_bus_fixed;
+#if 0
+/*
+  Maximum bus number on PCI is 0xff,
+  hence, start the ht_busno with
+  0xff + 1. This variable will get
+  reset to the actual value when
+  the enumeration of HT begins.
+*/
+int  ht_start_busno = 0x100;
+#else
+int  ht_start_busno = 0;
+#endif
+static int  ht_start_bus_fixed;
+static void *pci_config_base;
+#if 0
+static void *pci_io_base;
+#else
+void *pci_io_base;
+#endif
+static void *ht_io_base;
+
+volatile void *ht_config_base;
+/* Global Link Status */
+int link0 = 0, link1 = 0, link2 = 0, link3 = 0;
+
+#define CFGTYPE(x) ((x)<(1)?(0):(1))
+#define MB16 0x01000000
+
+#define SWAP32(x)				\
+        (((x) & 0xff000000) >> 24) |		\
+        (((x) & 0x000000ff) << 24) |		\
+        (((x) & 0x0000ff00) << 8)  |		\
+        (((x) & 0x00ff0000) >> 8)
+
+static __inline__ void disable_and_clear_cache_error(void)
+{
+        uint64_t lsu_cfg0 = read_64bit_phnx_ctrl_reg(CPU_BLOCKID_LSU, LSU_CFG0_REGID);
+        lsu_cfg0 = lsu_cfg0 & ~0x2e;
+        write_64bit_phnx_ctrl_reg(CPU_BLOCKID_LSU, LSU_CFG0_REGID, lsu_cfg0);
+        /* Clear cache error log */
+        write_64bit_phnx_ctrl_reg(CPU_BLOCKID_LSU, LSU_CERRLOG_REGID, 0);
+}
+
+static __inline__ void clear_and_enable_cache_error(void)
+{
+        uint64_t lsu_cfg0 = 0;
+
+        /* first clear the cache error logging register */
+        write_64bit_phnx_ctrl_reg(CPU_BLOCKID_LSU, LSU_CERRLOG_REGID, 0);
+        write_64bit_phnx_ctrl_reg(CPU_BLOCKID_LSU, LSU_CERROVF_REGID, 0);
+        write_64bit_phnx_ctrl_reg(CPU_BLOCKID_LSU, LSU_CERRINT_REGID, 0);
+
+        lsu_cfg0 = read_64bit_phnx_ctrl_reg(CPU_BLOCKID_LSU, LSU_CFG0_REGID);
+        lsu_cfg0 = lsu_cfg0 | 0x2e;
+        write_64bit_phnx_ctrl_reg(CPU_BLOCKID_LSU, LSU_CFG0_REGID, lsu_cfg0);
+}
+
+static inline int ht_controller_init_done(void)
+{
+	int init_done=0;
+	phoenix_reg_t *ht_mmio = phoenix_io_mmio(PHOENIX_IO_HT_OFFSET);
+	phoenix_reg_t reg = cpu_to_le32(phoenix_read_reg(ht_mmio, (0xA4 >> 2)));
+	if ((uint16_t)reg & PCI_HT_LCTR_INIT)
+		init_done = 1;
+	else
+		printk("Skipping XLR HT-Controller Registration...\n");
+	return init_done;
+}
+
+void pcie_controller_init_done(void) {
+
+    phoenix_reg_t *pcie_mmio_le = phoenix_io_mmio(PHOENIX_IO_PCIE_1_OFFSET);
+	phoenix_reg_t reg_link0     = phoenix_read_reg(pcie_mmio_le, (0x80 >> 2));
+	phoenix_reg_t reg_link1     = phoenix_read_reg(pcie_mmio_le, (0x84 >> 2));
+	phoenix_reg_t reg_link2  = 0;
+	phoenix_reg_t reg_link3  = 0;
+
+	if ((uint16_t)reg_link0 & PCIE_LINK_STATE)
+		link0 = 1;
+    else
+        link0 = 0;
+
+	if ((uint16_t)reg_link1 & PCIE_LINK_STATE)
+		link1 = 1;
+    else
+        link1 = 0;
+
+    if(is_xls2xx() || is_xls_b0()){
+
+        reg_link2 = phoenix_read_reg(pcie_mmio_le, (0x180 >> 2));
+
+        if((uint16_t)reg_link2 & PCIE_LINK_STATE)
+            link2 = 1;
+        else 
+            link2 = 0;
+
+	    reg_link3 = phoenix_read_reg(pcie_mmio_le, (0x184 >> 2));
+
+        if((uint16_t)reg_link3 & PCIE_LINK_STATE)
+            link3 = 1;
+        else
+            link3 = 0;
+    }
+}
+
+#if 1
+static inline __u32 pci_cfg_read_32bit(__u32 addr)
+{
+    __u32 temp = 0;
+    __u32 *p = (__u32 *) (pci_config_base + (addr & ~3));
+    __u64 cerr_cpu_log = 0;
+
+    disable_and_clear_cache_error();
+
+    temp = SWAP32(*p);
+
+    /* Read cache err log */
+    cerr_cpu_log = read_64bit_phnx_ctrl_reg(CPU_BLOCKID_LSU, LSU_CERRLOG_REGID);
+    if(cerr_cpu_log) {
+        /* Device doesn't exist. */
+        temp = ~0x0;
+    }
+    clear_and_enable_cache_error();
+    return temp;
+}
+
+static inline void pci_cfg_write_32bit(__u32 addr, __u32 data) {
+    
+        unsigned int *p = (unsigned int *)(pci_config_base + (addr & ~3));
+        *p = SWAP32(data);
+}
+#else
+/*
+ * Read/write 32-bit values in config space.
+ * pci config space is little endian
+ */
+static inline __u32 pci_cfg_read_32bit(__u32 addr)
+{
+	__u8 *p = (__u8 *)(pci_config_base + (addr & ~3));
+	//printk("[%s]: addr = %p, data = %x\n", __FUNCTION__, p, *(__u32*)p);
+	return ( (*(p+3) << 24) | (*(p+2) << 16) | (*(p+1) << 8) | *p);
+}
+
+static inline void pci_cfg_write_32bit(__u32 addr, __u32 data)
+{
+	__u8 *p = (__u8 *)(pci_config_base + (addr & ~3));
+	int i=0;
+	for(i=0;i<4;i++)
+		p[i] = (data >> (i<<3)) & 0xff;
+}
+#endif
+
+/*
+ * Low-level HT Configuration READ and Write Routines
+ */
+static inline __u32 ht_cfg_read_32bit(unsigned long addr) {
+
+    __u8 *p;
+    __u32 temp = 0;
+    __u64 cerr_cpu_log = 0;
+
+    disable_and_clear_cache_error();
+    p = (__u8 *)((addr & ~3));
+    //printk("[%s]: addr = %p, data = %x\n", __FUNCTION__, p, *(__u32*)p);
+    temp =  ( (*(p+3) << 24) | (*(p+2) << 16) | (*(p+1) << 8) | *p);
+
+    cerr_cpu_log = read_64bit_phnx_ctrl_reg(CPU_BLOCKID_LSU, LSU_CERRLOG_REGID);
+
+    if(cerr_cpu_log) {
+        /* Device doesn't exist. */
+        temp = ~0x0;
+    }
+    clear_and_enable_cache_error();
+    return temp;
+}
+
+static inline void ht_cfg_write_32bit(unsigned long addr, __u32 data) {
+
+    __u8 *p;
+    int i=0;
+    p = (__u8 *)((addr & ~3));
+
+    for(i=0;i<4;i++)
+        p[i] = (data >> (i<<3)) & 0xff;
+}
+/*
+ * HT Wrapper Routine: READ
+ */
+static int phoenix_htbios_read(struct pci_bus *bus, unsigned int devfn,
+                               int where, int size, u32 * val)
+{
+	__u32 data = 0;
+	unsigned long long int cfgaddr;
+
+	/* Keep track of where the PCIX
+	 * bus numbering starts from..
+	 */
+	if (!ht_start_bus_fixed) {
+		ht_start_busno     = (int)(bus->number);
+		ht_start_bus_fixed = 1;
+	}
+
+	if ((size == 2) && (where & 1))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+	else if ((size == 4) && (where & 3))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+
+	cfgaddr = (long) ht_config_base +
+		CFGTYPE(bus->number - ht_start_busno) * MB16 +
+		pci_cfg_offset((int)(bus->number-ht_start_busno),devfn,where);
+
+	if (pci_bus_status)
+		data = ht_cfg_read_32bit(cfgaddr);
+	else
+		data = 0xFFFFFFFF;
+
+	if (size == 1)
+		*val = (data >> ((where & 3) << 3)) & 0xff;
+	else if (size == 2)
+		*val = (data >> ((where & 3) << 3)) & 0xffff;
+	else
+		*val = data;
+
+	return PCIBIOS_SUCCESSFUL;
+}
+/*
+ * HT Wrapper Routine: WRITE
+ */
+static int phoenix_htbios_write(struct pci_bus *bus, unsigned int devfn,
+                                int where, int size, u32 val)
+{
+	unsigned long long int cfgaddr;
+	//    __u32 cfgaddr = pci_cfg_offset(bus->number , devfn, where);
+	__u32 data = 0;
+
+	if ((size == 2) && (where & 1))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+	else if ((size == 4) && (where & 3))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+
+	if (!pci_bus_status)
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+
+	cfgaddr = (long) ht_config_base +
+		CFGTYPE(bus->number - ht_start_busno) * MB16 +
+		pci_cfg_offset((bus->number-ht_start_busno),devfn,where);
+
+
+	data = ht_cfg_read_32bit(cfgaddr);
+
+	if (size == 1)
+		data = (data & ~(0xff << ((where & 3) << 3))) |
+			(val << ((where & 3) << 3));
+	else if (size == 2)
+		data = (data & ~(0xffff << ((where & 3) << 3))) |
+			(val << ((where & 3) << 3));
+	else
+		data = val;
+
+	ht_cfg_write_32bit(cfgaddr, data);
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+static int phoenix_pcibios_read(struct pci_bus *bus, unsigned int devfn,
+				int where, int size, u32 * val)
+{
+	__u32 data = 0;
+
+	/* Keep track of where the PCIX
+	 * bus numbering starts from..
+	 */
+	if (!pci_start_bus_fixed) {
+		pci_start_busno     = (int)(bus->number);
+		pci_start_bus_fixed = 1;
+	}
+
+	if ((size == 2) && (where & 1))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+	else if ((size == 4) && (where & 3))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+
+	if (pci_bus_status)
+		data = pci_cfg_read_32bit(pci_cfg_offset((bus->number-pci_start_busno), devfn, where));
+	else
+		data = 0xFFFFFFFF;
+
+	if (size == 1)
+		*val = (data >> ((where & 3) << 3)) & 0xff;
+	else if (size == 2)
+		*val = (data >> ((where & 3) << 3)) & 0xffff;
+	else
+		*val = data;
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+static int phoenix_pcibios_write(struct pci_bus *bus, unsigned int devfn,
+				 int where, int size, u32 val)
+{
+	__u32 cfgaddr = pci_cfg_offset((bus->number-pci_start_busno), devfn, where);
+	__u32 data = 0;
+
+	if ((size == 2) && (where & 1))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+	else if ((size == 4) && (where & 3))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+
+	if (!pci_bus_status)
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+
+	data = pci_cfg_read_32bit(cfgaddr);
+
+	if (size == 1)
+		data = (data & ~(0xff << ((where & 3) << 3))) |
+			(val << ((where & 3) << 3));
+	else if (size == 2)
+		data = (data & ~(0xffff << ((where & 3) << 3))) |
+			(val << ((where & 3) << 3));
+	else
+		data = val;
+
+	pci_cfg_write_32bit(cfgaddr, data);
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+struct pci_ops phoenix_pci_ops = {
+	.read  = phoenix_pcibios_read,
+	.write = phoenix_pcibios_write
+};
+
+struct pci_ops phoenix_ht_ops = {
+	.read  = phoenix_htbios_read,
+	.write = phoenix_htbios_write
+};
+
+/*
+ * XLR PCIX Controller
+ */
+static struct resource phoenix_mem_resource = {
+	.name           = "PHOENIX PCI MEM",
+	.start          = 0xd0000000UL,          /* 256MB PCI mem @ 0xd000_0000 */
+	.end            = 0xdfffffffUL,
+	.flags          = IORESOURCE_MEM,
+};
+static struct resource phoenix_io_resource = {
+	.name           = "PHOENIX IO MEM",
+	.start          = 0x10000000UL,         /* 16MB PCI IO @ 0x1000_0000 */
+	.end            = 0x100fffffUL,
+	.flags          = IORESOURCE_IO,
+};
+struct pci_controller phoenix_controller = {
+	.index          = 0,
+	.pci_ops        = &phoenix_pci_ops,
+	.mem_resource   = &phoenix_mem_resource,
+	.io_resource    = &phoenix_io_resource,
+	.io_offset      = 0x00000000UL,
+	.mem_offset     = 0x00000000UL
+};
+
+/*
+ * XLR HT Controller
+ */
+static struct resource phoenix_htmem_resource = {
+	.name           = "PHOENIX HT MEM",
+	.start          = 0xc0000000UL,                 /* 256MB HT mem @ 0xC0000000 */
+	.end            = 0xcfffffffUL,
+	.flags          = IORESOURCE_MEM,
+};
+static struct resource phoenix_htio_resource = {
+	.name           = "PHOENIX HT IO",
+	.start          = 0x14000000UL,                 /* 16MB HT IO @ 0x1400_0000 */
+	.end            = 0x140fffffUL,
+	.flags          = IORESOURCE_IO,
+};
+struct pci_controller phoenix_ht_controller = {
+	.index          = 1,
+	.pci_ops        = &phoenix_ht_ops,
+	.mem_resource   = &phoenix_htmem_resource,
+	.io_resource    = &phoenix_htio_resource,
+	.io_offset      = 0x00000000UL,
+	.mem_offset     = 0x00000000UL
+};
+
+/* I/O routines for IDE on PCI */
+#define pci_ide_phys_to_virt(x) (((x) - (phoenix_io_resource.start)) + (unsigned long)pci_io_base )
+
+inline void rmi_ide_mm_insw(unsigned long port, void *addr, u32 count)
+{
+	unsigned long v_port = pci_ide_phys_to_virt(port);
+	while (count--) {
+		*(u16 *)addr = (__raw_readw(v_port));
+		addr += 2;
+	}
+}
+
+inline void rmi_ide_mm_insl(unsigned long port, void *addr, unsigned int count)
+{
+	unsigned long v_port = pci_ide_phys_to_virt(port);
+	while (count--) {
+		*(u32 *)addr = (__raw_readl(v_port));
+		addr += 4;
+	}
+}
+
+inline void rmi_ide_mm_outsw(unsigned long port, void *addr, unsigned int count)
+{
+	unsigned long v_port = pci_ide_phys_to_virt(port);
+	while (count--) {
+		__raw_writew(*(u16 *)addr, v_port);
+		addr += 2;
+	}
+}
+
+inline void rmi_ide_mm_outsl(unsigned long port, void *addr, unsigned int count)
+{
+	unsigned long v_port = pci_ide_phys_to_virt(port);
+	while (count--) {
+		__raw_writel(*(u32 *)addr, v_port);
+		addr += 4;
+	}
+}
+
+u8 rmi_ide_mm_inb (unsigned long port)
+{
+	return((u8)__raw_readb(pci_ide_phys_to_virt(port)));
+}
+
+u16 rmi_ide_mm_inw (unsigned long port)
+{
+	return ((u16) swab16(__raw_readw(pci_ide_phys_to_virt(port))));
+}
+/* Not part of hwif anymore; remove static declaration */
+u32 rmi_ide_mm_inl (unsigned long port)
+{
+	return ((u32)swab32(__raw_readl(pci_ide_phys_to_virt(port))));
+}
+
+void rmi_ide_mm_outb (u8 value, unsigned long port)
+{
+	__raw_writeb(value, pci_ide_phys_to_virt(port));
+}
+
+static void rmi_ide_mm_outbsync (ide_drive_t *drive, u8 value, unsigned long port)
+{
+	__raw_writeb(value, pci_ide_phys_to_virt(port));
+}
+
+void rmi_ide_mm_outw (u16 value, unsigned long port)
+{
+	__raw_writew(swab16(value), pci_ide_phys_to_virt(port));
+}
+/* Not part of hwif anymore; remove static declaration */
+void rmi_ide_mm_outl (u32 value, unsigned long port)
+{
+	__raw_writel(swab32(value), pci_ide_phys_to_virt(port));
+}
+
+#if 0
+void xlr_hwif_mmiops (ide_hwif_t *hwif)
+{
+	hwif->OUTB      = rmi_ide_mm_outb;
+	hwif->OUTBSYNC  = rmi_ide_mm_outbsync;
+	hwif->OUTW      = rmi_ide_mm_outw;
+	hwif->OUTSW     = rmi_ide_mm_outsw;
+	hwif->OUTSL     = rmi_ide_mm_outsl;
+	hwif->INB       = rmi_ide_mm_inb;
+	hwif->INW       = rmi_ide_mm_inw;
+	hwif->INSW      = rmi_ide_mm_insw;
+	hwif->INSL      = rmi_ide_mm_insl;
+}
+
+EXPORT_SYMBOL(xlr_hwif_mmiops);
+#endif
+
+int __init pcibios_map_irq(const struct pci_dev *dev, u8 slot, u8 pin)
+{
+#if defined(XLP_SIM)
+	return 0;
+#else
+    /* Sane default values for XLR */
+    int index = 0;
+    int retVal= PIC_PCIX_IRQ;    
+
+    if (is_xls() && !is_xls2xx() && !is_xls_b0()) {
+        if (link0) {
+            if (dev->bus->number == 1)
+                return 0x22;
+            else
+                return 0x23;
+        }
+        else if (link1) {
+            if (dev->bus->number == 1)
+                return 0x23;
+        }
+    }else if(is_xls2xx() || is_xls_b0()){
+        if(dev->bus->number>0){
+            switch(dev->bus->self->devfn){
+            case 0x0:
+                return 0x22;
+            case 0x8:
+                return 0x23;
+            case 0x10:
+                if(is_xls_b0())
+                    return 0x24;
+                return 0x1f;
+            case 0x18:
+                if(is_xls_b0())
+                    return 0x25;
+                return 0x20;
+            default:
+                break;
+            }
+        }else 
+            return 0x23;    /*Need to FIX!!!, XLS logic does same.. Or probably
+                             we would never come here with bus number ZERO*/
+    }else{
+        /* XLR */
+        index = ((struct pci_controller *)(dev->sysdata))->index;
+        if(index == 0)
+            /* IRQ Vector 24 for PCI/X Devices */
+            retVal = PIC_PCIX_IRQ;   
+        else if (index == 1)
+            /* IRQ Vector 23 for HT Devices */
+            retVal = PIC_HYPER_IRQ;  
+    }
+    return retVal;
+#endif
+}
+
+/* Do platform specific device initialization at pci_enable_device() time */
+int pcibios_plat_dev_init(struct pci_dev *dev)
+{
+        return 0;
+}
+
+extern int pci_probe_only;
+
+/* Enabled by default */
+static int __initdata phoenix_nopci = 0; 
+
+#if defined(CONFIG_RMI_XLR)
+static int __init xlr_nopci_setup(char *str)
+{
+    /* Disable PCI/X/E; disables HT also */
+	phoenix_nopci = 1;  
+	return 1;
+}
+__setup("xlr_nopci", xlr_nopci_setup);
+#endif
+
+#if defined(CONFIG_RMI_XLP)
+static int __init xlp_nopci_setup(char *str)
+{
+    /* Disable PCI/X/E; disables HT also */
+	phoenix_nopci = 1;  
+	return 1;
+}
+__setup("xlp_nopci", xlp_nopci_setup);
+#endif
+
+extern uint32_t dev_tree_en;
+extern int fdt_get_pci_ht_map(int *pci_enable, int *ht_enable);
+
+static int __init pcibios_init(void)
+{
+	int pci_enable, ht_enable;
+
+	if(dev_tree_en)
+		fdt_get_pci_ht_map(&pci_enable, &ht_enable);
+	else
+		pci_enable = ht_enable = !phoenix_nopci;
+
+	if (!pci_enable && !ht_enable)  {
+		printk("PCI & HT disabled by boot arguments  - skipping.\n");
+		return 0;
+	}
+		
+	if (phoenix_nopci || xlr_board_atx_iii() || xlr_board_atx_v()) 
+        return 0;
+
+    if(is_xls_b0() && is_xlsb0_srio()){
+        printk("Detected XLS B0 in SRIO Mode, Skipping PCIE\n");
+        return 0;
+    }
+    
+	/* PSB assigns PCI resources */
+	pci_probe_only = 1;
+
+	/* Map the PCIX CFG space */
+	if(pci_enable) {
+		pci_config_base = ioremap(DEFAULT_PCI_CONFIG_BASE, (32<<20));
+		if (!pci_config_base) {
+			printk("Unable to map PCI config space!\n");
+			return 1;
+		}
+
+
+		{
+			unsigned long phys = phoenix_io_resource.start;
+			unsigned long size = phoenix_io_resource.end - phoenix_io_resource.start + 1;
+
+			pci_io_base = ioremap(phys, size);
+			if (!pci_io_base) {
+				printk("[%s]: Unable to IO-Remap phys=%lx, size=%lx\n",
+			       __FUNCTION__, phys, size);
+			}
+			else {
+				printk("[%s]: IO-Remapped phys=%lx, size=%lx to vaddr=%p\n",
+			       __FUNCTION__, phys, size, pci_io_base);
+			}
+		}
+	}
+	
+	if(ht_enable) {
+		/* Map the HT CFG spaces... */
+		ht_config_base = ioremap(DEFAULT_HT_TYPE0_CFG_BASE, (32<<20));
+		if (!ht_config_base) {
+			printk("Unable to map HT config space!\n");
+			return 1;
+		}
+
+		{
+			unsigned long phys = phoenix_htio_resource.start;
+			unsigned long size = phoenix_htio_resource.end - phoenix_htio_resource.start + 1;
+
+			ht_io_base = ioremap(phys, size);
+			if (!ht_io_base) {
+				printk("[%s]: Unable to IO-Remap phys=%lx, size=%lx\n",
+			       __FUNCTION__, phys, size);
+			}
+			else {
+				printk("[%s]: IO-Remapped phys=%lx, size=%lx to vaddr=%p\n",
+			       __FUNCTION__, phys, size, ht_io_base);
+			}
+		}
+	}
+
+	pci_bus_status = 1;
+	pci_start_bus_fixed = 0;
+	ht_start_bus_fixed = 0;
+
+	/* IO Range for 16MB from where the MEM Range Ends */
+	ioport_resource.start =  0;
+	ioport_resource.end   = ~0;
+	if(pci_enable) {
+	    printk("Registering XLR/XLS PCIX/PCIE Controller. \n");
+    	if (is_xls())
+        	pcie_controller_init_done();
+	    register_pci_controller(&phoenix_controller);
+	}
+
+    /* XLS : No native HT */
+    if (ht_enable && !is_xls()) {
+        /* XLR : ATX1, ATX2B Boards */
+        if ((xlr_board_atx_i() || xlr_board_atx_ii_b()) && ht_controller_init_done()) {
+            printk("Registering XLR HT Controller. \n");
+            register_pci_controller(&phoenix_ht_controller);
+        }
+    }
+	return 0;
+}
+
+#if 0
+void __iomem *pci_iomap(struct pci_dev *dev, int bar, unsigned long max)
+{
+	unsigned long start = pci_resource_start(dev, bar);
+	unsigned long len = pci_resource_len(dev, bar);
+	unsigned long flags = pci_resource_flags(dev, bar);
+
+	if (!len)
+		return NULL;
+	if (max && len > max)
+		len = max;
+#if 0
+	if (flags & IORESOURCE_IO)
+		return ioport_map(start, len);
+#endif
+	if (flags & IORESOURCE_MEM)
+		return ioremap(start, len);
+	/* What? */
+	return NULL;
+}
+
+
+void pci_iounmap(struct pci_dev *dev, void __iomem *addr)
+{
+	/* Nothing to do */
+}
+#endif
+
+arch_initcall(pcibios_init);
+
+struct pci_fixup pcibios_fixups[] = {
+	{0}
+};
+
diff --git a/arch/mips/pci/pci-xlp.c b/arch/mips/pci/pci-xlp.c
new file mode 100644
index 0000000..ec6a76b
--- /dev/null
+++ b/arch/mips/pci/pci-xlp.c
@@ -0,0 +1,241 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/types.h>
+#include <linux/pci.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/mm.h>
+#include <linux/console.h>
+#include <linux/ide.h>
+
+#include <asm/io.h>
+
+#include <asm/rmi/interrupt.h>
+#include <asm/rmi/pci.h>
+#include <asm/rmi/io.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/sim.h>
+
+extern int pci_probe_only;
+
+static void *pci_config_base;
+static void *pci_io_base;
+
+#define SWAP32(x)				\
+        (((x) & 0xff000000) >> 24) |		\
+        (((x) & 0x000000ff) << 24) |		\
+        (((x) & 0x0000ff00) << 8)  |		\
+        (((x) & 0x00ff0000) >> 8)
+
+static void pcie_controller_init_done(void)
+{
+	/* XLP_MERGE_TODO */
+	printk("[%s]: PCIE Controller initialization to be done\n", __FUNCTION__);
+	return;
+}
+
+static inline __u32 pci_cfg_read_32bit(__u32 addr)
+{
+	__u32 temp = 0;
+	__u32 *p = (__u32 *) (pci_config_base + (addr & ~3));
+
+	temp = *p;
+
+	return temp;
+}
+
+static inline void pci_cfg_write_32bit(__u32 addr, __u32 data)
+{
+        unsigned int *p = (unsigned int *)(pci_config_base + (addr & ~3));
+
+	*p = data;
+}
+
+static int pci_bus_status = 0;
+#define pci_cfg_offset(bus, devfn, where) (((bus)<<16)+((devfn)<<8)+(where))
+#define pci_cfg_addr(bus, devfn, where) pci_cfg_offset((bus)->number,(devfn),where)
+
+static int xlp_pcibios_read(struct pci_bus *bus, unsigned int devfn,
+				int where, int size, u32 * val)
+{
+	__u32 data = 0;
+
+	if ((size == 2) && (where & 1))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+	else if ((size == 4) && (where & 3))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+
+	if (pci_bus_status)
+		data = pci_cfg_read_32bit(pci_cfg_offset((bus->number), devfn, where));
+	else
+		data = 0xFFFFFFFF;
+
+	if (size == 1)
+		*val = (data >> ((where & 3) << 3)) & 0xff;
+	else if (size == 2)
+		*val = (data >> ((where & 3) << 3)) & 0xffff;
+	else
+		*val = data;
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+static int xlp_pcibios_write(struct pci_bus *bus, unsigned int devfn,
+				 int where, int size, u32 val)
+{
+	__u32 cfgaddr = pci_cfg_offset((bus->number), devfn, where);
+	__u32 data = 0;
+
+	if ((size == 2) && (where & 1))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+	else if ((size == 4) && (where & 3))
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+
+	if (!pci_bus_status)
+		return PCIBIOS_BAD_REGISTER_NUMBER;
+
+	data = pci_cfg_read_32bit(cfgaddr);
+
+	if (size == 1)
+		data = (data & ~(0xff << ((where & 3) << 3))) |
+			(val << ((where & 3) << 3));
+	else if (size == 2)
+		data = (data & ~(0xffff << ((where & 3) << 3))) |
+			(val << ((where & 3) << 3));
+	else
+		data = val;
+
+	pci_cfg_write_32bit(cfgaddr, data);
+
+	return PCIBIOS_SUCCESSFUL;
+}
+
+static struct pci_ops xlp_pci_ops = {
+	.read  = xlp_pcibios_read,
+	.write = xlp_pcibios_write
+};
+
+/*
+ * XLP PCIE Controller
+ */
+#define DEFAULT_XLP_PCI_CONFIG_BASE 0x1c000000UL
+static struct resource xlp_mem_resource = {
+	.name           = "XLP PCI MEM",
+	.start          = 0xd0000000UL,          /* 256MB PCI mem @ 0xd000_0000 */
+	.end            = 0xdfffffffUL,
+	.flags          = IORESOURCE_MEM,
+};
+static struct resource xlp_io_resource = {
+	.name           = "XLP IO MEM",
+	.start          = 0x10000000UL,         /* 16MB PCI IO @ 0x1000_0000 */
+	.end            = 0x100fffffUL,
+	.flags          = IORESOURCE_IO,
+};
+struct pci_controller xlp_controller = {
+	.index          = 0,
+	.pci_ops        = &xlp_pci_ops,
+	.mem_resource   = &xlp_mem_resource,
+	.io_resource    = &xlp_io_resource,
+	.io_offset      = 0x00000000UL,
+	.mem_offset     = 0x00000000UL
+};
+
+int __init pcibios_map_irq(const struct pci_dev *dev, u8 slot, u8 pin)
+{
+	return 0;
+}
+
+/* Do platform specific device initialization at pci_enable_device() time */
+int pcibios_plat_dev_init(struct pci_dev *dev)
+{
+        return 0;
+}
+
+/* Enabled by default */
+static int __initdata xlp_nopci = 0;
+
+static int __init xlp_nopci_setup(char *str)
+{
+	/* Disable PCI/X/E; disables HT also */
+	xlp_nopci = 1;
+
+	return 1;
+}
+__setup("xlp_nopci", xlp_nopci_setup);
+
+static int __init pcibios_init(void)
+{
+	unsigned long phys = 0;
+	unsigned long size = 0;
+
+	if (xlp_nopci) return 0;
+
+	/* Bootloader assigns PCI resources */
+	pci_probe_only = 1;
+
+	/* Map the PCIX CFG space */
+	pci_config_base = ioremap(DEFAULT_XLP_PCI_CONFIG_BASE, (32<<20));
+	if (!pci_config_base) {
+		printk("Unable to map PCI config space!\n");
+		return 1;
+	}
+
+	phys = xlp_io_resource.start;
+	size = xlp_io_resource.end - xlp_io_resource.start + 1;
+
+	pci_io_base = ioremap(phys, size);
+	if (!pci_io_base) {
+		printk("[%s]: Unable to IO-Remap phys=%lx, size=%lx\n",
+		       __FUNCTION__, phys, size);
+	}
+	else {
+		printk("[%s]: IO-Remapped phys=%lx, size=%lx to vaddr=%p\n",
+		       __FUNCTION__, phys, size, pci_io_base);
+	}
+
+	/* IO Range for 16MB from where the MEM Range Ends */
+	ioport_resource.start =  0;
+	ioport_resource.end   = ~0;
+
+	printk("Registering XLP PCIE Controller. \n");
+	pcie_controller_init_done();
+	register_pci_controller(&xlp_controller);
+
+	pci_bus_status = 1;
+	return 0;
+}
+
+arch_initcall(pcibios_init);
+
+struct pci_fixup pcibios_fixups[] = {
+	{0}
+};
+
diff --git a/arch/mips/rmi/Kconfig b/arch/mips/rmi/Kconfig
new file mode 100644
index 0000000..4347e16
--- /dev/null
+++ b/arch/mips/rmi/Kconfig
@@ -0,0 +1,199 @@
+config RMI_PHOENIX
+	bool 
+
+config RMI_XLR
+	bool
+
+config RMI_XLP
+	bool
+
+config PHOENIX_VM_DEBUG
+	bool "Debug VM System"
+	depends on RMI_PHOENIX
+	default n
+
+config PHOENIX_USERSEGV_DEBUG
+	bool "Debug User process SEGV crash"
+	depends on RMI_PHOENIX
+	default n
+
+config PHOENIX_SMP_PREFIX
+	bool "Prefix the cpu number for every printk"
+	depends on RMI_PHOENIX
+	default y
+
+config PHOENIX_GLOBAL_TLB_SPLIT_ASID
+        bool "Enable Shared TLB in each CPU core"
+	depends on RMI_PHOENIX
+	default n
+	help
+		This option enables the sharing of TLBs by all the threads in core.
+		
+
+config PHOENIX_MAC
+	bool "Enable On-Chip Networking support"
+	depends on RMI_XLR
+	default y
+
+config PHOENIX_PCIX_GEN_DRIVER
+	bool
+
+config PHOENIX_IP_OVER_PCI
+        bool "Enable IP-Over-Pci Networking Support"
+        depends on RMI_XLR
+	select PHOENIX_PCIX_GEN_DRIVER
+        default n
+
+config PHOENIX_BOOT_OVER_PCI
+        bool "Enable Boot-Over-Pci Support"
+        depends on RMI_XLR
+	select PHOENIX_PCIX_GEN_DRIVER
+        default n
+
+config PHOENIX_CONSOLE_OVER_PCI 
+        bool "Enable Console Over PCI Support"
+        depends on RMI_XLR
+	select PHOENIX_PCIX_GEN_DRIVER
+        default n
+
+config PHOENIX_SPI4
+        bool 'Support for on-chip SPI4 interfaces'
+        depends on RMI_XLR
+        default y
+        help
+          With the Vitesse SPI4 daughter card, this driver will abstract the
+          20 SPI4 channels as Gigabit ethernet interfaces.
+
+config PHOENIX_PSB
+	bool "Enable support for ATX eval board bootloader"
+
+config PHOENIX_MSGRING_NAPI
+	bool "XLR/XLS message ring NAPI"
+	depends on RMI_XLR
+	default y
+	help
+	  NAPI is a new driver API designed to reduce CPU and interrupt load
+	  when the driver is receiving lots of packets. This option enables 
+	  NAPI implementation for XLR/XLS message ring receive path.
+
+	  See <file:Documentation/networking/NAPI_HOWTO.txt> for more
+	  information.
+
+	  If in doubt, say N.
+
+
+config PHOENIX_HW_BUFFER_MGMT
+	bool "Enable support for network buffer recycling via hardware"
+	depends on RMI_XLR
+	default y
+	help
+	  Experimental addition to GMAC functionality allowing "recycling" of 
+          packet buffers by requesting HW to queue free elements upon Tx-complete 
+          back to the Rx free list.
+          This type of performance ehancement is important to forwarder-like
+          applications where fast path should stay as lean as possible.
+
+	  If in doubt, say N.
+
+
+config PHOENIX_IP_FLOW_AFFINITY
+	bool "Enable support for IP flow affinity"
+	depends on RMI_XLR
+	default n
+	help
+	  Experimental feature of GMAC driver guranteeing that IP flows are processed 
+          on logical CPUs corresponding to buckets assigned by packet classifier engine.
+          E.g. for XLR core #X, packets arriving to buckets 0 & 4 are processed by thread 0,
+          packets arriving to buckets 1 & 5 are processed by thread 1 and so on..
+          Such feature might be important for applications which require IP flows 
+          be seen on one logcal CPUs. Use of this feature involves performance cost.
+
+	  If in doubt, say N.
+
+config PHOENIX_IP_QUEUE_AFFINITY
+	bool "Enable multiprocess support for IP Queues"
+	depends on RMI_XLR && IP_NF_QUEUE
+	default n
+	help
+	  Experimental feature extending IP Queues by allowing multiple user space 
+          processes to receive IP packets from the kernel. Client processes should come 
+          with CPU affinity set to single logical CPU and will get packets which are 
+          recieved and processed by network stack on that logical CPU.
+
+          Example:
+
+               Let's Process_1 has CPU affinity set to x
+               Let's Process_2 has CPU affinity set to y
+
+               Packet1 --> Interrupt on CPU x --> IP Queues --> Process_1
+               Packet1 --> Interrupt on CPU y --> IP Queues --> Process_2
+
+          This feature could be useful for packet processing architectures requiring user 
+          space handling of multiple IP flows.
+
+          If in doubt, say N.
+
+config MAPPED_KERNEL
+       bool "Mapped kernel" 
+       default y
+       help
+         Select this option if you want the kernel's code and data to 
+         be in mapped memory.  The kernel will be mapped using a 
+         single wired TLB entry, thus reducing the number of
+         available TLB entries by one.  Kernel modules will be able 
+         to use a more efficient calling convention.
+
+config PHYS_LOAD_ADDRESS
+       hex "Physical load address"
+       depends on MAPPED_KERNEL
+       default 0xffffffff84000000
+       help
+         The physical load address reflected as the program header
+         physical address in the kernel ELF image.
+
+config RMI_PHOENIX_LOAD_ADDRESS
+	hex "RMI Linux kernel start address"
+	depends on RMI_PHOENIX
+	default "0xffffffffc4000000"
+	help
+	  This is start address for the linux kernel. Default value
+          should be good for most of the applications unless specified 
+          explicitly: e.g. running RMI ToE requires kernel to be linked
+	  at address 0xffffffff86000000.
+ 
+config PHOENIX_PTP_SUPPORT
+	bool "1588PTP Support(enables prepad)"
+	depends on RMI_PHOENIX
+	default n
+	help
+	 Support for 1588 timing feature. Timestamps Rx/Tx packets. 
+         
+config RMI_VMIPS
+	bool "Virtual Mips support"
+	depends on RMI_PHOENIX
+	default n
+	help
+	 The kseg0 and kseg1 unmapped access will become mapped. 
+
+config KSEG2_LOWMEM
+       bool "Mapped Lowmem"
+       depends on MAPPED_KERNEL && 64BIT
+       default y
+
+config RMI_NAS
+	bool "Enable NAS optimizations"
+	depends on RMI_PHOENIX
+	default n
+	help
+	  This options enables some optimizations done for XLS NAS solutions
+
+config READ_INHIBIT
+       bool "Enable Read Inhibit Semantics"
+       depends on RMI_XLP
+       default n
+
+config EXEC_INHIBIT
+       bool "Enable Exec Inhibit Semantics"
+       depends on RMI_XLP
+       default n
+
diff --git a/arch/mips/rmi/boot/Makefile b/arch/mips/rmi/boot/Makefile
new file mode 100644
index 0000000..3fceae5
--- /dev/null
+++ b/arch/mips/rmi/boot/Makefile
@@ -0,0 +1,3 @@
+obj-y  = boot.o bootloader.o
+
+EXTRA_AFLAGS := $(CFLAGS)
diff --git a/arch/mips/rmi/boot/Makefile.standalone b/arch/mips/rmi/boot/Makefile.standalone
new file mode 100644
index 0000000..c5d7964
--- /dev/null
+++ b/arch/mips/rmi/boot/Makefile.standalone
@@ -0,0 +1,36 @@
+ARCH = mips
+CROSS_COMPILE = mips-linux-
+TOP_DIR = ../../../..
+
+CC = $(CROSS_COMPILE)gcc
+LD = $(CROSS_COMPILE)ld
+AS = $(CROSS_COMPILE)as
+
+CC_DEFINES = -D__BOOT_STANDALONE__
+ifeq "$ARCH" "mips"
+CC_ARCH_OPTIONS = -mcpu=r5000 -mips2 -Wa,--trap
+else
+CC_ARCH_OPTIONS = -mcpu=r8000 -mips4 -Wa,--trap
+endif
+CC_OPTIONS = -g3 -Wall -Werror -G 0 -mno-abicalls -fno-pic -pipe $(CC_ARCH_OPTIONS)
+LINKFLAGS = -T ./ld.script.standalone -e 0xbfc00000
+
+all: boot.o bootloader.o ld.script.standalone
+	$(LD) $(LINKFLAGS) boot.o bootloader.o -o boot
+
+boot.o: boot.S
+	$(CC) $(CC_OPTIONS) $(CC_DEFINES) -c -o boot.o boot.S
+
+bootloader.o: bootloader.c
+	$(CC) $(CC_OPTIONS) $(CC_DEFINES) -c -o bootloader.o bootloader.c
+
+printb.o: printb.c
+	$(CC) $(CC_OPTIONS) $(CC_DEFINES) -c -o printb.o printb.c	
+
+install: dummy
+	cp -f ./boot $(TOP_DIR)
+
+clean: dummy
+	rm -rf *.o *~ ./boot
+
+dummy:
diff --git a/arch/mips/rmi/boot/boot.S b/arch/mips/rmi/boot/boot.S
new file mode 100644
index 0000000..a61b880
--- /dev/null
+++ b/arch/mips/rmi/boot/boot.S
@@ -0,0 +1,69 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ ******************************#RMI_2#**********************************/
+
+#include "bootloader.h"
+	
+	.section .boot.text, "ax"
+
+	.set push
+	.set noreorder
+	.set mips32
+		
+	EXPORT(_boot)
+
+	la    $29, BOOT_STACK_POINTER
+	la    $28, BOOT_SMP_INFO_ADDR
+	
+	/* Read the cpuid, thrid from the cp0 config register */
+	mfc0  $8, $16, 7
+	srl   $4, $8, 4
+	andi  $4, $4, 0x3f
+	andi  $5, $8, 0xf
+	
+	jal   boot_cpu
+	nop
+
+	b     hang
+	nop
+	
+	.globl	exec_elf
+	.type	exec_elf,@function
+exec_elf:
+	jalr $16
+	nop
+
+hang:
+1:	b    1b
+	nop
+	
+	nop
+	
+	
+	.set pop
diff --git a/arch/mips/rmi/boot/bootloader.c b/arch/mips/rmi/boot/bootloader.c
new file mode 100644
index 0000000..e0ddadd
--- /dev/null
+++ b/arch/mips/rmi/boot/bootloader.c
@@ -0,0 +1,138 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include "bootloader.h"
+
+#define __boot_text  __attribute__ ((section (".boot.text")))
+#define __boot_data  __attribute__ ((section (".boot.data")))
+#define __boot_stack __attribute__ ((section (".boot.stack")))
+
+typedef struct boot_smp_info_struct_s {
+  volatile unsigned long ready;
+  volatile unsigned long sp;
+  volatile unsigned long gp;
+  volatile unsigned long fn;
+} boot_smp_info_struct;
+
+extern int printb(const char *fmt, ...);
+
+static inline void __boot_text jump_address(unsigned long entry)
+{
+  asm volatile (
+		".set push         \n"
+		".set noreorder    \n"
+		"     jalr  %0     \n"
+		"     nop          \n"
+		
+		".set pop          \n"
+		:
+		: "r" (entry)
+		);
+}
+
+static inline void __boot_text write_sp(unsigned long value) 
+{
+   asm volatile ("or $29, %0, %0" : : "r" (value));
+}
+
+static inline void __boot_text write_gp(unsigned long value)
+{
+   asm volatile ("or $28, %0, %0" : : "r" (value));
+}
+
+static inline void __boot_text set_bit(int nr, volatile void *addr)
+{
+	unsigned long *m = ((unsigned long *) addr) + (nr >> 5);
+	unsigned long temp;
+
+	__asm__ __volatile__(
+		"1:\tll\t%0, %1\t\t# set_bit\n\t"
+		"or\t%0, %2\n\t"
+		"sc\t%0, %1\n\t"
+		"beqz\t%0, 1b"
+		: "=&r" (temp), "=m" (*m)
+		: "ir" (1UL << (nr & 0x1f)), "m" (*m));
+}
+
+extern void kernel_entry(void);
+
+void __boot_text boot_cpu(int cpuid, int thrid) 
+{
+  /* elf_entry is obtained from the elf executable that the bootloader
+   * loads. For now, since it is being linked with vmlinux, just use
+   * kernel_entry symbol directly
+   */
+  unsigned int status = 0;
+  unsigned int temp = 0;
+  int cpu = (cpuid << 2) + thrid;
+  unsigned long elf_entry = (unsigned long) &kernel_entry;
+  boot_smp_info_struct *boot_smp_info = 
+    (boot_smp_info_struct *)BOOT_SMP_INFO_ADDR + cpu;
+
+  if (cpuid >= 8 || thrid >= 4) 
+    while (1);
+
+  
+  set_bit(cpu, (void *)BOOT_CPU_MAP_ADDR);
+  
+  if (cpu == 0) {
+    __asm__ volatile (
+		      ".set push \n"
+		      ".set noreorder\n"
+		      " or $16, $0, %0\n"
+		      ".set pop \n"
+		      : : "r" (elf_entry) : "$16");
+    exec_elf(0, 0, 0, BOOT_CPU_MAP_ADDR);
+  }
+  else {
+    boot_smp_info->ready = 0;
+      
+    __asm__ volatile ("mfc0 %0, $12" : "=r" (status));
+    /* disable interrupts and enable cp2 */
+    temp = (status & ~0x1) | (0x40000000);
+    __asm__ volatile ("mtc0 %0, $12" : : "r" (temp));
+    
+    do {
+      __asm__ volatile (
+			".set push\n"
+			".set noreorder\n"
+			"c2 0x3\n"
+			"c2 0x2\n"
+			".set pop\n"
+			);
+    }while(boot_smp_info->ready == 0);
+    
+    __asm__ volatile ("mtc0 %0, $12" : : "r" (status));
+
+    write_sp(boot_smp_info->sp);
+    write_gp(boot_smp_info->gp);
+    jump_address(boot_smp_info->fn);
+  }
+}
diff --git a/arch/mips/rmi/boot/bootloader.h b/arch/mips/rmi/boot/bootloader.h
new file mode 100644
index 0000000..673f5c8
--- /dev/null
+++ b/arch/mips/rmi/boot/bootloader.h
@@ -0,0 +1,46 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _BOOTLOADER_H
+#define _BOOTLOADER_H
+
+#define BOOT_SMP_INFO_ADDR   0x9F500000
+#define BOOT_CPU_MAP_ADDR    0x9F501000
+#define BOOT_STACK_POINTER   0x9F600000
+
+#define CP0_PRID $15
+
+#define EXPORT(symbol)                          \
+               .globl symbol;                   \
+symbol:
+
+#define BOOT_CPU_ONLINE_MAP  0x0f
+
+#endif
diff --git a/arch/mips/rmi/boot/ld.script.standalone b/arch/mips/rmi/boot/ld.script.standalone
new file mode 100644
index 0000000..06020ac
--- /dev/null
+++ b/arch/mips/rmi/boot/ld.script.standalone
@@ -0,0 +1,16 @@
+OUTPUT_ARCH(mips)
+SECTIONS
+{
+  .boot.text  0xbfc00000 : AT (0x1fc00000)
+  {
+        *(.boot.text)   
+  }
+  .boot.data  0xbf500000 : AT (0x1f500000)
+  {
+        *(.boot.data)   
+  }
+  .boot.stack 0xbf600000 : AT (0x1f600000)
+  {
+        *(.boot.stack)  
+  }
+}
diff --git a/arch/mips/rmi/mm/Makefile b/arch/mips/rmi/mm/Makefile
new file mode 100644
index 0000000..4af77ca
--- /dev/null
+++ b/arch/mips/rmi/mm/Makefile
@@ -0,0 +1 @@
+obj-y += memory.o
diff --git a/arch/mips/rmi/mm/memory.c b/arch/mips/rmi/mm/memory.c
new file mode 100644
index 0000000..b4c3dc6
--- /dev/null
+++ b/arch/mips/rmi/mm/memory.c
@@ -0,0 +1,167 @@
+#include <linux/irqflags.h>
+#include <asm/mipsregs.h>
+#include <asm/page.h>
+#include <asm/mach-rmi/mmu.h>
+
+/*
+ * the following structures and definitions are internal to this
+ * file and hence not defined in a header file
+ */
+typedef struct
+{
+	unsigned int size;
+	unsigned int mask;
+} tlbparam_t;
+
+tlbparam_t mipstlbs[] = 
+{ {  4 << 10,    0x0},
+  { 16 << 10,    0x3},
+  { 64 << 10,    0xf},
+  {256 << 10,   0x3f},
+  {  1 << 20,   0xff},
+  {  4 << 20,  0x3ff},
+  { 16 << 20,  0xfff},
+  { 64 << 20, 0x3fff},
+  {256 << 20, 0xffff},
+};
+
+#define NTLB (sizeof(mipstlbs)/sizeof(tlbparam_t))
+#define ULL unsigned long long
+#define PCIDEV_ADDRSPACE_START (0x3ULL << 30)
+
+static uint32_t align_size(uint32_t size)
+{
+	int i;
+
+	for (i = 0; (i < NTLB - 1) && (size > mipstlbs[i].size); ++i)
+		;
+	return mipstlbs[i].size;
+}
+
+static uint32_t tlb_mask(uint32_t size)
+{
+	int i;
+
+	size = align_size(size);
+
+	for (i = 0; i < NTLB && mipstlbs[i].size != size; ++i)
+		;
+	return mipstlbs[i].mask;
+}
+
+#define entrylo(paddr, attr) \
+	((((paddr & 0xffffffffffULL) >> 12) << 6) | (attr))
+
+
+/*
+ * External Function / APIs
+ */
+
+void setup_tlb(tlb_info_t *tlb)
+{
+	write_c0_pagemask(tlb_mask(tlb->pagesize) << 13);
+	write_c0_entryhi(tlb->vaddr & ~0x1fff);
+	write_c0_entrylo0(entrylo(tlb->paddr0, tlb->attr0));
+	write_c0_entrylo1(entrylo(tlb->paddr1, tlb->attr1));
+
+	if (tlb->wired) {
+		write_c0_index(read_c0_wired());
+		tlb_write_indexed();
+		write_c0_wired(read_c0_wired() + 1);
+	}
+	else {
+		tlb_write_random();
+	}
+}
+
+#ifdef CONFIG_MAPPED_KERNEL
+
+/*
+ * the following initialization is needed for 32-bit
+ * mapped kernels. It must be set 512 MB past the
+ * mapped start kseg2 address (0xc0000000).
+ * 0xc0000000 + 0x20000000(512MB) = 0xe0000000
+ */
+unsigned long __vmalloc_start = 0xe0000000;
+
+#endif
+
+#if defined(CONFIG_KSEG2_LOWMEM) && defined(CONFIG_KSEG2_LOWMEM)
+
+#include <asm/barrier.h>
+
+static volatile int max_low_pfn_set = 0;
+extern unsigned long max_low_pfn;
+
+void setup_mapped_kernel_tlbs(int firstpage, int primary_cpu)
+{
+	tlb_info_t tlb;
+
+    tlb.pagesize = LARGEST_TLBPAGE_SZ; /* we set up the largest pages */
+
+	/*
+	 * In NetLogic's Linux kernel, the second 256MB of physical
+	 * address space is reserved for device configuration and
+	 * is not mapped to DRAM (to imply memory as opposed to IO
+	 * device space). Hence the attribute of the second part of
+	 * the first wired entry is invalid, while the both part of
+	 * other wired entries are symmetric. We handle the above
+	 * difference through the following unseemly if condition
+	 */
+	if (firstpage) {
+		tlb.vaddr = XKSEG;
+		tlb.paddr1 = tlb.paddr0 = 0;
+		tlb.attr0 = ((_CACHE_CACHABLE_COW |_PAGE_DIRTY |  _PAGE_VALID | _PAGE_GLOBAL) >> ENTRYLO_PFN_SHIFT);
+		tlb.attr1 = _PAGE_GLOBAL >> ENTRYLO_PFN_SHIFT;
+		tlb.wired = TRUE;
+		setup_tlb(&tlb);
+	}
+	else {
+		/*
+		 * the primary cpu reads the memory map and records
+		 * the highest page frame number. Secondary cpus
+		 * must wait till the variable max_low_pfn is set
+		 */
+		if (!primary_cpu)
+			while (!max_low_pfn_set)
+				;
+
+		tlb.vaddr = XKSEG + 2 * LARGEST_TLBPAGE_SZ; 
+		tlb.paddr0 = 2 * LARGEST_TLBPAGE_SZ;
+		for (; tlb.paddr0 < (max_low_pfn << PAGE_SHIFT);
+			 tlb.paddr0 += 2 * tlb.pagesize, tlb.vaddr += 2 * tlb.pagesize) {
+			/*
+			 * Skip 3 - 3.5GB range (PCI device space)
+			 */
+			if (tlb.paddr0 == PCIDEV_ADDRSPACE_START)
+				continue;
+			tlb.paddr1 = tlb.paddr0 + tlb.pagesize;
+			tlb.attr1 = tlb.attr0 = ((_CACHE_CACHABLE_COW |_PAGE_DIRTY |  _PAGE_VALID | _PAGE_GLOBAL) >> ENTRYLO_PFN_SHIFT);
+			tlb.wired = TRUE;
+			setup_tlb(&tlb);
+		}
+		if (primary_cpu)
+			__vmalloc_start = tlb.vaddr;
+	}
+}
+
+unsigned long recalculate_max_low_pfn(unsigned long max_low_pfn)
+{
+	/* 
+	 * truncate max_low_pfn to 512MB boundary as largest tlb
+	 * pages are used to minimize the number of wired entries
+	 */
+	if ((max_low_pfn << PAGE_SHIFT) >= (2ULL * LARGEST_TLBPAGE_SZ))
+		max_low_pfn = PFN_DOWN((uint64_t)(max_low_pfn << PAGE_SHIFT) & ~((2ULL * LARGEST_TLBPAGE_SZ) - 1));
+	max_low_pfn_set = TRUE;
+	__sync();
+	
+	return max_low_pfn;
+}
+
+#else
+
+void setup_mapped_kernel_tlbs(int index, int secondary_cpu) { }
+unsigned long recalculate_max_low_pfn(unsigned long max_low_pfn) {return max_low_pfn;}
+
+#endif /* #if defined(CONFIG_KSEG2_LOWMEM) && defined(CONFIG_KSEG2_LOWMEM) */
diff --git a/arch/mips/rmi/phoenix/Makefile.msgring b/arch/mips/rmi/phoenix/Makefile.msgring
new file mode 100644
index 0000000..56f32e2
--- /dev/null
+++ b/arch/mips/rmi/phoenix/Makefile.msgring
@@ -0,0 +1,25 @@
+ifeq ($(objtree),)
+objtree := ../../../../
+endif
+
+include $(objtree)/.config
+
+MSGRNG_CFG = msgring.cfg
+
+MSGRNG_OUT_DIR = $(objtree)/arch/mips/rmi/phoenix
+
+MSGRNG_CFG_C = $(MSGRNG_OUT_DIR)/$(patsubst %.cfg,%.c,$(MSGRNG_CFG))
+
+
+#all: msgring.l msgring.y msgring.cfg
+all: $(MSGRNG_CFG_C)
+
+$(MSGRNG_CFG_C): msgring.l msgring.y $(MSGRNG_CFG)
+	mkdir -p $(MSGRNG_OUT_DIR)
+	flex -o$(MSGRNG_OUT_DIR)/msgring.lex.c msgring.l
+	bison -d -o$(MSGRNG_OUT_DIR)/msgring.yacc.c  msgring.y
+	gcc -g3 $(MSGRNG_OUT_DIR)/msgring.lex.c $(MSGRNG_OUT_DIR)/msgring.yacc.c -o $(MSGRNG_OUT_DIR)/msgring
+	$(MSGRNG_OUT_DIR)/msgring -i $(MSGRNG_CFG) -o $(MSGRNG_CFG_C)
+
+clean:
+	$(RM) $(MSGRNG_OUT_DIR)/msgring.lex.c $(MSGRNG_OUT_DIR)/msgring.yacc.c $(MSGRNG_OUT_DIR)/msgring.yacc.h $(MSGRNG_OUT_DIR)/msgring
diff --git a/arch/mips/rmi/phoenix/Makefile.msgring.shared b/arch/mips/rmi/phoenix/Makefile.msgring.shared
new file mode 100644
index 0000000..aed418d
--- /dev/null
+++ b/arch/mips/rmi/phoenix/Makefile.msgring.shared
@@ -0,0 +1,23 @@
+ifeq ($(objtree),)
+objtree := ../../../../
+endif
+
+include  $(objtree)/.config
+
+MSGRNG_CFG = msgring_shared.cfg
+
+MSGRNG_OUT_DIR = $(objtree)/arch/mips/rmi/phoenix
+
+MSGRNG_CFG_C = $(MSGRNG_OUT_DIR)/$(patsubst %.cfg,%.c,$(MSGRNG_CFG))
+
+all: $(MSGRNG_CFG_C)
+
+$(MSGRNG_CFG_C): msgring_shared.l msgring_shared.y $(MSGRNG_CFG)
+	mkdir -p $(MSGRNG_OUT_DIR)
+	flex -o$(MSGRNG_OUT_DIR)/msgring_shared.lex.c msgring_shared.l
+	bison -d -o$(MSGRNG_OUT_DIR)/msgring_shared.yacc.c  msgring_shared.y
+	gcc -g3 $(MSGRNG_OUT_DIR)/msgring_shared.lex.c $(MSGRNG_OUT_DIR)/msgring_shared.yacc.c -o $(MSGRNG_OUT_DIR)/msgring_shared
+	$(MSGRNG_OUT_DIR)/msgring_shared -i $(MSGRNG_CFG) -o $(MSGRNG_CFG_C)
+
+clean:
+	$(RM) $(MSGRNG_OUT_DIR)/msgring_shared.lex.c $(MSGRNG_OUT_DIR)/msgring_shared.yacc.c $(MSGRNG_OUT_DIR)/msgring_shared.h $(MSGRNG_OUT_DIR)/msgring_shared
diff --git a/arch/mips/rmi/phoenix/Makefile.msgring.xls b/arch/mips/rmi/phoenix/Makefile.msgring.xls
new file mode 100644
index 0000000..232a4ed
--- /dev/null
+++ b/arch/mips/rmi/phoenix/Makefile.msgring.xls
@@ -0,0 +1,24 @@
+ifeq ($(objtree),)
+objtree := ../../../../
+endif
+
+include $(objtree)/.config
+
+MSGRNG_CFG = msgring_xls.cfg
+
+MSGRNG_OUT_DIR = $(objtree)/arch/mips/rmi/phoenix
+
+MSGRNG_CFG_C = $(MSGRNG_OUT_DIR)/$(patsubst %.cfg,%.c,$(MSGRNG_CFG))
+
+
+all: $(MSGRNG_CFG_C)
+
+$(MSGRNG_CFG_C): msgring_xls.l msgring_xls.y $(MSGRNG_CFG)
+	mkdir -p $(MSGRNG_OUT_DIR)
+	flex -o$(MSGRNG_OUT_DIR)/msgring_xls.lex.c msgring_xls.l
+	bison -d -o$(MSGRNG_OUT_DIR)/msgring_xls.yacc.c  msgring_xls.y
+	gcc -g3 $(MSGRNG_OUT_DIR)/msgring_xls.lex.c $(MSGRNG_OUT_DIR)/msgring_xls.yacc.c -o $(MSGRNG_OUT_DIR)/msgring_xls
+	$(MSGRNG_OUT_DIR)/msgring_xls -i $(MSGRNG_CFG) -o $(MSGRNG_CFG_C)
+
+clean:
+	$(RM) $(MSGRNG_OUT_DIR)/msgring_xls.lex.c $(MSGRNG_OUT_DIR)/msgring_xls.yacc.c $(MSGRNG_OUT_DIR)/msgring_xls.yacc.h $(MSGRNG_OUT_DIR)/msgring_xls
diff --git a/arch/mips/rmi/phoenix/cpu_proc.c b/arch/mips/rmi/phoenix/cpu_proc.c
new file mode 100644
index 0000000..db33b08
--- /dev/null
+++ b/arch/mips/rmi/phoenix/cpu_proc.c
@@ -0,0 +1,203 @@
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/poll.h>
+#include <linux/workqueue.h>
+#include <linux/proc_fs.h>
+#include <linux/cpumask.h>
+
+#include <asm/rmi/sim.h>
+#include <asm/rmi/proc.h>
+#include <asm/mach-rmi/mmu.h>
+
+extern struct proc_dir_entry *rmi_root_proc;
+
+#ifndef CONFIG_BTLB_LOADER
+extern void rmi_update_tlb_stats(void *ignored);
+#endif
+
+extern struct psb_info *prom_info;
+
+
+struct xlr_cpu_stat {
+	unsigned long long msgring_pic_int;
+	unsigned long long msgring_int;
+	unsigned long long msgring_cycles;
+	unsigned long long fp_exp;
+	unsigned long long rdhwr_exp;
+};
+
+struct xlr_cpu_stat xlr_cpu_stats[32];
+__u64 xlr_cp2_exceptions[32];
+
+extern unsigned long long phnx_tlb_stats[];
+
+
+void phoenix_cpu_stat_update_rdhwr(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	xlr_cpu_stats[cpu].rdhwr_exp++;
+
+	preempt_enable();
+}
+
+void phoenix_cpu_stat_update_fp(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	xlr_cpu_stats[cpu].fp_exp++;
+
+	preempt_enable();
+}
+
+void phoenix_cpu_stat_update_msgring_int(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	xlr_cpu_stats[cpu].msgring_int++;
+
+	preempt_enable();
+}
+
+void phoenix_cpu_stat_update_msgring_cycles(__u32 cycles)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	xlr_cpu_stats[cpu].msgring_cycles += cycles;
+
+	preempt_enable();
+}
+
+void phoenix_cpu_stat_update_msgring_pic_int(void)
+{
+	int cpu = 0;
+
+	preempt_disable();
+
+	cpu = hard_smp_processor_id();
+	xlr_cpu_stats[cpu].msgring_pic_int++;
+
+	preempt_enable();
+}
+
+static int xlr_cpu_proc_read(char *page, char **start, off_t off,
+			     int count, int *eof, void *data)
+{
+	int i = 0;
+	int len = 0;
+	off_t begin = 0;
+
+#ifndef CONFIG_BTLB_LOADER
+	/* Update the TLB stats from other CPUs */
+	on_each_cpu(rmi_update_tlb_stats, NULL, 1);
+#endif
+
+	len += sprintf(page + len,
+		       "CPU Frequency: %d HZ\n", 
+		       		(unsigned int)prom_info->cpu_frequency);
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	for(i=0;i<32;i++) {
+
+		if (!xlr_cp2_exceptions[i]) continue;
+
+			len += sprintf(page + len,
+				       "cop2_exp: %d %llx\n",
+				       i, (unsigned long long)xlr_cp2_exceptions[i]);
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;
+	}
+
+	for(i=0;i<32;i++) {
+
+		if (!xlr_cpu_stats[i].msgring_pic_int && !xlr_cpu_stats[i].msgring_int)
+			continue;
+
+			len += sprintf(page + len,
+				       "msgring: %d %llx %llx %llx\n",
+				       i, xlr_cpu_stats[i].msgring_pic_int,
+				       xlr_cpu_stats[i].msgring_int,
+				       xlr_cpu_stats[i].msgring_cycles);
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;
+	}
+
+	for(i=0;i<32;i++) {
+
+		if (!xlr_cpu_stats[i].fp_exp && !xlr_cpu_stats[i].rdhwr_exp)
+			continue;
+
+			len += sprintf(page + len,
+				       "cpu_exp: %d %llx %llx\n",
+				       i, xlr_cpu_stats[i].fp_exp,
+				       xlr_cpu_stats[i].rdhwr_exp);
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;
+	}
+
+	for (i = 0; i < 32; i++) {
+
+		if (!phnx_tlb_stats[i])
+			continue;
+
+		len += sprintf(page + len,
+			       "tlb: %d %llx \n",
+			       i, phnx_tlb_stats[i]);
+		if (!proc_pos_check(&begin, &len, off, count))
+			goto out;
+	}
+
+	*eof = 1;
+
+      out:
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;
+}
+
+static int rmi_cpu_proc_init(void)
+{
+	struct proc_dir_entry *entry;
+
+	entry = create_proc_read_entry("xlr_cpu", 0 /* def mode */ ,
+				       rmi_root_proc/* parent */ ,
+				       xlr_cpu_proc_read
+				       /* proc read function */ ,
+				       0	/* no client data */
+		);
+
+	if (!entry) {
+		printk("[%s]: Unable to create proc read entry for xlr_cpu!\n",
+		       __FUNCTION__);
+	}
+
+	return 0;
+}
+
+static void rmi_cpu_proc_exit(void)
+{
+}
+
+module_init(rmi_cpu_proc_init);
+module_exit(rmi_cpu_proc_exit);
diff --git a/arch/mips/rmi/phoenix/dma.c b/arch/mips/rmi/phoenix/dma.c
new file mode 100644
index 0000000..c119526
--- /dev/null
+++ b/arch/mips/rmi/phoenix/dma.c
@@ -0,0 +1,607 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/delay.h>
+
+#include <asm/io.h>
+#include <asm/mipsregs.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/debug.h>
+#include <asm/rmi/sim.h>
+
+#define CH0_CONTROL 8
+#define MSGRNG_CODE_DMA 8
+#define XLR_DMA_RESP_TIMEOUT 500
+#define MAX_DMA_QUEUE_LEN 256
+#define PCIX_ACK_TIMER_VAL 0x18
+
+#define MAX_DMA_TRANS_PER_CPU 256
+#define XLR_MAX_DMA_LEN_PER_DESC ((1 << 20) - 1)	/* 1 MB - 1 */
+
+#define NEXT_SEQ_NUM(x) ((x->sequence_number + 1) & (MAX_DMA_TRANS_PER_CPU - 1))
+#define INC_SEQ_NUM(x) x->sequence_number = \
+		((x->sequence_number + 1) & (MAX_DMA_TRANS_PER_CPU - 1))
+
+#define DMA_SLOT_BUSY(x) (x->trans[x->sequence_number].pending)
+
+#define DMA_RESP_PENDING(x, seq) (x->trans[seq].pending)
+
+#define DMA_SLOT_GET(x) (x->trans[x->sequence_number].pending = 1); \
+				INC_SEQ_NUM(ctrl);
+
+#define DMA_SLOT_PUT(x, seq) (x->trans[seq].pending = 0)
+
+#define DMA_GET_RESP(x, seq) (x->trans[seq].dma_resp)
+
+#define DMA_PUT_RESP(x, seq, msg) x->trans[seq].dma_resp = msg; \
+				x->trans[seq].pending = 0;
+
+#define DMA_DONE(x, seq) (x->trans[seq].pending == 0)
+
+#define Message(a,b...)		//printk("\n[%s] - "a"\n",__FUNCTION__,##b)
+#define ErrorMsg(a,b...) printk("\nError in [%s] - "a"\n",__FUNCTION__,##b)
+enum dma_msgring_bucket_config {
+
+	DMA_MSG_BUCKET0_SIZE = 0x320,
+	DMA_MSG_BUCKET1_SIZE,
+	DMA_MSG_BUCKET2_SIZE,
+	DMA_MSG_BUCKET3_SIZE,
+};
+
+enum dma_msgring_credit_config {
+
+	DMA_CC_CPU0_0 = 0x380,
+	DMA_CC_CPU1_0 = 0x388,
+	DMA_CC_CPU2_0 = 0x390,
+	DMA_CC_CPU3_0 = 0x398,
+	DMA_CC_CPU4_0 = 0x3a0,
+	DMA_CC_CPU5_0 = 0x3a8,
+	DMA_CC_CPU6_0 = 0x3b0,
+	DMA_CC_CPU7_0 = 0x3b8
+};
+
+/* We use 10 bit transaction id in the DMA message to uniquely identify a DMA
+   response.
+   0-7 indicate a sequence number (0 to 255)
+   8-9 bits encode the CPU thread id (0 to 3)
+   */
+typedef struct dma_trans {
+	volatile int pending;
+	uint64_t dma_resp;
+	void (*func) (void *, uint64_t);
+	void *data;
+} dma_trans_t;
+
+typedef struct xlr_dma_ctrl {
+	spinlock_t q_lock;
+	int sequence_number;
+	dma_trans_t trans[MAX_DMA_TRANS_PER_CPU];
+} xlr_dma_ctrl_t;
+
+volatile static int xlr_dma_producer = 0;
+volatile static int xlr_dma_consumer = 0;
+struct msgrng_msg xlr_dma_queue[MAX_DMA_QUEUE_LEN];
+static int xlr_dma_init_done = 0;
+xlr_dma_ctrl_t xlr_dma_ctrl[NR_CPUS];
+
+spinlock_t xlr_dma_lock = SPIN_LOCK_UNLOCKED;
+spinlock_t xlr_enqueue_dma_spin = SPIN_LOCK_UNLOCKED;
+uint32_t xlr_total_dma_reqs, xlr_total_dma_bytes;
+uint32_t xlr_dma_req_failed, xlr_dma_timeout_errors, xlr_dma_errors,
+    xlr_dma_stale_resp;
+uint32_t xlr_dma_msg_send_failed;
+
+void xlr_async_dma_task(unsigned long data);
+extern unsigned int phnx_get_shared_mem_base(void);
+#define CONFIG_PROC_FS 1
+#ifdef CONFIG_PROC_FS
+#include <linux/proc_fs.h>
+
+extern int xlr_loader_own_dma;
+extern struct proc_dir_entry *rmi_root_proc;
+
+static int xlr_dma_proc_read(char *page, char **start, off_t off,
+			     int count, int *eof, void *data)
+{
+	int len, total_len;
+	char *ptr = page;
+
+	if (count < 512)	/* Need minimum of this space */
+		return -EINVAL;
+
+	total_len = 0;
+	len = sprintf(ptr, "Total DMA Requests = %d\n", xlr_total_dma_reqs);
+	ptr += len;
+	total_len += len;
+
+	len = sprintf(ptr, "Total DMA Bytes = %d\n", xlr_total_dma_bytes);
+	ptr += len;
+	total_len += len;
+
+	len = sprintf(ptr, "DMA Requests failed = %d\n", xlr_dma_req_failed);
+	ptr += len;
+	total_len += len;
+
+	len = sprintf(ptr, "DMA Timeout errors = %d\n", xlr_dma_timeout_errors);
+	ptr += len;
+	total_len += len;
+
+	len = sprintf(ptr, "DMA errors = %d\n", xlr_dma_errors);
+	ptr += len;
+	total_len += len;
+
+	len = sprintf(ptr, "DMA Stale responses = %d\n", xlr_dma_stale_resp);
+	total_len += len;
+
+	len = sprintf(ptr, "DMA Message Send Failed = %d\n",
+		      xlr_dma_msg_send_failed);
+	total_len += len;
+
+	return total_len;
+}
+void xlr_init_dma_proc(void)
+{
+	struct proc_dir_entry *entry;
+
+	if (!(entry = create_proc_entry("xlr_dma_stats", 0444, rmi_root_proc))) {
+		printk("%s: create_proc_entry failed\n", __FUNCTION__);
+		return;
+	}
+	entry->read_proc = xlr_dma_proc_read;
+
+}
+void xlr_uninit_dma_proc(void)
+{
+	remove_proc_entry("xlr_dma_stat", rmi_root_proc);
+}
+#endif
+
+/* DMA message handler - Called from interrupt context */
+static void xlr_dma_msgring_handler(int bucket, int size, int code,
+				    int stid, struct msgrng_msg *msg,
+				    void *data /* ignored */ )
+{
+	int cpu, thr_id, tx_id, seq;
+	xlr_dma_ctrl_t *ctrl;
+
+	tx_id = (msg->msg0 >> 48) & 0x3ff;
+	thr_id = (tx_id >> 8) & 0x3;
+	seq = (tx_id & 0xff);
+
+	cpu = (phoenix_cpu_id() * 4) + thr_id;
+	ctrl = &xlr_dma_ctrl[cpu];
+
+	spin_lock(&ctrl->q_lock);
+	/* Check if there was a pending request. This can happen if the
+	   requestor times out and gives up the request. So in that case
+	   do not update the response
+	   NOTE: One corner case that is not handled here is that when seq no
+	   wraps around and request was pending for the new one and this response
+	   was for the old request. This ideally must not happen.
+	 */
+	if (DMA_RESP_PENDING(ctrl, seq)) {
+
+		DMA_PUT_RESP(ctrl, seq, msg->msg0);
+		if (ctrl->trans[seq].func) {
+			ctrl->trans[seq].func(ctrl->trans[seq].data, msg->msg0);
+		}
+		spin_unlock(&ctrl->q_lock);
+		return;
+	}
+	spin_unlock(&ctrl->q_lock);
+	printk("ERROR: Stale response from DMA engine for transaction id %d\n",
+	       seq);
+	spin_lock(&xlr_dma_lock);
+	xlr_dma_stale_resp++;
+	spin_unlock(&xlr_dma_lock);
+	return;
+}
+
+inline void xlr_build_xfer_msg(struct msgrng_msg *msg, uint64_t src,
+			       uint64_t dest, uint32_t len, int tx_id,
+			       int resp_bkt)
+{
+	msg->msg0 = (1ULL << 63) | ((uint64_t) len << 40) |
+	    (src & 0xffffffffffULL);
+	msg->msg1 = (1ULL << 58) | ((uint64_t) tx_id << 48) |
+	    ((uint64_t) resp_bkt << 40) | (dest & 0xffffffffffull);
+
+}
+
+int xlr_enqueue_dma_msg(struct msgrng_msg *msg)
+{
+	unsigned long mflags;
+	spin_lock_irqsave(&xlr_enqueue_dma_spin, mflags);
+	if (((xlr_dma_producer + 1) % (MAX_DMA_QUEUE_LEN)) == xlr_dma_consumer) {
+		//ErrorMsg("DMA Async Queue is full");
+		spin_unlock_irqrestore(&xlr_enqueue_dma_spin, mflags);
+		return -ENOMEM;
+	}
+	//Enqueue Msg 
+	xlr_dma_queue[xlr_dma_producer].msg0 = msg->msg0;
+	xlr_dma_queue[xlr_dma_producer].msg1 = msg->msg1;
+	xlr_dma_queue[xlr_dma_producer].msg2 = 0ULL;
+	xlr_dma_queue[xlr_dma_producer].msg3 = 0ULL;
+	xlr_dma_producer = (xlr_dma_producer + 1) % (MAX_DMA_QUEUE_LEN);
+	spin_unlock_irqrestore(&xlr_enqueue_dma_spin, mflags);
+	return 0;
+}
+
+DECLARE_TASKLET(xlr_dma_task, xlr_async_dma_task, 0);
+void xlr_async_dma_task(unsigned long data)
+{
+	unsigned long flags = 0;
+	int data_len;
+	uint64_t phys1, phys2;
+	struct msgrng_msg *msg;
+	static int last_msg_send_success = 1;
+	int msg_send_success = 0;
+
+	while ((xlr_dma_consumer != xlr_dma_producer)) {
+
+		msg = &xlr_dma_queue[xlr_dma_consumer];
+		phys1 = msg->msg0 & 0xffffffffffULL;	//DEST
+		phys2 = msg->msg1 & 0xffffffffffULL;	//SRC
+		data_len = (msg->msg0 >> 40) & 0xfffff;
+		msgrng_access_enable(flags);
+		if (xlr_dma_consumer == xlr_dma_producer) {
+			ErrorMsg("Shdnt Happen.");
+		}
+		if (message_send_retry(2, MSGRNG_CODE_DMA, MSGRNG_STNID_DMA_0,
+				       &xlr_dma_queue[xlr_dma_consumer])) {
+			xlr_dma_msg_send_failed++;
+			msgrng_access_disable(flags);
+			last_msg_send_success = 1;
+			msg_send_success = 0;
+			tasklet_schedule(&xlr_dma_task);
+			break;
+		}
+
+		msg_send_success = 1;
+		last_msg_send_success = 1;
+		xlr_dma_consumer = (xlr_dma_consumer + 1) % (MAX_DMA_QUEUE_LEN);
+		msgrng_access_disable(flags);
+	}
+
+}
+
+/* Returns 0 on success, -1 otherwise */
+int xlr_async_request_dma(uint64_t src, uint64_t dest, uint32_t len,
+			  void (*func) (void *, uint64_t), void *data)
+{
+	int thr_id, cpu;
+	xlr_dma_ctrl_t *ctrl;
+	int tx_id, resp_bkt, seq;
+	struct msgrng_msg msg;
+	unsigned long flags;
+
+	/* Driver does not support multiple descriptor DMA yet */
+	if (len > XLR_MAX_DMA_LEN_PER_DESC) {
+		ErrorMsg("%s: Cannot do DMA for more than %d bytes\n",
+			 __FUNCTION__, XLR_MAX_DMA_LEN_PER_DESC);
+		return -1;
+	}
+	if (xlr_dma_init_done == 0) {
+		ErrorMsg("%s: XLR DMA engine is not initialized\n",
+			 __FUNCTION__);
+		return -1;
+	}
+	Message("\nSrc Addr %#llx Dst Addr %#llx\n", src, dest);
+
+	preempt_disable();
+	thr_id = phoenix_thr_id();
+	cpu = (phoenix_cpu_id() * 4) + thr_id;
+	ctrl = &xlr_dma_ctrl[cpu];
+
+	spin_lock_irqsave(&ctrl->q_lock, flags);
+	preempt_enable();
+
+	if (DMA_SLOT_BUSY(ctrl)) {
+		//ErrorMsg("%s: No space to enqueue this request\n", __FUNCTION__);
+		spin_unlock_irqrestore(&ctrl->q_lock, flags);
+		return -1;
+	}
+	tx_id = (thr_id << 8) | ctrl->sequence_number;
+	seq = ctrl->sequence_number;
+	DMA_SLOT_GET(ctrl);
+
+	/* use bucket 0 of each core as the bucket where response will be 
+	   received
+	 */
+	resp_bkt = phoenix_cpu_id() * 8;
+
+	spin_unlock_irqrestore(&ctrl->q_lock, flags);
+
+	/*CallBack For Async Call. */
+	ctrl->trans[seq].func = func;
+	ctrl->trans[seq].data = data;
+
+	/* Form the DMA simple xfer request and send to Channel 0 */
+
+	xlr_build_xfer_msg(&msg, src, dest, len, tx_id, resp_bkt);
+
+	if (xlr_enqueue_dma_msg(&msg)) {
+		//ErrorMsg("Cant Enqueue Msg.");
+		spin_lock_irqsave(&ctrl->q_lock, flags);
+		DMA_SLOT_PUT(ctrl, seq);
+		spin_unlock_irqrestore(&ctrl->q_lock, flags);
+		tasklet_schedule(&xlr_dma_task);
+		return -1;
+	}
+	tasklet_schedule(&xlr_dma_task);
+	return 0;
+}
+
+/* Returns 0 on success, -1 otherwise */
+int xlr_request_dma(uint64_t src, uint64_t dest, uint32_t len)
+{
+	int thr_id, cpu, i;
+	xlr_dma_ctrl_t *ctrl;
+	int tx_id, resp_bkt, seq, ret, err;
+	struct msgrng_msg  msg = {0}, r_msg = {0};
+	unsigned long flags;
+
+	/* Driver does not support multiple descriptor DMA yet */
+	if (len > XLR_MAX_DMA_LEN_PER_DESC) {
+		printk("%s: Cannot do DMA for more than %d bytes\n",
+		       __FUNCTION__, XLR_MAX_DMA_LEN_PER_DESC);
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_req_failed++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	if (xlr_dma_init_done == 0) {
+		printk("%s: XLR DMA engine is not initialized\n", __FUNCTION__);
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_req_failed++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+
+	preempt_disable();
+	thr_id = phoenix_thr_id();
+	cpu = (phoenix_cpu_id() * 4) + thr_id;
+	ctrl = &xlr_dma_ctrl[cpu];
+
+	spin_lock_irqsave(&ctrl->q_lock, flags);
+	preempt_enable();	/* will not enable actually */
+	if (DMA_SLOT_BUSY(ctrl)) {
+		printk("%s: No space to enqueue this request\n", __FUNCTION__);
+		spin_unlock_irqrestore(&ctrl->q_lock, flags);
+
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_req_failed++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	tx_id = (thr_id << 8) | ctrl->sequence_number;
+	seq = ctrl->sequence_number;
+	DMA_SLOT_GET(ctrl);
+
+	/* use bucket 0 of each core as the bucket where response will be 
+	   received
+	 */
+	resp_bkt = phoenix_cpu_id() * 8;
+	spin_unlock_irqrestore(&ctrl->q_lock, flags);
+
+	/*Reset Callback - As this is not async call */
+	ctrl->trans[seq].func = NULL;
+	ctrl->trans[seq].data = NULL;
+
+	/* Form the DMA simple xfer request and send to Channel 0 */
+	xlr_build_xfer_msg(&msg, src, dest, len, tx_id, resp_bkt);
+	msgrng_access_enable(flags);
+	if (message_send_retry(2, MSGRNG_CODE_DMA, MSGRNG_STNID_DMA_0, &msg)) {
+		printk
+		    ("Message_send failed: Cannot submit DMA request to engine\n");
+		msgrng_access_disable(flags);
+		spin_lock_irqsave(&ctrl->q_lock, flags);
+		DMA_SLOT_PUT(ctrl, seq);
+		spin_unlock_irqrestore(&ctrl->q_lock, flags);
+
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_req_failed++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	msgrng_access_disable(flags);
+	/* wait for the response here */
+	for (i = 0; i < XLR_DMA_RESP_TIMEOUT; i++) {
+		if (DMA_DONE(ctrl, seq))
+			break;
+		udelay(50);
+	}
+	if (i == XLR_DMA_RESP_TIMEOUT) {
+		printk("%s:Did not get response from DMA engine\n",
+		       __FUNCTION__);
+		spin_lock_irqsave(&ctrl->q_lock, flags);
+		DMA_SLOT_PUT(ctrl, seq);
+		spin_unlock_irqrestore(&ctrl->q_lock, flags);
+
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_timeout_errors++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	/* Do some error checks */
+
+	r_msg.msg0 = DMA_GET_RESP(ctrl, seq);
+	ret = (r_msg.msg0 >> 62) & 0x3;
+	err = (r_msg.msg0 >> 60) & 0x3;
+	if (ret != 0x3) {
+		printk("%s: Bad return code %d from DMA engine\n", __FUNCTION__,
+		       ret);
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_errors++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	if (err & 0x2) {
+		printk("%s:DMA engine reported Message format error\n",
+		       __FUNCTION__);
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_errors++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+		return -1;
+	}
+	if (err & 0x1) {
+		printk("%s:DMA engine reported Bus error\n", __FUNCTION__);
+		spin_lock_irqsave(&xlr_dma_lock, flags);
+		xlr_dma_errors++;
+		spin_unlock_irqrestore(&xlr_dma_lock, flags);
+
+		return -1;
+	}
+	spin_lock_irqsave(&xlr_dma_lock, flags);
+	xlr_total_dma_reqs++;
+	xlr_total_dma_bytes += len;
+	spin_unlock_irqrestore(&xlr_dma_lock, flags);
+	return 0;
+}
+
+int xlr_init_dma(void)
+{
+	int i;
+	phoenix_reg_t *mmio = phoenix_io_mmio(0x1A000);
+	xlr_dma_ctrl_t *ctrl;
+#ifdef RMI_BRIDGE_WKAROUND
+	unsigned int flags=0;
+#endif
+
+	for (i = 0; i < NR_CPUS; i++) {
+		ctrl = &xlr_dma_ctrl[i];
+		spin_lock_init(&ctrl->q_lock);
+		ctrl->sequence_number = 0;
+	}
+	/* Register for the Message ring handler */
+	if (register_msgring_handler(TX_STN_DMA, xlr_dma_msgring_handler, NULL)) {
+		printk("Couldn't register DMA msgring handler\n");
+		return -1;
+	}
+#ifdef RMI_BRIDGE_WKAROUND
+	if (rmi_enable_br_wrkaround) {
+		flags = rmi_write_lock_irq_save(rmi_bridge_lock);
+	}
+#endif
+	/* Use channel 0 for all DMA */
+	/* Pci Stream Hint En = 1, Report Error = 1, Section Size = 4, 
+	 * RMaxCr=4, WMaxCr =4, En=1; */
+	mmio[CH0_CONTROL] = (1 << 28) | (1 << 24) | (4 << 12) | (4 << 8) |
+	    (4 << 5) | (1 << 4);
+	mmio[PCIX_ACK_TIMER_VAL] = 100;
+	/* Configure the bucket sizes */
+	if (xlr_loader_own_dma) {
+		mmio[DMA_MSG_BUCKET0_SIZE] =
+		    shared_bucket_sizes.bucket[MSGRNG_STNID_DMA_0];
+		mmio[DMA_MSG_BUCKET1_SIZE] =
+		    shared_bucket_sizes.bucket[MSGRNG_STNID_DMA_1];
+		mmio[DMA_MSG_BUCKET2_SIZE] =
+		    shared_bucket_sizes.bucket[MSGRNG_STNID_DMA_2];
+		mmio[DMA_MSG_BUCKET3_SIZE] =
+		    shared_bucket_sizes.bucket[MSGRNG_STNID_DMA_3];
+
+		/* Configure the DMA credits */
+		for (i = 0; i < 128; i++) {
+			mmio[DMA_CC_CPU0_0 + i] =
+			    shared_cc_table_dma.counters[i >> 3][i & 0x07];
+		}
+	} else {
+		mmio[DMA_MSG_BUCKET0_SIZE] =
+		    bucket_sizes.bucket[MSGRNG_STNID_DMA_0];
+		mmio[DMA_MSG_BUCKET1_SIZE] =
+		    bucket_sizes.bucket[MSGRNG_STNID_DMA_1];
+		mmio[DMA_MSG_BUCKET2_SIZE] =
+		    bucket_sizes.bucket[MSGRNG_STNID_DMA_2];
+		mmio[DMA_MSG_BUCKET3_SIZE] =
+		    bucket_sizes.bucket[MSGRNG_STNID_DMA_3];
+
+		/* Configure the DMA credits */
+		for (i = 0; i < 128; i++) {
+			mmio[DMA_CC_CPU0_0 + i] =
+			    cc_table_dma.counters[i >> 3][i & 0x07];
+		}
+	}
+#ifdef RMI_BRIDGE_WKAROUND
+	if (rmi_enable_br_wrkaround) {
+		rmi_write_unlock_irq_restore(rmi_bridge_lock, flags);
+	}
+#endif
+#ifdef CONFIG_PROC_FS
+	xlr_init_dma_proc();
+#endif
+	xlr_dma_init_done = 1;
+	printk("Initialized XLR DMA Controller, Channel 0 \n");
+	tasklet_schedule(&xlr_dma_task);
+	return 0;
+}
+
+#ifdef TEST_DMA
+void xlr_dma_test(void)
+{
+	int i;
+	uint8_t *ptr1, *ptr2;
+	unsigned long s_jiffy, e_jiffy;
+
+	ptr1 = (uint8_t *) kmalloc(0x1000, GFP_KERNEL);
+	ptr2 = (uint8_t *) kmalloc(0x1000, GFP_KERNEL);
+	if (!ptr1 || !ptr2) {
+		if (ptr1)
+			kfree(ptr1);
+		if (ptr2)
+			kfree(ptr2);
+
+		printk("DMA test buffer alloc failed\n");
+		return;
+	}
+	memset(ptr1, 0xa5, 0x1000);
+	s_jiffy = read_c0_count();
+	for (i = 0; i < 512; i++) {
+		xlr_request_dma((uint64_t) virt_to_phys(ptr1),
+				(uint64_t) virt_to_phys(ptr2), 0x1000);
+	}
+	e_jiffy = read_c0_count();
+	if (memcmp(ptr1, ptr2, 0x1000)) {
+		printk("DMA Data does not match. Test failed\n");
+	} else
+		printk("DMA Data Matches. Test Successful\n");
+
+	printk("Start time = %lx end time = %lx\n", s_jiffy, e_jiffy);
+	kfree(ptr1);
+	kfree(ptr2);
+}
+#endif
+EXPORT_SYMBOL(xlr_request_dma);
diff --git a/arch/mips/rmi/phoenix/irq.c b/arch/mips/rmi/phoenix/irq.c
new file mode 100644
index 0000000..fa6151e
--- /dev/null
+++ b/arch/mips/rmi/phoenix/irq.c
@@ -0,0 +1,759 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/linkage.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/pci.h>
+#include <linux/msi.h>
+#include <asm/errno.h>
+#include <asm/signal.h>
+#include <asm/system.h>
+#include <asm/ptrace.h>
+#include <asm/kgdb.h>
+#include <asm/mipsregs.h>
+
+#include <asm/rmi/sim.h>
+#include <asm/rmi/rmi_srio.h>
+#include <asm/rmi/msidef.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/pic.h>
+#include <asm/rmi/debug.h>
+#include <asm/thread_info.h>
+#include "asm/rmi/rmicrf/config.h"
+#include <asm/rmi/linux_crf.h>
+#include <linux/irq.h>
+/*
+ * These are the routines that handle all the low level interrupt stuff. 
+ * Actions handled here are: initialization of the interrupt map, requesting of
+ * interrupt lines by handlers, dispatching if interrupts to handlers, probing
+ * for interrupt lines 
+ */
+
+/* Externs */
+extern void phoenix_timer_interrupt(struct pt_regs *regs, int irq);
+extern void phoenix_smp_time_init(void);
+
+extern void *ht_config_base;
+extern int link0, link1;
+struct pic_tmask pic_tmask[PIC_NUM_IRTS];
+
+__u64 phnx_irq_mask;
+spinlock_t phnx_pic_lock = SPIN_LOCK_UNLOCKED;
+
+static unsigned int pic_startup(unsigned int irq)
+{
+#if defined(XLP_SIM)
+	pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+#else
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+#endif				/* #if defined(XLP_SIM) */
+	unsigned long flags;
+	phoenix_reg_t reg;
+/* 	uint32_t thread_mask = (1 << cpu_logical_map(0)); */
+
+/* 	printk("[%s]: IN irq=%d\n", __func__, irq); */
+
+	if (!PIC_IRQ_IS_IRT(irq))
+		return EINVAL;
+
+	spin_lock_irqsave(&phnx_pic_lock, flags);
+
+	/* What happens if this irq was previously not ack'ed? 
+	 * Assume, that doesn't happen?
+	 */
+#if defined(XLP_SIM)
+	reg = read_pic_reg(mmio, PIC_IRT(irq_to_irt(irq)));
+	/* phoenix_write_reg(mmio, PIC_IRT_1_BASE + irq_to_irt(irq), reg | (1<<31)); */
+	/* By default all the interrupts are initialized as level senstive - fix for the PCMCIA flash */
+	write_pic_reg(mmio, PIC_IRT(irq_to_irt(irq)),
+		      reg | (1 << 28) | (1 << 31));
+	printk("%s --  > Writing IRT reg %d with IRQ %d\n", __FUNCTION__,
+	       PIC_IRT(irq_to_irt(irq)), (irq_to_irt(irq)));
+#else
+	reg = phoenix_read_reg(mmio, PIC_IRT_1_BASE + irq - PIC_IRQ_BASE);
+	/* phoenix_write_reg(mmio, PIC_IRT_1_BASE + irq - PIC_IRQ_BASE, reg | (1<<31)); */
+	/* By default all the interrupts are initialized as level senstive - fix for the PCMCIA flash */
+	phoenix_write_reg(mmio, PIC_IRT_1_BASE + irq - PIC_IRQ_BASE,
+			  reg | (1 << 6) | (1 << 30) | (1 << 31));
+	printk("%s: Writing IRT reg %d with IRQ %d\n", __FUNCTION__, PIC_IRT_1_BASE+irq-PIC_IRQ_BASE, irq);
+#endif				/* #if defined(XLP_SIM) */
+
+	spin_unlock_irqrestore(&phnx_pic_lock, flags);
+
+	return 0;
+}
+
+static void pic_unmask(unsigned int irq)
+{
+#if defined(XLP_SIM)
+	pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+#else
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+#endif				/* #if defined(XLP_SIM) */
+	unsigned long flags;
+	phoenix_reg_t reg;
+/* 	uint32_t thread_mask = (1 << cpu_logical_map(0)); */
+
+/* 	printk("%s.%d: IN irq=%d\n", __func__, __LINE__, irq); */
+
+	if (!PIC_IRQ_IS_IRT(irq))
+		return;
+
+	spin_lock_irqsave(&phnx_pic_lock, flags);
+
+	/* What happens if this irq was previously not ack'ed? 
+	 * Assume, that doesn't happen?
+	 */
+#if defined(XLP_SIM)
+	reg = read_pic_reg(mmio, PIC_IRT(irq_to_irt(irq)));
+	/* phoenix_write_reg(mmio, PIC_IRT_1_BASE + irq_to_irt(irq), reg | (1<<31)); */
+	/* By default all the interrupts are initialized as level senstive - fix for the PCMCIA flash */
+	write_pic_reg(mmio, PIC_IRT(irq_to_irt(irq)),
+		      reg | (1 << 28) | (1 << 31));
+/* 	printk("%s --  > Writing IRT reg %d with IRQ %d\n", __FUNCTION__, irq_to_irt(irq), (irq)); */
+#else
+	reg = phoenix_read_reg(mmio, PIC_IRT_1_BASE + irq - PIC_IRQ_BASE);
+	/* phoenix_write_reg(mmio, PIC_IRT_1_BASE + irq - PIC_IRQ_BASE, reg | (1<<31)); */
+	/* By default all the interrupts are initialized as level senstive - fix for the PCMCIA flash */
+	phoenix_write_reg(mmio, PIC_IRT_1_BASE + irq - PIC_IRQ_BASE,
+			  reg | (1 << 6) | (1 << 30) | (1 << 31));
+/* 	printk("%s: Writing IRT reg %d with IRQ %d\n", __FUNCTION__, PIC_IRT_1_BASE+irq-PIC_IRQ_BASE, irq); */
+#endif				/* #if defined(XLP_SIM) */
+
+	spin_unlock_irqrestore(&phnx_pic_lock, flags);
+
+	return;
+}
+
+static void pic_ack(unsigned int irq)
+{
+#if !defined (XLP_SIM)
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+#endif
+	unsigned long flags;
+#if defined(CONFIG_RMI_XLR)
+	phoenix_reg_t *pci_mmio = phoenix_io_mmio(PHOENIX_IO_PCIX_OFFSET);
+	phoenix_reg_t *ht_mmio = phoenix_io_mmio(PHOENIX_IO_HT_OFFSET);
+
+	/* XLS PCIE : the Little Endian region */
+	phoenix_reg_t *pcie_mmio_le = NULL;
+
+	unsigned long i;
+	phoenix_reg_t reg;
+
+	//dbg_msg("IN irq=%d\n", irq);
+
+	if (is_xls()) {
+		pcie_mmio_le = phoenix_io_mmio(PHOENIX_IO_PCIE_1_OFFSET);
+	}
+#endif
+
+	if (!PIC_IRQ_IS_IRT(irq))
+		return;
+
+#if defined(CONFIG_RMI_XLR)
+	/* Interrupt (level sensitive ) acknowledge method for the PCMCIA flash */
+
+	if (irq == 21) {
+		reg = *(unsigned char *)(unsigned long)(0xffffffffBD0001f7ULL);
+		reg = *(unsigned int *)(unsigned long)(0xffffffffBEF19180ULL);
+		for (i = 0; i < 0x100; i++) ;
+		*(unsigned int *)(unsigned long)(0xffffffffBEF19180ULL) = reg;
+		for (i = 0; i < 0x1000; i++) ;
+		reg = *(unsigned int *)(unsigned long)(0xffffffffBEF19180ULL);
+	}
+
+	/* Deal with All PCI-Interrupts.. Brigde ACK */
+	if ((irq == 24) && (!is_xls()))
+		phoenix_read_reg(pci_mmio, (0x140 >> 2));
+
+	if (irq == 23) {
+
+		/* HyperTransport: Clear INT Status */
+		phoenix_read_reg(ht_mmio, (0x700 >> 2));
+
+		/* 
+		 *  ---------------------------------------------------------
+		 *  Generating EOI.
+		 *  Clear Interrupts by directly writing to PLX's CFG Space. 
+		 *  1. setup the off value in register 0xB8
+		 *     (Interrupt Discovery Configuration, bits 23-16). 
+		 *  2. clear the interrupt by setting the IRR bit 
+		 *     (bit 63) in reg 0xBC (IRDR). 
+		 *  ---------------------------------------------------------
+		 *  If more devices are added to HT, we have to use the EOI 
+		 *  broadcast.
+		 *  ---------------------------------------------------------
+		 *  NOTE: Send EOI for all interrupts (INT A, B, C and D).
+		 *  Bridge Cards, if plugged into the slot, may re-route 
+		 *  interrupts. E.g: Intel Bridge 31154 eval board re-routes 
+		 *  INTA of the endpoint to INTC of PLX.
+		 *  ---------------------------------------------------------
+		 */
+
+		/* Generate EOI for INTA */
+		*(volatile uint32_t *)(ht_config_base + 0x008b8) = 0x08c01180;
+		*(volatile uint32_t *)(ht_config_base + 0x008bc) = 0x00000080;
+
+		/* Generate EOI for INTB */
+		*(volatile uint32_t *)(ht_config_base + 0x008b8) = 0x08c01380;
+		*(volatile uint32_t *)(ht_config_base + 0x008bc) = 0x00000080;
+
+		/* Generate EOI for INTC */
+		*(volatile uint32_t *)(ht_config_base + 0x008b8) = 0x08c01580;
+		*(volatile uint32_t *)(ht_config_base + 0x008bc) = 0x00000080;
+
+		/* Generate EOI for INTD */
+		*(volatile uint32_t *)(ht_config_base + 0x008b8) = 0x08c01780;
+		*(volatile uint32_t *)(ht_config_base + 0x008bc) = 0x00000080;
+	}
+
+	/* Ack the PCIE Block MSI Status Register(s) */
+	if (is_xls() && !is_xlsb0_srio()) {
+		if (irq == 34) {
+			/*Link0 */
+			phoenix_write_reg(pcie_mmio_le, (0x90 >> 2),
+					  0xffffffff);
+		}
+		if (irq == 35) {
+			/*Link1 */
+			phoenix_write_reg(pcie_mmio_le, (0x94 >> 2),
+					  0xffffffff);
+		}
+		if ((is_xls2xx() && irq == 31) || (is_xls_b0() && irq == 36)) {
+			/*Link2 */
+			phoenix_write_reg(pcie_mmio_le, (0x190 >> 2),
+					  0xffffffff);
+		}
+		if ((is_xls2xx() && irq == 32) || (is_xls_b0() && irq == 37)) {
+			/*Link3 */
+			phoenix_write_reg(pcie_mmio_le, (0x194 >> 2),
+					  0xffffffff);
+		}
+	}
+#endif
+
+	/* If edge triggered IRQ, ack it immediately, else when the device
+	 * interrupt condition is cleared, we may lose interrupts 
+	 */
+	if (PIC_IRQ_IS_EDGE_TRIGGERED(irq)) {
+		spin_lock_irqsave(&phnx_pic_lock, flags);
+#if defined(XLP_SIM)
+		ack_pic(irq_to_irt(irq));
+#else
+		phoenix_write_reg(mmio, PIC_INT_ACK,
+				  (1 << (irq - PIC_IRQ_BASE)));
+#endif
+
+		spin_unlock_irqrestore(&phnx_pic_lock, flags);
+	}
+}
+
+static void pic_end(unsigned int irq)
+{
+#if !defined(XLP_SIM)
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+#endif
+	unsigned long flags;
+
+	//dbg_msg("IN irq=%d\n", irq);
+
+	if (!PIC_IRQ_IS_IRT(irq))
+		return;
+
+	/* If level triggered, ack it after the device condition is cleared */
+	if (!PIC_IRQ_IS_EDGE_TRIGGERED(irq)) {
+
+		spin_lock_irqsave(&phnx_pic_lock, flags);
+
+#if defined(XLP_SIM)
+		ack_pic(irq_to_irt(irq));
+#else
+		phoenix_write_reg(mmio, PIC_INT_ACK,
+				  (1 << (irq - PIC_IRQ_BASE)));
+#endif
+		spin_unlock_irqrestore(&phnx_pic_lock, flags);
+	}
+}
+
+static void pic_shutdown(unsigned int irq)
+{
+#if defined(XLP_SIM)
+	pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+#else
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+#endif				/* #if defined(XLP_SIM) */
+	unsigned long flags;
+	phoenix_reg_t reg;
+
+	//dbg_msg("IN irq=%d\n", irq);
+
+	if (!PIC_IRQ_IS_IRT(irq))
+		return;
+
+	spin_lock_irqsave(&phnx_pic_lock, flags);
+
+	/* What happens if this irq is currently pending an ack? 
+	 * Assume, that doesn't happen?
+	 */
+#if defined(XLP_SIM)
+	reg = read_pic_reg(mmio, PIC_IRT(irq_to_irt(irq)));
+	write_pic_reg(mmio, PIC_IRT(irq_to_irt(irq)), (reg & ~(1 << 31)));
+	printk("%s --  > Writing IRT reg %d with IRQ %d\n", __FUNCTION__,
+	       PIC_IRT(irq_to_irt(irq)), (irq_to_irt(irq)));
+#else
+	reg = phoenix_read_reg(mmio, PIC_IRT_1_BASE + irq - PIC_IRQ_BASE);
+	phoenix_write_reg(mmio, PIC_IRT_1_BASE + irq - PIC_IRQ_BASE,
+			  (reg & ~(1 << 31)));
+#endif				/* #if defined(XLP_SIM) */
+
+	spin_unlock_irqrestore(&phnx_pic_lock, flags);
+}
+
+static int pic_set_affinity(unsigned int irq, const struct cpumask *dest)
+{
+#ifdef XLP_MERGE_TODO
+#if defined(XLP_SIM)
+	pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+#else
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+#endif
+	unsigned long flags;
+/*   uint32_t physmap = 0, logmap = 0; */
+/*   int cpu = 0; */
+
+	//dbg_msg("IN irq=%d, mask=%lx\n", irq, mask);
+
+	if (!PIC_IRQ_IS_IRT(irq))
+		return -1;
+
+	spin_lock_irqsave(&phnx_pic_lock, flags);
+
+
+#if defined(XLP_SIM)
+	// XLP_TODO: verify if this is correct
+	write_pic_reg(mmio, PIC_IRT(irq_to_irt(irq)),
+		      (uint32_t) (mask.bits[0]));
+	printk("%s --  > Writing IRT reg %d with IRQ %d\n", __FUNCTION__,
+	       PIC_IRT(irq_to_irt(irq)), (irq_to_irt(irq)));
+
+#else
+	phoenix_write_reg(mmio, PIC_IRT_0_BASE + irq - PIC_IRQ_BASE,
+			  (uint32_t) (mask.bits[0]));
+#endif
+	spin_unlock_irqrestore(&phnx_pic_lock, flags);
+#endif /* XLP_MERGE_TODO */
+
+	return 0;
+}
+
+static struct irq_chip phnx_pic = {
+	.name = "Phoenix-PIC",
+	.unmask = pic_unmask,
+	.mask = pic_shutdown,
+	.ack = pic_ack,
+	.end = pic_end,
+	.set_affinity = pic_set_affinity
+};
+
+static void rsvd_pic_handler_1_1(unsigned int irq)
+{
+	if(irq < PIC_IRQ_BASE)
+		return;
+  dbg_msg("Requesting a reserved irq (%d)??", irq);
+  return;
+}
+
+static void rsvd_pic_handler_1(unsigned int irq)
+{
+	if(irq < PIC_IRQ_BASE)
+		return;
+  dbg_msg("handler called for a reserved irq (%d)\n", irq);
+}
+
+static int rsvd_pic_handler_2(unsigned int irq, const struct cpumask *mask)
+{
+	if(irq < PIC_IRQ_BASE)
+		return -1;
+  dbg_msg("handler called for a reserved irq (%d)\n", irq);
+  return 0;
+}
+
+struct irq_chip phnx_rsvd_pic_irq_timer = {
+  .name     =          "Count-Compare",
+  .unmask	=          rsvd_pic_handler_1_1,
+  .mask		=          rsvd_pic_handler_1,
+  .ack          =          rsvd_pic_handler_1,
+  .end          =          rsvd_pic_handler_1,
+  .set_affinity =          rsvd_pic_handler_2
+};
+
+struct irq_chip phnx_rsvd_pic = {
+	.name = "Phoenix-RSVD-PIC",
+	.unmask = rsvd_pic_handler_1_1,
+	.mask = rsvd_pic_handler_1,
+	.ack = rsvd_pic_handler_1,
+	.end = rsvd_pic_handler_1,
+	.set_affinity = rsvd_pic_handler_2
+};
+
+static irqreturn_t phnx_rsvd_irq_handler(int irq, void *dev_id)
+{
+	if(irq == IRQ_TIMER) 
+		return IRQ_HANDLED;
+  dbg_msg("handler for reserved irq %d\n", irq);
+  return IRQ_NONE;
+}
+
+struct irqaction phnx_rsvd_action = {
+	.handler = phnx_rsvd_irq_handler,
+	.flags = 0,
+	//.mask = 0,
+	.name = "phnx_rsvd_action",
+	.dev_id = 0,
+	.next = 0
+};
+
+void __init init_phoenix_irqs(void)
+{
+	int i;
+
+	for (i = 0; i < NR_IRQS; i++) {
+		set_irq_chip(i, &phnx_pic);
+	}
+
+#ifdef CONFIG_REMOTE_DEBUG
+	irq_desc[IRQ_REMOTE_DEBUG].chip = &phnx_rsvd_pic;
+	irq_desc[IRQ_REMOTE_DEBUG].action = phnx_rsvd_action;
+	phnx_irq_mask |= (1ULL << IRQ_REMOTE_DEBUG);
+#endif
+
+#ifdef CONFIG_SMP
+	irq_desc[IRQ_IPI_SMP_FUNCTION].chip = &phnx_rsvd_pic;
+	irq_desc[IRQ_IPI_SMP_FUNCTION].action = &phnx_rsvd_action;
+
+	irq_desc[IRQ_IPI_SMP_RESCHEDULE].chip = &phnx_rsvd_pic;
+	irq_desc[IRQ_IPI_SMP_RESCHEDULE].action = &phnx_rsvd_action;
+
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	/* PR: New IPI added here for netrx balancing */
+	irq_desc[IRQ_IPI_NETRX].chip = &phnx_rsvd_pic;
+	irq_desc[IRQ_IPI_NETRX].action = &phnx_rsvd_action;
+	phnx_irq_mask |= (1ULL << IRQ_IPI_NETRX);
+#endif				/* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
+	phnx_irq_mask |=
+	    ((1ULL << IRQ_IPI_SMP_FUNCTION) | (1ULL << IRQ_IPI_SMP_RESCHEDULE));
+#endif
+
+	/* msgring interrupt */
+	irq_desc[IRQ_MSGRING].chip = &phnx_rsvd_pic;
+	irq_desc[IRQ_MSGRING].action = &phnx_rsvd_action;
+	phnx_irq_mask |= (1ULL << IRQ_MSGRING);
+
+	if(rmik_en) {
+	  	irq_desc[IRQ_IPI_CRF_EVENTQ_IPI].chip = &phnx_rsvd_pic;
+	  	irq_desc[IRQ_IPI_CRF_EVENTQ_IPI].action = &phnx_rsvd_action;
+		phnx_irq_mask |= (1ULL << IRQ_IPI_CRF_EVENTQ_IPI);
+	}
+
+	/* unmask all PIC related interrupts. If no handler is installed by the 
+	 * drivers, it'll just ack the interrupt and return 
+	 */
+	for (i = PIC_IRT_FIRST_IRQ; i <= PIC_IRT_LAST_IRQ(); i++)
+		phnx_irq_mask |= (1ULL << i);
+
+#ifdef CONFIG_OPROFILE
+	phnx_irq_mask |= (1ULL << IRQ_IPI_OPROFILE);
+#endif
+
+#ifdef CONFIG_KGDB
+	phnx_irq_mask |= (1ULL << IRQ_IPI_SMP_KGDB);
+#endif
+
+	phnx_irq_mask |= (1ULL << IRQ_TIMER);
+}
+
+#ifdef CONFIG_KGDB
+extern irqreturn_t xlr_kgdb_ipi_handler(int irq, struct pt_regs *regs);
+#endif
+#ifdef CONFIG_OPROFILE
+extern void phoenix_oprofile_int_handler(int irq, void *dev_id,
+					 struct pt_regs *regs);
+#endif
+void do_phnx_IRQ(unsigned int irq, struct pt_regs *regs)
+{
+#ifdef CONFIG_SMP
+
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	if (irq == IRQ_IPI_SMP_FUNCTION || irq == IRQ_IPI_SMP_RESCHEDULE
+	    || irq == IRQ_IPI_NETRX) {
+#else
+	if (irq == IRQ_IPI_SMP_FUNCTION || irq == IRQ_IPI_SMP_RESCHEDULE) {
+#endif				/* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+		phoenix_ipi_handler(irq, regs);
+		return;
+	}
+#endif
+
+	if (irq == IRQ_MSGRING) phnx_msgring_int_handler(irq, regs);
+
+#ifdef CONFIG_KGDB
+	else if (irq == IRQ_IPI_SMP_KGDB) {
+#if 0
+	  xlr_kgdb_ipi_handler(irq, regs);
+#endif
+  }
+#endif
+#ifdef CONFIG_OPROFILE
+	else if (irq == IRQ_IPI_OPROFILE) {
+		if (phoenix_thr_id() != 0)
+			phoenix_oprofile_int_handler(irq, NULL, regs);
+	}
+#endif
+
+  else if(rmik_en && irq == IRQ_IPI_CRF_EVENTQ_IPI)
+		rmik_eventq_ipi_handler();
+  else do_IRQ(irq);
+}
+
+void __cpuinit rmi_smp_irq_init(void)
+{
+#ifdef XLP_MERGE_TODO
+	/* Set up kseg0 to be cachable coherent */
+	change_c0_config(CONF_CM_CMASK, CONF_CM_DEFAULT);
+#endif
+
+	/* set interrupt mask for non-zero cpus */
+	write_64bit_cp0_eimr(phnx_irq_mask | (1 << IRQ_TIMER));
+
+#ifdef XLP_MERGE_TODO
+	phoenix_smp_time_init();
+#endif
+}
+
+/* 
+ * MSI hook-up routines for RMI Boards;
+ * Arch-dependent implementation called
+ * from generic msi.c routines.
+ */
+
+struct irq_chip phnx_pic_msi = {
+	.name = "Phoenix-PIC-MSI",
+	.startup = pic_startup,
+	.shutdown = pic_shutdown,
+	.ack = pic_ack,
+	.end = pic_end,
+	.set_affinity = pic_set_affinity
+};
+
+void destroy_irq(unsigned int irq)
+{
+    /* no-op */
+}
+
+#ifdef CONFIG_PCI_MSI_XLR
+
+#if defined(CONFIG_RMI_XLP)
+static int get_irq_vector(struct pci_dev *dev)
+{
+	return irt_to_irq(PIC_IRT_PCIE_LINK_INDEX(0));
+}
+#else
+static int get_irq_vector(struct pci_dev *dev)
+{
+
+    int irq = 0;
+
+	if (is_xls() && !is_xls2xx() && !is_xls_b0()) {
+		/* Currently, PCIE bridges not supported */
+		if (link0) {
+			if (dev->bus->number == 1)
+				irq = PIC_PCIE_LINK0_IRQ;
+			else
+				irq = PIC_PCIE_LINK1_IRQ;
+		} else if (link1) {
+			if (dev->bus->number == 1)
+				irq = PIC_PCIE_LINK1_IRQ;
+		}
+	} else if (is_xls2xx() || is_xls_b0()) {
+		switch (dev->bus->self->devfn) {
+		case 0x0:
+			irq = PIC_PCIE_LINK0_IRQ;
+			break;
+		case 0x8:
+			irq = PIC_PCIE_LINK1_IRQ;
+			break;
+		case 0x10:
+			if (is_xls_b0())
+				irq = PIC_PCIE_XLSB0_LINK2_IRQ;
+			else
+				irq = PIC_PCIE_LINK2_IRQ;
+			break;
+		case 0x18:
+			if (is_xls_b0())
+				irq = PIC_PCIE_XLSB0_LINK3_IRQ;
+			else
+				irq = PIC_PCIE_LINK3_IRQ;
+			break;
+		default:
+			break;
+		}
+	} else {
+		irq = PIC_HYPER_IRQ;
+	}
+
+	return irq;
+}
+#endif
+
+static int msi_compose_msg(struct pci_dev *pdev, unsigned int irq,
+			   struct msi_msg *msg)
+{
+
+	unsigned dest;
+
+	if (irq >= 0) {
+		dest = 0x00;
+		msg->address_hi = MSI_ADDR_BASE_HI;
+		msg->address_lo = MSI_ADDR_BASE_LO |
+		    MSI_ADDR_DEST_MODE_PHYSICAL |
+		    MSI_ADDR_REDIRECTION_CPU | MSI_ADDR_DEST_ID(dest);
+		msg->data = MSI_DATA_TRIGGER_EDGE |
+		    MSI_DATA_LEVEL_ASSERT |
+		    MSI_DATA_DELIVERY_FIXED | MSI_DATA_VECTOR(irq);
+	}
+	return irq;
+}
+
+void arch_teardown_msi_irq(unsigned int irq)
+{
+	destroy_irq(irq);
+}
+
+int arch_setup_msi_irq(struct pci_dev *dev, struct msi_desc *desc)
+{
+	struct msi_msg msg;
+	int irq, ret;
+
+	irq = get_irq_vector(dev);
+	if (irq < 0)
+		return irq;
+	set_irq_msi(irq, desc);
+	ret = msi_compose_msg(dev, irq, &msg);
+	if (ret < 0) {
+		destroy_irq(irq);
+		return ret;
+	}
+	write_msi_msg(irq, &msg);
+	irq_desc[irq].chip = &phnx_pic_msi;
+	phnx_irq_mask |= (1ULL << irq);
+	return irq;
+}
+#endif
+
+#if defined(CONFIG_RMI_XLP)
+static int xlp_perf_irq(void)
+{
+	return IRQ_HANDLED;
+}
+#endif
+
+void __init arch_init_irq(void)
+{
+#if defined(CONFIG_RMI_XLP)
+	extern int (*perf_irq)(void);
+
+	perf_irq = xlp_perf_irq;
+#endif
+
+#ifdef CONFIG_KGDB
+	if (kgdb_early_setup)
+		return;
+#endif
+
+	/* TODO:
+	 * Initialize the irq registers on the PIC to route
+	 * interrupts to appropriate pins
+	 */
+
+	/* Initialize the irq descriptors */
+	init_phoenix_irqs();
+
+	write_64bit_cp0_eimr(phnx_irq_mask);
+
+}
+
+asmlinkage void plat_irq_dispatch(void)
+{
+	uint64_t eirr;
+	struct pt_regs *pt_regs = current_thread_info()->regs;
+	int i = 0;
+	eirr = read_64bit_cp0_eirr() & read_64bit_cp0_eimr();
+
+	if (!eirr)
+		return;
+
+	if (eirr & (1 << IRQ_TIMER)) {
+		phoenix_timer_interrupt(pt_regs, IRQ_TIMER);
+		return;
+	}
+	/*TODO use dcltz: optimize below code */
+	for (i = 63; i != -1; i--) {
+		if (eirr & (1ULL << i))
+			break;
+	}
+	if (i == -1) {
+		printk("no interrupt !!\n");
+		return;
+	}
+	/*ack eirr */
+	write_64bit_cp0_eirr(1ULL << i);
+	do_phnx_IRQ(i, pt_regs);
+	return;
+}
+
+
+void pic_setup_threadmask(unsigned int irt, uint32_t mask)
+{
+#ifdef XLP_MERGE_TODO
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+	pic_tmask[irt].mask = mask;
+	pic_tmask[irt].set = 1;
+	pic_tmask[irt].valid = 1;
+ 	phoenix_write_reg(mmio, PIC_IRT_0_BASE + irt, mask);
+	return;
+#endif
+}
diff --git a/arch/mips/rmi/phoenix/msgring.cfg b/arch/mips/rmi/phoenix/msgring.cfg
new file mode 100644
index 0000000..9680d51
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring.cfg
@@ -0,0 +1,1280 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES, LOSS OF USE, DATA, OR PROFITS, OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * *****************************RMI_2**********************************/
+
+
+/* 
+ * This file defines the message ring configuration for phoenix-8. It tries to allow 
+ * many different point-point communications between the message stations on the message ring
+ * and as result is _not_ the best configuration for performance
+ *
+ * The message ring on phoenix family of processors connects the cpus, gmacs, xgmac/spi4,
+ * security engine and the general purpose DMA engines. It provides a high bandwidth,
+ * low latency communication links. On traditional processors, this communication goes through
+ * which inherently does not scale very well with increasing number of cpus. 
+ * 
+ * Message ring has an in-built flow control mechanism. Every agent/station on the ring has to
+ * have software configured credits to send messages to any agent. Every receiving agent on the
+ * ring has a 256 entry FIFO that can divided into "buckets". All addressing on the ring is 
+ * in terms of buckets. There are a total 128 buckets on the ring. The total number of credits 
+ * across all sending agents should not exceed the bucket size. 
+ *
+ * Below are the receiving agents and the max number of buckets they can have
+ * 	CPU 0	: 8 buckets
+ * 	CPU 1	: 8 buckets
+ * 	CPU 2	: 8 buckets
+ * 	CPU 3	: 8 buckets
+ * 	CPU 4	: 8 buckets
+ * 	CPU 5	: 8 buckets
+ * 	CPU 6	: 8 buckets
+ * 	CPU 7	: 8 buckets
+ * 
+ * 	XGMAC 0 / SPI4 0
+ *			 TX	:	16 buckets
+ *			 FREE	:	2  buckets
+ * 	XGMAC 1 / SPI4 1
+ *			 TX	:	16 buckets
+ *			 FREE	:	2  buckets
+ * 
+ *	GMAC	: 8 buckets	
+ *	
+ *	SEC	: 8 buckets
+ * 
+ *	DMA	: 8 buckets
+ *
+ * The bucket size of a bucket should be aligned to the bucket's starting index in that
+ * receiving station's FIFO. For example, if sizes of bucket0 and bucket1 of a station 
+ * are 32 and 32, bucket2's size has to be 64. bucket size 0 is valid.
+ *
+ * The format of the file is pretty straight forward. Each bucket definition has the size
+ * and the list of sending agents to that bucket with the number of credits to send.
+ * 
+ * Undefined buckets have a size of 0 and Tx stations have 0 credits to send to that bucket.
+ *
+ *  Following are the currently supported bucket names
+ *  cpu_0_0
+ *  cpu_0_1
+ *  cpu_0_2
+ *  cpu_0_3
+ *  cpu_0_4
+ *  cpu_0_5
+ *  cpu_0_6
+ *  cpu_0_7
+ *  
+ *  cpu_1_0
+ *  cpu_1_1
+ *  cpu_1_2
+ *  cpu_1_3
+ *  cpu_1_4
+ *  cpu_1_5
+ *  cpu_1_6
+ *  cpu_1_7
+ *  
+ *  cpu_2_0
+ *  cpu_2_1
+ *  cpu_2_2
+ *  cpu_2_3
+ *  cpu_2_4
+ *  cpu_2_5
+ *  cpu_2_6
+ *  cpu_2_7
+ *  
+ *  cpu_3_0
+ *  cpu_3_1
+ *  cpu_3_2
+ *  cpu_3_3
+ *  cpu_3_4
+ *  cpu_3_5
+ *  cpu_3_6
+ *  cpu_3_7
+ *  
+ *  cpu_4_0
+ *  cpu_4_1
+ *  cpu_4_2
+ *  cpu_4_3
+ *  cpu_4_4
+ *  cpu_4_5
+ *  cpu_4_6
+ *  cpu_4_7
+ *  
+ *  cpu_5_0
+ *  cpu_5_1
+ *  cpu_5_2
+ *  cpu_5_3
+ *  cpu_5_4
+ *  cpu_5_5
+ *  cpu_5_6
+ *  cpu_5_7
+ *  
+ *  cpu_6_0
+ *  cpu_6_1
+ *  cpu_6_2
+ *  cpu_6_3
+ *  cpu_6_4
+ *  cpu_6_5
+ *  cpu_6_6
+ *  cpu_6_7
+ *  
+ *  cpu_7_0
+ *  cpu_7_1
+ *  cpu_7_2
+ *  cpu_7_3
+ *  cpu_7_4
+ *  cpu_7_5
+ *  cpu_7_6
+ *  cpu_7_7
+ *
+ *  xgs_0_tx_0
+ *  xgs_0_tx_1
+ *  xgs_0_tx_2
+ *  xgs_0_tx_3
+ *  xgs_0_tx_4
+ *  xgs_0_tx_5
+ *  xgs_0_tx_6
+ *  xgs_0_tx_7
+ *  xgs_0_tx_8
+ *  xgs_0_tx_9
+ *  xgs_0_tx_10
+ *  xgs_0_tx_11
+ *  xgs_0_tx_12
+ *  xgs_0_tx_13
+ *  xgs_0_tx_14
+ *  xgs_0_tx_15
+ *
+ *  xgs_1_tx_0
+ *  xgs_1_tx_1
+ *  xgs_1_tx_2
+ *  xgs_1_tx_3
+ *  xgs_1_tx_4
+ *  xgs_1_tx_5
+ *  xgs_1_tx_6
+ *  xgs_1_tx_7
+ *  xgs_1_tx_8
+ *  xgs_1_tx_9
+ *  xgs_1_tx_10
+ *  xgs_1_tx_11
+ *  xgs_1_tx_12
+ *  xgs_1_tx_13
+ *  xgs_1_tx_14
+ *  xgs_1_tx_15
+ *
+ *  gmac_rsvd_0
+ *  gmac_rfr_0
+ *  gmac_tx_0
+ *  gmac_tx_1
+ *  gmac_tx_2
+ *  gmac_tx_3
+ *  gmac_rsvd_1
+ *  gmac_rfr_1
+ *
+ *  xgs_0_rsvd
+ *  xgs_0_rfr
+ *
+ *  xgs_1_rsvd
+ *  xgs_1_rfr
+ *
+ *  sec_pipe_0
+ *  sec_pipe_1
+ *  sec_pipe_2
+ *  sec_pipe_3
+ *  sec_rsa
+ *
+ * Following are the currently supported Tx Agent/Station names
+ *
+ *   tx_stn_cpu_0
+ *  tx_stn_cpu_1
+ *  tx_stn_cpu_2
+ *  tx_stn_cpu_3
+ *  tx_stn_cpu_4
+ *  tx_stn_cpu_5
+ *  tx_stn_cpu_6
+ *  tx_stn_cpu_7
+ *
+ *   tx_stn_xgs_0
+ *  tx_stn_xgs_1
+ *
+ *   tx_stn_gmac
+ *
+ *   tx_stn_dma
+ *
+ *   tx_stn_sec
+ *
+ *
+ * 
+ */
+
+/*************************************************************/
+// CPU_0 Message Station 
+
+bucket "cpu_0_0" { 
+	size 32;
+	"tx_stn_xgs_0" 4;
+	"tx_stn_xgs_1" 4;
+	"tx_stn_gmac" 4;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cpu_0" 1;
+        "tx_stn_cpu_1" 1; /* NEEDED BY RMIOS IPSEC */
+        "tx_stn_cpu_2" 1;
+        "tx_stn_cpu_3" 1;
+        "tx_stn_cpu_4" 1;
+        "tx_stn_cpu_5" 1;
+        "tx_stn_cpu_6" 1;
+        "tx_stn_cpu_7" 1;
+}
+bucket "cpu_0_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_0_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_0_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_0_4" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec" 8;
+}
+bucket "cpu_0_5" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec" 8;
+}
+bucket "cpu_0_6" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec" 8;
+}
+bucket "cpu_0_7" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec" 8;
+}
+
+/*************************************************************/
+// CPU_1 Message Station 
+
+bucket "cpu_1_0" { 
+	size 32;
+	"tx_stn_xgs_0" 6;
+	"tx_stn_xgs_1" 6;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_1_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_1_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_1_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 6;
+	"tx_stn_xgs_1" 6;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+    "tx_stn_cpu_0" 4; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_1_4" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_1_5" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_1_6" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_1_7" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+
+/*************************************************************/
+// CPU_2 Message Station 
+
+bucket "cpu_2_0" { 
+	size 32;
+	"tx_stn_xgs_0" 6;
+	"tx_stn_xgs_1" 6;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_2_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_4" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_5" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_6" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_7" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+
+/*************************************************************/
+// CPU_3 Message Station 
+
+bucket "cpu_3_0" { 
+	size 32;
+	"tx_stn_xgs_0" 6;
+	"tx_stn_xgs_1" 6;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_3_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_4" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_5" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_6" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_7" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+
+/*************************************************************/
+// CPU_4 Message Station 
+
+bucket "cpu_4_0" { 
+	size 32;
+	"tx_stn_xgs_0" 6;
+	"tx_stn_xgs_1" 6;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_4_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_4_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_4_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_4_4" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_4_5" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_4_6" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_4_7" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+
+/*************************************************************/
+// CPU_5 Message Station 
+
+bucket "cpu_5_0" { 
+	size 32;
+	"tx_stn_xgs_0" 6;
+	"tx_stn_xgs_1" 6;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_5_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_5_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_5_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_5_4" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_5_5" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_5_6" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_5_7" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+
+
+/*************************************************************/
+// CPU_6 Message Station 
+
+bucket "cpu_6_0" { 
+	size 32;
+	"tx_stn_xgs_0" 6;
+	"tx_stn_xgs_1" 6;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_6_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_6_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_6_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_6_4" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_6_5" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_6_6" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_6_7" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+
+
+/*************************************************************/
+// CPU_7 Message Station 
+
+bucket "cpu_7_0" { 
+	size 32;
+	"tx_stn_xgs_0" 6;
+	"tx_stn_xgs_1" 6;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_7_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_7_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_7_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_7_4" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_7_5" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_7_6" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_7_7" {
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_sec"  8;
+}
+
+
+/*************************************************************/
+// GMAC Message Station 
+
+bucket "gmac_rfr_0" {
+	size 32;
+	"tx_stn_cpu_0" 2;
+	"tx_stn_cpu_1" 2;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+	"tx_stn_gmac" 4;
+}
+
+bucket "gmac_tx_0" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_1" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_2" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_3" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_rfr_1" {
+	size 32;
+	"tx_stn_cpu_0" 2;
+	"tx_stn_cpu_1" 2;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+	"tx_stn_gmac" 4;
+}
+/*********************************************/
+// xgmac
+bucket "xgs_0_rfr" {
+    size 32;
+    "tx_stn_cpu_0" 2;
+    "tx_stn_cpu_1" 2;
+    "tx_stn_cpu_2" 2;
+    "tx_stn_cpu_3" 2;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+    "tx_stn_xgs_0" 4;
+    "tx_stn_xgs_1" 4;
+}
+
+bucket "xgs_0_tx_0" {
+    size 32;
+    "tx_stn_cpu_0" 4;
+    "tx_stn_cpu_1" 4;
+    "tx_stn_cpu_2" 4;
+    "tx_stn_cpu_3" 4;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+}
+
+bucket "xgs_0_tx_1" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_2" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_3" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_4" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+bucket "xgs_0_tx_5" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_6" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_7" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_8" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_9" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_10" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_0_tx_11" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_12" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_13" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_14" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_rfr" {
+    size 32;
+    "tx_stn_cpu_0" 2;
+    "tx_stn_cpu_1" 2;
+    "tx_stn_cpu_2" 2;
+    "tx_stn_cpu_3" 2;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+    "tx_stn_xgs_0" 4;
+    "tx_stn_xgs_1" 4;
+}
+
+bucket "xgs_1_tx_0" {
+    size 32;
+    "tx_stn_cpu_0" 4;
+    "tx_stn_cpu_1" 4;
+    "tx_stn_cpu_2" 4;
+    "tx_stn_cpu_3" 4;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+}
+
+
+bucket "xgs_1_tx_1" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_2" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_3" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_4" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_5" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_6" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_7" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_tx_8" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_tx_9" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_tx_10" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_11" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_12" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_13" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_14" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+
+
+
+
+/*************************************************************/
+// Security Message Station 
+
+bucket "sec_pipe_0" {
+        size 128;
+        "tx_stn_cpu_0" 16;
+        "tx_stn_cpu_1" 16;
+        "tx_stn_cpu_2" 16;
+        "tx_stn_cpu_3" 16;
+        "tx_stn_cpu_4" 16;
+        "tx_stn_cpu_5" 16;
+        "tx_stn_cpu_6" 16;
+        "tx_stn_cpu_7" 16;
+}
+
+bucket "sec_rsa" {
+        size 128;
+        "tx_stn_cpu_0" 16;
+        "tx_stn_cpu_1" 16;
+        "tx_stn_cpu_2" 16;
+        "tx_stn_cpu_3" 16;
+        "tx_stn_cpu_4" 16;
+        "tx_stn_cpu_5" 16;
+        "tx_stn_cpu_6" 16;
+        "tx_stn_cpu_7" 16;
+}
+
+bucket "dma_chan_0" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+bucket "dma_chan_1" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+
+bucket "dma_chan_2" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+
+bucket "dma_chan_3" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
diff --git a/arch/mips/rmi/phoenix/msgring.l b/arch/mips/rmi/phoenix/msgring.l
new file mode 100644
index 0000000..33bb94a
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring.l
@@ -0,0 +1,44 @@
+%{
+#include <stdio.h>
+#include <string.h>
+#include "msgring.yacc.h"
+
+
+int yyerror(const char *str)
+{
+  fprintf(stderr, "%s\n", str);
+  return 1;
+}
+
+%}
+
+%x c_comment
+
+%%
+
+"/*"                    BEGIN(c_comment); /* c-style comment */
+<c_comment>[^*\n]*        /* eat anything that is not a * */
+<c_comment>"*"+[^*/\n]*   /* eat up * s not followed by a / */
+<c_comment>\n
+<c_comment>"*"+"/"      BEGIN(INITIAL);
+
+"//"[^\n]*"\n"         ; /* eat up one-line (C++-style) commens */
+
+bucket                  yylval = (unsigned long)"bucket"; return TOK_BUCKET;
+size                    yylval = (unsigned long)"size"; return TOK_SIZE;
+[a-zA-Z_][a-zA-Z_0-9]*    yylval = (unsigned long)strdup(yytext); return TOK_WORD;
+[0-9]+                  yylval = atoi(yytext); return TOK_INTEGER;
+\"                      yylval = (unsigned long)"\""; return TOK_QUOTE;
+\{                      yylval = (unsigned long)"{"; return TOK_OPEN_BRACE;
+\}                      yylval = (unsigned long)"}"; return TOK_CLOSE_BRACE;
+;                       yylval = (unsigned long)";"; return TOK_SEMICOLON;
+\n                      /* ignore newline */;
+[ \t]+                  /* ignore whitespace */;
+.                       yyerror("Unknown token\n");
+%%
+
+int yywrap()
+{
+  return 1;
+}
+
diff --git a/arch/mips/rmi/phoenix/msgring.y b/arch/mips/rmi/phoenix/msgring.y
new file mode 100644
index 0000000..be4da41
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring.y
@@ -0,0 +1,544 @@
+%{
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdarg.h>
+#include <unistd.h>
+
+	extern FILE *yyin;
+	extern void yyerror(const char *);
+	int yydebug = 1;
+
+	//#define MAX_RX_BUCKETS 128
+
+	struct tx_stn {
+		const char *name;
+		const char *tbl_name;
+	};
+
+	struct tx_stn tx_stns[] = {
+		{ .name = "TX_STN_CPU_0" , .tbl_name = "cpu_0" },
+		{ .name = "TX_STN_CPU_1" , .tbl_name = "cpu_1" },
+		{ .name = "TX_STN_CPU_2" , .tbl_name = "cpu_2" },
+		{ .name = "TX_STN_CPU_3" , .tbl_name = "cpu_3" },
+		{ .name = "TX_STN_CPU_4" , .tbl_name = "cpu_4" },
+		{ .name = "TX_STN_CPU_5" , .tbl_name = "cpu_5" },
+		{ .name = "TX_STN_CPU_6" , .tbl_name = "cpu_6" },
+		{ .name = "TX_STN_CPU_7" , .tbl_name = "cpu_7" },
+
+		{ .name = "TX_STN_XGS_0" , .tbl_name = "xgs_0" },
+		{ .name = "TX_STN_XGS_1" , .tbl_name = "xgs_1" },
+
+		{ .name = "TX_STN_GMAC" , .tbl_name = "gmac" },
+
+		{ .name = "TX_STN_DMA" , .tbl_name = "dma" },
+
+		{ .name = "TX_STN_SEC" , .tbl_name = "sec" },
+
+		{ 0 }
+	};
+
+#define MAX_TX_STNS ((int)(sizeof(tx_stns)/sizeof(struct tx_stn)) - 1)
+
+	struct rx_stn {
+		const char *name;
+		int base_bucket;
+		int num_buckets;
+		int rx_entries;
+	};
+
+	struct rx_stn rx_stns[] = {
+		{ "RX_STN_CPU_0", 0, 8, 256},
+		{ "RX_STN_CPU_1", 8, 8, 256},
+		{ "RX_STN_CPU_2", 16, 8, 256},
+		{ "RX_STN_CPU_3", 24, 8, 256},
+		{ "RX_STN_CPU_4", 32, 8, 256},
+		{ "RX_STN_CPU_5", 40, 8, 256},
+		{ "RX_STN_CPU_6", 48, 8, 256},
+		{ "RX_STN_CPU_7", 56, 8, 256},
+
+		{ "RX_STN_XGS_0_TX", 64, 16, 256},
+		{ "RX_STN_XGS_1_TX", 80, 16, 256},
+
+		{ "RX_STN_GMAC", 96, 8, 256},
+   
+		{ "RX_STN_DMA", 104, 8, 256 },
+
+		{ "RX_STN_XGS_0_FR", 112, 2, 256},
+		{ "RX_STN_XGS_1_FR", 114, 2, 256},
+   
+		{ "RX_STN_SEC", 120, 8, 256 },
+   
+		{0, 0, 0, 0}
+	};
+
+#define MAX_RX_STNS ((int)(sizeof(rx_stns)/sizeof(struct rx_stn)) - 1)
+
+	struct rx_bucket {
+		const char *name;   
+		int size;
+		int tx_credits[MAX_TX_STNS];
+		int rx_stn;
+		const char *rx_stn_name;
+	};
+ 
+	static struct rx_bucket rx_buckets[] = {
+		{.name = "cpu_0_0" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_1" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_2" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_3" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_4" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_5" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_6" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_7" , .rx_stn_name = "RX_STN_CPU_0" },
+   
+		{.name = "cpu_1_0" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_1" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_2" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_3" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_4" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_5" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_6" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_7" , .rx_stn_name = "RX_STN_CPU_1" },
+   
+		{.name = "cpu_2_0" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_1" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_2" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_3" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_4" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_5" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_6" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_7" , .rx_stn_name = "RX_STN_CPU_2" },
+   
+		{.name = "cpu_3_0" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_1" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_2" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_3" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_4" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_5" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_6" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_7" , .rx_stn_name = "RX_STN_CPU_3" },
+   
+		{.name = "cpu_4_0" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_1" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_2" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_3" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_4" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_5" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_6" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_7" , .rx_stn_name = "RX_STN_CPU_4" },
+   
+		{.name = "cpu_5_0" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_1" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_2" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_3" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_4" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_5" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_6" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_7" , .rx_stn_name = "RX_STN_CPU_5" },
+   
+		{.name = "cpu_6_0" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_1" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_2" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_3" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_4" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_5" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_6" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_7" , .rx_stn_name = "RX_STN_CPU_6" },
+   
+		{.name = "cpu_7_0" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_1" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_2" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_3" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_4" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_5" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_6" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_7" , .rx_stn_name = "RX_STN_CPU_7" },
+
+		{.name = "xgs_0_tx_0" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_1" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_2" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_3" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_4" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_5" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_6" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_7" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_8" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_9" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_10" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_11" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_12" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_13" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_14" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_15" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+
+		{.name = "xgs_1_tx_0" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_1" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_2" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_3" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_4" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_5" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_6" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_7" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_8" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_9" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_10" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_11" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_12" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_13" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_14" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_15" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+
+		{.name = "gmac_rsvd_0" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_rfr_0" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_tx_0" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_tx_1" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_tx_2" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_tx_3" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_rsvd_1" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_rfr_1" , .rx_stn_name = "RX_STN_GMAC" },
+
+		{.name = "dma_chan_0" , .rx_stn_name = "RX_STN_DMA" },
+		{.name = "dma_chan_1", .rx_stn_name = "RX_STN_DMA" },
+		{.name = "dma_chan_2", .rx_stn_name = "RX_STN_DMA" },
+		{.name = "dma_chan_3", .rx_stn_name = "RX_STN_DMA" },
+   
+		{.name = "rsvd_0", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_1", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_2", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_3", .rx_stn_name = "RX_STN_RSVD" },
+
+		{.name = "xgs_0_rsvd", .rx_stn_name = "RX_STN_XGS_0_FR" },
+		{.name = "xgs_0_rfr", .rx_stn_name = "RX_STN_XGS_0_FR" },
+
+		{.name = "xgs_1_rsvd", .rx_stn_name = "RX_STN_XGS_1_FR" },
+		{.name = "xgs_1_rfr", .rx_stn_name = "RX_STN_XGS_1_FR" },
+
+		{.name = "rsvd_4", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_5", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_6", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_7", .rx_stn_name = "RX_STN_RSVD" },
+
+		{.name = "sec_pipe_0", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_pipe_1", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_pipe_2", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_pipe_3", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_rsa", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_rsvd_5", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_rsvd_6", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_rsvd_7", .rx_stn_name = "RX_STN_SEC" },
+
+		{.name = 0 }
+	};
+
+#define MAX_RX_BUCKETS ((int)(sizeof(rx_buckets)/sizeof(struct rx_bucket)) - 1)
+
+	static void add_bucket(const char *name);
+	static void modify_bucket_size(int size);
+	static void modify_bucket_tx_credit(const char *str, int credits);
+
+#define fatal_error(fmt, args...) {fprintf(stderr, fmt, ##args); exit(-1);}
+
+	%}
+
+%token TOK_BUCKET TOK_SIZE TOK_WORD TOK_INTEGER TOK_QUOTE TOK_OPEN_BRACE TOK_CLOSE_BRACE TOK_SEMICOLON 
+
+%%
+
+def: 
+| def bucket_def 
+;
+
+bucket_def: 
+TOK_BUCKET quotedname bucket_content 
+{ //printf("grammar: bucket_def start: $1=%s, $2=%s \n", $1, $2);
+	add_bucket((const char *)$2); } 
+;
+
+bucket_content: 
+| TOK_OPEN_BRACE bucket_stmts TOK_CLOSE_BRACE	       
+;
+bucket_stmts: 
+| bucket_stmts bucket_stmt TOK_SEMICOLON
+;
+
+bucket_stmt: 
+| TOK_SIZE TOK_INTEGER 
+{ //printf("grammar: $2=%d\n", $2); 
+	modify_bucket_size($2);}
+					    
+| quotedname TOK_INTEGER
+{ //printf("grammar: $1=%s, $2=%d\n", $1, $2); 
+	modify_bucket_tx_credit((const char *)$1, $2);}
+;
+
+quotedname: TOK_QUOTE TOK_WORD TOK_QUOTE { $$=$2; } ;
+
+%%
+
+static const char *input = "msgring.cfg";  
+static const char *output = "msgring.c";  
+static int debug = 0;
+
+static int lookup_rx_stn(const char *name)
+{
+	int i=0;
+
+	if (!name) return MAX_RX_STNS;
+
+	for(i=0;rx_stns[i].name;i++) 
+		if (strcasecmp(rx_stns[i].name, name)==0) break;
+
+	return i;
+}
+
+static int lookup_rx_bucket(const char *name)
+{
+	int i=0;
+
+	if (!name) return MAX_RX_BUCKETS;
+
+	for(i=0;rx_buckets[i].name;i++) 
+		if (strcasecmp(rx_buckets[i].name, name)==0) break;
+
+	return i;
+}
+
+static void init_rx_bucket(int i)
+{
+	int j=0;
+
+	rx_buckets[i].size = 0;
+	for(j=0;j<MAX_TX_STNS;j++)
+		rx_buckets[i].tx_credits[j] = 0;
+
+	rx_buckets[i].rx_stn = lookup_rx_stn(rx_buckets[i].rx_stn_name);
+}
+
+static void copy_rx_bucket(struct rx_bucket *dest, struct rx_bucket *src)
+{
+	int i=0;
+  
+	dest->size = src->size;
+	for (i=0;i<MAX_TX_STNS;i++)
+		dest->tx_credits[i] = src->tx_credits[i];
+}
+
+static void init_defaults(void)
+{
+	int i=0;
+
+	for(i=0;i<MAX_RX_BUCKETS;i++) 
+		init_rx_bucket(i);
+}
+
+static void add_bucket(const char *name)
+{
+	int id = 0;
+
+	id = lookup_rx_bucket(name);
+
+	if (id == MAX_RX_BUCKETS) {
+		fatal_error("Unrecognised bucket name %s\n", name);
+	}
+
+	copy_rx_bucket(&rx_buckets[id], &rx_buckets[MAX_RX_BUCKETS]);
+
+	init_rx_bucket(MAX_RX_BUCKETS);
+}
+
+static void modify_bucket_size(int size)
+{
+	rx_buckets[MAX_RX_BUCKETS].size = size;
+	//printf("bucket configured with size %d\n", size);
+}
+
+static void modify_bucket_tx_credit(const char *name, int credits)
+{
+	int i=0;
+
+	for(i=0;tx_stns[i].name!=NULL;i++) 
+		if (strcasecmp(tx_stns[i].name, name)==0) break;
+	if (tx_stns[i].name) {
+		rx_buckets[MAX_RX_BUCKETS].tx_credits[i] = credits;
+		//printf("Tx Station %s configured with %d tx credits\n", name, credits);
+	}
+	else {
+		fatal_error("Unknown tx station %s!\n", name);
+	}
+}
+
+static void dump_config(void)
+{
+	int i=0, j=0;
+
+	for(i=0;i<MAX_RX_BUCKETS;i++) {
+		if (rx_stns[rx_buckets[i].rx_stn].name && rx_buckets[i].size) {
+			printf("bucket %3d: size = %3d, rx_stn = %s, tx_credits: ", i, rx_buckets[i].size, 
+			       rx_stns[rx_buckets[i].rx_stn].name);
+			for(j=0;j<MAX_TX_STNS;j++) 
+				if (rx_buckets[i].tx_credits[j]) 
+					printf("<%s, %d> ", tx_stns[j].name, rx_buckets[i].tx_credits[j]);    
+			printf("\n");
+		}
+	}
+}
+
+static void check_config(void)
+{
+	int i=0, j=0, k=0;
+	int total=0;
+
+	for(i=0;rx_stns[i].name;i++) {
+		if (debug) printf("Checking \"%s\"...\n", rx_stns[i].name);
+		total = 0;
+		for(j=rx_stns[i].base_bucket;j<rx_stns[i].base_bucket+rx_stns[i].num_buckets;j++) {
+      
+			if (rx_buckets[j].size) {
+
+				{
+					int num_ones = 0;
+					for(k=0;k<8;k++) if (rx_buckets[j].size & (1<<k)) num_ones++;
+					if (num_ones > 1) 
+						fatal_error("Bucket(%d)'s size(%d) is not a power of 2\n", j, rx_buckets[j].size);
+				}
+
+				if (total % rx_buckets[j].size) 
+					fatal_error("Bucket(%d)'s base address(%d) is not aligned to it's size(%d)\n", 
+						    j, total, rx_buckets[j].size);
+
+				if (rx_buckets[j].size < 4) 
+					fatal_error("Bucket(%d) size(%d) is bad, has to be 0 or >=4\n", j, rx_buckets[j].size);
+			}
+
+			total += rx_buckets[j].size;
+		}
+		//printf("\trx_entries=%d, configured size = %d\n", rx_stns[i].rx_entries, total);
+		if (total > rx_stns[i].rx_entries) {
+			fatal_error("Total configured bucket size for %s exceeds available rx entries\n", 
+				    rx_stns[i].name);
+		}
+		for(j=rx_stns[i].base_bucket;j<rx_stns[i].base_bucket+rx_stns[i].num_buckets;j++) {
+			total = 0;
+			for(k=0;k<MAX_TX_STNS;k++) 
+				total += rx_buckets[j].tx_credits[k];
+			//printf("\tbucket %d: size = %d, total configured credits = %d\n", 
+			//j, rx_buckets[j].size, total);
+			if (total > rx_buckets[j].size) {
+				fatal_error("Total tx credits to bucket_%d exceed the bucket size\n", j);
+			}
+		}  
+	}
+	if (debug) printf("...done\n");
+} 
+
+static void gen_tables(void)
+{
+	FILE *fp = fopen(output, "w");
+	char line[1024];
+	int i=0, j=0;
+
+	if (!output) {
+		fatal_error("Unable to write to %s\n", output);
+	}
+
+	sprintf(line, "/**********************************************************\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " * -----------------DO NOT EDIT THIS FILE------------------\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " * This file has been autogenerated by the build process\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " * from \"%s\"\n", input);
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " **********************************************************/\n\n");
+	fwrite(line, strlen(line), 1, fp);
+
+	sprintf(line, "#include <asm/rmi/msgring.h>\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, "#include <linux/module.h>\n\n");
+	fwrite(line, strlen(line), 1, fp);
+
+	/* Generate Bucket Sizes data structure */
+	sprintf(line, "struct bucket_size bucket_sizes = {\n\t{");
+	fwrite(line, strlen(line), 1, fp);
+
+	for (i=0;i<MAX_RX_BUCKETS;i++) {
+		if (i && (i%8)==0) sprintf(line, "\n\t\t%d, ", rx_buckets[i].size);
+		else sprintf(line, "%3d, ", rx_buckets[i].size);
+		fwrite(line, strlen(line), 1, fp);
+	}
+  
+	sprintf(line, "\n\t}\n};\nEXPORT_SYMBOL(bucket_sizes);\n\n");
+	fwrite(line, strlen(line), 1, fp);
+
+	/* Generate Credit tables */
+	for(i=0; tx_stns[i].name; i++) {
+		sprintf(line, "struct stn_cc cc_table_%s = {{", tx_stns[i].tbl_name);
+		fwrite(line, strlen(line), 1, fp);
+
+		for (j=0;j<MAX_RX_BUCKETS;j++) {
+			if ((j % 8)==0) sprintf(line, "\n\t\t{%d", rx_buckets[j].tx_credits[i]);
+			else sprintf(line, ", %d ", rx_buckets[j].tx_credits[i]);
+			fwrite(line, strlen(line), 1, fp);
+			if ((j % 8)==7) {sprintf(line, "},"); fwrite(line, strlen(line), 1, fp);}
+		}    
+		sprintf(line, "\n\t}};\nEXPORT_SYMBOL(cc_table_%s);\n\n",
+			tx_stns[i].tbl_name);
+		fwrite(line, strlen(line), 1, fp);
+	}
+}
+
+static void usage(const char *progname)
+{
+	fprintf(stderr, "Usage: %s -i <input file> -o <output file>\n", progname);
+	exit(-1);
+}
+
+int main(int argc, char *argv[])
+{
+	int ret = 0;
+	int ch=0;
+  
+	while ( (ch=getopt(argc, argv, "hdi:o:")) != -1) {
+		switch(ch) {
+		case 'i': input = strdup(optarg); break;
+		case 'o': output = strdup(optarg); break;
+		case 'd': debug = 1; break;
+			break;
+		case 'h':
+		default:
+			usage(argv[0]);
+			break;
+		}
+	}
+	printf("Input file = \"%s\", Output file = \"%s\" \n", input, output);
+
+	yyin = fopen(input, "r");
+
+	if (yyin == NULL) {
+		fatal_error("bad input file\n");
+	}
+  
+	//printf("MAX_RX_STNS = %d, MAX_TX_STNS = %d, MAX_RX_BUCKETS = %d\n", 
+	// MAX_RX_STNS, MAX_TX_STNS, MAX_RX_BUCKETS);
+
+	init_defaults();
+  
+	ret = yyparse();
+
+	if (ret) {
+		fprintf(stderr, "Unable to Parse %s\n", input);
+		return -1;
+	}
+	printf("Finished parsing \"%s\"\n", input);
+
+	if (debug) dump_config();
+  
+	check_config();
+
+	gen_tables();
+
+	return 0;
+}
+
+
diff --git a/arch/mips/rmi/phoenix/msgring_ike.cfg b/arch/mips/rmi/phoenix/msgring_ike.cfg
new file mode 100644
index 0000000..ce12417
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring_ike.cfg
@@ -0,0 +1,1258 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES, LOSS OF USE, DATA, OR PROFITS, OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * *****************************RMI_2**********************************/
+
+
+/* 
+ * This file defines the message ring configuration for phoenix-8. It tries to allow 
+ * many different point-point communications between the message stations on the message ring
+ * and as result is _not_ the best configuration for performance
+ *
+ * The message ring on phoenix family of processors connects the cpus, gmacs, xgmac/spi4,
+ * security engine and the general purpose DMA engines. It provides a high bandwidth,
+ * low latency communication links. On traditional processors, this communication goes through
+ * which inherently does not scale very well with increasing number of cpus. 
+ * 
+ * Message ring has an in-built flow control mechanism. Every agent/station on the ring has to
+ * have software configured credits to send messages to any agent. Every receiving agent on the
+ * ring has a 256 entry FIFO that can divided into "buckets". All addressing on the ring is 
+ * in terms of buckets. There are a total 128 buckets on the ring. The total number of credits 
+ * across all sending agents should not exceed the bucket size. 
+ *
+ * Below are the receiving agents and the max number of buckets they can have
+ * 	CPU 0	: 8 buckets
+ * 	CPU 1	: 8 buckets
+ * 	CPU 2	: 8 buckets
+ * 	CPU 3	: 8 buckets
+ * 	CPU 4	: 8 buckets
+ * 	CPU 5	: 8 buckets
+ * 	CPU 6	: 8 buckets
+ * 	CPU 7	: 8 buckets
+ * 
+ * 	XGMAC 0 / SPI4 0
+ *			 TX	:	16 buckets
+ *			 FREE	:	2  buckets
+ * 	XGMAC 1 / SPI4 1
+ *			 TX	:	16 buckets
+ *			 FREE	:	2  buckets
+ * 
+ *	GMAC	: 8 buckets	
+ *	
+ *	SEC	: 8 buckets
+ * 
+ *	DMA	: 8 buckets
+ *
+ * The bucket size of a bucket should be aligned to the bucket's starting index in that
+ * receiving station's FIFO. For example, if sizes of bucket0 and bucket1 of a station 
+ * are 32 and 32, bucket2's size has to be 64. bucket size 0 is valid.
+ *
+ * The format of the file is pretty straight forward. Each bucket definition has the size
+ * and the list of sending agents to that bucket with the number of credits to send.
+ * 
+ * Undefined buckets have a size of 0 and Tx stations have 0 credits to send to that bucket.
+ *
+ *  Following are the currently supported bucket names
+ *  cpu_0_0
+ *  cpu_0_1
+ *  cpu_0_2
+ *  cpu_0_3
+ *  cpu_0_4
+ *  cpu_0_5
+ *  cpu_0_6
+ *  cpu_0_7
+ *  
+ *  cpu_1_0
+ *  cpu_1_1
+ *  cpu_1_2
+ *  cpu_1_3
+ *  cpu_1_4
+ *  cpu_1_5
+ *  cpu_1_6
+ *  cpu_1_7
+ *  
+ *  cpu_2_0
+ *  cpu_2_1
+ *  cpu_2_2
+ *  cpu_2_3
+ *  cpu_2_4
+ *  cpu_2_5
+ *  cpu_2_6
+ *  cpu_2_7
+ *  
+ *  cpu_3_0
+ *  cpu_3_1
+ *  cpu_3_2
+ *  cpu_3_3
+ *  cpu_3_4
+ *  cpu_3_5
+ *  cpu_3_6
+ *  cpu_3_7
+ *  
+ *  cpu_4_0
+ *  cpu_4_1
+ *  cpu_4_2
+ *  cpu_4_3
+ *  cpu_4_4
+ *  cpu_4_5
+ *  cpu_4_6
+ *  cpu_4_7
+ *  
+ *  cpu_5_0
+ *  cpu_5_1
+ *  cpu_5_2
+ *  cpu_5_3
+ *  cpu_5_4
+ *  cpu_5_5
+ *  cpu_5_6
+ *  cpu_5_7
+ *  
+ *  cpu_6_0
+ *  cpu_6_1
+ *  cpu_6_2
+ *  cpu_6_3
+ *  cpu_6_4
+ *  cpu_6_5
+ *  cpu_6_6
+ *  cpu_6_7
+ *  
+ *  cpu_7_0
+ *  cpu_7_1
+ *  cpu_7_2
+ *  cpu_7_3
+ *  cpu_7_4
+ *  cpu_7_5
+ *  cpu_7_6
+ *  cpu_7_7
+ *
+ *  xgs_0_tx_0
+ *  xgs_0_tx_1
+ *  xgs_0_tx_2
+ *  xgs_0_tx_3
+ *  xgs_0_tx_4
+ *  xgs_0_tx_5
+ *  xgs_0_tx_6
+ *  xgs_0_tx_7
+ *  xgs_0_tx_8
+ *  xgs_0_tx_9
+ *  xgs_0_tx_10
+ *  xgs_0_tx_11
+ *  xgs_0_tx_12
+ *  xgs_0_tx_13
+ *  xgs_0_tx_14
+ *  xgs_0_tx_15
+ *
+ *  xgs_1_tx_0
+ *  xgs_1_tx_1
+ *  xgs_1_tx_2
+ *  xgs_1_tx_3
+ *  xgs_1_tx_4
+ *  xgs_1_tx_5
+ *  xgs_1_tx_6
+ *  xgs_1_tx_7
+ *  xgs_1_tx_8
+ *  xgs_1_tx_9
+ *  xgs_1_tx_10
+ *  xgs_1_tx_11
+ *  xgs_1_tx_12
+ *  xgs_1_tx_13
+ *  xgs_1_tx_14
+ *  xgs_1_tx_15
+ *
+ *  gmac_rsvd_0
+ *  gmac_rfr_0
+ *  gmac_tx_0
+ *  gmac_tx_1
+ *  gmac_tx_2
+ *  gmac_tx_3
+ *  gmac_rsvd_1
+ *  gmac_rfr_1
+ *
+ *  xgs_0_rsvd
+ *  xgs_0_rfr
+ *
+ *  xgs_1_rsvd
+ *  xgs_1_rfr
+ *
+ *  sec_pipe_0
+ *  sec_pipe_1
+ *  sec_pipe_2
+ *  sec_pipe_3
+ *  sec_rsa
+ *
+ * Following are the currently supported Tx Agent/Station names
+ *
+ *   tx_stn_cpu_0
+ *  tx_stn_cpu_1
+ *  tx_stn_cpu_2
+ *  tx_stn_cpu_3
+ *  tx_stn_cpu_4
+ *  tx_stn_cpu_5
+ *  tx_stn_cpu_6
+ *  tx_stn_cpu_7
+ *
+ *   tx_stn_xgs_0
+ *  tx_stn_xgs_1
+ *
+ *   tx_stn_gmac
+ *
+ *   tx_stn_dma
+ *
+ *   tx_stn_sec
+ *
+ *
+ * 
+ */
+
+/*************************************************************/
+// CPU_0 Message Station 
+
+bucket "cpu_0_0" { 
+	size 32;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_0_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_0_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_0_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_0_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_0_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_0_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_0_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+/*************************************************************/
+// CPU_1 Message Station 
+
+bucket "cpu_1_0" { 
+	size 32;
+/*
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cpu_0" 16; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_1_1" { 
+	size 32; 
+/*
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_cpu_0" 16; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_1_2" { 
+	size 32; 
+/*
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_cpu_0" 16; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_1_3" { 
+	size 32; 
+/*	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_cpu_0" 20; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_1_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_1_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_1_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_1_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+/*************************************************************/
+// CPU_2 Message Station 
+
+bucket "cpu_2_0" { 
+	size 32;
+//	"tx_stn_xgs_0" 8;
+//	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cpu_0" 16;
+}
+bucket "cpu_2_1" { 
+	size 32; 
+//	"tx_stn_xgs_0" 8;
+//	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_cpu_0" 16;
+}
+bucket "cpu_2_2" { 
+	size 32; 
+//	"tx_stn_xgs_0" 8;
+//	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_cpu_0" 16;
+}
+bucket "cpu_2_3" { 
+	size 32; 
+//	"tx_stn_xgs_0" 8;
+//	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_cpu_0" 16;
+}
+bucket "cpu_2_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_2_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_2_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_2_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+/*************************************************************/
+// CPU_3 Message Station 
+
+bucket "cpu_3_0" { 
+	size 32;
+//	"tx_stn_xgs_0" 8;
+//	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cpu_0" 16;
+}
+bucket "cpu_3_1" { 
+	size 32; 
+//	"tx_stn_xgs_0" 8;
+//	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_cpu_0" 16;
+}
+bucket "cpu_3_2" { 
+	size 32; 
+//	"tx_stn_xgs_0" 8;
+//	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_cpu_0" 16;
+}
+bucket "cpu_3_3" { 
+	size 32; 
+//	"tx_stn_xgs_0" 8;
+//	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_cpu_0" 16;
+}
+bucket "cpu_3_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_3_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_3_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_3_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+/*************************************************************/
+// CPU_4 Message Station 
+
+bucket "cpu_4_0" { 
+	size 32;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_4_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_4_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_4_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_4_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_4_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_4_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_4_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+/*************************************************************/
+// CPU_5 Message Station 
+
+bucket "cpu_5_0" { 
+	size 32;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_5_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_5_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_5_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_5_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_5_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_5_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_5_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+
+/*************************************************************/
+// CPU_6 Message Station 
+
+bucket "cpu_6_0" { 
+	size 32;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_6_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_6_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_6_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_6_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_6_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_6_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_6_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+
+/*************************************************************/
+// CPU_7 Message Station 
+
+bucket "cpu_7_0" { 
+	size 32;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_7_1" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_7_2" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_7_3" { 
+	size 32; 
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_7_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_7_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_7_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_7_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+
+/*************************************************************/
+// GMAC Message Station 
+
+bucket "gmac_rfr_0" {
+	size 32;
+	"tx_stn_cpu_0" 2;
+	"tx_stn_cpu_1" 2;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+	"tx_stn_gmac" 4;
+}
+
+bucket "gmac_tx_0" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_1" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_2" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_3" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_rfr_1" {
+	size 32;
+	"tx_stn_cpu_0" 2;
+	"tx_stn_cpu_1" 2;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+	"tx_stn_gmac" 4;
+}
+/*********************************************/
+// xgmac
+bucket "xgs_0_rfr" {
+    size 32;
+    "tx_stn_cpu_0" 2;
+    "tx_stn_cpu_1" 2;
+    "tx_stn_cpu_2" 2;
+    "tx_stn_cpu_3" 2;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+    "tx_stn_xgs_0" 4;
+    "tx_stn_xgs_1" 4;
+}
+
+bucket "xgs_0_tx_0" {
+    size 32;
+    "tx_stn_cpu_0" 4;
+    "tx_stn_cpu_1" 4;
+    "tx_stn_cpu_2" 4;
+    "tx_stn_cpu_3" 4;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+}
+
+bucket "xgs_0_tx_1" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_2" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_3" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_4" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+bucket "xgs_0_tx_5" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_6" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_7" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_8" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_9" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_10" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_0_tx_11" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_12" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_13" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_14" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_rfr" {
+    size 32;
+    "tx_stn_cpu_0" 2;
+    "tx_stn_cpu_1" 2;
+    "tx_stn_cpu_2" 2;
+    "tx_stn_cpu_3" 2;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+    "tx_stn_xgs_0" 4;
+    "tx_stn_xgs_1" 4;
+}
+
+bucket "xgs_1_tx_0" {
+    size 32;
+    "tx_stn_cpu_0" 4;
+    "tx_stn_cpu_1" 4;
+    "tx_stn_cpu_2" 4;
+    "tx_stn_cpu_3" 4;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+}
+
+
+bucket "xgs_1_tx_1" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_2" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_3" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_4" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_5" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_6" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_7" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_tx_8" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_tx_9" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_tx_10" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_11" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_12" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_13" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_14" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+
+
+
+
+/*************************************************************/
+// Security Message Station 
+
+bucket "sec_pipe_0" {
+        size 128;
+        "tx_stn_cpu_0" 16;
+        "tx_stn_cpu_1" 16;
+        "tx_stn_cpu_2" 16;
+        "tx_stn_cpu_3" 16;
+        "tx_stn_cpu_4" 16;
+        "tx_stn_cpu_5" 16;
+        "tx_stn_cpu_6" 16;
+        "tx_stn_cpu_7" 16;
+}
+
+bucket "sec_rsa" {
+        size 128;
+        "tx_stn_cpu_0" 16;
+        "tx_stn_cpu_1" 16;
+        "tx_stn_cpu_2" 16;
+        "tx_stn_cpu_3" 16;
+        "tx_stn_cpu_4" 16;
+        "tx_stn_cpu_5" 16;
+        "tx_stn_cpu_6" 16;
+        "tx_stn_cpu_7" 16;
+}
+
+bucket "dma_chan_0" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+bucket "dma_chan_1" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+
+bucket "dma_chan_2" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+
+bucket "dma_chan_3" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
diff --git a/arch/mips/rmi/phoenix/msgring_ike_xls.cfg b/arch/mips/rmi/phoenix/msgring_ike_xls.cfg
new file mode 100644
index 0000000..c612617
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring_ike_xls.cfg
@@ -0,0 +1,592 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES, LOSS OF USE, DATA, OR PROFITS, OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * *****************************RMI_2**********************************/
+
+
+/* 
+ * This file defines the message ring configuration for XLS two core. It tries to allow 
+ * many different point-point communications between the message stations on the message ring
+ * and as result is _not_ the best configuration for performance
+ *
+ * The message ring on phoenix family of processors connects the cpus, gmacs, xgmac/spi4,
+ * security engine and the general purpose DMA engines. It provides a high bandwidth,
+ * low latency communication links. On traditional processors, this communication goes through
+ * which inherently does not scale very well with increasing number of cpus. 
+ * 
+ * Message ring has an in-built flow control mechanism. Every agent/station on the ring has to
+ * have software configured credits to send messages to any agent. Every receiving agent on the
+ * ring has a 256 entry FIFO that can divided into "buckets". All addressing on the ring is 
+ * in terms of buckets. There are a total 128 buckets on the ring. The total number of credits 
+ * across all sending agents should not exceed the bucket size. 
+ *
+ * Below are the receiving agents and the max number of buckets they can have
+ * 	CPU 0	: 8 buckets
+ * 	CPU 1	: 8 buckets
+ * 
+ *	GMAC	: 8 buckets	
+ *	
+ *	SEC	: 8 buckets
+ * 
+ *	DMA	: 8 buckets
+ * 
+ *	CMP	: Currently disabled. 
+ *
+ * The bucket size of a bucket should be aligned to the bucket's starting index in that
+ * receiving station's FIFO. For example, if sizes of bucket0 and bucket1 of a station 
+ * are 32 and 32, bucket2's size has to be 64. bucket size 0 is valid.
+ *
+ * The format of the file is pretty straight forward. Each bucket definition has the size
+ * and the list of sending agents to that bucket with the number of credits to send.
+ * 
+ * Undefined buckets have a size of 0 and Tx stations have 0 credits to send to that bucket.
+ *
+ *  Following are the currently supported bucket names
+ *  cpu_0_0
+ *  cpu_0_1
+ *  cpu_0_2
+ *  cpu_0_3
+ *  cpu_0_4
+ *  cpu_0_5
+ *  cpu_0_6
+ *  cpu_0_7
+ *  
+ *  cpu_1_0
+ *  cpu_1_1
+ *  cpu_1_2
+ *  cpu_1_3
+ *  cpu_1_4
+ *  cpu_1_5
+ *  cpu_1_6
+ *  cpu_1_7
+ *
+ *  enabled only for xls-b0
+ *  cpu_2_0
+ *  cpu_2_1
+ *  cpu_2_2
+ *  cpu_2_3
+ *  cpu_2_4
+ *  cpu_2_5
+ *  cpu_2_6
+ *  cpu_2_7
+ *  
+ *  enabled only for xls-b0
+ *  cpu_3_0
+ *  cpu_3_1
+ *  cpu_3_2
+ *  cpu_3_3
+ *  cpu_3_4
+ *  cpu_3_5
+ *  cpu_3_6
+ *  cpu_3_7
+ *
+ *  gmac0_rfr
+ *  gmac0_tx_0
+ *  gmac0_tx_1
+ *  gmac0_tx_2
+ *  gmac0_tx_3
+ *  
+ *  gmac1_rfr
+ *  gmac1_tx_0
+ *  gmac1_tx_1
+ *  gmac1_tx_2
+ *  gmac1_tx_3
+ *
+ *  sec_pipe_0
+ *  sec_rsa
+ *
+ * Following are the currently supported Tx Agent/Station names
+ *
+ *  tx_stn_cpu_0
+ *  tx_stn_cpu_1
+ *
+ *  tx_stn_gmac0
+ *  tx_stn_gmac1
+ *
+ *  tx_stn_dma
+ *
+ *  tx_stn_sec
+ *
+ * 
+ */
+
+/*************************************************************/
+// CPU_0 Message Station 
+
+bucket "cpu_0_0" { 
+	size 32;
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  6;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+	"tx_stn_cpu_0" 1;
+	"tx_stn_cpu_1" 1; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_0_1" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_0_2" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_0_3" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_0_4" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+}
+bucket "cpu_0_5" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+}
+bucket "cpu_0_6" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+}
+bucket "cpu_0_7" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+}
+
+/*************************************************************/
+// CPU_1 Message Station 
+
+bucket "cpu_1_0" { 
+	size 32;
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+	"tx_stn_cpu_0" 12; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_1_1" { 
+	size 32; 
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+	"tx_stn_cpu_0" 12; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_1_2" { 
+	size 32; 
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+	"tx_stn_cpu_0" 12; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_1_3" { 
+	size 32; 
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 2;
+	"tx_stn_cmp" 2;
+	"tx_stn_cpu_0" 16; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_1_4" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_1_5" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_1_6" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_1_7" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+
+/*************************************************************/
+// CPU_2 Message Station 
+
+bucket "cpu_2_0" { 
+	size 32;
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+	"tx_stn_cpu_0" 12; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_2_1" { 
+	size 32; 
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+	"tx_stn_cpu_0" 12; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_2_2" { 
+	size 32; 
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+	"tx_stn_cpu_0" 12; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_2_3" { 
+	size 32; 
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 2;
+	"tx_stn_cmp" 2;
+	"tx_stn_cpu_0" 16; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_2_4" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_5" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_6" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_7" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+
+
+/*************************************************************/
+// CPU_3 Message Station 
+bucket "cpu_3_0" { 
+	size 32;
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+	"tx_stn_cpu_0" 12; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_3_1" { 
+	size 32; 
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+	"tx_stn_cpu_0" 12; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_3_2" { 
+	size 32; 
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+	"tx_stn_cpu_0" 12; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_3_3" { 
+	size 32; 
+	"tx_stn_gmac0" 4;
+	"tx_stn_gmac1" 4;
+	"tx_stn_sec"  4;
+	"tx_stn_dma" 2;
+	"tx_stn_cmp" 2;
+	"tx_stn_cpu_0" 16; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_3_4" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_5" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_6" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_7" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+
+/*************************************************************/
+
+// GMAC Message Station 
+
+bucket "gmac0_rfr" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+}
+
+bucket "gmac0_tx_0" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac0_tx_1" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac0_tx_2" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac0_tx_3" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac1_rfr" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+}
+
+bucket "gmac1_tx_0" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac1_tx_1" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac1_tx_2" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac1_tx_3" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+/*************************************************************/
+// Security Message Station 
+
+bucket "sec_pipe_0" {
+	size 128;
+	"tx_stn_cpu_0" 32;
+	"tx_stn_cpu_1" 32;
+	"tx_stn_cpu_2" 32;
+	"tx_stn_cpu_3" 32;
+}
+
+bucket "sec_rsa_ecc" {
+	size 128;
+	"tx_stn_cpu_0" 32;
+	"tx_stn_cpu_1" 32;
+	"tx_stn_cpu_2" 32;
+	"tx_stn_cpu_3" 32;
+}
+
+bucket "dma_chan_0" {
+	size 64;
+	"tx_stn_cpu_0" 16;
+	"tx_stn_cpu_1" 16;
+	"tx_stn_cpu_2" 16;
+	"tx_stn_cpu_3" 16;
+}
+bucket "dma_chan_1" {
+	size 64;
+	"tx_stn_cpu_0" 16;
+	"tx_stn_cpu_1" 16;
+	"tx_stn_cpu_2" 16;
+	"tx_stn_cpu_3" 16;
+}
+
+bucket "dma_chan_2" {
+	size 64;
+	"tx_stn_cpu_0" 16;
+	"tx_stn_cpu_1" 16;
+	"tx_stn_cpu_2" 16;
+	"tx_stn_cpu_3" 16;
+}
+
+bucket "dma_chan_3" {
+	size 64;
+	"tx_stn_cpu_0" 16;
+	"tx_stn_cpu_1" 16;
+	"tx_stn_cpu_2" 16;
+	"tx_stn_cpu_3" 16;
+}
+
+/*************************************************************/
+// Compression Message Station
+
+bucket "cmp_0" {
+        size 32; 
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+}
+
+bucket "cmp_1" { 
+        size 32;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+}
+
+bucket "cmp_2" {
+        size 32; 
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+}
+
+bucket "cmp_3" {      
+        size 32;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+}
+
diff --git a/arch/mips/rmi/phoenix/msgring_openssl.cfg b/arch/mips/rmi/phoenix/msgring_openssl.cfg
new file mode 100644
index 0000000..d0242ac
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring_openssl.cfg
@@ -0,0 +1,1311 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES, LOSS OF USE, DATA, OR PROFITS, OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * *****************************RMI_2**********************************/
+
+
+/*
+ * This file defines the message ring configuration for phoenix-8. It tries to allow
+ * many different point-point communications between the message stations on the message ring
+ * and as result is _not_ the best configuration for performance
+ *
+ * The message ring on phoenix family of processors connects the cpus, gmacs, xgmac/spi4,
+ * security engine and the general purpose DMA engines. It provides a high bandwidth,
+ * low latency communication links. On traditional processors, this communication goes through
+ * which inherently does not scale very well with increasing number of cpus.
+ *
+ * Message ring has an in-built flow control mechanism. Every agent/station on the ring has to
+ * have software configured credits to send messages to any agent. Every receiving agent on the
+ * ring has a 256 entry FIFO that can divided into "buckets". All addressing on the ring is
+ * in terms of buckets. There are a total 128 buckets on the ring. The total number of credits
+ * across all sending agents should not exceed the bucket size.
+ *
+ * Below are the receiving agents and the max number of buckets they can have
+ * 	CPU 0	: 8 buckets
+ * 	CPU 1	: 8 buckets
+ * 	CPU 2	: 8 buckets
+ * 	CPU 3	: 8 buckets
+ * 	CPU 4	: 8 buckets
+ * 	CPU 5	: 8 buckets
+ * 	CPU 6	: 8 buckets
+ * 	CPU 7	: 8 buckets
+ *
+ * 	XGMAC 0 / SPI4 0
+ *			 TX	:	16 buckets
+ *			 FREE	:	2  buckets
+ * 	XGMAC 1 / SPI4 1
+ *			 TX	:	16 buckets
+ *			 FREE	:	2  buckets
+ *
+ *	GMAC	: 8 buckets
+ *
+ *	SEC	: 8 buckets
+ *
+ *	DMA	: 8 buckets
+ *
+ * The bucket size of a bucket should be aligned to the bucket's starting index in that
+ * receiving station's FIFO. For example, if sizes of bucket0 and bucket1 of a station
+ * are 32 and 32, bucket2's size has to be 64. bucket size 0 is valid.
+ *
+ * The format of the file is pretty straight forward. Each bucket definition has the size
+ * and the list of sending agents to that bucket with the number of credits to send.
+ *
+ * Undefined buckets have a size of 0 and Tx stations have 0 credits to send to that bucket.
+ *
+ *  Following are the currently supported bucket names
+ *  cpu_0_0
+ *  cpu_0_1
+ *  cpu_0_2
+ *  cpu_0_3
+ *  cpu_0_4
+ *  cpu_0_5
+ *  cpu_0_6
+ *  cpu_0_7
+ *
+ *  cpu_1_0
+ *  cpu_1_1
+ *  cpu_1_2
+ *  cpu_1_3
+ *  cpu_1_4
+ *  cpu_1_5
+ *  cpu_1_6
+ *  cpu_1_7
+ *
+ *  cpu_2_0
+ *  cpu_2_1
+ *  cpu_2_2
+ *  cpu_2_3
+ *  cpu_2_4
+ *  cpu_2_5
+ *  cpu_2_6
+ *  cpu_2_7
+ *
+ *  cpu_3_0
+ *  cpu_3_1
+ *  cpu_3_2
+ *  cpu_3_3
+ *  cpu_3_4
+ *  cpu_3_5
+ *  cpu_3_6
+ *  cpu_3_7
+ *
+ *  cpu_4_0
+ *  cpu_4_1
+ *  cpu_4_2
+ *  cpu_4_3
+ *  cpu_4_4
+ *  cpu_4_5
+ *  cpu_4_6
+ *  cpu_4_7
+ *
+ *  cpu_5_0
+ *  cpu_5_1
+ *  cpu_5_2
+ *  cpu_5_3
+ *  cpu_5_4
+ *  cpu_5_5
+ *  cpu_5_6
+ *  cpu_5_7
+ *
+ *  cpu_6_0
+ *  cpu_6_1
+ *  cpu_6_2
+ *  cpu_6_3
+ *  cpu_6_4
+ *  cpu_6_5
+ *  cpu_6_6
+ *  cpu_6_7
+ *
+ *  cpu_7_0
+ *  cpu_7_1
+ *  cpu_7_2
+ *  cpu_7_3
+ *  cpu_7_4
+ *  cpu_7_5
+ *  cpu_7_6
+ *  cpu_7_7
+ *
+ *  xgs_0_tx_0
+ *  xgs_0_tx_1
+ *  xgs_0_tx_2
+ *  xgs_0_tx_3
+ *  xgs_0_tx_4
+ *  xgs_0_tx_5
+ *  xgs_0_tx_6
+ *  xgs_0_tx_7
+ *  xgs_0_tx_8
+ *  xgs_0_tx_9
+ *  xgs_0_tx_10
+ *  xgs_0_tx_11
+ *  xgs_0_tx_12
+ *  xgs_0_tx_13
+ *  xgs_0_tx_14
+ *  xgs_0_tx_15
+ *
+ *  xgs_1_tx_0
+ *  xgs_1_tx_1
+ *  xgs_1_tx_2
+ *  xgs_1_tx_3
+ *  xgs_1_tx_4
+ *  xgs_1_tx_5
+ *  xgs_1_tx_6
+ *  xgs_1_tx_7
+ *  xgs_1_tx_8
+ *  xgs_1_tx_9
+ *  xgs_1_tx_10
+ *  xgs_1_tx_11
+ *  xgs_1_tx_12
+ *  xgs_1_tx_13
+ *  xgs_1_tx_14
+ *  xgs_1_tx_15
+ *
+ *  gmac_rsvd_0
+ *  gmac_rfr_0
+ *  gmac_tx_0
+ *  gmac_tx_1
+ *  gmac_tx_2
+ *  gmac_tx_3
+ *  gmac_rsvd_1
+ *  gmac_rfr_1
+ *
+ *  xgs_0_rsvd
+ *  xgs_0_rfr
+ *
+ *  xgs_1_rsvd
+ *  xgs_1_rfr
+ *
+ *  sec_pipe_0
+ *  sec_pipe_1
+ *  sec_pipe_2
+ *  sec_pipe_3
+ *  sec_rsa
+ *
+ * Following are the currently supported Tx Agent/Station names
+ *
+ *   tx_stn_cpu_0
+ *  tx_stn_cpu_1
+ *  tx_stn_cpu_2
+ *  tx_stn_cpu_3
+ *  tx_stn_cpu_4
+ *  tx_stn_cpu_5
+ *  tx_stn_cpu_6
+ *  tx_stn_cpu_7
+ *
+ *   tx_stn_xgs_0
+ *  tx_stn_xgs_1
+ *
+ *   tx_stn_gmac
+ *
+ *   tx_stn_dma
+ *
+ *   tx_stn_sec
+ *
+ *
+ *
+ */
+
+/*************************************************************/
+// CPU_0 Message Station
+
+bucket "cpu_0_0" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 4;
+	"tx_stn_xgs_1" 4;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  12;
+	"tx_stn_dma" 4;
+        "tx_stn_cpu_1" 1; /* NEEDED BY RMIOS IPSEC */
+        "tx_stn_cpu_2" 1;
+        "tx_stn_cpu_3" 1;
+        "tx_stn_cpu_4" 1;
+        "tx_stn_cpu_5" 1;
+        "tx_stn_cpu_6" 1;
+        "tx_stn_cpu_7" 1;
+}
+bucket "cpu_0_1" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_0_2" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_0_3" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_0_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_0_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_0_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_0_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+/*************************************************************/
+// CPU_1 Message Station
+
+bucket "cpu_1_0" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_1_1" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_1_2" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_1_3" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+    "tx_stn_cpu_0" 4; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_1_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_1_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_1_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_1_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+/*************************************************************/
+// CPU_2 Message Station
+
+bucket "cpu_2_0" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_2_1" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_2_2" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_2_3" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_2_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_2_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_2_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_2_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+/*************************************************************/
+// CPU_3 Message Station
+
+bucket "cpu_3_0" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_3_1" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_3_2" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_3_3" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_3_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_3_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_3_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_3_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+/*************************************************************/
+// CPU_4 Message Station
+
+bucket "cpu_4_0" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_4_1" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_4_2" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_4_3" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_4_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_4_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_4_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_4_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+/*************************************************************/
+// CPU_5 Message Station
+
+bucket "cpu_5_0" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_5_1" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_5_2" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_5_3" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_5_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_5_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_5_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_5_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+
+/*************************************************************/
+// CPU_6 Message Station
+
+bucket "cpu_6_0" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_6_1" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_6_2" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_6_3" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_6_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_6_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_6_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_6_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+
+/*************************************************************/
+// CPU_7 Message Station
+
+bucket "cpu_7_0" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_7_1" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_7_2" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_7_3" {
+	size 32;
+/*BLAH
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+BLAH*/
+	"tx_stn_gmac" 8;
+	"tx_stn_sec"  16;
+}
+bucket "cpu_7_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_7_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_7_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+bucket "cpu_7_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+	"tx_stn_xgs_0" 8;
+	"tx_stn_xgs_1" 8;
+}
+
+
+/*************************************************************/
+// GMAC Message Station
+
+bucket "gmac_rfr_0" {
+	size 32;
+	"tx_stn_cpu_0" 2;
+	"tx_stn_cpu_1" 2;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+	"tx_stn_gmac" 4;
+}
+
+bucket "gmac_tx_0" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_1" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_2" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_3" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_rfr_1" {
+	size 32;
+	"tx_stn_cpu_0" 2;
+	"tx_stn_cpu_1" 2;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+	"tx_stn_gmac" 4;
+}
+/*********************************************/
+// xgmac
+bucket "xgs_0_rfr" {
+    size 32;
+    "tx_stn_cpu_0" 2;
+    "tx_stn_cpu_1" 2;
+    "tx_stn_cpu_2" 2;
+    "tx_stn_cpu_3" 2;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+    "tx_stn_xgs_0" 4;
+    "tx_stn_xgs_1" 4;
+}
+
+bucket "xgs_0_tx_0" {
+    size 32;
+    "tx_stn_cpu_0" 4;
+    "tx_stn_cpu_1" 4;
+    "tx_stn_cpu_2" 4;
+    "tx_stn_cpu_3" 4;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+}
+
+bucket "xgs_0_tx_1" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_2" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_3" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_4" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+bucket "xgs_0_tx_5" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_6" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_7" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_8" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_9" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_10" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_0_tx_11" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_12" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_13" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_0_tx_14" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_rfr" {
+    size 32;
+    "tx_stn_cpu_0" 2;
+    "tx_stn_cpu_1" 2;
+    "tx_stn_cpu_2" 2;
+    "tx_stn_cpu_3" 2;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+    "tx_stn_xgs_0" 4;
+    "tx_stn_xgs_1" 4;
+}
+
+bucket "xgs_1_tx_0" {
+    size 32;
+    "tx_stn_cpu_0" 4;
+    "tx_stn_cpu_1" 4;
+    "tx_stn_cpu_2" 4;
+    "tx_stn_cpu_3" 4;
+    "tx_stn_cpu_4" 4;
+    "tx_stn_cpu_5" 4;
+    "tx_stn_cpu_6" 4;
+    "tx_stn_cpu_7" 4;
+}
+
+
+bucket "xgs_1_tx_1" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_2" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_3" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_4" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_5" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_6" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_7" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_tx_8" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_tx_9" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+bucket "xgs_1_tx_10" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_11" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_12" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_13" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+bucket "xgs_1_tx_14" {
+  size 16;
+  "tx_stn_cpu_0" 2;
+  "tx_stn_cpu_1" 2;
+  "tx_stn_cpu_2" 2;
+  "tx_stn_cpu_3" 2;
+  "tx_stn_cpu_4" 2;
+  "tx_stn_cpu_5" 2;
+  "tx_stn_cpu_6" 2;
+  "tx_stn_cpu_7" 2;
+}
+
+
+
+
+
+
+/*************************************************************/
+// Security Message Station
+
+bucket "sec_pipe_0" {
+        size 128;
+        "tx_stn_cpu_0" 16;
+        "tx_stn_cpu_1" 16;
+        "tx_stn_cpu_2" 16;
+        "tx_stn_cpu_3" 16;
+        "tx_stn_cpu_4" 16;
+        "tx_stn_cpu_5" 16;
+        "tx_stn_cpu_6" 16;
+        "tx_stn_cpu_7" 16;
+}
+
+bucket "sec_rsa" {
+        size 128;
+        "tx_stn_cpu_0" 16;
+        "tx_stn_cpu_1" 16;
+        "tx_stn_cpu_2" 16;
+        "tx_stn_cpu_3" 16;
+        "tx_stn_cpu_4" 16;
+        "tx_stn_cpu_5" 16;
+        "tx_stn_cpu_6" 16;
+        "tx_stn_cpu_7" 16;
+}
+
+bucket "dma_chan_0" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+bucket "dma_chan_1" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+
+bucket "dma_chan_2" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+
+bucket "dma_chan_3" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
diff --git a/arch/mips/rmi/phoenix/msgring_shared.cfg b/arch/mips/rmi/phoenix/msgring_shared.cfg
new file mode 100644
index 0000000..079a7e5
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring_shared.cfg
@@ -0,0 +1,487 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES, LOSS OF USE, DATA, OR PROFITS, OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * *****************************RMI_2**********************************/
+/*
+ *
+ * This file defines the message ring configuration for phoenix-8. It tries to allow
+ * many different point-point communications between the message stations on the
+ * message ring  and as result is _not_ the best configuration for performance
+ *
+ * Please refer to msgring.cfg for more information about editing message
+ * ring configuration files.
+ *
+ * This file is used in the specific cases where: 
+ *  1. linux is brought up on XLR ATX-II board with xlr_loader, shared_core 
+ *     and own_gmac options. 
+ *     Under this configuration, Linux and RMIOS applications can share a 
+ *     XLR core and also the message ring resources. However, Linux is 
+ *     allowed to use only gmac message ring stations. Based on how RMIOS 
+ *     application use other message ring stations, this file has to be edited. 
+ *     It is recommended that Linux intialize the message ring credits required 
+ *     for all cpus on shared core including those that will run RMIOS 
+ *     applications.
+ *
+ *  2. linux is brought up on ATX-III PCI-X card with xlr_loader and 
+ *     shared_core option.
+ *     Under this configuration, linux needs message ring credits for dma
+ *     station. Based on how RMIOS application use other message ring stations,
+ *     this file has to be edited. It is recommended that Linux intialize the
+ *     message ring credits required for all cpus on shared core including
+ *     those that will run RMIOS applications.
+ *
+ * Credits are assigned in this configuration so that both the above cases
+ * are handled. This is not the best configuration for performance or for
+ * specific requirements.
+ *
+ */
+
+/*************************************************************/
+// CPU_0 Message Station 
+
+bucket "cpu_0_0" { 
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_0_1" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_0_2" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_0_3" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_0_4" {
+	size 32;
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_0_5" {
+	size 32;
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_0_6" {
+	size 32;
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_0_7" {
+	size 32;
+	"tx_stn_gmac" 8;
+}
+
+/*************************************************************/
+// CPU_1 Message Station 
+
+bucket "cpu_1_0" { 
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_1_1" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_1_2" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_1_3" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_1_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_1_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_1_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_1_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+
+/*************************************************************/
+// CPU_2 Message Station 
+
+bucket "cpu_2_0" { 
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_2_1" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_2_2" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_2_3" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_2_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_2_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_2_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_2_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+
+/*************************************************************/
+// CPU_3 Message Station 
+
+bucket "cpu_3_0" { 
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_3_1" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_3_2" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_3_3" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_3_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_3_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_3_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_3_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+
+/*************************************************************/
+// CPU_4 Message Station 
+
+bucket "cpu_4_0" { 
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_4_1" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_4_2" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_4_3" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_4_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_4_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_4_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_4_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+
+/*************************************************************/
+// CPU_5 Message Station 
+
+bucket "cpu_5_0" { 
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_5_1" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_5_2" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_5_3" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_5_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_5_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_5_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_5_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+
+
+/*************************************************************/
+// CPU_6 Message Station 
+
+bucket "cpu_6_0" { 
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_6_1" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_6_2" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_6_3" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_6_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_6_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_6_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_6_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+
+
+/*************************************************************/
+// CPU_7 Message Station 
+
+bucket "cpu_7_0" { 
+	size 32;
+	"tx_stn_gmac" 8;
+	"tx_stn_dma" 4;
+}
+bucket "cpu_7_1" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_7_2" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_7_3" { 
+	size 32; 
+	"tx_stn_gmac" 8;
+}
+bucket "cpu_7_4" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_7_5" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_7_6" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+bucket "cpu_7_7" {
+	size 32;
+	"tx_stn_gmac" 16;
+}
+
+
+/*************************************************************/
+// GMAC Message Station 
+
+bucket "gmac_rfr_0" {
+	size 32;
+	"tx_stn_cpu_0" 2;
+	"tx_stn_cpu_1" 2;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+	"tx_stn_gmac" 4;
+}
+
+bucket "gmac_tx_0" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_1" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_2" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_tx_3" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+}
+
+bucket "gmac_rfr_1" {
+	size 32;
+	"tx_stn_cpu_0" 2;
+	"tx_stn_cpu_1" 2;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_cpu_4" 4;
+	"tx_stn_cpu_5" 4;
+	"tx_stn_cpu_6" 4;
+	"tx_stn_cpu_7" 4;
+	"tx_stn_gmac" 4;
+}
+
+bucket "dma_chan_0" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+bucket "dma_chan_1" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+
+bucket "dma_chan_2" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+
+bucket "dma_chan_3" {
+        size 64;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+        "tx_stn_cpu_4" 8;
+        "tx_stn_cpu_5" 8;
+        "tx_stn_cpu_6" 8;
+        "tx_stn_cpu_7" 8;
+}
+
+/*********************************************/
diff --git a/arch/mips/rmi/phoenix/msgring_shared.l b/arch/mips/rmi/phoenix/msgring_shared.l
new file mode 100644
index 0000000..33bb94a
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring_shared.l
@@ -0,0 +1,44 @@
+%{
+#include <stdio.h>
+#include <string.h>
+#include "msgring.yacc.h"
+
+
+int yyerror(const char *str)
+{
+  fprintf(stderr, "%s\n", str);
+  return 1;
+}
+
+%}
+
+%x c_comment
+
+%%
+
+"/*"                    BEGIN(c_comment); /* c-style comment */
+<c_comment>[^*\n]*        /* eat anything that is not a * */
+<c_comment>"*"+[^*/\n]*   /* eat up * s not followed by a / */
+<c_comment>\n
+<c_comment>"*"+"/"      BEGIN(INITIAL);
+
+"//"[^\n]*"\n"         ; /* eat up one-line (C++-style) commens */
+
+bucket                  yylval = (unsigned long)"bucket"; return TOK_BUCKET;
+size                    yylval = (unsigned long)"size"; return TOK_SIZE;
+[a-zA-Z_][a-zA-Z_0-9]*    yylval = (unsigned long)strdup(yytext); return TOK_WORD;
+[0-9]+                  yylval = atoi(yytext); return TOK_INTEGER;
+\"                      yylval = (unsigned long)"\""; return TOK_QUOTE;
+\{                      yylval = (unsigned long)"{"; return TOK_OPEN_BRACE;
+\}                      yylval = (unsigned long)"}"; return TOK_CLOSE_BRACE;
+;                       yylval = (unsigned long)";"; return TOK_SEMICOLON;
+\n                      /* ignore newline */;
+[ \t]+                  /* ignore whitespace */;
+.                       yyerror("Unknown token\n");
+%%
+
+int yywrap()
+{
+  return 1;
+}
+
diff --git a/arch/mips/rmi/phoenix/msgring_shared.y b/arch/mips/rmi/phoenix/msgring_shared.y
new file mode 100644
index 0000000..0b7934b
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring_shared.y
@@ -0,0 +1,544 @@
+%{
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdarg.h>
+#include <unistd.h>
+
+	extern FILE *yyin;
+	extern void yyerror(const char *);
+	int yydebug = 1;
+
+	//#define MAX_RX_BUCKETS 128
+
+	struct tx_stn {
+		const char *name;
+		const char *tbl_name;
+	};
+
+	struct tx_stn tx_stns[] = {
+		{ .name = "TX_STN_CPU_0" , .tbl_name = "cpu_0" },
+		{ .name = "TX_STN_CPU_1" , .tbl_name = "cpu_1" },
+		{ .name = "TX_STN_CPU_2" , .tbl_name = "cpu_2" },
+		{ .name = "TX_STN_CPU_3" , .tbl_name = "cpu_3" },
+		{ .name = "TX_STN_CPU_4" , .tbl_name = "cpu_4" },
+		{ .name = "TX_STN_CPU_5" , .tbl_name = "cpu_5" },
+		{ .name = "TX_STN_CPU_6" , .tbl_name = "cpu_6" },
+		{ .name = "TX_STN_CPU_7" , .tbl_name = "cpu_7" },
+
+		{ .name = "TX_STN_XGS_0" , .tbl_name = "xgs_0" },
+		{ .name = "TX_STN_XGS_1" , .tbl_name = "xgs_1" },
+
+		{ .name = "TX_STN_GMAC" , .tbl_name = "gmac" },
+
+		{ .name = "TX_STN_DMA" , .tbl_name = "dma" },
+
+		{ .name = "TX_STN_SEC" , .tbl_name = "sec" },
+
+		{ 0 }
+	};
+
+#define MAX_TX_STNS ((int)(sizeof(tx_stns)/sizeof(struct tx_stn)) - 1)
+
+	struct rx_stn {
+		const char *name;
+		int base_bucket;
+		int num_buckets;
+		int rx_entries;
+	};
+
+	struct rx_stn rx_stns[] = {
+		{ "RX_STN_CPU_0", 0, 8, 256},
+		{ "RX_STN_CPU_1", 8, 8, 256},
+		{ "RX_STN_CPU_2", 16, 8, 256},
+		{ "RX_STN_CPU_3", 24, 8, 256},
+		{ "RX_STN_CPU_4", 32, 8, 256},
+		{ "RX_STN_CPU_5", 40, 8, 256},
+		{ "RX_STN_CPU_6", 48, 8, 256},
+		{ "RX_STN_CPU_7", 56, 8, 256},
+
+		{ "RX_STN_XGS_0_TX", 64, 16, 256},
+		{ "RX_STN_XGS_1_TX", 80, 16, 256},
+
+		{ "RX_STN_GMAC", 96, 8, 256},
+   
+		{ "RX_STN_DMA", 104, 8, 256 },
+
+		{ "RX_STN_XGS_0_FR", 112, 2, 256},
+		{ "RX_STN_XGS_1_FR", 114, 2, 256},
+   
+		{ "RX_STN_SEC", 120, 8, 256 },
+   
+		{0, 0, 0, 0}
+	};
+
+#define MAX_RX_STNS ((int)(sizeof(rx_stns)/sizeof(struct rx_stn)) - 1)
+
+	struct rx_bucket {
+		const char *name;   
+		int size;
+		int tx_credits[MAX_TX_STNS];
+		int rx_stn;
+		const char *rx_stn_name;
+	};
+ 
+	static struct rx_bucket rx_buckets[] = {
+		{.name = "cpu_0_0" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_1" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_2" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_3" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_4" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_5" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_6" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_7" , .rx_stn_name = "RX_STN_CPU_0" },
+   
+		{.name = "cpu_1_0" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_1" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_2" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_3" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_4" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_5" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_6" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_7" , .rx_stn_name = "RX_STN_CPU_1" },
+   
+		{.name = "cpu_2_0" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_1" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_2" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_3" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_4" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_5" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_6" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_7" , .rx_stn_name = "RX_STN_CPU_2" },
+   
+		{.name = "cpu_3_0" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_1" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_2" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_3" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_4" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_5" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_6" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_7" , .rx_stn_name = "RX_STN_CPU_3" },
+   
+		{.name = "cpu_4_0" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_1" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_2" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_3" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_4" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_5" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_6" , .rx_stn_name = "RX_STN_CPU_4" },
+		{.name = "cpu_4_7" , .rx_stn_name = "RX_STN_CPU_4" },
+   
+		{.name = "cpu_5_0" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_1" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_2" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_3" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_4" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_5" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_6" , .rx_stn_name = "RX_STN_CPU_5" },
+		{.name = "cpu_5_7" , .rx_stn_name = "RX_STN_CPU_5" },
+   
+		{.name = "cpu_6_0" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_1" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_2" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_3" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_4" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_5" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_6" , .rx_stn_name = "RX_STN_CPU_6" },
+		{.name = "cpu_6_7" , .rx_stn_name = "RX_STN_CPU_6" },
+   
+		{.name = "cpu_7_0" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_1" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_2" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_3" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_4" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_5" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_6" , .rx_stn_name = "RX_STN_CPU_7" },
+		{.name = "cpu_7_7" , .rx_stn_name = "RX_STN_CPU_7" },
+
+		{.name = "xgs_0_tx_0" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_1" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_2" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_3" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_4" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_5" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_6" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_7" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_8" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_9" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_10" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_11" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_12" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_13" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_14" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+		{.name = "xgs_0_tx_15" , .rx_stn_name = "RX_STN_XGS_0_TX" },
+
+		{.name = "xgs_1_tx_0" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_1" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_2" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_3" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_4" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_5" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_6" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_7" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_8" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_9" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_10" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_11" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_12" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_13" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_14" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+		{.name = "xgs_1_tx_15" , .rx_stn_name = "RX_STN_XGS_1_TX" },
+
+		{.name = "gmac_rsvd_0" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_rfr_0" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_tx_0" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_tx_1" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_tx_2" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_tx_3" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_rsvd_1" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac_rfr_1" , .rx_stn_name = "RX_STN_GMAC" },
+
+		{.name = "dma_chan_0", .rx_stn_name = "RX_STN_DMA" },
+		{.name = "dma_chan_1", .rx_stn_name = "RX_STN_DMA" },
+		{.name = "dma_chan_2", .rx_stn_name = "RX_STN_DMA" },
+		{.name = "dma_chan_3", .rx_stn_name = "RX_STN_DMA" },
+   
+		{.name = "rsvd_0", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_1", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_2", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_3", .rx_stn_name = "RX_STN_RSVD" },
+
+		{.name = "xgs_0_rsvd", .rx_stn_name = "RX_STN_XGS_0_FR" },
+		{.name = "xgs_0_rfr", .rx_stn_name = "RX_STN_XGS_0_FR" },
+
+		{.name = "xgs_1_rsvd", .rx_stn_name = "RX_STN_XGS_1_FR" },
+		{.name = "xgs_1_rfr", .rx_stn_name = "RX_STN_XGS_1_FR" },
+
+		{.name = "rsvd_4", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_5", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_6", .rx_stn_name = "RX_STN_RSVD" },
+		{.name = "rsvd_7", .rx_stn_name = "RX_STN_RSVD" },
+
+		{.name = "sec_pipe_0", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_pipe_1", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_pipe_2", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_pipe_3", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_rsa", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_rsvd_5", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_rsvd_6", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_rsvd_7", .rx_stn_name = "RX_STN_SEC" },
+
+		{.name = 0 }
+	};
+
+#define MAX_RX_BUCKETS ((int)(sizeof(rx_buckets)/sizeof(struct rx_bucket)) - 1)
+
+	static void add_bucket(const char *name);
+	static void modify_bucket_size(int size);
+	static void modify_bucket_tx_credit(const char *str, int credits);
+
+#define fatal_error(fmt, args...) {fprintf(stderr, fmt, ##args); exit(-1);}
+
+	%}
+
+%token TOK_BUCKET TOK_SIZE TOK_WORD TOK_INTEGER TOK_QUOTE TOK_OPEN_BRACE TOK_CLOSE_BRACE TOK_SEMICOLON 
+
+%%
+
+def: 
+| def bucket_def 
+;
+
+bucket_def: 
+TOK_BUCKET quotedname bucket_content 
+{ //printf("grammar: bucket_def start: $1=%s, $2=%s \n", $1, $2);
+	add_bucket((const char *)$2); } 
+;
+
+bucket_content: 
+| TOK_OPEN_BRACE bucket_stmts TOK_CLOSE_BRACE	       
+;
+bucket_stmts: 
+| bucket_stmts bucket_stmt TOK_SEMICOLON
+;
+
+bucket_stmt: 
+| TOK_SIZE TOK_INTEGER 
+{ //printf("grammar: $2=%d\n", $2); 
+	modify_bucket_size($2);}
+					    
+| quotedname TOK_INTEGER
+{ //printf("grammar: $1=%s, $2=%d\n", $1, $2); 
+	modify_bucket_tx_credit((const char *)$1, $2);}
+;
+
+quotedname: TOK_QUOTE TOK_WORD TOK_QUOTE { $$=$2; } ;
+
+%%
+
+static const char *input = "msgring_shared.cfg";  
+static const char *output = "msgring_shared.c";  
+static int debug = 0;
+
+static int lookup_rx_stn(const char *name)
+{
+	int i=0;
+
+	if (!name) return MAX_RX_STNS;
+
+	for(i=0;rx_stns[i].name;i++) 
+		if (strcasecmp(rx_stns[i].name, name)==0) break;
+
+	return i;
+}
+
+static int lookup_rx_bucket(const char *name)
+{
+	int i=0;
+
+	if (!name) return MAX_RX_BUCKETS;
+
+	for(i=0;rx_buckets[i].name;i++) 
+		if (strcasecmp(rx_buckets[i].name, name)==0) break;
+
+	return i;
+}
+
+static void init_rx_bucket(int i)
+{
+	int j=0;
+
+	rx_buckets[i].size = 0;
+	for(j=0;j<MAX_TX_STNS;j++)
+		rx_buckets[i].tx_credits[j] = 0;
+
+	rx_buckets[i].rx_stn = lookup_rx_stn(rx_buckets[i].rx_stn_name);
+}
+
+static void copy_rx_bucket(struct rx_bucket *dest, struct rx_bucket *src)
+{
+	int i=0;
+  
+	dest->size = src->size;
+	for (i=0;i<MAX_TX_STNS;i++)
+		dest->tx_credits[i] = src->tx_credits[i];
+}
+
+static void init_defaults(void)
+{
+	int i=0;
+
+	for(i=0;i<MAX_RX_BUCKETS;i++) 
+		init_rx_bucket(i);
+}
+
+static void add_bucket(const char *name)
+{
+	int id = 0;
+
+	id = lookup_rx_bucket(name);
+
+	if (id == MAX_RX_BUCKETS) {
+		fatal_error("Unrecognised bucket name %s\n", name);
+	}
+
+	copy_rx_bucket(&rx_buckets[id], &rx_buckets[MAX_RX_BUCKETS]);
+
+	init_rx_bucket(MAX_RX_BUCKETS);
+}
+
+static void modify_bucket_size(int size)
+{
+	rx_buckets[MAX_RX_BUCKETS].size = size;
+	//printf("bucket configured with size %d\n", size);
+}
+
+static void modify_bucket_tx_credit(const char *name, int credits)
+{
+	int i=0;
+
+	for(i=0;tx_stns[i].name!=NULL;i++) 
+		if (strcasecmp(tx_stns[i].name, name)==0) break;
+	if (tx_stns[i].name) {
+		rx_buckets[MAX_RX_BUCKETS].tx_credits[i] = credits;
+		//printf("Tx Station %s configured with %d tx credits\n", name, credits);
+	}
+	else {
+		fatal_error("Unknown tx station %s!\n", name);
+	}
+}
+
+static void dump_config(void)
+{
+	int i=0, j=0;
+
+	for(i=0;i<MAX_RX_BUCKETS;i++) {
+		if (rx_stns[rx_buckets[i].rx_stn].name && rx_buckets[i].size) {
+			printf("bucket %3d: size = %3d, rx_stn = %s, tx_credits: ", i, rx_buckets[i].size, 
+			       rx_stns[rx_buckets[i].rx_stn].name);
+			for(j=0;j<MAX_TX_STNS;j++) 
+				if (rx_buckets[i].tx_credits[j]) 
+					printf("<%s, %d> ", tx_stns[j].name, rx_buckets[i].tx_credits[j]);    
+			printf("\n");
+		}
+	}
+}
+
+static void check_config(void)
+{
+	int i=0, j=0, k=0;
+	int total=0;
+
+	for(i=0;rx_stns[i].name;i++) {
+		if (debug) printf("Checking \"%s\"...\n", rx_stns[i].name);
+		total = 0;
+		for(j=rx_stns[i].base_bucket;j<rx_stns[i].base_bucket+rx_stns[i].num_buckets;j++) {
+      
+			if (rx_buckets[j].size) {
+
+				{
+					int num_ones = 0;
+					for(k=0;k<8;k++) if (rx_buckets[j].size & (1<<k)) num_ones++;
+					if (num_ones > 1) 
+						fatal_error("Bucket(%d)'s size(%d) is not a power of 2\n", j, rx_buckets[j].size);
+				}
+
+				if (total % rx_buckets[j].size) 
+					fatal_error("Bucket(%d)'s base address(%d) is not aligned to it's size(%d)\n", 
+						    j, total, rx_buckets[j].size);
+
+				if (rx_buckets[j].size < 4) 
+					fatal_error("Bucket(%d) size(%d) is bad, has to be 0 or >=4\n", j, rx_buckets[j].size);
+			}
+
+			total += rx_buckets[j].size;
+		}
+		//printf("\trx_entries=%d, configured size = %d\n", rx_stns[i].rx_entries, total);
+		if (total > rx_stns[i].rx_entries) {
+			fatal_error("Total configured bucket size for %s exceeds available rx entries\n", 
+				    rx_stns[i].name);
+		}
+		for(j=rx_stns[i].base_bucket;j<rx_stns[i].base_bucket+rx_stns[i].num_buckets;j++) {
+			total = 0;
+			for(k=0;k<MAX_TX_STNS;k++) 
+				total += rx_buckets[j].tx_credits[k];
+			//printf("\tbucket %d: size = %d, total configured credits = %d\n", 
+			//j, rx_buckets[j].size, total);
+			if (total > rx_buckets[j].size) {
+				fatal_error("Total tx credits to bucket_%d exceed the bucket size\n", j);
+			}
+		}  
+	}
+	if (debug) printf("...done\n");
+} 
+
+static void gen_tables(void)
+{
+	FILE *fp = fopen(output, "w");
+	char line[1024];
+	int i=0, j=0;
+
+	if (!output) {
+		fatal_error("Unable to write to %s\n", output);
+	}
+
+	sprintf(line, "/**********************************************************\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " * -----------------DO NOT EDIT THIS FILE------------------\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " * This file has been autogenerated by the build process\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " * from \"%s\" \n", input);
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " **********************************************************/\n\n");
+	fwrite(line, strlen(line), 1, fp);
+
+	sprintf(line, "#include <linux/module.h>\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, "#include <asm/rmi/msgring.h>\n\n");
+	fwrite(line, strlen(line), 1, fp);
+
+	/* Generate Bucket Sizes data structure */
+	sprintf(line, "struct bucket_size shared_bucket_sizes = {\n\t{");
+	fwrite(line, strlen(line), 1, fp);
+
+	for (i=0;i<MAX_RX_BUCKETS;i++) {
+		if (i && (i%8)==0) sprintf(line, "\n\t\t%d, ", rx_buckets[i].size);
+		else sprintf(line, "%3d, ", rx_buckets[i].size);
+		fwrite(line, strlen(line), 1, fp);
+	}
+  
+	sprintf(line, "\n\t}\n};\nEXPORT_SYMBOL(shared_bucket_sizes);\n\n");
+	fwrite(line, strlen(line), 1, fp);
+
+	/* Generate Credit tables */
+	for(i=0; tx_stns[i].name; i++) {
+		sprintf(line, "struct stn_cc shared_cc_table_%s = {{", tx_stns[i].tbl_name);
+		fwrite(line, strlen(line), 1, fp);
+
+		for (j=0;j<MAX_RX_BUCKETS;j++) {
+			if ((j % 8)==0) sprintf(line, "\n\t\t{%d", rx_buckets[j].tx_credits[i]);
+			else sprintf(line, ", %d ", rx_buckets[j].tx_credits[i]);
+			fwrite(line, strlen(line), 1, fp);
+			if ((j % 8)==7) {sprintf(line, "},"); fwrite(line, strlen(line), 1, fp);}
+		}    
+		sprintf(line, "\n\t}};\nEXPORT_SYMBOL(shared_cc_table_%s);\n\n",
+			tx_stns[i].tbl_name);
+		fwrite(line, strlen(line), 1, fp);
+	}
+}
+
+static void usage(const char *progname)
+{
+	fprintf(stderr, "Usage: %s -i <input file> -o <output file>\n", progname);
+	exit(-1);
+}
+
+int main(int argc, char *argv[])
+{
+	int ret = 0;
+	int ch=0;
+  
+	while ( (ch=getopt(argc, argv, "hdi:o:")) != -1) {
+		switch(ch) {
+		case 'i': input = strdup(optarg); break;
+		case 'o': output = strdup(optarg); break;
+		case 'd': debug = 1; break;
+			break;
+		case 'h':
+		default:
+			usage(argv[0]);
+			break;
+		}
+	}
+	printf("Input file = \"%s\", Output file = \"%s\" \n", input, output);
+
+	yyin = fopen(input, "r");
+
+	if (yyin == NULL) {
+		fatal_error("bad input file\n");
+	}
+  
+	//printf("MAX_RX_STNS = %d, MAX_TX_STNS = %d, MAX_RX_BUCKETS = %d\n", 
+	// MAX_RX_STNS, MAX_TX_STNS, MAX_RX_BUCKETS);
+
+	init_defaults();
+  
+	ret = yyparse();
+
+	if (ret) {
+		fprintf(stderr, "Unable to Parse %s\n", input);
+		return -1;
+	}
+	printf("Finished parsing \"%s\"\n", input);
+
+	if (debug) dump_config();
+  
+	check_config();
+
+	gen_tables();
+
+	return 0;
+}
+
+
diff --git a/arch/mips/rmi/phoenix/msgring_xls.cfg b/arch/mips/rmi/phoenix/msgring_xls.cfg
new file mode 100644
index 0000000..11c715a
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring_xls.cfg
@@ -0,0 +1,587 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES, LOSS OF USE, DATA, OR PROFITS, OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * *****************************RMI_2**********************************/
+
+
+/* 
+ * This file defines the message ring configuration for XLS two core. It tries to allow 
+ * many different point-point communications between the message stations on the message ring
+ * and as result is _not_ the best configuration for performance
+ *
+ * The message ring on phoenix family of processors connects the cpus, gmacs, xgmac/spi4,
+ * security engine and the general purpose DMA engines. It provides a high bandwidth,
+ * low latency communication links. On traditional processors, this communication goes through
+ * which inherently does not scale very well with increasing number of cpus. 
+ * 
+ * Message ring has an in-built flow control mechanism. Every agent/station on the ring has to
+ * have software configured credits to send messages to any agent. Every receiving agent on the
+ * ring has a 256 entry FIFO that can divided into "buckets". All addressing on the ring is 
+ * in terms of buckets. There are a total 128 buckets on the ring. The total number of credits 
+ * across all sending agents should not exceed the bucket size. 
+ *
+ * Below are the receiving agents and the max number of buckets they can have
+ * 	CPU 0	: 8 buckets
+ * 	CPU 1	: 8 buckets
+ * 
+ *	GMAC	: 8 buckets	
+ *	
+ *	SEC	: 8 buckets
+ * 
+ *	DMA	: 8 buckets
+ * 
+ *	CMP	: Currently disabled. 
+ *
+ * The bucket size of a bucket should be aligned to the bucket's starting index in that
+ * receiving station's FIFO. For example, if sizes of bucket0 and bucket1 of a station 
+ * are 32 and 32, bucket2's size has to be 64. bucket size 0 is valid.
+ *
+ * The format of the file is pretty straight forward. Each bucket definition has the size
+ * and the list of sending agents to that bucket with the number of credits to send.
+ * 
+ * Undefined buckets have a size of 0 and Tx stations have 0 credits to send to that bucket.
+ *
+ *  Following are the currently supported bucket names
+ *  cpu_0_0
+ *  cpu_0_1
+ *  cpu_0_2
+ *  cpu_0_3
+ *  cpu_0_4
+ *  cpu_0_5
+ *  cpu_0_6
+ *  cpu_0_7
+ *  
+ *  cpu_1_0
+ *  cpu_1_1
+ *  cpu_1_2
+ *  cpu_1_3
+ *  cpu_1_4
+ *  cpu_1_5
+ *  cpu_1_6
+ *  cpu_1_7
+ *
+ *  enabled only for xls-b0
+ *  cpu_2_0
+ *  cpu_2_1
+ *  cpu_2_2
+ *  cpu_2_3
+ *  cpu_2_4
+ *  cpu_2_5
+ *  cpu_2_6
+ *  cpu_2_7
+ *  
+ *  enabled only for xls-b0
+ *  cpu_3_0
+ *  cpu_3_1
+ *  cpu_3_2
+ *  cpu_3_3
+ *  cpu_3_4
+ *  cpu_3_5
+ *  cpu_3_6
+ *  cpu_3_7
+ *
+ *  gmac0_rfr
+ *  gmac0_tx_0
+ *  gmac0_tx_1
+ *  gmac0_tx_2
+ *  gmac0_tx_3
+ *  
+ *  gmac1_rfr
+ *  gmac1_tx_0
+ *  gmac1_tx_1
+ *  gmac1_tx_2
+ *  gmac1_tx_3
+ *
+ *  sec_pipe_0
+ *  sec_rsa
+ *
+ * Following are the currently supported Tx Agent/Station names
+ *
+ *  tx_stn_cpu_0
+ *  tx_stn_cpu_1
+ *
+ *  tx_stn_gmac0
+ *  tx_stn_gmac1
+ *
+ *  tx_stn_dma
+ *
+ *  tx_stn_sec
+ *
+ * 
+ */
+
+/*************************************************************/
+// CPU_0 Message Station 
+
+bucket "cpu_0_0" { 
+	size 32;
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  6;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+	"tx_stn_cpu_0" 1;
+	"tx_stn_cpu_1" 1; /* NEEDED BY RMIOS IPSEC */
+}
+bucket "cpu_0_1" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_0_2" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_0_3" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_0_4" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_0_5" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_0_6" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_0_7" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+
+/*************************************************************/
+// CPU_1 Message Station 
+
+bucket "cpu_1_0" { 
+	size 32;
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_1_1" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_1_2" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_1_3" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_cpu_0" 8; /* NEEDED BY RMIOS IPSEC */
+	"tx_stn_dma" 2;
+	"tx_stn_cmp" 2;
+}
+bucket "cpu_1_4" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_1_5" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_1_6" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_1_7" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+
+/*************************************************************/
+// CPU_2 Message Station 
+
+bucket "cpu_2_0" { 
+	size 32;
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_2_1" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_2_2" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_2_3" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_cpu_0" 8; /* NEEDED BY RMIOS IPSEC */
+	"tx_stn_dma" 2;
+	"tx_stn_cmp" 2;
+}
+bucket "cpu_2_4" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_5" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_6" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_2_7" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+
+
+/*************************************************************/
+// CPU_3 Message Station 
+bucket "cpu_3_0" { 
+	size 32;
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_3_1" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_3_2" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  8;
+	"tx_stn_dma" 4;
+	"tx_stn_cmp" 4;
+}
+bucket "cpu_3_3" { 
+	size 32; 
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+	"tx_stn_sec"  4;
+	"tx_stn_cpu_0" 8; /* NEEDED BY RMIOS IPSEC */
+	"tx_stn_dma" 2;
+	"tx_stn_cmp" 2;
+}
+bucket "cpu_3_4" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_5" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_6" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+bucket "cpu_3_7" {
+	size 32;
+	"tx_stn_gmac0" 6;
+	"tx_stn_gmac1" 6;
+	"tx_stn_dma" 6;
+	"tx_stn_cmp" 6;
+	"tx_stn_sec"  8;
+}
+
+/*************************************************************/
+
+// GMAC Message Station 
+
+bucket "gmac0_rfr" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+}
+
+bucket "gmac0_tx_0" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac0_tx_1" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac0_tx_2" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac0_tx_3" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac1_rfr" {
+	size 32;
+	"tx_stn_cpu_0" 4;
+	"tx_stn_cpu_1" 4;
+	"tx_stn_cpu_2" 4;
+	"tx_stn_cpu_3" 4;
+	"tx_stn_gmac0" 8;
+	"tx_stn_gmac1" 8;
+}
+
+bucket "gmac1_tx_0" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac1_tx_1" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac1_tx_2" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+bucket "gmac1_tx_3" {
+	size 32;
+	"tx_stn_cpu_0" 8;
+	"tx_stn_cpu_1" 8;
+	"tx_stn_cpu_2" 8;
+	"tx_stn_cpu_3" 8;
+}
+
+/*************************************************************/
+// Security Message Station 
+
+bucket "sec_pipe_0" {
+	size 128;
+	"tx_stn_cpu_0" 32;
+	"tx_stn_cpu_1" 32;
+	"tx_stn_cpu_2" 32;
+	"tx_stn_cpu_3" 32;
+}
+
+bucket "sec_rsa_ecc" {
+	size 128;
+	"tx_stn_cpu_0" 32;
+	"tx_stn_cpu_1" 32;
+	"tx_stn_cpu_2" 32;
+	"tx_stn_cpu_3" 32;
+}
+
+bucket "dma_chan_0" {
+	size 64;
+	"tx_stn_cpu_0" 16;
+	"tx_stn_cpu_1" 16;
+	"tx_stn_cpu_2" 16;
+	"tx_stn_cpu_3" 16;
+}
+bucket "dma_chan_1" {
+	size 64;
+	"tx_stn_cpu_0" 16;
+	"tx_stn_cpu_1" 16;
+	"tx_stn_cpu_2" 16;
+	"tx_stn_cpu_3" 16;
+}
+
+bucket "dma_chan_2" {
+	size 64;
+	"tx_stn_cpu_0" 16;
+	"tx_stn_cpu_1" 16;
+	"tx_stn_cpu_2" 16;
+	"tx_stn_cpu_3" 16;
+}
+
+bucket "dma_chan_3" {
+	size 64;
+	"tx_stn_cpu_0" 16;
+	"tx_stn_cpu_1" 16;
+	"tx_stn_cpu_2" 16;
+	"tx_stn_cpu_3" 16;
+}
+
+/*************************************************************/
+// Compression Message Station
+
+bucket "cmp_0" {
+        size 32; 
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+}
+
+bucket "cmp_1" { 
+        size 32;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+}
+
+bucket "cmp_2" {
+        size 32; 
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+}
+
+bucket "cmp_3" {      
+        size 32;
+        "tx_stn_cpu_0" 8;
+        "tx_stn_cpu_1" 8;
+        "tx_stn_cpu_2" 8;
+        "tx_stn_cpu_3" 8;
+}
+
diff --git a/arch/mips/rmi/phoenix/msgring_xls.l b/arch/mips/rmi/phoenix/msgring_xls.l
new file mode 100644
index 0000000..33bb94a
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring_xls.l
@@ -0,0 +1,44 @@
+%{
+#include <stdio.h>
+#include <string.h>
+#include "msgring.yacc.h"
+
+
+int yyerror(const char *str)
+{
+  fprintf(stderr, "%s\n", str);
+  return 1;
+}
+
+%}
+
+%x c_comment
+
+%%
+
+"/*"                    BEGIN(c_comment); /* c-style comment */
+<c_comment>[^*\n]*        /* eat anything that is not a * */
+<c_comment>"*"+[^*/\n]*   /* eat up * s not followed by a / */
+<c_comment>\n
+<c_comment>"*"+"/"      BEGIN(INITIAL);
+
+"//"[^\n]*"\n"         ; /* eat up one-line (C++-style) commens */
+
+bucket                  yylval = (unsigned long)"bucket"; return TOK_BUCKET;
+size                    yylval = (unsigned long)"size"; return TOK_SIZE;
+[a-zA-Z_][a-zA-Z_0-9]*    yylval = (unsigned long)strdup(yytext); return TOK_WORD;
+[0-9]+                  yylval = atoi(yytext); return TOK_INTEGER;
+\"                      yylval = (unsigned long)"\""; return TOK_QUOTE;
+\{                      yylval = (unsigned long)"{"; return TOK_OPEN_BRACE;
+\}                      yylval = (unsigned long)"}"; return TOK_CLOSE_BRACE;
+;                       yylval = (unsigned long)";"; return TOK_SEMICOLON;
+\n                      /* ignore newline */;
+[ \t]+                  /* ignore whitespace */;
+.                       yyerror("Unknown token\n");
+%%
+
+int yywrap()
+{
+  return 1;
+}
+
diff --git a/arch/mips/rmi/phoenix/msgring_xls.y b/arch/mips/rmi/phoenix/msgring_xls.y
new file mode 100644
index 0000000..d9debdb
--- /dev/null
+++ b/arch/mips/rmi/phoenix/msgring_xls.y
@@ -0,0 +1,539 @@
+%{
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdarg.h>
+#include <unistd.h>
+
+	extern FILE *yyin;
+	extern void yyerror(const char *);
+	int yydebug = 1;
+
+	//#define MAX_RX_BUCKETS 128
+
+	struct tx_stn {
+		const char *name;
+		const char *tbl_name;
+	};
+
+	struct tx_stn tx_stns[] = {
+		{ .name = "TX_STN_CPU_0" , .tbl_name = "cpu_0" },
+		{ .name = "TX_STN_CPU_1" , .tbl_name = "cpu_1" },
+		{ .name = "TX_STN_CPU_2" , .tbl_name = "cpu_2" },
+		{ .name = "TX_STN_CPU_3" , .tbl_name = "cpu_3" },
+
+		{ .name = "TX_STN_GMAC0" , .tbl_name = "gmac0" },
+		{ .name = "TX_STN_GMAC1" , .tbl_name = "gmac1" },
+
+		{ .name = "TX_STN_DMA" , .tbl_name = "dma" },
+
+		{ .name = "TX_STN_CMP" , .tbl_name = "cmp" },
+
+		{ .name = "TX_STN_PCIE" , .tbl_name = "pcie" },
+
+		{ .name = "TX_STN_SEC" , .tbl_name = "sec" },
+
+		{ 0 }
+	};
+
+#define MAX_TX_STNS ((int)(sizeof(tx_stns)/sizeof(struct tx_stn)) - 1)
+
+	struct rx_stn {
+		const char *name;
+		int base_bucket;
+		int num_buckets;
+		int rx_entries;
+	};
+
+	struct rx_stn rx_stns[] = {
+		{ "RX_STN_CPU_0", 0, 8, 256},
+		{ "RX_STN_CPU_1", 8, 8, 256},
+		{ "RX_STN_CPU_2", 16, 8, 256},
+		{ "RX_STN_CPU_3", 24, 8, 256},
+
+		{ "RX_STN_GMAC0", 80, 8, 256},
+		{ "RX_STN_GMAC1", 96, 8, 256},
+   
+		{ "RX_STN_DMA", 104, 4, 256 },
+
+		{ "RX_STN_CMP", 108, 4, 256 },
+
+		{ "RX_STN_PCIE", 116, 8, 256 },
+
+		{ "RX_STN_SEC", 120, 8, 256 },
+   
+		{0, 0, 0, 0}
+	};
+
+#define MAX_RX_STNS ((int)(sizeof(rx_stns)/sizeof(struct rx_stn)) - 1)
+
+	struct rx_bucket {
+		const char *name;   
+		int size;
+		int tx_credits[MAX_TX_STNS];
+		int rx_stn;
+		const char *rx_stn_name;
+	};
+ 
+	static struct rx_bucket rx_buckets[] = {
+		{.name = "cpu_0_0" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_1" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_2" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_3" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_4" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_5" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_6" , .rx_stn_name = "RX_STN_CPU_0" },
+		{.name = "cpu_0_7" , .rx_stn_name = "RX_STN_CPU_0" },
+   
+		{.name = "cpu_1_0" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_1" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_2" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_3" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_4" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_5" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_6" , .rx_stn_name = "RX_STN_CPU_1" },
+		{.name = "cpu_1_7" , .rx_stn_name = "RX_STN_CPU_1" },
+
+        {.name = "cpu_2_0" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_1" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_2" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_3" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_4" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_5" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_6" , .rx_stn_name = "RX_STN_CPU_2" },
+		{.name = "cpu_2_7" , .rx_stn_name = "RX_STN_CPU_2" },
+
+        {.name = "cpu_3_0" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_1" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_2" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_3" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_4" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_5" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_6" , .rx_stn_name = "RX_STN_CPU_3" },
+		{.name = "cpu_3_7" , .rx_stn_name = "RX_STN_CPU_3" },
+
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "gmac1_rfr" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac1_tx_0" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac1_tx_1" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac1_tx_2" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac1_tx_3" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "gmac0_rfr" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac0_tx_0" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac0_tx_1" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac0_tx_2" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "gmac0_tx_3" , .rx_stn_name = "RX_STN_GMAC" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+
+		{.name = "dma_chan_0" , .rx_stn_name = "RX_STN_DMA" },
+		{.name = "dma_chan_1", .rx_stn_name = "RX_STN_DMA" },
+		{.name = "dma_chan_2", .rx_stn_name = "RX_STN_DMA" },
+		{.name = "dma_chan_3", .rx_stn_name = "RX_STN_DMA" },
+
+		{.name = "cmp_0" , .rx_stn_name = "RX_STN_CMP" },
+		{.name = "cmp_1" , .rx_stn_name = "RX_STN_CMP" },
+		{.name = "cmp_2" , .rx_stn_name = "RX_STN_CMP" },
+		{.name = "cmp_3" , .rx_stn_name = "RX_STN_CMP" },
+
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+   
+		{.name = "pcie_0", .rx_stn_name = "RX_STN_PCIE" },
+		{.name = "pcie_1", .rx_stn_name = "RX_STN_PCIE" },
+		{.name = "pcie_2", .rx_stn_name = "RX_STN_PCIE" },
+		{.name = "pcie_3", .rx_stn_name = "RX_STN_PCIE" },
+
+		{.name = "sec_pipe_0", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "sec_rsa_ecc", .rx_stn_name = "RX_STN_SEC" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+		{.name = "" , .rx_stn_name = "" },
+
+		{.name = 0 }
+	};
+
+#define MAX_RX_BUCKETS ((int)(sizeof(rx_buckets)/sizeof(struct rx_bucket)) - 1)
+
+	static void add_bucket(const char *name);
+	static void modify_bucket_size(int size);
+	static void modify_bucket_tx_credit(const char *str, int credits);
+
+#define fatal_error(fmt, args...) {fprintf(stderr, fmt, ##args); exit(-1);}
+
+	%}
+
+%token TOK_BUCKET TOK_SIZE TOK_WORD TOK_INTEGER TOK_QUOTE TOK_OPEN_BRACE TOK_CLOSE_BRACE TOK_SEMICOLON 
+
+%%
+
+def: 
+| def bucket_def 
+;
+
+bucket_def: 
+TOK_BUCKET quotedname bucket_content 
+{ //printf("grammar: bucket_def start: $1=%s, $2=%s \n", $1, $2);
+	add_bucket((const char *)$2); } 
+;
+
+bucket_content: 
+| TOK_OPEN_BRACE bucket_stmts TOK_CLOSE_BRACE	       
+;
+bucket_stmts: 
+| bucket_stmts bucket_stmt TOK_SEMICOLON
+;
+
+bucket_stmt: 
+| TOK_SIZE TOK_INTEGER 
+{ //printf("grammar: $2=%d\n", $2); 
+	modify_bucket_size($2);}
+					    
+| quotedname TOK_INTEGER
+{ //printf("grammar: $1=%s, $2=%d\n", $1, $2); 
+	modify_bucket_tx_credit((const char *)$1, $2);}
+;
+
+quotedname: TOK_QUOTE TOK_WORD TOK_QUOTE { $$=$2; } ;
+
+%%
+
+static const char *input = "msgring_xls.cfg";  
+static const char *output = "msgring_xls.c";  
+static int debug = 0;
+
+static int lookup_rx_stn(const char *name)
+{
+	int i=0;
+
+	if (!name) return MAX_RX_STNS;
+
+	for(i=0;rx_stns[i].name;i++) 
+		if (strcasecmp(rx_stns[i].name, name)==0) break;
+
+	return i;
+}
+
+static int lookup_rx_bucket(const char *name)
+{
+	int i=0;
+
+	if (!name) return MAX_RX_BUCKETS;
+
+	for(i=0;rx_buckets[i].name;i++) 
+		if (strcasecmp(rx_buckets[i].name, name)==0) break;
+
+	return i;
+}
+
+static void init_rx_bucket(int i)
+{
+	int j=0;
+
+	rx_buckets[i].size = 0;
+	for(j=0;j<MAX_TX_STNS;j++)
+		rx_buckets[i].tx_credits[j] = 0;
+
+	rx_buckets[i].rx_stn = lookup_rx_stn(rx_buckets[i].rx_stn_name);
+}
+
+static void copy_rx_bucket(struct rx_bucket *dest, struct rx_bucket *src)
+{
+	int i=0;
+  
+	dest->size = src->size;
+	for (i=0;i<MAX_TX_STNS;i++)
+		dest->tx_credits[i] = src->tx_credits[i];
+}
+
+static void init_defaults(void)
+{
+	int i=0;
+
+	for(i=0;i<MAX_RX_BUCKETS;i++) 
+		init_rx_bucket(i);
+}
+
+static void add_bucket(const char *name)
+{
+	int id = 0;
+
+	id = lookup_rx_bucket(name);
+
+	if (id == MAX_RX_BUCKETS) {
+		fatal_error("Unrecognised bucket name %s\n", name);
+	}
+
+	copy_rx_bucket(&rx_buckets[id], &rx_buckets[MAX_RX_BUCKETS]);
+
+	init_rx_bucket(MAX_RX_BUCKETS);
+}
+
+static void modify_bucket_size(int size)
+{
+	rx_buckets[MAX_RX_BUCKETS].size = size;
+	//printf("bucket configured with size %d\n", size);
+}
+
+static void modify_bucket_tx_credit(const char *name, int credits)
+{
+	int i=0;
+
+	for(i=0;tx_stns[i].name!=NULL;i++) 
+		if (strcasecmp(tx_stns[i].name, name)==0) break;
+	if (tx_stns[i].name) {
+		rx_buckets[MAX_RX_BUCKETS].tx_credits[i] = credits;
+		//printf("Tx Station %s configured with %d tx credits\n", name, credits);
+	}
+	else {
+		fatal_error("Unknown tx station %s!\n", name);
+	}
+}
+
+static void dump_config(void)
+{
+	int i=0, j=0;
+
+	for(i=0;i<MAX_RX_BUCKETS;i++) {
+		if (rx_stns[rx_buckets[i].rx_stn].name && rx_buckets[i].size) {
+			printf("bucket %3d: size = %3d, rx_stn = %s, tx_credits: ", i, rx_buckets[i].size, 
+			       rx_stns[rx_buckets[i].rx_stn].name);
+			for(j=0;j<MAX_TX_STNS;j++) 
+				if (rx_buckets[i].tx_credits[j]) 
+					printf("<%s, %d> ", tx_stns[j].name, rx_buckets[i].tx_credits[j]);    
+			printf("\n");
+		}
+	}
+}
+
+static void check_config(void)
+{
+	int i=0, j=0, k=0;
+	int total=0;
+
+	for(i=0;rx_stns[i].name;i++) {
+		if (debug) printf("Checking \"%s\"...\n", rx_stns[i].name);
+		total = 0;
+		for(j=rx_stns[i].base_bucket;j<rx_stns[i].base_bucket+rx_stns[i].num_buckets;j++) {
+      
+			if (rx_buckets[j].size) {
+
+				{
+					int num_ones = 0;
+					for(k=0;k<8;k++) if (rx_buckets[j].size & (1<<k)) num_ones++;
+					if (num_ones > 1) 
+						fatal_error("Bucket(%d)'s size(%d) is not a power of 2\n", j, rx_buckets[j].size);
+				}
+
+				if (total % rx_buckets[j].size) 
+					fatal_error("Bucket(%d)'s base address(%d) is not aligned to it's size(%d)\n", 
+						    j, total, rx_buckets[j].size);
+
+				if (rx_buckets[j].size < 4) 
+					fatal_error("Bucket(%d) size(%d) is bad, has to be 0 or >=4\n", j, rx_buckets[j].size);
+			}
+
+			total += rx_buckets[j].size;
+		}
+		//printf("\trx_entries=%d, configured size = %d\n", rx_stns[i].rx_entries, total);
+		if (total > rx_stns[i].rx_entries) {
+			fatal_error("Total configured bucket size for %s exceeds available rx entries\n", 
+				    rx_stns[i].name);
+		}
+		for(j=rx_stns[i].base_bucket;j<rx_stns[i].base_bucket+rx_stns[i].num_buckets;j++) {
+			total = 0;
+			for(k=0;k<MAX_TX_STNS;k++) 
+				total += rx_buckets[j].tx_credits[k];
+			//printf("\tbucket %d: size = %d, total configured credits = %d\n", 
+			//j, rx_buckets[j].size, total);
+			if (total > rx_buckets[j].size) {
+				fatal_error("Total tx credits to bucket_%d exceed the bucket size\n", j);
+			}
+		}  
+	}
+	if (debug) printf("...done\n");
+} 
+
+static void gen_tables(void)
+{
+	FILE *fp = fopen(output, "w");
+	char line[1024];
+	int i=0, j=0;
+
+	if (!output) {
+		fatal_error("Unable to write to %s\n", output);
+	}
+
+	sprintf(line, "/**********************************************************\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " * -----------------DO NOT EDIT THIS FILE------------------\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " * This file has been autogenerated by the build process\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " * from \"%s\"\n", input);
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, " **********************************************************/\n\n");
+	fwrite(line, strlen(line), 1, fp);
+
+	sprintf(line, "#include <linux/module.h>\n");
+	fwrite(line, strlen(line), 1, fp);
+	sprintf(line, "#include <asm/rmi/msgring.h>\n\n");
+	fwrite(line, strlen(line), 1, fp);
+
+	/* Generate Bucket Sizes data structure */
+	sprintf(line, "struct bucket_size xls_bucket_sizes = {\n\t{");
+	fwrite(line, strlen(line), 1, fp);
+
+	for (i=0;i<MAX_RX_BUCKETS;i++) {
+		if (i && (i%8)==0) sprintf(line, "\n\t\t%d, ", rx_buckets[i].size);
+		else sprintf(line, "%3d, ", rx_buckets[i].size);
+		fwrite(line, strlen(line), 1, fp);
+	}
+  
+	sprintf(line, "\n\t}\n};\nEXPORT_SYMBOL(xls_bucket_sizes);\n\n");
+	fwrite(line, strlen(line), 1, fp);
+
+	/* Generate Credit tables */
+	for(i=0; tx_stns[i].name; i++) {
+		sprintf(line, "struct stn_cc xls_cc_table_%s = {{", tx_stns[i].tbl_name);
+		fwrite(line, strlen(line), 1, fp);
+
+		for (j=0;j<MAX_RX_BUCKETS;j++) {
+			if ((j % 8)==0) sprintf(line, "\n\t\t{%d", rx_buckets[j].tx_credits[i]);
+			else sprintf(line, ", %d ", rx_buckets[j].tx_credits[i]);
+			fwrite(line, strlen(line), 1, fp);
+			if ((j % 8)==7) {sprintf(line, "},"); fwrite(line, strlen(line), 1, fp);}
+		}    
+		sprintf(line, "\n\t}};\nEXPORT_SYMBOL(xls_cc_table_%s);\n\n",
+			tx_stns[i].tbl_name);
+		fwrite(line, strlen(line), 1, fp);
+	}
+}
+
+static void usage(const char *progname)
+{
+	fprintf(stderr, "Usage: %s -i <input file> -o <output file>\n", progname);
+	exit(-1);
+}
+
+extern char *optarg;
+int main(int argc, char *argv[])
+{
+	int ret = 0;
+	int ch=0;
+  
+	while ( (ch=getopt(argc, argv, "hdi:o:")) != -1) {
+		switch(ch) {
+		case 'i': input = strdup(optarg); break;
+		case 'o': output = strdup(optarg); break;
+		case 'd': debug = 1; break;
+			break;
+		case 'h':
+		default:
+			usage(argv[0]);
+			break;
+		}
+	}
+	printf("Input file = \"%s\", Output file = \"%s\" \n", input, output);
+
+	yyin = fopen(input, "r");
+
+	if (yyin == NULL) {
+		fatal_error("bad input file\n");
+	}
+  
+	//printf("MAX_RX_STNS = %d, MAX_TX_STNS = %d, MAX_RX_BUCKETS = %d\n", 
+	// MAX_RX_STNS, MAX_TX_STNS, MAX_RX_BUCKETS);
+
+	init_defaults();
+  
+	ret = yyparse();
+
+	if (ret) {
+		fprintf(stderr, "Unable to Parse %s\n", input);
+		return -1;
+	}
+	printf("Finished parsing \"%s\"\n", input);
+
+	if (debug) dump_config();
+  
+	check_config();
+
+	gen_tables();
+
+	return 0;
+}
+
+
diff --git a/arch/mips/rmi/phoenix/on_chip.c b/arch/mips/rmi/phoenix/on_chip.c
new file mode 100644
index 0000000..f156891
--- /dev/null
+++ b/arch/mips/rmi/phoenix/on_chip.c
@@ -0,0 +1,857 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+#include <linux/module.h>
+#include <linux/timer.h>
+
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/debug.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/linux_crf.h>
+
+#ifdef CONFIG_RMI_XLP
+#include <asm/rmi/xlp_common/xlp_macros.h>
+#endif
+
+unsigned long phoenix_io_base = (unsigned long)(DEFAULT_PHOENIX_IO_BASE);
+EXPORT_SYMBOL(phoenix_io_base);
+extern int xlr_loader_support;
+extern int xlr_loader_sharedcore;
+extern int xlr_loader_own_gmac;
+extern int xlr_loader_own_dma;
+int msgring_timer_irq;
+
+#define MSGRNG_CC_INIT_CPU_DEST(conf, dest,cpu) \
+do { \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][0], 0 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][1], 1 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][2], 2 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][3], 3 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][4], 4 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][5], 5 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][6], 6 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf##cc_table_cpu_##cpu.counters[dest][7], 7 ); \
+} while(0)
+
+/* Initialized CC for cpu 0 to send to all buckets at 0-7 cpus */
+#define MSGRNG_CC_INIT_CPU(conf, cpu) \
+do { \
+  MSGRNG_CC_INIT_CPU_DEST(conf,0,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,1,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,2,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,3,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,4,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,5,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,6,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,7,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,8,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,9,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,10,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,11,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,12,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,13,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,14,cpu); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,15,cpu); \
+} while (0)
+
+#define MSGRNG_BUCKETSIZE_INIT_CPU(conf, base) \
+do { \
+  msgrng_write_bucksize(0, conf##bucket_sizes.bucket[base+0]);         \
+  msgrng_write_bucksize(1, conf##bucket_sizes.bucket[base+1]);         \
+  msgrng_write_bucksize(2, conf##bucket_sizes.bucket[base+2]);  \
+  msgrng_write_bucksize(3, conf##bucket_sizes.bucket[base+3]);  \
+  msgrng_write_bucksize(4, conf##bucket_sizes.bucket[base+4]);  \
+  msgrng_write_bucksize(5, conf##bucket_sizes.bucket[base+5]);  \
+  msgrng_write_bucksize(6, conf##bucket_sizes.bucket[base+6]);  \
+  msgrng_write_bucksize(7, conf##bucket_sizes.bucket[base+7]);  \
+} while(0)
+
+#define XLR_MSG_TBL
+#define XLS_MSG_TBL  xls_
+#define SHARED_XLR_MSG_TBL shared_
+
+#define X_MSGRNG_BUCKETSIZE_INIT_CPU(x,y) MSGRNG_BUCKETSIZE_INIT_CPU(x,y)
+
+__u32  pop_bucket_mask[NR_CORES];
+__u32  pop_bucket_start[NR_CORES];
+__u32  pop_bucket_end[NR_CORES];
+__u32 cpu_to_bktmask[NR_CPUS];
+__u32 cpu_to_frstid[NR_CPUS];
+
+uint32_t hard_cpu_online_map = 0;
+uint32_t msgring_global_thread_mask = 0;
+
+/* make this a read/write spinlock */
+spinlock_t msgrng_lock;
+static phnx_atomic_t msgring_registered;
+
+int msgring_int_type;
+int msgring_int_en;
+int msgring_watermark_count;
+static __u32 msgring_thread_mask;
+
+extern int rmi_dev_own_bucket_list_get(int *start, int *end, int *mask);
+extern struct irq_chip phnx_rsvd_pic;
+extern struct irqaction phnx_rsvd_action;
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+extern int rmi_msgring_napi;
+extern int xlr_napi_ready;
+extern void xlr_napi_rx_schedule(void);
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+struct tx_stn tx_stns[MAX_TX_STNS];
+
+int rxstn_to_txstn_map[128] = {
+	[0 ... 7] = TX_STN_CPU_0,
+	[8 ... 15] = TX_STN_CPU_1,
+	[16 ... 23] = TX_STN_CPU_2,
+	[24 ... 31] = TX_STN_CPU_3,
+	[32 ... 39] = TX_STN_CPU_4,
+	[40 ... 47] = TX_STN_CPU_5,
+	[48 ... 55] = TX_STN_CPU_6,
+	[56 ... 63] = TX_STN_CPU_7,
+	[64 ... 95] = TX_STN_INVALID,
+	[96 ... 103] = TX_STN_GMAC,
+	[104 ... 107] = TX_STN_DMA,
+	[108 ... 111] = TX_STN_INVALID,
+	[112 ... 113] = TX_STN_XGS_0,
+	[114 ... 115] = TX_STN_XGS_1,
+	[116 ... 119] = TX_STN_INVALID,
+	[120 ... 127] = TX_STN_SEC
+};
+
+int xls_rxstn_to_txstn_map[128] = {
+        [0 ... 7] = TX_STN_CPU_0,
+        [8 ... 15] = TX_STN_CPU_1,
+	[16 ... 23] = TX_STN_CPU_2,
+	[24 ... 31] = TX_STN_CPU_3,
+        [32 ... 80] = TX_STN_INVALID,
+	[80 ... 87] = TX_STN_GMAC1,
+	[96 ... 103] = TX_STN_GMAC0,
+	[104 ... 107] = TX_STN_DMA,
+	[108 ... 111] = TX_STN_CMP,
+	[112 ... 115] = TX_STN_INVALID,
+	[116 ... 119] = TX_STN_PCIE,
+	[120 ... 121] = TX_STN_SEC,
+	[122 ... 127] = TX_STN_INVALID,
+};
+
+void dummy_handler(int bucket, int size, int code, int tx_stid,
+		   struct msgrng_msg *msg, void *dev_id)
+{
+	printk("[%s]: No Handler for message from stn_id=%d, bucket=%d, "
+	       "size=%d, msg0=%llx, dropping message\n",
+	       __FUNCTION__, tx_stid, bucket, size,
+	       (unsigned long long)msg->msg0);
+}
+
+struct tx_stn_handler tx_stn_handler_map[128] = {
+	[0 ... 127] = {dummy_handler, NULL},
+};
+
+void phoenix_msgring_cpu_init(void)
+{
+	int id;
+	unsigned long flags;
+	int shared_msgring = 0;
+	static int only_once = 0;
+
+	if(rmik_en) {
+		if(only_once++ == 0)
+			rmik_own_bucket_list_get(pop_bucket_start, pop_bucket_end, pop_bucket_mask);
+		rmik_phoenix_msgring_cpu_init();
+		return;
+	}
+
+	id = cpu_logical_map(get_cpu());
+
+	msgring_int_en = 1;
+
+	if (xlr_loader_support && xlr_loader_sharedcore) {
+		/* if support for loading apps on same core as Linux is enabled */
+		if (xlr_loader_own_gmac || xlr_loader_own_dma) {
+			/* pop should only the buckets matching with the thread
+			   on which linux is loaded */
+			shared_msgring = 1;
+			msgring_int_en = 0;
+			pop_bucket_start[id >> 2] = 0;
+			pop_bucket_mask[id >> 2] |= (1 << (id % 4));
+			if (pop_bucket_end[id >> 2] < (id % 4) + 1)
+				pop_bucket_end[id >> 2] = (id % 4) + 1;
+		} else if (xlr_hybrid_rmios_ipsec()) {
+			/* rmios will always send to the bucket 0 */
+			pop_bucket_start[id >> 2] = 0;
+			pop_bucket_mask[id >> 2] = 1;
+			pop_bucket_end[id >> 2] = 1;
+			put_cpu();
+			return;
+		} else {
+			/* all the stations are owned by apps, 
+			   linux should not poll for any bucket */
+			pop_bucket_start[id >> 2] = 0;
+			pop_bucket_mask[id >> 2] = 0;
+			pop_bucket_end[id >> 2] = 0;
+		}
+	} else if (xlr_hybrid_user_mac() || xlr_hybrid_user_mac_xgmac()) {
+		/* msgring interrupt should be disabled */
+		msgring_int_type = 0x0;
+
+		pop_bucket_start[id >> 2] = 0;
+		pop_bucket_end[id >> 2] = 4;
+		pop_bucket_mask[id >> 2] = 0xf;
+	} else {
+		/* all the stations are owned by linux */
+		pop_bucket_start[id >> 2] = 0;
+		pop_bucket_end[id >> 2] = 8;
+		pop_bucket_mask[id >> 2] = 0xff;
+	}
+
+	/* if not thead 0 */
+	if ((id & 0x03) != 0) {
+		put_cpu();
+		return;
+	}
+
+	prom_dbg_msg("Initializing message ring for cpu_%d\n", id);
+
+	msgrng_flags_save(flags);
+
+	/* Message Stations are shared among all threads in a cpu core
+	 * Assume, thread 0 on all cores are always active when more than
+	 * 1 thread is active in a core
+	 */
+	if (is_xls()) {
+		if (id == 0) {
+			X_MSGRNG_BUCKETSIZE_INIT_CPU(XLS_MSG_TBL, 0);
+			MSGRNG_CC_INIT_CPU(XLS_MSG_TBL, 0);
+		} else if (id == 4) {
+			X_MSGRNG_BUCKETSIZE_INIT_CPU(XLS_MSG_TBL, 8);
+			MSGRNG_CC_INIT_CPU(XLS_MSG_TBL, 1);
+		} else if (id == 8) {
+			X_MSGRNG_BUCKETSIZE_INIT_CPU(XLS_MSG_TBL, 16);
+			MSGRNG_CC_INIT_CPU(XLS_MSG_TBL, 2);
+		} else if (id == 12) {
+			X_MSGRNG_BUCKETSIZE_INIT_CPU(XLS_MSG_TBL, 24);
+			MSGRNG_CC_INIT_CPU(XLS_MSG_TBL, 3);
+		}
+	} else {
+		if (shared_msgring) {
+			if (id == 0) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     0);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 0);
+			} else if (id == 4) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     8);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 1);
+			} else if (id == 8) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     16);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 2);
+			} else if (id == 12) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     24);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 3);
+			} else if (id == 16) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     32);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 4);
+			} else if (id == 20) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     40);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 5);
+			} else if (id == 24) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     48);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 6);
+			} else if (id == 28) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(SHARED_XLR_MSG_TBL,
+							     56);
+				MSGRNG_CC_INIT_CPU(SHARED_XLR_MSG_TBL, 7);
+			}
+		} else {
+			if (id == 0) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 0);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 0);
+			} else if (id == 4) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 8);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 1);
+			} else if (id == 8) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 16);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 2);
+			} else if (id == 12) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 24);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 3);
+			} else if (id == 16) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 32);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 4);
+			} else if (id == 20) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 40);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 5);
+			} else if (id == 24) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 48);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 6);
+			} else if (id == 28) {
+				X_MSGRNG_BUCKETSIZE_INIT_CPU(XLR_MSG_TBL, 56);
+				MSGRNG_CC_INIT_CPU(XLR_MSG_TBL, 7);
+			}
+		}
+	}
+	msgrng_flags_restore(flags);
+	put_cpu();
+}
+
+void phnx_msgring_config(void)
+{
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	/* If we use NAPI then we enable queue non-empty interrupt */
+	msgring_int_type = rmi_msgring_napi ? 0x01 : 0x02;
+#else
+	msgring_int_type = 0x02;
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+	msgring_watermark_count = 1;
+	msgring_thread_mask = 0x0f;
+
+/* 	printk("[%s]: int_type = 0x%x, pop_num_buckets=%d, pop_bucket_mask=%x" */
+/* 	       "watermark_count=%d, thread_mask=%x\n", __FUNCTION__, */
+/* 	       msgring_int_type, msgring_pop_num_buckets, msgring_pop_bucket_mask, */
+/* 	       msgring_watermark_count, msgring_thread_mask); */
+}
+
+void phnx_derive_cpu_to_bkt_map(void)
+{
+	int cpus_per_core[NR_CORES];
+	int stns_per_core[NR_CORES];
+	int num_cpus, cpus, cpu_off, from, i;
+	int bucket_mask[NR_CPUS_PER_CORE];
+	int fr_bucket[NR_CPUS_PER_CORE];
+	int core, bkt_idx, bkt_mask;
+
+#define GET_NEXT_SET_BIT_U8(val, rv) { \
+    if(val < ( 1 << rv)) \
+        rv = 0; \
+    for(i = rv; val != 0 && i <= 7; i++) { \
+        if(val & (1 << i)) { \
+            rv = i; \
+            break; \
+        } \
+    }  \
+    if( i >= 8) \
+        rv = 0; \
+}
+
+	memset(cpus_per_core, 0, sizeof(cpus_per_core));
+	memset(stns_per_core, 0, sizeof(stns_per_core));
+
+	for (i = 0; i < NR_CPUS; i++) {
+		if (!(hard_cpu_online_map & (1 << i)))
+			continue;
+		core = i / NR_CPUS_PER_CORE;
+		cpus_per_core[core]++;
+	}
+	for (core = 0; core < NR_CORES; core++) {
+		for (i = 0; i < NR_STNS_PER_CORE; i++) {
+			if (!(pop_bucket_mask[core] & (1 << i)))
+				continue;
+			stns_per_core[core]++;
+		}
+	}
+
+	for (core = 0; core < NR_CORES; core++) {
+		int filled_all = 0;
+		int rv = 0;
+		uint8_t fr_bucket_map = 0;
+		memset(bucket_mask, 0, sizeof(bucket_mask));
+		memset(fr_bucket, 0xff, sizeof(fr_bucket));
+
+        num_cpus = cpus_per_core[core];
+        if(num_cpus == 0)
+            continue;
+        for(cpus = 0, bkt_idx = 0, bkt_mask = pop_bucket_mask[core];
+                bkt_mask; bkt_mask = bkt_mask >> 1, bkt_idx++) {
+            if(!(bkt_mask & 0x01))
+                continue;
+            bucket_mask[cpus] |=  (1 << bkt_idx);
+			
+			if(((int)fr_bucket[cpus] != -1) && (fr_bucket[cpus] < NR_CPUS_PER_CORE))
+                fr_bucket_map &= (~(1 << fr_bucket[cpus]));
+            fr_bucket_map |= (1 << bkt_idx);
+			fr_bucket[cpus] = bkt_idx;
+
+			if((cpus + 1) == num_cpus)
+            	filled_all = 1;
+
+            cpus = (cpus + 1) % num_cpus;
+        }
+
+        /* fill the non filled cpus */
+		if(filled_all == 0) {
+	        for(from = 0; cpus < num_cpus; cpus++, from++) {
+    	        bucket_mask[cpus] = bucket_mask[from];
+       	 	}
+		}
+        cpu_off = core * NR_CPUS_PER_CORE;
+        for(from = 0, cpus = cpu_off;
+                cpus < cpu_off + NR_CPUS_PER_CORE; cpus++) {
+            if(!(hard_cpu_online_map & (1 << cpus)))
+                continue;
+            cpu_to_bktmask[cpus] = bucket_mask[from];
+			GET_NEXT_SET_BIT_U8(fr_bucket_map, rv);
+            cpu_to_frstid[cpus] = rv + (core * NR_STNS_PER_CORE);
+            from++;
+			rv++;
+        }
+    }
+#if 0
+	for (i = 0; i < NR_CPUS; i++)
+		printk("%d: bktmask=0x%x frstid=%d\n",
+		       i, cpu_to_bktmask[i], cpu_to_frstid[i]);
+#endif
+
+	return;
+}
+
+static int __init xlr_msgring_watermark_setup(char *str)
+{
+	if (*str == '=')
+		str++;
+
+	msgring_watermark_count = (int)simple_strtoul(str, NULL, 10);
+
+	return 1;
+}
+
+static int __init xlr_msgring_thread_mask_setup(char *str)
+{
+	if (*str == '=')
+		str++;
+
+	msgring_thread_mask = simple_strtoul(str, NULL, 16);
+	msgring_thread_mask &= 0x0f;
+
+	return 1;
+}
+
+static int __init xlr_complete_msgring_thread_mask_setup(char *str)
+{
+	if (*str == '=')
+		str++;
+	msgring_global_thread_mask = simple_strtoul(str, NULL, 16);
+	msgring_global_thread_mask &= 0xffffffff;
+	return 1;
+}
+
+__setup("xlr_msgring_watermark=", xlr_msgring_watermark_setup);
+__setup("xlr_msgring_thread_mask=", xlr_msgring_thread_mask_setup);
+__setup("xlr_complete_msgring_thread_mask=",
+	xlr_complete_msgring_thread_mask_setup);
+
+extern void phoenix_cpu_stat_update_msgring_int(void);
+extern void phoenix_cpu_stat_update_msgring_cycles(__u32 cycles);
+extern void phoenix_cpu_stat_update_msgring_pic_int(void);
+
+void msgring_process_rx_msgs(int start_bucket, int end_bucket,
+			     __u32 pop_bucket_mask)
+{
+	unsigned int bucket_empty_bm = 0;
+	int bucket = 0;
+	int size = 0, code = 0, rx_stid = 0;
+	struct msgrng_msg msg;
+	struct tx_stn_handler *handler = 0;
+	unsigned int status = 0;
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	if (xlr_napi_ready && in_irq()) {
+		xlr_napi_rx_schedule();
+		return;
+	}
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+	/* First Drain all the high priority messages */
+	for (;;) {
+
+		bucket_empty_bm =
+		    (msgrng_read_status() >> 24) & pop_bucket_mask;
+
+		/* all buckets empty, break */
+		if (bucket_empty_bm == pop_bucket_mask)
+			break;
+
+		for (bucket = start_bucket; bucket < end_bucket; bucket++) {
+
+			if ((bucket_empty_bm & (1 << bucket)) ||	/* empty */
+			    !((1 << bucket) & pop_bucket_mask))	/* not in mask */
+				continue;
+
+			status =
+			    message_receive(bucket, &size, &code, &rx_stid,
+					    &msg);
+			if (status)
+				continue;
+
+			handler = &tx_stn_handler_map[rx_stid];
+			/* Handler is always present. If not actual, atleast 
+			 * dummy_handler
+			 */
+			(handler->action) (bucket, size, code, rx_stid, &msg,
+					   handler->dev_id);
+		}
+	}
+}
+
+#if !defined(CONFIG_PHOENIX_MAC) && !defined(CONFIG_RMI_XLP)
+__u64 xlr_cp2_exceptions[32];
+struct user_mac_data *user_mac;
+struct user_mac_kernal_data user_mac_krnl_data;
+struct xlr_user_mac_config xlr_user_mac;
+void phoenix_cpu_stat_update_msgring_int(void) { }
+void phoenix_cpu_stat_update_msgring_cycles(__u32 cycles) { }
+void phoenix_cpu_stat_update_msgring_pic_int(void) { }
+#endif /* CONFIG_PHOENIX_MAC */
+
+__u32 msgrng_msg_cycles = 0;
+void phnx_msgring_int_handler(unsigned int irq, struct pt_regs *regs)
+{
+	unsigned long mflags;
+	int core;
+	__u32 cycles = 0;
+
+	if (irq == IRQ_MSGRING) {
+		/* normal message ring interrupt */
+		phnx_inc_counter(MSGRNG_INT);
+		phoenix_cpu_stat_update_msgring_int();
+	} else {
+		phoenix_cpu_stat_update_msgring_pic_int();
+	}
+
+	irq_enter();
+
+	//dbg_msg("IN irq=%d\n", irq);
+
+	/* TODO: not necessary to disable preemption */
+	msgrng_flags_save(mflags);
+
+	cycles = read_c0_count();
+
+	core = cpu_logical_map(smp_processor_id()) >> 2;
+	msgring_process_rx_msgs(pop_bucket_start[core], pop_bucket_end[core], pop_bucket_mask[core]);
+
+	phoenix_cpu_stat_update_msgring_cycles(read_c0_count() - cycles);
+
+	msgrng_flags_restore(mflags);
+
+	//dbg_msg("OUT irq=%d\n", irq);
+
+	/* Call the msg callback */
+	irq_exit();
+}
+
+static void enable_msgring_int(void *info)
+{
+	unsigned long flags = 0, mflags = 0;
+	unsigned int th_mask;
+	unsigned int core;
+	msgrng_access_save(&msgrng_lock, flags, mflags);
+
+	core = hard_smp_processor_id() & ~(0x3);
+	th_mask = (msgring_global_thread_mask >> core) & 0x0f;
+
+	if(rmik_en) {
+		th_mask = rmik_cpu_msgring_int_mask[phoenix_cpu_id()];
+		if(th_mask == 0) {
+			msgrng_access_restore(&msgrng_lock, flags, mflags);
+			return;
+		}
+	}
+#if 0
+	printk
+	    ("[%s:%d] cpu_%d cpu_online_map=0x%04x msgring_global_mask=0x%08x "
+	     "th_mask=0x%02x intype=%d wm=%d\n", __FUNCTION__, __LINE__,
+	     hard_smp_processor_id(), hard_cpu_online_map,
+	     msgring_global_thread_mask, th_mask, msgring_int_type,
+	     msgring_watermark_count);
+#endif
+
+	/* enable the message ring interrupts */
+	msgrng_write_config((msgring_watermark_count << 24) |
+			    (IRQ_MSGRING << 16)
+			    | (th_mask << 8) | msgring_int_type);
+	msgrng_access_restore(&msgrng_lock, flags, mflags);
+}
+
+static void msgring_bkp_timer(unsigned long data)
+{
+	unsigned long flags;
+	struct timer_list *timer = (struct timer_list *)data;
+	local_irq_save(flags);
+	phnx_msgring_int_handler(-1,NULL);
+	local_irq_restore(flags);
+	mod_timer(timer, timer->expires+2);
+}
+
+static void enable_msgring_timer(void *data)
+{
+	struct timer_list *timer;
+	timer = kmalloc(sizeof(struct timer_list), GFP_KERNEL);
+	setup_timer(timer, msgring_bkp_timer, (unsigned long)timer);
+	timer->expires = jiffies + 2;
+	add_timer(timer);
+}
+
+extern spinlock_t phnx_pic_lock;
+int register_msgring_handler(int major,
+			     void (*action) (int, int, int, int,
+					     struct msgrng_msg *, void *),
+			     void *dev_id)
+{
+	struct tx_stn_handler *handler = 0;
+	int ret = 1;
+	int i,j,tx_stid;
+	unsigned long flags = 0;
+	cpumask_t timer_cpu_mask;
+
+	if (major >= MAX_TX_STNS || action == NULL) {
+		printk(KERN_ALERT "%s:%d  Invalid parameter: major=%d, "
+		       "MAX_TX_STN=%d action=%p",
+		       __FUNCTION__, __LINE__, major, MAX_TX_STNS, action);
+		return ret;
+	}
+
+	/* Check if the message station is valid, if not return error */
+	spin_lock_irqsave(&msgrng_lock, flags);
+
+	for (i = 0; i < 128; i++) {
+		if (is_xls())
+			tx_stid = xls_rxstn_to_txstn_map[i];
+		else
+			tx_stid = rxstn_to_txstn_map[i];
+		if (tx_stid == major) {
+			tx_stn_handler_map[i].action = action;
+			tx_stn_handler_map[i].dev_id = dev_id;
+		}
+	}
+
+	handler = &tx_stns[major].handler;
+
+	// dbg_msg("major=%d, action=%p, dev_id=%p\n", major, action, dev_id);
+	handler->action = action;
+	handler->dev_id = dev_id;
+
+	ret = 0;
+	spin_unlock_irqrestore(&msgrng_lock, flags);
+
+	if (!ret && phnx_test_and_set(&msgring_registered)) {
+		int i=0;
+
+		hard_cpu_online_map = 0;
+		for (i = 0; i < NR_CPUS; i++) {
+			if (cpu_isset(i, cpu_online_map))
+				hard_cpu_online_map |=
+				    (1 << cpu_logical_map(i));
+		}
+
+		/* derive the cpu to bucket map */
+		phnx_derive_cpu_to_bkt_map();
+
+		if(rmik_en) {
+			msgring_int_en = 1; 
+			if (xlr_hybrid_user_mac() || xlr_hybrid_user_mac_xgmac()) {
+				printk("Disabling msgring interrupt\n");
+				msgring_int_en = 0;
+			}
+			/* msgring_int function checks the mask */
+			rmik_derive_msgring_int_mask();
+		}
+
+		/* Configure PIC to deliver msgring interrupt for timeouts */
+		if (msgring_global_thread_mask == 0) {
+			for (i = 0; i < NR_CORES; i++) {
+				msgring_global_thread_mask |=
+				    (msgring_thread_mask << (i << 2));
+			}
+		}
+
+		msgring_global_thread_mask &= hard_cpu_online_map;
+
+		/* configure the msgring interrupt on all cpus */
+		if (msgring_int_en)
+			on_each_cpu(enable_msgring_int, 0, 1);
+
+/* 		printk("[%s]: cpu_online_map = %lx, hard_cpu_online_map=%x, " */
+/* 		       "msgring_global_thread_mask=%x\n", */
+/* 		       __FUNCTION__,  */
+/* 		       (unsigned long)cpu_online_map,  */
+/* 		       hard_cpu_online_map,  */
+/* 		       msgring_global_thread_mask); */
+
+		/* Schedule a messagering backup timer at every 2 jiffies on one 
+		   therad per core 
+		 */
+
+		cpus_clear(timer_cpu_mask);
+		for(i = 0; i < NR_CORES; i++) {
+			int core_mask;			
+			int phys_id, logical_id;
+			if(hard_cpu_online_map & (0xf<<(i*NR_CPUS_PER_CORE))){
+				core_mask = (hard_cpu_online_map>>(i*NR_CPUS_PER_CORE)) & 0xf;
+				for(j=0; j<NR_CPUS_PER_CORE; j++){
+					if(core_mask & (1<<j))
+						break;
+				}
+				phys_id = (i*NR_CPUS_PER_CORE) + j;
+				logical_id = cpu_number_map(phys_id);
+				cpu_set(logical_id, timer_cpu_mask);
+			}
+		}
+		preempt_disable();
+		smp_call_function_many(&timer_cpu_mask, enable_msgring_timer, NULL, 1);
+		preempt_enable();
+		if(cpu_isset(cpu_number_map(hard_smp_processor_id()),timer_cpu_mask))
+			enable_msgring_timer(NULL);
+	}
+
+	return ret;
+}
+
+EXPORT_SYMBOL(register_msgring_handler);
+
+static void pic_init(void)
+{
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+	int i = 0;
+	int level;
+	uint32_t thread_mask = (1 << hard_smp_processor_id());
+
+	for (i = 0; i < PIC_NUM_IRTS; i++) {
+
+		level = PIC_IRQ_IS_EDGE_TRIGGERED(i);
+
+		/* Bind all PIC irqs to boot cpu */
+#if defined(XLP_SIM)
+		mmio = 0;	/* For compiler sake */
+		/* Use local scheduling and high polarity for all IRTs
+		 * Invalidate all IRTs, by default
+		 */
+		pic_write_irt(i, 0, 0, 1, irt_to_irq(i), 1, 0, thread_mask);
+#else
+		phoenix_write_reg(mmio, PIC_IRT_0_BASE + i, thread_mask);
+
+		/* Use local scheduling and high polarity for all IRTs
+		 * Invalidate all IRTs, by default
+		 */
+		phoenix_write_reg(mmio, PIC_IRT_1_BASE + i,
+				  (level << 30) | (1 << 6) | (PIC_IRQ_BASE +
+							      i));
+#endif
+	}
+}
+
+atomic_t phnx_counters[NR_CPUS][PHNX_MAX_COUNTERS] __cacheline_aligned;
+
+static void rmi_usb_init (void)
+{
+	phoenix_reg_t * gpio_mmio = phoenix_io_mmio(PHOENIX_IO_GPIO_OFFSET);
+	phoenix_reg_t * usb_mmio  = phoenix_io_mmio(PHOENIX_IO_USB_1_OFFSET);
+
+   /* The RMI-Specific USB Block */
+   phoenix_write_reg(usb_mmio, 49, 0x10000000); //Clear Rogue Phy INTs
+   phoenix_write_reg(usb_mmio, 50, 0x1f000000);
+
+	if (is_xls1xx()) {
+		/* Enabling only 1 USB Port */
+		if (xlr_board_atx_viii()) {
+			/* LTE board has usb port #1 */
+			phoenix_write_reg(usb_mmio,  1, 0x05000500);
+		}
+		else {
+			/* enable usb port #0 */
+			phoenix_write_reg(usb_mmio,  1, 0x03000500);
+		}
+	}
+	else {
+   	phoenix_write_reg(usb_mmio,  1, 0x07000500);
+	}
+
+   {
+      volatile unsigned int value = gpio_mmio[21];
+      if ((value >> 22) & 0x01) {
+         printk("Detected USB Host mode..\n");
+         phoenix_write_reg(usb_mmio,  0, 0x02000000);
+      }
+      else {
+         printk("Detected USB Device mode..\n");
+         phoenix_write_reg(usb_mmio,  0, 0x01000000);
+      }
+   }
+}
+
+void on_chip_init(void)
+{
+	int i = 0, j = 0;
+
+	cpu_logical_map(0)  = hard_smp_processor_id();
+
+	/* Set phoenix_io_base to the run time value */
+	spin_lock_init(&msgrng_lock);
+
+	msgring_registered.value = 0;
+
+#if defined(CONFIG_RMI_XLP)
+	xlp_dev_init();
+#endif
+
+	phnx_msgring_config();
+
+	pic_init(); 
+
+	/* XLP FMN code Not Yet ported! */
+#if !defined(CONFIG_RMI_XLP)
+	phoenix_msgring_cpu_init();
+#endif
+
+
+
+	for (i = 0; i < NR_CPUS; i++)
+		for (j = 0; j < PHNX_MAX_COUNTERS; j++)
+			atomic_set(&phnx_counters[i][j], 0);
+
+	if (is_xls())
+		rmi_usb_init();
+}
diff --git a/arch/mips/rmi/phoenix/platform.c b/arch/mips/rmi/phoenix/platform.c
new file mode 100644
index 0000000..742c6d9
--- /dev/null
+++ b/arch/mips/rmi/phoenix/platform.c
@@ -0,0 +1,120 @@
+/************************************************************************
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: Adapted Platform device support for RMI XLS[4/2]xx
+
+ *****************************#RMI_1#************************************/
+
+/*
+ * Copyright 2004, Matt Porter <mporter@kernel.crashing.org>
+ *
+ * This file is licensed under the terms of the GNU General Public
+ * License version 2.  This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/resource.h>
+#include <asm/rmi/rmi_srio.h>
+
+static u64 xls_usb_dmamask = ~(u32) 0;
+
+static struct platform_device xls_usb_ehci_device = {
+	.name = "ehci-xls",
+	.id = 0,
+	.num_resources = 2,
+	.dev = {
+		.dma_mask = &xls_usb_dmamask,
+		.coherent_dma_mask = 0xffffffff,
+		},
+	.resource = (struct resource[]){
+					{
+					 .start = 0x1EF24000,
+					 .end = (0x1EF24000 + 0x400 - 0x01),
+					 .flags = IORESOURCE_MEM,
+					 },
+					{
+					 .start = 39,
+					 .end = 39,
+					 .flags = IORESOURCE_IRQ,
+					 },
+					},
+};
+
+static struct platform_device xls_usb_ohci_device_0 = {
+	.name = "ohci-xls-0",
+	.id = 1,
+	.num_resources = 2,
+	.dev = {
+		.dma_mask = &xls_usb_dmamask,
+		.coherent_dma_mask = 0xffffffff,
+		},
+	.resource = (struct resource[]){
+					{
+					 .start = 0x1EF24400,
+					 .end = (0x1EF24400 + 0x400 - 0x01),
+					 .flags = IORESOURCE_MEM,
+					 },
+					{
+					 .start = 39,
+					 .end = 39,
+					 .flags = IORESOURCE_IRQ,
+					 },
+					},
+};
+
+static struct platform_device xls_usb_ohci_device_1 = {
+	.name = "ohci-xls-1",
+	.id = 2,
+	.num_resources = 2,
+	.dev = {
+		.dma_mask = &xls_usb_dmamask,
+		.coherent_dma_mask = 0xffffffff,
+		},
+	.resource = (struct resource[]){
+					{
+					 .start = 0x1EF24800,
+					 .end = (0x1EF24800 + 0x400 - 0x01),
+					 .flags = IORESOURCE_MEM,
+					 },
+					{
+					 .start = 39,
+					 .end = 39,
+					 .flags = IORESOURCE_IRQ,
+					 },
+					},
+};
+
+static struct platform_device *xls_platform_devices[] __initdata = {
+	&xls_usb_ehci_device,
+	&xls_usb_ohci_device_0,
+	&xls_usb_ohci_device_1,
+};
+
+int xls_platform_init(void)
+{
+    extern uint32_t dev_tree_en;
+    extern int fdt_get_usb_enabled(void);
+
+    if (dev_tree_en && fdt_get_usb_enabled() == 0) {
+        printk("USB disabled in configuration, skipping...\n");
+        return 0;
+    }
+
+    return platform_add_devices(xls_platform_devices, ARRAY_SIZE(xls_platform_devices));
+}
+
+arch_initcall(xls_platform_init);
+
+#ifdef CONFIG_RAPIDIO
+void platform_rio_init(void)
+{
+	rmi_rio_setup();
+}
+#endif				/* CONFIG_RAPIDIO */
diff --git a/arch/mips/rmi/phoenix/rmi_srio.c b/arch/mips/rmi/phoenix/rmi_srio.c
new file mode 100644
index 0000000..d46cac4
--- /dev/null
+++ b/arch/mips/rmi/phoenix/rmi_srio.c
@@ -0,0 +1,2228 @@
+/************************************************************************
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: Added SRIO controller driver for RMI XLS[4/6]xx
+
+ *****************************#RMI_1#************************************/
+
+/*
+ * MPC85xx RapidIO support
+ *
+ * Copyright 2005 MontaVista Software, Inc.
+ * Matt Porter <mporter@kernel.crashing.org>
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/dma-mapping.h>
+#include <linux/interrupt.h>
+#include <linux/rio.h>
+#include <linux/rio_drv.h>
+#include <linux/delay.h>
+#include <asm/rmi/rmi_srio.h>
+#include <asm/rmi/gpio.h>
+#include <asm/io.h>
+#include <asm/delay.h>
+#include <asm/rmi/sim.h>
+
+#define MYDBG(a,b...)
+#define Message(a,b...)		//printk("\nFunction[%s]-Line[%d]\n"a"\n",__FUNCTION__,__LINE__,##b)
+
+struct transaction_queue {
+	uint32_t *orig;
+	uint32_t start;
+	uint32_t end;
+	uint32_t head;
+	uint32_t tail;
+	spinlock_t lock;
+	uint32_t max_entries;
+	int curr_free_tq_entry;
+	int active;
+};
+
+struct status_queue {
+	uint32_t *orig;
+	uint32_t start;
+	uint32_t end;
+	uint32_t head;
+	uint32_t tail;
+	int active;
+	spinlock_t lock;
+	void *dev_id;
+	uint32_t max_entries;
+	int curr_sq_index;
+};
+
+struct mailbox_queue {
+	uint32_t *orig;
+	uint32_t start;
+	uint32_t end;
+	uint32_t head;
+	uint32_t tail;
+	int active;
+	spinlock_t lock;
+	void *dev_id;
+	uint32_t max_entries;
+};
+
+struct freel_queue {
+	uint32_t *orig;
+	uint32_t start;
+	uint32_t end;
+	uint32_t head;
+	uint32_t tail;
+	int active;
+	spinlock_t lock;
+	uint32_t max_entries;
+};
+
+struct rmi_rio_controller {
+	struct rio_mport *port;
+	int host_deviceid;
+	int index;
+	unsigned long regs_phy_start;
+	unsigned long regs_virt_start;
+	struct transaction_queue tq[MAX_TRANSACTION_Q];
+	struct status_queue sq[MAX_STATUS_Q];
+	struct mailbox_queue mq[MAX_MAILBOX_Q];
+	struct freel_queue fq[MAX_FREEL_Q];
+	int irq;
+	spinlock_t maintenance_lock;	/*lock for maintenance transactions. */
+	spinlock_t mailbox_lock;	/*lock for mailbox transactions. */
+	spinlock_t freel_lock;	/*lock for freeq. */
+};
+
+/*All function declaration goes here.*/
+int rmi_local_config_read(struct rmi_rio_controller *rio_ctrl,
+			  int pindex, u32 offset, int len, u32 * data);
+int rmi_local_config_write(struct rmi_rio_controller *rio_ctrl,
+			   int pindex, u32 offset, int len, u32 data);
+int rmi_rio_config_read(struct rmi_rio_controller *rio_ctrl,
+			int pindex, u16 destid, u8 hopcount,
+			u32 offset, int len, u32 * val);
+int rmi_rio_config_write(struct rmi_rio_controller *rio_ctrl,
+			 int pindex, u16 destid, u8 hopcount, u32 offset,
+			 int len, u32 val);
+int rmi_rio_doorbell_send(struct rmi_rio_controller *rio_ctrl,
+			  int pindex, u16 destid, u16 data);
+
+int rmi_setup_transaction_queue(struct rmi_rio_controller *rio_ctrl,
+				struct transaction_queue *tq, int tq_index,
+				int tq_entries);
+
+int rmi_setup_status_queue(struct rmi_rio_controller *rio_ctrl,
+			   struct status_queue *sq, int sq_index,
+			   int sq_entries);
+
+int rmi_setup_mailbox_queue(struct rmi_rio_controller *rio_ctrl,
+			    struct mailbox_queue *mq, int mq_index,
+			    int mq_entries);
+
+int rmi_setup_freel_queue(struct rmi_rio_controller *rio_ctrl,
+			  struct freel_queue *fq, int fq_index, int fq_entries);
+
+void free_unregistered_resrources(void);
+
+int rmi_clear_transaction_queue(struct rmi_rio_controller *rio_ctrl,
+				struct transaction_queue *tq, int tq_index);
+
+int rmi_clear_status_queue(struct rmi_rio_controller *rio_ctrl,
+			   struct status_queue *sq, int sq_index);
+
+int rmi_clear_mailbox_queue(struct rmi_rio_controller *rio_ctrl,
+			    struct mailbox_queue *mq, int mq_index);
+
+int rmi_clear_freel_queue(struct rmi_rio_controller *rio_ctrl,
+			  struct freel_queue *fq, int fq_index);
+
+/*Global data structures*/
+int srio_ports;
+int srio_mode;
+extern unsigned long phoenix_io_base;
+
+int rmi_rio_host_id[MAX_SRIO_PORTS] = { -1, -1, -1, -1 };
+
+unsigned long rio_reg_phy_start[MAX_SRIO_PORTS] =
+    { RMI_SRIO_MEM_0, RMI_SRIO_MEM_1, RMI_SRIO_MEM_2, RMI_SRIO_MEM_3 };
+
+struct rmi_rio_controller *rio_controller[MAX_SRIO_PORTS] = { NULL };
+extern int fdt_get_srio_port_map(uint32_t *srio_port_map);
+extern uint32_t dev_tree_en;
+
+/*controller-0 rio ops*/
+RIO_OPS_LOCAL_CONFIG_READ(0)
+    RIO_OPS_LOCAL_CONFIG_WRITE(0)
+    RIO_OPS_CONFIG_READ(0)
+    RIO_OPS_CONFIG_WRITE(0)
+    RIO_OPS_DOORBELL_SEND(0)
+
+/*controller-1 rio ops*/
+    RIO_OPS_LOCAL_CONFIG_READ(1)
+    RIO_OPS_LOCAL_CONFIG_WRITE(1)
+    RIO_OPS_CONFIG_READ(1)
+    RIO_OPS_CONFIG_WRITE(1)
+    RIO_OPS_DOORBELL_SEND(1)
+
+/*controller-2 rio ops*/
+    RIO_OPS_LOCAL_CONFIG_READ(2)
+    RIO_OPS_LOCAL_CONFIG_WRITE(2)
+    RIO_OPS_CONFIG_READ(2)
+    RIO_OPS_CONFIG_WRITE(2)
+    RIO_OPS_DOORBELL_SEND(2)
+
+/*controller-3 rio ops*/
+    RIO_OPS_LOCAL_CONFIG_READ(3)
+    RIO_OPS_LOCAL_CONFIG_WRITE(3)
+    RIO_OPS_CONFIG_READ(3)
+    RIO_OPS_CONFIG_WRITE(3)
+    RIO_OPS_DOORBELL_SEND(3)
+
+int rmi_rio_get_cmdline_0(char *s)
+{
+	int id;
+	if (!s)
+		return 0;
+	id = simple_strtoul(s, NULL, 10);
+	rmi_rio_host_id[0] = id;
+	return 1;
+}
+
+__setup("riohdid0=", rmi_rio_get_cmdline_0);
+
+int rmi_rio_get_cmdline_1(char *s)
+{
+	int id;
+	if (!s)
+		return 0;
+	id = simple_strtoul(s, NULL, 10);
+	rmi_rio_host_id[1] = id;
+	return 1;
+}
+
+__setup("riohdid1=", rmi_rio_get_cmdline_1);
+
+int rmi_rio_get_cmdline_2(char *s)
+{
+	int id;
+	if (!s)
+		return 0;
+	id = simple_strtoul(s, NULL, 10);
+	rmi_rio_host_id[2] = id;
+	return 1;
+}
+
+__setup("riohdid2=", rmi_rio_get_cmdline_2);
+
+int rmi_rio_get_cmdline_3(char *s)
+{
+	int id;
+	if (!s)
+		return 0;
+	id = simple_strtoul(s, NULL, 10);
+	rmi_rio_host_id[3] = id;
+	return 1;
+}
+
+__setup("riohdid3=", rmi_rio_get_cmdline_3);
+
+void *rmi_rio_ops[MAX_SRIO_PORTS][5] = {
+
+	{rmi_local_config_read_0,
+	 rmi_local_config_write_0,
+	 rmi_rio_config_read_0,
+	 rmi_rio_config_write_0,
+	 rmi_rio_doorbell_send_0},
+	{rmi_local_config_read_1,
+	 rmi_local_config_write_1,
+	 rmi_rio_config_read_1,
+	 rmi_rio_config_write_1,
+	 rmi_rio_doorbell_send_1},
+	{rmi_local_config_read_2,
+	 rmi_local_config_write_2,
+	 rmi_rio_config_read_2,
+	 rmi_rio_config_write_2,
+	 rmi_rio_doorbell_send_2},
+	{rmi_local_config_read_3,
+	 rmi_local_config_write_3,
+	 rmi_rio_config_read_3,
+	 rmi_rio_config_write_3,
+	 rmi_rio_doorbell_send_3}
+};
+
+#ifdef RMI_SRIO_DEBUG
+
+void dump_mq_regs(struct rmi_rio_controller *rio_ctrl,
+		  struct mailbox_queue *mq, int mq_index)
+{
+	uint32_t data;
+	printk("\nmq->orig %#lx\n", mq->orig);
+	rmi_local_config_read(rio_ctrl, 0, MAILBOX_QUEUE_START(mq_index), 4,
+			      &data);
+	printk("\nMQ QUEUE HEAD = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, MAILBOX_QUEUE_END(mq_index), 4,
+			      &data);
+	printk("\nMQ QUEUE END = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, MAILBOX_QUEUE_HEAD(mq_index), 4,
+			      &data);
+	printk("\nMQ QUEUE HEAD = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, MAILBOX_QUEUE_TAIL(mq_index), 4,
+			      &data);
+	printk("\nMQ QUEUE TAIL = %#x\n", data);
+
+}
+
+void dump_fq_regs(struct rmi_rio_controller *rio_ctrl,
+		  struct freel_queue *fq, int fq_index)
+{
+	uint32_t data;
+	printk("\nfq->orig %#lx\n", fq->orig);
+	rmi_local_config_read(rio_ctrl, 0, FREEL_QUEUE_START(fq_index), 4,
+			      &data);
+	printk("\nFREEL QUEUE HEAD = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, FREEL_QUEUE_END(fq_index), 4, &data);
+	printk("\nFREEL QUEUE END = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, FREEL_QUEUE_HEAD(fq_index), 4,
+			      &data);
+	printk("\nFREEL QUEUE HEAD = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, FREEL_QUEUE_TAIL(fq_index), 4,
+			      &data);
+	rmi_local_config_write(rio_ctrl, 0, FREEL_QUEUE_TAIL(fq_index), 4,
+			       data | 0x1);
+	printk("\nFREEL QUEUE TAIL = %#x\n", data);
+
+}
+
+void dump_tq_regs(struct rmi_rio_controller *rio_ctrl,
+		  struct transaction_queue *tq, int tq_index)
+{
+	uint32_t data;
+	printk("\ntq->orig %#lx\n", tq->orig);
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_START(tq_index), 4,
+			      &data);
+	printk("\nTRANSACTION QUEUE HEAD = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_END(tq_index), 4,
+			      &data);
+	printk("\nTRANSACTION QUEUE END = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_HEAD(tq_index), 4,
+			      &data);
+	printk("\nTRANSACTION QUEUE HEAD = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_TAIL(tq_index), 4,
+			      &data);
+	rmi_local_config_write(rio_ctrl, 0, TRANSACTION_QUEUE_TAIL(tq_index), 4,
+			       data | 0x1);
+	printk("\nTRANSACTION QUEUE TAIL = %#x\n", data);
+
+}
+
+void dump_sq_regs(struct rmi_rio_controller *rio_ctrl,
+		  struct status_queue *sq, int sq_index)
+{
+	uint32_t data;
+	printk("\nsq->orig %#lx\n", sq->orig);
+	rmi_local_config_read(rio_ctrl, 0, STATUS_QUEUE_START(sq_index), 4,
+			      &data);
+	printk("\nSTATUS QUEUE HEAD = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, STATUS_QUEUE_END(sq_index), 4,
+			      &data);
+	printk("\nSTATUS QUEUE END = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, STATUS_QUEUE_HEAD(sq_index), 4,
+			      &data);
+	printk("\nSTATUS QUEUE HEAD = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, STATUS_QUEUE_TAIL(sq_index), 4,
+			      &data);
+	printk("\nSTATUS QUEUE TAIL = %#x\n", data);
+
+}
+
+#endif
+
+struct rmi_rio_controller *to_rmi_rio_ctrl(struct rio_mport *mport)
+{
+	int i;
+	for (i = 0; i < MAX_SRIO_PORTS; i++) {
+		if (rio_controller[i]) {
+			if (rio_controller[i]->port == mport)
+				return rio_controller[i];
+		}
+	}
+	return NULL;
+}
+
+/**
+ * rio_open_outb_mbox - Initialize outbound mailbox
+ * @mport: Master port implementing the outbound message unit
+ * @dev_id: Device specific pointer to pass on event
+ * @mbox: Mailbox to open
+ * @entries: Number of entries in the outbound mailbox ring
+ *
+ * Initializes buffer ring, request the outbound message interrupt,
+ * and enables the outbound message unit. Returns %0 on success and
+ * %-EINVAL or %-ENOMEM on failure.
+ */
+int rio_open_outb_mbox(struct rio_mport *mport, void *dev_id, int mbox,
+		       int entries)
+{
+	struct rmi_rio_controller *rio_ctrl = to_rmi_rio_ctrl(mport);
+	int ret = 0;
+	uint32_t data;
+
+	MYDBG("Called");
+
+	if (entries < 4) {
+		printk("Minimum entries have to be 4\n");
+		return -1;
+	}
+
+	if (mbox != 0) {
+		printk("Invalid Resource for outb mbox - %d\n", mbox);
+		return -1;
+	}
+
+	/*setup transaction queue 0 */
+	ret = rmi_setup_transaction_queue(rio_ctrl, &rio_ctrl->tq[mbox], 0,
+					  entries);
+	if (ret)
+		return ret;
+
+	ret = rmi_setup_status_queue(rio_ctrl, &rio_ctrl->sq[mbox], 0, entries);
+
+	if (ret) {
+		rmi_clear_transaction_queue(rio_ctrl, &rio_ctrl->tq[mbox], 0);
+		return ret;
+	}
+
+	rio_ctrl->tq[mbox].curr_free_tq_entry = 0;
+	rio_ctrl->sq[mbox].curr_sq_index = 0;
+
+	/*Store max entries for this tq & sq */
+	rio_ctrl->tq[mbox].max_entries = entries;
+	rio_ctrl->sq[mbox].max_entries = entries;
+
+	/*Store dev_id to pass during callback */
+	rio_ctrl->sq[mbox].dev_id = dev_id;
+
+	/* Enable interrupts for status queue - TX OK */
+	rmi_local_config_read(rio_ctrl, 0, STATUS_QUEUE_IER, 4, &data);
+	data = data | (1 << NNE_INTR(mbox));
+	rmi_local_config_write(rio_ctrl, 0, STATUS_QUEUE_IER, 4, data);
+
+	return 0;
+}
+
+/**
+ * rio_close_outb_mbox - Shut down outbound mailbox
+ * @mport: Master port implementing the outbound message unit
+ * @mbox: Mailbox to close
+ *
+ * Disables the outbound message unit, free all buffers, and
+ * frees the outbound message interrupt.
+ */
+void rio_close_outb_mbox(struct rio_mport *mport, int mbox)
+{
+	struct rmi_rio_controller *rio_ctrl = to_rmi_rio_ctrl(mport);
+	struct transaction_queue *tq = &rio_ctrl->tq[mbox];
+	struct status_queue *sq = &rio_ctrl->sq[mbox];
+	unsigned long flags;
+
+	Message("");
+
+	spin_lock_irqsave(&tq->lock, flags);	/*lock against xmit */
+	spin_lock(&sq->lock);	/*lock against rx */
+
+	Message("");
+	/*clear transaction queue */
+	rmi_clear_transaction_queue(rio_ctrl, tq, mbox);
+
+	Message("");
+	/*clear status queue */
+	rmi_clear_status_queue(rio_ctrl, sq, mbox);
+
+	Message("");
+	spin_unlock(&sq->lock);
+	spin_unlock_irqrestore(&tq->lock, flags);
+	return;
+}
+
+/**
+ * rio_hw_add_outb_message - Add message to the outbound message queue
+ * @mport: Master port with outbound message queue
+ * @rdev: Target of outbound message
+ * @mbox: Destination mailbox number
+ * @buffer: MYDBG to add to outbound queue
+ * @len: Length of message
+ *
+ * Adds the @buffer message to the outbound message queue. Returns
+ * %0 on success or %-EINVAL on failure.
+ */
+int
+rio_hw_add_outb_message(struct rio_mport *mport, struct rio_dev *rdev, int mbox,
+			void *buffer, size_t len)
+{
+	struct rmi_rio_controller *rio_ctrl = to_rmi_rio_ctrl(mport);
+	int tq_index = 0;
+	unsigned long flags;
+	uint32_t tail_value = 0;
+	uint32_t *tail_ptr = NULL;
+	struct transaction_queue *tq = &rio_ctrl->tq[tq_index];
+	uint32_t word[6];
+	uint64_t phys64 = 0;
+	uint32_t phys = 0;
+#ifdef CONFIG_32BIT
+	uint32_t max_phys = 256 << 20;
+#else
+	uint32_t max_phys = 0xffffffff;
+#endif
+	uint32_t tran_size;
+	int retry_count = 0;
+	int destid = rdev->destid;
+
+	MYDBG("");
+	if (!tq->active)
+		return -1;
+
+	MYDBG("");
+	if (!len || (len & 0x7)) {
+		printk("\nXmit len has to be 8 byte aligned");
+		printk("\nInvalid buffer len\n");
+		return -1;
+	}
+
+	MYDBG("");
+	phys64 = virt_to_phys(buffer);
+
+	if ((phys64 > max_phys) || ((phys64 + len) > max_phys)) {
+		printk("\nInvalid xmit buffer address\n");
+#ifdef CONFIG_32BIT
+		printk("\nBuffer address has to be below 256M\n");
+#else
+		printk("\nBuffer address has to be below 4G\n");
+#endif
+		return -1;
+	}
+	phys = (uint32_t) phys64;
+	tran_size = (len / 8) - 1;
+
+      retry:
+
+	MYDBG("");
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_TAIL(tq_index), 4,
+			      &tail_value);
+	while ((tail_value & (1 << TQ_LOCK))) {
+		printk("\nTailQ - Locked- %#x\n", tail_value);
+		rmi_local_config_read(rio_ctrl, 0,
+				      TRANSACTION_QUEUE_TAIL(tq_index), 4,
+				      &tail_value);
+	}
+
+	if (tail_value & (1 << TQ_FULL)) {
+		tail_value |= (1 << TQ_LOCK);
+		printk("\nTailQ -Full - %#x\n", tail_value);
+		rmi_local_config_write(rio_ctrl, 0,
+				       TRANSACTION_QUEUE_TAIL(tq_index), 4,
+				       tail_value);
+		if (retry_count++ < 20)
+			goto retry;
+		else
+			return -1;
+	}
+
+	spin_lock_irqsave(&tq->lock, flags);
+
+	MYDBG("");
+	if (!tq->active) {
+		spin_unlock_irqrestore(&tq->lock, flags);
+		return -1;
+	}
+
+	MYDBG("");
+	tail_value = tail_value & 0xfffffff8;
+	tail_ptr = (uint32_t *) (unsigned long)CKSEG0ADDR(tail_value);
+
+#ifdef CONFIG_RAPIDIO_8_BIT_TRANSPORT
+	destid = destid & 0xff;
+	word[0] = __swab32((destid << MSG_DEST_ID) |
+			   (0 << MSG_DID_SIZE) | TYPE_MESSAGE);
+#else
+	destid = destid & 0xffff;
+	word[0] = __swab32((destid << MSG_DEST_ID) |
+			   (1 << MSG_DID_SIZE) | TYPE_MESSAGE);
+#endif
+	word[1] = __swab32(0x7 /*lower 3 bits are always set to 1 */  |
+			   tran_size << MSG_TRAN_SIZE | 0xe << MSG_SEG_SIZE |	/*256 bytes per segment */
+			   mbox << MSG_MAILBOX_NUMBER);
+	word[2] = __swab32((uint32_t) (phys));
+	word[3] = word[4] = word[5] = 0x0;
+
+	MYDBG("");
+	tail_ptr[0] = word[0];
+	tail_ptr[1] = word[1];
+	tail_ptr[2] = word[2];
+	tail_ptr[3] = word[3];
+	tail_ptr[4] = word[4];
+	tail_ptr[5] = word[5];
+	mb();
+
+	tq->curr_free_tq_entry++;
+	if (tq->curr_free_tq_entry >= tq->max_entries)
+		tq->curr_free_tq_entry = 0;
+
+	/*Kick the transcation by incrementing tail ptr */
+	tail_value += SIZE_OF_TQ_ENTRY;
+	if (tail_value > tq->end) {
+		MYDBG("Wraparound of transaction Queue %d", tq_index);
+		tail_value = tq->start;
+	}
+	tail_value = tail_value & ~0x7;
+	mb();
+	/* `sync` - make sure all data is written */
+	rmi_local_config_write(rio_ctrl, 0, TRANSACTION_QUEUE_TAIL(tq_index), 4,
+			       tail_value);
+	/*`sync` - make sure transaction is initiated */
+	mb();
+	MYDBG("");
+	spin_unlock_irqrestore(&tq->lock, flags);
+	return 0;
+}
+
+/**
+ * rio_hw_get_inb_message - Fetch inbound message from the message unit
+ * @mport: Master port implementing the inbound message unit
+ * @mbox: Inbound mailbox number
+ *
+ * Gets the next available inbound message from the inbound message queue.
+ * A pointer to the message is returned on success or NULL on failure.
+ */
+void *rio_hw_get_inb_message(struct rio_mport *mport, int mbox)
+{
+	struct rmi_rio_controller *rio_ctrl = to_rmi_rio_ctrl(mport);
+	uint32_t head_value;
+	volatile uint32_t word[4];
+	uint32_t orig_head_value;
+	volatile uint32_t *head_ptr = NULL;
+	struct mailbox_queue *mq = &rio_ctrl->mq[mbox];
+
+	rmi_local_config_read(rio_ctrl, 0, MAILBOX_QUEUE_HEAD(mbox), 4,
+			      &head_value);
+
+	if (!(head_value & (1 << MQ_EMPTY))) {
+
+		orig_head_value = head_value;
+		head_value = head_value & 0xfffffff8;
+
+		/*Left shift by 1 to get the actual physical address. */
+		head_value = head_value << 1;
+
+		/*Give sufficient delay so that glue logic copies data */
+//      udelay(1);
+
+		head_ptr =
+		    (volatile uint32_t *)(unsigned long)CKSEG0ADDR(head_value);
+
+	      retry:
+		word[0] = __swab32(head_ptr[0]);
+		if ((word[0] >> 2 & 0xf) == 0xf) {
+			goto retry;
+		}
+		mb();
+		if (((word[0] >> 2) & 0x8)) {
+			printk("\nword[0] = %#x\n", word[0]);
+			panic("\nSRIO: dma read from freel failed!!\n");
+		}
+
+		word[1] = __swab32(head_ptr[1]);
+		word[2] = __swab32(head_ptr[2]);
+		word[3] = __swab32(head_ptr[3]);
+
+#ifdef RMI_SRIO_DEBUG
+		if (((word[0] >> 2) & 0xf) != 0) {
+			printk
+			    ("\nMailbox Transaction turned in to an error !! Error %#x",
+			     word[0] >> 2 & 0xf);
+			panic("\npanic!!");
+		}
+#endif
+		head_ptr[0] = 0xffffffff;
+		mb();
+		/*Move head pointer ahead */
+		head_value += SIZE_OF_MQ_ENTRY;
+
+		/*Glue logic needs address to be right shifted by 1 */
+		head_value = head_value >> 1;
+
+		if (head_value > mq->end) {
+			head_value = mq->start;
+			MYDBG("Wraparound of Status Queue %d", sq_index);
+		}
+		rmi_local_config_write(rio_ctrl, 0, MAILBOX_QUEUE_HEAD(mbox), 4,
+				       head_value);
+
+		return phys_to_virt(word[2]);
+	}
+	return NULL;
+}
+
+/**
+ * rio_hw_add_inb_buffer - Add buffer to the inbound message queue
+ * @mport: Master port implementing the inbound message unit
+ * @mbox: Inbound mailbox number
+ * @buf: Buffer to add to inbound queue
+ *
+ * Assumes buffer size 4KB
+ * Adds the @buf buffer to the inbound message queue. Returns
+ * %0 on success or %-EINVAL on failure.
+ */
+int rio_hw_add_inb_buffer(struct rio_mport *mport, int mbox, void *buf)
+{
+	struct rmi_rio_controller *rio_ctrl = to_rmi_rio_ctrl(mport);
+	unsigned long flags;
+	uint32_t tail_value = 0;
+	uint32_t *tail_ptr = NULL;
+	struct freel_queue *fq = &rio_ctrl->fq[mbox];
+	uint32_t word[2];
+	uint64_t phys64 = 0;
+	uint32_t phys = 0;
+#ifdef CONFIG_32BIT
+	uint32_t max_phys = 256 << 20;
+#else
+	uint32_t max_phys = 0xffffffff;
+#endif
+	int retry_count = 0;
+	int len = 4096;
+
+	if (!fq->active)
+		return -1;
+
+	phys64 = virt_to_phys(buf);
+
+	if ((unsigned long long)phys64 & 0x7ULL) {
+		printk("Invalid inb buffer address - %#llx\n",
+		       (unsigned long long)phys64);
+		return -1;
+	}
+
+	if ((phys64 > max_phys) || ((phys64 + len) > max_phys)) {
+		printk("\nInvalid xmit buffer address\n");
+#ifdef CONFIG_32BIT
+		printk("\nBuffer address has to be below 256M\n");
+#else
+		printk("\nBuffer address has to be below 4G\n");
+#endif
+		return -1;
+	}
+
+	phys = (uint32_t) phys64;
+
+      retry:
+
+	rmi_local_config_read(rio_ctrl, 0, FREEL_QUEUE_TAIL(mbox), 4,
+			      &tail_value);
+	while ((tail_value & (1 << FQ_LOCK))) {
+		printk("\nTailQ - Locked- %#x\n", tail_value);
+		rmi_local_config_read(rio_ctrl, 0, FREEL_QUEUE_TAIL(mbox),
+				      4, &tail_value);
+	}
+
+	if (tail_value & (1 << FQ_FULL)) {
+		tail_value |= (1 << FQ_LOCK);
+		printk("\nTailQ -Full - %#x\n", tail_value);
+		rmi_local_config_write(rio_ctrl, 0,
+				       FREEL_QUEUE_TAIL(mbox), 4, tail_value);
+		if (retry_count++ < 20) {
+			goto retry;
+		} else {
+			printk("\nFQ is full!! can't enqueue message.\n");
+			return -1;
+		}
+	}
+
+	spin_lock_irqsave(&fq->lock, flags);
+
+	if (!fq->active) {
+		spin_unlock_irqrestore(&fq->lock, flags);
+		return -1;
+	}
+
+	tail_value = tail_value & 0xfffffff8;
+	tail_ptr = (uint32_t *) (unsigned long)CKSEG0ADDR(tail_value);
+
+	word[0] = __swab32(phys);
+	word[1] = 0x0;
+
+	tail_ptr[0] = word[0];
+	tail_ptr[1] = word[1];
+	mb();
+
+	/*Kick the transcation by incrementing tail ptr */
+	tail_value += SIZE_OF_FQ_ENTRY;
+	if (tail_value > fq->end) {
+		MYDBG("Wraparound of transaction Queue %d", mbox);
+		tail_value = fq->start;
+	}
+	tail_value = tail_value & ~0x7;
+	mb();
+	/* `sync` - make sure all data is written */
+	rmi_local_config_write(rio_ctrl, 0, FREEL_QUEUE_TAIL(mbox), 4,
+			       tail_value);
+	/*`sync` - make sure transaction is initiated */
+	mb();
+	spin_unlock_irqrestore(&fq->lock, flags);
+
+	return 0;
+}
+
+/**
+ * rio_open_inb_mbox - Initialize inbound mailbox
+ * @mport: Master port implementing the inbound message unit
+ * @dev_id: Device specific pointer to pass on event
+ * @mbox: Mailbox to open
+ * @entries: Number of entries in the inbound mailbox ring
+ *
+ * Initializes buffer ring, request the inbound message interrupt,
+ * and enables the inbound message unit. Returns %0 on success
+ * and %-EINVAL or %-ENOMEM on failure.
+ */
+int rio_open_inb_mbox(struct rio_mport *mport, void *dev_id, int mbox,
+		      int entries)
+{
+	struct rmi_rio_controller *rio_ctrl = to_rmi_rio_ctrl(mport);
+	struct mailbox_queue *mq = &rio_ctrl->mq[mbox];
+	struct freel_queue *fq = &rio_ctrl->fq[mbox];
+	int ret = 0;
+
+	MYDBG("Called");
+
+	if (entries < 4) {
+		printk("Minimum entries have to be 4\n");
+		return -1;
+	}
+
+	if (mbox < 0 || mbox > 3) {
+		printk("Invalid Resource for outb mbox - %d\n", mbox);
+		return -1;
+	}
+
+	ret = rmi_setup_mailbox_queue(rio_ctrl, mq, mbox, entries);
+	if (ret)
+		return -1;
+
+	ret = rmi_setup_freel_queue(rio_ctrl, fq, mbox, entries);
+	if (ret) {
+		rmi_clear_mailbox_queue(rio_ctrl, mq, mbox);
+		return -1;
+	}
+
+	/*Store max entries for this tq & sq */
+	rio_ctrl->mq[mbox].max_entries = entries;
+	rio_ctrl->fq[mbox].max_entries = entries;
+
+	/*Store dev_id to pass during callback */
+	rio_ctrl->mq[mbox].dev_id = dev_id;
+
+	return 0;
+}
+
+int rmi_clear_mailbox_queue(struct rmi_rio_controller *rio_ctrl,
+			    struct mailbox_queue *mq, int mq_index)
+{
+	uint32_t data;
+	unsigned long flags;
+
+	spin_lock_irqsave(&rio_ctrl->mailbox_lock, flags);
+
+	rmi_local_config_read(rio_ctrl, 0, MAILBOX_CONTROL_1, 4, &data);
+	data = data & ~(1 << CONFIGURE_MQUEUE(mq_index));
+	rmi_local_config_write(rio_ctrl, 0, MAILBOX_CONTROL_1, 4, data);
+
+	mq->active = 0;
+
+	/*Disable NNE interrupt */
+	rmi_local_config_read(rio_ctrl, 0, MAILBOX_INT_EN_3, 4, &data);
+	data = data & ~(1 << mq_index);
+	rmi_local_config_write(rio_ctrl, 0, MAILBOX_INT_EN_3, 4, data);
+
+	kfree(mq->orig);
+
+	spin_unlock_irqrestore(&rio_ctrl->mailbox_lock, flags);
+
+	return 0;
+}
+
+int rmi_clear_freel_queue(struct rmi_rio_controller *rio_ctrl,
+			  struct freel_queue *fq, int fq_index)
+{
+	uint32_t data;
+	unsigned long flags;
+	fq->active = 0;
+
+	spin_lock_irqsave(&rio_ctrl->freel_lock, flags);
+
+	rmi_local_config_read(rio_ctrl, 0, FREEL_CONTROL_REG, 4, &data);
+	data = data & ~(1 << CONFIGURE_FLQUEUE(fq_index));
+	rmi_local_config_write(rio_ctrl, 0, FREEL_CONTROL_REG, 4, data);
+
+	kfree(fq->orig);
+
+	spin_unlock_irqrestore(&rio_ctrl->freel_lock, flags);
+	return 0;
+}
+
+/**
+ * rio_close_inb_mbox - Shut down inbound mailbox
+ * @mport: Master port implementing the inbound message unit
+ * @mbox: Mailbox to close
+ *
+ * Disables the inbound message unit, free all buffers, and
+ * frees the inbound message interrupt.
+ */
+void rio_close_inb_mbox(struct rio_mport *mport, int mbox)
+{
+	struct rmi_rio_controller *rio_ctrl = to_rmi_rio_ctrl(mport);
+	struct mailbox_queue *mq = &rio_ctrl->mq[mbox];
+	struct freel_queue *fq = &rio_ctrl->fq[mbox];
+	unsigned long flags;
+
+	MYDBG("Called");
+
+	spin_lock_irqsave(&mq->lock, flags);	/*lock against xmit */
+	spin_lock(&fq->lock);	/*lock against rx */
+
+	rmi_clear_mailbox_queue(rio_ctrl, mq, mbox);
+	rmi_clear_freel_queue(rio_ctrl, fq, mbox);
+
+	spin_unlock(&fq->lock);	/*lock against rx */
+	spin_unlock_irqrestore(&mq->lock, flags);	/*lock against xmit */
+	return;
+}
+
+int rmi_setup_mailbox_queue(struct rmi_rio_controller *rio_ctrl,
+			    struct mailbox_queue *mq, int mq_index,
+			    int mq_entries)
+{
+	uint32_t phys = 0x0;
+	uint32_t size = SIZE_OF_MQ_ENTRY * mq_entries;
+	uint32_t data;
+	static int max_mailbox_number = 0;
+	unsigned long flags;
+
+	mq->orig = kmalloc(size + SMP_CACHE_BYTES, GFP_KERNEL | GFP_DMA);
+
+	if (!mq->orig)
+		return -ENOMEM;
+
+	memset(mq->orig, 0xff, size + SMP_CACHE_BYTES);
+
+	phys = virt_to_phys(mq->orig);
+
+	if (phys & (SMP_CACHE_BYTES - 1))
+		phys = (phys + SMP_CACHE_BYTES) & ~0x1f;
+
+	/*Glue logic needs address to be right shifted by 1 */
+	mq->start = phys >> 1;
+	mq->end = (phys + size - SIZE_OF_SQ_ENTRY) >> 1;
+
+	/*Configure MQ Start and End pointers */
+	rmi_local_config_write(rio_ctrl, 0, MAILBOX_QUEUE_START(mq_index), 4,
+			       mq->start);
+	rmi_local_config_write(rio_ctrl, 0, MAILBOX_QUEUE_END(mq_index), 4,
+			       mq->end);
+
+	/*Set MQ Upper pointer to 0 */
+	rmi_local_config_write(rio_ctrl, 0, MAILBOX_QUEUE_UPTR(mq_index), 4, 0);
+
+	if (max_mailbox_number == 0) {
+		/*Configure MAX Mailbox number */
+		max_mailbox_number = MAX_MAILBOX_Q - 1;
+		rmi_local_config_write(rio_ctrl, 0, MAILBOX_CONTROL_3, 4,
+				       max_mailbox_number << HIGH_MAILB_NO);
+	}
+
+	spin_lock_irqsave(&rio_ctrl->mailbox_lock, flags);
+
+	rmi_local_config_read(rio_ctrl, 0, MAILBOX_CONTROL_1, 4, &data);
+	data = data | (1 << CONFIGURE_MQUEUE(mq_index));
+	rmi_local_config_write(rio_ctrl, 0, MAILBOX_CONTROL_1, 4, data);
+
+	mq->active = 1;
+
+	/*Enable NNE interrupt */
+	rmi_local_config_read(rio_ctrl, 0, MAILBOX_INT_EN_3, 4, &data);
+	data = data | (1 << mq_index);
+	rmi_local_config_write(rio_ctrl, 0, MAILBOX_INT_EN_3, 4, data);
+
+#ifdef RMI_SRIO_DEBUG
+	dump_mq_regs(rio_ctrl, mq, mq_index);
+#endif
+	spin_unlock_irqrestore(&rio_ctrl->mailbox_lock, flags);
+
+	spin_lock_init(&mq->lock);
+	return 0;
+}
+
+int rmi_setup_freel_queue(struct rmi_rio_controller *rio_ctrl,
+			  struct freel_queue *fq, int fq_index, int fq_entries)
+{
+	uint32_t phys = 0x0;
+	uint32_t size = SIZE_OF_FQ_ENTRY * fq_entries;
+	uint32_t data;
+	unsigned long flags;
+
+	fq->orig = kmalloc(size + SMP_CACHE_BYTES, GFP_KERNEL | GFP_DMA);
+
+	if (!fq->orig)
+		return -ENOMEM;
+
+	phys = virt_to_phys(fq->orig);
+
+	if (phys & (SMP_CACHE_BYTES - 1))
+		phys = (phys + SMP_CACHE_BYTES) & ~0x1f;
+
+	fq->start = phys;
+	fq->end = phys + size - SIZE_OF_FQ_ENTRY;
+
+	phys = (uint32_t) virt_to_phys((void *)(unsigned long)fq->start);
+
+	/*Configure FQ Start and End pointers */
+	rmi_local_config_write(rio_ctrl, 0, FREEL_QUEUE_START(fq_index), 4,
+			       fq->start);
+	rmi_local_config_write(rio_ctrl, 0, FREEL_QUEUE_END(fq_index), 4,
+			       fq->end);
+
+	/*Set FQ Upper pointer to 0 */
+	rmi_local_config_write(rio_ctrl, 0, FREEL_QUEUE_UPTR(fq_index), 4, 0);
+
+	/*Freelist buff size */
+	rmi_local_config_write(rio_ctrl, 0, FREEL_BUF_SIZE(fq_index), 4,
+			       511 << FL_BUF_SIZE);
+
+	fq->active = 1;
+	/*Configure freelist q */
+
+	spin_lock_irqsave(&rio_ctrl->freel_lock, flags);
+
+	rmi_local_config_read(rio_ctrl, 0, FREEL_CONTROL_REG, 4, &data);
+	data = data | (1 << CONFIGURE_FLQUEUE(fq_index));
+	rmi_local_config_write(rio_ctrl, 0, FREEL_CONTROL_REG, 4, data);
+
+#ifdef RMI_SRIO_DEBUG
+	dump_fq_regs(rio_ctrl, fq, fq_index);
+#endif
+	spin_unlock_irqrestore(&rio_ctrl->freel_lock, flags);
+
+	spin_lock_init(&fq->lock);
+
+	return 0;
+}
+
+int rmi_clear_transaction_queue(struct rmi_rio_controller *rio_ctrl,
+				struct transaction_queue *tq, int tq_index)
+{
+	uint32_t data;
+	tq->active = 0;
+
+	/*disable transaction queue */
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_CTRL_1, 4, &data);
+	data = data & ~(1 << CONFIGURE_TQUEUE(tq_index));
+	rmi_local_config_write(rio_ctrl, 0, TRANSACTION_QUEUE_CTRL_1, 4, data);
+
+#ifdef RMI_SRIO_DEBUG
+	dump_tq_regs(rio_ctrl, tq, tq_index);
+#endif
+
+	kfree(tq->orig);
+	return 0;
+}
+
+int rmi_clear_status_queue(struct rmi_rio_controller *rio_ctrl,
+			   struct status_queue *sq, int sq_index)
+{
+	uint32_t data;
+	sq->active = 0;
+
+	/* Disable status q interrupt */
+	rmi_local_config_read(rio_ctrl, 0, STATUS_QUEUE_IER, 4, &data);
+	data = data & ~(1 << NNE_INTR(sq_index));
+	rmi_local_config_write(rio_ctrl, 0, STATUS_QUEUE_IER, 4, data);
+
+#ifdef RMI_SRIO_DEBUG
+	dump_sq_regs(rio_ctrl, sq, sq_index);
+#endif
+
+	/*disable status queue */
+	rmi_local_config_read(rio_ctrl, 0, STATUS_QUEUE_CTRL, 4, &data);
+	data = data & ~(1 << CONFIGURE_SQUEUE(sq_index));
+	rmi_local_config_write(rio_ctrl, 0, STATUS_QUEUE_CTRL, 4, data);
+	kfree(sq->orig);
+
+	return 0;
+}
+
+int rmi_setup_transaction_queue(struct rmi_rio_controller *rio_ctrl,
+				struct transaction_queue *tq, int tq_index,
+				int tq_entries)
+{
+	uint32_t phys = 0x0;
+	uint32_t size = SIZE_OF_TQ_ENTRY * tq_entries;
+	uint32_t data;
+
+	tq->orig = kmalloc(size + SMP_CACHE_BYTES, GFP_KERNEL | GFP_DMA);
+
+	if (!tq->orig)
+		return -ENOMEM;
+
+	phys = virt_to_phys(tq->orig);
+
+	if (phys & (SMP_CACHE_BYTES - 1))
+		phys = (phys + SMP_CACHE_BYTES) & ~0x1f;
+
+	tq->start = phys;
+	tq->end = phys + size - SIZE_OF_TQ_ENTRY;
+
+#if 0
+	/*Below are internal pointers. */
+	tq->head = phys;
+	tq->tail = phys + size - SIZE_OF_TQ_ENTRY;
+#endif
+
+	phys = (uint32_t) virt_to_phys((void *)(unsigned long)tq->start);
+
+	/*Configure TQ Start and End pointers */
+	rmi_local_config_write(rio_ctrl, 0, TRANSACTION_QUEUE_START(tq_index),
+			       4, tq->start);
+	rmi_local_config_write(rio_ctrl, 0, TRANSACTION_QUEUE_END(tq_index), 4,
+			       tq->end);
+
+	/*Set TQ Upper pointer to 0 */
+	rmi_local_config_write(rio_ctrl, 0, TRANSACTION_QUEUE_UPTR(tq_index), 4,
+			       0);
+	/*Configure and Enable TQ */
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_CTRL_1, 4, &data);
+	data = data | (1 << CONFIGURE_TQUEUE(tq_index)) | (1 << ENABLE_QUEUE);
+	rmi_local_config_write(rio_ctrl, 0, TRANSACTION_QUEUE_CTRL_1, 4, data);
+
+	tq->active = 1;
+
+#ifdef RMI_SRIO_DEBUG
+	dump_tq_regs(rio_ctrl, tq, tq_index);
+#endif
+
+	spin_lock_init(&tq->lock);
+
+	return 0;
+}
+
+int rmi_setup_status_queue(struct rmi_rio_controller *rio_ctrl,
+			   struct status_queue *sq, int sq_index,
+			   int sq_entries)
+{
+	uint32_t phys = 0x0;
+	uint32_t size = SIZE_OF_SQ_ENTRY * sq_entries;
+	uint32_t data;
+
+	sq->orig = kmalloc(size + SMP_CACHE_BYTES, GFP_KERNEL | GFP_DMA);
+
+	if (!sq->orig)
+		return -ENOMEM;
+
+	memset(sq->orig, 0xff, size + SMP_CACHE_BYTES);
+
+	phys = virt_to_phys(sq->orig);
+
+	if (phys & (SMP_CACHE_BYTES - 1))
+		phys = (phys + SMP_CACHE_BYTES) & ~0x1f;
+
+	/*Glue logic needs address to be right shifted by 1 */
+	sq->start = phys >> 1;
+	sq->end = (phys + size - SIZE_OF_SQ_ENTRY) >> 1;
+
+	/*Configure SQ Start and End pointers */
+	rmi_local_config_write(rio_ctrl, 0, STATUS_QUEUE_START(sq_index), 4,
+			       sq->start);
+	rmi_local_config_write(rio_ctrl, 0, STATUS_QUEUE_END(sq_index), 4,
+			       sq->end);
+
+	/*Set SQ Upper pointer to 0 */
+	rmi_local_config_write(rio_ctrl, 0, STATUS_QUEUE_UPTR(sq_index), 4, 0);
+
+	/*Configure and Enable SQ */
+	rmi_local_config_read(rio_ctrl, 0, STATUS_QUEUE_CTRL, 4, &data);
+	data = data | (1 << CONFIGURE_SQUEUE(sq_index));
+	rmi_local_config_write(rio_ctrl, 0, STATUS_QUEUE_CTRL, 4, data);
+
+	sq->active = 1;
+
+#ifdef RMI_SRIO_DEBUG
+	dump_sq_regs(rio_ctrl, sq, sq_index);
+#endif
+
+	spin_lock_init(&sq->lock);
+
+	return 0;
+}
+
+#if 0
+int rmi_setup_maint_trans_rsrc_test(struct rmi_rio_controller *rio_ctrl)
+{
+	int ret = 0;
+	uint32_t data;
+
+	/*Init maintainence transaction lock. */
+	spin_lock_init(&rio_ctrl->maintenance_lock);
+
+	ret = rmi_setup_transaction_queue(rio_ctrl, &rio_ctrl->tq[1], 1, 16);
+	if (ret)
+		return ret;
+
+	printk("\nAllocated buffer for tq = %#x\n", rio_ctrl->tq[1].start);
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_HEAD(1), 4, &data);
+	printk("\nTRANSACTION QUEUE HEAD = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_TAIL(1), 4, &data);
+	rmi_local_config_write(rio_ctrl, 0, TRANSACTION_QUEUE_TAIL(1), 4,
+			       data | 0x1);
+	printk("\nTRANSACTION QUEUE TAIL = %#x\n", data);
+
+	printk("\nDisableing Transaction Q Config bit for testing...\n");
+
+	/*Disable config bit */
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_CTRL_1, 4, &data);
+	data = data & ~(1 << CONFIGURE_TQUEUE(1));
+	rmi_local_config_write(rio_ctrl, 0, TRANSACTION_QUEUE_CTRL_1, 4, data);
+
+	printk("\nReconfiguring Transaction Queue for testing...\n");
+	ret = rmi_setup_transaction_queue(rio_ctrl, &rio_ctrl->tq[1], 1, 16);
+	if (ret)
+		return ret;
+
+	printk("\nNew Allocated buffer for tq = %#x\n", rio_ctrl->tq[1].start);
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_HEAD(1), 4, &data);
+	printk("\nNew TRANSACTION QUEUE HEAD = %#x\n", data);
+	rmi_local_config_read(rio_ctrl, 0, TRANSACTION_QUEUE_TAIL(1), 4, &data);
+	printk("\nNew TRANSACTION QUEUE TAIL = %#x\n", data);
+//    ret = rmi_setup_status_queue(rio_ctrl,&rio_ctrl->sq[1], 1, 16);
+//    if(ret)
+//        return ret;
+
+	return ret;
+}
+#endif
+
+int rmi_setup_maint_trans_rsrc(struct rmi_rio_controller *rio_ctrl)
+{
+	int ret = 0;
+
+	/*Init maintainence transaction lock. */
+	spin_lock_init(&rio_ctrl->maintenance_lock);
+
+	ret = rmi_setup_transaction_queue(rio_ctrl, &rio_ctrl->tq[1], 1, 16);
+	if (ret)
+		return ret;
+
+	ret = rmi_setup_status_queue(rio_ctrl, &rio_ctrl->sq[1], 1, 16);
+	if (ret) {
+		rmi_clear_transaction_queue(rio_ctrl, &rio_ctrl->tq[1], 1);
+		return ret;
+	}
+
+	return ret;
+}
+
+/**
+ * rmi_local_rio_config_read - Generate a XLS local config space read
+ * @pindex: ID of RapdiIO interface
+ * @offset: Offset into configuration space
+ * @len: Length (in bytes) of the maintenance transaction
+ * @data: Value to be read into
+ *
+ * Generates a XLS local configuration space read. Returns %0 on
+ * success or %-EINVAL on failure.
+ */
+int rmi_local_config_read(struct rmi_rio_controller *rio_ctrl,
+			  int pindex, u32 offset, int len, u32 * data)
+{
+    unsigned long virt = rio_ctrl->regs_virt_start;
+	MYDBG("rmi_local_config_read: index %d offset %8.8x\n", pindex,
+		 offset);
+#ifdef CONFIG_64BIT
+	*data = *(u32 *)(unsigned long)(virt + offset);
+#else
+	*data = *(u32 *)(u32)(virt + offset);
+#endif
+	return 0;
+}
+
+/**
+ * rmi_local_rio_config_write - Generate a XLS local config space write
+ * @index: ID of RapdiIO interface
+ * @offset: Offset into configuration space
+ * @len: Length (in bytes) of the maintenance transaction
+ * @data: Value to be written
+ *
+ * Generates a XLS local configuration space write. Returns %0 on
+ * success or %-EINVAL on failure.
+ */
+int rmi_local_config_write(struct rmi_rio_controller *rio_ctrl,
+			   int pindex, u32 offset, int len, u32 data)
+{
+	unsigned long virt = rio_ctrl->regs_virt_start;
+	MYDBG("rmi_local_config_write: index %d offset %8.8x\n", pindex,
+		 offset);
+#ifdef CONFIG_64BIT
+    *(u32 *)(unsigned long)(virt + offset) = data;
+#else
+    *(u32 *)(u32)(virt + offset) = data;
+#endif
+    return 0;
+}
+
+int setup_maint_tq_entry(struct rmi_rio_controller *rio_ctrl,
+			 int pindex, int tq_index, int type, u16 destid,
+			 u8 hopcount, u32 offset, int len, u32 phys)
+{
+	int words = 0;
+	uint32_t tail_value = 0;
+	uint32_t *tail_ptr = NULL;
+	struct transaction_queue *tq = &rio_ctrl->tq[tq_index];
+	uint32_t word[6];
+
+      retry:
+	rmi_local_config_read(rio_ctrl, pindex,
+			      TRANSACTION_QUEUE_TAIL(tq_index), 4, &tail_value);
+	while ((tail_value & (1 << TQ_LOCK))) {
+		printk("\nTailQ - Locked- %#x\n", tail_value);
+		rmi_local_config_read(rio_ctrl, pindex,
+				      TRANSACTION_QUEUE_TAIL(tq_index), 4,
+				      &tail_value);
+	}
+
+	if (tail_value & (1 << TQ_FULL)) {
+		tail_value |= (1 << TQ_LOCK);
+		printk("\nTailQ -Full - %#x\n", tail_value);
+		rmi_local_config_write(rio_ctrl, pindex,
+				       TRANSACTION_QUEUE_TAIL(tq_index), 4,
+				       tail_value);
+		goto retry;
+	}
+
+	tail_value = tail_value & 0xfffffff8;
+	tail_ptr = (uint32_t *) (unsigned long)CKSEG0ADDR(tail_value);
+
+#ifdef CONFIG_RAPIDIO_8_BIT_TRANSPORT
+	destid = destid & 0xff;
+	word[0] = __swab32((destid << MAINT_DEST_ID) |
+			   (0 << MAINT_DID_SIZE) | type);
+#else
+	destid = destid & 0xffff;
+	word[0] = __swab32((destid << MAINT_DEST_ID) |
+			   (1 << MAINT_DID_SIZE) | type);
+#endif
+	word[1] = __swab32((words << MAINT_TRANS_SIZE) |
+			   (0x3 << MAINT_TRANS_DEFAULT_BITS));
+	word[2] = __swab32((uint32_t) (phys));
+	word[3] = __swab32((hopcount << MAINT_HOP_COUNT) | (offset >> 2));
+	word[4] = word[5] = 0x0;
+
+	tail_ptr[0] = word[0];
+	tail_ptr[1] = word[1];
+	tail_ptr[2] = word[2];
+	tail_ptr[3] = word[3];
+	tail_ptr[4] = word[4];
+	tail_ptr[5] = word[5];
+	mb();
+	/*Kick the transcation by incrementing tail ptr */
+	tail_value += SIZE_OF_TQ_ENTRY;
+	if (tail_value > tq->end) {
+		MYDBG("Wraparound of transaction Queue %d", tq_index);
+		tail_value = tq->start;
+	}
+	tail_value = tail_value & ~0x7;
+	mb();
+	/*`sync` - make sure all data is written */
+	rmi_local_config_write(rio_ctrl, pindex,
+			       TRANSACTION_QUEUE_TAIL(tq_index), 4, tail_value);
+	/*`sync` - make sure transaction is initiated */
+	mb();
+	return 0;
+}
+
+int check_maint_sq_entry(struct rmi_rio_controller *rio_ctrl,
+			 int pindex, int sq_index, int type,
+			 u16 destid, u32 phys)
+{
+	uint32_t head_value = 0;
+	uint32_t *head_ptr = NULL;
+	struct status_queue *sq = &rio_ctrl->sq[sq_index];
+	uint32_t word[4];
+	uint32_t orig_head_value;
+
+	rmi_local_config_read(rio_ctrl, pindex, STATUS_QUEUE_HEAD(sq_index), 4,
+			      &head_value);
+	while (head_value & (1 << SQ_EMPTY)) {
+		mdelay(5);
+//      printk("\nStatusQ Is empty yet.. %#x\n",head_value);
+		rmi_local_config_read(rio_ctrl, pindex,
+				      STATUS_QUEUE_HEAD(sq_index), 4,
+				      &head_value);
+	}
+	orig_head_value = head_value;
+	head_value = head_value & 0xfffffff8;
+	/*Left shift by 1 to get the actual physical address. */
+	head_value = head_value << 1;
+
+	/*Give sufficient delay so that glue logic copies data */
+	udelay(1);
+
+	head_ptr = (uint32_t *) (unsigned long)CKSEG0ADDR(head_value);
+	word[0] = __swab32(head_ptr[0]);
+	word[1] = __swab32(head_ptr[1]);
+	word[2] = __swab32(head_ptr[2]);
+	word[3] = __swab32(head_ptr[3]);
+	mb();
+
+#ifdef RMI_SRIO_DEBUG
+	/*Check the transaction type is expected or not. */
+	if ((word[0] & 0x1f) != type) {
+		printk("\nhead_value = %#x\n", orig_head_value);
+		printk("word0=%#x, word1=%#x, word2=%#x, word3=%#x\n",
+		       word[0], word[1], word[2], word[3]);
+		printk("\nUnexpected Transaction %#x instead of %#x \n",
+		       word[0] & 0x1f, type);
+		panic("\npanic!!");
+	}
+
+	if (((word[0] >> 12) & 0xf) != 0) {
+		printk("\nTransaction turned in to an error !! Error %#x",
+		       word[0] >> 12 & 0xf);
+		panic("\npanic!!");
+	}
+	/*Check the phy address in response */
+	if (word[2] != phys) {
+		printk
+		    ("\n!!!Got the result for phys address %#x instead of %#x\n",
+		     word[2], phys);
+		panic("\npanic!!");
+	}
+#endif
+
+	/*Move head pointer ahead */
+	head_value += SIZE_OF_SQ_ENTRY;
+
+	/*Glue logic needs address to be right shifted by 1 */
+	head_value = head_value >> 1;
+
+	if (head_value > sq->end) {
+		head_value = sq->start;
+		MYDBG("Wraparound of Status Queue %d", sq_index);
+	}
+	rmi_local_config_write(rio_ctrl, pindex, STATUS_QUEUE_HEAD(sq_index), 4,
+			       head_value);
+	return 0;
+}
+
+/**
+ * rmi_rio_config_read - Generate a XLS read maintenance transaction
+ * @index: ID of RapdiIO interface
+ * @destid: Destination ID of transaction
+ * @hopcount: Number of hops to target device
+ * @offset: Offset into configuration space
+ * @len: Length (in bytes) of the maintenance transaction
+ * @val: Location to be read into
+ *
+ * Generates a XLS read maintenance transaction. Returns %0 on
+ * success or %-EINVAL on failure.
+ */
+int
+rmi_rio_config_read(struct rmi_rio_controller *rio_ctrl,
+		    int pindex, u16 destid, u8 hopcount, u32 offset, int len,
+		    u32 * val)
+{
+	u8 *data;
+	int tq_index = 1;	/*Use TQ-1 for all maint transactions. */
+	uint32_t result = 0x0;
+	uint32_t result_phys = 0x0;
+	int sq_index = 1;
+	unsigned long flags;
+	MYDBG
+	    ("index %d destid %d hopcount %d offset %8.8x len %d\n",
+	     pindex, destid, hopcount, offset, len);
+	result_phys = virt_to_phys(&result);
+
+	spin_lock_irqsave(&rio_ctrl->maintenance_lock, flags);
+
+	setup_maint_tq_entry(rio_ctrl, pindex, tq_index, TYPE_MAINTAIN_READ,
+			     destid, hopcount, offset, len, result_phys);
+
+	/*Check on the status Q for transaction completion. */
+	check_maint_sq_entry(rio_ctrl, pindex, sq_index, TYPE_MAINTAIN_READ,
+			     destid, result_phys);
+
+	spin_unlock_irqrestore(&rio_ctrl->maintenance_lock, flags);
+
+	/*Store the result back.. */
+	data = (u8 *) (unsigned long)((unsigned long)&result + (offset & 0x3));
+
+	switch (len) {
+	case 1:
+		*val = (u32) * (u8 *) data;
+		break;
+	case 2:
+		*val = (u32) * (u16 *) data;
+		break;
+	default:
+		*val = (u32) * (u32 *) data;
+		break;
+	}
+	return 0;
+}
+
+/**
+ * rmi_rio_config_write - Generate a XLS write maintenance transaction
+ * @index: ID of RapdiIO interface
+ * @destid: Destination ID of transaction
+ * @hopcount: Number of hops to target device
+ * @offset: Offset into configuration space
+ * @len: Length (in bytes) of the maintenance transaction
+ * @val: Value to be written
+ *
+ * Generates an XLS write maintenance transaction. Returns %0 on
+ * success or %-EINVAL on failure.
+ */
+int
+rmi_rio_config_write(struct rmi_rio_controller *rio_ctrl, int pindex,
+		     u16 destid, u8 hopcount, u32 offset, int len, u32 val)
+{
+	u8 *data;
+	int tq_index = 1;	/*Use TQ-1 for all maint transactions. */
+	uint32_t r_data = 0x0;
+	uint32_t r_data_phys = 0x0;
+	int sq_index = 1;
+	unsigned long flags;
+	uint32_t w_data = 0;
+	uint32_t w_data_phys = 0;
+
+	MYDBG
+	    ("index %d destid %d hopcount %d offset %8.8x len %d\n",
+	     pindex, destid, hopcount, offset, len);
+	w_data_phys = virt_to_phys(&w_data);
+
+	/*Check if we have to do read modify write */
+	if (len == 4) {
+		w_data = val;
+		goto skip;
+	}
+
+	/*Do Read Modify Write */
+
+	printk("\nWriting unaligned data\n");
+
+	r_data_phys = virt_to_phys(&r_data);
+
+	rmi_rio_config_read(rio_ctrl, pindex, destid, hopcount, offset & ~(0x3),
+			    4, &r_data);
+
+	data = (u8 *) (unsigned long)((unsigned long)&r_data + (offset & 0x3));
+
+	switch (len) {
+	case 1:
+		*data = (u8) val;
+		w_data = r_data;
+		break;
+	case 2:
+		*(u16 *) data = (u16) val;
+		w_data = r_data;
+		break;
+	default:
+		break;
+	}
+
+      skip:
+	spin_lock_irqsave(&rio_ctrl->maintenance_lock, flags);
+
+	setup_maint_tq_entry(rio_ctrl, pindex, tq_index, TYPE_MAINTAIN_WRITE,
+			     destid, hopcount, offset, len, w_data_phys);
+
+	/*Check on the status Q for transaction completion. */
+	check_maint_sq_entry(rio_ctrl, pindex, sq_index, TYPE_MAINTAIN_WRITE,
+			     destid, w_data_phys);
+
+	spin_unlock_irqrestore(&rio_ctrl->maintenance_lock, flags);
+
+	return 0;
+}
+
+int setup_doorbell_tq_entry(struct rmi_rio_controller *rio_ctrl,
+			    int pindex, int tq_index, u16 destid, u16 data)
+{
+	uint32_t tail_value = 0;
+	uint32_t *tail_ptr = NULL;
+	struct transaction_queue *tq = &rio_ctrl->tq[tq_index];
+	uint32_t word[6];
+	int type = TYPE_DOORBELL;
+
+      retry:
+
+	rmi_local_config_read(rio_ctrl, pindex,
+			      TRANSACTION_QUEUE_TAIL(tq_index), 4, &tail_value);
+
+	while ((tail_value & (1 << TQ_LOCK))) {
+		printk("\nTailQ - Locked- %#x\n", tail_value);
+		rmi_local_config_read(rio_ctrl, pindex,
+				      TRANSACTION_QUEUE_TAIL(tq_index), 4,
+				      &tail_value);
+	}
+
+	if (tail_value & (1 << TQ_FULL)) {
+		tail_value |= (1 << TQ_LOCK);
+		printk("\nTailQ -Full - %#x\n", tail_value);
+		rmi_local_config_write(rio_ctrl, pindex,
+				       TRANSACTION_QUEUE_TAIL(tq_index), 4,
+				       tail_value);
+		goto retry;
+	}
+
+	tail_value = tail_value & 0xfffffff8;
+	tail_ptr = (uint32_t *) (unsigned long)CKSEG0ADDR(tail_value);
+
+#ifdef CONFIG_RAPIDIO_8_BIT_TRANSPORT
+	destid = destid & 0xff;
+	word[0] = __swab32((destid << MAINT_DEST_ID) |
+			   (0 << MAINT_DID_SIZE) | type);
+#else
+	destid = destid & 0xffff;
+	word[0] = __swab32((destid << MAINT_DEST_ID) |
+			   (1 << MAINT_DID_SIZE) | type);
+#endif
+	word[1] = __swab32(data << DBELL_INFO);
+	word[2] = word[3] = word[4] = word[5] = 0x0;
+
+	tail_ptr[0] = word[0];
+	tail_ptr[1] = word[1];
+	tail_ptr[2] = word[2];
+	tail_ptr[3] = word[3];
+	tail_ptr[4] = word[4];
+	tail_ptr[5] = word[5];
+	mb();
+	/*Kick the transcation by incrementing tail ptr */
+	tail_value += SIZE_OF_TQ_ENTRY;
+	if (tail_value > tq->end) {
+		MYDBG("Wraparound of transaction Queue %d", tq_index);
+		tail_value = tq->start;
+	}
+	tail_value = tail_value & ~0x7;
+	mb();
+	/*`sync` - make sure all data is written */
+	rmi_local_config_write(rio_ctrl, pindex,
+			       TRANSACTION_QUEUE_TAIL(tq_index), 4, tail_value);
+	/*`sync` - make sure transaction is initiated */
+	mb();
+
+	return 0;
+}
+
+int check_doorbell_sq_entry(struct rmi_rio_controller *rio_ctrl,
+			    int pindex, int sq_index, u16 destid)
+{
+	uint32_t head_value = 0;
+	uint32_t *head_ptr = NULL;
+	struct status_queue *sq = &rio_ctrl->sq[sq_index];
+	uint32_t word[4];
+	uint32_t orig_head_value;
+
+#ifdef RMI_SRIO_DEBUG
+	int type = TYPE_DOORBELL;
+#endif
+
+	rmi_local_config_read(rio_ctrl, pindex, STATUS_QUEUE_HEAD(sq_index), 4,
+			      &head_value);
+	while (head_value & (1 << SQ_EMPTY)) {
+		mdelay(5);
+//      printk("\nStatusQ Is empty yet.. %#x\n",head_value);
+		rmi_local_config_read(rio_ctrl, pindex,
+				      STATUS_QUEUE_HEAD(sq_index), 4,
+				      &head_value);
+	}
+	orig_head_value = head_value;
+	head_value = head_value & 0xfffffff8;
+	/*Left shift by 1 to get the actual physical address. */
+	head_value = head_value << 1;
+
+	/*Give sufficient delay so that glue logic copies data */
+	udelay(1);
+
+	head_ptr = (uint32_t *) (unsigned long)CKSEG0ADDR(head_value);
+	word[0] = __swab32(head_ptr[0]);
+	word[1] = __swab32(head_ptr[1]);
+	word[2] = __swab32(head_ptr[2]);
+	word[3] = __swab32(head_ptr[3]);
+	mb();
+#ifdef RMI_SRIO_DEBUG
+	/*Check the transaction type is expected or not. */
+	if ((word[0] & 0x1f) != type) {
+		printk("\nhead_value = %#x\n", orig_head_value);
+		printk("word0=%#x, word1=%#x, word2=%#x, word3=%#x\n",
+		       word[0], word[1], word[2], word[3]);
+		printk("\nUnexpected Transaction %#x instead of %#x \n",
+		       word[0] & 0x1f, type);
+		panic("\npanic!!");
+	}
+
+	if (((word[0] >> 12) & 0xf) != 0) {
+		printk("\nTransaction turned in to an error !! Error %#x",
+		       word[0] >> 12 & 0xf);
+//      panic("\npanic!!");
+	}
+#endif
+
+	/*Move head pointer ahead */
+	head_value += SIZE_OF_SQ_ENTRY;
+
+	/*Glue logic needs address to be right shifted by 1 */
+	head_value = head_value >> 1;
+
+	if (head_value > sq->end) {
+		head_value = sq->start;
+		MYDBG("Wraparound of Status Queue %d", sq_index);
+	}
+	rmi_local_config_write(rio_ctrl, pindex, STATUS_QUEUE_HEAD(sq_index), 4,
+			       head_value);
+	return 0;
+}
+
+/**
+ * rmi_rio_doorbell_send - Send a XLS doorbell message
+ * @index: ID of RapidIO interface
+ * @destid: Destination ID of target device
+ * @data: 16-bit info field of RapidIO doorbell message
+ *
+ * Sends a XLS doorbell message. Returns %0 on success or
+ * %-EINVAL on failure.
+ */
+int rmi_rio_doorbell_send(struct rmi_rio_controller *rio_ctrl,
+			  int pindex, u16 destid, u16 data)
+{
+	int tq_index = 1;
+	int sq_index = 1;
+	unsigned long flags;
+
+	MYDBG("index %d destid %4.4x data %4.4x\n", pindex, destid, data);
+
+	spin_lock_irqsave(&rio_ctrl->maintenance_lock, flags);
+
+	MYDBG("");
+	setup_doorbell_tq_entry(rio_ctrl, pindex, tq_index, destid, data);
+	/*Check on the status Q for transaction completion. */
+	MYDBG("");
+	check_doorbell_sq_entry(rio_ctrl, pindex, sq_index, destid);
+	MYDBG("");
+	spin_unlock_irqrestore(&rio_ctrl->maintenance_lock, flags);
+
+	return 0;
+}
+
+void doorbell_intr(struct rmi_rio_controller *rio_ctrl, struct rio_mport *port)
+{
+	uint32_t no_of_msgs = 0;
+	uint32_t data;
+	struct rio_dbell *dbell;
+	u16 info, src;
+	int found = 0;
+
+	rmi_local_config_read(rio_ctrl, 0, DOORBELL_INFO, 4, &data);
+	no_of_msgs = (data >> DFIFO_NUM) & 0xf;
+	while (no_of_msgs) {
+		rmi_local_config_read(rio_ctrl, 0, DOORBELL_READ, 4, &data);
+
+		info = data & 0xffff;
+
+#ifdef CONFIG_RAPIDIO_8_BIT_TRANSPORT
+		src = (data >> DB_SRCID) & 0xff;
+#else
+		src = (data >> DB_SRCID) & 0xffff;
+#endif
+		list_for_each_entry(dbell, &port->dbells, node) {
+			if ((dbell->res->start <= info) &&
+			    (dbell->res->end >= info)) {
+				found = 1;
+				break;
+			}
+		}
+		if (found) {
+			dbell->dinb(port, dbell->dev_id, src, -1, info);
+		} else {
+			printk("RIO: spurious doorbell, sid %2.2x info %4.4x\n",
+			       src, info);
+		}
+		no_of_msgs--;
+	}
+	return;
+}
+
+void mailbox_intr(struct rmi_rio_controller *rio_ctrl, struct rio_mport *port)
+{
+	struct mailbox_queue *mq;
+	uint32_t status;
+	int i = 0;
+
+	rmi_local_config_read(rio_ctrl, 0, MAILBOX_STATUS_3, 4, &status);
+
+	for (i = 0; i < MAX_MAILBOX_Q; i++) {
+		if (!(status & (1 << i)))
+			continue;
+		mq = &rio_ctrl->mq[i];
+
+		spin_lock(&mq->lock);
+		if (!mq->active) {
+			spin_unlock(&mq->lock);
+			continue;
+		}
+		if (port->inb_msg[i].mcback)
+			port->inb_msg[i].mcback(port, mq->dev_id, -1, -1);
+		else
+			printk("No call back for this message !! Screwed ??\n");
+		spin_unlock(&mq->lock);
+	}
+	return;
+}
+
+void statusq_intr(struct rmi_rio_controller *rio_ctrl, struct rio_mport *port)
+{
+	int sq_index = 0;
+	struct status_queue *sq = &rio_ctrl->sq[sq_index];
+	uint32_t head_value = 0;
+	uint32_t orig_head_value = 0;
+	volatile uint32_t *head_ptr = NULL;
+	volatile uint32_t word[4];
+#ifdef RMI_SRIO_DEBUG
+	uint32_t ttype;
+#endif
+
+	MYDBG("Got status q intr");
+	/*Hold a lock, so that close does not free resources */
+	spin_lock(&sq->lock);
+
+	if (!sq->active) {
+		spin_unlock(&sq->lock);
+		return;
+	}
+
+	rmi_local_config_read(rio_ctrl, 0, STATUS_QUEUE_HEAD(sq_index), 4,
+			      &head_value);
+
+	while (!(head_value & (1 << SQ_EMPTY))) {
+
+		orig_head_value = head_value;
+		head_value = head_value & 0xfffffff8;
+		/*Left shift by 1 to get the actual physical address. */
+		head_value = head_value << 1;
+
+		/*Give sufficient delay so that glue logic copies data */
+//      udelay(1);
+
+		head_ptr =
+		    (volatile uint32_t *)(unsigned long)CKSEG0ADDR(head_value);
+	      retry:
+		word[0] = __swab32(head_ptr[0]);
+		if (((word[0] >> 12) & 0xf) == 0xf) {
+			goto retry;
+		}
+
+		word[1] = __swab32(head_ptr[1]);
+		word[2] = __swab32(head_ptr[2]);
+		word[3] = __swab32(head_ptr[3]);
+		mb();
+#ifdef RMI_SRIO_DEBUG
+		ttype = word[0] & 0x1f;
+		/*Check the transaction type is expected or not. */
+		if (ttype != TYPE_MESSAGE) {
+			printk("\nhead_value = %#x\n", orig_head_value);
+			printk("word0=%#x, word1=%#x, word2=%#x, word3=%#x\n",
+			       word[0], word[1], word[2], word[3]);
+			printk("\nUnexpected Transaction %#x \n",
+			       word[0] & 0x1f);
+			panic("\npanic!!");
+		}
+
+		if (((word[0] >> 12) & 0xf) != 0) {
+			printk
+			    ("\nTransaction turned in to an error !! Error %#x",
+			     word[0] >> 12 & 0xf);
+			panic("\npanic!!");
+		}
+#endif
+		head_ptr[0] = 0xffffffff;
+		mb();
+
+		/*Move head pointer ahead */
+		head_value += SIZE_OF_SQ_ENTRY;
+
+		/*Glue logic needs address to be right shifted by 1 */
+		head_value = head_value >> 1;
+
+		if (head_value > sq->end) {
+			head_value = sq->start;
+			MYDBG("Wraparound of Status Queue %d", sq_index);
+		}
+		rmi_local_config_write(rio_ctrl, 0, STATUS_QUEUE_HEAD(sq_index),
+				       4, head_value);
+
+		sq->curr_sq_index++;
+		if (sq->curr_sq_index >= sq->max_entries)
+			sq->curr_sq_index = 0;
+		/*Call the callback for msg transactions. */
+		port->outb_msg[sq_index].mcback(port, sq->dev_id, -1,
+						sq->curr_sq_index);
+
+		rmi_local_config_read(rio_ctrl, 0, STATUS_QUEUE_HEAD(sq_index),
+				      4, &head_value);
+	}
+
+	spin_unlock(&sq->lock);
+
+	return;
+}
+
+void general_intr(struct rmi_rio_controller *rio_ctrl, struct rio_mport *port)
+{
+	uint32_t gisr = 0;
+	uint32_t dma_high, dma_low, dma_info;
+	uint32_t perr_csr = 0;
+
+	rmi_local_config_read(rio_ctrl, port->index, GENERAL_INTR_STATUS_REG, 4,
+			      &gisr);
+	if (gisr & GISR_DEC) {
+		rmi_local_config_read(rio_ctrl, port->index, DMA_ERR_CAP_HIGH,
+				      4, &dma_high);
+		rmi_local_config_read(rio_ctrl, port->index, DMA_ERR_CAP_LOW, 4,
+				      &dma_low);
+		rmi_local_config_read(rio_ctrl, port->index, DMA_ERR_CAP_INFO,
+				      4, &dma_info);
+		printk("\nSRIO DMA ERROR:\n dma_high: [%#x], dma_low: [%#x],\
+                dma_info[%#x]\n", dma_high, dma_low, dma_info);
+		panic("SRIO: DMA Error");
+	}
+	if (gisr & GISR_MQWE) {
+		rmi_local_config_read(rio_ctrl, port->index, DMA_ERR_CAP_HIGH,
+				      4, &dma_high);
+		rmi_local_config_read(rio_ctrl, port->index, DMA_ERR_CAP_LOW, 4,
+				      &dma_low);
+		rmi_local_config_read(rio_ctrl, port->index, DMA_ERR_CAP_INFO,
+				      4, &dma_info);
+		printk("\nMQ DMA ERROR:\n dma_high: [%#x], dma_low: [%#x], \
+                dma_info[%#x]\n", dma_high, dma_low, dma_info);
+		panic("SRIO: MQ Error");
+	}
+	if (gisr & GISR_SQWE) {
+		rmi_local_config_read(rio_ctrl, port->index, DMA_ERR_CAP_HIGH,
+				      4, &dma_high);
+		rmi_local_config_read(rio_ctrl, port->index, DMA_ERR_CAP_LOW, 4,
+				      &dma_low);
+		rmi_local_config_read(rio_ctrl, port->index, DMA_ERR_CAP_INFO,
+				      4, &dma_info);
+		printk("\nSQ DMA ERROR:\n dma_high: [%#x], dma_low: [%#x], \
+                dma_info[%#x]\n", dma_high, dma_low, dma_info);
+		panic("SRIO: SQ Error");
+	}
+	if (gisr & GISR_PERR) {
+		printk("\nPORT ERROR!!\n");
+		rmi_local_config_read(rio_ctrl, port->index, P0_EAS_CSR, 4,
+				      &perr_csr);
+		printk("port error status register [%#x]\n", perr_csr);
+		panic("SRIO: PORT ERROR - Software Recovery not available\n");
+	}
+}
+
+irqreturn_t rmi_srio_irq_handler(int irq, void *dev_id)
+{
+	struct rmi_rio_controller *rio_ctrl =
+	    (struct rmi_rio_controller *)dev_id;
+	struct rio_mport *port = rio_ctrl->port;
+	uint32_t misr = 0;
+
+	MYDBG("");
+	/*Read MISR */
+	rmi_local_config_read(rio_ctrl, port->index, MASTER_INTR_STATUS_REG, 4,
+			      &misr);
+	if (misr & MISR_GEN) {
+		general_intr(rio_ctrl, port);
+	}
+
+	if (misr & MISR_DF) {
+		MYDBG("DF INTR");
+		doorbell_intr(rio_ctrl, port);
+	}
+
+	if (misr & MISR_MQ3) {
+		MYDBG("MQ INTR");
+		mailbox_intr(rio_ctrl, port);
+	}
+
+	if (misr & MISR_SQ) {
+		MYDBG("SQ INTR");
+		statusq_intr(rio_ctrl, port);
+	}
+
+	MYDBG("");
+	return IRQ_HANDLED;
+}
+
+void setup_controller(struct rmi_rio_controller *rio_ctrl,
+		      struct rio_mport *port, int index)
+{
+	rio_ctrl->index = index;
+	rio_ctrl->port = port;
+	rio_ctrl->irq = SRIO_IRQ(index);
+	rio_ctrl->regs_phy_start = rio_reg_phy_start[index];
+	rio_ctrl->host_deviceid = rmi_rio_host_id[index];
+	rio_ctrl->regs_virt_start =
+	    ((unsigned long)CKSEG1ADDR(rio_reg_phy_start[index]));
+	MYDBG("\nController[%d] regs starts @ [%#lx]\n", index,
+	      rio_ctrl->regs_virt_start);
+	MYDBG("\nHost device id %d\n", rio_ctrl->host_deviceid);
+}
+
+int is_rio_link_up(int index)
+{
+	unsigned long addr = CKSEG1ADDR(rio_reg_phy_start[index]);
+	uint32_t result;
+	result = *(uint32_t *) (addr + P0_EAS_CSR);
+	if (result & PORT_N_ERR_STS_PORT_OK)
+		return 1;
+	return 0;
+}
+
+int setup_rio_ops(struct rio_mport *mport, int index)
+{
+	struct rio_ops *ops = NULL;
+
+	ops = kmalloc(sizeof(struct rio_ops), GFP_KERNEL | GFP_DMA);
+
+	if (!ops) {
+		printk("Allocation failed for rio_ops!\n");
+		return -1;
+	}
+	ops->lcread = rmi_rio_ops[index][0];
+	ops->lcwrite = rmi_rio_ops[index][1];
+	ops->cread = rmi_rio_ops[index][2];
+	ops->cwrite = rmi_rio_ops[index][3];
+	ops->dsend = rmi_rio_ops[index][4];
+	mport->ops = ops;
+	return 0;
+}
+
+static int rmi_srio_glue_init_done(void)
+{
+    phoenix_reg_t *srio_be_mmio = 
+                (phoenix_reg_t *)(phoenix_io_base + PHOENIX_IO_SRIO_1_OFFSET);
+    uint32_t srio_ctrl = 0x0;
+    
+    srio_ctrl = phoenix_read_reg(srio_be_mmio, SRIO_CTRL);
+    if(((srio_ctrl>>28) & 0xf) == 0x3)
+        /*Bootloader has done required glue logic init*/
+        return 1;
+    return 0;
+}
+
+void rmi_rio_setup(void)
+{
+	phoenix_reg_t *gpio_mmio =
+	    (phoenix_reg_t *) (phoenix_io_base + PHOENIX_IO_GPIO_OFFSET);
+	uint32_t gpio_reset_cfg;
+	struct rio_mport *port;
+    int i = 0;
+    extern int avail_mem_above_4G;
+    struct rmi_rio_controller *rio_ctrl;
+	uint32_t srio_port_map;
+    
+    if(!is_xlsb0_srio())
+        return;
+
+    if (avail_mem_above_4G) {
+        printk("------------------------------------------------\n");
+        printk("[SRIO]: Detected DRAM above 4G\n");
+        printk("      : HW Support for DMA >32-bit Un-available. \n");
+        printk("------------------------------------------------\n");
+        return;
+    }
+
+    if(!rmi_srio_glue_init_done()){
+        printk("------------------------------------------------\n");
+        printk("SRIO Init is not done from bootloader\n");
+        printk("Skipping SRIO Initialization\n");
+        printk("------------------------------------------------\n");
+        return;
+    }
+
+    /*Check srio mode - x1 or x4*/
+    gpio_reset_cfg = 
+        phoenix_read_reg(gpio_mmio,PHOENIX_GPIO_PWRON_RESET_CFG_REG);
+    
+    if(gpio_reset_cfg & (1<<SRIO_CFG_BIT)){
+        srio_mode = SRIO_X1_MODE;
+        srio_ports = MAX_SRIO_PORTS;
+        printk("Detected SRIO x1 mode\n");
+        printk("Detected %d SRIO ports\n",srio_ports);
+    }else{
+        srio_mode = SRIO_X4_MODE;
+        srio_ports = MIN_SRIO_PORTS;
+        printk("Detected SRIO x4 mode\n");
+        printk("Detected %d SRIO port\n",srio_ports);
+    }
+
+	if(dev_tree_en) 
+		fdt_get_srio_port_map(&srio_port_map);
+	 else 
+		srio_port_map = (1 << srio_ports) - 1;
+
+	//printk("\nsrio_port_map = %#x\n",srio_port_map);
+    for(i=0; i<srio_ports; i++){
+
+	if(!(srio_port_map & ( 1 << i)))
+		continue;
+
+        /*Check if link is up*/
+        if(!is_rio_link_up(i)){
+//          printk("\nLink %d is down!!!\n",i);
+            continue;
+        }
+
+
+        printk("SRIO link %d up\n",i);
+
+	if (gpio_reset_cfg & (1 << SRIO_CFG_BIT)) {
+		srio_mode = SRIO_X1_MODE;
+		srio_ports = MAX_SRIO_PORTS;
+		printk("Detected SRIO x1 mode\n");
+		printk("Detected %d SRIO ports\n", srio_ports);
+	} else {
+		srio_mode = SRIO_X4_MODE;
+		srio_ports = MIN_SRIO_PORTS;
+		printk("Detected SRIO x4 mode\n");
+		printk("Detected %d SRIO port\n", srio_ports);
+	}
+
+	for (i = 0; i < srio_ports; i++) {
+		/*Check if link is up */
+		if (!is_rio_link_up(i)) {
+			//printk("\nLink %d is down!!!\n",i);
+			continue;
+		}
+
+		printk("SRIO link %d up\n", i);
+
+		rio_ctrl = rio_controller[i] = kmalloc
+		    (sizeof(struct rmi_rio_controller), GFP_KERNEL | GFP_DMA);
+
+		if (!rio_ctrl)
+			goto fail;
+
+		port = kmalloc(sizeof(struct rio_mport), GFP_KERNEL | GFP_DMA);
+
+		if (!port) {
+			printk("Allocation failed for rio_mport!\n");
+			printk("Registered %d rapidio controller\n", i);
+			goto fail;
+		}
+
+		sprintf(port->name, "RIO%d mport", i);
+
+		port->id = 0;
+		port->index = 0;
+		INIT_LIST_HEAD(&port->dbells);
+
+		port->phy_type = RIO_PHY_SERIAL;
+		port->sys_size = 1;	/*Controller supports 16bit transport addressing*/
+		port->host_deviceid = rio_ctrl->host_deviceid;
+
+		setup_controller(rio_ctrl, port, i);
+
+		port->iores.start = rio_ctrl->regs_phy_start;
+		port->iores.end = rio_ctrl->regs_phy_start + RMI_SRIO_MEM_SIZE;
+		port->iores.flags = IORESOURCE_MEM;
+
+		rio_init_dbell_res(&port->riores[RIO_DOORBELL_RESOURCE], 0,
+				   0xffff);
+		rio_init_mbox_res(&port->riores[RIO_INB_MBOX_RESOURCE], 0, 3);
+		rio_init_mbox_res(&port->riores[RIO_OUTB_MBOX_RESOURCE], 0, 0);
+
+		port->host_deviceid = rio_ctrl->host_deviceid;
+
+		/*Enable Output, Input and Multicast event partcipant */
+		rmi_local_config_write(rio_ctrl, port->index, P0_CTRL_CSR, 4,
+				       (1 << OUTPUT_PORT_EN) | (1 <<
+								INPUT_PORT_EN) |
+				       (1 << MULTI_EVENT_EN));
+
+		/*
+		   Setup resources for maintenance transactions.
+		   -setup Transaction Queue 1
+		   -setup Status Queue 1
+		 */
+		if (rmi_setup_maint_trans_rsrc(rio_ctrl))
+			goto fail;
+
+		/*Register irq for controller. */
+		if (request_irq
+		    (rio_ctrl->irq, rmi_srio_irq_handler, IRQF_DISABLED,
+		     rio_ctrl->port->name, rio_ctrl))
+			panic("Can't reserve srio irq!!");
+
+		/*Enable GENERL ERROR INTERRUPTS */
+		rmi_local_config_write(rio_ctrl, rio_ctrl->port->index,
+				       GENERAL_INTR_ENABLE_REG, 4,
+				       (1 << GIER_PERR) | (1 << GIER_DEC) |
+				       (1 << GIER_MQWE) | (1 << GIER_SQWE));
+		/*Enable MIER for SQ, MQ3 and DF */
+		rmi_local_config_write(rio_ctrl, rio_ctrl->port->index,
+				       MASTER_INTR_ENABLE_REG, 4,
+				       (1 << MIER_DF) | (1 << MIER_MQ3) | (1 <<
+									   MIER_SQ)
+				       | (1 << MIER_GEN));
+#if 0
+		rmi_setup_maint_trans_rsrc_test(rio_ctrl);
+		continue;
+#endif
+		/*Enable doorbell interrupts. Kernel doesn't give us any hook!! */
+		rmi_local_config_write(rio_ctrl, rio_ctrl->port->index,
+				       DOORBELL_INTR, 4, (1 << DB_NNE));
+
+		spin_lock_init(&rio_ctrl->mailbox_lock);
+		spin_lock_init(&rio_ctrl->freel_lock);
+		rio_register_mport(port);
+	}
+
+      fail:
+	free_unregistered_resrources();
+	return;
+}
+
+void free_unregistered_resrources(void)
+{
+	struct rio_mport *port = NULL;
+	struct rio_ops *ops = NULL;
+	int i = 0;
+
+	for (i = 0; i < srio_ports; i++) {
+		/*Free all partially initalized controller data struct */
+		if (!rio_controller[i])
+			continue;
+		port = rio_controller[i]->port;
+		if (!port) {
+			kfree(rio_controller[i]);
+			continue;
+		}
+		ops = port->ops;
+		if (!ops) {
+			kfree(port);
+			kfree(rio_controller[i]);
+			continue;
+		}
+	}
+}
diff --git a/arch/mips/rmi/phoenix/smp.c b/arch/mips/rmi/phoenix/smp.c
new file mode 100644
index 0000000..dd82e0b
--- /dev/null
+++ b/arch/mips/rmi/phoenix/smp.c
@@ -0,0 +1,170 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <asm/rmi/64bit.h>
+#include <asm/addrspace.h>
+#include <asm/smp.h>
+#include <linux/sched.h>
+#include <linux/types.h>
+#include <linux/hardirq.h>
+#include <linux/module.h>
+
+
+#include <asm/rmi/sim.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/pic.h>
+#include <asm/rmi/msgring.h>
+
+//#define IPI_PRINTK_DEBUG
+
+/* ipi statistics counters for debugging */
+__u32 ipi_3_counter_tx[NR_CPUS][NR_CPUS];
+__u32 ipi_3_counter_rx[NR_CPUS];
+
+extern void save_epc(unsigned long *epc);
+extern void smp_call_function_interrupt(void);
+extern void phoenix_smp_time_init(void);
+
+static int phoenix_ipi_stats[NR_CPUS];
+static unsigned long phoenix_ipi_epc[NR_CPUS];
+
+#define SET_IPI_VECTOR(x, y) x |= y
+
+void core_send_ipi(int logical_cpu, unsigned int action)
+{
+	int cpu = cpu_logical_map(logical_cpu);
+	__u32 tid = cpu & 0x3;
+	__u32 pid = (cpu >> 2) & 0x07;
+	__u32 ipi = (tid << 16) | (pid << 20);
+
+	if (action & SMP_CALL_FUNCTION) {
+		SET_IPI_VECTOR(ipi, IRQ_IPI_SMP_FUNCTION);
+
+#ifdef IPI_PRINTK_DEBUG
+		printk("[%s]: cpu_%d sending ipi_3 to cpu_%d \t\t\t[->%u] \n",
+		       __FUNCTION__, smp_processor_id(), cpu,
+		       ipi_3_counter_tx[smp_processor_id()][cpu] + 1);
+#endif
+		++ipi_3_counter_tx[smp_processor_id()][cpu];
+
+	} else if (action & SMP_RESCHEDULE_YOURSELF) {
+		SET_IPI_VECTOR(ipi, IRQ_IPI_SMP_RESCHEDULE);
+
+#ifdef IPI_PRINTK_DEBUG
+		printk("[%s]: cpu_%d sending ipi_4 to cpu_%d\n", __FUNCTION__,
+		       smp_processor_id(), cpu);
+#endif
+	} else if (action & SMP_CALL_KGDB_HOOK) {
+
+		SET_IPI_VECTOR(ipi, IRQ_IPI_SMP_KGDB);
+
+#ifdef IPI_PRINTK_DEBUG
+		printk("Sending KGDB IPI 0x%08x to tid %d pid %d\n", ipi, tid,
+		       pid);
+#endif
+	} else if (action & SMP_OPROFILE_IPI) {
+		SET_IPI_VECTOR(ipi, IRQ_IPI_OPROFILE);
+
+#ifdef IPI_PRINTK_DEBUG
+		printk("Sending OPROFILE IPI 0x%08x to tid %d pid %d\n", ipi,
+		       tid, pid);
+#endif
+	}
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	else if (action & SMP_NETRX_IPI) {
+		SET_IPI_VECTOR(ipi, IRQ_IPI_NETRX);
+
+#ifdef IPI_PRINTK_DEBUG
+		printk(KERN_ALERT
+		       "%s: Sending NETRX IPI 0x%08x to tid %d pid %d\n",
+		       __FUNCTION__, ipi, tid, pid);
+#endif				/* IPI_PRINTK_DEBUG */
+	}
+#endif				/* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+	else
+		BUG();
+	//  printk(" -- Sending Ipi %lx\n", ipi);
+#if defined(XLP_SIM)
+	pic_send_ipi(0, (ipi & 0x3f), 0, cpu);
+#else
+	pic_send_ipi(ipi);
+#endif
+}
+
+extern __u64 phnx_irq_mask;
+
+void phoenix_smp_finish(void)
+{
+#if !defined(CONFIG_RMI_XLP)
+	phoenix_msgring_cpu_init();
+#endif
+}
+
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+extern void skb_transfer_finish(void);
+#endif				/* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
+void phoenix_ipi_handler(int irq, struct pt_regs *regs)
+{
+	phoenix_ipi_stats[smp_processor_id()]++;
+	save_epc(&phoenix_ipi_epc[smp_processor_id()]);
+
+	if (irq == IRQ_IPI_SMP_FUNCTION) {
+#ifdef IPI_PRINTK_DEBUG
+		printk("[%s]: cpu_%d processing ipi_%d [->%u]\n", __FUNCTION__,
+		       smp_processor_id(), irq,
+		       ipi_3_counter_rx[smp_processor_id()]++);
+#endif
+		++ipi_3_counter_rx[smp_processor_id()];
+		smp_call_function_interrupt();
+	}
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	else if (irq == IRQ_IPI_NETRX) {
+		irq_enter();
+
+		skb_transfer_finish();
+
+		/* run soft IRQ at the end */
+		irq_exit();
+	}
+#endif				/* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
+	else {
+#ifdef IPI_PRINTK_DEBUG
+		printk("[%s]: cpu_%d processing ipi_%d\n", __FUNCTION__,
+		       smp_processor_id(), irq);
+#endif
+
+		/* Announce that we are for reschduling */
+		set_need_resched();
+
+	}
+	phoenix_ipi_stats[smp_processor_id()]--;
+}
diff --git a/arch/mips/rmi/phoenix/time.c b/arch/mips/rmi/phoenix/time.c
new file mode 100644
index 0000000..9b31d5c
--- /dev/null
+++ b/arch/mips/rmi/phoenix/time.c
@@ -0,0 +1,282 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/interrupt.h>
+#include <linux/sched.h>
+#include <linux/spinlock.h>
+
+#include <asm/irq.h>
+#include <asm/ptrace.h>
+#include <asm/addrspace.h>
+#include <asm/time.h>
+#include <asm/cpu.h>
+#include <asm/cpu-features.h>
+#include <asm/perfctr.h>
+#include <linux/oprofile.h>
+
+#include <linux/proc_fs.h>
+#include <asm/rmi/linux_crf.h>
+
+extern spinlock_t phnx_pic_lock;
+
+#if defined(CONFIG_PERFCTR) && defined(CONFIG_OPROFILE)
+#error "Cannot enable both VPERF and OProfile at the same time"
+#endif
+
+#ifndef CONFIG_PHOENIX_MAC
+void phoenix_user_mac_update_time(void)
+{
+}
+void phoenix_user_mac_update_ktime(void)
+{
+}
+#else
+extern void phoenix_user_mac_update_time(void);
+extern void phoenix_user_mac_update_ktime(void);
+#endif
+ 
+extern struct irq_chip phnx_rsvd_pic;
+extern struct irqaction phnx_rsvd_action;
+
+void save_epc(unsigned long *epc)
+{
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     "mfc0 %0, $14\n" ".set pop\n":"=r"(*epc));
+}
+
+#ifdef CONFIG_OPROFILE
+extern void phoenix_oprofile_int_handler(int irq, void *dev_id,
+					 struct pt_regs *regs);
+#endif
+void phoenix_timer_interrupt(struct pt_regs *regs, int irq)
+{
+	int cpu = smp_processor_id();
+
+#ifdef CONFIG_RMI_WATCHDOG
+#if defined(XLP_SIM)
+        pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+#else
+        phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+#endif
+
+	/* ack the watchdog */
+	/* XLP_TODO: Need to choose (?) the right heartbeat reg (0/1) and right chunk */
+	write_pic_reg(mmio, PIC_WD_HEARTBEAT_0(0), 1 << cpu_logical_map(cpu));
+#endif
+
+#if defined (CONFIG_OPROFILE) || defined (CONFIG_PERFCTR_INTERRUPT_SUPPORT)
+    int cntr0, cntr1;
+    uint32_t ctrl0, ctrl1;
+	int    perfctr_overflow = 0;
+#endif
+
+#ifdef CONFIG_RMI_WATCHDOG
+	/* ack the watchdog */
+	phoenix_write_reg(mmio, 0x0c, 1 << cpu_logical_map(cpu));
+#endif
+
+	if (irq != IRQ_TIMER) {
+		printk("[%s]:cpu_%d: bad timer irq = %x\n", __FUNCTION__, cpu, irq);
+		BUG();
+	}
+
+#if defined (CONFIG_PERFCTR_INTERRUPT_SUPPORT) || defined (CONFIG_OPROFILE)
+    ctrl0 = __read_32bit_c0_register($25, 0);
+    ctrl1 = __read_32bit_c0_register($25, 2);
+    cntr0 = __read_32bit_c0_register($25, 1);
+    cntr1 = __read_32bit_c0_register($25, 3);
+
+    /* if interrupts are enabled for perf events, check if any counter has
+       overflowed. Then we know for sure that this is a perf event
+       */
+    if((ctrl0 & 0x10) || (ctrl1 & 0x10))
+            if((cntr0 < 0) || (cntr1 < 0))
+                perfctr_overflow = 1;
+    if(perfctr_overflow == 0)
+#endif
+    {
+        do_IRQ(irq);
+
+        if (cpu == 0) {
+            phoenix_user_mac_update_time();
+	    phoenix_user_mac_update_ktime();
+        }
+    }
+
+#if defined (CONFIG_PERFCTR_INTERRUPT_SUPPORT) || defined (CONFIG_OPROFILE)
+	if (perfctr_overflow) {
+#ifdef CONFIG_PERFCTR_INTERRUPT_SUPPORT
+		(*perfctr_ihandler) (instruction_pointer(regs));
+#endif
+    }
+#ifdef CONFIG_OPROFILE
+	if (perfctr_overflow) {
+		if(phoenix_thr_id() == 0) {
+			phoenix_oprofile_int_handler (irq, NULL, regs);
+		}
+    }
+#endif
+#endif
+
+}
+
+/* PIC clock at 66Mhz takes more than 60 secs to come to 0 from max. So 32bit 
+   counter is sufficient
+   */
+#define PIC_FREE_RUNNING_TIMER_MAX_VAL 0xffffffff
+cycle_t xlr_hpt_read(void)
+{
+#if defined(XLP_SIM)
+	pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+#else
+
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+#endif				/* #if defined(XLP_SIM) */
+
+#if defined(XLP_SIM)
+	uint32_t counter = 0;
+
+	counter = (uint32_t) read_pic_reg(mmio, PIC_TIMER_6_COUNTER);
+#else
+	uint32_t counter = 0;
+
+	counter = phoenix_read_reg(mmio, PIC_TIMER_6_COUNTER_0);
+#endif				/* #if defined(XLP_SIM) */
+
+	return (cycle_t)(PIC_FREE_RUNNING_TIMER_MAX_VAL - counter);
+}
+EXPORT_SYMBOL(xlr_hpt_read);
+
+int read_current_timer(unsigned long *timer_val)
+{
+	*timer_val = xlr_hpt_read();
+	return 0;
+}
+
+#if defined (XLP_SIM)
+void phoenix_timer_setup(void)
+{
+        pic_reg_t *mmio = (pic_reg_t *) XLP_IO_PIC_OFFSET;
+        unsigned long flags = 0;
+
+        spin_lock_irqsave(&phnx_pic_lock, flags);
+
+        /* Use PIC Timer 6 as a free running counter */
+        write_pic_reg(mmio, PIC_TIMER_6_MAXVAL, 0xffffffffffffffffULL);
+
+	/* enable the timer */
+        pic_update_control(1 << (10 + 6));
+
+        spin_unlock_irqrestore(&phnx_pic_lock, flags);
+        //do_gettimeoffset = phoenix_gettimeoffset;
+
+}
+#else
+void phoenix_timer_setup(void)
+{
+        phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+        unsigned long flags = 0;
+
+        spin_lock_irqsave(&phnx_pic_lock, flags);
+
+        /* Use PIC Timer 6 as a free running counter */
+        phoenix_write_reg(mmio, PIC_TIMER_6_MAXVAL_0, 0xffffffff);
+        phoenix_write_reg(mmio, PIC_TIMER_6_MAXVAL_1, 0xffffffff);
+        /* we Don't need interrupts */
+        phoenix_write_reg(mmio, PIC_IRT_0_TIMER_6, 0);
+        phoenix_write_reg(mmio, PIC_IRT_1_TIMER_6,
+                          (1 << 31) | (0 << 30) | (1 << 6) | (PIC_TIMER_6_IRQ));
+        pic_update_control(1 << (8 + 6));
+
+        spin_unlock_irqrestore(&phnx_pic_lock, flags);
+
+        //do_gettimeoffset = phoenix_gettimeoffset;
+
+#if 0
+        printk
+            ("%s: phoenix_timer_stats = %p, phoenix_timer_diff = %p, phoenix_timer_count = %p, "
+             "phoenix_timer_epc = %p, phoenix_timer_cpu = %p, phoenix_timer_gettimeoffset = %p\n",
+             __FUNCTION__, phoenix_timer_stats, phoenix_timer_diff,
+             phoenix_timer_count, phoenix_timer_epc, phoenix_timer_cpu,
+             phoenix_timer_gettimeoffset);
+#endif
+}
+#endif
+
+static int rmi_timer_proc_read(char *page, char **start, off_t off, int count,
+			       int *eof, void *data)
+{
+	int len = 0;
+
+	preempt_disable();
+	len += sprintf(page + len, "cpu = %d, eimr = 0x%016llx, status = 0x%x\n", 
+				   smp_processor_id(), 
+                   (unsigned long long)read_64bit_cp0_eimr(), read_c0_status());
+	preempt_enable();
+	*eof = 1;
+
+	return len;
+}
+
+extern struct proc_dir_entry *rmi_root_proc;
+struct proc_dir_entry *main_entry;
+struct proc_dir_entry *sub_entry;
+
+static int init_pic_timer_procfs(void)
+{
+	main_entry = proc_mkdir("rmi_timer", rmi_root_proc);
+	if (!main_entry) {
+		printk(KERN_ERR "unable to create /proc/rmi_timer\n");
+		return -ENOMEM;
+	}
+
+	sub_entry = create_proc_entry("debug", 0644, main_entry);
+
+	if (!sub_entry) {
+		remove_proc_entry("rmi_timer", rmi_root_proc);
+		return -ENOMEM;
+	}
+
+	sub_entry->read_proc = rmi_timer_proc_read;
+
+	printk("created rmi_timer proc fs entry\n");
+
+	return 0;
+}
+
+static void exit_pic_timer_procfs(void)
+{
+	remove_proc_entry("debug", main_entry);
+	remove_proc_entry("rmi_timer", rmi_root_proc);
+}
+
+module_init(init_pic_timer_procfs);
+module_exit(exit_pic_timer_procfs);
diff --git a/arch/mips/rmi/ptr/Makefile b/arch/mips/rmi/ptr/Makefile
new file mode 100644
index 0000000..136be8d
--- /dev/null
+++ b/arch/mips/rmi/ptr/Makefile
@@ -0,0 +1,11 @@
+#EXTRA_CFLAGS := -Werror
+obj-y                   = setup.o config_net.o
+obj-$(CONFIG_RMI_XLR) += platform.o
+obj-$(CONFIG_RMI_XLP) += platform-xlp.o
+
+obj-$(CONFIG_SMP)      += smp.o smpboot.o 
+obj-$(CONFIG_KGDB)      += nmi.o
+obj-y 			+= loader/ rmicrf/
+
+EXTRA_AFLAGS := $(CFLAGS)
+EXTRA_CFLAGS += -I$(srctree)/arch/mips/include/asm/rmi
diff --git a/arch/mips/rmi/ptr/config_net.c b/arch/mips/rmi/ptr/config_net.c
new file mode 100644
index 0000000..63784a3
--- /dev/null
+++ b/arch/mips/rmi/ptr/config_net.c
@@ -0,0 +1,562 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/*
+ * Setup code for RMI's XLR-based boards
+ */
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/socket.h>
+#include <linux/errno.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/config_net.h>
+#include <asm/rmi/phoenix_mac.h>
+#include <asm/rmi/gpio.h>
+
+struct net_device_cfg phnx_net_dev_cfg;
+extern unsigned long phoenix_io_base;
+extern uint32_t dev_tree_en;
+extern void rmi_dev_config_net(void);
+
+static uint32_t gmac_offsets[] = { PHOENIX_IO_GMAC_0_OFFSET, PHOENIX_IO_GMAC_1_OFFSET, 
+			PHOENIX_IO_GMAC_2_OFFSET, PHOENIX_IO_GMAC_3_OFFSET,
+			PHOENIX_IO_GMAC_4_OFFSET, PHOENIX_IO_GMAC_5_OFFSET,
+			PHOENIX_IO_GMAC_6_OFFSET, PHOENIX_IO_GMAC_7_OFFSET };
+
+#if !defined(XLP_SIM)
+static uint32_t gmac_irqs[] = { PIC_GMAC_0_IRQ, PIC_GMAC_1_IRQ, 
+			PIC_GMAC_2_IRQ, PIC_GMAC_3_IRQ,
+			PIC_GMAC_4_IRQ, PIC_GMAC_5_IRQ,
+			PIC_GMAC_6_IRQ, PIC_GMAC_7_IRQ };
+
+static uint32_t xgmac_offsets[] = { PHOENIX_IO_XGMAC_0_OFFSET, PHOENIX_IO_XGMAC_1_OFFSET };
+static uint32_t spi4_offsets[] = { PHOENIX_IO_SPI4_0_OFFSET, PHOENIX_IO_SPI4_1_OFFSET };
+static uint32_t xgs_irqs[] = { PIC_XGS_0_IRQ, PIC_XGS_1_IRQ };
+#endif /* XLP_SIM */
+
+#define MAX_NUM_DESC		512
+#define PHNX_BASE(x) (phoenix_io_base + x)
+
+extern int xlr_loader_support;
+extern int xlr_loader_sharedcore;
+extern int xlr_loader_own_gmac;
+extern int rmik_en;
+/*
+   This functions returns:
+   True (1): if block is in XAUI mode
+   False(0): if block is in GMAC mode
+*/
+
+int xlsb0_in_xaui(int block)
+{
+    unsigned int gpio_xaui = 0;
+    phoenix_reg_t *gpio_mmio =
+                    (unsigned int *)(phoenix_io_base + PHOENIX_IO_GPIO_OFFSET);
+    if (xlr_board_atx_xi() || xlr_board_atx_xii()) {
+        gpio_xaui = ((phoenix_read_reg(gpio_mmio,21) >> 24) & 0x3);
+        switch(gpio_xaui){
+            case 0x1:
+                return block==0?1:0;
+            case 0x2:
+                 return block==1?1:0;
+            case 0x3:
+                 return 1;
+            default:
+                return 0;
+        }
+    }
+    return 0;
+}
+
+static int sgmii_daughter_card_present(int block)
+{
+	unsigned long cpld_base = (unsigned long)(PHOENIX_CPLD_OFFSET);
+	unsigned char *mmio = (unsigned char*)cpld_base;
+	unsigned char value = mmio[0x0d];
+	value = value & 0x03;
+
+	switch (block)
+	{
+		case 0:
+			if ((value == 0x0) || (value == 0x1))
+				return 1;
+			break;
+		case 1:
+			if ((value == 0x0) || (value == 0x2))
+				return 1;
+			break;
+		default:
+			return 0;
+	}
+	return 0;
+}
+
+/* This arrray is indexed with the processor id 8bits */
+char rmi_chip_gmac_count[256];
+void init_gmac_ports(void)
+{
+	int processor_id;
+
+    processor_id = ((read_c0_prid() & 0xff00) >> 8);
+
+    /* Currently handle for XLS B0 parts... */
+    switch(processor_id) {
+        case CHIP_PROCESSOR_ID_XLS_616_B0:
+        case CHIP_PROCESSOR_ID_XLS_608_B0:
+        case CHIP_PROCESSOR_ID_XLS_416_B0:
+        case CHIP_PROCESSOR_ID_XLS_412_B0:
+        case CHIP_PROCESSOR_ID_XLS_408_B0:
+        case CHIP_PROCESSOR_ID_XLS_404_B0:
+            rmi_chip_gmac_count[processor_id] = 8;
+            break;
+
+        default:
+            break;
+    }
+}
+int phnx_is_mac_active(int instance, int type, int *mode)
+{
+    uint32_t *gpio_base = (uint32_t *)(DEFAULT_PHOENIX_IO_BASE +
+                                    PHOENIX_IO_GPIO_OFFSET);    
+	int processor_id;
+    int xaui_board = 0;
+
+
+    if(xlr_board_atx_xi() || xlr_board_atx_xii())
+        xaui_board = 1;
+
+	*mode = PHY_MODE_RGMII;
+
+	/* On XLS xgmac is not available */
+	if (is_xls()) {
+		if(type == TYPE_XGMAC || type == TYPE_SPI4)
+                return 0;
+
+		processor_id = ((read_c0_prid() & 0xff00) >> 8);
+
+		*mode = PHY_MODE_SGMII;
+
+		if(instance == 0) {
+			/* Lite board does not have rgmii ifc */
+			if(xlr_board_atx_viii())
+				*mode = PHY_MODE_SGMII;
+			/* atx-xi/xii boards: SGMII mode for gmac 0 only if 
+			   daughter card for gmac block-0 is present.
+			   */
+			else if((xlr_board_atx_xi() || xlr_board_atx_xii()) &&
+					(!sgmii_daughter_card_present(0)))
+				*mode = PHY_MODE_RGMII;
+			else
+				*mode = PHY_MODE_RGMII | PHY_MODE_SELECTABLE;
+		}
+
+		if(is_xls_b0() && xaui_board){
+			if(instance < 4){
+                /* If port is not in XAUI mode, this board does not have SGMII.
+                   Only port 0 is in RGMII mode
+                   */
+				if(xlsb0_in_xaui(0)) {
+                    *mode = PHY_MODE_XAUI; /* else mode is set above */
+                    printk("Port %d is in XAUI mode\n", instance);
+                    if(instance == 0)
+                        return 1;
+                    else
+                        return 0;
+                } else
+				{
+					/* return TRUE if (instance == 0) OR
+					   if daughter card for block0 is 
+					   present 
+					 */
+					if ((instance == 0) || 
+						sgmii_daughter_card_present(0))
+						return 1;
+					else
+						return 0;
+				}
+			}
+			else if(instance < 8){
+                /* If port is not in XAUI mode, this board does not have SGMII*/
+				if(xlsb0_in_xaui(1)) {
+                    *mode = PHY_MODE_XAUI;
+                    printk("Port %d is in XAUI mode\n", instance);
+                    if(instance == 4)
+                        return 1;
+                    else
+                        return 0;
+                } else 
+				{
+					/* return TRUE only if daughter card 
+					   for block 1 is present */
+					if (sgmii_daughter_card_present(1))
+						return 1;
+					else
+						return 0;
+				}
+			}else
+				return 0;
+		}
+
+		/* all XLS parts have gmac0, gmac1 */
+		if (instance < 2)
+				return 1;
+
+		if (processor_id <= CHIP_PROCESSOR_ID_XLS_104) {
+			/* all XLS parts with processor_id <=104, have gmac3 */
+			if (instance < 3) 	
+				return 1;
+		}
+		if (processor_id <= CHIP_PROCESSOR_ID_XLS_204) {
+			/* all XLS parts with processor_id <=204, have gmac4 */
+			if (instance < 4) 	
+				return 1;
+		}
+
+		if ((processor_id >= CHIP_PROCESSOR_ID_XLS_608) &&
+		    (processor_id < CHIP_PROCESSOR_ID_XLS_208)) {
+			if (instance < 6) 
+				return 1;
+
+			if(((gpio_base[PHOENIX_GPIO_FUSE_BANK_REG] & (1<<28)) == 0)  &&
+    	            ((gpio_base[PHOENIX_GPIO_FUSE_BANK_REG] & (1<<29)) ==  0)){
+				/*Below bits are set when ports are disabled.
+				28 - GMAC7
+				29 - GMAC6
+				30 - GMAC5
+				31 - GMAC4
+				*/
+				/*We found an XLS-408 with 8 gmacs*/
+				if (instance < 8) 
+					return 1;
+			}
+		}
+		if (processor_id == CHIP_PROCESSOR_ID_XLS_608) {
+			if (instance == 6 || instance == 7) 
+				return 1;
+		}
+
+        if(rmi_chip_gmac_count[processor_id] &&
+                (instance < rmi_chip_gmac_count[processor_id]))
+            return 1;
+
+		/* should never come here */
+		return 0;
+	}
+	
+	if (type == TYPE_GMAC) {
+		/* On XLR gmac4 to gmac7 are unavailable */
+		if(instance >= 4)
+			return 0;
+
+		/* On ATX-II, gmac 0 and gmac 1 are not available */
+		if (xlr_board_atx_ii() && !xlr_board_atx_ii_b()) {
+			if(instance < 2)
+				return 0;
+		}
+
+		/* On ATX-IV-B and ATX-V, gmac 3 is not available */
+		if ((xlr_board_atx_v() || xlr_board_atx_iv_b())) {
+			if(instance > 2)
+				return 0;
+		}
+
+		return 1;
+
+	} else if(type == TYPE_XGMAC) {
+		/* On ATX-II and ATX IIB 2 xgmac is  available */
+		if (xlr_board_atx_ii() || xlr_board_atx_ii_b())
+			return 1;
+		return 0;
+
+	}  else if(type == TYPE_SPI4) {
+		if(xlr_board_atx_i())
+			return 1;
+		return 0;
+	}
+	
+	return 0;
+}
+
+int phnx_get_phy_info(int instance, int mode, unsigned long *mii_addr, 
+					unsigned long *pcs_addr, unsigned long *serdes_addr)
+{
+	uint32_t phy_addr;
+
+	*pcs_addr = 0x0;
+	*serdes_addr = 0x0;
+	*mii_addr = PHNX_BASE(gmac_offsets[0]);
+
+	if(is_xls()) {
+		if(instance < PHOENIX_GMAC_PORTS_PER_CTRL) {
+			*pcs_addr = PHNX_BASE(gmac_offsets[0]);
+		} else  {
+			*pcs_addr = PHNX_BASE(gmac_offsets[PHOENIX_GMAC_PORTS_PER_CTRL]);
+		}
+		*serdes_addr = PHNX_BASE(gmac_offsets[0]);
+
+		if(mode & PHY_MODE_RGMII) {
+			phy_addr = 0 + instance;
+			/*only atx-vi has rgmii-0 linked to sgmii-4 offset*/
+			if(xlr_board_atx_vi())
+				*mii_addr = PHNX_BASE(gmac_offsets[PHOENIX_GMAC_PORTS_PER_CTRL]);		
+		} else
+			phy_addr = 0x10 + instance;
+
+		/* boards 11 / 12 may have SGMII ports due to daughter
+		   cards.  In this case, the phy for block-0 is same as 
+		   gmac[0], but phy for block-1 is taken from gmac[4].
+		   Hence, update phy values if gmac instance >= 4.
+		   */
+		if ((xlr_board_atx_xi() || xlr_board_atx_xii()) &&
+				(instance >= PHOENIX_GMAC_PORTS_PER_CTRL))
+		{
+			*mii_addr = PHNX_BASE(gmac_offsets[PHOENIX_GMAC_PORTS_PER_CTRL]);
+			phy_addr -= PHOENIX_GMAC_PORTS_PER_CTRL;
+		}
+	} else {
+		if (xlr_board_atx_ii() && !xlr_board_atx_ii_b()) {
+			if(instance < 2)
+					phy_addr =  0;
+			phy_addr = instance - 2;
+		}
+		phy_addr = 0 + instance;
+	}
+	return phy_addr;
+}
+
+void config_net_init(void)
+{
+#if !defined(XLP_SIM)
+	struct net_device_cfg *net_dev = &phnx_net_dev_cfg;
+	int i, mode, gmac_pblock = 0;
+	int num_desc = MAX_NUM_DESC;
+
+    init_gmac_ports();
+	for(i = 0; i < PHOENIX_MAX_GMACS; i++)  {
+		/* general config for gmac */
+		net_dev->gmac_port[i].instance = i;
+		net_dev->gmac_port[i].irqno = gmac_irqs[i];
+		net_dev->gmac_port[i].config_pde = 1;
+		/* chip specific config for gmac */
+		if(phnx_is_mac_active(i, TYPE_GMAC, &mode) == 1) {
+			net_dev->gmac_port[i].mmio_addr = PHNX_BASE(gmac_offsets[i]);
+			net_dev->gmac_port[i].cfg_flag 	= PORT_OWN_LINUX;
+			
+			if(xlr_board_atx_vii() && i==4)
+				/*atx-vii board workaround for mdio-1*/
+				net_dev->gmac_port[i].cfg_flag 	= PORT_OWN_LINUX & ~(PHNX_INT_ATTACH);
+
+			if(i >= gmac_pblock) {
+				net_dev->gmac_port[i].num_desc = num_desc;
+				if(is_xls()) {
+					if(i < PHOENIX_GMAC_PORTS_PER_CTRL) {
+						net_dev->gmac_port[i].bucket = &xls_bucket_sizes.bucket[MSGRNG_STNID_GMAC0];
+						net_dev->gmac_port[i].credit = &xls_cc_table_gmac0;
+					} else {
+						net_dev->gmac_port[i].bucket = &xls_bucket_sizes.bucket[MSGRNG_STNID_GMAC1];
+						net_dev->gmac_port[i].credit = &xls_cc_table_gmac1;
+					}
+				} else {
+					net_dev->gmac_port[i].bucket = &bucket_sizes.bucket[MSGRNG_STNID_GMAC];
+					net_dev->gmac_port[i].credit = &cc_table_gmac;
+				}
+				gmac_pblock += PHOENIX_GMAC_PORTS_PER_CTRL;
+			}
+ 
+			net_dev->gmac_port[i].phy_mode = mode;
+
+			net_dev->gmac_port[i].phy_addr = phnx_get_phy_info(i, 
+				net_dev->gmac_port[i].phy_mode, 
+				&net_dev->gmac_port[i].mii_addr, 
+				&net_dev->gmac_port[i].pcs_addr, 
+				&net_dev->gmac_port[i].serdes_addr);
+			
+		}
+	}
+
+	/* general config for xgmac */
+	for(i = 0; i < PHOENIX_MAX_XGMACS; i++)  {
+		net_dev->xgs_port[i].instance = i;
+		net_dev->xgs_port[i].irqno = xgs_irqs[i];
+		net_dev->xgs_port[i].config_pde = 1;
+
+		if(phnx_is_mac_active(i, TYPE_XGMAC, &mode) == 1) {
+			net_dev->xgs_port[i].mmio_addr = PHNX_BASE(xgmac_offsets[i]);
+			net_dev->xgs_port[i].cfg_flag 	= PORT_OWN_LINUX;
+			net_dev->xgs_port[i].num_desc = num_desc;
+			net_dev->xgs_type[i] = TYPE_XGMAC;
+
+		} else 	if(phnx_is_mac_active(i, TYPE_SPI4, &mode) == 1) {
+			net_dev->xgs_port[i].mmio_addr = PHNX_BASE(spi4_offsets[i]);
+			net_dev->xgs_port[i].cfg_flag 	= PORT_OWN_LINUX;
+			net_dev->xgs_port[i].num_desc = num_desc;
+			net_dev->xgs_type[i] = TYPE_SPI4;
+		}
+		/* as descriptors are discontinues we need to pass the 
+           full list */
+		net_dev->xgs_port[i].bucket = &bucket_sizes.bucket[0];
+		if(i == 0)
+			net_dev->xgs_port[i].credit = &cc_table_xgs_0;
+		else
+			net_dev->xgs_port[i].credit = &cc_table_xgs_1;
+	}
+
+	/* Modify the basic configurations with the options 
+			supported in Linux */
+	/* Loader support */
+	if(xlr_loader_support) {
+		if(xlr_loader_sharedcore) {
+			/* GMAC, XGMAC and SPI4 are owned by apps */
+			for(i = 0; i < PHOENIX_MAX_XGMACS; i++)  {
+				net_dev->xgs_port[i].cfg_flag     = 0;
+			}
+
+			/* GMAC will be owned by linux if xlr_loader_own_gmac = 1*/
+			for(i = 0; i < PHOENIX_MAX_GMACS; i++)  {
+				if(!xlr_loader_own_gmac) {
+					net_dev->gmac_port[i].cfg_flag     = 0;
+				} else if(!(is_xls())) {
+					net_dev->gmac_port[i].bucket = &shared_bucket_sizes.bucket[MSGRNG_STNID_GMAC];
+					net_dev->gmac_port[i].credit = &shared_cc_table_gmac;
+				}
+			}
+		}
+	}
+
+	/* usermac support */
+	if(xlr_hybrid_user_mac()) {
+		for(i = 0; i < PHOENIX_MAX_GMACS; i++)  {
+			if(net_dev->gmac_port[i].mmio_addr == 0)
+				continue;
+			net_dev->gmac_port[i].cfg_flag     = PHNX_PORT_INIT;
+		}
+	}
+	if(xlr_hybrid_user_mac() || xlr_hybrid_user_mac_xgmac()) {
+		for(i = 0; i < PHOENIX_MAX_XGMACS; i++)  {
+			if(net_dev->xgs_port[i].mmio_addr == 0)
+				continue;
+			net_dev->xgs_port[i].cfg_flag = PHNX_PORT_INIT;
+		}
+	}
+
+	if(xlr_hybrid_rmios_ipsec()) {
+		/* port should be enabled by rmios apps
+          after configuring the descriptors */
+		for(i = 0; i < PHOENIX_MAX_GMACS; i++)  {
+			if(net_dev->gmac_port[i].mmio_addr == 0)
+				continue;
+		//	net_dev->gmac_port[i].cfg_flag     = PHNX_PORT_INIT | PHNX_PORT_ATTACH;
+			net_dev->gmac_port[i].cfg_flag     = PHNX_PORT_ATTACH;
+		}
+		for(i = 0; i < PHOENIX_MAX_XGMACS; i++)  {
+			net_dev->xgs_port[i].cfg_flag     = 0;
+		}
+	}
+
+	if(xlr_hybrid_rmios_tcpip_stack()) {
+		/* port should be enabled by rmios apps
+          after configuring the descriptors */
+		for(i = 0; i < PHOENIX_MAX_GMACS; i++)  {
+			if(net_dev->gmac_port[i].mmio_addr == 0)
+				continue;
+			net_dev->gmac_port[i].cfg_flag     = PHNX_PORT_ATTACH;
+		}
+		for(i = 0; i < PHOENIX_MAX_XGMACS; i++)  {
+			net_dev->xgs_port[i].cfg_flag     = 0;
+		}
+	}
+
+	/* dev_tree_en */
+	if(dev_tree_en) {
+		rmi_dev_config_net();
+	}
+
+	return;
+#endif /* XLP_SIM */
+}
+
+static int __init xlr_mac_desc_setup(char *str)
+{
+	int desc = simple_strtoul(str, 0, 10);
+	struct net_device_cfg *net_dev = &phnx_net_dev_cfg;
+	int i;
+
+	printk("[%s]: str = \"%s\", desc=%d\n", __FUNCTION__, str, desc);
+	if(desc == 0)
+		return 1;
+
+	for(i = 0; i < PHOENIX_MAX_GMACS; i++) {
+		if(net_dev->gmac_port[i].num_desc != 0)
+			net_dev->gmac_port[i].num_desc = desc;
+	}
+
+	for(i = 0; i < PHOENIX_MAX_XGMACS; i++)  {
+		if(net_dev->xgs_port[i].num_desc != 0)
+			net_dev->xgs_port[i].num_desc = desc;
+	}
+
+	return 1;
+}
+
+__setup("xlr_mac_desc=", xlr_mac_desc_setup);
+
+static int __init xls_gmac0_sgmii_setup(char *str)
+{
+	struct net_device_cfg *net_dev = &phnx_net_dev_cfg;
+	if(rmik_en) {
+		printk("***Option xls_gmac0_sgmii= is ignored when booted with CRF***\n");
+		return 1;
+	}
+	
+	if (is_xls()) {
+		if(net_dev->gmac_port[0].phy_mode & PHY_MODE_SELECTABLE) {
+			net_dev->gmac_port[0].phy_mode = 
+				(net_dev->gmac_port[0].phy_mode & PHY_MODE_SELECTABLE) | PHY_MODE_SGMII;
+			net_dev->gmac_port[0].phy_addr = phnx_get_phy_info(0, 
+				net_dev->gmac_port[0].phy_mode, 
+				&net_dev->gmac_port[0].mii_addr, 
+				&net_dev->gmac_port[0].pcs_addr, 
+				&net_dev->gmac_port[0].serdes_addr);
+
+			printk("[%s]: *********************************************\n", __FUNCTION__);
+			printk("[%s]: Enabling SGMII mode for gmac0\n", __FUNCTION__);
+			printk("[%s]: *********************************************\n", __FUNCTION__);
+		}
+	}
+
+	return 1;
+}
+__setup("xls_gmac0_sgmii=", xls_gmac0_sgmii_setup);
+
+
diff --git a/arch/mips/rmi/ptr/dbg_io.c b/arch/mips/rmi/ptr/dbg_io.c
new file mode 100644
index 0000000..1a70f8e
--- /dev/null
+++ b/arch/mips/rmi/ptr/dbg_io.c
@@ -0,0 +1,46 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/delay.h>
+#include <asm/rmi/sim.h>
+
+extern void set_async_breakpoint(unsigned int epc);
+
+void putDebugChar(unsigned char c)
+{
+  siminfo->putsocket = (char)c;
+}
+
+unsigned char getDebugChar(void)
+{
+  /*while ( (siminfo->socket_status & 0x1) == 0);*/
+
+  return (unsigned char)siminfo->getsocket;
+}
diff --git a/arch/mips/rmi/ptr/loader/Makefile b/arch/mips/rmi/ptr/loader/Makefile
new file mode 100644
index 0000000..b3f35a8
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/Makefile
@@ -0,0 +1,5 @@
+EXTRA_CFLAGS := -Werror
+obj-y  = loader.o uart.o console.o entry.o traps.o xlr_lib_launch.o reload_irq_handler.o 
+
+EXTRA_AFLAGS := $(CFLAGS)
+
diff --git a/arch/mips/rmi/ptr/loader/console.c b/arch/mips/rmi/ptr/loader/console.c
new file mode 100644
index 0000000..2cacb96
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/console.c
@@ -0,0 +1,74 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/*
+ *  Derived in part from linux/lib/vsprintf.c
+ *
+ *  Copyright (C) 1991, 1992  Linus Torvalds
+ */
+
+/* vsprintf.c -- Lars Wirzenius & Linus Torvalds. */
+
+#include <linux/console.h>
+
+#define CFG_PBSIZE 128
+
+extern void serial_puts (const char *s);
+extern int outbyte(char c);
+
+int puts (const char *s)
+{
+    serial_puts (s);
+    return 0;
+}
+
+int putchar (int c){
+    outbyte(c);
+    return 0;
+}
+
+/* we use this so that we can do without the ctype library */
+#define is_digit(c)	((c) >= '0' && (c) <= '9')
+
+#define ZEROPAD	1		/* pad with zero */
+#define SIGN	2		/* unsigned/signed long */
+#define PLUS	4		/* show plus */
+#define SPACE	8		/* space if plus */
+#define LEFT	16		/* left justified */
+#define SPECIAL	32		/* 0x */
+#define LARGE	64		/* use 'ABCDEF' instead of 'abcdef' */
+
+#define do_div(n,base) ({ \
+int __res; \
+__res = ((unsigned long) n) % (unsigned) base; \
+n = ((unsigned long) n) / (unsigned) base; \
+__res; })
+
+
diff --git a/arch/mips/rmi/ptr/loader/entry.S b/arch/mips/rmi/ptr/loader/entry.S
new file mode 100644
index 0000000..f1063ff
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/entry.S
@@ -0,0 +1,139 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *****************************#RMI_2#**********************************/
+
+#include <asm/mipsregs.h>
+#include <asm/regdef.h>
+#include <asm/asm.h> 
+#include "xlr_rmios_stackframe.h"
+#include <asm/stackframe.h>
+#include <asm/asm-offsets.h>
+
+
+#define KU_USER 0x10
+                                    
+    .text
+    .align 4
+    .set push
+    .set reorder
+
+FEXPORT(r_ret_from_exception)
+FEXPORT(r_ret_from_irq)
+    .set    noat
+	/* STI */
+    restore_stack_frame
+    eret
+ /*   RESTORE_ALL_AND_RET*/
+    .set    at
+
+NESTED(xlr_tlb_refill_secondary, K_STACK_SIZE, sp)
+	save_stack_frame
+	move a0, sp
+	jal xlr_tlb_panic
+	nop
+END(xlr_tlb_refill_secondary)
+
+NESTED(reload_except_vec_tlbrefill, 0, sp)
+	jal xlr_tlb_refill_secondary 
+	nop    
+END(reload_except_vec_tlbrefill)
+
+NESTED(xlr_xtlb_refill_secondary, K_STACK_SIZE, sp)
+	save_stack_frame
+	move a0, sp
+	jal xlr_xtlb_panic
+	nop
+END(xlr_xtlb_refill_secondary)
+
+
+NESTED(reload_except_vec_xtlbrefill, 0, sp)
+    jal xlr_xtlb_refill_secondary
+    nop
+END(reload_except_vec_xtlbrefill)
+
+NESTED(reload_except_vec_cacheerr, 0, sp)
+    PANIC("Unhandled Cache Err Exception, Reloading CPU\n")
+    nop
+END(reload_except_vec_cacheerr)
+
+NESTED(xlr_vecinit_secondary, K_STACK_SIZE, sp)
+	save_stack_frame
+	move a0, sp
+	jal xlr_vecint_panic
+	nop
+END(xlr_vecinit_secondary)
+
+NESTED(reload_except_vec_vecint, 0, sp)
+    jal xlr_vecinit_secondary
+    nop
+END(reload_except_vec_vecint)
+
+NESTED(reload_except_vec_genex, 0, sp)
+    mfc0    k1, CP0_CAUSE
+    PTR_LA      k0, r_exception_handlers 
+    andi    k1, k1, 0x7c
+    addu    k0, k0, k1
+    lw      k0, (k0)
+    jr      k0
+    nop
+END(reload_except_vec_genex)
+
+    .set pop
+
+	.text
+	.set    push
+	.set    noreorder
+	.set    mips4
+	.align    5
+NESTED(reload_handle_reserved, K_STACK_SIZE, sp)    
+    .set    noat
+    save_stack_frame 
+    .set    at
+    KMODE
+    dmfc0   t0, CP0_STATUS
+    ori t0, 2
+    xori t0, 2
+    dmtc0   t0, CP0_STATUS
+    jal     do_reload_setup
+    move 	a0, sp
+    j   	r_ret_from_exception
+    nop
+END(reload_handle_reserved)    
+
+    .set pop
+
+
+	.text
+	.set    push
+	.set    noreorder
+	.set    mips4
+	.align    5
+    .set pop
+
+
diff --git a/arch/mips/rmi/ptr/loader/fifo.h b/arch/mips/rmi/ptr/loader/fifo.h
new file mode 100644
index 0000000..034832b
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/fifo.h
@@ -0,0 +1,95 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _FIFO_H
+#define _FIFO_H
+
+#define FIFO_SIZE 32
+
+struct fifo {
+	int data[FIFO_SIZE];
+	int size;
+	int head;
+	int tail;
+};
+
+static __inline__ int fifo_next_head(struct fifo *fifo)
+{
+	return (fifo->head + 1) % fifo->size;
+}
+
+static __inline__ int fifo_next_tail(struct fifo *fifo)
+{
+	return (fifo->tail + 1) % fifo->size;
+}
+
+static __inline__ int fifo_empty(struct fifo *fifo)
+{
+	return fifo->head == fifo->tail ? 1 : 0;
+}
+
+static __inline__ int fifo_full(struct fifo *fifo)
+{
+	return fifo_next_tail(fifo) == fifo->head ? 1 : 0;
+}
+
+static __inline__ int fifo_size(struct fifo *fifo)
+{
+	if (fifo->head <= fifo->tail)
+		return fifo->tail - fifo->head;
+	else
+		return (fifo->size - fifo->head) + (fifo->tail - 0);
+}
+
+static __inline__ int fifo_dequeue(struct fifo *fifo, int *data)
+{
+	if (fifo_empty(fifo))
+		return 0;
+	*data = (fifo->data)[fifo->head];
+	fifo->head = fifo_next_head(fifo);
+	return 1;
+}
+
+static __inline__ int fifo_enqueue(struct fifo *fifo, int data)
+{
+	if (fifo_full(fifo))
+		return 0;
+	fifo->data[fifo->tail] = data;
+	fifo->tail = fifo_next_tail(fifo);
+	return 1;
+}
+
+static __inline__ void fifo_init(struct fifo *f)
+{
+	f->head = f->tail = 0;
+	f->size = FIFO_SIZE;
+}
+
+#endif
diff --git a/arch/mips/rmi/ptr/loader/loader.c b/arch/mips/rmi/ptr/loader/loader.c
new file mode 100644
index 0000000..4b3e3e6
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/loader.c
@@ -0,0 +1,580 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <linux/interrupt.h>
+
+#include <asm/mipsregs.h>
+#include <asm/mmu_context.h>
+#include <asm/atomic.h>
+
+#include <asm/rmi/sim.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/bootinfo.h>
+#include <asm/asm.h>
+#include <asm/mipsregs.h>
+#include <asm/rmi/phnx_loader.h>
+#include <user/rmi/phnx_loader.h>
+#include "xlr_boot_lib.h"
+
+#define GPIO_SWRESET_REG 8
+#define Message(a,b...) //printk("\n[%s]-[%d] "a"\n",__FUNCTION__,__LINE__,##b)
+#define ErrorMsg(a,b...) xlr_loader_print(a,##b)
+
+#define MB(x) (unsigned long)(x<<20)
+
+int xlr_loader_print(const char *fmt, ...);
+
+int xlr_loader_put_char(char c);
+char xlr_loader_get_char(void);
+
+void xlr_uart_init(void);
+
+extern struct environment xlr_bldr_env;
+extern struct kuseg_mem_info kuseg_mem_map[];
+
+extern uint32_t phnx_loader_kseg_start, phnx_loader_kseg_size;
+
+struct xlr_vcpu_wakeup_info *xlr_wakeup_info;
+/*Setup this structure and pass it to lib_launch_init. */
+struct xlr_lib_launch_import *xlr_launch;
+struct xlr_lib_load_import *xlr_load;
+extern struct psb_info *prom_info;
+struct psb_info loader_prom_info;
+/* Loader will use this as the boot1_info structure */
+struct psb_info *xlr_linux_boot_info;
+struct psb_mem_map xlr_loader_mem_map;
+struct psb_io_map xlr_loader_io_map;
+static spinlock_t phnx_loader_lock; /*Remove This. - */
+
+extern void reload_generic_trap_init(void);
+
+extern uint32_t phnx_loader_mask;
+extern uint32_t xlr_linux_cpu_mask;
+volatile extern phnx_loader_shared_struct_t *phnx_loader_sh_mem;
+extern struct smp_boot_info smp_boot;
+extern unsigned long  phnx_app_shmem_start;
+extern uint32_t phnx_app_sh_mem_sz;
+
+extern struct r_exception_region *r_exception_vectors;
+
+/* This address is passed in K0 ($26) for all loaded apps */
+phnx_loader_info_t phnx_loader_info;
+
+volatile int xlr_wakeup_ipi[32];
+
+void prom_check_image(void);
+
+unsigned char *xlr_lib_shmem_start  = NULL;
+uint32_t xlr_lib_shmem_size = 0;
+
+void reload_trap_init(void);
+static unsigned char printk_lock[16];
+static unsigned char loader_lock[16];
+static unsigned int global_wakeup_mask;
+#include <asm/cacheops.h>
+#include <asm/r4kcache.h>
+
+void xlr_loader_show_regs(struct xlr_rmios_pt_regs *regs)
+{
+    /* Saved main processor registers */
+    ErrorMsg("\n$0 :0x%016llx 0x%016llx 0x%016llx 0x%016llx",
+            0ULL, regs->regs[1], regs->regs[2], regs->regs[3]);
+    ErrorMsg("\n$4 :0x%016llx 0x%016llx 0x%016llx 0x%016llx",
+            regs->regs[4], regs->regs[5], regs->regs[6], regs->regs[7]);
+    ErrorMsg("\n$8 :0x%016llx 0x%016llx 0x%016llx 0x%016llx", regs->regs[8],  
+			regs->regs[9],  regs->regs[10], regs->regs[11]);
+	ErrorMsg("\n$12 :0x%016llx 0x%016llx 0x%016llx 0x%016llx",
+            regs->regs[12], regs->regs[13], regs->regs[14], regs->regs[15]);
+    ErrorMsg("\n$16 :0x%016llx 0x%016llx 0x%016llx 0x%016llx",
+            regs->regs[16], regs->regs[17], regs->regs[18], regs->regs[19]);
+    ErrorMsg("\n$20 :0x%016llx 0x%016llx 0x%016llx 0x%016llx",
+            regs->regs[20], regs->regs[21], regs->regs[22], regs->regs[23]);
+    ErrorMsg("\n$24 :0x%016llx 0x%016llx 0x%016llx 0x%016llx",
+			   regs->regs[24], regs->regs[25], regs->regs[26], regs->regs[27]);
+    ErrorMsg("\n$28 :0x%016llx 0x%016llx 0x%016llx 0x%016llx\n",            
+			   regs->regs[28], regs->regs[29], regs->regs[30], regs->regs[31]);
+    /* Saved cp0 registers */
+    ErrorMsg("Hi : 0x%016llx\n", regs->hi);
+    ErrorMsg("Lo : 0x%016llx\n", regs->lo);
+    ErrorMsg("epc  : 0x%016llx    \nStatus: 0x%016llx\nCause : 0x%016llx\n",
+        regs->cp0_epc, regs->cp0_status, regs->cp0_cause);
+}
+
+void xlr_flush_dcache_all(void)
+{
+	int i = 0;
+	int dcache_lines, dcache_sets, dcache_assoc, dcache_line_size;
+	uint32_t config1;
+	unsigned long base = (unsigned long)CKSEG0;
+
+	config1 = read_c0_config1();
+
+	dcache_sets = 1 << (((config1 >> 13) & 0x7) + 6);
+	dcache_assoc = ((config1 >> 7) & 0x7) + 1;
+	dcache_line_size = 1 << (((config1 >> 10) & 0x7) + 1);
+	dcache_lines = dcache_sets * dcache_assoc;
+
+	for (i = 0; i < dcache_lines; i++) {
+		cache_op(Index_Writeback_Inv_D, base);
+		base += dcache_line_size;
+	}
+}
+void local_flush_icache_all(void)
+{
+	int i = 0;
+	int icache_lines, icache_sets, icache_assoc, icache_line_size;
+	uint32_t config1;
+	unsigned long base = (unsigned long)CKSEG0;
+
+	config1 = read_c0_config1();
+	icache_sets = 1 << (((config1 >> 22) & 0x7) + 6);
+	icache_assoc = ((config1 >> 16) & 0x7) + 1;
+	icache_line_size = 1 << (((config1 >> 19) & 0x7) + 1);
+
+	icache_lines = icache_sets * icache_assoc;
+
+	for (i = 0; i < icache_lines; i++) {
+		cache_op(Index_Invalidate_I, base);
+		base += icache_line_size;
+	}
+
+}
+
+void phnx_local_flush_tlb_all(void)
+{
+	unsigned long old_ctx;
+	int entry;
+	int tlbsize;
+	unsigned int config1;
+
+	config1 = read_c0_config1();
+	tlbsize = ((config1 >> 25) & 0x3f) + 1;
+
+	/* Save old context and create impossible VPN2 value */
+	old_ctx = (read_c0_entryhi() & 0xff);
+	write_c0_entrylo0(0);
+	write_c0_entrylo1(0);
+	for (entry = 0; entry < tlbsize; entry++) {
+		write_c0_entryhi(((unsigned long)CKSEG0 + (PAGE_SIZE << 1) * entry));
+		write_c0_index(entry);
+		tlb_write_indexed();
+	}
+	write_c0_entryhi(old_ctx);
+}
+
+static uint32_t tlb_size_to_page_size(uint32_t size)
+{
+	if (size <= (4 * 1024))
+		return 4 * 1024;
+	if (size <= (16 * 1024))
+		return 16 * 1024;
+	if (size <= (64 * 1024))
+		return 64 * 1024;
+	if (size <= (256 * 1024))
+		return 256 * 1024;
+	if (size <= (1024 * 1024))
+		return 1024 * 1024;
+	if (size <= (4 * 1024 * 1024))
+		return 4 * 1024 * 1024;
+	if (size <= (16 * 1024 * 1024))
+		return 16 * 1024 * 1024;
+	if (size <= (64 * 1024 * 1024))
+		return 64 * 1024 * 1024;
+
+	return 256 * 1024 * 1024;
+}
+
+static uint32_t tlb_size_to_mask(uint32_t size)
+{
+	if (size <= (4 * 1024))
+		return 0x0 << 13;
+	if (size <= (16 * 1024))
+		return 0x03 << 13;
+	if (size <= (64 * 1024))
+		return 0x0f << 13;
+	if (size <= (256 * 1024))
+		return 0x3f << 13;
+	if (size <= (1024 * 1024))
+		return 0xff << 13;
+	if (size <= (4 * 1024 * 1024))
+		return 0x3ff << 13;
+	if (size <= (16 * 1024 * 1024))
+		return 0xfff << 13;
+	if (size <= (64 * 1024 * 1024))
+		return 0x3fff << 13;
+
+	return 0xffff << 13;
+}
+
+
+void phnx_setup_tlb(uint64_t virt, uint64_t phys, int size)
+{
+	uint64_t value = 0;
+	uint64_t attr = (3 << 3) | (1 << 2) | (1 << 1) | (1 << 0);
+	int wired = 0;
+	int page_size = tlb_size_to_page_size(size);
+	int page_mask = tlb_size_to_mask(page_size);
+
+	write_c0_pagemask(page_mask);
+	__write_64bit_c0_register($10, 0, virt);
+
+	value = (((phys & 0xffffffffffULL) >> 12) << 6) | attr;
+	write_c0_entrylo0(value);
+
+	value = ((((phys + page_size) & 0xffffffffffULL) >> 12) << 6) | attr;
+	write_c0_entrylo1(value);
+	wired = read_c0_wired();
+
+	write_c0_index(wired);
+	tlb_write_indexed();
+
+	write_c0_wired(wired + 1);
+}
+
+void phnx_get_sp_gp(void)
+{
+	unsigned long sp, gp;
+		__asm__ __volatile__(
+				".set push\n"
+				".set noreorder\n"
+				"move %1, $28\n" 
+				"move %0, $29\n" 
+				"nop\n"
+				".set pop\n"
+				:"=r"(sp), "=r"(gp)
+				);
+	Message("SP = 0x%lx GP = 0x%lx", sp, gp);
+}
+
+void phnx_update_args(phnx_loader_shared_struct_t *sh_mem)
+{
+	struct cpu_wakeup_info *p = &sh_mem->run_info;
+	int i;
+
+	for(i=0; i < p->argc; i++) {
+		p->argv[i] =(char *)((unsigned long)p->argv[i] + 
+				(unsigned long)p->buf);
+	}
+}
+
+void phnx_prepare_cpu(void)
+{
+	uint32_t status;
+	uint64_t eirr;
+
+	write_c0_pagemask(0);
+	write_c0_wired(0);
+
+	write_c0_status(ST0_KX | ST0_CU0 | ST0_CU2);
+	write_c0_cause(0);
+	write_c0_compare(0);
+
+	status = read_c0_status();
+	write_c0_status((status & ~ST0_KX));
+
+	eirr = read_64bit_cp0_eirr();
+	write_64bit_cp0_eirr(eirr);
+}
+
+static void xlr_loader_not_implemented(void)
+{
+	ErrorMsg("xlr_loader: Unimplemented service requested");
+	while(1);
+}
+
+static void xlr_loader_shutdown(void)
+{
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_GPIO_OFFSET);
+
+	/* trigger a chip reset */
+	phoenix_write_reg(mmio, GPIO_SWRESET_REG, 1);
+	for(;;) cpu_wait();
+}
+
+void prom_init_xlr_loader_setup(struct psb_info *prom_info)
+{
+	loader_prom_info = *prom_info;
+	loader_prom_info.size = sizeof(loader_prom_info);
+	loader_prom_info.bldr_envp = (uint64_t)(unsigned long)&xlr_bldr_env;
+}
+
+void prom_init_xlr_loader(struct psb_info *prom_info)
+{
+	unsigned long shared_mem_size=0;
+
+	shared_mem_size = sizeof(struct xlr_vcpu_wakeup_info)*32;
+	shared_mem_size += sizeof(struct psb_info);
+	shared_mem_size += sizeof(struct xlr_lib_load_import);
+	shared_mem_size += sizeof(struct xlr_lib_launch_import);
+	shared_mem_size += sizeof(struct vcpu_extended_info);
+	shared_mem_size += sizeof(struct per_cpu_info_loader) * 32;
+	shared_mem_size += sizeof(struct device_locks);
+	/* 1 additional slot for storing malloc info */
+	shared_mem_size += sizeof(struct ext_tlb) * (MAX_EXTENDED_TLBS+1) * 32;
+	/* room for cacheline alignment if needed by app*/
+	shared_mem_size += 64;
+
+	Message("**************RQD SharedMemSize**************");
+	Message("VcpuWakeupInfo [%lx]",
+					(unsigned long)sizeof(struct xlr_vcpu_wakeup_info)*32);
+	Message("PsbInfo [%lx]",(unsigned long)sizeof(struct psb_info));
+	Message("LibLoadImport [%lx]",
+					(unsigned long)sizeof(struct xlr_lib_load_import));
+	Message("LibLaunchImport [%lx]",
+					(unsigned long)sizeof(struct xlr_lib_launch_import));
+	Message("SharedMemSize [%lx]",(unsigned long)phnx_app_sh_mem_sz);
+	Message("TotalSize Required B4 Making It PageAlign [%#lx]",
+					(unsigned long)shared_mem_size);
+	/*Make shared mem size aligned.*/
+	if(shared_mem_size & (PAGE_SIZE-1)){
+		shared_mem_size += PAGE_SIZE;
+		shared_mem_size = shared_mem_size & ~(PAGE_SIZE-1);
+	}
+
+#ifdef CONFIG_64BIT
+	xlr_lib_shmem_start = (unsigned char *)(MB(49) | 0xffffffff80000000ULL);
+#else
+	xlr_lib_shmem_start = phys_to_virt(MB(49));
+#endif
+	xlr_lib_shmem_size = shared_mem_size;
+
+	/*SANITY CHECK*/
+	if(shared_mem_size > MB(2)){
+		printk("Required Shared Mem Size %#lx",shared_mem_size);
+		panic("---PANIC---");
+	}
+
+	if(!xlr_lib_shmem_start){
+		panic("Couldnt Allocate Memory For shared DataStructure\n");
+	}
+	Message("Before Alignment Addr %#lx, Size %#lx",
+				(unsigned long)xlr_lib_shmem_start,
+				(unsigned long)xlr_lib_shmem_size);
+
+	if(((unsigned long)xlr_lib_shmem_start) & (PAGE_SIZE-1)){
+		xlr_lib_shmem_start += PAGE_SIZE;
+		xlr_lib_shmem_start = (unsigned char *)
+						(((unsigned long)xlr_lib_shmem_start)&~(PAGE_SIZE-1));
+	}
+	Message("Got the memory @ %#lx, size %#lx",
+					(unsigned long)xlr_lib_shmem_start,
+					(unsigned long)xlr_lib_shmem_size);
+
+	xlr_wakeup_info = (struct xlr_vcpu_wakeup_info *)xlr_lib_shmem_start;
+	xlr_linux_boot_info = (struct psb_info *)(xlr_wakeup_info + 32);
+	xlr_load = (struct xlr_lib_load_import *)(xlr_linux_boot_info + 1);
+	xlr_launch = (struct xlr_lib_launch_import *)(xlr_load + 1);
+
+	Message("xlr_wakeup_info @ %#lx, Size %#lx",(unsigned long)xlr_wakeup_info,
+						sizeof(struct xlr_vcpu_wakeup_info));
+	Message("xlr_linux_boot_info @ %#lx, Size %#lx",
+				(unsigned long)xlr_linux_boot_info,	sizeof(struct psb_info));
+	Message("xlr_load @ %#lx, Size %#lx",(unsigned long)xlr_load,
+					sizeof(struct xlr_lib_load_import));
+	Message("xlr_launch @ %#lx, size %#lx",(unsigned long)xlr_launch,
+					sizeof(struct xlr_lib_launch_import));
+	Message(" shared mem size is %#lx",(unsigned long)phnx_app_sh_mem_sz);
+
+	Message("sanity access %#x",*xlr_lib_shmem_start);
+	memset((void *)xlr_lib_shmem_start,0,xlr_lib_shmem_size);
+	memcpy((void *)xlr_linux_boot_info, prom_info, sizeof(struct psb_info));
+
+	xlr_uart_init();
+	Message("UartInit Done.");
+	spin_lock_init(&phnx_loader_lock);
+
+	xlr_linux_boot_info->uart_print = PTR2U64(&xlr_loader_not_implemented);
+	xlr_linux_boot_info->led_output = PTR2U64(&xlr_loader_not_implemented);
+	xlr_linux_boot_info->init = PTR2U64(&xlr_loader_not_implemented);
+	xlr_linux_boot_info->exit = PTR2U64(&xlr_loader_not_implemented);
+	xlr_linux_boot_info->warm_reset = PTR2U64(&xlr_loader_shutdown); /*Make this unimplemented.*/
+	xlr_linux_boot_info->wakeup = PTR2U64(&xlr_loader_not_implemented);
+	xlr_linux_boot_info->rmi_cpu_online_map &= ~xlr_linux_cpu_mask;
+	xlr_linux_boot_info->master_reentry_sp = 0;
+	xlr_linux_boot_info->master_reentry_gp = 0;
+	xlr_linux_boot_info->master_reentry_fn = 
+					PTR2U64(&xlr_loader_not_implemented);
+	xlr_linux_boot_info->slave_reentry_fn = 
+					PTR2U64(&xlr_loader_not_implemented);
+	xlr_linux_boot_info->uart_putchar = PTR2U64(&xlr_loader_put_char); /*Make this not implemented*/
+	xlr_linux_boot_info->uart_getchar = PTR2U64(&xlr_loader_get_char); /*Make this not implemented.*/
+	xlr_linux_boot_info->nmi_handler = PTR2U64(&xlr_loader_not_implemented);
+	xlr_linux_boot_info->malloc = PTR2U64(&xlr_loader_not_implemented);
+	xlr_linux_boot_info->free = PTR2U64(&xlr_loader_not_implemented);
+	xlr_linux_boot_info->global_shmem_addr = prom_info->global_shmem_addr;
+	xlr_linux_boot_info->global_shmem_size = prom_info->global_shmem_size;
+	xlr_linux_boot_info->wakeup_os = PTR2U64(&xlr_loader_not_implemented);
+	/*yet xlr_loader_mem_map is not filled up with proper values, 
+	  we will do it once we are done with parsing of all arguments.*/
+	xlr_linux_boot_info->psb_mem_map = PTR2U64(&xlr_loader_mem_map);
+
+	memcpy((void *)&xlr_loader_io_map, 
+			(void *)(unsigned long)prom_info->psb_physaddr_map,
+				sizeof(struct psb_io_map));
+
+	xlr_linux_boot_info->psb_physaddr_map = PTR2U64(&xlr_loader_io_map);
+}
+
+void prom_start_loader(int cpu, unsigned long sp, unsigned long gp)
+{
+	/* Load Linux SP and GP for this thread and jump to loader function */
+	smp_boot.boot_info[cpu].sp = sp;
+	smp_boot.boot_info[cpu].gp = gp;
+	smp_boot.boot_info[cpu].fn = (unsigned long)&xlr_lib_entry;
+	/* barrier */
+	__sync();
+	smp_boot.boot_info[cpu].ready = 1;
+}
+
+int loader_processor_id(void)
+{
+	unsigned int id;
+	id  = __read_32bit_c0_register($15,1);
+	return (id & 0x1f);
+}
+
+void phnx_start_loader_threads(void)
+{
+	int i,index=0;
+	uint32_t mask = phnx_loader_mask;
+	unsigned long long sp = 0, gp = 0;
+	uint64_t stack_start = 0;
+
+	Message("\nCallin prominit_xlrloader\n");
+	prom_init_xlr_loader(&loader_prom_info);
+
+	stack_start = (uint64_t)(unsigned long)
+					(xlr_lib_shmem_start + xlr_lib_shmem_size);
+	stack_start = (stack_start + PAGE_SIZE) & ~(PAGE_SIZE-1);
+	xlr_launch->xlr_wakeup_info = (uint32_t)(unsigned long)xlr_wakeup_info;
+	xlr_launch->xlr_lib_boot1_info = (uint32_t)(unsigned long)
+										xlr_linux_boot_info;
+
+	/*Below routine ll fill up 'r_exception_vectors+32' with proper exception 
+	handlers*/
+	Message("");
+	reload_generic_trap_init();
+	
+	/*'r_exception_vectors + 1' is filled up with proper exception hadnerls.*/
+	xlr_launch->default_ebase = (uint32_t)(unsigned long)
+								(r_exception_vectors + 32);
+
+	Message("Default Ebase %#x",xlr_launch->default_ebase);
+	for(i=0; i < 32; i++) {
+		if(((1U << i) & mask) == 0)
+			continue;
+		gp = stack_start + ((PAGE_SIZE<<1)*i);
+		if(gp == 0) {
+			panic("%s:No memory available for launching xlr loader threads\n", __FUNCTION__);
+		}
+		sp = gp + (PAGE_SIZE << 1);
+		xlr_launch->gp[i] = gp;
+		xlr_launch->sp[i] = sp - 32;
+		Message("Thread %d ==> Sp [%#llx], GP [%#llx]",
+					i,(unsigned long long)xlr_launch->sp[i],
+					(unsigned long long)xlr_launch->gp[i]);
+	}
+	xlr_launch->cb_prelaunch_init_kuseg = 0;
+	xlr_launch->cb_prelaunch_init_kseg = 0;
+	xlr_launch->flush_icache_all = (int32_t)(long)local_flush_icache_all;
+	xlr_launch->flush_dcache_all = (int32_t)(long)xlr_flush_dcache_all;
+	xlr_launch->flush_tlb_all = (int32_t)(long)phnx_local_flush_tlb_all;
+	xlr_launch->xlr_setup_tlb = (int32_t)(long)phnx_setup_tlb;
+	xlr_launch->xlr_hard_vcpu_id = (int32_t)(long)loader_processor_id;
+	xlr_launch->loader_lock = (int32_t)(long)loader_lock;
+	xlr_launch->global_wakeup_mask = (int32_t)(long)&global_wakeup_mask;
+	xlr_launch->trap_init = (int32_t)(long)reload_trap_init;
+	xlr_launch->cpu_init = (int32_t)(long)phnx_prepare_cpu;
+	xlr_launch->print = (int32_t)(long)xlr_loader_print;
+	memset(loader_lock,0,16);
+	/*Do launch Init.*/
+	Message("\nCallin Launch Init\n");
+	xlr_lib_launch_init(xlr_launch);
+
+	/*Put all loader threads in "wait" inst loop..*/
+	for(i=0;i<32;i++){
+		if(((1U << i) & mask) == 0)
+			continue;
+		sp = xlr_launch->sp[i];
+		gp = xlr_launch->gp[i];
+		prom_start_loader(i, sp, gp);
+	}
+	/*Setup xlr_loader_mem_map with argument passed by user*/
+	xlr_loader_mem_map.nr_map = 1;
+
+	xlr_loader_mem_map.map[index].addr = (uint64_t)phnx_loader_kseg_start;
+	xlr_loader_mem_map.map[index].size = (uint64_t)phnx_loader_kseg_size;
+	xlr_loader_mem_map.map[index].type = BOOT_MEM_RAM;
+	index++;
+
+	for ( i = 0; i < MAX_NUM_KUSEG_BLOCKS;i++) {
+		if ( (kuseg_mem_map[i].start_addr == 0 ) && (kuseg_mem_map[i].size == 0) )
+			continue;
+
+		xlr_loader_mem_map.map[index].addr = kuseg_mem_map[i].start_addr;
+		xlr_loader_mem_map.map[index].size = kuseg_mem_map[i].size;
+		xlr_loader_mem_map.map[index].type = BOOT_MEM_RAM;
+		index++;
+		xlr_loader_mem_map.nr_map = xlr_loader_mem_map.nr_map + 1;
+	}
+
+	/*Setup load_init data structure.*/
+	memcpy((void *)&xlr_load->default_map, (void *)&xlr_loader_mem_map, 
+				sizeof(struct psb_mem_map));
+	memcpy((void *)&xlr_load->recent_map, (void *)&xlr_loader_mem_map, 
+				sizeof(struct psb_mem_map));
+	xlr_load->userapp_cpu_mask = phnx_loader_mask;
+	xlr_load->total_avail_cpu = phnx_loader_mask;
+	xlr_load->recent_avail_cpu = phnx_loader_mask;
+	xlr_load->coredump_support = 0;
+	xlr_load->persistent_data = 0;
+	Message("");
+	memset(printk_lock,0,16);
+	xlr_load->lib_base_lock = (int32_t)(long)printk_lock;
+	Message("*****XLR LOAD INFO*****");
+	Message("Total Avail Vcpu %#x",xlr_load->total_avail_cpu);
+	Message("Recent Avail Vcpu %#x",xlr_load->recent_avail_cpu);
+	Message("Kseg Mem %#llx @ %#llx",(unsigned long long)phnx_loader_kseg_size,
+					(unsigned long long)phnx_loader_kseg_start);
+	for ( i = 0;i < MAX_NUM_KUSEG_BLOCKS ; i++) {
+		Message("Kuseg Mem %#llx @ %#llx",
+					(unsigned long long)kuseg_mem_map[i].size,
+						(unsigned long long)kuseg_mem_map[i].start_addr);
+	}
+	Message("**********************");
+	Message("Main Thread REturning.");
+}
+
+
diff --git a/arch/mips/rmi/ptr/loader/reload_irq_handler.S b/arch/mips/rmi/ptr/loader/reload_irq_handler.S
new file mode 100644
index 0000000..d7a78eb
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/reload_irq_handler.S
@@ -0,0 +1,80 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ *****************************#RMI_2#**********************************/
+
+#include <asm/mipsregs.h>
+#include <asm/regdef.h>
+#include <asm/asm.h> 
+#include <asm/stackframe.h>
+#include <asm/asm-offsets.h>
+#include "xlr_rmios_stackframe.h"
+
+#define KU_USER 0x10
+     
+	.text
+        .set    push
+        .set    noreorder
+        .set    mips4
+        .align  5
+        NESTED(reload_irq_handler, K_STACK_SIZE, sp)
+        save_stack_frame 
+        CLI
+
+        /* Read EIRR :   */
+        .word   0x40304806        /* dmfc0 s0, eirr */
+
+        /* If no interrupts, return */
+        beqz    s0, 2f
+        nop
+
+1:
+        /* retrieve the highest priority interrupt */
+        .word   0x72118824        /* dclz s1 s0 */
+        dsubu   a0, zero, s1
+        daddiu  a0, a0, 63
+        /* a0 now has irq# */
+        move    a1, sp
+        /* a1 now has sp */
+        /* first things first : clear the irq in eirr
+        *  note that setting a bit in eirr actually clears it!
+        */
+        li      s0, 1
+        dsllv   s0, s0, a0
+        .word   0x40b04806        /* dmtc0 s0, eirr */
+
+
+        /* a0 = irq, a1 = sp (regs) */
+        jal     reload_do_IRQ
+        nop
+2:      j       r_ret_from_irq
+        nop
+
+        .set pop
+        END(reload_irq_handler)
+
diff --git a/arch/mips/rmi/ptr/loader/traps.c b/arch/mips/rmi/ptr/loader/traps.c
new file mode 100644
index 0000000..a4182ba
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/traps.c
@@ -0,0 +1,217 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+
+#include <asm/mipsregs.h>
+#include <asm/asm.h>
+#include <asm/addrspace.h>
+#include "xlr_boot_lib.h"
+#include <asm/rmi/phnx_loader.h>
+#include "xlr_rmios_stackframe.h"
+
+extern int xlr_loader_print(const char *fmt, ...);
+extern void xlr_loader_show_regs(struct xlr_rmios_pt_regs *regs);
+#define Message(a,b...) 
+#define ErrorMsg(a,b...) xlr_loader_print(a,##b)
+unsigned int r_exception_handlers[32];
+
+struct r_exception_region *r_exception_vectors = 
+			(struct r_exception_region *)CKSEG0;
+
+
+void local_flush_icache_all(void);
+void xlr_flush_dcache_all(void);
+
+extern void reload_handle_reserved(void);
+extern void reload_irq_handler(void);
+
+extern char    reload_except_vec_tlbrefill[], reload_except_vec_xtlbrefill[];
+extern char    reload_except_vec_genex[], reload_except_vec_cacheerr[];
+extern char    reload_except_vec_vecint[];
+
+
+static void *r_set_except_vector(int n, void *addr)
+{
+	unsigned long handler = (unsigned long) addr;
+	unsigned long old_handler = r_exception_handlers[n];
+
+	r_exception_handlers[n] = (unsigned int)handler;
+	return (void *)old_handler;
+}
+
+#define CP0_EBASE     $15
+
+void reload_generic_trap_init(void)
+{
+	int    i;
+	unsigned long ebase;
+	int cpu = 32;
+	for (i = 1; i < 32; i++) {
+		r_set_except_vector(i, reload_handle_reserved);
+	}
+
+	/* Set the Interrupt - Exception Handler (Ex Code 0) */
+	r_set_except_vector(0, reload_irq_handler);
+	ebase = (unsigned long)&r_exception_vectors[cpu];
+
+	memcpy((void *)(ebase       ),  reload_except_vec_tlbrefill, 0x80);
+	memcpy((void *)(ebase + 0x80),  reload_except_vec_xtlbrefill, 0x80);
+	memcpy((void *)(ebase + 0x100), reload_except_vec_cacheerr, 0x80);
+	memcpy((void *)(ebase + 0x180), reload_except_vec_genex, 0x80);
+	memcpy((void *)(ebase + 0x200), reload_except_vec_vecint, 0x80);
+	local_flush_icache_all();
+	xlr_flush_dcache_all();
+}
+
+void reload_trap_init(void)
+{
+	int    i;
+	unsigned long ebase;
+	int cpu;
+	cpu = hard_smp_processor_id();
+
+	/* Setup default vectors */
+	for (i = 1; i < 32; i++) {
+		r_set_except_vector(i, reload_handle_reserved);
+	}
+
+	/* Set the Interrupt - Exception Handler (Ex Code 0) */
+	r_set_except_vector(0, reload_irq_handler);
+
+	/* Copy the generic exception handler code to it's final destination. */
+
+	ebase = (unsigned long)&r_exception_vectors[cpu];
+
+	memcpy((void *)(ebase       ),  reload_except_vec_tlbrefill, 0x80);
+	memcpy((void *)(ebase + 0x80),  reload_except_vec_xtlbrefill, 0x80);
+	memcpy((void *)(ebase + 0x100), reload_except_vec_cacheerr, 0x80);
+	memcpy((void *)(ebase + 0x180), reload_except_vec_genex, 0x80);
+	memcpy((void *)(ebase + 0x200), reload_except_vec_vecint, 0x80);
+
+	/* set up the ebase register */
+	__write_32bit_c0_register($15, 1, (uint32_t)(ebase & 0x3ffff000));
+	/* Flush I-Cache */
+	local_flush_icache_all();
+
+	// Note: Need to do this only because the cacheerr exception vector may be still in
+	// D-cache when cpu takes the exception
+
+	xlr_flush_dcache_all();
+
+}
+
+unsigned int reload_do_IRQ(int irq, struct xlr_rmios_pt_regs *regs)
+{
+	int cpu ;
+	cpu = hard_smp_processor_id();
+	switch (irq) {
+		case IRQ_WAKEUP_CPU_IPI:
+		case IRQ_STOP_CPU_IPI:
+		case IRQ_RECLAIM_CPU_RSRC_IPI:
+			xlr_lib_intr_handler(irq);
+			break;
+		default:
+			ErrorMsg(" Received Unhandled Interrupt = %d!\n", irq);
+			break;
+	}
+	return 0;
+}
+
+void xlr_tlb_panic(struct xlr_rmios_pt_regs *pt_regs)
+{
+	int id = hard_smp_processor_id();
+        reset_printk_base_lock();
+	xlr_loader_show_regs(pt_regs);
+        ErrorMsg("\nUnahandled TLB Refill Exception!!");
+	ErrorMsg("\ncpu_%d: PANIC!!",id);
+        ErrorMsg("\nStop this vcpu using \"stop_vcpu -m <mask>\" cmd.\n");
+        __asm__ __volatile__(
+                "mtc0 %0, $14\n"
+                "move $4,%1\n"
+                "nop\n"
+                "eret\n"
+                "nop\n"
+                ::"r"(xlr_lib_entry),"r"(id)
+        );
+}
+
+void xlr_xtlb_panic(struct xlr_rmios_pt_regs *pt_regs)
+{
+	int id = hard_smp_processor_id();
+        reset_printk_base_lock();
+	xlr_loader_show_regs(pt_regs);
+        ErrorMsg("\nUnahandled XTLB Refill Exception!!");
+        ErrorMsg("\nStop this vcpu using \"stop_vcpu -m <mask>\" cmd.\n");
+        __asm__ __volatile__(
+                "mtc0 %0, $14\n"
+                "move $4,%1\n"
+                "nop\n"
+                "eret\n"
+                "nop\n"
+                ::"r"(xlr_lib_entry),"r"(id)
+        );
+}
+void xlr_vecint_panic(struct xlr_rmios_pt_regs *pt_regs)
+{
+	int id = hard_smp_processor_id();
+        reset_printk_base_lock();
+	xlr_loader_show_regs(pt_regs);
+        ErrorMsg("\nUnahandled Vectored Interrupt !!");
+        ErrorMsg("\nStop this vcpu using \"stop_vcpu -m <mask>\" cmd.\n");
+        __asm__ __volatile__(
+                "mtc0 %0, $14\n"
+                "move $4,%1\n"
+                "nop\n"
+                "eret\n"
+                "nop\n"
+                ::"r"(xlr_lib_entry),"r"(id)
+        );
+}
+
+void do_reload_setup(struct xlr_rmios_pt_regs *regs)
+{
+	int id = hard_smp_processor_id();
+        reset_printk_base_lock();
+	xlr_loader_show_regs(regs);
+	ErrorMsg("\ncpu_%d: PANIC!!",id);
+	ErrorMsg("Stop this vcpu using stop -m <mask> cmd\n");
+        __asm__ __volatile__(
+                "mtc0 %0, $14\n"
+                "move $4,%1\n"
+                "nop\n"
+                "eret\n"
+                "nop\n"
+                ::"r"(xlr_lib_entry),"r"(id)
+        );
+}
diff --git a/arch/mips/rmi/ptr/loader/uart.c b/arch/mips/rmi/ptr/loader/uart.c
new file mode 100644
index 0000000..05a08ce
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/uart.c
@@ -0,0 +1,328 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/init.h>
+
+#include <asm/irq.h>
+#include <asm/io.h>
+#include <asm/bootinfo.h>
+#include <asm/addrspace.h>
+#include <asm/reboot.h>
+#include <asm/time.h>
+#include <linux/interrupt.h>
+#include <asm/atomic.h>
+#include <asm/bootinfo.h>
+
+#include <asm/rmi/sim.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/xlr_virt_uart.h>
+#include "uart.h"
+#include "fifo.h"
+
+
+static struct fifo tx_fifo;
+static struct fifo rx_fifo;
+
+virt_uart virt_uart_outbuf[32];
+
+extern unsigned char load_env[32][6];
+extern int loader_processor_id(void);
+
+#define TX_BURST_SIZE 1
+
+#define DMESG_BUFSIZE 0x1000
+
+
+int tstbyte(void)
+{
+	int data = 0;
+	if (fifo_dequeue(&rx_fifo, &data)) {
+		/* FIFO not empty */
+		return 1;
+	}
+	return 0;
+}
+
+
+char inbyte(void)
+{
+	int data = 0;
+	int lsr = 0;
+	int i = 0;
+	volatile uint32_t *mmio = phoenix_io_mmio(PHOENIX_IO_UART_1_OFFSET);
+
+	if (fifo_dequeue(&rx_fifo, &data)) {
+		/* characters to be read already in fifo */
+		return (char)data;
+	}
+
+	for (;;) {
+
+		lsr = be32_to_cpu(phoenix_read_reg(mmio,UART_LSR));
+
+		if (lsr & 0x20) {
+			/* Tx available, try to send any characters */
+			for (i = 0;
+			     i < TX_BURST_SIZE && fifo_dequeue(&tx_fifo, &data);
+			     i++) {
+			//	uart_outbyte(mmio, data);
+                phoenix_write_reg(mmio,UART_THR, cpu_to_be32(data));
+			}
+		}
+		if (lsr & 0x80) {
+			/* parity/frame/break - push a 0! */
+			if (!fifo_enqueue(&rx_fifo, 0))
+				break;
+		}
+		if (lsr & 0x01) {
+			/* Rx Data */
+			data = be32_to_cpu(phoenix_read_reg(mmio,UART_RHR));
+			if (!fifo_enqueue(&rx_fifo, data))
+				break;
+		}
+		if (!fifo_empty(&rx_fifo))
+			break;
+	}
+
+	fifo_dequeue(&rx_fifo, &data);
+
+	return (char)data;
+}
+
+
+void virt_uart_outbyte(char c,int thrd_id)
+{
+
+       if(*(virt_uart_outbuf[thrd_id].status) != VIRT_UART_OPENED)
+               return;
+
+       while (((*(virt_uart_outbuf[thrd_id].tx_pro) + 1) % (USER_RESULT_SIZE))  ==
+               (*(virt_uart_outbuf[thrd_id].tx_con)))
+                               ;
+
+         *((virt_uart_outbuf[thrd_id].tx_fifo) + *(virt_uart_outbuf[thrd_id].tx_pro)) = c;
+         *(virt_uart_outbuf[thrd_id].tx_pro) = (*(virt_uart_outbuf[thrd_id].tx_pro) + 1) % (USER_RESULT_SIZE);
+	
+	if (c == '\n') {
+	       while (((*(virt_uart_outbuf[thrd_id].tx_pro) + 1) % (USER_RESULT_SIZE))  ==
+        	       (*(virt_uart_outbuf[thrd_id].tx_con)))
+                               ;
+                *((virt_uart_outbuf[thrd_id].tx_fifo) + *(virt_uart_outbuf[thrd_id].tx_pro)) = '\r';
+     		*(virt_uart_outbuf[thrd_id].tx_pro) = (*(virt_uart_outbuf[thrd_id].tx_pro) + 1) % (USER_RESULT_SIZE);
+	}
+        return ;
+}
+
+int outbyte(char c)
+{
+	int data = 0;
+	int lsr = 0;
+	int i = 0;
+	int thrd_id;
+
+	volatile uint32_t *mmio = phoenix_io_mmio(PHOENIX_IO_UART_1_OFFSET);
+
+	thrd_id = loader_processor_id();
+
+       if ( strcmp(load_env[thrd_id],"vuart") == 0)    {
+               virt_uart_outbyte(c,thrd_id);
+               return 0;
+       }
+	if (c == '\n') {
+		char cr = '\r';
+		if (!fifo_enqueue(&tx_fifo, (int)cr)) {
+			/* Too bad tx fifo is full, drop the character */
+			return 1;
+		}
+	}
+	if (!fifo_enqueue(&tx_fifo, (int)c)) {
+		/* Too bad tx fifo is full, drop the character */
+		return 1;
+	}
+
+	/* accumalate some more characters */
+	if ((fifo_size(&tx_fifo) < TX_BURST_SIZE) && (c != '\n') && (c != '\r'))
+		return 0;
+	for (;;) {
+
+		if (fifo_empty(&tx_fifo))
+			break;
+
+		/* wait for Tx empty indication */
+		for (;;) {
+
+			lsr = be32_to_cpu(phoenix_read_reg(mmio,UART_LSR));
+
+			if (lsr & 0x80) {
+				/* parity/frame/break - push a 0! */
+				fifo_enqueue(&rx_fifo, 0);
+			}
+			if (lsr & 0x01) {
+				/* Rx Data */
+				data = 
+				be32_to_cpu(phoenix_read_reg(mmio,UART_RHR));
+				fifo_enqueue(&rx_fifo, data);
+			}
+			/* Tx Fifo empty */
+			if (lsr & 0x20)
+				break;
+		}
+
+		/* transmit upto TX_BURST_SIZE char */
+		for (i = 0; i < TX_BURST_SIZE && fifo_dequeue(&tx_fifo, &data);
+		     i++) {
+			//uart_outbyte(mmio, data);
+                phoenix_write_reg(mmio,UART_THR, cpu_to_be32(data));
+		}
+	}
+
+	return 0;
+}
+
+void
+serial_puts (const char *s)
+{
+    while (*s) {
+        outbyte (*s++);
+    }
+}
+
+int putch(int ch){
+    return outbyte(ch);
+}
+void uart_flush_tx_buf(void)
+{
+	int data = 0;
+	int lsr = 0;
+	volatile uint32_t *mmio = phoenix_io_mmio(PHOENIX_IO_UART_1_OFFSET);
+
+	for (;;) {
+
+		lsr = be32_to_cpu(phoenix_read_reg(mmio,UART_LSR));
+
+		if (lsr & 0x20) {
+
+			if (!fifo_dequeue(&tx_fifo, &data))
+				break;
+
+			/* Tx available, try to send more characters */
+		//	uart_outbyte(mmio, data);
+                	phoenix_write_reg(mmio,UART_THR, cpu_to_be32(data));
+		}
+	}
+}
+
+    
+spinlock_t printf_lock;
+
+void xlr_virt_uart_init(void)
+{
+       int i, size;
+
+       size = USER_CMD_SIZE + USER_RESULT_SIZE + sizeof(unsigned int) * 5;
+
+         for (i=0; i<32; i++){
+                 virt_uart_outbuf[i].rx_fifo = i*size + (unsigned char *) VIRT_UART_BUF_START;
+                 virt_uart_outbuf[i].rx_pro = (unsigned int *)(virt_uart_outbuf[i].rx_fifo + USER_CMD_SIZE);
+                 virt_uart_outbuf[i].rx_con = (unsigned int *)(virt_uart_outbuf[i].rx_pro + 1);
+                 virt_uart_outbuf[i].tx_fifo = (unsigned char *) (virt_uart_outbuf[i].rx_con + 1);
+                 virt_uart_outbuf[i].tx_pro = (unsigned int *) (virt_uart_outbuf[i].tx_fifo + USER_RESULT_SIZE);
+                 virt_uart_outbuf[i].tx_con = (unsigned int *) (virt_uart_outbuf[i].tx_pro + 1);
+                 virt_uart_outbuf[i].status = (unsigned int *) (virt_uart_outbuf[i].tx_con + 1);
+         }
+}
+
+void xlr_uart_init(void)
+{
+	volatile uint32_t *mmio = phoenix_io_mmio(PHOENIX_IO_UART_1_OFFSET);
+
+	fifo_init(&rx_fifo);
+	fifo_init(&tx_fifo);
+	spin_lock_init(&printf_lock);
+	xlr_virt_uart_init();
+
+	/* Set up the baud rate */
+	phoenix_write_reg(mmio,UART_LCR,
+		     cpu_to_be32(be32_to_cpu(phoenix_read_reg(mmio,UART_LCR)) 
+			     		| (1 << 7)));
+	phoenix_write_reg(mmio,UART_DLB_1,  cpu_to_be32(UART_BR_DLB1));
+	phoenix_write_reg(mmio,UART_DLB_2, cpu_to_be32(UART_BR_DLB2));
+	phoenix_write_reg(mmio,UART_LCR, 
+		cpu_to_be32(be32_to_cpu(
+			phoenix_read_reg(mmio, UART_LCR)) & ~(1 << 7)));
+
+}
+
+
+
+char xlr_loader_get_char(void)
+{
+	return inbyte();
+}
+
+
+#define CFG_PBSIZE 128
+int puts (const char *s);
+int xlr_loader_print(const char *fmt, ...)
+{
+	va_list args;
+	unsigned long flags;
+	char printbuffer[CFG_PBSIZE];
+	int i;
+
+	local_irq_save(flags);
+	spin_lock(&printf_lock);
+
+	va_start(args, fmt);
+	/* For this to work, printbuffer must be larger than
+	 * anything we ever want to print.
+	 */
+	i = vsprintf (printbuffer, fmt, args);
+	va_end (args);
+
+
+	/* Print the string */
+	puts (printbuffer);
+	/* flush the transmit buffer */
+	uart_flush_tx_buf();
+	spin_unlock(&printf_lock);
+	local_irq_restore(flags);
+	return 0;
+}
+
+int xlr_loader_put_char(char c) 
+{
+	outbyte(c);
+	return 0;
+}
diff --git a/arch/mips/rmi/ptr/loader/uart.h b/arch/mips/rmi/ptr/loader/uart.h
new file mode 100644
index 0000000..36c8aa3
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/uart.h
@@ -0,0 +1,75 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _UART_H
+#define _UART_H
+
+#define UART_RHR 0
+#define UART_THR 0
+#define UART_IER 1
+#define UART_IIR 2
+#define UART_FCR 2
+#define UART_LCR 3
+#define UART_MCR 4
+#define UART_LSR 5
+#define UART_MSR 6
+
+#define UART_DLB_1 0
+#define UART_DLB_2 1
+
+#define UART_DEBUG_1 8
+#define UART_DEBUG_2 9
+
+// baud rate divisors
+#define UART_BR9600_DLB1 0xad
+#define UART_BR9600_DLB2 0x01
+
+#define UART_BR38400_DLB1 0x6b
+#define UART_BR38400_DLB2 0x00
+
+#define UART_BR115200_DLB1 0x23
+#define UART_BR115200_DLB2 0x00
+
+//#define UART_BR_DLB1 UART_BR9600_DLB1
+//#define UART_BR_DLB2 UART_BR9600_DLB2
+#ifndef PHOENIX_SIM
+#define UART_BR_DLB1 UART_BR38400_DLB1
+#define UART_BR_DLB2 UART_BR38400_DLB2
+#else
+#define UART_BR_DLB1 UART_BR115200_DLB1
+#define UART_BR_DLB2 UART_BR115200_DLB2
+#endif
+
+#ifndef __ASSEMBLY__
+extern int outbyte(char c);
+extern char inbyte(void);
+#endif
+
+#endif
diff --git a/arch/mips/rmi/ptr/loader/xlr_boot_lib.h b/arch/mips/rmi/ptr/loader/xlr_boot_lib.h
new file mode 100644
index 0000000..41fdf6b
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/xlr_boot_lib.h
@@ -0,0 +1,403 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+
+#ifndef __XLR_BOOT_LIB_H
+#define __XLR_BOOT_LIB_H
+typedef struct {
+    volatile unsigned int lock;
+} lib_spinlock_t;
+
+#define CPU_RUNNING 0x1
+#define CPU_STOPPED 0x2
+#define CPU_WAIT_TO_RELEASE_RESOURCE 0x3
+#define CPU_RESOURCE_RELEASED 0x4
+
+#define MAX_ELF_SEGMENTS 16
+#define MAX_TLB_MAPPINGS 16
+#define MAX_EXTENDED_TLBS 512
+#define MAX_WIRED_ENTRIES 14
+#include "xlr_lib_platform.h"
+
+enum {KUSEG_APP, KSEG0_APP};
+
+typedef volatile uint32_t xlr_lib_phnx_reg_t;
+
+#define IRQ_STOP_CPU_IPI 51
+#define IRQ_WAKEUP_CPU_IPI 52
+#define IRQ_RECLAIM_CPU_RSRC_IPI 53
+
+#define XLR_PERSISTENT_MEMORY_MAGIC 0xdead900d
+#define NMI_BL_SHARED_REGION 0x1f000000
+
+#define KSEG0_MEM_MAP 0x10000001
+#define KUSEG_MEM_MAP 0x10000002
+
+#define XLR_ARGV_BUF_SIZE 256
+#define XLR_ENV_BUF_SIZE 256
+#define XLR_MAX_ARGV 32
+#define XLR_MAX_ENV 32
+#define XLR_NUM_CPU 32
+
+#define EXTENDED_BOOT_MAGIC 0xE88E8DED
+#define FREE_TLB_NONSHARED 1
+#define FREE_TLB_ALL 2
+#define MAX_FRAGMENTS 32
+struct xlr_lib_shared_mem
+{
+	uint64_t entries;
+	uint64_t tot_size;
+	uint64_t addr[MAX_FRAGMENTS];
+	uint64_t size[MAX_FRAGMENTS];	
+};
+
+struct proc_section_info
+{
+        int mode;
+        uint32_t vaddr[MAX_ELF_SEGMENTS];
+        uint32_t size[MAX_ELF_SEGMENTS];
+        uint32_t tlb_vaddr[MAX_TLB_MAPPINGS];
+        uint32_t tlb_size[MAX_TLB_MAPPINGS];
+        uint64_t tlb_phys[MAX_TLB_MAPPINGS];
+};
+
+
+struct lib_cpu_tlb_mapping {
+	int page_size;
+	int asid;
+	int coherency;
+	int attr;
+	uint32_t virt;
+	uint64_t phys;
+};
+
+
+struct core_segment_info
+{
+	uint64_t vaddr;
+	uint64_t memsz;
+	uint32_t flags;
+};
+
+
+struct xlr_vcpu_wakeup_info {
+
+	volatile uint32_t cpu_status; /*RUNNING or STOPPED*/
+ 
+	/*Validity for this structure.*/
+	int            valid;
+ 
+	/*For master vcpu this is an elf_entry, for buddy vcpus this points to the function pointer passed in "wakeup" call.*/
+	int32_t func,args;
+
+	/*Stack pointer for this cpu.*/
+	uint64_t sp, gp;
+
+	/*Master CPU No.*/
+	int master_cpu;
+ 
+	/*Master CPU Mask.*/
+	uint32_t master_mask;
+
+	/*Buddy CPU Mask*/
+	uint32_t buddy_mask;
+
+	uint32_t       psb_os_cpu_map;
+ 
+	/*Argv passed while launching application. These all are pointers in 
+    argv_buf.*/
+
+	int argc; /*No. of arg*/
+	uint32_t argv[XLR_MAX_ARGV];
+	char argv_buf[XLR_ARGV_BUF_SIZE]; /*Actual Argv */
+ 
+	/*No. Of Valid TLB Entries*/
+	int            map_count;
+
+	/*Valid only in case of kuseg applications. Kuseg master and buddy vcpus 
+	both will have valid entries here.*/
+	struct lib_cpu_tlb_mapping map[MAX_TLB_MAPPINGS];
+	struct core_segment_info seg_info[MAX_ELF_SEGMENTS];
+ 
+	/*Environment variables, envs is an array of pointers. All pointers points 
+	in to env_buf. Output io device is specfied in one of the environment 
+    variale as ttyS0 or ttyS1. Generic bootloader always sets this to ttyS0*/
+	int env; /*No. Of env*/
+	uint32_t envs[XLR_MAX_ENV];   
+	char env_buf[XLR_ENV_BUF_SIZE];
+
+	/*Mode to decide Kuseg/Kseg applications*/
+	uint32_t mode; 
+
+	/*This points to same physical memory (kseg0), for all applications. "printk" routine of rmios_lib will hold this lock while dumping*/
+	int32_t printk_lock;
+
+	/*Set when we are launching an kseg application on other than vcpu0*/
+	int kseg_master;
+
+	/*Reentry Function For KUSEG Applications, Each vcpu can have its own 
+	reentry function.*/
+	int32_t reentry_function;
+	uint32_t reentry_args;
+
+	/*Reserved shared memory between all application launched by bootloader*/
+	uint64_t app_shared_mem_addr;
+	uint64_t app_shared_mem_size;
+	uint64_t app_shared_mem_orig;
+
+	/*Lock used to avoid window between wakeup and stop*/
+	int32_t loader_lock;
+
+	/*This must contain same values in all xlr_vcpu_wakeup_info structures.
+	  This is used to avoid window while freeing memory.
+	*/
+	/*unsigned long *global_wakeup_mask;*/
+	int32_t global_wakeup_mask;
+
+	/*Unused variables - free for future use*/
+	union {
+		uint32_t unused_0;
+		struct vcpu_extended_info *vcpu_extended_info_ptr;
+	};
+};
+
+struct per_cpu_info_loader {
+	uint64_t num_tlbs;
+	uint64_t ext_tlb_ptr;
+};
+
+struct per_cpu_info{
+	uint64_t num_tlbs;
+	struct tlb *ext_tlb_ptr;
+};
+
+struct device_locks{
+	unsigned char uart0_lock[32];
+	unsigned char uart1_lock[32];
+	unsigned char global_lock[32];
+	unsigned char bridge_io_lock[32];
+	/* Following locks wont be used often. Put them in the same cacheline */
+	unsigned char gmac_lock[8][4];
+	unsigned char xgmac_lock[2][4];
+	unsigned char spi4_lock[2][4];
+} __attribute__ ((aligned(32)));
+
+struct vcpu_extended_info {
+	uint64_t magic;
+	uint64_t ver_major;
+	uint64_t ver_minor;
+	uint64_t size;
+	uint64_t per_cpu_info_size;
+	uint64_t per_cpu_info_ptr;
+	uint64_t uart0_lock;
+	uint64_t uart1_lock;
+	uint64_t global_lock;
+	uint64_t bridge_io_lock;
+	uint64_t gmac_lock[8];
+	uint64_t xgmac_lock[2];
+	uint64_t spi4_lock[2];
+	struct xlr_lib_shared_mem loader_shmem;
+};
+
+struct ext_tlb{
+	uint32_t page_size;
+	uint32_t asid;
+	uint32_t coherency;
+	uint32_t attr;
+	uint64_t virt;
+	uint64_t phys;
+};
+
+
+/*GLOBAL STRUCTURES SHARED BETWEEN ALL VCPUS
+	xlr_lib_load_import:	Used For Elfload.
+	xlr_lib_launch_import:	Used During Launching any application, 
+							for setup tlb, wakeup, prelaunchinit etc.
+*/
+
+/*Foll. structure contains implementation dependent routines and variables. This must be filled by the loader implementation. Strucure should be defined in KSEG0 region, and memory has to be persistent. Library may change values of this structure variables, and also expects value to be same when load_init/launch_init gets call second time.
+	
+	Linux Loader:	In case of linux loader, "loading" is done from user space and "launhing" is done from kernel space, so foll routines will have mixed kernel/user space address. This will be mmaped structure for linux loader, whenver any application is launched using "load" cmd, he has to set this structure with proper function pointers. Kernel Implementation of linux loader has to take care of setting "prelaunch_init" routines.*/
+
+/*Implementation has to fill up foll. structures with appropriate values.
+	This strucure must be defined in KSEG0 Region. Linux Loader loading applications must have to mmap this structure.
+	*Generic Bootloader: All pointers will have kseg0 address.
+	*Linux Loader: All pointers will have kuseg address.
+*/
+struct xlr_lib_load_import
+{
+	/*CopyData - (DestPhysAddr, SrcVirtAddr, Size). Must contain "kuseg" 
+	address for linux loader.*/
+	int32_t copy_data;
+	int32_t copy_data_uncached;
+
+	/*SetData - (DestPhysAddr, SetValue, Size). Must contain "kuseg" address for linux loader.*/
+	int32_t set_data;
+	
+	/*Pointer to function to call wakeup_cpu. Proceduer is implementation dependent. 
+	LinuxLoader: Linux loader sends an ioctl to the driver and driver sends an ipi to the specified cpu and wakes up it.
+	GenericLoader: Directly sends an ipi to the specified vcpu.
+	*/
+
+	/*Args: (cpu, Func, Data) 
+	TODO: Check if we can remove this callback.
+	*/
+
+	int32_t call_wakeup_cpu;
+	int32_t call_stop_vcpu;
+
+	/*call_xlr_start_app: valid only in case of generic bootlaoder.*/
+	int32_t call_xlr_start_app;
+
+	/*Implementation must have to fill up this region.*/
+	struct xlr_lib_psb_mem_map default_map;
+	struct xlr_lib_psb_mem_map recent_map;
+
+	/*Befor Loading Verify whether application can be launched on specified 
+	cpu or not.
+	*Linux Loader	: Before loading any kuseg/kseg application verify whether specified vcpu is available or not. If available then update the mask.
+	*Generic Loader	: Before loading any kuseg application verify whether specified vcpu is availble or not, if yes then update it while loading only. Kseg application never fails in case of generic bootloader, atleast you will find one vcpu free (vcpu0) which can launch this application. Once kseg is launched we are mot much bothered about any other stuffs .. as we wont have any other control.. though update boot1_info as it is.
+	*/
+
+	uint32_t total_avail_cpu;
+	uint32_t recent_avail_cpu;	
+	uint32_t userapp_cpu_mask;
+	
+	/*Pointer To Base of WakeupInfo Structure.*/
+	int32_t xlr_wakeup_info;
+	int32_t vcpu_extended_info;
+	int32_t per_cpu_info;
+
+	/*Pointer To Generic Boot1Info*/
+	int32_t xlr_lib_boot1_info;
+
+	/*Define This as a pointer to buffer of 16 bytes this must be defined in kseg0 region. Implementation must have to call memset on this b4 calling library routines. This must be done only once, linux loader has to take care of this with some additional logic. This ll be used for printk spin_lock.*/
+	/*unsigned char *lib_base_lock;*/
+	int32_t lib_base_lock;
+	
+	int coredump_support;
+
+	/*Below routine must return hard vcpu id if and only if launching is allowed on threads running loader, Otherwise return -1*/
+	uint32_t xlr_hard_vcpu_id;
+
+	/*Library can call this routine to store some data, this memory has to be persistent, next time while calling lib_load_init, implementation has to set persistent_data to this memory*/
+	int32_t xlr_get_persistent_memory;
+	int32_t xlr_free_persistent_memory;
+
+	/*If lib has ever stored anything in persistent memory then this pointer will point to that memory. Implementation need not worry about the way data is stored in to this memory, it must mmap(in case of linux loader) this memory and pass it to loader library.*/
+	int32_t persistent_data;	   
+	uint32_t persistent_data_length;
+	int32_t print;
+
+	int32_t lib_malloc;
+	int32_t lib_free;
+
+	int32_t mmap_to_kseg;
+	int32_t kseg_to_mmap;
+	int32_t lib_send_ipi;
+};
+
+/*Implementation has to fill up foll. structures with appropriate values.
+	This strucure must be defined in KSEG0 Region. Linux Loader loading applications must have to mmap this structure.
+	*Generic Bootloader: All pointers will have kseg0 address.
+	*Linux Loader: All pointers will have kseg0/kseg2 address.
+*/
+
+struct xlr_lib_launch_import
+{
+
+	/*Implementation has to set this to some kseg0 values for each cpu.*/
+	uint64_t sp[32];
+	uint64_t gp[32];
+
+	/*PreLaunchInit, Before launching any application on the kuseg/kseg "master" cpu respective routine will get call. In linux loader this ll be called frm kernel context and in generic bootloader this ll get call in context of vcpu0.
+*/
+	int32_t cb_prelaunch_init_kuseg;	
+	int32_t cb_prelaunch_init_kseg;	
+
+	/*Foll. Args will be passed to callbacks. Make sure if it is an address of any variable then it must be kseg0 address.*/
+	uint32_t kuseg_prelaunch_init_args;
+	uint32_t kseg_prelaunch_init_args;
+
+	/*Foll. is the pointer to the boot1_info, this address will be passed to the all applications (in scratch-0)*/
+	int32_t xlr_lib_boot1_info;
+
+
+	/*Pointer To Base of WakeupInfo Structure.*/
+	int32_t xlr_wakeup_info;
+	int32_t vcpu_extended_info;
+	int32_t per_cpu_info;
+	
+	uint32_t default_ebase;	
+	int32_t global_wakeup_mask;
+	int32_t loader_lock;
+
+	int32_t flush_icache_all;
+	int32_t flush_dcache_all;
+	int32_t flush_tlb_all;
+	int32_t xlr_setup_tlb;
+	int32_t xlr_hard_vcpu_id;
+	int32_t trap_init;
+	int32_t cpu_init;	
+	int32_t print;
+};
+
+struct xlr_kuseg_mem_blk
+{
+	uint64_t phys;
+	uint64_t size;
+	struct xlr_kuseg_mem_blk *next;
+};
+
+extern void xlr_start_app(void);
+extern void wakeup_cpu(uint32_t cpu, unsigned long fn, unsigned long args);
+extern void xlr_send_stop_ipi(unsigned long mask);
+extern void xlr_lib_load_init(struct xlr_lib_load_import *lib_load);
+extern void xlr_lib_launch_init(struct xlr_lib_launch_import *lib_launch);
+extern void xlr_lib_prelaunch_init_kseg(unsigned long data);
+extern int xlr_lib_stop_vcpu(unsigned long mask);
+extern void xlr_lib_load_exit(void);
+int setup_lib_env(void);
+extern int xlr_load_kuseg_app(struct xlr_lib_boot_file *file, uint32_t master, char *loadaddr,
+			      char *user_app_addr, uint32_t buddy, int override, int nargs,
+			      char **cmdline_args, char **, int );
+extern void xlr_lib_get_avail_mem(unsigned long *kuseg_mem, 
+											unsigned long *kseg_mem);
+extern uint64_t xlr_lib_reserve_shmem(uint64_t);
+extern void xlr_lib_intr_handler(int ipi);
+extern void xlr_lib_entry(unsigned long args);
+extern void reset_printk_base_lock(void);
+extern int xlr_lib_launch_userapp(int cpu);
+extern int xlr_load_kseg_app(struct xlr_lib_boot_file *file, uint32_t master, 
+					int argc,char *argv[], int nmiload);
+extern int xlr_lib_load_userapp(uint32_t cpu, int nargs, char *cmdline_args[], 						char *env_args[]);
+
+
+#endif
diff --git a/arch/mips/rmi/ptr/loader/xlr_lib_launch.c b/arch/mips/rmi/ptr/loader/xlr_lib_launch.c
new file mode 100644
index 0000000..c8c1553
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/xlr_lib_launch.c
@@ -0,0 +1,539 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+/*This is the main bootloader lib file.*/
+#include "xlr_boot_lib.h"
+
+#define Message(a,b...) //print("\n[%s]-[%d] "a"\n",__FUNCTION__,__LINE__,##b)
+
+static volatile struct xlr_vcpu_wakeup_info *xlr_vcpu_wakeup_info = NULL;
+static struct xlr_lib_psb_info *xlr_lib_boot1_info=NULL;
+static struct xlr_lib_launch_import *xlr_lib_launch = NULL;
+static void xlr_park(unsigned long args);
+static void xlr_lib_kuseg_helper(void);
+static void load_scratch_info(void);
+static void disable_ie(void);
+static void enable_ie(void);
+struct exception_region {
+	unsigned long data[1024];
+};
+
+static volatile int xlr_wakeup_ipi[XLR_NUM_CPU] = {0};
+static int loading_kseg0 = 0;
+#ifndef __STR
+#define __STR(x) #x
+#endif
+#ifndef STR
+#define STR(x) __STR(x)
+#endif
+
+
+static void (*flush_icache_all)(void);
+static void (*flush_dcache_all) (void);
+static void (*flush_tlb_all) (void);
+static void (*xlr_setup_tlb)(uint64_t, uint64_t , int );
+static int (*xlr_hard_vcpu_id)(void);
+static void (*trap_init) (void);
+static void (*cpu_init) (void);
+static int (*print)(const char *fmt, ...);
+static void (*cb_prelaunch_init_kseg)(unsigned long);
+
+static __inline__ void lib_sync(void)
+{
+	__asm__ volatile(
+		"sync\n"
+	);
+
+}
+
+static __inline__ void load_scratch_info(void)
+{
+	struct xlr_vcpu_wakeup_info *t = (struct xlr_vcpu_wakeup_info *)
+									xlr_vcpu_wakeup_info + xlr_hard_vcpu_id();
+	__asm__ volatile(
+		".set push\n"
+		".set noreorder\n"
+		".set mips64\n"	
+		"dmtc0 %0, $22, 0\n"	/* move (&boot1_info) into $22    */
+		"dmtc0 %1, $22, 1\n"	/* move (master cpu + buddy mask) into $22 */
+		"dmtc0 %2, $22, 3\n"
+		"dmtc0 %3, $22, 4\n"
+		"dmtc0 %4, $22, 5\n"
+		"dmtc0 %5, $22, 6\n"
+		"dmtc0 %6, $22, 7\n"
+	    ".set pop\n"
+		:: "r"(xlr_lib_boot1_info),"r"(xlr_lib_boot1_info->userapp_cpu_map),
+		"r"(1),"r"((int)t->argc),
+		"r"((unsigned long)t->argv),
+		"r"((unsigned long)t->envs),"r"(xlr_vcpu_wakeup_info)
+	);
+}
+
+static __inline__ void disable_ie()
+{
+	__asm__ volatile (
+		".set push     \n"
+		  ".set noreorder        \n"
+		  ".set noat             \n"
+		  "mfc0 $1, $12          \n"
+		  "ori  $1, 0x1          \n"
+		  "xori $1, 0x1          \n"
+		  "mtc0 $1, $12          \n"
+		  "nop                   \n"
+		  "nop                   \n"
+		  "nop                   \n"
+		  "nop                   \n"
+		  ".set pop              \n"
+	);
+}
+
+static __inline__ void enable_ie()
+{
+	__asm__ volatile (
+		".set push             \n"
+		  ".set noreorder        \n"
+		  ".set noat             \n"
+		  "mfc0 $1, $12          \n"
+		  "ori  $1, 0x1f         \n"
+		  "xori $1, 0x1e         \n"
+		  "mtc0 $1, $12          \n"
+		  "nop                   \n"
+		  "nop                   \n"
+		  "nop                   \n"
+		  "nop                   \n"
+		  ".set pop              \n"
+	);
+}
+
+void xlr_lib_reclaim_resources(void)
+{
+	struct xlr_vcpu_wakeup_info *t = (struct xlr_vcpu_wakeup_info *)
+                                      xlr_vcpu_wakeup_info + xlr_hard_vcpu_id();
+	t->cpu_status = CPU_WAIT_TO_RELEASE_RESOURCE;
+	lib_sync();
+
+	while(t->cpu_status != CPU_RESOURCE_RELEASED);
+
+	t->cpu_status = CPU_STOPPED;
+	lib_sync();
+}
+
+void xlr_lib_entry(unsigned long args)
+{
+	struct xlr_vcpu_wakeup_info *t = (struct xlr_vcpu_wakeup_info *)
+					xlr_vcpu_wakeup_info + xlr_hard_vcpu_id();
+
+	register unsigned long __sp asm("$29") = t->sp;
+	register unsigned long __gp asm("$28") = t->gp;
+	register unsigned long __func asm("$25") = (unsigned long) xlr_park;
+	register unsigned long __a0 asm("$4") = 0;
+	
+	__asm__ volatile(
+		".set noreorder\n"
+		"jr $25\n"
+		"nop\n"
+		".set reorder\n"
+		:
+		: "r"(__sp), "r"(__a0), "r"(__gp),"r"(__func)
+	);
+}
+
+void set_argv_envs(struct xlr_vcpu_wakeup_info *t)
+{
+	int i=0;
+	unsigned char *tmp=NULL;
+	tmp = t->argv_buf;
+
+	for(i=0;i<t->argc;i++){
+		t->argv[i] = (int32_t)(long)tmp;
+		while(*tmp != ' ' && *tmp)
+			tmp++;
+		tmp++;
+	}
+	for(;i<XLR_MAX_ARGV;i++)
+		t->argv[i] = (int32_t)(long)NULL;
+
+	tmp = t->env_buf;
+	for(i=0;i<t->env;i++){
+		t->envs[i] = (int32_t)(long)tmp;
+		while(*tmp != ' ' && *tmp)
+			tmp++;
+		tmp++;
+	}
+	for(;i<XLR_MAX_ARGV;i++)
+		t->envs[i] = (int32_t)(long)NULL;
+}
+
+void xlr_start_app(void)
+{
+	int vcpu = xlr_hard_vcpu_id();
+	struct xlr_vcpu_wakeup_info *t = (struct xlr_vcpu_wakeup_info *)
+						(xlr_vcpu_wakeup_info + vcpu);
+	unsigned long ebase = xlr_lib_launch->default_ebase;
+	volatile int i=0;
+	uint32_t *gbl_wakeup_mask = (uint32_t *)(long)t->global_wakeup_mask;
+
+	t->cpu_status = CPU_RUNNING;
+	lib_spin_lock(((lib_spinlock_t *)(long)t->loader_lock));
+	*gbl_wakeup_mask = (*gbl_wakeup_mask) & ~(1UL<<vcpu);
+	lib_spin_unlock(((lib_spinlock_t *)(long)t->loader_lock));
+	
+	flush_tlb_all();
+
+	/*Reset EBASE Value*/
+	xlr_fill_cop0_reg_32($15,1,ebase&0x3ffff000);
+	/*Reset STATUS Register*/
+	xlr_fill_cop0_reg_32($12,0,0x50000000);
+
+	/*Call Helper And Setup TLB For KUSEG Apps*/
+	if(t->mode == KUSEG_APP){
+		xlr_lib_kuseg_helper();
+	}
+	/*Set argv and envs with proper pointers.*/
+	set_argv_envs(t);
+	/*Implementation must setup all default handler @ this ebase.*/
+
+	flush_icache_all();
+	flush_dcache_all();
+	/*
+	1)Setup $22,0 with boot1_info structure. This may required for initialization process.
+	2)Setup $22,7 with "xlr_vcpu_wakeup_info" base address. Rmios lib startup routine will find the appropriate offset based on this.
+	*/
+	load_scratch_info();
+	if(!loading_kseg0)
+		for(i=0;i<10000000;i++);
+	if(t->kseg_master == 1){
+		/*Case where we are launching kseg application on vcpu not running 
+		loader, Setup all the required arguments accordingly.*/
+        __asm__ volatile(
+			".set push\n"
+			".set noreorder\n"
+			".set mips64\n"
+			"move $4, %0\n"
+			"move $5, %1\n"
+			"move $6, %2\n"
+			"move $7, %3\n"
+			"nop\n"
+			"nop\n"
+			".set reorder\n"
+			".set pop\n"
+			::"r"(t->argc),"r"(t->argv),"r"(t->envs),
+			"r"((unsigned long)xlr_lib_boot1_info)
+			:"$4","$5","$6","$7"
+        );
+	}
+	else{
+		__asm__ volatile(
+			".set push\n"
+			".set noreorder\n"
+			".set mips64\n"
+			"move $4, %0\n"
+			"move $5, %0\n"
+			"nop\n"
+			"nop\n"
+			".set reorder\n"
+			".set pop\n"
+			::"r"(t->args)
+			:"$4","$5"
+		);
+	}
+	/*Setup gp,sp and jump to the function.*/
+	
+    {
+	register unsigned long __func asm("$25") = t->func;
+    register unsigned long __sp asm("$29") = t->sp;
+    register unsigned long __gp asm("$28") = t->gp;
+    register unsigned long __rentry_func asm("$31") = (unsigned long) t->reentry_function;
+
+	__asm__ volatile(
+		".set noreorder\n\t"
+		"jr $25\n\t"
+		"nop\n\t"
+        ".set  reorder\n\t"
+		:
+		:"r"(__sp), "r"(__gp), "r"(__func), "r"(__rentry_func)
+	);
+    }
+	/*We will never come back here.*/
+}
+
+void xlr_send_stop_ipi(unsigned long mask)
+{
+/* XLP_MERGE_TODO */
+#if !defined(XLP_SIM)
+	int ipi;
+	volatile unsigned long k = 0;
+	int pid, tid;
+	xlr_lib_phnx_reg_t *mmio = xlr_lib_phnx_io_mmio(PHOENIX_IO_PIC_OFFSET);
+	volatile struct xlr_vcpu_wakeup_info *m = xlr_vcpu_wakeup_info;
+	volatile struct xlr_vcpu_wakeup_info *t = NULL;
+	volatile int i;
+
+	lib_spin_lock(((lib_spinlock_t *)(long)m->loader_lock));
+
+	/*Send stop ipi to all requested vcpus.*/
+	for(i=0; i<XLR_NUM_CPU; i++){
+		if(mask & (1U<<i)){
+			pid = i >> 2;
+			tid = i % 4;
+			ipi = (pid << 20) | (tid << 16) | IRQ_STOP_CPU_IPI ;
+			xlr_lib_phnx_write_reg(mmio, PIC_IPI, ipi);
+		}
+	}
+
+	/*wait for some time.... let cpus come back to park mode.*/
+	for(k=0;k<100000000UL;k++);
+
+	for(i=0; i<XLR_NUM_CPU; i++){
+		if(mask & (1U<<i)){
+			t = xlr_vcpu_wakeup_info + i;
+			if(t->cpu_status == CPU_STOPPED){
+				pid = i >> 2;
+				tid = i % 4;
+				ipi = (pid << 20) | (tid << 16) | IRQ_RECLAIM_CPU_RSRC_IPI;
+				xlr_lib_phnx_write_reg(mmio, PIC_IPI, ipi);
+				lib_sync();
+				/*wait till cpu comes to wait_to_release state*/
+				while(t->cpu_status != CPU_WAIT_TO_RELEASE_RESOURCE);
+			}
+		}
+	}
+
+	lib_spin_unlock(((lib_spinlock_t *)(long)m->loader_lock));
+#endif
+}
+
+void wakeup_cpu(unsigned int cpu, unsigned long fn, unsigned long args)
+{
+/* XLP_MERGE_TODO */
+
+#if !defined(XLP_SIM)
+	volatile struct xlr_vcpu_wakeup_info *t;
+	int ipi;
+	int pid = cpu >> 2;
+	int tid = cpu % 4;
+	uint32_t *gbl_wakeup_mask;
+	xlr_lib_phnx_reg_t *mmio = xlr_lib_phnx_io_mmio(PHOENIX_IO_PIC_OFFSET);
+
+	t = xlr_vcpu_wakeup_info + cpu;
+	gbl_wakeup_mask = (uint32_t *)(long)t->global_wakeup_mask;
+	lib_spin_lock(((lib_spinlock_t *)(long)t->loader_lock));
+	t = xlr_vcpu_wakeup_info + cpu;
+	t->func = fn;
+	t->args = args;
+	ipi = (pid << 20) | (tid << 16) | IRQ_WAKEUP_CPU_IPI ;
+	*gbl_wakeup_mask = (*gbl_wakeup_mask) | (1UL<<cpu);
+	xlr_lib_phnx_write_reg(mmio, PIC_IPI, ipi);
+	lib_spin_unlock(((lib_spinlock_t *)(long)t->loader_lock));
+#endif
+}
+
+static void xlr_lib_kuseg_helper(void)
+{
+	struct xlr_vcpu_wakeup_info *t = (struct xlr_vcpu_wakeup_info *)
+					xlr_vcpu_wakeup_info + xlr_hard_vcpu_id();
+	int i;
+	xlr_fill_cop0_reg_32($6,0,0);
+
+	if (!t->map_count) {
+		print("cpu_%d: No TLB mappings?\n", xlr_hard_vcpu_id());
+		return;
+	}
+	for (i = 0; i < t->map_count; i++){
+		xlr_setup_tlb((unsigned long long)t->map[i].virt 
+			      |((unsigned long long)t->map[i].asid << 32), 
+			      t->map[i].phys, t->map[i].page_size);
+	}
+	trap_init();
+}
+
+void xlr_lib_launch_init(struct xlr_lib_launch_import *lib_launch)
+{
+	int i=0;
+	struct xlr_vcpu_wakeup_info *t = NULL;
+	xlr_lib_launch = lib_launch;
+	
+	Message("");
+	/*Initialize All Callbacks*/
+	flush_icache_all = (void(*)(void))(long)(xlr_lib_launch->flush_icache_all);
+	flush_dcache_all = (void(*)(void))(long)(xlr_lib_launch->flush_dcache_all);
+	flush_tlb_all = (void(*)(void))(long)(xlr_lib_launch->flush_tlb_all);
+	xlr_setup_tlb = (void (*)(uint64_t, uint64_t , int ))
+							(long)(xlr_lib_launch->xlr_setup_tlb);
+	xlr_hard_vcpu_id = (int(*)(void))(long)(xlr_lib_launch->xlr_hard_vcpu_id);
+	trap_init = (void(*)(void))(long)(xlr_lib_launch->trap_init);
+	cpu_init = (void(*)(void))(long)(xlr_lib_launch->cpu_init);
+	print = (int (*)(const char *fmt, ...))(long)(xlr_lib_launch->print);
+	cb_prelaunch_init_kseg = (void (*)(unsigned long))
+								(long)(xlr_lib_launch->cb_prelaunch_init_kseg);
+	
+	t = (struct xlr_vcpu_wakeup_info *)(long)lib_launch->xlr_wakeup_info;
+	xlr_vcpu_wakeup_info = t;
+	xlr_lib_boot1_info = (struct xlr_lib_psb_info *)(long)
+							lib_launch->xlr_lib_boot1_info;
+	Message("");
+	memset((void *)(long)lib_launch->loader_lock,0,sizeof(t->loader_lock));
+	Message("");
+	for(i=0;i<XLR_NUM_CPU;i++){
+		t->sp = lib_launch->sp[i];
+		t->gp = lib_launch->gp[i];
+		t->global_wakeup_mask = lib_launch->global_wakeup_mask;
+		t->loader_lock = lib_launch->loader_lock;
+		t++;
+	}
+	Message("");
+}
+
+int xlr_lib_launch_userapp(int cpu)
+{
+	struct xlr_vcpu_wakeup_info *t = (struct xlr_vcpu_wakeup_info *)
+					xlr_vcpu_wakeup_info + cpu;
+
+	loading_kseg0 = 1;
+
+	if(cb_prelaunch_init_kseg)
+		cb_prelaunch_init_kseg(xlr_lib_launch->kseg_prelaunch_init_args);
+
+	t->cpu_status = CPU_RUNNING;
+
+	if(cpu != xlr_hard_vcpu_id()){
+		t->kseg_master = 1;
+		wakeup_cpu(cpu,t->func,t->args);
+		return 0;
+	}
+	flush_tlb_all();
+	load_scratch_info();
+	__asm__ volatile(
+		".set push\n"
+		".set noreorder\n"
+		".set mips64\n"
+		"move $29, %0\n"
+		"move $28, %1\n"
+		"nop\n"
+		".set reorder\n"
+		".set pop\n"
+		::"r"(t->sp), "r"(t->gp)
+	);
+	((void (*)(int, char *, char *, uint64_t))(long)t->func)
+			(t->argc,(char *)t->argv,(char *)t->envs,
+			 (unsigned long)xlr_lib_boot1_info);
+	/*We will never come back here.*/
+	return 0;	
+}
+
+void xlr_lib_intr_handler(int irq)
+{
+	int cpu = xlr_hard_vcpu_id();
+	switch(irq){
+		case IRQ_WAKEUP_CPU_IPI:
+			xlr_wakeup_ipi[cpu] = 1;
+			break;
+		case IRQ_STOP_CPU_IPI:
+			reset_printk_base_lock();
+			__asm__ __volatile__(
+				"mtc0 %0, $14\n"
+				"nop\n"
+				"eret\n"
+				"nop\n"
+				::"r"(xlr_lib_entry)
+			);
+			break;
+		case IRQ_RECLAIM_CPU_RSRC_IPI:
+			xlr_lib_reclaim_resources();
+			break;
+		default:
+			print("Lib Doesnt support Interupt %d\n",irq);
+			break;
+	}
+	return;
+}
+
+static void xlr_park(unsigned long args)
+{
+	uint64_t new_mask = (1ULL<<IRQ_WAKEUP_CPU_IPI) | (1ULL<<IRQ_STOP_CPU_IPI)
+						|(1ULL<<IRQ_RECLAIM_CPU_RSRC_IPI);
+	uint64_t old_mask = (1ULL<<4);
+	volatile struct xlr_vcpu_wakeup_info *t;
+	volatile struct xlr_vcpu_wakeup_info *master;
+	int cpu = xlr_hard_vcpu_id();
+
+	/*Dont Read EIMR and or with newmask, we may come here from rmios 
+	applications, which may have all interrupts enabled, here we have to 
+	reset all interrupts except wakeup/stop ipi.*/
+
+	new_mask = new_mask | old_mask;
+	cpu_init();
+
+	/*Set Proper Status Reg Value.*/
+	t = (struct xlr_vcpu_wakeup_info *)xlr_vcpu_wakeup_info + cpu;
+	t->reentry_function = (int32_t)(long)xlr_lib_entry;
+	t->reentry_args = cpu;
+	disable_ie();
+	trap_init();
+	/*clear any pending interrupts in eirr.*/
+	xlr_fill_cop0_reg_64($9, 6, ~0x0);
+	/*setup a new eimr mask*/
+	xlr_fill_cop0_reg_64($9,7,new_mask);
+	t->cpu_status = CPU_STOPPED;
+	lib_sync();
+
+	enable_ie();
+	while(!xlr_wakeup_ipi[cpu])
+		__asm__ volatile(
+			".set noreorder\n"
+			"wait\n"
+			".set reorder\n"	
+		);
+	disable_ie();
+	xlr_wakeup_ipi[cpu] = 0;
+	/*Continue if this cpu is a master*/
+	if(t->master_cpu != cpu){
+		/*check if this is still a valid buddy!!*/
+		master = (struct xlr_vcpu_wakeup_info *)
+		xlr_vcpu_wakeup_info + t->master_cpu;
+		if(!(master->buddy_mask & (1<<cpu))){
+			/*this cpu is just stopped*/
+			xlr_lib_entry(0UL);
+		}
+	}
+	xlr_fill_cop0_reg_64($9,6,0xfffffffffffffffcULL);
+	xlr_fill_cop0_reg_64($9,7,old_mask);
+	xlr_start_app();
+}
+
+void reset_printk_base_lock(void)
+{
+	struct xlr_vcpu_wakeup_info *t = (struct xlr_vcpu_wakeup_info *)
+					xlr_vcpu_wakeup_info + xlr_hard_vcpu_id();
+	uint32_t *ptr = (uint32_t *)(long)t->printk_lock;
+
+	if(*ptr ==  (xlr_hard_vcpu_id()+1))
+		*ptr = 0;
+}
diff --git a/arch/mips/rmi/ptr/loader/xlr_lib_platform.h b/arch/mips/rmi/ptr/loader/xlr_lib_platform.h
new file mode 100644
index 0000000..3cdd33c
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/xlr_lib_platform.h
@@ -0,0 +1,93 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_2#**********************************/
+
+#ifndef __XLR_LIB_PLATEFORM_H
+#define __XLR_LIB_PLATEFORM_H
+
+#include <linux/types.h>/*All kind of type conversions.*/
+#include <asm/rmi/phnx_loader.h> /*psb_mem_map structure*/
+#include <asm/rmi/sim.h>/*boot1_info*/
+#include <asm/rmi/iomap.h>/*PHOENIX_IO_PIC_OFFSET*/
+#include <asm/rmi/pic.h>/*PIC Offset*/
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include "xlr_boot_lib.h"
+
+#define xlr_lib_psb_mem_map psb_mem_map
+#define xlr_lib_psb_info psb_info
+#define xlr_lib_phnx_io_mmio(offset) phoenix_io_mmio(offset)
+#define xlr_lib_phnx_write_reg(base,offset,val) phoenix_write_reg(base,offset,val)
+#define xlr_lib_phnx_read_reg(base,offset) phoenix_read_reg(base,offset)
+
+#define xlr_fill_cop0_reg_32(reg,sel,value) 	\
+				__asm__ __volatile__(\
+					".set\tpush\n\t"\
+					".set mips32\n\t"\
+					"mtc0\t%0,"STR(reg)", %1\n\t"\
+					".set\tpop"\
+					:: "r" (value), "i" (sel) );
+
+#define xlr_fill_cop0_reg_64(source,sel,val) __write_64bit_c0_register(source,sel,val)
+
+struct xlr_lib_boot_file{
+        char *name;
+        unsigned char *start;
+        int size;
+        unsigned int max_size;
+        int valid;
+};
+
+static __inline__ void lib_spin_lock(lib_spinlock_t *lock)
+{
+	unsigned int tmp;
+
+	__asm__ __volatile__(
+	    ".set\tnoreorder\t\t\t# spin_lock\n"
+	    "1:\tll\t%1, %2\n\t"
+	    "bnez\t%1, 1b\n\t"
+	    " li\t%1, 1\n\t"
+	    "sc\t%1, %0\n\t"
+	    "beqz\t%1, 1b\n\t"
+	    " sync\n\t"
+	    ".set\treorder"
+	    : "=m" (lock->lock), "=&r" (tmp)
+	    : "m" (lock->lock)
+	    : "memory");
+}
+
+static __inline__ void lib_spin_unlock(lib_spinlock_t *lock)
+{
+	__asm__ __volatile__(
+	    ".set\tnoreorder\t\t\t# spin_unlock\n\t"
+	    "sync\n\t"
+	    "sw\t$0, %0\n\t"
+	    ".set\treorder"
+	    : "=m" (lock->lock)
+	    : "m" (lock->lock)
+	    : "memory");
+}
+
+
+#endif
diff --git a/arch/mips/rmi/ptr/loader/xlr_rmios_stackframe.h b/arch/mips/rmi/ptr/loader/xlr_rmios_stackframe.h
new file mode 100644
index 0000000..244acdc
--- /dev/null
+++ b/arch/mips/rmi/ptr/loader/xlr_rmios_stackframe.h
@@ -0,0 +1,190 @@
+/***********************************************************************
+Copyright 2003-2006 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+#ifndef __RMIOS_STACKFRAME_H__
+#define __RMIOS_STACKFRAME_H__
+
+#include <asm/regdef.h>
+#include <asm/asm.h>
+#include <asm/types.h>
+
+
+#define COP_0_STATUS      $12
+#define COP_0_CAUSE       $13
+#define COP_0_EPC         $14
+
+#define STACK_OFF_R0  		    48
+#define STACK_OFF_R1     	    56
+#define STACK_OFF_R2     	    64
+#define STACK_OFF_R3     	    72
+#define STACK_OFF_R4     	    80
+#define STACK_OFF_R5     	    88
+#define STACK_OFF_R6     	    96
+#define STACK_OFF_R7     	   104
+#define STACK_OFF_R8     	   112
+#define STACK_OFF_R9     	   120
+#define STACK_OFF_R10    	   128
+#define STACK_OFF_R11    	   136
+#define STACK_OFF_R12    	   144
+#define STACK_OFF_R13    	   152
+#define STACK_OFF_R14    	   160
+#define STACK_OFF_R15    	   168
+#define STACK_OFF_R16    	   176
+#define STACK_OFF_R17    	   184
+#define STACK_OFF_R18    	   192
+#define STACK_OFF_R19    	   200
+#define STACK_OFF_R20    	   208
+#define STACK_OFF_R21    	   216
+#define STACK_OFF_R22    	   224
+#define STACK_OFF_R23    	   232
+#define STACK_OFF_R24    	   240
+#define STACK_OFF_R25    	   248
+#define STACK_OFF_R26    	   256
+#define STACK_OFF_R27    	   264
+#define STACK_OFF_R28    	   272
+#define STACK_OFF_R29    	   280
+#define STACK_OFF_R30    	   288
+#define STACK_OFF_R31    	   296
+
+#define STACK_OFF_STATUS 	   304
+#define STACK_OFF_HI     	   312
+#define STACK_OFF_LO     	   320
+
+#define STACK_OFF_BVADDR 	   328
+#define STACK_OFF_CAUSE  	   336
+#define STACK_OFF_EPC    	   344
+
+#define K_STACK_SIZE   	           352
+
+
+#define save_stack_frame           \
+	.set push;                 \
+	.set noat;                 \
+	.set reorder;              \
+	move	k1, sp;            \
+        move	k0, sp;            \
+	dsubu	sp, k1, K_STACK_SIZE;     \
+	sd	k0, STACK_OFF_R29(sp);	  \
+        sd	$3, STACK_OFF_R3(sp);	  \
+	sd	$0, STACK_OFF_R0(sp);	  \
+	dmfc0	v1, COP_0_STATUS;         \
+	sd	$2, STACK_OFF_R2(sp);	  \
+	sd	v1, STACK_OFF_STATUS(sp); \
+	sd	$4, STACK_OFF_R4(sp);	  \
+	dmfc0	v1, COP_0_CAUSE;          \
+	sd	$5, STACK_OFF_R5(sp);	  \
+	sd	v1, STACK_OFF_CAUSE(sp);  \
+	sd	$6, STACK_OFF_R6(sp);	  \
+	dmfc0	v1, COP_0_EPC;            \
+	sd	$7, STACK_OFF_R7(sp);	  \
+	sd	v1, STACK_OFF_EPC(sp);	  \
+	sd	$25, STACK_OFF_R25(sp);   \
+	sd	$28, STACK_OFF_R28(sp);   \
+	sd	$31, STACK_OFF_R31(sp);   \
+	ori	$28, sp, 0x1fff;          \
+	xori	$28, 0x1fff;              \
+	sd	$1, STACK_OFF_R1(sp);	  \
+	mfhi	v1;		          \
+	sd	$8, STACK_OFF_R8(sp);	  \
+	sd	$9, STACK_OFF_R9(sp);	  \
+	sd	v1, STACK_OFF_HI(sp);	  \
+	mflo	v1;		          \
+	sd	$10,STACK_OFF_R10(sp);	  \
+	sd	$11, STACK_OFF_R11(sp);   \
+	sd	v1,  STACK_OFF_LO(sp);	  \
+	sd	$12, STACK_OFF_R12(sp);   \
+	sd	$13, STACK_OFF_R13(sp);   \
+	sd	$14, STACK_OFF_R14(sp);   \
+	sd	$15, STACK_OFF_R15(sp);   \
+	sd	$24, STACK_OFF_R24(sp);   \
+	sd	$16, STACK_OFF_R16(sp);   \
+	sd	$17, STACK_OFF_R17(sp);   \
+	sd	$18, STACK_OFF_R18(sp);   \
+	sd	$19, STACK_OFF_R19(sp);   \
+	sd	$20, STACK_OFF_R20(sp);   \
+	sd	$21, STACK_OFF_R21(sp);   \
+	sd	$22, STACK_OFF_R22(sp);   \
+	sd	$23, STACK_OFF_R23(sp);   \
+	sd	$30, STACK_OFF_R30(sp);   \
+.set pop;			   
+
+#define restore_stack_frame                  \
+	.set	push;		             \
+	.set    noat;                        \
+	.set	reorder;	             \
+	mfc0	t0, COP_0_STATUS;            \
+	ori	t0, 0x1f;	             \
+	xori	t0, 0x1f;	             \
+	mtc0	t0, COP_0_STATUS;            \
+	li	v1, 0xff00;	             \
+	and	t0, v1;		             \
+	ld	v0, STACK_OFF_STATUS(sp);    \
+	nor	v1, $0, v1;	             \
+	and	v0, v1;		             \
+	or	v0, t0;		             \
+	mtc0	v0, COP_0_STATUS;            \
+	ld	v1, STACK_OFF_EPC(sp);	     \
+	mtc0	v1, COP_0_EPC;	             \
+	ld	$31, STACK_OFF_R31(sp);      \
+	ld	$28, STACK_OFF_R28(sp);      \
+	ld	$25, STACK_OFF_R25(sp);      \
+	ld	$7,  STACK_OFF_R7(sp);	     \
+	ld	$6,  STACK_OFF_R6(sp);	     \
+	ld	$5,  STACK_OFF_R5(sp);	     \
+	ld	$4,  STACK_OFF_R4(sp);	     \
+	ld	$3,  STACK_OFF_R3(sp);	     \
+	ld	$2,  STACK_OFF_R2(sp);	     \
+	ld	$1,  STACK_OFF_R1(sp);       \
+	ld	$24, STACK_OFF_LO(sp);	     \
+	ld	$8, STACK_OFF_R8(sp);	     \
+	ld	$9, STACK_OFF_R9(sp);	     \
+	mtlo	$24;		             \
+	ld	$24, STACK_OFF_HI(sp);	     \
+	ld	$10,STACK_OFF_R10(sp);	     \
+	ld	$11, STACK_OFF_R11(sp);      \
+	mthi	$24;		             \
+	ld	$12, STACK_OFF_R12(sp);      \
+	ld	$13, STACK_OFF_R13(sp);      \
+	ld	$14, STACK_OFF_R14(sp);      \
+	ld	$15, STACK_OFF_R15(sp);      \
+	ld	$24, STACK_OFF_R24(sp);      \
+	ld	$16, STACK_OFF_R16(sp);      \
+	ld	$17, STACK_OFF_R17(sp);      \
+	ld	$18, STACK_OFF_R18(sp);      \
+	ld	$19, STACK_OFF_R19(sp);      \
+	ld	$20, STACK_OFF_R20(sp);      \
+	ld	$21, STACK_OFF_R21(sp);      \
+	ld	$22, STACK_OFF_R22(sp);      \
+	ld	$23, STACK_OFF_R23(sp);      \
+	ld	$30, STACK_OFF_R30(sp);      \
+	ld	sp,  STACK_OFF_R29(sp);      \
+.set pop;			   
+
+#endif
diff --git a/arch/mips/rmi/ptr/nmi.S b/arch/mips/rmi/ptr/nmi.S
new file mode 100644
index 0000000..0e6aa82
--- /dev/null
+++ b/arch/mips/rmi/ptr/nmi.S
@@ -0,0 +1,80 @@
+#include <linux/init.h>
+
+#include <asm/asm.h>
+#include <asm/asmmacro.h>
+#include <asm/cacheops.h>
+#include <asm/irqflags.h>
+#include <asm/regdef.h>
+#include <asm/fpregdef.h>
+#include <asm/mipsregs.h>
+#include <asm/stackframe.h>
+#include <asm/war.h>
+#include <asm/page.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/interrupt.h>
+
+
+NESTED(rmi_except_vec_nmi, 0, sp)
+	.set push
+	.set noat
+	.set mips64
+	.set noreorder
+	MTC0	k0, OS_KGDB_SCRATCH_REG6
+	nop
+	nop
+	PTR_LA	k0, rmi_nmi_handler
+	jr       k0
+	nop
+	.set pop
+END(rmi_except_vec_nmi)
+
+
+	/* This nmi handler is currently only for taking oprofile samples
+	   on non-zero cpus
+	   */
+NESTED(rmi_nmi_handler, PT_SIZE,  sp)
+	.set	push
+	.set	noat
+	.set noreorder
+	.set 	mips64
+
+	/* Save K0 and K1 first */
+	/* K0 is already saved in rmi_except_vec_nmi */
+	MTC0	k1, OS_KGDB_SCRATCH_REG7
+	
+	/* Clear the  NMI and BEV bits */
+	MFC0	k0, CP0_STATUS
+	li 	k1, 0xffb7ffff
+	and	k0, k0, k1
+	MTC0	k0, CP0_STATUS
+
+	SAVE_ALL
+	CLI
+	TRACE_IRQS_OFF
+
+	li	a0, IRQ_IPI_SMP_KGDB
+	move	a1, sp
+	/* jal	do_phnx_IRQ */
+	/* nop */
+	jal	rmi_kgdb_call_nmi_hook
+	nop
+
+	RESTORE_ALL
+
+	/*
+	MFC0 	k0, $15, 1
+	andi	k0, 0x1f
+	sll	k0, 2
+	la	k1, rmi_cpus_in_nmi
+ 	PTR_ADDU	k1, k0
+	sw	zero, 0(k1)
+	*/
+
+	MFC0	k0, OS_KGDB_SCRATCH_REG6
+	MFC0	k1, OS_KGDB_SCRATCH_REG7
+	
+	.set mips3
+	eret
+
+	.set pop
+END(rmi_nmi_handler)
diff --git a/arch/mips/rmi/ptr/platform-xlp.c b/arch/mips/rmi/ptr/platform-xlp.c
new file mode 100644
index 0000000..3d56c2e
--- /dev/null
+++ b/arch/mips/rmi/ptr/platform-xlp.c
@@ -0,0 +1,294 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/dma-mapping.h>
+#include <linux/init.h>
+#include <linux/platform_device.h>
+#include <linux/serial.h>
+#include <linux/serial_8250.h>
+#include <linux/pci.h>
+
+#include <asm/time.h>
+#include <asm/rmi/xlp_common/xlp_macros.h>
+
+#define XLP_SOC_PCI_DRIVER "XLP SoC Driver"
+
+#define PCI_NETL_VENDOR             0x184E
+
+#define PCI_DEVID_DEFAULT           0x1000
+#define PCI_DEVID_BASE              (PCI_DEVID_DEFAULT + 0x00)
+
+#define PCI_DEVID_OFF_SBU           0x01
+#define PCI_DEVID_OFF_ICI           0x02
+#define PCI_DEVID_OFF_PIC           0x03
+#define PCI_DEVID_OFF_PCIE          0x04
+#define PCI_DEVID_OFF_CAM           0x05
+#define PCI_DEVID_OFF_USB           0x06
+#define PCI_DEVID_OFF_EHCI          0x07
+#define PCI_DEVID_OFF_OHCI          0x08
+#define PCI_DEVID_OFF_NET           0x09
+
+#define PCI_DEVID_OFF_POE           0x0A
+#define PCI_DEVID_OFF_MSG           0x0B
+#define PCI_DEVID_OFF_GDX           0x0C
+#define PCI_DEVID_OFF_SEC           0x0D
+#define PCI_DEVID_OFF_RSA           0x0E
+#define PCI_DEVID_OFF_CMP           0x0F
+
+#define PCI_DEVID_OFF_UART          0x10
+#define PCI_DEVID_OFF_I2C           0x11
+#define PCI_DEVID_OFF_GPIO          0x12
+#define PCI_DEVID_OFF_SYS           0x13
+#define PCI_DEVID_OFF_JTAG          0x14
+#define PCI_DEVID_OFF_NOR           0x15
+#define PCI_DEVID_OFF_NAND          0x16
+#define PCI_DEVID_OFF_SPI           0x17
+#define PCI_DEVID_OFF_MMC           0x18
+#define PCI_DEVID_OFF_LAST          0x19
+
+#define PCI_MAX_DEVICES             (PCI_DEVID_OFF_LAST + 1)
+
+#define UART_CLK 133333333
+
+#define MAX_NUM_UARTS 3
+
+struct soc_dev {
+	const char *name;
+	void (*probe)(struct pci_dev *pdev, unsigned long pci_cfg_dev_base);
+};
+
+const char *pci_cfg_dev_regs[16] = {
+	[0] = "Dev Info 0",
+	[1] = "Dev Info 1",
+	[2] = "Dev Info 2",
+	[3] = "Dev Info 3",
+	[4] = "Dev Info 4",
+	[5] = "Dev Info 5",
+	[6] = "Dev Info 6",
+	[7] = "Dev Info 7",
+	[8] = "Dev Scratch 0",
+	[9] = "Dev Scratch 1",
+	[10] = "Dev Scratch 2",
+	[11] = "Dev Scratch 3",
+	[12] = "Dev Msg Stn Info",
+	[13] = "Dev IRT Info",
+	[14] = "uCode Engine Info",
+	[15] = "SBB BW Weight Entry Info"
+};
+
+static struct pci_device_id soc_pci_table[PCI_MAX_DEVICES] __devinitdata;
+
+static struct plat_serial8250_port uart_ports[MAX_NUM_UARTS] = {
+	[MAX_NUM_UARTS - 1] = { .flags = 0 } /* terminating condition */
+};
+
+static void nlmc_hal_pci_cfg(int devfn, unsigned long pci_cfg_dev_base)
+{
+	int i = 0;
+	unsigned int *cfg_base = (unsigned int *)pci_cfg_dev_base;
+
+	cfg_base += (0xC0 >> 2);
+	for (i = 0; i < 16; i++) {
+		unsigned int value = cfg_base[i];
+
+		if (!value) continue;
+/* 		printk("[%s]: reg[%s] = %08x\n", __FUNCTION__, pci_cfg_dev_regs[i], value); */
+	}
+}
+
+static void xlp_sbu_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+}
+
+static void xlp_pic_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+}
+
+static void xlp_cms_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+}
+
+static void xlp_sys_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+}
+
+static void xlp_default_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+}
+
+static void xlp_uart_probe(struct pci_dev *pdev, unsigned long pci_cfg_dev_base)
+{
+	static atomic_t num_uarts = ATOMIC_INIT(0);
+	int instance = atomic_inc_return(&num_uarts) - 1;
+
+	if (instance < 0 || instance >= (MAX_NUM_UARTS - 1)) {
+		printk("Request for Invalid uart port_%d\n", instance);
+		return ;
+	}
+
+ 	if (!instance) {
+		struct platform_device *uart = 0;
+
+		/* If this is the first instance of registration, create the platform device */
+
+		uart = platform_device_alloc("serial8250", PLAT8250_DEV_PLATFORM);
+		if (!uart) {
+			printk("Unable to allocate memory for UART platform device!\n");
+			return;
+		}
+
+		uart->dev.platform_data = &uart_ports[0];
+
+		if (platform_device_add(uart)) {
+			printk("Unable to register uart plaform device!\n");
+			return;
+		}
+		printk("Platform registered UART device\n");
+	}
+
+	uart_ports[instance].mapbase       = pci_cfg_dev_base + 0x100; /* skip PCI CFG header */
+	uart_ports[instance].membase       = (void __iomem *)uart_ports[instance].mapbase;
+	uart_ports[instance].irq           = PIC_UART_0_IRQ + instance;
+
+	uart_ports[instance].uartclk       = UART_CLK;
+	uart_ports[instance].iotype        = UPIO_MEM;
+	uart_ports[instance].flags         = ASYNC_BOOT_AUTOCONF | ASYNC_SKIP_TEST;
+	uart_ports[instance].type          = UPIO_PORT;
+	uart_ports[instance].regshift      = 2;
+
+	printk("Platform added UART port_%d (irq=%d, @%lx)\n", instance,
+	       uart_ports[instance].irq, (unsigned long)uart_ports[instance].mapbase);
+
+	nlmc_hal_pci_cfg(pdev->devfn, pci_cfg_dev_base);
+}
+
+static struct soc_dev soc_devices[PCI_MAX_DEVICES] = {
+	[PCI_DEVID_OFF_SBU]  = {.name = "South Bridge",                      .probe = xlp_sbu_probe},
+	[PCI_DEVID_OFF_PIC]  = {.name = "Programmable Interrupt Controller", .probe = xlp_pic_probe},
+	[PCI_DEVID_OFF_MSG]  = {.name = "Central Messaging Station",         .probe = xlp_cms_probe},
+	[PCI_DEVID_OFF_UART] = {.name = "UART",                              .probe = xlp_uart_probe},
+	[PCI_DEVID_OFF_SYS]  = {.name = "Sys",                               .probe = xlp_sys_probe},
+};
+
+static int __devinit soc_device_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
+{
+	unsigned long mmio_paddr = 0, mmio_size = 0;
+	void *mmio_vaddr = 0;
+	int irq;
+	int result;
+	int base_class, sub_class, prog_int;
+	int dev = (pdev->devfn >> 3) & 0x1f;
+
+	int dev_off = pdev->device - PCI_DEVID_BASE;
+	void (*probe)(struct pci_dev *, unsigned long);
+
+	int fn = (pdev->devfn & 0x7);
+	const int num_fns = 8;
+	const int pci_cfg_size = 0x1000;
+	unsigned long pci_cfg_dev_base = (unsigned long)(xlp_io_base + (dev * num_fns * pci_cfg_size)
+							 + (fn * pci_cfg_size));
+
+	base_class = (pdev->class >> 16) & 0xff;
+	sub_class = (pdev->class >> 8) & 0xff;
+	prog_int = (pdev->class >> 0) & 0xff;
+
+	result = pci_enable_device(pdev);
+	if (result) return result;
+
+	mmio_paddr = pci_resource_start(pdev, 0);
+	mmio_size = pci_resource_len(pdev, 0);
+	irq = pdev->irq;
+
+	if (mmio_paddr) {
+		result = pci_request_regions(pdev, XLP_SOC_PCI_DRIVER);
+		if (result) {
+			printk("[%s]: unable to pci_request_regions\n", __FUNCTION__);
+			return result;
+		}
+
+		mmio_vaddr = ioremap(mmio_paddr, mmio_size);
+		if (!mmio_vaddr) {
+			printk("[%s]: unable to ioremap\n", __FUNCTION__);
+			pci_release_regions(pdev);
+			return 1;
+		}
+	}
+
+	probe = soc_devices[dev_off].probe;
+	if (!probe) {
+		printk("No probe handler found for XLP device \"%s\"\n", soc_devices[dev_off].name);
+	}
+	else {
+		printk("Invoking probe handler for XLP device \"%s\"\n", soc_devices[dev_off].name);
+		probe(pdev, pci_cfg_dev_base);
+	}
+
+	return 0;
+}
+
+static struct pci_driver soc_driver = {
+	.name             = XLP_SOC_PCI_DRIVER,
+	.id_table         = soc_pci_table,
+	.probe            = soc_device_probe,
+};
+
+static int __init soc_device_init(void)
+{
+	int i = 0;
+
+	for (i = 0; i < PCI_MAX_DEVICES; i++) {
+		soc_pci_table[i].vendor        = PCI_NETL_VENDOR;
+		soc_pci_table[i].device        = PCI_DEVID_BASE + i;
+		soc_pci_table[i].subvendor     = PCI_ANY_ID;
+		soc_pci_table[i].subdevice        = PCI_ANY_ID;
+		soc_pci_table[i].driver_data   = 0;
+
+		if (soc_devices[i].name) continue;
+		soc_devices[i].name = "unrecognized";
+		soc_devices[i].probe = xlp_default_probe;
+	}
+	soc_pci_table[PCI_DEVID_OFF_LAST].vendor        = 0;
+	soc_pci_table[PCI_DEVID_OFF_LAST].device        = 0;
+	soc_pci_table[PCI_DEVID_OFF_LAST].subvendor     = 0;
+	soc_pci_table[PCI_DEVID_OFF_LAST].subdevice     = 0;
+	soc_pci_table[PCI_DEVID_OFF_LAST].driver_data   = 0;
+
+	return pci_register_driver(&soc_driver);
+}
+
+static void __init soc_device_exit(void)
+{
+	pci_unregister_driver(&soc_driver);
+}
+
+module_init(soc_device_init);
+module_exit(soc_device_exit);
+
+MODULE_DEVICE_TABLE(pci, soc_pci_table);
diff --git a/arch/mips/rmi/ptr/platform.c b/arch/mips/rmi/ptr/platform.c
new file mode 100644
index 0000000..6a05539
--- /dev/null
+++ b/arch/mips/rmi/ptr/platform.c
@@ -0,0 +1,245 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/dma-mapping.h>
+#include <linux/init.h>
+#include <linux/platform_device.h>
+#include <linux/serial.h>
+#include <linux/serial_8250.h>
+#include <linux/pci.h>
+
+#include <asm/time.h>
+#include <asm/rmi/xlp_common/xlp_macros.h>
+
+#ifdef CONFIG_RMI_XLR
+/* don't enable IDE for now, as it is faster to boot up XLR simulator */
+/* #define ENABLE_IDE */
+#define UART_CLK 66666666
+#else
+#define UART_CLK 133333333
+#endif
+
+#ifdef ENABLE_IDE
+static u64 ide_dmamask = DMA_BIT_MASK(32);
+
+static struct platform_device ide_device = {
+	.name		= "phoenix-pcmcia",
+	.id		= 0,
+	.dev = {
+		.dma_mask 		= &ide_dmamask,
+		.coherent_dma_mask	= DMA_BIT_MASK(32),
+	},
+};
+#endif
+
+static struct plat_serial8250_port uart8250_data[] = {
+	{
+		.mapbase	= (DEFAULT_PHOENIX_IO_BASE+PHOENIX_IO_UART_0_OFFSET),
+		.membase	= (unsigned char __iomem *)(DEFAULT_PHOENIX_IO_BASE+PHOENIX_IO_UART_0_OFFSET),
+		.irq		= 17,
+		.uartclk        = UART_CLK,
+		.iotype		= UPIO_MEM,
+		.flags		= ASYNC_BOOT_AUTOCONF | ASYNC_SKIP_TEST,
+		.type           = UPIO_PORT,
+		.regshift	= 2,
+	},
+	{
+		.mapbase	=  (DEFAULT_PHOENIX_IO_BASE+PHOENIX_IO_UART_1_OFFSET),
+		.membase	= (unsigned char __iomem *)(DEFAULT_PHOENIX_IO_BASE+PHOENIX_IO_UART_1_OFFSET),
+		.irq		= 18,
+		.uartclk        = UART_CLK,
+		.iotype		= UPIO_MEM,
+		.flags		= ASYNC_BOOT_AUTOCONF | ASYNC_SKIP_TEST,
+		.type           = UPIO_PORT,
+		.regshift	= 2,
+	},
+	{ },
+};
+
+static struct platform_device uart_device = {
+	.name			= "serial8250",
+	.id			= PLAT8250_DEV_PLATFORM,
+	.dev			= {
+		.platform_data	= uart8250_data,
+	},
+};
+
+static struct platform_device *board_platform_devices[] __initdata = {
+	&uart_device,
+#ifdef ENABLE_IDE
+	&ide_device,
+#endif
+};
+
+static int __init board_register_devices(void)
+{
+	return platform_add_devices(board_platform_devices,
+				    ARRAY_SIZE(board_platform_devices));
+}
+
+arch_initcall(board_register_devices);
+
+static struct pci_device_id soc_device_table[] __devinitdata = {
+	{ .vendor = 0x182e, .device = 0x1001, .subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID,
+	  .class = 0, .class_mask = 0, .driver_data = 0,
+	},
+	{ .vendor = 0x182e, .device = 0x1003, .subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID,
+	  .class = 0, .class_mask = 0, .driver_data = 0,
+	},
+	{ .vendor = 0x182e, .device = 0x100b, .subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID,
+	  .class = 0, .class_mask = 0, .driver_data = 0,
+	},
+	{ .vendor = 0x182e, .device = 0x1010, .subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID,
+	  .class = 0, .class_mask = 0, .driver_data = 0,
+	},
+	{ .vendor = 0x182e, .device = 0x1013, .subvendor = PCI_ANY_ID, .subdevice = PCI_ANY_ID,
+	  .class = 0, .class_mask = 0, .driver_data = 0,
+	},
+	{} /* terminate list */
+};
+
+MODULE_DEVICE_TABLE(pci, soc_device_table);
+
+#define XLP_SOC_PCI_DRIVER "XLP SoC Driver"
+const char *pci_cfg_dev_regs[16] = {
+	[(0xC0 - 0xC0) >> 2] = "Dev Info 0",
+	[(0xC4 - 0xC0) >> 2] = "Dev Info 1",
+	[(0xC8 - 0xC0) >> 2] = "Dev Info 2",
+	[(0xCC - 0xC0) >> 2] = "Dev Info 3",
+	[(0xD0 - 0xC0) >> 2] = "Dev Info 4",
+	[(0xD4 - 0xC0) >> 2] = "Dev Info 5",
+	[(0xD8 - 0xC0) >> 2] = "Dev Info 6",
+	[(0xDC - 0xC0) >> 2] = "Dev Info 7",
+	[(0xE0 - 0xC0) >> 2] = "Dev Scratch 0",
+	[(0xE4 - 0xC0) >> 2] = "Dev Scratch 1",
+	[(0xE8 - 0xC0) >> 2] = "Dev Scratch 2",
+	[(0xEC - 0xC0) >> 2] = "Dev Scratch 3",
+	[(0xF0 - 0xC0) >> 2] = "Dev Msg Stn Info",
+	[(0xF4 - 0xC0) >> 2] = "Dev IRT Info",
+	[(0xF8 - 0xC0) >> 2] = "uCode Engine Info",
+	[(0xFC - 0xC0) >> 2] = "SBB BW Weight Entry Info"
+};
+
+static void nlmc_hal_pci_cfg(int dev, int fn)
+{
+	const int num_fns = 8;
+	const int pci_cfg_size = 0x1000;
+	__u64 pci_cfg_base = xlp_io_base;
+	unsigned int *cfg_base = (unsigned int *)(pci_cfg_base + (dev * num_fns * pci_cfg_size)
+						    + (fn * pci_cfg_size));
+	const int reg_base = 0xC0 >> 2;
+	int i = 0;
+
+	printk("[%s] cfg_base = %p, xlp_io_base=%p, dev=%d, fn=%d\n", __FUNCTION__,
+	       cfg_base, (unsigned char *)pci_cfg_base, dev, fn);
+
+	for (i = 0; i < 16; i++) {
+		int reg = reg_base + i;
+		unsigned int value = cfg_base[reg];
+
+		if (value) {
+			printk("[%s]: reg[%s]@%p = %08x\n", __FUNCTION__, pci_cfg_dev_regs[reg],
+			       &cfg_base[reg], value);
+		}
+	}
+}
+
+static int __devinit soc_device_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
+{
+	unsigned long mmio_paddr = 0, mmio_size = 0;
+	void *mmio_vaddr = 0;
+	int irq;
+	int result;
+	int base_class, sub_class, prog_int;
+	int dev = (pdev->devfn >> 3) & 0x1f;
+	int fn = (pdev->devfn & 0x7);
+
+	base_class = (pdev->class >> 16) & 0xff;
+	sub_class = (pdev->class >> 8) & 0xff;
+	prog_int = (pdev->class >> 0) & 0xff;
+
+	if (base_class == 7 && sub_class == 0 && prog_int == 2) {
+		printk("[%s]: Found a 16550 UART device\n", __FUNCTION__);
+	}
+	else if (base_class == 8 && sub_class == 0) {
+		printk("[%s]: Found PIC \n", __FUNCTION__);
+	}
+	else {
+		printk("[%s]: Found unrecognized XLP SoC device (%x.%x.%x!)\n", __FUNCTION__,
+		       base_class, sub_class, prog_int);
+	}
+
+	nlmc_hal_pci_cfg(dev, fn);
+
+	result = pci_enable_device(pdev);
+	if (result) return result;
+
+	mmio_paddr = pci_resource_start(pdev, 0);
+	mmio_size = pci_resource_len(pdev, 0);
+	irq = pdev->irq;
+
+	if (mmio_paddr) {
+		result = pci_request_regions(pdev, XLP_SOC_PCI_DRIVER);
+		if (result) {
+			printk("[%s]: unable to pci_request_regions\n", __FUNCTION__);
+			return result;
+		}
+
+		mmio_vaddr = ioremap(mmio_paddr, mmio_size);
+		if (!mmio_vaddr) {
+			printk("[%s]: unable to ioremap\n", __FUNCTION__);
+			pci_release_regions(pdev);
+			return 1;
+		}
+	}
+	printk("[%s]: (bdf:0.%d.%d, %x.%x.%x) mmio_paddr=%lx, mmio_size=%lx, irq=%d, mmio_vaddr=%p \n", __FUNCTION__,
+	       dev, fn, base_class, sub_class, prog_int, mmio_paddr, mmio_size, irq, mmio_vaddr);
+
+	return 0;
+}
+
+static struct pci_driver soc_driver = {
+	.name             = XLP_SOC_PCI_DRIVER,
+	.id_table         = soc_device_table,
+	.probe            = soc_device_probe,
+};
+
+static int __init soc_device_init(void)
+{
+	return pci_register_driver(&soc_driver);
+}
+
+static void __init soc_device_exit(void)
+{
+	pci_unregister_driver(&soc_driver);
+}
+
+module_init(soc_device_init);
+module_exit(soc_device_exit);
diff --git a/arch/mips/rmi/ptr/rmicrf/Makefile b/arch/mips/rmi/ptr/rmicrf/Makefile
new file mode 100644
index 0000000..598c2c0
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/Makefile
@@ -0,0 +1,8 @@
+EXTRA_CFLAGS := -Werror
+obj-y  = fifo.o mutex.o processor.o entry.o entry-linux.o memcpy.o fmn.o 
+obj-y += rmik_utils.o utils.o eventq.o clpool.o event_handle.o
+obj-y  += dtb/
+
+EXTRA_CFLAGS += -I$(srctree)/arch/mips/include/asm/rmi
+EXTRA_AFLAGS := $(CFLAGS) 
+
diff --git a/arch/mips/rmi/ptr/rmicrf/Makefile.sync b/arch/mips/rmi/ptr/rmicrf/Makefile.sync
new file mode 100644
index 0000000..1ceb2bd
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/Makefile.sync
@@ -0,0 +1,41 @@
+ifeq (,$(wildcard $(CRFROOT)/include/rmicrf/api.h))
+   $(error 'CRFROOT' not set. Set this variable to the CRF top dir.)
+endif
+
+TOP = ../../../../..
+RMIDEV_INCLUDES = $(subst $(CRFROOT)/include/,,$(wildcard $(CRFROOT)/include/rmidev/*.h))
+RMICRF_INCLUDES = $(subst $(CRFROOT)/include/,,$(wildcard $(CRFROOT)/include/rmicrf/*.h))
+RMICRF_COMMON_SRC = $(subst $(CRFROOT)/librmicrf/,,$(wildcard $(CRFROOT)/librmicrf/*.c))
+RMICRF_LINUX_SRC = $(subst $(CRFROOT)/librmicrf/linuxk/,,$(wildcard $(CRFROOT)/librmicrf/linuxk/*.c))
+
+all:
+	@echo "Syncing with $(CRFROOT).."
+	@for file in $(RMICRF_INCLUDES) $(RMIDEV_INCLUDES); do \
+		if cmp $(CRFROOT)/include/$$file $(TOP)/include/asm-mips/rmi/$$file >/dev/null ; then \
+			echo "Skip include/$$file ..."; \
+		else \
+			echo "Copy include/$$file -> include/asm-mips/rmi/$$file ..."; \
+			mv -f $(TOP)/include/asm-mips/rmi/$$file $(TOP)/include/asm-mips/rmi/$$file.sync.orig; \
+			cp -f $(CRFROOT)/include/$$file $(TOP)/include/asm-mips/rmi/$$file; \
+		fi; \
+	done	
+	@for file in $(RMICRF_COMMON_SRC); do \
+		if cmp $(CRFROOT)/librmicrf/$$file $(TOP)/arch/mips/rmi/ptr/rmicrf/$$file >/dev/null ; then \
+			echo "Skip librmicrf/$$file ..." ;\
+		else \
+			echo "Copy librmicrf/$$file -> arch/mips/rmi/ptr/rmicrf/$$file ..."; \
+			mv -f  $(TOP)/arch/mips/rmi/ptr/rmicrf/$$file $(TOP)/arch/mips/rmi/ptr/rmicrf/$$file.sync.orig ;   \
+			cp -f $(CRFROOT)/librmicrf/$$file $(TOP)/arch/mips/rmi/ptr/rmicrf/$$file;  \
+		fi; \
+	done
+	@for file in $(RMICRF_LINUX_SRC); do \
+		if cmp $(CRFROOT)/librmicrf/linuxk/$$file $(TOP)/arch/mips/rmi/ptr/rmicrf/$$file >/dev/null ; then \
+			echo "Skip librmicrf/linuxk/$$file ..."; \
+		else \
+			echo "Copy librmicrf/linuxk/$$file -> arch/mips/rmi/ptr/rmicrf/$$file ..."; \
+			mv -f $(TOP)/arch/mips/rmi/ptr/rmicrf/$$file $(TOP)/arch/mips/rmi/ptr/rmicrf/$$file.sync.orig;    \
+			cp -f $(CRFROOT)/librmicrf/linuxk/$$file $(TOP)/arch/mips/rmi/ptr/rmicrf/$$file; \
+		fi; \
+	done
+	@echo "Done."
+
diff --git a/arch/mips/rmi/ptr/rmicrf/clpool.c b/arch/mips/rmi/ptr/rmicrf/clpool.c
new file mode 100644
index 0000000..f86923f
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/clpool.c
@@ -0,0 +1,487 @@
+/*
+ * Copyright (c) 2006 Ondrej Palkovsky
+ * All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * - Redistributions of source code must retain the above copyright
+ *   notice, this list of conditions and the following disclaimer.
+ * - Redistributions in binary form must reproduce the above copyright
+ *   notice, this list of conditions and the following disclaimer in the
+ *   documentation and/or other materials provided with the distribution.
+ * - The name of the author may not be used to endorse or promote products
+ *   derived from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE AUTHOR ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
+ * OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
+ * IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT,
+ * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT
+ * NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
+ * THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/**
+* @file_name clpool.c
+* @author Hareesh
+* @brief cluster pools
+*
+* Description: This file contains the libraris to create and manage a cluster pool
+*
+*/
+/**
+* @defgroup  crf_clpool CRF Cluster Pool Library
+* @brief CRF Cluster Pool Library for Inter Domain Communications. 
+* This library can be used to crate a cluster pool and alloc and share
+* an object with other domains.
+*
+* Similar kind of applications running on 2 different domains (A and B) can create a 
+* cluster pool of required size. If domain A want to send some data to domain B, 
+* domain A can allocate a cluster object from B, copy the data to domain B using crf event queues. 
+* Domain B can free the object after use. 
+*
+* So it eliminates the need for sending back the object to domain A for freeing object.
+* Also inter domain communication will be faster since copy operation happens only once per call.
+*
+*/
+
+
+
+#include <rmicrf/api.h>
+#include <rmicrf/types.h>
+#include <rmicrf/errcode.h>
+#include <rmicrf/clpool.h>
+#include <rmidev/xlrregs.h>
+
+/* Cluster pool info of all domains */
+#ifdef RMICRF_RMIOS
+#include "cdefs.h"
+struct rmi_cluster *rmi_pool_info[RMI_MAX_DOMAINS][RMI_MAX_CL_POOLS_PER_DOMAIN] __shared_memory__; 
+struct rmi_mutex cl_pool_lock __shared_memory__ = { .lock = { 0 } } ;
+#else
+struct rmi_cluster *rmi_pool_info[RMI_MAX_DOMAINS][RMI_MAX_CL_POOLS_PER_DOMAIN]; 
+struct rmi_mutex cl_pool_lock = { .lock = { 0 } };
+#endif
+
+#define GET_1ST_SETBIT_POS(size) (31 - xlr_clz(size))
+
+#if 1
+void dbg_mem(const char *fmt, ...) { }
+#else
+#define dbg_mem printf
+#endif
+
+
+/**************************************/
+/** Initialize cluster structure */
+static void
+pool_create(struct rmi_cluster *cluster, const char *name, void *data, rmi_physaddr_t paddr,
+		size_t num_units, size_t unit_size,  int flags)
+{
+	int i;
+
+	memset(cluster, sizeof(*cluster), 0);
+	memcpy(cluster->name, name, RMI_MAX_NAMELEN - 1);
+
+	cluster->datasize = num_units * unit_size;
+	cluster->paddr = paddr;
+	cluster->unit_size = unit_size;
+	cluster->flags = flags;
+	cluster->start = rmi_ptr_to_addr(data);
+	cluster->num_units = num_units;
+	cluster->available = num_units;
+	cluster->nextavail = 0;
+
+	for (i = 0; i < cluster->num_units; i++)
+		*((int *) (rmi_addr_to_ptr(cluster->start) + i * cluster->unit_size)) = i + 1;
+
+	dbg_mem("cluster create name=%s data=0x%lx size=0x%x\n", name, (long)data, cluster->datasize);
+	return;
+
+}
+
+/* Print list of clusters */
+void rmi_cluster_print_list(void)
+{
+	int idx, dom;
+	struct rmi_cluster *cluster;
+
+	for(dom = 0; dom < RMI_MAX_DOMAINS; dom++) {
+		for(idx = 0; idx < RMI_MAX_CL_POOLS_PER_DOMAIN; idx++) {
+			if((cluster = rmi_pool_info[dom][idx]) == NULL)
+				continue;
+			dbg_mem("cluster name        num_units  unit_size  available\n");
+			dbg_mem("---------------- -------- ------ ------ ------ ---\n");
+		
+			dbg_mem("%-16s   %08u   %08u   %08u 0x%llx \n",
+				    cluster->name, cluster->num_units, cluster->unit_size, 
+				    cluster->available,  cluster->paddr);
+		}
+	}
+}
+
+
+/**
+ * Delete the object from the cluster
+ * @param cluster 
+ *
+ */
+static int cluster_obj_destroy(struct rmi_cluster *cluster, void *obj)
+{
+	if(cluster == NULL)
+		return -RMI_EINVAL;
+
+	rmi_mutex_lock(&cluster->clusterlock);
+	assert(cluster->available < cluster->num_units);
+
+	if((obj < rmi_addr_to_ptr(cluster->start)) || 
+			((obj >= rmi_addr_to_ptr(cluster->start) + cluster->datasize))) {
+		rmi_log_error("[%s] Invalid address\n", __FUNCTION__);
+		return -RMI_EINVAL;
+	}
+
+	*((int *)obj) = cluster->nextavail;
+	cluster->nextavail = (obj - rmi_addr_to_ptr(cluster->start)) / cluster->unit_size;
+	cluster->available++;
+
+	rmi_mutex_unlock(&cluster->clusterlock);
+	return 0;
+}
+
+/**
+ * Take new object from cluster 
+ *
+ * @return Object address or null
+ */
+static void *cluster_obj_create(struct rmi_cluster *cluster, int flags)
+{
+	void *obj;
+	
+	if(cluster == NULL)
+		return NULL;
+	
+	rmi_mutex_lock(&cluster->clusterlock);
+
+	if(cluster->available <= 0) {
+		rmi_mutex_unlock(&cluster->clusterlock);
+		return NULL;
+	}
+	obj = rmi_addr_to_ptr(cluster->start) + cluster->nextavail * cluster->unit_size;
+	cluster->nextavail = *((int *)obj);
+	cluster->available--;
+
+	rmi_mutex_unlock(&cluster->clusterlock);
+
+	return obj;
+}
+
+
+
+
+
+/**
+  * @brief Create a Cluster Pool
+  *
+  * Create a cluster pool with the given unit size and number of units.
+  *
+  * @param[in] name name of the pool
+  * @param[in] num_units number of units of this cluster pool
+  * @param[in] unit_size unit of this cluster pool 
+  * @param[in] flags not used now .
+  *
+  * @return Returns 0 on success otherwise ERROR code.
+  *
+  * @ingroup crf_clpool
+  */
+
+int rmi_clpool_create(const char *name, uint32_t num_units, 
+		uint32_t unit_size , int flags)
+{
+	uint32_t dsize = 0, esize = SLAB_ALIGN;
+	struct rmi_cluster *cluster;
+	char rname[RMI_MAX_NAMELEN];
+	uint32_t mflags = RMI_RES_MEM_FLAGS | RMI_M_ALLOC_UNMAPPED;
+	int dom = rmi_this_domain->id, rv, idx;
+	struct rmi_resource *dres = NULL, *res = NULL;
+	rmi_physaddr_t paddr;
+	void 	*vaddr, *data;
+
+	
+	if((flags & RMI_MALLOC_UNMAPPED) != RMI_MALLOC_UNMAPPED) {
+		rmi_log_error("Alloc from only Unmapped space is supported now\n");
+		return -1;
+	}
+	if((name == NULL) || (strlen(name) >= RMI_CL_POOL_NAMELEN)) {
+		rmi_log_error("Invalid name, no name or namelen exceeds limit\n");
+		return -1;
+	}
+	
+	idx = GET_1ST_SETBIT_POS(unit_size);
+	if(idx <= 2) {
+		rmi_log_error("Error : Minimum cluster size is 8\n");
+		return -1;
+	}
+	
+	if((unit_size % RMI_DEF_L2C_LINE_SZ) != 0) {
+		rmi_log_error("[%s] size should be cache aligned\n", __FUNCTION__);
+		return -1;
+	}
+
+	dsize += unit_size * num_units;
+	esize += sizeof(struct rmi_cluster);
+
+	rmi_mutex_lock(&cl_pool_lock);
+
+	/* get vacant idx */
+	for(idx = 0; idx < RMI_MAX_CL_POOLS_PER_DOMAIN; idx++) {
+		if(rmi_pool_info[dom][idx] == NULL)
+			break;
+	}
+	if(idx >= RMI_MAX_CL_POOLS_PER_DOMAIN) {
+		rmi_log_error("Number of pools reaches limit\n");
+		goto err_exit;
+	}
+	
+	if(rmi_resource_getref(rmi_this_domain->name, &dres, NULL) < 0) {
+		rmi_log_error("[%s] Domain %s get failed \n", __FUNCTION__, rmi_this_domain->name);
+		goto err_exit;
+	}
+
+	/* create memory */
+	sprintf(rname, "%s.%s", rmi_this_domain->name, name);
+	if((rv = rmi_memseg_create(dres, rname, 0, dsize + esize,
+					0, 0, unit_size, mflags)) != 0) {
+		rmi_log_error("[%s] Failed to allocate memory segment\n", __FUNCTION__);
+		goto err_exit;
+	}
+
+	if((rv = rmi_resource_getref(rname, &res, NULL)) < 0) {
+		rmi_log_error("[%s] Resource %s get failed\n", __FUNCTION__, rname);
+		goto err_exit;
+	}
+
+	if((rv = rmi_resource_allocate(rname, dom)) < 0) {
+		rmi_log_error("[%s]Allocate %s to domain %d failed(%d)\n", __FUNCTION__, name, dom, rv);
+		goto err_exit;
+	}
+
+	paddr = rmi_memseg_physaddr_get(rname);
+	data = vaddr = rmi_addr_to_ptr(rmi_phys_to_kseg0(paddr));
+
+	/* all the cluster structures will be at the end of allocated memory */
+	cluster = rmi_addr_to_ptr(rmi_roundup((long)data + dsize, SLAB_ALIGN));
+	pool_create(cluster, name, data, paddr, num_units, unit_size, 0);
+	
+	cluster->size = dsize + esize;
+	cluster->poolid = idx;
+	cluster->res = rmi_ptr_to_addr(res);
+	rmi_pool_info[dom][idx] = cluster;
+
+	rmi_mutex_unlock(&cl_pool_lock);
+	rmi_resource_putref(dres);
+	rmi_resource_putref(res);
+	return 0;
+
+err_exit:
+
+	rmi_mutex_unlock(&cl_pool_lock);
+	if(res) {
+		rmi_resource_putref(res);
+		rmi_resource_delete(res->name);
+	}
+	if(dres)
+		rmi_resource_putref(dres);
+
+	return -1;
+}	
+
+/**
+  * @brief Dreate a Cluster Pool
+  *
+  * Delete a cluster pool with the given name.
+  *
+  * @param[in] name of the pool
+  *
+  * @return Returns 0 on success otherwise ERROR code.
+  *
+  *
+  * @ingroup crf_clpool
+  */
+
+int rmi_clpool_delete(const char *name)
+{
+	struct rmi_cluster *cluster;
+	int i;
+	int dom = rmi_this_domain->id;
+	char rname[RMI_MAX_NAMELEN];
+
+	for(i = 0; i < RMI_MAX_CL_POOLS_PER_DOMAIN; i++) {
+		if((cluster = rmi_pool_info[dom][i]) == NULL)
+			continue;
+		if(strcmp(cluster->name, name) != 0)
+			continue;
+
+		sprintf(rname, "%s.%s", rmi_this_domain->name, name);
+		rmi_pool_info[dom][i] = NULL;
+		dbg_mem("pool delete name=%s\n", cluster->name);
+		rmi_resource_free(rname);
+		rmi_resource_delete(rname);
+		return 0;
+	}
+	return -RMI_EINVAL;
+
+}
+
+/**
+* @brief Get clpool reference
+*
+* Gets a reference and/or details for the clpool with the specified name.
+*
+* @param[in] dom the owner of this clpool 
+* @param[in] name name of the clpool 
+*
+* @return Returns the pointer to the cluster on success, NULL on failure.
+*
+* @ingroup crf_clpool
+*
+*/
+
+struct rmi_cluster *rmi_clpool_getref(int dom, const char *name)
+{
+	char *data, *ch;
+	struct rmi_cluster *cluster;
+	struct rmi_resource *res = NULL;
+	struct rmi_domain domain;
+	struct rmi_memseg *mseg;
+	char rname[RMI_MAX_NAMELEN];
+	int clsize = SLAB_ALIGN + sizeof(struct rmi_cluster);
+
+	rmi_get_domain(dom, &domain);
+	if((ch = strchr(name, '.')) == NULL) 
+		sprintf(rname, "%s.%s", domain.name, name);
+	else
+		sprintf(rname, "%s.%s", domain.name, ch + 1);
+	
+	if(rmi_resource_getref(rname, &res, NULL) < 0) {
+		rmi_log_error("[%s] Resource %s get failed\n", __FUNCTION__, rname);
+		return NULL;
+	}
+	
+
+	mseg = rmi_addr_to_ptr(res->obj);
+	if(mseg->allocstart > XLR_PHYS_KSEG0_END) {
+		rmi_resource_putref(res);
+		rmi_log_error("Only Unmapped space is supported now %llx\n", mseg->allocstart);
+		return NULL;
+	}
+
+	data = rmi_addr_to_ptr(rmi_phys_to_kseg0(mseg->allocstart));
+	cluster = rmi_addr_to_ptr(rmi_roundup((long)data + mseg->size - clsize, SLAB_ALIGN));
+	cluster->res = rmi_ptr_to_addr(res);
+	rmi_pool_info[dom][cluster->poolid] = cluster;
+	return cluster;
+}
+
+/**
+* @brief Put clpool reference
+*
+* Puts a clpool reference by decrementing its reference count.
+*
+* @param[in] cluster cluster pointer
+*
+* @return Returns 0 on success otherwise ERROR code.
+*
+* @ingroup crf_clpool
+*
+*/
+
+int rmi_clpool_putref(struct rmi_cluster *cluster)
+{
+	return rmi_resource_putref(rmi_addr_to_ptr(cluster->res));
+}
+
+/**
+* @brief Alloc an object
+*
+* Alloc a singe object(memory) from the cluster pool
+*
+* @param[in] cluster cluter pointer returned by rmi_clpool_getref call 
+* @param[in] flags not used now 
+*
+* @return Returns the pointer to the object on success, NULL on failure.
+*
+* @ingroup crf_clpool
+*
+*/
+
+
+void *rmi_cluster_alloc(struct rmi_cluster *cluster, int flags)
+{
+	if (!cluster)
+		return NULL;
+	
+	return cluster_obj_create(cluster, flags); 	
+
+}
+
+/**
+* @brief Free an object
+*
+* Free the object(memory) from the cluster pool
+*
+* @param[in] cluster cluter pointer returned by rmi_clpool_getref call 
+* @param[in] obj object returned by the alloc function
+*
+* @return void
+*
+* @ingroup crf_clpool
+*
+*/
+
+void rmi_cluster_free(struct rmi_cluster *cluster, void *obj)
+{
+	if (!obj || !cluster)
+		return;
+	
+	cluster_obj_destroy(cluster, obj); 	
+	return;
+}
+
+void rmi_clpool_test(void)
+{
+	void *obj, *obj1;
+	struct rmi_cluster *cl;
+	int rv;
+
+	if((rv = rmi_clpool_create("cltest", 2, 1024, RMI_MALLOC_UNMAPPED)) < 0) {
+		rmi_log_error("Pool create failed\n");
+		return;
+	}
+
+	if((rv = rmi_clpool_create("cltest1", 2, 2048, RMI_MALLOC_UNMAPPED)) < 0) {
+		rmi_log_error("Pool create failed\n");
+		return;
+	}
+	rmi_cluster_print_list();
+	cl = rmi_clpool_getref(2, "cltest");
+	obj = rmi_cluster_alloc(cl, 0);
+	dbg_mem("Cluster alloc obj=%lx\n", (long)obj);
+	obj1 = rmi_cluster_alloc(cl, 0);
+	dbg_mem("Cluster alloc obj=%lx\n", (long)obj1);
+	obj1 = rmi_cluster_alloc(cl, 0);
+	dbg_mem("Cluster alloc obj=%lx\n", (long)obj1);
+	rmi_cluster_free(cl, obj);
+	obj1 = rmi_cluster_alloc(cl, 0);
+	dbg_mem("Cluster alloc obj=%lx\n", (long)obj1);
+
+	rmi_clpool_putref(cl);
+	rmi_clpool_delete("cltest");
+	rmi_cluster_print_list();
+}
+/** @}
+ */
diff --git a/arch/mips/rmi/ptr/rmicrf/dtb/Makefile b/arch/mips/rmi/ptr/rmicrf/dtb/Makefile
new file mode 100644
index 0000000..3b881a1
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/dtb/Makefile
@@ -0,0 +1,5 @@
+obj-y                   = flatdevtree.o flatdevtree_misc.o simple_alloc.o flatdevtree_utils.o
+
+EXTRA_AFLAGS := $(CFLAGS)
+
+
diff --git a/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree.c b/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree.c
new file mode 100644
index 0000000..eea7dc7
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree.c
@@ -0,0 +1,1011 @@
+/************************************************************************
+  Copyright 2007-2008 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: Fixed the issue found in n64 mode
+
+ *****************************#RMI_1#************************************/
+
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+ * Copyright Pantelis Antoniou 2006
+ * Copyright (C) IBM Corporation 2006
+ *
+ * Authors: Pantelis Antoniou <pantelis@embeddedalley.com>
+ *	    Hollis Blanchard <hollisb@us.ibm.com>
+ *	    Mark A. Greer <mgreer@mvista.com>
+ *	    Paul Mackerras <paulus@samba.org>
+ */
+
+#include <linux/string.h>
+#include <linux/kernel.h>
+#include <stddef.h>
+#include "flatdevtree.h"
+#include "flatdevtree_env.h"
+
+#define _ALIGN(x, al)	(((x) + (al) - 1) & ~((al) - 1))
+
+static char *ft_root_node(struct ft_cxt *cxt)
+{
+	return cxt->rgn[FT_STRUCT].start;
+}
+
+/* Routines for keeping node ptrs returned by ft_find_device current */
+/* First entry not used b/c it would return 0 and be taken as NULL/error */
+static void *ft_get_phandle(struct ft_cxt *cxt, char *node)
+{
+	unsigned int i;
+
+	if (!node)
+		return NULL;
+
+	for (i = 1; i < cxt->nodes_used; i++)	/* already there? */
+		if (cxt->node_tbl[i] == node)
+			return (void *)(long)i;
+
+	if (cxt->nodes_used < cxt->node_max) {
+		cxt->node_tbl[cxt->nodes_used] = node;
+		return (void *)(long)cxt->nodes_used++;
+	}
+
+	return NULL;
+}
+
+static char *ft_node_ph2node(struct ft_cxt *cxt, const void *phandle)
+{
+	unsigned int i = (unsigned int)(long)phandle;
+
+	if (i < cxt->nodes_used)
+		return cxt->node_tbl[i];
+	return NULL;
+}
+
+static void ft_node_update_before(struct ft_cxt *cxt, char *addr, int shift)
+{
+	unsigned int i;
+
+	if (shift == 0)
+		return;
+
+	for (i = 1; i < cxt->nodes_used; i++)
+		if (cxt->node_tbl[i] < addr)
+			cxt->node_tbl[i] += shift;
+}
+
+static void ft_node_update_after(struct ft_cxt *cxt, char *addr, int shift)
+{
+	unsigned int i;
+
+	if (shift == 0)
+		return;
+
+	for (i = 1; i < cxt->nodes_used; i++)
+		if (cxt->node_tbl[i] >= addr)
+			cxt->node_tbl[i] += shift;
+}
+
+/* Struct used to return info from ft_next() */
+struct ft_atom {
+	u32 tag;
+	const char *name;
+	void *data;
+	u32 size;
+};
+
+/* Set ptrs to current one's info; return addr of next one */
+static char *ft_next(struct ft_cxt *cxt, char *p, struct ft_atom *ret)
+{
+	u32 sz;
+
+	if (p >= cxt->rgn[FT_STRUCT].start + cxt->rgn[FT_STRUCT].size)
+		return NULL;
+
+	ret->tag = be32_to_cpu(*(u32 *) p);
+	p += 4;
+
+	switch (ret->tag) {	/* Tag */
+	case OF_DT_BEGIN_NODE:
+		ret->name = p;
+		ret->data = (void *)(p - 4);	/* start of node */
+		p += _ALIGN(strlen(p) + 1, 4);
+		break;
+	case OF_DT_PROP:
+		ret->size = sz = be32_to_cpu(*(u32 *) p);
+		ret->name = cxt->str_anchor + be32_to_cpu(*(u32 *) (p + 4));
+		ret->data = (void *)(p + 8);
+		p += 8 + _ALIGN(sz, 4);
+		break;
+	case OF_DT_END_NODE:
+	case OF_DT_NOP:
+		break;
+	case OF_DT_END:
+	default:
+		p = NULL;
+		break;
+	}
+
+	return p;
+}
+
+#define HDR_SIZE	_ALIGN(sizeof(struct boot_param_header), 8)
+#define EXPAND_INCR	1024	/* alloc this much extra when expanding */
+static int ft_ordered(struct ft_cxt *cxt) __attribute__((unused));
+
+/* See if the regions are in the standard order and non-overlapping */
+static int ft_ordered(struct ft_cxt *cxt) 
+{
+	char *p = (char *)cxt->bph + HDR_SIZE;
+	enum ft_rgn_id r;
+
+	for (r = FT_RSVMAP; r <= FT_STRINGS; ++r) {
+		if (p > cxt->rgn[r].start)
+			return 0;
+		p = cxt->rgn[r].start + cxt->rgn[r].size;
+	}
+	return p <= (char *)cxt->bph + cxt->max_size;
+}
+
+/* Copy the tree to a newly-allocated region and put things in order */
+static int ft_reorder(struct ft_cxt *cxt, int nextra)
+{
+	unsigned long tot;
+	enum ft_rgn_id r;
+	char *p, *pend;
+	int stroff;
+
+	tot = HDR_SIZE + EXPAND_INCR;
+	for (r = FT_RSVMAP; r <= FT_STRINGS; ++r)
+		tot += cxt->rgn[r].size;
+	if (nextra > 0)
+		tot += nextra;
+	tot = _ALIGN(tot, 8);
+
+	if (!cxt->realloc)
+		return 0;
+	p = cxt->realloc(NULL, tot);
+	if (!p)
+		return 0;
+
+	memcpy(p, cxt->bph, sizeof(struct boot_param_header));
+	/* offsets get fixed up later */
+
+	cxt->bph = (struct boot_param_header *)p;
+	cxt->max_size = tot;
+	pend = p + tot;
+	p += HDR_SIZE;
+
+	memcpy(p, cxt->rgn[FT_RSVMAP].start, cxt->rgn[FT_RSVMAP].size);
+	cxt->rgn[FT_RSVMAP].start = p;
+	p += cxt->rgn[FT_RSVMAP].size;
+
+	memcpy(p, cxt->rgn[FT_STRUCT].start, cxt->rgn[FT_STRUCT].size);
+	ft_node_update_after(cxt, cxt->rgn[FT_STRUCT].start,
+			p - cxt->rgn[FT_STRUCT].start);
+	cxt->p += p - cxt->rgn[FT_STRUCT].start;
+	cxt->rgn[FT_STRUCT].start = p;
+
+	p = pend - cxt->rgn[FT_STRINGS].size;
+	memcpy(p, cxt->rgn[FT_STRINGS].start, cxt->rgn[FT_STRINGS].size);
+	stroff = cxt->str_anchor - cxt->rgn[FT_STRINGS].start;
+	cxt->rgn[FT_STRINGS].start = p;
+	cxt->str_anchor = p + stroff;
+
+	cxt->isordered = 1;
+	return 1;
+}
+
+static inline char *prev_end(struct ft_cxt *cxt, enum ft_rgn_id r)
+{
+	if (r > FT_RSVMAP)
+		return cxt->rgn[r - 1].start + cxt->rgn[r - 1].size;
+	return (char *)cxt->bph + HDR_SIZE;
+}
+
+static inline char *next_start(struct ft_cxt *cxt, enum ft_rgn_id r)
+{
+	if (r < FT_STRINGS)
+		return cxt->rgn[r + 1].start;
+	return (char *)cxt->bph + cxt->max_size;
+}
+
+/*
+ * See if we can expand region rgn by nextra bytes by using up
+ * free space after or before the region.
+ */
+static int ft_shuffle(struct ft_cxt *cxt, char **pp, enum ft_rgn_id rgn,
+		int nextra)
+{
+	char *p = *pp;
+	char *rgn_start, *rgn_end;
+
+	rgn_start = cxt->rgn[rgn].start;
+	rgn_end = rgn_start + cxt->rgn[rgn].size;
+	if (nextra <= 0 || rgn_end + nextra <= next_start(cxt, rgn)) {
+		/* move following stuff */
+		if (p < rgn_end) {
+			if (nextra < 0)
+				memmove(p, p - nextra, rgn_end - p + nextra);
+			else
+				memmove(p + nextra, p, rgn_end - p);
+			if (rgn == FT_STRUCT)
+				ft_node_update_after(cxt, p, nextra);
+		}
+		cxt->rgn[rgn].size += nextra;
+		if (rgn == FT_STRINGS)
+			/* assumes strings only added at beginning */
+			cxt->str_anchor += nextra;
+		return 1;
+	}
+	if (prev_end(cxt, rgn) <= rgn_start - nextra) {
+		/* move preceding stuff */
+		if (p > rgn_start) {
+			memmove(rgn_start - nextra, rgn_start, p - rgn_start);
+			if (rgn == FT_STRUCT)
+				ft_node_update_before(cxt, p, -nextra);
+		}
+		*pp -= nextra;
+		cxt->rgn[rgn].start -= nextra;
+		cxt->rgn[rgn].size += nextra;
+		return 1;
+	}
+	return 0;
+}
+
+static int ft_make_space(struct ft_cxt *cxt, char **pp, enum ft_rgn_id rgn,
+			 int nextra)
+{
+	unsigned long size, ssize, tot;
+	char *str, *next;
+	enum ft_rgn_id r;
+
+	if (!cxt->isordered) {
+		unsigned long rgn_off = *pp - cxt->rgn[rgn].start;
+
+		if (!ft_reorder(cxt, nextra))
+			return 0;
+
+		*pp = cxt->rgn[rgn].start + rgn_off;
+	}
+	if (ft_shuffle(cxt, pp, rgn, nextra))
+		return 1;
+
+	/* See if there is space after the strings section */
+	ssize = cxt->rgn[FT_STRINGS].size;
+	if (cxt->rgn[FT_STRINGS].start + ssize
+			< (char *)cxt->bph + cxt->max_size) {
+		/* move strings up as far as possible */
+		str = (char *)cxt->bph + cxt->max_size - ssize;
+		cxt->str_anchor += str - cxt->rgn[FT_STRINGS].start;
+		memmove(str, cxt->rgn[FT_STRINGS].start, ssize);
+		cxt->rgn[FT_STRINGS].start = str;
+		/* enough space now? */
+		if (rgn >= FT_STRUCT && ft_shuffle(cxt, pp, rgn, nextra))
+			return 1;
+	}
+
+	/* how much total free space is there following this region? */
+	tot = 0;
+	for (r = rgn; r < FT_STRINGS; ++r) {
+		char *r_end = cxt->rgn[r].start + cxt->rgn[r].size;
+		tot += next_start(cxt, rgn) - r_end;
+	}
+
+	/* cast is to shut gcc up; we know nextra >= 0 */
+	if (tot < (unsigned int)nextra) {
+		/* have to reallocate */
+		char *newp, *new_start;
+		int shift;
+
+		if (!cxt->realloc)
+			return 0;
+		size = _ALIGN(cxt->max_size + (nextra - tot) + EXPAND_INCR, 8);
+		newp = cxt->realloc(cxt->bph, size);
+		if (!newp)
+			return 0;
+		cxt->max_size = size;
+		shift = newp - (char *)cxt->bph;
+
+		if (shift) { /* realloc can return same addr */
+			cxt->bph = (struct boot_param_header *)newp;
+			ft_node_update_after(cxt, cxt->rgn[FT_STRUCT].start,
+					shift);
+			for (r = FT_RSVMAP; r <= FT_STRINGS; ++r) {
+				new_start = cxt->rgn[r].start + shift;
+				cxt->rgn[r].start = new_start;
+			}
+			*pp += shift;
+			cxt->str_anchor += shift;
+		}
+
+		/* move strings up to the end */
+		str = newp + size - ssize;
+		cxt->str_anchor += str - cxt->rgn[FT_STRINGS].start;
+		memmove(str, cxt->rgn[FT_STRINGS].start, ssize);
+		cxt->rgn[FT_STRINGS].start = str;
+
+		if (ft_shuffle(cxt, pp, rgn, nextra))
+			return 1;
+	}
+
+	/* must be FT_RSVMAP and we need to move FT_STRUCT up */
+	if (rgn == FT_RSVMAP) {
+		next = cxt->rgn[FT_RSVMAP].start + cxt->rgn[FT_RSVMAP].size
+			+ nextra;
+		ssize = cxt->rgn[FT_STRUCT].size;
+		if (next + ssize >= cxt->rgn[FT_STRINGS].start)
+			return 0;	/* "can't happen" */
+		memmove(next, cxt->rgn[FT_STRUCT].start, ssize);
+		ft_node_update_after(cxt, cxt->rgn[FT_STRUCT].start, nextra);
+		cxt->rgn[FT_STRUCT].start = next;
+
+		if (ft_shuffle(cxt, pp, rgn, nextra))
+			return 1;
+	}
+
+	return 0;		/* "can't happen" */
+}
+
+static void ft_put_word(struct ft_cxt *cxt, u32 v)
+{
+	*(u32 *) cxt->p = cpu_to_be32(v);
+	cxt->p += 4;
+}
+
+static void ft_put_bin(struct ft_cxt *cxt, const void *data, unsigned int sz)
+{
+	unsigned long sza = _ALIGN(sz, 4);
+
+	/* zero out the alignment gap if necessary */
+	if (sz < sza)
+		*(u32 *) (cxt->p + sza - 4) = 0;
+
+	/* copy in the data */
+	memcpy(cxt->p, data, sz);
+
+	cxt->p += sza;
+}
+
+int ft_begin_node(struct ft_cxt *cxt, const char *name)
+{
+	unsigned long nlen = strlen(name) + 1;
+	unsigned long len = 8 + _ALIGN(nlen, 4);
+
+	if (!ft_make_space(cxt, &cxt->p, FT_STRUCT, len))
+		return -1;
+	ft_put_word(cxt, OF_DT_BEGIN_NODE);
+	ft_put_bin(cxt, name, strlen(name) + 1);
+	return 0;
+}
+
+void ft_end_node(struct ft_cxt *cxt)
+{
+	ft_put_word(cxt, OF_DT_END_NODE);
+}
+
+void ft_nop(struct ft_cxt *cxt)
+{
+	if (ft_make_space(cxt, &cxt->p, FT_STRUCT, 4))
+		ft_put_word(cxt, OF_DT_NOP);
+}
+
+#define NO_STRING	0x7fffffff
+
+static int lookup_string(struct ft_cxt *cxt, const char *name)
+{
+	char *p, *end;
+
+	p = cxt->rgn[FT_STRINGS].start;
+	end = p + cxt->rgn[FT_STRINGS].size;
+	while (p < end) {
+		if (strcmp(p, (char *)name) == 0)
+			return p - cxt->str_anchor;
+		p += strlen(p) + 1;
+	}
+
+	return NO_STRING;
+}
+
+/* lookup string and insert if not found */
+static int map_string(struct ft_cxt *cxt, const char *name)
+{
+	int off;
+	char *p;
+
+	off = lookup_string(cxt, name);
+	if (off != NO_STRING)
+		return off;
+	p = cxt->rgn[FT_STRINGS].start;
+	if (!ft_make_space(cxt, &p, FT_STRINGS, strlen(name) + 1))
+		return NO_STRING;
+	strcpy(p, name);
+	return p - cxt->str_anchor;
+}
+
+int ft_prop(struct ft_cxt *cxt, const char *name, const void *data,
+		unsigned int sz)
+{
+	int off, len;
+
+	off = map_string(cxt, name);
+	if (off == NO_STRING)
+		return -1;
+
+	len = 12 + _ALIGN(sz, 4);
+	if (!ft_make_space(cxt, &cxt->p, FT_STRUCT, len))
+		return -1;
+
+	ft_put_word(cxt, OF_DT_PROP);
+	ft_put_word(cxt, sz);
+	ft_put_word(cxt, off);
+	ft_put_bin(cxt, data, sz);
+	return 0;
+}
+
+int ft_prop_str(struct ft_cxt *cxt, const char *name, const char *str)
+{
+	return ft_prop(cxt, name, str, strlen(str) + 1);
+}
+
+int ft_prop_int(struct ft_cxt *cxt, const char *name, unsigned int val)
+{
+	u32 v = cpu_to_be32((u32) val);
+
+	return ft_prop(cxt, name, &v, 4);
+}
+
+/* Calculate the size of the reserved map */
+static unsigned long rsvmap_size(struct ft_cxt *cxt)
+{
+	struct ft_reserve *res;
+
+	res = (struct ft_reserve *)cxt->rgn[FT_RSVMAP].start;
+	while (res->start || res->len)
+		++res;
+	return (char *)(res + 1) - cxt->rgn[FT_RSVMAP].start;
+}
+
+/* Calculate the size of the struct region by stepping through it */
+static unsigned long struct_size(struct ft_cxt *cxt)
+{
+	char *p = cxt->rgn[FT_STRUCT].start;
+	char *next;
+	struct ft_atom atom;
+
+	/* make check in ft_next happy */
+	if (cxt->rgn[FT_STRUCT].size == 0)
+		cxt->rgn[FT_STRUCT].size = (ULONG_MAX) - (unsigned long)p;
+
+	while ((next = ft_next(cxt, p, &atom)) != NULL)
+		p = next;
+	return p + 4 - cxt->rgn[FT_STRUCT].start;
+}
+
+/* add `adj' on to all string offset values in the struct area */
+static void adjust_string_offsets(struct ft_cxt *cxt, int adj)
+{
+	char *p = cxt->rgn[FT_STRUCT].start;
+	char *next;
+	struct ft_atom atom;
+	int off;
+
+	while ((next = ft_next(cxt, p, &atom)) != NULL) {
+		if (atom.tag == OF_DT_PROP) {
+			off = be32_to_cpu(*(u32 *) (p + 8));
+			*(u32 *) (p + 8) = cpu_to_be32(off + adj);
+		}
+		p = next;
+	}
+}
+
+/* start construction of the flat OF tree from scratch */
+void ft_begin(struct ft_cxt *cxt, void *blob, unsigned int max_size,
+		void *(*realloc_fn) (void *, unsigned long))
+{
+	struct boot_param_header *bph = blob;
+	char *p;
+	struct ft_reserve *pres;
+
+	/* clear the cxt */
+	memset(cxt, 0, sizeof(*cxt));
+
+	cxt->bph = bph;
+	cxt->max_size = max_size;
+	cxt->realloc = realloc_fn;
+	cxt->isordered = 1;
+
+	/* zero everything in the header area */
+	memset(bph, 0, sizeof(*bph));
+
+	bph->magic = cpu_to_be32(OF_DT_HEADER);
+	bph->version = cpu_to_be32(0x10);
+	bph->last_comp_version = cpu_to_be32(0x10);
+
+	/* start pointers */
+	cxt->rgn[FT_RSVMAP].start = p = blob + HDR_SIZE;
+	cxt->rgn[FT_RSVMAP].size = sizeof(struct ft_reserve);
+	pres = (struct ft_reserve *)p;
+	cxt->rgn[FT_STRUCT].start = p += sizeof(struct ft_reserve);
+	cxt->rgn[FT_STRUCT].size = 4;
+	cxt->rgn[FT_STRINGS].start = blob + max_size;
+	cxt->rgn[FT_STRINGS].size = 0;
+
+	/* init rsvmap and struct */
+	pres->start = 0;
+	pres->len = 0;
+	*(u32 *) p = cpu_to_be32(OF_DT_END);
+
+	cxt->str_anchor = blob;
+}
+
+/* open up an existing blob to be examined or modified */
+int ft_open(struct ft_cxt *cxt, void *blob, unsigned int max_size,
+		unsigned int max_find_device,
+		void *(*realloc_fn) (void *, unsigned long))
+{
+	struct boot_param_header *bph = blob;
+
+	/* can't cope with version < 16 */
+	if (be32_to_cpu(bph->version) < 16)
+		return -1;
+
+	/* clear the cxt */
+	memset(cxt, 0, sizeof(*cxt));
+
+	/* alloc node_tbl to track node ptrs returned by ft_find_device */
+	++max_find_device;
+	cxt->node_tbl = realloc_fn(NULL, max_find_device * sizeof(char *));
+	if (!cxt->node_tbl)
+		return -1;
+	memset(cxt->node_tbl, 0, max_find_device * sizeof(char *));
+	cxt->node_max = max_find_device;
+	cxt->nodes_used = 1;	/* don't use idx 0 b/c looks like NULL */
+
+	cxt->bph = bph;
+	cxt->max_size = max_size;
+	cxt->realloc = realloc_fn;
+
+	cxt->rgn[FT_RSVMAP].start = blob + be32_to_cpu(bph->off_mem_rsvmap);
+	cxt->rgn[FT_RSVMAP].size = rsvmap_size(cxt);
+	cxt->rgn[FT_STRUCT].start = blob + be32_to_cpu(bph->off_dt_struct);
+	cxt->rgn[FT_STRUCT].size = struct_size(cxt);
+	cxt->rgn[FT_STRINGS].start = blob + be32_to_cpu(bph->off_dt_strings);
+	cxt->rgn[FT_STRINGS].size = be32_to_cpu(bph->dt_strings_size);
+	/* Leave as '0' to force first ft_make_space call to do a ft_reorder
+	 * and move dt to an area allocated by realloc.
+	cxt->isordered = ft_ordered(cxt);
+	*/
+
+	cxt->p = cxt->rgn[FT_STRUCT].start;
+	cxt->str_anchor = cxt->rgn[FT_STRINGS].start;
+
+	return 0;
+}
+
+/* add a reserver physical area to the rsvmap */
+int ft_add_rsvmap(struct ft_cxt *cxt, u64 physaddr, u64 size)
+{
+	char *p;
+	struct ft_reserve *pres;
+
+	p = cxt->rgn[FT_RSVMAP].start + cxt->rgn[FT_RSVMAP].size
+		- sizeof(struct ft_reserve);
+	if (!ft_make_space(cxt, &p, FT_RSVMAP, sizeof(struct ft_reserve)))
+		return -1;
+
+	pres = (struct ft_reserve *)p;
+	pres->start = cpu_to_be64(physaddr);
+	pres->len = cpu_to_be64(size);
+
+	return 0;
+}
+
+void ft_begin_tree(struct ft_cxt *cxt)
+{
+	cxt->p = ft_root_node(cxt);
+}
+
+void ft_end_tree(struct ft_cxt *cxt)
+{
+	struct boot_param_header *bph = cxt->bph;
+	char *p, *oldstr, *str, *endp;
+	unsigned long ssize;
+	int adj;
+
+	if (!cxt->isordered)
+		return;		/* we haven't touched anything */
+
+	/* adjust string offsets */
+	oldstr = cxt->rgn[FT_STRINGS].start;
+	adj = cxt->str_anchor - oldstr;
+	if (adj)
+		adjust_string_offsets(cxt, adj);
+
+	/* make strings end on 8-byte boundary */
+	ssize = cxt->rgn[FT_STRINGS].size;
+	endp = (char *)_ALIGN((unsigned long)cxt->rgn[FT_STRUCT].start
+			+ cxt->rgn[FT_STRUCT].size + ssize, 8);
+	str = endp - ssize;
+
+	/* move strings down to end of structs */
+	memmove(str, oldstr, ssize);
+	cxt->str_anchor = str;
+	cxt->rgn[FT_STRINGS].start = str;
+
+	/* fill in header fields */
+	p = (char *)bph;
+	bph->totalsize = cpu_to_be32(endp - p);
+	bph->off_mem_rsvmap = cpu_to_be32(cxt->rgn[FT_RSVMAP].start - p);
+	bph->off_dt_struct = cpu_to_be32(cxt->rgn[FT_STRUCT].start - p);
+	bph->off_dt_strings = cpu_to_be32(cxt->rgn[FT_STRINGS].start - p);
+	bph->dt_strings_size = cpu_to_be32(ssize);
+}
+
+void *ft_find_device(struct ft_cxt *cxt, const char *srch_path)
+{
+	char *node;
+
+	/* require absolute path */
+	if (srch_path[0] != '/')
+		return NULL;
+	node = ft_find_descendent(cxt, ft_root_node(cxt), srch_path);
+	return ft_get_phandle(cxt, node);
+}
+
+void *ft_find_device_rel(struct ft_cxt *cxt, const void *top,
+                         const char *srch_path)
+{
+	char *node;
+
+	node = ft_node_ph2node(cxt, top);
+	if (node == NULL)
+		return NULL;
+
+	node = ft_find_descendent(cxt, node, srch_path);
+	return ft_get_phandle(cxt, node);
+}
+
+void *ft_find_descendent(struct ft_cxt *cxt, void *top, const char *srch_path)
+{
+	struct ft_atom atom;
+	char *p;
+	const char *cp, *q;
+	int cl;
+	int depth = -1;
+	int dmatch = 0;
+	const char *path_comp[FT_MAX_DEPTH];
+
+	cp = srch_path;
+	cl = 0;
+	p = top;
+
+	while ((p = ft_next(cxt, p, &atom)) != NULL) {
+		switch (atom.tag) {
+		case OF_DT_BEGIN_NODE:
+			++depth;
+			if (depth != dmatch)
+				break;
+			cxt->genealogy[depth] = atom.data;
+			cxt->genealogy[depth + 1] = NULL;
+			if (depth && !(strncmp(atom.name, cp, cl) == 0
+					&& (atom.name[cl] == '/'
+						|| atom.name[cl] == '\0'
+						|| atom.name[cl] == '@')))
+				break;
+			path_comp[dmatch] = cp;
+			/* it matches so far, advance to next path component */
+			cp += cl;
+			/* skip slashes */
+			while (*cp == '/')
+				++cp;
+			/* we're done if this is the end of the string */
+			if (*cp == 0)
+				return atom.data;
+			/* look for end of this component */
+			q = strchr(cp, '/');
+			if (q)
+				cl = q - cp;
+			else
+				cl = strlen(cp);
+			++dmatch;
+			break;
+		case OF_DT_END_NODE:
+			if (depth == 0)
+				return NULL;
+			if (dmatch > depth) {
+				--dmatch;
+				cl = cp - path_comp[dmatch] - 1;
+				cp = path_comp[dmatch];
+				while (cl > 0 && cp[cl - 1] == '/')
+					--cl;
+			}
+			--depth;
+			break;
+		}
+	}
+	return NULL;
+}
+
+void *__ft_get_parent(struct ft_cxt *cxt, void *node)
+{
+	int d;
+	struct ft_atom atom;
+	char *p;
+
+	for (d = 0; cxt->genealogy[d] != NULL; ++d)
+		if (cxt->genealogy[d] == node)
+			return d > 0 ? cxt->genealogy[d - 1] : NULL;
+
+	/* have to do it the hard way... */
+	p = ft_root_node(cxt);
+	d = 0;
+	while ((p = ft_next(cxt, p, &atom)) != NULL) {
+		switch (atom.tag) {
+		case OF_DT_BEGIN_NODE:
+			cxt->genealogy[d] = atom.data;
+			if (node == atom.data) {
+				/* found it */
+				cxt->genealogy[d + 1] = NULL;
+				return d > 0 ? cxt->genealogy[d - 1] : NULL;
+			}
+			++d;
+			break;
+		case OF_DT_END_NODE:
+			--d;
+			break;
+		}
+	}
+	return NULL;
+}
+
+void *ft_get_parent(struct ft_cxt *cxt, const void *phandle)
+{
+	void *node = ft_node_ph2node(cxt, phandle);
+	if (node == NULL)
+		return NULL;
+
+	node = __ft_get_parent(cxt, node);
+	return ft_get_phandle(cxt, node);
+}
+
+static const void *__ft_get_prop(struct ft_cxt *cxt, void *node,
+                                 const char *propname, unsigned int *len)
+{
+	struct ft_atom atom;
+	int depth = 0;
+
+	while ((node = ft_next(cxt, node, &atom)) != NULL) {
+		switch (atom.tag) {
+		case OF_DT_BEGIN_NODE:
+			++depth;
+			break;
+
+		case OF_DT_PROP:
+			if (depth != 1 || strcmp(atom.name, propname))
+				break;
+
+			if (len)
+				*len = atom.size;
+
+			return atom.data;
+
+		case OF_DT_END_NODE:
+			if (--depth <= 0)
+				return NULL;
+		}
+	}
+
+	return NULL;
+}
+
+int ft_get_prop(struct ft_cxt *cxt, const void *phandle, const char *propname,
+		void *buf, const unsigned int buflen)
+{
+	const void *data;
+	unsigned int size;
+
+	void *node = ft_node_ph2node(cxt, phandle);
+	if (!node)
+		return -1;
+
+	data = __ft_get_prop(cxt, node, propname, &size);
+	if (data) {
+		unsigned int clipped_size = min(size, buflen);
+		memcpy(buf, data, clipped_size);
+		return size;
+	}
+
+	return -1;
+}
+
+void *__ft_find_node_by_prop_value(struct ft_cxt *cxt, void *prev,
+                                   const char *propname, const char *propval,
+                                   unsigned int proplen)
+{
+	struct ft_atom atom;
+	char *p = ft_root_node(cxt);
+	char *next;
+	int past_prev = prev ? 0 : 1;
+	int depth = -1;
+
+	while ((next = ft_next(cxt, p, &atom)) != NULL) {
+		const void *data;
+		unsigned int size;
+
+		switch (atom.tag) {
+		case OF_DT_BEGIN_NODE:
+			depth++;
+
+			if (prev == p) {
+				past_prev = 1;
+				break;
+			}
+
+			if (!past_prev || depth < 1)
+				break;
+
+			data = __ft_get_prop(cxt, p, propname, &size);
+			if (!data || size != proplen)
+				break;
+			if (memcmp(data, propval, size))
+				break;
+
+			return p;
+
+		case OF_DT_END_NODE:
+			if (depth-- == 0)
+				return NULL;
+
+			break;
+		}
+
+		p = next;
+	}
+
+	return NULL;
+}
+
+void *ft_find_node_by_prop_value(struct ft_cxt *cxt, const void *prev,
+                                 const char *propname, const char *propval,
+                                 int proplen)
+{
+	void *node = NULL;
+
+	if (prev) {
+		node = ft_node_ph2node(cxt, prev);
+
+		if (!node)
+			return NULL;
+	}
+
+	node = __ft_find_node_by_prop_value(cxt, node, propname,
+	                                    propval, proplen);
+	return ft_get_phandle(cxt, node);
+}
+
+int ft_set_prop(struct ft_cxt *cxt, const void *phandle, const char *propname,
+		const void *buf, const unsigned int buflen)
+{
+	struct ft_atom atom;
+	void *node;
+	char *p, *next;
+	int nextra;
+
+	node = ft_node_ph2node(cxt, phandle);
+	if (node == NULL)
+		return -1;
+
+	next = ft_next(cxt, node, &atom);
+	if (atom.tag != OF_DT_BEGIN_NODE)
+		/* phandle didn't point to a node */
+		return -1;
+	p = next;
+
+	while ((next = ft_next(cxt, p, &atom)) != NULL) {
+		switch (atom.tag) {
+		case OF_DT_BEGIN_NODE: /* properties must go before subnodes */
+		case OF_DT_END_NODE:
+			/* haven't found the property, insert here */
+			cxt->p = p;
+			return ft_prop(cxt, propname, buf, buflen);
+		case OF_DT_PROP:
+			if (strcmp(atom.name, propname))
+				break;
+			/* found an existing property, overwrite it */
+			nextra = _ALIGN(buflen, 4) - _ALIGN(atom.size, 4);
+			cxt->p = atom.data;
+			if (nextra && !ft_make_space(cxt, &cxt->p, FT_STRUCT,
+						nextra))
+				return -1;
+			*(u32 *) (cxt->p - 8) = cpu_to_be32(buflen);
+			ft_put_bin(cxt, buf, buflen);
+			return 0;
+		}
+		p = next;
+	}
+	return -1;
+}
+
+int ft_del_prop(struct ft_cxt *cxt, const void *phandle, const char *propname)
+{
+	struct ft_atom atom;
+	void *node;
+	char *p, *next;
+	int size;
+
+	node = ft_node_ph2node(cxt, phandle);
+	if (node == NULL)
+		return -1;
+
+	p = node;
+	while ((next = ft_next(cxt, p, &atom)) != NULL) {
+		switch (atom.tag) {
+		case OF_DT_BEGIN_NODE:
+		case OF_DT_END_NODE:
+			return -1;
+		case OF_DT_PROP:
+			if (strcmp(atom.name, propname))
+				break;
+			/* found the property, remove it */
+			size = 12 + -_ALIGN(atom.size, 4);
+			cxt->p = p;
+			if (!ft_make_space(cxt, &cxt->p, FT_STRUCT, -size))
+				return -1;
+			return 0;
+		}
+		p = next;
+	}
+	return -1;
+}
+
+void *ft_create_node(struct ft_cxt *cxt, const void *parent, const char *name)
+{
+	struct ft_atom atom;
+	char *p, *next;
+	int depth = 0;
+
+	if (parent) {
+		p = ft_node_ph2node(cxt, parent);
+		if (!p)
+			return NULL;
+	} else {
+		p = ft_root_node(cxt);
+	}
+
+	while ((next = ft_next(cxt, p, &atom)) != NULL) {
+		switch (atom.tag) {
+		case OF_DT_BEGIN_NODE:
+			++depth;
+			if (depth == 1 && strcmp(atom.name, name) == 0)
+				/* duplicate node name, return error */
+				return NULL;
+			break;
+		case OF_DT_END_NODE:
+			--depth;
+			if (depth > 0)
+				break;
+			/* end of node, insert here */
+			cxt->p = p;
+			ft_begin_node(cxt, name);
+			ft_end_node(cxt);
+			return p;
+		}
+		p = next;
+	}
+	return NULL;
+}
diff --git a/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree.h b/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree.h
new file mode 100644
index 0000000..cb26325
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree.h
@@ -0,0 +1,113 @@
+/*
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#ifndef FLATDEVTREE_H
+#define FLATDEVTREE_H
+
+#include "flatdevtree_env.h"
+
+/* Definitions used by the flattened device tree */
+#define OF_DT_HEADER            0xd00dfeed      /* marker */
+#define OF_DT_BEGIN_NODE        0x1     /* Start of node, full name */
+#define OF_DT_END_NODE          0x2     /* End node */
+#define OF_DT_PROP              0x3     /* Property: name off, size, content */
+#define OF_DT_NOP               0x4     /* nop */
+#define OF_DT_END               0x9
+
+#define OF_DT_VERSION           0x10
+
+struct boot_param_header {
+	u32 magic;              /* magic word OF_DT_HEADER */
+	u32 totalsize;          /* total size of DT block */
+	u32 off_dt_struct;      /* offset to structure */
+	u32 off_dt_strings;     /* offset to strings */
+	u32 off_mem_rsvmap;     /* offset to memory reserve map */
+	u32 version;            /* format version */
+	u32 last_comp_version;  /* last compatible version */
+	/* version 2 fields below */
+	u32 boot_cpuid_phys;    /* Physical CPU id we're booting on */
+	/* version 3 fields below */
+	u32 dt_strings_size;    /* size of the DT strings block */
+};
+
+struct ft_reserve {
+	u64 start;
+	u64 len;
+};
+
+struct ft_region {
+	char *start;
+	unsigned long size;
+};
+
+enum ft_rgn_id {
+	FT_RSVMAP,
+	FT_STRUCT,
+	FT_STRINGS,
+	FT_N_REGION
+};
+
+#define FT_MAX_DEPTH	50
+
+struct ft_cxt {
+	struct boot_param_header *bph;
+	int max_size;           /* maximum size of tree */
+	int isordered;		/* everything in standard order */
+	void *(*realloc)(void *, unsigned long);
+	char *str_anchor;
+	char *p;		/* current insertion point in structs */
+	struct ft_region rgn[FT_N_REGION];
+	void *genealogy[FT_MAX_DEPTH+1];
+	char **node_tbl;
+	unsigned int node_max;
+	unsigned int nodes_used;
+};
+
+int ft_begin_node(struct ft_cxt *cxt, const char *name);
+void ft_end_node(struct ft_cxt *cxt);
+
+void ft_begin_tree(struct ft_cxt *cxt);
+void ft_end_tree(struct ft_cxt *cxt);
+
+void ft_nop(struct ft_cxt *cxt);
+int ft_prop(struct ft_cxt *cxt, const char *name,
+	    const void *data, unsigned int sz);
+int ft_prop_str(struct ft_cxt *cxt, const char *name, const char *str);
+int ft_prop_int(struct ft_cxt *cxt, const char *name, unsigned int val);
+void ft_begin(struct ft_cxt *cxt, void *blob, unsigned int max_size,
+	      void *(*realloc_fn)(void *, unsigned long));
+int ft_open(struct ft_cxt *cxt, void *blob, unsigned int max_size,
+		unsigned int max_find_device,
+		void *(*realloc_fn)(void *, unsigned long));
+int ft_add_rsvmap(struct ft_cxt *cxt, u64 physaddr, u64 size);
+
+void ft_dump_blob(const void *bphp);
+void ft_merge_blob(struct ft_cxt *cxt, void *blob);
+void *ft_find_device(struct ft_cxt *cxt, const char *srch_path);
+void *ft_find_device_rel(struct ft_cxt *cxt, const void *top,
+                         const char *srch_path);
+void *ft_find_descendent(struct ft_cxt *cxt, void *top, const char *srch_path);
+int ft_get_prop(struct ft_cxt *cxt, const void *phandle, const char *propname,
+		void *buf, const unsigned int buflen);
+int ft_set_prop(struct ft_cxt *cxt, const void *phandle, const char *propname,
+		const void *buf, const unsigned int buflen);
+void *ft_get_parent(struct ft_cxt *cxt, const void *phandle);
+void *ft_find_node_by_prop_value(struct ft_cxt *cxt, const void *prev,
+                                 const char *propname, const char *propval,
+                                 int proplen);
+void *ft_create_node(struct ft_cxt *cxt, const void *parent, const char *name);
+
+#endif /* FLATDEVTREE_H */
diff --git a/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_env.h b/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_env.h
new file mode 100644
index 0000000..7b32975
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_env.h
@@ -0,0 +1,66 @@
+/*
+ * This file adds the header file glue so that the shared files
+ * flatdevicetree.[ch] can compile and work in the powerpc bootwrapper.
+ *
+ * strncmp & strchr copied from <file:lib/strings.c>
+ * Copyright (C) 1991, 1992  Linus Torvalds
+ *
+ * Maintained by: Mark A. Greer <mgreer@mvista.com>
+ */
+#ifndef _PPC_BOOT_FLATDEVTREE_ENV_H_
+#define _PPC_BOOT_FLATDEVTREE_ENV_H_
+
+#include <stdarg.h>
+#include <stddef.h>
+#include "types.h"
+#include <linux/string.h> 
+/* #include <stdio.h> */
+#include "ops.h"
+
+#ifndef be16_to_cpu
+#define be16_to_cpu(x)		(x)
+#endif
+
+#ifndef cpu_to_be16
+#define cpu_to_be16(x)		(x)
+#endif
+
+#ifndef be32_to_cpu 
+#define be32_to_cpu(x)		(x)
+#endif
+
+#ifndef cpu_to_be32
+#define cpu_to_be32(x)		(x)
+#endif 
+
+#ifndef be64_to_cpu
+#define be64_to_cpu(x)		(x)
+#endif
+
+#ifndef cpu_to_be64
+#define cpu_to_be64(x)		(x)
+#endif
+
+#if 0
+static inline int strncmp(const char *cs, const char *ct, size_t count)
+{
+	signed char __res = 0;
+
+	while (count) {
+		if ((__res = *cs - *ct++) != 0 || !*cs++)
+			break;
+		count--;
+	}
+	return __res;
+}
+
+static inline char *strchr(const char *s, int c)
+{
+	for (; *s != (char)c; ++s)
+		if (*s == '\0')
+			return NULL;
+	return (char *)s;
+}
+#endif
+
+#endif /* _PPC_BOOT_FLATDEVTREE_ENV_H_ */
diff --git a/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_misc.c b/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_misc.c
new file mode 100644
index 0000000..4341e65
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_misc.c
@@ -0,0 +1,73 @@
+/*
+ * This file does the necessary interface mapping between the bootwrapper
+ * device tree operations and the interface provided by shared source
+ * files flatdevicetree.[ch].
+ *
+ * Author: Mark A. Greer <mgreer@mvista.com>
+ *
+ * 2006 (c) MontaVista Software, Inc.  This file is licensed under
+ * the terms of the GNU General Public License version 2.  This program
+ * is licensed "as is" without any warranty of any kind, whether express
+ * or implied.
+ */
+#include <stddef.h>
+#include "flatdevtree.h"
+#include "ops.h"
+
+static struct ft_cxt cxt;
+
+static void *fdtm_finddevice(const char *name)
+{
+	return ft_find_device(&cxt, name);
+}
+
+static int fdtm_getprop(const void *phandle, const char *propname,
+                        void *buf, const int buflen)
+{
+	return ft_get_prop(&cxt, phandle, propname, buf, buflen);
+}
+
+static int fdtm_setprop(const void *phandle, const char *propname,
+                        const void *buf, const int buflen)
+{
+	return ft_set_prop(&cxt, phandle, propname, buf, buflen);
+}
+
+static void *fdtm_get_parent(const void *phandle)
+{
+	return ft_get_parent(&cxt, phandle);
+}
+
+static void *fdtm_create_node(const void *phandle, const char *name)
+{
+	return ft_create_node(&cxt, phandle, name);
+}
+
+static void *fdtm_find_node_by_prop_value(const void *prev,
+                                          const char *propname,
+                                          const char *propval,
+                                          int proplen)
+{
+	return ft_find_node_by_prop_value(&cxt, prev, propname,
+	                                  propval, proplen);
+}
+
+static unsigned long fdtm_finalize(void)
+{
+	ft_end_tree(&cxt);
+	return (unsigned long)cxt.bph;
+}
+
+int ft_init(void *dt_blob, unsigned int max_size, unsigned int max_find_device)
+{
+	dt_ops.finddevice = fdtm_finddevice;
+	dt_ops.getprop = fdtm_getprop;
+	dt_ops.setprop = fdtm_setprop;
+	dt_ops.get_parent = fdtm_get_parent;
+	dt_ops.create_node = fdtm_create_node;
+	dt_ops.find_node_by_prop_value = fdtm_find_node_by_prop_value;
+	dt_ops.finalize = fdtm_finalize;
+
+	return ft_open(&cxt, dt_blob, max_size, max_find_device,
+			platform_ops.realloc);
+}
diff --git a/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_utils.c b/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_utils.c
new file mode 100644
index 0000000..1201e3d
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/dtb/flatdevtree_utils.c
@@ -0,0 +1,814 @@
+/*********************************************************************
+
+  Copyright 2007-2008 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/init.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/phnx_loader.h>
+#include <asm/bootinfo.h>
+#include <asm/rmi/debug.h>
+#include <asm/rmi/config_net.h>
+#include <asm/rmi/rmi_srio.h>
+#include <asm/rmi/msgring.h>
+
+#include <stddef.h>
+#include "flatdevtree.h"
+#include "flatdevtree_env.h" 
+
+
+/* device tree */
+extern uint32_t dev_tree_en;
+#define DTB_ALLOC_BUF_SIZE (64 * 1024)
+extern unsigned char _dtb_start[], _dtb_end[];
+static __u8 dtb_alloc_buf[DTB_ALLOC_BUF_SIZE];
+
+struct boot_mem_map ftd_prom_map;
+struct platform_ops platform_ops;
+struct dt_ops dt_ops;
+#define XLR_MAX_PIC_TIMERS 8
+extern struct psb_info *rmi_boot_info;
+
+static char dom_name[32];
+
+
+extern int xlr_console_pci_con_dev, xlr_console_pci_con_baud, xlr_boot_over_nfs;
+
+
+int fdt_init(char *start, char *end)
+{
+		int rv;
+		void *devp;
+
+		if(!dev_tree_en)
+			return 0;
+
+		/* prom_dbg_msg("Fdt init start = 0x%lx, size = %d\n", 
+				(unsigned long)start, (int)(end - start)); */
+		simple_alloc_init(dtb_alloc_buf, DTB_ALLOC_BUF_SIZE, 32, 128);
+		if((rv = ft_init(start, end - start, 64)) != 0)
+			return rv;
+
+		if((devp = ((void *)finddevice("/"))) == NULL )
+			return -1;
+
+		if((getprop(devp, "domain", &dom_name, sizeof(dom_name))) == -1)
+			return -1;
+
+		return 0;
+}
+
+int fdt_add_console_string(char *cmdline)
+{
+    char fname[64];
+    char pval[64];
+    char str[100];
+    int len = 100;
+    uint32_t baud;
+    void *devp;
+    
+    snprintf(fname, sizeof(fname), "/%s", dom_name);
+    if((devp = ((void *)finddevice(fname))) == NULL)
+        goto err_exit;
+    if((getprop(devp, "console", pval, sizeof(pval))) == -1)
+        goto err_exit;
+
+    if (strncmp(pval, "vuart", strlen("vuart")) == 0) {
+        if(pval[5] == '\0')
+            snprintf(str, len, "console=%s%d", pval, hard_smp_processor_id());
+        else
+            snprintf(str, len, "console=%s", pval);
+    } else  if (strcmp(pval, "uart@0") == 0) {
+        if((devp = ((void *)finddevice("/uart@0"))) == NULL)
+            goto err_exit;
+        if((getprop(devp, "baudrate", &baud, sizeof(baud))) == -1)
+            goto err_exit;
+
+        snprintf(str, len, "console=ttyS0,%d", be32_to_cpu(baud));
+    } else  if (strcmp(pval, "uart@1") == 0)  {
+        if((devp = ((void *)finddevice("/uart@1"))) == NULL)
+            goto err_exit;
+        if((getprop(devp, "baudrate", &baud, sizeof(baud))) == -1)
+            goto err_exit;
+
+        snprintf(str, len, "console=ttyS1,%d", be32_to_cpu(baud));
+    } else
+        goto err_exit;
+
+    strcat(cmdline, str);
+    strcat(cmdline, " ");
+    return 0;
+
+    err_exit:
+        return -1;
+}
+
+uint64_t fdt_get_heap_size(void)
+{
+    uint64_t pval;
+    void *devp;
+    char fname[64];
+
+    snprintf(fname, sizeof(fname), "/%s", dom_name);
+    if((devp = ((void *)finddevice(fname))) == NULL)
+        return 0;
+    if((getprop(devp, "heap-size", &pval, sizeof(pval))) == -1)
+        return 0;
+
+    return be64_to_cpu(pval);
+}
+
+int fdt_get_uart_status(int uartno)
+{
+    char rname[64];
+	void *devp;
+
+    snprintf(rname, sizeof(rname), "/uart@%d", uartno);
+    if((devp = ((void *)finddevice(rname))) == NULL)
+        return -1;
+    return 0;
+}
+
+
+
+int fdt_get_msgring_int_status(int core, uint32_t *en)
+{
+	void *devp;
+	char fname[64];
+	unsigned int dtb_rd;
+
+	*en = 0;
+
+	snprintf(fname, sizeof(fname), "/core-fmn-stations/fmn-station@%d", core);
+	if((devp = ((void *)finddevice(fname))) != NULL ) {
+			if((getprop(devp, "int-enable", &dtb_rd, sizeof(dtb_rd))) != -1)
+				*en = be32_to_cpu(dtb_rd);
+			else
+				return -1;
+	} else
+		return -1;
+	return 0;
+}	
+	
+int fdt_get_core_bucket_conf(int core, char buckets[], int bklen, char credits[][8], int crlen)
+{
+	char fname[64];
+	void *devp;
+
+	snprintf(fname, sizeof(fname), "/core-fmn-stations/fmn-station@%d", core);
+	if((devp = ((void *)finddevice(fname))) != NULL ) {
+			if((getprop(devp, "bucket-sizes", buckets, bklen)) == -1)
+				return -1;
+			
+			if((getprop(devp, "credit-sizes", (void *)credits, crlen)) == -1)
+				return -1;
+	} else
+		return -1;
+
+	return 0;
+}
+
+/* XLS gmac has 2 controllers , so there are 2 seprate msgring stations for GMAC */
+int fdt_get_gmac_bucket_conf(int gmac_id, bucket_t buckets[], int bklen, bucket_t credits[], int crlen)
+{
+	void *devp;
+	char bkts[MAX_NUM_MSGRNG_STN_CC];
+	int i;
+	char fname[32];
+
+	for(i = 0; i < bklen; i++)
+		buckets[i] = 0;
+
+	for(i = 0; i < crlen; i++)
+		credits[i] = 0;
+
+	if(bklen > MAX_NUM_MSGRNG_STN_CC || crlen > MAX_NUM_MSGRNG_STN_CC)
+		return -1;
+
+	snprintf(fname, sizeof(fname), "/gmac@%d", gmac_id);
+	if((devp = ((void *)finddevice(fname))) != NULL ) {
+			
+		if((getprop(devp, "bucket-sizes", bkts, bklen)) == -1)
+			return -1;
+
+		for(i = 0; i < bklen; i++) 
+			buckets[i] = bkts[i];
+			
+		if((getprop(devp, "credit-sizes", (void *)bkts, crlen)) == -1)
+			return -1;
+		for(i = 0; i < crlen; i++) 
+			credits[i] = bkts[i];
+	} else
+		return -1;
+
+	return 0;
+}
+
+int fdt_get_xgmac_bucket_conf(int instance, bucket_t buckets[], int bklen, bucket_t credits[], int crlen)
+{
+	char fname[32];
+	void *devp;
+	char bkts[MAX_NUM_MSGRNG_STN_CC];
+	int i;
+
+	for(i = 0; i < bklen; i++)
+		buckets[i] = 0;
+
+	for(i = 0; i < crlen; i++)
+		credits[i] = 0;
+
+
+	if(bklen > MAX_NUM_MSGRNG_STN_CC || crlen > MAX_NUM_MSGRNG_STN_CC)
+		return -1;
+
+	snprintf(fname, sizeof(fname), "/xgmac@%d", instance);
+	if((devp = ((void *)finddevice(fname))) != NULL ) {
+		if((getprop(devp, "bucket-sizes", bkts, bklen)) == -1)
+			return -1;
+		for(i = 0; i < bklen; i++) 
+			buckets[i] = bkts[i];
+
+		if((getprop(devp, "credit-sizes", (void *)bkts, crlen)) == -1)
+			return -1;
+		for(i = 0; i < crlen; i++) 
+			credits[i] = bkts[i];
+
+	} else
+		return -1;
+
+	return 1;
+}
+
+int fdt_get_gmac_ppties(unsigned int *gmac_list, unsigned long *gmac_addr, int *gmac_own)
+{
+	unsigned int online_map = 0x0;
+	void *devp;
+	int i;
+	char name[32];
+	uint32_t value[2];
+
+	*gmac_own = 0;
+
+    /* get the gmac list */
+	for(i = 0; i < PHOENIX_MAX_MACS; i++) {
+		snprintf(name, sizeof(name), "/gmac@%d", i);
+		if((devp = ((void *)finddevice(name))) != NULL ) {
+			if((getprop(devp, "reg", (void *)value, sizeof(value))) != -1) {
+				gmac_addr[i] = (long)(int)value[0];
+				online_map |= (1 << i);
+			}
+			if((getprop(devp, "owned", (void *)value, sizeof(value))) != -1) {
+				*gmac_own |= (value[0] << i);
+			}
+		}
+	} 
+
+	*gmac_list =  online_map;
+	/*if(online_map)
+		printk("Gmac online map = 0x%x, own=%d \n",	online_map,  *gmac_own);*/
+	return 0;
+}
+
+int fdt_get_xgmac_ppties(int port, unsigned int *gmac_list, unsigned long *gmac_addr, int *gmac_own)
+{
+	unsigned int online_map = 0x0;
+	void *devp;
+	char name[32];
+	uint32_t value[2];
+
+    /* get the gmac list */
+	online_map = 0x0;
+	*gmac_own = 0;
+
+	snprintf(name, sizeof(name), "/xgmac@%d", port);
+	if((devp = ((void *)finddevice(name))) != NULL) {
+		online_map = 1;
+		if((getprop(devp, "reg", (void *)value, sizeof(value))) != -1)
+			*gmac_addr = (long)(int)value[0];
+
+		if((getprop(devp, "owned", (void *)value, sizeof(value))) != -1) 
+			*gmac_own  = value[0];
+	} 
+
+	*gmac_list =  online_map;
+	/*if(online_map)
+		printk("XGmac %d  own=%d\n", port, *gmac_own);*/
+	return 0;
+}
+
+int fdt_get_spi4_ppties(int slot, unsigned int *spi4_list, unsigned long *spi4_addr, int *spi4_own)
+{
+	unsigned int online_map = 0x0;
+	void *devp;
+	char name[32];
+	uint32_t value[2];
+
+    /* get the gmac list */
+	online_map = 0x0;
+	*spi4_own = 0;
+
+	snprintf(name, sizeof(name), "/spi4@%d", slot);
+	if((devp = ((void *)finddevice(name))) != NULL) {
+		online_map = 1;
+		if((getprop(devp, "reg", (void *)value, sizeof(value))) != -1)
+			*spi4_addr = (long)(int)value[0];
+		if((getprop(devp, "owned", (void *)value, sizeof(value))) != -1) 
+			*spi4_own  = value[0];
+	}
+
+	*spi4_list =  online_map;
+	/*if(online_map)
+		printk("spi4 %d own=%d\n", slot, *spi4_own);*/
+	return 0;
+}
+
+int fdt_get_spi4_bucket_conf(int instance, bucket_t buckets[], int bklen, bucket_t credits[], int crlen)
+{
+	char fname[32];
+	void *devp;
+	char bkts[MAX_NUM_MSGRNG_STN_CC];
+	int i;
+
+	for(i = 0; i < bklen; i++)
+		buckets[i] = 0;
+
+	for(i = 0; i < crlen; i++)
+		credits[i] = 0;
+
+
+	if(bklen > MAX_NUM_MSGRNG_STN_CC || crlen > MAX_NUM_MSGRNG_STN_CC)
+		return -1;
+
+	snprintf(fname, sizeof(fname), "/spi4@%d", instance);
+	if((devp = ((void *)finddevice(fname))) != NULL ) {
+		if((getprop(devp, "bucket-sizes", bkts, bklen)) == -1)
+			return -1;
+		for(i = 0; i < bklen; i++) 
+			buckets[i] = bkts[i];
+
+		if((getprop(devp, "credit-sizes", (void *)bkts, crlen)) == -1)
+			return -1;
+		for(i = 0; i < crlen; i++) 
+			credits[i] = bkts[i];
+
+	} else
+		return -1;
+
+	return 0;
+}
+
+uint64_t fdt_get_vuart_fifo_addr(int tx, int instance)
+{
+    char fname[64];
+    void *devp;
+    uint64_t addr;
+
+    if(tx)
+        snprintf(fname, sizeof(fname), "/vuart/txfifo@%d", instance);
+    else
+        snprintf(fname, sizeof(fname), "/vuart/rxfifo@%d", instance);
+
+    if((devp = ((void *)finddevice(fname))) != NULL ) {
+        if((getprop(devp, "reg", &addr, sizeof(addr))) == -1)
+            return 0;
+        return be64_to_cpu(addr);
+    }
+    return 0;
+}
+
+
+int fdt_get_bucketmask(uint64_t *bucket_mask)
+{
+	void *devp;
+	uint64_t value;
+
+	if((devp = ((void *)finddevice("/cpus"))) != NULL ) {
+			if((getprop(devp, "bucketmap", &value, sizeof(value))) <= 0)
+				return -1;
+	} else
+		return -1;
+	*bucket_mask = be64_to_cpu(value);
+	return 1;
+}
+
+int fdt_get_pci_ht_map(int *pci_map, int *ht_map)
+{
+	void *devp;
+
+	*pci_map = 0;
+	*ht_map = 0;
+
+	if((devp = ((void *)finddevice("/pci"))) != NULL )
+			*pci_map = 1;
+
+	if((devp = ((void *)finddevice("/ht"))) != NULL )
+			*ht_map = 1;
+	
+	return 1;
+}
+
+int fdt_get_xaui_ppties(int port, unsigned int *xaui_list, unsigned long *xaui_addr, int *xaui_own)
+{
+	unsigned int online_map = 0x0;
+	void *devp;
+	char name[32];
+	uint32_t value[2];
+
+    /* get the gmac list */
+	online_map = 0x0;
+	*xaui_own = 0;
+
+	snprintf(name, sizeof(name), "/xaui@%d", port);
+	if((devp = ((void *)finddevice(name))) != NULL) {
+		online_map = 1;
+		if((getprop(devp, "reg", (void *)value, sizeof(value))) != -1)
+			*xaui_addr = (long)(int)value[0];
+
+		if((getprop(devp, "owned", (void *)value, sizeof(value))) != -1) 
+			*xaui_own  = value[0];
+	} 
+
+	*xaui_list =  online_map;
+	if(online_map)
+		printk("xaui %d  own=%d\n", port, *xaui_own);
+	return 0;
+}
+
+int fdt_get_xaui_bucket_conf(int instance, bucket_t buckets[], int bklen, bucket_t credits[], int crlen)
+{
+	char fname[32];
+	void *devp;
+	char bkts[MAX_NUM_MSGRNG_STN_CC];
+	int i;
+
+	for(i = 0; i < bklen; i++)
+		buckets[i] = 0;
+
+	for(i = 0; i < crlen; i++)
+		credits[i] = 0;
+
+
+	if(bklen > MAX_NUM_MSGRNG_STN_CC || crlen > MAX_NUM_MSGRNG_STN_CC)
+		return -1;
+
+	snprintf(fname, sizeof(fname), "/xaui@%d", instance);
+	if((devp = ((void *)finddevice(fname))) != NULL ) {
+		if((getprop(devp, "bucket-sizes", bkts, bklen)) == -1)
+			return -1;
+		for(i = 0; i < bklen; i++) 
+			buckets[i] = bkts[i];
+
+		if((getprop(devp, "credit-sizes", (void *)bkts, crlen)) == -1)
+			return -1;
+		for(i = 0; i < crlen; i++) 
+			credits[i] = bkts[i];
+
+	} else
+		return -1;
+
+	return 0;
+}
+
+int fdt_get_cde_enabled(void)
+{
+        return finddevice("/cde") != NULL;
+}
+
+int fdt_get_sae_enabled(void)
+{
+        return finddevice("/sae") != NULL;
+}
+
+int fdt_get_usb_enabled(void)
+{
+	return finddevice("/usb") != NULL;
+}
+
+int fdt_get_flash_enabled(void)
+{
+	return finddevice("/flash") != NULL;
+}
+
+int fdt_get_i2c_enabled(int instance)
+{
+	char fname[20];
+	snprintf(fname, sizeof(fname), "/i2c@%d", instance);
+	return finddevice(fname) != NULL;
+}
+
+int fdt_get_srio_port_map(uint32_t *srio_port_map)
+{
+	char name[32];
+	int i;
+	void *devp;
+
+	*srio_port_map = 0;
+	for(i = 0; i < MAX_SRIO_PORTS; i++) {
+		snprintf(name, sizeof(name), "/srio@%d", i);
+		if((devp = ((void *)finddevice(name))) != NULL ) 
+			*srio_port_map = *srio_port_map | ( 1 << i);
+	}
+	printk("DTB: Srio ports = 0x%x\n", *srio_port_map);
+	return 0;
+}
+
+int fdt_get_pic_timer_map(unsigned int *timer_list, int max)
+{
+	void *devp;
+	int i, timer_cnt = 0;
+	char name[32];
+	
+
+	*timer_list = 0;
+
+    /* get the gmac list */
+	for(i = 0; i < max; i++) {
+		snprintf(name, sizeof(name), "/pic-timer@%d", i);
+		if((devp = ((void *)finddevice(name))) != NULL ) {
+				*timer_list |= 1 << i;
+				timer_cnt++;
+		}
+	} 
+
+	//printk("Pic timer list = 0x%x\n", *timer_list);
+	return timer_cnt;
+}
+
+int fdt_is_gmac0_in_sgmii(void)
+{
+	int value = -1;
+	void *devp;
+
+    /* get the gmac list */
+	if((devp = ((void *)finddevice("/gmac@0"))) != NULL ) {
+		if((getprop(devp, "phy-mode-sgmii", (void *)&value, sizeof(value))) == -1) {
+			printk("Error in getting gmac0 mode\n");
+			return -1;
+		}
+	}	
+	return value;
+}
+
+
+#define TLB_SZ_64 1
+#define TLB_SZ_32 2
+#define TLB_SZ_16 3
+
+int fdt_get_core_tlb_size(int core)
+{
+	/* 1 for 64, 2 for 32 and 3 for 16 (default) */
+	return TLB_SZ_16;
+}
+
+void rmi_dev_config_net(void)
+{
+	extern struct net_device_cfg phnx_net_dev_cfg;
+	struct net_device_cfg *net_dev = &phnx_net_dev_cfg;
+	unsigned long gmac_addr[PHOENIX_MAX_MACS], port_addr;
+	unsigned int port_list = 0x0, port_own;
+	int i, type_xgmac  = 0, tx_stcnt;
+	bucket_t buckets[MAX_NUM_MSGRNG_STN_CC], credits[MAX_NUM_MSGRNG_STN_CC];
+
+	if(fdt_get_gmac_ppties(&port_list, gmac_addr, &port_own) == 0) {
+		for (i = 0; i < PHOENIX_MAX_GMACS; i++) {
+			if(!(port_list & ( 1 << i))) {
+				net_dev->gmac_port[i].cfg_flag = 0;
+				continue;
+			}
+			/* It is called after linux init net_dev structure. 
+                It initialize all the gmac, xgmac and spi4 . We will not 
+                enable a port if linux config_net_init disabled it. */
+			if(net_dev->gmac_port[i].cfg_flag == 0)
+				continue;
+
+			if(i == 0) {
+				if(fdt_is_gmac0_in_sgmii() == 1)
+					net_dev->gmac_port[0].phy_mode = 
+						(net_dev->gmac_port[0].phy_mode & PHY_MODE_SELECTABLE) | PHY_MODE_SGMII;
+				else
+					net_dev->gmac_port[0].phy_mode = 
+						(net_dev->gmac_port[0].phy_mode & PHY_MODE_SELECTABLE) | PHY_MODE_RGMII;
+
+				net_dev->gmac_port[0].phy_addr = phnx_get_phy_info(0, 
+						net_dev->gmac_port[0].phy_mode, 
+						&net_dev->gmac_port[0].mii_addr, 
+						&net_dev->gmac_port[0].pcs_addr, 
+						&net_dev->gmac_port[0].serdes_addr);
+			}
+
+			net_dev->gmac_port[i].config_pde = 0;
+			net_dev->gmac_port[i].mmio_addr = gmac_addr[i];
+			if((!(port_own & ( 1 << i))) && (net_dev->gmac_port[i].cfg_flag == PORT_OWN_LINUX)) 
+				net_dev->gmac_port[i].cfg_flag = PHNX_PORT_ATTACH;
+			
+
+			fdt_get_gmac_bucket_conf(i, buckets, MAX_NUM_GMAC_STNS, 
+						credits, MAX_NUM_MSGRNG_STN_CC);
+
+			if(net_dev->gmac_port[i].bucket != 0)
+				memcpy(net_dev->gmac_port[i].bucket, 
+						buckets, sizeof(bucket_t) * MAX_NUM_GMAC_STNS);
+			if(net_dev->gmac_port[i].credit != 0)
+					memcpy(net_dev->gmac_port[i].credit, 
+						credits, sizeof(bucket_t) * MAX_NUM_MSGRNG_STN_CC);
+		}
+	}
+
+	for (i = 0; i < PHOENIX_MAX_XAUIS; i++) {
+		int gmac_idx;
+		/* Set the phy mode and bucket config only. It is same as gmac config */
+		if(fdt_get_xaui_ppties(i, &port_list, &port_addr, &port_own) != 0)
+			continue;
+		if(port_list == 0)
+			continue;
+	
+		gmac_idx = i * PHOENIX_GMAC_PORTS_PER_CTRL;
+
+		net_dev->gmac_port[gmac_idx].phy_mode = PHY_MODE_XAUI;
+		if((port_own == 0) && (net_dev->gmac_port[gmac_idx].cfg_flag == PORT_OWN_LINUX))
+			net_dev->gmac_port[gmac_idx].cfg_flag = PHNX_PORT_ATTACH;
+
+		fdt_get_xaui_bucket_conf(i, buckets, MAX_NUM_GMAC_STNS, 
+						credits, MAX_NUM_MSGRNG_STN_CC);
+	    if(net_dev->gmac_port[gmac_idx].bucket != 0) 
+			memcpy(net_dev->gmac_port[gmac_idx].bucket,  
+                        buckets, sizeof(bucket_t) * MAX_NUM_GMAC_STNS); 
+        if(net_dev->gmac_port[gmac_idx].credit != 0) 
+			memcpy(net_dev->gmac_port[gmac_idx].credit,  
+	                    credits, sizeof(bucket_t) * MAX_NUM_MSGRNG_STN_CC); 
+
+	}
+
+	for (i = 0; i < PHOENIX_MAX_XGMACS; i++) {
+		if(fdt_get_xgmac_ppties(i, &port_list, &port_addr, &port_own) != 0)
+			continue;
+		type_xgmac = 1;
+		if(port_list == 0) {
+			if(fdt_get_spi4_ppties(i, &port_list, &port_addr, &port_own) != 0)
+				continue;
+			if(port_list == 0) {
+				net_dev->xgs_port[i].cfg_flag = 0;
+				continue;
+			}
+			type_xgmac = 0;
+		}
+
+		net_dev->xgs_port[i].config_pde = 0;
+		net_dev->xgs_port[i].mmio_addr = port_addr;
+		if((port_own == 0) && (net_dev->xgs_port[i].cfg_flag == PORT_OWN_LINUX))
+			net_dev->xgs_port[i].cfg_flag = PHNX_PORT_ATTACH;
+
+		/* fill the bucket and credit info */
+		if(type_xgmac == 1) 
+			fdt_get_xgmac_bucket_conf(i, buckets, MAX_NUM_XGMAC_STNS, 
+						credits, MAX_NUM_MSGRNG_STN_CC);
+		else
+			fdt_get_spi4_bucket_conf(i, buckets, MAX_NUM_XGMAC_STNS, 
+						credits, MAX_NUM_MSGRNG_STN_CC);
+		
+		tx_stcnt = (MSGRNG_STNID_XMAC0_15_TX - MSGRNG_STNID_XMAC0_00_TX) + 1;
+		if(i== 0) {
+			if(net_dev->xgs_port[i].bucket != 0) {
+				memcpy(&net_dev->xgs_port[i].bucket[MSGRNG_STNID_XGS0_TX], 
+					buckets, sizeof(bucket_t) * tx_stcnt);
+				memcpy(&net_dev->xgs_port[i].bucket[MSGRNG_STNID_XGS0FR], 
+					&buckets[tx_stcnt], sizeof(bucket_t) * (MAX_NUM_XGMAC_STNS - tx_stcnt));
+			}
+		} else if(i == 1) {
+			if(net_dev->xgs_port[i].bucket != 0) { 
+				memcpy(&net_dev->xgs_port[i].bucket[MSGRNG_STNID_XGS1_TX], 
+					buckets, sizeof(bucket_t) * tx_stcnt); 
+				memcpy(&net_dev->xgs_port[i].bucket[MSGRNG_STNID_XGS1FR],
+					&buckets[tx_stcnt], sizeof(bucket_t) * (MAX_NUM_XGMAC_STNS - tx_stcnt));
+			}
+		}
+		if(net_dev->xgs_port[i].credit != 0)
+			memcpy(net_dev->xgs_port[i].credit, credits,
+				sizeof(bucket_t) * MAX_NUM_MSGRNG_STN_CC);
+
+	}
+	return;
+}
+
+int fdt_get_gmac_pde_reginfo(int id, uint64_t *pde_bkt_map)
+{
+    int value = 0;
+	void *devp;
+    char name[32];
+
+    snprintf(name, sizeof(name), "/gmac@%d", id);
+    /* get the gmac list */
+	if((devp = ((void *)finddevice(name))) != NULL ) {
+		if((getprop(devp, "pde-reginfo", &value, sizeof(value))) == -1)
+			return value;
+		if((getprop(devp, "pde-bkt-map", pde_bkt_map, sizeof(*pde_bkt_map))) == -1)
+			return value;
+
+	} else {
+		if(id == PHOENIX_GMAC_PORTS_PER_CTRL) 
+			id = 1;
+		
+    	snprintf(name, sizeof(name), "/xaui@%d", id);
+		if((devp = ((void *)finddevice(name))) != NULL ) {
+			if((getprop(devp, "pde-reginfo", &value, sizeof(value))) == -1)
+				return value;
+			if((getprop(devp, "pde-bkt-map", pde_bkt_map, sizeof(*pde_bkt_map))) == -1)
+				return value;
+		}
+	}
+	return value;
+}
+
+int fdt_get_xgmac_pde_reginfo(int id, uint64_t *pde_bkt_map)
+{
+    int value = 0;
+	void *devp;
+    char name[32];
+
+    snprintf(name, sizeof(name), "/xgmac@%d", id);
+    /* get the gmac list */
+	if((devp = ((void *)finddevice(name))) != NULL ) {
+		if((getprop(devp, "pde-reginfo", &value, sizeof(value))) == -1)
+			return value;
+
+		if((getprop(devp, "pde-bkt-map", pde_bkt_map, sizeof(*pde_bkt_map))) == -1)
+			return value;
+	}
+	return value;
+}
+
+int fdt_get_spi4_pde_reginfo(int id, uint64_t *pde_bkt_map)
+{
+    int value = 0;
+	void *devp;
+    char name[32];
+
+    snprintf(name, sizeof(name), "/spi4@%d", id);
+    /* get the gmac list */
+	if((devp = ((void *)finddevice(name))) != NULL ) {
+		if((getprop(devp, "pde-reginfo", &value, sizeof(value))) == -1)
+			return value;
+
+		if((getprop(devp, "pde-bkt-map", pde_bkt_map, sizeof(*pde_bkt_map))) == -1)
+			return value;
+	}
+	return value;
+}
+
+int fdt_get_sae_bucket_conf(char buckets[], int bklen, char credits[][8], int crlen)
+{
+	void *devp;
+
+	if((devp = ((void *)finddevice("/sae"))) != NULL ) {
+			if((getprop(devp, "bucket-sizes", buckets, bklen)) == -1)
+				return -1;
+			
+			if((getprop(devp, "credit-sizes", (void *)credits, crlen)) == -1)
+				return -1;
+	} else
+		return -1;
+
+	return 0;
+}
+
+int fdt_get_cde_bucket_conf(char buckets[], int bklen, char credits[][8], int crlen)
+{
+	void *devp;
+
+	if((devp = ((void *)finddevice("/cde"))) != NULL ) {
+			if((getprop(devp, "bucket-sizes", buckets, bklen)) == -1)
+				return -1;
+			
+			if((getprop(devp, "credit-sizes", (void *)credits, crlen)) == -1)
+				return -1;
+	} else
+		return -1;
+
+	return 0;
+}
diff --git a/arch/mips/rmi/ptr/rmicrf/dtb/ops.h b/arch/mips/rmi/ptr/rmicrf/dtb/ops.h
new file mode 100644
index 0000000..05a96b2
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/dtb/ops.h
@@ -0,0 +1,192 @@
+/*
+ * Global definition of all the bootwrapper operations.
+ *
+ * Author: Mark A. Greer <mgreer@mvista.com>
+ *
+ * 2006 (c) MontaVista Software, Inc.  This file is licensed under
+ * the terms of the GNU General Public License version 2.  This program
+ * is licensed "as is" without any warranty of any kind, whether express
+ * or implied.
+ */
+#ifndef _PPC_BOOT_OPS_H_
+#define _PPC_BOOT_OPS_H_
+
+#include <stddef.h>
+#include "types.h"
+#include "linux/string.h"
+
+/* #define	COMMAND_LINE_SIZE	512 */
+#define	MAX_PATH_LEN		256
+#define	MAX_PROP_LEN		256 /* What should this be? */
+
+/* Platform specific operations */
+struct platform_ops {
+	void	(*fixups)(void);
+	void	(*image_hdr)(const void *);
+	void *	(*malloc)(unsigned long size);
+	void	(*free)(void *ptr);
+	void *	(*realloc)(void *ptr, unsigned long size);
+	void	(*exit)(void);
+	void *	(*vmlinux_alloc)(unsigned long size);
+};
+extern struct platform_ops platform_ops;
+
+/* Device Tree operations */
+struct dt_ops {
+	void *	(*finddevice)(const char *name);
+	int	(*getprop)(const void *phandle, const char *name, void *buf,
+			const int buflen);
+	int	(*setprop)(const void *phandle, const char *name,
+			const void *buf, const int buflen);
+	void *(*get_parent)(const void *phandle);
+	/* The node must not already exist. */
+	void *(*create_node)(const void *parent, const char *name);
+	void *(*find_node_by_prop_value)(const void *prev,
+	                                 const char *propname,
+	                                 const char *propval, int proplen);
+	unsigned long (*finalize)(void);
+};
+extern struct dt_ops dt_ops;
+
+/* Console operations */
+struct console_ops {
+	int	(*open)(void);
+	void	(*write)(char *buf, int len);
+	void	(*edit_cmdline)(char *buf, int len);
+	void	(*close)(void);
+	void	*data;
+};
+extern struct console_ops console_ops;
+
+/* Serial console operations */
+struct serial_console_data {
+	int		(*open)(void);
+	void		(*putc)(unsigned char c);
+	unsigned char	(*getc)(void);
+	u8		(*tstc)(void);
+	void		(*close)(void);
+};
+
+struct loader_info {
+	void *promptr;
+	unsigned long initrd_addr, initrd_size;
+	char *cmdline;
+	int cmdline_len;
+};
+extern struct loader_info loader_info;
+
+void start(void);
+int ft_init(void *dt_blob, unsigned int max_size, unsigned int max_find_device);
+int serial_console_init(void);
+int ns16550_console_init(void *devp, struct serial_console_data *scdp);
+int mpsc_console_init(void *devp, struct serial_console_data *scdp);
+void *simple_alloc_init(char *base, unsigned long heap_size,
+			unsigned long granularity, unsigned long max_allocs);
+extern void flush_cache(void *, unsigned long);
+int dt_xlate_reg(void *node, int res, unsigned long *addr, unsigned long *size);
+int dt_xlate_addr(void *node, u32 *buf, int buflen, unsigned long *xlated_addr);
+
+static inline void *finddevice(const char *name)
+{
+	return (dt_ops.finddevice) ? dt_ops.finddevice(name) : NULL;
+}
+
+static inline int getprop(void *devp, const char *name, void *buf, int buflen)
+{
+	return (dt_ops.getprop) ? dt_ops.getprop(devp, name, buf, buflen) : -1;
+}
+
+static inline int setprop(void *devp, const char *name,
+                          const void *buf, int buflen)
+{
+	return (dt_ops.setprop) ? dt_ops.setprop(devp, name, buf, buflen) : -1;
+}
+#define setprop_val(devp, name, val) \
+	do { \
+		typeof(val) x = (val); \
+		setprop((devp), (name), &x, sizeof(x)); \
+	} while (0)
+
+static inline int setprop_str(void *devp, const char *name, const char *buf)
+{
+	if (dt_ops.setprop)
+		return dt_ops.setprop(devp, name, buf, strlen(buf) + 1);
+
+	return -1;
+}
+
+static inline void *get_parent(const char *devp)
+{
+	return dt_ops.get_parent ? dt_ops.get_parent(devp) : NULL;
+}
+
+static inline void *create_node(const void *parent, const char *name)
+{
+	return dt_ops.create_node ? dt_ops.create_node(parent, name) : NULL;
+}
+
+
+static inline void *find_node_by_prop_value(const void *prev,
+                                            const char *propname,
+                                            const char *propval, int proplen)
+{
+	if (dt_ops.find_node_by_prop_value)
+		return dt_ops.find_node_by_prop_value(prev, propname,
+		                                      propval, proplen);
+
+	return NULL;
+}
+
+static inline void *find_node_by_prop_value_str(const void *prev,
+                                                const char *propname,
+                                                const char *propval)
+{
+	return find_node_by_prop_value(prev, propname, propval,
+	                               strlen(propval) + 1);
+}
+
+static inline void *find_node_by_devtype(const void *prev,
+                                         const char *type)
+{
+	return find_node_by_prop_value_str(prev, "device_type", type);
+}
+
+void dt_fixup_memory(u64 start, u64 size);
+void dt_fixup_cpu_clocks(u32 cpufreq, u32 tbfreq, u32 busfreq);
+void dt_fixup_clock(const char *path, u32 freq);
+void __dt_fixup_mac_addresses(u32 startindex, ...);
+#define dt_fixup_mac_addresses(...) \
+	__dt_fixup_mac_addresses(0, __VA_ARGS__, NULL)
+
+
+static inline void *find_node_by_linuxphandle(const u32 linuxphandle)
+{
+	return find_node_by_prop_value(NULL, "linux,phandle",
+			(char *)&linuxphandle, sizeof(u32));
+}
+
+static inline void *malloc(unsigned long size)
+{
+	return (platform_ops.malloc) ? platform_ops.malloc(size) : NULL;
+}
+
+static inline void free(void *ptr)
+{
+	if (platform_ops.free)
+		platform_ops.free(ptr);
+}
+
+static inline void exit(void)
+{
+	if (platform_ops.exit)
+		platform_ops.exit();
+	for(;;);
+}
+#define fatal(args...) { printf(args); exit(); }
+
+
+#define BSS_STACK(size) \
+	static char _bss_stack[size]; \
+	void *_platform_stack_top = _bss_stack + sizeof(_bss_stack);
+
+#endif /* _PPC_BOOT_OPS_H_ */
diff --git a/arch/mips/rmi/ptr/rmicrf/dtb/page.h b/arch/mips/rmi/ptr/rmicrf/dtb/page.h
new file mode 100644
index 0000000..14eca30
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/dtb/page.h
@@ -0,0 +1,34 @@
+#ifndef _PPC_BOOT_PAGE_H
+#define _PPC_BOOT_PAGE_H
+/*
+ * Copyright (C) 2001 PPC64 Team, IBM Corp
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#ifdef __ASSEMBLY__
+#define ASM_CONST(x) x
+#else
+#define __ASM_CONST(x) x##UL
+#define ASM_CONST(x) __ASM_CONST(x)
+#endif
+
+/* PAGE_SHIFT determines the page size */
+#define PAGE_SHIFT	12
+#define PAGE_SIZE	(ASM_CONST(1) << PAGE_SHIFT)
+#define PAGE_MASK	(~(PAGE_SIZE-1))
+
+/* align addr on a size boundary - adjust address up/down if needed */
+#define _ALIGN_UP(addr,size)	(((addr)+((size)-1))&(~((size)-1)))
+#define _ALIGN_DOWN(addr,size)	((addr)&(~((size)-1)))
+
+/* align addr on a size boundary - adjust address up if needed */
+#define _ALIGN(addr,size)     _ALIGN_UP(addr,size)
+
+/* to align the pointer to the (next) page boundary */
+#define PAGE_ALIGN(addr)	_ALIGN(addr, PAGE_SIZE)
+
+#endif				/* _PPC_BOOT_PAGE_H */
diff --git a/arch/mips/rmi/ptr/rmicrf/dtb/simple_alloc.c b/arch/mips/rmi/ptr/rmicrf/dtb/simple_alloc.c
new file mode 100644
index 0000000..1e5673d
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/dtb/simple_alloc.c
@@ -0,0 +1,150 @@
+/*
+ * Implement primitive realloc(3) functionality.
+ *
+ * Author: Mark A. Greer <mgreer@mvista.com>
+ *
+ * 2006 (c) MontaVista, Software, Inc.  This file is licensed under
+ * the terms of the GNU General Public License version 2.  This program
+ * is licensed "as is" without any warranty of any kind, whether express
+ * or implied.
+ */
+
+#include <stddef.h>
+#include "types.h"
+#include "page.h"
+#include "linux/string.h"
+#include "ops.h"
+
+#define	ENTRY_BEEN_USED	0x01
+#define	ENTRY_IN_USE	0x02
+
+static struct alloc_info {
+	unsigned long	flags;
+	unsigned long	base;
+	unsigned long	size;
+} *alloc_tbl;
+
+static unsigned long tbl_entries;
+static unsigned long alloc_min;
+static unsigned long next_base;
+static unsigned long space_left;
+
+/*
+ * First time an entry is used, its base and size are set.
+ * An entry can be freed and re-malloc'd but its base & size don't change.
+ * Should be smart enough for needs of bootwrapper.
+ */
+static void *simple_malloc(unsigned long size)
+{
+	unsigned long i;
+	struct alloc_info *p = alloc_tbl;
+
+	if (size == 0)
+		goto err_out;
+
+	size = _ALIGN_UP(size, alloc_min);
+
+	for (i=0; i<tbl_entries; i++, p++)
+		if (!(p->flags & ENTRY_BEEN_USED)) { /* never been used */
+			if (size <= space_left) {
+				p->base = next_base;
+				p->size = size;
+				p->flags = ENTRY_BEEN_USED | ENTRY_IN_USE;
+				next_base += size;
+				space_left -= size;
+				return (void *)p->base;
+			}
+			goto err_out; /* not enough space left */
+		}
+		/* reuse an entry keeping same base & size */
+		else if (!(p->flags & ENTRY_IN_USE) && (size <= p->size)) {
+			p->flags |= ENTRY_IN_USE;
+			return (void *)p->base;
+		}
+err_out:
+	return NULL;
+}
+
+static struct alloc_info *simple_find_entry(void *ptr)
+{
+	unsigned long i;
+	struct alloc_info *p = alloc_tbl;
+
+	for (i=0; i<tbl_entries; i++,p++) {
+		if (!(p->flags & ENTRY_BEEN_USED))
+			break;
+		if ((p->flags & ENTRY_IN_USE) &&
+		    (p->base == (unsigned long)ptr))
+			return p;
+	}
+	return NULL;
+}
+
+static void simple_free(void *ptr)
+{
+	struct alloc_info *p = simple_find_entry(ptr);
+
+	if (p != NULL)
+		p->flags &= ~ENTRY_IN_USE;
+}
+
+/*
+ * Change size of area pointed to by 'ptr' to 'size'.
+ * If 'ptr' is NULL, then its a malloc().  If 'size' is 0, then its a free().
+ * 'ptr' must be NULL or a pointer to a non-freed area previously returned by
+ * simple_realloc() or simple_malloc().
+ */
+static void *simple_realloc(void *ptr, unsigned long size)
+{
+	struct alloc_info *p;
+	void *new;
+
+	if (size == 0) {
+		simple_free(ptr);
+		return NULL;
+	}
+
+	if (ptr == NULL)
+		return simple_malloc(size);
+
+	p = simple_find_entry(ptr);
+	if (p == NULL) /* ptr not from simple_malloc/simple_realloc */
+		return NULL;
+	if (size <= p->size) /* fits in current block */
+		return ptr;
+
+	new = simple_malloc(size);
+	memcpy(new, ptr, p->size);
+	simple_free(ptr);
+	return new;
+}
+
+/*
+ * Returns addr of first byte after heap so caller can see if it took
+ * too much space.  If so, change args & try again.
+ */
+void *simple_alloc_init(char *base, unsigned long heap_size,
+			unsigned long granularity, unsigned long max_allocs)
+{
+	unsigned long heap_base, tbl_size;
+
+	heap_size = _ALIGN_UP(heap_size, granularity);
+	alloc_min = granularity;
+	tbl_entries = max_allocs;
+
+	tbl_size = tbl_entries * sizeof(struct alloc_info);
+
+	alloc_tbl = (struct alloc_info *)_ALIGN_UP((unsigned long)base, 8);
+	memset(alloc_tbl, 0, tbl_size);
+
+	heap_base = _ALIGN_UP((unsigned long)alloc_tbl + tbl_size, alloc_min);
+
+	next_base = heap_base;
+	space_left = heap_size;
+
+	platform_ops.malloc = simple_malloc;
+	platform_ops.free = simple_free;
+	platform_ops.realloc = simple_realloc;
+
+	return (void *)(heap_base + heap_size);
+}
diff --git a/arch/mips/rmi/ptr/rmicrf/dtb/types.h b/arch/mips/rmi/ptr/rmicrf/dtb/types.h
new file mode 100644
index 0000000..a20f6b0
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/dtb/types.h
@@ -0,0 +1,32 @@
+#ifndef _TYPES_H_
+#define _TYPES_H_
+
+#ifndef ARRAY_SIZE
+#define ARRAY_SIZE(x) (sizeof(x) / sizeof((x)[0]))
+#endif
+
+#if 0
+typedef unsigned char		u8;
+typedef unsigned short		u16;
+typedef unsigned int		u32;
+typedef unsigned long long	u64;
+#endif
+
+#ifndef min
+#define min(x,y) ({ \
+	typeof(x) _x = (x);	\
+	typeof(y) _y = (y);	\
+	(void) (&_x == &_y);	\
+	_x < _y ? _x : _y; })
+#endif
+
+#ifndef max
+#define max(x,y) ({ \
+	typeof(x) _x = (x);	\
+	typeof(y) _y = (y);	\
+	(void) (&_x == &_y);	\
+	_x > _y ? _x : _y; })
+
+#endif
+
+#endif /* _TYPES_H_ */
diff --git a/arch/mips/rmi/ptr/rmicrf/entry-linux.c b/arch/mips/rmi/ptr/rmicrf/entry-linux.c
new file mode 100644
index 0000000..8cfbef5
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/entry-linux.c
@@ -0,0 +1,103 @@
+/*********************************************************************
+
+  Copyright 2007-2008 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/string.h>  /* strcpy, memcpy */
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <asm/uaccess.h>  /* copy_to_user etc */
+
+#include <rmicrf/api.h>
+#include <rmicrf/oscalls.h>
+
+#include <rmidev/xlrregs.h>
+#include <rmicrf/linux.h>
+
+static int check_arg_size(int callnum, int size)
+{
+	switch(callnum) {
+
+		case RMI_MEM_ALLOC:     	return size == sizeof(struct rmi_mem_alloc_args);
+		case RMI_MEM_RESERVE:		return size == sizeof(struct rmi_mem_reserve_args);
+		case RMI_MEM_FREE:      	return size == sizeof(struct rmi_mem_free_args);
+ 
+        case RMI_RESOURCE_GETREF:       return size == sizeof(struct rmi_resource_getref_args);
+        case RMI_RESOURCE_PUTREF:	return size == sizeof(struct rmi_resource_putref_args);
+        case RMI_RESOURCE_ALLOCATE:     return size == sizeof(struct rmi_resource_allocate_args);
+        case RMI_RESOURCE_FREE:         return size == sizeof(struct rmi_resource_free_args);
+        case RMI_RESOURCE_DELETE:       return size == sizeof(struct rmi_resource_delete_args);
+
+        case RMI_DOMAIN_CREATE:         return size == sizeof(struct rmi_domain_create_args);
+        case RMI_DOMAIN_START:  	return size == sizeof(struct rmi_domain_start_args);
+        case RMI_DOMAIN_STOP:		return size == sizeof(struct rmi_domain_stop_args);
+        case RMI_DOMAIN_DELETE:  	return size == sizeof(struct rmi_domain_delete_args);
+
+        case RMI_VRESOURCE_CREATE:       return size == sizeof(struct rmi_vresource_create_args);
+        case RMI_MUTEX_CREATE:  	return size == sizeof(struct rmi_mutex_create_args);
+        case RMI_FIFO_CREATE:   	return size == sizeof(struct rmi_fifo_create_args);
+        case RMI_FMNQ_CREATE:		return size == sizeof(struct rmi_fmnq_create_args);
+        case RMI_MEMSEG_CREATE:         return size == sizeof(struct rmi_memseg_create_args);
+        case RMI_DEVICE_CREATE:         return size == sizeof(struct rmi_device_create_args);
+
+        case RMI_GET_PROPERTY:  	return size >= sizeof(struct rmi_get_property_args) &&
+			                       size < RMI_PCPU_MAXARG;
+        case RMI_SET_PROPERTY:  	return size >= sizeof(struct rmi_set_property_args) && 
+			                       size < RMI_PCPU_MAXARG;
+        case RMI_DEL_PROPERTY:  	return size == sizeof(struct rmi_del_property_args);
+        case RMI_GET_PROPNAMES:  	return size >= sizeof(struct rmi_get_propnames_args) && 
+			                       size < RMI_PCPU_MAXARG;
+        case RMI_PRINT_BUFFER:  	return size >= sizeof(struct rmi_print_buffer_args) && 
+			                       size < RMI_PCPU_MAXARG;
+	default: return 0;
+	}
+}
+
+/* Forward a user space call to RMI Kernel */
+int rmi_kernel_call(int callnum, int size, void __user *inargs) 
+{
+	struct rmi_mem_alloc_args *kargs = rmi_get_pcpumem(xlr_get_cpuid());
+
+	/* printk("ioctl %d size %d ptr %p entry %p\n", callnum, size, inargs, rmi_rmik_entry); */
+	if (check_arg_size(callnum, size) == 0) {
+		printk("Invalid size for ioctl (%d) - size %d\n", callnum, size);
+		return -EINVAL;
+	}
+	if (copy_from_user(kargs, inargs, size)) {
+		printk("Invalid memory %p\n", inargs);
+		return -EFAULT;
+	}
+
+	rmi_enter_kernel(callnum);
+
+	if (copy_to_user(inargs, kargs, size)) {
+		printk("*** RMIK ERROR - copy back to user failed to ptr %p\n", inargs);
+		return -EFAULT;
+	}
+	return 0;
+}
diff --git a/arch/mips/rmi/ptr/rmicrf/entry.c b/arch/mips/rmi/ptr/rmicrf/entry.c
new file mode 100644
index 0000000..4b48054
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/entry.c
@@ -0,0 +1,369 @@
+/*********************************************************************
+
+  Copyright 2007-2008 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <rmicrf/api.h>
+#include <rmicrf/oscalls.h>
+#include <rmicrf/crflib.h>
+#include <rmidev/xlrregs.h>
+
+#if defined(RMICRF_LINUXK)
+#include <linux/string.h>
+#include <rmicrf/linux.h>
+#elif defined(RMICRF_RMIOS)
+#include <rmicrf/rmios.h>
+#elif defined(RMICRF_VXWORKS)
+#include <string.h>
+#include <rmicrf/vxworks6.h>
+#else
+#error "You need to supply common routines for entry.c"
+#endif
+
+rmi_physaddr_t rmi_mem_alloc (int type, uint64_t size, uint64_t align)
+{
+	struct rmi_mem_alloc_args *args =  rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->type = type;
+	args->size = size;
+	args->align = align;
+	rmi_enter_kernel(RMI_MEM_ALLOC);
+	return args->rv;
+}
+
+int rmi_mem_reserve (rmi_physaddr_t paddr, uint64_t size)
+{
+	struct rmi_mem_reserve_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->paddr = paddr;
+	args->size = size;
+	rmi_enter_kernel(RMI_MEM_RESERVE);
+	return args->rv;
+}
+
+void rmi_mem_free (rmi_physaddr_t addr)
+{
+	struct rmi_mem_free_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->addr = addr;
+	rmi_enter_kernel(RMI_MEM_FREE);
+}
+
+int rmi_resource_getref (const char *name, rmi_resource_t *res, struct rmi_resource *res_data)
+{
+	struct rmi_resource_getref_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	
+	/* we need to put in special value to pass NULL pointer */
+	rmi_set_isnull_arg(&args->res, res);
+	rmi_set_isnull_arg(&args->res_data, res_data);
+	rmi_enter_kernel(RMI_RESOURCE_GETREF);
+	if (args->rv == 0) {
+		if (res_data)
+			memcpy(res_data, &args->res_data, sizeof(*res_data));
+		if (res)
+			*res = rmi_addr_to_ptr(args->res);
+	}
+	return args->rv;
+}
+
+int rmi_resource_putref (rmi_resource_t res)
+{
+	struct rmi_resource_putref_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->res = rmi_ptr_to_addr(res);
+	rmi_enter_kernel(RMI_RESOURCE_PUTREF);
+	return args->rv;
+}
+
+int rmi_resource_allocate (const char *name, rmi_dom_t domain)
+{
+	struct rmi_resource_allocate_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	args->domain = domain;
+	rmi_enter_kernel(RMI_RESOURCE_ALLOCATE);
+	return args->rv;
+}
+
+int rmi_resource_free (const char *name)
+{
+	struct rmi_resource_free_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	rmi_enter_kernel(RMI_RESOURCE_FREE);
+	return args->rv;
+}
+
+int rmi_resource_delete (const char *name)
+{
+	struct rmi_resource_delete_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	rmi_enter_kernel(RMI_RESOURCE_DELETE);
+	return args->rv;
+}
+
+int rmi_vresource_create(rmi_resource_t parent, const char *name, rmi_resource_t real_res)
+{
+	struct rmi_vresource_create_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->parent = rmi_ptr_to_addr(parent);
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	args->res = rmi_ptr_to_addr(real_res);
+	rmi_enter_kernel(RMI_VRESOURCE_CREATE);
+	return args->rv;
+}
+
+rmi_dom_t rmi_domain_create (const char *name)
+{
+	struct rmi_domain_create_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	rmi_enter_kernel(RMI_DOMAIN_CREATE);
+	return args->rv;
+}
+
+int rmi_domain_start (rmi_dom_t domain)
+{
+	struct rmi_domain_start_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->domain = domain;
+	rmi_enter_kernel(RMI_DOMAIN_START);
+	return args->rv;
+}
+
+int rmi_domain_stop (rmi_dom_t domain)
+{
+	struct rmi_domain_stop_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->domain = domain;
+	rmi_enter_kernel(RMI_DOMAIN_STOP);
+	return args->rv;
+}
+
+int rmi_domain_delete (rmi_dom_t domain)
+{
+	struct rmi_domain_delete_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->domain = domain;
+	rmi_enter_kernel(RMI_DOMAIN_DELETE);
+	return args->rv;
+}
+
+int rmi_mutex_create (rmi_resource_t parent, const char *name, uint32_t flags)
+{
+	struct rmi_mutex_create_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->parent = rmi_ptr_to_addr(parent);
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	args->flags = flags;
+	rmi_enter_kernel(RMI_MUTEX_CREATE);
+	return args->rv;
+}
+
+int rmi_fifo_create (rmi_resource_t parent, const char *name, 
+					int entrysize, int nentries, uint32_t flags)
+{
+	struct rmi_fifo_create_args *args = (struct rmi_fifo_create_args *)rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->parent = rmi_ptr_to_addr(parent);
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	args->flags = flags;
+	args->entrysize = entrysize;
+	args->nentries = nentries;
+	rmi_enter_kernel(RMI_FIFO_CREATE);
+	return args->rv;
+}
+
+int rmi_fmnq_create (rmi_resource_t parent, const char *name, 
+				int bucket, uint32_t flags)
+{
+	struct rmi_fmnq_create_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->parent = rmi_ptr_to_addr(parent);
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	args->bucket = bucket;
+	args->flags = flags;
+	rmi_enter_kernel(RMI_FMNQ_CREATE);
+	return args->rv;
+}
+
+int rmi_memseg_create (rmi_resource_t parent, const char *name, 
+		       rmi_addr_t vaddr, uint64_t size, rmi_physaddr_t allocstart, uint64_t allocend,
+		       uint32_t pagesize, uint32_t flags)
+{
+	struct rmi_memseg_create_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->parent = rmi_ptr_to_addr(parent);
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	args->vaddr = vaddr;
+	args->size = size;
+	args->allocstart = allocstart;
+	args->allocend = allocend;
+	args->pagesize = pagesize;
+	args->flags = flags;
+	rmi_enter_kernel(RMI_MEMSEG_CREATE);
+	return args->rv;
+}
+
+int rmi_device_create (rmi_resource_t parent, const char *name, rmi_addr_t obj, uint32_t flags)
+{
+	struct rmi_device_create_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->parent = rmi_ptr_to_addr(parent);
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	args->obj = obj;
+	args->flags = flags;
+	rmi_enter_kernel(RMI_DEVICE_CREATE);
+	return args->rv;
+}
+
+int rmi_set_property (rmi_resource_t res,  const char *name, int type, 
+		      const void *val, int len)
+{
+	struct rmi_set_property_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	if (len + sizeof(*args) >= RMI_PCPU_MAXARG)
+		return -1;
+
+	args->rv = -1;
+	args->res = rmi_ptr_to_addr(res);
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	args->type = type;
+	memcpy(args->val, val, len);
+	args->len = len;
+	rmi_enter_kernel(RMI_SET_PROPERTY);
+	return args->rv;
+}
+
+int rmi_get_property (rmi_resource_t res, const char *name, 
+		      struct rmi_property *prop_data, void *val, int len)
+{
+	struct rmi_get_property_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+	
+	/* we can only go up to MAXARG, so cut down the len if it is larger */
+	if (len + sizeof(*args) >= RMI_PCPU_MAXARG)
+		len = RMI_PCPU_MAXARG - sizeof(*args) - 1;
+
+	args->rv = -1;
+	args->res = rmi_ptr_to_addr(res);
+	/* support passing NULL in prop_data */
+	rmi_set_isnull_arg(&args->prop_data, prop_data);
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	args->len = len;
+	rmi_enter_kernel(RMI_GET_PROPERTY);
+	if (args->rv > 0) {
+		/* copy propdata only if needed */
+		if (prop_data)
+			*prop_data = args->prop_data;
+		if (len) {
+			if (args->rv < len)
+				len = args->rv;
+			
+			memcpy(val, args->val, len);
+		}
+	}
+	return args->rv;
+}
+
+int rmi_del_property (rmi_resource_t res,  const char *name)
+{
+	struct rmi_del_property_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	args->rv = -1;
+	args->res = rmi_ptr_to_addr(res);
+	strncpy(args->name, name, RMI_MAX_NAMELEN);
+	args->name[RMI_MAX_NAMELEN-1] = '\0';
+	rmi_enter_kernel(RMI_DEL_PROPERTY);
+	return args->rv;
+}
+
+int rmi_get_propnames (rmi_resource_t res, void *buf, int len)
+{
+	struct rmi_get_propnames_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	if (len + sizeof(*args) >= RMI_PCPU_MAXARG)
+		return -1;
+
+	args->rv = -1;
+	args->res = rmi_ptr_to_addr(res);
+	args->len = len;
+	rmi_enter_kernel(RMI_GET_PROPNAMES);
+	if (args->rv >= 0) {
+		if (args->len > len)
+			return -1;
+		memcpy(buf, args->val, args->len);
+	}
+	return args->rv;
+}
+
+int rmi_print_buffer (const char *buf, int len)
+{
+	struct rmi_print_buffer_args *args = rmi_get_pcpumem(xlr_get_cpuid());
+
+	if (len + sizeof(*args) >= RMI_PCPU_MAXARG)
+		len = RMI_PCPU_MAXARG - sizeof(*args) - 1;
+
+	args->rv = -1;
+	args->len = len;
+	memcpy(args->buf, buf, len);
+	rmi_enter_kernel(RMI_PRINT_BUFFER);
+	return args->rv;
+}
diff --git a/arch/mips/rmi/ptr/rmicrf/event_handle.c b/arch/mips/rmi/ptr/rmicrf/event_handle.c
new file mode 100644
index 0000000..6c00a70
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/event_handle.c
@@ -0,0 +1,246 @@
+/*********************************************************************
+
+  Copyright 2007-2008 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/*
+ * RMIK utils
+ */
+
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/init.h>
+#include <linux/kallsyms.h>
+#include <linux/netdevice.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/config_net.h>
+#include <rmicrf/config.h>
+#include <rmicrf/types.h>
+#include <rmicrf/api.h>
+#include <rmicrf/crflib.h>
+#include <rmicrf/frame.h>
+#include <rmicrf/linux.h>
+#include <rmicrf/clpool.h>
+#include <rmicrf/eventdefs.h>
+#include <rmicrf/bootinfo.h>
+#include <asm/rmi/linux_crf.h>
+
+static struct work_struct stop_domain_work;
+volatile uint32_t *rmik_cpu_reset_map;
+volatile int stop_dom_cpu = NR_CPUS;
+static int event_fmnq_polling_enabled = 1;
+#if defined(XLP_MERGE_TODO) || defined(CONFIG_RMI_XLR)
+extern struct rmi_cluster *rmi_pkt_pool;
+extern void rmik_cpu_to_cpu_pkt_msgring_handler(int size, struct msgrng_msg *msg);
+#else
+struct rmi_cluster *rmi_pkt_pool = NULL;
+void rmik_cpu_to_cpu_pkt_msgring_handler(int size, struct msgrng_msg *msg)
+{
+	printk("[%s]: XLP_MERGE_TODO, unsupported function!\n", __FUNCTION__);
+}
+#endif
+
+void rmik_reset_cpus(void *arg)
+{
+    int cpu = hard_smp_processor_id();
+	atomic_t *cpu_reset_map = arg;
+	atomic_add(( 1 << cpu), cpu_reset_map);
+	*rmik_cpu_reset_map |= atomic_read(cpu_reset_map);
+	while(1);
+}
+
+static void stop_domain(struct work_struct *args /* ignored */ )
+{
+	struct net *net;
+	struct net_device *dev;
+	atomic_t cpu_reset_map = { 0 };
+
+	for_each_net(net) {
+		for_each_netdev(net, dev) {
+			if (!(dev->flags & IFF_UP))
+				continue;
+
+//			if(dev->stop)
+//				dev->stop(dev);
+		}
+	}
+	
+	smp_call_function(rmik_reset_cpus, (void *)&cpu_reset_map, 0);
+
+	/* apply on my own cpu */
+	rmik_reset_cpus(&cpu_reset_map);
+
+	while(1);
+}
+
+static void rmik_vnet_event(int len, uint64_t *msg)
+{
+	struct rmi_event_simple_msg *smsg = rmi_addr_to_ptr(msg);
+
+	switch(smsg->msgtype) {
+	    case RMI_EVENT_VNET_PKT:
+		if (rmi_vnet_pkt_event_handler)
+		    rmi_vnet_pkt_event_handler(len, smsg);
+		break;
+	    default:
+		printk("Invalid VNET Event Q msg type %d(len=%d) : %llx:%llx\n",
+		       smsg->msgtype, len, (unsigned long long)msg[0],
+		       (unsigned long long)msg[1]);
+	}
+
+}
+
+static void rmik_cl_pool_info_event(int len, uint64_t *msg)
+{
+	printk("[%s] Todo\n", __FUNCTION__);
+	return;
+}
+
+static void rmik_dom_ctrl_event(int len, uint64_t *msg)
+{
+	struct rmi_event_simple_msg *smsg = rmi_addr_to_ptr(msg);
+	switch(smsg->msgtype) {
+            case RMI_EVENT_MSG_STOP_DOM:
+                printk("IPI Stop domain \n");
+
+                /* Return if we are already in stop domain */
+                if(stop_dom_cpu != NR_CPUS)
+                    return;
+        
+                /* reset all the devices owned by it */
+                rmik_cpu_reset_map = rmi_addr_to_ptr(smsg->arg);
+                stop_dom_cpu =  hard_smp_processor_id();
+
+                INIT_WORK(&stop_domain_work, stop_domain);
+                schedule_work(&stop_domain_work);
+                return;
+	    default:
+                printk("Invalid Q type %d(len=%d) : %llx:%llx \n", smsg->msgtype, len,
+                        (unsigned long long)msg[0], (unsigned long long)msg[1]);
+
+	}
+}
+
+static void rmik_veth_event(int len, uint64_t *msg)
+{
+	struct rmi_event_simple_msg *smsg = rmi_addr_to_ptr(msg);
+       	struct rmi_event_eth_ifc_msg *ifcmsg;
+	switch(smsg->msgtype) {
+
+	    case RMI_EVENT_MSG_IFC_UP:
+		ifcmsg = rmi_addr_to_ptr(smsg->arg);
+		printk("[%s] Interface up \n", __FUNCTION__);
+		rmi_cluster_free(rmi_pkt_pool, rmi_addr_to_ptr(smsg->arg));
+		break;
+
+	    case RMI_EVENT_MSG_IFC_DOWN:
+		ifcmsg = rmi_addr_to_ptr(smsg->arg);
+		printk("[%s] Interface down \n", __FUNCTION__);
+		rmi_cluster_free(rmi_pkt_pool, rmi_addr_to_ptr(smsg->arg));
+		break;
+
+          default:
+                printk("Invalid Q type %d(len=%d) : %llx:%llx \n", smsg->msgtype, len,
+                        (unsigned long long)msg[0], (unsigned long long)msg[1]);
+	}
+}
+
+
+
+
+void rmik_eventq_ipi_handler(void)
+{
+	int qtype, len, rv;
+	uint64_t msg[10];
+	uint32_t mflags = 0;
+	struct rmi_eventq *event = rmi_get_eventq(rmi_this_domain->id);
+
+	/* if bucket polling enabled the message will be handled by 
+	   rmik_cpu_to_cpu_msgring_handler */
+	if(event->type == RMI_FMNQ && event_fmnq_polling_enabled)
+		return;
+
+	len = sizeof(msg);
+
+	while(1) {
+		msgrng_flags_save(mflags);
+		if((rv = rmi_get_event(&qtype, &len, msg)) <= 0) {
+			msgrng_flags_restore(mflags);
+			return;
+		}
+		msgrng_flags_restore(mflags);
+
+
+		switch(qtype) {
+			case RMI_EVENT_DOM_CTRL:
+				rmik_dom_ctrl_event(len/sizeof(uint64_t), msg);
+				break;
+
+			case RMI_EVENT_VETH_INFO:
+				rmik_veth_event(len/sizeof(uint64_t), msg);
+				break;
+
+			case RMI_EVENT_PKT_FW :
+				rmik_cpu_to_cpu_pkt_msgring_handler(len / sizeof(uint64_t), 
+						rmi_addr_to_ptr(msg)); 
+				break;
+
+			case RMI_EVENT_CL_POOL_INFO:
+				rmik_cl_pool_info_event(len/sizeof(uint64_t), msg);
+				break;
+
+			case RMI_EVENT_VNET:
+				rmik_vnet_event(len, msg);
+				break;
+
+			default:
+				printk("Invalid Event Q type %d(len=%d) : %llx:%llx\n", qtype, len,
+						(unsigned long long)msg[0], (unsigned long long)msg[1]);
+		}
+	}
+	return;
+}
+
+void rmik_cpu_to_cpu_msgring_handler(int bucket, int size, int code,
+				    int stid, struct msgrng_msg *msg,
+				    void *data /* ignored */ )
+{
+	switch(code)  {
+		case RMI_EVENT_DOM_CTRL:
+			return rmik_dom_ctrl_event(size, rmi_addr_to_ptr(msg));
+
+		case RMI_EVENT_VETH_INFO:
+			return rmik_veth_event(size, rmi_addr_to_ptr(msg));
+
+		case RMI_EVENT_PKT_FW:
+			return rmik_cpu_to_cpu_pkt_msgring_handler(size, msg);
+		default:
+			printk("Unknown code %d in %s\n", code, __FUNCTION__);
+	}
+}
diff --git a/arch/mips/rmi/ptr/rmicrf/eventq.c b/arch/mips/rmi/ptr/rmicrf/eventq.c
new file mode 100644
index 0000000..580d225
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/eventq.c
@@ -0,0 +1,123 @@
+#include <rmicrf/api.h>
+#include <rmicrf/crflib.h>
+#include <rmidev/pic.h>
+
+struct rmi_eventq *rmi_get_eventq(rmi_dom_t dom)
+{
+	struct rmi_domain *dst;
+
+	if (dom <= RMI_DOMAIN_REMOVED || dom >= RMI_MAX_DOMAINS)
+		return NULL;
+
+	dst = &rmi_this_domain[(int32_t)(dom - rmi_this_domain->id)];
+
+	return &dst->eventq;
+}
+
+/*  returns 0 for success
+ *  returns negative value for failure
+ */
+int rmi_send_event(rmi_dom_t domain, int type, int len, const uint64_t *msg)
+{
+	int rv = -1;
+	struct rmi_eventq *q;
+	
+	q = rmi_get_eventq(domain);
+	if (q == NULL)
+		return -1;
+
+	switch (q->type) {
+	case RMI_FIFO:
+		rv = rmi_fifo_sendmsg(rmi_addr_to_ptr(q->transport), type, len, msg);
+		break;
+	case RMI_FMNQ:
+		rv = rmi_fmnq_send(rmi_addr_to_ptr(q->transport), type, len, msg);
+		break;
+	default:
+		rmi_log_error("Bad queue type for event q\n");
+		break;
+	}
+
+	if (rv == len && q->notify_ipi != -1) {
+		xlr_send_ipi(q->notify_cpu, q->notify_ipi);
+	}
+	if(rv == len)
+		return 0;
+	return -1;
+}	
+
+/* returns the length of the received message */
+int rmi_get_event(int *type, int *len, uint64_t *msg)
+{
+	int rv = -1;
+	int stnid;
+	struct rmi_eventq *q;
+	
+	q = rmi_get_eventq(rmi_this_domain->id);
+	if (q == NULL)
+		return -1;
+
+	switch (q->type) {
+	case RMI_FIFO:
+		rv = rmi_fifo_recvmsg(rmi_addr_to_ptr(q->transport), type, len, msg);
+		break;
+
+	case RMI_FMNQ:
+		rv = rmi_fmnq_recv(rmi_addr_to_ptr(q->transport), type, len, &stnid, msg);
+		break;
+
+	default:
+		rmi_log_error("Bad queue type for event q\n");
+		break;
+	}
+
+	return rv;
+}
+
+/**
+* resname : resource name(Event recipients from this resource)
+*
+* @returns 0 on success.
+*           negative value on error.
+*  dom_map will be updated
+*/
+int rmi_get_event_recipients(char *resname, uint64_t *dom_map)
+{
+	struct rmi_resource *res;
+	struct rmi_domain dom;
+	int rv, domain;
+	rmi_addr_t addr;
+	
+	*dom_map = 0;
+
+	if((rv = rmi_resource_getref(resname, &res, NULL)) != 0) 
+		return rv;
+	rmi_resource_putref(res);
+	
+	/* Resource is not allocated to anyone */
+	if(res->domain == RMI_DOMAIN_NONE) 
+		return 0;
+
+	if((rv = rmi_get_property(res, "dom-map", NULL, &addr, 
+					sizeof(addr))) < 0) 
+		return rv;
+
+	*dom_map = *(uint64_t *)(long)addr;
+
+	/* Set the owner domain and clear my own domain */
+	*dom_map |= (1ULL << res->domain);
+	*dom_map = *dom_map & (~(1ULL << rmi_this_domain->id));
+
+	/* Update with only running domain */
+	for(domain = 0; domain < RMI_MAX_DOMAINS; domain++) {
+		if(!((1ULL << domain) & *dom_map))
+			continue;
+		if(rmi_get_domain(domain, &dom) < 0)
+			continue;
+		if(dom.state != RMI_D_RUNNING) 
+			*dom_map = *dom_map & (~(1ULL << dom.id));
+
+	}
+
+	return 0;
+}
diff --git a/arch/mips/rmi/ptr/rmicrf/fifo.c b/arch/mips/rmi/ptr/rmicrf/fifo.c
new file mode 100644
index 0000000..762d48e
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/fifo.c
@@ -0,0 +1,359 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+
+#include <rmicrf/types.h>
+#include <rmicrf/api.h>
+#include <rmicrf/crflib.h>
+#include <rmicrf/errcode.h>
+
+#include <rmidev/xlrregs.h>
+#include <rmidev/fmn.h>
+#include <rmidev/xlrextns.h>
+#include <rmidev/pic.h>
+
+
+#define RMI_EVENTQ_SHM_MAGIC  0x0d00dad5
+
+
+uint32_t rmi_fmnq_send(struct rmi_fmnq *q, int code, int size, const uint64_t *msg)
+{
+	uint32_t rv;
+	int retries = 0;
+	int tsize = size;
+
+	assert (size > 0 && size <=16);
+
+	/* FMN expects size - 1 */
+	size = (size / sizeof(uint64_t)) - 1;
+retry:	switch (size) {
+		case 3: xlr_dmtc2(0, 3, msg[3]);
+		case 2: xlr_dmtc2(0, 2, msg[2]);
+		case 1: xlr_dmtc2(0, 1, msg[1]);
+		case 0: xlr_dmtc2(0, 0, msg[0]);
+	}
+	
+	rv = xlr_msgsnd(size, code, q->bucket);	
+	if ((rv & 0x6) != 0) {
+		if (rv & 0x4)
+			q->stat_fail_credit++;
+		if (rv & 0x2)
+			q->stat_fail_thread++;
+		if (++retries < RMI_MSGRNG_MAX_RETRIES)
+			goto retry;
+		else {
+			rmi_log_error("msgsnd failed to cpu %d to bucket %d\n", q->bucket);
+			return 0;
+		}
+	}
+
+	return tsize;
+}
+
+uint32_t rmi_fmnq_recv(struct rmi_fmnq *q, int *code, int *size, int *stnid, uint64_t *msg)
+{
+	uint32_t rv;
+
+	rv = xlr_msgld(q->bucket);
+	if (rv & 0x30) {
+		if (rv & 0x20)
+			q->stat_fail_empty++;
+		if (rv & 0x10)
+			q->stat_fail_pending++;
+		return 0;
+	}
+
+	*size = (rv >> 6) & 0x3;
+	*code = (rv >> 8)  & 0xff;
+	*stnid = (rv >> 16) & 0x7f;
+	switch (*size) {
+		case 3: msg[3] = xlr_dmfc2(1, 3);
+		case 2: msg[2] = xlr_dmfc2(1, 2);
+		case 1: msg[1] = xlr_dmfc2(1, 1);
+		case 0: msg[0] = xlr_dmfc2(1, 0);
+	}
+	*size = (*size + 1) * sizeof(uint64_t);
+	return *size;
+}
+
+#define  fifo_full(q, t) (((t+1) % q->nentries) == q->head)
+#define  fifo_empty(q, t) (t == q->tail)
+
+/**
+* @brief send a buffer to the specified fifo
+*
+* Sends the given buffer into the fifo with the given fifo pointer and the specified entries.
+*
+* @param[in] struct rmi_fifo *q
+* @param[in] char *buf
+* @param[in] int num_entries
+*
+* @return uint32_t
+* @n returns the size copied to fifo
+* @sa rmi_fifo_recv 
+*
+* @ingroup crf_fifo
+*/
+uint32_t rmi_fifo_send(struct rmi_fifo *q, const char *buf, int num_entries)
+{
+	int i;
+    uint32_t tmptail;
+    uint32_t copied = 0;
+    char *queue = (char *)&q->data;
+    int delete_old = 1;
+
+    if(q == NULL || buf == NULL || num_entries == 0)
+        return 0;
+
+    if(!delete_old) {
+	    rmi_mutex_lock(&q->lock);
+	    tmptail = q->tail;
+	    for (i=0; (i < num_entries * q->entrysize) && !fifo_full(q, tmptail); i++) {
+		    tmptail = (tmptail+1) % q->nentries;
+		    queue[tmptail] = buf[i];
+		    copied++;
+	    }
+	    q->tail = tmptail;
+	    rmi_mutex_unlock(&q->lock);
+
+	    return (copied / q->entrysize);
+    } else {
+	    rmi_mutex_lock(&q->lock);
+	    tmptail = q->tail;
+	    for (i=0; i < num_entries * q->entrysize; i++) {
+		    if(fifo_full(q, tmptail))
+			    q->head = (q->head + 1) % q->nentries;
+		    tmptail = (tmptail+1) % q->nentries;
+		    queue[tmptail] = buf[i];
+	    }
+	    q->tail = tmptail;
+	    rmi_mutex_unlock(&q->lock);
+	    return num_entries;
+    }
+}
+
+/**
+* @brief Receive a buffer from the specified fifo
+*
+* Receives entries to the given buffer from the fifo with the specified entries.
+*
+* @param[in] struct rmi_fifo *q
+* @param[out] char *buf
+* @param[in] int num_entries
+*
+* @return uint32_t
+* @n returns the size copied to buffer 
+* @sa rmi_fifo_recv 
+*
+* @ingroup crf_fifo
+*/
+uint32_t rmi_fifo_recv(struct rmi_fifo *q, char *buf, int num_entries)
+{
+   	uint32_t tmphead, copied = 0;
+	int i;
+	char *queue = (char *)&q->data;
+
+	if(q == NULL || buf == NULL || num_entries == 0)
+		return 0;
+
+    	rmi_mutex_lock(&q->lock);
+	tmphead = q->head;
+	for (i=0; (i < num_entries * q->entrysize) && !fifo_empty(q, tmphead); i++) {
+		tmphead = (tmphead+1) % q->nentries;
+		buf[i] = queue[tmphead];
+		copied++;
+	}
+	q->head = tmphead;
+    	rmi_mutex_unlock(&q->lock);
+
+	return (copied / q->entrysize);
+}
+
+/**
+* @brief send a buffer to the specified fifo
+*
+* Sends the given buffer into the fifo with the given fifo pointer and the specified entries.
+*
+* @param[in] struct rmi_fifo *q
+* @param[in] char *buf
+* @param[in] int num_entries
+*
+* @return uint32_t
+* @n returns the size copied to fifo
+* @sa rmi_fifo_recv 
+*
+* @ingroup crf_fifo
+*/
+uint32_t rmi_fifo_sendmsg(struct rmi_fifo *q, int type, int len, const void *value)
+{
+	int i;
+	uint32_t tmptail;
+	unsigned char *queue = (unsigned char *)&q->data;
+	const unsigned char *inval = value;
+
+	assert(q->entrysize == 1);
+
+	rmi_mutex_lock(&q->lock);
+
+	tmptail = q->tail;
+	tmptail = (tmptail+1) % q->nentries;
+	if (tmptail == q->head)
+		goto err_exit;
+	queue[tmptail] = type;
+
+	tmptail = (tmptail+1) % q->nentries;
+	if (tmptail == q->head)
+		goto err_exit;
+	queue[tmptail] = len;
+	
+	for (i=0; (i < len); i++) {
+		tmptail = (tmptail+1) % q->nentries;
+		if (tmptail == q->head)
+			goto err_exit;
+		queue[tmptail] = inval[i];
+	}
+	/* the tail update has to be done after the data goes out,
+	   we don't lock in the recv side */
+	xlr_memory_barrier(); 
+	q->tail = tmptail;
+	rmi_mutex_unlock(&q->lock);
+	return len;
+
+err_exit:
+	rmi_mutex_unlock(&q->lock);
+	return 0;
+	
+}
+
+/**
+* @brief Receive a buffer from the specified fifo
+*
+* Receives entries to the given buffer from the fifo with the specified entries.
+*
+* @param[in] struct rmi_fifo *q
+* @param[out] char *buf
+* @param[in] int num_entries
+*
+* @return uint32_t
+* @n returns the size copied to buffer 
+* @sa rmi_fifo_recv 
+*
+* @ingroup crf_fifo
+*/
+uint32_t rmi_fifo_recvmsg(struct rmi_fifo *q, int *type, int *len, void *value)
+{
+   	uint32_t tmphead;
+	int i;
+	unsigned char *queue = (unsigned char *)&q->data;
+	unsigned char *outval = value;
+	int tlen = *len;
+
+	assert(q->entrysize == 1);
+	assert(tlen > 0);
+	
+	tmphead = q->head;
+	if (tmphead == q->tail)
+		goto err_exit;
+	tmphead = (tmphead+1) % q->nentries;
+	*type = queue[tmphead];
+
+	if (tmphead == q->tail)
+		goto err_exit;
+	tmphead = (tmphead+1) % q->nentries;
+	*len = queue[tmphead];
+
+	if (tlen > *len)
+		tlen = *len;
+		
+	for (i=0; i < tlen; i++) {
+		if (tmphead == q->tail)
+			goto err_exit;
+		tmphead = (tmphead+1) % q->nentries;
+		outval[i] = queue[tmphead];
+	}
+
+	q->head = tmphead;
+	return tlen;
+	
+err_exit:
+	return 0;
+	
+}
+
+static struct rmi_fifo *logfifo = NULL;
+int rmi_get_logbuf(char *buf, uint32_t len)
+{
+	struct rmi_resource *res = NULL;
+	struct rmi_fifo *q; 
+	char *queue;
+	uint32_t tmphead, copied = 0, i;
+	const char *name = "logbuf";
+
+	if(logfifo == NULL) {
+		if(rmi_resource_getref(name, &res, NULL) != 0)
+			return -1;
+		q = logfifo = rmi_addr_to_ptr(res->obj);
+		rmi_resource_putref(res);
+	} else
+		q = logfifo;
+
+	queue = (char *)&q->data;
+	rmi_mutex_lock(&q->lock);
+	tmphead = q->head;
+	for (i=0; i < len && !fifo_empty(q, tmphead); i++) {
+		tmphead = (tmphead+1) % q->nentries;
+		buf[i] = queue[tmphead];
+		copied++;
+	}
+	rmi_mutex_unlock(&q->lock);
+	return copied;
+}
+
+int rmi_clear_logbuf(void)
+{
+	struct rmi_resource *res = NULL;
+	struct rmi_fifo *q;
+	const char *name = "logbuf";
+
+	if(logfifo == NULL) {
+		if(rmi_resource_getref(name, &res, NULL) != 0)
+			return -1;
+		q = logfifo = rmi_addr_to_ptr(res->obj);
+		rmi_resource_putref(res);
+	} else
+		q = logfifo;
+
+
+	rmi_mutex_lock(&q->lock);
+	q->head  = q->tail = 0;
+	rmi_mutex_unlock(&q->lock);
+	return 0;
+}
+
diff --git a/arch/mips/rmi/ptr/rmicrf/fmn.c b/arch/mips/rmi/ptr/rmicrf/fmn.c
new file mode 100644
index 0000000..12143f7
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/fmn.c
@@ -0,0 +1,90 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+#include <rmicrf/types.h>
+#include <rmidev/xlrregs.h>
+#include <rmidev/xlrextns.h>
+#include <rmidev/fmn.h>
+
+
+int xlr_fmn_send(int bucket, int size, int code, uint64_t *msg)
+{
+	uint32_t rv;
+	int retries = 0;
+
+	assert (size > 0 && size <=4);
+
+	/* FMN expects size - 1 */
+	size = size - 1;
+retry:	switch (size) {
+		case 3: xlr_dmtc2(0, 3, msg[3]);
+		case 2: xlr_dmtc2(0, 2, msg[2]);
+		case 1: xlr_dmtc2(0, 1, msg[1]);
+		case 0: xlr_dmtc2(0, 0, msg[0]);
+	}
+	
+	rv = xlr_msgsnd(size, code, bucket);	
+	if ((rv & 0x6) != 0) {
+		if (++retries < RMI_MSGRNG_MAX_RETRIES)
+			goto retry;
+		else {
+			/* TODO have a platform independent error logger */
+			extern int printf(const char *fmt, ...);
+			printf("msgsnd failed to bucket %d size %d rv %x\n", bucket, size, rv);
+			return -1;
+		}
+	}
+
+	return rv & 0x6;
+}
+
+int xlr_fmn_recv(int bucket, int *size, int *code, int *stnid,
+			uint64_t *msg)
+{
+	uint32_t rv;
+
+	rv = xlr_msgld(bucket);
+	if (rv & 0x30)
+		return rv & 0x30;
+
+	*size = (rv >> 6) & 0x3;
+	*code = (rv >> 8)  & 0xff;
+	*stnid = (rv >> 16) & 0x7f;
+	switch (*size) {
+		case 3: msg[3] = xlr_dmfc2(1, 3);
+		case 2: msg[2] = xlr_dmfc2(1, 2);
+		case 1: msg[1] = xlr_dmfc2(1, 1);
+		case 0: msg[0] = xlr_dmfc2(1, 0);
+	}
+	*size += 1;
+	return 0;
+}
+
+/* TODO code for messge ring intitialization etc */
diff --git a/arch/mips/rmi/ptr/rmicrf/memcpy.c b/arch/mips/rmi/ptr/rmicrf/memcpy.c
new file mode 100644
index 0000000..bea8e22
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/memcpy.c
@@ -0,0 +1,94 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+#include <rmicrf/types.h>
+#include <rmicrf/api.h>
+#include <rmidev/xlrregs.h>
+
+
+void rmi_xkphys_sb(rmi_physaddr_t dstpaddr, void *srcvaddr, uint64_t size)
+{
+	uint64_t i;
+	uint8_t *s = rmi_addr_to_ptr(srcvaddr);
+
+	dstpaddr |= XLR_XKPHYS_CACHED;
+
+	for (i=0; i<size; i++) {
+		__asm__ ("sb   %0, 0(%1)\n" 
+			 : : "r"(s[i]), "r"(dstpaddr+i)
+			 : "memory");
+	}
+	return;
+}
+
+void rmi_xkphys_lb(void *dstvaddr, rmi_physaddr_t srcpaddr, uint64_t size)
+{
+	uint64_t i;
+	uint8_t *s = rmi_addr_to_ptr(dstvaddr);
+
+	srcpaddr |= XLR_XKPHYS_CACHED;
+
+	for (i=0; i<size; i++) {
+		__asm__ ("lbu   %0, 0(%1)\n"
+			: "=r" (s[i])
+			: "r"(srcpaddr + i)
+			: "memory"
+			);
+	}
+	return;
+}
+
+extern void *memcpy(void *dest, const void *src, size_t n);
+
+void rmi_phys_memcpy(rmi_physaddr_t dstpaddr, void *srcvaddr, uint64_t size)
+{
+	if((dstpaddr + size) <= XLR_PHYS_KSEG0_END) {
+		void *buf = rmi_addr_to_ptr(rmi_phys_to_kseg0(dstpaddr));
+		memcpy(buf, srcvaddr, size);
+		return; 
+	}
+
+	return rmi_xkphys_sb(dstpaddr, srcvaddr, size);
+}
+
+
+void rmi_phys_memget(void *dstvaddr, rmi_physaddr_t srcpaddr, uint64_t size)
+{
+
+	if((srcpaddr + size) <= XLR_PHYS_KSEG0_END) {	
+		void *buf = rmi_addr_to_ptr(rmi_phys_to_kseg0(srcpaddr));
+		memcpy(dstvaddr, buf, size);
+		return; 
+	}
+
+	return rmi_xkphys_lb(dstvaddr, srcpaddr, size);
+}
+
+
diff --git a/arch/mips/rmi/ptr/rmicrf/mutex.c b/arch/mips/rmi/ptr/rmicrf/mutex.c
new file mode 100644
index 0000000..fe3dc28
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/mutex.c
@@ -0,0 +1,119 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+
+#include <rmicrf/types.h>
+#include <rmicrf/crflib.h>
+#include <rmidev/xlrregs.h>
+
+extern void rmi_log_error(const char *fmt, ...);
+
+static inline uint32_t xlr_atomic_swap(uint32_t *addr, uint32_t val)
+{
+	uint32_t tmp, ret;
+
+	__asm__ __volatile__(
+		" .set	push      \n\t"
+		" .set	noreorder \n\t"
+		"1:ll    %0, %2   \n\t"
+		"  move  %1, %3   \n\t"
+		"  sc    %1, %4	  \n\t"
+		"  beqz  %1, 1b   \n\t"
+		"  nop            \n\t"
+		"2:.set   pop      \n"
+		: "=&r" (ret), "=&r" (tmp), "=m" (*addr)
+		: "r" (val), "m" (*addr)
+		: "memory");
+		return ret;
+}
+
+static void rmi_mutex_lock_slow(struct rmi_mutex *mtx, rmi_dom_t dom)
+{
+	int n = 0;
+	int val;
+	do {
+		if (n++ > 65535) {
+			mtx->spincount++;
+			n = 0;
+		}
+
+		val = xlr_atomic_swap(&mtx->lock.value, 1);
+		if (val == 0) {
+			mtx->domain = dom;
+			mtx->cpu = xlr_get_cpuid();
+			xlr_memory_barrier();
+			return;
+		}
+	} while(1);
+}
+
+void rmi_mutex_lock(struct rmi_mutex *mtx)
+{
+	rmi_dom_t dom = rmi_this_domain->id;
+	uint32_t val;
+
+	val = xlr_atomic_swap(&mtx->lock.value, 1);
+	if (val == 0) {
+		mtx->domain = dom;
+		mtx->cpu = xlr_get_cpuid();
+		xlr_memory_barrier();
+		return;
+	} else {
+		/* slow path with spin */
+		return rmi_mutex_lock_slow(mtx, dom);
+	}
+}
+
+void rmi_mutex_unlock(struct rmi_mutex *mtx)
+{
+	uint32_t rv;
+
+	mtx->domain = 0;
+	mtx->cpu = -1;
+	xlr_memory_barrier();
+	rv = xlr_atomic_swap(&mtx->lock.value, 0);
+	assert(rv == 1);
+}
+
+
+
+void rmi_mutex_init(struct rmi_mutex *mtx, uint32_t flags)
+{
+	rmi_dom_t dom = rmi_this_domain->id;
+
+	if (flags & RMI_MUTEX_LOCKED) {
+		mtx->lock.value = 1;
+		mtx->domain = dom;
+	} else {
+		mtx->lock.value = 0;
+		mtx->domain = 0;
+	}
+	xlr_memory_barrier();
+}
diff --git a/arch/mips/rmi/ptr/rmicrf/processor.c b/arch/mips/rmi/ptr/rmicrf/processor.c
new file mode 100644
index 0000000..6df6292
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/processor.c
@@ -0,0 +1,281 @@
+/***********************************************************************
+Copyright 2003-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+#include <rmicrf/types.h>
+#include <rmicrf/api.h>
+#include <rmicrf/crflib.h>
+#include <rmidev/xlrregs.h>
+#include <rmidev/xlrio.h>
+#include <rmidev/pic.h>
+
+/* cache operations */
+#define Index_Invalidate_I_cache      0x00
+#define Index_Writeback_Inv_D_cache   0x01
+#define Hit_Invalidate_I_cache        0x10
+
+#define xlr_cacheop(op, base)                 \
+{                                             \
+	__asm__ __volatile__ (                \
+		".set   push\n"               \
+		".set   mips4\n"              \
+		"cache   %0, 0(%1)\n"         \
+		".set pop\n"                  \
+		: : "i"(op), "r"(base));      \
+}
+
+void rmi_flush_dcache_all(void)
+{
+	int i = 0;
+	int dcache_lines, dcache_sets, dcache_assoc, dcache_line_size;
+	uint64_t base = 0xffffffff80000000ULL;
+	uint32_t config1;
+
+		config1 = xlr_read_c0_config1();
+		dcache_sets = 1 << (((config1 >> 13) & 0x7) + 6);
+		dcache_assoc = ((config1 >> 7) & 0x7) + 1;
+		dcache_line_size = 1 << (((config1 >> 10) & 0x7) + 1);
+		dcache_lines = dcache_sets * dcache_assoc;
+
+		for (i = 0; i < dcache_lines; i++) {
+			xlr_cacheop(Index_Writeback_Inv_D_cache, base);
+		base += dcache_line_size;
+	}
+}
+
+void rmi_flush_icache_all(void)
+{
+	int i = 0;
+	int icache_lines, icache_line_size, icache_sets, icache_assoc;
+	uint64_t base = 0xffffffff80000000ULL;
+	uint32_t config1;
+
+	config1 = xlr_read_c0_config1();
+	icache_line_size = 1 << (((config1 >> 19) & 0x7) + 1);
+	icache_sets = 1 << (((config1 >> 22) & 0x7) + 6);
+	icache_assoc = ((config1 >> 16) & 0x7) + 1;
+	icache_lines = icache_sets * icache_assoc;
+
+	for (i = 0; i < icache_lines; i++) {
+		xlr_cacheop(Index_Invalidate_I_cache, base);
+		base += icache_line_size;
+	}
+}
+
+/* TODO better name ? */
+
+uint32_t rmi_tlb_size_to_page_size(uint32_t size)
+{
+	if (size <= (4 * 1024))
+		return 4 * 1024;
+	if (size <= (16 * 1024))
+		return 16 * 1024;
+	if (size <= (64 * 1024))
+		return 64 * 1024;
+	if (size <= (256 * 1024))
+		return 256 * 1024;
+	if (size <= (1024 * 1024))
+		return 1024 * 1024;
+	if (size <= (4 * 1024 * 1024))
+		return 4 * 1024 * 1024;
+	if (size <= (16 * 1024 * 1024))
+		return 16 * 1024 * 1024;
+	if (size <= (64 * 1024 * 1024))
+		return 64 * 1024 * 1024;
+
+	return 256 * 1024 * 1024;
+}
+
+uint32_t rmi_tlb_size_to_mask(uint32_t size)
+{
+	if (size <= (4 * 1024))
+		return 0x0 << 13;
+	if (size <= (16 * 1024))
+		return 0x03 << 13;
+	if (size <= (64 * 1024))
+		return 0x0f << 13;
+	if (size <= (256 * 1024))
+		return 0x3f << 13;
+	if (size <= (1024 * 1024))
+		return 0xff << 13;
+	if (size <= (4 * 1024 * 1024))
+		return 0x3ff << 13;
+	if (size <= (16 * 1024 * 1024))
+		return 0xfff << 13;
+	if (size <= (64 * 1024 * 1024))
+		return 0x3fff << 13;
+
+	return 0xffff << 13;
+}
+
+/* Dump the current entry* and pagemask registers */
+static void dump_cur_tlb_regs(void)
+{
+	unsigned int entryhihi, entryhilo, entrylo0hi, entrylo0lo, entrylo1hi;
+	unsigned int entrylo1lo, pagemask;
+
+	__asm__ __volatile__(".set push             \n"
+			     ".set noreorder        \n"
+			     ".set mips64           \n"
+			     ".set noat             \n"
+			     "     tlbr             \n"
+			     "     dmfc0  $1, $10   \n"
+			     "     dsrl32 %0, $1, 0 \n"
+			     "     sra    %1, $1, 0 \n"
+			     "     dmfc0  $1, $2    \n"
+			     "     dsrl32 %2, $1, 0 \n"
+			     "     sra    %3, $1, 0 \n"
+			     "     dmfc0  $1, $3    \n"
+			     "     dsrl32 %4, $1, 0 \n"
+			     "     sra    %5, $1, 0 \n"
+			     "     mfc0   %6, $5    \n"
+			     ".set pop              \n":"=r"(entryhihi),
+			     "=r"(entryhilo),
+			     "=r"(entrylo0hi),
+			     "=r"(entrylo0lo),
+			     "=r"(entrylo1hi),
+			     "=r"(entrylo1lo), "=r"(pagemask));
+	printf("%08X%08X %08X%08X %08X%08X %08X",
+	       entryhihi, entryhilo,
+	       entrylo0hi, entrylo0lo, entrylo1hi, entrylo1lo, pagemask);
+}
+
+int rmi_add_wired_tlb_entry(uint64_t entryhi, uint64_t physlo0, uint64_t physlo1, uint32_t pagesz, uint32_t attr)
+{
+    int page_mask = rmi_tlb_size_to_mask(pagesz);
+    uint64_t entrylo0 = (((physlo0 & 0xffffffffffULL) >> 12) << 6) | attr;
+    uint64_t entrylo1 = (((physlo1 & 0xffffffffffULL) >> 12) << 6) | attr;
+    int wired;
+
+    xlr_write_c0_pagemask(page_mask);
+    xlr_write_c0_entryhi(entryhi);
+    xlr_write_c0_entrylo0(entrylo0);
+    xlr_write_c0_entrylo1(entrylo1);
+    wired = xlr_read_c0_wired();
+
+    xlr_write_c0_index(wired);
+    xlr_write_tlb_indexed();
+
+    xlr_write_c0_wired(wired + 1);
+    return wired;
+}
+
+void rmi_delete_wired_tlb_entry(int wired_idx)
+{
+
+    int wired;
+    xlr_write_c0_pagemask(0);
+    xlr_write_c0_entryhi(0);
+    xlr_write_c0_entrylo0(0);
+    xlr_write_c0_entrylo1(0);
+
+    wired = xlr_read_c0_wired();
+
+    xlr_write_c0_index(wired_idx);
+    xlr_write_tlb_indexed();
+
+    if(wired_idx == (wired - 1))
+        xlr_write_c0_wired(wired - 1);
+    return;
+}
+
+
+
+void rmi_dump_tlb(int argc, char *argv[])
+{
+	int entry;
+	int tlbsize;
+	unsigned int config1;
+
+	config1 = xlr_read_c0_config1();
+	tlbsize = ((config1 >> 25) & 0x3f) + 1;
+
+	printf("Current TLB registers state:\n"
+	       "      EntryHi       EntryLo0          EntryLo1     PageMask  Index\n"
+	       "--------------------------------------------------------------------\n");
+	dump_cur_tlb_regs();
+	printf(" %08X\n", xlr_read_c0_index());
+	printf("\n\nFull TLB Dump:\n"
+	       "Idx      EntryHi       EntryLo0          EntryLo1     PageMask\n"
+	       "--------------------------------------------------------------\n");
+	for (entry = 0; entry < tlbsize; entry++) {
+		xlr_write_c0_index(entry);
+		printf("\n%02i ", entry);
+		__asm__ __volatile__(".set push             \n"
+				     ".set mips64           \n"
+				     "     tlbr             \n"
+				     ".set pop              \n");
+		dump_cur_tlb_regs();
+	}
+	printf("\n");
+}
+
+static struct rmi_mutex rmik_def_pic_lock;
+static struct rmi_mutex *rmi_pic_ctrl_lock_get(void)
+{
+	struct rmi_resource *res;
+	rmi_addr_t value;
+	int len;
+	struct rmi_mutex *pic_lock = NULL;
+
+	len = sizeof(value);
+	if(((rmi_resource_getref("pic", &res, NULL)) == 0) &&
+		(rmi_get_property(res, "mutex", NULL, &value, len) > 0))
+		pic_lock = rmi_addr_to_ptr(value);
+	else 
+		rmi_log_error("Pic mutex get failed\n");
+
+	if(pic_lock == NULL) {
+		pic_lock = &rmik_def_pic_lock;
+		rmi_mutex_init(pic_lock, RMI_MUTEX_UNLOCKED);
+   	}
+	rmi_resource_putref(res);
+	return pic_lock;
+}
+
+void rmi_pic_update_ctrl(int timerid, int en)
+{
+	uint32_t ctrl;
+	uint32_t mmio = xlr_io_base + XLR_IO_PIC_OFFSET;
+	static struct rmi_mutex *pic_lock = NULL;
+
+	if(pic_lock == NULL) 
+		pic_lock = rmi_pic_ctrl_lock_get();
+
+	rmi_mutex_lock(pic_lock);
+	ctrl = xlr_read_reg(mmio,  XLR_PIC_CTRL);
+	if(en)
+		ctrl |= (1<<(8 + (timerid)));
+	else
+		ctrl &= (~(1<<(8 + (timerid))));
+
+	xlr_write_reg(mmio, XLR_PIC_CTRL, ctrl);
+	rmi_mutex_unlock(pic_lock);
+}
+
diff --git a/arch/mips/rmi/ptr/rmicrf/rmik_utils.c b/arch/mips/rmi/ptr/rmicrf/rmik_utils.c
new file mode 100644
index 0000000..b420d0f
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/rmik_utils.c
@@ -0,0 +1,486 @@
+/*********************************************************************
+
+  Copyright 2007-2008 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/*
+ * RMIK utils
+ */
+
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/init.h>
+#include <linux/kallsyms.h>
+#include <linux/netdevice.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/config_net.h>
+#include <rmicrf/config.h>
+#include <rmicrf/types.h>
+#include <rmicrf/api.h>
+#include <rmicrf/crflib.h>
+#include <rmicrf/frame.h>
+#include <rmicrf/linux.h>
+#include <rmicrf/crflib.h>
+#include <rmicrf/bootinfo.h>
+#include <asm/rmi/linux_crf.h>
+
+uint64_t *rmi_kernel_args = NULL;
+char *rmi_fdt_buf;
+uint32_t rmi_fdt_buf_size;
+struct rmi_domain *rmi_this_domain;
+void (*rmi_rmik_entry)(int);
+struct rmi_pcpu_info *rmi_pcpu_info;
+int rmi_pcpu_info_size;
+struct psb_info *rmi_boot_info;
+struct rmi_resource *rmi_this_domres = NULL;
+void (*rmi_vnet_pkt_event_handler) (int len, void *msg);
+
+uint32_t dev_tree_en;
+uint32_t rmik_en;
+
+uint32_t xlr_io_base = (uint32_t)DEFAULT_PHOENIX_IO_BASE;
+
+#ifdef CONFIG_RMI_VMIPS
+int	rmi_vmips_max_wired_entries = 2;
+unsigned long rmi_vmips_phys_offset = 0;
+#ifdef CONFIG_32BIT
+unsigned long long rmi_vmips_highmem_start = _AC(0x20000000, UL);
+#endif
+#ifdef CONFIG_64BIT
+unsigned long long rmi_vmips_highmem_start = (_AC(1, UL) << _AC(59, UL));
+#endif
+#endif
+
+
+extern int fdt_init(char *start, char *end);
+
+static __inline__ uint64_t load_c0_scratch0(void)
+{
+  __u32 high, low;
+  __asm__ __volatile__ (
+	    ".set push\n"
+        ".set noreorder\n"
+		".set noat\n"
+        ".set mips64\n" 
+		"dmfc0 $1, $22, 0 \n\t"
+		"nop			\n\t"
+		"dsra32 %0, $1, 0  \n\t"
+		"sll    %1, $1, 0  \n\t"
+		".set pop\n"
+		: "=r" (high), "=r" (low)
+		);
+
+  return ( ((__u64)high) << 32) | low;
+
+}
+
+void *rmi_get_usermac_addr(int size)
+{
+	char name[RMI_MAX_NAMELEN];
+	uint32_t flags = RMI_RES_MEM_FLAGS | RMI_M_ALLOC_UNMAPPED;
+	rmi_physaddr_t paddr = 0;
+	rmi_addr_t vaddr = 0;
+	extern rmi_physaddr_t rmi_memseg_physaddr_get(const char *msegname);
+
+	snprintf(name, sizeof(name), "%s.usermac", rmi_this_domain->name);
+	if(rmi_memseg_create(rmi_this_domres, name, vaddr, size, 0, 
+				0, PAGE_SIZE, flags) < 0) {
+		printk("Usermac address alloc failed\n");
+		return 0;
+	}
+
+	if(rmi_resource_allocate(name, rmi_this_domain->id) < 0) {
+		printk("Usermac domain allocate failed\n");
+		return 0;
+	}
+
+	paddr = rmi_memseg_physaddr_get(name);
+	return (void *)(long)(paddr + CKSEG0);
+}
+
+
+int rmik_alloc_timer(void)
+{
+	static int timer_id = 0;
+	int i;
+	extern int fdt_get_pic_timer_map(unsigned int *timer_list, int max);
+	static int timer_map = 0;
+
+	if(!rmik_en) {
+		if(timer_id >= RMI_MAX_PIC_TIMERS)
+			return -1;
+		return timer_id++;
+	}
+
+	if(timer_map == 0)
+		fdt_get_pic_timer_map(&timer_map, RMI_MAX_PIC_TIMERS); 
+
+	for(i = 0; i < RMI_MAX_PIC_TIMERS; i++) {
+		if(timer_map & ( 1 << i)) {
+			timer_map &= (~( 1 << i));
+			return i;
+		}
+	}
+
+	return -1;
+}
+
+
+int rmik_get_free_running_timer(void)
+{
+	if(!rmik_en)
+		return rmik_alloc_timer();
+
+	return RMI_FREE_RUNNING_PIC_TIMERID;
+}
+
+int rmik_get_uart_status(int uartno)
+{
+    if(!rmik_en)
+        return 0;
+	
+	return fdt_get_uart_status(uartno);
+}
+
+
+static inline void xlr_send_nmi_ipi(int cpu, int vector)
+{       
+/* XLP_MERGE_TODO */
+#if !defined(XLP_SIM)
+    int thread = cpu & 0x3;
+    int core = (cpu >> 2) & 0x7;
+    
+    uint32_t val = (core<<20) | (thread<<16) | (1<<8) | vector;
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+
+    phoenix_write_reg(mmio, PIC_IPI, val);
+#endif
+}
+
+void rmik_wakeup_cpus(void *fn, void *args, uint32_t cpu_mask)
+{
+    int i = 0;
+    int cpuid;
+	uint64_t *trap_frame;
+	struct rmi_pcpu_info *pcpu;
+	struct rmi_domain *dom = rmi_this_domain;
+
+    cpuid = phoenix_cpu_id();
+    cpu_mask &= ~(1 << cpuid);
+	cpu_mask &= dom->cpu_map;
+
+    for (i = 0; i < NR_CPUS; i++) {
+        if (!(cpu_mask & (1 << i)))
+			continue;
+		pcpu = rmi_get_pcpuinfo(i);
+		trap_frame = rmi_addr_to_ptr(pcpu->trapframe);
+		trap_frame[XLR_TF_A0] = (uint64_t)(long)args;
+		trap_frame[XLR_TF_RA] =  (uint64_t)(long)fn;
+		if(smp_boot.boot_info[i].gp)
+            trap_frame[XLR_TF_GP] = smp_boot.boot_info[i].gp;
+        if(smp_boot.boot_info[i].sp)
+            trap_frame[XLR_TF_SP] = smp_boot.boot_info[i].sp;
+		barrier();
+		xlr_send_nmi_ipi(i, IRQ_IPI_CRF_MGMT_IPI);
+    }
+	return ;
+}
+
+void rmik_init(char *g_argv[], int *argc, char *g_envp[])
+{
+	int i;
+	char *strarea;
+	int g_argc = 1;
+	uint64_t *bootargs;
+	uint32_t rmi_boot_version;
+	uint32_t required_heap = 64 * 1024 * 1024;
+
+	 //bootargs = (uint64_t *)(unsigned long)__read_64bit_c0_register($22,0);
+	bootargs = (uint64_t *)(unsigned long)load_c0_scratch0();
+	if(bootargs == NULL) 
+		return;
+
+ 	if(bootargs[-1] != RMI_RMIK_MAGIC)
+		return;
+
+	rmi_kernel_args = bootargs - RMI_BAREA_BINFO_INDEX;
+	rmi_this_domain = (struct rmi_domain *) (long) rmi_kernel_args[RMI_BAREA_DOM_INDEX];
+	strarea = (char *) (long) rmi_kernel_args[RMI_BAREA_ARG_INDEX];
+	
+	/* create argv array, don't copy args as it is in domain mem */
+	while (1) {
+		if (*strarea == '\0')
+			break;
+		if (g_argc != RMI_MAX_ARGS)
+			g_argv[g_argc++] = strarea;	
+
+		while(*strarea++);
+	}
+	if (g_argc == RMI_MAX_ARGS)
+		printk("*** Too many args ***, only %d used\n", g_argc);
+	g_argv[g_argc]  = NULL;
+	
+	strarea++;
+	i = 0;
+	while (1) {
+		if (*strarea == '\0')
+			break;
+		if (i != RMI_MAX_ENVS) 
+			g_envp[i++] = strarea;	
+		while(*strarea++);
+	}
+	if (i == RMI_MAX_ENVS) 
+		printk("*** Too many envs ***, only %d used\n", i);
+	g_envp[i]  = NULL;
+
+	*argc = g_argc;
+	rmi_fdt_buf = (char *)(long)rmi_kernel_args[RMI_BAREA_FDT_INDEX];
+	rmi_fdt_buf_size = rmi_kernel_args[RMI_BAREA_FDT_SZ_INDEX];
+	rmi_rmik_entry = (void (*)(int))(long)(rmi_kernel_args[RMI_BAREA_OS_ENTRY_INDEX]);
+	rmi_pcpu_info = (struct rmi_pcpu_info *)(long)rmi_kernel_args[RMI_BAREA_PCPU_INDEX];
+	rmi_pcpu_info_size = rmi_kernel_args[RMI_BAREA_PCPU_SZ_INDEX];
+	rmi_boot_version = rmi_kernel_args[RMI_BAREA_VERSION_INDEX];
+	rmi_boot_info = (struct psb_info *)bootargs;
+
+	if(rmi_resource_getref(rmi_this_domain->name, &rmi_this_domres, NULL) < 0) 
+		rmicrf_early_print("Domain resource get failed\n");
+	if(rmi_this_domres)
+		rmi_resource_putref(rmi_this_domres);
+
+	   /* panic if crfboot and crf-linux are not compatible */
+	if((RMICRF_VERSION >> RMICRF_COMPAT_ID_OFF) !=
+                (rmi_boot_version >> RMICRF_COMPAT_ID_OFF)) {
+		rmicrf_early_print("Compatibility version mismatch bootVer=%x linuxVer=%x\n",
+				rmi_boot_version >> 16, RMICRF_VERSION >> 16);
+        panic("crf version mismatch\n");
+   	}
+
+	if((RMICRF_VERSION & RMICRF_VERSION_ID_MASK) > (rmi_boot_version & RMICRF_VERSION_ID_MASK))
+        rmicrf_early_print("** Warning ** CRF Linux version is more than the CRF boot version.");
+
+
+	dev_tree_en = rmik_en = 1;
+
+	if(fdt_init(rmi_fdt_buf, rmi_fdt_buf + rmi_fdt_buf_size) != 0x0) {
+           rmicrf_early_print("Fdt init failed \n"); 
+           panic("Fdt init failed \n"); 
+	}
+
+	rmik_vmips_init();
+
+	#ifndef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+	if(read_32bit_phnx_ctrl_reg(4, 0) & 0x01) {
+		rmicrf_early_print("Error: Shared tlb support is disabled in Linux\n");
+		panic("Compile Linux with Shared tlb support enabled\n");
+	}
+	#endif
+#if 0
+	/* Linux requires atleast 64M heap size and 1 free running pic timer, */
+	i = fdt_get_pic_timer_map(&timer_map, RMI_MAX_PIC_TIMERS); 
+	if(i < 1) 
+		rmicrf_early_print("Linux requires 1 Free running PIC timer , Configured is %d", i);
+#endif
+
+	if(fdt_get_heap_size() < required_heap) 
+		rmicrf_early_print("Booting may fail if the heap size %lld MB configured is < %d MB",
+			 (unsigned long long)fdt_get_heap_size()/(1024 * 1024), required_heap / (1024 * 1024));
+
+	return;
+}
+
+extern void rmi_vmips_wired_entry_read(
+		int index, uint64_t *entryhi,
+        unsigned long *entrylo0, unsigned long *entrylo1);
+
+void rmik_vmips_init(void)
+{
+	int vmips_mode;
+
+	/* check whether vmips enabled or not */
+	vmips_mode = read_32bit_phnx_ctrl_reg(1, 0);
+	if(!(vmips_mode & (1 << 15)))
+		return;
+	#ifndef CONFIG_RMI_VMIPS
+	rmicrf_early_print("Error : VMIPS is disabled in Linux. ");
+	panic("Vmips not enabled");
+	#else 
+	{
+	unsigned long entrylo0;
+	/* Wired entry 0 mapps the linux link address */
+	rmi_vmips_wired_entry_read(0, NULL, &entrylo0, NULL);
+	rmi_vmips_phys_offset = (entrylo0 >> 6) << 12;
+	rmi_vmips_highmem_start = rmi_vmips_phys_offset + 512 * 1024 * 1024;
+	}
+	#endif
+
+	//printk("rmi vmips physoffset=%lx\n", rmi_vmips_phys_offset);
+
+}
+
+#define MSGRNG_CC_INIT_CPU_DEST(conf, dest) \
+do { \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf[dest][0], 0 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf[dest][1], 1 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf[dest][2], 2 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf[dest][3], 3 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf[dest][4], 4 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf[dest][5], 5 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf[dest][6], 6 ); \
+     msgrng_write_cc(MSGRNG_CC_##dest##_REG, conf[dest][7], 7 ); \
+} while(0)
+
+/* Initialized CC for cpu 0 to send to all buckets at 0-7 cpus */
+#define MSGRNG_CC_INIT_CPU(conf) \
+do { \
+  MSGRNG_CC_INIT_CPU_DEST(conf,0); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,1); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,2); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,3); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,4); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,5); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,6); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,7); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,8); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,9); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,10); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,11); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,12); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,13); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,14); \
+  MSGRNG_CC_INIT_CPU_DEST(conf,15); \
+} while (0)
+
+#define MSGRNG_BUCKETSIZE_INIT_CPU(conf) \
+do { \
+  msgrng_write_bucksize(0, conf[0]);         \
+  msgrng_write_bucksize(1, conf[1]);         \
+  msgrng_write_bucksize(2, conf[2]);  \
+  msgrng_write_bucksize(3, conf[3]);  \
+  msgrng_write_bucksize(4, conf[4]);  \
+  msgrng_write_bucksize(5, conf[5]);  \
+  msgrng_write_bucksize(6, conf[6]);  \
+  msgrng_write_bucksize(7, conf[7]);  \
+} while(0)
+
+void rmik_phoenix_msgring_cpu_init(void)
+{
+	int id = cpu_logical_map(smp_processor_id());
+	int core;
+	int ret;
+	char buckets[NR_STNS_PER_CORE + 1];
+	char credits[MAX_TX_STNS][8];
+	unsigned long flags;
+	static int cpu_msgring_cfgd[NR_CORES] = { 0, 0, 0, 0, 0, 0, 0, 0 };
+
+	/* get the ownership flags proceed only if this cpu is the owner */
+	core = id / 4;
+	if(cpu_msgring_cfgd[core])
+		return;
+
+
+	cpu_msgring_cfgd[core] = 1;
+
+	ret = fdt_get_core_bucket_conf(core, buckets, NR_STNS_PER_CORE, credits, MAX_NUM_MSGRNG_STN_CC);
+	if(ret < 0) {
+		prom_dbg_msg("DTB:Linux is not the msgring owner for core-%d\n", core);
+		return;
+	}
+	prom_dbg_msg("DTB:Initializing message ring for core-%d\n", core);
+
+	msgrng_flags_save(flags);
+	MSGRNG_BUCKETSIZE_INIT_CPU(buckets);
+	MSGRNG_CC_INIT_CPU(credits);
+	msgrng_flags_restore(flags);
+	return;
+}
+
+int rmik_own_bucket_list_get(int *start, int *end, int *mask)
+{
+	uint64_t bkmask = 0x0;
+	uint16_t bk, core;
+	int sfound = 0, ret = 0x0, i;
+
+	fdt_get_bucketmask(&bkmask);
+
+	for(core = 0x0; core < NR_CPUS / NR_CPUS_PER_CORE ; core++ ) {
+		sfound = 0;
+		bk = (uint16_t)(bkmask >> (core * NR_STNS_PER_CORE)) & 0x00ff;
+		for(i = 0x0; i < NR_STNS_PER_CORE; i++) {
+			if(!sfound && (bk & (1 << i))) {
+				start[core] = i;
+				sfound = 1;
+			}
+			if((bk & (1 << i)))
+				end[core] = i + 1;
+		}
+		mask[core] = bk;
+		prom_dbg_msg("DTB:Core bucket map for core-%d is 0x%x 0x%x 0x%x\n", core, 
+							start[core], end[core], mask[core]);
+	}
+	return ret;
+}
+
+uint32_t rmik_cpu_msgring_int_mask[RMI_MAX_CORES];
+int rmik_derive_msgring_int_mask(void)
+{
+	int ret_fdt;
+	int core, vcpu_idx;
+	uint32_t msgring_int_en = 0x0;
+	int i=0;
+	int core_processed = 0xff;
+
+	for (i=0; i < NR_CPUS ;i++) {
+		if (cpu_isset(i, cpu_online_map)) {
+			core = cpu_logical_map(i) / 4;
+			vcpu_idx = cpu_logical_map(i);
+
+			if(core_processed == core) {
+				if(msgring_int_en)
+					rmik_cpu_msgring_int_mask[core] |= (1 << (vcpu_idx % NR_CPUS_PER_CORE));
+				continue;
+			}
+			core_processed = core;
+					
+			rmik_cpu_msgring_int_mask[core] = 0x0;
+
+			msgring_int_en = 0x0;
+			ret_fdt = fdt_get_msgring_int_status(core, &msgring_int_en);
+			if(msgring_int_en) 
+				rmik_cpu_msgring_int_mask[core] |= (1 << (vcpu_idx % NR_CPUS_PER_CORE));
+
+		}
+	}
+	return 0;
+}
+
+int rmi_get_domain(rmi_dom_t dom, struct rmi_domain *domain)
+{
+        memcpy(domain, &rmi_this_domain[(int)(dom - rmi_this_domain->id)], sizeof(*domain));
+        return 0;
+}
diff --git a/arch/mips/rmi/ptr/rmicrf/utils.c b/arch/mips/rmi/ptr/rmicrf/utils.c
new file mode 100644
index 0000000..6788bcb
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmicrf/utils.c
@@ -0,0 +1,42 @@
+/***********************************************************************
+Copyright 2007-2008 Raza Microelectronics, Inc.(RMI). All rights
+reserved.
+Use of this software shall be governed in all respects by the terms and
+conditions of the RMI software license agreement ("SLA") that was
+accepted by the user as a condition to opening the attached files.
+Without limiting the foregoing, use of this software in source and
+binary code forms, with or without modification, and subject to all
+other SLA terms and conditions, is permitted.
+Any transfer or redistribution of the source code, with or without
+modification, IS PROHIBITED,unless specifically allowed by the SLA.
+Any transfer or redistribution of the binary code, with or without
+modification, is permitted, provided that the following condition is
+met:
+Redistributions in binary form must reproduce the above copyright
+notice, the SLA, this list of conditions and the following disclaimer
+in the documentation and/or other materials provided with the
+distribution:
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. `AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************#RMI_3#***********************************/
+
+#include <rmicrf/types.h>
+#include <rmicrf/crflib.h>
+
+void rmi_log_error(const char *fmt, ...)
+{
+	va_list alist;
+
+	va_start(alist, fmt);
+	vprintk(fmt, alist);
+	va_end(alist);
+}
diff --git a/arch/mips/rmi/ptr/setup.c b/arch/mips/rmi/ptr/setup.c
new file mode 100644
index 0000000..27f7076
--- /dev/null
+++ b/arch/mips/rmi/ptr/setup.c
@@ -0,0 +1,1653 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/*
+ * Setup code for RMI's XLR-based boards
+ */
+
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/init.h>
+#include <linux/pm.h>
+
+#include <asm/irq.h>
+#include <asm/io.h>
+#include <asm/bootinfo.h>
+#include <asm/addrspace.h>
+#include <asm/reboot.h>
+#include <asm/time.h>
+#include <linux/interrupt.h>
+#include <asm/atomic.h>
+#include <asm/cacheflush.h>
+
+#include <asm/rmi/sim.h>
+#include <asm/mipsregs.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/debug.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/msgring.h>
+
+#include <asm/rmi/phnx_loader.h>
+#include <user/rmi/phnx_loader.h>
+#include <asm/rmi/rmi_pcix_gen_dev.h>
+#include <asm/rmi/memory-exclusion.h>
+#include <asm/rmi/linux_crf.h>
+#include <asm/rmi/rmicrf/api.h>
+
+#include <linux/serial.h>
+#include <linux/serial_core.h>
+#include <linux/module.h>
+#include <linux/proc_fs.h>
+
+#ifdef RMI_BRIDGE_WKAROUND
+#include <asm/rmi/rmi_rw_lock.h>
+#include <asm/rmi/global_shmem.h>
+rmi_rwlock_t *rmi_bridge_lock;
+EXPORT_SYMBOL(rmi_bridge_lock);
+int rmi_enable_br_wrkaround = 0;
+EXPORT_SYMBOL(rmi_enable_br_wrkaround);
+#endif
+
+struct proc_dir_entry *rmi_root_proc;
+EXPORT_SYMBOL(rmi_root_proc);
+
+unsigned long long phnx_tlb_stats[32] __cacheline_aligned;
+
+spinlock_t atomic_lock = SPIN_LOCK_UNLOCKED;
+
+__u8 phoenix_base_mac_addr[6];
+volatile phnx_loader_shared_struct_t *phnx_loader_sh_mem = NULL;
+/* used for command line parsing */
+uint32_t phnx_loader_kseg_start, phnx_loader_kseg_size;
+uint32_t phnx_loader_mask;
+/* Size of the shared memory b/w Linux userapp and rmios apps */
+uint32_t phnx_app_sh_mem_sz;
+unsigned long  phnx_app_shmem_start;
+static int index = 0;
+static char *hybrid_str = NULL;
+
+/* xls chip family variables */
+int chip_is_xls6xx = 0;
+int chip_is_xls4xx = 0;
+int chip_is_xls2xx = 0;
+int chip_is_xls1xx = 0;
+int chip_is_xls = 0;
+int chip_is_xls_b0 = 0;
+int chip_is_xls6xx_b0 = 0;
+int chip_is_xls4xx_b0 = 0;
+EXPORT_SYMBOL(chip_is_xls6xx);
+EXPORT_SYMBOL(chip_is_xls4xx);
+EXPORT_SYMBOL(chip_is_xls2xx);
+EXPORT_SYMBOL(chip_is_xls1xx);
+EXPORT_SYMBOL(chip_is_xls);
+EXPORT_SYMBOL(chip_is_xls_b0);
+EXPORT_SYMBOL(chip_is_xls6xx_b0);
+EXPORT_SYMBOL(chip_is_xls4xx_b0);
+
+/*Environment Vairables*/
+struct environment xlr_bldr_env ;
+
+__u32 xlr_board_major_version = RMI_PHOENIX_BOARD_ARIZONA_I;
+__u32 xlr_board_minor_version = 0;
+
+#define DEFAULT_LINUX_CPU_MASK 0x1
+#define DEFAULT_LOADER_MASK ~DEFAULT_LINUX_CPU_MASK
+
+struct kuseg_mem_info kuseg_mem_map[MAX_NUM_KUSEG_BLOCKS];
+
+void prom_init_xlr_loader_setup(struct psb_info *prom_info);
+
+void *phoenix_psb_shm = 0;
+unsigned long phoenix_psb_shm_size = 0;
+static int dyna_exc_index=0;
+extern unsigned long _text[];
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+unsigned long rmi_asid_mask = 0x3f;
+unsigned int rmi_shtlb = 1; /* by default shared TLB is enabled */
+#endif
+
+extern struct psb_info *rmi_boot_info;
+struct psb_info *prom_info = 0;
+struct psb_info prom_info_copy; /* Bootloader prom_info is saved here */
+static struct psb_info default_prom_info = {
+	.boot_level              = 2,
+	.io_base                 = DEFAULT_PHOENIX_IO_BASE,
+	.output_device           = 2,
+	.rmi_cpu_online_map          = 0x01,
+	.magic_dword             = (((__u64)0x900dbeef << 32)|PSB_INFO_VERSION),
+	.size                    = sizeof(struct psb_info),
+	.mac_addr                = 0x000102030405ULL,
+	.cpu_frequency           = 1200000000,
+	.board_version           = 1,
+	.board_major_version     = 1,
+	.board_minor_version     = 0,
+};
+
+static struct physmap_info {
+	int type;
+	char *name;
+} psb_physmap_info[] =
+{
+	{ 0x01 , "Memory" },
+	{ 0x02 , " *** HOLE ***" },
+	{ 0x10 , "Phoenix IO Space" },
+	{ 0x11 , "PCIX IO Space"    },
+	{ 0x12 , "PCIX CFG Space"   },
+	{ 0x13 , "PCIX Memory Space"},
+	{ 0x14 , "HT IO Space"      },
+	{ 0x15 , "HT CFG Space" },
+	{ 0x16 , "HT Memory Space" },
+	{ 0x17 , "SRAM (QDR) Space" },
+	{ 0x18 , "Flash Controller Space" },
+	{ 0xff , "Unknown type" }
+};
+
+struct boot_mem_map boot_physaddr_info;
+
+/* The below regions should be in ascending order of the starting physical addresses */
+static struct boot_mem_map_exclude_region dynamic_exclude_regions[] = {
+	[0] = {0, 0}, /* PCI Shared Mem Or RMIOS Lib Memory*/
+	[1] = {0, 0}, /* PCI Shared Mem Or RMIOS Lib Memory*/
+	[2] = {0, 0}, /* Loader KSEG0 region */
+	[3] = {0, 0}, /* Loader KUSEG region Block 1*/
+	[4] = {0, 0}, /* Loader KUSEG region Block 2 or Hybrid Mode exclusion*/
+	[5] = {0, 0}, /* Loader KUSEG region Block 3 or Hybrid Mode exclusion */
+	[6] = {0, 0}, /* Loader KUSEG region Block 4 or Hybrid Mode exclusion */
+	[7] = {0, 0}, /* Hybrid Mode exclusion*/
+	[8] = {0, 0}, /* END of the list - MUST be the last entry always */
+};
+
+#if 0
+static void _early_print(const char *fmt, int a1, int a2, int a3, int a4, int a5, int a6, int a7, int a8, int a9, int a10)
+{
+	if(prom_info && prom_info->uart_print){
+		((void (*)(const char *, int, int, int, int, int, int, int, int, int, int))(unsigned long)prom_info->uart_print)(fmt, a1, a2, a3, a4, a5, a6, a7, a8, a9, a10);
+	}
+}
+
+static void _rmi_early_print(const char *fmt)
+{
+	_early_print(fmt, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);
+}
+
+void rmi_early_print(const char *func, int line)
+{
+	char buf[100] = {0};
+	sprintf(buf,"%s %d\n",func,line);
+	_rmi_early_print(buf);
+}
+#endif
+
+static char *get_psb_physmap_name(int type)
+{
+	int i = 0;
+	int tsize = sizeof(psb_physmap_info) / sizeof(struct physmap_info);
+
+	for( i = 0; i < tsize; i++ )
+	{
+		if( (psb_physmap_info[i].type == type ) ||
+		    (psb_physmap_info[i].type == 0xff ) )
+			return psb_physmap_info[i].name;
+	}
+	return ("Unknown type");
+}
+
+// returns 1 for IO and 0 for mem 1 for not found
+int phnx_get_pgprot(unsigned long address)
+{
+	int i;
+	__u64 start=0, end=0;
+	char *name = NULL;
+
+	for(i=0; i < boot_physaddr_info.nr_map; i++) 
+	{
+		start = boot_physaddr_info.map[i].addr;
+		end = boot_physaddr_info.map[i].addr + boot_physaddr_info.map[i].size;
+		if((address >= start) && (address < end)) 
+		{
+			name = get_psb_physmap_name(boot_physaddr_info.map[i].type);
+			if(!(strcmp(name, "Memory"))) 
+			{
+				return 0;
+			} else {
+				return 1;
+			}
+		}
+	}
+	return 1;
+}
+
+
+/* return 1 for success and 0 for failure */
+int valid_mmap_phnx_addr_range(unsigned long pfn)
+{
+	int i;
+	__u64 end=0;
+	for(i=0; i < boot_physaddr_info.nr_map; i++) 
+	{
+		end = boot_physaddr_info.map[i].addr + boot_physaddr_info.map[i].size;
+		end = end >> PAGE_SHIFT;
+		if(pfn <= (unsigned long)end)
+			return 1;
+	}
+	return 0;
+}
+
+static int sanity_check_prom_info(struct psb_info *info)
+{
+	if (!prom_info) return 0;
+  
+	if ((prom_info->magic_dword & 0xffffffffULL) != 0x900dbeef) return 0;
+	if ((prom_info->magic_dword >> 32) != PSB_INFO_VERSION) return 0;
+	//if (prom_info->size < sizeof(struct psb_info)) return 0;
+
+	return 1;
+}
+
+#if defined(CONFIG_RMI_XLP_SIM)
+const char *DEFAULT_CONSOLE_BOOT_PARAMS = "xlp_noi2c mem=255m@1m mem=512m@512m console=ttyS0,115200 ";
+#else
+const char *DEFAULT_CONSOLE_BOOT_PARAMS = "mem=255m@1m mem=512m@512m console=ttyS0,115200 ";
+#endif
+const char *DEFAULT_INITRD_BOOT_PARAMS = "rdinit=/sbin/init ";
+
+const char *get_system_type(void)
+{
+#ifdef CONFIG_RMI_XLP
+	return "RMI XLP SIM";
+#else
+	if ( is_xls() )
+		return "RMI XLS";
+	return "RMI XLR";
+#endif
+}
+
+#ifdef CONFIG_SMP
+atomic_t cpus_rebooted = ATOMIC_INIT(0);
+#endif
+
+#define GPIO_SWRESET_REG 8
+
+static void ptr_linux_exit(void)
+{
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_GPIO_OFFSET);
+	extern struct rmi_domain *rmi_this_domain;
+
+	if(rmik_en)  {
+		rmi_domain_stop(rmi_this_domain->id);
+	} else
+		/* trigger a chip reset */
+		phoenix_write_reg(mmio, GPIO_SWRESET_REG, 1);
+	for(;;) cpu_wait();
+}
+
+void __init bus_error_init(void)
+{
+}
+
+void prom_reconfigure_thr_resources(void)
+{
+	unsigned int mmu_setup = 0;
+	int value = 0;
+	__u32 online_map = prom_info->rmi_cpu_online_map;
+	__u32 thr_mask = online_map >> (phoenix_cpu_id()<<2);
+	int i=0, count=0;
+	int dis_contig=0;
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+	uint32_t map;
+#endif
+
+
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+	/* rmi kernel configures this */
+	if(rmik_en) {
+		if((read_32bit_phnx_ctrl_reg(4, 0) & 0x01) == 0) {
+			/* shared tlb is disabled */
+			rmi_shtlb = 0;
+			rmi_asid_mask = 0xff;
+		}
+		return;
+	}
+
+	if(rmi_shtlb && (rmi_asid_mask == 0x3f)) {
+		/* global TLB will work only if all the cores enabled
+		   have all the threads owned by Linux. If not, fall back to
+		   the default mode.
+		 */
+		map = online_map;
+		for(i=0; i < NR_CPUS; i+=4){
+			if((map & 0xf) && ((map & 0xf) != 0xf)) {
+				rmi_asid_mask = 0xff;
+				rmi_shtlb = 0;
+				printk("Disabling Shared TLB mode\n");
+				break;
+			}
+			map >>= 4;
+		}
+		if((rmi_asid_mask == 0x3f) && (phoenix_thr_id() == 0)) {
+			mmu_setup = read_32bit_phnx_ctrl_reg(4, 0);
+			mmu_setup = mmu_setup | 0x1;
+			write_32bit_phnx_ctrl_reg(4, 0, mmu_setup);
+
+			printk("CPU %d: Enabled Shared TLB mode \n", 
+					phoenix_cpu_id());
+			return;
+		}
+	}
+	return;
+#endif
+	if(rmik_en)
+		return;
+
+	 if (phoenix_thr_id()==0 ) { 
+
+		for(i=0;i<4;i++) {
+			if (thr_mask & (1<<i)) {
+				if(i != count)
+					dis_contig = 1;
+				count++;
+			}
+		}
+		switch(count) {
+		case 1: value = 0x00; break;
+		case 2: value = 0x02; break;
+		default:
+			value = 0x03; break;
+		}
+		if(dis_contig)
+			value = 0x3; 
+
+		mmu_setup = read_32bit_phnx_ctrl_reg(4, 0);
+		mmu_setup = mmu_setup & ~0x06;
+		mmu_setup |= (value << 1);
+
+		/* turn on global mode */
+		/* mmu_setup |= 0x01; */
+    
+		write_32bit_phnx_ctrl_reg(4, 0, mmu_setup);
+      
+	} 
+}
+int xlr_hybrid;
+int xlr_loader_support=0;
+int xlr_loader_sharedcore=0;
+int xlr_loader_own_gmac=0;
+int xlr_loader_own_dma=0;
+
+uint32_t xlr_linux_cpu_mask;
+int xlr_console_pci_con_dev = 0;
+int xlr_console_pci_con_baud = 0;
+int xlr_boot_over_nfs = 0;
+
+unsigned long phnx_ebase = 0x0;
+
+#if !defined(CONFIG_PHOENIX_MAC)
+struct user_mac_data *user_mac;
+struct xlr_user_mac_config xlr_user_mac;
+#endif
+
+static void xlr_initialize_setups(void)
+{
+	xlr_hybrid = XLR_HYBRID_NONE;
+	xlr_user_mac.l4_extract = 0;
+	xlr_user_mac.fast_syscall = 1;
+	xlr_loader_support = 0;
+	xlr_loader_sharedcore = 0;
+	xlr_loader_own_gmac = 0;
+	xlr_loader_own_dma = 0;
+	xlr_linux_cpu_mask = DEFAULT_LINUX_CPU_MASK; 
+	phnx_loader_kseg_start = 0;
+	for ( index = 0 ; index < MAX_NUM_KUSEG_BLOCKS ; index++) {
+		kuseg_mem_map[index].start_addr = 0;
+		kuseg_mem_map[index].size = 0;
+	}
+	phnx_loader_kseg_size = 0;
+	phnx_loader_mask = DEFAULT_LOADER_MASK;
+}
+
+void exclude_hybrid_mem_region(void)
+{
+	if(xlr_loader_support){
+		return;
+	}
+	dynamic_exclude_regions[dyna_exc_index].start = 1<<20;
+	dynamic_exclude_regions[dyna_exc_index].end = 
+		(unsigned long long)(((unsigned long)&_text) & 0x1fffffffUL);
+	dyna_exc_index++;
+}
+
+#ifndef CONFIG_MAPPED_KERNEL
+static void xlr_early_hybrid_setup(char *str)
+{
+
+	hybrid_str = str;
+
+	if(rmik_en ) {
+		if(strcmp(str, "=rmios_ipsec") == 0)
+			printk("***Hybrid Option rmios_ipsec is not supported with CRF***\n");
+		
+		if(strcmp(str, "=rmios_tcpip_stack") == 0)
+			printk("***Hybrid Option rmios_tcpip_stack is not supported with CRF***\n");
+
+		return ;
+	}
+
+    if ((strcmp(str, "=rmios_ipsec") == 0)||
+		 (strcmp(str, "rmios_ipsec") == 0)){
+        exclude_hybrid_mem_region();
+	}
+	else if ((strcmp(str, "=rmios_tcpip_stack") == 0)||
+		 (strcmp(str, "rmios_tcpip_stack") == 0)) {
+		exclude_hybrid_mem_region();
+	}
+}
+#endif
+
+static int xlr_hybrid_setup(char *str)
+{
+	uint32_t loader_reg;
+	uint64_t kernel_start;
+
+	if ((strcmp(str, "=user_mac_xgmac") == 0)||
+	    (strcmp(str, "user_mac_xgmac") == 0)) {
+		if(xlr_board_atx_ii()){
+			xlr_hybrid = XLR_HYBRID_USER_MAC_XGMAC;
+			printk("Configured for Hybrid mode with USER_MAC_XGMAC\n");
+		} else if ( xlr_board_atx_i()) {
+			xlr_hybrid = XLR_HYBRID_USER_MAC_SPI4;
+			printk("Configured for Hybrid mode with USER_MAC_SPI4\n");
+		}else{
+			printk("user_mac_xgmac hybrid mode is available only on ATX-II\n");
+		}
+	}
+	else if ((strcmp(str, "=user_mac") == 0)||(strcmp(str, "user_mac") == 0)) {
+		xlr_hybrid = XLR_HYBRID_USER_MAC;
+		printk("Configured for Hybrid mode with USER_MAC\n");
+	}
+	else if ((strcmp(str, "=rmios_ipsec") == 0)||
+		 (strcmp(str, "rmios_ipsec") == 0)){
+		xlr_hybrid = XLR_HYBRID_RMIOS_IPSEC;
+		printk("Configured for Hybrid mode with RMIOS IPSEC\n");
+	}
+	else if ((strcmp(str, "=rmios_tcpip_stack") == 0)||
+		 (strcmp(str, "rmios_tcpip_stack") == 0)) {
+		xlr_hybrid = XLR_HYBRID_RMIOS_TCPIP_STACK;
+		kernel_start = (uint64_t)(((unsigned long)&_text) & 0x1fffffffUL);
+		if(kernel_start < PHNX_RMIOS_TCPIP_END){
+			panic("Build kernel with loadaddress above %#x\n",
+			      PHNX_RMIOS_TCPIP_END);
+		}
+		printk("Configured for Hybrid mode with RMIOS_TCPIP_STACK\n");
+	}
+	else {
+		xlr_hybrid = XLR_HYBRID_NONE;
+		printk("Configured for Hybrid mode with None\n");
+	}
+
+	/* usermac or usermac xgmac cannot work with shared core */
+	if(xlr_hybrid_user_mac() || xlr_hybrid_user_mac_xgmac()){
+		if(xlr_loader_support && xlr_loader_sharedcore) {
+			printk("Disabling USER_MAC support:Cannot be enabled with shared_core option\n");
+			xlr_hybrid = XLR_HYBRID_NONE;
+		}
+	}
+
+	if((xlr_hybrid != XLR_HYBRID_NONE) && (xlr_loader_support)) {
+		/* Don't allow loader feature if hybrid app and loader are
+		   using same memory region
+		*/
+		loader_reg = phnx_loader_kseg_start + phnx_loader_kseg_size;
+
+        if(xlr_hybrid == XLR_HYBRID_RMIOS_IPSEC){
+            if(((PHNX_RMIOS_IPSEC_START >= phnx_loader_kseg_start) &&
+	    		(PHNX_RMIOS_IPSEC_END< loader_reg)) ||
+	           	  ((phnx_loader_kseg_start >= PHNX_RMIOS_IPSEC_START) &&
+    		   (phnx_loader_kseg_start < PHNX_RMIOS_IPSEC_END)))	{
+	    		xlr_loader_support=0;
+		    	printk("Disabling Loader support as hybrid mode is selected\n");
+    			printk("Use different memory range for loader KSEG region if hybrid mode needs to be enabled.\n");
+	    	}
+        }else if(xlr_hybrid == XLR_HYBRID_RMIOS_TCPIP_STACK){
+            if(((PHNX_RMIOS_TCPIP_START >= phnx_loader_kseg_start) &&
+			    (PHNX_RMIOS_TCPIP_END< loader_reg)) ||
+			   ((phnx_loader_kseg_start >= PHNX_RMIOS_TCPIP_START) &&
+			    (phnx_loader_kseg_start < PHNX_RMIOS_TCPIP_END)))	{
+				xlr_loader_support=0;
+				printk("Disabling Loader support as hybrid mode is selected\n");
+				printk("Use different memory range for loader KSEG region if hybrid mode needs to be enabled.\n");
+			}
+		}
+	}
+
+	if(rmik_en) {
+		if((xlr_hybrid != XLR_HYBRID_NONE) &&  (!(
+			(xlr_hybrid == XLR_HYBRID_USER_MAC) ||
+			(xlr_hybrid == XLR_HYBRID_USER_MAC_XGMAC) ||
+			(xlr_hybrid == XLR_HYBRID_USER_MAC_SPI4)))) {
+			printk("***Hybrid Options other than user_mac and user_mac_xgmac are not supported with CRF***\n");
+			xlr_hybrid = XLR_HYBRID_NONE;
+		}
+	}
+			
+	
+	return 1;
+}
+
+
+unsigned int __cpuinit get_c0_compare_int(void)
+{
+    return IRQ_TIMER;
+}
+
+void plat_time_init(void)
+{
+    extern void phoenix_timer_setup(void);
+
+    /* only needed for use cpu counter timer interrupt source */
+    mips_hpt_frequency = (unsigned int)prom_info->cpu_frequency;
+    printk("mips_hpt_frequency = %u\n", mips_hpt_frequency);
+
+    phoenix_timer_setup();
+}
+
+
+void __init plat_mem_setup(void)
+{
+	extern int panic_timeout;
+  
+	panic_timeout = 5;  
+  
+	//board_be_handler = ptr_be_handler;
+  
+	_machine_restart   = (void (*)(char *))ptr_linux_exit;
+	_machine_halt      = ptr_linux_exit;
+	pm_power_off = ptr_linux_exit;
+
+	return;
+}  
+
+/* Don't need a really big stack here */
+#define PER_CPU_THREAD_SIZE (THREAD_SIZE >> 2)
+#define TOTAL_THREAD_SIZE       (PER_CPU_THREAD_SIZE * (NR_CPUS - 1))
+/* This structure is used for changing sp and gp of secondary CPUs from that
+   of the bootloader and used until Linux kernel allocates one for them
+*/
+struct xlr_stack_pages {
+	unsigned long stack[(TOTAL_THREAD_SIZE)/sizeof(long)];
+};
+
+struct xlr_stack_pages xlr_stack_pages_temp
+__attribute__((__section__(".data.init_task"),
+	       __aligned__(THREAD_SIZE)));
+
+extern void prom_pre_boot_secondary_cpus(void *);
+
+#ifdef CONFIG_MAPPED_KERNEL
+#define secondary_cpus_bootup_func ((unsigned long)prom_pre_boot_secondary_cpus - (unsigned long)LOADADDR + (unsigned long)PHYSADDR)
+#else
+#define secondary_cpus_bootup_func prom_pre_boot_secondary_cpus
+#endif
+
+#define BOOT_LOADER_REGION_SZ 0x04000000
+#define LOADER_KSEG_END 0x10000000
+
+/* arg -> arg passed by user
+   name - pointer to the start of name=value string
+   base - conversion base 
+   res - converted number is stored here 
+   NOTE: returned value is a 32 bit number always
+   
+   Returns 0 on success, -1 otherwise
+*/
+static int get_name_value(char *arg, char *name, int base, uint32_t *res)
+{
+	char *ptr;
+
+	if((ptr = strstr(arg, name)) == NULL)
+		return -1;
+
+	if(!strcmp("app_sh_mem_sz=", name)){
+
+		printk("WARNING: \"app_sh_mem_sz\"  option  is  deprecated\n");
+		printk("WARNING: Use ./userapp shmem option to reserve app "
+				 "shared memory\n");
+		return -1;
+	}
+			
+	ptr = strrchr(ptr, '=');
+	dprintk("ptr after strrchr = %s\n", ptr);
+	ptr++;
+	*res = (uint32_t)simple_strtol(ptr, (char **)NULL, base);
+	return 0;
+
+}
+
+struct phnx_name_value_struct {
+	char *name;
+	uint32_t *val;
+};
+static struct phnx_name_value_struct phnx_name_value_args[] = {
+	{"linux_cpu_mask=", &xlr_linux_cpu_mask },
+        {"kseg0_start=", &phnx_loader_kseg_start}, 
+	{"kseg0_size=", &phnx_loader_kseg_size},
+	{"app_sh_mem_sz=", &phnx_app_sh_mem_sz},
+	{NULL, NULL}
+};
+
+void parse_kuseg_mem_args(char *p)
+{
+	static int count = 0;
+	uint64_t start = 0, size= 0;
+
+	if ( count == MAX_NUM_KUSEG_BLOCKS ) {
+		printk("The maximun number of kuseg block that can be allocated is %d so ignoring this %s\n",MAX_NUM_KUSEG_BLOCKS,p);
+		return;
+	}
+	p = p + strlen("kumem=");
+	size = memparse(p, &p);
+
+	if ( (size == 0) || ((size & (((uint64_t)2 << 20) - 1)) == (1 << 20 ) ))
+		return;
+
+
+	kuseg_mem_map[count].size = size;
+
+	if (*p == '@'){
+		start = memparse(p + 1, &p);
+		
+		/* start Addr should be the multiple of 2M */
+		if (((size & (((uint64_t)2 << 20) - 1)) == (1 << 20 ) ) ) 
+			return;
+	}
+	
+	kuseg_mem_map[count].start_addr = start;
+        count++;
+
+
+}
+void prom_parse_args(int argc, char *argv[]) 
+{
+	int i, j;
+	int ret;
+	char *tmp = NULL;
+	/* Check if loader support needs to be enabled */
+	for(i=1;i<argc;i++) {
+		if (argv && argv[i]) {
+			if(strcmp(argv[i], "rmi_no_shtlb") == 0){
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+				rmi_shtlb = 0;
+				rmi_asid_mask = 0xff;
+				printk("Disabling Shared TLB Support\n");
+#endif
+			} else if(strcmp(argv[i], "xlr_loader") == 0){
+				xlr_loader_support = 1;
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+				rmi_shtlb = 0;
+				rmi_asid_mask = 0xff;
+#endif
+				printk("Enabling XLR Linux Loader support\n");
+			}else if(strcmp(argv[i], "shared_core") == 0) {
+				xlr_loader_sharedcore = 1;
+				printk("Linux and RMIOS applications can run"
+							"on same core\n");
+			}else if(strstr(argv[i],"kumem=") != NULL){
+                                parse_kuseg_mem_args(argv[i]);
+                        }else if(strcmp(argv[i],"console=/dev/pci_co0") == 0){
+				xlr_console_pci_con_dev = 1;
+			}else if(strcmp(argv[i],"console=pci_co,38400") == 0){
+				xlr_console_pci_con_baud = 1;
+			}
+			else if(strcmp(argv[i],"root=/dev/nfs") == 0){
+				xlr_boot_over_nfs = 1;
+			}else if(strcmp(argv[i], "own_gmac") == 0) {
+				xlr_loader_own_gmac = 1;
+				printk("Linux will own gmac ports\n");	
+			}else if(strncmp(argv[i],"xlr_hybrid=",strlen("xlr_hybrid=")) == 0){
+				/*Will parse this after loader arguments are parsed, as this
+				  has memory dependency on loader*/
+				tmp = argv[i]+strlen("xlr_hybrid=");
+			}else{
+				j=0;
+				while(phnx_name_value_args[j].name != NULL) {
+					ret = get_name_value(argv[i],
+							     phnx_name_value_args[j].name,
+							     16, phnx_name_value_args[j].val);
+					if(ret == 0)
+						break;
+					j++;
+				}
+			}
+		}
+	}
+
+#ifdef CONFIG_MAPPED_KERNEL
+	exclude_hybrid_mem_region();
+#else
+	if (tmp) {
+		xlr_early_hybrid_setup(tmp);
+	}
+#endif
+}
+
+void check_cpu_mask(void) 
+{
+	uint32_t tmask,i;
+
+	if(!xlr_linux_cpu_mask)
+		xlr_linux_cpu_mask = 0x1;
+	
+	/* trim to what is available */
+	xlr_linux_cpu_mask &= prom_info->rmi_cpu_online_map;
+	xlr_linux_cpu_mask |= (1U<<hard_smp_processor_id());
+
+	/* Exclude CPUs that boot linux from the loader CPU mask */
+	phnx_loader_mask = ~xlr_linux_cpu_mask;
+	phnx_loader_mask &= prom_info->rmi_cpu_online_map;
+	/* Loader should not run on the same core, unless "sharedcore" option
+	   is enabled */
+	if(xlr_loader_sharedcore == 0) {
+		tmask = 0xf;
+		for(i=0; i < 8; i++) {
+			if(tmask & xlr_linux_cpu_mask)
+				phnx_loader_mask &= ~tmask;
+			tmask = tmask << 4;
+		}
+	}
+	if(phnx_loader_mask == 0){
+		xlr_loader_support = 0;
+		printk("Disabling loader support as loader mask is 0\n");
+		return;
+	}
+	printk("Using 0x%08x as linux cpu mask\n", xlr_linux_cpu_mask);
+	printk("Using 0x%08x as loader cpu mask\n", phnx_loader_mask);
+}
+#define LOADER_KSEG_DEFAULTS phnx_loader_kseg_start = PHNX_LOADER_KSEG0_START;\
+				phnx_loader_kseg_size = PHNX_LOADER_KSEG0_SIZE;
+extern char _end;
+void check_kseg_args(void)
+{
+	if((phnx_loader_kseg_start == 0) ||(phnx_loader_kseg_size == 0)) {
+	       	/* no args passed */
+		LOADER_KSEG_DEFAULTS;
+		printk("No KSEG args passed. Using defaults\n");
+		return;
+	}
+	dprintk("Checking kseg start %x with _end %p\n", phnx_loader_kseg_start,
+		&_end);
+	if(((phnx_loader_kseg_start | CKSEG0) < (unsigned long)&_end) || 
+	   (phnx_loader_kseg_start >= LOADER_KSEG_END)) {
+		printk("Invalid KSEG args passed. Using defaults\n");
+		printk("Start cannot overlap with image or bootloader region\n");
+		LOADER_KSEG_DEFAULTS;
+		return;
+	}
+	if(phnx_loader_kseg_start & ((2 << 20) - 1)) {
+		/* Start not aligned at 2MB boundry */
+		printk("Invalid KSEG args passed. Using defaults\n");
+		printk("Start address not aligned at 2MB boundry\n");
+		LOADER_KSEG_DEFAULTS;
+		return;
+	}
+	if((phnx_loader_kseg_start + phnx_loader_kseg_size) > 
+	   LOADER_KSEG_END) {
+		printk("Invalid KSEG args passed. Using defaults\n");
+		printk("Bootloader region cannot be used\n");
+		LOADER_KSEG_DEFAULTS;
+		return;
+	}
+	printk("Using 0x%08x as KSEG0 load start and 0x%08x as size\n",
+	       phnx_loader_kseg_start, phnx_loader_kseg_size);
+
+}
+
+static void use_kuseg_defaults(struct boot_mem_map *map)
+{
+	int i=0;
+	uint64_t start = PHNX_LOADER_KUSEG_PHYS_START;
+	uint64_t size = PHNX_LOADER_KUSEG_PHYS_SIZE;
+	
+	for(i=0; i<map->nr_map; i++){
+		if(map->map[i].type != BOOT_MEM_RAM) continue;
+		if(map->map[i].addr >= start)
+			break;
+	}
+	if(i == map->nr_map){
+		/*found no memory!!!*/
+		printk("\n***********WARNING**************");
+		printk("\nNO LOADER KUSEG REGION FOUND\n");
+		return;
+	}
+	start = map->map[i].addr;
+	size = map->map[i].size > size ? size : map->map[i].size;
+	kuseg_mem_map[0].start_addr = start;
+	kuseg_mem_map[0].size = size;
+	printk("\nUsing Kuseg Region %#llx@%#llx\n",
+			(unsigned long long)kuseg_mem_map[0].size,
+			(unsigned long long)kuseg_mem_map[0].start_addr);
+}
+
+#define LOADER_KUSEG_DEFAULTS   memset (kuseg_mem_map, 0, (sizeof(struct kuseg_mem_info) * 4));\
+				use_kuseg_defaults(map);
+
+void check_kuseg_args(struct boot_mem_map *map)
+{
+	int i,j;
+	uint64_t end1, end2;
+
+	for (j = 0; j < MAX_NUM_KUSEG_BLOCKS; j++) {
+		/* if size is 0 ignore the entry */
+		if ( kuseg_mem_map[j].size == 0)
+			continue;
+
+		if ( kuseg_mem_map[j].start_addr < (512 << 20))  { /* cannot be < 512MB */
+			printk("Kuseg start should be > 512MB. Using defaults for start addr %llx\n", (unsigned long long)kuseg_mem_map[j].start_addr);
+			LOADER_KUSEG_DEFAULTS;
+			return;
+		}
+
+		end1 = kuseg_mem_map[j].start_addr + kuseg_mem_map[j].size;
+
+		for(i=0; i < map->nr_map; i++) {
+			if(map->map[i].type != BOOT_MEM_RAM) continue;
+			end2 = map->map[i].addr +  map->map[i].size;
+			if(( kuseg_mem_map[j].start_addr >= map->map[i].addr) &&
+			   (end1 <= end2)) break;
+		}
+		if(i == map->nr_map) {
+			printk("Invalid KUSEG range passed. Using defaults\n");
+			LOADER_KUSEG_DEFAULTS;
+			return;
+		}
+		printk("Using 0x%llx as KUSEG start and 0x%llx as KUSEG size\n",
+		       (unsigned long long)kuseg_mem_map[j].start_addr,
+		       (unsigned long long)kuseg_mem_map[j].size);
+	}
+	/* if no input is given , then use the default */
+	if ( kuseg_mem_map[0].start_addr == 0 )	{
+		LOADER_KUSEG_DEFAULTS;
+	}
+}
+
+uint32_t align_shared_mem(uint32_t shared_mem)
+{
+	if(shared_mem <= (2<<20))
+		return (2<<20);
+	if(shared_mem <= (8 << 20))
+		return (8<<20);
+	if(shared_mem <= (32 << 20))
+		return (32<<20);
+	if(shared_mem <= (128 << 20))
+		return (128<<20);
+	if(shared_mem <= (512 << 20))
+		return (512<<20);
+	return (2<<20);
+}
+
+void prom_validate_loader_args(struct boot_mem_map *map)
+{
+	if(!xlr_loader_support) 
+		return;
+#if 0
+	/*Currently loader is supported on all boards.*/
+	if(!(xlr_board_atx_i() || xlr_board_atx_ii() || 
+	     xlr_board_atx_iii() || xlr_board_atx_vi() ||
+             xlr_board_atx_v() || xlr_board_atx_vii())) {
+		printk("Loader support available only on AZI, AZII, "
+                       "AZIII, AZV, AZVI and AZVII boards\n");
+		xlr_loader_support = 0;
+		return;
+	}
+
+	if (xlr_loader_own_gmac && (!xlr_board_atx_ii()|| is_xls())) {
+		printk("own_gmac option is valid only on ATX II XLR boards."
+                       " Ignoring option.\n");
+		xlr_loader_own_gmac = 0;
+	}
+#endif
+	check_cpu_mask();
+	check_kseg_args();
+	check_kuseg_args(map);
+	
+}
+
+/* The below regions should be in ascending order of the starting physical addresses */
+
+static struct boot_mem_map_exclude_region _exclude_regions[2][MAX_EXCLUDE + 2];
+
+static struct boot_mem_map_exclude_region *exclude_regions = _exclude_regions[1];
+
+static struct boot_mem_map_exclude_region static_exclude_regions[] = {
+	[0] = { 0,0},
+};
+
+void prom_exclude_kseg(void)
+{
+   	dynamic_exclude_regions[dyna_exc_index].start = (unsigned long long)
+		1<<20;
+   	dynamic_exclude_regions[dyna_exc_index].end = (unsigned long long)
+                (((unsigned long)&_text) & 0x1fffffffUL);
+   	dyna_exc_index++;
+
+	dynamic_exclude_regions[dyna_exc_index].start = (unsigned long long)
+		phnx_loader_kseg_start;
+	dynamic_exclude_regions[dyna_exc_index].end = (unsigned long long)
+		(phnx_loader_kseg_start + phnx_loader_kseg_size);
+	dyna_exc_index++;
+}
+#if 0
+void prom_exclude_bootloader(void)
+{
+	dynamic_exclude_regions[1].start = (unsigned long long)
+		BOOT_LOADER_REGION_START;
+	dynamic_exclude_regions[1].end = (unsigned long long)
+		(BOOT_LOADER_REGION_START + BOOT_LOADER_REGION_SZ);
+}
+#endif
+
+void sort_kuseg_region(void)
+{
+	int i,j;
+	uint64_t temp_addr;
+	uint64_t temp_size;
+
+	for (i = 1; i < 4; i++) {
+		for ( j = 0; j < i; j++){
+			if ( kuseg_mem_map[i].start_addr <  kuseg_mem_map[j].start_addr ){
+				temp_addr = kuseg_mem_map[j].start_addr;
+				temp_size = kuseg_mem_map[j].size;
+				kuseg_mem_map[j].start_addr = kuseg_mem_map[i].start_addr;
+				kuseg_mem_map[j].size = kuseg_mem_map[i].size;
+				kuseg_mem_map[i].start_addr = temp_addr;
+				kuseg_mem_map[i].size = temp_size;
+			}
+		}
+	}
+}
+
+void check_kuseg_region_overlap(void)
+{
+	int i,max;
+	uint64_t end1, end2;
+
+	max = MAX_NUM_KUSEG_BLOCKS - 1;
+
+	sort_kuseg_region();
+	for ( i = 0 ;i < max; i++) {
+		end1 = kuseg_mem_map[i].start_addr + kuseg_mem_map[i].size ;
+		if ( ( kuseg_mem_map[i+1].start_addr <= end1 )&& ( kuseg_mem_map[i].start_addr != 0 ) ){
+			end2 = kuseg_mem_map[i+1].start_addr + kuseg_mem_map[i+1].size;
+			if ( end2 >  end1 )
+				kuseg_mem_map[i].size = end2 - kuseg_mem_map[i].start_addr;
+			kuseg_mem_map[i+1].start_addr = 0;
+			kuseg_mem_map[i+1].size = 0;
+			sort_kuseg_region();
+		}
+	}
+}
+void prom_exclude_kuseg(void)
+{
+	int i = 0;
+	check_kuseg_region_overlap();
+
+	for (i = 0 ; i < MAX_NUM_KUSEG_BLOCKS ; i++) {
+		if ( (kuseg_mem_map[i].start_addr != 0 ) && (kuseg_mem_map[i].size != 0) ){
+			dynamic_exclude_regions[dyna_exc_index].start = kuseg_mem_map[i].start_addr;
+			dynamic_exclude_regions[dyna_exc_index].end = kuseg_mem_map[i].start_addr + kuseg_mem_map[i].size;
+			dyna_exc_index++;
+		}
+	}
+}
+
+void prom_exclude_pci_shmem(void)
+{
+	dynamic_exclude_regions[dyna_exc_index].start =
+		PHNX_PCIX_SHARED_MEM_START;
+	dynamic_exclude_regions[dyna_exc_index].end = PHNX_PCIX_SHARED_MEM_END; 
+	dyna_exc_index++;
+	printk("Excluding PCI Shared Memory\n");
+}
+
+void sort_dynamic_exclude_region(void)
+{
+	int i=0;
+	int j=0;
+	int max=0;
+	struct boot_mem_map_exclude_region *list = dynamic_exclude_regions;
+
+	uint64_t start = 0;
+	uint64_t end = 0;
+
+	while (list[max].start != 0)
+		max++;
+
+	for(i = 0; i < max; i++){
+		for(j = i; j < max; j++){
+			if (list[i].start > list[j].start){
+				start = list[i].start;
+				end = list[i].end;
+				list[i].start = list[j].start;
+				list[i].end = list[j].end;
+				list[j].start = start;
+				list[j].end = end;
+			}
+		}
+	}
+}
+
+static int merge_exclude_regions(struct boot_mem_map_exclude_region *,
+                                 struct boot_mem_map_exclude_region *);
+
+void prom_update_exclude_region(void)
+{
+	int i;
+
+#ifdef CONFIG_PHOENIX_PCIX_GEN_DRIVER
+	if(xlr_get_pci_mode() == XLR_PCI_DEV_MODE){
+		prom_exclude_pci_shmem();
+	}
+#endif
+
+	if (xlr_loader_support) {
+		prom_exclude_kseg();
+		prom_exclude_kuseg();
+	}
+    
+	sort_dynamic_exclude_region();
+	
+	exclude_regions = _exclude_regions[0];
+	
+	/*
+	 * we assume that all exclude regions are sorted
+	 * to start with.
+	 */
+	
+	merge_exclude_regions(exclude_regions, static_exclude_regions);
+	merge_exclude_regions(exclude_regions, dynamic_exclude_regions);
+	
+	dprintk("Final exclude regions ----->\n");
+	for (i = 0; exclude_regions[i].start; i++) {
+		dprintk("%d: Start 0x%llx End 0x%llx\n", i, 
+			exclude_regions[i].start,
+			exclude_regions[i].end);
+	}
+}
+
+#define TRUE 1
+#define FALSE 0
+
+struct boot_mem_map prom_map;
+int use_default_phymem = FALSE;
+
+void read_prom_memory(void)
+{
+	struct boot_mem_map *map;
+
+	/* sanity check prom_info and it's mem_map fields */
+	if (!prom_info || (!prom_info->psb_mem_map && !prom_info->avail_mem_map)) 
+		goto use_default;
+
+	/* copy the mem_map from bootloader */
+	if (sizeof(*prom_info) <= prom_info->size && prom_info->avail_mem_map)
+		map = (struct boot_mem_map *) ((unsigned long)prom_info->avail_mem_map);	
+	else
+		map = (struct boot_mem_map *)((unsigned long)prom_info->psb_mem_map);
+	
+	if (!(map->nr_map > 0 && map->nr_map <= 32))
+		goto use_default;
+	memcpy (&prom_map, map,	sizeof(struct boot_mem_map));
+	
+	return;
+
+ use_default:
+	use_default_phymem = TRUE;
+	return;
+}
+
+#define DEF_PHYMEM_START_ADDR 0x100000
+#define DEF_PHYMEM_SIZE 0x0ff00000
+
+static void prom_add_memory(void)
+{
+	int i = 0, j = 0;
+	__u64 start = 0, end = 0, exc_start = 0, exc_end = 0;
+	__u64 pref_backup = 512;
+
+	if (use_default_phymem)
+		goto use_default;
+
+	prom_validate_loader_args(&prom_map);
+	
+	prom_update_exclude_region();
+	
+	/* 
+	 * TODO: Need to remove this brain damaged hack. The bootloader passed 
+	 * memory map should indicate the bootloader memory as available.
+	 */
+	if (prom_map.map[0].size == 0x0c000000)
+		prom_map.map[0].size = 0x0ff00000;
+	
+	for (i = 0; i < prom_map.nr_map; i++) {
+		start = prom_map.map[i].addr;
+		end = prom_map.map[i].addr + prom_map.map[i].size;
+
+		for (j = 0; j < MAX_EXCLUDE; j++) {
+			exc_start = exclude_regions[j].start;
+			exc_end = exclude_regions[j].end;
+			
+			if ((exc_start == 0) && (exc_end == 0)) /* Empty slot */
+				continue;
+
+			if (exc_start >= start && exc_start < end) {
+				if(exc_start == start) { /* Continuous exclude */
+					start = exc_end;
+					continue;
+				}
+				if (prom_map.map[i].type == BOOT_MEM_RAM){
+
+					/*
+					 * memcpy/__copy_user prefetch, which
+					 * will cause a bus error for
+					 * KSEG/KUSEG addrs not backed by RAM.
+					 * Hence, reserve some padding for the
+					 * prefetch distance.
+				 	*/
+					if(exc_start-start > pref_backup){
+						add_memory_region(start,
+									  exc_start-start-pref_backup, 
+									  (long)prom_map.map[i].type);
+					}
+					start = exc_end;
+				}
+			} 
+			else if ((exc_start < start) && (exc_end > start)) {
+				/* Overlapping excludes */
+				start = exc_end;
+			}
+		}
+		if (start != end)
+			if (prom_map.map[i].type == BOOT_MEM_RAM){
+				if(end-start > pref_backup)
+					add_memory_region(start, end-start-pref_backup, (long)prom_map.map[i].type);
+			}
+	}
+	
+	return;
+	
+ use_default:
+	printk("Using default physical memory map\n");
+	add_memory_region (DEF_PHYMEM_START_ADDR, DEF_PHYMEM_SIZE-pref_backup, (long)BOOT_MEM_RAM); // 255m@1m
+	xlr_loader_support = 0;
+}
+
+static void psb_print_physmap(void)
+{
+	struct boot_mem_map *physaddr_map = 
+		(struct boot_mem_map *)((unsigned long)prom_info->psb_physaddr_map);
+	char *name;
+	int i = 0;
+	int max;
+
+	if(physaddr_map == NULL)
+		return;
+
+	max = physaddr_map->nr_map;
+
+	prom_dbg_msg("Physical Address Map\n");
+	for(i=0 ; i <max ; i++)
+	{
+		name = get_psb_physmap_name(physaddr_map->map[i].type);
+
+		prom_dbg_msg("\t%010llx --> %010llx ( %s )\n",
+			     (unsigned long long)physaddr_map->map[i].addr,
+			     (unsigned long long)(physaddr_map->map[i].addr +
+						  physaddr_map->map[i].size -1),
+			     name);
+	}
+
+}
+
+static void save_physaddr_info(void)
+{
+	struct boot_mem_map *physaddr_map = 
+		(struct boot_mem_map *)((unsigned long)prom_info->psb_physaddr_map);
+
+	if(physaddr_map == NULL)
+		return;
+
+	memcpy(&boot_physaddr_info,  physaddr_map, sizeof(struct boot_mem_map));
+	return;
+}
+
+/* disable dedicated interrupt vector for virtual mips mode */
+void disable_divec(void)
+{
+    int i;
+    for (i = 0; i < NR_CPUS; i++)
+        cpu_data[i].options &= ~MIPS_CPU_DIVEC;
+
+    return;
+}
+
+extern void (*board_nmi_handler_setup)(void );
+
+void __init rmi_nmi_setup (void)
+{
+	/* setup nmi handler only if KGDB is enabled */
+#ifdef CONFIG_KGDB
+	void *base;
+	extern char rmi_except_vec_nmi;
+
+	printk("Setting up NMI Handler \n");
+	base = (void *)(unsigned long)0xffffffffbfc00000ULL;
+	memcpy(base, &rmi_except_vec_nmi, 0x80);
+#endif
+}
+
+/* setup early serial port driver */
+#ifdef CONFIG_SERIAL_8250
+
+#ifdef CONFIG_RMI_XLR
+#define UART_CLK 66666666
+#else
+#define UART_CLK 133333333
+#endif
+
+static void rmi_early_serial_setup(void)
+{
+	struct uart_port s;
+	extern int __init early_serial_setup(struct uart_port *port);
+
+	memset(&s, 0, sizeof(s));
+
+	s.flags = ASYNC_BOOT_AUTOCONF | ASYNC_SKIP_TEST;
+	/* XLP_MERGE_TODO */
+	s.iotype = UPIO_MEM;
+	/* registers are 4 bytes wide */
+	s.regshift = 2;
+	/* hardware int 4 - the serial int, is CPU int 6
+	 but poll for now */
+	s.irq =  PIC_UART_0_IRQ;
+	s.uartclk = UART_CLK;
+	s.membase = (unsigned char __iomem *)(DEFAULT_PHOENIX_IO_BASE+PHOENIX_IO_UART_0_OFFSET);
+	s.mapbase = (DEFAULT_PHOENIX_IO_BASE+PHOENIX_IO_UART_0_OFFSET);
+
+	if (early_serial_setup(&s) != 0) {
+		printk(KERN_ERR "Serial setup failed!\n");
+	}
+
+
+}
+#else
+static void rmi_early_serial_setup(void) {}
+#endif
+
+extern struct plat_smp_ops rmi_smp_ops;
+/*
+ * prom_init is called just after the cpu type is determined, from setup_arch()
+ */
+void __init prom_init(void)
+{
+	int i=0;
+	int argc = (int)fw_arg0;
+	long temp ;
+	char **argv;
+	char **envp;
+	int t_argc = argc;
+	char *n_argv[RMI_MAX_ARGS] = {NULL};
+	char *n_envp[RMI_MAX_ENVS] = {NULL};
+	struct psb_info *t_prom_info;
+
+	void (*wakeup)(void *, void *, __u32);
+	__u32 wakeup_mask;
+
+	temp = (int)fw_arg1;
+	argv = (char **)temp;
+
+	temp = (int)fw_arg2;
+	envp = (char **)temp;
+
+#if 0
+	mips_machgroup = MACH_GROUP_RMI;
+#endif
+	
+	xlr_initialize_setups();
+
+	/* initialise from rmi-kernel if booted with */
+	rmik_init(n_argv, &argc, n_envp);
+
+	/* default mac addr */
+	phoenix_base_mac_addr[0] = 0x00;
+	phoenix_base_mac_addr[1] = 0x01;
+	phoenix_base_mac_addr[2] = 0x02;
+	phoenix_base_mac_addr[3] = 0x03;
+	phoenix_base_mac_addr[4] = 0x04;
+	phoenix_base_mac_addr[5] = 0x05;
+
+	phoenix_psb_shm = 0;
+  
+	prom_info = &prom_info_copy;
+	if(rmik_en) {
+		t_prom_info = (struct psb_info *)rmi_boot_info;
+		t_prom_info->wakeup = PTR2U64(&rmik_wakeup_cpus);
+	} else {
+		temp = (int)fw_arg3;
+		prom_info = &prom_info_copy;
+		t_prom_info = (struct psb_info *)temp;
+	}
+	memcpy((void *)prom_info, (void *)t_prom_info, sizeof(struct psb_info));
+
+#ifdef RMI_BRIDGE_WKAROUND
+	if(prom_info->global_shmem_size == GLOBAL_SHMEM_SIZE) {
+		rmi_bridge_lock = 
+			(rmi_rwlock_t *)(unsigned long)
+			(prom_info->global_shmem_addr + BRIDGE_WKAROUND_AREA_OFFSET);
+		rmi_enable_br_wrkaround = 1;
+		printk("Enabling Bridge Workaround \n");
+	}
+#endif
+
+	if(!dev_tree_en)
+	{
+		/* Get the right 64bit pointers from bootloader args */
+		{
+			int32_t *t_argv;
+
+			t_argv = (int32_t *)argv;
+			for(i=0; i < t_argc; i++, t_argv++) {
+				n_argv[i] = (char *)(unsigned long)(*t_argv);
+			}
+		}
+		argc = t_argc;
+
+		/* Get the right env pointers */
+		if(envp != NULL)
+		{
+			int32_t *t_envp;
+			t_envp = (int32_t *)envp;
+			for(i=0; *t_envp; i++) {
+				n_envp[i] = (char *)(unsigned long)(*t_envp);
+				t_envp++;
+			}
+		}
+	} /* devtree en */
+
+	if (!sanity_check_prom_info(prom_info)) {
+		printk("Sanity Check failed on prom_info @ %p\n", prom_info);
+		if (prom_info) {
+			printk("sizeof(psb_info) = %d, psb_info_version = %x, "
+			       "prom_info->magic_dword = %llx, prom_info->size = %llx\n", 
+			       (unsigned int)sizeof(struct psb_info), PSB_INFO_VERSION, 
+			       (unsigned long long)prom_info->magic_dword, 
+			       (unsigned long long)prom_info->size);
+		}
+		prom_info = &default_prom_info;
+		goto parse_args;
+	}
+
+	/*Copy Environment variable*/
+	if(prom_info->bldr_envp)
+		memcpy(&xlr_bldr_env,
+		       (void *)(unsigned long)prom_info->bldr_envp,
+		       sizeof(xlr_bldr_env));
+
+
+	xlr_board_major_version = prom_info->board_major_version;
+	xlr_board_minor_version = prom_info->board_minor_version;
+	prom_parse_args(argc, n_argv);
+
+	read_prom_memory(); 
+
+	phnx_ebase = read_c0_ebase() & (~((1 << 12) - 1));	
+
+	psb_print_physmap();
+
+	save_physaddr_info();
+
+	prom_add_memory();
+
+	if(xlr_loader_support){
+		if (xlr_loader_sharedcore && 
+		    (xlr_board_atx_iii() || xlr_board_atx_v())) {
+			xlr_loader_own_dma = 1;
+		}
+		prom_init_xlr_loader_setup(prom_info);
+	}
+	/* update the phoenix mac addr */
+	phoenix_base_mac_addr[0] = (prom_info->mac_addr >> 40) & 0xff;
+	phoenix_base_mac_addr[1] = (prom_info->mac_addr >> 32) & 0xff;
+	phoenix_base_mac_addr[2] = (prom_info->mac_addr >> 24) & 0xff;
+	phoenix_base_mac_addr[3] = (prom_info->mac_addr >> 16) & 0xff;
+	phoenix_base_mac_addr[4] = (prom_info->mac_addr >> 8) & 0xff;
+	phoenix_base_mac_addr[5] = (prom_info->mac_addr >> 0) & 0xff;
+
+	/* pull all the cpus out of the bootloader and force them to spin in 
+	 * prom_pre_boot_secondary_cpus
+	 */
+	wakeup = ((void (*)(void *, void *, __u32))(unsigned long)(prom_info->wakeup));
+
+	smp_boot.online_map = (1 << hard_smp_processor_id());
+
+	if(xlr_loader_support) {
+		wakeup_mask = xlr_linux_cpu_mask | phnx_loader_mask;
+		if(wakeup != 0x0)
+			wakeup((void *)secondary_cpus_bootup_func, 0, wakeup_mask);
+	} else {
+		if(wakeup != 0x0) {
+			wakeup((void *)secondary_cpus_bootup_func, 0, (__u32)prom_info->rmi_cpu_online_map & (~smp_boot.online_map));
+#if defined(CONFIG_RMI_XLP_SIM)
+			unsigned int wait_count = 0;
+
+			while (smp_boot.online_map != prom_info->rmi_cpu_online_map) {
+				if ((wait_count++ % 1000000) == 0) {
+					printk("[%s%d]: Master cpu waiting for slave cpus to wakeup from bootloader (%x != %llx)\n",
+					       __FUNCTION__, __LINE__, smp_boot.online_map, 
+						   (unsigned long long) prom_info->rmi_cpu_online_map);
+				}
+			}
+			printk("[%s@%d]: woke up prom_info->rmi_cpu_online_map=%016llx\n", __FILE__, __LINE__, 
+				   (unsigned long long) prom_info->rmi_cpu_online_map);
+#endif
+		}
+	}
+
+ parse_args:
+
+	for(i=1;i<argc;i++) {
+		if (n_argv[i]) {
+			strcat(arcs_cmdline, n_argv[i]);
+			strcat(arcs_cmdline, " ");
+		}
+		else {
+			prom_dbg_msg("bad args, i=%d\n", i);
+		}
+	}
+	strcat(arcs_cmdline, " ");
+
+	if(rmik_en) {
+		fdt_add_console_string(arcs_cmdline);
+		disable_divec();
+	}
+#ifdef CONFIG_PHOENIX_CONSOLE_OVER_PCI
+	if(!(xlr_board_atx_iii() || xlr_board_atx_v()) || 
+           !(xlr_console_pci_con_baud && 
+	     xlr_console_pci_con_dev))
+		strcat(arcs_cmdline, DEFAULT_CONSOLE_BOOT_PARAMS);
+#else
+	if((strstr(arcs_cmdline, "console=")) == NULL)
+		strcat(arcs_cmdline, DEFAULT_CONSOLE_BOOT_PARAMS);
+#endif
+	strcat(arcs_cmdline, " ");
+
+#ifdef CONFIG_ROOT_NFS
+	if(!xlr_boot_over_nfs)
+		strcat(arcs_cmdline, DEFAULT_INITRD_BOOT_PARAMS);
+#else
+	strcat(arcs_cmdline, DEFAULT_INITRD_BOOT_PARAMS);
+#endif
+	strcat(arcs_cmdline, " ");
+
+	for(i=0; n_envp[i];i++) {
+		if (strcmp(n_envp[i], "") == 0) break;
+	}
+
+#ifdef DEBUG
+	printk("MAC ADDR BASE: %02x:%02x:%02x:%02x:%02x:%02x\n",
+	       phoenix_base_mac_addr[0], phoenix_base_mac_addr[1], phoenix_base_mac_addr[2],
+	       phoenix_base_mac_addr[3], phoenix_base_mac_addr[4], phoenix_base_mac_addr[5]);
+#endif
+	if(hybrid_str != NULL)
+		xlr_hybrid_setup(hybrid_str);
+
+	config_net_init();
+	board_nmi_handler_setup = rmi_nmi_setup;
+
+	on_chip_init();
+	prom_reconfigure_thr_resources();
+
+	/* setup early serial port driver */
+	rmi_early_serial_setup();
+
+    	register_smp_ops(&rmi_smp_ops);
+}
+
+void prom_free_prom_memory(void)
+{
+	/* nothing to free */
+}
+
+void read_cp0_regs(void)
+{
+	printk("[%s]: count = 0x%x, compare = 0x%x\n"
+	       "status = 0x%x, cause = 0x%x\n"
+	       "eimr = 0x%llx, eirr = 0x%llx\n",
+	       __FUNCTION__, 
+	       read_c0_count(),
+	       read_c0_compare(),
+	       read_c0_status(),
+	       read_c0_cause(),
+	       (unsigned long long)read_64bit_cp0_eimr(),
+	       (unsigned long long)read_64bit_cp0_eirr()
+		);
+}
+
+struct boot_mem_map_entry *psb_get_physaddr_base_address(unsigned long type)
+{
+	struct boot_mem_map *physaddr_map = 
+		(struct boot_mem_map *)((unsigned long)prom_info->psb_physaddr_map);
+
+	int i = 0;
+	int max = physaddr_map->nr_map;
+
+	for(i=0 ; i <max ; i++)
+	{
+		if (physaddr_map->map[i].type == type)
+			return (physaddr_map->map);
+	}
+	return NULL;
+}
+
+void static add_region(struct boot_mem_map_exclude_region *x, int *k,
+		       uint64_t start, uint64_t end)
+{
+	if (*k > MAX_EXCLUDE) {
+		printk("No of exclude regions = %d; Cannot add more\n", MAX_EXCLUDE);
+		return;
+	}
+
+	if (start < x[*k-1].end) {
+		return;
+	}
+
+	x[*k].start = start;
+	x[*k].end = end;
+	++*k;
+}
+
+static int merge_exclude_regions(struct boot_mem_map_exclude_region *x,
+				 struct boot_mem_map_exclude_region *y)
+{
+	static int _index = 0;
+	int i, j, k;
+
+	i = j = 0;
+	k = 1;
+
+	while (x[i].start != 0 && y[j].start != 0) {
+		if (x[i].start < y[j].start) {
+			add_region(_exclude_regions[_index], &k, x[i].start, x[i].end);
+			++i;
+		}
+		else {
+			add_region(_exclude_regions[_index], &k, y[j].start, y[j].end);
+			++j;
+		}
+	}
+
+	if (x[i].start == 0) {
+		while (y[j].start) {
+			add_region(_exclude_regions[_index], &k, y[j].start, y[j].end);
+			++j;
+		}
+	}
+	else if (y[j].start == 0) {
+		while (x[i].start) {
+			add_region(_exclude_regions[_index], &k, x[i].start, x[i].end);
+			++i;
+		}
+	}
+
+	exclude_regions = &_exclude_regions[_index][1];
+	_index = _index ? 0 : 1;
+
+	return 0;
+}
+
+
+#ifdef CONFIG_EARLY_PRINTK
+void prom_putchar(char c)
+{
+    void (*putchar)(char);
+    putchar = ((void (*)(char c))(unsigned long)(prom_info->uart_putchar));
+    putchar(c);
+}
+
+#endif
+
+static int __init rmi_proc_setup(void)
+{
+	rmi_root_proc = proc_mkdir("rmi", 0);	
+	if (!rmi_root_proc)
+		return -ENOMEM;
+	
+	return 0;
+}
+rootfs_initcall(rmi_proc_setup);
diff --git a/arch/mips/rmi/ptr/smp.c b/arch/mips/rmi/ptr/smp.c
new file mode 100644
index 0000000..4429f52
--- /dev/null
+++ b/arch/mips/rmi/ptr/smp.c
@@ -0,0 +1,241 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+
+#include <asm/mipsregs.h>
+#include <asm/mmu_context.h>
+#include <asm/atomic.h>
+//#include <asm/cpumask.h>
+
+#include <asm/rmi/sim.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/phnx_user_mac.h>
+
+#include <asm/asm.h>
+#include <asm/mipsregs.h>
+#include <asm/processor.h>
+#include <asm/rmi/phnx_loader.h>
+#include <user/rmi/phnx_loader.h>
+
+#include <asm/mach-rmi/mmu.h>
+
+extern int xlr_loader_support;
+extern volatile cpumask_t cpu_callin_map;
+extern void __init phoenix_smp_init(void); 
+extern void phoenix_smp_finish(void);
+
+extern void smp_tune_scheduling (void);
+extern void ptr_smp_boot(unsigned long, unsigned long, unsigned long);
+struct smp_boot_info smp_boot;
+extern void prom_reconfigure_thr_resources(void);
+extern uint32_t phnx_loader_mask;
+extern unsigned long phnx_ebase;
+
+
+int phys_proc_id[NR_CPUS]; /* cpuid+thrid of each logical CPU */
+cpumask_t phys_cpu_present_map;
+extern void asmlinkage smp_bootstrap(void);
+extern void core_send_ipi(int cpu, unsigned int action);
+
+void rmi_send_ipi_single(int cpu, unsigned int action)
+{
+    core_send_ipi(cpu, action);
+}
+
+void rmi_send_ipi_mask(const struct cpumask * mask, unsigned int action)
+{
+    int cpu;
+    for_each_cpu(cpu, mask){
+        core_send_ipi(cpu, action);
+    }
+}
+
+/*
+ * Code to run on secondary just after probing the CPU
+ */
+static void __cpuinit rmi_init_secondary(void)
+{
+    extern void rmi_smp_irq_init(void);
+
+    rmi_smp_irq_init();
+    /* Time init for this cpu is done in mips_clockevent_init() */
+}
+
+void rmi_smp_finish(void)
+{
+#if !defined(CONFIG_RMI_XLP)
+    phoenix_msgring_cpu_init();
+#endif
+}
+
+void rmi_cpus_done(void)
+{
+}
+
+/* Boot all other cpus in the system, initialize them, and
+   bring them into the boot fn */
+void rmi_boot_secondary(int logical_cpu, struct task_struct *idle)
+{
+	unsigned long gp = (unsigned long)task_thread_info(idle);
+	unsigned long sp = (unsigned long)__KSTK_TOS(idle);
+	int cpu = cpu_logical_map(logical_cpu);
+
+/* 	printk("[%s]: (PROM): waking up phys cpu# %d: address of boot_info=%p (addressof(ready)=%p)\n", */
+/* 	       __FUNCTION__, cpu, &(smp_boot.boot_info[cpu]), &((smp_boot.boot_info[cpu]).ready)); */
+  
+	smp_boot.boot_info[cpu].sp = sp;
+	smp_boot.boot_info[cpu].gp = gp;
+	smp_boot.boot_info[cpu].fn = (unsigned long)&smp_bootstrap;  
+	/* barrier */
+	__sync();
+	smp_boot.boot_info[cpu].ready = 1;
+  
+/* 	printk("[%s]: (PROM): sent a wakeup message to cpu %d\n", __FUNCTION__, cpu); */
+}
+
+extern void ptr_smp_boot(unsigned long, unsigned long, unsigned long);
+struct smp_boot_info smp_boot;
+extern void prom_reconfigure_thr_resources(void);
+extern uint32_t phnx_loader_mask;
+extern unsigned long phnx_ebase;
+
+unsigned int fast_syscall_cpumask_phy = 0x1;
+
+void __init rmi_smp_setup(void)
+{
+	int num_cpus = 1;
+	__u32 boot_cpu_online_map = 0, boot_cpu = 0x0;
+
+
+	extern __u32 ipi_3_counter_tx[NR_CPUS][NR_CPUS];
+	extern __u32 ipi_3_counter_rx[NR_CPUS];
+	int i=0, j=0;
+
+	boot_cpu = hard_smp_processor_id();
+
+	cpus_clear(phys_cpu_present_map);
+	/*	cpu_set(0, phys_cpu_present_map);
+	__cpu_number_map[0] = 0;
+	__cpu_logical_map[0] = 0;  
+	dev_tree_en fix , and also not required for the existing case also */
+
+	cpus_clear(cpu_possible_map);
+	/* cpu_set(0, cpu_possible_map); */
+
+	/* Initialize the ipi debug stat variables */
+	for(i=0;i<NR_CPUS;i++) {
+		for(j=0;j<NR_CPUS;j++)
+			ipi_3_counter_tx[i][j] = 0;
+  
+		ipi_3_counter_rx[i] = 0;
+	}
+
+	if(xlr_loader_support) {
+		smp_boot.online_map &= ~phnx_loader_mask;
+	}
+
+	boot_cpu_online_map = smp_boot.online_map;
+	printk("(PROM) CPU present map: %x\n", boot_cpu_online_map);
+
+	/* 0th entry in the logical_map should be the bootcpu and all
+       others proceeds after that */
+	/* Fill the entries for boot cpu */
+	boot_cpu_online_map &= (~(1 << boot_cpu));
+	cpu_set(boot_cpu, phys_cpu_present_map);
+	__cpu_number_map[boot_cpu] = 0;
+	__cpu_logical_map[0] = boot_cpu;
+	cpu_set(0, cpu_possible_map);
+
+	for(i = 0;i<NR_CPUS;i++) {
+		if (boot_cpu_online_map & (1<<i)) {
+			cpu_set(i, phys_cpu_present_map);
+			__cpu_number_map[i] = num_cpus;
+			__cpu_logical_map[num_cpus] = i;
+			cpu_set(num_cpus, cpu_possible_map);
+			++num_cpus;
+		}
+	}
+
+
+	fast_syscall_cpumask_phy = (unsigned int)phys_cpu_present_map.bits[0];
+
+	printk("Phys CPU present map: %lx, possible map %lx\n", 
+	       (unsigned long)phys_cpu_present_map.bits[0], 
+	       (unsigned long)cpu_possible_map.bits[0]);
+
+	printk("Detected %i Slave CPU(s)\n", num_cpus);
+}
+
+void rmi_prepare_cpus(unsigned int max_cpus)
+{
+}
+
+
+struct plat_smp_ops rmi_smp_ops = {
+    .send_ipi_single    = rmi_send_ipi_single,
+    .send_ipi_mask      = rmi_send_ipi_mask,
+    .init_secondary     = rmi_init_secondary,
+    .smp_finish     = rmi_smp_finish,
+    .cpus_done      = rmi_cpus_done,
+    .boot_secondary     = rmi_boot_secondary,
+    .smp_setup      = rmi_smp_setup,
+    .prepare_cpus       = rmi_prepare_cpus,
+};
+
+
+
+void prom_boot_cpus_secondary(void *args)
+{
+	int cpu = hard_smp_processor_id();
+  
+	write_c0_ebase((uint32_t)phnx_ebase);
+	atomic_add((1<<cpu), (atomic_t *)&smp_boot.online_map);
+	for(;;) {
+		if (smp_boot.boot_info[cpu].ready) break;
+	}
+	__sync();
+
+	prom_reconfigure_thr_resources();
+
+        setup_mapped_kernel_tlbs(TRUE, FALSE);
+        setup_mapped_kernel_tlbs(FALSE, FALSE);
+
+	ptr_smp_boot(smp_boot.boot_info[cpu].fn, smp_boot.boot_info[cpu].sp, 
+		     smp_boot.boot_info[cpu].gp);
+}
+
+
+
+
diff --git a/arch/mips/rmi/ptr/smpboot.S b/arch/mips/rmi/ptr/smpboot.S
new file mode 100644
index 0000000..a94bacd
--- /dev/null
+++ b/arch/mips/rmi/ptr/smpboot.S
@@ -0,0 +1,73 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ ******************************#RMI_2#**********************************/
+
+#include <asm/asm.h>
+#include <asm/asm-offsets.h>
+#include <asm/regdef.h>
+#include <asm/mipsregs.h>
+
+#include <asm/mach-rmi/kernel-entry-init.h>
+
+NESTED(ptr_smp_boot, 16, sp)
+
+	move	sp, a1
+	move	gp, a2
+	jal	a0
+	nop
+	
+END(ptr_smp_boot)
+	
+/* Don't jump to linux function from Bootloader stack. Change it 
+ * here. Kernel might allocate bootloader memory before all the CPUs are 
+ * brought up (eg: Inode cache region) and we better don't overwrite this 
+ * memory
+ */
+NESTED(prom_pre_boot_secondary_cpus, 16, sp)
+	SET_MIPS64
+	MAPPED_KERNEL_SETUP_TLB
+	mfc0 t0, $15, 1 #read ebase
+	andi t0, 0x1f #t0 has the processor_id()
+	PTR_LA	t1, xlr_stack_pages_temp
+	li   t2, _THREAD_SIZE
+	srl  t2, 2
+	mul  t3, t2, t0
+	nop
+	nop
+	nop
+	nop
+	nop
+	nop
+	PTR_ADDU  gp, t1, t3
+	PTR_ADDU       sp, gp, t2
+	PTR_ADDI       sp, sp, -32
+	PTR_LA t0, prom_boot_cpus_secondary
+	jr t0
+	nop
+END(prom_pre_boot_secondary_cpus)
diff --git a/arch/mips/rmi/xlp/Makefile b/arch/mips/rmi/xlp/Makefile
new file mode 100644
index 0000000..294e6c5
--- /dev/null
+++ b/arch/mips/rmi/xlp/Makefile
@@ -0,0 +1 @@
+obj-y += mmu.o
diff --git a/arch/mips/rmi/xlp/mmu.c b/arch/mips/rmi/xlp/mmu.c
new file mode 100644
index 0000000..b685ec5
--- /dev/null
+++ b/arch/mips/rmi/xlp/mmu.c
@@ -0,0 +1,150 @@
+#include <asm/mipsregs.h>
+#include <asm/mach-rmi/mmu.h>
+#include <asm/mach-rmi/pgwalker.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/asm-offsets.h>
+#include <asm/page.h>
+#include <asm/pgtable.h>
+
+#define READ_INHIBIT (1 << 31)
+#define EXEC_INHIBIT (1 << 30)
+
+static int __initdata tlb_config = (ENABLE_ETLB | ENABLE_128_TLB | ENABLE_PGWALKER);
+
+int __init disable_etlb(char *str)
+{
+	tlb_config &= ~ENABLE_ETLB;
+	return 1;
+}
+__setup("disable_etlb", disable_etlb);
+
+int __init disable_128tlb(char *str)
+{
+	tlb_config &= ~ENABLE_128_TLB;
+
+	return 1;
+}
+__setup("disable_128tlb", disable_128tlb);
+
+int __init disable_pgwalker(char *str)
+{
+	tlb_config &= ~ENABLE_PGWALKER;
+
+	return 1;
+}
+__setup("disable_pgwalker", disable_pgwalker);
+
+void mmu_init(void)
+{
+	write_c0_config6(read_c0_config6() | tlb_config);
+
+	/* 
+	 * Read back TLB entries after configuration
+	 */
+	current_cpu_data.tlbsize = (read_c0_config6() >> 16 ) & 0xffff;
+
+	/* 
+	 * shift right half the number of 1s in 
+	 * the pagemask and populate that value
+	 */
+	write_c0_config7(PM_DEFAULT_MASK >> (13 + (ffz(PM_DEFAULT_MASK >> 13) / 2)));
+#ifdef DEBUG
+	printk(KERN_INFO "( %s ): write_c0_config7 = %d\n", __FUNCTION__,
+		   read_c0_config7());
+#endif
+
+#ifdef CONFIG_EXEC_INHIBIT
+	pagegrain_write(pagegrain_read() | EXEC_INHIBIT);
+#endif
+
+#ifdef CONFIG_READ_INHIBIT
+	pagegrain_write(pagegrain_read() | READ_INHIBIT);
+#endif
+
+	pgwalker_init();
+	tlbstats_init();
+	entrylo0_mask_init();
+}
+
+/*
+ * Page Walker
+ */
+
+DEFINE_PER_CPU(unsigned long [NR_ADDR_SEGMENTS], pgd_bases);
+
+#ifdef CONFIG_64BIT
+static int pgtable_levels = PGD | PMD | PTE;
+#else
+static int pgtable_levels = PGD | PTE;
+#endif
+
+void pgwalker_init(void)
+{
+	unsigned int value;
+
+	if (read_c0_config6() & ENABLE_PGWALKER) {
+		/* 
+		 * hardware page levels information:
+		 * 
+		 * [15:8] no of top-most bits of vaddr used to form
+		 *        an index into the pgdirs table
+		 * [ 7:4] shift amount by which pfn (page frame number)
+		 *        needs to be left shifted for populating the
+		 *        entrylo0 and entrylo1 registers
+		 * [ 3:0] page table levels used. 32-bit kernels use 
+		 *        pgd and pte levels, while 64-bits kernels
+		 *        use pgd, pmd, and pte
+		 */
+		value  = ((ffs(NR_ADDR_SEGMENTS) - 1) & 0xff) << 8;
+		value |= ENTRYLO_PFN_SHIFT << 4;
+		value |= pgtable_levels;
+		pgw_register_write_w(PGW_MMU_INFO, value);
+
+#ifdef CONFIG_64BIT
+		pgw_register_write_d(PGW_PGD_BASES, (unsigned long long)&(__get_cpu_var(pgd_bases)[0]));
+#else
+		pgw_register_write_w(PGW_PGD_BASES, (unsigned int)&(__get_cpu_var(pgd_bases)[0]));
+#endif
+
+		/* PGD shift and mask information */
+		pgw_register_write_w(PGW_PGD_SHIFT, _PGDIR_SHIFT - _PGD_T_LOG2);
+		pgw_register_write_w(PGW_PGD_MASK, (_PTRS_PER_PGD - 1) << _PGD_T_LOG2);
+#ifdef CONFIG_64BIT
+		/*
+		 * MIPS Linux currently does not use 4-level page tables
+		 * and hence it is not necessary to fill in pud information
+		 *
+		 * So, just fill in the PMD shift and mask information 
+		 */
+		pgw_register_write_w(PGW_PMD_SHIFT, _PMD_SHIFT - _PMD_T_LOG2);
+		pgw_register_write_w(PGW_PMD_MASK, (_PTRS_PER_PMD - 1) << _PMD_T_LOG2);
+#endif
+
+		/* PTE shift and mask */
+		pgw_register_write_w(PGW_PTE_SHIFT, PAGE_SHIFT - _PTE_T_LOG2);
+		pgw_register_write_w(PGW_PTE_MASK, (_PTRS_PER_PTE - 1) << _PTE_T_LOG2);
+
+		get_cpu_var(pgd_bases)[VMALLOC_SEG] = (unsigned long) swapper_pg_dir;
+
+#ifdef XLP_MERGE_TODO
+#ifdef MODULE_START
+		__get_cpu_var(pgd_bases)[MODULE_SEG] = (unsigned long) module_pg_dir;
+#endif
+#endif
+		put_cpu_var(pgd_bases);
+
+		dump_pgwalker_config();
+		printk("Initialized Page Walker\n");
+	}
+}
+
+void dump_pgwalker_config(void)
+{
+	pgw_print_w(PGW_MMU_INFO);
+	pgw_print_w(PGW_PGD_SHIFT);
+	pgw_print_w(PGW_PGD_MASK);
+	pgw_print_w(PGW_PMD_SHIFT);
+	pgw_print_w(PGW_PMD_MASK);
+	pgw_print_w(PGW_PTE_SHIFT);
+	pgw_print_w(PGW_PTE_MASK);
+}
diff --git a/arch/mips/rmi/xlr/Makefile b/arch/mips/rmi/xlr/Makefile
new file mode 100644
index 0000000..294e6c5
--- /dev/null
+++ b/arch/mips/rmi/xlr/Makefile
@@ -0,0 +1 @@
+obj-y += mmu.o
diff --git a/arch/mips/rmi/xlr/mmu.c b/arch/mips/rmi/xlr/mmu.c
new file mode 100644
index 0000000..3640b7e
--- /dev/null
+++ b/arch/mips/rmi/xlr/mmu.c
@@ -0,0 +1,7 @@
+#include <asm/mach-rmi/mmu.h>
+
+void mmu_init(void)
+{
+	tlbstats_init();
+	entrylo0_mask_init();
+}
diff --git a/crypto/Makefile b/crypto/Makefile
index 21ae324..da9ed90 100644
--- a/crypto/Makefile
+++ b/crypto/Makefile
@@ -86,6 +86,7 @@ obj-$(CONFIG_CRYPTO_RNG2) += rng.o
 obj-$(CONFIG_CRYPTO_RNG2) += krng.o
 obj-$(CONFIG_CRYPTO_ANSI_CPRNG) += ansi_cprng.o
 obj-$(CONFIG_CRYPTO_TEST) += tcrypt.o
+obj-$(CONFIG_PHOENIX_IPSEC_SEC_OFFLOAD) += phoenix_sec.o
 obj-$(CONFIG_CRYPTO_GHASH) += ghash-generic.o
 obj-$(CONFIG_CRYPTO_USER_API) += af_alg.o
 obj-$(CONFIG_CRYPTO_USER_API_HASH) += algif_hash.o
diff --git a/crypto/phoenix_sec.c b/crypto/phoenix_sec.c
new file mode 100644
index 0000000..2ae9a06
--- /dev/null
+++ b/crypto/phoenix_sec.c
@@ -0,0 +1,224 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <net/ip.h>
+#include <net/xfrm.h>
+#include <net/ah.h>
+#include <net/icmp.h>
+#include <linux/crypto.h>
+
+#include <asm/io.h>
+
+#include <asm/rmi/debug.h>
+#include <asm/rmi/phoenix_sec.h>
+
+#define NUM_CHUNKS(size, bits) ( ((size)>>(bits)) + (((size)&((1<<(bits))-1))?1:0) )
+//#define DEBUG
+
+static u8 tmp_auth_data[MAX_AH_AUTH_LEN] __cacheline_aligned;
+static PacketDescriptor_t pkt_descs[NR_CPUS] __cacheline_aligned;
+static ControlDescriptor_t ctrl_descs[NR_CPUS] __cacheline_aligned;
+
+static spinlock_t msgrng_lock;
+
+void phoenix_ah_hmac_digest(struct ah_data *ahp, struct sk_buff *skb, u8 *auth_data)
+{
+	struct crypto_tfm *tfm = ahp->tfm;
+	u8 *key = ahp->key;
+	unsigned int keylen = ahp->key_len;
+	
+	int len_dwords=0;
+	PacketDescriptor_t *pkt_desc = &pkt_descs[smp_processor_id()];
+	ControlDescriptor_t *ctrl_desc = &ctrl_descs[smp_processor_id()];
+	unsigned long addr = virt_to_phys(skb->data);
+	int offset = addr - (addr & ~(SMP_CACHE_BYTES - 1));
+	int len=0, len_lastdword_remainder=0;
+	int ctrl_desc_size=0, ctrl_len_cachelines=0;
+	int i=0;
+	struct msgrng_msg msg;
+	int size=0, code=0, stid=0;
+	unsigned long flags=0, msgrng_flags=0;
+
+#ifdef DEBUG
+        {
+	  dbg_msg("Expected auth result:\n");
+	  for(i=0;i<ahp->icv_trunc_len;i++) {
+	    printk("%02x ", auth_data[i]);
+	    if (i && (i % 16) == 0) printk("\n");
+	  }
+	  printk("\n");
+        }
+#endif	
+	/* zero out the destination auth field */
+	memset(auth_data, 0, ahp->icv_trunc_len);
+
+	/* zero out the tmp auth field */
+	//memset(tmp_auth_data, 0, ahp->icv_trunc_len);
+	
+	/* no big keys support */
+	if ( (keylen > crypto_tfm_alg_blocksize(tfm)) || (keylen & 0x07) ) {
+	  dbg_msg("keylen(=%d) > algo_blocksize(%d) or unaligned keylen\n", 
+		 keylen, crypto_tfm_alg_blocksize(tfm));
+	  return;
+	}
+#if 0
+	/* no packet fragments support */
+	if (skb_shinfo(skb)->nr_frags != 1) {
+	  dbg_msg("fragmented packets (#frags=%d) not supported\n", 
+		  skb_shinfo(skb)->nr_frags);
+	  return;
+	}
+#endif	
+	len = skb->len + offset;
+	len_dwords = NUM_CHUNKS(len, 3);
+	len_lastdword_remainder = len & 0x07;
+
+#ifdef DEBUG
+	dbg_msg("ctrl_desc=%p, pkt_desc=%p, addr=%lx, offset=%d, len=%d, len_dwords=%d\n", 
+		ctrl_desc, pkt_desc, addr, offset, skb->len, len_dwords);
+#endif
+
+	/* Construct the packet descriptor */
+	pkt_desc->srcLengthIVOffUseIVNext = ( ((uint64_t)1 << 63) | 
+					      ((uint64_t)1 << 62) |
+					      ((uint64_t)len_lastdword_remainder << 59) |
+					      (((uint64_t)len_dwords & 0xeff)<<43) |  
+					      ((uint64_t)addr & ~(SMP_CACHE_BYTES - 1)) |
+					      ((uint64_t)offset & 0x07)
+					      );
+	pkt_desc->dstLLWMask = 0;
+	pkt_desc->authDst = (uint64_t)virt_to_phys(tmp_auth_data);
+	pkt_desc->ckSumDst = 0;
+  
+	memset(ctrl_desc, 0, sizeof(ControlDescriptor_t));
+	/* Construct the control descriptor */
+	ctrl_desc->instruction = ( ((uint64_t)(offset >> 3) << 18) |
+				   ((uint64_t)1 << 20) |
+				   ((uint64_t)HASH_MD5 << 21) |
+				   ((uint64_t)1 << 23) |
+				   ((uint64_t)1 << 36)
+				   );
+	len_dwords = NUM_CHUNKS(keylen, 3);
+	for(i=0;i<len_dwords;i++)
+	  ctrl_desc->cipherHashInfo.infoDwords[i] = *((uint64_t *)&key[i<<3]);
+	ctrl_desc_size = 9<<3;
+
+#ifdef DEBUG
+	{      
+	  dbg_msg("ctrl_desc_size=%d, ctrl_desc->instr=%llx, pkt_desc<%llx,%llx,%llx,%llx>\n",
+		  ctrl_desc_size, ctrl_desc->instruction, 
+		  pkt_desc->srcLengthIVOffUseIVNext, pkt_desc->dstLLWMask,
+		  pkt_desc->authDst, pkt_desc->ckSumDst);
+	}
+#endif
+	
+	/* Send the message to the sec_engine */
+	ctrl_len_cachelines = NUM_CHUNKS(ctrl_desc_size, 5);
+	stid = make_sec_desc(&msg, ctrl_desc, ctrl_len_cachelines, pkt_desc);	  
+
+#ifdef DEBUG	
+	dbg_msg("cachelines=%d, ctrl_desc=%p, pkt_desc=%p, ctrl_desc->instr=%llx, "
+		"pkt_desc<%llx,%llx,%llx,%llx>\n",
+		ctrl_len_cachelines, ctrl_desc, pkt_desc, ctrl_desc->instruction, 
+		pkt_desc->srcLengthIVOffUseIVNext, pkt_desc->dstLLWMask,
+		pkt_desc->authDst, pkt_desc->ckSumDst);
+#endif
+	
+	msgrng_access_save(&msgrng_lock, flags, msgrng_flags);
+
+	while (message_send(2, MSGRNG_CODE_SEC, stid, &msg));
+	
+	/* Wait for the response */
+	for(;;) {
+	  int bucket = (cpu_logical_map(smp_processor_id()) & 0x03) + 4;
+	  int ctrl_err=0, pkt_err=0;
+#ifdef DEBUG	  
+	  dbg_msg("waiting for a response from sec engine (bucket=%x)...\n", bucket);
+#endif
+	  msgrng_wait(1 << bucket);
+
+	  if (message_receive(bucket, &size, &code, &stid, &msg)) 
+	    continue;
+
+	  ctrl_desc = (ControlDescriptor_t *)phys_to_virt(msg.msg0 & 0xffffffffe0ULL);
+	  pkt_desc = (PacketDescriptor_t *)phys_to_virt(msg.msg1 & 0xffffffffe0ULL);
+	  
+	  ctrl_err = (msg.msg0 >> 40) & 0x1ff;
+	  pkt_err = (msg.msg1 >> 40) & 0x1ff;
+	  if (ctrl_err || pkt_err) {
+	    dbg_msg("error (ctrl_err=%x, pkt_err=%x) reported by sec_engine\n", 
+		   ctrl_err, pkt_err);
+	    goto out;
+	  }
+
+	  /* copy the auth result */
+	  if (pkt_desc->authDst != (uint64_t)virt_to_phys(tmp_auth_data)) {
+	    dbg_msg("bad authDst in sec engine response\n");
+	    goto out;
+	  }
+	  
+	  memcpy(auth_data, tmp_auth_data, ahp->icv_trunc_len);
+#ifdef DEBUG
+	  {
+	    dbg_msg("sec engine auth result:\n");
+	    for(i=0;i<ahp->icv_trunc_len;i++) {
+	      printk("%02x ", auth_data[i]);
+	      if (i && (i % 16) == 0) printk("\n");
+	    }
+	    printk("\n");
+	  }
+#endif	  
+	  break;
+	}
+ out:
+	msgrng_access_restore(&msgrng_lock, flags, msgrng_flags);
+} 
+
+static int __init phoenix_sec_init(void)
+{
+  int i=0;
+  phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_SECURITY_OFFSET);
+
+  spin_lock_init(&msgrng_lock);
+
+  phoenix_write_reg(mmio, SEC_DMA_CREDIT, 0x00924924);
+  
+  for(i=0;i<8;i++)
+    phoenix_write_reg(mmio, SEC_MSG_BUCKET0_SIZE + i, bucket_sizes.bucket[MSGRNG_STNID_SEC + i]);
+  
+  for(i=0;i<128;i++)
+    phoenix_write_reg(mmio, SEC_CC_CPU0_0 + i, cc_table_sec.counters[i>>3][i&0x07]);
+
+  dbg_msg("Intialized Phoenix security engine\n");
+
+  return 0;
+}
+
+module_init(phoenix_sec_init);
diff --git a/drivers/Makefile b/drivers/Makefile
index 1acbcea..f908b12 100644
--- a/drivers/Makefile
+++ b/drivers/Makefile
@@ -104,6 +104,8 @@ obj-$(CONFIG_INFINIBAND)	+= infiniband/
 obj-$(CONFIG_SGI_SN)		+= sn/
 obj-y				+= firmware/
 obj-$(CONFIG_CRYPTO)		+= crypto/
+#obj-$(CONFIG_PERFCTR)		+= perfctr/
+obj-y += perfctr/
 obj-$(CONFIG_SUPERH)		+= sh/
 obj-$(CONFIG_ARCH_SHMOBILE)	+= sh/
 ifndef CONFIG_ARCH_USES_GETTIMEOFFSET
diff --git a/drivers/block/sbull.c b/drivers/block/sbull.c
new file mode 100644
index 0000000..da33c5b
--- /dev/null
+++ b/drivers/block/sbull.c
@@ -0,0 +1,357 @@
+/*
+ * Sample disk driver, from the beginning.
+ */
+
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+
+#include <linux/sched.h>
+#include <linux/kernel.h>	/* printk() */
+#include <linux/slab.h>		/* kmalloc() */
+#include <linux/fs.h>		/* everything... */
+#include <linux/errno.h>	/* error codes */
+#include <linux/timer.h>
+#include <linux/types.h>	/* size_t */
+#include <linux/fcntl.h>	/* O_ACCMODE */
+#include <linux/hdreg.h>	/* HDIO_GETGEO */
+#include <linux/kdev_t.h>
+#include <linux/vmalloc.h>
+#include <linux/genhd.h>
+#include <linux/blkdev.h>
+#include <linux/buffer_head.h>	/* invalidate_bdev */
+#include <linux/bio.h>
+
+static int sbull_major = 0;
+module_param(sbull_major, int, 0);
+
+static int hardsect_size = 512;
+module_param(hardsect_size, int, 0);
+
+static int nsectors = 1024;	/* How big the drive is */
+module_param(nsectors, int, 0);
+
+static int ndevices = 1;
+module_param(ndevices, int, 0);
+
+/**
+ * Minor number and partition management.
+ **/
+
+#define SBULL_MINORS	16
+#define MINOR_SHIFT	4
+#define DEVNUM(kdevnum)	(MINOR(kdev_t_to_nr(kdevnum)) >> MINOR_SHIFT
+
+/**
+ * We can tweak our hardware sector size, but the kernel talks to us
+ * in terms of small sectors, always.
+ **/
+
+#define KERNEL_SECTOR_SIZE	512
+
+/**
+ * After this much idle time, the driver will simulate a media change.
+ **/
+#define INVALIDATE_DELAY	30*HZ
+
+/*
+ * The internal representation of our device.
+ */
+struct sbull_dev {
+        int size;                       /* Device size in sectors */
+        u8 *data;                       /* The data array */
+        short users;                    /* How many users */
+        short media_change;             /* Flag a media change? */
+        spinlock_t lock;                /* For mutual exclusion */
+        struct request_queue *queue;    /* The device request queue */
+        struct gendisk *gd;             /* The gendisk structure */
+        struct timer_list timer;        /* For simulated media changes */
+};
+
+static struct sbull_dev *Devices = NULL;
+
+/**
+ * Handle an I/O request.
+ **/
+
+static void sbull_transfer(struct sbull_dev *dev, unsigned long sector,
+		unsigned long nsect, char *buffer, int write)
+{
+	unsigned long offset = sector*KERNEL_SECTOR_SIZE;
+	unsigned long nbytes = nsect*KERNEL_SECTOR_SIZE;
+
+	if ((offset + nbytes) > dev->size) {
+		printk (KERN_NOTICE "Beyond-end write (%ld %ld)\n", offset, nbytes);
+		return;
+	}
+	if (write)
+		memcpy(dev->data + offset, buffer, nbytes);
+	else
+		memcpy(buffer, dev->data + offset, nbytes);
+}
+
+/**
+ * Transfer a single BIO.
+ **/
+
+static int sbull_xfer_bio(struct sbull_dev *dev, struct bio *bio)
+{
+	int i;
+	struct bio_vec *bvec;
+	sector_t sector = bio->bi_sector;
+
+	/* Do each segment independently. */
+	bio_for_each_segment(bvec, bio, i) {
+		char *buffer = __bio_kmap_atomic(bio, i, KM_USER0);
+		sbull_transfer(dev, sector, bio_cur_sectors(bio),
+				buffer, bio_data_dir(bio) == WRITE);
+		sector += bio_cur_sectors(bio);
+		__bio_kunmap_atomic(bio, KM_USER0);
+	}
+	return 0; /* Always "succeed" */
+}
+
+/*
+ * The direct make request version.
+ */
+static int sbull_make_request(struct request_queue *q, struct bio *bio)
+{
+	struct sbull_dev *dev = q->queuedata;
+	int status;
+
+	status = sbull_xfer_bio(dev, bio);
+	bio_endio(bio, status);
+	return 0;
+}
+
+
+/**
+ * Open and close.
+ **/
+
+static int sbull_open(struct inode *inode, struct file *filp)
+{
+	struct sbull_dev *dev = inode->i_bdev->bd_disk->private_data;
+
+	// del_timer_sync(&dev->timer);
+	filp->private_data = dev;
+	spin_lock(&dev->lock);
+	if (! dev->users) 
+		check_disk_change(inode->i_bdev);
+	dev->users++;
+	spin_unlock(&dev->lock);
+	return 0;
+}
+
+static int sbull_release(struct inode *inode, struct file *filp)
+{
+	struct sbull_dev *dev = inode->i_bdev->bd_disk->private_data;
+
+	spin_lock(&dev->lock);
+	dev->users--;
+
+	/* if (!dev->users) {
+		dev->timer.expires = jiffies + INVALIDATE_DELAY;
+		add_timer(&dev->timer);
+	} */
+	spin_unlock(&dev->lock);
+
+	return 0;
+}
+
+/*
+ * Look for a (simulated) media change.
+ */
+int sbull_media_changed(struct gendisk *gd)
+{
+	struct sbull_dev *dev = gd->private_data;
+	
+	return dev->media_change;
+}
+
+/*
+ * Revalidate.  WE DO NOT TAKE THE LOCK HERE, for fear of deadlocking
+ * with open.  That needs to be reevaluated.
+ */
+int sbull_revalidate(struct gendisk *gd)
+{
+	struct sbull_dev *dev = gd->private_data;
+	
+	if (dev->media_change) {
+		dev->media_change = 0;
+		memset (dev->data, 0, dev->size);
+	}
+	return 0;
+}
+
+/*
+ * The "invalidate" function runs out of the device timer; it sets
+ * a flag to simulate the removal of the media.
+ */
+void sbull_invalidate(unsigned long ldev)
+{
+	struct sbull_dev *dev = (struct sbull_dev *) ldev;
+
+	spin_lock(&dev->lock);
+	if (dev->users || !dev->data) 
+		printk (KERN_WARNING "sbull: timer sanity check failed\n");
+	else
+		dev->media_change = 1;
+	spin_unlock(&dev->lock);
+}
+
+/*
+ * The ioctl() implementation
+ */
+
+int sbull_ioctl (struct inode *inode, struct file *filp,
+                 unsigned int cmd, unsigned long arg)
+{
+	long size;
+	struct hd_geometry geo;
+	struct sbull_dev *dev = filp->private_data;
+
+	switch(cmd) {
+	    case HDIO_GETGEO:
+        	/*
+		 * Get geometry: since we are a virtual device, we have to make
+		 * up something plausible.  So we claim 16 sectors, four heads,
+		 * and calculate the corresponding number of cylinders.  We set the
+		 * start of data at sector four.
+		 */
+		size = dev->size*(hardsect_size/KERNEL_SECTOR_SIZE);
+		geo.cylinders = (size & ~0x3f) >> 6;
+		geo.heads = 4;
+		geo.sectors = 16;
+		geo.start = 4;
+		if (copy_to_user((void __user *) arg, &geo, sizeof(geo)))
+			return -EFAULT;
+		return 0;
+	}
+
+	return -ENOTTY; /* unknown command */
+}
+
+
+
+/*
+ * The device operations structure.
+ */
+static struct block_device_operations sbull_ops = {
+	.owner           = THIS_MODULE,
+	.open 	         = sbull_open,
+	.release 	 = sbull_release,
+	.media_changed   = sbull_media_changed,
+	.revalidate_disk = sbull_revalidate,
+	.ioctl	         = sbull_ioctl
+};
+
+
+/*
+ * Set up our internal device.
+ */
+static void setup_device(struct sbull_dev *dev, int which)
+{
+	/*
+	 * Get some memory.
+	 */
+	memset (dev, 0, sizeof (struct sbull_dev));
+	dev->size = nsectors*hardsect_size;
+
+	// dev->data = vmalloc(dev->size);
+	dev->data = (u8 *) (unsigned long)0xffffffff80400000ULL; // 4 MB
+
+	/* if (dev->data == NULL) {
+		printk (KERN_NOTICE "vmalloc failure.\n");
+		return;
+	} */
+	spin_lock_init(&dev->lock);
+	
+	/*
+	 * The timer which "invalidates" the device.
+	 */
+	/* init_timer(&dev->timer);
+	dev->timer.data = (unsigned long) dev;
+	dev->timer.function = sbull_invalidate; */
+	
+	dev->queue = blk_alloc_queue(GFP_KERNEL);
+	if (dev->queue == NULL)
+		goto out_vfree;
+	blk_queue_make_request(dev->queue, sbull_make_request);
+
+	blk_queue_hardsect_size(dev->queue, hardsect_size);
+	dev->queue->queuedata = dev;
+
+	/*
+	 * And the gendisk structure.
+	 */
+
+	dev->gd = alloc_disk(SBULL_MINORS);
+	if (! dev->gd) {
+		printk (KERN_NOTICE "alloc_disk failure\n");
+		goto out_vfree;
+	}
+	dev->gd->major = sbull_major;
+	dev->gd->first_minor = which*SBULL_MINORS;
+	dev->gd->fops = &sbull_ops;
+	dev->gd->queue = dev->queue;
+	dev->gd->private_data = dev;
+	snprintf (dev->gd->disk_name, 32, "sbull%c", which + 'a');
+	set_capacity(dev->gd, nsectors*(hardsect_size/KERNEL_SECTOR_SIZE));
+	add_disk(dev->gd);
+
+  out_vfree:
+	return;
+}
+
+static int __init sbull_init(void)
+{
+	int i;
+	/*
+	 * Get registered.
+	 */
+	sbull_major = register_blkdev(sbull_major, "sbull");
+	if (sbull_major <= 0) {
+		printk(KERN_WARNING "sbull: unable to get major number\n");
+		return -EBUSY;
+	}
+	/*
+	 * Allocate the device array, and initialize each one.
+	 */
+	Devices = kmalloc(ndevices*sizeof (struct sbull_dev), GFP_KERNEL);
+	if (Devices == NULL)
+		goto out_unregister;
+	for (i = 0; i < ndevices; i++) 
+		setup_device(Devices + i, i);
+
+	return 0;
+
+  out_unregister:
+	unregister_blkdev(sbull_major, "sbd");
+	return -ENOMEM;
+}
+
+static void sbull_exit(void)
+{
+	int i;
+
+	for (i = 0; i < ndevices; i++) {
+		struct sbull_dev *dev = Devices + i;
+
+		// del_timer_sync(&dev->timer);
+		if (dev->gd) {
+			del_gendisk(dev->gd);
+			put_disk(dev->gd);
+		}
+		if (dev->queue) {
+			blk_put_queue(dev->queue);
+		}
+		if (dev->data)
+			vfree(dev->data);
+	}
+	unregister_blkdev(sbull_major, "sbull");
+	kfree(Devices);
+}
+
+module_init(sbull_init);
+module_exit(sbull_exit);
diff --git a/drivers/char/Kconfig b/drivers/char/Kconfig
index a16c927..4370751 100644
--- a/drivers/char/Kconfig
+++ b/drivers/char/Kconfig
@@ -264,6 +264,18 @@ config NWFLASH
 
 source "drivers/char/hw_random/Kconfig"
 
+config PHOENIX_RMIOS_DEBUGGER
+	bool "RMIOS Debugger support"
+	depends on RMI_PHOENIX!=n
+	default n
+	---help---
+	This module provides debugging facility for rmios images loaded on the
+	board, before loading linux image. Network interface is used to
+	communicate with remote gdb host. GDB clients communicate using the
+	network connection. Multiple rmios sessions can be run on different
+	virtual cpus. These gdb capable rmios sessions can be debugged
+	remotely by connecting to these session remotely through gdb.
+
 config NVRAM
 	tristate "/dev/nvram support"
 	depends on ATARI || X86 || (ARM && RTC_DRV_CMOS) || GENERIC_NVRAM
@@ -630,3 +642,10 @@ config TILE_SROM
 
 endmenu
 
+config RMICDE
+	tristate "RMI Compression/Decompression Engine"
+	depends on RMI_PHOENIX!=n
+	default n
+	help
+	  The CDE allows deflate/inflate through hardware
+
diff --git a/drivers/char/Makefile b/drivers/char/Makefile
index 2f843ba..f579767 100644
--- a/drivers/char/Makefile
+++ b/drivers/char/Makefile
@@ -54,6 +54,11 @@ obj-$(CONFIG_MWAVE)		+= mwave/
 obj-$(CONFIG_AGP)		+= agp/
 obj-$(CONFIG_PCMCIA)		+= pcmcia/
 obj-$(CONFIG_IPMI_HANDLER)	+= ipmi/
+obj-$(CONFIG_RMI_XLR) 	+= phnx_tb.o
+obj-$(CONFIG_PHOENIX_PCIX_GEN_DRIVER) += rmi_pcix_gen_dev.o
+obj-$(CONFIG_PHOENIX_PCIX_GEN_DRIVER) += rmi_pcix_gen_host.o
+obj-$(CONFIG_PHOENIX_CONSOLE_OVER_PCI) += xlr_pcix_console_dev.o
+obj-$(CONFIG_PHOENIX_CONSOLE_OVER_PCI) += xlr_pcix_console_host.o
 
 obj-$(CONFIG_HANGCHECK_TIMER)	+= hangcheck-timer.o
 obj-$(CONFIG_TCG_TPM)		+= tpm/
diff --git a/drivers/char/hw_random/Kconfig b/drivers/char/hw_random/Kconfig
index b2402eb..5257ab4 100644
--- a/drivers/char/hw_random/Kconfig
+++ b/drivers/char/hw_random/Kconfig
@@ -4,7 +4,7 @@
 
 config HW_RANDOM
 	tristate "Hardware Random Number Generator Core support"
-	default m
+	default y
 	---help---
 	  Hardware Random Number Generator Core infrastructure.
 
@@ -139,6 +139,11 @@ config HW_RANDOM_OMAP
 
  	  If unsure, say Y.
 
+config HW_RANDOM_MIPS_XLR
+	bool "RMI XLR Random Number Generator support"
+	depends on HW_RANDOM && RMI_PHOENIX
+	default y
+
 config HW_RANDOM_OCTEON
 	tristate "Octeon Random Number Generator support"
 	depends on HW_RANDOM && CPU_CAVIUM_OCTEON
diff --git a/drivers/char/hw_random/Makefile b/drivers/char/hw_random/Makefile
index b2ff526..441970c 100644
--- a/drivers/char/hw_random/Makefile
+++ b/drivers/char/hw_random/Makefile
@@ -14,6 +14,7 @@ n2-rng-y := n2-drv.o n2-asm.o
 obj-$(CONFIG_HW_RANDOM_VIA) += via-rng.o
 obj-$(CONFIG_HW_RANDOM_IXP4XX) += ixp4xx-rng.o
 obj-$(CONFIG_HW_RANDOM_OMAP) += omap-rng.o
+obj-$(CONFIG_HW_RANDOM_MIPS_XLR) += xlr-rng.o
 obj-$(CONFIG_HW_RANDOM_PASEMI) += pasemi-rng.o
 obj-$(CONFIG_HW_RANDOM_VIRTIO) += virtio-rng.o
 obj-$(CONFIG_HW_RANDOM_TX4939) += tx4939-rng.o
diff --git a/drivers/char/hw_random/xlr-rng.c b/drivers/char/hw_random/xlr-rng.c
new file mode 100644
index 0000000..de57e41
--- /dev/null
+++ b/drivers/char/hw_random/xlr-rng.c
@@ -0,0 +1,85 @@
+/*
+ * RNG driver for RMI PHOENIX CPU
+ *
+ * derived from
+ *
+ * Hardware driver for the AMD 768 Random Number Generator (RNG)
+ * (c) Copyright 2001 Red Hat Inc <alan@redhat.com>
+ *
+ * derived from
+ *
+ * Hardware driver for Intel i810 Random Number Generator (RNG)
+ * Copyright 2000,2001 Jeff Garzik <jgarzik@pobox.com>
+ * Copyright 2000,2001 Philipp Rumpf <prumpf@mandrakesoft.com>
+ *
+ * This file is licensed under  the terms of the GNU General Public
+ * License version 2. This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/hw_random.h>
+#include <asm/io.h>
+#include <asm/rmi/gpio.h>
+
+
+#define PFX	KBUILD_MODNAME ": "
+
+
+static phoenix_reg_t   *mmio;
+static int xlr_data_present(struct hwrng *rng, int wait)
+{
+	return 1;
+}
+
+static int xlr_data_read(struct hwrng *rng, u32 *data)
+{
+	*data = phoenix_read_reg(mmio, PHOENIX_GPIO_RNG_REG);
+	return 4;
+}
+
+static int xlr_init(struct hwrng *rng)
+{
+	mmio = phoenix_io_mmio(PHOENIX_IO_GPIO_OFFSET);
+	return 0;
+
+}
+
+static void xlr_cleanup(struct hwrng *rng)
+{
+}
+
+
+static struct hwrng xlr_rng = {
+	.name		= "xlr",
+	.init		= xlr_init,
+	.cleanup	= xlr_cleanup,
+	.data_present	= xlr_data_present,
+	.data_read	= xlr_data_read,
+};
+
+
+static int __init mod_init(void)
+{
+	int err = -ENODEV;
+	err = hwrng_register(&xlr_rng);
+	if (err) {
+		printk(KERN_ERR PFX "RNG registering failed (%d)\n",
+		       err);
+	}
+	printk(KERN_INFO "RMI RNG registered\n");
+	return err;
+}
+
+static void __exit mod_exit(void)
+{
+	hwrng_unregister(&xlr_rng);
+}
+
+module_init(mod_init);
+module_exit(mod_exit);
+
+MODULE_AUTHOR("The Linux Kernel team");
+MODULE_DESCRIPTION("H/W RNG driver for RMI XLR chipsets");
+MODULE_LICENSE("GPL");
diff --git a/drivers/char/mem.c b/drivers/char/mem.c
index d6e9d08..0cf0a06 100644
--- a/drivers/char/mem.c
+++ b/drivers/char/mem.c
@@ -87,6 +87,9 @@ void __weak unxlate_dev_mem_ptr(unsigned long phys, void *addr)
 {
 }
 
+extern int phnx_get_pgprot(unsigned long address);
+extern int valid_mmap_phnx_addr_range(unsigned long pfn);
+
 /*
  * This funcion reads the *physical* memory. The f_pos points directly to the
  * memory location.
@@ -307,6 +310,13 @@ static int mmap_mem(struct file *file, struct vm_area_struct *vma)
 	if (!private_mapping_ok(vma))
 		return -ENOSYS;
 
+  #ifdef CONFIG_MIPS
+  #ifdef CONFIG_RMI_PHOENIX
+	if(!valid_mmap_phnx_addr_range(vma->vm_pgoff))
+		return -EINVAL;
+	#endif
+  #endif
+
 	if (!range_is_allowed(vma->vm_pgoff, size))
 		return -EPERM;
 
diff --git a/drivers/char/phnx_cde.c b/drivers/char/phnx_cde.c
new file mode 100644
index 0000000..2640d3c
--- /dev/null
+++ b/drivers/char/phnx_cde.c
@@ -0,0 +1,797 @@
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/poll.h>
+
+#include <linux/slab.h>         /* kmalloc() */
+#include <linux/fs.h>           /* everything... */
+#include <linux/errno.h>        /* error codes */
+#include <linux/types.h>        /* size_t */
+#include <linux/proc_fs.h>
+#include <linux/fcntl.h>        /* O_ACCMODE */
+#include <linux/seq_file.h>
+#include <linux/cdev.h>
+#include <linux/module.h>
+
+#include <asm/system.h>         /* cli(), *_flags */
+#include <asm/uaccess.h>        /* copy_*_user */
+#include <asm/rmi/sim.h>        /* is_xls */
+
+#include <asm/rmi/phnx_cde.h>
+#include <asm/rmi/linux_crf.h>
+#include <asm/rmi/rmi_rw_lock.h>
+
+
+#define CDE_NON      0
+#define CDE_STATIC   1
+#define CDE_DYNAMIC  2
+#define CDE_DYNAMIC2 3
+
+#define FD_BURST_SIZE 1
+#define RTN_BKT 2
+#define CC_CPU0_0 0x380
+
+#define SPILL_SIZE   1024
+#define NUM_FREE_DESCRIPTORS 100 //must be less or equal to MAX_NUM_PAGES
+#define MAX_NUM_PAGES 100
+#define MAX_BUFFER_SIZE 1024*16
+#define CMP_PAGE_SIZE   1024
+#define SCRATCH_SIZE    1024
+
+#define MAX_NUM_MESSAGES 20
+
+extern __u32 cpu_to_frstid[];
+
+/*
+typedef struct cmp_data_structure {
+  char src[MAX_BUFFER_SIZE];    // source data
+  char target[MAX_BUFFER_SIZE]; // inflated or deflated result
+  unsigned long long src_desc[CMP_PAGE_SIZE];  // source descriptors
+  unsigned long long scratch[SCRATCH_SIZE];    // scratch page
+  unsigned long long src_size;    //size of source data
+  unsigned long long target_size; // size of result
+  unsigned long long num_desc;    // number of source descriptors including scratch desc
+  short op;                       // to deflate or inflate
+} cmp_data_t;
+
+*/
+
+typedef struct cmp_data_structure {
+  char *src;    // source data
+  char *target; // inflated or deflated result
+  unsigned long long *src_desc;  // source descriptors
+  unsigned long long *scratch;    // scratch page
+  unsigned long long src_size;    //size of source data
+  unsigned long long target_size; // size of result
+  unsigned long long num_desc;    // number of source descriptors including scratch desc
+  short op;                       // to deflate or inflate
+} cmp_data_t;
+
+typedef enum {
+	CDE_READ_DONE = 0,
+	CDE_WRITE_PENDING,
+	CDE_WRITE_DONE
+} phnx_cde_state;
+
+typedef struct msgrng_msg msg;
+wait_queue_head_t cde_write_queue;
+static volatile int cde_write_completed;
+static spinlock_t cde_read_write_lock;
+
+// Data Structures
+struct cde_dev {
+  struct cdev cdev;	  /* Char device structure	    */
+  void *data;
+};
+
+typedef struct free_page_structure {
+	  char *data_array;
+} fr_page;
+
+typedef struct spill_page_structure {
+	  char *data_array;
+} sp_page;
+
+
+volatile msg cmp_msg[MAX_NUM_MESSAGES]    __attribute__((aligned(32)));
+volatile fr_page page_array[MAX_NUM_PAGES]    __attribute__((aligned(32)));
+volatile sp_page spill_page  __attribute__((aligned(32)));
+volatile char *spill_page_tmp_data_array __attribute__((aligned(32)));
+volatile char *(page_array_tmp_data_array[MAX_NUM_PAGES])__attribute__((aligned(32)));
+
+
+#define CACHELINE_ALIGNED_ADDR(addr) (((unsigned long)(addr)) & ~(SMP_CACHE_BYTES-1))
+
+static __inline__ void *cacheline_aligned_kmalloc(int size, char **buf_addr, int gfp_mask)
+{
+	void *buf = kmalloc(size + SMP_CACHE_BYTES, gfp_mask);
+	
+	if (buf)	{
+		*buf_addr = (char *)buf;
+		buf = (void*)(CACHELINE_ALIGNED_ADDR((unsigned long)buf +
+					SMP_CACHE_BYTES));
+	}
+	return buf;
+}
+
+static int cde_debug = 0;
+
+
+static int config_cmp(void)
+{
+  int i;
+  phoenix_reg_t *cmp_mmio = phoenix_io_mmio(PHOENIX_IO_COMP_OFFSET);
+  
+  spill_page.data_array = cacheline_aligned_kmalloc(SPILL_SIZE+SMP_CACHE_BYTES,(char **)&spill_page_tmp_data_array, GFP_KERNEL);
+  if(!spill_page.data_array)
+	  return -1;
+
+  if (dev_tree_en) {
+    char bkt[8], cc[16][8];
+    int rv = fdt_get_cde_bucket_conf(bkt, 4, cc, 128);
+
+    if (rv == -1) {
+       printk(KERN_ERR "CDE: Could not get credit info from FDT\n");
+       return -1;
+    }
+    phoenix_write_reg(cmp_mmio, CMP_MSG_BUCKET0_SIZE, bkt[0]);
+    phoenix_write_reg(cmp_mmio, CMP_MSG_BUCKET1_SIZE, bkt[1]);
+
+    for (i = 0; i < 32; i++)
+       phoenix_write_reg(cmp_mmio, CC_CPU0_0 + i, cc[i/8][i%8]);
+  } else {
+    phoenix_write_reg(cmp_mmio, CMP_MSG_BUCKET0_SIZE, xls_bucket_sizes.bucket[MSGRNG_STNID_CMP_0]);
+    phoenix_write_reg(cmp_mmio, CMP_MSG_BUCKET1_SIZE, xls_bucket_sizes.bucket[MSGRNG_STNID_CMP_1]);
+    for (i = 0; i < 32; i++)
+      phoenix_write_reg(cmp_mmio, CC_CPU0_0 + i, 
+			xls_cc_table_cmp.counters[i >> 3][i & 0x7]);
+  }
+   
+  cmp_write_reg(CMP_REG_CTRL_REG,        ((0x39CE << 16) | CMP_PAGE_SIZE)); //16'h{CMP_PAGE_SIZE}
+  cmp_write_reg(CMP_REG_DMA_CREDITS_REG, 0x0FFFFFFF);
+  cmp_write_reg(CMP_REG_SPILL_ADDR0_REG, (virt_to_phys(spill_page.data_array) >> 5) & 0xffffffffffffffffUll);
+  cmp_write_reg(CMP_REG_SPILL_ADDR1_REG, ((__u64)virt_to_phys(spill_page.data_array) >> 36) & 0x7);
+  cmp_write_reg(CMP_REG_SPILL_SIZE_REG,  SPILL_SIZE); //16'h{SPILL_SIZE}
+
+  if (cde_debug) {
+    printk("COMP OFFSET = 0x%x\n", PHOENIX_IO_COMP_OFFSET);
+    printk("register = 0x%0x data = 0x%0x\n", CMP_MSG_BUCKET0_SIZE,cmp_mmio[CMP_MSG_BUCKET0_SIZE]);
+    printk("register = 0x%0x data = 0x%0x\n", CMP_MSG_BUCKET1_SIZE,cmp_mmio[CMP_MSG_BUCKET1_SIZE]);
+
+    printk("register=0x%0x data=0x%0x\n", CMP_REG_CTRL_REG, cmp_read_reg(CMP_REG_CTRL_REG));
+    printk("register=0x%0x data=0x%0x\n", CMP_REG_DMA_CREDITS_REG, cmp_read_reg(CMP_REG_DMA_CREDITS_REG));
+    printk("register=0x%0x data=0x%0x\n", CMP_REG_SPILL_ADDR0_REG, cmp_read_reg(CMP_REG_SPILL_ADDR0_REG));
+    printk("register=0x%0x data=0x%0x\n", CMP_REG_SPILL_ADDR1_REG, cmp_read_reg(CMP_REG_SPILL_ADDR1_REG));
+    printk("register=0x%0x data=0x%0x\n", CMP_REG_SPILL_SIZE_REG, cmp_read_reg(CMP_REG_SPILL_SIZE_REG));
+  }
+  return 0;
+}
+
+static int send_message(int stid, struct msgrng_msg *msg)
+{
+  unsigned long mflags = 0;
+  int ret = 0;
+
+  msgrng_flags_save(mflags);
+  ret = message_send_retry(1, 0, stid, msg);
+  msgrng_flags_restore(mflags);
+
+  return ret;
+}
+
+
+static int send_free_desc(void)
+{
+  int i;
+  int status = 0;
+  int stid;
+  struct msgrng_msg fd_msg;
+
+
+  // send free descriptors to cmp block
+  for (i = 0; i < NUM_FREE_DESCRIPTORS; i++) {
+    if (!page_array[i].data_array)	  
+       page_array[i].data_array = cacheline_aligned_kmalloc(CMP_PAGE_SIZE+SMP_CACHE_BYTES, (char **)&page_array_tmp_data_array[i], GFP_KERNEL);
+    if (!page_array[i].data_array)	{
+	    printk("cacheline_aligned_kmalloc returmed error\n");
+	    return -1;
+    }
+
+    stid = make_fd_msg(&fd_msg, page_array[i].data_array);
+    //    printk("Free descriptor message [%0d] = 0x%016llx\n", i, fd_msg.msg0);
+
+    status = send_message(MSGRNG_STNID_CMP_0, &fd_msg);
+
+    if (status != 0) {
+      printk("[%s@%d]: Free descriptor (%d) didnt not reach cmpm status=%0d\n",
+	     __FUNCTION__, __LINE__, i, status);
+      return -1;
+    }
+  }
+
+  if (cde_debug) {
+    printk("[%s@%d]: Sent %d free desc to comp engine\n",
+	   __FUNCTION__, __LINE__, i);
+  }
+
+  return 0;
+}
+
+
+int create_message(cmp_data_t *cmp_data, int num_blk, int num_desc, int en_save_restore)
+{
+  int num_messages;
+  int i,j,k,stid;
+
+  int type = CDE_STATIC;
+  int rtn_bkt;
+
+  int cur_blk = 0;
+  int cur_desc = 0;
+
+  int eof  = 0;
+  int sod  = 0;
+  int sob  = 0;
+  int eob  = 0;
+  int save = 0;
+  int restore = 0;
+
+  int length = 0;
+  int start = 0;
+  int div = num_blk * num_desc;
+
+  int desc_idx = 0;
+
+  if (en_save_restore)
+    num_messages = num_blk;
+  else
+    num_messages = 1;
+
+  rtn_bkt = cpu_to_frstid[hard_smp_processor_id()];
+  /*
+   * dliao: num_messages = 1 for now. not sure how it works when num_messages > 0 or num_desc > 0
+   * what is num_blk or num_desc for ?
+   */
+  for (i = 0; i < num_messages; i++) {
+    //create scratch page descriptor
+    cur_desc = 0;
+    restore = ((num_messages > 1) & (cur_blk != 0));
+    length = SCRATCH_SIZE;
+
+    cmp_data->src_desc[desc_idx] =
+      make_src_desc(0, 0, 0, 0, 0, restore, 0, length, cmp_data->scratch);
+
+    if (cde_debug) {
+      printk("scratch=0x%p, v2p=0x%lx, scratch_desc = 0x%016llx &scratch_desc=0x%p\n", 
+	     cmp_data->scratch, virt_to_phys(cmp_data->scratch), cmp_data->src_desc[desc_idx], &(cmp_data->src_desc[0])); 
+    }
+
+    cur_desc++;
+
+    for (j = 0; j < num_blk/num_messages; j++) {
+      for (k = 0; k < num_desc; k++) {
+	eof = (cur_blk == num_blk-1);
+
+	sod = (start == 0);
+	sob = (k == 0);
+	eob = (k == num_desc-1);
+	save = ((en_save_restore == 1) & (eob == 1) & (eof == 0));
+	restore = 0; //restore only can be 1 on scratch descriptor
+
+	//	length = (cmp_data->src_size - start) / div;
+	length = (cmp_data->src_size - start); //dliao: assume div == 1
+
+	cmp_data->src_desc[cur_desc] =
+	  make_src_desc(eof, type, sod, sob, save, restore, eob, length, cmp_data->src + start);
+
+	if (cde_debug) {
+	  printk("[%s@%d]: eof=%d, sod=%d, sob=%d, eob=%d, save=%d, restore=0, length=%d\n",
+		 __FUNCTION__, __LINE__, eof, sod, sob, eob, save, length);
+	  
+	  printk("[%s@%d]: cur_desc=%d, i=%d, j=%d, k=%d, &(cmp_data->src)=0x%p, src_desc[1]=0x%llx &(src_desc[1])=0x%p\n",
+		 __FUNCTION__, __LINE__,
+		 cur_desc, i, j, k, cmp_data->src, cmp_data->src_desc[cur_desc], &(cmp_data->src_desc[cur_desc]));
+	}
+
+	start = start + length;
+	div--;
+	cur_desc++;
+      }
+
+      if (type == 2) {//dynamic has 2x descriptors
+	cur_desc = cur_desc + num_desc;
+      }
+
+      cur_blk++;
+    }
+
+    stid = make_cmp_msg((struct msgrng_msg *) (cmp_msg + i), rtn_bkt, cmp_data->op,
+			cur_desc, cmp_data->src_desc + desc_idx);
+    if (cde_debug) {
+      printk("[%s@%d]: desc_idx=%d, &(src_desc[0])=0x%p, v2p=0x%lx, i=%d, cmp_msg.msg0 = 0x%016llx\n", __FUNCTION__, __LINE__, desc_idx, cmp_data->src_desc+0, virt_to_phys(cmp_data->src_desc+0),i, cmp_msg[i].msg0); 
+    }
+
+    desc_idx = desc_idx + cur_desc;
+  }
+
+  // returns the number of messages created
+  return (num_messages);
+}
+
+
+void return_free_descriptors(msg *msg_list, int msg_index)
+{
+  int i, j, k, status, num_desc;
+  msg return_msg, fd_msg;
+  uint64_t * temp_desc;
+  uint64_t dest_desc;
+  int used_fd_index = 0;
+
+  volatile uint64_t used_fd[NUM_FREE_DESCRIPTORS] __attribute__((aligned(32)));
+
+  for (i = 0; i < msg_index; i++) {
+
+    memcpy ((void *) &return_msg, (void *)(msg_list+i), sizeof(msg));
+    used_fd[used_fd_index++] = ((uint64_t) return_msg.msg1 & 0xffffffffffUll);
+
+    num_desc = (return_msg.msg1>>40 & 0xffff);
+
+    temp_desc = (uint64_t *) phys_to_virt(return_msg.msg1 & 0xffffffffffUll);
+
+    for (j = 0; j< num_desc; j++) {
+      dest_desc = temp_desc[j];
+      used_fd[used_fd_index++] = ((uint64_t) dest_desc & 0xffffffffffUll);
+    }
+
+
+    if (used_fd_index > FD_BURST_SIZE) {
+      for (k = 0; k < used_fd_index; k++) {
+	fd_msg.msg0 = ((uint64_t) used_fd[k]);
+	status = send_message(MSGRNG_STNID_CMP_0, &fd_msg);
+	if (status != 0)
+	  printk("Return free descriptor didnt not reach cmp! status=%0d\n", status);
+	}
+        used_fd_index = 0;
+    }
+  }
+}
+
+static cmp_data_t *cmp_data = 0;
+
+static void phnx_msgring_comp_int_handler(int bucket, int size, int code, int stid,
+					  struct msgrng_msg *msg, void *data/* ignored */)
+{
+  int last = 0; 
+  int msg_index = 0; 
+  struct msgrng_msg msg_list[MAX_NUM_MESSAGES]; 
+  int offset = cmp_data->target_size;
+  
+  if (cde_debug) {
+    printk("[%s@%d]: bucket=%d, size=%d, code=%d, stid=%d "
+	   " msg0=0x%016llx, msg1=0x%016llx\n",
+	   __FUNCTION__, __LINE__, bucket, size, code, stid, msg->msg0, msg->msg1);
+    printk("@msg = %p \n", msg);
+  }
+
+  // TODO need to fix not-last case
+  last = ((msg->msg0 >> 63) & 0x1ULL); 
+  
+  if (cde_debug)
+    printk("[%s@%d]: last = %d\n", __FUNCTION__, __LINE__, last); 
+    
+  offset = cmp_data->target_size; 
+  cmp_data->target_size += read_cmp_msg((char *) cmp_data->target + offset, msg->msg1);
+
+  if (last) {
+	  spin_lock(&cde_read_write_lock);
+	  cde_write_completed = CDE_WRITE_DONE;
+	  spin_unlock(&cde_read_write_lock);
+  }
+
+  memcpy((void *)&msg_list[msg_index],(void *)msg, sizeof(struct msgrng_msg));
+
+  if (cde_write_completed == CDE_WRITE_DONE) {
+	  wake_up_interruptible(&cde_write_queue);
+  }
+
+  return_free_descriptors(msg_list, msg_index); 
+//  printk("[\n%s@%d]:end of phnx_msgring_comp_int_handler\n", __FUNCTION__, __LINE__);
+}
+
+/*
+ * Our parameters which can be set at load time.
+ */
+
+static int cde_major =   CDE_MAJOR;
+static int cde_minor =   0;
+static int cde_nr_devs = 1;
+
+module_param(cde_major, int, S_IRUGO);
+module_param(cde_minor, int, S_IRUGO);
+module_param(cde_nr_devs, int, S_IRUGO);
+
+struct cde_dev *cde_device;
+static int cde_open_flag = 0;
+static spinlock_t cde_open_lock; 
+
+
+int cde_open(struct inode *inode, struct file *filp)
+{
+  spin_lock(&cde_open_lock);
+  if (cde_open_flag)
+  {       spin_unlock(&cde_open_lock);
+	  return -EAGAIN;
+  }
+ 
+  cde_open_flag = 1;
+  spin_unlock(&cde_open_lock);
+
+  cmp_data = (cmp_data_t *) kmalloc(sizeof(cmp_data_t), GFP_KERNEL);
+  if (!cmp_data)
+    return -ENOMEM;
+  memset(cmp_data, 0, sizeof(cmp_data_t));
+
+  cmp_data->src = kmalloc(MAX_BUFFER_SIZE, GFP_KERNEL);
+  if (! cmp_data->src)	{
+	  printk("kmalloc returns Error : cmp_data->src\n");
+	  kfree(cmp_data);
+	  
+	  return -ENOMEM;
+  }
+	  
+  cmp_data->target = kmalloc(MAX_BUFFER_SIZE, GFP_KERNEL);
+  if (! cmp_data->target)	{
+	  printk("kmalloc returns Error : cmp_data->target\n");
+	  kfree(cmp_data->src);
+	  kfree(cmp_data);
+	  return -ENOMEM;
+  }
+  cmp_data->src_desc = kmalloc(sizeof(unsigned long long) * CMP_PAGE_SIZE , GFP_KERNEL);
+  if (! cmp_data->src_desc)	{
+	  printk("kmalloc returns Error : cmp_data->src_desc\n");
+	  kfree(cmp_data->src);
+	  kfree(cmp_data->target);
+	  kfree(cmp_data);
+	  return -ENOMEM;
+  }
+  cmp_data->scratch = kmalloc(sizeof(unsigned long long) * SCRATCH_SIZE , GFP_KERNEL);
+  if (! cmp_data->scratch)	{
+	  printk("kmalloc returns Error : cmp_data->scratch\n");
+	  kfree(cmp_data->src);
+	  kfree(cmp_data->target);
+	  kfree(cmp_data->src_desc);
+	  kfree(cmp_data);
+	  return -ENOMEM;
+  }
+  memset(cmp_data->src, 0, MAX_BUFFER_SIZE);
+  memset(cmp_data->target, 0, MAX_BUFFER_SIZE);
+  memset(cmp_data->src_desc, 0, sizeof(unsigned long long) * CMP_PAGE_SIZE);
+  memset(cmp_data->scratch, 0, sizeof(unsigned long long) * SCRATCH_SIZE);
+
+  if (config_cmp() == -1)
+	return -ENOMEM;
+
+  if (send_free_desc() == -1)
+	return -ENOMEM;
+
+  init_waitqueue_head(&cde_write_queue);
+  return 0;
+}
+
+
+int cde_release(struct inode *inode, struct file *filp)
+{ 
+	
+  int i;
+  if (cmp_data->src)  
+	  kfree(cmp_data->src);
+  if (cmp_data->target)  
+	  kfree(cmp_data->target);
+  if (cmp_data->src_desc)  
+	  kfree(cmp_data->src_desc);
+  if (cmp_data->scratch)  
+	  kfree(cmp_data->scratch);
+  if (cmp_data)
+    kfree(cmp_data);
+    cmp_data->src = NULL;
+    cmp_data->target = NULL;
+    cmp_data->src_desc = NULL; 
+    cmp_data->scratch = NULL;
+    cmp_data = NULL;
+
+  
+  cmp_write_reg(CMP_REG_RESET_REG, 0x10);
+  do {
+    unsigned int ret = cmp_read_reg(CMP_REG_RESET_REG);
+    if (((ret >> 4) & 0x1) == 1)
+      break;
+  } while (1);
+
+  cmp_write_reg(CMP_REG_RESET_REG, 0x01);
+  cmp_write_reg(CMP_REG_RESET_REG, 0x00);
+  
+  if (spill_page.data_array)	{
+    kfree((void *)spill_page_tmp_data_array);
+    spill_page_tmp_data_array = NULL;
+    spill_page.data_array = NULL;
+  }
+
+  for (i = 0; i < NUM_FREE_DESCRIPTORS; i++) {
+    if (page_array[i].data_array)	{
+	kfree((void *)page_array_tmp_data_array[i]);
+	page_array_tmp_data_array[i] = NULL;
+	page_array[i].data_array = NULL;
+    }	
+  }
+  spin_lock(&cde_open_lock);
+	cde_open_flag = 0;
+  spin_unlock(&cde_open_lock);
+  return 0;
+}
+
+
+// TODO: 1. fix the case when more data than user want to read.
+//       2. mutiple reads
+ssize_t cde_read(struct file *filp, char __user *buf,
+		 size_t count, loff_t *f_pos)
+{
+  int size = 0;
+  unsigned long irq_flags;
+  static volatile int readlock;
+
+  spin_lock_irqsave(&cde_read_write_lock, irq_flags);
+  if (readlock == 1)
+  {
+  	spin_unlock_irqrestore(&cde_read_write_lock, irq_flags);
+	return -EAGAIN;
+  }
+  readlock = 1;
+  spin_unlock_irqrestore(&cde_read_write_lock, irq_flags);
+
+  if (cde_write_completed != CDE_WRITE_DONE)	{
+	  wait_event_interruptible(cde_write_queue, 
+			  (cde_write_completed == CDE_WRITE_DONE) );         
+  }
+  
+  spin_lock_irqsave(&cde_read_write_lock, irq_flags);
+  if (cde_write_completed != CDE_WRITE_DONE) {
+	  readlock = 0;
+	  spin_unlock_irqrestore(&cde_read_write_lock, irq_flags);
+	  return -EAGAIN;
+  }
+  spin_unlock_irqrestore(&cde_read_write_lock, irq_flags);
+
+  size = count < cmp_data->target_size ? count : cmp_data->target_size;
+  
+  if (copy_to_user(buf, cmp_data->target, size)) {
+    printk("copy_to_user failed\n");
+    size = -EFAULT;
+  }
+
+  cmp_data->target_size = 0;
+
+  spin_lock_irqsave(&cde_read_write_lock, irq_flags);
+  cde_write_completed = CDE_READ_DONE;
+  readlock = 0;
+  spin_unlock_irqrestore(&cde_read_write_lock, irq_flags);
+
+  return size;
+}
+
+
+ssize_t cde_write(struct file *filp, const char __user *buf,
+		  size_t count, loff_t *f_pos)
+{
+  int i;
+  int num_messages = 0;
+  unsigned long irq_flags;
+
+  spin_lock_irqsave(&cde_read_write_lock, irq_flags);
+  if (cde_write_completed != CDE_READ_DONE)
+  {
+	  spin_unlock_irqrestore(&cde_read_write_lock, irq_flags);
+	  return -EAGAIN;
+  }
+  cde_write_completed = CDE_WRITE_PENDING;
+  spin_unlock_irqrestore(&cde_read_write_lock, irq_flags);
+  
+  if (copy_from_user(cmp_data->src, buf, count)) {
+	  spin_lock_irqsave(&cde_read_write_lock, irq_flags);
+	  cde_write_completed = CDE_READ_DONE;
+	  spin_unlock_irqrestore(&cde_read_write_lock, irq_flags);
+	  return -EFAULT;
+  }
+
+  cmp_data->src_size = count;
+
+  num_messages = create_message(cmp_data, 1, 1, 0);
+
+  // send message
+  for (i = 0; i < num_messages; i++) {
+
+    int status = send_message(MSGRNG_STNID_CMP_1, (struct msgrng_msg *) (cmp_msg + i));
+
+    if (status != 0) {
+	    printk("Cmp Message didnt not reach cmp, status=%0d\n", status);
+	    spin_lock_irqsave(&cde_read_write_lock, irq_flags);
+	    cde_write_completed = CDE_READ_DONE;
+	    spin_unlock_irqrestore(&cde_read_write_lock, irq_flags);
+    }
+
+  }
+
+  return count;
+}
+
+
+int cde_ioctl(struct inode *inode, struct file *filp,
+	      unsigned int cmd, unsigned long arg)
+{
+  int err = 0;
+  /*
+    if (_IOC_TYPE(cmd) != CDE_IOC_MAGIC)
+    return -ENOTTY;
+
+    if (_IOC_NR(cmd) > CDE_IOC_MAXNR)
+    return -ENOTTY;
+
+    if (_IOC_DIR(cmd) & _IOC_READ)
+    err = !access_ok(VERIFY_WRITE, (void __user *)arg, _IOC_SIZE(cmd));
+
+    else if (_IOC_DIR(cmd) & _IOC_WRITE)
+    err =  !access_ok(VERIFY_READ, (void __user *)arg, _IOC_SIZE(cmd));
+
+    if (err)
+    return -EFAULT;
+  */
+
+  switch(cmd) {
+
+  case CDE_INFLATE:
+    cmp_data->op = CDE_INFLATE;
+    break;
+
+  case CDE_DEFLATE:
+    cmp_data->op = CDE_DEFLATE;
+    break;
+
+  default:
+    return -ENOTTY;
+  }
+
+  return err;
+}
+
+long  cde_compat_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+  unsigned long ret = -1;
+  lock_kernel();
+  ret = cde_ioctl(NULL, filp, cmd, arg);
+  unlock_kernel();
+  if(ret){
+     printk("%s: ioctl error\n", __FUNCTION__);
+     return -EINVAL;
+  }
+  return ret;
+}
+
+struct file_operations cde_fops = {
+  .owner =    THIS_MODULE,
+  .read =     cde_read,
+  .write =    cde_write,
+  .ioctl =    cde_ioctl,
+  .compat_ioctl = cde_compat_ioctl,
+  .open =     cde_open,
+  .release =  cde_release,
+};
+
+
+void cde_cleanup_module(void)
+{
+  dev_t devno = MKDEV(cde_major, cde_minor);
+  
+  if (cde_device) {
+    cdev_del(&(cde_device->cdev));
+    kfree(cde_device);
+  }
+
+  /* cleanup_module is never called if registering failed */
+  unregister_chrdev_region(devno, cde_nr_devs);
+}
+
+
+static int cde_setup_cdev(struct cde_dev *dev)
+{
+  int err, devno = MKDEV(cde_major, cde_minor);
+
+  cdev_init(&dev->cdev, &cde_fops);
+  dev->cdev.owner = THIS_MODULE;
+  dev->cdev.ops = &cde_fops;
+  err = cdev_add(&dev->cdev, devno, 1);
+
+  if (err)
+    printk(KERN_NOTICE "Error %d adding cde", err);
+
+  return err;
+}
+
+
+#ifdef CONFIG_RMI_MSGRING_NAPI
+extern int rmi_on_chip_napi;
+extern int rmi_msgring_napi;
+#endif /* CONFIG_RMI_MSGRING_NAPI */
+
+
+int cde_init_module(void)
+{
+  int ret;
+  dev_t dev = 0;
+
+  if (!is_xls_b0())
+    return 0;
+  cde_write_completed = CDE_READ_DONE;
+  spin_lock_init(&cde_open_lock);
+  spin_lock_init(&cde_read_write_lock);
+
+  if (dev_tree_en && fdt_get_cde_enabled() == 0) {
+    printk("Compression Engine disabled in configuration, skipping...\n");
+    return -ENODEV;
+  }
+
+#ifdef CONFIG_RMI_MSGRING_NAPI
+  if (rmi_msgring_napi && !rmi_on_chip_napi) {
+	  printk(KERN_ALERT "%s: RMI Compression Driver: Incompatibility with GMAC"
+		 " NAPI mode\n", __FUNCTION__);
+	  printk(KERN_ALERT "%s: RMI Compression Driver: Aborting init sequence.\n", 
+		 __FUNCTION__);
+	  return -EINVAL;
+  }
+#endif /* CONFIG_RMI_MSGRING_NAPI */
+
+  if (cde_major) {
+    dev = MKDEV(cde_major, cde_minor);
+    ret = register_chrdev_region(dev, cde_nr_devs, "xls_cde");
+  }
+  else {
+    ret = alloc_chrdev_region(&dev, cde_minor, cde_nr_devs, "xls_cde");
+    cde_major = MAJOR(dev);
+  }
+
+  if (ret < 0) {
+    printk(KERN_WARNING "xls_cde: can't get major %d\n", cde_major);
+    return ret;
+  }
+
+  /*
+   * allocate the devices or static variable?
+   */
+  cde_device = kmalloc(sizeof(struct cde_dev), GFP_KERNEL);
+  if (!cde_device) {
+    printk(KERN_WARNING "xls_cde: can't allocate memory\n");
+    ret = -ENOMEM;
+    goto fail;
+  }
+
+  memset(cde_device, 0, sizeof(struct cde_dev));
+
+  ret = cde_setup_cdev(cde_device);
+  if (ret)
+    goto fail;
+  ret = register_msgring_handler(TX_STN_CMP, phnx_msgring_comp_int_handler, NULL);
+  if (ret) {
+    printk("[%s@%d]: unable to register handler for msgring stations for Compression Station\n",
+	   __FILE__, __LINE__);
+    goto fail;
+  }
+
+  return 0;
+
+ fail:
+  cde_cleanup_module();
+  return ret;
+}
+
+module_init(cde_init_module);
+module_exit(cde_cleanup_module);
diff --git a/drivers/char/phnx_loader.c b/drivers/char/phnx_loader.c
new file mode 100644
index 0000000..7dc000c
--- /dev/null
+++ b/drivers/char/phnx_loader.c
@@ -0,0 +1,629 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/spinlock.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/poll.h>
+#include <asm/uaccess.h>
+#include <asm/rmi/devices.h>
+#include <asm/rmi/phnx_loader.h>
+#include <user/rmi/phnx_loader.h>
+#include <asm/rmi/pic.h>
+#include <asm/io.h>
+#include <asm/system.h>
+#include <linux/rwsem.h>
+#define dbg_msg(fmt, args...) //printk(fmt,##args)
+
+#define Message(fmt, args...) //printk("\n[%s]-[%d] "fmt"\n",__FUNCTION__,__LINE__,##args)
+
+extern int xlr_lib_launch_userapp(int cpu);
+extern void wakeup_cpu(unsigned int cpu, unsigned long fn, unsigned long args);
+extern void xlr_send_stop_ipi(unsigned long mask);
+extern volatile unsigned int xlr_lib_shmem_size;
+static int phnx_loader_major;
+static spinlock_t phnx_loader_lock;
+static int phnx_loader_user = 0;
+static int phnx_map_sh_mem=0;
+static int phnx_map_persistent_mem = 0;
+static int phnx_map_load_addr = 0;
+static int phnx_map_app_shmem=0;
+unsigned char *xlr_persistent_data_start=NULL;
+unsigned char *xlr_persistent_data_start_orig=NULL;
+static uint64_t xlr_app_shmem_start = 0x0;
+
+unsigned int xlr_persistent_data_size=0;
+/* Size of the shared memory b/w Linux userapp and rmios apps */
+extern uint32_t phnx_app_sh_mem_sz;
+extern unsigned long  phnx_app_shmem_start;
+
+extern uint64_t phnx_loader_kuseg_size, phnx_loader_kuseg_start;
+extern uint32_t phnx_loader_kseg_size, phnx_loader_kseg_start;
+extern int xlr_loader_support;
+extern uint32_t phnx_loader_mask;
+extern void phnx_start_loader_threads(void);
+extern void prom_check_image(void);
+unsigned char load_env[32][6];
+extern unsigned char *xlr_lib_shmem_start;
+
+struct wakeup_info
+{
+	int vcpu;
+    unsigned long long func;
+    unsigned long long data;
+};
+
+struct xlr_load_addr
+{
+	uint64_t phys;
+	uint64_t size;
+	uint32_t flag;
+}xlr_image_load_addr;
+
+
+struct loader_send_ipi
+{
+	uint32_t mask;
+	uint32_t ipi;
+};
+
+struct xlr_lib_shared_mem
+{
+	uint64_t entries;
+	uint64_t tot_size;
+	uint64_t addr[32];
+	uint64_t size[32];
+};
+static struct xlr_lib_shared_mem app_shared_mem;
+
+static int phnx_loader_open (struct inode *inode, struct file *filp)
+{
+	uint32_t minor=0;
+	if(xlr_loader_support == 0) 
+		return -EPERM;
+
+	minor = MINOR(inode->i_rdev);	
+	if(minor == XLR_MAP_SLAVE_DEVICE){
+		filp->private_data = (void *)inode;
+		return 0;
+	}
+
+	/* ALLOW ONLY ONE OPEN at a time */
+	spin_lock(&phnx_loader_lock);
+	if(phnx_loader_user == 1){
+		spin_unlock(&phnx_loader_lock);
+		return -EAGAIN;
+	}
+	filp->private_data = (void *)inode;
+	phnx_loader_user = 1;
+	phnx_map_load_addr = 0;
+	phnx_map_persistent_mem = 0;
+	phnx_map_sh_mem = 0;
+	phnx_map_app_shmem = 0;
+
+	spin_unlock(&phnx_loader_lock);
+
+
+	return 0;
+}
+
+void phnx_loader_send_ipi(struct loader_send_ipi *data)
+{
+	uint32_t i;
+
+	for(i=0; i<32; i++){
+		if((data->mask) & (1<<i)){
+#if defined(CONFIG_RMI_XLP)
+			pic_send_ipi(0, data->ipi, 0, i);
+#else
+			uint32_t pid, tid;
+			uint32_t val;
+			phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+
+			pid = i >> 2;
+			tid = i % 4;
+			val = (pid << 20) | (tid << 16) | data->ipi;
+			phoenix_write_reg(mmio, PIC_IPI, val);
+#endif /* #if defined(CONFIG_RMI_XLP) */
+		}
+	}
+}
+
+int phnx_loader_ioctl (struct inode *inode, struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	unsigned int *addr = (unsigned int*)arg;
+	struct loader_send_ipi data;
+	switch (cmd) {
+
+		/*size of the data structures shared memory - this includes
+		 all xlr_vcpu_wakeup_info and other lib data structure.*/
+		case PHNX_LOADER_IOC_SHMEM_SIZE: 
+		{
+			Message(" available shared mem [%#x]",xlr_lib_shmem_size);
+			if(put_user(xlr_lib_shmem_size, addr)){
+				panic("\nput user failed for ioc shmem size\n");
+			}
+		}
+		break;
+
+		/*Next mmap should be for global data structure - 
+		 wakeup_info and other structures*/
+		case PHNX_LOADER_IOC_MMAP_SHMEM:
+		{
+			phnx_map_sh_mem = 1;
+			phnx_map_persistent_mem = 0;
+			phnx_map_load_addr = 0;
+			phnx_map_app_shmem = 0;
+		}
+		break;
+
+		/*Do an mmap of the passed physical address and size*/
+		case PHNX_LOADER_IOC_MMAP_LOAD_ADDR:
+		{
+			if(copy_from_user((void *)&xlr_image_load_addr,
+								(const void __user *)addr,
+								sizeof(struct xlr_load_addr)))
+					panic("\nmmap load addr - copy frm user - failed\n");
+			phnx_map_load_addr = 1;
+			phnx_map_persistent_mem = 0;
+			phnx_map_sh_mem = 0;
+			phnx_map_app_shmem = 0;
+		}
+		break;
+
+		/*Wakeup cpu*/
+		case PHNX_LOADER_IOC_START_IPI: 
+		{
+			struct wakeup_info tmp;
+			if(copy_from_user((void *)&tmp, (const void __user *)addr,
+								sizeof(struct wakeup_info)))
+				panic("copy from user failed for START IPI\n");
+			wakeup_cpu(tmp.vcpu, (unsigned long)tmp.func, 
+									(unsigned long)tmp.data);
+		}
+		break;
+
+		/*Stop cpu*/
+		case PHNX_LOADER_IOC_STOP_IPI:
+		{
+			uint32_t vcpu=0;
+			if(get_user(vcpu, (uint32_t *)addr))
+				panic("\nGetUser Failed for stop ipi\n");	
+			/*Below Func Is Library Call.*/
+			xlr_send_stop_ipi(vcpu);
+		}
+		break;
+
+		/*Send ipi to the cpu*/
+		case PHNX_LOADER_SEND_IPI:
+		{
+			if(copy_from_user((void *)&data , (const void __user *)arg, 
+							sizeof(data))){
+					panic("\ncopy_from_user failed for send_ipi\n");
+			}
+			phnx_loader_send_ipi(&data);
+		}
+		break;
+
+		/*Check if pereistent memory is present*/
+		case PHNX_LOADER_IOC_LIB_BKP:
+		{
+			if(xlr_persistent_data_start_orig){
+				if(put_user(1, addr)){
+					panic("\nput_user failed for lib_bkp\n");
+				}
+			}
+			else{
+				if(put_user(0, addr))
+					panic("\nput_user failed for lib_bkp\n");
+			}
+		}
+		break;
+
+		/*Store shared memory info*/
+		case PHNX_LOADER_IOC_STORE_APP_SHMEM_INFO:
+		{
+			if(copy_from_user((void *)&app_shared_mem, (const void __user *)arg, 
+							sizeof(app_shared_mem))){
+				panic("copy from User failed for app shared mem info\n");
+			}
+			/*
+			int i=0;
+			for(i=0; i<app_shared_mem.entries; i++){
+				printk("\nStoring Physical Addr %#llx, Size %#llx\n",
+						(unsigned long long)app_shared_mem.addr[i], 
+						(unsigned long long)app_shared_mem.size[i]);
+			}
+			*/
+		}
+		break;
+
+		/*Retrive shared memory info*/
+		case PHNX_LOADER_IOC_GET_APP_SHMEM_INFO:
+		{
+			/*
+			int i=0;
+			for(i=0; i<app_shared_mem.entries; i++){
+				printk("\nRetrive Physical Addr %#llx, Size %#llx\n",
+						(unsigned long long)app_shared_mem.addr[i], 
+						(unsigned long long)app_shared_mem.size[i]);
+			}*/
+
+			if(copy_to_user((void __user *)arg, (const void *)&app_shared_mem,
+							sizeof(app_shared_mem))){
+				panic("\ncopy_to_user failed for app shared mem info\n");
+			}			
+		}
+		break;
+
+#if 0
+		/*Check if app shared memory is already reserved*/
+		case PHNX_LOADER_IOC_APP_SHMEM_RESERVE:
+		{
+			if(xlr_app_shmem_start){
+				if(put_user(1, addr)){
+					panic("\nput_user failed for lib_bkp\n");
+				}
+			}
+			else{
+				if(put_user(0, addr)){
+					panic("\nput_user failed for lib_bkp\n");
+				}
+			}	
+		}
+		break;
+		
+		/*Get the app shared memory physical address start from user space*/
+		case PHNX_LOADER_IOC_APP_SHMEM_PHYS:
+		{
+				if(get_user(xlr_app_shmem_start, (uint64_t *)addr)){
+					panic("\nput_user failed for lib_bkp\n");
+				}
+		}
+		break;
+
+		/*Get the app shared memory size*/
+		case PHNX_LOADER_IOC_APP_SHMEM_SIZE:
+		{
+			if(put_user(phnx_app_sh_mem_sz, addr)){
+				panic("\nput user failed for ioc shmem size\n");
+			}
+		}
+		break;
+
+		/*mmap app shared memory in next mmap call*/
+		case PHNX_LOADER_IOC_MMAP_APP_SHMEM:
+		{
+			phnx_map_app_shmem = 1;
+			phnx_map_persistent_mem = 0;
+			phnx_map_sh_mem = 0;
+			phnx_map_load_addr = 0;
+		}
+		break;
+#endif	
+
+		/*Get the kseg0 base of the data structure's shared memory
+		  used bye mmap_to_kseg/kseg_to_mmap*/
+		case PHNX_LOADER_IOC_SHMEM_KSEG_ADDR:
+		{
+			if (put_user((long long)(int)(long)xlr_lib_shmem_start, (uint64_t *)addr)){
+				panic("\nput user failed for ioc shmem kseg addr\n");
+			}
+		}
+		break;
+		
+		
+		/*Free persistent memory*/
+		case PHNX_LOADER_IOC_FREE_PERSISTENT_MEM:
+		{
+			unsigned long addr=0;
+			if(!xlr_persistent_data_start_orig){
+				printk("\nData Is Not Allocated.\n");
+				return -EINVAL;
+			}
+			addr = (unsigned long)xlr_persistent_data_start;
+			while(addr < (unsigned long)
+						(xlr_persistent_data_start+xlr_persistent_data_size)){
+                ClearPageReserved(virt_to_page((void *)addr));
+                addr += PAGE_SIZE;	
+			}
+			kfree(xlr_persistent_data_start_orig);
+			xlr_persistent_data_start_orig = xlr_persistent_data_start = NULL;
+		}
+		break;
+
+		/*Alloc persistent memory*/
+		case PHNX_LOADER_IOC_ALLOC_PERSISTENT_MEM:
+		{
+			unsigned long tmp_addr=0;
+			if(get_user(xlr_persistent_data_size,(unsigned int *)addr)){
+				panic("\nGetUser Failed for alloc persistent mem\n");	
+			}
+			if(!xlr_persistent_data_size){
+				printk("\nInvalid Len %#x\n", xlr_persistent_data_size);
+				return -EINVAL;
+			}
+			xlr_persistent_data_start_orig = 
+				kmalloc(xlr_persistent_data_size+PAGE_SIZE, GFP_KERNEL|GFP_DMA);
+			if(!xlr_persistent_data_start_orig)
+				return -ENOMEM;
+			xlr_persistent_data_start = (unsigned char *)
+						(((unsigned long)(xlr_persistent_data_start_orig + 
+											PAGE_SIZE)) & ~(PAGE_SIZE-1));
+			tmp_addr = (unsigned long)xlr_persistent_data_start;
+			while(tmp_addr < (unsigned long)
+						(xlr_persistent_data_start+xlr_persistent_data_size)){
+                SetPageReserved(virt_to_page((void *)tmp_addr));
+                tmp_addr += PAGE_SIZE;	
+			}
+		}
+		break;
+
+		/*mmap persistent memory in next mmap call.*/
+		case PHNX_LOADER_IOC_MMAP_PERSISTENT_MEM:
+		{
+			phnx_map_persistent_mem = 1;
+			phnx_map_sh_mem = 0;
+			phnx_map_load_addr = 0;
+			phnx_map_app_shmem = 0;
+		}
+		break;
+
+		/*call lib_launch.c's launch_userapp for kseg app*/
+		case PHNX_LOADER_IOC_LAUNCH_KSEG:
+		{
+				uint32_t vcpu=0;
+				if(get_user(vcpu, (uint32_t *)addr))
+						panic("\nGetUser Failed for launch kseg\n");
+				/*Below Func Is Library Call.*/
+				xlr_lib_launch_userapp(vcpu);
+		}
+		break;
+
+		/*store UART info*/
+		case PHNX_LOADER_STORE_ENV:
+		{
+				int i;
+				unsigned char temp[32][6];
+				copy_from_user ((void *)&temp , (const void __user *)addr, sizeof(temp));
+
+				for (i=0; i<32; i++)    {
+						if (strcmp(temp[i],"") != 0)
+								strcpy(load_env[i],temp[i]);
+				}
+		}
+		break;
+		default:
+		{
+			printk("ioctl(): invalid command=0x%x\n", cmd);
+			return -EINVAL;
+		}
+	}
+	return 0;
+}
+
+static long phnx_loader_compat_ioctl(struct file *filp, unsigned int cmd, 
+		unsigned long arg)
+{
+	unsigned long ret = -1;
+	Message("");
+	lock_kernel();	
+	Message("Got the user space address [%#lx]",arg);
+	ret = phnx_loader_ioctl(NULL,filp,cmd,(uint32_t)arg);
+	unlock_kernel();
+	if(ret){
+		printk("phnx_loader_ioctl returned with an error.");
+		return -ENOIOCTLCMD;
+	}
+	return ret;
+}
+
+static int phnx_loader_mmap_app_shared_mem(struct file *file,
+		struct vm_area_struct *vma)
+{
+	struct xlr_lib_shared_mem *shmem = &app_shared_mem;
+	unsigned long offset = vma->vm_pgoff << PAGE_SHIFT;
+	unsigned long vaddr = 0;
+	int i=0;
+	int result = 0;
+	unsigned long mmap_size = 0;
+	unsigned long size = 0;
+
+	for(i=0; i<shmem->entries; i++){
+		if(shmem->addr[i] & (PAGE_SIZE-1)){
+			printk("\nMmaping to invalid address ... %#llx\n",
+						(unsigned long long)shmem->addr[i]);
+			return -EINVAL;
+		}
+	}
+
+	if (vma->vm_flags & VM_LOCKED) return -EPERM;
+
+	if (offset >= shmem->tot_size) return -ESPIPE;
+	
+	pgprot_val (vma->vm_page_prot) &= ~_CACHE_MASK;
+	pgprot_val (vma->vm_page_prot) |= _CACHE_CACHABLE_COW;
+
+	vaddr = vma->vm_start;
+	size = vma->vm_end - vma->vm_start;
+
+	for(i=0; i<shmem->entries && size; i++){
+	/*	printk("\nMapping vaddr = %#lx, Physical Addr %#llx, Size %#llx\n",
+						(unsigned long)vaddr, 
+						(unsigned long long)shmem->addr[i], 
+						(unsigned long long)shmem->size[i]);
+	*/
+		mmap_size = (shmem->size[i] > size) ? size : shmem->size[i];
+		result = remap_pfn_range(vma, vaddr, (shmem->addr[i])>>PAGE_SHIFT, 
+					mmap_size, vma->vm_page_prot);
+		if (result) return -EAGAIN;
+		vaddr += shmem->size[i];
+		size -= mmap_size;
+	}
+	return 0;
+}
+
+static int phnx_loader_map_helper(struct file *file, struct vm_area_struct *vma)
+{
+	unsigned long offset = vma->vm_pgoff << PAGE_SHIFT;
+	uint64_t shm_addr;
+	unsigned long shm_size;
+	unsigned long size = 0;
+	int result = 0;
+	unsigned long shm_pfn_addr = 0;
+	struct inode *i;
+	uint32_t minor;
+	i = (struct inode *)file->private_data;
+	minor = MINOR(i->i_rdev);	
+	if(minor == XLR_MAP_SLAVE_DEVICE){
+		return phnx_loader_mmap_app_shared_mem(file, vma);
+	}else if(phnx_map_sh_mem){
+		shm_addr = (uint64_t)(49<<20);
+		shm_size = xlr_lib_shmem_size; 
+		shm_pfn_addr = ((uint64_t)shm_addr >> PAGE_SHIFT);
+	}else if(phnx_map_persistent_mem){
+		shm_addr = (uint64_t)virt_to_phys(xlr_persistent_data_start);
+		shm_size = xlr_persistent_data_size;
+		shm_pfn_addr = ((uint64_t)shm_addr >> PAGE_SHIFT);
+	}else if(phnx_map_load_addr){
+		shm_addr = xlr_image_load_addr.phys;
+		shm_size = (unsigned long)xlr_image_load_addr.size;
+		shm_pfn_addr = ((uint64_t)shm_addr >> PAGE_SHIFT);
+	}else if(phnx_map_app_shmem){
+		shm_addr = xlr_app_shmem_start;
+		shm_size = phnx_app_sh_mem_sz;
+		shm_pfn_addr = (unsigned long)((uint64_t)shm_addr >> PAGE_SHIFT);
+	}else{
+		printk("\nInvalid mmap command.\n");
+		return -EINVAL;
+	}
+	dbg_msg("[%s]: shm_addr=%lx, shm_size=%lx, offset = %lx, vm_start=%lx, vm_size=%lx, vm_flags=%lx, vm_page_prot=%lx\n", __FUNCTION__, shm_addr, shm_size, offset, vma->vm_start, vm_size, vma->vm_flags, pgprot_val(vma->vm_page_prot));
+	if (!shm_addr) return -ENXIO;
+
+	if(shm_addr & (PAGE_SIZE-1)){
+		printk("\nMmaping to invalid address ... %#llx\n",
+						(unsigned long long)shm_addr);
+		return -EINVAL;
+	}
+	if (offset >= shm_size) return -ESPIPE;
+
+	if (vma->vm_flags & VM_LOCKED) return -EPERM;
+
+	size = vma->vm_end - vma->vm_start;
+	pgprot_val (vma->vm_page_prot) &= ~_CACHE_MASK;
+	if(phnx_map_load_addr && (xlr_image_load_addr.flag == XLR_MAP_UNCACHED)){
+		pgprot_val (vma->vm_page_prot) |= _CACHE_UNCACHED;
+	}else{
+		pgprot_val (vma->vm_page_prot) |= _CACHE_CACHABLE_COW;
+	}
+	result = remap_pfn_range(vma, vma->vm_start, shm_pfn_addr, size, 
+								vma->vm_page_prot);
+	if (result) return -EAGAIN;
+
+	return 0;
+}
+
+static int phnx_loader_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	int res;
+	
+	res = phnx_loader_map_helper(file, vma);
+	phnx_map_app_shmem = 0;
+	phnx_map_sh_mem = 0;
+	phnx_map_persistent_mem = 0;
+	phnx_map_load_addr = 0;
+	return res;
+}
+
+static int phnx_loader_release (struct inode *inode, struct file *filp)
+{
+	return 0;
+}
+
+static int phnx_loader_flush(struct file *fp, fl_owner_t id)
+{
+	uint32_t minor=0;
+	struct inode *inode = (struct inode *)(fp->private_data);
+	minor = MINOR(inode->i_rdev);
+	if(minor == XLR_MAP_SLAVE_DEVICE){
+		return 0;
+	}
+	spin_lock(&phnx_loader_lock);
+	phnx_loader_user = 0;
+	spin_unlock(&phnx_loader_lock);
+	return 0;
+
+}
+
+struct file_operations phnx_loader_fops = {
+	.mmap     = phnx_loader_mmap,
+	.open	  = phnx_loader_open,
+	.ioctl    = phnx_loader_ioctl,
+	.release  = phnx_loader_release,
+	.flush = phnx_loader_flush,
+	.compat_ioctl = phnx_loader_compat_ioctl,
+};
+
+static int phnx_loader_init(void)	
+{
+	if(xlr_loader_support == 0)
+		return -EINVAL;
+
+	spin_lock_init(&phnx_loader_lock);
+
+	phnx_loader_major = register_chrdev (XLR_APP_LOADER_MAJOR, 
+					     PHNX_APP_LOADER_CHRDEV_NAME, &phnx_loader_fops);
+
+	if (phnx_loader_major < 0) {
+		printk("[%s]: register_chrdev failed\n", __FUNCTION__);
+		return phnx_loader_major;
+	}
+
+	/* Launch the threads now */
+	phnx_start_loader_threads();
+
+	printk("Registered phoenix app loader driver: phnx_loader_major=%d\n", XLR_APP_LOADER_MAJOR);
+
+	return 0;
+}
+
+static void phnx_loader_exit(void)
+{
+	/*TODO: Clean up*/
+    unregister_chrdev (phnx_loader_major, PHNX_APP_LOADER_CHRDEV_NAME);
+}
+
+module_init (phnx_loader_init);
+module_exit (phnx_loader_exit);
+
diff --git a/drivers/char/phnx_msgring.c b/drivers/char/phnx_msgring.c
new file mode 100644
index 0000000..704ef3c
--- /dev/null
+++ b/drivers/char/phnx_msgring.c
@@ -0,0 +1,742 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/poll.h>
+#include <linux/module.h>
+
+#include <asm/uaccess.h>
+#include <asm/mman.h>
+
+#include <asm/rmi/pic.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/devices.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/linux_crf.h>
+
+#include <user/rmi/phnx_msgring.h>
+
+#define MAX_MSG_FIFOS 12
+#define MSG_FIFO_SIZE 1024
+#define MSG_FIFO_MASK (MSG_FIFO_SIZE-1)
+
+enum LEVEL {
+	LOG_EMERG = 0,
+		LOG_ALERT,
+		LOG_CRIT,
+		LOG_ERR,
+		LOG_WARNING,
+		LOG_NOTICE,
+		LOG_INFO,
+		LOG_DEBUG
+};
+
+#define PRINTK_ERR(FMT, ...) \
+do { \
+    if(msgring_debug_level >= LOG_ERR) { \
+        printk(KERN_ERR FMT, ## __VA_ARGS__); \
+    } \
+} while(0)
+
+#define PRINTK_INFO(FMT, ...) \
+do { \
+    if(msgring_debug_level >= LOG_INFO) { \
+        printk(KERN_INFO FMT, ## __VA_ARGS__); \
+    } \
+} while(0)
+
+typedef enum syscall_id_s {
+	SYSCALL_exec,
+	SYSCALL_socketcall,
+	SYSCALL_open,
+	SYSCALL_write,
+	SYSCALL_read,
+	SYSCALL_close,
+	SYSCALL_ioctl,
+	SYSCALL_select,
+	SYSCALL_exit,
+	SYSCALL_interrupt,
+	SYSCALL_max
+} SYSCALL_ID;
+
+typedef struct syscall {
+	wait_queue_head_t sleep;
+	int done;
+	void *process;
+	int pid;
+	SYSCALL_ID id;
+	int err;
+	int _errno;
+	int num;
+	int src_id;
+	void *trace;
+	union {
+		struct {
+			int call;
+		} socketcall;
+	} u;
+} SYSCALL;
+
+extern char *saved_command_line;
+static char *hybrid = 0;
+extern int msgring_debug_level;
+
+extern void *phoenix_psb_shm;
+extern unsigned long phoenix_psb_shm_size;
+
+static int    msgring_major;
+
+extern int xlr_loader_support;
+extern int xlr_loader_sharedcore;
+
+struct fifo {
+	struct msgring_msg_data *data;
+	int       size;
+	int       head;
+	int       tail;
+	spinlock_t lock;
+	wait_queue_head_t wq;
+};
+
+static void fifo_init (struct fifo *fifo, int fifo_size)
+{
+	void *ptr = kmalloc(fifo_size * sizeof(struct msgring_msg_data), GFP_KERNEL);
+
+	if (!ptr) panic("[%s]: Unable to allocate memory for Tx Fifos\n", __FUNCTION__);
+
+	fifo->data = ptr;
+	fifo->head = fifo->tail = 0;
+	fifo->size = fifo_size;
+	spin_lock_init(&fifo->lock);
+}
+
+/* TODO: Change all modulos to boolean arithmetic */
+__inline__ int fifo_next_index(volatile struct fifo *fifo, int index)
+{
+	return (index+1) & MSG_FIFO_MASK;
+}
+
+__inline__ int  fifo_next_head(volatile struct fifo *fifo)
+{ return (fifo->head+1) & MSG_FIFO_MASK ; }
+
+__inline__ int  fifo_next_tail(volatile struct fifo *fifo)
+{ return (fifo->tail+1) & MSG_FIFO_MASK ; }
+
+__inline__ int  fifo_empty(volatile struct fifo *fifo)
+{ return (fifo->head == fifo->tail); }
+
+static __inline__ int  fifo_full(volatile struct fifo *fifo)
+{ return (fifo_next_tail(fifo) == fifo->head); }
+
+static __inline__ int  fifo_count(volatile struct fifo *fifo)
+{
+	if (fifo->head <= fifo->tail)
+		return fifo->tail - fifo->head;
+	else
+		return (fifo->size - fifo->head) + fifo->tail;
+}
+static __inline__ int fifo_dequeue(volatile struct fifo *fifo,
+				   struct msgring_msg_data *data)
+{
+	if (fifo_empty(fifo))
+		return 0;
+
+	*data = fifo->data[fifo->head];
+	fifo->head = fifo_next_head(fifo);
+
+	return 1;
+}
+static __inline__ int fifo_enqueue(volatile struct fifo *fifo,
+				   struct msgring_msg_data *data)
+{
+	int cnt = 0;
+	while (fifo_full(fifo)) {
+		++cnt;
+	}
+	if(cnt > 10000) {
+		PRINTK_ERR("%s:%d fifo queue full cnt=%d.\n", __FUNCTION__, __LINE__,
+			   cnt);
+	}
+
+	fifo->data[fifo->tail] = *data;
+	fifo->tail = fifo_next_tail(fifo);
+
+	return 1;
+}
+
+#define PRINT_RMI_FIFO_DATA(p) \
+do { \
+	PRINTK_INFO("%s:%d fifo=%p fifo size=%d head=%d tail=%d.\n", __FUNCTION__, \
+		    __LINE__, p, p->size, p->head, p->tail); \
+} while(0)
+
+static struct fifo msg_fifos[MAX_MSG_FIFOS];
+
+#ifdef CONFIG_PHOENIX_MAC
+extern void rmi_phnx_rmios_msgring_handler(int bucket, int size, int code, int stid,
+					   struct msgrng_msg *msg, void *data/* ignored */);
+#else /* CONFIG_PHOENIX_MAC */
+void rmi_phnx_rmios_msgring_handler(int bucket, int size, int code,
+                                    int stid, struct msgrng_msg *msg,
+                                    void *data /* ignored */ ) { }
+#endif /* CONFIG_PHOENIX_MAC */
+extern void rmi_phnx_mac_msgring_handler(int bucket, int size, int code, int stid,
+                                           struct msgrng_msg *msg, void *data/* ignored */);
+static void rmi_phnx_syscall_msgring_handler(int bucket, int size, int code, int stid,
+                                           struct msgrng_msg *msg, void *data/* ignored */);
+
+
+
+void phnx_msgring_drv_int_handler(int bucket, int size, int code, int stid,
+				  struct msgrng_msg *msg, void *data/* ignored */)
+{
+	volatile struct fifo *msg_fifo = 0;
+	struct msgring_msg_data msg_data;
+	int ret = 0;
+	int tx_stid = MAX_MSG_FIFOS;
+
+
+	if (stid < MSGRING_STNID_DEVICES) {
+
+		if(rmik_en)
+			return rmik_cpu_to_cpu_msgring_handler(bucket, size, code, stid, msg, data);
+
+		if (((code&0xf) == 0xf) && hybrid) {
+			// forward to linux driver
+			rmi_phnx_rmios_msgring_handler(bucket, size, code, stid, msg, data);
+			return;
+		}
+		if (((code&0xf) == 0xe) && hybrid) {
+			rmi_phnx_syscall_msgring_handler(bucket, size, code, stid, msg, data);
+			return;
+		}
+		tx_stid = stid >> 3;
+	}
+	else {
+		if (stid == 96 || (is_xls() && stid == 80)) {
+			tx_stid = 8 + (msg->msg1 & 0x0f);
+		}
+		else {
+			printk("[%s]: illegal tx_stid = %d, stid=%d\n", __FUNCTION__, tx_stid, stid);
+			return;
+		}
+	}
+
+	//printk("[%s:%d]: \n", __FUNCTION__, __LINE__);
+
+	if (hybrid)
+		tx_stid = (msg->msg0 & 0xffffffff);
+
+	msg_fifo = &msg_fifos[tx_stid];
+
+	msg_data.size = size;
+	msg_data.code = code;
+	msg_data.rx_bucket = bucket;
+	msg_data.stid = stid;
+	msg_data.msgs[0] = (msg->msg0 & 0xffffffff);
+	msg_data.msgs[1] = (msg->msg0 >> 32);
+	msg_data.msgs[2] = (msg->msg1 & 0xffffffff);
+	msg_data.msgs[3] = (msg->msg1 >> 32);
+	msg_data.msgs[4] = (msg->msg2 & 0xffffffff);
+	msg_data.msgs[5] = (msg->msg2 >> 32);
+	msg_data.msgs[6] = (msg->msg3 & 0xffffffff);
+	msg_data.msgs[7] = (msg->msg3 >> 32);
+
+	PRINTK_INFO("%s:%d adding message to txid=%d fifo:%p\n", __FUNCTION__, __LINE__,
+		    tx_stid, msg_fifo);
+	spin_lock((spinlock_t *)(&msg_fifo->lock));
+	ret = fifo_enqueue(msg_fifo, &msg_data);
+	spin_unlock((spinlock_t *)(&msg_fifo->lock));
+
+	/* wake up any readers */
+	wake_up_interruptible((wait_queue_head_t *)&msg_fifo->wq);
+
+	if (!ret) {
+		PRINTK_ERR("[%s]: Unable to queue message from %d tx_stid (stid=%d)\n", __FUNCTION__, tx_stid, stid);
+	}
+
+}
+
+static int msgring_open (struct inode *inode, struct file *filp)
+{
+	//printk("msgring_open() invoked\n");
+
+	filp->private_data = NULL;
+
+	return 0;
+}
+
+static DECLARE_WAIT_QUEUE_HEAD(msgring_read_wait);
+static DECLARE_WAIT_QUEUE_HEAD(msgring_write_wait);
+
+static unsigned int msgring_poll(struct file *filp, struct poll_table_struct *wait)
+{
+	unsigned int mask;
+	volatile struct fifo *msg_fifo = NULL;
+	int count = 0;
+	unsigned long flags;
+
+	if (!filp->private_data) return -EINVAL;
+
+	msg_fifo = filp->private_data;
+
+	mask = 0;
+
+	spin_lock_irqsave((spinlock_t *)&msg_fifo->lock, flags);
+	count = fifo_count(msg_fifo);
+	spin_unlock_irqrestore((spinlock_t *)&msg_fifo->lock, flags);
+
+	if(!count) {
+		poll_wait(filp, (wait_queue_head_t *)&msg_fifo->wq, wait);
+
+		spin_lock_irqsave((spinlock_t *)&msg_fifo->lock, flags);
+		count = fifo_count(msg_fifo);
+		spin_unlock_irqrestore((spinlock_t *)&msg_fifo->lock, flags);
+	}
+	/* if there is data in the read buffer */
+	if (count > 0) {
+		PRINT_RMI_FIFO_DATA(msg_fifo);
+		mask |= POLLIN | POLLRDNORM;
+	} else {
+		PRINT_RMI_FIFO_DATA(msg_fifo);
+		PRINTK_INFO("%s:%d count=%d\n", __FUNCTION__, __LINE__, count);
+	}
+
+	/* mark it writable always! */
+	mask |= POLLOUT | POLLWRNORM;
+
+	return mask;
+}
+
+static ssize_t msgring_read (struct file *filp, char __user *buf, size_t count, loff_t *offset)
+// offset: the offset in the file
+// count : no of bytes to read
+// buf   : start location (in user space) to which to copy the contents
+// filp  : pointer to 'struct file'  of the file
+{
+	volatile struct fifo *msg_fifo = NULL;
+	int msg_size = sizeof(struct msgring_msg_data);
+	struct msgring_msg_data msg;
+	int ret = 0;
+	unsigned long flags;
+
+	if (!filp->private_data) return -EINVAL;
+
+	if (count < msg_size) return -EINVAL;
+
+	msg_fifo = filp->private_data;
+
+	// we don't care about the passed file offset, but will update it
+	// with the no of bytes read
+ retry:
+	spin_lock_irqsave((spinlock_t *)&msg_fifo->lock, flags);
+	ret = fifo_dequeue(msg_fifo, &msg);
+	spin_unlock_irqrestore((spinlock_t *)&msg_fifo->lock, flags);
+
+	if (!ret) {
+		if (filp->f_flags & O_NONBLOCK) return -EAGAIN;
+		if (wait_event_interruptible((((struct fifo *)(msg_fifo))->wq), 
+					fifo_count(msg_fifo)))
+			return -ERESTARTSYS;
+		goto retry;
+	}
+
+	PRINTK_INFO("%s:%d reading message from fifo:%p\n", __FUNCTION__, __LINE__, msg_fifo);
+	if ( __copy_to_user(buf, &msg, count) )
+		return -EFAULT;
+
+	filp->f_pos += count;
+	return count;
+}
+
+static ssize_t msgring_write(struct file *filp, const char __user *buf, size_t count, loff_t *off)
+{
+	struct msgring_msg_data *umsg_data = NULL;
+	int msg_size = sizeof(struct msgring_msg_data);
+	struct msgrng_msg msg;
+	int size=0, code=0, stid=0;
+	unsigned long mflags = 0;
+	struct msgring_msg_data msg_data;
+
+	if (count < msg_size) return -EINVAL;
+
+	umsg_data = (struct msgring_msg_data *)buf;
+
+	__copy_from_user(&size, &umsg_data->size, 4);
+	__copy_from_user(&code, &umsg_data->code, 4);
+	__copy_from_user(&stid, &umsg_data->stid, 4);
+
+	__copy_from_user(&msg_data.msgs[0], &umsg_data->msgs[0], 4);
+	__copy_from_user(&msg_data.msgs[1], &umsg_data->msgs[1], 4);
+	__copy_from_user(&msg_data.msgs[2], &umsg_data->msgs[2], 4);
+	__copy_from_user(&msg_data.msgs[3], &umsg_data->msgs[3], 4);
+	__copy_from_user(&msg_data.msgs[4], &umsg_data->msgs[4], 4);
+	__copy_from_user(&msg_data.msgs[5], &umsg_data->msgs[5], 4);
+	__copy_from_user(&msg_data.msgs[6], &umsg_data->msgs[6], 4);
+	__copy_from_user(&msg_data.msgs[7], &umsg_data->msgs[7], 4);
+
+	msg.msg0 = ((__u64)msg_data.msgs[1] << 32) | ((__u64)msg_data.msgs[0]);
+	msg.msg1 = ((__u64)msg_data.msgs[3] << 32) | ((__u64)msg_data.msgs[2]);
+	msg.msg2 = ((__u64)msg_data.msgs[5] << 32) | ((__u64)msg_data.msgs[4]);
+	msg.msg3 = ((__u64)msg_data.msgs[7] << 32) | ((__u64)msg_data.msgs[6]);
+
+	__sync();
+
+	msgrng_flags_save(mflags);
+
+	if (message_send_retry(size, code, stid, &msg)) {
+		printk("Failed to send message!\n");
+		msgrng_flags_restore(mflags);
+		return -EAGAIN;
+	}
+
+	msgrng_flags_restore(mflags);
+
+
+	return msg_size;
+}
+
+static int msgring_mmap_syscall (struct file *file, struct vm_area_struct *vma)
+{
+        unsigned long addr = __pa(file->private_data);
+        unsigned long size = vma->vm_end - vma->vm_start;
+
+	if (vma->vm_flags & VM_LOCKED) return -EPERM;
+	vma->vm_flags |= (VM_RESERVED | VM_IO);
+	if (remap_pfn_range(vma, vma->vm_start, (addr >> PAGE_SHIFT), size, vma->vm_page_prot))
+		return -EAGAIN;
+	return 0;
+}
+
+static int msgring_mmap (struct file *file, struct vm_area_struct *vma)
+{
+	unsigned long offset = vma->vm_pgoff << PAGE_SHIFT;
+	unsigned long shm_addr = __pa(phoenix_psb_shm);
+	unsigned long shm_size = phoenix_psb_shm_size;
+	unsigned long size = 0;
+	unsigned long vm_size = vma->vm_end - vma->vm_start;
+
+	if (file->private_data != 0 &&
+           ((char *)file->private_data < (char *)&msg_fifos[0] ||
+            (char *)file->private_data > (char *)&msg_fifos[MAX_MSG_FIFOS]))
+		return msgring_mmap_syscall(file, vma);
+
+	if (vma->vm_start != (unsigned long)PHNX_USER_MAC_MMAP_VIRT_START)
+		return -EINVAL;
+
+	if (!shm_addr) return -ENXIO;
+
+	if (offset >= shm_size) return -ESPIPE;
+
+	if (vma->vm_flags & VM_LOCKED) return -EPERM;
+
+	size = shm_size - offset;
+	if (vm_size > size) return -ENOSPC;
+
+	vma->vm_flags |= (VM_RESERVED | VM_IO);
+
+	if (remap_pfn_range(vma, vma->vm_start, (shm_addr >> PAGE_SHIFT), size, vma->vm_page_prot))
+		return -EAGAIN;
+
+	return 0;
+}
+static DEFINE_PER_CPU(spinlock_t, msgring_lock) = SPIN_LOCK_UNLOCKED;
+static int cpu_spread[16];
+
+static int send_syscall (SYSCALL *syscall, int arg)
+{
+	struct msgrng_msg msg;
+	unsigned long mflags = 0;
+	int cpu, dst_stid, src_stid;
+	int ret;
+
+	cpu = hard_smp_processor_id();
+	src_stid = (((cpu >> 2) << 3) | (cpu & 0x3));
+	if (smp_boot.online_map == 0xff)
+		dst_stid = 16 + src_stid + (((cpu_spread[cpu]++ % 3) & 0x3) << 4);
+	else if (smp_boot.online_map == 0xf) {
+		dst_stid = 8 + src_stid;
+	}
+	else
+		dst_stid = 32 + src_stid;
+	msg.msg0 = (1ULL<<63) | ((uint64_t)src_stid<<40) |
+		((uint64_t)arg<<32) | (uint32_t)(unsigned long)syscall;
+	msg.msg1 = msg.msg2 = msg.msg3 = 0;
+	spin_lock(&__get_cpu_var(msgring_lock));
+	msgrng_flags_save(mflags);
+	ret = message_send_retry(1, 0, dst_stid, &msg);
+	msgrng_flags_restore(mflags);
+	spin_unlock(&__get_cpu_var(msgring_lock));
+
+	return ret;
+}
+
+static int msgring_ioctl (struct inode *inode, struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	unsigned long shm_vaddr = (unsigned long)phoenix_psb_shm;
+	unsigned long shm_paddr = __pa(phoenix_psb_shm); // assume it is in kseg0, for now
+
+	switch (cmd) {
+
+	case MSGRING_IOC_SSTNNO: {
+		int tx_stn = arg;
+		if (tx_stn >= MAX_MSG_FIFOS) {
+			printk("[%s]: illegal tx stn id=%d\n", __FUNCTION__, tx_stn);
+			return -EINVAL;
+		}
+		filp->private_data = &msg_fifos[tx_stn];
+		PRINTK_INFO("%s:%d registering tx_stn=%d fifo=%p\n", __FUNCTION__, __LINE__,
+			    tx_stn, filp->private_data);
+		msg_fifos[tx_stn].head = msg_fifos[tx_stn].tail = 0;
+	}
+		break;
+
+	case MSGRING_IOC_GSHMPHYS: {
+		*(unsigned int *)arg = shm_paddr;
+	}
+		break;
+
+	case MSGRING_IOC_GSHMVIRT: {
+		*(unsigned int *)arg = shm_vaddr;
+	}
+		break;
+
+	case MSGRING_IOC_GMMAP_START:{
+			*(unsigned int *)arg =
+			    (unsigned int)PHNX_USER_MAC_MMAP_VIRT_START;
+	}
+		break;
+
+	case MSGRING_IOC_SYSINIT: {
+		/* allocate the socket interfacxe */
+		SYSCALL *syscall;
+
+		/* allocate the syscall interface */
+		syscall = kmalloc(arg, GFP_KERNEL);
+		if (!syscall) {
+			printk("syscall: no memory\n");
+			return -ENOMEM;
+		}
+		init_waitqueue_head(&syscall->sleep);
+                syscall->process = 0;
+		syscall->pid = current->pid;
+		filp->private_data = syscall;
+	}
+		break;
+
+	case MSGRING_IOC_SYSPHYS:
+		*(unsigned int *)arg = (unsigned int)(unsigned long)filp->private_data;
+		break;
+
+	case MSGRING_IOC_SYSCALL: {
+		SYSCALL *syscall;
+		DEFINE_WAIT(wait);
+		int not_sent;
+
+		/* send a system call */
+		syscall = filp->private_data;
+		syscall->done = 0;
+		syscall->num++;
+		syscall->trace = 0;
+		not_sent = send_syscall(syscall, arg);
+
+		/* wait for the answer */
+		if (syscall->done) {
+			if (syscall->id == 10) /*SYSCALL_memcpy */
+  		          return 100;
+			/* the system call was acknowledged */
+			break;
+		}
+
+		do {
+			prepare_to_wait(&syscall->sleep, &wait, TASK_INTERRUPTIBLE);
+			schedule_timeout(1);
+			if (not_sent)
+				/* we have not yet sent the system call */
+				not_sent = send_syscall(syscall, arg);
+		} while (!signal_pending(current) && !syscall->done);
+		finish_wait(&syscall->sleep, &wait);
+		if (syscall->done) {
+			if (syscall->id == 10) /*SYSCALL_memcpy */
+  		          return 100;
+
+			/* the system call was acknowledged, stop, because rmios will not
+			 * reply to an interrupt when it is idle */
+			break;
+		}
+		if (not_sent)
+			/* the system call was not sent and the process caught a signal,
+			 * stop, because rmios will not reply to an interrupt when it is
+			 * idle */
+			return -EINTR;
+		not_sent = send_syscall(syscall, SYSCALL_interrupt);
+		if (syscall->done)
+			/* the interrupt was acknowledged wither by a system call response
+			 * or by an interrupt response */
+			return -EINTR;
+		do {
+			prepare_to_wait(&syscall->sleep, &wait, TASK_UNINTERRUPTIBLE);
+			schedule_timeout(1);
+			if (not_sent)
+				/* we have not yet sent the interrupt */
+				not_sent = send_syscall(syscall, SYSCALL_interrupt);
+		} while (!syscall->done);
+		finish_wait(&syscall->sleep, &wait);
+		/* the interrupt was acknowledged wither by a system call response
+		 * or by an interrupt response */
+		return -EINTR;
+	}
+		break;
+
+	default: {
+		printk("ioctl(): invalid command\n");
+		return -EINVAL;
+	}
+
+	}
+
+	//printk("[%s:%d]: \n", __FUNCTION__, __LINE__);
+
+	return 0;
+}
+
+static long msgring_compat_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	unsigned long ret = -1;
+	lock_kernel();
+	ret = msgring_ioctl(NULL,filp,cmd,arg);
+	unlock_kernel();
+	if(ret){
+		printk("msgring_ioctl returned with an error %lx", ret);
+		return -ENOIOCTLCMD;
+	}
+	return ret;
+}
+
+static void rmi_phnx_syscall_msgring_handler(int bucket, int size, int code, int stid,
+                                      struct msgrng_msg *msg, void *data/* ignored */) {
+
+	SYSCALL *syscall;
+	syscall = (SYSCALL *)(unsigned long)msg->msg0;
+	//printk("Wake up syscall %p sleep %p\n",syscall,&syscall->sleep);
+	if (msg->msg0 & (1ULL<<62))
+		syscall->done = 2;
+	else
+		syscall->done = 1;
+	wake_up_interruptible(&syscall->sleep);
+}
+
+// called only when the reference count (maintained in inode) is zero
+static int msgring_release (struct inode *inode, struct file *filp)
+{
+	if (filp->private_data != 0 &&
+           ((char *)filp->private_data < (char *)&msg_fifos[0] ||
+            (char *)filp->private_data > (char *)&msg_fifos[MAX_MSG_FIFOS])) {
+		SYSCALL *syscall;
+		syscall = filp->private_data;
+		if (syscall->process) {
+			int sig = test_tsk_thread_flag(current, TIF_SIGPENDING);
+			if (sig)
+				clear_tsk_thread_flag(current, TIF_SIGPENDING);
+			msgring_ioctl(inode, filp, MSGRING_IOC_SYSCALL, SYSCALL_exit);
+			if (sig)
+				set_tsk_thread_flag(current, TIF_SIGPENDING);
+		}
+		kfree(filp->private_data);
+		filp->private_data = 0;
+	}
+	return 0;
+}
+
+static struct file_operations msgring_fops = {
+	owner:		THIS_MODULE,
+	read:		msgring_read,
+	write:		msgring_write,
+	mmap:		msgring_mmap,
+	open:		msgring_open,
+	ioctl:		msgring_ioctl,
+	poll:		msgring_poll,
+	release:	msgring_release,
+	compat_ioctl:	msgring_compat_ioctl,
+};
+
+// msgring_init(): invoked as part of the kernel bootup process
+static int msgring_init(void)
+{
+	int err;
+	int i=0;
+
+	/* if support for loading apps on same core as Linux is enabled */
+	if(xlr_loader_support && xlr_loader_sharedcore && !xlr_hybrid_rmios_ipsec())
+		return -EINVAL;
+
+	hybrid = strstr(saved_command_line, "hybrid=");
+
+	// Intitialize 8 FIFO queues for each of the 8 cpu stations
+	for (i = 0; i < MAX_MSG_FIFOS; ++i) {
+
+		fifo_init(&msg_fifos[i], MSG_FIFO_SIZE);
+		init_waitqueue_head(&msg_fifos[i].wq);
+
+		if (i > 7) continue;
+
+		err = register_msgring_handler(TX_STN_CPU_0 + i, phnx_msgring_drv_int_handler, NULL);
+		if (err) {
+			// should we panic or just return an error message
+			panic("In %s at line %d: unable to register handler for msgring stations for stn %d\n",
+			      __FILE__, __LINE__, i);
+		}
+	}
+
+	msgring_major = register_chrdev (XLR_MSGRING_SHM_MAJOR, PHNX_MSGRING_CHRDEV_NAME, &msgring_fops);
+	if (msgring_major < 0) {
+		printk("msgring_init() register_chrdev() failed\n");
+		return msgring_major;
+	}
+	msgring_major = XLR_MSGRING_SHM_MAJOR;
+	printk("Registered phoenix msgring driver: major=%d\n", msgring_major);
+
+	return 0;
+}
+
+static void msgring_exit(void)
+{
+	unregister_chrdev (msgring_major, PHNX_MSGRING_CHRDEV_NAME);
+}
+
+module_init (msgring_init);
+module_exit (msgring_exit);
+
+// Do we need to export any names ?
diff --git a/drivers/char/phnx_msgring_debugger.c b/drivers/char/phnx_msgring_debugger.c
new file mode 100644
index 0000000..418a859
--- /dev/null
+++ b/drivers/char/phnx_msgring_debugger.c
@@ -0,0 +1,86 @@
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/proc_fs.h>
+
+
+struct proc_dir_entry *msgring_debug;
+struct proc_dir_entry *msgring_dbglevel;
+
+static int initstatus = 0;
+
+int msgring_debug_level = 3;
+EXPORT_SYMBOL(msgring_debug_level);
+extern struct proc_dir_entry *rmi_root_proc;
+
+#define MAX_DEBUG_LEVEL 128
+
+
+static int msgring_debug_read(char *page, char **start, off_t off, int count, int *eof,
+				       void *data) {
+	int ret = 0;
+	if(off > 0) {
+		*eof = 1;
+		return 0;
+	}
+
+	if(!initstatus) {
+		ret = sprintf(page, "%d", msgring_debug_level);
+	}
+	return ret;
+}
+
+static int msgring_debug_write(struct file *filp, const char __user *buf,
+					unsigned long count, void *data) {
+	int ret = 0;
+	int level = 0;
+	if(!initstatus) {
+		char scratch[10];
+		if(count < sizeof(scratch)) {
+			__copy_from_user(&scratch, buf, count);
+			scratch[count] = '\0';
+			level = simple_strtol(scratch, NULL, 0);
+			if(level < 0 || level > MAX_DEBUG_LEVEL) {
+				ret = -EINVAL;
+			} else {
+				msgring_debug_level = level;
+				ret = count;
+			}
+		} else {
+			ret = -ENOSPC;
+		}
+	}
+	return ret;
+}
+
+
+static int msgring_debug_init(void) {
+	msgring_debug = proc_mkdir("msgring_debug", rmi_root_proc);
+	if(!msgring_debug) {
+		printk(KERN_ERR "unable to create /proc/msgring_debug.\n");
+		initstatus = -ENOMEM;
+	}
+
+	if(!initstatus) {
+		msgring_dbglevel = create_proc_entry("level", 0644, msgring_debug);
+		if(!msgring_dbglevel) {
+			printk(KERN_ERR "unable to create proc entry: /proc/msgring_debug/level.\n");
+			initstatus = -ENOMEM;
+			remove_proc_entry("msgring_debug", rmi_root_proc);
+		} else {
+			msgring_dbglevel->read_proc = msgring_debug_read;
+			msgring_dbglevel->write_proc = msgring_debug_write;
+		}
+	}
+	return initstatus;
+}
+
+static void msgring_debug_exit(void) {
+	if(!initstatus) {
+		remove_proc_entry("level", msgring_debug);
+		remove_proc_entry("msgring_debug", rmi_root_proc);
+	}
+}
+
+module_init(msgring_debug_init);
+module_exit(msgring_debug_exit);
diff --git a/drivers/char/phnx_tb.c b/drivers/char/phnx_tb.c
new file mode 100644
index 0000000..ff11f9b
--- /dev/null
+++ b/drivers/char/phnx_tb.c
@@ -0,0 +1,325 @@
+/*********************************************************************
+
+Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions
+are met:
+
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+
+*****************************#RMI_2#**********************************/
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <asm/uaccess.h>
+#include <asm/rmi/pic.h>
+#include <asm/rmi/phnx_tb.h>
+#include <linux/phnx_tb.h>
+#include <asm/rmi/sim.h>
+
+#define PHNX_TB_DEBUG 1
+#define TB_INT_FLAGS 0
+
+#define Message(a,b...) //printk("\n"a"\n",##b)
+#define ErrorMsg(a,b...) printk("\n"a"\n",##b)
+
+
+static int			tb_major;
+long tb_compat_ioctl(struct file *filp, unsigned int cmd, unsigned long arg);
+static spinlock_t trace_buf_lock=SPIN_LOCK_UNLOCKED;
+static int tb_is_opened = 0;
+tb_dev_t    tb_dev; 
+loff_t tb_seek (struct file *filp, loff_t offset, int where);
+
+
+
+struct file_operations tb_fops = {
+	.read	    = tb_read,
+	.open	    = tb_open,
+	.llseek	    = tb_seek,
+	.ioctl      = tb_ioctl,
+	.release    = tb_release,
+	.compat_ioctl = tb_compat_ioctl,
+};
+
+
+
+/* -----------------------------    LAYER 2 Code   ------------------------------ */
+
+static inline void read_tb_entry(unsigned char *tb_entry_ptr)
+{
+	int j;
+	unsigned int *x;
+
+	tb_pop_entry();
+	for (j = 0; j < 4; ++j) {
+		x = (unsigned int *) (tb_entry_ptr + 4*j);
+		*x = tb_read_rddata_reg (j);
+	}
+}
+
+
+irqreturn_t tb_int_handler(int irq, void *dev_id) 
+{
+  unsigned int  status_reg, ctrl_reg;
+	unsigned int  tb_wr_ptr, tb_rd_ptr, tb_first_match_ptr;
+	int    m, n;
+	unsigned int no_of_junk_entry;
+	unsigned int no_of_valid_entry;
+	unsigned int req_read_pos =0;
+	status_reg = tb_read_status_reg();
+	Message("Interrupt Handler Called.");
+	
+	if (!TB_IS_STATUS_DONE(status_reg)){
+		ErrorMsg("something is wrong as int must not have been generated");
+		return IRQ_HANDLED;
+	}
+
+	tb_wr_ptr = TB_GET_WRPTR(status_reg);
+	tb_rd_ptr = TB_GET_RDPTR(status_reg);
+	tb_first_match_ptr = TB_GET_FIRST_MATCH_PTR(status_reg); 
+
+	ctrl_reg = tb_read_ctrl_reg();
+	n = TB_GET_CTRL_REQCNT(ctrl_reg);
+
+	Message("tb_wr_ptr %d, tb_rd_ptr %d, tb_first_match_ptr %d, Count %d",
+									tb_wr_ptr,tb_rd_ptr,tb_first_match_ptr,n);
+
+	if (!(status_reg & TB_FULL)) {
+		req_read_pos = tb_first_match_ptr;
+		no_of_valid_entry = n;
+	} else {
+		if (tb_first_match_ptr >= tb_rd_ptr)
+			no_of_valid_entry = tb_first_match_ptr - tb_rd_ptr;
+		else 
+			no_of_valid_entry = 256 - ( tb_rd_ptr - tb_first_match_ptr);
+		req_read_pos = no_of_valid_entry;
+	}
+	no_of_junk_entry = req_read_pos;
+
+	while(no_of_junk_entry--)
+	  tb_pop_entry();
+
+	status_reg = tb_read_status_reg();
+	tb_rd_ptr = TB_GET_RDPTR(status_reg);
+	Message("After Removin Junk Entry ReadPtr %d",tb_rd_ptr);
+	
+	tb_dev.size = 16 * TB_GET_CTRL_REQCNT(ctrl_reg);
+	for (m = 0; m < tb_dev.size; m += 16)
+	  read_tb_entry (tb_dev.data + m);
+
+	status_reg = tb_read_status_reg();
+	tb_rd_ptr = TB_GET_RDPTR(status_reg);
+	Message("After Popin All Valid Entry ReadPtr %d",tb_rd_ptr);
+	return IRQ_HANDLED;
+}
+
+/* -----------------------------    LAYER 3 Code   ------------------------------ */
+
+int tb_open (struct inode *inode, struct file *filp)
+{
+	unsigned long flags=0;
+
+	Message("tb_open() invoked");
+	spin_lock_irqsave(&trace_buf_lock,flags);
+	if(tb_is_opened){
+		spin_unlock_irqrestore(&trace_buf_lock,flags);
+		return -1;
+	}
+	tb_is_opened = 1;
+	spin_unlock_irqrestore(&trace_buf_lock,flags);
+	tb_dev.size =0;
+	return 0;
+}
+
+ssize_t tb_read (struct file *filp, char *buf, size_t count, loff_t *offset)
+{
+	// if current position is past the size of the buffer
+
+	if (*offset >= tb_dev.size)
+		return 0;
+
+	if ((*offset + count) > tb_dev.size)
+		count = tb_dev.size - *offset;
+
+	if (__copy_to_user (buf, (tb_dev.data+*offset) , count))
+		return -EFAULT;
+
+	*offset += count;
+	return count;
+}
+
+loff_t tb_seek (struct file *filp, loff_t offset, int where)
+{
+	loff_t position;
+
+	switch(where) {
+		case 0: /* SEEK_SET */
+			position = offset;
+			break;
+		case 1: /* SEEK_CUR */
+			position = filp->f_pos + offset;
+			break;
+		case 2: /* SEEK_END */
+			position = tb_dev.size + offset;
+			break;
+		default: 
+			return -EINVAL;
+	}
+	if (position < 0) 
+		return -EINVAL;
+	filp->f_pos = position;
+	return position;
+}
+
+
+long tb_compat_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	unsigned long ret = -1;
+	lock_kernel();	
+	ret = tb_ioctl(NULL,filp,cmd,arg);
+	unlock_kernel();
+	if(ret){
+		ErrorMsg("tb_ioctl returned with an error.");
+		return -ENOIOCTLCMD;
+	}
+	return ret;
+}
+
+
+int tb_ioctl (struct inode *inode, struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	switch (cmd) {
+		case TB_IOC_GTBREG: {
+			struct tb_register requested_reg;
+		
+			Message("file: %s, line: %d: ioctl(): TB_IOC_GTBREG\n", __FILE__, __LINE__);
+			// copy_from_user(to, from, size)
+			if ( copy_from_user (&requested_reg, (struct tb_register *)arg, 
+					sizeof(struct tb_register))) {
+				ErrorMsg("ioctl(): copy_to_user() failed in file %s at line %d",
+					__FILE__, __LINE__);
+				return -EFAULT;
+			}
+			if(requested_reg.type > 0xf || requested_reg.type < 0){
+				ErrorMsg("Invalid Register Access");
+				return -EINVAL;
+			}
+			requested_reg.val = tb_read_reg_be32(requested_reg.type);
+			if ( copy_to_user ((struct tb_register *) arg, &requested_reg, 
+					sizeof(struct tb_register)) ) {
+				ErrorMsg("ioctl(): copy_to_user() failed in file %s at line %d",
+					__FILE__, __LINE__);
+				return -EFAULT;
+			}
+		}
+			break;
+
+		case TB_IOC_STBREG: {
+			struct tb_register reg;
+		
+			Message("file: %s, line: %d: ioctl(): TB_IOC_STBREG\n", __FILE__, __LINE__);
+			// copy_from_user(to, from, size)
+			if ( copy_from_user (&reg, (struct tb_register *)arg, 
+					sizeof(struct tb_register))) {
+				ErrorMsg("ioctl(): copy_to_user() failed in file %s at line %d",
+					__FILE__, __LINE__);
+				return -EFAULT;
+			}
+			if(reg.type > 0xf || reg.type < 0){
+				ErrorMsg("Invalid Register Access");
+				return -EINVAL;
+			}
+
+
+			tb_write_reg_be32(reg.type, reg.val);
+			if (reg.type == TB_CTRL_REG) {
+							unsigned int x;
+
+							Message("ioctl(): the reqcnt in the ctrl reg is(1): %d\n", TB_GET_CTRL_REQCNT(reg.val));
+							x = tb_read_ctrl_reg();
+							Message("ioctl(): the reqcnt in the ctrl reg is(2): %d\n", TB_GET_CTRL_REQCNT(x));
+			}
+			
+		}
+			break;
+
+		case TB_IOC_REINIT: {
+			Message("file: %s, line: %d: ioctl(): TB_REINIT\n", __FILE__, __LINE__);
+			tb_reinit();
+			tb_dev.size =0;
+		}
+			break;
+
+		default:
+			ErrorMsg("Unindentified ioctl() command");
+			return -EINVAL;
+	}
+
+	return 0;
+}
+
+int tb_release (struct inode *inode, struct file *filp)
+{
+	unsigned long flags;
+	spin_lock_irqsave(&trace_buf_lock,flags);
+	tb_is_opened = 0;
+	spin_unlock_irqrestore(&trace_buf_lock,flags);
+	return 0;
+}
+
+// tb_init(): invoked as part of the kernel bootup process
+static int tb_init(void)	
+{
+	int err=0;
+
+	Message("tb_init() invoked");
+	tb_major = register_chrdev (240, "xlr_tracebuffer", &tb_fops);
+	if (tb_major < 0) {
+		ErrorMsg("tb_init() register_chrdev() failed");
+		return tb_major;
+	}
+	
+	// the handler too gets registered in the following call 
+	err = request_irq(PIC_BRIDGE_TB_IRQ(), tb_int_handler, TB_INT_FLAGS, "trace buffer", NULL);
+	if (err) {
+		unregister_chrdev (tb_major, "trace buffer");
+		ErrorMsg("tb_init(): request_irq() failed");
+		return err;
+	}
+	tb_dev.data = (unsigned char *)kmalloc(TB_SIZE,GFP_KERNEL);
+	Message("tb_init() request_irq() succeeded");
+	printk("Registered tracebuffer driver with Major No. [%d]\n", 240);
+
+	return 0;
+}
+
+static void tb_exit(void)
+{
+	free_irq(PIC_BRIDGE_TB_IRQ(), NULL);
+	kfree(tb_dev.data);
+
+	unregister_chrdev (tb_major, "trace buffer");
+}
+module_init (tb_init);
+module_exit (tb_exit);
+// Do we need to export any names ?
diff --git a/drivers/char/phoenix_rmios_debugger.c b/drivers/char/phoenix_rmios_debugger.c
new file mode 100644
index 0000000..8524a68
--- /dev/null
+++ b/drivers/char/phoenix_rmios_debugger.c
@@ -0,0 +1,332 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/poll.h>
+#include <linux/workqueue.h>
+#include <linux/module.h>
+#include <linux/init.h>
+/*#include <linux/proc_fs.h>*/
+/*#include <linux/cpumask.h>*/
+
+#include <asm/uaccess.h>
+#include <asm/mman.h>
+#include <asm/atomic.h>
+#include <asm/smp.h>
+#include <asm/bootinfo.h>
+
+#include <asm/rmi/pic.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/debug.h>
+#include <asm/rmi/devices.h>
+#include <asm/rmi/phoenix_rmios_debugger.h>
+
+#define PHXDEB_DIAG(a, b...) //printk(a, ##b)
+#define ErrorMsg(a, b...) printk(a, ##b) 
+//#define barrier() __asm__ __volatile__(".set mips3\n" "sync": : :"memory")
+
+struct phnx_rmios_debugger_struct {
+	int cpu;
+	int bucket;
+	int code;
+	int msgsize;
+	int stid;
+	struct msgrng_msg msg;
+	uint64_t buf;
+	uint64_t mem_addr;
+};
+static spinlock_t phnx_rmios_debugger_lock[LINUX_RMIOS_VCPU];
+static struct __wait_queue_head phnx_rmios_debugger_waitq[LINUX_RMIOS_VCPU];
+static u32 length[LINUX_RMIOS_VCPU];
+static struct phnx_rmios_debugger_struct phnx_rmios_debugger_data[LINUX_RMIOS_VCPU][2]; /* one pending message allowed. */
+static int phnx_rmios_data_available[LINUX_RMIOS_VCPU];
+static spinlock_t msgrng_lock;
+
+
+static ssize_t phnx_rmios_debugger_read(struct file *filep, char __user *user,
+					size_t len, loff_t *offset)
+{
+	int cpu;
+	struct phnx_rmios_debugger_struct local;
+	if(copy_from_user((void *)&local, (void __user *)user, sizeof(local))) {
+		ErrorMsg("Invalid address\n");
+		return -EINVAL;
+	}
+	cpu = local.cpu;
+
+	wait_event_interruptible(phnx_rmios_debugger_waitq[cpu], (phnx_rmios_data_available[cpu] > 0) /* condition */);
+
+    
+	if(copy_to_user((void __user *)user, (void *)&phnx_rmios_debugger_data[cpu][0], sizeof(local))){
+		return -EINVAL;
+	}
+	spin_lock_irq(&phnx_rmios_debugger_lock[cpu]);
+	phnx_rmios_data_available[cpu]--;
+	if (phnx_rmios_data_available[cpu]) {
+		phnx_rmios_debugger_data[cpu][0].code = 
+			phnx_rmios_debugger_data[cpu][1].code;
+		phnx_rmios_debugger_data[cpu][0].msgsize =
+			phnx_rmios_debugger_data[cpu][1].msgsize;
+		phnx_rmios_debugger_data[cpu][0].stid =
+			phnx_rmios_debugger_data[cpu][1].stid;
+		memcpy(&(phnx_rmios_debugger_data[cpu][0].msg), &(phnx_rmios_debugger_data[cpu][1].msg), sizeof(struct msgrng_msg));
+	}
+	spin_unlock_irq(&phnx_rmios_debugger_lock[cpu]);
+	return 0;
+}
+
+static ssize_t phnx_rmios_debugger_write(struct file *filep, const char __user *user,
+					size_t len, loff_t *offset)
+{
+	struct phnx_rmios_debugger_struct local;
+	struct msgrng_msg msg;
+	int bucket;
+	int code;
+	int msgsize;
+	unsigned long flags, msgrng_flags;
+
+	if(copy_from_user((void *)&local, (void __user *)user, sizeof(local))) {
+		ErrorMsg("Invalid address\n");
+		return -EINVAL;
+	}
+	bucket = local.bucket;
+	code = local.code;
+	msgsize = local.msgsize;
+	memcpy(&msg, &local.msg, sizeof(msg));
+	
+	msgrng_access_save(&msgrng_lock, flags, msgrng_flags);
+
+	while ((code = message_send(msgsize, code, bucket, &msg)) != 0) { };     
+
+	PHXDEB_DIAG("Message Sent:   code = %x\n", code);
+
+	msgrng_access_restore(&msgrng_lock, flags, msgrng_flags); 
+	return 0;
+
+}
+
+static int phnx_rmios_debugger_ioctl(struct inode *inode, struct file *file,
+        unsigned int cmd, unsigned long arg)
+{
+	struct phnx_rmios_debugger_struct local;
+	struct msgrng_msg msg;
+	int bucket;
+	int code;
+	int msgsize=0;
+	int cpu;
+	unsigned long flags, msgrng_flags;
+	char *buf;
+	
+	if (copy_from_user(&local, (void __user *)arg, sizeof(local)))
+	{
+		ErrorMsg("Invalid address\n");
+		return -EINVAL;
+	}
+	cpu = local.cpu;
+
+	switch (cmd) {
+		case PHNX_RMIOS_DEBUGGER_WRITE: 
+			bucket = local.bucket;
+			code = local.code;
+			msgsize = local.msgsize;
+			memcpy(&msg, &local.msg, sizeof(msg));
+			msgrng_access_save(&msgrng_lock, flags, msgrng_flags);
+
+			while ((code = message_send(msgsize, code, bucket, &msg)) != 0) { };     
+
+			PHXDEB_DIAG("Message Sent:   code = %x\n", code);
+
+			msgrng_access_restore(&msgrng_lock, flags, msgrng_flags); 
+			break;
+		case PHNX_RMIOS_DEBUGGER_READ:
+			wait_event_interruptible(phnx_rmios_debugger_waitq[cpu], (phnx_rmios_data_available[cpu] > 0) /* condition */);
+
+			spin_lock_irq(&phnx_rmios_debugger_lock[cpu]);
+			if (copy_to_user((void __user *)arg, (void *)&phnx_rmios_debugger_data[cpu][0], sizeof(local))){
+				return -EINVAL;
+			}
+			phnx_rmios_data_available[cpu]--;
+			if (phnx_rmios_data_available[cpu]) {
+				phnx_rmios_debugger_data[cpu][0].code = 
+					phnx_rmios_debugger_data[cpu][1].code;
+				phnx_rmios_debugger_data[cpu][0].msgsize =
+					phnx_rmios_debugger_data[cpu][1].msgsize;
+				phnx_rmios_debugger_data[cpu][0].stid =
+					phnx_rmios_debugger_data[cpu][1].stid;
+				memcpy(&(phnx_rmios_debugger_data[cpu][0].msg), &(phnx_rmios_debugger_data[cpu][1].msg), sizeof(struct msgrng_msg));
+			}
+			spin_unlock_irq(&phnx_rmios_debugger_lock[cpu]);
+			break;
+		case PHNX_RMIOS_DEBUGGER_TX_MEM_WRITE:
+			buf = (unsigned char *)(LINUX_RMIOS_TX_BUF_BASE + LINUX_RMIOS_TX_BUF_SIZE * cpu);
+			msgsize = local.msgsize;
+			if (copy_from_user(buf, (void __user *)(long)(local.buf), msgsize))
+			{
+				ErrorMsg("Invalid address\n");
+				return -EINVAL;
+			}
+			barrier();
+			break;
+		case PHNX_RMIOS_DEBUGGER_TX_MEM_READ:
+			buf = (unsigned char *)(LINUX_RMIOS_TX_BUF_BASE + LINUX_RMIOS_TX_BUF_SIZE * cpu);
+			msgsize = local.msgsize;
+			if (copy_to_user((void __user *)(long)(local.buf), (void *)buf, msgsize))
+			{
+				ErrorMsg("Invalid address\n");
+				return -EINVAL;
+			}
+			break;
+		case PHNX_RMIOS_DEBUGGER_RX_MEM_WRITE:
+			buf = (unsigned char *)(LINUX_RMIOS_RX_BUF_BASE + LINUX_RMIOS_RX_BUF_SIZE * cpu);
+			msgsize = local.msgsize;
+			if (copy_from_user(buf, (void __user *)(long)(local.buf), msgsize))
+			{
+				ErrorMsg("Invalid address\n");
+				return -EINVAL;
+			}
+			barrier();
+			break;
+		case PHNX_RMIOS_DEBUGGER_RX_MEM_READ:
+			buf = (unsigned char *)(LINUX_RMIOS_RX_BUF_BASE + LINUX_RMIOS_RX_BUF_SIZE * cpu);
+			msgsize = local.msgsize;
+			if (copy_to_user((void __user *)(long)(local.buf), (void *)buf, msgsize))
+			{
+				ErrorMsg("Invalid address\n");
+				return -EINVAL;
+			}
+			break;
+		case PHNX_RMIOS_DEBUGGER_MEM_READ:
+			buf = (char *)(long)(local.mem_addr);
+			msgsize = local.msgsize;
+			if (copy_to_user((void __user *)(long)(local.buf), (void *)buf, msgsize))
+			{
+				ErrorMsg("Invalid address\n");
+				return -EINVAL;
+			}
+			break;
+		case PHNX_RMIOS_DEBUGGER_MEM_WRITE:
+			buf = (char *)(long)(local.mem_addr);
+			msgsize = local.msgsize;
+			if (copy_from_user(buf, (void __user *)(long)(local.buf), msgsize))
+			{
+				ErrorMsg("Invalid address\n");
+				return -EINVAL;
+			}
+			barrier();
+			break;
+		case PHNX_RMIOS_DEBUGGER_PIC_IPI:
+			{
+			phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);	
+			phoenix_write_reg(mmio, PIC_IPI, local.cpu);
+			}
+			break;
+		default:
+			ErrorMsg("Invalid command\n");
+			return -EINVAL;
+	}
+	return 0;
+}
+
+static long phnx_rmios_debugger_compat_ioctl(struct file *filp, unsigned int cmd,
+                unsigned long arg)
+{
+        unsigned long ret = -1;
+        lock_kernel();
+        ret = phnx_rmios_debugger_ioctl(NULL, filp, cmd, arg);
+        unlock_kernel();
+        if(ret){
+                printk("%s: ioctl error\n", __FUNCTION__);
+                return -EINVAL;
+        }
+        return ret;
+}
+
+static int phnx_rmios_debugger_open(struct inode *inode, struct file *filp)
+{
+	return 0;
+}
+
+static int phnx_rmios_debugger_release(struct inode *inode, struct file *filp)
+{
+	return 0;
+}
+
+struct file_operations phnx_rmios_debugger_fops = {
+	.owner    = THIS_MODULE,
+	.open     = phnx_rmios_debugger_open,
+	.release  = phnx_rmios_debugger_release,
+	.read     = phnx_rmios_debugger_read,
+	.write    = phnx_rmios_debugger_write,
+	.ioctl    = phnx_rmios_debugger_ioctl,
+	.compat_ioctl    = phnx_rmios_debugger_compat_ioctl, /* 32-bit appn in 64-bit linux goes through this */
+};
+
+static int phnx_rmios_debugger_major;
+
+static int phnx_rmios_debugger_init(void)
+{
+	int i;
+	printk("%s - Phnx Rmios Debugger\n", __FUNCTION__);
+
+	phnx_rmios_debugger_major = register_chrdev(XLR_DEBUGGER_MAJOR, PHNX_DEB_DEV_NAME, 
+			&phnx_rmios_debugger_fops);
+	if(phnx_rmios_debugger_major < 0) {
+		printk("%s: register_chrdev() failed\n", __FUNCTION__);
+		return phnx_rmios_debugger_major;
+	}
+	printk("Created Device %s with major number %d\n", PHNX_DEB_DEV_NAME,
+				XLR_DEBUGGER_MAJOR);
+	for (i = 0; i < LINUX_RMIOS_VCPU; i++) {
+		init_waitqueue_head(&phnx_rmios_debugger_waitq[i]);
+		spin_lock_init(&phnx_rmios_debugger_lock[i]);
+	}
+	return 0;
+}
+
+static void phnx_rmios_debugger_exit(void)
+{
+	printk("%s - Exit called\n", __FUNCTION__);
+	unregister_chrdev(phnx_rmios_debugger_major, PHNX_DEB_DEV_NAME);
+}
+
+static void __init reserve_linux_rmios_memory(void)
+{
+	add_memory_region (LINUX_RMIOS_SHARED_BASE, 0x10000, BOOT_MEM_RESERVED);
+}
+early_initcall(reserve_linux_rmios_memory);
+
+
+module_init(phnx_rmios_debugger_init);
+module_exit(phnx_rmios_debugger_exit);
+
diff --git a/drivers/char/random.c b/drivers/char/random.c
index aa7ead0..54bb511 100644
--- a/drivers/char/random.c
+++ b/drivers/char/random.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
 /*
  * random.c -- A strong random number generator
  *
@@ -1196,6 +1208,17 @@ void rand_initialize_disk(struct gendisk *disk)
 }
 #endif
 
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_HW_RANDOM)
+static ssize_t
+random_read(struct file * file, char * buf, size_t nbytes, loff_t *ppos)
+{
+  get_random_bytes(buf, nbytes);
+
+  file_accessed(file);
+	
+  return nbytes;
+}
+#else
 static ssize_t
 random_read(struct file *file, char __user *buf, size_t nbytes, loff_t *ppos)
 {
@@ -1251,12 +1274,25 @@ random_read(struct file *file, char __user *buf, size_t nbytes, loff_t *ppos)
 
 	return (count ? count : retval);
 }
+#endif
+
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_HW_RANDOM)
+static ssize_t
+urandom_read(struct file * file, char * buf, size_t nbytes, loff_t *ppos)
+{
+  get_random_bytes(buf, nbytes);
 
+  file_accessed(file);
+	
+  return nbytes;
+}
+#else
 static ssize_t
 urandom_read(struct file *file, char __user *buf, size_t nbytes, loff_t *ppos)
 {
 	return extract_entropy_user(&nonblocking_pool, buf, nbytes);
 }
+#endif
 
 static unsigned int
 random_poll(struct file *file, poll_table * wait)
diff --git a/drivers/char/rmi_pcix_gen_dev.c b/drivers/char/rmi_pcix_gen_dev.c
new file mode 100644
index 0000000..5873d09
--- /dev/null
+++ b/drivers/char/rmi_pcix_gen_dev.c
@@ -0,0 +1,282 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/sched.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/compiler.h>
+#include <linux/pci.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/netdevice.h>
+#include <linux/interrupt.h>
+#include <linux/etherdevice.h>
+#include <linux/rtnetlink.h>
+#include <linux/delay.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/completion.h>
+#include <linux/crc32.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <asm/atomic.h>
+#include <linux/timer.h>
+#include <asm/rmi/sim.h>
+#include <linux/bootmem.h>
+#include <asm/bootinfo.h>
+#include <asm/rmi/rmi_pcix_gen_dev.h>
+//#include <linux/moduleparam.h>
+#define Message(a,b...)  //printk("\nFun [%s]\t"a"\n",__FUNCTION__,##b);
+#define ErrorMsg(a,b...) printk("\nFun [%s]\t"a"\n",__FUNCTION__,##b);
+
+
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+static rwlock_t rmi_mailbox_rw_lock = RW_LOCK_UNLOCKED;
+static spinlock_t rmi_mailbox_spin_lock = SPIN_LOCK_UNLOCKED;
+static int no_of_active_handler;
+
+struct rmi_mailbox_irq{
+  int valid;
+  int disabled;
+  mailbox_handler func;
+  void *data;
+}mailbox_desc[PHNX_MAX_IRQS_SUPPORTED];
+#endif
+
+static long phnx_shared_mem_base;
+int rmi_pcix_early_setup_dev(void);
+long phnx_get_shared_mem_base_dev(void)
+{
+	return phnx_shared_mem_base;
+}
+void phnx_interrupt_host(void)
+{
+#ifdef XLR_MSI_IS_SUPPORTED
+  phoenix_reg_t *pcix_ctrl_mmio = 0;
+  pcix_ctrl_mmio = phoenix_io_mmio(PHOENIX_IO_PCIX_OFFSET);
+  /* Trigger an MSI to the host */
+  pcix_ctrl_mmio[PCIX_INTRPT_CONTROL_REG] = 0x2;	
+#endif
+}
+
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+static inline void rmi_phnx_mask_mailbox(void)
+{
+  phoenix_reg_t *pcix_ctrl_mmio = 0;
+  pcix_ctrl_mmio = phoenix_io_mmio(PHOENIX_IO_PCIX_OFFSET);
+  /*Mask the mailbox interrupts */
+  pcix_ctrl_mmio[PCIX_INTRPT_CONTROL_REG] = 0xc0;
+}
+
+
+static void rmi_phnx_unmask_mailbox(void)
+{
+  phoenix_reg_t *pcix_ctrl_mmio = 0;
+ /* Setup the mailbox and MSI interrupts
+  * Setup the shared memory regions with the host.
+ */
+  pcix_ctrl_mmio = phoenix_io_mmio(PHOENIX_IO_PCIX_OFFSET);
+  //pcix_ctrl_mmio[PCIX_PHOENIX_CONTROL_REG] = 0xf2;
+  pcix_ctrl_mmio[PCIX_PHOENIX_CONTROL_REG] = (pcix_ctrl_mmio[PCIX_PHOENIX_CONTROL_REG] & 0xffffff00) | 0xf2;  
+  pcix_ctrl_mmio[PCIX_INTRPT_CONTROL_REG] = 0x0;
+}
+
+static int rmi_phnx_generic_mailbox_handler(int irq, void *data, struct pt_regs *regs)
+{
+  int i;
+  unsigned int status;
+  phoenix_reg_t *pcix_ctrl_mmio = 0;
+
+  pcix_ctrl_mmio = phoenix_io_mmio(PHOENIX_IO_PCIX_OFFSET);
+
+  Message("Got some Mailbox intr");
+/* First ack the interrupt */
+  status = pcix_ctrl_mmio[PCIX_INTRPT_STATUS_REG];
+  if(status == 0) /* Not our interrupt */
+    return IRQ_NONE;
+
+  pcix_ctrl_mmio[PCIX_INTRPT_STATUS_REG] = status;
+
+  read_lock(&rmi_mailbox_rw_lock);
+
+  Message("Scheduling mailbox ISRs");
+  for(i=0; i<PHNX_MAX_IRQS_SUPPORTED; i++)
+    if(mailbox_desc[i].valid && !mailbox_desc[i].disabled)
+      mailbox_desc[i].func(mailbox_desc[i].data,regs);
+    
+  read_unlock(&rmi_mailbox_rw_lock);
+  return IRQ_HANDLED;
+}
+
+int phnx_enable_mailbox_intr(int *index)
+{
+  mailbox_desc[*index].disabled = 0;
+  spin_lock(&rmi_mailbox_spin_lock);
+
+  no_of_active_handler++;
+  rmi_phnx_unmask_mailbox();
+
+  spin_unlock(&rmi_mailbox_spin_lock);
+  return 0;
+}
+
+int phnx_disable_mailbox_intr(int *index)
+{
+  mailbox_desc[*index].disabled = 1;
+
+  spin_lock(&rmi_mailbox_spin_lock);
+  no_of_active_handler--;
+  if(no_of_active_handler == 0)
+    rmi_phnx_mask_mailbox();
+
+  spin_unlock(&rmi_mailbox_spin_lock);
+  return 0;
+}
+
+int phnx_request_mailbox_handler(mailbox_handler func,void *data, int *index)
+{
+  int i;
+  u32 flags;
+
+  Message("Request for mailbox intr reg");
+  write_lock_irqsave(&rmi_mailbox_rw_lock, flags);
+  for(i=0; i<PHNX_MAX_IRQS_SUPPORTED; i++)
+    if(!mailbox_desc[i].valid)
+      break;
+  if(i == PHNX_MAX_IRQS_SUPPORTED)
+    return -EIO;
+		  
+  mailbox_desc[i].valid = 1;
+  mailbox_desc[i].func = func;
+  mailbox_desc[i].data = data;
+  *index = i;
+  Message("Request for mailbox intr reg SUCCESSFUL index %d", i);
+
+  write_unlock_irqrestore(&rmi_mailbox_rw_lock, flags);
+
+  phnx_enable_mailbox_intr(index);
+  return 0;
+}
+
+int phnx_free_mailbox_handler(int *index)
+{
+  u32 flags;
+
+  write_lock_irqsave(&rmi_mailbox_rw_lock, flags);
+  mailbox_desc[*index].valid = 0;
+  write_unlock_irqrestore(&rmi_mailbox_rw_lock, flags);
+
+  phnx_disable_mailbox_intr(index);
+  return 0;
+}
+#endif
+
+static int rmi_phnx_device_generic_init(void)
+{
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+  int err;
+#endif
+
+  rmi_pcix_early_setup_dev();
+  if(xlr_get_pci_mode() == XLR_PCI_HOST_MODE){
+	  phnx_shared_mem_base = 0;
+	  return -ENODEV;
+  }
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+  Message("Registring Generic Intr Handler.");	
+  if((err = request_irq(PIC_PCIX_IRQ,rmi_phnx_generic_mailbox_handler,
+		SA_INTERRUPT,"rmi_phnx_generic_mailbox_handler",NULL)))
+  {
+	  ErrorMsg("Cannot register handler for PCIX irq Error %d", err);
+	  return err;
+  }
+#endif
+  printk(KERN_INFO "Phoenix PCIX Shared membase is %lx\n", phnx_shared_mem_base);
+  return 0;
+}
+
+void rmi_phnx_device_generic_cleanup(void)
+{
+  free_irq(PIC_PCIX_IRQ,NULL);	
+  return;
+}
+int xlr_get_pci_mode()
+{
+  phoenix_reg_t *pcix_ctrl_mmio = phoenix_io_mmio(PHOENIX_IO_PCIX_OFFSET);
+  uint32_t mode;
+  if(is_xls()){
+      return XLR_PCI_HOST_MODE;
+  }
+  mode = pcix_ctrl_mmio[PCIX_HOST_MODE_CTRL_STATUS_REG];
+  if(mode & 0x2){
+	  return XLR_PCI_HOST_MODE;
+  }
+  return XLR_PCI_DEV_MODE;
+}
+
+int rmi_pcix_early_setup_dev(void)
+{
+  uint32_t mapper ;
+  unsigned long phy_addr;
+  static int done = 0;
+  phoenix_reg_t *pcix_ctrl_mmio = phoenix_io_mmio(PHOENIX_IO_PCIX_OFFSET);
+
+  if(xlr_get_pci_mode() == XLR_PCI_HOST_MODE){
+	  phnx_shared_mem_base = 0;
+	  return -ENODEV;
+  }
+
+  if(done)
+    return 0;
+  done = 1;	
+
+  pcix_ctrl_mmio[PCIX_DEVMODE_TBL_BAR0_REG] = (0x8000000 >> 8);
+
+  mapper = pcix_ctrl_mmio[PCIX_DEVMODE_TBL_BAR0_REG];
+  phy_addr = (mapper << 8);
+  phnx_shared_mem_base = (long)(int)((mapper << 8) | 0x80000000);
+  
+  return 0;
+}
+
+arch_initcall(rmi_pcix_early_setup_dev);
+
+module_init(rmi_phnx_device_generic_init); 
+module_exit(rmi_phnx_device_generic_cleanup);
+
+EXPORT_SYMBOL(phnx_get_shared_mem_base_dev);
+EXPORT_SYMBOL(phnx_interrupt_host);
+EXPORT_SYMBOL(xlr_get_pci_mode);
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+EXPORT_SYMBOL(phnx_free_mailbox_handler);
+EXPORT_SYMBOL(phnx_request_mailbox_handler);
+EXPORT_SYMBOL(phnx_disable_mailbox_intr);
+EXPORT_SYMBOL(phnx_enable_mailbox_intr);
+#endif
diff --git a/drivers/char/rmi_pcix_gen_host.c b/drivers/char/rmi_pcix_gen_host.c
new file mode 100644
index 0000000..3011cbf
--- /dev/null
+++ b/drivers/char/rmi_pcix_gen_host.c
@@ -0,0 +1,518 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/sched.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/compiler.h>
+#include <linux/pci.h>
+#include <linux/init.h>
+#include <linux/ioport.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/rtnetlink.h>
+#include <linux/delay.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/completion.h>
+#include <linux/crc32.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <asm/atomic.h>
+#include <linux/timer.h>
+#include <linux/sysctl.h>
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/sim.h>
+#include <asm/rmi/rmi_pcix_gen_host.h>
+#else
+#include "rmi_pcix_gen_host.h"
+#endif
+
+#define Message(a,b...) //printk("\n[%s]\t"a"\n",__FUNCTION__,##b)
+#define ErrorMsg(a,b...) printk("\n[%s]\t"a"\n",__FUNCTION__,##b)
+#define RMI_VENDOR_ID 0x182e
+#define RMI_DEVICE_ID 0x0000
+
+#define RMI_DRIVER "rmi_pcix_gen_drv"
+#define PHNX_MAX_IRQS_SUPPORTED 16
+
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+static unsigned volatile int *rmi_phnx_mailbox_addr=NULL;
+#endif
+static unsigned volatile int *rmi_phnx_shared_mem_base_host=NULL;
+
+
+struct pci_dev *rmi_pdev=NULL;
+
+#if !defined(CONFIG_RMI_PHOENIX) && defined(XLR_MSI_IS_SUPPORTED)
+static rwlock_t rmi_msi_rw_lock = RW_LOCK_UNLOCKED;
+static spinlock_t rmi_msi_spin_lock = SPIN_LOCK_UNLOCKED;
+static int no_of_active_handler=0;
+static int msi_irq=0;
+struct rmi_msi_irq{
+  int valid;
+  int disabled;
+  msi_handler func;
+  void *data;  
+}msi_desc[PHNX_MAX_IRQS_SUPPORTED] = {{0}};
+#endif
+
+void rmi_phnx_interrupt_device(void);
+
+void phnx_pci_writel(unsigned int  data,unsigned int *addr)
+{
+#ifdef CONFIG_RMI_PHOENIX
+  writel(cpu_to_le32(data),addr);
+#else
+  writel(cpu_to_be32(data),addr);
+#endif
+}
+void phnx_pci_writeb(unsigned char data, void *addr)
+{
+  writeb(data,addr);
+}
+
+unsigned int phnx_pci_readl(unsigned int  *base)
+{
+#ifdef CONFIG_RMI_PHOENIX
+  return le32_to_cpu(readl(base));
+#else
+  return be32_to_cpu(readl(base));
+#endif
+}
+ 
+
+u8 phnx_pci_readb(u8 *base)
+{
+  return readb(base);
+}
+#if !defined(CONFIG_RMI_PHOENIX) && defined(XLR_MSI_IS_SUPPORTED)
+static void phnx_unmask_msi(void)
+{
+#if 0
+  unsigned short  word;
+  Message("\nPhnxUnmaskMsi Called.\n");
+  pci_read_config_word(rmi_pdev, 0x56, &word);
+  word = word | 0x1;
+  pci_write_config_word(rmi_pdev, 0x56, word);
+  Message("--Returns..");
+#endif
+}
+
+static void phnx_mask_msi(void)
+{
+#if 0
+  unsigned short  word;
+  Message("\nMask Msi Called.\n");
+  pci_read_config_word(rmi_pdev, 0x56, &word);
+  word = word & ~(0x1);
+  pci_write_config_word(rmi_pdev, 0x56, word);
+#endif
+}
+
+static int rmi_phnx_generic_msi_handler(int irq, void *data, struct pt_regs *regs)
+{
+  int i;
+  Message("Got MSI intr");
+  read_lock(&rmi_msi_rw_lock);
+  for(i=0; i<PHNX_MAX_IRQS_SUPPORTED; i++){
+    if(msi_desc[i].valid && !msi_desc[i].disabled)
+      msi_desc[i].func(msi_desc[i].data,regs);
+  }
+  read_unlock(&rmi_msi_rw_lock);
+  return IRQ_HANDLED;
+}
+
+int phnx_enable_msi(int *index)
+{
+  Message("\nEnable Msi Called...With Index %d\n",*index);
+	if(*index < 0 || *index > PHNX_MAX_IRQS_SUPPORTED)
+		return -EINVAL;
+
+  msi_desc[*index].disabled = 0;
+
+  spin_lock(&rmi_msi_spin_lock);
+
+  no_of_active_handler++;
+  phnx_unmask_msi();
+  Message("\nNoActiveHandler %d\n",no_of_active_handler);
+  spin_unlock(&rmi_msi_spin_lock);
+  return 0;
+  
+}
+
+int phnx_disable_msi(int *index)
+{
+  if(*index < 0 || *index > PHNX_MAX_IRQS_SUPPORTED)
+    	return -EINVAL;
+
+  msi_desc[*index].disabled = 1;
+
+  spin_lock(&rmi_msi_spin_lock);
+
+  no_of_active_handler--;
+  if(no_of_active_handler == 0)
+    phnx_mask_msi();
+
+  spin_unlock(&rmi_msi_spin_lock);
+  return 0;
+}
+
+int phnx_request_msi_handler(msi_handler func,void *data, int *index)
+{
+  int i;
+  unsigned long flags=0;
+
+  Message("\nRequest for MSI handler\n");
+
+  write_lock_irqsave(&rmi_msi_rw_lock, flags);
+ 
+  for(i=0; i<PHNX_MAX_IRQS_SUPPORTED; i++)
+    if(!msi_desc[i].valid)
+      break;
+  
+  if(i == PHNX_MAX_IRQS_SUPPORTED) {
+    write_unlock_irqrestore(&rmi_msi_rw_lock, flags);
+    return -EIO;
+	}
+  Message("\nGot The Index %d Max %d\n",i,PHNX_MAX_IRQS_SUPPORTED);
+  msi_desc[i].valid = 1;
+  msi_desc[i].disabled = 0;
+  msi_desc[i].func = func;
+  msi_desc[i].data = data;
+  *index = i;
+
+  Message("\nRequest for MSI handler DONE at index %d\n", *index);
+
+  write_unlock_irqrestore(&rmi_msi_rw_lock, flags);
+  phnx_enable_msi(index);
+  return 0;  
+
+}
+
+void phnx_free_msi_handler(int *index)
+{
+  unsigned long flags=0;
+
+  write_lock_irqsave(&rmi_msi_rw_lock, flags);
+  msi_desc[*index].valid = 0;  
+  write_unlock_irqrestore(&rmi_msi_rw_lock, flags);
+  
+  phnx_disable_msi(index);
+  Message("\nIndex %d Freed\n",*index);
+  return;
+}
+#endif
+
+static struct pci_device_id rmi_id_table[] = {
+  {RMI_VENDOR_ID, PCI_ANY_ID, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0 },
+  {0,}
+};
+
+#ifdef CONFIG_SYSCTL
+static int rmi_gen_mailbox=0;
+static struct ctl_table_header *rmi_pcix_sysctl_header;
+int rmi_ctl_handler(ctl_table *ctl, int write,
+			void __user *buffer, size_t *lenp, loff_t *ppos)
+{
+	int ret;
+	ret = proc_dointvec(ctl, write, buffer, lenp, ppos);
+
+	if (write && *(int *)(ctl->data))
+		*(int *)(ctl->data) = 1;
+	rmi_phnx_interrupt_device();
+	return ret;
+}
+
+static ctl_table rmi_tbl[] = {
+	{
+		.ctl_name       = 28,
+		.procname       = "rmi_pcix",
+		.mode           = 0555,
+		.data           = &rmi_gen_mailbox,
+		.maxlen         = sizeof(int),
+		.mode           = 0644,
+		.proc_handler   = &rmi_ctl_handler,
+	},
+	{ .ctl_name = 0 }
+
+};
+static ctl_table rmi_pcix_sysctl_tbl[] = {
+	{
+		.ctl_name       = CTL_NET,
+		.procname       = "net",
+		.mode           = 0555,
+		.child          = rmi_tbl,
+	},
+	{ .ctl_name = 0 }
+
+};
+#endif
+
+
+static int rmi_phnx_generic_probe(struct pci_dev *pdev, const struct pci_device_id *id)
+{
+
+  int err;
+  unsigned long base;
+#ifdef CONFIG_RMI_PHOENIX
+  static int x=0;
+  uint32_t tmp;
+
+  if(!x){
+    /*Setting MaxOutSplitTrans to zero*/
+    pci_read_config_dword(pdev,0x40,&tmp); 
+    tmp = tmp & ~(0x7U<<20);
+    pci_write_config_dword(pdev,0x40,tmp);
+    pci_read_config_dword(pdev,0x40,&tmp); 
+    x=1;
+    return -1;
+  }
+#endif
+  rmi_pdev = pdev;
+#ifndef CONFIG_RMI_PHOENIX
+  if((err = pci_enable_device(pdev)))
+  {
+    ErrorMsg("Cannot enable PCI device, aborting.");
+    return err;
+  }
+#endif
+  if (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM))
+  {
+    ErrorMsg("Cannot find proper PCI device " 
+	     	    "base address BAR0, aborting.\n");
+    err = -ENODEV;
+    pci_disable_device(pdev);
+    return err;
+  }
+  err = pci_request_region(pdev, 0, RMI_DRIVER);
+  if (err)
+  {
+    ErrorMsg("Cannot obtain PCI resources, aborting.");
+    err = -ENODEV;
+    pci_disable_device(pdev);
+    return err;
+  }
+  pci_set_master(pdev);
+#if !defined(CONFIG_RMI_PHOENIX) && defined(XLR_MSI_IS_SUPPORTED)
+  if ((err = pci_find_capability(pdev, PCI_CAP_ID_MSI)))
+  {
+    Message("Device is MSI capable..Enabling MSI");
+    err = pci_enable_msi(pdev);
+    msi_irq = pdev->irq;
+    if(err == 0) {
+      Message("MSI Enabled");
+	}
+    else{
+      ErrorMsg("MSI Enable failed");
+      return err;
+    }
+  }
+  else
+  {
+    ErrorMsg("Device is NOT MSI capable");
+    err = -ENODEV;
+    pci_disable_device(pdev);
+    return err;
+  }
+#endif
+  base = pci_resource_start(pdev, 0);
+  rmi_phnx_shared_mem_base_host = (unsigned volatile int *)
+			ioremap_nocache(base,pci_resource_len(pdev, 0));
+  printk("Device Memory Available @ %#x \n",
+			(uint32_t)(unsigned long)rmi_phnx_shared_mem_base_host);
+  if(rmi_phnx_shared_mem_base_host == NULL)
+  {
+    err = -ENODEV;
+#if !defined(CONFIG_RMI_PHOENIX) && defined(XLR_MSI_IS_SUPPORTED)
+    pci_disable_msi(pdev);
+#endif
+#ifndef CONFIG_RMI_PHOENIX
+    pci_disable_device(pdev);
+#endif
+    return err;
+  }
+
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+  /* Use BAR2 as the mailbox address */
+  base = pci_resource_start(pdev, 2);
+  rmi_phnx_mailbox_addr = (unsigned int *)ioremap(base,pci_resource_len(pdev, 2));
+
+  if(rmi_phnx_mailbox_addr == NULL || base == 0)
+  {
+    ErrorMsg("MailBox Is Not Supported");
+    err = -ENODEV;
+    iounmap((void *)rmi_phnx_shared_mem_base_host);
+		rmi_phnx_mailbox_addr	= rmi_phnx_shared_mem_base_host = 0;
+
+#if !defined(CONFIG_RMI_PHOENIX) && defined(XLR_MSI_IS_SUPPORTED)
+    pci_disable_msi(pdev);
+#endif
+#ifndef CONFIG_RMI_PHOENIX
+    pci_disable_device(pdev);
+#endif
+    return err;
+  }
+#endif 
+
+#if !defined(CONFIG_RMI_PHOENIX) && defined(XLR_MSI_IS_SUPPORTED)
+  if((err = request_irq(msi_irq,rmi_phnx_generic_msi_handler, SA_INTERRUPT,												"rmi_phnx_generic_msi_handler", (void *)NULL)))
+	{
+		ErrorMsg("Cant Register interrupt handler irq %d",msi_irq);
+		iounmap((void *)rmi_phnx_shared_mem_base_host);
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+		iounmap((void *)rmi_phnx_mailbox_addr);
+#endif
+		pci_disable_msi(pdev);
+		pci_disable_device(pdev);
+		return err ;
+	}
+//pci_set_mwi(pdev); 
+#endif
+
+#ifdef CONFIG_SYSCTL
+  rmi_pcix_sysctl_header = register_sysctl_table(rmi_pcix_sysctl_tbl);
+  if(rmi_pcix_sysctl_header == NULL) {
+	  printk(KERN_WARNING "Could not register to sysctl\n");
+  }
+  else{
+	  printk("rmi_pcix: registered with sysctl\n");
+  }
+#endif
+
+  return 0;
+}
+
+void rmi_phnx_interrupt_device(void)
+{
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+  writel(0x1234abcd, rmi_phnx_mailbox_addr);
+#endif
+}
+
+
+
+unsigned volatile long phnx_get_shared_mem_base_host(void)
+{
+  return (unsigned volatile long)rmi_phnx_shared_mem_base_host;
+}
+
+static void rmi_phnx_generic_remove(struct pci_dev *pdev)
+{
+#if !defined(CONFIG_RMI_PHOENIX) && defined(XLR_MSI_IS_SUPPORTED)
+  phnx_unmask_msi();	
+  free_irq(pdev->irq, NULL);
+  pci_disable_msi(pdev);
+#endif
+  iounmap((void *)rmi_phnx_shared_mem_base_host);
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+  iounmap((void *)rmi_phnx_mailbox_addr);
+#endif
+  pci_release_regions(pdev);
+  pci_disable_device(pdev);
+  pci_set_drvdata(pdev, NULL);
+
+#ifdef CONFIG_SYSCTL
+  if(rmi_pcix_sysctl_header)
+  	unregister_sysctl_table(rmi_pcix_sysctl_header);
+#endif
+  return;     
+}
+
+static struct pci_driver rmi_pci_driver = {
+  .name = RMI_DRIVER,
+  .id_table = rmi_id_table,
+  .probe  = rmi_phnx_generic_probe,
+  .remove = rmi_phnx_generic_remove,
+  #ifdef POWER_MANAGEMENT
+    .suspend = rmi_suspend,
+    .resume  = rmi_resume
+  #endif
+};
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/iomap.h>
+int rmi_get_pci_mode()
+{
+  phoenix_reg_t *pcix_ctrl_mmio;
+  uint32_t mode;
+
+  if (is_xls()) {
+	  return XLR_PCI_HOST_MODE;
+  }
+
+  pcix_ctrl_mmio = phoenix_io_mmio(PHOENIX_IO_PCIX_OFFSET);
+
+  mode = pcix_ctrl_mmio[PCIX_HOST_MODE_CTRL_STATUS_REG];
+  if(mode & 0x2){
+	  return XLR_PCI_HOST_MODE;
+  }
+  return XLR_PCI_DEV_MODE;
+}
+#endif
+
+int __init rmi_pcix_gen_init(void)
+{
+#ifdef CONFIG_RMI_PHOENIX
+  if(rmi_get_pci_mode() == XLR_PCI_DEV_MODE)
+    return -EIO;
+  /* This driver is currently support on XLR hosts in case of RMI boards */
+  if(is_xls())
+      return -EIO;
+#endif
+  return pci_register_driver(&rmi_pci_driver);
+}
+
+void __exit rmi_pcix_gen_uninit(void)
+{
+  pci_unregister_driver(&rmi_pci_driver);
+}
+EXPORT_SYMBOL(phnx_pci_readl);
+EXPORT_SYMBOL(phnx_pci_readb);
+EXPORT_SYMBOL(phnx_pci_writel);
+EXPORT_SYMBOL(phnx_pci_writeb);
+EXPORT_SYMBOL(phnx_get_shared_mem_base_host);
+#if !defined(CONFIG_RMI_PHOENIX) && defined(XLR_MSI_IS_SUPPORTED)
+EXPORT_SYMBOL(phnx_request_msi_handler);
+EXPORT_SYMBOL(phnx_free_msi_handler);
+EXPORT_SYMBOL(phnx_enable_msi);
+EXPORT_SYMBOL(phnx_disable_msi);
+#endif
+EXPORT_SYMBOL(rmi_phnx_interrupt_device);
+EXPORT_SYMBOL(rmi_pdev);
+
+module_init(rmi_pcix_gen_init);
+module_exit(rmi_pcix_gen_uninit);
+#ifdef CONFIG_RMI_PHOENIX
+//Xlr Can be either pci dev or pci host
+EXPORT_SYMBOL(rmi_get_pci_mode);
+#endif
+#ifndef CONFIG_RMI_PHOENIX
+MODULE_LICENSE("GPL");
+#endif
diff --git a/drivers/char/rmicrf/Makefile b/drivers/char/rmicrf/Makefile
new file mode 100644
index 0000000..e309635
--- /dev/null
+++ b/drivers/char/rmicrf/Makefile
@@ -0,0 +1,5 @@
+#
+# Makefile for the Chip Resource Framework interface
+#
+EXTRA_CFLAGS             += -I$(srctree)/arch/mips/include/asm/rmi
+obj-y += crfdev.o #vuart.o
diff --git a/drivers/char/rmicrf/crfdev.c b/drivers/char/rmicrf/crfdev.c
new file mode 100644
index 0000000..8824690
--- /dev/null
+++ b/drivers/char/rmicrf/crfdev.c
@@ -0,0 +1,220 @@
+/*********************************************************************
+
+  Copyright 2007-2008 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/poll.h>
+
+#include <asm/rmi/devices.h>
+#include <asm/mman.h>
+
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/module.h>
+
+#include <linux/memblk.h>
+#include <asm/tlbflush.h>
+#include <asm/mipsregs.h>
+
+#include <rmicrf/config.h>
+#include <rmicrf/types.h>
+#include <rmicrf/crflib.h>
+#include <rmicrf/linux.h>
+#include <rmicrf/errcode.h>
+
+static int rmikdev_open(struct inode *inode, struct file *filp)
+{
+	if(rmi_kernel_args == NULL)
+		return -ENODEV;
+	printk("rmikdev_open\n");
+	filp->private_data = NULL;
+	return 0;
+}
+
+static long rmi_ioctl_get_domain(struct rmi_get_domain_args *arg)
+{
+	rmi_dom_t domid = arg->dom;
+	struct rmi_domain *dom;
+
+	if (domid >= RMI_MAX_DOMAINS) {
+		arg->rv = -RMI_EINVAL;
+		return 0;
+	}
+
+	dom = &rmi_this_domain[(int32_t)(domid - rmi_this_domain->id)];
+
+	/* unallocated */
+	if (dom->id != domid) {
+		arg->rv = -RMI_EEXIST;
+		return 0;
+	}
+
+	if (copy_to_user(&arg->copy, dom, sizeof(struct rmi_domain))) {
+		arg->rv = -RMI_EINVAL;
+		return -EFAULT;
+	}
+
+	arg->rv = 0;
+	return 0;
+}
+
+static long rmi_ioctl_get_logbuf(struct rmi_logbuf_args *arg)
+{
+	int copied;
+	char *buf;
+	uint32_t size;
+
+	size = arg->len < RMI_LOG_FIFO_SZ ? arg->len : RMI_LOG_FIFO_SZ;
+	
+	if((buf = kmalloc(size, GFP_KERNEL)) == NULL) {
+		arg->rv = -RMI_ENOMEM;
+		return -EFAULT;
+	}
+	
+	if((copied = rmi_get_logbuf(buf, size)) < 0) {
+		arg->rv = -RMI_EINVAL;
+		kfree(buf);
+		return -EFAULT;
+	}
+	if (copy_to_user(rmi_addr_to_ptr(arg->buf), buf, copied)) {
+		arg->rv = -RMI_EINVAL;
+		kfree(buf);
+		return -EFAULT;
+	}
+
+	kfree(buf);
+	arg->len = copied;
+	arg->rv = 0;
+	return 0;
+}
+
+static long rmi_ioctl_clear_logbuf(void)
+{
+	rmi_clear_logbuf();
+	return 0;
+}
+
+static int rmikdev_ioctl(struct inode *inode, struct file *filp, unsigned int cmd, unsigned long larg)
+{
+	void __user *arg = (void __user *)larg;
+	int callnum = _IOC_NR(cmd);
+	int size = _IOC_SIZE(cmd);
+
+	/* printk("ioctl call %u, %lx callnum %d size %d\n", cmd, larg, callnum, size); */
+	if (_IOC_TYPE(cmd) != RMICRF_IOC) 
+		return -ENOTTY;
+
+	/* Calls directly to the RMI Kernel */
+	if (callnum > 0 && callnum < RMI_CALL_MAX)
+		return rmi_kernel_call(callnum, size, arg);
+
+	/* Other calls */
+	if (cmd == RMICRF_IOC_GET_DOMAIN)
+		return rmi_ioctl_get_domain(arg);
+
+	if (cmd == RMICRF_IOC_GET_LOGBUF)
+		return rmi_ioctl_get_logbuf(arg);
+
+	if (cmd == RMICRF_IOC_CLR_LOGBUF)
+		return rmi_ioctl_clear_logbuf();
+
+	
+	return -ENOTTY;
+}
+
+static int rmikdev_release(struct inode *inode, struct file *filp)
+{
+	return 0;
+}
+
+static ssize_t rmikdev_read(struct file *filep, char __user *buf,	size_t len, loff_t *offset)
+{
+	printk("rmikdev_read\n");
+	return -EINVAL;
+}
+
+static ssize_t rmikdev_write(struct file *filep, const char __user *user,	size_t len, loff_t *offset)
+{
+	printk("rmikdev_write\n");
+	return -EINVAL;
+}
+
+#ifdef CONFIG_COMPAT
+static long rmikdev_compat_ioctl(struct file *filp, unsigned int cmd, unsigned long larg)
+{
+	int rv;
+
+	lock_kernel();
+	/* printk("Compat ioctl %p file %p, cmd %x, arg %lx\n", filp->f_path.dentry->d_inode, filp, cmd, larg); */
+	rv = rmikdev_ioctl(filp->f_path.dentry->d_inode, filp, cmd, larg);
+	unlock_kernel();
+
+	return rv;
+}
+#endif
+
+struct file_operations rmikdev_fops = {
+	.open	  = rmikdev_open,
+	.ioctl    = rmikdev_ioctl,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl =  rmikdev_compat_ioctl,
+#endif
+	.read     = rmikdev_read,
+	.write    = rmikdev_write,
+	.release  = rmikdev_release
+};
+
+static int rmikdev_major = -1;
+static int rmikdev_init(void)
+{
+	rmikdev_major = register_chrdev(0, RMI_KERNEL_DEV_NAME, &rmikdev_fops);
+	if (rmikdev_major < 0) {
+		printk("[%s]: register_chrdev failed\n", __FUNCTION__);
+		return rmikdev_major;
+	}
+	printk("Registered RMI KERNEL character device MAJOR(%d)\n", rmikdev_major);
+
+
+	return 0;
+}
+
+static void rmikdev_exit(void)
+{
+	if (rmikdev_major < 0)
+		return;
+	
+	unregister_chrdev(rmikdev_major, RMI_KERNEL_DEV_NAME);
+}
+
+module_init (rmikdev_init);
+module_exit (rmikdev_exit);
diff --git a/drivers/char/rmicrf/vuart.c b/drivers/char/rmicrf/vuart.c
new file mode 100644
index 0000000..f6fdb7e
--- /dev/null
+++ b/drivers/char/rmicrf/vuart.c
@@ -0,0 +1,502 @@
+/*********************************************************************
+
+  Copyright 2007-2008 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/console.h>
+#include <linux/pci.h>
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/tty.h>
+#include <linux/tty_flip.h>
+#include <linux/serial.h>
+#include <linux/serial_core.h>
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/rtnetlink.h>
+#include <linux/delay.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/completion.h>
+#include <linux/crc32.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <asm/atomic.h>
+#include <linux/timer.h>
+#include <asm/rmi/devices.h>
+#include <rmicrf/config.h>
+#include <rmicrf/types.h>
+#include <rmicrf/api.h>
+#include <rmicrf/crflib.h>
+#include <asm/rmi/linux_crf.h>
+
+#define RX_THRESHOLD 10
+#define DRIVER_VERSION "v0.1"
+#define DRIVER_AUTHOR "RMI"
+#define DRIVER_DESC "Virtual uart serial console driver for Arizona3"
+
+#define Message(a,b...) //printk("Function [%s]"a"\n",__FUNCTION__,##b)
+#define ErrorMsg(a,b...) printk("Function [%s]"a"\n",__FUNCTION__,##b)
+
+typedef struct {
+	struct rmi_fifo *tx_fifo;
+	struct rmi_fifo *rx_fifo;
+	int status;
+} rmik_vuart_struct;
+
+extern cpumask_t phys_cpu_present_map;
+rmik_vuart_struct rmik_vuart_tx_rx[NR_CPUS];
+static struct timer_list *timer[NR_CPUS];
+extern uint32_t rmik_en;
+static volatile int rmik_vcons_id = -1;
+#define VIRTUAL_UART_NR 32
+#define VIRT_UART_OPENED 1
+#define VIRTUAL_UART_CONSOLE_MAJOR        XLR_VIRT_UART_MAJOR
+#define VIRTUAL_UART_CONSOLE_MINOR        168
+#define VIRTUAL_UART_CONSOLE      	  "vuart"
+#define CONSOLE_OVER_VUART			  "vuart"
+#define DELAY_TIME                         2
+
+static struct console rmik_vuart_console;
+static struct uart_ops rmik_vuart_console_ops;
+
+static struct uart_driver rmik_vuart_console_reg = {
+  	.owner  = THIS_MODULE,
+	.driver_name  = VIRTUAL_UART_CONSOLE,
+  	.dev_name  = "vuart",
+  	.major  = VIRTUAL_UART_CONSOLE_MAJOR,
+  	.minor  = VIRTUAL_UART_CONSOLE_MINOR,
+  	.nr  = VIRTUAL_UART_NR,
+	.cons = &rmik_vuart_console
+};
+
+static struct uart_port rmik_vuart_console_port [VIRTUAL_UART_NR] = {
+  	[0 ... VIRTUAL_UART_NR-1] = {
+  	.ops          = &rmik_vuart_console_ops,
+  	.type         = PORT_8250,
+  	.fifosize     = 255,
+  	}
+};
+  
+
+static int vuart_console_request_port(struct uart_port *port) 
+{
+ 	return 0;
+}
+
+static void vuart_console_config_port(struct uart_port *port, int flags)
+{
+}
+
+static int vuart_console_verify_port(struct uart_port *port, struct serial_struct *ser)
+{
+  	return 0;
+}
+
+static void vuart_console_release_port(struct uart_port *port)
+{
+
+}
+
+static const char *vuart_console_type(struct uart_port *port)
+{
+  	return "rmi_vuart_consoletty";
+}
+
+static void vuart_console_set_termios(struct uart_port *port, 
+			struct ktermios *termios, struct ktermios *old)
+{
+        return;
+}
+
+static unsigned int vuart_console_tx_empty(struct uart_port *port)
+{
+        return 1;
+}
+
+static unsigned int vuart_console_get_mctrl(struct uart_port *port)
+{
+        return port->mctrl;
+}
+
+static void vuart_console_set_mctrl(struct uart_port *port, unsigned int mctrl)
+{
+  	port->mctrl = mctrl;
+}
+
+static void vuart_console_break_ctl(struct uart_port *port, int break_state)
+{
+}
+
+static void vuart_console_start_tx(struct uart_port *port)
+{
+        Message("");
+}
+
+static void vuart_console_stop_tx(struct uart_port *port)
+{
+        Message("");
+}
+
+static void vuart_console_stop_rx(struct uart_port *port)
+{
+        Message("");
+}
+
+static void vuart_console_enable_ms(struct uart_port *port)
+{
+        Message("");
+}
+
+
+/* Rx from other domain and send to minicom */
+static void vuart_console_rx_chars(struct uart_port *port)
+{
+  	struct tty_struct *tty;
+	int inlen = 0, cnt = 0;
+	char buf[256];
+
+	if ((inlen = rmi_fifo_recv(rmik_vuart_tx_rx[port->line].rx_fifo, buf, 256)) <= 0)
+		return;
+  	tty = port->info->port.tty;
+  	if (!tty){
+          	ErrorMsg("tty is nt thr...");
+          	return;
+  	}
+
+  	tty->low_latency = 1;
+  	while(inlen-- > 0) {     
+	
+		tty_insert_flip_char(tty, buf[cnt++], TTY_NORMAL); 
+    		tty_flip_buffer_push(tty);
+               /* if (ch == '\r') {
+                        tty_insert_flip_char(tty, '\n', TTY_NORMAL);
+                        tty_flip_buffer_push(tty);
+                } */
+  	};
+
+}
+
+static void rmi_cmd_put_char(char ch, int thrd_id)
+{
+  	Message("-- Called");
+   	rmi_fifo_send(rmik_vuart_tx_rx[thrd_id].tx_fifo, &ch, 1);
+}
+
+/* Take from minicom and send to other domains */
+static void vuart_console_tx_chars(struct uart_port *port)
+{
+        struct circ_buf *xmit = &port->info->xmit; 
+        int count;
+
+        if (port->x_char) {
+
+               	rmi_cmd_put_char(port->x_char, port->line);
+                port->icount.tx++;
+                port->x_char = 0;
+                return;
+        }
+        if (uart_circ_empty(xmit) || uart_tx_stopped(port)) {
+                vuart_console_stop_tx(port);
+                return;
+        }
+
+        count = port->fifosize >> 1;
+        do{
+		rmi_cmd_put_char(xmit->buf[xmit->tail], port->line);
+                xmit->tail = (xmit->tail + 1) & (UART_XMIT_SIZE - 1);
+                port->icount.tx++;
+
+                if (uart_circ_empty(xmit))
+                        break;
+
+        }while(--count > 0);
+
+
+        if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS){
+                uart_write_wakeup(port);
+        }
+}
+
+static void vuart_console_timer (unsigned long data)
+{
+        struct uart_port *port;
+
+        port = (struct uart_port *)data;
+        if (!port){
+                ErrorMsg("port is nt there...");
+                return;
+        }
+        if (!port->info){
+                ErrorMsg("port->info is nt there... ");
+                return;
+        }
+
+        /* see if we have any data for rx*/
+        vuart_console_rx_chars(port);
+        /* see if we have any data to transmit */
+        vuart_console_tx_chars(port);
+        /* resubmit the timer again */
+        timer[port->line]->expires = jiffies + DELAY_TIME;
+        add_timer(timer[port->line]);
+}
+
+static int vuart_console_startup(struct uart_port *port)
+{
+	struct rmi_fifo *txfifo, *rxfifo;
+	int tx=1, rx = 0;
+	uint64_t addr;
+	char name[RMI_MAX_NAMELEN];
+	struct rmi_resource *res = NULL;
+	
+  	/* this is the first time this port is opened */
+  	/* do any hardware initialization needed here */
+
+  	/* create our timer and submit it */
+
+  	Message("Open Called..");
+  	if (!timer[port->line]) {
+          	timer[port->line] = kmalloc (sizeof(*timer[port->line]), GFP_KERNEL);
+          	if (!timer[port->line])
+                  	return -ENOMEM;
+  	}
+  	init_timer(timer[port->line]);
+  	timer[port->line]->data = (unsigned long )port;
+  	timer[port->line]->expires = jiffies + DELAY_TIME;
+  	timer[port->line]->function = vuart_console_timer;
+  	add_timer(timer[port->line]);
+
+	if(rmik_vuart_tx_rx[port->line].status == VIRT_UART_OPENED)
+		return 0;
+		
+	rmik_vuart_tx_rx[port->line].tx_fifo = NULL;
+	rmik_vuart_tx_rx[port->line].rx_fifo = NULL;
+
+
+	if((addr = fdt_get_vuart_fifo_addr(tx, port->line)) != 0)
+		txfifo = rmi_addr_to_ptr(addr);
+	else {
+		sprintf(name, "vuart-txfifo@%d", port->line);
+		if(rmi_resource_getref(name, &res, NULL) == 0)  {
+			txfifo = rmi_addr_to_ptr(res->obj);
+			rmi_resource_putref(res);
+		} else
+			goto exit;
+	}
+
+	if((addr = fdt_get_vuart_fifo_addr(rx, port->line)) != 0) 
+		rxfifo = rmi_addr_to_ptr(addr);
+	else {
+		sprintf(name, "vuart-rxfifo@%d", port->line); 
+		if((rmi_resource_getref(name, &res, NULL)) == 0)  {
+			rxfifo = rmi_addr_to_ptr(res->obj);
+			rmi_resource_putref(res);
+		} else
+			goto exit;
+	}
+
+	if(cpu_isset(port->line, phys_cpu_present_map)) {
+		rmik_vuart_tx_rx[port->line].tx_fifo = txfifo;
+		rmik_vuart_tx_rx[port->line].rx_fifo = rxfifo;
+	} else {
+		rmik_vuart_tx_rx[port->line].tx_fifo = rxfifo;
+		rmik_vuart_tx_rx[port->line].rx_fifo = txfifo;
+	}
+
+	rmik_vuart_tx_rx[port->line].status = VIRT_UART_OPENED;
+
+	return 0;
+
+	exit:
+	return -EINVAL;
+}
+
+static void vuart_console_shutdown(struct uart_port *port)
+{
+	struct rmi_fifo *q;
+  	/* The port is being closed by the last user. */
+  	/* Do any hardware specific stuff here */
+
+  	/* shut down our timer */
+  	Message("Close Called");
+	if(timer[port->line])
+	  	del_timer_sync(timer[port->line]);
+
+	if(port->line == rmik_vcons_id)
+		return;
+
+	if(rmik_vuart_tx_rx[port->line].status != 0) {
+		q = (void *)(long)rmik_vuart_tx_rx[port->line].tx_fifo;
+		q->head = q->tail = 0;
+
+		q = (void *)(long)rmik_vuart_tx_rx[port->line].rx_fifo;
+		q->head = q->tail = 0;
+	}
+		
+	rmik_vuart_tx_rx[port->line].tx_fifo = NULL;
+	rmik_vuart_tx_rx[port->line].rx_fifo = NULL;
+	rmik_vuart_tx_rx[port->line].status = 0x0;
+
+}
+
+static void
+rmik_vuart_console_write(struct console *co, const char *str, unsigned int count)
+{
+	rmi_fifo_send(rmik_vuart_tx_rx[rmik_vcons_id].tx_fifo, str, count);
+}
+
+static int __init rmik_vuart_console_setup(struct console *co,char *options)
+{
+  return 0;
+}
+
+static struct uart_ops rmik_vuart_console_ops = {
+  	.tx_empty     = vuart_console_tx_empty,
+  	.set_mctrl    = vuart_console_set_mctrl,
+  	.get_mctrl    = vuart_console_get_mctrl,
+  	.stop_tx      = vuart_console_stop_tx,
+  	.start_tx     = vuart_console_start_tx,
+  	.stop_rx      = vuart_console_stop_rx,
+  	.enable_ms    = vuart_console_enable_ms,
+  	.break_ctl    = vuart_console_break_ctl,
+  	.startup      = vuart_console_startup,
+  	.shutdown     = vuart_console_shutdown,
+  	.set_termios  = vuart_console_set_termios,
+  	.type         = vuart_console_type,
+  	.release_port = vuart_console_release_port,
+  	.request_port = vuart_console_request_port,
+  	.config_port  = vuart_console_config_port,
+  	.verify_port  = vuart_console_verify_port,
+};
+
+static struct console rmik_vuart_console= {
+    .name           = CONSOLE_OVER_VUART,
+    .write          = rmik_vuart_console_write,
+    .device         = uart_console_device,
+    .setup          = rmik_vuart_console_setup,
+    .flags          = CON_PRINTBUFFER,
+    .index          = -1,
+    .data           = &rmik_vuart_console_reg,
+};
+
+
+static int __init rmik_vuart_init(void)
+{
+	int result;
+  	unsigned int line;
+
+	if(!rmik_en)
+			return 0;
+
+  	result = uart_register_driver(&rmik_vuart_console_reg);
+
+  	if (result){
+    		ErrorMsg("Cant Register Driver");
+    		return result;
+  	}
+  
+	for (line=0; line < VIRTUAL_UART_NR; line++)	{
+       	rmik_vuart_console_port[line].line = line;
+       	result = uart_add_one_port(&rmik_vuart_console_reg, &rmik_vuart_console_port[line]);
+        if (result){
+           	for(; line > 0; line--) {
+               	rmik_vuart_console_port[line].line = line;
+               	uart_remove_one_port(&rmik_vuart_console_reg, &rmik_vuart_console_port[line]);
+           	}
+			rmik_vuart_console_port[line].line = line;
+			uart_remove_one_port(&rmik_vuart_console_reg, &rmik_vuart_console_port[line]);
+                	uart_unregister_driver(&rmik_vuart_console_reg);
+            return result;
+       	}
+  	}
+ 
+  	return 0;
+}
+
+static int __init rmik_vuart_console_init(void)
+{
+	int cpu, tx =1, rx = 0, i = 0;
+	extern char arcs_cmdline[];
+	char temp[10], *console, *ch;
+	uint64_t addr;
+
+	if(!rmik_en)
+		return 0;
+	console = strstr(arcs_cmdline, "console=vuart");
+	if(console == NULL)
+		return 0;
+
+	for(ch =  console + strlen("console=vuart"); 
+			(*ch >= '0') && (*ch <= '9') && i <= 3; ch++)
+		temp[i++] = *ch;
+	temp[i] = '\0';
+	sscanf(temp, "%d", &cpu);
+
+	if((addr = fdt_get_vuart_fifo_addr(tx, cpu)) != 0ULL)
+		rmik_vuart_tx_rx[cpu].tx_fifo = rmi_addr_to_ptr(addr);
+	else
+		goto exit;
+
+	if((addr = fdt_get_vuart_fifo_addr(rx, cpu)) != 0ULL)
+		rmik_vuart_tx_rx[cpu].rx_fifo = rmi_addr_to_ptr(addr);
+	else
+		goto exit;
+
+	rmik_vuart_tx_rx[cpu].status = VIRT_UART_OPENED;
+
+	rmik_vcons_id = cpu;
+	register_console(&rmik_vuart_console);
+	return 0;
+
+exit:
+	printf("Error in rmik_vuart_console_init\n");
+	return -EINVAL;
+}
+
+
+static void __exit rmik_vuart_cleanup(void)
+{
+  	int line;
+
+  	for (line=0; line < VIRTUAL_UART_NR; line++)  {
+		rmik_vuart_console_port[line].line = line;
+        	uart_remove_one_port(&rmik_vuart_console_reg, &rmik_vuart_console_port[line]);
+  	}
+  	uart_unregister_driver(&rmik_vuart_console_reg);
+}
+
+module_init(rmik_vuart_init);
+module_exit(rmik_vuart_cleanup);
+
+console_initcall(rmik_vuart_console_init);
+
+
diff --git a/drivers/char/xlr_pcix_console_dev.c b/drivers/char/xlr_pcix_console_dev.c
new file mode 100644
index 0000000..b6e0062
--- /dev/null
+++ b/drivers/char/xlr_pcix_console_dev.c
@@ -0,0 +1,464 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/console.h>
+#include <linux/pci.h>
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/tty.h>
+#include <linux/tty_flip.h>
+#include <linux/serial.h>
+#include <linux/serial_core.h>
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/rtnetlink.h>
+#include <linux/delay.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/completion.h>
+#include <linux/crc32.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <asm/atomic.h>
+#include <linux/timer.h>
+#include <asm/rmi/rmi_pcix_gen_dev.h>
+#include <asm/rmi/devices.h>
+
+#define DRIVER_VERSION "v0.1"
+#define DRIVER_AUTHOR "RMI"
+#define DRIVER_DESC "Virtual serial console driver for Arizona3"
+#define BUF_SIZE (1024*4)
+#define USER_CMD_SIZE (1*1024)
+#define USER_RESULT_SIZE (7*1024)
+
+
+/* Module information */
+MODULE_AUTHOR( DRIVER_AUTHOR );
+MODULE_DESCRIPTION( DRIVER_DESC );
+MODULE_LICENSE("GPL");
+
+#define DELAY_TIME   2	     /* 2 seconds per character */
+#define CONSOLE_OVER_PCI_MINORSS	244	/* only have one minor */
+#define UART_NR			1	/* only use one port */
+
+#define CONSOLE_OVER_PCI	"pci_co"
+
+#define Message(a,b...) //printk("Function [%s]"a"\n",__FUNCTION__,##b)
+#define ErrorMsg(a,b...) printk("Function [%s]"a"\n",__FUNCTION__,##b)
+static u32 *phnx_user_cmd_producer;
+static u32 *phnx_user_cmd_consumer;
+static u32 *phnx_user_result_consumer;
+static u32 *phnx_user_result_producer;
+static u8 *phnx_user_cmd;
+static u8 *phnx_user_result;
+static volatile u32 *phnx_dev_status;
+static volatile u32 *phnx_host_status;
+
+
+static wait_queue_head_t user_result_buffer;
+
+static struct timer_list *timer;
+
+extern int rmi_pcix_early_setup_dev(void);
+extern long phnx_get_shared_mem_base_dev(void);
+static void rmi_pcix_console_stop_tx(struct uart_port *port)
+{
+	Message("");
+}
+
+static void rmi_pcix_console_stop_rx(struct uart_port *port)
+{
+	Message("");
+}
+
+static void rmi_pcix_console_enable_ms(struct uart_port *port)
+{
+	Message("");
+}
+
+static void rmi_dev_put_char(char ch)
+{
+ 
+  if(*phnx_host_status != 0xdeadbeef)
+	return;
+
+  Message("-- Called"); 
+
+  if((*phnx_user_result_producer) + 1 == *phnx_user_result_consumer){
+    return;
+  }  
+  *(phnx_user_result + *phnx_user_result_producer) = ch;
+  
+  *phnx_user_result_producer = (*phnx_user_result_producer + 1) % (USER_RESULT_SIZE);
+
+   Message("phnx_user_result_producer [%d]",*phnx_user_result_producer);
+}
+
+static void rmi_pcix_console_rx_chars(struct uart_port *port)
+{
+  struct tty_struct *tty;
+  char ch;
+	
+  if(*phnx_user_cmd_producer == *phnx_user_cmd_consumer)
+    return;
+
+  tty = port->state->port.tty;
+  if (!tty){
+	  ErrorMsg("tty is nt thr...");
+	  return;
+  }
+
+  do{
+    ch = *(phnx_user_cmd + (*phnx_user_cmd_consumer));
+    Message("[%c]",ch);
+    tty_insert_flip_char(tty, ch, TTY_NORMAL); 
+    tty_flip_buffer_push(tty);
+    *phnx_user_cmd_consumer = (*phnx_user_cmd_consumer + 1) % (USER_CMD_SIZE);
+  }while(*phnx_user_cmd_producer != *phnx_user_cmd_consumer);
+  
+}
+
+static void rmi_pcix_console_tx_chars(struct uart_port *port)
+{
+	struct circ_buf *xmit = &port->state->xmit;
+	int count;
+	Message("");
+	if (port->x_char) {
+		Message ("DATA [%c] - port->x_char", port->x_char);
+		rmi_dev_put_char(port->x_char);
+		port->icount.tx++;
+		port->x_char = 0;
+		return;
+	}
+	if (uart_circ_empty(xmit) || uart_tx_stopped(port)) {
+		rmi_pcix_console_stop_tx(port);
+		return;
+	}
+
+	count = port->fifosize >> 1;
+	do{
+		Message ("DATA [%c] - do while", xmit->buf[xmit->tail]);
+		
+		rmi_dev_put_char(xmit->buf[xmit->tail]);
+		xmit->tail = (xmit->tail + 1) & (UART_XMIT_SIZE - 1);
+		port->icount.tx++;
+		
+		if (uart_circ_empty(xmit))
+			break;
+		
+	}while(--count > 0);
+
+
+	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS){
+		Message("uart write wakeup");
+		uart_write_wakeup(port);
+	}
+
+}
+
+static void rmi_pcix_console_start_tx(struct uart_port *port)
+{
+	Message("");
+}
+
+static void rmi_pcix_console_timer (unsigned long data)
+{
+	struct uart_port *port;
+
+	Message("");
+	port = (struct uart_port *)data;
+	if (!port){
+		ErrorMsg("port is nt there...");
+		return;
+	}
+
+	/* see if port is closed ??*/
+        if(*phnx_host_status != 0xdeadbeef){
+	  /*hangup device*/  	
+	  goto out;
+	}
+	/* see if we have any data for rx*/
+	rmi_pcix_console_rx_chars(port);
+out:
+	/* see if we have any data to transmit */
+	rmi_pcix_console_tx_chars(port);
+	/* resubmit the timer again */
+	timer->expires = jiffies + DELAY_TIME;
+	add_timer (timer);
+}
+
+static unsigned int rmi_pcix_console_tx_empty(struct uart_port *port)
+{
+	return 1;
+}
+
+static unsigned int rmi_pcix_console_get_mctrl(struct uart_port *port)
+{
+	return port->mctrl;
+}
+
+static void rmi_pcix_console_set_mctrl(struct uart_port *port, unsigned int mctrl)
+{
+  port->mctrl = mctrl;
+}
+
+static void rmi_pcix_console_break_ctl(struct uart_port *port, int break_state)
+{
+}
+
+static int rmi_pcix_console_startup(struct uart_port *port)
+{
+  /* this is the first time this port is opened */
+  /* do any hardware initialization needed here */
+  /* create our timer and submit it */
+
+  Message("Open Called..");	
+  Message("phnx_user_result_consumer is [%d]",*phnx_user_result_consumer);
+  Message("phnx_user_result_producer is [%d]",*phnx_user_result_producer);
+
+  if (!timer) {
+    timer = kmalloc (sizeof (*timer), GFP_KERNEL);
+    if (!timer)
+      return -ENOMEM;
+  }
+  init_timer(timer);
+  timer->data = (unsigned long )port;
+  timer->expires = jiffies + DELAY_TIME;
+  timer->function = rmi_pcix_console_timer;
+  add_timer (timer);
+  *phnx_dev_status = 0xdeadbeef;
+  Message("-- Returns");	
+  return 0;
+}
+
+static void rmi_pcix_console_shutdown(struct uart_port *port)
+{
+  /* The port is being closed by the last user. */
+  /* Do any hardware specific stuff here */
+
+  /* shut down our timer */
+  Message("Close Called");
+  del_timer (timer);
+  *phnx_dev_status = 0x0;
+}
+
+static const char *rmi_pcix_console_type(struct uart_port *port)
+{
+  return "rmi_pcix_consoletty";
+}
+
+static void rmi_pcix_console_release_port(struct uart_port *port)
+{
+
+}
+
+static int rmi_pcix_console_request_port(struct uart_port *port)
+{
+  return 0;
+}
+
+static void rmi_pcix_console_config_port(struct uart_port *port, int flags)
+{
+}
+
+static int rmi_pcix_console_verify_port(struct uart_port *port, struct serial_struct *ser)
+{
+  return 0;
+}
+static void
+rmi_pcix_console_set_termios(struct uart_port *port, struct ktermios *termios,
+		       struct ktermios *old)
+{
+	return;
+}
+static struct uart_ops rmi_pcix_console_ops = {
+  .tx_empty	= rmi_pcix_console_tx_empty,
+  .set_mctrl	= rmi_pcix_console_set_mctrl,
+  .get_mctrl	= rmi_pcix_console_get_mctrl,
+  .stop_tx	= rmi_pcix_console_stop_tx,
+  .start_tx	= rmi_pcix_console_start_tx,
+  .stop_rx	= rmi_pcix_console_stop_rx,
+  .enable_ms	= rmi_pcix_console_enable_ms,
+  .break_ctl	= rmi_pcix_console_break_ctl,
+  .startup	= rmi_pcix_console_startup,
+  .shutdown	= rmi_pcix_console_shutdown,
+  .set_termios  = rmi_pcix_console_set_termios,
+  .type		= rmi_pcix_console_type,
+  .release_port	= rmi_pcix_console_release_port,
+  .request_port	= rmi_pcix_console_request_port,
+  .config_port	= rmi_pcix_console_config_port,
+  .verify_port	= rmi_pcix_console_verify_port,
+};
+
+static struct uart_port rmi_pcix_console_port = {
+  .ops		= &rmi_pcix_console_ops,
+  .type 	= PORT_8250,
+  .fifosize	= 255,
+};
+
+static struct console phnx_pcix_console; 
+
+static struct uart_driver rmi_pcix_console_reg = {
+  .owner  = THIS_MODULE,
+  .driver_name  = CONSOLE_OVER_PCI,
+  .dev_name  = CONSOLE_OVER_PCI,
+  .major  = XLR_CONSOLE_OVER_PCI_MAJOR,
+  .minor  = CONSOLE_OVER_PCI_MINORSS,
+  .nr  = UART_NR,
+  .cons = &phnx_pcix_console
+};
+
+static int __init rmi_pcix_console_init(void)
+{
+  int result;
+
+  if(xlr_get_pci_mode() == XLR_PCI_HOST_MODE){
+    Message("Xlr Is configured in Host Mode - unloading console_over_pci_dev\n");
+    return -EIO;
+  }
+  if(phnx_get_shared_mem_base_dev() == 0){
+	ErrorMsg("Get Shared Mem Base Iz Zero");
+	return -ENODEV;
+  }
+
+  Message ("Tiny serial driver");
+
+  result = uart_register_driver(&rmi_pcix_console_reg);
+  if (result){
+    ErrorMsg("Cant Register Driver");
+    return result;
+  }
+
+  result = uart_add_one_port(&rmi_pcix_console_reg, &rmi_pcix_console_port);
+		
+  if (result){
+    ErrorMsg("Cant Add Port");	  
+    uart_unregister_driver(&rmi_pcix_console_reg);
+  }
+  Message("Returning From init_module [%d]",result);
+
+  Message("\nphnx_user_cmd @ %#x\n",(u32)phnx_user_cmd);
+  Message("phnx_user_result @ %#x\n",(u32)phnx_user_result);
+  Message("User_Cmd_Producer [%#x]\n",(u32)phnx_user_cmd_producer);
+  Message("User_Cmd_Consumer [%#x]\n",(u32)phnx_user_cmd_consumer);
+  Message("User_Result_Consumer [%#x]\n",(u32)phnx_user_result_consumer);
+  Message("User_Result_Producer [%#x]\n",(u32)phnx_user_result_producer);
+
+  init_waitqueue_head(&user_result_buffer);
+  printk("\nConsole Over Pci Driver - Registered\n"); 
+  return result;
+}
+
+static void __exit rmi_pcix_console_cleanup(void)
+{
+  uart_remove_one_port(&rmi_pcix_console_reg, &rmi_pcix_console_port);
+  uart_unregister_driver(&rmi_pcix_console_reg);
+}
+
+static void
+phnx_pcix_console_write(struct console *co, const char *str, unsigned int count)
+{
+  int i;
+  *phnx_dev_status = 0xdeadbeef;
+  for(i=0;i<count;i++){
+    rmi_dev_put_char(*(str+i));
+    if(*(str+i) == '\n')
+      rmi_dev_put_char('\r');	    
+  }
+}
+
+static int __init phnx_pcix_console_setup(struct console *co,char *options)
+{
+  return 0;
+}
+static struct console phnx_pcix_console= {
+	.name           = CONSOLE_OVER_PCI,
+	.write          = phnx_pcix_console_write,
+	.device         = uart_console_device,
+	.setup          = phnx_pcix_console_setup,
+	.flags          = CON_PRINTBUFFER,
+	.index          = -1,
+	.data           = &rmi_pcix_console_reg,
+};
+
+
+
+static int __init phnx_pcix_console_init(void)
+{
+
+  if(xlr_get_pci_mode() == XLR_PCI_HOST_MODE)
+    return -EIO;
+
+  rmi_pcix_early_setup_dev();
+
+  if(phnx_get_shared_mem_base_dev() == 0){
+	ErrorMsg("Either XLR Is in Host Mode or pci_shared_mem option is not specified");
+	return -ENODEV;
+  }
+  phnx_user_cmd = (u8 *)phnx_get_shared_mem_base_dev() + 
+                   PHNX_CONSOLE_OVER_PCI_SHARED_MEM_BASE;
+
+  phnx_user_result = phnx_user_cmd + USER_CMD_SIZE;
+  phnx_user_cmd_producer = (u32 *)(phnx_user_result + USER_RESULT_SIZE);
+  
+  phnx_user_cmd_consumer = phnx_user_cmd_producer + 1;
+  phnx_user_result_consumer= phnx_user_cmd_consumer + 1;
+  phnx_user_result_producer= phnx_user_result_consumer + 1;
+  phnx_dev_status = phnx_user_result_producer + 1;
+  phnx_host_status = phnx_dev_status + 1;
+  *phnx_user_cmd_consumer = *phnx_user_result_consumer = 
+	  *phnx_user_cmd_producer = *phnx_user_result_producer =
+	  *phnx_dev_status = 0;
+  Message("\nphnx_user_cmd @ %#x\n",(uint32_t)phnx_user_cmd);
+  Message("phnx_user_result @ %#x\n",(uint32_t)phnx_user_result);
+  Message("phnx_user_cmd_producer @ %#x\n",(uint32_t)phnx_user_cmd_producer);
+  Message("phnx_user_cmd_consumer @ %#x\n",(uint32_t)phnx_user_cmd_consumer);
+  Message("phnx_user_result_consumer @ %#x\n",
+				(uint32_t)phnx_user_result_consumer);
+  Message("phnx_user_result_producer @ %#x\n",
+			(uint32_t)phnx_user_result_producer);
+  Message("*phnx_user_cmd %#x\n",(uint32_t)*phnx_user_cmd);
+  Message("phnx_dev_status %#x\n",(uint32_t)phnx_dev_status);
+  Message("phnx_host_status %#x\n",(uint32_t)phnx_host_status);
+
+  register_console(&phnx_pcix_console);
+  return 0;
+}
+
+console_initcall(phnx_pcix_console_init);
+
+
+module_init(rmi_pcix_console_init);
+module_exit(rmi_pcix_console_cleanup);
+
diff --git a/drivers/char/xlr_pcix_console_host.c b/drivers/char/xlr_pcix_console_host.c
new file mode 100644
index 0000000..aac2f32
--- /dev/null
+++ b/drivers/char/xlr_pcix_console_host.c
@@ -0,0 +1,481 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/pci.h>
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/tty.h>
+#include <linux/tty_flip.h>
+#include <linux/serial.h>
+#include <linux/serial_core.h>
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/rtnetlink.h>
+#include <linux/delay.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/completion.h>
+#include <linux/crc32.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <asm/atomic.h>
+#include <linux/timer.h>
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/rmi_pcix_gen_host.h>
+#include <asm/rmi/devices.h>
+#else
+#include "rmi_pcix_gen_host.h"
+#endif
+
+
+#define DRIVER_VERSION "v0.1"
+#define DRIVER_AUTHOR "RMI-INDIA"
+#define DRIVER_DESC "console over pci"
+#define BUF_SIZE (1024*4)
+#define PHNX_USER_CMD_SIZE (1*1024)
+#define PHNX_USER_RESULT_SIZE (7*1024)
+
+/* Module information */
+MODULE_AUTHOR( DRIVER_AUTHOR );
+MODULE_DESCRIPTION( DRIVER_DESC );
+MODULE_LICENSE("GPL");
+
+#define DELAY_TIME  2	/* 2 seconds per character */
+
+#ifndef CONFIG_RMI_PHOENIX
+#define XLR_CONSOLE_OVER_PCI_MAJOR 246
+#endif
+#define CONSOLE_OVER_PCI_MINORS	244	/* only have one minor */
+#define UART_NR			1	/* only use one port */
+
+#define CONSOLE_OVER_PCI	"pci_console"
+
+
+#define Message(a,b...) //printk("Function [%s]"a"\n",__FUNCTION__,##b)
+#define ErrorMsg(a,b...) printk("Function [%s]"a"\n",__FUNCTION__,##b)
+
+static volatile u32 *phnx_user_cmd_producer;
+static volatile u32 *phnx_user_cmd_consumer;
+static volatile u32 *phnx_user_result_consumer;
+static volatile u32 *phnx_user_result_producer;
+static volatile u8 *phnx_user_cmd;
+static volatile u8 *phnx_user_result;
+static volatile u32 *phnx_dev_status;
+static volatile u32 *phnx_host_status;
+static int phnx_pcix_dev_up=0;
+
+extern unsigned long phnx_get_shared_mem_base_host(void);
+static struct timer_list *phnx_timer=NULL;
+extern void phnx_pci_writel(unsigned int  data,unsigned int *addr);
+extern void phnx_pci_writeb(unsigned char data, unsigned int *addr);
+
+unsigned int rmi_phnx_readl(unsigned int *base)
+{
+  return (phnx_pci_readl(base));
+}
+
+static void get_user_data(struct uart_port *port)
+{
+  u32 next_consumer;
+  u8 ch;
+  struct tty_struct *tty;
+  int flag=0;
+  
+  
+  phnx_pcix_dev_up=1;
+  Message("\nGot MSI - phnx_pcix_dev_up iz %d\n",phnx_pcix_dev_up);
+  
+  if (!port){
+    ErrorMsg("port is nt there...");
+    return;
+  }
+
+  tty = port->state->port.tty;
+  if (!tty){
+    ErrorMsg("tty is nt thr...");
+    return;
+  }
+
+  /* Read The Data And Push It To TTY Buffer */
+
+  next_consumer = rmi_phnx_readl((uint32_t *)phnx_user_result_consumer);
+  Message("next_consumer [%d]",next_consumer);
+  Message("phnx_user_result_producer [%d]",
+		rmi_phnx_readl((uint32_t *)phnx_user_result_producer));
+  tty->low_latency = 1;
+  while(next_consumer != rmi_phnx_readl((uint32_t *)phnx_user_result_producer)){
+    ch = phnx_pci_readb((u8 *)(phnx_user_result + next_consumer));
+    tty_insert_flip_char(tty, ch, TTY_NORMAL);
+    tty_flip_buffer_push(tty);  
+    flag = 1;
+    next_consumer = (next_consumer + 1) % (PHNX_USER_RESULT_SIZE);
+
+    Message("next_consumer [%d]",next_consumer);
+    Message("phnx_user_result_producer [%d]",rmi_phnx_readl((uint32_t *)phnx_user_result_producer));
+  }
+  
+  
+  if(flag)
+    phnx_pci_writel(next_consumer,(uint32_t *)phnx_user_result_consumer);
+  
+  return;
+}
+#ifdef CONFIG_RMI_PHOENIX
+static void rmi_pcix_console_stop_tx(struct uart_port *port)
+#else
+static void rmi_pcix_console_stop_tx(struct uart_port *port, unsigned int tty_stop)
+#endif
+{
+	Message("");
+}
+
+static void rmi_pcix_console_stop_rx(struct uart_port *port)
+{
+	Message("");
+}
+
+static void rmi_pcix_console_enable_ms(struct uart_port *port)
+{
+	Message("");
+}
+
+static int rmi_host_put_char(char ch)
+{
+  u32 next_producer=0;
+ 
+  Message("-- Called"); 
+  next_producer = rmi_phnx_readl((uint32_t *)phnx_user_cmd_producer);
+
+  if(((next_producer + 1) % PHNX_USER_CMD_SIZE) == rmi_phnx_readl((uint32_t *)phnx_user_cmd_consumer)){
+      Message("in if cond\n");
+      return 0;
+  }
+
+  phnx_pci_writeb(ch,(void *)(phnx_user_cmd + next_producer));
+
+  next_producer = (next_producer + 1) % (PHNX_USER_CMD_SIZE);
+
+  phnx_pci_writel((next_producer),(uint32_t *)phnx_user_cmd_producer);
+  
+  Message("next_producer [%u] phnx_user_cmd_producer [%p]",
+               next_producer,phnx_user_cmd_producer);
+
+  Message("[%c]",ch);
+
+  return 1;
+
+}
+
+static void rmi_pcix_console_tx_chars(struct uart_port *port)
+{
+	struct circ_buf *xmit = &port->state->xmit;
+	int count;
+
+	if(!phnx_pcix_dev_up)   // Xmit if Device Is Up.
+		return;
+  Message("\nInside TX CHARS\n");	
+	if (port->x_char) {
+		
+		if(!rmi_host_put_char(port->x_char))
+		   return;
+		Message ("DATA [%c] - port->x_char", port->x_char);
+		port->icount.tx++;
+		port->x_char = 0;
+		return;
+	}
+	if (uart_circ_empty(xmit) || uart_tx_stopped(port)) {
+#ifdef CONFIG_RMI_PHOENIX
+		rmi_pcix_console_stop_tx(port);
+#else
+		rmi_pcix_console_stop_tx(port, 0);
+#endif
+		return;
+	}
+
+	count = port->fifosize >> 1;
+	do{
+		Message ("DATA [%c] - do while", xmit->buf[xmit->tail]);
+		
+		if(!rmi_host_put_char(xmit->buf[xmit->tail]))
+		  return;
+		xmit->tail = (xmit->tail + 1) & (UART_XMIT_SIZE - 1);
+		port->icount.tx++;
+		
+		if (uart_circ_empty(xmit))
+			break;
+		
+	}while(--count > 0);
+
+	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS){
+		Message("uart write wakeup");
+		uart_write_wakeup(port);
+	}
+
+	if (uart_circ_empty(xmit))
+#ifdef CONFIG_RMI_PHOENIX
+		rmi_pcix_console_stop_tx(port);
+#else
+		rmi_pcix_console_stop_tx(port, 0);
+#endif
+	else
+	   Message("xmit->tail [%d] != xmit->head = [%d]",xmit->tail,
+			   xmit->head);
+}
+
+#ifdef CONFIG_RMI_PHOENIX
+static void rmi_pcix_console_start_tx(struct uart_port *port)
+#else
+static void rmi_pcix_console_start_tx(struct uart_port *port, unsigned int tty_start)
+#endif
+{
+	Message("");
+}
+
+static void rmi_pcix_console_timer (unsigned long data)
+{
+	struct uart_port *port;
+
+
+	port = (struct uart_port *)data;
+	if (!port){
+		ErrorMsg("port is nt there...");
+		return;
+	}
+
+	/* see if we have any data to transmit */
+	rmi_pcix_console_tx_chars(port);
+ 
+        /* see if nythin to rcv */
+//	if(phnx_pci_readl((uint32_t *)phnx_dev_status) == 0xdeadbeef)
+	get_user_data(port);
+	/* resubmit the timer again */
+	phnx_timer->expires = jiffies + DELAY_TIME;
+	add_timer (phnx_timer);
+}
+
+static unsigned int rmi_pcix_console_tx_empty(struct uart_port *port)
+{
+	return 1;
+}
+
+static unsigned int rmi_pcix_console_get_mctrl(struct uart_port *port)
+{
+	return port->mctrl;
+}
+
+static void rmi_pcix_console_set_mctrl(struct uart_port *port, unsigned int mctrl)
+{
+  port->mctrl = mctrl;
+}
+
+static void rmi_pcix_console_break_ctl(struct uart_port *port, int break_state)
+{
+}
+
+static int rmi_pcix_console_startup(struct uart_port *port)
+{
+	/* this is the first time this port is opened */
+	/* do any hardware initialization needed here */
+
+	/* create our timer and submit it */
+
+  Message("Open Called..");	
+  if (!phnx_timer) {
+	  phnx_timer = kmalloc (sizeof(*phnx_timer), GFP_KERNEL);
+	  if (!phnx_timer)
+		  return -ENOMEM;
+	  Message("\nRequest Msi Handler Returned..\n");
+  }
+  init_timer(phnx_timer);
+  phnx_timer->data = (unsigned long )port;
+  phnx_timer->expires = jiffies + DELAY_TIME;
+  phnx_timer->function = rmi_pcix_console_timer;
+
+
+  Message("Opening Port");
+  phnx_pci_writel(0xdeadbeef,(uint32_t *)phnx_host_status);
+
+  add_timer (phnx_timer);
+  return 0;
+}
+
+static void rmi_pcix_console_shutdown(struct uart_port *port)
+{
+  /* The port is being closed by the last user. */
+  /* Do any hardware specific stuff here */
+
+  /* shut down our timer */
+  Message("Close Called");
+  Message("\nGoin To Free MSI HANDLER Index %d\n",index);
+  if(phnx_timer){
+  	del_timer_sync(phnx_timer);
+  	kfree(phnx_timer);
+  }
+  phnx_timer = NULL;
+  phnx_pci_writel(0,(uint32_t *)phnx_host_status);
+  Message("phnx_host_status 2 written");
+}
+
+static const char *rmi_pcix_console_type(struct uart_port *port)
+{
+  return "rmi_pcix_consoletty";
+}
+
+static void rmi_pcix_console_release_port(struct uart_port *port)
+{
+
+}
+
+static int rmi_pcix_console_request_port(struct uart_port *port)
+{
+  return 0;
+}
+
+static void rmi_pcix_console_config_port(struct uart_port *port, int flags)
+{
+}
+
+static int rmi_pcix_console_verify_port(struct uart_port *port, struct serial_struct *ser)
+{
+  return 0;
+}
+static void
+rmi_pcix_console_set_termios(struct uart_port *port, struct ktermios *termios,
+		       struct ktermios *old)
+{
+	return;
+}
+static struct uart_ops rmi_pcix_console_ops = {
+  .tx_empty	= rmi_pcix_console_tx_empty,
+  .set_mctrl	= rmi_pcix_console_set_mctrl,
+  .get_mctrl	= rmi_pcix_console_get_mctrl,
+  .stop_tx	= rmi_pcix_console_stop_tx,
+  .start_tx	= rmi_pcix_console_start_tx,
+  .stop_rx	= rmi_pcix_console_stop_rx,
+  .enable_ms	= rmi_pcix_console_enable_ms,
+  .break_ctl	= rmi_pcix_console_break_ctl,
+  .startup	= rmi_pcix_console_startup,
+  .shutdown	= rmi_pcix_console_shutdown,
+  .set_termios  = rmi_pcix_console_set_termios,
+  .type		= rmi_pcix_console_type,
+  .release_port	= rmi_pcix_console_release_port,
+  .request_port	= rmi_pcix_console_request_port,
+  .config_port	= rmi_pcix_console_config_port,
+  .verify_port	= rmi_pcix_console_verify_port,
+};
+
+static struct uart_port rmi_pcix_console_port = {
+  .ops		= &rmi_pcix_console_ops,
+  .type 	= PORT_8250,
+  .fifosize	= 255,
+};
+
+static struct uart_driver rmi_pcix_console_reg = {
+  .owner  = THIS_MODULE,
+  .driver_name  = CONSOLE_OVER_PCI,
+  .dev_name  = CONSOLE_OVER_PCI,
+  .major  = XLR_CONSOLE_OVER_PCI_MAJOR,
+  .minor  = CONSOLE_OVER_PCI_MINORS,
+  .nr  = UART_NR,
+};
+
+
+static int __init rmi_pcix_console_init(void)
+{
+  int result;
+
+#ifdef CONFIG_RMI_PHOENIX
+  if(rmi_get_pci_mode() == XLR_PCI_DEV_MODE){
+    return -EIO;
+  }
+#endif
+  if(phnx_get_shared_mem_base_host() == 0){
+    printk("\nLooks like device is not connected.\n");
+    return -ENODEV; 
+  }
+  result = uart_register_driver(&rmi_pcix_console_reg);
+  if (result){
+    ErrorMsg("Cant Register Driver");
+    return result;
+  }
+
+  result = uart_add_one_port(&rmi_pcix_console_reg, &rmi_pcix_console_port);
+		
+  if (result){
+    ErrorMsg("Cant Add Port");	  
+    uart_unregister_driver(&rmi_pcix_console_reg);
+    return result;
+  }
+  Message("Returning From init_module [%d]",result);
+  
+  phnx_user_cmd = (u8 *)phnx_get_shared_mem_base_host() + 
+                   PHNX_CONSOLE_OVER_PCI_SHARED_MEM_BASE;
+  phnx_user_result = phnx_user_cmd + PHNX_USER_CMD_SIZE;
+  phnx_user_cmd_producer = (u32 *)(phnx_user_result + PHNX_USER_RESULT_SIZE);
+  phnx_user_cmd_consumer = phnx_user_cmd_producer + 1;
+  phnx_user_result_consumer= phnx_user_cmd_consumer + 1;
+  phnx_user_result_producer= phnx_user_result_consumer + 1;
+
+  phnx_dev_status  = phnx_user_result_producer + 1;
+  phnx_host_status = phnx_dev_status + 1;
+
+  Message("\nphnx_user_cmd @ %#x\n",(uint32_t)phnx_user_cmd);
+  Message("phnx_user_result @ %#x\n",(uint32_t )phnx_user_result);
+  Message("phnx_user_cmd_producer @ %#x\n",(uint32_t )phnx_user_cmd_producer);
+  Message("phnx_user_cmd_consumer @ %#x\n",(uint32_t )phnx_user_cmd_consumer);
+  Message("phnx_user_result_consumer @ %#x\n",
+			(uint32_t )phnx_user_result_consumer);
+  Message("phnx_user_result_producer @ %#x\n",
+				(uint32_t )phnx_user_result_producer);
+  Message("*phnx_user_cmd %#x\n",(uint32_t )*phnx_user_cmd);
+  Message("phnx_dev_status %#x\n",(uint32_t)phnx_dev_status);
+  Message("phnx_host_status %#x\n",(uint32_t)phnx_host_status);
+
+  phnx_pci_writel(0,(uint32_t *)phnx_user_result_producer);
+  phnx_pci_writel(0,(uint32_t *)phnx_user_result_consumer);
+  phnx_pci_writel(0,(uint32_t *)phnx_user_cmd_producer);
+  phnx_pci_writel(0,(uint32_t *)phnx_user_cmd_consumer);
+  phnx_pci_writel(0,(uint32_t *)phnx_host_status);
+  printk("xlr_console_over_pci: registerd successfully.\n");
+  return 0;
+}
+
+static void __exit rmi_pcix_console_cleanup(void)
+{
+  uart_remove_one_port(&rmi_pcix_console_reg, &rmi_pcix_console_port);
+  uart_unregister_driver(&rmi_pcix_console_reg);
+}
+
+module_init(rmi_pcix_console_init);
+module_exit(rmi_pcix_console_cleanup);
diff --git a/drivers/char/xlr_virtual_uart.c b/drivers/char/xlr_virtual_uart.c
new file mode 100644
index 0000000..8e4b0fc
--- /dev/null
+++ b/drivers/char/xlr_virtual_uart.c
@@ -0,0 +1,396 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/console.h>
+#include <linux/pci.h>
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/tty.h>
+#include <linux/tty_flip.h>
+#include <linux/serial.h>
+#include <linux/serial_core.h>
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/rtnetlink.h>
+#include <linux/delay.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/completion.h>
+#include <linux/crc32.h>
+#include <asm/io.h>
+#include <asm/uaccess.h>
+#include <asm/atomic.h>
+#include <linux/timer.h>
+#include <asm/rmi/rmi_pcix_gen_dev.h>
+#include <asm/rmi/devices.h>
+#include <asm/rmi/xlr_virt_uart.h>
+
+#define RX_THRESHOLD 10
+#define DRIVER_VERSION "v0.1"
+#define DRIVER_AUTHOR "RMI"
+#define DRIVER_DESC "Virtual uart serial console driver for Arizona3"
+
+#define Message(a,b...) //printk("Function [%s]"a"\n",__FUNCTION__,##b)
+#define ErrorMsg(a,b...) printk("Function [%s]"a"\n",__FUNCTION__,##b)
+
+virt_uart_struct virt_uart_tx_rx[32];
+
+extern uint32_t rmik_en;
+static struct timer_list *timer[32];
+
+extern int xlr_loader_support;
+
+static struct uart_driver virtual_uart_console_reg = {
+  	.owner  = THIS_MODULE,
+	.driver_name  = VIRTUAL_UART_CONSOLE,
+  	.dev_name  = "virt_uart",
+  	.major  = VIRTUAL_UART_CONSOLE_MAJOR,
+  	.minor  = VIRTUAL_UART_CONSOLE_MINOR,
+  	.nr  = VIRTUAL_UART_NR,
+};
+
+static int virtual_uart_console_request_port(struct uart_port *port) 
+{
+ 	return 0;
+}
+
+static void virtual_uart_console_config_port(struct uart_port *port, int flags)
+{
+}
+
+static int virtual_uart_console_verify_port(struct uart_port *port, struct serial_struct *ser)
+{
+  	return 0;
+}
+
+static void virtual_uart_console_release_port(struct uart_port *port)
+{
+
+}
+
+static const char *virtual_uart_console_type(struct uart_port *port)
+{
+  	return "rmi_virtual_uart_consoletty";
+}
+
+static void virtual_uart_console_set_termios(struct uart_port *port, 
+			struct ktermios *termios, struct ktermios *old)
+{
+        return;
+}
+
+static unsigned int virtual_uart_console_tx_empty(struct uart_port *port)
+{
+        return 1;
+}
+
+static unsigned int virtual_uart_console_get_mctrl(struct uart_port *port)
+{
+        return port->mctrl;
+}
+
+static void virtual_uart_console_set_mctrl(struct uart_port *port, unsigned int mctrl)
+{
+  	port->mctrl = mctrl;
+}
+
+static void virtual_uart_console_break_ctl(struct uart_port *port, int break_state)
+{
+}
+
+static void virtual_uart_console_start_tx(struct uart_port *port)
+{
+        Message("");
+}
+
+static void virtual_uart_console_stop_tx(struct uart_port *port)
+{
+        Message("");
+}
+
+static void virtual_uart_console_stop_rx(struct uart_port *port)
+{
+        Message("");
+}
+
+static void virtual_uart_console_enable_ms(struct uart_port *port)
+{
+        Message("");
+}
+
+static int virtual_uart_console_startup(struct uart_port *port);
+static void virtual_uart_console_shutdown(struct uart_port *port);
+
+static struct uart_ops virtual_uart_console_ops = {
+  	.tx_empty     = virtual_uart_console_tx_empty,
+  	.set_mctrl    = virtual_uart_console_set_mctrl,
+  	.get_mctrl    = virtual_uart_console_get_mctrl,
+  	.stop_tx      = virtual_uart_console_stop_tx,
+  	.start_tx     = virtual_uart_console_start_tx,
+  	.stop_rx      = virtual_uart_console_stop_rx,
+  	.enable_ms    = virtual_uart_console_enable_ms,
+  	.break_ctl    = virtual_uart_console_break_ctl,
+  	.startup      = virtual_uart_console_startup,
+  	.shutdown     = virtual_uart_console_shutdown,
+  	.set_termios  = virtual_uart_console_set_termios,
+  	.type         = virtual_uart_console_type,
+  	.release_port = virtual_uart_console_release_port,
+  	.request_port = virtual_uart_console_request_port,
+  	.config_port  = virtual_uart_console_config_port,
+  	.verify_port  = virtual_uart_console_verify_port,
+};
+
+
+static struct uart_port virtual_uart_console_port [VIRTUAL_UART_NR] = {
+  	[0 ... VIRTUAL_UART_NR-1] = {
+  	.ops          = &virtual_uart_console_ops,
+  	.type         = PORT_8250,
+  	.fifosize     = 255,
+  	}
+};
+
+static void virtual_uart_console_rx_chars(struct uart_port *port)
+{
+  	struct tty_struct *tty;
+  	char ch;
+	int rx_cnt = 0;
+	if (*(virt_uart_tx_rx[port->line].rx_pro) == *(virt_uart_tx_rx[port->line].rx_con))
+		return;
+     
+  	tty = port->state->port.tty;
+  	if (!tty){
+          	ErrorMsg("tty is nt thr...");
+          	return;
+  	}
+
+  	tty->low_latency = 1;
+  	do{     
+	
+		ch = *((virt_uart_tx_rx[port->line].rx_fifo) + (*(virt_uart_tx_rx[port->line].rx_con)));
+		tty_insert_flip_char(tty, ch, TTY_NORMAL); 
+    		tty_flip_buffer_push(tty);
+		*(virt_uart_tx_rx[port->line].rx_con) = (*(virt_uart_tx_rx[port->line].rx_con) + 1) % (USER_RESULT_SIZE);
+
+		if(rx_cnt++ > RX_THRESHOLD)
+			break;
+  	}while(*(virt_uart_tx_rx[port->line].rx_pro) != *(virt_uart_tx_rx[port->line].rx_con));
+
+}
+
+static int rmi_cmd_put_char(char ch, int thrd_id)
+{
+
+  	Message("-- Called");
+	Message("\nXmitting [%d]\n",ch);
+	
+	if(((*(virt_uart_tx_rx[thrd_id].tx_pro) + 1) % USER_CMD_SIZE ) == (*(virt_uart_tx_rx[thrd_id].tx_con)))	
+		return -1;
+
+   	*((virt_uart_tx_rx[thrd_id].tx_fifo) + *(virt_uart_tx_rx[thrd_id].tx_pro)) = ch;
+
+	*(virt_uart_tx_rx[thrd_id].tx_pro) = (*(virt_uart_tx_rx[thrd_id].tx_pro) + 1) % (USER_CMD_SIZE);
+	return 0;
+}
+
+
+/* Take the data(command) from the user and write it in to the Tx buf buffer.*/
+static void virtual_uart_console_tx_chars(struct uart_port *port)
+{
+        struct circ_buf *xmit = &port->state->xmit; 
+        int count;
+
+        if (port->x_char) {
+
+               	if(rmi_cmd_put_char(port->x_char, port->line))
+			return;
+                port->icount.tx++;
+                port->x_char = 0;
+                return;
+        }
+        if (uart_circ_empty(xmit) || uart_tx_stopped(port)) {
+                virtual_uart_console_stop_tx(port);
+                return;
+        }
+
+        count = port->fifosize >> 1;
+        do{
+		if(rmi_cmd_put_char(xmit->buf[xmit->tail], port->line))
+			break;
+                xmit->tail = (xmit->tail + 1) & (UART_XMIT_SIZE - 1);
+                port->icount.tx++;
+
+                if (uart_circ_empty(xmit))
+                        break;
+
+        }while(--count > 0);
+
+
+        if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS){
+                uart_write_wakeup(port);
+        }
+}
+
+
+static void virtual_uart_console_timer (unsigned long data)
+{
+        struct uart_port *port;
+
+        port = (struct uart_port *)data;
+        if (!port){
+                ErrorMsg("port is nt there...");
+                return;
+        }
+        if (!port->state){
+                ErrorMsg("port->info is nt there... ");
+                return;
+        }
+
+        /* see if we have any data for rx*/
+        virtual_uart_console_rx_chars(port);
+        /* see if we have any data to transmit */
+        virtual_uart_console_tx_chars(port);
+        /* resubmit the timer again */
+        timer[port->line]->expires = jiffies + DELAY_TIME;
+        add_timer (timer[port->line]);
+}
+
+static int virtual_uart_console_startup(struct uart_port *port)
+{
+  	/* this is the first time this port is opened */
+  	/* do any hardware initialization needed here */
+
+  	/* create our timer and submit it */
+
+  	Message("Open Called..");
+  	if (!timer[port->line]) {
+          	timer[port->line] = kmalloc (sizeof(*timer[port->line]), GFP_KERNEL);
+          	if (!timer[port->line])
+                  	return -ENOMEM;
+  	}
+  	init_timer(timer[port->line]);
+  	timer[port->line]->data = (unsigned long )port;
+  	timer[port->line]->expires = jiffies + DELAY_TIME;
+  	timer[port->line]->function = virtual_uart_console_timer;
+  	Message("Opening Port");
+	*(virt_uart_tx_rx[port->line].tx_pro) = 0;
+	*(virt_uart_tx_rx[port->line].tx_con) = 0;
+	*(virt_uart_tx_rx[port->line].rx_pro) = 0;
+	*(virt_uart_tx_rx[port->line].rx_con) = 0;
+  	add_timer(timer[port->line]);
+	*(virt_uart_tx_rx[port->line].status) = VIRT_UART_OPENED;
+  	return 0;
+}
+
+
+static int __init virtual_uart_init(void)
+{
+	int result, i, size;
+  	unsigned int line;
+
+	if (xlr_loader_support == 0)	{
+		return 0;
+	}
+	if(rmik_en)
+		return 0;
+
+  	result = uart_register_driver(&virtual_uart_console_reg);
+
+  	if (result){
+    		ErrorMsg("Cant Register Driver");
+    		return result;
+  	}
+  
+  	for (line=0; line < VIRTUAL_UART_NR; line++){
+        	virtual_uart_console_port[line].line = line;
+        	result = uart_add_one_port(&virtual_uart_console_reg, &virtual_uart_console_port[line]);
+
+        	if (result){
+                	for(; line > 0; line--) {
+                        	virtual_uart_console_port[line].line = line;
+                        	uart_remove_one_port(&virtual_uart_console_reg, &virtual_uart_console_port[line]);
+                	}
+			virtual_uart_console_port[line].line = line;
+			uart_remove_one_port(&virtual_uart_console_reg, &virtual_uart_console_port[line]);
+                	uart_unregister_driver(&virtual_uart_console_reg);
+                	return result;
+        	}
+  	}
+
+  
+  	size = USER_CMD_SIZE + 4 + 4 + USER_RESULT_SIZE + 4 + 4 + 4;
+
+  	for (i=0; i<VIRTUAL_UART_NR; i++){
+        	virt_uart_tx_rx[i].tx_fifo = i*size + (unsigned char *) VIRT_UART_BUF_START;
+        	virt_uart_tx_rx[i].tx_pro = (unsigned int *) (virt_uart_tx_rx[i].tx_fifo + USER_CMD_SIZE); 
+        	virt_uart_tx_rx[i].tx_con = (unsigned int *) (virt_uart_tx_rx[i].tx_pro + 1);
+        	virt_uart_tx_rx[i].rx_fifo = (unsigned char *) (virt_uart_tx_rx[i].tx_con + 1);
+        	virt_uart_tx_rx[i].rx_pro = (unsigned int *) (virt_uart_tx_rx[i].rx_fifo + USER_RESULT_SIZE); 
+        	virt_uart_tx_rx[i].rx_con = (unsigned int *) (virt_uart_tx_rx[i].rx_pro + 1);
+		virt_uart_tx_rx[i].status = (unsigned int *) (virt_uart_tx_rx[i].rx_con + 1);
+		*(virt_uart_tx_rx[i].tx_pro) = *(virt_uart_tx_rx[i].tx_con) = 
+		*(virt_uart_tx_rx[i].rx_pro) = *(virt_uart_tx_rx[i].rx_con) = 0;
+		*(virt_uart_tx_rx[i].status) = 0;
+  	}
+
+  	return 0;
+}
+
+static void virtual_uart_console_shutdown(struct uart_port *port)
+{
+  	/* The port is being closed by the last user. */
+  	/* Do any hardware specific stuff here */
+
+  	/* shut down our timer */
+  	Message("Close Called");
+	*(virt_uart_tx_rx[port->line].status) = 0;
+  	del_timer_sync(timer[port->line]);
+}
+
+
+static void __exit virtual_uart_console_cleanup(void)
+{
+  	int line;
+
+  	for (line=0; line < VIRTUAL_UART_NR; line++)  {
+		virtual_uart_console_port[line].line = line;
+        	uart_remove_one_port(&virtual_uart_console_reg, &virtual_uart_console_port[line]);
+  	}
+  	uart_unregister_driver(&virtual_uart_console_reg);
+}
+
+module_init(virtual_uart_init);
+module_exit(virtual_uart_console_cleanup);
+
+
+
diff --git a/drivers/crypto/Kconfig b/drivers/crypto/Kconfig
index 7a356fe..4b1bdcd 100644
--- a/drivers/crypto/Kconfig
+++ b/drivers/crypto/Kconfig
@@ -355,4 +355,15 @@ config CRYPTO_DEV_ATMEL_TEST
 	  To compile this driver as a module, choose M here: the module
 	  will be called atmel-test.
 
+config CRYPTO_XLR
+	tristate "Support for the XLR Security engine"
+	depends on CRYPTO && RMI_PHOENIX 
+	default Y
+	help
+	  Say 'Y' here to use the XLR hardware Security engine for the 
+	  Crypto operations.
+
+	  To compile this driver as a module, choose M here: the module
+	  will be called xlr_sec.
+
 endif # CRYPTO_HW
diff --git a/drivers/crypto/rmi/Makefile b/drivers/crypto/rmi/Makefile
new file mode 100644
index 0000000..8c12ca1
--- /dev/null
+++ b/drivers/crypto/rmi/Makefile
@@ -0,0 +1,2 @@
+obj-$(CONFIG_CRYPTO_XLR) += xlr_sec.o
+xlr_sec-objs := common/sec_api.o rmisec.o rmi_auth.o rmi_enc.o
diff --git a/drivers/crypto/rmi/ecc_ucode_data.h b/drivers/crypto/rmi/ecc_ucode_data.h
new file mode 100644
index 0000000..6a99a9d
--- /dev/null
+++ b/drivers/crypto/rmi/ecc_ucode_data.h
@@ -0,0 +1,363 @@
+/***********************************************************************
+Copyright 2003-2009 RMI Corporation (RMI) All rights reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY RMI Corporation. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************_ RMI_2_**********************************/
+#ifndef ECC_UCODE_DATA_H
+#define ECC_UCODE_DATA_H
+static const uint64_t ecc_msg0 = 0xc07c000000000010ULL;
+static const uint64_t ecc_msg1 = 0xa000000000000000ULL;
+
+static uint64_t ecc_uc_data [] __attribute__((aligned(32))) = {
+    0x0000000022000006ULL,
+    0x0000000022000009ULL,
+    0x0000000022000288ULL,
+    0x220000232200028fULL,
+    0x2200028f24000000ULL,
+    0x2400000022000062ULL,
+    0x0000000022000240ULL,
+    0x000000002200022fULL,
+    0x0000000022000213ULL,
+    0x0000000022000225ULL,
+    0x0000000022000239ULL,
+    0x0000000022000248ULL,
+    0x000000002200025eULL,
+    0x000000002200001eULL,
+    0x000000002200027eULL,
+    0x4518400008c00001ULL,
+    0x4308868044184400ULL,
+    0x220000ae2000010dULL,
+    0x4500c3c0220000bcULL,
+    0x10c0000050d07e00ULL,
+    0x08a0010043004780ULL,
+    0x21a0003415ba8000ULL,
+    0x15ba800008a00200ULL,
+    0x68d0fa0021a00034ULL,
+    0x4400478031600032ULL,
+    0x3100003650b0f200ULL,
+    0x2000003b50b0fa00ULL,
+    0x50d07e004500c3c0ULL,
+    0x14ba800010c00000ULL,
+    0x3300006120000040ULL,
+    0x2200015028a00040ULL,
+    0x2000005f22000084ULL,
+    0x68b0fa0028a00048ULL,
+    0x08c0000131600045ULL,
+    0x220001ad2000004eULL,
+    0x2000005f2200008bULL,
+    0x08c0000110a00000ULL,
+    0x68f0fa0008e00000ULL,
+    0x08c000003360004eULL,
+    0x220001ad10a00000ULL,
+    0x11a000002200007dULL,
+    0x6890fa0008800001ULL,
+    0x23c000593160005bULL,
+    0x08c000012200008bULL,
+    0x220001502000005bULL,
+    0x220001ad22000084ULL,
+    0x108000002200007dULL,
+    0x2200009228a00053ULL,
+    0x24000000220000a0ULL,
+    0x220000ae4008dc00ULL,
+    0x2200020040185000ULL,
+    0x4018120040180380ULL,
+    0x2200020040184000ULL,
+    0x220001f940181200ULL,
+    0x4018320040180340ULL,
+    0x220001f94010d800ULL,
+    0x220001f940181200ULL,
+    0x40183a00401802c0ULL,
+    0x220001f94010d800ULL,
+    0x22000248d0005c00ULL,
+    0x22000248d0006c00ULL,
+    0x50988000d8007400ULL,
+    0x40182a0024000000ULL,
+    0x40186800401840c0ULL,
+    0x4018a800401802c0ULL,
+    0x24000000401804c0ULL,
+    0x4018408040182200ULL,
+    0x4018028040186000ULL,
+    0x401804804018a000ULL,
+    0x40182a0024000000ULL,
+    0x4018680040184080ULL,
+    0x4018a80040180280ULL,
+    0x2400000040180480ULL,
+    0x4418400040181200ULL,
+    0x40180200220001f9ULL,
+    0x4018500040184080ULL,
+    0x220001f944180200ULL,
+    0x4018900040180280ULL,
+    0x220001f944180200ULL,
+    0x2400000040180480ULL,
+    0x4018900040181400ULL,
+    0x40188080220000a9ULL,
+    0x4018900040185400ULL,
+    0x40188280220000a9ULL,
+    0x08c0000024000000ULL,
+    0x430887004010c200ULL,
+    0x24000000220000caULL,
+    0x4010d80040181200ULL,
+    0x40180200220001f9ULL,
+    0x4018500040184080ULL,
+    0x220001f94010da00ULL,
+    0x4018900040180280ULL,
+    0x220001f94010da00ULL,
+    0x2400000040180480ULL,
+    0x4010d80040181a00ULL,
+    0x40180200220001f9ULL,
+    0x40185800401840c0ULL,
+    0x220001f94010da00ULL,
+    0x40189800401802c0ULL,
+    0x220001f94010da00ULL,
+    0x24000000401804c0ULL,
+    0x4010c20008800000ULL,
+    0x200000d023c000ceULL,
+    0x200000d708c00000ULL,
+    0x50a18a00d8004440ULL,
+    0x688804003300010cULL,
+    0x41180440336000dfULL,
+    0x6888860040188800ULL,
+    0x41008240336000dcULL,
+    0x200000d040014c00ULL,
+    0x41180c00d010c040ULL,
+    0x68804400200000d0ULL,
+    0x41184440336000ecULL,
+    0x6888e40040188a00ULL,
+    0x4100e440336000e8ULL,
+    0x200000d040018f00ULL,
+    0xd011c0404000e440ULL,
+    0x200000d041110f00ULL,
+    0x334000fcd8004440ULL,
+    0xd810e04041088800ULL,
+    0x314000f440090c00ULL,
+    0x40180c00d010c040ULL,
+    0x336000f968888700ULL,
+    0x40180c0041188040ULL,
+    0xd010c040200000d0ULL,
+    0x200000d041180c00ULL,
+    0x41008a00d8080440ULL,
+    0x40090f00d81c8040ULL,
+    0xd001c44031400103ULL,
+    0x6888e40040018f00ULL,
+    0x4100e44033600108ULL,
+    0x200000d040018f00ULL,
+    0xd011c0404000e440ULL,
+    0x200000d041100f00ULL,
+    0x0880000024000000ULL,
+    0x23c001114010c200ULL,
+    0x08c0000020000113ULL,
+    0xd80044402000011aULL,
+    0x3300014f50a18a00ULL,
+    0x3360012268880400ULL,
+    0x4018880041180440ULL,
+    0x3360011f68888600ULL,
+    0x40014c0041008240ULL,
+    0xd010c04020000113ULL,
+    0x2000011341180c00ULL,
+    0x3360012f68804400ULL,
+    0x40188a0041184440ULL,
+    0x3360012b6888d400ULL,
+    0x40018e804100d440ULL,
+    0x4000d44020000113ULL,
+    0x41110e80d011c040ULL,
+    0xd800444020000113ULL,
+    0x410888003340013fULL,
+    0x40090c00d810d040ULL,
+    0xd010c04031400137ULL,
+    0x6888868040180c00ULL,
+    0x411880403360013cULL,
+    0x2000011340180c00ULL,
+    0x41180c00d010c040ULL,
+    0xd808044020000113ULL,
+    0xd81a804041008a00ULL,
+    0x3140014640090e80ULL,
+    0x40018e80d001c440ULL,
+    0x3360014b6888d400ULL,
+    0x40018e804100d440ULL,
+    0x4000d44020000113ULL,
+    0x41100e80d011c040ULL,
+    0x2400000020000113ULL,
+    0x4018980040101200ULL,
+    0x40080700220001f9ULL,
+    0x4008900040101a00ULL,
+    0x40100300220001f9ULL,
+    0x22000207d80ce400ULL,
+    0xd00ce40040180500ULL,
+    0x4008054022000248ULL,
+    0x220002004018a000ULL,
+    0x4000a20040100740ULL,
+    0x40080780220001f9ULL,
+    0x4000aa004010e800ULL,
+    0x40100340220001f9ULL,
+    0x40189a0040185000ULL,
+    0x40180580220001f9ULL,
+    0x4018920040185800ULL,
+    0x40100700220001f9ULL,
+    0x40187400d81cb380ULL,
+    0x4010038022000207ULL,
+    0x40180400d01cb000ULL,
+    0x401003c022000248ULL,
+    0x2200020040107000ULL,
+    0x401845c040100200ULL,
+    0x40189a0040189000ULL,
+    0x40100700220001f9ULL,
+    0x220001f94018ba00ULL,
+    0xd8006c0040080740ULL,
+    0x4018a20022000207ULL,
+    0x40180200220001f9ULL,
+    0x4210680040184100ULL,
+    0x2200024840180400ULL,
+    0x22000248d00d0400ULL,
+    0x4208ec0040180500ULL,
+    0x4018020022000248ULL,
+    0x40180400d8144000ULL,
+    0x4018020022000207ULL,
+    0x220001f940187000ULL,
+    0x4018780040180500ULL,
+    0x220001f94000f200ULL,
+    0x4000ec00d8140740ULL,
+    0x4010074022000207ULL,
+    0x68f0e80008e00000ULL,
+    0x200001a7336001a4ULL,
+    0xd008e8004010c200ULL,
+    0x4110eb0040100740ULL,
+    0x4010f2004008e000ULL,
+    0x40080500220001f9ULL,
+    0x40009a0024000000ULL,
+    0x220001f940185800ULL,
+    0x2200024842080400ULL,
+    0x40101a0040080540ULL,
+    0x2200020040104000ULL,
+    0x4210020040100780ULL,
+    0x2200024840004400ULL,
+    0x22000248d000f400ULL,
+    0x4018980040180580ULL,
+    0x401804c022000200ULL,
+    0x4010d80040183200ULL,
+    0x40189a00220001f9ULL,
+    0xd0160200220001f9ULL,
+    0x2200024840004400ULL,
+    0x40101a0040180580ULL,
+    0x220001f940105800ULL,
+    0x4018b000401805c0ULL,
+    0x4010038022000200ULL,
+    0x4018ba004018a800ULL,
+    0x401003c0220001f9ULL,
+    0x220002004018a800ULL,
+    0x42187c0040080700ULL,
+    0x4010074022000248ULL,
+    0x2200024842180400ULL,
+    0x40187000401803c0ULL,
+    0x22000207d8007c00ULL,
+    0x220001f94018aa00ULL,
+    0x4018814040180400ULL,
+    0x22000248d00fec00ULL,
+    0x22000207d8007400ULL,
+    0x220001f94018b200ULL,
+    0x40185800401803c0ULL,
+    0x4010e20022000200ULL,
+    0x42180400220001f9ULL,
+    0xd80f040022000248ULL,
+    0x4018034022000207ULL,
+    0x4000e2004018a800ULL,
+    0x40180540220001f9ULL,
+    0xc800440024000000ULL,
+    0xc808c000c910ca00ULL,
+    0x40184c00d1008200ULL,
+    0x2400000022000248ULL,
+    0xc910ca00ca004400ULL,
+    0xd1008200c808c000ULL,
+    0x2200024840184c00ULL,
+    0x3340020924000000ULL,
+    0xd010c0002000020bULL,
+    0x400880002000020cULL,
+    0x3340020f24000000ULL,
+    0xd010c00020000211ULL,
+    0x4008800020000212ULL,
+    0x3340021c24000000ULL,
+    0x08c0000133200220ULL,
+    0xd000440022000257ULL,
+    0xd800c40022000248ULL,
+    0x2000022431400218ULL,
+    0x4310024043104040ULL,
+    0x20000217d0014c00ULL,
+    0x4310024043104040ULL,
+    0x20000217d8014c00ULL,
+    0x2200025724000000ULL,
+    0x3340022b22000251ULL,
+    0x40188000d8188040ULL,
+    0xd81880002000022eULL,
+    0x2000022e40188040ULL,
+    0x4010468024000000ULL,
+    0x4008040022000240ULL,
+    0x400086804010d000ULL,
+    0x4010d20022000240ULL,
+    0x22000244220001f9ULL,
+    0x4018820024000000ULL,
+    0x4018440022000257ULL,
+    0x08c0000043104680ULL,
+    0x240000002200010dULL,
+    0x4010d80040180200ULL,
+    0x24000000220001f9ULL,
+    0x08c000014410c200ULL,
+    0x24000000220001f9ULL,
+    0x2000024c3320024aULL,
+    0x40080c00d810c040ULL,
+    0xd800c40040088000ULL,
+    0x4008800033400250ULL,
+    0xd800440024000000ULL,
+    0x2000025633400254ULL,
+    0xd8004440d8080400ULL,
+    0x4010068024000000ULL,
+    0x2200024840184400ULL,
+    0x4008d40040100200ULL,
+    0x2400000022000248ULL,
+    0x43180a00f8000000ULL,
+    0x4318404043080e40ULL,
+    0x4110c24044184000ULL,
+    0x6a8044005180c400ULL,
+    0xd100440008c00000ULL,
+    0x3340026ed91a88c0ULL,
+    0x401880003300027aULL,
+    0x6a80cc0040188840ULL,
+    0x6b004c0008c00001ULL,
+    0x08c0000033600272ULL,
+    0x41004c4041004400ULL,
+    0x40008a4040008200ULL,
+    0x6d20440021c00278ULL,
+    0x2000026711800000ULL,
+    0x3100026e51c08600ULL,
+    0x240000006a80cc00ULL,
+    0x6b10020008c00003ULL,
+    0xd000c20031600283ULL,
+    0x4118020040184000ULL,
+    0x28c0027f40184000ULL,
+    0x24000000400806c0ULL,
+    0x401032002200028fULL,
+    0x40103a0040104000ULL,
+    0x2200022f40104040ULL,
+    0x2200027e24000000ULL,
+    0x400086802200001eULL,
+    0x440044802200025eULL,
+    0x24000000440044c0ULL,
+    0x0000000000000000ULL,
+};
+#endif /* ECC_UCODE_DATA_H */
diff --git a/drivers/crypto/rmi/rmi_auth.c b/drivers/crypto/rmi/rmi_auth.c
new file mode 100644
index 0000000..a6945f1
--- /dev/null
+++ b/drivers/crypto/rmi/rmi_auth.c
@@ -0,0 +1,459 @@
+/*
+ * Cryptographic API.
+ *
+ * Support for XLR hardware crypto engine.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ */
+
+#include <crypto/algapi.h>
+#include <crypto/sha.h>
+#include <linux/err.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/cryptohash.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/scatterlist.h>
+#include "rmi_state_info.h"
+#include "rmisae.h"
+#include "rmisec_internal.h" 
+
+#define XLR_AUTH_PRIORITY      300
+#define XLR_HMAC_PRIORITY      320
+
+#define MD5_DIGEST_SIZE		16
+#define MD5_BLOCK_SIZE		64
+
+#define AUTH_BUFFER_SIZE	(16 * 1024)
+
+//#define SEC_DEBUG
+
+#ifdef SEC_DEBUG
+#ifdef __KERNEL__
+#define debug_print(fmt, args...) printk(fmt, ##args)
+#else  /* __KERNEL__ */
+#define debug_print(fmt, args...) printf(fmt, ##args)
+#endif /* __KERNEL__ */
+#else /* SEC_DEBUG */
+#define debug_print(fmt, args...)
+#endif /* SEC_DEBUG */
+
+static inline struct xlr_crypt_state* ctx(struct crypto_tfm *tfm)
+{
+	return crypto_tfm_ctx(tfm);
+}
+
+static void xlr_auth_init(struct crypto_tfm *tfm)
+{
+	struct xlr_crypt_state *op = ctx(tfm);
+	op->auth_src = kmalloc(AUTH_BUFFER_SIZE, GFP_KERNEL);
+        debug_print("in func %s\n",__FUNCTION__);
+	op->len = 0;
+}
+
+static void xlr_auth_update(struct crypto_tfm *tfm,
+			const uint8_t *data, unsigned int length)
+{
+	struct xlr_crypt_state *op = ctx(tfm);
+
+	if (!op->auth_src)
+		return;
+	if (op->len + length > AUTH_BUFFER_SIZE)
+		return;
+
+	memcpy(op->auth_src + op->len, data, length);
+	op->len += length;
+        debug_print(KERN_INFO "in func %s\n",__FUNCTION__);
+//	dump_stack();
+
+}
+
+static void xlr_auth_final(struct crypto_tfm *tfm, uint8_t *out)
+{
+	struct xlr_crypt_state *op = ctx(tfm);
+	op_handle_t handle = RMISAE_HANDLE_INITIALIZER;
+	int ret;
+
+	ret = rmisec_op_init(&handle);
+        debug_print("in func %s\n",__FUNCTION__);
+
+	if (ret) {
+		printk("Cannot malloc. returning from %s\n", __FUNCTION__);
+		return; 
+	}
+
+	debug_print(KERN_INFO "hash = %d, hmac keylen = %d\n",op->hash, op->hmac_keylen);
+
+	ret = rmisec_cipher_and_hash(handle, CIPHER_BYPASS, RMI_ECB, NULL, NULL,
+				     0, 0, op->hash, 
+				     (op->hmac_keylen?op->hmac_key:NULL), 0, 0,
+				     op->auth_src, op->len, NULL, out);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		xlr_inc_auth_stat(op->hash, op->len);
+	}
+        debug_print(KERN_INFO "ret val after hashing is %d\n",ret);
+	op->len = 0;
+	rmisec_op_cleanup(&handle);
+	kfree(op->auth_src);
+}
+
+static void xlr_sha1_final(struct crypto_tfm *tfm, uint8_t *out)
+{
+	struct xlr_crypt_state *op = ctx(tfm);
+
+	op->hash = RMI_SHA1;
+	xlr_auth_final(tfm, out);
+}
+
+static void xlr_sha256_final(struct crypto_tfm *tfm, uint8_t *out)
+{
+	struct xlr_crypt_state *op = ctx(tfm);
+
+	op->hash = RMI_SHA256;
+	xlr_auth_final(tfm, out);
+}
+
+static void xlr_sha384_final(struct crypto_tfm *tfm, uint8_t *out)
+{
+	struct xlr_crypt_state *op = ctx(tfm);
+
+	op->hash = RMI_SHA384;
+	xlr_auth_final(tfm, out);
+}
+
+static void xlr_sha512_final(struct crypto_tfm *tfm, uint8_t *out)
+{
+	struct xlr_crypt_state *op = ctx(tfm);
+
+	op->hash = RMI_SHA512;
+	xlr_auth_final(tfm, out);
+}
+
+static void xlr_md5_final(struct crypto_tfm *tfm, uint8_t *out)
+{
+	struct xlr_crypt_state *op = ctx(tfm);
+
+	op->hash = RMI_MD5;
+	xlr_auth_final(tfm, out);
+}
+
+static int xlr_auth_setkey(struct crypto_tfm *tfm, const u8 *key, unsigned int keylen)
+{
+	struct xlr_crypt_state *op = ctx(tfm);
+	op->hmac = 1;
+	op->hmac_keylen = keylen;
+	memcpy(op->hmac_key, key, keylen);
+        debug_print(KERN_INFO "[%s] keylen is %d\n",__FUNCTION__ ,keylen);
+	return 0;
+}
+
+static struct crypto_alg sha512_alg = {
+	.cra_name		=	"sha512",
+	.cra_driver_name	=	"sha512-xlr",
+	.cra_priority		=	XLR_AUTH_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_DIGEST|
+					CRYPTO_ALG_HW,
+	.cra_blocksize		=	SHA512_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(sha512_alg.cra_list),
+	.cra_u			=	{
+		.digest = {
+			.dia_digestsize	=	SHA512_DIGEST_SIZE,
+			.dia_init   	= 	xlr_auth_init,
+			.dia_update 	=	xlr_auth_update,
+			.dia_final  	=	xlr_sha512_final,
+		}
+	}
+};
+
+
+static struct crypto_alg sha384_alg = {
+	.cra_name		=	"sha384",
+	.cra_driver_name	=	"sha384-xlr",
+	.cra_priority		=	XLR_AUTH_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_DIGEST|
+					CRYPTO_ALG_HW,
+	.cra_blocksize		=	SHA384_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(sha384_alg.cra_list),
+	.cra_u			=	{
+		.digest = {
+			.dia_digestsize	=	SHA384_DIGEST_SIZE,
+			.dia_init   	= 	xlr_auth_init,
+			.dia_update 	=	xlr_auth_update,
+			.dia_final  	=	xlr_sha384_final,
+		}
+	}
+};
+
+static struct crypto_alg sha256_alg = {
+	.cra_name		=	"sha256",
+	.cra_driver_name	=	"sha256-xlr",
+	.cra_priority		=	XLR_AUTH_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_DIGEST |
+					CRYPTO_ALG_HW,
+	.cra_blocksize		=	SHA256_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(sha256_alg.cra_list),
+	.cra_u			=	{
+		.digest = {
+			.dia_digestsize	=	SHA256_DIGEST_SIZE,
+			.dia_init   	= 	xlr_auth_init,
+			.dia_update 	=	xlr_auth_update,
+			.dia_final  	=	xlr_sha256_final,
+		}
+	}
+};
+
+static struct crypto_alg sha1_alg = {
+	.cra_name		=	"sha1",
+	.cra_driver_name	=	"sha1-xlr",
+	.cra_priority		=	XLR_AUTH_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_DIGEST|
+					CRYPTO_ALG_HW,
+	.cra_blocksize		=	SHA1_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(sha1_alg.cra_list),
+	.cra_u			=	{
+		.digest = {
+			.dia_digestsize	=	SHA1_DIGEST_SIZE,
+			.dia_init   	= 	xlr_auth_init,
+			.dia_update 	=	xlr_auth_update,
+			.dia_final  	=	xlr_sha1_final,
+		}
+	}
+};
+
+static struct crypto_alg md5_alg = {
+	.cra_name		=	"md5",
+	.cra_driver_name	=	"md5-xlr",
+	.cra_priority		=	XLR_AUTH_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_DIGEST |
+					CRYPTO_ALG_HW,
+	.cra_blocksize		=	MD5_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(md5_alg.cra_list),
+	.cra_u			=	{
+		.digest = {
+			.dia_digestsize	=	MD5_DIGEST_SIZE,
+			.dia_init   	= 	xlr_auth_init,
+			.dia_update 	=	xlr_auth_update,
+			.dia_final  	=	xlr_md5_final,
+		}
+	}
+};
+
+static struct crypto_alg sha512_hmac_alg = {
+	.cra_name		=	"hmac(sha512)",
+	.cra_driver_name	=	"hmac-sha512-xlr",
+	.cra_priority		=	XLR_HMAC_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_DIGEST|
+					CRYPTO_ALG_HW,
+	.cra_blocksize		=	SHA512_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(sha512_alg.cra_list),
+	.cra_u			=	{
+		.digest = {
+			.dia_digestsize	=	SHA512_DIGEST_SIZE,
+			.dia_init   	= 	xlr_auth_init,
+			.dia_update 	=	xlr_auth_update,
+			.dia_final  	=	xlr_sha512_final,
+			.dia_setkey     =	xlr_auth_setkey,
+		}
+	}
+};
+
+
+static struct crypto_alg sha384_hmac_alg = {
+	.cra_name		=	"hmac(sha384)",
+	.cra_driver_name	=	"hmac-sha384-xlr",
+	.cra_priority		=	XLR_HMAC_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_DIGEST|
+					CRYPTO_ALG_HW,
+	.cra_blocksize		=	SHA384_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(sha384_alg.cra_list),
+	.cra_u			=	{
+		.digest = {
+			.dia_digestsize	=	SHA384_DIGEST_SIZE,
+			.dia_init   	= 	xlr_auth_init,
+			.dia_update 	=	xlr_auth_update,
+			.dia_final  	=	xlr_sha384_final,
+			.dia_setkey     =	xlr_auth_setkey,
+		}
+	}
+};
+
+
+static struct crypto_alg sha256_hmac_alg = {
+	.cra_name		=	"hmac(sha256)",
+	.cra_driver_name	=	"hmac-sha256-xlr",
+	.cra_priority		=	XLR_HMAC_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_DIGEST |
+					CRYPTO_ALG_HW,
+	.cra_blocksize		=	SHA256_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(sha256_alg.cra_list),
+	.cra_u			=	{
+		.digest = {
+			.dia_digestsize	=	SHA256_DIGEST_SIZE,
+			.dia_init   	= 	xlr_auth_init,
+			.dia_update 	=	xlr_auth_update,
+			.dia_final  	=	xlr_sha256_final,
+			.dia_setkey     =	xlr_auth_setkey,
+		}
+	}
+};
+
+static struct crypto_alg sha1_hmac_alg = {
+	.cra_name		=	"hmac(sha1)",
+	.cra_driver_name	=	"hmac-sha1-xlr",
+	.cra_priority		=	XLR_HMAC_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_DIGEST|
+					CRYPTO_ALG_HW,
+	.cra_blocksize		=	SHA1_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(sha1_alg.cra_list),
+	.cra_u			=	{
+		.digest = {
+			.dia_digestsize	=	SHA1_DIGEST_SIZE,
+			.dia_init   	= 	xlr_auth_init,
+			.dia_update 	=	xlr_auth_update,
+			.dia_final  	=	xlr_sha1_final,
+			.dia_setkey     =	xlr_auth_setkey,
+		}
+	}
+};
+
+static struct crypto_alg md5_hmac_alg = {
+	.cra_name		=	"hmac(md5)",
+	.cra_driver_name	=	"hmac-md5-xlr",
+	.cra_priority		=	XLR_HMAC_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_DIGEST |
+					CRYPTO_ALG_HW,
+	.cra_blocksize		=	MD5_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(md5_alg.cra_list),
+	.cra_u			=	{
+		.digest = {
+			.dia_digestsize	=	MD5_DIGEST_SIZE,
+			.dia_init   	= 	xlr_auth_init,
+			.dia_update 	=	xlr_auth_update,
+			.dia_final  	=	xlr_md5_final,
+			.dia_setkey	=	xlr_auth_setkey,
+		}
+	}
+};
+
+static int __init xlr_auth_alg_init(void)
+{
+	int rc = -ENODEV;
+
+	rc = crypto_register_alg(&sha1_alg);
+	if (rc)
+		goto out;
+
+	rc = crypto_register_alg(&sha256_alg);
+	if (rc)
+		goto out_unreg1;
+
+	rc = crypto_register_alg(&sha384_alg);
+	if (rc)
+		goto out_unreg2;
+
+	rc = crypto_register_alg(&sha512_alg);
+	if (rc)
+		goto out_unreg3;
+
+	rc = crypto_register_alg(&md5_alg);
+	if (rc)
+		goto out_unreg4;
+
+	rc = crypto_register_alg(&sha1_hmac_alg);
+	if (rc)
+		goto out_unreg5;
+
+	rc = crypto_register_alg(&sha256_hmac_alg);
+	if (rc)
+		goto out_unreg6;
+
+	rc = crypto_register_alg(&sha384_hmac_alg);
+	if (rc)
+		goto out_unreg7;
+
+	rc = crypto_register_alg(&sha512_hmac_alg);
+	if (rc)
+		goto out_unreg8;
+
+	rc = crypto_register_alg(&md5_hmac_alg);
+	if (rc)
+		goto out_unreg9;
+
+	printk(KERN_NOTICE "Using XLR hardware for SHA/MD5 algorithms.\n");
+
+	return 0;
+
+out_unreg9:
+	crypto_unregister_alg(&sha512_hmac_alg);
+out_unreg8:
+	crypto_unregister_alg(&sha384_hmac_alg);
+out_unreg7:
+	crypto_unregister_alg(&sha256_hmac_alg);
+out_unreg6:
+	crypto_unregister_alg(&sha1_hmac_alg);
+out_unreg5:
+	crypto_unregister_alg(&md5_alg);
+out_unreg4:
+	crypto_unregister_alg(&sha512_alg);
+out_unreg3:
+	crypto_unregister_alg(&sha384_alg);
+out_unreg2:
+	crypto_unregister_alg(&sha256_alg);
+out_unreg1:
+	crypto_unregister_alg(&sha1_alg);
+out:
+	printk(KERN_ERR "XLR SHA/MD5 initialization failed.\n");
+	return rc;
+
+}
+
+static void __exit xlr_auth_alg_fini(void)
+{
+	crypto_unregister_alg(&sha1_alg);
+	crypto_unregister_alg(&sha256_alg);
+	crypto_unregister_alg(&sha384_alg);
+	crypto_unregister_alg(&sha512_alg);
+	crypto_unregister_alg(&md5_alg);
+	crypto_unregister_alg(&md5_hmac_alg);
+	crypto_unregister_alg(&sha1_hmac_alg);
+	crypto_unregister_alg(&sha256_hmac_alg);
+	crypto_unregister_alg(&sha384_hmac_alg);
+	crypto_unregister_alg(&sha512_hmac_alg);
+}
+
+//module_init(xlr_auth_alg_init);
+//module_exit(xlr_auth_alg_fini);
+
+MODULE_DESCRIPTION("XLR SHA/MD5 algorithms support.");
+MODULE_LICENSE("GPL/BSD");
+MODULE_AUTHOR("Sandip Matte");
+
+MODULE_ALIAS("sha-xlr");
+MODULE_ALIAS("md5-xlr");
diff --git a/drivers/crypto/rmi/rmi_enc.c b/drivers/crypto/rmi/rmi_enc.c
new file mode 100644
index 0000000..362e29b
--- /dev/null
+++ b/drivers/crypto/rmi/rmi_enc.c
@@ -0,0 +1,822 @@
+
+ /* Copyright (C) 2004-2009, RMI Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/pci.h>
+#include <linux/pci_ids.h>
+#include <linux/crypto.h>
+#include <linux/spinlock.h>
+#include <crypto/algapi.h>
+#include <crypto/aes.h>
+#include <crypto/des.h>
+
+#include <linux/hardirq.h>
+
+#include <asm/io.h>
+#include <asm/delay.h>
+#include <asm/rmi/msgring.h>
+#include "rmi_state_info.h"
+#include "rmisae.h"
+#include "rmisec_internal.h" 
+
+
+#define AES_CTR_IV_SIZE		8
+#define XLR_CRYPT_PRIORITY	300
+
+//#define SEC_DEBUG
+
+#ifdef SEC_DEBUG
+#ifdef __KERNEL__
+#define debug_print(fmt, args...) printk(fmt, ##args)
+#else  /* __KERNEL__ */
+#define debug_print(fmt, args...) printf(fmt, ##args)
+#endif /* __KERNEL__ */
+#else /* SEC_DEBUG */
+#define debug_print(fmt, args...)
+#endif /* SEC_DEBUG */
+
+
+/* CRYPTO-API Functions */
+
+static int xlr_aes_setkey(struct crypto_tfm *tfm, const u8 *in_key,
+		       unsigned int len)
+{
+	struct xlr_crypt_state *op = crypto_tfm_ctx(tfm);
+	u32 *flags = &tfm->crt_flags;
+
+	op->key_len = len;
+
+	debug_print("in %s keylen is %d\n",__FUNCTION__, len);
+
+	switch (len) {
+	case 16: op->cipher = RMI_AES128; break;
+	case 24: op->cipher = RMI_AES192; break;
+	case 32: op->cipher = RMI_AES256; break;
+	default: printk(KERN_WARNING"[%s]: Cannot handle keylen = %d\n",
+			__FUNCTION__,len);
+		*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;
+		 return -EINVAL;
+	}
+
+	op->block_size = AES_BLOCK_SIZE;
+	op->iv_len = AES_BLOCK_SIZE;
+	memcpy(op->key, in_key, len);
+	return 0;
+}
+
+static int xlr_aes_ctr_setkey(struct crypto_tfm *tfm, const u8 *in_key,
+		       unsigned int len)
+{
+	struct xlr_crypt_state *op = crypto_tfm_ctx(tfm);
+	u32 *flags = &tfm->crt_flags;
+
+	debug_print("in %s keylen is %d\n",__FUNCTION__, len);
+	op->key_len = len - 4;
+
+	switch (len) {
+	case 20: op->cipher = RMI_AES128; break;
+	case 28: op->cipher = RMI_AES192; break;
+	case 36: op->cipher = RMI_AES256; break;
+
+	default: printk(KERN_WARNING"[%s]: Cannot handle keylen = %d\n",
+			__FUNCTION__,len);
+		*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;
+		 return -EINVAL;
+	}
+
+	op->block_size = 1; // stream cipher
+	op->iv_len = AES_CTR_IV_SIZE;
+	memcpy(op->key, in_key, len);
+	memcpy(&op->nonce, in_key + len - 4, 4);
+	return 0;
+}
+
+static int xlr_des_setkey(struct crypto_tfm *tfm, const u8 *in_key,
+		       unsigned int len)
+{
+	struct xlr_crypt_state *op = crypto_tfm_ctx(tfm);
+	u32 *flags = &tfm->crt_flags;
+
+	op->key_len = len;
+	op->cipher = RMI_DES;
+
+	if (len == DES_KEY_SIZE) {
+		memcpy(op->key, in_key, len);
+		op->block_size = DES_BLOCK_SIZE;
+	} else {
+		*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;
+		 return -EINVAL;
+	}
+	op->iv_len = DES_BLOCK_SIZE;
+	return 0;
+}
+
+static int xlr_des3_setkey(struct crypto_tfm *tfm, const u8 *in_key,
+		       unsigned int len)
+{
+	struct xlr_crypt_state *op = crypto_tfm_ctx(tfm);
+	u32 *flags = &tfm->crt_flags;
+
+	op->key_len = len;
+	op->cipher = RMI_DES3;
+
+	if (len == DES3_EDE_KEY_SIZE) {
+		memcpy(op->key, in_key, len);
+		op->block_size = DES3_EDE_BLOCK_SIZE;
+	} else {
+		*flags |= CRYPTO_TFM_RES_BAD_KEY_LEN;
+		 return -EINVAL;
+	}
+	op->iv_len = DES3_EDE_BLOCK_SIZE;
+	return 0;
+}
+
+int xlr_crypt_op_init(struct xlr_crypt_state *op, op_handle_t *handle, Crypto_Operation_pt *cop_ptr)
+{
+	operation_pt op_ptr;
+	Crypto_Operation_pt cop;
+	int ret;
+
+	ret = rmisec_op_init(handle);
+
+	if(ret) {
+		printk("Cannot malloc. returning from %s\n", __FUNCTION__);
+		return ret;
+	}
+
+	op_ptr = (operation_pt)(*handle);
+	cop = &op_ptr->cop_instance;
+	*cop_ptr = cop;
+
+	cop->c = op->cipher;
+	cop->h = HASH_BYPASS;
+	cop->hmac = NULL;
+	cop->hmac_len = 0;
+//	cop->cipher_mask = ; //probably nonce...
+	cop->key = op->key; // use the thing setup in setkey...
+	cop->key_len = op->key_len;
+//	cop->hash_bytes_to_skip = 0;
+//	cop->nonce = NULL;
+//	cop->cksum_output = NULL;
+
+	return 0;
+}
+
+static int
+xlr_ecb_decrypt(struct blkcipher_desc *desc,
+		  struct scatterlist *dst, struct scatterlist *src,
+		  unsigned int nbytes)
+{
+	struct xlr_crypt_state *op = crypto_blkcipher_ctx(desc->tfm);
+	op_handle_t handle = RMISAE_HANDLE_INITIALIZER;
+	Crypto_Operation_pt cop=NULL;
+	struct blkcipher_walk walk;
+	int err, ret;
+
+	if (( ret = xlr_crypt_op_init(op, &handle, &cop)))
+		return ret; 
+
+	cop->m = RMI_ECB;
+	cop->encrypt = CIPHER_DECRYPT;
+
+	blkcipher_walk_init(&walk, dst, src, nbytes);
+	err = blkcipher_walk_virt(desc, &walk);
+
+	while((nbytes = walk.nbytes)) {
+		cop->iv_len = 0;
+		cop->input = walk.src.virt.addr;
+		cop->input_len = nbytes - (nbytes % op->block_size);
+		cop->output = walk.dst.virt.addr;
+
+		ret = rmisec_cipher_digest_hmac_cksum(handle, cop);
+		if(IS_SUCCESS_SAEOP(ret)) 
+			xlr_inc_enc_stat(cop->c, cop->m, cop->input_len);
+		if (ret == -1)
+			return ret;
+		nbytes -= ret;
+		err = blkcipher_walk_done(desc, &walk, nbytes);
+	}
+
+	rmisec_op_cleanup(&handle);
+	return err;
+}
+
+static int
+xlr_ecb_encrypt(struct blkcipher_desc *desc,
+		  struct scatterlist *dst, struct scatterlist *src,
+		  unsigned int nbytes)
+{
+	struct xlr_crypt_state *op = crypto_blkcipher_ctx(desc->tfm);
+	op_handle_t handle = RMISAE_HANDLE_INITIALIZER;
+	Crypto_Operation_pt cop=NULL;
+	struct blkcipher_walk walk;
+	int err, ret;
+
+	if (( ret = xlr_crypt_op_init(op, &handle, &cop)))
+		return ret; 
+
+	cop->m = RMI_ECB;
+	cop->encrypt = CIPHER_ENCRYPT;
+
+	blkcipher_walk_init(&walk, dst, src, nbytes);
+	err = blkcipher_walk_virt(desc, &walk);
+
+	while((nbytes = walk.nbytes)) {
+		cop->iv_len = 0;
+		cop->input = walk.src.virt.addr;
+		cop->input_len = nbytes - (nbytes % op->block_size);
+		cop->output = walk.dst.virt.addr;
+
+		ret = rmisec_cipher_digest_hmac_cksum(handle, cop);
+		if(IS_SUCCESS_SAEOP(ret)) 
+			xlr_inc_enc_stat(cop->c, cop->m, cop->input_len);
+		if (ret == -1)
+			return ret;
+		nbytes -= ret;
+		ret =  blkcipher_walk_done(desc, &walk, nbytes);
+	}
+	rmisec_op_cleanup(&handle);
+
+	return err;
+}
+
+static void
+xlr_encrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)
+{
+	struct xlr_crypt_state *op = crypto_tfm_ctx(tfm);
+	op_handle_t handle = RMISAE_HANDLE_INITIALIZER;
+	Crypto_Operation_pt cop=NULL;
+	int ret;
+
+	if ((out == NULL) || (in == NULL))
+		return;
+
+        debug_print(KERN_INFO "in func %s\n",__FUNCTION__);
+
+	if (xlr_crypt_op_init(op, &handle, &cop))
+		return; 
+
+	cop->m = RMI_ECB;
+	cop->encrypt = CIPHER_ENCRYPT;
+	cop->input = in;
+	cop->input_len = op->block_size;
+	cop->output = out;
+
+	ret = rmisec_cipher_digest_hmac_cksum(handle, cop);
+	if(IS_SUCCESS_SAEOP(ret))
+		xlr_inc_enc_stat(cop->c, cop->m, cop->input_len);
+	rmisec_op_cleanup(&handle);
+	return;
+}
+
+static void
+xlr_decrypt(struct crypto_tfm *tfm, u8 *out, const u8 *in)
+{
+	struct xlr_crypt_state *op = crypto_tfm_ctx(tfm);
+	op_handle_t handle = RMISAE_HANDLE_INITIALIZER;
+	Crypto_Operation_pt cop=NULL;
+	int ret;
+
+	if ((out == NULL) || (in == NULL))
+		return;
+
+        debug_print(KERN_INFO "in func %s\n",__FUNCTION__);
+
+	if (xlr_crypt_op_init(op, &handle, &cop))
+		return; 
+
+	cop->m = RMI_ECB;
+	cop->encrypt = CIPHER_DECRYPT;
+	cop->input = in;
+	cop->input_len = op->block_size;
+	cop->output = out;
+
+	ret = rmisec_cipher_digest_hmac_cksum(handle, cop);
+	if(IS_SUCCESS_SAEOP(ret)) 
+		xlr_inc_enc_stat(cop->c, cop->m, cop->input_len);
+	rmisec_op_cleanup(&handle);
+	return;
+}
+
+static int
+xlr_cbc_decrypt(struct blkcipher_desc *desc,
+		  struct scatterlist *dst, struct scatterlist *src,
+		  unsigned int nbytes)
+{
+	struct xlr_crypt_state *op = crypto_blkcipher_ctx(desc->tfm);
+	op_handle_t handle = RMISAE_HANDLE_INITIALIZER;
+	Crypto_Operation_pt cop=NULL;
+	struct blkcipher_walk walk;
+	int err, ret;
+
+        debug_print(KERN_INFO "in func %s:%d\n",__FUNCTION__,__LINE__);
+
+	if (( ret = xlr_crypt_op_init(op, &handle, &cop)))
+		return ret; 
+
+	cop->m = RMI_CBC;
+	cop->encrypt = CIPHER_DECRYPT;
+
+	blkcipher_walk_init(&walk, dst, src, nbytes);
+	err = blkcipher_walk_virt(desc, &walk);
+	while((nbytes = walk.nbytes)) {
+
+		cop->iv = op->iv;
+		cop->iv_len = op->iv_len;
+		cop->input = walk.src.virt.addr;
+		cop->input_len = nbytes - (nbytes % op->block_size);
+		cop->output = walk.dst.virt.addr;
+
+		memcpy(op->iv, walk.iv, op->iv_len);
+
+        debug_print(KERN_INFO "in func %s:%d\n",__FUNCTION__,__LINE__);
+		ret = rmisec_cipher_digest_hmac_cksum(handle, cop);
+		if(IS_SUCCESS_SAEOP(ret)) 
+			xlr_inc_enc_stat(cop->c, cop->m, cop->input_len);
+
+	debug_print(KERN_INFO "input_len = %d, retval = %d \n",cop->input_len, 
+		    ret);
+		if (ret == -1)
+			return ret;
+//		memcpy(walk.iv, op->iv, AES_IV_LENGTH);
+		memcpy(walk.iv, cop->input + cop->input_len - op->iv_len,
+		       op->iv_len);
+//		nbytes -= ret;
+		nbytes -= cop->input_len;
+
+		err = blkcipher_walk_done(desc, &walk, nbytes);
+		if (err)
+			return err;
+	}
+
+	rmisec_op_cleanup(&handle);
+	return err;
+}
+
+static int
+xlr_cbc_encrypt(struct blkcipher_desc *desc,
+		  struct scatterlist *dst, struct scatterlist *src,
+		  unsigned int nbytes)
+{
+	struct xlr_crypt_state *op = crypto_blkcipher_ctx(desc->tfm);
+	op_handle_t handle = RMISAE_HANDLE_INITIALIZER;
+	Crypto_Operation_pt cop=NULL;
+	struct blkcipher_walk walk;
+	int err, ret;
+
+	if (( ret = xlr_crypt_op_init(op, &handle, &cop)))
+		return ret; 
+
+	cop->m = RMI_CBC;
+	cop->encrypt = CIPHER_ENCRYPT;
+
+	blkcipher_walk_init(&walk, dst, src, nbytes);
+	err = blkcipher_walk_virt(desc, &walk);
+
+        debug_print(KERN_INFO "in func %s:%d\n",__FUNCTION__,__LINE__);
+	while((nbytes = walk.nbytes)) {
+		cop->iv = op->iv;
+		cop->iv_len = op->iv_len;
+		cop->input = walk.src.virt.addr;
+		cop->input_len = nbytes - (nbytes % op->block_size);
+		cop->output = walk.dst.virt.addr;
+
+		memcpy(op->iv, walk.iv, op->iv_len);
+
+		ret = rmisec_cipher_digest_hmac_cksum(handle, cop);
+		if(IS_SUCCESS_SAEOP(ret)) 
+			xlr_inc_enc_stat(cop->c, cop->m, cop->input_len);
+
+		if (ret == -1)
+			return ret;
+		
+		memcpy(walk.iv, cop->output + cop->input_len - op->iv_len,
+		       op->iv_len);
+
+		nbytes -= cop->input_len;
+		err = blkcipher_walk_done(desc, &walk, nbytes);
+	}
+	debug_print(KERN_INFO "in func %s:%d\n",__FUNCTION__,__LINE__);
+
+	rmisec_op_cleanup(&handle);
+	return err;
+}
+
+
+static int
+xlr_ctr_decrypt(struct blkcipher_desc *desc,
+		  struct scatterlist *dst, struct scatterlist *src,
+		  unsigned int nbytes)
+{
+	struct xlr_crypt_state *op = crypto_blkcipher_ctx(desc->tfm);
+	op_handle_t handle = RMISAE_HANDLE_INITIALIZER;
+	Crypto_Operation_pt cop=NULL;
+	struct blkcipher_walk walk;
+	int err, ret;
+
+        debug_print(KERN_INFO "in func %s:%d\n",__FUNCTION__,__LINE__);
+
+	if (( ret = xlr_crypt_op_init(op, &handle, &cop)))
+		return ret; 
+
+	cop->m = RMI_CTR;
+	cop->encrypt = CIPHER_DECRYPT;
+
+	blkcipher_walk_init(&walk, dst, src, nbytes);
+	err = blkcipher_walk_virt(desc, &walk);
+	while((nbytes = walk.nbytes)) {
+
+		cop->iv = op->iv;
+		cop->iv_len = op->iv_len;
+		cop->nonce = op->nonce;
+		cop->input = walk.src.virt.addr;
+		cop->input_len = nbytes - (nbytes % op->block_size);
+		cop->output = walk.dst.virt.addr;
+
+		memcpy(op->iv, walk.iv, op->iv_len);
+
+		debug_print(KERN_INFO "in func %s:%d\n",__FUNCTION__,__LINE__);
+		ret = rmisec_cipher_digest_hmac_cksum(handle, cop);
+		if(IS_SUCCESS_SAEOP(ret)) 
+			xlr_inc_enc_stat(cop->c, cop->m, cop->input_len);
+
+		debug_print(KERN_INFO "input_len = %d, retval = %d \n",
+			    cop->input_len, ret);
+		if (ret == -1)
+			return ret;
+		memcpy(walk.iv, cop->input + cop->input_len - op->iv_len,
+		       op->iv_len);
+		nbytes -= cop->input_len;
+
+		err = blkcipher_walk_done(desc, &walk, nbytes);
+		if (err)
+			return err;
+	}
+
+	rmisec_op_cleanup(&handle);
+	return err;
+}
+
+static int
+xlr_ctr_encrypt(struct blkcipher_desc *desc,
+		  struct scatterlist *dst, struct scatterlist *src,
+		  unsigned int nbytes)
+{
+	struct xlr_crypt_state *op = crypto_blkcipher_ctx(desc->tfm);
+	op_handle_t handle = RMISAE_HANDLE_INITIALIZER;
+	Crypto_Operation_pt cop=NULL;
+	struct blkcipher_walk walk;
+	int err, ret;
+
+	if (( ret = xlr_crypt_op_init(op, &handle, &cop)))
+		return ret; 
+
+
+	cop->m = RMI_CTR;
+	cop->encrypt = CIPHER_ENCRYPT;
+
+	blkcipher_walk_init(&walk, dst, src, nbytes);
+	err = blkcipher_walk_virt(desc, &walk);
+
+        debug_print(KERN_INFO "in func %s:%d\n",__FUNCTION__,__LINE__);
+	while((nbytes = walk.nbytes)) {
+		cop->iv = op->iv;
+		cop->iv_len = op->iv_len;
+		cop->nonce = op->nonce;
+		cop->input = walk.src.virt.addr;
+		cop->input_len = nbytes - (nbytes % op->block_size);
+		cop->output = walk.dst.virt.addr;
+
+		memcpy(op->iv, walk.iv, op->iv_len);
+
+		ret = rmisec_cipher_digest_hmac_cksum(handle, cop);
+		if(IS_SUCCESS_SAEOP(ret)) 
+			xlr_inc_enc_stat(cop->c, cop->m, cop->input_len);
+		debug_print(KERN_INFO "input_len = %d, retval = %d \n",
+			    cop->input_len, ret);
+
+		if (ret == -1)
+			return ret;
+		
+		memcpy(walk.iv, cop->output + cop->input_len - op->iv_len,
+		       op->iv_len);
+
+		nbytes -= cop->input_len;
+		err = blkcipher_walk_done(desc, &walk, nbytes);
+	}
+	debug_print(KERN_INFO "in func %s:%d\n",__FUNCTION__,__LINE__);
+
+	rmisec_op_cleanup(&handle);
+	return err;
+}
+
+static struct crypto_alg xlr_ecb_aes_alg = {
+	.cra_name		=	"ecb(aes)",
+	.cra_driver_name	=	"ecb-aes-xlr",
+	.cra_priority		=	XLR_CRYPT_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_BLKCIPHER,
+	.cra_blocksize		=	AES_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_alignmask		=	15,
+	.cra_type		=	&crypto_blkcipher_type,
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(xlr_ecb_aes_alg.cra_list),
+	.cra_u			=	{
+		.blkcipher = {
+			.min_keysize		=	AES_MIN_KEY_SIZE,
+			.max_keysize		=	AES_MAX_KEY_SIZE,
+			.setkey			=	xlr_aes_setkey,
+			.encrypt		=	xlr_ecb_encrypt,
+			.decrypt		=	xlr_ecb_decrypt,
+		}
+	}
+};
+
+static struct crypto_alg xlr_aes_alg = {
+	.cra_name               =       "aes",
+	.cra_driver_name	=       "aes-xlr",
+	.cra_priority           =       XLR_CRYPT_PRIORITY,
+	.cra_alignmask          =       15,
+	.cra_flags		=	CRYPTO_ALG_TYPE_CIPHER,
+	.cra_blocksize		=	AES_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(xlr_aes_alg.cra_list),
+	.cra_u			=	{
+		.cipher = {
+			.cia_min_keysize	=  AES_MIN_KEY_SIZE,
+			.cia_max_keysize	=  AES_MAX_KEY_SIZE,
+			.cia_setkey		=  xlr_aes_setkey,
+			.cia_encrypt		=  xlr_encrypt,
+			.cia_decrypt		=  xlr_decrypt
+		}
+	}
+};
+
+static struct crypto_alg xlr_cbc_aes_alg = {
+	.cra_name		=	"cbc(aes)",
+	.cra_driver_name	=	"cbc-aes-xlr",
+	.cra_priority		=	XLR_CRYPT_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_BLKCIPHER,
+	.cra_blocksize		=	AES_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_alignmask		=	15,
+	.cra_type		=	&crypto_blkcipher_type,
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(xlr_cbc_aes_alg.cra_list),
+	.cra_u			=	{
+		.blkcipher = {
+			.min_keysize		=	AES_MIN_KEY_SIZE,
+			.max_keysize		=	AES_MAX_KEY_SIZE,
+			.setkey			=	xlr_aes_setkey,
+			.encrypt		=	xlr_cbc_encrypt,
+			.decrypt		=	xlr_cbc_decrypt,
+			.ivsize			=	AES_BLOCK_SIZE,
+		}
+	}
+};
+
+static struct crypto_alg xlr_ctr_aes_alg = {
+	.cra_name		=	"ctr(aes)",
+	.cra_driver_name	=	"ctr-aes-xlr",
+	.cra_priority		=	XLR_CRYPT_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_BLKCIPHER,
+	.cra_blocksize		=	1,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_alignmask		=	15,
+	.cra_type		=	&crypto_blkcipher_type,
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(xlr_ctr_aes_alg.cra_list),
+	.cra_u			=	{
+		.blkcipher = {
+			.min_keysize		=	AES_MIN_KEY_SIZE,
+			.max_keysize		=	AES_MAX_KEY_SIZE,
+			.setkey			=	xlr_aes_ctr_setkey,
+			.encrypt		=	xlr_ctr_encrypt,
+			.decrypt		=	xlr_ctr_decrypt,
+			.ivsize			=	AES_CTR_IV_SIZE,
+		}
+	}
+};
+
+static struct crypto_alg xlr_ecb_des_alg = {
+	.cra_name		=	"ecb(des)",
+	.cra_driver_name	=	"ecb-des-xlr",
+	.cra_priority		=	XLR_CRYPT_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_BLKCIPHER,
+	.cra_blocksize		=	DES_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_alignmask		=	15,
+	.cra_type		=	&crypto_blkcipher_type,
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(xlr_ecb_des_alg.cra_list),
+	.cra_u			=	{
+		.blkcipher = {
+			.min_keysize		=	DES_KEY_SIZE,
+			.max_keysize		=	DES_KEY_SIZE,
+			.setkey			=	xlr_des_setkey,
+			.encrypt		=	xlr_ecb_encrypt,
+			.decrypt		=	xlr_ecb_decrypt,
+		}
+	}
+};
+
+static struct crypto_alg xlr_des_alg = {
+	.cra_name               =       "des",
+	.cra_driver_name	=       "des-xlr",
+	.cra_priority           =       XLR_CRYPT_PRIORITY,
+	.cra_alignmask          =       15,
+	.cra_flags		=	CRYPTO_ALG_TYPE_CIPHER,
+	.cra_blocksize		=	DES_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(xlr_des_alg.cra_list),
+	.cra_u			=	{
+		.cipher = {
+			.cia_min_keysize	=  DES_KEY_SIZE,
+			.cia_max_keysize	=  DES_KEY_SIZE,
+			.cia_setkey		=  xlr_des_setkey,
+			.cia_encrypt		=  xlr_encrypt,
+			.cia_decrypt		=  xlr_decrypt
+		}
+	}
+};
+
+static struct crypto_alg xlr_cbc_des_alg = {
+	.cra_name		=	"cbc(des)",
+	.cra_driver_name	=	"cbc-des-xlr",
+	.cra_priority		=	XLR_CRYPT_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_BLKCIPHER,
+	.cra_blocksize		=	DES_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_alignmask		=	15,
+	.cra_type		=	&crypto_blkcipher_type,
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(xlr_cbc_des_alg.cra_list),
+	.cra_u			=	{
+		.blkcipher = {
+			.min_keysize		=	DES_KEY_SIZE,
+			.max_keysize		=	DES_KEY_SIZE,
+			.setkey			=	xlr_des_setkey,
+			.encrypt		=	xlr_cbc_encrypt,
+			.decrypt		=	xlr_cbc_decrypt,
+			.ivsize			=	DES_BLOCK_SIZE,
+		}
+	}
+};
+
+static struct crypto_alg xlr_ecb_des3_alg = {
+	.cra_name		=	"ecb(des3_ede)",
+	.cra_driver_name	=	"ecb-des3-xlr",
+	.cra_priority		=	XLR_CRYPT_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_BLKCIPHER,
+	.cra_blocksize		=	DES3_EDE_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_alignmask		=	15,
+	.cra_type		=	&crypto_blkcipher_type,
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(xlr_ecb_des3_alg.cra_list),
+	.cra_u			=	{
+		.blkcipher = {
+			.min_keysize		=	DES3_EDE_KEY_SIZE,
+			.max_keysize		=	DES3_EDE_KEY_SIZE,
+			.setkey			=	xlr_des3_setkey,
+			.encrypt		=	xlr_ecb_encrypt,
+			.decrypt		=	xlr_ecb_decrypt,
+		}
+	}
+};
+
+static struct crypto_alg xlr_des3_alg = {
+	.cra_name               =       "des3_ede",
+	.cra_driver_name	=       "des3_ede-xlr",
+	.cra_priority           =       XLR_CRYPT_PRIORITY,
+	.cra_alignmask          =       15,
+	.cra_flags		=	CRYPTO_ALG_TYPE_CIPHER,
+	.cra_blocksize		=	DES3_EDE_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(xlr_des3_alg.cra_list),
+	.cra_u			=	{
+		.cipher = {
+			.cia_min_keysize	=  DES3_EDE_KEY_SIZE,
+			.cia_max_keysize	=  DES3_EDE_KEY_SIZE,
+			.cia_setkey		=  xlr_des3_setkey,
+			.cia_encrypt		=  xlr_encrypt,
+			.cia_decrypt		=  xlr_decrypt
+		}
+	}
+};
+
+static struct crypto_alg xlr_cbc_des3_alg = {
+	.cra_name		=	"cbc(des3_ede)",
+	.cra_driver_name	=	"cbc-des3_ede-xlr",
+	.cra_priority		=	XLR_CRYPT_PRIORITY,
+	.cra_flags		=	CRYPTO_ALG_TYPE_BLKCIPHER,
+	.cra_blocksize		=	DES3_EDE_BLOCK_SIZE,
+	.cra_ctxsize		=	sizeof(struct xlr_crypt_state),
+	.cra_alignmask		=	15,
+	.cra_type		=	&crypto_blkcipher_type,
+	.cra_module		=	THIS_MODULE,
+	.cra_list		=	LIST_HEAD_INIT(xlr_cbc_aes_alg.cra_list),
+	.cra_u			=	{
+		.blkcipher = {
+			.min_keysize		=	DES3_EDE_KEY_SIZE,
+			.max_keysize		=	DES3_EDE_KEY_SIZE,
+			.setkey			=	xlr_des3_setkey,
+			.encrypt		=	xlr_cbc_encrypt,
+			.decrypt		=	xlr_cbc_decrypt,
+			.ivsize			=	DES3_EDE_BLOCK_SIZE,
+		}
+	}
+};
+
+
+static int __init xlr_crypt_alg_init(void)
+{
+	int ret;
+
+	if ((ret = crypto_register_alg(&xlr_aes_alg)))
+		goto err_out;
+
+	if ((ret = crypto_register_alg(&xlr_ecb_aes_alg)))
+		goto err1;
+
+	if ((ret = crypto_register_alg(&xlr_cbc_aes_alg)))
+		goto err2;
+
+	if ((ret = crypto_register_alg(&xlr_des_alg)))
+		goto err3;
+
+	if ((ret = crypto_register_alg(&xlr_ecb_des_alg)))
+		goto err4;
+
+	if ((ret = crypto_register_alg(&xlr_cbc_des_alg)))
+		goto err5;
+
+	if ((ret = crypto_register_alg(&xlr_des3_alg)))
+		goto err6;
+
+	if ((ret = crypto_register_alg(&xlr_ecb_des3_alg)))
+		goto err7;
+
+	if ((ret = crypto_register_alg(&xlr_cbc_des3_alg)))
+		goto err8;
+	
+//	if ((ret = crypto_register_alg(&xlr_ctr_aes_alg)))
+//		goto err9;
+
+	printk(KERN_NOTICE "Using XLR hardware for AES/DES/3DES algorithm.\n");
+	return 0;
+
+//err9:
+//	crypto_unregister_alg(&xlr_cbc_des3_alg);
+err8:
+	crypto_unregister_alg(&xlr_ecb_des3_alg);
+err7:
+	crypto_unregister_alg(&xlr_des3_alg);
+err6:
+	crypto_unregister_alg(&xlr_cbc_des_alg);
+err5:
+	crypto_unregister_alg(&xlr_ecb_des_alg);
+err4:
+	crypto_unregister_alg(&xlr_des_alg);
+err3:
+	crypto_unregister_alg(&xlr_cbc_aes_alg);
+err2:
+	crypto_unregister_alg(&xlr_ecb_aes_alg);
+err1:
+	crypto_unregister_alg(&xlr_aes_alg);
+err_out:
+	printk(KERN_ERR "XLR hardware AES/DES/3DES initialization failed.\n");
+	return ret;
+}
+
+static void __exit xlr_crypt_alg_fini(void)
+{
+	crypto_unregister_alg(&xlr_cbc_aes_alg);
+	crypto_unregister_alg(&xlr_ecb_aes_alg);
+	crypto_unregister_alg(&xlr_aes_alg);
+	crypto_unregister_alg(&xlr_cbc_des_alg);
+	crypto_unregister_alg(&xlr_ecb_des_alg);
+	crypto_unregister_alg(&xlr_des_alg);
+	crypto_unregister_alg(&xlr_cbc_des3_alg);
+	crypto_unregister_alg(&xlr_ecb_des3_alg);
+	crypto_unregister_alg(&xlr_des3_alg);
+//	crypto_unregister_alg(&xlr_ctr_aes_alg);
+}
+
+//module_init(xlr_crypt_alg_init);
+//module_exit(xlr_crypt_alg_fini);
+
+MODULE_DESCRIPTION("XLR Hardware AES/DES/3DES algorithms support.");
+MODULE_LICENSE("GPL/BSD");
+MODULE_AUTHOR("Sandip Matte");
+
diff --git a/drivers/crypto/rmi/rmi_state_info.h b/drivers/crypto/rmi/rmi_state_info.h
new file mode 100644
index 0000000..91158ed
--- /dev/null
+++ b/drivers/crypto/rmi/rmi_state_info.h
@@ -0,0 +1,115 @@
+struct xlr_crypt_state {
+
+	void *src;
+	void *dst;
+	void *auth_dst;
+	void *auth_src;
+	
+	u32 cipher;
+	u32 hash;
+
+	u32 mode;
+	u32 dir;
+	u32 flags;
+	int len;
+	int iv_len;
+	int block_size;
+	u8 *iv_ptr;
+	u8 *data_ptr;
+	u8 *out_data_ptr;
+	u8 *auth_ptr;
+	int hmac;
+	int hmac_keylen;
+	void *malloc_ptr;
+	int nr_data_desc;
+	//sandip -> check data_desc ptr...
+	uint64_t *cipher_desc;
+	uint64_t *cipher_key_hash_info;
+	uint64_t *data_desc;
+	int key_len;
+
+	u8 key[32]; // max key length
+	u8 iv[32]; // max iv length
+	u8 hmac_key[128]; // max hmac key length //sandip -> Check this length
+	u8 hash_result[128];
+	uint32_t nonce;
+//	u8 nonce[16];
+//	int nonce_len;
+	uint64_t data_msg;
+	uint64_t ctrl_msg;
+};
+
+#ifdef SANDIP
+
+/**
+ * SIZES of control data in bytes
+ */
+#define CTRL_DESC_VECTOR_SIZE 8
+#define CTRL_INSTR_SIZE 8
+#define MAX_CTRL_DATA_SIZE 472
+#define DATA_DESC_VECTOR_SIZE 8
+#define DATA_DESC_SIZE 32
+#define CEIL_BY_DIV(a,b) (((a)/b) + ((a%b)?1:0))
+#define ADDR_MASK 0xffffffffe0ULL
+#define DATA_DESC_VECTOR_TEMPLATE         ((5ULL << 61) | (1ULL << 45))
+#define MAX_FRAG_TOT_SIZE (((1 << 11) -1) * 8) /* 16 K - 8 */
+#define MAX_PER_FRAG_FIELD_SIZE (MAX_FRAG_TOT_SIZE >> 5 << 2)
+#define MAX_PER_FRAG_SIZE (MAX_FRAG_TOT_SIZE >> 5 << 5);
+
+#define PTR_OFFSET(a,b) (unsigned long)((((unsigned long)a) + (b)))
+#define HAS_REMINDER(x, y)  (((uint64_t)(x) & ((1ULL << (y)) - 1))?1:0)
+#define CEIL(n, bits) ((((uint64_t)n)>>(bits)) + HAS_REMINDER(n,bits))
+#define CEIL_BYTES(m,n) ((CEIL(m,n))<<(n))
+#define NEXT_CACHELINE_ALIGN(m) (unsigned long)(CEIL_BYTES(m, 5))
+#define CACHELINE_ALIGN(m) ((unsigned long long)(unsigned long)(m) >> 5 << 5)
+#define PTR_DIFF(x, y)   (((unsigned long)x) - ((unsigned long)(y)))
+
+#define APPLY_ADDR_MASK(phys,mask) ((unsigned long long)(phys) & (mask))
+
+typedef enum CipherAlgo {
+	CIPHER_BYPASS = 0,
+	RMI_DES,
+	RMI_DES3,
+	RMI_AES128,
+	RMI_AES192,
+	RMI_AES256,
+	RMI_ARC4,
+	RMI_KASUMI_F8,
+	MAX_CIPHER_ALGO
+} CipherAlgo_t;
+
+typedef enum CipherMode {
+	RMI_ECB = 0,
+	RMI_CBC,
+	RMI_CFB,
+	RMI_OFB,
+	RMI_CTR,
+	RMI_F8,
+	RMI_CCM,
+	MAX_CIPHER_MODE
+} CipherMode_t;
+
+typedef enum HashAlgo {
+	HASH_BYPASS = 0,
+	RMI_MD5,
+	RMI_SHA1,
+	RMI_SHA256,
+	RMI_SHA384,
+	RMI_SHA512,
+	RMI_GCM,
+	RMI_KASUMI_F9,
+	RMI_DES3_CMAC,
+	RMI_AES_CMAC,
+	MAX_HASH_ALGO
+} HashAlgo_t;
+
+typedef enum {
+	CIPHER_DECRYPT=0,
+	CIPHER_ENCRYPT
+} Cipher_Function_t;
+
+#endif /* SANDIP */
+
+//extern unsigned int xlr_digest(struct xlr_sae_op *op);
+//extern unsigned int xlr_crypt(struct xlr_sae_op *op);
+//extern int xlr_sec_init(void);
diff --git a/drivers/crypto/rmi/rmisec.c b/drivers/crypto/rmi/rmisec.c
new file mode 100644
index 0000000..b17f703
--- /dev/null
+++ b/drivers/crypto/rmi/rmisec.c
@@ -0,0 +1,2400 @@
+/***********************************************************************
+Copyright 2003-2009 RMI Corporation (RMI) All rights reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY RMI Corporation. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************_ RMI_2_**********************************/
+
+#ifndef AUTOCONF_INCLUDED
+#include <linux/config.h>
+#endif
+
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/sched.h>
+#include <linux/cdev.h>
+#include <linux/list.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <linux/highmem.h>
+#include <linux/proc_fs.h>
+#include <linux/kernel.h>
+#include <linux/hardirq.h>
+#include <linux/netdevice.h>
+#include <asm/current.h>
+#include <asm/atomic.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/utils.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/linux_crf.h>
+
+#ifdef CONFIG_OCF_OCF_MODULE
+#include <linux/crypto.h>
+#include <cryptodev.h>
+#endif /* CONFIG_OCF_OCF_MODULE */
+#include "rmisec_internal.h"
+#include "ecc_ucode_data.h"
+
+#define	ECC_UC_LOAD 0x70
+MODULE_AUTHOR("RMI Corporation");
+MODULE_DESCRIPTION("XLS/XLR SAE Driver");
+MODULE_LICENSE("Dual BSD/GPL");
+
+typedef struct device_info *device_info_pt;
+
+enum progress_type {
+	NOT_IN_PROGRESS = 0,
+	IN_PROGRESS,
+	IN_WAIT_QUEUE
+};
+
+#define IS_IN_PROGRESS(m) ((m)->in_progress == IN_PROGRESS)
+#define IS_IN_WAIT_QUEUE(m) ((m)->in_progress == IN_WAIT_QUEUE)
+
+#define NR_CRYPTO_BITS 9
+#define NR_PK_BITS 3
+/* we use only the last 8 bits, so we offet result of
+ * clz with this offset */
+#define PK_BITMAP_OFFSET 24
+
+#define NR_CRYPTO_OPS (1 << NR_CRYPTO_BITS)
+#define NR_PK_OPS     (1 << NR_PK_BITS)
+
+#define MAX_CRYPTO_OPS_INDEX   (NR_CRYPTO_OPS >> 5)
+
+#define CRYPTO_BITMAP_INDEX(x) (x >> 5)
+#define BITMAP_OFF_MASK(x)     ~(0x80000000 >> ((x) & 0x1f))
+#define BITMAP_ON_MASK(x)       (0x80000000 >> ((x) & 0x1f))
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+
+DECLARE_PER_CPU(struct napi_struct, xlr_napi_poll_struct);
+extern struct net_device xlr_napi_dummy_dev;
+void xlr_napi_poll_upper(struct net_device *dummy_dev, int *budget);
+extern int xlr_napi_ready, rmi_on_chip_napi;
+#define upper_buckets_nonempty() ((~msgrng_read_status() >> 28) & 0xf)
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+
+extern __u32 cpu_to_frstid[];
+static char driver_name[] = DRIVER_NAME;
+static char debug_name[] __attribute__((unused)) = "debug";
+static char stats_name[] = "stats";
+static char RMISAE_BUILD_VERSION[] = "1.7";
+static const char *versionstr = RMISAE_BUILD_VERSION;
+extern int xlr_loader_support;
+extern int xlr_loader_sharedcore;
+
+static atomic_t vma_count __cacheline_aligned;
+static uint64_t msgs_sent[NR_CPUS] __cacheline_aligned;
+static uint64_t resp_recieved[NR_CPUS] __cacheline_aligned;
+static uint64_t wait_count[NR_CPUS] __cacheline_aligned;
+static uint64_t mmap_cnt[NR_CPUS] __cacheline_aligned __attribute__((unused));
+static uint64_t mmapfree[NR_CPUS] __cacheline_aligned __attribute__((unused));
+static uint64_t cipher_cnt[NR_CPUS][MAX_CIPHER_ALGO][MAX_CIPHER_MODE] __cacheline_aligned;
+static uint64_t cipher_data_cnt[NR_CPUS][MAX_CIPHER_ALGO][MAX_CIPHER_MODE] __cacheline_aligned;
+static uint64_t hash_cnt[NR_CPUS][MAX_HASH_ALGO] __cacheline_aligned;
+static uint64_t hash_data_cnt[NR_CPUS][MAX_HASH_ALGO] __cacheline_aligned;
+static uint64_t mod_exp_cnt[NR_CPUS][2] __cacheline_aligned;
+static uint64_t ecc_prime_cnt[NR_CPUS][RMI_ECC_PRIME_CURVE_MAX][RMI_ECC_PRIME_OP_MAX] __cacheline_aligned __attribute__((unused));
+static uint64_t ecc_binary_cnt[NR_CPUS][RMI_ECC_BINARY_CURVE_MAX][RMI_ECC_BINARY_OP_MAX] __cacheline_aligned __attribute__((unused));
+
+static struct device_info {
+	int version;
+	dev_t device;
+	struct proc_dir_entry *pdir;
+	struct proc_dir_entry *pdebug;
+	struct proc_dir_entry *pstats;
+	struct cdev rmisec_cdev;
+#ifdef CONFIG_OCF_OCF_MODULE
+	op_callback_t ocf_cb;
+	softc_device_decl ocf_dev;
+	int32_t ocf_id;
+#endif /* CONFIG_OCF_OCF_MODULE */
+	spinlock_t mem_lock;
+	struct list_head pmem_list;
+
+	spinlock_t crypto_lock;
+	atomic_t crypto_used_slots;
+	unsigned int max_crypto_used_slots;
+	meminfo_pt crypto_ops_slot[NR_CRYPTO_OPS];
+	unsigned int pk_used_slots;
+	unsigned int max_pk_used_slots;
+	uint32_t crypto_ops_bitmap[MAX_CRYPTO_OPS_INDEX];
+	unsigned int bitmap_start;
+
+	spinlock_t pkops_lock;
+	volatile uint32_t pk_ops_bitmap;
+	meminfo_pt pk_ops_slot[NR_PK_OPS];
+	wait_queue_head_t crypto_queue;
+	wait_queue_head_t pkop_queue;
+	int exit_driver;
+} dev_info;
+
+extern void phnx_msgring_int_handler(unsigned int irq, struct pt_regs *regs);
+extern int msgring_int_type;
+
+static inline void remote_napi_poll_upper(void)
+{
+	unsigned long flags;
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	if(xlr_napi_ready && rmi_on_chip_napi &&
+	   upper_buckets_nonempty()) {
+		xlr_napi_poll_upper(&xlr_napi_dummy_dev, 0);
+	} else if (in_softirq() && (!msgring_int_type)){
+		local_irq_save(flags);
+		phnx_msgring_int_handler(-1,NULL);
+		local_irq_restore(flags);
+	}
+#else
+	if (in_softirq() && (!msgring_int_type)) {
+		local_irq_save(flags);
+		phnx_msgring_int_handler(-1,NULL);
+		local_irq_restore(flags);
+	}
+	return;
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+}
+
+
+#ifdef CONFIG_OCF_OCF_MODULE
+int rmisae_ocf_newsession(device_t dev, u_int64_t *sidp, struct cryptoini *cri);
+int rmisae_ocf_freesession(device_t dev, u_int64_t sid);
+int rmisae_ocf_process(device_t dev, struct cryptop *crp, int hint);
+
+static device_method_t rmisae_ocf_methods = {
+	DEVMETHOD(cryptodev_newsession, rmisae_ocf_newsession),
+	DEVMETHOD(cryptodev_freesession, rmisae_ocf_freesession),
+	DEVMETHOD(cryptodev_process, rmisae_ocf_process)
+};
+
+static struct {
+	int ocf_algo_num;
+	CipherAlgo_t c;
+	CipherMode_t m;
+	HashAlgo_t h;
+	int hmac;
+} algo_mapper[] = {
+	{CRYPTO_DES_CBC, RMI_DES, RMI_CBC, HASH_BYPASS, 0},
+	{CRYPTO_3DES_CBC, RMI_DES3, RMI_CBC, HASH_BYPASS, 0},
+	{-1},/* CRYPTO_BLF_CBC */
+	{-1},/* CRYPTO_CAST_CBC */
+	{-1},/* CRYPTO_SKIPJACK_CBC */
+	{CRYPTO_MD5_HMAC, CIPHER_BYPASS, RMI_ECB, RMI_MD5, 1},
+	{CRYPTO_SHA1_HMAC, CIPHER_BYPASS, RMI_ECB, RMI_SHA1, 1},
+	{-1},/* CRYPTO_RIPEMD160_HMAC */
+	{-1},/* CRYPTO_MD5_KPDK */
+	{-1},/* CRYPTO_SHA1_KPDK */
+	{CRYPTO_AES_CBC, RMI_AES128, RMI_CBC, HASH_BYPASS, 0},
+	{-1},/* ARC4 */
+	{CRYPTO_MD5, CIPHER_BYPASS, RMI_ECB, RMI_MD5, 0},
+	{CRYPTO_SHA1, CIPHER_BYPASS, RMI_ECB, RMI_SHA1, 0},
+	{-1},/* CRYPTO_NULL_HMAC */
+	{-1},/* CRYPTO_NULL_CBC */
+	{-1},/* CRYPTO_DEFLATE_COMP */
+	{CRYPTO_SHA2_256_HMAC, CIPHER_BYPASS, RMI_ECB, RMI_SHA256, 1},
+	{CRYPTO_SHA2_384_HMAC, CIPHER_BYPASS, RMI_ECB, RMI_SHA384, 1},
+	{CRYPTO_SHA2_512_HMAC, CIPHER_BYPASS, RMI_ECB, RMI_SHA512, 1},
+	{-1},/* CRYPTO_CAMELLIA_CBC */
+	{CRYPTO_SHA2_256, CIPHER_BYPASS, RMI_ECB, RMI_SHA256, 0},
+	{CRYPTO_SHA2_384, CIPHER_BYPASS, RMI_ECB, RMI_SHA384, 0},
+	{CRYPTO_SHA2_512, CIPHER_BYPASS, RMI_ECB, RMI_SHA512, 0},
+	{-1},/* CRYPTO_RIPEMD160 */
+};
+
+int rmisae_ocf_newsession(device_t dev, u_int64_t *sidp, struct cryptoini *cri)
+{
+	Crypto_Operation_pt cop;
+	if(in_atomic() || in_interrupt()) {
+		cop = (Crypto_Operation_pt)kmalloc(sizeof(Crypto_Operation_t),
+						  GFP_ATOMIC);
+	} else {
+		cop = (Crypto_Operation_pt)kmalloc(sizeof(Crypto_Operation_t),
+						  GFP_KERNEL);
+	}
+	if(cop == NULL) {
+		return -ENOMEM;
+	}
+
+	memset(cop, 0, sizeof(Crypto_Operation_t));
+
+	// populate all crypto fields here
+	cop->c = algo_mapper[cri->cri_alg].c;
+	cop->m = algo_mapper[cri->cri_alg].m;
+	cop->key = cri->key;
+	cop->key_len = cri->klen;
+	cop->iv = cri->cri_iv;
+	if(crp->flags & CRYPTO_OP_ENCRYPT) {
+		cop->encrypt = CIPHER_ENCRYPT;
+	}
+
+	/* authentication parameters */
+	if(cri->cri_next != NULL) {
+		cri = cri->next;
+		cop->h = algo_mapper[cri->cri_alg].h;
+		if(algo_mapper[cri->cri_alg].hmac) {
+			cop->hmac = (unsigned char *)cri->cri_key;
+			cop->hmac_len = cri->cri_klen;
+		}
+	}
+
+
+	*sidp = (u_int64_t)op;
+	return 0;
+
+	return rmisec_op_init(sidp);
+}
+
+int rmisae_ocf_freesession(device_t dev, u_int64_t sid)
+{
+	op_handle_t op = (op_handle_t)sid;
+	return rmisec_op_cleanup(&op);
+}
+
+int rmisae_ocf_process(device_t dev, struct cryptop *crp, int hint)
+{
+	Crypto_Operation_pt *cop = (Crypto_Operation_pt)crp->crp_sid;
+	op_handle_t op;
+	int ret = RMISAE_SUCCESS;
+
+	ret = rmisec_op_init(&op);
+	if(ret) {
+		goto bail;
+	}
+
+	if((ret = rmisec_op_callback_setup(op, &dev_info.ocf_cb,
+					  (unsigned long)op, 0))) {
+		printk(KERN_ALERT "%s:%d Error while submitting operation to SAE.",
+		       __FUNCTION__, __LINE__);
+		rmisec_op_cleanup(&op);
+		goto bail;
+	}
+
+	ret = rmisec_cipher_and_hash(op, cop->c, cop->m, cop->key, cop->iv,
+				     0, (crp->crp_desc.crd_flags & CRD_F_ENCRYPT),
+				     cop->h, cop->hmac,
+				     0, /* hash_src */
+				     0, /* hash_bytes_to_skip */
+				     crp->crp_buf, crp->crp_ilen,
+
+);
+	crypto_copyback(crp->crp_flags, crp->crp_buf,
+			crd->crd_inject, sw->u.hmac.sw_mlen, result);
+
+	if(!IS_ASYNC_SUCCESS_SAEOP(ret)) {
+		rmisec_op_cleanup(&op);
+	}
+ bail:
+	return ret;
+}
+
+void rmisae_ocf_callback(int result, unsigned long arg)
+{
+}
+
+#endif /* CONFIG_OCF_OCF_MODULE */
+
+#ifdef CONFIG_64BIT
+// doesn't read the old value
+static __inline__ void ldadd_d_noread(long long value, uint64_t *addr)
+{
+  __asm__ __volatile__(
+                       ".set push\n"
+                       ".set noreorder\n"
+                       "move $8, %2\n"
+                       "move $9, %3\n"
+//                       "ldaddd $8, $9\n"
+		       ".word 0x71280012\n"
+                       // "move %0, $8\n"
+                       ".set pop\n"
+                       : "=&r"(value), "+m"(*addr)
+                       : "0" (value), "r"((unsigned long)addr)
+                       : "$8", "$9"
+                       );
+}
+#endif /* CONFIG_64BIT */
+
+static inline int
+message_send_fast_2(unsigned int code,
+                    unsigned int stid,
+                    unsigned long long msg0,
+                    unsigned long long msg1)
+{
+        int ret;
+
+
+        msgrng_load_tx_msg0(msg0);
+        msgrng_load_tx_msg1(msg1);
+
+        __asm__ __volatile__ (".set push\n"
+                              ".set noreorder\n"
+                              ".set mips64\n"
+                              "sync\n"
+                              "1:move $8, %1\n"
+                              "c2 0x80001\n"
+			      "nop\n"
+			      "nop\n"
+			      "nop\n"
+			      "nop\n"
+			      "nop\n"
+                              "mfc2 $8, "STR(MSGRNG_MSG_STATUS_REG)"\n"
+                              "andi $8, $8, 0x6\n"
+                              "beqz $8, 2f\n"
+                              "andi $8, 2\n"
+                              "bnez $8, 1b\n"
+                              "2:move %0, $8\n"
+                              ".set pop\n"
+                              :"=r"(ret)
+                              : "r"((1<<16)|(code<<8)|stid)
+                              : "$8"
+                             );
+        return ret;
+}
+
+static inline int add_meminfo_to_queue(secop_queue_pt q, meminfo_pt mem)
+{
+	unsigned long flags = 0;
+	if(q->response_type == SECOP_Q) {
+		spin_lock_irqsave(&q->q.lock, flags);
+
+		if(q->q.max_length != -1 && q->q.length >= q->q.max_length) {
+			spin_unlock_irqrestore(&q->q.lock, flags);
+			return -EAGAIN;
+		}
+
+		q->q.length++;
+#ifdef SAE_STATS
+		if(q->q.length > q->q.stats_max_length) {
+			q->q.stats_max_length = q->q.length;
+		}
+#endif /* SAE_STATS */
+		mem->async_next = &q->q.head;
+		q->q.tail->async_next = mem;
+		q->q.tail = mem;
+
+#ifdef DEBUG_QUEUE
+		printk("%s:%d q=%p q->head=%p q->length=%d q->tail=%p "
+		       "h->next=%p t->next=%p\n", __FILE__, __LINE__, q,
+		       &q->q.head, q->q.length, q->q.tail, q->q.head.async_next,
+		       q->q.tail->async_next);
+#endif /* DEBUG_QUEUE */
+
+		spin_unlock_irqrestore(&q->q.lock, flags);
+	} else {
+		q->cb.cbfunc(mem->result, mem->return_value);
+	}
+
+	return 0;
+}
+
+static inline meminfo_pt remove_meminfo_from_queue(secop_queue_pt q)
+{
+	meminfo_pt ret = NULL;
+	unsigned long flags;
+
+	if(q->response_type == SECOP_Q) {
+		spin_lock_irqsave(&q->q.lock, flags);
+
+		if(q->q.head.async_next != &q->q.head) {
+			ret = q->q.head.async_next;
+			q->q.length--;
+			q->q.head.async_next = ret->async_next;
+
+			if(ret->async_next == &q->q.head) {
+				q->q.tail = &q->q.head;
+			}
+			ret->async_next = NULL;
+		}
+
+		spin_unlock_irqrestore(&q->q.lock, flags);
+	}
+	return ret;
+}
+
+#define ALL_SEC_STN 120
+#define PK_STN 124
+struct {
+	wait_queue_head_t *wq;
+	int stid;
+} op_data[OP_ALL] = {
+	{0, 0},
+	{&dev_info.crypto_queue, ALL_SEC_STN},
+	{&dev_info.pkop_queue, PK_STN},
+	{&dev_info.pkop_queue, PK_STN}
+};
+
+struct page *rmisec_vma_nopage(struct vm_area_struct *vma,
+			       unsigned long address, int *type);
+
+void rmisec_vma_open(struct vm_area_struct *vma);
+void rmisec_vma_close(struct vm_area_struct * vma);
+void write_magic(meminfo_pt mem, char __user *buf);
+
+struct vm_operations_struct vmops = {
+	.open = rmisec_vma_open,
+	.close = rmisec_vma_close,
+//	.nopage = rmisec_vma_nopage,
+};
+
+#define MEMINFO_MATCHED_PTR(m, ptr) ((m)->ptr == ptr)
+#define MEMINFO_MATCHED_VMA(m, vma) ((m)->vma == vma)
+
+/*
+ * Ops slot functions
+ */
+static int inline
+find_free_crypto_slot(device_info_pt dinfo)
+{
+	unsigned int start = dinfo->bitmap_start % MAX_CRYPTO_OPS_INDEX, i, j;
+ 	uint32_t *ptr = &dinfo->crypto_ops_bitmap[0];
+
+	i = start;
+	do {
+		j = find_32bit_1st_zero_bit(ptr[i]);
+		if(j < 32) {
+			ptr[i] |= BITMAP_ON_MASK(j);
+			dinfo->bitmap_start = i;
+			atomic_inc(&dinfo->crypto_used_slots);
+			return ((i << 5) + j);
+		}
+		i = ((i + 1) % MAX_CRYPTO_OPS_INDEX);
+	} while(i != start);
+
+	return -1;
+}
+
+static int inline
+alloc_crypto_op_slot(device_info_pt dinfo, meminfo_pt mem)
+{
+	unsigned long flags;
+	int i;
+	spin_lock_irqsave(&dinfo->crypto_lock, flags);
+	i = find_free_crypto_slot(dinfo);
+	spin_unlock_irqrestore(&dinfo->crypto_lock, flags);
+	if(i > -1) {
+		dinfo->crypto_ops_slot[i] = mem;
+#ifdef SAE_STATS
+		if(dinfo->max_crypto_used_slots < dinfo->crypto_used_slots.counter) {
+			dinfo->max_crypto_used_slots = dinfo->crypto_used_slots.counter;
+		}
+#endif /* SAE_STATS */
+	}
+	return i;
+}
+
+static int inline
+alloc_pk_ops_slot(device_info_pt dinfo, meminfo_pt mem)
+{
+	int j;
+	unsigned long flags;
+	spin_lock_irqsave(&dinfo->pkops_lock, flags);
+	j = find_32bit_1st_zero_bit(dinfo->pk_ops_bitmap);
+	if(j < 32) {
+		dinfo->pk_ops_bitmap |= BITMAP_ON_MASK(j);
+	}
+	spin_unlock_irqrestore(&dinfo->pkops_lock, flags);
+	if(j < 32) {
+		j = j - PK_BITMAP_OFFSET;
+		dinfo->pk_ops_slot[j] = mem;
+		/* for PK Ops bit 3 needs to be set to 1 */
+		j |= 0x8;
+		ldadd_wu_no_read(1, &dinfo->pk_used_slots);
+#ifdef SAE_STATS
+		if(dinfo->max_pk_used_slots < dinfo->pk_used_slots) {
+			dinfo->max_pk_used_slots = dinfo->pk_used_slots;
+		}
+#endif /* SAE_STATS */
+	} else {
+		j = -1;
+	}
+	return j;
+}
+
+static int inline
+alloc_op_slot(device_info_pt dinfo, meminfo_pt mem)
+{
+	if(mem->op_type == RMI_CRYPTO_OP) {
+		return alloc_crypto_op_slot(dinfo, mem);
+	} else if(mem->op_type > RMI_CRYPTO_OP && mem->op_type < OP_ALL) {
+		return alloc_pk_ops_slot(dinfo, mem);
+	} else {
+		printk("%s:%d Unknown op_type=%d\n", __FUNCTION__, __LINE__, mem->op_type);
+	}
+	return -1;
+}
+
+static void inline
+clear_op_slot(device_info_pt dinfo, OpType_t op_type, int cs)
+{
+	unsigned long flags;
+
+	if(op_type == RMI_CRYPTO_OP) {
+		spin_lock_irqsave(&dinfo->crypto_lock, flags);
+		dinfo->crypto_ops_bitmap[CRYPTO_BITMAP_INDEX(cs)] &= BITMAP_OFF_MASK(cs);
+		atomic_dec(&dinfo->crypto_used_slots);
+		spin_unlock_irqrestore(&dinfo->crypto_lock, flags);
+	} else if(op_type > RMI_CRYPTO_OP && op_type < OP_ALL) {
+		spin_lock_irqsave(&dinfo->pkops_lock, flags);
+		dinfo->pk_ops_bitmap &= BITMAP_OFF_MASK(cs + PK_BITMAP_OFFSET);
+		ldadd_w_no_read(-1, &dinfo->pk_used_slots);
+		spin_unlock_irqrestore(&dinfo->pkops_lock, flags);
+	} else {
+		printk("%s:%d Unknown op_type=%d crypto=%d cs=%d\n", __FUNCTION__, __LINE__,
+		       op_type, RMI_CRYPTO_OP, cs);
+	}
+	return;
+}
+
+/*
+ * Proc memlist functions
+ */
+static void inline
+free_proc_memlist(device_info_pt dinfo, proc_memlist_pt proc_info)
+{
+	meminfo_pt mem;
+	memlist_pt tmp, m;
+	int i = 0;
+
+	if(proc_info == NULL) {
+		printk(KERN_ALERT "%s:%d Invalid proc_memlist passed for "
+		       "freeing.\n", __FUNCTION__, __LINE__);
+		return;
+	}
+
+	list_for_each_safe(m, tmp, &proc_info->mem) {
+		mem = (meminfo_pt) m;
+		if(mem->owner != current->tgid) {
+			printk(KERN_ALERT "%s:%d Memory attempted to be freed by "
+			       "non-owner. owner=%d tgid=%d\n", __FUNCTION__, __LINE__,
+			       mem->owner, current->tgid);
+			return;
+		}
+		/*
+		 * Waiting for existing operation to complete.
+		 */
+		while(IS_IN_PROGRESS(mem)) {
+			i = 0;
+			while(IS_IN_PROGRESS(mem) && i < 100000) ++i;
+			if(IS_IN_PROGRESS(mem)) {
+				printk(KERN_NOTICE "%s:%d Waiting for meminfo "
+				       "in_progress state to change mem=%p\n",
+				       __FUNCTION__, __LINE__, mem);
+			}
+		}
+		free_meminfo(mem);
+	}
+
+	INIT_LIST_HEAD(&proc_info->mem);
+
+	kfree(proc_info);
+	return;
+}
+
+static proc_memlist_pt inline
+find_proc_memlist(device_info_pt dev)
+{
+	proc_memlist_pt proc_info = (proc_memlist_pt)dev->pmem_list.next;
+	while(proc_info != (proc_memlist_pt)&dev->pmem_list) {
+		if(proc_info->tgid == current->tgid) {
+			return proc_info;
+		}
+		proc_info = (proc_memlist_pt)proc_info->elem.next;
+	}
+	return NULL;
+}
+
+/*
+ * Meminfo functions
+ */
+static inline meminfo_pt
+find_meminfo_for_virt_addr(proc_memlist_pt proc_info, unsigned long start_addr)
+{
+	memlist_pt tmp;
+	meminfo_pt mem;
+	list_for_each(tmp, &proc_info->mem) {
+		mem = (meminfo_pt)tmp;
+		if(mem->owner == current->tgid) {
+			if(mem->vma->vm_start == start_addr) {
+				return mem;
+			}
+		} else {
+			printk(KERN_ALERT "%s:%d Memory attempted to be freed by "
+			       "non-owner. owner=%d tgid=%d\n", __FUNCTION__, __LINE__,
+			       mem->owner, current->tgid);
+		}
+	}
+	return 0;
+}
+
+void
+free_meminfo(meminfo_pt mem)
+{
+	if(!mem) return;
+	mem->magic = 0xBADBADBADBADBADAULL;
+#ifdef SAE_STATS
+#ifdef SYSTEM_CALL_STATS
+	dev_info.mmapfree[hard_smp_processor_id()]++;
+#endif /* SYSTEM_CALL_STATS */
+#endif /* SAE_STATS */
+	if(mem->ptr && mem->order > -1) {
+		if(mem->ctx == PROCESS_CTX) {
+			__free_pages((struct page *)mem->ptr, mem->order);
+		} else {
+			free_pages((unsigned long)mem->ptr, mem->order);
+		}
+	}
+	mem->memlist.next = mem->memlist.prev = NULL;
+	mem->ptr = NULL;
+	mem->proc = NULL;
+	mem->async_next = NULL;
+	mem->owner = 0;
+	mem->order = -1;
+	kfree(mem);
+	return;
+}
+
+static void inline
+insert_meminfo(proc_memlist_pt proc_info, meminfo_pt mem)
+{
+	list_add_tail((memlist_pt)mem, &proc_info->mem);
+	return;
+}
+
+static void inline
+free_meminfo_for_proc(proc_memlist_pt proc_info, meminfo_pt mem)
+{
+	if(mem->owner == current->tgid) {
+		list_del((memlist_pt)mem);
+		free_meminfo(mem);
+	} else {
+		printk(KERN_ALERT "%s:%d Memory attempted to be freed by "
+		       "non-owner. owner=%d tgid=%d\n", __FUNCTION__, __LINE__,
+		       mem->owner, current->tgid);
+	}
+	return;
+}
+
+void rmisec_vma_open(struct vm_area_struct *vma)
+{
+#ifdef DEBUG_2
+	printk(KERN_NOTICE "%s:%d\n", __FUNCTION__, __LINE__);
+#endif /* DEBUG */
+	atomic_inc(&vma_count);
+	return;
+}
+
+static meminfo_pt inline
+alloc_meminfo(proc_memlist_pt proc_info, CALL_CTX c_ctx,
+	      struct vm_area_struct *vma, int korder)
+{
+	unsigned long size;
+	unsigned int nrpages, order;
+	void *page_or_addr;
+	gfp_t gfp_flags = GFP_KERNEL;
+	int in_asi = (in_atomic() || in_softirq() || in_interrupt());
+
+	meminfo_pt ret;
+
+	if(c_ctx == PROCESS_CTX) {
+		/* find required size */
+		size = vma->vm_end - vma->vm_start;
+
+		/* find next higher order of 2 */
+		nrpages = CEIL(size, PAGE_SHIFT);
+
+		order = (31 - find_32bit_1st_one_bit(nrpages));
+
+		order += HAS_REMINDER(nrpages, order);
+		if(order) {
+			page_or_addr = alloc_pages(GFP_HIGHUSER|__GFP_COMP, order);
+		} else {
+			page_or_addr = alloc_pages(GFP_HIGHUSER, order);
+		}
+		if(!page_or_addr) {
+			printk("%s:%d No memory allocated to kernel %p\n", __FUNCTION__,
+			       __LINE__, page_or_addr);
+		}
+	} else {
+		if(in_asi) {
+		    gfp_flags = GFP_ATOMIC;
+		}
+		order = korder;
+		if(order) {
+			page_or_addr = (void *)__get_free_pages(gfp_flags|__GFP_COMP,
+								order);
+		} else {
+			page_or_addr = (void *)__get_free_page(gfp_flags);
+		}
+	}
+
+	if(page_or_addr != NULL) {
+		ret = (meminfo_pt)kmalloc(sizeof(meminfo_t), gfp_flags);
+		if(ret == NULL) {
+			if(c_ctx == PROCESS_CTX) {
+				__free_pages((struct page *)page_or_addr, order);
+			} else {
+				free_pages((unsigned long)page_or_addr, order);
+			}
+			printk(KERN_ALERT "%s:%d Error allocating meminfo "
+			       "structure.\n", __FUNCTION__, __LINE__);
+			return NULL;
+		}
+	} else {
+		printk(KERN_ALERT "%s:%d Error allocating pages "
+		       "order=%d\n", __FUNCTION__, __LINE__, order);
+		return NULL;
+	}
+
+	memset(ret, 0, sizeof(meminfo_t));
+	ret->magic = DRIVER_MAGIC;
+	ret->order = order;
+	ret->ptr = page_or_addr;
+	ret->ctx = c_ctx;
+	ret->vma = vma;
+	ret->memlist.next = ret->memlist.prev = NULL;
+	ret->async_next = NULL;
+	ret->in_progress = NOT_IN_PROGRESS;
+	init_waitqueue_head(&ret->wq);
+
+	if(c_ctx == PROCESS_CTX) {
+		ret->return_queue = &proc_info->async_queue;
+		ret->return_value = vma->vm_start;
+		ret->owner = current->tgid;
+		ret->proc = proc_info;
+		vma->vm_ops = &vmops;
+		vma->vm_private_data = ret;
+//		vma->vm_flags &= ~(VM_IO | VM_RESERVED);
+		vma->vm_flags |= VM_DONTCOPY;
+		rmisec_vma_open(vma);
+	}
+
+#ifdef DEBUG_MEMINFO
+	printk(KERN_NOTICE "%s:%d mem=%p order=%d page=%p\n",
+	       __FUNCTION__, __LINE__, ret, ret->order, ret->ptr);
+#endif /* DEBUG_MEMINFO */
+
+	return ret;
+}
+
+meminfo_pt
+alloc_meminfo_kernel_ctx(int order)
+{
+	meminfo_pt ret= alloc_meminfo(NULL, KERNEL_CTX, NULL, order);
+	if(ret) {
+		write_magic(ret, NULL);
+	}
+	return ret;
+}
+
+static meminfo_pt inline
+alloc_meminfo_process_ctx(proc_memlist_pt proc_info,
+			  struct vm_area_struct *vma)
+{
+	return alloc_meminfo(proc_info, PROCESS_CTX, vma, 0);
+}
+
+void rmisec_vma_close(struct vm_area_struct *vma)
+{
+	meminfo_pt mem = (meminfo_pt)vma->vm_private_data;
+	proc_memlist_pt proc_info;
+	int i;
+
+#ifdef DEBUG_2
+	printk(KERN_NOTICE "%s:%d\n", __FUNCTION__, __LINE__);
+#endif /* DEBUG */
+
+	if(mem != NULL && mem->magic == DRIVER_MAGIC &&
+	   mem->owner == current->tgid && mem->ptr != NULL && mem->order > -1) {
+		proc_info = mem->proc;
+		mem->proc = NULL;
+		if(proc_info && proc_info->tgid == current->tgid) {
+			do {
+				i = 0;
+				while(IS_IN_PROGRESS(mem) && i < 100000) ++i;
+				if(IS_IN_PROGRESS(mem)) {
+					printk(KERN_NOTICE "%s:%d Waiting for meminfo "
+					       "in_progress state to change mem=%p\n",
+					       __FUNCTION__, __LINE__, mem);
+				}
+			} while(IS_IN_PROGRESS(mem));
+			spin_lock_bh(&dev_info.mem_lock);
+			free_meminfo_for_proc(proc_info, mem);
+			spin_unlock_bh(&dev_info.mem_lock);
+
+			vma->vm_ops = NULL;
+			vma->vm_private_data = NULL;
+			atomic_dec(&vma_count);
+		}
+#if 0
+	} else {
+		if(mem) {
+			printk(KERN_ALERT "%s:%d Invalid meminfo %p %"LLX_FMT,
+			       __FUNCTION__, __LINE__, mem, mem->magic);
+		} else {
+			printk(KERN_ALERT "%s:%d meminfo is null",
+			       __FUNCTION__, __LINE__);
+		}
+#endif
+	}
+	return;
+}
+
+#if 0
+struct page *
+rmisec_vma_nopage(struct vm_area_struct *vma, unsigned long address, int *type)
+{
+	meminfo_pt m = (meminfo_pt)vma->vm_private_data;
+	struct page *page = NOPAGE_SIGBUS;
+	unsigned long offset = address - vma->vm_start;
+	int pg_idx = offset >> PAGE_SHIFT;
+
+	if(m && m->magic == DRIVER_MAGIC) {
+		if(pg_idx > ((1 << m->order) - 1)) {
+			printk(KERN_ALERT "%s:%d page=%p idx=%d count=%d map_count=%d "
+			       "flags=%08lx\n", __FUNCTION__, __LINE__, page, pg_idx,
+			       page->_count.counter, page->_mapcount.counter,
+			       page->flags);
+			return page;
+		}
+
+		page = ((struct page *)m->ptr) + pg_idx;
+#ifdef DEBUG
+		printk(KERN_NOTICE "%s:%d pid=%d tid=%d idx=%d pfn=0x%lx page=%p "
+		       "address=0x%lx vma->vm_start=0x%lx\n",
+		       __FUNCTION__, __LINE__, current->pid, current->tgid, pg_idx,
+		       page_to_pfn(page), page, address, vma->vm_start);
+#endif /* DEBUG */
+
+		get_page(page);
+
+		if(type)
+			*type = VM_FAULT_MINOR;
+	} else {
+		printk(KERN_ALERT "%s:%d no page mapping found at addr=0x%lx\n",
+		       __FILE__, __LINE__, address);
+	}
+
+	return page;
+}
+#endif /* 0 */
+
+void insert_proc_memlist(device_info_pt dinfo, proc_memlist_pt proc_info)
+{
+	proc_info->elem.prev = dinfo->pmem_list.prev;
+	proc_info->elem.next = &dinfo->pmem_list;
+
+	dinfo->pmem_list.prev->next = (struct list_head *)proc_info;
+	dinfo->pmem_list.prev = (struct list_head *)proc_info;
+}
+
+int rmisec_open(struct inode *iptr, struct file *fptr)
+{
+#ifdef DEBUG_SYSTEM_CALL
+	printk(KERN_NOTICE "%s:%d pid=%d tgid=%d ftpr=%p\n",
+	       __FUNCTION__, __LINE__, current->pid, current->tgid, fptr);
+#endif /* DEBUG_SYSTEM_CALL */
+	fptr->private_data = (void *)&dev_info;
+	return 0;
+}
+
+int rmisec_flush(struct file *fptr, fl_owner_t id)
+{
+#ifdef DEBUG_SYSTEM_CALL
+	printk(KERN_NOTICE "%s:%d pid=%d tgid=%d\n", __FUNCTION__, __LINE__,
+	       current->pid, current->tgid);
+#endif /* DEBUG_SYSTEM_CALL */
+	return 0;
+}
+
+int rmisec_release(struct inode *iptr, struct file *fptr)
+{
+	proc_memlist_pt proc_info;
+	device_info_pt dinfo = (device_info_pt)fptr->private_data;
+	if(current->pid != current->tgid) {
+		printk(KERN_DEBUG "%s:%d thread exit pid=%d tgid=%d\n",
+		       __FUNCTION__, __LINE__, current->pid, current->tgid);
+		return 0;
+	}
+
+	if(dinfo) {
+		fptr->private_data = NULL;
+		spin_lock_bh(&dinfo->mem_lock);
+		proc_info = find_proc_memlist(dinfo);
+		if(proc_info) {
+			/* dequeue proc_info */
+			proc_info->elem.prev->next = proc_info->elem.next;
+			proc_info->elem.next->prev = proc_info->elem.prev;
+			proc_info->elem.prev = proc_info->elem.next = NULL;
+		}
+		spin_unlock_bh(&dinfo->mem_lock);
+		if (proc_info) free_proc_memlist(dinfo, proc_info);
+	}
+
+#ifdef DEBUG_SYSTEM_CALL
+	printk(KERN_NOTICE "%s:%d pid=%d tgid=%d\n", __FUNCTION__, __LINE__,
+	       current->pid, current->tgid);
+#endif /* DEBUG_SYSTEM_CALL */
+	return 0;
+}
+
+void write_magic(meminfo_pt mem, char __user *buf)
+{
+	uint64_t ptr2 = 0;
+	control_struct_t ctrl;
+	control_struct_t *ptr;
+
+	if(mem->ctx == PROCESS_CTX) {
+		ptr = &ctrl;
+	} else {
+		ptr = mem->ptr;
+	}
+
+	memset(ptr, 0, sizeof(control_struct_t));
+	if(ptr != NULL) {
+		ptr->version = dev_info.version;
+		ptr->owner = current->tgid;
+		if(mem->ctx == PROCESS_CTX && ptr->owner == 0) {
+			printk("%s:%d tgid=0x%x\n", __FUNCTION__, __LINE__,
+			       current->tgid);
+/* 		} else { */
+/* 			printk("%s:%d tgid=0x%x\n", __FUNCTION__, __LINE__, */
+/* 			       current->tgid); */
+		}
+		ptr->magic = DRIVER_MAGIC;
+		if(mem->ctx == PROCESS_CTX) {
+			ptr2 = page_to_pfn((struct page *)(mem->ptr));
+			ptr2 <<= PAGE_SHIFT;
+		} else {
+			ptr2 = virt_to_phys(mem->ptr);
+		}
+		ptr->phy_addr = ptr2;
+		ptr->mem_addr = (uint64_t)((unsigned long)mem);
+		ptr->msg0 = ptr->msg1 = 0ULL;
+	} else {
+		printk(KERN_ALERT "%s:%d mem=%p ctx=%d ptr=NULL\n",
+		       __FUNCTION__, __LINE__, mem, mem->ctx);
+		return;
+	}
+
+	ptr = NULL;
+	if(mem->ctx == PROCESS_CTX) {
+		copy_to_user(buf, &ctrl, sizeof(control_struct_t));
+	}
+
+#ifdef DEBUG_MEMINFO
+	printk(KERN_NOTICE "%s:%d version=%x mem=%p ctx=%d buf=%p mptr=%p "
+	       "ptr2=0x%" LLX_FMT "\n",
+	       __FUNCTION__, __LINE__, dev_info.version, mem, mem?mem->ctx:-1,
+	       buf, mem->ptr, ptr2);
+#endif /* DEBUG_MEMINFO */
+	return;
+}
+
+
+int rmisec_mmap(struct file *fptr, struct vm_area_struct *vma)
+{
+	proc_memlist_pt proc_info;
+	meminfo_pt mem;
+	device_info_pt dinfo = (device_info_pt)fptr->private_data;
+	int ret = 0;
+	unsigned long pfn;
+//	unsigned long flags;
+
+	if(!dinfo) {
+		printk(KERN_NOTICE "%s:%d pid=%d tgid=%d ftpr=%p\n",
+		       __FUNCTION__, __LINE__, current->pid, current->tgid, fptr);
+		return -EINVAL;
+	}
+#ifdef DEBUG_SYSTEM_CALL
+	printk(KERN_NOTICE "%s:%d pid=%d tgid=%d ftpr=%p\n",
+	       __FUNCTION__, __LINE__, current->pid, current->tgid, fptr);
+#endif /* DEBUG_SYSTEM_CALL */
+
+	spin_lock_bh(&dinfo->mem_lock);
+
+	proc_info = find_proc_memlist(dinfo);
+#ifdef SAE_STATS
+#ifdef SYSTEM_CALL_STATS
+	dinfo->mmapcnt[hard_smp_processor_id()]++;
+#endif /* SYSTEM_CALL */
+#endif /* SAE_STATS */
+	spin_unlock_bh(&dev_info.mem_lock);
+
+	if(proc_info == NULL) {
+		proc_info = (proc_memlist_pt)kmalloc(sizeof(proc_memlist_t),
+						     GFP_KERNEL);
+		if(proc_info != NULL) {
+			INIT_SECOP_QUEUE(&proc_info->async_queue, -1);
+			proc_info->tgid = current->tgid;
+			INIT_LIST_HEAD(&proc_info->mem);
+			insert_proc_memlist(dinfo, proc_info);
+		} else {
+			printk("%s:%d Error allocating proc_memlist.\n",
+			       __FUNCTION__, __LINE__);
+			ret = -ENOMEM;
+			goto bail;
+		}
+	}
+
+	mem = alloc_meminfo_process_ctx(proc_info, vma);
+	if(mem == NULL) {
+		printk("%s:%d Error allocating meminfo.\n", __FUNCTION__,
+		       __LINE__);
+		ret = -ENOMEM;
+		goto bail;
+	}
+
+	spin_lock_bh(&dinfo->mem_lock);
+	insert_meminfo(proc_info, mem);
+#if 1
+	pfn = page_to_pfn((struct page *)mem->ptr);
+	if((ret = remap_pfn_range(vma, vma->vm_start,
+				  pfn, vma->vm_end - vma->vm_start,
+				  vma->vm_page_prot)) < 0) {
+		printk("%s:%d ret=%d\n", __FUNCTION__, __LINE__, ret);
+	}
+//	printk("%s:%d pfn=0x%lx page=%p\n", __FUNCTION__, __LINE__, pfn, mem->ptr);
+#endif
+	spin_unlock_bh(&dinfo->mem_lock);
+
+
+ bail:
+	return ret;
+}
+
+/*
+ * Send the operation pointed by meminfo to the crypto engine.
+ * Params:
+ * mem - Memory structure where the operation exists
+ * allow_sync - If asynchronous dispatch of this operation is allowed
+ * Returns:
+ * EAGAIN         : if the operation could not be sent to security engine
+ *                  due to credit failure
+ * RMISAE_SUCCESS : If the operation succeded
+ */
+
+int send_to_sae(meminfo_pt mem, int allow_async)
+{
+	device_info_pt dinfo = &dev_info;
+	int ret = RMISAE_SUCCESS;
+	int cs, stid;
+	unsigned long flags;
+	OpType_t op_type = mem->op_type;
+	struct msgrng_msg msg = {0ULL};
+	unsigned int t, hcpuid;
+	int in_asi = (in_atomic() || in_softirq() || in_interrupt());
+
+	if ((op_type != RMI_CRYPTO_OP) && (op_type != RMI_RSA_OP) &&
+	    (op_type != RMI_ECC_OP)) {
+		printk(KERN_ALERT "%s:%d Invalid op_type=%d mem=%p page=%p\n",
+		       __FUNCTION__, __LINE__, op_type, mem, mem->ptr);
+		return -EINVAL;
+	}
+
+	do {
+		cs = alloc_op_slot(dinfo, mem);
+		if(cs < 0) {
+			if(!in_asi &&
+			   waitqueue_active(op_data[op_type].wq)) {
+				init_waitqueue_entry(&mem->wqe, current);
+				add_wait_queue_exclusive(&mem->wq, &mem->wqe);
+				schedule_timeout(1);
+				remove_wait_queue(op_data[op_type].wq,
+						  &mem->wqe);
+			}
+		}
+	} while(cs < 0);
+
+	/* set response bucket and callslot.  That's the only
+	 * information userspace driver can't set.
+	 */
+	msg.msg0 = mem->msg0;
+	msg.msg1 = mem->msg1;
+
+	if(op_type == RMI_CRYPTO_OP) {
+		SET_CTRL_SCRATCH_VALUE(msg.msg0, cs);
+		SET_DATA_SCRATCH_VALUE(msg.msg1, cs);
+	} else if(op_type == RMI_RSA_OP || op_type == RMI_ECC_OP) {
+		/* bit 3 needs to be set to 1 for public key ops */
+		SET_CTRL_PK_SCRATCH_VALUE(msg.msg0, cs);
+		SET_DATA_PK_SCRATCH_VALUE(msg.msg1, cs);
+	}
+
+	stid = op_data[op_type].stid;
+
+	if(is_xls() && op_type != RMI_CRYPTO_OP) {
+		stid = MSGRNG_STNID_XLS_PK0;
+	}
+
+
+#ifdef DEBUG_MSGRNG
+	printk(KERN_NOTICE "%s:%d stid=%d ctrl_msg=0x%016" LLX_FMT
+	       " data_msg=0x%016" LLX_FMT " mem=%p cs=0x%x op_type=%d\n",
+	       __FUNCTION__, __LINE__, stid, msg.msg0, msg.msg1, mem,
+	       cs, op_type);
+#endif /* DEBUG_MSGRNG */
+
+	mem->resp0 = mem->resp1 = 0ULL;
+	mem->in_progress = IN_PROGRESS;
+
+	if(!in_asi) {
+		init_waitqueue_entry(&mem->wqe, current);
+		add_wait_queue(&mem->wq, &mem->wqe);
+	}
+
+	do {
+		t = 0;
+		msgrng_access_enable(flags);
+		hcpuid = hard_smp_processor_id();
+		remote_napi_poll_upper();
+		SET_FREEBACK_STN(msg.msg1, (cpu_to_frstid[hcpuid]));
+
+		ret = message_send_fast_2(0, stid, msg.msg0, msg.msg1);
+		if(ret != 0) {
+#ifdef DEBUG
+			printk(KERN_WARNING "%s:%d Error returned=%d cs=%d op_type=%d\n",
+			       __FUNCTION__, __LINE__, ret, cs, op_type);
+#endif /* DEBUG */
+#ifdef SAE_STATS
+			wait_count[hcpuid]++;
+#endif /* SAE_STATS */
+			if(allow_async && IS_ASYNC_OP(mem)) {
+				msgrng_access_disable(flags);
+				clear_op_slot(dinfo, op_type, cs);
+				ret = -EAGAIN;
+				mem->in_progress = NOT_IN_PROGRESS;
+				goto out;
+			} else {
+				if(++t == 100000) {
+					printk(KERN_WARNING
+					       "%s:%d Waiting to send message to SAE "
+					       "op_type=%d stid=%x ret=0x%x\n",
+					       __FUNCTION__, __LINE__, op_type, stid, ret);
+					t = 0;
+				}
+			}
+		}
+		msgrng_access_disable(flags);
+	} while(ret);
+#ifdef SAE_STATS
+	msgs_sent[hcpuid]++;
+#endif
+	t = 0;
+
+	// wait only if the ASYNC flag is not set
+	if(!IS_ASYNC_OP(mem)) {
+		if(op_type == RMI_CRYPTO_OP) {
+			while(IS_IN_PROGRESS(mem)) {
+				if(dinfo->crypto_used_slots.counter > 60 && !in_asi) {
+					schedule();
+				}
+				msgrng_access_enable(flags);
+				remote_napi_poll_upper();
+				msgrng_access_disable(flags);
+				if(++t == 10000000) {
+					printk("Stuck here\n");
+					t = 0;
+				}
+			}
+		} else {
+			while(IS_IN_PROGRESS(mem)) {
+				if(dinfo->pk_used_slots > 4 && !in_asi) {
+					schedule();
+				}
+				if(++t == 10000000) {
+					printk("Stuck here\n");
+					t = 0;
+				}
+				msgrng_access_enable(flags);
+				remote_napi_poll_upper();
+				msgrng_access_disable(flags);
+			}
+
+#if 0
+			printk("%s:%d th=%p qh=%p wq_active=%d\n",
+			       __FUNCTION__, __LINE__, mem->wqe.task_list.next,
+			       op_data[op_type].wq,
+			       waitqueue_active(op_data[op_type].wq));
+			printk("%s:%d qh=%p\n", __FUNCTION__, __LINE__,
+			       op_data[op_type].wq);
+#endif
+		}
+		ret = mem->result;
+	}
+
+ out:
+	if(!in_asi) {
+		remove_wait_queue(&mem->wq, &mem->wqe);
+	}
+	return ret;
+}
+
+#if 0
+static void print_meminfo_proclist(device_info_pt dinfo)
+{
+	proc_memlist_pt proc_info;
+	memlist_pt tmp;
+	meminfo_pt mem;
+
+	spin_lock_bh(&dinfo->mem_lock);
+	proc_info = find_proc_memlist(dinfo);
+	if (proc_info) {
+		list_for_each(tmp, &proc_info->mem) {
+			mem = (meminfo_pt)tmp;
+			printk(KERN_ALERT "[%s:%d] magic=%llx op_type=%x mem=%p page=%p, "
+			       "msg0=%" LLX_FMT ", msg1=%" LLX_FMT "\n",
+			       __FUNCTION__, __LINE__, mem->magic, mem->op_type,
+			       mem, mem->ptr, mem->msg0, mem->msg1);
+		}
+	}
+	spin_unlock_bh(&dinfo->mem_lock);
+}
+#endif
+
+static long
+rmisec_ioctl(struct file *fptr, unsigned int type, unsigned long val)
+{
+	char __user *buf = (char __user *)val;
+	device_info_pt dinfo = (device_info_pt)fptr->private_data;
+	proc_memlist_pt proc_info;
+	meminfo_pt mem = NULL;
+	int ret = 0;
+
+	if(type == RMISEC_IOCTL_GET_MEMINFO) {
+		spin_lock_bh(&dinfo->mem_lock);
+		proc_info = find_proc_memlist(dinfo);
+
+		mem = find_meminfo_for_virt_addr(proc_info, val);
+		if(mem) {
+			write_magic(mem, buf);
+		} else {
+			ret = -2;
+		}
+		spin_unlock_bh(&dinfo->mem_lock);
+	} else {
+		ret = -1;
+	}
+
+#ifdef DEBUG
+	printk("%s:%d type=%d val=%lx ret=%d\n", __FUNCTION__, __LINE__, type, val, ret);
+#endif /* DEBUG */
+	return ret;
+}
+
+// no range checking... Take care while calling this function
+void xlr_inc_enc_stat(int cipher_algo, int cipher_mode, int data_size)
+{
+	int cpu = hard_smp_processor_id();
+
+	if(cipher_algo != CIPHER_BYPASS) {
+		cipher_cnt[cpu][cipher_algo][cipher_mode]++;
+		cipher_data_cnt[cpu][cipher_algo][cipher_mode] += data_size;
+	}
+}
+
+// no range checking... Take care while calling this function
+void xlr_inc_auth_stat(int hash_algo, int data_size)
+{
+	int cpu = hard_smp_processor_id();
+
+	if(hash_algo != HASH_BYPASS) {
+		hash_cnt[cpu][hash_algo]++;
+		hash_data_cnt[cpu][hash_algo] += data_size;
+	}
+}
+
+void
+add_stats_count(control_struct_pt ctrl, int cpu)
+{
+	if(ctrl->op_type == RMI_CRYPTO_OP) {
+		if(ctrl->cipher_algo != CIPHER_BYPASS) {
+			cipher_cnt[cpu][ctrl->cipher_algo][ctrl->cipher_mode]++;
+			cipher_data_cnt[cpu][ctrl->cipher_algo][ctrl->cipher_mode] += ctrl->data_size;
+		}
+
+		if(ctrl->hash_algo != HASH_BYPASS) {
+			hash_cnt[cpu][ctrl->hash_algo]++;
+			hash_data_cnt[cpu][ctrl->hash_algo] += ctrl->data_size;
+		}
+	}
+
+	if(ctrl->op_type == RMI_RSA_OP) {
+		if(ctrl->rsa_algo == BIT_512 ||
+		   ctrl->rsa_algo == BIT_1024) {
+			mod_exp_cnt[cpu][ctrl->rsa_algo - 1]++;
+		}
+	}
+
+	if(ctrl->op_type == RMI_ECC_OP) {
+		if(ctrl->ecc_degree < RMI_ECC_PRIME_CURVE_MAX) {
+			ecc_prime_cnt[cpu][ctrl->ecc_degree][ctrl->ecc_algo]++;
+		} else {
+			ecc_binary_cnt[cpu][ctrl->ecc_degree -
+					    RMI_ECC_BINARY_163][ctrl->ecc_algo]++;
+		}
+	}
+
+	return;
+}
+
+static ssize_t
+rmisec_read(struct file *fptr, char __user *cptr, size_t size,
+	     loff_t *off)
+{
+	uint64_t magic;
+	pid_t owner_pid;
+	int ret = 0;
+	meminfo_pt mem = NULL;
+	device_info_pt dinfo = (device_info_pt)fptr->private_data;
+	control_struct_t ctrl;
+	int async = 0;
+
+	if(size != sizeof(control_struct_t)) {
+		printk(KERN_ALERT "%s:%d Incorrect operation attempted.\n",
+		       __FUNCTION__, __LINE__);
+		return -EFAULT;
+	}
+
+	copy_from_user(&ctrl, cptr, sizeof(control_struct_t));
+
+	if(ctrl.magic != DRIVER_MAGIC) {
+		printk(KERN_ALERT "%s:%d Invalid call to write system call id=%"
+		       LLX_FMT "\n",
+		       __FUNCTION__, __LINE__, ctrl.magic);
+		return -EINVAL;
+	}
+
+
+	mem = (meminfo_pt)((unsigned long)ctrl.mem_addr);
+
+#ifdef DEBUG
+	printk(KERN_NOTICE "%s:%d tgid=0x%x pid=0x%x ptr=%p size=%u magic=%llx "
+	       "owner=0x%x mem=%p\n",
+	       __FUNCTION__, __LINE__, current->tgid, current->pid, cptr,
+	       (unsigned int)size, ctrl.magic, ctrl.owner, mem);
+#endif /* DEBUG */
+
+	spin_lock_bh(&dinfo->mem_lock);
+
+	if(mem == NULL || mem->ptr == NULL || mem->magic != DRIVER_MAGIC) {
+		printk(KERN_ALERT "%s:%d Unknown operation structure mem=%p magic=%llx\n",
+		       __FUNCTION__, __LINE__, mem, mem?mem->magic:0ULL);
+
+//		print_meminfo_proclist(dinfo);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	if(mem->owner != current->tgid) {
+		printk(KERN_ALERT "%s:%d The memory region was allocated by "
+		       "another process pid=%d and now being accessed by process %d",
+		       __FUNCTION__, __LINE__, mem->owner, current->tgid);
+		ret = -EFAULT;
+		goto bail;
+	}
+
+	magic = ctrl.magic;
+	mem->msg0 = ctrl.msg0;
+	mem->msg1 = ctrl.msg1;
+	if(async) {
+		mem->op_flags = OP_NO_WAIT;
+	}
+	mem->result = RMISAE_SUCCESS;
+//	mem->return_queue = proc_info->async_queue;
+//	mem->return_value = proc_info;
+	mem->op_type = ctrl.op_type;
+	mem->in_progress = IN_PROGRESS;
+	owner_pid = ctrl.owner;
+ bail:
+	spin_unlock_bh(&dinfo->mem_lock);
+	if(ret) {
+		printk("%s:%d Aborting operation due to error=%d\n",
+		       __FUNCTION__, __LINE__, ret);
+		return ret;
+	}
+
+	ret = -1;
+	/* Check magic of the memory passed to kernel */
+	if ((magic != DRIVER_MAGIC) || (current->tgid != owner_pid) ||
+	     ((mem->op_type != RMI_CRYPTO_OP) &&
+	      (mem->op_type != RMI_RSA_OP) && (mem->op_type != RMI_ECC_OP))) {
+
+		printk(KERN_ALERT "%s:%d magic=%" LLX_FMT
+		       " pid=0x%x owner=0x%x op_type=%x mem=%p page=%p, msg0=%" LLX_FMT
+		       ", msg1=%" LLX_FMT "\n", __FUNCTION__, __LINE__, magic,
+		       current->tgid, owner_pid, mem->op_type, mem, mem->ptr,
+		       mem->msg0, mem->msg1);
+		mem->in_progress = NOT_IN_PROGRESS;
+		return -EFAULT;
+	}
+
+	ret = send_to_sae(mem, async);
+
+#ifdef DEBUG_3
+	copy_from_user(&junk_buf[0], cptr, 4096);
+	print_4k(&junk_buf[0], 0);
+#endif /* DEBUG_2 */
+	if(IS_SUCCESS_SAEOP(ret)) {
+		add_stats_count(&ctrl, hard_smp_processor_id());
+		/* copying response back */
+		ctrl.msg0 = mem->resp0;
+		ctrl.msg1 = mem->resp1;
+		copy_to_user(cptr, &ctrl, sizeof(control_struct_t));
+		ret = mem->result;
+	}
+
+	return ret;
+}
+
+struct file_operations fops = {
+    .owner = THIS_MODULE,
+    .open = rmisec_open,
+    .mmap = rmisec_mmap,
+    .read = rmisec_read,
+//    .write = rmisec_write,
+
+    .unlocked_ioctl = rmisec_ioctl,
+//    .flush = rmisec_flush,
+    .release = rmisec_release,
+};
+
+static int
+print_stats_info(device_info_pt dinfo, char *buf, int size)
+{
+	int i, x, t = size, p, q;
+	uint64_t m_sent = 0, r_received = 0, w_count = 0;
+	uint64_t c_cnt[MAX_CIPHER_ALGO][MAX_CIPHER_MODE] = {{0}};
+	uint64_t c_data_cnt[MAX_CIPHER_ALGO][MAX_CIPHER_MODE] = {{0}};
+	uint64_t h_cnt[MAX_HASH_ALGO] = {0};
+	uint64_t h_data_cnt[MAX_HASH_ALGO] = {0};
+	uint64_t m_exp_cnt[2] = {0};
+	uint64_t ec_p_cnt[RMI_ECC_PRIME_CURVE_MAX][RMI_ECC_PRIME_OP_MAX] = {{0}};
+	uint64_t ec_b_cnt[RMI_ECC_BINARY_CURVE_MAX][RMI_ECC_BINARY_OP_MAX] = {{0}};
+
+#ifdef SYSTEM_CALL_STATS
+	uint64_t map_cnt = 0, map_free = 0;
+#endif /* SYSTEM_CALL_STATS */
+	x = snprintf(buf, t, "CPU\t\tSent\t\tReceived\n");
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+
+	for(i = 0; i < NR_CPUS; ++i) {
+		x = snprintf(buf, t, "%d\t\t%" LLU_FMT "\t\t%" LLU_FMT "\n", i,
+			     msgs_sent[i], resp_recieved[i]);
+		t -= x;
+		buf += x;
+		if(t <= 0) {
+			goto end;
+		}
+
+		m_sent += msgs_sent[i];
+		r_received += resp_recieved[i];
+		w_count += wait_count[i];
+		for(p = 1; p < MAX_CIPHER_ALGO; ++p) {
+			for(q = 0; q < MAX_CIPHER_MODE; ++q) {
+				if(valid_cipher_algo_mode_matrix[p][q]) {
+					c_cnt[p][q] += cipher_cnt[i][p][q];
+					c_data_cnt[p][q] += cipher_data_cnt[i][p][q];
+//					cipher_cnt[i][p][q] = cipher_data_cnt[i][p][q] = 0;
+				}
+			}
+		}
+
+		for(p = 1; p < MAX_HASH_ALGO-2; ++p) {
+			h_cnt[p] += hash_cnt[i][p];
+			h_data_cnt[p] += hash_data_cnt[i][p];
+//			hash_cnt[i][p] = hash_data_cnt[i][p] = 0;
+		}
+
+		if(is_xls()) {
+			for(p = RMI_ECC_PRIME_160;
+			    p < RMI_ECC_PRIME_CURVE_MAX; ++p) {
+				for(q = RMI_ECC_PRIME_P_MUL; q < RMI_ECC_PRIME_OP_MAX;
+				    ++q) {
+					ec_p_cnt[p][q] += ecc_prime_cnt[i][p][q];
+//					ecc_prime_cnt[i][p][q] = 0;
+				}
+			}
+
+			for(p = 0; p < RMI_ECC_BINARY_CURVE_MAX; ++p) {
+				for(q = RMI_ECC_BINARY_P_MUL;
+				    q < RMI_ECC_BINARY_OP_MAX; ++q) {
+					ec_b_cnt[p][q] += ecc_binary_cnt[i][p][q];
+//					ecc_binary_cnt[i][p][q] = 0;
+				}
+			}
+		}
+#ifdef SYSTEM_CALL_STATS
+		map_cnt += mmapcnt[i];
+		map_free += mmapfree[i];
+		mmapcnt[i] = mmapfree[i] =
+#endif /* SYSTEM_CALL_STATS */
+//			wait_count[i] =
+//			msgs_sent[i] =
+//			resp_recieved[i] = 0;
+	}
+
+	x = snprintf(buf, t, "Total msgs\t\t%"LLU_FMT "\t\t%" LLU_FMT "\n",
+		     m_sent, r_received);
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "Cipher Algorithms:\n");
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+
+	for(p = 1; p < MAX_CIPHER_ALGO; ++p) {
+		for(q = 0; q < MAX_CIPHER_MODE; ++q) {
+			if(valid_cipher_algo_mode_matrix[p][q] && c_cnt[p][q]) {
+				x = snprintf(buf, t,
+					     "%11s-%-4s Count: %16" LLU_FMT
+					     " Size: %16" LLU_FMT "\n",
+					     cipher_str[p], mode_str[q], c_cnt[p][q],
+					     c_data_cnt[p][q]);
+				t -= x;
+				buf += x;
+				if(t <= 0) {
+					goto end;
+				}
+			}
+		}
+	}
+
+	x = snprintf(buf, t, "Hash Algorithms:\n");
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+
+	for(p = 1; p < MAX_HASH_ALGO - 2; ++p) {
+		if(h_cnt[p]) {
+			x = snprintf(buf, t, "%11s Count: %16" LLU_FMT " Size: %16"
+				     LLU_FMT "\n", hash_str[p],
+				     h_cnt[p], h_data_cnt[p]);
+			t -= x;
+			buf += x;
+			if(t <= 0) {
+				goto end;
+			}
+		}
+	}
+
+	x = snprintf(buf, t, "RSA Mod Exp Algorithms:\n");
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+
+	for(p = BIT_512; p < BIT_SIZE_MAX; ++p) {
+		for(i = 0; i < NR_CPUS; ++i) {
+			m_exp_cnt[p-1] += mod_exp_cnt[i][p-1];
+//			mod_exp_cnt[i][p-1] = 0;
+		}
+		if(m_exp_cnt[p-1]) {
+			x = snprintf(buf, t, "%11s: %11" LLU_FMT "\n",
+				     rsa_mod_str[p-1], m_exp_cnt[p-1]);
+			t -= x;
+			buf += x;
+			if(t <= 0) {
+				goto end;
+			}
+		}
+	}
+
+	if(is_xls()) {
+		x = snprintf(buf, t, "ECC Algorithms:\n");
+		t -= x;
+		buf += x;
+		if(t <= 0) {
+			goto end;
+		}
+
+
+		for(p = RMI_ECC_PRIME_160;
+		    p < RMI_ECC_PRIME_CURVE_MAX; ++p) {
+			for(q = RMI_ECC_PRIME_P_MUL; q < RMI_ECC_PRIME_OP_MAX;
+			    ++q) {
+				if(ec_p_cnt[p][q]) {
+					x = snprintf(buf, t,
+						     "%11s-%-11s: %11" LLU_FMT "\n",
+						     ecc_prime_curve_str[p],
+						     ecc_prime_func_str[q],
+						     ec_p_cnt[p][q]);
+					t -= x;
+					buf += x;
+					if(t <= 0) {
+						goto end;
+					}
+				}
+			}
+		}
+
+		for(p = 0; p < RMI_ECC_BINARY_CURVE_MAX; ++p) {
+			for(q = RMI_ECC_BINARY_P_MUL;
+			    q < RMI_ECC_BINARY_OP_MAX; ++q) {
+				if(ec_b_cnt[p][q]) {
+					x = snprintf(buf, t,
+						     "%11s-%-11s: %11" LLU_FMT "\n",
+						     ecc_binary_curve_str[p],
+						     ecc_binary_func_str[q],
+						     ec_b_cnt[p][q]);
+					t -= x;
+					buf += x;
+					if(t <= 0) {
+						goto end;
+					}
+				}
+			}
+		}
+	}
+
+	x = snprintf(buf, t, "Current Crypto outstanding msg=%u\n", dinfo->crypto_used_slots.counter);
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "Max Crypto outstanding msg=%u\n", dinfo->max_crypto_used_slots);
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+//	dinfo->max_crypto_used_slots = 0;
+
+	x = snprintf(buf, t, "Current Pk outstanding msg=%u\n", dinfo->pk_used_slots);
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "Max Pk outstanding msg=%u\n", dinfo->max_pk_used_slots);
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+//	dinfo->max_pk_used_slots = 0;
+
+	x = snprintf(buf, t, "Wait count =%"LLU_FMT "\n", w_count);
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "VMA count =%u\n", vma_count.counter);
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+//	vma_count.counter = 0;
+
+#ifdef SYSTEM_CALL_STATS
+	x = snprintf(buf, t, "MMap count =%"LLU_FMT "\n", map_cnt);
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "MMap free =%"LLU_FMT "\n", map_free);
+	t -= x;
+	buf += x;
+	if(t <= 0) {
+		goto end;
+	}
+#endif /* SYSTEM_CALL_STATS */
+ end:
+	return size - t;
+}
+
+#ifdef ENABLE_DEBUG_PROC
+static int
+print_page_info(device_info_pt dinfo, char *buf, int size)
+{
+	proc_memlist_pt proc_info;
+	memlist_pt m;
+	meminfo_pt mem;
+	int t = size, x;
+
+	if(!spin_trylock_bh(&dinfo->mem_lock)) {
+		return snprintf(buf, t, "Lock not acquired.  Please try later.\n");
+	}
+
+	x = snprintf(buf, t, "Build version: %s\n", versionstr);
+	t -= x;
+	buf += x;
+
+	x = snprintf(buf, t, "pid\torder\tpage addr\t\tpfn\n");
+	t -= x;
+	buf += x;
+
+	proc_info = (proc_memlist_pt)dinfo->pmem_list.next;
+	while(proc_info != (proc_memlist_pt)&dinfo->pmem_list) {
+		list_for_each(m, &proc_info->mem) {
+			mem = (meminfo_pt)m;
+			x = snprintf(buf, t, "%d\t%d\t%p\t\t%lx\n", proc_info->tgid,
+				     mem->order, mem->ptr,
+				     page_to_pfn((struct page *)(mem->ptr)));
+			t -= x;
+			buf += x;
+			if(t <= 0) {
+				break;
+			}
+		}
+		proc_info = (proc_memlist_pt)proc_info->elem.next;
+	}
+
+	spin_unlock_bh(&dinfo->mem_lock);
+	return size - t;
+}
+#endif /* ENABLE_DEBUG_PROC */
+
+static inline
+meminfo_pt get_meminfo(device_info_pt dinfo, uint64_t msg0, uint64_t msg1)
+{
+#define CRYPTO_SCRATCH_VALUE(x,y)     ((((x) & 0xfULL) << 5) | \
+				       ((y) & 0x1fULL))
+
+#define PK_SCRATCH_VALUE(x,y)         ((((x) & 0x8ULL) >> 1) | \
+				       (((y) >> 3) & 0x3ULL))
+	int cs;
+	meminfo_pt mem = NULL;
+
+	if(msg0 & 0x10) {  /* PK OP Condition */
+		cs = PK_SCRATCH_VALUE(msg0, msg1);
+		mem = dinfo->pk_ops_slot[cs];
+		dinfo->pk_ops_slot[cs] = NULL;
+		clear_op_slot(dinfo, RMI_RSA_OP, cs);
+	} else { /* Crypto Condition */
+		cs = CRYPTO_SCRATCH_VALUE(msg0, msg1);
+		mem = dinfo->crypto_ops_slot[cs];
+		dinfo->crypto_ops_slot[cs] = NULL;
+		clear_op_slot(dinfo, RMI_CRYPTO_OP, cs);
+	}
+
+	/* Added this to catch a problem observed a few times when
+	 * response comes back, but mem ptr is NULL. */
+	if(mem == NULL) {
+		int i;
+		printk("%s:%d MEMPTR is NULL. OpType=%" LLX_FMT " msg0=%" LLX_FMT " msg1=%"
+		       LLX_FMT " cs=%d mem=%p\n",
+		       __FUNCTION__, __LINE__, (msg0 & 0x10), msg0, msg1, cs, mem);
+		if(msg0 & 0x10) {
+			for(i = 0; i < 8; ++i) {
+				printk("%d=[%p] ", i, dinfo->pk_ops_slot[i]);
+			}
+		} else {
+			for(i = 0; i < 8; ++i) {
+				printk(" %d=[%p] ", i,
+				       dinfo->crypto_ops_slot[i]);
+			}
+		}
+		printk("\n");
+	}
+
+	return mem;
+}
+
+void rmisec_msgring_handler(int bucket, int size, int code, int stid,
+                            struct msgrng_msg *msg, void *data)
+{
+	device_info_pt dinfo = (device_info_pt)data;
+	volatile meminfo_pt mem;
+	int ret = RMISAE_SUCCESS;
+	control_struct_pt ctrl;
+#ifdef SAE_STATS
+	resp_recieved[hard_smp_processor_id()]++;
+#endif /* SAE_STATS */
+
+#ifdef DEBUG_MSGRNG
+	printk("%s:%d msg0=%016" LLX_FMT " msg1=%016" LLX_FMT "\n", __FUNCTION__,
+	       __LINE__, msg->msg0, msg->msg1);
+#endif
+
+	if(CTRL_HEAD(msg->msg0) != 2ULL ||
+	   CTRL_DEST_CTRL(msg->msg0) != 6ULL ||
+	   DATA_HEAD(msg->msg1) != 2ULL ||
+	   DATA_DEST_CTRL(msg->msg1) != 5ULL ||
+	   CTRL_ERROR(msg->msg0) != 0ULL ||
+	   DATA_ERROR(msg->msg1) != 0ULL) {
+		printk(KERN_ALERT "%s:%d Invalid/Error response from SAE "
+		       "msg0=%016" LLX_FMT " msg1=%016" LLX_FMT " ctrl_head=%"
+		       LLX_FMT " ctrl_error=%" LLX_FMT " ctrl_ctrl=%" LLX_FMT
+		       " data_head=%" LLX_FMT " data_error=%" LLX_FMT
+		       " dest_ctrl=%" LLX_FMT "\n",
+		       __FUNCTION__, __LINE__,
+		       msg->msg0, msg->msg1, CTRL_HEAD(msg->msg0),
+		       CTRL_ERROR(msg->msg0),
+		       CTRL_DEST_CTRL(msg->msg0), DATA_HEAD(msg->msg1),
+		       DATA_ERROR(msg->msg1), DATA_DEST_CTRL(msg->msg1));
+		ret = -CTRL_ERROR(msg->msg0);
+		if(!ret)
+			ret = -DATA_ERROR(msg->msg1);
+	}
+
+#if 0
+	if(dinfo != &dev_info) {
+		printk(KERN_ALERT
+		       "%s:%d Error returning handler data=%p dev_info=%p\n",
+		       __FUNCTION__, __LINE__, data, &dev_info);
+		dinfo = &dev_info;
+	}
+#endif
+
+	mem = get_meminfo(dinfo, msg->msg0, msg->msg1);
+#ifdef DEBUG_MSGRNG
+	printk(KERN_NOTICE "%s:%d stid=%d code=%d meminfo=%p\n",
+	       __FUNCTION__, __LINE__, stid, code, mem);
+#endif /* DEBUG_MSGRNG */
+
+	if(mem != NULL && mem->magic == DRIVER_MAGIC) {
+		mem->resp0 = msg->msg0;
+		mem->resp1 = msg->msg1;
+
+		if(mem->ctx == PROCESS_CTX) {
+			mem->resp0 = msg->msg0;
+			mem->resp1 = msg->msg1;
+		} else if(mem->ctx == KERNEL_CTX) {
+			ctrl = (control_struct_pt)(mem->ptr);
+//			magic = ctrl->magic;
+			ctrl->msg0 = msg->msg0;
+			ctrl->msg1 = msg->msg1;
+		}
+
+		ctrl = NULL;
+
+		mem->result = ret;
+
+		if(IS_ASYNC_OP(mem)) {
+			add_meminfo_to_queue(mem->return_queue, mem);
+		} else {
+			if(waitqueue_active(&mem->wq)) {
+				wake_up(&mem->wq);
+			}
+
+			if(waitqueue_active(op_data[mem->op_type].wq)) {
+				wake_up_interruptible(op_data[mem->op_type].wq);
+			}
+		}
+
+		mem->in_progress = NOT_IN_PROGRESS;
+		wmb();
+
+#if 0
+		if(unlikely(magic != DRIVER_MAGIC)) {
+			printk(KERN_ALERT "%s:%d Invalid magic=%" LLX_FMT " mem=%p\n",
+			       __FUNCTION__, __LINE__, magic, mem);
+		}
+#endif
+
+#ifdef DEBUG
+	} else {
+		printk(KERN_NOTICE "%s:%d Operation completed but, "
+		       "no meminfo found.\n", __FUNCTION__, __LINE__);
+#endif /* DEBUG */
+	}
+
+	return;
+}
+
+static int
+rmisec_read_stats_proc(char *page, char **start, off_t offset, int count,
+		       int *eof, void *data)
+{
+	device_info_pt dinfo = (device_info_pt)data;
+	int len = 0;
+	if(offset == 0) {
+		len = print_stats_info(dinfo, page, count);
+	}
+	*eof = 1;
+	return len;
+}
+
+#ifdef ENABLE_DEBUG_PROC
+static int
+rmisec_read_proc(char *page, char **start, off_t offset, int count,
+		 int *eof, void *data)
+{
+	device_info_pt dinfo = (device_info_pt)data;
+	int len = 0;
+	if(offset == 0) {
+		len = print_page_info(dinfo, page, count);
+	}
+	*eof = 1;
+	return len;
+}
+#endif /* ENABLE_DEBUG_PROC */
+
+static void rmisec_driver_exit(void)
+{
+	unsigned long flags;
+
+	/* device cleanup */
+	// unregister the character device
+	dev_info.exit_driver = 1;
+	unregister_chrdev_region(dev_info.device, 1);
+
+	cdev_del(&dev_info.rmisec_cdev);
+
+	// remove proc entries
+	spin_lock_irqsave(&dev_info.mem_lock, flags);
+	remove_proc_entry(stats_name, dev_info.pdir);
+#ifdef ENABLE_DEBUG_PROC
+	remove_proc_entry(debug_name, dev_info.pdir);
+#endif /* ENABLE_DEBUG_PROC */
+	remove_proc_entry(driver_name, (struct proc_dir_entry *)NULL);
+	spin_unlock_irqrestore(&dev_info.mem_lock, flags);
+
+
+	printk(KERN_NOTICE "Unloading driver\n");
+
+	return;
+}
+
+
+static int ecc_init(void)
+{
+	meminfo_t mem;
+	struct page *page;
+	unsigned char *ecc;
+	unsigned long flags, phy;
+
+	memset(&mem, 0, sizeof(meminfo_t));
+
+	mem.msg0 = ecc_msg0;
+	mem.msg1 = ecc_msg1;
+	mem.magic = DRIVER_MAGIC;
+	mem.ctx = INIT_CTX;
+	mem.op_type = RMI_ECC_OP;
+	mem.in_progress = IN_PROGRESS;
+	mem.result = RMISAE_SUCCESS;
+	mem.return_value = (unsigned long)&mem;
+	init_waitqueue_head(&mem.wq);
+
+	page = alloc_pages(GFP_ATOMIC | __GFP_ZERO, 0);
+
+	local_irq_save(flags);
+	ecc = (unsigned char *)kmap_atomic(page, KM_USER0);
+	mem.ptr = ecc;
+	memcpy(ecc, ecc_uc_data, sizeof(ecc_uc_data));
+	kunmap_atomic(page, KM_USER0);
+	local_irq_restore(flags);
+	ecc = NULL;
+
+	phy = page_to_pfn(page);
+	phy <<= PAGE_SHIFT;
+	SET_SEGMENT_ADDR(mem.msg0, phy);
+	send_to_sae(&mem, 0);
+
+	__free_page(page);
+
+	if(mem.result != RMISAE_SUCCESS) {
+		printk(KERN_ALERT "%s:%d ECC init failed with error=%x\n", __FUNCTION__,
+		       __LINE__, mem.result);
+		return -1;
+	}
+	return 0;
+}
+
+static int msgring_config_init(void)
+{
+	int i;
+	uint8_t sae_bkt[8];
+	uint8_t sae_crdt[16][8];
+	
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_SECURITY_OFFSET);
+
+	phoenix_write_reg(mmio, SEC_DMA_CREDIT, SEC_DMA_CREDIT_CONFIG);
+
+	phoenix_write_reg(mmio, SEC_CONFIG2, SEC_CFG2_ROUND_ROBIN_ON);
+
+
+	if (xlr_hybrid_rmios_ipsec() || xlr_hybrid_rmios_tcpip_stack())
+		return;
+
+	if(dev_tree_en) {
+		if(fdt_get_sae_bucket_conf(sae_bkt, 8, sae_crdt, 128) != 0) {
+			printk("Bucket and credit config failed for sae\n");
+			return -1;
+		}
+		
+		for(i = 0; i < 5; i++)
+			phoenix_write_reg (mmio, SEC_MSG_BUCKET0_SIZE + i, sae_bkt[i]);
+
+		for(i = 0; i < 128; i++)
+			phoenix_write_reg (mmio,  SEC_CC_CPU0_0 + i, sae_crdt[i/8][i%8]);
+
+	} else if (!is_xls()) {
+		for(i = 0; i < 8; i++)
+			phoenix_write_reg (mmio, SEC_MSG_BUCKET0_SIZE + i,
+					   bucket_sizes.bucket[MSGRNG_STNID_SEC + i]);
+		for(i = 0; i < 128; i++)
+			phoenix_write_reg (mmio,  SEC_CC_CPU0_0 + i,
+						   cc_table_sec.counters[i>>3][i&0x07]);
+	} else {
+		for(i = 0; i < 8; i++)
+			phoenix_write_reg (mmio, SEC_MSG_BUCKET0_SIZE + i,
+					   xls_bucket_sizes.bucket[MSGRNG_STNID_SEC + i]);
+		for(i = 0; i < 128; i++)
+			phoenix_write_reg (mmio,  SEC_CC_CPU0_0 + i,
+					   xls_cc_table_sec.counters[i>>3][i&0x07]);
+	}
+	return 0;
+}
+
+extern int xlr_loader_support;
+extern int xlr_loader_sharedcore;
+static int __init rmisec_driver_init(void)
+{
+    int ret;
+    int major, minor;
+
+    /* In case of RMI CRF, check for ownership */
+    if (dev_tree_en && fdt_get_sae_enabled() == 0)
+	return -ENODEV;
+
+    if ((xlr_loader_support && xlr_loader_sharedcore))
+        return -ENODEV;
+
+    /* init device_info strucuture */
+    memset(&dev_info, 0, sizeof(struct device_info));
+    dev_info.version = MKDEV(2,0);
+
+    /* the pk ops bitmap uses only 8 bits, rest are marked used */
+    dev_info.pk_ops_bitmap = 0xffffff00;
+
+#if 0 /* set this to serialize crypto operations */
+    for(ret = 0; ret < 15; ++ret) {
+	    dev_info.crypto_ops_bitmap[ret] = 0xffffffff;
+    }
+    dev_info.crypto_ops_bitmap[ret] = 0xfffffffe;
+#endif
+
+    init_waitqueue_head(&dev_info.crypto_queue);
+    init_waitqueue_head(&dev_info.pkop_queue);
+    spin_lock_init(&dev_info.pkops_lock);
+    spin_lock_init(&dev_info.crypto_lock);
+
+    spin_lock_init(&dev_info.mem_lock);
+    dev_info.pmem_list.next = &dev_info.pmem_list;
+    dev_info.pmem_list.prev = &dev_info.pmem_list;
+
+    /* registering device */
+    dev_info.device = MKDEV(0, 0);
+    ret = alloc_chrdev_region(&dev_info.device, 0, 1, driver_name);
+    if(ret < 0) {
+	printk(KERN_ALERT "%s:%d device could not get major number\n",
+	       __FILE__, __LINE__);
+	goto bail;
+    }
+
+    major = MAJOR(dev_info.device);
+    minor = MINOR(dev_info.device);
+
+    cdev_init(&dev_info.rmisec_cdev, &fops);
+    dev_info.rmisec_cdev.owner = THIS_MODULE;
+
+#ifdef CONFIG_OCF_OCF_MODULE
+    /* create a asyncrhonous queue to process OCF operations */
+    if(rmisec_create_operation_callback(&dev_info.ocf_cb, rmisae_ocf_callback)) {
+	    unregister_chrdev_region(dev_info.device, 1);
+	    printk(KERN_ALERT "%s:%d OCF async queue initialization failed.",
+		   __FUNCTION__, __LINE__);
+	    goto bail;
+    }
+
+    softc_device_init(&dev_info.ocf_dev, "rmisae", 0, rmisae_methods);
+    dev_info.ocf_id = crypto_get_driverid(softc_get_device(&dev_info.ocf_dev),
+					  CRYPTOCAP_F_HARDWARE);
+    if(dev_info.ocf_id < 0) {
+	    unregister_chrdev_region(dev_info.device, 1);
+	    printk(KERN_ALERT "%s:%d RMISAE cannot initialize into OCF.",
+		   __FUNCTION__, __LINE__);
+	    goto bail;
+    } else {
+#define	REGISTER(alg) \
+	crypto_register(dev_info.ocf_id,alg,0,0)
+	REGISTER(CRYPTO_DES_CBC);
+	REGISTER(CRYPTO_3DES_CBC);
+	REGISTER(CRYPTO_RIJNDAEL128_CBC);
+	REGISTER(CRYPTO_MD5);
+	REGISTER(CRYPTO_SHA1);
+	REGISTER(CRYPTO_MD5_HMAC);
+	REGISTER(CRYPTO_SHA1_HMAC);
+    }
+#endif /* CONFIG_OCF_OCF_MODULE */
+
+    // create character device
+    ret = cdev_add(&dev_info.rmisec_cdev, dev_info.device, 1);
+    if(ret < 0) {
+	    unregister_chrdev_region(dev_info.device, 1);
+#ifdef CONFIG_OCF_OCF_MODULE
+	    crypto_unregister_all(dev_info.ocf_id);
+#endif /* CONFIG_OCF_OCF_MODULE */
+	    printk(KERN_ALERT "%s:%d Error adding char driver err=%d.\n",
+		   __FUNCTION__, __LINE__, ret);
+	    goto bail;
+    }
+
+    // initialize the sae configuration
+    msgring_config_init();
+
+    // create proc fs entries
+    dev_info.pdir = proc_mkdir("rmi/" DRIVER_NAME, NULL);
+    if(dev_info.pdir == NULL)
+    {
+	    printk("%s:%d failed creating proc directory: %s\n",
+		   __FUNCTION__, __LINE__, driver_name);
+	    ret = -ENOMEM;
+	    goto bail;
+    } else {
+#ifdef ENABLE_DEBUG_PROC
+	    dev_info.pdebug = create_proc_read_entry(debug_name, 0, dev_info.pdir,
+						     rmisec_read_proc,
+						     &dev_info);
+	    if(dev_info.pdebug == NULL) {
+		    remove_proc_entry(driver_name, NULL);
+		    printk("%s:%d failed creating debug entry: %s/%s\n",
+			   __FUNCTION__, __LINE__, driver_name, debug_name);
+		    ret = -EINVAL;
+		    goto bail;
+	    }
+#endif /* ENABLE_DEBUG_PROC */
+
+	    dev_info.pstats = create_proc_read_entry(stats_name, 0, dev_info.pdir,
+						     rmisec_read_stats_proc,
+						     &dev_info);
+
+	    if(dev_info.pstats == NULL) {
+#ifdef ENABLE_DEBUG_PROC
+		    remove_proc_entry(debug_name, dev_info.pdir);
+#endif /* ENABLE_DEBUG_PROC */
+		    remove_proc_entry("rmi/" DRIVER_NAME, NULL);
+		    printk("%s:%d failed creating stats entry: %s/%s\n",
+			   __FUNCTION__, __LINE__, driver_name, stats_name);
+		    ret = -EINVAL;
+		    goto bail;
+	    }
+
+    }
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+    if(rmi_on_chip_napi) {
+	    printk(KERN_NOTICE "SAE NAPI-compatible Subsystem.\n");
+    }
+#endif
+
+    // register handler
+    if ((ret = register_msgring_handler(TX_STN_SEC,
+					rmisec_msgring_handler,
+					&dev_info))) {
+	    rmisec_driver_exit();
+	    ret = -EINVAL;
+	    goto bail;
+    }
+
+    if(is_xls()) {
+	    ecc_init();
+    }
+
+#ifdef DEBUG
+    printk(KERN_NOTICE "%s:%d SEC handler=%p\n", __FUNCTION__, __LINE__,
+	   rmisec_msgring_handler);
+#endif /* DEBUG */
+    printk(KERN_NOTICE "Loaded SAE driver version=[%s] major=%d minor=%d\n",
+	   versionstr, major, minor);
+
+    return 0;
+ bail:
+    rmisec_driver_exit();
+    return ret;
+}
+
+/* Queuing functions */
+int rmisec_op_setup(op_handle_t handle, op_queue_t async_queue,
+		    unsigned long arg, int op_flags)
+{
+	operation_pt op = (operation_pt)handle;
+
+	if(op == NULL)
+		return -1;
+
+	op->return_queue = (secop_queue_pt)async_queue;
+	op->op_flags = op_flags;
+
+	if(op->return_queue != NULL) {
+		op->op_flags |= OP_NO_WAIT;
+	} else {
+		op->op_flags &= ~(OP_NO_WAIT);
+	}
+
+	op->arg = arg;
+	return 0;
+}
+EXPORT_SYMBOL(rmisec_op_setup);
+
+int
+rmisec_op_callback_setup(op_handle_t handle, op_callback_t async_callback,
+			     unsigned long arg, int op_flags)
+{
+	return rmisec_op_setup(handle, (op_queue_t)async_callback, arg, op_flags);
+}
+EXPORT_SYMBOL(rmisec_op_callback_setup);
+
+int rmisec_create_operation_queue(op_queue_pt handle)
+{
+	secop_queue_pt ret;
+	gfp_t flg;
+	if(in_atomic() || in_softirq() || in_interrupt()) {
+		flg = GFP_ATOMIC;
+	} else {
+		flg = GFP_KERNEL;
+	}
+
+	ret = (secop_queue_pt)kmalloc(sizeof(secop_queue_t), flg);
+	if(ret == NULL) {
+		return -ENOMEM;
+	}
+	INIT_SECOP_QUEUE(ret, -1);
+	*handle = (op_queue_t)ret;
+
+	return 0;
+}
+EXPORT_SYMBOL(rmisec_create_operation_queue);
+
+int rmisec_destroy_operation_queue(op_queue_pt handle)
+{
+	secop_queue_pt ret = (secop_queue_pt)(*handle);
+	if(ret && ret->response_type == SECOP_Q) {
+		if(ret->q.length != 0) {
+			printk(KERN_INFO "%s:%d Error queue not empty: %d\n",
+			       __FUNCTION__, __LINE__, ret->q.length);
+			return -1;
+		}
+
+		kfree(ret);
+		*handle = 0;
+	}
+	return 0;
+}
+EXPORT_SYMBOL(rmisec_destroy_operation_queue);
+
+int rmisec_create_operation_callback(op_callback_pt handle,
+				     op_callback_func_t func)
+{
+	secop_queue_pt ret;
+	gfp_t flg;
+	if(in_atomic() || in_softirq() || in_interrupt()) {
+		flg = GFP_ATOMIC;
+	} else {
+		flg = GFP_KERNEL;
+	}
+
+	ret = (secop_queue_pt)kmalloc(sizeof(secop_queue_t), flg);
+	if(ret == NULL) {
+		return -ENOMEM;
+	}
+	INIT_SECOP_CB(ret, func);
+	*handle = (op_queue_t)ret;
+
+	return 0;
+}
+EXPORT_SYMBOL(rmisec_create_operation_callback);
+
+int rmisec_destroy_operation_callback(op_callback_pt handle)
+{
+	secop_queue_pt queue = (secop_queue_pt)handle;
+	if(queue && queue->response_type == SECOP_CB) {
+		kfree(queue);
+		*handle = (op_callback_t)NULL;
+	}
+	return 0;
+}
+EXPORT_SYMBOL(rmisec_destroy_operation_callback);
+
+int rmisec_op_queue_dequeue(op_queue_t qhandle, int *result, op_handle_pt phandle)
+{
+	secop_queue_pt queue = (secop_queue_pt)qhandle;
+	operation_pt op;
+	meminfo_pt mem = remove_meminfo_from_queue(queue);
+
+	if(mem != NULL) {
+		if(mem->magic == DRIVER_MAGIC) {
+			*result = mem->result;
+			op = (operation_pt)mem->return_value;
+			if(mem->ctx == KERNEL_CTX ) {
+				*result = post_process_op(*result, op);
+			} else {
+				printk(KERN_WARNING "%s:%d Meminfo Not kernel context\n",
+				       __FUNCTION__, __LINE__);
+			}
+			*phandle = (op_handle_t)op;
+			return 0;
+		} else {
+			printk(KERN_WARNING "%s:%d Invalid mem=%p magic=%llx\n",
+			       __FUNCTION__, __LINE__, mem, mem->magic);
+		}
+	}
+	return -1;
+}
+EXPORT_SYMBOL(rmisec_op_queue_dequeue);
+
+unsigned int rmisec_op_queue_size(op_queue_t qhandle)
+{
+	int ret = 0;
+	secop_queue_pt queue = (secop_queue_pt)qhandle;
+	if(queue && queue->response_type == SECOP_Q) {
+		ret = queue->q.length;
+	}
+	return ret;
+}
+EXPORT_SYMBOL(rmisec_op_queue_size);
+
+unsigned long rmisec_op_get_arg(op_handle_t handle)
+{
+	operation_pt op;
+	if(handle != 0UL) {
+		op = (operation_pt)handle;
+		return op->arg;
+	}
+	return 0;
+}
+EXPORT_SYMBOL(rmisec_op_get_arg);
+
+module_init(rmisec_driver_init);
+module_exit(rmisec_driver_exit);
diff --git a/drivers/i2c/algos/Kconfig b/drivers/i2c/algos/Kconfig
index f1cfe7e..ccbe357 100644
--- a/drivers/i2c/algos/Kconfig
+++ b/drivers/i2c/algos/Kconfig
@@ -11,6 +11,15 @@ config I2C_ALGOBIT
 config I2C_ALGOPCF
 	tristate "I2C PCF 8584 interfaces"
 
+config I2C_ALGOPALM
+        tristate "PalmChip's I2C interfaces"
+        depends on I2C
+        help
+          This allows you to use the BK3220 I2C Host Adapter on the RMI Phoenix.
+
+          This support is also available as a module.  If so, the module
+          will be called i2c-algo-palm.
+
 config I2C_ALGOPCA
 	tristate "I2C PCA 9564 interfaces"
 
diff --git a/drivers/i2c/algos/Makefile b/drivers/i2c/algos/Makefile
index 215303f..48e9b8e 100644
--- a/drivers/i2c/algos/Makefile
+++ b/drivers/i2c/algos/Makefile
@@ -5,5 +5,6 @@
 obj-$(CONFIG_I2C_ALGOBIT)	+= i2c-algo-bit.o
 obj-$(CONFIG_I2C_ALGOPCF)	+= i2c-algo-pcf.o
 obj-$(CONFIG_I2C_ALGOPCA)	+= i2c-algo-pca.o
+obj-$(CONFIG_I2C_ALGOPALM)      += i2c-algo-palm.o
 
 ccflags-$(CONFIG_I2C_DEBUG_ALGO) := -DDEBUG
diff --git a/drivers/i2c/algos/i2c-algo-palm.c b/drivers/i2c/algos/i2c-algo-palm.c
new file mode 100644
index 0000000..e5889df
--- /dev/null
+++ b/drivers/i2c/algos/i2c-algo-palm.c
@@ -0,0 +1,325 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/*
+ *  i2c-algo-palm.c i2c driver algorithms for the BK3220 I2C Host 
+ *  adapter on the RMI Phoenix System.
+ *  Derived from the PCA-ISA I2C-Algo/Bus files.
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/delay.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/spinlock.h>
+#include <linux/i2c.h>
+#include <linux/i2c-algo-palm.h>
+#include "i2c-algo-palm.h"
+
+#define DRIVER "i2c-algo-palm"
+
+#define DEB1(fmt, args...) do { if (i2c_debug>=1) printk(fmt, ## args); } while(0)
+#define DEB2(fmt, args...) do { if (i2c_debug>=2) printk(fmt, ## args); } while(0)
+#define DEB3(fmt, args...) do { if (i2c_debug>=3) printk(fmt, ## args); } while(0)
+
+static int i2c_debug=0;
+spinlock_t palm_lock;
+					
+#define palm_write(algo_data, reg, val) 	algo_data->write(reg, val)
+#define palm_read(algo_data, reg) 		algo_data->read(reg)
+
+#define palm_clock(adap) 		adap->get_clock(adap)
+#define palm_status(adap) 		palm_inw(adap, I2C_PCA_STA)
+#define palm_set_con(adap, val) 	palm_outw(adap, I2C_PCA_CON, val)
+#define palm_get_con(adap) 		palm_inw(adap, I2C_PCA_CON)
+
+/*
+ * Check if the I2C Bus is idle or busy
+ */
+static int wait_for_idle(struct i2c_algo_palm_data *algo_data)
+{
+	int timeOut=0x1000;
+	volatile __u32 regVal=0x00;
+	regVal = palm_read(algo_data, I2C_PALM_STATUS) & 0x0001;
+	while (regVal && timeOut--) {
+		regVal = palm_read(algo_data, I2C_PALM_STATUS) & 0x0001;
+	}
+	if (timeOut == 0x00)
+		return -1;	/* Timed Out */
+	else
+		return 0;
+}
+
+/*
+ * Transmit Routine
+ */
+static int palm_tx(struct i2c_algo_palm_data *algo_data,  __u16 len, 
+		__u8 *buf, __u16 addr, __u8 offset)
+{
+	volatile __u32 regVal=0x00;
+	int timeOut, ctr=0x00, numBytes=len;
+
+	for (ctr=0x00; ctr<len; ctr++) {
+		if (wait_for_idle(algo_data) < 0) {
+			printk("TimedOut on Waiting for I2C Bus Idle.\n");
+			return -EIO;
+		}
+		palm_write(algo_data, I2C_PALM_CFG, 0xF8);			
+		palm_write(algo_data, I2C_PALM_BYTECNT, 0x00);
+		palm_write(algo_data, I2C_PALM_DEVADDR, addr); //0x4c, 0x68	
+		palm_write(algo_data, I2C_PALM_ADDR, offset+numBytes-1); //offset
+		palm_write(algo_data, I2C_PALM_DATAOUT, buf[ctr]);
+		palm_write(algo_data, I2C_PALM_STARTXFR, I2C_PALM_STARTXFR_WR );
+		spin_lock_irq(&palm_lock);
+		mdelay(0x1);
+		spin_unlock_irq(&palm_lock);
+		
+		regVal = palm_read(algo_data, I2C_PALM_STATUS);
+		spin_lock_irq(&palm_lock);
+		mdelay(0x01);
+		spin_unlock_irq(&palm_lock);
+		if (regVal & 0x0008) {
+			printk("palm_tx: ACKERR. Aborting...\n");
+			return -1;
+		}
+		timeOut= 0x1000;
+		while (!(regVal & 0x0002) && timeOut) {
+			regVal = palm_read(algo_data, I2C_PALM_STATUS);
+			timeOut--;
+		}
+		if (timeOut==0x00) {
+			printk("palm_tx: [TimeOut] SDOEMPTY Not Set\n");
+			return -1;
+		}
+		timeOut=1000;
+		while ((regVal & 0x0030) && timeOut) {
+			palm_write(algo_data, I2C_PALM_STARTXFR, I2C_PALM_STARTXFR_WR);
+			regVal = palm_read(algo_data, I2C_PALM_STATUS);
+			timeOut--;
+		}
+		if (timeOut==0x00) {
+			printk("palm_rx: TimedOut on Valid STARTXFR/Arbitration\n");
+			return -1;
+		}
+		numBytes--;
+	}
+	return 0;
+}
+static int palm_addr_only(struct i2c_algo_palm_data *algo_data, __u8 *buf,
+		__u16 addr, __u8 offset)
+{
+	volatile __u32 regVal=0x00;
+
+	palm_write(algo_data, I2C_PALM_ADDR,    offset);
+	palm_write(algo_data, I2C_PALM_DEVADDR, addr);
+	palm_write(algo_data, I2C_PALM_CFG,     0xfa);
+	palm_write(algo_data, I2C_PALM_STARTXFR,0x02);
+	regVal = palm_read(algo_data, I2C_PALM_STATUS);
+	if (regVal & 0x0008) {
+		printk("palm_addr_only: ACKERR. Aborting...\n");
+		return -1;
+	}
+	return 0;
+}
+
+
+/*
+ * Receive Routine
+ * Read 'len' bytes from device @ 'addr'
+ */
+static int palm_rx(struct i2c_algo_palm_data *algo_data, __u16 len,
+		__u8 *buf, __u16 addr, __u8 offset)
+{	
+	volatile __u32 regVal=0x00, ctr=0x00;
+	int timeOut, numBytes=0x00;
+
+	palm_write(algo_data, I2C_PALM_CFG, 0xfa);
+	palm_write(algo_data, I2C_PALM_BYTECNT, len);
+	palm_write(algo_data, I2C_PALM_DEVADDR, addr); //DEVADDR=0x4c, 0x68
+	spin_lock_irq(&palm_lock);
+	mdelay(0x01);
+	spin_unlock_irq(&palm_lock);
+
+	for (numBytes=0x00; numBytes < len; numBytes++) {
+		palm_write(algo_data, I2C_PALM_ADDR,  offset+numBytes);//I2C_PALM_ADDR:offset	
+		spin_lock_irq(&palm_lock);
+		mdelay(0x01);
+		spin_unlock_irq(&palm_lock);
+		if (!ctr) {
+			/* Trigger a READ Transaction */
+			palm_write(algo_data, I2C_PALM_STARTXFR, I2C_PALM_STARTXFR_RD);
+			ctr++;
+		}
+
+		/* Error Conditions [Begin] */
+		regVal = palm_read(algo_data, I2C_PALM_STATUS);
+		spin_lock_irq(&palm_lock);
+		mdelay(0x01);
+		spin_unlock_irq(&palm_lock);
+		if (regVal & 0x0008) {
+			printk("palm_rx: ACKERR. Aborting...\n");
+			return -1;
+		}
+		timeOut=10;
+		while ((regVal & 0x0030) && timeOut--) {
+			palm_write(algo_data, I2C_PALM_STARTXFR, I2C_PALM_STARTXFR_RD);
+			regVal = palm_read(algo_data, I2C_PALM_STATUS);
+		}
+		if (timeOut==0x00) {
+			printk("palm_rx: TimedOut on Valid STARTXFR/Arbitration\n");
+			return -1;
+		}
+		timeOut=10;
+		/* Do we have valid data from the device yet..? */
+		regVal &= 0x0004;
+		while (!regVal && timeOut--) {
+			regVal = palm_read(algo_data, I2C_PALM_STATUS) & 0x0004;
+		}
+		if (timeOut==0x00) {
+			printk("palm_rx: TimedOut Waiting for Valid Data\n");
+			return -1;
+		}
+		/* Error Conditions [End] */
+		/* Read the data */
+		buf[numBytes] = (__u8)palm_read(algo_data, I2C_PALM_DATAIN);
+	}
+	return 0;
+}
+
+static int palm_xfer(struct i2c_adapter *i2c_adap,
+		struct i2c_msg msgs[],
+		int num)
+{
+	struct 	i2c_algo_palm_data *algo_data = i2c_adap->algo_data;
+	struct 	i2c_msg *msg = NULL;
+	int 	curmsg;
+
+	for (curmsg = 0; curmsg < num; curmsg++) {
+
+		int addr;
+		msg = &msgs[curmsg];
+
+		addr = (0x7f & msg->addr);
+
+		/*
+		 * Check if I2C State Machine is idle
+		 * 'wait_for_idle' returns 0 => timedOut
+		 * 'BUSY' bit cleared => BUS is IDLE
+		 */
+		if (wait_for_idle(algo_data) < 0) {
+			printk("TimedOut on Waiting for I2C Bus Idle.\n");
+			return -EIO;
+		}
+		if (msg->flags & I2C_M_RD ) {
+			if (palm_addr_only(algo_data, &msg->buf[0], addr, msg->offset) == -1) {
+				printk("I2C ADDRONLY Phase Fail.\n");
+				return -EIO;
+			}
+			if (palm_rx(algo_data, msg->len, &msg->buf[0], addr, msg->offset) == -1) {
+				printk("I2C Read Fail.\n");
+				return -EIO;
+			}
+		}
+		else {
+			if (palm_tx(algo_data, msg->len, &msg->buf[0], addr, msg->offset) == -1) {
+				printk("I2C Write Fail.\n");
+				return -EIO;
+			}
+		}
+	}
+	return num;
+}
+
+static u32 palm_func(struct i2c_adapter *adap)
+{
+	/* We emulate SMBUS over I2C */
+	return I2C_FUNC_SMBUS_EMUL;
+}
+
+static int palm_init(struct i2c_algo_palm_data *algo_data)
+{
+	printk("Intializing BK-3220 I2C Host Adapter...");
+	spin_lock_init(&palm_lock);
+#if 0
+	/* RMI Phoenix has a hardcoded value for CLKDIV now... */
+	palm_write(algo_data, I2C_PALM_CLKDIV, I2C_PALM_CLKDIV_DEF);
+	/* Needed only for Multi-master environments */
+	palm_write(algo_data, I2C_PALM_HDSTATIM, I2C_PALM_HDSTATIM_DEF);
+#endif
+	printk("done.\n");
+	return 0;
+}
+
+static struct i2c_algorithm palm_algo = {
+/* 	.name		= "PalmChips I2C algorithm", */
+/* 	.id		= I2C_ALGO_PALM, */
+	.master_xfer	= palm_xfer,
+	.functionality	= palm_func,
+};
+
+/* 
+ * registering functions to load algorithms at runtime 
+ */
+int i2c_palm_add_bus(struct i2c_adapter *adap)
+{
+	struct i2c_algo_palm_data *palm_adap = adap->algo_data;
+	int rval;
+
+/* 	adap->id |= palm_algo.id; */
+	adap->algo = &palm_algo;
+
+	adap->timeout = 100;		
+	adap->retries = 3;		
+
+	rval = palm_init(palm_adap);
+
+	/* register new adapter to i2c module... */
+	if (!rval)
+		i2c_add_adapter(adap);
+
+	return rval;
+}
+
+int i2c_palm_del_bus(struct i2c_adapter *adap)
+{
+	return i2c_del_adapter(adap);
+}
+
+EXPORT_SYMBOL(i2c_palm_add_bus);
+EXPORT_SYMBOL(i2c_palm_del_bus);
+
+MODULE_AUTHOR("RMI");
+MODULE_DESCRIPTION("I2C-Bus PalmChip's Host Adapter algorithm");
+MODULE_LICENSE("GPL");
+
+module_param(i2c_debug, int, 0);
diff --git a/drivers/i2c/algos/i2c-algo-palm.h b/drivers/i2c/algos/i2c-algo-palm.h
new file mode 100644
index 0000000..5f254a1
--- /dev/null
+++ b/drivers/i2c/algos/i2c-algo-palm.h
@@ -0,0 +1,58 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+/*
+ *  i2c-algo-palm.c i2c driver algorithms for the BK3220 I2C Host 
+ *  adapter on the RMI Phoenix System.
+ *  Derived from the PCA-ISA I2C-Algo/Bus files.
+ */
+
+#ifndef I2C_PALM_H
+#define I2C_PALM_H 			1
+
+#define I2C_PALM_CFG			0x00 
+#define I2C_PALM_CLKDIV			0x01 
+#define I2C_PALM_DEVADDR		0x02 
+#define I2C_PALM_ADDR			0x03
+#define I2C_PALM_DATAOUT		0x04 
+#define I2C_PALM_DATAIN			0x05 
+#define I2C_PALM_STATUS			0x06
+#define I2C_PALM_STARTXFR		0x07
+#define I2C_PALM_BYTECNT		0x08
+#define I2C_PALM_HDSTATIM		0x09
+
+/* TEST Values!! Change as required */
+#define I2C_PALM_CFG_DEF		0x000000F8	/* 8-Bit Addr + POR Values */
+#define I2C_PALM_CLKDIV_DEF		0x14A //0x00000052	
+#define I2C_PALM_HDSTATIM_DEF		0x107 //0x00000000
+
+#define I2C_PALM_STARTXFR_RD		0x00000001
+#define I2C_PALM_STARTXFR_WR		0x00000000
+
+#endif /* I2C_PALM_H */
diff --git a/drivers/i2c/busses/Kconfig b/drivers/i2c/busses/Kconfig
index 2313f08..33ac4e7 100644
--- a/drivers/i2c/busses/Kconfig
+++ b/drivers/i2c/busses/Kconfig
@@ -303,6 +303,17 @@ config I2C_AT91
 	  the latency to fill the transmission register is too long. If you
 	  are facing this situation, use the i2c-gpio driver.
 
+config I2C_BK3220
+        tristate "PalmChip BK-3220"
+        depends on I2C && EXPERIMENTAL
+        select I2C_ALGOPALM
+        help
+          This supports the BK-3220 I2C adapter.  Say Y if you own
+          such an adapter.
+
+          This support is also available as a module.  If so, the module
+          will be called i2c-bk3220.
+
 config I2C_AU1550
 	tristate "Au1550/Au1200/Au1300 SMBus interface"
 	depends on MIPS_ALCHEMY
diff --git a/drivers/i2c/busses/Makefile b/drivers/i2c/busses/Makefile
index 316c5e6..16ccde9 100644
--- a/drivers/i2c/busses/Makefile
+++ b/drivers/i2c/busses/Makefile
@@ -12,6 +12,7 @@ obj-$(CONFIG_I2C_ALI15X3)	+= i2c-ali15x3.o
 obj-$(CONFIG_I2C_AMD756)	+= i2c-amd756.o
 obj-$(CONFIG_I2C_AMD756_S4882)	+= i2c-amd756-s4882.o
 obj-$(CONFIG_I2C_AMD8111)	+= i2c-amd8111.o
+obj-$(CONFIG_I2C_BK3220)        += i2c-bk3220.o
 obj-$(CONFIG_I2C_I801)		+= i2c-i801.o
 obj-$(CONFIG_I2C_ISCH)		+= i2c-isch.o
 obj-$(CONFIG_I2C_NFORCE2)	+= i2c-nforce2.o
diff --git a/drivers/i2c/busses/i2c-bk3220.c b/drivers/i2c/busses/i2c-bk3220.c
new file mode 100644
index 0000000..28999ff
--- /dev/null
+++ b/drivers/i2c/busses/i2c-bk3220.c
@@ -0,0 +1,144 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+/*
+ *  i2c-palm-bk3220.c driver for the BK-3220 Host Adapter on the
+ *  RMI Phoenix System.
+ */
+
+#include <linux/kernel.h>
+#include <linux/ioport.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/delay.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/pci.h>
+#include <linux/wait.h>
+#include <linux/i2c.h>
+#include <linux/i2c-algo-palm.h>
+#include <asm/io.h>
+#include <asm/irq.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/sim.h>
+
+#include "../algos/i2c-algo-palm.h"
+
+#undef 	DEBUG
+
+#define ARIZONA_RTC_BUS 1
+#define PHOENIX_CPLD_PHYS_ADDR	0xbd850000
+
+static wait_queue_head_t palm_wait;
+__u32 * iobase_i2c_regs = 0;
+
+__u32 * get_i2c_base(unsigned short bus)
+{
+	phoenix_reg_t *mmio = 0;
+
+	if (bus == 0)
+		mmio = phoenix_io_mmio(PHOENIX_IO_I2C_0_OFFSET);
+	else
+		mmio = phoenix_io_mmio(PHOENIX_IO_I2C_1_OFFSET);
+
+	return (__u32 *)mmio;
+}
+
+static void	
+palm_bk3220_write(int reg, int val)
+{
+	/* Code to access the low-level
+	 * I2C Block on the RMI Phoenix 
+	 */		
+	phoenix_write_reg(iobase_i2c_regs, reg, val);
+}
+
+static int
+palm_bk3220_read(int reg)
+{
+  /* Code to access the low-level
+   * I2C Block on the RMI Phoenix 
+   */		
+  __u32 retVal = phoenix_read_reg(iobase_i2c_regs, reg);
+  return (int)retVal;
+}
+
+static struct i2c_algo_palm_data palm_bk3220_data = {
+	.write		= palm_bk3220_write,
+	.read		= palm_bk3220_read,
+};
+
+/* This is our i2c_adapter structure */
+static struct i2c_adapter palm_bk3220_ops = {
+	.owner          = THIS_MODULE,
+	.id		= I2C_HW_PALM_BK3220,			
+	.algo_data	= &palm_bk3220_data,
+	.name		= "Palm Chip BK3220 Adapter",
+};
+
+static int __init palm_bk3220_init(void)
+{
+	extern int dev_tree_en;
+	extern int fdt_get_i2c_enabled(int instance);
+	extern int phoenix_noi2c;
+
+	if(phoenix_noi2c || (dev_tree_en && fdt_get_i2c_enabled(ARIZONA_RTC_BUS) == 0)) {
+		printk("I2C disabled by boot args: Skipping BUS %d registration...\n", ARIZONA_RTC_BUS);
+		return 0;
+	}
+
+    iobase_i2c_regs = get_i2c_base(ARIZONA_RTC_BUS);
+
+	init_waitqueue_head(&palm_wait);
+
+	if (i2c_palm_add_bus(&palm_bk3220_ops) < 0) {
+		printk(KERN_ERR "i2c-palm-bk3220: Failed to add i2c bus\n");
+		goto out;
+	}
+	else {
+		printk("i2c-palm-bk3220: Added I2C Bus.\n");
+	}
+
+	return 0;
+out:
+	return -ENODEV;
+}
+
+static void palm_bk3220_exit(void)
+{
+	i2c_palm_del_bus(&palm_bk3220_ops);
+}
+
+MODULE_AUTHOR("RMI Inc.");
+MODULE_DESCRIPTION("BK3220 I2C Host adapter driver");
+MODULE_LICENSE("GPL");
+
+module_init(palm_bk3220_init);
+module_exit(palm_bk3220_exit);
diff --git a/drivers/i2c/chips/ds1374-rtc.c b/drivers/i2c/chips/ds1374-rtc.c
new file mode 100644
index 0000000..c4f6730
--- /dev/null
+++ b/drivers/i2c/chips/ds1374-rtc.c
@@ -0,0 +1,533 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+/*
+ *  linux/drivers/char/ds1374-rtc.c
+ *
+ *	based on drivers/char/x1226-rtc.c
+ *	Steve Longerbeam <stevel@mvista.com, or source@mvista.com>
+ *	2002-2003 (c) MontaVista Software, Inc.
+ *
+ * RTC Driver for the Maxim DS1374 32-bit Binary
+ * Counter WatchDog/RTC
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/i2c.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/rtc.h>		/* get the user-level API */
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/miscdevice.h>
+#include <linux/fcntl.h>
+#include <linux/fs.h>
+#include <linux/proc_fs.h>
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/time.h>
+
+#include <asm/rmi/sim.h>
+
+/* #define	DEBUG_DS1374 */
+
+#define EPOCH 		2000
+#define SYS_EPOCH 	1900
+
+#ifdef DEBUG_DS1374		
+#define dbg(fmt, args...) 	printk(KERN_DEBUG "%s: " fmt, __func__, ## args)
+#else
+#define dbg(fmt, args...)
+#endif
+
+#define err(format, arg...) 	printk(KERN_ERR ": " format , ## arg)
+#define info(format, arg...) 	printk(KERN_INFO ": " format , ## arg)
+
+#define DEVID_RTC    	   	0x68
+#define DS1374_RTC_BASE    	0x00
+
+#define PHOENIX_I2C_DRIVERID_DS1374   	0x00
+
+extern struct proc_dir_entry *rmi_root_proc;
+
+static struct 	i2c_driver ds1374_driver;
+static struct 	i2c_client *this_client = NULL;
+static int 	ds1374_use_count = 0;
+static int 	rtc_read_proc(char *page, char **start, off_t off, int count, 
+		int *eof, void *data);
+static void 	ds1374_BinaryToDate(unsigned long binary, struct rtc_time *datetime);
+
+
+/* This is an image of the RTC registers starting at offset 0x00 */
+struct rtc_registers {
+	unsigned char todc_byte0;     	// 0x00
+	unsigned char todc_byte1;     	// 0x01
+	unsigned char todc_byte2;    	// 0x02
+	unsigned char todc_byte3; 	// 0x03
+};
+
+/* Array representing the number of days in one non-leap year at 
+   the beginning of each month */
+
+unsigned long DaysToMonth[13] = {
+	0,31,59,90,120,151,181,212,243,273,304,334,365
+};
+
+static int
+ds1374_read(struct i2c_client *client, u16 offset, u8 * buf, int len)
+{
+	int ret;
+	struct i2c_msg todc_read[1] = {
+		{
+			client->addr,			/* 0x68 */
+			client->flags | I2C_M_RD,	/* I2C Read Command */
+            offset,
+			4,				/* Need 4 Bytes */
+			buf				/* Store the result here */
+		}
+	};
+
+	if ((ret = i2c_transfer(client->adapter, todc_read, 1)) != 1) {
+		err("i2c_transfer failed, ret=%d\n", ret);
+		ret = -ENXIO;
+	}
+
+	return ret;
+}
+
+static int
+ds1374_write(struct i2c_client *client, u16 offset, u8 * buf, int len)
+{
+	int ret;
+	struct i2c_msg todc_write = {
+		client->addr,			/* 0x68 */
+		client->flags,			/* I2C Write Command */
+        offset, // register offset which to write
+		4,				/* Write 4 Bytes */
+		buf				/* Data to be written */
+	};
+
+	if ((ret = i2c_transfer(client->adapter, &todc_write, 1)) != 1) {
+		err("i2c_transfer failed, ret=%d\n", ret);
+		ret = -ENXIO;
+	}
+	return ret;
+}
+
+
+/* The DS1374 gives a 32-bit up-counter counting in seconds.
+ * We rely on a Maxim Algorithm to convert this 32-bit binary
+ * to a user-friendly time/date format
+ */
+static void ds1374_BinaryToDate(unsigned long binary, struct rtc_time *datetime) {
+
+	unsigned long hour;
+	unsigned long day;
+	unsigned long minute;
+	unsigned long second;
+	unsigned long month;
+	unsigned long year;
+
+	unsigned long whole_minutes;
+	unsigned long whole_hours;
+	unsigned long whole_days;
+	unsigned long whole_days_since_1968;
+	unsigned long leap_year_periods;
+	unsigned long days_since_current_lyear;
+	unsigned long whole_years;
+	unsigned long days_since_first_of_year;
+	unsigned long days_to_month;
+	unsigned long day_of_week;
+
+	whole_minutes = binary / 60;
+	second = binary - (60 * whole_minutes);			/* leftover seconds */
+
+	whole_hours  = whole_minutes / 60;
+	minute = whole_minutes - (60 * whole_hours);		/* leftover minutes */
+
+	whole_days   = whole_hours / 24;
+	hour         = whole_hours - (24 * whole_days);		/* leftover hours */
+
+	whole_days_since_1968 = whole_days + 365 + 366;
+	leap_year_periods = whole_days_since_1968 / ((4 * 365) + 1);
+
+	days_since_current_lyear = whole_days_since_1968 % ((4 * 365) + 1);
+
+	/* if days are after a current leap year then add a leap year period */
+	if ((days_since_current_lyear >= (31 + 29))) {
+		leap_year_periods++;
+	}
+	whole_years = (whole_days_since_1968 - leap_year_periods) / 365;
+	days_since_first_of_year = whole_days_since_1968 - 
+		(whole_years * 365) - leap_year_periods;
+
+	if ((days_since_current_lyear <= 365) && (days_since_current_lyear >= 60)) {
+		days_since_first_of_year++;
+	}
+	year = whole_years + 68;
+
+	/* setup for a search for what month it is based on how many days have past
+	 * within the current year	
+	 */
+	month = 13;
+	days_to_month = 366;
+	while (days_since_first_of_year < days_to_month) {
+		month--;
+		days_to_month = DaysToMonth[month];
+		if ((month >= 2) && ((year % 4) == 0)) {
+			days_to_month++;
+		}
+	}
+	day = days_since_first_of_year - days_to_month + 1;
+
+	day_of_week = (whole_days  + 4) % 7;
+
+	datetime->tm_yday =  days_since_first_of_year;	/* days since Jan 1 - [0,365]*/
+	datetime->tm_sec  = second;			/* seconds after the minute - [0,59]*/
+	datetime->tm_min  = minute;			/* minutes after the hour - [0,59]*/
+	datetime->tm_hour = hour;			/* hours since midnight - [0,23]*/
+	datetime->tm_mday = day;			/* day of the month - [1,31]*/
+	datetime->tm_wday = day_of_week;		/* days since Sunday - [0,6]*/
+	datetime->tm_mon  = month;			/* months since January - [0,11]*/
+	datetime->tm_year = year;			/* years since 1900*/
+}
+
+/* Converting DateTime format to the 32-bit Binary */
+unsigned long ds1374_DateToBinary(struct rtc_time *datetime) {
+
+	unsigned long iday;
+	unsigned long val;
+
+	iday = (365 * (datetime->tm_year - 70)) + DaysToMonth[datetime->tm_mon] + (datetime->tm_mday - 1);
+	iday = iday + ((datetime->tm_year - 69) / 4);
+	if ((datetime->tm_mon > 1) && ((datetime->tm_year % 4) == 0)) {
+		iday++;
+	}
+	val = datetime->tm_sec + (60 * datetime->tm_min) + (3600 * (datetime->tm_hour + (24 * iday)));
+	dbg("ds1374_DateToBinary: 0x%lx [%d]\n", val, val);
+	return val;
+}
+
+static int
+ds1374_get_time(struct i2c_client *client, struct rtc_time *tm)
+{
+	struct rtc_registers rtc;
+	int ret;
+	unsigned int binary=0x00, binary1;
+	int limit=10;
+
+	if (!client) return -ENXIO;
+	
+retry:
+	/* read RTC registers */
+	if ((ret = ds1374_read(client, DS1374_RTC_BASE, (u8 *) & rtc,
+					sizeof (struct rtc_registers))) < 0) {
+		dbg("couldn't read RTC\n");
+		return ret;
+	}
+
+	dbg("IN: todc_B0=%02d, todc_B1=%02d, todc_B2=%02d, todc_B3=%02d\n",
+			rtc.todc_byte0, 
+			rtc.todc_byte1, 
+			rtc.todc_byte2, 
+			rtc.todc_byte3);
+
+	binary = 	(rtc.todc_byte0) + (rtc.todc_byte1 << 8) + 
+		  	(rtc.todc_byte2 << 16) + (rtc.todc_byte3 << 24);
+
+	if ((ret = ds1374_read(client, DS1374_RTC_BASE, (u8 *) & rtc,
+					sizeof (struct rtc_registers))) < 0) {
+		dbg("couldn't read RTC\n");
+		return ret;
+	}
+	binary1 = (rtc.todc_byte0) + (rtc.todc_byte1 << 8) +
+		(rtc.todc_byte2 << 16) + (rtc.todc_byte3 << 24);
+
+	if((binary1 != binary) && limit) {
+		limit--;
+		goto retry;
+	}
+	if(binary1 != binary)
+		printk("ds1374_read:Unable to read consistent date value\n");
+
+	ds1374_BinaryToDate(binary, tm);
+
+	dbg("Date [%02d:%02d:%04d] Time [%02d:%02d:%02d]\n",
+			tm->tm_mon+1, tm->tm_mday,  (1900+tm->tm_year),
+			tm->tm_hour, tm->tm_min, tm->tm_sec);
+	return 0;
+}
+
+static int
+ds1374_set_time(struct i2c_client *client, struct rtc_time *tm)
+{
+	struct rtc_registers rtc, rtc1;
+	unsigned int binary=0x00, binary1;
+	int limit;
+
+	if (!client) return -ENXIO;
+	
+	dbg("IN: year=%d, mon=%d, day=%d, hour=%d, min=%d, sec=%d\n",
+			tm->tm_year, tm->tm_mon, tm->tm_mday, tm->tm_hour,
+			tm->tm_min, tm->tm_sec);
+
+	binary = ds1374_DateToBinary(tm);
+
+	rtc.todc_byte0	= (unsigned char)(binary >> 24);
+	rtc.todc_byte1	= (unsigned char)(binary >> 16);
+	rtc.todc_byte2	= (unsigned char)(binary >> 8);
+	rtc.todc_byte3	= (unsigned char)(binary & 0xFF);
+
+	/* write RTC registers */
+	limit = 10;
+	do {
+		ds1374_write(client, DS1374_RTC_BASE, (u8 *)&rtc, 
+				sizeof (struct rtc_registers));
+		ds1374_read(client, DS1374_RTC_BASE, (u8 *)&rtc1, 
+				sizeof (struct rtc_registers));
+		binary1 = (rtc1.todc_byte0) + (rtc1.todc_byte1 << 8) + 
+			(rtc1.todc_byte2 << 16) + (rtc1.todc_byte3 << 24);
+	} while ((binary1 != binary) && limit--);
+
+	if(binary1 != binary)
+		printk("ds1374_set_time: cannot set date on rtc\n");
+	return 0;
+}
+
+static int
+ds1374_probe(struct i2c_adapter *adap)
+{
+	int ret;
+	struct rtc_time dummy_tm;
+	struct i2c_board_info info;
+
+	memset(&info, 0, sizeof(struct i2c_board_info));
+	strlcpy(info.type, "DS1374", I2C_NAME_SIZE);
+	info.addr = DEVID_RTC;
+
+	this_client = i2c_new_device(adap, &info);
+	if (this_client == NULL)
+		ret = -1;
+
+	/* use ds1374_get_time() to probe for a DS1374 on this bus.  */
+	if ((ret = ds1374_get_time(this_client, &dummy_tm)) < 0) {
+		i2c_unregister_device(this_client);
+		this_client = NULL;
+		return ret;
+	}
+
+	info("Found DS1374 on %s\n", adap->name);
+	return 0;
+}
+
+static int
+ds1374_detach(struct i2c_client *client)
+{
+	i2c_unregister_device(client);
+
+	return 0;
+}
+
+int
+rtc_open(struct inode *minode, struct file *mfile)
+{
+	/*if(MOD_IN_USE) */
+	if (ds1374_use_count > 0) {
+		return -EBUSY;
+	}
+/* 	MOD_INC_USE_COUNT; */
+	++ds1374_use_count;
+	return 0;
+}
+
+int
+rtc_release(struct inode *minode, struct file *mfile)
+{
+/* 	MOD_DEC_USE_COUNT; */
+	--ds1374_use_count;
+	return 0;
+}
+
+static loff_t
+rtc_llseek(struct file *mfile, loff_t offset, int origint)
+{
+	return -ESPIPE;
+}
+
+static int
+ds1374_command(struct i2c_client *client, unsigned int cmd, void *arg)
+{
+	return -EINVAL;
+}
+
+static int
+rtc_ioctl(struct inode *inode, struct file *file, unsigned int cmd,
+		unsigned long arg)
+{
+	struct rtc_time rtc_tm;
+	int ret;
+
+	switch (cmd) {
+		case RTC_RD_TIME:       /* Read the time/date from RTC  */
+			memset(&rtc_tm, 0, sizeof(rtc_tm));
+			if ((ret = ds1374_get_time(this_client, &rtc_tm)) < 0)
+				return ret;
+			return copy_to_user((void *) arg, &rtc_tm, sizeof (rtc_tm)) ?
+				-EFAULT : 0;
+		case RTC_SET_TIME:      /* Set the RTC */
+			if (!capable(CAP_SYS_TIME))
+				return -EACCES;
+
+			if (copy_from_user(&rtc_tm,
+						(struct rtc_time *) arg,
+						sizeof (struct rtc_time)))
+				return -EFAULT;
+			return ds1374_set_time(this_client, &rtc_tm);
+			return 0;
+		default:
+			return -EINVAL;
+	}
+}
+
+static struct i2c_driver ds1374_driver = {
+	//.id		= PHOENIX_I2C_DRIVERID_DS1374,
+	.driver = {
+		.name   = "ds1374",
+	},
+	.attach_adapter = ds1374_probe,
+	.remove 	= ds1374_detach,
+	.command	= ds1374_command
+};
+
+static struct file_operations rtc_fops = {
+	.owner 		= THIS_MODULE,
+	.llseek 	= rtc_llseek,
+	.ioctl 		= rtc_ioctl,
+	.open 		= rtc_open,
+	.release 	= rtc_release,
+};
+
+static struct miscdevice ds1374_miscdev = {
+	RTC_MINOR,
+	"rtc",
+	&rtc_fops
+};
+
+static int __init ds1374_init(void)
+{
+	int ret;
+	extern int xlr_noi2c;
+
+	if(xlr_noi2c)
+		return 0;
+
+	printk("Registering Phoenix I2C based RTC driver...\n");
+	ret = i2c_add_driver(&ds1374_driver);
+	if (ret) {
+		printk("Unable to register phoenix RTC driver!\n");
+		return ret;		
+	}	
+
+	ret = misc_register(&ds1374_miscdev);
+	if (ret) {
+		err("Register misc driver failed, errno is %d\n", ret);
+		i2c_del_driver(&ds1374_driver);
+		return ret;
+	}
+
+	create_proc_read_entry("rtc", 0, rmi_root_proc, rtc_read_proc, NULL);
+
+	return 0;
+}
+
+static void __exit ds1374_exit(void)
+{
+	remove_proc_entry("rtc", rmi_root_proc);
+	misc_deregister(&ds1374_miscdev);
+	i2c_del_driver(&ds1374_driver);
+}
+
+
+module_init(ds1374_init);
+module_exit(ds1374_exit);
+
+/*
+ * Info exported via "/proc/driver/rtc".
+ */
+
+static int
+rtc_proc_output(char *buf)
+{
+	char *p;
+	struct rtc_time tm;
+	int ret;
+
+	if (!this_client) {
+		p = buf;
+		p += sprintf(p, "Driver Not Initialized Properly!\n");		
+		return p - buf;		
+	}
+	
+	if ((ret = ds1374_get_time(this_client, &tm)) < 0)
+		return ret;
+
+	p = buf;
+	/*
+	 * There is no way to tell if the luser has the RTC set for local
+	 * time or for Universal Standard Time (GMT). Probably local though.
+	 */
+	p += sprintf(p,
+			"rtc_time\t: %02d:%02d:%02d\n"
+			"rtc_date\t: %04d-%02d-%02d\n"
+			"rtc_epoch\t: %04d\n",
+			tm.tm_hour, tm.tm_min, tm.tm_sec,
+			tm.tm_year + SYS_EPOCH, tm.tm_mon + 1, tm.tm_mday, EPOCH);
+	return p - buf;
+}
+
+static int
+rtc_read_proc(char *page, char **start, off_t off,
+		int count, int *eof, void *data)
+{
+	int len = rtc_proc_output(page);
+	if (len <= off + count)
+		*eof = 1;
+	*start = page + off;
+	len -= off;
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+	return len;
+}
+
+MODULE_AUTHOR("RMI Inc.");
+MODULE_DESCRIPTION("Maxim DS1374 RTC Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/i2c/chips/max6602.c b/drivers/i2c/chips/max6602.c
new file mode 100644
index 0000000..ba2790a
--- /dev/null
+++ b/drivers/i2c/chips/max6602.c
@@ -0,0 +1,345 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/*
+ * linux/drivers/i2c/chips/max6602.c
+ *
+ * based on drivers/char/x1226-rtc.c
+ * Steve Longerbeam <stevel@mvista.com, or source@mvista.com>
+ * 2002-2003 (c) MontaVista Software, Inc.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/i2c.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/miscdevice.h>
+#include <linux/fcntl.h>
+#include <linux/fs.h>
+#include <linux/proc_fs.h>
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/time.h>
+
+#include <asm/rmi/sim.h>
+
+/* #define 	DEBUG_MAX6602 */
+
+
+#ifdef DEBUG_MAX6602		
+#define dbg(fmt, args...) 	printk(KERN_DEBUG "%s: " fmt, __func__, ## args)
+#else
+#define dbg(fmt, args...)
+#endif
+
+#define err(format, arg...) 	printk(KERN_ERR ": " format , ## arg)
+#define info(format, arg...) 	printk(KERN_INFO ": " format , ## arg)
+
+#define DEVID_TEMP    	   	0x4d
+#define MAX6602_TEMP_BASE    	0x07
+#define XLS_I2C_DRIVERID_MAX6602   	0x02
+
+static struct 	i2c_driver max6602_driver;
+static struct 	i2c_client *this_client = NULL;
+static int 	max6602_use_count = 0;
+static int 	temp_read_proc(char *page, char **start, off_t off, int count, 
+		int *eof, void *data);
+extern struct proc_dir_entry *rmi_root_proc;
+
+
+static int
+max6602_read(struct i2c_client *client, u16 offset, u8 * buf, int len)
+{
+	int ret;
+	struct i2c_msg temp_read[1] = {
+		{
+			client->addr,			/* 0x4c */
+			client->flags | I2C_M_RD,	/* I2C Read Command */
+            offset,
+			len,				/* Need 4 Bytes */
+			buf				/* Store the result here */
+		}
+	};
+
+	if ((ret = i2c_transfer(client->adapter, temp_read, 1)) != 1) {
+		err("i2c_transfer failed, ret=%d\n", ret);
+		ret = -ENXIO;
+	}
+
+	return ret;
+}
+#if 0
+static int
+max6602_write(struct i2c_client *client, u16 offset, u8 * buf, int len)
+{
+	int ret;
+	struct i2c_msg temp_write = {
+		client->addr,			/* 0x4c */
+		client->flags,			/* I2C Write Command */
+        offset,
+		len,				/* Write 4 Bytes */
+		buf				/* Data to be written */
+	};
+
+	if ((ret = i2c_transfer(client->adapter, &temp_write, 1)) != 1) {
+		err("i2c_transfer failed, ret=%d\n", ret);
+		ret = -ENXIO;
+	}
+	return ret;
+}
+#endif
+
+static int
+max6602_get_value(struct i2c_client *client, unsigned char *value, int offset)
+{
+	int ret;
+
+	if (!client) return -ENXIO;
+
+	/* read TEMP registers */
+	if ((ret = max6602_read(client, offset, value, sizeof (char))) < 0) {
+		dbg("couldn't read TEMP\n");
+		return ret;
+	}
+
+	dbg("IN: value=%0x\n", *value);
+
+	return 0;
+}
+
+#if 0
+static int
+max6602_set_value(struct i2c_client *client, unsigned char value, int offset)
+{
+	int ret;
+
+	/* write TEMP registers */
+	if ((ret = max6602_write(client, offset, value, sizeof (char))) < 0) {
+		err("couldn't write TEMP\n");
+		return ret;
+	}
+	return 0;
+}
+#endif
+
+static int max6602_probe(struct i2c_adapter *adap)
+{
+	int ret;
+	unsigned char temp;
+	struct i2c_board_info info;
+
+	memset(&info, 0, sizeof(struct i2c_board_info));
+	strlcpy(info.type, "MAX6602", I2C_NAME_SIZE);
+	info.addr = DEVID_TEMP;
+
+	this_client = i2c_new_device(adap, &info);
+	if (this_client != NULL)
+		return -EBUSY;
+
+	/* * use max6602_get_value() to probe for a MAX6602 on this bus.  */
+	if ((ret = max6602_get_value(this_client, &temp, MAX6602_TEMP_BASE)) < 0) {
+		i2c_unregister_device(this_client);
+		this_client = NULL;
+		return ret;
+	}
+
+	info("Found MAX6602 on %s\n", adap->name);
+	printk("XLS Chip temperature is %d degrees Celsius\n", temp);
+	return 0;
+}
+
+static int
+max6602_detach(struct i2c_client *client)
+{
+	i2c_unregister_device(client);
+
+	return 0;
+}
+
+static int
+temp_open(struct inode *minode, struct file *mfile)
+{
+	/*if(MOD_IN_USE) */
+	if (max6602_use_count > 0) {
+		return -EBUSY;
+	}
+/* 	MOD_INC_USE_COUNT; */
+	++max6602_use_count;
+	return 0;
+}
+
+static int
+temp_release(struct inode *minode, struct file *mfile)
+{
+/* 	MOD_DEC_USE_COUNT; */
+	--max6602_use_count;
+	return 0;
+}
+
+
+static int
+max6602_command(struct i2c_client *client, unsigned int cmd, void *arg)
+{
+	return -EINVAL;
+}
+
+static int
+temp_ioctl(struct inode *inode, struct file *file, unsigned int cmd,
+		unsigned long arg)
+{
+	return -EINVAL;
+}
+
+static struct i2c_driver max6602_driver = {
+	//.id		= XLS_I2C_DRIVERID_MAX6602,
+	.driver = {
+		.name   = "max6602",
+	},
+	.attach_adapter = max6602_probe,
+	.remove		= max6602_detach,
+	.command	= max6602_command
+};
+
+static struct file_operations temp_fops = {
+	.owner 		= THIS_MODULE,
+	.ioctl 		= temp_ioctl,
+	.open 		= temp_open,
+	.release 	= temp_release,
+};
+
+static struct miscdevice max6602_miscdev = {
+	TEMP_MINOR,
+	"max6602",
+	&temp_fops
+};
+
+static int __init max6602_init(void)
+{
+	int ret;
+	extern int xlr_noi2c;
+
+	/* LTE boards have max6602 chips - other boards have max6657 */
+	if(!xlr_board_atx_viii() || xlr_noi2c)
+		return 0;
+
+	printk("Registering XLS I2C based Temperature Sensor driver...\n");
+	ret = i2c_add_driver(&max6602_driver);
+	if (ret) {
+		printk("Unable to register XLS temperaturn sensor driver!\n");
+		return ret;		
+	}	
+
+	ret = misc_register(&max6602_miscdev);
+	if (ret) {
+		err("Register misc driver failed, errno is %d\n", ret);
+		i2c_del_driver(&max6602_driver);
+		return ret;
+	}
+
+	create_proc_read_entry("max6602", 0, rmi_root_proc, temp_read_proc, NULL);
+
+	return 0;
+}
+
+static void __exit max6602_exit(void)
+{
+	remove_proc_entry("max6602", rmi_root_proc);
+	misc_deregister(&max6602_miscdev);
+	i2c_del_driver(&max6602_driver);
+}
+
+
+module_init(max6602_init);
+module_exit(max6602_exit);
+
+/*
+ * Info exported via "/proc/driver/max6602".
+ */
+
+static int
+temp_proc_output(char *buf)
+{
+	char *p;
+	unsigned char temp, temp1, temp2, temp3, temp4;
+	int ret;
+
+	/* Local temp */
+	if ((ret = max6602_get_value(this_client, &temp, MAX6602_TEMP_BASE)) < 0)
+		return ret;
+
+	/* Remote 1 */
+	if ((ret = max6602_get_value(this_client, &temp1, 1)) < 0)
+		return ret;
+
+	/* Remote 2 */
+	if ((ret = max6602_get_value(this_client, &temp2, 2)) < 0)
+		return ret;
+
+	/* Remote 3 */
+	if ((ret = max6602_get_value(this_client, &temp3, 3)) < 0)
+		return ret;
+
+	/* Remote 4 */
+	if ((ret = max6602_get_value(this_client, &temp4, 4)) < 0)
+		return ret;
+
+	p = buf;
+	/*
+	 * There is no way to tell if the luser has the TEMP set for local
+	 * time or for Universal Standard Time (GMT). Probably local though.
+	 */
+	p += sprintf(p, "temperature: %dC %dC %dC %dC %dC\n", 
+				temp, temp1, temp2, temp3, temp4);
+	return p - buf;
+}
+
+static int
+temp_read_proc(char *page, char **start, off_t off,
+		int count, int *eof, void *data)
+{
+	int len = temp_proc_output(page);
+	if (len <= off + count)
+		*eof = 1;
+	*start = page + off;
+	len -= off;
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+	return len;
+}
+
+MODULE_AUTHOR("RMI");
+MODULE_DESCRIPTION("Maxim max6602 Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/i2c/chips/max6657.c b/drivers/i2c/chips/max6657.c
new file mode 100644
index 0000000..ed6f955
--- /dev/null
+++ b/drivers/i2c/chips/max6657.c
@@ -0,0 +1,329 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/*
+ * linux/drivers/i2c/chips/max6657.c
+ *
+ * based on drivers/char/x1226-rtc.c
+ * Steve Longerbeam <stevel@mvista.com, or source@mvista.com>
+ * 2002-2003 (c) MontaVista Software, Inc.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/i2c.h>
+#include <linux/string.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/miscdevice.h>
+#include <linux/fcntl.h>
+#include <linux/fs.h>
+#include <linux/proc_fs.h>
+#include <asm/uaccess.h>
+#include <asm/system.h>
+#include <asm/time.h>
+
+#include <asm/rmi/sim.h>
+
+/* #define 	DEBUG_MAX6657 */
+
+
+#ifdef DEBUG_MAX6657		
+#define dbg(fmt, args...) 	printk(KERN_DEBUG "%s: " fmt, __func__, ## args)
+#else
+#define dbg(fmt, args...)
+#endif
+
+#define err(format, arg...) 	printk(KERN_ERR ": " format , ## arg)
+#define info(format, arg...) 	printk(KERN_INFO ": " format , ## arg)
+
+#define DEVID_TEMP    	   	0x4c
+#define MAX6657_TEMP_BASE    	0x00
+#define PHOENIX_I2C_DRIVERID_MAX6657   	0x01
+
+static struct 	i2c_driver max6657_driver;
+static struct 	i2c_client *this_client = NULL;
+static int 	max6657_use_count = 0;
+static int 	temp_read_proc(char *page, char **start, off_t off, int count, 
+		int *eof, void *data);
+extern struct proc_dir_entry *rmi_root_proc;
+
+
+static int
+max6657_read(struct i2c_client *client, u16 offset, u8 * buf, int len)
+{
+	int ret;
+	struct i2c_msg temp_read[1] = {
+		{
+			client->addr,			/* 0x4c */
+			client->flags | I2C_M_RD,	/* I2C Read Command */
+            offset,
+			len,				/* Need 4 Bytes */
+			buf				/* Store the result here */
+		}
+	};
+
+	if ((ret = i2c_transfer(client->adapter, temp_read, 1)) != 1) {
+		err("i2c_transfer failed, ret=%d\n", ret);
+		ret = -ENXIO;
+	}
+
+	return ret;
+}
+#if 0
+static int
+max6657_write(struct i2c_client *client, u16 offset, u8 * buf, int len)
+{
+	int ret;
+	struct i2c_msg temp_write = {
+		client->addr,			/* 0x4c */
+		client->flags,			/* I2C Write Command */
+        offset,
+		len,				/* Write 4 Bytes */
+		buf				/* Data to be written */
+	};
+
+	if ((ret = i2c_transfer(client->adapter, &temp_write, 1)) != 1) {
+		err("i2c_transfer failed, ret=%d\n", ret);
+		ret = -ENXIO;
+	}
+	return ret;
+}
+#endif
+
+static int
+max6657_get_value(struct i2c_client *client, unsigned char *value, int offset)
+{
+	int ret;
+
+	if (!client) return -ENXIO;
+
+	/* read TEMP registers */
+	if ((ret = max6657_read(client, offset, value, sizeof (char))) < 0) {
+		dbg("couldn't read TEMP\n");
+		return ret;
+	}
+
+	dbg("IN: value=%0x\n", *value);
+
+	return 0;
+}
+
+#if 0
+static int
+max6657_set_value(struct i2c_client *client, unsigned char value, int offset)
+{
+	int ret;
+
+	/* write TEMP registers */
+	if ((ret = max6657_write(client, offset, value, sizeof (char))) < 0) {
+		err("couldn't write TEMP\n");
+		return ret;
+	}
+	return 0;
+}
+#endif
+
+static int max6657_probe(struct i2c_adapter *adap)
+{
+	int ret;
+	unsigned char temp;
+	struct i2c_board_info info;
+
+	memset(&info, 0, sizeof(struct i2c_board_info));
+	strlcpy(info.type, "MAX6657", I2C_NAME_SIZE);
+	info.addr = DEVID_TEMP;
+
+	this_client = i2c_new_device(adap, &info);
+	if (this_client == NULL)
+		return -EBUSY;
+
+	/*
+	 * use max6657_get_value() to probe for a MAX6657 on this bus.
+	 */
+	if ((ret = max6657_get_value(this_client, &temp, MAX6657_TEMP_BASE+1)) < 0) {
+		i2c_unregister_device(this_client);
+		this_client = NULL;
+		return ret;
+	}
+
+	info("Found MAX6657 on %s\n", adap->name);
+	printk("Phoenix Chip temperature is %d degrees Celsius\n", temp);
+	return 0;
+}
+
+static int
+max6657_detach(struct i2c_client *client)
+{
+	i2c_unregister_device(client);
+
+	return 0;
+}
+
+int
+temp_open(struct inode *minode, struct file *mfile)
+{
+	/*if(MOD_IN_USE) */
+	if (max6657_use_count > 0) {
+		return -EBUSY;
+	}
+/* 	MOD_INC_USE_COUNT; */
+	++max6657_use_count;
+	return 0;
+}
+
+int
+temp_release(struct inode *minode, struct file *mfile)
+{
+/* 	MOD_DEC_USE_COUNT; */
+	--max6657_use_count;
+	return 0;
+}
+
+
+static int
+max6657_command(struct i2c_client *client, unsigned int cmd, void *arg)
+{
+	return -EINVAL;
+}
+
+static int
+temp_ioctl(struct inode *inode, struct file *file, unsigned int cmd,
+		unsigned long arg)
+{
+	return -EINVAL;
+}
+
+static struct i2c_driver max6657_driver = {
+	//.id		= PHOENIX_I2C_DRIVERID_MAX6657,
+	.driver = {
+		.name   = "max6657",
+	},
+	.attach_adapter = max6657_probe,
+	.remove		= max6657_detach,
+	.command	= max6657_command
+};
+
+static struct file_operations temp_fops = {
+	.owner 		= THIS_MODULE,
+	.ioctl 		= temp_ioctl,
+	.open 		= temp_open,
+	.release 	= temp_release,
+};
+
+static struct miscdevice max6657_miscdev = {
+	TEMP_MINOR,
+	"max6657",
+	&temp_fops
+};
+
+static int __init max6657_init(void)
+{
+	int ret;
+	extern int xlr_noi2c;
+
+	/* LTE boards have max6602 chips */
+	if(xlr_board_atx_viii() || xlr_noi2c)
+		return 0;
+
+	printk("Registering Phoenix I2C based Temperature Sensor driver...\n");
+	ret = i2c_add_driver(&max6657_driver);
+	if (ret) {
+		printk("Unable to register phoenix temperaturn sensor driver!\n");
+		return ret;		
+	}	
+
+	ret = misc_register(&max6657_miscdev);
+	if (ret) {
+		err("Register misc driver failed, errno is %d\n", ret);
+		i2c_del_driver(&max6657_driver);
+		return ret;
+	}
+
+	create_proc_read_entry("max6657", 0, rmi_root_proc, temp_read_proc, NULL);
+
+	return 0;
+}
+
+static void __exit max6657_exit(void)
+{
+	remove_proc_entry("max6657", rmi_root_proc);
+	misc_deregister(&max6657_miscdev);
+	i2c_del_driver(&max6657_driver);
+}
+
+
+module_init(max6657_init);
+module_exit(max6657_exit);
+
+/*
+ * Info exported via "/proc/driver/max6657".
+ */
+
+static int
+temp_proc_output(char *buf)
+{
+	char *p;
+	unsigned char temp;
+	int ret;
+
+	if ((ret = max6657_get_value(this_client, &temp, 1)) < 0)
+		return ret;
+
+	p = buf;
+	/*
+	 * There is no way to tell if the luser has the TEMP set for local
+	 * time or for Universal Standard Time (GMT). Probably local though.
+	 */
+	p += sprintf(p, "temperature: %d C\n", temp);
+	return p - buf;
+}
+
+static int
+temp_read_proc(char *page, char **start, off_t off,
+		int count, int *eof, void *data)
+{
+	int len = temp_proc_output(page);
+	if (len <= off + count)
+		*eof = 1;
+	*start = page + off;
+	len -= off;
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+	return len;
+}
+
+MODULE_AUTHOR("RMI");
+MODULE_DESCRIPTION("Maxim max6657 Driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/i2c/i2c-core.c b/drivers/i2c/i2c-core.c
index feb7dc3..8533255 100644
--- a/drivers/i2c/i2c-core.c
+++ b/drivers/i2c/i2c-core.c
@@ -761,6 +761,29 @@ static struct attribute_group i2c_adapter_attr_group = {
 	.attrs		= i2c_adapter_attrs,
 };
 
+#if defined(CONFIG_RMI_PHOENIX)
+int __initdata phoenix_noi2c;
+
+#if defined(CONFIG_RMI_XLR)
+static int __init xlr_noi2c_setup(char *str)
+{
+	phoenix_noi2c = 1;
+	return 1;
+}
+__setup("xlr_noi2c", xlr_noi2c_setup);
+#endif
+
+#if defined(CONFIG_RMI_XLP)
+static int __init xlp_noi2c_setup(char *str)
+{
+	phoenix_noi2c = 1;
+	return 1;
+}
+__setup("xlp_noi2c", xlp_noi2c_setup);
+#endif
+
+#endif
+
 static const struct attribute_group *i2c_adapter_attr_groups[] = {
 	&i2c_adapter_attr_group,
 	NULL
diff --git a/drivers/ide/Kconfig b/drivers/ide/Kconfig
index 5a26584..5804297 100644
--- a/drivers/ide/Kconfig
+++ b/drivers/ide/Kconfig
@@ -679,6 +679,11 @@ config BLK_DEV_IDE_AU1XXX
        bool "IDE for AMD Alchemy Au1200"
        depends on MIPS_ALCHEMY
        select IDE_XFER_MODE
+
+config BLK_DEV_IDE_PHOENIX
+       bool "IDE for RMI XLR eval boards" 
+       depends on RMI_PHOENIX 
+
 choice
        prompt "IDE Mode for AMD Alchemy Au1200"
        default BLK_DEV_IDE_AU1XXX_PIO_DBDMA
diff --git a/drivers/ide/ide-dma-sff.c b/drivers/ide/ide-dma-sff.c
index 289d16c..b5bd0ae 100644
--- a/drivers/ide/ide-dma-sff.c
+++ b/drivers/ide/ide-dma-sff.c
@@ -6,6 +6,12 @@
 #include <linux/dma-mapping.h>
 #include <linux/io.h>
 
+#ifdef CONFIG_RMI_PHOENIX
+extern u8 rmi_ide_mm_inb (unsigned long port);              /* readb  */
+extern void rmi_ide_mm_outb (u8 value, unsigned long port); /* writeb */
+extern void rmi_ide_mm_outl (u32 value, unsigned long port);
+#endif
+
 /**
  *	config_drive_for_dma	-	attempt to activate IDE DMA
  *	@drive: the drive to place in DMA mode
@@ -57,7 +63,11 @@ u8 ide_dma_sff_read_status(ide_hwif_t *hwif)
 	if (hwif->host_flags & IDE_HFLAG_MMIO)
 		return readb((void __iomem *)addr);
 	else
+#ifdef CONFIG_RMI_PHOENIX
+		return (u8) rmi_ide_mm_inb(addr);
+#else
 		return inb(addr);
+#endif
 }
 EXPORT_SYMBOL_GPL(ide_dma_sff_read_status);
 
@@ -68,7 +78,11 @@ static void ide_dma_sff_write_status(ide_hwif_t *hwif, u8 val)
 	if (hwif->host_flags & IDE_HFLAG_MMIO)
 		writeb(val, (void __iomem *)addr);
 	else
+#ifdef CONFIG_RMI_PHOENIX
+		rmi_ide_mm_outb(val, addr);
+#else
 		outb(val, addr);
+#endif
 }
 
 /**
@@ -202,13 +216,21 @@ int ide_dma_setup(ide_drive_t *drive, struct ide_cmd *cmd)
 		writel(hwif->dmatable_dma,
 		       (void __iomem *)(hwif->dma_base + ATA_DMA_TABLE_OFS));
 	else
+#ifdef CONFIG_RMI_PHOENIX
+		rmi_ide_mm_outl(hwif->dmatable_dma, hwif->dma_base + ATA_DMA_TABLE_OFS);
+#else
 		outl(hwif->dmatable_dma, hwif->dma_base + ATA_DMA_TABLE_OFS);
+#endif
 
 	/* specify r/w */
 	if (mmio)
 		writeb(rw, (void __iomem *)(hwif->dma_base + ATA_DMA_CMD));
 	else
+#ifdef CONFIG_RMI_PHOENIX
+		rmi_ide_mm_outb(rw, hwif->dma_base + ATA_DMA_CMD);
+#else
 		outb(rw, hwif->dma_base + ATA_DMA_CMD);
+#endif
 
 	/* read DMA status for INTR & ERROR flags */
 	dma_stat = hwif->dma_ops->dma_sff_read_status(hwif);
@@ -275,8 +297,13 @@ void ide_dma_start(ide_drive_t *drive)
 		writeb(dma_cmd | ATA_DMA_START,
 		       (void __iomem *)(hwif->dma_base + ATA_DMA_CMD));
 	} else {
+#ifdef CONFIG_RMI_PHOENIX
+		dma_cmd = (u8)rmi_ide_mm_inb(hwif->dma_base + ATA_DMA_CMD);
+		rmi_ide_mm_outb(dma_cmd | ATA_DMA_START, hwif->dma_base + ATA_DMA_CMD);
+#else
 		dma_cmd = inb(hwif->dma_base + ATA_DMA_CMD);
 		outb(dma_cmd | ATA_DMA_START, hwif->dma_base + ATA_DMA_CMD);
+#endif
 	}
 }
 EXPORT_SYMBOL_GPL(ide_dma_start);
@@ -293,8 +320,13 @@ int ide_dma_end(ide_drive_t *drive)
 		writeb(dma_cmd & ~ATA_DMA_START,
 		       (void __iomem *)(hwif->dma_base + ATA_DMA_CMD));
 	} else {
+#ifdef CONFIG_RMI_PHOENIX
+		dma_cmd = (u8)rmi_ide_mm_inb(hwif->dma_base + ATA_DMA_CMD);
+		rmi_ide_mm_outb(dma_cmd & ~ATA_DMA_START, hwif->dma_base + ATA_DMA_CMD);
+#else
 		dma_cmd = inb(hwif->dma_base + ATA_DMA_CMD);
 		outb(dma_cmd & ~ATA_DMA_START, hwif->dma_base + ATA_DMA_CMD);
+#endif
 	}
 
 	/* get DMA status */
diff --git a/drivers/ide/ide-io-std.c b/drivers/ide/ide-io-std.c
index 1976397..850a6cd 100644
--- a/drivers/ide/ide-io-std.c
+++ b/drivers/ide/ide-io-std.c
@@ -14,14 +14,31 @@
  *	Conventional PIO operations for ATA devices
  */
 
+#ifdef CONFIG_RMI_PHOENIX
+extern u8 rmi_ide_mm_inb (unsigned long port);              /* readb  */
+extern void rmi_ide_mm_outb (u8 value, unsigned long port); /* writeb */
+extern void rmi_ide_mm_insl(unsigned long port, void *addr, unsigned int count);
+extern void rmi_ide_mm_outsl(unsigned long port, void *addr,unsigned int count);
+extern void rmi_ide_mm_insw(unsigned long port, void *addr, u32 count);
+extern void rmi_ide_mm_outsw(unsigned long port, void *addr,unsigned int count);
+#endif
+
 static u8 ide_inb(unsigned long port)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	return (u8) rmi_ide_mm_inb(port);
+#else
 	return (u8) inb(port);
+#endif
 }
 
 static void ide_outb(u8 val, unsigned long port)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_ide_mm_outb(val, port);
+#else
 	outb(val, port);
+#endif
 }
 
 /*
@@ -43,7 +60,11 @@ void ide_exec_command(ide_hwif_t *hwif, u8 cmd)
 	if (hwif->host_flags & IDE_HFLAG_MMIO)
 		writeb(cmd, (void __iomem *)hwif->io_ports.command_addr);
 	else
+#ifdef CONFIG_RMI_PHOENIX
+		rmi_ide_mm_outb(cmd, hwif->io_ports.command_addr);
+#else
 		outb(cmd, hwif->io_ports.command_addr);
+#endif
 }
 EXPORT_SYMBOL_GPL(ide_exec_command);
 
@@ -52,7 +73,11 @@ u8 ide_read_status(ide_hwif_t *hwif)
 	if (hwif->host_flags & IDE_HFLAG_MMIO)
 		return readb((void __iomem *)hwif->io_ports.status_addr);
 	else
+#ifdef CONFIG_RMI_PHOENIX
+		return (u8) rmi_ide_mm_inb(hwif->io_ports.status_addr);
+#else
 		return inb(hwif->io_ports.status_addr);
+#endif
 }
 EXPORT_SYMBOL_GPL(ide_read_status);
 
@@ -61,7 +86,11 @@ u8 ide_read_altstatus(ide_hwif_t *hwif)
 	if (hwif->host_flags & IDE_HFLAG_MMIO)
 		return readb((void __iomem *)hwif->io_ports.ctl_addr);
 	else
+#ifdef CONFIG_RMI_PHOENIX
+		return (u8) rmi_ide_mm_inb(hwif->io_ports.ctl_addr);
+#else
 		return inb(hwif->io_ports.ctl_addr);
+#endif
 }
 EXPORT_SYMBOL_GPL(ide_read_altstatus);
 
@@ -70,7 +99,11 @@ void ide_write_devctl(ide_hwif_t *hwif, u8 ctl)
 	if (hwif->host_flags & IDE_HFLAG_MMIO)
 		writeb(ctl, (void __iomem *)hwif->io_ports.ctl_addr);
 	else
+#ifdef CONFIG_RMI_PHOENIX
+		rmi_ide_mm_outb(ctl, hwif->io_ports.ctl_addr);
+#else
 		outb(ctl, hwif->io_ports.ctl_addr);
+#endif
 }
 EXPORT_SYMBOL_GPL(ide_write_devctl);
 
@@ -82,7 +115,11 @@ void ide_dev_select(ide_drive_t *drive)
 	if (hwif->host_flags & IDE_HFLAG_MMIO)
 		writeb(select, (void __iomem *)hwif->io_ports.device_addr);
 	else
+#ifdef CONFIG_RMI_PHOENIX
+		rmi_ide_mm_outb(select, hwif->io_ports.device_addr);
+#else
 		outb(select, hwif->io_ports.device_addr);
+#endif
 }
 EXPORT_SYMBOL_GPL(ide_dev_select);
 
@@ -198,7 +235,11 @@ void ide_input_data(ide_drive_t *drive, struct ide_cmd *cmd, void *buf,
 	if (mmio)
 		__ide_mm_insw((void __iomem *)data_addr, buf, words);
 	else
+#ifdef CONFIG_RMI_PHOENIX
+		rmi_ide_mm_insw(data_addr, buf, words);
+#else
 		insw(data_addr, buf, words);
+#endif
 }
 EXPORT_SYMBOL_GPL(ide_input_data);
 
@@ -242,7 +283,11 @@ void ide_output_data(ide_drive_t *drive, struct ide_cmd *cmd, void *buf,
 	if (mmio)
 		__ide_mm_outsw((void __iomem *)data_addr, buf, words);
 	else
+#ifdef CONFIG_RMI_PHOENIX
+		rmi_ide_mm_outsw(data_addr, buf, words);
+#else
 		outsw(data_addr, buf, words);
+#endif
 }
 EXPORT_SYMBOL_GPL(ide_output_data);
 
diff --git a/drivers/ide/pdc202xx_new.c b/drivers/ide/pdc202xx_new.c
index 9546fe2..d18bba4 100644
--- a/drivers/ide/pdc202xx_new.c
+++ b/drivers/ide/pdc202xx_new.c
@@ -63,6 +63,11 @@ static u8 max_dma_rate(struct pci_dev *pdev)
 	return mode;
 }
 
+#ifdef CONFIG_RMI_PHOENIX
+extern void rmi_ide_mm_outb (u8 value, unsigned long port);
+extern u8 rmi_ide_mm_inb (unsigned long port);
+#endif
+
 /**
  * get_indexed_reg - Get indexed register
  * @hwif: for the port address
@@ -72,8 +77,13 @@ static u8 get_indexed_reg(ide_hwif_t *hwif, u8 index)
 {
 	u8 value;
 
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_ide_mm_outb(index, hwif->dma_base + 1);
+	value = rmi_ide_mm_inb(hwif->dma_base + 3);
+#else
 	outb(index, hwif->dma_base + 1);
 	value = inb(hwif->dma_base + 3);
+#endif
 
 	DBG("index[%02X] value[%02X]\n", index, value);
 	return value;
@@ -86,8 +96,13 @@ static u8 get_indexed_reg(ide_hwif_t *hwif, u8 index)
  */
 static void set_indexed_reg(ide_hwif_t *hwif, u8 index, u8 value)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_ide_mm_outb(index, hwif->dma_base + 1);
+	rmi_ide_mm_outb(value, hwif->dma_base + 3);
+#else
 	outb(index, hwif->dma_base + 1);
 	outb(value, hwif->dma_base + 3);
+#endif
 	DBG("index[%02X] value[%02X]\n", index, value);
 }
 
@@ -212,6 +227,16 @@ static long read_counter(u32 dma_base)
 		last = count;
 
 		/* Read the current count */
+#ifdef CONFIG_RMI_PHOENIX
+		rmi_ide_mm_outb(0x20, pri_dma_base + 0x01);
+		cnt0 = rmi_ide_mm_inb(pri_dma_base + 0x03);
+		rmi_ide_mm_outb(0x21, pri_dma_base + 0x01);
+		cnt1 = rmi_ide_mm_inb(pri_dma_base + 0x03);
+		rmi_ide_mm_outb(0x20, sec_dma_base + 0x01);
+		cnt2 = rmi_ide_mm_inb(sec_dma_base + 0x03);
+		rmi_ide_mm_outb(0x21, sec_dma_base + 0x01);
+		cnt3 = rmi_ide_mm_inb(sec_dma_base + 0x03);
+#else
 		outb(0x20, pri_dma_base + 0x01);
 		cnt0 = inb(pri_dma_base + 0x03);
 		outb(0x21, pri_dma_base + 0x01);
@@ -220,6 +245,7 @@ static long read_counter(u32 dma_base)
 		cnt2 = inb(sec_dma_base + 0x03);
 		outb(0x21, sec_dma_base + 0x01);
 		cnt3 = inb(sec_dma_base + 0x03);
+#endif
 
 		count = (cnt3 << 23) | (cnt2 << 15) | (cnt1 << 8) | cnt0;
 
@@ -252,10 +278,17 @@ static long detect_pll_input_clock(unsigned long dma_base)
 	do_gettimeofday(&start_time);
 
 	/* Start the test mode */
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_ide_mm_outb(0x01, dma_base + 0x01);
+	scr1 = rmi_ide_mm_inb(dma_base + 0x03);
+	DBG("scr1[%02X]\n", scr1);
+	rmi_ide_mm_outb(scr1 | 0x40, dma_base + 0x03);
+#else
 	outb(0x01, dma_base + 0x01);
 	scr1 = inb(dma_base + 0x03);
 	DBG("scr1[%02X]\n", scr1);
 	outb(scr1 | 0x40, dma_base + 0x03);
+#endif
 
 	/* Let the counter run for 10 ms. */
 	mdelay(10);
@@ -264,10 +297,17 @@ static long detect_pll_input_clock(unsigned long dma_base)
 	do_gettimeofday(&end_time);
 
 	/* Stop the test mode */
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_ide_mm_outb(0x01, dma_base + 0x01);
+	scr1 = rmi_ide_mm_inb(dma_base + 0x03);
+	DBG("scr1[%02X]\n", scr1);
+	rmi_ide_mm_outb(scr1 & ~0x40, dma_base + 0x03);
+#else
 	outb(0x01, dma_base + 0x01);
 	scr1 = inb(dma_base + 0x03);
 	DBG("scr1[%02X]\n", scr1);
 	outb(scr1 & ~0x40, dma_base + 0x03);
+#endif
 
 	/*
 	 * Calculate the input clock in Hz
@@ -304,7 +344,9 @@ static int init_chipset_pdcnew(struct pci_dev *dev)
 {
 	const char *name = DRV_NAME;
 	unsigned long dma_base = pci_resource_start(dev, 4);
+#ifndef CONFIG_RMI_PHOENIX
 	unsigned long sec_dma_base = dma_base + 0x08;
+#endif
 	long pll_input, pll_output, ratio;
 	int f, r;
 	u8 pll_ctl0, pll_ctl1;
@@ -351,10 +393,17 @@ static int init_chipset_pdcnew(struct pci_dev *dev)
 	/* Show the current clock value of PLL control register
 	 * (maybe already configured by the BIOS)
 	 */
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_ide_mm_outb(0x02, sec_dma_base + 0x01);
+	pll_ctl0 = rmi_ide_mm_inb(sec_dma_base + 0x03);
+	rmi_ide_mm_outb(0x03, sec_dma_base + 0x01);
+	pll_ctl1 = rmi_ide_mm_inb(sec_dma_base + 0x03);
+#else
 	outb(0x02, sec_dma_base + 0x01);
 	pll_ctl0 = inb(sec_dma_base + 0x03);
 	outb(0x03, sec_dma_base + 0x01);
 	pll_ctl1 = inb(sec_dma_base + 0x03);
+#endif
 
 	DBG("pll_ctl[%02X][%02X]\n", pll_ctl0, pll_ctl1);
 #endif
@@ -398,10 +447,12 @@ static int init_chipset_pdcnew(struct pci_dev *dev)
 
 	DBG("Writing pll_ctl[%02X][%02X]\n", pll_ctl0, pll_ctl1);
 
+#ifndef CONFIG_RMI_PHOENIX
 	outb(0x02,     sec_dma_base + 0x01);
 	outb(pll_ctl0, sec_dma_base + 0x03);
 	outb(0x03,     sec_dma_base + 0x01);
 	outb(pll_ctl1, sec_dma_base + 0x03);
+#endif
 
 	/* Wait the PLL circuit to be stable */
 	mdelay(30);
@@ -410,10 +461,17 @@ static int init_chipset_pdcnew(struct pci_dev *dev)
 	/*
 	 *  Show the current clock value of PLL control register
 	 */
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_ide_mm_outb(0x02, sec_dma_base + 0x01);
+	pll_ctl0 = rmi_ide_mm_inb(sec_dma_base + 0x03);
+	rmi_ide_mm_outb(0x03, sec_dma_base + 0x01);
+	pll_ctl1 = rmi_ide_mm_inb(sec_dma_base + 0x03);
+#else
 	outb(0x02, sec_dma_base + 0x01);
 	pll_ctl0 = inb(sec_dma_base + 0x03);
 	outb(0x03, sec_dma_base + 0x01);
 	pll_ctl1 = inb(sec_dma_base + 0x03);
+#endif
 
 	DBG("pll_ctl[%02X][%02X]\n", pll_ctl0, pll_ctl1);
 #endif
diff --git a/drivers/ide/phoenix_ide.c b/drivers/ide/phoenix_ide.c
new file mode 100644
index 0000000..e3fbfe6
--- /dev/null
+++ b/drivers/ide/phoenix_ide.c
@@ -0,0 +1,526 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: Support for XLR's on-chip PCMCIA interface...
+
+  *****************************#RMI_1#************************************/
+
+/*  Derived loosely from ide-pmac.c, so:
+ *  
+ *  Copyright (C) 1998 Paul Mackerras.
+ *  Copyright (C) 1995-1998 Mark Lord
+ */
+
+/*
+ * Boards with phoenix processors so far have supported IDE devices via
+ * the Generic Bus, PCI bus, and built-in PCMCIA interface.  In all
+ * cases, byte-swapping must be avoided for these devices (whereas
+ * other PCI devices, for example, will require swapping).  Any
+ * phoenix-targetted kernel including IDE support will include this
+ * file.  Probing of a Generic Bus for an IDE device is controlled by
+ * the definitions of "PHOENIX_HAVE_IDE" and "IDE_PHYS", which are
+ * provided by <asm/rmi/phoenix_ide.h> for ATX1 boards.
+ */
+
+#include <linux/kernel.h>
+#include <linux/ide.h>
+#include <linux/platform_device.h>
+#include <asm/rmi/phoenix_ide.h>
+#include <asm/rmi/64bit.h>
+#include <asm/rmi/pic.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/sim.h>
+
+#ifdef CONFIG_MIPS
+#include <asm/ide.h>
+#else
+#include <asm-generic/ide_iops.h>
+#endif
+
+/* #define DEBUG_PORT  */
+
+#define GPIO_INTR_CLR_REG    0x1EF19180
+#define PCMCIA_CONFIG_REG    0x1EF19140
+
+/*
+ * Our non-swapping I/O operations.  
+ */
+static inline void phoenix_outb(u8 val, unsigned long port) 
+{
+	unsigned int flags=0;
+#ifdef DEBUG_PORT
+	printk(" %s port = %x %x \n", __FUNCTION__, (mips_io_port_base + port),val);
+#endif
+
+	flags = rmi_br_write_lock();
+	*(volatile u8 *)(mips_io_port_base + (port)) = val;
+	rmi_br_write_unlock(flags);
+}
+
+static inline void phoenix_outw(u16 val, unsigned long port) 
+{
+	unsigned int flags=0;
+#ifdef DEBUG_PORT
+	printk("%s  port = %x  %x\n",__FUNCTION__,  (mips_io_port_base + port),val);
+#endif
+	flags = rmi_br_write_lock();
+	*(volatile u16 *)(mips_io_port_base + (port)) = val;
+	rmi_br_write_unlock(flags);
+}
+
+static inline void phoenix_outl(u32 val, unsigned long port) 
+{
+	unsigned int flags=0;
+#ifdef DEBUG_PORT
+	printk("%s  port = %x %x\n",__FUNCTION__,  (mips_io_port_base + port),val);
+#endif
+	flags = rmi_br_write_lock();
+	*(volatile u32 *)(mips_io_port_base + (port)) = val;
+	rmi_br_write_unlock(flags);
+}
+
+static inline unsigned char phoenix_inb(unsigned long port)
+{
+	unsigned int flags=0;
+	unsigned char val ;
+
+	flags = rmi_br_read_lock();
+	val =  (*(volatile u8 *)(mips_io_port_base + (port)));
+	rmi_br_read_unlock(flags);
+#ifdef DEBUG_PORT
+	printk("%s  port = %x %x \n",__FUNCTION__,  (mips_io_port_base + port),val );
+#endif
+	return val;
+}
+
+static inline unsigned short phoenix_inw(unsigned long port)
+{
+	unsigned int flags=0;
+	unsigned short val ;
+	flags = rmi_br_read_lock();
+	val = (*(volatile u16 *)(mips_io_port_base + (port)));
+	rmi_br_read_unlock(flags);
+#ifdef DEBUG_PORT
+	printk("%s  port = %x %x \n",__FUNCTION__,  (mips_io_port_base + port),val );
+#endif
+	return val;
+}
+
+static inline unsigned int phoenix_inl(unsigned long port)
+{
+	unsigned int flags=0;
+	unsigned int val ;
+	flags = rmi_br_read_lock();
+	val =  (*(volatile u32 *)(mips_io_port_base + (port)));
+	rmi_br_read_unlock(flags);
+#ifdef DEBUG_PORT
+	printk("%s  port = %x %x \n",__FUNCTION__,  (mips_io_port_base + port),val );
+#endif
+	return val;
+}
+
+static inline void phoenix_outsb(unsigned long port, void *addr, unsigned int count)
+{
+	while (count--) {
+		phoenix_outb(*(u8 *)addr, port);
+		addr++;
+	}
+}
+
+static inline void phoenix_insb(unsigned long port, void *addr, unsigned int count)
+{
+	while (count--) {
+		*(u8 *)addr = phoenix_inb(port);
+		addr++;
+	}
+}
+
+static inline void phoenix_outsw(unsigned long port, void *addr, unsigned int count)
+{
+	while (count--) {
+		phoenix_outw(*(u16 *)addr, port);
+		addr += 2;
+	}
+}
+
+static inline void phoenix_insw(unsigned long port, void *addr, unsigned int count)
+{
+	while (count--) {
+		*(u16 *)addr = phoenix_inw(port);
+		addr += 2;
+	}
+}
+
+static inline void phoenix_outsl(unsigned long port, void *addr, unsigned int count)
+{
+	while (count--) {
+		phoenix_outl(*(u32 *)addr, port);
+		addr += 4;
+	}
+}
+
+static inline void phoenix_insl(unsigned long port, void *addr, unsigned int count)
+{
+	while (count--) {
+		*(u32 *)addr = phoenix_inl(port);
+		addr += 4;
+	}
+}
+
+
+/* Note:
+   Following functions are taken from drivers/ide/ide-io-std.c
+   unmodified, as required for PCMCIA.
+   The original functions in drivers/ide/ide-io-std.c have been modified so 
+   that PCI devices work properly
+   */
+
+/*
+ *	Conventional PIO operations for ATA devices
+ */
+
+static u8 ide_inb(unsigned long port)
+{
+	return (u8) inb(port);
+}
+
+static void ide_outb(u8 val, unsigned long port)
+{
+	outb(val, port);
+}
+
+/*
+ *	MMIO operations, typically used for SATA controllers
+ */
+
+static u8 ide_mm_inb(unsigned long port)
+{
+	return (u8) readb((void __iomem *) port);
+}
+
+static void ide_mm_outb(u8 value, unsigned long port)
+{
+	writeb(value, (void __iomem *) port);
+}
+
+static void phoenix_ide_exec_command(ide_hwif_t *hwif, u8 cmd)
+{
+	if (hwif->host_flags & IDE_HFLAG_MMIO)
+		writeb(cmd, (void __iomem *)hwif->io_ports.command_addr);
+	else
+		outb(cmd, hwif->io_ports.command_addr);
+}
+
+static u8 phoenix_ide_read_status(ide_hwif_t *hwif)
+{
+	if (hwif->host_flags & IDE_HFLAG_MMIO)
+		return readb((void __iomem *)hwif->io_ports.status_addr);
+	else
+		return inb(hwif->io_ports.status_addr);
+}
+
+static u8 phoenix_ide_read_altstatus(ide_hwif_t *hwif)
+{
+	if (hwif->host_flags & IDE_HFLAG_MMIO)
+		return readb((void __iomem *)hwif->io_ports.ctl_addr);
+	else
+		return inb(hwif->io_ports.ctl_addr);
+}
+
+static void phoenix_ide_write_devctl(ide_hwif_t *hwif, u8 ctl)
+{
+	if (hwif->host_flags & IDE_HFLAG_MMIO)
+		writeb(ctl, (void __iomem *)hwif->io_ports.ctl_addr);
+	else
+		outb(ctl, hwif->io_ports.ctl_addr);
+}
+
+static void phoenix_ide_dev_select(ide_drive_t *drive)
+{
+	ide_hwif_t *hwif = drive->hwif;
+	u8 select = drive->select | ATA_DEVICE_OBS;
+
+	if (hwif->host_flags & IDE_HFLAG_MMIO)
+		writeb(select, (void __iomem *)hwif->io_ports.device_addr);
+	else
+		outb(select, hwif->io_ports.device_addr);
+}
+
+static void phoenix_ide_tf_load(ide_drive_t *drive, struct ide_taskfile *tf, u8 valid)
+{
+	ide_hwif_t *hwif = drive->hwif;
+	struct ide_io_ports *io_ports = &hwif->io_ports;
+	void (*tf_outb)(u8 addr, unsigned long port);
+	u8 mmio = (hwif->host_flags & IDE_HFLAG_MMIO) ? 1 : 0;
+
+	if (mmio)
+		tf_outb = ide_mm_outb;
+	else
+		tf_outb = ide_outb;
+
+	if (valid & IDE_VALID_FEATURE)
+		tf_outb(tf->feature, io_ports->feature_addr);
+	if (valid & IDE_VALID_NSECT)
+		tf_outb(tf->nsect, io_ports->nsect_addr);
+	if (valid & IDE_VALID_LBAL)
+		tf_outb(tf->lbal, io_ports->lbal_addr);
+	if (valid & IDE_VALID_LBAM)
+		tf_outb(tf->lbam, io_ports->lbam_addr);
+	if (valid & IDE_VALID_LBAH)
+		tf_outb(tf->lbah, io_ports->lbah_addr);
+	if (valid & IDE_VALID_DEVICE)
+		tf_outb(tf->device, io_ports->device_addr);
+}
+
+static void phoenix_ide_tf_read(ide_drive_t *drive, struct ide_taskfile *tf, u8 valid)
+{
+	ide_hwif_t *hwif = drive->hwif;
+	struct ide_io_ports *io_ports = &hwif->io_ports;
+	u8 (*tf_inb)(unsigned long port);
+	u8 mmio = (hwif->host_flags & IDE_HFLAG_MMIO) ? 1 : 0;
+
+	if (mmio)
+		tf_inb  = ide_mm_inb;
+	else
+		tf_inb  = ide_inb;
+
+	if (valid & IDE_VALID_ERROR)
+		tf->error  = tf_inb(io_ports->feature_addr);
+	if (valid & IDE_VALID_NSECT)
+		tf->nsect  = tf_inb(io_ports->nsect_addr);
+	if (valid & IDE_VALID_LBAL)
+		tf->lbal   = tf_inb(io_ports->lbal_addr);
+	if (valid & IDE_VALID_LBAM)
+		tf->lbam   = tf_inb(io_ports->lbam_addr);
+	if (valid & IDE_VALID_LBAH)
+		tf->lbah   = tf_inb(io_ports->lbah_addr);
+	if (valid & IDE_VALID_DEVICE)
+		tf->device = tf_inb(io_ports->device_addr);
+}
+
+/*
+ * Some localbus EIDE interfaces require a special access sequence
+ * when using 32-bit I/O instructions to transfer data.  We call this
+ * the "vlb_sync" sequence, which consists of three successive reads
+ * of the sector count register location, with interrupts disabled
+ * to ensure that the reads all happen together.
+ */
+static void ata_vlb_sync(unsigned long port)
+{
+	(void)inb(port);
+	(void)inb(port);
+	(void)inb(port);
+}
+
+/*
+ * This is used for most PIO data transfers *from* the IDE interface
+ *
+ * These routines will round up any request for an odd number of bytes,
+ * so if an odd len is specified, be sure that there's at least one
+ * extra byte allocated for the buffer.
+ */
+static void phoenix_ide_input_data(ide_drive_t *drive, struct ide_cmd *cmd, void *buf,
+		    unsigned int len)
+{
+	ide_hwif_t *hwif = drive->hwif;
+	struct ide_io_ports *io_ports = &hwif->io_ports;
+	unsigned long data_addr = io_ports->data_addr;
+	unsigned int words = (len + 1) >> 1;
+	u8 io_32bit = drive->io_32bit;
+	u8 mmio = (hwif->host_flags & IDE_HFLAG_MMIO) ? 1 : 0;
+
+	if (io_32bit) {
+		unsigned long uninitialized_var(flags);
+
+		if ((io_32bit & 2) && !mmio) {
+			local_irq_save(flags);
+			ata_vlb_sync(io_ports->nsect_addr);
+		}
+
+		words >>= 1;
+		if (mmio)
+			__ide_mm_insl((void __iomem *)data_addr, buf, words);
+		else
+			insl(data_addr, buf, words);
+
+		if ((io_32bit & 2) && !mmio)
+			local_irq_restore(flags);
+
+		if (((len + 1) & 3) < 2)
+			return;
+
+		buf += len & ~3;
+		words = 1;
+	}
+
+	if (mmio)
+		__ide_mm_insw((void __iomem *)data_addr, buf, words);
+	else
+		insw(data_addr, buf, words);
+}
+
+/*
+ * This is used for most PIO data transfers *to* the IDE interface
+ */
+static void phoenix_ide_output_data(ide_drive_t *drive, struct ide_cmd *cmd, void *buf,
+		     unsigned int len)
+{
+	ide_hwif_t *hwif = drive->hwif;
+	struct ide_io_ports *io_ports = &hwif->io_ports;
+	unsigned long data_addr = io_ports->data_addr;
+	unsigned int words = (len + 1) >> 1;
+	u8 io_32bit = drive->io_32bit;
+	u8 mmio = (hwif->host_flags & IDE_HFLAG_MMIO) ? 1 : 0;
+
+	if (io_32bit) {
+		unsigned long uninitialized_var(flags);
+
+		if ((io_32bit & 2) && !mmio) {
+			local_irq_save(flags);
+			ata_vlb_sync(io_ports->nsect_addr);
+		}
+
+		words >>= 1;
+		if (mmio)
+			__ide_mm_outsl((void __iomem *)data_addr, buf, words);
+		else
+			outsl(data_addr, buf, words);
+
+		if ((io_32bit & 2) && !mmio)
+			local_irq_restore(flags);
+
+		if (((len + 1) & 3) < 2)
+			return;
+
+		buf += len & ~3;
+		words = 1;
+	}
+
+	if (mmio)
+		__ide_mm_outsw((void __iomem *)data_addr, buf, words);
+	else
+		outsw(data_addr, buf, words);
+}
+
+const struct ide_tp_ops phoenix_tp_ops = {
+	.exec_command		= phoenix_ide_exec_command,
+	.read_status		= phoenix_ide_read_status,
+	.read_altstatus		= phoenix_ide_read_altstatus,
+	.write_devctl		= phoenix_ide_write_devctl,
+
+	.dev_select		= phoenix_ide_dev_select,
+	.tf_load		= phoenix_ide_tf_load,
+	.tf_read		= phoenix_ide_tf_read,
+
+	.input_data		= phoenix_ide_input_data,
+	.output_data		= phoenix_ide_output_data,
+};
+
+/* Note ends:
+   Above functions are taken from drivers/ide/ide-io-std.c
+   */
+
+static const struct ide_port_info phoenix_port_info = {
+	.tp_ops			= &phoenix_tp_ops,
+	.host_flags 		= IDE_HFLAG_NO_DMA,
+};
+
+#define PHOENIX_IDE_REG(pcaddr) (IOADDR(IDE_PHYS) + ((pcaddr)) - mips_io_port_base)
+
+/*
+ * phoenix_ide_probe :
+ *      - Probe the PCMCIA interface
+ *        on selected  XLR Boards.
+ */
+
+static int __devinit phoenix_ide_probe (struct platform_device *dev)
+{
+#if defined(PHOENIX_HAVE_IDE) && defined(IDE_PHYS)
+	unsigned int i = 0;
+	int ret = 0;
+	struct ide_host *host;
+	struct ide_hw hw, *hws[] = { &hw };
+	ide_hwif_t *phoenix_ide_hwif;
+	extern int dev_tree_en;
+	extern int fdt_get_flash_enabled(void);
+
+	if(dev_tree_en && fdt_get_flash_enabled() == 0) {
+		printk("FLASH disabled by boot arg, skipping..\n");
+		return 0;
+	}
+
+
+	if (xlr_board_atx_iii() || xlr_board_atx_v())
+	{
+		printk("** Skipping PCMCIA Interface Probe.\n");
+		goto out;
+	}
+
+	printk ("Initializing Phoenix PCMCIA IDE...\n");
+
+	memset(&hw, 0, sizeof(hw));
+	
+	/* setup ports here */
+	hw.io_ports.data_addr   = PHOENIX_IDE_REG(0x1f0);
+	hw.io_ports.error_addr  = PHOENIX_IDE_REG(0x1f1);
+	hw.io_ports.nsect_addr  = PHOENIX_IDE_REG(0x1f2);
+	hw.io_ports.lbal_addr   = PHOENIX_IDE_REG(0x1f3);
+	hw.io_ports.lbam_addr   = PHOENIX_IDE_REG(0x1f4);
+	hw.io_ports.lbah_addr   = PHOENIX_IDE_REG(0x1f5);
+	hw.io_ports.device_addr = PHOENIX_IDE_REG(0x1f6);
+	hw.io_ports.status_addr = PHOENIX_IDE_REG(0x1f7);
+	hw.io_ports.ctl_addr    = PHOENIX_IDE_REG(0x3f6);
+	hw.io_ports.irq_addr    = PHOENIX_IDE_REG(0x3f7);
+
+	hw.irq = PIC_PCMCIA_IRQ;
+	hw.dev = &dev->dev;
+
+	ret = ide_host_add(&phoenix_port_info, hws, 1, &host);
+	if (ret)
+		goto out;
+
+	platform_set_drvdata(dev, host);
+
+	phoenix_ide_hwif = host->ports[0];
+
+        printk("Phoenix PCMCIA configured as IDE interface = %d\n", i);
+out:
+	return ret;
+
+#endif
+}
+
+static int phoenix_ide_remove (struct platform_device *dev)
+{
+
+	return 0;
+}
+
+static struct platform_driver phoenix_ide_driver = {
+	.driver = {
+		.name = "phoenix-pcmcia",
+		.owner = THIS_MODULE,
+	},
+	.probe          = phoenix_ide_probe,
+	.remove         = phoenix_ide_remove,
+};
+
+static int __init phoenix_ide_init(void)
+{
+	return platform_driver_register(&phoenix_ide_driver);
+}
+
+static void __exit phoenix_ide_exit(void)
+{
+	platform_driver_unregister(&phoenix_ide_driver);
+}
+
+module_init(phoenix_ide_init);
+module_exit(phoenix_ide_exit);
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("PHOENIX-PCMCIA IDE driver");
diff --git a/drivers/mtd/maps/Kconfig b/drivers/mtd/maps/Kconfig
index 8af67cf..7142cdb 100644
--- a/drivers/mtd/maps/Kconfig
+++ b/drivers/mtd/maps/Kconfig
@@ -249,6 +249,12 @@ config MTD_LANTIQ
 	help
 	  Support for NOR flash attached to the Lantiq SoC's External Bus Unit.
 
+config MTD_XLR
+   	tristate "XLR Flash MTD support"
+   	depends on RMI_PHOENIX
+   	help
+     	  Flash memory access on XLR/XLS Reference Boards
+
 config MTD_DILNETPC
 	tristate "CFI Flash device mapped on DIL/Net PC"
 	depends on X86 && MTD_CFI_INTELEXT && BROKEN
diff --git a/drivers/mtd/maps/Makefile b/drivers/mtd/maps/Makefile
index 68a9a91..ea41d84 100644
--- a/drivers/mtd/maps/Makefile
+++ b/drivers/mtd/maps/Makefile
@@ -54,6 +54,7 @@ obj-$(CONFIG_MTD_INTEL_VR_NOR)	+= intel_vr_nor.o
 obj-$(CONFIG_MTD_BFIN_ASYNC)	+= bfin-async-flash.o
 obj-$(CONFIG_MTD_RBTX4939)	+= rbtx4939-flash.o
 obj-$(CONFIG_MTD_VMU)		+= vmu-flash.o
+obj-$(CONFIG_MTD_XLR)           += xlr-flash.o
 obj-$(CONFIG_MTD_GPIO_ADDR)	+= gpio-addr-flash.o
 obj-$(CONFIG_MTD_LATCH_ADDR)	+= latch-addr-flash.o
 obj-$(CONFIG_MTD_LANTIQ)	+= lantiq-flash.o
diff --git a/drivers/mtd/maps/xlr-flash.c b/drivers/mtd/maps/xlr-flash.c
new file mode 100644
index 0000000..409b0bf
--- /dev/null
+++ b/drivers/mtd/maps/xlr-flash.c
@@ -0,0 +1,100 @@
+/*
+ * Flash memory access on XLR evaluation boards
+ *
+ * (C) 2008, 2009  RMI Corp <sandip@rmicorp.com>
+ *
+ */
+
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/map.h>
+#include <linux/mtd/partitions.h>
+
+#include <asm/io.h>
+#include <asm/rmi/sim.h>
+
+#ifdef 	DEBUG_RW
+#define	DBG(x...)	printk(x)
+#else
+#define	DBG(x...)
+#endif
+
+#define BOARD_MAP_NAME "SPS Flash"
+#define BOARD_FLASH_SIZE 0x01000000 /* 16MB */
+#define BOARD_FLASH_BASE 0x1c000000 
+#define BOARD_FLASH_WIDTH 2 /* 16-bits */
+
+static struct map_info sps_map = {
+	.name =	BOARD_MAP_NAME,
+};
+
+static struct mtd_partition sps_partitions[] = {
+        {
+                .name = "User FS",
+                .offset = 0x800000, // Upto 8 MB is used by bootloader.
+		.size = MTDPART_SIZ_FULL ,
+        }
+};
+
+static struct mtd_info *mymtd;
+
+int __init sps_mtd_init(void)
+{
+	struct mtd_partition *parts;
+	int nb_parts = 0;
+	unsigned long window_addr;
+	unsigned long window_size;
+
+	if (xlr_board_atx_viii()){
+		return -ENODEV;
+	}
+	/* Default flash buswidth */
+	sps_map.bankwidth = BOARD_FLASH_WIDTH;
+
+	window_addr = BOARD_FLASH_BASE;
+	window_size = BOARD_FLASH_SIZE;
+
+	/*
+	 * Static partition definition selection
+	 */
+	parts = sps_partitions;
+	nb_parts = ARRAY_SIZE(sps_partitions);
+	sps_map.size = window_size;
+
+	/*
+	 * Now let's probe for the actual flash.  Do it here since
+	 * specific machine settings might have been set above.
+	 */
+	printk(KERN_NOTICE BOARD_MAP_NAME ": probing %d-bit flash bus\n",
+			sps_map.bankwidth*8);
+	sps_map.virt = ioremap(window_addr, window_size);
+	mymtd = do_map_probe("cfi_probe", &sps_map);
+	if (!mymtd) {
+		iounmap(sps_map.virt);
+		return -ENXIO;
+	}
+	mymtd->owner = THIS_MODULE;
+
+	add_mtd_partitions(mymtd, parts, nb_parts);
+	return 0;
+}
+
+static void __exit sps_mtd_cleanup(void)
+{
+	if (mymtd) {
+		del_mtd_partitions(mymtd);
+		map_destroy(mymtd);
+		iounmap(sps_map.virt);
+	}
+}
+
+module_init(sps_mtd_init);
+module_exit(sps_mtd_cleanup);
+
+MODULE_AUTHOR("Sandip Matte, RMI Corporation");
+MODULE_DESCRIPTION(BOARD_MAP_NAME " MTD driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/mtd/nand/nand_base.c b/drivers/mtd/nand/nand_base.c
index 821644a..9e972dd 100644
--- a/drivers/mtd/nand/nand_base.c
+++ b/drivers/mtd/nand/nand_base.c
@@ -93,6 +93,8 @@ static struct nand_ecclayout nand_oob_128 = {
 		 .length = 78} }
 };
 
+static int nand_manufacturer;
+
 static int nand_get_device(struct nand_chip *chip, struct mtd_info *mtd,
 			   int new_state);
 
@@ -619,6 +621,11 @@ static void nand_command(struct mtd_info *mtd, unsigned int command,
 	case NAND_CMD_STATUS:
 		return;
 
+	/* In case of micron nand, we need to return */
+	case NAND_CMD_READID:
+		udelay(chip->chip_delay);
+		return;
+
 	case NAND_CMD_RESET:
 		if (chip->dev_ready)
 			break;
@@ -666,6 +673,7 @@ static void nand_command_lp(struct mtd_info *mtd, unsigned int command,
 			    int column, int page_addr)
 {
 	register struct nand_chip *chip = mtd->priv;
+	int micron_chip = 0;
 
 	/* Emulate NAND_CMD_READOOB */
 	if (command == NAND_CMD_READOOB) {
@@ -701,6 +709,14 @@ static void nand_command_lp(struct mtd_info *mtd, unsigned int command,
 	}
 	chip->cmd_ctrl(mtd, NAND_CMD_NONE, NAND_NCE | NAND_CTRL_CHANGE);
 
+	if ((mtd->name) && (nand_manufacturer == NAND_MFR_MICRON))
+		micron_chip = 1;
+
+	if (micron_chip) {
+		if (command == NAND_CMD_READID)
+			return;
+	}
+
 	/*
 	 * Program and erase have their own busy handlers status, sequential
 	 * in, and deplete1 need no delay.
@@ -771,6 +787,10 @@ static void nand_command_lp(struct mtd_info *mtd, unsigned int command,
 	ndelay(100);
 
 	nand_wait_ready(mtd);
+	if ((micron_chip) && (command == NAND_CMD_READ0)) {
+		chip->cmd_ctrl(mtd, NAND_CMD_READ0,
+			       NAND_CLE | NAND_CTRL_CHANGE);
+	}
 }
 
 /**
@@ -3167,6 +3187,8 @@ ident_done:
 		nand_manuf_ids[maf_idx].name,
 		chip->onfi_version ? chip->onfi_params.model : type->name);
 
+	nand_manufacturer =  *maf_id;
+
 	return type;
 }
 
diff --git a/drivers/mtd/nand/xls_nand.c b/drivers/mtd/nand/xls_nand.c
new file mode 100644
index 0000000..45f1826
--- /dev/null
+++ b/drivers/mtd/nand/xls_nand.c
@@ -0,0 +1,281 @@
+/*
+ * drivers/mtd/nand/xls_nand.c
+ *
+ *  Copyright (C) 2007 Raza microelectronics Inc
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ */
+
+#include <linux/genhd.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/delay.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/nand_ecc.h>
+#include <linux/mtd/partitions.h>
+#include <linux/interrupt.h>
+#include <asm/io.h>
+#include <asm/rmi/sim.h>
+
+#include "xls_nand.h"
+
+static u8 hwctl;
+static void __iomem *xls_io_base;
+static int xls_nand_phys_base = 0xBD800000;
+
+/* register offset */
+#define FLASHIO	 	0xBD800000		/* Flash I/O */
+
+/*
+ * MTD structure for xls
+ */
+static struct mtd_info *xls_mtd= NULL;
+
+/*
+ * Define partitions for flash device
+ */
+#define DEFAULT_NUM_PARTITIONS 2
+
+#define CLE_REG (0xbef19240 + (long)(((struct nand_chip *)(mtd->priv))->priv) * 4)
+#define ALE_REG (0xbef19280 + (long)(((struct nand_chip *)(mtd->priv))->priv) * 4)
+#define RW_OFFSET  0xbd800000 
+
+#define WRITE_NAND_CLE(command)(nand_write_cmd((long)(int)CLE_REG, command))
+#define WRITE_NAND_ALE(address)(nand_write_addr((long)(int)ALE_REG, address))
+#define WRITE_NAND_ARRAY(data,n) (nand_write_multi((long)(int)RW_OFFSET, data, n))
+#define READ_NAND_BYTE(data)(nand_read_byte((long)(int)RW_OFFSET, &(data)))
+#define READ_NAND_ARRAY(data,n) (nand_read_multi((long)(int)RW_OFFSET, data, n))
+
+
+static int nr_partitions;
+static struct mtd_partition xls_nand_default_partition_info[] = {
+	{
+	.name = "Root Filesystem",
+	.offset = 64 * 64 * 2048, /* 54M@8M */
+	.size = 432 * 64 * 2048,
+	},
+	{
+	.name = "Home Filesystem",
+	.offset = MTDPART_OFS_APPEND , /* Rest@62M */
+	.size = MTDPART_SIZ_FULL ,
+	},
+};
+
+/*
+ *	hardware specific access to control-lines
+ *	In case of xls, we remember the access, and accordingly do read/write of
+ *	ale/cle or IO.
+ */
+static void xls_nand_hwcontrol(struct mtd_info *mtd, int cmd,
+				   unsigned int ctrl)
+{
+	unsigned char bits = ctrl & 0x07;
+
+		if (bits & NAND_CLE)
+			WRITE_NAND_CLE(cmd);
+		else if (bits & NAND_ALE)
+			WRITE_NAND_ALE(cmd);
+}
+
+#define STATUS_BIT_0 0x01
+#define STATUS_BIT_6 0x40
+#define MAX_READ_STATUS_COUNT 100000
+#define NAND_CMD_READ_STATUS 0x70
+
+int nand_read_status(struct mtd_info *mtd)
+{
+	int status_count;
+	unsigned char status;
+
+	WRITE_NAND_CLE(NAND_CMD_READ_STATUS);		
+	status_count = 0;
+
+	while(status_count < MAX_READ_STATUS_COUNT)
+	{
+		/* Read status byte */
+		READ_NAND_BYTE(status);
+		/* Check status */
+		if((status& STATUS_BIT_6) == STATUS_BIT_6)  /* if 1, device is ready */
+		{
+			if((status& STATUS_BIT_0) == 0)	/* if 0, the last operation was succesful */
+				return 1;
+			else
+				return 0;
+		}			
+		status_count++;
+	}
+
+	return 0;
+}
+
+static unsigned char xls_nand_read_byte(struct mtd_info *mtd)
+{
+	unsigned char x;
+	READ_NAND_BYTE(x);
+	return x;
+}
+
+static void xls_nand_write_buf(struct mtd_info *mtd, const unsigned char *buf, int len)
+{
+	int i;
+    unsigned char *tmp = (unsigned char *)buf;
+
+	for (i = 0; i < len; i++) {
+		WRITE_NAND_ARRAY((void *)&tmp[i],1);
+	}
+}
+
+static void xls_nand_read_buf(struct mtd_info *mtd, unsigned char *buf, int len)
+{
+	READ_NAND_ARRAY(buf,len);
+}
+
+static int xls_nand_verify_buf(struct mtd_info *mtd, const unsigned char *buf, int len)
+{
+	int i;
+	unsigned char temp_byte;
+
+	for (i = 0; i < len; i++) {
+		READ_NAND_BYTE(temp_byte);
+		if (buf[i] != temp_byte)
+			return i;
+	}
+
+	return 0;
+}
+
+static int xls_nand_dev_ready(struct mtd_info *mtd)
+{
+	return nand_read_status(mtd);
+}
+
+#ifdef CONFIG_MTD_PARTITIONS
+const char *part_probes[] = { "cmdlinepart", NULL };
+#endif
+
+/*
+ * Main initialization routine
+ */
+int __init
+xls_nand_init(void)
+{
+	struct nand_chip *this;
+	struct mtd_partition* xls_partition_info;
+	int err = 0;
+	uint32_t nand_gpio_check;
+	uint32_t read_cs_base;
+	int nand_chip_select;
+	
+	hwctl = 0;
+
+	if (!is_xls())
+		return -ENODEV;
+
+
+	/* nand is present */
+	nand_gpio_check = *(uint32_t *)((long)(int)(0xbef00000 + 0x18000 + 84));
+	if ((nand_gpio_check >> 16) & 0x1)
+		nand_chip_select = 0;
+	else
+		nand_chip_select = 2;
+	
+	read_cs_base = *(uint32_t *)((long)(int)(0xbef19000 + nand_chip_select * 4));
+
+	read_cs_base = read_cs_base & 0xffff;
+
+	if (read_cs_base  != 384) { /* This checks if flash bar is mapped at
+				       0xbd800000 */
+		printk ("Burn bootloader version > 1.4.2 to use nand flash\n");
+		return -ENODEV;
+	}
+	/* Allocate memory for MTD device structure and private data */
+	xls_mtd = kmalloc(sizeof(struct mtd_info) + sizeof(struct nand_chip),
+				GFP_KERNEL);
+	if (!xls_mtd) {
+		printk ("Unable to allocate xls NAND MTD device structure.\n");
+		return -ENOMEM;
+	}
+
+	/* map physical adress */
+	xls_io_base = ioremap((long)xls_nand_phys_base, 0x1000);
+	if(!xls_io_base){
+		printk("ioremap to access XLS NAND chip failed\n");
+		kfree(xls_mtd);
+		return -EIO;
+	}
+
+	/* Get pointer to private data */
+	this = (struct nand_chip *) (&xls_mtd[1]);
+
+	/* Initialize structures */
+	memset((char *) xls_mtd, 0, sizeof(struct mtd_info));
+	memset((char *) this, 0, sizeof(struct nand_chip));
+
+	/* Link the private data with the MTD structure */
+	xls_mtd->priv = this;
+
+	/* Set address of NAND IO lines */
+	this->IO_ADDR_R = (char *)(long)(int)FLASHIO;
+	this->IO_ADDR_W = (char *)(long)(int)FLASHIO;
+	/* Set address of hardware control function */
+	this->cmd_ctrl = xls_nand_hwcontrol;
+	this->dev_ready = xls_nand_dev_ready;
+	this->read_byte  = xls_nand_read_byte;
+	this->write_buf  = xls_nand_write_buf;
+	this->read_buf   = xls_nand_read_buf;
+	this->verify_buf = xls_nand_verify_buf;
+	
+	/* 15 us command delay time */
+	this->chip_delay = 15;
+	this->ecc.mode = NAND_ECC_SOFT;
+	this->priv = (void *)(unsigned long)nand_chip_select;
+
+	/* Scan to find existence of the device */
+	err=nand_scan(xls_mtd,1);
+	if (err) {
+		iounmap(xls_io_base);
+		kfree(xls_mtd);
+		return err;
+	}
+
+	xls_mtd->name = "xls-nand";
+	/* Register the partitions */
+#ifdef CONFIG_MTD_PARTITIONS
+	nr_partitions = parse_mtd_partitions(xls_mtd, part_probes,
+						&xls_partition_info, 0);
+#endif 
+
+	if (nr_partitions <= 0) {
+		nr_partitions = DEFAULT_NUM_PARTITIONS;
+		xls_partition_info = xls_nand_default_partition_info;
+	}
+
+	add_mtd_partitions(xls_mtd, xls_partition_info, nr_partitions);
+
+	return 0;
+}
+module_init(xls_nand_init);
+
+#ifdef MODULE
+static void __exit xls_nand_cleanup(void)
+{
+	struct nand_chip *this = (struct nand_chip *) &xls_mtd[1];
+
+	/* Release resources, unregister device */
+	nand_release(xls_mtd);
+
+	iounmap(xls_io_base);
+
+	/* Free the MTD device structure */
+	kfree(xls_mtd);
+}
+module_exit(xls_nand_cleanup);
+#endif
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Raza Micronelectronics <sandip@razamicro.com>");
+MODULE_DESCRIPTION("Device specific logic for NAND flash on XLS Series");
diff --git a/drivers/mtd/nand/xls_nand.h b/drivers/mtd/nand/xls_nand.h
new file mode 100644
index 0000000..6558b8b
--- /dev/null
+++ b/drivers/mtd/nand/xls_nand.h
@@ -0,0 +1,41 @@
+#ifndef __XLS_NAND_H__
+#define __XLS_NAND_H__
+
+static void nand_write_cmd(unsigned long offset, unsigned char cmd)
+{
+	*(volatile uint32_t *)offset = (uint32_t)cmd;
+}
+
+static void nand_write_addr(unsigned long offset, unsigned char addr)
+{
+	*(volatile uint32_t *)offset = (uint32_t)addr;
+}
+
+static void nand_read_multi(unsigned long offset, void *buf, unsigned short len)
+{
+	int i;
+	volatile unsigned char *tbuf = (volatile unsigned char *)buf;
+
+	for (i = 0; i < len; i++) {
+		*tbuf = *(volatile unsigned char *)offset;
+		tbuf++;
+	}
+}
+
+static void nand_read_byte(unsigned long offset, void *buf)
+{
+	*(volatile unsigned char *) buf = *(volatile unsigned char *)offset;
+}
+
+static void nand_write_multi(unsigned long offset, void *buf, unsigned short len)
+{
+	int i;
+	volatile unsigned char *tbuf = (volatile char *)buf;
+
+	for (i = 0; i < len; i++) {
+		*(volatile unsigned char *)offset = *(volatile unsigned char *)tbuf;
+		tbuf++;
+	}
+}
+
+#endif /* __XLS_NAND_H__ */
diff --git a/drivers/net/Kconfig b/drivers/net/Kconfig
index b982854..0b7decb 100644
--- a/drivers/net/Kconfig
+++ b/drivers/net/Kconfig
@@ -160,6 +160,12 @@ config NETCONSOLE
 	If you want to log kernel messages over the network, enable this.
 	See <file:Documentation/networking/netconsole.txt> for details.
 
+config RMI_VNET
+	bool "Virtual Networking for CRF"
+	---help---
+	This enables internal network for CRF domains using shared memory and
+	event queues.
+
 config NETCONSOLE_DYNAMIC
 	bool "Dynamic reconfiguration of logging targets"
 	depends on NETCONSOLE && SYSFS && CONFIGFS_FS && \
diff --git a/drivers/net/kgdboe.c b/drivers/net/kgdboe.c
new file mode 100644
index 0000000..600347f
--- /dev/null
+++ b/drivers/net/kgdboe.c
@@ -0,0 +1,220 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/*
+ * drivers/net/kgdboe.c
+ *
+ * A network interface for GDB.
+ * Based upon 'gdbserial' by David Grothe <dave@gcom.com>
+ * and Scott Foehner <sfoehner@engr.sgi.com>
+ *
+ * Maintainers: Amit S. Kale <amitkale@linsyssoft.com> and
+ * 		Tom Rini <trini@kernel.crashing.org>
+ *
+ * 2004 (c) Amit S. Kale <amitkale@linsyssoft.com>
+ * 2004-2005 (c) MontaVista Software, Inc.
+ * 2005 (c) Wind River Systems, Inc.
+ *
+ * Other folks:
+ * San Mehat <nettwerk@biodome.org>
+ * Robert Walsh <rjwalsh@durables.org>
+ * wangdi <wangdi@clusterfs.com>.
+ * Matt Mackall <mpm@selenic.com>
+ * Pavel Machek <pavel@suse.cz>
+ * Jason Wessel <jason.wessel@windriver.com>
+ *
+ * This file is licensed under the terms of the GNU General Public License
+ * version 2. This program is licensed "as is" without any warranty of any
+ * kind, whether express or implied.
+ *
+ * Changes:
+ * 3/10/05 - Jason Wessel <jason.wessel@windriver.com>
+ * - Added ability to compile/load as module
+ *
+ * Known problems:
+ * - There is no way to deny the unloading of the module
+ *   if KGDB is connected, but an attempt is made to handle it
+ */
+
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/string.h>
+#include <linux/kgdb.h>
+#include <linux/netpoll.h>
+#include <linux/init.h>
+
+#include <asm/atomic.h>
+
+#define IN_BUF_SIZE 512		/* power of 2, please */
+#define OUT_BUF_SIZE 30		/* We don't want to send too big of a packet. */
+
+static char in_buf[IN_BUF_SIZE], out_buf[OUT_BUF_SIZE];
+static int in_head, in_tail, out_count;
+static atomic_t in_count;
+/* 0 = unconfigured, 1 = netpoll options parsed, 2 = fully configured. */
+static int configured;
+
+static void rx_hook(struct netpoll *np, int port, char *msg, int len);
+static void eth_pre_exception_handler(void);
+static void eth_post_exception_handler(void);
+static int eth_get_char(void);
+static void eth_flush_buf(void);
+static void eth_put_char(int chr);
+int init_kgdboe(void);
+
+static struct netpoll np = {
+	.name = "kgdboe",
+	.dev_name = "eth0",
+	.rx_hook = rx_hook,
+	.local_port = 6443,
+	.remote_port = 6442,
+	.remote_mac = {0xff, 0xff, 0xff, 0xff, 0xff, 0xff},
+};
+
+MODULE_DESCRIPTION("KGDB driver for network interfaces");
+MODULE_LICENSE("GPL");
+static char config[256];
+module_param_string(kgdboe, config, 256, 0);
+MODULE_PARM_DESC(kgdboe, " kgdboe=[src-port]@[src-ip]/[dev],"
+		 "[tgt-port]@<tgt-ip>/<tgt-macaddr>\n");
+
+static struct kgdb_io local_kgdb_io_ops = {
+	.read_char = eth_get_char,
+	.write_char = eth_put_char,
+	.init = init_kgdboe,
+	.flush = eth_flush_buf,
+	.pre_exception = eth_pre_exception_handler,
+	.post_exception = eth_post_exception_handler
+};
+
+static void eth_pre_exception_handler(void)
+{
+	netpoll_set_trap(1);
+}
+
+static void eth_post_exception_handler(void)
+{
+	netpoll_set_trap(0);
+}
+
+static int eth_get_char(void)
+{
+	int chr;
+
+	while (atomic_read(&in_count) == 0)
+		netpoll_poll(&np);
+
+	chr = in_buf[in_tail++];
+	in_tail &= (IN_BUF_SIZE - 1);
+	atomic_dec(&in_count);
+	return chr;
+}
+
+static void eth_flush_buf(void)
+{
+	if (out_count && np.dev) {
+		netpoll_send_udp(&np, out_buf, out_count);
+		memset(out_buf, 0, sizeof(out_buf));
+		out_count = 0;
+	}
+}
+
+static void eth_put_char(int chr)
+{
+	out_buf[out_count++] = chr;
+	if (out_count == OUT_BUF_SIZE)
+		eth_flush_buf();
+}
+
+static void rx_hook(struct netpoll *np, int port, char *msg, int len)
+{
+	int i;
+
+	np->remote_port = port;
+
+	/*
+	 * This could be GDB trying to attach.  But it could also be GDB
+	 * finishing up a session, with kgdb_connected=0 but GDB sending
+	 * an ACK for the final packet.  To make sure we don't try and
+	 * make a breakpoint when GDB is leaving, make sure that if
+	 * !kgdb_connected the only len == 1 packet we allow is ^C.
+	 */
+	if (!kgdb_connected && (len != 1 || msg[0] == 3) &&
+	    !atomic_read(&kgdb_setting_breakpoint))
+		tasklet_schedule(&kgdb_tasklet_breakpoint);
+
+	for (i = 0; i < len; i++) {
+		if (msg[i] == 3)
+			tasklet_schedule(&kgdb_tasklet_breakpoint);
+
+		if (atomic_read(&in_count) >= IN_BUF_SIZE) {
+			/* buffer overflow, clear it */
+			in_head = in_tail = 0;
+			atomic_set(&in_count, 0);
+			break;
+		}
+		in_buf[in_head++] = msg[i];
+		in_head &= (IN_BUF_SIZE - 1);
+		atomic_inc(&in_count);
+	}
+}
+
+static int option_setup(char *opt)
+{
+	configured = !netpoll_parse_options(&np, opt);
+	return 0;
+}
+
+__setup("kgdboe=", option_setup);
+
+int init_kgdboe(void)
+{
+	/* Already done? */
+	if (configured == 2)
+		return 0;
+
+	if (strlen(config))
+		option_setup(config);
+
+	if (!configured) {
+		printk("kgdboe: configuration incorrect - kgdboe not "
+		       "loaded.\n");
+		printk("  Usage: kgdboe=[src-port]@[src-ip]/[dev],[tgt-port]"
+		       "@<tgt-ip>/[tgt-macaddr]\n");
+		return -EINVAL;
+	}
+
+	if (netpoll_setup(&np)) {
+		printk("kgdboe: netpoll_setup failed kgdboe failed\n");
+		return -EINVAL;
+	}
+
+	if (kgdb_register_io_module(&local_kgdb_io_ops))
+		return -EINVAL;
+
+	printk(KERN_INFO "kgdboe: debugging over ethernet enabled\n");
+
+	configured = 2;
+
+	return 0;
+}
+
+static void cleanup_kgdboe(void)
+{
+	netpoll_cleanup(&np);
+	configured = 0;
+
+	kgdb_unregister_io_module(&local_kgdb_io_ops);
+}
+
+module_init(init_kgdboe);
+module_exit(cleanup_kgdboe);
diff --git a/drivers/net/phoenix_mac.c b/drivers/net/phoenix_mac.c
new file mode 100644
index 0000000..002c6c4
--- /dev/null
+++ b/drivers/net/phoenix_mac.c
@@ -0,0 +1,4560 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/socket.h>
+#include <linux/errno.h>
+#include <linux/fcntl.h>
+#include <linux/in.h>
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/workqueue.h>
+#include <linux/kernel.h>
+#include <linux/inet.h>
+#include <linux/netdevice.h>
+#include <linux/ethtool.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <net/sock.h>
+#include <linux/if_ether.h>	/* For the statistics structure. */
+#include <linux/if_arp.h>	/* For ARPHRD_ETHER */
+#include <linux/autoconf.h>
+#include <linux/proc_fs.h>
+#include <linux/mii.h>
+#include <linux/delay.h>
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/io.h>
+#include <asm/cache.h>
+
+#include <asm/rmi/debug.h>
+#include <asm/rmi/pci.h>
+#include <asm/rmi/pic.h>
+#include <asm/rmi/phoenix_mac.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/atx_cpld.h>
+#include <asm/rmi/xgmac_mdio.h>
+#include <asm/rmi/proc.h>
+#include <asm/smp.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/gpio.h>
+#include <user/rmi/phnx_user_mac.h>
+#include <asm/rmi/linux_crf.h>
+
+#define DRV_NAME	"rmi_phnx_mac"
+#define DRV_VERSION	"0.1"
+/* #define DEBUG */
+
+#ifdef DEBUG
+#undef dbg_msg
+int mac_debug = 1;
+#define dbg_msg(fmt, args...) \
+        do {\
+            if (mac_debug) {\
+                printk("[%s@%d|%s]: cpu_%d: " fmt, \
+                __FILE__, __LINE__, __FUNCTION__,  smp_processor_id(), ##args);\
+            }\
+        } while(0);
+
+#define DUMP_PACKETS
+#else
+#undef dbg_msg
+#define dbg_msg(fmt, args...)
+int mac_debug = 0;
+#endif
+extern int xlr_loader_support;
+extern int xlr_loader_sharedcore;
+extern int xlr_loader_own_gmac;
+
+
+extern struct proc_dir_entry *rmi_root_proc;
+extern int xlsb0_in_xaui(int block);
+
+static struct net_device_ops rmi_mac_net_ops;
+
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+void dump_all_interface(unsigned int reg);
+void ( *p_ptp_set_ts) (u32 , u32, ktime_t *, u32);
+#endif
+/* 
+ *  Packet dump tools
+*/
+#define dump_packet(skb) \
+do \
+{ \
+	int i = 0; \
+	printk("%s: Packet: length=%d\n", __FUNCTION__, skb->len); \
+	for (i = 0; i < 64; i++) { \
+		printk("%02x ", skb->data[i]); \
+		if (i && (i % 16) == 0) \
+			printk("\n"); \
+	} \
+	printk("\n"); \
+} while (0)
+
+
+
+/*
+ * This macro returns non-zero if any of the upper buckets (4-7) is non-empty
+*/
+#define upper_buckets_nonempty() ((~msgrng_read_status() >> 28) & 0xf)
+
+
+extern __u32 cpu_to_frstid[];
+extern __u32 cpu_to_bktmask[];
+extern uint32_t hard_cpu_online_map;
+uint64_t free_back_stid_map = 0ULL;
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+
+/* XLR_NAPI global data strucutre */
+struct net_device xlr_napi_dummy_dev;  
+DEFINE_PER_CPU(struct napi_struct, xlr_napi_poll_struct);  
+EXPORT_SYMBOL(xlr_napi_dummy_dev);
+EXPORT_PER_CPU_SYMBOL(xlr_napi_poll_struct);
+
+/* XLR NAPI per CPU packet counter */
+DEFINE_PER_CPU(unsigned long long, xlr_napi_rx_count); 
+
+/* NAPI is disabled by default */
+int rmi_msgring_napi = 0; 
+int rmi_on_chip_napi = 0; 
+EXPORT_SYMBOL(rmi_on_chip_napi);
+int xlr_napi_ready = 0; 
+EXPORT_SYMBOL(xlr_napi_ready);
+static inline void rmi_phnx_free_skb(struct msgrng_msg *msg);
+
+struct napi_control_s 
+{
+  /* core-wide lock */
+  spinlock_t xlr_napi_msgrng_lock __attribute__((aligned(SMP_CACHE_BYTES)));
+
+  /* Mask tracking if NetRx SoftIRQ is scheduled on core's threads
+   *
+   * Only bits 0-3 are used:
+   *
+   *   i-th bit 0:  iff netrx SoftIRQ has been scheduled for thread i
+   *   i-th bit 1:  iff netrx SoftIRQ has NOT been scheduled for thread i
+  */
+  unsigned long netrx_mask;
+};
+
+__aligned(SMP_CACHE_BYTES) struct napi_control_s napi_control[NR_CPUS / 4];
+
+
+/* We need this little hack to improve handler speed */
+static int *rxstn_to_txstn_ptr;
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+
+
+#define MAC_B2B_IPG             88
+
+/* 
+ * Weight for GMAC/XGMAC NAPI polls. We override standard value of 300 
+ * to improve packet forwarding rate 
+*/
+#define XLR_NAPI_WEIGHT		1200
+static int napi_weight = XLR_NAPI_WEIGHT;
+
+
+/* 
+ * TCP stack termination in NAPI mode requires spill area for FreeOut's of 
+ * considerable size. We always set it to 15K descriptors which traslates into
+ * 15K * 8 bytes kernel memory alloc.
+*/
+#define XLR_FROUT_JUMBO_SPILL	(15 * 1024)
+
+
+/* NOTE:
+   Don't change this threshold to > 15 if MAX_NUM_DESC is 512. 
+   When msgring_thread_mask is 0xf, each cpu could receive 16 packets 
+   and replenishment may never happen.
+   THRESHOLD should be less than 
+   max_num_desc / (number of threads processing msgring * number of cores)
+   */
+#define MAC_FRIN_TO_BE_SENT_THRESHOLD max_frin_threshold
+#define MAC_FRIN_WORK_NUM 32
+
+/* Computed as described above */
+static int max_frin_threshold;
+
+/* Total Nr of Free Descriptors to GMACs > 2816 for Usermac 
+ * If configuring max_num_desc use at least 2816/4.
+ */
+
+static struct net_device *dev_mac[PHOENIX_MAX_MACS];
+struct net_device *dev_mac_type[MAX_NET_TYPES][PHOENIX_MAX_MACS];
+#define mac_addr_to_ptr(x) ((void *)(long)x)
+
+#define PHNX_NUM_REG_DUMP 9 /* Register 0xa0 to 0xa8 */
+#define PHNX_ETHTOOL_REG_LEN (PHNX_NUM_REG_DUMP * 4) 
+
+static void xlr_get_mac_stats(struct net_device *dev, 
+					struct net_device_stats *stats);
+
+/*
+ * New message assembly toolbox: newer, faster versions of messge send functions!
+ *
+ * NB: Please be advised that they require interrupts be off
+ *
+ * TODO: move them into msgring.h, if all goes well here
+*/
+static inline int 
+message_send_fast_1(unsigned int code, 
+                    unsigned int stid, 
+                    unsigned long long msg0)
+{
+	int ret, retry = 16;
+
+
+  	msgrng_load_tx_msg0(msg0);
+
+	__asm__ __volatile__ (".set push\n"
+	                      ".set noreorder\n"
+		              ".set mips64\n"
+		              "move $8, %1\n"
+		              "1: c2 0x80001\n"
+		              "mfc2 $8, "STR(MSGRNG_MSG_STATUS_REG)"\n"
+		              "andi $8, $8, 0x6\n"
+		              "beqz $8, 2f\n"
+			      "addi %2, -1\n"
+			      "bnez %2, 1b\n"
+		              "move $8, %1\n"
+			      "addiu $8, $0, 4\n"
+			      "2: move %0, $8\n"
+		              ".set pop\n"
+		              :"=r"(ret)
+		              : "r"((code<<8)|stid), "r"(retry)
+		              : "$8"
+		             );
+	return ret;
+}
+
+
+static inline int 
+message_send_fast_2(unsigned int code, 
+                    unsigned int stid, 
+                    unsigned long long msg0, 
+                    unsigned long long msg1)
+{
+	int ret, retry = 16;
+
+
+  	msgrng_load_tx_msg0(msg0);
+  	msgrng_load_tx_msg1(msg1);
+
+	__asm__ __volatile__ (".set push\n"
+	                      ".set noreorder\n"
+		              ".set mips64\n"
+		              "move $8, %1\n"
+		              "1: c2 0x80001\n"
+		              "mfc2 $8, "STR(MSGRNG_MSG_STATUS_REG)"\n"
+		              "andi $8, $8, 0x6\n"
+		              "beqz $8, 2f\n"
+			      "addi %2, -1\n"
+			      "bnez %2, 1b\n"
+		              "move $8, %1\n"
+			      "addiu $8, $0, 4\n"
+			      "2: move %0, $8\n"
+		              ".set pop\n"
+		              :"=r"(ret)
+		              : "r"((1<<16)|(code<<8)|stid), "r"(retry)
+		              : "$8"
+		             );
+	return ret;
+}
+
+
+#define message_receive_fast_1(bucket, size, code, stid, msg0)   \
+        ( { unsigned int _status=0, _tmp=0;                     \
+           msgrng_receive(bucket);                              \
+           while ( (_status=msgrng_read_status()) & 0x08) ;     \
+           _tmp = _status & 0x30;                               \
+           if (likely(!_tmp)) {                                 \
+                 (size)=((_status & 0xc0)>>6)+1;                \
+                 (code)=(_status & 0xff00)>>8;                  \
+                 (stid)=(_status & 0x7f0000)>>16;               \
+                 (msg0)=msgrng_load_rx_msg0();                  \
+                 _tmp=0;                                        \
+                }                                               \
+           _tmp;                                                \
+        } )
+
+
+static inline void prefetch_local(const void *addr)
+{
+	__asm__ __volatile__(
+	"	.set	mips4		\n"
+	"	pref	%0, (%1)	\n"
+	"	.set	mips0		\n"
+	:
+	: "i" (Pref_StoreStreamed), "r" (addr));
+}
+
+
+
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+/* skb transfer statistics */
+unsigned long long skb_transfer_stat[NR_CPUS][NR_CPUS];
+void skb_transfer_finish(void);
+static void skb_transfer(int bucket, struct sk_buff *skb);
+
+
+/* skb transfer queues, one per CPU */
+static struct sk_buff_head cpu_skb_tqueue[NR_CPUS];
+
+static void
+cpu_tx_queue_init(void)
+{
+  int i;
+
+  for (i = 0; i < NR_CPUS; i++)
+  {
+    skb_queue_head_init(&(cpu_skb_tqueue[i]));
+  }
+}
+
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
+
+/* This message ring interrupt type, can be adjusted by NAPI setup callback */
+extern int msgring_int_type;
+extern struct user_mac_data *user_mac;
+extern struct user_mac_kernal_data user_mac_krnl_data;
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+static int rmi_phnx_napi_setup(void);
+#endif
+
+#ifdef CONFIG_PHOENIX_HW_BUFFER_MGMT
+static int setup_auto_free(struct sk_buff *skb, int type, struct msgrng_msg *msg);
+#endif /* CONFIG_PHOENIX_HW_BUFFER_MGMT */
+
+/* global flag for automatic hardware buffer management, disabled by default */
+int rmi_auto_buffer_mgmt = 0;
+
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+void xlr_napi_rx_schedule(void);
+static int mac_frin_replenish_one_msg(struct net_device *dev);
+static int rmi_phnx_napi_mac_xmit(struct sk_buff *skb, struct net_device *dev);
+
+/*
+ * get_adjusted_bucket_index: returns index of the highest bit set incremented by 4
+ * 
+ * E.g.: get_adjusted_bucket_index(1) = 4
+ *       get_adjusted_bucket_index(2) = 5
+ *       get_adjusted_bucket_index(3) = 5
+ *
+*/
+static inline int
+get_adjusted_bucket_index(int word)
+{
+	__asm__ __volatile__ (".set push\n"
+	                      ".set noreorder\n"
+		              ".set mips64\n"
+			      "clz %0, %1\n"
+			      ".set pop\n"
+			      : "=r" (word) : "r" (word));
+	return 35 - word;
+}
+
+
+/*
+ * The following function checks if bucket/freeback allocation scheme is NAPI-compatible
+ *
+ * Returns 0 if napi compatibility fails and != 0 otherwise
+*/
+static int
+rmi_napi_compatibility_check(void)
+{
+	__u32 freeback, i;
+
+
+	printk("MSGRING_NAPI: HARD_CPU_ONLINE_MAP: 0x%08x\n", hard_cpu_online_map);
+
+	if (rmik_en) {
+		for (i = 0; i < NR_CPUS; i++) {
+			if ((hard_cpu_online_map & (1 << i)) == 0)
+				continue;
+			free_back_stid_map |= (1ULL << cpu_to_frstid[i]);
+		}
+
+		printk("MSGRING_NAPI: Incompatibility with CRF mode detected\n");
+		return 0;
+	}
+
+	for (i = 0; i < NR_CPUS; i++) {
+
+		if ((hard_cpu_online_map & (1 << i)) == 0) {
+			continue;
+		}
+
+		freeback = i / 4 * 8 + i % 4 + 4;
+
+		if (cpu_to_frstid[i] != freeback) {
+
+			printk("MSGRING_NAPI: Bucket allocation is not compatible with NAPI mode\n");
+			printk("MSGRING_NAPI: Conflict detected: thread %d, freeback %d\n", i, cpu_to_frstid[i]);
+			printk("MSGRING_NAPI: Expected freeback %d\n", freeback);
+
+			return 0;
+		}
+	}
+	return 1;
+}
+
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+
+/*****************************************************************
+ * Phoenix Generic Mac driver
+ *****************************************************************/
+
+typedef enum { phnx_mac_speed_10, phnx_mac_speed_100,
+	       phnx_mac_speed_1000, phnx_mac_speed_rsvd
+} phnx_mac_speed_t;
+
+typedef enum { phnx_mac_duplex_auto, phnx_mac_duplex_half,
+	       phnx_mac_duplex_full
+} phnx_mac_duplex_t;
+
+typedef enum { phnx_mac_fc_auto, phnx_mac_fc_disabled, phnx_mac_fc_frame,
+	       phnx_mac_fc_collision, phnx_mac_fc_carrier
+} phnx_mac_fc_t;
+
+/* These 2 structures are always indexed by "hard_smp_processor_id()" */
+static struct work_struct mac_frin_replenish_work[MAC_FRIN_WORK_NUM];
+static struct tasklet_struct mac_frin_replenish_task[MAC_FRIN_WORK_NUM];
+
+struct cpu_stat {
+	unsigned long tx_packets;
+	unsigned long txc_packets;
+	unsigned long rx_packets;
+	unsigned long interrupts;
+};
+
+struct phy_info {
+	int addr;
+	int mode;
+	phoenix_reg_t *mii_addr;
+	phoenix_reg_t *pcs_addr;
+	phoenix_reg_t *serdes_addr;
+};
+
+struct driver_data {
+
+	/* Let these be the first fields in this structure 
+	 * the structure is cacheline aligned when allocated in 
+	 * init_etherdev
+	 */
+	struct fr_desc *frin_spill;
+	struct fr_desc *frout_spill;
+	union rx_tx_desc *class_0_spill;
+	union rx_tx_desc *class_1_spill;
+	union rx_tx_desc *class_2_spill;
+	union rx_tx_desc *class_3_spill;
+
+	struct net_device *dev;	/* pointer to linux device */
+	struct timer_list link_timer;	/* for monitoring MII */
+	struct net_device_stats stats;
+	spinlock_t lock;
+
+	phoenix_reg_t *mmio;
+
+	__u8 hwaddr[6];
+	int phy_oldbmsr;
+	int phy_oldanlpar;
+	int phy_oldk1stsr;
+	int phy_oldlinkstat;
+	unsigned char phys_addr[2];
+
+	phnx_mac_speed_t speed;	/* current speed */
+	phnx_mac_duplex_t duplex;	/* current duplex */
+	phnx_mac_fc_t flow_ctrl;	/* current flow control setting */
+	int				advertising;
+
+	int id;
+	int type;
+	int instance;
+	uint32_t cfg_flag;
+
+	int spill_init;
+	int config_pde;
+	int num_desc;
+
+	struct phy_info phy;
+	
+	atomic_t frin_to_be_sent[MAC_FRIN_WORK_NUM];
+	int init_frin_desc;
+
+	struct cpu_stat cpu_stats[NR_CPUS];
+
+	int fr_stid;
+	int tx_stid;
+	int frstid_rsvd;
+};
+
+enum {
+	PORT_TX,
+	PORT_TX_COMPLETE,
+	PORT_STARTQ,
+	PORT_STOPQ,
+	PORT_START_DEV_STATE,
+	PORT_STOP_DEV_STATE,
+};
+
+#define port_inc_counter(port, counter) 	atomic_inc(&port_counters[port][(counter)])
+#define port_set_counter(port, counter, value) 	atomic_set(&port_counters[port][(counter)], (value))
+static atomic_t port_counters[8][8] __cacheline_aligned;
+static spinlock_t pending_tx_lock[PHOENIX_MAX_MACS] __cacheline_aligned;
+static volatile int pending_tx[PHOENIX_MAX_MACS] __cacheline_aligned;
+
+int mac_xmit(struct sk_buff *skb, struct net_device *dev,
+		    struct driver_data *priv, int txq);
+
+static __inline__ unsigned int rmi_ldadd_wu(unsigned int value, unsigned long *addr)
+{
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     ".set mips64\n"
+			     "move $8, %2\n" "move $9, %3\n"
+#ifdef CONFIG_64BIT
+			     //"ldadd $8, $9\n"
+			     ".dword 0x71280012\n"
+#else
+			     //"ldaddwu $8, $9\n"
+			     ".word 0x71280011\n"
+#endif
+			     "move %0, $8\n"
+			     ".set pop\n":"=&r"(value), "+m"(*addr)
+			     :"0"(value), "r"((unsigned long)addr)
+			     :"$8", "$9");
+	return value;
+}
+#define mac_stats_add(x, val) rmi_ldadd_wu(val, &x)
+
+void mac_stats_update(int pkts, struct sk_buff *skb)
+{
+	struct driver_data *priv;
+	priv = netdev_priv(skb->dev);
+	mac_stats_add(priv->stats.rx_packets, pkts);
+	mac_stats_add(priv->stats.rx_bytes, skb->len);
+}
+
+void rmi_phnx_mac_set_enable(struct driver_data *priv, int flag);
+static void phnx_mac_set_rx_mode(struct net_device *dev);
+void rmi_phnx_mac_msgring_handler(int bucket, int size, int code,
+				  int stid, struct msgrng_msg *msg,
+				  void *data);
+static irqreturn_t rmi_phnx_mac_int_handler(int irq, void *dev_id);
+static int rmi_phnx_mac_open(struct net_device *dev);
+static int rmi_phnx_mac_xmit(struct sk_buff *skb, struct net_device *dev);
+static int rmi_phnx_mac_close(struct net_device *dev);
+static void rmi_phnx_mac_timer(unsigned long data);
+static struct net_device_stats *rmi_phnx_mac_get_stats(struct net_device *dev);
+static void rmi_phnx_mac_set_multicast_list(struct net_device *dev);
+static int rmi_phnx_mac_do_ioctl(struct net_device *dev,
+				 struct ifreq *rq, int cmd);
+static void rmi_phnx_mac_tx_timeout(struct net_device *dev);
+static int rmi_phnx_mac_change_mtu(struct net_device *dev, int new_mtu);
+static int rmi_phnx_mac_fill_rxfr(struct net_device *dev);
+static void rmi_phnx_config_spill_area(struct driver_data *priv);
+static int mac_frin_replenish_one_msg(struct net_device *dev);
+
+
+
+#define MSGRING_PROCESS_FROUT_START_BUCKET 4
+#define MSGRING_PROCESS_FROUT_END_BUCKET 8
+#define MSGRING_PROCESS_FROUT_POP_BUCKET_MASK 0xf0
+void msgring_process_rx_msgs(int start_bucket, int end_bucket, __u32 pop_bucket_mask);
+
+
+
+/*****************************************************************
+ * Driver Helper Functions
+ *****************************************************************/
+
+static __inline__ struct sk_buff *mac_get_skb_back_ptr(unsigned long addr)
+{
+	unsigned long *back_ptr =
+		(unsigned long *)(addr - MAC_SKB_BACK_PTR_SIZE);
+	dbg_msg("addr = %lx,  skb = %lx\n", addr, *back_ptr);
+	/* this function should be used only for newly allocated packets. It assumes
+	 * the first cacheline is for the back pointer related book keeping info
+	 */
+	return (struct sk_buff *)(*back_ptr);
+}
+
+static __inline__ void mac_put_skb_back_ptr(struct sk_buff *skb)
+{
+	unsigned long *back_ptr = (unsigned long *)skb->data;
+
+	/* this function should be used only for newly allocated packets. It assumes
+	 * the first cacheline is for the back pointer related book keeping info
+	 */
+	skb_reserve(skb, MAC_SKB_BACK_PTR_SIZE);
+	*back_ptr = (unsigned long)skb;
+	dbg_msg("p=%p, skb=%p\n", back_ptr, skb);
+}
+
+#define CACHELINE_ALIGNED_ADDR(addr) (((unsigned long)(addr)) & ~(SMP_CACHE_BYTES-1))
+
+static __inline__ void *cacheline_aligned_kmalloc(int size, int gfp_mask)
+{
+	void *buf = kmalloc(size + SMP_CACHE_BYTES, gfp_mask);
+	if (buf)
+		buf =
+			(void
+			 *)(CACHELINE_ALIGNED_ADDR((unsigned long)buf +
+						   SMP_CACHE_BYTES));
+	return buf;
+}
+
+static __inline__ struct sk_buff *rmi_phnx_alloc_skb(void)
+{
+	int offset = 0;
+	struct sk_buff *skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE, GFP_KERNEL);
+
+	if (!skb) {
+		return NULL;
+	}
+
+	/* align the data to the next cache line */
+	offset = ((unsigned long)skb->data + SMP_CACHE_BYTES) &
+		~(SMP_CACHE_BYTES - 1);
+	skb_reserve(skb, (offset - (unsigned long)skb->data));
+
+	return skb;
+}
+
+/**********************************************************************
+ **********************************************************************/
+void rmi_phnx_mac_set_enable(struct driver_data *priv, int flag)
+{
+	uint32_t regval;
+	int tx_threshold = 512;
+
+	if(!(PORT_EN(priv->cfg_flag)))
+		return;
+
+
+	if (flag) {
+		regval = phoenix_read_reg(priv->mmio, R_TX_CONTROL);
+		regval &= ~(0x3fff);
+		regval |= (1 << O_TX_CONTROL__TxEnable) |
+			(tx_threshold << O_TX_CONTROL__TxThreshold);
+
+		phoenix_write_reg(priv->mmio, R_TX_CONTROL, regval);
+
+		regval = phoenix_read_reg(priv->mmio, R_RX_CONTROL);
+		regval |= 1 << O_RX_CONTROL__RxEnable;
+		if (priv->phy.serdes_addr != 0 && (priv->phy.mode & PHY_MODE_RGMII))
+			regval |= 1 << O_RX_CONTROL__RGMII;
+		phoenix_write_reg(priv->mmio, R_RX_CONTROL, regval);
+	} else {
+		regval = phoenix_read_reg(priv->mmio, R_TX_CONTROL);
+		regval &= ~((1 << O_TX_CONTROL__TxEnable) |
+			    (tx_threshold << O_TX_CONTROL__TxThreshold));
+
+		phoenix_write_reg(priv->mmio, R_TX_CONTROL, regval);
+
+		regval = phoenix_read_reg(priv->mmio, R_RX_CONTROL);
+		regval &= ~(1 << O_RX_CONTROL__RxEnable);
+		phoenix_write_reg(priv->mmio, R_RX_CONTROL, regval);
+	}
+}
+
+
+
+/**********************************************************************
+ **********************************************************************/
+static __inline__ int phnx_mac_send_fr(struct driver_data *priv,
+				       unsigned long addr, int len)
+{
+	int stid = 0;
+	struct msgrng_msg msg;
+
+ 	stid = priv->fr_stid;
+	msg.msg0 = (uint64_t)addr & 0xffffffffe0ULL;
+    	msg.msg1 = msg.msg2 = msg.msg3 = 0;
+
+	/* Send the packet to MAC */
+	dbg_msg("mac_%d: Sending free packet to stid %d\n",
+		                                  priv->instance, stid);
+	__sync();
+	if (priv->type == TYPE_XGMAC) {
+		while (message_send_fast_1(MSGRNG_CODE_XGMAC, stid, msg.msg0));
+	} else {
+		while (message_send_fast_1(MSGRNG_CODE_MAC, stid, msg.msg0));
+	}
+
+	/* Let the mac keep the free descriptor */
+	return 0;
+}
+
+
+
+
+
+/*
+ * Configure and send SKB to device free-in ring
+*/
+static int
+mac_frin_send_skb(struct net_device *dev, struct sk_buff *skb)
+{
+	int offset = 0;
+	unsigned long msgrng_flags = 0;
+	struct driver_data *priv;
+
+
+	priv = netdev_priv(dev);
+
+	/* align the data to the next cache line */
+	offset = (((unsigned long)skb->data + SMP_CACHE_BYTES) & ~(SMP_CACHE_BYTES - 1));
+	skb_reserve(skb, (offset - (unsigned long)skb->data));
+
+#ifdef CONFIG_PHOENIX_HW_BUFFER_MGMT
+	if (rmi_auto_buffer_mgmt) {
+		/* Put skb under automatic buffer management */
+		skb_shinfo(skb)->rmi_flags = 1;
+		skb_shinfo(skb)->rmi_owner = dev;
+		skb_shinfo(skb)->rmi_refill = mac_frin_replenish_one_msg;
+	} else {
+		skb_shinfo(skb)->rmi_flags = 0;
+		skb_shinfo(skb)->rmi_owner = NULL;
+		skb_shinfo(skb)->rmi_refill = NULL;
+	}
+#endif /* CONFIG_PHOENIX_HW_BUFFER_MGMT */
+
+	mac_put_skb_back_ptr(skb);
+	msgrng_access_enable(msgrng_flags);
+	if (phnx_mac_send_fr(priv, virt_to_bus(skb->data), skb->len)) {
+		dev_kfree_skb(skb);
+		printk("[%s]: rx free message_send failed!\n", __FUNCTION__);
+	}
+	msgrng_access_disable(msgrng_flags);
+
+	return 0; 
+}
+
+
+/*
+ * Allocates new SKB for a particular device and queues it
+ * up to the device Rx ring
+*/
+static int
+mac_frin_replenish_one_msg(struct net_device *dev)
+{
+	struct sk_buff *skb = 0;
+
+
+	if (!dev) {
+		return 0;
+	}
+
+	skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE, GFP_ATOMIC);
+	if (!skb) {
+		printk(KERN_ALERT "%s: can't alloc skb\n", __FUNCTION__);
+		return 0;
+	}
+	phnx_inc_counter(REPLENISH_FRIN);
+  
+	return mac_frin_send_skb(dev, skb); 
+}
+
+
+
+
+#ifdef CONFIG_PHOENIX_HW_BUFFER_MGMT
+/*
+ * This helper macro resets SKB data pointers for reuse
+ * as free-in buffer
+*/
+#define skb_reset_ptrs(skb) \
+do { \
+	struct skb_shared_info *shinfo; \
+	\
+	shinfo = skb_shinfo(skb); \
+	\
+	\
+	/* Now reinitialize old skb, cut & paste from dev_alloc_skb */ \
+	memset(skb, 0, offsetof(struct sk_buff, tail)); \
+	skb->data = skb->head;  \
+	skb_reset_tail_pointer(skb);\
+	\
+	atomic_set(&shinfo->dataref, 1); \
+	shinfo->nr_frags  = 0; \
+	shinfo->gso_size = 0; \
+	shinfo->gso_segs = 0; \
+	shinfo->gso_type = 0; \
+	shinfo->ip6_frag_id = 0; \
+	shinfo->frag_list = NULL; \
+} while (0)
+
+
+/*
+ * If we are in the HW buffer management case we handler frames with rx errors
+ * via this function
+*/
+static void 
+discard_rx_frame(struct net_device *dev, struct sk_buff *skb, int cpu)
+{
+	/* Reset all fields to 0, reset data pointers */
+	skb_reset_ptrs(skb);
+
+	mac_frin_send_skb(dev, skb); 
+}
+
+
+/*
+ *  Prepare SKB for automatic memory management operation (buffer recycling)
+ *
+ *  Return: 0 -- recycling is not possible
+ *          1 -- SKB set up for recycling successfully
+*/
+static int
+setup_auto_free(struct sk_buff *skb, int type, struct msgrng_msg *msg)
+{
+	struct driver_data *priv;
+	struct skb_shared_info *shinfo;
+	int fr_stid, offset;
+
+	shinfo = skb_shinfo(skb);
+	if (!shinfo->rmi_flags)
+		return 0;
+
+	if (atomic_read(&skb->users) != 1) {
+		printk(KERN_ALERT "%s: Can't recycle because of users count\n", __FUNCTION__);
+		return 0;
+	}
+
+	if (skb->cloned || atomic_read(&(skb_shinfo(skb)->dataref)) != 1) {
+		printk(KERN_EMERG "%s: Can't recycle because of cloned or dataref\n", __FUNCTION__);
+		return 0;
+	}
+
+	/* Leak no dsk entries! */
+	skb_dst_drop(skb);
+
+	/* Reset all fields to 0, reset data pointers */
+	skb_reset_ptrs(skb);
+
+	offset = (((unsigned long)skb->data + SMP_CACHE_BYTES) & ~(SMP_CACHE_BYTES - 1));
+	skb_reserve(skb, (offset - (unsigned long)skb->data));
+
+	priv = netdev_priv(skb_shinfo(skb)->rmi_owner);
+	fr_stid = priv->fr_stid;
+
+	mac_put_skb_back_ptr(skb);
+
+	msg->msg1 = ( ((uint64_t) 1 << 63) |
+		      ((uint64_t) fr_stid << 54) |
+		      ((uint64_t) 0 << 40) |
+		      ((uint64_t)virt_to_phys(skb->data) & 0xffffffffffULL)
+		    );
+	return 1;
+}
+
+#endif /* CONFIG_PHOENIX_HW_BUFFER_MGMT */
+
+
+
+/**************************************************************/
+
+static void xgmac_mdio_setup(volatile unsigned int *_mmio)
+{
+	int i;
+	uint32_t rd_data;
+
+	for (i = 0; i < 4; i++) {
+		rd_data = xmdio_read(_mmio, 1, 0x8000 + i);
+		rd_data = rd_data & 0xffffdfff;	// clear isolate bit
+		xmdio_write(_mmio, 1, 0x8000 + i, rd_data);
+	}
+}
+
+/**********************************************************************
+ *  Init MII interface
+ *  
+ *  Input parameters: 
+ *  	   s - priv structure
+ ********************************************************************* */
+#define PHY_STATUS_RETRIES 25000
+
+static void rmi_phnx_mac_mii_init(struct driver_data *priv)
+{
+    /* use the lowest clock divisor - divisor 28 */
+    phoenix_write_reg(priv->phy.mii_addr, R_MII_MGMT_CONFIG, 0x07);
+}
+
+/**********************************************************************
+ *  Read a PHY register.
+ *  
+ *  Input parameters: 
+ *  	   phyaddr - PHY's address
+ *  	   regidx = index of register to read
+ *  	   
+ *  Return value:
+ *  	   value read (16 bits), or 0xffffffff if an error occurred.
+ ********************************************************************* */
+static unsigned int rmi_phnx_mac_mii_read(phoenix_reg_t *mmio, int phyaddr, int regidx)
+{
+	int i;
+	/* setup the phy reg to be used */
+	phoenix_write_reg(mmio, R_MII_MGMT_ADDRESS,
+			  (phyaddr << 8) | (regidx << 0));
+
+	/* Issue the read command */
+	phoenix_write_reg(mmio, R_MII_MGMT_COMMAND,
+			  (1 << O_MII_MGMT_COMMAND__rstat));
+
+	/* poll for the read cycle to complete */
+	for (i = 0; i < PHY_STATUS_RETRIES; i++) {
+		if (phoenix_read_reg(mmio, R_MII_MGMT_INDICATORS) == 0)
+			break;
+	}
+
+	/* clear the read cycle */
+	phoenix_write_reg(mmio, R_MII_MGMT_COMMAND, 0);
+
+	if (i == PHY_STATUS_RETRIES) {
+		return 0xffffffff;
+	}
+
+	/* Read the data back */
+	return phoenix_read_reg(mmio, R_MII_MGMT_STATUS);
+}
+
+/**********************************************************************
+ *  Write a value to a PHY register.
+ *  
+ *  Input parameters: 
+ *  	   s - priv structure
+ *  	   phyaddr - PHY to use
+ *  	   regidx - register within the PHY
+ *  	   regval - data to write to register
+ *  	   
+ *  Return value:
+ *  	   nothing
+ ********************************************************************* */
+static void rmi_phnx_mac_mii_write(phoenix_reg_t *mmio, int phyaddr, int regidx, unsigned int regval)
+{
+	int i = 0;
+
+	phoenix_write_reg(mmio, R_MII_MGMT_ADDRESS,
+			  (phyaddr << 8) | (regidx << 0));
+
+	/* Write the data which starts the write cycle */
+	phoenix_write_reg(mmio, R_MII_MGMT_WRITE_DATA, regval);
+
+	/* poll for the write cycle to complete */
+	for (i = 0; i < PHY_STATUS_RETRIES; i++) {
+		if (phoenix_read_reg(mmio, R_MII_MGMT_INDICATORS) == 0)
+			break;
+	}
+
+	return;
+}
+
+
+/*****************************************************************
+ * Initialize GMAC
+ *****************************************************************/
+static void rmi_phnx_config_pde(struct driver_data *priv)
+{
+	int i = 0, cpu = 0, bucket = 0;
+	__u64 bucket_map = 0;
+
+	for (i = 0; i < 32; i++) {
+		if (cpu_isset(i, cpu_online_map)) {
+			cpu = cpu_logical_map(i);
+				bucket = ((cpu >> 2) << 3) | (cpu & 0x03);
+			bucket_map |= (1ULL << bucket);
+			dbg_msg("i=%d, cpu=%d, bucket = %d, bucket_map=%llx\n",
+				i, cpu, bucket, bucket_map);
+		}
+	}
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_0, (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_0 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_1, (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_1 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_2, (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_2 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_3, (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_3 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+}
+
+static void rmi_phnx_config_parser(struct driver_data *priv)
+{
+	/* Mark it as no classification 
+	 * The parser extract is gauranteed to be zero with no classfication
+	 */
+	phoenix_write_reg(priv->mmio, R_L2TYPE_0, 0x00);
+	
+}
+
+static void rmi_phnx_config_classifier(struct driver_data *priv)
+{
+	int i = 0;
+
+	if (priv->type == TYPE_XGMAC) {
+		/* xgmac translation table doesn't have sane values on reset */
+		for(i=0;i<64;i++)
+			phoenix_write_reg(priv->mmio, R_TRANSLATETABLE + i, 0x0);		
+
+		/* use upper 7 bits of the parser extract to index the translate
+		 * table
+		 */
+		phoenix_write_reg(priv->mmio, R_PARSERCONFIGREG, 0x0);
+	}
+}
+
+static void rmi_phnx_gmac_clr_pending_intr(struct driver_data *phy_priv)
+{
+	phoenix_reg_t *mmio = NULL;
+
+    if(!xlr_board_atx_vii())
+        return;
+
+    if(phy_priv->instance == 0){
+        /*All MDIO interrupts goes to mdio 0 - ack mac 0*/
+        mmio = phy_priv->mmio;
+	    phoenix_write_reg(mmio, R_INTREG, 0xffffffff);
+    }
+}
+
+static void rmi_phnx_gmac_config_speed(struct driver_data *priv)
+{
+	phoenix_reg_t *mmio = priv->mmio;
+	int id = priv->instance;
+
+	priv->speed = rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr, 28);
+	priv->speed = (priv->speed >> 3) & 0x03;
+
+	if (priv->speed == phnx_mac_speed_10) {
+		if (priv->phy.serdes_addr)
+			phoenix_write_reg(mmio, R_INTERFACE_CONTROL, SGMII_SPEED_10);
+		phoenix_write_reg(mmio, R_MAC_CONFIG_2, 0x7117);
+		phoenix_write_reg(mmio, R_CORECONTROL, 0x02);
+		printk("configuring gmac_%d in 10Mbps mode\n", id);
+	} else if (priv->speed == phnx_mac_speed_100) {
+		if (priv->phy.serdes_addr)
+			phoenix_write_reg(mmio, R_INTERFACE_CONTROL, SGMII_SPEED_100);
+		phoenix_write_reg(mmio, R_MAC_CONFIG_2, 0x7117);
+		phoenix_write_reg(mmio, R_CORECONTROL, 0x01);
+		printk("configuring gmac_%d in 100Mbps mode\n", id);
+	} else {
+		if (priv->phy.serdes_addr)
+			phoenix_write_reg(mmio, R_INTERFACE_CONTROL, SGMII_SPEED_1000);
+		if (priv->speed != phnx_mac_speed_1000) {
+			printk("gmac_%d phy reported unknown mac speed," 
+				" defaulting to 100Mbps mode\n",id);
+			phoenix_write_reg(mmio, R_MAC_CONFIG_2, 0x7117);
+			phoenix_write_reg(mmio, R_CORECONTROL, 0x01);
+		}else{
+			phoenix_write_reg(mmio, R_MAC_CONFIG_2, 0x7217);
+			phoenix_write_reg(mmio, R_CORECONTROL, 0x00);
+			printk("configuring gmac_%d in 1000Mbps mode\n", id);
+		}
+	}
+}
+
+/*****************************************************************
+ * Initialize XGMAC
+ *****************************************************************/
+static void rmi_phnx_xgmac_init(struct driver_data *priv, struct port_cfg *pcfg)
+{
+	int i = 0;
+	phoenix_reg_t *mmio = priv->mmio;
+	int id = priv->instance;
+	volatile unsigned short *cpld;
+	uint32_t rx_control;
+	bucket_t *bucket;
+	struct stn_cc *credit;
+
+	cpld = (volatile unsigned short *)(unsigned long)0xffffffffBD840000ULL;
+	phoenix_write_reg(priv->mmio, R_DESC_PACK_CTRL,
+			  (MAC_MAX_FRAME_SIZE << O_DESC_PACK_CTRL__RegularSize) | (4 << 20));
+	phoenix_write_reg(priv->mmio, R_BYTEOFFSET0, BYTE_OFFSET);
+
+	if(priv->config_pde) {
+	rmi_phnx_config_pde(priv);
+	rmi_phnx_config_parser(priv);
+	rmi_phnx_config_classifier(priv);
+	}
+
+	phoenix_write_reg(priv->mmio, R_MSG_TX_THRESHOLD, 1);
+
+	/* configure the XGMAC Registers */
+	phoenix_write_reg(mmio, R_XGMAC_CONFIG_1, 0x50000026);
+
+	/* configure the XGMAC_GLUE Registers */
+	phoenix_write_reg(mmio, R_DMACR0, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR1, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR2, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR3, 0xffffffff);
+	phoenix_write_reg(mmio, R_STATCTRL, 0x04);
+	phoenix_write_reg(mmio, R_L2ALLOCCTRL, 0xffffffff);
+
+	phoenix_write_reg(mmio, R_XGMACPADCALIBRATION, 0x030);
+	phoenix_write_reg(mmio, R_EGRESSFIFOCARVINGSLOTS, 0x0f);
+	phoenix_write_reg(mmio, R_L2ALLOCCTRL, 0xffffffff);
+	phoenix_write_reg(mmio, R_XGMAC_MIIM_CONFIG, 0x3e);
+
+	/* take XGMII phy out of reset 
+	 */
+	/* we are pulling everything out of reset because writing a 0 would
+	 * reset other devices on the chip
+	 */
+	cpld[ATX_CPLD_RESET_1] = 0xffff;
+	cpld[ATX_CPLD_MISC_CTRL] = 0xffff;
+	cpld[ATX_CPLD_RESET_2] = 0xffff;
+
+	xgmac_mdio_setup(mmio);
+
+	rmi_phnx_config_spill_area(priv);
+
+	bucket = pcfg->bucket;
+	credit = pcfg->credit;
+
+	if (id == 0) {
+		for (i = 0; i < 16; i++) {
+			phoenix_write_reg(mmio, R_XGS_TX0_BUCKET_SIZE + i,
+					  bucket[MSGRNG_STNID_XGS0_TX + i]);
+		}
+
+		phoenix_write_reg(mmio, R_XGS_RFR_BUCKET_SIZE,
+				  bucket[MSGRNG_STNID_XMAC0RFR]);
+
+	} else if (id == 1) {
+		for (i = 0; i < 16; i++) {
+			phoenix_write_reg(mmio, R_XGS_TX0_BUCKET_SIZE + i,
+					  bucket[MSGRNG_STNID_XGS1_TX + i]);
+		}
+
+		phoenix_write_reg(mmio, R_XGS_RFR_BUCKET_SIZE,
+				  bucket[MSGRNG_STNID_XMAC1RFR]);
+
+	}
+		for (i = 0; i < MAX_NUM_MSGRNG_STN_CC; i++) {
+			phoenix_write_reg(mmio, R_CC_CPU0_0 + i,
+				credit->counters[i >> 3][i & 0x07]);
+	}
+
+	priv->init_frin_desc = 1;
+
+    /* Clear the flagging of rx length check errors */
+    rx_control = phoenix_read_reg(mmio, R_RX_CONTROL);
+    rx_control &= ~(1 << 9);
+    phoenix_write_reg(mmio, R_RX_CONTROL, rx_control);
+}
+
+
+void sgmii_serdes_reset(void) 
+{
+	int i;
+	volatile unsigned int *mmio_gpio;
+	mmio_gpio = (unsigned int *)(phoenix_io_base + PHOENIX_IO_GPIO_OFFSET);
+
+	for (i=0;i<1000000;i++);
+
+	// use 125 Mhz instead of 156.25Mhz ref clock
+	if (!xlsb0_in_xaui(0)) {
+		mmio_gpio[0x10] = 0x7103;
+	}
+
+	if (!xlsb0_in_xaui(1)) {
+		mmio_gpio[0x21] = 0x7103;
+	}
+
+	for (i=0;i<1000000;i++);
+}
+
+
+
+static void serdes_regs_init(struct driver_data *priv) 
+{
+    int i;
+    volatile unsigned int *mmio_gpio;
+    mmio_gpio = (unsigned int *)(phoenix_io_base + PHOENIX_IO_GPIO_OFFSET);
+    /*
+       P Reg   Val
+       -------------
+       26 0     6DB0
+       26 1     0FFF
+       26 2     B6D0
+       26 3     00FF
+       26 4     0000
+       26 5     0000
+       26 6     0005
+       26 7     0001
+       26 8     0000
+       26 9     0000
+       26 10    0000
+     */
+    rmi_phnx_mac_mii_write (priv->phy.serdes_addr, 26, 0, 0x6DB0);
+    rmi_phnx_mac_mii_write (priv->phy.serdes_addr, 26, 1, 0xFFFF);  
+    rmi_phnx_mac_mii_write (priv->phy.serdes_addr, 26, 2, 0xB6D0);
+    rmi_phnx_mac_mii_write (priv->phy.serdes_addr, 26, 3, 0x00FF);
+    rmi_phnx_mac_mii_write (priv->phy.serdes_addr, 26, 4, 0x0000);
+    rmi_phnx_mac_mii_write (priv->phy.serdes_addr, 26, 5, 0x0000);
+    rmi_phnx_mac_mii_write (priv->phy.serdes_addr, 26, 6, 0x0005);
+    rmi_phnx_mac_mii_write (priv->phy.serdes_addr, 26, 7, 0x0001);
+    rmi_phnx_mac_mii_write (priv->phy.serdes_addr, 26, 8, 0x0000);
+    rmi_phnx_mac_mii_write (priv->phy.serdes_addr, 26, 9, 0x0000);
+    rmi_phnx_mac_mii_write (priv->phy.serdes_addr, 26,10, 0x0000);
+
+    for(i=0;i<10000000;i++){}
+
+    /* program  GPIO values for serdes init parameters */
+    mmio_gpio[0x20] = 0x7e6802;
+    mmio_gpio[0x10] = 0x7104;
+    for(i=0;i<100000000;i++){}
+
+    if (xlr_board_atx_xaui_rework())
+	    sgmii_serdes_reset();
+}
+
+static void serdes_autoconfig(struct driver_data *priv)
+{
+    int delay = 100;
+
+    /* Enable Auto negotiation in the PCS Layer*/
+    if ( (priv->instance == 0) || (priv->instance == 4)) {
+	rmi_phnx_mac_mii_write (priv->phy.pcs_addr, 27, 0, 0x1000);
+	mdelay(delay);
+	rmi_phnx_mac_mii_write (priv->phy.pcs_addr, 27, 0, 0x0200);
+	mdelay(delay);
+    }
+
+    if ( (priv->instance == 1) || (priv->instance == 5)) {
+	rmi_phnx_mac_mii_write (priv->phy.pcs_addr, 28, 0, 0x1000);
+	mdelay(delay);
+	rmi_phnx_mac_mii_write (priv->phy.pcs_addr, 28, 0, 0x0200);
+	mdelay(delay);
+    }
+
+    if ( (priv->instance == 2) || (priv->instance == 6)) {
+	rmi_phnx_mac_mii_write (priv->phy.pcs_addr, 29, 0, 0x1000);
+	mdelay(delay);
+	rmi_phnx_mac_mii_write (priv->phy.pcs_addr, 29, 0, 0x0200);
+	mdelay(delay);
+    }
+
+    if ( (priv->instance == 3) || (priv->instance == 7)) {
+	rmi_phnx_mac_mii_write (priv->phy.pcs_addr, 30, 0, 0x1000);
+	mdelay(delay);
+	rmi_phnx_mac_mii_write (priv->phy.pcs_addr, 30, 0, 0x0200);
+	mdelay(delay);
+    }
+
+    return;
+}
+
+void xaui_serdes_reset( void ) 
+{
+    int i;
+    volatile unsigned int *mmio_gpio;
+    mmio_gpio = (unsigned int *)(phoenix_io_base +
+            PHOENIX_IO_GPIO_OFFSET);
+
+    for (i=0;i<1000000;i++);
+
+    // disable serdes pll for both serdes
+    mmio_gpio[0x20] = 0x007e6804;
+    mmio_gpio[0x22] = 0x007e6804;
+    for (i=0;i<1000000;i++);
+
+    // use 156.25Mhz ref clock instead of 125Mhz
+    // ref clk
+    mmio_gpio[0x10] = 0x7104;
+    mmio_gpio[0x21] = 0x7104;
+    for (i=0;i<1000000;i++);
+
+    // re-enable serdes pll
+    mmio_gpio[0x20] = 0x007e6801;
+    mmio_gpio[0x22] =
+        0x007e6801;
+
+    for (i=0;i<1000000;i++);
+}
+
+
+static void rmi_phnx_xaui_init(struct driver_data *priv, struct port_cfg *pcfg)
+{
+	int i = 0;
+	phoenix_reg_t *mmio = priv->mmio;
+	__u32 value = 0;
+	bucket_t *bucket;
+	struct stn_cc *credit;
+
+    value = phoenix_read_reg(mmio, R_XGMAC_CONFIG_1);
+    phoenix_write_reg(mmio, R_XGMAC_CONFIG_1, (value | 0x50000020));
+    phoenix_write_reg(mmio, R_XGMAC_MAX_FRAME_LEN, 0x0A000A00);
+
+	rmi_phnx_config_spill_area(priv);
+
+	phoenix_write_reg(priv->mmio, R_DESC_PACK_CTRL,
+			  (BYTE_OFFSET << O_DESC_PACK_CTRL__ByteOffset) |
+			  (1 << O_DESC_PACK_CTRL__MaxEntry)| 
+			  (MAC_MAX_FRAME_SIZE << O_DESC_PACK_CTRL__RegularSize));
+   #ifdef CONFIG_PHOENIX_PTP_SUPPORT 
+   	phoenix_write_reg(priv->mmio, R_DESC_PACK_CTRL,
+                      phoenix_read_reg(priv->mmio, R_DESC_PACK_CTRL)|
+                      (1<< O_DESC_PACK_CTRL__PrePadEnable)); 
+   #endif
+
+	if(priv->config_pde) {
+	rmi_phnx_config_pde(priv);
+	rmi_phnx_config_parser(priv);
+	rmi_phnx_config_classifier(priv);
+	}
+
+    phoenix_write_reg(priv->mmio, R_MSG_TX_THRESHOLD, 3);
+
+    phoenix_write_reg(mmio,R_RX_CONTROL,(0x7<<6));
+
+	phoenix_write_reg(mmio, R_DMACR0, (7<<28)|(7<<24));
+	phoenix_write_reg(mmio, R_DMACR3,
+            (2<<21)|(2<<18)|(2<<15)|(2<<12)|(2<<9)|(2<<6)|(2<<3)|(2<<0));
+	phoenix_write_reg(mmio, R_L2ALLOCCTRL, 0xffffffff);
+	phoenix_write_reg(mmio, 0x221, (224 << 16));
+	phoenix_write_reg(mmio, R_STATCTRL, 0x04);
+	phoenix_write_reg(mmio, R_INTMASK, 0);
+	phoenix_write_reg(mmio, R_FREEQCARVE, 0);
+
+    priv->init_frin_desc = 1;
+    bucket = pcfg->bucket;
+	credit = pcfg->credit;
+
+	if(bucket != NULL) {
+			phoenix_write_reg(mmio, R_GMAC_RFR0_BUCKET_SIZE, bucket[1]);
+			phoenix_write_reg(mmio, R_GMAC_TX0_BUCKET_SIZE,  bucket[2]);
+			phoenix_write_reg(mmio, R_GMAC_TX1_BUCKET_SIZE,  bucket[3]);
+			phoenix_write_reg(mmio, R_GMAC_TX2_BUCKET_SIZE,  bucket[4]);
+			phoenix_write_reg(mmio, R_GMAC_TX3_BUCKET_SIZE,  bucket[5]);
+			phoenix_write_reg(mmio, R_GMAC_RFR1_BUCKET_SIZE, bucket[7]);
+	}
+
+	if(credit != NULL) {
+		for (i = 0; i < MAX_NUM_MSGRNG_STN_CC; i++) {
+			phoenix_write_reg(mmio, R_CC_CPU0_0 + i,
+					credit->counters[i >> 3][i & 0x07]);
+		}
+	}
+	return;
+}
+/*******************************************************
+ * Initialization gmac
+ *******************************************************/
+static void rmi_phnx_gmac_init(struct driver_data *priv, struct port_cfg *pcfg)
+{
+	int i = 0;
+	phoenix_reg_t *mmio = priv->mmio;
+	__u32 value = 0;
+	bucket_t *bucket;
+	struct stn_cc *credit;
+
+	rmi_phnx_config_spill_area(priv);
+
+	phoenix_write_reg(priv->mmio, R_DESC_PACK_CTRL,
+			  (BYTE_OFFSET << O_DESC_PACK_CTRL__ByteOffset) |
+			  (1 << O_DESC_PACK_CTRL__MaxEntry)| 
+			  (MAC_MAX_FRAME_SIZE << O_DESC_PACK_CTRL__RegularSize));
+   #ifdef CONFIG_PHOENIX_PTP_SUPPORT 
+   	phoenix_write_reg(priv->mmio, R_DESC_PACK_CTRL,
+                      phoenix_read_reg(priv->mmio, R_DESC_PACK_CTRL)|
+                      (1<< O_DESC_PACK_CTRL__PrePadEnable)); 
+   #endif
+
+	if(priv->config_pde) {
+	rmi_phnx_config_pde(priv);
+	rmi_phnx_config_parser(priv);
+	rmi_phnx_config_classifier(priv);
+	}
+
+	phoenix_write_reg(priv->mmio, R_MSG_TX_THRESHOLD, 3);
+
+	phoenix_write_reg(mmio, R_MAC_CONFIG_1, 0x35);
+
+          phoenix_write_reg(mmio,R_RX_CONTROL,(0x7<<6));
+
+	if (priv->phy.serdes_addr != 0 && (priv->phy.mode & PHY_MODE_RGMII)) {
+		value = phoenix_read_reg(priv->mmio, R_RX_CONTROL);
+		value |= 1 << O_RX_CONTROL__RGMII;
+		phoenix_write_reg(priv->mmio, R_RX_CONTROL, value);
+	}
+
+	rmi_phnx_mac_mii_init(priv);
+
+	priv->advertising = ADVERTISED_10baseT_Full | ADVERTISED_10baseT_Half | 
+			ADVERTISED_100baseT_Full | ADVERTISED_100baseT_Half |
+			ADVERTISED_1000baseT_Full | ADVERTISED_Autoneg |
+			ADVERTISED_MII;
+    
+	/*Clear pending mdio interrupt*/
+	rmi_phnx_gmac_clr_pending_intr(priv);
+    
+
+	/* Enable all MDIO interrupts in the phy 
+	 * RX_ER bit seems to be get set about every 1 sec in GigE mode,
+	 * ignore it for now...
+	 */
+	rmi_phnx_mac_mii_write(priv->phy.mii_addr, priv->phy.addr, 25, 0xfffffffe);
+	if(priv->phy.serdes_addr) {
+        serdes_regs_init(priv);
+        mdelay(10);
+        serdes_autoconfig(priv);
+    }
+	rmi_phnx_gmac_config_speed(priv);
+
+	value = phoenix_read_reg(mmio, R_IPG_IFG);
+	phoenix_write_reg(mmio, R_IPG_IFG, ((value & ~0x7f) | MAC_B2B_IPG));
+	phoenix_write_reg(mmio, R_DMACR0, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR1, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR2, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR3, 0xffffffff);
+	phoenix_write_reg(mmio, R_STATCTRL, 0x04);
+	phoenix_write_reg(mmio, R_L2ALLOCCTRL, 0xffffffff);
+	phoenix_write_reg(mmio, R_INTMASK, 0);
+	phoenix_write_reg(mmio, R_FREEQCARVE, 0);
+
+		priv->init_frin_desc = 1;
+	bucket = pcfg->bucket;
+	credit = pcfg->credit;
+
+	if(bucket != NULL) {
+			phoenix_write_reg(mmio, R_GMAC_RFR0_BUCKET_SIZE, bucket[1]);
+			phoenix_write_reg(mmio, R_GMAC_TX0_BUCKET_SIZE,  bucket[2]);
+			phoenix_write_reg(mmio, R_GMAC_TX1_BUCKET_SIZE,  bucket[3]);
+			phoenix_write_reg(mmio, R_GMAC_TX2_BUCKET_SIZE,  bucket[4]);
+			phoenix_write_reg(mmio, R_GMAC_TX3_BUCKET_SIZE,  bucket[5]);
+			phoenix_write_reg(mmio, R_GMAC_RFR1_BUCKET_SIZE, bucket[7]);
+	}
+
+	if(credit != NULL) {
+		for (i = 0; i < MAX_NUM_MSGRNG_STN_CC; i++) {
+			phoenix_write_reg(mmio, R_CC_CPU0_0 + i,
+					credit->counters[i >> 3][i & 0x07]);
+		}
+	}
+	return;
+}
+
+/**********************************************************************
+ * Set promiscuous mode
+ **********************************************************************/
+static void phnx_mac_set_rx_mode(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	uint32_t regval;
+
+	regval = phoenix_read_reg(priv->mmio, R_MAC_FILTER_CONFIG);
+
+	if (dev->flags & IFF_PROMISC) {
+		regval |= (1 << O_MAC_FILTER_CONFIG__BROADCAST_EN) |
+			(1 << O_MAC_FILTER_CONFIG__PAUSE_FRAME_EN) |
+			(1 << O_MAC_FILTER_CONFIG__ALL_MCAST_EN) |
+			(1 << O_MAC_FILTER_CONFIG__ALL_UCAST_EN);
+	} else {
+		regval &= ~((1 << O_MAC_FILTER_CONFIG__PAUSE_FRAME_EN) |
+			    (1 << O_MAC_FILTER_CONFIG__ALL_UCAST_EN));
+#ifdef PA10401_1_GMAC_PKT_DISCARD
+	  if (!is_xls()){
+                regval |= (1 << O_MAC_FILTER_CONFIG__ALL_MCAST_EN) |
+		          (1 << O_MAC_FILTER_CONFIG__ALL_UCAST_EN);
+          } 
+#endif
+	}
+
+	phoenix_write_reg(priv->mmio, R_MAC_FILTER_CONFIG, regval);
+}
+
+/**********************************************************************
+ *  Configure LAN speed for the specified MAC.
+ ********************************************************************* */
+static int rmi_phnx_mac_set_speed(struct driver_data *s, phnx_mac_speed_t speed)
+{
+	return 0;
+}
+
+/**********************************************************************
+ *  Set Ethernet duplex and flow control options for this MAC
+ ********************************************************************* */
+static int rmi_phnx_mac_set_duplex(struct driver_data *s,
+				   phnx_mac_duplex_t duplex, phnx_mac_fc_t fc)
+{
+	return 0;
+}
+
+/*****************************************************************
+ * Kernel Net Stack <-> MAC Driver Interface
+ *****************************************************************/
+/**********************************************************************
+ **********************************************************************/
+#define MAC_TX_PASS NETDEV_TX_OK
+#define MAC_TX_FAIL NETDEV_TX_BUSY
+
+static inline int phnx_netif_queue_tx(struct net_device *dev, 
+		struct sk_buff *skb, int txq)
+{
+	unsigned long flags, mflags;
+	int port = ((struct driver_data *)netdev_priv(dev))->id;
+	struct driver_data *priv = netdev_priv(dev);
+	int ret;
+
+	spin_lock_irqsave(&pending_tx_lock[port], flags);
+	/* try xmit once again. This should take care of the race b/w stopq 
+	   here and wakeup in tx complete 
+	   */
+
+	msgrng_access_enable(mflags);
+	ret = mac_xmit(skb, dev, priv, txq);
+	msgrng_access_disable(mflags);
+
+	if (ret == MAC_TX_PASS) {
+		mac_stats_add(priv->cpu_stats[txq].tx_packets, 1);
+		spin_unlock_irqrestore(&pending_tx_lock[port], flags);
+		return ret;
+	}
+	pending_tx[port]++;
+	netif_tx_stop_queue(netdev_get_tx_queue(dev, smp_processor_id()));
+	priv->stats.tx_dropped++;
+	ret = MAC_TX_FAIL;
+	spin_unlock_irqrestore(&pending_tx_lock[port], flags);
+	return ret;
+}
+
+static inline void phnx_netif_queue_tx_complete(struct net_device *dev)
+{
+	int port = ((struct driver_data *)netdev_priv(dev))->id;
+	struct driver_data *priv = netdev_priv(dev);
+	int end_port = 0;
+	if(port < PHOENIX_MAX_GMACS){
+		port = (port/4) * 4;
+		end_port = port + 4;
+		for(; port<end_port; port++){
+			if(pending_tx[port]) {
+				priv = netdev_priv(dev_mac[port]);
+				spin_lock(&pending_tx_lock[port]);
+				if(pending_tx[port]){
+					pending_tx[port] = 0;
+					/* is there a easy way to wake up only stopped queues ? */
+					netif_tx_wake_all_queues(dev);
+				}
+				spin_unlock(&pending_tx_lock[port]);
+			}
+		}
+	}else{
+		if(pending_tx[port]) {
+			spin_lock(&pending_tx_lock[port]);
+			if(pending_tx[port]){
+				pending_tx[port] = 0;
+				/* is there a easy way to wake up only stopped queues ? */
+				netif_tx_wake_all_queues(dev);
+			}
+			spin_unlock(&pending_tx_lock[port]);
+		}
+	}
+}
+
+
+
+static int mac_fill_tx_stid(int id, int type)
+{
+	int tx_stid;
+	if (type == TYPE_XGMAC) {
+		tx_stid = msgrng_xgmac_stid_tx(id);
+	} 
+	else {
+		tx_stid = msgrng_gmac_stid_tx(id);
+	}
+	return tx_stid;
+}
+
+
+static inline int mac_make_desc_b0_tx(struct msgrng_msg *msg, struct driver_data *priv,
+				      unsigned long addr, struct sk_buff *skb, unsigned long desc_id)
+{
+	int tx_stid = 0;
+	int fr_stid = 0;
+	int cpu = (phoenix_cpu_id() << 2) | phoenix_thr_id();
+	int len = skb->len;
+
+	fr_stid = cpu_to_frstid[cpu];
+	tx_stid = priv->tx_stid;
+
+
+	msg->msg0 = ( ((uint64_t)1 << 63) | 
+		      (((uint64_t)desc_id) << 54) | 
+		      ((uint64_t)len << 40) | 
+		      ((uint64_t)addr)
+		    );
+
+#ifdef CONFIG_PHOENIX_HW_BUFFER_MGMT
+        if (rmi_auto_buffer_mgmt && setup_auto_free(skb, priv->type, msg))
+		return tx_stid;
+	else 
+#endif /* CONFIG_PHOENIX_HW_BUFFER_MGMT */
+	{
+		msg->msg1 = ( ((uint64_t)1 << 63) |
+			      ((uint64_t)fr_stid << 54) |
+		      	      ((uint64_t)0 << 40) |
+#ifdef CONFIG_64BIT
+		              ((uint64_t)virt_to_phys(skb))
+#else
+		              ((unsigned long)(skb)&0xffffffffUL)
+#endif
+		            );
+	}
+		
+	msg->msg2 = msg->msg3 = 0;
+
+	return tx_stid;
+}
+
+int
+mac_xmit(struct sk_buff *skb, struct net_device *dev,
+		    struct driver_data *priv, int txq)
+{
+	struct msgrng_msg msg;
+	int stid = 0;
+	int cpu = (phoenix_cpu_id() << 2) | phoenix_thr_id();
+
+	if(cpu_to_bktmask[cpu] == 0) {
+		printk("Tx fail : No buckets are allocated for this cpu\n");
+		return MAC_TX_FAIL;
+	}
+#ifdef  CONFIG_PHOENIX_PTP_SUPPORT
+    if(skb->sk && sock_flag(skb->sk, SOCK_TIMESTAMP)) {
+           dbg_msg("transmit timestamp packet \n"); 
+       	   stid = mac_make_desc_b0_tx(&msg, priv, virt_to_phys(skb->data), skb, 126);
+        } else 
+#endif
+        {
+           	stid = mac_make_desc_b0_tx(&msg, priv, virt_to_phys(skb->data), skb, 127);
+        }
+       
+	__sync();
+
+	if (message_send_fast_2(MSGRNG_CODE_MAC, stid, msg.msg0, msg.msg1))
+		return MAC_TX_FAIL;
+
+	port_inc_counter(priv->instance, PORT_TX);
+
+	/* Send the packet to MAC */
+	dbg_msg("Sent tx packet to stid %d, msg0=%llx, msg1=%llx \n", stid, msg.msg0, msg.msg1);
+#ifdef DUMP_PACKETS
+	dump_packet(skb);
+#endif
+
+	phnx_inc_counter(NETIF_TX);
+
+	dev->trans_start = jiffies;
+
+	return MAC_TX_PASS;
+}
+
+
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+
+/* 
+ * NAPI poll function on upper four buckets 
+*/
+void
+xlr_napi_poll_upper(struct net_device *dummy_dev, int budget)
+{
+	struct msgrng_msg msg_body, *msg = &msg_body;
+	int bucket, stid = 0, length;
+	unsigned long mflags = 0;
+	unsigned int status;
+	int data_rx_bucket;
+	int size = 0, code = 0;
+	struct tx_stn_handler *handler;
+	int tx_stid, rcv_mask;
+#ifdef CONFIG_64BIT
+	unsigned long tmp;
+#endif /* CONFIG_64BIT */
+
+
+	data_rx_bucket = phoenix_thr_id() + 4;
+
+	msg_body.msg0 = 0; // Keep compiler happy
+	while (1) {
+
+		msgrng_access_enable(mflags);
+		if ((rcv_mask = (~msgrng_read_status() >> 28) & 0xf))
+			bucket = get_adjusted_bucket_index(rcv_mask);
+		else {
+			msgrng_access_disable(mflags);
+			break;
+		}
+
+		if (rmi_on_chip_napi) {
+			status = message_receive(bucket, &size, &code, &stid, msg);
+		}
+		else {
+			status = message_receive_fast_1(bucket, size, code, stid, msg_body.msg0);
+		}
+
+		msgrng_access_disable(mflags);
+
+		if (status) {
+			continue;
+		}
+
+		if (rmi_on_chip_napi) {
+			/* this block is a quick check for messages arriving from non GMAC/XGMAC stations */
+			tx_stid = rxstn_to_txstn_ptr[stid];
+			if (tx_stns[tx_stid].handler.action != rmi_phnx_mac_msgring_handler) {
+				handler = &tx_stns[tx_stid].handler;
+				if (handler->action) {
+					(handler->action)(bucket, size, code, stid, msg, handler->dev_id);
+				}
+				continue;
+			}
+		}
+
+		length = (msg->msg0 >> 40) & 0x3fff;
+
+		if (length) {
+			printk("%s: message with non-zero length from buckets 4-7\n", __FUNCTION__);
+			continue;
+		}
+
+		rmi_phnx_free_skb(msg);
+	} /* closing while (1) */
+}
+EXPORT_SYMBOL(xlr_napi_poll_upper);
+
+/* 
+ * NAPI poll function on lower four buckets 
+*/
+int
+napi_poll_lower(struct net_device *dummy_dev, int budget)
+{
+	struct msgrng_msg msg_body, *msg = &msg_body;
+	int stid = 0, length;
+	int port;
+	struct sk_buff *skb;
+	int received = 0;
+	unsigned int data_rx_bucket; 
+	unsigned long addr;
+	unsigned long mflags = 0;
+	unsigned int status;
+	int size = 0, code = 0;
+	int cpu = hard_smp_processor_id();
+	struct driver_data *priv;
+	unsigned int rxStatus;
+	struct tx_stn_handler *handler;
+	int tx_stid;
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+	unsigned char *prepad = NULL;
+#endif /* CONFIG_PHOENIX_PTP_SUPPORT */
+
+	data_rx_bucket = phoenix_thr_id();
+	msg_body.msg0 = 0;
+
+	while (1) {
+		msgrng_access_enable(mflags);
+
+		if  ((msgrng_read_status() >> (data_rx_bucket + 24)) & 0x1) {
+			msgrng_access_disable(mflags);
+			break;
+		}
+
+		if (rmi_on_chip_napi) {
+			status = message_receive(data_rx_bucket, &size, &code, &stid, msg);
+		}
+		else {
+			status = message_receive_fast_1(data_rx_bucket, size, code, stid, msg_body.msg0);
+		}
+
+		msgrng_access_disable(mflags);
+   
+		if (status) {
+			continue;
+		}
+
+		if (rmi_on_chip_napi) {
+			/* quick check for messages arriving from stations different from GMAC/XGMAC */
+			tx_stid = rxstn_to_txstn_ptr[stid];
+			if (tx_stns[tx_stid].handler.action != rmi_phnx_mac_msgring_handler) {
+				handler = &tx_stns[tx_stid].handler;
+				if (handler->action) {
+					(handler->action)(data_rx_bucket, size, code, stid, msg, handler->dev_id);
+				}
+				continue;
+			}
+		}
+
+		length = (msg->msg0 >> 40) & 0x3fff;
+		if (length == 0) {
+			printk("%s: message from data buckets with zero length...\n", __FUNCTION__);
+			continue;
+		}
+
+		/* we got a rx buffer with data from the MAC */
+		addr = (unsigned long) bus_to_virt(msg->msg0 & 0xffffffffe0ULL);
+		length = length  - BYTE_OFFSET -MAC_CRC_LEN - MAC_PREPAD;
+		port = msg->msg0 & 0x0f;
+		skb = mac_get_skb_back_ptr(addr);
+    
+		prefetch_local(skb->data);
+	    
+		if (is_xls()) {
+			if (stid == MSGRNG_STNID_GMAC0)
+				skb->dev = dev_mac_type[TYPE_GMAC][port];
+			else if (stid == MSGRNG_STNID_GMAC1)
+				skb->dev = dev_mac_type[TYPE_GMAC][4 + port];
+			else {
+				printk("[%s]: desc (0x%lx) for unknown station %d? dropping\n",
+									__FUNCTION__, addr, stid);
+				continue;
+			}
+		}
+		else {
+			if (stid == MSGRNG_STNID_XGS0FR)
+				skb->dev = dev_mac_type[TYPE_XGMAC][0];
+			else if (stid == MSGRNG_STNID_XGS1FR)
+				skb->dev = dev_mac_type[TYPE_XGMAC][1];
+			else
+				skb->dev = dev_mac_type[TYPE_GMAC][port];
+		}
+
+		priv = netdev_priv(skb->dev);
+   
+		if (msg->msg0 & (0x40ULL << 56))
+		{
+			rxStatus = (msg->msg0 >> 56 ) & 0x7f;
+			dbg_msg("Rx err 0x%x\n",rxStatus);
+			mac_stats_add(priv->stats.rx_errors,1);
+			if (rxStatus & 0x02)
+				mac_stats_add(priv->stats.rx_crc_errors,1);
+			if (rxStatus & 0x01)
+				mac_stats_add(priv->stats.rx_length_errors,1);
+
+			if (!rmi_auto_buffer_mgmt) {
+				mac_frin_replenish_one_msg(skb->dev);
+			}
+			dev_kfree_skb(skb);
+
+			continue;
+		}
+
+#ifdef PA10401_1_GMAC_PKT_DISCARD
+		if ((!is_xls()) && (!(skb->dev->flags & IFF_PROMISC))) {
+			if (!(msg->msg0 & (0x20ULL << 56))) {
+				if ((*(uint64_t *)(skb->data + MAC_PREPAD + BYTE_OFFSET)>>16) !=
+							   ((*(uint64_t *)skb->dev->dev_addr)>>16))
+				{
+					if (!rmi_auto_buffer_mgmt) {
+						mac_frin_replenish_one_msg(skb->dev);
+					}
+					dev_kfree_skb(skb);
+					continue;
+				}
+			}
+		}
+#endif
+
+       	skb_reserve(skb, MAC_PREPAD+BYTE_OFFSET );
+        
+		skb_put(skb, length);
+		skb->protocol = eth_type_trans(skb, skb->dev);
+// 1588
+    #ifdef CONFIG_PHOENIX_PTP_SUPPORT
+        prepad =(unsigned char *) addr; 
+        if(p_ptp_set_ts)
+            p_ptp_set_ts(*((unsigned int *) prepad), 
+                         *((unsigned int *) prepad + 1), 
+                         &skb->tstamp, 1); 
+    #endif
+        
+		mac_stats_add(priv->stats.rx_packets, 1);
+		mac_stats_add(priv->stats.rx_bytes, skb->len);
+		mac_stats_add(priv->cpu_stats[cpu].rx_packets, 1);
+
+		phnx_inc_counter(NETIF_RX);
+		phnx_set_counter(NETIF_RX_CYCLES, (read_c0_count() - msgrng_msg_cycles));
+
+		if (!rmi_auto_buffer_mgmt) {
+			mac_frin_replenish_one_msg(skb->dev);
+		}
+
+		skb->dev->last_rx = jiffies;
+		netif_receive_skb(skb);
+
+		__get_cpu_var(xlr_napi_rx_count)++; 
+
+		/* If number of received packets is exceeding poll weight we exit */
+		if (++received >= budget) {
+			break;
+		}
+	} /* end of while loop */
+
+	return received;
+}
+
+
+
+/*
+ *  Version of transmit used in conjunction with NAPI mode
+*/
+static int
+rmi_phnx_napi_mac_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	unsigned long mflags = 0;
+	int txq = hard_smp_processor_id();
+	int count = 0, ret;
+
+
+	phnx_inc_counter(NETIF_STACK_TX);
+
+	do {
+		msgrng_access_enable(mflags);
+
+		if (upper_buckets_nonempty()) {
+			msgrng_access_disable(mflags);
+			xlr_napi_poll_upper(dev, 0);
+			msgrng_access_enable(mflags);
+		}
+
+		ret = mac_xmit(skb, dev, priv, txq);
+		msgrng_access_disable(mflags);
+
+		if (ret == MAC_TX_PASS) {
+			mac_stats_add(priv->cpu_stats[txq].tx_packets, 1);
+			return ret;
+		}
+
+		count++;
+
+		if(count < 16)
+			continue;
+
+		ret = phnx_netif_queue_tx(dev, skb, txq);
+		break;
+
+	} while (1);
+	
+	if (ret == MAC_TX_FAIL) {
+		/* FULL */
+		dbg_msg("Msg Ring Full. Stopping upper layer Q\n");
+		port_inc_counter(priv->instance, PORT_STOPQ);
+	}
+
+	return ret;
+}
+
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+
+
+/*
+ * Version of transmit used in regular interrupt-driven mode
+*/
+static int
+rmi_phnx_mac_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	int ret = -ENOSPC;
+	unsigned long mflags = 0;
+	int txq = hard_smp_processor_id();
+	int count = 0;
+
+
+	phnx_inc_counter(NETIF_STACK_TX);
+
+	do {
+		msgrng_access_enable(mflags);
+		
+		if (priv->frstid_rsvd == 1 && upper_buckets_nonempty()) {
+
+			irq_enter();
+			msgring_process_rx_msgs(MSGRING_PROCESS_FROUT_START_BUCKET,
+						MSGRING_PROCESS_FROUT_END_BUCKET,
+						MSGRING_PROCESS_FROUT_POP_BUCKET_MASK);
+			irq_exit();
+		}
+		ret = mac_xmit(skb, dev, priv, txq);
+		msgrng_access_disable(mflags);
+
+		if (ret == MAC_TX_PASS) {
+			mac_stats_add(priv->cpu_stats[txq].tx_packets, 1);
+			break;
+		}
+
+		count++;
+
+		if(count < 16)
+			continue;
+
+		ret = phnx_netif_queue_tx(dev, skb, txq);
+		break;
+	} while (1);
+
+	return ret;
+}
+
+
+/* If allocation fails in the replenish tasklet, this function will replenish
+   the RX buffers from the workqueue context. Replenish tasklet is disabled
+   until this function is done with replenishment.
+   */
+static void mac_frin_replenish_wq(struct work_struct *args /* ignored */)
+{
+	int cpu = hard_smp_processor_id();
+	int done = 0;
+	int i = 0;
+
+	phnx_inc_counter(REPLENISH_ENTER);
+	//phnx_set_counter(REPLENISH_ENTER_COUNT, atomic_read(frin_to_be_sent));
+	phnx_set_counter(REPLENISH_CPU, hard_smp_processor_id());
+
+	for (;;) {
+
+		done = 0;
+
+		for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+			int offset = 0;
+			unsigned long msgrng_flags;
+			struct sk_buff *skb = 0;
+			__u32 cycles;
+			struct net_device *dev;
+			struct driver_data *priv;
+			atomic_t *frin_to_be_sent;
+
+			dev = dev_mac[i];
+			if (dev == 0)
+				goto skip;
+
+			priv = netdev_priv(dev);
+			frin_to_be_sent = &priv->frin_to_be_sent[cpu];
+
+			if(!(MSGRNG_OWN(priv->cfg_flag)))
+				goto skip;
+
+			if (atomic_read(frin_to_be_sent) < 0) {
+				panic
+					("BUG?: [%s]: gmac_%d illegal value for frin_to_be_sent=%d\n",
+					 __FUNCTION__, i,
+					 atomic_read(frin_to_be_sent));
+			}
+
+			if (!atomic_read(frin_to_be_sent))
+				goto skip;
+
+			cycles = read_c0_count();
+			{
+				skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE,
+					GFP_ATOMIC | __GFP_REPEAT |
+				       	__GFP_NOWARN);
+
+				if (!skb) {
+					skb =
+					__dev_alloc_skb(PHNX_RX_BUF_SIZE,
+								GFP_KERNEL);
+					if (!skb)
+						panic
+						("[%s]:Unable to allocate skb!\n",
+							 __FUNCTION__);
+				}
+			}
+			phnx_inc_counter(REPLENISH_FRIN);
+
+			/* align the data to the next cache line */
+			offset = (((unsigned long)skb->data + SMP_CACHE_BYTES) &
+				  ~(SMP_CACHE_BYTES - 1));
+			skb_reserve(skb, (offset - (unsigned long)skb->data));
+
+			//skb->dev = dev;
+
+			msgrng_access_enable(msgrng_flags);
+			mac_put_skb_back_ptr(skb);
+
+			if (phnx_mac_send_fr(priv, virt_to_bus(skb->data), skb->len)) {
+				dev_kfree_skb(skb);
+				printk("[%s]: rx free message_send failed!\n",
+				       __FUNCTION__);
+				break;
+			}
+			msgrng_access_disable(msgrng_flags);
+
+			phnx_set_counter(REPLENISH_CYCLES,
+					 (read_c0_count() - cycles));
+
+			atomic_dec(frin_to_be_sent);
+
+			continue;
+		skip:
+			done++;
+		}
+		if (done == PHOENIX_MAX_MACS)
+			break;
+	}
+	tasklet_enable(&mac_frin_replenish_task[cpu]);
+}
+
+
+static void mac_frin_replenish(unsigned long arg /* ignored */ )
+{
+	int cpu = hard_smp_processor_id();
+	int done = 0;
+	int i = 0;
+
+	phnx_inc_counter(REPLENISH_ENTER);
+	//phnx_set_counter(REPLENISH_ENTER_COUNT, atomic_read(frin_to_be_sent));
+	phnx_set_counter(REPLENISH_CPU, hard_smp_processor_id());
+
+	for (;;) {
+
+		done = 0;
+
+		for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+			int offset = 0;
+			unsigned long msgrng_flags;
+			struct sk_buff *skb = 0;
+			__u32 cycles;
+			struct net_device *dev;
+			struct driver_data *priv;
+			atomic_t *frin_to_be_sent;
+
+			dev = dev_mac[i];
+			if (dev == 0)
+				goto skip;
+
+			priv = netdev_priv(dev);
+			frin_to_be_sent = &priv->frin_to_be_sent[cpu];
+
+			if(!(MSGRNG_OWN(priv->cfg_flag)))
+				goto skip;
+
+			if (atomic_read(frin_to_be_sent) < 0) {
+				panic
+					("BUG?: [%s]: gmac_%d illegal value for frin_to_be_sent=%d\n",
+					 __FUNCTION__, i,
+					 atomic_read(frin_to_be_sent));
+			}
+
+			if (!atomic_read(frin_to_be_sent))
+				goto skip;
+
+			cycles = read_c0_count();
+			{
+				skb =
+					__dev_alloc_skb(PHNX_RX_BUF_SIZE,
+							GFP_ATOMIC | __GFP_REPEAT |
+							__GFP_NOWARN);
+				if (!skb) {
+					tasklet_disable_nosync
+					(&mac_frin_replenish_task[cpu]);
+					schedule_work
+					(&mac_frin_replenish_work[cpu]);
+					return;
+				}
+			}
+			phnx_inc_counter(REPLENISH_FRIN);
+
+			/* align the data to the next cache line */
+			offset = (((unsigned long)skb->data + SMP_CACHE_BYTES) &
+				  ~(SMP_CACHE_BYTES - 1));
+			skb_reserve(skb, (offset - (unsigned long)skb->data));
+
+			//skb->dev = dev;
+
+			msgrng_access_enable(msgrng_flags);
+			mac_put_skb_back_ptr(skb);
+
+			if (phnx_mac_send_fr(priv, virt_to_bus(skb->data), skb->len)) {
+				dev_kfree_skb(skb);
+				printk("[%s]: rx free message_send failed!\n",
+				       __FUNCTION__);
+				break;
+			}
+			msgrng_access_disable(msgrng_flags);
+
+			phnx_set_counter(REPLENISH_CYCLES,
+					 (read_c0_count() - cycles));
+
+			atomic_dec(frin_to_be_sent);
+
+			continue;
+		skip:
+			done++;
+		}
+		if (done == PHOENIX_MAX_MACS)
+			break;
+	}
+}
+
+/*
+ * Send a packet back to the station
+ */
+void rmi_phnx_drop_message_unowned(int fbid, uint64_t physaddr, int cop_en)
+{
+	struct msgrng_msg msg;
+	unsigned long msgrng_flags = 0;
+
+	/*printk(" rmi_phnx_drop_message_unowned fbid = %d physaddr=%llx\n",
+			fbid, physaddr); */
+
+	if(cop_en)
+		msgrng_access_enable(msgrng_flags);
+
+	msg.msg0 =
+		((u64) CTRL_REG_FREE << 61) | ((u64) fbid << 52) | (u64) physaddr;
+	msg.msg1 = msg.msg2 = msg.msg3 = 0;
+	while (message_send(1, MSGRNG_CODE_MAC, fbid, &msg)) ;
+
+	if(cop_en)
+		msgrng_access_disable(msgrng_flags);
+}
+
+
+
+
+static inline void rmi_phnx_free_skb(struct msgrng_msg *msg)
+{
+	struct sk_buff *skb;
+	struct driver_data *priv;
+	int cpu = hard_smp_processor_id();
+	#ifdef CONFIG_64BIT
+	unsigned long tmp;
+	tmp = (unsigned long)(msg->msg0 & 0xffffffffffULL);
+	skb = (struct sk_buff *)phys_to_virt(tmp);
+	#else
+	skb = (struct sk_buff *)(unsigned long)msg->msg0;
+	#endif
+	/* Tx Complete */
+	phnx_inc_counter(NETIF_TX_COMPLETE);
+
+	dbg_msg("skb = %p\n", skb);
+	/* release the skb and update statistics outside the spinlock */
+	priv = netdev_priv(skb->dev);
+	mac_stats_add(priv->stats.tx_packets, 1);
+	mac_stats_add(priv->stats.tx_bytes, skb->len);
+	mac_stats_add(priv->cpu_stats[cpu].txc_packets, 1);
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+        if(skb->sk) {
+        	if (sock_flag(skb->sk, SOCK_TIMESTAMP)) {
+//               dump_all_interface(0x75); 
+              if(p_ptp_set_ts) {
+                   
+                    p_ptp_set_ts(phoenix_read_reg(priv->mmio, 0x76), 
+                                   phoenix_read_reg(priv->mmio, 0x75), NULL, 1); 
+                }
+            }
+        }
+#endif
+
+
+	port_inc_counter(priv->instance, PORT_TX_COMPLETE);
+	phnx_netif_queue_tx_complete(skb->dev);
+
+	phnx_set_counter(NETIF_TX_COMPLETE_CYCLES,
+		(read_c0_count() - msgrng_msg_cycles));
+	dev_kfree_skb_any(skb);
+}
+
+
+/*
+ * Send a packet back to ipsec rmios
+ */
+static void ipsec_drop_packet(IPSEC_PACKET * pbuf)
+{
+	int stid=0;
+	u32 addr;
+	struct msgrng_msg msg;
+        if (is_xls()) {
+            if (pbuf->src_id == MSGRNG_STNID_GMAC0)
+		stid = MSGRNG_STNID_GMAC0_FR;
+            else if (pbuf->src_id == MSGRNG_STNID_GMAC1)
+		stid = MSGRNG_STNID_GMAC1_FR;
+            else {
+                printk("[%s]: rx packet (0x%p) for unknown station %d? dropping packet\n",
+                       __FUNCTION__, pbuf, stid);
+                return;
+	    }
+        }
+        else {
+	    if (pbuf->src_id == MSGRNG_STNID_XGS0FR)
+		stid = MSGRNG_STNID_XMAC0RFR;
+	    else if (pbuf->src_id == MSGRNG_STNID_XGS1FR)
+		stid = MSGRNG_STNID_XMAC1RFR;
+	    else
+		stid = MSGRNG_STNID_GMACRFR_0;
+        }
+	addr = virt_to_phys(pbuf->packet_data + SKBUF_HEAD);
+	msg.msg0 =
+		((u64) CTRL_REG_FREE << 61) | ((u64) stid << 52) | (u64) addr;
+	msg.msg1 = msg.msg2 = msg.msg3 = 0;
+	while (message_send(1, MSGRNG_CODE_MAC, stid, &msg)) ;
+}
+
+/*
+ * Receive a packet from rmios ipsec. This function is called by the message
+ * ring driver when the message source is a CPU and the message code indicates
+ * a packet from rmios. The message ring driver can also receive a fifo message
+ * from a CPU sending an event or response to a user space process.
+ */
+void rmi_phnx_rmios_msgring_handler(int bucket, int size, int code,
+				    int stid, struct msgrng_msg *msg,
+				    void *data /* ignored */ )
+{
+	unsigned long addr;
+	__u32 length;
+	int port;
+	struct sk_buff *skb;
+	struct driver_data *priv;
+	IPSEC_PACKET *ipsec_packet;
+	/*
+	 * Find the ipsec packet
+	 */
+	addr = (unsigned long)bus_to_virt(msg->msg0 & 0xffffffffe0ULL);
+	ipsec_packet = (IPSEC_PACKET *) (addr - SKBUF_HEAD -
+					 offsetof(IPSEC_PACKET, packet_data));
+	/*
+	 * Do nothing during the boot.
+	 */
+	if (system_state != SYSTEM_RUNNING) {
+		ipsec_drop_packet(ipsec_packet);
+		return;
+	}
+	/*
+	 * Allocate an skbuff, initialize it, and copy the data to it.
+	 */
+	length =
+		((msg->msg0 >> 40) & 0x3fff) - BYTE_OFFSET - MAC_CRC_LEN -MAC_PREPAD;
+	skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE, GFP_ATOMIC);
+	if (!skb) {
+		printk("[%s] - no skbuff\n", __FUNCTION__);
+		ipsec_drop_packet(ipsec_packet);
+		return;
+	}
+	port = code >> 4;
+	skb->dev = dev_mac_type[TYPE_GMAC][port];
+	skb_put(skb, length);
+	memcpy(skb->data, (char *)addr + 2, length);
+	ipsec_drop_packet(ipsec_packet);
+	skb->protocol = eth_type_trans(skb, skb->dev);
+	/*
+	 * Increment the driver stats counters.
+	 */
+	priv = netdev_priv(skb->dev);
+	mac_stats_add(priv->stats.rx_packets, 1);
+	mac_stats_add(priv->stats.rx_bytes, skb->len);
+	/*
+	 * Queue the packet to the upper layer.
+	 */
+	skb->dev->last_rx = jiffies;
+	netif_rx(skb);
+}
+
+
+
+/* This function is called from an interrupt handler */
+void rmi_phnx_mac_msgring_handler(int bucket, int size, int code,
+				  int stid, struct msgrng_msg *msg,
+				  void *data /* ignored */ )
+{
+#ifndef CONFIG_PHOENIX_HW_BUFFER_MGMT
+/* 
+ * Special helper macro to handle Rx errors within this interrupt handler
+ * macro is used locally in this function only
+ *
+ * NB: the alternative case when HW buffer management is on is handled by a 
+ * larger function defined above
+*/
+#define discard_rx_frame(dev, skb, cpu) \
+do { \
+	if (atomic_inc_return(&priv->frin_to_be_sent[cpu]) > \
+				MAC_FRIN_TO_BE_SENT_THRESHOLD) { \
+		tasklet_schedule(&mac_frin_replenish_task[cpu]); \
+	} \
+	dev_kfree_skb_irq(skb); \
+} while (0)
+
+#endif /* !CONFIG_PHOENIX_HW_BUFFER_MGMT */
+
+	unsigned long addr = 0;
+	__u32 length = 0;
+	int ctrl = 0, port = 0;
+	struct sk_buff *skb = 0;
+	int cpu = hard_smp_processor_id();
+
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+	unsigned char *prepad = NULL;
+#endif /* CONFIG_PHOENIX_PTP_SUPPORT */
+
+	dbg_msg("mac: bucket=%d, size=%d, code=%d, stid=%d, msg0=%llx msg1=%llx\n",
+		 bucket, size, code, stid, msg->msg0, msg->msg1);
+
+	addr = (unsigned long)bus_to_virt(msg->msg0 & 0xffffffffe0ULL);
+	length = (msg->msg0 >> 40) & 0x3fff;
+	if (length == 0) {
+		ctrl = CTRL_REG_FREE;
+		port = (msg->msg0 >> 54) & 0x0f;
+	}
+	else {
+		ctrl = CTRL_SNGL;
+		length = length - BYTE_OFFSET - MAC_CRC_LEN - MAC_PREPAD;
+		port = msg->msg0 & 0x0f;
+	}
+
+	dbg_msg("msg0 = %llx, msg1 = %llx, stid = %d, port = %d, addr=%lx, length=%d, ctrl=%d\n", 
+		msg->msg0, msg->msg1, stid, port, addr, length, ctrl);
+
+	if (ctrl == CTRL_REG_FREE) {
+		/* free the message , freeback should be the 
+			packets send by linux */
+		rmi_phnx_free_skb(msg);
+
+	} else if (ctrl == CTRL_SNGL || ctrl == CTRL_START) {
+		/* Rx Packet */
+
+		struct driver_data *priv = 0;
+                unsigned int rxStatus=0;
+
+		dbg_msg("Received packet, port = %d\n", port);
+
+		skb = mac_get_skb_back_ptr(addr);
+		if (!skb) {
+			printk("[%s]: rx desc (0x%lx) for unknown skb? dropping packet\n", 
+                                                                                __FUNCTION__, addr);
+			return;
+		}
+		
+		if (is_xls()) {
+			if (stid == MSGRNG_STNID_GMAC0)
+				skb->dev = dev_mac_type[TYPE_GMAC][port];
+			else if (stid == MSGRNG_STNID_GMAC1)
+				skb->dev = dev_mac_type[TYPE_GMAC][4 + port];
+			else {
+				printk("[%s]: rx desc (0x%lx) for unknown station %d? dropping packet\n",
+					__FUNCTION__, addr, stid);
+				return;
+			}
+		}
+		else {
+			if (stid == MSGRNG_STNID_XGS0FR)
+				skb->dev = dev_mac_type[TYPE_XGMAC][0];
+			else if (stid == MSGRNG_STNID_XGS1FR)
+				skb->dev = dev_mac_type[TYPE_XGMAC][1];
+			else
+				skb->dev = dev_mac_type[TYPE_GMAC][port];
+		}
+		
+		priv = netdev_priv(skb->dev);
+                
+                rxStatus = (msg->msg0 >> 56 ) & 0x7f;
+                if (rxStatus & 0x40)
+                {
+                  dbg_msg("Rx err 0x%x\n",rxStatus);
+                  mac_stats_add(priv->stats.rx_errors,1);
+                  if (rxStatus & 0x02)
+                    mac_stats_add(priv->stats.rx_crc_errors,1);
+                  if (rxStatus & 0x01)
+                    mac_stats_add(priv->stats.rx_length_errors,1);
+
+                  discard_rx_frame(skb->dev, skb, cpu);
+                  return;
+                }
+
+#ifdef PA10401_1_GMAC_PKT_DISCARD
+               if ((!is_xls()) && (!(skb->dev->flags & IFF_PROMISC)))
+                {
+                  if (!(rxStatus & 0x20))
+                  {
+                    if ((*(uint64_t *)(skb->data+MAC_PREPAD + BYTE_OFFSET)>>16) !=
+                     ((*(uint64_t *)skb->dev->dev_addr)>>16))
+                     {
+		      discard_rx_frame(skb->dev, skb, cpu);
+                      return;
+                     }
+                  }
+               }
+#endif
+
+		/* if num frins to be sent exceeds threshold, wake up the helper thread */
+		if (!rmi_auto_buffer_mgmt && 
+			     atomic_inc_return(&priv->frin_to_be_sent[cpu]) > MAC_FRIN_TO_BE_SENT_THRESHOLD) {
+			tasklet_schedule(&mac_frin_replenish_task[cpu]);
+		}
+
+#ifdef DUMP_PACKETS
+		dump_packet(skb);
+#endif /* DUMP_PACKETS */
+
+		/* compensate for the prepend data, byte offset */
+		skb_reserve(skb, MAC_PREPAD + BYTE_OFFSET);
+
+		skb_put(skb, length);
+		skb->protocol = eth_type_trans(skb, skb->dev);
+                
+		dbg_msg("gmac_%d: rx packet: addr = %lx, length = %x, protocol=%d\n",
+			 priv->instance, addr, length, skb->protocol);
+
+		mac_stats_add(priv->stats.rx_packets, 1);
+		mac_stats_add(priv->stats.rx_bytes, skb->len);
+		mac_stats_add(priv->cpu_stats[cpu].rx_packets, 1);
+
+    #ifdef CONFIG_PHOENIX_PTP_SUPPORT
+        prepad =(unsigned char *) addr; 
+        if(p_ptp_set_ts)
+            p_ptp_set_ts(*((unsigned int *) prepad), 
+                         *((unsigned int *) prepad + 1), 
+                         &skb->tstamp, 1); 
+    #endif
+ 
+		phnx_inc_counter(NETIF_RX);
+		phnx_set_counter(NETIF_RX_CYCLES, (read_c0_count() - msgrng_msg_cycles));
+
+#ifdef CONFIG_PHOENIX_IP_QUEUE_AFFINITY
+		/* 
+                 * We pass bucket number in the last field of skb->cb[] structure 
+                 * it might be later picked up by multiprocess ip_queue
+                */
+                skb->cb[sizeof(skb->cb) - 1] = bucket;
+#endif /* CONFIG_PHOENIX_IP_QUEUE_AFFINITY */
+
+
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+		skb_transfer(bucket, skb);
+#else
+		skb->dev->last_rx = jiffies;
+		netif_rx(skb);
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
+	} else {
+		printk("[%s]: unrecognized ctrl=%d!\n", __FUNCTION__, ctrl);
+	}
+}
+
+/* message ring handler where mac is owned by apps not linux */
+void rmi_phnx_station_unowned_msgring_handler(int bucket, int size, int code,
+				    int stid, struct msgrng_msg *msg,
+				    void *data /* ignored */ )
+{
+	unsigned long addr;
+	__u32 length;
+	int port;
+	struct sk_buff *skb = NULL;
+	struct driver_data *priv;
+	int fbstid = 0x0;
+
+	addr = (unsigned long)bus_to_virt(msg->msg0 & 0xffffffffe0ULL);
+	port = ((msg->msg0)  & 0x0f);
+	length = ((msg->msg0 >> 40) & 0x3fff);
+
+	/* printk("[%s] : port=%d length=%d\n", __FUNCTION__, port, length); */
+
+	/* free back should be the packets send by linux */
+	if(length == 0x0)  {
+		/* free the message , freeback should be the 
+			packets send by linux */
+		rmi_phnx_free_skb(msg);
+		return;
+	}
+
+
+	/*
+	 * Allocate an skbuff, initialize it, and copy the data to it.
+	 */
+	skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE, GFP_ATOMIC);
+	if (!skb) {
+		printk("[%s] - no skbuff\n", __FUNCTION__);
+		goto err_exit;
+	}
+
+	if (is_xls()) {
+		if (stid == MSGRNG_STNID_GMAC0) {
+			skb->dev = dev_mac_type[TYPE_GMAC][port];
+			fbstid = MSGRNG_STNID_GMAC0_FR;
+		} else if (stid == MSGRNG_STNID_GMAC1) {
+			skb->dev = dev_mac_type[TYPE_GMAC][4 + port];
+			fbstid = MSGRNG_STNID_GMAC1_FR;
+		} else {
+			printk("[%s]: rx desc (0x%lx) for unknown station %d? dropping packet\n",
+				__FUNCTION__, addr, stid);
+			goto err_exit;
+		}
+	} else {
+		if (stid == MSGRNG_STNID_XGS0FR) {
+			skb->dev = dev_mac_type[TYPE_XGMAC][0];
+			fbstid = MSGRNG_STNID_XMAC0RFR;
+		} else if (stid == MSGRNG_STNID_XGS1FR) {
+			skb->dev = dev_mac_type[TYPE_XGMAC][1];
+			fbstid = MSGRNG_STNID_XMAC1RFR;
+		} else {
+			skb->dev = dev_mac_type[TYPE_GMAC][port];
+			fbstid = MSGRNG_STNID_GMACRFR_0;
+		}
+	}
+
+#if 0
+	printk("rmi_phnx_station_unowned_msgring_handler ingress port=%d stid=%d\n", port, stid);
+#endif
+	if(skb->dev == 0) {
+		printk("[%s] - no dev\n", __FUNCTION__);
+		goto err_exit;
+	}
+	
+	length = length - (BYTE_OFFSET + MAC_CRC_LEN);
+	skb_put(skb, length);
+	memcpy(skb->data, (char *)addr + 2, length);
+	
+	if(rmik_queue_pkt_mem(fbstid, msg->msg0 & 0xffffffffe0ULL) < 0)
+		rmi_phnx_drop_message_unowned(fbstid, msg->msg0 & 0xffffffffe0ULL, 1);
+
+#if 0
+		{
+			int i = 0;
+			printk("Rx Packet: length=%d\n", length);
+			for (i = 0; i < 64; i++) {
+				printk("%02x ", skb->data[i]);
+				if (i && (i % 16) == 0)
+					printk("\n");
+			}
+			printk("\n");
+		}
+#endif
+
+	skb->protocol = eth_type_trans(skb, skb->dev);
+	/*
+	 * Increment the driver stats counters.
+	 */
+	priv = netdev_priv(skb->dev);
+	mac_stats_add(priv->stats.rx_packets, 1);
+	mac_stats_add(priv->stats.rx_bytes, skb->len);
+	/*
+	 * Queue the packet to the upper layer.
+	 */
+	skb->dev->last_rx = jiffies;
+	netif_rx(skb);
+	return;
+
+	err_exit:
+		rmi_phnx_drop_message_unowned(fbstid, msg->msg0 & 0xffffffffe0ULL, 1);
+		if(skb)
+			kfree_skb(skb);
+		return;
+
+}
+
+
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+extern void core_send_ipi(int cpu, unsigned int action);
+
+static void
+skb_transfer(int bucket, struct sk_buff *skb)
+{
+  u_long my_cpu_no, my_thread_no, my_core_no, target_cpu_no, target_thread_no;
+
+
+  target_thread_no = bucket & 0x3;
+  my_cpu_no = smp_processor_id();
+  my_thread_no = phoenix_thr_id();
+  my_core_no = phoenix_cpu_id();
+  target_cpu_no = cpu_number_map((my_core_no << 2) | target_thread_no);
+
+  /*
+   * Version with NETRX IPI aggregation
+  */
+  if (target_thread_no != my_thread_no && cpu_isset(target_cpu_no, cpu_online_map))
+  {
+    unsigned long flags;
+    struct sk_buff_head *ptqueue = &cpu_skb_tqueue[target_cpu_no];
+
+    spin_lock_irqsave(&ptqueue->lock, flags);
+    if (ptqueue->qlen)
+    {
+       __skb_queue_tail(ptqueue, skb);
+    }
+    else
+    {
+       __skb_queue_tail(ptqueue, skb);
+       core_send_ipi(target_cpu_no, SMP_NETRX_IPI);
+    }
+    spin_unlock_irqrestore(&ptqueue->lock, flags);
+
+    skb_transfer_stat[my_cpu_no][target_cpu_no]++;
+  }
+  else
+  {
+    skb_transfer_stat[my_cpu_no][my_cpu_no]++;
+
+    skb_queue_tail(&cpu_skb_tqueue[my_cpu_no], skb);
+    skb_transfer_finish();
+  }
+
+}
+
+
+/* second part of SKB transfer logic, called from IRQ_IPI_NETRX handler */
+void
+skb_transfer_finish(void)
+{
+  struct sk_buff *skb;
+  u_long cpu = smp_processor_id();
+
+  while ((skb = skb_dequeue(&cpu_skb_tqueue[cpu])) != NULL)
+  {
+	  skb->dev->last_rx = jiffies;
+	  netif_rx(skb);
+  }
+}
+
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
+
+/**********************************************************************
+ **********************************************************************/
+static irqreturn_t rmi_phnx_mac_int_handler(int irq, void *dev_id)
+{
+    struct net_device *dev = (struct net_device *)dev_id;
+    struct driver_data *priv = netdev_priv(dev);
+    phoenix_reg_t *mmio = priv->mmio;
+    __u32 intreg = phoenix_read_reg(mmio, R_INTREG);
+    int cpu = hard_smp_processor_id();
+
+    mac_stats_add(priv->cpu_stats[cpu].interrupts, 1);
+
+    if (intreg & (1 << O_INTREG__MDInt)) {
+        __u32 phy_int_status = 0;
+        int i=0;
+
+        for(i=0; i<PHOENIX_MAX_MACS; i++) {
+            struct net_device *phy_dev = 0;
+            struct driver_data *phy_priv = 0;
+            uint32_t config_val =0;
+
+            phy_dev = dev_mac[i];
+			if(phy_dev == 0)
+				continue;
+
+            phy_priv = netdev_priv(phy_dev);
+
+            if (phy_priv->type == TYPE_XGMAC) continue;
+            if (phy_priv->phy.mode == PHY_MODE_XAUI) continue;
+
+           		phy_int_status = rmi_phnx_mac_mii_read(phy_priv->phy.mii_addr, phy_priv->phy.addr, 26);
+			
+            /*printk(KERN_DEBUG"[%s]: Received MDIO interrupt from mac_%d (type=%d), "
+              "phy_int_status = 0x%08x reconfiguring gmac speed \n",
+              __FUNCTION__, phy_priv->instance, phy_priv->type,
+              phy_int_status);*/
+            if (!phy_priv->instance && phy_priv->phy.serdes_addr != 0x0 
+						&& phy_priv->phy.mode & PHY_MODE_SELECTABLE) {
+				int phyaddr;
+				unsigned long mii_addr, temp;
+				int mode = PHY_MODE_RGMII;
+				if(phy_priv->phy.mode & PHY_MODE_RGMII)
+					mode = PHY_MODE_SGMII;
+
+				phyaddr = phnx_get_phy_info(phy_priv->instance, mode, &mii_addr, &temp, &temp);
+		        phy_int_status = rmi_phnx_mac_mii_read((phoenix_reg_t *)mii_addr, phyaddr, 26);
+				/*ack rgmii/sgmii mac*/
+    			phoenix_write_reg((phoenix_reg_t *)mii_addr, R_INTREG, 
+										0xffffffff);
+
+                /*	printk(KERN_DEBUG"[%s]: Received MDIO interrupt from mac_%d (type=%d), "
+                    "phy_int_status = 0x%08x reconfiguring gmac speed \n",
+                    __FUNCTION__, phy_priv->instance, phy_priv->type,
+                    phy_int_status);*/
+            } 
+            config_val = phoenix_read_reg(phy_priv->mmio, R_MAC_CONFIG_1);
+            phoenix_write_reg(phy_priv->mmio,R_MAC_CONFIG_1,(config_val & ~(0x35)));
+
+            if(phy_priv->phy.serdes_addr) {
+                serdes_autoconfig(phy_priv);
+            }
+            rmi_phnx_gmac_config_speed(phy_priv);
+            phoenix_write_reg(phy_priv->mmio,R_MAC_CONFIG_1,config_val);
+        }
+    } else {
+        printk("[%s]: mac type = %d, instance %d error "
+                "interrupt: INTREG = 0x%08x\n", 
+                __FUNCTION__, priv->type, priv->instance, intreg);
+    }
+
+    /* clear all interrupts and hope to make progress */
+    phoenix_write_reg(mmio, R_INTREG, 0xffffffff);
+    //phnx_set_counter(NETIF_INT_REG, intreg);
+
+    /* on A0 and B0, xgmac interrupts are routed only to xgs_1 irq */
+    if ( (xlr_revision_b0()) && (priv->type == TYPE_XGMAC) ) {
+        struct net_device *xgs0_dev = dev_mac_type[TYPE_XGMAC][0];
+        struct driver_data *xgs0_priv = netdev_priv(xgs0_dev);
+        phoenix_reg_t *xgs0_mmio = xgs0_priv->mmio;			
+        __u32 xgs0_intreg = phoenix_read_reg(xgs0_mmio, R_INTREG);
+
+        if (xgs0_intreg) {
+            printk("[%s]: mac type = %d, instance %d error "
+                    "interrupt: INTREG = 0x%08x\n", 
+                    __FUNCTION__, xgs0_priv->type, xgs0_priv->instance, xgs0_intreg);
+
+            phoenix_write_reg(xgs0_mmio, R_INTREG, 0xffffffff);
+        }
+    }
+
+    return IRQ_HANDLED;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static int rmi_phnx_mac_open(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+
+	dbg_msg("IN\n");
+
+	if (rmi_phnx_mac_fill_rxfr(dev)) {
+		return -1;
+	}
+
+	spin_lock_bh(&priv->lock);
+	if(PORT_INIT(priv->cfg_flag))
+		phnx_mac_set_rx_mode(dev);
+
+
+	if(PORT_INT_ATTACH(priv->cfg_flag)) {
+		phoenix_write_reg(priv->mmio, R_INTMASK, 
+				(1<<O_INTMASK__TxIllegal)       |
+				(((priv->instance&0x3)==0)<<O_INTMASK__MDInt)|
+				(1<<O_INTMASK__TxFetchError)    |
+				(1<<O_INTMASK__P2PSpillEcc)     |
+				(1<<O_INTMASK__TagFull)         |
+				(1<<O_INTMASK__Underrun)        |
+				(1<<O_INTMASK__Abort)
+				);
+	}
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	if (rmi_msgring_napi) {
+		xlr_napi_ready = 1; 
+	}
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+
+	if(PORT_INIT(priv->cfg_flag)) {
+	/*
+	 * Configure the speed, duplex, and flow control
+	 */
+	rmi_phnx_mac_set_speed(priv, priv->speed);
+	rmi_phnx_mac_set_duplex(priv, priv->duplex, priv->flow_ctrl);
+	rmi_phnx_mac_set_enable(priv, 1);
+	}
+
+	spin_unlock_bh(&priv->lock);
+	netif_tx_start_all_queues(dev);
+
+	/* Set the timer to check for link beat. */
+	init_timer(&priv->link_timer);
+	priv->link_timer.expires = jiffies + 2 * HZ / 100;
+	priv->link_timer.data = (unsigned long)dev;
+	priv->link_timer.function = &rmi_phnx_mac_timer;
+	priv->phy_oldlinkstat = -1; /* set link state to undefined */
+	add_timer(&priv->link_timer);
+
+	return 0;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static int rmi_phnx_mac_close(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	spin_lock_irq(&priv->lock);
+
+	/* There may have left over skbs in the ring as well as in free in 
+	 * they will be reused next time open is called 
+	 */
+
+	rmi_phnx_mac_set_enable(priv, 0);
+
+	del_timer_sync(&priv->link_timer);
+	netif_tx_stop_all_queues(dev);
+	phnx_inc_counter(NETIF_STOP_Q);
+	port_inc_counter(priv->instance, PORT_STOPQ);
+
+	spin_unlock_irq(&priv->lock);
+
+	return 0;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static void rmi_phnx_mac_timer(unsigned long data)
+{
+	struct net_device *dev = (struct net_device *)data;
+	struct driver_data *priv = netdev_priv(dev);
+	int next_tick = HZ;
+	int mii_status;
+
+	spin_lock_irq(&priv->lock);
+
+	if((priv->type == TYPE_GMAC) && (priv->phy.mode != PHY_MODE_XAUI))
+	/* read flag "Link established" (0x04) of MII status register (1) */
+	mii_status = rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr, 1) & 0x04;
+	else
+		mii_status = 1;
+
+	if (mii_status != priv->phy_oldlinkstat) {
+		priv->phy_oldlinkstat = mii_status;
+		if (mii_status) {
+			netif_carrier_on(dev);
+			netif_tx_start_all_queues( dev);
+		} else {
+			netif_carrier_off(dev);
+		}
+	}
+
+	spin_unlock_irq(&priv->lock);
+	priv->link_timer.expires = jiffies + next_tick;
+	add_timer(&priv->link_timer);
+}
+
+/**********************************************************************
+ **********************************************************************/
+static struct net_device_stats *rmi_phnx_mac_get_stats(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	xlr_get_mac_stats(dev, &priv->stats);
+
+	/* XXX update other stats here */
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return &priv->stats;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static void rmi_phnx_mac_set_multicast_list(struct net_device *dev)
+{
+	/* 
+	 * Clear out entire multicast table.  We do this by nuking
+	 * the entire hash table and all the direct matches except
+	 * the first one, which is used for our station address 
+	 */
+
+	/*
+	 * Clear the filter to say we don't want any multicasts.
+	 */
+
+	if (dev->flags & IFF_ALLMULTI) {
+		/* 
+		 * Enable ALL multicasts.  Do this by inverting the 
+		 * multicast enable bit. 
+		 */
+		return;
+	}
+
+	/* 
+	 * Progam new multicast entries.  For now, only use the
+	 * perfect filter.  In the future we'll need to use the
+	 * hash filter if the perfect filter overflows
+	 */
+}
+
+
+
+/**********************************************************************
+ **********************************************************************/
+static int
+rmi_phnx_mac_do_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
+{
+	int rc = 0;
+	switch (cmd) {
+	default:
+		rc = -EOPNOTSUPP;
+		break;
+	}
+
+	return rc;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static void rmi_phnx_mac_tx_timeout(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+
+	spin_lock_irq(&priv->lock);
+
+	dev->trans_start = jiffies;
+	mac_stats_add(priv->stats.tx_errors, 1);
+
+	spin_unlock_irq(&priv->lock);
+
+	netif_tx_wake_all_queues(dev);
+	phnx_inc_counter(NETIF_START_Q);
+	port_inc_counter(priv->instance, PORT_STARTQ);
+
+	printk(KERN_WARNING "%s: Transmit timed out\n", dev->name);
+}
+
+/**********************************************************************
+ **********************************************************************/
+static int rmi_phnx_mac_change_mtu(struct net_device *dev, int new_mtu)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	if ((new_mtu > 1500) || (new_mtu < 64)) {
+		return -EINVAL;
+	}
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	dev->mtu = new_mtu;
+
+	if (netif_running(dev)) {
+		/* Disable MAC TX/RX */
+		rmi_phnx_mac_set_enable(priv, 0);
+
+		/* Flush RX FR IN */
+		/* Flush TX IN */
+		rmi_phnx_mac_set_enable(priv, 1);
+	}
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return 0;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static int rmi_phnx_mac_fill_rxfr(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	struct sk_buff *skb = 0;
+	unsigned long msgrng_flags;
+	int i;
+	int ret = 0;
+
+	dbg_msg("\n");
+	if (!priv->init_frin_desc) return ret;
+	priv->init_frin_desc = 0;	
+
+	if(!(MSGRNG_OWN(priv->cfg_flag)))
+		return ret; 
+	
+	for (i = 0; i < priv->num_desc; i++) {
+		skb = rmi_phnx_alloc_skb();
+		if (!skb) {
+			ret = -ENOMEM;
+			break;
+		}
+
+		skb->dev = dev;
+
+#ifdef CONFIG_PHOENIX_HW_BUFFER_MGMT
+		if (rmi_auto_buffer_mgmt) {
+			skb_shinfo(skb)->rmi_flags = 1;
+			skb_shinfo(skb)->rmi_owner = dev;
+			skb_shinfo(skb)->rmi_refill = mac_frin_replenish_one_msg;
+		}
+#endif /* CONFIG_PHOENIX_HW_BUFFER_MGMT */
+
+		/* Send the free Rx desc to the MAC */
+		msgrng_access_enable(msgrng_flags);
+		mac_put_skb_back_ptr(skb);
+		if (phnx_mac_send_fr(priv, virt_to_bus(skb->data), skb->len)) {
+			dev_kfree_skb(skb);
+			printk
+				("message_send failed!, unable to send free desc to mac\n");
+			ret = -EIO;
+			break;
+		}
+		msgrng_access_disable(msgrng_flags);
+	}
+
+	for (i = 0; i < MAC_FRIN_WORK_NUM; i++)
+		atomic_set(&priv->frin_to_be_sent[i], 0);
+	return ret;
+}
+
+
+/**********************************************************************
+ **********************************************************************/
+static __inline__ void *rmi_phnx_config_spill(phoenix_reg_t * mmio,
+					      int reg_start_0, int reg_start_1,
+					      int reg_size, int size)
+{
+	__u32 spill_size = CACHELINE_ALIGNED_ADDR(size);
+	void *spill = cacheline_aligned_kmalloc(spill_size, GFP_KERNEL);
+	__u64 phys_addr = 0;
+
+	if (!spill) {
+		panic("Unable to allocate memory for spill area!\n");
+	}
+	phys_addr = virt_to_phys(spill);
+	phoenix_write_reg(mmio, reg_start_0, (phys_addr >> 5) & 0xffffffff);
+	phoenix_write_reg(mmio, reg_start_1, (phys_addr >> 37) & 0x07);
+	phoenix_write_reg(mmio, reg_size, spill_size);
+
+	return spill;
+}
+
+static void rmi_phnx_config_spill_area(struct driver_data *priv)
+{
+	int max_frin_spill    = 0;
+	int max_frout_spill   = 0;
+	int max_class_0_spill = 0;
+	int max_class_1_spill = 0;
+	int max_class_2_spill = 0;
+	int max_class_3_spill = 0;
+
+	if(!priv->num_desc || !priv->spill_init)
+		return;
+
+	if(!(MSGRNG_OWN(priv->cfg_flag)))
+		return;
+
+	max_frin_threshold = (priv->num_desc/NR_CPUS);
+	if(max_frin_threshold)
+			max_frin_threshold -= 1;
+
+
+	/* 
+	 * This is new approach to set up spill sizes. TCP stack termination in
+	 * the NAPI mode requires spill area for FreeOut's of considerable size.
+	 * We set frout spill here always to 15K descriptors which traslates into
+	 * 15K * 8 bytes kernel memory alloc.
+	*/
+	max_frin_spill = priv->num_desc << 2;
+	max_frout_spill = XLR_FROUT_JUMBO_SPILL; /* 15K  */
+	max_class_0_spill = priv->num_desc;
+	max_class_1_spill = priv->num_desc;
+	max_class_2_spill = priv->num_desc;
+	max_class_3_spill = priv->num_desc;
+
+	priv->frin_spill =
+		rmi_phnx_config_spill(priv->mmio,
+				      R_REG_FRIN_SPILL_MEM_START_0,
+				      R_REG_FRIN_SPILL_MEM_START_1,
+				      R_REG_FRIN_SPILL_MEM_SIZE,
+				      max_frin_spill *
+				      sizeof(struct fr_desc));
+
+	priv->class_0_spill =
+		rmi_phnx_config_spill(priv->mmio,
+				      R_CLASS0_SPILL_MEM_START_0,
+				      R_CLASS0_SPILL_MEM_START_1,
+				      R_CLASS0_SPILL_MEM_SIZE,
+				      max_class_0_spill *
+				      sizeof(union rx_tx_desc));
+	priv->class_1_spill =
+		rmi_phnx_config_spill(priv->mmio,
+				      R_CLASS1_SPILL_MEM_START_0,
+				      R_CLASS1_SPILL_MEM_START_1,
+				      R_CLASS1_SPILL_MEM_SIZE,
+				      max_class_1_spill *
+				      sizeof(union rx_tx_desc));
+
+	priv->frout_spill =
+		rmi_phnx_config_spill(priv->mmio, R_FROUT_SPILL_MEM_START_0,
+				      R_FROUT_SPILL_MEM_START_1,
+				      R_FROUT_SPILL_MEM_SIZE,
+				      max_frout_spill *
+				      sizeof(struct fr_desc));
+
+	priv->class_2_spill =
+		rmi_phnx_config_spill(priv->mmio,
+				      R_CLASS2_SPILL_MEM_START_0,
+				      R_CLASS2_SPILL_MEM_START_1,
+				      R_CLASS2_SPILL_MEM_SIZE,
+				      max_class_2_spill *
+				      sizeof(union rx_tx_desc));
+	priv->class_3_spill =
+		rmi_phnx_config_spill(priv->mmio,
+				      R_CLASS3_SPILL_MEM_START_0,
+				      R_CLASS3_SPILL_MEM_START_1,
+				      R_CLASS3_SPILL_MEM_SIZE,
+				      max_class_3_spill *
+				      sizeof(union rx_tx_desc));
+}
+
+/*****************************************************************
+ * Write the MAC address to the PHNX registers
+ * All 4 addresses are the same for now
+ *****************************************************************/
+static void phnx_mac_setup_hwaddr(struct driver_data *priv)
+{
+	struct net_device *dev = priv->dev;
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR0,
+			  ((dev->dev_addr[5] << 24) | (dev->dev_addr[4] << 16)
+			   | (dev->dev_addr[3] << 8) | (dev->dev_addr[2]))
+		);
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR0 + 1,
+			  ((dev->dev_addr[1] << 24) | (dev->
+						       dev_addr[0] << 16)));
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR_MASK2, 0xffffffff);
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR_MASK2 + 1, 0xffffffff);
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR_MASK3, 0xffffffff);
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR_MASK3 + 1, 0xffffffff);
+
+	phoenix_write_reg(priv->mmio, R_MAC_FILTER_CONFIG,
+				  (1 << O_MAC_FILTER_CONFIG__BROADCAST_EN) |
+				  (1 << O_MAC_FILTER_CONFIG__ALL_MCAST_EN) |
+				  (1 << O_MAC_FILTER_CONFIG__MAC_ADDR0_VALID)
+			);
+
+}
+
+/*****************************************************************
+ * Read the MAC address from the PHNX registers
+ * All 4 addresses are the same for now
+ *****************************************************************/
+static void phnx_mac_get_hwaddr(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+
+	dev->dev_addr[0] = phoenix_base_mac_addr[0];
+	dev->dev_addr[1] = phoenix_base_mac_addr[1];
+	dev->dev_addr[2] = phoenix_base_mac_addr[2];
+	dev->dev_addr[3] = phoenix_base_mac_addr[3];
+	dev->dev_addr[4] = phoenix_base_mac_addr[4];
+	dev->dev_addr[5] = phoenix_base_mac_addr[5] + priv->id;
+}
+
+/**********************************************************************
+ * Set a new Ethernet address for the interface.
+ **********************************************************************/
+static int rmi_phnx_set_mac_address(struct net_device *dev, void *addr) {
+    struct driver_data *priv = netdev_priv(dev);
+    struct sockaddr *p_sockaddr = (struct sockaddr *) addr;
+
+    memcpy(dev->dev_addr, p_sockaddr->sa_data, 6);
+    phnx_mac_setup_hwaddr(priv);
+    return 0;
+}
+
+/*****************************************************************
+ * Mac Module Initialization
+ *****************************************************************/
+static void mac_common_init(struct driver_data *priv)
+{
+	int i = 0, stid;
+	void (*handler)(int, int,int,int,struct msgrng_msg *, void *);
+
+
+	for (i = 0; i < MAC_FRIN_WORK_NUM; i++) {
+		if(mac_frin_replenish_work[i].func == 0) 
+			INIT_WORK(&mac_frin_replenish_work[i],
+				  mac_frin_replenish_wq);
+		if(mac_frin_replenish_task[i].func == 0)
+			tasklet_init(&mac_frin_replenish_task[i],
+				  mac_frin_replenish, 0UL);
+	}
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	/* Cached pointer to station ID translation table, needed for NAPI */ 
+	if(is_xls())
+		rxstn_to_txstn_ptr = &xls_rxstn_to_txstn_map[0];
+	else
+		rxstn_to_txstn_ptr = &rxstn_to_txstn_map[0];
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+
+
+	if(priv->type == TYPE_GMAC) {
+		if (is_xls()) {
+			if(priv->instance <  PHOENIX_GMAC_PORTS_PER_CTRL)
+				stid = TX_STN_GMAC0;
+			else
+				stid = TX_STN_GMAC1;
+		} else
+			stid = TX_STN_GMAC;
+	} else if(priv->type == TYPE_XGMAC) {
+		if(priv->instance == 0)
+			stid = TX_STN_XGS_0;
+		else
+			stid = TX_STN_XGS_1;
+	} else {
+		printk("Invalid type %d\n", priv->type);
+		return;
+	}
+
+	if((MSGRNG_OWN(priv->cfg_flag))) 
+		handler = rmi_phnx_mac_msgring_handler;
+	else 
+		handler = rmi_phnx_station_unowned_msgring_handler;
+
+	if (register_msgring_handler(stid, handler, NULL))
+			panic("Couldn't register msgring handler for TX_STN_GMAC0\n");
+
+	return;
+}
+
+
+
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+/*
+ * Function covering only gmac/xgmac NAPI statistics
+*/
+static int
+xlr_napi_proc_read(char *page, char **start, off_t off, int count, int *eof, void *data)
+{
+	int len = 0;
+	off_t begin = 0;
+	int cpu = 0;
+
+
+	if (rmi_msgring_napi) 
+        {
+		len += sprintf(page + len, "NAPI Poll Weight=%u\n",
+			       napi_weight);
+		len += sprintf(page + len, "         CPU          RX_COUNT\n");
+
+		for (cpu = 0; cpu < NR_CPUS; cpu++) {
+			if (!cpu_isset(cpu, cpu_online_map)) {
+				continue;
+			}
+			len += sprintf(page + len, "napi: cpu=%02d: %16lld\n", cpu, 
+								per_cpu(xlr_napi_rx_count, cpu));
+
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;			 
+		}      
+
+		/* Clear on read */
+		for (cpu = 0; cpu < NR_CPUS; cpu++) {
+			per_cpu(xlr_napi_rx_count, cpu) = 0; 
+		}
+	}
+	*eof = 1;
+
+out:
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;	
+}
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+
+static int __init
+rmi_napi_poll_weight(char *str)
+{
+	unsigned int wt = simple_strtoul(str, 0, 10);
+	if(wt < 1200) {
+		napi_weight = wt;
+	}
+	return 0;
+}
+
+early_param("rmi_napi_poll_weight", rmi_napi_poll_weight);
+
+static int
+xlr_mac_proc_read(char *page, char **start, off_t off,
+			     int count, int *eof, void *data)
+{
+	int len = 0;
+	off_t begin = 0;
+	int i = 0, cpu = 0;
+	struct net_device *dev = 0;
+	struct driver_data *priv = 0;
+
+
+	for(i=0; i<PHOENIX_MAX_MACS; i++) {
+		dev = dev_mac[i];
+		if(dev == 0)
+			continue;
+
+		priv = netdev_priv(dev);
+		
+		for(cpu=0;cpu<32;cpu++) {
+		
+                        if (!cpu_isset(cpu, cpu_online_map))
+                          continue;
+		
+			len += sprintf(page + len, "per_cpu: %d %d %d %d %lx %lx %lx %lx\n", 
+				       i, cpu,
+				       user_mac ? user_mac->time.hi : user_mac_krnl_data.time.hi,
+				       user_mac ? user_mac->time.lo : user_mac_krnl_data.time.lo,
+				       priv->cpu_stats[cpu].tx_packets,
+				       priv->cpu_stats[cpu].txc_packets,
+				       priv->cpu_stats[cpu].rx_packets,
+				       priv->cpu_stats[cpu].interrupts);
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;			       
+		}
+
+		len += sprintf(page + len,
+			       "per_port: %d %d %d %lx %lx %lx %lx\n",
+			       i,
+			       user_mac ? user_mac->time.hi : user_mac_krnl_data.time.hi,
+			       user_mac ? user_mac->time.lo : user_mac_krnl_data.time.lo,
+			       priv->stats.rx_packets, priv->stats.rx_bytes,
+			       priv->stats.tx_packets, priv->stats.tx_bytes);
+		if (!proc_pos_check(&begin, &len, off, count))
+			goto out;	     
+	}
+
+	*eof = 1;
+
+      out:
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;	
+}
+
+
+
+#ifdef CONFIG_PHOENIX_HW_BUFFER_MGMT
+/*
+ * Setup for XLR/XLS automatic hardware buffer management. 
+*/
+static int __init
+rmi_auto_buffer_mgmt_setup(char *str)
+{
+	if (str == NULL || !strcmp(str, "yes") || !strcmp(str, "y")) {
+		rmi_auto_buffer_mgmt = 1;
+		printk(KERN_ALERT "Enabling automatic hardware buffer management\n");
+	}
+	else if (!strcmp(str, "no") || !strcmp(str, "n")) {
+		rmi_auto_buffer_mgmt = 0;
+		printk(KERN_ALERT "Disabling automatic hardware buffer management\n");
+	}
+
+	return 0;
+}
+
+/* for compatibility we use "xlr_" prefix for the option */
+early_param("xlr_auto_buffer_mgmt", rmi_auto_buffer_mgmt_setup);
+#endif /* CONFIG_PHOENIX_HW_BUFFER_MGMT */
+
+
+
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+/*
+ * This function is used upon the exit from NAPI poll to re-enable interrupts
+*/
+static void
+xlr_napi_enable_ints(void)
+{
+	unsigned int msgring_config;
+	unsigned long flags = 0, mflags = 0; 
+	struct napi_control_s *p = &napi_control[phoenix_cpu_id()];
+	unsigned long rcv_bmask; 
+	unsigned long this_thread_bmask = (1 << phoenix_thr_id());
+
+
+	msgrng_access_save(&p->xlr_napi_msgrng_lock, flags, mflags);
+	p->netrx_mask |= this_thread_bmask;
+
+
+	/* Read message ring status */
+	rcv_bmask = (~(msgrng_read_status() >> 24)) & 0xff;
+	rcv_bmask = ((rcv_bmask & 0xf) | (rcv_bmask >> 4));
+
+	rcv_bmask &= p->netrx_mask; 
+
+	if (rcv_bmask) {
+		/* rewrite the interrupt mask */
+		msgring_config = msgrng_read_config();
+		msgring_config |= (rcv_bmask << 8);
+		msgrng_write_config(msgring_config); 
+	}
+	else {
+
+		/* rewrite the interrupt mask */
+		msgring_config = msgrng_read_config();
+		msgring_config |= (this_thread_bmask << 8);
+		msgrng_write_config(msgring_config); 
+	}
+	msgrng_access_restore(&p->xlr_napi_msgrng_lock, flags, mflags);
+}
+
+
+/* called from msgring_process_rx_msgs() from on_chip.c  */
+void
+xlr_napi_rx_schedule(void)
+{
+	unsigned int msgring_config;
+	unsigned long flags = 0, mflags = 0; 
+	struct napi_struct *napi;
+	unsigned long rcv_bmask; // bit array: bmask[i] is 1 iff bucket[i] or bucket[i + 4] non-empty 
+	unsigned long this_thread_bmask; // non-zero if THIS thread has packets in its buckets
+	struct napi_control_s *p = &napi_control[phoenix_cpu_id()];
+
+	if (!xlr_napi_ready)
+		return;
+
+	/* rewrite the interrupt mask */
+	msgrng_access_save(&p->xlr_napi_msgrng_lock, flags, mflags);
+
+	/* Read message ring status */
+	rcv_bmask = (~(msgrng_read_status() >> 24)) & 0xff;
+	rcv_bmask = ((rcv_bmask & 0xf) | (rcv_bmask >> 4));
+
+	if (rcv_bmask == 0) {
+		msgrng_access_restore(&p->xlr_napi_msgrng_lock, flags, mflags);
+		write_64bit_cp0_eirr(1ULL << IRQ_MSGRING);
+		return;
+	}
+
+	this_thread_bmask = rcv_bmask & (1 << phoenix_thr_id());
+	p->netrx_mask &= ~this_thread_bmask;
+	rcv_bmask = rcv_bmask & p->netrx_mask; // & ~(1 << phoenix_thr_id());
+
+	msgring_config = msgrng_read_config();
+	msgring_config = (msgring_config & 0xfffff0ff) | (rcv_bmask << 8) ;
+
+	msgrng_write_config(msgring_config);
+
+	msgrng_access_restore(&p->xlr_napi_msgrng_lock, flags, mflags);
+  
+	/* Acknowledge interrupt in eirr */
+	write_64bit_cp0_eirr(1ULL << IRQ_MSGRING);
+
+	if (this_thread_bmask) {
+		/* schedule polling for this cpu using dummy_dev */
+		napi = &__get_cpu_var(xlr_napi_poll_struct);
+		napi_schedule(napi);
+	}
+}
+
+
+/*
+ * Main NAPI poll loop
+*/
+int
+xlr_napi_poll(struct napi_struct *napi, int budget)
+{
+	int rx_pkts = 0;
+	xlr_napi_poll_upper(&xlr_napi_dummy_dev, budget);
+	rx_pkts = napi_poll_lower(&xlr_napi_dummy_dev, budget);
+
+	if(rx_pkts < budget)
+	{
+		napi_complete(napi);
+		/* enable message ring interrupts */
+		xlr_napi_enable_ints();
+	}
+	return rx_pkts;
+}
+
+
+/*
+ * Setup for XLR/XLS msgring NAPI parameter. 
+*/
+static int __init
+rmi_msgring_napi_setup(char *str)
+{
+	if (str == NULL || !strcmp(str, "yes") || !strcmp(str, "y")) {
+		rmi_msgring_napi = 1;
+		rmi_on_chip_napi = 1;
+	}
+	else if (!strcmp(str, "no") || !strcmp(str, "n")) {
+		rmi_msgring_napi = 0;
+		rmi_on_chip_napi = 0;
+	}
+
+	return 0;
+}
+
+/* for compatibility we use "xlr_" prefix for the option */
+early_param("xlr_msgring_napi", rmi_msgring_napi_setup);
+
+
+/*
+ * Setup for XLR/XLS msgring NAPI parameter. 
+*/
+static int __init
+rmi_deprecated_napi_setup(char *str)
+{
+	if (str == NULL || !strcmp(str, "yes") || !strcmp(str, "y")) {
+		rmi_msgring_napi = 1;
+		rmi_on_chip_napi = 1;
+	}
+	return 0;
+}
+
+/* Deprecated setup option for NAPI */
+early_param("xlr_napi", rmi_deprecated_napi_setup);
+
+
+
+/*
+ * NAPI setup for non-networking on-chip devices. 
+*/
+static int __init
+rmi_on_chip_napi_setup(char *str)
+{
+	if (str == NULL || !strcmp(str, "yes") || !strcmp(str, "y")) {
+		if (rmi_msgring_napi == 0) {
+			printk("MSGRING_NAPI:*****************************************************************\n");
+			printk("MSGRING_NAPI:  Can't enable on_chip NAPI: enable xlr_msgring_napi first      *\n");
+			printk("MSGRING_NAPI:*****************************************************************\n");
+			rmi_on_chip_napi = 0;
+		} else {
+			rmi_on_chip_napi = 1;
+		}
+	}
+	else if (!strcmp(str, "no") || !strcmp(str, "n")) {
+		rmi_on_chip_napi = 0;
+	}
+
+	return 0;
+}
+
+/* for compatibility we use "xlr_" prefix for the option */
+early_param("xlr_on_chip_napi", rmi_on_chip_napi_setup);
+
+
+
+/*
+ * Setup XLR/XLS NAPI subsystem 
+*/
+static int
+rmi_phnx_napi_setup(void)
+{
+	int i, cpu_count; 
+	struct napi_struct *napi; 
+	int weight_p = napi_weight; 
+
+	/* napi required msgring interrupt to be enabled, 
+	 * but it can be enabled only if both gmac and xgmac/spi4
+	 * are owned by linux 
+         */
+	if (xlr_hybrid_user_mac_xgmac())
+		return 0;
+
+	printk("MSGRING_NAPI: Initializing RMI GMAC/XGMAC NAPI subsystem\n");
+
+	msgring_int_type = 0x01;
+
+	atomic_set(&(xlr_napi_dummy_dev.refcnt), 1);
+	set_bit(__LINK_STATE_START, &xlr_napi_dummy_dev.state);
+
+	for (cpu_count = 0; cpu_count < NR_CPUS; cpu_count++) 
+	{
+		napi = &per_cpu(xlr_napi_poll_struct, cpu_count);
+		memset(napi, 0, sizeof(napi));
+		netif_napi_add(&xlr_napi_dummy_dev, napi, xlr_napi_poll, weight_p);
+		napi_enable(napi);
+	}
+
+	for (i = 0; i < NR_CPUS; i++) {
+		per_cpu(xlr_napi_rx_count, i) = 0; 
+	}
+
+	return 0;
+}
+
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+
+
+
+
+static int xlr_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	int mii_status;
+
+	if ((priv->type == TYPE_XGMAC) || (priv->phy.mode == PHY_MODE_XAUI)){
+		cmd->supported = SUPPORTED_FIBRE|SUPPORTED_10000baseT_Full;
+		cmd->advertising = SUPPORTED_FIBRE|SUPPORTED_10000baseT_Full;
+		cmd->speed = SPEED_10000;
+		cmd->port = PORT_FIBRE;
+		cmd->duplex = DUPLEX_FULL;
+		cmd->phy_address = priv->instance;
+		cmd->autoneg = AUTONEG_DISABLE;
+		cmd->maxtxpkt = 0;
+		cmd->maxrxpkt = 0;
+
+	}else{
+
+		cmd->supported = SUPPORTED_10baseT_Full | 
+			SUPPORTED_10baseT_Half | 
+			SUPPORTED_100baseT_Full | SUPPORTED_100baseT_Half |
+			SUPPORTED_1000baseT_Full | SUPPORTED_MII |
+			SUPPORTED_Autoneg | SUPPORTED_TP;
+
+		cmd->advertising = priv->advertising;
+
+		mii_status = rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr, MII_NCONFIG);
+		priv->speed = (mii_status >> 3) & 0x03;
+
+		cmd->speed = (priv->speed == phnx_mac_speed_1000) ? SPEED_1000 :
+		(priv->speed == phnx_mac_speed_100) ? SPEED_100: SPEED_10;
+
+		cmd->duplex = (mii_status >> 5) & 0x1;
+		cmd->port = PORT_TP;
+		cmd->phy_address = priv->instance;
+		cmd->transceiver = XCVR_INTERNAL;
+		cmd->autoneg = (~(mii_status >> 14)) & 0x1;
+		cmd->maxtxpkt = 0;
+		cmd->maxrxpkt = 0;
+	}
+
+	return 0;
+}
+static int xlr_enable_autoneg(struct net_device *dev, u32 adv)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	int mii_status;
+	u32 adv1, adv2;
+    unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	rmi_phnx_mac_set_enable(priv, 0);
+	/* advertising for 10/100 Mbps */
+	adv1 = rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr, MII_ADVERTISE);
+	adv1 &= ~(ADVERTISE_ALL | ADVERTISE_100BASE4);
+	/* advertising for 1000 Mbps */
+	adv2 = rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr, 0x9);
+	adv2 &= ~(0x300);
+
+	if(adv & ADVERTISED_10baseT_Half)
+		adv1 |= ADVERTISE_10HALF;
+	if(adv & ADVERTISED_10baseT_Full)
+		adv1 |= ADVERTISE_10FULL;
+	if(adv & ADVERTISED_100baseT_Full)
+		adv1 |= ADVERTISE_100FULL;
+	if(adv & ADVERTISED_100baseT_Half)
+		adv1 |= ADVERTISE_100HALF;
+
+	if(adv & ADVERTISED_1000baseT_Full)
+		adv2 |= 0x200;
+	if(adv & ADVERTISED_1000baseT_Half)
+		adv2 |= 0x100;
+
+	/* Set the advertising parameters */
+	rmi_phnx_mac_mii_write(priv->phy.mii_addr, priv->phy.addr, MII_ADVERTISE, adv1);
+	rmi_phnx_mac_mii_write(priv->phy.mii_addr, priv->phy.addr, 0x9, adv2);
+
+	priv->advertising = adv1 | adv2;
+
+	mii_status = rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr, MII_BMCR);
+	/* enable autoneg and force restart autoneg */
+	mii_status |= (BMCR_ANENABLE | BMCR_ANRESTART);
+	rmi_phnx_mac_mii_write(priv->phy.mii_addr, priv->phy.addr, MII_BMCR, mii_status);
+
+	rmi_phnx_mac_set_enable(priv, 1);
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+
+static int xlr_set_link_speed(struct net_device *dev, int speed, int duplex)
+{
+	u32 adv;
+	int ret =0;
+
+	switch(speed) {
+		case SPEED_10:
+			if ( duplex == DUPLEX_FULL )
+				adv = ADVERTISED_10baseT_Full;
+			else
+				adv = ADVERTISED_10baseT_Half;
+			break;
+		case SPEED_100:
+			if ( duplex == DUPLEX_FULL )
+				adv = ADVERTISED_100baseT_Full;
+			else
+				adv = ADVERTISED_100baseT_Half;
+			break;
+		case SPEED_1000:
+			if ( duplex == DUPLEX_FULL )
+				adv = ADVERTISED_1000baseT_Full;
+			else
+				adv = ADVERTISED_1000baseT_Half;
+			break;
+		default:
+			ret = -EINVAL;
+			return ret;
+	}
+	ret = xlr_enable_autoneg( dev,adv);
+	return ret;
+
+}
+
+static int xlr_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	int ret;
+	struct driver_data *priv = netdev_priv(dev);
+
+	if ((priv->type == TYPE_XGMAC) || (priv->phy.mode == PHY_MODE_XAUI)){
+		return -EIO;
+	}
+	if (cmd->autoneg == AUTONEG_ENABLE) {
+		ret = xlr_enable_autoneg(dev, cmd->advertising);
+	}else {
+		ret = xlr_set_link_speed(dev, cmd->speed, cmd->duplex);
+	}
+	return ret;
+}
+
+static void xlr_get_drvinfo(struct net_device *dev, 
+				struct ethtool_drvinfo *info)
+{
+	strcpy(info->driver, DRV_NAME);
+	strcpy(info->version, DRV_VERSION);
+}
+
+static int xlr_get_regs_len(struct net_device *dev) 
+{
+	return PHNX_ETHTOOL_REG_LEN;
+}
+static void xlr_get_regs(struct net_device *dev,
+				struct ethtool_regs *regs, void *p)
+{
+	u32 *data = (u32 *)p;
+	int i;
+	struct driver_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	memset((void *)data, 0, PHNX_ETHTOOL_REG_LEN);
+
+	spin_lock_irqsave(&priv->lock, flags);
+	for(i=0; i <= PHNX_NUM_REG_DUMP; i++)
+		*(data + i) = phoenix_read_reg(priv->mmio,  R_TX_CONTROL + i);
+	spin_unlock_irqrestore(&priv->lock, flags);
+}
+static u32 xlr_get_msglevel(struct net_device *dev)
+{
+	return mac_debug;
+}
+static void xlr_set_msglevel(struct net_device *dev, u32 value)
+{
+	mac_debug = value;
+}
+
+static int xlr_nway_reset(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	int mii_status;
+	unsigned long flags;
+	int ret = -EINVAL;
+
+   if ((priv->type == TYPE_XGMAC) || (priv->phy.mode == PHY_MODE_XAUI))
+    return -EIO;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	mii_status = rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr, MII_BMCR);
+	if(mii_status & BMCR_ANENABLE)
+	{
+		rmi_phnx_mac_mii_write(priv->phy.mii_addr, priv->phy.addr, 
+				MII_BMCR, BMCR_ANRESTART | mii_status);
+		ret = 0;
+	}
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return ret;
+}
+static u32 xlr_get_link(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	int mii_status;
+	unsigned long flags;
+
+   if ((priv->type == TYPE_XGMAC) || (priv->phy.mode == PHY_MODE_XAUI))
+    return -EIO;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	mii_status = rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr, MII_BMSR);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	if(mii_status & BMSR_LSTATUS)
+		return 1;
+	return 0;
+}
+#define PHNX_STATS_KEY_LEN  \
+		(sizeof(struct net_device_stats) / sizeof(unsigned long))
+static struct {
+	        const char string[ETH_GSTRING_LEN];
+} phnx_ethtool_stats_keys[PHNX_STATS_KEY_LEN] = {
+	{ "rx_packets" },
+	{ "tx_packets" },
+	{ "rx_bytes" },
+	{ "tx_bytes" },
+	{ "rx_errors" },
+	{ "tx_errors" },
+	{ "rx_dropped" },
+	{ "tx_dropped" },
+	{ "multicast" },
+	{ "collisions" },
+	{ "rx_length_errors" },
+	{ "rx_over_errors" },
+	{ "rx_crc_errors" },
+	{ "rx_frame_errors" },
+	{ "rx_fifo_errors" },
+	{ "rx_missed_errors" },
+	{ "tx_aborted_errors" },
+	{ "tx_carrier_errors" },
+	{ "tx_fifo_errors" },
+	{ "tx_heartbeat_errors" },
+	{ "tx_window_errors" },
+	{ "rx_compressed" },
+	{ "tx_compressed" }
+};
+static int xlr_get_stats_count (struct net_device *dev)
+{
+	return PHNX_STATS_KEY_LEN;
+}
+
+static void xlr_get_strings (struct net_device *dev, u32 stringset, u8 *buf)
+{
+	switch (stringset) {
+	case ETH_SS_STATS:
+		memcpy(buf, &phnx_ethtool_stats_keys, 
+				sizeof(phnx_ethtool_stats_keys));
+		break;
+	default:
+		printk(KERN_WARNING "%s: Invalid stringset %d\n", 
+				__FUNCTION__, stringset);
+		break;
+	}
+}
+
+static void xlr_get_mac_stats(struct net_device *dev, 
+					struct net_device_stats *stats)
+{
+	struct driver_data *priv = netdev_priv(dev);
+
+	stats->tx_errors = phoenix_read_reg(priv->mmio, TX_FCS_ERROR_COUNTER);
+	stats->rx_dropped = phoenix_read_reg(priv->mmio, 
+						RX_DROP_PACKET_COUNTER);
+	stats->tx_dropped = phoenix_read_reg(priv->mmio, TX_DROP_FRAME_COUNTER);
+
+	stats->multicast = phoenix_read_reg(priv->mmio, 
+						RX_MULTICAST_PACKET_COUNTER);
+	stats->collisions = phoenix_read_reg(priv->mmio, 
+						TX_TOTAL_COLLISION_COUNTER);
+
+	stats->rx_length_errors = phoenix_read_reg(priv->mmio, 
+						RX_FRAME_LENGTH_ERROR_COUNTER);
+	stats->rx_over_errors = phoenix_read_reg(priv->mmio, 
+						RX_DROP_PACKET_COUNTER);
+	stats->rx_crc_errors = phoenix_read_reg(priv->mmio, 
+						RX_FCS_ERROR_COUNTER);
+	stats->rx_frame_errors = phoenix_read_reg(priv->mmio, 
+						RX_ALIGNMENT_ERROR_COUNTER);
+
+	stats->rx_fifo_errors = phoenix_read_reg(priv->mmio,
+					    	RX_DROP_PACKET_COUNTER);
+	stats->rx_missed_errors = phoenix_read_reg(priv->mmio,
+					    	RX_CARRIER_SENSE_ERROR_COUNTER);
+
+	stats->rx_errors = (stats->rx_over_errors + stats->rx_crc_errors +
+			     stats->rx_frame_errors + stats->rx_fifo_errors +
+			     stats->rx_missed_errors);
+
+	stats->tx_aborted_errors = phoenix_read_reg(priv->mmio, 
+			TX_EXCESSIVE_COLLISION_PACKET_COUNTER);
+	stats->tx_carrier_errors = phoenix_read_reg(priv->mmio, 
+					TX_DROP_FRAME_COUNTER);
+	stats->tx_fifo_errors = phoenix_read_reg(priv->mmio, 
+					TX_DROP_FRAME_COUNTER);
+
+}
+
+static void xlr_get_ethtool_stats (struct net_device *dev,
+			struct ethtool_stats *estats, u64 *stats)
+{
+	int i;
+	struct driver_data *priv = netdev_priv(dev);
+	unsigned long flags;
+	unsigned long *tmp_stats;
+	
+	spin_lock_irqsave(&priv->lock, flags);
+	
+	xlr_get_mac_stats(dev, &priv->stats);
+	
+	
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	tmp_stats = (unsigned long *)&priv->stats;
+	for(i=0; i < PHNX_STATS_KEY_LEN; i++) {
+		*stats = (u64)*tmp_stats;
+		stats++;
+		tmp_stats++;
+	}
+}
+
+static struct ethtool_ops xlr_ethtool_ops= {
+        .get_settings           = xlr_get_settings,
+        .set_settings           = xlr_set_settings,
+        .get_drvinfo            = xlr_get_drvinfo,
+        .get_regs_len           = xlr_get_regs_len,
+        .get_regs               = xlr_get_regs,
+        .get_msglevel           = xlr_get_msglevel,
+        .set_msglevel           = xlr_set_msglevel,
+        .nway_reset             = xlr_nway_reset,
+        .get_link               = xlr_get_link,
+        .get_strings            = xlr_get_strings,
+        .get_stats_count        = xlr_get_stats_count,
+        .get_ethtool_stats      = xlr_get_ethtool_stats,
+};
+
+void rmi_reset_gmac(phoenix_reg_t *mmio)
+{
+    volatile uint32_t val;
+
+        /* Disable MAC RX */
+        val = phoenix_read_reg(mmio, R_MAC_CONFIG_1);
+        val &= ~0x4;
+        phoenix_write_reg(mmio, R_MAC_CONFIG_1, val);
+
+        /* Disable Core RX */
+        val = phoenix_read_reg(mmio, R_RX_CONTROL);
+        val &= ~0x1;
+        phoenix_write_reg(mmio, R_RX_CONTROL, val);
+
+        /* wait for rx to halt */
+        while(1) {
+            val = phoenix_read_reg(mmio, R_RX_CONTROL);
+            if(val & 0x2)
+                break;
+            mdelay(1);
+        }
+
+        /* Issue a soft reset */
+        val = phoenix_read_reg(mmio, R_RX_CONTROL);
+        val |= 0x4;
+        phoenix_write_reg(mmio, R_RX_CONTROL, val);
+           
+        /* wait for reset to complete */
+        while(1) {
+            val = phoenix_read_reg(mmio, R_RX_CONTROL);
+            if(val & 0x8)
+                break;
+            mdelay(1);
+        }
+
+        /* Clear the soft reset bit */
+        val = phoenix_read_reg(mmio, R_RX_CONTROL);
+        val &= ~0x4;
+        phoenix_write_reg(mmio, R_RX_CONTROL, val);
+}
+
+void rmi_reset_xaui(phoenix_reg_t *mmio)
+{
+    volatile uint32_t val;
+
+    /* Disable Core RX */
+    val = phoenix_read_reg(mmio, R_RX_CONTROL);
+    val &= ~0x1;
+    phoenix_write_reg(mmio, R_RX_CONTROL, val);
+
+    /* wait for rx to halt */
+    while(1) {
+        val = phoenix_read_reg(mmio, R_RX_CONTROL);
+        if(val & 0x2)
+            break;
+        mdelay(1);
+    }
+
+    /* Issue a soft reset */
+    val = phoenix_read_reg(mmio, R_RX_CONTROL);
+    val |= 0x4;
+    phoenix_write_reg(mmio, R_RX_CONTROL, val);
+
+    /* wait for reset to complete */
+    while(1) {
+        val = phoenix_read_reg(mmio, R_RX_CONTROL);
+        if(val & 0x8)
+            break;
+        mdelay(1);
+    }
+
+    /* Clear the soft reset bit */
+    val = phoenix_read_reg(mmio, R_RX_CONTROL);
+    val &= ~0x4;
+    phoenix_write_reg(mmio, R_RX_CONTROL, val);
+}
+
+u16  rmi_select_tx_queue(struct net_device *dev, struct sk_buff *skb)
+{
+	return (u16)smp_processor_id();
+}
+
+
+static void setup_net_ops(struct net_device_ops *mac_ops)
+{
+	mac_ops->ndo_open = rmi_phnx_mac_open;
+	mac_ops->ndo_stop = rmi_phnx_mac_close;
+	mac_ops->ndo_get_stats = rmi_phnx_mac_get_stats;
+	mac_ops->ndo_set_multicast_list = rmi_phnx_mac_set_multicast_list;
+	mac_ops->ndo_set_mac_address = rmi_phnx_set_mac_address;
+	mac_ops->ndo_do_ioctl = rmi_phnx_mac_do_ioctl;
+	mac_ops->ndo_tx_timeout = rmi_phnx_mac_tx_timeout;
+	mac_ops->ndo_change_mtu = rmi_phnx_mac_change_mtu;
+	mac_ops->ndo_select_queue = rmi_select_tx_queue;
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	if (rmi_msgring_napi) {
+		mac_ops->ndo_start_xmit = rmi_phnx_napi_mac_xmit;
+	}
+	else {
+		mac_ops->ndo_start_xmit = rmi_phnx_mac_xmit;
+	}
+#else
+	mac_ops->ndo_start_xmit = rmi_phnx_mac_xmit;
+
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+}
+
+int rmi_phnx_mac_init_module(void)
+{
+	struct net_device *dev = 0;
+	struct driver_data *priv = 0;
+	unsigned long mmio_start = 0;
+	int i = 0, num_desc = 0, num_desc_total = 0;
+	int ret = 0, port_type;
+	struct proc_dir_entry *entry;
+	struct port_cfg *port_cfg;
+	extern struct net_device_cfg phnx_net_dev_cfg;
+	struct net_device_cfg *net_cfg = &phnx_net_dev_cfg;
+    int port_xaui = 0;
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+
+	/* Run NAPI compatibility test */
+	if (!rmi_napi_compatibility_check()) {
+		rmi_msgring_napi = 0;
+		rmi_on_chip_napi = 0;
+	}
+
+	if (rmi_msgring_napi) {
+		rmi_phnx_napi_setup();
+	}
+	else {
+		printk("MSGRING_NAPI: NAPI is not enabled!\n");
+	}
+
+        /* Initialize spinlock protecting NAPI msgring_config access */
+        for (i = 0; i < NR_CPUS / 4; i++) {
+		spin_lock_init(&napi_control[i].xlr_napi_msgrng_lock);
+		napi_control[i].netrx_mask = 0xf;
+        }
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+        for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+		spin_lock_init(&pending_tx_lock[i]);
+	}
+
+	chip_is_xls = is_xls();
+
+	entry = create_proc_read_entry("rmi_mac_stats", 0 /* def mode */ ,
+				       rmi_root_proc /* parent */ ,
+				       xlr_mac_proc_read
+				       /* proc read function */ ,
+				       0	/* no client data */
+		);
+	if (!entry) {
+		printk("[%s]: Unable to create proc read entry for xlr_mac!\n",
+		       __FUNCTION__);
+	}	
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	if (rmi_msgring_napi) {
+		entry = create_proc_read_entry("rmi_napi_stats", 0 /* def mode */ ,
+					       rmi_root_proc /* parent */ ,
+					       xlr_napi_proc_read
+					       /* proc read function */ ,
+					       0 /* no client data */
+		);
+		if (!entry) {
+			printk("[%s]: Unable to create proc read entry for xlr_napi!\n",
+				__FUNCTION__);
+		}	
+	}
+#endif /* CONFIG_PHOENIX_MSGRING_NAPI */
+	setup_net_ops(&rmi_mac_net_ops);
+
+	for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+
+		if(i < PHOENIX_MAX_GMACS) {
+			port_cfg = &net_cfg->gmac_port[i];
+			port_type = TYPE_GMAC;
+            port_xaui = (port_cfg->phy_mode == PHY_MODE_XAUI);
+		} else if(net_cfg->xgs_type[i - PHOENIX_MAX_GMACS] == TYPE_XGMAC) {
+			port_cfg = &net_cfg->xgs_port[i - PHOENIX_MAX_GMACS];
+			port_type = TYPE_XGMAC;
+		} else
+			continue;
+
+		if(port_cfg->cfg_flag == 0)
+			continue;
+
+		dbg_msg("Registering phnx_mac[%d]\n", i);
+
+		dev = alloc_etherdev_mq(sizeof(struct driver_data), 32);
+		if (!dev) {
+			ret = -ENOMEM;
+			goto out;
+		}
+
+		priv = netdev_priv(dev);
+		priv->dev = dev;
+		priv->cfg_flag = port_cfg->cfg_flag;
+
+		priv->mmio = (phoenix_reg_t *) port_cfg->mmio_addr;
+		if (!priv->mmio) {
+			dbg_panic
+				("Unable to ioremap MMIO region of size %x @ %lx\n",
+				 PHOENIX_IO_SIZE, mmio_start);
+		}
+
+		dbg_msg(" priv->mmio=%p\n",	priv->mmio);
+
+		if(port_type == TYPE_GMAC && PORT_INIT(priv->cfg_flag)) {
+            if(port_xaui)
+                rmi_reset_xaui(priv->mmio);
+            else
+                rmi_reset_gmac(priv->mmio);
+        }
+
+		/* Initialize the net_device */
+		if (PORT_INT_ATTACH(priv->cfg_flag)) {
+			dev->irq = port_cfg->irqno;
+			if (request_irq(dev->irq, rmi_phnx_mac_int_handler,
+						IRQF_DISABLED, dev->name, dev)) {
+				ret = -EBUSY;
+				panic("Couldn't get mac interrupt line (%d)", dev->irq);
+			}
+		}
+
+		ether_setup(dev);
+
+		dev->base_addr = (long)priv->mmio;
+		dev->mem_end = (long)priv->mmio + PHOENIX_IO_SIZE - 1;
+		dev->netdev_ops = &rmi_mac_net_ops;
+
+		dev->watchdog_timeo = (1000 * HZ);
+
+		dev->features |= NETIF_F_LLTX;
+
+		SET_ETHTOOL_OPS(dev,&xlr_ethtool_ops);
+		/* Initialize the device specific driver data */
+		spin_lock_init(&priv->lock);
+
+		priv->id = i;
+		priv->instance = port_cfg->instance;
+		priv->type = port_type;
+		if(port_cfg->num_desc) {
+			num_desc = port_cfg->num_desc;
+			priv->spill_init = 1;
+		} else
+			priv->spill_init = 0;
+
+		dev->tx_queue_len = (num_desc/32) - 1;
+		priv->num_desc = num_desc;
+		priv->config_pde = port_cfg->config_pde;
+
+		num_desc_total += num_desc;
+
+		/* Caching FRF and TX station IDs */
+  		priv->fr_stid = msgrng_stid_rfr(priv->instance, priv->type);
+  		priv->tx_stid = mac_fill_tx_stid(priv->instance, priv->type);
+
+		/* fill the phy info*/
+		priv->phy.addr 	   = port_cfg->phy_addr;
+		priv->phy.mode = port_cfg->phy_mode;
+		priv->phy.mii_addr = mac_addr_to_ptr(port_cfg->mii_addr);
+		priv->phy.pcs_addr = mac_addr_to_ptr(port_cfg->pcs_addr);
+		priv->phy.serdes_addr = mac_addr_to_ptr(port_cfg->serdes_addr);
+
+
+		phnx_mac_get_hwaddr(dev);
+
+		if(PORT_INIT(priv->cfg_flag)) {
+			if (priv->type == TYPE_GMAC) {
+                if(port_xaui)
+                    rmi_phnx_xaui_init(priv, port_cfg);
+                else
+                    rmi_phnx_gmac_init(priv, port_cfg);
+            }
+			else if(priv->type == TYPE_XGMAC) 
+				rmi_phnx_xgmac_init(priv, port_cfg);
+			
+            phnx_mac_setup_hwaddr(priv);
+		}
+
+		if(PORT_ATTACH(priv->cfg_flag))  {
+			ret = register_netdev(dev);
+			if (ret) {
+				dbg_panic("Unable to register net device\n");
+			}
+			else {
+				if (priv->type == TYPE_GMAC)
+					printk("GMAC_%d initialized as %s\n", priv->instance, priv->dev->name);
+				else if (priv->type == TYPE_XGMAC)
+					printk("XGMAC_%d initialized as %s\n", priv->instance, priv->dev->name);
+			}
+		}
+
+		if(PORT_INIT(priv->cfg_flag)) 
+			rmik_config_pde(priv->type, priv->instance, priv->mmio);
+
+		if(rmik_en) {
+			uint64_t pde_bkt_map = 0ULL;
+			pde_bkt_map = rmik_get_pde_bktmap(priv->type, priv->instance);
+			priv->frstid_rsvd = ((pde_bkt_map & free_back_stid_map) == 0ULL) ? 1 : 0;
+		} else
+			priv->frstid_rsvd = 1;
+
+
+		mac_common_init(priv);
+		rmi_phnx_mac_set_enable(priv, 0);
+
+		dbg_msg("%s: Phoenix Mac at 0x%p (mtu=%d)\n",
+			dev->name, priv->mmio, dev->mtu);
+
+		dev_mac_type[priv->type][priv->instance] = dev;
+		dev_mac[i] = dev;
+	}
+	
+	rmik_init_replenish_work(num_desc);
+	rmik_register_net_events();
+
+	dbg_msg("port_counters = %p\n", port_counters);
+	dbg_msg("pending_tx_lock = %p, pending_tx = %p\n", port_counters,
+		pending_tx);
+
+
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+        /* initialize cpu skb queues */
+        cpu_tx_queue_init();
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
+ out:
+        if ( (xlr_board_atx_v() || xlr_board_atx_iv_b())) {
+            /* on atx-v and atx-iv-b read rgmii interrupt at least once */
+            dev = dev_mac_type[TYPE_GMAC][0];
+            if(dev != 0) {
+                priv = netdev_priv(dev);
+                rmi_phnx_mac_mii_read(priv->phy.mii_addr, 3, 26);
+            }
+        }
+ 
+	for (i = 0; i < PHOENIX_MAX_GMACS; i++) {
+		if(dev_mac[i] == 0)
+                       continue;
+
+		priv = netdev_priv(dev_mac[i]);
+		if (PORT_INIT(priv->cfg_flag)) 
+			phnx_mac_set_rx_mode(dev_mac[i]);
+
+        if (PORT_INT_ATTACH(priv->cfg_flag)) {
+            phoenix_write_reg(priv->mmio, R_INTMASK,
+                    (1<<O_INTMASK__TxIllegal)       |
+                    (((priv->instance&0x3)==0)<<O_INTMASK__MDInt)           |
+                    (1<<O_INTMASK__TxFetchError)    |
+                    (1<<O_INTMASK__P2PSpillEcc)     |
+                    (1<<O_INTMASK__TagFull)         |
+                    (1<<O_INTMASK__Underrun)        |
+                    (1<<O_INTMASK__Abort));
+        }
+	}
+	if (ret < 0) {
+		dbg_panic("Error, ret = %d\n", ret);
+	}
+	return ret;
+}
+
+/**********************************************************************
+ **********************************************************************/
+void rmi_phnx_mac_exit_module(void)
+{
+	struct net_device *dev;
+	int idx;
+
+	for (idx = 0; idx < PHOENIX_MAX_MACS; idx++) {
+		dev = dev_mac[idx];
+		if (dev == 0)
+			continue;
+
+		unregister_netdev(dev);
+		free_netdev(dev);
+	}
+}
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+
+int rmi_macreg_set(int inf, unsigned int reg, unsigned int val)
+{
+struct driver_data *priv = NULL;
+struct net_device *dev = NULL;
+ 
+    dev = dev_mac[inf];
+
+    if (!dev) 
+         return -1;
+ 
+   	priv = netdev_priv(dev);
+    phoenix_write_reg(priv->mmio, reg, phoenix_read_reg(priv->mmio, reg)|val);
+    return 0;
+}
+
+u32 rmi_macreg_get(int inf, unsigned int reg)
+{
+struct driver_data *priv = NULL;
+struct net_device *dev = NULL;
+ 
+    dev = dev_mac[inf];
+
+    if (!dev) 
+         return -1;
+ 
+    priv = netdev_priv(dev);
+    return phoenix_read_reg(priv->mmio, reg);
+}
+
+int rmi_mac_get_inf_idx(char *infname)
+{
+int i = 0;
+struct net_device *dev = NULL;
+u32  rc = -1; 
+  for( i= 0 ; i < PHOENIX_MAX_MACS ; i++) {
+        if(!strncmp( infname, dev[i].name, sizeof(infname))) {
+            rc = i;
+           break;
+        }
+    }
+   return rc; 
+}
+
+int rmi_macreg_clr_set(int inf, u32 reg, u32 val, u32 mask)
+{
+struct driver_data *priv = NULL;
+struct net_device *dev = NULL;
+u32 curr_val = 0;
+ 
+    dev = dev_mac[inf];
+
+    if (!dev) 
+         return -1;
+ 
+   	priv = netdev_priv(dev);
+    curr_val = phoenix_read_reg(priv->mmio, reg) & (~mask);
+//    printk("reg %x curval %x reg %x\n", reg, curr_val, phoenix_read_reg(priv->mmio,reg));
+//    printk("wr reg %x curval %x val %x mask %x\n", reg, curr_val| (val& mask), val , mask);
+    phoenix_write_reg(priv->mmio, reg, curr_val|(val & mask));
+    
+    //printk("reg %x rdval %x\n", reg, phoenix_read_reg(priv->mmio,reg));
+    return 0;
+}
+void rmi_macreg_set_all(u32 reg, u32 val,u32 mask)
+{
+int i = 0;
+
+    for( i = 0; i < PHOENIX_MAX_MACS; i++) {
+        rmi_macreg_clr_set(i, reg, val, mask);        
+        //rmi_macreg_set(i, reg, val);        
+    }
+}
+void rmi_macreg_clr_set_all(u32 reg, u32 val,u32 mask)
+{
+int i = 0;
+
+    for( i = 0; i < PHOENIX_MAX_MACS; i++) {
+        rmi_macreg_clr_set(i, reg, val, mask);        
+//        rmi_macreg_set(i, reg, val);        
+    }
+}
+void dump_all_interface(unsigned int reg)
+{
+int i = 0;
+struct net_device *dev;
+struct driver_data *priv;
+u32 curr_val = 0; 
+       
+    for( i = 0; i < PHOENIX_MAX_MACS; i++) {
+
+        dev = dev_mac[i];
+           if (!dev) 
+                continue; 
+     	priv = netdev_priv(dev);
+        curr_val = phoenix_read_reg(priv->mmio,reg);
+//        printk("interface %x    val %x name %s\n", priv->mmio,  curr_val, dev->name); 
+    }
+
+}
+void rmi_register_ptp_ts_fp(void(*fp)(u32, u32,ktime_t *, u32))
+{
+    printk("register ptp\n");
+    p_ptp_set_ts = fp;
+}
+void rmi_clr_ptp_ts_fp(void){
+    p_ptp_set_ts = NULL;
+}
+EXPORT_SYMBOL(rmi_macreg_set_all);
+EXPORT_SYMBOL(dump_all_interface);
+EXPORT_SYMBOL(rmi_register_ptp_ts_fp);
+#endif
+module_init(rmi_phnx_mac_init_module);
+module_exit(rmi_phnx_mac_exit_module);
+
+/*************************************************************************
+ * TODO:
+ *     o Currently, if Tx completes do not come back, Tx hangs for ever. Though it is good
+ *       for debugging, there should be a timeout mechanism.
+ *     o Right now, all cpu-threads across cpus are serialized for transmitting
+ *       packets. However, message_send is "atomic", hence all of them should
+ *       transmit without contending for the lock. some like per-cpu, per device lock 
+ *       and handling tx complete on the cpu that did the transmit
+ *     o use fetchadd for stat variable. currently, it not even atomic
+ *************************************************************************/
diff --git a/drivers/net/phoenix_rmik.c b/drivers/net/phoenix_rmik.c
new file mode 100644
index 0000000..a14fb18
--- /dev/null
+++ b/drivers/net/phoenix_rmik.c
@@ -0,0 +1,706 @@
+/*********************************************************************
+
+  Copyright 2003-2008 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/errno.h>
+#include <linux/fcntl.h>
+#include <linux/in.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/inet.h>
+#include <linux/etherdevice.h>
+#include <linux/netdevice.h>
+#include <linux/inetdevice.h>
+#include <linux/skbuff.h>
+#include <linux/autoconf.h>
+#include <asm/system.h>
+#include <asm/io.h>
+#include <asm/cache.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/config_net.h>
+#include <asm/rmi/phoenix_mac.h>
+#include <rmicrf/types.h>
+#include <rmicrf/api.h>
+#include <rmicrf/eventdefs.h>
+#include <rmicrf/clpool.h>
+#include <asm/rmi/linux_crf.h>
+
+#include <net/netevent.h>
+#include <net/neighbour.h>
+#include <linux/route.h>
+#include <net/ip_fib.h>
+
+
+extern struct net_device *dev_mac_type[][PHOENIX_MAX_MACS];
+extern void mac_stats_update(int pkts, struct sk_buff *skb);
+extern struct net_device  *spi4_dev[];
+extern void rmi_phnx_mac_msgring_handler(int bucket, int size, int code,
+				  int stid, struct msgrng_msg *msg,
+				  void *data);
+
+static int rmik_net_events_reg = 0;
+struct rmi_cluster *rmi_pkt_pool = NULL;
+#define RMI_SPI4_MAX_PORTS 20
+#define RMI_SPI4_MAX_SLOTS 2
+
+void rmik_cpu_to_cpu_pkt_msgring_handler(int size, struct msgrng_msg *msg)
+{
+	unsigned long addr;
+	__u32 length;
+	int port, type, stid;
+	struct sk_buff *skb = NULL; 
+	int fbstid = 0x0;
+	rmi_physaddr_t physaddr;
+	struct net_device   *dev;
+	extern struct net_device_cfg phnx_net_dev_cfg;
+	struct port_cfg *port_cfg;
+	struct net_device_cfg *net_cfg = &phnx_net_dev_cfg;
+	struct rmi_event_packet_fw_msg *rx_pkt = rmi_addr_to_ptr(msg);
+
+	type =  rx_pkt->fwinfo.ptype;
+	fbstid = rx_pkt->fwinfo.fbstid;
+	port = rx_pkt->pktinfo.fields.fwport;
+	physaddr = msg->msg1 & 0xffffffffe0ULL;
+	addr = (unsigned long)bus_to_virt(physaddr);
+	length = rx_pkt->pktinfo.fields.length;
+
+	if(length == 0x0)  {
+		printk("Invalid length 0 packet received \n");
+		goto err_exit;
+	}
+		
+	/*
+	 * Do nothing during the boot.
+	 */
+	if (system_state != SYSTEM_RUNNING) {
+		printk("Invalid system state pkt received \n");
+		goto err_exit;
+	}
+
+#if 0
+	printk("rmi_phnx_dom_msgring_handler ingress port=%d type=%d fbstid=%d, msg=%llx:%llx\n", 
+				port, type, fbstid, msg->msg0, msg->msg1);
+#endif
+
+	switch(type) {
+		case RMI_GMAC0 :
+			dev = dev_mac_type[TYPE_GMAC][port];
+			port_cfg = &net_cfg->gmac_port[port];
+			stid = MSGRNG_STNID_GMAC0;
+			break; 
+		case RMI_GMAC1 :
+			dev = dev_mac_type[TYPE_GMAC][port + PHOENIX_GMAC_PORTS_PER_CTRL];
+			port_cfg = &net_cfg->gmac_port[port + PHOENIX_GMAC_PORTS_PER_CTRL];
+			stid = MSGRNG_STNID_GMAC1;
+			break; 
+		case RMI_XGS0  :
+			dev = dev_mac_type[TYPE_XGMAC][0];
+			if(spi4_dev[port] != NULL)
+				dev = spi4_dev[port];
+			stid = MSGRNG_STNID_XGS0FR;
+			port_cfg = &net_cfg->xgs_port[0];
+			break;
+		case RMI_XGS1  :
+			port = port + RMI_SPI4_MAX_PORTS / RMI_SPI4_MAX_SLOTS;
+			dev = dev_mac_type[TYPE_XGMAC][1];
+			if(spi4_dev[port] != NULL)
+				dev = spi4_dev[port];
+			stid = MSGRNG_STNID_XGS1FR;
+			port_cfg = &net_cfg->xgs_port[1];
+			break;
+		default:
+			printk("Unknown type\n");
+			goto err_exit;
+	}
+
+	if(dev == 0) {
+		printk("[%s] - no dev\n", __FUNCTION__);
+		goto err_exit;
+	}
+
+	if(MSGRNG_OWN(port_cfg->cfg_flag) == 0) {
+		/*
+		 * Allocate an skbuff, initialize it, and copy the data to it.
+		 */
+		skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE, GFP_ATOMIC);
+		if (!skb) {
+			printk("[%s] - no skbuff\n", __FUNCTION__);
+			goto err_exit;
+		}
+		skb->dev = dev;
+
+		length = length - (BYTE_OFFSET + MAC_CRC_LEN);
+		skb_put(skb, length);
+		memcpy(skb->data, (char *)addr + 2, length);
+
+		if(rmik_queue_pkt_mem(fbstid, physaddr) < 0)
+			rmi_phnx_drop_message_unowned(fbstid, physaddr, 1);
+
+		#if 0
+		{
+			int i = 0;
+			printk("[%s] Rx Packet: length=%d\n", dev->name, length);
+			for (i = 0; i < 64; i++) {
+				printk("%02x ", skb->data[i]);
+				if (i && (i % 16) == 0)
+					printk("\n");
+			}
+			printk("\n");
+		}
+		#endif
+
+		skb->protocol = eth_type_trans(skb, skb->dev);
+		/*
+		 * Increment the driver stats counters.
+		 */
+		mac_stats_update(1, skb);
+		/*
+		 * Queue the packet to the upper layer.
+		 */
+		netif_rx(skb);
+		return;
+	} else {
+		msg->msg0 = msg->msg1;
+		size = size - 1;
+		/* printk("calling mac msgring handler size=%d stid=%d\n", size, stid); */
+		return rmi_phnx_mac_msgring_handler(0 /* bucket ignored */, size, 0 /* code ignored */, stid, msg, NULL);
+	}
+
+	err_exit:
+		rmi_phnx_drop_message_unowned(fbstid, physaddr, 1);
+		if(skb != NULL)
+			kfree_skb(skb);
+	return;
+
+}
+
+void rmik_config_pde(int type, int instance, phoenix_reg_t *base)
+{
+	uint32_t *pde_addr;
+	int rv;
+	int j, off, len;
+	uint64_t pde_bkt_map = 0ULL;
+
+	if(!rmik_en)
+		return;
+
+	if(type == TYPE_GMAC) {
+		instance = instance < PHOENIX_GMAC_PORTS_PER_CTRL ? 0 : PHOENIX_GMAC_PORTS_PER_CTRL;
+		rv = fdt_get_gmac_pde_reginfo(instance, &pde_bkt_map);
+	} else if(type == TYPE_XGMAC)
+		rv = fdt_get_xgmac_pde_reginfo(instance, &pde_bkt_map);
+	else if(type == TYPE_SPI4)
+		rv = fdt_get_spi4_pde_reginfo(instance, &pde_bkt_map);
+	else
+		return ;
+		
+	if(rv == 0 )
+		return;
+	pde_addr = rmi_addr_to_ptr(rv);
+	while(1) {
+		base =  (phoenix_reg_t *)(unsigned long)(int)((pde_addr[0] >> 12) << 12);
+        off = pde_addr[0] & 0xfff;
+        len =   pde_addr[1];
+
+
+		pde_addr = pde_addr + 2;
+		if(len == 0)
+			break;
+		for(j = 0; j < len; j++, off++) {
+			phoenix_write_reg(base, off, *pde_addr++);
+		}
+	}
+	return;
+}
+
+uint64_t rmik_get_pde_bktmap(int type, int instance)
+{
+	uint64_t pde_bkt_map = 0ULL;
+
+	if(!rmik_en)
+		return pde_bkt_map;
+
+	if(type == TYPE_GMAC) {
+		instance = instance < PHOENIX_GMAC_PORTS_PER_CTRL ? 0 : PHOENIX_GMAC_PORTS_PER_CTRL;
+		fdt_get_gmac_pde_reginfo(instance, &pde_bkt_map);
+	} else if(type == TYPE_XGMAC)
+		fdt_get_xgmac_pde_reginfo(instance, &pde_bkt_map);
+	else if(type == TYPE_SPI4)
+		fdt_get_spi4_pde_reginfo(instance, &pde_bkt_map);
+	
+	return pde_bkt_map;
+}
+
+
+struct work_struct rmik_replenish_work[NR_CPUS];
+uint64_t *rmik_replenish_data[NR_CPUS];
+atomic_t rmik_replenish_cnt[NR_CPUS];
+int rmik_schedule_thr = 4;
+#define RMIK_MAX_DESC_IN_QUEUE 64
+
+static void rmik_frin_replenish(struct work_struct *args /* ignored */ )
+{
+	int cpu;
+	atomic_t *rep_cnt;
+	unsigned long msgrng_flags;
+	int i, fbstid, cnt;
+	uint64_t *data, physaddr;
+
+	msgrng_access_enable(msgrng_flags);
+
+	cpu = hard_smp_processor_id();
+	rep_cnt =  &rmik_replenish_cnt[cpu];
+	data = rmik_replenish_data[cpu];
+
+	/* printk("[%d]rmik_frin_replenish[%d] \n", cpu, atomic_read(rep_cnt)); */
+
+	if ((cnt = atomic_read(rep_cnt)) < 0) {
+		printk("Error replenish cnt becomes negative\n");
+		msgrng_access_disable(msgrng_flags);
+		return;
+	}
+	if (cnt == 0) {
+		msgrng_access_disable(msgrng_flags);
+		return;
+	}
+
+
+	for(i = 0; i < (cnt * 2); i = i + 2) {
+		fbstid = data[i];
+		physaddr = data[i + 1];
+		rmi_phnx_drop_message_unowned(fbstid, physaddr, 0);
+	}
+	atomic_set(rep_cnt, 0);
+	msgrng_access_disable(msgrng_flags);
+}
+
+void rmik_init_replenish_work(int numdesc)
+{
+	int i;
+	if(numdesc > NR_CPUS)
+		rmik_schedule_thr = numdesc / NR_CPUS;
+	if(rmik_schedule_thr > 16)
+		rmik_schedule_thr = 16;
+
+	for(i = 0; i < NR_CPUS; i++) {
+		INIT_WORK(&rmik_replenish_work[i], rmik_frin_replenish);
+		rmik_replenish_data[i] = kmalloc(RMIK_MAX_DESC_IN_QUEUE * sizeof(uint64_t), GFP_KERNEL);
+		if(rmik_replenish_data[i] == NULL)
+			panic("Invalid mem in rmik replenish\n");
+	}
+	return;
+}
+
+int rmik_queue_pkt_mem(uint32_t fbstid, uint64_t physaddr)
+{
+	int cpu, i;
+	unsigned long msgrng_flags;
+	atomic_t *rep_cnt;
+	uint64_t *data;
+
+
+	msgrng_access_enable(msgrng_flags);
+	cpu = hard_smp_processor_id();
+    rep_cnt =  &rmik_replenish_cnt[cpu];
+
+	/* printk(" [cpu%d]rmik_queue_pkt_mem[cnt%d, fbid%d] \n", cpu, atomic_read(rep_cnt), fbstid);*/
+	data = rmik_replenish_data[cpu];
+	if(((data == NULL) || (i = atomic_read(rep_cnt)) >= RMIK_MAX_DESC_IN_QUEUE / 2)) {
+		msgrng_access_disable(msgrng_flags);
+		return -1;
+	}
+	data[i * 2] = fbstid;
+	data[i * 2 + 1] = physaddr;
+	atomic_inc(rep_cnt);
+	msgrng_access_disable(msgrng_flags);
+
+	if(atomic_read(rep_cnt) >= rmik_schedule_thr) {
+		if(rmik_replenish_work[cpu].func == NULL)
+			return -1;
+		schedule_work(&rmik_replenish_work[cpu]);
+	}
+	
+	return 0;
+}
+
+/*
+ * Event handlers 
+ */
+
+static int rmik_inetaddr_event(struct notifier_block *, unsigned long, void *);
+static int rmik_net_event(struct notifier_block *, unsigned long, void *);
+static struct notifier_block rmik_inetaddr_notifier = {
+	.notifier_call = rmik_inetaddr_event
+};
+
+static struct notifier_block rmik_net_notifier = {
+	.notifier_call = rmik_net_event
+};
+
+static int get_ptype_from_dev(struct net_device *netdev, int *ptype, int *instance, char *rname)
+{
+	int spi4_port_per_ctrl = RMI_SPI4_MAX_PORTS / RMI_SPI4_MAX_SLOTS;
+	int nettype, port;
+
+	for(nettype = 0; nettype < MAX_NET_TYPES; nettype++) {
+		if(nettype == TYPE_GMAC || nettype == TYPE_XGMAC) {
+			for(port = 0; port < PHOENIX_MAX_MACS; port++) {
+				if(netdev == dev_mac_type[nettype][port])
+					goto found;
+			}
+		} else  {
+			for(port = 0; port < RMI_SPI4_MAX_PORTS; port++) {
+				if(netdev == spi4_dev[port]) 
+					goto found;
+			}
+		}
+	}
+	return -1;
+			
+
+found:
+	switch(nettype) {
+		case TYPE_GMAC :
+			if(port >= PHOENIX_GMAC_PORTS_PER_CTRL)  {
+				*ptype = RMI_GMAC1;
+				*instance = port - PHOENIX_GMAC_PORTS_PER_CTRL;
+				strcpy(rname, "gmac-block@1");
+			} else {
+				*ptype = RMI_GMAC0;
+				*instance = port;
+				strcpy(rname, "gmac-block@0");
+			}
+			break;
+		case TYPE_XGMAC: 
+			*instance = 0;
+			if(port == 0) {
+				*ptype = RMI_XGS0;
+				strcpy(rname, "xgmac@0");
+
+			} else {
+				*ptype = RMI_XGS1;
+				strcpy(rname, "xgmac@1");
+			}
+			break;
+		case TYPE_SPI4:
+			if(port < spi4_port_per_ctrl) {
+				*ptype = RMI_XGS0;
+				*instance = port;
+				strcpy(rname, "spi4@0");
+			} else {
+				*ptype = RMI_XGS1;
+				*instance = port - spi4_port_per_ctrl;
+				strcpy(rname, "spi4@1");
+			}
+			break;
+	}
+	return 0;
+}
+
+int send_interface_state_change(struct net_device *netdev, uint32_t myip, int msgtype)
+{
+	struct rmi_event_eth_ifc_msg *ifc;	
+	struct rmi_cluster *cl;
+	struct rmi_event_simple_msg smsg;
+	int dom, ptype, instance, i;
+	char rname[RMI_MAX_NAMELEN];
+	uint64_t dom_map;
+	uint64_t *ip_mac, tmac = 0;
+
+	if(get_ptype_from_dev(netdev, &ptype, &instance, rname) != 0)
+		return NOTIFY_DONE;
+
+
+	if(rmi_get_event_recipients(rname, &dom_map) < 0) 
+		return NOTIFY_DONE;
+	
+	/* No receivng domains */
+	if(dom_map == 0ULL)
+		return NOTIFY_DONE;
+	dom_map &= ~(1ULL << rmi_this_domain->id);
+
+	for(dom = 0; dom < RMI_MAX_DOMAINS; dom++) {
+		if(!((1ULL << dom) & dom_map))
+			continue;
+		if((cl = rmi_clpool_getref(dom, RMI_PKT_POOL_NAME)) == NULL) {
+			printk("No pool found for domain %d\n", dom);
+			rmi_send_pool_event(dom, RMI_EVENT_MSG_CL_POOL_NOT_FOUND, 0ULL);
+			continue;
+		}
+
+		if((ifc = rmi_cluster_alloc(cl, 0)) == NULL)  {
+			printk("Cluster alloc failed %d\n", dom);
+			rmi_send_pool_event(dom, RMI_EVENT_MSG_CL_POOL_EMPTY, 0ULL);
+			rmi_clpool_putref(cl);
+			continue;
+		}
+
+		memset(ifc, 0, sizeof(*ifc));
+		ifc->ptype = ptype;
+		ifc->port = instance;
+		ifc->count = 1;
+		ip_mac = rmi_addr_to_ptr(ifc->data);
+		ip_mac[0] = myip;
+		ip_mac[1] = 0ULL;
+		for(i = 5; i >= 0 ; i--) {
+			tmac = (uint64_t)(uint32_t)netdev->dev_addr[5 - i];
+			ip_mac[1] |= (tmac << (i * 8)); 
+		}
+
+		smsg.msgtype = msgtype;
+		smsg.domid = rmi_this_domain->id;
+		smsg.arg = rmi_ptr_to_addr(ifc);
+
+		if(rmi_send_event(dom, RMI_EVENT_VETH_INFO, sizeof(smsg),
+						rmi_addr_to_ptr(&smsg)) < 0) {
+			printk("Critical : Event failed to send for dom %d\n", dom);
+			rmi_cluster_free(cl, ifc);
+		}
+		rmi_clpool_putref(cl);
+	}
+	return NOTIFY_DONE;
+}
+
+struct rmi_event_eth_ifc_msg *update_arp_entry(struct net_device *netdev, 
+				uint32_t ipaddr, uint8_t *mac_addr, int msgtype)
+{
+	int i;
+	uint64_t *ip_mac, tmac;
+	struct rmi_cluster *cl;
+	struct rmi_event_eth_ifc_msg *ifc;	
+	struct rmi_event_simple_msg smsg;
+	int dom, ptype, instance;
+	char rname[RMI_MAX_NAMELEN];
+	uint64_t dom_map;
+
+	
+	if(get_ptype_from_dev(netdev, &ptype, &instance, rname) != 0)
+		return NOTIFY_DONE;
+
+
+	if(rmi_get_event_recipients(rname, &dom_map) < 0) 
+		return NOTIFY_DONE;
+	
+	/* No receivng domains */
+	if(dom_map == 0ULL)
+		return NOTIFY_DONE;
+	dom_map &= ~(1ULL << rmi_this_domain->id);
+
+	for(dom = 0; dom < RMI_MAX_DOMAINS; dom++) {
+		if(!((1ULL << dom) & dom_map))
+			continue;
+		if((cl = rmi_clpool_getref(dom, RMI_PKT_POOL_NAME)) == NULL) {
+			printk("No pool found for domain %d\n", dom);
+			rmi_send_pool_event(dom, RMI_EVENT_MSG_CL_POOL_NOT_FOUND, 0ULL);
+			continue;
+		}
+
+		if((ifc = rmi_cluster_alloc(cl, 0)) == NULL)  {
+			printk("Cluster alloc failed %d\n", dom);
+			rmi_send_pool_event(dom, RMI_EVENT_MSG_CL_POOL_EMPTY, 0ULL);
+			rmi_clpool_putref(cl);
+			continue;
+		}
+
+		memset(ifc, 0, sizeof(*ifc));
+		ifc->count = 1;
+		ifc->ptype = ptype;
+		ifc->port = instance;
+
+		ip_mac = rmi_addr_to_ptr(ifc->data);
+		ip_mac[0] = ipaddr;
+		ip_mac[1] = 0ULL;
+		for(i = 5; i >= 0 ; i--) {
+			tmac = (uint64_t)(uint32_t)mac_addr[5 - i];
+			ip_mac[1] |= (tmac << (i * 8)); 
+		}
+
+		smsg.msgtype = msgtype;
+		smsg.domid = rmi_this_domain->id;
+		smsg.arg = rmi_ptr_to_addr(ifc);
+
+
+		if(rmi_send_event(dom, RMI_EVENT_VETH_INFO, sizeof(smsg),
+					rmi_addr_to_ptr(&smsg)) < 0) {
+			printk("Critical : Event failed to send for dom %d\n", dom);
+			rmi_cluster_free(cl, ifc);
+		}
+		rmi_clpool_putref(cl);
+	}
+
+	return NOTIFY_DONE;
+}
+
+/**
+ * rmik_inetaddr_event
+ */
+static int rmik_inetaddr_event(struct notifier_block *notifier,
+		unsigned long event, void *ptr)
+{
+	struct in_ifaddr *ifa = ptr;
+	struct net_device *netdev;
+	unsigned int addr;
+	unsigned int mask;
+	       
+	if(!rmik_net_events_reg)
+		return NOTIFY_DONE;
+	
+	netdev = ifa->ifa_dev->dev;
+	addr = ntohl(ifa->ifa_address);
+	mask = ntohl(ifa->ifa_mask);
+
+	/*printk("rmik inetaddr_event: ip address " NIPQUAD_FMT
+			", netmask " NIPQUAD_FMT ".\n",
+			HIPQUAD(addr), HIPQUAD(mask)); */
+
+	switch (event) {
+		case NETDEV_DOWN:
+			/* printk("event:DOWN \n"); */
+			send_interface_state_change(netdev, addr, RMI_EVENT_MSG_IFC_DOWN);
+			return NOTIFY_OK;
+
+		case NETDEV_UP:
+			/*printk("event:UP \n"); */
+			send_interface_state_change(netdev, addr, RMI_EVENT_MSG_IFC_UP);
+			return NOTIFY_OK;
+
+		default:
+			break;
+	}
+	return NOTIFY_DONE;
+}
+
+
+/**
+ * nes_net_event
+ */
+static int rmik_net_event(struct notifier_block *notifier,
+		unsigned long event, void *ptr)
+{
+	struct neighbour *neigh = ptr;
+	struct net_device *netdev = neigh->dev;
+
+	if(!rmik_net_events_reg)
+		return NOTIFY_DONE;
+	
+	switch (event) {
+		case NETEVENT_NEIGH_UPDATE:
+			/* printk("Neighbour update\n");  */
+			if (neigh->nud_state & NUD_VALID) {
+				update_arp_entry(netdev, ntohl(*(__be32 *)neigh->primary_key), neigh->ha, RMI_EVENT_MSG_IFC_ARP_ADD);
+				return NOTIFY_OK;
+			} else {
+				update_arp_entry(netdev, ntohl(*(__be32 *)neigh->primary_key), neigh->ha, RMI_EVENT_MSG_IFC_ARP_DEL);
+				return NOTIFY_OK;
+			}
+			break;
+		default:
+			printk("NETEVENT_ %lu undefined\n", event);
+			break;
+	}
+
+	return NOTIFY_DONE;
+}
+
+static void create_pkt_pool(void)
+{
+	int num_units = 128;
+	static int pkt_pool_init_done = 0;
+
+	if(pkt_pool_init_done == 0) {
+		if(rmi_clpool_create(RMI_PKT_POOL_NAME, num_units, RMI_PKT_POOL_UNIT_SIZE, RMI_MALLOC_UNMAPPED) != 0) {
+			printk("Pktpool create failed\n");
+			return;
+		}
+		if((rmi_pkt_pool = rmi_clpool_getref(rmi_this_domain->id, RMI_PKT_POOL_NAME)) == NULL) {
+			printk("No pool found for domain %d\n", rmi_this_domain->id);
+		}
+		if(rmi_pkt_pool)
+			rmi_clpool_putref(rmi_pkt_pool);
+
+		pkt_pool_init_done = 1;
+	}
+}
+
+static void register_net_events(char *rname)
+{
+
+#if 0
+	rmi_atomic_t dom_map;
+	
+	if((rmi_get_event_recipients(rname, &dom_map) < 0) || (dom_map == 0)) 
+		return ;
+#endif
+	
+	if(rmik_net_events_reg == 0) {
+		rmik_net_events_reg = 1;
+		register_inetaddr_notifier(&rmik_inetaddr_notifier);
+		register_netevent_notifier(&rmik_net_notifier);
+	}
+
+	return;
+}
+
+void rmik_register_net_events(void)
+{
+	extern struct net_device_cfg phnx_net_dev_cfg;
+	struct net_device_cfg *net_cfg = &phnx_net_dev_cfg;
+
+	if (!rmik_en)
+		return;
+
+	create_pkt_pool();
+
+	if (rmik_net_events_reg == 0) {
+		if(net_cfg->gmac_port[0].cfg_flag != 0)
+			register_net_events("gmac-block@0");
+
+		if(net_cfg->gmac_port[RMI_GMAC_PORTS_PER_CTRL].cfg_flag != 0)
+			register_net_events("gmac-block@1");
+
+		if(net_cfg->xgs_port[0].cfg_flag != 0) {
+			if(net_cfg->xgs_type[0] == TYPE_SPI4)
+				register_net_events("spi4@0");
+			else
+				register_net_events("xgmac@0");
+		}
+
+		if(net_cfg->xgs_port[1].cfg_flag != 0) {
+			if(net_cfg->xgs_type[1] == TYPE_SPI4)
+				register_net_events("spi4@1");
+			else
+				register_net_events("xgmac@1");
+		}
+
+	}
+}
diff --git a/drivers/net/phoenix_user_mac.c b/drivers/net/phoenix_user_mac.c
new file mode 100644
index 0000000..2cd002b
--- /dev/null
+++ b/drivers/net/phoenix_user_mac.c
@@ -0,0 +1,1212 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/poll.h>
+#include <linux/workqueue.h>
+#include <linux/proc_fs.h>
+#include <linux/cpumask.h>
+#include <linux/hugetlb.h>
+#include <linux/bootmem.h>
+
+#include <asm/uaccess.h>
+#include <asm/mman.h>
+#include <asm/atomic.h>
+#include <asm/smp.h>
+#include <asm/page.h>
+
+#include <asm/rmi/pic.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/debug.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/devices.h>
+#include <asm/rmi/phoenix_mac.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/gpio.h>
+#include <asm/rmi/proc.h>
+#include <user/rmi/phnx_user_mac.h>
+#include <asm/rmi/linux_crf.h>
+
+#include <asm/mach-rmi/mmu.h>
+
+#define MB(x)	(x<<20)
+#define	KB(x)	(x<<10)
+#ifdef dbg_msg
+#undef dbg_msg
+#endif
+#define dbg_msg(fmt, args...) //printk(fmt, ##args)
+#define Message(a, b...) //printk("\nFunc[%s], Line[%d], "a"\n",__FUNCTION__,__LINE__,##b)
+
+/* this flag will be set by rmi spi4 driver, it indicates
+   whether spi4 daughter cards are present on the board or not
+*/
+#ifdef CONFIG_PHOENIX_SPI4
+extern unsigned int g_spi4_card_flag;
+extern void spi4_enable_tx_rx(unsigned int  *mmio);
+extern void spi4_disable_tx_rx(unsigned int  *mmio);
+#else /* CONFIG_PHOENIX_SPI4 */
+static unsigned int g_spi4_card_flag;
+#endif /* CONFIG_PHOENIX_SPI4 */
+
+//#define USER_MAC_LOOPBACK
+extern int xlr_loader_support, xlr_loader_sharedcore;
+
+extern void *phoenix_psb_shm;
+extern unsigned long phoenix_psb_shm_size;
+
+static unsigned long long phoenix_psb_shm_paddr;
+static int user_mac_major;
+struct user_mac_data *user_mac;
+struct user_mac_kernal_data user_mac_krnl_data;
+/* use per cpu data structures for the Queues below */
+extern int xlr_hybrid;
+extern struct proc_dir_entry *rmi_root_proc;
+
+#define USER_MAC_TX_THRESHOLD 1
+
+#define MAC_CRC_LEN 4
+#define BYTE_OFFSET 2
+#define MAC_PREPAD_LEN 32
+
+#define MAC_DEV_NULL_BUCKET 127
+
+struct usermac_priv
+{
+	int num_desc;
+	int type;
+	phoenix_reg_t *mmio;	
+	void*	frin_spill;
+	void*	frout_spill;
+	void*	class_0_spill;
+	void*	class_1_spill;
+	void*	class_2_spill;
+	void*	class_3_spill;
+};
+
+struct usermac_dev {
+	uint32_t gmac_list;
+	int xgmac_present;
+	int spi4_present;
+	struct usermac_priv priv[32];
+};
+
+static struct usermac_dev usermac_dev;
+static int hybrid_mem_init = 1;
+
+/*Hugetlb usermac data structures*/
+static struct page **page_array;
+static void *htlb_kvaddr = NULL;
+static phys_t htlb_kpaddr= 0ULL;
+static void user_mac_mem_init(void);
+
+
+static unsigned long long user_mac_vaddr_to_phys(void *addr)
+{
+	if(htlb_kvaddr){
+		return ((unsigned long)addr - (unsigned long)htlb_kvaddr + htlb_kpaddr);
+	}else{
+		return __pa(addr);
+	}
+}
+
+static __inline__ int user_mac_ptr2index(unsigned long long addr)
+{
+	int index = (addr - user_mac_vaddr_to_phys(user_mac->pkt_data)) / USER_MAC_PKT_BUF_SIZE;
+
+	if (index < 0 || index >= MAX_USER_MAC_PKTS) {
+		printk("[%s]: bad index=%d, addr=%llx, pkt_data=%p\n",
+		       __FUNCTION__, index, addr, &user_mac->pkt_data);
+		return -1;
+	}
+	return index;
+}
+
+#ifdef MAC_TX_DESC_ALIGNMENT
+#undef MAC_TX_DESC_ALIGNMENT
+#endif
+#define MAC_TX_DESC_ALIGNMENT (SMP_CACHE_BYTES + MAC_PREPAD_LEN - 1)
+
+#define CTRL_RES0           0
+#define CTRL_RES1           1
+#define CTRL_REG_FREE       2
+#define CTRL_CONT           4
+#define CTRL_EOP            5
+#define CTRL_START          6
+#define CTRL_SNGL           7
+
+static __inline__ int user_mac_send_frin_num_xgs_pkts(void)
+{
+	int num_xgmac_pkts = MAX_USER_MAC_FRIN_PKTS / 2.5;
+
+	return num_xgmac_pkts;
+}
+
+static __inline__ int user_mac_send_frin_num_gmac_pkts(void)
+{
+	return user_mac_send_frin_num_xgs_pkts() / 2;
+}
+
+static __inline__ int user_mac_send_frin_is_desc_gmac(int index)
+{
+	int start_index = 0, end_index = 0;
+
+	start_index = 0;
+	end_index = start_index + user_mac_send_frin_num_gmac_pkts();
+	return ( (index >= start_index) && (index < end_index) ) ? 1 : 0;
+}
+
+static __inline__ int user_mac_send_frin_is_desc_xgs0(int index)
+{
+	int start_index = 0, end_index = 0;
+
+	start_index = user_mac_send_frin_num_gmac_pkts();
+	end_index = start_index + user_mac_send_frin_num_xgs_pkts();
+	return ( (index >= start_index) && (index < end_index) ) ? 1 : 0;
+}
+
+static __inline__ int user_mac_send_frin_is_desc_xgs1(int index)
+{
+	int start_index = 0, end_index = 0;
+
+	start_index = user_mac_send_frin_num_gmac_pkts() + user_mac_send_frin_num_xgs_pkts();
+	end_index = start_index + user_mac_send_frin_num_xgs_pkts();
+	return ( (index >= start_index) && (index < end_index) ) ? 1 : 0;
+}
+
+static __inline__ int user_mac_send_frin_stid(int index)
+{
+	if (is_xls()) {
+		/* If only gmac-block 0 is active , Or only gmac-block1 is active */
+		if((usermac_dev.gmac_list & 0x0f) && (!(usermac_dev.gmac_list & 0xf0)))
+			return MSGRNG_STNID_GMAC0_FR;
+		else if((usermac_dev.gmac_list & 0xf0) && (!(usermac_dev.gmac_list & 0x0f)))
+			return MSGRNG_STNID_GMAC1_FR;
+		if((index >= 0) && (index < (MAX_USER_MAC_FRIN_PKTS / 2)))
+			return MSGRNG_STNID_GMAC0_FR;
+		return MSGRNG_STNID_GMAC1_FR;
+	}
+	/* xlr case */
+	if(usermac_dev.gmac_list & 0x0f) {
+		switch(usermac_dev.xgmac_present | usermac_dev.spi4_present) {
+			case 0x03:
+				if (user_mac_send_frin_is_desc_gmac(index)) return MSGRNG_STNID_GMACRFR_0;
+				if (user_mac_send_frin_is_desc_xgs0(index)) return MSGRNG_STNID_XMAC0RFR;
+				if (user_mac_send_frin_is_desc_xgs1(index)) return MSGRNG_STNID_XMAC1RFR;
+				return MSGRNG_STNID_GMACRFR_0;
+			case 0x01:
+				if((index >= 0) && (index < (MAX_USER_MAC_FRIN_PKTS / 4)))
+					return MSGRNG_STNID_GMACRFR_0;
+				return MSGRNG_STNID_XMAC0RFR;
+			case 0x02:
+				if((index >= 0) && (index < (MAX_USER_MAC_FRIN_PKTS / 4)))
+					return MSGRNG_STNID_GMACRFR_0;
+				return MSGRNG_STNID_XMAC1RFR;
+			default:
+				return MSGRNG_STNID_GMACRFR_0;
+		}
+	} else {
+		/* xgmac should be present, this function should not be called when
+                   all the gmac & xgmac stations are not owned by linux */
+		switch(usermac_dev.xgmac_present | usermac_dev.spi4_present) {
+			case 0x03:
+				if((index >= 0) && (index < (MAX_USER_MAC_FRIN_PKTS / 2)))
+					return MSGRNG_STNID_XMAC0RFR;
+				return MSGRNG_STNID_XMAC1RFR;
+			case 0x01:
+				return MSGRNG_STNID_XMAC0RFR;
+			case 0x02:
+				return MSGRNG_STNID_XMAC1RFR;
+			default:
+				return -1;
+
+
+		}
+	}
+}
+
+static void user_mac_send_frin(void)
+{
+	struct msgrng_msg msg;
+	struct packet_data *packet_data = user_mac->pkt_data;
+	int i = 0;
+	int cnt[4] = { 0, 0, 0, 0 };
+	uint64_t addr = 0;
+	unsigned long mflags = 0;
+	int stid = 0;
+	int host_gen_num_pkts = (MAX_USER_MAC_PKTS - MAX_USER_MAC_FRIN_PKTS) / 32;
+
+	if(usermac_dev.gmac_list == 0 && usermac_dev.xgmac_present == 0 &&
+			usermac_dev.spi4_present == 0)
+		return;
+
+	
+	msgrng_flags_save(mflags);
+
+	for (i = 0; i < MAX_USER_MAC_FRIN_PKTS; i++) {
+		addr = user_mac_vaddr_to_phys(&packet_data[i].data);
+		user_mac->pkt_desc[i].free = 0;
+
+		msg.msg0 = (uint64_t) addr & ~(SMP_CACHE_BYTES - 1);
+		msg.msg1 = msg.msg2 = msg.msg3 = 0;
+
+		stid = user_mac_send_frin_stid(i);
+
+		if (usermac_dev.spi4_present){
+            		if((stid == MSGRNG_STNID_XMAC0RFR) && (!(g_spi4_card_flag & 0x01))){
+                		/*spi4-0 card is not present*/
+						Message("SPI4-0 Card not present - %d index not send",i);
+                		continue;
+            		}
+            		else if((stid == MSGRNG_STNID_XMAC1RFR) && (!(g_spi4_card_flag & 0x02))){
+                		/*spi4-1 card is not present*/
+						Message("SPI4-1 Card not present - %d index not send",i);
+                		continue;
+            		}
+       	}
+
+        	do {
+            		if (!message_send_retry(1, MSGRNG_CODE_MAC, stid, &msg)){
+							if(stid == MSGRNG_STNID_XMAC0RFR){
+								Message("Index %d, Phys Addr [%#llx] sent to Station XGMAC0",i, (unsigned long long)(addr & ~(SMP_CACHE_BYTES - 1)));
+								cnt[2]++;
+							}else if(stid == MSGRNG_STNID_XMAC1RFR){
+								Message("Index %d, Phys Addr [%#llx] sent to Station XGMAC1",i,(unsigned long long)(addr & ~(SMP_CACHE_BYTES - 1)));
+								cnt[3]++;
+							}else if(stid == MSGRNG_STNID_GMACRFR_0){
+								Message("Index %d Phys Addr [%#llx] sent to Station GMAC0",i, (unsigned long long)(addr & ~(SMP_CACHE_BYTES - 1)));
+								cnt[0]++;
+							}else if(stid == MSGRNG_STNID_GMAC1_FR){
+								Message("Index %d Phys Addr [%#llx] sent to Station GMAC1",i, (unsigned long long)(addr & ~(SMP_CACHE_BYTES - 1)));
+								cnt[1]++;
+
+							}else{
+								Message("Index %d sent to unknown station!!! %d ",i,stid);
+							}
+						   	break;
+					}
+            		printk("[%s:%d]: retrying free_desc[%d] message send to stid=%d, [status gmac0=%d xmac0=%d xmac1=%d\n", 
+                    		__FUNCTION__,
+                    		__LINE__, i, stid, cnt[0], cnt[2], cnt[3]);
+        	} while(1);
+	
+        	phnx_inc_counter(USER_MAC_FRIN);
+    	}
+	msgrng_flags_restore(mflags);
+	printk("[%s]:...done[Free descriptors gmac0=%d gmac1=%d xgmac0=%d xgmac1=%d\n", __FUNCTION__,
+				cnt[0], cnt[1], cnt[2], cnt[3]);
+
+	for (i=0; i<32; i++) {
+		user_mac->host_pkt_next_free[i] =
+			MAX_USER_MAC_FRIN_PKTS + (i * host_gen_num_pkts);
+	}
+
+	for(i=MAX_USER_MAC_FRIN_PKTS; i<MAX_USER_MAC_PKTS; i++)
+		user_mac->pkt_desc[i].free = 1;
+
+	printk
+	    ("[%s]: packet_data[first].data=%llx, packet_data[last].data=%llx\n",
+	     __FUNCTION__, user_mac_vaddr_to_phys(&packet_data[0].data),
+	     user_mac_vaddr_to_phys(&packet_data[MAX_USER_MAC_PKTS - 1].data));
+}
+
+static void user_mac_send_frin_xgmac(void)
+{
+	struct msgrng_msg msg;
+	struct packet_data *packet_data = user_mac->pkt_data;
+	int i = 0;
+	unsigned long addr = 0, mflags = 0;
+	int stid = 0;
+	int cnt[2] = {0, 0 };
+	int host_gen_num_pkts = (MAX_USER_MAC_PKTS - MAX_USER_MAC_FRIN_PKTS) / 32;
+		
+	if(usermac_dev.xgmac_present == 0 && usermac_dev.spi4_present == 0)
+		return;
+
+	msgrng_flags_save(mflags);
+
+	for (i = 0; i < MAX_USER_MAC_FRIN_PKTS; i++) {
+		
+		stid = user_mac_send_frin_stid(i);
+	
+		if(stid == MSGRNG_STNID_XMAC0RFR)
+			cnt[0]++;
+		else if( stid == MSGRNG_STNID_XMAC1RFR)
+			cnt[1]++;
+		else
+			continue;
+		
+		addr = user_mac_vaddr_to_phys(&packet_data[i].data);
+		user_mac->pkt_desc[i].free = 0;
+
+		msg.msg0 = (uint64_t) addr & ~(SMP_CACHE_BYTES - 1);
+		msg.msg1 = msg.msg2 = msg.msg3 = 0;
+
+        	do {
+            		if (!message_send_retry(1, MSGRNG_CODE_MAC, stid, &msg)) break;
+            		printk("[%s:%d]: retrying free_desc[%d] message send to stid=%d\n", 
+                    		__FUNCTION__,
+                    		__LINE__, i, stid);
+        	} while(1);
+	
+        	phnx_inc_counter(USER_MAC_FRIN);
+    	}
+	msgrng_flags_restore(mflags);
+	printk("[%s]:...done, Free descriptors xgmac0=%d xgmac1=%d\n", __FUNCTION__, cnt[0], cnt[1]);
+
+	for (i=0; i<32; i++) {
+		user_mac->host_pkt_next_free[i] =
+			MAX_USER_MAC_FRIN_PKTS + (i * host_gen_num_pkts);
+	}
+
+	for(i=MAX_USER_MAC_FRIN_PKTS; i<MAX_USER_MAC_PKTS; i++)
+		user_mac->pkt_desc[i].free = 1;
+
+	printk
+	    ("[%s]: packet_data[first].data=%llx, packet_data[last].data=%llx\n",
+	     __FUNCTION__, user_mac_vaddr_to_phys(&packet_data[0].data),
+	     user_mac_vaddr_to_phys(&packet_data[MAX_USER_MAC_PKTS - 1].data));
+}
+
+void phoenix_user_mac_update_time(void)
+{
+	if (user_mac) {
+		user_mac->time.lo++;
+		if (!user_mac->time.lo)
+			user_mac->time.hi++;
+	}else {
+		user_mac_krnl_data.time.lo++;
+		if (!user_mac_krnl_data.time.lo)
+			user_mac_krnl_data.time.hi++;
+	}
+		
+	
+}
+void phoenix_user_mac_update_ktime(void)
+{
+    if(user_mac) {
+       user_mac->ktime = current_kernel_time(); 
+     } else {
+	user_mac_krnl_data.ktime = current_kernel_time();
+	}
+
+}
+static int user_mac_open(struct inode *inode, struct file *filp)
+{
+	//printk("user_mac_open() invoked\n");
+
+	filp->private_data = NULL;
+
+	return 0;
+}
+
+static int user_mac_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	unsigned long offset = vma->vm_pgoff << PAGE_SHIFT;
+	unsigned long long shm_addr = phoenix_psb_shm_paddr;
+	unsigned long shm_size = phoenix_psb_shm_size;
+	unsigned long size = 0;
+	unsigned long vm_size = vma->vm_end - vma->vm_start;
+
+	dbg_msg
+	    ("[%s]: shm_addr=%lx, shm_size=%lx, offset = %lx, vm_start=%lx, vm_size=%lx, vm_flags=%lx, "
+	     "vm_page_prot=%lx\n", __FUNCTION__, shm_addr, shm_size, offset,
+	     vma->vm_start, vm_size, vma->vm_flags,
+	     pgprot_val(vma->vm_page_prot));
+
+	if (vma->vm_start != (unsigned long)PHNX_USER_MAC_MMAP_VIRT_START)
+		return -EINVAL;
+
+	if (!shm_addr)
+		return -ENXIO;
+
+	if (offset >= shm_size)
+		return -ESPIPE;
+
+	if (vma->vm_flags & VM_LOCKED)
+		return -EPERM;
+
+	size = shm_size - offset;
+	if (vm_size > size)
+		return -ENOSPC;
+
+	vma->vm_flags |= (VM_RESERVED | VM_IO);
+
+	if (remap_pfn_range
+	    (vma, vma->vm_start, (shm_addr >> PAGE_SHIFT), size, vma->vm_page_prot))
+		return -EAGAIN;
+
+	return 0;
+}
+
+/*****************************************************************
+ * Initialize GMAC
+ *****************************************************************/
+static void rmi_usermac_config_pde(struct usermac_priv *priv)
+{
+	int i = 0, cpu = 0, bucket = 0;
+	__u64 bucket_map = 0;
+
+	for (i = 0; i < 32; i++) {
+		if (cpu_isset(i, cpu_online_map)) {
+			cpu = cpu_logical_map(i);
+			bucket = 4 + (((cpu >> 2) << 3) | (cpu & 0x03));
+			bucket_map |= (1ULL << bucket);
+			dbg_msg("i=%d, cpu=%d, bucket = %d, bucket_map=%llx\n",
+				i, cpu, bucket, bucket_map);
+		}
+	}
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_0, (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_0 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_1, (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_1 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_2, (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_2 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_3, (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_3 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+}
+
+static void rmi_usermac_config_parser(struct usermac_priv *priv)
+{
+	/* Mark it as no classification 
+	 * The parser extract is gauranteed to be zero with no classfication
+	 */
+	
+	phoenix_write_reg(priv->mmio, R_L2TYPE_0, 0x01);
+	
+	/* configure the parser : L2 Type is configured in the bootloader */
+	/* extract IP: src, dest protocol */
+	phoenix_write_reg(priv->mmio, R_L3CTABLE,
+			  (9 << 20) | (1 << 19) | (1 << 18) | (0x01 << 16) |
+			  (0x0800 << 0));
+	phoenix_write_reg(priv->mmio, R_L3CTABLE + 1,
+			  (12 << 25) | (4 << 21) | (16 << 14) | (4 << 10));
+
+	if (xlr_user_mac_l4_extract()) {
+		/* extract TCP: src port, dest port */
+		phoenix_write_reg(priv->mmio, R_L4CTABLE, (6 << 0));
+		phoenix_write_reg(priv->mmio, R_L4CTABLE + 1,
+				  (0 << 21) | (2 << 17) | (2 << 11) | (2 << 7));
+		/* extract UDP: src port, dest port */
+		phoenix_write_reg(priv->mmio, R_L4CTABLE + 2, (17 << 0));
+		phoenix_write_reg(priv->mmio, R_L4CTABLE + 3,
+				  (0 << 21) | (2 << 17) | (2 << 11) | (2 << 7));
+	}
+}
+
+static void rmi_usermac_port_enable(struct usermac_priv *priv, int flag)
+{
+	uint32_t regval;
+	int tx_threshold = 1518;
+
+
+	phoenix_write_reg(priv->mmio, R_MAC_FILTER_CONFIG,
+		(1 << O_MAC_FILTER_CONFIG__BROADCAST_EN) |
+		(1 << O_MAC_FILTER_CONFIG__ALL_MCAST_EN) |
+		(1 << O_MAC_FILTER_CONFIG__ALL_UCAST_EN) |
+		(1 << O_MAC_FILTER_CONFIG__MAC_ADDR0_VALID));
+
+
+	if (flag) {
+
+		regval = phoenix_read_reg(priv->mmio, R_TX_CONTROL);
+		regval |= (1 << O_TX_CONTROL__TxEnable) |
+			(tx_threshold << O_TX_CONTROL__TxThreshold);
+
+		phoenix_write_reg(priv->mmio, R_TX_CONTROL, regval);
+
+		regval = phoenix_read_reg(priv->mmio, R_RX_CONTROL);
+		regval |= 1 << O_RX_CONTROL__RxEnable;
+		phoenix_write_reg(priv->mmio, R_RX_CONTROL, regval);
+
+#ifdef CONFIG_PHOENIX_SPI4
+		if(priv->type == TYPE_SPI4)
+			spi4_enable_tx_rx((uint32_t *)priv->mmio);
+#endif
+
+	
+	} else {
+
+		if(priv->type == TYPE_SPI4)
+			spi4_disable_tx_rx((uint32_t *)priv->mmio);
+
+		regval = phoenix_read_reg(priv->mmio, R_TX_CONTROL);
+		regval &= ~((1 << O_TX_CONTROL__TxEnable) |
+			    (tx_threshold << O_TX_CONTROL__TxThreshold));
+
+		phoenix_write_reg(priv->mmio, R_TX_CONTROL, regval);
+
+		regval = phoenix_read_reg(priv->mmio, R_RX_CONTROL);
+		regval &= ~(1 << O_RX_CONTROL__RxEnable);
+		phoenix_write_reg(priv->mmio, R_RX_CONTROL, regval);
+
+	}
+}
+
+#define CACHELINE_ALIGNED_ADDR(addr) (((unsigned long)(addr)) & ~(SMP_CACHE_BYTES-1))
+static __inline__ void *cacheline_aligned_kmalloc(int size, int gfp_mask)
+{
+	void *buf = kmalloc(size + SMP_CACHE_BYTES, gfp_mask);
+	if (buf)
+		buf =
+			(void
+			 *)(CACHELINE_ALIGNED_ADDR((unsigned long)buf +
+						   SMP_CACHE_BYTES));
+	return buf;
+}
+
+static __inline__ void *rmi_usermac_config_spill(phoenix_reg_t * mmio,
+					      int reg_start_0, int reg_start_1,
+					      int reg_size, int size)
+{
+	__u32 spill_size = CACHELINE_ALIGNED_ADDR(size);
+	void *spill = cacheline_aligned_kmalloc(spill_size, GFP_KERNEL);
+	__u64 phys_addr = 0;
+
+	if (!spill) {
+		panic("Unable to allocate memory for spill area!\n");
+	}
+	phys_addr = user_mac_vaddr_to_phys(spill);
+	phoenix_write_reg(mmio, reg_start_0, (phys_addr >> 5) & 0xffffffff);
+	phoenix_write_reg(mmio, reg_start_1, (phys_addr >> 37) & 0x07);
+	phoenix_write_reg(mmio, reg_size, spill_size);
+
+	return spill;
+}
+
+static void rmi_usermac_config_spill_area(struct usermac_priv *priv)
+{
+	/* */
+	int max_frin_spill    = 0;
+	int max_frout_spill   = 0;
+	int max_class_0_spill = 0;
+	int max_class_1_spill = 0;
+	int max_class_2_spill = 0;
+	int max_class_3_spill = 0;
+
+	if(!priv->num_desc)
+		return;
+
+	max_frin_spill = priv->num_desc << 2;
+	max_frout_spill = priv->num_desc << 2;
+
+	max_class_0_spill = priv->num_desc;
+	max_class_1_spill = priv->num_desc;
+	max_class_2_spill = priv->num_desc;
+	max_class_3_spill = priv->num_desc;
+
+
+	priv->frin_spill =
+		rmi_usermac_config_spill(priv->mmio,
+				      R_REG_FRIN_SPILL_MEM_START_0,
+				      R_REG_FRIN_SPILL_MEM_START_1,
+				      R_REG_FRIN_SPILL_MEM_SIZE,
+				      max_frin_spill *
+				      sizeof(struct fr_desc));
+
+	priv->class_0_spill =
+		rmi_usermac_config_spill(priv->mmio,
+				      R_CLASS0_SPILL_MEM_START_0,
+				      R_CLASS0_SPILL_MEM_START_1,
+				      R_CLASS0_SPILL_MEM_SIZE,
+				      max_class_0_spill *
+				      sizeof(union rx_tx_desc));
+	priv->class_1_spill =
+		rmi_usermac_config_spill(priv->mmio,
+				      R_CLASS1_SPILL_MEM_START_0,
+				      R_CLASS1_SPILL_MEM_START_1,
+				      R_CLASS1_SPILL_MEM_SIZE,
+				      max_class_1_spill *
+				      sizeof(union rx_tx_desc));
+
+	priv->frout_spill =
+		rmi_usermac_config_spill(priv->mmio, R_FROUT_SPILL_MEM_START_0,
+				      R_FROUT_SPILL_MEM_START_1,
+				      R_FROUT_SPILL_MEM_SIZE,
+				      max_frout_spill *
+				      sizeof(struct fr_desc));
+
+	priv->class_2_spill =
+		rmi_usermac_config_spill(priv->mmio,
+				      R_CLASS2_SPILL_MEM_START_0,
+				      R_CLASS2_SPILL_MEM_START_1,
+				      R_CLASS2_SPILL_MEM_SIZE,
+				      max_class_2_spill *
+				      sizeof(union rx_tx_desc));
+	priv->class_3_spill =
+		rmi_usermac_config_spill(priv->mmio,
+				      R_CLASS3_SPILL_MEM_START_0,
+				      R_CLASS3_SPILL_MEM_START_1,
+				      R_CLASS3_SPILL_MEM_SIZE,
+				      max_class_3_spill *
+				      sizeof(union rx_tx_desc));
+}
+
+
+/*Translate user space vaddr to page*/
+static struct page *user_vaddr_to_page(unsigned long addr, unsigned long size)
+{
+	pgd_t *pgd;
+	pud_t *pud;
+	pmd_t *pmd;
+	pte_t *pte = NULL;
+	pte_t pteval;
+	unsigned long pfn = 0;
+	struct mm_struct *mm = current->mm;
+	struct vm_area_struct *vma = NULL;
+
+	/*Check whether address falls in user space or not*/
+	if(addr >= PAGE_OFFSET){
+		printk("\nInvalid Userspace address\n");
+		return NULL;
+	}
+	
+	/*Make sure addr doesn't overlap*/
+	if(addr > (addr+size)){
+		printk("\nAddress overlaps!!!\n");
+		return NULL;
+	}
+	
+	/*Make sure address is already present in VMA*/
+	vma = find_vma(mm, addr+size-1);
+	if(!vma){
+		printk("\nNo VMA found!!!\n");
+		return NULL;
+	}
+	
+	if(vma->vm_start > addr){
+		/*`addr` doesn't fall under vma*/
+		printk("\nAddress doesn't fall under vma!!\n");
+		printk("\nvma_start = %#lx, vma_end = %#lx\n",
+						vma->vm_start, vma->vm_end);
+		return NULL;
+	}
+
+#ifdef CONFIG_HUGETLBFS
+	if(!is_vm_hugetlb_page(vma))
+		return NULL;
+#else
+	return NULL;
+#endif
+	/*Acquire pagetable sem*/
+	down_read(&mm->mmap_sem);
+	pgd = pgd_offset(mm, addr);
+	if (!pgd_none(*pgd)){
+		pud = pud_offset(pgd, addr);
+		if (!pud_none(*pud)) {
+			pmd = pmd_offset(pud, addr);
+			if (!pmd_none(*pmd)){
+				pte = pte_offset_map(pmd, addr);
+			}
+		}
+	}
+	/*Release pagetable sem*/
+	up_read(&mm->mmap_sem);
+
+	if(!pte){
+		printk("\nHugepage is not allocated yet\n");
+		return NULL;
+	}
+	pteval = *pte;
+	if(pte_none(pteval)){
+		printk("\nPTE not allocated yet\n");
+		return NULL;
+	}
+	pfn = (pte_val(pteval) & 0xffffffffffULL) >> PAGE_SHIFT;
+	Message("User virt Addr [%#lx], PTE VAL [%#llx], pfn [%#lx]",
+					(unsigned long)addr, (unsigned long long)pte_val(pteval),
+					(unsigned long)pfn);
+	return pfn_to_page(pfn);
+}
+
+int user_mac_ioctl(struct inode *inode, struct file *filp, unsigned int cmd,
+		   unsigned long arg)
+{
+    extern struct net_device_cfg phnx_net_dev_cfg;
+    struct net_device_cfg *net_cfg = &phnx_net_dev_cfg;
+    extern cpumask_t phys_cpu_present_map;
+
+	switch (cmd) {
+	case USER_MAC_IOC_HUGETLB_SHM_VIRT_ADDR:{
+			__u64 *ptr = (__u64 *) arg;
+			__u64	user_vaddr;
+			__u64	user_vaddr_len;
+			int no_of_pages = 0;
+			int i = 0;
+
+			if(htlb_kvaddr)
+				/*Usermac memory already initialized*/
+				return 0;	
+			
+			copy_from_user(&user_vaddr, ptr, sizeof(*ptr));
+			copy_from_user(&user_vaddr_len, ptr+1, sizeof(*ptr));
+
+			if(user_vaddr_len < MB(8ULL)){
+				printk("\nCan't init usermac buffers with < 8MB buffer\n");
+				return -ENOMEM; 
+			}else{
+				no_of_pages = MB(8ULL)/KB(4);
+				page_array = (struct page **)kmalloc
+						(sizeof(struct page *)*(no_of_pages),GFP_KERNEL);
+				if(!page_array){
+					printk("\nCan't allocate memory for page_array\n");
+					return -ENOMEM;
+				}
+				Message("User Space Virtual ADdress [%#lx]",(unsigned long)user_vaddr);
+				for(i=0; i<no_of_pages; i++, user_vaddr+=KB(4)){
+					page_array[i] = 
+						user_vaddr_to_page((unsigned long)user_vaddr, KB(4));
+					if(!page_array[i]){
+						kfree(page_array);
+						printk("\nuser_vaddr_to_page returned NULL!!\n");
+						return -ENOMEM;
+					}
+				}
+				/*vmap this page range in kernel address space*/
+				htlb_kvaddr = vmap(page_array, no_of_pages, VM_MAP, PAGE_KERNEL);
+				if(!htlb_kvaddr){
+					printk("\nNot enough virtual address space available to map the hugepage in kernel\n");
+					kfree(page_array);
+					return -ENOMEM;
+				}
+				htlb_kpaddr = ((unsigned long long)vmalloc_to_pfn((const void *)htlb_kvaddr))<<PAGE_SHIFT;
+				Message("HugeTlb Physical Address [%#llx]",(unsigned long long)htlb_kpaddr);
+			}
+			phoenix_psb_shm = htlb_kvaddr;
+			/*Init user mac descriptors now!!*/
+			user_mac_mem_init();
+		}
+		break;
+	case USER_MAC_IOC_EARLY_MEM_INIT:{
+			put_user((unsigned int)hybrid_mem_init, (unsigned int*)arg);
+		}
+		break;
+	case USER_MAC_IOC_GSHMPHYS:{
+			put_user((unsigned long long)phoenix_psb_shm_paddr,(unsigned long long*)arg);
+		}
+		break;
+
+	case USER_MAC_IOC_GSHMVIRT:{
+			put_user((unsigned long long)(unsigned long)phoenix_psb_shm,(unsigned long long *)arg);
+		}
+		break;
+
+	case USER_MAC_IOC_GSHMSIZE:{
+			put_user((unsigned int)phoenix_psb_shm_size,(unsigned int*)arg);
+		}
+		break;
+
+	case USER_MAC_IOC_GMMAP_START:{
+			put_user((unsigned int)PHNX_USER_MAC_MMAP_VIRT_START,(unsigned int*)arg);
+		}
+		break;
+
+	case USER_MAC_IOC_GREAD_REG:{
+			__u32 *ptr = (__u32 *) arg;
+			__u32 dev = 0, reg = 0, value = 0;
+			phoenix_reg_t *mmio = 0;
+
+			get_user(dev, ptr + 0);
+			get_user(reg, ptr + 1);
+
+			if(dev < 31)
+				mmio = usermac_dev.priv[dev].mmio;
+			
+			if(mmio == NULL || (reg>(0x1000>>2))){
+				printk("[%s]: bad args, dev=0x%x, reg=0x%x\n",
+				       __FUNCTION__, dev, reg);
+				value = 0xdeadbeef;
+			}else {
+				printk("\nMMIO %#lx, REG %#lx\n",(unsigned long)mmio,(unsigned long)reg);
+				printk("\nReading @ Address %#lx-->%#x\n",
+						(unsigned long)&mmio[reg],
+						mmio[reg]);
+				value = phoenix_read_reg(mmio, reg);
+				dbg_msg	
+				    ("[%s]: dev=0x%x, reg=0x%x, value=0x%x\n",
+				     __FUNCTION__, dev, reg, value);
+			}
+			put_user(value, ptr + 2);
+		}
+		break;
+
+	case USER_MAC_IOC_SWRITE_REG:{
+			__u32 *ptr = (__u32 *) arg;
+			__u32 dev = 0, reg = 0, value = 0;
+			phoenix_reg_t *mmio = 0;
+
+			get_user(dev, ptr + 0);
+			get_user(reg, ptr + 1);
+			get_user(value, ptr + 2);
+			if(dev < 31)
+				mmio = usermac_dev.priv[dev].mmio;
+			if(mmio == NULL || (reg>(0x1000>>2))){
+				printk("[%s]: bad args, dev=0x%x, reg=0x%x\n",
+				       __FUNCTION__, dev, reg);
+			} else{
+				dbg_msg
+				    ("[%s]: dev=0x%x, reg=0x%x, value=0x%x\n",
+				     __FUNCTION__, dev, reg, value);
+
+				phoenix_write_reg(mmio, reg, value);
+			}
+
+		}
+		break;
+
+	case USER_MAC_IOC_GPHYS_CPU_PRESENT_MAP:{
+			put_user((unsigned int)phys_cpu_present_map.bits[0],(unsigned int*)arg);
+		}
+		break;
+
+	case USER_MAC_IOC_GCPU_ONLINE_MAP:{
+			put_user((unsigned int)cpu_online_map.bits[0],(unsigned int*)arg);
+		}
+		break;
+	case USER_MAC_IOC_HYBRID_MODE_SETUP:{
+			if(xlr_hybrid_user_mac()){
+				if(net_cfg->xgs_type[0] == TYPE_XGMAC || net_cfg->xgs_type[1] == TYPE_XGMAC){
+					/*ATX-II*/
+					put_user((unsigned int)XLR_HYBRID_USER_MAC_GMAC_XGMAC,
+								   	(unsigned int*)arg);
+				}
+				else if(net_cfg->xgs_type[0] == TYPE_SPI4 || net_cfg->xgs_type[1] == TYPE_SPI4){
+					/*ATX-I*/
+					put_user((unsigned int)XLR_HYBRID_USER_MAC_GMAC_SPI4,
+								   	(unsigned int*)arg);
+				}
+				else{
+					/*All remaining XLR and XLS boards.*/
+					put_user((unsigned int)XLR_HYBRID_USER_MAC_GMAC,
+								   	(unsigned int*)arg);
+				}
+			}
+			else{
+				put_user((unsigned int)xlr_hybrid, (unsigned int*)arg);
+			}
+		}
+		break;
+	default:{
+			printk("ioctl(): invalid command=0x%x\n", cmd);
+			//return -EINVAL;
+			return 0;
+		}
+
+	}
+
+	return 0;
+}
+
+long user_mac_compat_ioctl(struct file *filp, unsigned int cmd,
+	       			unsigned long arg)
+{
+	unsigned long ret = -1;
+	lock_kernel();	
+	ret = user_mac_ioctl(NULL,filp,cmd,arg);
+	unlock_kernel();
+	if(ret){
+		printk("user_mac_ioctl returned with an error.\n");
+		return -ENOIOCTLCMD;
+	}
+	return ret;
+}
+
+  // called only when the reference count (maintained in inode) is zero
+static int user_mac_release(struct inode *inode, struct file *filp)
+{
+
+	return 0;
+}
+
+struct file_operations user_mac_fops = {
+	.mmap = user_mac_mmap,
+	.open = user_mac_open,
+	.ioctl = user_mac_ioctl,
+	.compat_ioctl = user_mac_compat_ioctl,
+	.release = user_mac_release,
+};
+
+static int proc_read_count;
+
+static int user_mac_proc_read(char *page, char **start, off_t off,
+			      int count, int *eof, void *data)
+{
+	int len = 0;
+	off_t begin = 0;
+	struct user_mac_time *time;
+	if (user_mac)
+		time = &user_mac->time;
+	else
+		time = &user_mac_krnl_data.time;
+
+	proc_read_count++;
+
+	len += sprintf(page + len,
+		       "\n*************** USER MAC STATISTICS ****************\n"
+		       "cpu_%d: proc_read_count = %d\n",
+		       smp_processor_id(), proc_read_count);
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	len +=
+	    sprintf(page + len,
+		    "\nshm_paddr=%llx, shm_size=%lx, mmap_virt_start=%x\n"
+		    "sizeof(user_mac_data)=0x%x\n", phoenix_psb_shm_paddr,
+		    phoenix_psb_shm_size, PHNX_USER_MAC_MMAP_VIRT_START,
+		    (unsigned int)sizeof(struct user_mac_data));
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	len +=
+	    sprintf(page + len,
+		    "\noffsetof(time)=0x%x, time.hi=%u, time.lo=%u\n",
+		    (unsigned int)offsetof(struct user_mac_data, time), 
+			(unsigned int)time->hi,
+		    (unsigned int)time->lo);
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	len += sprintf(page + len, "\n");
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	*eof = 1;
+
+      out:
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;
+}
+
+struct xlr_user_mac_config xlr_user_mac;
+
+static int __init xlr_user_mac_setup(char *str)
+{
+	if ( (strcmp(str, "=fast_syscall") == 0) || (strcmp(str, "fast_syscall") == 0)) {
+		xlr_user_mac.fast_syscall = 1;
+		printk("XLR: user_mac configured with fast syscalls\n");
+	} else {
+		printk("XLR: user_mac configured with unknown args \"%s\"\n", str);
+	}
+
+	return 1;
+}
+
+early_param("xlr_user_mac", xlr_user_mac_setup);
+
+static void user_mac_mem_init(void)
+{
+	int i = 0;
+	static int init_mem = 0;
+
+	if(init_mem){
+		printk("\nUser Mac Memory is already initialized\n");	
+		return;
+	}
+	
+	user_mac = (struct user_mac_data *)phoenix_psb_shm;
+	if (!user_mac) {
+		printk("[%s]: Null Shared Memory Pointer?\n", __FUNCTION__);
+		printk("\nInvalid user mac shared memory !!\n");
+		return;
+	}
+	printk("\nUserMac Data structures Starts @ %#lx\n",(unsigned long)phoenix_psb_shm);
+	if (sizeof(struct user_mac_data) > phoenix_psb_shm_size) {
+		printk("[%s]: psb shared memory is too small: user_mac_data=0x%x, psb_shm_size=0x%lx\n", __FUNCTION__, (unsigned int)sizeof(struct user_mac_data),
+		     (unsigned long)phoenix_psb_shm_size);
+		printk("User Mac Memory initialization failed!!\n");
+		return;
+	}
+
+	for(i=0;i<MAX_USER_MAC_PKTS;i++)
+		user_mac->pkt_desc[i].free = 1;
+
+	if(htlb_kpaddr){
+		phoenix_psb_shm_paddr = htlb_kpaddr;
+	}else{
+		phoenix_psb_shm_paddr = user_mac_vaddr_to_phys(phoenix_psb_shm);
+	}
+
+	if (xlr_hybrid_user_mac()){
+		Message("Calling User Mac Send FRIN ");
+		user_mac_send_frin();
+	}
+	else if(xlr_hybrid_user_mac_xgmac())
+		user_mac_send_frin_xgmac();
+
+	for(i = 0; i < PHOENIX_MAX_MACS; i++) {
+		if(usermac_dev.priv[i].mmio != 0)
+			rmi_usermac_port_enable(&usermac_dev.priv[i], 1);	
+	}
+	init_mem = 1;
+	return;
+}
+
+
+#ifdef CONFIG_HUGETLBFS
+static int __init xlr_hybrid_early_init(char *str)
+{
+	if(HPAGE_SIZE < MB(8)){
+		printk("Hugetlb user mac is not supported with < 8MB huge page size\n");
+		return 0;
+	}
+	if (strcmp(str,"no")==0){
+		hybrid_mem_init = 0;
+	}
+	return 0;
+}
+early_param("xlr_hybrid_early_init", xlr_hybrid_early_init);
+#endif
+
+static int user_mac_init(void)
+{
+	int i = 0, next = 0;
+	struct proc_dir_entry *entry;
+	extern struct net_device_cfg phnx_net_dev_cfg;
+	struct net_device_cfg *net_cfg = &phnx_net_dev_cfg;
+
+	usermac_dev.gmac_list = 0;
+	usermac_dev.xgmac_present = 0;
+	usermac_dev.spi4_present = 0;
+
+	/* if support for loading apps on same core as Linux is enabled */
+	if(xlr_loader_support && xlr_loader_sharedcore)
+		return -EINVAL;
+
+	if (xlr_hybrid_user_mac())	{
+		for(i = 0; i < PHOENIX_MAX_GMACS; i++) {
+			if(net_cfg->gmac_port[i].mmio_addr == 0 || net_cfg->gmac_port[i].cfg_flag == 0)
+				continue;
+			usermac_dev.gmac_list |= (1 << i);
+			usermac_dev.priv[i].mmio = (void *)net_cfg->gmac_port[i].mmio_addr;
+			usermac_dev.priv[i].type = TYPE_GMAC;
+
+			/* Need to call only once, num_desc will be nonzero for only the first
+                           port of every gmac block */
+			if(net_cfg->gmac_port[i].num_desc != 0) { 
+				usermac_dev.priv[i].num_desc = MAX_USER_MAC_FRIN_PKTS;
+				rmi_usermac_config_spill_area(&usermac_dev.priv[i]);
+				rmi_usermac_config_parser(&usermac_dev.priv[i]);
+				rmi_usermac_config_pde(&usermac_dev.priv[i]);
+			}		
+			next = i + 1;
+		}
+		if(usermac_dev.gmac_list == 0) 
+			printk("Skipping usermac configuration on gmac ports..\n");
+	}
+
+	if (xlr_hybrid_user_mac() || xlr_hybrid_user_mac_xgmac())	{
+		for(i = 0; i < PHOENIX_MAX_XGMACS; i++) {
+			if(net_cfg->xgs_port[i].mmio_addr == 0 || net_cfg->xgs_port[i].cfg_flag == 0)
+				continue;
+			if(net_cfg->xgs_type[i] == TYPE_XGMAC)
+				usermac_dev.xgmac_present |= (1  << i);
+			else
+				usermac_dev.spi4_present |= (1 << i);
+			usermac_dev.priv[next + i].mmio = (void *)net_cfg->xgs_port[i].mmio_addr;
+			usermac_dev.priv[next + i].type = net_cfg->xgs_type[i];
+			usermac_dev.priv[next + i].num_desc = MAX_USER_MAC_FRIN_PKTS;
+			rmi_usermac_config_spill_area(&usermac_dev.priv[next + i]);
+			rmi_usermac_config_parser(&usermac_dev.priv[next + i]);
+			rmi_usermac_config_pde(&usermac_dev.priv[next + i]);
+		}
+		if(usermac_dev.xgmac_present == 0 && usermac_dev.spi4_present == 0) 
+			printk("Skipping usermac configuration on xgmac ports..\n");
+	}
+
+	if(usermac_dev.gmac_list != 0 || usermac_dev.xgmac_present != 0 ||
+			usermac_dev.spi4_present != 0) {
+		user_mac_major =
+			register_chrdev(XLR_USER_MAC_MAJOR, PHNX_USER_MAC_CHRDEV_NAME, &user_mac_fops);
+		if (user_mac_major < 0) {
+			printk("user_mac_init() register_chrdev() failed\n");
+			return user_mac_major;
+		}
+		printk("Registered user_mac driver: major=%d\n", XLR_USER_MAC_MAJOR);
+	}
+
+	entry = create_proc_read_entry(PHNX_USER_MAC_CHRDEV_NAME, 0 /* def mode */ ,
+				       rmi_root_proc /* parent directory*/ ,
+                                       user_mac_proc_read
+				       /* proc read function */ ,
+				       0	/* no client data */
+		);
+
+	if (!entry) {
+		printk("[%s]: Unable to create proc read entry for %s!\n",
+		       __FUNCTION__, PHNX_USER_MAC_CHRDEV_NAME);
+	}
+
+	if(hybrid_mem_init){
+		user_mac_mem_init();
+		return 0;
+	}
+	printk("Memory init for hybrid mode is not done.\n");
+	return 0;
+}
+
+static void user_mac_exit(void)
+{
+	unregister_chrdev(user_mac_major, PHNX_USER_MAC_CHRDEV_NAME);
+}
+static int user_mac_mem(char *str)
+{
+
+	if ( !(xlr_hybrid_user_mac()) && !(xlr_hybrid_user_mac_xgmac()))
+		return 0;
+
+	if(!rmik_en) {
+		phoenix_psb_shm = alloc_bootmem_low( PHNX_USER_MAC_SIZE );
+		phoenix_psb_shm_size = PHNX_USER_MAC_SIZE;
+	} else {
+		phoenix_psb_shm = rmi_get_usermac_addr(PHNX_USER_MAC_SIZE);
+		phoenix_psb_shm_size = PHNX_USER_MAC_SIZE;
+	}
+	return 0;
+}
+
+module_init(user_mac_init);
+__setup("xlr_hybrid",user_mac_mem);
+module_exit(user_mac_exit);
diff --git a/drivers/net/rmi_ptp1588/Makefile b/drivers/net/rmi_ptp1588/Makefile
new file mode 100644
index 0000000..78a073a
--- /dev/null
+++ b/drivers/net/rmi_ptp1588/Makefile
@@ -0,0 +1,8 @@
+################################################################################
+
+#
+# Makefile for rmi_ptp1588
+#
+#EXTRA_CFLAGS := -Werror
+
+obj-y += ptp_main.o
diff --git a/drivers/net/rmi_ptp1588/ptp_common.h b/drivers/net/rmi_ptp1588/ptp_common.h
new file mode 100644
index 0000000..867d525
--- /dev/null
+++ b/drivers/net/rmi_ptp1588/ptp_common.h
@@ -0,0 +1,35 @@
+#ifndef PTP_COMMON_H
+#define PTP_COMMON_H
+                
+enum {
+    PTP_INIT     = 1, 
+    PTP_TX_TIMESTAMP,        
+    PTP_SET_TIME,
+    PTP_GET_INF_IDX,
+    PTP_SET_INF_IDX,
+    PTP_MAX_IOCTL
+ };
+            
+typedef struct _ptp_ts_t_ {
+    u32    ts_msb;
+    u32    ts_lsb;
+    } ptp_ts_t;
+
+typedef struct _ptp_clock_val_t_ {
+       u32 inf_type;
+       u32 inf_idx;
+       u32 offset0;
+       u32 offset1;
+       u32 frac_div;
+       u32 frac_mul;
+       u32 src_div;
+       u32 src_clk;
+    }ptp_clk_t;
+
+typedef struct _intf_type_t_{
+     unsigned char name[8][10];
+     unsigned long numif;
+     unsigned int inf_idx[8];
+ } intf_type_t;
+
+#endif
diff --git a/drivers/net/rmi_ptp1588/ptp_main.c b/drivers/net/rmi_ptp1588/ptp_main.c
new file mode 100644
index 0000000..6cf0ae3
--- /dev/null
+++ b/drivers/net/rmi_ptp1588/ptp_main.c
@@ -0,0 +1,358 @@
+#include <linux/module.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/init.h>
+
+#include <linux/kernel.h>	
+#include <linux/slab.h>		
+#include <linux/fs.h>		
+#include <linux/errno.h>	
+#include <linux/types.h>	
+#include <linux/proc_fs.h>
+#include <linux/fcntl.h>	
+#include <linux/seq_file.h>
+#include <linux/cdev.h>
+#include <linux/time.h>
+#include <linux/skbuff.h>
+
+//#include <linux/config.h>
+#include <linux/init.h>
+#include <asm/rmi/debug.h>
+#include <asm/rmi/pci.h>
+#include <asm/rmi/pic.h>
+#include <asm/rmi/phoenix_mac.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/atx_cpld.h>
+#include <asm/rmi/xgmac_mdio.h>
+#include <asm/rmi/proc.h>
+#include <asm-mips/smp.h>
+#include <asm-mips/rmi/iomap.h>
+#include <asm-mips/rmi/gpio.h>
+#include <user/rmi/phnx_user_mac.h>
+#include <asm-mips/div64.h>
+#include "ptp_common.h"
+#include "ptp_mod.h"
+extern struct psb_info *prom_info;
+void dump_all_interface(u32 reg);
+u32 rmi_macreg_get(u32 reg, u32 val);
+void rmi_macreg_set_all(u32 reg, u32 val, u32 mask);
+//int rmi_macreg_set_all(int inf, u32 reg, u32 val, u32 mask);
+int  rmi_macreg_set(int inf, u32 reg, u32 val);
+void rmi_register_ptp_ts_fp(void (*fp) (u32,u32,ktime_t *, u32));
+void rmi_clr_ptp_ts_fp(void);
+void tgl_timer_bit(u32, u32);
+int rmi_mac_get_inf_idx(char *infname);
+
+
+dev_t dev;
+struct cdev cdev;
+spinlock_t ptp_lock;
+struct timespec g_srttime;
+intf_type_t intf;
+
+#define GMAC_CORE_0                 0
+#define GMAC_CORE_1                 4
+ptp_clk_t clk;
+ptp_ts_t     ptp_ts;
+#define PTP1588_CONTROL                 0x077
+
+#define PTP1588_FREQ_MUL                3    
+#define PTP1588_FREQ_INS                2
+#define PTP_TICKS_PER_SEC               66666666ULL // assume 66MHZ
+#define PTP_FRM_MASK                    0x3
+#define ANY_INF                         2
+#define CLK_SRC_DIV                    7
+#define CLK_FREQ_DIV                   10000000
+#define dbg_ptp(...)            
+
+int ptp_ioctl(struct inode *inode, struct file *filp, u32 cmd, unsigned long arg);
+   
+int ptp_open(struct inode *inode, struct file *filp);
+
+struct file_operations ptp_fops = {
+        .owner = THIS_MODULE,
+        .ioctl = ptp_ioctl,
+        .open = ptp_open,
+    };
+#if 0
+unsigned long tmp_buff[1000];
+void dump_offset(void)
+{
+    static u32 prev = 0, cur = 0, idx = 0, iter = 0, cur_sec = 0 , 
+               cur_msec= 0 ,prev_sec = 0, prev_msec = 0, cnt = 0; 
+    int i = 0;
+    u32  msb = 0;
+    u64 cur_tic, tmp_tic;
+    static u64 prev_tic = 0;
+    tgl_timer_bit(1<<12, 1<<12);
+    cur = rmi_macreg_get( 2, PTP_TIMER_LATCH_VAL);
+    msb = rmi_macreg_get( 2, PTP_TIMER_LATCH_VAL1);
+
+ 
+//    get_cur_clk_val( &cur, &msb);
+    tmp_tic = cur_tic = ((u64)msb <<32|cur); 
+    #if 0
+    dbg_ptp("dump %u %u off %u systic %lu\n", rmi_macreg_get( 2, PTP_TIMER_LATCH_VAL1), cur, 
+                                   (cur - prev),   phnx_timer_get_stats(0)); 
+    #endif
+    tmp_buff[idx] = (cur - prev);
+    if(!(idx = (++idx)%1000)) {
+        iter++;
+     //   for(i = 0; i < 1000 ; i ++) {
+            dbg_ptp("iter %d off[%d] %lu\n",iter, i, tmp_buff[0]);
+       // }
+    }
+    cur_msec  = do_div(tmp_tic, PTP_TICKS_PER_SEC);
+    cur_sec = tmp_tic;
+//    dbg_ptp("cur %lu %lu diff %lu %lu\n", cur_sec, cur_msec, 
+//                                        (cur_sec - prev_sec), (cur_msec- prev_msec));
+    if(!(cnt%1000))
+        dbg_ptp("%u num seco %d tic %lld curtic %lld sec %u %u\n", cnt, cnt/1000, cur_tic - prev_tic, cur_tic, cur_sec, cur_msec);
+    prev_tic = cur_tic;
+    prev_sec = cur_sec;
+    prev_msec = cur_msec;
+
+    cnt ++; 
+    
+    prev = rmi_macreg_get( 2, PTP_TIMER_LATCH_VAL);
+}
+#endif
+
+
+
+void tgl_timer_bit(u32 ctr, u32 mask)
+{
+    rmi_macreg_set_all( PTP1588_CONTROL, 0, mask);
+    rmi_macreg_set_all( PTP1588_CONTROL, ctr, mask);
+    return;
+}
+
+int get_cur_clk_val( u32 *cur, u32 *msb)
+{    
+    tgl_timer_bit( 1<<O_PTP_CTRL_RTC_LATCH, NUM_BITS_1<<O_PTP_CTRL_RTC_LATCH);
+    *cur = rmi_macreg_get( ANY_INF, PTP_TIMER_LATCH_VAL);
+    *msb = rmi_macreg_get( ANY_INF, PTP_TIMER_LATCH_VAL1);
+   return 0;
+}
+
+void set_prepad_frm(u32 frm)
+{
+    rmi_macreg_set_all( R_RX_CONTROL, frm<<O_PTP_Rx1588TS, NUM_BITS_2<<O_PTP_Rx1588TS);
+    dbg_ptp("set format %x\n", 1<<11);
+    return;
+}
+
+
+void set_prepad(u32 enable)
+{
+    rmi_macreg_set_all( R_DESC_PACK_CTRL, (enable<<O_DESC_PACK_CTRL__PrePadEnable) , (NUM_BITS_1<<O_DESC_PACK_CTRL__PrePadEnable));
+    return;
+}
+
+/* 
+
+    Assume only one instance of ptp can run in the box
+    Convert Ticks to seconds and nano seconds
+ 
+*/
+void __inline__ ptp_set_tx_ts(u32 sec , u32 usec)
+{
+    spin_lock(&ptp_lock);
+    ptp_ts.ts_msb = usec;
+    ptp_ts.ts_lsb = sec; 
+    spin_unlock(&ptp_lock);
+}
+
+void ptp_set_ts(u32 msb, u32 lsb, ktime_t *tv, u32 flags)
+{
+   u64 cur_tic = ((u64)msb <<32|lsb) ;
+   // total nano seconds 
+   u32 sec = 0, nsec = 0;
+  
+  nsec = (do_div( cur_tic, PTP_TICKS_PER_SEC));
+  sec = cur_tic;
+  nsec += g_srttime.tv_nsec;
+  sec  += g_srttime.tv_sec ;
+
+  if(!tv) {
+    ptp_set_tx_ts( sec , nsec/1000);
+#if 0 
+       dbg_ptp(" TX TV %u %u hex %x %x \n", ptp_ts.ts_msb, ptp_ts.ts_lsb, 
+                                           ptp_ts.ts_msb, ptp_ts.ts_lsb);
+#endif
+
+    } else {
+	    *tv = ktime_set(sec, nsec);
+ #if 0 
+   struct timespec l_time;
+       l_time       = current_kernel_time(); 
+       dbg_ptp("RX TV sec %u  usec%u hex %x %x\n", tv->off_sec, tv->off_usec,
+                                         tv->off_sec, tv->off_usec); 
+       dbg_ptp("gxtime %lu %lu\n", g_srttime.tv_sec, g_srttime.tv_nsec);
+       dbg_ptp("xtime  %lu %lu\n", l_time.tv_sec, l_time.tv_nsec);
+       dbg_ptp("sxtime %u %u\n",  tv->off_sec , 
+                                   tv->off_usec);
+#endif
+    }
+
+    return;
+}
+
+void ptp_get_tx_ts(ptp_ts_t *ts)
+{
+    spin_lock(&ptp_lock);
+    ts->ts_msb = ptp_ts.ts_msb; 
+    ts->ts_lsb = ptp_ts.ts_lsb; 
+    spin_unlock(&ptp_lock);
+    return;
+}
+int  ptp_set_clk(ptp_clk_t *clk, int flag)
+{ 
+ dbg_ptp("clk %d,div %d, den %d, num %d, off0 %d, off1 %d\n", clk->src_clk, clk->src_div,
+                                                             clk->frac_div, clk->frac_mul,
+                                                             clk->offset0, clk->offset1);
+
+ rmi_macreg_set_all( PTP_SOURCE     , clk->src_clk , NUM_BITS_1); 
+ rmi_macreg_set_all( PTP_SOURCE_DIV , clk->src_div , NUM_BITS_3); 
+ rmi_macreg_set_all( PTP_FRAC_DIV   , clk->frac_div, NUM_BITS_32); 
+ rmi_macreg_set_all( PTP_FRAC_MUL   , clk->frac_mul, NUM_BITS_32); 
+ rmi_macreg_set_all( PTP_OFFSET0    , clk->offset0 , NUM_BITS_32); 
+ rmi_macreg_set_all( PTP_OFFSET1    , clk->offset1 , NUM_BITS_32);
+ return 0;
+}
+
+int ptp_open(struct inode *inode, struct file *filp)
+{
+    dbg_ptp("%s\n", __FUNCTION__);
+    return 0;
+}
+
+int init_ptp(void)
+{
+u32  cur = 0 , msb = 0, biu_clk_div = 1;
+u64  cur64, tmp64;
+u32 gpio_reset_cfg = 0;
+phoenix_reg_t *gpio_mmio =
+                    (phoenix_reg_t *)(phoenix_io_base + PHOENIX_IO_GPIO_OFFSET); 
+u64 clk_freq = prom_info->cpu_frequency;
+
+gpio_reset_cfg = phoenix_read_reg(gpio_mmio,PHOENIX_GPIO_PWRON_RESET_CFG_REG);
+
+ do_div( clk_freq, CLK_SRC_DIV);
+ if(gpio_reset_cfg & (PTP_BIU_HALF_CLOCK) ) {
+        biu_clk_div = 2;
+  } else {
+        biu_clk_div = 1;
+  }
+ memset( &clk, 0, sizeof(ptp_clk_t)); 
+ 
+ clk.src_clk  = PTP_CLK_SRC_CORE; 
+// (Pic clock hz)/(clock hz/src_div)
+ clk.frac_mul = 4444444*biu_clk_div;
+ dbg_ptp("multi %d \n", (PTP_TICKS_PER_SEC*1000000/(u32)clk_freq));
+// clk.frac_mul = (prom_info->cpu_frequency)*biu_clk_div;
+
+ clk.frac_div = CLK_FREQ_DIV;
+ clk.src_div  = CLK_SRC_DIV;
+
+// Reset clock 
+ tgl_timer_bit(1, NUM_BITS_1);
+
+/*  Set clock
+    u need to toggle the control bits for the setting to work,hardware anomaly */
+
+ ptp_set_clk( &clk, 0);
+
+//set prepad format
+ set_prepad(1);
+ set_prepad_frm(2);
+
+ tgl_timer_bit( (1<<PTP1588_FREQ_MUL), (1<<PTP1588_FREQ_MUL));
+//Register timestamp 
+rmi_register_ptp_ts_fp(ptp_set_ts);
+
+
+
+// store the number the "time zero"
+
+ tgl_timer_bit((1<<O_PTP_CTRL_RTC_LATCH), (1<<O_PTP_CTRL_RTC_LATCH));
+ cur = rmi_macreg_get( ANY_INF, PTP_TIMER_LATCH_VAL);
+ msb = rmi_macreg_get( ANY_INF, PTP_TIMER_LATCH_VAL1);
+   
+ tmp64=  cur64 = ((u64)msb<<32 | cur);
+ g_srttime=  current_kernel_time();
+
+ dbg_ptp("INIT gstart %lu %lu \n", g_srttime.tv_sec , g_srttime.tv_nsec);
+ g_srttime.tv_nsec -= do_div(cur64, PTP_TICKS_PER_SEC);;
+ g_srttime.tv_sec  -= (u32) cur64;
+
+ dbg_ptp("INIT start %llu sec %lu nsec %lu \n", tmp64, g_srttime.tv_sec, g_srttime.tv_nsec );
+ return 0;
+}
+
+void deinit_ptp(void)
+{
+ dbg_ptp("%s\n", __FUNCTION__); 
+// set_prepad(0);
+ //set_prepad_frm(0);
+ tgl_timer_bit(( 1<<PTP1588_FREQ_MUL) , ( 1<<PTP1588_FREQ_MUL));
+ rmi_clr_ptp_ts_fp();
+ return;
+}
+
+int ptp_ioctl(struct inode *inode, struct file *filp,
+                 u32 cmd, unsigned long arg)
+{
+int  rc = 0;
+ptp_ts_t ptp;
+ptp_clk_t ptp_clk;
+
+switch (cmd) {
+    case PTP_INIT:
+        dbg_ptp("init %s\n", __FUNCTION__);
+        rc= init_ptp();
+        break;
+    case PTP_GET_INF_IDX:
+        break;
+    case PTP_SET_INF_IDX:
+        copy_from_user( &intf, (const char __user *)arg, sizeof(intf_type_t));
+        dbg_ptp("intfname %s num %ld\n", &intf.name[0][0], intf.numif); 
+        break;
+    case PTP_TX_TIMESTAMP:  
+        dbg_ptp("%s %d\n", __FUNCTION__, cmd);
+        memset( &ptp,  0 , sizeof(ptp));
+        ptp_get_tx_ts(&ptp);   
+        copy_to_user((void *)arg, &ptp, sizeof(ptp_ts_t));
+        break;
+    case PTP_SET_TIME:
+        memset( &ptp_clk, 0, sizeof(ptp_clk_t));
+        copy_from_user( &ptp_clk, (const char __user *)arg, sizeof(ptp_clk_t));
+        rc = ptp_set_clk( &ptp_clk, 0);
+        break;
+    default:
+        dbg_ptp("default\n");
+        break;
+   }
+return rc;
+}
+static int __init init_mod(void)
+{
+int  major = 0;
+   major = register_chrdev( PTP_DEV_MAJOR_NUM, PTP_DRV_NAME, &ptp_fops);
+   
+   spin_lock_init(&ptp_lock);
+   return 0;
+}
+static void __exit exit_mod(void)
+{
+    dbg_ptp("%s \n", __FUNCTION__);
+    unregister_chrdev_region(0, dev);
+    deinit_ptp(); 
+    return;
+}
+EXPORT_SYMBOL(ptp_set_ts);
+module_init(init_mod);
+module_exit(exit_mod);
diff --git a/drivers/net/rmi_ptp1588/ptp_mod.h b/drivers/net/rmi_ptp1588/ptp_mod.h
new file mode 100644
index 0000000..8a4509b
--- /dev/null
+++ b/drivers/net/rmi_ptp1588/ptp_mod.h
@@ -0,0 +1,33 @@
+#ifndef PTP_MOD_H
+#define PTP_MOD_H
+
+
+#define     PTP_SOURCE_DIV          0x24a
+#define     PTP_SOURCE              0x24b
+#define     PTP_FRAC_DIV            0x70
+#define     PTP_FRAC_MUL            0x71
+#define     PTP_INCR                0x72
+#define     PTP_OFFSET0             0x73
+#define     PTP_OFFSET1             0x74
+#define     PTP_TX_LATCH_LSB        0x75
+#define     PTP_TX_LATCH_MSB        0x76
+#define     PTP_CTRL                0x77
+#define     O_PTP_CTRL_RTC_LATCH    12
+#define     PTP_TIMER_LATCH_VAL     0x7e
+#define     PTP_TIMER_LATCH_VAL1    0x7f
+
+#define     O_PTP_Rx1588TS          11
+
+#define     PTP_BIU_HALF_CLOCK      (1<<23)
+#define     PTP_CLK_SRC_GMAC        0x0
+#define     PTP_CLK_SRC_CORE        0x1
+#define     PTP_DEV_MAJOR_NUM       250
+
+
+#define   NUM_BITS_1        0x1
+#define   NUM_BITS_2        0x3
+#define   NUM_BITS_3        0x7
+#define   NUM_BITS_32       0xffffffff  
+
+#define   PTP_DRV_NAME      "ptp1588"     
+#endif
diff --git a/drivers/net/rmi_rionet.c b/drivers/net/rmi_rionet.c
new file mode 100644
index 0000000..be229fb
--- /dev/null
+++ b/drivers/net/rmi_rionet.c
@@ -0,0 +1,615 @@
+/*
+ * rionet - Ethernet driver over RapidIO messaging services
+ *
+ * Copyright 2005 MontaVista Software, Inc.
+ * Matt Porter <mporter@kernel.crashing.org>
+ *
+ * This program is free software; you can redistribute  it and/or modify it
+ * under  the terms of  the GNU General  Public License as published by the
+ * Free Software Foundation;  either version 2 of the  License, or (at your
+ * option) any later version.
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/dma-mapping.h>
+#include <linux/delay.h>
+#include <linux/rio.h>
+#include <linux/rio_drv.h>
+#include <linux/rio_ids.h>
+
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/crc32.h>
+#include <linux/ethtool.h>
+
+#define DRV_NAME        "rionet"
+#define DRV_VERSION     "0.2"
+#define DRV_AUTHOR      "Matt Porter <mporter@kernel.crashing.org>"
+#define DRV_DESC        "Ethernet over RapidIO"
+
+#define RMI_RIO_MAX_ROUTE_ENTRIES (1<<16)
+MODULE_AUTHOR(DRV_AUTHOR);
+MODULE_DESCRIPTION(DRV_DESC);
+MODULE_LICENSE("GPL");
+
+#define MYDBG(a, ...)
+#define Message(a,b...) //printk("\nFunction [%s], Line [%d] "a"\n",__FUNCTION__,__LINE__,##b)
+
+#define RIONET_DEFAULT_MSGLEVEL \
+			(NETIF_MSG_DRV          | \
+			 NETIF_MSG_LINK         | \
+			 NETIF_MSG_RX_ERR       | \
+			 NETIF_MSG_TX_ERR)
+
+#define RIONET_DOORBELL_JOIN	0x1000
+#define RIONET_DOORBELL_LEAVE	0x1001
+
+#define RIONET_MAILBOX		0
+
+#define RIONET_TX_RING_SIZE	CONFIG_RIONET_TX_SIZE
+#define RIONET_RX_RING_SIZE	CONFIG_RIONET_RX_SIZE
+
+static LIST_HEAD(rionet_peers);
+
+struct rionet_private {
+	struct rio_mport *mport;
+	struct sk_buff *rx_skb[RIONET_RX_RING_SIZE];
+	struct sk_buff *tx_skb[RIONET_TX_RING_SIZE];
+	struct net_device_stats stats;
+	int rx_slot;
+	int tx_slot;
+	int tx_cnt;
+	int ack_slot;
+	spinlock_t lock;
+	spinlock_t tx_lock;
+	spinlock_t tx_cnt_lock;
+	u32 msg_enable;
+};
+
+struct rionet_peer {
+	struct list_head node;
+	struct rio_dev *rdev;
+	struct resource *res;
+};
+
+static int rionet_check = 0;
+static int rionet_capable = 1;
+
+/*
+ * This is a fast lookup table for for translating TX
+ * Ethernet packets into a destination RIO device. It
+ * could be made into a hash table to save memory depending
+ * on system trade-offs.
+ */
+static struct rio_dev *rionet_active[RMI_RIO_MAX_ROUTE_ENTRIES];
+#if 0
+#define is_rionet_capable(pef, src_ops, dst_ops)		\
+			((pef & RIO_PEF_INB_MBOX) &&		\
+			 (pef & RIO_PEF_INB_DOORBELL) &&	\
+			 (src_ops & RIO_SRC_OPS_DOORBELL) &&	\
+			 (dst_ops & RIO_DST_OPS_DOORBELL))
+#endif
+#define is_rionet_capable(pef, src_ops, dst_ops)		\
+            ((src_ops & RIO_SRC_OPS_DOORBELL) && \
+              (dst_ops & RIO_DST_OPS_DOORBELL) && \
+               (src_ops & RIO_SRC_OPS_DATA_MSG) && \
+               (dst_ops & RIO_DST_OPS_DATA_MSG))
+
+#define dev_rionet_capable(dev) \
+	is_rionet_capable(dev->pef, dev->src_ops, dev->dst_ops)
+
+#define RIONET_MAC_MATCH(x)	(*(u32 *)x == 0x00010001)
+#define RIONET_GET_DESTID(x)	(*(u16 *)(x + 4))
+
+static struct net_device_stats *rionet_stats(struct net_device *ndev)
+{
+	struct rionet_private *rnet = ndev->priv;
+	return &rnet->stats;
+}
+
+static int rionet_rx_clean(struct net_device *ndev)
+{
+	int i;
+	int error = 0;
+	struct rionet_private *rnet = ndev->priv;
+	void *data;
+    volatile unsigned long dummy;
+
+	i = rnet->rx_slot;
+
+	do {
+		if (!rnet->rx_skb[i])
+			continue;
+
+		if (!(data = rio_get_inb_message(rnet->mport, RIONET_MAILBOX))){
+			break;
+        }
+
+        /*dummy read to make sure data is valid!*/
+        dummy = *(volatile unsigned long *)data;
+
+		rnet->rx_skb[i]->data = data;
+		skb_put(rnet->rx_skb[i], RIO_MAX_MSG_SIZE);
+		rnet->rx_skb[i]->dev = ndev;
+		rnet->rx_skb[i]->protocol =
+		    eth_type_trans(rnet->rx_skb[i], ndev);
+		error = netif_rx(rnet->rx_skb[i]);
+
+		if (error == NET_RX_DROP) {
+			rnet->stats.rx_dropped++;
+		} else if (error == NET_RX_BAD) {
+			if (netif_msg_rx_err(rnet))
+				printk(KERN_WARNING "%s: bad rx packet\n",
+				       DRV_NAME);
+			rnet->stats.rx_errors++;
+		} else {
+			rnet->stats.rx_packets++;
+			rnet->stats.rx_bytes += RIO_MAX_MSG_SIZE;
+		}
+
+	} while ((i = (i + 1) % RIONET_RX_RING_SIZE) != rnet->rx_slot);
+
+	return i;
+}
+
+static void rionet_rx_fill(struct net_device *ndev, int end)
+{
+	int i;
+	struct rionet_private *rnet = ndev->priv;
+
+	i = rnet->rx_slot;
+	do {
+		rnet->rx_skb[i] = dev_alloc_skb(RIO_MAX_MSG_SIZE);
+
+		if (!rnet->rx_skb[i])
+			break;
+
+		if(rio_add_inb_buffer(rnet->mport, RIONET_MAILBOX,
+				   rnet->rx_skb[i]->data))
+            break;
+	} while ((i = (i + 1) % RIONET_RX_RING_SIZE) != end);
+
+	rnet->rx_slot = i;
+}
+
+static int rionet_queue_tx_msg(struct sk_buff *skb, struct net_device *ndev,
+			       struct rio_dev *rdev)
+{
+	struct rionet_private *rnet = ndev->priv;
+    int len = skb->len;
+    unsigned long flags;
+    int ret = 0;
+
+    if(len & 0x7)
+        len = (len + 0x7) & ~(0x7);
+
+	if(rio_add_outb_message(rnet->mport, rdev, 0, skb->data, len))
+        return -EIO;
+
+	rnet->tx_skb[rnet->tx_slot] = skb;
+
+	rnet->stats.tx_packets++;
+	rnet->stats.tx_bytes += skb->len;
+
+    spin_lock_irqsave(&rnet->tx_cnt_lock, flags);
+    rnet->tx_cnt++;
+	if (rnet->tx_cnt == RIONET_TX_RING_SIZE){
+        MYDBG("Max tx_cnt reached stopping queue");
+		netif_stop_queue(ndev);
+    }
+    spin_unlock_irqrestore(&rnet->tx_cnt_lock, flags);
+
+	++rnet->tx_slot;
+	rnet->tx_slot &= (RIONET_TX_RING_SIZE - 1);
+
+	if (netif_msg_tx_queued(rnet))
+		printk(KERN_INFO "%s: queued skb %8.8x len %8.8x\n", DRV_NAME,
+		       (u32) skb, skb->len);
+
+	return ret;
+}
+
+static int rionet_start_xmit(struct sk_buff *skb, struct net_device *ndev)
+{
+	int i;
+	struct rionet_private *rnet = ndev->priv;
+	struct ethhdr *eth = (struct ethhdr *)skb->data;
+	u16 destid;
+	unsigned long flags;
+    int ret = 0;
+
+	local_irq_save(flags);
+	if ((rnet->tx_cnt + 1) > RIONET_TX_RING_SIZE) {
+        MYDBG("Stopping queue");
+		netif_stop_queue(ndev);
+		local_irq_restore(flags);
+		printk(KERN_ERR "%s: BUG! Tx Ring full when queue awake!\n",
+		       ndev->name);
+		return NETDEV_TX_BUSY;
+	}
+
+	if (eth->h_dest[0] & 0x01) {
+		for (i = 0; i < RMI_RIO_MAX_ROUTE_ENTRIES; i++){
+			if (rionet_active[i]){
+				if((ret = rionet_queue_tx_msg(skb, ndev,
+						    rionet_active[i]))){
+                    MYDBG("Xmit failed!!!\n");
+                    break;
+                }
+            }
+        }
+	} else if (RIONET_MAC_MATCH(eth->h_dest)) {
+		destid = RIONET_GET_DESTID(eth->h_dest);
+		if (rionet_active[destid]){
+			ret = rionet_queue_tx_msg(skb, ndev, rionet_active[destid]);
+            if(ret)
+                MYDBG("XMIT FAILED!!\n");
+        }
+	}else{
+        ret = -EIO;
+	}
+
+    local_irq_restore(flags);
+	return ret;
+}
+
+static void rionet_dbell_event(struct rio_mport *mport, void *dev_id, u16 sid, 
+                                u16 tid, u16 info)
+{
+	struct net_device *ndev = dev_id;
+	struct rionet_private *rnet = ndev->priv;
+	struct rionet_peer *peer;
+
+	if (netif_msg_intr(rnet))
+		printk(KERN_INFO "%s: doorbell sid %4.4x tid %4.4x info %4.4x",
+		       DRV_NAME, sid, tid, info);
+	if (info == RIONET_DOORBELL_JOIN) {
+		if (!rionet_active[sid]) {
+			list_for_each_entry(peer, &rionet_peers, node) {
+				if (peer->rdev->destid == sid)
+					rionet_active[sid] = peer->rdev;
+			}
+			rio_mport_send_doorbell(mport, sid,
+						RIONET_DOORBELL_JOIN);
+		}
+	} else if (info == RIONET_DOORBELL_LEAVE) {
+		rionet_active[sid] = NULL;
+	} else {
+		if (netif_msg_intr(rnet))
+			printk(KERN_WARNING "%s: unhandled doorbell\n",
+			       DRV_NAME);
+	}
+}
+
+static void rionet_inb_msg_event(struct rio_mport *mport, void *dev_id, int mbox, int slot)
+{
+	int n;
+	struct net_device *ndev = dev_id;
+	struct rionet_private *rnet = (struct rionet_private *)ndev->priv;
+
+	if (netif_msg_intr(rnet))
+		printk(KERN_INFO "%s: inbound message event, mbox %d slot %d\n",
+		       DRV_NAME, mbox, slot);
+
+	spin_lock(&rnet->lock);
+	if ((n = rionet_rx_clean(ndev)) != rnet->rx_slot)
+		rionet_rx_fill(ndev, n);
+	spin_unlock(&rnet->lock);
+}
+
+static void rionet_outb_msg_event(struct rio_mport *mport, void *dev_id, int mbox, int slot)
+{
+	struct net_device *ndev = dev_id;
+	struct rionet_private *rnet = ndev->priv;
+
+	spin_lock(&rnet->lock);
+    MYDBG("Rcvd TX OK!!! - slot %d, ack_slot = %d",slot,rnet->ack_slot);
+	if (netif_msg_intr(rnet))
+		printk(KERN_INFO
+		       "%s: outbound message event, mbox %d slot %d\n",
+		       DRV_NAME, mbox, slot);
+
+	while (rnet->tx_cnt && (rnet->ack_slot != slot)) {
+		/* dma unmap single */
+		dev_kfree_skb_irq(rnet->tx_skb[rnet->ack_slot]);
+		rnet->tx_skb[rnet->ack_slot] = NULL;
+		++rnet->ack_slot;
+		rnet->ack_slot &= (RIONET_TX_RING_SIZE - 1);
+        spin_lock(&rnet->tx_cnt_lock);
+		rnet->tx_cnt--;
+        spin_unlock(&rnet->tx_cnt_lock);
+	}
+
+    spin_lock(&rnet->tx_cnt_lock);
+	if (rnet->tx_cnt < RIONET_TX_RING_SIZE){
+        MYDBG("Waking queue\n");
+		netif_wake_queue(ndev);
+    }
+    spin_unlock(&rnet->tx_cnt_lock);
+
+	spin_unlock(&rnet->lock);
+}
+
+static int rionet_open(struct net_device *ndev)
+{
+	int i, rc = 0;
+	struct rionet_peer *peer, *tmp;
+	struct rionet_private *rnet = ndev->priv;
+
+	if (netif_msg_ifup(rnet))
+		printk(KERN_INFO "%s: open\n", DRV_NAME);
+
+	/* Initialize inbound message ring */
+	for (i = 0; i < RIONET_RX_RING_SIZE; i++)
+		rnet->rx_skb[i] = NULL;
+	rnet->rx_slot = 0;
+
+	if ((rc = rio_request_inb_dbell(rnet->mport,
+					(void *)ndev,
+					RIONET_DOORBELL_JOIN,
+					RIONET_DOORBELL_LEAVE,
+					rionet_dbell_event)) < 0)
+		goto out;
+
+	if ((rc = rio_request_inb_mbox(rnet->mport,
+				       (void *)ndev,
+				       RIONET_MAILBOX,
+				       RIONET_RX_RING_SIZE,
+				       rionet_inb_msg_event)) < 0)
+		goto out;
+
+	if ((rc = rio_request_outb_mbox(rnet->mport,
+					(void *)ndev,
+					RIONET_MAILBOX,
+					RIONET_TX_RING_SIZE,
+					rionet_outb_msg_event)) < 0)
+		goto out;
+
+	rionet_rx_fill(ndev, 0);
+
+	rnet->tx_slot = 0;
+	rnet->tx_cnt = 0;
+	rnet->ack_slot = 0;
+
+	netif_carrier_on(ndev);
+	netif_start_queue(ndev);
+
+	list_for_each_entry_safe(peer, tmp, &rionet_peers, node) {
+		if (!(peer->res = rio_request_outb_dbell(peer->rdev,
+							 RIONET_DOORBELL_JOIN,
+							 RIONET_DOORBELL_LEAVE)))
+		{
+			printk(KERN_ERR "%s: error requesting doorbells\n",
+			       DRV_NAME);
+			continue;
+		}
+
+		/*
+		 * send a join message to peer.
+		 */
+			rio_send_doorbell(peer->rdev, RIONET_DOORBELL_JOIN);
+	}
+
+	return rc;
+      out:
+	return rc;
+}
+
+static int rionet_close(struct net_device *ndev)
+{
+	struct rionet_private *rnet = (struct rionet_private *)ndev->priv;
+	struct rionet_peer *peer, *tmp;
+	int i;
+
+	if (netif_msg_ifup(rnet))
+		printk(KERN_INFO "%s: close\n", DRV_NAME);
+
+    MYDBG("Stopping queue");
+	netif_stop_queue(ndev);
+	netif_carrier_off(ndev);
+
+	list_for_each_entry_safe(peer, tmp, &rionet_peers, node) {
+		if (rionet_active[peer->rdev->destid]) {
+			rio_send_doorbell(peer->rdev, RIONET_DOORBELL_LEAVE);
+		}
+		rio_release_outb_dbell(peer->rdev, peer->res);
+	}
+
+	rio_release_inb_dbell(rnet->mport, RIONET_DOORBELL_JOIN,
+			      RIONET_DOORBELL_LEAVE);
+	rio_release_inb_mbox(rnet->mport, RIONET_MAILBOX);
+	rio_release_outb_mbox(rnet->mport, RIONET_MAILBOX);
+
+
+	for (i = 0; i < RIONET_RX_RING_SIZE; i++)
+		if (rnet->rx_skb[i])
+			kfree_skb(rnet->rx_skb[i]);
+
+	return 0;
+}
+
+static void rionet_remove(struct rio_dev *rdev)
+{
+	struct net_device *ndev = NULL;
+	struct rionet_peer *peer, *tmp;
+
+	unregister_netdev(ndev);
+	kfree(ndev);
+
+	list_for_each_entry_safe(peer, tmp, &rionet_peers, node) {
+		list_del(&peer->node);
+		kfree(peer);
+	}
+}
+
+static void rionet_get_drvinfo(struct net_device *ndev,
+			       struct ethtool_drvinfo *info)
+{
+	struct rionet_private *rnet = ndev->priv;
+
+	strcpy(info->driver, DRV_NAME);
+	strcpy(info->version, DRV_VERSION);
+	strcpy(info->fw_version, "n/a");
+	strcpy(info->bus_info, rnet->mport->name);
+}
+
+static u32 rionet_get_msglevel(struct net_device *ndev)
+{
+	struct rionet_private *rnet = ndev->priv;
+
+	return rnet->msg_enable;
+}
+
+static void rionet_set_msglevel(struct net_device *ndev, u32 value)
+{
+	struct rionet_private *rnet = ndev->priv;
+
+	rnet->msg_enable = value;
+}
+
+static const struct ethtool_ops rionet_ethtool_ops = {
+	.get_drvinfo = rionet_get_drvinfo,
+	.get_msglevel = rionet_get_msglevel,
+	.set_msglevel = rionet_set_msglevel,
+	.get_link = ethtool_op_get_link,
+};
+
+static int rionet_setup_netdev(struct rio_mport *mport)
+{
+	int rc = 0;
+	struct net_device *ndev = NULL;
+	struct rionet_private *rnet;
+	u16 device_id;
+
+	/* Allocate our net_device structure */
+	ndev = alloc_etherdev(sizeof(struct rionet_private));
+	if (ndev == NULL) {
+		printk(KERN_INFO "%s: could not allocate ethernet device.\n",
+		       DRV_NAME);
+		rc = -ENOMEM;
+		goto out;
+	}
+
+	/* Set up private area */
+	rnet = (struct rionet_private *)ndev->priv;
+	rnet->mport = mport;
+
+	/* Set the default MAC address */
+	device_id = rio_local_get_device_id(mport);
+	ndev->dev_addr[0] = 0x00;
+	ndev->dev_addr[1] = 0x01;
+	ndev->dev_addr[2] = 0x00;
+	ndev->dev_addr[3] = 0x01;
+	ndev->dev_addr[4] = device_id >> 8;
+	ndev->dev_addr[5] = device_id & 0xff;
+
+	/* Fill in the driver function table */
+	ndev->open = &rionet_open;
+	ndev->hard_start_xmit = &rionet_start_xmit;
+	ndev->stop = &rionet_close;
+	ndev->get_stats = &rionet_stats;
+	ndev->mtu = RIO_MAX_MSG_SIZE - 14;
+	SET_ETHTOOL_OPS(ndev, &rionet_ethtool_ops);
+
+	spin_lock_init(&rnet->lock);
+	spin_lock_init(&rnet->tx_lock);
+	spin_lock_init(&rnet->tx_cnt_lock);
+
+	rnet->msg_enable = RIONET_DEFAULT_MSGLEVEL;
+
+	rc = register_netdev(ndev);
+	if (rc != 0)
+		goto out;
+
+	printk("%s: %s %s Version %s, MAC %02x:%02x:%02x:%02x:%02x:%02x\n",
+	       ndev->name,
+	       DRV_NAME,
+	       DRV_DESC,
+	       DRV_VERSION,
+	       ndev->dev_addr[0], ndev->dev_addr[1], ndev->dev_addr[2],
+	       ndev->dev_addr[3], ndev->dev_addr[4], ndev->dev_addr[5]);
+
+      out:
+	return rc;
+}
+
+/*
+ * XXX Make multi-net safe
+ */
+static int rionet_probe(struct rio_dev *rdev, const struct rio_device_id *id)
+{
+	int rc = -ENODEV;
+	u32 lpef, lsrc_ops, ldst_ops;
+	struct rionet_peer *peer;
+
+	/* If local device is not rionet capable, give up quickly */
+	if (!rionet_capable)
+		goto out;
+
+	/*
+	 * First time through, make sure local device is rionet
+	 * capable, setup netdev,  and set flags so this is skipped
+	 * on later probes
+	 */
+	if (!rionet_check) {
+		rio_local_read_config_32(rdev->net->hport, RIO_PEF_CAR, &lpef);
+		rio_local_read_config_32(rdev->net->hport, RIO_SRC_OPS_CAR,
+					 &lsrc_ops);
+		rio_local_read_config_32(rdev->net->hport, RIO_DST_OPS_CAR,
+					 &ldst_ops);
+		if (!is_rionet_capable(lpef, lsrc_ops, ldst_ops)) {
+			printk(KERN_ERR
+			       "%s: local device is not network capable\n",
+			       DRV_NAME);
+			rionet_check = 1;
+			rionet_capable = 0;
+			goto out;
+		}
+
+		rc = rionet_setup_netdev(rdev->net->hport);
+		rionet_check = 1;
+	}
+
+	/*
+	 * If the remote device has mailbox/doorbell capabilities,
+	 * add it to the peer list.
+	 */
+	if (dev_rionet_capable(rdev)) {
+		if (!(peer = kmalloc(sizeof(struct rionet_peer), GFP_KERNEL))) {
+			rc = -ENOMEM;
+			goto out;
+		}
+		peer->rdev = rdev;
+        rionet_active[rdev->destid] = peer->rdev;
+		list_add_tail(&peer->node, &rionet_peers);
+	}
+
+      out:
+	return rc;
+}
+
+static struct rio_device_id rionet_id_table[] = {
+	{RIO_DEVICE(RIO_ANY_ID, RIO_ANY_ID)}
+};
+
+static struct rio_driver rionet_driver = {
+	.name = "rionet",
+	.id_table = rionet_id_table,
+	.probe = rionet_probe,
+	.remove = rionet_remove,
+};
+
+static int __init rionet_init(void)
+{
+	return rio_register_driver(&rionet_driver);
+}
+
+static void __exit rionet_exit(void)
+{
+	rio_unregister_driver(&rionet_driver);
+}
+
+module_init(rionet_init);
+module_exit(rionet_exit);
diff --git a/drivers/net/rmi_spi4/Makefile b/drivers/net/rmi_spi4/Makefile
new file mode 100644
index 0000000..e509b2d
--- /dev/null
+++ b/drivers/net/rmi_spi4/Makefile
@@ -0,0 +1,9 @@
+################################################################################
+
+#
+# Makefile for the rmi_spi4 ethernet driver
+#
+EXTRA_CFLAGS := -Werror
+
+obj-$(CONFIG_PHOENIX_SPI4) += os_layer.o rmi_spi4.o rmi_vits_eth.o vitesse_highlevel.o \
+                            vitesse_io.o vitesse_phy_ctrl.o rmi_vits_driver.o  rmi_vits_wrapper.o
diff --git a/drivers/net/rmi_spi4/meigsii_reg.h b/drivers/net/rmi_spi4/meigsii_reg.h
new file mode 100644
index 0000000..99d51e3
--- /dev/null
+++ b/drivers/net/rmi_spi4/meigsii_reg.h
@@ -0,0 +1,463 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/************************************************************-*- mode: C -*-*/
+/*                                                                          */
+/*           Copyright (C) 2003 Vitesse Semiconductor Corporation           */
+/*                           All Rights Reserved.                           */
+/*                                                                          */
+/****************************************************************************/
+/*                                                                          */
+/*                            Copyright Notice:                             */
+/*                                                                          */
+/*  Unpublished rights reserved under the copyright laws of the             */
+/*  United States of America, other countries and international treaties.   */
+/*  The software is provided without fee.                                   */  
+/*  Permission to use,  copy, store, modify, disclose, transmit or          */
+/*  distribute the software is granted, provided that this copyright        */
+/*  notice must appear in any copy, modification, disclosure,               */
+/*  transmission or distribution of the software.                           */
+/*  Vitesse Semiconductor Corporation retains all ownership, copyright,     */
+/*  trade secret and proprietary rights in the software.                    */
+/*  THIS SOFTWARE HAS BEEN PROVIDED "AS IS," WITHOUT EXPRESS OR IMPLIED     */
+/*  WARRANTY INCLUDING, WITHOUT LIMITATION, IMPLIED WARRANTIES OF           */
+/*  MERCHANTABILITY, FITNESS FOR A PARTICULAR USE AND NON-INFRINGEMENT.     */
+/*                                                                          */
+/****************************************************************************/
+/*                                                                          */
+/*                                                                          */
+/*  meigsii_reg.h  -- Definitions for Meigs-II chip internal registers.     */
+/*                                                                          */
+/*                                                                          */
+/* The general rule used for naming the registers is to prefix M2_ to the   */
+/* register name as described in the datasheet, using all capital letters.  */
+/* However, there are a few deviations, which are kept to a minimum and     */
+/* pointed out in the code using comments.                                  */
+/*                                                                          */
+/*                                                                          */
+/*                                                                          */
+/****************************************************************************/
+#ifndef _MEIGSII_REG_H
+#define _MEIGSII_REG_H 1
+
+
+/*
+ * Register Addressing:
+ *
+ * +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
+ * |15|14|13|12|11|10| 9| 8| 7| 6| 5| 4| 3| 2| 1| 0|
+ * +--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
+ * |Block ID| Sub Block |    Register Address   |WS|
+ * +--------+--+--+--+--+--+--+--+--+--+--+--+--+--+
+ *
+ * The WS (Word Select) bit selects between the most or least
+ * significant 16 bits of the register. Which one it selects
+ * depends on the endian mode set in the Parallel Interface
+ * setup register.
+ */
+
+/*
+#define M2_REG_ADDR(block,subblock,register) (((block)<<13)|((subblock)<<9)|((register)<<1))
+
+*/
+
+/* Meigs-II Block IDs */
+
+#define M2_BLK_MACS     1       /* Port - Sub Block: 0-10)                */
+#define M2_BLK_FIFO     2       /* FIFOs - Sub Block: 0 Ingress           */
+                                /*                    1 Egress            */
+#define M2_BLK_MIIM     3       /* MII Management - Sub Block: 0-1)       */
+#define M2_BLK_STAT     4       /* Statistics - Sub Block: 0-10)          */
+#define M2_BLK_SPI4     5       /* SPI-4.2 I/F - Sub Block: 0)            */
+#define M2_BLK_SYSTEM   7       /* System Regs - Sub Block: 1 Aggregator  */
+                                /*                          2 Ram BIST    */
+                                /*                          F Regs/CPU IF */
+
+
+/* Meigs-II Sub Block IDs */
+
+#define M2_SUBBLK_MIIM_0 0      /* MII Management Sub Block 0 */
+#define M2_SUBBLK_MIIM_1 1      /* MII Management Sub Block 1 */
+
+
+
+/* System Block Registers (Block ID: SYSTEM) */
+/* Subblock Control 0x0F */
+#define M2_SUBBLK_CTRL      0x0F
+/* Subblock Aggregator 0x01 */
+#define M2_SUBBLK_AGGR      0x01
+/* Subblock BIST 0x02 */
+#define M2_SUBBLK_BIST      0x02
+
+
+/* Block without subblocks -- currently only the value of '0' is used */
+#define M2_SUBBLK_NONE      0x00
+
+/* Two fifo's subblocks */
+#define M2_SUBBLK_INGRESS   0x00
+#define M2_SUBBLK_EGRESS    0x01
+
+/* 10x1G mac subblocks + 1x10G mac */
+#define M2_SUBBLK_MAC_10G   0x0A
+
+
+
+#define M2_CHIPID           0x00    /* Chip Identification */
+#define M2_BLADE_ID         0x01    /* Blade Identification */
+#define M2_SW_RESET         0x02    /* Global Software Reset */
+#define M2_IFACE_MODE       0x07    /* Interface Mode */
+#define M2_CRC_CNT          0x0A    /* CRC Error Count */
+#define M2_CRC_CFG          0x0B    /* CRC Configuration */
+#define M2E_SI_INSERT_BYTES 0x0F    /* SI insert bytes on read */
+#define M2_SI_TRANSFER_SEL  0x18    /* SI Transfer Select */
+#define M2_PLL_CLK_SPEED    0x19    /* Clock Speed Selection */
+#define M2_SYS_CLK_SELECT   0x1C    /* System Clock Select */
+#define M2_GPIO_CTRL        0x1D    /* GPIO Control */
+#define M2_GPIO_OUT         0x1E    /* GPIO Out */
+#define M2_GPIO_IN          0x1F    /* GPIO In */
+#define M2_CPU_TRANSFER_SEL 0x20    /* CPU Transfer Select */
+#define M2_LOCAL_DATA       0xFE    /* Local CPU Data */
+#define M2_LOCAL_STATUS     0xFF    /* Local CPU Status */
+
+/* System Block Registers (Block ID: SYSTEM) */
+/* Subblock Aggregator 0x01 */
+#define M2_AGGR_SETUP       0x00    /* Aggregator Setup */
+#define M2_PMAP_TABLE       0x01    /* Port Map Table */
+#define M2_MPLS_BIT0        0x08    /* MPLS Bit0 Position */
+#define M2_MPLS_BIT1        0x09    /* MPLS Bit1 Position */
+#define M2_MPLS_BIT2        0x0A    /* MPLS Bit2 Position */
+#define M2_MPLS_BIT3        0x0B    /* MPLS Bit3 Position */
+#define M2_MPLS_BITMASK     0x0C    /* MPLS Bit Mask */
+#define M2_PRE_BIT0POS      0x10    /* Preamble Bit0 Position */
+#define M2_PRE_BIT1POS      0x11    /* Preamble Bit1 Position */
+#define M2_PRE_BIT2POS      0x12    /* Preamble Bit2 Position */
+#define M2_PRE_BIT3POS      0x13    /* Preamble Bit3 Position */
+#define M2_PRE_ERR_CNT      0x14    /* Preamble Parity Error Counter */
+
+/* System Block Registers (Block ID: SYSTEM) */
+/* Subblock BIST 0x02 */
+
+#define M2_RAM_BIST_CMD     0x00    /* RAM BIST Command */
+#define M2_RAM_BIST_RESULT  0x01    /* RAM BIST Read Status & Read Result */
+
+/* System Block Registers (Block ID: SYSTEM) */
+/* Subblock BIST 0x02, Indirect BIST Register */
+
+#define M2_BIST_PORT_SELECT 0x00    /* BIST Port Select */
+#define M2_BIST_COMMAND     0x01    /* BIST Command */
+#define M2_BIST_STATUS      0x02    /* BIST Status */
+#define M2_BIST_ERR_CNT_LSB 0x03    /* BIST Error Count LSB */
+#define M2_BIST_ERR_CNT_MSB 0x04    /* BIST Error Count MSB */
+#define M2_BIST_ERR_SEL_LSB 0x05    /* BIST Error Select LSB */
+#define M2_BIST_ERR_SEL_MSB 0x06    /* BIST Error Select MSB */
+#define M2_BIST_ERROR_STATE 0x07    /* BIST Error State */
+#define M2_BIST_ERR_ADR0    0x08    /* BIST Error Address 0 */
+#define M2_BIST_ERR_ADR1    0x09    /* BIST Error Address 1 */
+#define M2_BIST_ERR_ADR2    0x0A    /* BIST Error Address 2 */
+#define M2_BIST_ERR_ADR3    0x0B    /* BIST Error Address 3 */
+
+/* FIFO Block Registers (Block ID: FIFO) */
+/* Subblock Ingress 0x00 */
+/* Subblock Egress 0x01 */
+/* These values are actually base addresses where the actual port
+ * address is obtained by adding the port # (0-9) to the address
+ */
+
+#define M2_TEST             0x00    /* Mode & Test */
+#define M2_TOP_BOTTOM       0x10    /* FIFO Buffer Top & Bottom */
+#define M2_TAIL             0x20    /* Write Pointer */
+#define M2_HEAD             0x30    /* Read Pointer */
+#define M2_HIGH_LOW_WM      0x40    /* Flow Control Water Marks */
+#define M2_CT_THRHLD        0x50    /* Cut Through Threshold */
+#define M2_FIFO_DROP_CNT    0x60    /* Drop & CRC Error Counter */
+#define M2_DEBUG_BUF_CNT    0x70    /* Input Side Debug Counter */
+
+/* FIFO Block Registers (Block ID: FIFO) */
+/* Subblock Ingress 0x00 */
+/* Subblock Egress 0x01 */
+
+#define M2_TRAFFIC_SHAPER_BUCKET0  0x0A    /* Traffic Shaper Bucket Setting */
+#define M2_TRAFFIC_SHAPER_BUCKET1  0x1A    /* Traffic Shaper Bucket Setting */
+#define M2_TRAFFIC_SHAPER_BUCKET2  0x2A    /* Traffic Shaper Bucket Setting */
+#define M2_TRAFFIC_SHAPER_BUCKET3  0x3A    /* Traffic Shaper Bucket Setting */
+#define M2_TRAFFIC_SHAPER_BUCKET4  0x4A    /* Traffic Shaper Bucket Setting */
+#define M2_TRAFFIC_SHAPER_BUCKET5  0x5A    /* Traffic Shaper Bucket Setting */
+#define M2_TRAFFIC_SHAPER_BUCKET6  0x6A    /* Traffic Shaper Bucket Setting */
+#define M2_TRAFFIC_SHAPER_BUCKET7  0x7A    /* Traffic Shaper Bucket Setting */
+#define M2_TRAFFIC_SHAPER_BUCKET8  0x0B    /* Traffic Shaper Bucket Setting */
+#define M2_TRAFFIC_SHAPER_BUCKET9  0x1B    /* Traffic Shaper Bucket Setting */
+#define M2_TRAFFIC_SHAPER_BUCKET10 0x2B    /* Traffic Shaper Bucket Setting */
+
+#define M2_TRAFFIC_SHAPER_CTRL     0x3B    /* Traffic Shaper Control Register */
+
+
+#define M2_SRAM_ADR         0x0E    /* SRAM Address in FIFO Buffer */
+#define M2_SRAM_WR_STRB     0x1E    /* SRAM Write Storage Block */
+#define M2_SRAM_RD_STRB     0x2E    /* SRAM Read Storage Block */
+#define M2_SRAM_DATA_0      0x3E    /* Bytes  3-0 of Data in Block */
+#define M2_SRAM_DATA_1      0x4E    /* Bytes  7-4 of Data in Block */
+#define M2_SRAM_DATA_2      0x5E    /* Bytes 11-8 of Data in Block */
+#define M2_SRAM_DATA_3      0x6E    /* Bytes 15-12 of Data in Block */
+#define M2_DATA_BLK_TYPE    0x7E    /* Data Block Type */
+
+
+/* FIFO Block Registers (Block ID: FIFO) */
+/* Subblock Ingress 0x00 */
+
+#define M2_ING_CONTROL      0x0F    /* Ingress Control */
+
+/* FIFO Block Registers (Block ID: FIFO) */
+/* Subblock Egress 0x01 */
+
+#define M2_EGR_CONTROL      0x0F    /* Egress Control */
+
+/* FIFO Block Registers (Block ID: FIFO) */
+/* Subblock Ingress 0x00 */
+/* Subblock Egress 0x01 */
+
+#define M2_AGE_TIMER        0x1F    /* Age Timer */
+#define M2_AGE_INC          0x2F    /* Age Increment */
+#define M2_DEBUG_OUT        0x3F    /* Output Side Debug Counter Control */
+#define M2_DEBUG_CNT        0x4F    /* Output Side Debug Counter */
+
+
+/* SPI-4.2 Host Interface Block Registers (Block ID: SPI4) */
+/* Subblock SPI-4.2 Interface 0x00 */
+
+#define M2_SPI4_MISC        0x00    /* Miscellaneous */
+#define M2_SPI4_STATUS      0x01    /* CML Status */
+#define M2_SPI4_ING_SETUP0  0x02    /* Ingress Status Channel Setup */
+#define M2_SPI4_ING_SETUP1  0x03    /* Ingress Data Training Setup */
+#define M2_SPI4_ING_SETUP2  0x04    /* Ingress Data Burst Sizes Setup */
+#define M2_SPI4_EGR_SETUP0  0x05    /* Egress Status Channel Setup */
+#define M2_SPI4_DBG_CNT     0x10    /* Debug Counters (Add Port # 0 - 9) */
+#define M2_SPI4_DBG_SETUP   0x1A    /* Counters Setup */
+
+#define M2_SPI4_TEST        0x20    /* Test Setup */
+#define M2_TPGEN_UP0        0x21    /* Test Pattern Generator User Pattern0 */
+#define M2_TPGEN_UP1        0x22    /* Test Pattern Generator User Pattern1 */
+#define M2_TPCHK_UP0        0x23    /* Test Pattern Checker User Pattern0 */
+#define M2_TPCHK_UP1        0x24    /* Test Pattern Checker User Pattern1 */
+#define M2_TPSAM_P0         0x25    /* Sampled Pattern 0 */
+#define M2_TPSAM_P1         0x26    /* Sampled Pattern 1 */
+#define M2_TPERR_CNT        0x27    /* Pattern Checker Error Counter */
+#define M2_SPI4_STICKY      0x30    /* Sticky Bits */
+
+#define M2_SPI4_DBG_INH     0x31    /* MeigsII Core Egress & Ingress Inhibit */
+#define M2_SPI4_DBG_STATUS  0x32    /* Sampled Ingress Status Channel */
+#define M2_SPI4_DBG_GRANT   0x33    /* Ingress Status Channel Granted
+                                       Credit Value */
+
+/* MAC Block Registers (Block ID: MAC) */
+/* Subblock 10 GbE 0x0A */
+
+#define M2_MISC_10G          0x00    /* Miscellaneous 10GbE Setup */
+#define M2_PAUSE             0x01    /* Pause */
+#define M2_MAX_LEN           0x02    /* Max Length */
+#define M2_MAC_HIGH_ADDR     0x03    /* MAC High Address */
+#define M2_MAC_LOW_ADDR      0x04    /* MAC Low Address */
+#define M2_NORMALIZER        0x05    /* Normalizer Control */
+#define M2_STICKY_RX         0x06    /* RX Debug */
+#define M2_DENORM            0x07    /* Denormalizer Control */
+#define M2_STICKY_TX         0x08    /* TX Debug */
+#define M2_MAC_RXHIGH        0x0A    /* XGMII Lane 0-3 Debug */
+#define M2_MAC_RXLOW         0x0B    /* XGMII Lane 4-7 Debug */
+#define M2_MAC_TX_STICKY     0x0C    /* MAC TX State Sticky Debug */
+#define M2_MAC_TX_RUNNING    0x0D    /* MAC TX State Running Debug */
+#define M2_TX_ABORT_AGE      0x14    /* Aged TX Frames Discards Counter */
+#define M2_TX_ABORT_SHORT    0x15    /* Short TX Frames Discards Counter */
+#define M2_TX_ABORT_TAXI     0x16    /* Taxi Error TX Frames Discards 
+                                        Counter */
+#define M2_TX_ABORT_UNDERRUN 0x17    /* TX Underrun Abort Discards Counter */
+#define M2_TX_DENORM_DISCARD 0x18    /* TX Denormalizer Discards Counter */
+
+#define M2_XAUI_STAT_A       0x20    /* XAUI Status Register A */
+#define M2_XAUI_STAT_B       0x21    /* XAUI Status Register B */
+#define M2_XAUI_STAT_C       0x22    /* XAUI Status Register C */
+#define M2_XAUI_CONF_A       0x23    /* XAUI Configuration Register A */
+#define M2_XAUI_CONF_B       0x24    /* XAUI Configuration Register B */
+#define M2_XAUI_CODE_GRP_CNT 0x25    /* XAUI Code Group Error Counter */
+#define M2_XAUI_CONF_TEST_A  0x26    /* XAUI Test Register A */
+#define M2_PDERRCNT          0x27    /* XAUI Test Register B */
+
+/* MAC Block Registers (Block ID: MAC) */
+/* Subblock Tri-Speed MACs 0x00-0x09 */
+
+#define M2_MODE_CFG          0x00    /* Mode Configuration */
+#define M2_PAUSE_CFG         0x01    /* Pause Configuration */
+#define M2_MAXLEN_CFG        0x02    /* Max Length Configuration */
+#define M2_MAC_ADDR_HIGH_CFG 0x03    /* MAC Address Configuration - High */
+#define M2_MAC_ADDR_LOW_CFG  0x04    /* MAC Address Configuration - Low */
+/* Following #define is duplicate of 10 GbE version, so redefine the name
+ * to avoid namespace collision, although, the value is equivalent, so
+ * it's benign to use either #define
+ */
+#define M2_TRI_NORMALIZER    0x05    /* Tri-Speed MAC Normalizer */
+#define M2_PCS_STATUS        0x06    /* PCS Status */
+#define M2_PCS_STATUS_DBG    0x07    /* PCS Status Debug */
+#define M2_PCS_CTRL          0x08    /* PCS Control */
+#define M2_PCS_CONFIG        0x09    /* PCS Configuration */
+#define M2_STICK_BIT         0x0A    /* Sticky Bits */
+#define M2_DEV_SETUP         0x0B    /* Tri-Speed MAC Clock/Reset Setup */
+#define M2_DROP_CNT          0x0C    /* Drop Counter */
+#define M2_PORT_POS          0x0D    /* Preamble Port Position */
+#define M2_SERDES_CONF       0x0F    /* SerDes Configuration */
+#define M2_SERDES_TEST       0x10    /* SerDes Test */
+#define M2_SERDES_STAT       0x11    /* SerDes Status */
+#define M2_SERDES_COM_CNT    0x12    /* SerDes Comma Detect Counter */
+
+
+#define M2E_TRI_MULTI_DBG    0x0E    /* Multidebug register */
+
+
+/* M2_DENORM is already defined as 0x07 for 10 GbE, but it's 0x15 for
+ * tri-speed macs.  This is an unfortunate name collision in the manual,
+ * so define it as M2_TRI_DENORM for tri-speed macs. Unfortunately, it is
+ * not benign to mix up the tri-speed and 10G #defines!!!
+ */
+
+#define M2_TRI_DENORM        0x15    /* Frame Denormalization */
+
+#define M2E_TX_IFG           0x18    /* Tx Inter Frame Gap configuration */
+#define M2E_ADV_HDX_CFG      0x19    /* Advance Half Duplex configuration */
+
+
+/* Only Campbell-I have the following GFP-T registers */
+#define C1_GFPT_CONFIG       0x1A    /* GFP-T block configuration */
+#define C1_GFPT_CLIENT1      0x1B    /* Client signal configuration */
+#define C1_GFPT_CLIENT2      0x1C    /* Rate adaptation configuration */
+#define C1_GFPT_BLOCK_CODE   0x1D    /* GFP-T block encode */
+#define C1_GFPT_FRM_LEN      0x1E    /* GFP-T Frame length */
+#define C1_GFPT_HEAD_ENA     0x1F    /* GFP-T header expectation/generation */
+#define C1_GFPT_BIT_ERR_CORR  0x20   /* Bit error correction configuration */
+#define C1_GFPT_BIT_ERR_POS1  0x21   /* Bit error insertion position 1 */
+#define C1_GFPT_BIT_ERR_POS2  0x22   /* Bit error insertion position 2 */
+#define C1_GFPT_BIT_ERR_ONCE  0x23   /* Force bit error insertion once or continuously */
+#define C1_GFPT_BIT_ERR_FORCE 0x24   /* Force bit error insert at pos1 and/or pos2 */
+#define C1_GFPT_STATUS       0x25    /* GFPT Status */
+#define C1_GFPT_PCS_RX       0x26    /* PCS RX Setup */
+#define C1_GFPT_PCS_TX       0x27    /* PCS TX Setup */
+
+
+/* Statistics Block Registers (Block ID: STATISTICS) */
+/* Subblock Tri-Speed MACs 0x00-0x09 */
+
+#define M2_RX_IN_BYTES       0x00    /* RX # of Nibbles or Bytes */
+#define M2_RX_SYMBOL_CARRIER 0x01    /* RX # of Symbol Errors, No Collisions */
+#define M2_RX_PAUSE          0x02    /* RX # of Pause Control Frames */
+#define M2_RX_UNSUP_OPCODE   0x03    /* RX # of Unsupported Opcode Frames */
+#define M2_RX_OK_BYTES       0x04    /* RX # of Bytes in Valid Frames */
+#define M2_RX_BAD_BYTES      0x05    /* RX # of Bytes in Error Frames */
+#define M2_RX_UNICAST        0x06    /* RX # of Valid Unicast Frames */
+#define M2_RX_MULTICAST      0x07    /* RX # of Valid Multicast Frames */
+#define M2_RX_BROADCAST      0x08    /* RX # of Valid Broadcast Frames */
+#define M2_RX_CRC            0x09    /* RX # of CRC Error Only Frames */
+#define M2_RX_ALIGNMENT      0x0A    /* RX # of Alignment Error Frames */
+#define M2_RX_UNDERSIZE      0x0B    /* RX # of Undersize Well Formed Frames */
+#define M2_RX_FRAGMENTS      0x0C    /* RX # of Undersize with CRC Error */
+#define M2_RX_IN_RANGE_LENGTH_ERROR 0x0D    /* RX # of Frames with Legal
+                                               Lengths but Mismatch */
+#define M2_RX_OUT_OF_RANGE_ERROR    0x0E    /* RX # of Frames with Illegal
+                                               Length Field */
+
+/* NOTE: Names for RX_SIZE_ and TX_SIZE_ registers deviate from manual names
+ * for typing convenience
+ */
+
+#define M2_RX_OVERSIZE       0x0F    /* RX # of Oversize Well Formed Frames */
+#define M2_RX_JABBERS        0x10    /* RX # of Oversize with CRC Error */
+#define M2_RX_SIZE_64        0x11    /* RX # of 64 Byte Frames */
+#define M2_RX_SIZE_65        0x12    /* RX # of 65-127 Byte Frames */
+#define M2_RX_SIZE_128       0x13    /* RX # of 128-255 Byte Frames */
+#define M2_RX_SIZE_256       0x14    /* RX # of 256-511 Byte Frames */
+#define M2_RX_SIZE_512       0x15    /* RX # of 512-1023 Byte Frames */
+#define M2_RX_SIZE_1024      0x16    /* RX # of 1024-1518 Byte Frames */
+#define M2_RX_SIZE_1519      0x17    /* RX # of > 1518 Byte Allowed Frames */
+
+
+#define M2_TX_OUT_BYTES      0x18    /* TX # of Bytes (Good, Bad, Framing) */
+#define M2_TX_PAUSE          0x19    /* TX # of Pause Control Frames */
+#define M2_TX_OK_BYTES       0x1A    /* TX # of Bytes Successful */
+#define M2_TX_UNICAST        0x1B    /* TX # of Unicast Frames */
+#define M2_TX_MULTICAST      0x1C    /* TX # of Multicast Frames */
+#define M2_TX_BROADCAST      0x1D    /* TX # of Broadcast Frames */
+#define M2_TX_MULTIPLE_COLL  0x1E    /* TX # of Frames Successful After
+                                        Multiple Collisions */
+#define M2_TX_LATE_COL       0x1F    /* TX # of Late Collisions Detected */
+#define M2_TX_XCOLL          0x20    /* TX # of Frames Lost Due to 
+                                        Excessive Collisions */
+#define M2_TX_DEFER          0x21    /* TX # of Frames Deferred on First Try */
+#define M2_TX_XDEFER         0x22    /* TX # of Frames Sent with Excessive
+                                        Deferral*/
+#define M2_TX_CSENSE         0x23    /* TX # of Carrier Sense Error at End
+                                        of Frame Transmission*/
+#define M2_TX_SIZE_64        0x24    /* TX # of 64 Byte Frames */
+#define M2_TX_SIZE_65        0x25    /* TX # of 65-127 Byte Frames */
+#define M2_TX_SIZE_128       0x26    /* TX # of 128-255 Byte Frames */
+#define M2_TX_SIZE_256       0x27    /* TX # of 256-511 Byte Frames */
+#define M2_TX_SIZE_512       0x28    /* TX # of 512-1023 Byte Frames */
+#define M2_TX_SIZE_1024      0x29    /* TX # of 1024-1518 Byte Frames */
+#define M2_TX_SIZE_1519      0x2A    /* TX # of > 1518 Byte Allowed Frames */
+#define M2_TX_SINGLE_COL     0x2B    /* TX # of Single Collision Transmits */
+#define M2_TX_BACKOFF2       0x2C    /* TX # of Frames 2 backoff/collision */
+#define M2_TX_BACKOFF3       0x2D    /* TX # of Frames 3 backoff/collision */
+#define M2_TX_BACKOFF4       0x2E    /* TX # of Frames 4 backoff/collision */
+#define M2_TX_BACKOFF5       0x2F    /* TX # of Frames 5 backoff/collision */
+#define M2_TX_BACKOFF6       0x30    /* TX # of Frames 6 backoff/collision */
+#define M2_TX_BACKOFF7       0x31    /* TX # of Frames 7 backoff/collision */
+#define M2_TX_BACKOFF8       0x32    /* TX # of Frames 8 backoff/collision */
+#define M2_TX_BACKOFF9       0x33    /* TX # of Frames 9 backoff/collision */
+#define M2_TX_BACKOFF10      0x34    /* TX # of Frames 10 backoff/collision */
+#define M2_TX_BACKOFF11      0x35    /* TX # of Frames 11 backoff/collision */
+#define M2_TX_BACKOFF12      0x36    /* TX # of Frames 12 backoff/collision */
+#define M2_TX_BACKOFF13      0x37    /* TX # of Frames 13 backoff/collision */
+#define M2_TX_BACKOFF14      0x38    /* TX # of Frames 14 backoff/collision */
+#define M2_TX_BACKOFF15      0x39    /* TX # of Frames 15 backoff/collision */
+#define M2_TX_UNDERRUN       0x3A    /* TX # of FIFO Underrun Frame Drops */
+
+
+#define M2_RX_XGMII_PROT_ERR 0x3B    /* XGMII_RX Interface Protocol Errors */
+                                     /* NOTE: Only Available on 10 GbE MAC */
+
+#define M2_RX_IPG_SHRINK     0x3C    /* IPG Shrink Detected Counter */
+
+#define M2_STAT_STICKY1G     0x3E    /* Tri-Speed MAC Sticky Bits */
+#define M2_STAT_STICKY10G    0x3E    /* 10 GbE MAC Sticky Bits */
+
+#define M2_STAT_INIT         0x3F    /* Clears Statistics in all Tri-Speed
+                                        or 10 GbE depending on subblock */
+
+/* MII Management Block Registers (Block ID: MIIM) */
+/* Subblock Management #0-1 0x00-0x01 */
+
+#define M2_MIIM_STATUS       0x00    /* MII-M Status */
+#define M2_MIIM_CMD          0x01    /* MII-M Command */
+#define M2_MIIM_DATA         0x02    /* MII-M Data */
+#define M2_MIIM_PRESCALE     0x03    /* MII-M MDC Pre-Scale */
+
+
+/*************   Most oftern used bits and bitmasks       ******************** */
+#define M2_NORMALIZER_BIT_NLE    0x00000004
+#define M2_NORMALIZER_BIT_NH     0x00000002
+#define M2_NORMALIZER_BIT_PH     0x00000001
+
+
+#define M2_DENORMAL_BIT_EXP_NH   0x00000002
+#define M2_DENORMAL_BIT_ECP_PH   0x00000001
+
+
+#endif /* _MEIGSII_REG_H */
+/****************************************************************************/
+/*                                                                          */
+/*  End of file.                                                            */
+/*                                                                          */
+/****************************************************************************/
diff --git a/drivers/net/rmi_spi4/os_layer.c b/drivers/net/rmi_spi4/os_layer.c
new file mode 100644
index 0000000..412de4d
--- /dev/null
+++ b/drivers/net/rmi_spi4/os_layer.c
@@ -0,0 +1,97 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/gfp.h>
+
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+
+#include "os_layer.h"
+
+#define PHNX_RX_BUF_SIZE (MAX_FRAME_SIZE+SPI4_BYTE_OFFSET+MAC_PREPAD+ \
+		                MAC_SKB_BACK_PTR_SIZE+SMP_CACHE_BYTES)
+
+
+void os_free_buffer(char *addr){
+	kfree(addr);
+	return;
+}
+
+char*	os_malloc(unsigned long size){
+	return	kmalloc(size, GFP_KERNEL);
+
+}
+
+
+char*	os_malloc_buffer(){
+
+	return  kmalloc(PHNX_RX_BUF_SIZE, GFP_KERNEL);
+
+}
+
+
+
+void* os_cacheline_aligned_kmalloc(int size){
+
+	void *buf = kmalloc(size+SMP_CACHE_BYTES, GFP_KERNEL);
+	if (buf){
+		buf = (void *)(CACHELINE_ALIGNED_ADDR(
+			(unsigned long)buf+SMP_CACHE_BYTES));
+	}
+	return buf;
+}
+
+
+struct sk_buff *os_alloc_skb(void){
+
+	int offset=0;
+	struct sk_buff *skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE, GFP_KERNEL);
+
+	if (!skb) {
+		return NULL;
+	}
+
+	/* align the data to the next cache line */
+	offset = ((unsigned long)skb->data + SMP_CACHE_BYTES) &
+		~(SMP_CACHE_BYTES - 1);
+	skb_reserve(skb, (offset - (unsigned long)skb->data));
+
+	return skb;
+}
+
+
+void os_free(struct sk_buff *skb){
+
+	//	dev_kfree_skb(skb);
+	dev_kfree_skb_irq(skb);
+
+	return;
+}
diff --git a/drivers/net/rmi_spi4/os_layer.h b/drivers/net/rmi_spi4/os_layer.h
new file mode 100644
index 0000000..69c2caf
--- /dev/null
+++ b/drivers/net/rmi_spi4/os_layer.h
@@ -0,0 +1,51 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_OS_LAYER_H
+#define _ASM_RMI_OS_LAYER_H
+
+#include "rmi_spi4_config.h"
+
+extern char* os_malloc(unsigned long size);
+
+extern char* os_malloc_buffer(void);
+
+extern void* os_cacheline_aligned_kmalloc(int size);
+
+extern struct sk_buff *os_alloc_skb(void);
+
+extern void os_free(struct sk_buff *skb);
+
+extern void os_free_buffer(char *addr);
+
+#define CACHELINE_ALIGNED_ADDR(addr) (((unsigned long)(addr)) & ~(SMP_CACHE_BYTES-1))
+
+
+#endif
diff --git a/drivers/net/rmi_spi4/rmi_spi4.c b/drivers/net/rmi_spi4/rmi_spi4.c
new file mode 100644
index 0000000..48d81ff
--- /dev/null
+++ b/drivers/net/rmi_spi4/rmi_spi4.c
@@ -0,0 +1,864 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/types.h>
+#include <linux/sched.h>
+#include <linux/delay.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/io.h>
+#include <asm/cache.h>
+
+#include "os_layer.h"
+#include "rmi_spi4.h"
+#include "rmi_spi4_config.h"
+#include <asm/rmi/phoenix_mac.h>
+#include <asm/rmi/msgring.h>
+#include "rmi_vits_driver.h"
+
+#define CLEAR_INT 0xf
+#define CLEAR_TX_STATUS 0x0f
+#define CLEAR_RX_STATUS 0x1f
+#define MAX_BUCKET 64
+#define RMI_SPI4_MAX_THREADS 32
+#define RMI_SPI4_DEBUG 0
+#define MAX_NUM_MSGRNG_STN_CC   128
+
+unsigned long g_dip4_error[RMI_SPI4_MAX_THREADS];
+
+extern int xlr_loader_support;
+extern int xlr_loader_sharedcore;
+extern void rmik_config_pde(int type, int instance, phoenix_reg_t *mmio);
+
+spi4_driver_data*	spi4_data[TOTAL_SPI4];
+
+static void spi4_msgring_handler(	int 	bucket, 
+					int 	size, 
+					int 	code, 
+					int 	stid, 
+					struct msgrng_msg *msg, 
+					void 	*data);
+
+extern void rx_indication(int port, 	char* addr, 	int len);
+extern void tx_complete(int port, 	char* addr);
+
+#if RMI_SPI4_DEBUG
+void spi4_init_read_counter(unsigned int	*mmio)
+{
+	mmio[0x236] = 0; // read count0 of debugcount0
+	mmio[0x237] = 0; // read count1 of debugcount0
+
+	mmio[0x23a] = 0; // read count0 of debugcount1
+	mmio[0x23b] = 0; // read count1 of debugcount1
+
+	return;
+}
+
+void spi4_write_select(unsigned int  *mmio,int write_select,	int bit_no)
+{
+	long value;
+	value = 1<<bit_no;
+	printk("write_select=%d, bit no=%d,value=0x%lx\n", 
+		write_select, bit_no,value);
+	switch(write_select){
+	case 0:
+		mmio[0x234] = value;
+		break;
+	case 1:
+		mmio[0x235] = value;
+		break;
+	case 2:
+		mmio[0x238] = value;
+		break;
+	case 3:
+		mmio[0x239] = value;
+		break;
+	default:
+		printk("wrong write select\n");
+	}// end of switch
+	return;
+}
+
+void spi4_print_debug_value(unsigned int  *mmio)
+{
+
+	printk(" Read counter0 = %d\n", mmio[0x236]);
+	printk(" Read counter1 = %d\n", mmio[0x237]);
+	printk(" Read counter3 = %d\n", mmio[0x23a]);
+	printk(" Read counter4 = %d\n", mmio[0x23b]);
+
+	return;
+}
+
+#endif
+/*******************************************************************************
+*
+* Function name	:	spi4_configure_pde_spray_mode
+* Input		:	spi4 slot
+* Description	:	This function will program the PDE for the given 
+*	spi4 slot. Based on the cpu mask, it will check the enabled cpu and 
+*	then calculates the bucket mapp, with this bucket map it will program
+*	all the 4 classes of PDE .
+*	
+* RETURNS: void
+*******************************************************************************/
+static int spi4_configure_pde_spray_mode(uint32 slot, struct port_cfg *pcfg)
+{
+
+	int i, cpu=0, bkt=0;
+	__u64 bucket_map = 0;
+	bucket_t *bucket;
+	struct stn_cc *credit;
+	spi4_driver_data*   driver_data;
+	unsigned int        *mmio;
+
+	driver_data = spi4_data[slot];
+	mmio = driver_data->mmio;
+
+	if(!(PORT_INIT(driver_data->cfg_flag)))
+		return SPI4_CONFIG_PDE_SUCCESS;
+
+	for_each_online_cpu(i) {
+		cpu = cpu_logical_map(i);
+		bkt = ((cpu >> 2)<<3)|(cpu & 0x03);
+		bucket_map |= (1ULL << bkt);
+	}
+
+	if(pcfg->config_pde) {
+		phoenix_write_reg(mmio, R_PDE_CLASS_0, (bucket_map & 0xffffffff));
+		phoenix_write_reg(mmio, R_PDE_CLASS_0+1, 
+				((bucket_map>>RMI_SPI4_MAX_THREADS) & 0xffffffff));
+
+		phoenix_write_reg(mmio, R_PDE_CLASS_1, (bucket_map & 0xffffffff));
+		phoenix_write_reg(mmio, R_PDE_CLASS_1+1, 
+				((bucket_map>>RMI_SPI4_MAX_THREADS) & 0xffffffff));
+
+		phoenix_write_reg(mmio, R_PDE_CLASS_2, (bucket_map & 0xffffffff));
+		phoenix_write_reg(mmio, R_PDE_CLASS_2+1,
+			 ((bucket_map>>RMI_SPI4_MAX_THREADS) & 0xffffffff));
+
+		phoenix_write_reg(mmio, R_PDE_CLASS_3, (bucket_map & 0xffffffff));
+		phoenix_write_reg(mmio, R_PDE_CLASS_3+1, 
+			((bucket_map>>RMI_SPI4_MAX_THREADS) & 0xffffffff));
+	}
+
+
+	bucket = pcfg->bucket;
+	credit = pcfg->credit;
+
+	if(slot == SPI4_0){
+		for(i=0;i<XLR_MAX_SPI4_CHANNEL;i++){
+			phoenix_write_reg(mmio, R_XGS_TX0_BUCKET_SIZE+i, 
+			bucket[MSGRNG_STNID_XGS0_TX+i]);
+		}
+
+		phoenix_write_reg(mmio, R_XGS_RFR_BUCKET_SIZE, 
+			bucket[MSGRNG_STNID_XMAC0RFR]);
+
+	}
+	else if(slot == SPI4_1){
+		for(i=0;i<XLR_MAX_SPI4_CHANNEL;i++)
+			phoenix_write_reg(mmio, R_XGS_TX0_BUCKET_SIZE+i, 
+				bucket[MSGRNG_STNID_XGS1_TX+i]);
+
+		phoenix_write_reg(mmio, R_XGS_RFR_BUCKET_SIZE, 
+			bucket[MSGRNG_STNID_XMAC1RFR]);
+
+	}
+	for(i=0;i<128;i++){
+		phoenix_write_reg(mmio, R_CC_CPU0_0 + i, 
+		credit->counters[i>>3][i&0x07]);
+	}
+
+	return SPI4_CONFIG_PDE_SUCCESS;
+}
+
+static void spi4_free_spill_memory(spi4_driver_data*   driver_data)
+{
+	if(driver_data->frin_spill != NULL)
+		kfree(driver_data->frin_spill);
+	
+	if(driver_data->frout_spill != NULL)
+		kfree(driver_data->frout_spill);
+	
+	if(driver_data->class_0_spill != NULL)
+		kfree(driver_data->class_0_spill);
+
+	if(driver_data->class_1_spill != NULL)
+		kfree(driver_data->class_1_spill);
+
+	if(driver_data->class_2_spill != NULL)
+		kfree(driver_data->class_2_spill);
+
+	if(driver_data->class_3_spill != NULL)
+		kfree(driver_data->class_3_spill);
+
+	return;
+}	
+
+static void* config_spill(unsigned int *mmio, int reg_start_0,
+		int 	reg_start_1,
+		int 	reg_size, 
+		int 	size,
+		void**	spill_orig)
+{
+
+	__u32 spill_size = CACHELINE_ALIGNED_ADDR(size);
+	void *spill = os_cacheline_aligned_kmalloc(spill_size);
+	__u64 phys_addr = 0;
+
+	if (!spill) {
+		return NULL;
+	}
+	*spill_orig = spill;
+	phys_addr = virt_to_phys(spill);
+	phoenix_write_reg(mmio, reg_start_0, ((phys_addr >> 5) & 0xffffffff));
+
+	phoenix_write_reg(mmio, reg_start_1, ((phys_addr >> 37) & 0x07));
+
+	phoenix_write_reg(mmio, reg_size, spill_size);
+
+	return spill;
+}
+
+/*******************************************************************************
+* Function name :       spi4_configure_spill_memory
+* Input         :
+* Description   :       This function programs the freein, free out and class0, 
+*	class1, class2 spill memory
+* RETURNS       :       void
+*******************************************************************************/
+
+static int spi4_configure_spill_memory(uint32 slot)
+{
+
+	spi4_driver_data*   driver_data;
+	unsigned int        *mmio;
+
+	driver_data = spi4_data[slot];
+	mmio = driver_data->mmio;
+
+	if(!(MSGRNG_OWN(driver_data->cfg_flag)))
+		return SPI4_CONFIG_SPILL_SUCCESS;
+
+	if(config_spill(mmio,R_REG_FRIN_SPILL_MEM_START_0,
+			R_REG_FRIN_SPILL_MEM_START_1,R_REG_FRIN_SPILL_MEM_SIZE,
+			MAX_FRIN_SPILL * sizeof(struct fr_desc),
+			&driver_data->frin_spill) == NULL){
+		return SPI4_CONFIG_SPILL_FAIL ;
+	}
+
+	if(config_spill(mmio, R_FROUT_SPILL_MEM_START_0,
+			R_FROUT_SPILL_MEM_START_1,
+			R_FROUT_SPILL_MEM_SIZE,
+			(2* MAX_FROUT_SPILL * sizeof(struct fr_desc)),
+			&driver_data->frout_spill) == NULL){
+			spi4_free_spill_memory(driver_data);
+			return SPI4_CONFIG_SPILL_FAIL ;	
+	}
+
+	if(config_spill(mmio, R_CLASS0_SPILL_MEM_START_0,
+			R_CLASS0_SPILL_MEM_START_1,
+			R_CLASS0_SPILL_MEM_SIZE,
+			MAX_CLASS_0_SPILL * sizeof(union rx_tx_desc),
+			&driver_data->class_0_spill) == NULL){
+			spi4_free_spill_memory(driver_data);
+			return SPI4_CONFIG_SPILL_FAIL;
+	}
+
+	if(config_spill(mmio,R_CLASS1_SPILL_MEM_START_0,
+			R_CLASS1_SPILL_MEM_START_1,
+			R_CLASS1_SPILL_MEM_SIZE,
+			MAX_CLASS_1_SPILL * sizeof(union rx_tx_desc),
+			&driver_data->class_1_spill) == NULL){
+			spi4_free_spill_memory(driver_data);
+			return SPI4_CONFIG_SPILL_FAIL ;
+	}
+
+
+	if(config_spill(mmio,R_CLASS2_SPILL_MEM_START_0,
+			R_CLASS2_SPILL_MEM_START_1,
+			R_CLASS2_SPILL_MEM_SIZE,
+			MAX_CLASS_2_SPILL * sizeof(union rx_tx_desc),
+			&driver_data->class_2_spill) == NULL){
+			spi4_free_spill_memory(driver_data);
+			return SPI4_CONFIG_SPILL_FAIL ;
+	}
+
+	if( config_spill(mmio, R_CLASS3_SPILL_MEM_START_0,
+			R_CLASS3_SPILL_MEM_START_1,
+			R_CLASS3_SPILL_MEM_SIZE,
+			MAX_CLASS_3_SPILL * sizeof(union rx_tx_desc),
+			&driver_data->class_3_spill) == NULL){
+			spi4_free_spill_memory(driver_data);
+			return SPI4_CONFIG_SPILL_FAIL ;
+	}
+
+	return SPI4_CONFIG_SPILL_SUCCESS;
+}//end of spi4_configure_spill_memory
+
+
+/*******************************************************************************
+*
+* Function name :       spi4_register_msgrng_handler
+* Input         :       spi4 slot
+* Description   :       This function will register message ring handler for the 
+*       given spi4. Registered function will be called whenever msg will be send 
+*	by the spi4. 
+* RETURNS	: 	int
+*			1 - fail
+*			0 - success
+*******************************************************************************/
+
+static int spi4_register_msgrng_handler(uint32 slot)
+{
+	spi4_driver_data*   driver_data;
+	driver_data = spi4_data[slot];
+	
+	if(slot == SPI4_0){
+		if (register_msgring_handler(TX_STN_XGS_0, 
+		spi4_msgring_handler, NULL)) {
+			return SPI4_REGISTER_MSGRING_FAIL;
+		}
+	}	
+	else if(slot == SPI4_1){
+		if (register_msgring_handler(TX_STN_XGS_1, 
+		spi4_msgring_handler, NULL)) {
+			return SPI4_REGISTER_MSGRING_FAIL;
+		}
+	}
+	else{
+		/*invalid spi4*/
+		return SPI4_SLOT_ERROR;
+	}
+
+	return SPI4_REGISTER_MSGRING_SUCESS;
+}// end of spi4_register_msgrng_handler()
+
+static int spi4_validate_config_params(void)
+{
+	if(XLR_TOTAL_CHANNELS > XLR_MAX_SPI4_CHANNEL){
+		printk("invalid total channels\n");
+		return SPI4_CALENDER_LEN_ERROR ;
+	}
+	if(XLR_SPI4_TX_MAXBURST1 > XLR_MAX_TX_BURST){
+		printk("invalid TX max burst1\n");
+		return SPI4_TX_MAXBURST1_ERROR;
+	}
+	if(XLR_SPI4_TX_MAXBURST2 > XLR_MAX_TX_BURST){
+		printk("invalid TX max burst2\n");
+		return SPI4_TX_MAXBURST2_ERROR;
+	}
+	if(XLR_SPI4_RX_MAXBURST1 > XLR_MAX_RX_BURST){
+		printk("invalid RX max burst1\n");
+		return SPI4_RX_MAXBURST1_ERROR;
+	}
+	if(XLR_SPI4_RX_MAXBURST2 > XLR_MAX_RX_BURST){
+		printk("invalid RX max burst2\n");
+		return SPI4_RX_MAXBURST2_ERROR;
+	}
+	if(XLR_SPI4_TX_MAXBURST2 < XLR_SPI4_TX_MAXBURST1){
+		printk("invalid TX max bursts\n");
+		return SPI4_TX_MAX_BURST_ERROR;
+	}
+	if(XLR_SPI4_RX_MAXBURST2 < XLR_SPI4_RX_MAXBURST1){
+		printk("invalid RX max bursts\n");
+		return SPI4_RX_MAX_BURST_ERROR ;
+	}
+	if(SPI4_BYTE_OFFSET > XLR_MAX_SPI4_BYTE_OFFSET){
+		printk("invalid byte offset\n");
+		return SPI4_BYTE_OFFSET_ERROR;
+	}
+	return SPI4_PARAMS_VALID;
+}	
+
+void spi4_disable_tx_rx(unsigned int	*mmio)
+{
+	uint32  reg_val;
+	
+	reg_val = phoenix_read_reg(mmio, SPI4_CNTRL_REG);
+        reg_val &= ~(0xa);
+        phoenix_write_reg(mmio, SPI4_CNTRL_REG, reg_val ) ;
+
+	return;
+}	
+
+void spi4_enable_tx_rx(unsigned int	*mmio)
+{
+	uint32  reg_val;
+	
+	reg_val = phoenix_read_reg(mmio, SPI4_CNTRL_REG);
+        reg_val |= 0xa;
+        phoenix_write_reg(mmio, SPI4_CNTRL_REG, reg_val ) ;
+
+	return;
+}
+
+/*******************************************************************************
+*
+* Function name :       spi4_init
+* Input         :       spi4 slot, callback function
+* Description   :       This function will initialize the given spi4. It resets 
+*	the spi4, programs the tx calender, max burst, DMA and spi4 channels 
+*	and FIFO. 
+* RETURNS: void
+*******************************************************************************/
+
+unsigned int spi4_init(uint32 	slot, spi4_callback_func calbk_func )
+{
+	uint32	reg_val, byte_offset=0;
+	int i;
+	unsigned int 			*mmio, spi4_ret_value;
+	spi4_driver_data*		driver_data;
+	int tx_fifo_base[XLR_MAX_SPI4_CHANNEL];
+	int tx_fifo_size[XLR_MAX_SPI4_CHANNEL];
+	int rx_fifo_base[XLR_MAX_SPI4_CHANNEL];
+	int rx_fifo_size[XLR_MAX_SPI4_CHANNEL];
+	extern struct net_device_cfg phnx_net_dev_cfg;
+	struct net_device_cfg *net_cfg = &phnx_net_dev_cfg;
+	struct port_cfg *port_cfg;
+
+	port_cfg = &net_cfg->xgs_port[slot];
+	/* if support for loading apps on same core as Linux is enabled */
+	if(port_cfg->cfg_flag == 0)
+		return -EINVAL;
+
+	if((slot < SPI4_0) || (slot > SPI4_1)){
+		return SPI4_SLOT_ERROR;
+	}
+	driver_data = (spi4_driver_data*) os_malloc(sizeof(spi4_driver_data));
+	
+	if(driver_data == NULL){
+		return SPI4_MALLOC_FAIL;
+	}
+	driver_data->frin_spill =driver_data->frout_spill = NULL; 
+	driver_data->class_0_spill = driver_data->class_1_spill = NULL;
+	driver_data->class_2_spill = driver_data->class_3_spill = NULL; 
+
+	spi4_data[slot] = driver_data;
+
+
+	/*initilizing the spi4 and elements of the driver data*/
+	driver_data->calbk_func  = calbk_func;
+	driver_data->spi4_slot   = slot;
+	driver_data->tx_calendar = driver_data->rx_calendar = XLR_TOTAL_CHANNELS;
+	driver_data->tx_cal_sequence = TX_CAL_SEQ;
+	driver_data->rx_cal_sequence = RX_CAL_SEQ;	
+	driver_data->tx_maxburst1 = XLR_SPI4_TX_MAXBURST1;
+	driver_data->tx_maxburst2 = XLR_SPI4_TX_MAXBURST2;
+	driver_data->rx_maxburst1 = XLR_SPI4_RX_MAXBURST1;
+	driver_data->rx_maxburst2 = XLR_SPI4_RX_MAXBURST2;
+
+	driver_data->cfg_flag = port_cfg->cfg_flag;
+	driver_data->mmio = (uint32_t *)port_cfg->mmio_addr;
+	mmio = driver_data->mmio;
+
+	if(PORT_INIT(driver_data->cfg_flag)) {
+		spi4_ret_value = spi4_validate_config_params();
+		if(spi4_ret_value != SPI4_PARAMS_VALID){
+			printk("invalid configuration parameters\n");
+			return spi4_ret_value ;
+		}
+
+		/*configuring the IP registers*/
+		reg_val = phoenix_read_reg(mmio, SPI4_CNTRL_REG);
+		reg_val &= ~(0xa);
+		phoenix_write_reg(mmio, SPI4_CNTRL_REG, reg_val ) ; 
+
+		/*programming the Hungry thresholds*/
+		phoenix_write_reg(mmio, R_SPIHNGY0, 0x04040404);
+		phoenix_write_reg(mmio, R_SPIHNGY1, 0x04040404 );
+		phoenix_write_reg(mmio, R_SPIHNGY2, 0x04040404);
+		phoenix_write_reg(mmio, R_SPIHNGY3, 0x04040404);
+
+		/*programming the starving thresholds*/
+		phoenix_write_reg(mmio, R_SPISTRV0, 0x06060606);
+		phoenix_write_reg(mmio, R_SPISTRV1, 0x06060606);
+		phoenix_write_reg(mmio, R_SPISTRV2, 0x06060606);
+		phoenix_write_reg(mmio, R_SPISTRV3, 0x06060606);
+
+		phoenix_write_reg(mmio, 0x50, 4);/* F_ALPHA */
+		/*programming the DMA credits*/
+		phoenix_write_reg(mmio, R_DMACR0, 0xffffffff);
+		phoenix_write_reg(mmio, R_DMACR1, 0xffffffff);
+		phoenix_write_reg(mmio, R_DMACR2, 0xffffffff);
+		phoenix_write_reg(mmio, R_DMACR3, 
+			(0xff<<24)|(2<<21)|(2<<18)|(2<<12)|(2<<9)|(2<<6)|(2<<3)|(2<<0));
+
+		vtss_rmi_init(slot+1);
+
+		for(i=0; i<8; i++){
+			byte_offset <<= 3 ;
+			byte_offset |= SPI4_BYTE_OFFSET ; 	
+		}
+ 		phoenix_write_reg(mmio,DESC_PKT_CTRL_1,byte_offset);
+	 	phoenix_write_reg(mmio,DESC_PKT_CTRL_2,byte_offset);
+		phoenix_write_reg(mmio, PAD_CALIB_0,0x02030);
+
+
+	  /*configure: TX cal, RX cal and cal seq*/
+	  phoenix_write_reg(mmio, SPI4_TX_CAL_LEN, driver_data->tx_calendar);
+	  phoenix_write_reg(mmio, SPI4_RX_CAL_LEN, driver_data->rx_calendar);
+	  phoenix_write_reg(mmio, SPI4_TX_CAL_MAX , driver_data->tx_cal_sequence);
+	  phoenix_write_reg(mmio, SPI4_RX_CAL_MAX, driver_data->rx_cal_sequence);
+
+
+		for(i=0;i< driver_data->tx_calendar; i++){
+		  	phoenix_write_reg(mmio,SPI4_TX_CAL_X, (i | (i<<16)));
+		}
+		for(i=0;i< driver_data->rx_calendar; i++){
+		  	phoenix_write_reg(mmio,SPI4_RX_CAL_X, (i | (i<<16)));
+		}
+	}
+	
+	if(PORT_EN(driver_data->cfg_flag)) {
+
+		phoenix_write_reg(mmio, R_TX_CONTROL,
+      		((1<<W_TX_CONTROL__TxThreshold) | TX_THRESHOLD_SIZE));
+
+		phoenix_write_reg(mmio, R_RX_CONTROL, 1);
+
+	}
+
+	if(PORT_INIT(driver_data->cfg_flag)) {
+		phoenix_write_reg(mmio, R_DESC_PACK_CTRL,
+		    ((4 << 20) | REG_FRAME_SIZE));
+
+		phoenix_write_reg(mmio, R_L2ALLOCCTRL, 0x2);
+
+		mdelay(5);
+
+		phoenix_write_reg(mmio, SPI4_INTR_REG, CLEAR_INT);
+		phoenix_write_reg(mmio, SPI4_TX_STATUS , CLEAR_TX_STATUS);
+		phoenix_write_reg(mmio, SPI4_RX_STATUS, CLEAR_RX_STATUS);
+
+
+		/* change rx maxburst 1 */
+		for (i=0;i<XLR_MAX_SPI4_CHANNEL;i++)
+    		phoenix_write_reg(mmio, SPI4_RX_MAXBURST1_I,
+        		XLR_SPI4_RX_MAXBURST1 + (i << XLR_MAX_SPI4_CHANNEL));
+
+
+	  	/* change rx maxburst 2 */
+		for (i=0;i<XLR_MAX_SPI4_CHANNEL;i++)
+		    phoenix_write_reg(mmio, SPI4_RX_MAXBURST2_I,
+        		XLR_SPI4_RX_MAXBURST2 + (i << XLR_MAX_SPI4_CHANNEL));
+
+		for (i=0;i<XLR_MAX_SPI4_CHANNEL;i++){
+    		tx_fifo_base[i]  = i*8;  
+		    tx_fifo_size[i]  = 8 ; 
+    		rx_fifo_base[i]  = i*32;  
+	    	rx_fifo_size[i]  = 32 ; 
+  		}
+
+
+		for (i=0;i<XLR_MAX_SPI4_CHANNEL;i++){
+    		phoenix_write_reg(mmio, SPI4_TX_FIFO_BASE_I,
+      				tx_fifo_base[i] + (i<<XLR_MAX_SPI4_CHANNEL));
+		    phoenix_write_reg(mmio, SPI4_RX_FIFO_BASE_I,
+      				rx_fifo_base[i] + (i<<XLR_MAX_SPI4_CHANNEL));
+  		}
+
+	 	for (i=0;i<XLR_MAX_SPI4_CHANNEL;i++){
+    		phoenix_write_reg(mmio, SPI4_TX_FIFO_DEPTH_I,
+		   		tx_fifo_size[i] + (i<< XLR_MAX_SPI4_CHANNEL));
+		    phoenix_write_reg(mmio, SPI4_RX_FIFO_DEPTH_I,
+      			rx_fifo_size[i] + (i<< XLR_MAX_SPI4_CHANNEL));
+  		}
+	}
+
+	if(PORT_EN(driver_data->cfg_flag)) {
+		phoenix_write_reg(mmio, 0x78, 4);
+		phoenix_write_reg(mmio, SPI4_CNTRL_REG, 0x00000e0f);
+
+		mdelay(10);
+
+		i = phoenix_read_reg(mmio, SPI4_TX_STATUS);
+		if(!(i & SPI4_TX_STATUS_TX_SYNC)){
+			spi4_disable_tx_rx(mmio);
+			printk("TX path no sync\n");
+			return SPI4_TX_SYNC_FAIL;
+		}
+
+		i = phoenix_read_reg(mmio, SPI4_RX_STATUS);
+		if(!(i & SPI4_RX_STATUS_RX_SYNC)){
+			spi4_disable_tx_rx(mmio);
+			printk("RX path no sync\n");
+			return SPI4_RX_SYNC_FAIL;
+		}
+	}
+	
+	spi4_ret_value = spi4_configure_spill_memory(slot);
+	if(spi4_ret_value != SPI4_CONFIG_SPILL_SUCCESS){
+			spi4_disable_tx_rx(mmio);
+			printk("spill memory configuration failed\n");
+			return spi4_ret_value;
+	}
+
+	spi4_ret_value = spi4_configure_pde_spray_mode(slot, port_cfg);
+	if(spi4_ret_value != SPI4_CONFIG_PDE_SUCCESS){
+			spi4_disable_tx_rx(mmio);
+			spi4_free_spill_memory(driver_data);
+			printk("pde configuration failed\n");
+			return spi4_ret_value ;
+	}
+
+	if(PORT_INIT(driver_data->cfg_flag)) 
+		rmik_config_pde(TYPE_SPI4, slot, mmio);
+
+	spi4_ret_value = spi4_register_msgrng_handler(slot);
+	if(spi4_ret_value != SPI4_REGISTER_MSGRING_SUCESS){
+		spi4_disable_tx_rx(mmio);
+		spi4_free_spill_memory(driver_data);
+		printk("registering msgring handler failed\n");
+		return spi4_ret_value ;
+	}
+
+	return SPI4_INIT_SUCCESS;
+
+}// end of function spi4_init()
+/*******************************************************************************
+* Function name :       spi4_msgring_handler
+* Input         :       
+* Description   :       This function will be called when spi4 sends any msg. 
+*	It handles TX_DONE and RX_IND mesg and informs the same to registered
+*	function by the upper application.
+* RETURNS       :       void
+*******************************************************************************/
+static void spi4_msgring_handler(int 	bucket, 	int size, 
+			int	code, 		int stid,
+			struct 	msgrng_msg *msg, void *data)
+{
+
+	unsigned int slot, port, ctrl, length;
+	unsigned long addr = 0;
+	unsigned int  error=0, th_id;
+	char*	ptr;
+	spi4_driver_data*   driver_data;
+
+
+	if(stid == MSGRNG_STNID_XGS0FR)
+		slot = SPI4_0;
+	else if(stid == MSGRNG_STNID_XGS1FR)
+		slot = SPI4_1;
+	else{
+		printk("ERROR: wrong slot\n");
+		return;
+	}
+	driver_data = spi4_data[slot];
+	port = get_port(msg->msg0);
+
+
+
+	length = get_length(msg->msg0);
+  if(length == 0)
+    ctrl = CTRL_REG_FREE;
+  else
+	  ctrl = CTRL_SNGL;
+
+
+	if (ctrl == CTRL_REG_FREE ) {
+   	/*TX complete*/
+    		addr = msg->msg0 & 0xffffffffffULL;
+    		addr = (unsigned long) phys_to_virt(addr);
+		ptr = (char*) addr;
+   	(*driver_data->calbk_func)
+      (SPI4_TX_DONE,slot,bucket,ptr,length, error);
+	}	
+	else if(ctrl == CTRL_SNGL || ctrl == CTRL_START){
+		/*RX indication*/
+		addr = (unsigned long) bus_to_virt(get_address(msg->msg0));
+		ptr = (char*) addr;
+		error = ((msg->msg0 >> 62)& 0x01);
+
+		if((port >= XLR_TOTAL_CHANNELS)){
+			/*if wrong port is received, then treat that as error packet
+			and try to replenish it*/
+			error = 1; 
+		}
+		
+		if(error){
+			spi4_program_rx_desc(slot,ptr);
+			th_id = hard_smp_processor_id();
+			g_dip4_error[th_id]++;
+		}
+		else{
+		length -=  (SPI4_BYTE_OFFSET + MAC_CRC_LEN );
+		(*driver_data->calbk_func)
+			(SPI4_RX_IND,slot,port,ptr,length, error);
+		}
+	}
+	return;
+}//spi4_msgring_handler()
+
+/*******************************************************************************
+* Function name :       spi4_tx
+* Input         :
+* Description   :       This function will be called by the upper application
+*	to transmit data. Before doing TX it makes sure TX and RX path are in 
+*	sync.
+* RETURNS       :       int
+*			1 - fail
+*			0 - success
+*******************************************************************************/
+
+int spi4_tx(	unsigned int thr_id, uint32 slot,  uint32 spi4_port, 
+						char* data, unsigned char* skb,uint32 len)
+{
+	unsigned int 		msgrng_flags;
+	spi4_driver_data*   	driver_data;
+	struct msgrng_msg 	msg;
+	int 			stid=0, ret =0;
+
+
+	driver_data = spi4_data[slot];
+
+	stid = spi4_make_desc_tx(thr_id, &msg,  driver_data->spi4_slot,
+													spi4_port, TYPE_SPI4, virt_to_phys(data), 
+													(unsigned long) skb, len);
+
+	__sync();
+	msgrng_access_enable(msgrng_flags);
+  if (message_send_retry(2, MSGRNG_CODE_SPI4, stid, &msg)){
+    ret =  SPI4_TX_FAIL;
+	}
+	msgrng_access_disable(msgrng_flags);
+	return ret;
+}// end of spi4_tx()
+
+/*******************************************************************************
+* Function name :       spi4_program_rx_desc
+* Input         :
+* Description   :       This function will make a regular free descriptor 
+*	and sends it to spi4.
+* RETURNS       :       int
+*                       1 - fail
+*                       0 - success
+*******************************************************************************/
+
+void spi4_program_rx_desc(uint32 	slot, 	
+			char*		addr)
+{
+
+	unsigned long 		msgrng_flags;
+	int 			stid = 0;
+	struct msgrng_msg 	msg;
+	spi4_driver_data*   	driver_data;
+
+	driver_data = spi4_data[slot];
+
+	stid = spi4_make_desc_rfr(&msg, driver_data->spi4_slot,
+				TYPE_SPI4 , virt_to_bus(addr));
+	__sync();
+	msgrng_access_enable(msgrng_flags);
+	while (message_send(1, MSGRNG_CODE_SPI4, stid, &msg));
+	msgrng_access_disable(msgrng_flags);
+
+
+	return ;	
+}
+
+
+/*******************************************************************************
+* Function name :       spi4_open
+* Input         :
+* Description   :       This function enable TX and RX of the spi4 also sends 
+*	a jumbo frame.
+* RETURNS       :       void
+*******************************************************************************/
+
+int spi4_open(uint32 slot)
+{
+
+	spi4_driver_data*	driver_data;
+	unsigned int        	*mmio;
+
+	driver_data = spi4_data[slot];
+	if(driver_data == NULL){
+		return  SPI4_SLOT_ERROR;
+	}
+
+	mmio = driver_data->mmio;
+	if(mmio == NULL){
+		return SPI4_MMIO_ERROR;
+	}
+
+		return SPI4_OPEN_SUCCESS;
+}// end of function spi4_open()
+
+/*******************************************************************************
+* Function name :       spi4_close
+* Input         :
+* Description   :       This function disable TX and RX of the spi4 .
+* RETURNS       :       void
+*******************************************************************************/
+
+void spi4_close(uint32 slot)
+{
+
+	spi4_driver_data*   	driver_data;
+	unsigned int        	*mmio;
+	unsigned int 		tmp;
+
+	driver_data = spi4_data[slot];
+	mmio = driver_data->mmio;
+
+	tmp = phoenix_read_reg(mmio, R_TX_CONTROL);
+	tmp &= ~(1<<W_TX_CONTROL__TxThreshold);
+	phoenix_write_reg(mmio, R_TX_CONTROL, tmp);
+
+	tmp = phoenix_read_reg(mmio, R_RX_CONTROL);
+	tmp &= ~(1<<O_RX_CONTROL__RxEnable) ;
+	phoenix_write_reg(mmio, R_RX_CONTROL, tmp);
+
+	tmp = phoenix_read_reg(mmio, SPI4_CNTRL_REG);
+	tmp &= ~(TX_ENABLE |  RX_ENABLE);
+	phoenix_write_reg(mmio, SPI4_CNTRL_REG, tmp);
+
+	return;
+
+}
+
+int spi4_read_reg(uint32 slot, uint32 addr)
+{
+
+	spi4_driver_data*   driver_data;
+	unsigned int        *mmio;
+	unsigned int        tmp;
+
+	driver_data = spi4_data[slot];
+	mmio = driver_data->mmio;
+
+	tmp = phoenix_read_reg(mmio, addr);
+	return tmp;
+}
+
+
diff --git a/drivers/net/rmi_spi4/rmi_spi4.h b/drivers/net/rmi_spi4/rmi_spi4.h
new file mode 100644
index 0000000..811933b
--- /dev/null
+++ b/drivers/net/rmi_spi4/rmi_spi4.h
@@ -0,0 +1,232 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_SPI4_H
+#define _ASM_RMI_SPI4_H
+
+#include <linux/types.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/phoenix_mac.h>
+#include <asm/rmi/sim.h>
+#include "rmi_spi4_config.h"
+
+
+#define RMI_SPI4_MAX_THREADS 32
+#define RMI_SPI4_PORTS_PER_CARD XLR_TOTAL_CHANNELS
+
+
+#define MAX_SPILL_SIZE          (MAX_NUM_DESC + 128)
+#define MAX_FRIN_SPILL          (MAX_SPILL_SIZE * RMI_SPI4_PORTS_PER_CARD)
+#define MAX_FROUT_SPILL         (MAX_SPILL_SIZE * RMI_SPI4_PORTS_PER_CARD)
+#define MAX_CLASS_0_SPILL       (MAX_SPILL_SIZE * RMI_SPI4_PORTS_PER_CARD)
+#define MAX_CLASS_1_SPILL       (MAX_SPILL_SIZE * RMI_SPI4_PORTS_PER_CARD)
+#define MAX_CLASS_2_SPILL       (MAX_SPILL_SIZE * RMI_SPI4_PORTS_PER_CARD)
+#define MAX_CLASS_3_SPILL       (MAX_SPILL_SIZE * RMI_SPI4_PORTS_PER_CARD)
+
+
+
+#define SPI4_0_BASE_ADDR 0x10000
+#define SPI4_1_BASE_ADDR 0x12000
+#define XLR_MAX_SPI4_CHANNEL 0x10
+#define XLR_MAX_SPI4_BYTE_OFFSET 7
+#define XLR_MAX_TX_BURST 8
+#define XLR_MAX_RX_BURST 32
+#define TX_CAL_SEQ      0x01
+#define RX_CAL_SEQ      0x01
+
+
+#define TOTAL_SPI4	2
+#define SPI4_0	0
+#define SPI4_1	1
+
+
+/* SPI4 registers */
+#define SPI4_TX_CAL_LEN 	0x0
+#define SPI4_TX_CAL_MAX	0x04
+#define SPI4_TX_CAL_X 0x08
+#define SPI4_RX_CAL_LEN	0x18
+#define SPI4_RX_CAL_X 0x20
+#define SPI4_RX_CAL_MAX	0x1c
+#define SPI4_TX_MAXBURST1_I 0x30
+#define	SPI4_TX_MAXBURST2_I 0x34
+#define SPI4_RX_MAXBURST1_I 0x38
+#define	SPI4_RX_MAXBURST2_I 0x3c
+
+/* spi4 control register and its bit fields */
+#define SPI4_CNTRL_REG	0x6c
+#define	TX_RESET		0x1
+#define	TX_ENABLE		0x2	
+#define	RX_RESET		0x04
+#define	RX_ENABLE		0x08
+#define	RX_CAL_Y		0x10
+#define	USR_SHAL_LPB	0x20
+#define	USR_DEEP_LPB	0x40
+#define	SPI_SHAL_LPB	0x80
+#define	SPI_DEP_LPB		0x100
+#define	DDL_ENABLE		0x200
+#define	FIFO_SW_RESET	0x400
+#define	RX_TRAIN_RESET 	0x800
+#define	RX_TRAIN_LOS		0x1000
+#define	TX_FRM_ERR_EN		0x2000
+#define	MORE_TRN_EN			0x4000
+#define	ERL_TRN_EN			0x8000
+#define	SYNC_PAT_EN			0x10000
+
+
+#define SPI4_INTR_REG		0x70
+#define	SPI4_TX_STATUS		0x7c
+#define	SPI4_TX_STATUS_TX_SYNC 0x4
+#define	SPI4_RX_STATUS		0x80
+#define SPI4_RX_STATUS_RX_SYNC 0x02
+#define	SPI4_RX_FIFO_DEPTH_I 0x88
+#define	SPI4_RX_FIFO_BASE_I 0x90
+#define	SPI4_TX_FIFO_DEPTH_I 0x8c
+#define	SPI4_TX_FIFO_BASE_I	0x94
+
+/* glue logic registers */
+
+#define DESC_PKT_CTRL_1 0xa9
+#define DESC_PKT_CTRL_2 0xaa
+#define PAD_CALIB_0	0x231
+#define RX_P_PRESET 0x1
+#define RX_N_PRESET 0x02
+#define	TX_P_PRESET 0x4
+#define TX_N_PRESET	0x08
+#define	RX_EN_COUNTER	 0x10
+#define	TX_EN_COUNTER  0x20
+#define	CAL_PRESET		0
+#define	HSTL_TERMINATION 0x1000
+#define	LVDS_TERMINATION 0x2000
+
+/********** CPLD register     **************/
+#define  CPLD_MISC_STATUS_REG  0x0e
+#define SPI4_MASK_BIT1 1
+
+
+typedef struct _spi4_driver_data{
+
+	uint32  tx_calendar; // number of ports
+	uint32  tx_cal_sequence ;
+
+	uint32  rx_calendar; // number of ports
+	uint32  rx_cal_sequence ;
+
+	uint32  tx_maxburst1;
+	uint32  tx_maxburst2;
+
+	uint32  rx_maxburst1;
+	uint32  rx_maxburst2;
+
+	uint32 		*mmio;
+	uint    spi4_slot ; 
+	uint32_t cfg_flag;
+
+	spi4_callback_func calbk_func;
+
+	void*	frin_spill;
+	void*	frout_spill;
+	void*	class_0_spill;
+	void*	class_1_spill;
+	void*	class_2_spill;
+	void*	class_3_spill;
+	
+}spi4_driver_data;
+
+/* spi4 descriptors */
+#define PORT_MASK 0xf
+#define DESK_CTRL_MASK 0x7
+#define DESC_CTRL_OFFSET  61
+#define DESC_LEN_MASK 0x3fff
+#define DESC_LEN_OFFSET 40
+#define DESC_ERROR_OFFSET 60 
+#define DESC_ERROR_MASK 0x01
+
+#define get_error(a) ((((a)>> DESC_ERROR_OFFSET) & DESC_ERROR_MASK ))
+#define get_port(a) ((a)&(PORT_MASK))
+#define get_ctrl(a) (((a)>>(DESC_CTRL_OFFSET))& (DESK_CTRL_MASK))
+#define get_length(a) (((a) >> (DESC_LEN_OFFSET)) & (DESC_LEN_MASK))
+#define get_address(a) (((a)&(0xffffffffe0ULL)))
+
+
+
+#define SPI4_TX_DESC_ALIGNMENT (SMP_CACHE_BYTES - 1)
+extern int cpu_to_frstid[];
+
+static inline int spi4_make_desc_tx(unsigned int thr_id,
+		struct  msgrng_msg *msg,
+    int   id,
+    int   port,
+    int   type,
+    unsigned long addr,
+    unsigned long skb,
+    int   len)
+{
+  int tx_stid = 0;
+  int fr_stid = 0;
+
+  tx_stid = msgrng_xgmac_stid_tx(id);
+  tx_stid += port;
+  fr_stid = cpu_to_frstid[thr_id];
+
+  msg->msg0 = ( ((uint64_t)1 << 63) |
+              ( ((uint64_t)127) << 54) |
+                ((uint64_t)len << 40) |
+                ((uint64_t)addr & 0xffffffffffULL)
+              );
+
+  msg->msg1 = ( ((uint64_t)1 << 63) |
+              ( ((uint64_t)fr_stid) << 54) |
+                ((uint64_t)0 << 40) |
+                ((uint64_t)virt_to_phys((void*)skb) & 0xffffffffffULL)
+              );
+
+  msg->msg2 = msg->msg3 = 0;
+
+  return tx_stid;
+
+}
+
+
+static inline int spi4_make_desc_rfr(struct msgrng_msg *msg, int id, int type,
+                                           unsigned long addr)
+{
+  int stid = 0;
+
+  stid = msgrng_xgmac_stid_rfr(id);
+
+  msg->msg0 = (uint64_t)addr & 0xffffffffe0ULL;
+  msg->msg1 = msg->msg2 = msg->msg3 = 0;
+
+  return stid;
+}
+
+
+#endif
diff --git a/drivers/net/rmi_spi4/rmi_spi4_config.h b/drivers/net/rmi_spi4/rmi_spi4_config.h
new file mode 100644
index 0000000..12a9cdf
--- /dev/null
+++ b/drivers/net/rmi_spi4/rmi_spi4_config.h
@@ -0,0 +1,141 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_SPI4_CONFIG_H
+#define _ASM_RMI_SPI4_CONFIG_H
+
+#include <linux/types.h>
+
+typedef unsigned int uint32;
+
+
+
+/* configuration parameters*/
+
+/* indicates how many spi4 channels currently need to be used
+ * by the upper driver */
+#define XLR_TOTAL_CHANNELS 0xa
+
+/* indicates number of 16 byte blocks that fifo can accept
+ * during fifo starving for the transmit path*/
+#define XLR_SPI4_TX_MAXBURST1    0x8
+
+/* indicates number of 16 byte blocks that fifo can accept
+ *  * during fifo hungry for the transmit path*/
+#define XLR_SPI4_TX_MAXBURST2    0x8
+
+/* indicates number of 16 byte blocks that fifo can accept
+ * during fifo starving for the receive path*/
+#define XLR_SPI4_RX_MAXBURST1    0x8
+
+/* indicates number of 16 byte blocks that fifo can accept
+ * during fifo hungry for the receive path*/
+#define XLR_SPI4_RX_MAXBURST2    0x8
+
+
+
+/* folowing are the configuration parameters for the ethrnet mac 
+ * driver */
+
+/* threshold for tx starts*/
+#define TX_THRESHOLD_SIZE      	512
+
+/* max buffer size for the tx and rx*/
+#define REG_FRAME_SIZE 		1536
+#define MAX_FRAME_SIZE          REG_FRAME_SIZE
+
+/* indicates byte offset for rx data start 
+ * from the rx buffer  */
+#define SPI4_BYTE_OFFSET        2
+
+#define MAC_CRC_LEN             4
+#define MAC_SKB_BACK_PTR_SIZE   SMP_CACHE_BYTES
+
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+#define MAC_PREPAD             32
+#else 
+#define MAC_PREPAD              0
+#endif
+
+/* number of descriptors for each spi4 channel given for the 
+ * rx data*/
+#define MAX_NUM_DESC            512
+
+
+
+
+typedef void (*spi4_callback_func)(uint32,uint32, uint32, char*, 
+		uint32, uint32 error);
+
+enum spi4_callback_cmd{
+	SPI4_TX_DONE ,
+	SPI4_RX_IND
+};
+
+/* exported API*/
+
+extern unsigned int spi4_init(uint32   slot, spi4_callback_func);
+extern void spi4_program_rx_desc(uint32  slot,  char*);
+extern int spi4_open(uint32 slot);
+extern void spi4_close(uint32 slot);
+extern int spi4_tx(unsigned int thr_id, uint32 slot,  uint32 spi4_port,
+                char* data, unsigned char* skb,uint32 len);
+extern int spi4_read_reg(uint32 slot, uint32 addr);
+
+
+enum spi4_returns{
+        SPI4_PASS = 0x0,
+        SPI4_TX_FAIL,
+        SPI4_SLOT_ERROR,
+        SPI4_MALLOC_FAIL,
+        SPI4_TX_SYNC_FAIL,
+	SPI4_RX_SYNC_FAIL,
+        SPI4_INIT_SUCCESS,
+	SPI4_CALENDER_LEN_ERROR,
+	SPI4_TX_MAXBURST1_ERROR,
+	SPI4_TX_MAXBURST2_ERROR,
+	SPI4_RX_MAXBURST1_ERROR,
+	SPI4_RX_MAXBURST2_ERROR,
+	SPI4_TX_MAX_BURST_ERROR,
+	SPI4_RX_MAX_BURST_ERROR,
+	SPI4_BYTE_OFFSET_ERROR,
+	SPI4_PARAMS_VALID,
+	SPI4_CONFIG_SPILL_FAIL,
+        SPI4_CONFIG_SPILL_SUCCESS,
+        SPI4_CONFIG_PDE_SUCCESS,
+	SPI4_REGISTER_MSGRING_FAIL,
+        SPI4_REGISTER_MSGRING_SUCESS,
+        SPI4_MMIO_ERROR,
+        SPI4_OPEN_SUCCESS,
+
+};
+
+#endif
+
diff --git a/drivers/net/rmi_spi4/rmi_vits_driver.c b/drivers/net/rmi_spi4/rmi_vits_driver.c
new file mode 100644
index 0000000..09a4064
--- /dev/null
+++ b/drivers/net/rmi_spi4/rmi_vits_driver.c
@@ -0,0 +1,282 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <asm/rmi/iomap.h>
+#include "rmi_spi4_config.h"
+#include "rmi_vits_wrapper.h"
+#include "rmi_vits_driver.h"
+#include "vitesse_common.h"
+#include "vitesse_highlevel.h"
+#include "vitesse_io.h"
+#include "vitesse_phy_ctrl.h"
+#include <asm/rmi/debug.h>
+#include "meigsii_reg.h"
+#include <linux/kernel.h>
+
+vtss_mapped_port_t eds_ports_table[VTSS_PORT_ARRAY_SIZE] = {
+
+	/* chip_port, miim_controller, phy_addr */
+	/* logical port 0 doesn't exsist */
+	{         -1,              -1,     -1  }, 
+	{          0,               0,     0x3 },
+	{          1,               0,     0x2 },
+	{          2,               0,     0x1 },
+	{          3,               0,     0x0 },
+	{          4,               0,     0x7 },
+	{          5,               0,     0x6 },
+	{          6,               0,     0x5 },
+	{          7,               0,     0x4 },
+	{          8,               0,     0xb },
+	{          9,               0,     0xa },
+	{         10,               1,     0x1 }  /* This is 10g port */
+};
+
+
+void vtss_eds_init( vtss_mac_major_mode_t mmode, vtss_port_interface_t pmode, BOOL fc)
+{
+	vtss_rc phy_val;
+
+	/* Note that the (R/)GMII ports must be mapped before calling this function */
+
+	int ports_in_use = XLR_TOTAL_CHANNELS; /* all 10 GMII ports are used */
+	int portnum = 0;       
+	vtss_system_setup_t sys_setup;
+	vtss_fifo_setup_t   egress_fifo_setup;
+	vtss_fifo_setup_t   ingress_fifo_setup;
+	vtss_port_setup_t   port_1G_setup;
+	vtss_spi4_setup_t   spi4_setup;
+	vtss_fifo_fc_watermarks_t fc_watermarks;
+	vtss_mac_t smac = {{0,0,0,0,0,0}};
+
+	/* Reset I/O-level software (will also reset the chip) */
+	vtss_chip_reset();
+
+	/* Prepare major mode for runtime calls */
+	vtss_major_mode_set(mmode);
+
+	/* Mapping logical ports with physical ports */
+	vtss_port_map_set(eds_ports_table);
+
+	/* Setup of basic system parameters -- clock, endianess, etc.. */
+	vtss_system_setup_get_default_values( &sys_setup, mmode);
+	vtss_system_setup( &sys_setup);
+
+	/* Setup Host interface */
+	vtss_spi4_setup_get_default_values( &spi4_setup, mmode);
+	vtss_spi4_setup( &spi4_setup);
+
+	/* Setup FIFO */
+	vtss_fifo_setup_get_default_values( &ingress_fifo_setup, 
+				&egress_fifo_setup, mmode);
+	vtss_fifo_setup( &ingress_fifo_setup, &egress_fifo_setup);
+
+
+	/* Setup logical ports */
+	for (portnum = 1; portnum <= ports_in_use; portnum++) {
+
+		phy_val = vtss_phy_reset(portnum) ;
+		if(phy_val != VTSS_OK)
+			printk("Not able to reset phy=%d\n",portnum);
+
+		vtss_port_setup_get_default_values( &port_1G_setup, mmode);
+		/* Change default gmii to pmode */
+		port_1G_setup.interface_mode.interface_type = pmode;
+
+		if (fc) {
+			/* Change flowcontrol settings i MAC */
+			smac.addr[5] = portnum;
+			port_1G_setup.flowcontrol.smac = smac;
+			port_1G_setup.flowcontrol.obey = 1;
+			port_1G_setup.flowcontrol.generate = 1;
+
+			/* Change watermarks settings in FIFO buffer 
+			 * to be used for flowcontrol Ingress for port 
+			 * flowcontrol. Egress for SPI4 flowcontrol */
+			fc_watermarks.low_watermark = 0xc6;
+			fc_watermarks.high_watermark = 0xca;
+			vtss_fifo_watermarks_set( portnum, &fc_watermarks,
+						 &fc_watermarks);
+		}
+		if(vtss_port_setup( portnum, &port_1G_setup))
+			printk("Not able to set the port=%d\n",portnum);
+		if(vtss_port_set_mode(portnum, VTSS_SPEED_100M, 1)!= VTSS_OK)
+			printk("not able to set 100mb\n");	
+
+		/* Port enable */
+		vtss_port_set_enable( portnum, 1, 1);
+	}
+}
+
+
+
+void vtss_rmi_init(int device_number) 
+{
+	long egr_control, crc_cfg, crc_add;
+	int loop;
+	int  portnum  ;
+	unsigned long	tx_rx_status;
+
+	ulong value;
+	BOOL  flow_ena;
+	vtss_mac_major_mode_t eds_mmode; /* major mode */
+	vtss_port_interface_t eds_pmode; /* port  mode */ 
+
+	megis_phoenix_init(device_number);
+
+	/* Reset I/O layer, configure operating system driver, and reset chip */
+	vtss_io_reset();
+
+	/* Get Chip ID */
+	value = vtss_chip_id_get();
+
+
+	/* Initialize MAC to major mode and port mode */
+	eds_mmode = VTSS_MAC_MAJOR_MODE_SPI4_1G; /* default SPI4<->1G*/
+	eds_pmode = VTSS_PORT_INTERFACE_RGMII; /* default RGMII */
+	flow_ena = 0; 
+
+	vtss_eds_init( eds_mmode, eds_pmode, flow_ena);
+
+	// reset training period 
+	vtss_io_write(M2_BLK_SPI4,0,M2_SPI4_ING_SETUP1, 0x1000f);
+
+	// setup debug counter to count ingress fifo events
+	vtss_io_write(M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_TEST, 0x00010000);
+	vtss_io_write(M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_DEBUG_BUF_CNT, 0x00010000);
+
+	// Setting IFG to small value
+	for(loop=0; loop<=10; loop++){
+		vtss_io_write(M2_BLK_MACS, loop, M2E_TX_IFG, 0x6);
+	}
+
+	// not to drop frame with crc error in egress
+	crc_cfg = vtss_io_read(M2_BLK_SYSTEM,M2_SUBBLK_CTRL,0xb);
+	crc_cfg |= 1<<5;
+	vtss_io_write(M2_BLK_SYSTEM, M2_SUBBLK_CTRL, 0xb, crc_cfg);
+
+	egr_control = vtss_io_read(M2_BLK_FIFO,M2_SUBBLK_EGRESS,M2_EGR_CONTROL);
+	egr_control |= 1<<18;
+	vtss_io_write(M2_BLK_FIFO,M2_SUBBLK_EGRESS,M2_EGR_CONTROL, egr_control);
+
+	for(portnum=0; portnum < XLR_TOTAL_CHANNELS; portnum++){
+			crc_add = vtss_io_read(M2_BLK_MACS, portnum, M2_TRI_DENORM);
+			crc_add &= ~(1<<5); // clear 5th bit crc_upd
+			crc_add |= 1<<4;  // set 4th bit crc_add
+			vtss_io_write(M2_BLK_MACS, portnum, 
+						M2_TRI_DENORM,crc_add);
+			crc_add = vtss_io_read(M2_BLK_MACS, 
+						portnum, M2_TRI_DENORM);
+
+				crc_add = vtss_io_read(M2_BLK_MACS, 
+						portnum, M2_DEV_SETUP);
+			tx_rx_status = vtss_io_read(M2_BLK_MACS, portnum, M2_MODE_CFG);
+			tx_rx_status &= ~(0X3) ; // DISABLE TX RX
+	  	vtss_io_write(M2_BLK_MACS, portnum, M2_MODE_CFG, tx_rx_status);
+		}
+	
+
+	// setup debug counter to count egress fifo events
+	vtss_io_write(M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_TEST, 0x00010000);
+	vtss_io_write(M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_DEBUG_BUF_CNT, 0);
+
+
+	// setup debug counter to count spi4 egress traffic
+	vtss_io_write(M2_BLK_SPI4, 0, M2_SPI4_DBG_CNT, 0);
+	vtss_io_write(M2_BLK_SPI4, 0, M2_SPI4_DBG_SETUP, 0x00000002);
+
+	return;
+}
+
+
+int vtss_rmi_monitor_phy_status(int port, int *speed, int *duplexity)
+{
+	vtss_rc ret, dup;
+	vtss_phy_status_t   status;
+
+	ret = vtss_phy_status_get(port, &status);
+	if(ret != VTSS_OK){
+		return 0;
+	}
+	dup = ret = vtss_phy_read(port, 0x1c);
+	if(ret<0) return 0;
+
+	ret >>=3;
+	ret &= 0x3;
+	switch(ret){
+		case 2:
+			(*speed) =(int) SPEED_1000M;
+			break;
+		case 1:
+			(*speed )= (int)SPEED_100M;
+			break;
+		case 0:
+			(*speed) = (int)SPEED_10M;
+			break;
+		default:
+			(*speed) = (int)UNDEFINED_SPEED;
+	}
+	dup >>= 5;
+	dup &= 0x01;
+	if(dup){
+		(*duplexity) = 1;
+	}
+	else{
+		(*duplexity) = 0;
+	}
+
+	return 1;
+}
+
+int vtss_rmi_change_port_status(int port, int speed, int duplexity)
+{
+	int i;
+
+	switch(speed){
+	case SPEED_1000M:
+		speed = VTSS_SPEED_1G;
+		break;
+	case SPEED_100M:
+		speed = VTSS_SPEED_100M;
+		break;
+	case SPEED_10M:
+		speed = VTSS_SPEED_10M;
+		break;
+	default :
+		speed = VTSS_SPEED_1G;
+	}
+	i = vtss_port_set_mode(port, speed, duplexity);
+	if(i == VTSS_OK ){
+		return 1;
+	}
+	else{
+		return 0;
+	}
+}
+
diff --git a/drivers/net/rmi_spi4/rmi_vits_driver.h b/drivers/net/rmi_spi4/rmi_vits_driver.h
new file mode 100644
index 0000000..a51b0bb
--- /dev/null
+++ b/drivers/net/rmi_spi4/rmi_vits_driver.h
@@ -0,0 +1,52 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_VITS_DRIVER_H
+#define _ASM_RMI_VITS_DRIVER_H
+
+#include "vitesse_highlevel.h"
+
+typedef enum _vits_driver_speed{
+	SPEED_10M = 1,
+	SPEED_100M,
+	SPEED_1000M,
+	UNDEFINED_SPEED
+}vits_driver_speed;
+
+
+// driver function prototypes
+void vtss_eds_init( vtss_mac_major_mode_t mmode, 
+		vtss_port_interface_t pmode, BOOL fc);
+void vtss_rmi_init(int device_number);
+int vtss_rmi_monitor_phy_status(int port, int *speed, int *duplexity);
+int vtss_rmi_change_port_status(int port, int speed, int duplexity);
+
+
+#endif
diff --git a/drivers/net/rmi_spi4/rmi_vits_eth.c b/drivers/net/rmi_spi4/rmi_vits_eth.c
new file mode 100644
index 0000000..de6f4dc
--- /dev/null
+++ b/drivers/net/rmi_spi4/rmi_vits_eth.c
@@ -0,0 +1,1225 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/workqueue.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+
+#include <linux/inet.h>
+#include <linux/netdevice.h>
+#include <linux/ethtool.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+
+#include "rmi_vits_eth.h"
+#include "rmi_spi4_config.h"
+#include "os_layer.h"
+
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/sim.h>
+#include "meigsii_reg.h"
+#include "rmi_vits_wrapper.h"
+#include "rmi_vits_driver.h"
+#include "vitesse_common.h"
+#include "vitesse_highlevel.h"
+#include "vitesse_io.h"
+#include "vitesse_phy_ctrl.h"
+
+#include <asm/rmi/phoenix_mac.h>
+
+#define DRV_NAME  "rmi_vits_spi4"
+#define DRV_VERSION "0.1"
+#define DRV_RELDATE "10Aug2005"
+
+#define PHY_MONITOR	1
+#define RMI_SPI4_MAX_CPUS 32
+#define SPI4_FRIN_THRESHOLD spi4_frin_threashold
+#define RMI_SPI4_TX_MAX_COUNTER 100
+#define MAKE_CACHE_ALIGN ~(0x1f)
+#define RMI_SPI4_DEBUG 0
+
+enum vits_returns{
+	VITS_PROGRAM_RX_DESC_FAIL,
+	VITS_PROGRAM_RX_DESC_SUCCESS,
+	VITS_COMMON_INIT_SUCCESS,
+};
+
+struct net_device  *spi4_dev[RMI_SPI4_MAX_PORTS];
+typedef struct _driver_data{
+
+	struct net_device 	*dev;
+	spinlock_t          lock;
+
+	uint	port; // this is eth port: 0-19
+	uint	slot;
+	uint	spi4_port;	//this is spi4 port :0-9
+	uint	speed;
+	uint	duplex;
+	uint 	autoneg;
+	uint	type;
+	uint	cfg_flag;
+	struct net_device_stats        stats;
+  atomic_t     frin_to_be_sent[RMI_SPI4_MAX_CPUS];
+
+}driver_data ;
+
+static int spi4_frin_threashold;
+static struct net_device_ops rmi_spi4_net_ops;
+
+unsigned int g_spi4_card_flag;
+static spinlock_t pending_tx_lock[RMI_SPI4_MAX_PORTS] __cacheline_aligned;
+static spinlock_t base_change=SPIN_LOCK_UNLOCKED;
+
+struct timer_list link_monitor_timer;
+extern unsigned long g_dip4_error[];
+extern int cpu_to_bktmask[];
+static struct 	work_struct vits_frin_replenish_work[RMI_SPI4_MAX_CPUS];
+
+void set_ethtool_ops(struct net_device *netdev);
+
+void rmi_vits_rx_tx_done( uint32  cmd, uint32 slot,  	uint32	port,
+		char*	addr, uint32  len,	uint32	error);
+
+
+unsigned char spi4_check_daughter_cards(void);
+static __inline__ struct sk_buff *spi4_get_skb_back_ptr(unsigned long addr)
+{
+	unsigned long *back_ptr =
+		(unsigned long *)(addr - MAC_SKB_BACK_PTR_SIZE);
+
+	/* this function should be used only for newly allocated packets.
+	 * It assumes the first cacheline is for the back pointer related
+	 * book keeping info
+	 */
+	return (struct sk_buff *)(*back_ptr);
+}
+
+static __inline__ void spi4_put_skb_back_ptr(struct sk_buff *skb)
+{
+	unsigned long *back_ptr = (unsigned long *)skb->data;
+
+	/* this function should be used only for newly allocated
+	 * packets. It assumes  the first cacheline is for the back
+	 * pointer related book keeping info
+	 */
+	skb_reserve(skb, MAC_SKB_BACK_PTR_SIZE);
+
+	*back_ptr = (unsigned long)skb;
+}
+
+void change_vits_base(int port)
+{
+    if(port < RMI_SPI4_PORTS_PER_CARD){
+      megis_phoenix_init(1);
+    }
+    else{
+      megis_phoenix_init(2);
+    }
+	return;
+}
+
+/*******************************************************************************
+* Function name :       rmi_link_monitor
+* Input         :
+* Description   :       This function monitors all the phy channels and if speed
+*	or duplexity changed, then it changes the mac's speed and duplexity.
+* RETURNS       :       void
+*******************************************************************************/
+
+void rmi_link_monitor(unsigned long data)
+{
+
+	int i, port, cpu, thr_id, slot;
+	struct net_device *dev;
+	driver_data *priv ;
+	int speed, duplexity;
+	unsigned long flags;
+	vtss_phy_status_t phy_status;
+
+	cpu = phoenix_cpu_id() ;
+	thr_id = phoenix_thr_id() ;
+
+	spin_lock_irqsave(&base_change, flags);
+	for(i =0; i< RMI_SPI4_MAX_PORTS; i++){
+		slot = active_port[i].slot ;
+
+		if((spi4_slot[slot] == INVALID_SLOT ) ||
+		(active_port[i].port == INVALID_PORT)) continue;
+
+		if(!(g_spi4_card_flag & (1<<slot)))
+      			continue;
+
+		change_vits_base(i);
+
+		if(active_port[i].slot == SPI4_0)
+			port = active_port[i].port;
+		else if(active_port[i].slot == SPI4_1)
+			port = (active_port[i].port) - RMI_SPI4_PORTS_PER_CARD;
+		else{
+			printk("ERROR: wrong slot should never happen\n");
+			continue;
+		}
+
+		/*if the link is down for the particular port just continue
+		  for the remaining ports */
+		port++;
+		if(!vtss_rmi_monitor_phy_status(port, &speed, &duplexity)){
+			continue;
+		}
+		dev = spi4_dev[i];
+		if(!dev) continue;
+		priv = netdev_priv(dev);
+		if(speed == UNDEFINED_SPEED){
+			continue;
+		}
+#if RMI_SPI4_DEBUG
+		printk("new speed=%d, old_speed=%d\n",
+			speed, priv->speed);
+#endif
+		if((priv->speed != speed) || (priv->duplex != duplexity)){
+#if RMI_SPI4_DEBUG
+			printk("speed change to port=%d : speed=%d, dup=%d\n",
+				port, speed, duplexity);
+#endif
+			if(vtss_rmi_change_port_status(port, speed, duplexity)){
+				priv->speed = speed;
+				priv->duplex = duplexity;
+			}
+		}
+
+		if(vtss_phy_status_get(port, &phy_status) == VTSS_OK){
+			if (phy_status.link_status) {
+				netif_carrier_on(dev);
+			}
+			else {
+				netif_carrier_off(dev);
+			}
+		}
+		else {
+#if RMI_SPI4_DEBUG
+			printk("phy status read failed\n");
+#endif
+		}
+	}// end of for loop
+
+	spin_unlock_irqrestore(&base_change,flags);
+	link_monitor_timer.expires = jiffies +  HZ;
+	add_timer(&link_monitor_timer);
+
+	return;
+}
+
+
+
+static int rmi_vits_open(struct net_device *dev)
+{
+	unsigned int vits_port;
+  unsigned long  tx_rx_status;
+	driver_data *priv = netdev_priv(dev);
+  unsigned long flags;
+
+#if RMI_SPI4_DEBUG
+	printk("opening the spi4 interface: %d\n", priv->port);
+#endif
+
+  spin_lock_irqsave(&base_change, flags);
+  if(priv->port < RMI_SPI4_PORTS_PER_CARD){
+		vits_port =  priv->port ;
+	}
+	else {
+		vits_port =  priv->port - RMI_SPI4_PORTS_PER_CARD;
+	}
+	change_vits_base(priv->port);
+  tx_rx_status = vtss_io_read(M2_BLK_MACS, vits_port, M2_MODE_CFG);
+	tx_rx_status |= 0x3 ; // enable TX and RX
+	vtss_io_write(M2_BLK_MACS, vits_port, M2_MODE_CFG, tx_rx_status);
+
+  spin_unlock_irqrestore(&base_change,flags);
+	return 0;
+}
+
+static int rmi_vits_close(struct net_device *dev)
+{
+  unsigned int vits_port;
+  unsigned long  tx_rx_status;
+  unsigned long flags;
+
+	driver_data *priv = netdev_priv(dev);
+
+#if RMI_SPI4_DEBUG
+	printk("closing the spi4 interface: %d\n", priv->port);
+#endif
+  spin_lock_irqsave(&base_change, flags);
+  if(priv->port < RMI_SPI4_PORTS_PER_CARD){
+		vits_port =  priv->port ;
+	}
+	else {
+		vits_port =  priv->port - RMI_SPI4_PORTS_PER_CARD;
+	}
+  change_vits_base(priv->port);
+  tx_rx_status = vtss_io_read(M2_BLK_MACS, vits_port, M2_MODE_CFG);
+	tx_rx_status &= ~(0x3) ; // disable TX and RX
+	vtss_io_write(M2_BLK_MACS, vits_port, M2_MODE_CFG, tx_rx_status);
+  spin_unlock_irqrestore(&base_change,flags);
+	return 0;
+}
+
+#if RMI_SPI4_DEBUG
+void print_stats(vtss_port_counters_t *stat)
+{
+
+	printk("out byte		: %ld\n",stat->tx_out_bytes);
+	printk("tx_pause		: %ld\n", stat->tx_pause);
+	printk("tx_ok_by		: %ld\n", stat->tx_ok_bytes);
+	printk("tx_unicast		: %ld\n", stat->tx_unicast);
+	printk("tx_multicast		: %ld\n", stat->tx_multicast);
+	printk("tx_broadcast		: %ld\n", stat->tx_broadcast);
+	printk("tx_multiple_coll	: %ld\n", stat->tx_multiple_coll);
+	printk("tx_late_coll		: %ld\n", stat->tx_late_coll);
+	printk("tx_xcoll		: %ld\n", stat->tx_xcoll);
+	printk("tx_defer		: %ld\n", stat->tx_defer);
+	printk("tx_xdefer		: %ld\n", stat->tx_xdefer);
+	printk("tx_carrier_sense	: %ld\n", stat->tx_carrier_sense);
+	printk("tx_size_64		: %ld\n", stat->tx_size_64);
+	printk("tx_size_65_to_127	: %ld\n", stat->tx_size_65_to_127);
+	printk("tx_size_128_to_255	: %ld\n", stat->tx_size_128_to_255);
+	printk("tx_size_256_to_511	: %ld\n", stat->tx_size_256_to_511);
+
+	printk("tx_single_coll		: %ld\n", stat->tx_single_coll);
+	printk("tx_backoff2		: %ld\n", stat->tx_backoff2);
+	printk("tx_backoff3		: %ld\n", stat->tx_backoff3);
+	printk("\n");
+	printk("tx_underrun		: %ld\n", stat->tx_underrun);
+	printk("ingress_overflow_drop	: %ld\n", stat->ingress_overflow_drop);
+	printk("egress_overflow_drop	: %ld\n", stat->egress_overflow_drop);
+	printk("\n");
+
+
+	printk("rx_in_bytes            : %ld\n",stat->rx_in_bytes);
+	printk("rx_ok_bytes            : %ld\n",stat->rx_ok_bytes);
+	printk("rx_bad_bytes           : %ld\n", stat->rx_bad_bytes);
+	printk("rx_unicast             : %ld\n", stat->rx_unicast);
+	printk("rx_multicast           : %ld\n",stat->rx_multicast);
+	printk("rx_broadcast           : %ld\n", stat->rx_broadcast);
+	printk("rx_crc                 : %ld\n", stat->rx_crc);
+	printk("rx_undersize           : %ld\n", stat->rx_undersize);
+	printk("rx_fragments           : %ld\n", stat->rx_fragments);
+	printk("rx_in_range_error      : %ld\n", stat->rx_in_range_error);
+	printk("rx_out_of_range_error  : %ld\n", stat->rx_out_of_range_error);
+	printk("rx_oversize            : %ld\n", stat->rx_oversize);
+
+	printk("\n");
+	printk("\n");
+
+	return;
+}
+
+void rmi_vits_dump_dbg_regs(struct net_device *dev)
+{
+
+	int port;
+	long reg_value;
+
+	driver_data *priv = netdev_priv(dev);
+	if(priv->slot == SPI4_0)
+		port = priv->port;
+	else if(priv->slot == SPI4_1)
+		port = priv->port - RMI_SPI4_PORTS_PER_CARD;
+	else
+		return ;
+
+	port++;
+	reg_value = spi4_read_reg(priv->slot, R_TX_CONTROL);
+	printk("GLUE REG: TX CONTROL addr : A0 = %lx\n", reg_value);
+	reg_value = spi4_read_reg(priv->slot, SPI4_TX_STATUS);
+	printk("TX STATUS = 0x%lx\n", reg_value);
+	reg_value = spi4_read_reg(priv->slot, SPI4_RX_STATUS);
+	printk("RX STATUS = 0x%lx\n", reg_value);
+	reg_value = spi4_read_reg(priv->slot, 0x70);
+	printk("INT REG = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(1, port, 0x0a);
+	printk("VTSS reg stick_bit - addr 0x0a = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(1, port, 0x0c);
+	printk("VTSS reg drop count - addr 0x0c = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(7, 0xf, 0x0a);
+	printk("VTSS reg egr crc count -(7,f,a)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(7, 0xf, 0x0b);
+	printk("VTSS reg crc config -(7,f,b)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(2, 1, 0x0f);
+	printk("VTSS reg EGR_CONTROL -(2,1,f)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(2, 1, 0x60);
+	printk("VTSS reg EGR DROP COUNT -(2,1,60)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(2, 1, 0x61);
+	printk("VTSS reg EGR DROP COUNT  -(2,1,61)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(2, 1, 0x62);
+	printk("VTSS reg EGR DROP COUNT  -(2,1,62)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(2, 1, 0x63);
+	printk("VTSS reg EGR DROP COUNT  -(2,1,63)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(2, 1, 0x64);
+	printk("VTSS reg EGR DROP COUNT  -(2,1,64)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(2, 1, 0x65);
+	printk("VTSS reg EGR DROP COUNT  -(2,1,65)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(2, 1, 0x66);
+	printk("VTSS reg EGR DROP COUNT  -(2,1,66)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(2, 1, 0x67);
+	printk("VTSS reg EGR DROP COUNT  -(2,1,67)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(2, 1, 0x68);
+	printk("VTSS reg EGR DROP COUNT  -(2,1,68)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(2, 1, 0x69);
+	printk("VTSS reg EGR DROP COUNT  -(2,1,69)  = 0x%lx\n", reg_value);
+	reg_value = vtss_io_read(5, 0, 0x30);
+	printk("VTSS reg spi4_sticky : host spi:   -(5,0,30)  = 0x%lx\n", reg_value);
+
+	return;
+}
+#endif
+
+int rmi_vits_collect_stats(struct net_device *dev,
+		vtss_port_counters_t *stat)
+{
+	int port;
+	driver_data *priv = netdev_priv(dev);
+
+	if(priv->slot == SPI4_0)
+		port = priv->port;
+	else if(priv->slot == SPI4_1)
+		port = priv->port - RMI_SPI4_PORTS_PER_CARD ;
+	else
+		return 1;
+	change_vits_base(priv->port);
+	// this is for the VTSS API, which will search the port data structure
+	port++;
+	if(vtss_port_counters_get((const vtss_port_no_t)port,stat)== VTSS_OK){
+		return 0;
+	}
+	return 1;
+}
+/*
+   VTSS API for clearing stat has some problem, one can't clear for a
+   particular port, it will clear all the ports, so currently stat clear
+   is not done
+ */
+static struct net_device_stats* rmi_vits_get_stats(struct net_device *dev)
+{
+  unsigned long flags, i ;
+	unsigned long total_dip4=0;
+	vtss_port_counters_t stat;
+	driver_data *priv = netdev_priv(dev);
+
+  spin_lock_irqsave(&base_change, flags);
+	if((priv->slot == INVALID_SLOT ) ||
+	(priv->port == INVALID_PORT)){
+	  spin_unlock_irqrestore(&base_change,flags);
+		return &priv->stats;
+	}
+	if(rmi_vits_collect_stats(dev, &stat)){
+	  spin_unlock_irqrestore(&base_change,flags);
+		return &priv->stats;
+	}
+
+	/*update the vits stats to dev stats*/
+	priv->stats.rx_packets = stat.rx_unicast + stat.rx_broadcast;
+	priv->stats.tx_packets = stat.tx_unicast;
+	priv->stats.rx_bytes =	stat.rx_ok_bytes;
+	priv->stats.tx_bytes = stat.tx_ok_bytes;
+	priv->stats.rx_fifo_errors = stat.ingress_overflow_drop;
+	priv->stats.tx_fifo_errors = stat.egress_overflow_drop;
+	priv->stats.multicast = stat.rx_multicast;
+	for(i = 0; i< RMI_SPI4_MAX_THREADS; i++){
+		total_dip4 += g_dip4_error[i] ;
+	}
+	priv->stats.rx_errors = total_dip4;
+	priv->stats.rx_crc_errors = stat.rx_crc ;
+	priv->stats.multicast = stat.rx_multicast;
+  spin_unlock_irqrestore(&base_change,flags);
+	return &priv->stats;
+
+}
+
+static int rmi_vits_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	unsigned int thr_id, ret = 0;
+	unsigned eth_port;
+  unsigned long flags;
+	driver_data *priv = netdev_priv(dev);
+
+#if RMI_SPI4_DEBUG
+	printk("[%s]: port=%d, skb=%p, len=%d\n",
+			__FUNCTION__, priv->port,skb, skb->len);
+	for(i=0; i<skb->len; i++)
+		printk("%x  ", skb->data[i]);
+	printk("\n");
+#endif
+	thr_id = hard_smp_processor_id();
+	
+	if(cpu_to_bktmask[thr_id] == 0) {
+		printk("Tx fail : No buckets are allocated for this cpu\n");
+		return 1;
+	}
+
+
+	if(spi4_tx(thr_id,priv->slot, priv->spi4_port, skb->data,
+						(unsigned char*) skb, skb->len)){
+		eth_port = priv->port;
+		spin_lock_irqsave(&pending_tx_lock[eth_port], flags);
+		/* now once again attempt to send, in case, by this time
+			 if any TX_DONE happend for the corresponding port*/
+  	if(spi4_tx(thr_id,priv->slot, priv->spi4_port, skb->data,
+            (unsigned char*) skb, skb->len)){
+	    netif_stop_queue(dev);
+			ret = 1;
+		}
+		else{
+			ret = 0;
+		}
+		spin_unlock_irqrestore(&pending_tx_lock[eth_port], flags);
+	}
+
+	return ret;
+}
+
+
+int rmi_vits_program_rx_desc(unsigned int slot,
+		int total_desc)
+{
+	int     i;
+	struct  sk_buff *skb = 0;
+	unsigned int ret = VITS_PROGRAM_RX_DESC_SUCCESS;
+
+	for(i=0; i< total_desc; i++){
+		skb = os_alloc_skb();
+		if (!skb) {
+			printk("ERROR: alloc skb failed\n");
+			ret = VITS_PROGRAM_RX_DESC_FAIL;
+			break;
+		}
+		spi4_put_skb_back_ptr(skb);
+		spi4_program_rx_desc(slot, skb->data) ;
+	}
+	return ret;
+}
+
+/*******************************************************************************
+* Function name :       rmi_vits_frin_replenish
+* Input         :
+* Description   :       This function replenish RX desc for all ports for
+*	a cpu on which it is scheduled.
+* RETURNS       :       void
+*******************************************************************************/
+static void rmi_vits_frin_replenish(struct work_struct *data)
+{
+  int done = 0;
+  int cpu = hard_smp_processor_id();
+
+  driver_data *priv;
+  struct net_device *dev;
+  atomic_t *frin_to_be_sent;
+  int i;
+
+  while(1){
+    done = 0;
+    for(i=0; i< RMI_SPI4_MAX_PORTS; i++){
+      if(active_port[i].port == INVALID_PORT){
+        goto skip;
+      }
+      dev = spi4_dev[i];
+      if(dev == NULL){
+        goto skip;
+      }
+      priv =netdev_priv(dev);
+
+	  if(!(MSGRNG_OWN(priv->cfg_flag)))
+			continue;
+
+      frin_to_be_sent = &priv->frin_to_be_sent[cpu];
+      if(atomic_read(frin_to_be_sent) < 0) {
+        printk("ERROR: wrong frin_to_be_sent \n");
+      }
+
+		
+      if (!atomic_read(frin_to_be_sent)) goto skip;
+      			if(rmi_vits_program_rx_desc(priv->slot, 1) ==
+					VITS_PROGRAM_RX_DESC_SUCCESS){
+        atomic_dec(frin_to_be_sent);
+      }
+      continue;
+      skip:
+      done++;
+    }
+    if(done == RMI_SPI4_MAX_PORTS) break;
+  }
+  return;
+}
+
+/*******************************************************************************
+* Function name :    	rmi_vits_rx_tx_done
+* Input         :
+* Description   :       This function handles the TX DONE and RX IND. It keeps
+*	track the RX desc to be replenish, if it crosses the water mark then
+*	schedules the replenish work item.
+* RETURNS       :       void
+*******************************************************************************/
+
+void rmi_vits_rx_tx_done(	uint32  cmd, 	uint32 	slot,
+				uint32 	port,	char*   addr,
+				uint32  len,	uint32	error)
+{
+	struct 	net_device   *dev;
+	struct 	sk_buff      *skb = 0;
+	int 	cpu ;
+	driver_data	*priv;
+	unsigned int 	eth_interface ;
+
+	cpu = hard_smp_processor_id();
+	switch(cmd){
+	case SPI4_TX_DONE:
+	 	/*in TX_DONE case, port indicates bucket*/
+    skb = (struct  sk_buff*)addr;
+
+		if(skb==NULL){
+			printk("ERROR - TX_DONE: null skb \n");
+			return;
+		}
+    		priv = netdev_priv(skb->dev);
+		eth_interface = priv->port;
+    		spin_lock(&pending_tx_lock[eth_interface]);
+		if(netif_queue_stopped(skb->dev)){
+		 	netif_wake_queue(skb->dev);
+		}
+    		spin_unlock(&pending_tx_lock[eth_interface]);
+		os_free(skb);
+		break;
+	case SPI4_RX_IND:
+#if RMI_SPI4_DEBUG
+		printk("[%s]RX_IND :   port=%d\n",
+			__FUNCTION__,  priv->port);
+#endif
+
+    if(slot == SPI4_0){
+      eth_interface = port;
+    }
+    else if(slot == SPI4_1){
+      eth_interface = port + RMI_SPI4_PORTS_PER_CARD;
+    }
+    else{
+      printk("[%s] ERROR!!! invalid slot\n",__FUNCTION__);
+      return;
+    }
+    dev = spi4_dev[eth_interface];
+    if(dev == NULL){
+      			printk("[%s]ERROR!! eth interface=%d , port=%d , \
+					not registered\n",
+          __FUNCTION__, eth_interface,port);
+      return;
+    }
+
+    priv = netdev_priv(dev);
+		skb = spi4_get_skb_back_ptr((unsigned long)addr);
+		if(!skb){
+			printk("NULL skb pointer in RX handling\n");
+			return;
+		}
+		skb->dev = dev;
+		skb_reserve(skb, MAC_PREPAD+SPI4_BYTE_OFFSET);
+		skb_put(skb, len);
+		skb->protocol = eth_type_trans(skb, skb->dev);
+		//schedule work to do replenishing
+    if (atomic_inc_return(&priv->frin_to_be_sent[cpu]) >
+      SPI4_FRIN_THRESHOLD){
+      schedule_work(&vits_frin_replenish_work[cpu]);
+    }
+
+#if RMI_SPI4_DEBUG
+		{
+			int loop;
+			printk("[%s] skb: len=%d, data is:\n",
+				__FUNCTION__, skb->len);
+			for(loop=0; loop<skb->len; loop++)
+				printk("%x  ", skb->data[loop]);
+			printk("\n");
+
+		}
+#endif
+		netif_rx(skb);
+		break;
+	}//end of switch
+	return;
+}
+
+/*******************************************************************************
+* Function name :    	rmi_vits_station_unowned_rx_tx_done
+* Input         :
+* Description   :       This function handles the TX DONE and RX IND. It keeps
+*	track the RX desc to be replenish, if it crosses the water mark then
+*	schedules the replenish work item.
+* RETURNS       :       void
+*******************************************************************************/
+
+void rmi_vits_station_unowned_rx_tx_done(	uint32  cmd, 	uint32 	slot,
+				uint32 	port,	char*   addr,
+				uint32  len,	uint32	error)
+{
+	struct 	net_device   *dev;
+	struct 	sk_buff      *skb = 0;
+	int 	cpu ;
+	driver_data	*priv;
+	unsigned int 	eth_interface ;
+	int fbstid;
+
+	cpu = hard_smp_processor_id();
+	switch(cmd){
+	case SPI4_TX_DONE:
+	 	/*in TX_DONE case, port indicates bucket*/
+    skb = (struct  sk_buff*)addr;
+
+		if(skb==NULL){
+			printk("ERROR - TX_DONE: null skb \n");
+			return;
+		}
+    		priv = netdev_priv(skb->dev);
+		eth_interface = priv->port;
+    		spin_lock(&pending_tx_lock[eth_interface]);
+		if(netif_queue_stopped(skb->dev)){
+		 	netif_wake_queue(skb->dev);
+		}
+    		spin_unlock(&pending_tx_lock[eth_interface]);
+		os_free(skb);
+		break;
+	case SPI4_RX_IND:
+#if RMI_SPI4_DEBUG
+		printk("[%s]RX_IND :   port=%d\n",
+			__FUNCTION__,  priv->port);
+#endif
+
+    if(slot == SPI4_0){
+		fbstid = msgrng_xgmac_stid_rfr(0);
+      eth_interface = port;
+    }
+    else if(slot == SPI4_1){
+		fbstid = msgrng_xgmac_stid_rfr(1);
+      eth_interface = port + RMI_SPI4_PORTS_PER_CARD;
+    }
+    else{
+      printk("[%s] ERROR!!! invalid slot\n",__FUNCTION__);
+      return;
+    }
+    dev = spi4_dev[eth_interface];
+    if(dev == NULL){
+      			printk("[%s]ERROR!! eth interface=%d , port=%d , \
+					not registered\n",
+          __FUNCTION__, eth_interface,port);
+      return;
+    }
+
+    priv = netdev_priv(dev);
+	/*
+	 * Allocate an skbuff, initialize it, and copy the data to it.
+	 */
+	skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE, GFP_ATOMIC);
+	if (!skb) {
+		printk("[%s] - no skbuff\n", __FUNCTION__);
+		goto err_exit;
+	}
+
+		skb->dev = dev;
+		skb_reserve(skb, MAC_PREPAD+SPI4_BYTE_OFFSET);
+		skb_put(skb, len);
+		skb->protocol = eth_type_trans(skb, skb->dev);
+		memcpy(skb->data, (char *)addr + 2, len);
+
+		if(rmik_queue_pkt_mem(fbstid, virt_to_phys(addr) & 0xffffffffe0ULL) < 0)
+		rmi_phnx_drop_message_unowned(fbstid, virt_to_phys(addr) & 0xffffffffe0ULL, 1);
+
+	
+#if RMI_SPI4_DEBUG
+		{
+			int loop;
+			printk("[%s] skb: len=%d, data is:\n",
+				__FUNCTION__, skb->len);
+			for(loop=0; loop<skb->len; loop++)
+				printk("%x  ", skb->data[loop]);
+			printk("\n");
+
+		}
+#endif
+		netif_rx(skb);
+		return;
+		err_exit:
+
+		rmi_phnx_drop_message_unowned(fbstid, virt_to_phys(addr) & 0xffffffffe0ULL, 1);
+		if(skb)
+			kfree_skb(skb);
+
+	}//end of switch
+	return;
+}
+
+
+/****************************************************************************
+* Function name :       spi4_check_daughter_cards
+* Input         :
+* Description   :       This function reads the cpld register and checks
+*                       whether any spi4 daughter card present on the board.
+* RETURNS       :       0-if no spi4 cards present
+*                       1-if only spi4-A present
+*                       2-if only spi4-B present
+*                       3-if both spi4-A and spi4-B present
+****************************************************************************/
+unsigned char spi4_check_daughter_cards(void)
+{
+	unsigned char value, flag = 0;
+	unsigned long cpld_base;
+	unsigned char *mmio ;
+
+        cpld_base = (unsigned long)(PHOENIX_CPLD_OFFSET);
+        mmio = (unsigned char*) cpld_base;
+	value = mmio[CPLD_MISC_STATUS_REG];
+
+
+	value = value>>3;
+       	if(!(value & SPI4_MASK_BIT1))
+		flag = 1;
+
+	value = value >>1;
+	if(!(value & SPI4_MASK_BIT1))
+		flag |=2;
+
+        return flag;
+
+}
+
+/*******************************************************************************
+* Function name :	rmi_vits_common_init
+* Input         :
+* Description   :       This function calls the spi4 drivers functions to
+*	ititilize the spi4, configure spills and programs RX desc.
+* RETURNS       :       void
+*******************************************************************************/
+
+int  rmi_vits_common_init(unsigned int slot)
+{
+	unsigned int spi4_ret_value;
+	static int work_init = 0;
+	extern struct net_device_cfg phnx_net_dev_cfg;
+	struct net_device_cfg *net_cfg = &phnx_net_dev_cfg;
+	struct port_cfg *port_cfg;
+	spi4_callback_func callback;
+
+	port_cfg = &net_cfg->xgs_port[slot];
+
+	if(spi4_frin_threashold == 0)
+		spi4_frin_threashold =  MAX_NUM_DESC / NR_CPUS;
+
+	if(MSGRNG_OWN(port_cfg->cfg_flag))
+		callback = rmi_vits_rx_tx_done;
+	else
+		callback = rmi_vits_station_unowned_rx_tx_done;
+
+	spi4_ret_value = spi4_init(slot, (spi4_callback_func)callback);
+	if(spi4_ret_value != SPI4_INIT_SUCCESS)
+		return spi4_ret_value ;
+
+	if(MSGRNG_OWN(port_cfg->cfg_flag)) {
+		spi4_ret_value = rmi_vits_program_rx_desc(slot,
+							  (int)MAX_NUM_DESC * XLR_TOTAL_CHANNELS);
+		if( spi4_ret_value != VITS_PROGRAM_RX_DESC_SUCCESS ){
+			return spi4_ret_value ;
+		}
+	}
+
+	if(PORT_INIT(port_cfg->cfg_flag)) {
+		spi4_ret_value = spi4_open(slot);
+		if( spi4_ret_value != SPI4_OPEN_SUCCESS ){
+			return spi4_ret_value ;
+		}
+	}
+
+	if(MSGRNG_OWN(port_cfg->cfg_flag)) {
+		if(!work_init){
+			for(slot=0; slot<RMI_SPI4_MAX_CPUS; slot++){
+				INIT_WORK(&vits_frin_replenish_work[slot],
+					rmi_vits_frin_replenish);
+			}
+			work_init = 1;
+		}
+	}
+	return  VITS_COMMON_INIT_SUCCESS;
+}
+
+
+static void setup_net_ops(struct net_device_ops *spi4_ops)
+{
+	spi4_ops->ndo_open = rmi_vits_open;
+	spi4_ops->ndo_stop = rmi_vits_close;
+	spi4_ops->ndo_get_stats = rmi_vits_get_stats;
+	spi4_ops->ndo_start_xmit = rmi_vits_xmit;
+}
+/*******************************************************************************
+* Function name :      	rmi_vits_init
+* Input         :
+* Description   :       This function allocates the dev data structure for the
+*	eth drivers and initializes it
+* RETURNS       :       void
+*******************************************************************************/
+
+int rmi_vits_init(void)
+{
+	unsigned int 				slot, port_start, port_end;
+	struct net_device  	*dev  = 0;
+	driver_data 				*priv = 0;
+	extern struct net_device_cfg phnx_net_dev_cfg;
+	struct net_device_cfg *net_cfg = &phnx_net_dev_cfg;
+	struct port_cfg *port_cfg;
+	int 	i = 0;
+	int 	ret = 0, port_register_flag=0;
+
+  	for(slot =0; slot < RMI_SPI4_MAX_SLOTS; slot++){
+		if(net_cfg->xgs_type[slot] == TYPE_SPI4)
+			break;
+	}
+	if(slot == RMI_SPI4_MAX_SLOTS) {
+		printk(KERN_INFO "This board does not support spi4\n");
+		return -1;
+	}
+
+  	g_spi4_card_flag = spi4_check_daughter_cards();
+
+	if(!g_spi4_card_flag){
+        printk(KERN_INFO "rmi_spi4: No SPI4 cards detected\n");
+		return -1;
+	}
+
+	setup_net_ops(&rmi_spi4_net_ops);
+
+	for(slot =0; slot < RMI_SPI4_MAX_SLOTS; slot++){
+		if(spi4_slot[slot] == INVALID_SLOT) continue;
+
+    		if(!(g_spi4_card_flag & (1<<slot))) continue;
+
+			port_cfg = &net_cfg->xgs_port[slot];
+			if(port_cfg->cfg_flag == 0)
+				continue;
+
+    		printk("initializing spi4-%d\n", slot);
+		   if(rmi_vits_common_init(slot) != VITS_COMMON_INIT_SUCCESS){
+      			printk("initialization failed for spi4-%d\n",slot);
+			continue;
+		}
+
+		if(slot == SPI4_0){
+			port_start = 0;
+			port_end =  RMI_SPI4_PORTS_PER_CARD;
+		}
+		else if(slot == SPI4_1){
+      port_start = 0 + RMI_SPI4_PORTS_PER_CARD;
+      port_end = RMI_SPI4_MAX_PORTS ;
+    }
+		else{
+			port_start = port_end = 0;
+		}
+		for(i = port_start; i < port_end; i++){
+			if((active_port[i].slot == INVALID_SLOT ) ||
+			(active_port[i].port == INVALID_PORT)) continue;
+
+			dev = alloc_etherdev(sizeof(driver_data));
+			if (!dev) {
+				ret = -ENOMEM;
+				goto out;
+			}
+			spi4_dev[i] = dev;
+			priv = netdev_priv(dev);
+			priv->dev= dev;
+			ether_setup(dev);
+
+			sprintf(dev->name, "%s%d", "spi",i);
+			dev->netdev_ops = &rmi_spi4_net_ops;
+
+			/* initializing priv member */
+			spin_lock_init(&priv->lock);
+			priv->port =(uint) active_port[i].port;
+			priv->slot =(uint) active_port[i].slot;
+			priv->cfg_flag = port_cfg->cfg_flag;
+
+			if(priv->slot == SPI4_0){
+				priv->spi4_port = priv->port;
+			}
+			else{
+				priv->spi4_port = priv->port - RMI_SPI4_PORTS_PER_CARD;
+			}
+			priv->type = (uint)TYPE_SPI4;
+			/*this is the default link configuration*/
+			priv->speed = SPEED_100M;
+			priv->duplex = 1;
+			priv->autoneg = 1;
+
+			dev->dev_addr[0] = 0x0;
+			dev->dev_addr[1] = 0x0f;
+			dev->dev_addr[2] = 0x30;
+			dev->dev_addr[3] = 0x00;
+			dev->dev_addr[4] = 0x01;
+			dev->dev_addr[5] = i ;
+
+			if(PORT_ATTACH(port_cfg->cfg_flag)){
+			ret = register_netdev(dev);
+			if (ret) {
+				printk("Unable to register %s  eth interface \n",
+				dev->name);
+	    	free_netdev(dev);
+				continue;
+			}
+			printk("%s eth interface is registered\n", dev->name);
+			set_ethtool_ops(dev);
+		}
+			else{
+				rmi_vits_open(dev);
+			}
+			port_register_flag = 1;
+		}
+	}
+
+  	if(port_register_flag){
+	// starting a timer to monitor the link
+	init_timer(&link_monitor_timer);
+	link_monitor_timer.expires = jiffies + 2 * HZ/100;
+	link_monitor_timer.function = rmi_link_monitor;
+	add_timer(&link_monitor_timer);
+	}
+out:
+	if (ret < 0) {
+		printk("Error, ret = %d\n", ret);
+	}
+	return ret;
+}
+
+
+
+void rmi_vits_exit(void)
+{
+	struct net_device *dev;
+	int i;
+
+	for (i = 0; i < RMI_SPI4_MAX_PORTS; i++) {
+		dev = spi4_dev[i];
+		if (!dev)
+			continue;
+		printk("unregistering dev%d\n", i);
+		unregister_netdev(dev);
+		free_netdev(dev);
+	}
+}
+
+/*******************************************************************************
+* Function name :       spi4_get_settings
+* Input         :
+* Description   :       This function provides info about speed, duplexity,
+*	autoneg to ethtool commands.
+* RETURNS       :       void
+*******************************************************************************/
+
+static int
+spi4_get_settings(	struct net_device *dev,
+			struct ethtool_cmd *ecmd)
+{
+
+	driver_data *priv = netdev_priv(dev);
+
+
+	ecmd->supported = (SUPPORTED_10baseT_Half |
+			SUPPORTED_10baseT_Full |
+			SUPPORTED_100baseT_Half |
+			SUPPORTED_100baseT_Full |
+			SUPPORTED_1000baseT_Full|
+			SUPPORTED_Autoneg
+			);
+
+	ecmd->advertising = ADVERTISED_10baseT_Full | ADVERTISED_10baseT_Half |
+		ADVERTISED_100baseT_Full | ADVERTISED_100baseT_Half |
+		ADVERTISED_1000baseT_Full | ADVERTISED_Autoneg;
+
+	switch(priv->speed){
+	case  SPEED_1000M:
+		ecmd->speed = SPEED_1000;
+		break;
+
+	case SPEED_100M:
+		ecmd->speed = SPEED_100;
+		break;
+
+	case SPEED_10M:
+		ecmd->speed = SPEED_10;
+		break;
+
+	}// end of switch
+	ecmd->duplex = priv->duplex;
+	ecmd->phy_address = priv->port;
+	ecmd->port = PORT_TP;
+	ecmd->autoneg = priv->autoneg;
+	return 0;
+}
+
+/*******************************************************************************
+* Function name :       spi4_set_settings
+* Input         :
+* Description   :       This function provides ethtool to set speed, duplexity,
+*       autoneg to ethtool commands.
+* RETURNS       :       void
+*******************************************************************************/
+
+static int
+spi4_set_settings(	struct net_device *netdev,
+			struct ethtool_cmd *ecmd)
+{
+
+  unsigned long flags;
+	driver_data *priv = netdev_priv(netdev);
+	vtss_phy_control_t    phy_cnt;
+	int speed	, driver_speed;
+	int ret = 0;
+	int port;
+	vtss_pcs_autoneg_control_t  autoneg;
+
+	/*
+	   only speed and duplexity parameters are supported
+	 */
+  spin_lock_irqsave(&base_change, flags);
+	port = active_port[ecmd->port].port ;
+	if(port == INVALID_PORT){
+	  	spin_unlock_irqrestore(&base_change,flags);
+		return -EINVAL;
+	}
+	change_vits_base(port);
+	port++;// this is to make the vtss APIs to get the correct PHY port
+	if(vtss_phy_control_get(port, &phy_cnt) == VTSS_OK){
+#if RMI_SPI4_DEBUG
+		printk("phy status read success\n");
+#endif
+	}
+	else{
+	  spin_unlock_irqrestore(&base_change,flags);
+#if RMI_SPI4_DEBUG
+		printk("phy status read failed\n");
+#endif
+		return  1;
+	}
+
+
+	if(ecmd->autoneg == AUTONEG_ENABLE){
+		phy_cnt.autoneg_enable = 1 ;
+	}
+	else{
+		phy_cnt.autoneg_enable = 0 ;
+	}
+	if(priv->autoneg != phy_cnt.autoneg_enable){
+		/*changeing the autoneg*/
+		autoneg.enable = phy_cnt.autoneg_enable;
+		if(vtss_pcs_autoneg_control_set(port,&autoneg) == VTSS_OK){
+			priv->autoneg = phy_cnt.autoneg_enable;
+		}
+		else{
+		  spin_unlock_irqrestore(&base_change,flags);
+			return 1;
+		}
+	}
+	phy_cnt.fdx = ecmd->duplex ;
+	switch(ecmd->speed){
+	case SPEED_1000:
+		speed = (int) VTSS_SPEED_1G ;
+		driver_speed = SPEED_1000M;
+		break;
+	case SPEED_100:
+		speed = (int) VTSS_SPEED_100M ;
+		driver_speed = SPEED_100M;
+		break;
+	case SPEED_10 :
+		speed = (int) VTSS_SPEED_10M ;
+		driver_speed = SPEED_10M;
+		break;
+	default:
+	  spin_unlock_irqrestore(&base_change,flags);
+		return -EINVAL;
+	}
+
+	phy_cnt.speed =  speed;
+	if(vtss_port_set_mode( port, speed, ecmd->duplex) == VTSS_OK){
+	}
+	else{
+		ret = 1;
+	}
+	if(ret){
+		/*mac speed is not success so, no need to change phy speed*/
+		return ret;
+	}
+	if(vtss_phy_control_set(port, &phy_cnt) == VTSS_OK){
+	}
+	else{
+		ret = 1;
+	}
+
+	if(ret==0){
+		/*update the speed, and duplexity*/
+		priv->speed = driver_speed;
+		priv->duplex = ecmd->duplex;
+	}
+
+  spin_unlock_irqrestore(&base_change,flags);
+	return ret;
+}
+
+
+static void
+spi4_get_drvinfo(	struct net_device *dev,
+		struct ethtool_drvinfo *drvinfo)
+{
+
+	printk("[%s]: \n",__FUNCTION__);
+	strcpy(drvinfo->driver,DRV_NAME);
+	strcpy(drvinfo->version, DRV_VERSION);
+	strcpy(drvinfo->fw_version, "N/A");
+	return;
+}
+
+struct ethtool_ops spi4_ethtool_ops = {
+	.get_settings           = spi4_get_settings,
+	.set_settings           = spi4_set_settings,
+	.get_drvinfo            = spi4_get_drvinfo
+};
+
+void set_ethtool_ops(struct net_device *netdev)
+{
+	SET_ETHTOOL_OPS(netdev, &spi4_ethtool_ops);
+}
+
+
+
+
+module_init(rmi_vits_init);
+module_exit(rmi_vits_exit);
+
diff --git a/drivers/net/rmi_spi4/rmi_vits_eth.h b/drivers/net/rmi_spi4/rmi_vits_eth.h
new file mode 100644
index 0000000..1f54115
--- /dev/null
+++ b/drivers/net/rmi_spi4/rmi_vits_eth.h
@@ -0,0 +1,154 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_VITS_ETH_H
+#define _ASM_RMI_VITS_ETH_H
+
+#include "rmi_spi4.h"
+
+#define INVALID_SLOT 	100
+#define INVALID_PORT	100
+
+#define RMI_SPI4_MAX_PORTS 20 
+#define RMI_SPI4_MAX_SLOTS 2
+
+#define PORT_0 0
+#define PORT_1 1
+#define PORT_2 2
+#define PORT_3 3 
+#define PORT_4 4
+#define PORT_5 5
+#define PORT_6 6
+#define PORT_7 7
+#define PORT_8 8
+#define PORT_9 9
+#define PORT_10 10
+#define PORT_11 11
+#define PORT_12 12
+#define PORT_13 13
+#define PORT_14 14
+#define PORT_15 15 
+#define PORT_16 16
+#define PORT_17 17
+#define PORT_18 18
+#define PORT_19 19
+
+struct spi4_port{
+	int	slot; // value should be either SPI4_0 or SPI4_1
+	int port;
+	unsigned long	io_base;
+
+};
+
+int spi4_slot[] = {SPI4_0,SPI4_1};
+static struct spi4_port active_port[] = {
+	{
+		.slot=SPI4_0,
+		.port=PORT_0
+	},
+	{
+		.slot=SPI4_0,
+		.port=PORT_1
+	},
+	{
+		.slot=SPI4_0,
+		.port=PORT_2
+	},
+	{
+		.slot=SPI4_0,
+		.port=PORT_3
+	},
+	{
+		.slot=SPI4_0,
+		.port=PORT_4
+	},
+	{
+		.slot=SPI4_0,
+		.port=PORT_5
+	},
+	{
+		.slot=SPI4_0,
+		.port=PORT_6
+	},
+	{
+		.slot=SPI4_0,
+		.port=PORT_7
+	},
+	{
+		.slot=SPI4_0,
+		.port=PORT_8
+	},
+	{
+		.slot=SPI4_0,
+		.port=PORT_9
+	},
+	{
+		.slot=SPI4_1,
+		.port=PORT_10
+	},
+	{
+		.slot=SPI4_1,
+		.port=PORT_11
+	},
+	{
+		.slot=SPI4_1,
+		.port=PORT_12
+	},
+	{
+		.slot=SPI4_1,
+		.port=PORT_13
+	},
+	{
+		.slot=SPI4_1,
+		.port=PORT_14
+	},
+	{
+		.slot=SPI4_1,
+		.port=PORT_15
+	},
+	{
+		.slot=SPI4_1,
+		.port=PORT_16
+	},
+	{
+		.slot=SPI4_1,
+		.port=PORT_17
+	},
+	{
+		.slot=SPI4_1,
+		.port=PORT_18
+	},
+	{
+		.slot=SPI4_1,
+		.port=PORT_19
+	},
+
+};
+#endif
diff --git a/drivers/net/rmi_spi4/rmi_vits_wrapper.c b/drivers/net/rmi_spi4/rmi_vits_wrapper.c
new file mode 100644
index 0000000..3dd414c
--- /dev/null
+++ b/drivers/net/rmi_spi4/rmi_vits_wrapper.c
@@ -0,0 +1,103 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <asm/rmi/iomap.h>
+#include "rmi_vits_wrapper.h"
+#include <asm/rmi/debug.h>
+
+
+// global reference   
+volatile unsigned int *megis = (unsigned int*)(long)VITESS_BASE_ADDR_1;
+
+
+// function to setup CS_2 area correctly
+void megis_phoenix_init(int vitess_device) 
+{
+
+	if (vitess_device == 1)
+		megis = (unsigned int*)(long)VITESS_BASE_ADDR_1;
+
+	if (vitess_device == 2)
+		megis = (unsigned int*)(long)VITESS_BASE_ADDR_2;
+	return;
+}  
+
+
+
+
+
+// function to convert from littleE to bigE
+unsigned int swizzle(unsigned int _in) 
+{
+	unsigned int i;
+	i = (((_in & 0xff00ff00) >> 8) | ((_in & 0x00ff00ff) << 8));
+	return i;
+}
+
+
+
+
+// lower level register write routines
+void megis_write(unsigned int _block, unsigned int _sub, 
+		unsigned int _addr, unsigned int value) 
+{
+	//  printf ("MEIGS: Write block %x sub %x Addr %x Value %x\n", _block, _sub, 
+	//  	_addr, value);
+	int lvalue = swizzle(value);
+	megis[(  (_block << 12) + (_sub << 8) + (_addr))] = lvalue; 
+	return;
+}
+
+
+
+
+// lower level register read routine
+unsigned int megis_read(unsigned int _block, unsigned int _sub, 
+			unsigned int _addr) 
+{
+	unsigned int i;
+	i =  megis[((_block << 12) + (_sub << 8) + (_addr))];
+	i = swizzle(i);
+	return i;
+}
+
+
+
+// lower level posted register read routine
+unsigned int megis_pread(unsigned int _block, unsigned int _sub, 
+unsigned int _addr) 
+{
+	unsigned int i;
+	i =  megis[((_block << 12) + (_sub << 8) + (_addr))];
+	i =  megis[((_block << 12) + (_sub << 8) + (0xfe))];
+	i = swizzle(i);
+	return i;
+}
+
diff --git a/drivers/net/rmi_spi4/rmi_vits_wrapper.h b/drivers/net/rmi_spi4/rmi_vits_wrapper.h
new file mode 100644
index 0000000..0e839b0
--- /dev/null
+++ b/drivers/net/rmi_spi4/rmi_vits_wrapper.h
@@ -0,0 +1,46 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_VITS_WRAPPER_H
+#define _ASM_RMI_VITS_WRAPPER_H 1
+#define VITESS_BASE_ADDR_1 0xffffffffBD800000ULL
+#define VITESS_BASE_ADDR_2 0xffffffffBD820000ULL
+
+
+
+// lower level access functions
+void 		megis_phoenix_init(int vitess_device);
+unsigned int 	swizzle     (unsigned int _in);
+void 		megis_write (unsigned int _block, unsigned int _sub, 
+		unsigned int _addr, unsigned int value);
+unsigned int 	megis_read  (unsigned int _block, unsigned int _sub, unsigned int _addr);
+unsigned int 	megis_pread (unsigned int _block, unsigned int _sub, unsigned int _addr);
+
+#endif
diff --git a/drivers/net/rmi_spi4/vitesse_common.h b/drivers/net/rmi_spi4/vitesse_common.h
new file mode 100644
index 0000000..d7a1fe3
--- /dev/null
+++ b/drivers/net/rmi_spi4/vitesse_common.h
@@ -0,0 +1,283 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/*
+
+ vitesse_common.h  -- Vitesse common definitions
+
+ This file is used by the Vitesse Switch/Mac API software.
+ Modify it to fit your configuration.
+
+ Copyright (c) 2003 Vitesse Semiconductor Corporation. All Rights Reserved.
+ Unpublished rights reserved under the copyright laws of the United States of 
+ America, other countries and international treaties. The software is provided
+ without fee. Permission to use, copy, store, modify, disclose, transmit or 
+ distribute the software is granted, provided that this copyright notice must 
+ appear in any copy, modification, disclosure, transmission or distribution of 
+ the software. Vitesse Semiconductor Corporation retains all ownership, 
+ copyright, trade secret and proprietary rights in the software. THIS SOFTWARE
+ HAS BEEN PROVIDED "AS IS," WITHOUT EXPRESS OR IMPLIED WARRANTY INCLUDING, 
+ WITHOUT LIMITATION, IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A 
+ PARTICULAR USE AND NON-INFRINGEMENT.
+ 
+*/
+#include <linux/types.h>
+
+#define VSC7323
+
+#ifndef _VITESSE_COMMON_H
+#define _VITESSE_COMMON_H 1
+
+/* ================================================================= *
+ *  Basic types:
+ *    uint, ulong, ushort, uchar - unsigned standard types.
+ *    longlong, ulonglong - 64 bit integers.
+ *    BOOL - The boolean type. false: 0, true: anything but 0.
+ * ================================================================= */
+
+//typedef unsigned long       ulong;
+typedef unsigned char       uchar;
+
+/* - longlong, ulonglong ------------------------------------------- */
+
+/* longlong and ulonglong: 64 bit integers */
+#ifdef __GNUC__
+typedef long long           longlong;
+typedef unsigned long long  ulonglong;
+#endif /* __GNUC__ */
+#ifdef _MSC_VER
+typedef __int64             longlong;
+typedef unsigned __int64    ulonglong;
+#endif /* _MSC_VER */
+
+/* - BOOL ---------------------------------------------------------- */
+
+/* BOOL: The boolean type. false: 0, true: anything but 0. */
+/* You may redefine it to any other type, e.g. char. */
+typedef int                 BOOL;
+
+
+/* ================================================================= *
+ *  Custom types
+ * ================================================================= */
+
+/* Big counter type, may be 32 or 64 bits depending on the OS */
+/* You may redefine it to ulong or ulonglong */
+typedef ulonglong vtss_counter_t;
+
+
+/* ================================================================= *
+ *  Macros:
+ *    VTSS_ASSERT(expr) - Call assert(expr).
+ *    VTSS_NSLEEP(nsec) - Sleep at least nsec nanoseconds.
+ *    VTSS_MSLEEP(msec) - Sleep at least msec milliseconds.
+ *  Notes:
+ *    VTSS_NSLEEP uses busy waiting, so it should only be used for
+ *    very short intervals.
+ *    VTSS_MSLEEP should not use busy waiting, but may do so.
+ * ================================================================= */
+
+
+/* - VTSS_ASSERT(expr) -------------------------------------------------- */
+
+/* VTSS_ASSERT(expr): Call assert(). */
+#if !defined(VTSS_ASSERT)
+/* You may define your own VTSS_ASSERT here. */
+#endif
+
+#ifndef _POSIX_C_SOURCE
+#define _POSIX_C_SOURCE 0
+#endif
+
+#if !defined(VTSS_ASSERT) && (_POSIX_C_SOURCE > 0)
+#include <assert.h>
+#define VTSS_ASSERT(expr) { assert(expr); }
+#endif
+
+/* - VTSS_NSLEEP(nsec) -------------------------------------------------- */
+#define VTSS_NSLEEP(nsec)
+
+/* VTSS_NSLEEP(nsec): Sleep nsec nanoseconds. Use busy waiting. */
+#if !defined(VTSS_NSLEEP)
+/* You may define your own VTSS_NSLEEP here. */
+#endif
+
+#if !defined(VTSS_NSLEEP) && defined(_BSD_SOURCE)
+/* The function "gettimeofday" is available, so use it. */
+#include <sys/time.h>
+#define VTSS_NSLEEP(nsec) { \
+    struct timeval tve, tv; \
+    gettimeofday(&tve,NULL); \
+    tve.tv_usec+=(nsec+999)/1000;\
+    if (tve.tv_usec>=1000000) { tve.tv_sec+=tve.tv_usec/1000000; tve.tv_usec%=1000000; } \
+    do { gettimeofday(&tv,NULL); } \
+    while ( timercmp(&tv,&tve,<) ); \
+}
+#endif /* _BSD_SOURCE */
+#if !defined(VTSS_NSLEEP) && ( (_POSIX_C_SOURCE - 0) >= 199309L )
+/* The function "nanosleep" is available, so use it. */
+#include <time.h>
+#include <errno.h>
+#define VTSS_NSLEEP(nsec) {struct timespec ts = { 0, nsec }; while (nanosleep(&ts,&ts)==-1 && errno==EINTR) ;}
+#endif /* (_POSIX_C_SOURCE - 0) >= 199309L */
+#if !defined(VTSS_NSLEEP) && defined(_WIN32)
+#define VTSS_NSLEEP(nsec) {VOID Sleep(DWORD); Sleep((nsec+999999)/1000000);}
+#endif /* _WIN32 */
+/* VTSS_NSLEEP is required by the API. */
+#if defined(__VTSS_LIBRARY__) && !defined(VTSS_NSLEEP)
+#error Macro function VTSS_NSLEEP must be defined in vitesse_common.h.
+#endif /* __VTSS_LIBRARY__ && !VTSS_NSLEEP */
+
+/* - VTSS_MSLEEP(msec) -------------------------------------------------- */
+#define VTSS_MSLEEP(msec)
+
+/* VTSS_MSLEEP(msec): Sleep msec milliseconds. Avoid busy waiting. */
+#if !defined(VTSS_MSLEEP)
+/* You may define your own VTSS_MSLEEP here. */
+#endif
+
+#if !defined(VTSS_MSLEEP) && ( (_POSIX_C_SOURCE - 0) >= 199309L )
+/* The function "nanosleep" is available, so use it. */
+#include <time.h>
+#include <errno.h>
+#define VTSS_MSLEEP(msec) { \
+    struct timespec ts; \
+    ts.tv_sec = msec/1000; \
+    ts.tv_nsec = (msec%1000)*1000000; \
+    while (nanosleep(&ts,&ts)==-1 && errno==EINTR) ; \
+}
+#endif /* (_POSIX_C_SOURCE - 0) >= 199309L */
+#if !defined(VTSS_MSLEEP) && defined(_WIN32)
+#define VTSS_MSLEEP(msec) {VOID Sleep(DWORD); Sleep(msec);}
+#endif /* _WIN32 */
+/* VTSS_MSLEEP is required by the API. */
+#if defined(__VTSS_LIBRARY__) && !defined(VTSS_MSLEEP)
+#error Macro function VTSS_MSLEEP must be defined in vitesse_common.h.
+#endif /* __VTSS_LIBRARY__ && !VTSS_MSLEEP */
+
+
+/* ================================================================= *
+ *  Debugging Macros:
+ *    VTSS_E(args) - Error.
+ *    VTSS_D(args) - Debug.
+ *    VTSS_N(args) - Noise.
+ *
+ *    Usage Example: VTSS_E(("Port %d",port_no));
+ * ================================================================= */
+
+#if !defined(VTSS_E) && !defined(VTSS_D) && !defined(VTSS_N)
+/* You may define your own VTSS_E, VTSS_D and VTSS_N here. */
+#endif
+
+#if !defined(VTSS_E) && !defined(VTSS_D) && !defined(VTSS_N) && defined(SWITCH_APP_TRACE)
+/* Debugging for an VTSS internal application. */
+#include <stdio.h>
+#include <stdarg.h>
+
+extern const char *vtss_trace_func;
+extern int vtss_trace_line;
+extern int vtss_trace_layer;
+extern int vtss_trace_level;
+void vtss_api_trace(int level, BOOL debug, const char *func, int line, char *msg);
+void vtss_trace(const char *fmt, ...);
+
+#define E(args); {vtss_trace_level=1, vtss_trace_layer=VTSS_TRACE_LAYER, vtss_trace_func=__FUNCTION__; vtss_trace_line=__LINE__; vtss_trace args;}
+#define D(args); {vtss_trace_level=2, vtss_trace_layer=VTSS_TRACE_LAYER, vtss_trace_func=__FUNCTION__; vtss_trace_line=__LINE__; vtss_trace args;}
+#define N(args); {vtss_trace_level=3, vtss_trace_layer=VTSS_TRACE_LAYER, vtss_trace_func=__FUNCTION__; vtss_trace_line=__LINE__; vtss_trace args;}
+#endif
+
+#if !defined(VTSS_E) && !defined(VTSS_D) && !defined(VTSS_N)
+#if (_POSIX_C_SOURCE > 0)
+/* Fallback to debugging using printf. */
+#include <stdio.h>
+#define VTSS_E(args) { printf("E:%s#%d: ",__FUNCTION__,__LINE__); printf args; printf("\n"); }
+#define VTSS_D(args) { printf("D:%s#%d: ",__FUNCTION__,__LINE__); printf args; printf("\n"); }
+#define VTSS_N(args) { printf("N:%s#%d: ",__FUNCTION__,__LINE__); printf args; printf("\n"); }
+#else
+/* Fallback to no debugging. */
+#define VTSS_E(args)
+#define VTSS_D(args)
+#define VTSS_N(args)
+#endif
+#endif
+
+
+/* ================================================================= *
+ *  No changes should be needed below this line
+ * ================================================================= */
+
+#if !defined(MEIGS2) && !defined(MEIGS2E) && !defined(CAMPBELL) && \
+    !defined(VSC7321) && !defined(VSC7323) && !defined(VSC7331) 
+#warning Device MEIGS2, MEIGS2E, CAMPBELL, VSC7321, VSC7323 or VSC7331 should be defined.
+#endif
+
+/* ================================================================= *
+ *  Various definitions and macros
+ * ================================================================= */
+
+/* MAKEBOOL01(value): Convert BOOL value to 0 (false) or 1 (true). */
+/* Use this to ensure BOOL values returned are always 1 or 0. */
+#ifndef MAKEBOOL01
+#define MAKEBOOL01(value) ((value)?1:0)
+#endif
+#ifndef TRUE
+#define TRUE MAKEBOOL01(1)
+#endif
+#ifndef FALSE
+#define FALSE MAKEBOOL01(0)
+#endif
+
+/* - Basic defines/macros: NULL, offsetof() ------------------------ */
+
+#ifndef NULL
+#ifdef __cplusplus
+#define NULL 0
+#else
+#define NULL ((void *)0)
+#endif
+#endif
+
+#ifndef offsetof
+#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)
+#endif
+
+/* - Compiler Hints ------------------------------------------------ */
+
+#ifdef __GNUC__
+/* "__attribute__ ((const))" informs the GNU C compiler that a
+ * function does not change any states anywhere
+ */
+#define __VTSS_ATTRIB_CONST_FUNCTION__ __attribute__ ((const))
+#else
+#define __VTSS_ATTRIB_CONST_FUNCTION__ /* no "const" compiler hint */
+#endif
+
+
+/* ================================================================= *
+ *  Private data and functions (used internally by VTSS library)
+ * ================================================================= */
+#ifdef __VTSS_LIBRARY__
+
+/* - Compiler Hints ------------------------------------------------ */
+
+#ifdef __GNUC__
+/* "__attribute__ ((unused))" informs the GNU C compiler that a
+ * variable is not used, so we don't get a warning about it
+ */
+#define __VTSS_ATTRIB_UNUSED_VARIABLE__ __attribute__ ((unused))
+#else
+#define __VTSS_ATTRIB_UNUSED_VARIABLE__ /* no "unused" compiler hint */
+#endif
+
+#endif /* __VTSS_LIBRARY__ */
+
+#endif /* _VITESSE_COMMON_H_ */
diff --git a/drivers/net/rmi_spi4/vitesse_highlevel.c b/drivers/net/rmi_spi4/vitesse_highlevel.c
new file mode 100644
index 0000000..4f6db18
--- /dev/null
+++ b/drivers/net/rmi_spi4/vitesse_highlevel.c
@@ -0,0 +1,5367 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/************************************************************-*- mode: C -*-*/
+/*                                                                          */
+/*           Copyright (C) 2003 Vitesse Semiconductor Corporation           */
+/*                           All Rights Reserved.                           */
+/*                                                                          */
+/****************************************************************************/
+/*                                                                          */
+/*                            Copyright Notice:                             */
+/*                                                                          */
+/*  Unpublished rights reserved under the copyright laws of the United      */
+/*  States of America, other countries and international treaties.          */
+/*                                                                          */
+/*      The software is provided without fee.                               */
+/*                                                                          */
+/*  Permission to use,  copy, store, modify, disclose, transmit or          */
+/*  distribute the software is granted, provided that this copyright notice */
+/*  must appear in any copy, modification, disclosure, transmission or      */
+/*  distribution of the software.                                           */
+/*                                                                          */
+/*  Vitesse Semiconductor Corporation retains all ownership, copyright,     */
+/*  trade secret and proprietary rights in the software.                    */
+/*                                                                          */
+/*  THIS SOFTWARE HAS BEEN PROVIDED "AS IS," WITHOUT EXPRESS OR IMPLIED     */
+/*  WARRANTY INCLUDING, WITHOUT LIMITATION, IMPLIED WARRANTIES OF           */
+/*  MERCHANTABILITY, FITNESS FOR A PARTICULAR USE AND NON-INFRINGEMENT.     */
+/*                                                                          */
+/*    $Id: vitesse_highlevel.c,v 1.1.2.6 2008-05-22 02:59:56 kmurthy Exp $         */
+/*                                                                          */
+/****************************************************************************/
+/*                                                                          */
+/*  File content:                                                           */
+/*                                                                          */
+/*  vitesse_highlevel.c -- a set of functions for configuration of various  */
+/*                  system features in a MeigsII/MeigsIIe/Campbell chip     */
+/*                                                                          */
+/****************************************************************************/
+#define __MEIGSII_LIBRARY__
+
+
+
+#include "vitesse_highlevel.h"
+#include "meigsii_reg.h"
+#include "vitesse_io.h"
+#include <asm/rmi/debug.h>
+#include <linux/kernel.h>
+
+#define     SET_BIT( A,SHIFT)    A |=  ((ulong)1<<SHIFT)
+#define     CLR_BIT( A,SHIFT)    A &= ~((ulong)1<<SHIFT)
+
+#define     SET_BITS_MASKED( result, value, mask)  \
+	result = (result & ~(mask))|(value & mask)
+
+
+/****************************************************************************/
+/*                                                                          */
+/*   Type definitions                                                       */
+/*                                                                          */
+/****************************************************************************/
+typedef struct _vtss_device_setup_t {
+
+	vtss_mac_major_mode_t    mmode;
+	ulong                    chip_id;
+
+} vtss_device_setup_t;
+
+
+/************     Use of the normalised and preamble headers   *************/
+/*
+   The related NLE bit selects the way data is transmitted internally in the 
+   device and is always used when the normalized header is used.
+ */
+typedef struct _m2_header_t {
+
+	BOOL use_norm_hdr;
+	BOOL use_prm_hdr;
+	/*
+	   BOOL mpls_normalize;
+	   BOOL vlan_normalize;
+	 */
+} m2_header_t;
+
+
+/****************************************************************************/
+/*                                                                          */
+/*   Local function prototypes                                              */
+/*                                                                          */
+/****************************************************************************/
+/*static vtss_rc vtss_aggr_mode_set( vtss_aggr_mode_t *p_aggrmode);*/
+
+/* control of the use of header in ingress direction */
+static vtss_rc vtss_hdr_insert( BOOL enable, m2_header_t hdr);
+#if 0
+/* control of the use of header in egress direction */
+static vtss_rc vtss_hdr_expect( BOOL enable, m2_header_t hdr);
+#endif
+
+
+/* Enabling/disabling use of the header in different blocks */
+static void vtss_fifo_use_hdr( int fifo, BOOL enable, m2_header_t hdr);
+
+static void vtss_aggr_use_header( BOOL enable, m2_header_t hdr);
+
+
+static void vtss_port10G_header_insert( BOOL enable, m2_header_t hdr);
+
+static void vtss_port1G_header_insert( int ppn, BOOL enable, 
+		const m2_header_t hdr);
+
+/* vtss_rc vtss_device_major_mode_setup( vtss_mac_major_mode_t mm); */
+
+
+/****************************************************************************/
+/*                                                                          */
+/*   Global data                                                            */
+/*                                                                          */
+/****************************************************************************/
+
+static vtss_mapped_port_t vtss_logical_ports[VTSS_PORT_ARRAY_SIZE] = {
+	{ -1, -1, -1},
+	{ -1, -1, -1},
+};
+
+static vtss_device_setup_t vtss_device_setup = {
+	VTSS_MAC_MAJOR_MODE_UNDEFINED,
+	0,  /* chip id */
+};
+
+
+/* Current state of 1G ports */
+static vtss_port_setup_t vtss_1G_ports_setup[VTSS_PORT_ARRAY_SIZE];/* = {} */
+
+
+/* Pointer to the global device setup structure */
+static vtss_device_setup_t *pdevice = &vtss_device_setup;
+
+
+/*******************************************************************************
+
+  Function vtss_port_map_set()
+  =================================================================================
+
+Description:
+The function initializes internally kept port mapping structure based on 
+the information received from the user 
+
+
+Syntax
+vtss_rc  vtss_port_map_set( const vtss_mapped_port_t 
+mapped_ports[VTSS_PORT_ARRAY_SIZE]);
+
+Arguments:
+mapped_ports    an array mapping logical port numbers to physical 
+(on-chip) port numbers, MIIM controller channel and
+PHY addresses.
+
+Return code:
+VTSS_OK   if operation completed successfully
+
+ *******************************************************************************/
+vtss_rc vtss_port_map_set( const vtss_mapped_port_t 
+		mapped_ports[VTSS_PORT_ARRAY_SIZE])
+{
+	int i;
+
+	for (i=0;i<VTSS_PORT_ARRAY_SIZE; i++) {
+		vtss_logical_ports[i] = mapped_ports[i];
+	}
+
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+
+  Function vtss_port_mapped()
+  =================================================================================
+
+Description:
+Checks whether the logical port is mapped to any physical port or not.
+
+Syntax
+BOOL vtss_port_mapped( const vtss_port_no_t port_no )
+
+Arguments:
+port_no     logical port number
+
+
+Return code:
+VTSS_OK   if operation completed successfully
+
+ *******************************************************************************/
+BOOL vtss_port_mapped( const vtss_port_no_t port_no )
+{
+
+	return ( -1 != vtss_logical_ports[port_no].chip_port);
+}
+
+
+/*******************************************************************************
+
+  Function vtss_chip_reset()
+================================================================================
+
+Description:
+Performs a software reset of the chip
+
+
+Syntax
+void vtss_chip_reset(void);
+
+Arguments:
+None
+
+Return code:
+None
+
+*******************************************************************************/
+void vtss_chip_reset(void)
+{
+
+	/* Reset the chip */
+	vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, 
+			M2_SW_RESET, M2_SW_GLOBAL_RESET);
+	VTSS_NSLEEP(VTSS_T_RESET);
+
+}
+
+
+/*******************************************************************************
+
+  Function vtss_get_chip_id()
+================================================================================
+
+Description:
+Returns the content of the chip identification register
+
+NOTE: -----------------------------    
+|  device         chip id   |
+-----------------------------
+|  VSC7321       0x0F407321 |
+|  VSC7323       0x073230E9 |
+|  VSC7331       0x073310E9 |
+-----------------------------
+
+Syntax
+ulong vtss_chip_id_get(void);
+
+
+Arguments:
+None
+
+
+Return code:
+The content of the chip identification register.
+
+ *******************************************************************************/
+ulong vtss_chip_id_get(void)
+{
+	vtss_device_setup_t *pvds = pdevice;
+	pvds->chip_id = vtss_io_read( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_CHIPID);
+	return pvds->chip_id;
+}
+
+
+/*******************************************************************************
+
+  Function vtss_major_mode_set( )
+  ================================================================================
+
+Description:
+Prepares the system to run in one of the major modes.
+This function must be called only once after reset. If the function is 
+called when the system is up and running it will return an error.
+It is not allowed to call this function with VTSS_MAC_MAJOR_MODE_UNDEFINED
+as an argument.
+
+NOTE:
+
+
+Syntax
+vtss_rc vtss_major_mode_set( vtss_mac_major_mode_t mm);
+
+Arguments:
+mm     select the major mode for the session
+
+
+Return code:
+VTSS_OK                  successful completion
+VTSS_WRONG_PARAMETER     if called after the major mode has been set
+
+ *******************************************************************************/
+vtss_rc vtss_major_mode_set( vtss_mac_major_mode_t mm)
+{
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+
+	if (mm == VTSS_MAC_MAJOR_MODE_UNDEFINED) {
+		return VTSS_WRONG_PARAMETER;
+	}
+
+	if ( VTSS_MAC_MAJOR_MODE_UNDEFINED != pvds->mmode) { 
+		return VTSS_WRONG_PARAMETER;
+	} else {
+		pvds->mmode = mm;
+	}
+
+	return VTSS_OK;
+}
+
+
+/******************************************************************************
+ *
+ * Description: Performs several low-level initialization operations on the chip.
+ *              The function must be called after start-up or chip reset.
+ *
+ * NOTE:        This function does not perform COMPLETE initialization of the chip.
+ *
+ * \param:      psystem   pointer to a structure with configuration data
+ *
+ * \return:     VTSS_OK   if operation completed successfully or
+ *              VTSS_WRONG_PARAMETER
+ *
+ **************************************************************************kbp*/
+vtss_rc vtss_system_setup( vtss_system_setup_t *ps)
+{
+	ulong reg  = 0;
+
+	/* Setup Serial and Parallel CPU interfaces */
+	/* Assuming order of bits in a byte big-endian, 
+		however it can be changed */
+	if ( ps->big_endian == FALSE) {
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, 
+			M2_SI_TRANSFER_SEL, M2_LTL_END_BYTE_BIG_END_BIT);
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, 
+			M2_CPU_TRANSFER_SEL, M2_LTL_END_BYTE_BIG_END_BIT);
+	} else {
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, 
+			M2_SI_TRANSFER_SEL, M2_BIG_END_BYTE_BIG_END_BIT);
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, 
+			M2_CPU_TRANSFER_SEL, M2_BIG_END_BYTE_BIG_END_BIT);
+	}
+
+
+#if !defined MEIGS2 && !defined VSC7321
+	/* Set-up wait states on serial read when frequency > 0.5MHz 
+	   to match the chip response time on reads of 1 us. */
+	if ( ps->si_dummy_bytes < 8 ) {
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, 
+				M2E_SI_INSERT_BYTES, ps->si_dummy_bytes);
+	} else {
+		return VTSS_WRONG_PARAMETER;
+	}
+#endif
+
+
+	reg = 0;
+	/* Take SerDes PLL out of reset when not in Single Channel mode */
+	if ( ps->rx_chain_mode_10G == FALSE) { SET_BIT( reg, 7); }
+
+	/* Setup SerDes reference clock sources */
+	if ( ps->serdes_ref_clk_external == FALSE) {
+		/* NB: serdes_ref_clk_external must be 
+			TRUE when using VSC7323 or VSC7331 */
+#if !defined MEIGS2 && !defined VSC7321
+		return VTSS_WRONG_PARAMETER;
+#endif
+	} else {
+		SET_BIT( reg, 1);
+	}
+	vtss_io_writemasked( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, 
+			M2_PLL_CLK_SPEED, reg, 0x82);
+
+
+	/* Setup System reference clock sources */
+	if ( ps->system_ref_clk_extern == FALSE) {
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_SYS_CLK_SELECT, 0);
+	} else {
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_SYS_CLK_SELECT, 1);
+	}
+
+
+	reg = 0;
+	/* Setup interface mode */
+	if( ps->single_chip_mode != FALSE) { SET_BIT( reg, 3); SET_BIT( reg, 2); }
+	if( ps->rx_chain_mode_10G != FALSE) { SET_BIT( reg, 1); SET_BIT( reg, 0); }
+	vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_IFACE_MODE, reg);
+
+
+	return VTSS_OK;
+}
+
+
+/******************************************************************************
+ *
+ * Description: This is a supplementary function.
+ *              It configures a structure referenced by the pointer to the
+ *              default values for the chosen major mode.
+ *
+ * \param:      ps        pointer to a structure, which will be filled out
+ *              mjm       mode the device will run
+ *
+ * \return:     VTSS_OK   if operation completed successfully or
+ *
+ **************************************************************************kbp*/
+vtss_rc vtss_system_setup_get_default_values( vtss_system_setup_t *ps,
+		vtss_mac_major_mode_t mjm)
+{
+
+	/* TRUE (default):  CPU interface runs as big-endian */
+	ps->big_endian = TRUE;
+
+
+	/* Number of dummy bytes that will be inserted in the 
+	   reply before valid data when serial interface is used
+	   at high frequency. Set to 0 if not used */
+	ps->si_dummy_bytes = 0;  
+
+
+	/* Select the source of the serdes reference clock */
+	/* TRUE (default):  external source of the reference clock */
+	/* FALSE         :  internal source of the reference clock */
+	/* NOTE!!   MUST be TRUE when using VSC7323 or VSC7331 */
+	ps->serdes_ref_clk_external = TRUE;
+
+
+	/* Select the source of the system clock */
+	/* FALSE (default): system clock uses internal source */
+	/* TRUE             system clock uses GPIO15 as system clock input */
+	ps->system_ref_clk_extern = FALSE; 
+
+
+	/* Single Chip Aggregation or trunking mode */
+	if ( mjm == VTSS_MAC_MAJOR_MODE_10G_1G_AGGR || 
+			mjm == VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK) {
+		ps->single_chip_mode = TRUE; 
+	} else {
+		ps->single_chip_mode = FALSE;
+	}
+
+
+	/* Single Channel mode */
+	if ( mjm == VTSS_MAC_MAJOR_MODE_SPI4_10G) {
+		ps->rx_chain_mode_10G = TRUE;  /* SPI4.2<->10G mode */
+	} else {
+		ps->rx_chain_mode_10G = FALSE; /* all other modes */
+	}
+
+	return VTSS_OK;
+}
+
+
+/****************************************************************************/
+/*                                                                          */
+/*   1G(triple speed) port setup                                            */
+/*                                                                          */
+/****************************************************************************/
+
+
+
+/*******************************************************************************
+
+  Function 
+  ================================================================================
+
+Description:
+Configures 10M/100M/1G port according to the structure provided.
+
+
+Syntax
+vtss_rc vtss_port_setup( vtss_port_no_t portnum, vtss_port_setup_t* ps);
+
+Arguments:
+portnum      logical port to be initialized
+ps           pointer to the setup structure
+
+Return code:
+VTSS_OK   if operation completed successfully
+VTSS_PORT_NOT_MAPPED
+VTSS_MAJOR_MODE_NOT_SET
+VTSS_WRONG_MAJOR_MODE
+VTSS_WRONG_PARAMETER
+
+ *******************************************************************************/
+vtss_rc vtss_port_setup( vtss_port_no_t portnum, vtss_port_setup_t* ps)
+{
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+
+	ulong mode_cfg_reg = 0;
+	ulong dev_setup_reg_value = 0x80; /* Bit 7 shall be set to 1 */
+	ulong pcs_enable = 0;
+	ulong pause_reg_value = 0;
+	ulong reg = 0;
+
+	/* Some hardcoded values */
+	BOOL use_back_seed = FALSE;
+	/*  ulong backseed = 0; */
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+	//  VTSS_N(("Port setup. Logic port #%d, phys prt #%d", portnum, ppn));
+	//printk("Port setup. Logic port #%d, phys prt #%d\n", portnum, ppn);
+
+	/* Check the physical port number */
+	if (ppn < 0) { 
+		printk("[%s]port=%d not mapped\n",__FUNCTION__,portnum);
+		return VTSS_PORT_NOT_MAPPED; 
+	}
+
+
+	/* Check major mode */
+	switch ( pvds->mmode) {
+	/* valid major modes */
+	case VTSS_MAC_MAJOR_MODE_SPI4_1G:      /* SPI4 <-> 10x1G */
+	case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:  /* Single Chip aggr */
+	case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* Single Chip trunking */
+		break;
+
+	/* Error - major mode undefined */
+	case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+		return VTSS_MAJOR_MODE_NOT_SET;
+
+	/* Error - wrong major mode */
+	case VTSS_MAC_MAJOR_MODE_SPI4_10G:     /* SPI4 <-> 1x10G */
+	case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:   /* */
+	case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+	default:
+		printk("[%s]wrong major mode=%d\n",__FUNCTION__,pvds->mmode);
+		return VTSS_WRONG_MAJOR_MODE;
+	}
+
+#if defined MEIGS2 || defined VSC7321
+	/* VSC7321 (Meigs-II) requires BOTH fields being either set or cleared */
+	if (ps->flowcontrol.obey != ps->flowcontrol.generate) { return VTSS_WRONG_PARAMETER; }
+#endif
+
+	/* -------------------- Device Setup Register ------------------------ */
+
+	/* While changing speed, the port must be in reset state */
+	SET_BIT( dev_setup_reg_value, 0);
+
+	/* Select speed and interface for the device */
+	switch (ps->interface_mode.speed) {
+	case VTSS_SPEED_10M:
+		SET_BITS_MASKED( dev_setup_reg_value, M2_1G_PORT_CLOCK_MODE_10M<<1, 
+				M2_1G_PORT_CLOCK_MODE_MASK<<1);
+		break;
+	case VTSS_SPEED_100M:
+		SET_BITS_MASKED( dev_setup_reg_value, M2_1G_PORT_CLOCK_MODE_100M<<1, 
+				M2_1G_PORT_CLOCK_MODE_MASK<<1);
+		break;
+	case VTSS_SPEED_1G:
+	case VTSS_SPEED_ETH_GFPT:
+	case VTSS_SPEED_FC2_GFPT: /* 6    Gbit/s Fibre Channel */
+	case VTSS_SPEED_FC4_GFPT: /* 7    Gbit/s Fibre Channel */
+	case VTSS_SPEED_1FC_GFPT: /* 8    1Gbit/s Fibre Channel or FICON*/
+	case VTSS_SPEED_2FC_GFPT: /* 9    2Gbit/s Fibre Channel */
+	case VTSS_SPEED_ESC_GFPT: /* 10 200Mbit/s ESCON or SBCON */
+	case VTSS_SPEED_DVB_GFPT: /* 11 270Mbit/s DVB ASI */
+
+	if (ps->interface_mode.interface_type == VTSS_PORT_INTERFACE_SERDES) {
+		SET_BITS_MASKED( dev_setup_reg_value, 
+			M2_1G_PORT_CLOCK_MODE_1G_SERDES<<1, 
+			M2_1G_PORT_CLOCK_MODE_MASK<<1);
+
+	} else if (ps->interface_mode.interface_type == VTSS_PORT_INTERFACE_TBI) {
+		SET_BITS_MASKED( dev_setup_reg_value, 
+			M2E_1G_PORT_CLOCK_MODE_TBI<<1, 
+			M2_1G_PORT_CLOCK_MODE_MASK<<1);
+
+	} else {
+		SET_BITS_MASKED( dev_setup_reg_value, 
+			M2_1G_PORT_CLOCK_MODE_1G_GMII<<1, 
+			M2_1G_PORT_CLOCK_MODE_MASK<<1);
+	}
+
+	/* Overrule setting by disable Ingress CRC updating when in GFP-T mode */
+	if (ps->interface_mode.speed != VTSS_SPEED_1G) { ps->crc_update = FALSE; }
+		break;
+
+	default:
+		//VTSS_E(("1G port #%d. Wrong speed: %d", ppn, ps->interface_mode.speed));
+		printk("1G port #%d. Wrong speed: %d\n", ppn, ps->interface_mode.speed);
+		return VTSS_WRONG_PARAMETER;
+	}
+
+	/* Set-up selected interface */
+	switch ( ps->interface_mode.interface_type) {
+	case VTSS_PORT_INTERFACE_GMII:
+		/* Invert (R)GMII_TX_clock when GMII */
+		SET_BIT( dev_setup_reg_value, 6); 
+			break;
+#if !defined MEIGS2 && !defined VSC7321
+	case VTSS_PORT_INTERFACE_RGMII:
+		SET_BIT( dev_setup_reg_value, 4);   /* Enable RGMII */
+		break;
+#endif
+	case VTSS_PORT_INTERFACE_SERDES:
+		SET_BIT( pcs_enable, 0);            /* Enable Ethernet PCS */
+		break;
+	case VTSS_PORT_INTERFACE_TBI:
+		/* Disable Signal detect */
+		vtss_io_writemasked( M2_BLK_MACS, ppn, M2_PCS_CTRL, 0, (ulong)3<<22);
+		SET_BIT( dev_setup_reg_value, 23);  /* Enable TBI */
+		SET_BIT( dev_setup_reg_value, 22);  /* Invert TBI_TX_clock when TBI */
+		SET_BIT( pcs_enable, 0);            /* Enable Ethernet PCS */
+		break;
+	default:
+		printk("1G port #%d. Wrong interface type: %d\n", 
+			ppn, ps->interface_mode.interface_type);
+		break;
+	}
+
+
+	/* -------------------- Mode config Register ------------------------ */
+
+	/* interframe gaps */  
+	SET_BITS_MASKED( mode_cfg_reg, ps->frame_gaps.ifg1 << 6, VTSS_IFG_MASK << 6);
+	SET_BITS_MASKED( mode_cfg_reg, ps->frame_gaps.ifg2 << 10, VTSS_IFG_MASK << 10);
+
+	/* duplex mode */
+	if ( ps->fdx != FALSE) {
+		SET_BIT( mode_cfg_reg, 2);
+		if (ps->interface_mode.speed == VTSS_SPEED_1G) { SET_BIT( mode_cfg_reg, 3); }
+	}
+
+	/* vlan_awr */
+	if ( ps->vlan_aware != FALSE) { SET_BIT( mode_cfg_reg, 4); }
+
+	/* back_seed */
+	/*
+	   if (use_back_seed) {
+	   SET_BITS_MASKED( mode_cfg_reg, (ulong)back_seed << 16); SET_BIT( mode_cfg_reg, 14);
+	   }
+	 */
+
+	/* drop_on_length_error */
+	if ( ps->drop_on_length_error != FALSE) { SET_BIT( mode_cfg_reg, 15); }
+
+	/* Old Backoff Enable */
+	/*
+	//VTSS_ASSERT((old_backoff >= 0) && (old_backoff <= 2));
+	switch (old_backoff) {
+	case 0:
+	CLR_BITS_MASKED( mode_cfg_reg, (ulong)0x3 << 24);
+	break;
+	case 1:
+	SET_BITS_MASKED( mode_cfg_reg, (ulong)0x1 << 24);
+	break;
+	case 2:
+	SET_BITS_MASKED( mode_cfg_reg, (ulong)0x2 << 24);
+	break;
+	}
+	 */
+
+	/* Write to device Mode configureation register */
+	vtss_io_write( M2_BLK_MACS, ppn, M2_MODE_CFG, mode_cfg_reg);
+
+	/* Clear load_seed bit */
+	if (use_back_seed) { 
+		vtss_io_writemasked( M2_BLK_MACS, ppn, 
+				M2_MODE_CFG, 0, (ulong)1<<14); 
+	}
+
+	/* -------------------- Update other Register ------------------------ */
+
+	/* Set flow control */
+	pause_reg_value = (ps->tx_pause_value & VTSS_PORT_1G_TX_PAUSE_MASK);
+	if( ps->enable_tx_pause_xon_xoff != FALSE){ 
+		SET_BIT( pause_reg_value, 17); 
+	}
+	vtss_io_write( M2_BLK_MACS, ppn, M2_PAUSE_CFG, pause_reg_value);
+
+	/* VSC7321 (Meigs-II) requires both bits to be set */
+	vtss_port_flow_control_mode( portnum, ps->flowcontrol.obey, ps->flowcontrol.generate);
+
+	/* Set-up MAC address. Will be written if flowcontrol setup is requested. */
+	if( ps->flowcontrol.obey != FALSE || ps->flowcontrol.generate != FALSE ) {
+		ulong mac_addr_low_reg = 
+			(ps->flowcontrol.smac.addr[2] << 16)| 
+			(ps->flowcontrol.smac.addr[1] <<  8)|
+			ps->flowcontrol.smac.addr[0];
+
+		ulong mac_addr_high_reg = 
+			(ps->flowcontrol.smac.addr[5] << 16)| 
+			(ps->flowcontrol.smac.addr[4] <<  8)|
+			ps->flowcontrol.smac.addr[3];
+
+		vtss_io_write( M2_BLK_MACS, ppn, M2_MAC_ADDR_HIGH_CFG, mac_addr_high_reg);
+		vtss_io_write( M2_BLK_MACS, ppn, M2_MAC_ADDR_LOW_CFG, mac_addr_low_reg);
+	}
+
+	/* Write to device max length register */
+	vtss_io_write( M2_BLK_MACS, ppn, M2_MAXLEN_CFG, 
+			ps->maxframelength & VTSS_MAX_FRAME_LENGTH_MASK);
+
+	/* Change Egress CT_THRSHLD to maxframelength when set to store&forward */
+	if (( pvds->mmode == VTSS_MAC_MAJOR_MODE_SPI4_1G )|| 
+		(pvds->mmode == VTSS_MAC_MAJOR_MODE_SPI4_10G )){
+		if ( vtss_io_read ( M2_BLK_FIFO, M2_SUBBLK_EGRESS, 
+					M2_CT_THRHLD + ppn) == 0 ) { 
+			vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_EGRESS, 
+					M2_CT_THRHLD + ppn, ps->maxframelength>>5); 
+		}
+	}
+
+	/* HOLD device clock in reset while changing the clock-mode */
+	/* vtss_io_writemasked( M2_BLK_MACS, ppn, M2_DEV_SETUP, 0x1, 0x1); */
+
+	/* Write to device PCS config register */
+	vtss_io_write( M2_BLK_MACS, ppn, M2_PCS_CONFIG, pcs_enable);
+
+	/* Write to device setup register */
+	vtss_io_write( M2_BLK_MACS, ppn, M2_DEV_SETUP, dev_setup_reg_value);
+
+	/* Configure 1G SERDES */
+	if (ps->interface_mode.interface_type == VTSS_PORT_INTERFACE_SERDES) {
+		/* Apply RESET to SERDES. This will keep it reset */
+		vtss_io_write( 	M2_BLK_MACS, ppn, M2_SERDES_TEST, 
+				VTSS_SERDES_RESET_AND_ENABLE);
+		/* Write the serdes configuration word */
+		vtss_io_write( M2_BLK_MACS, ppn, M2_SERDES_CONF, 
+				VTSS_SERDES_CONFIG_WORD);
+		/* Take SERDES out of reset */
+		vtss_io_write( M2_BLK_MACS, ppn, M2_SERDES_TEST, 
+				VTSS_SERDES_ENABLE);
+	}
+
+	/* Take the MAC block out of RESET */
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_DEV_SETUP, 0, 0x1);
+
+	/* --------------- Update Normalizer Register ------------- */
+
+	/* Set-up port number in fake preamble header */
+	reg = ((ps->prm_hdr_value & 0xF)<<12);
+
+	/* Insert fake preamble header */
+	if( ps->prm_hdr_insert != FALSE) { SET_BIT( reg, 0); }
+
+	/* Insert Normalized header */
+	if( ps->norm_hdr_insert != FALSE) {
+		SET_BIT( reg, 1);
+	} else {
+		SET_BIT( reg, 2); /* NLE */
+	}
+
+	/* Disable Ingress CRC updating */
+	if( ps->crc_update == FALSE) { SET_BIT( reg, 9); }
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_TRI_NORMALIZER, reg, (ulong)0xF207);
+
+	/* ----------- Update De-Normalizer Register --------- */
+
+	reg = 0;
+	if ( ps->norm_hdr_expect != FALSE) { SET_BIT( reg, 1); }
+	if ( ps->prm_hdr_expect != FALSE) { SET_BIT( reg, 0); }
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_TRI_DENORM, reg, (ulong)0x3);
+
+	/* Egress CRC-32 Checker after SPI4 must be disabled to 
+		let bad frames pass through */
+	if( VTSS_OK != vtss_port_fcs_modify( portnum, ps->fcs_modify)){
+		/* Issue a warning */
+		printk("[%s] not able to modify fcs\n",__FUNCTION__);
+	}
+
+	/* Save user data to the global structure */
+	vtss_1G_ports_setup[ppn] = *ps;
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+
+  Function void vtss_port_setup_get_default_values( vtss_port_setup_t* ps,
+  vtss_mac_major_mode_t mmode)
+
+================================================================================
+
+Description:
+Supplementary function: fills the structure referenced by the pointer 
+with the default values for a given major_mode.
+By default the port is setup to run in 1G GMII mode.
+
+NOTE: 
+Requires global port mapping table to be initialized
+
+Syntax
+void vtss_port_setup_get_default_values( vtss_port_setup_t* ps,
+vtss_mac_major_mode_t mmode);
+
+Arguments:
+ps           pointer to a structure that will be filled with default data
+mmode        one of the major modes
+
+Return code:
+VTSS_OK
+
+ *******************************************************************************/
+vtss_rc vtss_port_setup_get_default_values( vtss_port_setup_t* ps,
+		vtss_mac_major_mode_t mmode)
+{
+
+	vtss_mac_t mac_addr = {{0,0,0,0,0,0}};
+
+
+	switch ( mmode) {
+		/* valid major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+	/* By default 1G GMII interface is assumed */
+	ps->interface_mode.interface_type = VTSS_PORT_INTERFACE_GMII;
+	ps->interface_mode.speed = VTSS_SPEED_1G;
+
+
+	ps->fdx = TRUE; /* Full duplex: TRUE, half duplex: FALSE */
+
+	/* Flow control setup */
+	ps->flowcontrol.obey = FALSE;
+	ps->flowcontrol.generate = FALSE;
+	ps->flowcontrol.smac = mac_addr;
+
+
+	ps->enable_tx_pause_xon_xoff = TRUE;
+	ps->tx_pause_value = VTSS_PORT_1G_TX_PAUSE_VALUE;
+
+
+	/* interframe gaps for 1G speed */
+	ps->frame_gaps.ifg1 = VTSS_IFG1_1G;
+	ps->frame_gaps.ifg2 = VTSS_IFG2_1G;
+
+	ps->maxframelength = VTSS_MAX_FRAME_LENGTH; /* Max frame length. */
+
+	ps->vlan_aware = FALSE;
+
+	ps->drop_on_length_error = FALSE;
+
+	ps->crc_update = FALSE;
+	ps->fcs_modify = VTSS_FCS_DO_NOTHING;
+
+
+
+	/* The following two fields are hw related */
+	ps->invert_gtx_tx_clock = TRUE;  /* HW related */
+	ps->invert_rx_clock     = FALSE; /* HW related */
+
+
+	switch ( mmode) {
+		/* valid major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+			ps->norm_hdr_insert = FALSE;
+			ps->prm_hdr_insert = FALSE;
+			ps->prm_hdr_value = 0;
+
+			ps->norm_hdr_expect = FALSE;
+			ps->prm_hdr_expect = FALSE;
+			break;
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+			ps->norm_hdr_insert = TRUE;
+			ps->prm_hdr_insert = FALSE;
+			ps->prm_hdr_value = 0;
+
+			ps->norm_hdr_expect = FALSE;
+			ps->prm_hdr_expect = FALSE;
+			break;
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			/* by default configured to preamble trunking */
+			ps->norm_hdr_insert = TRUE;
+			ps->prm_hdr_insert = TRUE;
+			ps->prm_hdr_value = 0;
+
+			ps->norm_hdr_expect = FALSE;
+			ps->prm_hdr_expect = TRUE;
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G:
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:
+			/* these cases are needed only to make the compiler happy */
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+	return VTSS_OK;
+}
+
+
+/*----------------  Run-time funcitons  ---------------------------------------*/
+/*******************************************************************************
+
+  Function  vtss_port_set_mode( )
+================================================================================
+
+Description:
+Configure speed and duplex mode of a 10M/100M/1G port
+
+NOTE: 
+
+
+Registers affected:
+DEV_SETUP     0xB
+MODE_CFG      0x0
+
+
+Syntax
+vtss_rc vtss_port_set_mode( vtss_port_no_t portnum, vtss_speed_t speed, 
+BOOL fdx);
+
+Arguments:
+portnum   logical port number
+speed     10M, 100M, 1G
+fdx       TRUE - full duplex, FALSE -- half duplex
+
+Return code:
+VTSS_OK                 if operation completed successfully
+VTSS_PORT_NOT_MAPPED    if the logical port is not mapped
+VTSS_WRONG_PARAMETER    wrong value or combination of input parameters
+
+*******************************************************************************/
+vtss_rc vtss_port_set_mode( 	vtss_port_no_t 	portnum, 
+				vtss_speed_t 	speed, 
+				BOOL 		fdx)
+{
+
+	ulong dev_setup_reg = 0;
+	ulong mode_cfg_reg = 0, mode_cfg_reg_mask = 0;
+	ulong old_value = 0;
+	uchar ifg1 = 0, ifg2 = 0;
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	/* 1G requre full duplex mode */
+	if ((speed == VTSS_SPEED_1G) && (!fdx)) {
+		return VTSS_WRONG_PARAMETER;
+	}
+
+
+	switch (speed) {
+		case VTSS_SPEED_10M:
+			SET_BIT( dev_setup_reg, 1);
+
+			ifg1 = (fdx) ? VTSS_IFG1_10M_FDX : VTSS_IFG1_10M_HDX;
+			ifg2 = (fdx) ? VTSS_IFG2_10M_FDX : VTSS_IFG2_10M_HDX;
+
+			break;
+		case VTSS_SPEED_100M:
+			SET_BIT( dev_setup_reg, 2);
+
+			ifg1 = (fdx) ? VTSS_IFG1_10M_FDX : VTSS_IFG1_10M_HDX;
+			ifg2 = (fdx) ? VTSS_IFG2_10M_FDX : VTSS_IFG2_10M_HDX;
+
+			break;
+		case VTSS_SPEED_1G:
+			if ( vtss_1G_ports_setup[ppn].interface_mode.interface_type == 
+					VTSS_PORT_INTERFACE_SERDES) {
+				SET_BIT( dev_setup_reg, 3);
+			} else {
+				SET_BIT( dev_setup_reg, 2);
+				SET_BIT( dev_setup_reg, 1);
+			}
+
+			ifg1 = VTSS_IFG1_1G;
+			ifg2 = VTSS_IFG2_1G;
+
+			SET_BIT( mode_cfg_reg, 3); /*GIGA mode*/
+
+			break;
+		default:
+			//    VTSS_E(("1G port #%d. Wrong speed: %d", ppn, speed));
+			printk("1G port #%d. Wrong speed: %d\n", ppn, speed);
+			return VTSS_WRONG_PARAMETER;
+	}
+
+	SET_BIT( mode_cfg_reg_mask, 3);
+
+	/* Prepare port for reset */
+	SET_BIT( dev_setup_reg, 0);
+
+	if(fdx) {
+		SET_BIT( mode_cfg_reg, 2);
+	}
+	SET_BIT( mode_cfg_reg_mask, 2);
+
+	SET_BITS_MASKED( mode_cfg_reg, (ulong)ifg1<<6, (ulong)VTSS_IFG_MASK<<6);
+	SET_BITS_MASKED( mode_cfg_reg, (ulong)ifg2<<10, (ulong)VTSS_IFG_MASK<<10);
+	/* set the mode_cfg_reg mask */
+	SET_BITS_MASKED( mode_cfg_reg_mask, (ulong)VTSS_IFG_MASK<<6, 
+			(ulong)VTSS_IFG_MASK<<6);
+	SET_BITS_MASKED( mode_cfg_reg_mask, (ulong)VTSS_IFG_MASK<<10, 
+			(ulong)VTSS_IFG_MASK<<10);
+
+	/* Read the current value */
+	old_value = 0x3 & vtss_io_read( M2_BLK_MACS, ppn, M2_MODE_CFG); 
+	/* Disable port */
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_MODE_CFG, 0, 0x3);
+
+	/* Change the mode */
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_MODE_CFG,
+			mode_cfg_reg, mode_cfg_reg_mask);
+
+	/* Write device setup register. It will also reset the port */
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_DEV_SETUP,
+			dev_setup_reg, 0xF);
+
+	/* leave reset state */
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_DEV_SETUP,
+			0, 0x1);
+
+	/* Restore old RX and TX values */
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_MODE_CFG, old_value, 0x3);
+
+
+	/* Update global data */
+	vtss_1G_ports_setup[ppn].interface_mode.speed = speed;
+	vtss_1G_ports_setup[ppn].fdx = fdx;
+	vtss_1G_ports_setup[ppn].frame_gaps.ifg1 = ifg1;
+	vtss_1G_ports_setup[ppn].frame_gaps.ifg2 = ifg2;
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+
+  Function vtss_port_set_enable()
+================================================================================
+
+Description:
+Enable/disable rx, tx or both in a 10M/100M/1G port 
+
+NOTE: 
+
+
+Syntax
+vtss_rc vtss_port_set_enable( vtss_port_no_t portnum, 
+BOOL rx_en, BOOL tx_en);
+
+Arguments:
+portnum      logical port number
+rx_en        if TRUE, enables reception of Ethernet frames
+if FALSE, disables reception of Ethernet frames
+tx_en        if TRUE, enables transmission of Ethernet frames
+if FALSE, disables transmission of Ethernet frames
+
+Return code:
+VTSS_OK                if operation completed successfully
+VTSS_PORT_NOT_MAPPED   if the logical port is not mapped
+
+ *******************************************************************************/
+vtss_rc vtss_port_set_enable( vtss_port_no_t portnum, BOOL rx_en, BOOL tx_en)
+{
+	ulong mode_cfg_reg = 0;
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	if(rx_en) {
+		SET_BIT(mode_cfg_reg, 1);
+	}
+	if(tx_en) {
+		SET_BIT(mode_cfg_reg, 0);
+	}
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_MODE_CFG, mode_cfg_reg, 0x3);
+
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+
+  Function vtss_port_fcs_modify()
+================================================================================
+
+Description:
+Set CRC adding/updating mode (done in the denormalizer).
+
+NOTE:
+Only in egress direction.
+SPI4 block must not discard frames with incorrect FCS.
+
+
+Syntax
+vtss_rc vtss_port_fcs_modify( vtss_port_no_t portnum, vtss_fcs_modify_t mc);
+
+Arguments:
+portnum     logical port number
+mc          select the way FCS is modified
+
+Return code:
+VTSS_OK                 if operation completed successfully
+VTSS_PORT_NOT_MAPPED    logical port not mapped
+
+ *******************************************************************************/
+vtss_rc vtss_port_fcs_modify( vtss_port_no_t portnum, vtss_fcs_modify_t mc)
+{
+	ulong denorm_reg = 0;
+	ulong mask = (1<<5)|(1<<4);
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	/* Meigs2 has two independent bits: UPDATE and ADD, which should always have
+	   opposite values */
+	switch ( mc) {
+		case  VTSS_FCS_DO_NOTHING:
+			/* denorm_reg is already set to 0 */
+			break;
+		case VTSS_FCS_UPDATE:
+			SET_BIT( denorm_reg, 5);
+			/* CLR_BIT( denorm_reg, 4); denorm_reg is already set to 0 */
+			break;
+		case VTSS_FCS_ADD:
+			SET_BIT( denorm_reg, 4);
+			/* CLR_BIT( denorm_reg, 5); denorm_reg is already set to 0 */
+			break;
+	}
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_TRI_DENORM, denorm_reg, mask);
+
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+
+  Function 
+  ================================================================================
+
+Description:
+Discard/do_not_discard  Ethernet frames with wrong FCS in ingress direciton
+
+NOTE: 
+Not only frames with incorrect FCS will be allowed upstream, but also 
+all wrong frames including fragments.
+
+Syntax
+vtss_rc vtss_port_check_fcs( vtss_port_no_t portnum, BOOL check);
+
+Arguments:
+portnum   logical port number
+check     TRUE   -- frames with wrong FCS are discarded (default)
+FALSE  -- frames with wrong FCS are forwarded upstream
+
+Return code:
+VTSS_OK   if operation completed successfully
+VTSS_FEATURE_NOT_SUPPORTED
+VTSS_PORT_NOT_MAPPED   logical port not mapped
+
+ *******************************************************************************/
+vtss_rc vtss_port_check_fcs( vtss_port_no_t portnum, BOOL check)
+{
+
+#if defined MEIGS2 || defined VSC7321
+
+	/* MEIGS2 always discards ingress frames with bad FCS */
+	/* it is not possible to disable this feature */
+	return VTSS_FEATURE_NOT_SUPPORTED;
+
+#else
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+
+	ulong norm_reg_value = 0;
+	ulong mdbg_reg_value = 0;
+	ulong gress_test_reg = 0;
+	ulong gress = M2_SUBBLK_INGRESS;
+
+	vtss_device_setup_t *pvds = pdevice;
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	/* Only one global device per API is currently supported */
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			gress = M2_SUBBLK_EGRESS;
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+	if (check) {
+		SET_BIT( norm_reg_value, 9); /* NO_CRC update */
+		SET_BITS_MASKED( mdbg_reg_value, 0x3, 0x3); /* SET_FAIL & KEEP_BAD */
+		SET_BIT( gress_test_reg, 4); /* NO_DROP_IN_FRM */
+	} else {
+		/* bits are already cleared, just write them down */
+	}
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_TRI_NORMALIZER, 
+			norm_reg_value, 1<<9);
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2E_TRI_MULTI_DBG, 
+			mdbg_reg_value, 0x3);
+
+	vtss_io_writemasked(M2_BLK_FIFO, gress, ppn,
+			gress_test_reg, 1<<4);
+
+	return VTSS_OK;
+
+#endif
+}
+
+
+/*******************************************************************************
+
+  Function   vtss_port_forward_pause_frames( )
+  ================================================================================
+
+Description: 
+Allow pause frames pass through the device. By default 10M/100M/1G block
+prevents propagation of pause frames through the device.
+
+NOTE: 
+
+Syntax
+vtss_rc vtss_port_forward_pause_frames( vtss_port_no_t portnum, BOOL allow);
+
+Arguments:
+portnum   number of the logical port
+allow     if TRUE, allows pause frames pass through the device
+if FALSE, pause frames will not be allowed to pass
+
+Return code:
+VTSS_OK               if operation completed successfully
+VTSS_PORT_NOT_MAPPED  logical port is not mapped to any physical port
+
+ *******************************************************************************/
+vtss_rc vtss_port_forward_pause_frames( vtss_port_no_t portnum, BOOL allow)
+{
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_TRI_NORMALIZER, (allow)?0:(1<<6), 1<<6);
+	return VTSS_OK;
+}
+
+
+
+/*******************************************************************************
+
+  Function vtss_port_flow_control_mode( )
+
+  ================================================================================
+
+Description:
+Select different modes of flow control on Ethernet interface.
+
+Terminology:
+obey        obeys pause frames received from Ethernet 
+generate    generate pause frames/backpressure upon request from the 
+destination (FIFO or the host interface)
+
+NOTE:
+If fc_obey AND fc_generate are set to FALSE, then flow control is disabled
+
+IMPORTANT
+VSC7321 supports only symmetrical flow control and requires both
+arguments to be set to TRUE.
+
+Syntax
+vtss_rc vtss_port_flow_control_mode( vtss_port_no_t port_num, 
+BOOL fc_obey, 
+BOOL fc_generate)
+
+Arguments:
+obey        if TRUE, obeys pause frames from Ethernet
+if FALSE, disregard pause frames from Ethernet
+generate    if TRUE, generate pause frames/backpressure upon request 
+from the destination block (FIFO or the host interface)
+
+
+Return code:
+VTSS_OK               if operation completed successfully
+VTSS_PORT_NOT_MAPPED  logical port is not mapped to any physical port
+
+ *******************************************************************************/
+vtss_rc vtss_port_flow_control_mode( vtss_port_no_t port_num, 
+		BOOL fc_obey, 
+		BOOL fc_generate)
+{
+	ulong pause_reg_value = 0;
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[port_num].chip_port;
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+
+#if defined MEIGS2 || defined VSC7321
+
+	if(fc_obey && fc_generate) {
+
+		/* The only mode supported in Meigs-II*/
+		SET_BIT( pause_reg_value, 16);
+		/* IMPORTANT:                                                */
+		/* tx_pause_value and mac_address must be already initialized */
+
+	} else {
+		/* disable flow control */
+	}
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_PAUSE_CFG, pause_reg_value, 1<<16);
+
+#else /* VSC7323 && VSC7331*/
+
+	if(fc_obey && fc_generate) {
+		SET_BIT( pause_reg_value, 16);
+	} else if (fc_obey) {
+		SET_BIT( pause_reg_value, 18);
+		CLR_BIT( pause_reg_value, 16);
+	} else if (fc_generate) {
+		SET_BIT( pause_reg_value, 19);
+		/* SET_BIT( pause_reg_value, 17); */
+		CLR_BIT( pause_reg_value, 16);
+	}
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_PAUSE_CFG, 
+			pause_reg_value, 0xD<<16);
+
+#endif
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+
+  Function vtss_port_counters_clear(  )
+
+  ================================================================================
+
+Description:
+Clears counter for the logical port 
+
+NOTE:
+In its current form this funciton clears counters in all 1G ports.
+This behaviour will be corrected in the next release.
+
+
+Syntax
+vtss_rc vtss_port_counters_clear( const vtss_port_no_t portnum );
+
+Arguments:
+
+
+Return code:
+
+ *******************************************************************************/
+vtss_rc vtss_port_counters_clear( const vtss_port_no_t portnum )
+{
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+	//  VTSS_N(("Port setup. Logic port #%d, phys prt #%d", portnum, ppn));
+	//printk("Port setup. Logic port #%d, phys prt #%d\n", portnum, ppn);
+
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+
+	/* Writing to this register clears counters in all 1G ports */
+	vtss_io_write( M2_BLK_STAT, ppn, M2_STAT_INIT, 0x0);
+
+
+	return VTSS_OK;
+}
+
+
+
+/*******************************************************************************
+
+  Function  vtss_port_counters_get()
+
+  ================================================================================
+
+Description:
+Clears counter for the logical port 
+
+Syntax
+vtss_rc vtss_port_counters_get( const vtss_port_no_t  portnum,
+vtss_port_counters_t *pcounters)
+
+Arguments:
+portnum   number of the logical port
+pc 
+
+Return code:
+
+ *******************************************************************************/
+vtss_rc vtss_port_counters_get( const vtss_port_no_t  portnum,
+		vtss_port_counters_t *pc)
+{
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+	//  VTSS_N(("Port setup. Logic port #%d, phys prt #%d", portnum, ppn));
+	//	printk("Port setup. Logic port #%d, phys prt #%d\n", portnum, ppn);
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+
+	pc->rx_in_bytes = vtss_io_read(M2_BLK_STAT, ppn, M2_RX_IN_BYTES);
+	pc->rx_symbol_carrier = vtss_io_read( M2_BLK_STAT, ppn, 
+			M2_RX_SYMBOL_CARRIER);
+	pc->rx_pause = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_PAUSE);
+	pc->rx_unsup_opcode = vtss_io_read( M2_BLK_STAT, ppn, 
+					M2_RX_UNSUP_OPCODE);
+
+	pc->rx_ok_bytes = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_OK_BYTES);
+	pc->rx_bad_bytes = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_BAD_BYTES);
+
+	pc->rx_unicast = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_UNICAST);
+	pc->rx_multicast = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_MULTICAST);
+	pc->rx_broadcast = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_BROADCAST);
+	pc->rx_crc = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_CRC);
+	pc->rx_alignment = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_ALIGNMENT); 
+	pc->rx_undersize = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_UNDERSIZE);
+
+	pc->rx_fragments = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_FRAGMENTS);
+	pc->rx_in_range_error = vtss_io_read( M2_BLK_STAT, ppn, 
+			M2_RX_IN_RANGE_LENGTH_ERROR);
+	pc->rx_out_of_range_error = vtss_io_read( M2_BLK_STAT, ppn, 
+			M2_RX_OUT_OF_RANGE_ERROR);
+	pc->rx_oversize = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_OVERSIZE);
+	pc->rx_jabbers = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_JABBERS);
+	pc->rx_size_64 = vtss_io_read( M2_BLK_STAT, ppn, M2_RX_SIZE_64);
+
+	pc->rx_size_65_to_127 = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_RX_SIZE_65);
+	pc->rx_size_128_to_255 = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_RX_SIZE_128);
+	pc->rx_size_256_to_511 = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_RX_SIZE_256);
+	pc->rx_size_512_to_1023 = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_RX_SIZE_512);
+	pc->rx_size_1024_to_1518 = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_RX_SIZE_1024);
+	pc->rx_size_1519_to_max = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_RX_SIZE_1519);
+
+	pc->rx_xgmii_prot_err = 0; /* Only on 10G MAC port */
+
+	pc->rx_ipg_shrink = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_RX_IPG_SHRINK);
+
+
+	pc->tx_out_bytes = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_TX_OUT_BYTES);
+	pc->tx_pause = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_PAUSE);
+	pc->tx_ok_bytes = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_OK_BYTES);
+
+	pc->tx_unicast = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_UNICAST);
+	pc->tx_multicast = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_MULTICAST);
+	pc->tx_broadcast = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BROADCAST);
+
+	pc->tx_multiple_coll = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_TX_MULTIPLE_COLL);
+	pc->tx_late_coll = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_LATE_COL);
+	pc->tx_xcoll = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_XCOLL);
+	pc->tx_defer = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_DEFER);
+	pc->tx_xdefer = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_XDEFER);
+	pc->tx_carrier_sense = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_CSENSE);
+
+
+	pc->tx_size_64 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_SIZE_64);
+	pc->tx_size_65_to_127 = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_TX_SIZE_65);
+	pc->tx_size_128_to_255 = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_TX_SIZE_128);
+	pc->tx_size_256_to_511 = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_TX_SIZE_256);
+	pc->tx_size_512_to_1023 = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_TX_SIZE_512);
+	pc->tx_size_1024_to_1518 = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_TX_SIZE_1024);
+	pc->tx_size_1519_to_max = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_TX_SIZE_1519);
+
+
+	pc->tx_single_coll = vtss_io_read( M2_BLK_STAT, ppn, 
+						M2_TX_SINGLE_COL);
+	pc->tx_backoff2 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF2);
+	pc->tx_backoff3 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF3);
+	pc->tx_backoff4 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF4);
+	pc->tx_backoff5 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF5);
+	pc->tx_backoff6 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF6);
+	pc->tx_backoff7 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF7);
+	pc->tx_backoff8 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF8);
+	pc->tx_backoff9 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF9);
+	pc->tx_backoff10 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF10);
+	pc->tx_backoff11 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF11);
+	pc->tx_backoff12 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF12);
+	pc->tx_backoff13 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF13);
+	pc->tx_backoff14 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF14);
+	pc->tx_backoff15 = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_BACKOFF15);
+
+	pc->tx_underrun = vtss_io_read( M2_BLK_STAT, ppn, M2_TX_UNDERRUN);
+
+
+	/* 10G is not properly being handled for the drop counters */
+	/* It must reflect the major mode: 10G as single or multi channel, kbp */
+
+	pc->ingress_overflow_drop = 
+		vtss_io_read( M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_FIFO_DROP_CNT+ppn);
+	pc->egress_overflow_drop = 
+		vtss_io_read( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_FIFO_DROP_CNT+ppn);
+
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+
+  Function   
+
+  ================================================================================
+
+Description:
+Configure 1G MAC block to insert normalisation of incoming ethernet frames.
+Works in the direction from 1G MAC to the ingress FIFO.
+
+NOTE. If an element in the 'hdr' structure is set to FALSE, that type of 
+header is left unmodified. 
+
+Syntax
+
+
+
+Arguments:
+ppn        physical port (port-on-chip)
+enable     action to be taken -- enable or disable header insertion
+hdr        normalized header/preamble header structure
+
+
+Return code:
+
+ *******************************************************************************/
+static void vtss_port1G_header_insert( int ppn, BOOL enable, 
+		const m2_header_t hdr)
+{
+	ulong reg = 0, reg_mask = 0;
+
+	if ( hdr.use_norm_hdr) {
+
+		if (enable == TRUE) {
+			reg |= M2_NORMALIZER_BIT_NH;
+			/* Norm hdr requires NLE bit to be set */
+			reg |= M2_NORMALIZER_BIT_NLE;
+		}
+		/* else -- do nothing, the bits are already cleared */
+
+		reg_mask |= M2_NORMALIZER_BIT_NH;
+		reg_mask |= M2_NORMALIZER_BIT_NLE;
+	}
+
+	if ( hdr.use_prm_hdr) {
+		if (enable == TRUE)
+			reg |= M2_NORMALIZER_BIT_PH;
+
+		reg_mask |= M2_NORMALIZER_BIT_PH;
+	}
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_NORMALIZER, reg, reg_mask);
+
+	return;
+}
+
+
+/*******************************************************************************
+ *
+ *      Autonegotiation functions. Used when TBI or Serdes is enabled.
+ *
+ ******************************************************************************/
+
+/*
+   Returns the autonegotiation advertisment word and the status (enabled/disabled) 
+   of the autonegotiation.
+ */
+vtss_rc vtss_pcs_autoneg_control_get( const vtss_port_no_t  port_num,
+		vtss_pcs_autoneg_control_t * const        control )
+{
+
+	ulong reg_value = 0;
+
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[port_num].chip_port;
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	reg_value = vtss_io_read( M2_BLK_MACS, ppn, M2_PCS_CTRL);
+
+
+	control->advertisement.fdx = ( (reg_value >> 5) & 0x1) ? TRUE : FALSE;
+	control->advertisement.hdx = ( (reg_value >> 6) & 0x1) ? TRUE : FALSE;
+
+	control->advertisement.symmetric_pause =   /* a.k.a. PAUSE (PS1) */
+		((reg_value >> 7) & 0x1) ? TRUE : FALSE;
+
+	control->advertisement.asymmetric_pause = /* a.k.a. ASM_DIR (PS2) */
+		((reg_value >> 8) & 0x1) ? TRUE : FALSE;
+
+	switch ( ( reg_value >> 12) & 0x3) {
+
+	case VTSS_1000BASEX_LINK_OK:
+		control->advertisement.remote_fault = VTSS_1000BASEX_LINK_OK;
+		break;
+	case VTSS_1000BASEX_OFFLINE:
+		control->advertisement.remote_fault = VTSS_1000BASEX_OFFLINE;
+		break;
+	case VTSS_1000BASEX_LINK_FAILURE:
+		control->advertisement.remote_fault = VTSS_1000BASEX_LINK_FAILURE;
+		break;
+	case VTSS_1000BASEX_AUTONEG_ERROR:
+		control->advertisement.remote_fault = VTSS_1000BASEX_AUTONEG_ERROR;
+		break;
+	}
+
+
+	control->advertisement.acknowledge = ((reg_value>>14) & 0x1)?TRUE:FALSE;
+
+	control->advertisement.next_page = ( ( reg_value>>15) & 0x1)?TRUE:FALSE;
+
+
+	control->enable = ( ( reg_value>>17) & 0x1)?TRUE:FALSE;
+
+	return VTSS_OK;
+}
+
+/*
+   Enables/disables autonegotiation in the PCS module and sets advertisment word
+ */
+vtss_rc vtss_pcs_autoneg_control_set( const vtss_port_no_t                      port_num,
+		const vtss_pcs_autoneg_control_t * const  control )
+{
+
+	ulong reg_value = 0, reg_mask = 0;
+
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[port_num].chip_port;
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	if ( control->enable == TRUE) {
+		/* Autonegotiation must be enabled and the advertisment word must be 
+		   written down */
+
+		if ( control->advertisement.fdx == TRUE) {
+			SET_BIT( reg_value, 5);
+		} 
+		SET_BIT(reg_mask, 5);
+
+		if ( control->advertisement.hdx) {
+			SET_BIT( reg_value, 6);
+		}
+		SET_BIT( reg_mask, 6);
+
+		if ( control->advertisement.symmetric_pause) { /* a.k.a. PAUSE (PS1) */
+			SET_BIT( reg_value, 7);
+		}
+		SET_BIT(reg_mask, 7);
+
+		if ( control->advertisement.asymmetric_pause) { /* a.k.a. ASM_DIR (PS2) */
+			SET_BIT( reg_value, 8);
+		}
+		SET_BIT( reg_mask, 8);
+
+		switch ( control->advertisement.remote_fault) {
+			case VTSS_1000BASEX_LINK_OK:
+				CLR_BIT( reg_value, 12);
+				CLR_BIT( reg_value, 13);
+				break;
+			case VTSS_1000BASEX_OFFLINE:
+				CLR_BIT( reg_value, 12);
+				SET_BIT( reg_value, 13);
+				break;
+			case VTSS_1000BASEX_LINK_FAILURE:
+				SET_BIT( reg_value, 12);
+				CLR_BIT( reg_value, 13);
+				break;
+			case VTSS_1000BASEX_AUTONEG_ERROR:
+				SET_BIT( reg_value, 12);
+				SET_BIT( reg_value, 13);
+				break;
+		}
+		SET_BIT( reg_mask, 12);
+		SET_BIT( reg_mask, 13);
+
+
+		if( control->advertisement.acknowledge == TRUE) {
+			SET_BIT( reg_value, 14);
+		}
+		SET_BIT( reg_mask, 14);
+
+		if ( control->advertisement.next_page == TRUE) {
+			SET_BIT( reg_value, 15);
+		}
+		SET_BIT( reg_mask, 15);
+
+
+		/* enable and restart autoneg bits */
+		SET_BIT( reg_value, 16);
+		SET_BIT( reg_value, 17);
+
+		SET_BIT( reg_mask, 16);
+		SET_BIT( reg_mask, 17);
+
+		/* and the write_strobe: used in Meigs2, harmless in VSC7323/7331 */
+		SET_BIT( reg_value, 31);
+		SET_BIT( reg_mask, 31);
+
+	} else {
+		/* restart autoneg bits must be set when disabling autoneg */
+		SET_BIT( reg_value, 16);
+		/* disable autoneg */
+		CLR_BIT( reg_value, 17);
+
+		SET_BIT( reg_mask, 16);
+		SET_BIT( reg_mask, 17);
+
+		/* and the write_strobe: used in Meigs2, harmless in VSC7323/7331 */
+		SET_BIT( reg_value, 31);
+		SET_BIT( reg_mask, 31);
+
+	}
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_PCS_CTRL, reg_value, reg_mask);
+
+	return VTSS_OK;
+}
+
+
+/*
+   Restarts autonegotiation, does not check whether autonegotiation is enabled
+ */
+vtss_rc vtss_pcs_autoneg_restart( const vtss_port_no_t  port_num )
+{
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[port_num].chip_port;
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+
+	/* Autoneg restart bit#16
+	   Write strobe bit#31 -- used in VSC7321, harmless in VSC7323/7331
+	 */
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_PCS_CTRL, 
+			0x8001<<16, 0x8001<<16);
+
+	return VTSS_OK;
+}
+
+
+/*  
+    Return the status of the current status of the link partner
+ */
+vtss_rc vtss_pcs_autoneg_status_get( const vtss_port_no_t port_num,
+		vtss_pcs_autoneg_status_t *paneg)
+{
+
+	ulong reg_value = 0;
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[port_num].chip_port;
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	reg_value = vtss_io_read( M2_BLK_MACS, ppn, M2_PCS_STATUS);
+
+
+	/*  Read XMIT_MODE: bits #18-19  */
+	switch ( ( reg_value >> 18) & 0x3) {
+
+		case VTSS_PCS_ANEG_STATE_IDLE:      /* Idle */
+			paneg->aneg_state = VTSS_PCS_ANEG_STATE_IDLE;
+			break;
+		case VTSS_PCS_ANEG_STATE_CONFIG:    /* Config (i.e. ANEG in progress) */
+			paneg->aneg_state = VTSS_PCS_ANEG_STATE_CONFIG;
+			break;
+		case VTSS_PCS_ANEG_STATE_DATA:      /* Data */
+			paneg->aneg_state = VTSS_PCS_ANEG_STATE_DATA;
+			break;
+		default:
+			paneg->aneg_state = VTSS_PCS_ANEG_STATE_NOTVALID;
+	}
+
+	/* ANC:  autoneg complete bit #16 */
+	paneg->aneg_complete = ( (reg_value >> 16) & 0x1) ? TRUE : FALSE;
+
+	paneg->partner_advertisement.fdx = ( (reg_value >> 5) & 0x1) ? TRUE : FALSE;
+	paneg->partner_advertisement.hdx = ( (reg_value >> 6) & 0x1) ? TRUE : FALSE;
+
+	paneg->partner_advertisement.symmetric_pause =   /* a.k.a. PAUSE (PS1) */
+		((reg_value >> 7) & 0x1) ? TRUE : FALSE;
+
+	paneg->partner_advertisement.asymmetric_pause = /* a.k.a. ASM_DIR (PS2) */
+		((reg_value >> 8) & 0x1) ? TRUE : FALSE;
+
+
+
+	switch ( ( reg_value >> 12) & 0x3) {
+
+		case VTSS_1000BASEX_LINK_OK:
+			paneg->partner_advertisement.remote_fault = VTSS_1000BASEX_LINK_OK;
+			break;
+		case VTSS_1000BASEX_OFFLINE:
+			paneg->partner_advertisement.remote_fault = VTSS_1000BASEX_OFFLINE;
+			break;
+		case VTSS_1000BASEX_LINK_FAILURE:
+			paneg->partner_advertisement.remote_fault = VTSS_1000BASEX_LINK_FAILURE;
+			break;
+		case VTSS_1000BASEX_AUTONEG_ERROR:
+			paneg->partner_advertisement.remote_fault = VTSS_1000BASEX_AUTONEG_ERROR;
+			break;
+	}
+
+
+	paneg->partner_advertisement.acknowledge = ((reg_value>>14) & 0x1)?TRUE:FALSE;
+
+	paneg->partner_advertisement.next_page = ( ( reg_value>>15) & 0x1)?TRUE:FALSE;
+
+	return VTSS_OK;
+}
+
+
+/* Returns more detailed status than vtss_pcs_autoneg_status_get */
+vtss_rc vtss_pcs_status_get( const vtss_port_no_t       port_num,
+		vtss_pcs_status_t * const  pstatus )
+{
+
+	ulong pcs_status = 0;
+	ulong pcs_ctrl = 0;
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[port_num].chip_port;
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	pcs_status = vtss_io_read( M2_BLK_MACS, ppn, M2_PCS_STATUS);
+	pcs_ctrl = vtss_io_read( M2_BLK_MACS, ppn, M2_PCS_CTRL);
+
+
+	/*  Read XMIT_MODE: bits #18-19  */
+	switch ( ( pcs_status >> 18) & 0x3) {
+
+		case VTSS_PCS_ANEG_STATE_IDLE:  /* Idle */
+			pstatus->autoneg.aneg_state = VTSS_PCS_ANEG_STATE_IDLE;
+			break;
+		case VTSS_PCS_ANEG_STATE_CONFIG:    /* Config (i.e. ANEG in progress) */
+			pstatus->autoneg.aneg_state = VTSS_PCS_ANEG_STATE_CONFIG;
+			break;
+		case VTSS_PCS_ANEG_STATE_DATA:       /* Data */
+			pstatus->autoneg.aneg_state = VTSS_PCS_ANEG_STATE_DATA;
+			break;
+		default:
+			pstatus->autoneg.aneg_state = VTSS_PCS_ANEG_STATE_NOTVALID;
+	}
+
+	/* ANC:  autoneg complete bit #16 */
+	pstatus->autoneg.aneg_complete = ( (pcs_status >> 16) & 0x1) ? TRUE : FALSE;
+
+	/* SHOW_LDC_TOP bit of the PCS_CTRL register (bit #25) selects how to 
+	   interpret bits 24..31 of the PCS_STATUS register */
+	if ( ( pcs_ctrl >> 25) & 0x1) { /* the link down counter is 8 bit long */
+
+		pstatus->show_ldc_top = TRUE;
+
+		pstatus->losync = FALSE;
+
+		pstatus->pcs_in_sync = FALSE;
+
+		/* link down counter is 8bit long */
+		pstatus->link_down_counter = (pcs_status >> 24) & 0xFF;
+
+	} else { /* the link down counter is 6 bit long */
+
+		pstatus->show_ldc_top = FALSE;;
+
+		pstatus->losync = 
+			((pcs_status >> 31) & 0x1) ? TRUE : FALSE;
+
+		pstatus->pcs_in_sync = 
+			((pcs_status >> 30) & 0x1) ? TRUE : FALSE;
+
+
+		/* link down counter is only 6 bits long */
+		pstatus->link_down_counter = (pcs_status >> 24) & 0x3F;
+
+	}
+
+
+	/* signal_detected indicates that there is light in the fiber; 
+	   require SD_EN in the PCS_CTRL register to be set */
+	pstatus->signal_detected = 
+		((pcs_status >> 23) & 0x1) ? TRUE : FALSE;
+
+
+	pstatus->jtp_lock = 
+		((pcs_status >> 22) & 0x1) ? TRUE : FALSE;
+
+	pstatus->jtp_error = 
+		((pcs_status >> 21) & 0x1) ? TRUE : FALSE;
+
+
+	/* link_status:  FALSE if link has been down since last status read */
+	pstatus->link_status_ok =
+		((pcs_status >> 20) & 0x1) ? TRUE : FALSE;
+
+
+
+
+	pstatus->autoneg.partner_advertisement.fdx = ( (pcs_status >> 5) & 0x1) ? TRUE : FALSE;
+	pstatus->autoneg.partner_advertisement.hdx = ( (pcs_status >> 6) & 0x1) ? TRUE : FALSE;
+
+	pstatus->autoneg.partner_advertisement.symmetric_pause =   /* a.k.a. PAUSE (PS1) */
+		((pcs_status >> 7) & 0x1) ? TRUE : FALSE;
+
+	pstatus->autoneg.partner_advertisement.asymmetric_pause = /* a.k.a. ASM_DIR (PS2) */
+		((pcs_status >> 8) & 0x1) ? TRUE : FALSE;
+
+
+
+	switch ( ( pcs_status >> 12) & 0x3) {
+
+		case VTSS_1000BASEX_LINK_OK:
+			pstatus->autoneg.partner_advertisement.remote_fault = VTSS_1000BASEX_LINK_OK;
+			break;
+		case VTSS_1000BASEX_OFFLINE:
+			pstatus->autoneg.partner_advertisement.remote_fault = VTSS_1000BASEX_OFFLINE;
+			break;
+		case VTSS_1000BASEX_LINK_FAILURE:
+			pstatus->autoneg.partner_advertisement.remote_fault = VTSS_1000BASEX_LINK_FAILURE;
+			break;
+		case VTSS_1000BASEX_AUTONEG_ERROR:
+			pstatus->autoneg.partner_advertisement.remote_fault = VTSS_1000BASEX_AUTONEG_ERROR;
+			break;
+	}
+
+
+	pstatus->autoneg.partner_advertisement.acknowledge = ((pcs_status>>14) & 0x1)?TRUE:FALSE;
+
+	pstatus->autoneg.partner_advertisement.next_page = ( ( pcs_status>>15) & 0x1)?TRUE:FALSE;
+
+	return VTSS_OK;
+}
+
+
+vtss_rc vtss_serdes_signal_detect_setup( const vtss_port_no_t port_num,
+		BOOL enable,
+		BOOL sd_polarity_high,
+		BOOL sd_source_extern)
+{
+
+	ulong reg = 0, mask = 0;
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[port_num].chip_port;
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+
+
+	if ( enable == TRUE) {
+
+		/* set Signal Detect source */
+		if ( sd_source_extern == TRUE)
+			SET_BIT( reg, 8);
+		SET_BIT( mask, 8);
+		vtss_io_writemasked( M2_BLK_MACS, ppn, M2_DEV_SETUP, reg, mask);
+		reg = mask = 0;
+
+		/* and now Polarity and Enable */
+		SET_BIT( reg, 22); /* Signal Detect Enable */
+
+		if ( sd_polarity_high == TRUE)
+			SET_BIT( reg, 23); /* Signal Detect Polarity */
+
+		SET_BIT( mask, 22);
+		SET_BIT( mask, 23);
+
+	} else {
+		/* Disable serdes Signal Detect */
+		SET_BIT( mask, 22);
+	}
+
+	/* write_strobe used in Meigs2, otherwise harmless */
+	SET_BIT( reg, 31);
+	SET_BIT( mask, 31);
+
+
+	vtss_io_writemasked( M2_BLK_MACS, ppn, M2_PCS_CTRL, reg, mask);
+
+
+
+	return VTSS_OK;
+
+}
+
+
+
+vtss_rc vtss_serdes_extern_signal_detect_status_get(const vtss_port_no_t port_num, 
+		BOOL *pstatus)
+{
+	ulong reg = 0;
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[port_num].chip_port;
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* right major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR: /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* single chip trunking */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+
+	reg = vtss_io_read( M2_BLK_MACS, ppn, M2_PCS_STATUS);
+
+	if ( (reg >> 23) & 0x1 ) { /* bit 23 is set */
+		*pstatus = TRUE;
+	} else {
+		*pstatus = FALSE;
+	}
+
+	return VTSS_OK;
+}
+
+
+/*****************************************************************************/
+/*                                                                           */
+/*        10G port setup                                                     */
+/*                                                                           */
+/*****************************************************************************/
+
+
+/*--       Setup  Funtions                            -----------------------*/
+
+
+/* Setup 10G port */
+vtss_rc vtss_10Gport_setup( vtss_port_no_t port_num, vtss_10Gport_setup_t* ps)
+{
+
+
+	ulong misc_reg_value = 0;
+	ulong reg_mask = 0;
+	ulong reg_value = 0;
+
+	ulong max_len_reg_value = 0;
+
+	ulong pause_reg_value = 0;
+
+	ulong denorm_reg = 0;
+
+	m2_header_t hdr;
+
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+
+
+	//  VTSS_N(("10G port setup."));
+	printk("10G port setup.\n");
+
+	/* check for appropriate major mode */
+	switch ( pvds->mmode) {
+		/* Suppported modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G:      /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK:
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:
+			break;
+
+			/* Undefined major mode */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+			/* Wrong mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G:    /* SPI4 <-> 10x1G */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+
+	if (VTSS_SPEED_10G != ps->interface_mode.speed) {
+		printk("10G port. Wrong speed: %d\n", ps->interface_mode.speed);
+		return VTSS_WRONG_PARAMETER;
+	}
+
+	if (VTSS_PORT_INTERFACE_XAUI != ps->interface_mode.interface_type) {
+		printk("10G port. Wrong interface type: %d\n", 
+					ps->interface_mode.interface_type);
+		return VTSS_WRONG_PARAMETER;
+	}
+
+	/* -------------------  MISC  ------------------------- */
+
+	/* Enable the 10G block */
+	SET_BIT( misc_reg_value, 1);
+	SET_BIT( misc_reg_value, 0);
+
+	if ( ps->vlan_aware)           { SET_BIT( misc_reg_value, 2); }
+	if ( ps->prm_hdr_insert)       { SET_BIT( misc_reg_value, 3); }
+	if ( ps->pace_mode)            { SET_BIT( misc_reg_value, 5); }
+	if ( ps->drop_in_range_error)  { SET_BIT( misc_reg_value, 6); }
+	if ( ps->drop_on_length_error) { SET_BIT( misc_reg_value, 7); }
+	if ( ps->sfd_check)            { SET_BIT( misc_reg_value, 8); }
+
+	/* It is recommended to set 3-bit LFS_MODE bitfield to 000b */
+	SET_BITS_MASKED( misc_reg_value, 0, (ulong)7<<9);
+	SET_BITS_MASKED( reg_mask, (ulong)7<<9, (ulong)7<<9);
+
+	if ( ps->ext_sop_check_enable) { SET_BIT( misc_reg_value, 13); }
+	if ( ps->ext_eop_check_enable) { SET_BIT( misc_reg_value, 14); }
+
+	/* Before writing the value down to the register, take the 10g block 
+	   out of reset */
+	CLR_BIT( misc_reg_value, 31);
+
+	vtss_io_writemasked( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_MISC_10G, 
+			misc_reg_value, 0XFFFFFFFF);
+
+
+	/* -------------------  DENORM  ------------------------- */
+
+	/* For this to work SPI4(when used) must be set to let bad frames 
+	   pass through */
+	switch ( ps->fcs_modify) {
+		case  VTSS_FCS_DO_NOTHING:
+			/* bits are cleared, do nothing */
+			break;
+		case VTSS_FCS_UPDATE:
+			SET_BIT( denorm_reg, 5);
+			/* bit #4 is cleared */
+			break;
+		case VTSS_FCS_ADD:
+			SET_BIT( denorm_reg, 4);
+			/* bit #5 is cleared */
+			break;
+	}
+
+	if( ps->norm_hdr_expect == TRUE) { SET_BIT(denorm_reg, 1); }
+	if( ps->prm_hdr_expect  == TRUE) { SET_BIT(denorm_reg, 0); }
+
+	/* Denormalizer register */
+	vtss_io_writemasked( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_DENORM, denorm_reg, 0x3f);
+
+
+	/* -------------------  Flowcontrol  ----------------------- */
+
+	if(ps->flowcontrol.obey || ps->flowcontrol.generate) {
+
+		/* Mac address will be written if flowcontrol setup is requested */
+		ulong mac_addr_low_reg = 
+			(ps->flowcontrol.smac.addr[3] << 16)| 
+			(ps->flowcontrol.smac.addr[4] <<  8)|
+			ps->flowcontrol.smac.addr[5];
+
+		ulong mac_addr_high_reg = 
+			(ps->flowcontrol.smac.addr[0] << 16)| 
+			(ps->flowcontrol.smac.addr[1] <<  8)|
+			ps->flowcontrol.smac.addr[2];
+
+		vtss_io_write( M2_BLK_MACS, M2_SUBBLK_MAC_10G, 
+				M2_MAC_HIGH_ADDR, mac_addr_high_reg);
+		vtss_io_write( M2_BLK_MACS, M2_SUBBLK_MAC_10G, 
+				M2_MAC_LOW_ADDR, mac_addr_low_reg);
+
+		if (ps->flowcontrol.obey) {
+			SET_BIT( pause_reg_value, 17);
+		}
+		if (ps->flowcontrol.generate) {
+			SET_BIT( pause_reg_value, 16);
+		}
+
+
+	}
+
+
+	if( ps->enable_tx_pause_xon_xoff == TRUE) {
+		SET_BIT( pause_reg_value, 18);
+	}
+
+	/*  TX pause value */
+	SET_BITS_MASKED( pause_reg_value, ps->tx_pause_value,
+			VTSS_PORT_10G_TX_PAUSE_MASK);
+	vtss_io_write( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_PAUSE, pause_reg_value);
+
+
+	/* maxframelength */
+	SET_BITS_MASKED( max_len_reg_value, ps->maxframelength, 
+			VTSS_MAX_FRAME_LENGTH_MASK);
+
+	vtss_io_write( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_MAX_LEN, max_len_reg_value);
+
+
+
+	/* -------------------  NORMALIZER  ------------------------- */
+	/* RxChainMode must be set in the system block */
+
+	/* 10G port always reads data from the FIFO (i.e. in egress direction) on 
+	   frame-interleaved basis, thus normalised header is needed */
+	/* Chip major mode must be defined at this point */
+	hdr.use_norm_hdr = TRUE;
+	hdr.use_prm_hdr = FALSE;
+	//VTSS_ASSERT( VTSS_OK == vtss_hdr_expect( TRUE, hdr));
+
+	reg_value = reg_mask =  0;
+	if ( ps->norm_hdr_insert == TRUE ) {
+		SET_BIT(reg_value, 1); /* NH bit */
+		/* NLE must be cleared */
+	} else {
+		/* witout normalized header NLE must be set */
+		SET_BIT(reg_value, 2);
+	}
+	SET_BIT(reg_mask, 1); /* NH bit */
+	SET_BIT(reg_mask, 2); /* NLE bit */
+
+	if ( ps->prm_hdr_insert == TRUE) {
+		SET_BIT( reg_value, 0);
+	}
+	SET_BIT( reg_mask, 0);
+
+	vtss_io_writemasked( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_NORMALIZER,
+			reg_value, reg_mask);
+
+
+	/* -------------------  XAUI  ------------------------- */
+
+
+	/* Power-up control */
+	vtss_io_writemasked( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_XAUI_CONF_B,
+			0x4, 0x7);
+
+
+	/* Reset the block */
+	vtss_io_writemasked( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_XAUI_CONF_A,
+			(ulong)1<<31, (ulong)1<<31);
+	vtss_io_writemasked( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_XAUI_CONF_A,
+			0, (ulong)1<<31);
+	vtss_io_writemasked( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_XAUI_CONF_A,
+			(ulong)1<<31, (ulong)1<<31);
+
+	return VTSS_OK;
+}
+
+
+/* 
+   Supplementary function: fills the structure referenced by the pointer 
+   with the default values for a given major_mode.
+ */
+vtss_rc vtss_10Gport_setup_get_default_values( vtss_10Gport_setup_t* psetup,
+		vtss_mac_major_mode_t major_mode)
+{
+	vtss_mac_t smac_addr = {{0,0,0,0,0,0}};
+
+	switch ( major_mode) {
+		/* Suppported modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G:      /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK:
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:
+			break;
+
+			/* Wrong mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G:    /* SPI4 <-> 10x1G */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+	psetup->interface_mode.interface_type = VTSS_PORT_INTERFACE_XAUI;
+	psetup->interface_mode.speed          = VTSS_SPEED_10G;
+
+
+	psetup->flowcontrol.obey     = TRUE;
+	psetup->flowcontrol.generate = TRUE;
+	psetup->flowcontrol.smac     = smac_addr;
+
+
+	psetup->enable_tx_pause_xon_xoff = TRUE;
+	psetup->tx_pause_value           = VTSS_PORT_10G_TX_PAUSE_VALUE;
+
+
+	psetup->maxframelength = VTSS_MAX_FRAME_LENGTH; /* Max frame length. */
+
+	psetup->vlan_aware = FALSE;
+	psetup->pace_mode = FALSE;
+	psetup->drop_on_length_error = FALSE;
+	psetup->drop_in_range_error = FALSE;
+
+	psetup->fcs_modify = VTSS_FCS_DO_NOTHING;
+
+	psetup->ext_eop_check_enable = FALSE;
+	psetup->ext_sop_check_enable = FALSE;
+
+
+
+	switch ( major_mode) {
+		/* Suppported modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G:      /* SPI4 <-> 1x10G */
+			psetup->norm_hdr_insert = FALSE;
+			psetup->prm_hdr_insert = FALSE;
+			psetup->norm_hdr_expect = FALSE;
+			psetup->prm_hdr_expect = FALSE;
+			psetup->sfd_check = TRUE;
+			break;
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:
+			psetup->norm_hdr_insert = FALSE;
+			psetup->prm_hdr_insert = FALSE;
+			psetup->norm_hdr_expect = TRUE;
+			psetup->prm_hdr_expect = FALSE;
+			psetup->sfd_check = TRUE;
+			break;
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK:
+			psetup->norm_hdr_insert = FALSE;
+			psetup->prm_hdr_insert = TRUE;
+			psetup->norm_hdr_expect = TRUE;
+			psetup->prm_hdr_expect = TRUE;
+			psetup->sfd_check = FALSE;
+			break;
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:
+			psetup->norm_hdr_insert = TRUE;
+			psetup->prm_hdr_insert = FALSE;
+			psetup->norm_hdr_expect = TRUE;
+			psetup->prm_hdr_expect = FALSE;
+			psetup->sfd_check = TRUE;
+			break;
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:
+			psetup->norm_hdr_insert = TRUE;
+			psetup->prm_hdr_insert = TRUE;
+			psetup->norm_hdr_expect = TRUE;
+			psetup->prm_hdr_expect = TRUE;
+			psetup->sfd_check = FALSE;
+			break;
+
+			/* Wrong mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G:    /* SPI4 <-> 10x1G */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+	return VTSS_OK;
+
+}
+
+
+/*----------------  Run-time funcitons  ---------------------------------------*/
+/* Enable/disable rx, tx or both in a 10G port */
+vtss_rc vtss_10Gport_set_enable( vtss_port_no_t port_num, 
+		BOOL rx_en, BOOL tx_en)
+{
+
+	ulong mode_cfg_reg = 0;
+	ulong mode_cfg_reg_mask = 0x3; /* two bits are affected */
+
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+
+	/* check for appropriate major mode */
+	switch ( pvds->mmode) {
+		/* Suppported modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G:      /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK:
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:
+			break;
+
+			/* Undefined major mode */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+			/* Wrong mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G:    /* SPI4 <-> 10x1G */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+	if(rx_en) {
+		SET_BIT(mode_cfg_reg, 1);
+	}
+	if(tx_en) {
+		SET_BIT(mode_cfg_reg, 0);
+	}
+
+
+	vtss_io_writemasked( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_MISC_10G, 
+			mode_cfg_reg, mode_cfg_reg_mask);
+
+
+	return VTSS_OK;
+}
+
+
+/* Set CRC adding/updating mode */
+vtss_rc vtss_10Gport_fcs_modify( vtss_port_no_t port_num, vtss_fcs_modify_t mc)
+{
+
+	ulong denorm_reg = 0;
+	ulong denorm_reg_mask = (1<<5)|(1<<4);
+
+	/* Check for the right major mode */
+	/* TBD */
+
+	/* Meigs2 has two independent bits: UPDATE and ADD, which should always have
+	   opposite values */
+	switch ( mc) {
+		case  VTSS_FCS_DO_NOTHING:
+			break;
+		case VTSS_FCS_UPDATE:
+			SET_BIT( denorm_reg, 5);
+			CLR_BIT( denorm_reg, 4);
+			break;
+		case VTSS_FCS_ADD:
+			SET_BIT( denorm_reg, 4);
+			CLR_BIT( denorm_reg, 5);
+			break;
+	}
+
+	vtss_io_writemasked( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_DENORM, 
+			denorm_reg, denorm_reg_mask);
+
+
+	return VTSS_OK;
+
+}
+
+
+/* Allow pause frames pass through the device. By default 10G block
+   prevents propagation of pause frames through the device.
+ */
+vtss_rc vtss_10Gport_forward_pause_frames( vtss_port_no_t port_num, BOOL allow)
+{
+
+	/*!!! DROP_PAUSE bit (bit #5) is different from its counterpart in 1G ports*/
+	ulong norm_reg = (allow)?0:(1<<5);
+	ulong norm_reg_mask = 1<<5;
+
+	vtss_io_writemasked( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_NORMALIZER, 
+			norm_reg, norm_reg_mask);
+	return VTSS_OK;
+}
+
+/*
+   obey -- obeys pause frames from external Eth client 
+   generate -- generate pause frames/backpressure upon request from the 
+   destination (FIFO or the host interface)
+
+   If fc_obey AND fc_generate are set to FALSE, then flow control is disabled
+
+
+ */
+vtss_rc vtss_10Gport_flow_control_mode( vtss_port_no_t port_num, 
+		BOOL fc_obey, 
+		BOOL fc_generate)
+{
+	ulong pause_reg_value = 0;
+	ulong pause_reg_mask = ((ulong)1<<16)|(1<<17);
+
+
+
+	if (fc_obey) {
+		SET_BIT( pause_reg_value, 17);
+	} 
+
+	if (fc_generate) {
+		SET_BIT( pause_reg_value, 16);
+	}
+
+	vtss_io_writemasked( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_PAUSE, 
+			pause_reg_value, pause_reg_mask);
+
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+
+  Function   vtss_10Gport_signal_detect
+
+  ================================================================================
+
+Description:
+Once a 10G Base-X optical module is connected to the XAUI port,
+this function can use to drive an GPIO connected LED to visualize 
+signal detection/link status. The CPU must poll this function.
+
+Syntax
+
+Arguments: None
+
+Return code: TRUE/FALSE
+
+ *******************************************************************************/
+BOOL vtss_10Gport_signal_detect(void)
+{
+	ulong mac_tx_sticky_value = 0;
+
+	/* Clear sticky-bits in MAC_TX_STICKY */
+	vtss_io_write( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_MAC_TX_STICKY, 0x1f);
+	mac_tx_sticky_value = vtss_io_read( M2_BLK_MACS, M2_SUBBLK_MAC_10G, M2_MAC_TX_STICKY);
+
+	return (mac_tx_sticky_value & ((ulong)1 << 4))?(FALSE):(TRUE);
+}
+
+
+/*******************************************************************************
+
+  Function   
+
+  ================================================================================
+
+Description:
+Works in the direction from MAC to FIFO.
+
+Syntax
+
+Arguments:
+hdr   normalized header/preamble header structure
+
+Return code:
+
+ *******************************************************************************/
+static void vtss_port10G_header_insert( BOOL enable, const m2_header_t hdr)
+{
+	ulong reg = 0, reg_mask = 0;
+
+	if ( hdr.use_norm_hdr) {
+
+		if( enable == TRUE) {
+			SET_BIT( reg, 1);
+			/* Normalized header requires the NLE bit set */
+			SET_BIT( reg, 2);
+		}
+
+		SET_BIT( reg_mask,1);
+		SET_BIT( reg_mask,2);
+	}
+
+
+	if ( hdr.use_prm_hdr) {
+		if ( enable == TRUE)
+			SET_BIT( reg, 0);
+
+		SET_BIT( reg_mask, 0);
+	}
+
+
+	/* If any changes, write to the register */
+	if( reg_mask) {
+		vtss_io_writemasked( M2_BLK_MACS, M2_PHYS_PORT_10G, M2_NORMALIZER, 
+				reg, reg_mask);
+	}
+
+	return;
+}
+
+/*******************************************************************************
+
+  Function   
+
+  ================================================================================
+
+Description:
+FIFO -> MAC
+
+Syntax
+
+
+
+Arguments:
+ppn   physical port (port-on-chip)
+hdr   normalized header/preamble header structure
+
+
+Return code:
+
+ *******************************************************************************/
+#if 0 
+static void vtss_port10G_header_expect( BOOL enable, const m2_header_t hdr)
+{
+	ulong reg = 0, reg_mask = 0;
+
+	if ( hdr.use_norm_hdr) {
+		if (enable == TRUE) {
+			SET_BIT( reg,1);
+		}
+
+		SET_BIT( reg_mask,1);
+	}
+
+	if ( hdr.use_prm_hdr) {
+		if (hdr.use_prm_hdr == TRUE)
+			SET_BIT( reg, 0);
+
+		SET_BIT( reg_mask, 0);
+	}
+
+	if( reg_mask != 0) {
+		vtss_io_writemasked( M2_BLK_MACS, M2_PHYS_PORT_10G, M2_DENORM, 
+				reg, reg_mask);
+	}
+
+	return;
+}
+#endif
+
+/******************************************************************************
+ *                                                                            *
+ *       SPI4.2 Setup                                                         *
+ *                                                                            *
+ ******************************************************************************/
+
+
+/******************************************************************************
+ *
+ * Description: Set up the SPI4.2 block 
+ *
+ * \param:      ps       Pointer to a structure which determines configuration
+ *
+ * \return:     VTSS_OK  Operation completed successfully.
+ *              VTSS_WRONG_MAJOR_MODE
+ *              VTSS_MAJOR_MODE_NOT_SET
+ *              VTSS_WRONG_PARAMETER
+ *
+ **************************************************************************kbp*/
+vtss_rc vtss_spi4_setup( vtss_spi4_setup_t* ps)
+{
+	ulong reg  = 0;
+	ulong mask = 0;
+	ulong active_ports = 0;
+	ulong pll_clk_speed = 0;
+	int i;
+	m2_header_t hdr;
+	BOOL hdr_present;
+
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	switch ( pvds->mmode) {
+		/* valid major modes */
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G:  /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK: /* */
+			break;
+
+			/* Error - major mode undefined */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+			/* Error - wrong major mode */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:  /* Single Chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK: /* Single Chip trunking */
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+
+	/* Burst size from ingress FIFO -> SPI4 */
+	reg = ps->burst_size & 0xF;
+
+	/* Selection between burst or frame interleaved scheduling
+	   is done in the ingress FIFO: CM bit in ing_ctrl_reg */
+	hdr.use_norm_hdr = TRUE; hdr.use_prm_hdr = FALSE;
+	switch ( ps->sch_mode) {
+#if !defined MEIGS2 && !defined VSC7321
+		case VTSS_SPI4_BURST_MODE_WITH_HEADER:
+			vtss_hdr_insert( TRUE, hdr);
+			SET_BIT( reg, 4); /* set CM bit */
+			break;
+#endif
+		case VTSS_SPI4_BURST_MODE:
+			SET_BIT( reg, 4); /* set CM bit */
+			break;
+		case VTSS_SPI4_FRAME_MODE:
+			CLR_BIT( reg, 4); /* clear CM bit */
+			vtss_hdr_insert( TRUE, hdr);
+			break;
+		default:
+			return VTSS_WRONG_PARAMETER;
+	}
+	/* Write to ingress fifo control register */
+	vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_ING_CONTROL, reg, 0x1F);
+
+
+	/* Set-up Header Stripper located before Ingress SPI4.2 */
+	if( ps->norm_hdr_strip == FALSE) {
+		vtss_io_writemasked( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_IFACE_MODE, 0, (ulong)1<<4);
+	} else {
+		vtss_io_writemasked( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_IFACE_MODE, (ulong)1<<4, (ulong)1<<4);
+	}
+
+
+	/* Set-up FCS/CRC-32 Checker located after Egress SPI4.2 */
+	if ( ps->norm_hdr_expect != FALSE) {
+		hdr_present = TRUE;
+		if ( ps->prm_hdr_expect != FALSE) {
+			reg = 0x0; /* hdr_size = 16 bytes */
+		} else {
+			reg = 0x9; /* hdr_size = 9 bytes */
+		}
+	} else {
+		if ( ps->prm_hdr_expect != FALSE) {
+			hdr_present = TRUE;
+			reg = 0x7; /* hdr_size = 7 bytes */
+		} else {
+			hdr_present = FALSE; /* no header */
+			reg = 0x0; /* hdr_size = 0 bytes */
+		}
+	}
+	vtss_io_writemasked( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_CRC_CFG,
+			((hdr_present)?((ulong)1<<4):0) | reg, 0x1F);
+
+
+	/******************    SPI4  MISC register  setup    ************************/
+
+	/* SPI4 output frequency 390(default), 312, 195, 156 MHz */
+	reg = 0x1; mask = 0x11;
+	switch ( ps->spi4_output_freq) {
+		case VTSS_SPI4_OUTPUT_FREQ_390MHZ:
+			SET_BIT( pll_clk_speed, 0);
+			break;
+#if defined MEIGS2 || defined VSC7321
+		case VTSS_SPI4_OUTPUT_FREQ_312MHZ:
+			break;
+		case VTSS_SPI4_OUTPUT_FREQ_156MHZ:
+			SET_BIT( reg, 4);
+			break;
+#endif
+		case VTSS_SPI4_OUTPUT_FREQ_195MHZ:
+			SET_BIT( pll_clk_speed, 0);
+			SET_BIT( reg, 4);
+			break;
+		default:
+			return VTSS_WRONG_PARAMETER;
+	}
+	/* Select SPI4 clock source from either SerDes or XAUI PLL */
+	vtss_io_writemasked( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_PLL_CLK_SPEED, 
+			pll_clk_speed, 0x1);
+
+
+	/* 1. Power-up CML logic
+	   2. Release reset on CML logic and set-up RQC
+
+	   3. Set-up rest
+	   Always assert bit 18, SD; spi4_swap_bytes in order to be spi4 compliant
+	   Always de-assert bits 29-31: SPI clock reset bits */
+
+	/* Power-up CML logic */
+	vtss_io_writemasked( M2_BLK_SPI4, M2_SUBBLK_NONE, M2_SPI4_MISC, reg, mask);
+
+	/* Set-up RQC. Board dependent. */
+	if ( ps->spi4_data_clock_skew != FALSE)  { SET_BIT( reg, 2); }
+	SET_BIT( mask, 2);
+
+	/* Release reset on CML logic */
+	SET_BIT( reg, 3); SET_BIT( mask, 3);
+
+	/* Release reset on CML logic and set-up RQC */
+	vtss_io_writemasked( M2_BLK_SPI4, M2_SUBBLK_NONE, M2_SPI4_MISC, reg, mask);
+
+	/* Bit SD. Swap bytes in order to be spi4 compliant */
+	SET_BIT( reg, 18); SET_BIT( mask, 18);
+
+	/* Enable all clocks */
+	SET_BITS_MASKED( mask, (ulong)7<<29, (ulong)7<<29);
+
+	/* Bit WI. Board dependent. */
+	if ( ps->spi4_swap_ingress_data != FALSE) { SET_BIT( reg, 9); }
+	SET_BIT( mask, 9);
+
+	/* Bit WE. Board dependent. */
+	if ( ps->spi4_swap_egress_data != FALSE) { SET_BIT( reg, 8); }
+	SET_BIT( mask, 8);
+
+	vtss_io_writemasked( M2_BLK_SPI4, M2_SUBBLK_NONE, M2_SPI4_MISC, reg, mask);
+
+
+	/******************    SPI4_ING_SETUP0 register setup   *********************/
+
+	/* Calendar length is defined by number of ports. Calculate active ports */
+	for(i=0; i<VTSS_PORT_ARRAY_SIZE; i++) {
+		ulong ppn = vtss_logical_ports[i].chip_port;
+		if ( ppn != -1) {
+			SET_BIT(active_ports, ppn);
+		}
+	}
+	/* Setup active ports, kbp_test: active_ports = 0x3FF;*/
+	reg = active_ports & 0x3FF; mask = 0x3FF;
+
+	/* SPI4_calendar_order */
+	if ( ps->spi4_calendar_order_ascending == FALSE) { SET_BIT( reg, 10); }
+	SET_BIT( mask, 10);
+
+	/* SPI4_calendar_m */
+	SET_BITS_MASKED( reg, (ulong)(ps->spi4_calendar_m)<<12, 0xF<<12);
+	SET_BITS_MASKED( mask, 0xF<<12, 0xF<<12);
+
+	/* write to spi4_ingress_setup0_reg register */
+	vtss_io_writemasked( M2_BLK_SPI4, M2_SUBBLK_NONE, M2_SPI4_ING_SETUP0, reg, mask);
+
+
+	/******************    SPI4_ING_SETUP1 register setup   *********************/
+
+	/* kbp: Where do we set-up this ?
+#if defined MEIGS2 || defined VSC7321
+ps->tm = VTSS_SPI4_TRAINING_OFF;
+#else
+ps->tm = VTSS_SPI4_TRAINING_AUTO;
+#endif
+	 */
+
+	/* Parameters of the training mode (only in ingress direction) */
+	vtss_io_write( M2_BLK_SPI4, M2_SUBBLK_NONE, M2_SPI4_ING_SETUP1,
+			(ps->alpha<<16) | (ps->tsperiod));
+
+
+	/******************    SPI4_ING_SETUP2 register setup   *********************/
+
+	vtss_io_writemasked( M2_BLK_SPI4, M2_SUBBLK_NONE, M2_SPI4_ING_SETUP2,
+			(ps->maxburst2<<24) | (ps->maxburst1<<16) | ps->burst_size, 
+			0xFFFF000F);
+
+
+	/******************    SPI4_EGR_SETUP0 register setup   *********************/
+
+	/* Setup active ports */
+	reg = active_ports & 0x3FF; mask = 0x3FF;
+
+	/* Shift status clock output. Board dependent. */
+	if ( ps->spi4_status_clock_skew != FALSE) { SET_BIT( reg, 18); }
+	SET_BIT( mask, 18);
+
+	/* SPI4_calendar_order */
+	if ( ps->spi4_calendar_order_ascending == FALSE) { SET_BIT( reg, 10); }
+	SET_BIT( mask, 10);
+
+	/* SPI4_calendar_m */
+	SET_BITS_MASKED( reg, (ulong)(ps->spi4_calendar_m)<<12, 0xF<<12);
+	SET_BITS_MASKED( mask, 0xF<<12, 0xF<<12);
+
+	/* write to spi4_egress_setup0_reg register. */
+	vtss_io_writemasked( M2_BLK_SPI4, M2_SUBBLK_NONE, M2_SPI4_EGR_SETUP0, reg, mask);
+
+
+	return VTSS_OK;
+}
+
+
+/******************************************************************************
+ *
+ * Description: Configures a user provided structure with default values for
+ *              the selected major mode.
+ *
+ * \param:      ps       Pointer to a structure which determines configuration
+ *              mode     Major mode
+ *
+ * \return:     VTSS_OK  Operation completed successfully.
+ *              VTSS_MAJOR_MODE_NOT_SET
+ *
+ **************************************************************************kbp*/
+vtss_rc vtss_spi4_setup_get_default_values( vtss_spi4_setup_t* ps, 
+		vtss_mac_major_mode_t mode)
+{
+
+	/* By default in the ingress direction SPI4.2 runs in burst interleaved mode*/
+	ps->sch_mode   = VTSS_SPI4_BURST_MODE;
+	ps->burst_size = VTSS_SPI4_BURST_SIZE;
+	ps->maxburst1  = VTSS_SPI4_MAX_BURST_1;
+	ps->maxburst2  = VTSS_SPI4_MAX_BURST_2;
+
+
+	/* Parameters of the training mode (only in ingress direction) */
+#if defined MEIGS2 || defined VSC7321
+	ps->tm = VTSS_SPI4_TRAINING_OFF;
+#else
+	ps->tm = VTSS_SPI4_TRAINING_AUTO;
+#endif
+	ps->alpha    = 1;
+	ps->tsperiod = 0;
+
+	/* spi4 output frequency: 390(default), 312, 195, 156 MHz */
+	ps->spi4_output_freq = VTSS_SPI4_OUTPUT_FREQ_390MHZ;
+
+	/* For the description of the following four elements refer to the desription 
+	   of the SPI4 misc register in the datasheet */
+	ps->spi4_swap_ingress_data = FALSE;  /* Board dependent */ /* Bit WI, SPI4 MISC reg*/
+	ps->spi4_swap_egress_data  = FALSE;  /* Board dependent */ /* Bit WE, SPI4 MISC reg*/
+	ps->spi4_data_clock_skew   = FALSE;  /* Board dependent */
+	ps->spi4_status_clock_skew = FALSE;  /* Board dependent */
+
+	/* calendar length is defined by number of ports */
+	ps->spi4_calendar_order_ascending = TRUE;
+	ps->spi4_calendar_m = 1;
+
+	/* normalized and preamble headers */
+	/* ingress direction: strip the norm header before sending it over SPI4 */
+	/* if normalization is not used (i.e there is no header to strip) this 
+	   parameter must be set to FALSE */
+	ps->norm_hdr_strip = FALSE;
+
+
+	/* egress direction: expect/do not expect headers  */
+	switch (mode) {
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G:  /* SPI4 <-> 10x1G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G: /* SPI4 <-> 1x10G */
+			ps->prm_hdr_expect = FALSE;
+			ps->norm_hdr_expect = FALSE;
+			break;
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+			ps->prm_hdr_expect = FALSE;
+			ps->norm_hdr_expect = TRUE;
+			break;
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK: /* */
+			ps->prm_hdr_expect = TRUE;
+			ps->norm_hdr_expect = TRUE;
+			break;
+		default:
+			/* VTSS_MAC_MAJOR_MODE_10G_1G_AGGR  - Single Chip aggr */
+			/* VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK - Single Chip trunking */
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+
+  Function  vtss_spi4_fcs_check_enable()
+  ================================================================================
+
+Description:
+The function turns on/off FCS check of Ethernet frames arriving from the 
+host interface. This is done for all channels simultaneously.
+
+
+NOTE. FCS check in the SPI4 block must be OFF, if FCS will be modified
+(added/updated) in Ethernet port(s) in the egress direction
+
+Syntax
+vtss_rc vtss_spi4_fcs_check_enable( BOOL check_fcs);
+
+Arguments:
+check_fcs    TRUE  -- turns FCS check ON
+FALSE -- turns FCS check OFF
+
+Return code:
+VTSS_OK   if operation completed successfully
+
+ *******************************************************************************/
+vtss_rc vtss_spi4_fcs_check_enable( BOOL check_fcs)
+{
+	ulong fcs = 0;
+
+	if (check_fcs) {
+		/* CLR_BIT(fcs,5); Already cleared */
+	} else {
+		/*ignore fcs check*/
+		SET_BIT(fcs,5);
+	}
+
+	vtss_io_writemasked(M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_CRC_CFG,
+			fcs, 1<<5);
+
+	return VTSS_OK;
+}
+
+
+
+
+/*******************************************************************************
+
+  Function  vtss_spi4_keep_norm_header()
+  ================================================================================
+
+Description:
+The function controls whether to strip the normalised header or to keep it.
+Usually the normalised header is stripped before the frame is sent over 
+SPI4. However, if the remove receiver can use information in the header, 
+keeping it may be an advantage.
+
+
+NOTE. Works in ingress direction
+
+Syntax
+vtss_rc vtss_spi4_keep_norm_header( BOOL keep);
+
+Arguments:
+keep     TRUE  -- the noramlised header is not stripped
+FALSE -- the noramlised header is stripped (Default)
+
+Return code:
+VTSS_OK   if operation completed successfully
+
+ *******************************************************************************/
+vtss_rc vtss_spi4_keep_norm_header( BOOL keep)
+{
+	ulong reg_value = 0, reg_mask = 0;
+
+
+	if ( keep == TRUE)
+		SET_BIT( reg_value, 4);
+
+	SET_BIT( reg_mask, 4);
+
+	vtss_io_writemasked( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_IFACE_MODE, 
+			reg_value, reg_mask);
+
+	return VTSS_OK;
+}
+
+
+/******************************************************************************/
+/***        Flow Control Configuration        *********************************/
+/******************************************************************************/
+
+/* 
+
+   transparent off -- filling of the FIFO causes generation of pause frames
+   transparent on  -- destination (host i/f), not FIFO, requests pause frames
+
+Note:
+
+ */
+/*******************************************************************************
+
+  Function 
+  ================================================================================
+
+Description:
+Function vtss_device_transparent_flow_control_mode() selects FIFO flow 
+control mode 
+
+NOTE: 
+This mode is enabled for all 10/100/1000 Eth ports simultaneously.
+This functions does not set RX_PAUSE or TX_PAUSE bits in 1G port blocks,
+the user need to do it after calling this function.
+
+
+Syntax
+vtss_rc vtss_device_transparent_flow_control_mode( BOOL ingress_enable,
+BOOL egress_enable);
+
+
+Arguments:
+ingress_enable      when set to TRUE, SPI4.2 flow control signals will 
+cause generation of Ethernet flow control frames
+egress_enable       when set to TRUE, Ethernet flow control frames will
+translate to SPI4.2 flow control signals
+
+Return code:
+VTSS_OK   if operation completed successfully
+
+ *******************************************************************************/
+vtss_rc vtss_device_transparent_flow_control_mode( BOOL ingress_enable,
+		BOOL egress_enable)
+{
+	ulong gress_ctrl_reg = 0;
+	ulong gress = M2_SUBBLK_INGRESS;
+
+
+	if (ingress_enable) {
+		SET_BIT( gress_ctrl_reg, 11); /* IPT bit */
+		SET_BIT( gress_ctrl_reg, 12); /* IGI bit */
+	} 
+	vtss_io_writemasked(M2_BLK_FIFO, gress, M2_ING_CONTROL,
+			gress_ctrl_reg, (1<<11)|(1<<12));
+
+
+	gress_ctrl_reg = 0;
+	gress = M2_SUBBLK_EGRESS;
+
+	if (egress_enable) {
+		/* In egress direction use the MFE bit, not IPT/IGI */
+		SET_BIT( gress_ctrl_reg, 15);
+	}
+	vtss_io_writemasked(M2_BLK_FIFO, gress, M2_EGR_CONTROL,
+			gress_ctrl_reg, 1<<15);
+
+	/* Remember to set RX_PAUSE_EN, TX_PAUSE_EN or PAUSE_EN bits in the PAUSE_CFG 
+	   register of 1G ports */
+
+
+	return VTSS_OK;
+}
+
+
+
+
+/******************************************************************************/
+/***        FIFO Configuration                       **************************/
+/******************************************************************************/
+
+
+/*-----------------  FIFO setup funcitons   ----------------------------------*/
+
+
+/*******************************************************************************
+
+  Function vtss_fifo_setup()
+  ================================================================================
+
+Description:
+Initializes the FIFO block based on the information in the provided 
+structures. If the pointer to the structure is set to NULL, the corresponding
+FIFO will not be initialized (it will be left in its current state).
+
+The function must be called after start-up and may be called at run-
+time to reconfigure the FIFO. 
+
+NOTE: port mapping table must be initialized.
+
+
+Syntax
+vtss_rc vtss_fifo_setup( vtss_fifo_setup_t *ps_ingress, 
+vtss_fifo_setup_t *ps_egress)
+
+Arguments:
+ps_ingress   pointer to a structure for the ingress fifo
+ps_egress   pointer to a structure for the egress fifo
+
+Return code:
+VTSS_OK   if operation completed successfully
+VTSS_MAJOR_MODE_NOT_SET
+
+ *******************************************************************************/
+
+vtss_rc vtss_fifo_setup( vtss_fifo_setup_t *ps_ingress, 
+		vtss_fifo_setup_t *ps_egress)
+{
+	int i, ppn;
+	ulong reg, mask;
+
+	/* Only one global device per API is currently supported */
+	vtss_device_setup_t *pvds = pdevice;
+	if ( pvds->mmode == VTSS_MAC_MAJOR_MODE_UNDEFINED) { return VTSS_MAJOR_MODE_NOT_SET; }
+
+	for ( i=1; i<=VTSS_PORTS_1G; i++) {
+
+		ppn = vtss_logical_ports[i].chip_port;
+		//    VTSS_N(("FIFO setup: log port#%d, phys port #%d", i, ppn));
+		//printk("FIFO setup: log port#%d, phys port #%d\n", i, ppn);
+		if( ppn < 0 ) { continue; }
+
+		/* Clear pointer mode when changing top/bottom */
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_INGRESS, 
+				M2_TEST + ppn, M2_TEST_FIFO_CLR, 0xF);
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_EGRESS, 
+				M2_TEST + ppn, M2_TEST_FIFO_CLR, 0xF);
+
+		/* TOP and BOTTOM values */
+		vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_TOP_BOTTOM + ppn, 
+				(ulong)((ps_ingress->fifo_port_area[i].top<<16) | 
+					ps_ingress->fifo_port_area[i].bottom));
+
+		vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_TOP_BOTTOM + ppn, 
+				(ulong)((ps_egress->fifo_port_area[i].top<<16) | 
+					ps_egress->fifo_port_area[i].bottom));
+
+		/* Watermarks */
+		vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_HIGH_LOW_WM + ppn, 
+			(ulong)((ps_ingress->fifo_port_wm[i].low_watermark<<16) | 
+					ps_ingress->fifo_port_wm[i].high_watermark));
+
+		vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_HIGH_LOW_WM + ppn, 
+			(ulong)((ps_egress->fifo_port_wm[i].low_watermark<<16) | 
+				ps_egress->fifo_port_wm[i].high_watermark));
+
+		/* Threshold, if cut-through mode enabled */
+		vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_CT_THRHLD + ppn, 
+				(ulong)((ps_ingress->thrhld[i].cut_through_enable)?
+					ps_ingress->thrhld[i].threshold_value:0));
+
+		vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_CT_THRHLD + ppn, 
+				(ulong)((ps_egress->thrhld[i].cut_through_enable)?
+					ps_egress->thrhld[i].threshold_value:0));
+
+		/* Enable FIFO again */
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_INGRESS, 
+				M2_TEST + ppn, M2_TEST_FIFO_NORMAL, 0xF);
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_EGRESS, 
+				M2_TEST + ppn, M2_TEST_FIFO_NORMAL, 0xF);
+	}
+
+	/* Ageing */
+	vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_AGE_INC,
+		 (ps_ingress->ageing.enable)? ps_ingress->ageing.interval:0);
+	vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_AGE_INC, 
+			(ps_egress->ageing.enable)? ps_egress->ageing.interval:0);
+
+	/* --- Ingress FIFO control register setup (major mode dependent) --- */
+	reg = 0;
+	if( ps_ingress->prm_hdr_used != FALSE) { SET_BIT( reg, 9); }
+
+	if( ps_ingress->norm_hdr_used != FALSE) {
+		SET_BIT( reg, 8);
+		/* Ingress FIFO gets data only from MACs thus bit 
+		   LE must always be set when the normalized header is used */
+		SET_BIT( reg, 13);
+	}
+
+	/* OUT_PORT_OFFSET */
+	reg  |= (ps_ingress->output_port_offset<<28) & 0xF0000000;
+
+	/* IN_PORT_OFFSET */
+	reg  |= (ps_ingress->input_port_offset<<24) & 0x0F000000;
+
+	/* Single Channel, M10G mode */
+	if (pvds->mmode == VTSS_MAC_MAJOR_MODE_SPI4_10G){ SET_BIT( reg, 5); }
+
+	/* Ingress FIFO by default is always set to run in burst-interleaved mode */
+	SET_BIT( reg, 4);
+
+	/* MUX bits, SS bit and burst size */
+	if ( (pvds->mmode == VTSS_MAC_MAJOR_MODE_10G_1G_AGGR) ||
+			(pvds->mmode == VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK)) {
+		/* if Single Chip aggr or single chip trunking */
+		SET_BIT( reg, 16);
+		SET_BIT( reg, 7);
+		/* burst size towards 1G ports */
+		SET_BITS_MASKED( reg, 
+			VTSS_FIFO_DEFAULT_BURST_SIZE_TOWARDS_1G_PORT, 0xF);
+	} else {
+		/* burst size towards SPI4.2 */
+		SET_BITS_MASKED( reg, 
+			VTSS_FIFO_DEFAULT_BURST_SIZE_TOWARDS_SPI4_2, 0xF); 
+	}
+
+	/* Enable the FIFO */
+	CLR_BIT( reg, 6);
+
+	mask = 0xFF0323FF;
+	vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_INGRESS, 
+		M2_ING_CONTROL, reg, mask);
+
+
+	/* --- Egress FIFO control register setup (major mode dependent) --- */
+	reg = 0;
+	if( ps_egress->prm_hdr_used != FALSE) { SET_BIT( reg, 9); }
+
+	if( ps_egress->norm_hdr_used != FALSE) {
+		SET_BIT( reg, 8);
+		/* Single Chip aggr o trunking */
+		if( ( pvds->mmode == VTSS_MAC_MAJOR_MODE_10G_1G_AGGR) || 
+			( pvds->mmode == VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK)) {
+			/* Receiving data from 1G MACs in SMES mode */
+			SET_BIT( reg, 13);
+		} else {
+			/* Receiving data from SPI4.2 always SME mode */
+			CLR_BIT( reg, 13);
+		}
+	}
+
+	/* OUT_PORT_OFFSET */
+	reg  |= (ps_egress->output_port_offset<<28) & 0xF0000000;
+
+	/* IN_PORT_OFFSET */
+	reg  |= (ps_egress->input_port_offset<<24) & 0x0F000000;
+
+	switch (pvds->mmode) {
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G:       /* SPI4 <-> 1x10G */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK: /* */
+			CLR_BIT( reg, 17);
+			CLR_BIT( reg, 16); /* MUX bits */
+			CLR_BIT( reg, 7); /* SS bit */
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G:        /* SPI4 <-> 10x1G */
+			CLR_BIT( reg, 17);
+			SET_BIT( reg, 16); /* MUX bits */
+			SET_BIT( reg, 7); /* SS bit */
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:    /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK:   /* single chip trunking */
+			SET_BIT( reg, 17);
+			CLR_BIT( reg, 16); /* MUX bits */
+			CLR_BIT( reg, 7); /* SS bit */
+			break;
+
+		default:
+			break;
+	}
+
+	/* Activate the FIFO */
+	CLR_BIT( reg, 6);
+
+	/* Frame-, burst- interleaving and burst size */
+	switch (pvds->mmode) {
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G:  /* Single Channel, M10G mode */
+			/* Egress FIFO sends data to 10G MAC from onei
+			 channel burst-interleaved is fine */
+			SET_BIT( reg, 4);
+			SET_BIT( reg, 5);
+			SET_BITS_MASKED( reg, 
+			VTSS_FIFO_DEFAULT_BURST_SIZE_TOWARDS_10G_PORT, 0xF);
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:   /* */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:     /* Single Chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK:    /* Single Chip trunking */
+			/* Egress FIFO sends data to 10G MAC 
+			from upto 10 channels always frame-interleaved */
+			CLR_BIT( reg, 4);
+			/* It's recommended to write a value into the 
+			   burst size bitfield even  when running in frame-interleaved
+			     mode */
+			SET_BITS_MASKED( reg, 
+			VTSS_FIFO_DEFAULT_BURST_SIZE_TOWARDS_10G_PORT, 0xF);
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G: /* SPI4 <-> 10x1G */
+			/* Egress FIFO sends data to 1G MACs from upto
+			 10 channels always burst-interleaved */
+			SET_BIT( reg, 4);
+			SET_BITS_MASKED( reg,
+			VTSS_FIFO_DEFAULT_BURST_SIZE_TOWARDS_1G_PORT, 0xF);
+			break;
+
+		default:
+			break;
+	}
+
+	mask = 0xFF0323FF;
+	vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_EGRESS, 
+				M2_EGR_CONTROL, reg, mask);
+
+	return VTSS_OK;
+}
+
+
+/******************************************************************************
+ * Description:
+ *     This is a supplementary function. It configures a structure referenced 
+ *     by the pointer to the default values for the chosen major mode.
+ *     After that the user may modify the fields of the structure for 
+ *     fine-tuning of the system and then call the vtss_fifo_setup() function.
+ *
+ * Arguments:
+ *     ps_ingress   pointer to a structure for the ingress fifo
+ *     ps_egress    pointer to a structure for the egress fifo
+ *     major_mode   select the major mode  for the session
+ *
+ * Return code:
+ *     VTSS_OK      if operation completed successfully
+ *     VTSS_WRONG_MAJOR_MODE
+ *     VTSS_PORT_NOT_MAPPED
+ *
+ **************************************************************************kbp*/
+vtss_rc vtss_fifo_setup_get_default_values( vtss_fifo_setup_t *ps_ingress,
+		vtss_fifo_setup_t *ps_egress,
+		vtss_mac_major_mode_t major_mode)
+{
+	uint  i;
+	uint  ports = 0;
+	uint  ingress_tb = 0;
+	uint  egress_tb  = 0;
+	ulong fifo_ingress_block_size = 0x0; 
+	ulong fifo_egress_block_size  = 0x0; 
+
+	switch (major_mode) {
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G:   /* SPI4 <-> 1x10G */
+			ps_ingress->prm_hdr_used = FALSE;
+			ps_ingress->norm_hdr_used = FALSE;
+			ps_egress->prm_hdr_used = FALSE;
+			ps_egress->norm_hdr_used = FALSE;
+
+			ps_ingress->output_port_offset = 0;
+			ps_ingress->input_port_offset = 0;
+			ps_egress->output_port_offset = 0;
+			ps_egress->input_port_offset = 0;
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G:    /* SPI4 <-> 10x1G */
+			ps_ingress->prm_hdr_used = FALSE;
+			ps_ingress->norm_hdr_used = FALSE;
+			ps_egress->prm_hdr_used = FALSE;
+			ps_egress->norm_hdr_used = FALSE;
+
+			ps_ingress->output_port_offset = 0;
+			ps_ingress->input_port_offset = 0xA;
+			ps_egress->output_port_offset = 0xA;
+			ps_egress->input_port_offset = 0;
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:
+			ps_ingress->prm_hdr_used = FALSE;
+			ps_ingress->norm_hdr_used = FALSE;
+			ps_egress->prm_hdr_used = FALSE;
+			ps_egress->norm_hdr_used = TRUE;
+
+			ps_ingress->output_port_offset = 0xA;
+			ps_ingress->input_port_offset = 0;
+			ps_egress->output_port_offset = 0;
+			ps_egress->input_port_offset = 0xA;
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK:
+			ps_ingress->prm_hdr_used = TRUE;
+			ps_ingress->norm_hdr_used = FALSE;
+			ps_egress->prm_hdr_used = TRUE;
+			ps_egress->norm_hdr_used = TRUE;
+
+			ps_ingress->output_port_offset = 0xA;
+			ps_ingress->input_port_offset = 0;
+			ps_egress->output_port_offset = 0;
+			ps_egress->input_port_offset = 0xA;
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:
+			ps_ingress->prm_hdr_used = FALSE;
+			ps_ingress->norm_hdr_used = TRUE;
+			ps_egress->prm_hdr_used = FALSE;
+			ps_egress->norm_hdr_used = TRUE;
+
+			ps_ingress->output_port_offset = 0;
+			ps_ingress->input_port_offset = 0;
+			ps_egress->output_port_offset = 0;
+			ps_egress->input_port_offset = 0;
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:
+			ps_ingress->prm_hdr_used = TRUE;
+			ps_ingress->norm_hdr_used = TRUE;
+			ps_egress->prm_hdr_used = TRUE;
+			ps_egress->norm_hdr_used = TRUE;
+
+			ps_ingress->output_port_offset = 0;
+			ps_ingress->input_port_offset = 0;
+			ps_egress->output_port_offset = 0;
+			ps_egress->input_port_offset = 0;
+			break;
+
+		default:
+			/* VTSS_MAC_MAJOR_MODE_UNDEFINED */
+			return VTSS_WRONG_MAJOR_MODE;
+	}
+
+	fifo_ingress_block_size = VTSS_MAX_INGRESS_FIFO_SIZE >> 11;
+	fifo_egress_block_size  = VTSS_MAX_EGRESS_FIFO_SIZE  >> 11;
+
+	/* Single Channel mode, 10G is logical port number 1 */
+	if (major_mode == VTSS_MAC_MAJOR_MODE_SPI4_10G) {   /* SPI4 <-> 1x10G */
+
+		/* vtss_fifo_block_t  */
+		ps_ingress->fifo_port_area[1].bottom = 0;
+		ps_ingress->fifo_port_area[1].top = fifo_ingress_block_size;
+		ps_egress->fifo_port_area[1].bottom = 0;
+		ps_egress->fifo_port_area[1].top = fifo_egress_block_size;
+
+		/* vtss_fifo_fc_watermarks_t */
+		ps_ingress->fifo_port_wm[1].low_watermark = 0xFFFFFFFF;
+		ps_ingress->fifo_port_wm[1].high_watermark = 0xFFFFFFFF;
+		ps_egress->fifo_port_wm[1].low_watermark = 0xFFFFFFFF;
+		ps_egress->fifo_port_wm[1].high_watermark = 0xFFFFFFFF;
+
+		/* cut-through mode/threshold. If not enabled then store-forward */
+		/* vtss_fifo_cut_through_mode_t */
+		ps_ingress->thrhld[1].cut_through_enable = FALSE;
+		ps_ingress->thrhld[1].threshold_value = 0;
+		ps_egress->thrhld[1].cut_through_enable = FALSE;
+		ps_egress->thrhld[1].threshold_value = 0;
+
+	} else {
+
+		/* Multi Channel mode */
+		for( i=1; i<=VTSS_PORTS_1G; i++ ) {
+			if( vtss_logical_ports[i].chip_port >= 0 ) { ports++; }
+		}
+
+		if ( ports == 0 ) { return VTSS_PORT_NOT_MAPPED; } 
+		fifo_ingress_block_size = fifo_ingress_block_size / ports;
+		fifo_egress_block_size  = fifo_egress_block_size  / ports;
+
+
+		for(i=1; i<=VTSS_PORTS_1G; i++) {
+			if( vtss_logical_ports[i].chip_port < 0 ) { continue; }
+
+			/* TOP and BOTTOM values */
+			ps_ingress->fifo_port_area[i].bottom = ingress_tb;
+			ingress_tb = ingress_tb + fifo_ingress_block_size;
+			ps_ingress->fifo_port_area[i].top = ingress_tb;
+			ps_egress->fifo_port_area[i].bottom = egress_tb;
+			egress_tb = egress_tb + fifo_egress_block_size;
+			ps_egress->fifo_port_area[i].top = egress_tb;
+			/*VTSS_D(("tb: 0x%08lX 0x%08lX", ingress_tb, egress_tb));*/
+
+			/* Watermarks */
+			ps_ingress->fifo_port_wm[i].low_watermark = 0xFFFFFFFF;
+			ps_ingress->fifo_port_wm[i].high_watermark = 0xFFFFFFFF;
+			ps_egress->fifo_port_wm[i].low_watermark = 0x40; 
+			ps_egress->fifo_port_wm[i].high_watermark = 256; 
+
+			/* cut-through mode/threshold. If not enabled then store-forward */
+			ps_ingress->thrhld[i].cut_through_enable = FALSE;
+			ps_ingress->thrhld[i].threshold_value = 0;
+			ps_egress->thrhld[i].cut_through_enable = FALSE;
+			ps_egress->thrhld[i].threshold_value = 0;
+		}
+
+	}
+
+	/* vtss_fifo_ageing_t */
+	ps_ingress->ageing.enable = FALSE;
+	ps_ingress->ageing.interval = 0;
+	ps_egress->ageing.enable = FALSE;
+	ps_egress->ageing.interval = 0;
+
+	return VTSS_OK;
+}
+
+/*-----------------  Run-time funcitons   ------------------------------------*/
+
+
+
+/*******************************************************************************
+  Function 
+  Syntax 
+  Parameters 
+
+  Returns 
+  VTSS_OK        No errors detected
+
+  Description
+
+ ********************************************************************************/
+vtss_rc vtss_fifo_thrhld_set( vtss_port_no_t portnum, 
+		vtss_fifo_cut_through_mode_t *pctt_ingress,
+		vtss_fifo_cut_through_mode_t *pctt_egress)
+{
+	/* Find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+
+	/* Check the physical port number */
+	if (ppn == -1) { return VTSS_PORT_NOT_MAPPED; }
+
+	vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_INGRESS, 
+			M2_CT_THRHLD + ppn, 
+			(pctt_ingress->cut_through_enable)?
+			(pctt_ingress->threshold_value):0);
+
+	vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_EGRESS, 
+			M2_CT_THRHLD + ppn, 
+			(pctt_egress->cut_through_enable)?
+				(pctt_egress->threshold_value):0);
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+  Function 
+  vtss_fifo_watermarks_set()
+
+  Syntax 
+  vtss_fifo_watermarks_set( vtss_port_no_t portnum,
+  vtss_fifo_fc_watermarks_t *pwm_ingress,
+  vtss_fifo_fc_watermarks_t *pwm_egress)
+  Parameters 
+  portnum        Logical port number
+  pwm_ingress    Pointer to the 'watermarks' structure in ingress direction. 
+  If set to NULL no initialization is performed.
+  pwm_egress     Pointer to the 'watermarks' structure in egress directon.
+  If set to NULL no initalization is performed
+
+  Returns 
+  VTSS_OK        No errors detected
+
+  Description
+  This function sets watermarks for a given logical port
+
+ ********************************************************************************/
+vtss_rc vtss_fifo_watermarks_set( vtss_port_no_t portnum,
+		vtss_fifo_fc_watermarks_t *pwm_ingress,
+		vtss_fifo_fc_watermarks_t *pwm_egress)
+{
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_HIGH_LOW_WM + ppn, 
+			(ulong)((pwm_ingress->low_watermark<<16) |
+			 pwm_ingress->high_watermark));
+
+	vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_HIGH_LOW_WM + ppn, 
+			(ulong)((pwm_egress->low_watermark<<16) |  
+			pwm_egress->high_watermark));
+
+	return VTSS_OK;
+}
+
+
+/*
+
+   Set a fifo to expect incoming data with/without the header (normalised or 
+   preamble)
+
+   The function does not check how the fifo is configured. (Note: running in 
+   cut-through mode with the header makes no sense)
+
+
+   Parameters
+   fifo      which fifo to use: engress or ingress
+   enable    enable or disable the feature
+   if TRUE,  incoming frame have normalized and/or preamble header
+   if FALSE, incoming frame co not have normalized and/or preamble 
+   header
+   hdr       Describes what header to expect
+
+Note: this function will set or clear only that bit in the register which 
+corresponding element in the 'hdr' structure is set, i.e. it will not 
+affect preamble header settings, if the use_prm_hdr element is not set.
+
+ */
+static void vtss_fifo_use_hdr( int fifo, BOOL enable, m2_header_t hdr)
+{
+	ulong value = 0;
+	ulong mask = 0;
+	ulong reg_offset = 0;
+
+	switch( fifo) {
+		case M2_SUBBLK_EGRESS:
+			reg_offset = M2_EGR_CONTROL;
+			break;
+		case M2_SUBBLK_INGRESS:
+			reg_offset = M2_ING_CONTROL;
+			break;
+		default:
+			return;
+	}
+
+	if ( hdr.use_norm_hdr != FALSE) {
+		if ( enable != FALSE)
+			SET_BIT( value, 8);
+		SET_BIT( mask, 8);
+	}
+
+	if ( hdr.use_prm_hdr != FALSE){
+		if (enable != FALSE)
+			SET_BIT( value, 9);
+		SET_BIT( mask, 9);
+	}
+
+
+
+	vtss_io_writemasked( M2_BLK_FIFO, fifo, reg_offset, value, mask);
+
+	return;
+}
+
+
+#define VTSS_MIIM_READ_OPR      0x2
+#define VTSS_MIIM_WRITE_OPR     0x1
+
+#define VTSS_MIIM_OPR_MODE      0x1
+#define VTSS_MDIO_OPR_MODE      0x0
+
+
+/* Direct miim read/write operation using miim_controller address as a 
+   parameter */
+long vtss_miim_subblock_read( const uint miim_chnl, const uint phy_addr, 
+		const uint phy_reg)
+{
+	uint opcode = VTSS_MIIM_READ_OPR; /* read operation */
+	uint mode = VTSS_MIIM_OPR_MODE; /* MIIM operation, not MDIO */
+	ulong i = 0;
+	ulong data;
+
+
+	/* read status of the channel */
+	while ( 0 != (0x1C & vtss_io_read( M2_BLK_MIIM, 
+				miim_chnl, M2_MIIM_STATUS))) {
+		i++;
+		if(i > VTSS_MIIM_READ_ATTEMPT) {
+//			printk("API: channel busy1\n");
+			return VTSS_MIIM_CHANNEL_BUSY;
+		}
+	}
+
+
+	vtss_io_write( M2_BLK_MIIM, miim_chnl, M2_MIIM_CMD, 
+			(phy_addr<<9)|(phy_reg<<4)|(opcode <<2)|mode);
+
+
+	/* read status of the channel */
+	while ( 0 != (0x1C & vtss_io_read( M2_BLK_MIIM, 
+			miim_chnl, M2_MIIM_STATUS))) {
+		VTSS_NSLEEP( 2000000); /* sleep 2 uS */
+		i++;
+		if(i > VTSS_MIIM_READ_ATTEMPT) {
+			printk("API: channel busy2\n");
+			return VTSS_MIIM_CHANNEL_BUSY;
+		}
+	}
+
+	data = vtss_io_read( M2_BLK_MIIM, miim_chnl, M2_MIIM_DATA);
+
+	return (data & ((ulong)1 << 16))?(-1):(data&0xFFFF);
+
+}
+
+
+void vtss_miim_subblock_write( const uint miim_chnl, const uint phy_addr, 
+		const uint phy_reg, const ushort value)
+{
+	uint opcode = VTSS_MIIM_WRITE_OPR; /* write operation */
+	uint mode = VTSS_MIIM_OPR_MODE; /* MIIM operation, not MDIO */
+
+
+	/* read status of the channel */
+	while( 0 != (0x1C & vtss_io_read( M2_BLK_MIIM, miim_chnl, M2_MIIM_STATUS))) 
+		; /* wait until the channel is ready */
+
+
+	vtss_io_write( M2_BLK_MIIM, miim_chnl, M2_MIIM_CMD, 
+	(ulong)((value<<16)|(phy_addr<<9)|(phy_reg<<4)|(opcode <<2)|mode));
+
+	return;
+}
+
+
+/* Indirect miim read/write operation. Accesses the PHY corresponding to the 
+   logical port number (PHY address is found via the mapping table)
+ */
+long vtss_miim_port_reg_read( const vtss_port_no_t portnum, 
+		const uint phy_reg){
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+	int miimchnl =  vtss_logical_ports[portnum].miim_controller;
+	int phy_addr =  vtss_logical_ports[portnum].phy_addr;
+	long data;
+
+	/* check the physical port number */
+	if (ppn == -1) {
+		printk("API: port not mapped\n");
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	/* long */ 
+	data = vtss_miim_subblock_read( miimchnl, phy_addr,  phy_reg);
+	return data;
+}
+
+
+void  vtss_miim_port_reg_write( const vtss_port_no_t portnum, 
+		const uint phy_reg, const ushort value)
+{
+	/* find the physical port number in the global map table */
+	/* int ppn = vtss_logical_ports[portnum].chip_port; */
+	int miimchnl =  vtss_logical_ports[portnum].miim_controller;
+	int phy_addr =  vtss_logical_ports[portnum].phy_addr;
+
+
+
+
+	/* long */ 
+	vtss_miim_subblock_write( miimchnl, phy_addr,  phy_reg, value);
+}
+
+
+BOOL vtss_phy_mapped( const vtss_port_no_t port_no )
+{
+	return  -1 != vtss_logical_ports[port_no].phy_addr;
+
+}
+
+/*******************************************************************************
+  Policing and shaping traffic.
+
+Terminology:
+Policer limits traffic in ingress direction
+Shaper does the same in engress direction
+
+In functions below only the term 'shaper' is used.
+ ********************************************************************************/
+int get_shaper_register( int port_on_chip)
+{
+	if ( port_on_chip >= 0 && port_on_chip <= 7)
+		return 0xA | (port_on_chip << 4);
+	else if ( port_on_chip >= 8 && port_on_chip <= 9)
+		return 0xB | ((port_on_chip & 0x7) << 4);
+	else 
+		return -1;
+
+}
+
+#if 0
+/*******************************************************************************
+  Function 
+  vtss_egress_shaper_set()
+
+  Description
+  This function configures bitrate and leaky buvket level in the egress 
+  direction for a given logical port.
+
+  Syntax 
+  vtss_rc vtss_egress_shaper_set( vtss_port_no_t portnum, vtss_bitrate_t br);
+
+  Parameters 
+  portnum        Logical port number
+  br             Bitrate (in kilobits/second)
+  lblvl          Leaky bucket level in bytes. Range (0...0xFFFF)*128 bytes
+
+  Note
+  The bitrate is in kbits/second, so to get a throughput in bits/second 
+  the value must be multiplied by 1000.
+
+  Returns 
+  VTSS_OK        No errors detected
+
+
+ ********************************************************************************/
+vtss_rc vtss_egress_shaper_set( vtss_port_no_t portnum, vtss_kbitrate_t br, 
+		ulong lblvl)
+{
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+	//  VTSS_N(("Shaper setup (egress dir). Logic port #%d, phys prt #%d", portnum, ppn));
+	//	printk("Shaper setup (egress dir). Logic port #%d, phys prt #%d\n", portnum, ppn);
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	if( br == VTSS_DISABLE_SHAPER) {
+		/* disable the shaper */
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_TRAFFIC_SHAPER_CTRL,
+				(ulong)1<<22, (ulong)1<<22);
+
+	} else {
+
+		ulonglong reg_value = (ulonglong)br*1000/VTSS_SHAPER_BITRATE_UNIT_PER_PORT;
+		ulong lvl = lblvl/VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+
+		if (reg_value > 0xFFFF)
+			reg_value = 0xFFFF;
+
+		if ( lvl > 0xFFFF)
+			lvl = 0xFFFF;
+
+		reg_value |= (lvl << 16);
+
+		vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_EGRESS, get_shaper_register( ppn),
+				(ulong)reg_value);
+
+		/* Enable the shaper */
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_TRAFFIC_SHAPER_CTRL,
+				0, (ulong)1<<22);
+
+	}
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+  Function 
+  vtss_ingress_shaper_set()
+
+  Description
+  This function configures bitrate in the ingress direction for a given 
+  logical port.
+
+  Syntax 
+  vtss_rc vtss_ingress_shaper_set( vtss_port_no_t portnum, vtss_bitrate_t br);
+
+  Parameters 
+  portnum        Logical port number
+  br             Bitrate (in kilobits/second)
+
+  Note
+  The bitrate is in kbits/second, so to get a throughput in bits/second 
+  the value must be multiplied by 1000.
+
+  Returns 
+  VTSS_OK        No errors detected
+
+
+ ********************************************************************************/
+vtss_rc vtss_ingress_shaper_set( vtss_port_no_t portnum, vtss_kbitrate_t br,
+		ulong lblvl)
+{
+
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+	//  VTSS_N(("Shaper setup (ingress dir). Logic port #%d, phys prt #%d", portnum, ppn));
+	printk("Shaper setup (ingress dir). Logic port #%d, phys prt #%d\n", portnum, ppn);
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+	if( br == VTSS_DISABLE_SHAPER) {
+		/* disable the shaper */
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_TRAFFIC_SHAPER_CTRL,
+				(ulong)1<<22, (ulong)1<<22);
+
+	} else {
+
+		ulonglong reg_value = (ulonglong)br*1000/VTSS_SHAPER_BITRATE_UNIT_PER_PORT;
+		ulong lvl = lblvl/VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+
+		if (reg_value > 0xFFFF)
+			reg_value = 0xFFFF;
+
+		if ( lvl > 0xFFFF)
+			lvl = 0xFFFF;
+
+		reg_value |= (lvl << 16);
+
+		vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_INGRESS, get_shaper_register( ppn), 
+				reg_value);
+
+		/* Enable the shaper */
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_TRAFFIC_SHAPER_CTRL,
+				0, (ulong)1<<22 | (ulong)1<<ppn);
+	}
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+  Function 
+  vtss_egress_common_shaper_set()
+
+  Description
+  This function configures bitrate and leaky bucket level  of the common 
+  bucket in the egress direction.
+
+  Syntax 
+  vtss_rc vtss_ingress_common_shaper_set( vtss_bitrate_t br);
+
+  Parameters 
+  br             Bitrate (in kilobits/second)
+  lblvl          Leaky bucket level in bytes. Range (0..0xFFFF)*128 bytes
+
+  Note
+  The bitrate is in kbits/second, so to get a throughput in bits/second 
+  the value must be multiplied by 1000.
+
+
+  Returns 
+  VTSS_OK        No errors detected
+
+
+ ********************************************************************************/
+vtss_rc vtss_egress_common_shaper_set( vtss_kbitrate_t br, ulong lblvl)
+{
+	if( br == VTSS_DISABLE_SHAPER) {
+		/* disable the shaper */
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_TRAFFIC_SHAPER_CTRL,
+				(ulong)1<<22, (ulong)1<<22);
+
+	} else {
+		/* Check that shaping is enabled */
+
+		ulonglong reg_value = (ulonglong)br*1000/VTSS_SHAPER_BITRATE_UNIT_PER_LINK;
+		ulong lvl = lblvl/VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+
+		if (reg_value > 0xFFFF)
+			reg_value = 0xFFFF;
+
+		if ( lvl > 0xFFFF)
+			lvl = 0xFFFF;
+
+		reg_value |= (lvl << 16);
+
+		vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_TRAFFIC_SHAPER_BUCKET10,
+				reg_value);
+
+		/* Enable the shaper */
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_EGRESS, M2_TRAFFIC_SHAPER_CTRL,
+				0, (ulong)1<<22 | (ulong)1<<10);
+	}
+
+	return VTSS_OK;
+}
+
+
+/*******************************************************************************
+  Function 
+  vtss_ingress_common_shaper_set()
+
+  Description
+  This function configures bitrate and leaky bucket level in the ingress 
+  direction for the common shaper
+
+  Syntax 
+  vtss_rc vtss_ingress_shaper_set( vtss_port_no_t portnum, vtss_bitrate_t br);
+
+  Parameters 
+  portnum        Logical port number
+  br             Bitrate (in kilobits/second)
+
+  Note
+  The bitrate is in kbits/second, so to get a throughput in bits/second 
+  the value must be multiplied by 1000.
+
+  Returns 
+  VTSS_OK        No errors detected
+
+
+ ********************************************************************************/
+vtss_rc vtss_ingress_common_shaper_set( vtss_kbitrate_t br, ulong lblvl)
+{
+	if( br == VTSS_DISABLE_SHAPER) {
+		/* disable the shaper -- set DB (disable buckets) bit in the */
+		/* TRAFFIC_SHAPER_CTRL register */
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_TRAFFIC_SHAPER_CTRL,
+				(ulong)1<<22, (ulong)1<<22);
+
+	} else {
+		/* Check that shaping is enabled */
+
+		ulonglong reg_value = (ulonglong)br*1000/VTSS_SHAPER_BITRATE_UNIT_PER_LINK;
+		ulong lvl = lblvl/VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+
+		if (reg_value > 0xFFFF)
+			reg_value = 0xFFFF;
+
+		if ( lvl > 0xFFFF)
+			lvl = 0xFFFF;
+
+		reg_value |= (lvl << 16);
+
+		vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_TRAFFIC_SHAPER_BUCKET10,
+				reg_value);
+
+		/* Enable the shaper */
+		vtss_io_writemasked( M2_BLK_FIFO, M2_SUBBLK_INGRESS, M2_TRAFFIC_SHAPER_CTRL,
+				0, (ulong)1<<22 | (ulong)1<<10);
+	}
+
+	return VTSS_OK;
+}
+
+
+vtss_rc vtss_egress_shaper_get( vtss_port_no_t port_no, vtss_kbitrate_t *pbr, 
+		ulong *leaky_bucket_level)
+{
+	ulong ctrl_reg_value=0;
+	ulong bitrate_reg_value=0;
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[port_no].chip_port;
+	//  VTSS_N(("Shaper setup (ingress dir). Logic port #%d, phys prt #%d", port_no, ppn));
+	printk("Shaper setup (ingress dir). Logic port #%d, phys prt #%d\n", port_no, ppn);
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+
+	/* Check that shaping is enabled */
+	ctrl_reg_value = vtss_io_read( M2_BLK_FIFO, M2_SUBBLK_EGRESS, 
+			M2_TRAFFIC_SHAPER_CTRL);
+	bitrate_reg_value = vtss_io_read( M2_BLK_FIFO, M2_SUBBLK_EGRESS, 
+			get_shaper_register( ppn));
+
+
+	if( 0x1 == (( ctrl_reg_value >> 22) & 0x1)) {
+		/* shaping disabled, return VTSS_DISABLE_SHAPER */
+		*pbr = VTSS_DISABLE_SHAPER;
+		*leaky_bucket_level = 
+			(0xFFFF & (bitrate_reg_value >> 16)) * VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+	} else {
+		/* if the shaper is enabled, return the value from the device */
+		*pbr = (ulong)( (ulonglong)VTSS_SHAPER_BITRATE_UNIT_PER_PORT * 
+				(bitrate_reg_value & 0xFFFF) / 1000);
+		*leaky_bucket_level = 
+			(0xFFFF & (bitrate_reg_value>>16)) * VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+	}
+
+	return VTSS_OK;
+}
+
+
+vtss_rc vtss_ingress_shaper_get( vtss_port_no_t port_no, vtss_kbitrate_t *pbr, 
+		ulong *leaky_bucket_level)
+{
+
+	ulong ctrl_reg_value=0;
+	ulong bitrate_reg_value=0;
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[port_no].chip_port;
+	//  VTSS_N(("Shaper setup (ingress dir). Logic port #%d, phys prt #%d", port_no, ppn));
+	printk("Shaper setup (ingress dir). Logic port #%d, phys prt #%d\n", port_no, ppn);
+	/* check the physical port number */
+	if (ppn == -1) {
+		return VTSS_PORT_NOT_MAPPED;
+	}
+
+
+	/* Check that shaping is enabled */
+	ctrl_reg_value = vtss_io_read( M2_BLK_FIFO, M2_SUBBLK_INGRESS, 
+			M2_TRAFFIC_SHAPER_CTRL);
+	bitrate_reg_value = vtss_io_read( M2_BLK_FIFO, M2_SUBBLK_INGRESS, 
+			get_shaper_register( ppn));
+
+
+	if( 0x1 == (( ctrl_reg_value >> 22) & 0x1)) {
+		/* shaping disabled, return VTSS_DISABLE_SHAPER */
+		*pbr = VTSS_DISABLE_SHAPER;
+		*leaky_bucket_level = 
+			(0xFFFF & (bitrate_reg_value >> 16)) * VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+	} else {
+		/* if the shaper is enabled, return the value from the device */
+		*pbr = (ulong)( (ulonglong)VTSS_SHAPER_BITRATE_UNIT_PER_PORT * 
+				(bitrate_reg_value & 0xFFFF) / 1000);
+		*leaky_bucket_level = 
+			(0xFFFF & (bitrate_reg_value>>16)) * VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+	}
+
+	return VTSS_OK;
+}
+
+
+
+vtss_rc vtss_egress_common_shaper_get( vtss_kbitrate_t *pbr, 
+		ulong *leaky_bucket_level)
+{
+
+	ulong ctrl_reg_value=0;
+	ulong bitrate_reg_value=0;
+
+	//  VTSS_N(("Egress common shaper get"));
+	printk("Egress common shaper get\n");
+
+	/* Check that shaping is enabled */
+	ctrl_reg_value = vtss_io_read( M2_BLK_FIFO, M2_SUBBLK_EGRESS, 
+			M2_TRAFFIC_SHAPER_CTRL);
+	bitrate_reg_value = vtss_io_read( M2_BLK_FIFO, M2_SUBBLK_EGRESS, 
+			M2_TRAFFIC_SHAPER_BUCKET10);
+
+
+	if( 0x1 == (( ctrl_reg_value >> 22) & 0x1)) {
+		/* shaping disabled, return VTSS_DISABLE_SHAPER */
+		*pbr = VTSS_DISABLE_SHAPER;
+		*leaky_bucket_level = 
+			(0xFFFF & (bitrate_reg_value >> 16)) * VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+	} else {
+		/* if the shaper is enabled, return the value from the device */
+		*pbr = (ulong)( (ulonglong)VTSS_SHAPER_BITRATE_UNIT_PER_LINK * 
+				(bitrate_reg_value & 0xFFFF) / 1000);
+		*leaky_bucket_level = 
+			(0xFFFF & (bitrate_reg_value>>16)) * VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+	}
+
+	return VTSS_OK;
+}
+
+
+vtss_rc vtss_ingress_common_shaper_get( vtss_kbitrate_t *pbr, 
+		ulong *leaky_bucket_level)
+{
+
+	ulong ctrl_reg_value=0;
+	ulong bitrate_reg_value=0;
+
+	//  VTSS_N(("Ingress common shaper get"));
+	printk("Ingress common shaper get\n");
+
+	/* Check that shaping is enabled */
+	ctrl_reg_value = vtss_io_read( M2_BLK_FIFO, M2_SUBBLK_INGRESS, 
+			M2_TRAFFIC_SHAPER_CTRL);
+	bitrate_reg_value = vtss_io_read( M2_BLK_FIFO, M2_SUBBLK_INGRESS, 
+			M2_TRAFFIC_SHAPER_BUCKET10);
+
+
+	if( 0x1 == (( ctrl_reg_value >> 22) & 0x1)) {
+		/* shaping disabled, return VTSS_DISABLE_SHAPER */
+		*pbr = VTSS_DISABLE_SHAPER;
+		*leaky_bucket_level = 
+			(0xFFFF & (bitrate_reg_value >> 16)) * VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+	} else {
+		/* if the shaper is enabled, return the value from the device */
+		*pbr = (ulong)( (ulonglong)VTSS_SHAPER_BITRATE_UNIT_PER_LINK * 
+				(bitrate_reg_value & 0xFFFF) / 1000);
+		*leaky_bucket_level = 
+			(0xFFFF & (bitrate_reg_value>>16)) * VTSS_SHAPER_LEAKY_BUCKET_UNIT;
+	}
+
+	return VTSS_OK;
+}
+
+#endif
+
+/*******************************************************************************
+
+  Aggregation/trunking 
+
+
+ ********************************************************************************/
+
+/*
+   Initialises port map table of the aggregator.
+   The function must be called after virtual ports have been mapped to 
+   physical ports.
+   The function also tests whether the port is enabled or disabled.
+   Disabled ports are removed from the aggregation table.
+ */
+vtss_rc vtss_aggr_pmap_table_initialise( void)
+{
+	int i;
+
+	for ( i=0; i < M2_AGGR_PMAP_TABLE_SIZE; i++) {
+		vtss_aggr_pmap_table_set( i, i % VTSS_PORTS_1G);
+	}
+
+	return VTSS_OK;
+}
+
+
+
+/*
+   Writes one entry into the port map table of the aggregator
+ */
+vtss_rc vtss_aggr_pmap_table_set( int index, int portnum)
+{
+	vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_AGGR,
+		 M2_PMAP_TABLE, (portnum<<8)|(index & 0xFF));
+
+	return VTSS_OK;
+}
+
+
+
+vtss_rc vtss_aggr_setup( vtss_aggr_mode_t *pamode)
+{
+	ulong reg_value = 0;
+	ulong reg_mask = 0x1BE; /* will not alter NLE,HDR,P_PAR and reserved bits */
+
+
+
+	if (pamode->preamble_trunking) {
+
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_AGGR, M2_PRE_BIT0POS,
+				pamode->u.bit.pos0);
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_AGGR, M2_PRE_BIT1POS,
+				pamode->u.bit.pos1);
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_AGGR, M2_PRE_BIT2POS,
+				pamode->u.bit.pos2);
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_AGGR, M2_PRE_BIT3POS,
+				pamode->u.bit.pos3);
+		reg_value = 1 << 5;
+
+	} else if (pamode->mpls_trunking) {
+
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_AGGR, M2_MPLS_BIT0,
+				pamode->u.bit.pos0);
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_AGGR, M2_MPLS_BIT1,
+				pamode->u.bit.pos1);
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_AGGR, M2_MPLS_BIT2,
+				pamode->u.bit.pos2);
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_AGGR, M2_MPLS_BIT3,
+				pamode->u.bit.pos3);
+		reg_value = (1<<8) |( 1<<7);
+
+	} else if (pamode->mpls_aggregation) {
+
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_AGGR, M2_MPLS_BITMASK,
+				pamode->u.mpls_bitmask);
+		reg_value = 1<<7;
+
+	} else if (pamode->l2_aggr || pamode->l3_aggr || pamode->l4_aggr) {
+
+		if ( pamode->l2_aggr)
+			SET_BIT( reg_value, 2);
+		if ( pamode->l3_aggr)
+			SET_BIT( reg_value, 3);
+		if ( pamode->l4_aggr)
+			SET_BIT( reg_value, 4);
+
+		SET_BIT(reg_value, 1);
+
+	}
+
+	if( pamode->norm_hdr_used == TRUE) {
+		SET_BIT( reg_value, 0);/* Norm header is present */
+		CLR_BIT( reg_value, 9);/* NLE bit must be cleared when the norm header
+					  is present */
+	} else {
+		CLR_BIT( reg_value, 0);
+		SET_BIT( reg_value, 9);
+	}
+
+	vtss_io_writemasked( M2_BLK_SYSTEM, M2_SUBBLK_AGGR, M2_AGGR_SETUP,
+			reg_value, reg_mask);
+
+	return VTSS_OK;
+}
+
+
+
+vtss_rc vtss_aggr_setup_get_default_values( vtss_aggr_mode_t* pam, 
+		vtss_mac_major_mode_t mmode)
+{
+
+	pam->preamble_trunking = FALSE;
+	pam->mpls_trunking = FALSE;
+	pam->mpls_aggregation = FALSE;
+	pam->l2_aggr = FALSE;
+	pam->l3_aggr = FALSE;
+	pam->l4_aggr = FALSE;
+
+	pam->u.bit.pos0 = 0;
+	pam->u.bit.pos1 = 0;
+	pam->u.bit.pos2 = 0;
+	pam->u.bit.pos3 = 0;
+
+	pam->u.mpls_bitmask = 0;
+
+	pam->norm_hdr_used = FALSE;
+
+
+	switch (mmode) {
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G:   /* SPI4 <-> 1x10G */
+
+			return VTSS_WRONG_MAJOR_MODE;
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G:    /* SPI4 <-> 10x1G */
+
+			return VTSS_WRONG_MAJOR_MODE;
+
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:
+			/* Default: layer 2 aggregation */
+			pam->l2_aggr = TRUE;
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK:
+
+			/* Default: preamble trunking */
+			pam->preamble_trunking = TRUE;
+
+			pam->u.bit.pos0 = M2_PREAMBLE_BIT0_POS;
+			pam->u.bit.pos1 = M2_PREAMBLE_BIT1_POS;
+			pam->u.bit.pos2 = M2_PREAMBLE_BIT2_POS;
+			pam->u.bit.pos3 = M2_PREAMBLE_BIT3_POS;
+
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:
+			/* Default: layer 2 aggregation */
+			pam->l2_aggr = TRUE;
+			break;
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:
+			/* Default: preamble trunking */
+			pam->preamble_trunking = TRUE;
+
+			pam->u.bit.pos0 = M2_PREAMBLE_BIT0_POS;
+			pam->u.bit.pos1 = M2_PREAMBLE_BIT1_POS;
+			pam->u.bit.pos2 = M2_PREAMBLE_BIT2_POS;
+			pam->u.bit.pos3 = M2_PREAMBLE_BIT3_POS;
+
+			break;
+
+		default:
+			/* VTSS_MAC_MAJOR_MODE_UNDEFINED */
+			return VTSS_WRONG_MAJOR_MODE;
+
+	}
+
+	return VTSS_OK;
+}
+
+
+/*
+   Inform the aggregator that frames are with/without a normalized and/or 
+   preamble header
+ */
+static void vtss_aggr_use_header( BOOL enable, m2_header_t hdr)
+{
+	ulong cfg_reg = 0;
+	BOOL prm_hdr_enabled = FALSE;
+	BOOL norm_hdr_enabled = FALSE;
+
+	if( hdr.use_norm_hdr == FALSE && hdr.use_prm_hdr == FALSE)
+		return;
+
+	cfg_reg = vtss_io_read( M2_BLK_FIFO, M2_BLK_SYSTEM, M2_CRC_CFG);
+
+	if ( cfg_reg & (1<<4)) {
+		switch (cfg_reg & 0xf) {
+			case 0:
+				prm_hdr_enabled = TRUE;
+				norm_hdr_enabled = TRUE;
+				break;
+			case 7:
+				prm_hdr_enabled = TRUE;
+				break;
+			case 9:
+				norm_hdr_enabled = TRUE;
+				break;
+			default:
+				break;
+		}
+	}
+
+	if( hdr.use_norm_hdr == TRUE) {
+
+		if( enable == TRUE) {
+			SET_BIT( cfg_reg, 4);
+			if( prm_hdr_enabled == TRUE)
+				cfg_reg &= ~(ulong)0xF;
+			else
+				cfg_reg = (cfg_reg & ~(ulong)0xF) + 9;
+
+		} else {
+			/* disable norm hdr */
+			if (prm_hdr_enabled == TRUE) {
+				SET_BIT( cfg_reg, 4);
+				cfg_reg = (cfg_reg & ~(ulong)0xF) + 7;
+			}
+
+		}
+
+	}
+
+	if (hdr.use_prm_hdr == TRUE) {
+
+		if ( enable == TRUE) {
+			SET_BIT( cfg_reg, 4);
+			if( norm_hdr_enabled == TRUE)
+				cfg_reg &= ~(ulong)0xF;
+			else
+				cfg_reg = (cfg_reg & ~(ulong)0xF) + 7;
+
+		} else {
+			/* disable preamble header */
+			if ( norm_hdr_enabled == TRUE) {
+				SET_BIT( cfg_reg, 4);
+				cfg_reg = (cfg_reg & ~(ulong)0xF) + 9;
+			}
+
+		}
+
+	}
+
+	vtss_io_writemasked( M2_BLK_FIFO, M2_BLK_SYSTEM, 
+				M2_CRC_CFG, cfg_reg, 0x1F);
+
+}
+
+
+/*
+
+   Works only in INGRESS direction. To use normalized header in egress direction
+   use the vtss_norm_hdr_expect_enable() function.
+
+   Configures the whole device to use normalized header in ingress direction.
+   In 1G<->SPI4 mode normalization (insertion of the normalized header)
+   is done by 1G MAC devices.
+   In other modes normalized header is inserted by 10G MAC.
+
+   Normalized header is needed when the ingress FIFO runs in frame-interleaved
+   mode. 
+
+   To enable normalized header (that also requires setting the LE/NLE bit):
+   - write to the 10M/100M/1G/10G MAC block
+   - write to the ingress FIFO
+   - 
+ */
+static vtss_rc vtss_hdr_insert( BOOL able, m2_header_t hdr)
+{
+
+	/* Global pointer to a structure that can tell in which mode we are */
+	vtss_device_setup_t *pdv = pdevice;
+	int i;
+
+	switch( pdv->mmode) {
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G:        /* SPI4 <-> 10x1G */
+			/* configure all 1G devices to normalize frames */
+			for (i = M2_PHYS_PORT_1G_MIN; i <= M2_PHYS_PORT_1G_MAX; i++) {
+
+				vtss_port1G_header_insert( i, able, hdr);
+			}
+
+			/* Aggregator is not involved in this major mode */
+
+			/* Configure the ingress FIFO */
+			vtss_fifo_use_hdr( M2_SUBBLK_INGRESS, able, hdr);
+			break;
+
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+			/* Aggregator must be configured */
+			vtss_aggr_use_header( able, hdr);
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+
+			/* normalizer in 10G device, only one 10G port in M2 */
+			vtss_port10G_header_insert( able, hdr);
+
+			/* Aggregator must be configured */
+
+			/* Ingress FIFO must be configured to run with the norm header */
+			vtss_fifo_use_hdr( M2_SUBBLK_INGRESS, able, hdr);
+
+			break;
+
+
+			/* Undefined major mode */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			/* undefined major mode */
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+
+			/* In the following two modes the ingress channel 
+			(1x10G->10x1G) always runs in burst-interleaved mode,
+			 i.e. without the normalised  header. Currently, 
+			there does not seem to be a reason to use 
+		   	normalisation of frames in ingress direction.
+
+			In the egress direction (10x1G->1x10G) the normalized header
+			is always enabled, because the egress fifo runs in 
+			frame-interleaved mode. Currently there is no reason to
+			disable it   */
+
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:    /* single chip aggr */
+
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK:   /* single chip trunking */
+
+		/* In the next major mode ingress fifo always runs in the 
+		burst-interleaved  mode */
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G:       /* SPI4 <-> 1x10G */
+
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+
+	}
+	return VTSS_OK;
+}
+
+#if 0
+/*
+   Works only in EGRESS direction
+
+ */
+static vtss_rc vtss_hdr_expect( BOOL able, m2_header_t hdr)
+{
+
+	/* Global pointer to a structure that can tell in which mode we are */
+	vtss_device_setup_t *pdv = pdevice;
+	int i;
+
+	switch( pdv->mmode) {
+		case VTSS_MAC_MAJOR_MODE_SPI4_1G:        /* SPI4 <-> 10x1G */
+			/*
+			   Blocks affected:
+			   - System (CRC_CFG)
+			   - SPI4
+			   - Egress FIFO
+			   - 1G MAC (denormalizer register)
+			 */
+
+			/* configure all 1G devices to denormalize frames */
+			for (i = M2_PHYS_PORT_1G_MIN; i <= M2_PHYS_PORT_1G_MAX; i++) {
+
+				vtss_port1G_header_insert( i, able, hdr);
+			}
+
+			/* Aggregator is not involved in this major mode */
+
+			/* Configure the egress FIFO */
+			vtss_fifo_use_hdr( M2_SUBBLK_EGRESS, able, hdr);
+			break;
+
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR:  /* */
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK:  /* */
+
+			/* normalizer in 10G device, only one 10G port in M2 */
+			vtss_port10G_header_insert( able, hdr);
+
+			/* Aggregator must be configured */
+
+			/* Ingress FIFO must be configured to run with the norm header */
+
+			break;
+
+
+			/* In the following two modes the ingress channel 
+			(1x10G->10x1G) always runs in burst-interleaved mode, 
+			i.e. without the normalised header. Thus just repeat 
+			initalization.
+
+			In the egress direction (10x1G->1x10G) the normalized 
+			header  is always enabled, because the egress fifo 
+			runs in frame-interleaved mode */
+
+		case VTSS_MAC_MAJOR_MODE_10G_1G_AGGR:    /* single chip aggr */
+		case VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK:   /* single chip trunking */
+
+		/* 1G devices are configured in vtss_norm_hdr_expect_enable() 
+		function */
+		/* configure all 1G devices to normalize frames */
+		/*
+			   hdr.use_norm_hdr = TRUE;
+			   hdr.use_prm_hdr = FALSE;
+			   for (i = M2_PHYS_PORT_1G_MIN; 
+				i <= M2_PHYS_PORT_1G_MAX; i++) {
+
+			   vtss_port1G_header_insert_enable( i, hdr);
+			   }
+			 */
+
+			/* Aggregator is not involved in this major mode, 
+			skipping it */
+
+			/* Configure the egress FIFO */
+			vtss_fifo_use_hdr( M2_SUBBLK_EGRESS, able, hdr);
+
+
+			/* normalizer in 10G device, only one 10G port in M2 */
+			vtss_port10G_header_insert( able, hdr);
+
+			break;
+
+			/* */
+		case VTSS_MAC_MAJOR_MODE_UNDEFINED:
+			/* undefined major mode */
+			return VTSS_MAJOR_MODE_NOT_SET;
+
+		case VTSS_MAC_MAJOR_MODE_SPI4_10G:       /* SPI4 <-> 1x10G */
+			/* In this major mode ingress and egress fifo's 
+			always runs in burst-interleaved mode */
+			break;
+
+		default:
+			return VTSS_WRONG_MAJOR_MODE;
+
+	}
+
+	return VTSS_OK;
+}
+#endif
+
+
+/******************************************************************************
+ * Description: Set GPIO direction to input or output.
+ *
+ * \param gpio_no (input): GPIO pin number.
+ * \param output (input) : TRUE if output, FALSE if input.
+ *
+ * \return : Return code OK.
+ ******************************************************************************/
+vtss_rc vtss_gpio_direction_set(const vtss_gpio_no_t gpio_no, const BOOL output)
+{
+	//  VTSS_D(("gpio_no: %d, direction: %d",gpio_no,output));
+//	printk("gpio_no: %d, direction: %d\n",gpio_no,output);  
+	vtss_io_writemasked( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_GPIO_CTRL, 
+			output ? (ulong)1<<(gpio_no & 0xF) : 0, 
+			(ulong)1<<(gpio_no & 0xF));
+
+	return VTSS_OK;
+}
+
+
+/******************************************************************************
+ * Description: Read from GPIO input pin.
+ *
+ * \param gpio_no (input): GPIO pin number.
+ *
+ * \return : TRUE if pin is high, FALSE if it is low.
+ ******************************************************************************/
+BOOL vtss_gpio_input_read(const vtss_gpio_no_t gpio_no)
+{
+	uint value;
+
+	value = vtss_io_read( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, M2_GPIO_IN);
+
+	//  VTSS_D(("gpio_no: %d, input: %i", gpio_no, value));
+//	printk("gpio_no: %d, input: %i\n", gpio_no, value);  
+	return ( value & ((ulong)1<<(gpio_no & 0xF))) ? 1 : 0;
+}
+
+
+/******************************************************************************
+ * Description: Write to GPIO output pin.
+ *
+ * \param gpio_no (input): GPIO pin number.
+ * \param value (input)  : TRUE to set pin high, FALSE to set pin low.
+ *
+ * \return : TRUE if pin is high, FALSE if it is low.
+ ******************************************************************************/
+vtss_rc vtss_gpio_output_write(const vtss_gpio_no_t gpio_no, const BOOL value)
+{
+	//  VTSS_D(("gpio_no: %d, output: %d", gpio_no, value));
+//	printk("gpio_no: %d, output: %d\n",gpio_no, value);
+	vtss_io_writemasked( M2_BLK_SYSTEM, M2_SUBBLK_CTRL, 
+		M2_GPIO_OUT, value ?
+		(ulong)1<<(gpio_no & 0xF) : 0, (ulong)1<<(gpio_no & 0xF));
+
+	return VTSS_OK;
+}
+
+
+/******************************************************************************/
+/***        BIST test                                **************************/
+/******************************************************************************/
+
+/******************************************************************************
+ * Description: Start a specific bist test
+ *
+ * \param bist_no (input): bist test number range <0..VTSS_BIST_NAME_SIZE-1>.
+ *
+ * \return : VTSS_OK if write was started,
+ *           VTSS_BIST_CMD_FAILED if last write was still in progress.
+ **************************************************************************kbp*/
+vtss_rc vtss_chip_bist_start(const uint bist_no)
+{
+	ulong value = 0;
+
+	/*Last write completed?*/
+	value = vtss_io_read( M2_BLK_SYSTEM, M2_SUBBLK_BIST, M2_RAM_BIST_CMD);
+	if ( (value & (1<<27)) != 0 ) { return  VTSS_BIST_CMD_FAILED; }
+
+	/*Enable bist_no test by writing 0x1 to the indirect BIST_COMMAND register*/
+	vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_BIST, M2_RAM_BIST_CMD,  
+			(1<<24)|(M2_BIST_COMMAND<<16)|(0x1<<8)|bist_no);
+
+	return VTSS_OK;
+}
+
+
+/******************************************************************************
+ * Description: Get result for a specific bist test
+ *
+ * \param bist_no (input): bist test number range <0..VTSS_BIST_NAME_SIZE-1>.
+ *                         >= VTSS_BIST_NAME_SIZE returns the write status.
+ *
+ * \return : VTSS_OK               when bist test went OK
+ *           VTSS_BIST_CMD_FAILED  when write accesses failed.
+ *           VTSS_BIST_TEST_FAILED when bist test failed.
+ **************************************************************************kbp*/
+vtss_rc vtss_chip_bist_result(const uint bist_no)
+{
+	ulong value = 0;
+	uint i = 0;
+
+	/* Test for any previous write errors */
+	if ( bist_no >= VTSS_BIST_NAME_SIZE ) {
+		value = vtss_io_read( M2_BLK_SYSTEM, M2_SUBBLK_BIST, M2_RAM_BIST_CMD);
+		if ( (value & (1<<25)) != 0 ) { return  VTSS_BIST_CMD_FAILED; }
+		return VTSS_OK;
+	}
+
+	/*Wait for the BIST test to be done RD_DATA and when valid.*/
+	while ( (value & 0x3FD) == 0 && i++ < 0xF ) {
+
+		/*Transfer bist_no BIST_STATUS register to the 
+		RAM_BIST_RESULT register*/
+		vtss_io_write( M2_BLK_SYSTEM, M2_SUBBLK_BIST, 
+			M2_RAM_BIST_CMD,  
+			(0<<24)|(M2_BIST_STATUS<<16)|(bist_no & 0x3f));
+
+		/*Wait for read to complete*/
+		do {
+			value = vtss_io_read( M2_BLK_SYSTEM, 
+			M2_SUBBLK_BIST, M2_RAM_BIST_RESULT);
+		} while ( (value & (1<<9) ) != 0 ) ;
+	}
+	return ( value & (ulong)1<<1 ? VTSS_OK : VTSS_BIST_TEST_FAILED );
+}
+
+
+/******************************************************************************
+ * Description: Setup for GFP-T handling in Campbell-I
+ *
+ * \param portnum
+ *          vtss_gfpt_setup_t* gs
+ *       
+ *
+ * \return : VTSS_OK               
+ *           VTSS_PORT_NOT_MAPPED
+ *           VTSS_WRONG_PARAMETER
+ **************************************************************************kbp*/
+vtss_rc vtss_gfpt_setup( vtss_port_no_t portnum, vtss_gfpt_setup_t* gs)
+{
+	ulong gfpt_rx_pcs_reg = 0;
+
+	/* find the physical port number in the global map table */
+	int ppn = vtss_logical_ports[portnum].chip_port;
+	/* Check the physical port number */
+	if (ppn < 0) { return VTSS_PORT_NOT_MAPPED; }
+
+	/* Check selected interface */
+	switch ( gs->interface_mode.interface_type) {
+		/* right interface */
+		case VTSS_PORT_INTERFACE_SERDES:
+			if (gs->interface_mode.speed != VTSS_SPEED_ETH_GFPT) {
+				return VTSS_WRONG_PARAMETER; 
+			}
+			break;
+		case VTSS_PORT_INTERFACE_TBI:
+			/* Select Rx path as TBI interface */
+			SET_BIT(gfpt_rx_pcs_reg, 8); 
+			break;
+			/* Error - wrong interface */
+		default:
+			return VTSS_WRONG_PARAMETER;
+	}
+
+	/* Setup client clock when in clock source mode. */
+	/* Note: Per default the GPIos are set as input. */
+	/* GBE: use Internal SerDes, FC/2,FC/4,FC: Use GPIO1,
+	 (2FC or GBE: Use GPIO4), ESC: Use GPIO7, DVB: Use GPIO10 */  
+	if (gs->source_mode_en) {
+		vtss_io_writemasked( M2_BLK_MACS, ppn, 
+		M2_DEV_SETUP, (ulong)((1<<20)|
+			(gs->interface_mode.speed<<16)), (ulong)17<<16);
+	}
+
+	/* Setup client signal for the Egress and Ingress direction */
+	switch (gs->interface_mode.speed) {
+	case VTSS_SPEED_ETH_GFPT:
+		/* Setup client signal */
+		vtss_io_write( M2_BLK_MACS, ppn, C1_GFPT_CLIENT1, 
+			(C1_GFPT_CLIENT_GBE<<16)|(C1_GFPT_CLIENT_GBE));
+		/* Setup PCS TX */
+		vtss_io_write( M2_BLK_MACS, ppn, 
+		C1_GFPT_PCS_TX, (ulong)(
+			(1<<20)|(0xF1<<4)|((gs->gfpt_en)? 1:0)));
+		break;
+	case VTSS_SPEED_FC2_GFPT: /* 6    Gbit/s Fibre Channel */
+	case VTSS_SPEED_FC4_GFPT: /* 7    Gbit/s Fibre Channel */
+	case VTSS_SPEED_1FC_GFPT: /* 8    1Gbit/s Fibre Channel or FICON*/
+	case VTSS_SPEED_2FC_GFPT: /* 9    2Gbit/s Fibre Channel */
+		/* Setup client signal */
+		vtss_io_write( M2_BLK_MACS, ppn,
+		C1_GFPT_CLIENT1, 
+		(C1_GFPT_CLIENT_FC<<16)|(C1_GFPT_CLIENT_FC));
+		/* Setup PCS TX */
+		vtss_io_write( M2_BLK_MACS, ppn, 
+		C1_GFPT_PCS_TX, (ulong)(
+			(3<<20)|(0xF1<<4)|((gs->gfpt_en)? 1:0)));
+		/* Rx Synchronization mode, FC/FICON */    
+		SET_BIT(gfpt_rx_pcs_reg, 1); 
+		break;
+	case VTSS_SPEED_ESC_GFPT: /* 10 200Mbit/s ESCON or SBCON */
+		/* Setup client signal */
+		vtss_io_write( M2_BLK_MACS, ppn, C1_GFPT_CLIENT1, 
+			(C1_GFPT_CLIENT_ESC<<16)|(C1_GFPT_CLIENT_ESC));
+		/* Setup PCS TX */
+		vtss_io_write( M2_BLK_MACS, ppn, C1_GFPT_PCS_TX, 
+			(ulong)((0xF1<<4)|((gs->gfpt_en)? 1:0)));
+		/* Rx Synchronization mode, ESCON/SBCON */    
+		SET_BIT(gfpt_rx_pcs_reg, 2); 
+		break;
+	case VTSS_SPEED_DVB_GFPT: /* 11 270Mbit/s DVB ASI */
+		/* Setup client signal */
+		vtss_io_write( M2_BLK_MACS, ppn, 
+		C1_GFPT_CLIENT1, (C1_GFPT_CLIENT_DVB<<16)|(C1_GFPT_CLIENT_DVB));
+		/*Setup PCS TX */
+		vtss_io_write( M2_BLK_MACS, ppn, C1_GFPT_PCS_TX, 
+		(ulong)((0xF1<<4)|((gs->gfpt_en)? 1:0)));
+		/* Rx Synchronization mode, DVB ASI */    
+		SET_BIT(gfpt_rx_pcs_reg, 2); 
+		SET_BIT(gfpt_rx_pcs_reg, 1); 
+		break;
+
+		/* Error - wrong client */
+		default:
+			return VTSS_WRONG_PARAMETER;
+	}
+
+	/* Enable Rx symbol alignment, explicit bit 6=0 */
+	SET_BIT(gfpt_rx_pcs_reg, 7); 
+	/* Enable GFP-T processing */
+	if (gs->gfpt_en != FALSE) { SET_BIT(gfpt_rx_pcs_reg, 0); }
+	/* Setup PCS RX */
+	vtss_io_write( M2_BLK_MACS, ppn, C1_GFPT_PCS_RX, gfpt_rx_pcs_reg);
+
+	/* Change FIFO Threshold levels for GFP-T */
+	vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_INGRESS, 
+		M2_CT_THRHLD + ppn, (ulong)1); 
+	vtss_io_write( M2_BLK_FIFO, M2_SUBBLK_EGRESS, 
+		M2_CT_THRHLD + ppn, (ulong)((gs->threshold_level<<16)|1)); 
+
+	/* Setup rate adaptation rules */
+	if ( gs->rate_period >= 16 ) {
+		return VTSS_WRONG_PARAMETER;
+	} else if ( gs->rate_max_delta >= 8 ) {
+		return VTSS_WRONG_PARAMETER;
+	} else if ( gs->rate_min_idles >= 8 ) {
+		return VTSS_WRONG_PARAMETER;
+	} else {
+		vtss_io_write( M2_BLK_MACS, ppn, C1_GFPT_CLIENT2, 
+		/* (ulong)1<<26 */
+		(gs->rate_period<<16) | (gs->rate_max_delta<<8) | 
+						gs->rate_min_idles);
+	}
+
+	/* Setup Ingress Pading rate */
+	if ( gs->rate_padding >= 1024) {
+		return VTSS_WRONG_PARAMETER;
+	} else {
+		vtss_io_write( M2_BLK_MACS, ppn, 
+		C1_GFPT_BLOCK_CODE, gs->rate_padding);
+	}
+
+	/* GFPT frame length */
+	if ( gs->frame_length <= 0 || gs->frame_length >= 256) {
+		return VTSS_WRONG_PARAMETER;
+	} else {
+		vtss_io_write( M2_BLK_MACS, ppn, 
+		C1_GFPT_FRM_LEN, gs->frame_length);
+	}
+
+	/* GFPT header */
+	vtss_io_write( M2_BLK_MACS, ppn, C1_GFPT_HEAD_ENA,
+			(ulong)(((gs->egress_header_expect)? 1<<1:0) |
+			((gs->ingress_header_insert)? 1:0)));
+
+	/* Error correction */
+	vtss_io_write( M2_BLK_MACS, ppn, C1_GFPT_BIT_ERR_CORR,
+		(ulong)((gs->egress_err_corr == VTSS_GFPT_DISABLE_ERR)? 0 : 
+		(1 | (gs->egress_err_corr<<1)) & 0x7));
+
+	/* GFP enable */
+	vtss_io_write( M2_BLK_MACS, ppn, C1_GFPT_CONFIG, 
+		(ulong)((gs->gfpt_en)? 1:0));
+
+	return VTSS_OK;
+}
+
+
+/******************************************************************************
+ * Description: Get default setting for GFP-T handling in Campbell-I
+ *
+ * \param     : vtss_gfpt_setup_t* gs
+ *              vtss_port_interface_mode_t  mode
+ *
+ * \return    : VTSS_OK               
+ *              VTSS_WRONG_PARAMETER
+ **************************************************************************kbp*/
+vtss_rc vtss_gfpt_setup_get_default_values( vtss_gfpt_setup_t* gs,
+		vtss_port_interface_mode_t mode)
+{
+
+	gs->gfpt_en = TRUE;
+	gs->interface_mode = mode;
+	gs->rate_padding = 0;
+	gs->egress_err_corr = VTSS_GFPT_FORWARD_ERR; /* Let 
+			uncorretable error come through */
+	gs->source_mode_en = FALSE; /* Let Campbell-I 
+		deliver the clock source for TBI */
+
+	/* Setup parameters specific for the client signal  */
+	switch (gs->interface_mode.speed) {
+		case VTSS_SPEED_ETH_GFPT:
+			gs->threshold_level = 14;
+			gs->rate_period = 12;
+			gs->rate_max_delta = 1;
+			gs->rate_min_idles = 3;
+			gs->frame_length = 95;
+			gs->ingress_header_insert = TRUE;
+			gs->egress_header_expect = TRUE;
+			break;
+		case VTSS_SPEED_2FC_GFPT: /* 6    2Gbit/s Fibre Channel */
+		case VTSS_SPEED_1FC_GFPT: /* 7    1Gbit/s Fibre 
+					Channel or FICON*/
+		case VTSS_SPEED_FC2_GFPT: /* 8    Gbit/s Fibre Channel */
+		case VTSS_SPEED_FC4_GFPT: /* 9    Gbit/s Fibre Channel */
+			gs->threshold_level = 12;
+			gs->rate_period = 12;
+			gs->rate_max_delta = 1;
+			gs->rate_min_idles = 2;
+			gs->frame_length = 13;
+			gs->ingress_header_insert = FALSE;
+			gs->egress_header_expect = FALSE;
+			break;
+		case VTSS_SPEED_ESC_GFPT: /* 10 200Mbit/s ESCON or SBCON */
+			gs->threshold_level = 8;
+			gs->rate_period = 10;
+			gs->rate_max_delta = 2;
+			gs->rate_min_idles = 2;
+			gs->frame_length = 1;
+			gs->ingress_header_insert = TRUE;
+			gs->egress_header_expect = TRUE;
+			break;
+		case VTSS_SPEED_DVB_GFPT: /* 11 270Mbit/s DVB ASI */
+			gs->threshold_level = 10;
+			gs->rate_period = 10;
+			gs->rate_max_delta = 2;
+			gs->rate_min_idles = 2;
+			gs->frame_length = 2;
+			gs->ingress_header_insert = TRUE;
+			gs->egress_header_expect = TRUE;
+			break;
+			/* Error - wrong client */
+		default:
+			return VTSS_WRONG_PARAMETER;
+	}
+
+	return VTSS_OK;
+}
+
+
+/****************************************************************************/
+/*                                                                          */
+/*  End of file.                                                            */
+/*                                                                          */
+/****************************************************************************/
+
+
+
diff --git a/drivers/net/rmi_spi4/vitesse_highlevel.h b/drivers/net/rmi_spi4/vitesse_highlevel.h
new file mode 100644
index 0000000..7bdc58f
--- /dev/null
+++ b/drivers/net/rmi_spi4/vitesse_highlevel.h
@@ -0,0 +1,1388 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/************************************************************-*- mode: C -*-*/
+/*                                                                          */
+/*           Copyright (C) 2003 Vitesse Semiconductor Corporation           */
+/*                           All Rights Reserved.                           */
+/*                                                                          */
+/****************************************************************************/
+/*                                                                          */
+/*                            Copyright Notice:                             */
+/*                                                                          */
+/*  Unpublished rights reserved under the copyright laws of the             */
+/*  United States of America, other countries and international treaties.   */
+/*  The software is provided without fee.                                   */  
+/*  Permission to use,  copy, store, modify, disclose, transmit or          */
+/*  distribute the software is granted, provided that this copyright        */
+/*  notice must appear in any copy, modification, disclosure,               */
+/*  transmission or distribution of the software.                           */
+/*  Vitesse Semiconductor Corporation retains all ownership, copyright,     */
+/*  trade secret and proprietary rights in the software.                    */
+/*  THIS SOFTWARE HAS BEEN PROVIDED "AS IS," WITHOUT EXPRESS OR IMPLIED     */
+/*  WARRANTY INCLUDING, WITHOUT LIMITATION, IMPLIED WARRANTIES OF           */
+/*  MERCHANTABILITY, FITNESS FOR A PARTICULAR USE AND NON-INFRINGEMENT.     */
+/*                                                                          */
+/****************************************************************************/
+/*                                                                          */
+/*                                                                          */
+/*  vitesse_highlevel.h  -- API functions and data structures for MAC       */
+/*                          devices.                                        */
+/*                                                                          */
+/*                                                                          */
+/*  $Id: vitesse_highlevel.h,v 1.1.2.4 2006-09-28 01:24:16 nphilips Exp $           */
+/*                                                                          */
+/****************************************************************************/
+#ifndef _VITESSE_HIGHLEVEL_H
+#define _VITESSE_HIGHLEVEL_H 1
+
+
+
+/******************************************************************************/
+/***        Common Type Definitions                  **************************/
+/******************************************************************************/
+
+#include <linux/types.h>
+#include "vitesse_common.h"
+
+
+
+/******     Return codes   ****************************************************/
+typedef int vtss_rc;
+
+#define VTSS_OK                        0     /* rc>=0 means OK */
+/* General warnings */
+#define VTSS_WARNING                (-0x01)  /* Error, but fixed by API. */
+/* General errors */
+#define VTSS_UNSPECIFIED_ERROR      (-0x02)
+#define VTSS_NOT_IMPLEMENTED        (-0x03)
+#define VTSS_INVALID_PARAMETER      (-0x04)
+#define VTSS_DATA_NOT_READY         (-0x05)
+#define VTSS_PORT_NOT_MAPPED        (-0x06)
+#define VTSS_FEATURE_NOT_SUPPORTED  (-0x07)
+#define VTSS_WRONG_PARAMETER        (-0x08)
+#define VTSS_MAJOR_MODE_NOT_SET     (-0x09)
+#define VTSS_WRONG_MAJOR_MODE       (-0x0A)
+#define VTSS_MIIM_CHANNEL_BUSY      (-0x0C)
+#define VTSS_PHY_READ_ERROR         (-0x0D)
+#define VTSS_PHY_NOT_MAPPED         (-0x0E)
+#define VTSS_PHY_ABILITY            (-0x0F)
+#define VTSS_BIST_CMD_FAILED        (-0x10)
+#define VTSS_BIST_TEST_FAILED       (-0x11)
+
+
+/******************************************************************************/
+/***        Type definitions common for 1G and 10G MAC ports   ****************/
+/******************************************************************************/
+typedef struct _vtss_mac_t {
+  uchar addr[6]; /* Network byte order */
+} vtss_mac_t;
+
+
+typedef enum _vtss_speed_t {
+  VTSS_SPEED_UNDEFINED,
+  VTSS_SPEED_10M,      /* 1   10Mbit/s Ethernet */
+  VTSS_SPEED_100M,     /* 2  100Mbit/s Ethernet */
+  VTSS_SPEED_1G,       /* 3    1Gbit/s Ethernet */
+  VTSS_SPEED_10G,      /* 4   10Gbit/s Ethernet */
+  VTSS_SPEED_ETH_GFPT, /* 5    1Gbit/s Ethernet */
+  VTSS_SPEED_FC2_GFPT, /* 6    Gbit/s Fibre Channel */
+  VTSS_SPEED_FC4_GFPT, /* 7    Gbit/s Fibre Channel */
+  VTSS_SPEED_1FC_GFPT, /* 8    1Gbit/s Fibre Channel or FICON*/
+  VTSS_SPEED_2FC_GFPT, /* 9    2Gbit/s Fibre Channel */
+  VTSS_SPEED_ESC_GFPT, /* 10 200Mbit/s ESCON or SBCON */
+  VTSS_SPEED_DVB_GFPT  /* 11 270Mbit/s DVB ASI */
+} vtss_speed_t;
+
+
+/* In egress direction it is possible to alter FCS in those frames that 
+   were inserted in the stream without FCS, for ex. by the host 
+   
+   For this feature to work FCS check done in the SPI4 block must be 
+   disabled.
+*/
+typedef enum _vtss_fcs_modify_t {
+  VTSS_FCS_DO_NOTHING,
+  VTSS_FCS_UPDATE,
+  VTSS_FCS_ADD
+} vtss_fcs_modify_t;
+
+
+/******************************************************************************/
+/***        Major mode type definitions              **************************/
+/******************************************************************************/
+/* ----- TBD: mode detailed description of major modes  ------- */
+typedef enum _vtss_mac_major_mode_t {
+  VTSS_MAC_MAJOR_MODE_UNDEFINED,      /* After the reset */
+  VTSS_MAC_MAJOR_MODE_SPI4_1G,        /* SPI4 <-> 10x1G */
+  VTSS_MAC_MAJOR_MODE_SPI4_10G,       /* SPI4 <-> 1x10G */
+  VTSS_MAC_MAJOR_MODE_10G_1G_AGGR,    /* single chip aggr */
+  VTSS_MAC_MAJOR_MODE_10G_1G_TRUNK,   /* single chip trunking */
+  VTSS_MAC_MAJOR_MODE_SPI4_10G_AGGR,  /* */
+  VTSS_MAC_MAJOR_MODE_SPI4_10G_TRUNK  /* */
+} vtss_mac_major_mode_t;
+
+
+/******************************************************************************/
+/***        Device Specific Configuration                 *********************/
+/***        may be moved to a device specific .h file     *********************/
+/******************************************************************************/
+
+/* Time to wait after a reset in nanoseconds */
+#define VTSS_T_RESET                     2000000L
+
+#if defined MEIGS2 || defined VSC7321
+#define VTSS_MAX_INGRESS_FIFO_SIZE       (128*1024)
+#define VTSS_MAX_EGRESS_FIFO_SIZE        (128*1024)
+#elif defined CAMPBELL || defined VSC7331 || defined MEIGS2E || defined VSC7323
+/* Meigs2e and Campbell have 3Mbit ingress fifo, egress fifo is the same */
+#define VTSS_MAX_INGRESS_FIFO_SIZE       (3*128*1024)
+#define VTSS_MAX_EGRESS_FIFO_SIZE        (128*1024)
+#endif
+
+
+#define M2_TEST_FIFO_NORMAL              0x0
+#define M2_TEST_FIFO_RX_STOP             0x1
+#define M2_TEST_FIFO_CLR                 0x2
+#define M2_TEST_FIFO_TX_STOP             0x3
+#define M2_TEST_FIFO_REPLAY_TO_TOP       0x4
+#define M2_TEST_FIFO_REPLAY_TO_TAIL      0xC
+
+
+#define VTSS_MAX_FRAME_LENGTH            1518  /* 16-bit value */
+#define VTSS_MAX_FRAME_LENGTH_MASK       0xFFFF
+#define VTSS_MAX_IFG_VALUE               0xF   /*  4-bit value */
+#define VTSS_IFG_MASK                    0xF
+
+/* Recommended values for interframe gaps */
+#define VTSS_IFG1_1G                     5
+#define VTSS_IFG1_100M_HDX               6
+#define VTSS_IFG1_100M_FDX               7
+#define VTSS_IFG1_10M_HDX                6
+#define VTSS_IFG1_10M_FDX                7
+
+
+#define VTSS_IFG2_1G                     1
+#define VTSS_IFG2_100M_HDX               8
+#define VTSS_IFG2_100M_FDX               11
+#define VTSS_IFG2_10M_HDX                8
+#define VTSS_IFG2_10M_FDX                11
+
+
+#define M2_1G_PORT_CLOCK_MODE_10M        0x1
+#define M2_1G_PORT_CLOCK_MODE_100M       0x2
+#define M2_1G_PORT_CLOCK_MODE_1G_GMII    0x3
+#define M2_1G_PORT_CLOCK_MODE_1G_SERDES  0x4
+#ifndef VSC7321
+#define M2E_1G_PORT_CLOCK_MODE_TBI       0x5
+#endif
+
+#define M2_1G_PORT_CLOCK_MODE_MASK       0x7
+
+
+/* Order of bytes in a word and bits in a byte */
+#define M2_BIG_END_BYTE_BIG_END_BIT      0x99999999
+#define M2_LTL_END_BYTE_BIG_END_BIT      0x81818181
+
+#define M2_BIG_END_BYTE_LTL_END_BIT      0x18181818
+#define M2_LTL_END_BYTE_LTL_END_BIT      0x00000000
+
+
+/**/
+#define M2_SW_GLOBAL_RESET               0x80000001
+
+/* Some default values */
+#define VTSS_PORT_1G_TX_PAUSE_VALUE      ((ushort)0xFF)
+#define VTSS_PORT_1G_TX_PAUSE_MASK       0xFFFF   /* 16bit field */
+/* #define VTSS_PORT_1G_TX_PAUSE_XON_XOFF   FALSE */
+
+#define VTSS_PORT_10G_TX_PAUSE_VALUE      ((ushort)0xFF)
+#define VTSS_PORT_10G_TX_PAUSE_MASK       0xFFFF   /* 16bit field */
+/* #define VTSS_PORT_10G_TX_PAUSE_XON_XOFF   FALSE */
+
+
+#define VTSS_SPI4_BURST_SIZE     4
+#define VTSS_SPI4_MAX_BURST_1    8
+#define VTSS_SPI4_MAX_BURST_2    8
+
+#define VTSS_SPI4_OUTPUT_FREQ_390MHZ   390
+#define VTSS_SPI4_OUTPUT_FREQ_312MHZ   312
+#define VTSS_SPI4_OUTPUT_FREQ_195MHZ   195
+#define VTSS_SPI4_OUTPUT_FREQ_156MHZ   156
+
+
+/* Meigs2 physical port numbering */
+#define M2_PHYS_PORT_1G_MIN   0
+#define M2_PHYS_PORT_1G_MAX   9
+
+#define M2_PHYS_PORT_10G     10
+
+
+/* Default values for preamble bit position */
+/*     same values as in the datasheet      */
+#define M2_PREAMBLE_BIT0_POS   0x37
+#define M2_PREAMBLE_BIT1_POS   0x36
+#define M2_PREAMBLE_BIT2_POS   0x35
+#define M2_PREAMBLE_BIT3_POS   0x34
+
+
+/* Default values for burst size from FIFO to the ouput module */
+#define VTSS_FIFO_DEFAULT_BURST_SIZE_TOWARDS_1G_PORT   1
+#define VTSS_FIFO_DEFAULT_BURST_SIZE_TOWARDS_10G_PORT  1
+#define VTSS_FIFO_DEFAULT_BURST_SIZE_TOWARDS_SPI4_2    4
+
+
+#define VTSS_SHAPER_BITRATE_UNIT_PER_PORT   152588
+#define VTSS_SHAPER_BITRATE_UNIT_PER_LINK   305176 
+#define VTSS_SHAPER_LEAKY_BUCKET_UNIT          128
+
+
+/* GPIO number: VTSS_GPIO_NO_START..(VTSS_GPIO_NO_END-1) */
+typedef uint vtss_gpio_no_t;
+
+#define VTSS_GPIOS (16)
+#define VTSS_GPIO_NO_START ((vtss_gpio_no_t)0)
+#define VTSS_GPIO_NO_END   (VTSS_GPIO_NO_START+VTSS_GPIOS)
+
+
+
+/******************************************************************************/
+/***        Default Device Configuration             **************************/
+/******************************************************************************/
+
+
+/*-------        Mapping of logical into physical ports           ------------*/
+/* Port Number: 1..VTSS_PORTS */
+typedef uint vtss_port_no_t;    /* VTSS_PORT_NO_START..(VTSS_PORT_NO_END-1) */
+
+#define VTSS_PORTS              (10+1)
+#define VTSS_PORTS_1G           10
+#define VTSS_PORTS_10G          1 /* How many of the VTSS_PORTS are 10G ports */
+#define VTSS_CHIP_PORTS         11 /* Number of ports inside chip */
+#define VTSS_CHIP_PORT_IS_10G(chip_port) (chip_port == 10)
+
+#define VTSS_PORT_NO_START      ((vtss_port_no_t)1) /* The first logical port 
+						       number is 1 */
+#define VTSS_PORT_NO_END        (VTSS_PORT_NO_START+VTSS_PORTS)
+#define VTSS_PORT_ARRAY_SIZE    VTSS_PORT_NO_END
+
+#define VTSS_PORT_IS_PORT(x)    (x>=VTSS_PORT_NO_START && x<VTSS_PORT_NO_END)
+
+/* MeigsII/MeigsIIe/Campbell port mapping: 0..9 -- 10/100/1000M, 10 -- 10G */
+
+
+
+
+/******************************************************************************/
+/***        General Device Configuration             **************************/
+/******************************************************************************/
+
+/* 1G ports of a MAC device are known to the user under the numbers on the 
+   front panel of the final system. This numeration is not necessarily the same 
+   as the internal numeration from 0..MAX_PORT_NUMBER. Thus the need for 
+   mapping. Terminology: logical port number -- the number on the front panel,
+   physical "chip_port" port number -- internal number from 0 to 
+   MAX_1G_PORT_NUMBER. Some additional information such as the address of the 
+   corresponding PHY device and the number of a MIIM controller to use to 
+   communicate with the PHY device is also in the mapping table */
+
+typedef struct _vtss_mapped_port_t {
+    int     chip_port;          /* Physical port. Set to -1 if not in use. */
+    int     miim_controller;    /* Set to 0 or 1. Set to -1 if not in use. */
+    int     phy_addr;           /* Ignored if miim_controller==-1. */
+} vtss_mapped_port_t;
+
+
+/* 
+   Set physical addresses of logical ports. Index is logical port_no. 
+   The mapping table must be initialized early in the initialization phase,
+   as most funcitons use logical port number as an argument and get the
+   matching physical port from the table.
+*/
+vtss_rc vtss_port_map_set( const vtss_mapped_port_t mapped_ports[VTSS_PORT_ARRAY_SIZE] );
+
+BOOL vtss_port_mapped( const vtss_port_no_t port_no );
+
+
+/*******************************************************************************
+
+  Function vtss_major_mode_set( ).
+
+  Prepares the system to run in one of the major modes.
+  This function must be called only once after reset. If the function is 
+  called when the system is up and running it will return an error.
+  It is not allowed to call this function with VTSS_MAC_MAJOR_MODE_UNDEFINED
+  as an argument.
+
+*******************************************************************************/
+vtss_rc vtss_major_mode_set( vtss_mac_major_mode_t mm);
+
+
+
+/******************************************************************************/
+/***        System Configuration                     **************************/
+/******************************************************************************/
+typedef struct vtss_system_setup_t {
+
+  BOOL big_endian;      /* TRUE -- CPU interface runs as big-endian */
+  uint si_dummy_bytes;  /* number of dummy bytes that will be inserted in the 
+			   reply before valid data when serial interface is used
+			   at high frequency. Set to 0 if not used */
+
+  /* serdes_ref_clk_external must be TRUE when using VSC7323 or VSC7331 */
+  BOOL serdes_ref_clk_external; /* TRUE serdes ref clk is external, 
+				   FALSE -- internal */
+
+  BOOL system_ref_clk_extern;  /* TRUE  -- one of the GPIO pins is used as 
+				  system clock input 
+				  FALSE -- internal source is used for the 
+				  system clock (default)
+			       */
+
+  BOOL single_chip_mode;  /* TRUE -- 1x10G<->10x1G mode is used 
+			     FALSE -- all other modes */
+
+  BOOL rx_chain_mode_10G; /* TRUE -- when in 10G<->SPI4.2 mode 
+		         FALSE -- all other modes */
+
+} vtss_system_setup_t;
+
+
+/*
+  Function vtss_system_setup()
+
+  Performs most basic initialization of the chip.
+  The function must be called after start-up or chip reset.
+
+
+  Arguments:
+       psystem   pointer to a structure with configuration data
+
+  Return code:
+       VTSS_OK   if operation completed successfully
+       
+ */
+vtss_rc vtss_system_setup( vtss_system_setup_t *psystem);
+
+/* 
+   This is a supplementary function. It configures a structure referenced 
+   by the pointer to the default values for the chosen major mode.
+   After that the user may modify the fields of the structure for 
+   fine-tuning of the system and than call the vtss_system_setup() function.
+*/
+vtss_rc vtss_system_setup_get_default_values( vtss_system_setup_t *psystem,
+					   vtss_mac_major_mode_t major_mode);
+
+
+/* vtss_chip_reset() performs a software reset of the chip */
+void vtss_chip_reset(void);
+
+
+/* vtss_get_chip_id() returns the content of the chip identification register */
+ulong vtss_chip_id_get(void);
+
+
+
+/******************************************************************************/
+/***        FIFO Configuration                       **************************/
+/******************************************************************************/
+typedef struct _vtss_fifo_block_t {
+  uint top;       /* 2Kbytes granularity */
+  uint bottom;
+} vtss_fifo_block_t;
+
+
+/* Flow control watermarks */
+typedef struct _vtss_fifo_fc_watermarks_t {
+  uint low_watermark; /* 32 bytes granularity */
+  uint high_watermark;
+} vtss_fifo_fc_watermarks_t;
+
+
+/* Cut-through threshold */
+typedef struct _vtss_fifo_cut_through_mode_t {
+  BOOL cut_through_enable;  /* If FALSE -- FIFO runs in store-forward mode */
+  uint threshold_value;
+} vtss_fifo_cut_through_mode_t;
+
+
+/* Ageing mode */
+typedef struct _vtss_fifo_ageing_t {
+  BOOL enable;    /* enables ageing timer */
+  uint interval;  /* ageing interval */
+} vtss_fifo_ageing_t;
+
+
+/* 
+   Used for one-time complete setup of the fifo. Usually used after reset,
+   Using this structure the user can alter the default setup of the block.
+*/
+/* May be used to initialize both ingress and egress fifo */
+typedef struct vtss_fifo_setup_t {
+
+  vtss_fifo_block_t       fifo_port_area[VTSS_PORT_NO_START+VTSS_PORTS_1G];
+  vtss_fifo_fc_watermarks_t fifo_port_wm[VTSS_PORT_NO_START+VTSS_PORTS_1G];
+
+  /* cut-through mode/threshold. If not enabled then store-forward */
+  vtss_fifo_cut_through_mode_t    thrhld[VTSS_PORT_NO_START+VTSS_PORTS_1G];
+
+  vtss_fifo_ageing_t ageing;
+
+  /* */
+  BOOL norm_hdr_used;
+  BOOL prm_hdr_used;
+
+  /**/
+  ulong output_port_offset;
+  ulong input_port_offset;
+
+} vtss_fifo_setup_t;
+
+
+/*-----------------  FIFO setup funcitons   ----------------------------------*/
+
+/*
+  Function vtss_fifo_setup()
+
+  Initializes the FIFO block based on the information in the provided 
+  structures. If the pointer to the structure is set to NULL, the corresponding
+  FIFO will not be initialized (it will be left in its current state).
+
+  The function must be called after start-up and may be called at run-
+  time to reconfigure the FIFO. 
+
+  Note: port mapping table must be initialized.
+
+  Arguments:
+       ps_ingress   pointer to a structure for the ingress fifo
+       ps_egress   pointer to a structure for the egress fifo
+
+  Return code:
+       VTSS_OK   if operation completed successfully
+       
+ */
+vtss_rc vtss_fifo_setup( vtss_fifo_setup_t *ps_ingress, 
+			 vtss_fifo_setup_t *ps_egress);
+
+/* 
+   This is a supplementary function. It configures a structure referenced 
+   by the pointer to the default values for the chosen major mode.
+   After that the user may modify the fields of the structure for 
+   fine-tuning of the system and then call the vtss_fifo_setup() function.
+*/
+vtss_rc vtss_fifo_setup_get_default_values( vtss_fifo_setup_t *ps_ingress,
+					    vtss_fifo_setup_t *ps_engress,
+					    vtss_mac_major_mode_t major_mode);
+
+/*-----------------  Run-time funcitons   ------------------------------------*/
+/* 
+   Select store-forward or cut-through mode of fifo for a specified logical 
+   port 
+*/
+vtss_rc vtss_fifo_thrhld_set( vtss_port_no_t portnum, 
+			      vtss_fifo_cut_through_mode_t *pctt_ingress,
+			      vtss_fifo_cut_through_mode_t *pctt_egress);
+
+/*
+  Configure watermarks for a given logical port
+*/
+vtss_rc vtss_fifo_watermarks_set( vtss_port_no_t portnum,
+				  vtss_fifo_fc_watermarks_t *pwm_ingress,
+				  vtss_fifo_fc_watermarks_t *pwm_egress);
+
+
+
+/******************************************************************************/
+/***      10M/100M/1G  Ethernet Port Configuration   **************************/
+/******************************************************************************/
+/* ================================================================= *
+ *  Port
+ * ================================================================= */
+
+/* - Port Setup (Operational) -------------------------------------- */
+
+/* The different interfaces for connecting MAC and PHY. */
+typedef enum _vtss_port_interface_t {
+    VTSS_PORT_INTERFACE_NO_CONNECTION,  /* No connection */
+    VTSS_PORT_INTERFACE_MII,            /* MII */
+    VTSS_PORT_INTERFACE_GMII,           /* GMII */
+    VTSS_PORT_INTERFACE_RGMII,          /* RGMII */
+    VTSS_PORT_INTERFACE_TBI,            /* TBI */
+    VTSS_PORT_INTERFACE_SERDES,         /* SERDES */
+    VTSS_PORT_INTERFACE_XAUI            /* XAUI */
+} vtss_port_interface_t;
+
+
+typedef struct _vtss_port_interface_mode_t {
+    vtss_port_interface_t   interface_type; /* not just "interface" because it 
+					       is a reserved word in C++ */
+    vtss_speed_t            speed;
+} vtss_port_interface_mode_t;
+
+
+typedef struct _vtss_flowcontrol_setup_t {
+    BOOL                obey;       /* Should PAUSE frames be obeyed. */
+    BOOL                generate;   /* Show flow control:
+				       fdx: PAUSE frames, 
+				       hdx: backpressure  be generated. */
+    vtss_mac_t          smac;
+} vtss_flowcontrol_setup_t;
+
+
+/* Interframe gaps */
+typedef struct _vtss_frame_gaps_t {
+
+    uint    ifg1;
+    uint    ifg2;
+
+} vtss_frame_gaps_t;
+
+
+
+/* Advertisement Word (Refer to IEEE 802.3 Clause 37):
+ *  MSB                                                                         LSB
+ *  D15  D14  D13  D12  D11  D10   D9   D8   D7   D6   D5   D4   D3   D2   D1   D0 
+ * +----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+
+ * | NP | Ack| RF2| RF1|rsvd|rsvd|rsvd| PS2| PS1| HD | FD |rsvd|rsvd|rsvd|rsvd|rsvd|
+ * +----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+
+ */
+
+/* enum used in vtss_autoneg_1000base_x_config_t */
+typedef enum _vtss_autoneg_1000base_x_remote_fault_t {
+                                     /* RF2 */  /* RF1 */
+    VTSS_1000BASEX_LINK_OK          = (( 0 <<1) | ( 0 <<0)),
+    VTSS_1000BASEX_OFFLINE          = (( 1 <<1) | ( 0 <<0)),
+    VTSS_1000BASEX_LINK_FAILURE     = (( 0 <<1) | ( 1 <<0)),
+    VTSS_1000BASEX_AUTONEG_ERROR    = (( 1 <<1) | ( 1 <<0))
+} vtss_autoneg_1000base_x_remote_fault_t;
+
+typedef struct _vtss_autoneg_1000base_x_advertisement_t {
+    BOOL                                    fdx;
+    BOOL                                    hdx;
+    BOOL                                    symmetric_pause;    /* a.k.a. PAUSE (PS1) */
+    BOOL                                    asymmetric_pause;   /* a.k.a. ASM_DIR (PS2) */
+    vtss_autoneg_1000base_x_remote_fault_t  remote_fault;
+    BOOL                                    acknowledge;
+    BOOL                                    next_page;
+} vtss_autoneg_1000base_x_advertisement_t;
+
+
+typedef struct _vtss_pcs_autoneg_control_t {
+    BOOL                                    enable;
+    vtss_autoneg_1000base_x_advertisement_t advertisement;
+} vtss_pcs_autoneg_control_t;
+
+
+
+/* Used for the initial setup of the PCS module */
+typedef struct _vtss_pcs_control_t {
+
+  BOOL   disable_lss_on_gpio14;
+
+  BOOL   disable_link_timer;
+  BOOL   debug_link_timer_select;
+
+  BOOL   signal_detect_polarity_low;
+  BOOL   signal_detect_enable;
+
+  BOOL   show_complete_link_down_counter;
+
+  BOOL   pcs_aneg_sw_resolve;
+
+  BOOL   pcs_autoneg_enable;
+  BOOL   pcs_autoneg_restart;
+
+  vtss_autoneg_1000base_x_advertisement_t advertisement;
+
+} vtss_pcs_control_t;
+
+
+/* Used for the setup of the Serdes module */
+#define VTSS_SERDES_CONFIG_WORD        0x0000003E
+/* the following two values to be written to the SERDES_TEST register */
+#define VTSS_SERDES_RESET_AND_ENABLE   0x00000003
+#define VTSS_SERDES_ENABLE             0x00000023
+
+
+/* Port setup, which may change dynamically, e.g. after auto-negotiation */
+typedef struct _vtss_port_setup_t {
+  vtss_port_interface_mode_t  interface_mode;
+  BOOL                        fdx;                /* Full duplex: TRUE, 
+						     Half duplex: FALSE */
+  vtss_flowcontrol_setup_t    flowcontrol;
+  vtss_frame_gaps_t           frame_gaps;
+  BOOL                        enable_tx_pause_xon_xoff;
+  uint                        tx_pause_value;
+  uint                        maxframelength; /* Max frame length. */
+  BOOL                        vlan_aware;
+  BOOL                        drop_on_length_error;
+  BOOL                        crc_update;
+  vtss_fcs_modify_t           fcs_modify;
+  BOOL                        invert_gtx_tx_clock;  /* HW related */
+  BOOL                        invert_rx_clock;      /* HW related */
+  BOOL norm_hdr_insert;
+  BOOL prm_hdr_insert;
+  uint prm_hdr_value;
+  BOOL norm_hdr_expect;
+  BOOL prm_hdr_expect;
+} vtss_port_setup_t;
+
+
+/* Setup 10M/100M/1G port */
+vtss_rc vtss_port_setup( vtss_port_no_t portnum, vtss_port_setup_t* psetup);
+
+/* 
+   Supplementary function: fills the structure referenced by the pointer 
+   with the default values for a given major_mode.
+
+   Requires global port mapping table to be initialized
+*/
+vtss_rc vtss_port_setup_get_default_values( vtss_port_setup_t* psetup,
+					 vtss_mac_major_mode_t major_mode);
+
+/*----------------  Run-time funcitons  ---------------------------------------*/
+/* Configure speed and duplex mode of a 10M/100M/1G port */
+/*
+  Arguments:
+      portnum   logical port number
+      speed     10M, 100M, 1G
+      fdx       TRUE - full duplex, FALSE -- half duplex
+ */
+vtss_rc vtss_port_set_mode( vtss_port_no_t portnum, vtss_speed_t speed, 
+			    BOOL fdx);
+
+/* Enable/disable rx, tx or both in a 10M/100M/1G port */
+vtss_rc vtss_port_set_enable( vtss_port_no_t portnum, BOOL rx_en, BOOL tx_en);
+
+
+/* Set CRC adding/updating mode */
+/* Only 10/100/1000 ports have this feature -- done in the denormalizer */
+vtss_rc vtss_port_fcs_modify( vtss_port_no_t portnum, vtss_fcs_modify_t mc);
+
+/* 
+   Discard/do_not_discard  Ethernet frames with wrong FCS in ingress direciton
+
+   Arguments:
+        portnum   logical port number
+	check     TRUE   -- frames with wrong FCS are discarded (default)
+	          FALSE  -- frames with wrong FCS are forwarded upstream
+*/
+vtss_rc vtss_port_check_fcs( vtss_port_no_t portnum, BOOL check);
+
+
+/* Allow pause frames pass through the device. By default 10M/100M/1G block
+   prevents propagation of pause frames through the device.
+ */
+vtss_rc vtss_port_forward_pause_frames( vtss_port_no_t portnum, BOOL allow);
+
+
+
+/*
+  obey -- obeys pause frames from external Eth client 
+  generate -- generate pause frames/backpressure upon request from the 
+              destination (FIFO or the host interface)
+
+  If fc_obey AND fc_generate are set to FALSE, then flow control is disabled
+
+
+ */
+vtss_rc vtss_port_flow_control_mode( vtss_port_no_t port_num, 
+				     BOOL fc_obey, 
+				     BOOL fc_generate);
+
+
+
+/******************************************************************************/
+/***      10G  Ethernet Port Configuration           **************************/
+/******************************************************************************/
+
+/* 10G Port setup */
+typedef struct _vtss_10Gport_setup_t {
+  vtss_port_interface_mode_t  interface_mode;
+
+  vtss_flowcontrol_setup_t    flowcontrol;
+
+  uint                        maxframelength; /* Max frame length. */
+
+  BOOL                        enable_tx_pause_xon_xoff;
+  uint                        tx_pause_value;
+
+  BOOL                        vlan_aware;
+  BOOL                        pace_mode;
+  BOOL                        drop_on_length_error;
+  BOOL                        drop_in_range_error;
+
+  /* Extended End-of-packet and Start-of-packet checks */
+  BOOL                        ext_eop_check_enable;
+  BOOL                        ext_sop_check_enable;
+
+  vtss_fcs_modify_t           fcs_modify;
+
+
+  /* Start-of-frame delimiter check */
+  /* Must be disabled, ie set to FALSE, when using preamble trunking */
+  BOOL sfd_check;
+
+  /* Use of the headers */
+  BOOL norm_hdr_insert;
+  BOOL prm_hdr_insert;
+
+  BOOL norm_hdr_expect;
+  BOOL prm_hdr_expect;
+
+
+} vtss_10Gport_setup_t;
+
+
+/* Setup 10G port */
+vtss_rc vtss_10Gport_setup( vtss_port_no_t port_num, vtss_10Gport_setup_t* psetup);
+
+/* 
+   Supplementary function: fills the structure referenced by the pointer 
+   with the default values for a given major_mode.
+
+*/
+vtss_rc vtss_10Gport_setup_get_default_values( vtss_10Gport_setup_t* psetup,
+					    vtss_mac_major_mode_t major_mode);
+
+/*----------------  Run-time funcitons  ---------------------------------------*/
+/* Enable/disable rx, tx or both in a 10G port */
+vtss_rc vtss_10Gport_set_enable( vtss_port_no_t port_num, 
+				 BOOL rx_en, BOOL tx_en);
+
+
+/* Set CRC adding/updating mode */
+vtss_rc vtss_10Gport_fcs_modify( vtss_port_no_t port_num, vtss_fcs_modify_t mc);
+
+
+
+/* Allow pause frames pass through the device. By default 10G block
+   prevents propagation of pause frames through the device.
+ */
+vtss_rc vtss_10Gport_forward_pause_frames( vtss_port_no_t port_num, BOOL allow);
+
+
+
+/*
+  obey -- obeys pause frames from external Eth client 
+  generate -- generate pause frames/backpressure upon request from the 
+              destination (FIFO or the host interface)
+
+  If fc_obey AND fc_generate are set to FALSE, then flow control is disabled
+
+
+ */
+vtss_rc vtss_10Gport_flow_control_mode( vtss_port_no_t port_num, 
+					BOOL fc_obey, 
+					BOOL fc_generate);
+
+/*
+  Once a 10G Base-X optical module is connected to the XAUI port,
+  this function can use to drive an GPIO connected LED to visualize 
+  signal detection/link status. The CPU must poll this function.
+ */
+BOOL vtss_10Gport_signal_detect(void);
+
+
+/******************************************************************************/
+/***        Host Interface (SPI-4.2) Configuration     ************************/
+/******************************************************************************/
+
+/*--        type definitions                           -----------------------*/
+
+typedef enum _vtss_spi4_sch_mode_t {
+  /* Controled by Ingress(Egress)_Fifo_Ctrl register */
+  VTSS_SPI4_BURST_MODE_WITH_HEADER, /* when user wants header on SPI4 */
+  VTSS_SPI4_BURST_MODE,  /* Burst interleaved output */
+  VTSS_SPI4_FRAME_MODE   /* Frame interleaved output */
+} vtss_spi4_sch_mode_t;
+
+
+typedef enum _vtss_spi4_training_mode_t {
+  /* VTSS_SPI4_TRAINING_AUTO not used in Meigs-II */
+  VTSS_SPI4_TRAINING_AUTO, /* issue training sequences in response to all '11's
+			     in the status channel */
+  VTSS_SPI4_TRAINING_OFF,  /* don't issue training sequences */
+  VTSS_SPI4_TRAINING_FORCE /* send training sequences continiously */
+
+} vtss_spi4_training_mode_t;
+
+
+typedef struct _vtss_spi4_setup_t {
+
+  /* 
+     This stucture gives a possibility to alter the default configuration of
+     the spi4 block after reset according to end-user needs.
+  */
+
+  vtss_spi4_sch_mode_t sch_mode;
+  uint burst_size;
+  uint maxburst1;
+  uint maxburst2;
+
+  /* Parameters of the training mode (only in ingress direction) */
+  vtss_spi4_training_mode_t tm;
+  uint alpha;
+  uint tsperiod;
+
+  /* spi4 output frequency*/
+  uint spi4_output_freq; /* 390, 312, 195, 156 MHz */
+
+  /* For the description of the following four elements refer to the desription 
+     of the SPI4 misc register in the datasheet */
+  BOOL spi4_swap_ingress_data;    /* Board dependent */ /* Bit WI, SPI4 MISC reg*/
+  BOOL spi4_swap_egress_data;     /* Board dependent */ /* Bit WE, SPI4 MISC reg*/
+  BOOL spi4_data_clock_skew;      /* Board dependent */
+  BOOL spi4_status_clock_skew;    /* Board dependent */
+
+  /* calendar length is defined by number of ports */
+  BOOL	spi4_calendar_order_ascending;  /* Ascending or descending order */
+  uint	spi4_calendar_m;
+
+  /* In ingress direction */
+  BOOL norm_hdr_strip;
+
+  /* In egress direction */
+  BOOL prm_hdr_expect;
+  BOOL norm_hdr_expect;
+
+
+} vtss_spi4_setup_t;
+
+
+/*--        Setup  Funtions                            -----------------------*/
+vtss_rc vtss_spi4_setup( vtss_spi4_setup_t* ps);
+
+/* Configures a user provided structure with values default for the selected 
+   major mode.
+*/
+vtss_rc vtss_spi4_setup_get_default_values( vtss_spi4_setup_t* ps, 
+					    vtss_mac_major_mode_t mode);
+
+/*--        Run-time Functions                         -----------------------*/
+
+
+/*
+  Function vtss_spi4_fcs_check_enable()
+
+  The function turns on/off FCS check of Ehternet frames arriving from the 
+  host interface. This is done for all channels.
+
+
+  NOTE. FCS check in the SPI4 block must be OFF if the FCS modify feature is
+        used in the egress direction
+
+*/
+vtss_rc vtss_spi4_fcs_check_enable( BOOL check);
+
+
+/*
+  Function vtss_spi4_keep_norm_header()
+
+  The funciton controls whether to strip the normalised header or to keep it.
+  Usually the normalised header is stripped before the frame is sent over 
+  SPI4. However, if the remove receiver can use information in the header, 
+  keeping it may be an advantage.
+
+
+  NOTE. Works in ingress direction
+
+*/
+vtss_rc vtss_spi4_keep_norm_header( BOOL keep);
+
+
+
+/******************************************************************************/
+/***        Flow Control Configuration        *********************************/
+/******************************************************************************/
+
+/* 
+   Function device_flow_control() selects FIFO flow control mode 
+      transparent off -- filling of the FIFO causes generation of pause frames
+      transparent on  -- destination (host i/f), not FIFO, requests pause frames
+
+   Note:
+   This mode is enabled for all 10/100/1000 Eth ports simultaneously 
+*/
+vtss_rc vtss_device_transparent_flow_control_mode( BOOL ingress_enable,
+						   BOOL egress_enable);
+
+
+
+
+
+/******************************************************************************/
+/***        Statistics                                         ****************/
+/******************************************************************************/
+typedef struct _vtss_port_counters_t {
+
+  /* if a counter is not implemented in 10G or 1G module the software will 
+     return 0 */
+  ulong rx_in_bytes;
+  ulong rx_symbol_carrier;
+  ulong rx_pause;
+  ulong rx_unsup_opcode;
+
+  ulong rx_ok_bytes;
+  ulong rx_bad_bytes;
+
+  ulong rx_unicast;
+  ulong rx_multicast;
+  ulong rx_broadcast;
+  ulong rx_crc;
+  ulong rx_alignment; /* 10/100/1G mac only */
+  ulong rx_undersize;
+
+  ulong rx_fragments;
+  ulong rx_in_range_error;
+  ulong rx_out_of_range_error;
+  ulong rx_oversize;
+  ulong rx_jabbers;
+  ulong rx_size_64;
+
+  ulong rx_size_65_to_127;
+  ulong rx_size_128_to_255;
+  ulong rx_size_256_to_511;
+  ulong rx_size_512_to_1023;
+  ulong rx_size_1024_to_1518;
+  ulong rx_size_1519_to_max;
+
+  ulong rx_xgmii_prot_err; /* Only on 10G MAC port */
+
+  ulong rx_ipg_shrink;
+
+
+  ulong tx_out_bytes;
+  ulong tx_pause;
+  ulong tx_ok_bytes;
+
+  ulong tx_unicast;
+  ulong tx_multicast;
+  ulong tx_broadcast;
+
+  ulong tx_multiple_coll; /* 10/100/1G MAC only */
+  ulong tx_late_coll;     /* 10/100/1G MAC only */
+  ulong tx_xcoll;         /* 10/100/1G MAC only */
+  ulong tx_defer;         /* 10/100/1G MAC only */
+  ulong tx_xdefer;        /* 10/100/1G MAC only */
+  ulong tx_carrier_sense; /* 10/100/1G MAC only */
+
+
+  ulong tx_size_64;
+  ulong tx_size_65_to_127;
+  ulong tx_size_128_to_255;
+  ulong tx_size_256_to_511;
+  ulong tx_size_512_to_1023;
+  ulong tx_size_1024_to_1518;
+  ulong tx_size_1519_to_max;
+
+
+  ulong tx_single_coll; /* 10/100/1G MAC only */
+  ulong tx_backoff2;    /* 10/100/1G MAC only */
+  ulong tx_backoff3;    /* 10/100/1G MAC only */
+  ulong tx_backoff4;    /* 10/100/1G MAC only */
+  ulong tx_backoff5;    /* 10/100/1G MAC only */
+  ulong tx_backoff6;    /* 10/100/1G MAC only */
+  ulong tx_backoff7;    /* 10/100/1G MAC only */
+  ulong tx_backoff8;    /* 10/100/1G MAC only */
+  ulong tx_backoff9;    /* 10/100/1G MAC only */
+  ulong tx_backoff10;   /* 10/100/1G MAC only */
+  ulong tx_backoff11;   /* 10/100/1G MAC only */
+  ulong tx_backoff12;   /* 10/100/1G MAC only */
+  ulong tx_backoff13;   /* 10/100/1G MAC only */
+  ulong tx_backoff14;   /* 10/100/1G MAC only */
+  ulong tx_backoff15;   /* 10/100/1G MAC only */
+
+  ulong tx_underrun;
+
+  ulong ingress_overflow_drop;
+  ulong egress_overflow_drop;
+
+
+} vtss_port_counters_t;
+
+
+/*------------   TBD:  Error monitoring    ---------------------------------*/
+/* DIP4, sync errors, fifo ageing drop, etc.. */
+
+
+
+
+/* Clears counter for the logical port */
+vtss_rc vtss_port_counters_clear( const vtss_port_no_t port_no );
+
+/* */
+vtss_rc vtss_port_counters_get( const vtss_port_no_t  port_no,
+				vtss_port_counters_t *pcounters);
+
+
+/******************************************************************************/
+/***        MIIM(MDIO) Interface Functions           **************************/
+/******************************************************************************/
+
+#define VTSS_MIIM_READ_ATTEMPT    0xF000
+
+/* Direct miim read/write operation using miim_controller address as a 
+parameter */
+long vtss_miim_subblock_read( const uint miim_chnl, const uint phy_addr, 
+			       const uint phy_reg);
+void vtss_miim_subblock_write( const uint miim_chnl, const uint phy_addr, 
+			       const uint phy_reg, const ushort value);
+
+
+/* Indirect miim read/write operation. Accesses the PHY corresponding to the 
+   logical port number (PHY address is found via the mapping table)
+*/
+long vtss_miim_port_reg_read( const vtss_port_no_t port_no, 
+			       const uint phy_reg);
+void  vtss_miim_port_reg_write( const vtss_port_no_t port_no, 
+				const uint phy_reg, const ushort value);
+
+
+/******************************************************************************/
+/***        Policer/shaper                           **************************/
+/******************************************************************************/
+typedef ulong   vtss_kbitrate_t;
+
+#define VTSS_DISABLE_SHAPER  ((vtss_kbitrate_t)-1)
+
+vtss_rc vtss_egress_shaper_set( vtss_port_no_t port_no, vtss_kbitrate_t br,
+				ulong lb_lvl);
+vtss_rc vtss_ingress_shaper_set( vtss_port_no_t port_no, vtss_kbitrate_t br,
+				 ulong lb_lvl);
+vtss_rc vtss_egress_common_shaper_set( vtss_kbitrate_t br, ulong lb_lvl);
+vtss_rc vtss_ingress_common_shaper_set( vtss_kbitrate_t br, ulong lb_lvl);
+
+vtss_rc vtss_egress_shaper_get( vtss_port_no_t port_no, vtss_kbitrate_t *pbr, 
+				ulong *lb_lvl);
+vtss_rc vtss_ingress_shaper_get( vtss_port_no_t port_no, vtss_kbitrate_t *pbr, 
+				ulong *lb_lvl);
+vtss_rc vtss_egress_common_shaper_get( vtss_kbitrate_t *pbr, ulong *lb_lvl);
+vtss_rc vtss_ingress_common_shaper_get( vtss_kbitrate_t *pbr, ulong *lb_lvl);
+
+
+
+/******************************************************************************/
+/***        Aggregator Configuration                 **************************/
+/******************************************************************************/
+
+#define M2_AGGR_PMAP_TABLE_SIZE    256
+
+typedef struct _vtss_aggr_mode_t {
+  BOOL preamble_trunking;
+  BOOL mpls_trunking;
+  BOOL mpls_aggregation;
+  BOOL l2_aggr;
+  BOOL l3_aggr;
+  BOOL l4_aggr;
+  union {
+    struct {
+      ulong pos0;
+      ulong pos1;
+      ulong pos2;
+      ulong pos3;
+    } bit;
+    ulong mpls_bitmask;
+  } u;
+
+  BOOL norm_hdr_used;
+
+} vtss_aggr_mode_t;
+
+
+vtss_rc vtss_aggr_pmap_table_set( int index, int portnum);
+
+/* Reinitialises aggregation map table, if the port is mot mapped or disabled */
+/* it will be removed from the table, if the port has been enabled it will be */
+/* added to the table */
+vtss_rc vtss_aggr_pmap_table_initialise( void);
+
+
+/*--        Setup  Funtions                            -----------------------*/
+vtss_rc vtss_aggr_setup( vtss_aggr_mode_t* pam);
+
+/* Configures a user provided structure with values default for the selected 
+   major mode.
+*/
+vtss_rc vtss_aggr_setup_get_default_values( vtss_aggr_mode_t* pam, 
+					    vtss_mac_major_mode_t mmode);
+
+
+/******************************************************************************/
+/***        PCS Autonegotiation (Serdes and TBI)     **************************/
+/******************************************************************************/
+
+vtss_rc vtss_pcs_autoneg_control_get( const vtss_port_no_t                      port_no,
+                                      vtss_pcs_autoneg_control_t * const        control );
+
+vtss_rc vtss_pcs_autoneg_control_set( const vtss_port_no_t                      port_no,
+                                      const vtss_pcs_autoneg_control_t * const  control );
+
+vtss_rc vtss_pcs_autoneg_restart( const vtss_port_no_t  port_no );
+
+
+/* Current state of the PCS autonegotiation state machine */
+typedef enum _vtss_pcs_aneg_state_t {
+  VTSS_PCS_ANEG_STATE_IDLE,      /* Idle */
+  VTSS_PCS_ANEG_STATE_CONFIG,    /* Config (i.e. ANEG in progress) */
+  VTSS_PCS_ANEG_STATE_NOTVALID,  /*  */
+  VTSS_PCS_ANEG_STATE_DATA       /* Data */
+} vtss_pcs_aneg_state_t;
+
+typedef struct _vtss_pcs_autoneg_status_t {
+  vtss_pcs_aneg_state_t                   aneg_state;
+  BOOL                                    aneg_complete;
+  vtss_autoneg_1000base_x_advertisement_t partner_advertisement;
+} vtss_pcs_autoneg_status_t;
+
+
+
+vtss_rc vtss_pcs_autoneg_status_get( const vtss_port_no_t port_no,
+				     vtss_pcs_autoneg_status_t *paneg);
+
+
+typedef struct _vtss_pcs_status_t {
+
+  BOOL  losync;   /* loss of sync: sticky self-cleared bit. PCS sync state 
+		     machine has lost sync at least once since last read 
+		     of the register */
+  BOOL  pcs_in_sync; 
+  BOOL  signal_detected; /* signal_detected indicates that there is light 
+			    in fiber; require SD_EN in the PCS_CTRL register 
+			    to be set */
+  BOOL  jtp_lock;
+  BOOL  jtp_error;
+
+  BOOL  link_status_ok;  /* link_status:  FALSE if link has been down since 
+			    last status read */
+
+  uint  link_down_counter;  /* link down counter: 8bit counter (only 6 bits 
+			       visible), saturates when reaching 256 */
+
+  BOOL  show_ldc_top; /* if TRUE indicates that the link down counter 
+			 is 8 bit long, not 6 bit as usually */
+
+  vtss_pcs_autoneg_status_t autoneg;
+
+} vtss_pcs_status_t;
+
+#define VTSS_PCS_LINK_DOWN_COUNTER_SATURATED 255
+
+/* Returns more detailed status than vtss_pcs_autoneg_status_get */
+vtss_rc vtss_pcs_status_get( const vtss_port_no_t       port_no,
+                             vtss_pcs_status_t * const  status );
+
+
+
+/******************************************************************************/
+/***        Serdes Signal Detect Control             **************************/
+/******************************************************************************/
+vtss_rc vtss_serdes_signal_detect_setup( const vtss_port_no_t port_num,
+					 BOOL enable,
+					 BOOL sd_polarity_high,
+					 BOOL sd_source_extern);
+
+
+/*
+  Reads serdes signal detect status.
+
+  Return values 
+    VTSS_OK                    successful completion
+
+    or an error:
+    VTSS_WRONG_MAJOR_MODE
+    VTSS_MAJOR_MODE_NOT_SET
+    VTSS_PORT_NOT_MAPPED
+
+  If VTSS_OK, then if the content of psignal_detected is 
+    TRUE    signal is detected
+    FALSE   no signal detected
+
+
+*/
+vtss_rc vtss_serdes_extern_signal_detect_status_get( const vtss_port_no_t port_num,
+						     BOOL *psignal_detected);
+
+
+
+
+/******************************************************************************
+ * Description: Set GPIO direction to input or output.
+ *
+ * \param chip_no (input): Chip number (for multi chip targets only).
+ * \param gpio_no (input): GPIO pin number.
+ * \param output (input) : TRUE if output, FALSE if input.
+ *
+ * \return : Return code.
+ ******************************************************************************/
+#if defined(VTSS_CHIPS)
+vtss_rc vtss_gpio_direction_set(const vtss_chip_no_t chip_no,
+                                const vtss_gpio_no_t gpio_no,
+                                const BOOL output);
+#else
+vtss_rc vtss_gpio_direction_set(const vtss_gpio_no_t gpio_no,
+                                const BOOL output);
+#endif /* VTSS_CHIPS */
+
+
+/******************************************************************************
+ * Description: Read from GPIO input pin.
+ *
+ * \param chip_no (input): Chip number (for multi chip targets only).
+ * \param gpio_no (input): GPIO pin number.
+ *
+ * \return : TRUE if pin is high, FALSE if it is low.
+ ******************************************************************************/
+#if defined(VTSS_CHIPS)
+BOOL vtss_gpio_input_read(const vtss_chip_no_t chip_no,
+                          const vtss_gpio_no_t gpio_no);
+#else
+BOOL vtss_gpio_input_read(const vtss_gpio_no_t gpio_no);
+#endif /* VTSS_CHIPS */
+
+
+/******************************************************************************
+ * Description: Write to GPIO output pin.
+ *
+ * \param chip_no (input): Chip number (for multi chip targets only).
+ * \param gpio_no (input): GPIO pin number.
+ * \param value (input)  : TRUE to set pin high, FALSE to set pin low.
+ *
+ * \return : TRUE if pin is high, FALSE if it is low.
+ ******************************************************************************/
+#if defined(VTSS_CHIPS)
+/* Write to GPIO output pin */
+vtss_rc vtss_gpio_output_write(const vtss_chip_no_t chip_no,
+                            const vtss_gpio_no_t gpio_no, 
+                            const BOOL value);
+#else
+vtss_rc vtss_gpio_output_write(const vtss_gpio_no_t gpio_no, 
+                            const BOOL value);
+#endif /* VTSS_CHIPS */
+
+
+
+/******************************************************************************/
+/***        BIST test                                **************************/
+/******************************************************************************/
+
+#if defined MEIGS2 || defined VSC7321
+#define VTSS_BIST_NAME_SIZE 29
+#else
+#define VTSS_BIST_NAME_SIZE 33
+#endif
+
+
+/******************************************************************************
+ * Description: Start a specific bist test
+ *
+ * \param bist_no (input): bist test number range <0..VTSS_BIST_NAME_SIZE-1>.
+ *
+ * \return : VTSS_OK if write was started,
+ *           VTSS_BIST_CMD_FAILED if last write was still in progress.
+ **************************************************************************kbp*/
+vtss_rc vtss_chip_bist_start(const uint bist_no);
+
+
+/******************************************************************************
+ * Description: Get result for a specific bist test
+ *
+ * \param bist_no (input): bist test number range <0..VTSS_BIST_NAME_SIZE-1>.
+ *                         >= VTSS_BIST_NAME_SIZE returns the write status.
+ *
+ * \return : VTSS_OK               when bist test went OK
+ *           VTSS_BIST_CMD_FAILED  when write accesses failed.
+ *           VTSS_BIST_TEST_FAILED when bist test failed.
+ **************************************************************************kbp*/
+vtss_rc vtss_chip_bist_result(const uint bist_no);
+
+
+/******************************************************************************/
+/***        GFP-T Configuration                      **************************/
+/******************************************************************************/
+
+/* Used to define the client signal type for GFP-T */
+#define C1_GFPT_CLIENT_GBE    0x0
+#define C1_GFPT_CLIENT_FC     0x1
+#define C1_GFPT_CLIENT_ESC    0x2
+#define C1_GFPT_CLIENT_DVB    0x3
+
+/* GFP-T Egress Frame Disassembler, Single bit Error Correction mode */
+typedef enum _vtss_gfpt_error_corr_t {
+  VTSS_GFPT_REPLACE_10B_ERR,
+  VTSS_GFPT_FORWARD_ERR,
+  VTSS_GFPT_DISCARD_ERR,
+  VTSS_GFPT_DISABLE_ERR
+} vtss_gfpt_error_corr_t;
+
+/* GFP-T port setup, which may change dynamically */
+typedef struct _vtss_gfpt_setup_t {
+  BOOL                        gfpt_en;
+  BOOL                        source_mode_en;
+  vtss_port_interface_mode_t  interface_mode;
+  uint                        threshold_level;
+  uint                        rate_period;
+  uint                        rate_max_delta;
+  uint                        rate_min_idles;
+  uint                        rate_padding;
+  uint                        frame_length;
+  BOOL                        ingress_header_insert;
+  BOOL                        egress_header_expect;
+  vtss_gfpt_error_corr_t      egress_err_corr;
+} vtss_gfpt_setup_t;
+
+
+/******************************************************************************
+ * Description: Setup for GFP-T handling in Campbell-I
+ *
+ * \param     : portnum
+ *              vtss_gfpt_setup_t* gs
+ *       
+ *
+ * \return    : VTSS_OK               
+ *              VTSS_PORT_NOT_MAPPED
+ *              VTSS_WRONG_PARAMETER
+ **************************************************************************kbp*/
+vtss_rc vtss_gfpt_setup( vtss_port_no_t portnum, vtss_gfpt_setup_t* gs);
+
+
+/******************************************************************************
+ * Description: Get default setting for GFP-T handling in Campbell-I
+ *
+ * \param     : vtss_gfpt_setup_t* gs
+ *              vtss_port_interface_mode_t  mode
+ *
+ * \return    : VTSS_OK               
+ *              VTSS_WRONG_PARAMETER
+ **************************************************************************kbp*/
+vtss_rc vtss_gfpt_setup_get_default_values( vtss_gfpt_setup_t* gs,
+					    vtss_port_interface_mode_t mode);
+
+
+/******************************************************************************/
+/***        Debug Section                            **************************/
+/******************************************************************************/
+
+/*-------------   Loopback  funtions will be added here  ---------------------*/
+
+/*-------------   Error counters will be added here      ---------------------*/
+
+
+BOOL vtss_port_mapped( const vtss_port_no_t port_no );
+BOOL vtss_phy_mapped( const vtss_port_no_t port_no );
+
+#endif /* _VITESSE_HIGHLEVEL_H */
+/****************************************************************************/
+/*                                                                          */
+/*  End of file.                                                            */
+/*                                                                          */
+/****************************************************************************/
diff --git a/drivers/net/rmi_spi4/vitesse_io.c b/drivers/net/rmi_spi4/vitesse_io.c
new file mode 100644
index 0000000..6ff7200
--- /dev/null
+++ b/drivers/net/rmi_spi4/vitesse_io.c
@@ -0,0 +1,233 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/*
+
+   vitesse_io.c  -- Vitesse hardware access layer.
+
+   This file provides the hardware access to target chip registers.
+   Modify it to fit your configuration.
+
+   Copyright (c) 2003 Vitesse Semiconductor Corporation. All Rights Reserved.
+   Unpublished rights reserved under the copyright laws of the United States of 
+   America, other countries and international treaties. The software is provided
+   without fee. Permission to use, copy, store, modify, disclose, transmit or 
+   distribute the software is granted, provided that this copyright notice must 
+   appear in any copy, modification, disclosure, transmission or distribution of 
+   the software. Vitesse Semiconductor Corporation retains all ownership, 
+   copyright, trade secret and proprietary rights in the software. THIS SOFTWARE
+   HAS BEEN PROVIDED "AS IS," WITHOUT EXPRESS OR IMPLIED WARRANTY INCLUDING, 
+   WITHOUT LIMITATION, IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A 
+   PARTICULAR USE AND NON-INFRINGEMENT.
+
+   $Id: vitesse_io.c,v 1.1.2.4 2007-05-17 01:15:36 rpmbuilder Exp $
+
+ */
+
+#include "rmi_vits_wrapper.h"
+#include <asm/rmi/debug.h>
+
+#define __VTSS_LIBRARY__
+
+#define VTSS_TRACE_LAYER 1
+
+#include "vitesse_io.h"
+#include "meigsii_reg.h"
+
+
+#define VTSS_CHIP_ADDR_MMAP_SIZE (0x8000*sizeof(ulong))
+
+#ifdef VITGENIO
+#include <linux/vitgenio.h>
+#include <fcntl.h> /* open() */
+#include <sys/ioctl.h> /* ioctl() */
+#include <sys/mman.h> /* mmap() */
+#endif
+
+
+
+
+#ifdef CUSTOMERIO
+#endif
+
+#define VTSS_BLK_SYSTEM             M2_BLK_SYSTEM
+#define VTSS_SUBBLK_CTRL            M2_SUBBLK_CTRL
+#define VTSS_REG_SW_RESET           M2_SW_RESET
+#define VTSS_REG_CPU_TRANSFER_SEL   M2_SI_TRANSFER_SEL
+#define VTSS_REG_LOCAL_DATA         M2_LOCAL_DATA
+#define VTSS_REG_LOCAL_STATUS       M2_LOCAL_STATUS
+
+#define VTSS_T_RESET 2000000L
+
+/* ================================================================= *
+ *  I/O Layer Helper functions
+ * ================================================================= */
+
+
+
+/* ================================================================= *
+ *  I/O Layer initialisation and
+ *  Chip hardware access configuration (pin polarity etc.)
+ * ================================================================= */
+#if 0 
+/* Reset and configure the chip. */
+static void vtss_io_reset_chip( void )
+{
+	/* Reset the chip */
+	vtss_io_write(VTSS_BLK_SYSTEM,VTSS_SUBBLK_CTRL,VTSS_REG_SW_RESET,0x80000001);
+	VTSS_NSLEEP(VTSS_T_RESET);
+
+	/* Set the chip hardware access configuration (pin polarity etc.). */
+	{
+		const ulong DONE_PINPOLARITY_BITS = 0x99999999;
+
+		vtss_io_writemasked(VTSS_BLK_SYSTEM,VTSS_SUBBLK_CTRL,
+					VTSS_REG_CPU_TRANSFER_SEL,
+			(0/*done_pinpolarity_activehigh*/)?0:
+			DONE_PINPOLARITY_BITS,DONE_PINPOLARITY_BITS);
+	}
+}
+#endif
+/* Note: This must be called before any access to the target chip.
+ *       vtss_reset_io_layer() calls this directly.
+ */
+void vtss_io_reset( void )
+{
+
+#ifdef VITGENIO
+	/* Setup the hardware access (open device driver and setup MMU). */
+	if (vtss_io_state->chip_addr == NULL) {
+		vtss_io_state->fd_driver = open( "/dev/vitgenio", 0 );
+		//VTSS_ASSERT(vtss_io_state->fd_driver != -1);
+
+#ifdef NO_MMAP
+		printf ("VTSS:io_reset no_mmap\n");
+
+		vtss_io_state->chip_addr = (void*)4; /* Any non-NULL value to indicate that the driver is ready. */
+#else
+		vtss_io_state->chip_addr = mmap( 0, VTSS_CHIP_ADDR_MMAP_SIZE, 
+						PROT_READ | PROT_WRITE, 
+						MAP_SHARED, 
+						vtss_io_state->fd_driver, 
+						0 );
+		//VTSS_ASSERT( vtss_io_state->chip_addr != MAP_FAILED );
+#endif
+	}
+
+	/* Call the I/O Layer driver callback, if present. */
+	if (vtss_io_state->io_driver_callback) vtss_io_state->io_driver_callback();
+#endif
+
+
+#ifdef CUSTOMERIO
+	/* Setup the hardware access (open device driver and setup MMU). */
+	/* Call the I/O Layer driver callback, if present. */
+	vtss_io_state->chip_addr = (void*)4;
+	if (vtss_io_state->io_driver_callback) vtss_io_state->io_driver_callback();
+#endif
+	/* Reset and configure the chip. */
+	/* vtss_io_reset_chip(); */
+}
+
+
+
+
+/* ================================================================= *
+ *  Chip register access methods
+ * ================================================================= */
+
+static ulong vtss_io_pi_read(const uint block, const uint subblock, const uint reg)
+{
+	//VTSS_ASSERT( (block<=0x7)&&(subblock<=0xF)&&(reg<=0xFF) );
+
+	/* Use 32 bit access, letting the CPU split it up to two 16 bit bus accesses */
+	VTSS_NSLEEP( 240 ); /* Refer to the data sheet for timing diagrams. */
+	if ((block==VTSS_BLK_SYSTEM)
+		&&
+	(subblock==VTSS_SUBBLK_CTRL)
+		&&
+	((reg==VTSS_REG_LOCAL_DATA)||(reg==VTSS_REG_LOCAL_STATUS))) {
+		return (ulong)megis_read(block, subblock, reg);
+	} else {
+		/* Perform a dummy read to activate read request. */
+		megis_read(block, subblock, reg) ;
+		/* Wait for data ready. */
+		VTSS_NSLEEP( 1000 ); /* Refer to the data sheet for timing diagrams. */
+		return (ulong)megis_read(VTSS_BLK_SYSTEM, 
+					VTSS_SUBBLK_CTRL, 
+					VTSS_REG_LOCAL_DATA);
+	}
+}
+
+static void vtss_io_pi_write(const uint block, const uint subblock, const uint reg, const ulong value)
+{
+	//VTSS_ASSERT( (block<=0x7)&&(subblock<=0xF)&&(reg<=0xFF) );
+
+	/* Use 32 bit access, letting the CPU 
+	split it up to two 16 bit bus accesses */
+	VTSS_NSLEEP( 120 ); /* Refer to the data sheet for timing diagrams. */
+	megis_write(block, subblock, reg, value);
+}
+
+
+ulong vtss_io_read(uint block, uint subblock, const uint reg)
+{
+	ulong value;
+
+	value = vtss_io_pi_read(block, subblock, reg);
+
+	VTSS_N(("R 0x%01X 0x%01X 0x%02X 0x%08lX",block,subblock,reg,value));
+
+	return value;
+}
+
+void vtss_io_write(uint block, uint subblock, const uint reg, const ulong value)
+{
+	VTSS_N(("W 0x%01X 0x%01X 0x%02X 0x%08lX",block,subblock,reg,value));
+
+	vtss_io_pi_write(block, subblock, reg, value);
+}
+
+void vtss_io_writemasked(uint block, uint subblock, 
+			const uint reg, const ulong value, 
+			const ulong mask)
+{
+	VTSS_N(("M 0x%01X 0x%01X 0x%02X 0x%08lX 0x%08lX",
+		block,subblock,reg,value,mask));
+
+	vtss_io_write(block,subblock,reg, 
+			(vtss_io_read(block,subblock,reg) & ~mask) | 
+			(value & mask) );
+}
+
+
+/* ================================================================= *
+ *  I/O Layer state information
+ * ================================================================= */
+
+static vtss_io_state_t default_io_state =
+{
+
+	/* The following members must be present: */
+	/* This optional callback function will be called after 
+		the vtss_io_init function has completed. */
+	NULL,       /*void                (*io_driver_callback) (void);*/
+
+	/* The following members are implementation specific: */
+	0,          /*int                 fd_driver;*/
+	NULL        /*ulong *             chip_addr;*/
+
+};
+
+/* Pointer to current state. */
+vtss_io_state_t * vtss_io_state = &default_io_state;
+
diff --git a/drivers/net/rmi_spi4/vitesse_io.h b/drivers/net/rmi_spi4/vitesse_io.h
new file mode 100644
index 0000000..6a56b90
--- /dev/null
+++ b/drivers/net/rmi_spi4/vitesse_io.h
@@ -0,0 +1,81 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/*
+
+ vitesse_io.h  -- Vitesse hardware access layer.
+ This file provides the hardware access to target chip registers.
+ Modify it to fit your configuration.
+
+ Copyright (c) 2003 Vitesse Semiconductor Corporation. All Rights Reserved.
+ Unpublished rights reserved under the copyright laws of the United States of 
+ America, other countries and international treaties. The software is provided
+ without fee. Permission to use, copy, store, modify, disclose, transmit or 
+ distribute the software is granted, provided that this copyright notice must 
+ appear in any copy, modification, disclosure, transmission or distribution of 
+ the software. Vitesse Semiconductor Corporation retains all ownership, 
+ copyright, trade secret and proprietary rights in the software. THIS SOFTWARE
+ HAS BEEN PROVIDED "AS IS," WITHOUT EXPRESS OR IMPLIED WARRANTY INCLUDING, 
+ WITHOUT LIMITATION, IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A 
+ PARTICULAR USE AND NON-INFRINGEMENT.
+ 
+ $Id: vitesse_io.h,v 1.1.2.3 2006-09-28 01:24:16 nphilips Exp $
+
+*/
+
+#ifndef _VITESSE_IO_H
+#define _VITESSE_IO_H 1
+
+//#include <stdio.h>
+#include "vitesse_common.h"
+
+/* ================================================================= *
+ *  I/O Layer initialisation and
+ *  Chip hardware access configuration (pin polarity etc.)
+ * ================================================================= */
+
+/* Note: This must be called before any access to the target chip.
+ *       vtss_reset_io_layer() calls this directly.
+ */
+void vtss_io_reset( void );
+
+/* ================================================================= *
+ *  Chip register access
+ * ================================================================= */
+
+ulong vtss_io_read(uint block, uint subblock, const uint reg);
+void vtss_io_write(uint block, uint subblock, const uint reg, const ulong value);
+void vtss_io_writemasked(uint block, uint subblock, const uint reg, const ulong value, const ulong mask);
+
+
+/* ================================================================= *
+ *  I/O Layer state information
+ * ================================================================= */
+
+typedef struct _vtss_io_state_t {
+
+/* The following members must be present: */
+    /* This optional callback function will be called after the chip hardware access driver has been opened,
+       but before the chip has been reset and configured for hardware access (pin polarity etc.).
+       It can be used for passing extra parameters to the chip hardware access driver. */
+    void                (*io_driver_callback) (void);
+
+/* The following members are implementation specific: */
+    int                 fd_driver; /* File descriptor to VitGenIO Linux driver */
+    ulong *             chip_addr; /* mmap'ed address of chip */
+
+} vtss_io_state_t;
+
+/* Pointer to I/O layer current state information. */
+extern vtss_io_state_t * vtss_io_state;
+
+#endif /* _VITESSE_IO_H */
diff --git a/drivers/net/rmi_spi4/vitesse_phy_ctrl.c b/drivers/net/rmi_spi4/vitesse_phy_ctrl.c
new file mode 100644
index 0000000..85825d2
--- /dev/null
+++ b/drivers/net/rmi_spi4/vitesse_phy_ctrl.c
@@ -0,0 +1,444 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/************************************************************-*- mode: C -*-*/
+/*                                                                          */
+/*           Copyright (C) 2003 Vitesse Semiconductor Corporation           */
+/*                           All Rights Reserved.                           */
+/*                                                                          */
+/****************************************************************************/
+/*                                                                          */
+/*                            Copyright Notice:                             */
+/*                                                                          */
+/*  Unpublished rights reserved under the copyright laws of the United      */
+/*  States of America, other countries and international treaties.          */
+/*                                                                          */
+/*      The software is provided without fee.                               */
+/*                                                                          */
+/*  Permission to use,  copy, store, modify, disclose, transmit or          */
+/*  distribute the software is granted, provided that this copyright notice */
+/*  must appear in any copy, modification, disclosure, transmission or      */
+/*  distribution of the software.                                           */
+/*                                                                          */
+/*  Vitesse Semiconductor Corporation retains all ownership, copyright,     */
+/*  trade secret and proprietary rights in the software.                    */
+/*                                                                          */
+/*  THIS SOFTWARE HAS BEEN PROVIDED "AS IS," WITHOUT EXPRESS OR IMPLIED     */
+/*  WARRANTY INCLUDING, WITHOUT LIMITATION, IMPLIED WARRANTIES OF           */
+/*  MERCHANTABILITY, FITNESS FOR A PARTICULAR USE AND NON-INFRINGEMENT.     */
+/*                                                                          */
+/*    $Id: vitesse_phy_ctrl.c,v 1.1.2.3 2006-09-28 01:24:16 nphilips Exp $           */
+/*                                                                          */
+/****************************************************************************/
+/*                                                                          */
+/*  File content:                                                           */
+/*                                                                          */
+/*  vitesse_phy_ctrl.c -- C-library for controlling PHY devices             */
+/*                        Copied/compiled from Heathrow PHY ctrl functions  */
+/*                                                                          */
+/****************************************************************************/
+#include "vitesse_highlevel.h"
+#include "meigsii_reg.h"
+#include "vitesse_io.h"
+#include "vitesse_phy_ctrl.h"
+#include <asm/rmi/debug.h>
+
+
+/* ================================================================= *
+ *  PHY
+ * ================================================================= */
+
+/* - Read/Write PHY registers via MII-Management ------------------- */
+/* returns >=0: (ushort)result or <0: (long)error */
+long vtss_phy_read(             const vtss_port_no_t    port_no,
+		const uint              phy_reg )
+{
+	long rc;
+
+	if (!vtss_phy_mapped(port_no)) return VTSS_PHY_NOT_MAPPED;
+	rc = vtss_miim_port_reg_read( port_no, phy_reg );
+	if (rc<0) return VTSS_PHY_READ_ERROR;
+	return rc;
+}
+
+vtss_rc vtss_phy_write(         const vtss_port_no_t    port_no,
+		const uint              phy_reg,
+		const ushort            value )
+{
+	if (!vtss_phy_mapped(port_no)) return VTSS_PHY_NOT_MAPPED;
+	vtss_miim_port_reg_write( port_no, phy_reg, value );
+	return VTSS_OK;
+}
+
+vtss_rc vtss_phy_writemasked(   const vtss_port_no_t    port_no,
+		const uint              phy_reg,
+		const ushort            value,
+		const ushort            mask )
+{
+	long rc;
+
+	if (!vtss_phy_mapped(port_no)) return VTSS_PHY_NOT_MAPPED;
+	rc = vtss_miim_port_reg_read( port_no, phy_reg );
+	if (rc<0) return VTSS_PHY_READ_ERROR;
+	rc = (rc & (0xFFFF^mask)) | (value & mask);
+	vtss_miim_port_reg_write( port_no, phy_reg, rc );
+	return VTSS_OK;
+}
+
+/* - PHY Registers, see IEEE 802.3 clause 22.2.4 ------------------- */
+
+vtss_rc vtss_phy_reset( const vtss_port_no_t port_no )
+{
+	vtss_rc rc;
+	vtss_phy_control_t  control;
+
+	control.reset = 1;
+	if ((rc=vtss_phy_control_set( port_no, &control ))<0) return rc;
+	do {
+		uint read_attempt=0;
+		do {
+			rc = vtss_phy_control_get( port_no, &control );
+		} while ((rc==VTSS_PHY_READ_ERROR) 
+				&& 
+			(read_attempt++<VTSS_PHY_RESET_READ_MAXRETRIES));
+		if (rc<0) return rc;
+	} while (control.reset);
+	return VTSS_OK;
+}
+
+vtss_rc vtss_phy_control_get(   const vtss_port_no_t                port_no,
+		vtss_phy_control_t * const          control )
+{
+	long reg0;
+
+	if ((reg0 = vtss_phy_read( port_no, 0 ))<0) return (vtss_rc)reg0;
+	control->reset          = MAKEBOOL01(reg0 & (1<<15));
+	control->loopback       = MAKEBOOL01(reg0 & (1<<14));
+	switch ( reg0 & ((1<<6)|(1<<13)) ) {
+	case (1<<6)|(1<<13): control->speed = VTSS_SPEED_UNDEFINED; 
+		break;
+	case (1<<6)|(0<<13): control->speed = VTSS_SPEED_1G; 
+		break;
+	case (0<<6)|(1<<13): control->speed = VTSS_SPEED_100M; 
+		break;
+	case (0<<6)|(0<<13): control->speed = VTSS_SPEED_10M; 
+		break;
+	}
+	control->autoneg_enable = MAKEBOOL01(reg0 & (1<<12));
+	control->powerdown      = MAKEBOOL01(reg0 & (1<<11));
+	control->isolate        = MAKEBOOL01(reg0 & (1<<10));
+	control->autoneg_restart = MAKEBOOL01(reg0 & (1<< 9));
+	control->fdx            = MAKEBOOL01(reg0 & (1<< 8));
+	control->collision_test = MAKEBOOL01(reg0 & (1<< 7));
+	return VTSS_OK;
+}
+
+vtss_rc vtss_phy_control_set(   const vtss_port_no_t                port_no,
+				const vtss_phy_control_t * const    control )
+{
+	vtss_rc rc;
+	ushort reg0 = 0;
+
+	reg0 |= control->reset          ? (1<<15) : 0;
+	reg0 |= control->loopback       ? (1<<14) : 0;
+	switch (control->speed) {
+	case VTSS_SPEED_UNDEFINED:  
+		reg0 |= (1<<6)|(1<<13); 
+		break;
+	case VTSS_SPEED_1G:         
+		reg0 |= (1<<6)|(0<<13); 
+		break;
+	case VTSS_SPEED_100M:       
+		reg0 |= (0<<6)|(1<<13); 
+		break;
+	case VTSS_SPEED_10M:        
+		reg0 |= (0<<6)|(0<<13); 
+		break;
+	default:  
+		reg0 |= (1<<6)|(1<<13); 
+		break;
+	}
+	reg0 |= control->autoneg_enable ? (1<<12) : 0;
+	reg0 |= control->powerdown      ? (1<<11) : 0;
+	reg0 |= control->isolate        ? (1<<10) : 0;
+	reg0 |= (control->autoneg_enable && control->autoneg_restart) ? (1<< 9) : 0;
+	reg0 |= control->fdx            ? (1<< 8) : 0;
+	reg0 |= control->collision_test ? (1<< 7) : 0;
+
+	rc=vtss_phy_write( port_no, 0, reg0 );
+#if VTSS_PHY_RESET_PAUSE
+	if (control->reset) {
+		/* Wait after issuing a soft reset to the PHY. */
+		VTSS_NSLEEP(VTSS_PHY_RESET_PAUSE);
+	}
+#endif
+	return rc;
+}
+
+vtss_rc vtss_phy_status_get(    const vtss_port_no_t        port_no,
+		vtss_phy_status_t * const   status )
+{
+	const long reg1 = vtss_phy_read( port_no, 1 );
+	if (reg1<0) return (vtss_rc)reg1;
+	status->ability_100base_t4              = MAKEBOOL01(reg1 & (1<<15));
+	status->ability_100base_x_fdx           = MAKEBOOL01(reg1 & (1<<14));
+	status->ability_100base_x_hdx           = MAKEBOOL01(reg1 & (1<<13));
+	status->ability_10mbps_fdx              = MAKEBOOL01(reg1 & (1<<12));
+	status->ability_10mbps_hdx              = MAKEBOOL01(reg1 & (1<<11));
+	status->ability_100base_t2_fdx          = MAKEBOOL01(reg1 & (1<<10));
+	status->ability_100base_t2_hdx          = MAKEBOOL01(reg1 & (1<< 9));
+	status->accepts_mf_preamble_suppression = MAKEBOOL01(reg1 & (1<< 6));
+	status->autoneg_complete                = MAKEBOOL01(reg1 & (1<< 5));
+	status->remote_fault                    = MAKEBOOL01(reg1 & (1<< 4));
+	status->ability_autoneg                 = MAKEBOOL01(reg1 & (1<< 3));
+	status->link_status                     = MAKEBOOL01(reg1 & (1<< 2));
+	status->jabber_detected                 = MAKEBOOL01(reg1 & (1<< 1));
+	status->extended_capability             = MAKEBOOL01(reg1 & (1<< 0));
+	status->extended_status                 = MAKEBOOL01(reg1 & (1<< 8));
+	if (status->extended_status) {
+		const long reg15 = vtss_phy_read( port_no, 15 );
+		if (reg15<0) return (vtss_rc)reg15;
+		status->extended.ability_1000base_x_fdx = 
+					MAKEBOOL01(reg15 & (1<<15));
+		status->extended.ability_1000base_x_hdx = 
+					MAKEBOOL01(reg15 & (1<<14));
+		status->extended.ability_1000base_t_fdx = 
+					MAKEBOOL01(reg15 & (1<<13));
+		status->extended.ability_1000base_t_hdx = 
+					MAKEBOOL01(reg15 & (1<<12));
+	} else {
+		status->extended.ability_1000base_x_fdx = 0;
+		status->extended.ability_1000base_x_hdx = 0;
+		status->extended.ability_1000base_t_fdx = 0;
+		status->extended.ability_1000base_t_hdx = 0;
+	}
+	return VTSS_OK;
+}
+
+/* Note: This function can be used to see if a PHY is present by calling it with id=NULL. */
+vtss_rc vtss_phy_id_get(const vtss_port_no_t    port_no,
+			vtss_phy_id_t * const   id )
+{
+	long reg2, reg3;
+
+	if ((reg2 = vtss_phy_read( port_no, 2 ))<0) 
+		return (vtss_rc)reg2;
+	if ((reg3 = vtss_phy_read( port_no, 3 ))<0) 
+		return (vtss_rc)reg3;
+	if (id) {
+		/* 16 bits from reg2 and 6 bits from reg3 */
+		id->manufacturer = (reg2 <<6) | ((reg3 >> 10) & 0x3F); 
+		id->model        = (reg3 >> 4) & 0x3F; /* 6 bits */
+		id->revision     = reg3 & 0xF;         /* 4 bits */
+	}
+	return VTSS_OK;
+}
+
+vtss_rc vtss_phy_autoneg_advertisement_get( const 	uint   	port_no,
+		vtss_phy_autoneg_advertisement_t * const        advertisement )
+{
+	long reg4;
+
+	if ((reg4 = vtss_phy_read( port_no, 4 ))<0) return (vtss_rc)reg4;
+	advertisement->ability_100base_t4   = MAKEBOOL01(reg4 & (1<< 9));
+	advertisement->ability_100base_x_fdx= MAKEBOOL01(reg4 & (1<< 8));
+	advertisement->ability_100base_x_hdx= MAKEBOOL01(reg4 & (1<< 7));
+	advertisement->ability_10base_t_fdx = MAKEBOOL01(reg4 & (1<< 6));
+	advertisement->ability_10base_t_hdx = MAKEBOOL01(reg4 & (1<< 5));
+	advertisement->symmetric_pause      = MAKEBOOL01(reg4 & (1<<10));
+	advertisement->asymmetric_pause     = MAKEBOOL01(reg4 & (1<<11));
+	advertisement->remote_fault         = MAKEBOOL01(reg4 & (1<<13));
+	advertisement->acknowledge          = 0;    /* Unused in Register 4 */
+	advertisement->next_page_present    = MAKEBOOL01(reg4 & (1<<15));
+	return VTSS_OK;
+}
+
+vtss_rc vtss_phy_autoneg_advertisement_set( const uint   port_no,
+		const vtss_phy_autoneg_advertisement_t * const  advertisement )
+{
+	ushort reg4 = 0;
+
+	reg4 |= advertisement->ability_100base_t4   ? (1<< 9) : 0;
+	reg4 |= advertisement->ability_100base_x_fdx? (1<< 8) : 0;
+	reg4 |= advertisement->ability_100base_x_hdx? (1<< 7) : 0;
+	reg4 |= advertisement->ability_10base_t_fdx ? (1<< 6) : 0;
+	reg4 |= advertisement->ability_10base_t_hdx ? (1<< 5) : 0;
+	reg4 |= advertisement->symmetric_pause      ? (1<<10) : 0;
+	reg4 |= advertisement->asymmetric_pause     ? (1<<11) : 0;
+	reg4 |= advertisement->remote_fault         ? (1<<13) : 0;
+	/* advertisement->acknowledge is unused in Register 4 */
+	reg4 |= advertisement->next_page_present    ? (1<<15) : 0;
+
+	/* Selector field must be set to 1 for IEEE802.3 twisted pair. 
+	(Refer to IEEE 802.3 Clause 28.2.1.2.1 and Annex 28A) */
+	reg4 |= ((1 & 0x1F)<<0);
+
+	return vtss_phy_write( port_no, 4, reg4 );
+}
+
+vtss_rc vtss_phy_autoneg_linkpartner_ability_get(   const uint    port_no,
+		vtss_phy_autoneg_advertisement_t * const    linkpartner_advertisement )
+{
+	long reg5;
+
+	if ((reg5 = vtss_phy_read( port_no, 5 ))<0) return (vtss_rc)reg5;
+	linkpartner_advertisement->ability_100base_t4   = 
+					MAKEBOOL01(reg5 & (1<< 9));
+	linkpartner_advertisement->ability_100base_x_fdx= 
+					MAKEBOOL01(reg5 & (1<< 8));
+	linkpartner_advertisement->ability_100base_x_hdx= 
+					MAKEBOOL01(reg5 & (1<< 7));
+	linkpartner_advertisement->ability_10base_t_fdx = 
+					MAKEBOOL01(reg5 & (1<< 6));
+	linkpartner_advertisement->ability_10base_t_hdx = 
+					MAKEBOOL01(reg5 & (1<< 5));
+	linkpartner_advertisement->symmetric_pause      = 
+					MAKEBOOL01(reg5 & (1<<10));
+	linkpartner_advertisement->asymmetric_pause     = 
+					MAKEBOOL01(reg5 & (1<<11));
+	linkpartner_advertisement->remote_fault         = 
+					MAKEBOOL01(reg5 & (1<<13));
+	linkpartner_advertisement->acknowledge          = 
+					MAKEBOOL01(reg5 & (1<<14));
+	linkpartner_advertisement->next_page_present    = 
+					MAKEBOOL01(reg5 & (1<<15));
+	return VTSS_OK;
+}
+
+vtss_rc vtss_phy_masterslave_control_get(   const vtss_port_no_t    port_no,
+		vtss_phy_masterslave_control_t * const  masterslave_control )
+{
+	long reg9;
+
+	if ((reg9 = vtss_phy_read( port_no, 9 ))<0) 
+		return (vtss_rc)reg9;
+	masterslave_control->test_mode              = 
+					(reg9 & (7<<13)) >> 13;
+	masterslave_control->masterslave_force      = 
+					MAKEBOOL01(reg9 & (1<<12));
+	masterslave_control->masterslave_master     = 
+					MAKEBOOL01(reg9 & (1<<11));
+	masterslave_control->port_type              = 
+					MAKEBOOL01(reg9 & (1<<10));
+	masterslave_control->ability_1000base_t_fdx = 
+					MAKEBOOL01(reg9 & (1<< 9));
+	masterslave_control->ability_1000base_t_fdx = 
+					MAKEBOOL01(reg9 & (1<< 8));
+	return VTSS_OK;
+}
+
+vtss_rc vtss_phy_masterslave_control_set(   const vtss_port_no_t  port_no,
+	const vtss_phy_masterslave_control_t * const  masterslave_control )
+{
+	ushort reg9 = 0;
+
+	reg9 |= (masterslave_control->test_mode & 7)            <<13;
+	reg9 |= masterslave_control->masterslave_force      ? (1<<12) : 0;
+	reg9 |= masterslave_control->masterslave_master     ? (1<<11) : 0;
+	reg9 |= masterslave_control->port_type              ? (1<<10) : 0;
+	reg9 |= masterslave_control->ability_1000base_t_fdx ? (1<< 9) : 0;
+	reg9 |= masterslave_control->ability_1000base_t_fdx ? (1<< 8) : 0;
+
+	return vtss_phy_write( port_no, 9, reg9 );
+}
+
+vtss_rc vtss_phy_masterslave_status_get(    const vtss_port_no_t     port_no,
+	vtss_phy_masterslave_status_t * const   masterslave_status )
+{
+	long reg10;
+
+	if ((reg10 = vtss_phy_read( port_no, 10 ))<0) return (vtss_rc)reg10;
+	masterslave_status->fault                               = 
+					MAKEBOOL01(reg10 & (1<<15));
+	masterslave_status->master                              = 
+					MAKEBOOL01(reg10 & (1<<14));
+	masterslave_status->local_receiver_status_ok            = 
+					MAKEBOOL01(reg10 & (1<<13));
+	masterslave_status->remote_receiver_status_ok           = 
+					MAKEBOOL01(reg10 & (1<<12));
+	masterslave_status->linkpartner_ability_1000base_t_fdx  = 
+					MAKEBOOL01(reg10 & (1<<11));
+	masterslave_status->linkpartner_ability_1000base_t_hdx  = 
+					MAKEBOOL01(reg10 & (1<<10));
+	masterslave_status->idle_error_count                    = 
+							reg10 & 0xFF;
+	return VTSS_OK;
+}
+
+/* - PHY Auto-Negotiation and Forced Speed ------------------------- */
+
+/* Note: Some PHYs (DP83865) requires a reset to run with forced speed. This function does not reset the PHY. */
+vtss_rc vtss_phy_force_speed(   const vtss_port_no_t    port_no,
+		const vtss_speed_t      speed,
+		const BOOL              fdx /* Full duplex: TRUE, Half duplex: FALSE */ )
+{
+	vtss_rc rc;
+	vtss_phy_status_t   status;
+	vtss_phy_control_t  control;
+
+	/* Verify PHY ability. */
+	if ((rc=vtss_phy_status_get( port_no, &status ))<0) 
+		return rc;
+	switch (speed) {
+	case VTSS_SPEED_10M:
+		if (fdx) {
+			if (status.ability_10mbps_fdx) break;
+		} else {
+			if (status.ability_10mbps_hdx) break;
+		}
+		return VTSS_PHY_ABILITY;
+	case VTSS_SPEED_100M:
+		if (fdx) {
+			if (status.ability_100base_x_fdx) break;
+			if (status.ability_100base_t2_fdx) break;
+		} else {
+			/* Note: 100Base-T4 is always half duplex. */
+			if (status.ability_100base_t4) break;
+			if (status.ability_100base_x_hdx) break;
+			if (status.ability_100base_t2_hdx) break;
+		}
+		return VTSS_PHY_ABILITY;
+	case VTSS_SPEED_1G:
+		if (!status.extended_status) return VTSS_PHY_ABILITY;
+		if (fdx) {
+			if (status.extended.ability_1000base_x_fdx) break;
+			if (status.extended.ability_1000base_t_fdx) break;
+		} else {
+			if (status.extended.ability_1000base_x_hdx) break;
+			if (status.extended.ability_1000base_t_hdx) break;
+		}
+		return VTSS_PHY_ABILITY;
+	default:
+		return VTSS_PHY_ABILITY;
+	}
+
+	/* Set PHY mode. */
+	control.reset           = 0;
+	control.loopback        = 0;
+	control.speed           = speed;
+	control.autoneg_enable  = 0;
+	control.powerdown       = 0;
+	control.isolate         = 0;
+	control.autoneg_restart = 0;
+	control.fdx             = fdx;
+	control.collision_test  = 0;
+	return vtss_phy_control_set( port_no, &control );
+}
+
+
+
+
+/****************************************************************************/
+/*                                                                          */
+/*  End of file.                                                            */
+/*                                                                          */
+/****************************************************************************/
diff --git a/drivers/net/rmi_spi4/vitesse_phy_ctrl.h b/drivers/net/rmi_spi4/vitesse_phy_ctrl.h
new file mode 100644
index 0000000..faadb0b
--- /dev/null
+++ b/drivers/net/rmi_spi4/vitesse_phy_ctrl.h
@@ -0,0 +1,296 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/************************************************************-*- mode: C -*-*/
+/*                                                                          */
+/*           Copyright (C) 2003 Vitesse Semiconductor Corporation           */
+/*                           All Rights Reserved.                           */
+/*                                                                          */
+/****************************************************************************/
+/*                                                                          */
+/*                            Copyright Notice:                             */
+/*                                                                          */
+/*  Unpublished rights reserved under the copyright laws of the United      */
+/*  States of America, other countries and international treaties.          */
+/*                                                                          */
+/*      The software is provided without fee.                               */
+/*                                                                          */
+/*  Permission to use,  copy, store, modify, disclose, transmit or          */
+/*  distribute the software is granted, provided that this copyright notice */
+/*  must appear in any copy, modification, disclosure, transmission or      */
+/*  distribution of the software.                                           */
+/*                                                                          */
+/*  Vitesse Semiconductor Corporation retains all ownership, copyright,     */
+/*  trade secret and proprietary rights in the software.                    */
+/*                                                                          */
+/*  THIS SOFTWARE HAS BEEN PROVIDED "AS IS," WITHOUT EXPRESS OR IMPLIED     */
+/*  WARRANTY INCLUDING, WITHOUT LIMITATION, IMPLIED WARRANTIES OF           */
+/*  MERCHANTABILITY, FITNESS FOR A PARTICULAR USE AND NON-INFRINGEMENT.     */
+/*                                                                          */
+/*    $Id: vitesse_phy_ctrl.h,v 1.1.2.3 2006-09-28 01:24:16 nphilips Exp $           */
+/*                                                                          */
+/****************************************************************************/
+/*                                                                          */
+/*  File content:                                                           */
+/*                                                                          */
+/*  vitesse_phy_ctrl.h -- C-library for controlling PHY devices             */
+/*                                                                          */
+/*                                                                          */
+/****************************************************************************/
+
+
+
+/* ================================================================= *
+ *  PHY
+ * ================================================================= */
+
+/* - Read/Write PHY registers via MII-Management ------------------- */
+
+/* returns >=0: (ushort)result or <0: (long)error */
+long vtss_phy_read(             const vtss_port_no_t    port_no,
+                                const uint              phy_reg );
+
+vtss_rc vtss_phy_write(         const vtss_port_no_t    port_no,
+                                const uint              phy_reg,
+                                const ushort            value );
+
+vtss_rc vtss_phy_writemasked(   const vtss_port_no_t    port_no,
+                                const uint              phy_reg,
+                                const ushort            value,
+                                const ushort            mask );
+
+/* - PHY Registers, see IEEE 802.3 clause 22.2.4 ------------------- */
+
+/* Some PHYs do not respond to MII-M READ during Reset, although they
+   must (according to IEEE 802.3 clause 22.2.4.1.1), so we try reading
+   a number of times before we give up when there is no read response
+   from the PHY during reset. Set to 0 to disable retrying. */
+#define VTSS_PHY_RESET_READ_MAXRETRIES 15625
+
+/* Some PHYs require silence on the MII-M bus a short period after
+   soft reset, so we pause this many nanoseconds.
+   Set to 0 to disable. */
+#define VTSS_PHY_RESET_PAUSE 1000
+
+vtss_rc vtss_phy_reset( const vtss_port_no_t port_no );
+
+/* PHY Basic Capability registers */
+
+/* PHY Control Register (Register 0) */
+typedef struct _vtss_phy_control_t {
+    BOOL                reset;              /* Self Clearing */
+    BOOL                loopback;
+    vtss_speed_t        speed;
+    BOOL                autoneg_enable;
+    BOOL                powerdown;
+    BOOL                isolate;
+    BOOL                autoneg_restart;    /* Self Clearing */
+    BOOL                fdx;                /* Full duplex: TRUE, Half duplex: FALSE */
+    BOOL                collision_test;
+} vtss_phy_control_t;
+
+vtss_rc vtss_phy_control_get(   const vtss_port_no_t                port_no,
+                                vtss_phy_control_t * const          control );
+
+vtss_rc vtss_phy_control_set(   const vtss_port_no_t                port_no,
+                                const vtss_phy_control_t * const    control );
+
+/* PHY Status Registers (Registers 1 and 15) */
+/* Note: The link_status entry is "shared" between vtss_port_status and 
+	vtss_phy_status_get functions. 
+*/
+
+typedef struct _vtss_phy_status_t {
+    BOOL            ability_100base_t4; /* Note: 100Base-T4 is always hdx. */
+    BOOL            ability_100base_x_fdx; /* Covers 100Base-TX or 100Base-FX */
+    BOOL            ability_100base_x_hdx; /* Covers 100Base-TX or 100Base-FX */
+    BOOL            ability_10mbps_fdx;
+    BOOL            ability_10mbps_hdx;
+    BOOL            ability_100base_t2_fdx;
+    BOOL            ability_100base_t2_hdx;
+    BOOL            accepts_mf_preamble_suppression;
+    BOOL            autoneg_complete;
+    BOOL            remote_fault;
+    BOOL            ability_autoneg;
+    BOOL            link_status;
+    BOOL            jabber_detected;
+    BOOL            extended_capability;    /* PHY supports Registers 2-14 and 16-31 */
+    BOOL            extended_status;
+    struct {
+    BOOL            ability_1000base_x_fdx;
+    BOOL            ability_1000base_x_hdx;
+    BOOL            ability_1000base_t_fdx;
+    BOOL            ability_1000base_t_hdx;
+    }               extended;    /* Only available when extended_status==TRUE. */
+} vtss_phy_status_t;
+
+vtss_rc vtss_phy_status_get(    const vtss_port_no_t        port_no,
+                                vtss_phy_status_t * const   status );
+
+/* PHY Extended Capability registers */
+
+/* PHY Identifier (Registers 2 and 3) */
+typedef struct _vtss_phy_id_t {
+    uint            manufacturer;   /* 22 bits (bits 3-24 of the manufacturer's OUI) */
+    uint            model;          /* 6 bits */
+    uint            revision;       /* 4 bits */
+} vtss_phy_id_t;
+
+/* Note: This function can be used to see if a PHY is present by calling it with id=NULL. */
+vtss_rc vtss_phy_id_get(    const vtss_port_no_t    port_no,
+                            vtss_phy_id_t * const   id );
+
+/* PHY Auto-Negotiation Advertisement (Register 4) and Link Partner Ability (Register 5) */
+typedef struct _vtss_phy_autoneg_advertisement_t {
+    BOOL            ability_100base_t4; /* Note: 100Base-T4 is always half duplex. */
+    BOOL            ability_100base_x_fdx; /* Covers 100Base-TX or 100Base-FX */
+    BOOL            ability_100base_x_hdx; /* Covers 100Base-TX or 100Base-FX */
+    BOOL            ability_10base_t_fdx;
+    BOOL            ability_10base_t_hdx;
+    BOOL            symmetric_pause;    /* a.k.a. PAUSE (PS1) */
+    BOOL            asymmetric_pause;   /* a.k.a. ASM_DIR (PS2) */
+    BOOL            remote_fault;
+    BOOL            acknowledge;    /* Unused in Register 4 */
+    BOOL            next_page_present;
+} vtss_phy_autoneg_advertisement_t;
+
+/* PHY Auto-Negotiation Advertisement (Register 4) */
+vtss_rc vtss_phy_autoneg_advertisement_get( const uint   port_no,
+      vtss_phy_autoneg_advertisement_t * const        advertisement );
+
+/* PHY Auto-Negotiation Advertisement (Register 4) */
+vtss_rc vtss_phy_autoneg_advertisement_set( const uint   port_no,
+        const vtss_phy_autoneg_advertisement_t * const  advertisement );
+
+/* PHY Auto-Negotiation Link Partner Ability (Register 5) */
+vtss_rc vtss_phy_autoneg_linkpartner_ability_get(   const uint    port_no,
+      vtss_phy_autoneg_advertisement_t * const    linkpartner_advertisement );
+
+/* PHY Master-Slave Control Register (Register 9), 1000Base-T only. 
+Set this before PHY Control Register */
+typedef struct _vtss_phy_masterslave_control_t {
+    uint                test_mode;          /* (3 bits wide), 0: Normal operation */
+    BOOL                masterslave_force;  /* Manually set Master/Slave mode */
+    BOOL                masterslave_master; /* Only used when masterslave_force==TRUE */
+    BOOL                port_type;          /* TRUE: multi-port device, FALSE: single-port device */
+    BOOL                ability_1000base_t_fdx; /* Used for Auto-Negotiation */
+    BOOL                ability_1000base_t_hdx; /* Used for Auto-Negotiation */
+} vtss_phy_masterslave_control_t;
+
+vtss_rc vtss_phy_masterslave_control_get(   const vtss_port_no_t  port_no,
+     vtss_phy_masterslave_control_t * const          masterslave_control );
+
+vtss_rc vtss_phy_masterslave_control_set(   const vtss_port_no_t   port_no,
+      const vtss_phy_masterslave_control_t * const    masterslave_control );
+
+/* PHY Master-Slave Status Register (Register 10), 1000Base-T only */
+typedef struct _vtss_phy_masterslave_status_t {
+    BOOL                fault;
+    BOOL                master;
+    BOOL                local_receiver_status_ok;
+    BOOL                remote_receiver_status_ok;
+    BOOL                linkpartner_ability_1000base_t_fdx; /* Used for Auto-Negotiation */
+    BOOL                linkpartner_ability_1000base_t_hdx; /* Used for Auto-Negotiation */
+    uchar               idle_error_count;   /* Saturates when reaching 0xFF */
+} vtss_phy_masterslave_status_t;
+
+vtss_rc vtss_phy_masterslave_status_get(    const vtss_port_no_t    port_no,
+         vtss_phy_masterslave_status_t * const   masterslave_status );
+
+/* - PHY Auto-Negotiation and Forced Speed ------------------------- */
+
+vtss_rc vtss_phy_force_speed(   const vtss_port_no_t    port_no,
+                                const vtss_speed_t      speed,
+                                const BOOL              fdx /* Full duplex: TRUE, 
+				Half duplex: FALSE */ );
+
+
+#if defined(HEATHROW2) || defined(STAPLEFORD)
+/* ================================================================= *
+ *  TBI Auto-Negotiation and Status
+ * ================================================================= */
+
+BOOL vtss_tbi_enabled(  const vtss_port_no_t    port_no );
+
+/* Advertisement Word (Refer to IEEE 802.3 Clause 37):
+ *  MSB                                                                         LSB
+ *  D15  D14  D13  D12  D11  D10   D9   D8   D7   D6   D5   D4   D3   D2   D1   D0 
+ * +----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+
+ * | NP | Ack| RF2| RF1|rsvd|rsvd|rsvd| PS2| PS1| HD | FD |rsvd|rsvd|rsvd|rsvd|rsvd|
+ * +----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+
+ */
+
+/* enum used in vtss_autoneg_1000base_x_config_t */
+typedef enum _vtss_autoneg_1000base_x_remote_fault_t {
+                                     /* RF2 */  /* RF1 */
+    VTSS_1000BASEX_LINK_OK          = (( 0 <<1) | ( 0 <<0)),
+    VTSS_1000BASEX_OFFLINE          = (( 1 <<1) | ( 0 <<0)),
+    VTSS_1000BASEX_LINK_FAILURE     = (( 0 <<1) | ( 1 <<0)),
+    VTSS_1000BASEX_AUTONEG_ERROR    = (( 1 <<1) | ( 1 <<0))
+} vtss_autoneg_1000base_x_remote_fault_t;
+
+typedef struct _vtss_autoneg_1000base_x_advertisement_t {
+    BOOL                                    fdx;
+    BOOL                                    hdx;
+    BOOL                                    symmetric_pause;    /* a.k.a. PAUSE (PS1) */
+    BOOL                                    asymmetric_pause;   /* a.k.a. ASM_DIR (PS2) */
+    vtss_autoneg_1000base_x_remote_fault_t  remote_fault;
+    BOOL                                    acknowledge;
+    BOOL                                    next_page;
+} vtss_autoneg_1000base_x_advertisement_t;
+
+typedef struct _vtss_tbi_autoneg_control_t {
+    BOOL                                    enable;
+    vtss_autoneg_1000base_x_advertisement_t advertisement;
+} vtss_tbi_autoneg_control_t;
+
+vtss_rc vtss_tbi_autoneg_control_get( const vtss_port_no_t    port_no,
+                   vtss_tbi_autoneg_control_t * const        control );
+
+vtss_rc vtss_tbi_autoneg_control_set( const vtss_port_no_t   port_no,
+	        const vtss_tbi_autoneg_control_t * const  control );
+
+vtss_rc vtss_tbi_autoneg_restart( const vtss_port_no_t  port_no );
+
+/* TBI Status, Current state of the PCS */
+typedef enum _vtss_tbi_pcs_state_t {
+    VTSS_TBI_PCS_STATE_IDLE,      /* Idle */
+    VTSS_TBI_PCS_STATE_CONFIG,    /* Config (i.e. ANEG in progress) */
+    VTSS_TBI_PCS_STATE_DATA       /* Data */
+} vtss_tbi_pcs_state_t;
+
+/* Note: The link_status entry is "shared" between vtss_port_status 
+and vtss_tbi_status_get functions. */
+typedef struct _vtss_tbi_status_t {
+    BOOL                                    link_status;        /* FALSE if link has been down since last status read */
+    uint                                    link_down_counter;  /* Note: Saturates when reaching VTSS_TBI_LINK_DOWN_COUNTER_SATURATED. */
+    struct {
+    vtss_tbi_pcs_state_t                    pcs_state;
+    BOOL                                    priority_resolution;
+    BOOL                                    complete;
+    vtss_autoneg_1000base_x_advertisement_t partner_advertisement;
+    }                                       autoneg;
+} vtss_tbi_status_t;
+
+#define VTSS_TBI_LINK_DOWN_COUNTER_SATURATED 255
+
+vtss_rc vtss_tbi_status_get( const vtss_port_no_t       port_no,
+                             vtss_tbi_status_t * const  status );
+
+#endif /* HEATHROW2/STAPLEFORD */
+
+
+/****************************************************************************/
+/*                                                                          */
+/*  End of file.                                                            */
+/*                                                                          */
+/****************************************************************************/
diff --git a/drivers/net/rmi_vnet.c b/drivers/net/rmi_vnet.c
new file mode 100644
index 0000000..d121481
--- /dev/null
+++ b/drivers/net/rmi_vnet.c
@@ -0,0 +1,670 @@
+/*
+ * $Id: $ 
+ *
+ * Shared memory based network driver to provide communication between
+ * different chip resource framework (CRF) domains.
+ */
+
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/*
+ * Copyright (C) 2001 Alessandro Rubini and Jonathan Corbet
+ * Copyright (C) 2001 O'Reilly & Associates
+ *
+ * The source code in this file can be freely used, adapted,
+ * and redistributed in source or binary form, so long as an
+ * acknowledgment appears in derived source files.  The citation
+ * should list that the code comes from the book "Linux Device
+ * Drivers" by Alessandro Rubini and Jonathan Corbet, published
+ * by O'Reilly & Associates.   No warranty is attached;
+ * we cannot take responsibility for errors or fitness for use.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/moduleparam.h>
+
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/interrupt.h>
+
+#include <linux/in.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/ip.h>
+#include <linux/tcp.h>
+#include <linux/skbuff.h>
+#include <rmicrf/types.h>
+#include <rmicrf/api.h>
+#include <rmicrf/crflib.h>
+#include <rmicrf/eventdefs.h>
+#include <rmicrf/clpool.h>
+#include <asm/rmi/linux_crf.h>
+
+#include "rmi_vnet.h"
+
+
+/*
+ * Transmitter lockup simulation, normally disabled.
+ */
+static int lockup = 0;
+module_param(lockup, int, 0);
+
+static int timeout = RMI_VNET_TIMEOUT;
+module_param(timeout, int, 0);
+
+int rmi_vnet_debug = 0;
+struct net_device *vnet_dev;  /* The device */
+
+/*
+ * This structure is private to each device. It is used to pass
+ * packets in and out, so there is place for a packet
+ */
+struct rmi_vnet_priv {
+	struct net_device_stats stats;
+	int status;
+	struct sk_buff *skb;
+	spinlock_t lock;
+};
+
+struct rmi_vnet_cluster_cache {
+	struct rmi_cluster *cl;
+};
+
+static struct rmi_vnet_cluster_cache cl_cache_send[RMI_MAX_DOMAINS];
+static struct rmi_vnet_cluster_cache cl_cache_rx;
+
+/*
+ * Addr of 64-bit vnet dom-map which has respective domain id bits
+ * set for the domains where vnet0 interface is up.
+ */
+static rmi_addr_t rmi_vnet_dom_map_addr;
+/*
+ * Addr of 64-bit vnet promisc-dom-map which has respective domain id
+ * bits set for the domains where vnet0 interface is in promiscuous mode.
+ * .
+ */
+static rmi_addr_t rmi_vnet_promisc_dom_map_addr;
+
+
+static inline void rmi_vnet_dump_ether_hdr(struct ethhdr* eth)
+{
+	DECLARE_MAC_BUF(dest);
+	DECLARE_MAC_BUF(src);
+
+	VNET_DBG("eth header: dest %s source %s proto %04x\n",
+		 print_mac(dest, eth->h_dest),
+		 print_mac(src, eth->h_source),
+		 ntohs(eth->h_proto));
+}
+
+
+static void rmi_vnet_dump_pkt_info(struct sk_buff *skb)
+{
+	struct iphdr *ih;
+	uint32_t *saddr, *daddr;
+
+	rmi_vnet_dump_ether_hdr((struct ethhdr*)skb->data);
+
+	/*
+	 * Ethhdr is 14 bytes, but the kernel arranges for iphdr
+	 * to be aligned (i.e., ethhdr is unaligned)
+	 */
+	ih = (struct iphdr *)(skb->data + sizeof (struct ethhdr));
+	saddr = &ih->saddr;
+	daddr = &ih->daddr;
+
+	VNET_DBG("%s: %08x:%05i --> %08x:%05i\n", __FUNCTION__,
+		ntohl(ih->saddr),ntohs(((struct tcphdr *)(ih+1))->source),
+		ntohl(ih->daddr),ntohs(((struct tcphdr *)(ih+1))->dest));
+}
+
+
+static void rmi_vnet_rx(struct net_device *dev, uint64_t datalen, void *data)
+{
+
+	struct sk_buff *skb;
+	struct rmi_vnet_priv *priv = netdev_priv(dev);
+	int rval;
+
+	/*
+	 * The packet has been retrieved from the transmission
+	 * medium. Build an skb around it, so upper layers can handle it
+	 */
+	skb = dev_alloc_skb(datalen + 2);
+	if (!skb) {
+		if (printk_ratelimit())
+		    printk(KERN_NOTICE "rmi_vnet: rx - low on mem - packet dropped\n");
+		priv->stats.rx_dropped++;
+		goto out;
+	}
+
+	skb_reserve(skb, 2); /* align IP on 16B boundary */  
+	memcpy(skb_put(skb, datalen), data, datalen);
+
+	/* Write metadata, and then pass to the receive level */
+	skb->dev = dev;
+	skb->protocol = eth_type_trans(skb, dev);
+
+	priv->stats.rx_packets++;
+	priv->stats.rx_bytes += datalen;
+
+	rval = netif_rx(skb);
+  out:
+	return;
+}
+
+
+static void rmi_vnet_pkt_get_event(int len, void *msg)
+{
+	struct rmi_event_simple_msg *smsg = msg;
+	struct rmi_event_vnet_msg *vnet_msg = rmi_addr_to_ptr(smsg->arg);
+
+	VNET_DBG("%s: rx from domid %u in %u msg len %u type %u datalen %llu "
+		 "data %p arg 0x%llx\n", __FUNCTION__, smsg->domid,
+		 rmi_this_domain->id, len, smsg->msgtype,
+		 (unsigned long long)vnet_msg->datalen,
+		 rmi_addr_to_ptr(vnet_msg->data),
+		 (unsigned long long)smsg->arg);
+
+	if (!cl_cache_rx.cl) {
+	    if ((cl_cache_rx.cl = rmi_clpool_getref(rmi_this_domain->id,
+						 RMI_PKT_POOL_NAME)) == NULL) {
+		printk("No pool found for domain %u\n", rmi_this_domain->id);
+		rmi_send_pool_event(rmi_this_domain->id,
+				    RMI_EVENT_MSG_CL_POOL_NOT_FOUND, 0ULL);
+		return;
+	    }
+	}
+
+	rmi_vnet_dump_ether_hdr((struct ethhdr*)rmi_addr_to_ptr(vnet_msg->data));
+	rmi_vnet_rx(vnet_dev, vnet_msg->datalen, vnet_msg->data);
+	rmi_cluster_free(cl_cache_rx.cl, vnet_msg);
+}
+
+
+static void rmi_vnet_pkt_unicast(rmi_dom_t domid, struct sk_buff *skb)
+{
+    struct rmi_event_vnet_msg *vnet_msg;
+    struct rmi_event_simple_msg smsg;
+    char *shortpkt = NULL;
+    char *skbdata;
+    int skblen;
+    struct rmi_vnet_priv *priv;
+
+    skblen = skb->len;
+    skbdata = skb->data;
+
+    if (skblen < ETH_ZLEN) {
+	    shortpkt = kmalloc(ETH_ZLEN, GFP_KERNEL);
+	    if (shortpkt == NULL) {
+		printk (KERN_NOTICE "Ran out of memory allocating short packet\n");
+		return;
+	    }
+	    memset(shortpkt, 0, ETH_ZLEN);
+	    memcpy(shortpkt, skbdata, skblen);
+	    skblen = ETH_ZLEN;
+	    skbdata = shortpkt;
+    }
+
+    if (!cl_cache_send[domid].cl) {
+
+	VNET_DBG("%s: caching cluster ref for domid %u\n", __FUNCTION__, domid);
+
+	if ((cl_cache_send[domid].cl =
+	    rmi_clpool_getref(domid, RMI_PKT_POOL_NAME)) == NULL) {
+	    printk("No pool found for domain %u\n", domid);
+	    rmi_send_pool_event(domid, RMI_EVENT_MSG_CL_POOL_NOT_FOUND, 0ULL);
+	    return;
+	}
+    }
+
+    if ((vnet_msg = rmi_cluster_alloc(cl_cache_send[domid].cl, 0)) == NULL) {
+	printk("Cluster alloc failed %d\n", domid);
+	rmi_send_pool_event(domid, RMI_EVENT_MSG_CL_POOL_EMPTY, 0ULL);
+	return;
+    }
+
+    memset(vnet_msg, 0, sizeof(*vnet_msg));
+    vnet_msg->datalen = skblen;
+    memcpy(vnet_msg->data, skbdata, skblen);
+
+    smsg.msgtype = RMI_EVENT_VNET_PKT;
+    smsg.domid = rmi_this_domain->id;
+    smsg.arg = rmi_ptr_to_addr(vnet_msg);
+
+    VNET_DBG("%s: tx from domid %u to %u msglen %llu type %u datalen %llu "
+	     "data %p arg 0x%llx\n", __FUNCTION__, smsg.domid, domid,
+	     (unsigned long long)sizeof(smsg), smsg.msgtype,
+	     (unsigned long long)vnet_msg->datalen,
+	     rmi_addr_to_ptr(vnet_msg->data), (unsigned long long)smsg.arg);
+
+    if (rmi_send_event(domid, RMI_EVENT_VNET, sizeof(smsg),
+		       rmi_addr_to_ptr(&smsg)) < 0) {
+	printk("Critical : Event send failed for domain %d\n", domid);
+	rmi_cluster_free(cl_cache_send[domid].cl, vnet_msg);
+    }
+
+    priv = netdev_priv(vnet_dev);
+    priv->stats.tx_packets++;
+    priv->stats.tx_bytes += skblen;
+
+    if (shortpkt)
+	kfree(shortpkt);
+
+}
+
+
+/*
+ * Broadcast vnet packet to all up and running domains which
+ * have vnet0 interface up.
+ */
+static void rmi_vnet_pkt_broadcast(uint64_t vnet_dom_map, struct sk_buff *skb)
+{
+    struct rmi_domain dest_dom;
+    rmi_dom_t domid;
+
+    for (domid = RMI_DOMAIN_REMOVED + 1; domid < RMI_MAX_DOMAINS; domid++) {
+
+	rmi_get_domain(domid, &dest_dom);
+
+	if ((domid == rmi_this_domain->id) ||
+	    (dest_dom.state != RMI_D_RUNNING)) {
+	    continue;
+	}
+
+	if (!((1ULL << domid) & vnet_dom_map))
+	    continue;
+	
+
+	VNET_DBG("broadcast to domid %u dest_dom.id %u state %d\n",
+		 domid, dest_dom.id, dest_dom.state);
+
+	rmi_vnet_pkt_unicast(domid, skb);
+
+    }
+}
+
+
+static void rmi_vnet_pkt_send_event(struct sk_buff *skb, int broadcast)
+{
+    struct rmi_domain promisc_dest_dom;
+    rmi_dom_t promisc_domid;
+    struct rmi_domain dest_dom;
+    rmi_dom_t domid;
+    char *skb_data;
+    volatile uint64_t vnet_dom_map = 0x0ULL;
+    volatile uint64_t vnet_promisc_map = 0x0ULL;
+    uint64_t mask;
+    int i;
+
+    skb_data = skb->data;
+    domid = skb_data[ETH_ALEN - 1];
+
+    vnet_dom_map = *(uint64_t*)(long)rmi_vnet_dom_map_addr;
+    vnet_promisc_map = *(uint64_t*)(long)rmi_vnet_promisc_dom_map_addr;
+
+    if (!broadcast) { /* unicast packets */
+
+	/*
+	 * First check for promiscuous vnet0 interfaces and steer the packets
+	 * to the owning domains.
+	 */
+	for (i = RMI_DOMAIN_REMOVED + 1; i < RMI_MAX_DOMAINS; i++) {
+	    
+	    mask = 0x1ULL << i;
+	    promisc_domid = i;
+
+	    if (!(vnet_promisc_map & mask))
+		continue;
+
+	    rmi_get_domain(promisc_domid, &promisc_dest_dom);
+	    if ((promisc_domid == rmi_this_domain->id) ||
+		(promisc_dest_dom.state != RMI_D_RUNNING)) {
+		continue;
+	    }
+
+	    VNET_DBG("unicast to promisc domid %u dest_dom.id %u state %d\n",
+		    promisc_domid, promisc_dest_dom.id, promisc_dest_dom.state);
+	    rmi_vnet_pkt_unicast(promisc_domid, skb);
+	}
+
+	/*
+	 * Now send the packets to the specified domain id.
+	 */
+	if ((domid <= RMI_DOMAIN_REMOVED) || (domid >= RMI_MAX_DOMAINS)) {
+	    return;
+	}
+
+	rmi_get_domain(domid, &dest_dom);
+	if ((domid == rmi_this_domain->id) || (dest_dom.state != RMI_D_RUNNING)) {
+	    return;
+	}
+
+	if (!((1ULL << domid) & vnet_dom_map))
+	    return;
+
+	rmi_vnet_pkt_unicast(domid, skb);
+    } else {  /* broadcast packets */
+	rmi_vnet_pkt_broadcast(vnet_dom_map, skb);
+    }
+}
+
+
+/*
+ * rmi_vnet_open
+ *
+ * Open the "vnet0" device.
+ */
+static int rmi_vnet_open(struct net_device *dev)
+{
+	/* Interface coming up; set the domain bit in vnet bitmap. */
+	rmi_vnet_dom_map_set_clear_bit(rmi_vnet_dom_map_addr,
+				       rmi_this_domain->id, 1);
+	netif_start_queue(dev);
+	return 0;
+}
+
+
+static int rmi_vnet_release(struct net_device *dev)
+{
+	int domid;
+    
+	for (domid = 0; domid < RMI_MAX_DOMAINS; domid++) {
+	    if (cl_cache_send[domid].cl) {
+		rmi_clpool_putref(cl_cache_send[domid].cl);
+		cl_cache_send[domid].cl = NULL;
+	    }
+	}
+
+	if (cl_cache_rx.cl) {
+	    rmi_clpool_putref(cl_cache_rx.cl);
+	    cl_cache_rx.cl = NULL;
+	}
+
+	/* Interface going down; clear domain bit in vnet bitmap. */
+	rmi_vnet_dom_map_set_clear_bit(rmi_vnet_dom_map_addr,
+				       rmi_this_domain->id, 0);
+	/* Clear promisc bit */
+	rmi_vnet_promisc_map_set_clear_bit(rmi_vnet_promisc_dom_map_addr,
+					   rmi_this_domain->id, 0);
+	netif_stop_queue(dev); /* can't transmit any more */
+	return 0;
+}
+
+
+/*
+ * Configuration changes (passed on by ifconfig)
+ */
+static int rmi_vnet_config(struct net_device *dev, struct ifmap *map)
+{
+
+	if (dev->flags & IFF_UP) /* can't act on a running interface */
+		return -EBUSY;
+
+	/* Don't allow changing the I/O address */
+	if (map->base_addr != dev->base_addr) {
+		printk(KERN_WARNING "rmi_vnet: Can't change I/O address\n");
+		return -EOPNOTSUPP;
+	}
+
+	/* ignore other fields */
+	return 0;
+}
+
+
+
+/*
+ * Transmit a packet (low level interface)
+ */
+static void rmi_vnet_hw_tx(struct sk_buff *skb)
+{
+	int is_broadcast = 1;	
+	struct ethhdr *eth;
+	int i;
+    
+	VNET_DBG("%s\n", __FUNCTION__);
+	/* I am paranoid. Ain't I? */
+	if (skb->len < sizeof(struct ethhdr) + sizeof(struct iphdr)) {
+		printk("rmi_vnet: Hmm... packet too short (%i octets)\n", skb->len);
+		return;
+	}
+
+	rmi_vnet_dump_pkt_info(skb);
+
+	/*
+	 * If it is a broadcast packet, broadcast it to all running CRF
+	 * domains.
+	 */
+	eth = (struct ethhdr*)skb->data;
+
+	for (i = 0; i < 6; i++) {
+	    if ((eth->h_dest[i] & 0xff) != 0xff) {
+		is_broadcast = 0;
+		break;
+	    }
+	}
+
+	rmi_vnet_pkt_send_event(skb, is_broadcast);
+}
+
+
+/*
+ * Transmit a packet (called by the kernel)
+ */
+static int rmi_vnet_tx(struct sk_buff *skb, struct net_device *dev)
+{
+	dev->trans_start = jiffies; /* save the timestamp */
+	rmi_vnet_hw_tx(skb);
+	dev_kfree_skb(skb); /* Free the skbuf */
+
+	return 0; /* Our simple device can not fail */
+}
+
+
+/*
+ * Deal with a transmit timeout.
+ */
+static void rmi_vnet_tx_timeout (struct net_device *dev)
+{
+	struct rmi_vnet_priv *priv = netdev_priv(dev);
+
+	VNET_DBG("rmi_vnet: Transmit timeout at %ld, latency %ld\n", jiffies,
+		jiffies - dev->trans_start);
+
+	priv->stats.tx_errors++;
+	netif_wake_queue(dev);
+	return;
+}
+
+
+/*
+ * Ioctl commands 
+ */
+static int rmi_vnet_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
+{
+	VNET_DBG("rmi_vnet: ioctl\n");
+	return 0;
+}
+
+
+/*
+ * Return statistics to the caller
+ */
+static struct net_device_stats *rmi_vnet_stats(struct net_device *dev)
+{
+	struct rmi_vnet_priv *priv = netdev_priv(dev);
+	return &priv->stats;
+}
+
+
+/*
+ * Change MTU
+ */
+static int rmi_vnet_change_mtu(struct net_device *dev, int new_mtu)
+{
+	unsigned long flags;
+	struct rmi_vnet_priv *priv = netdev_priv(dev);
+	spinlock_t *lock = &priv->lock;
+    
+	/* check ranges */
+	if ((new_mtu < 68) || (new_mtu > 1500))
+		return -EINVAL;
+
+	/* accept the value */
+	spin_lock_irqsave(lock, flags);
+	dev->mtu = new_mtu;
+	spin_unlock_irqrestore(lock, flags);
+
+	return 0; /* success */
+}
+
+
+/*
+ * Hard code mac address and associate the CRF domainid with it.
+ */
+static void rmi_vnet_set_mac_address(struct net_device *dev) {
+	/* 
+	 * Assign the hardware address to the vnet interface:
+	 * Use "\0VNETx", where x is 0. The first byte is '\0'
+	 * to avoid being a multicast address (the first byte
+	 * of multicast addrs is odd).
+	 */
+	memcpy(dev->dev_addr, "\0VNET0", ETH_ALEN);
+
+	/*
+	 * Make last byte of MAC addr as domainid. This helps
+	 * identify CRF domain to which ether packet belongs.
+	 */
+	dev->dev_addr[ETH_ALEN - 1] = rmi_this_domain->id;
+}
+
+
+static void rmi_vnet_multicast_list(struct net_device *dev)
+{
+
+    if (dev->flags & IFF_PROMISC) {
+	VNET_DBG("%s: vnet0 interface entering promisc mode\n", __FUNCTION__);
+	rmi_vnet_promisc_map_set_clear_bit(
+				rmi_vnet_promisc_dom_map_addr,
+				rmi_this_domain->id, 1);
+    } else {
+	VNET_DBG("%s: vnet0 interface exiting promisc mode\n", __FUNCTION__);
+	rmi_vnet_promisc_map_set_clear_bit(
+				rmi_vnet_promisc_dom_map_addr,
+				rmi_this_domain->id, 0);
+    }
+}
+
+
+/*
+ * The init function (sometimes called probe).
+ * It is invoked by register_netdev()
+ */
+static void rmi_vnet_init(struct net_device *dev)
+{
+	struct rmi_vnet_priv *priv;
+
+	ether_setup(dev);
+
+	dev->open            = rmi_vnet_open;
+	dev->stop            = rmi_vnet_release;
+
+	/*
+	 * MAC addr change is not allowed as last byte is hardcoded
+	 * to represent domainid within CRF
+	 */
+	dev->set_mac_address = NULL; 
+
+	dev->set_config      = rmi_vnet_config;
+	dev->hard_start_xmit = rmi_vnet_tx;
+	dev->do_ioctl        = rmi_vnet_ioctl;
+	dev->get_stats       = rmi_vnet_stats;
+	dev->change_mtu      = rmi_vnet_change_mtu;  
+	dev->tx_timeout      = rmi_vnet_tx_timeout;
+	dev->set_multicast_list = rmi_vnet_multicast_list;
+	dev->watchdog_timeo = timeout;
+
+	/*
+	 * Then, initialize the priv field. This encloses the statistics
+	 * and a few private fields.
+	 */
+	priv = netdev_priv(dev);
+	memset(priv, 0, sizeof(struct rmi_vnet_priv));
+	spin_lock_init(&priv->lock);
+	rmi_vnet_dom_map_addr = rmi_vnet_dom_map_get_addr();
+	rmi_vnet_promisc_dom_map_addr = rmi_vnet_promisc_map_get_addr();
+}
+
+
+/*
+ * Finally, the module stuff
+ */
+static void rmi_vnet_cleanup(void)
+{
+	if (vnet_dev) {
+	    unregister_netdev(vnet_dev);
+	    free_netdev(vnet_dev);
+	}
+
+	return;
+}
+
+
+static int rmi_vnet_init_module(void)
+{
+	int result, ret = -ENOMEM;
+
+	/* 
+	 * This driver is meant for communicating between different domains in CRF.
+	 * So, if CRF is not up, simply return.
+	 */
+	if (!rmik_en) {
+	    return -ENODEV;
+	}
+
+	/* Allocate the devices */
+	vnet_dev = alloc_netdev(sizeof(struct rmi_vnet_priv), "vnet%d", rmi_vnet_init);
+
+	if (vnet_dev == NULL)
+		goto out;
+
+	ret = -ENODEV;
+
+
+	if ((result = register_netdev(vnet_dev))) {
+	    printk("rmi_vnet: error %i registering device \"%s\" \n",
+		    result, vnet_dev->name);
+	} else {
+	    ret = 0;
+	}
+
+	/* Assign mac address */
+	rmi_vnet_set_mac_address(vnet_dev);
+
+	/* Register virtual net handler for receiving events from other CRF domain */
+	rmi_vnet_pkt_event_handler = rmi_vnet_pkt_get_event;
+
+   out:
+	if (ret) 
+		rmi_vnet_cleanup();
+	return ret;
+}
+
+
+module_init(rmi_vnet_init_module);
+module_exit(rmi_vnet_cleanup);
diff --git a/drivers/net/rmi_vnet.h b/drivers/net/rmi_vnet.h
new file mode 100644
index 0000000..2ef063a
--- /dev/null
+++ b/drivers/net/rmi_vnet.h
@@ -0,0 +1,90 @@
+/*
+ * $Id: $
+ *
+ * rmi_vnet.h - Shared memory based virtual network driver defines
+ *
+ */
+
+#ifndef _RMI_VNET_H
+#define _RMI_VNET_H
+
+
+extern uint32_t rmik_en;
+extern int rmi_vnet_debug;
+
+#define VNET_DBG(format, args...) \
+    if (rmi_vnet_debug) printk(KERN_DEBUG format, ##args );
+
+#define RMI_VNET_TIMEOUT	5
+
+static inline rmi_addr_t rmi_vnet_dom_map_get_addr(void)
+{
+	rmi_addr_t addr = 0x0ULL;
+	rmi_resource_t res;
+
+	if (rmi_resource_getref("vnet", &res, NULL) != 0) {
+		return 0;
+	}
+
+	if (rmi_get_addr_property(res, "dom-map", &addr) < 0) {
+		rmi_resource_putref(res);
+		return 0;
+	}
+
+	rmi_resource_putref(res);
+	return addr;
+
+}
+
+static inline void rmi_vnet_dom_map_set_clear_bit(rmi_addr_t vnet_dom_map_addr,
+						  rmi_dom_t domid, int set)
+{
+	if (domid < 0 || domid >= RMI_MAX_DOMAINS)
+		return;
+
+	if (set) {
+		xlr_atomic_bit_set_u64(domid,
+				       rmi_addr_to_ptr(vnet_dom_map_addr));
+	} else {
+		xlr_atomic_bit_clear_u64(domid,
+					 rmi_addr_to_ptr(vnet_dom_map_addr));
+	}
+}
+
+
+static inline rmi_addr_t rmi_vnet_promisc_map_get_addr(void)
+{
+	rmi_addr_t addr = 0x0ULL;
+	rmi_resource_t res;
+
+	if (rmi_resource_getref("vnet", &res, NULL) != 0) {
+		return 0;
+	}
+
+	if (rmi_get_addr_property(res, "promisc-dom-map", &addr) < 0) {
+		rmi_resource_putref(res);
+		return 0;
+	}
+
+	rmi_resource_putref(res);
+	return addr;
+
+}
+
+static inline void rmi_vnet_promisc_map_set_clear_bit(
+					    rmi_addr_t promisc_dom_map_addr,
+					    rmi_dom_t domid, int set)
+{
+	if (domid < 0 || domid >= RMI_MAX_DOMAINS)
+		return;
+
+	if (set) {
+		xlr_atomic_bit_set_u64(domid,
+				       rmi_addr_to_ptr(promisc_dom_map_addr));
+	} else {
+		xlr_atomic_bit_clear_u64(domid,
+					 rmi_addr_to_ptr(promisc_dom_map_addr));
+	}
+}
+
+#endif /* _RMI_VNET_H */
diff --git a/drivers/net/xlr_ip_over_pci_dev.c b/drivers/net/xlr_ip_over_pci_dev.c
new file mode 100644
index 0000000..4d751c9
--- /dev/null
+++ b/drivers/net/xlr_ip_over_pci_dev.c
@@ -0,0 +1,615 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/socket.h>
+#include <linux/errno.h>
+#include <linux/fcntl.h>
+#include <linux/in.h>
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/workqueue.h>
+#include <linux/kernel.h>
+#include <linux/inet.h>
+#include <linux/netdevice.h>
+#include <linux/ethtool.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <net/sock.h>
+#include <linux/if_ether.h>	/* For the statistics structure. */
+#include <linux/if_arp.h>	/* For ARPHRD_ETHER */
+#include <linux/autoconf.h>
+#include <linux/proc_fs.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/io.h>
+#include <asm/cache.h>
+
+#include <asm/rmi/debug.h>
+#include <asm/rmi/pci.h>
+#include <asm/rmi/pic.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/proc.h>
+#include <asm/rmi/rmi_pcix_gen_dev.h>
+
+#define DRV_NAME	"rmi_ip_over_pci"
+#define DRV_VERSION	"0.1"
+#define DRV_RELDATE	"10Feb2004"
+
+#define XLR_TX_DESC 512 
+#define XLR_RX_DESC 512
+
+#define BRIDGE_PCIXMEM_BAR 35
+
+#define Message(a,b...) //printk("\n[%s] - "a"\n",__FUNCTION__,##b)
+#define ErrorMsg(a,b...) printk("\nError in [%s] - "a"\n",__FUNCTION__,##b)
+
+#define XLR_INTERFACE_IS_UP 1
+#define XLR_INTERFACE_IS_DOWN 2
+#define XLR_MAGIC_NO 0xdeadbeef
+
+static struct net_device *xlr_netdev= NULL;
+static unsigned int *xlr_ip_over_pci_base = NULL;
+typedef volatile unsigned int xlr_reg_t;
+static struct net_device_ops rmi_dev_net_ops;
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+static int mailbox_index;
+#endif
+
+extern int xlr_init_dma(void);
+extern int xlr_request_dma(uint64_t src, uint64_t dest, uint32_t len);
+extern int xlr_async_request_dma(uint64_t src, uint64_t dest, uint32_t len,
+			void (*func)(void *,uint64_t),void *data);
+extern long phnx_get_shared_mem_base_dev(void);
+static void setup_shared_mem(void);
+static void xlr_pcix_init(void);
+
+/*DEBUG CNTRS*/
+static int xlr_rx_pkt;
+static int xlr_tx_pkt;
+static int xlr_rx_dma_enqueue_failed;
+static int xlr_tx_dma_enqueue_failed;
+static int xlr_rx_dma_error;
+static int xlr_tx_dma_error;
+/*DEBUG CNTRS END*/
+
+#define XLR_GET_OWN(x) (x->info & 0x80000000)
+#define XLR_RESET_OWN(x) (x->info = x->info & 0x7fffffff)
+#define XLR_GET_HOST_PHYS(x) (x->addr)
+#define XLR_SET_LEN(x,len) x->info = x->info & ~(0x3fff); \
+			   x->info |= len;
+#define XLR_GET_LEN(x) (x->info & 0x3fff)
+
+
+struct xlr_xmit_desc{
+	uint32_t addr;
+	uint32_t info;/*  Bit 0 to 15 LEN
+    		 	  Bit 16 to 30 Reserved 
+			  Bit 31 OWN						                       */
+
+};
+struct xlr_rcv_desc{
+	uint32_t addr;
+	uint32_t info;/*  Bit 0 to 15 LEN
+    		 	  Bit 16 to 30 RESERVED
+			  Bit 31 OWN						                       */
+
+};
+
+static volatile struct xlr_xmit_desc *xlr_xmit_desc_base;
+
+static volatile struct xlr_rcv_desc *xlr_rcv_desc_base;
+
+static volatile unsigned int xmit_producer=0;
+static volatile unsigned int rx_consumer=0;
+
+static volatile uint32_t *xlr_magic_no;
+static volatile uint32_t *xlr_host_status;
+static volatile uint32_t *xlr_dev_status;
+static struct timer_list xlr_link_status_timer;
+static volatile uint32_t xlr_dev_status_local;
+static struct driver_data{
+	struct net_device *dev;	
+	struct xlr_xmit_desc *curr_xmit;
+	struct xlr_xmit_desc *xmit_base;
+	struct xlr_rcv_desc *curr_rx;
+	struct xlr_rcv_desc *rx_base;
+}*ip_over_pci_priv;
+
+
+static volatile int xmit_dma_request_submitted=0;
+static volatile int xmit_dma_request_completed=0;
+static volatile int rx_dma_request_submitted=0;
+static volatile int rx_dma_request_completed=0;
+static volatile int xlr_queue_is_stop=0;
+static spinlock_t xlr_tx_ok_sync=SPIN_LOCK_UNLOCKED;
+static spinlock_t xlr_rx_dma=SPIN_LOCK_UNLOCKED;
+static spinlock_t xlr_tx_dma=SPIN_LOCK_UNLOCKED;
+static spinlock_t xlr_xmit_sync = SPIN_LOCK_UNLOCKED;
+
+#if !defined(XLR_MAILBOX_IS_SUPPORTED)
+static void ip_over_pci_rx(struct work_struct *data);
+#else
+static irqreturn_t ip_over_pci_rx(void *data, struct pt_regs *regs);
+#endif
+struct priv_rx_data{
+	struct sk_buff *skb;
+	int rx_consumer;
+};
+
+struct priv_tx_data{
+	struct sk_buff *skb;
+	int tx_producer;
+};
+
+static void tx_dma_done(void *data, uint64_t status)
+{
+	struct priv_tx_data *priv= (struct priv_tx_data *)data;
+	int ret,err;
+	int error_flag=0;
+	volatile struct xlr_xmit_desc *curr_xmit_desc;
+	unsigned long mflags;
+
+	ret = (status >> 62) & 0x3;
+	err = (status >> 60) & 0x3;
+	
+	if(ret != 0x3) {
+		ErrorMsg("%s: Bad return code %d from DMA engine\n", \
+				__FUNCTION__,ret);
+		error_flag=1;
+	}
+	if(err & 0x2) {
+		ErrorMsg("%s:DMA engine reported Message format error\n", \
+				__FUNCTION__);
+		error_flag=1;
+	}
+	if(err & 0x1) {
+		ErrorMsg("%s:DMA engine reported Bus error\n", __FUNCTION__);
+		error_flag=1;
+	}
+
+	dev_kfree_skb_irq(priv->skb);
+	if(error_flag){
+		curr_xmit_desc = xlr_xmit_desc_base + priv->tx_producer;
+		//TODO: Instead of own bit set some error flag in descriptor.
+		//This packet will be dropped by host proto stack.
+		XLR_RESET_OWN(curr_xmit_desc);
+		xlr_tx_dma_error++;
+		phnx_interrupt_host();
+	}
+	else{
+		curr_xmit_desc = xlr_xmit_desc_base + priv->tx_producer;
+		XLR_RESET_OWN(curr_xmit_desc);
+		xlr_tx_pkt++;
+		//Send msi to host - Rx For HOST 
+		phnx_interrupt_host();
+	}
+	spin_lock_irqsave(&xlr_tx_dma,mflags);
+	xmit_dma_request_completed = (xmit_dma_request_completed+1)%XLR_TX_DESC;
+	spin_unlock_irqrestore(&xlr_tx_dma,mflags);
+	kfree(priv);
+	spin_lock_irqsave(&xlr_tx_ok_sync,mflags);
+	if(xlr_queue_is_stop){
+		netif_start_queue(xlr_netdev);
+		xlr_queue_is_stop = 0;
+	}
+	spin_unlock_irqrestore(&xlr_tx_ok_sync,mflags);
+}
+
+
+static void rx_dma_done(void *data, uint64_t status)
+{
+	struct priv_rx_data *priv= (struct priv_rx_data *)data;
+	int ret,err;
+	int error_flag=0;
+	volatile struct xlr_rcv_desc *curr_rcv_desc;
+	unsigned long mflags;
+
+	
+	ret = (status >> 62) & 0x3;
+	err = (status >> 60) & 0x3;
+	if(ret != 0x3) {
+		ErrorMsg("%s: Bad return code %d from DMA engine\n", \
+				__FUNCTION__,ret);
+		error_flag=1;
+	}
+	if(err & 0x2) {
+		ErrorMsg("%s:DMA engine reported Message format error\n", \
+				__FUNCTION__);
+		error_flag=1;
+	}
+	if(err & 0x1) {
+		ErrorMsg("%s:DMA engine reported Bus error\n", __FUNCTION__);\
+		error_flag=1;
+	}
+	if(error_flag){
+		dev_kfree_skb_irq(priv->skb);
+		curr_rcv_desc = xlr_rcv_desc_base + priv->rx_consumer;
+		XLR_RESET_OWN(curr_rcv_desc);
+		xlr_rx_dma_error++;
+		phnx_interrupt_host();
+	}
+	else{
+		curr_rcv_desc = xlr_rcv_desc_base + priv->rx_consumer;
+		XLR_RESET_OWN(curr_rcv_desc);
+		priv->skb->protocol = eth_type_trans(priv->skb,priv->skb->dev);
+		netif_rx(priv->skb);
+		Message("\nSKB QUEUED TO UPPER LAYER - Len %d\n",priv->skb->len);
+		//Send msi to host - tx_ok
+		phnx_interrupt_host();
+		xlr_rx_pkt++;
+	}
+	spin_lock_irqsave(&xlr_rx_dma,mflags);
+	rx_dma_request_completed = (rx_dma_request_completed+1)%XLR_RX_DESC;
+	spin_unlock_irqrestore(&xlr_rx_dma,mflags);
+	kfree(priv);
+}
+
+#if !defined(XLR_MAILBOX_IS_SUPPORTED)
+static DECLARE_DELAYED_WORK(ip_over_pci_task,ip_over_pci_rx);
+static void ip_over_pci_rx(struct work_struct  *data)
+#else
+static irqreturn_t ip_over_pci_rx (void *data,struct pt_regs *regs)
+#endif
+{
+	volatile struct xlr_rcv_desc *curr_rcv_desc;
+	uint64_t phys_addr=0;
+	struct sk_buff *skb;
+	int data_len;
+	int count = 0x0;
+	struct priv_rx_data *priv;
+
+	curr_rcv_desc = xlr_rcv_desc_base + rx_consumer;
+	/*Check If There Is ANyting To Rcv.*/
+	while(XLR_GET_OWN(curr_rcv_desc)){
+		if(((rx_dma_request_submitted + 1)%XLR_RX_DESC) == 
+						rx_dma_request_completed){
+			//ErrorMsg("rx_dma_request_completed = %d,rx_dma_request_submitted = %d",	rx_dma_request_completed,rx_dma_request_submitted);
+			break;
+		}
+    count++;
+		priv = kmalloc(sizeof(struct priv_rx_data),GFP_ATOMIC);
+		
+		if(!priv){
+			ErrorMsg("Priv Allocation Failed In tasklet");
+			break;
+		}
+		
+		phys_addr = XLR_GET_HOST_PHYS(curr_rcv_desc);
+		phys_addr = phys_addr | 0x8000000000ULL;
+		data_len = XLR_GET_LEN(curr_rcv_desc);
+
+		skb = dev_alloc_skb(data_len+14);
+		Message("\nRcvd Buf From Host\n");
+		if(!skb){
+			ErrorMsg("\nSKB Alloction Failed\n");
+			kfree(priv);
+			break;
+		}
+		priv->skb = skb;
+		priv->rx_consumer = rx_consumer;
+
+		Message("\nRcvd Pkt Len of %d\n",data_len);
+		skb_reserve(skb, 2);
+		skb_put(skb,data_len);
+		skb->dev = xlr_netdev;
+
+		if(xlr_async_request_dma(phys_addr,virt_to_phys(skb->data),
+					data_len,rx_dma_done,(void *)priv)){
+			//ErrorMsg("Rx DMA Queue Failed");
+			xlr_rx_dma_enqueue_failed++;
+			dev_kfree_skb(skb);
+			kfree(priv);
+			break;
+		}
+		rx_dma_request_submitted = (rx_dma_request_submitted+1)%
+							XLR_RX_DESC;
+		rx_consumer = (rx_consumer + 1)% XLR_RX_DESC;
+		curr_rcv_desc = xlr_rcv_desc_base + rx_consumer;
+	}
+	if(*xlr_magic_no != XLR_MAGIC_NO){
+		//Reset All Prod/Cons here.
+		spin_lock(&xlr_xmit_sync);
+                xmit_dma_request_submitted = xmit_dma_request_completed = 0;
+                xmit_producer = rx_consumer = 0;
+                rx_dma_request_submitted = rx_dma_request_completed = 0;
+		spin_unlock(&xlr_xmit_sync);
+	}	
+#if defined(XLR_MAILBOX_IS_SUPPORTED)
+	return IRQ_HANDLED;
+#else
+	schedule_delayed_work(&ip_over_pci_task, 1);
+#endif
+}
+
+
+static void put_dummy_mac_address(struct net_device *dev)
+{
+	dev->dev_addr[0] = 0x0;
+	dev->dev_addr[1] = 0xa;
+	dev->dev_addr[2] = 0x0;
+	dev->dev_addr[3] = 0xa;
+	dev->dev_addr[4] = 0x0;
+	dev->dev_addr[5] = 0xa;
+}
+
+static int xlr_ip_over_pci_open(struct net_device *dev)
+{
+	xlr_dev_status_local = 1;
+	*xlr_dev_status = 1;
+	return 0;
+}
+
+static int xlr_ip_over_pci_close(struct net_device *dev)
+{
+	netif_stop_queue(dev);
+	xlr_dev_status_local = 2;
+	*xlr_dev_status = 2;
+	return 0;
+}
+
+static int xlr_ip_over_pci_xmit (struct sk_buff *skb,struct net_device *dev)
+{
+	volatile struct xlr_xmit_desc *curr_xmit_desc;
+	uint64_t phys_addr=0;
+	struct priv_tx_data *priv;
+	int old_val;
+	unsigned long mflags;
+
+	if(*xlr_magic_no != XLR_MAGIC_NO){
+		netif_stop_queue(dev);
+		return -EIO;
+	}
+	if(*xlr_host_status == XLR_INTERFACE_IS_DOWN){
+		netif_stop_queue(dev);
+		return -EIO;
+	}
+	if(skb->len > 1514){
+		ErrorMsg("\n %d Len Not Supported\n",skb->len);
+		return -ENOMEM;
+	}
+	if(((xmit_dma_request_submitted + 1)%XLR_TX_DESC) == 
+				xmit_dma_request_completed){
+		Message("xmit_dma_request_completed = %d,xmit_dma_request_submitted = %d",xmit_dma_request_completed,xmit_dma_request_submitted);
+		spin_lock_irqsave(&xlr_tx_ok_sync,mflags);
+		if(((xmit_dma_request_submitted + 1)%XLR_TX_DESC) !=
+                                xmit_dma_request_completed){
+			spin_unlock_irqrestore(&xlr_tx_ok_sync,mflags);
+			goto try_again;
+		}
+		xlr_queue_is_stop = 1;
+		netif_stop_queue(dev);	
+		spin_unlock_irqrestore(&xlr_tx_ok_sync,mflags);
+		return -ENOMEM;
+	}
+try_again:
+	priv = kmalloc(sizeof(struct priv_tx_data),GFP_KERNEL);
+	if(!priv){
+		ErrorMsg("priv allocation failed");
+		return -ENOMEM;
+	}
+	curr_xmit_desc = xlr_xmit_desc_base + xmit_producer;
+
+	if(!XLR_GET_OWN(curr_xmit_desc)){
+		Message("\nHost Memory is Not Available for XMIT\n");
+		kfree(priv);
+		return -ENOMEM;
+	}
+	phys_addr = XLR_GET_HOST_PHYS(curr_xmit_desc);
+	
+	
+	phys_addr = phys_addr | 0x8000000000ULL;
+	priv->tx_producer = xmit_producer;
+	priv->skb = skb;
+	XLR_SET_LEN(curr_xmit_desc,skb->len);
+
+	old_val = xmit_dma_request_submitted;
+	xmit_dma_request_submitted = (xmit_dma_request_submitted+1)%XLR_TX_DESC;
+	if(xlr_async_request_dma(virt_to_phys(skb->data),phys_addr,skb->len,\
+				tx_dma_done,priv)){
+		//ErrorMsg("Cant Queue XMIT Msg.");
+		kfree(priv);
+		xlr_tx_dma_enqueue_failed++;
+		xmit_dma_request_submitted = old_val;
+		return -EIO;
+	}
+	Message("Xmit Pkt With Len skblen %d -> desc len %d",
+				skb->len,XLR_GET_LEN(curr_xmit_desc));
+
+	spin_lock_irqsave(&xlr_xmit_sync,mflags);
+	if(*xlr_magic_no == XLR_MAGIC_NO)
+		xmit_producer = (xmit_producer + 1) % XLR_TX_DESC;
+	spin_unlock_irqrestore(&xlr_xmit_sync,mflags);
+	return 0;
+}
+
+
+static void setup_shared_mem(void)
+{
+	xlr_ip_over_pci_base = (unsigned int *)(phnx_get_shared_mem_base_dev()
+				 +PHNX_IP_OVER_PCI_MEM_BASE);
+	xlr_xmit_desc_base = (struct xlr_xmit_desc *)xlr_ip_over_pci_base;
+	xlr_rcv_desc_base = (struct xlr_rcv_desc *)
+				((unsigned char *)xlr_xmit_desc_base
+				 + XLR_TX_DESC*sizeof(struct xlr_xmit_desc));
+
+	xlr_magic_no = (uint32_t *)((xlr_rcv_desc_base + XLR_RX_DESC));
+        xlr_host_status = xlr_magic_no + 1;
+        xlr_dev_status = xlr_host_status + 1;
+
+        Message("\nXlrXmitBase %#x to %#x\n",(uint32_t)xlr_xmit_desc_base,
+			(uint32_t)xlr_rcv_desc_base);
+        Message("\nXlrRxBase %#x to %#x\n",(uint32_t)xlr_rcv_desc_base,
+	(uint32_t)(xlr_rcv_desc_base+XLR_RX_DESC*sizeof(struct xlr_rcv_desc)));
+	Message("XlrMagicNo. %#x",xlr_magic_no);
+}
+
+static void xlr_pcix_init(void)
+{
+        xlr_reg_t *bmmio = 0;
+        bmmio = phoenix_io_mmio(PHOENIX_IO_BRIDGE_OFFSET);
+	/*Set Defeature bit*/
+	bmmio[59] |= 0x2;
+	/* Use 0x8000000000ULL and above for PCI addresses in XLR memory map */
+	bmmio[BRIDGE_PCIXMEM_BAR] = 0x8000ffff;
+	Message("\nDefeature REgister Addr %#x And Value Is %#x\n",
+			(unsigned int)&bmmio[59],bmmio[59]);
+	Message("\nBRIDGE PCIXMEM BAR REG ADDR %#x and Value Is %#x\n",
+			(unsigned int)&bmmio[BRIDGE_PCIXMEM_BAR],
+			bmmio[BRIDGE_PCIXMEM_BAR]);
+}
+
+static struct net_device_stats xlr_net_stats;;
+static struct net_device_stats* xlr_get_stats(struct net_device *dev)
+{
+	memset(&xlr_net_stats,0,sizeof(struct net_device_stats));
+	xlr_net_stats.rx_packets = xlr_rx_pkt;
+	xlr_net_stats.tx_packets = xlr_tx_pkt;
+	xlr_net_stats.rx_errors = xlr_rx_dma_error;
+	xlr_net_stats.tx_errors = xlr_tx_dma_error;
+	return &xlr_net_stats;
+}
+
+static void xlr_link_status(unsigned long data)
+{
+	uint32_t host_status, dev_status;
+
+	*xlr_dev_status = xlr_dev_status_local;
+
+	if(*xlr_magic_no != XLR_MAGIC_NO){
+		if(!netif_queue_stopped(xlr_netdev))
+			netif_stop_queue(xlr_netdev);
+		goto try_again;
+	}
+
+	/*Read Host n Dev Status*/
+	/*1 = open, 2 = close*/
+	host_status = *xlr_host_status;
+	dev_status = *xlr_dev_status;
+
+	if(dev_status == 1 && host_status == 1){
+		if(netif_queue_stopped(xlr_netdev) && !xlr_queue_is_stop){
+			netif_start_queue(xlr_netdev);
+		}
+	}else if(!netif_queue_stopped(xlr_netdev)){
+		Message("\nStoppin Queue.\n");
+		netif_stop_queue(xlr_netdev);
+	}
+
+try_again:
+	xlr_link_status_timer.expires = jiffies + 10;
+	add_timer(&xlr_link_status_timer);
+}
+
+static void setup_net_ops(struct net_device *dev)
+{
+	rmi_dev_net_ops.ndo_open = xlr_ip_over_pci_open;
+	rmi_dev_net_ops.ndo_stop = xlr_ip_over_pci_close;
+	rmi_dev_net_ops.ndo_get_stats = xlr_get_stats;
+	rmi_dev_net_ops.ndo_start_xmit = xlr_ip_over_pci_xmit;
+	dev->netdev_ops = &rmi_dev_net_ops;
+}
+
+static int xlr_ip_over_pci_init(void)
+{
+	struct net_device *dev = 0;
+	struct driver_data *priv = 0;
+	int ret = 0;
+
+  if(xlr_get_pci_mode() == XLR_PCI_HOST_MODE){
+    Message("\nXlr Is Configured In Host Mode - Unloading xlr_ip_over_pci_dev");
+		return -EIO;
+  }
+	
+	/*Do DMA initialization*/
+	if(xlr_init_dma()){
+		ErrorMsg("xlr_init_dma failed");
+		ret = -EIO;
+		goto out;
+	}
+
+	xlr_netdev = dev = alloc_etherdev(sizeof(struct driver_data));
+	if (!dev) {
+		ret = -ENOMEM;
+		goto out;
+	}
+	/*Set Defeature bit and bridge pcix mmio bar*/	
+	xlr_pcix_init();	
+	/*Get the shared region base address for ip_over_pci descriptors.*/
+	setup_shared_mem();
+
+	ip_over_pci_priv = priv = netdev_priv(dev);
+	priv->dev = dev;
+
+	setup_net_ops(dev);
+	
+	put_dummy_mac_address(dev);
+
+	ether_setup(dev);
+
+	ret = register_netdev(dev);
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+	phnx_request_mailbox_handler(ip_over_pci_rx,NULL,&mailbox_index);
+#else
+	schedule_delayed_work(&ip_over_pci_task, 0);
+#endif
+	init_timer(&xlr_link_status_timer);       
+        xlr_link_status_timer.function = xlr_link_status;
+        xlr_link_status_timer.expires = jiffies + 10;
+        add_timer(&xlr_link_status_timer);
+
+  printk("xlr_ip_over_pci_dev registered\n");
+out:
+	return ret;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static void xlr_ip_over_pci_exit(void)
+{
+	if(!xlr_netdev)
+		return;	
+	unregister_netdev(xlr_netdev);
+	free_netdev(xlr_netdev);
+#ifdef XLR_MAILBOX_IS_SUPPORTED
+	phnx_free_mailbox_handler(&mailbox_index);
+#endif
+}
+
+module_init(xlr_ip_over_pci_init);
+module_exit(xlr_ip_over_pci_exit);
diff --git a/drivers/net/xlr_ip_over_pci_host.c b/drivers/net/xlr_ip_over_pci_host.c
new file mode 100644
index 0000000..4ad60c4
--- /dev/null
+++ b/drivers/net/xlr_ip_over_pci_host.c
@@ -0,0 +1,708 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/socket.h>
+#include <linux/errno.h>
+#include <linux/fcntl.h>
+#include <linux/in.h>
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/workqueue.h>
+#include <linux/kernel.h>
+#include <linux/inet.h>
+#include <linux/netdevice.h>
+#include <linux/ethtool.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <net/sock.h>
+#include <linux/if_ether.h>	/* For the statistics structure. */
+#include <linux/if_arp.h>	/* For ARPHRD_ETHER */
+#include <linux/autoconf.h>
+#include <linux/proc_fs.h>
+
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/io.h>
+#include <asm/cache.h>
+#include <linux/delay.h>
+#include <linux/timer.h>
+
+
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/rmi_pcix_gen_host.h>
+#else
+#include "rmi_pcix_gen_host.h"
+#endif
+
+#define DRV_NAME	"rmi_ip_over_pci"
+#define DRV_VERSION	"0.1"
+#define DRV_RELDATE	"10Feb2004"
+
+#define XLR_TX_DESC 512 
+#define XLR_RX_DESC 512  
+#define RX_DESC_SIZE (sizeof(struct xlr_rcv_desc) / sizeof(unsigned int)) 
+#define TX_DESC_SIZE (sizeof(struct xlr_xmit_desc) / sizeof(unsigned int)) 
+#define PHNX_SMP_CACHE_BYTES 32
+
+#define Message(a,b...) //printk("\n[%s] - "a"\n",__FUNCTION__,##b)
+#define ErrorMsg(a,b...) printk("\nError in [%s] - "a"\n",__FUNCTION__,##b)
+#define XLR_MAX_RX_LEN 1536
+
+static struct net_device *xlr_netdev= NULL;
+static unsigned int *xlr_ip_over_pci_base = NULL;
+typedef volatile unsigned int xlr_reg_t;
+static struct sk_buff *tx_skb_ptr[XLR_TX_DESC];
+static void setup_shared_mem(void);
+static struct sk_buff * xlr_alloc_skb(void);
+static int xlr_replenish_buffer(void);
+static int replenish_buffer_at_index(int index);
+static int process_rx_desc(void);
+static void process_tx_ok_desc(void);
+static void free_rx_desc(void);
+static void free_rx_desc_index(int i);
+static void free_tx_desc(void);
+
+extern unsigned volatile long phnx_get_shared_mem_base_host(void);
+extern int xlr_init_dma(void);
+extern int xlr_request_dma(uint64_t src, uint64_t dest, uint32_t len);
+extern void rmi_phnx_interrupt_device(void);
+
+
+#define XLR_GET_OWN(x) (((x)->info) & 0x80000000)
+#define XLR_RESET_OWN(x) ((x)->info = ((x)->info) & 0x7fffffff)
+#define XLR_SET_OWN(x) ((x)->info = (x)->info | 0x80000000)
+#define XLR_GET_HOST_PHYS(x) ((x)->addr)
+#define XLR_GET_LEN(x) ((x)->info & 0x3fff)
+#define XLR_SET_LEN(x,len) (x)->info = ((x)->info & ~(0x3fff));\
+		   	    (x)->info |= len
+#define XLR_SET_HOST_PHYS(x,y) ((x)->addr = (y))
+
+#define XLR_INTERFACE_IS_UP 1
+#define XLR_INTERFACE_IS_DOWN 2
+#define XLR_MAGIC_NO 0xdeadbeef
+struct xlr_xmit_desc{
+	uint32_t addr;
+	uint32_t info;/*  Bit 0 to 14 LEN
+    		 	  Bit 15 to 30 Reserved 
+			  Bit 31 OWN						                       */
+
+};
+struct xlr_rcv_desc{
+	uint32_t addr;
+	uint32_t info;/*  Bit 0 to 15 LEN
+    		 	  Bit 16 to 30 RESERVED
+			  Bit 31 OWN						                       */
+
+};
+struct tx_free_info
+{
+        struct sk_buff *tx_skb_ptr;
+        dma_addr_t phys_addr;
+        int len;
+}xlr_tx_free_info[XLR_TX_DESC];
+
+struct rx_free_info
+{
+        struct sk_buff *skb;
+        dma_addr_t phys_addr;
+        int len;
+}xlr_rx_info[XLR_RX_DESC];
+extern struct pci_dev *rmi_pdev;
+
+static struct net_device_ops rmi_host_net_ops;
+/*DEBUG CNTR START*/
+static int xlr_tx_pkt;
+static int xlr_rx_pkt;
+static int xlr_tx_enqueue_failed;
+/*DEBUG CNTR END*/
+
+static spinlock_t xlr_tx_ok_sync = SPIN_LOCK_UNLOCKED;
+static volatile int xlr_queue_is_stop=0;
+
+// xlr_xmit_desc - Xmit Pkt towards host from xlr. Host has to give its memory address where xlr can xmit.
+static volatile struct xlr_xmit_desc *xlr_xmit_desc_base;
+
+static volatile struct xlr_rcv_desc *xlr_rcv_desc_base;
+
+static unsigned int xmit_producer;
+static unsigned int xmit_consumer;
+static unsigned int rx_consumer;
+#if !defined(CONFIG_RMI_PHOENIX) && defined(XLR_MSI_IS_SUPPORTED)
+static int msi_index;
+#endif
+static volatile uint32_t *xlr_magic_no;
+static volatile uint32_t *xlr_host_status;
+static volatile uint32_t *xlr_dev_status;
+static volatile uint32_t xlr_host_status_local;
+
+extern unsigned int phnx_pci_readl(unsigned int  *base);
+extern void phnx_pci_writel(unsigned int  data,unsigned int *addr);
+static struct driver_data{
+	struct net_device *dev;	
+	struct xlr_xmit_desc *curr_xmit;
+	struct xlr_xmit_desc *xmit_base;
+	struct xlr_rcv_desc *curr_rx;
+	struct xlr_rcv_desc *rx_base;
+}*ip_over_pci_priv;
+
+volatile static int rmmod_is_set=0;
+static struct timer_list xlr_link_status_timer;
+
+static void rmi_pci_read(u32 *src, int words, u32 *dest)
+{
+  int i;
+
+  for(i=0; i<words; i++){
+      *(dest + i) = phnx_pci_readl(src+i);
+  }
+  return;
+}
+
+static void rmi_pci_write(u32 *src, int words, u32 *dest)
+{
+  int i;
+  for(i=0; i<words; i++){
+	phnx_pci_writel(*(src+i), dest + i);
+  }
+  return;
+}
+
+static int process_rx_desc(void)
+{
+	volatile struct xlr_rcv_desc *curr_rcv_desc;
+	struct xlr_rcv_desc tmp_rx;
+	uint32_t phys_addr=0;
+	struct sk_buff *skb;
+	int data_len;
+	unsigned int status;
+  int count = 0x0;
+
+	curr_rcv_desc = xlr_rcv_desc_base + rx_consumer;
+	rmi_pci_read((uint32_t *)curr_rcv_desc,RX_DESC_SIZE,
+			(uint32_t *)&tmp_rx);
+	while(!XLR_GET_OWN(&tmp_rx)){
+                pci_unmap_single(rmi_pdev,xlr_rx_info[rx_consumer].phys_addr,
+                                xlr_rx_info[rx_consumer].len,DMA_FROM_DEVICE);
+
+		count++;
+		data_len = XLR_GET_LEN(&tmp_rx);
+		if(data_len > 1514){
+			ErrorMsg("Rcvd Wrong Len Pkt %d",data_len);
+		}
+		Message("\nRcvd A Pkt Frm XLR With LEN %d, Addr %#x Len %#x\n",
+					data_len,tmp_rx.addr,tmp_rx.info);
+                skb = xlr_rx_info[rx_consumer].skb;
+		if(!skb){
+			panic("xlr_ip_over_pci.c - Rcvd skb is null\n");
+		}	
+		if(replenish_buffer_at_index(rx_consumer)){
+			Message("Droppin Packet As replenishment is failed");
+			phys_addr = pci_map_single(rmi_pdev,skb->data,
+						XLR_MAX_RX_LEN,DMA_FROM_DEVICE);
+			xlr_rx_info[rx_consumer].phys_addr = phys_addr;
+        		xlr_rx_info[rx_consumer].skb = skb;
+		        xlr_rx_info[rx_consumer].len = XLR_MAX_RX_LEN;
+
+			XLR_SET_HOST_PHYS(&tmp_rx,phys_addr);
+			XLR_SET_OWN(&tmp_rx);
+			rmi_pci_write((uint32_t *)&tmp_rx,RX_DESC_SIZE,
+				(uint32_t *)curr_rcv_desc);	
+			rx_consumer = (rx_consumer + 1)% XLR_RX_DESC;
+			break;
+		}
+		skb_put(skb,data_len);
+		skb->dev = xlr_netdev;
+		skb->protocol = eth_type_trans(skb,skb->dev);
+
+		if((status = netif_rx(skb)) == NET_RX_DROP){
+			ErrorMsg("netif rx failed with status %d",status);	
+		}
+		xlr_rx_pkt++;
+		rx_consumer = (rx_consumer + 1)% XLR_RX_DESC;
+		curr_rcv_desc = xlr_rcv_desc_base + rx_consumer;
+		rmi_pci_read((uint32_t *)curr_rcv_desc,RX_DESC_SIZE,
+				(uint32_t *)&tmp_rx);
+	}
+	return count;
+}
+
+static void process_tx_ok_desc()
+{
+	volatile struct xlr_xmit_desc *curr_xmit = NULL; 
+	struct xlr_xmit_desc tmp_xmit;
+
+	if(xmit_consumer == xmit_producer)
+		return;
+	curr_xmit = xlr_xmit_desc_base + xmit_consumer;
+	rmi_pci_read((uint32_t *)curr_xmit+1,TX_DESC_SIZE-1,
+			(uint32_t *)&tmp_xmit.info);
+	
+	while((!XLR_GET_OWN(&tmp_xmit)) && (xmit_consumer != xmit_producer)){
+		Message("Rcvd Tx Ok");
+                pci_unmap_single(rmi_pdev,
+                        xlr_tx_free_info[xmit_consumer].phys_addr,
+                        xlr_tx_free_info[xmit_consumer].len,
+                        DMA_TO_DEVICE);
+#if defined(CONFIG_RMI_PHOENIX) || !defined(XLR_MSI_IS_SUPPORTED)
+                dev_kfree_skb(xlr_tx_free_info[xmit_consumer].tx_skb_ptr);
+#else
+                dev_kfree_skb_irq(xlr_tx_free_info[xmit_consumer].tx_skb_ptr);
+#endif
+		xmit_consumer = (xmit_consumer + 1) % XLR_TX_DESC;
+		curr_xmit = xlr_xmit_desc_base + xmit_consumer;
+		xlr_tx_pkt++;
+		rmi_pci_read((uint32_t *)curr_xmit+1,TX_DESC_SIZE-1,
+			(uint32_t *)&tmp_xmit.info);
+		spin_lock(&xlr_tx_ok_sync);
+		if(xlr_queue_is_stop){
+			netif_start_queue(xlr_netdev);
+			xlr_queue_is_stop = 0;
+		}
+		spin_unlock(&xlr_tx_ok_sync);
+	}
+}
+
+#if defined(CONFIG_RMI_PHOENIX) || !defined(XLR_MSI_IS_SUPPORTED)
+static void ip_over_pci_rx(struct work_struct *data);
+static DECLARE_DELAYED_WORK(ip_over_pci_task_host,ip_over_pci_rx);
+static void ip_over_pci_rx(struct work_struct *data)
+#else
+static irqreturn_t ip_over_pci_rx (void *data,struct pt_regs *regs)
+#endif
+{
+	uint32_t dev_status , count;
+	rmi_pci_read((uint32_t *)xlr_dev_status,1,&dev_status);
+
+	if(dev_status == XLR_INTERFACE_IS_UP){
+		process_tx_ok_desc();	
+		count = process_rx_desc();
+	}
+#if defined(CONFIG_RMI_PHOENIX) || !defined(XLR_MSI_IS_SUPPORTED)
+	if(!rmmod_is_set) {
+		schedule_delayed_work(&ip_over_pci_task_host, 1);
+	}
+	return;
+#else
+	return IRQ_HANDLED;
+#endif
+}
+
+static void put_dummy_mac_address(struct net_device *dev)
+{
+	dev->dev_addr[0] = 0x0;
+	dev->dev_addr[1] = 0xb;
+	dev->dev_addr[2] = 0x0;
+	dev->dev_addr[3] = 0xb;
+	dev->dev_addr[4] = 0x0;
+	dev->dev_addr[5] = 0xb;
+}
+
+static int xlr_ip_over_pci_open(struct net_device *dev)
+{
+	uint32_t tmp = XLR_INTERFACE_IS_UP;
+	xlr_host_status_local = XLR_INTERFACE_IS_UP;
+	rmi_pci_write((uint32_t *)&tmp,1,(uint32_t *)xlr_host_status);
+	return 0;
+}
+
+static int xlr_ip_over_pci_close(struct net_device *dev)
+{
+	uint32_t tmp = XLR_INTERFACE_IS_DOWN;
+	if(!netif_queue_stopped(dev))
+		netif_stop_queue(dev);
+	xlr_host_status_local = XLR_INTERFACE_IS_DOWN;
+	rmi_pci_write((uint32_t *)&tmp,1,(uint32_t *)xlr_host_status);
+	return 0;
+}
+
+static int xlr_ip_over_pci_xmit (struct sk_buff *skb,struct net_device *dev)
+{
+	volatile struct xlr_xmit_desc *curr_xmit_desc;
+	struct xlr_xmit_desc tmp_xmit;
+	uint64_t phys_addr=0;
+	uint32_t dev_status;
+	unsigned long mflags;
+
+	rmi_pci_read((uint32_t *)xlr_dev_status,1,&dev_status);
+
+	if(dev_status != XLR_INTERFACE_IS_UP){
+		netif_stop_queue(xlr_netdev);
+		return -EIO;
+	}
+	
+	if(skb->len > 1514){
+		ErrorMsg("Pkt Iz Greater Than Max Size %d",skb->len);
+		return -EIO;
+	}
+	if(((xmit_producer + 1)%(XLR_TX_DESC)) == xmit_consumer){
+		Message("No TX Desc Available.");
+		spin_lock_irqsave(&xlr_tx_ok_sync,mflags);
+	        if(((xmit_producer + 1)%(XLR_TX_DESC)) != xmit_consumer){
+			spin_unlock_irqrestore(&xlr_tx_ok_sync,mflags);
+			goto try_again;
+		}
+		xlr_queue_is_stop=1;
+		netif_stop_queue(xlr_netdev);
+		spin_unlock_irqrestore(&xlr_tx_ok_sync,mflags);
+		xlr_tx_enqueue_failed++;
+		return -ENOMEM;
+	}
+try_again:
+	curr_xmit_desc = xlr_xmit_desc_base + xmit_producer;
+	Message("\nCurrXmitDescBase %#x, xmit_prod %d, xlr_xmit_desc_base %#x\n",curr_xmit_desc,xmit_producer,xlr_xmit_desc_base);
+	rmi_pci_read((uint32_t *)curr_xmit_desc, TX_DESC_SIZE,
+				 (uint32_t *)&tmp_xmit);
+	if(XLR_GET_OWN(&tmp_xmit)){
+		Message("All Xmit Desc are full...");
+		return -ENOMEM;
+	}
+	tx_skb_ptr[xmit_producer] = skb;
+        phys_addr = xlr_tx_free_info[xmit_producer].phys_addr =
+                pci_map_single(rmi_pdev,skb->data,skb->len,DMA_TO_DEVICE);
+        xlr_tx_free_info[xmit_producer].tx_skb_ptr = skb;
+	memset(&tmp_xmit,0,sizeof(tmp_xmit));
+	XLR_SET_HOST_PHYS(&tmp_xmit,phys_addr);
+	XLR_SET_LEN(&tmp_xmit,skb->len);
+	XLR_SET_OWN(&tmp_xmit);
+	Message("\nXmittin Pkt With Len %d\n",XLR_GET_LEN(&tmp_xmit));
+	rmi_pci_write((uint32_t *)&tmp_xmit,TX_DESC_SIZE,
+			(uint32_t *)curr_xmit_desc);
+	xmit_producer = (xmit_producer + 1) % XLR_TX_DESC;
+	rmi_phnx_interrupt_device();
+	return 0;
+}
+
+static void setup_shared_mem()
+{
+	uint32_t tmp;
+	struct xlr_rcv_desc tmp_desc;
+	int i;
+	xlr_ip_over_pci_base = (uint32_t *)(phnx_get_shared_mem_base_host() +
+			PHNX_IP_OVER_PCI_MEM_BASE);
+	xlr_rcv_desc_base = (struct xlr_rcv_desc *)xlr_ip_over_pci_base;
+	xlr_xmit_desc_base = (struct xlr_xmit_desc *)
+				((unsigned char *)xlr_rcv_desc_base
+				 + XLR_RX_DESC*sizeof(struct xlr_rcv_desc));
+
+        xlr_magic_no = (unsigned int *)((xlr_xmit_desc_base + XLR_TX_DESC));
+	Message("\nMajic no. Addr %#x\n",virt_to_phys(xlr_magic_no));
+	xlr_host_status = xlr_magic_no + 1;
+	xlr_dev_status = xlr_host_status + 1;
+	Message("\nxlr_rcv_desc_base %#x",xlr_rcv_desc_base);
+	Message("\nxlr_xmit_desc_base %#x",xlr_xmit_desc_base);
+	Message("\nxlr_magic_no %#x",xlr_magic_no);
+	Message("\nxlr_host_status %#x",xlr_host_status);
+	Message("\nxlr_dev_status %#x",xlr_dev_status);
+	
+	tmp = 0;
+	rmi_pci_write((uint32_t *)&tmp,1,(uint32_t *)xlr_magic_no);
+	rmi_pci_write((uint32_t *)&tmp,1,(uint32_t *)xlr_host_status);
+	rmi_pci_write((uint32_t *)&tmp,1,(uint32_t *)xlr_dev_status);
+
+	memset(&tmp_desc,0,sizeof(struct xlr_rcv_desc));
+	for(i=0;i<XLR_RX_DESC;i++){
+		rmi_pci_write((uint32_t *)&tmp_desc,2,
+				(uint32_t *)xlr_rcv_desc_base+i);	
+		rmi_pci_write((uint32_t *)&tmp_desc,2,
+				(uint32_t *)xlr_xmit_desc_base+i);	
+	}
+
+	Message("\nXlrRxBase %#x to %#x\n",
+		(uint32_t)xlr_rcv_desc_base,(uint32_t)xlr_xmit_desc_base);
+	Message("\nXlrXmitBase %#x to %#x\n",
+			(uint32_t)xlr_xmit_desc_base,
+	(uint32_t)(xlr_xmit_desc_base+XLR_TX_DESC*sizeof(struct xlr_rcv_desc)));
+}
+
+
+static struct sk_buff * xlr_alloc_skb()
+{
+	struct sk_buff *skb;
+	unsigned long *tmp;
+	unsigned long offset;
+	unsigned char *tmp_addr;
+	skb = dev_alloc_skb(1536+32+32);
+	if(!skb){
+		Message("SKB Allocation Failed");
+		return NULL;
+	}
+	tmp_addr = skb->data;
+	offset = ((unsigned long)skb->data + PHNX_SMP_CACHE_BYTES) &  
+			~(PHNX_SMP_CACHE_BYTES - 1);
+	skb_reserve(skb, (offset - (unsigned long)skb->data));
+	tmp = (unsigned long*)(skb->data);
+	*tmp = (unsigned long)skb;
+	skb_reserve(skb,PHNX_SMP_CACHE_BYTES+2);
+	Message("\nSKB->DATA %#x, orig_addr %#x, diff %#x\n",
+			(unsigned int)virt_to_phys((void *)skb->data),
+			(uint32_t)virt_to_phys((void *)tmp_addr),
+			(uint32_t)virt_to_phys
+		((void *)((unsigned int)tmp_addr - (unsigned int)skb->data)));
+	return skb;
+}
+
+static int replenish_buffer_at_index(int index)
+{
+	struct sk_buff *skb;
+	struct xlr_rcv_desc *curr_desc =
+			 (struct xlr_rcv_desc *)xlr_rcv_desc_base+index;
+	struct xlr_rcv_desc tmp_desc;
+        unsigned int phys_addr;
+
+	memset(&tmp_desc,0,sizeof(struct xlr_rcv_desc));
+
+	skb = xlr_alloc_skb();
+
+	if(!skb){
+		ErrorMsg("\nCouldnt Replenish Buffer\n");
+		return -ENOMEM;
+	}
+        phys_addr = pci_map_single(rmi_pdev,skb->data,XLR_MAX_RX_LEN,
+                                DMA_FROM_DEVICE);
+        xlr_rx_info[index].phys_addr = phys_addr;
+        xlr_rx_info[index].skb = skb;
+        xlr_rx_info[index].len = XLR_MAX_RX_LEN;
+
+	XLR_SET_HOST_PHYS(&tmp_desc,phys_addr);
+	XLR_SET_OWN(&tmp_desc);
+	rmi_pci_write((uint32_t *)&tmp_desc,RX_DESC_SIZE,
+			(uint32_t *)curr_desc);	
+	return 0;
+}
+
+static int xlr_replenish_buffer()
+{
+	int i, j;
+
+	for(i=0;i<XLR_RX_DESC;i++){
+		if(replenish_buffer_at_index(i)){
+			ErrorMsg("replenish failed for buffer %d",i);
+			break;
+		}
+	}
+	if(i != XLR_RX_DESC){
+		for(j=0;j<i;j++)
+			free_rx_desc_index(j);
+		return -ENOMEM;
+	}
+	return 0;
+}
+
+static struct net_device_stats xlr_net_stats;
+static struct net_device_stats* xlr_get_stats(struct net_device *dev)
+{
+	memset(&xlr_net_stats,0,sizeof(struct net_device_stats));
+	xlr_net_stats.rx_packets = xlr_rx_pkt;
+	xlr_net_stats.tx_packets = xlr_tx_pkt;
+	return &xlr_net_stats;
+}
+
+static void xlr_link_status(unsigned long data)
+{
+	uint32_t host_status, dev_status;
+
+	/*Read Host n Dev Status*/
+	/*1 = open, 2 = close*/
+	host_status = xlr_host_status_local;
+	rmi_pci_read((uint32_t *)xlr_dev_status,1,&dev_status);
+
+	if(host_status == XLR_INTERFACE_IS_UP && 
+			dev_status == XLR_INTERFACE_IS_UP){
+		if(netif_queue_stopped(xlr_netdev) && !xlr_queue_is_stop){
+			netif_start_queue(xlr_netdev);
+		}
+	}else if(!netif_queue_stopped(xlr_netdev)){
+		Message("\nStoppin Queue.\n");
+		netif_stop_queue(xlr_netdev);
+	}
+	xlr_link_status_timer.expires = jiffies + 10;
+	add_timer(&xlr_link_status_timer);
+}
+
+static void setup_net_ops(struct net_device *dev)
+{
+	rmi_host_net_ops.ndo_open = xlr_ip_over_pci_open;
+	rmi_host_net_ops.ndo_stop = xlr_ip_over_pci_close;
+	rmi_host_net_ops.ndo_get_stats = xlr_get_stats;
+	rmi_host_net_ops.ndo_start_xmit = xlr_ip_over_pci_xmit;
+	dev->netdev_ops = &rmi_host_net_ops;
+}
+static int xlr_ip_over_pci_init(void)
+{
+	struct net_device *dev = 0;
+	struct driver_data *priv = 0;
+	int ret = 0;
+	uint32_t status;
+
+#ifdef CONFIG_RMI_PHOENIX
+  if(rmi_get_pci_mode() == XLR_PCI_DEV_MODE){
+    Message("Xlr Is configured in Dev Mode - unloading xlr_ip_over_pci_host");
+    return -ENODEV;
+  }
+#endif
+  if(phnx_get_shared_mem_base_host() == 0){
+    printk("\nLooks like device is not connected.\n");
+    return -ENODEV; 
+  }
+	xlr_netdev = dev = alloc_etherdev(sizeof(struct driver_data));
+	if (!dev) {
+		ret = -ENOMEM;
+		goto out;
+	}
+	setup_shared_mem();	
+	ip_over_pci_priv = priv = netdev_priv(dev);
+	priv->dev = dev;
+
+	setup_net_ops(dev);
+	put_dummy_mac_address(dev);
+
+	ether_setup(dev);
+
+	ret = register_netdev(dev);
+
+	if(xlr_replenish_buffer()){
+		unregister_netdev(xlr_netdev);
+		free_netdev(xlr_netdev);
+		return -ENOMEM;
+	}
+#if defined(CONFIG_RMI_PHOENIX) || !defined(XLR_MSI_IS_SUPPORTED)
+  schedule_delayed_work(&ip_over_pci_task_host, 0);
+#else
+	phnx_request_msi_handler(ip_over_pci_rx,(void *)NULL,&msi_index);
+#endif
+	status = XLR_MAGIC_NO;
+	rmi_pci_write((void *)&status,1,(void *)xlr_magic_no);	
+	init_timer(&xlr_link_status_timer);
+	xlr_link_status_timer.function = xlr_link_status;
+	xlr_link_status_timer.expires = jiffies + 10;		
+	add_timer(&xlr_link_status_timer);	
+
+	printk("xlr_ip_over_pci_host registered\n");
+out:
+	return ret;
+}
+
+static void free_tx_desc(void)
+{
+	while(xmit_consumer != xmit_producer){
+                pci_unmap_single(rmi_pdev,
+                        xlr_tx_free_info[xmit_consumer].phys_addr,
+                        xlr_tx_free_info[xmit_consumer].len,
+                        DMA_TO_DEVICE);
+		dev_kfree_skb(tx_skb_ptr[xmit_consumer]);
+		xmit_consumer = (xmit_consumer + 1 ) % XLR_TX_DESC;
+	}
+}
+
+static void free_rx_desc_index(int i)
+{
+	struct xlr_rcv_desc *curr_rcv_desc, tmp_rx;
+	uint64_t phys_addr;
+	struct sk_buff *skb;
+	curr_rcv_desc = (struct xlr_rcv_desc *)xlr_rcv_desc_base+i;
+	rmi_pci_read((uint32_t *)curr_rcv_desc,RX_DESC_SIZE,
+			(uint32_t *)&tmp_rx);
+	phys_addr = XLR_GET_HOST_PHYS(&tmp_rx);
+        pci_unmap_single(rmi_pdev,xlr_rx_info[i].phys_addr,
+                                xlr_rx_info[i].len,DMA_FROM_DEVICE);
+        skb = xlr_rx_info[i].skb;
+	dev_kfree_skb(skb);	
+}
+
+static void free_rx_desc(void)
+{
+	int i;
+	for(i=0;i<XLR_RX_DESC;i++){
+		free_rx_desc_index(i);
+	}
+}
+
+static void reset_tx_desc(void)
+{
+        int i=0;
+	uint32_t info;
+        for(i=0;i<XLR_TX_DESC;i++){
+		rmi_pci_read((void *)&info,1,
+			(void *)&((xlr_xmit_desc_base+i)->info));
+		info = info & (0x7fffffffU);
+		rmi_pci_write((void *)&info,1,
+			(void *)&((xlr_xmit_desc_base+i)->info));
+	}
+}
+static void reset_rx_desc(void)
+{
+        int i=0;
+	uint32_t info;
+        for(i=0;i<XLR_RX_DESC;i++){
+		rmi_pci_read((void *)&info,1,
+			(void *)&((xlr_rcv_desc_base+i)->info));
+		info = info & (0x7fffffffU);
+		rmi_pci_write((void *)&info,1,
+			(void *)&((xlr_rcv_desc_base+i)->info));
+	}
+}
+		
+
+static void xlr_ip_over_pci_exit(void)
+{
+	uint32_t status;
+	if(!xlr_netdev)
+		return;	
+	del_timer_sync(&xlr_link_status_timer);
+	status = 0x0;
+	rmi_pci_write((uint32_t *)&status,1,(uint32_t *)xlr_magic_no);	
+	rmi_phnx_interrupt_device();
+
+#if defined(CONFIG_RMI_PHOENIX) || !defined(XLR_MSI_IS_SUPPORTED)
+	rmmod_is_set=1;
+#else
+	phnx_free_msi_handler(&msi_index);
+#endif
+
+	
+	reset_rx_desc();
+	reset_tx_desc();
+	mdelay(3000);
+	unregister_netdev(xlr_netdev);
+	free_tx_desc();
+	free_rx_desc();
+	free_netdev(xlr_netdev);
+}
+
+module_init(xlr_ip_over_pci_init);
+module_exit(xlr_ip_over_pci_exit);
+MODULE_LICENSE("GPL");
+
diff --git a/drivers/net/xlr_pcix_boot.c b/drivers/net/xlr_pcix_boot.c
new file mode 100644
index 0000000..6df6b71
--- /dev/null
+++ b/drivers/net/xlr_pcix_boot.c
@@ -0,0 +1,335 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef CONFIG_RMI_PHOENIX
+#ifndef MODULE
+#define MODULE
+#endif
+#endif
+#ifndef __KERNEL__
+#define __KERNEL__
+#endif
+
+
+#include <linux/sched.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/compiler.h>
+#include <linux/init.h>
+
+#include <linux/ioport.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/rtnetlink.h>
+#include <linux/delay.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <asm/io.h>
+#include <linux/completion.h>
+#include <linux/crc32.h>
+
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/rmi_pcix_gen_host.h>
+#include <asm/rmi/xlr_pcix_boot.h>
+#else
+#include "rmi_pcix_gen_host.h"
+#include "xlr_pcix_boot.h"
+#endif
+
+#define Message(a,b...) //printk("\nFun [%s]\t"a"\n",__FUNCTION__,##b);
+#define ErrorMsg(a,b...) printk("\nFun [%s]\t"a"\n",__FUNCTION__,##b);
+
+#define RMI_IOCTL_DRIVER "RMI_PCIX_BOOT_DRIVER"
+#define PHNX_IMAGE_BUFF_LEN 1024
+static struct net_device_ops rmi_boot_net_ops;
+
+extern unsigned long phnx_get_shared_mem_base_host(void);
+static struct net_device *ndev;
+
+extern void phnx_pci_writeb(unsigned char data, void *addr);
+extern void phnx_pci_writel(unsigned int  data,unsigned int *addr);
+struct priv
+{
+				struct net_device *dev;
+				struct net_device_stats stats;
+				int port;
+				u32 phnx_tx_producer;
+				u32 phnx_pending_tx;
+				u32 phnx_rx_consumer;
+};
+
+static int kimage_phnx_open(struct net_device *);
+static int kimage_phnx_close(struct net_device *);
+
+static int rmi_ioctl_phnx_probe(void);
+static void rmi_phnx_remove(void);
+
+
+static int rmi_phnx_pcix_init(void);
+static void rmi_phnx_pcix_uninit(void);
+
+static unsigned volatile int *rmi_phnx_shared_mem_base;
+
+
+static int kimage_phnx_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+				Message("in kimage_phnx_xmit !! BLANK BLANK !! \n");
+				dev_kfree_skb(skb);
+				return 0;
+}
+
+
+
+static int kimage_phnx_close(struct net_device *dev)
+{
+				Message("in close !!! BLANK BLANK !!! \n");
+				return 0;
+
+}
+
+static int kimage_phnx_open(struct net_device *dev)
+{
+				Message("in open !!! BLANK BLANK !!! \n");
+				return 0;
+}
+
+
+static int kimage_phnx_ioctl(struct net_device *dev,struct ifreq *ifr, int cmd)
+{
+				u8 *ptr;
+				unsigned long result;
+				static unsigned char *kimage_loc ;
+				static int phnx_image_len;
+				int buff_len;
+				int argc;
+				int argv_len;
+				u8 *arg_buf, *dst;
+				int i;
+
+				switch (cmd){
+
+								case SIOCDEVPRIVATE+0x03:
+												kimage_loc = (unsigned char *)rmi_phnx_shared_mem_base +
+																PCIX_BOOT_FILE_START; //kernel image location;
+												phnx_image_len = 0;
+												return 0; 
+
+								case SIOCDEVPRIVATE+0x04:
+												// send argc + len + args
+
+												result = __copy_from_user((void *)&argc,
+																				(void *)ifr->ifr_data,4);
+												if(result > 0){
+																ErrorMsg("invalid address frm user space");			
+																return -1;
+												}	
+
+												result = __copy_from_user((void *)&argv_len,
+																				(void *)(ifr->ifr_data+4),4);
+												if(result > 0){
+																ErrorMsg("invalid address frm user space");
+																return -1;
+												}							
+
+												phnx_pci_writel(argc,
+														(uint32_t *)((u8 *)rmi_phnx_shared_mem_base + 
+														 			PCIX_BOOT_ARG_CNT_OFF));
+
+												phnx_pci_writel(argv_len,
+														(uint32_t *)((u8 *)rmi_phnx_shared_mem_base + 
+														 			PCIX_BOOT_ARGS_LEN_OFF));
+
+												arg_buf = kmalloc(argv_len, GFP_KERNEL);
+												if(arg_buf == NULL)
+													return -ENOMEM;
+
+												__copy_from_user((void *)arg_buf, 
+															(void *)(ifr->ifr_data+8), argv_len);
+
+												dst = ((u8 *)rmi_phnx_shared_mem_base + 
+																								PCIX_BOOT_ARGS_OFF);
+
+												for(i=0; i < argv_len; i++) {
+													phnx_pci_writeb(arg_buf[i], dst);
+													dst++;
+												}
+
+												return 0;
+
+								case SIOCDEVPRIVATE+0x02:
+
+												ptr = (u8 *)kmalloc(PHNX_IMAGE_BUFF_LEN, GFP_KERNEL);
+												if (ptr == NULL){
+																ErrorMsg(KERN_ERR "Unable to allocate memory !!!\n");
+																return -ENOMEM;
+												}
+
+												result = __copy_from_user(ptr, ifr->ifr_data, 
+																				PHNX_IMAGE_BUFF_LEN);
+												if (result > 0)
+																return -EIO;
+												buff_len = *((int *)ptr);
+												Message("Got %d bytes Chunk \n", buff_len);
+
+												for(i=0; i < buff_len; i++)
+													phnx_pci_writeb(ptr[i+4], kimage_loc+i);
+
+												kimage_loc += buff_len; 
+												phnx_image_len += buff_len;
+
+												kfree(ptr);
+												if (buff_len < (PHNX_IMAGE_BUFF_LEN-4) ||
+																							 buff_len == 0){
+																Message("File Download \
+																				completed Total len %d\n", 
+																				phnx_image_len);
+																phnx_pci_writel(phnx_image_len, 
+																		((uint32_t *)rmi_phnx_shared_mem_base + 1));
+																phnx_pci_writel(0xa5a5a5a5,
+																		(uint32_t *) rmi_phnx_shared_mem_base);
+
+												}
+												return 0;
+
+								default:
+												return -EINVAL;
+
+				}
+				return -EINVAL;
+}
+
+
+
+static void rmi_phnx_remove(void)
+{
+				rmi_phnx_pcix_uninit();
+				return;
+}
+
+static void setup_net_ops(struct net_device *dev)
+{
+	rmi_boot_net_ops.ndo_open = kimage_phnx_open;
+	rmi_boot_net_ops.ndo_stop = kimage_phnx_close;
+	rmi_boot_net_ops.ndo_start_xmit = kimage_phnx_xmit;
+	rmi_boot_net_ops.ndo_do_ioctl = kimage_phnx_ioctl;
+	dev->netdev_ops = &rmi_boot_net_ops;
+}
+
+static int rmi_ioctl_phnx_probe(void)
+{
+				struct priv *priv = NULL;
+				int i;
+				int ret=0;
+				Message("\n%s Called\n",__FUNCTION__);
+
+				if(rmi_phnx_pcix_init()){
+								ErrorMsg("pcix_init failed");
+								return -EIO;
+				}
+
+				ndev = alloc_etherdev(sizeof(struct priv));
+				if(!ndev){
+								ret = -ENOMEM;
+								goto out;
+				}
+
+				priv = netdev_priv(ndev);
+				priv->dev = ndev;
+
+				setup_net_ops(ndev);
+
+				strcpy(ndev->name, "phnx_boot0");
+
+				for(i=0; i<6; i++)
+								ndev->dev_addr[i] = i;
+				printk("\"phnx_boot0\" Boot Over PCI - interface registered\n");
+				register_netdev(ndev);
+				return ret;
+out:
+				ErrorMsg("Returnin Error %d",ret);
+				return ret;  
+}
+
+/*  ioctl driver starts */
+#define RMI_VENDOR_ID 0x0182e
+#define RMI_DEVICE_ID 0x0
+
+
+int __init rmi_virt_driver_init_module(void)
+{
+#ifdef CONFIG_RMI_PHOENIX
+  if(rmi_get_pci_mode() == XLR_PCI_DEV_MODE){
+    Message("Xlr Is configured in Dev Mode - unloading xlr_pcix_boot");
+    return -ENODEV;
+  }
+#endif
+  if(phnx_get_shared_mem_base_host() == 0){
+    printk("\nLooks like device is not connected.\n");
+    return -ENODEV; 
+  }
+  Message("\n%s called\n",__FUNCTION__);
+	return rmi_ioctl_phnx_probe();
+}
+
+void __exit rmi_virt_driver_cleanup_module(void)
+{
+
+				rmi_phnx_remove();
+				return;
+}
+
+
+static int rmi_phnx_pcix_init(void)
+{
+				int err;
+
+				rmi_phnx_shared_mem_base = (uint32_t *)phnx_get_shared_mem_base_host();
+				Message("\n%s Called\n",__FUNCTION__);
+				if(rmi_phnx_shared_mem_base == NULL)
+				{
+								ErrorMsg("Shared MEM ioremap failed");
+								err = -ENODEV;
+								return err;
+				}
+				return 0;
+}
+
+/* This should be called only after successful return from rmi_phnx_pcix_init */
+static void rmi_phnx_pcix_uninit(void)
+{
+				unregister_netdev(ndev);
+				free_netdev(ndev);
+
+}
+
+
+module_init(rmi_virt_driver_init_module);
+module_exit(rmi_virt_driver_cleanup_module);
+MODULE_LICENSE("GPL");
diff --git a/drivers/oprofile/oprof.c b/drivers/oprofile/oprof.c
index ed2c3ec..432da15 100644
--- a/drivers/oprofile/oprof.c
+++ b/drivers/oprofile/oprof.c
@@ -243,6 +243,13 @@ static int timer_mode;
 
 static int __init oprofile_init(void)
 {
+	/* Architecture must fill in the interrupt ops and the
+	 * logical CPU type, or we can fall back to the timer
+	 * interrupt profiler.
+	 */
+
+	// oprofile_ops{} contains virtual pointes to all functions that are invoked
+	// whenever the counters have to be stopped, started or restored
 	int err;
 
 	/* always init architecture to setup backtrace support */
diff --git a/drivers/oprofile/oprofile_files.c b/drivers/oprofile/oprofile_files.c
index 84a208d..c5413c6 100644
--- a/drivers/oprofile/oprofile_files.c
+++ b/drivers/oprofile/oprofile_files.c
@@ -190,7 +190,9 @@ void oprofile_create_files(struct super_block *sb, struct dentry *root)
 	oprofilefs_create_ulong(sb, root, "buffer_watershed", &oprofile_buffer_watershed);
 	oprofilefs_create_ulong(sb, root, "cpu_buffer_size", &oprofile_cpu_buffer_size);
 	oprofilefs_create_file(sb, root, "cpu_type", &cpu_type_fops);
-	oprofilefs_create_file(sb, root, "backtrace_depth", &depth_fops);
+	if (oprofile_ops.backtrace)
+		oprofilefs_create_file(sb, root, "backtrace_depth", 
+							&depth_fops);
 	oprofilefs_create_file(sb, root, "pointer_size", &pointer_size_fops);
 #ifdef CONFIG_OPROFILE_EVENT_MULTIPLEX
 	oprofilefs_create_file(sb, root, "time_slice", &timeout_fops);
diff --git a/drivers/pci/Makefile b/drivers/pci/Makefile
index 165274c..af24a15 100644
--- a/drivers/pci/Makefile
+++ b/drivers/pci/Makefile
@@ -25,6 +25,7 @@ endif
 
 # Build the PCI MSI interrupt support
 obj-$(CONFIG_PCI_MSI) += msi.o
+obj-$(CONFIG_PCI_MSI_XLR) += msi.o
 
 # Build the Hypertransport interrupt support
 obj-$(CONFIG_HT_IRQ) += htirq.o
diff --git a/drivers/pci/pci.h b/drivers/pci/pci.h
index e494347..d254eb0 100644
--- a/drivers/pci/pci.h
+++ b/drivers/pci/pci.h
@@ -141,7 +141,7 @@ extern raw_spinlock_t pci_lock;
 
 extern unsigned int pci_pm_d3_delay;
 
-#ifdef CONFIG_PCI_MSI
+#if defined(CONFIG_PCI_MSI) || defined(CONFIG_PCI_MSI_XLR)
 void pci_no_msi(void);
 extern void pci_msi_init_pci_dev(struct pci_dev *dev);
 #else
diff --git a/drivers/pci/probe.c b/drivers/pci/probe.c
index 63e0199..2510a54 100644
--- a/drivers/pci/probe.c
+++ b/drivers/pci/probe.c
@@ -17,6 +17,24 @@
 
 static LIST_HEAD(pci_host_bridges);
 
+#ifdef CONFIG_RMI_XLR
+/* Hack! This file includes references to XLR
+ * specific routines/defines. To be removed...
+ * -------------------------------------------
+ * The Global ht_start_busno variable (set in
+ * pci-phoenix.c) is used here, as a reference 
+ * to programming the Seconday/Subordinate bus 
+ * nrs. during bridge scans...
+ */
+extern int ht_start_busno;
+/*
+ * for the is_xls routine.
+ */
+#include <asm/rmi/sim.h>    
+extern void pcie_controller_init_done(void);
+extern int link0, link1, link2, link3;
+#endif
+
 /* Ugh.  Need to stop exporting this to modules. */
 LIST_HEAD(pci_root_buses);
 EXPORT_SYMBOL(pci_root_buses);
@@ -1320,7 +1338,14 @@ void pci_device_add(struct pci_dev *dev, struct pci_bus *bus)
 
 	dev->dev.dma_mask = &dev->dma_mask;
 	dev->dev.dma_parms = &dev->dma_parms;
+#ifdef CONFIG_RMI_XLR
+    if(xlr_revision_c())
+	    dev->dev.coherent_dma_mask = DMA_BIT_MASK(31);
+    else
+	    dev->dev.coherent_dma_mask = DMA_BIT_MASK(32);
+#else
 	dev->dev.coherent_dma_mask = 0xffffffffull;
+#endif
 
 	pci_set_dma_max_seg_size(dev, 65536);
 	pci_set_dma_seg_boundary(dev, 0xffffffff);
@@ -1628,6 +1653,13 @@ unsigned int __devinit pci_scan_child_bus(struct pci_bus *bus)
 			bus->is_added = 1;
 	}
 
+
+#ifdef CONFIG_RMI_XLR
+    /*link2 and link3 are always set to zero incase of xls-4xx/6xx*/
+    if ((is_xls()) && (!link0) && (!link1) && (!link2) && (!link3))
+        return max;
+#endif
+
 	for (pass=0; pass < 2; pass++)
 		list_for_each_entry(dev, &bus->devices, bus_list) {
 			if (dev->hdr_type == PCI_HEADER_TYPE_BRIDGE ||
diff --git a/drivers/pci/proc.c b/drivers/pci/proc.c
index 27911b5..9018925 100644
--- a/drivers/pci/proc.c
+++ b/drivers/pci/proc.c
@@ -401,12 +401,20 @@ int pci_proc_attach_device(struct pci_dev *dev)
 		return -EACCES;
 
 	if (!bus->procdir) {
+#ifdef CONFIG_RMI_PHOENIX
+		/* 
+		   create /proc entries in "%02x" format at all times.
+		   Otherwise, for HT, it will be created in "%04x:%02x" format
+		   */
+		sprintf(name, "%02x", bus->number);
+#else
 		if (pci_proc_domain(bus)) {
 			sprintf(name, "%04x:%02x", pci_domain_nr(bus),
 					bus->number);
 		} else {
 			sprintf(name, "%02x", bus->number);
 		}
+#endif
 		bus->procdir = proc_mkdir(name, proc_bus_pci_dir);
 		if (!bus->procdir)
 			return -ENOMEM;
diff --git a/drivers/pci/quirks.c b/drivers/pci/quirks.c
index 680dbfa..e473f92 100644
--- a/drivers/pci/quirks.c
+++ b/drivers/pci/quirks.c
@@ -2162,7 +2162,7 @@ static void __devinit quirk_tile_plx_gen1(struct pci_dev *dev)
 DECLARE_PCI_FIXUP_EARLY(PCI_VENDOR_ID_PLX, 0x8624, quirk_tile_plx_gen1);
 #endif /* CONFIG_TILE */
 
-#ifdef CONFIG_PCI_MSI
+#if defined(CONFIG_PCI_MSI) || defined(CONFIG_PCI_MSI_XLR)
 /* Some chipsets do not support MSI. We cannot easily rely on setting
  * PCI_BUS_FLAGS_NO_MSI in its bus flags because there are actually
  * some other busses controlled by the chipset even if Linux is not
diff --git a/drivers/perfctr/Kconfig b/drivers/perfctr/Kconfig
new file mode 100644
index 0000000..0247e0a
--- /dev/null
+++ b/drivers/perfctr/Kconfig
@@ -0,0 +1,64 @@
+# $Id: Kconfig,v 1.1.2.1 2005-02-20 21:48:11 pboddupalli Exp $
+# Performance-monitoring counters driver configuration
+#
+
+menu "Performance-monitoring counters support"
+
+config PERFCTR
+	bool "Performance monitoring counters support"
+	help
+	  This driver provides access to the performance-monitoring counter
+	  registers available in some (but not all) modern processors.
+	  These special-purpose registers can be programmed to count low-level
+	  performance-related events which occur during program execution,
+	  such as cache misses, pipeline stalls, etc.
+
+	  You can safely say Y here, even if you intend to run the kernel
+	  on a processor without performance-monitoring counters.
+
+	  At <http://www.csd.uu.se/~mikpe/linux/perfctr/> you can find
+	  the corresponding user-space components, as well as other
+	  versions of this package. A mailing list is also available, at
+	  <http://lists.sourceforge.net/lists/listinfo/perfctr-devel>.
+
+config PERFCTR_INIT_TESTS
+	bool "Init-time hardware tests"
+	depends on PERFCTR
+	default y
+	help
+	  This option makes the driver perform additional hardware tests
+	  during initialisation, and log their results in the kernel's
+	  message buffer. For most supported processors, these tests simply
+	  measure the runtime overheads of performance counter operations.
+
+	  If you have a less well-known processor (one not listed in the
+	  etc/costs/ directory in the user-space package), you should enable
+	  this option and email the results to the perfctr developers.
+
+	  If unsure, say N.
+
+config PERFCTR_VIRTUAL
+	bool "Virtual performance counters support"
+	depends on PERFCTR
+	default y
+	help
+	  The processor's performance-monitoring counters are special-purpose
+	  global registers. This option adds support for virtual per-process
+	  performance-monitoring counters which only run when the process
+	  to which they belong is executing. This improves the accuracy of
+	  performance measurements by reducing "noise" from other processes.
+
+	  Say Y.
+
+config PERFCTR_INTERRUPT_SUPPORT
+	prompt "Performance counter overflow interrupt support" if PPC
+	bool
+	depends on PERFCTR
+	default y
+
+config PERFCTR_CPUS_FORBIDDEN_MASK
+	bool
+	depends on PERFCTR
+	default n
+
+endmenu
diff --git a/drivers/perfctr/Makefile b/drivers/perfctr/Makefile
new file mode 100644
index 0000000..2eb07b8
--- /dev/null
+++ b/drivers/perfctr/Makefile
@@ -0,0 +1,25 @@
+# $Id: Makefile,v 1.1.2.2 2006-06-06 20:28:30 pboddupalli Exp $
+# Makefile for the Performance-monitoring counters driver.
+
+ifeq ("$(CONFIG_PERFCTR)","y")
+
+# This also covers x86_64.
+perfctr-objs-$(CONFIG_X86) := x86.o
+tests-objs-$(CONFIG_X86) := x86_tests.o
+
+perfctr-objs-$(CONFIG_PPC32) := ppc.o
+tests-objs-$(CONFIG_PPC32) := ppc_tests.o
+
+perfctr-objs-$(CONFIG_MIPS) := mips.o
+tests-objs-$(CONFIG_MIPS) := mips_tests.o
+
+perfctr-objs-y += init.o
+perfctr-objs-$(CONFIG_PERFCTR_INIT_TESTS) += $(tests-objs-y)
+perfctr-objs-$(CONFIG_PERFCTR_VIRTUAL) += virtual.o
+
+perfctr-objs		:= $(perfctr-objs-y)
+obj-$(CONFIG_PERFCTR)	:= perfctr.o
+
+else
+obj-y := dummy-syscalls.o
+endif
diff --git a/drivers/perfctr/compat.h b/drivers/perfctr/compat.h
new file mode 100644
index 0000000..8b40888
--- /dev/null
+++ b/drivers/perfctr/compat.h
@@ -0,0 +1,51 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/* 
+ * Performance-monitoring counters driver.
+ * Compatibility definitions for 2.6 kernels.
+ *
+ * Copyright (C) 1999-2005  Mikael Pettersson
+ */
+#include <linux/version.h>
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,5,0)
+#include "compat24.h"
+#else
+
+#include "cpumask.h"
+
+#define EXPORT_SYMBOL_mmu_cr4_features	EXPORT_SYMBOL(mmu_cr4_features)
+#define EXPORT_SYMBOL___put_task_struct	EXPORT_SYMBOL(__put_task_struct)
+
+#define task_siglock(tsk)	((tsk)->sighand->siglock)
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,4)	/* names changed in 2.6.4-rc2 */
+#define sysdev_register(dev)	sys_device_register((dev))
+#define sysdev_unregister(dev)	sys_device_unregister((dev))
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,10) /* remap_page_range() obsoleted in 2.6.10-rc1 */
+#include <linux/mm.h>
+static inline int
+remap_pfn_range(struct vm_area_struct *vma, unsigned long uvaddr,
+		unsigned long pfn, unsigned long size, pgprot_t prot)
+{
+	return remap_page_range(vma, uvaddr, pfn << PAGE_SHIFT, size, prot);
+}
+#endif
+
+#if !defined(DEFINE_SPINLOCK) /* added in 2.6.11-rc1 */
+#define DEFINE_SPINLOCK(x)	spinlock_t x = SPIN_LOCK_UNLOCKED
+#endif
+
+#endif
diff --git a/drivers/perfctr/cpumask.h b/drivers/perfctr/cpumask.h
new file mode 100644
index 0000000..2249db3
--- /dev/null
+++ b/drivers/perfctr/cpumask.h
@@ -0,0 +1,90 @@
+/* $Id: cpumask.h,v 1.1.2.2 2005-03-02 04:57:49 pboddupalli Exp $
+ * Performance-monitoring counters driver.
+ * Partial simulation of cpumask_t on non-cpumask_t kernels.
+ * Extension to allow inspecting a cpumask_t as array of ulong.
+ * Appropriate definition of perfctr_cpus_forbidden_mask.
+ *
+ * Copyright (C) 2003-2004  Mikael Pettersson
+ */
+
+/* 2.6.0-test4 changed set-of-CPUs values from ulong to cpumask_t */
+
+#include <linux/version.h>
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0))
+
+#if (!defined(PERFCTR_HAVE_CPUMASK_T) && !defined(HAVE_CPUMASK_T))
+typedef unsigned long cpumask_t;
+#endif
+
+/* RH/FC1 kernel 2.4.22-1.2115.nptl added cpumask_t, but with
+   an incomplete API and a broken cpus_and() [misspelled parameter
+   in its body]. Sigh.
+   Assume cpumask_t is unsigned long and use our own code. */
+#undef cpu_set
+#define cpu_set(cpu, map)	atomic_set_mask((1UL << (cpu)), &(map))
+#undef cpu_isset
+#define cpu_isset(cpu, map)	((map) & (1UL << (cpu)))
+#undef cpus_and
+#define cpus_and(dst,src1,src2)	do { (dst) = (src1) & (src2); } while(0)
+#undef cpus_clear
+#define cpus_clear(map)		do { (map) = 0UL; } while(0)
+#undef cpus_complement
+#define cpus_complement(map)	do { (map) = ~(map); } while(0)
+#undef cpus_empty
+#define cpus_empty(map)		((map) == 0UL)
+#undef cpus_equal
+#define cpus_equal(map1, map2)	((map1) == (map2))
+#undef cpus_addr
+#define cpus_addr(map)		(&(map))
+
+#undef CPU_MASK_NONE
+#define CPU_MASK_NONE		0UL
+
+#elif (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,1))
+
+/* 2.6.1-rc1 introduced cpus_addr() */
+#ifdef CPU_ARRAY_SIZE
+#define cpus_addr(map)		((map).mask)
+#else
+#define cpus_addr(map)		(&(map))
+#endif
+
+#endif
+
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(2,6,8) && !defined(cpus_andnot))
+#define cpus_andnot(dst, src1, src2) \
+do { \
+    cpumask_t _tmp2; \
+    _tmp2 = (src2); \
+    cpus_complement(_tmp2); \
+    cpus_and((dst), (src1), _tmp2); \
+} while(0)
+#endif
+
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,8)) && !defined(CONFIG_SMP))
+#undef cpu_online_map
+#define cpu_online_map	cpumask_of_cpu(0)
+#endif
+
+#ifdef CPU_ARRAY_SIZE
+#define PERFCTR_CPUMASK_NRLONGS	CPU_ARRAY_SIZE
+#else
+#define PERFCTR_CPUMASK_NRLONGS	1
+#endif
+
+/* CPUs in `perfctr_cpus_forbidden_mask' must not use the
+   performance-monitoring counters. TSC use is unrestricted.
+   This is needed to prevent resource conflicts on hyper-threaded P4s. */
+
+#ifdef CONFIG_PERFCTR_CPUS_FORBIDDEN_MASK
+
+extern cpumask_t perfctr_cpus_forbidden_mask;
+#define perfctr_cpu_is_forbidden(cpu)	cpu_isset((cpu), perfctr_cpus_forbidden_mask)
+
+#else
+
+#define perfctr_cpus_forbidden_mask	CPU_MASK_NONE
+#define perfctr_cpu_is_forbidden(cpu)	0 /* cpu_isset() needs an lvalue :-( */
+
+#endif
diff --git a/drivers/perfctr/dummy-syscalls.c b/drivers/perfctr/dummy-syscalls.c
new file mode 100644
index 0000000..8e7181f
--- /dev/null
+++ b/drivers/perfctr/dummy-syscalls.c
@@ -0,0 +1,73 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/* $Id: dummy-syscalls.c,v 1.1.2.3 2007-10-31 17:34:40 kmurthy Exp $
+ * Virtual per-process performance counters.
+ *
+ * Copyright (C) 1999-2004  Mikael Pettersson
+ */
+#include <linux/init.h>
+#include <linux/compiler.h> /* for unlikely() in 2.4.18 and older */
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/ptrace.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/perfctr.h>
+
+#include <asm/io.h>
+#include <asm/uaccess.h>
+
+#include "cpumask.h"
+#include "virtual.h"
+#include "compat.h"
+
+/****************************************************************
+ *								*
+ * Virtual perfctr actual system calls.				*
+ *								*
+ ****************************************************************/
+
+/* tid is the actual task/thread id (ne pid, stored as ->pid),
+   pid/tgid is that 2.6 thread group id crap (stored as ->tgid) */
+
+asmlinkage long sys_vperfctr_open(int tid, int creat)
+{
+   printk ("PERFCTR not configured, unimplemented syscall\n");
+   return -EINVAL;
+}
+
+asmlinkage long sys_vperfctr_control(int fd,
+				     const struct vperfctr_control __user *argp,
+				     unsigned int argbytes)
+{
+   printk ("PERFCTR not configured, unimplemented syscall\n");
+   return -EINVAL;
+}
+
+asmlinkage long sys_vperfctr_unlink(int fd)
+{
+   printk ("PERFCTR not configured, unimplemented syscall\n");
+   return -EINVAL;
+}
+
+asmlinkage long sys_vperfctr_iresume(int fd)
+{
+   printk ("PERFCTR not configured, unimplemented syscall\n");
+   return -EINVAL;
+}
+
+asmlinkage long sys_vperfctr_read(int fd, unsigned int cmd, void __user *argp, unsigned int argbytes)
+{
+   printk ("PERFCTR not configured, unimplemented syscall\n");
+   return -EINVAL;
+}
diff --git a/drivers/perfctr/init.c b/drivers/perfctr/init.c
new file mode 100644
index 0000000..f5d4841
--- /dev/null
+++ b/drivers/perfctr/init.c
@@ -0,0 +1,198 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/* $Id: init.c,v 1.1.2.7 2007-11-15 13:42:00 kmurthy Exp $
+ * Performance-monitoring counters driver.
+ * Top-level initialisation code.
+ *
+ * Copyright (C) 1999-2004  Mikael Pettersson
+ */
+#include <linux/fs.h>
+#include <linux/init.h>
+#include <linux/sched.h>
+#include <linux/device.h>
+#include <linux/sysctl.h>
+#include <linux/perfctr.h>
+
+#include <asm/uaccess.h>
+
+#include "cpumask.h"
+#include "virtual.h"
+#include "version.h"
+
+struct perfctr_info perfctr_info = {
+	.abi_version = PERFCTR_ABI_VERSION,
+	.driver_version = VERSION,
+};
+
+static ssize_t
+driver_version_show(struct class *class, char *buf)
+{
+	return sprintf(buf, "%s\n", perfctr_info.driver_version);
+}
+
+static ssize_t
+cpu_type_show(struct class *class, char *buf)
+{
+	return sprintf(buf, "%#x\n", perfctr_info.cpu_type);
+}
+
+static ssize_t
+cpu_features_show(struct class *class, char *buf)
+{
+	return sprintf(buf, "%#x\n", perfctr_info.cpu_features);
+}
+
+static ssize_t
+cpu_khz_show(struct class *class, char *buf)
+{
+	return sprintf(buf, "%u\n", perfctr_info.cpu_khz);
+}
+
+static ssize_t
+tsc_to_cpu_mult_show(struct class *class, char *buf)
+{
+	return sprintf(buf, "%u\n", perfctr_info.tsc_to_cpu_mult);
+}
+
+static ssize_t
+cpus_online_show(struct class *class, char *buf)
+{
+	int ret = cpumask_scnprintf(buf, PERFCTR_PAGE_SIZE-1, &cpu_online_map);
+	buf[ret++] = '\n';
+	return ret;
+}
+
+static ssize_t
+cpus_forbidden_show(struct class *class, char *buf)
+{
+#ifdef CONFIG_PERFCTR_CPUS_FORBIDDEN_MASK
+	int ret = cpumask_scnprintf(buf, PERFCTR_PAGE_SIZE-1, perfctr_cpus_forbidden_mask);
+	buf[ret++] = '\n';
+	return ret;
+#endif
+	return 0;
+}
+
+static CLASS_ATTR(driver_version, 0444, driver_version_show, NULL);
+static CLASS_ATTR(cpu_type, 0444, cpu_type_show, NULL);
+static CLASS_ATTR(cpu_features, 0444, cpu_features_show, NULL);
+static CLASS_ATTR(cpu_khz, 0444, cpu_khz_show, NULL);
+static CLASS_ATTR(tsc_to_cpu_mult, 0444, tsc_to_cpu_mult_show, NULL);
+static CLASS_ATTR(cpus_online, 0444, cpus_online_show, NULL);
+static CLASS_ATTR(cpus_forbidden, 0444, cpus_forbidden_show, NULL);
+
+/* static struct class_attribute perfctr_class_attrs[] = {
+	__ATTR_RO(driver_version),
+	__ATTR_RO(cpu_type),
+	__ATTR_RO(cpu_features),
+	__ATTR_RO(cpu_khz),
+	__ATTR_RO(tsc_to_cpu_mult),
+	__ATTR_RO(cpus_online),
+	__ATTR_RO(cpus_forbidden),
+	__ATTR_NULL
+}; */
+
+static struct class perfctr_class = {
+	.name		= "perfctr",
+	// .class_attrs	= perfctr_class_attrs,
+};
+
+char *perfctr_cpu_name __initdata;
+
+static int __init perfctr_class_init(void)
+{
+	int err;
+
+	err = class_register(&perfctr_class);
+	if (err)
+		return err;
+
+	err |= class_create_file(&perfctr_class, &class_attr_driver_version);
+	err |= class_create_file(&perfctr_class, &class_attr_cpu_type);
+	err |= class_create_file(&perfctr_class, &class_attr_cpu_features);
+	err |= class_create_file(&perfctr_class, &class_attr_cpu_khz);
+	err |= class_create_file(&perfctr_class, &class_attr_tsc_to_cpu_mult);
+	err |= class_create_file(&perfctr_class, &class_attr_cpus_online);
+	err |= class_create_file(&perfctr_class, &class_attr_cpus_forbidden);
+
+	if (err)
+		class_unregister(&perfctr_class);
+	return err;
+}
+
+extern int	perfctr_cntmode;
+
+ctl_table  perfctr_cntmode_table[] = {
+    {
+        .ctl_name   	= PERFCTR_CNTMODE,
+		.procname   	= "cntmode",
+        .data       	= &perfctr_cntmode,
+        .maxlen     	= sizeof(int),
+        .mode       	= 0644,
+        .proc_handler   = &proc_dointvec,
+    },
+	{0}
+};
+
+ctl_table perfctr_sysctl_table[] = {
+	{
+		.ctl_name	= CTL_PERFCTR,
+		.procname	= "perfctr",
+		.mode		= 0555,
+		.child		= perfctr_cntmode_table,
+	},
+	{0}
+};
+
+static struct ctl_table_header *perfctr_sysctl_table_handle;
+
+static int __init perfctr_init(void)
+{
+	int err;
+
+	err = perfctr_cpu_init();
+	if (err) {
+		printk(KERN_INFO "perfctr: not supported by this processor\n");
+		return err;
+	}
+	err = vperfctr_init();
+	if (err)
+		return err;
+	err = perfctr_class_init();
+	if (err) {
+		printk(KERN_ERR "perfctr: class initialisation failed\n");
+		return err;
+	}
+	printk(KERN_INFO "perfctr: driver %s, cpu type %s at %u kHz\n",
+	       perfctr_info.driver_version,
+	       perfctr_cpu_name,
+	       perfctr_info.cpu_khz);
+
+	// code to create entries in the proc filesystem for perfctr count mode
+	if ( (perfctr_sysctl_table_handle = register_sysctl_table (perfctr_sysctl_table)) == NULL) {
+		printk (KERN_ERR "register_sysctl_table() for perfctr failed\n");
+		printk (KERN_INFO "perfctr count mode defaults to individual threads");
+	};
+
+	return 0;
+}
+
+static void __exit perfctr_exit(void)
+{
+	vperfctr_exit();
+	perfctr_cpu_exit();
+	unregister_sysctl_table(perfctr_sysctl_table_handle);
+}
+
+module_init(perfctr_init)
+module_exit(perfctr_exit)
diff --git a/drivers/perfctr/mips.c b/drivers/perfctr/mips.c
new file mode 100644
index 0000000..e6cdbfe
--- /dev/null
+++ b/drivers/perfctr/mips.c
@@ -0,0 +1,838 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/* $Id: mips.c,v 1.1.2.9 2007-10-31 17:34:41 kmurthy Exp $
+ * MIPS64 performance-monitoring counters driver.
+ *
+ * Copyright (C) 2004
+ */
+#include <linux/init.h>
+#include <linux/sched.h>
+#include <linux/fs.h>
+#include <linux/perfctr.h>
+#include <asm/time.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/perfctr.h>
+
+#include <asm/mipsregs.h>
+
+#include "mips_tests.h"
+
+// Support for lazy evntsel and perfctr control regiters updates.
+// good, I don't see any point in maintaing the values of the
+// counters.
+
+struct per_cpu_cache {    /* roughly a subset of perfctr_cpu_state */
+    union {
+        unsigned int id;    /* cache owner id */
+    } k1;
+
+    /* Physically indexed cache of control registers */
+    unsigned int ctrl_regs[2];
+};
+static DEFINE_PER_CPU(struct per_cpu_cache, per_cpu_cache);
+#define __get_cpu_cache(cpu) (&per_cpu(per_cpu_cache, cpu))
+#define get_cpu_cache()    (&__get_cpu_var(per_cpu_cache))
+
+/* Structure for counter snapshots, as 32-bit values. */
+struct perfctr_low_ctrs {
+    unsigned int tsc;
+    unsigned int pmc[2];
+};
+
+static int pm_type;
+
+static struct {
+	spinlock_t lock ____cacheline_aligned;
+	int current_thread;
+} pmc_resource[8];
+
+// Bits users shouldn't set in control registers
+// #define MIPS_XLR_PERFCTRL_RESERVED        0
+
+// returns a new id each time
+static unsigned int new_id(void)
+{
+    static spinlock_t lock = SPIN_LOCK_UNLOCKED;
+    static unsigned int counter;
+    int id;
+
+    spin_lock(&lock);
+    id = ++counter;
+    spin_unlock(&lock);
+    return id;
+}
+
+#ifdef CONFIG_PERFCTR_INTERRUPT_SUPPORT
+
+static void perfctr_default_ihandler(unsigned long pc)
+{
+    // do nothing
+    return;
+}
+
+perfctr_ihandler_t perfctr_ihandler = perfctr_default_ihandler;
+
+void perfctr_cpu_set_ihandler(perfctr_ihandler_t ihandler)
+{
+    perfctr_ihandler = ihandler ? ihandler : perfctr_default_ihandler;
+}
+#else
+#define perfctr_cstatus_has_ictrs(cstatus)    0
+#endif
+
+#if defined(CONFIG_SMP) && defined(CONFIG_PERFCTR_INTERRUPT_SUPPORT)
+
+// to set the cpu on which the current thread is suspended
+// aids in telling if the control and PMC registers are warm
+
+static inline void
+set_isuspend_cpu(struct perfctr_cpu_state *state, int cpu)
+{
+    state->k1.isuspend_cpu = cpu;
+}
+
+static inline int
+is_isuspend_cpu(const struct perfctr_cpu_state *state, int cpu)
+{
+    return state->k1.isuspend_cpu == cpu;
+}
+
+static inline void clear_isuspend_cpu(struct perfctr_cpu_state *state)
+{
+    state->k1.isuspend_cpu = NR_CPUS;
+}
+
+#else
+static inline void set_isuspend_cpu(struct perfctr_cpu_state *state, int cpu) { }
+static inline int is_isuspend_cpu(const struct perfctr_cpu_state *state, int cpu) { return 1; }
+static inline void clear_isuspend_cpu(struct perfctr_cpu_state *state) { }
+#endif
+
+/****************************************************************
+ *                                                                *
+ * Driver procedures.                                            *
+ *                                                                *
+ ****************************************************************/
+
+/*
+ * The MIPS familiy, currently only support for RMI XLR
+ *
+ * Common features
+ * ---------------
+ * - Per counter event selection data in subfields of control registers.
+ * - Overflow interrupt support is present in all processors,
+ * - The counter register available on a per-thread basis is used to
+ *   to sample the TSC value  
+ */
+
+inline unsigned int read_pmc(unsigned int pmc)
+{
+    switch (pmc) {
+        default: 
+        case 0:
+            return __read_32bit_c0_register($25, 1);
+        case 1:
+            return __read_32bit_c0_register($25, 3);
+    }
+}
+
+inline void write_pmc (unsigned int pmc, unsigned int value)
+{
+    switch (pmc) {
+        default: 
+        case 0:
+            __write_32bit_c0_register($25, 1, value);
+            break;
+        case 1:
+            __write_32bit_c0_register($25, 3, value);
+            break;
+    }
+}
+
+inline void write_pmctrl(unsigned int pmc, unsigned int value)
+{
+    switch (pmc) {
+        default: 
+        case 0:
+            __write_32bit_c0_register($25, 0, value);
+            break;
+        case 1:
+            __write_32bit_c0_register($25, 2, value);
+            break;
+    }
+}
+
+// when asked to read, we will have to read only if the thread
+// id in the control register corresponds to our's. What
+// do we do if the performance registers are configured to
+// record numbers for all the 4 threads. It would be better
+// if the user dictates whethere or not to pick the values.
+// provide a mechansim for the user to tell the same to the driver
+
+static void mips_read_counters(struct perfctr_cpu_state *state,
+                  struct perfctr_low_ctrs *ctrs)
+{
+    unsigned int cstatus, nrctrs, i;
+
+    cstatus = state->cstatus;
+    if (perfctr_cstatus_has_tsc(cstatus)) {
+        ctrs->tsc = read_c0_count();
+	}
+    nrctrs = perfctr_cstatus_nractrs(cstatus);
+    for(i = 0; i < nrctrs; ++i) {
+        unsigned int pmc = state->pmc[i].map;
+        ctrs->pmc[i] = read_pmc(pmc);
+    }
+}
+
+// The highest index of the event that one can specify
+
+/* static unsigned int pmc_max_event(unsigned int pmc)
+{
+    switch (pmc) {
+    default:
+    case 0:
+        return 63;
+    case 1:
+        return 63;
+    }
+} */
+
+static unsigned int get_nr_pmcs(void)
+{
+    switch (pm_type) {
+        case MIPS_XLR:
+            return 2;
+        default: /* MIPS_GENERIC, but silences gcc warning */
+            return 0;
+    }
+}
+
+static int mips_check_control(struct perfctr_cpu_state *state)
+{
+    unsigned int i, nractrs, nrctrs, pmc_mask, pmi_mask, pmc;
+    unsigned int nr_pmcs;
+
+    // ensuring that the total no of performance registers that
+    // are monitored are not more than available number
+    nr_pmcs = get_nr_pmcs();
+    nractrs = state->control.nractrs;
+    nrctrs = nractrs + state->control.nrictrs;    // we could have got this from cstatus. Isn't that so?
+    if ( (nrctrs < nractrs) || (nrctrs > nr_pmcs) )
+        return -EINVAL;
+
+    // ctrl_reg are the control registers, while .map contains
+    // the actual register number to use while reading and writing
+    pmc_mask = 0;
+    pmi_mask = 0;
+    // memset(ctrl_regs, 0, sizeof(ctrl_regs));
+
+    for(i = 0; i < nrctrs; ++i) {
+        pmc = state->control.pmc[i].map;    // for ppc, 0 <= pmc, the map value <= 5
+
+        // ok, here is where the user-specified values are being copied to the
+        // variables in the 'state' variable
+
+        state->pmc[i].map = pmc;
+
+        if (pmc >= nr_pmcs || (pmc_mask & (1<<pmc))) {
+            return -EINVAL;
+        }
+
+        pmc_mask |= (1<<pmc);
+        if (i >= nractrs) {
+            pmi_mask |= (1<<pmc);
+        }
+
+        // IMPORTANT: check that we haven't set the interrupt-enable bit for a-mode registers
+
+        // do some more sanity check that the user specifed valid control data
+        // if ( (ctrl_reg[pmc] & MIPS_XLR_EVNTSEL_RESERVED) != 0 )
+        //    return -EINVAL;
+
+        // what more sanity checks do we need ?
+    }
+
+    state->k1.id = new_id();
+
+    return 0;
+}
+
+#ifdef CONFIG_PERFCTR_INTERRUPT_SUPPORT
+/* PRE: perfctr_cstatus_has_ictrs(state->cstatus) != 0 */
+/* PRE: counters frozen */
+
+// Suspend the collection of statistics in the performance registers
+// Both mips_isuspend() and mips_iresume() are for i-mode regs only
+
+static void mips_isuspend(struct perfctr_cpu_state *state)
+{
+    struct per_cpu_cache *cache;
+    unsigned int cstatus, nrctrs, i;
+    int cpu;
+
+    // it is on the cpu no 'cpu' that we suspended gathering statistics
+    cpu = smp_processor_id();
+
+    // what are we going to with the stored 'cpu' no? telling somone
+    // look this state was last suspended on cpu 'cpu'
+    set_isuspend_cpu(state, cpu); /* early to limit cpu's live range */
+
+    // what are we caching?
+    cache = __get_cpu_cache(cpu);
+    cstatus = state->cstatus;
+    nrctrs = perfctr_cstatus_nrctrs(cstatus);
+    for(i = perfctr_cstatus_nractrs(cstatus); i < nrctrs; ++i) {
+        unsigned int pmc, now;
+
+        pmc = state->pmc[i].map;
+
+        // instead of setting the freeze bits, just zero out the whole reg
+        cache->ctrl_regs[pmc] = 0;
+        write_pmctrl(pmc, cache->ctrl_regs[pmc]);
+
+        now = read_pmc(pmc);
+        state->pmc[i].sum += now - state->pmc[i].start;
+        state->pmc[i].start = now;
+    }
+    /* cache->k1.id is still == state->k1.id */
+
+    // sampled the i-mode registers
+}
+
+static void mips_iresume(const struct perfctr_cpu_state *state)
+{
+    struct per_cpu_cache *cache;
+    unsigned int cstatus, nrctrs, i;
+    int cpu;
+
+    cpu = smp_processor_id();
+    cache = __get_cpu_cache(cpu);
+
+    if (cache->k1.id == state->k1.id) {
+        // we need to do this and force reload of control registers
+        // to unfreeze control registers
+        cache->k1.id = 0; 
+
+        // if no one else was scheduled after we were suspended,
+        // the regiseters are still warm, actually hot and don't
+        // have to reload them. Is that right ?
+
+        // we are being rescheduled on the same processor
+        if (is_isuspend_cpu(state, cpu))
+            return; /* skip reload of PMCs */
+    }
+
+    // The CPU state wasn't ours.
+    // The counters must be frozen before being reinitialised,
+    // to prevent unexpected increments and missed overflows.
+
+    // At this point, only the i-mode registers are frozen. Is there
+    // any reason to freeze a-mode counters ?!
+
+    // All unused counters must be reset to a non-overflow state.
+    // accumulation mode registers are reset to zero, while the i-mode
+    // registers are being written from state->pmc[i].start. The field
+    // state->pmc[].start for i-mode registers was set to the values
+    // specified in the .ireset field in the function ...
+
+    cstatus = state->cstatus;
+    nrctrs = perfctr_cstatus_nrctrs(cstatus);
+    for(i = perfctr_cstatus_nractrs(cstatus); i < nrctrs; ++i) {
+        unsigned int map = state->pmc[i].map;
+
+        cache->ctrl_regs[map] = 0;
+        write_pmctrl(map, 0); // zero value
+        write_pmc(map, state->pmc[i].start);
+    }
+    // cache->k1.id remains != state->k1.id
+}
+#endif
+
+// this is invoked by the _resume() routine. If the id in the cache
+// equals to our id, it implies no one else touched the control
+// registers of this id and hence need not be written all over again
+// however this is not a good idea when control registers have to
+// be written to for some reason, such as when the control registers
+// have to unfrozen and so on. This is done by settind the id in the
+// cache to 0. The cache id is updated with the id of the verpfctr
+// id when a new state is schduled to collect statistics on this cpu
+
+int perfctr_cntmode = 0;
+
+static void mips_write_control(const struct perfctr_cpu_state *state)
+{
+    struct per_cpu_cache *cache;
+    unsigned int nrctrs, i;
+
+    // cache stores the information pertaining to one id. Under
+    // what conditions does that cache state remain intact? Can some
+    // processes tell that their statistics be not recorded. In such
+    // a case when a thread is rescheuldes on the same processpor
+    // without the intervening thread recording the statistics, then
+    // the cache will be hot
+
+    cache = get_cpu_cache();
+    if (cache->k1.id == state->k1.id) {
+        return;
+    }
+    nrctrs = perfctr_cstatus_nrctrs(state->cstatus);
+
+	preempt_disable();
+    for (i = 0; i < nrctrs; ++i) {
+        unsigned int ctrl_reg = state->control.pmc[i].ctrl_reg;
+        unsigned int pmc = state->pmc[i].map;    // assuming that the 'state' values have been
+                                                 // updated from control values specified by users
+        if (ctrl_reg != cache->ctrl_regs[pmc]) {
+			if (!perfctr_cntmode) {
+				MIPS_XLR_UNSET_CNT_ALL_THREADS(ctrl_reg);
+				MIPS_XLR_SET_THREADID(ctrl_reg, phoenix_thr_id());
+			}
+			else {
+				MIPS_XLR_SET_CNT_ALL_THREADS(ctrl_reg);
+			}
+            cache->ctrl_regs[pmc] = ctrl_reg;
+            write_pmctrl(pmc, ctrl_reg);
+        }
+    }
+    cache->k1.id = state->k1.id;
+	preempt_enable();
+}
+
+static void mips_clear_counters(void)
+{
+    switch (pm_type) {
+        case MIPS_XLR:
+            __write_32bit_c0_register($25, 0, 0);
+            __write_32bit_c0_register($25, 1, 0);
+            __write_32bit_c0_register($25, 2, 0);
+            __write_32bit_c0_register($25, 3, 0);
+        case MIPS_GENERIC:
+            ;
+    }
+}
+
+// Driver methods, internal and exported.
+
+static inline void perfctr_cpu_write_control(const struct perfctr_cpu_state *state)
+{
+    return mips_write_control(state);
+}
+
+static inline void perfctr_cpu_read_counters(struct perfctr_cpu_state *state,
+                      struct perfctr_low_ctrs *ctrs)
+{
+    return mips_read_counters(state, ctrs);
+}
+
+#ifdef CONFIG_PERFCTR_INTERRUPT_SUPPORT
+static inline void perfctr_cpu_isuspend(struct perfctr_cpu_state *state)
+{
+    return mips_isuspend(state);
+}
+
+static inline void perfctr_cpu_iresume(const struct perfctr_cpu_state *state)
+{
+    return mips_iresume(state);
+}
+
+/* Call perfctr_cpu_ireload() just before perfctr_cpu_resume() to
+   bypass internal caching and force a reload if the I-mode PMCs. */
+void perfctr_cpu_ireload(struct perfctr_cpu_state *state)
+{
+#ifdef CONFIG_SMP
+    clear_isuspend_cpu(state);
+#else
+    get_cpu_cache()->k1.id = 0;
+#endif
+}
+
+/* PRE: the counters have been suspended and sampled by perfctr_cpu_suspend() */
+// the following overflow check is being done only for the i-mode registers
+// how is the overflow of a-mode registers handled ?
+inline unsigned int perfctr_cpu_identify_overflow(struct perfctr_cpu_state *state)
+{
+    unsigned int cstatus, nrctrs, i, pmc_mask;
+
+    cstatus = state->cstatus;
+    i = perfctr_cstatus_nractrs(cstatus);    // a-mode count
+    nrctrs = perfctr_cstatus_nrctrs(cstatus);
+
+    for(pmc_mask = 0; i < nrctrs; ++i) {
+
+        // Ok, reset the overflown i-mode counters
+
+        if ((int)state->pmc[i].start < 0) { /* MIPS-specific */
+            /* XXX: "+=" to correct for overshots */
+            state->pmc[i].start = state->control.pmc[i].ireset;
+            pmc_mask |= (1 << i);
+        }
+    }
+    return pmc_mask;
+}
+
+static inline int check_ireset(const struct perfctr_cpu_state *state)
+{
+    unsigned int nrctrs, i;
+
+    i = state->control.nractrs;
+    nrctrs = i + state->control.nrictrs;
+    for(; i < nrctrs; ++i) {
+        if (state->control.pmc[i].ireset < 0)    /* MIPS-specific */ {
+            return -EINVAL;
+        }
+    }
+    return 0;
+}
+
+// the start values have to be reset as we might have changed then in
+// _isuspend()
+static inline void setup_imode_start_values(struct perfctr_cpu_state *state)
+{
+    unsigned int cstatus, nrctrs, i;
+
+    cstatus = state->cstatus;
+    nrctrs = perfctr_cstatus_nrctrs(cstatus);
+    for(i = perfctr_cstatus_nractrs(cstatus); i < nrctrs; ++i)
+        state->pmc[i].start = state->control.pmc[i].ireset;
+}
+
+#else    /* CONFIG_PERFCTR_INTERRUPT_SUPPORT */
+static inline void perfctr_cpu_isuspend(struct perfctr_cpu_state *state) { }
+static inline void perfctr_cpu_iresume(const struct perfctr_cpu_state *state) { }
+static inline int check_ireset(const struct perfctr_cpu_state *state) { return 0; }
+static inline void setup_imode_start_values(struct perfctr_cpu_state *state) { }
+#endif    /* CONFIG_PERFCTR_INTERRUPT_SUPPORT */
+
+static int check_control(struct perfctr_cpu_state *state)
+{
+    return mips_check_control(state);
+}
+
+int perfctr_cpu_update_control(struct perfctr_cpu_state *state, int is_global)
+{
+    int err;
+
+    // since we updated the control, we invalidate the cpu id in the state
+    // so that we can force reload of control registers
+    clear_isuspend_cpu(state);
+    state->cstatus = 0;
+
+    /* disallow i-mode counters if we cannot catch the interrupts */
+    if (!(perfctr_info.cpu_features & PERFCTR_FEATURE_PCINT)
+        && state->control.nrictrs) {
+        
+        return -EPERM;
+    }
+
+    err = check_ireset(state);
+    if (err < 0) {
+        return err;
+    }
+    err = check_control(state); /* may initialise state->cstatus */
+    if (err < 0) {
+        return err;
+    }
+
+    // Ok, while the map values and the start values for i-mode counters
+    // are updated in the above function check_control() and the following
+    // function setup_imode_start_values(), the 'cstatus' values is set here
+
+    // how do u ensure that all i-mode registers are specified beyond a-mode
+    // registers
+    state->cstatus |= perfctr_mk_cstatus(state->control.tsc_on,
+                         state->control.nractrs,
+                         state->control.nrictrs);
+    setup_imode_start_values(state);
+    return 0;
+}
+
+inline void perfctr_cpu_suspend(struct perfctr_cpu_state *state)
+{
+    unsigned int i, cstatus, nractrs;
+    struct perfctr_low_ctrs now;
+	int   cpu_id;
+
+	cpu_id = hard_smp_processor_id() / 4;
+	spin_lock (&pmc_resource[cpu_id].lock);
+	if ( pmc_resource[cpu_id].current_thread != phoenix_thr_id() ) {
+		// printk (KERN_INFO "PMCounters do not belong to this process[%d]\n", current->pid);
+		spin_unlock (&pmc_resource[cpu_id].lock);
+		return;
+	}
+	pmc_resource[cpu_id].current_thread = -1;
+	spin_unlock (&pmc_resource[cpu_id].lock);
+
+    // To prevent polluting the numbers, can we freeze the counters
+    // here, as early as possible ?
+
+    if (perfctr_cstatus_has_ictrs(state->cstatus)) {
+        perfctr_cpu_isuspend(state);
+	}
+    perfctr_cpu_read_counters(state, &now);
+    cstatus = state->cstatus;
+    if (perfctr_cstatus_has_tsc(cstatus)) {
+        state->tsc_sum += now.tsc - state->tsc_start;
+    }
+    nractrs = perfctr_cstatus_nractrs(cstatus);
+    for(i = 0; i < nractrs; ++i) {
+        state->pmc[i].sum += now.pmc[i] - state->pmc[i].start;
+    }
+}
+
+inline void perfctr_cpu_resume(struct perfctr_cpu_state *state)
+{
+	int   cpu_id;
+
+	cpu_id = hard_smp_processor_id() / 4;
+	spin_lock (&pmc_resource[cpu_id].lock);
+	if ( pmc_resource[cpu_id].current_thread != -1 ) {
+		// printk (KERN_INFO "PMCounters unavailable for process %d\n", current->pid);
+		spin_unlock (&pmc_resource[cpu_id].lock);
+		return;
+	}
+	pmc_resource[cpu_id].current_thread = phoenix_thr_id();
+	spin_unlock (&pmc_resource[cpu_id].lock);
+
+    if (perfctr_cstatus_has_ictrs(state->cstatus)) {
+        perfctr_cpu_iresume(state);
+	}
+
+    // the counters are triggered, having been frozen in _iresume()
+    // that preceded this point. So, the model is to trigger the
+    // registere to collect the numbers and record the start state
+    // that completes the 'resume' process.
+
+    perfctr_cpu_write_control(state);
+    {
+        struct perfctr_low_ctrs now;
+        unsigned int i, cstatus, nrctrs;
+        perfctr_cpu_read_counters(state, &now);
+        cstatus = state->cstatus;
+
+        // the start state of the registers has to be recorded only
+        // in resume() and that is what is being done.
+
+        if (perfctr_cstatus_has_tsc(cstatus)) {
+            state->tsc_start = now.tsc;
+		}
+        nrctrs = perfctr_cstatus_nractrs(cstatus);
+        for (i = 0; i < nrctrs; ++i) {
+            state->pmc[i].start = now.pmc[i];
+		}
+    }
+    /* XXX: if (SMP && start.tsc == now.tsc) ++now.tsc; */
+}
+
+// Sampling only a-mode registers
+void perfctr_cpu_sample(struct perfctr_cpu_state *state)
+{
+    unsigned int i, cstatus, nractrs;
+    struct perfctr_low_ctrs now;
+	int   cpu_id;
+
+	cpu_id = hard_smp_processor_id() / 4;
+	spin_lock (&pmc_resource[cpu_id].lock);
+	if ( pmc_resource[cpu_id].current_thread != phoenix_thr_id() ) {
+		// printk (KERN_INFO "PMCounters do not belong to this process[%d]\n", current->pid);
+		spin_unlock (&pmc_resource[cpu_id].lock);
+		return;
+	}
+	spin_unlock (&pmc_resource[cpu_id].lock);
+
+    perfctr_cpu_read_counters(state, &now);        // reads only a-mode registers
+    cstatus = state->cstatus;
+    if (perfctr_cstatus_has_tsc(cstatus)) {
+        state->tsc_sum += now.tsc - state->tsc_start;
+        // one needs to update the start status as we continue to gather
+        // statistics without interruption
+        state->tsc_start = now.tsc;
+    }
+    nractrs = perfctr_cstatus_nractrs(cstatus);
+    for(i = 0; i < nractrs; ++i) {
+		
+        state->pmc[i].sum += now.pmc[i] - state->pmc[i].start;
+        state->pmc[i].start = now.pmc[i];
+    }
+}
+
+static void perfctr_cpu_clear_counters(void)
+{
+    struct per_cpu_cache *cache;
+
+    cache = get_cpu_cache();
+    memset(cache, 0, sizeof *cache);
+    cache->k1.id = -1;
+
+    mips_clear_counters();
+}
+
+/****************************************************************
+ *                                                            *
+ * Processor detection and initialisation procedures.        *
+ *                                                            *
+ ****************************************************************/
+
+cpumask_t perfctr_cpus_forbidden_mask;
+
+static inline void clear_perfctr_cpus_forbidden_mask(void)
+{
+#if !defined(perfctr_cpus_forbidden_mask)
+    cpus_clear(perfctr_cpus_forbidden_mask);
+#endif
+}
+
+static inline void set_perfctr_cpus_forbidden_mask(cpumask_t mask)
+{
+#if !defined(perfctr_cpus_forbidden_mask)
+    perfctr_cpus_forbidden_mask = mask;
+#endif
+}
+
+static void __init mips_setup_cpu_mask(void *forbidden)
+{
+    unsigned int logical_processor_id = hard_smp_processor_id();
+    if ((logical_processor_id % 4) != 0) {
+        // We rely on cpu_set() being atomic!
+        cpu_set(logical_processor_id, *(cpumask_t*)forbidden);
+    }
+}
+
+static int __init mips_smp_init(void)
+{
+    cpumask_t forbidden;
+    unsigned int cpu;
+
+    cpus_clear(forbidden);
+#ifdef CONFIG_SMP
+    smp_call_function(mips_setup_cpu_mask, &forbidden, 1);
+#endif
+    mips_setup_cpu_mask(&forbidden);
+    if (cpus_empty(forbidden))
+        return 0;
+    perfctr_cpus_forbidden_mask = forbidden;
+    for(cpu = 0; cpu < NR_CPUS; ++cpu)
+        if (cpu_isset(cpu, forbidden))
+            printk(" %u", cpu);
+        printk("\n");
+    return 0;
+}
+
+static void perfctr_cpu_clear_one(void *ignore)
+{
+    // cache too is also getting invalidated in the following routine
+    perfctr_cpu_clear_counters();
+}
+
+static int init_done;
+
+int __init perfctr_cpu_init(void)
+{
+    int i, err = 0;
+
+    preempt_disable();
+    
+    mips_smp_init();
+
+    // The  first two fields of the structure 'perfctr_info' are defined/assigned
+    // in the declaration itself
+    perfctr_info.cpu_type = pm_type = MIPS_XLR;
+    perfctr_info.cpu_features |= PERFCTR_FEATURE_PCINT;
+    perfctr_info.cpu_khz = mips_hpt_frequency;
+    perfctr_info.tsc_to_cpu_mult = 1;
+
+    /* for 2.7 versions only. This variable is not visible to users. */
+    perfctr_cpu_name = "MIPS_XLR";
+
+    perfctr_mips_init_tests();
+
+	// Init Spinlocks and the current thead of PMC registers
+	for (i = 0; i < 8; ++i) {
+		spin_lock_init(&pmc_resource[i].lock);
+		pmc_resource[i].current_thread = -1;
+	}
+
+	init_done = 1;
+    preempt_enable();
+    return err;
+}
+
+void __exit perfctr_cpu_exit(void)
+{
+}
+
+/****************************************************************
+ *                                                                *
+ * Hardware reservation.                                        *
+ *                                                                *
+ ****************************************************************/
+
+static DECLARE_MUTEX(mutex);
+static const char *current_service = 0;
+
+const char *perfctr_cpu_reserve(const char *service)
+{
+    const char *ret;
+	int i;
+
+    if (!init_done)
+        return "unsupported hardware";
+    down(&mutex);
+    ret = current_service;
+    if (ret)
+        goto out_up;
+    current_service = service;
+    on_each_cpu(perfctr_cpu_clear_one, NULL, 1);
+
+	// Ideally at this point of time, all the current thread values of
+	// pmc_resource must be -1
+	for (i = 0; i < 8; ++i) {
+		if (pmc_resource[i].current_thread != -1) {
+			printk (KERN_INFO "pmc_resource[%d].current_thread != -1\n", i);
+		}
+		pmc_resource[i].current_thread = -1;
+	}
+
+    perfctr_cpu_set_ihandler(NULL);
+    ret = NULL;
+out_up:
+    up(&mutex);
+    return ret;
+}
+
+void perfctr_cpu_release(const char *service)
+{
+	int i;
+
+    down(&mutex);
+    if (service != current_service) {
+        printk(KERN_ERR "%s: attempt by %s to release while reserved by %s\n", __FUNCTION__, service, current_service);
+        goto out_up;
+    } else {
+        /* power down the counters */
+        on_each_cpu(perfctr_cpu_clear_one, NULL, 1);
+        perfctr_cpu_set_ihandler(NULL);
+        current_service = 0;
+
+		// Ideally at this point of time, all the current thread values of
+		// pmc_resource must be -1
+		for (i = 0; i < 8; ++i) {
+			if (pmc_resource[i].current_thread != -1) {
+				printk (KERN_INFO "pmc_resource[%d].current_thread != -1\n", i);
+			}
+			pmc_resource[i].current_thread = -1;
+		}
+    }
+out_up:
+    up(&mutex);
+}
diff --git a/drivers/perfctr/mips.h b/drivers/perfctr/mips.h
new file mode 100644
index 0000000..618fb42
--- /dev/null
+++ b/drivers/perfctr/mips.h
@@ -0,0 +1,48 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+#ifndef __PerfMonCtrs_MIPS_H
+#define __PerfMonCtrs_MIPS_H
+
+#define PMC_KERNEL_MODE		0x2
+#define PMC_SUP_MODE		0x4
+#define PMC_USERL_MODE		0x8
+
+#define PMC_SET_EVNTCNT_MODE(x, mode)		x |= mode
+#define PMC_UNSET_EVNTCNT_MODE(x, mode)		x &= ~mode
+
+#define PMC_ENABLE_ITRPT(x)				x |= 0x10
+#define PMC_DISABLE_ITRPT(x)			x &= ~0x10
+
+#define PMC_EVNTSEL_MASK			0x3f
+#define PMC_EVNTSEL_SHIFT			5
+#define PMC_SET_EVNT(x, event)		x |= ((event & PMC_EVNTSEL_MASK) << PMC_EVNTSEL_SHIFT)
+
+#define PMC_THREADID_MASK			0x03
+#define PMC_THREADID_SHIFT			11
+#define PMC_SET_THREADID(x, tid)	x |= ((tid & PMC_EVNTSEL_MASK) << PMC_EVNTSEL_SHIFT)
+
+#define PMC_SET_CNT_ALL_THREADS(x)		x |= 0x2000
+#define PMC_UNSET_CNT_ALL_THREADS(x)	x &= ~0x2000
+
+#define PMC_INSTRS_FETCHED			0
+#define PMC_INSTR_CACHE_MISSES		1
+
+#define PMC_INSTR_CACHE_PARITY_ERRS		6
+#define PMC_INSTR_MICRO_TLB_MISSES		8
+
+#define PMC_INSTRS_RETIRED			17
+#define PMC_BRANCH_INSTRS			18
+
+#define PMC_CYCLE_CNT				63
+
+#endif
diff --git a/drivers/perfctr/mips_tests.c b/drivers/perfctr/mips_tests.c
new file mode 100644
index 0000000..2ddd261
--- /dev/null
+++ b/drivers/perfctr/mips_tests.c
@@ -0,0 +1,221 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/* $Id: mips_tests.c,v 1.1.2.6 2007-10-31 17:34:41 kmurthy Exp $
+ * Performance-monitoring counters driver.
+ * Optional PPC32-specific init-time tests.
+ *
+ * Copyright (C) 2004  Mikael Pettersson
+ */
+#include <linux/init.h>
+#include <linux/sched.h>
+#include <linux/fs.h>
+#include <linux/perfctr.h>
+#include <asm/processor.h>
+#include <asm/time.h>
+#include <asm/mipsregs.h>
+#include <asm/perfctr.h>
+#include "mips_tests.h"
+
+#define NITER	256
+#define X2(S)	S"; "S
+#define X8(S)	X2(X2(X2(S)))
+
+static void __init do_read_tsc(unsigned int unused)
+{
+	unsigned int i, dummy;
+	__asm__ __volatile__ (".set mips32\n\t");
+	for(i = 0; i < NITER/8; ++i)
+		__asm__ __volatile__(X8("mfc0 %0, $9, 0") : "=r" (dummy));
+	__asm__ __volatile__ (".set mips0\n\t");
+}
+
+static void __init do_read_pmc1(unsigned int unused)
+{
+	unsigned int i, dummy;
+	__asm__ __volatile__ (".set mips32\n\t");
+	for(i = 0; i < NITER/8; ++i)
+		__asm__ __volatile__(X8("mfc0 %0, $25, 1") : "=r" (dummy));
+	__asm__ __volatile__ (".set mips0\n\t");
+}
+
+static void __init do_read_pmc2(unsigned int unused)
+{
+	unsigned int i, dummy;
+	__asm__ __volatile__ (".set mips32\n\t");
+	for(i = 0; i < NITER/8; ++i)
+		__asm__ __volatile__(X8("mfc0 %0, $25, 3") : "=r" (dummy));
+	__asm__ __volatile__ (".set mips0\n\t");
+}
+
+static void __init do_read_ctrl1(unsigned int unused)
+{
+	unsigned int i, dummy;
+	__asm__ __volatile__ (".set mips32\n\t");
+	for(i = 0; i < NITER/8; ++i)
+		__asm__ __volatile__(X8("mfc0 %0, $25, 0") : "=r" (dummy));
+	__asm__ __volatile__ (".set mips0\n\t");
+}
+
+static void __init do_read_ctrl2(unsigned int unused)
+{
+	unsigned int i, dummy;
+	__asm__ __volatile__ (".set mips32\n\t");
+	for(i = 0; i < NITER/8; ++i)
+		__asm__ __volatile__(X8("mfc0 %0, $25, 2") : "=r" (dummy));
+	__asm__ __volatile__ (".set mips0\n\t");
+}
+
+static void __init do_write_pmc1(unsigned int arg)
+{
+	unsigned int i;
+	__asm__ __volatile__ (".set mips32\n\t");
+	for(i = 0; i < NITER/8; ++i)
+		__asm__ __volatile__(X8("mtc0 %z0, $25, 1") : : "Jr" ((unsigned int)arg));
+	__asm__ __volatile__ (".set mips0\n\t");
+}
+
+static void __init do_write_pmc2(unsigned int arg)
+{
+	unsigned int i;
+	__asm__ __volatile__ (".set mips32\n\t");
+	for(i = 0; i < NITER/8; ++i)
+		__asm__ __volatile__(X8("mtc0 %z0, $25, 3") : : "Jr" ((unsigned int)arg));
+	__asm__ __volatile__ (".set mips0\n\t");
+}
+
+static void __init do_write_ctrl1(unsigned int arg)
+{
+	unsigned int i;
+	__asm__ __volatile__ (".set mips32\n\t");
+	for(i = 0; i < NITER/8; ++i)
+		__asm__ __volatile__(X8("mtc0 %z0, $25, 0") : : "Jr" ((unsigned int)arg));
+	__asm__ __volatile__ (".set mips0\n\t");
+}
+
+static void __init do_write_ctrl2(unsigned int arg)
+{
+	unsigned int i;
+	__asm__ __volatile__ (".set mips32\n\t");
+	for(i = 0; i < NITER/8; ++i)
+		__asm__ __volatile__(X8("mtc0 %z0, $25, 2") : : "Jr" ((unsigned int)arg));
+	__asm__ __volatile__ (".set mips0\n\t");
+}
+
+static void __init do_empty_loop(unsigned int unused)
+{
+	unsigned i;
+	for(i = 0; i < NITER/8; ++i)
+		__asm__ __volatile__("" : : );
+}
+
+static unsigned __init run(void (*doit)(unsigned int), unsigned int arg)
+{
+	unsigned int start, stop;
+	start = __read_32bit_c0_register ($25, 1);
+	(*doit)(arg);	/* should take < 2^32 cycles to complete */
+	stop = __read_32bit_c0_register ($25, 1);
+	return (stop - start);
+}
+
+static void __init init_tests_message(void)
+{
+	printk(KERN_INFO "Please email the following PERFCTR INIT lines "
+	       "to mikpe@csd.uu.se\n"
+	       KERN_INFO "To remove this message, rebuild the driver "
+	       "with CONFIG_PERFCTR_INIT_TESTS=n\n");
+	printk(KERN_INFO "PERFCTR INIT: CPU clock %u kHz\n", perfctr_info.cpu_khz);
+}
+
+static void __init clear(void)
+{
+	__write_32bit_c0_register($25, 0, 0);
+	__write_32bit_c0_register($25, 1, 0);
+	__write_32bit_c0_register($25, 2, 0);
+	__write_32bit_c0_register($25, 3, 0);
+}
+
+static void __init measure_overheads(void)
+{
+	int i;
+	unsigned int loop, ticks[9];
+	const char *name[9];
+	unsigned int ctrl1, ctrl2;
+
+	/* PMC1 = "processor cycles", PMC2 = "completed instructions",
+	   not disabled in any mode, no interrupts */
+
+	clear();
+
+	//setup control register 1 and 2
+
+	ctrl1 = ctrl2 = 0;
+
+	ctrl1 |= MIPS_XLR_DOM_KERNEL | MIPS_XLR_DOM_USR;
+	MIPS_XLR_OVF_PMI_DABLE(ctrl1);
+	MIPS_XLR_SET_CNT_ALL_THREADS(ctrl1);
+	MIPS_XLR_SET_EVNT(ctrl1, 63); // CYCLE_CNT
+
+	ctrl2 |= MIPS_XLR_DOM_KERNEL | MIPS_XLR_DOM_USR;
+	MIPS_XLR_OVF_PMI_DABLE(ctrl2);
+	MIPS_XLR_SET_CNT_ALL_THREADS(ctrl2);
+	MIPS_XLR_SET_EVNT(ctrl2, 0); // INSTRS FETCHED
+
+	__write_32bit_c0_register($25, 0, ctrl1);
+	__write_32bit_c0_register($25, 2, ctrl2);
+
+ 	name[0] = "read (tsc)";
+	ticks[0] = run(do_read_tsc, 0);
+
+	name[1] = "read (pmc0)";
+	ticks[1] = run(do_read_pmc1, 0);
+	name[2] = "read (pmc1)";
+	ticks[2] = run(do_read_pmc2, 0);
+
+	name[3] = "read (ctrl0)";
+	ticks[3] = run(do_read_ctrl1, 0);
+	name[4] = "read (ctrl1)";
+	ticks[4] = run(do_read_ctrl2, 0);
+
+	name[5] = "write (pmc1)";
+	ticks[5] = run(do_write_pmc1, 0);
+	name[6] = "write (pmc2)";
+	ticks[6] = run(do_write_pmc2, 0);
+
+	name[7] = "write (ctrl1)";
+	ticks[7] = run(do_write_ctrl1, ctrl1);
+	name[8] = "write (ctrl2)";
+	ticks[8] = run(do_write_ctrl2, ctrl2);
+
+	loop = run(do_empty_loop, 0);
+
+	clear();
+
+	init_tests_message();
+	printk(KERN_INFO "PERFCTR INIT: NITER == %u\n", NITER);
+	printk(KERN_INFO "PERFCTR INIT: loop overhead is %u cycles\n", loop);
+	for(i = 0; i < ARRAY_SIZE(ticks); ++i) {
+		unsigned int x;
+		if (!ticks[i])
+			continue;
+		x = ((ticks[i] - loop) * 10) / NITER;
+		printk(KERN_INFO "PERFCTR INIT: %s cost is %u.%u cycles (%u total)\n",
+		       name[i], x/10, x%10, ticks[i]);
+	}
+}
+
+void __init perfctr_mips_init_tests()
+{
+	preempt_disable();
+	measure_overheads();
+	preempt_enable();
+}
diff --git a/drivers/perfctr/mips_tests.h b/drivers/perfctr/mips_tests.h
new file mode 100644
index 0000000..4747fbf
--- /dev/null
+++ b/drivers/perfctr/mips_tests.h
@@ -0,0 +1,24 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/* $Id: mips_tests.h,v 1.1.2.3 2006-09-28 01:24:17 nphilips Exp $
+ * Performance-monitoring counters driver.
+ * Optional PPC32-specific init-time tests.
+ *
+ * Copyright (C) 2004  Mikael Pettersson
+ */
+
+#ifdef CONFIG_PERFCTR_INIT_TESTS
+extern void perfctr_mips_init_tests(void);
+#else
+static inline void perfctr_mips_init_tests(void) { };
+#endif
diff --git a/drivers/perfctr/pmc.h b/drivers/perfctr/pmc.h
new file mode 100644
index 0000000..8a63b8a
--- /dev/null
+++ b/drivers/perfctr/pmc.h
@@ -0,0 +1,38 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+#ifndef __PERFCTR_PMC_H
+#define __PERFCTR_PMC_H
+
+#define PMC_KERNEL_MODE		0x2
+#define PMC_SUP_MODE		0x4
+#define PMC_USER_MODE		0x8
+
+#define PMC_SET_EVNTCNT_MODE(x, mode)		x |= mode
+#define PMC_UNSET_EVNTCNT_MODE(x, mode)		x &= ~mode
+
+#define PMC_ENABLE_ITRPT(x)					x |= 0x10
+#define PMC_DISABLE_ITRPT(x)				x &= ~0x10
+
+#define PMC_EVNTSEL_MASK			0x3f
+#define PMC_EVNTSEL_SHIFT			5
+#define PMC_SET_EVNT(x, event)		x |= ((event & PMC_EVNTSEL_MASK) << PMC_EVNTSEL_SHIFT)
+#define PMC_GET_EVNT(x)				((x >> PMC_EVNTSEL_SHIFT) & PMC_EVNTSEL_MASK)
+
+#define PMC_THREADID_MASK				0x03
+#define PMC_THREADID_SHIFT				11
+#define PMC_SET_THREADID(x, tid)		x |= ((tid & PMC_EVNTSEL_MASK) << PMC_EVNTSEL_SHIFT)
+
+#define PMC_SET_CNT_ALL_THREADS(x)		x |= 0x2000
+#define PMC_UNSET_CNT_ALL_THREADS(x)	x &= ~0x2000
+
+#endif
diff --git a/drivers/perfctr/version.h b/drivers/perfctr/version.h
new file mode 100644
index 0000000..a117acc
--- /dev/null
+++ b/drivers/perfctr/version.h
@@ -0,0 +1,13 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+#define VERSION "2.7.9"
diff --git a/drivers/perfctr/virtual.c b/drivers/perfctr/virtual.c
new file mode 100644
index 0000000..5a20183
--- /dev/null
+++ b/drivers/perfctr/virtual.c
@@ -0,0 +1,1360 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/* $Id: virtual.c,v 1.1.2.8 2007-11-15 13:42:01 kmurthy Exp $
+ * Virtual per-process performance counters.
+ *
+ * Copyright (C) 1999-2004  Mikael Pettersson
+ */
+#include <linux/init.h>
+#include <linux/compiler.h>	/* for unlikely() in 2.4.18 and older */
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/ptrace.h>
+#include <linux/fs.h>
+#include <linux/file.h>
+#include <linux/perfctr.h>
+#include <linux/nsproxy.h>
+
+#include <asm/io.h>
+#include <asm/uaccess.h>
+
+#include "cpumask.h"
+#include "virtual.h"
+#include "compat.h"
+
+// #define __DEBUG__ 1
+
+/****************************************************************
+ * Data types and macros.					*
+ ****************************************************************/
+
+struct vperfctr {
+	/* User-visible fields: (must be first for mmap()) */
+	struct perfctr_cpu_state cpu_state;
+	
+	/* Kernel-private fields: */
+	int si_signo;
+	atomic_t count;
+	spinlock_t owner_lock;
+	struct task_struct *owner;
+
+	/* sampling_timer and bad_cpus_allowed are frequently
+	   accessed, so they get to share a cache line 
+	*/
+	unsigned int sampling_timer ____cacheline_aligned;
+
+	#ifdef CONFIG_PERFCTR_CPUS_FORBIDDEN_MASK
+	atomic_t bad_cpus_allowed;
+	#endif
+
+	#ifdef CONFIG_PERFCTR_INTERRUPT_SUPPORT
+	unsigned int iresume_cstatus;
+	#endif
+
+	/* children_lock protects inheritance_id and children,
+	   when parent is not the one doing release_task() 
+	*/
+	spinlock_t children_lock;
+	unsigned long long inheritance_id;
+	struct perfctr_sum_ctrs children;
+
+	/* schedule_work() data for when an operation cannot be
+	   done in the current context due to locking rules 
+	*/
+	struct work_struct work;
+	struct task_struct *parent_tsk;
+};
+
+#define IS_RUNNING(perfctr)	perfctr_cstatus_enabled((perfctr)->cpu_state.cstatus)
+
+#ifdef CONFIG_PERFCTR_INTERRUPT_SUPPORT
+
+static void vperfctr_ihandler(unsigned long pc);
+static inline void vperfctr_handle_overflow(struct task_struct*, struct vperfctr*);
+
+static inline void vperfctr_set_ihandler(void)
+{
+	perfctr_cpu_set_ihandler(vperfctr_ihandler);
+}
+
+static inline void vperfctr_clear_iresume_cstatus(struct vperfctr *perfctr)
+{
+	perfctr->iresume_cstatus = 0;
+}
+
+#else
+static inline void vperfctr_set_ihandler(void) { }
+static inline void vperfctr_clear_iresume_cstatus(struct vperfctr *perfctr) { }
+#endif
+
+#ifdef CONFIG_PERFCTR_CPUS_FORBIDDEN_MASK
+
+static inline void vperfctr_init_bad_cpus_allowed(struct vperfctr *perfctr)
+{
+	atomic_set(&perfctr->bad_cpus_allowed, 0);
+}
+
+#else	/* !CONFIG_PERFCTR_CPUS_FORBIDDEN_MASK */
+static inline void vperfctr_init_bad_cpus_allowed(struct vperfctr *perfctr) { }
+#endif	/* !CONFIG_PERFCTR_CPUS_FORBIDDEN_MASK */
+
+/****************************************************************
+ *																*
+ * Resource management.											*
+ *																*
+ ****************************************************************/
+
+/* XXX: perhaps relax this to number of _live_ perfctrs */
+static DECLARE_MUTEX(nrctrs_mutex);
+static int nrctrs;
+static const char this_service[] = __FILE__;
+
+static int inc_nrctrs(void)
+{
+	const char *other;
+
+	other = NULL;
+	down(&nrctrs_mutex);
+	if (++nrctrs == 1) {
+		other = perfctr_cpu_reserve(this_service);
+		if (other)
+			nrctrs = 0;
+	}
+	up(&nrctrs_mutex);
+	if (other) {
+		printk(KERN_ERR __FILE__ ": cannot operate, perfctr hardware taken by '%s'\n", other);
+		return -EBUSY;
+	}
+	vperfctr_set_ihandler();
+	return 0;
+}
+
+static void dec_nrctrs(void)
+{
+	down(&nrctrs_mutex);
+	if (--nrctrs == 0)
+		perfctr_cpu_release(this_service);
+	up(&nrctrs_mutex);
+}
+
+/* Allocate a `struct vperfctr'. Claim and reserve
+   an entire page so that it can be mmap():ed. */
+static struct vperfctr *vperfctr_alloc(void)
+{
+	unsigned long page;
+
+	if (inc_nrctrs() != 0)
+		return ERR_PTR(-EBUSY);
+	page = get_zeroed_page(GFP_KERNEL);
+	if (!page) {
+		dec_nrctrs();
+		return ERR_PTR(-ENOMEM);
+	}
+	SetPageReserved(virt_to_page((void *)(page)));
+	return (struct vperfctr*) page;
+}
+
+static void vperfctr_free(struct vperfctr *perfctr)
+{
+	ClearPageReserved(virt_to_page(perfctr));
+	free_page((unsigned long)perfctr);
+	dec_nrctrs();
+}
+
+static struct vperfctr *get_empty_vperfctr(void)
+{
+	struct vperfctr *perfctr = vperfctr_alloc();
+	if (!IS_ERR(perfctr)) {
+		atomic_set(&perfctr->count, 1);
+		vperfctr_init_bad_cpus_allowed(perfctr);
+		spin_lock_init(&perfctr->owner_lock);
+		spin_lock_init(&perfctr->children_lock);
+	}
+	return perfctr;
+}
+
+static void put_vperfctr(struct vperfctr *perfctr)
+{
+	// returns true if the value after decrement is zero
+	if (atomic_dec_and_test(&perfctr->count))
+		vperfctr_free(perfctr);
+}
+
+static void scheduled_vperfctr_free(struct work_struct *work)
+{
+	struct vperfctr *perfctr =
+		container_of(work, struct vperfctr, work);
+	// printk ("vperfctr being released from %s\n", __FUNCTION__);
+	vperfctr_free((struct vperfctr*)perfctr);
+}
+
+static void schedule_put_vperfctr(struct vperfctr *perfctr)
+{
+	if (!atomic_dec_and_test(&perfctr->count))
+		return;
+	INIT_WORK(&perfctr->work, scheduled_vperfctr_free);
+	schedule_work(&perfctr->work);
+}
+
+static unsigned long long new_inheritance_id(void)
+{
+	static spinlock_t lock = SPIN_LOCK_UNLOCKED;
+	static unsigned long long counter;
+	unsigned long long id;
+
+	spin_lock(&lock);
+	id = ++counter;
+	spin_unlock(&lock);
+	return id;
+}
+
+/****************************************************************
+ *								*
+ * Basic counter operations.					*
+ * These must all be called by the owner process only.		*
+ * These must all be called with preemption disabled.		*
+ *								*
+ ****************************************************************/
+
+/* PRE: IS_RUNNING(perfctr)
+ * Suspend the counters.
+ */
+static inline void vperfctr_suspend(struct vperfctr *perfctr)
+{
+	perfctr_cpu_suspend(&perfctr->cpu_state);
+}
+
+static inline void vperfctr_reset_sampling_timer(struct vperfctr *perfctr)
+{
+	/* XXX: base the value on perfctr_info.cpu_khz instead! */
+	perfctr->sampling_timer = HZ/2;
+}
+
+/* PRE: perfctr == current->thread.perfctr && IS_RUNNING(perfctr)
+ * Restart the counters.
+ */
+static inline void vperfctr_resume(struct vperfctr *perfctr)
+{
+	perfctr_cpu_resume(&perfctr->cpu_state);
+	vperfctr_reset_sampling_timer(perfctr);
+}
+
+static inline void vperfctr_resume_with_overflow_check(struct vperfctr *perfctr)
+{
+#ifdef CONFIG_PERFCTR_INTERRUPT_SUPPORT
+	if (perfctr_cpu_has_pending_interrupt(&perfctr->cpu_state)) {
+		vperfctr_handle_overflow(current, perfctr);
+		return;
+	}
+#endif
+	vperfctr_resume(perfctr);
+}
+
+/* Sample the counters but do not suspend them. */
+static inline void vperfctr_sample(struct vperfctr *perfctr)
+{
+	if (IS_RUNNING(perfctr)) {
+		// logical place to see if the counters are ours else return
+	
+		perfctr_cpu_sample(&perfctr->cpu_state);
+		vperfctr_reset_sampling_timer(perfctr);
+	}
+}
+
+#ifdef CONFIG_PERFCTR_INTERRUPT_SUPPORT
+
+// PREEMPT note: called in IRQ context with preemption disabled.
+static void vperfctr_ihandler(unsigned long pc)
+{
+	struct task_struct *tsk = current;
+	struct vperfctr *perfctr;
+	unsigned int pmc, cstatus, now = 0;
+	int i;
+
+	perfctr = tsk->thread.perfctr;
+	if (!perfctr) {
+		return;
+	}
+	if (!perfctr_cstatus_has_ictrs(perfctr->cpu_state.cstatus)) {
+		return;
+	}
+
+	// if someone has really overflown then continue else return
+	// just read, don't freeze them
+	
+	cstatus = perfctr->cpu_state.cstatus;
+	for (i = perfctr_cstatus_nractrs(cstatus); (i < perfctr_cstatus_nrctrs(cstatus)) && ((int)now >= 0); ++i) {
+		pmc = perfctr->cpu_state.pmc[i].map;
+		now = read_pmc(pmc);
+	}
+	if ((int)now >= 0) {
+		return;
+	}
+
+	// Fine, we are suspending the counters and reading them. vperfctr_suspend() 
+	// in turn invokes _suspend() on i-mode ctrs (where they are frozen and read) 
+	// and a-mode counters (where they are just read)
+
+	vperfctr_suspend(perfctr);
+
+	// Ok, Signal to the userland is sent in the following routine. But before that
+	// the following routine calls vperfctr_resume() if the TSC counting is on.
+	// what happens in that resume is just the TSC value is read and stored in the
+	// 'start' state of the TSC
+
+	vperfctr_handle_overflow(tsk, perfctr);
+}
+
+static inline void vperfctr_handle_overflow(struct task_struct *tsk,
+				     struct vperfctr *perfctr)
+{
+	unsigned int pmc_mask;
+	siginfo_t si;
+	sigset_t old_blocked;
+
+	pmc_mask = perfctr_cpu_identify_overflow(&perfctr->cpu_state);
+	if (!pmc_mask) {
+		printk(KERN_ERR "%s: BUG! pid %d has unidentifiable overflow source\n", __FUNCTION__, tsk->pid);
+		return;
+	}
+	/* suspend a-mode and i-mode PMCs, leaving only TSC on */
+	/* XXX: some people also want to suspend the TSC */
+
+	// we are storing 'cpu_state.cstatus' in 'iresume_cstatus' because
+	// in vperfctr_resume, we only want to read the status of those
+	// In the following TSC is resumed and continues to collect the
+	// stats
+
+	// if 'perfctr->iresume_cstatus' is not updated below, vperfctr_iresume() fails
+	// as it thinks it was spuriously called inspite of absence of i-mode counters.
+	// vperfctr_iresume() -> ... -> do_vperfctr_iresume() is a different thread of
+	// execution from vperfctr_resume() -> ... -> vperfctr_iresume() -> __write_control() ->
+	// ...
+	perfctr->iresume_cstatus = perfctr->cpu_state.cstatus;
+
+	if (perfctr_cstatus_has_tsc(perfctr->iresume_cstatus)) {
+		perfctr->cpu_state.cstatus = perfctr_mk_cstatus(1, 0, 0);
+		vperfctr_resume(perfctr);
+	} 
+	else {
+		perfctr->cpu_state.cstatus = 0;
+	}
+
+	// the following siginfo_t structure helps the kernel in invoking
+	// the correct signal handler. Is that right ?
+	// what's the deal with si_errno? what does it say ? si_code ?
+
+	si.si_signo = perfctr->si_signo;
+	si.si_errno = 0;
+	si.si_code = SI_PMC_OVF;
+	si.si_pmc_ovf_mask = pmc_mask;
+
+	/* deliver signal without waking up the receiver */
+	spin_lock_irq(&tsk->sighand->siglock);
+	old_blocked = tsk->blocked;
+	sigaddset(&tsk->blocked, si.si_signo);
+	spin_unlock_irq(&tsk->sighand->siglock);
+
+	if (!send_sig_info(si.si_signo, &si, tsk)) {
+		send_sig(si.si_signo, tsk, 1);
+	}
+
+	spin_lock_irq(&tsk->sighand->siglock);
+	tsk->blocked = old_blocked;
+	recalc_sigpending();
+	spin_unlock_irq(&tsk->sighand->siglock);
+}
+
+#else
+static void vperfctr_ihandler(unsigned long pc) { };
+#endif
+
+
+/****************************************************************
+ *								*
+ * Process management operations.				*
+ * These must all, with the exception of vperfctr_unlink()	*
+ * and __vperfctr_set_cpus_allowed(), be called by the owner	*
+ * process only.						*
+ *								*
+ ****************************************************************/
+
+/* do_fork() -> copy_process() -> copy_thread() -> __vperfctr_copy().
+ * Inherit the parent's perfctr settings to the child.
+ * PREEMPT note: do_fork() etc do not run with preemption disabled.
+*/
+void __vperfctr_copy(struct task_struct *child_tsk, struct pt_regs *regs)
+{
+	struct vperfctr *parent_perfctr;
+	struct vperfctr *child_perfctr;
+
+	/* Do not inherit perfctr settings to kernel-generated
+	   threads, like those created by kmod. */
+	child_perfctr = NULL;
+	if (!user_mode(regs)) {
+		goto out;
+	}
+
+	/* Allocation may sleep. Do it before the critical region. */
+	child_perfctr = get_empty_vperfctr();
+	if (IS_ERR(child_perfctr)) {
+		child_perfctr = NULL;
+		goto out;
+	}
+
+	/* Although we're executing in the parent, if it is scheduled
+	   then a remote monitor may attach and change the perfctr
+	   pointer or the object it points to. This may already have
+	   occurred when we get here, so the old copy of the pointer
+	   in the child cannot be trusted. */
+	preempt_disable();
+	parent_perfctr = current->thread.perfctr;
+	if (parent_perfctr) {
+		child_perfctr->cpu_state.control = parent_perfctr->cpu_state.control;
+		child_perfctr->si_signo = parent_perfctr->si_signo;
+		child_perfctr->inheritance_id = parent_perfctr->inheritance_id;
+	}
+	preempt_enable();
+	if (!parent_perfctr) {
+		put_vperfctr(child_perfctr);
+		child_perfctr = NULL;
+		goto out;
+	}
+	(void)perfctr_cpu_update_control(&child_perfctr->cpu_state, 0);
+	child_perfctr->owner = child_tsk;
+ out:
+	child_tsk->thread.perfctr = child_perfctr;
+}
+
+/* Called from exit_thread() or do_vperfctr_unlink().
+ * If the counters are running, stop them and sample their final values.
+ * Mark the vperfctr object as dead.
+ * Optionally detach the vperfctr object from its owner task.
+ * PREEMPT note: exit_thread() does not run with preemption disabled.
+ */
+
+// exit_thread() --> ... ; do_vperfctr_unlink() --> ...
+static void vperfctr_unlink(struct task_struct *owner, struct vperfctr *perfctr, int do_unlink)
+{
+	/* this synchronises with sys_vperfctr() */
+	spin_lock(&perfctr->owner_lock);
+	perfctr->owner = NULL;
+	spin_unlock(&perfctr->owner_lock);
+
+	/* perfctr suspend+detach must be atomic wrt process suspend */
+	/* this also synchronises with perfctr_set_cpus_allowed() */
+	task_lock(owner);
+	if (IS_RUNNING(perfctr) && owner == current)
+		vperfctr_suspend(perfctr);
+	if (do_unlink)
+		owner->thread.perfctr = NULL;
+	task_unlock(owner);
+
+	perfctr->cpu_state.cstatus = 0;
+	vperfctr_clear_iresume_cstatus(perfctr);
+	if (do_unlink)
+		put_vperfctr(perfctr);
+}
+
+// called from the _exit_thread() in arch/mips/kernel/process.c
+// this is called by tasks onselves. Since we specified '0' as the 3rd
+// argument for vperfctr_unlink(), only the stats are collected but the
+// the task structure itself is not freed
+
+void __vperfctr_exit(struct vperfctr *perfctr)
+{
+	vperfctr_unlink(current, perfctr, 0);
+}
+
+// release_task() is called during the deallocation of resources of
+// a zombie thread/process and not when a process/thread exits
+
+/* release_task() -> perfctr_release_task() -> __vperfctr_release().
+ * A task is being released. If it inherited its perfctr settings
+ * from its parent, then merge its final counts back into the parent.
+ * Then unlink the child's perfctr.
+ * PRE: caller has write_lock_irq(&tasklist_lock).
+ * PREEMPT note: preemption is disabled due to tasklist_lock.
+ */
+
+static void do_vperfctr_release(struct vperfctr *child_perfctr, struct task_struct *parent_tsk)
+{
+	struct vperfctr *parent_perfctr;
+	unsigned int cstatus, nrctrs, i;
+
+	parent_perfctr = parent_tsk->thread.perfctr;
+	if (parent_perfctr && child_perfctr) {
+		
+		// since more than one child can try to add to parent's
+		// counters, we need a lock
+
+		spin_lock(&parent_perfctr->children_lock);
+		if (parent_perfctr->inheritance_id == child_perfctr->inheritance_id) {
+			cstatus = parent_perfctr->cpu_state.cstatus;
+			if (perfctr_cstatus_has_tsc(cstatus))
+				parent_perfctr->children.tsc +=
+					child_perfctr->cpu_state.tsc_sum +
+					child_perfctr->children.tsc;
+			nrctrs = perfctr_cstatus_nrctrs(cstatus);
+			for(i = 0; i < nrctrs; ++i)
+				parent_perfctr->children.pmc[i] +=
+					child_perfctr->cpu_state.pmc[i].sum +
+					child_perfctr->children.pmc[i];
+		}
+		spin_unlock(&parent_perfctr->children_lock);
+	}
+
+	// now that we reaped the data from child's task structure
+	// the child's task structure can be freed. Only the child's
+	// vperfctr structure seems to be released. Is the 'task_struct'
+	// released in __vperfctr_release() itself? Doesn't seem so.
+	schedule_put_vperfctr(child_perfctr);
+}
+
+static void scheduled_release(struct work_struct *data)
+{
+	struct vperfctr *child_perfctr = 
+		container_of(data, struct vperfctr, work);
+	struct task_struct *parent_tsk = child_perfctr->parent_tsk;
+
+	// why are we getting a lock on the parent task structure ?
+	// of course, we incremented the reference count to parent's task_struct
+	task_lock(parent_tsk);
+	do_vperfctr_release(child_perfctr, parent_tsk);
+	task_unlock(parent_tsk);
+	
+	// good, the incremented reference count of the parent task is now
+	// decremented, now that we are done adding up our counts to that
+	// of the parent
+	put_task_struct(parent_tsk);
+}
+
+void __vperfctr_release(struct task_struct *child_tsk)
+{
+	struct task_struct *parent_tsk = child_tsk->parent;
+	struct vperfctr *child_perfctr = child_tsk->thread.perfctr;
+
+	// this is invoked either in the waitpid() or if there the parent is not
+	// interesting in its children. In the latter case, "parent_tsk != current"
+
+	// one releases oneself, when the parent is not interested in one's data
+	// but even then we would like to add our counters to those of the parent's
+	
+	// another step towards freeing the task_struct(ure).
+	child_tsk->thread.perfctr = NULL;
+
+	// if the parent is releasing the children's task structure, then it (the
+	// parent) can go ahead and add the children's vperfctr's values to the
+	// 'children' field in the parent's 'vperfctr' structure.
+	// So, am 'I' the parent of the task_structure I am attempting to release?
+	// When current == parent_tsk, the child's counts can be merged
+	// into the parent's immediately. This is the common case.
+
+	// printk ("%s, %d\n", __FUNCTION__, __LINE__);
+	if (child_perfctr == NULL) {
+		// printk("%s, %d, child_perfctr == NULL\n", __FUNCTION__, __LINE__);
+	}
+
+	if (parent_tsk == current)
+		do_vperfctr_release(child_perfctr, parent_tsk);
+	else {
+
+		/* When current != parent_tsk, the parent must be task_lock()ed
+		 * before its perfctr state can be accessed. task_lock() is illegal
+		 * here due to the write_lock_irq(&tasklist_lock) in release_task(),
+		 * so the operation is done via schedule_work(). Also, increment
+		 * the reference count of parent's task_struct so that it will not be
+		 * freed for good
+	     */
+
+		get_task_struct(parent_tsk);	// increments the reference count
+
+		INIT_WORK(&child_perfctr->work, scheduled_release);
+		child_perfctr->parent_tsk = parent_tsk;
+		schedule_work(&child_perfctr->work);
+	}
+}
+
+/* schedule() --> switch_to() --> .. --> __vperfctr_suspend().
+ * If the counters are running, suspend them.
+ * PREEMPT note: switch_to() runs with preemption disabled.
+ */
+void __vperfctr_suspend(struct vperfctr *perfctr)
+{
+	if (IS_RUNNING(perfctr))
+		vperfctr_suspend(perfctr);
+}
+
+/* schedule() --> switch_to() --> .. --> __vperfctr_resume().
+ * PRE: perfctr == current->thread.perfctr
+ * If the counters are runnable, resume them.
+ * PREEMPT note: switch_to() runs with preemption disabled.
+ */
+void __vperfctr_resume(struct vperfctr *perfctr)
+{
+	if (IS_RUNNING(perfctr)) {
+		// logical place to add the functionality
+
+	// what exactly are we doing here ?
+#ifdef CONFIG_PERFCTR_CPUS_FORBIDDEN_MASK
+		if (unlikely(atomic_read(&perfctr->bad_cpus_allowed)) &&
+		    perfctr_cstatus_nrctrs(perfctr->cpu_state.cstatus)) {
+			perfctr->cpu_state.cstatus = 0;
+			vperfctr_clear_iresume_cstatus(perfctr);
+			BUG_ON(current->state != TASK_RUNNING);
+			send_sig(SIGILL, current, 1);
+			return;
+		}
+#endif
+		vperfctr_resume_with_overflow_check(perfctr);
+	}
+}
+
+/* Called from update_one_process() [triggered by timer interrupt].
+ * PRE: perfctr == current->thread.perfctr.
+ * Sample the counters but do not suspend them.
+ * Needed to avoid precision loss due to multiple counter
+ * wraparounds between resume/suspend for CPU-bound processes.
+ * PREEMPT note: called in IRQ context with preemption disabled.
+ */
+void __vperfctr_sample(struct vperfctr *perfctr)
+{
+	if (--perfctr->sampling_timer == 0)
+		vperfctr_sample(perfctr);
+}
+
+#ifdef CONFIG_PERFCTR_CPUS_FORBIDDEN_MASK
+/* Called from set_cpus_allowed().
+ * PRE: current holds task_lock(owner)
+ * PRE: owner->thread.perfctr == perfctr
+ */
+void __vperfctr_set_cpus_allowed(struct task_struct *owner,
+				 struct vperfctr *perfctr,
+				 cpumask_t new_mask)
+{
+	if (cpus_intersects(new_mask, perfctr_cpus_forbidden_mask)) {
+		atomic_set(&perfctr->bad_cpus_allowed, 1);
+		if (printk_ratelimit())
+			printk(KERN_WARNING "perfctr: process %d (comm %s) issued unsafe"
+				" set_cpus_allowed() on process %d (comm %s)\n",
+			    	current->pid, current->comm, owner->pid, owner->comm);
+	} else
+		atomic_set(&perfctr->bad_cpus_allowed, 0);
+}
+#endif
+
+/****************************************************************
+ *								*
+ * Virtual perfctr system calls implementation.			*
+ * These can be called by the owner process (tsk == current),	*
+ * a monitor process which has the owner under ptrace ATTACH	*
+ * control (tsk && tsk != current), or anyone with a handle to	*
+ * an unlinked perfctr (!tsk).					*
+ *								*
+ ****************************************************************/
+
+static int do_vperfctr_control(struct vperfctr *perfctr,
+			       const struct vperfctr_control __user *argp,
+			       unsigned int argbytes,
+			       struct task_struct *tsk)
+{
+	struct vperfctr_control *control;
+	int err;
+	unsigned int next_cstatus;
+	unsigned int nrctrs, i;
+
+	if (!tsk) {
+		return -ESRCH;	/* attempt to update unlinked perfctr */
+	}
+
+	/* The control object can be large (over 300 bytes on i386),
+	   so kmalloc() it instead of storing it on the stack.
+	   We must use task-private storage to prevent racing with a
+	   monitor process attaching to us before the non-preemptible
+	   perfctr update step. Therefore we cannot store the copy
+	   in the perfctr object itself. */
+	control = kmalloc(sizeof(*control), GFP_USER);
+	if (!control) {
+		return -ENOMEM;
+	}
+
+	err = -EINVAL;
+	if (argbytes > sizeof *control) {
+		goto out_kfree;
+	}
+
+	err = -EFAULT;
+	if (copy_from_user(control, argp, argbytes)) {
+		goto out_kfree;
+	}
+
+	if (argbytes < sizeof *control)
+		memset((char*)control + argbytes, 0, sizeof *control - argbytes);
+
+	// figure out what is happening in the following 'if' loop
+
+	if (control->cpu_control.nractrs || control->cpu_control.nrictrs) {
+		cpumask_t old_mask, new_mask;
+
+		old_mask = tsk->cpus_allowed;
+		cpus_andnot(new_mask, old_mask, perfctr_cpus_forbidden_mask);
+
+		err = -EINVAL;
+		if (cpus_empty(new_mask)) {
+			goto out_kfree;
+		}
+		if (!cpus_equal(new_mask, old_mask))
+			set_cpus_allowed(tsk, new_mask);
+	}
+
+	/* PREEMPT note: preemption is disabled over the entire
+	   region since we're updating an active perfctr. */
+	preempt_disable();
+
+	// the task whose control register I am changing might actually be
+	// in suspended state. That can happen when the other is executing
+	// under the control of another task as in the case of debugging
+	// or ptrace. However, if the write_control is done for the current
+	// executing process, first suspend them and then do the update
+	// why are we resetting 'perfctr->cpu_state.cstatus' ?
+
+	if (IS_RUNNING(perfctr)) {
+		if (tsk == current)
+			vperfctr_suspend(perfctr);
+	
+		// not sure why we are zeroing out the following explicitly
+		perfctr->cpu_state.cstatus = 0;
+		vperfctr_clear_iresume_cstatus(perfctr);
+	}
+
+	// coying the user-specified control values to 'state'
+	perfctr->cpu_state.control = control->cpu_control;
+
+	/* remote access note: perfctr_cpu_update_control() is ok */
+	err = perfctr_cpu_update_control(&perfctr->cpu_state, 0);
+	if (err < 0) {
+		goto out;
+	}
+	next_cstatus = perfctr->cpu_state.cstatus;
+	if (!perfctr_cstatus_enabled(next_cstatus))
+		goto out;
+
+	/* XXX: validate si_signo? */
+	perfctr->si_signo = control->si_signo;
+
+	if (!perfctr_cstatus_has_tsc(next_cstatus))
+		perfctr->cpu_state.tsc_sum = 0;
+
+	nrctrs = perfctr_cstatus_nrctrs(next_cstatus);
+	for(i = 0; i < nrctrs; ++i)
+		if (!(control->preserve & (1<<i)))
+			perfctr->cpu_state.pmc[i].sum = 0;
+
+	// I am not sure why we are removing the inheritance just because
+	// we updated the control information. True, because the children might
+	// be performing something else. So, the control will have to be set
+	// before spawning any children
+
+	spin_lock(&perfctr->children_lock);
+	perfctr->inheritance_id = new_inheritance_id();
+	memset(&perfctr->children, 0, sizeof perfctr->children);
+	spin_unlock(&perfctr->children_lock);
+
+	if (tsk == current) {
+		vperfctr_resume(perfctr);
+	}
+
+ out:
+	preempt_enable();
+ out_kfree:
+	kfree(control);
+	return err;
+}
+
+static int do_vperfctr_iresume(struct vperfctr *perfctr, const struct task_struct *tsk)
+{
+#ifdef CONFIG_PERFCTR_INTERRUPT_SUPPORT
+	unsigned int iresume_cstatus;
+
+	if (!tsk)
+		return -ESRCH;	/* attempt to update unlinked perfctr */
+
+	iresume_cstatus = perfctr->iresume_cstatus;
+	if (!perfctr_cstatus_has_ictrs(iresume_cstatus)) {
+		return -EPERM;
+	}
+
+	/* PREEMPT note: preemption is disabled over the entire
+	   region because we're updating an active perfctr. */
+	preempt_disable();
+
+	// this is for resuming a task whose signal was handled prior to this call
+	// are the i-mode counters frozen before the overflow-signal is delivered
+	// yes, they are. in the suspend call invoked in the handler
+
+	// why exactly are we suspending the following? Makes sense ... if the
+	// counters are already running, then one should not just resume the task
+	// which will overwrite the PMC registers with old values. Nice. Under
+	// what condition do counters continue to count after the signal is delivered
+	// remember TSC was not suspend in the handler and continues to count
+
+	if (IS_RUNNING(perfctr) && tsk == current)
+		vperfctr_suspend(perfctr);
+
+	// setting the cstatus of 'cpu_state' back to what it was prior to its
+	// zeroing out in the interrupt handler
+	perfctr->cpu_state.cstatus = iresume_cstatus;
+	perfctr->iresume_cstatus = 0;
+
+	/* remote access note: perfctr_cpu_ireload() is ok */
+	// the following forces the reload of control registers that 
+	// unfreezes the i-mode registers
+	perfctr_cpu_ireload(&perfctr->cpu_state);
+
+	if (tsk == current)
+		vperfctr_resume(perfctr);
+
+	preempt_enable();
+
+	return 0;
+#else
+	return -ENOSYS;
+#endif
+}
+
+static int do_vperfctr_unlink(struct vperfctr *perfctr, struct task_struct *tsk)
+{
+	if (tsk)
+		vperfctr_unlink(tsk, perfctr, 1);
+	return 0;
+}
+
+// sys_vperfctr_read() -> this()
+static int do_vperfctr_read(struct vperfctr *perfctr,
+			    unsigned int cmd,
+			    void __user *argp,
+			    unsigned int argbytes,
+			    struct task_struct *tsk)
+{
+	union {
+		struct perfctr_sum_ctrs sum;
+		struct vperfctr_control control;
+		struct perfctr_sum_ctrs children;
+	} *tmp;
+	unsigned int tmpbytes;
+	int ret;
+
+	/* The state snapshot can be large, so kmalloc() it instead of storing it on the stack.
+	   We must use task-private storage to prevent racing with a monitor process attaching to 
+	   us during the preemptible copy_to_user() step. Therefore we cannot store the snapshot
+	   in the perfctr object itself. 
+    */
+	tmp = kmalloc(sizeof(*tmp), GFP_USER);
+	if (!tmp)
+		return -ENOMEM;
+
+	/* PREEMPT note: While we're reading our own control, another process may ptrace ATTACH 
+       to us and update our control. Disable preemption to ensure we get a consistent copy.
+	   Not needed for other cases since the perfctr is either unlinked or its owner is ptrace 
+       ATTACH suspended by us. 
+	*/
+	if (tsk == current)
+		preempt_disable();
+
+	switch (cmd) {
+    	case VPERFCTR_READ_SUM: {
+    		int j;
+    
+    		vperfctr_sample(perfctr);
+    		tmp->sum.tsc = perfctr->cpu_state.tsc_sum;
+    		for(j = 0; j < ARRAY_SIZE(tmp->sum.pmc); ++j)
+    			tmp->sum.pmc[j] = perfctr->cpu_state.pmc[j].sum;
+    		tmpbytes = sizeof(tmp->sum);
+    	}
+    	break;
+    	case VPERFCTR_READ_CONTROL:
+    		tmp->control.si_signo = perfctr->si_signo;
+    		tmp->control.cpu_control = perfctr->cpu_state.control;
+    		tmp->control.preserve = 0;
+    		tmpbytes = sizeof(tmp->control);
+    	break;
+    	case VPERFCTR_READ_CHILDREN:
+    		if (tsk)
+    			spin_lock(&perfctr->children_lock);
+    		tmp->children = perfctr->children;
+    		if (tsk)
+    			spin_unlock(&perfctr->children_lock);
+    		tmpbytes = sizeof(tmp->children);
+    	break;
+    	default:
+    		tmpbytes = 0;
+	}
+
+	if (tsk == current)
+		preempt_enable();
+
+	ret = -EINVAL;
+	if (tmpbytes > argbytes)
+		tmpbytes = argbytes;
+	if (tmpbytes > 0) {
+		ret = tmpbytes;
+		if (copy_to_user(argp, tmp, tmpbytes))
+			ret = -EFAULT;
+	}
+	kfree(tmp);
+	return ret;
+}
+
+/****************************************************************
+ *																*
+ * Virtual perfctr file operations.								*
+ *																*
+ ****************************************************************/
+
+static int vperfctr_mmap(struct file *filp, struct vm_area_struct *vma)
+{
+	struct vperfctr *perfctr;
+
+	/* Only allow read-only mapping of first page. */
+	// (pgprot_val(vma->vm_page_prot) & _PAGE_RW) ||
+
+	if ( ((vma->vm_end - vma->vm_start) != PERFCTR_PAGE_SIZE) || (vma->vm_pgoff != 0) ||
+	     (pgprot_val(vma->vm_page_prot) & _PAGE_WRITE) || (vma->vm_flags & (VM_WRITE | VM_MAYWRITE))
+       ) {
+		return -EPERM;
+	}
+	perfctr = filp->private_data;
+	if (!perfctr) {
+		return -EPERM;
+	}
+
+    return remap_pfn_range (vma, vma->vm_start, 
+		    (virt_to_phys(perfctr) >> PAGE_SHIFT),
+			PERFCTR_PAGE_SIZE, vma->vm_page_prot);
+}
+
+static int vperfctr_release(struct inode *inode, struct file *filp)
+{
+	struct vperfctr *perfctr = filp->private_data;
+	filp->private_data = NULL;
+
+	// printk("%s, %d\n", __FUNCTION__, __LINE__);
+	if (perfctr) {
+		// printk("%s, %d\n", __FUNCTION__, __LINE__);
+		put_vperfctr(perfctr);
+	}
+	return 0;
+}
+
+static struct file_operations vperfctr_file_ops = {
+	.mmap = vperfctr_mmap,
+	.release = vperfctr_release,
+};
+
+/****************************************************************
+ *																*
+ * File system for virtual perfctrs. Based on pipefs.			*
+ *																*
+ ****************************************************************/
+
+#define VPERFCTRFS_MAGIC (('V'<<24)|('P'<<16)|('M'<<8)|('C'))
+
+/* The code to set up a `struct file_system_type' for a pseudo fs
+   is unfortunately not the same in 2.4 and 2.6. */
+#include <linux/mount.h> /* needed for 2.6, included by fs.h in 2.4 */
+
+static struct vfsmount *vperfctr_mnt;
+static int 
+vperfctrfs_get_sb(struct file_system_type *fs_type,
+		  int flags, const char *dev_name, void *data,  
+		  struct vfsmount *mount)
+{
+	return get_sb_pseudo(fs_type, "vperfctr:", NULL, VPERFCTRFS_MAGIC,
+						mount);
+}
+
+static struct file_system_type vperfctrfs_type = {
+	.name		= "vperfctrfs",
+	.get_sb		= vperfctrfs_get_sb,
+	.kill_sb	= kill_anon_super,
+};
+
+/* XXX: check if s/vperfctr_mnt/vperfctrfs_type.kern_mnt/ would work */
+#define vperfctr_fs_init_done()	(vperfctr_mnt != NULL)
+
+static int __init vperfctrfs_init(void)
+{
+	int err = register_filesystem(&vperfctrfs_type);
+	if (!err) {
+		vperfctr_mnt = kern_mount(&vperfctrfs_type);
+		if (!IS_ERR(vperfctr_mnt))
+			return 0;
+		err = PTR_ERR(vperfctr_mnt);
+		unregister_filesystem(&vperfctrfs_type);
+		vperfctr_mnt = NULL;
+	}
+	return err;
+}
+
+static void __exit vperfctrfs_exit(void)
+{
+	unregister_filesystem(&vperfctrfs_type);
+	mntput(vperfctr_mnt);
+}
+
+static struct inode *vperfctr_get_inode(void)
+{
+	struct inode *inode;
+
+	inode = new_inode(vperfctr_mnt->mnt_sb);
+	if (!inode)
+		return NULL;
+	inode->i_fop = &vperfctr_file_ops;
+	inode->i_state = I_DIRTY;
+	inode->i_mode = S_IFCHR | S_IRUSR | S_IWUSR;
+	inode->i_uid = current->cred->fsuid;
+	inode->i_gid = current->cred->fsgid;
+	inode->i_atime = inode->i_mtime = inode->i_ctime = CURRENT_TIME;
+	return inode;
+}
+
+static int vperfctrfs_delete_dentry(struct dentry *dentry)
+{
+	return 1;
+}
+
+static struct dentry_operations vperfctrfs_dentry_operations = {
+	.d_delete	= vperfctrfs_delete_dentry,
+};
+
+static struct dentry *vperfctr_d_alloc_root(struct inode *inode)
+{
+	struct qstr this;
+	char name[32];
+	struct dentry *dentry;
+
+	sprintf(name, "[%lu]", inode->i_ino);
+	this.name = name;
+	this.len = strlen(name);
+	this.hash = inode->i_ino; /* will go */
+	dentry = d_alloc(vperfctr_mnt->mnt_sb->s_root, &this);
+	if (dentry) {
+		dentry->d_op = &vperfctrfs_dentry_operations;
+		d_add(dentry, inode);
+	}
+	return dentry;
+}
+
+static struct file *vperfctr_get_filp(void)
+{
+	struct file *filp;
+	struct inode *inode;
+	struct dentry *dentry;
+
+	filp = get_empty_filp();
+	if (!filp)
+		goto out;
+	inode = vperfctr_get_inode();
+	if (!inode)
+		goto out_filp;
+	dentry = vperfctr_d_alloc_root(inode);
+	if (!dentry)
+		goto out_inode;
+
+	filp->f_vfsmnt = mntget(vperfctr_mnt);
+	filp->f_dentry = dentry;
+	filp->f_mapping = dentry->d_inode->i_mapping;
+
+	filp->f_pos = 0;
+	filp->f_flags = 0;
+	filp->f_op = &vperfctr_file_ops; /* fops_get() if MODULE */
+	filp->f_mode = FMODE_READ;
+	filp->f_version = 0;
+
+	return filp;
+
+ out_inode:
+	iput(inode);
+ out_filp:
+	put_filp(filp);	/* doesn't run ->release() like fput() does */
+ out:
+	return NULL;
+}
+
+/****************************************************************
+ *								*
+ * Virtual perfctr actual system calls.				*
+ *								*
+ ****************************************************************/
+
+/* tid is the actual task/thread id (ne pid, stored as ->pid),
+   pid/tgid is that 2.6 thread group id crap (stored as ->tgid) */
+asmlinkage long sys_vperfctr_open(int tid, int creat)
+{
+	struct file *filp;
+	struct task_struct *tsk;
+	struct vperfctr *perfctr;
+	int err;
+	int fd;
+
+	if (!vperfctr_fs_init_done())
+		return -ENODEV;
+	filp = vperfctr_get_filp();
+	if (!filp)
+		return -ENOMEM;
+	err = fd = get_unused_fd();
+	if (err < 0)
+		goto err_filp;
+	perfctr = NULL;
+	if (creat) {
+		perfctr = get_empty_vperfctr(); /* may sleep */
+		if (IS_ERR(perfctr)) {
+			err = PTR_ERR(perfctr);
+			goto err_fd;
+		}
+	}
+	tsk = current;
+
+	if (tid != 0 && tid != tsk->pid) { /* remote? */
+		// tasklist_lock is to access the linked list of task_struct structures exclusively
+		read_lock(&tasklist_lock);
+		//tsk = find_task_by_pid(tid);
+		tsk = find_task_by_pid_ns(tid, current->nsproxy->pid_ns);
+		if (tsk)
+			get_task_struct(tsk);
+		read_unlock(&tasklist_lock);
+		err = -ESRCH;
+		if (!tsk)
+			goto err_perfctr;
+		err = ptrace_check_attach(tsk, 0);
+		if (err < 0)
+			goto err_tsk;
+	}
+	if (creat) {
+		/* check+install must be atomic to prevent remote-control races */
+		task_lock(tsk);
+		if (!tsk->thread.perfctr) {
+			perfctr->owner = tsk;
+			tsk->thread.perfctr = perfctr;
+			err = 0;
+		} else
+			err = -EEXIST;
+		task_unlock(tsk);
+		if (err)
+			goto err_tsk;
+	} else {
+		perfctr = tsk->thread.perfctr;
+		/* XXX: Old API needed to allow NULL perfctr here.
+		   Do we want to keep or change that rule? */
+	}
+	filp->private_data = perfctr;
+	if (perfctr)
+		atomic_inc(&perfctr->count);
+	if (tsk != current)
+		put_task_struct(tsk);
+	#if 0
+	if (perfctr) {
+    	printk ("sys_vperfctr_open(): fd = %d, perfctr is NOT null\n", fd);
+	}
+	else {
+    	printk ("sys_vperfctr_open(): fd = %d, perfctr is null\n", fd);
+	}
+	#endif
+	fd_install(fd, filp);
+	return fd;
+ err_tsk:
+	if (tsk != current)
+		put_task_struct(tsk);
+ err_perfctr:
+	if (perfctr)	/* can only occur if creat != 0 */
+		put_vperfctr(perfctr);
+ err_fd:
+	put_unused_fd(fd);
+ err_filp:
+	fput(filp);
+	return err;
+}
+
+static struct vperfctr *fd_get_vperfctr(int fd)
+{
+	struct vperfctr *perfctr;
+	struct file *filp;
+	int err;
+
+	err = -EBADF;
+	filp = fget(fd);
+	if (!filp)
+		goto out;
+	err = -EINVAL;
+	if (filp->f_op != &vperfctr_file_ops)
+		goto out_filp;
+	perfctr = filp->private_data;
+	if (!perfctr)
+		goto out_filp;
+	atomic_inc(&perfctr->count);
+	fput(filp);
+	return perfctr;
+ out_filp:
+	fput(filp);
+ out:
+	return ERR_PTR(err);
+}
+
+static struct task_struct *vperfctr_get_tsk(struct vperfctr *perfctr)
+{
+	struct task_struct *tsk;
+
+	tsk = current;
+	if (perfctr != current->thread.perfctr) {
+		/* this synchronises with vperfctr_unlink() and itself */
+		spin_lock(&perfctr->owner_lock);
+		tsk = perfctr->owner;
+		if (tsk)
+			get_task_struct(tsk);
+		spin_unlock(&perfctr->owner_lock);
+		if (tsk) {
+			int ret = ptrace_check_attach(tsk, 0);
+			if (ret < 0) {
+				put_task_struct(tsk);
+				return ERR_PTR(ret);
+			}
+		}
+	}
+	return tsk;
+}
+
+static void vperfctr_put_tsk(struct task_struct *tsk)
+{
+	if (tsk && tsk != current)
+		put_task_struct(tsk);
+}
+
+asmlinkage long sys_vperfctr_control(int fd,
+				     const struct vperfctr_control __user *argp,
+				     unsigned int argbytes)
+{
+	struct vperfctr *perfctr;
+	struct task_struct *tsk;
+	int ret;
+
+	perfctr = fd_get_vperfctr(fd);
+	if (IS_ERR(perfctr)) {
+		printk ("sys_vperfctr_control(): fd: %d, perfctr == NULL\n", fd);
+		return PTR_ERR(perfctr);
+	}
+	tsk = vperfctr_get_tsk(perfctr);
+	if (IS_ERR(tsk)) {
+		ret = PTR_ERR(tsk);
+		goto out;
+	}
+
+	// About the arguments:
+	// perfctr: kernel-level 'struct vperfctr'
+	// argp: pointer to a user level 'struct vperfctr_control'
+    // argp: sizeof(struct vperfctr_control)
+	// tsk, the task_struct associated with 'perfctr'
+
+	ret = do_vperfctr_control(perfctr, argp, argbytes, tsk);
+	vperfctr_put_tsk(tsk);
+ out:
+	put_vperfctr(perfctr);
+	return ret;
+}
+
+asmlinkage long sys_vperfctr_unlink(int fd)
+{
+	struct vperfctr *perfctr;
+	struct task_struct *tsk;
+	int ret;
+
+	perfctr = fd_get_vperfctr(fd);
+	if (IS_ERR(perfctr))
+		return PTR_ERR(perfctr);
+	tsk = vperfctr_get_tsk(perfctr);
+	if (IS_ERR(tsk)) {
+		ret = PTR_ERR(tsk);
+		goto out;
+	}
+
+	ret = do_vperfctr_unlink(perfctr, tsk);
+	vperfctr_put_tsk(tsk);
+ out:
+	put_vperfctr(perfctr);
+	return ret;
+}
+
+asmlinkage long sys_vperfctr_iresume(int fd)
+{
+	struct vperfctr *perfctr;
+	struct task_struct *tsk;
+	int ret;
+
+
+	perfctr = fd_get_vperfctr(fd);
+	if (IS_ERR(perfctr)) {
+		return PTR_ERR(perfctr);
+	}
+
+	tsk = vperfctr_get_tsk(perfctr);
+	if (IS_ERR(tsk)) {
+		ret = PTR_ERR(tsk);
+		goto out;
+	}
+
+	ret = do_vperfctr_iresume(perfctr, tsk);
+
+	vperfctr_put_tsk(tsk);
+ out:
+	put_vperfctr(perfctr);
+	return ret;
+}
+
+asmlinkage long sys_vperfctr_read(int fd, unsigned int cmd, void __user *argp, unsigned int argbytes)
+{
+	struct vperfctr *perfctr;
+	struct task_struct *tsk;
+	int ret;
+
+	perfctr = fd_get_vperfctr(fd);
+	if (IS_ERR(perfctr)) {
+		return PTR_ERR(perfctr);
+	}
+	tsk = vperfctr_get_tsk(perfctr);
+	if (IS_ERR(tsk)) {
+		ret = PTR_ERR(tsk);
+		goto out;
+	}
+
+	ret = do_vperfctr_read(perfctr, cmd, argp, argbytes, tsk);
+
+	vperfctr_put_tsk(tsk);
+ out:
+	put_vperfctr(perfctr);
+	return ret;
+}
+
+/****************************************************************
+ *								*
+ * module_init/exit						*
+ *								*
+ ****************************************************************/
+
+int __init vperfctr_init(void)
+{
+	return vperfctrfs_init();
+}
+
+void __exit vperfctr_exit(void)
+{
+	vperfctrfs_exit();
+}
diff --git a/drivers/perfctr/virtual.h b/drivers/perfctr/virtual.h
new file mode 100644
index 0000000..1c7d7a7
--- /dev/null
+++ b/drivers/perfctr/virtual.h
@@ -0,0 +1,25 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/* $Id: virtual.h,v 1.1.2.2 2006-09-28 01:24:17 nphilips Exp $
+ * Virtual per-process performance counters.
+ *
+ * Copyright (C) 1999-2004  Mikael Pettersson
+ */
+
+#ifdef CONFIG_PERFCTR_VIRTUAL
+extern int vperfctr_init(void);
+extern void vperfctr_exit(void);
+#else
+static inline int vperfctr_init(void) { return 0; }
+static inline void vperfctr_exit(void) { }
+#endif
diff --git a/drivers/rapidio/switches/tsi578.c b/drivers/rapidio/switches/tsi578.c
new file mode 100644
index 0000000..91b6bb8
--- /dev/null
+++ b/drivers/rapidio/switches/tsi578.c
@@ -0,0 +1,71 @@
+/*
+ * RapidIO Tsi578 switch support
+ *
+ */
+
+#include <linux/rio.h>
+#include <linux/rio_drv.h>
+#include <linux/rio_ids.h>
+#include "../rio.h"
+#include <linux/delay.h>
+
+#ifdef RMI_SRIO_DEBUG 
+#define Message(a,b...) printk("\nFunction[%s]-Line[%d] \n"a"\n",__FUNCTION__,__LINE__,##b)
+#else
+#define Message(a,b...)
+#endif
+
+static int init_done = 0;
+static int
+tsi578_route_add_entry(struct rio_mport *mport, u16 destid, u8 hopcount, u16 table, u16 route_destid, u8 route_port)
+{
+	u32 offset0 = 0x70;
+	u32 offset1 = 0x74;
+    uint32_t data = 0;
+    Message("route_destid = %#x",route_destid);
+    Message("destid=%d, hopcount=%d, table=%d, route_port=%d",
+            destid,hopcount,table,route_port);
+
+    if(!init_done){
+        rio_mport_read_config_32(mport, 0xffff, 0, 0x10004, &data);
+        data = data & ~(1<<24);
+        rio_mport_write_config_32(mport, 0xffff, 0, 0x10004, data);
+        init_done = 1; 
+    }
+
+	if (table == 0xff) {
+        Message("Writing in to per port route table..");
+        Message("Writing @ Offset %#x and Offset %#x",offset0, offset1);
+        rio_mport_write_config_32(mport, destid, hopcount, offset0, 
+                                    route_destid);
+        rio_mport_write_config_32(mport, destid, hopcount, offset1, 
+                                    route_port);
+	}
+	return 0;
+}
+
+static int
+tsi578_route_get_entry(struct rio_mport *mport, u16 destid, u8 hopcount, u16 table, u16 route_destid, u8 *route_port)
+{
+	u32 offset0 = 0x70;
+	u32 offset1 = 0x74;
+    u32 result = 0;
+    Message("route_destid = %#x",route_destid);
+    Message("destid=%d, hopcount=%d, table=%d, route_port=%d",
+            destid,hopcount,table,route_port);
+
+    if(route_destid > 15)
+       return -1; 
+
+	if (table == 0xff) {
+        Message("Reading from switch..");
+	    rio_mport_write_config_32(mport, destid, hopcount, offset0, 
+                                    route_destid);
+	    rio_mport_read_config_32(mport, destid, hopcount, offset1, &result);
+        *route_port = (u8)result;
+	    return 0;
+	}
+    return -1;
+}
+
+DECLARE_RIO_ROUTE_OPS(RIO_VID_TUNDRA, RIO_DID_TSI578, tsi578_route_add_entry, tsi578_route_get_entry);
diff --git a/drivers/usb/core/usb.c b/drivers/usb/core/usb.c
index c74ba7b..be83a34 100644
--- a/drivers/usb/core/usb.c
+++ b/drivers/usb/core/usb.c
@@ -44,6 +44,10 @@
 
 #include "usb.h"
 
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+extern int avail_mem_above_4G;
+#endif
+
 
 const char *usbcore_name = "usbcore";
 
@@ -941,6 +945,10 @@ int usb_disabled(void)
 }
 EXPORT_SYMBOL_GPL(usb_disabled);
 
+#ifdef CONFIG_RMI_PHOENIX
+extern int force_usb;
+#endif
+
 /*
  * Notifications of device and interface registration
  */
@@ -1006,6 +1014,19 @@ static void usb_debugfs_cleanup(void)
 static int __init usb_init(void)
 {
 	int retval;
+
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+    if (avail_mem_above_4G && !force_usb) {
+        printk("------------------------------------------------\n");
+        printk("[USB]: Running 64-bit Linux with DRAM above 4G. \n");
+        printk("     : HW Support for DMA >32-bit Un-available. \n");
+        printk("     : Disabling USB, to force enable, use      \n");
+        printk("     : cmdline option 'forceusb'\n");
+        printk("------------------------------------------------\n");
+        nousb=1;
+    }
+#endif
+
 	if (nousb) {
 		pr_info("%s: USB support disabled\n", usbcore_name);
 		return 0;
diff --git a/drivers/usb/host/ehci-hcd.c b/drivers/usb/host/ehci-hcd.c
index 987db27..6d41935 100644
--- a/drivers/usb/host/ehci-hcd.c
+++ b/drivers/usb/host/ehci-hcd.c
@@ -1,3 +1,14 @@
+/************************************************************************
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: Added support hooks for RMI XLS USB Controller
+
+ *****************************#RMI_1#************************************/
+
 /*
  * Enhanced Host Controller Interface (EHCI) driver for USB.
  *
@@ -51,6 +62,10 @@
 #include <asm/firmware.h>
 #endif
 
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/sim.h>
+#endif
+
 /*-------------------------------------------------------------------------*/
 
 /*
@@ -1315,6 +1330,11 @@ MODULE_LICENSE ("GPL");
 #define	PLATFORM_DRIVER		ixp4xx_ehci_driver
 #endif
 
+#ifdef CONFIG_RMI_PHOENIX
+#include "ehci-xls.c"
+#define  PLATFORM_DRIVER      ehci_xls_driver
+#endif
+
 #ifdef CONFIG_USB_W90X900_EHCI
 #include "ehci-w90x900.c"
 #define	PLATFORM_DRIVER		ehci_hcd_w90x900_driver
@@ -1429,6 +1449,10 @@ static int __init ehci_hcd_init(void)
 #endif
 
 #ifdef PLATFORM_DRIVER
+#ifdef CONFIG_RMI_PHOENIX
+    /* On the XLS, use the internal USB Controller */
+    if (is_xls())
+#endif
 	retval = platform_driver_register(&PLATFORM_DRIVER);
 	if (retval < 0)
 		goto clean0;
@@ -1499,6 +1523,10 @@ static void __exit ehci_hcd_cleanup(void)
 	platform_driver_unregister(&OF_PLATFORM_DRIVER);
 #endif
 #ifdef PLATFORM_DRIVER
+#ifdef CONFIG_RMI_PHOENIX
+    /* On the XLS, use the internal USB Controller */
+    if (is_xls())
+#endif 
 	platform_driver_unregister(&PLATFORM_DRIVER);
 #endif
 #ifdef PCI_DRIVER
diff --git a/drivers/usb/host/ohci-hcd.c b/drivers/usb/host/ohci-hcd.c
index 235171f..823be94 100644
--- a/drivers/usb/host/ohci-hcd.c
+++ b/drivers/usb/host/ohci-hcd.c
@@ -1,3 +1,14 @@
+/************************************************************************
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+    
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: Added support hooks for RMI XLS USB Controller
+
+ *****************************#RMI_1#************************************/
+
 /*
  * Open Host Controller Interface (OHCI) driver for USB.
  *
@@ -46,6 +57,10 @@
 #include <asm/byteorder.h>
 
 
+#ifdef CONFIG_RMI_PHOENIX
+#include <asm/rmi/sim.h>
+#endif
+
 #define DRIVER_AUTHOR "Roman Weissgaerber, David Brownell"
 #define DRIVER_DESC "USB 1.1 'Open' Host Controller (OHCI) Driver"
 
@@ -994,6 +1009,11 @@ MODULE_LICENSE ("GPL");
 #define PCI_DRIVER		ohci_pci_driver
 #endif
 
+#ifdef CONFIG_RMI_PHOENIX
+#include "ohci-xls.c"
+#define PLATFORM_DRIVER     ohci_xls_driver
+#endif
+
 #if defined(CONFIG_ARCH_SA1100) && defined(CONFIG_SA1111)
 #include "ohci-sa1111.c"
 #define SA1111_DRIVER		ohci_hcd_sa1111_driver
@@ -1160,6 +1180,10 @@ static int __init ohci_hcd_mod_init(void)
 #endif
 
 #ifdef PLATFORM_DRIVER
+#ifdef CONFIG_RMI_PHOENIX
+    /* On the XLS, use the internal USB Controller */
+    if (is_xls())
+#endif
 	retval = platform_driver_register(&PLATFORM_DRIVER);
 	if (retval < 0)
 		goto error_platform;
@@ -1288,6 +1312,9 @@ static void __exit ohci_hcd_mod_exit(void)
 	platform_driver_unregister(&OF_PLATFORM_DRIVER);
 #endif
 #ifdef PLATFORM_DRIVER
+#ifdef CONFIG_RMI_PHOENIX
+    if (is_xls())
+#endif
 	platform_driver_unregister(&PLATFORM_DRIVER);
 #endif
 #ifdef OMAP3_PLATFORM_DRIVER
diff --git a/drivers/watchdog/Kconfig b/drivers/watchdog/Kconfig
index 257acf3..80fc64c 100644
--- a/drivers/watchdog/Kconfig
+++ b/drivers/watchdog/Kconfig
@@ -1042,6 +1042,14 @@ config LANTIQ_WDT
 	help
 	  Hardware driver for the Lantiq SoC Watchdog Timer.
 
+config RMI_WATCHDOG
+        tristate "RMI XL* Hardware Watchdog"
+        depends on WATCHDOG && RMI_PHOENIX
+        help
+          Hardware driver for the XL* watchdog. This is a watchdog timer
+          that will reboot the machine after a 60 second timer expired
+          and no process has written to /dev/watchdog during that time.
+
 # PARISC Architecture
 
 # POWERPC Architecture
diff --git a/drivers/watchdog/phoenix_wdt.c b/drivers/watchdog/phoenix_wdt.c
new file mode 100644
index 0000000..bb0fc45
--- /dev/null
+++ b/drivers/watchdog/phoenix_wdt.c
@@ -0,0 +1,301 @@
+/*
+ * drivers/char/watchdog/phoenix_wdt.c
+ *
+ * Watchdog driver for RMI processors
+ *
+ * Adapted from the IXP4xx watchdog driver by Lennert Buytenhek.
+ * The original version carries these notices:
+ *
+ * Author: Deepak Saxena <dsaxena@plexity.net>
+ *
+ * Copyright 2004 (c) MontaVista, Software, Inc.
+ * Based on sa1100 driver, Copyright (C) 2000 Oleg Drokin <green@crimea.edu>
+ *
+ * This file is licensed under  the terms of the GNU General Public
+ * License version 2. This program is licensed "as is" without any
+ * warranty of any kind, whether express or implied.
+ */
+
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/miscdevice.h>
+#include <linux/watchdog.h>
+#include <linux/init.h>
+#include <linux/bitops.h>
+#include <linux/jiffies.h>
+#include <linux/reboot.h>
+
+#include <asm/uaccess.h>
+#include <asm/rmi/sim.h>
+#include <linux/smp_lock.h>
+
+static int nowayout = WATCHDOG_NOWAYOUT;
+static unsigned int heartbeat = 60;	/* (secs) Default is 1 minute */
+static unsigned long phoenix_wdt_status;
+
+#define	WDT_IN_USE		0
+#define	WDT_OK_TO_CLOSE		1
+
+static unsigned long phoenix_wdt_tick_rate;
+
+static void
+phoenix_wdt_enable(void)
+{
+        phoenix_reg_t *mmio;
+	printk("[%s] -\n", __FUNCTION__);
+        mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+
+        /* The WatchDog timer requires configuration before it can be used. The
+           WatchDog Max Value register contains the value of the counter that
+           will be reloaded every time it starts counting.
+           WatchDogMaxValue{0,1} = 0.1 * 66Mhz */
+
+        phoenix_write_reg(mmio, 0x08, heartbeat * 66666666);
+        phoenix_write_reg(mmio, 0x09, 0x00000000);
+
+        /* The Heartbeat Register maintains a record of which threads have
+           acknowledged with a heartbeat. The Heartbeat Mask register
+           quantifies which threads need to acknowledge. If all the required
+           Heartbeats are not received before the Timer reaches 0, an
+           interrupt will be generated.
+           WatchDogMask{0,1} = 0x00000000ffffffff */
+
+        phoenix_write_reg(mmio, 0x0a, smp_boot.online_map);
+        phoenix_write_reg(mmio, 0x0b, 0x00000000);
+
+        /* PIC_IRT_ENTRY_WATCHDOG = {Interrupt Delivery CPU Mask[31:0]=1
+                                     Valid[63]=1 Trigger[62]=0
+                                     Polarity[61]=0 NMI[39]=1
+                                     Scheduling[38]=1 Interrupt
+                                     Vector[35:32]=8} */
+
+        phoenix_write_reg(mmio, 0x40, 0x00000001); /* XXX: first cpu */
+        phoenix_write_reg(mmio, 0x80, 0x800000c8);
+
+        /* Watchdog Enable[0]=1 : */
+
+        phoenix_write_reg(mmio, 0x00, phoenix_read_reg(mmio, 0x00) | 1);
+}
+
+static void
+phoenix_wdt_disable(void)
+{
+	phoenix_reg_t *mmio;
+	printk("[%s] -\n", __FUNCTION__);
+	mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+
+	/* Watchdog Enable[0]=1 : */
+
+	phoenix_write_reg(mmio, 0x00, phoenix_read_reg(mmio, 0x00) & ~1);
+}
+
+static void
+phoenix_wdt_keepalive(void)
+{
+        phoenix_reg_t *mmio;
+        printk("[%s] -\n", __FUNCTION__);
+        mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+
+	/* ack the watchdog on the first cpu */
+
+	phoenix_write_reg(mmio, 0x0c, 1);
+
+	/* other cpu ack the watchdog in their timer interrupt handler */
+}
+
+static int
+phoenix_wdt_open(struct inode *inode, struct file *file)
+{
+	printk("[%s] -\n", __FUNCTION__);
+
+	if (test_and_set_bit(WDT_IN_USE, &phoenix_wdt_status))
+		return -EBUSY;
+
+	clear_bit(WDT_OK_TO_CLOSE, &phoenix_wdt_status);
+
+	phoenix_wdt_enable();
+
+	return nonseekable_open(inode, file);
+}
+
+static ssize_t
+phoenix_wdt_write(struct file *file, const char *data, size_t len, loff_t *ppos)
+{
+	printk("[%s] - len %d\n", __FUNCTION__, len);
+
+	if (len) {
+		if (!nowayout) {
+			size_t i;
+
+			clear_bit(WDT_OK_TO_CLOSE, &phoenix_wdt_status);
+
+			for (i = 0; i != len; i++) {
+				char c;
+
+				if (get_user(c, data + i))
+					return -EFAULT;
+				if (c == 'V')
+					set_bit(WDT_OK_TO_CLOSE, &phoenix_wdt_status);
+			}
+		}
+		phoenix_wdt_keepalive();
+	}
+
+	return len;
+}
+
+
+static struct watchdog_info ident = {
+	.options	= WDIOF_MAGICCLOSE | WDIOF_SETTIMEOUT |
+				WDIOF_KEEPALIVEPING,
+	.identity	= "RMI Watchdog",
+};
+
+int
+phoenix_wdt_ioctl(struct inode *inode, struct file *file, unsigned int cmd,
+			unsigned long arg)
+{
+	int ret = -ENOTTY;
+	int time;
+
+	printk("[%s] - cmd %x arg %lx\n", __FUNCTION__, cmd, arg);
+	switch (cmd) {
+	case WDIOC_GETSUPPORT:
+		ret = copy_to_user((struct watchdog_info *)arg, &ident,
+				   sizeof(ident)) ? -EFAULT : 0;
+		break;
+
+	case WDIOC_GETSTATUS:
+		ret = put_user(0, (int *)arg);
+		break;
+
+	case WDIOC_GETBOOTSTATUS:
+		ret = put_user(0, (int *)arg);
+		break;
+
+	case WDIOC_SETTIMEOUT:
+		ret = get_user(time, (int *)arg);
+		if (ret)
+			break;
+
+		if (time <= 0 || time > 60) {
+			ret = -EINVAL;
+			break;
+		}
+
+		heartbeat = time;
+		phoenix_wdt_keepalive();
+		/* Fall through */
+
+	case WDIOC_GETTIMEOUT:
+		ret = put_user(heartbeat, (int *)arg);
+		break;
+
+	case WDIOC_KEEPALIVE:
+		phoenix_wdt_enable();
+		ret = 0;
+		break;
+	}
+
+	return ret;
+}
+
+long phoenix_wdt_compat_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
+{
+	unsigned long ret = -1;
+  	lock_kernel();
+	ret = phoenix_wdt_ioctl(NULL, filp, cmd, arg);
+	unlock_kernel();
+	if(ret){
+		printk("%s: ioctl error\n", __FUNCTION__);
+		return -EINVAL;
+	}
+	return ret;
+}
+
+static int
+phoenix_wdt_release(struct inode *inode, struct file *file)
+{
+	printk("[%s] -\n", __FUNCTION__);
+
+	if (test_bit(WDT_OK_TO_CLOSE, &phoenix_wdt_status)) {
+		phoenix_wdt_disable();
+	} else {
+		printk(KERN_CRIT "WATCHDOG: Device closed unexpectedly - "
+					"timer will not stop\n");
+	}
+	clear_bit(WDT_IN_USE, &phoenix_wdt_status);
+	clear_bit(WDT_OK_TO_CLOSE, &phoenix_wdt_status);
+
+	return 0;
+}
+
+static int phoenix_notify_sys(struct notifier_block *this, unsigned long code, void *unused)
+{
+        if (code == SYS_DOWN || code == SYS_HALT)
+                phoenix_wdt_disable();         /* Turn the WDT off */
+
+        return NOTIFY_DONE;
+}
+
+static const struct file_operations phoenix_wdt_fops =
+{
+	.owner		= THIS_MODULE,
+	.llseek		= no_llseek,
+	.write		= phoenix_wdt_write,
+	.ioctl		= phoenix_wdt_ioctl,
+	.compat_ioctl   = phoenix_wdt_compat_ioctl,
+	.open		= phoenix_wdt_open,
+	.release	= phoenix_wdt_release,
+};
+
+static struct miscdevice phoenix_wdt_miscdev =
+{
+	.minor		= WATCHDOG_MINOR,
+	.name		= "watchdog",
+	.fops		= &phoenix_wdt_fops,
+};
+
+static struct notifier_block phoenix_notifier = {
+        .notifier_call = phoenix_notify_sys,
+};
+
+static int __init phoenix_wdt_init(void)
+{
+	int ret;
+	printk("[%s] -\n", __FUNCTION__);
+	phoenix_wdt_tick_rate = HZ;
+        ret = register_reboot_notifier(&phoenix_notifier);
+        if (ret) {
+                printk(KERN_ERR "cannot register reboot notifier (err=%d)\n",
+                        ret);
+                return ret;
+        }
+	return misc_register(&phoenix_wdt_miscdev);
+}
+
+static void __exit phoenix_wdt_exit(void)
+{
+	printk("[%s] -\n", __FUNCTION__);
+	misc_deregister(&phoenix_wdt_miscdev);
+	unregister_reboot_notifier(&phoenix_notifier);
+}
+
+module_init(phoenix_wdt_init);
+module_exit(phoenix_wdt_exit);
+
+MODULE_AUTHOR("RMI Corp.">);
+MODULE_DESCRIPTION("RMI Processors Watchdog");
+
+module_param(heartbeat, int, 0);
+MODULE_PARM_DESC(heartbeat, "Watchdog heartbeat in seconds (default 60s)");
+
+module_param(nowayout, int, 0);
+MODULE_PARM_DESC(nowayout, "Watchdog cannot be stopped once started");
+
+MODULE_LICENSE("GPL");
+MODULE_ALIAS_MISCDEV(WATCHDOG_MINOR);
+
diff --git a/fs/Makefile b/fs/Makefile
index 3a08584..d07f06d 100644
--- a/fs/Makefile
+++ b/fs/Makefile
@@ -39,6 +39,7 @@ obj-$(CONFIG_BINFMT_MISC)	+= binfmt_misc.o
 obj-y				+= binfmt_script.o
 
 obj-$(CONFIG_BINFMT_ELF)	+= binfmt_elf.o
+#obj-$(CONFIG_BINFMT_ELF)    += coredump_elf.o
 obj-$(CONFIG_COMPAT_BINFMT_ELF)	+= compat_binfmt_elf.o
 obj-$(CONFIG_BINFMT_ELF_FDPIC)	+= binfmt_elf_fdpic.o
 obj-$(CONFIG_BINFMT_SOM)	+= binfmt_som.o
diff --git a/fs/coredump_elf.c b/fs/coredump_elf.c
new file mode 100644
index 0000000..84955aa
--- /dev/null
+++ b/fs/coredump_elf.c
@@ -0,0 +1,679 @@
+/*
+ * linux/fs/binfmt_elf.c
+ *
+ * These are the functions used to load ELF format executables as used
+ * on SVr4 machines.  Information on the format may be found in the book
+ * "UNIX SYSTEM V RELEASE 4 Programmers Guide: Ansi C and Programming Support
+ * Tools".
+ *
+ * Copyright 1993, 1994: Eric Youngdale (ericy@cais.com).
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/stat.h>
+#include <linux/time.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/a.out.h>
+#include <linux/errno.h>
+#include <linux/signal.h>
+#include <linux/binfmts.h>
+#include <linux/string.h>
+#include <linux/file.h>
+#include <linux/fcntl.h>
+#include <linux/ptrace.h>
+#include <linux/slab.h>
+#include <linux/shm.h>
+#include <linux/personality.h>
+#include <linux/elfcore.h>
+#include <linux/init.h>
+#include <linux/highuid.h>
+#include <linux/smp.h>
+#include <linux/smp_lock.h>
+#include <linux/compiler.h>
+#include <linux/highmem.h>
+#include <linux/pagemap.h>
+#include <linux/security.h>
+#include <linux/syscalls.h>
+#include <linux/random.h>
+#include <linux/elf.h>
+#include <asm/uaccess.h>
+#include <asm/param.h>
+#include <asm/page.h>
+
+
+#ifndef ELF_EXEC_PAGESIZE
+
+#if ELF_EXEC_PAGESIZE > PAGE_SIZE
+#define ELF_MIN_ALIGN	ELF_EXEC_PAGESIZE
+#else
+#define ELF_MIN_ALIGN	PAGE_SIZE
+#endif
+
+#endif
+
+#ifndef ELF_CORE_EFLAGS
+#define ELF_CORE_EFLAGS	0
+#endif
+
+/*
+ * Note that some platforms still use traditional core dumps and not
+ * the ELF core dump.  Each platform can select it as appropriate.
+ */
+#if defined(USE_ELF_CORE_DUMP) && defined(CONFIG_ELF_CORE)
+
+/*
+ * ELF core dumper
+ *
+ * Modelled on fs/exec.c:aout_core_dump()
+ * Jeremy Fitzhardinge <jeremy@sw.oz.au>
+ */
+/*
+ * These are the only things you should do on a core-file: use only these
+ * functions to write out all the necessary info.
+ */
+static int dump_write(struct file *file, const void *addr, int nr)
+{
+	return file->f_op->write(file, addr, nr, &file->f_pos) == nr;
+}
+
+static int dump_seek(struct file *file, loff_t off)
+{
+	if (file->f_op->llseek && file->f_op->llseek != no_llseek) {
+		if (file->f_op->llseek(file, off, SEEK_CUR) < 0)
+			return 0;
+	} else {
+		char *buf = (char *)get_zeroed_page(GFP_KERNEL);
+		if (!buf)
+			return 0;
+		while (off > 0) {
+			unsigned long n = off;
+			if (n > PAGE_SIZE)
+				n = PAGE_SIZE;
+			if (!dump_write(file, buf, n))
+				return 0;
+			off -= n;
+		}
+		free_page((unsigned long)buf);
+	}
+	return 1;
+}
+
+/*
+ * Decide whether a segment is worth dumping; default is yes to be
+ * sure (missing info is worse than too much; etc).
+ * Personally I'd include everything, and use the coredump limit...
+ *
+ * I think we should skip something. But I am not sure how. H.J.
+ */
+static int maydump(struct vm_area_struct *vma)
+{
+	/* The vma can be set up to tell us the answer directly.  */
+	if (vma->vm_flags & VM_ALWAYSDUMP)
+		return 1;
+
+	/* Do not dump I/O mapped devices or special mappings */
+	if (vma->vm_flags & (VM_IO | VM_RESERVED))
+		return 0;
+
+	/* Dump shared memory only if mapped from an anonymous file. */
+	if (vma->vm_flags & VM_SHARED)
+		return vma->vm_file->f_path.dentry->d_inode->i_nlink == 0;
+
+	/* If it hasn't been written to, don't write it out */
+	if (!vma->anon_vma)
+		return 0;
+
+	return 1;
+}
+
+/* An ELF note in memory */
+struct memelfnote
+{
+	const char *name;
+	int type;
+	unsigned int datasz;
+	void *data;
+};
+
+static int notesize(struct memelfnote *en)
+{
+	int sz;
+
+	sz = sizeof(struct elf_note);
+	sz += roundup(strlen(en->name) + 1, 4);
+	sz += roundup(en->datasz, 4);
+
+	return sz;
+}
+
+#define DUMP_WRITE(addr, nr, foffset)	\
+	do { if (!dump_write(file, (addr), (nr))) return 0; *foffset += (nr); } while(0)
+
+static int alignfile(struct file *file, loff_t *foffset)
+{
+	static const char buf[4] = { 0, };
+	DUMP_WRITE(buf, roundup(*foffset, 4) - *foffset, foffset);
+	return 1;
+}
+
+static int writenote(struct memelfnote *men, struct file *file,
+			loff_t *foffset)
+{
+	struct elf_note en;
+	en.n_namesz = strlen(men->name) + 1;
+	en.n_descsz = men->datasz;
+	en.n_type = men->type;
+
+	DUMP_WRITE(&en, sizeof(en), foffset);
+	DUMP_WRITE(men->name, en.n_namesz, foffset);
+	if (!alignfile(file, foffset))
+		return 0;
+	DUMP_WRITE(men->data, men->datasz, foffset);
+	if (!alignfile(file, foffset))
+		return 0;
+
+	return 1;
+}
+#undef DUMP_WRITE
+
+#define DUMP_WRITE(addr, nr)	\
+	if ((size += (nr)) > limit || !dump_write(file, (addr), (nr))) \
+		goto end_coredump;
+#define DUMP_SEEK(off)	\
+	if (!dump_seek(file, (off))) \
+		goto end_coredump;
+
+static void fill_elf_header(struct elfhdr *elf, int segs)
+{
+	memcpy(elf->e_ident, ELFMAG, SELFMAG);
+	elf->e_ident[EI_CLASS] = ELF_CLASS;
+	elf->e_ident[EI_DATA] = ELF_DATA;
+	elf->e_ident[EI_VERSION] = EV_CURRENT;
+	elf->e_ident[EI_OSABI] = ELF_OSABI;
+	memset(elf->e_ident+EI_PAD, 0, EI_NIDENT-EI_PAD);
+
+	elf->e_type = ET_CORE;
+	elf->e_machine = ELF_ARCH;
+	elf->e_version = EV_CURRENT;
+	elf->e_entry = 0;
+	elf->e_phoff = sizeof(struct elfhdr);
+	elf->e_shoff = 0;
+	elf->e_flags = ELF_CORE_EFLAGS;
+	elf->e_ehsize = sizeof(struct elfhdr);
+	elf->e_phentsize = sizeof(struct elf_phdr);
+	elf->e_phnum = segs;
+	elf->e_shentsize = 0;
+	elf->e_shnum = 0;
+	elf->e_shstrndx = 0;
+	return;
+}
+
+static void fill_elf_note_phdr(struct elf_phdr *phdr, int sz, loff_t offset)
+{
+	phdr->p_type = PT_NOTE;
+	phdr->p_offset = offset;
+	phdr->p_vaddr = 0;
+	phdr->p_paddr = 0;
+	phdr->p_filesz = sz;
+	phdr->p_memsz = 0;
+	phdr->p_flags = 0;
+	phdr->p_align = 0;
+	return;
+}
+
+static void fill_note(struct memelfnote *note, const char *name, int type, 
+		unsigned int sz, void *data)
+{
+	note->name = name;
+	note->type = type;
+	note->datasz = sz;
+	note->data = data;
+	return;
+}
+
+/*
+ * fill up all the fields in prstatus from the given task struct, except
+ * registers which need to be filled up separately.
+ */
+static void fill_prstatus(struct elf_prstatus *prstatus,
+		struct task_struct *p, long signr)
+{
+	prstatus->pr_info.si_signo = prstatus->pr_cursig = signr;
+	prstatus->pr_sigpend = p->pending.signal.sig[0];
+	prstatus->pr_sighold = p->blocked.sig[0];
+	prstatus->pr_pid = p->pid;
+	prstatus->pr_ppid = p->parent->pid;
+	prstatus->pr_pgrp = task_pgrp_nr(p);
+	prstatus->pr_sid = task_session_nr(p);
+	if (thread_group_leader(p)) {
+		/*
+		 * This is the record for the group leader.  Add in the
+		 * cumulative times of previous dead threads.  This total
+		 * won't include the time of each live thread whose state
+		 * is included in the core dump.  The final total reported
+		 * to our parent process when it calls wait4 will include
+		 * those sums as well as the little bit more time it takes
+		 * this and each other thread to finish dying after the
+		 * core dump synchronization phase.
+		 */
+		cputime_to_timeval(cputime_add(p->utime, p->signal->utime),
+				   &prstatus->pr_utime);
+		cputime_to_timeval(cputime_add(p->stime, p->signal->stime),
+				   &prstatus->pr_stime);
+	} else {
+		cputime_to_timeval(p->utime, &prstatus->pr_utime);
+		cputime_to_timeval(p->stime, &prstatus->pr_stime);
+	}
+	cputime_to_timeval(p->signal->cutime, &prstatus->pr_cutime);
+	cputime_to_timeval(p->signal->cstime, &prstatus->pr_cstime);
+}
+
+static int fill_psinfo(struct elf_prpsinfo *psinfo, struct task_struct *p,
+		       struct mm_struct *mm)
+{
+	unsigned int i, len;
+	
+	/* first copy the parameters from user space */
+	memset(psinfo, 0, sizeof(struct elf_prpsinfo));
+
+	len = mm->arg_end - mm->arg_start;
+	if (len >= ELF_PRARGSZ)
+		len = ELF_PRARGSZ-1;
+	if (copy_from_user(&psinfo->pr_psargs,
+		           (const char __user *)mm->arg_start, len))
+		return -EFAULT;
+	for(i = 0; i < len; i++)
+		if (psinfo->pr_psargs[i] == 0)
+			psinfo->pr_psargs[i] = ' ';
+	psinfo->pr_psargs[len] = 0;
+
+	psinfo->pr_pid = p->pid;
+	psinfo->pr_ppid = p->parent->pid;
+	psinfo->pr_pgrp = task_pgrp_nr(p);
+	psinfo->pr_sid = task_session_nr(p);
+
+	i = p->state ? ffz(~p->state) + 1 : 0;
+	psinfo->pr_state = i;
+	psinfo->pr_sname = (i > 5) ? '.' : "RSDTZW"[i];
+	psinfo->pr_zomb = psinfo->pr_sname == 'Z';
+	psinfo->pr_nice = task_nice(p);
+	psinfo->pr_flag = p->flags;
+	SET_UID(psinfo->pr_uid, p->uid);
+	SET_GID(psinfo->pr_gid, p->gid);
+	strncpy(psinfo->pr_fname, p->comm, sizeof(psinfo->pr_fname));
+	
+	return 0;
+}
+
+/* Here is the structure in which status of each thread is captured. */
+struct elf_thread_status
+{
+	struct list_head list;
+	struct elf_prstatus prstatus;	/* NT_PRSTATUS */
+	elf_fpregset_t fpu;		/* NT_PRFPREG */
+	struct task_struct *thread;
+#ifdef ELF_CORE_COPY_XFPREGS
+	elf_fpxregset_t xfpu;		/* NT_PRXFPREG */
+#endif
+	struct memelfnote notes[3];
+	int num_notes;
+};
+
+/*
+ * In order to add the specific thread information for the elf file format,
+ * we need to keep a linked list of every threads pr_status and then create
+ * a single section for them in the final core file.
+ */
+static int elf_dump_thread_status(long signr, struct elf_thread_status *t)
+{
+	int sz = 0;
+	struct task_struct *p = t->thread;
+	t->num_notes = 0;
+
+	fill_prstatus(&t->prstatus, p, signr);
+	elf_core_copy_task_regs(p, &t->prstatus.pr_reg);	
+	
+	fill_note(&t->notes[0], "CORE", NT_PRSTATUS, sizeof(t->prstatus),
+		  &(t->prstatus));
+	t->num_notes++;
+	sz += notesize(&t->notes[0]);
+
+	if ((t->prstatus.pr_fpvalid = elf_core_copy_task_fpregs(p, NULL,
+								&t->fpu))) {
+		fill_note(&t->notes[1], "CORE", NT_PRFPREG, sizeof(t->fpu),
+			  &(t->fpu));
+		t->num_notes++;
+		sz += notesize(&t->notes[1]);
+	}
+
+#ifdef ELF_CORE_COPY_XFPREGS
+	if (elf_core_copy_task_xfpregs(p, &t->xfpu)) {
+		fill_note(&t->notes[2], "LINUX", NT_PRXFPREG, sizeof(t->xfpu),
+			  &t->xfpu);
+		t->num_notes++;
+		sz += notesize(&t->notes[2]);
+	}
+#endif	
+	return sz;
+}
+
+static struct vm_area_struct *first_vma(struct task_struct *tsk,
+					struct vm_area_struct *gate_vma)
+{
+	struct vm_area_struct *ret = tsk->mm->mmap;
+
+	if (ret)
+		return ret;
+	return gate_vma;
+}
+/*
+ * Helper function for iterating across a vma list.  It ensures that the caller
+ * will visit `gate_vma' prior to terminating the search.
+ */
+static struct vm_area_struct *next_vma(struct vm_area_struct *this_vma,
+					struct vm_area_struct *gate_vma)
+{
+	struct vm_area_struct *ret;
+
+	ret = this_vma->vm_next;
+	if (ret)
+		return ret;
+	if (this_vma == gate_vma)
+		return NULL;
+	return gate_vma;
+}
+
+/*
+ * Actual dumper
+ *
+ * This is a two-pass process; first we find the offsets of the bits,
+ * and then they are actually written out.  If we run out of core limit
+ * we just truncate.
+ */
+int btlb_elf_core_dump(long signr, struct pt_regs *regs, struct file *file)
+{
+#define	NUM_NOTES	6
+	int has_dumped = 0;
+	mm_segment_t fs;
+	int segs;
+	size_t size = 0;
+	int i;
+	struct vm_area_struct *vma, *gate_vma;
+	struct elfhdr *elf = NULL;
+	loff_t offset = 0, dataoff, foffset;
+	unsigned long limit = current->signal->rlim[RLIMIT_CORE].rlim_cur;
+	int numnote;
+	struct memelfnote *notes = NULL;
+	struct elf_prstatus *prstatus = NULL;	/* NT_PRSTATUS */
+	struct elf_prpsinfo *psinfo = NULL;	/* NT_PRPSINFO */
+ 	struct task_struct *g, *p;
+ 	LIST_HEAD(thread_list);
+ 	struct list_head *t;
+	elf_fpregset_t *fpu = NULL;
+#ifdef ELF_CORE_COPY_XFPREGS
+	elf_fpxregset_t *xfpu = NULL;
+#endif
+	int thread_status_size = 0;
+	elf_addr_t *auxv;
+
+	/*
+	 * We no longer stop all VM operations.
+	 * 
+	 * This is because those proceses that could possibly change map_count
+	 * or the mmap / vma pages are now blocked in do_exit on current
+	 * finishing this core dump.
+	 *
+	 * Only ptrace can touch these memory addresses, but it doesn't change
+	 * the map_count or the pages allocated. So no possibility of crashing
+	 * exists while dumping the mm->vm_next areas to the core file.
+	 */
+  
+	/* alloc memory for large data structures: too large to be on stack */
+	elf = kmalloc(sizeof(*elf), GFP_KERNEL);
+	if (!elf)
+		goto cleanup;
+	prstatus = kmalloc(sizeof(*prstatus), GFP_KERNEL);
+	if (!prstatus)
+		goto cleanup;
+	psinfo = kmalloc(sizeof(*psinfo), GFP_KERNEL);
+	if (!psinfo)
+		goto cleanup;
+	notes = kmalloc(NUM_NOTES * sizeof(struct memelfnote), GFP_KERNEL);
+	if (!notes)
+		goto cleanup;
+	fpu = kmalloc(sizeof(*fpu), GFP_KERNEL);
+	if (!fpu)
+		goto cleanup;
+#ifdef ELF_CORE_COPY_XFPREGS
+	xfpu = kmalloc(sizeof(*xfpu), GFP_KERNEL);
+	if (!xfpu)
+		goto cleanup;
+#endif
+
+	if (signr) {
+		struct elf_thread_status *tmp;
+		rcu_read_lock();
+		do_each_thread(g,p)
+			if (current->mm == p->mm && current != p) {
+				tmp = kzalloc(sizeof(*tmp), GFP_ATOMIC);
+				if (!tmp) {
+					rcu_read_unlock();
+					goto cleanup;
+				}
+				tmp->thread = p;
+				list_add(&tmp->list, &thread_list);
+			}
+		while_each_thread(g,p);
+		rcu_read_unlock();
+		list_for_each(t, &thread_list) {
+			struct elf_thread_status *tmp;
+			int sz;
+
+			tmp = list_entry(t, struct elf_thread_status, list);
+			sz = elf_dump_thread_status(signr, tmp);
+			thread_status_size += sz;
+		}
+	}
+	/* now collect the dump for the current */
+	memset(prstatus, 0, sizeof(*prstatus));
+	fill_prstatus(prstatus, current, signr);
+	elf_core_copy_regs(&prstatus->pr_reg, regs);
+	
+	segs = current->mm->map_count;
+#ifdef ELF_CORE_EXTRA_PHDRS
+	segs += ELF_CORE_EXTRA_PHDRS;
+#endif
+
+	gate_vma = get_gate_vma(current);
+	if (gate_vma != NULL)
+		segs++;
+
+	/* Set up header */
+	fill_elf_header(elf, segs + 1);	/* including notes section */
+
+	has_dumped = 1;
+	current->flags |= PF_DUMPCORE;
+
+	/*
+	 * Set up the notes in similar form to SVR4 core dumps made
+	 * with info from their /proc.
+	 */
+
+	fill_note(notes + 0, "CORE", NT_PRSTATUS, sizeof(*prstatus), prstatus);
+	fill_psinfo(psinfo, current->group_leader, current->mm);
+	fill_note(notes + 1, "CORE", NT_PRPSINFO, sizeof(*psinfo), psinfo);
+	
+	numnote = 2;
+
+	auxv = (elf_addr_t *)current->mm->saved_auxv;
+
+	i = 0;
+	do
+		i += 2;
+	while (auxv[i - 2] != AT_NULL);
+	fill_note(&notes[numnote++], "CORE", NT_AUXV,
+		  i * sizeof(elf_addr_t), auxv);
+
+  	/* Try to dump the FPU. */
+	if ((prstatus->pr_fpvalid =
+	     elf_core_copy_task_fpregs(current, regs, fpu)))
+		fill_note(notes + numnote++,
+			  "CORE", NT_PRFPREG, sizeof(*fpu), fpu);
+#ifdef ELF_CORE_COPY_XFPREGS
+	if (elf_core_copy_task_xfpregs(current, xfpu))
+		fill_note(notes + numnote++,
+			  "LINUX", NT_PRXFPREG, sizeof(*xfpu), xfpu);
+#endif	
+  
+	fs = get_fs();
+	set_fs(KERNEL_DS);
+
+	DUMP_WRITE(elf, sizeof(*elf));
+	offset += sizeof(*elf);				/* Elf header */
+	offset += (segs + 1) * sizeof(struct elf_phdr); /* Program headers */
+	foffset = offset;
+
+	/* Write notes phdr entry */
+	{
+		struct elf_phdr phdr;
+		int sz = 0;
+
+		for (i = 0; i < numnote; i++)
+			sz += notesize(notes + i);
+		
+		sz += thread_status_size;
+
+#ifdef ELF_CORE_WRITE_EXTRA_NOTES
+		sz += ELF_CORE_EXTRA_NOTES_SIZE;
+#endif
+
+		fill_elf_note_phdr(&phdr, sz, offset);
+		offset += sz;
+		DUMP_WRITE(&phdr, sizeof(phdr));
+	}
+
+	dataoff = offset = roundup(offset, ELF_EXEC_PAGESIZE);
+
+	/* Write program headers for segments dump */
+	for (vma = first_vma(current, gate_vma); vma != NULL;
+			vma = next_vma(vma, gate_vma)) {
+		struct elf_phdr phdr;
+		size_t sz;
+
+		sz = vma->vm_end - vma->vm_start;
+
+		phdr.p_type = PT_LOAD;
+		phdr.p_offset = offset;
+		phdr.p_vaddr = vma->vm_start;
+		phdr.p_paddr = 0;
+		phdr.p_filesz = maydump(vma) ? sz : 0;
+		phdr.p_memsz = sz;
+		offset += phdr.p_filesz;
+		phdr.p_flags = vma->vm_flags & VM_READ ? PF_R : 0;
+		if (vma->vm_flags & VM_WRITE)
+			phdr.p_flags |= PF_W;
+		if (vma->vm_flags & VM_EXEC)
+			phdr.p_flags |= PF_X;
+		phdr.p_align = ELF_EXEC_PAGESIZE;
+
+		DUMP_WRITE(&phdr, sizeof(phdr));
+	}
+
+#ifdef ELF_CORE_WRITE_EXTRA_PHDRS
+	ELF_CORE_WRITE_EXTRA_PHDRS;
+#endif
+
+ 	/* write out the notes section */
+	for (i = 0; i < numnote; i++)
+		if (!writenote(notes + i, file, &foffset))
+			goto end_coredump;
+
+#ifdef ELF_CORE_WRITE_EXTRA_NOTES
+	ELF_CORE_WRITE_EXTRA_NOTES;
+#endif
+
+	/* write out the thread status notes section */
+	list_for_each(t, &thread_list) {
+		struct elf_thread_status *tmp =
+				list_entry(t, struct elf_thread_status, list);
+
+		for (i = 0; i < tmp->num_notes; i++)
+			if (!writenote(&tmp->notes[i], file, &foffset))
+				goto end_coredump;
+	}
+
+	/* Align to page */
+	DUMP_SEEK(dataoff - foffset);
+
+	for (vma = first_vma(current, gate_vma); vma != NULL;
+			vma = next_vma(vma, gate_vma)) {
+		unsigned long addr;
+
+		if (!maydump(vma))
+			continue;
+		{
+		for (addr = vma->vm_start;
+		     addr < vma->vm_end;
+		     addr += PAGE_SIZE) {
+			struct page *page;
+			struct vm_area_struct *vma;
+
+			if (get_user_pages(current, current->mm, addr, 1, 0, 1,
+						&page, &vma) <= 0) {
+				DUMP_SEEK(PAGE_SIZE);
+			} else {
+				if (page == ZERO_PAGE(addr)) {
+					if (!dump_seek(file, PAGE_SIZE)) {
+						page_cache_release(page);
+						goto end_coredump;
+					}
+				} else {
+					void *kaddr;
+					flush_cache_page(vma, addr,
+							 page_to_pfn(page));
+					kaddr = kmap(page);
+					if ((size += PAGE_SIZE) > limit ||
+					    !dump_write(file, kaddr,
+					    PAGE_SIZE)) {
+						kunmap(page);
+						page_cache_release(page);
+						goto end_coredump;
+					}
+					kunmap(page);
+				}
+				page_cache_release(page);
+			}
+		}
+		}
+	}
+
+#ifdef ELF_CORE_WRITE_EXTRA_DATA
+	ELF_CORE_WRITE_EXTRA_DATA;
+#endif
+
+end_coredump:
+	set_fs(fs);
+
+cleanup:
+	while (!list_empty(&thread_list)) {
+		struct list_head *tmp = thread_list.next;
+		list_del(tmp);
+		kfree(list_entry(tmp, struct elf_thread_status, list));
+	}
+
+	kfree(elf);
+	kfree(prstatus);
+	kfree(psinfo);
+	kfree(notes);
+	kfree(fpu);
+#ifdef ELF_CORE_COPY_XFPREGS
+	kfree(xfpu);
+#endif
+	return has_dumped;
+#undef NUM_NOTES
+}
+
+#endif		/* USE_ELF_CORE_DUMP */
diff --git a/fs/dcookies.c b/fs/dcookies.c
index 17c7799..9338125 100644
--- a/fs/dcookies.c
+++ b/fs/dcookies.c
@@ -209,6 +209,46 @@ asmlinkage long SyS_lookup_dcookie(u64 cookie64, long buf, long len)
 SYSCALL_ALIAS(sys_lookup_dcookie, SyS_lookup_dcookie);
 #endif
 
+#if defined (CONFIG_64BIT) && defined (CONFIG_RMI_PHOENIX)
+#if defined (CONFIG_MIPS32_O32) || defined (CONFIG_MIPS32_N32)
+#ifdef CONFIG_HAVE_SYSCALL_WRAPPERS
+compat_SyS_lookup_dcookie(u32 cookie_msb, u32 cookie_lsb,
+        compat_uptr_t buf, compat_size_t len)
+{
+    u64 cookie;
+    char __user *user_buf;
+    size_t size;
+
+    size = (size_t)len;
+
+    user_buf = compat_ptr(buf);
+    cookie = (((u64)cookie_msb) << 32) | (u64)cookie_lsb;
+
+    return SYSC_lookup_dcookie(cookie, user_buf, size);
+
+}
+SYSCALL_ALIAS(compat_sys_lookup_dcookie, compat_SyS_lookup_dcookie);
+#else
+compat_sys_lookup_dcookie(u32 cookie_msb, u32 cookie_lsb,
+        compat_uptr_t buf, compat_size_t len)
+{
+    u64 cookie;
+    char __user *user_buf;
+    size_t size;
+
+    size = (size_t)len;
+
+    user_buf = compat_ptr(buf);
+    cookie = (((u64)cookie_msb) << 32) | (u64)cookie_lsb;
+
+    return sys_lookup_dcookie(cookie, user_buf, size);
+
+}
+#endif
+#endif
+#endif
+
+
 static int dcookie_init(void)
 {
 	struct list_head * d;
diff --git a/include/asm-generic/kgdb.h b/include/asm-generic/kgdb.h
new file mode 100644
index 0000000..04e8aa9
--- /dev/null
+++ b/include/asm-generic/kgdb.h
@@ -0,0 +1,46 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/*
+ * include/asm-generic/kgdb.h
+ *
+ * This provides the assembly level information so that KGDB can provide
+ * a GDB that has been patched with enough information to know to stop
+ * trying to unwind the function.
+ *
+ * Author: Tom Rini <trini@kernel.crashing.org>
+ *
+ * 2005 (c) MontaVista Software, Inc. This file is licensed under the terms
+ * of the GNU General Public License version 2. This program is licensed
+ * "as is" without any warranty of any kind, whether express or implied.
+ */
+
+#ifndef __ASM_GENERIC_KGDB_H__
+#define __ASM_GENERIC_KGDB_H__
+
+#include <linux/dwarf2-lang.h>
+#ifdef __ASSEMBLY__
+#ifdef CONFIG_KGDB
+/* This MUST be put at the end of a given assembly function */
+#define __CFI_END_FRAME(pc,sp,func)			\
+CAT3(.Lend_,func,:)					\
+	CFI_preamble(func,pc,0x1,-DATA_ALIGN_FACTOR)	\
+	CFA_define_reference(sp, 0)			\
+	CFA_undefine_reg(pc)				\
+	CFI_postamble()					\
+	FDE_preamble(func,func,CAT3(.Lend,_,func))	\
+	FDE_postamble()
+#else
+#define __CFI_END_FRAME(pc,sp,fn)
+#endif				/* CONFIG_KGDB */
+#endif				/* __ASSEMBLY__ */
+#endif				/* __ASM_GENERIC_KGDB_H__ */
diff --git a/include/linux/crypto.h b/include/linux/crypto.h
index b92eadf..1d5bc89 100644
--- a/include/linux/crypto.h
+++ b/include/linux/crypto.h
@@ -51,6 +51,8 @@
 #define CRYPTO_ALG_DYING		0x00000040
 #define CRYPTO_ALG_ASYNC		0x00000080
 
+#define CRYPTO_ALG_HW                   0x00000100
+
 /*
  * Set this bit if and only if the algorithm requires another algorithm of
  * the same type to handle corner cases.
@@ -308,6 +310,11 @@ struct crypto_alg {
 	void (*cra_destroy)(struct crypto_alg *alg);
 	
 	struct module *cra_module;
+	struct crypto_alg *cra_helper; /* Only makes sense for hw algs. 
+					This is a pointer to sw implementation, 
+					it can be used as fallback 
+					implementation if hw one cannot handle 
+					particular request. */
 };
 
 /*
diff --git a/include/linux/dwarf2-defs.h b/include/linux/dwarf2-defs.h
new file mode 100644
index 0000000..8068c79
--- /dev/null
+++ b/include/linux/dwarf2-defs.h
@@ -0,0 +1,515 @@
+#ifndef  _ELF_DWARF_H
+/* Machine generated from dwarf2.h by scripts/dwarfh.awk */
+#define _ELF_DWARF2_H
+#define DW_TAG_padding	 0x00
+#define DW_TAG_array_type	 0x01
+#define DW_TAG_class_type	 0x02
+#define DW_TAG_entry_point	 0x03
+#define DW_TAG_enumeration_type	 0x04
+#define DW_TAG_formal_parameter	 0x05
+#define DW_TAG_imported_declaration	 0x08
+#define DW_TAG_label	 0x0a
+#define DW_TAG_lexical_block	 0x0b
+#define DW_TAG_member	 0x0d
+#define DW_TAG_pointer_type	 0x0f
+#define DW_TAG_reference_type	 0x10
+#define DW_TAG_compile_unit	 0x11
+#define DW_TAG_string_type	 0x12
+#define DW_TAG_structure_type	 0x13
+#define DW_TAG_subroutine_type	 0x15
+#define DW_TAG_typedef	 0x16
+#define DW_TAG_union_type	 0x17
+#define DW_TAG_unspecified_parameters	 0x18
+#define DW_TAG_variant	 0x19
+#define DW_TAG_common_block	 0x1a
+#define DW_TAG_common_inclusion	 0x1b
+#define DW_TAG_inheritance	 0x1c
+#define DW_TAG_inlined_subroutine	 0x1d
+#define DW_TAG_module	 0x1e
+#define DW_TAG_ptr_to_member_type	 0x1f
+#define DW_TAG_set_type	 0x20
+#define DW_TAG_subrange_type	 0x21
+#define DW_TAG_with_stmt	 0x22
+#define DW_TAG_access_declaration	 0x23
+#define DW_TAG_base_type	 0x24
+#define DW_TAG_catch_block	 0x25
+#define DW_TAG_const_type	 0x26
+#define DW_TAG_constant	 0x27
+#define DW_TAG_enumerator	 0x28
+#define DW_TAG_file_type	 0x29
+#define DW_TAG_friend	 0x2a
+#define DW_TAG_namelist	 0x2b
+#define DW_TAG_namelist_item	 0x2c
+#define DW_TAG_packed_type	 0x2d
+#define DW_TAG_subprogram	 0x2e
+#define DW_TAG_template_type_param	 0x2f
+#define DW_TAG_template_value_param	 0x30
+#define DW_TAG_thrown_type	 0x31
+#define DW_TAG_try_block	 0x32
+#define DW_TAG_variant_part	 0x33
+#define DW_TAG_variable	 0x34
+#define DW_TAG_volatile_type	 0x35
+#define DW_TAG_dwarf_procedure	 0x36
+#define DW_TAG_restrict_type	 0x37
+#define DW_TAG_interface_type	 0x38
+#define DW_TAG_namespace	 0x39
+#define DW_TAG_imported_module	 0x3a
+#define DW_TAG_unspecified_type	 0x3b
+#define DW_TAG_partial_unit	 0x3c
+#define DW_TAG_imported_unit	 0x3d
+#define DW_TAG_MIPS_loop	 0x4081
+#define DW_TAG_HP_array_descriptor	 0x4090
+#define DW_TAG_format_label	 0x4101
+#define DW_TAG_function_template	 0x4102
+#define DW_TAG_class_template	 0x4103
+#define DW_TAG_GNU_BINCL	 0x4104
+#define DW_TAG_GNU_EINCL	 0x4105
+#define DW_TAG_upc_shared_type	 0x8765
+#define DW_TAG_upc_strict_type	 0x8766
+#define DW_TAG_upc_relaxed_type	 0x8767
+#define DW_TAG_PGI_kanji_type	 0xA000
+#define DW_TAG_PGI_interface_block	 0xA020
+#define DW_TAG_lo_user	0x4080
+#define DW_TAG_hi_user	0xffff
+#define DW_children_no   0
+#define	DW_children_yes  1
+#define DW_FORM_addr	 0x01
+#define DW_FORM_block2	 0x03
+#define DW_FORM_block4	 0x04
+#define DW_FORM_data2	 0x05
+#define DW_FORM_data4	 0x06
+#define DW_FORM_data8	 0x07
+#define DW_FORM_string	 0x08
+#define DW_FORM_block	 0x09
+#define DW_FORM_block1	 0x0a
+#define DW_FORM_data1	 0x0b
+#define DW_FORM_flag	 0x0c
+#define DW_FORM_sdata	 0x0d
+#define DW_FORM_strp	 0x0e
+#define DW_FORM_udata	 0x0f
+#define DW_FORM_ref_addr	 0x10
+#define DW_FORM_ref1	 0x11
+#define DW_FORM_ref2	 0x12
+#define DW_FORM_ref4	 0x13
+#define DW_FORM_ref8	 0x14
+#define DW_FORM_ref_udata	 0x15
+#define DW_FORM_indirect	 0x16
+#define DW_AT_sibling	 0x01
+#define DW_AT_location	 0x02
+#define DW_AT_name	 0x03
+#define DW_AT_ordering	 0x09
+#define DW_AT_subscr_data	 0x0a
+#define DW_AT_byte_size	 0x0b
+#define DW_AT_bit_offset	 0x0c
+#define DW_AT_bit_size	 0x0d
+#define DW_AT_element_list	 0x0f
+#define DW_AT_stmt_list	 0x10
+#define DW_AT_low_pc	 0x11
+#define DW_AT_high_pc	 0x12
+#define DW_AT_language	 0x13
+#define DW_AT_member	 0x14
+#define DW_AT_discr	 0x15
+#define DW_AT_discr_value	 0x16
+#define DW_AT_visibility	 0x17
+#define DW_AT_import	 0x18
+#define DW_AT_string_length	 0x19
+#define DW_AT_common_reference	 0x1a
+#define DW_AT_comp_dir	 0x1b
+#define DW_AT_const_value	 0x1c
+#define DW_AT_containing_type	 0x1d
+#define DW_AT_default_value	 0x1e
+#define DW_AT_inline	 0x20
+#define DW_AT_is_optional	 0x21
+#define DW_AT_lower_bound	 0x22
+#define DW_AT_producer	 0x25
+#define DW_AT_prototyped	 0x27
+#define DW_AT_return_addr	 0x2a
+#define DW_AT_start_scope	 0x2c
+#define DW_AT_stride_size	 0x2e
+#define DW_AT_upper_bound	 0x2f
+#define DW_AT_abstract_origin	 0x31
+#define DW_AT_accessibility	 0x32
+#define DW_AT_address_class	 0x33
+#define DW_AT_artificial	 0x34
+#define DW_AT_base_types	 0x35
+#define DW_AT_calling_convention	 0x36
+#define DW_AT_count	 0x37
+#define DW_AT_data_member_location	 0x38
+#define DW_AT_decl_column	 0x39
+#define DW_AT_decl_file	 0x3a
+#define DW_AT_decl_line	 0x3b
+#define DW_AT_declaration	 0x3c
+#define DW_AT_discr_list	 0x3d
+#define DW_AT_encoding	 0x3e
+#define DW_AT_external	 0x3f
+#define DW_AT_frame_base	 0x40
+#define DW_AT_friend	 0x41
+#define DW_AT_identifier_case	 0x42
+#define DW_AT_macro_info	 0x43
+#define DW_AT_namelist_items	 0x44
+#define DW_AT_priority	 0x45
+#define DW_AT_segment	 0x46
+#define DW_AT_specification	 0x47
+#define DW_AT_static_link	 0x48
+#define DW_AT_type	 0x49
+#define DW_AT_use_location	 0x4a
+#define DW_AT_variable_parameter	 0x4b
+#define DW_AT_virtuality	 0x4c
+#define DW_AT_vtable_elem_location	 0x4d
+#define DW_AT_allocated	 0x4e
+#define DW_AT_associated	 0x4f
+#define DW_AT_data_location	 0x50
+#define DW_AT_stride	 0x51
+#define DW_AT_entry_pc	 0x52
+#define DW_AT_use_UTF8	 0x53
+#define DW_AT_extension	 0x54
+#define DW_AT_ranges	 0x55
+#define DW_AT_trampoline	 0x56
+#define DW_AT_call_column	 0x57
+#define DW_AT_call_file	 0x58
+#define DW_AT_call_line	 0x59
+#define DW_AT_MIPS_fde	 0x2001
+#define DW_AT_MIPS_loop_begin	 0x2002
+#define DW_AT_MIPS_tail_loop_begin	 0x2003
+#define DW_AT_MIPS_epilog_begin	 0x2004
+#define DW_AT_MIPS_loop_unroll_factor	 0x2005
+#define DW_AT_MIPS_software_pipeline_depth	 0x2006
+#define DW_AT_MIPS_linkage_name	 0x2007
+#define DW_AT_MIPS_stride	 0x2008
+#define DW_AT_MIPS_abstract_name	 0x2009
+#define DW_AT_MIPS_clone_origin	 0x200a
+#define DW_AT_MIPS_has_inlines	 0x200b
+#define DW_AT_HP_block_index	 0x2000
+#define DW_AT_HP_unmodifiable	 0x2001
+#define DW_AT_HP_actuals_stmt_list	 0x2010
+#define DW_AT_HP_proc_per_section	 0x2011
+#define DW_AT_HP_raw_data_ptr	 0x2012
+#define DW_AT_HP_pass_by_reference	 0x2013
+#define DW_AT_HP_opt_level	 0x2014
+#define DW_AT_HP_prof_version_id	 0x2015
+#define DW_AT_HP_opt_flags	 0x2016
+#define DW_AT_HP_cold_region_low_pc	 0x2017
+#define DW_AT_HP_cold_region_high_pc	 0x2018
+#define DW_AT_HP_all_variables_modifiable	 0x2019
+#define DW_AT_HP_linkage_name	 0x201a
+#define DW_AT_HP_prof_flags	 0x201b
+#define DW_AT_sf_names	 0x2101
+#define DW_AT_src_info	 0x2102
+#define DW_AT_mac_info	 0x2103
+#define DW_AT_src_coords	 0x2104
+#define DW_AT_body_begin	 0x2105
+#define DW_AT_body_end	 0x2106
+#define DW_AT_GNU_vector	 0x2107
+#define DW_AT_VMS_rtnbeg_pd_address	 0x2201
+#define DW_AT_upc_threads_scaled	 0x3210
+#define DW_AT_PGI_lbase	 0x3a00
+#define DW_AT_PGI_soffset	 0x3a01
+#define DW_AT_PGI_lstride	 0x3a02
+#define DW_AT_lo_user	0x2000	/* Implementation-defined range start.  */
+#define DW_AT_hi_user	0x3ff0	/* Implementation-defined range end.  */
+#define DW_OP_addr	 0x03
+#define DW_OP_deref	 0x06
+#define DW_OP_const1u	 0x08
+#define DW_OP_const1s	 0x09
+#define DW_OP_const2u	 0x0a
+#define DW_OP_const2s	 0x0b
+#define DW_OP_const4u	 0x0c
+#define DW_OP_const4s	 0x0d
+#define DW_OP_const8u	 0x0e
+#define DW_OP_const8s	 0x0f
+#define DW_OP_constu	 0x10
+#define DW_OP_consts	 0x11
+#define DW_OP_dup	 0x12
+#define DW_OP_drop	 0x13
+#define DW_OP_over	 0x14
+#define DW_OP_pick	 0x15
+#define DW_OP_swap	 0x16
+#define DW_OP_rot	 0x17
+#define DW_OP_xderef	 0x18
+#define DW_OP_abs	 0x19
+#define DW_OP_and	 0x1a
+#define DW_OP_div	 0x1b
+#define DW_OP_minus	 0x1c
+#define DW_OP_mod	 0x1d
+#define DW_OP_mul	 0x1e
+#define DW_OP_neg	 0x1f
+#define DW_OP_not	 0x20
+#define DW_OP_or	 0x21
+#define DW_OP_plus	 0x22
+#define DW_OP_plus_uconst	 0x23
+#define DW_OP_shl	 0x24
+#define DW_OP_shr	 0x25
+#define DW_OP_shra	 0x26
+#define DW_OP_xor	 0x27
+#define DW_OP_bra	 0x28
+#define DW_OP_eq	 0x29
+#define DW_OP_ge	 0x2a
+#define DW_OP_gt	 0x2b
+#define DW_OP_le	 0x2c
+#define DW_OP_lt	 0x2d
+#define DW_OP_ne	 0x2e
+#define DW_OP_skip	 0x2f
+#define DW_OP_lit0	 0x30
+#define DW_OP_lit1	 0x31
+#define DW_OP_lit2	 0x32
+#define DW_OP_lit3	 0x33
+#define DW_OP_lit4	 0x34
+#define DW_OP_lit5	 0x35
+#define DW_OP_lit6	 0x36
+#define DW_OP_lit7	 0x37
+#define DW_OP_lit8	 0x38
+#define DW_OP_lit9	 0x39
+#define DW_OP_lit10	 0x3a
+#define DW_OP_lit11	 0x3b
+#define DW_OP_lit12	 0x3c
+#define DW_OP_lit13	 0x3d
+#define DW_OP_lit14	 0x3e
+#define DW_OP_lit15	 0x3f
+#define DW_OP_lit16	 0x40
+#define DW_OP_lit17	 0x41
+#define DW_OP_lit18	 0x42
+#define DW_OP_lit19	 0x43
+#define DW_OP_lit20	 0x44
+#define DW_OP_lit21	 0x45
+#define DW_OP_lit22	 0x46
+#define DW_OP_lit23	 0x47
+#define DW_OP_lit24	 0x48
+#define DW_OP_lit25	 0x49
+#define DW_OP_lit26	 0x4a
+#define DW_OP_lit27	 0x4b
+#define DW_OP_lit28	 0x4c
+#define DW_OP_lit29	 0x4d
+#define DW_OP_lit30	 0x4e
+#define DW_OP_lit31	 0x4f
+#define DW_OP_reg0	 0x50
+#define DW_OP_reg1	 0x51
+#define DW_OP_reg2	 0x52
+#define DW_OP_reg3	 0x53
+#define DW_OP_reg4	 0x54
+#define DW_OP_reg5	 0x55
+#define DW_OP_reg6	 0x56
+#define DW_OP_reg7	 0x57
+#define DW_OP_reg8	 0x58
+#define DW_OP_reg9	 0x59
+#define DW_OP_reg10	 0x5a
+#define DW_OP_reg11	 0x5b
+#define DW_OP_reg12	 0x5c
+#define DW_OP_reg13	 0x5d
+#define DW_OP_reg14	 0x5e
+#define DW_OP_reg15	 0x5f
+#define DW_OP_reg16	 0x60
+#define DW_OP_reg17	 0x61
+#define DW_OP_reg18	 0x62
+#define DW_OP_reg19	 0x63
+#define DW_OP_reg20	 0x64
+#define DW_OP_reg21	 0x65
+#define DW_OP_reg22	 0x66
+#define DW_OP_reg23	 0x67
+#define DW_OP_reg24	 0x68
+#define DW_OP_reg25	 0x69
+#define DW_OP_reg26	 0x6a
+#define DW_OP_reg27	 0x6b
+#define DW_OP_reg28	 0x6c
+#define DW_OP_reg29	 0x6d
+#define DW_OP_reg30	 0x6e
+#define DW_OP_reg31	 0x6f
+#define DW_OP_breg0	 0x70
+#define DW_OP_breg1	 0x71
+#define DW_OP_breg2	 0x72
+#define DW_OP_breg3	 0x73
+#define DW_OP_breg4	 0x74
+#define DW_OP_breg5	 0x75
+#define DW_OP_breg6	 0x76
+#define DW_OP_breg7	 0x77
+#define DW_OP_breg8	 0x78
+#define DW_OP_breg9	 0x79
+#define DW_OP_breg10	 0x7a
+#define DW_OP_breg11	 0x7b
+#define DW_OP_breg12	 0x7c
+#define DW_OP_breg13	 0x7d
+#define DW_OP_breg14	 0x7e
+#define DW_OP_breg15	 0x7f
+#define DW_OP_breg16	 0x80
+#define DW_OP_breg17	 0x81
+#define DW_OP_breg18	 0x82
+#define DW_OP_breg19	 0x83
+#define DW_OP_breg20	 0x84
+#define DW_OP_breg21	 0x85
+#define DW_OP_breg22	 0x86
+#define DW_OP_breg23	 0x87
+#define DW_OP_breg24	 0x88
+#define DW_OP_breg25	 0x89
+#define DW_OP_breg26	 0x8a
+#define DW_OP_breg27	 0x8b
+#define DW_OP_breg28	 0x8c
+#define DW_OP_breg29	 0x8d
+#define DW_OP_breg30	 0x8e
+#define DW_OP_breg31	 0x8f
+#define DW_OP_regx	 0x90
+#define DW_OP_fbreg	 0x91
+#define DW_OP_bregx	 0x92
+#define DW_OP_piece	 0x93
+#define DW_OP_deref_size	 0x94
+#define DW_OP_xderef_size	 0x95
+#define DW_OP_nop	 0x96
+#define DW_OP_push_object_address	 0x97
+#define DW_OP_call2	 0x98
+#define DW_OP_call4	 0x99
+#define DW_OP_call_ref	 0x9a
+#define DW_OP_GNU_push_tls_address	 0xe0
+#define DW_OP_HP_unknown	 0xe0
+#define DW_OP_HP_is_value	 0xe1
+#define DW_OP_HP_fltconst4	 0xe2
+#define DW_OP_HP_fltconst8	 0xe3
+#define DW_OP_HP_mod_range	 0xe4
+#define DW_OP_HP_unmod_range	 0xe5
+#define DW_OP_HP_tls	 0xe6
+#define DW_OP_lo_user	0xe0	/* Implementation-defined range start.  */
+#define DW_OP_hi_user	0xff	/* Implementation-defined range end.  */
+#define DW_ATE_void	 0x0
+#define DW_ATE_address	 0x1
+#define DW_ATE_boolean	 0x2
+#define DW_ATE_complex_float	 0x3
+#define DW_ATE_float	 0x4
+#define DW_ATE_signed	 0x5
+#define DW_ATE_signed_char	 0x6
+#define DW_ATE_unsigned	 0x7
+#define DW_ATE_unsigned_char	 0x8
+#define DW_ATE_imaginary_float	 0x9
+#define DW_ATE_HP_float80	 0x80
+#define DW_ATE_HP_complex_float80	 0x81
+#define DW_ATE_HP_float128	 0x82
+#define DW_ATE_HP_complex_float128	 0x83
+#define DW_ATE_HP_floathpintel	 0x84
+#define DW_ATE_HP_imaginary_float80	 0x85
+#define DW_ATE_HP_imaginary_float128	 0x86
+#define	DW_ATE_lo_user 0x80
+#define	DW_ATE_hi_user 0xff
+#define DW_ORD_row_major	 0
+#define DW_ORD_col_major	 1
+#define DW_ACCESS_public	 1
+#define DW_ACCESS_protected	 2
+#define DW_ACCESS_private	 3
+#define DW_VIS_local	 1
+#define DW_VIS_exported	 2
+#define DW_VIS_qualified	 3
+#define DW_VIRTUALITY_none	 0
+#define DW_VIRTUALITY_virtual	 1
+#define DW_VIRTUALITY_pure_virtual	 2
+#define DW_ID_case_sensitive	 0
+#define DW_ID_up_case	 1
+#define DW_ID_down_case	 2
+#define DW_ID_case_insensitive	 3
+#define DW_CC_normal	 0x1
+#define DW_CC_program	 0x2
+#define DW_CC_nocall	 0x3
+#define DW_CC_lo_user 0x40
+#define DW_CC_hi_user 0xff
+#define DW_INL_not_inlined	 0
+#define DW_INL_inlined	 1
+#define DW_INL_declared_not_inlined	 2
+#define DW_INL_declared_inlined	 3
+#define DW_DSC_label	 0
+#define DW_DSC_range	 1
+#define DW_LNS_extended_op	 0
+#define DW_LNS_copy	 1
+#define DW_LNS_advance_pc	 2
+#define DW_LNS_advance_line	 3
+#define DW_LNS_set_file	 4
+#define DW_LNS_set_column	 5
+#define DW_LNS_negate_stmt	 6
+#define DW_LNS_set_basic_block	 7
+#define DW_LNS_const_add_pc	 8
+#define DW_LNS_fixed_advance_pc	 9
+#define DW_LNS_set_prologue_end	 10
+#define DW_LNS_set_epilogue_begin	 11
+#define DW_LNS_set_isa	 12
+#define DW_LNE_end_sequence	 1
+#define DW_LNE_set_address	 2
+#define DW_LNE_define_file	 3
+#define DW_LNE_HP_negate_is_UV_update	 0x11
+#define DW_LNE_HP_push_context	 0x12
+#define DW_LNE_HP_pop_context	 0x13
+#define DW_LNE_HP_set_file_line_column	 0x14
+#define DW_LNE_HP_set_routine_name	 0x15
+#define DW_LNE_HP_set_sequence	 0x16
+#define DW_LNE_HP_negate_post_semantics	 0x17
+#define DW_LNE_HP_negate_function_exit	 0x18
+#define DW_LNE_HP_negate_front_end_logical	 0x19
+#define DW_LNE_HP_define_proc	 0x20
+#define DW_CFA_advance_loc	 0x40
+#define DW_CFA_offset	 0x80
+#define DW_CFA_restore	 0xc0
+#define DW_CFA_nop	 0x00
+#define DW_CFA_set_loc	 0x01
+#define DW_CFA_advance_loc1	 0x02
+#define DW_CFA_advance_loc2	 0x03
+#define DW_CFA_advance_loc4	 0x04
+#define DW_CFA_offset_extended	 0x05
+#define DW_CFA_restore_extended	 0x06
+#define DW_CFA_undefined	 0x07
+#define DW_CFA_same_value	 0x08
+#define DW_CFA_register	 0x09
+#define DW_CFA_remember_state	 0x0a
+#define DW_CFA_restore_state	 0x0b
+#define DW_CFA_def_cfa	 0x0c
+#define DW_CFA_def_cfa_register	 0x0d
+#define DW_CFA_def_cfa_offset	 0x0e
+#define DW_CFA_def_cfa_expression	 0x0f
+#define DW_CFA_expression	 0x10
+#define DW_CFA_offset_extended_sf	 0x11
+#define DW_CFA_def_cfa_sf	 0x12
+#define DW_CFA_def_cfa_offset_sf	 0x13
+#define DW_CFA_MIPS_advance_loc8	 0x1d
+#define DW_CFA_GNU_window_save	 0x2d
+#define DW_CFA_GNU_args_size	 0x2e
+#define DW_CFA_GNU_negative_offset_extended	 0x2f
+#define DW_CIE_ID	  0xffffffff
+#define DW_CIE_VERSION	  1
+#define DW_CFA_extended   0
+#define DW_CFA_lo_user    0x1c
+#define DW_CFA_hi_user    0x3f
+#define DW_CHILDREN_no		     0x00
+#define DW_CHILDREN_yes		     0x01
+#define DW_ADDR_none		0
+#define DW_LANG_C89	 0x0001
+#define DW_LANG_C	 0x0002
+#define DW_LANG_Ada83	 0x0003
+#define DW_LANG_C_plus_plus	 0x0004
+#define DW_LANG_Cobol74	 0x0005
+#define DW_LANG_Cobol85	 0x0006
+#define DW_LANG_Fortran77	 0x0007
+#define DW_LANG_Fortran90	 0x0008
+#define DW_LANG_Pascal83	 0x0009
+#define DW_LANG_Modula2	 0x000a
+#define DW_LANG_Java	 0x000b
+#define DW_LANG_C99	 0x000c
+#define DW_LANG_Ada95	 0x000d
+#define DW_LANG_Fortran95	 0x000e
+#define DW_LANG_Mips_Assembler	 0x8001
+#define DW_LANG_Upc	 0x8765
+#define DW_LANG_lo_user 0x8000	/* Implementation-defined range start.  */
+#define DW_LANG_hi_user 0xffff	/* Implementation-defined range start.  */
+#define DW_MACINFO_define	 1
+#define DW_MACINFO_undef	 2
+#define DW_MACINFO_start_file	 3
+#define DW_MACINFO_end_file	 4
+#define DW_MACINFO_vendor_ext	 255
+#define DW_EH_PE_absptr		0x00
+#define DW_EH_PE_omit		0xff
+#define DW_EH_PE_uleb128	0x01
+#define DW_EH_PE_udata2		0x02
+#define DW_EH_PE_udata4		0x03
+#define DW_EH_PE_udata8		0x04
+#define DW_EH_PE_sleb128	0x09
+#define DW_EH_PE_sdata2		0x0A
+#define DW_EH_PE_sdata4		0x0B
+#define DW_EH_PE_sdata8		0x0C
+#define DW_EH_PE_signed		0x08
+#define DW_EH_PE_pcrel		0x10
+#define DW_EH_PE_textrel	0x20
+#define DW_EH_PE_datarel	0x30
+#define DW_EH_PE_funcrel	0x40
+#define DW_EH_PE_aligned	0x50
+#define DW_EH_PE_indirect	0x80
+#endif
diff --git a/include/linux/dwarf2-lang.h b/include/linux/dwarf2-lang.h
new file mode 100644
index 0000000..eab33c3
--- /dev/null
+++ b/include/linux/dwarf2-lang.h
@@ -0,0 +1,312 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+#ifndef DWARF2_LANG
+#define DWARF2_LANG
+
+/*
+ * This is free software; you can redistribute it and/or modify it under
+ * the terms of the GNU General Public License as published by the Free
+ * Software Foundation; either version 2, or (at your option) any later
+ * version.
+ */
+/*
+ * This file defines macros that allow generation of DWARF debug records
+ * for asm files.  This file is platform independent.  Register numbers
+ * (which are about the only thing that is platform dependent) are to be
+ * supplied by a platform defined file.
+ */
+/*
+ * We need this to work for both asm and C.  In asm we are using the
+ * old comment trick to concatenate while C uses the new ANSI thing.
+ * Here we have concat macro...  The multi level thing is to allow and
+ * macros used in the names to be resolved prior to the cat (at which
+ * time they are no longer the same string).
+ */
+#define CAT3(a,b,c) _CAT3(a,b,c)
+#define _CAT3(a,b,c) __CAT3(a,b,c)
+#ifndef __STDC__
+#define __CAT3(a,b,c) a/**/b/**/c
+#else
+#define __CAT3(a,b,c) a##b##c
+#endif
+#ifdef __ASSEMBLY__
+#define IFC(a)
+#define IFN_C(a) a
+#define NL ;
+#define QUOTE_THIS(a) a
+#define DWARF_preamble .section .debug_frame,"",%progbits;
+#else
+#define IFC(a) a
+#define IFN_C(a)
+#define NL \n\t
+#define QUOTE_THIS(a) _QUOTE_THIS(a)
+#define _QUOTE_THIS(a) #a
+/* Don't let CPP see the " and , \042=" \054=, */
+#define DWARF_preamble .section .debug_frame \054\042\042\054%progbits
+#endif
+
+#ifdef CONFIG_64BIT
+#define DATA_ALIGN_FACTOR	8
+#define ADDR_LOC		.quad
+#else
+#define DATA_ALIGN_FACTOR	4
+#define ADDR_LOC		.long
+#endif
+
+#include <linux/dwarf2-defs.h>
+/*
+ * This macro starts a debug frame section.  The debug_frame describes
+ * where to find the registers that the enclosing function saved on
+ * entry.
+ *
+ * ORD is use by the label generator and should be the same as what is
+ * passed to CFI_postamble.
+ *
+ * pc,	pc register gdb ordinal.
+ *
+ * code_align this is the factor used to define locations or regions
+ * where the given definitions apply.  If you use labels to define these
+ * this should be 1.
+ *
+ * data_align this is the factor used to define register offsets.  If
+ * you use struct offset, this should be the size of the register in
+ * bytes or the negative of that.  This is how it is used: you will
+ * define a register as the reference register, say the stack pointer,
+ * then you will say where a register is located relative to this
+ * reference registers value, say 40 for register 3 (the gdb register
+ * number).  The <40> will be multiplied by <data_align> to define the
+ * byte offset of the given register (3, in this example).  So if your
+ * <40> is the byte offset and the reference register points at the
+ * begining, you would want 1 for the data_offset.  If <40> was the 40th
+ * 4-byte element in that structure you would want 4.  And if your
+ * reference register points at the end of the structure you would want
+ * a negative data_align value(and you would have to do other math as
+ * well).
+ */
+
+#define CFI_preamble(ORD, pc, code_align, data_align)	\
+         DWARF_preamble	NL				\
+	.align DATA_ALIGN_FACTOR NL			\
+        .globl CAT3(frame,_,ORD) NL			\
+CAT3(frame,_,ORD): NL					\
+	.long 7f-6f NL					\
+6:							\
+	.long	DW_CIE_ID NL				\
+	.byte	DW_CIE_VERSION NL			\
+	.byte 0	 NL					\
+	.uleb128 code_align NL				\
+	.sleb128 data_align NL				\
+	.byte pc NL
+
+/*
+ * After the above macro and prior to the CFI_postamble, you need to
+ * define the initial state.  This starts with defining the reference
+ * register and, usually the pc.  Here are some helper macros:
+ */
+
+#define CFA_define_reference(reg, offset)	\
+	.byte DW_CFA_def_cfa NL			\
+	.uleb128 reg NL				\
+	.uleb128 (offset) NL
+
+#define CFA_define_offset(reg, offset)		\
+	.byte (DW_CFA_offset + reg) NL		\
+	.uleb128 (offset) NL
+
+#define CFA_restore(reg)			\
+        .byte (DW_CFA_restore + reg) NL
+
+#define CFI_postamble()				\
+	.align DATA_ALIGN_FACTOR NL				\
+7: NL						\
+.previous NL
+
+/*
+ * So now your code pushs stuff on the stack, you need a new location
+ * and the rules for what to do.  This starts a running description of
+ * the call frame.  You need to describe what changes with respect to
+ * the call registers as the location of the pc moves through the code.
+ * The following builds an FDE (fram descriptor entry?).  Like the
+ * above, it has a preamble and a postamble.  It also is tied to the CFI
+ * above.
+ * The preamble macro is tied to the CFI thru the first parameter.  The
+ * second is the code start address and then the code end address+1.
+ */
+#define FDE_preamble(ORD, initial_address, end_address)	\
+        DWARF_preamble NL				\
+	.align DATA_ALIGN_FACTOR NL					\
+	.long 9f-8f NL					\
+8:							\
+	.long CAT3(frame,_,ORD) NL			\
+	ADDR_LOC initial_address NL			\
+	ADDR_LOC (end_address - initial_address) NL
+
+#define FDE_postamble()				\
+	.align DATA_ALIGN_FACTOR NL				\
+9:	 NL					\
+.previous NL
+
+/*
+ * That done, you can now add registers, subtract registers, move the
+ * reference and even change the reference.  You can also define a new
+ * area of code the info applies to.  For discontinuous bits you should
+ * start a new FDE.  You may have as many as you like.
+ */
+
+/*
+ * To advance the stack address by <bytes> (0x3f max)
+ */
+
+#define CFA_advance_loc(bytes)			\
+	.byte DW_CFA_advance_loc+bytes NL
+
+/*
+ * This one is good for 0xff or 255
+ */
+#define CFA_advance_loc1(bytes)			\
+	.byte DW_CFA_advance_loc1 NL		\
+        .byte bytes NL
+
+#define CFA_undefine_reg(reg)			\
+        .byte DW_CFA_undefined NL		\
+	.uleb128 reg NL
+/*
+ * With the above you can define all the register locations.  But
+ * suppose the reference register moves... Takes the new offset NOT an
+ * increment.  This is how esp is tracked if it is not saved.
+ */
+
+#define CFA_define_cfa_offset(offset)		\
+	.byte DW_CFA_def_cfa_offset NL		\
+	.uleb128 (offset) NL
+/*
+ * Or suppose you want to use a different reference register...
+ */
+#define CFA_define_cfa_register(reg)		\
+	.byte DW_CFA_def_cfa_register NL	\
+	.uleb128 reg NL
+
+/*
+ * If you want to mess with the stack pointer, here is the expression.
+ * The stack starts empty.
+ */
+#define CFA_def_cfa_expression 			\
+        .byte DW_CFA_def_cfa_expression	NL	\
+	.uleb128 20f-10f NL			\
+10:     NL
+/*
+ * This expression is to be used for other regs.  The stack starts with the
+ * stack address.
+ */
+
+#define CFA_expression(reg)			\
+        .byte DW_CFA_expression	 NL		\
+        .uleb128 reg NL				\
+	.uleb128 20f-10f NL			\
+10:     NL
+/*
+ * Here we do the expression stuff.  You should code the above followed
+ *  by expression OPs followed by CFA_expression_end.
+ */
+
+
+#define CFA_expression_end			\
+20:	 NL
+
+#define CFA_exp_OP_const4s(a)			\
+        .byte DW_OP_const4s NL			\
+        .long a NL
+
+#define  CFA_exp_OP_swap  .byte DW_OP_swap NL
+#define  CFA_exp_OP_dup  .byte DW_OP_dup NL
+#define  CFA_exp_OP_drop  .byte DW_OP_drop NL
+/*
+ * All these work on the top two elements on the stack, replacing them
+ * with the result.  Top comes first where it matters.  True is 1, false 0.
+ */
+#define  CFA_exp_OP_deref .byte DW_OP_deref NL
+#define  CFA_exp_OP_and   .byte DW_OP_and NL
+#define  CFA_exp_OP_div   .byte DW_OP_div NL
+#define  CFA_exp_OP_minus .byte DW_OP_minus NL
+#define  CFA_exp_OP_mod   .byte DW_OP_mod NL
+#define  CFA_exp_OP_neg   .byte DW_OP_neg NL
+#define  CFA_exp_OP_plus  .byte DW_OP_plus NL
+#define  CFA_exp_OP_not   .byte DW_OP_not NL
+#define  CFA_exp_OP_or    .byte DW_OP_or NL
+#define  CFA_exp_OP_xor   .byte DW_OP_xor NL
+#define  CFA_exp_OP_le    .byte DW_OP_le NL
+#define  CFA_exp_OP_ge    .byte DW_OP_ge NL
+#define  CFA_exp_OP_eq    .byte DW_OP_eq NL
+#define  CFA_exp_OP_lt    .byte DW_OP_lt NL
+#define  CFA_exp_OP_gt    .byte DW_OP_gt NL
+#define  CFA_exp_OP_ne    .byte DW_OP_ne NL
+/*
+ * These take a parameter as noted
+ */
+/*
+ * Unconditional skip to loc. loc is a label (loc:)
+ */
+#define CFA_exp_OP_skip(loc)			\
+         .byte DW_OP_skip  NL 			\
+	 .hword  loc-.-2 NL
+/*
+ * Conditional skip to loc (TOS != 0, TOS--) (loc is a label)
+ */
+#define CFA_exp_OP_bra(loc)			\
+         .byte DW_OP_bra NL			\
+	 .hword loc-.-2 NL
+
+/*
+ * TOS += no (an unsigned number)
+ */
+#define CFA_exp_OP_plus_uconst(no)		\
+         .byte DW_OP_plus_uconst NL		\
+         .uleb128 no NL
+
+/*
+ * ++TOS = no (a unsigned number)
+ */
+#define CFA_exp_OP_constu(no)			\
+         .byte DW_OP_constu NL			\
+	 .uleb128 no NL
+/*
+ * ++TOS = no (a signed number)
+ */
+#define CFA_exp_OP_consts(no)			\
+         .byte DW_OP_consts NL			\
+	 .sleb128 no NL
+/*
+ * ++TOS = no (an unsigned byte)
+ */
+#define CFA_exp_OP_const1u(no)			\
+         .byte DW_OP_const1u NL			\
+	 .byte no NL
+
+
+/*
+ * ++TOS = no (a address)
+ */
+#define CFA_exp_OP_addr(no)			\
+         .byte DW_OP_addr NL			\
+	 .long no NL
+
+/*
+ * Push current frames value for "reg" + offset
+ * We take advantage of the opcode assignments to make this a litteral reg
+ * rather than use the DW_OP_bregx opcode.
+ */
+
+#define CFA_exp_OP_breg(reg,offset)		\
+         .byte DW_OP_breg0+reg NL		\
+         .sleb128 offset NL
+#endif
diff --git a/include/linux/dwarf2.h b/include/linux/dwarf2.h
new file mode 100644
index 0000000..a6fdc19
--- /dev/null
+++ b/include/linux/dwarf2.h
@@ -0,0 +1,787 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/* Declarations and definitions of codes relating to the DWARF2 symbolic
+   debugging information format.
+   Copyright (C) 1992, 1993, 1995, 1996, 1997, 1999, 2000, 2001, 2002,
+   2003 Free Software Foundation, Inc.
+
+   Written by Gary Funck (gary@intrepid.com) The Ada Joint Program
+   Office (AJPO), Florida State Unviversity and Silicon Graphics Inc.
+   provided support for this effort -- June 21, 1995.
+
+   Derived from the DWARF 1 implementation written by Ron Guilmette
+   (rfg@netcom.com), November 1990.
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify it under
+   the terms of the GNU General Public License as published by the Free
+   Software Foundation; either version 2, or (at your option) any later
+   version.
+
+   GCC is distributed in the hope that it will be useful, but WITHOUT
+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+   or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+   License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with GCC; see the file COPYING.  If not, write to the Free
+   Software Foundation, 59 Temple Place - Suite 330, Boston, MA
+   02111-1307, USA.  */
+
+/* This file is derived from the DWARF specification (a public document)
+   Revision 2.0.0 (July 27, 1993) developed by the UNIX International
+   Programming Languages Special Interest Group (UI/PLSIG) and distributed
+   by UNIX International.  Copies of this specification are available from
+   UNIX International, 20 Waterview Boulevard, Parsippany, NJ, 07054.
+
+   This file also now contains definitions from the DWARF 3 specification.  */
+
+/* This file is shared between GCC and GDB, and should not contain
+   prototypes.  */
+
+#ifndef _ELF_DWARF2_H
+#define _ELF_DWARF2_H
+
+/* Structure found in the .debug_line section.  */
+typedef struct
+{
+  unsigned char li_length          [4];
+  unsigned char li_version         [2];
+  unsigned char li_prologue_length [4];
+  unsigned char li_min_insn_length [1];
+  unsigned char li_default_is_stmt [1];
+  unsigned char li_line_base       [1];
+  unsigned char li_line_range      [1];
+  unsigned char li_opcode_base     [1];
+}
+DWARF2_External_LineInfo;
+
+typedef struct
+{
+  unsigned long  li_length;
+  unsigned short li_version;
+  unsigned int   li_prologue_length;
+  unsigned char  li_min_insn_length;
+  unsigned char  li_default_is_stmt;
+  int            li_line_base;
+  unsigned char  li_line_range;
+  unsigned char  li_opcode_base;
+}
+DWARF2_Internal_LineInfo;
+
+/* Structure found in .debug_pubnames section.  */
+typedef struct
+{
+  unsigned char pn_length  [4];
+  unsigned char pn_version [2];
+  unsigned char pn_offset  [4];
+  unsigned char pn_size    [4];
+}
+DWARF2_External_PubNames;
+
+typedef struct
+{
+  unsigned long  pn_length;
+  unsigned short pn_version;
+  unsigned long  pn_offset;
+  unsigned long  pn_size;
+}
+DWARF2_Internal_PubNames;
+
+/* Structure found in .debug_info section.  */
+typedef struct
+{
+  unsigned char  cu_length        [4];
+  unsigned char  cu_version       [2];
+  unsigned char  cu_abbrev_offset [4];
+  unsigned char  cu_pointer_size  [1];
+}
+DWARF2_External_CompUnit;
+
+typedef struct
+{
+  unsigned long  cu_length;
+  unsigned short cu_version;
+  unsigned long  cu_abbrev_offset;
+  unsigned char  cu_pointer_size;
+}
+DWARF2_Internal_CompUnit;
+
+typedef struct
+{
+  unsigned char  ar_length       [4];
+  unsigned char  ar_version      [2];
+  unsigned char  ar_info_offset  [4];
+  unsigned char  ar_pointer_size [1];
+  unsigned char  ar_segment_size [1];
+}
+DWARF2_External_ARange;
+
+typedef struct
+{
+  unsigned long  ar_length;
+  unsigned short ar_version;
+  unsigned long  ar_info_offset;
+  unsigned char  ar_pointer_size;
+  unsigned char  ar_segment_size;
+}
+DWARF2_Internal_ARange;
+
+
+/* Tag names and codes.  */
+enum dwarf_tag
+  {
+    DW_TAG_padding = 0x00,
+    DW_TAG_array_type = 0x01,
+    DW_TAG_class_type = 0x02,
+    DW_TAG_entry_point = 0x03,
+    DW_TAG_enumeration_type = 0x04,
+    DW_TAG_formal_parameter = 0x05,
+    DW_TAG_imported_declaration = 0x08,
+    DW_TAG_label = 0x0a,
+    DW_TAG_lexical_block = 0x0b,
+    DW_TAG_member = 0x0d,
+    DW_TAG_pointer_type = 0x0f,
+    DW_TAG_reference_type = 0x10,
+    DW_TAG_compile_unit = 0x11,
+    DW_TAG_string_type = 0x12,
+    DW_TAG_structure_type = 0x13,
+    DW_TAG_subroutine_type = 0x15,
+    DW_TAG_typedef = 0x16,
+    DW_TAG_union_type = 0x17,
+    DW_TAG_unspecified_parameters = 0x18,
+    DW_TAG_variant = 0x19,
+    DW_TAG_common_block = 0x1a,
+    DW_TAG_common_inclusion = 0x1b,
+    DW_TAG_inheritance = 0x1c,
+    DW_TAG_inlined_subroutine = 0x1d,
+    DW_TAG_module = 0x1e,
+    DW_TAG_ptr_to_member_type = 0x1f,
+    DW_TAG_set_type = 0x20,
+    DW_TAG_subrange_type = 0x21,
+    DW_TAG_with_stmt = 0x22,
+    DW_TAG_access_declaration = 0x23,
+    DW_TAG_base_type = 0x24,
+    DW_TAG_catch_block = 0x25,
+    DW_TAG_const_type = 0x26,
+    DW_TAG_constant = 0x27,
+    DW_TAG_enumerator = 0x28,
+    DW_TAG_file_type = 0x29,
+    DW_TAG_friend = 0x2a,
+    DW_TAG_namelist = 0x2b,
+    DW_TAG_namelist_item = 0x2c,
+    DW_TAG_packed_type = 0x2d,
+    DW_TAG_subprogram = 0x2e,
+    DW_TAG_template_type_param = 0x2f,
+    DW_TAG_template_value_param = 0x30,
+    DW_TAG_thrown_type = 0x31,
+    DW_TAG_try_block = 0x32,
+    DW_TAG_variant_part = 0x33,
+    DW_TAG_variable = 0x34,
+    DW_TAG_volatile_type = 0x35,
+    /* DWARF 3.  */
+    DW_TAG_dwarf_procedure = 0x36,
+    DW_TAG_restrict_type = 0x37,
+    DW_TAG_interface_type = 0x38,
+    DW_TAG_namespace = 0x39,
+    DW_TAG_imported_module = 0x3a,
+    DW_TAG_unspecified_type = 0x3b,
+    DW_TAG_partial_unit = 0x3c,
+    DW_TAG_imported_unit = 0x3d,
+    /* SGI/MIPS Extensions.  */
+    DW_TAG_MIPS_loop = 0x4081,
+    /* HP extensions.  See: ftp://ftp.hp.com/pub/lang/tools/WDB/wdb-4.0.tar.gz .  */
+    DW_TAG_HP_array_descriptor = 0x4090,
+    /* GNU extensions.  */
+    DW_TAG_format_label = 0x4101,	/* For FORTRAN 77 and Fortran 90.  */
+    DW_TAG_function_template = 0x4102,	/* For C++.  */
+    DW_TAG_class_template = 0x4103,	/* For C++.  */
+    DW_TAG_GNU_BINCL = 0x4104,
+    DW_TAG_GNU_EINCL = 0x4105,
+    /* Extensions for UPC.  See: http://upc.gwu.edu/~upc.  */
+    DW_TAG_upc_shared_type = 0x8765,
+    DW_TAG_upc_strict_type = 0x8766,
+    DW_TAG_upc_relaxed_type = 0x8767,
+    /* PGI (STMicroelectronics) extensions.  No documentation available.  */
+    DW_TAG_PGI_kanji_type      = 0xA000,
+    DW_TAG_PGI_interface_block = 0xA020
+  };
+
+#define DW_TAG_lo_user	0x4080
+#define DW_TAG_hi_user	0xffff
+
+/* Flag that tells whether entry has a child or not.  */
+#define DW_children_no   0
+#define	DW_children_yes  1
+
+/* Form names and codes.  */
+enum dwarf_form
+  {
+    DW_FORM_addr = 0x01,
+    DW_FORM_block2 = 0x03,
+    DW_FORM_block4 = 0x04,
+    DW_FORM_data2 = 0x05,
+    DW_FORM_data4 = 0x06,
+    DW_FORM_data8 = 0x07,
+    DW_FORM_string = 0x08,
+    DW_FORM_block = 0x09,
+    DW_FORM_block1 = 0x0a,
+    DW_FORM_data1 = 0x0b,
+    DW_FORM_flag = 0x0c,
+    DW_FORM_sdata = 0x0d,
+    DW_FORM_strp = 0x0e,
+    DW_FORM_udata = 0x0f,
+    DW_FORM_ref_addr = 0x10,
+    DW_FORM_ref1 = 0x11,
+    DW_FORM_ref2 = 0x12,
+    DW_FORM_ref4 = 0x13,
+    DW_FORM_ref8 = 0x14,
+    DW_FORM_ref_udata = 0x15,
+    DW_FORM_indirect = 0x16
+  };
+
+/* Attribute names and codes.  */
+enum dwarf_attribute
+  {
+    DW_AT_sibling = 0x01,
+    DW_AT_location = 0x02,
+    DW_AT_name = 0x03,
+    DW_AT_ordering = 0x09,
+    DW_AT_subscr_data = 0x0a,
+    DW_AT_byte_size = 0x0b,
+    DW_AT_bit_offset = 0x0c,
+    DW_AT_bit_size = 0x0d,
+    DW_AT_element_list = 0x0f,
+    DW_AT_stmt_list = 0x10,
+    DW_AT_low_pc = 0x11,
+    DW_AT_high_pc = 0x12,
+    DW_AT_language = 0x13,
+    DW_AT_member = 0x14,
+    DW_AT_discr = 0x15,
+    DW_AT_discr_value = 0x16,
+    DW_AT_visibility = 0x17,
+    DW_AT_import = 0x18,
+    DW_AT_string_length = 0x19,
+    DW_AT_common_reference = 0x1a,
+    DW_AT_comp_dir = 0x1b,
+    DW_AT_const_value = 0x1c,
+    DW_AT_containing_type = 0x1d,
+    DW_AT_default_value = 0x1e,
+    DW_AT_inline = 0x20,
+    DW_AT_is_optional = 0x21,
+    DW_AT_lower_bound = 0x22,
+    DW_AT_producer = 0x25,
+    DW_AT_prototyped = 0x27,
+    DW_AT_return_addr = 0x2a,
+    DW_AT_start_scope = 0x2c,
+    DW_AT_stride_size = 0x2e,
+    DW_AT_upper_bound = 0x2f,
+    DW_AT_abstract_origin = 0x31,
+    DW_AT_accessibility = 0x32,
+    DW_AT_address_class = 0x33,
+    DW_AT_artificial = 0x34,
+    DW_AT_base_types = 0x35,
+    DW_AT_calling_convention = 0x36,
+    DW_AT_count = 0x37,
+    DW_AT_data_member_location = 0x38,
+    DW_AT_decl_column = 0x39,
+    DW_AT_decl_file = 0x3a,
+    DW_AT_decl_line = 0x3b,
+    DW_AT_declaration = 0x3c,
+    DW_AT_discr_list = 0x3d,
+    DW_AT_encoding = 0x3e,
+    DW_AT_external = 0x3f,
+    DW_AT_frame_base = 0x40,
+    DW_AT_friend = 0x41,
+    DW_AT_identifier_case = 0x42,
+    DW_AT_macro_info = 0x43,
+    DW_AT_namelist_items = 0x44,
+    DW_AT_priority = 0x45,
+    DW_AT_segment = 0x46,
+    DW_AT_specification = 0x47,
+    DW_AT_static_link = 0x48,
+    DW_AT_type = 0x49,
+    DW_AT_use_location = 0x4a,
+    DW_AT_variable_parameter = 0x4b,
+    DW_AT_virtuality = 0x4c,
+    DW_AT_vtable_elem_location = 0x4d,
+    /* DWARF 3 values.  */
+    DW_AT_allocated     = 0x4e,
+    DW_AT_associated    = 0x4f,
+    DW_AT_data_location = 0x50,
+    DW_AT_stride        = 0x51,
+    DW_AT_entry_pc      = 0x52,
+    DW_AT_use_UTF8      = 0x53,
+    DW_AT_extension     = 0x54,
+    DW_AT_ranges        = 0x55,
+    DW_AT_trampoline    = 0x56,
+    DW_AT_call_column   = 0x57,
+    DW_AT_call_file     = 0x58,
+    DW_AT_call_line     = 0x59,
+    /* SGI/MIPS extensions.  */
+    DW_AT_MIPS_fde = 0x2001,
+    DW_AT_MIPS_loop_begin = 0x2002,
+    DW_AT_MIPS_tail_loop_begin = 0x2003,
+    DW_AT_MIPS_epilog_begin = 0x2004,
+    DW_AT_MIPS_loop_unroll_factor = 0x2005,
+    DW_AT_MIPS_software_pipeline_depth = 0x2006,
+    DW_AT_MIPS_linkage_name = 0x2007,
+    DW_AT_MIPS_stride = 0x2008,
+    DW_AT_MIPS_abstract_name = 0x2009,
+    DW_AT_MIPS_clone_origin = 0x200a,
+    DW_AT_MIPS_has_inlines = 0x200b,
+    /* HP extensions.  */
+    DW_AT_HP_block_index         = 0x2000,
+    DW_AT_HP_unmodifiable        = 0x2001, /* Same as DW_AT_MIPS_fde.  */
+    DW_AT_HP_actuals_stmt_list   = 0x2010,
+    DW_AT_HP_proc_per_section    = 0x2011,
+    DW_AT_HP_raw_data_ptr        = 0x2012,
+    DW_AT_HP_pass_by_reference   = 0x2013,
+    DW_AT_HP_opt_level           = 0x2014,
+    DW_AT_HP_prof_version_id     = 0x2015,
+    DW_AT_HP_opt_flags           = 0x2016,
+    DW_AT_HP_cold_region_low_pc  = 0x2017,
+    DW_AT_HP_cold_region_high_pc = 0x2018,
+    DW_AT_HP_all_variables_modifiable = 0x2019,
+    DW_AT_HP_linkage_name        = 0x201a,
+    DW_AT_HP_prof_flags          = 0x201b,  /* In comp unit of procs_info for -g.  */
+    /* GNU extensions.  */
+    DW_AT_sf_names   = 0x2101,
+    DW_AT_src_info   = 0x2102,
+    DW_AT_mac_info   = 0x2103,
+    DW_AT_src_coords = 0x2104,
+    DW_AT_body_begin = 0x2105,
+    DW_AT_body_end   = 0x2106,
+    DW_AT_GNU_vector = 0x2107,
+    /* VMS extensions.  */
+    DW_AT_VMS_rtnbeg_pd_address = 0x2201,
+    /* UPC extension.  */
+    DW_AT_upc_threads_scaled = 0x3210,
+    /* PGI (STMicroelectronics) extensions.  */
+    DW_AT_PGI_lbase    = 0x3a00,
+    DW_AT_PGI_soffset  = 0x3a01,
+    DW_AT_PGI_lstride  = 0x3a02
+  };
+
+#define DW_AT_lo_user	0x2000	/* Implementation-defined range start.  */
+#define DW_AT_hi_user	0x3ff0	/* Implementation-defined range end.  */
+
+/* Location atom names and codes.  */
+enum dwarf_location_atom
+  {
+    DW_OP_addr = 0x03,
+    DW_OP_deref = 0x06,
+    DW_OP_const1u = 0x08,
+    DW_OP_const1s = 0x09,
+    DW_OP_const2u = 0x0a,
+    DW_OP_const2s = 0x0b,
+    DW_OP_const4u = 0x0c,
+    DW_OP_const4s = 0x0d,
+    DW_OP_const8u = 0x0e,
+    DW_OP_const8s = 0x0f,
+    DW_OP_constu = 0x10,
+    DW_OP_consts = 0x11,
+    DW_OP_dup = 0x12,
+    DW_OP_drop = 0x13,
+    DW_OP_over = 0x14,
+    DW_OP_pick = 0x15,
+    DW_OP_swap = 0x16,
+    DW_OP_rot = 0x17,
+    DW_OP_xderef = 0x18,
+    DW_OP_abs = 0x19,
+    DW_OP_and = 0x1a,
+    DW_OP_div = 0x1b,
+    DW_OP_minus = 0x1c,
+    DW_OP_mod = 0x1d,
+    DW_OP_mul = 0x1e,
+    DW_OP_neg = 0x1f,
+    DW_OP_not = 0x20,
+    DW_OP_or = 0x21,
+    DW_OP_plus = 0x22,
+    DW_OP_plus_uconst = 0x23,
+    DW_OP_shl = 0x24,
+    DW_OP_shr = 0x25,
+    DW_OP_shra = 0x26,
+    DW_OP_xor = 0x27,
+    DW_OP_bra = 0x28,
+    DW_OP_eq = 0x29,
+    DW_OP_ge = 0x2a,
+    DW_OP_gt = 0x2b,
+    DW_OP_le = 0x2c,
+    DW_OP_lt = 0x2d,
+    DW_OP_ne = 0x2e,
+    DW_OP_skip = 0x2f,
+    DW_OP_lit0 = 0x30,
+    DW_OP_lit1 = 0x31,
+    DW_OP_lit2 = 0x32,
+    DW_OP_lit3 = 0x33,
+    DW_OP_lit4 = 0x34,
+    DW_OP_lit5 = 0x35,
+    DW_OP_lit6 = 0x36,
+    DW_OP_lit7 = 0x37,
+    DW_OP_lit8 = 0x38,
+    DW_OP_lit9 = 0x39,
+    DW_OP_lit10 = 0x3a,
+    DW_OP_lit11 = 0x3b,
+    DW_OP_lit12 = 0x3c,
+    DW_OP_lit13 = 0x3d,
+    DW_OP_lit14 = 0x3e,
+    DW_OP_lit15 = 0x3f,
+    DW_OP_lit16 = 0x40,
+    DW_OP_lit17 = 0x41,
+    DW_OP_lit18 = 0x42,
+    DW_OP_lit19 = 0x43,
+    DW_OP_lit20 = 0x44,
+    DW_OP_lit21 = 0x45,
+    DW_OP_lit22 = 0x46,
+    DW_OP_lit23 = 0x47,
+    DW_OP_lit24 = 0x48,
+    DW_OP_lit25 = 0x49,
+    DW_OP_lit26 = 0x4a,
+    DW_OP_lit27 = 0x4b,
+    DW_OP_lit28 = 0x4c,
+    DW_OP_lit29 = 0x4d,
+    DW_OP_lit30 = 0x4e,
+    DW_OP_lit31 = 0x4f,
+    DW_OP_reg0 = 0x50,
+    DW_OP_reg1 = 0x51,
+    DW_OP_reg2 = 0x52,
+    DW_OP_reg3 = 0x53,
+    DW_OP_reg4 = 0x54,
+    DW_OP_reg5 = 0x55,
+    DW_OP_reg6 = 0x56,
+    DW_OP_reg7 = 0x57,
+    DW_OP_reg8 = 0x58,
+    DW_OP_reg9 = 0x59,
+    DW_OP_reg10 = 0x5a,
+    DW_OP_reg11 = 0x5b,
+    DW_OP_reg12 = 0x5c,
+    DW_OP_reg13 = 0x5d,
+    DW_OP_reg14 = 0x5e,
+    DW_OP_reg15 = 0x5f,
+    DW_OP_reg16 = 0x60,
+    DW_OP_reg17 = 0x61,
+    DW_OP_reg18 = 0x62,
+    DW_OP_reg19 = 0x63,
+    DW_OP_reg20 = 0x64,
+    DW_OP_reg21 = 0x65,
+    DW_OP_reg22 = 0x66,
+    DW_OP_reg23 = 0x67,
+    DW_OP_reg24 = 0x68,
+    DW_OP_reg25 = 0x69,
+    DW_OP_reg26 = 0x6a,
+    DW_OP_reg27 = 0x6b,
+    DW_OP_reg28 = 0x6c,
+    DW_OP_reg29 = 0x6d,
+    DW_OP_reg30 = 0x6e,
+    DW_OP_reg31 = 0x6f,
+    DW_OP_breg0 = 0x70,
+    DW_OP_breg1 = 0x71,
+    DW_OP_breg2 = 0x72,
+    DW_OP_breg3 = 0x73,
+    DW_OP_breg4 = 0x74,
+    DW_OP_breg5 = 0x75,
+    DW_OP_breg6 = 0x76,
+    DW_OP_breg7 = 0x77,
+    DW_OP_breg8 = 0x78,
+    DW_OP_breg9 = 0x79,
+    DW_OP_breg10 = 0x7a,
+    DW_OP_breg11 = 0x7b,
+    DW_OP_breg12 = 0x7c,
+    DW_OP_breg13 = 0x7d,
+    DW_OP_breg14 = 0x7e,
+    DW_OP_breg15 = 0x7f,
+    DW_OP_breg16 = 0x80,
+    DW_OP_breg17 = 0x81,
+    DW_OP_breg18 = 0x82,
+    DW_OP_breg19 = 0x83,
+    DW_OP_breg20 = 0x84,
+    DW_OP_breg21 = 0x85,
+    DW_OP_breg22 = 0x86,
+    DW_OP_breg23 = 0x87,
+    DW_OP_breg24 = 0x88,
+    DW_OP_breg25 = 0x89,
+    DW_OP_breg26 = 0x8a,
+    DW_OP_breg27 = 0x8b,
+    DW_OP_breg28 = 0x8c,
+    DW_OP_breg29 = 0x8d,
+    DW_OP_breg30 = 0x8e,
+    DW_OP_breg31 = 0x8f,
+    DW_OP_regx = 0x90,
+    DW_OP_fbreg = 0x91,
+    DW_OP_bregx = 0x92,
+    DW_OP_piece = 0x93,
+    DW_OP_deref_size = 0x94,
+    DW_OP_xderef_size = 0x95,
+    DW_OP_nop = 0x96,
+    /* DWARF 3 extensions.  */
+    DW_OP_push_object_address = 0x97,
+    DW_OP_call2 = 0x98,
+    DW_OP_call4 = 0x99,
+    DW_OP_call_ref = 0x9a,
+    /* GNU extensions.  */
+    DW_OP_GNU_push_tls_address = 0xe0,
+    /* HP extensions.  */
+    DW_OP_HP_unknown     = 0xe0, /* Ouch, the same as GNU_push_tls_address.  */
+    DW_OP_HP_is_value    = 0xe1,
+    DW_OP_HP_fltconst4   = 0xe2,
+    DW_OP_HP_fltconst8   = 0xe3,
+    DW_OP_HP_mod_range   = 0xe4,
+    DW_OP_HP_unmod_range = 0xe5,
+    DW_OP_HP_tls         = 0xe6
+  };
+
+#define DW_OP_lo_user	0xe0	/* Implementation-defined range start.  */
+#define DW_OP_hi_user	0xff	/* Implementation-defined range end.  */
+
+/* Type encodings.  */
+enum dwarf_type
+  {
+    DW_ATE_void = 0x0,
+    DW_ATE_address = 0x1,
+    DW_ATE_boolean = 0x2,
+    DW_ATE_complex_float = 0x3,
+    DW_ATE_float = 0x4,
+    DW_ATE_signed = 0x5,
+    DW_ATE_signed_char = 0x6,
+    DW_ATE_unsigned = 0x7,
+    DW_ATE_unsigned_char = 0x8,
+    /* DWARF 3.  */
+    DW_ATE_imaginary_float = 0x9,
+    /* HP extensions.  */
+    DW_ATE_HP_float80            = 0x80, /* Floating-point (80 bit).  */
+    DW_ATE_HP_complex_float80    = 0x81, /* Complex floating-point (80 bit).  */
+    DW_ATE_HP_float128           = 0x82, /* Floating-point (128 bit).  */
+    DW_ATE_HP_complex_float128   = 0x83, /* Complex floating-point (128 bit).  */
+    DW_ATE_HP_floathpintel       = 0x84, /* Floating-point (82 bit IA64).  */
+    DW_ATE_HP_imaginary_float80  = 0x85,
+    DW_ATE_HP_imaginary_float128 = 0x86
+  };
+
+#define	DW_ATE_lo_user 0x80
+#define	DW_ATE_hi_user 0xff
+
+/* Array ordering names and codes.  */
+enum dwarf_array_dim_ordering
+  {
+    DW_ORD_row_major = 0,
+    DW_ORD_col_major = 1
+  };
+
+/* Access attribute.  */
+enum dwarf_access_attribute
+  {
+    DW_ACCESS_public = 1,
+    DW_ACCESS_protected = 2,
+    DW_ACCESS_private = 3
+  };
+
+/* Visibility.  */
+enum dwarf_visibility_attribute
+  {
+    DW_VIS_local = 1,
+    DW_VIS_exported = 2,
+    DW_VIS_qualified = 3
+  };
+
+/* Virtuality.  */
+enum dwarf_virtuality_attribute
+  {
+    DW_VIRTUALITY_none = 0,
+    DW_VIRTUALITY_virtual = 1,
+    DW_VIRTUALITY_pure_virtual = 2
+  };
+
+/* Case sensitivity.  */
+enum dwarf_id_case
+  {
+    DW_ID_case_sensitive = 0,
+    DW_ID_up_case = 1,
+    DW_ID_down_case = 2,
+    DW_ID_case_insensitive = 3
+  };
+
+/* Calling convention.  */
+enum dwarf_calling_convention
+  {
+    DW_CC_normal = 0x1,
+    DW_CC_program = 0x2,
+    DW_CC_nocall = 0x3
+  };
+
+#define DW_CC_lo_user 0x40
+#define DW_CC_hi_user 0xff
+
+/* Inline attribute.  */
+enum dwarf_inline_attribute
+  {
+    DW_INL_not_inlined = 0,
+    DW_INL_inlined = 1,
+    DW_INL_declared_not_inlined = 2,
+    DW_INL_declared_inlined = 3
+  };
+
+/* Discriminant lists.  */
+enum dwarf_discrim_list
+  {
+    DW_DSC_label = 0,
+    DW_DSC_range = 1
+  };
+
+/* Line number opcodes.  */
+enum dwarf_line_number_ops
+  {
+    DW_LNS_extended_op = 0,
+    DW_LNS_copy = 1,
+    DW_LNS_advance_pc = 2,
+    DW_LNS_advance_line = 3,
+    DW_LNS_set_file = 4,
+    DW_LNS_set_column = 5,
+    DW_LNS_negate_stmt = 6,
+    DW_LNS_set_basic_block = 7,
+    DW_LNS_const_add_pc = 8,
+    DW_LNS_fixed_advance_pc = 9,
+    /* DWARF 3.  */
+    DW_LNS_set_prologue_end = 10,
+    DW_LNS_set_epilogue_begin = 11,
+    DW_LNS_set_isa = 12
+  };
+
+/* Line number extended opcodes.  */
+enum dwarf_line_number_x_ops
+  {
+    DW_LNE_end_sequence = 1,
+    DW_LNE_set_address = 2,
+    DW_LNE_define_file = 3,
+    /* HP extensions.  */
+    DW_LNE_HP_negate_is_UV_update      = 0x11,
+    DW_LNE_HP_push_context             = 0x12,
+    DW_LNE_HP_pop_context              = 0x13,
+    DW_LNE_HP_set_file_line_column     = 0x14,
+    DW_LNE_HP_set_routine_name         = 0x15,
+    DW_LNE_HP_set_sequence             = 0x16,
+    DW_LNE_HP_negate_post_semantics    = 0x17,
+    DW_LNE_HP_negate_function_exit     = 0x18,
+    DW_LNE_HP_negate_front_end_logical = 0x19,
+    DW_LNE_HP_define_proc              = 0x20
+  };
+
+/* Call frame information.  */
+enum dwarf_call_frame_info
+  {
+    DW_CFA_advance_loc = 0x40,
+    DW_CFA_offset = 0x80,
+    DW_CFA_restore = 0xc0,
+    DW_CFA_nop = 0x00,
+    DW_CFA_set_loc = 0x01,
+    DW_CFA_advance_loc1 = 0x02,
+    DW_CFA_advance_loc2 = 0x03,
+    DW_CFA_advance_loc4 = 0x04,
+    DW_CFA_offset_extended = 0x05,
+    DW_CFA_restore_extended = 0x06,
+    DW_CFA_undefined = 0x07,
+    DW_CFA_same_value = 0x08,
+    DW_CFA_register = 0x09,
+    DW_CFA_remember_state = 0x0a,
+    DW_CFA_restore_state = 0x0b,
+    DW_CFA_def_cfa = 0x0c,
+    DW_CFA_def_cfa_register = 0x0d,
+    DW_CFA_def_cfa_offset = 0x0e,
+    /* DWARF 3.  */
+    DW_CFA_def_cfa_expression = 0x0f,
+    DW_CFA_expression = 0x10,
+    DW_CFA_offset_extended_sf = 0x11,
+    DW_CFA_def_cfa_sf = 0x12,
+    DW_CFA_def_cfa_offset_sf = 0x13,
+    /* SGI/MIPS specific.  */
+    DW_CFA_MIPS_advance_loc8 = 0x1d,
+    /* GNU extensions.  */
+    DW_CFA_GNU_window_save = 0x2d,
+    DW_CFA_GNU_args_size = 0x2e,
+    DW_CFA_GNU_negative_offset_extended = 0x2f
+  };
+
+#define DW_CIE_ID	  0xffffffff
+#define DW_CIE_VERSION	  1
+
+#define DW_CFA_extended   0
+#define DW_CFA_lo_user    0x1c
+#define DW_CFA_hi_user    0x3f
+
+#define DW_CHILDREN_no		     0x00
+#define DW_CHILDREN_yes		     0x01
+
+#define DW_ADDR_none		0
+
+/* Source language names and codes.  */
+enum dwarf_source_language
+  {
+    DW_LANG_C89 = 0x0001,
+    DW_LANG_C = 0x0002,
+    DW_LANG_Ada83 = 0x0003,
+    DW_LANG_C_plus_plus = 0x0004,
+    DW_LANG_Cobol74 = 0x0005,
+    DW_LANG_Cobol85 = 0x0006,
+    DW_LANG_Fortran77 = 0x0007,
+    DW_LANG_Fortran90 = 0x0008,
+    DW_LANG_Pascal83 = 0x0009,
+    DW_LANG_Modula2 = 0x000a,
+    DW_LANG_Java = 0x000b,
+    /* DWARF 3.  */
+    DW_LANG_C99 = 0x000c,
+    DW_LANG_Ada95 = 0x000d,
+    DW_LANG_Fortran95 = 0x000e,
+    /* MIPS.  */
+    DW_LANG_Mips_Assembler = 0x8001,
+    /* UPC.  */
+    DW_LANG_Upc = 0x8765
+  };
+
+#define DW_LANG_lo_user 0x8000	/* Implementation-defined range start.  */
+#define DW_LANG_hi_user 0xffff	/* Implementation-defined range start.  */
+
+/* Names and codes for macro information.  */
+enum dwarf_macinfo_record_type
+  {
+    DW_MACINFO_define = 1,
+    DW_MACINFO_undef = 2,
+    DW_MACINFO_start_file = 3,
+    DW_MACINFO_end_file = 4,
+    DW_MACINFO_vendor_ext = 255
+  };
+
+/* @@@ For use with GNU frame unwind information.  */
+
+#define DW_EH_PE_absptr		0x00
+#define DW_EH_PE_omit		0xff
+
+#define DW_EH_PE_uleb128	0x01
+#define DW_EH_PE_udata2		0x02
+#define DW_EH_PE_udata4		0x03
+#define DW_EH_PE_udata8		0x04
+#define DW_EH_PE_sleb128	0x09
+#define DW_EH_PE_sdata2		0x0A
+#define DW_EH_PE_sdata4		0x0B
+#define DW_EH_PE_sdata8		0x0C
+#define DW_EH_PE_signed		0x08
+
+#define DW_EH_PE_pcrel		0x10
+#define DW_EH_PE_textrel	0x20
+#define DW_EH_PE_datarel	0x30
+#define DW_EH_PE_funcrel	0x40
+#define DW_EH_PE_aligned	0x50
+
+#define DW_EH_PE_indirect	0x80
+
+#endif /* _ELF_DWARF2_H */
diff --git a/include/linux/i2c-algo-palm.h b/include/linux/i2c-algo-palm.h
new file mode 100644
index 0000000..ab57cc7
--- /dev/null
+++ b/include/linux/i2c-algo-palm.h
@@ -0,0 +1,53 @@
+
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/*
+ *  i2c-algo-palm.c i2c driver algorithms for the BK3220 I2C Host 
+ *  adapter on the RMI Phoenix System.
+ *  Derived from the PCA-ISA I2C-Algo/Bus files.
+ */
+
+#ifndef _LINUX_I2C_ALGO_PALM_H
+#define _LINUX_I2C_ALGO_PALM_H
+
+#define WORD	1
+
+struct i2c_algo_palm_data {
+	void (*write)(int ctl, int val);
+	int  (*read) (int ctl);
+};
+
+#define I2C_PCA_ADAP_MAX	16
+
+int i2c_palm_add_bus(struct i2c_adapter *);
+int i2c_palm_del_bus(struct i2c_adapter *);
+
+#endif /* _LINUX_I2C_ALGO_PALM_H */
diff --git a/include/linux/i2c.h b/include/linux/i2c.h
index 195d8b3..43f131f 100644
--- a/include/linux/i2c.h
+++ b/include/linux/i2c.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /* ------------------------------------------------------------------------- */
 /*									     */
 /* i2c.h - definitions for the i2c-bus interface			     */
@@ -545,6 +557,7 @@ struct i2c_msg {
 #define I2C_M_IGNORE_NAK	0x1000	/* if I2C_FUNC_PROTOCOL_MANGLING */
 #define I2C_M_NO_RD_ACK		0x0800	/* if I2C_FUNC_PROTOCOL_MANGLING */
 #define I2C_M_RECV_LEN		0x0400	/* length will be first received byte */
+	__u16 offset;
 	__u16 len;		/* msg length				*/
 	__u8 *buf;		/* pointer to msg data			*/
 };
diff --git a/include/linux/libata.h b/include/linux/libata.h
index 6e887c7..eb46f8e 100644
--- a/include/linux/libata.h
+++ b/include/linux/libata.h
@@ -55,7 +55,7 @@
  */
 #undef ATA_DEBUG		/* debugging output */
 #undef ATA_VERBOSE_DEBUG	/* yet more debugging output */
-#undef ATA_IRQ_TRAP		/* define to ack screaming irqs */
+#define ATA_IRQ_TRAP		/* define to ack screaming irqs */
 #undef ATA_NDEBUG		/* define to disable quick runtime checks */
 
 
diff --git a/include/linux/linkage.h b/include/linux/linkage.h
index 807f1e5..f10d848 100644
--- a/include/linux/linkage.h
+++ b/include/linux/linkage.h
@@ -54,13 +54,13 @@
 #ifdef __ASSEMBLY__
 
 #ifndef LINKER_SCRIPT
-#define ALIGN __ALIGN
-#define ALIGN_STR __ALIGN_STR
+#define ASM_ALIGN __ALIGN
+#define ASM_ALIGN_STR __ALIGN_STR
 
 #ifndef ENTRY
 #define ENTRY(name) \
   .globl name; \
-  ALIGN; \
+  ASM_ALIGN; \
   name:
 #endif
 #endif /* LINKER_SCRIPT */
diff --git a/include/linux/memblk.h b/include/linux/memblk.h
new file mode 100644
index 0000000..421642b
--- /dev/null
+++ b/include/linux/memblk.h
@@ -0,0 +1,55 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without 
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE 
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE. 
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/list.h>
+
+#define NTLBSZ 5
+
+typedef struct list_head list_t;
+
+struct memblk_list {
+	list_t list;
+	unsigned long align;
+};
+
+typedef struct memblk_list memblk_list_t;
+
+struct memblk {
+	list_t list;
+	uint64_t addr;
+	uint64_t size;
+};
+
+typedef struct memblk memblk_t;
+
+extern unsigned int vaddr_max_tlb_size(unsigned long addr);
+
+extern int add_memblk(uint64_t addr, uint64_t size);
+extern uint64_t __find_memblk(unsigned long page_size);
diff --git a/include/linux/mm.h b/include/linux/mm.h
index 441a564..075dd11 100644
--- a/include/linux/mm.h
+++ b/include/linux/mm.h
@@ -1421,8 +1421,13 @@ int write_one_page(struct page *page, int wait);
 void task_dirty_inc(struct task_struct *tsk);
 
 /* readahead.c */
+#ifndef CONFIG_RMI_NAS
 #define VM_MAX_READAHEAD	128	/* kbytes */
 #define VM_MIN_READAHEAD	16	/* kbytes (includes current page) */
+#else
+#define VM_MAX_READAHEAD	1024	/* kbytes */
+#define VM_MIN_READAHEAD	32	/* kbytes (includes current page) */
+#endif
 
 int force_page_cache_readahead(struct address_space *mapping, struct file *filp,
 			pgoff_t offset, unsigned long nr_to_read);
diff --git a/include/linux/mtd/map.h b/include/linux/mtd/map.h
index 3595a02..c73465e 100644
--- a/include/linux/mtd/map.h
+++ b/include/linux/mtd/map.h
@@ -392,6 +392,12 @@ static inline map_word map_word_ff(struct map_info *map)
 static inline map_word inline_map_read(struct map_info *map, unsigned long ofs)
 {
 	map_word r;
+#ifdef CONFIG_RMI_PHOENIX
+	unsigned int flags=0;
+	
+	flags = rmi_br_read_lock();
+
+#endif
 
 	if (map_bankwidth_is_1(map))
 		r.x[0] = __raw_readb(map->virt + ofs);
@@ -408,11 +414,20 @@ static inline map_word inline_map_read(struct map_info *map, unsigned long ofs)
 	else
 		BUG();
 
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_br_read_unlock(flags);
+#endif
 	return r;
 }
 
 static inline void inline_map_write(struct map_info *map, const map_word datum, unsigned long ofs)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	unsigned int flags=0;
+	
+	flags = rmi_br_write_lock();
+
+#endif
 	if (map_bankwidth_is_1(map))
 		__raw_writeb(datum.x[0], map->virt + ofs);
 	else if (map_bankwidth_is_2(map))
@@ -426,19 +441,38 @@ static inline void inline_map_write(struct map_info *map, const map_word datum,
 	else if (map_bankwidth_is_large(map))
 		memcpy_toio(map->virt+ofs, datum.x, map->bankwidth);
 	mb();
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_br_write_unlock(flags);
+#endif
 }
 
 static inline void inline_map_copy_from(struct map_info *map, void *to, unsigned long from, ssize_t len)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	unsigned int flags=0;
+	
+	flags = rmi_br_write_lock();
+#endif
 	if (map->cached)
 		memcpy(to, (char *)map->cached + from, len);
 	else
 		memcpy_fromio(to, map->virt + from, len);
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_br_write_unlock(flags);
+#endif
 }
 
 static inline void inline_map_copy_to(struct map_info *map, unsigned long to, const void *from, ssize_t len)
 {
+#ifdef CONFIG_RMI_PHOENIX
+	unsigned int flags=0;
+	
+	flags = rmi_br_write_lock();
+#endif
 	memcpy_toio(map->virt + to, from, len);
+#ifdef CONFIG_RMI_PHOENIX
+	rmi_br_write_unlock(flags);
+#endif
 }
 
 #ifdef CONFIG_MTD_COMPLEX_MAPPINGS
diff --git a/include/linux/oprofile.h b/include/linux/oprofile.h
index a4c5624..c5e16b2 100644
--- a/include/linux/oprofile.h
+++ b/include/linux/oprofile.h
@@ -177,6 +177,8 @@ void oprofile_put_buff(unsigned long *buf, unsigned int start,
 unsigned long oprofile_get_cpu_buffer_size(void);
 void oprofile_cpu_buffer_inc_smpl_lost(void);
  
+void phoenix_oprofile_int_handler(int irq, void * dev_id, struct pt_regs *regs);
+
 /* cpu buffer functions */
 
 struct op_sample;
diff --git a/include/linux/pci.h b/include/linux/pci.h
index e444f5b..8d524cc 100644
--- a/include/linux/pci.h
+++ b/include/linux/pci.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: Basic Defines for MSI support for RMI Eval Board
+
+ *****************************#RMI_1#************************************/
+
 /*
  *	pci.h
  *
@@ -333,7 +345,7 @@ struct pci_dev {
 	int rom_attr_enabled;		/* has display of the rom attribute been enabled? */
 	struct bin_attribute *res_attr[DEVICE_COUNT_RESOURCE]; /* sysfs file for resources */
 	struct bin_attribute *res_attr_wc[DEVICE_COUNT_RESOURCE]; /* sysfs file for WC mapping of resources */
-#ifdef CONFIG_PCI_MSI
+#if defined(CONFIG_PCI_MSI) || defined(CONFIG_PCI_MSI_XLR)
 	struct list_head msi_list;
 	struct kset *msi_kset;
 #endif
@@ -1011,7 +1023,7 @@ struct msix_entry {
 };
 
 
-#ifndef CONFIG_PCI_MSI
+#if (!defined(CONFIG_PCI_MSI) && !defined(CONFIG_PCI_MSI_XLR))
 static inline int pci_enable_msi_block(struct pci_dev *dev, unsigned int nvec)
 {
 	return -1;
diff --git a/include/linux/perfctr.h b/include/linux/perfctr.h
new file mode 100644
index 0000000..f2fcb7e
--- /dev/null
+++ b/include/linux/perfctr.h
@@ -0,0 +1,202 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
+/* $Id: perfctr.h,v 1.1.2.4 2006-09-28 01:24:22 nphilips Exp $
+ * Performance-Monitoring Counters driver
+ *
+ * Copyright (C) 1999-2004  Mikael Pettersson
+ */
+#ifndef _LINUX_PERFCTR_H
+#define _LINUX_PERFCTR_H
+
+#ifdef CONFIG_PERFCTR	/* don't break archs without <asm/perfctr.h> */
+
+#include <asm/perfctr.h>
+
+// Ensure that the following constant doesn't conflict constants specified
+// for other entries in "/proc/sys"
+
+#define CTL_PERFCTR	171
+
+// Extend the following enum type if more entries have to be created under
+// "/proc/sys/perfctr"
+
+enum {
+	PERFCTR_CNTMODE = 1
+};
+
+struct perfctr_info {
+	unsigned int abi_version;
+	char driver_version[32];
+	unsigned int cpu_type;
+	unsigned int cpu_features;
+	unsigned int cpu_khz;
+	unsigned int tsc_to_cpu_mult;
+	unsigned int _reserved2;
+	unsigned int _reserved3;
+	unsigned int _reserved4;
+};
+
+struct perfctr_cpu_mask {
+	unsigned int nrwords;
+	unsigned int mask[1];	/* actually 'nrwords' */
+};
+
+/* abi_version values: Lower 16 bits contain the CPU data version, upper
+   16 bits contain the API version. Each half has a major version in its
+   upper 8 bits, and a minor version in its lower 8 bits. */
+#define PERFCTR_API_VERSION	0x0600	/* 6.0 */
+#define PERFCTR_ABI_VERSION	((PERFCTR_API_VERSION<<16)|PERFCTR_CPU_VERSION)
+
+/* cpu_features flag bits */
+#define PERFCTR_FEATURE_RDPMC	0x01
+#define PERFCTR_FEATURE_RDTSC	0x02
+#define PERFCTR_FEATURE_PCINT	0x04
+
+/* user's view of mmap:ed virtual perfctr */
+struct vperfctr_state {
+	struct perfctr_cpu_state cpu_state;
+};
+
+/* virtual perfctr control object */
+struct vperfctr_control {
+	int si_signo;
+	unsigned int preserve;
+	unsigned int _reserved1;
+	unsigned int _reserved2;
+	unsigned int _reserved3;
+	unsigned int _reserved4;
+	struct perfctr_cpu_control cpu_control;
+};
+
+/* commands for sys_vperfctr_read() */
+#define VPERFCTR_READ_SUM	0x01
+#define VPERFCTR_READ_CONTROL	0x02
+#define VPERFCTR_READ_CHILDREN	0x03
+
+#else
+struct perfctr_info;
+struct perfctr_cpu_mask;
+struct perfctr_sum_ctrs;
+struct vperfctr_control;
+#endif	/* CONFIG_PERFCTR */
+
+#ifdef __KERNEL__
+
+/*
+ * The perfctr system calls.
+ */
+asmlinkage long sys_vperfctr_open(int tid, int creat);
+asmlinkage long sys_vperfctr_control(int fd,
+				     const struct vperfctr_control __user *argp,
+				     unsigned int argbytes);
+asmlinkage long sys_vperfctr_unlink(int fd);
+asmlinkage long sys_vperfctr_iresume(int fd);
+asmlinkage long sys_vperfctr_read(int fd, unsigned int cmd, void __user *argp, unsigned int argbytes);
+
+extern struct perfctr_info perfctr_info;
+
+#ifdef CONFIG_PERFCTR_VIRTUAL
+
+/*
+ * Virtual per-process performance-monitoring counters.
+ */
+struct vperfctr;	/* opaque */
+
+/* process management operations */
+extern void __vperfctr_copy(struct task_struct*, struct pt_regs*);
+extern void __vperfctr_release(struct task_struct*);
+extern void __vperfctr_exit(struct vperfctr*);
+extern void __vperfctr_suspend(struct vperfctr*);
+extern void __vperfctr_resume(struct vperfctr*);
+extern void __vperfctr_sample(struct vperfctr*);
+extern void __vperfctr_set_cpus_allowed(struct task_struct*, struct vperfctr*, cpumask_t);
+
+static inline void perfctr_copy_task(struct task_struct *tsk, struct pt_regs *regs)
+{
+	if (tsk->thread.perfctr) {
+		__vperfctr_copy(tsk, regs);
+	}
+}
+
+static inline void perfctr_release_task(struct task_struct *tsk)
+{
+	if (tsk->thread.perfctr) {
+		__vperfctr_release(tsk);
+	}
+}
+
+static inline void perfctr_exit_thread(struct thread_struct *thread)
+{
+	struct vperfctr *perfctr;
+	perfctr = thread->perfctr;
+	if (perfctr) {
+		__vperfctr_exit(perfctr);
+	}
+}
+
+static inline void perfctr_suspend_thread(struct thread_struct *prev)
+{
+	struct vperfctr *perfctr;
+	perfctr = prev->perfctr;
+	if (perfctr) {
+		__vperfctr_suspend(perfctr);
+	}
+}
+
+static inline void perfctr_resume_thread(struct thread_struct *next)
+{
+	struct vperfctr *perfctr;
+	perfctr = next->perfctr;
+	if (perfctr) {
+		__vperfctr_resume(perfctr);
+	}
+}
+
+static inline void perfctr_sample_thread(struct thread_struct *thread)
+{
+	struct vperfctr *perfctr;
+	perfctr = thread->perfctr;
+	if (perfctr) {
+		__vperfctr_sample(perfctr);
+	}
+}
+
+static inline void perfctr_set_cpus_allowed(struct task_struct *p, cpumask_t new_mask)
+{
+#ifdef CONFIG_PERFCTR_CPUS_FORBIDDEN_MASK
+	struct vperfctr *perfctr;
+
+	task_lock(p);
+	perfctr = p->thread.perfctr;
+	if (perfctr) {
+		__vperfctr_set_cpus_allowed(p, perfctr, new_mask);
+	}
+	task_unlock(p);
+#endif
+}
+
+#else	/* !CONFIG_PERFCTR_VIRTUAL */
+
+static inline void perfctr_copy_task(struct task_struct *p, struct pt_regs *r) { }
+static inline void perfctr_release_task(struct task_struct *p) { }
+static inline void perfctr_exit_thread(struct thread_struct *t) { }
+static inline void perfctr_suspend_thread(struct thread_struct *t) { }
+static inline void perfctr_resume_thread(struct thread_struct *t) { }
+static inline void perfctr_sample_thread(struct thread_struct *t) { }
+static inline void perfctr_set_cpus_allowed(struct task_struct *p, cpumask_t m) { }
+
+#endif	/* CONFIG_PERFCTR_VIRTUAL */
+
+#endif	/* __KERNEL__ */
+
+#endif	/* _LINUX_PERFCTR_H */
diff --git a/include/linux/phnx_tb.h b/include/linux/phnx_tb.h
new file mode 100644
index 0000000..ae91939
--- /dev/null
+++ b/include/linux/phnx_tb.h
@@ -0,0 +1,172 @@
+/*********************************************************************
+
+Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+reserved.
+
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions
+are met:
+
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+
+THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+
+*****************************#RMI_2#**********************************/
+#ifndef __USER_MIPS_RMI_PHNXTB_H
+#define __USER_MIPS_RMI_PHNXTB_H
+
+#include <asm/ioctl.h>
+
+/* Trace Buffer registers */
+
+#define    TB_REQMATCH_REGS         0x00
+#define    TB_REQMATCH_REG_1        0x00
+#define    TB_REQMATCH_REG_2        0x01
+#define    TB_RADDR_REGS            0x02
+#define    TB_RADDR_REG_1           0x02
+#define    TB_RADDR_REG_2           0x03
+#define    TB_CTRL_REG              0x04
+#define    TB_INIT_REG              0x05
+#define    TB_ACCESS_REG            0x06
+#define    TB_RDDATA_REGS           0x07
+#define    TB_WRDATA_REGS           0x0b
+#define    TB_STATUS_REG            0x0f
+
+// values
+#define    TB_REQMATCH_RCMD_WR             0x01
+#define    TB_REQMATCH_RCMD_RD             0x02
+#define    TB_REQMATCH_RCMD_RDEX           0x03
+#define    TB_REQMATCH_RCMD_UPGRD          0x04
+#define    TB_REQMATCH_RCMD_INV            0x05
+#define    TB_REQMATCH_RCMD_MASK           0x00000007
+#define    TB_SET_RCMD(reg, val)    \
+               reg |= (val & TB_REQMATCH_RCMD_MASK)
+#define    TB_GET_RCMD(reg) \
+               (reg & TB_REQMATCH_RCMD_MASK)
+
+// Node ID
+#define    TB_REQMATCH_RCONNID_SHIFT       4 
+#define    TB_REQMATCH_RCONNID_MASK        0x0000001f
+#define    TB_SET_RCONNID(reg, nodeId)     \
+                reg |= (nodeId & TB_REQMATCH_RCONNID_MASK) << TB_REQMATCH_RCONNID_SHIFT
+#define    TB_GET_RCONNID(reg) \
+                ((reg >> TB_REQMATCH_RCONNID_SHIFT) & TB_REQMATCH_RCONNID_MASK)
+
+// Transaction ID
+#define    TB_REQMATCH_RTHREADID_SHIFT     12
+#define    TB_REQMATCH_RTHREADID_MASK      0x0000008f
+#define    TB_SET_REQMATCH_RTHREADID(reg, transId)    \
+               reg |= (transId & TB_REQMATCH_RTHREADID_MASK) << TB_REQMATCH_RTHREADID_SHIFT
+#define    TB_GET_REQMATCH_RTHREADID(reg) \
+               ((reg >> TB_REQMATCH_RTHREADID_SHIFT) & TB_REQMATCH_RTHREADID_MASK)
+
+// Snoop Status
+#define    TB_REQMATCH_SSTAT
+#define    TB_REQMATCH_SSTAT_BRIDGE            0x00100000
+#define    TB_REQMATCH_SSTAT_L1TAG             0x00200000
+#define    TB_REQMATCH_SSTAT_L2CTAG            0x00400000
+#define    TB_REQMATCH_SSTAT_L2UCTAG           0x00800000
+
+#define    TB_SET_REQMATCH_SSTAT(x, val)       x |= val
+#define    TB_IS_SET_REQMATCH_SSTAT(x, val)    (x & val)
+
+// Cacheable?
+#define    TB_REQMATCH_RCACHE              0x01000000
+#define    TB_SET_REQMATCH_CACHEABLE(x)    x |=  TB_REQMATCH_RCACHE
+#define    TB_IS_REQMATCH_CACHEABLE(x)     (x & TB_REQMATCH_RCACHE)
+
+// Node ID of Hit
+#define    TB_REQMATCH_RSPHITID_MASK       0x0000001f
+#define    TB_SET_REQMATCH_RSPHITID(reg, hitNodeId)    \
+               reg |= (hitNodeId & TB_REQMATCH_RSPHITID_MASK)
+#define    TB_GET_REQMATCH_RSPHITID(reg) (reg & TB_REQMATCH_RSPHITID_MASK)
+
+// Snoop Result Status
+#define    TB_REQMATCH_SRSLT_CPUSHR            0x00000100
+#define    TB_REQMATCH_SRSLT_CPUMOD            0x00000200
+#define    TB_REQMATCH_SRSLT_L2SHR             0x00000400
+#define    TB_REQMATCH_SRSLT_L2MODE            0x00000800
+
+#define    TB_SET_REQMATCH_SRSLT(x, val)       x |= val
+#define    TB_IS_SET_REQMATCH_SRSLT(x,val)     (x & val)
+
+#define    TB_CTRL_RCMD                    0x0001
+#define    TB_CTRL_RCONNID                 0x0002
+#define    TB_CTRL_RTHREADID               0x0004
+#define    TB_CTRL_SSTAT                   0x0008
+#define    TB_CTRL_RCACHE                  0x0010
+#define    TB_CTRL_SRSPHITID               0x0020
+#define    TB_CTRL_SRSLT                   0x0040
+#define    TB_CTRL_RADDR                   0x0080
+#define    TB_CTRL_COLLMODE_MATCHONLY      0x0100
+
+#define    TB_SET_CTRL(x, flag)            x |= flag
+#define    TB_IS_SET_CTRL(x, flag)         (x & flag)
+
+#define    TB_CTRL_REQCNT_SHIFT            16
+#define    TB_CTRL_REQCNT_MASK             0x000000ff
+#define    TB_SET_CTRL_REQCNT(reg, cnt)    \
+               reg |= ((cnt & TB_CTRL_REQCNT_MASK) << TB_CTRL_REQCNT_SHIFT)
+#define    TB_GET_CTRL_REQCNT(reg) \
+               ((reg >> TB_CTRL_REQCNT_SHIFT) & TB_CTRL_REQCNT_MASK)
+
+#define    TB_CTRL_DISABLE                 0x01000000
+#define    TB_SET_CTRL_DISABLE(x)          x |= TB_CTRL_DISABLE
+#define    TB_IS_CTRL_DISABLED(x)          (x & TB_CTRL_DISABLE)
+
+#define    TB_EMPTY              0x01
+#define    TB_FULL               0x02
+#define    TB_COLLECTS_BMATCH    0x10
+#define    TB_COLLECTS_AMATCH    0x20
+#define    TB_STATUS_DONE        0x40
+#define    TB_DISABLED           0x80
+
+#define    TB_IS_EMPTY(x)              (x & TB_EMPTY)
+#define    TB_IS_FULL(x)               (x & TB_FULL)
+#define    TB_IS_COLLECTS_BMATCH(x)    (x & TB_COLLECTS_BMATCH)
+#define    TB_IS_COLLECTS_AMATCH(x)    (x & TB_COLLECTS_AMATCH)
+#define    TB_IS_STATUS_DONE(x) 	   (x & TB_STATUS_DONE)
+#define    TB_IS_DISABLED(x)           (x & TB_DISABLED)
+
+#define    TB_WRPTR_SHIFT        8
+#define    TB_WRPTR_MASK         0x000000ff
+#define    TB_GET_WRPTR(reg)     \
+               ((reg >> TB_WRPTR_SHIFT) & TB_WRPTR_MASK)
+
+#define    TB_RDPTR_SHIFT        16
+#define    TB_RDPTR_MASK         0x000000ff
+#define    TB_GET_RDPTR(reg)     \
+               ((reg >> TB_RDPTR_SHIFT) & TB_RDPTR_MASK)
+
+#define    TB_FIRST_MATCH_PTR_SHIFT    24
+#define    TB_FIRST_MATCH_PTR_MASK     0x000000ff
+#define    TB_GET_FIRST_MATCH_PTR(reg)     \
+               ((reg >> TB_FIRST_MATCH_PTR_SHIFT) & TB_FIRST_MATCH_PTR_MASK) 
+
+typedef struct tb_register {
+    int             type;
+    unsigned int    val;
+} tb_register_t;
+
+#define TB_IOC_MAGIC 241
+
+#define    TB_IOC_GTBREG    _IO(TB_IOC_MAGIC, 0)
+#define    TB_IOC_STBREG    _IO(TB_IOC_MAGIC, 1)
+#define    TB_IOC_REINIT    _IO(TB_IOC_MAGIC, 2)
+
+#endif
diff --git a/include/linux/serial_8250.h b/include/linux/serial_8250.h
index 10dbce5..41f4cb6 100644
--- a/include/linux/serial_8250.h
+++ b/include/linux/serial_8250.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
+
 /*
  *  linux/include/linux/serial_8250.h
  *
@@ -72,6 +84,7 @@ struct uart_8250_port;
 int serial8250_register_8250_port(struct uart_8250_port *);
 int serial8250_register_port(struct uart_port *);
 void serial8250_unregister_port(int line);
+void serial8250_unregister_by_port(struct uart_port *port);
 void serial8250_suspend_port(int line);
 void serial8250_resume_port(int line);
 
diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index c1bae8d..9555f3e 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -1676,7 +1676,11 @@ static inline void __skb_queue_purge(struct sk_buff_head *list)
 static inline struct sk_buff *__dev_alloc_skb(unsigned int length,
 					      gfp_t gfp_mask)
 {
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+	struct sk_buff *skb = alloc_skb(length + NET_SKB_PAD, gfp_mask|GFP_DMA);
+#else
 	struct sk_buff *skb = alloc_skb(length + NET_SKB_PAD, gfp_mask);
+#endif
 	if (likely(skb))
 		skb_reserve(skb, NET_SKB_PAD);
 	return skb;
@@ -1703,7 +1707,11 @@ extern struct sk_buff *__netdev_alloc_skb(struct net_device *dev,
 static inline struct sk_buff *netdev_alloc_skb(struct net_device *dev,
 		unsigned int length)
 {
+#if defined(CONFIG_RMI_PHOENIX) && defined(CONFIG_64BIT)
+	return __netdev_alloc_skb(dev, length, GFP_ATOMIC | GFP_DMA);
+#else
 	return __netdev_alloc_skb(dev, length, GFP_ATOMIC);
+#endif
 }
 
 static inline struct sk_buff *__netdev_alloc_skb_ip_align(struct net_device *dev,
diff --git a/include/linux/smp.h b/include/linux/smp.h
index 10530d9..d4d6fb3 100644
--- a/include/linux/smp.h
+++ b/include/linux/smp.h
@@ -52,7 +52,6 @@ extern void smp_send_stop(void);
  */
 extern void smp_send_reschedule(int cpu);
 
-
 /*
  * Prepare machine for booting other CPUs.
  */
diff --git a/include/linux/syscalls.h b/include/linux/syscalls.h
index 5f7309d..8239fc5 100644
--- a/include/linux/syscalls.h
+++ b/include/linux/syscalls.h
@@ -594,7 +594,18 @@ asmlinkage long sys_mkdir(const char __user *pathname, umode_t mode);
 asmlinkage long sys_chdir(const char __user *filename);
 asmlinkage long sys_fchdir(unsigned int fd);
 asmlinkage long sys_rmdir(const char __user *pathname);
+#if defined (CONFIG_64BIT) && defined (CONFIG_RMI_PHOENIX)
+#if defined (CONFIG_MIPS32_O32) || defined (CONFIG_MIPS32_N32)
+long sys_lookup_dcookie(u64 cookie64, char __user *buf, size_t len);
+#include <asm/compat.h>
+asmlinkage long compat_sys_lookup_dcookie(u32 cookie_msb, u32 cookie_lsb,
+                                      compat_uptr_t buf, compat_size_t len);
+#else
 asmlinkage long sys_lookup_dcookie(u64 cookie64, char __user *buf, size_t len);
+#endif
+#else
+asmlinkage long sys_lookup_dcookie(u64 cookie64, char __user *buf, size_t len);
+#endif
 asmlinkage long sys_quotactl(unsigned int cmd, const char __user *special,
 				qid_t id, void __user *addr);
 asmlinkage long sys_getdents(unsigned int fd,
diff --git a/include/user-mips/perfctr/unistd.h b/include/user-mips/perfctr/unistd.h
new file mode 100644
index 0000000..22dc8a0
--- /dev/null
+++ b/include/user-mips/perfctr/unistd.h
@@ -0,0 +1,41 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _USER_MIPS_RMI_UNISTD_H
+#define _USER_MIPS_RMI_UNISTD_H
+
+#define __NR_vperfctr            (__NR_Linux + 277)
+#define __NR_vperfctr_open       (__NR_vperfctr + 0)
+#define __NR_vperfctr_control    (__NR_vperfctr + 1)
+#define __NR_vperfctr_unlink     (__NR_vperfctr + 2)
+#define __NR_vperfctr_iresume    (__NR_vperfctr + 3)
+#define __NR_vperfctr_read       (__NR_vperfctr + 4)
+
+#endif
diff --git a/include/user/rmi/phnx_loader.h b/include/user/rmi/phnx_loader.h
new file mode 100644
index 0000000..d8ade1c
--- /dev/null
+++ b/include/user/rmi/phnx_loader.h
@@ -0,0 +1,153 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef __USER_RMI_PHNX_LOADER_H
+#define __USER_RMI_PHNX_LOADER_H
+
+#include <asm/ioctl.h>
+#include <asm/types.h>
+
+#define XLR_MAP_SLAVE_DEVICE 0x1
+
+#define XLR_MAP_UNCACHED 0x1
+#define XLR_MAP_CACHED 0x2
+
+#define PHNX_APP_LOADER_CHRDEV_NAME "xlr_app_loader"
+
+#define PHNX_LOADER_IOC_MAGIC 'X'
+
+#define PHNX_LOADER_IOC_SHMEM_SIZE _IOR(PHNX_LOADER_IOC_MAGIC, 0, unsigned int)
+
+#define PHNX_LOADER_IOC_MMAP_SHMEM _IOR(PHNX_LOADER_IOC_MAGIC, 1, unsigned int)
+
+#define PHNX_LOADER_IOC_LIB_BKP _IOR(PHNX_LOADER_IOC_MAGIC, 2, unsigned int)
+
+#define PHNX_LOADER_IOC_MMAP_LOAD_ADDR  _IOR(PHNX_LOADER_IOC_MAGIC, 3, unsigned int)
+
+#define PHNX_LOADER_IOC_START_IPI _IOR(PHNX_LOADER_IOC_MAGIC, 4, unsigned int)
+
+#define PHNX_LOADER_IOC_STOP_IPI  _IOR(PHNX_LOADER_IOC_MAGIC, 5, unsigned int)
+
+#define PHNX_LOADER_IOC_ALLOC_PERSISTENT_MEM  _IOR(PHNX_LOADER_IOC_MAGIC, 6, unsigned int)
+
+#define PHNX_LOADER_IOC_MMAP_PERSISTENT_MEM  _IOR(PHNX_LOADER_IOC_MAGIC, 7, unsigned int)
+
+#define PHNX_LOADER_IOC_FREE_PERSISTENT_MEM  _IOR(PHNX_LOADER_IOC_MAGIC, 8, unsigned int)
+
+#define PHNX_LOADER_IOC_SHMEM_KSEG_ADDR _IOR(PHNX_LOADER_IOC_MAGIC, 10, unsigned int)
+
+#define PHNX_LOADER_IOC_LAUNCH_KSEG _IOR(PHNX_LOADER_IOC_MAGIC, 15, unsigned int)
+
+#define PHNX_LOADER_IOC_APP_SHMEM_SIZE _IOR(PHNX_LOADER_IOC_MAGIC, 25, unsigned int)
+
+#define PHNX_LOADER_IOC_APP_SHMEM_RESERVE _IOR(PHNX_LOADER_IOC_MAGIC, 35, unsigned int)
+
+#define PHNX_LOADER_IOC_MMAP_APP_SHMEM _IOR(PHNX_LOADER_IOC_MAGIC, 45, unsigned int)
+
+#define PHNX_LOADER_IOC_APP_SHMEM_PHYS _IOR(PHNX_LOADER_IOC_MAGIC, 55, unsigned int)
+
+#define PHNX_LOADER_STORE_ENV _IOR(PHNX_LOADER_IOC_MAGIC, 65, unsigned int)
+
+#define PHNX_LOADER_SEND_IPI _IOR(PHNX_LOADER_IOC_MAGIC, 75, unsigned int)
+
+#define PHNX_LOADER_IOC_STORE_APP_SHMEM_INFO _IOR(PHNX_LOADER_IOC_MAGIC, 85, unsigned int)
+
+#define PHNX_LOADER_IOC_GET_APP_SHMEM_INFO _IOR(PHNX_LOADER_IOC_MAGIC, 95, unsigned int)
+
+
+#define PHNX_MAX_VCPUS 32
+
+enum { KUSEG_MODE, KSEG0_MODE };
+typedef enum {
+	STOP_THREAD=0xbeef,
+	START_THREAD,
+	RUN_FUNCTION, /* Used by wakeup and wakeup_os call */
+
+}loader_cmd;
+typedef enum {
+	THREAD_STOPPED=0x600d,
+	THREAD_RUNNING,
+	THREAD_SCHEDULED,
+}thread_status;
+
+struct cpu_tlb_mapping {
+	int page_size;
+	int asid;
+	int coherency;
+	int attr;
+	unsigned long virt;
+	uint64_t phys;
+};
+
+#define MAX_TLB_MAPPINGS 16
+#define MAX_ARGS 16
+#define MAX_ARGV_LEN 16
+struct cpu_wakeup_info {
+	int            master_cpu;
+	int            map_count;
+	int            valid;
+	unsigned long  func;
+	unsigned long  args;
+	int            argc;
+	uint32_t       buddy_mask;
+	uint32_t       cpu_mask;
+	char          *argv[32]; /* RMIOS LIB NEEDS this to be 32 */
+	char           buf[256];/* must be > MAX_ARGS * MAX_ARGV_LEN + some buffer */
+	struct cpu_tlb_mapping map[MAX_TLB_MAPPINGS];
+};
+
+/* SHARED memory structure b/w loader app, linux and RMIOS apps */
+typedef struct phnx_loader_shared_struct {
+	unsigned long park_entry;
+	loader_cmd    cmd;
+	thread_status thr_status;
+	unsigned long entry; /* Entry point address */
+	int 	      run_mode;
+	struct cpu_wakeup_info run_info;
+	uint32_t 	app_sh_mem_sz; /* Size of the shared memory */
+	unsigned long	sp;/* Used for reentry */
+	unsigned long	gp;
+}phnx_loader_shared_struct_t;
+
+
+/* This structure is passed to all applications launched from the linux
+   loader through OS 7 scratch register
+   */
+#define PHNX_LOADER_INFO_MAGIC 0x600ddeed
+typedef struct phnx_loader_info {
+	uint32_t magic;
+	/* phnx_loader_shared_struct_t for CPU 0 will start here */
+	unsigned long sh_mem_start;
+	/* Size of the shared memory b/w linux apps and rmios apps  */
+	uint32_t app_sh_mem_size;
+	uint8_t printk_lock[16]; /* used for printk */
+}phnx_loader_info_t;
+
+#endif
diff --git a/include/user/rmi/phnx_mmap.h b/include/user/rmi/phnx_mmap.h
new file mode 100644
index 0000000..8bf22e5
--- /dev/null
+++ b/include/user/rmi/phnx_mmap.h
@@ -0,0 +1,43 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef __USER_RMI_PHNX_MMAP_H
+#define __USER_RMI_PHNX_MMAP_H
+
+#include <asm/ioctl.h>
+
+
+#define PHNX_MMAP_IOC_MAGIC 'N'
+
+#define    PHNX_MMAP_IOC_GPHYS_START         _IOR(PHNX_MMAP_IOC_MAGIC, 0, unsigned long)
+#define    PHNX_MMAP_IOC_GPHYS_SIZE          _IOR(PHNX_MMAP_IOC_MAGIC, 1, unsigned long)
+#define    PHNX_MMAP_IOC_GVIRT_START         _IOR(PHNX_MMAP_IOC_MAGIC, 2, unsigned long)
+
+#endif
diff --git a/include/user/rmi/phnx_msgring.h b/include/user/rmi/phnx_msgring.h
new file mode 100644
index 0000000..684c944
--- /dev/null
+++ b/include/user/rmi/phnx_msgring.h
@@ -0,0 +1,56 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef __USER_RMI_PHNX_MSG_RNG_H
+#define __USER_RMI_PHNX_MSG_RNG_H
+
+#include <asm/ioctl.h>
+
+struct msgring_msg_data {
+  int		size;
+  int           code;
+  int           stid;
+  int           rx_bucket;
+  unsigned int  msgs[8];
+};
+
+#define MSG_RNG_IOC_MAGIC 'M'
+
+#define    MSGRING_IOC_SSTNNO       _IOW(MSG_RNG_IOC_MAGIC, 0, unsigned int)
+#define    MSGRING_IOC_GSHMPHYS     _IOR(MSG_RNG_IOC_MAGIC, 1, unsigned int)
+#define    MSGRING_IOC_GSHMVIRT     _IOR(MSG_RNG_IOC_MAGIC, 2, unsigned int)
+#define    MSGRING_IOC_GMMAP_START  _IOR(MSG_RNG_IOC_MAGIC, 3, unsigned int)
+#define    MSGRING_IOC_SYSINIT      _IOR(MSG_RNG_IOC_MAGIC, 4, unsigned int)
+#define    MSGRING_IOC_SYSPHYS      _IOR(MSG_RNG_IOC_MAGIC, 5, unsigned int)
+#define    MSGRING_IOC_SYSCALL      _IOW(MSG_RNG_IOC_MAGIC, 6, unsigned int)
+
+#define PHNX_MSGRING_CHRDEV_NAME "xlr_msgring_shm"
+
+#endif
diff --git a/include/user/rmi/phnx_user_mac.h b/include/user/rmi/phnx_user_mac.h
new file mode 100644
index 0000000..a8fedc5
--- /dev/null
+++ b/include/user/rmi/phnx_user_mac.h
@@ -0,0 +1,138 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef __USER_RMI_PHNX_USER_MAC_H
+#define __USER_RMI_PHNX_USER_MAC_H
+
+#include <asm/ioctl.h>
+
+#define USER_MAC_IOC_MAGIC 'M'
+
+#define    USER_MAC_IOC_GSHMPHYS            _IOR(USER_MAC_IOC_MAGIC, 1, unsigned int)
+#define    USER_MAC_IOC_GSHMVIRT            _IOR(USER_MAC_IOC_MAGIC, 2, unsigned int)
+#define    USER_MAC_IOC_GSHMSIZE            _IOR(USER_MAC_IOC_MAGIC, 3, unsigned int)
+#define    USER_MAC_IOC_GMMAP_START         _IOR(USER_MAC_IOC_MAGIC, 4, unsigned int)
+#define    USER_MAC_IOC_SWRITE_REG          _IOW(USER_MAC_IOC_MAGIC, 10, unsigned int)
+#define    USER_MAC_IOC_GREAD_REG           _IOR(USER_MAC_IOC_MAGIC, 11, unsigned int)
+#define    USER_MAC_IOC_SPERF               _IOW(USER_MAC_IOC_MAGIC, 12, unsigned int)
+#define    USER_MAC_IOC_GPHYS_CPU_PRESENT_MAP _IOR(USER_MAC_IOC_MAGIC, 13, unsigned int)
+#define    USER_MAC_IOC_GCPU_ONLINE_MAP     _IOR(USER_MAC_IOC_MAGIC, 14, unsigned int)
+#define    USER_MAC_IOC_HYBRID_MODE_SETUP   _IOR(USER_MAC_IOC_MAGIC, 15, unsigned int)
+#define    USER_MAC_IOC_HUGETLB_SHM_VIRT_ADDR _IOR(USER_MAC_IOC_MAGIC, 16, unsigned int)
+#define    USER_MAC_IOC_EARLY_MEM_INIT		_IOR(USER_MAC_IOC_MAGIC, 17, unsigned int)
+
+#define PHNX_USER_MAC_CHRDEV_NAME "xlr_user_mac"
+
+#define MAX_USER_MAC_PKTS 3072
+#define MAX_USER_MAC_FRIN_PKTS (MAX_USER_MAC_PKTS - 256)
+#define USER_MAC_FIFO_SIZE 128
+#define USER_MAC_PKT_BUF_SIZE 1600
+
+struct packet_data {
+  unsigned char data[USER_MAC_PKT_BUF_SIZE];
+};
+
+struct packet_desc {
+  unsigned int offset;
+  int len;
+  int port;
+  int type;
+  int xgmac; //ignore in gmac. 1 xgmac loopback, 2, xgmac crossover
+  int device; //0 xgmac0, 1 xgmac1
+  int free;
+  unsigned char priv[48];
+  uint64_t priv_ptr;	//uint32_t *priv_ptr;
+};
+
+#define USER_MAC_TXQ_FREE 0
+#define USER_MAC_TXQ_TX 1
+#define USER_MAC_TXQ_HOST 2
+
+struct user_mac_time {
+  unsigned int hi;
+  unsigned int lo;
+};
+struct user_mac_data {
+  struct packet_data pkt_data[MAX_USER_MAC_PKTS];
+  struct packet_desc pkt_desc[MAX_USER_MAC_PKTS];
+  struct user_mac_time time;
+  struct timespec ktime;
+  int host_pkt_next_free[32];
+};
+
+/* copy all the user_mac_data which are accessed from the kernal to user_mac_kernal_data */
+struct user_mac_kernal_data {
+	struct user_mac_time time;
+	struct timespec ktime;
+};
+
+static __inline__ unsigned char *user_mac_host_pkt_alloc(struct user_mac_data *user_mac, int cpu)
+{
+	int num_pkts = (MAX_USER_MAC_PKTS - MAX_USER_MAC_FRIN_PKTS) / 32;
+	int start_index = MAX_USER_MAC_FRIN_PKTS + (cpu * num_pkts);
+	int next_free = user_mac->host_pkt_next_free[cpu];
+	int i=0;
+
+	if (next_free < start_index || next_free >= (start_index + num_pkts)) 
+		return NULL;
+	
+	for (i=next_free; i<(start_index+num_pkts) ;i++) {
+		if (user_mac->pkt_desc[i].free) {
+			user_mac->pkt_desc[i].free = 0;
+			user_mac->host_pkt_next_free[cpu] = i;
+			return user_mac->pkt_data[i].data;
+		}
+	}
+	
+	for (i=start_index; i<next_free; i++) {
+		if (user_mac->pkt_desc[i].free) {
+			user_mac->pkt_desc[i].free = 0;
+			user_mac->host_pkt_next_free[cpu] = i;
+			return user_mac->pkt_data[i].data;
+		}		
+	}
+
+	return NULL;
+}
+
+static __inline__ int user_mac_host_pkt_free(struct user_mac_data *user_mac, int index, int cpu)
+{
+	/* This function can be called from any cpu */
+	if (index < MAX_USER_MAC_FRIN_PKTS || index >= MAX_USER_MAC_PKTS)
+		return -1;
+	
+	if (user_mac->pkt_desc[index].free) return -1;
+
+	user_mac->pkt_desc[index].free = 1;
+
+	return 0;
+}
+
+#endif
diff --git a/init/Kconfig b/init/Kconfig
index d999254..795c16e 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -978,9 +978,7 @@ config BLK_DEV_INITRD
 	  If unsure say Y.
 
 if BLK_DEV_INITRD
-
 source "usr/Kconfig"
-
 endif
 
 config CC_OPTIMIZE_FOR_SIZE
@@ -1391,6 +1389,8 @@ config PROFILING
 
 source ltt/Kconfig
 
+source "drivers/perfctr/Kconfig"
+
 #
 # Place an empty function call at each tracepoint site. Can be
 # dynamically changed for a probe function.
diff --git a/init/main.c b/init/main.c
index 41fa147..a60ada4 100644
--- a/init/main.c
+++ b/init/main.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: Some additional Output/Debug statements
+
+ *****************************#RMI_1#************************************/
+
 /*
  *  linux/init/main.c
  *
@@ -122,6 +134,7 @@ extern void softirq_init(void);
 char __initdata boot_command_line[COMMAND_LINE_SIZE];
 /* Untouched saved command line (eg. for /proc) */
 char *saved_command_line;
+EXPORT_SYMBOL(saved_command_line);
 /* Command line for parameter parsing */
 static char *static_command_line;
 
diff --git a/kernel/exit.c b/kernel/exit.c
index e765d98..456a5de 100644
--- a/kernel/exit.c
+++ b/kernel/exit.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  *  linux/kernel/exit.c
  *
@@ -54,6 +66,10 @@
 #include <linux/writeback.h>
 #include <linux/shm.h>
 
+#ifdef CONFIG_PERFCTR
+#include <linux/perfctr.h>
+#endif
+
 #include <asm/uaccess.h>
 #include <asm/unistd.h>
 #include <asm/pgtable.h>
@@ -202,6 +218,9 @@ repeat:
 
 	msa_update_parent(p->parent, p);
 
+#ifdef CONFIG_PERFCTR
+    perfctr_release_task(p);
+#endif
 	write_unlock_irq(&tasklist_lock);
 	release_thread(p);
 	call_rcu(&p->rcu, delayed_put_task_struct);
diff --git a/kernel/pid.c b/kernel/pid.c
index e1f7f31..1943d66 100644
--- a/kernel/pid.c
+++ b/kernel/pid.c
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * Generic pidhash and scalable, time-bounded PID allocator
  *
@@ -545,8 +557,13 @@ struct pid *find_ge_pid(int nr, struct pid_namespace *ns)
 /*
  * The pid hash table is scaled according to the amount of memory in the
  * machine.  From a minimum of 16 slots up to 4096 slots at one gigabyte or
- * more.
+ * more. KGDB needs to know if this function has been called already,
+ * since we might have entered KGDB very early.
  */
+#ifdef CONFIG_KGDB
+int pidhash_init_done;
+#endif
+
 void __init pidhash_init(void)
 {
 	unsigned int i, pidhash_size;
@@ -558,6 +575,11 @@ void __init pidhash_init(void)
 
 	for (i = 0; i < pidhash_size; i++)
 		INIT_HLIST_HEAD(&pid_hash[i]);
+
+#ifdef CONFIG_KGDB
+	pidhash_init_done = 1;
+#endif
+
 }
 
 void __init pidmap_init(void)
diff --git a/kernel/ptrace.c b/kernel/ptrace.c
index daf4394..7e1bef5 100644
--- a/kernel/ptrace.c
+++ b/kernel/ptrace.c
@@ -32,6 +32,7 @@ static int ptrace_trapping_sleep_fn(void *flags)
 	return 0;
 }
 
+
 /*
  * ptrace a task: make the debugger its new parent and
  * move it to the ptrace list.
@@ -547,7 +548,7 @@ int ptrace_writedata(struct task_struct *tsk, char __user *src, unsigned long ds
 		this_len = (len > sizeof(buf)) ? sizeof(buf) : len;
 		if (copy_from_user(buf, src, this_len))
 			return -EFAULT;
-		retval = access_process_vm(tsk, dst, buf, this_len, 1);
+		retval = access_process_vm(tsk, (unsigned long)src, buf, this_len, 0);
 		if (!retval) {
 			if (copied)
 				break;
diff --git a/kernel/sys_ni.c b/kernel/sys_ni.c
index 47bfa16..d1ca769 100644
--- a/kernel/sys_ni.c
+++ b/kernel/sys_ni.c
@@ -20,6 +20,7 @@ cond_syscall(sys_quotactl);
 cond_syscall(sys32_quotactl);
 cond_syscall(sys_acct);
 cond_syscall(sys_lookup_dcookie);
+cond_syscall(compat_sys_lookup_dcookie);
 cond_syscall(sys_swapon);
 cond_syscall(sys_swapoff);
 cond_syscall(sys_kexec_load);
diff --git a/kernel/timer.c b/kernel/timer.c
index 53e4c66..cc2fae8 100644
--- a/kernel/timer.c
+++ b/kernel/timer.c
@@ -1,3 +1,14 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
 /*
  *  linux/kernel/timer.c
  *
@@ -42,6 +53,11 @@
 #include <linux/slab.h>
 #include <trace/timer.h>
 
+#ifdef CONFIG_PERFCTR
+#include <linux/perfctr.h>
+#include <linux/syscalls.h>
+#endif
+
 #include <asm/uaccess.h>
 #include <asm/unistd.h>
 #include <asm/div64.h>
diff --git a/mm/memory.c b/mm/memory.c
index 4bbf2a5..26771f7 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -3649,6 +3649,73 @@ int make_pages_present(unsigned long addr, unsigned long end)
 	return ret == len ? 0 : -EFAULT;
 }
 
+#if defined(CONFIG_PHOENIX_USERSEGV_DEBUG) || defined(CONFIG_PHOENIX_VM_DEBUG)
+
+static void print_pte_range(pte_t *pte, int pgd_index, int pmd_index)
+{
+	int i;
+	
+	for (i = 0; i < PTRS_PER_PTE; ++pte, ++i)
+	{
+		if (pte_none(*pte))
+			continue;
+		printk("\t\tpte[%d] = %lx, vpage = %lx\n", i, pte_val(*pte), 
+			  	((unsigned long)pgd_index << PGDIR_SHIFT)
+				| ((unsigned long)pmd_index << PAGE_SHIFT));
+	}
+}
+
+static void print_pmd_range(pmd_t *pmd, int pgd_index)
+{
+	int i;
+
+	for (i = 0; i < PTRS_PER_PMD; ++pmd, ++i)
+	{
+		if (pmd_none(*pmd))
+			continue;
+	 	print_pte_range((pte_t *) pmd_val(*pmd), pgd_index, i);
+	}
+}
+
+void dump_pgtable(pgd_t *pgd)
+{
+	int i = 0;
+
+	if (pgd == NULL) {
+		printk("NULL pgd ... bailing out\n");
+		return;
+	}
+
+	printk("dumping page table: pgd=%lx\n", (unsigned long)pgd);   
+	for (i = 0; i < PTRS_PER_PGD; ++pgd, ++i) 
+    {    
+		if (pgd_none(*pgd))
+			continue;	
+		print_pmd_range((pmd_t *) pgd_val(*pgd), i);
+	}
+}
+	
+void dump_mm_pgtable(struct mm_struct *mm)
+{
+	if (!mm) {
+    	printk("[%s]: mm == NULL (Kernel Thread?)\n", __FUNCTION__);
+    	return;
+	}
+
+	return dump_pgtable(mm->pgd);
+}
+
+void dump_current_pgtable(void)
+{
+  printk("[%s]: current = %lx, current->mm=%lx, current->active_mm=%lx\n", 
+	 __FUNCTION__,
+	 (unsigned long)current, (unsigned long)current->mm,
+	 (unsigned long)current->active_mm);
+  dump_mm_pgtable(current->mm);
+}
+
+#endif
+
 #if !defined(__HAVE_ARCH_GATE_AREA)
 
 #if defined(AT_SYSINFO_EHDR)
diff --git a/net/core/dev.c b/net/core/dev.c
index 373de32..30fa048 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -1,3 +1,14 @@
+/************************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI: 
+
+  *****************************#RMI_1#************************************/
 /*
  * 	NET3	Protocol independent device support routines.
  *
@@ -2063,6 +2074,20 @@ static int illegal_highdma(struct net_device *dev, struct sk_buff *skb)
 		}
 	}
 #endif
+
+#if defined (CONFIG_RMI_PHOENIX) && defined (CONFIG_64BIT)
+	{
+		int i;
+
+		if (dev->features & NETIF_F_HIGHDMA)
+			return 0;
+		for (i = 0; i < skb_shinfo(skb)->nr_frags; i++)
+			if ((page_to_phys((skb_shinfo(skb)->frags[i].page))) >=
+					dev->dev.coherent_dma_mask)
+				return 1;
+	}
+#endif
+
 	return 0;
 }
 
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index e99aedd..8b83e1a 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -924,6 +924,11 @@ int pskb_expand_head(struct sk_buff *skb, int nhead, int ntail,
 	long off;
 	bool fastpath;
 
+#if defined (CONFIG_RMI_PHOENIX) && defined (CONFIG_64BIT)
+	gfp_mask |= GFP_DMA;
+#endif
+
+
 	BUG_ON(nhead < 0);
 
 	if (skb_shared(skb))
diff --git a/net/ipv4/af_inet.c b/net/ipv4/af_inet.c
index 78ec298..45446c0 100644
--- a/net/ipv4/af_inet.c
+++ b/net/ipv4/af_inet.c
@@ -1670,7 +1670,10 @@ static int __init inet_init(void)
 	 *	Tell SOCKET that we are alive...
 	 */
 
-	(void)sock_register(&inet_family_ops);
+	rc = sock_register(&inet_family_ops);
+	if (rc) {
+		BUG();
+	}
 
 #ifdef CONFIG_SYSCTL
 	ip_static_sysctl_init();
diff --git a/net/ipv4/netfilter/ip_queue.c b/net/ipv4/netfilter/ip_queue.c
index 94d45e1..56302cf 100644
--- a/net/ipv4/netfilter/ip_queue.c
+++ b/net/ipv4/netfilter/ip_queue.c
@@ -90,10 +90,30 @@ static void __ipq_flush(ipq_cmpfn cmpfn, unsigned long data);
 static inline void
 __ipq_reset(void)
 {
+#ifdef CONFIG_PHOENIX_IP_QUEUE_AFFINITY
+	int i;
+	int total = 0;
+#ifdef RMI_IPQ_DEBUG	
+	printk(KERN_ALERT "%s: Removing PID %d from core %d\n",
+			__FUNCTION__, peer_pid[smp_processor_id()], smp_processor_id());
+#endif
+	peer_pid[smp_processor_id()] = 0;
+	
+	for (i = 0; i < NR_CPUS; i++) {
+		total |= peer_pid[i];
+	}
+	
+	if (total == 0) {
+		net_disable_timestamp();
+		__ipq_set_mode(IPQ_COPY_NONE, 0);
+		__ipq_flush(NF_DROP, 0);
+	}
+#else
 	peer_pid = 0;
 	net_disable_timestamp();
 	__ipq_set_mode(IPQ_COPY_NONE, 0);
 	__ipq_flush(NULL, 0);
+#endif /* CONFIG_PHOENIX_IP_QUEUE_AFFINITY */
 }
 
 static struct nf_queue_entry *
@@ -229,6 +249,10 @@ ipq_enqueue_packet(struct nf_queue_entry *entry, unsigned int queuenum)
 {
 	int status = -EINVAL;
 	struct sk_buff *nskb;
+#ifdef CONFIG_PHOENIX_IP_QUEUE_AFFINITY
+	int dst_cpu;
+	struct sk_buff *skb = entry->skb;
+#endif /* CONFIG_PHOENIX_IP_QUEUE_AFFINITY */
 
 	if (copy_mode == IPQ_COPY_NONE)
 		return -EAGAIN;
@@ -239,7 +263,12 @@ ipq_enqueue_packet(struct nf_queue_entry *entry, unsigned int queuenum)
 
 	spin_lock_bh(&queue_lock);
 
+#ifdef CONFIG_PHOENIX_IP_QUEUE_AFFINITY
+	dst_cpu = smp_processor_id() + (skb->cb[sizeof(skb->cb) - 1] & 3);
+	if (!peer_pid[dst_cpu])
+#else
 	if (!peer_pid)
+#endif /* CONFIG_PHOENIX_IP_QUEUE_AFFINITY */
 		goto err_out_free_nskb;
 
 	if (queue_total >= queue_maxlen) {
@@ -253,7 +282,17 @@ ipq_enqueue_packet(struct nf_queue_entry *entry, unsigned int queuenum)
 	}
 
 	/* netlink_unicast will either free the nskb or attach it to a socket */
+
+#ifdef CONFIG_PHOENIX_IP_QUEUE_AFFINITY
+#ifdef RMI_IPQ_DEBUG
+	printk(KERN_ALERT "%s: Sending packet from bucket: %d\n",
+			__FUNCTION__, skb->cb[sizeof(skb->cb) - 1]);
+#endif
+	status = netlink_unicast(ipqnl, nskb, peer_pid[dst_cpu], MSG_DONTWAIT);
+#else
 	status = netlink_unicast(ipqnl, nskb, peer_pid, MSG_DONTWAIT);
+#endif  /* CONFIG_PHOENIX_IP_QUEUE_AFFINITY */
+
 	if (status < 0) {
 		queue_user_dropped++;
 		goto err_out_unlock;
@@ -436,6 +475,25 @@ __ipq_rcv_skb(struct sk_buff *skb)
 
 	spin_lock_bh(&queue_lock);
 
+#ifdef CONFIG_PHOENIX_IP_QUEUE_AFFINITY
+#ifdef RMI_IPQ_DEBUG
+	if (current->pid != pid)
+	{
+		printk(KERN_ALERT "%s: PID mismatch: current: %d, PID: %d, core %d\n",
+				__FUNCTION__, current->pid, pid, smp_processor_id());
+	}
+#endif /* RMI_IPQ_DEBUG */
+
+	if (!peer_pid[smp_processor_id()])
+	{
+		net_enable_timestamp();
+		peer_pid[smp_processor_id()] = pid;
+#ifdef  RMI_IPQ_DEBUG
+		printk(KERN_ALERT "%s: Setting PID %d for core %d\n",
+				__FUNCTION__, pid, smp_processor_id());
+#endif
+	}
+#else
 	if (peer_pid) {
 		if (peer_pid != pid) {
 			spin_unlock_bh(&queue_lock);
@@ -445,6 +503,7 @@ __ipq_rcv_skb(struct sk_buff *skb)
 		enable_timestamp = true;
 		peer_pid = pid;
 	}
+#endif  /* CONFIG_PHOENIX_IP_QUEUE_AFFINITY */
 
 	spin_unlock_bh(&queue_lock);
 	if (enable_timestamp)
@@ -539,6 +598,7 @@ static int ip_queue_show(struct seq_file *m, void *v)
 		      queue_maxlen,
 		      queue_dropped,
 		      queue_user_dropped);
+#endif  /* CONFIG_PHOENIX_IP_QUEUE_AFFINITY */
 
 	spin_unlock_bh(&queue_lock);
 	return 0;
-- 
1.7.0.4

