From 722c418583d582b5a8933ca81745b74d3f64fe8e Mon Sep 17 00:00:00 2001
From: Venu Vadapalli <vvadapalli@netlogicmicro.com>
Date: Tue, 2 Nov 2010 19:46:07 -0700
Subject: [PATCH 221/761] Enable pgwalker for XLP, install default NMI handler

       * Pipeflush before and after disabling pgwalker
       * Disable/Enable pgwalker whenever updating pgd_bases and ASIDs
       * Enable pgwalker after initializing it
       * Fully populate L4 of pgwalker pgd_bases

Based on Broadcom SDK 2.3.

Signed-off-by: Venu Vadapalli <vvadapalli@netlogicmicro.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/include/asm/mach-netlogic/pgwalker.h |    1 -
 arch/mips/include/asm/mach-netlogic/xlp-mmu.h  |   33 +++++
 arch/mips/include/asm/mmu_context.h            |   11 ++
 arch/mips/lib/dump_tlb.c                       |   23 +++-
 arch/mips/mm/c-phoenix.c                       |  115 +++++++---------
 arch/mips/mm/tlb-r4k.c                         |   69 ++++------
 arch/mips/netlogic/xlp/Makefile                |   11 +-
 arch/mips/netlogic/xlp/mmu.c                   |  174 ++++++++++++++----------
 arch/mips/netlogic/xlp/nmi.S                   |   19 ++-
 arch/mips/netlogic/xlp/on_chip.c               |   23 ++++
 arch/mips/netlogic/xlp/setup.c                 |    5 -
 11 files changed, 283 insertions(+), 201 deletions(-)

diff --git a/arch/mips/include/asm/mach-netlogic/pgwalker.h b/arch/mips/include/asm/mach-netlogic/pgwalker.h
index 8c3fb60..855f900 100644
--- a/arch/mips/include/asm/mach-netlogic/pgwalker.h
+++ b/arch/mips/include/asm/mach-netlogic/pgwalker.h
@@ -30,7 +30,6 @@ enum {
 
 #define pgw_print_w(reg) printk(KERN_INFO #reg " = 0x%x\n", pgw_register_read_w(reg))
 
-extern void pgwalker_init(void);
 extern void dump_pgwalker_config(void);
 
 #endif
diff --git a/arch/mips/include/asm/mach-netlogic/xlp-mmu.h b/arch/mips/include/asm/mach-netlogic/xlp-mmu.h
index 1589b9a..4da9dfa 100644
--- a/arch/mips/include/asm/mach-netlogic/xlp-mmu.h
+++ b/arch/mips/include/asm/mach-netlogic/xlp-mmu.h
@@ -2,6 +2,7 @@
 #define _ASM_MACH_NLM_XLP_MMU_H
 
 #include <linux/percpu.h>
+#include <asm/mipsregs.h>
 
 /* 
  * These numbers correspond to Cop0 Config6 reg 
@@ -32,4 +33,36 @@ static inline void setup_user_pgd(pgd_t *pgd)
 	}
 };
 
+#ifdef CONFIG_NLM_XLP
+
+static __inline__ void pipeline_flush(void)
+{
+	__asm__ __volatile__ (
+		".set push         \n"
+		".set arch=xlp     \n"
+		"dla      $8, 1f    \n"
+		"jr.hb   $8        \n"
+		"nop               \n"
+		"1: nop            \n"
+		".set pop          \n"
+		:
+		:
+		: "$8"
+		);
+}
+
+#define disable_pgwalker(flags)						\
+	({ flags = read_c0_config6();					\
+		pipeline_flush(); write_c0_config6(read_c0_config6() & ~ENABLE_PGWALKER); pipeline_flush();})
+
+#define enable_pgwalker(flags)						\
+	({ write_c0_config6(read_c0_config6() | (flags & ENABLE_PGWALKER)); })
+
+#else
+
+#define disable_pgwalker(flags) {}
+#define enable_pgwalker(flags) {}
+
+#endif
+
 #endif
diff --git a/arch/mips/include/asm/mmu_context.h b/arch/mips/include/asm/mmu_context.h
index ec8677f..7730a79 100644
--- a/arch/mips/include/asm/mmu_context.h
+++ b/arch/mips/include/asm/mmu_context.h
@@ -167,6 +167,7 @@ static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,
 {
 	unsigned int cpu = smp_processor_id();
 	unsigned long flags;
+	unsigned int pflags;
 #ifdef CONFIG_MIPS_MT_SMTC
 	unsigned long oldasid;
 	unsigned long mtflags;
@@ -205,10 +206,12 @@ static inline void switch_mm(struct mm_struct *prev, struct mm_struct *next,
 	ehb(); /* Make sure it propagates to TCStatus */
 	evpe(mtflags);
 #else
+	disable_pgwalker(pflags);
 	write_c0_entryhi(cpu_asid(cpu, next));
 #endif /* CONFIG_MIPS_MT_SMTC */
 	TLBMISS_HANDLER_SETUP_PGD(next->pgd);
 	setup_user_pgd(next->pgd);
+	enable_pgwalker(pflags);
 
 	/*
 	 * Mark current->active_mm as not "active" anymore.
@@ -239,6 +242,7 @@ activate_mm(struct mm_struct *prev, struct mm_struct *next)
 {
 	unsigned long flags;
 	unsigned int cpu = smp_processor_id();
+	unsigned int pflags;
 
 #ifdef CONFIG_MIPS_MT_SMTC
 	unsigned long oldasid;
@@ -266,11 +270,13 @@ activate_mm(struct mm_struct *prev, struct mm_struct *next)
 	ehb(); /* Make sure it propagates to TCStatus */
 	evpe(mtflags);
 #else
+	disable_pgwalker(pflags);
 	write_c0_entryhi(cpu_asid(cpu, next));
 #endif /* CONFIG_MIPS_MT_SMTC */
 
 	TLBMISS_HANDLER_SETUP_PGD(next->pgd);
 	setup_user_pgd(next->pgd);
+	enable_pgwalker(pflags);
 
 	/* mark mmu ownership change */
 	cpumask_clear_cpu(cpu, mm_cpumask(prev));
@@ -287,6 +293,7 @@ static inline void
 drop_mmu_context(struct mm_struct *mm, unsigned cpu)
 {
 	unsigned long flags;
+	unsigned int pflags;
 #ifdef CONFIG_MIPS_MT_SMTC
 	unsigned long oldasid;
 	/* Can't use spinlock because called from TLB flush within DVPE */
@@ -313,10 +320,13 @@ drop_mmu_context(struct mm_struct *mm, unsigned cpu)
 		ehb(); /* Make sure it propagates to TCStatus */
 		evpe(prevvpe);
 #else /* not CONFIG_MIPS_MT_SMTC */
+		disable_pgwalker(pflags);
 		write_c0_entryhi(cpu_asid(cpu, mm));
+		enable_pgwalker(pflags);
 #endif /* CONFIG_MIPS_MT_SMTC */
 	} else {
 		/* will get a new context next time */
+
 #ifndef CONFIG_MIPS_MT_SMTC
 		cpu_context(cpu, mm) = 0;
 #else /* SMTC */
@@ -329,6 +339,7 @@ drop_mmu_context(struct mm_struct *mm, unsigned cpu)
 			cpu_context(i, mm) = 0;
 		}
 #endif /* CONFIG_MIPS_MT_SMTC */
+
 	}
 	local_irq_restore(flags);
 }
diff --git a/arch/mips/lib/dump_tlb.c b/arch/mips/lib/dump_tlb.c
index 3f69725..5f29e23 100644
--- a/arch/mips/lib/dump_tlb.c
+++ b/arch/mips/lib/dump_tlb.c
@@ -51,6 +51,13 @@ static void dump_tlb(int first, int last)
 	unsigned long s_entryhi, entryhi, asid;
 	unsigned long long entrylo0, entrylo1;
 	unsigned int s_index, pagemask, c0, c1, i;
+#ifdef CONFIG_NLM_XLP
+	unsigned int asid_mask = 0x3ff;
+#else
+	unsigned int asid_mask = 0xff;
+#endif
+	int wired = read_c0_wired();
+	int print_tlb = 0;
 
 	s_entryhi = read_c0_entryhi();
 	s_index = read_c0_index();
@@ -66,9 +73,16 @@ static void dump_tlb(int first, int last)
 		entrylo0 = read_c0_entrylo0();
 		entrylo1 = read_c0_entrylo1();
 
+		print_tlb = 0;
+		if ( (i >= 0) && (i < wired) ) print_tlb = 1;
+		else {
+			if ( ((entryhi & ~0x1ffffUL) != CKSEG0)
+			     && ((entryhi & asid_mask) == asid) )
+				print_tlb = 1;
+		}
+
 		/* Unused entries have a virtual address of CKSEG0.  */
-		if ((entryhi & ~0x1ffffUL) != CKSEG0
-		    && (entryhi & 0xff) == asid) {
+		if (print_tlb) {
 #ifdef CONFIG_32BIT
 			int width = 8;
 #else
@@ -107,5 +121,8 @@ static void dump_tlb(int first, int last)
 
 void dump_tlb_all(void)
 {
-	dump_tlb(0, current_cpu_data.tlbsize - 1);
+	int ntlbs = current_cpu_data.tlbsize - 1;
+
+	printk("Dumping TLBS (0 --> %d): nwired = %d\n", ntlbs, read_c0_wired());
+	dump_tlb(0, ntlbs);
 }
diff --git a/arch/mips/mm/c-phoenix.c b/arch/mips/mm/c-phoenix.c
index f001bdd..293f156 100644
--- a/arch/mips/mm/c-phoenix.c
+++ b/arch/mips/mm/c-phoenix.c
@@ -8,7 +8,7 @@ the header of the original work apply to this derived work.
 /*
  * Copyright (C) 1996 David S. Miller (dm@engr.sgi.com)
  * Copyright (C) 1997, 2001 Ralf Baechle (ralf@gnu.org)
- * 
+ *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License
  * as published by the Free Software Foundation; either version 2
@@ -18,11 +18,11 @@ the header of the original work apply to this derived work.
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- * 
+ *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
- */ 
+ */
 #include <linux/init.h>
 #include <asm/asm.h>
 #include <asm/mmu_context.h>
@@ -35,6 +35,7 @@ the header of the original work apply to this derived work.
 #include <linux/mm.h>
 #include <linux/module.h>
 
+#include <asm/mach-netlogic/xlp-mmu.h>
 #include <asm/netlogic/debug.h>
 
 static unsigned int icache_linesz;
@@ -59,26 +60,10 @@ extern void nlm_vmips_wired_entry_remove(int index);
 		            STR(PTR)"\t1b, 2b\n\t"        \
 		       "     .previous               \n"   \
 		       : : "i" (op), "r" (base));          \
-  } while (0) 
+  } while (0)
 
 #ifdef CONFIG_NLM_XLP
 
-static __inline__ void pipeline_flush(void)
-{
-	__asm__ __volatile__ (
-		".set push         \n"
-		".set arch=xlp     \n"
-		"dla      $8, 1f    \n"
-		"jr.hb   $8        \n"
-		"nop               \n"
-		"1: nop            \n"
-		".set pop          \n"
-		:
-		:
-		: "$8"
-		);
-}
-
 static __inline__ void sync_istream(void)
 {
 	pipeline_flush();
@@ -98,12 +83,12 @@ static __inline__ void cacheop_sync_istream(void)
 
 static __inline__ void sync_istream(void)
 {
-  __asm__ __volatile__ (                                     
-                       ".set push                     \n"    
-                       ".set noreorder                \n"    
-		       //                       " la     $8, 1f                \n"    
-                       //" mtc0   $8, $14               \n"    
-                       //"eret                          \n"    
+  __asm__ __volatile__ (
+                       ".set push                     \n"
+                       ".set noreorder                \n"
+		       //                       " la     $8, 1f                \n"
+                       //" mtc0   $8, $14               \n"
+                       //"eret                          \n"
 		       //"1:nop                         \n"
 		       "nop                           \n"
 		       "nop                           \n"
@@ -115,20 +100,20 @@ static __inline__ void sync_istream(void)
 		       "nop                           \n"
 		       "nop                           \n"
 		       "nop                           \n"
-                       ".set pop                      \n"    
+                       ".set pop                      \n"
                        : : : "$8"
 		       );
 }
 
 static __inline__ void cacheop_hazard(void)
 {
-  __asm__ __volatile__ (                                     
-                       ".set push                     \n"    
-                       ".set noreorder                \n"    
-                       " nop;nop;nop;nop              \n"    
-                       " nop;nop;nop;nop              \n"    
-                       ".set pop                      \n"    
-                       );  
+  __asm__ __volatile__ (
+                       ".set push                     \n"
+                       ".set noreorder                \n"
+                       " nop;nop;nop;nop              \n"
+                       " nop;nop;nop;nop              \n"
+                       ".set pop                      \n"
+                       );
 }
 
 static __inline__ void cacheop_sync_istream(void)
@@ -142,20 +127,20 @@ static __inline__ void cacheop_sync_istream(void)
 #if 0
 #define optimize_thread_flush() do { \
   if ( (cpu_logical_map(smp_processor_id()) & 0x03) != 0) return; \
-} while(0) 
+} while(0)
 #else
 #define optimize_thread_flush()
 #endif
 
 extern unsigned long nlm_common_ebase;
 /*****************************************************************************************
- * 
+ *
  * These routines support Generic Kernel cache flush requirements
  *
  *****************************************************************************************/
 void nlm_common_flush_dcache_page(struct page *page)
 {
-  ClearPageDcacheDirty(page);    
+  ClearPageDcacheDirty(page);
 }
 
 EXPORT_SYMBOL(nlm_common_flush_dcache_page);
@@ -163,10 +148,10 @@ EXPORT_SYMBOL(nlm_common_flush_dcache_page);
 static void nlm_common_local_flush_icache_range(unsigned long start, unsigned long end)
 {
   unsigned long addr;
-  
+
   //dbg_msg("flush icache range, start=%lx, end=%lx\n", start, end);
 
-  for(addr = (start & ~((unsigned long)(icache_linesz - 1))); addr < end; 
+  for(addr = (start & ~((unsigned long)(icache_linesz - 1))); addr < end;
             addr += icache_linesz) {
     cacheop_extable(Hit_Invalidate_I, addr);
   }
@@ -200,15 +185,15 @@ void nlm_common_flush_icache_range(unsigned long start, unsigned long end)
   dbg_msg("return address: ");
   print_symbol("ra[0]=%s\n", return_address());
 #endif
-  
+
   if ((end - start) > PAGE_SIZE) {
     dbg_msg("flushing more than page size of icache addresses starting @ %lx\n", start);
   }
-  
+
   args.start = start;
   args.end = end;
-  /* TODO: don't even send ipi to non-zero thread ids 
-   * This may require some changes to smp_call_function interface, for now just avoid 
+  /* TODO: don't even send ipi to non-zero thread ids
+   * This may require some changes to smp_call_function interface, for now just avoid
    * redundant cache ops
    */
   on_each_cpu(nlm_common_flush_icache_range_ipi, &args, 1);
@@ -231,9 +216,9 @@ static void nlm_common_flush_cache_sigtramp(unsigned long addr)
 }
 
 /*****************************************************************************************
- * 
+ *
  * These routines support MIPS specific cache flush requirements.
- * These are called only during bootup or special system calls 
+ * These are called only during bootup or special system calls
  *
  *****************************************************************************************/
 
@@ -250,7 +235,7 @@ static void nlm_common_local_flush_icache(void)
     base += icache_linesz;
   }
 
-  cacheop_sync_istream(); 
+  cacheop_sync_istream();
 
 }
 
@@ -263,14 +248,14 @@ static void nlm_common_local_flush_dcache(void)
   //dbg_msg("flushing the whole damn local D-cache\n");
 
   lines = current_cpu_data.dcache.ways * current_cpu_data.dcache.sets;
-  
-  /* Index Invalidate all the lines and the ways */  
+
+  /* Index Invalidate all the lines and the ways */
   for(i=0;i<lines;i++) {
     cacheop(Index_Writeback_Inv_D, base);
     base += current_cpu_data.dcache.linesz;
   }
 
-  cacheop_hazard(); 
+  cacheop_hazard();
 
 }
 
@@ -288,7 +273,7 @@ static void nlm_common_flush_l1_caches_ipi(void *info)
 #endif
 {
   optimize_thread_flush();
- 
+
   nlm_common_local_flush_dcache();
   nlm_common_local_flush_icache();
 }
@@ -340,7 +325,7 @@ static __init void probe_l1_cache(void)
     printk("Primary instruction cache %dkB, %d-way, linesize %d bytes.\n",
 	   icache_size >> 10,
 	   c->icache.ways, c->icache.linesz);
-    
+
     printk("Primary data cache %dkB %d-way, linesize %d bytes.\n",
 	   dcache_size >> 10, c->dcache.ways, c->dcache.linesz);
   }
@@ -379,11 +364,11 @@ void ld_mmu_xlr(void)
 
 	probe_l1_cache();
 
-	if (smp_processor_id()) {  
+	if (smp_processor_id()) {
 
 #if 0
-		/* flush the exception vector region to make sure 
-		 * not to execute bootloader's exception code 
+		/* flush the exception vector region to make sure
+		 * not to execute bootloader's exception code
 		 */
 		nlm_common_local_flush_icache_range(nlm_common_ebase, nlm_common_ebase + 0x400);
 #endif
@@ -399,18 +384,18 @@ void ld_mmu_xlr(void)
 	icache_linesz = current_cpu_data.icache.linesz;
 
 	/* When does this function get called? Looks like MIPS has some syscalls
-	 * to flush the caches. 
+	 * to flush the caches.
 	 */
 	__flush_cache_all = nlm_common_flush_l1_caches;
 
 	/* flush_cache_all: makes all kernel data coherent.
 	 * This gets called just before changing or removing
-	 * a mapping in the page-table-mapped kernel segment (kmap). 
+	 * a mapping in the page-table-mapped kernel segment (kmap).
 	 * Physical Cache -> do nothing
 	 */
 	flush_cache_all = nlm_common_noflush;
 
-	/* flush_icache_range: makes the range of addresses coherent w.r.t I-cache and D-cache 
+	/* flush_icache_range: makes the range of addresses coherent w.r.t I-cache and D-cache
 	 * This gets called after the instructions are written to memory
 	 * All addresses are valid kernel or mapped user-space virtual addresses
 	 */
@@ -426,7 +411,7 @@ void ld_mmu_xlr(void)
 	flush_cache_page = (void *) nlm_common_noflush;
 
 	/* flush_icache_page: flush_dcache_page + update_mmu_cache takes care of this
-	 * 
+	 *
 	 */
 	flush_data_cache_page = (void *) nlm_common_noflush;
 
@@ -481,7 +466,7 @@ static inline void cacheop_paddr(const unsigned int op, phys_t base)
 		"dli $8,0x9800000000000000\n"
 		"dsll32 %0, %2,0\n"
 		"or %0,%0,%3\n"
-		"daddu $8, $8, %0\n"  
+		"daddu $8, $8, %0\n"
 		"cache %1, 0($8)\n"
 		".set pop\n"
 		".set reorder\n"
@@ -505,14 +490,14 @@ static inline void cacheop_paddr(const unsigned int op, phys_t base)
         ".set pop\n"          \
         : "=r"(flags) ); \
   preempt_enable();
-	
+
 #define disable_KX(flags)   \
  __asm__ __volatile__ (          \
 	".set push\n"              \
 	"mtc0 %0, $12\n"       \
         ".set pop\n"          \
         : : "r"(flags) )
-	
+
 
 #define SETS_PER_WAY_SHIFT 22
 #define SETS_PER_WAY_MASK 0x7
@@ -560,7 +545,7 @@ static void nlm_common_local_flush_icache_range_paddr(phys_t start, phys_t end)
 
 #ifdef CONFIG_NLM_VMIPS
 	for(;tlbe >= tlbs; tlbe--)
-        nlm_vmips_wired_entry_remove(tlbe); 
+        nlm_vmips_wired_entry_remove(tlbe);
 
 #endif
 	cacheop_sync_istream();
@@ -583,11 +568,11 @@ void nlm_common_flush_icache_range_paddr(phys_t start)
   dbg_msg("return address: ");
   print_symbol("ra[0]=%s\n", (unsigned long) return_address());
 #endif
-  
+
   args.start = start;
   args.end = start + PAGE_SIZE;
-  /* TODO: don't even send ipi to non-zero thread ids 
-   * This may require some changes to smp_call_function interface, for now just avoid 
+  /* TODO: don't even send ipi to non-zero thread ids
+   * This may require some changes to smp_call_function interface, for now just avoid
    * redundant cache ops
    */
   on_each_cpu(nlm_common_flush_icache_range_paddr_ipi, &args, 1);
diff --git a/arch/mips/mm/tlb-r4k.c b/arch/mips/mm/tlb-r4k.c
index 7d97857..8b2abbe 100644
--- a/arch/mips/mm/tlb-r4k.c
+++ b/arch/mips/mm/tlb-r4k.c
@@ -84,29 +84,14 @@ extern void build_tlb_refill_handler(void);
 extern int nlm_vmips_max_wired_entries;
 #endif
 
-#ifdef CONFIG_NLM_XLP
-
-#define disable_pgwalker(flags) \
-({ flags = read_c0_config7(); \
-   write_c0_config7(read_c0_config7() & ~ENABLE_PGWALKER); })
-#define enable_pgwalker(flags) \
-({ write_c0_config7(read_c0_config7() | (flags & ENABLE_PGWALKER)); })
-
-#else
-
-#define disable_pgwalker(flags) {}
-#define enable_pgwalker(flags) {}
-
-#endif
-
 void local_flush_tlb_all(void)
 {
-	unsigned long flags, config7_flags __maybe_unused;
+	unsigned long flags, config6_flags __maybe_unused;
 	unsigned long old_ctx;
 	int entry;
 
 	ENTER_CRITICAL(flags);
-	disable_pgwalker(config7_flags);
+	disable_pgwalker(config6_flags);
 	/* Save old context and create impossible VPN2 value */
 	old_ctx = read_c0_entryhi();
 	write_c0_entrylo0(0);
@@ -134,7 +119,7 @@ void local_flush_tlb_all(void)
 	tlbw_use_hazard();
 	write_c0_entryhi(old_ctx);
 	FLUSH_ITLB;
-	enable_pgwalker(config7_flags);
+	enable_pgwalker(config6_flags);
 	EXIT_CRITICAL(flags);
 }
 
@@ -143,17 +128,17 @@ void local_flush_tlb_all(void)
 void local_flush_tlb_mm(struct mm_struct *mm)
 {
 	int cpu;
-	unsigned long config7_flags __maybe_unused;
+	unsigned long config6_flags __maybe_unused;
 
 	preempt_disable();
 
 	cpu = smp_processor_id();
 
-	disable_pgwalker(config7_flags);
+	disable_pgwalker(config6_flags);
 	if (cpu_context(cpu, mm) != 0) {
 		drop_mmu_context(mm, cpu);
 	}
-	enable_pgwalker(config7_flags);
+	enable_pgwalker(config6_flags);
 	preempt_enable();
 }
 
@@ -165,10 +150,10 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 
 	if (cpu_context(cpu, mm) != 0) {
 		unsigned long size, flags;
-		unsigned long config7_flags __maybe_unused;
+		unsigned long config6_flags __maybe_unused;
 
 		ENTER_CRITICAL(flags);
-		disable_pgwalker(config7_flags);
+		disable_pgwalker(config6_flags);
 		size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
 		size = (size + 1) >> 1;
 		if (size <= current_cpu_data.tlbsize/2) {
@@ -206,7 +191,7 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 			drop_mmu_context(mm, cpu);
 		}
 		FLUSH_ITLB;
-		enable_pgwalker(config7_flags);
+		enable_pgwalker(config6_flags);
 		EXIT_CRITICAL(flags);
 	}
 }
@@ -214,10 +199,10 @@ void local_flush_tlb_range(struct vm_area_struct *vma, unsigned long start,
 void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
 {
 	unsigned long size, flags;
-	unsigned long config7_flags __maybe_unused;
+	unsigned long config6_flags __maybe_unused;
 
 	ENTER_CRITICAL(flags);
-	disable_pgwalker(config7_flags);
+	disable_pgwalker(config6_flags);
 	size = (end - start + (PAGE_SIZE - 1)) >> PAGE_SHIFT;
 	size = (size + 1) >> 1;
 	if (size <= current_cpu_data.tlbsize / 2) {
@@ -255,7 +240,7 @@ void local_flush_tlb_kernel_range(unsigned long start, unsigned long end)
 		local_flush_tlb_all();
 	}
 	FLUSH_ITLB;
-	enable_pgwalker(config7_flags);
+	enable_pgwalker(config6_flags);
 	EXIT_CRITICAL(flags);
 }
 
@@ -264,13 +249,13 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
 	int cpu = smp_processor_id();
 
 	if (cpu_context(cpu, vma->vm_mm) != 0) {
-		unsigned long flags, config7_flags __maybe_unused;
+		unsigned long flags, config6_flags __maybe_unused;
 		int oldpid, newpid, idx;
 
 		newpid = cpu_asid(cpu, vma->vm_mm);
 		page &= (PAGE_MASK << 1);
 		ENTER_CRITICAL(flags);
-		disable_pgwalker(config7_flags);
+		disable_pgwalker(config6_flags);
 		oldpid = read_c0_entryhi();
 		write_c0_entryhi(page | newpid);
 		mtc0_tlbw_hazard();
@@ -294,7 +279,7 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
 	finish:
 		write_c0_entryhi(oldpid);
 		FLUSH_ITLB_VM(vma);
-		enable_pgwalker(config7_flags);
+		enable_pgwalker(config6_flags);
 		EXIT_CRITICAL(flags);
 	}
 }
@@ -305,11 +290,11 @@ void local_flush_tlb_page(struct vm_area_struct *vma, unsigned long page)
  */
 void local_flush_tlb_one(unsigned long page)
 {
-	unsigned long flags, config7_flags __maybe_unused;
+	unsigned long flags, config6_flags __maybe_unused;
 	int oldpid, idx;
 
 	ENTER_CRITICAL(flags);
-	disable_pgwalker(config7_flags);
+	disable_pgwalker(config6_flags);
 	oldpid = read_c0_entryhi();
 	page &= (PAGE_MASK << 1);
 	write_c0_entryhi(page);
@@ -332,7 +317,7 @@ void local_flush_tlb_one(unsigned long page)
 	}
 	write_c0_entryhi(oldpid);
 	FLUSH_ITLB;
-	enable_pgwalker(config7_flags);
+	enable_pgwalker(config6_flags);
 	EXIT_CRITICAL(flags);
 }
 
@@ -349,7 +334,7 @@ void __update_tlb(struct vm_area_struct * vma, unsigned long address, pte_t pte)
 	pmd_t *pmdp;
 	pte_t *ptep;
 	int idx, pid;
-	unsigned long config7_flags;
+	unsigned long config6_flags;
 
 	/*
 	 * Handle debugger faulting in for debugee.
@@ -358,7 +343,7 @@ void __update_tlb(struct vm_area_struct * vma, unsigned long address, pte_t pte)
 		return;
 
 	ENTER_CRITICAL(flags);
-	disable_pgwalker(config7_flags);
+	disable_pgwalker(config6_flags);
 
 	pid = read_c0_entryhi() & ASID_MASK;
 	address &= (PAGE_MASK << 1);
@@ -407,7 +392,7 @@ void __update_tlb(struct vm_area_struct * vma, unsigned long address, pte_t pte)
 	}
 	tlbw_use_hazard();
 	FLUSH_ITLB_VM(vma);
-	enable_pgwalker(config7_flags);
+	enable_pgwalker(config6_flags);
 	EXIT_CRITICAL(flags);
 }
 
@@ -452,10 +437,10 @@ void __init add_wired_entry(unsigned long entrylo0, unsigned long entrylo1,
 	unsigned long wired;
 	unsigned long old_pagemask;
 	unsigned long old_ctx;
-	unsigned long config7_flags;
+	unsigned long config6_flags;
 
 	ENTER_CRITICAL(flags);
-	disable_pgwalker(config7_flags);
+	disable_pgwalker(config6_flags);
 	/* Save old context and create impossible VPN2 value */
 	old_ctx = read_c0_entryhi();
 	old_pagemask = read_c0_pagemask();
@@ -475,7 +460,7 @@ void __init add_wired_entry(unsigned long entrylo0, unsigned long entrylo1,
 	tlbw_use_hazard();	/* What is the hazard here? */
 	write_c0_pagemask(old_pagemask);
 	local_flush_tlb_all();
-	enable_pgwalker(config7_flags);
+	enable_pgwalker(config6_flags);
 	EXIT_CRITICAL(flags);
 }
 
@@ -495,10 +480,10 @@ __init int add_temporary_entry(unsigned long entrylo0, unsigned long entrylo1,
 	unsigned long wired;
 	unsigned long old_pagemask;
 	unsigned long old_ctx;
-	unsigned long config7_flags;
+	unsigned long config6_flags;
 
 	ENTER_CRITICAL(flags);
-	disable_pgwalker(config7_flags);
+	disable_pgwalker(config6_flags);
 	/* Save old context and create impossible VPN2 value */
 	old_ctx = read_c0_entryhi();
 	old_pagemask = read_c0_pagemask();
@@ -522,7 +507,7 @@ __init int add_temporary_entry(unsigned long entrylo0, unsigned long entrylo1,
 	write_c0_entryhi(old_ctx);
 	write_c0_pagemask(old_pagemask);
 out:
-	enable_pgwalker(config7_flags);
+	enable_pgwalker(config6_flags);
 	EXIT_CRITICAL(flags);
 	return ret;
 }
diff --git a/arch/mips/netlogic/xlp/Makefile b/arch/mips/netlogic/xlp/Makefile
index c9b12fd..cfbdfc8 100644
--- a/arch/mips/netlogic/xlp/Makefile
+++ b/arch/mips/netlogic/xlp/Makefile
@@ -1,10 +1,13 @@
 EXTRA_CFLAGS := -Werror
 EXTRA_CFLAGS := $(CFLAGS) -DNLM_HAL_LINUX_KERNEL -Iarch/mips/include/asm/netlogic/hal
 
-obj-y                    	= setup.o
+obj-y                    	= setup.o nmi.o
 obj-y 				+= irq.o time.o on_chip.o mmu.o
-obj-$(CONFIG_NLM_XLP) 	+= platform-xlp.o
+obj-$(CONFIG_NLM_XLP) 		+= platform-xlp.o
 obj-$(CONFIG_SMP)       	+= smp.o
 
-obj-$(CONFIG_KGDB)      	+= nmi.o
-obj-$(CONFIG_NLM_XLP) 	+= cpu_control.o cpu_control_asm.o
+ifeq ($(CONFIG_XEN),y)
+obj-y += xenbootinfo.o
+endif
+
+obj-$(CONFIG_NLM_XLP) += cpu_control.o cpu_control_asm.o
diff --git a/arch/mips/netlogic/xlp/mmu.c b/arch/mips/netlogic/xlp/mmu.c
index 6d1ca8e..adeece0 100644
--- a/arch/mips/netlogic/xlp/mmu.c
+++ b/arch/mips/netlogic/xlp/mmu.c
@@ -52,45 +52,13 @@ int __init disable_128tlb(char *str)
 }
 __setup("disable_128tlb", disable_128tlb);
 
-int __init disable_pgwalker(char *str)
+int __init disable_pgwalker_cmdline(char *str)
 {
 	tlb_config &= ~ENABLE_PGWALKER;
 
 	return 1;
 }
-__setup("disable_pgwalker", disable_pgwalker);
-
-void mmu_init(void)
-{
-	write_c0_config6(read_c0_config6() | tlb_config);
-
-	/* 
-	 * Read back TLB entries after configuration
-	 */
-	current_cpu_data.tlbsize = (read_c0_config6() >> 16 ) & 0xffff;
-
-	/* 
-	 * shift right half the number of 1s in 
-	 * the pagemask and populate that value
-	 */
-	write_c0_config7(PM_DEFAULT_MASK >> (13 + (ffz(PM_DEFAULT_MASK >> 13) / 2)));
-#ifdef DEBUG
-	printk(KERN_INFO "( %s ): write_c0_config7 = %d\n", __FUNCTION__,
-		   read_c0_config7());
-#endif
-
-#ifdef CONFIG_EXEC_INHIBIT
-	pagegrain_write(pagegrain_read() | EXEC_INHIBIT);
-#endif
-
-#ifdef CONFIG_READ_INHIBIT
-	pagegrain_write(pagegrain_read() | READ_INHIBIT);
-#endif
-
-	pgwalker_init();
-	tlbstats_init();
-	entrylo0_mask_init();
-}
+__setup("disable_pgwalker", disable_pgwalker_cmdline);
 
 /*
  * Page Walker
@@ -104,68 +72,82 @@ static int pgtable_levels = PGD | PMD | PTE;
 static int pgtable_levels = PGD | PTE;
 #endif
 
-void pgwalker_init(void)
+static void pgwalker_init(void)
 {
 	unsigned int value;
+	int i = 0;
+
+	if (!(tlb_config & ENABLE_PGWALKER)) return;
+
+	/* Initialize pgd_bases to default values */
+	for(i = 0; i < NR_ADDR_SEGMENTS; i++) {
+		get_cpu_var(pgd_bases)[i] = (unsigned long)swapper_pg_dir;
+		put_cpu_var(pgd_bases);
+	}
 
-	if (read_c0_config6() & ENABLE_PGWALKER) {
-		/* 
-		 * hardware page levels information:
-		 * 
-		 * [15:8] no of top-most bits of vaddr used to form
-		 *        an index into the pgdirs table
-		 * [ 7:4] shift amount by which pfn (page frame number)
-		 *        needs to be left shifted for populating the
-		 *        entrylo0 and entrylo1 registers
-		 * [ 3:0] page table levels used. 32-bit kernels use 
-		 *        pgd and pte levels, while 64-bits kernels
-		 *        use pgd, pmd, and pte
-		 */
-		value  = ((ffs(NR_ADDR_SEGMENTS) - 1) & 0xff) << 8;
-		value |= ENTRYLO_PFN_SHIFT << 4;
-		value |= pgtable_levels;
-		pgw_register_write_w(PGW_MMU_INFO, value);
+	/* 
+	 * hardware page levels information:
+	 * 
+	 * [15:8] no of top-most bits of vaddr used to form
+	 *        an index into the pgdirs table
+	 * [ 7:4] shift amount by which pfn (page frame number)
+	 *        needs to be left shifted for populating the
+	 *        entrylo0 and entrylo1 registers
+	 * [ 3:0] page table levels used. 32-bit kernels use 
+	 *        pgd and pte levels, while 64-bits kernels
+	 *        use pgd, pmd, and pte
+	 */
+	value  = ((ffs(NR_ADDR_SEGMENTS) - 1) & 0xff) << 8;
+	value |= ENTRYLO_PFN_SHIFT << 4;
+	value |= pgtable_levels;
+	pgw_register_write_w(PGW_MMU_INFO, value);
 
 #ifdef CONFIG_64BIT
-		pgw_register_write_d(PGW_PGD_BASES, (unsigned long long)&(__get_cpu_var(pgd_bases)[0]));
+	pgw_register_write_d(PGW_PGD_BASES, (unsigned long long)&(__get_cpu_var(pgd_bases)[0]));
 #else
-		pgw_register_write_w(PGW_PGD_BASES, (unsigned int)&(__get_cpu_var(pgd_bases)[0]));
+	pgw_register_write_w(PGW_PGD_BASES, (unsigned int)&(__get_cpu_var(pgd_bases)[0]));
 #endif
 
-		/* PGD shift and mask information */
-		pgw_register_write_w(PGW_PGD_SHIFT, _PGDIR_SHIFT - _PGD_T_LOG2);
-		pgw_register_write_w(PGW_PGD_MASK, (_PTRS_PER_PGD - 1) << _PGD_T_LOG2);
+	/* PGD shift and mask information */
+	pgw_register_write_w(PGW_PGD_SHIFT, _PGDIR_SHIFT - _PGD_T_LOG2);
+	pgw_register_write_w(PGW_PGD_MASK, (_PTRS_PER_PGD - 1) << _PGD_T_LOG2);
 #ifdef CONFIG_64BIT
-		/*
-		 * MIPS Linux currently does not use 4-level page tables
-		 * and hence it is not necessary to fill in pud information
-		 *
-		 * So, just fill in the PMD shift and mask information 
-		 */
-		pgw_register_write_w(PGW_PMD_SHIFT, _PMD_SHIFT - _PMD_T_LOG2);
-		pgw_register_write_w(PGW_PMD_MASK, (_PTRS_PER_PMD - 1) << _PMD_T_LOG2);
+	/*
+	 * MIPS Linux currently does not use 4-level page tables
+	 * and hence it is not necessary to fill in pud information
+	 *
+	 * So, just fill in the PMD shift and mask information 
+	 */
+	pgw_register_write_w(PGW_PMD_SHIFT, _PMD_SHIFT - _PMD_T_LOG2);
+	pgw_register_write_w(PGW_PMD_MASK, (_PTRS_PER_PMD - 1) << _PMD_T_LOG2);
 #endif
 
-		/* PTE shift and mask */
-		pgw_register_write_w(PGW_PTE_SHIFT, PAGE_SHIFT - _PTE_T_LOG2);
-		pgw_register_write_w(PGW_PTE_MASK, (_PTRS_PER_PTE - 1) << _PTE_T_LOG2);
+	/* PTE shift and mask */
+	pgw_register_write_w(PGW_PTE_SHIFT, PAGE_SHIFT - _PTE_T_LOG2);
+	pgw_register_write_w(PGW_PTE_MASK, (_PTRS_PER_PTE - 1) << _PTE_T_LOG2);
 
-		get_cpu_var(pgd_bases)[VMALLOC_SEG] = (unsigned long) swapper_pg_dir;
+	/* PUD shift and mask */
+	pgw_register_write_w(PGW_PUD_SHIFT, 0);
+	pgw_register_write_w(PGW_PUD_MASK, 0);
+
+	get_cpu_var(pgd_bases)[VMALLOC_SEG] = (unsigned long)swapper_pg_dir;
 
 #ifdef MODULE_START
-		__get_cpu_var(pgd_bases)[MODULE_SEG] = (unsigned long)
-                    swapper_pg_dir;
+	__get_cpu_var(pgd_bases)[MODULE_SEG] = (unsigned long)swapper_pg_dir;
 #endif
-		put_cpu_var(pgd_bases);
 
-		dump_pgwalker_config();
-		printk("Initialized Page Walker on cpu@%d\n", hard_smp_processor_id());
-	}
+
+	put_cpu_var(pgd_bases);
+
+	dump_pgwalker_config();
+	printk("Initialized Page Walker on cpu@%d\n", hard_smp_processor_id());
 }
 
 void dump_pgwalker_config(void)
 {
 #ifdef DEBUG
+	int i = 0;
+
 	pgw_print_w(PGW_MMU_INFO);
 	pgw_print_w(PGW_PGD_SHIFT);
 	pgw_print_w(PGW_PGD_MASK);
@@ -173,5 +155,47 @@ void dump_pgwalker_config(void)
 	pgw_print_w(PGW_PMD_MASK);
 	pgw_print_w(PGW_PTE_SHIFT);
 	pgw_print_w(PGW_PTE_MASK);
+	pgw_print_w(PGW_PUD_SHIFT);
+	pgw_print_w(PGW_PUD_MASK);
+
+	printk("swapper_pg_dir = %lx\n", (unsigned long)swapper_pg_dir);
+	for(i = 0; i < NR_ADDR_SEGMENTS; i++) {
+		printk("pgd_bases[%d] = 0x%lx\n", i, __get_cpu_var(pgd_bases)[i]);
+	}
+
+#endif
+}
+
+void mmu_init(void)
+{
+
+	/* 
+	 * Read back TLB entries after configuration
+	 */
+	current_cpu_data.tlbsize = (read_c0_config6() >> 16 ) & 0xffff;
+
+	/* 
+	 * shift right half the number of 1s in 
+	 * the pagemask and populate that value
+	 */
+	write_c0_config7(PM_DEFAULT_MASK >> (13 + (ffz(PM_DEFAULT_MASK >> 13) / 2)));
+#ifdef DEBUG
+	printk(KERN_INFO "( %s ): write_c0_config7 = %d\n", __FUNCTION__,
+		   read_c0_config7());
+#endif
+
+#ifdef CONFIG_EXEC_INHIBIT
+	pagegrain_write(pagegrain_read() | EXEC_INHIBIT);
 #endif
+
+#ifdef CONFIG_READ_INHIBIT
+	pagegrain_write(pagegrain_read() | READ_INHIBIT);
+#endif
+
+	pgwalker_init();
+	tlbstats_init();
+	entrylo0_mask_init();
+
+	/* Intialize after pgwalker and others are configured! */
+	write_c0_config6(read_c0_config6() | tlb_config);
 }
diff --git a/arch/mips/netlogic/xlp/nmi.S b/arch/mips/netlogic/xlp/nmi.S
index a584663..61006eb 100644
--- a/arch/mips/netlogic/xlp/nmi.S
+++ b/arch/mips/netlogic/xlp/nmi.S
@@ -44,20 +44,26 @@ NESTED(nlm_except_vec_nmi, 0, sp)
 	.set noat
 	.set mips64
 	.set noreorder
+#ifdef CONFIG_KGDB
 	MTC0	k0, OS_KGDB_SCRATCH_REG6
 	nop
 	nop
-	PTR_LA	k0, nlm_nmi_handler
+	PTR_LA	k0, nlm_nmi_kgdb_handler
 	jr       k0
 	nop
+#else
+1:	wait
+	b	1b
+	nop
+#endif
 	.set pop
 END(nlm_except_vec_nmi)
 
-
+#ifdef CONFIG_KGDB
 	/* This nmi handler is currently only for taking oprofile samples
 	   on non-zero cpus
 	   */
-NESTED(nlm_nmi_handler, PT_SIZE,  sp)
+NESTED(nlm_nmi_kgdb_handler, PT_SIZE,  sp)
 	.set	push
 	.set	noat
 	.set noreorder
@@ -66,7 +72,7 @@ NESTED(nlm_nmi_handler, PT_SIZE,  sp)
 	/* Save K0 and K1 first */
 	/* K0 is already saved in nlm_except_vec_nmi */
 	MTC0	k1, OS_KGDB_SCRATCH_REG7
-	
+
 	/* Clear the  NMI and BEV bits */
 	MFC0	k0, CP0_STATUS
 	li 	k1, 0xffb7ffff
@@ -97,9 +103,10 @@ NESTED(nlm_nmi_handler, PT_SIZE,  sp)
 
 	MFC0	k0, OS_KGDB_SCRATCH_REG6
 	MFC0	k1, OS_KGDB_SCRATCH_REG7
-	
+
 	.set mips3
 	eret
 
 	.set pop
-END(nlm_nmi_handler)
+END(nlm_nmi_kgdb_handler)
+#endif
\ No newline at end of file
diff --git a/arch/mips/netlogic/xlp/on_chip.c b/arch/mips/netlogic/xlp/on_chip.c
index 6457eec..7b56e0d 100644
--- a/arch/mips/netlogic/xlp/on_chip.c
+++ b/arch/mips/netlogic/xlp/on_chip.c
@@ -276,6 +276,29 @@ int register_xlp_msgring_handler(int major,
 
 EXPORT_SYMBOL(register_xlp_msgring_handler);
 
+#include <asm/netlogic/cpumask.h>
+void nlm_nmi_cpus(unsigned int mask)
+{
+	uint32_t cpumask = cpumask_to_uint32(&cpu_present_map); /* doesn't handle non-n0 nodes */
+	uint32_t cpumask_lo;
+	uint32_t cpumask_hi;
+	const int nmi = 1;
+
+	pic_reg_t *mmio = nlm_hal_pic_offset();
+
+	cpumask = cpumask & mask;
+
+	cpumask_hi = cpumask >> 16;;
+	cpumask_lo = cpumask & 0xffff;
+
+	/* Send IRQ_MSGRING vector in an IPI to all cpus but the current one */
+	if (cpumask_lo)
+		nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, (nmi << 31) | cpumask_lo );
+
+	if (cpumask_hi)
+		nlm_hal_write_pic_reg(mmio, PIC_IPI_CTL, (nmi << 31) | (1 << 16) | (cpumask_hi));
+}
+
 
 /*********************************************************************
  * enable_msgconfig_int 
diff --git a/arch/mips/netlogic/xlp/setup.c b/arch/mips/netlogic/xlp/setup.c
index 2eb6f86..f3fc4f6 100644
--- a/arch/mips/netlogic/xlp/setup.c
+++ b/arch/mips/netlogic/xlp/setup.c
@@ -347,15 +347,12 @@ static void prom_add_memory(uint64_t start, uint64_t size)
 
 void __init nlm_nmi_setup (void)
 {
-	/* setup nmi handler only if KGDB is enabled */
-#ifdef CONFIG_KGDB
 	void *base;
 	extern char nlm_except_vec_nmi;
 
 	printk("Setting up NMI Handler \n");
 	base = (void *)(unsigned long)0xffffffffbfc00000ULL;
 	memcpy(base, &nlm_except_vec_nmi, 0x80);
-#endif
 }
 
 /* setup early serial port driver */
@@ -591,8 +588,6 @@ void __init prom_init(void)
 {
 	setup_mapped_kernel_tlbs(TRUE, TRUE);
 
-        strcat(arcs_cmdline, " disable_pgwalker ");
-
 	fdt_process();
 
 	xen_init();
-- 
1.7.10.4

