From e29cb8b4eec496e0565b78efcec5342c1280c802 Mon Sep 17 00:00:00 2001
From: Sreenidhi BR <sreenidhibr@netlogicmicro.com>
Date: Thu, 23 Jun 2011 12:38:26 +0530
Subject: [PATCH 296/762] adding msgtype 7 (p2p) for handling large memcpy (> 1MB).

Based on Broadcom SDK 2.3.

Signed-off-by: Sreenidhi BR <sreenidhibr@netlogicmicro.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 drivers/dma/nlm_adma.c |  298 ++++++++++++++++++++++++++++++------------------
 drivers/dma/nlm_adma.h |    8 +-
 2 files changed, 194 insertions(+), 112 deletions(-)

diff --git a/drivers/dma/nlm_adma.c b/drivers/dma/nlm_adma.c
index a70c04f..51dc836 100644
--- a/drivers/dma/nlm_adma.c
+++ b/drivers/dma/nlm_adma.c
@@ -106,6 +106,66 @@ uint64_t gen_dtr_raid_msg_format_2 (const void * ret_entry)
 }
 
 
+static __inline__
+uint64_t gen_dtr_xfer_msg_format_0 (const unsigned long len, const uint64_t src)
+{
+	return (1ULL << 63)
+		| shift_lower_bits(0, 60, 3)  /* msgtype 0 for transfer */
+		| shift_lower_bits(len, 40, 20)
+		| shift_lower_bits ((volatile void *)src, 0, 40);
+}
+
+static __inline__
+uint64_t gen_dtr_xfer_msg_format_1 (const uint32_t dest_id)
+{
+	return (0ULL << 63)
+		| shift_lower_bits (1, 59, 1) /* write control */
+		| shift_lower_bits (1, 56, 1) /* Inform Source */
+		| shift_lower_bits (dest_id, 44, 12);
+}
+
+static __inline__
+uint64_t gen_dtr_xfer_msg_format_2 (const uint64_t dst)
+{
+	return (0ULL << 63)
+		| shift_lower_bits (1, 40, 1) /* perform transfer */
+		| shift_lower_bits ((volatile void *)dst, 0, 40);
+}
+
+static __inline__
+uint64_t gen_dtr_xfer_msg_format_3 (const void * ret_entry)
+{
+	return 0ULL << 63
+		| shift_lower_bits ((unsigned long)ret_entry, 0, 63);
+}
+
+static __inline__
+uint64_t gen_dtr_xfer_p2pmsg_format_0 (const uint32_t len, const uint64_t src)
+{
+	return (1ULL << 63)
+		| shift_lower_bits (7, 60, 3) /* msgtype 7 for p2p */
+		| shift_lower_bits (len, 40, 20)
+		| shift_lower_bits ((volatile void *)src, 0, 40);
+}
+
+static __inline__
+uint64_t gen_dtr_xfer_p2pmsg_format_1 (const uint32_t dest_id)
+{
+	return (0ULL << 63)
+		| shift_lower_bits (0, 62, 1)  /* i/o data interconnect */
+		| shift_lower_bits (1, 56, 1) /* Inform Source */
+		| shift_lower_bits (dest_id, 44, 12);
+}
+
+static __inline__
+uint64_t gen_dtr_xfer_p2pmsg_format_2 (const void * ret_entry)
+{
+	return 0ULL << 63
+		| shift_lower_bits ((unsigned long)ret_entry, 0, 63);
+}
+
+
+
 static void nlm_dtre_msgring_handler(uint32_t vc, uint32_t src_id,
 		uint32_t size, uint32_t code,
 		uint64_t msg0, uint64_t msg1,
@@ -126,7 +186,8 @@ static void nlm_dtre_msgring_handler(uint32_t vc, uint32_t src_id,
 		return;
 	}
 
-	if (nlm_dtre_debug) {
+	if (nlm_dtre_debug) 
+	{
 		printk("DTRE recv msg: vc %d sender 0x%x, size 0x%x, data0 0x%llx data1 0x%llx optype %d.\n",
 				vc, src_id, size, msg0, msg1, desc->optype);
 	}
@@ -268,14 +329,61 @@ static void __process_completed_tx(struct nlm_adma_chan * chan)
 	}
 }
 
+static void dtre_send_message(int vc_id, int msgtype, uint64_t * msg)
+{
+	uint64_t pop_data[4];
+	uint32_t pop_vc, pop_src, pop_size, pop_code;
+	uint32_t freeback_msg_dest_id, msgstatus1;
+	int rc, i;
+
+	freeback_msg_dest_id = (netlogic_cpu_id()*16)+(netlogic_thr_id()*4);
+	rc = 0;
+	i = 0;
+
+	while(1)
+	{
+		rc = xlp_message_send(vc_id, msgtype, 0, msg);
+		if (rc == 0)
+			break;
+
+		/* pop out messages from vc, if any */
+		pop_vc = freeback_msg_dest_id;
+
+		if ((nlm_hal_recv_msg2(pop_vc, &pop_src, &pop_size, &pop_code, &pop_data[0], &pop_data[1])) == 0)
+		{
+			if (nlm_dtre_debug)
+				printk("POP msg found in vc.\n");
+			nlm_dtre_msgring_handler(pop_vc, pop_src, pop_size, pop_code, pop_data[0], pop_data[1], pop_data[2], pop_data[3], NULL);
+		}
+
+		if ((i%100) == 0) {
+			msgstatus1 = xlp_read_status1();
+			// printk("DTRE:continuing retry, rc:0x%08x, msgstatus1: 0x%08x.\n", rc, msgstatus1);
+		}
+	}
+
+	if (rc != 0) {
+		msgstatus1 = xlp_read_status1();
+		printk("Error: unable to send DTRE Xfer msg: rc:%d, msgstatus1: 0x%08x.\n", rc, msgstatus1);
+		return;
+	}
+	else {
+		if (nlm_dtre_debug) 
+		{
+			printk("sent msg 0x%llx 0x%llx 0x%llx to %d.\n",
+					msg[0], msg[1], msg[2], vc_id);
+		}
+	}
+}
+
 
 static dma_cookie_t nlm_tx_submit (struct dma_async_tx_descriptor *tx)
 {
 	enum dma_transaction_type optype;
-	int rc, vc_id;
+	int vc_id;
 	uint32_t disks, freeback_msg_dest_id;
 	dma_cookie_t cookie;
-	int i;
+	int i, index, loopout;
 
 	enum nlm_raid_type raid_type;
 	enum nlm_write_syndrome operation;
@@ -284,13 +392,10 @@ static dma_cookie_t nlm_tx_submit (struct dma_async_tx_descriptor *tx)
 	struct nlm_tx_desc *nlm_tx ;
 	struct nlm_adma_chan *chan ;
 
-	uint32_t msgstatus1;
-
 	uint64_t raid_list_msg[DTRE_RAID_LIST_MSG_SIZE] = { 0ULL };
 	uint64_t transfer_msg[DTRE_TRANSFER_MSG_SIZE] = { 0ULL };
 
-	uint64_t pop_data[4];
-	uint32_t pop_vc, pop_src, pop_size, pop_code;
+	unsigned long msg_len, desc_len;
 
 	disks = 0;
 	nlm_tx = tx_to_nlm_adma_tx(tx);
@@ -334,7 +439,8 @@ static dma_cookie_t nlm_tx_submit (struct dma_async_tx_descriptor *tx)
 
 	if (optype == DMA_MEMCPY)
 	{
-		if (nlm_tx->len > DTRE_MAX_MEMCPY_SIZE)
+		/* handle in CPU */
+		if (nlm_tx->len >= DTRE_MAX_MEMCPY_DESC_SIZE)
 		{
 			memcpy((phys_to_virt(nlm_tx->hw_desc.dst)), (phys_to_virt(nlm_tx->hw_desc.src)), nlm_tx->len);
 			nlm_tx->done_flag = 1;
@@ -343,76 +449,93 @@ static dma_cookie_t nlm_tx_submit (struct dma_async_tx_descriptor *tx)
 
 			return cookie;
 		}
-	}
 
+		/* need to send list of descriptors in this case */
+		if ((nlm_tx->len > DTRE_MAX_MEMCPY_SIZE) &&
+				(nlm_tx->len <= DTRE_MAX_MEMCPY_DESC_SIZE))
+		{
+			msg_len = nlm_tx->len;
+			memset(nlm_tx->list_desc, 0, (8*4*DTRE_MAX_MEMCPY_DESC_LIST));
 
-	/* Handle the DMA_MEMSET and DMA_MEMCPY cases first and return.
-	   All RAID messages are handled later 
-	   */
+			/* construct a list of msgtype 0 (msg transfer) */
+			loopout = 0;
+			for (i=0; i<DTRE_MAX_MEMCPY_DESC_LIST; i++)
+			{
+				index = i*4;  /* 4 entry msg */
 
-	if ((optype == DMA_MEMCPY) || (optype == DMA_MEMSET))
-	{
-		transfer_msg[0] = 
-			(1ULL << 63)
-			| shift_lower_bits(0, 60, 3)
-			| shift_lower_bits((nlm_tx->len), 40, 20)
-			| shift_lower_bits ((volatile void *)nlm_tx->hw_desc.src, 0, 40);
+				if (msg_len > DTRE_MAX_MEMCPY_SIZE) {
+					desc_len = DTRE_MAX_MEMCPY_SIZE;
+					msg_len -= DTRE_MAX_MEMCPY_SIZE;
+				}
+				else {
+					desc_len = msg_len;
+					loopout = 1;
+				}
 
-		transfer_msg[1] = 
-			(0ULL << 63)
-			| shift_lower_bits (1, 59, 1) /* write control */
-			| shift_lower_bits (1, 56, 1) /* Inform Source */
-			| shift_lower_bits (freeback_msg_dest_id, 44, 12);
 
-		transfer_msg[2] = 
-			(0ULL << 63)
-			| shift_lower_bits (1, 40, 1) /* perform transfer */
-			| shift_lower_bits ((volatile void *)nlm_tx->hw_desc.dst, 0, 40);
+				/* This is a 4-entry msg */
+				nlm_tx->list_desc[index+0] = gen_dtr_xfer_msg_format_0(desc_len, nlm_tx->hw_desc.src);
+				nlm_tx->list_desc[index+1] = gen_dtr_xfer_msg_format_1(freeback_msg_dest_id);
+				nlm_tx->list_desc[index+2] = gen_dtr_xfer_msg_format_2(nlm_tx->hw_desc.dst);
+				nlm_tx->list_desc[index+3] = gen_dtr_xfer_msg_format_3((void *)((unsigned long)nlm_tx>>1));
 
-		transfer_msg[3] = gen_dtr_raid_msg_format_2((void *)((unsigned long)nlm_tx>>1));
+				if (nlm_dtre_debug)
+				{
+					printk("i %d, len 0x%lx, msg_len 0x%lx.\n", i, desc_len, msg_len);
+					printk("0x%llx, 0x%llx, 0x%llx, 0x%llx.\n",
+							nlm_tx->list_desc[index+0],
+							nlm_tx->list_desc[index+1],
+							nlm_tx->list_desc[index+2],
+							nlm_tx->list_desc[index+3]);
+				}
 
-		vc_id = DTRE_MIN_VC + 1;
-		msgtype = p2d;
+				if (loopout == 1)
+					break;
 
-		rc = 0;
-		i = 0;
-		while(1)
-		{
-			rc = xlp_message_send(vc_id, msgtype, 0, transfer_msg);
-			if (rc == 0)
-				break;
+				/* increment src and dest */
+				nlm_tx->hw_desc.src += desc_len;
+				nlm_tx->hw_desc.dst += desc_len;
 
-			/* pop out messages from vc, if any */
-			pop_vc = freeback_msg_dest_id;
+			}
 
-			if ((nlm_hal_recv_msg2(pop_vc, &pop_src, &pop_size, &pop_code, &pop_data[0], &pop_data[1])) == 0)
+			/* construct msgtype 7 (p2p) */
+			/* 8 bytes per entry * 4 entry msg */
+			raid_list_msg[0] = gen_dtr_xfer_p2pmsg_format_0((i+1)*8*4, (unsigned long)(virt_to_phys((volatile void*)nlm_tx->list_desc)));
+			raid_list_msg[1] = gen_dtr_xfer_p2pmsg_format_1(freeback_msg_dest_id);
+			raid_list_msg[2] = gen_dtr_xfer_p2pmsg_format_2((void *)((unsigned long)nlm_tx>>1));
+
+			if (nlm_dtre_debug)
 			{
-				if (nlm_dtre_debug)
-					printk("POP msg found in vc.\n");
-				nlm_dtre_msgring_handler(pop_vc, pop_src, pop_size, pop_code, pop_data[0], pop_data[1], pop_data[2], pop_data[3], NULL);
+				printk("msg7: 0x%llx, 0x%llx, 0x%llx.\n",
+						raid_list_msg[0],
+						raid_list_msg[1],
+						raid_list_msg[2]);
 			}
 
-			if ((i%100) == 0) {
-				msgstatus1 = xlp_read_status1();
-				// printk("DTRE:continuing retry, rc:0x%08x, msgstatus1: 0x%08x.\n", rc, msgstatus1);
-			}
-		}
+			/* call the send msg function */
+			vc_id = DTRE_MIN_VC + 1;
+			msgtype = p2p;
+			dtre_send_message(vc_id, msgtype, raid_list_msg);
 
-		if (rc != 0) {
-			msgstatus1 = xlp_read_status1();
-			printk("Error: unable to send DTRE Xfer msg: rc:%d, msgstatus1: 0x%08x.\n", rc, msgstatus1);
-			return -ENODEV;
-		}
-		else {
-			if (nlm_dtre_debug) {
-				printk("sent msg CPY 0x%llx 0x%llx 0x%llx 0x%llx to %d optype %d cookie %d.\n",
-						transfer_msg[0],
-						transfer_msg[1],
-						transfer_msg[2],
-						transfer_msg[3],
-						vc_id, optype, cookie);
-			}
+			return cookie;
 		}
+	}
+
+
+	/* Handle the DMA_MEMSET and DMA_MEMCPY cases first and return.
+	   All RAID messages are handled later 
+	   */
+
+	if ((optype == DMA_MEMCPY) || (optype == DMA_MEMSET))
+	{
+		transfer_msg[0] = gen_dtr_xfer_msg_format_0(nlm_tx->len, nlm_tx->hw_desc.src); 
+		transfer_msg[1] = gen_dtr_xfer_msg_format_1(freeback_msg_dest_id); 
+		transfer_msg[2] = gen_dtr_xfer_msg_format_2(nlm_tx->hw_desc.dst);
+		transfer_msg[3] = gen_dtr_xfer_msg_format_3((void *)((unsigned long)nlm_tx>>1));
+
+		vc_id = DTRE_MIN_VC + 1;
+		msgtype = p2d;
+		dtre_send_message(vc_id, msgtype, transfer_msg);
 
 		return cookie;
 	}
@@ -455,48 +578,7 @@ static dma_cookie_t nlm_tx_submit (struct dma_async_tx_descriptor *tx)
 	raid_list_msg [1] = gen_dtr_raid_msg_format_1(raid_type, operation, disks, freeback_msg_dest_id);
 	raid_list_msg [2] = gen_dtr_raid_msg_format_2((void *)((unsigned long)nlm_tx>>1));
 
-	rc = 0;
-	i = 0;
-	while(1)
-	{
-		i++;
-		rc = xlp_message_send(vc_id, msgtype, 0, raid_list_msg);
-		if (rc == 0)
-			break;
-
-		/* pop out messages from vc, if any */
-		pop_vc = freeback_msg_dest_id;
-
-		if ((nlm_hal_recv_msg2(pop_vc, &pop_src, &pop_size, &pop_code, &pop_data[0], &pop_data[1])) == 0)
-		{
-			if (nlm_dtre_debug)
-				printk("POP msg found in vc.\n");
-			nlm_dtre_msgring_handler(pop_vc, pop_src, pop_size, pop_code, pop_data[0], pop_data[1], pop_data[2], pop_data[3], NULL);
-		}
-
-		if ((i%100) == 0)
-		{
-			msgstatus1 = xlp_read_status1();
-			// printk("DTRE:continuing retry, rc:0x%08x, msgstatus1: 0x%08x.\n", rc, msgstatus1);
-		}
-	}
-
-	if (rc != 0) {
-		msgstatus1 = xlp_read_status1();
-		printk("Error: unable to send DTRE RAID msg: rc:%d, msgstatus1: 0x%08x.\n", rc, msgstatus1);
-
-		return -ENODEV;
-	}
-	else
-	{
-		if (nlm_dtre_debug) {
-			printk("sent msg RAID 0x%llx 0x%llx 0x%llx to %d optype %d cookie %d.\n",
-					raid_list_msg[0],
-					raid_list_msg[1],
-					raid_list_msg[2],
-					vc_id, optype, cookie);
-		}
-	}
+	dtre_send_message(vc_id, msgtype, raid_list_msg);
 
 	return cookie;
 
@@ -1009,9 +1091,6 @@ nlm_adma_prep_dma_pq(struct dma_chan *chan, dma_addr_t *dst, dma_addr_t *src,
 		}
 		pgaddr = (void *)page_to_phys(desc->pg);
 	}
-#if 0
-	pgaddr = (void *)page_to_phys(nlm_dtre_pg);
-#endif
 
 	/* specify valid address for disabled result */
 	if (flags & DMA_PREP_PQ_DISABLE_P)
@@ -1199,9 +1278,6 @@ nlm_adma_prep_dma_pq_val(struct dma_chan *chan, dma_addr_t *pq, dma_addr_t *src,
 		}
 		pgaddr = (void *) page_to_phys(desc->pg);
 	}
-#if 0
-	pgaddr = (void *) page_to_phys(nlm_dtre_pg);
-#endif
 
 	for (i=0; i<DTRE_RAID_MAX_ENTRIES; i++)
 		desc->hw_desc.entries[i] = 0ULL;
diff --git a/drivers/dma/nlm_adma.h b/drivers/dma/nlm_adma.h
index 615b207..1375985 100644
--- a/drivers/dma/nlm_adma.h
+++ b/drivers/dma/nlm_adma.h
@@ -42,7 +42,10 @@ THE POSSIBILITY OF SUCH DAMAGE.
 #define DTRE_RAID_MAX_DEVICES		24
 #define DTRE_RAID_MAX_SRC		16
 #define DTRE_NLM_Q_POLY			0x1d
-#define DTRE_MAX_MEMCPY_SIZE		((1*1024*1024) - 1) /* 1 MB */
+
+#define DTRE_MAX_MEMCPY_SIZE		((1*1024*1024) - 1)  /* 1 MB */
+#define DTRE_MAX_MEMCPY_DESC_LIST	4
+#define DTRE_MAX_MEMCPY_DESC_SIZE	(DTRE_MAX_MEMCPY_DESC_LIST*DTRE_MAX_MEMCPY_SIZE)
 
 #define DTRE_NUM_VC		4
 #define DTRE_MIN_VC		264
@@ -64,6 +67,9 @@ struct nlm_hw_desc {
 };
 
 struct nlm_tx_desc {
+	/* DTRE_MAX_MEMCPY_DESC_LIST(4) descs, each of 4 entry */
+	uint64_t list_desc[DTRE_MAX_MEMCPY_DESC_LIST*4] ____cacheline_aligned; 
+
 	struct nlm_tx_desc * next;
 	struct dma_async_tx_descriptor async_tx;
 	enum dma_transaction_type optype;
-- 
1.7.0.4

