From 0c883e1efa7beec37a42f3a2666baa17c78ba15a Mon Sep 17 00:00:00 2001
From: Hareesh R <hareeshr@broadcom.com>
Date: Mon, 7 Oct 2013 03:48:22 -0700
Subject: nae : Tcp performance fix, GRO support

[Based on SDK 3.2]
Change the function "xlp_poll_upper" type from "inline void"
to "void" because of the compile error.

Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
Signed-off-by: Nam Ninh <nam.ninh@windriver.com>

diff --git a/drivers/net/ethernet/broadcom/nae/xlpge.h b/drivers/net/ethernet/broadcom/nae/xlpge.h
index 0f6533d..3efb508 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge.h
+++ b/drivers/net/ethernet/broadcom/nae/xlpge.h
@@ -420,19 +420,100 @@ static __inline__ void dump_buffer(unsigned char *buf, uint32_t len,
 	printk("%s\n", out);
 }
 
+static inline int mac_refill_frin_skb(nae_t* nae_cfg, int cpu, uint64_t paddr,
+			       uint32_t bufsize, int hw_port_id)
+{
+	/*
+	 * We have to use the logical map here as the below arrays are
+	 * indexed by logical cpu id
+	 */
+	int ret, code, qid;
+	ulong __attribute__ ((unused)) mflags;
+	int node = nae_cfg->node;
+	int nae_id = nae_cfg->nae_id;
+	int node_cpu;
+	extern uint32_t cpu_2_normal_frfifo[NLM_MAX_NODES][MAX_NAE_PERNODE][NR_CPUS];
+	extern uint32_t cpu_2_jumbo_frfifo[NLM_MAX_NODES][MAX_NAE_PERNODE][NR_CPUS];
+	extern int phys_cpu_to_log_map[NLM_MAX_NODES][MAX_NAE_PERNODE][NR_CPUS];
+	extern int enable_jumbo;
+
+	node_cpu = phys_cpu_to_log_map[node][nae_id][cpu];
+
+	if (nae_cfg == NULL) {
+		printk("%s Error, Invalid node id %d\n", __FUNCTION__, node);
+		return -1;
+	}
+
+	if(nae_cfg->port_fifo_en)
+		qid = hw_port_id;
+	else
+		qid = (bufsize >= NLM_RX_JUMBO_BUF_SIZE) ?
+		cpu_2_jumbo_frfifo[node][nae_id][node_cpu] :
+		cpu_2_normal_frfifo[node][nae_id][node_cpu];
+
+	Message("%s in cpu %d bufsize %d node %d qid %d qbase %d node_cpu %d nae_id %d\n",
+		__FUNCTION__, cpu, bufsize, node, qid,
+		nae_cfg->frin_queue_base, node_cpu, nae_id);
+
+	ret = 0;
+	qid = nae_cfg->frin_queue_base + qid;
+
+	/* Assumption: SKB is all set to go */
+	/* Send the free Rx desc to the MAC */
+	code = 0;
+
+	//* Send the packet to nae rx  */
+	msgrng_access_enable(mflags);
+	for (;;) {
+		//ret = netsoc_nae_send_freein_buf(nae_cfg, qid, paddr & 0xffffffffffULL);
+	  	ret = xlp_message_send_1(qid, code, (paddr & 0xffffffffffULL));
+	  if (!ret) break;
+	}
+	msgrng_access_disable(mflags);
+
+	return ret;
+}
+
+static inline int mac_refill_frin_one_buffer(struct net_device *dev, int cpu,
+				      uint32_t truesize)
+{
+	struct dev_data* priv = netdev_priv(dev);
+	struct sk_buff * skb;
+	int buf_size = NLM_RX_ETH_BUF_SIZE;
+	nae_t* nae_cfg = priv->nae;
+	extern int enable_jumbo;
+
+	if (enable_jumbo)
+		if(truesize > NLM_RX_JUMBO_BUF_SIZE)
+			buf_size = NLM_RX_JUMBO_BUF_SIZE;
+
+	skb = nlm_xlp_alloc_skb_atomic(buf_size, priv->node);
+	if (!skb) {
+		printk("[%s] alloc skb failed\n",__FUNCTION__);
+		panic("panic...");
+		return -ENOMEM;
+	}
+
+	skb->dev = dev;
+
+	mac_put_skb_back_ptr(skb, nae_cfg);
+
+	return mac_refill_frin_skb(nae_cfg, cpu, (uint64_t)virt_to_bus(skb->data), buf_size, priv->hw_port_id);
+}
+
+
+
 void nlm_xlp_nae_init(void);
 void nlm_xlp_nae_remove(void);
 extern int xlpge_eeprom_init(void);
 void init_phy_state_timer(void *);
 inline void process_tx_complete(int , uint32_t , uint64_t);
-inline void napi_lro_flush(int);
 struct eeprom_data * get_nlm_eeprom(void);
 unsigned int nlm_xlp_mac_mii_read(struct dev_data *, int);
 void nlm_xlp_mac_mii_write(struct dev_data *, int , uint16_t);
 int xlp_enable_autoneg(struct net_device *, u32);
 int xlp_set_link_speed(struct net_device *, int , int);
 void nlm_nae_remove_procentries(void);
-void lro_init(struct net_device *);
 void xlp_get_mac_stats(struct net_device *, struct net_device_stats *);
 int eth_mac_addr(struct net_device *, void *);
 int nlm_xlp_nae_start_xmit(struct sk_buff *, struct net_device *);
@@ -447,22 +528,15 @@ int nae_proc_read(char *, char **, off_t , int , int *, void *);
 int nlm_xlp_disable_napi(void);
 void nlm_spawn_kthread(void);
 int nlm_xlp_enable_napi(void);
-int mac_refill_frin_skb(nae_t* , int , uint64_t , uint32_t, int);
-int mac_refill_frin_one_buffer(struct net_device *, int , uint32_t);
-void xlp_napi_lro_flush(void *);
+//int mac_refill_frin_skb(nae_t* , int , uint64_t , uint32_t, int);
+//int mac_refill_frin_one_buffer(struct net_device *, int , uint32_t);
 void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag);
-inline void *alloc_p2p_desc_mem(int);
-uint16_t pseuodo_chksum(uint16_t *, uint16_t);
-inline int create_p2p_desc(uint64_t , uint64_t , uint64_t *, int);
-inline void create_last_p2p_desc(uint64_t *, struct sk_buff *, int);
 void xlp_poll_upper(int);
-void free_p2p_desc_mem(int cpu, void *);
-inline int tso_xmit_skb(struct sk_buff *, struct net_device *);
+//inline int tso_xmit_skb(struct sk_buff *, struct net_device *);
 int xlp_config_msec_tx(struct net_device *, struct ethtool_cmd *);
 int xlp_config_msec_tx_mem(struct net_device *, struct ethtool_cmd *);
 int xlp_config_msec_rx(struct net_device *, struct ethtool_cmd *);
 int xlp_config_msec_rx_mem(struct net_device *, struct ethtool_cmd *);
-int tso_enable(struct net_device *, u32);
 int nlm_load_balance_proc_open(struct inode *, struct file *);
 void nlm_init_load_balance(void);
 
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_lro.c b/drivers/net/ethernet/broadcom/nae/xlpge_lro.c
deleted file mode 100644
index 19e9dd8..0000000
--- a/drivers/net/ethernet/broadcom/nae/xlpge_lro.c
+++ /dev/null
@@ -1,116 +0,0 @@
-/*-
- * Copyright (c) 2003-2012 Broadcom Corporation
- * All Rights Reserved
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in
- *    the documentation and/or other materials provided with the
- *    distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
- * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
- * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- * #BRCM_2# */
-
-#include <linux/module.h>
-#include <linux/pci.h>
-#include <linux/netdevice.h>
-#include <linux/inet_lro.h>
-#include <linux/clocksource.h>
-#include <linux/timecompare.h>
-
-#include <nlm_xlp.h>
-#include "xlpge.h"
-
-#ifdef CONFIG_INET_LRO
-
-int enable_lro = 0;
-module_param(enable_lro, int, 0);
-int lro_flush_priv_cnt[NR_CPUS];
-int lro_flush_needed[NR_CPUS][20];
-struct dev_data *lro_flush_priv[NR_CPUS][20];
-
-static int lro_get_skb_hdr(struct sk_buff *skb, void **iphdr, void **tcph,
-			   uint64_t *hdr_flags, void *priv)
-{
-	skb_reset_network_header(skb);
-	skb_set_transport_header(skb, ip_hdrlen(skb));
-
-	if (ip_hdr(skb)->protocol != 0x6)
-		return -1;
-
-	*iphdr = ip_hdr(skb);
-	*tcph = tcp_hdr(skb);
-
-	*hdr_flags = LRO_IPV4 | LRO_TCP;
-	skb->ip_summed = CHECKSUM_UNNECESSARY;
-
-	return 0;
-}
-
-void lro_init(struct net_device *dev)
-{
-	struct dev_data* priv;
-	struct net_lro_mgr *lp;
-	int cpu;
-
-	priv = netdev_priv(dev);
-
-	if (enable_lro) {
-		printk("LRO is enabled \n");
-		dev->features |= NETIF_F_LRO;
-		for (cpu = 0; cpu < NR_CPUS; cpu++) {
-			lp = &priv->lro_mgr[cpu];
-			memset(lp, 0, sizeof(struct net_lro_mgr));
-			lp->max_aggr = 48;
-			lp->max_desc = LRO_MAX_DESCS;
-			lp->get_skb_header = lro_get_skb_hdr;
-			lp->features = LRO_F_NAPI;
-			lp->dev = dev;
-			lp->ip_summed = CHECKSUM_UNNECESSARY;
-			lp->ip_summed_aggr = CHECKSUM_UNNECESSARY;
-			lp->lro_arr = cacheline_aligned_kmalloc(
-					sizeof(struct net_lro_desc) *
-						LRO_MAX_DESCS, GFP_KERNEL);
-			memset(lp->lro_arr, 0,
-				sizeof(struct net_lro_desc) * LRO_MAX_DESCS);
-		}
-	}
-}
-
-inline void napi_lro_flush(int cpu)
-{
-	struct dev_data *priv = NULL;
-	int i;
-
-	for (i = 0; i < lro_flush_priv_cnt[cpu]; i++) {
-		priv = lro_flush_priv[cpu][i];
-		lro_flush_all(&priv->lro_mgr[cpu]);
-		lro_flush_needed[cpu][priv->port_index] = 0;
-		Message("Lro flush cpu %d port %d\n", cpu, priv->port_index);
-	}
-
-	lro_flush_priv_cnt[cpu] = 0;
-}
-
-void xlp_napi_lro_flush(void *arg)
-{
-	int cpu = hard_smp_processor_id();
-	napi_lro_flush(cpu);
-}
-#endif
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_lro.h b/drivers/net/ethernet/broadcom/nae/xlpge_lro.h
new file mode 100644
index 0000000..8a247e4
--- /dev/null
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_lro.h
@@ -0,0 +1,120 @@
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_2# */
+
+#ifndef	__XLPGE_LRO_H__
+#define __XLPGE_LRO_H__
+#include <linux/module.h>
+#include <linux/pci.h>
+#include <linux/netdevice.h>
+#include <linux/inet_lro.h>
+#include <linux/clocksource.h>
+#include <linux/timecompare.h>
+
+#include <nlm_xlp.h>
+#include "xlpge.h"
+
+#ifdef CONFIG_INET_LRO
+
+extern int enable_lro;
+extern int lro_flush_priv_cnt[NR_CPUS];
+extern int lro_flush_needed[NR_CPUS][20];
+extern struct dev_data *lro_flush_priv[NR_CPUS][20];
+
+static int lro_get_skb_hdr(struct sk_buff *skb, void **iphdr, void **tcph,
+			   uint64_t *hdr_flags, void *priv)
+{
+	skb_reset_network_header(skb);
+	skb_set_transport_header(skb, ip_hdrlen(skb));
+
+	if (ip_hdr(skb)->protocol != 0x6)
+		return -1;
+
+	*iphdr = ip_hdr(skb);
+	*tcph = tcp_hdr(skb);
+
+	*hdr_flags = LRO_IPV4 | LRO_TCP;
+	skb->ip_summed = CHECKSUM_UNNECESSARY;
+
+	return 0;
+}
+
+static void lro_init(struct net_device *dev)
+{
+	struct dev_data* priv;
+	struct net_lro_mgr *lp;
+	int cpu;
+
+	priv = netdev_priv(dev);
+
+	if (enable_lro) {
+		printk("LRO is enabled \n");
+		dev->features |= NETIF_F_LRO;
+	//	dev->features |= NETIF_F_GRO;
+	//	return;
+		for (cpu = 0; cpu < NR_CPUS; cpu++) {
+			lp = &priv->lro_mgr[cpu];
+			memset(lp, 0, sizeof(struct net_lro_mgr));
+			lp->max_aggr = 48;
+			lp->max_desc = LRO_MAX_DESCS;
+			lp->get_skb_header = lro_get_skb_hdr;
+			lp->features = LRO_F_NAPI;
+			lp->dev = dev;
+			lp->ip_summed = CHECKSUM_UNNECESSARY;
+			lp->ip_summed_aggr = CHECKSUM_UNNECESSARY;
+			lp->lro_arr = cacheline_aligned_kmalloc(
+					sizeof(struct net_lro_desc) *
+						LRO_MAX_DESCS, GFP_KERNEL);
+			memset(lp->lro_arr, 0,
+				sizeof(struct net_lro_desc) * LRO_MAX_DESCS);
+		}
+	}
+}
+
+static inline void napi_lro_flush(int cpu)
+{
+	struct dev_data *priv = NULL;
+	int i;
+
+	for (i = 0; i < lro_flush_priv_cnt[cpu]; i++) {
+		priv = lro_flush_priv[cpu][i];
+		lro_flush_all(&priv->lro_mgr[cpu]);
+		lro_flush_needed[cpu][priv->port_index] = 0;
+		Message("Lro flush cpu %d port %d\n", cpu, priv->port_index);
+	}
+
+	lro_flush_priv_cnt[cpu] = 0;
+}
+
+static void xlp_napi_lro_flush(void *arg)
+{
+	int cpu = hard_smp_processor_id();
+	napi_lro_flush(cpu);
+}
+#endif //INET_LRO
+#endif //LRO_H_
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_nae.c b/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
index d2ccaa4..385d4f1 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
@@ -42,10 +42,12 @@
 //#include <nlm_eeprom.h>
 
 #include "xlpge.h"
+#include "xlpge_lro.h"
+#include "xlpge_tso.h"
 
-static uint32_t cpu_2_normal_frfifo[NLM_MAX_NODES][MAX_NAE_PERNODE][NR_CPUS];
-static uint32_t cpu_2_jumbo_frfifo[NLM_MAX_NODES][MAX_NAE_PERNODE][NR_CPUS];
-static int phys_cpu_to_log_map[NLM_MAX_NODES][MAX_NAE_PERNODE][NR_CPUS];
+uint32_t cpu_2_normal_frfifo[NLM_MAX_NODES][MAX_NAE_PERNODE][NR_CPUS];
+uint32_t cpu_2_jumbo_frfifo[NLM_MAX_NODES][MAX_NAE_PERNODE][NR_CPUS];
+int phys_cpu_to_log_map[NLM_MAX_NODES][MAX_NAE_PERNODE][NR_CPUS];
 int lcpu_2_pcpu[NR_CPUS];
 static unsigned int fmem[NR_CPUS];
 int num_cpus_per_node;
@@ -78,12 +80,19 @@ module_param(num_descs_per_normalq, int, 0);
 int num_descs_per_jumboq = 48;
 module_param(num_descs_per_jumboq, int, 0);
 
+int enable_lro = 0;
+module_param(enable_lro, int, 0);
+int lro_flush_priv_cnt[NR_CPUS];
+int lro_flush_needed[NR_CPUS][20];
+struct dev_data *lro_flush_priv[NR_CPUS][20];
+
+
 static uint32_t lnx_frfifo_normal_mask[NLM_MAX_NODES][MAX_NAE_PERNODE];
 static uint32_t lnx_frfifo_jumbo_mask[NLM_MAX_NODES][MAX_NAE_PERNODE];
 
-static int enable_jumbo = 0;
+int enable_jumbo = 0;
 module_param(enable_jumbo, int, 0);
-static struct p2p_desc_mem p2p_desc_mem[NR_CPUS] __cacheline_aligned;
+struct p2p_desc_mem p2p_desc_mem[NR_CPUS] __cacheline_aligned;
 static unsigned int phys_cpu_map[NLM_MAX_NODES];
 struct timer_list phy_int_timer;
 #ifdef CONFIG_NLM_ENABLE_LOAD_BALANCING
@@ -887,65 +896,6 @@ static int p2p_desc_mem_init(void)
 	return 0;
 }
 
-inline void *alloc_p2p_desc_mem(int cpu)
-{
-	void *buf;
-	buf = p2p_desc_mem[cpu].mem;
-	if (buf)
-		p2p_desc_mem[cpu].mem = (void *)*(ulong *)(buf);
-	else {
-		buf = cacheline_aligned_kmalloc(p2p_desc_mem[cpu].dsize,
-			GFP_KERNEL);
-		p2p_dynamic_alloc_cnt[CPU_INDEX(cpu)]++;
-	}
-	return buf;
-}
-
-void free_p2p_desc_mem(int cpu, void *buf)
-{
-	*(ulong *)buf = (ulong)p2p_desc_mem[cpu].mem;
-	p2p_desc_mem[cpu].mem = buf;
-
-}
-
-inline int create_p2p_desc(uint64_t paddr, uint64_t len,
-				  uint64_t *p2pmsg, int idx)
-{
-	int plen;
-	do {
-		plen = len >= MAX_PACKET_SZ_PER_MSG ?
-				(MAX_PACKET_SZ_PER_MSG - 64): len;
-		p2pmsg[idx] = cpu_to_be64(nae_tx_desc(DESC_TYPE_P2DNEOP, NULL_VFBID,
-				plen, paddr));
-		len -= plen;
-		paddr += plen;
-		idx++;
-	} while (len > 0);
-	return idx;
-}
-
-inline void create_last_p2p_desc(uint64_t *p2pmsg,
-					struct sk_buff *skb, int idx)
-{
-	p2pmsg[idx -1 ] = cpu_to_be64(be64_to_cpu(p2pmsg[idx - 1]) |
-				((uint64_t)P2D_EOP << 62));
-	p2pmsg[P2P_SKB_OFF] = (uint64_t)(ulong)skb;
-}
-
-uint16_t pseuodo_chksum(uint16_t *ipsrc, uint16_t proto)
-{
-	uint32_t sum = 0;
-	sum += cpu_to_be16(ipsrc[0]);
-	sum += cpu_to_be16(ipsrc[1]);
-	sum += cpu_to_be16(ipsrc[2]);
-	sum += cpu_to_be16(ipsrc[3]);
-	sum += proto;
-	while(sum >> 16)
-		sum = (sum & 0xffff)  + (sum >> 16);
-	//      sum = ~sum;
-	return (uint16_t)sum;
-}
-
 static void nlm_enable_l3_l4_parser(nae_t *nae)
 {
 	printk("Enabling parser for nae node %d naeid %d\n",
@@ -1015,80 +965,6 @@ int get_hw_frfifo_queue_id(int rxnode, nae_t* nae_cfg,
 }
 #endif
 
-int mac_refill_frin_skb(nae_t* nae_cfg, int cpu, uint64_t paddr,
-			       uint32_t bufsize, int hw_port_id)
-{
-	/*
-	 * We have to use the logical map here as the below arrays are
-	 * indexed by logical cpu id
-	 */
-	int ret, code, qid;
-	ulong __attribute__ ((unused)) mflags;
-	int node = nae_cfg->node;
-	int nae_id = nae_cfg->nae_id;
-	int node_cpu = phys_cpu_to_log_map[node][nae_id][cpu];
-
-	if (nae_cfg == NULL) {
-		printk("%s Error, Invalid node id %d\n", __FUNCTION__, node);
-		return -1;
-	}
-
-	if(nae_cfg->port_fifo_en)
-		qid = hw_port_id;
-	else
-		qid = (bufsize >= NLM_RX_JUMBO_BUF_SIZE) ?
-		cpu_2_jumbo_frfifo[node][nae_id][node_cpu] :
-		cpu_2_normal_frfifo[node][nae_id][node_cpu];
-
-	Message("%s in cpu %d bufsize %d node %d qid %d qbase %d node_cpu %d nae_id %d\n",
-		__FUNCTION__, cpu, bufsize, node, qid,
-		nae_cfg->frin_queue_base, node_cpu, nae_id);
-
-	ret = 0;
-	qid = nae_cfg->frin_queue_base + qid;
-
-	/* Assumption: SKB is all set to go */
-	/* Send the free Rx desc to the MAC */
-	code = 0;
-
-	//* Send the packet to nae rx  */
-	msgrng_access_enable(mflags);
-	for (;;) {
-		//ret = netsoc_nae_send_freein_buf(nae_cfg, qid, paddr & 0xffffffffffULL);
-	  	ret = xlp_message_send_1(qid, code, (paddr & 0xffffffffffULL));
-	  if (!ret) break;
-	}
-	msgrng_access_disable(mflags);
-
-	return ret;
-}
-
-int mac_refill_frin_one_buffer(struct net_device *dev, int cpu,
-				      uint32_t truesize)
-{
-	struct dev_data* priv = netdev_priv(dev);
-	struct sk_buff * skb;
-	int buf_size = NLM_RX_ETH_BUF_SIZE;
-	nae_t* nae_cfg = priv->nae;
-
-	if (enable_jumbo)
-		if(truesize > NLM_RX_JUMBO_BUF_SIZE)
-			buf_size = NLM_RX_JUMBO_BUF_SIZE;
-
-	skb = nlm_xlp_alloc_skb_atomic(buf_size, priv->node);
-	if (!skb) {
-		printk("[%s] alloc skb failed\n",__FUNCTION__);
-		panic("panic...");
-		return -ENOMEM;
-	}
-
-	skb->dev = dev;
-
-	mac_put_skb_back_ptr(skb, nae_cfg);
-
-	return mac_refill_frin_skb(nae_cfg, cpu, (uint64_t)virt_to_bus(skb->data), buf_size, priv->hw_port_id);
-}
-
 /**********************************************************************
  * nlm_xlp_nae_open -  called when bring up a device interface
  * @dev  -  this is per device based function
@@ -1163,6 +1039,7 @@ static int  nlm_xlp_nae_open (struct net_device *dev)
 		else 
 			priv->flow_ctrl=0;
 		//nlm_xlp_mac_set_enable(priv, 1);
+		//netsoc_disable_flow_control(priv->nae_port);
 
 	return ret;
 }
@@ -1491,7 +1368,7 @@ static int nlm_per_port_nae_init(nae_t* nae_cfg, int port, int maxnae)
 		return -1;
 
 	dev = alloc_etherdev_mq(sizeof(struct dev_data),
-		maxnae * num_cpus_per_node);
+		NLM_MAX_NODES * num_cpus_per_node);
 	if(!dev)
 		return -1;
 
@@ -1597,7 +1474,7 @@ void nlm_xlp_nae_init(void)
 	printk("======= Module Parameters =========\n");
 	printk("num_descs_per_normalq=%d num_descs_per_jumboq=%d ",
 	       num_descs_per_normalq, num_descs_per_jumboq);
-	printk("perf_mode=%s enable_lro=%d enable_jumbo=%d\n",
+	printk("perf_mode=%s enable_lro=%d enable_jumbo=%d \n",
 	       mode_str[perf_mode], enable_lro, enable_jumbo);
 
 	for (i = 0; i < NR_CPUS; i++)
@@ -1621,9 +1498,9 @@ void nlm_xlp_nae_init(void)
 		return;
 
 	maxnae = get_num_nae_pernode();
-	for (node = 0; node < maxnae; node++) {
+	for (node = 0; node < NLM_MAX_NODES; node++) {
 		int num_nae;
-		for(num_nae=0; num_nae<NLM_MAX_NODES; num_nae++){
+		for(num_nae=0; num_nae<maxnae; num_nae++){
 			nae_cfg = get_nae(node, num_nae);
 			if (nae_cfg == NULL)
 				continue;
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_rx.c b/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
index dd403cf..24c412c 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
@@ -41,6 +41,8 @@
 #include <nlm_hal_fmn.h>
 
 #include "xlpge.h"
+#include "xlpge_lro.h"
+#include "xlpge_tso.h"
 
 #ifdef CONFIG_NLM_ENABLE_LOAD_BALANCING
 #define NBITS_32 32
@@ -631,7 +633,7 @@ static int inline valid_buffer_lifo(int cpu, uint64_t msg1, uint32_t src_id)
 		return 1;
 }
 
-static inline void process_rx_packets(int cpu, unsigned int src_id, 
+static inline void process_rx_packets(void *arg, int cpu, unsigned int src_id, 
 		unsigned long long msg0, unsigned long long msg1, unsigned long long msg2)
 {
 	uint64_t addr;
@@ -643,6 +645,7 @@ static inline void process_rx_packets(int cpu, unsigned int src_id,
 	struct sk_buff* skb;
 	nae_t* nae_cfg;
 	uint32_t msec_port;
+	struct napi_struct *napi = (struct napi_struct *)arg;
 
 	if(is_nlm_xlp9xx()){
 		msg1 = msg2;	
@@ -804,7 +807,10 @@ static inline void process_rx_packets(int cpu, unsigned int src_id,
 	} else
 #endif
 	{
-		netif_receive_skb(skb);
+		if ((skb->dev->features & NETIF_F_GRO) && napi)
+			napi_gro_receive(napi, skb);
+		else
+			netif_receive_skb(skb);
 	}
 
 	/* Update Stats */
@@ -826,7 +832,7 @@ static inline void process_rx_packets(int cpu, unsigned int src_id,
 /*
  * NAE poll function on freeback only if rx and freeback vcs are different
 */
-void xlp_poll_upper(int cpu)
+inline void xlp_poll_upper(int cpu)
 {
 	unsigned int status;
 	uint64_t msg0 = 0;
@@ -853,7 +859,7 @@ void xlp_poll_upper(int cpu)
 /*
  * NAE poll function on lower four buckets
  */
-static int xlp_poll_lower(int budget, int cpu)
+static int xlp_poll_lower(void *arg, int budget, int cpu)
 {
 	int status;
 	uint64_t msg0 = 0, msg1 = 0, msg2=0;
@@ -881,7 +887,7 @@ static int xlp_poll_lower(int budget, int cpu)
 		}
 #endif
 		if (size >= 2)
-			process_rx_packets(cpu, src_id, msg0, msg1, msg2);
+			process_rx_packets(arg, cpu, src_id, msg0, msg1, msg2);
 		else if (size == 1)
 			process_tx_complete(cpu, src_id, msg0);
 		else {
@@ -913,7 +919,7 @@ static void nlm_xlp_nae_msgring_handler(uint32_t vc, uint32_t src_id,
 	int cpu = hard_smp_processor_id();
 
 	if (vc == nae_rx_vc && size >= 2)
-		 process_rx_packets(cpu, src_id, msg0, msg1, msg2);
+		 process_rx_packets(NULL, cpu, src_id, msg0, msg1, msg2);
 	else if (vc == nae_fb_vc && size == 1)
 		process_tx_complete(cpu, src_id, msg0);
 	else {
@@ -926,20 +932,25 @@ static void nlm_xlp_nae_msgring_handler(uint32_t vc, uint32_t src_id,
  * Main NAE napi poll loop for exclusive vc handler
  */
 
-static int xlp_nae_napi_poll(int vc, int budget)
+static int xlp_nae_napi_poll(void *arg, int vc, int budget)
 {
 	int rx_pkts = 0, rx, i;
 	int cpu = hard_smp_processor_id();
 
 	Message("%s in vc %d budget %d\n", __func__, vc, budget);
 
+	if(nlm_mode[CPU_INDEX(cpu)] == NLM_RT_MODE){
 	for(i =0; i < budget; i++) {
 		xlp_poll_upper(cpu);
-		rx = xlp_poll_lower(1, cpu);
+		rx = xlp_poll_lower(arg, 1, cpu);
 		if(!rx)
 			break;
 		rx_pkts += rx;
 	}
+	} else {
+		xlp_poll_upper(cpu);
+		rx_pkts = xlp_poll_lower(arg, budget, cpu);
+	}
 
 	return rx_pkts;
 }
@@ -961,7 +972,7 @@ static int xlp_nae_poll(void *buf)
 
 		local_bh_disable();
 		xlp_poll_upper(cpu);
-		rx_pkts = xlp_poll_lower(budget, cpu);
+		rx_pkts = xlp_poll_lower(NULL, budget, cpu);
 		local_bh_enable();
 
 
@@ -1003,7 +1014,7 @@ void nlm_spawn_kthread(void)
  * Setup XLP NAPI subsystem
  */
 extern int nlm_xlp_register_napi_vc_handler(int nae_rx_vc,
-	int (*napi_msgint_handler)(int, int));
+	int (*napi_msgint_handler)(void *, int, int));
 extern int nlm_xlp_register_napi_final_handler(int major,
 	void (*napi_final)(void *arg), void *arg);
 
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_tso.c b/drivers/net/ethernet/broadcom/nae/xlpge_tso.c
deleted file mode 100644
index 256d751..0000000
--- a/drivers/net/ethernet/broadcom/nae/xlpge_tso.c
+++ /dev/null
@@ -1,298 +0,0 @@
-/*-
- * Copyright (c) 2003-2012 Broadcom Corporation
- * All Rights Reserved
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in
- *    the documentation and/or other materials provided with the
- *    distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
- * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
- * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- * #BRCM_2# */
-
-#include <linux/module.h>
-#include <linux/pci.h>
-#include <linux/netdevice.h>
-#include <linux/inet_lro.h>
-#include <linux/clocksource.h>
-#include <linux/timecompare.h>
-#include <linux/ethtool.h>
-
-#include <nlm_msgring.h>
-#include <nlm_xlp.h>
-#include <nlm_hal_fmn.h>
-
-#include "xlpge.h"
-//#define MACSEC_DEBUG	1
-
-static __inline__ uint64_t nae_tso_desc0(
-		unsigned int type,
-		unsigned int subtype,
-		unsigned int opcode,
-		unsigned int param_index,
-		unsigned int l3hdroff,
-		unsigned int l4hdroff,
-		unsigned int l3chksumoff,
-		unsigned int pseudohdrchksum,
-		unsigned int l4chksumoff,
-		unsigned int pyldoff)
-{
-
-	return ((uint64_t)(type & 0x3) << 62) |
-		((uint64_t)(subtype & 3) << 60) |
-		((uint64_t)(opcode & 0xf) << 56) |
-		((uint64_t)(param_index & 0xf) << 49) |
-		((uint64_t)(l3hdroff & 0x3f) << 43) |
-		((uint64_t)(l4hdroff & 0x7f) << 36) |
-		((uint64_t)(l3chksumoff & 0x1f) << 31) |
-		((uint64_t)(pseudohdrchksum & 0xffff) << 15) |
-		((uint64_t)(l4chksumoff & 0x7f) << 8) |
-		((uint64_t)(pyldoff & 0xff));
-}
-
-static __inline__ uint64_t nae_tso_desc1(
-		unsigned int type,
-		unsigned int subtype,
-		unsigned int poly,
-		unsigned int mss,
-		unsigned int crcstopoff,
-		unsigned int crcinsoff)
-{
-	return ((uint64_t)(type & 0x3) << 62) |
-		((uint64_t)(subtype & 3) << 60) |
-		((uint64_t)(poly & 0x3) << 48) |
-		((uint64_t)(mss & 0xffff) << 32) |
-		((uint64_t)(crcstopoff & 0xffff) << 16) |
-		((uint64_t)(crcinsoff & 0xffff));
-
-}
-
-inline int tso_xmit_skb(struct sk_buff *skb, struct net_device *dev)
-{
-	int mss  = 0, idx = 0, len, i ;
-	struct skb_shared_info *sp = skb_shinfo(skb);
-	struct iphdr *iph;
-	struct dev_data *priv = netdev_priv(dev);
-	uint64_t msg, mscmsg0 = 0, mscmsg1 = 0;
-	uint64_t *p2pdesc = NULL;
-	int cpu = hard_smp_processor_id();
-	int  ret, retry_cnt = 0, qid;
-	nae_t* nae_cfg = priv->nae;
-	unsigned long __attribute__ ((unused)) mflags;
-	uint32_t msec_port, send_msec = 0, msec_bypass = 0;
-	uint32_t pad_len = 0, icv_len = 0, param_index = 0;
-
-#ifdef MACSEC_DEBUG
-	printk("nae_cfg->sectag_offset = %d sectag_len = %d icv_len = %d\n",
-		nae_cfg->sectag_offset[priv->port],
-		nae_cfg->sectag_len[priv->port], nae_cfg->icv_len[priv->port]);
-#endif
-	if(priv->index == XGMAC0)
-		msec_port = (priv->port | 0xf) << (4 * priv->block);
-	else
-		msec_port = 1 << priv->port;
-
-#ifdef MACSEC_DEBUG
-	dump_buffer(skb->data, skb->len, "Org skb pkt:");
-	printk("msec_port = %x priv->port = %d priv->block = %d \
-		priv->index = %d skb->len = %d \
-		nae_cfg->msec_tx_port_enable = %x\n",
-		msec_port, priv->port, priv->block, priv->index,
-		skb->len, nae_cfg->msec_tx_port_enable);
-#endif
-	/* check if tx port is enabled for msec
-	 * else bypass MACSec
-	 */
-	if (nae_cfg->msec_tx_port_enable & msec_port) {
-		short ether_type = *(short*)(((char*)skb->data) +
-					MAC_HEADER_LEN);
-
-#ifdef MACSEC_DEBUG
-	printk("skb->len = %d ether_type = %x\n",
-			skb->len, ether_type);
-#endif
-		/* Enable Macsec processing */
-		if((ether_type & 0xffff) == PROTOCOL_TYPE_IP) {
-			send_msec = 1;
-			/* param_index should be between 1 - 7 */
-			param_index = (priv->port)?priv->port:1;
-
-			pad_len =  nae_cfg->sectag_offset[priv->port] +
-					nae_cfg->sectag_len[priv->port];
-			icv_len = nae_cfg->icv_len[priv->port];
-
-#ifdef MACSEC_DEBUG
-	printk("pad_len = %d icv_len = %d ether_type = %x\n",
-			pad_len, icv_len, ether_type);
-#endif
-		}
-		else
-			msec_bypass = 1;
-	}
-
-	p2pdesc = alloc_p2p_desc_mem(cpu);
-	if (p2pdesc == NULL) {
-		goto out_unlock;
-	}
-
-	if (((mss = sp->gso_size) != 0) ||
-		(skb->ip_summed == CHECKSUM_PARTIAL)) {
-		u32 iphdroff, tcphdroff, pyldoff, pcsum, tcp_packet = 1;
-
-		if (skb_header_cloned(skb) &&
-			pskb_expand_head(skb, 0, 0, GFP_ATOMIC)) {
-			goto out_unlock;
-		}
-
-		iph = ip_hdr(skb);
-		iphdroff = (char *)iph - (char *)skb->data;
-		tcphdroff = iphdroff + ip_hdrlen(skb);
-		if (ip_hdr(skb)->protocol == 0x6) {
-			pyldoff = iphdroff + ip_hdrlen(skb) +
-				sizeof(struct tcphdr) + tcp_optlen(skb);
-			pcsum = pseuodo_chksum((uint16_t *)((char *)iph + 12),
-					0x6);
-			tcp_hdr(skb)->check = 0;
-		} else if (ip_hdr(skb)->protocol == 0x11) {
-			pyldoff = iphdroff + ip_hdrlen(skb) + sizeof(struct udphdr);
-			pcsum = pseuodo_chksum((uint16_t *)((char *)iph + 12),
-					0x11);
-			udp_hdr(skb)->check = 0;
-			tcp_packet = 0;
-		} else {
-			printk("Invalid packet in %s\n", __FUNCTION__);
-			goto out_unlock;
-		}
-
-		if(mss) {
-			iph->check = 0;
-			iph->tot_len = 0;
-			mscmsg0 = nae_tso_desc0(MSC, 1, TSO_IP_TCP_CHKSUM,
-				param_index, iphdroff, tcphdroff,
-				(iphdroff + 10), pcsum, tcphdroff + 16,
-				pyldoff);
-			mscmsg1 = nae_tso_desc1(MSC, 2, 0, mss, 0, 0);
-		} else if(tcp_packet) {
-			mscmsg0 = nae_tso_desc0(MSC, 0, TCP_CHKSUM,
-				param_index, iphdroff, tcphdroff,
-				(iphdroff + 10), pcsum, tcphdroff + 16,
-				pyldoff);
-		} else {
-			mscmsg0 = nae_tso_desc0(MSC, 0, UDP_CHKSUM,
-				param_index, iphdroff, tcphdroff,
-				(iphdroff + 10), pcsum, tcphdroff + 6,
-				pyldoff);
-		}
-
-	} else if (send_msec || msec_bypass) {
-		mscmsg0 = nae_tso_desc0(MSC, 0, 0, param_index,
-				0, 0, 0, 0, 0, 0);
-	}
-
-	if(((len = skb_headlen(skb)) != 0)) {
-		if (send_msec) {
-			memcpy((char*)&p2pdesc[P2P_SKB_OFF-8], skb->data,
-				MAC_HEADER_LEN);
-			idx = create_p2p_desc(virt_to_bus((char *)
-				&p2pdesc[P2P_SKB_OFF-8]), pad_len,
-				p2pdesc, idx);
-			idx = create_p2p_desc(virt_to_bus((((char *)skb->data) +
-				MAC_HEADER_LEN)), (len - MAC_HEADER_LEN),
-				p2pdesc, idx);
-#ifdef MACSEC_DEBUG
-			dump_buffer((char *)&p2pdesc[P2P_SKB_OFF-8],
-				pad_len, "first_seg:");
-			printk(" len = %d pad_len = %d icv_len = %d \
-				param_index = %d\n", len, pad_len, icv_len,
-				param_index);
-#endif
-		} else{
-			idx = create_p2p_desc(virt_to_bus((char *)skb->data), len,
-			p2pdesc, idx);
-		 }
-	}
-
-	for (i = 0; i < sp->nr_frags; i++)  {
-		skb_frag_t *fp = &sp->frags[i];
-		idx = create_p2p_desc(virt_to_bus(((char *)
-				page_address(skb_frag_page(fp))) + fp->page_offset),
-				fp->size, p2pdesc, idx);
-	}
-
-	if (send_msec) {
-		if (!param_index)
-			idx = create_p2p_desc(virt_to_bus((char *)
-				&p2pdesc[P2P_SKB_OFF-2]), icv_len,
-				p2pdesc, idx);
-	}
-
-
-	qid = nae_cfg->vfbtbl_sw_offset + (cpu % num_cpus_per_node);
-	{
-		create_last_p2p_desc(p2pdesc, skb, idx);
-		msg = nae_tx_desc(DESC_TYPE_P2P, qid, idx, virt_to_bus(p2pdesc));
-	}
-
-
-	__sync();
-
-retry_send:
-	msgrng_access_enable(mflags);
-	if(mss)
-		ret = xlp_message_send_3(priv->nae_tx_qid, 0, mscmsg0,
-				mscmsg1, msg);
-	else if(skb->ip_summed == CHECKSUM_PARTIAL)
-		ret = xlp_message_send_2(priv->nae_tx_qid, 0, mscmsg0, msg);
-	else if (send_msec || msec_bypass)
-		ret = xlp_message_send_2(priv->nae_tx_qid, 0, mscmsg0, msg);
-	else
-		ret = xlp_message_send_1(priv->nae_tx_qid, 0, msg);
-	msgrng_access_disable(mflags);
-	if(ret)	{
-		xlp_poll_upper(cpu);
-		retry_cnt++;
-		if(retry_cnt >= 128) {
-			goto out_unlock;
-		}
-		goto retry_send;
-	}
-
-	dev->trans_start = jiffies;
-	priv->cpu_stats[cpu].tx_packets += idx;
-
-	return NETDEV_TX_OK;
-out_unlock:
-
-	dev_kfree_skb_any(skb);
-	if(p2pdesc)
-		free_p2p_desc_mem(cpu, p2pdesc);
-	return NETDEV_TX_OK;
-}
-
-int tso_enable(struct net_device *dev, u32 data)
-{
-	int rv = 0;
-
-	dev->hw_features = NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_TSO;
-	dev->features = dev->hw_features;
-	dev->features |= NETIF_F_HIGHDMA;
-
-	return rv;
-}
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_tso.h b/drivers/net/ethernet/broadcom/nae/xlpge_tso.h
new file mode 100644
index 0000000..38ab0c0
--- /dev/null
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_tso.h
@@ -0,0 +1,361 @@
+/*-
+ * Copyright (c) 2003-2012 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ * #BRCM_2# */
+
+#ifndef	__XLPGE_TSO_H__
+#define __XLPGE_TSO_H__
+#include <linux/module.h>
+#include <linux/pci.h>
+#include <linux/netdevice.h>
+#include <linux/inet_lro.h>
+#include <linux/clocksource.h>
+#include <linux/timecompare.h>
+#include <linux/ethtool.h>
+
+#include <nlm_msgring.h>
+#include <nlm_xlp.h>
+#include <nlm_hal_fmn.h>
+
+#include "xlpge.h"
+//#define MACSEC_DEBUG	1
+extern struct p2p_desc_mem p2p_desc_mem[NR_CPUS];
+
+static __inline__ uint64_t nae_tso_desc0(
+		unsigned int type,
+		unsigned int subtype,
+		unsigned int opcode,
+		unsigned int param_index,
+		unsigned int l3hdroff,
+		unsigned int l4hdroff,
+		unsigned int l3chksumoff,
+		unsigned int pseudohdrchksum,
+		unsigned int l4chksumoff,
+		unsigned int pyldoff)
+{
+
+	return ((uint64_t)(type & 0x3) << 62) |
+		((uint64_t)(subtype & 3) << 60) |
+		((uint64_t)(opcode & 0xf) << 56) |
+		((uint64_t)(param_index & 0xf) << 49) |
+		((uint64_t)(l3hdroff & 0x3f) << 43) |
+		((uint64_t)(l4hdroff & 0x7f) << 36) |
+		((uint64_t)(l3chksumoff & 0x1f) << 31) |
+		((uint64_t)(pseudohdrchksum & 0xffff) << 15) |
+		((uint64_t)(l4chksumoff & 0x7f) << 8) |
+		((uint64_t)(pyldoff & 0xff));
+}
+
+static __inline__ uint64_t nae_tso_desc1(
+		unsigned int type,
+		unsigned int subtype,
+		unsigned int poly,
+		unsigned int mss,
+		unsigned int crcstopoff,
+		unsigned int crcinsoff)
+{
+	return ((uint64_t)(type & 0x3) << 62) |
+		((uint64_t)(subtype & 3) << 60) |
+		((uint64_t)(poly & 0x3) << 48) |
+		((uint64_t)(mss & 0xffff) << 32) |
+		((uint64_t)(crcstopoff & 0xffff) << 16) |
+		((uint64_t)(crcinsoff & 0xffff));
+
+}
+
+static inline void *alloc_p2p_desc_mem(int cpu)
+{
+	void *buf;
+	buf = p2p_desc_mem[cpu].mem;
+	if (buf)
+		p2p_desc_mem[cpu].mem = (void *)*(ulong *)(buf);
+	else {
+		buf = cacheline_aligned_kmalloc(p2p_desc_mem[cpu].dsize,
+			GFP_KERNEL);
+		p2p_dynamic_alloc_cnt[CPU_INDEX(cpu)]++;
+	}
+	return buf;
+}
+
+static inline void free_p2p_desc_mem(int cpu, void *buf)
+{
+	*(ulong *)buf = (ulong)p2p_desc_mem[cpu].mem;
+	p2p_desc_mem[cpu].mem = buf;
+
+}
+
+static inline int create_p2p_desc(uint64_t paddr, uint64_t len,
+				  uint64_t *p2pmsg, int idx)
+{
+	int plen;
+	do {
+		plen = len >= MAX_PACKET_SZ_PER_MSG ?
+				(MAX_PACKET_SZ_PER_MSG - 64): len;
+		p2pmsg[idx] = cpu_to_be64(nae_tx_desc(DESC_TYPE_P2DNEOP, NULL_VFBID,
+				plen, paddr));
+		len -= plen;
+		paddr += plen;
+		idx++;
+	} while (len > 0);
+	return idx;
+}
+
+static inline void create_last_p2p_desc(uint64_t *p2pmsg,
+					struct sk_buff *skb, int idx)
+{
+	p2pmsg[idx -1 ] = cpu_to_be64(be64_to_cpu(p2pmsg[idx - 1]) |
+				((uint64_t)P2D_EOP << 62));
+	p2pmsg[P2P_SKB_OFF] = (uint64_t)(ulong)skb;
+}
+
+static inline uint16_t pseuodo_chksum(uint16_t *ipsrc, uint16_t proto)
+{
+	uint32_t sum = 0;
+	sum += cpu_to_be16(ipsrc[0]);
+	sum += cpu_to_be16(ipsrc[1]);
+	sum += cpu_to_be16(ipsrc[2]);
+	sum += cpu_to_be16(ipsrc[3]);
+	sum += proto;
+	while(sum >> 16)
+		sum = (sum & 0xffff)  + (sum >> 16);
+	//      sum = ~sum;
+	return (uint16_t)sum;
+}
+
+static inline int tso_xmit_skb(struct sk_buff *skb, struct net_device *dev)
+{
+	int mss  = 0, idx = 0, len, i ;
+	struct skb_shared_info *sp = skb_shinfo(skb);
+	struct iphdr *iph;
+	struct dev_data *priv = netdev_priv(dev);
+	uint64_t msg, mscmsg0 = 0, mscmsg1 = 0;
+	uint64_t *p2pdesc = NULL;
+	int cpu = hard_smp_processor_id();
+	int  ret, retry_cnt = 0, qid;
+	nae_t* nae_cfg = priv->nae;
+	unsigned long __attribute__ ((unused)) mflags;
+	uint32_t msec_port, send_msec = 0, msec_bypass = 0;
+	uint32_t pad_len = 0, icv_len = 0, param_index = 0;
+
+#ifdef MACSEC_DEBUG
+	printk("nae_cfg->sectag_offset = %d sectag_len = %d icv_len = %d\n",
+		nae_cfg->sectag_offset[priv->port],
+		nae_cfg->sectag_len[priv->port], nae_cfg->icv_len[priv->port]);
+#endif
+	if(priv->index == XGMAC0)
+		msec_port = (priv->port | 0xf) << (4 * priv->block);
+	else
+		msec_port = 1 << priv->port;
+
+#ifdef MACSEC_DEBUG
+	dump_buffer(skb->data, skb->len, "Org skb pkt:");
+	printk("msec_port = %x priv->port = %d priv->block = %d \
+		priv->index = %d skb->len = %d \
+		nae_cfg->msec_port_enable = %x\n",
+		msec_port, priv->port, priv->block, priv->index,
+		skb->len, nae_cfg->msec_port_enable);
+#endif
+	/* check if tx port is enabled for msec
+	 * else bypass MACSec
+	 */
+	if (nae_cfg->msec_port_enable & msec_port) {
+		short ether_type = *(short*)(((char*)skb->data) +
+					MAC_HEADER_LEN);
+
+#ifdef MACSEC_DEBUG
+	printk("skb->len = %d ether_type = %x\n",
+			skb->len, ether_type);
+#endif
+		/* Enable Macsec processing */
+		if((ether_type & 0xffff) == PROTOCOL_TYPE_IP) {
+			send_msec = 1;
+			/* param_index should be between 1 - 7 */
+			param_index = (priv->port)?priv->port:1;
+
+			pad_len =  nae_cfg->sectag_offset[priv->port] +
+					nae_cfg->sectag_len[priv->port];
+			icv_len = nae_cfg->icv_len[priv->port];
+
+#ifdef MACSEC_DEBUG
+	printk("pad_len = %d icv_len = %d ether_type = %x\n",
+			pad_len, icv_len, ether_type);
+#endif
+		}
+		else
+			msec_bypass = 1;
+	}
+
+	p2pdesc = alloc_p2p_desc_mem(cpu);
+	if (p2pdesc == NULL) {
+		goto out_unlock;
+	}
+
+	if (((mss = sp->gso_size) != 0) ||
+		(skb->ip_summed == CHECKSUM_PARTIAL)) {
+		u32 iphdroff, tcphdroff, pyldoff, pcsum, tcp_packet = 1;
+
+		if (skb_header_cloned(skb) &&
+			pskb_expand_head(skb, 0, 0, GFP_ATOMIC)) {
+			goto out_unlock;
+		}
+
+		iph = ip_hdr(skb);
+		iphdroff = (char *)iph - (char *)skb->data;
+		tcphdroff = iphdroff + ip_hdrlen(skb);
+		if (ip_hdr(skb)->protocol == 0x6) {
+			pyldoff = iphdroff + ip_hdrlen(skb) +
+				sizeof(struct tcphdr) + tcp_optlen(skb);
+			pcsum = pseuodo_chksum((uint16_t *)((char *)iph + 12),
+					0x6);
+			tcp_hdr(skb)->check = 0;
+		} else if (ip_hdr(skb)->protocol == 0x11) {
+			pyldoff = iphdroff + ip_hdrlen(skb) + sizeof(struct udphdr);
+			pcsum = pseuodo_chksum((uint16_t *)((char *)iph + 12),
+					0x11);
+			udp_hdr(skb)->check = 0;
+			tcp_packet = 0;
+		} else {
+			printk("Invalid packet in %s\n", __FUNCTION__);
+			goto out_unlock;
+		}
+
+		if(mss) {
+			iph->check = 0;
+			iph->tot_len = 0;
+			mscmsg0 = nae_tso_desc0(MSC, 1, TSO_IP_TCP_CHKSUM,
+				param_index, iphdroff, tcphdroff,
+				(iphdroff + 10), pcsum, tcphdroff + 16,
+				pyldoff);
+			mscmsg1 = nae_tso_desc1(MSC, 2, 0, mss, 0, 0);
+		} else if(tcp_packet) {
+			mscmsg0 = nae_tso_desc0(MSC, 0, TCP_CHKSUM,
+				param_index, iphdroff, tcphdroff,
+				(iphdroff + 10), pcsum, tcphdroff + 16,
+				pyldoff);
+		} else {
+			mscmsg0 = nae_tso_desc0(MSC, 0, UDP_CHKSUM,
+				param_index, iphdroff, tcphdroff,
+				(iphdroff + 10), pcsum, tcphdroff + 6,
+				pyldoff);
+		}
+
+	} else if (send_msec || msec_bypass) {
+		mscmsg0 = nae_tso_desc0(MSC, 0, 0, param_index,
+				0, 0, 0, 0, 0, 0);
+	}
+
+	if(((len = skb_headlen(skb)) != 0)) {
+		if (send_msec) {
+			memcpy((char*)&p2pdesc[P2P_SKB_OFF-8], skb->data,
+				MAC_HEADER_LEN);
+			idx = create_p2p_desc(virt_to_bus((char *)
+				&p2pdesc[P2P_SKB_OFF-8]), pad_len,
+				p2pdesc, idx);
+			idx = create_p2p_desc(virt_to_bus((((char *)skb->data) +
+				MAC_HEADER_LEN)), (len - MAC_HEADER_LEN),
+				p2pdesc, idx);
+#ifdef MACSEC_DEBUG
+			dump_buffer((char *)&p2pdesc[P2P_SKB_OFF-8],
+				pad_len, "first_seg:");
+			printk(" len = %d pad_len = %d icv_len = %d \
+				param_index = %d\n", len, pad_len, icv_len,
+				param_index);
+#endif
+		} else{
+			idx = create_p2p_desc(virt_to_bus((char *)skb->data), len,
+			p2pdesc, idx);
+		 }
+	}
+
+	for (i = 0; i < sp->nr_frags; i++)  {
+		skb_frag_t *fp = &sp->frags[i];
+		idx = create_p2p_desc(virt_to_bus(((char *)
+				page_address(skb_frag_page(fp))) + fp->page_offset),
+				fp->size, p2pdesc, idx);
+	}
+
+	if (send_msec) {
+		if (!param_index)
+			idx = create_p2p_desc(virt_to_bus((char *)
+				&p2pdesc[P2P_SKB_OFF-2]), icv_len,
+				p2pdesc, idx);
+	}
+
+
+	qid = nae_cfg->vfbtbl_sw_offset + (cpu % num_cpus_per_node);
+	{
+		create_last_p2p_desc(p2pdesc, skb, idx);
+		msg = nae_tx_desc(DESC_TYPE_P2P, qid, idx, virt_to_bus(p2pdesc));
+	}
+	
+
+	__sync();
+
+retry_send:
+	msgrng_access_enable(mflags);
+	if(mss)
+		ret = xlp_message_send_3(priv->nae_tx_qid, 0, mscmsg0,
+				mscmsg1, msg);
+	else if(skb->ip_summed == CHECKSUM_PARTIAL)
+		ret = xlp_message_send_2(priv->nae_tx_qid, 0, mscmsg0, msg);
+	else if (send_msec || msec_bypass)
+		ret = xlp_message_send_2(priv->nae_tx_qid, 0, mscmsg0, msg);
+	else
+		ret = xlp_message_send_1(priv->nae_tx_qid, 0, msg);
+	msgrng_access_disable(mflags);
+	if(ret)	{
+		printk("Transmit failed\n");
+		xlp_poll_upper(cpu);
+		retry_cnt++;
+		if(retry_cnt >= 128) {
+			goto out_unlock;
+		}
+		goto retry_send;
+	}
+
+//	dev->trans_start = jiffies;
+	priv->cpu_stats[cpu].tx_packets += idx;
+
+	return NETDEV_TX_OK;
+out_unlock:
+
+	dev_kfree_skb_any(skb);
+	if(p2pdesc)
+		free_p2p_desc_mem(cpu, p2pdesc);
+	return NETDEV_TX_OK;
+}
+
+static int tso_enable(struct net_device *dev, u32 data)
+{
+	int rv = 0;
+
+	dev->hw_features = NETIF_F_SG | NETIF_F_IP_CSUM | NETIF_F_TSO;
+	dev->features = dev->hw_features;
+	dev->features |= NETIF_F_HIGHDMA;
+	return rv;
+}
+#endif //TSO_H_
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_tx.c b/drivers/net/ethernet/broadcom/nae/xlpge_tx.c
index 6265f11..cd2beb7 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_tx.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_tx.c
@@ -41,6 +41,7 @@
 #include <nlm_hal_fmn.h>
 
 #include "xlpge.h"
+#include "xlpge_tso.h"
 
 #ifdef CONFIG_NLM_NET_OPTS
 extern struct dev_data *last_rcvd_priv[NR_CPUS * 8] ____cacheline_aligned;
-- 
1.7.1

