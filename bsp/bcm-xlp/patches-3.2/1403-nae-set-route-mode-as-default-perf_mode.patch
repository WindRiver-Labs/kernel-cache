From 4ae8eee98c1a23496fddaa632591ffefdcb75069 Mon Sep 17 00:00:00 2001
From: P. Sadik <psadik@broadcom.com>
Date: Fri, 24 May 2013 17:49:58 +0530
Subject: nae: set route mode as default perf_mode.

With perf_mode=TCP, kernel is not stable. Use perf_mode=RT as default for now.
[Based on SDK 3.2]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
Signed-off-by: Nam Ninh <nam.ninh@windriver.com>

diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_nae.c b/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
index 49a0115..0ed578c 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
@@ -59,14 +59,14 @@ module_param(load_balance_timer_run, int, S_IRUGO|S_IWUSR);
 #endif
 int enable_napi = 1;
 int nlm_prepad_len = 0;
-int perf_mode= NLM_TCP_MODE;
+int perf_mode= NLM_RT_MODE;
 extern cpumask_t phys_cpu_present_map;
 module_param(perf_mode, int, 0);
-/* Descriptors for each normal fifo. For xaui ports, if port fifo mode 
+/* Descriptors for each normal fifo. For xaui ports, if port fifo mode
    is enabled, this will be multiplied by 4 (3 fifos are unused) */
 int num_descs_per_normalq = 64;
 module_param(num_descs_per_normalq, int, 0);
-/* Descriptors for each jumbo fifo. For xaui ports, if port fifo mode 
+/* Descriptors for each jumbo fifo. For xaui ports, if port fifo mode
    is enabled, this will be multiplied by 4 (3 fifos are unused) */
 int num_descs_per_jumboq = 48;
 module_param(num_descs_per_jumboq, int, 0);
@@ -183,7 +183,7 @@ static int nlm_initialize_vfbid(nae_t* nae_cfg)
 	int start = nae_cfg->vfbtbl_sw_offset;
 	int end = start + nae_cfg->vfbtbl_sw_nentries;
 	int frin_q_base = nae_cfg->frin_queue_base;
-	int node = nae_cfg->node; 
+	int node = nae_cfg->node;
 	int cpu, tblidx, i;
 
 	/*
@@ -438,7 +438,7 @@ static int initialize_nae_per_node(nae_t * nae_cfg, uint32_t *phys_cpu_map, int
 		}
 	}
 
-	lnx_shinfo[0].mode = nae_cfg->port_fifo_en ? NLM_PORT_FIFO_EN : 0; 
+	lnx_shinfo[0].mode = nae_cfg->port_fifo_en ? NLM_PORT_FIFO_EN : 0;
 #ifdef CONFIG_NLM_ENABLE_LOAD_BALANCING
 	if(mode == NLM_TCP_MODE)
 		lnx_shinfo[0].mode |= NLM_TCP_LOAD_BALANCE_MODE;
@@ -529,7 +529,7 @@ int initialize_nae(uint32_t *phys_cpu_map, int mode, int *jumbo_enabled)
 	mod_api.writel = NULL;
 	mod_api.free = NULL;
 	mod_api.contig_free = NULL;
-	
+
 	brcm_netsoc_lib_init(&mod_api);
 
 	if (init_netsoc(fdt, dom_id) < 0) {
@@ -639,7 +639,7 @@ int replenish_freein_fifos(void)
 
 			/* configure the descs */
 			for (i = 0; i < nae_cfg->frin_total_queue; i++) {
-				/* if no onchip space. when port fifo is enabled, 
+				/* if no onchip space. when port fifo is enabled,
 				 we will unset all the unused fifo size */
 				if(nae_cfg->freein_fifo_onchip_num_descs[i] == 0)
 					continue;
@@ -754,9 +754,9 @@ void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag)
 		if (priv->type == SGMII_IF) {
 
 			if(nlm_hal_status_ext_phy(priv->node, inf, &mii_info))
-			{		
+			{
 				speed= mii_info.speed;
-                                duplex= mii_info.duplex;	
+                                duplex= mii_info.duplex;
 				ifmode = ((speed == 2) ? 2: 1);
 				nlm_hal_mac_disable(priv->node, inf,
 					priv->type);
@@ -959,7 +959,7 @@ int mac_refill_frin_skb(nae_t* nae_cfg, int cpu, uint64_t paddr,
 		return -1;
 	}
 
-	if(nae_cfg->port_fifo_en) 
+	if(nae_cfg->port_fifo_en)
 		qid = hw_port_id;
 	else
 		qid = (bufsize >= NLM_RX_JUMBO_BUF_SIZE) ?
@@ -980,7 +980,7 @@ int mac_refill_frin_skb(nae_t* nae_cfg, int cpu, uint64_t paddr,
 	//* Send the packet to nae rx  */
 	msgrng_access_enable(mflags);
 	for (;;) {
-		//ret = netsoc_nae_send_freein_buf(nae_cfg, qid, paddr & 0xffffffffffULL);	
+		//ret = netsoc_nae_send_freein_buf(nae_cfg, qid, paddr & 0xffffffffffULL);
 	  	ret = xlp_message_send_1(qid, code, (paddr & 0xffffffffffULL));
 	  if (!ret) break;
 	}
@@ -1114,7 +1114,7 @@ static void  nlm_xlp_set_multicast_list (struct net_device *dev)
 {
 	struct dev_data *priv = netdev_priv(dev);
         int reg_val=0;
-	
+
 	if ((dev->flags & IFF_PROMISC)) {
 		reg_val=nlm_hal_read_mac_reg(priv->node, priv->block, priv->index,
 						MAC_FILTER_CONFIG);
@@ -1122,12 +1122,12 @@ static void  nlm_xlp_set_multicast_list (struct net_device *dev)
 						(1 << MAC_FILTER_ALL_UCAST_EN));
 		nlm_hal_write_mac_reg(priv->node, priv->block, priv->index,
                 	                        MAC_FILTER_CONFIG,reg_val);
-		
+
 		reg_val=nlm_hal_read_mac_reg(priv->node, priv->block, priv->index,
 						NETIOR_VLANTYPE_FILTER);
 		reg_val &= ~(1<<VLAN_RxPAC);
         	nlm_hal_write_mac_reg(priv->node, priv->block, priv->index,
-						NETIOR_VLANTYPE_FILTER,reg_val);	
+						NETIOR_VLANTYPE_FILTER,reg_val);
 	}
 	else {
 		reg_val=nlm_hal_read_mac_reg(priv->node, priv->block, priv->index,
@@ -1143,13 +1143,13 @@ static void  nlm_xlp_set_multicast_list (struct net_device *dev)
 			nlm_hal_write_mac_reg(priv->node, priv->block, priv->index,
                                 MAC_FILTER_CONFIG,reg_val);
 		}
-	
+
         	reg_val  = nlm_hal_read_mac_reg(priv->node, priv->block, priv->index,
 						NETIOR_VLANTYPE_FILTER);
 		reg_val |= (1<<VLAN_RxPAC);
         	nlm_hal_write_mac_reg(priv->node, priv->block, priv->index,
 						NETIOR_VLANTYPE_FILTER,reg_val);
-	}	
+	}
 	return;
 }
 #endif
@@ -1159,7 +1159,7 @@ static void xlp_mac_setup_hwaddr(struct dev_data *priv)
 {
         struct net_device *dev = priv->dev;
 	int reg_val=0;
-	
+
 	nlm_hal_write_mac_reg(priv->node, priv->block, priv->index,
 				MAC_ADDR0_LO,
 				(dev->dev_addr[5] << 24) |
@@ -1179,17 +1179,17 @@ static void xlp_mac_setup_hwaddr(struct dev_data *priv)
 				MAC_ADDR0_MASK_HI,
 				0xFFFFFFFF);
 
-        
+
 	nlm_hal_write_mac_reg(priv->node, priv->block, priv->index,
 				MAC_FILTER_CONFIG,
 				(1 << MAC_FILTER_BCAST_EN_POS) |
                                 (1 << MAC_FILTER_ADDR0_VALID_POS));
-                                					
+
 	reg_val=nlm_hal_read_mac_reg(priv->node, priv->block, priv->index,
 				NETIOR_VLANTYPE_FILTER);
         reg_val |=(1<<VLAN_RxPAC);
         nlm_hal_write_mac_reg(priv->node, priv->block, priv->index,
-				NETIOR_VLANTYPE_FILTER,reg_val);	
+				NETIOR_VLANTYPE_FILTER,reg_val);
 
 }
 #endif
@@ -1252,7 +1252,7 @@ static int nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu)
 			netsoc_mac_disable(nae_port);
 			//nlm_xlp_mac_set_enable(priv, 0); /* Disable MAC TX/RX */
 	}
-	
+
 	if (priv->type==SGMII_IF || priv->type==XAUI_IF)
 		netsoc_set_framesize(nae_port, local_mtu);
 	else if (priv->type==INTERLAKEN_IF){
@@ -1273,7 +1273,7 @@ static int nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu)
 		if(nae_cfg->owned)
 			netsoc_mac_enable(nae_port);
 			//nlm_xlp_mac_set_enable(priv, 1);
-			
+
 	}
 
 	spin_unlock_irqrestore(&priv->lock, flags);
@@ -1584,4 +1584,4 @@ void nlm_xlp_nae_init(void)
 	if (enable_napi)
 		nlm_xlp_enable_napi();
 }
-	
+
-- 
1.7.1

