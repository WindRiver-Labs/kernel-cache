From 07d9b53ca0230b592290047925c725769020f8a9 Mon Sep 17 00:00:00 2001
From: Jayachandran C <jchandra@broadcom.com>
Date: Mon, 14 Apr 2014 11:24:22 +0530
Subject: NAND: Add support for the XLP9XX on-chip NAND interface

Just adds basic support for polled IO.
[Based on SDK 3.2]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
Signed-off-by: Nam Ninh <nam.ninh@windriver.com>

diff --git a/drivers/mtd/nand/Kconfig b/drivers/mtd/nand/Kconfig
index a682764..a03ddee 100644
--- a/drivers/mtd/nand/Kconfig
+++ b/drivers/mtd/nand/Kconfig
@@ -547,6 +547,16 @@ config MTD_NAND_XLP
 
 	  If unsure, say N.
 
+config MTD_NAND_XLP9XX
+	tristate "Support for NAND on Netlogic XLP9XX SoC"
+	depends on CPU_XLP
+	help
+	  Enables support for NAND Flash driver on Netlogic XLP9XX SoCs.
+
+	  If you have Netlogic XLP 9xx boards, say yes here.
+	  If unsure, say N.
+
+
 config MTD_NAND_XWAY
 	tristate "Support for NAND on Lantiq XWAY SoC"
 	depends on LANTIQ && SOC_TYPE_XWAY
diff --git a/drivers/mtd/nand/Makefile b/drivers/mtd/nand/Makefile
index 022b399..ccaf193 100644
--- a/drivers/mtd/nand/Makefile
+++ b/drivers/mtd/nand/Makefile
@@ -49,6 +49,7 @@ obj-$(CONFIG_MTD_NAND_RICOH)		+= r852.o
 obj-$(CONFIG_MTD_NAND_JZ4740)		+= jz4740_nand.o
 obj-$(CONFIG_MTD_NAND_GPMI_NAND)	+= gpmi-nand/
 obj-$(CONFIG_MTD_NAND_XLP)		+= xlp_nand.o
+obj-$(CONFIG_MTD_NAND_XLP9XX)		+= xlp9xx_nand.o
 obj-$(CONFIG_MTD_NAND_XWAY)		+= xway_nand.o
 obj-$(CONFIG_MTD_NAND_BCM47XXNFLASH)	+= bcm47xxnflash/
 
diff --git a/drivers/mtd/nand/xlp9xx_nand.c b/drivers/mtd/nand/xlp9xx_nand.c
new file mode 100644
index 0000000..f4f13c2
--- /dev/null
+++ b/drivers/mtd/nand/xlp9xx_nand.c
@@ -0,0 +1,924 @@
+/*
+ * Copyright (c) 2003-2013 Broadcom Corporation
+ * All Rights Reserved
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the Broadcom
+ * license below:
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ *    notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ *    notice, this list of conditions and the following disclaimer in
+ *    the documentation and/or other materials provided with the
+ *    distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
+ * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
+ * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+#include <linux/delay.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/partitions.h>
+#include <linux/dma-mapping.h>
+#include <linux/of_mtd.h>
+#include <linux/of_irq.h>
+#include <linux/interrupt.h>
+
+#define NAND_COMMAND		0x40
+#define NAND_CONTROL		0x41
+#define NAND_STATUS		0x42
+#define NAND_STATUS_MASK  	0x43
+#define NAND_INT_MASK		0x44
+#define NAND_INT_STATUS		0x45
+#define NAND_ECC_CTRL		0x46
+#define NAND_ECC_OFFSET		0x47
+#define NAND_ECC_STAT		0x48
+#define NAND_ADDR0_COL		0x49
+#define NAND_ADDR0_ROW		0x4A
+#define NAND_ADDR1_COL		0x4B
+#define NAND_ADDR1_ROW		0x4C
+#define NAND_PROTECT		0x4D
+#define NAND_FIFO_DATA		0x4E
+#define NAND_DATA_REG0		0x4f
+#define NAND_DATA_REG SIZE 	0x50
+#define NAND_DMA_ADDR_L		0x5A
+#define NAND_DMA_ADD_H		0x5B
+#define NAND_DMA_CNT		0x5C
+#define NAND_DMA_CTRL		0x7D
+#define NAND_MEM_CTRL		0x60
+#define NAND_DATA_SIZE		0x61
+#define NAND_TIMINGS_ASYN 	0x62
+#define NAND_TIMINGS_SYN 	0x63
+#define NAND_TIME_SEQ0		0x64
+#define NAND_TIME_SEQ1		0x65
+#define NAND_FIFO_INIT		0x6c
+#define NAND_FIFO_STATE		0x6d
+#define FIFO_STAT_FULL		BIT(0)
+#define FIFO_STAT_EMPTY		BIT(1)
+#define NAND_SYSCTRL		0x80
+#define NAND_RYBYSEL		0x81
+#define NAND_RYBYSEL_STAT	0x8b
+
+				/*CMD 2		CMD 1/CMD 3	CMD 0	  SEQ */
+#define NAND_RESET_CMD		((0x0 << 24) | (0x0 << 16) | (0xFF << 8) | 0x0)
+#define NAND_READ_PARAMETER_CMD	((0x0 << 24) | (0x0 << 16) | (0xEC << 8) | 0x22)
+#define NAND_READ_ID_CMD	((0x0 << 24) | (0x0 << 16) | (0x90 << 8) | 0x21)
+#define NAND_READ_PAGE_CMD	((0x30 << 24) | (0x0 << 16) | (0x0 << 8) | 0x2a)
+#define NAND_ERASE_BLOCK_CMD	((0x0 << 24) | (0xD0 << 16) | (0x60 << 8) | 0xe)
+#define NAND_PAGE_PROGRAM_CMD	((0x0 << 24) | (0x10 << 16) | (0x80 << 8) | 0xc)
+#define NAND_READ_STATUS_CMD	((0x0 << 24) | (0x0 << 16) | (0x70 << 8) | 0x24)
+
+#define NAND_CMD_DATA_SEL		(1 << 7)
+#define NAND_CMD_DMA_FLAG		(1 << 6)
+#define NAND_CMD_ADDR1_FLAG		(1 << 7)
+#define NAND_CTRL_GINTR_EN		(1 << 4)
+#define NAND_CTRL_X16_FLAG		(1 << 12)
+#define NAND_CTRL_CUSTOM_XFER_FLAG	(1 << 11)
+
+#define NAND_CTRL_PAGE_SIZE(size)	(size << 8)
+#define NAND_CTRL_BLOCK_SIZE(size)	(size << 6)
+#define NAND_CTRL_ADDR_CYCLE(cyc)	(cyc << 0)
+#define NAND_CTRL_ECC_EN(en)		(en << 5)
+
+/*Sync mode WE High->RE Low*/
+#define NAND_TIME_SEQ0_TWHR(x)		(x << 24)
+/*ASync mode RE High->WE Low*/
+#define NAND_TIME_SEQ0_TRHW(x)		(x << 16)
+/*Async ALE->Data start*/
+#define NAND_TIME_SEQ0_TADL(x)		(x << 8)
+/*Chance column setup*/
+#define NAND_TIME_SEQ0_TCCS(x)		(x << 0)
+/*TRR time peroid*/
+#define NAND_TIME_ASYN_TREH(x)         (x << 12)
+#define NAND_TIME_ASYN_TREP(x)         (x << 8)
+
+#define NAND_TIME_SEQ1_TRR(x)		(x << 9)
+/*Busy time peroid for async->sync*/
+#define NAND_TIME_SEQ1_TWB(x)		(x << 0)
+/*RE/WE high hold time*/
+#define NAND_TIME_ASYN_TRH(x)		(x << 12)
+#define NAND_TIME_ASYN_TRP(x)		(x << 8)
+#define NAND_TIME_ASYN_TWH(x)		(x << 4)
+/*RE/WE pulse width*/
+#define NAND_TIME_ASYN_TWP(x)		(x << 0)
+
+#define BUF_SIZE	(16 * 1024)
+#define NAND_DEV_CS	1
+#define NAND_PARAM_SIZE (256 * 3)
+
+#define XLP_HWECC_OOBSIZE       0xc
+
+struct xlp9xx_nand_data {
+	struct nand_chip	chip;
+	struct mtd_info		mtd;
+	struct completion	cmd_complete;
+	void __iomem		*io_base;
+	int			hwecc;
+};
+
+struct nand_state {
+	int col_cyc;
+	int row_cyc;
+	int page_size;
+	int block_size;
+	int pages_per_block;
+	int spare_size;
+	int cs;
+	u32 buf_ptr;
+	u32 buf_len;
+	u32 block_lun;
+	u32 lun;
+	u8  *buf;
+	u32 last_cmd;
+	dma_addr_t buf_dma;
+};
+
+struct nand_info {
+	int node;
+	struct nand_state *nand_state;
+};
+
+static inline int xlp9xx_nand_read_reg(struct xlp9xx_nand_data *data,
+		int regidx)
+{
+	return readl(data->io_base + (regidx << 2));
+}
+
+static inline void xlp9xx_nand_write_reg(struct xlp9xx_nand_data *data,
+		int regidx, u32 val)
+{
+	writel(val, data->io_base + (regidx << 2));
+}
+
+static u8 s_eccbytes[] = { 4, 8, 14, 28, 42, 56 };
+static void xlp9xx_onfi_init(struct nand_chip *chip)
+{
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+	u8 *param_ptr = state->buf;
+	u32 val, sparee_bytes_per_512, ecc_bytes;
+	int block_val;
+	int ecc_offset;
+	int n, index;
+	int nBlk;
+	int bytes_eccblock, ecc_val;
+
+	struct xlp9xx_nand_data *data = container_of(chip,
+					struct xlp9xx_nand_data, chip);
+
+	state->page_size = ((param_ptr[80] << 0) |
+			    (param_ptr[81] << 8) |
+			    (param_ptr[82] << 16) |
+			    (param_ptr[83] << 24));
+
+	state->pages_per_block = ((param_ptr[92] << 0) |
+				  (param_ptr[93] << 8) |
+				  (param_ptr[94] << 16) |
+				  (param_ptr[95] << 24));
+
+	state->block_size = state->pages_per_block * state->page_size;
+
+	switch (state->pages_per_block) {
+	case 32:
+		block_val = 0;
+		break;
+	case 64:
+		block_val = 1;
+		break;
+	case 128:
+		block_val = 2;
+		break;
+	case 256:
+		block_val = 3;
+		break;
+	default:
+		block_val = -1;
+	}
+
+	if (block_val < 0)
+		pr_err("%s Invalide pages/block %d", __func__, block_val);
+
+	state->block_lun = param_ptr[96] |
+			   (u32) param_ptr[97] << 8 |
+			   (u32) param_ptr[98] << 16 |
+			   (u32) param_ptr[99] << 24;
+
+	state->lun = param_ptr[100];
+
+	state->spare_size = ((unsigned int)(param_ptr[84] << 0) |
+				(unsigned int)(param_ptr[85] << 8));
+
+	sparee_bytes_per_512 = state->spare_size / (state->page_size/512);
+
+	if (sparee_bytes_per_512 <= 4) {
+		ecc_bytes = 0;
+		ecc_val = 0;
+	} else if (sparee_bytes_per_512 <= 8) {
+		ecc_bytes = 4;
+		ecc_val = 0;
+	} else if (sparee_bytes_per_512 <= 16) {
+		ecc_bytes = 13;
+		ecc_val = 3;
+	} else if (sparee_bytes_per_512 <= 16) {
+		ecc_bytes = 20;
+		ecc_val = 5;
+	} else {
+		ecc_bytes = 23;
+		ecc_val = 6;
+	}
+
+	nBlk = state->page_size/512;
+	bytes_eccblock = ((int)state->spare_size -1)/ nBlk;
+	index = 0xff;
+	for (n = 0; n < sizeof(s_eccbytes); n++) {
+		if (bytes_eccblock < s_eccbytes[n])
+			break;
+		index = n;
+	}
+
+	if (index <= sizeof(s_eccbytes)) {
+		val = xlp9xx_nand_read_reg(data, NAND_CONTROL);
+		val |= 1 << 1; //512 bytes ecc block
+		val |= 1 << 5; // enable ecc block
+		xlp9xx_nand_write_reg(data, NAND_CONTROL, val);
+
+		val = xlp9xx_nand_read_reg(data, NAND_ECC_CTRL);
+		val |= (32 << 8) | (index & 7);
+		xlp9xx_nand_write_reg(data, NAND_ECC_CTRL, val);
+	}
+
+	ecc_offset = state->spare_size - ((state->page_size/512) * ecc_bytes);
+
+	if (data->hwecc) {
+		xlp9xx_nand_write_reg(data, NAND_ECC_OFFSET,
+					ecc_offset + state->page_size);
+
+		if (ecc_offset < XLP_HWECC_OOBSIZE)
+			pr_err("%s: OOBSIZE is small for nand!\n", __func__);
+
+		val = xlp9xx_nand_read_reg(data, NAND_CONTROL);
+
+		chip->ecc.size = 512;
+		chip->ecc.strength = 2;
+		chip->ecc.bytes = ecc_bytes;
+		chip->ecc.steps	= state->page_size / 512;
+		chip->ecc.total	= chip->ecc.steps * chip->ecc.bytes;
+		chip->ecc.layout = kzalloc(sizeof(struct nand_ecclayout),
+					   GFP_KERNEL);
+		if (!chip->ecc.layout)
+			pr_err("%s: kzalloc failed!!\n", __func__);
+		chip->ecc.layout->eccbytes = chip->ecc.bytes;
+		for (n = 0; n < chip->ecc.bytes; n++)
+			chip->ecc.layout->eccpos[n] = ecc_offset + n;
+
+		chip->ecc.layout->oobfree[0].offset = 2;
+		chip->ecc.layout->oobfree[0].length = XLP_HWECC_OOBSIZE -2;
+	} else {
+		val = xlp9xx_nand_read_reg(data, NAND_CONTROL);
+		val &= ~NAND_CTRL_ECC_EN(1);
+	}
+
+	val |= NAND_CTRL_BLOCK_SIZE(block_val);
+
+	xlp9xx_nand_write_reg(data, NAND_CONTROL, val);
+}
+
+static inline int nand_wait_fifo_stat(struct xlp9xx_nand_data *data,
+				      u32 reg, int mask)
+{
+	unsigned long timeout, stoptime, checktime;
+	int timedout;
+	u32 stat;
+
+	timeout = msecs_to_jiffies(1000);
+	stoptime = jiffies + timeout;
+	timedout = 0;
+
+	while (!timedout) {
+		checktime = jiffies;
+		stat = xlp9xx_nand_read_reg(data, reg);
+
+		if (!(stat & mask))
+			return 0;
+		timedout = time_after(checktime, stoptime);
+
+		cpu_relax();
+	}
+	return -ETIMEDOUT;
+} 
+
+static int stat_wait_ready(struct xlp9xx_nand_data *data, u32 reg, int cs)
+{
+	unsigned long timeout, stoptime, checktime;
+	int timedout;
+	u32 stat;
+
+	timeout = msecs_to_jiffies(1000);
+	stoptime = jiffies + timeout;
+	timedout = 0;
+
+	while (!timedout) {
+		checktime = jiffies;
+		stat = xlp9xx_nand_read_reg(data, reg);
+
+		if (stat & BIT(cs))
+			return 0;
+		timedout = time_after(checktime, stoptime);
+
+		cpu_relax();
+
+	}
+	return -ETIMEDOUT;
+}
+static void xlp9xx_send_cmd(struct mtd_info *mtd,
+		unsigned int cmd,
+		int column,
+		int row,
+		int len,
+		u8* buf)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+	int n, m;
+	u32 fifo_data = 0;
+	int status, ret;
+	u32 ctrl = 0;
+
+	struct xlp9xx_nand_data *data = container_of(mtd,
+			struct xlp9xx_nand_data, mtd);
+
+	if (buf == NULL || len <= 0 || mtd == NULL) {
+		pr_err("%s ERROR !!\n", __func__);
+		return;
+	}
+
+	status = stat_wait_ready(data, NAND_STATUS, state->cs);
+	if (status < 0)
+		pr_err("%s: wait timedout!!\n", __func__);
+
+	len = ((len + 7)/8) * 8;
+
+	ctrl = xlp9xx_nand_read_reg(data, NAND_CONTROL);
+
+	if ((column + len) > mtd->writesize)
+		xlp9xx_nand_write_reg(data, NAND_CONTROL, ctrl & (~(1 << 5)));
+
+	if (len > 0) {
+		xlp9xx_nand_write_reg(data, NAND_ADDR0_COL, column);
+		xlp9xx_nand_write_reg(data, NAND_ADDR0_ROW, row);
+		xlp9xx_nand_write_reg(data, NAND_DATA_SIZE, len);
+		xlp9xx_nand_write_reg(data, NAND_COMMAND, cmd);
+	}
+
+	for (n= 0; n < len; n += 8) {
+		ret = nand_wait_fifo_stat(data, NAND_FIFO_STATE,
+					  FIFO_STAT_FULL);
+		if ((ret != 0)) {
+			pr_err("%s: Empty FIFO !!\n", __func__);
+			break;
+		}
+
+		for (m = 0; m < 8; m += 4) {
+			fifo_data = xlp9xx_nand_read_reg(data, NAND_FIFO_DATA);
+
+			buf[n + m + 0] = (fifo_data >> 0 ) & 0xFF;
+			buf[n + m + 1] = (fifo_data >> 8 ) & 0xFF;
+			buf[n + m + 2] = (fifo_data >> 16) & 0xFF;
+			buf[n + m + 3] = (fifo_data >> 24) & 0xFF;
+		}
+	}
+
+	xlp9xx_nand_write_reg(data, NAND_CONTROL, ctrl);
+	state->last_cmd = cmd;
+}
+
+static int nand_write_page(struct xlp9xx_nand_data *data,
+		struct nand_state *state,
+		struct nand_chip *chip,
+		struct mtd_info *mtd, u32 row, u32 col, u32 len, u8* buf)
+{
+	u32  stat, n = 0, m, fifo_data, off;
+	u8 tmp[8];
+	int ret;
+
+	len = ((len + 7)/8) * 8;
+	if (buf == NULL || len <= 0)
+		return -ENOBUFS;
+
+	stat = stat_wait_ready(data, NAND_STATUS, state->cs);
+	if (stat < 0) {
+		pr_err("%s wait READY timedout!!\n", __func__);
+		return -EBUSY;
+	}
+
+	xlp9xx_nand_write_reg(data, NAND_DATA_SIZE, len);
+	xlp9xx_nand_write_reg(data, NAND_ADDR0_COL, col);
+	xlp9xx_nand_write_reg(data, NAND_ADDR0_ROW, row);
+	xlp9xx_nand_write_reg(data, NAND_COMMAND, NAND_PAGE_PROGRAM_CMD);
+
+	for (n = 0; n < len; n+=8) {
+		ret = nand_wait_fifo_stat(data, NAND_FIFO_STATE,
+					  FIFO_STAT_EMPTY);
+		if (ret != 0)
+			break;
+		for (m = 0; m < 8; m+=4) {
+			off = n + m;
+
+			fifo_data = (u32)buf[off + 0] << 0;
+			fifo_data |= (u32)buf[off + 1] << 8;
+			fifo_data |= (u32)buf[off + 2] << 16;
+			fifo_data |= (u32)buf[off + 3] << 24;
+
+			xlp9xx_nand_write_reg(data, NAND_FIFO_DATA, fifo_data);
+		}
+	}
+
+	stat = stat_wait_ready(data, NAND_STATUS, state->cs);
+	if (stat < 0) {
+		pr_err("%s READY timedout!!\n", __func__);
+		return -EBUSY;
+	}
+
+	xlp9xx_send_cmd(mtd, NAND_READ_PAGE_CMD, 0, 0, 8, tmp);
+
+	stat = chip->waitfunc(mtd, chip);
+	if (stat & 0x01) {
+		pr_debug("%s: error status = 0x%08x\n",
+				__func__, stat);
+		return -EBUSY;
+	}
+
+	if (n != len) {
+		pr_err("%s programe page failed!!!\n", __func__);
+		return -EIO;
+	}
+
+	return 0;
+}
+
+static void xlp9xx_nand_cmdfunc(struct mtd_info *mtd,
+		unsigned int command,
+		int column,
+		int page_addr)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+	static int column_prog;
+	static int page_prog;
+	int len = 0, status;
+	static int s_pageaddr;
+
+	u32 col, pos;
+	struct xlp9xx_nand_data *data = container_of(mtd,
+					struct xlp9xx_nand_data, mtd);
+
+	if (state->cs < 0)
+		return;
+
+	switch (command) {
+	/*
+	 * READ0 - read in first  256 bytes
+	 * READ1 - read in second 256 bytes
+	 */
+	case NAND_CMD_READ1:
+		column += 256;
+	case NAND_CMD_READ0:
+		state->buf_ptr = 0;
+		len = (mtd->writesize - column + 7) / 8 * 8;
+		xlp9xx_send_cmd(mtd,
+				NAND_READ_PAGE_CMD,
+				column,
+				page_addr,
+				len,
+				state->buf);
+
+		state->buf_ptr += mtd->writesize;
+		pos = mtd->writesize - column;
+		len = (mtd->oobsize + 7)/ 8 * 8;
+		xlp9xx_send_cmd(mtd,
+				NAND_READ_PAGE_CMD,
+				mtd->writesize + column,
+				page_addr,
+				len,
+				state->buf + pos);
+		state->buf_ptr = 0;
+		state->last_cmd = NAND_CMD_READ0;
+		break;
+		/* READOOB reads only the OOB because no ECC is performed. */
+	case NAND_CMD_READOOB:
+		state->buf_ptr = 0;
+		col = mtd->writesize;
+		len = (mtd->oobsize + 7) / 8 * 8;
+		xlp9xx_send_cmd(mtd,
+				NAND_READ_PAGE_CMD,
+				col,
+				page_addr,
+				len,
+				state->buf);
+		state->buf_ptr = column;
+		state->last_cmd = NAND_CMD_READOOB;
+		break;
+		/* READID must read all 5 possible bytes while CEB is active */
+	case NAND_CMD_READID:
+		state->buf_ptr = 0;
+		memset(state->buf, 0, state->buf_len);
+		xlp9xx_send_cmd(mtd, NAND_READ_ID_CMD, column, 0, 8, state->buf);
+		state->last_cmd = NAND_CMD_READID;
+		state->buf_ptr = 0;
+		break;
+	case NAND_CMD_PARAM:
+		memset(state->buf, 0, state->buf_len);
+		xlp9xx_send_cmd(mtd, NAND_READ_PARAMETER_CMD, 0, 0,
+				NAND_PARAM_SIZE, state->buf);
+		state->buf_ptr = 0;
+
+		if (state->page_size == 0)
+			xlp9xx_onfi_init(chip);
+
+		if (state->page_size > 0) {
+			u8* oldbuf = state->buf;
+			len = state->page_size + state->spare_size;
+			state->buf_len = NAND_PARAM_SIZE < len ? len :
+								NAND_PARAM_SIZE;
+			state->buf = kmalloc(state->buf_len, GFP_KERNEL);
+			if (state->buf == NULL)
+				pr_info("Kzalloc failed!!\n");
+			memcpy(state->buf, oldbuf, NAND_PARAM_SIZE);
+		}
+		state->last_cmd = NAND_CMD_PARAM;
+		break;
+		/* ERASE1 stores the block and page address */
+	case NAND_CMD_ERASE1:
+		s_pageaddr = page_addr;
+		break;
+		/* ERASE2 uses the block and page address from ERASE1 */
+	case NAND_CMD_ERASE2:
+		xlp9xx_nand_write_reg(data, NAND_ADDR0_COL, 0);
+		xlp9xx_nand_write_reg(data, NAND_ADDR0_ROW, s_pageaddr);
+		xlp9xx_nand_write_reg(data, NAND_COMMAND, NAND_ERASE_BLOCK_CMD);
+
+		state->last_cmd = NAND_ERASE_BLOCK_CMD;
+		status = chip->waitfunc(mtd, chip);
+		if (status & 0x01)
+			pr_debug("%s: error status = 0x%08x\n",
+					__func__, status);
+		break;
+		/* SEQIN sets up the addr buffer and all registers except
+		 * the length */
+	case NAND_CMD_SEQIN:
+		page_prog = page_addr;
+		column_prog = column;
+		state->buf_ptr = 0;
+		break;
+		/* PAGEPROG reuses all of the setup from SEQIN and adds
+		 * the length */
+	case NAND_CMD_PAGEPROG:
+		len = state->buf_ptr;
+		state->buf_ptr = 0;
+		status = nand_write_page(data, state, chip, mtd, page_prog,
+				column_prog, len, state->buf);
+		if (status < 0)
+			pr_err("%s PAGEPROG cmd failed\n", mtd->name);
+
+		status = chip->waitfunc(mtd, chip);
+		if (status & 0x01)
+			pr_err("%s: error status = 0x%08x\n",
+					__func__, status);
+		state->last_cmd = NAND_CMD_PAGEPROG;
+		break;
+
+	case NAND_CMD_STATUS:
+		memset(state->buf, 0, state->buf_len);
+		xlp9xx_send_cmd(mtd, NAND_READ_STATUS_CMD, column, 0, 8,
+				state->buf);
+		state->buf_ptr = 0;
+		state->last_cmd = NAND_CMD_STATUS;
+		break;
+		/* RESET command */
+	case NAND_CMD_RESET:
+		xlp9xx_nand_write_reg(data, NAND_COMMAND, NAND_RESET_CMD);
+		state->last_cmd = NAND_RESET_CMD;
+		status = stat_wait_ready(data, NAND_STATUS, state->cs);
+		if (status < 0)
+			pr_err("%s: RESET timedout!!\n", mtd->name);
+		break;
+
+	default:
+		pr_err("%s: unsupported command 0x%x\n", mtd->name, command);
+	}
+}
+
+static void xlp9xx_select_chip(struct mtd_info *mtd, int dev)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+
+	struct xlp9xx_nand_data *data = container_of(mtd,
+			struct xlp9xx_nand_data, mtd);
+
+	if (state->cs < 0) {
+		pr_err("%s: Invalid chip select [%d]\n", mtd->name, state->cs);
+		return;
+	}
+
+	if ((dev >= 0) && (dev < 8))
+		xlp9xx_nand_write_reg(data, NAND_MEM_CTRL, (state->cs & 0x7));
+}
+
+static uint8_t xlp9xx_nand_read_byte(struct mtd_info *mtd)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+	u32 id;
+
+	if (state->cs < 0)
+		return -ENODEV;
+
+	id = state->buf[state->buf_ptr];
+	state->buf_ptr = (state->buf_ptr + 1) % state->buf_len;
+
+	return id;
+}
+
+static void xlp9xx_nand_read_buf(struct mtd_info *mtd, uint8_t *buf, int len)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+	int i;
+
+	memset(buf, 0, len);
+	if (state->cs < 0)
+		return;
+
+	for (i = 0; i < len; i++) {
+		buf[i] = state->buf[state->buf_ptr];
+		state->buf_ptr = (state->buf_ptr + 1) % state->buf_len;
+	}
+}
+
+static void xlp9xx_nand_write_buf(struct mtd_info *mtd, const u8 *buf, int len)
+{
+	struct nand_chip *chip = (struct nand_chip *)mtd->priv;
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+	int i = 0, y;
+
+	if (state->cs < 0)
+		return;
+
+	while (len > 0) {
+		y = i++;
+		state->buf[state->buf_ptr] = buf[y];
+
+		state->buf_ptr = (state->buf_ptr + 1) % state->buf_len;
+		len--;
+	}
+}
+
+static int xlp9xx_nand_read_page(struct mtd_info *mtd, struct nand_chip *chip,
+		uint8_t *buf, int oob, int page)
+{
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+
+	if (state->cs < 0)
+		return -ENODEV;
+
+	if (oob)
+		xlp9xx_nand_read_buf(mtd, chip->oob_poi, mtd->oobsize);
+	else
+		xlp9xx_nand_read_buf(mtd, buf, mtd->writesize);
+
+	return 0;
+}
+
+static int xlp9xx_nand_write_page(struct mtd_info *mtd, struct nand_chip *chip,
+			const uint8_t *buf, int oob)
+{
+	struct nand_info *info = (struct nand_info *)chip->priv;
+	struct nand_state *state = (struct nand_state *)info->nand_state;
+
+	if (state->cs < 0)
+		return -ENODEV;
+
+	if (oob)
+		xlp9xx_nand_write_buf(mtd, chip->oob_poi, mtd->oobsize);
+	else
+		xlp9xx_nand_write_buf(mtd, buf, mtd->writesize);
+	return 0;
+}
+
+static int of_xlp_nand_devices(void __iomem *io_base,
+		struct platform_device *pdev,
+		struct device_node *child, int count)
+{
+	struct xlp9xx_nand_data *data = NULL;
+	struct nand_info *info = NULL;
+	struct nand_state *state = NULL;
+	struct mtd_part_parser_data ppdata;
+	const __be32 *prop;
+	int ecc_mode, len, chip_select, val, ret;
+
+	if (count > 0) {
+		chip_select = 1;
+	} else {
+		prop = of_get_property(child, "reg", &len);
+		if (!prop || len < sizeof(*prop)) {
+			dev_err(&pdev->dev, "No 'reg' property\n");
+			return -ENXIO;
+		}
+		chip_select = be32_to_cpup(prop);
+	}
+
+	data = devm_kzalloc(&pdev->dev, sizeof(struct xlp9xx_nand_data),
+			    GFP_KERNEL);
+	if (!data) {
+		dev_err(&pdev->dev, "failed to get device structure.\n");
+		return -ENOMEM;
+	}
+
+	info = devm_kzalloc(&pdev->dev, sizeof(struct nand_info), GFP_KERNEL);
+	if (!info)
+		return -ENOMEM;
+
+	info->nand_state = devm_kzalloc(&pdev->dev, sizeof(struct nand_state),
+					GFP_KERNEL);
+	if (!info->nand_state)
+		return -ENOMEM;
+
+	data->io_base	= io_base;
+
+	state		= info->nand_state;
+	state->last_cmd	= 0;
+	state->cs	= chip_select;
+	state->buf_ptr	= 0;
+	state->buf_len	= BUF_SIZE;
+	state->buf	= devm_kzalloc(&pdev->dev, BUF_SIZE, GFP_KERNEL);
+	if (!state->buf) {
+		dev_err(&pdev->dev, "devm_kzalloc failed\n");
+		return -ENXIO;
+	}
+
+	data->chip.priv	= (void *)info;
+
+	data->mtd.priv	= &data->chip;
+	data->mtd.owner	= THIS_MODULE;
+	data->mtd.name	= dev_name(&pdev->dev);
+
+	data->chip.chip_delay	= 25;
+	data->chip.IO_ADDR_R	= data->io_base;
+	data->chip.IO_ADDR_W	= data->io_base;
+	data->chip.read_byte	= xlp9xx_nand_read_byte;
+	data->chip.read_buf	= xlp9xx_nand_read_buf;
+	data->chip.write_buf	= xlp9xx_nand_write_buf;
+	data->chip.cmdfunc	= xlp9xx_nand_cmdfunc;
+	data->chip.select_chip	= xlp9xx_select_chip;
+	data->chip.options	= NAND_SKIP_BBTSCAN;
+
+	xlp9xx_nand_write_reg(data, NAND_RYBYSEL, 0x1);
+	val = stat_wait_ready(data, NAND_RYBYSEL_STAT, state->cs);
+	if (val < 0) {
+		dev_err(&pdev->dev, "nand device not ready\n");
+		return -ETIMEDOUT;
+	}
+
+	xlp9xx_nand_write_reg(data, NAND_COMMAND, NAND_RESET_CMD);
+	val = stat_wait_ready(data, NAND_STATUS, state->cs);
+	if (val < 0) {
+		dev_err(&pdev->dev, "nand device not ready\n");
+		return -ETIMEDOUT;
+	}
+
+	xlp9xx_nand_write_reg(data, NAND_CONTROL, 0x0);
+	xlp9xx_nand_write_reg(data, NAND_MEM_CTRL, 0x1);
+	val = (NAND_TIME_SEQ0_TWHR(0x1f) |
+			NAND_TIME_SEQ0_TRHW(0x1f) |
+			NAND_TIME_SEQ0_TADL(0x1f) |
+			NAND_TIME_SEQ0_TCCS(0x1f));
+	xlp9xx_nand_write_reg(data, NAND_TIME_SEQ0, val);
+
+	val = NAND_TIME_ASYN_TWH(0xf) | NAND_TIME_ASYN_TWP(0xf) |
+		NAND_TIME_ASYN_TRP(0xf) | NAND_TIME_ASYN_TRH(0xf);
+	xlp9xx_nand_write_reg(data, NAND_TIMINGS_ASYN, val);
+
+	ecc_mode = of_get_nand_ecc_mode(pdev->dev.of_node);
+	data->chip.ecc.mode = ecc_mode < 0 ? NAND_ECC_SOFT : ecc_mode;
+	data->hwecc = ecc_mode == NAND_ECC_HW ? 1 : 0;
+
+	if (data->hwecc) {
+		data->mtd.oobsize = XLP_HWECC_OOBSIZE;
+	} else
+		data->mtd.oobsize = 64;
+
+	data->chip.ecc.read_page  = xlp9xx_nand_read_page;
+	data->chip.ecc.write_page = xlp9xx_nand_write_page;
+
+	platform_set_drvdata(pdev, data);
+	if (nand_scan(&data->mtd, 1))
+		return -ENXIO;
+
+	ppdata.of_node = child;
+	ret = mtd_device_parse_register(&data->mtd, NULL, &ppdata, NULL, 0);
+
+	if (!ret)
+		return ret;
+
+	nand_release(&data->mtd);
+	return ret;
+}
+
+/*
+ * Probe for the NAND devices.
+ */
+static int xlp9xx_nand_probe(struct platform_device *pdev)
+{
+	struct device_node *child;
+	struct resource *res;
+	void __iomem *io_base;
+	int ret = 0, count = 0;
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(&pdev->dev, " couldn't get resource !!\n");
+		return -ENOMEM;
+	}
+
+	io_base = devm_request_and_ioremap(&pdev->dev, res);
+	if (!io_base) {
+		dev_err(&pdev->dev, "ioremap failed!!\n");
+		return -ENOMEM;
+	}
+
+	for_each_child_of_node(pdev->dev.of_node, child) {
+		/* Deprecated, Needs to be removed with updated FDT */
+		if (!strcmp(child->name, "partition")) {
+			count++;
+		} else {
+			ret = of_xlp_nand_devices(io_base, pdev, child, count);
+			if (ret < 0)
+				return ret;
+		}
+		continue;
+	}
+	/* Deprecated, Needs to be removed with updated FDT */
+	if (count > 0) {
+		dev_err(&pdev->dev, "Old FDT, DTS file needs to be updated!\n");
+		child = pdev->dev.of_node;
+		ret = of_xlp_nand_devices(io_base, pdev, child, count);
+		if (ret < 0)
+			return ret;
+	}
+	return ret;
+}
+
+static int xlp9xx_nand_remove(struct platform_device *pdev)
+{
+	struct xlp9xx_nand_data *data = platform_get_drvdata(pdev);
+	nand_release(&data->mtd);
+	kfree(data);
+	return 0;
+
+}
+static const struct of_device_id xlp9xx_nand_dt[] = {
+	{ .compatible = "brcm,xlp9xx-nand" },
+	{}
+};
+
+static struct platform_driver xlp9xx_nand_driver = {
+	.probe	= xlp9xx_nand_probe,
+	.remove	= xlp9xx_nand_remove,
+	.driver	= {
+		.name		= "xlp9xx-nand",
+		.owner		= THIS_MODULE,
+		.of_match_table = xlp9xx_nand_dt,
+	},
+};
+module_platform_driver(xlp9xx_nand_driver);
+
+MODULE_AUTHOR("Kamlakant Patel <kamlakant.patel@broadcom.com>");
+MODULE_DESCRIPTION("Netlogic XLP NAND Flash Controller driver");
+MODULE_LICENSE("GPL v2");
-- 
1.7.1

