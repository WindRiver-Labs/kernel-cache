From 397e2e1fc10938a92834dbde7ae957303b992f98 Mon Sep 17 00:00:00 2001
From: Om Narasimhan <onarasimhan@netlogicmicro.com>
Date: Wed, 7 Dec 2011 15:55:44 -0800
Subject: Rewrite of PCIe network driver

PCIe card has a driver that can connect to host. This driver now uses the PCIe
infrastructure driver's subsystem. Tested with iperf and ping -f without any
packet loss on PCIe interface.

MSI-X enabled on the host. But /proc/interrupts in x86 does not differentiate
between MSI and MSI-X. (The file will contain the same vector number if device
uses only one MSI-X like this driver).

Further bugs fixed :
1. rmmod stack dump : rmmod of pcieip used to stack dump. Fixed.
2. README.txt is synced up with the new code.
[Based on SDK 3.2]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
Signed-off-by: Nam Ninh <nam.ninh@windriver.com>

diff --git a/drivers/misc/netlogic/pcie-offload/README.txt b/drivers/misc/netlogic/pcie-offload/README.txt
index 45d189b..ee99b2c 100644
--- a/drivers/misc/netlogic/pcie-offload/README.txt
+++ b/drivers/misc/netlogic/pcie-offload/README.txt
@@ -17,7 +17,7 @@ environment.
 $ cd pcie-offload
 $ ./setup_dev.sh
 
-   
+
 IMPORTANT NOTE :
 This script will compile the modules and installs the modules in the root file
 system. To use them, you might have to re-build linux kernel image again.
@@ -39,18 +39,19 @@ For the network over PCIe interface:
 ===================================
 1. Use the vmlinux to boot the device
 2. In the booted pcie device, run
-   $ modprobe pcieipdev
-3. in the host (as root or using sudo)
-   $ insmod ./net/host/pcieip.ko
-4. On the pcie device
+   $ modprobe netl_pti
+3. In the HOST (as root or using sudo)
+   $ insmod ./char/host/netl_pti.ko
+4. In the pcie device
+   $ modprobe pcieip
    $ ifconfig eth0 <IP addr> <netmask>	...etc
-4. On the host
+4. In the host
+   $ insmod ./net/host/pcieip.ko
    $ ifconfig ethX <IP addr> <netmas> ...etc
    # You need to find the ethX using $ifconfig -a
 
 You can do ftp, tftp ..etc between the host and device interfaces now.
 
-
 For the character device interface :
 ===================================
 Once card boots up
@@ -68,22 +69,18 @@ There are guidelines till an all automated version of this program is completed.
    netl_pti.ko on the host side.
 
 2. Once the handshake is complete, you would see something like,
-   "Ctrl Subsys init done. DEV ready for TXRX" printed on the console.
-
+	Init subsystem X
+	Subsystem Done X
+	X could be 0 - 7 (including)
 3. You need to figure out the minor and major numbers from /proc/devices before
 you create a node. Execute
  $ cat /proc/devices | grep netl_pti
 Use the major number printed like,
  #mknod /dev/netl_char1 c <MAJOR> 1 # 1 is minor number
+ This character device would use subsystem 1
+ You may not use the minor number 0, for this is reserved for control traffic
 
 4. Userspace components need be initialized before dd can work. For that,
  $ dd if=/dev/zero of=/dev/netl_char1 bs=4k count=0
 
 5. Repeat the above command on host side as well.
-
-*NOTE*
-=====
-It is important that you execute the above command in the host first.
-Otherwise, device would never see anything from host.
-
-For testing the device,  you may use dd command on the device and host.
diff --git a/drivers/misc/netlogic/pcie-offload/char/device/netl_pti_dev.c b/drivers/misc/netlogic/pcie-offload/char/device/netl_pti_dev.c
index a9d7018..4c69992 100644
--- a/drivers/misc/netlogic/pcie-offload/char/device/netl_pti_dev.c
+++ b/drivers/misc/netlogic/pcie-offload/char/device/netl_pti_dev.c
@@ -3,7 +3,6 @@
 static struct handshake_struct *dev_hs;
 extern int init_subsystems(struct handshake_struct *hs);
 extern void dealloc_all_subsys(struct handshake_struct *hs);
-extern void dump_hs(struct seq_file *seq, struct handshake_struct *hs);
 extern void dump_desc_ring(struct seq_file *seq, struct desc_ring *ring, int dump_all);
 extern void dump_descriptor(struct seq_file *seq, struct descriptor *ptr);
 extern int add_to_rxlist(struct pti_subsys *ss, volatile struct kvec *iov);
@@ -16,8 +15,6 @@ static u64 pti_mem_start;
 struct workqueue_struct *ss_workq;
 
 /* Function delcarations */
-static void hs_dev_func(struct work_struct *work);
-static int hs_get_cmdval(struct handshake_struct *, volatile u32 *);
 void hs_set_cmdreg(struct handshake_struct *hs);
 void subsys_poll(struct pti_subsys *);
 static void subsys_poll_rx(struct pti_subsys *);
@@ -96,11 +93,11 @@ void dev_def_rx_cmpl(void *ptr, uint64_t ignored)
 	u32 tmp;
 
 	if(!ptr){
-		PDEBUG("NULL func ptr\n");
+		fdebug("NULL func ptr\n");
 		return;
 	}
 	ss = d->pring->ss;
-	//PDEBUG("ss->id = %#x, d->idx = %#x\n", ss->id, d->idx);
+	//fdebug("ss->id = %#x, d->idx = %#x\n", ss->id, d->idx);
 	spin_lock_irqsave(&d->pring->rng_lock, flags);
 	pti_pci_write32(0, (void *)&d->pci_desc->dma_stat);
 	d->pring->end = INCR_CEIL(d->idx);
@@ -119,7 +116,7 @@ void dev_def_rx_cmpl(void *ptr, uint64_t ignored)
 		PERROR("W %#x, R %#x\n", INCR_CEIL(d->idx), tmp);
 	}
 #endif
-	//PDEBUG("Updated STAT %#x, TAIL = %#x\n", pti_pci_read32((void *)&d->pci_desc->dma_stat), pti_pci_read32((void *)d->pring->tail));
+	//fdebug("Updated STAT %#x, TAIL = %#x\n", pti_pci_read32((void *)&d->pci_desc->dma_stat), pti_pci_read32((void *)d->pring->tail));
 	/* Send data upstream here  TODO */
 	rx.iov_len = d->len;
 	ss->rxbytes += d->len;
@@ -163,7 +160,7 @@ void dev_def_tx_cmpl(void *ptr, uint64_t ignored)
 		PERROR("W %#x, R %#x\n", d->len, tmp);
 	}
 #endif
-	//PDEBUG("Cleared dma_stat:%p, head = %#x\n", &d->pci_desc->dma_stat, d->idx);
+	//fdebug("Cleared dma_stat:%p, head = %#x\n", &d->pci_desc->dma_stat, d->idx);
 	//dump_desc_ring(NULL, d->pring, 0);
 	spin_unlock_irqrestore(&d->pring->rng_lock, flags);
 	raise_host_interrupt(0);
@@ -179,10 +176,10 @@ static void subsys_poll_tx(struct pti_subsys *ss)
 	txr = ss->txring;
 	spin_lock_irqsave(&txr->rng_lock, fl_rng);
 	tail = pti_pci_read32((void *)txr->tail);
-	loops = (ss->hs->params.nr_desc + tail - txr->end) % ss->hs->params.nr_desc;
-	// PDEBUG("tail = %#x, END = %#x\n", tail, txr->end);
+	loops = (NETL_NR_DESC + tail - txr->end) % NETL_NR_DESC;
+	// fdebug("tail = %#x, END = %#x\n", tail, txr->end);
 	while(loops--){
-		//PDEBUG("loops = %d, end = %#x\n", loops+1, txr->end);
+		//fdebug("loops = %d, end = %#x\n", loops+1, txr->end);
 		free_page(txr->pdesc[txr->end].buf);
 		txr->pdesc[txr->end].buf = 0;
 		txr->pdesc[txr->end].len = 0;
@@ -217,10 +214,9 @@ static void subsys_poll_rx(struct pti_subsys *ss)
 	rxr = ss->rxring;
 	spin_lock_irqsave(&rxr->rng_lock, fl_rng);
 	head = pti_pci_read32((void *)rxr->head);
-	loops = (ss->hs->params.nr_desc + head - rxr->start) % ss->hs->params.nr_desc;
+	loops = (NETL_NR_DESC + head - rxr->start) % NETL_NR_DESC;
 	spin_unlock_irqrestore(&rxr->rng_lock, fl_rng);
 	while(loops--){
-//		PDEBUG("loops = %d, head = %#x, start= %#x\n", loops+1, head, rxr->start);
 		spin_lock_irqsave(&rxr->rng_lock, fl_rng);
 		copy_desc_pci(&d_cp, rxr->pdesc[rxr->start].pci_desc);
 		if(!is_dma_set(d_cp.dma_stat)){
@@ -231,11 +227,11 @@ static void subsys_poll_rx(struct pti_subsys *ss)
 			return;
 		}
 		/* setup DMA with the tail we have now */
-		//PDEBUG("d_cp.dma_len = %#x\n", d_cp.dma_len);
+		//fdebug("d_cp.dma_len = %#x\n", d_cp.dma_len);
 		rxr->pdesc[rxr->start].buf = get_zeroed_page(GFP_ATOMIC);
 		rxr->pdesc[rxr->start].len = d_cp.dma_len;
 		rxr->pdesc[rxr->start].idx = rxr->start;
-		//PDEBUG("head = %#x, rxr->start = %#x, idx = %#x\n", head, rxr->start, rxr->pdesc[rxr->start].idx);
+		//fdebug("head = %#x, rxr->start = %#x, idx = %#x\n", head, rxr->start, rxr->pdesc[rxr->start].idx);
 		stmp = rxr->start;
 		rxr->start= INCR_CEIL(rxr->start);
 		spin_unlock_irqrestore(&rxr->rng_lock, fl_rng);
@@ -249,7 +245,7 @@ static void subsys_poll_rx(struct pti_subsys *ss)
 	ss->flags &= ~SUBSYS_FLAGS_RX;
 	ss->flags &= ~SUBSYS_FLAGS_RX_PENDING;
 	spin_unlock_irqrestore(&ss->slock, fl_rng);
-//	PDEBUG("Exiting with head = %#x, start= %#x, end = %#x\n", head, rxr->start, rxr->end);
+//	fdebug("Exiting with head = %#x, start= %#x, end = %#x\n", head, rxr->start, rxr->end);
 	return;
 }
 
@@ -268,9 +264,9 @@ int send_one_packet_to_host(struct pti_subsys *ss, unsigned long page, u32 len)
 	u32 tmp;
 	txr = ss->txring;
 	spin_lock_irqsave(&txr->rng_lock, fl_rng);
-	// PDEBUG("end = %#x, start = %#x\n", txr->end, txr->start);
+	// fdebug("end = %#x, start = %#x\n", txr->end, txr->start);
 	if(INCR_CEIL(txr->start) == txr->end){	/* Queue full */
-		//PDEBUG("Queue full\n");
+		//fdebug("Queue full\n");
 		spin_unlock_irqrestore(&txr->rng_lock, fl_rng);
 		return EAGAIN;
 	}
@@ -304,7 +300,7 @@ int send_one_packet_to_host(struct pti_subsys *ss, unsigned long page, u32 len)
 		PERROR("dma failure\n");
 		return EFAULT;
 	}
-	// PDEBUG("\n");
+	// fdebug("\n");
 	return 0;
 }
 
@@ -388,115 +384,49 @@ rx_done:
 }
 
 /*
- * Sets the cmd and stat pointers to pci mem space
- *
- * @hs : the handshake structure
- */
-void hs_set_cmdreg(struct handshake_struct *hs)
-{
-	PDEBUG("hs->start = %p\n", hs->start);
-	hs->wcmd = (volatile u32 *)(hs->start + PTI_ADDR_OFFSET + DCMD0_OFFSET);
-	hs->rstat = (volatile u32 *)(hs->start + PTI_ADDR_OFFSET + DSTAT0_OFFSET);
-	hs->rcmd = (volatile u32 *)(hs->start + PTI_ADDR_OFFSET + HCMD0_OFFSET);
-	hs->wstat = (volatile u32 *)(hs->start + PTI_ADDR_OFFSET + HSTAT0_OFFSET);
-	return;
-}
-
-/*
- * Helper function to read ONE cmd value, cmd0/stat0 or cmd1/stat1
- * Need to call repeatedly till returns HS_PARAM_{FINISH,ERROR}
- * @hs : handshake structure
- */
-static int hs_get_cmdval(struct handshake_struct *hs, volatile u32 *pos)
-{
-	volatile u32 cval = 0;
-
-	//PDEBUG("Reading commands from host\n");
-	cval = pti_pci_read32((void *)pos);
-	/* clear what we read */
-	pti_pci_write32(0, (void *)pos);
-	hs->params.max_subsys = cval;
-
-	pos++;
-	cval = pti_pci_read32((void *)pos);
-	/* clear what we read */
-	pti_pci_write32(0, (void *)pos);
-	hs->params.flags = cval;
-
-	pos++;
-	cval = pti_pci_read32((void *)pos);
-	/* clear what we read */
-	pti_pci_write32(0, (void *)pos);
-	hs->params.nr_desc = cval;
-
-	return 0;
-}
-
-/*
- * This function gets cmd/val pairs from host and fills hs structure
- *
- * @hs : handshake struct to fill
- *
- * returns : 0 if all is well
- */
-u32 parse_hs_from_host(struct handshake_struct *hs)
-{
-	u32 ret = 0;
-	volatile u32 *pos = hs->rcmd + 1;
-
-	ret = pti_pci_read32((void *)hs->rcmd);
-	if(ret != NETL_HOST_SIGNATURE){
-		PDEBUG("No host signature yet\n");
-		return HS_STATUS_NOT_DONE;
-	}
-	pti_pci_write32(0, (void *)hs->rcmd);
-	hs_get_cmdval(hs, pos);
-	/* update device signature */
-	pti_pci_write32(NETL_DEV_SIGNATURE, (void *)(hs->rcmd));
-	return HS_STATUS_COMPLETE;
-}
-
-/*
  * This function is the looping handshake function for handshake
  *
  * @work : handshake_struct -> hs_work
  */
-static void hs_dev_func(struct work_struct *work)
+void hs_work_func(struct work_struct *work)
 {
-	struct handshake_struct *hs = container_of(work, struct handshake_struct,
-			hs_work.work);
-	u32 ret = 0;
+	__label__ init_ss_fail;
+	struct handshake_struct *hs = container_of(
+		work, struct handshake_struct, hs_work.work);
+	unsigned long flags;
+	u32 ret, i;
 
-	if(hs->status == HS_DEV_EXITING){
+	pti_pci_write32(NETL_DEV_SIGNATURE, (void *)hs->start);
+	ret = pti_pci_read32((void *)(hs->start + 4));
+	//PDEBUG("hs->start = %p,* =%#x\n", hs->start, pti_pci_read32(hs->start));
+	if (ret != NETL_HOST_SIGNATURE) {
+		fdebug("No signature yet\n");
+		schedule_delayed_work(&hs->hs_work, HZ);
 		return;
 	}
-	ret = parse_hs_from_host(hs);
-	if(ret == HS_STATUS_COMPLETE){
-		netl_register_chrdev(hs);
-		dump_hs(NULL, hs);
-		if (init_one_subsys(hs, NETL_CONTROL_SUBSYS) == NULL) {
-			PERROR("FATAL : Ctrl Subsys init FAILED\n");
-			return;
+	spin_lock_irqsave(&hs->hs_lock, flags);
+	hs->status = HS_DEV_READY_TXRX;
+	spin_unlock_irqrestore(&hs->hs_lock, flags);
+	netl_register_chrdev(hs);
+	for(i = 0; i < NETL_MAX_SUBSYS; i++) {
+		hs->ss[i] = init_one_subsys(hs, i);
+		if (hs->ss[i] == NULL) {
+			goto init_ss_fail;
 		}
-		hs->status = HS_DEV_READY_TXRX;
-		PDEBUG("Ctrl Subsys init done. DEV ready for TXRX\n");
-		/* No more self schedule. Just start tasklet */
-		tasklet_schedule(&hs->hs_stask);
-	}else{
-		//PDEBUG("(%#x). Rescheduling...\n", ret);
-		schedule_delayed_work(&hs->hs_work, HZ);
+	}
+	/* No more self schedule. Just start tasklet */
+	tasklet_schedule(&hs->hs_stask);
+	return;
+init_ss_fail:
+	while (i--) {
+		/* free the subsystem  TBD TODO */
 	}
 	return;
 }
 
 int dev_specific_hs_init(struct handshake_struct *hs)
 {
-	hs_set_cmdreg(hs);
 	hs->status = HS_STATUS_NOT_DONE;
-	hs->params.nr_desc = 0;
-	hs->params.max_subsys = 0;
-	hs->params.flags = 0;
-	INIT_DELAYED_WORK(&hs->hs_work, hs_dev_func);
 	INIT_DELAYED_WORK(&hs->temp_int_work, temp_int_func);
 	tasklet_init(&hs->hs_stask, hs_task_func, (long unsigned int)hs);
 	return 0;
@@ -524,12 +454,19 @@ int __init netl_pti_dev_init(void)
 	if (dev_hs->start == NULL) {
 		return -EFAULT;
 	}
+	dev_hs->start += PTI_ADDR_OFFSET;
 	init_handshake_struct(dev_hs);
-	schedule_delayed_work(&dev_hs->hs_work, 100);	/*In keventd*/
+	schedule_delayed_work(&dev_hs->hs_work, HZ);
 	PERROR("pti_subsys = %ld, desc_ring = %ld, descriptor = %ld, _desc_pci = %ld, rx=%ld\n", sizeof(struct pti_subsys), sizeof(struct desc_ring), sizeof(struct descriptor), sizeof(struct _desc_pci), sizeof(struct rx_struct));
 	return 0;
 }
 
+int get_hs(struct handshake_struct **res)
+{
+	*res = dev_hs;
+	return 0;
+}
+
 void __exit netl_pti_dev_uninit(void)
 {
 	if(dev_hs->status == HS_DEV_READY_TXRX){
@@ -539,6 +476,8 @@ void __exit netl_pti_dev_uninit(void)
 	tasklet_kill(&dev_hs->hs_stask);
 	cancel_delayed_work_sync(&dev_hs->temp_int_work);
 	flush_delayed_work(&dev_hs->temp_int_work);
+	cancel_delayed_work_sync(&dev_hs->hs_work);
+	flush_delayed_work(&dev_hs->hs_work);
 	dealloc_all_subsys(dev_hs);
 	debugfs_remove_recursive(dev_hs->dbg_root);
 	kfree(dev_hs);
diff --git a/drivers/misc/netlogic/pcie-offload/char/host/netl_pti_host.c b/drivers/misc/netlogic/pcie-offload/char/host/netl_pti_host.c
index 63dc6e7..dc55212 100644
--- a/drivers/misc/netlogic/pcie-offload/char/host/netl_pti_host.c
+++ b/drivers/misc/netlogic/pcie-offload/char/host/netl_pti_host.c
@@ -16,7 +16,6 @@ static struct pci_device_id netl_id_table[] = {
 };
 
 extern void dealloc_all_subsys(struct handshake_struct *hs);
-extern void dump_hs(struct seq_file *seq, struct handshake_struct *hs);
 extern void dump_desc_ring(struct seq_file *seq, struct desc_ring *ring, int dump_all);
 extern void netl_unregister_chrdev(struct handshake_struct *hs);
 extern int netl_register_chrdev(struct handshake_struct *hs);
@@ -48,7 +47,6 @@ irqreturn_t host_msi_handler(int irq, void *d);
 int send_one_packet_to_device(struct pti_subsys *ss, unsigned long data, u32 len);
 void netl_rm_dev(struct handshake_struct *p);
 int init_device(struct handshake_struct *hs, int blocking);
-static void hs_work_func(struct work_struct *work);
 static void netl_phnx_generic_remove(struct pci_dev *pdev);
 int netl_pti_default_rx(uint8_t msg_code, void *laddr, unsigned int llen, void *addr, unsigned int len);
 static void raise_device_interrupt(void);
@@ -56,7 +54,6 @@ int __host_def_rx_cmpl(struct pti_subsys *ss, struct descriptor *d, struct iovec
 int add_to_rxlist(struct pti_subsys *ss, volatile struct kvec *iov);
 
 struct pti_subsys *get_ss_from_idx(struct handshake_struct *hs, int idx);
-static int start_host_control_subsys(struct handshake_struct *hs, struct pti_subsys **ctrl_ss);
 
 void temp_int_func(struct work_struct *work);
 int setup_host_irq(struct handshake_struct *);
@@ -67,13 +64,6 @@ static void raise_device_interrupt(void)
 //	PDEBUG("Raising an interrupt to device\n");
 }
 
-#define incr_sent_seq(hs)\
-do{\
-	volatile u32 sn = phnx_pci_readb(&(hs->sent_msg_seq));\
-	host_to_pci32(sn+1, &(hs->sent_msg_seq));\
-}while(0)
-
-
 static struct pci_driver netl_pci_driver = {
 	.name = NETL_DRIVER,
 	.id_table = netl_id_table,
@@ -98,10 +88,13 @@ static void netl_phnx_generic_remove(struct pci_dev *pdev)
 	hs->status = HS_DEV_EXITING;
 	spin_unlock_irqrestore(&hs->hs_lock, flags);
 #ifdef NETL_TARGET_XLP
-	if(hs->msi_flag == NETL_MSI_ENABLE){
+	if(hs->msi_flag == NETL_MSIX_ENABLE) {
+		free_irq(hs->msix.vector, hs);
+		pci_disable_msix(pdev);
+	} else if (hs->msi_flag == NETL_MSI_ENABLE) {
 		free_irq(pdev->irq, hs);
 		pci_disable_msi(pdev);
-	}else if(hs->msi_flag == NETL_INTX_ENABLE){
+	} else if (hs->msi_flag == NETL_INTX_ENABLE) {
 		free_irq(pdev->irq, pdev);
 	}
 #else
@@ -111,11 +104,10 @@ static void netl_phnx_generic_remove(struct pci_dev *pdev)
 	/* No more tasklet scheduling from now onwards */
 	netl_rm_dev(hs);
 	dealloc_all_subsys(hs);
+	del_timer_sync(&hs->link_timer);
 	debugfs_remove_recursive(hs->dbg_root);
 	kfree(hs->hhash);
 	pci_set_drvdata(pdev, NULL);
-	cancel_delayed_work(&hs->hs_work);
-	flush_delayed_work(&hs->hs_work);
 	iounmap(hs->start);
 	pci_release_region(pdev, 0);
 	pci_disable_device(pdev);
@@ -207,36 +199,47 @@ int host_def_rx_cmpl(struct descriptor *d)
 }
 /*
  * Handles the handshake of device
+ * The device writes 'NETL'. Host waits till this value is read.
+ * Then host writes elements of hs_params into shared space
+ * This function is executed from a timer
  */
-static void hs_work_func(struct work_struct *work)
+void hs_work_func(struct work_struct *work)
 {
+	__label__ init_ss_fail, init_irq_fail;
 	struct handshake_struct *hs = container_of(
 		work, struct handshake_struct, hs_work.work);
 	unsigned long flags;
-	u32 ret;
+	u32 ret, i;
 
-	if(!hs){
-		PDEBUG("Null HS\n");
-		return;
-	}
-	ret = pti_pci_read32((void *)hs->wcmd);
+	ret = pti_pci_read32((void *)hs->start);
+	PDEBUG("hs->start = %p, * = %#x\n", hs->start, ret);
 	if(ret == NETL_DEV_SIGNATURE){
-		/* Now clear host and dev signatures */
-		pti_pci_write32(0, (void *)hs->wcmd);
-		pti_pci_write32(0, (void *)(hs->wcmd + (NETL_HS_MAX_PARAMS - 1)));
+		for(i = 0; i < NETL_MAX_SUBSYS; i++) {
+			hs->ss[i] = init_one_subsys(hs, i);
+			if (hs->ss[i] == NULL) {
+				goto init_ss_fail;
+			}
+		}
+		if(setup_host_irq(hs) < 0){
+			PERROR("Failed to setup Interrupt. Exiting\n");
+			goto init_irq_fail;
+		}
+		pti_pci_write32(NETL_HOST_SIGNATURE, (void *)hs->start + 4);
+		mdelay(500);
 		spin_lock_irqsave(&hs->hs_lock, flags);
 		hs->status = HS_DEV_READY_TXRX;
 		spin_unlock_irqrestore(&hs->hs_lock, flags);
 		PDEBUG("HS complete. Device ready for Tx and Rx\n");
-		ret = setup_host_irq(hs);
-		if(ret < 0){
-			PERROR("Failed to setup Interrupt. Exiting\n");
-			return;
-		}
 	}else{
 		schedule_delayed_work(&hs->hs_work, HZ);
 	}
 	return;
+init_irq_fail:
+init_ss_fail:
+	while (i--) {
+		/* free the subsystem  TBD TODO */
+	}
+	return;
 }
 
 /*
@@ -244,56 +247,31 @@ static void hs_work_func(struct work_struct *work)
  *
  * @hs	: handshake struct
  */
+/* TBD REMOVE */
+#if 0
 static int start_host_control_subsys(struct handshake_struct *hs, struct pti_subsys **ctrl_ss)
 {
-	u32 ret = 0;
 	struct pti_subsys *ss;
 
-	switch(hs->status){
-	case HS_DEV_READY_TXRX:
-		ss = get_ss_from_idx(hs, NETL_CONTROL_SUBSYS);
-		if(ss == NULL){
-			ret = -EFAULT;
-			PDEBUG("HS has no control SS - XXX\n");
-			goto do_nothing;
-		}
-		goto success;
-	case HS_STATUS_NOT_DONE:
-		hs->status = HS_STATUS_PROGRESSING;
-		break;
-	case HS_STATUS_PROGRESSING:
-		goto do_nothing;
-	default:
-		PDEBUG("Inconsistent state during handshake\n");
-		ret = -EBUSY;
-		goto fail;
-	}
 	ss = init_one_subsys(hs, NETL_CONTROL_SUBSYS);
 	if(ss == NULL){
-		ret = -EFAULT;
-		goto fail;
+		return -EFAULT;
 	}
-success:
 	if(ctrl_ss != NULL){
 		*ctrl_ss = ss;
 	}
 	return 0;
-
-do_nothing:
-	return ret;
-fail:
-	hs->status = HS_STATUS_NOT_DONE;
-	return ret;
 }
+#endif
 
 /*
  * Allocate and initialize handshake structure
  */
 int host_specific_hs_init(struct handshake_struct *hs)
 {
-	hs->params.max_subsys = NETL_MAX_SUBSYS;
-	hs->params.nr_desc = NETL_NR_DESC;
-	hs->params.flags = 0;
+	//hs->params.max_subsys = NETL_MAX_SUBSYS;
+	//hs->params.nr_desc = NETL_NR_DESC;
+	//hs->params.flags = 0;
 
 	hs->status = HS_STATUS_NOT_DONE;
 	INIT_LIST_HEAD(&hs->dhead);	/* device list */
@@ -301,60 +279,12 @@ int host_specific_hs_init(struct handshake_struct *hs)
 
 	/* host cmd/stat [0/4]
 	 * dev cmd/stat [8/0xc] */
-	hs->wcmd = (volatile u32 *)
-		((u8 *)hs->start + PTI_ADDR_OFFSET + HCMD0_OFFSET);
-	hs->rstat = (volatile u32 *)
-		((u8 *)hs->start + PTI_ADDR_OFFSET + HSTAT0_OFFSET);
-	hs->rcmd = (volatile u32 *)
-		((u8 *)hs->start + PTI_ADDR_OFFSET + DCMD0_OFFSET);
-	hs->wstat = (volatile u32 *)
-		((u8 *)hs->start + PTI_ADDR_OFFSET + DSTAT0_OFFSET);
 	INIT_DELAYED_WORK(&hs->temp_int_work, temp_int_func);
-	INIT_DELAYED_WORK(&hs->hs_work, hs_work_func);
 	tasklet_init(&hs->hs_stask, hs_task_func, (long unsigned int)hs);
-	dump_hs(NULL, hs);
 	PDEBUG("HS initialization success\n");
 	return 0;
 }
 
-/*
- * Device waiting for handshake inputs. Supply them
- * Write u32 values one by one with a header and footer.
- * When footer is modified from HOST to DEV signature, handshake is complete
- */
-int init_device(struct handshake_struct *hs, int blocking)
-{
-	u32 idx= 0;
-	volatile u32 *pos = hs->wcmd + 1;
-	u32 readval;
-	u32 param_array[NETL_HS_MAX_PARAMS] = {
-		NETL_HOST_SIGNATURE,
-		hs->params.max_subsys,
-		hs->params.flags,
-		hs->params.nr_desc,
-		NETL_HOST_SIGNATURE,
-	};
-
-	//PDEBUG("max_subsys = %#x, flags = %#x, nr_desc= %#x\n", hs->params.max_subsys, hs->params.flags, hs->params.nr_desc);
-	/* check the end offset. If it is set, something is wrong */
-	readval = pti_pci_read32((void *)(hs->wcmd + (NETL_HS_MAX_PARAMS - 1)));
-	if(readval == NETL_DEV_SIGNATURE){
-		/* something wrong. Cannot proceed */
-		return -EFAULT;
-	}
-	/* write params to pci space */
-	for(idx = 1; idx < NETL_HS_MAX_PARAMS; idx++){
-		pti_pci_write32(param_array[idx], (void *)pos);
-		pos++;
-	}
-	/* Now write the signature */
-	pti_pci_write32(NETL_HOST_SIGNATURE, (void *)hs->wcmd);
-	/* We dont read the values back for handshake.
-	 * TODO
-	 * An interrupt be generated when device is fully initialized */
-	return 0;
-}
-
 void __iomem *iomem_start = NULL;
 
 /*
@@ -590,7 +520,7 @@ void subsys_poll_tx(struct pti_subsys *ss)
 	txr = ss->txring;
 	spin_lock_irqsave(&txr->rng_lock, fl_rng);
 	tail = pti_pci_read32((void *)txr->tail);
-	loops = (ss->hs->params.nr_desc + tail - txr->end) % ss->hs->params.nr_desc;
+	loops = (NETL_NR_DESC + tail - txr->end) % NETL_NR_DESC;
 	/* We loop from txr->end (incl) to tail (excl). As a result, at the end
 	 * of the loop, we would have freed all buffers with DMA complete and
 	 * reach
@@ -649,7 +579,7 @@ void subsys_poll_tx(struct pti_subsys *ss)
 	//PDEBUG("Wake up process\n");
 	wake_up_interruptible(&ss->wrq);
 	tail = pti_pci_read32((void *)txr->tail);
-	loops = (ss->hs->params.nr_desc + tail - txr->end) % ss->hs->params.nr_desc;
+	loops = (NETL_NR_DESC + tail - txr->end) % NETL_NR_DESC;
 	if(loops > 0){
 		tasklet_schedule(&ss->hs->hs_stask);
 	}
@@ -670,15 +600,14 @@ static void subsys_poll_rx(struct pti_subsys *ss)
 	rxr = ss->rxring;
 	spin_lock_irqsave(&rxr->rng_lock, fl_rng);
 	head = pti_pci_read32((void *)rxr->head);
-	loops = (ss->hs->params.nr_desc + head - rxr->start) % ss->hs->params.nr_desc;
+	loops = (NETL_NR_DESC + head - rxr->start) % NETL_NR_DESC;
 	//PDEBUG("LOOPS = %d, HEAD = %#x, START = %#x\n", loops, head, rxr->start);
 	while(loops--){
 		//PDEBUG("loops = %d, head = %#x, start = %#x\n", loops, head, rxr->start);
 		BUG_ON(head == rxr->start);
 		dma_stat = pti_pci_read32((void *)&rxr->pdesc[rxr->start].pci_desc->dma_stat);
 		if(dma_stat == 0xFFFFFFFF){
-			PDEBUG("PCI read fail %llx\n",
-				(void *)&rxr->pdesc[rxr->start].pci_desc->dma_stat);
+//			PDEBUG("PCI read fail %llx\n", (void *)&rxr->pdesc[rxr->start].pci_desc->dma_stat);
 			spin_unlock_irqrestore(&rxr->rng_lock, fl_rng);
 			return;
 		}
@@ -703,7 +632,7 @@ static void subsys_poll_rx(struct pti_subsys *ss)
 	ss->flags &= ~SUBSYS_FLAGS_RX_PENDING;
 	spin_unlock_irqrestore(&ss->slock, fl_rng);
 	head = pti_pci_read32((void *)rxr->head);
-	loops = (ss->hs->params.nr_desc + head - rxr->start) % ss->hs->params.nr_desc;
+	loops = (NETL_NR_DESC + head - rxr->start) % NETL_NR_DESC;
 	if(loops > 0){
 		tasklet_schedule(&ss->hs->hs_stask);
 	}
@@ -729,8 +658,24 @@ void temp_int_func(struct work_struct *work)
  */
 int setup_host_irq(struct handshake_struct *hs)
 {
+	__label__ setup_linex, setup_msi;
 	int ret;
 
+	hs->msix.entry = 0;
+	ret = pci_enable_msix(hs->p_dev, &hs->msix, 1);
+	if (ret < 0) {
+		PDEBUG("NO MSI-X support. Trying MSI\n");
+		goto setup_msi;
+	}
+	hs->msi_flag = NETL_MSIX_ENABLE;
+	ret = request_irq(hs->msix.vector, host_msi_handler, 0, NETL_DRIVER, hs);
+	if (ret) {
+		PERROR("MSI-X request_irq failed for %#x\n", hs->msix.vector);
+		pci_disable_msix(hs->p_dev);
+		return ret;
+	}
+	return 0;
+setup_msi:
 	ret = pci_enable_msi(hs->p_dev);
 	if(ret < 0){
 		PDEBUG("No MSI. Falling back to INTX\n");
@@ -739,6 +684,7 @@ int setup_host_irq(struct handshake_struct *hs)
 	ret = request_irq(hs->p_dev->irq, host_msi_handler, 0, NETL_DRIVER, hs);
 	if(ret){
 		PERROR("MSI request_irq failed for %#x\n", hs->p_dev->irq);
+		pci_disable_msi(hs->p_dev);
 		return ret;
 	}
 	hs->msi_flag = NETL_MSI_ENABLE;
@@ -746,7 +692,7 @@ int setup_host_irq(struct handshake_struct *hs)
 setup_linex:
 	ret = request_irq(hs->p_dev->irq, host_msi_handler, 0, NETL_DRIVER, hs);
 	if(ret){
-		PERROR("LINEX request_irq failed for %#x\n", hs->p_dev->irq);
+		PERROR("LINE-X request_irq failed for %#x\n", hs->p_dev->irq);
 		return ret;
 	}
 	hs->msi_flag = NETL_INTX_ENABLE;
@@ -774,6 +720,7 @@ static int netl_phnx_generic_probe(struct pci_dev *pdev, const struct pci_device
 	struct handshake_struct *hs = NULL;
 
 	hs = kzalloc(sizeof(struct handshake_struct), GFP_KERNEL);
+	PDEBUG("ALLOCATED HS = %p\n", hs);
 	if(!hs){
 		return -ENOMEM;
 	}
@@ -799,8 +746,7 @@ static int netl_phnx_generic_probe(struct pci_dev *pdev, const struct pci_device
 		goto resource_err;
 	}
 	iomem_start = ioremap_nocache(base, pci_resource_len(pdev, 0));
-	*((u32 *)iomem_start) = 0x2badf00d;
-	hs->start = (volatile void *)iomem_start;
+	hs->start = (volatile void *)iomem_start + PTI_ADDR_OFFSET;
 	pci_set_drvdata(pdev, (void *)hs);
 	if(hs->start == NULL){
 		PERROR("IOREMAP failed on resource in BAR\n");
@@ -826,13 +772,7 @@ static int netl_phnx_generic_probe(struct pci_dev *pdev, const struct pci_device
 		goto pci_en_fail;
 	}
 	pci_set_master(pdev);
-	/* Setup host side control subsys now */
-	start_host_control_subsys(hs, NULL);
-	err = init_device(hs, 0);
-	if(err != 0){
-		goto pci_en_fail;
-	}
-	schedule_delayed_work(&hs->hs_work, HZ/100);
+	schedule_delayed_work(&hs->hs_work, HZ);
 	return err;
 
 pci_en_fail:
@@ -882,9 +822,9 @@ void netl_rm_dev(struct handshake_struct *p)
 	return;
 }
 
-#ifdef NETL_PTI_TEST
-int get_hs_from_idx(struct handshake_struct **res, int idx)
+int get_hs(struct handshake_struct **res)
 {
+	int idx = 0;
 	struct handshake_struct *cur, *n;
 
 	list_for_each_entry_safe(cur, n, &dev_list->head, dhead){
@@ -895,8 +835,7 @@ int get_hs_from_idx(struct handshake_struct **res, int idx)
 	}
 	return -ENODEV;
 }
-EXPORT_SYMBOL(get_hs_from_idx);
-#endif
+EXPORT_SYMBOL(get_hs);
 
 void __exit netl_pti_host_uninit(void)
 {
diff --git a/drivers/misc/netlogic/pcie-offload/include/netl_pti.h b/drivers/misc/netlogic/pcie-offload/include/netl_pti.h
index 4e3d9f9..95eee63 100644
--- a/drivers/misc/netlogic/pcie-offload/include/netl_pti.h
+++ b/drivers/misc/netlogic/pcie-offload/include/netl_pti.h
@@ -5,8 +5,8 @@
 #define NETL_CONTROL_SUBSYS		0
 #define NETL_DEF_MAX_SUBSYS		8
 #define NETL_BUFSIZE			4096	/*__MUST__ BE PAGE_SIZE */
-#define	NETL_NR_DESC		0x400
-#define NETL_MAX_SUBSYS		0x4
+#define	NETL_NR_DESC			0x400
+#define NETL_MAX_SUBSYS			0x8
 
 #ifdef __KERNEL__
 #include <linux/types.h>
@@ -32,10 +32,7 @@
 
 #ifdef NETL_PTI_DEVICE
 
-#ifndef CONFIG_NLM_XLP
-#define XLR_PCI_HOST_MODE 0x1
-#define XLR_PCI_DEV_MODE 0x2
-#else
+#ifdef CONFIG_NLM_XLP
 #include <asm/netlogic/iomap.h>
 #include <asm/netlogic/cpumask.h>
 #include <asm/netlogic/msgring.h>
@@ -44,26 +41,20 @@
 #include <hal/nlm_hal_macros.h>
 #include <hal/nlm_hal_fmn.h>
 #include <hal/nlm_hal_xlp_dev.h>
-#include <nlm_pcie.h>
 #endif	// CONFIG_NLM_XLP
 
 #endif	// NETL_PTI_DEVICE
 
 #define PTI_ADDR_OFFSET (unsigned long)0x00100000
 
-#ifndef CONFIG_NLM_XLP	// kludge, replace with fdebug
 #define DPRINTK(level,fmt,args...)\
 do{\
 	printk(level "%s()@%s:%d " fmt,__func__, __FILE__, __LINE__, ##args);\
 }while(0)
+#ifndef CONFIG_NLM_XLP	// kludge, replace with fdebug
+#define fdebug(fmt, args...) DPRINTK(KERN_DEBUG, fmt, ##args)
 #endif
-
-#ifdef NETL_PTI_DEBUG
 #define PDEBUG(fmt, args...) DPRINTK(KERN_DEBUG, fmt, ##args)
-#else
-#define PDEBUG(fmt, args...)
-#endif
-
 #define PWARN(fmt, args...)\
 	DPRINTK(KERN_WARNING, fmt, ##args)
 #define PERROR(fmt, args...)\
@@ -75,8 +66,15 @@ do{\
 #define NETL_HOST_SIGNATURE		0x4e45544c	/* NETL */
 #define NETL_DEV_SIGNATURE		0x4e444556	/* NDEV */
 
+extern void raise_host_interrupt(int vec);
+extern int xlp_async_request_dma(uint64_t src, uint64_t dest, uint32_t len,
+			void (*func)(void *,uint64_t),void *data,
+			enum dma_data_direction dir);
+extern u64 setup_pcie_shared_memspace(u64 * len);
+
 struct descriptor;
 struct pti_subsys;
+#define NETL_HS_PARAMSPACE	0x20
 
 #define _pti_pci
 struct _desc_pci{
@@ -162,6 +160,10 @@ struct rx_struct{
  _x = ((_x + 1) % NETL_NR_DESC);\
  _x;\
 })
+extern int send_one_packet_to_device(struct pti_subsys *, unsigned long , u32);
+extern int send_one_packet_to_host(struct pti_subsys *, unsigned long , u32);
+extern struct pti_subsys *reserve_subsystem(int);
+int get_hs(struct handshake_struct **);
 
 // #define NETL_MAX_MSG_RETRIES		8
 enum hshake_cmd{
@@ -171,31 +173,22 @@ enum hshake_cmd{
 	HS_STATUS_COMPLETE,
 	HS_DEV_EXITING,
 };
-#define NETL_HS_MAX_PARAMS	5
-struct hs_params{
-	u32 max_subsys;
-	u32 flags;
-	u32 nr_desc;
-};
 
+#define NETL_LINK_TIMER_INTERVAL	100
 struct handshake_struct{
-	volatile u32 *rcmd;	/* read commands from here */
-	volatile u32 *wstat;	/* write status here */
-	volatile u32 *wcmd;	/* read commands from here */
-	volatile u32 *rstat;	/* write status here */
-	volatile void *start;			/* PCI space start */
-	struct hs_params params;	/* host<->device params */
+	volatile void *start;		/* PCI Shared mem space start */
 	int status;
 	wait_queue_head_t openq;	/* blocking open wait queue */
 	spinlock_t hs_lock;
 	struct cdev hs_cdev;
 	struct dentry *dbg_root;
 	struct semaphore hhsem;
+	struct timer_list link_timer;
 	struct hlist_head *hhash;/* Array of NETL_SUBSYS_HASH hlist_heads */
 	volatile u64 rxpending;		/* bits corresponding to rxpending subsys */
 	volatile u64 txpending;		/* bits corresponding to txpending subsys */
-	struct delayed_work hs_work;	/* work queue for polling handshake */
 	struct delayed_work temp_int_work;	/* remove later */
+	struct delayed_work hs_work;		/* handshake thread */
 	struct tasklet_struct hs_stask;
 	unsigned long pci_len;		/* PCI space length */
 #ifdef NETL_PTI_HOST
@@ -204,16 +197,14 @@ struct handshake_struct{
 	struct list_head dhead;		/* linked to dev_list */
 	struct pci_dev *p_dev;
 	unsigned int msi_flag;		/* MSI, MSIX or INTX */
+#ifdef CONFIG_PCI_MSI
+	struct msix_entry msix;		/* only one MSI-X entry */
+#endif
 #endif
+	struct pti_subsys *ss[NETL_MAX_SUBSYS];
 };
 
 /* Offsets from top of the memory + PTI_ADDR_OFFSET */
-#define HCMD0_OFFSET		0x00
-#define HSTAT0_OFFSET		0X04
-#define END_HCMDSTAT		0X08
-#define DCMD0_OFFSET		0X08
-#define DSTAT0_OFFSET		0X0C
-#define END_DCMDSTAT		0x10
 #define NETL_DBG_ROOT		"netl"
 #define NETL_DBG_FNAME_LEN	0x10
 #define NETL_SUBSYS_HASH	512	/* Number of hash buckets */
diff --git a/drivers/misc/netlogic/pcie-offload/include/netl_pti_char.c b/drivers/misc/netlogic/pcie-offload/include/netl_pti_char.c
index 66db6af..d381b48 100644
--- a/drivers/misc/netlogic/pcie-offload/include/netl_pti_char.c
+++ b/drivers/misc/netlogic/pcie-offload/include/netl_pti_char.c
@@ -309,7 +309,7 @@ void host_flush_dma_pages(struct pti_subsys *ss)
 
 	rxr = ss->rxring;
 	spin_lock_irqsave(&rxr->rng_lock, fl_rng);
-	loops = ss->hs->params.nr_desc;
+	loops = NETL_NR_DESC;
 	while(loops--){
 		dma_stat = pti_pci_read32((void *)&rxr->pdesc[loops].pci_desc->dma_stat);
 		if(is_dma_set(dma_stat)){
@@ -427,7 +427,7 @@ int netl_register_chrdev(struct handshake_struct *hs)
 {
 	dev_t devid;
 	int rc;
-	int max_subsys = hs->params.max_subsys;
+	int max_subsys = NETL_MAX_SUBSYS;
 
 	if(major){
 		devid = MKDEV(major, 0);
@@ -454,7 +454,7 @@ int netl_register_chrdev(struct handshake_struct *hs)
 void netl_unregister_chrdev(struct handshake_struct *hs)
 {
 	dev_t devid = MKDEV(major, 0);
-	int max_subsys = hs->params.max_subsys;
+	int max_subsys = NETL_MAX_SUBSYS;
 
 	cdev_del(&hs->hs_cdev);
 	unregister_chrdev_region(devid, max_subsys);
diff --git a/drivers/misc/netlogic/pcie-offload/include/netl_pti_common.c b/drivers/misc/netlogic/pcie-offload/include/netl_pti_common.c
index f03ccfa..40937ba 100644
--- a/drivers/misc/netlogic/pcie-offload/include/netl_pti_common.c
+++ b/drivers/misc/netlogic/pcie-offload/include/netl_pti_common.c
@@ -7,7 +7,6 @@ struct pti_subsys *init_one_subsys(struct handshake_struct *hs, int id);
 static void dealloc_desc_ring(struct desc_ring *ring, int type);
 static int init_desc_ring(struct pti_subsys *ss, struct desc_ring *ring, int type);
 int add_to_rxlist(struct pti_subsys *ss, volatile struct kvec *iov);
-int get_packet_from_rxlist(struct pti_subsys *ss, struct rx_struct **ret);
 static int netl_dbg_open(struct inode *inode, struct file *filp);
 int netl_pti_debugfs_init(struct handshake_struct *hs);
 int init_handshake_struct(struct handshake_struct *hs);
@@ -18,8 +17,8 @@ void dealloc_all_subsys(struct handshake_struct *hs);
 void dealloc_this_subsystem(struct pti_subsys *ss);
 void copy_desc_pci(volatile struct _desc_pci *new, volatile struct _desc_pci *orig);
 void hs_clear_cmd(struct handshake_struct *hs, u32 sval);
+void hs_work_func(struct work_struct *);
 
-void dump_hs(struct seq_file *seq, struct handshake_struct *hs);
 void dump_subsystem(struct seq_file *seq, struct pti_subsys *ss, int txr, int rxr);
 void dump_desc_ring(struct seq_file *seq, struct desc_ring *ring, int dump_all);
 void dump_descriptor(struct seq_file *seq, struct descriptor *ptr);
@@ -65,28 +64,24 @@ static int init_desc_ring(struct pti_subsys *ss, struct desc_ring *ring, int typ
 #endif
 
 	// PDEBUG("ss[%#x]->hs = %p, ring = %p\n", ss->id, ss->hs, ring);
-	ring->pdesc = kzalloc(sizeof(struct descriptor) * ss->hs->params.nr_desc, GFP_KERNEL);
+	ring->pdesc = kzalloc(sizeof(struct descriptor) * NETL_NR_DESC, GFP_KERNEL);
 	if(!ring->pdesc){
 		PDEBUG("Failed to allocate pdesc\n");
 		return ENOMEM;
 	}
-	if (ss->hs->params.max_subsys == 0 || ss->hs->params.nr_desc == 0) {
-		PERROR("Fatal failure. Can't allocate 0 bytes\n");
-		return EFAULT;
-	}
 	ring->ss = ss;
 	spin_lock_init(&ring->rng_lock);
 	ring->start = ring->end = 0;
 	ring->head = (volatile u32 *)ss_get_ringcmd_offset(ss,type);
 	ring->tail = ring->head + 1;	/* pointer arithmetic */
-	ring->nfree = ss->hs->params.nr_desc - 1;
+	ring->nfree = NETL_NR_DESC - 1;
 	/* Keeping one slot open. If head == tail, empty.
 	 * if tail == head + 1, full */
 #ifdef NETL_PTI_HOST
 	pti_pci_write32(0, (void *)ring->head);
 	pti_pci_write32(0, (void *)ring->tail);
 #endif
-	for(count = 0; count < ss->hs->params.nr_desc; count++){
+	for(count = 0; count < NETL_NR_DESC; count++){
 		ptr = &ring->pdesc[count];
 		ptr->idx = count;
 		ptr->pring = ring;
@@ -300,17 +295,11 @@ ring_fail:
 volatile u8 *ss_get_ringcmd_offset(struct pti_subsys *ss, int is_rx)
 {
 	/* calculate size of subsystem here */
-#ifdef NETL_PTI_DEVICE
-	volatile u8 *ret = (volatile u8*)(ss->hs->wcmd + 2);
-#else
-	volatile u8 *ret = (volatile u8*)(ss->hs->wcmd + 4);
-#endif
 	u32 offset;
-	u16 da_size = DESC_ARRAY_SIZE(ss->hs->params.nr_desc);
+	u16 da_size = DESC_ARRAY_SIZE(NETL_NR_DESC);
 
-	offset = ((ss->id * 2 + is_rx) * da_size);
-	ret += offset;
-	return ret;
+	offset = ((ss->id * 2 + is_rx) * da_size) + NETL_HS_PARAMSPACE;
+	return (volatile u8 *) (ss->hs->start + offset);
 }
 
 /*
@@ -338,26 +327,6 @@ do{\
 		printk(fmt, ##args);\
 }while(0)
 
-void dump_hs(struct seq_file *seq, struct handshake_struct *hs)
-{
-	netl_print(seq, "rcmd = %p, val = %#x\n",
-			hs->rcmd, pti_pci_read32((void*)hs->rcmd));
-	netl_print(seq, "wcmd = %p, val = %#x\n",
-			hs->wcmd, pti_pci_read32((void*)hs->wcmd));
-	netl_print(seq, "wstat = %p, val = %#x\n",
-			hs->wstat, pti_pci_read32((void*)hs->wstat));
-	netl_print(seq, "rstat = %p, val = %#x\n",
-			hs->rstat, pti_pci_read32((void*)hs->rstat));
-	netl_print(seq, "params.max_subsys = %#x\n", hs->params.max_subsys);
-	netl_print(seq, "params.flags = %#x\n", hs->params.flags);
-	netl_print(seq, "params.nr_desc = %#x\n", hs->params.nr_desc);
-	netl_print(seq, "status = %#x\n", hs->status);
-#ifdef NETL_PTI_HOST
-	netl_print(seq, "dev_list = %p\n", hs->dev_list);
-#endif
-	return;
-}
-
 void dump_subsystem(struct seq_file *seq, struct pti_subsys *ss, int txr, int rxr)
 {
 	netl_print(seq, "id = %#x\n", ss->id);
@@ -390,7 +359,7 @@ void dump_desc_ring(struct seq_file *seq, struct desc_ring *ring, int dump_all)
 	netl_print(seq, "\tend = %#x\n", ring->end);
 	netl_print(seq, "\tss = %p\n", ring->ss);
 	if(dump_all){
-		for(i = 0; i < ring->ss->hs->params.nr_desc; i++){
+		for(i = 0; i < NETL_NR_DESC; i++){
 			dump_descriptor(seq, &ring->pdesc[i]);
 			netl_print(seq, "\n");
 		}
@@ -473,6 +442,7 @@ struct rx_struct *__dequeue_msg(struct pti_subsys *ss, u32 msgid, int match)
 			}
 		}
 	}
+	PDEBUG("\n");
 	return NULL;
 }
 
@@ -543,22 +513,19 @@ fnfail:
 }
 
 /*
- * Gets an rx_struct from list -- control path only
+ * Gets an rx_struct from list -- control and n/w path only
  */
 int get_packet_from_rxlist(struct pti_subsys *ss, struct rx_struct **ret)
 {
 	unsigned long flags;
 
-//	PDEBUG("Getting sem\n");
 	spin_lock_irqsave(&ss->rxlock, flags);
 	if(list_empty(&ss->rx_head)){
 		BUG_ON(ss->rnum != 0);
 		spin_unlock_irqrestore(&ss->rxlock, flags);
-//		PDEBUG("List empty\n");
 		return -EAGAIN;
 	}
 	*ret = __dequeue_msg(ss, 0, NETL_MSG_ANY);
-//	PDEBUG("remaining %#x elems\n", ss->rnum);
 	spin_unlock_irqrestore(&ss->rxlock, flags);
 	return 0;
 }
@@ -619,7 +586,7 @@ struct pti_subsys *get_ss_from_idx(struct handshake_struct *hs, int idx)
 	struct hlist_head *head;
 	unsigned long flags;
 
-	if(idx > hs->params.max_subsys){
+	if(idx > NETL_MAX_SUBSYS){
 		return NULL;
 	}
 	spin_lock_irqsave(&hs->hs_lock, flags);
@@ -658,7 +625,7 @@ void stop_subsystem(struct pti_subsys *ss)
 	r = ss->rxring;
 	spin_lock_irqsave(&r->rng_lock, flags);
 	r->end = r->start = pti_pci_read32((void *)r->head);
-	for(count = 0; count < ss->hs->params.nr_desc; count++){
+	for(count = 0; count < NETL_NR_DESC; count++){
 		pti_pci_write32(0, (void *)&r->pdesc[count].pci_desc->dma_stat);
 	}
 	pti_pci_write32(r->start, (void *)r->tail);
@@ -667,7 +634,7 @@ void stop_subsystem(struct pti_subsys *ss)
 	r = ss->txring;
 	spin_lock_irqsave(&r->rng_lock, flags);
 	r->end = r->start = pti_pci_read32((void *)r->head);
-	for(count = 0; count < ss->hs->params.nr_desc; count++){
+	for(count = 0; count < NETL_NR_DESC; count++){
 		pti_pci_write32(0, (void *)&r->pdesc[count].pci_desc->dma_stat);
 	}
 	pti_pci_write32(r->start, (void *)r->tail);
@@ -707,10 +674,18 @@ int init_handshake_struct(struct handshake_struct *hs)
 		INIT_HLIST_HEAD(&(hs->hhash[i]));
 	}
 	init_MUTEX(&hs->hhsem);
-	/* Common initialization here */
+	INIT_DELAYED_WORK(&hs->hs_work, hs_work_func);
 	if((ret = specific_init(hs)) != 0){
 		kfree(hs->hhash);
 		return ret;
 	}
 	return 0;
 }
+
+struct pti_subsys *reserve_subsystem(int idx)
+{
+	struct handshake_struct *hs;
+	get_hs(&hs);
+	return hs->ss[idx];
+}
+EXPORT_SYMBOL(reserve_subsystem);
diff --git a/drivers/misc/netlogic/pcie-offload/include/nlm_pcie.h b/drivers/misc/netlogic/pcie-offload/include/nlm_pcie.h
deleted file mode 100644
index 2a17a4a..0000000
--- a/drivers/misc/netlogic/pcie-offload/include/nlm_pcie.h
+++ /dev/null
@@ -1,11 +0,0 @@
-#ifndef NLM_PCIE_H
-#define NLM_PCIE_H
-#include <asm/netlogic/nlm_dma.h>
-
-int nlm_common_request_msi_handler(irq_handler_t host_msi_handler, void *data);
-void nlm_common_free_msi_handler(void);
-volatile void *nlm_common_get_shared_mem_base_host(void);
-void nlm_common_interrupt_device(void);
-extern struct pci_dev *nlm_pdev;
-void __exit nlm_pcie_exit(void);
-#endif
diff --git a/drivers/misc/netlogic/pcie-offload/include/nlm_pcieip.h b/drivers/misc/netlogic/pcie-offload/include/nlm_pcieip.h
index ed607dc..bd6643b 100644
--- a/drivers/misc/netlogic/pcie-offload/include/nlm_pcieip.h
+++ b/drivers/misc/netlogic/pcie-offload/include/nlm_pcieip.h
@@ -61,139 +61,31 @@
 #include <asm/netlogic/nlm_dma.h>
 #include <nlm_dma.h>
 #endif
+#include <netl_pti.h>
 
+int pcieip_receive_skbuff(struct sk_buff *skb, void (*func)(void *,uint64_t),void *data);
+int pcieip_send_skbuff(struct sk_buff *skb, void (*func)(void *,uint64_t),void *data);
+extern int get_packet_from_rxlist(struct pti_subsys *ss, struct rx_struct **ret);
 #define DRV_NAME	"nlm_pcieip"
-#define DRV_VERSION	"0.9"
-#define DRV_RELDATE	"8Aug2011"
+#define DRV_VERSION	"0.95"
+#define DRV_RELDATE	"22dec2011"
 
-#define DESC_MAX 128	/* Max descriptors for RX and Tx */
-#define TX_DESC_MAX			DESC_MAX
-#define RX_DESC_MAX			DESC_MAX
-#define NLM_SMP_CACHE_BYTES 32
-
-#define PCIEIP_MAX_RXLEN 1536
-#define PCIEIP_MAGIC	0xdeadbeef
-
-struct xlp_desc{
-	u64 addr;
-	u32 info;/*  Bit 0 to 15 LEN, Bit 16 to 30 Reserved, Bit 31 OWN */
-}__attribute__((packed));
-
-#define DMA_BIT		(1 << 31)
-#define GET_DMA_READY(x) ((x) & DMA_BIT)
-#define CLEAR_DMA_READY(x) ((x) = ((x) & ~DMA_BIT))
-#define SET_DMA_READY(x) ((x) = (x) | DMA_BIT)
-#define GET_LEN(x) ((x) & 0x3fff)
-#define SET_LEN(x,len) (x) = (((x)->info & ~(0x3fff)); (x) |= len)
-#define NLM_PCIE_IP_OFFSET	(1 * 512 * 1024)
-
-#define PCIEIP_FLAG_MSI_ENABLED		0x1
+#define NLM_SMP_CACHE_BYTES		32
+#define PCIEIP_MAX_RXLEN		1536
+#define PCIEIP_FLAG_MSI_ENABLED		(0x1 << 0)
+#define PCIEIP_FLAG_EXITING		(0x1 << 2)
 #define PCIEIP_SKB_ALLOC_SIZE		(1536 + 32 + 32)
-#define PCIEIP_IF_UP			(0x1 << 0)
-#define PCIEIP_IF_DOWN			(0x1 << 1)
-#define PCIEIP_DESC_RX_CLEAR		(0x1 << 2)
-#define PCIEIP_DESC_TX_CLEAR		(0x1 << 3)
-
-struct debug_ctrs {
-	int rx_pkt;
-	int tx_pkt;
-	int tx_q;
-	int rx_q;
-	int rx_dma;
-	int tx_dma;
-};
-
-struct skb_free_info {
-	struct sk_buff *skb;
-        dma_addr_t paddr;
-        int len;
-	int idx;
-	struct driver_data *priv;
-};
-
-#define INCR_CEIL(x)\
-({typeof(x) _x = (x);\
- _x = ((_x + 1) % DESC_MAX);\
- _x;\
-})
-
-#define nlm_pci_readl(s)\
-({\
-	readl((void*)s);\
-})
-
-#define nlm_pci_writel(v,d)\
-({\
-	writel(((u32)v), (void *)d);\
- 	mb();\
-})
-
-#define nlm_pci_readq(s)\
-({\
-	readq((void*)s);\
-})
-
-#define nlm_pci_writeq(v,d)\
-({\
-	writeq(((u64)v), (void *)d);\
- 	mb();\
-})
-
-#define NETL_VENDOR_ID 0x184e
-#define NETL_DEVICE_ID 0x1004
-#define	PCIEIP_LINK_TIMER_INTERVAL	(1)
-#define PCIEIP_MAX_LOOPS	16	/* Max # of Rx or Tx loops with spin lock held */
-
+#define PCIEIP_PTI_SUBSYS		1
+#define PCIEIP_MIN_RXLEN		(20)
 struct driver_data {
 	struct net_device *ndev;
-	struct pci_dev *pdev;
-	volatile void *base;	/* base of pci memory */
-	struct xlp_desc *tx_base;
-	int xhead, xtail;
-	struct skb_free_info tx_q[TX_DESC_MAX];
-	struct xlp_desc *rx_base;
-	struct skb_free_info rx_q[RX_DESC_MAX];
-	volatile u32 *th_stat, *my_stat, *magic;/* status : my and their */
-	int rhead, rtail;
 	spinlock_t lock;
 	struct net_device_stats stats;
-	struct timer_list link_timer;
 	struct delayed_work poll_work;
-	struct msix_entry *msix;
-	u32 flags;	/* MSI/MSIX, status ..etc */
 	struct dentry *dbgf;
 	u32 poll_delay;
-};	/* Not shared between host and device */
-
-#define nlm_printk(seq,fmt,args...)\
-do{\
-	if(seq != NULL)\
-		seq_printf(seq, fmt, ##args);\
-	else\
-		printk(fmt, ##args);\
-}while(0)
-
-inline static void dump_one_desc(struct seq_file *s, struct xlp_desc *d, int i, char *prefix)
-{
-	nlm_printk(s, "%s %d: addr = %#llx, info = %#x\n", prefix, i, (u64)readq(&(d->addr)), readl(&(d->info)));
-}
-inline static void dump_all_desc(struct seq_file *s, struct driver_data *priv)
-{
-	int i;
-	nlm_printk(s, "rx_base = 0x%p, tx_base = 0x%p\n", priv->rx_base, priv->tx_base);
-	nlm_printk(s, "xhead = %d, xtail = %d\n", priv->xhead, priv->xtail);
-	nlm_printk(s, "rhead = %d, rtail = %d\n", priv->rhead, priv->rtail);
-	for (i = 0; i < DESC_MAX; i++) {
-		dump_one_desc(s, priv->tx_base + i, i, "TX:");
-	}
-	for (i = 0; i < DESC_MAX; i++) {
-		dump_one_desc(s, priv->rx_base + i, i, "RX:");
-	}
-}
-#ifdef CONFIG_NLM_PCIEIP_DEV
-/* Device specific functions goes here */
-
-
-#endif
+	struct pti_subsys *ss;
+	u32 flags;
+};
 
 #endif	// NLM_PCIEIP_H
diff --git a/drivers/misc/netlogic/pcie-offload/net/device/Kbuild b/drivers/misc/netlogic/pcie-offload/net/device/Kbuild
index d3b34b9..56f6efd 100644
--- a/drivers/misc/netlogic/pcie-offload/net/device/Kbuild
+++ b/drivers/misc/netlogic/pcie-offload/net/device/Kbuild
@@ -1,5 +1,5 @@
 EXTRA_CFLAGS := -DNLM_HAL_LINUX_KERNEL	-I$(src)/../../include -DCONFIG_NLM_PCIEIP_DEV
 # EXTRA_CFLAGS += -DCONFIG_HOST_NOIRQ
 
-obj-m += pcieipdev.o
-pcieipdev-y := pcieip_common.o pcieip_dev.o
+obj-m += pcieip.o
+pcieip-y := pcieip_common.o
diff --git a/drivers/misc/netlogic/pcie-offload/net/device/pcieip_common.c b/drivers/misc/netlogic/pcie-offload/net/device/pcieip_common.c
index 20e6ba6..ee85491 100644
--- a/drivers/misc/netlogic/pcie-offload/net/device/pcieip_common.c
+++ b/drivers/misc/netlogic/pcie-offload/net/device/pcieip_common.c
@@ -24,49 +24,18 @@ THE POSSIBILITY OF SUCH DAMAGE.
 *****************************#NETL_2#********************************/
 #include <nlm_pcieip.h>
 
-void free_all_desc(struct net_device *ndev, u32 rxtx);
-void setup_shared_mem(struct driver_data *priv);
 void put_dummy_mac_address(struct net_device *dev);
-extern int pcieip_fillup_rxbuf(struct net_device *ndev);
+int process_rx_dev(struct driver_data *priv);
 irqreturn_t ip_over_pci_rx (int unused, void *data);
-
+int pcieip_start_xmit(struct sk_buff *skb,struct net_device *ndev);
 static int poll_delay = 0;
 module_param(poll_delay, int, 0);
 MODULE_PARM_DESC(poll_delay, "Delay in jiffies between status polls\n");
 
-#ifdef CONFIG_NLM_PCIEIP_HOST
-extern int pcieip_start_xmit(struct sk_buff *skb,struct net_device *ndev);
-extern int pcieip_request_irq(irq_handler_t host_handler, struct net_device *ndev);
-extern irqreturn_t irq_handler(int unused, void *data);
-#else
-extern int pcieip_start_xmit_dev(struct sk_buff *skb,struct net_device *ndev);
+#ifndef CONFIG_NLM_PCIEIP_HOST
+extern int xlp_ctrl_fn_from_dev(const struct pci_dev *);
 #endif
-
-/*
- * Can be used as a show routine on debugfs
- *
- * @seq		: seq file to output
- * @v		: driver_data
- */
-static int netl_dbg_show(struct seq_file *seq, void *v)
-{
-	struct driver_data *priv = (struct driver_data *) seq->private;
-	dump_all_desc(seq, priv);
-	return 0;
-}
-
-static int netl_dbg_open(struct inode *inode, struct file *filp)
-{
-	return single_open(filp, netl_dbg_show, inode->i_private);
-}
-
-static struct file_operations netl_dbg_fops = {
-	.owner = THIS_MODULE,
-	.open = netl_dbg_open,
-	.llseek = seq_lseek,
-	.read = seq_read,
-	.release = single_release,
-};
+struct net_device *gndev;
 
 /*
  * Device specific allocation routine
@@ -78,13 +47,12 @@ struct sk_buff *pcieip_alloc_skb(u32 size, u32 flags)
 {
 	struct sk_buff *skb;
 	unsigned long offset;
-	unsigned char *tmp_addr;
+
 	skb = dev_alloc_skb(size);
 	if(!skb){
 		fdebug("SKB Allocation Failed");
 		return NULL;
 	}
-	tmp_addr = skb->data;
 	offset = ((u64)skb->data + NLM_SMP_CACHE_BYTES) &
 			~(NLM_SMP_CACHE_BYTES - 1);
 	skb_reserve(skb,NLM_SMP_CACHE_BYTES + 2);
@@ -92,25 +60,14 @@ struct sk_buff *pcieip_alloc_skb(u32 size, u32 flags)
 	return skb;
 }
 
-/*
- * This is slightly tricky
- * On a device, since there are no interrupts from host, this function always
- * poll for Rx (ip_over_pci_rx on device) and reschedules itself
- * On the host, ip_over_pci_rx is called only if CONFIG_HOST_NOIRQ is defined,
- * but the implementation calls tx_done_host _and_ process_rx_host and then
- * reschedules itself
- *
- * @w		: workqueue structure
- */
 void temp_int_func(struct work_struct *w)
 {
 	struct driver_data *priv = container_of(w, struct driver_data, poll_work.work);
-	ip_over_pci_rx(0, (void *)priv);
-#if 0
-#if defined(CONFIG_NLM_PCIEIP_DEV) || defined(CONFIG_HOST_NOIRQ)
+	process_rx_dev(priv);
+	if (unlikely(priv->flags & PCIEIP_FLAG_EXITING)) {
+		return;
+	}
 	schedule_delayed_work(&priv->poll_work, priv->poll_delay);
-#endif
-#endif
 }
 
 /*
@@ -118,10 +75,7 @@ void temp_int_func(struct work_struct *w)
  */
 static int pcieip_open(struct net_device *dev)
 {
-	struct driver_data *priv;
-	priv = netdev_priv(dev);
-
-	nlm_pci_writel(PCIEIP_IF_UP, priv->my_stat);
+	netif_start_queue(dev);
 	return 0;
 }
 
@@ -130,9 +84,7 @@ static int pcieip_open(struct net_device *dev)
  */
 static int pcieip_stop(struct net_device *dev)
 {
-	struct driver_data *priv = netdev_priv(dev);
-
-	nlm_pci_writel(PCIEIP_IF_DOWN, priv->my_stat);
+	netif_stop_queue(dev);
 	return 0;
 }
 
@@ -141,36 +93,6 @@ static struct net_device_stats* pcieip_get_stats(struct net_device *dev)
 	return &(((struct driver_data *)(netdev_priv(dev)))->stats);
 }
 
-/*
- * Link status check
- *
- * @data		: net_device structure
- */
-static void pcieip_link_status(unsigned long data)
-{
-	struct net_device *ndev = (struct net_device *)data;
-	struct driver_data *priv = netdev_priv(ndev);
-	u32 my_stat = 0, th_stat = 0;
-
-	my_stat = nlm_pci_readl(priv->my_stat);
-	th_stat = nlm_pci_readl(priv->th_stat);
-	if (th_stat == PCIEIP_IF_UP &&
-			my_stat == PCIEIP_IF_UP) {
-		if(netif_queue_stopped(ndev)) {
-			netif_start_queue(ndev);
-		}
-#if defined(CONFIG_NLM_PCIEIP_DEV) || defined(CONFIG_HOST_NOIRQ)
-		/* Only for Device. For host, only if no irq support */
-		schedule_delayed_work(&priv->poll_work, priv->poll_delay);
-		//dump_all_desc(priv);
-#endif
-	}else if(!netif_queue_stopped(ndev)){
-		netif_stop_queue(ndev);
-	}
-	/* Link timer should always be active */
-	mod_timer(&priv->link_timer, jiffies + PCIEIP_LINK_TIMER_INTERVAL);
-}
-
 struct net_device_ops nlm_ops;
 
 /*
@@ -181,11 +103,7 @@ static void setup_net_ops(struct net_device *dev)
 	nlm_ops.ndo_open = pcieip_open;
 	nlm_ops.ndo_stop = pcieip_stop;
 	nlm_ops.ndo_get_stats = pcieip_get_stats;
-#ifdef CONFIG_NLM_PCIEIP_HOST
 	nlm_ops.ndo_start_xmit = pcieip_start_xmit;
-#else
-	nlm_ops.ndo_start_xmit = pcieip_start_xmit_dev;
-#endif
 	dev->netdev_ops = &nlm_ops;
 	dev->flags |= IFF_NOARP;
 	dev->features |= NETIF_F_NO_CSUM;
@@ -199,79 +117,156 @@ static void setup_net_ops(struct net_device *dev)
  */
 int pcieip_init(struct pci_dev *pdev, volatile void *start)
 {
-#ifdef CONFIG_NLM_PCIEIP_HOST
-	__label__ fail_replenish;
-#endif
 	__label__ fail_register;
-
 	struct net_device *ndev = 0;
 	struct driver_data *priv = 0;
 	int ret = 0;
 
-	ndev = alloc_etherdev(sizeof(struct driver_data));
+	gndev = ndev = alloc_etherdev(sizeof(struct driver_data));
 	if (!ndev) {
 		return -ENOMEM;
 	}
 	priv = netdev_priv(ndev);
-	priv->pdev = pdev;	/* struct pci_dev corresponding to this */
 	priv->ndev = ndev;	/* struct net_device corresponding to this */
-	priv->base = (volatile void *)start;
-#ifdef CONFIG_NLM_PCIEIP_HOST
-	pci_set_drvdata(pdev, ndev);
-#endif
-	setup_shared_mem(priv);
-	priv->xhead = priv->xtail = priv->rtail = priv->rhead = 0;
 	spin_lock_init(&priv->lock);
-	memset(priv->rx_q, 0, RX_DESC_MAX * sizeof(struct skb_free_info));
-	memset(priv->tx_q, 0, TX_DESC_MAX * sizeof(struct skb_free_info));
-	memset(&priv->stats, 0, sizeof(struct net_device_stats));
 	put_dummy_mac_address(ndev);
 	ether_setup(ndev);
 	setup_net_ops(ndev);
 	priv->poll_delay = poll_delay;
+	priv->ss = reserve_subsystem(PCIEIP_PTI_SUBSYS);
 	ret = register_netdev(ndev);
 	if (ret < 0) {
 		fdebug("Failed to register ndev\n");
 		goto fail_register;
 	}
-#ifdef CONFIG_NLM_PCIEIP_DEV
-	priv->msix = NULL;
-#else
-	if(pcieip_fillup_rxbuf(ndev) != 0){
-		goto fail_replenish;
+	INIT_DELAYED_WORK(&priv->poll_work, temp_int_func);
+	schedule_delayed_work(&priv->poll_work, 10);
+	return ret;
+fail_register:
+	free_netdev(ndev);
+	return -ENODEV;
+}
+
+/*
+ * Process rx on device
+ *
+ * @priv	: driver_data
+ */
+int process_rx_dev(struct driver_data *priv)
+{
+	__label__ rx_errors;
+	struct sk_buff *skb;
+	unsigned long flags;
+	struct rx_struct *pkt;
+	int status;
+
+	skb = pcieip_alloc_skb(PCIEIP_SKB_ALLOC_SIZE, 0);
+	if (skb == NULL) {
+		return -ENOMEM;
 	}
-	priv->msix = NULL;	/* TODO, enable MSI-X */
-#endif
-	priv->dbgf = debugfs_create_file("pcieip", S_IRUGO, NULL, priv, &netl_dbg_fops);
-	if (priv->dbgf == NULL) {
-		fdebug("Failed to create debugfs\n");
+	if (get_packet_from_rxlist(priv->ss, &pkt) < 0) {
+		dev_kfree_skb(skb);
+		return -EAGAIN;
 	}
-	init_timer(&priv->link_timer);
-	priv->link_timer.function = pcieip_link_status;
-	priv->link_timer.data = (unsigned long)ndev;
-	priv->link_timer.expires = jiffies + PCIEIP_LINK_TIMER_INTERVAL;
-	add_timer(&priv->link_timer);	/* starts timer */
-	INIT_DELAYED_WORK(&priv->poll_work, temp_int_func);
-#if !defined(CONFIG_NLM_PCIEIP_DEV) && !defined(CONFIG_HOST_NOIRQ)
-	if (pcieip_request_irq(irq_handler, ndev) < 0) {
-		goto fail_irq;
+	if (pkt->iov.iov_len > PCIEIP_MAX_RXLEN) {
+		priv->stats.rx_over_errors++;
+		goto rx_errors;
+	} else if (pkt->iov.iov_len < PCIEIP_MIN_RXLEN) {
+		priv->stats.rx_length_errors++;
+		goto rx_errors;
 	}
-#endif
-	return ret;
+	memcpy(skb->data, pkt->iov.iov_base, pkt->iov.iov_len);
+	skb_put(skb, pkt->iov.iov_len);
+	skb->dev = priv->ndev;
+	skb->protocol = eth_type_trans(skb, skb->dev);
+	skb->ip_summed = CHECKSUM_UNNECESSARY;
+	priv->stats.rx_packets++;
+	priv->stats.rx_bytes += skb->len;
+	if((status = netif_rx(skb)) == NET_RX_DROP){
+		fdebug("Sending up failed %d",status);
+		priv->stats.rx_dropped++;
+	}
+	free_page((unsigned long)pkt->iov.iov_base);
+	kfree(pkt);
+	return 0;
+rx_errors:
+	free_page((unsigned long)pkt->iov.iov_base);
+	kfree(pkt);
+	priv->stats.rx_errors++;
+	return -EAGAIN;
+}
 
-#if defined(CONFIG_NLM_PCIEIP_HOST) && !defined(CONFIG_HOST_NOIRQ)
-fail_irq:
-#endif
-	del_timer_sync(&priv->link_timer);
-#ifdef CONFIG_NLM_PCIEIP_HOST
-	free_all_desc(ndev, PCIEIP_DESC_RX_CLEAR | PCIEIP_DESC_TX_CLEAR);
-fail_replenish:
-#endif
-fail_register:
+/*
+ * Dummy mac address
+ *
+ * @dev		: net_device structure
+ */
+void put_dummy_mac_address(struct net_device *dev)
+{
+	dev->dev_addr[0] = 0x0;
+	dev->dev_addr[1] = 0xb;
+	dev->dev_addr[2] = 0x0;
+	dev->dev_addr[3] = 0xb;
+	dev->dev_addr[4] = 0x0;
+	dev->dev_addr[5] = 0xb;
+}
+
+/*
+ * Send data to other end
+ *
+ * @skb		: skb to send
+ * @ndev	: net_device structure
+ */
+netdev_tx_t pcieip_start_xmit(struct sk_buff *skb,struct net_device *ndev)
+{
+	//unsigned long mflags;
+	struct driver_data *priv = netdev_priv(ndev);
+	unsigned long page = get_zeroed_page(GFP_ATOMIC);
+
+	if (page == 0) {
+		return -ENOMEM;
+	}
+	if (skb->len > PCIEIP_SKB_ALLOC_SIZE) {
+		fdebug("Max rx len(%d) < skb->len(%d)\n", 1536, skb->len);
+		return NETDEV_TX_BUSY;
+	}
+	/* Queue up the DMA transfer */
+	memcpy((void *)page, skb->data, skb->len);
 #ifdef CONFIG_NLM_PCIEIP_HOST
-	pci_set_drvdata(pdev, NULL);
+	send_one_packet_to_device(priv->ss, page, skb->len);
+#else
+	send_one_packet_to_host(priv->ss, page, skb->len);
 #endif
-	unregister_netdev(ndev);
-	free_netdev(ndev);
-	return -ENODEV;
+	priv->stats.tx_packets++;
+	priv->stats.tx_bytes += skb->len;
+	dev_kfree_skb_any(skb);
+	return NETDEV_TX_OK;
+}
+
+int __init xlp_pcieip_init(void)
+{
+	fdebug("Compiled on %s %s\n", __DATE__, __TIME__);
+	if (pcieip_init(NULL, NULL) < 0) {
+		return -EFAULT;
+	}
+	return 0;
 }
+
+void __exit xlp_pcieip_exit(void)
+{
+	struct driver_data *priv = netdev_priv(gndev);
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	priv->flags |= PCIEIP_FLAG_EXITING;
+	spin_unlock_irqrestore(&priv->lock, flags);
+	cancel_delayed_work_sync(&priv->poll_work);
+	unregister_netdev(gndev);
+	free_netdev(gndev);
+	gndev = NULL;
+	fdebug("Exiting nlm_pcie\n");
+}
+
+module_init(xlp_pcieip_init);
+module_exit(xlp_pcieip_exit);
+MODULE_LICENSE("GPL");
diff --git a/drivers/misc/netlogic/pcie-offload/net/device/pcieip_dev.c b/drivers/misc/netlogic/pcie-offload/net/device/pcieip_dev.c
deleted file mode 100644
index 40d2cd2..0000000
--- a/drivers/misc/netlogic/pcie-offload/net/device/pcieip_dev.c
+++ /dev/null
@@ -1,273 +0,0 @@
-/***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
-reserved.
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are
-met:
-1. Redistributions of source code must retain the above copyright
-notice, this list of conditions and the following disclaimer.
-2. Redistributions in binary form must reproduce the above copyright
-notice, this list of conditions and the following disclaimer in
-the documentation and/or other materials provided with the
-distribution.
-THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
-ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
-PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
-FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
-CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
-SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
-INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
-CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
-ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
-THE POSSIBILITY OF SUCH DAMAGE.
-*****************************#NETL_2#********************************/
-#include <nlm_pcieip.h>
-
-/* Device specific functions goes here */
-extern int xlp_ctrl_fn_from_dev(const struct pci_dev *);
-extern int pcieip_init(struct pci_dev *pdev, volatile void *start);
-static void rx_done_dev(void *data, uint64_t unused);
-extern struct sk_buff *pcieip_alloc_skb(u32 size, u32 flags);
-
-/*
- * Dont' write anything to shared memspace. That is done from host side
- *
- * @priv	: driver_data
- */
-void setup_shared_mem(struct driver_data *priv)
-{
-	priv->rx_base = (struct xlp_desc *)(priv->base + NLM_PCIE_IP_OFFSET);
-	priv->tx_base = priv->rx_base + RX_DESC_MAX;
-	priv->magic = (volatile u32 *)(priv->tx_base + TX_DESC_MAX);
-	priv->th_stat = priv->magic + 1;
-	priv->my_stat = priv->th_stat + 1;
-	//fdebug("tx_base  = %#llx, rx_base = %#llx, magic = %#llx, my_stat = %#llx, th_stat = %#llx\n", (u64)priv->tx_base, (u64)priv->rx_base, (u64)priv->magic, (u64)priv->my_stat, (u64)priv->th_stat);
-}
-
-/*
- * This is _not_ automatically called. Just to keep the same naming convention
- *
- * @pdev	: always null
- * @id		: always null
- */
-static int xlp_pcieip_probe_dev(struct pci_dev *pdev, const struct pci_device_id *id)
-{
-	u64 mem_base;
-	volatile void __iomem *iomem_start;
-	u64 len = 0;
-
-	mem_base = setup_pcie_shared_memspace(&len);
-	if (mem_base == 0) {
-		return -ENOMEM;
-	}
-	iomem_start = ioremap_nocache(virt_to_phys((volatile const void *)mem_base), len);
-	if (iomem_start == NULL) {
-		return -ENOMEM;
-	}
-	if (pcieip_init(NULL, (volatile void *)iomem_start) <0) {
-		iounmap(iomem_start);
-		return -EFAULT;
-	}
-	return 0;
-}
-
-/*
- * Process rx on device
- *
- * @priv	: driver_data
- */
-int process_rx_dev(struct driver_data *priv)
-{
-	dma_addr_t daddr;
-	u64 paddr;
-	struct sk_buff *skb;
-	int data_len, count = 0;
-	int th_stat, my_stat;
-	unsigned long flags;
-	u32 info;
-
-	th_stat = nlm_pci_readl(priv->th_stat);	/* Are they up? */
-	my_stat = nlm_pci_readl(priv->my_stat);	/* Am I up? */
-	if ((my_stat != PCIEIP_IF_UP) || (th_stat != PCIEIP_IF_UP)) {
-		netif_stop_queue(priv->ndev);
-		return -EIO;
-	}
-
-	spin_lock_irqsave(&priv->lock, flags);
-	info = nlm_pci_readl(&(priv->rx_base[priv->rhead].info));
-	while(GET_DMA_READY(info)){
-		data_len = GET_LEN(info);/* Guaranteed not to exceed max */
-		paddr = nlm_pci_readq(&(priv->rx_base[priv->rhead].addr));
-                skb = pcieip_alloc_skb(PCIEIP_SKB_ALLOC_SIZE, 0);
-		BUG_ON(skb == NULL);
-		priv->rx_q[priv->rhead].skb = skb;
-		priv->rx_q[priv->rhead].len = data_len;
-		priv->rx_q[priv->rhead].idx = priv->rhead;
-		priv->rx_q[priv->rhead].priv = priv;
-		priv->rx_q[priv->rhead].paddr = daddr = virt_to_phys(skb->data);
-		if (xlp_async_request_dma(paddr, daddr, data_len, rx_done_dev,
-			&priv->rx_q[priv->rhead], DMA_TO_DEVICE) < 0) {
-			/* TODO handle error during DMA */
-		}
-		if (count++ > PCIEIP_MAX_LOOPS) {
-			break;
-		}
-		priv->rhead = INCR_CEIL(priv->rhead);
-		info = nlm_pci_readl(&(priv->rx_base[priv->rhead].info));
-	}
-	spin_unlock_irqrestore(&priv->lock, flags);
-	return 0;
-}
-
-/*
- * Complete Rx here and raise irq if possible
- *
- * @data	: device specific data
- * @unused	: just to keep the format
- */
-static void rx_done_dev(void *data, uint64_t unused)
-{
-	struct skb_free_info *entry = (struct skb_free_info *)data;
-	unsigned long flags;
-	int status;
-	u32 info;
-
-	spin_lock_irqsave(&entry->priv->lock, flags);
-	info = nlm_pci_readl(&(entry->priv->rx_base[entry->idx].info));
-	CLEAR_DMA_READY(info);
-	nlm_pci_writel(info, &entry->priv->rx_base[entry->idx].info);
-	skb_put(entry->skb, entry->len);
-	entry->skb->dev = entry->priv->ndev;
-	entry->skb->protocol = eth_type_trans(entry->skb, entry->skb->dev);
-	entry->skb->ip_summed = CHECKSUM_UNNECESSARY;
-	entry->priv->stats.rx_packets++;
-	entry->priv->stats.rx_bytes += entry->skb->len;
-	spin_unlock_irqrestore(&entry->priv->lock, flags);
-	if((status = netif_rx(entry->skb)) == NET_RX_DROP){
-		fdebug("Sending up failed %d",status);
-		entry->priv->stats.rx_dropped++;
-	}
-#ifndef CONFIG_HOST_NOIRQ
-	raise_host_interrupt(0);
-#endif
-}
-
-/*
- * Dummy mac address
- *
- * @dev		: net_device structure
- */
-void put_dummy_mac_address(struct net_device *dev)
-{
-	dev->dev_addr[0] = 0x0;
-	dev->dev_addr[1] = 0xb;
-	dev->dev_addr[2] = 0x0;
-	dev->dev_addr[3] = 0xb;
-	dev->dev_addr[4] = 0x0;
-	dev->dev_addr[5] = 0xb;
-}
-
-/*
- * Tx complete here
- *
- * @data	: device specific data
- */
-void tx_done_dev(void *data, uint64_t unused)
-{
-	struct skb_free_info *entry = (struct skb_free_info *)data;
-	unsigned long flags;
-
-	spin_lock_irqsave(&entry->priv->lock, flags);
-	nlm_pci_writel(entry->skb->len & ~DMA_BIT, &(entry->priv->tx_base[entry->idx].info));
-	spin_unlock_irqrestore(&entry->priv->lock, flags);
-	dev_kfree_skb_any(entry->skb);
-	memset(entry, 0, sizeof(struct skb_free_info));
-#ifndef CONFIG_HOST_NOIRQ
-	raise_host_interrupt(0);
-#endif
-}
-
-
-/*
- * Send data to host
- *
- * @skb		: skb to send
- * @ndev	: net_device structure
- */
-netdev_tx_t pcieip_start_xmit_dev(struct sk_buff *skb,struct net_device *ndev)
-{
-	uint32_t status;
-	unsigned long mflags;
-	struct driver_data *priv = netdev_priv(ndev);
-	int rxlen, idx;
-	unsigned long daddr;
-	u32 info;
-	u64 paddr;
-
-	status = nlm_pci_readl(priv->th_stat);	/* Are they up? */
-	if(status != PCIEIP_IF_UP){
-		netif_stop_queue(ndev);
-		return NETDEV_TX_BUSY;
-	}
-	spin_lock_irqsave(&priv->lock, mflags);
-
-	/* Check if xhead is free */
-	idx = priv->xhead;
-	info = nlm_pci_readl(&(priv->tx_base[priv->xhead].info));
-	if(!GET_DMA_READY(info)){
-		fdebug("All Xmit Desc are full...");
-		return NETDEV_TX_BUSY;;
-	}
-	rxlen = GET_LEN(info);
-	if (rxlen < skb->len) {
-		fdebug("Max rx len(%d) < skb->len(%d)\n", rxlen, skb->len);
-		spin_unlock_irqrestore(&priv->lock, mflags);
-		return NETDEV_TX_BUSY;
-	}
-	/* Queue up the DMA transfer */
-	priv->tx_q[idx].skb = skb;
-        priv->tx_q[idx].paddr = daddr = virt_to_phys(skb->data);
-	priv->tx_q[idx].len = skb->len;
-	priv->tx_q[idx].idx = idx;
-	priv->tx_q[idx].priv = priv;
-	priv->xhead = INCR_CEIL(idx);
-	paddr = nlm_pci_readq(&(priv->tx_base[idx].addr));
-	if (xlp_async_request_dma(daddr, paddr, skb->len, tx_done_dev,
-			&priv->tx_q[idx], DMA_FROM_DEVICE) < 0) {
-		fdebug("DMA failed\n");
-		spin_unlock_irqrestore(&priv->lock, mflags);
-		return NETDEV_TX_BUSY;
-	}
-	spin_unlock_irqrestore(&priv->lock, mflags);
-	return NETDEV_TX_OK;
-}
-
-/*
- * Process rx on device
- * @unused	: interrupt?
- * @data	: driver_data
- */
-irqreturn_t ip_over_pci_rx (int unused, void *data)
-{
-	process_rx_dev((struct driver_data*)data);
-	return IRQ_HANDLED;
-}
-
-int __init xlp_pcieip_init(void)
-{
-	//fdebug("Compiled on %s %s\n", __DATE__, __TIME__);
-	if (xlp_pcieip_probe_dev(NULL, NULL) < 0) {
-		return -ENODEV;
-	}
-	return 0;
-}
-
-void __exit xlp_pcieip_exit(void)
-{
-	fdebug("Exiting nlm_pcie\n");
-}
-
-module_init(xlp_pcieip_init);
-module_exit(xlp_pcieip_exit);
-MODULE_LICENSE("GPL");
diff --git a/drivers/misc/netlogic/pcie-offload/net/host/Makefile b/drivers/misc/netlogic/pcie-offload/net/host/Makefile
index 7aebca6..8aa428e 100644
--- a/drivers/misc/netlogic/pcie-offload/net/host/Makefile
+++ b/drivers/misc/netlogic/pcie-offload/net/host/Makefile
@@ -7,9 +7,9 @@ ifeq ($(KDIR),)
 endif
 # EXTRA_CFLAGS += -DNETL_PTI_TEST
 ifneq ($(KERNELRELEASE),)
-EXTRA_CFLAGS := -I$(src)/../../include -g -DCONFIG_NLM_PCIEIP_HOST #-DCONFIG_HOST_NOIRQ
+EXTRA_CFLAGS := -I$(src)/../../include -g -DCONFIG_NLM_PCIEIP_HOST -DCONFIG_HOST_NOIRQ
 obj-m += pcieip.o
-pcieip-y := pcieip_host.o pcieip_common.o
+pcieip-y := pcieip_common.o
 else
 modules:
 	make -C $(KDIR) M=$(PWD) modules
diff --git a/drivers/misc/netlogic/pcie-offload/net/host/pcieip_host.c b/drivers/misc/netlogic/pcie-offload/net/host/pcieip_host.c
deleted file mode 100644
index 517d8df..0000000
--- a/drivers/misc/netlogic/pcie-offload/net/host/pcieip_host.c
+++ /dev/null
@@ -1,531 +0,0 @@
-/***********************************************************************
-Copyright 2003-2010 Netlogic Microsystems (“Netlogic”). All rights
-reserved.
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are
-met:
-1. Redistributions of source code must retain the above copyright
-notice, this list of conditions and the following disclaimer.
-2. Redistributions in binary form must reproduce the above copyright
-notice, this list of conditions and the following disclaimer in
-the documentation and/or other materials provided with the
-distribution.
-THIS SOFTWARE IS PROVIDED BY Netlogic Microsystems ``AS IS'' AND
-ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
-PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL NETLOGIC OR CONTRIBUTORS BE LIABLE
-FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
-CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
-SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
-INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
-CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
-ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
-THE POSSIBILITY OF SUCH DAMAGE.
-*****************************#NETL_2#********************************/
-#include <nlm_pcieip.h>
-extern irqreturn_t ip_over_pci_rx (int unused, void *data);
-extern int pcieip_init(struct pci_dev *pdev, volatile void *start);
-extern int fill_this_rx_desc(struct driver_data *priv, int i);
-extern void free_all_desc(struct net_device *ndev, u32 rxtx);
-extern struct sk_buff *pcieip_alloc_skb(u32 size, u32 flags);
-static void tx_done_host(struct net_device *ndev);
-int process_rx_host(struct net_device *ndev);
-
-/*
- * Frees a descriptor @ index i
- *
- * @priv	: driver data pointer
- * @i		: index of desc. to free
- */
-static void free_tx_desc_index(struct driver_data *priv, int i)
-{
-	struct xlp_desc *tmp = (struct xlp_desc *) (priv->tx_base + i);
-
-	nlm_pci_writeq(0, &(tmp->addr));
-	nlm_pci_writel(0, &(tmp->info));
-	pci_unmap_single(priv->pdev, priv->tx_q[i].paddr, priv->tx_q[i].len,
-                        DMA_TO_DEVICE);
-	dev_kfree_skb(priv->tx_q[i].skb);
-}
-
-/*
- * Frees rx desc at an index
- *
- * @priv	: driver data ptr
- * @i		: index of desc. to free
- */
-static void free_rx_desc_index(struct driver_data *priv, int i)
-{
-	uint64_t phys_addr;
-	struct xlp_desc *tmp = (struct xlp_desc *) (priv->tx_base + i);
-
-	nlm_pci_writeq(0, &(tmp->addr));
-	nlm_pci_writel(0, &(tmp->info));
-	phys_addr = priv->rx_q[i].paddr;
-        pci_unmap_single(priv->pdev, phys_addr, priv->rx_q[i].len,
-			DMA_FROM_DEVICE);
-	dev_kfree_skb(priv->rx_q[i].skb);
-}
-
-/*
- * Frees up all descriptors
- *
- * @ndef	: net dev structure
- * @rxtx	: flag to determine rx desc or tx desc
- */
-void free_all_desc(struct net_device *ndev, u32 rxtx)
-{
-        int i=0;
-	struct driver_data *priv = netdev_priv(ndev);
-
-        for(i = 0;i < RX_DESC_MAX; i++){
-		if (rxtx & PCIEIP_DESC_RX_CLEAR) {
-			free_rx_desc_index(priv, i);
-		}
-		if (rxtx & PCIEIP_DESC_TX_CLEAR) {
-			free_tx_desc_index(priv, i);
-		}
-	}
-}
-
-/*
- * Fills up a Rx descritpr
- *
- * @priv	: driver data ptr
- * @i		: index to fill up the descriptor
- */
-int fill_this_rx_desc(struct driver_data *priv, int i)
-{
-	struct sk_buff *skb;
-        unsigned int phys_addr;
-
-	skb = pcieip_alloc_skb(PCIEIP_SKB_ALLOC_SIZE, 0);
-	if(!skb){
-		fdebug("Couldnt Replenish Buffer\n");
-		return -ENOMEM;
-	}
-        phys_addr = pci_map_single(priv->pdev, skb->data, PCIEIP_MAX_RXLEN,
-                                DMA_FROM_DEVICE);
-	priv->rx_q[i].skb = skb;
-	priv->rx_q[i].paddr = phys_addr;
-        priv->rx_q[i].len = PCIEIP_MAX_RXLEN;
-
-	nlm_pci_writeq(phys_addr, &(priv->rx_base[i].addr));
-	nlm_pci_writel(PCIEIP_MAX_RXLEN | DMA_BIT , &(priv->rx_base[i].info));
-	return 0;
-}
-
-/*
- * Fills up all Rx bufs
- *
- * @ndef	: net device structure
- */
-int pcieip_fillup_rxbuf(struct net_device *ndev)
-{
-	int i, j;
-	struct driver_data *priv = netdev_priv(ndev);
-
-	for(i = 0;i < RX_DESC_MAX;i++){
-		if (fill_this_rx_desc(priv, i)){
-			fdebug("replenish failed for buffer %d",i);
-			break;
-		}
-	}
-	if(i != RX_DESC_MAX){
-		for(j = 0; j < i; j++) {
-			free_rx_desc_index(priv, j);
-		}
-		return -ENOMEM;
-	}
-	return 0;
-}
-
-/*
- * Sets up the shared memory by writing magic, rx/tx descriptors..etc
- * This must be done prior to loading device part, for the device expects
- * the target addresses to be present in the shared address space
- *
- * @priv	: driver data pointer
- */
-void setup_shared_mem(struct driver_data *priv)
-{
-	int i;
-
-	priv->tx_base = (struct xlp_desc *)(priv->base + NLM_PCIE_IP_OFFSET);
-	priv->rx_base = priv->tx_base + TX_DESC_MAX;
-	priv->magic = (volatile u32 *)(priv->rx_base + RX_DESC_MAX);
-	priv->my_stat = priv->magic + 1;
-	priv->th_stat = priv->my_stat + 1;
-
-	//fdebug("tx_base  = %#llx, rx_base = %#llx, magic = %#llx, my_stat = %#llx, th_stat = %#llx\n", (u64)priv->tx_base, (u64)priv->rx_base, (u64)priv->magic, (u64)priv->my_stat, (u64)priv->th_stat);
-	/* Only host initializes shared memory */
-	nlm_pci_writel(PCIEIP_MAGIC, priv->magic);
-	nlm_pci_writel(0, priv->my_stat);
-	nlm_pci_writel(0, priv->th_stat);
-	for(i = 0; i < RX_DESC_MAX; i++){
-		nlm_pci_writeq(0, &(priv->rx_base[i].addr));
-		nlm_pci_writel(0, &(priv->rx_base[i].info));
-	}
-}
-
-/*
- * Process rx on the host
- *
- * @ndev	: net_device structure
- */
-int process_rx_host(struct net_device *ndev)
-{
-	dma_addr_t paddr;
-	struct sk_buff *skb;
-	int data_len;
-	int th_stat, my_stat, status;
-	unsigned long flags;
-	struct driver_data *priv = netdev_priv(ndev);
-	u32 info;
-
-	th_stat = nlm_pci_readl(priv->th_stat);	/* Are they up? */
-	my_stat = nlm_pci_readl(priv->my_stat);	/* Am I up? */
-	if ((my_stat != PCIEIP_IF_UP) || (th_stat != PCIEIP_IF_UP)) {
-		netif_stop_queue(ndev);
-		return -EIO;
-	}
-
-	spin_lock_irqsave(&priv->lock, flags);
-	info = nlm_pci_readl(&(priv->rx_base[priv->rtail].info));
-
-	while(!GET_DMA_READY(info)){
-		paddr = priv->rx_q[priv->rtail].paddr;
-                pci_unmap_single(priv->pdev,priv->rx_q[priv->rtail].paddr,
-			priv->rx_q[priv->rtail].len, DMA_FROM_DEVICE);
-		data_len = GET_LEN(info);
-                skb = priv->rx_q[priv->rtail].skb;
-		BUG_ON(skb == NULL);
-		if(fill_this_rx_desc(priv, priv->rtail) != 0){
-			fdebug("Droppin Packet As replenishment is failed");
-			paddr = pci_map_single(priv->pdev, skb->data,
-					PCIEIP_MAX_RXLEN, DMA_FROM_DEVICE);
-			priv->rx_q[priv->rtail].paddr = paddr;
-			priv->rx_q[priv->rtail].skb = skb;
-		        priv->rx_q[priv->rtail].len = PCIEIP_MAX_RXLEN;
-
-			nlm_pci_writeq(paddr, &(priv->rx_base[priv->rtail].addr));
-			nlm_pci_writel(PCIEIP_MAX_RXLEN | DMA_BIT , &(priv->rx_base[priv->rtail].info));
-			priv->rtail = INCR_CEIL(priv->rtail);
-			break;
-		}
-		skb_put(skb, data_len);
-		skb->dev = ndev;
-		skb->protocol = eth_type_trans(skb, skb->dev);
-		skb->ip_summed = CHECKSUM_UNNECESSARY;
-		if((status = netif_rx(skb)) == NET_RX_DROP){
-			fdebug("Sending up failed %d",status);
-		}
-		priv->stats.rx_packets++;
-		priv->stats.rx_bytes += skb->len;
-		priv->rtail = INCR_CEIL(priv->rtail);
-		info = nlm_pci_readl(&(priv->rx_base[priv->rtail].info));
-	}
-	spin_unlock_irqrestore(&priv->lock, flags);
-	return 0;
-}
-
-/*
- * At this point, TX is complete.
- * We find out the used up descriptors and free them
- *
- * @ndev	: net_device structure
- */
-static void tx_done_host(struct net_device *ndev)
-{
-	struct driver_data *priv = netdev_priv(ndev);
-	unsigned long flags;
-	int loops, tail;
-	u32 info;
-
-	spin_lock_irqsave(&priv->lock, flags);
-	tail = priv->xtail;
-	loops = (priv->xhead + DESC_MAX - tail) % DESC_MAX;
-	/* Need better logic XXX */
-	while (loops--) {
-		info = nlm_pci_readl(&(priv->tx_base[tail].info));
-		if (GET_DMA_READY(info) != 0) { /* Busy */
-			spin_unlock_irqrestore(&priv->lock, flags);
-			fdebug("Still busy, returning\n");
-			return;
-		}
-		pci_unmap_single(priv->pdev, priv->tx_q[tail].paddr,
-				priv->tx_q[tail].len, DMA_TO_DEVICE);
-                dev_kfree_skb(priv->tx_q[tail].skb);
-		priv->stats.tx_packets++;
-		nlm_pci_writel(0, &(priv->tx_base[tail].info));	// XXX remove
-		nlm_pci_writeq(0, &(priv->tx_base[tail].addr));	// XXX remove
-		tail = priv->xtail = INCR_CEIL(priv->xtail);
-	}
-	spin_unlock_irqrestore(&priv->lock, flags);
-	netif_start_queue(priv->ndev);
-}
-
-
-/*
- * This is the bottom half handler called from workqueue
- */
-irqreturn_t ip_over_pci_rx (int unused, void *data)
-{
-	struct driver_data *priv = (struct driver_data *)data;
-	uint32_t dev_status;
-	dev_status = nlm_pci_readl(priv->th_stat);
-
-	if(dev_status == PCIEIP_IF_UP){
-		tx_done_host(priv->ndev);
-		process_rx_host(priv->ndev);
-	}
-	return IRQ_HANDLED;
-}
-
-/*
- * Actual IRQ routine
- */
-irqreturn_t irq_handler(int unused, void *data)
-{
-	struct driver_data *priv = netdev_priv((struct net_device *)data);
-	/* TODO : make this cmdline param as well */
-	schedule_delayed_work(&priv->poll_work, 0);
-	return IRQ_HANDLED;
-}
-
-/*
- * Programs the pseudo mac address
- * @dev		: net_device structure
- */
-void put_dummy_mac_address(struct net_device *dev)
-{
-	/* Fixed address. There must be a way to make this cmdline param */
-	dev->dev_addr[0] = 0x0;
-	dev->dev_addr[1] = 0xb;
-	dev->dev_addr[2] = 0x0;
-	dev->dev_addr[3] = 0xb;
-	dev->dev_addr[4] = 0x0;
-	dev->dev_addr[5] = 0xb;
-}
-
-/*
- * Hard transmit function
- *
- * @skb		: sk_buff struct to send
- * @ndev	: net_device structure
- */
-netdev_tx_t pcieip_start_xmit(struct sk_buff *skb,struct net_device *ndev)
-{
-	uint32_t status;
-	unsigned long mflags;
-	struct driver_data *priv = netdev_priv(ndev);
-	dma_addr_t daddr;
-	u32 info;
-
-	status = nlm_pci_readl(priv->th_stat);	/* Are they up? */
-	if(status != PCIEIP_IF_UP){
-		netif_stop_queue(ndev);
-		return NETDEV_TX_BUSY;
-	}
-	if(skb->len > 1514){
-		fdebug("Pkt size Greater Than Max Size %d",skb->len);
-		return NETDEV_TX_BUSY;
-	}
-	spin_lock_irqsave(&priv->lock, mflags);
-	if(INCR_CEIL(priv->xhead) == priv->xtail){
-		fdebug("No TX Desc Available.");
-		netif_stop_queue(priv->ndev);
-		spin_unlock_irqrestore(&priv->lock, mflags);
-		return NETDEV_TX_BUSY;
-	}
-	/* The logic is not entirely correct
-	 * In fact, we need a more sophisticated mechanism
-	 * Since there are no locking across device and host, there must 
-	 * be two different reads to achieve that exclusive access.
-	 * Need to keep a head and tail pointer in the shared space.
-	 * They should be updated after local head and tails are updated.
-	 * TODO
-	 */
-	/* there is at least one space */
-	info = nlm_pci_readl(&(priv->tx_base[priv->xhead].info));
-	if(GET_DMA_READY(info)){
-		fdebug("All Xmit Desc are full...");
-		return NETDEV_TX_BUSY;;
-	}
-	priv->tx_q[priv->xhead].skb = skb;
-        daddr = pci_map_single(priv->pdev, skb->data, skb->len, DMA_TO_DEVICE);
-	if (daddr == 0) {
-		fdebug("Daddr NULL, skb->data = 0x%p\n", skb->data);
-		return NETDEV_TX_BUSY;
-	}
-        priv->tx_q[priv->xhead].paddr = daddr;
-	priv->tx_q[priv->xhead].len = skb->len;
-
-	nlm_pci_writeq(daddr, &(priv->tx_base[priv->xhead].addr));
-	info = skb->len | DMA_BIT;
-	nlm_pci_writel(info, &(priv->tx_base[priv->xhead].info));
-	priv->xhead = INCR_CEIL(priv->xhead);
-	spin_unlock_irqrestore(&priv->lock, mflags);
-	return NETDEV_TX_OK;
-}
-
-
-/*
- * Host implementation of request irq
- *
- * @host_handler	: function of type irq_handler_t
- * ndev			: net-device structure
- *
- * We need this function to use the common code figuring out what
- * mode of interrupt to request
- */
-int pcieip_request_irq(irq_handler_t host_handler, struct net_device *ndev)
-{
-	int ret;
-	struct driver_data *priv = netdev_priv(ndev);
-
-	/* Check if MSI is enabled
-	 * MSI-X TODO */
-	priv->flags |= PCIEIP_FLAG_MSI_ENABLED;
-	if ((ret = pci_enable_msi(priv->pdev)) < 0) {
-		priv->flags &= ~PCIEIP_FLAG_MSI_ENABLED;
-		fdebug("Failed to enable MSI. Falling back\n");
-		return ret;
-	}
-	ret = request_irq(priv->pdev->irq, host_handler, 0, DRV_NAME, (void *)ndev);
-	if (ret < 0) {
-		priv->flags &= ~PCIEIP_FLAG_MSI_ENABLED;
-		fdebug("Failed request_irq\n");
-		return ret;
-	}
-	return 0;
-}
-
-/*
- * PCI probe function
- */
-static int xlp_pcieip_probe(struct pci_dev *pdev, const struct pci_device_id *id)
-{
-	__label__ init_fail, pci_en_fail, resource_err, err_return;
-	int err;
-	unsigned long base;
-	void *iomem_start;
-
-	/* list_dev has 0 or more entries. Allocate this device now */
-	if (!(pci_resource_flags(pdev, 0) & IORESOURCE_MEM)) {
-		fdebug("No memory resource in BAR\n");
-		err = ENODEV;
-		goto err_return;
-	}
-	err = pci_request_region(pdev, 0, DRV_NAME);
-	if (err) {
-		fdebug("Cannot obtain PCI resources, aborting.");
-		err = ENODEV;
-		goto err_return;
-	}
-	base = pci_resource_start(pdev, 0);
-	if(base == 0){
-		fdebug("Cannot allocate memory resource in BAR\n");
-		goto resource_err;
-	}
-	/* base must be physical address */
-	iomem_start = ioremap_nocache(base, pci_resource_len(pdev, 0));
-	if(iomem_start == NULL){
-		fdebug("IOREMAP failed on resource in BAR\n");
-		goto resource_err;
-	}
-	if ((err = pci_enable_device(pdev))) {
-		fdebug("Cannot enable PCI device, aborting.");
-		goto pci_en_fail;
-	}
-	if (pcieip_init(pdev, iomem_start) != 0) {
-		goto init_fail;
-	}
-	pci_set_master(pdev);
-	return 0;
-
-init_fail:
-	pci_disable_device(pdev);
-pci_en_fail:
-	iounmap(iomem_start);
-resource_err:
-	pci_release_region(pdev, 0);
-err_return:
-	fdebug("FAILED\n");
-	return -EFAULT;
-}
-
-/*
- * Remove function
- */
-static void xlp_pcieip_remove(struct pci_dev *pdev)
-{
-	struct driver_data *priv;
-	struct net_device *ndev = pci_get_drvdata(pdev);
-	unsigned long flags;
-
-	/* Need to implement a protocol to let other side know
-	 * that we are being removed. XXX TODO
-	 */
-	priv = netdev_priv(ndev);
-	netif_stop_queue(ndev);
-	ndev->netdev_ops->ndo_stop(ndev);
-	unregister_netdev(ndev);
-	/* We don't know the interrupt mode configured.
-	 * Check and disable all modes and free irqs */
-	if (priv->msix != NULL) {
-		free_irq(priv->msix[0].vector, ndev);
-		pci_disable_msix(priv->pdev);
-		kfree(priv->msix);
-		priv->msix = NULL;
-	} else if (priv->flags & PCIEIP_FLAG_MSI_ENABLED) {
-		free_irq(priv->pdev->irq, ndev);
-		priv->flags &= ~PCIEIP_FLAG_MSI_ENABLED;
-		pci_disable_msi(priv->pdev);
-	} else {
-		free_irq(priv->pdev->irq, ndev);
-	}
-	pci_set_drvdata(pdev, NULL);
-	pci_release_region(pdev, 0);
-	iounmap(priv->base);
-	free_all_desc(ndev, PCIEIP_DESC_RX_CLEAR);
-	/* Make sure timer is deleted and sync-ed */
-	del_timer_sync(&priv->link_timer);
-	cancel_delayed_work_sync(&priv->poll_work);
-	pci_disable_device(pdev);
-	pci_clear_master(pdev);
-	free_netdev(ndev);
-	return;
-}
-
-static struct pci_device_id netl_id_table[] = {
-	{NETL_VENDOR_ID, PCI_ANY_ID, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 0},
-	{0,}
-};
-
-static struct pci_driver nlm_pcie_driver = {
-	.name = DRV_NAME,
-	.id_table = netl_id_table,
-	.probe = xlp_pcieip_probe,
-	.remove = xlp_pcieip_remove,
-};
-
-int __init xlp_pcieip_init(void)
-{
-	//fdebug("Compiled on %s %s\n", __DATE__, __TIME__);
-	if (pci_register_driver(&nlm_pcie_driver) < 0){
-		fdebug("Register failed\n");
-		return -ENODEV;
-	}
-	return 0;
-}
-
-void __exit xlp_pcieip_exit(void)
-{
-	pci_unregister_driver(&nlm_pcie_driver);
-	fdebug("Exiting nlm_pcie\n");
-}
-
-module_init(xlp_pcieip_init);
-module_exit(xlp_pcieip_exit);
-MODULE_LICENSE("GPL");
-- 
1.7.1

