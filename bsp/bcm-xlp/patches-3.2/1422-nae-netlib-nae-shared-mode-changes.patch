From d938b8fc65dd3bead1632fe04c98162d8065560b Mon Sep 17 00:00:00 2001
From: Hareesh R <hareeshr@broadcom.com>
Date: Fri, 6 Sep 2013 10:07:15 +0530
Subject: nae : netlib nae shared mode changes

[Based on SDK 3.2]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
Signed-off-by: Nam Ninh <nam.ninh@windriver.com>

diff --git a/drivers/net/ethernet/broadcom/nae/xlpge.h b/drivers/net/ethernet/broadcom/nae/xlpge.h
index d16bffe..16a6b89 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge.h
+++ b/drivers/net/ethernet/broadcom/nae/xlpge.h
@@ -299,17 +299,16 @@ struct dev_data
  * This strucutre has been referenced in templates/hybrid_nae and
  * ucore/hybrid_nae. So when you modify, modify the above places also.
  */
+
 struct nlm_nae_linux_shinfo {
-	int valid;
+	unsigned int flags;
 	int rxvc;
 	int domid;
 	int mode;
-	int jumbo_enabled;
 	int node;
-	/* logical cpu to physical cpu map */
-	unsigned int lcpu_2_pcpu_map[NLM_NAE_SH_LCPU_TO_MAP_SZ];
-	unsigned int cpu_2_freeinfifo_map[NLM_NAE_SH_LCPU_TO_MAP_SZ];
-	unsigned int cpu_2_jumbo_freeinfifo_map[NLM_NAE_SH_LCPU_TO_MAP_SZ];
+	int num_cpus;
+	/* variable sizes depending on the num cpus */
+	unsigned int fwd_info[0]; 
 };
 
 struct p2p_desc_mem {
@@ -480,6 +479,7 @@ int nlm_load_balance_proc_open(struct inode *, struct file *);
 void nlm_init_load_balance(void);
 
 extern int enable_lro; 	
+extern int num_cpus_per_node;
 extern unsigned char eth_hw_addr[NLM_MAX_NODES][MAX_GMAC_PORT][6];
 extern struct proc_dir_entry *nlm_root_proc;
 extern uint64_t receive_count[NR_CPUS * 8] __cacheline_aligned;
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_nae.c b/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
index 2d83234..d4479ce 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
@@ -43,10 +43,14 @@
 
 #include "xlpge.h"
 
-uint32_t cpu_2_normal_frfifo[NLM_MAX_NODES][NLM_NCPUS_PER_NODE];
-uint32_t cpu_2_jumbo_frfifo[NLM_MAX_NODES][NLM_NCPUS_PER_NODE];
+static uint32_t cpu_2_normal_frfifo[NLM_MAX_NODES][MAX_NAE_PERNODE][NR_CPUS];
+static uint32_t cpu_2_jumbo_frfifo[NLM_MAX_NODES][MAX_NAE_PERNODE][NR_CPUS];
+int lcpu_2_pcpu[NR_CPUS];
+static unsigned int fmem[NR_CPUS];
+int num_cpus_per_node;
+
 uint64_t nlm_mode[NR_CPUS*8] ____cacheline_aligned;
-struct nlm_nae_linux_shinfo lnx_shinfo[NLM_NAE_MAX_SHARED_DOMS + 1];
+static struct nlm_nae_linux_shinfo *lnx_shinfo[3];
 uint64_t p2p_dynamic_alloc_cnt[NR_CPUS * 8] __cacheline_aligned;
 struct net_device *xlp_dev_mac[NLM_MAX_NODES][MAX_GMAC_PORT];
 struct net_device *
@@ -71,8 +75,9 @@ module_param(num_descs_per_normalq, int, 0);
 int num_descs_per_jumboq = 48;
 module_param(num_descs_per_jumboq, int, 0);
 
-static uint32_t lnx_normal_mask[NLM_MAX_NODES];
-static uint32_t lnx_jumbo_mask[NLM_MAX_NODES];
+static uint32_t lnx_frfifo_normal_mask[NLM_MAX_NODES][MAX_NAE_PERNODE];
+static uint32_t lnx_frfifo_jumbo_mask[NLM_MAX_NODES][MAX_NAE_PERNODE];
+
 static int enable_jumbo = 0;
 module_param(enable_jumbo, int, 0);
 static struct p2p_desc_mem p2p_desc_mem[NR_CPUS] __cacheline_aligned;
@@ -128,12 +133,9 @@ static int init_dummy_entries_for_port_fifos(nae_t* nae_cfg)
 	for (shdom = 0; shdom <= NLM_NAE_MAX_SHARED_DOMS; shdom++) {
 		if (!nae_cfg->shinfo[shdom].valid)
 			continue;
-		//TODO:
-		//fifo_mask |= nlm_hal_retrieve_freein_fifo_mask(fdt, node,
-		//		nae_cfg->shinfo[shdom].domid);
-		fifo_mask = nae_cfg->freein_fifo_dom_mask;
-		printk("OOPppS nlm_hal_retrieve_freein_fifo_mask not ye called fifo_mask=0x%x\n", fifo_mask);
+		fifo_mask |= nae_cfg->shinfo[shdom].freein_fifo_mask;
 	}
+	return 0;
 
 //	msgrng_access_enable(mflags);
 	printk("Total free ins = 0x%x\n", nae_cfg->frin_total_queue);
@@ -233,7 +235,6 @@ static inline uint32_t fdt32_to_cpu(uint32_t x)
 #endif
 }
 
-#if 0
 static int nlm_configure_shared_freein_fifo(int node,
 					    nlm_nae_config_ptr nae_cfg)
 {
@@ -248,6 +249,8 @@ static int nlm_configure_shared_freein_fifo(int node,
 	int len = 0, i = 0;
 	char *paddr_info, *desc_info;
 
+	printk("%s in \n", __FUNCTION__);
+
 	for(shdom = 0; shdom <= NLM_NAE_MAX_SHARED_DOMS; shdom++) {
 		if(!nae_cfg->shinfo[shdom].valid)
 			continue;
@@ -255,13 +258,15 @@ static int nlm_configure_shared_freein_fifo(int node,
 		if(nae_cfg->shinfo[shdom].domid == 0)
 			continue;
 
-		rv = nlm_hal_retrieve_shared_freein_fifo_info(fdt,
-				nae_cfg->shinfo[shdom].domid,
-				&owner_replenish,
-				&paddr_info, &paddr_info_len,
-				&desc_info, &desc_info_len);
-		if(rv != 0)
-			continue;
+		owner_replenish = nae_cfg->shinfo[shdom].owner_replenish;
+		paddr_info = nae_cfg->shinfo[shdom].paddr_info;
+		paddr_info_len = nae_cfg->shinfo[shdom].paddr_info_len;
+		desc_info = nae_cfg->shinfo[shdom].desc_info;
+		desc_info_len = nae_cfg->shinfo[shdom].desc_info_len;
+
+		printk("shind %d dom %d repl %d paddr %lx len %d desc %lx dlen %d\n",
+				shdom, nae_cfg->shinfo[shdom].domid, owner_replenish,
+				(long)paddr_info, paddr_info_len, (long)desc_info, desc_info_len);
 
 		if(!owner_replenish)
 			continue;
@@ -352,30 +357,46 @@ static int nlm_configure_shared_freein_fifo(int node,
 err_exit:
 	return err;
 }
-#endif
 
 static int initialize_nae_per_node(nae_t * nae_cfg, uint32_t *phys_cpu_map, int mode,
 				   int *jumbo_enabled)
 {
-	int i, len, pos, bitoff, rv = -1, node;
+	int i, len, rv = -1, node;
+	int cpus = 0, nae_id, size = 0;
+	void *mem = NULL;
 
 	if (nae_cfg == NULL)
 		goto err;
 	node = nae_cfg->node;
+	nae_id = nae_cfg->nae_id;
 
 	for (i = 0; i <= NLM_NAE_MAX_SHARED_DOMS; i++) {
-		lnx_shinfo[i].valid = nae_cfg->shinfo[i].valid;
-		lnx_shinfo[i].rxvc = nae_cfg->shinfo[i].rxvc;
-		lnx_shinfo[i].domid = nae_cfg->shinfo[i].domid;
-		memcpy(&lnx_shinfo[i].lcpu_2_pcpu_map,
-			nae_cfg->shinfo[i].lcpu_2_pcpu_map,
-			sizeof(nae_cfg->shinfo[i].lcpu_2_pcpu_map));
-		memcpy(&lnx_shinfo[i].cpu_2_freeinfifo_map,
-			nae_cfg->shinfo[i].cpu_2_freeinfifo_map,
-			sizeof(nae_cfg->shinfo[i].cpu_2_freeinfifo_map));
+		 cpus += nae_cfg->shinfo[i].num_cpus;
 	}
+	size = ((NLM_NAE_MAX_SHARED_DOMS + 1) * (sizeof(struct nlm_nae_linux_shinfo))) + 
+		(sizeof(unsigned int) * cpus);
+	mem = kmalloc(size, GFP_KERNEL);
+	if(!mem)
+		goto err;
 
-	lnx_normal_mask[node] = nae_cfg->freein_fifo_dom_mask;
+
+	for (i = 0; i <= NLM_NAE_MAX_SHARED_DOMS; i++) {
+		printk("naeid %d shind %d dom %d valid %x numcpus %d\n", nae_id,
+				i, nae_cfg->shinfo[i].domid, nae_cfg->shinfo[i].valid, nae_cfg->shinfo[i].num_cpus);
+		lnx_shinfo[i] = (struct nlm_nae_linux_shinfo *)mem;
+		lnx_shinfo[i]->flags  = nae_cfg->shinfo[i].valid ? NLM_NAE_LNX_SHINFO_FL_VALID : 0;
+		lnx_shinfo[i]->rxvc = nae_cfg->shinfo[i].rxvc;
+		lnx_shinfo[i]->domid = nae_cfg->shinfo[i].domid;
+		lnx_shinfo[i]->num_cpus = nae_cfg->shinfo[i].num_cpus;
+		lnx_shinfo[i]->node = node;
+		for(cpus = 0; cpus < lnx_shinfo[i]->num_cpus; cpus++)  {
+			lnx_shinfo[i]->fwd_info[cpus] = nae_cfg->shinfo[i].fwd_info[cpus];
+			printk("cpu %d value %08x\n", cpus, nae_cfg->shinfo[i].fwd_info[cpus]);
+		}
+		mem += sizeof(struct nlm_nae_linux_shinfo) + (sizeof(unsigned int) * cpus);
+	}
+
+	lnx_frfifo_normal_mask[node][nae_id] = nae_cfg->freein_fifo_dom_mask;
 
 	/* if jumbo enabled , we use half of the linux owned freein fifos
 	 * for jumbo skbs */
@@ -392,35 +413,40 @@ static int initialize_nae_per_node(nae_t * nae_cfg, uint32_t *phys_cpu_map, int
 					mine = 0;
 					continue;
 				}
-				lnx_normal_mask[node] &= (~(1 << i));
-				lnx_jumbo_mask[node] |= (1 << i);
+				lnx_frfifo_normal_mask[node][nae_id] &= (~(1 << i));
+				lnx_frfifo_jumbo_mask[node][nae_id] |= (1 << i);
 				mine = 1;
 			}
 		}
 
-		if (lnx_jumbo_mask[node]) {
-//TODO: Jumbo not enabled
-#if 0
-			nlm_hal_derive_cpu_to_freein_fifo_map(node,
-				phys_cpu_map[node], lnx_normal_mask[node],
-				cpu_2_normal_frfifo[node]);
-			nlm_hal_derive_cpu_to_freein_fifo_map(node,
-				phys_cpu_map[node], lnx_jumbo_mask[node],
-				cpu_2_jumbo_frfifo[node]);
-#endif
-			memset(lnx_shinfo[0].cpu_2_freeinfifo_map,
-				0, sizeof(lnx_shinfo[0].cpu_2_freeinfifo_map));
-
-			for (i = 0; i < NLM_NCPUS_PER_NODE; i++) {
-				pos = i / NLM_NAE_SH_LCPU_TO_MAP_SZ;
-				bitoff = (i %
-					NLM_NAE_SH_LCPU_TO_MAP_NVALS_PER_ENTRY)
-					* NLM_NAE_SH_LCPU_TO_MAP_SNG_VAL_SZ;
-				lnx_shinfo[0].cpu_2_freeinfifo_map[pos] |=
-					(cpu_2_normal_frfifo[node][i] <<
-						bitoff);
-				lnx_shinfo[0].cpu_2_jumbo_freeinfifo_map[pos] |=
-					(cpu_2_jumbo_frfifo[node][i] << bitoff);
+		if (lnx_frfifo_jumbo_mask[node][nae_id]) {
+			for(cpus = 0; cpus < lnx_shinfo[0]->num_cpus; cpus++) {
+				lcpu_2_pcpu[cpus] = (lnx_shinfo[0]->fwd_info[cpus] >> 
+					NLM_NAE_LNX_SHINFO_FWD_INFO_LCPU_2_PCPU_OFF) &
+					NLM_NAE_LNX_SHINFO_FWD_INFO_LCPU_2_PCPU_MASK;
+			}
+			memset(fmem, 0, sizeof(fmem));
+			if(derive_cpu_to_freein_fifo_map(nae_cfg->frin_total_queue, 
+						   lnx_shinfo[0]->num_cpus,
+						   fmem, sizeof(fmem),
+			               lcpu_2_pcpu, lnx_frfifo_normal_mask[node][nae_id], 
+						   cpu_2_normal_frfifo[node][nae_id]) != 0) {
+				goto err;
+			}
+			memset(fmem, 0, sizeof(fmem));
+			if(derive_cpu_to_freein_fifo_map(nae_cfg->frin_total_queue, 
+						   lnx_shinfo[0]->num_cpus,
+						   fmem, sizeof(fmem),
+			               lcpu_2_pcpu, lnx_frfifo_jumbo_mask[node][nae_id], 
+						   cpu_2_jumbo_frfifo[node][nae_id]) != 0) {
+				goto err;
+			}
+
+			for(cpus = 0; cpus < lnx_shinfo[0]->num_cpus; cpus++) {
+				lnx_shinfo[0]->fwd_info[cpus] =  
+					(lcpu_2_pcpu[cpus] << NLM_NAE_LNX_SHINFO_FWD_INFO_LCPU_2_PCPU_OFF) |
+					(cpu_2_normal_frfifo[node][nae_id][cpus] << NLM_NAE_LNX_SHINFO_FWD_INFO_LCPU_2_RF_OFF)|
+					(cpu_2_jumbo_frfifo[node][nae_id][cpus] << NLM_NAE_LNX_SHINFO_FWD_INFO_LCPU_2_JF_OFF);
 			}
 		} else {
 			printk("freein-fifo unavailable: ");
@@ -428,29 +454,28 @@ static int initialize_nae_per_node(nae_t * nae_cfg, uint32_t *phys_cpu_map, int
 			*jumbo_enabled = 0;
 		}
 	} else if (*jumbo_enabled == 0) {
-		for (i = 0; i < NLM_NCPUS_PER_NODE; i++) {
-			pos = i / NLM_NAE_SH_LCPU_TO_MAP_SZ;
-			bitoff = (i % NLM_NAE_SH_LCPU_TO_MAP_NVALS_PER_ENTRY) *
-				NLM_NAE_SH_LCPU_TO_MAP_SNG_VAL_SZ;
-			cpu_2_normal_frfifo[node][i] =
-				(lnx_shinfo[0].cpu_2_freeinfifo_map[pos] >>
-					bitoff) & 0x1f;
+		for(cpus = 0; cpus < lnx_shinfo[0]->num_cpus; cpus++) {
+			cpu_2_normal_frfifo[node][nae_id][cpus] =
+				(lnx_shinfo[0]->fwd_info[cpus] >> NLM_NAE_LNX_SHINFO_FWD_INFO_LCPU_2_RF_OFF) &
+				NLM_NAE_LNX_SHINFO_FWD_INFO_LCPU_2_RF_MASK;
 		}
 	}
 
-	lnx_shinfo[0].mode = nae_cfg->port_fifo_en ? NLM_PORT_FIFO_EN : 0;
+	lnx_shinfo[0]->mode = nae_cfg->port_fifo_en ? NLM_PORT_FIFO_EN : 0;
 #ifdef CONFIG_NLM_ENABLE_LOAD_BALANCING
 	if(mode == NLM_TCP_MODE)
-		lnx_shinfo[0].mode |= NLM_TCP_LOAD_BALANCE_MODE;
+		lnx_shinfo[0]->mode |= NLM_TCP_LOAD_BALANCE_MODE;
 	else
 #endif
-	lnx_shinfo[0].mode |= mode;
-	lnx_shinfo[0].jumbo_enabled = *jumbo_enabled;
-	lnx_shinfo[0].node = node;
+	lnx_shinfo[0]->mode |= mode;
+	lnx_shinfo[0]->flags |= (*jumbo_enabled) ? NLM_NAE_LNX_SHINFO_FL_JUMBO_EN : 0;
 	if (nae_cfg->owned) {
-		netsoc_write_ucore_shmem(nae_cfg,
-			(uint32_t *)lnx_shinfo,
-			sizeof(lnx_shinfo)/sizeof(uint32_t));
+		if(netsoc_write_ucore_shmem(nae_cfg,
+			(uint32_t *)lnx_shinfo[0],  size/sizeof(uint32_t)) != 0) {
+			printk("Error, Write ucore sram failed!!!, size %d\n", size);
+		} else 
+			printk("Write ucore sram success, size %d\n", size);
+
 		netsoc_restart_ucore_using_fdt(nae_cfg, fdt);
 	}
 
@@ -471,8 +496,8 @@ static int initialize_nae_per_node(nae_t * nae_cfg, uint32_t *phys_cpu_map, int
 		netsoc_init_ingress (nae_cfg,
 			(len + ETH_DATA_LEN) & ~(SMP_CACHE_BYTES - 1));
 
-	//if (nlm_configure_shared_freein_fifo(node, nae_cfg) != 0)
-	//	goto err;
+	if (nlm_configure_shared_freein_fifo(node, nae_cfg) != 0)
+		goto err;
 
 	init_dummy_entries_for_port_fifos(nae_cfg);
 
@@ -488,6 +513,21 @@ static int initialize_nae_per_node(nae_t * nae_cfg, uint32_t *phys_cpu_map, int
 								  nae_cfg->shinfo[0].rxvc);
 	}
 
+#if 1
+	for (i = 0; i <= NLM_NAE_MAX_SHARED_DOMS; i++) {
+		printk("naeid %d domid %d node %d flag %x\n", nae_id, 
+				lnx_shinfo[i]->domid, lnx_shinfo[i]->node, lnx_shinfo[i]->flags);
+		for(cpus = 0; cpus < lnx_shinfo[i]->num_cpus; cpus++) {
+			printk("lcpu %d value %08x (pcpu %d rxfifo %d jfifo %d)\n",
+					cpus, lnx_shinfo[i]->fwd_info[cpus],
+					(lnx_shinfo[i]->fwd_info[cpus] >> NLM_NAE_LNX_SHINFO_FWD_INFO_LCPU_2_PCPU_OFF) & 0xff ,
+					(lnx_shinfo[i]->fwd_info[cpus] >> NLM_NAE_LNX_SHINFO_FWD_INFO_LCPU_2_RF_OFF) & 0xff,
+					(lnx_shinfo[i]->fwd_info[cpus] >> NLM_NAE_LNX_SHINFO_FWD_INFO_LCPU_2_JF_OFF) & 0xff);
+		}
+	}
+#endif
+
+
 #if 0
 	if (is_nlm_xlp2xx()) {
 		nlm_hal_msec_tx_default_config(node,
@@ -505,6 +545,11 @@ static int initialize_nae_per_node(nae_t * nae_cfg, uint32_t *phys_cpu_map, int
 	rv = 0;
 
 err:
+	if(lnx_shinfo[0]) {
+		kfree(lnx_shinfo[0]);
+		lnx_shinfo[0] = NULL;
+	}
+
 	return rv;
 }
 
@@ -549,6 +594,7 @@ int initialize_nae(uint32_t *phys_cpu_map, int mode, int *jumbo_enabled)
 		return -1;
 	}
 	printk("DONE WITH INIT NETSOC #######\n");
+
 	/*get max nae*/
 	max_nae_units = get_num_nae_pernode();
 	for (node = 0; node < NLM_MAX_NODES; node++) {
@@ -560,6 +606,7 @@ int initialize_nae(uint32_t *phys_cpu_map, int mode, int *jumbo_enabled)
 	}
 
 	msgrng_access_disable(mflags);
+	printk("%s done\n", __FUNCTION__);
 	return 0;
 }
 
@@ -575,7 +622,7 @@ static int nlm_replenish_per_cpu_buffer(nae_t* nae_cfg,
 	int size = NLM_RX_ETH_BUF_SIZE;
 	int node = nae_cfg->node;
 
-	if ((1 << qindex) & lnx_jumbo_mask[node])
+	if ((1 << qindex) & lnx_frfifo_jumbo_mask[node][nae_cfg->nae_id])
 		size = NLM_RX_JUMBO_BUF_SIZE;
 
 	/* For queue index 16 and 17, we still use  the port level descriptor info */
@@ -630,7 +677,7 @@ static int nlm_replenish_per_cpu_buffer(nae_t* nae_cfg,
 
 int replenish_freein_fifos(void)
 {
-	int node, i, rv = 0;
+	int node, i, rv = 0, nae_id;
 	nae_t* nae_cfg;
 	int max_descs_pqueue, num_descs, max_nae_units;
 	unsigned int blk_cmplx_map, cmplx;
@@ -644,7 +691,7 @@ int replenish_freein_fifos(void)
 			nae_cfg = get_nae(node, num_nae);
 			if (nae_cfg == NULL)
 				continue;
-
+			nae_id = nae_cfg->nae_id;
 			/* Xaui/rxaui/interlaken uses only one fifo per complex */
 			blk_cmplx_map = nae_cfg->xaui_complex_map |  nae_cfg->rxaui_complex_map |
 				nae_cfg->ilk_complex_map | nae_cfg->xlgmac_complex_map;
@@ -666,9 +713,9 @@ int replenish_freein_fifos(void)
 				 will be filled with jumbo packets as the ucore cannot select
 				 the fifos */
 				if(nae_cfg->port_fifo_en) {
-					if(lnx_jumbo_mask[node]) {
-						lnx_jumbo_mask[node] |= lnx_normal_mask[node];
-						lnx_normal_mask[node] = 0;
+					if(lnx_frfifo_jumbo_mask[node][nae_id]) {
+						lnx_frfifo_jumbo_mask[node][nae_id] |= lnx_frfifo_normal_mask[node][nae_id];
+						lnx_frfifo_normal_mask[node][nae_id] = 0;
 					}
 
 					cmplx = i / MAX_PORTS_PERBLOCK;
@@ -678,12 +725,12 @@ int replenish_freein_fifos(void)
 					}
 				}
 
-				if ((1 << i) & lnx_normal_mask[node])
+				if ((1 << i) & lnx_frfifo_normal_mask[node][nae_id])
 					num_descs = (ndescs_nq <=
 						max_descs_pqueue) ?
 						ndescs_nq :
 						max_descs_pqueue;
-				else if ((1 << i) & lnx_jumbo_mask[node])
+				else if ((1 << i) & lnx_frfifo_jumbo_mask[node][nae_id])
 					num_descs = (ndescs_jq <=
 						max_descs_pqueue) ?
 						ndescs_jq :
@@ -889,40 +936,43 @@ uint16_t pseuodo_chksum(uint16_t *ipsrc, uint16_t proto)
 	return (uint16_t)sum;
 }
 
-#if 0
-static void nlm_enable_l3_l4_parser(int node)
+static void nlm_enable_l3_l4_parser(nae_t *nae)
 {
-	int l2proto = 1; //ethernet
-	int port = 0, i, ipchk = 1;
-	uint32_t val = 0;
-	uint32_t naereg;
-
-	//enabling hardware parser
-	naereg = nlm_hal_read_nae_reg(node, RX_CONFIG);
-	nlm_hal_write_nae_reg(node, RX_CONFIG, (naereg | RX_PARSER_EN << 12 |
-		RX_PPAD_EN << 13 | RX_PPAD_SZ << 22));
-
-	/* enabling extraction of data */
-	for (i = 0; i < 16; i++)
-		nlm_hal_write_nae_reg(node, L2_TYPE_0 + i, l2proto);
-
-	/* l2proto and ethertype included */
-	nlm_hal_write_nae_reg(node, L3_CTABLE_MASK_0, port | 0 << 5 | 1 << 6);
-
-	val = ((0 << 26) | (9 << 20) | (ipchk << 18) | (1 << 16) | (0x800));
-	nlm_hal_write_nae_reg(node, L3_CTABLE_0_0, val);
-	/* extract src-ip and dst-ip */
-	val =   (12 << 26) | (4 << 21) | (16 << 15) | (4 << 10);
-	nlm_hal_write_nae_reg(node, L3_CTABLE_0_1, val);
-
-	/* ip proto = tcp */
-	nlm_hal_write_nae_reg(node, L4_CTABLE_0_0, 1 << 17 | 0x6);
-	/* extract source and dst port */
-	val = ((0 << 21) | (2 << 17) | (2 << 11) | (2 << 7));
-	nlm_hal_write_nae_reg(node, L4_CTABLE_0_1, val);
+	
+	l2_parser_config_t l2;
+	l3_parser_config_t l3;
+	l4_parser_config_t l4;
+
+	memset(&l2, 0, sizeof(l2));
+	memset(&l3, 0, sizeof(l3));
+	memset(&l4, 0, sizeof(l4));
+
+	l2.l2_proto = 1;
+	netsoc_config_nae_l2parser(nae, &l2);
+
+	l3.l2_proto_eth_mask =1;
+	l3.l3_hdr_off=0;
+	l3.l4_proto_off=9;
+	l3.l4_extract_en = 1;
+	l3.l2_proto = 1;
+	l3.eth_type = 0x800;
+	l3.l3_hdr_off0=12;
+	l3.l3_hdr_len0=4;
+	l3.l3_hdr_off1=16;
+	l3.l3_hdr_len1=4;
+	netsoc_config_nae_l3parser(nae, &l3, 0);
+	
+	l4.l4_proto_mask = 1;
+	l4.l4_proto = 0x6;
+	l4.l4_hdr_off0 = 0;
+	l4.l4_hdr_len0= 2;
+	l4.l4_hdr_off1 = 2;
+	l4.l4_hdr_len1= 2;
+	netsoc_config_nae_l4parser(nae, &l4, 0);
+
+	netsoc_enable_nae_hwparser(nae);
 
 }
-#endif
 
 #ifdef CONFIG_NLM_NET_OPTS
 /* Get the hardware replenishment queue id */
@@ -962,9 +1012,10 @@ int mac_refill_frin_skb(nae_t* nae_cfg, int cpu, uint64_t paddr,
 	 * indexed by logical cpu id
 	 */
 	int ret, code, qid;
-	int node_cpu = __cpu_number_map[cpu] % NLM_NCPUS_PER_NODE;
+	int node_cpu = __cpu_number_map[cpu] % num_cpus_per_node;
 	ulong __attribute__ ((unused)) mflags;
 	int node = nae_cfg->node;
+	int nae_id = nae_cfg->nae_id;
 
 	if (nae_cfg == NULL) {
 		printk("%s Error, Invalid node id %d\n", __FUNCTION__, node);
@@ -975,8 +1026,8 @@ int mac_refill_frin_skb(nae_t* nae_cfg, int cpu, uint64_t paddr,
 		qid = hw_port_id;
 	else
 		qid = (bufsize >= NLM_RX_JUMBO_BUF_SIZE) ?
-		cpu_2_jumbo_frfifo[node][node_cpu] :
-		cpu_2_normal_frfifo[node][node_cpu];
+		cpu_2_jumbo_frfifo[node][nae_id][node_cpu] :
+		cpu_2_normal_frfifo[node][nae_id][node_cpu];
 
 	Message("%s in cpu %d bufsize %d node %d qid %d qbase %d\n",
 		__FUNCTION__, cpu, bufsize, node, qid,
@@ -1048,7 +1099,7 @@ static int  nlm_xlp_nae_open (struct net_device *dev)
 #endif
 		if (!done) {
 			done = 1;
-			//nlm_enable_l3_l4_parser(nae_cfg);
+			nlm_enable_l3_l4_parser(nae_cfg);
 		}
 	}
 
@@ -1423,7 +1474,7 @@ static int nlm_per_port_nae_init(nae_t* nae_cfg, int port, int maxnae)
 		return -1;
 
 	dev = alloc_etherdev_mq(sizeof(struct dev_data),
-		maxnae * NLM_NCPUS_PER_NODE);
+		maxnae * num_cpus_per_node);
 	if(!dev)
 		return -1;
 
@@ -1497,6 +1548,17 @@ static int nlm_per_port_nae_init(nae_t* nae_cfg, int port, int maxnae)
 	return 0;
 }
 
+static inline int get_num_cpus_per_node(void)
+{
+
+	if (is_nlm_xlp9xx())
+		return  XLP9XX_NCPUS_PER_NODE;
+	else
+		return XLP_NCPUS_PER_NODE;
+}
+
+
+
 /**********************************************************************
  * nlm_xlp_nae_init -  xlp_nae device driver init function
  * @dev  -  this is per device based function
@@ -1530,6 +1592,8 @@ void nlm_xlp_nae_init(void)
 			(1 << (i % NLM_NCPUS_PER_NODE));
 	}
 
+	num_cpus_per_node = get_num_cpus_per_node();
+
 	if (perf_mode == NLM_TCP_MODE)
 		p2p_desc_mem_init();
 
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_rx.c b/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
index 224c122..9cc4576 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
@@ -933,7 +933,6 @@ void nlm_spawn_kthread(void)
     char buf[20];
     static struct task_struct *task[NR_CPUS];
 
-    //nr_cpus = nlm_node_cfg.num_nodes * NLM_NCPUS_PER_NODE;	
 	//TODO:	
 	nr_cpus = 4*32;
     /*Spawn kthread*/
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_tso.c b/drivers/net/ethernet/broadcom/nae/xlpge_tso.c
index 7c6793d..a2e6ad9 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_tso.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_tso.c
@@ -244,7 +244,7 @@ inline int tso_xmit_skb(struct sk_buff *skb, struct net_device *dev)
 	}
 
 
-	qid = nae_cfg->vfbtbl_sw_offset + (cpu % NLM_NCPUS_PER_NODE);
+	qid = nae_cfg->vfbtbl_sw_offset + (cpu % num_cpus_per_node);
 	{
 		create_last_p2p_desc(p2pdesc, skb, idx);
 		msg = nae_tx_desc(DESC_TYPE_P2P, qid, idx, virt_to_bus(p2pdesc));
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_tx.c b/drivers/net/ethernet/broadcom/nae/xlpge_tx.c
index b39ad84..b8a11e5 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_tx.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_tx.c
@@ -158,7 +158,7 @@ int nlm_xlp_nae_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	else 
 #endif
 	{
-		qid = nae_cfg->vfbtbl_sw_offset + (cpu % NLM_NCPUS_PER_NODE);
+		qid = nae_cfg->vfbtbl_sw_offset + (cpu % num_cpus_per_node);
 		msg0 = nae_tx_desc(DESC_TYPE_P2DNEOP, qid, 0, virt_to_bus(skb));
 
 		Message("Tx, tx complete to cpu, cpu %d len %d qid %d\n",
-- 
1.7.1

