From 8c6047357e0be44a8791777c1259b4c0322f3152 Mon Sep 17 00:00:00 2001
From: Vikas Gupta <vikas.gupta@broadcom.com>
Date: Thu, 23 May 2013 12:50:34 +0530
Subject: nae: modified nae driver to work with netlib, syslib and fmnlib.

        1) Verified items:
                Packet transfer over SGMII and XAUI with perf_mode=2 on xlp2xx.
        2) Verified with ping.

     TODO items:
        1) Verify/Fix with perf_mode=1 and  verify LRO and TSO support.
        2) Enable/Verify/Fix  Load balancer.
        3) Fix fifo configuration for shared domain(s).
        4) Enable HW address setting.
        5) Enable Jumbo for xlp8xx,xlp3xx and xlp3xx.
        6) Add MSEC support.
        7) Add/Enable PHY timer support.
        8) Statistics not shown in ifconfig command.
[Based on SDK 3.2]
Signed-off-by: Quanyang Wang <quanyang.wang@windriver.com>
Signed-off-by: Nam Ninh <nam.ninh@windriver.com>

diff --git a/drivers/net/ethernet/broadcom/nae/xlpge.h b/drivers/net/ethernet/broadcom/nae/xlpge.h
index f8f9ad0..b6ddf94 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge.h
+++ b/drivers/net/ethernet/broadcom/nae/xlpge.h
@@ -30,7 +30,15 @@
 #ifndef	__XLPGE_H__
 #define	__XLPGE_H__
 #include <asm/atomic.h>
-#include <nlm_hal_nae.h>
+//#include <nlm_hal_nae.h>
+#include "netsoc_nae.h"
+#include "netsoc_haliface.h"
+#include "netsoc_msg.h"
+#include "netsoc_msgiface.h"
+#include "netsoc_libiface.h"
+#include "nlm_nae.h"
+#include "ext_phy.h"
+#include "nlm_msgring.h"
 
 #define	XLP_SOC_MAC_DRIVER		"mac-xlp"
 #define DRV_VERSION			"0.2"
@@ -254,6 +262,8 @@ struct dev_data
 	struct cpu_stat cpu_stats[NR_CPUS];
 	struct timer_list link_timer;
 	struct napi_struct napi;
+	nae_t* nae;
+	net_port_t *nae_port;
 	spinlock_t lock;
 	unsigned short port;
 	unsigned short inited;
@@ -309,17 +319,6 @@ struct p2p_desc_mem {
 
 extern void *fdt;
 
-static __inline__ uint64_t nae_tx_desc(uint32_t type, uint32_t rdex,
-                                       uint32_t fbid, uint32_t len,
-                                       uint64_t addr)
-{
-	return ((uint64_t)(type & 0x3) << 62)		|
-		((uint64_t)(rdex & 0x1) << 61)		|
-		((uint64_t)(fbid & 0x7f) << 54)		|
-		((uint64_t)(len & 0x3fff) << 40)	|
-		(addr & 0xffffffffffULL);
-}
-
 static __inline__ void cpu_halt(void)
 {
 	__asm__ volatile (
@@ -452,7 +451,7 @@ int nae_proc_read(char *, char **, off_t , int , int *, void *);
 int nlm_xlp_disable_napi(void);
 void nlm_spawn_kthread(void);
 int nlm_xlp_enable_napi(void);
-int mac_refill_frin_skb(int , int , uint64_t , uint32_t, int);
+int mac_refill_frin_skb(nae_t* , int , uint64_t , uint32_t, int);
 int mac_refill_frin_one_buffer(struct net_device *, int , uint32_t);
 void xlp_napi_lro_flush(void *);
 void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag);
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_ethtool.c b/drivers/net/ethernet/broadcom/nae/xlpge_ethtool.c
index 1f622fc..d515428 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_ethtool.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_ethtool.c
@@ -76,6 +76,7 @@ static struct {
 static int xlp_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
 {
 	struct dev_data *priv = netdev_priv(dev);
+	net_port_t* nae_port = priv->nae_port;
 	struct nlm_hal_mii_info mii_info;
 	if (priv->type != SGMII_IF) {
 		cmd->supported = SUPPORTED_FIBRE | SUPPORTED_10000baseT_Full;
@@ -102,15 +103,17 @@ static int xlp_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
 
 	cmd->advertising = priv->advertising;
 
-	nlm_hal_status_ext_phy( priv->node, priv->phy.addr, &mii_info);
-        priv->speed = mii_info.speed;
-        cmd->duplex = mii_info.duplex;
+	//nlm_hal_status_ext_phy( priv->node, priv->phy.addr, &mii_info);
+	netsoc_get_phy_status(nae_port, &cmd->duplex, &cmd->speed);
+        //priv->speed = mii_info.speed;
+        //cmd->duplex = mii_info.duplex;
 	cmd->speed = (priv->speed == xlp_mac_speed_1000) ? SPEED_1000 :
 			(priv->speed == xlp_mac_speed_100) ?
 				SPEED_100 : SPEED_10;
 
 	cmd->port = PORT_TP;
-	cmd->phy_address = mii_info.phyaddr;
+	//cmd->phy_address = mii_info.phyaddr;
+	cmd->phy_address = priv->phy.addr;
 	cmd->transceiver = XCVR_INTERNAL;
 	cmd->autoneg  = 1; /*Autoneg is always enabled by default*/ 
 	cmd->maxtxpkt = 0;
@@ -210,10 +213,12 @@ static void xlp_get_regs(struct net_device *dev,
 	memset((void *)data, 0, NLM_ETHTOOL_REG_LEN);
 
 	spin_lock_irqsave(&priv->lock, flags);
-
+//TODO:
+#if 0
 	for(i=0; i <= NLM_NUM_REG_DUMP; i++)
 		*(data + i) = nlm_hal_read_mac_reg(priv->node, priv->block,
 					priv->index, R_TX_CONTROL + i);
+#endif
 
 	spin_unlock_irqrestore(&priv->lock, flags);
 }
@@ -242,8 +247,8 @@ static int xlp_nway_reset(struct net_device *dev)
 
 	mii_status = nlm_xlp_mac_mii_read(priv, MII_BMCR);
 	if (mii_status & BMCR_ANENABLE) {
-		nlm_xlp_mac_mii_write(priv, MII_BMCR,
-				BMCR_ANRESTART | mii_status);
+		//nlm_xlp_mac_mii_write(priv, MII_BMCR,
+		//		BMCR_ANRESTART | mii_status);
 		ret = 0;
 	}
 
@@ -261,7 +266,7 @@ static u32 xlp_get_link(struct net_device *dev)
 		return -EIO;
 
 	spin_lock_irqsave(&priv->lock, flags);
-	nlm_hal_status_ext_phy( priv->node, priv->phy.addr, &mii_info);
+	//nlm_hal_status_ext_phy( priv->node, priv->phy.addr, &mii_info);
 
 	spin_unlock_irqrestore(&priv->lock, flags);
 
@@ -285,16 +290,18 @@ static void xlp_get_strings (struct net_device *dev, u32 stringset, u8 *buf)
 	}
 }
 
-#define STATS_RD(x)		\
-	nlm_hal_read_mac_reg(priv->node, priv->block, priv->index, x)
+//#define STATS_RD(x)		\
+//	nlm_hal_read_mac_reg(priv->node, priv->block, priv->index, x)
 
 /**********************************************************************
  * xlp_get_mac_stats -  collect stats info from Mac stats register
  * @dev   -  this is per device based function
  * @stats -  net device stats structure
  **********************************************************************/
+
 void xlp_get_mac_stats(struct net_device *dev, struct net_device_stats *stats)
 {
+#if 0
 	struct dev_data *priv = netdev_priv(dev);
 #ifdef CONFIG_64BIT
 	uint64_t val;
@@ -358,6 +365,7 @@ void xlp_get_mac_stats(struct net_device *dev, struct net_device_stats *stats)
 	stats->tx_fifo_errors = STATS_RD(TX_DROP_FRAME_COUNTER);
 	*/
 	return;
+#endif
 }
 
 #undef STATS_RD
@@ -377,7 +385,8 @@ static void xlp_get_ethtool_stats (struct net_device *dev,
 
 	spin_lock_irqsave(&priv->lock, flags);
 
-	xlp_get_mac_stats(dev, &priv->stats);
+//TODO:
+	//xlp_get_mac_stats(dev, &priv->stats);
 
 	spin_unlock_irqrestore(&priv->lock, flags);
 
@@ -402,8 +411,9 @@ static void xlp_get_ethtool_stats (struct net_device *dev,
  ********************************************************************* */
 unsigned int nlm_xlp_mac_mii_read(struct dev_data *priv, int regidx)
 {
-	return nlm_hal_mdio_read(priv->node, NLM_HAL_EXT_MDIO, 0,
-		BLOCK_7, LANE_CFG, priv->phy.addr, regidx);
+//TODO:
+	//return nlm_hal_mdio_read(priv->node, NLM_HAL_EXT_MDIO, 0,
+	//	BLOCK_7, LANE_CFG, priv->phy.addr, regidx);
 }
 
 /**********************************************************************
@@ -420,8 +430,9 @@ unsigned int nlm_xlp_mac_mii_read(struct dev_data *priv, int regidx)
 void nlm_xlp_mac_mii_write(struct dev_data *priv, int regidx,
 				  uint16_t regval)
 {
-	nlm_hal_mdio_write(priv->node, NLM_HAL_EXT_MDIO, 0, BLOCK_7,
-		LANE_CFG, priv->phy.addr, regidx, regval);
+//TODO:
+//	nlm_hal_mdio_write(priv->node, NLM_HAL_EXT_MDIO, 0, BLOCK_7,
+//		LANE_CFG, priv->phy.addr, regidx, regval);
 }
 
 static struct ethtool_ops xlp_ethtool_ops = {
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_main.c b/drivers/net/ethernet/broadcom/nae/xlpge_main.c
index 358d7b1..415444e 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_main.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_main.c
@@ -69,7 +69,7 @@ static int __init brcmxlp_nae_init(void)
 	xlpge_eeprom_init();
 	/* TODO:XXX Move to pci init? */
 	nlm_xlp_nae_init();
-	init_phy_state_timer(NULL);
+	//init_phy_state_timer(NULL);
 
 	return pci_register_driver(&brcmxlp_nae_driver);
 }
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_nae.c b/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
index 8ca0da2..49a0115 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_nae.c
@@ -36,10 +36,10 @@
 #include <linux/timecompare.h>
 #include <linux/proc_fs.h>
 #include <linux/timer.h>
-#include <nlm_xlp.h>
-#include <nlm_msgring.h>
-#include <nlm_hal_fmn.h>
-#include <nlm_eeprom.h>
+//#include <nlm_xlp.h>
+//#include <nlm_msgring.h>
+//#include <nlm_hal_fmn.h>
+//#include <nlm_eeprom.h>
 
 #include "xlpge.h"
 
@@ -60,6 +60,7 @@ module_param(load_balance_timer_run, int, S_IRUGO|S_IWUSR);
 int enable_napi = 1;
 int nlm_prepad_len = 0;
 int perf_mode= NLM_TCP_MODE;
+extern cpumask_t phys_cpu_present_map;
 module_param(perf_mode, int, 0);
 /* Descriptors for each normal fifo. For xaui ports, if port fifo mode 
    is enabled, this will be multiplied by 4 (3 fifos are unused) */
@@ -105,8 +106,7 @@ static unsigned short nlm_select_queue(struct net_device *dev,
  * the port fifos ( 0, 4, 8, 12 & 16) with some dummy entries if it is not
  * owned by anyone.
  */
-static int init_dummy_entries_for_port_fifos(int node,
-					     nlm_nae_config_ptr nae_cfg)
+static int init_dummy_entries_for_port_fifos(nae_t* nae_cfg)
 {
 	struct sk_buff *skb;
 	static uint64_t msg;
@@ -114,6 +114,7 @@ static int init_dummy_entries_for_port_fifos(int node,
 	uint32_t fifo_mask = 0;
 	int rv = 0, vc_index = 0, i, j, ret, code = 0, shdom;
 	int size = NLM_RX_JUMBO_BUF_SIZE;
+	int node = nae_cfg->node;
 
 	skb = nlm_xlp_alloc_skb_atomic(size, node);
 	if (!skb) {
@@ -127,13 +128,15 @@ static int init_dummy_entries_for_port_fifos(int node,
 	for (shdom = 0; shdom <= NLM_NAE_MAX_SHARED_DOMS; shdom++) {
 		if (!nae_cfg->shinfo[shdom].valid)
 			continue;
-
-		fifo_mask |= nlm_hal_retrieve_freein_fifo_mask(fdt, node,
-				nae_cfg->shinfo[shdom].domid);
+		//TODO:
+		//fifo_mask |= nlm_hal_retrieve_freein_fifo_mask(fdt, node,
+		//		nae_cfg->shinfo[shdom].domid);
+		fifo_mask = nae_cfg->freein_fifo_dom_mask;
+		printk("OOPppS nlm_hal_retrieve_freein_fifo_mask not ye called fifo_mask=0x%x\n", fifo_mask);
 	}
 
-	msgrng_access_enable(mflags);
-
+//	msgrng_access_enable(mflags);
+	printk("Total free ins = 0x%x\n", nae_cfg->frin_total_queue);
 	for (i = 0; i < nae_cfg->frin_total_queue; i++) {
 		/* nothing to do, if it is owned by some domain */
 		if((1 << i) & fifo_mask)
@@ -146,8 +149,11 @@ static int init_dummy_entries_for_port_fifos(int node,
 		vc_index = i + nae_cfg->frin_queue_base;
 
 		for (j = 0; j < 4; j++) {
-			__sync();
-			if ((ret = nlm_hal_send_msg1(vc_index, code, msg))
+			//netsoc_nae_send_freein_buf(nae_cfg, vc_index, msg);
+//#if 0
+				printk("Sending message check freein carving (qid=%d)\n",
+					vc_index);
+			if ((ret = xlp_message_send_1(vc_index, code, msg))
 				& 0x7) {
 				print_fmn_send_error(__func__, ret);
 				printk("Unable to send configured free desc\n");
@@ -156,12 +162,13 @@ static int init_dummy_entries_for_port_fifos(int node,
 				rv = -1;
 				goto err;
 			}
+//#endif
 		}
 		printk("Send %d dummy descriptors for queue %d(vc %d) of length %d\n",
 			j, i, vc_index, size);
 	}
 err:
-	msgrng_access_disable(mflags);
+	//msgrng_access_disable(mflags);
 
 	/* if not used */
 	if(!vc_index)
@@ -170,12 +177,13 @@ err:
 }
 
 
-static int nlm_initialize_vfbid(int node, nlm_nae_config_ptr nae_cfg)
+static int nlm_initialize_vfbid(nae_t* nae_cfg)
 {
 	uint32_t vfbid_tbl[128];
 	int start = nae_cfg->vfbtbl_sw_offset;
 	int end = start + nae_cfg->vfbtbl_sw_nentries;
-	int frin_q_base = nlm_node_cfg.nae_cfg[0]->frin_queue_base;
+	int frin_q_base = nae_cfg->frin_queue_base;
+	int node = nae_cfg->node; 
 	int cpu, tblidx, i;
 
 	/*
@@ -186,7 +194,7 @@ static int nlm_initialize_vfbid(int node, nlm_nae_config_ptr nae_cfg)
 		vfbid_tbl[tblidx] = (cpu * 4) + nae_cfg->fb_vc +
 					(node * 1024);
 
-	nlm_config_vfbid_table(node, start, end - start,
+	netsoc_config_vfbid_table(nae_cfg, start, end - start,
 		&vfbid_tbl[start]);
 	/*
 	 * For h/w replenishment, each node fills up 20 entries for all other
@@ -202,15 +210,15 @@ static int nlm_initialize_vfbid(int node, nlm_nae_config_ptr nae_cfg)
 		}
 		vfbid_tbl[tblidx] = frin_q_base + i;
 	}
-	nlm_config_vfbid_table(node, start, end - start, &vfbid_tbl[start]);
+	netsoc_config_vfbid_table(nae_cfg, start, end - start, &vfbid_tbl[start]);
 
 	/* NULL FBID Should map to cpu0 to detect NAE send message errors*/
 	vfbid_tbl[127] = 0;
-	nlm_config_vfbid_table(node, 127, 1, &vfbid_tbl[127]);
+	netsoc_config_vfbid_table(nae_cfg, 127, 1, &vfbid_tbl[127]);
 
 	/*IEEE-1588 timestamp*/
 	vfbid_tbl[126] = 0;
-	nlm_config_vfbid_table(node, 126, 1, &vfbid_tbl[126]);
+	netsoc_config_vfbid_table(nae_cfg, 126, 1, &vfbid_tbl[126]);
 
 	return 0;
 }
@@ -225,6 +233,7 @@ static inline uint32_t fdt32_to_cpu(uint32_t x)
 #endif
 }
 
+#if 0
 static int nlm_configure_shared_freein_fifo(int node,
 					    nlm_nae_config_ptr nae_cfg)
 {
@@ -315,7 +324,7 @@ static int nlm_configure_shared_freein_fifo(int node,
 					msg = paddr + dppadsz;
 
 					__sync();
-					rv = nlm_hal_send_msg1(vc_index, code, msg);
+					rv = xlp_message_send_1(vc_index, code, msg);
 					if(rv & 0x7) {
 						msgrng_access_disable(mflags);
 						printk("Unable to send \
@@ -343,17 +352,16 @@ static int nlm_configure_shared_freein_fifo(int node,
 err_exit:
 	return err;
 }
+#endif
 
-static int initialize_nae_per_node(int node, uint32_t *phys_cpu_map, int mode,
+static int initialize_nae_per_node(nae_t * nae_cfg, uint32_t *phys_cpu_map, int mode,
 				   int *jumbo_enabled)
 {
-	nlm_nae_config_ptr nae_cfg;
 	int i, len, pos, bitoff, rv = -1;
 
-	nae_cfg = nlm_node_cfg.nae_cfg[node];
-
 	if (nae_cfg == NULL)
 		goto err;
+	int node = nae_cfg->node;
 
 	for (i = 0; i <= NLM_NAE_MAX_SHARED_DOMS; i++) {
 		lnx_shinfo[i].valid = nae_cfg->shinfo[i].valid;
@@ -375,7 +383,8 @@ static int initialize_nae_per_node(int node, uint32_t *phys_cpu_map, int mode,
 		int mine = 1;
 
 		/* update rx xon/xoff thresholds for jumbo */
-		nlm_hal_set_context_xon_xoff_threshold(node, ETH_JUMBO_DATA_LEN);
+		//TODO: function is commented in xon xoff thres.
+		//nlm_hal_set_context_xon_xoff_threshold(node, ETH_JUMBO_DATA_LEN);
 
 		for (i = 0; i < nae_cfg->frin_total_queue; i++) {
 			if ((1 << i) & nae_cfg->freein_fifo_dom_mask) {
@@ -390,12 +399,15 @@ static int initialize_nae_per_node(int node, uint32_t *phys_cpu_map, int mode,
 		}
 
 		if (lnx_jumbo_mask[node]) {
+//TODO: Jumbo not enabled
+#if 0
 			nlm_hal_derive_cpu_to_freein_fifo_map(node,
 				phys_cpu_map[node], lnx_normal_mask[node],
 				cpu_2_normal_frfifo[node]);
 			nlm_hal_derive_cpu_to_freein_fifo_map(node,
 				phys_cpu_map[node], lnx_jumbo_mask[node],
 				cpu_2_jumbo_frfifo[node]);
+#endif
 			memset(lnx_shinfo[0].cpu_2_freeinfifo_map,
 				0, sizeof(lnx_shinfo[0].cpu_2_freeinfifo_map));
 
@@ -436,16 +448,16 @@ static int initialize_nae_per_node(int node, uint32_t *phys_cpu_map, int mode,
 	lnx_shinfo[0].jumbo_enabled = *jumbo_enabled;
 	lnx_shinfo[0].node = node;
 	if (nae_cfg->owned) {
-		nlm_hal_write_ucore_shared_mem(node,
+		netsoc_write_ucore_shmem(nae_cfg,
 			(uint32_t *)lnx_shinfo,
 			sizeof(lnx_shinfo)/sizeof(uint32_t));
-		nlm_hal_restart_ucore(node, fdt);
+		netsoc_restart_ucore_using_fdt(nae_cfg, fdt);
 	}
 
 
 	/* initialize my vfbid table */
 	if (!(nae_cfg->flags & VFBID_FROM_FDT))
-		nlm_initialize_vfbid(node, nae_cfg);
+		nlm_initialize_vfbid(nae_cfg);
 
 	if (nae_cfg->owned == 0)
 		goto err;
@@ -453,16 +465,16 @@ static int initialize_nae_per_node(int node, uint32_t *phys_cpu_map, int mode,
 	/* Update RX_CONFIG for desc size */
 	len = (ETH_HLEN + ETH_FCS_LEN + SMP_CACHE_BYTES);
 	if (*jumbo_enabled)
-		nlm_hal_init_ingress (node,
+		netsoc_init_ingress (nae_cfg,
 			(len + ETH_JUMBO_DATA_LEN) & ~(SMP_CACHE_BYTES - 1));
 	else
-		nlm_hal_init_ingress (node,
+		netsoc_init_ingress (nae_cfg,
 			(len + ETH_DATA_LEN) & ~(SMP_CACHE_BYTES - 1));
 
-	if (nlm_configure_shared_freein_fifo(node, nae_cfg) != 0)
-		goto err;
+	//if (nlm_configure_shared_freein_fifo(node, nae_cfg) != 0)
+	//	goto err;
 
-	init_dummy_entries_for_port_fifos(node, nae_cfg);
+	//init_dummy_entries_for_port_fifos(nae_cfg);
 
 #if 0
 	if (is_nlm_xlp2xx()) {
@@ -484,26 +496,62 @@ err:
 	return rv;
 }
 
+static void * allocate_contig_phys(uint32_t align, uint32_t size)
+{
+	void *buf = kmalloc(size + align, GFP_KERNEL);
+        if (buf == NULL)
+                return NULL;
+
+        buf =(void *)(ulong)(CACHELINE_ALIGNED_ADDR((ulong)buf +
+                                align));
+        return buf;
+}
+
+static void *netlib_malloc(uint32_t size)
+{
+	return kmalloc(size, GFP_KERNEL);
+}
+
 int initialize_nae(uint32_t *phys_cpu_map, int mode, int *jumbo_enabled)
 {
 	ulong __attribute__ ((unused)) mflags;
 	int dom_id = 0;
-	int node, ret;
+	int node, ret, max_nae_units, nodes, num_nae;
+	nae_t* nae;
+	struct netsoc_lib_param mod_api;
 
 	msgrng_access_enable(mflags);
+	mod_api.contig_alloc = allocate_contig_phys;
+	mod_api.malloc = NULL;
+	mod_api.phys_to_virt = phys_to_virt;
+	mod_api.virt_to_phys = virt_to_phys;
+	mod_api.readl = NULL;
+	mod_api.writel = NULL;
+	mod_api.free = NULL;
+	mod_api.contig_free = NULL;
+	
+	brcm_netsoc_lib_init(&mod_api);
 
-	nlm_hal_init_nae(fdt, dom_id);
-
+	if (init_netsoc(fdt, dom_id) < 0) {
+                printk("NETSOC initialization failed \n");
+		return -1;
+	}
+	printk("DONE WITH INIT NETSOC #######\n");
+	/*get max nae*/
+	max_nae_units = get_num_nae_pernode();
 	for (node = 0; node < NLM_MAX_NODES; node++) {
-		ret = initialize_nae_per_node(node, phys_cpu_map,
-			mode, jumbo_enabled);
+		for(num_nae=0; num_nae<max_nae_units; num_nae++){
+			nae = get_nae(node, num_nae);
+			ret = initialize_nae_per_node(nae, phys_cpu_map,
+				mode, jumbo_enabled);
+		}
 	}
 
 	msgrng_access_disable(mflags);
 	return 0;
 }
 
-static int nlm_replenish_per_cpu_buffer(int node, nlm_nae_config_ptr nae_cfg,
+static int nlm_replenish_per_cpu_buffer(nae_t* nae_cfg,
 					int qindex, int bufcnt)
 {
 	int i, port;
@@ -513,6 +561,7 @@ static int nlm_replenish_per_cpu_buffer(int node, nlm_nae_config_ptr nae_cfg,
 	struct sk_buff * skb;
 	int ret = 0;
 	int size = NLM_RX_ETH_BUF_SIZE;
+	int node = nae_cfg->node;
 
 	if ((1 << qindex) & lnx_jumbo_mask[node])
 		size = NLM_RX_JUMBO_BUF_SIZE;
@@ -545,7 +594,7 @@ static int nlm_replenish_per_cpu_buffer(int node, nlm_nae_config_ptr nae_cfg,
 		/* Send the packet to nae rx  */
 		__sync();
 
-		if ((ret = nlm_hal_send_msg1(vc_index, code, msg)) & 0x7) {
+		if ((ret = xlp_message_send_1(vc_index, code, msg)) & 0x7) {
 			print_fmn_send_error(__func__, ret);
 			printk("Unable to send configured free desc, ");
 			printk("check freein carving (qid=%d)\n", vc_index);
@@ -570,68 +619,72 @@ static int nlm_replenish_per_cpu_buffer(int node, nlm_nae_config_ptr nae_cfg,
 int replenish_freein_fifos(void)
 {
 	int node, i, rv;
-	nlm_nae_config_ptr nae_cfg;
-	int max_descs_pqueue, num_descs;
+	nae_t* nae_cfg;
+	int max_descs_pqueue, num_descs, max_nae_units;
 	unsigned int blk_cmplx_map, cmplx;
 	unsigned int ndescs_nq, ndescs_jq;
 
+	/*get max nae*/
+	max_nae_units = get_num_nae_pernode();
 	for (node = 0; node < NLM_MAX_NODES; node++) {
-		nae_cfg = nlm_node_cfg.nae_cfg[node];
-		if (nae_cfg == NULL)
-			continue;
+		int num_nae;
+		for(num_nae=0; num_nae<max_nae_units; num_nae++){
+			nae_cfg = get_nae(node, num_nae);
+			if (nae_cfg == NULL)
+				continue;
 
-		/* Xaui/rxaui/interlaken uses only one fifo per complex */
-		blk_cmplx_map = nae_cfg->xaui_complex_map |  nae_cfg->rxaui_complex_map |
-			nae_cfg->ilk_complex_map;
+			/* Xaui/rxaui/interlaken uses only one fifo per complex */
+			blk_cmplx_map = nae_cfg->xaui_complex_map |  nae_cfg->rxaui_complex_map |
+				nae_cfg->ilk_complex_map;
 
-		/* configure the descs */
-		for (i = 0; i < nae_cfg->frin_total_queue; i++) {
-			/* if no onchip space. when port fifo is enabled, 
-			 we will unset all the unused fifo size */
-			if(nae_cfg->freein_fifo_onchip_num_descs[i] == 0)
-				continue;
+			/* configure the descs */
+			for (i = 0; i < nae_cfg->frin_total_queue; i++) {
+				/* if no onchip space. when port fifo is enabled, 
+				 we will unset all the unused fifo size */
+				if(nae_cfg->freein_fifo_onchip_num_descs[i] == 0)
+					continue;
 
-			max_descs_pqueue =
-				nae_cfg->freein_fifo_onchip_num_descs[i] +
-					nae_cfg->freein_fifo_spill_num_descs;
-
-			ndescs_nq = num_descs_per_normalq;
-			ndescs_jq = num_descs_per_jumboq;
-			/* if jumbo enabled and port fifo is enabled, all the fifos
-			 will be filled with jumbo packets as the ucore cannot select
-			 the fifos */
-			if(nae_cfg->port_fifo_en) {
-				if(lnx_jumbo_mask[node]) {
-					lnx_jumbo_mask[node] |= lnx_normal_mask[node];
-					lnx_normal_mask[node] = 0;
-				}
+				max_descs_pqueue =
+					nae_cfg->freein_fifo_onchip_num_descs[i] +
+						nae_cfg->freein_fifo_spill_num_descs;
+
+				ndescs_nq = num_descs_per_normalq;
+				ndescs_jq = num_descs_per_jumboq;
+				/* if jumbo enabled and port fifo is enabled, all the fifos
+				 will be filled with jumbo packets as the ucore cannot select
+				 the fifos */
+				if(nae_cfg->port_fifo_en) {
+					if(lnx_jumbo_mask[node]) {
+						lnx_jumbo_mask[node] |= lnx_normal_mask[node];
+						lnx_normal_mask[node] = 0;
+					}
 
-				cmplx = i / MAX_PORTS_PERBLOCK;
-				if((1 << cmplx) & blk_cmplx_map) {
-					ndescs_nq = num_descs_per_normalq * MAX_PORTS_PERBLOCK;
-					ndescs_jq = num_descs_per_jumboq * MAX_PORTS_PERBLOCK;
+					cmplx = i / MAX_PORTS_PERBLOCK;
+					if((1 << cmplx) & blk_cmplx_map) {
+						ndescs_nq = num_descs_per_normalq * MAX_PORTS_PERBLOCK;
+						ndescs_jq = num_descs_per_jumboq * MAX_PORTS_PERBLOCK;
+					}
 				}
-			}
 
-			if ((1 << i) & lnx_normal_mask[node])
-				num_descs = (ndescs_nq <=
-					max_descs_pqueue) ?
-					ndescs_nq :
-					max_descs_pqueue;
-			else if ((1 << i) & lnx_jumbo_mask[node])
-				num_descs = (ndescs_jq <=
-					max_descs_pqueue) ?
-					ndescs_jq :
-					max_descs_pqueue;
-			else
-				continue;
+				if ((1 << i) & lnx_normal_mask[node])
+					num_descs = (ndescs_nq <=
+						max_descs_pqueue) ?
+						ndescs_nq :
+						max_descs_pqueue;
+				else if ((1 << i) & lnx_jumbo_mask[node])
+					num_descs = (ndescs_jq <=
+						max_descs_pqueue) ?
+						ndescs_jq :
+						max_descs_pqueue;
+				else
+					continue;
 
-			rv = nlm_replenish_per_cpu_buffer(node, nae_cfg,
-				i, num_descs);
+				rv = nlm_replenish_per_cpu_buffer(nae_cfg, i, num_descs);
+			}
+			if(rv != 0)
+				break;
+			}
 		}
-		if(rv != 0)
-			break;
-	}
 	return rv;
 }
 
@@ -655,6 +708,7 @@ void nlm_xlp_nae_remove(void)
 	nlm_nae_remove_procentries();
 }
 
+#if 0
 static void phy_st_timer_handler(unsigned long data)
 {
         struct timer_list *timer = &phy_int_timer;
@@ -673,6 +727,9 @@ void init_phy_state_timer(void *data)
         timer->function = phy_st_timer_handler;
         add_timer(timer);
 }
+#endif
+
+#if 0
 void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag)
 {
 	int inf;
@@ -729,7 +786,7 @@ void nlm_xlp_mac_set_enable(struct dev_data *priv, int flag)
 	} else
 		nlm_hal_mac_disable(priv->node, inf, priv->type);
 }
-
+#endif
 static int p2p_desc_mem_init(void)
 {
 	int cpu, cnt;
@@ -789,7 +846,7 @@ inline int create_p2p_desc(uint64_t paddr, uint64_t len,
 	do {
 		plen = len >= MAX_PACKET_SZ_PER_MSG ?
 				(MAX_PACKET_SZ_PER_MSG - 64): len;
-		p2pmsg[idx] = cpu_to_be64(nae_tx_desc(P2D_NEOP, 0, NULL_VFBID,
+		p2pmsg[idx] = cpu_to_be64(nae_tx_desc(DESC_TYPE_P2DNEOP, NULL_VFBID,
 				plen, paddr));
 		len -= plen;
 		paddr += plen;
@@ -820,6 +877,7 @@ uint16_t pseuodo_chksum(uint16_t *ipsrc, uint16_t proto)
 	return (uint16_t)sum;
 }
 
+#if 0
 static void nlm_enable_l3_l4_parser(int node)
 {
 	int l2proto = 1; //ethernet
@@ -852,10 +910,11 @@ static void nlm_enable_l3_l4_parser(int node)
 	nlm_hal_write_nae_reg(node, L4_CTABLE_0_1, val);
 
 }
+#endif
 
 #ifdef CONFIG_NLM_NET_OPTS
 /* Get the hardware replenishment queue id */
-int get_hw_frfifo_queue_id(int rxnode, nlm_nae_config_ptr nae_cfg,
+int get_hw_frfifo_queue_id(int rxnode, nae_t* nae_cfg,
 				  int cpu, uint32_t truesize, int hw_port_id)
 {
 	/*
@@ -883,7 +942,7 @@ int get_hw_frfifo_queue_id(int rxnode, nlm_nae_config_ptr nae_cfg,
 }
 #endif
 
-int mac_refill_frin_skb(int node, int cpu, uint64_t paddr,
+int mac_refill_frin_skb(nae_t* nae_cfg, int cpu, uint64_t paddr,
 			       uint32_t bufsize, int hw_port_id)
 {
 	/*
@@ -891,11 +950,10 @@ int mac_refill_frin_skb(int node, int cpu, uint64_t paddr,
 	 * indexed by logical cpu id
 	 */
 	int ret, code, qid;
-	nlm_nae_config_ptr nae_cfg;
 	int node_cpu = __cpu_number_map[cpu] % NLM_NCPUS_PER_NODE;
 	ulong __attribute__ ((unused)) mflags;
+	int node = nae_cfg->node;
 
-	nae_cfg = nlm_node_cfg.nae_cfg[node];
 	if (nae_cfg == NULL) {
 		printk("%s Error, Invalid node id %d\n", __FUNCTION__, node);
 		return -1;
@@ -922,7 +980,8 @@ int mac_refill_frin_skb(int node, int cpu, uint64_t paddr,
 	//* Send the packet to nae rx  */
 	msgrng_access_enable(mflags);
 	for (;;) {
-	  ret = nlm_hal_send_msg1(qid, code, (paddr & 0xffffffffffULL));
+		//ret = netsoc_nae_send_freein_buf(nae_cfg, qid, paddr & 0xffffffffffULL);	
+	  	ret = xlp_message_send_1(qid, code, (paddr & 0xffffffffffULL));
 	  if (!ret) break;
 	}
 	msgrng_access_disable(mflags);
@@ -936,6 +995,7 @@ int mac_refill_frin_one_buffer(struct net_device *dev, int cpu,
 	struct dev_data* priv = netdev_priv(dev);
 	struct sk_buff * skb;
 	int buf_size = NLM_RX_ETH_BUF_SIZE;
+	nae_t* nae_cfg = priv->nae;
 
 	if (enable_jumbo)
 		if(truesize > NLM_RX_JUMBO_BUF_SIZE)
@@ -952,8 +1012,7 @@ int mac_refill_frin_one_buffer(struct net_device *dev, int cpu,
 
 	mac_put_skb_back_ptr(skb);
 
-	return mac_refill_frin_skb(priv->node, cpu,
-		(uint64_t)virt_to_bus(skb->data), buf_size, priv->hw_port_id);
+	return mac_refill_frin_skb(nae_cfg, cpu, (uint64_t)virt_to_bus(skb->data), buf_size, priv->hw_port_id);
 }
 
 /**********************************************************************
@@ -966,7 +1025,8 @@ static int  nlm_xlp_nae_open (struct net_device *dev)
 	struct dev_data *priv = netdev_priv(dev);
 	int i;
 	int ret = 0;
-	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[priv->node];
+	nae_t* nae_cfg = priv->nae;
+	net_port_t* nae_port = priv->nae_port;
 	static int done = 0;
 	if (perf_mode == NLM_TCP_MODE) {
 #ifdef TSO_ENABLED
@@ -977,14 +1037,15 @@ static int  nlm_xlp_nae_open (struct net_device *dev)
 #endif
 		if (!done) {
 			done = 1;
-			nlm_enable_l3_l4_parser(priv->node);
+			//nlm_enable_l3_l4_parser(nae_cfg);
 		}
 	}
 
 	if (priv->inited) {
 		spin_lock_irq(&priv->lock);
 		if(nae_cfg->owned)
-			nlm_xlp_mac_set_enable(priv, 1);
+			netsoc_open_port(nae_cfg, priv->port);
+			//nlm_xlp_mac_set_enable(priv, 1);
 		netif_tx_wake_all_queues(dev);
 		spin_unlock_irq(&priv->lock);
 		return 0;
@@ -1016,7 +1077,8 @@ static int  nlm_xlp_nae_open (struct net_device *dev)
 	priv->inited = 1;
 
 	if(nae_cfg->owned)
-		nlm_xlp_mac_set_enable(priv, 1);
+		netsoc_open_port(nae_cfg, priv->port);
+		//nlm_xlp_mac_set_enable(priv, 1);
 
 	return ret;
 }
@@ -1029,12 +1091,13 @@ static int  nlm_xlp_nae_open (struct net_device *dev)
 static int  nlm_xlp_nae_stop (struct net_device *dev)
 {
 	struct dev_data *priv = netdev_priv(dev);
-	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[priv->node];
+	nae_t* nae_cfg = priv->nae;
 
 	spin_lock_irq(&priv->lock);
 
-	if (nae_cfg->owned)
-		nlm_xlp_mac_set_enable(priv, 0);
+	if (nae_cfg->owned){
+		//nlm_xlp_mac_set_enable(priv, 0);
+	}
 	priv->inited = 0;
 	netif_tx_stop_all_queues(dev);
 
@@ -1042,11 +1105,11 @@ static int  nlm_xlp_nae_stop (struct net_device *dev)
 	return 0;
 }
 
-#ifdef NOTYET
 /**********************************************************************
  * nlm_xlp_set_multicast_list
  *
  **********************************************************************/
+#if 0
 static void  nlm_xlp_set_multicast_list (struct net_device *dev)
 {
 	struct dev_data *priv = netdev_priv(dev);
@@ -1091,6 +1154,7 @@ static void  nlm_xlp_set_multicast_list (struct net_device *dev)
 }
 #endif
 
+#if 0
 static void xlp_mac_setup_hwaddr(struct dev_data *priv)
 {
         struct net_device *dev = priv->dev;
@@ -1128,7 +1192,7 @@ static void xlp_mac_setup_hwaddr(struct dev_data *priv)
 				NETIOR_VLANTYPE_FILTER,reg_val);	
 
 }
-
+#endif
 
 /**********************************************************************
  * nlm_xlp_nae_ioctl
@@ -1160,7 +1224,8 @@ static int nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu)
 	struct dev_data *priv = netdev_priv(dev);
 	ulong flags;
 	ulong local_mtu, len;
-	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[priv->node];
+	nae_t* nae_cfg = priv->nae;
+	net_port_t* nae_port = priv->nae_port;
 
 	if (enable_jumbo &&
 		(new_mtu > ETH_JUMBO_DATA_LEN || new_mtu < ETH_ZLEN)) {
@@ -1184,18 +1249,17 @@ static int nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu)
 	{
 		netif_tx_stop_all_queues (dev);
 		if(nae_cfg->owned)
-			nlm_xlp_mac_set_enable(priv, 0); /* Disable MAC TX/RX */
+			netsoc_mac_disable(nae_port);
+			//nlm_xlp_mac_set_enable(priv, 0); /* Disable MAC TX/RX */
+	}
+	
+	if (priv->type==SGMII_IF || priv->type==XAUI_IF)
+		netsoc_set_framesize(nae_port, local_mtu);
+	else if (priv->type==INTERLAKEN_IF){
+		/*TODO: Add IL frame set in brcm_netsoc */
+		//nlm_hal_set_ilk_framesize(priv->node, priv->block,
+		//	priv->phy.addr, local_mtu);
 	}
-
-	if (priv->type==SGMII_IF)
-		nlm_hal_set_sgmii_framesize(priv->node, priv->block,
-			priv->index, local_mtu);
-	else if (priv->type==XAUI_IF)
-		nlm_hal_set_xaui_framesize(priv->node, priv->block,
-			local_mtu, local_mtu);
-	else if (priv->type==INTERLAKEN_IF)
-		nlm_hal_set_ilk_framesize(priv->node, priv->block,
-			priv->phy.addr, local_mtu);
 	else {
 		spin_unlock_irqrestore(&priv->lock, flags);
 		return -1;
@@ -1207,7 +1271,9 @@ static int nlm_xlp_nae_change_mtu(struct net_device *dev, int new_mtu)
 	{
 		netif_tx_start_all_queues (dev);
 		if(nae_cfg->owned)
-			nlm_xlp_mac_set_enable(priv, 1);
+			netsoc_mac_enable(nae_port);
+			//nlm_xlp_mac_set_enable(priv, 1);
+			
 	}
 
 	spin_unlock_irqrestore(&priv->lock, flags);
@@ -1253,7 +1319,7 @@ static void  nlm_xlp_nae_tx_timeout (struct net_device *dev)
 	printk(KERN_WARNING "%s: Transmit timed out\n", dev->name);
 	return;
 }
-
+#if 0
 static int nlm_xlp_nae_set_hwaddr(struct net_device *dev, void *p)
 {
 	struct sockaddr *addr = (struct sockaddr *)p;
@@ -1281,6 +1347,7 @@ static int nlm_xlp_nae_set_hwaddr(struct net_device *dev, void *p)
 
 	return rc;
 }
+#endif
 
 #ifdef ENABLE_NAE_PIC_INT
 /**********************************************************************
@@ -1323,17 +1390,18 @@ static const struct net_device_ops nlm_xlp_nae_ops = {
 	.ndo_do_ioctl			= nlm_xlp_nae_ioctl,
 	.ndo_tx_timeout 		= nlm_xlp_nae_tx_timeout,
 	.ndo_change_mtu			= nlm_xlp_nae_change_mtu,
-	.ndo_set_mac_address		= nlm_xlp_nae_set_hwaddr,
+	//.ndo_set_mac_address		= nlm_xlp_nae_set_hwaddr,
 	.ndo_get_stats 			= nlm_xlp_mac_get_stats,
 	.ndo_select_queue		= nlm_select_queue,
 };
 
-static int nlm_per_port_nae_init(int node, int port,
-			  nlm_nae_config_ptr nae_cfg, int maxnae)
+static int nlm_per_port_nae_init(nae_t* nae_cfg, int port, int maxnae)
 {
 	struct net_device *dev;
 	struct dev_data *priv;
 	int cpu;
+	int node = nae_cfg->node;
+	net_port_t *net_port_cfg;
 
 	if (!nae_cfg->ports[port].valid)
 		return -1;
@@ -1349,7 +1417,9 @@ static int nlm_per_port_nae_init(int node, int port,
 
 	priv = netdev_priv(dev);
 	spin_lock_init(&priv->lock);
-	priv->dev 	= dev;
+	priv->dev = dev;
+	priv->nae = nae_cfg;
+	priv->nae_port = get_net_port(nae_cfg, port);
 	dev->netdev_ops = &nlm_xlp_nae_ops;
 
 	/* set ethtool_ops which is inside xlp_ethtool.c file*/
@@ -1371,9 +1441,11 @@ static int nlm_per_port_nae_init(int node, int port,
 		priv->phy.addr = nae_cfg->ports[port].hw_port_id;
 		break;
 	case XAUI_IF:
+	#if 0	//TODO:
 		nlm_hal_write_mac_reg(priv->node,
 			(nae_cfg->ports[port].hw_port_id / 4),
 			XGMAC, XAUI_MAX_FRAME_LEN , 0x01800600);
+	#endif /*No frame length should be done here.*/
 		priv->index = XGMAC;
 		break;
 	case INTERLAKEN_IF:
@@ -1399,8 +1471,8 @@ static int nlm_per_port_nae_init(int node, int port,
 
 	register_netdev(dev);
 
-	xlp_dev_mac[node][port] = dev;
-	xlp_mac_setup_hwaddr(priv);
+	//xlp_dev_mac[node][port] = dev;
+	//xlp_mac_setup_hwaddr(priv);
 
 
 	for (cpu = 0; cpu < NR_CPUS; cpu++)
@@ -1419,7 +1491,7 @@ void nlm_xlp_nae_init(void)
 	int i, node = 0, maxnae;
 	struct proc_dir_entry *entry;
 	unsigned char *mode_str[3] = {"INVALID","TCP_PERF","ROUTE_PERF"};
-	nlm_nae_config_ptr nae_cfg;
+	nae_t* nae_cfg;
 
 	if (!(perf_mode == NLM_TCP_MODE || perf_mode == NLM_RT_MODE)) {
 		printk("Invalid perf mode passed -- Using TCP_PERF mode\n");
@@ -1450,15 +1522,16 @@ void nlm_xlp_nae_init(void)
 	if (initialize_nae(phys_cpu_map, perf_mode, &enable_jumbo))
 		return;
 
-	maxnae = nlm_node_cfg.num_nodes;
+	maxnae = get_num_nae_pernode();
 	for (node = 0; node < maxnae; node++) {
-		nae_cfg = nlm_node_cfg.nae_cfg[node];
-		if (nae_cfg == NULL)
-			continue;
-
-		for(i = 0; i < nae_cfg->num_ports; i++)
-			nlm_per_port_nae_init(node, i, nae_cfg, maxnae);
-
+		int num_nae;
+		for(num_nae=0; num_nae<NLM_MAX_NODES; num_nae++){
+			nae_cfg = get_nae(node, num_nae);
+			if (nae_cfg == NULL)
+				continue;
+				for(i = 0; i < nae_cfg->num_ports; i++)
+					nlm_per_port_nae_init(nae_cfg, i, maxnae);
+		}
 	}
 
 	entry = create_proc_read_entry("mac_stats",
@@ -1501,7 +1574,7 @@ void nlm_xlp_nae_init(void)
 				);
 		if (entry)
 			entry->proc_fops = &nlm_load_balance_proc_fops;
-		nlm_init_load_balance();
+		//nlm_init_load_balance();
 	}
 #endif
 
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_rx.c b/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
index 302bb7f..f0061d1 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_rx.c
@@ -203,7 +203,7 @@ static void nlm_remove_inactive_flow(int cpu)
 	}
 	spin_unlock_irqrestore(&afl->lock, mflags);
 }
-
+#if 0
 static void setup_search_path(void)
 {
 	uint32_t pcpu;
@@ -303,7 +303,9 @@ static void setup_search_path(void)
 #endif
 	return;
 }
+#endif
 
+#if 0
 static void nlm_load_balance_timer_func(unsigned long arg)
 {
 	int cpu = hard_smp_processor_id();
@@ -401,14 +403,14 @@ restart:
 		mod_timer(&nlm_load_balance_timer[cpu],
 			jiffies + load_balance_timer_run * HZ);
 }
-
+#endif
 void nlm_setup_load_balance_timer(void *data)
 {
 	int pcpu = hard_smp_processor_id();
 	nlm_load_balance_timer[pcpu].expires = jiffies + 5*HZ;
 	add_timer(&nlm_load_balance_timer[pcpu]);
 }
-
+#if 0
 void nlm_init_load_balance(void)
 {
 	uint32_t signature;
@@ -493,6 +495,7 @@ void nlm_init_load_balance(void)
 	nlm_hal_modify_nae_ucore_sram_mem(0, 0, &signature,
 		NLM_UCORE_SHMEM_OFFSET - 4, 1);
 }
+#endif
 
 #ifdef LOAD_BALANCE_DEBUG_ENABLE
 static void dump_packet(unsigned char *vaddr, int len)
@@ -594,7 +597,7 @@ static inline void process_rx_packets(int cpu, unsigned int src_id,
 	struct dev_data *priv = NULL;
 	uint64_t vaddr;
 	struct sk_buff* skb;
-	nlm_nae_config_ptr nae_cfg;
+	nae_t* nae_cfg;
 	uint32_t msec_port;
 
 	err = (msg1 >> 4) & 0x1;
@@ -671,7 +674,7 @@ static inline void process_rx_packets(int cpu, unsigned int src_id,
 	else
 		msec_port = 1 << port;
 
-	nae_cfg = nlm_node_cfg.nae_cfg[node];
+	nae_cfg = priv->nae;
 
 #ifdef MACSEC_DEBUG
 	printk("%s nae_cfg->sectag_offset = %d sectag_len = %d icv_len = %d\n",
@@ -790,8 +793,6 @@ void xlp_poll_upper(int cpu)
 			if(status) break;
 			__sync();
 
-			Message("poll upper cpu %d src_id %d size %d\n",
-				cpu, src_id, size);
 			process_tx_complete(cpu, src_id, msg0);
 
 	}
@@ -812,6 +813,7 @@ static int xlp_poll_lower(int budget, int cpu)
 		msgrng_access_enable(mflags);
 		status = xlp_message_receive_2(nae_rx_vc, &src_id, &size,
 				&code, &msg0, &msg1);
+		Message("xlp_message_receive_2 src_id = 0x%x size=0x%x \n", src_id, size);
 		msgrng_access_disable(mflags);
 
 		if (status) {
@@ -923,7 +925,9 @@ void nlm_spawn_kthread(void)
     char buf[20];
     static struct task_struct *task[NR_CPUS];
 
-    nr_cpus = nlm_node_cfg.num_nodes * NLM_NCPUS_PER_NODE;	
+    //nr_cpus = nlm_node_cfg.num_nodes * NLM_NCPUS_PER_NODE;	
+	//TODO:	
+	nr_cpus = 4*32;
     /*Spawn kthread*/
     for (i = 0; i < nr_cpus; i++) {
 	if (!cpumask_test_cpu(i, cpu_present_mask))
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_sgmii.c b/drivers/net/ethernet/broadcom/nae/xlpge_sgmii.c
index e7d11d4..d20e82d 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_sgmii.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_sgmii.c
@@ -39,6 +39,8 @@
 
 int xlp_enable_autoneg(struct net_device *dev, u32 adv)
 {
+//TODO:
+#if 0
 	struct dev_data *priv = netdev_priv(dev);
 	int mii_status;
 	u32 adv1, adv2;
@@ -82,10 +84,12 @@ int xlp_enable_autoneg(struct net_device *dev, u32 adv)
 	spin_unlock_irqrestore(&priv->lock, flags);
 
 	return 0;
+#endif
 }
 
 int xlp_set_link_speed(struct net_device *dev, int speed, int duplex)
 {
+#if 0
 	u32 adv;
 	int ret =0;
 
@@ -115,4 +119,5 @@ int xlp_set_link_speed(struct net_device *dev, int speed, int duplex)
 	ret = xlp_enable_autoneg( dev,adv);
 	return ret;
 
+#endif
 }
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_tso.c b/drivers/net/ethernet/broadcom/nae/xlpge_tso.c
index 94fa7b3..b000879 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_tso.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_tso.c
@@ -93,7 +93,7 @@ inline int tso_xmit_skb(struct sk_buff *skb, struct net_device *dev)
 	uint64_t *p2pdesc = NULL;
 	int cpu = hard_smp_processor_id();
 	int  ret, retry_cnt = 0, qid;
-	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[priv->node];
+	nae_t* nae_cfg = priv->nae;
 	unsigned long __attribute__ ((unused)) mflags;
 	uint32_t msec_port, send_msec = 0, msec_bypass = 0;
 	uint32_t pad_len = 0, icv_len = 0, param_index = 0;
@@ -246,7 +246,7 @@ inline int tso_xmit_skb(struct sk_buff *skb, struct net_device *dev)
 	qid = nae_cfg->vfbtbl_sw_offset + (cpu % NLM_NCPUS_PER_NODE);
 	{
 		create_last_p2p_desc(p2pdesc, skb, idx);
-		msg = nae_tx_desc(P2P, 0, qid, idx, virt_to_bus(p2pdesc));
+		msg = nae_tx_desc(DESC_TYPE_P2P, qid, idx, virt_to_bus(p2pdesc));
 	}
 	
 
@@ -255,14 +255,14 @@ inline int tso_xmit_skb(struct sk_buff *skb, struct net_device *dev)
 retry_send:
 	msgrng_access_enable(mflags);
 	if(mss)
-		ret = nlm_hal_send_msg3(priv->nae_tx_qid, 0, mscmsg0,
+		ret = xlp_message_send_3(priv->nae_tx_qid, 0, mscmsg0,
 				mscmsg1, msg);
 	else if(skb->ip_summed == CHECKSUM_PARTIAL)
-		ret = nlm_hal_send_msg2(priv->nae_tx_qid, 0, mscmsg0, msg);
+		ret = xlp_message_send_2(priv->nae_tx_qid, 0, mscmsg0, msg);
 	else if (send_msec || msec_bypass)
-		ret = nlm_hal_send_msg2(priv->nae_tx_qid, 0, mscmsg0, msg);
+		ret = xlp_message_send_2(priv->nae_tx_qid, 0, mscmsg0, msg);
 	else
-		ret = nlm_hal_send_msg1(priv->nae_tx_qid, 0, msg);
+		ret = xlp_message_send_1(priv->nae_tx_qid, 0, msg);
 	msgrng_access_disable(mflags);
 	if(ret)	{
 		xlp_poll_upper(cpu);
diff --git a/drivers/net/ethernet/broadcom/nae/xlpge_tx.c b/drivers/net/ethernet/broadcom/nae/xlpge_tx.c
index 04476ba..de93ba1 100644
--- a/drivers/net/ethernet/broadcom/nae/xlpge_tx.c
+++ b/drivers/net/ethernet/broadcom/nae/xlpge_tx.c
@@ -65,7 +65,7 @@ int nlm_xlp_nae_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	int  offset, qid;
 	unsigned long __attribute__ ((unused)) mflags;
 
-	nlm_nae_config_ptr nae_cfg = nlm_node_cfg.nae_cfg[priv->node];
+	nae_t* nae_cfg = priv->nae;
 
 
 #ifdef ENABLE_SANITY_CHECKS
@@ -94,8 +94,7 @@ int nlm_xlp_nae_start_xmit(struct sk_buff *skb, struct net_device *dev)
 
 		qid = get_hw_frfifo_queue_id(last_rcvd_node[CPU_INDEX(cpu)],
 			nae_cfg, cpu, skb->truesize, rpriv->hw_port_id);
-		msg0 = nae_tx_desc(P2D_NEOP, 0, qid,
-				0, last_rcvd_skb_phys[CPU_INDEX(cpu)]);
+		msg0 = nae_tx_desc(DESC_TYPE_P2DNEOP, 0, last_rcvd_skb_phys[CPU_INDEX(cpu)]);
 		hw_repl = 1;
 
 		Message("Tx, tx complete to nae, cpu %d len %d qid %d\n",
@@ -107,14 +106,14 @@ int nlm_xlp_nae_start_xmit(struct sk_buff *skb, struct net_device *dev)
 #endif
 	{
 		qid = nae_cfg->vfbtbl_sw_offset + (cpu % NLM_NCPUS_PER_NODE);
-		msg0 = nae_tx_desc(P2D_NEOP, 0, qid, 0, virt_to_bus(skb));
+		msg0 = nae_tx_desc(DESC_TYPE_P2DNEOP, qid, 0, virt_to_bus(skb));
 
 		Message("Tx, tx complete to cpu, cpu %d len %d qid %d\n",
 			cpu, skb->len, qid);
 	}
 	
 	{
-		msg1 = nae_tx_desc(P2D_EOP, 0, NULL_VFBID, skb->len,
+		msg1 = nae_tx_desc(DESC_TYPE_P2DEOP, NULL_VFBID, skb->len,
 			       virt_to_bus(skb->data));
 	}
 	if(hw_repl) {
@@ -138,7 +137,7 @@ int nlm_xlp_nae_start_xmit(struct sk_buff *skb, struct net_device *dev)
 
 retry_send:
 	msgrng_access_enable(mflags);
-	ret = nlm_hal_send_msg2(priv->nae_tx_qid, 0, msg0, msg1);
+	ret = xlp_message_send_2(priv->nae_tx_qid, 0, msg0, msg1);
 	msgrng_access_disable(mflags);
 	if (ret)
 	{
@@ -151,6 +150,5 @@ retry_send:
         }
 
 	dev->trans_start = jiffies;
-
 	return NETDEV_TX_OK;
 }
-- 
1.7.1

