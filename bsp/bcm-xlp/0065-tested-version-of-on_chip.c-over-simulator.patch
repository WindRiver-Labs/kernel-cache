From 86dcf7b642f90eb5c3ed7bc534bd5760b5abe62b Mon Sep 17 00:00:00 2001
From: henry shao <hshao@netlogicmicro.com>
Date: Sun, 27 Jun 2010 01:00:52 -0700
Subject: [PATCH 065/762] tested version of on_chip.c over simulator

Based on Broadcom SDK 2.3.

Signed-off-by: henry shao <hshao@netlogicmicro.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/netlogic/xlp/on_chip.c |  361 ++++++++++++--------------------------
 1 files changed, 111 insertions(+), 250 deletions(-)

diff --git a/arch/mips/netlogic/xlp/on_chip.c b/arch/mips/netlogic/xlp/on_chip.c
index 3261753..b24c1ed 100644
--- a/arch/mips/netlogic/xlp/on_chip.c
+++ b/arch/mips/netlogic/xlp/on_chip.c
@@ -42,14 +42,14 @@ THE POSSIBILITY OF SUCH DAMAGE.
 
 unsigned long netlogic_io_base = (unsigned long)(DEFAULT_NETLOGIC_IO_BASE);
 EXPORT_SYMBOL(netlogic_io_base);
-int msgring_timer_irq;
 extern uint32_t xlp_linux_cpu_mask;
 
-__u32  pop_bucket_mask[NR_CORES];
-__u32  pop_bucket_start[NR_CORES];
-__u32  pop_bucket_end[NR_CORES];
-__u32 cpu_to_bktmask[NR_CPUS];
-__u32 cpu_to_frstid[NR_CPUS];
+
+//__u32  pop_bucket_mask[NR_CORES];
+//__u32  pop_bucket_start[NR_CORES];
+//__u32  pop_bucket_end[NR_CORES];
+//__u32 cpu_to_bktmask[NR_CPUS];
+//__u32 cpu_to_frstid[NR_CPUS];
 
 uint32_t hard_cpu_online_map = 0;
 uint32_t msgring_global_thread_mask = 0;
@@ -67,6 +67,10 @@ extern int nlm_dev_own_bucket_list_get(int *start, int *end, int *mask);
 extern struct irq_chip nlm_common_rsvd_pic;
 extern struct irqaction nlm_common_rsvd_action;
 
+struct msgstn_handler {
+        void (*action)(uint32_t, uint32_t, uint32_t, uint32_t, uint64_t, uint64_t, uint64_t, uint64_t, void *);
+        void *dev_id;
+};
 static uint16_t vc_to_handle_map[1024] = {
 	[0 ... 15] = XLP_MSG_HANDLE_CPU0,
 	[16 ... 31] = XLP_MSG_HANDLE_CPU1,
@@ -93,210 +97,66 @@ static uint16_t vc_to_handle_map[1024] = {
 	[281 ... 296] = XLP_MSG_HANDLE_CRYPTO,
 	[297 ... 304] = XLP_MSG_HANDLE_CMP,
 	[305 ... 383] = XLP_MSG_HANDLE_INVALID,
-	[384 ... 391] = XLP_MSG_HANDLE_POE,
+	[384 ... 391] = XLP_MSG_HANDLE_NAE_0,
 	[392 ... 475] = XLP_MSG_HANDLE_INVALID,
 	[476] 	      = XLP_MSG_HANDLE_NAE_0,
-	[477] 	      = XLP_MSG_HANDLE_NAE_1,
-	[478] 	      = XLP_MSG_HANDLE_NAE_2,
-	[479] 	      = XLP_MSG_HANDLE_NAE_3,
-	[480] 	      = XLP_MSG_HANDLE_NAE_4,
-	[481] 	      = XLP_MSG_HANDLE_NAE_5,
-	[482] 	      = XLP_MSG_HANDLE_NAE_6,
-	[483] 	      = XLP_MSG_HANDLE_NAE_7,
-	[484] 	      = XLP_MSG_HANDLE_NAE_8,
-	[485] 	      = XLP_MSG_HANDLE_NAE_9,
-	[486] 	      = XLP_MSG_HANDLE_NAE_10,
-	[487] 	      = XLP_MSG_HANDLE_NAE_11,
-	[488] 	      = XLP_MSG_HANDLE_NAE_12,
-	[489] 	      = XLP_MSG_HANDLE_NAE_13,
-	[490] 	      = XLP_MSG_HANDLE_NAE_14,
-	[491] 	      = XLP_MSG_HANDLE_NAE_15,
-	[492] 	      = XLP_MSG_HANDLE_NAE_16,
-	[493] 	      = XLP_MSG_HANDLE_NAE_17,
+	[477] 	      = XLP_MSG_HANDLE_NAE_0,
+	[478] 	      = XLP_MSG_HANDLE_NAE_0,
+	[479] 	      = XLP_MSG_HANDLE_NAE_0,
+	[480] 	      = XLP_MSG_HANDLE_NAE_0,
+	[481] 	      = XLP_MSG_HANDLE_NAE_0,
+	[482] 	      = XLP_MSG_HANDLE_NAE_0,
+	[483] 	      = XLP_MSG_HANDLE_NAE_0,
+	[484] 	      = XLP_MSG_HANDLE_NAE_0,
+	[485] 	      = XLP_MSG_HANDLE_NAE_0,
+	[486] 	      = XLP_MSG_HANDLE_NAE_0,
+	[487] 	      = XLP_MSG_HANDLE_NAE_0,
+	[488] 	      = XLP_MSG_HANDLE_NAE_0,
+	[489] 	      = XLP_MSG_HANDLE_NAE_0,
+	[490] 	      = XLP_MSG_HANDLE_NAE_0,
+	[491] 	      = XLP_MSG_HANDLE_NAE_0,
+	[492] 	      = XLP_MSG_HANDLE_NAE_0,
+	[493] 	      = XLP_MSG_HANDLE_NAE_0,
 	[494 ... 999] = XLP_MSG_HANDLE_NAE_0,
 	[1000] 	      = XLP_MSG_HANDLE_NAE_0,
-	[1001] 	      = XLP_MSG_HANDLE_NAE_1,
-	[1002] 	      = XLP_MSG_HANDLE_NAE_2,
-	[1003] 	      = XLP_MSG_HANDLE_NAE_3,
-	[1004] 	      = XLP_MSG_HANDLE_NAE_4,
-	[1005] 	      = XLP_MSG_HANDLE_NAE_5,
-	[1006] 	      = XLP_MSG_HANDLE_NAE_6,
-	[1007] 	      = XLP_MSG_HANDLE_NAE_7,
-	[1008] 	      = XLP_MSG_HANDLE_NAE_8,
-	[1009] 	      = XLP_MSG_HANDLE_NAE_9,
-	[1010] 	      = XLP_MSG_HANDLE_NAE_10,
-	[1011] 	      = XLP_MSG_HANDLE_NAE_11,
-	[1012] 	      = XLP_MSG_HANDLE_NAE_12,
-	[1013] 	      = XLP_MSG_HANDLE_NAE_13,
-	[1014] 	      = XLP_MSG_HANDLE_NAE_14,
-	[1015] 	      = XLP_MSG_HANDLE_NAE_15,
-	[1016] 	      = XLP_MSG_HANDLE_NAE_16,
-	[1017] 	      = XLP_MSG_HANDLE_NAE_17,
+	[1001] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1002] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1003] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1004] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1005] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1006] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1007] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1008] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1009] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1010] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1011] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1012] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1013] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1014] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1015] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1016] 	      = XLP_MSG_HANDLE_NAE_0,
+	[1017] 	      = XLP_MSG_HANDLE_NAE_0,
 	[1018 ... 1019] = XLP_MSG_HANDLE_NAE_0,
 	[1020 ... 1023] = XLP_MSG_HANDLE_INVALID
 };
 
-void dummy_handler(int bucket, int size, int code, int tx_stid,
-		   struct msgrng_msg *msg, void *dev_id)
+void dummy_handler(uint32_t vc, uint32_t src_id, uint32_t size, uint32_t code, 
+		   uint64_t msg0, uint64_t msg1, uint64_t msg2, uint64_t msg3, void *dev_id)
 {
 	printk("[%s]: No Handler for message from stn_id=%d, bucket=%d, "
 	       "size=%d, msg0=%llx, dropping message\n",
-	       __FUNCTION__, tx_stid, bucket, size,
-	       (unsigned long long)msg->msg0);
+	       __FUNCTION__, src_id, vc, size,
+	       (unsigned long long)msg0);
 }
 
-struct tx_stn_handler msg_handler_map[XLP_MSG_HANDLE_MAX] = {
+struct msgstn_handler msg_handler_map[XLP_MSG_HANDLE_MAX] = {
 	[0 ... (XLP_MSG_HANDLE_MAX-1)] = {dummy_handler, NULL},
 };
 
-void nlm_xlp_msgring_cpu_init(void)
-{
-	int id;
-
-	id = cpu_logical_map(get_cpu());
-
-	msgring_int_en = 1;
-
-
-	/* if not thead 0 */
-	if ((id & 0x03) != 0) {
-		put_cpu();
-		return;
-	}
-
-	prom_dbg_msg("Initializing message ring for cpu_%d\n", id);
-}
-
-
-void nlm_common_derive_cpu_to_bkt_map(void)
-{
-	int cpus_per_core[NR_CORES];
-	int stns_per_core[NR_CORES];
-	int num_cpus, cpus, cpu_off, from, i;
-	int bucket_mask[NR_CPUS_PER_CORE];
-	int fr_bucket[NR_CPUS_PER_CORE];
-	int core, bkt_idx, bkt_mask;
-
-#define GET_NEXT_SET_BIT_U8(val, rv) { \
-    if(val < ( 1 << rv)) \
-        rv = 0; \
-    for(i = rv; val != 0 && i <= 7; i++) { \
-        if(val & (1 << i)) { \
-            rv = i; \
-            break; \
-        } \
-    }  \
-    if( i >= 8) \
-        rv = 0; \
-}
-
-	memset(cpus_per_core, 0, sizeof(cpus_per_core));
-	memset(stns_per_core, 0, sizeof(stns_per_core));
-
-	for (i = 0; i < NR_CPUS; i++) {
-		if (!(hard_cpu_online_map & (1 << i)))
-			continue;
-		core = i / NR_CPUS_PER_CORE;
-		cpus_per_core[core]++;
-	}
-	for (core = 0; core < NR_CORES; core++) {
-		for (i = 0; i < NR_STNS_PER_CORE; i++) {
-			if (!(pop_bucket_mask[core] & (1 << i)))
-				continue;
-			stns_per_core[core]++;
-		}
-	}
-
-	for (core = 0; core < NR_CORES; core++) {
-		int filled_all = 0;
-		int rv = 0;
-		uint8_t fr_bucket_map = 0;
-		memset(bucket_mask, 0, sizeof(bucket_mask));
-		memset(fr_bucket, 0xff, sizeof(fr_bucket));
-
-        num_cpus = cpus_per_core[core];
-        if(num_cpus == 0)
-            continue;
-        for(cpus = 0, bkt_idx = 0, bkt_mask = pop_bucket_mask[core];
-                bkt_mask; bkt_mask = bkt_mask >> 1, bkt_idx++) {
-            if(!(bkt_mask & 0x01))
-                continue;
-            bucket_mask[cpus] |=  (1 << bkt_idx);
-			
-			if(((int)fr_bucket[cpus] != -1) && (fr_bucket[cpus] < NR_CPUS_PER_CORE))
-                fr_bucket_map &= (~(1 << fr_bucket[cpus]));
-            fr_bucket_map |= (1 << bkt_idx);
-			fr_bucket[cpus] = bkt_idx;
-
-			if((cpus + 1) == num_cpus)
-            	filled_all = 1;
-
-            cpus = (cpus + 1) % num_cpus;
-        }
-
-        /* fill the non filled cpus */
-		if(filled_all == 0) {
-	        for(from = 0; cpus < num_cpus; cpus++, from++) {
-    	        bucket_mask[cpus] = bucket_mask[from];
-       	 	}
-		}
-        cpu_off = core * NR_CPUS_PER_CORE;
-        for(from = 0, cpus = cpu_off;
-                cpus < cpu_off + NR_CPUS_PER_CORE; cpus++) {
-            if(!(hard_cpu_online_map & (1 << cpus)))
-                continue;
-            cpu_to_bktmask[cpus] = bucket_mask[from];
-			GET_NEXT_SET_BIT_U8(fr_bucket_map, rv);
-            cpu_to_frstid[cpus] = rv + (core * NR_STNS_PER_CORE);
-            from++;
-			rv++;
-        }
-    }
-
-	return;
-}
 
 extern void nlm_cpu_stat_update_msgring_int(void);
 extern void nlm_cpu_stat_update_msgring_cycles(__u32 cycles);
 extern void nlm_cpu_stat_update_msgring_pic_int(void);
-#if 0
-void msgring_process_rx_msgs(int start_bucket, int end_bucket,
-			     __u32 pop_bucket_mask)
-{
-	unsigned int bucket_empty_bm = 0;
-	int bucket = 0;
-	int size = 0, code = 0, rx_stid = 0;
-	struct msgring_msg msg;
-	struct tx_stn_handler *handler = 0;
-	unsigned int status = 0;
-
-printk("[%s] \n", __FUNCTION__);
-
-	/* First Drain all the high priority messages */
-	for (;;) {
-
-		bucket_empty_bm =
-		    (msgrng_read_status() >> 24) & pop_bucket_mask;
-
-printk("bucket_empty_bm:%d pop_bucket_mask %d \n", bucket_empty_bm, pop_bucket_mask);
-		/* all buckets empty, break */
-		if (bucket_empty_bm == pop_bucket_mask)
-			break;
-
-		for (bucket = start_bucket; bucket < end_bucket; bucket++) {
-
-			if ((bucket_empty_bm & (1 << bucket)) ||	/* empty */
-			    !((1 << bucket) & pop_bucket_mask))	/* not in mask */
-				continue;
-
-			status = xlp_msg_recv(bucket, &rx_stid,  &size, &code, &msg);
-printk("rx_stid:%d  \n", rx_stid);
-			handler = &msg_handler_map[vc_to_handle_map[rx_stid]];
-			(handler->action) (bucket, size, code, rx_stid, &msg, handler->dev_id);
-		}
-	}
-}
-#endif
 
 #if !defined(CONFIG_NLMCOMMON_MAC) && !defined(CONFIG_NLM_XLP)
 void nlm_cpu_stat_update_msgring_int(void) { }
@@ -308,14 +168,16 @@ __u32 msgrng_msg_cycles = 0;
 void nlm_xlp_msgring_int_handler(unsigned int irq, struct pt_regs *regs)
 {
 	unsigned long mflags;
-	int core;
+	int core, i;
 	__u32 cycles = 0;
 	int vc = 0;
-	int size = 0, code = 0, rx_stid = 0;
-	struct msgring_msg msg;
-	struct tx_stn_handler *handler = 0;
+	uint32_t size = 0, code = 0, src_id = 0;
+	struct msgstn_handler *handler = 0;
 	unsigned int status = 0;
-//printk("[%s] \n",__FUNCTION__);
+	uint64_t msg0, msg1, msg2, msg3;
+	uint64_t val;
+
+	msg0 = msg1 = msg2 = msg3 = 0;
 
 	if (irq == IRQ_MSGRING) {
 		/* normal message ring interrupt */
@@ -327,72 +189,59 @@ void nlm_xlp_msgring_int_handler(unsigned int irq, struct pt_regs *regs)
 
 	irq_enter();
 
-	dbg_msg("[%s] IN irq=%d\n",__function__, irq);
-
-	/* TODO: not necessary to disable preemption */
-//	msgrng_flags_save(mflags);
-
-	cycles = read_c0_count();
-
-//	core = cpu_logical_map(smp_processor_id()) >> 2;
 	core = cpu_logical_map(hard_smp_processor_id()) >> 2;
-//	msgring_process_rx_msgs(pop_bucket_start[core], pop_bucket_end[core], pop_bucket_mask[core]);
         msgrng_access_enable(mflags);
-	for( vc = 0; vc < 4; vc++){
-	status = xlp_msg_recv(vc, &rx_stid,  &size, &code, &msg);
-	if(status & 0x1)
-	{
-printk("rx_stid:%d handler_id %d\n", rx_stid, vc_to_handle_map[rx_stid]);
-		handler = &msg_handler_map[vc_to_handle_map[rx_stid]];
-		(handler->action) (vc, size, code, rx_stid, &msg, handler->dev_id);
-	
-		nlm_cpu_stat_update_msgring_cycles(read_c0_count() - cycles);
-	}
+	for( vc = core; vc < (core+4); vc++){
+//		for( i = 0; i < 10; i++) 
+		{
+		status = xlp_message_receive( vc, &src_id, &size, &code, &msg0, &msg1, &msg2, &msg3);
+		if(status == 0 )
+			continue;
+		
+		{
+printk("[%s] status: %x  vc:%d  src_id:%d handler_id %d\n", __FUNCTION__, status, vc, src_id, vc_to_handle_map[src_id]);
+			if(src_id >= 0 && src_id < 1024)
+			{
+				handler = &msg_handler_map[vc_to_handle_map[src_id]];
+				(handler->action) (vc, src_id, size, code, msg0, msg1, msg2, msg3, handler->dev_id);
+			}
+		}
+		}
 	}
         msgrng_access_disable(mflags);
-//	msgrng_flags_restore(mflags);
 
-	//dbg_msg("OUT irq=%d\n", irq);
 
-	/* Call the msg callback */
 	irq_exit();
 }
 
 static void enable_msgring_int(void *info)
 {
+#if 0
 	unsigned long flags = 0, mflags = 0;
 	unsigned int th_mask, i;
 	unsigned int core;
 	uint64_t val;
-
 	msgrng_access_save(&msgrng_lock, flags, mflags);
 
 	core = hard_smp_processor_id() & ~(0x3);
 	th_mask = (msgring_global_thread_mask >> core) & 0x0f;
 
-#if 0
-	printk
-	    ("[%s:%d] cpu_%d cpu_online_map=0x%04x msgring_global_mask=0x%08x "
-	     "th_mask=0x%02x intype=%d wm=%d\n", __FUNCTION__, __LINE__,
-	     hard_smp_processor_id(), hard_cpu_online_map,
-	     msgring_global_thread_mask, th_mask, msgring_int_type,
-	     msgring_watermark_count);
-#endif
-
 	/* enable the message ring interrupts */
 
 	for(i = 0; i < 128; i++)
 	{
 		val = nlm_hal_read_outq_config(i);
 		/* clear and then set int level value and high watermark field*/
-		val &= ~(0xfULL << 53);
-		val |= ((uint64_t)HWM_NON_EMPTY << 55)|((uint64_t)LVL_INT_HIGH_WM << 53);	
+		val &= ~(0xfULL << 54);
+		val |= ((uint64_t)HWM_NON_EMPTY << 56)|((uint64_t)LVL_INT_HIGH_WM << 54);	
 		/*enable interrupt*/	
-		val |= 1ULL << 59;
+		if( val & ( 1ULL << 59))
+			val &= ( 1ULL << 59 );
 		nlm_hal_write_outq_config(i, val);
 	}
 
 	msgrng_access_restore(&msgrng_lock, flags, mflags);
+#endif
 }
 
 static void msgring_bkp_timer(unsigned long data)
@@ -402,7 +251,7 @@ static void msgring_bkp_timer(unsigned long data)
 	local_irq_save(flags);
 	nlm_xlp_msgring_int_handler(-1,NULL);
 	local_irq_restore(flags);
-	mod_timer(timer, timer->expires+2);
+	mod_timer(timer, timer->expires+HZ/10000);
 }
 
 static void enable_msgring_timer(void *data)
@@ -410,14 +259,13 @@ static void enable_msgring_timer(void *data)
 	struct timer_list *timer;
 	timer = kmalloc(sizeof(struct timer_list), GFP_KERNEL);
 	setup_timer(timer, msgring_bkp_timer, (unsigned long)timer);
-	timer->expires = jiffies + 2;
+	timer->expires = jiffies + HZ/10000;
 	add_timer(timer);
 }
 
-extern spinlock_t nlm_common_pic_lock;
-int register_msgring_handler(int major,
-			     void (*action) (int, int, int, int,
-					     struct msgrng_msg *, void *),
+int register_xlp_msgring_handler(int major,
+			     void (*action) (uint32_t, uint32_t, uint32_t, uint32_t,
+					     uint64_t, uint64_t, uint64_t, uint64_t, void *),
 			     void *dev_id)
 {
 	int ret = 1;
@@ -436,7 +284,6 @@ int register_msgring_handler(int major,
 	spin_lock_irqsave(&msgrng_lock, flags);
 
 
-printk("[%s] major=%d, tx_stid=%d action=%p, dev_id=%p\n", __FUNCTION__, major,tx_stid, action, dev_id);
 	msg_handler_map[major].action = action;
 	msg_handler_map[major].dev_id = dev_id;
 
@@ -481,6 +328,7 @@ printk("[%s] major=%d, tx_stid=%d action=%p, dev_id=%p\n", __FUNCTION__, major,t
 		   therad per core 
 		 */
 
+#if 1 
 		cpus_clear(timer_cpu_mask);
 		for(i = 0; i < NR_CORES; i++) {
 			int core_mask;			
@@ -496,7 +344,8 @@ printk("[%s] major=%d, tx_stid=%d action=%p, dev_id=%p\n", __FUNCTION__, major,t
 				cpu_set(logical_id, timer_cpu_mask);
 			}
 		}
-#if 1
+#endif
+#if 1 
                 preempt_disable();
                 smp_call_function_many(&timer_cpu_mask, enable_msgring_timer, NULL, 1);
                 preempt_enable();
@@ -504,15 +353,15 @@ printk("[%s] major=%d, tx_stid=%d action=%p, dev_id=%p\n", __FUNCTION__, major,t
                         enable_msgring_timer(NULL);
 #endif
 	}
-
+//enable_msgring_int(0);
 	return ret;
 }
 
-EXPORT_SYMBOL(register_msgring_handler);
+EXPORT_SYMBOL(register_xlp_msgring_handler);
 
 static void pic_init(void)
 {
-	nlm_reg_t *mmio = netlogic_io_mmio(NETLOGIC_IO_PIC_OFFSET);
+//	nlm_reg_t *mmio = netlogic_io_mmio(NETLOGIC_IO_PIC_OFFSET);
 	int i = 0;
 	int level;
 	uint32_t thread_mask = (1 << hard_smp_processor_id());
@@ -522,7 +371,7 @@ static void pic_init(void)
 		level = PIC_IRQ_IS_EDGE_TRIGGERED(i);
 
 		/* Bind all PIC irqs to boot cpu */
-		mmio = 0;	/* For compiler sake */
+//		mmio = 0;	/* For compiler sake */
 		/* Use local scheduling and high polarity for all IRTs
 		 * Invalidate all IRTs, by default
 		 */
@@ -535,23 +384,30 @@ atomic_t nlm_common_counters[NR_CPUS][NLM_MAX_COUNTERS] __cacheline_aligned;
 static void nlm_usb_init (void)
 {
 	volatile unsigned int value;
-	nlm_reg_t * gpio_mmio = netlogic_io_mmio(NETLOGIC_IO_GPIO_OFFSET);
-	nlm_reg_t * usb_mmio  = netlogic_io_mmio(NETLOGIC_IO_USB_1_OFFSET);
+//	nlm_reg_t * gpio_mmio = netlogic_io_mmio(NETLOGIC_IO_GPIO_OFFSET);
+	nlm_reg_t * gpio_mmio = (nlm_reg_t*)xlp_gpio_base;
+//	nlm_reg_t * usb_mmio  = netlogic_io_mmio(NETLOGIC_IO_USB_1_OFFSET);
 
 	/* The NLM-Specific USB Block */
-	netlogic_write_reg(usb_mmio, 49, 0x10000000); //Clear Rogue Phy INTs
-	netlogic_write_reg(usb_mmio, 50, 0x1f000000);
+//	netlogic_write_reg(usb_mmio, 49, 0x10000000); //Clear Rogue Phy INTs
+//	netlogic_write_reg(usb_mmio, 50, 0x1f000000);
+
+//	netlogic_write_reg(usb_mmio,  1, 0x07000500);
+	nlm_hal_write_32bit_reg(xlp_usb_ehci_1_base, 49, 0x10000000); //Clear Rogue Phy INTs
+	nlm_hal_write_32bit_reg(xlp_usb_ehci_1_base, 50, 0x1f000000);
 
-	netlogic_write_reg(usb_mmio,  1, 0x07000500);
+	nlm_hal_write_32bit_reg(xlp_usb_ehci_1_base,  1, 0x07000500);
 
 	value = gpio_mmio[21];
 	if ((value >> 22) & 0x01) {
 		printk("Detected USB Host mode..\n");
-		netlogic_write_reg(usb_mmio,  0, 0x02000000);
+//		netlogic_write_reg(usb_mmio,  0, 0x02000000);
+		nlm_hal_write_32bit_reg(xlp_usb_ehci_1_base, 0, 0x02000000);
 	}
 	else {
 		printk("Detected USB Device mode..\n");
-		netlogic_write_reg(usb_mmio,  0, 0x01000000);
+//		netlogic_write_reg(usb_mmio,  0, 0x01000000);
+		nlm_hal_write_32bit_reg(xlp_usb_ehci_1_base,  0, 0x01000000);
 	}
 }
 
@@ -568,6 +424,11 @@ void on_chip_init(void)
 
 	nlm_hal_init();
 
+//	nlm_hal_pcie_base();
+printk("xlp_uart_0_base: %llx xlp_uart_1_base: %llx\n",xlp_uart_0_base, xlp_uart_1_base);
+printk("xlp_usb_ehci_1_base: %llx\n",xlp_usb_ehci_1_base);
+printk("xlp_bridge_base: %llx\n",xlp_bridge_base);
+
 	nlm_hal_fmn_init( xlp_linux_cpu_mask );
 
 	
@@ -581,5 +442,5 @@ void on_chip_init(void)
 	for (j = 0; j < NLM_MAX_COUNTERS; j++)
 			atomic_set(&nlm_common_counters[i][j], 0);
 
-	nlm_usb_init();
+//	nlm_usb_init();
 }
-- 
1.7.0.4

