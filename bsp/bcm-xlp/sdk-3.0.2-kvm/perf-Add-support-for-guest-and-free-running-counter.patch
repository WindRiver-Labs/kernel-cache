From 9111c0091f3e2915df26b1ab78713748339da065 Mon Sep 17 00:00:00 2001
From: Ashok Kumar <ashoks@broadcom.com>
Date: Wed, 8 Jan 2014 19:32:52 +0530
Subject: [PATCH] perf: Add support for guest and free-running-counter.

Commit 75524a98857c1e8a4738e84e0b58592c4e1b2e1b from Broadcom SDK 3.0.2

o) To support virtualization, MIPS VZ supports 4 event codes for each
counter.
   EC0 - root only events
   EC1 - root intervention events
   EC2 - guest only events
   EC3 - Both guest and root intervention events
o) At root, the available EC do not allow to count both root and
   guest cycles at the same time.
   Hence, a 5th counter, FRC in XLP, is added for perf tool so that
   by combining FRC and performance counter cycle event, a fair
   understanding of the root/guest cycles over total cycles FRC
   can be arrived.
o) FRC counter and event cannot be used in sampling mode.
o) 'perf kvm --host stat' - measures in EC0 mode.
o) 'perf kvm --guest stat' - measures in EC1 mode.
o) 'perf kvm --host --guest' is invalid.
o) 'perf kvm stat' - if cycles event is present in the
   list, 'frc' is also chosen automatically.
o) frc also prints the ratio cycles/frc and the freq.

Signed-off-by: Ashok Kumar <ashoks@broadcom.com>
Signed-off-by: Nam Ninh <nam.ninh@windriver.com>

diff --git a/arch/mips/kernel/perf_event_mipsxx.c b/arch/mips/kernel/perf_event_mipsxx.c
index 45f1ffc..1451ff7 100644
--- a/arch/mips/kernel/perf_event_mipsxx.c
+++ b/arch/mips/kernel/perf_event_mipsxx.c
@@ -52,6 +52,20 @@ DEFINE_PER_CPU(struct cpu_hw_events, cpu_hw_events) = {
 	.saved_ctrl = {0},
 };
 
+#ifdef CONFIG_KVM
+static inline u64 read_frc(void)
+{
+	u64 val;
+	__asm__ __volatile__ ("dmfur %0, $16\n": "=r" (val));
+	return val;
+}
+
+static inline void write_frc(u64 val)
+{
+	__asm__ __volatile ("dmtur %0, $16\n": : "r" (val));
+	return ;
+}
+#endif
 /* The description of MIPS performance events. */
 struct mips_perf_event {
 	unsigned int event_id;
@@ -61,9 +75,16 @@ struct mips_perf_event {
 	 * even numbers.
 	 */
 	unsigned int cntr_mask;
+#ifdef CONFIG_KVM
+	#define CNTR_EVEN	0x555
+	#define CNTR_ODD	0xaaa
+	#define CNTR_FRC	0x1000
+	#define CNTR_ALL	0xfff
+#else
 	#define CNTR_EVEN	0x55555555
 	#define CNTR_ODD	0xaaaaaaaa
 	#define CNTR_ALL	0xffffffff
+#endif
 #ifdef CONFIG_MIPS_MT_SMP
 	enum {
 		T  = 0,
@@ -134,10 +155,22 @@ static struct mips_pmu mipspmu;
 #ifdef CONFIG_MIPS_MT_SMP
 #define M_PERFCTL_CONFIG_MASK		0x3fff801f
 #else
+#ifdef CONFIG_KVM
+#define M_PERFCTL_CONFIG_MASK		((0x3 << 23) | 0x1f)
+#else
 #define M_PERFCTL_CONFIG_MASK		0x1f
 #endif
+#endif
 #define M_PERFCTL_EVENT_MASK		0xfe0
 
+#ifdef CONFIG_KVM
+#define M_PERFCTL_EC_0 (0x0 << 23)
+#define M_PERFCTL_EC_1 (0x1 << 23)
+#define M_PERFCTL_EC_2 (0x2 << 23)
+#define M_PERFCTL_EC_3 (0x3 << 23)
+#define M_PERFCTL_EC_MASK (0x3 << 23)
+#endif
+
 
 #ifdef CONFIG_MIPS_PERF_SHARED_TC_COUNTERS
 static int cpu_has_mipsmt_pertccounters;
@@ -223,6 +256,10 @@ static u64 mipsxx_pmu_read_counter_64(unsigned int idx)
 		return read_c0_perfcntr2_64();
 	case 3:
 		return read_c0_perfcntr3_64();
+#ifdef CONFIG_KVM
+	case 4:
+		return read_frc();
+#endif
 	default:
 		WARN_ONCE(1, "Invalid performance counter number (%d)\n", idx);
 		return 0;
@@ -266,6 +303,11 @@ static void mipsxx_pmu_write_counter_64(unsigned int idx, u64 val)
 	case 3:
 		write_c0_perfcntr3_64(val);
 		return;
+#ifdef CONFIG_KVM
+	case 4:
+		write_frc(val);
+		return;
+#endif
 	}
 }
 
@@ -282,6 +324,10 @@ static unsigned int mipsxx_pmu_read_control(unsigned int idx)
 		return read_c0_perfctrl2();
 	case 3:
 		return read_c0_perfctrl3();
+#ifdef CONFIG_KVM
+	case 4:
+		return 0;
+#endif
 	default:
 		WARN_ONCE(1, "Invalid performance counter number (%d)\n", idx);
 		return 0;
@@ -305,6 +351,10 @@ static void mipsxx_pmu_write_control(unsigned int idx, unsigned int val)
 	case 3:
 		write_c0_perfctrl3(val);
 		return;
+#ifdef CONFIG_KVM
+	case 4:
+		return;
+#endif
 	}
 }
 
@@ -761,8 +811,11 @@ static int __n_counters(void)
 		return 2;
 	if (!(read_c0_perfctrl2() & M_PERFCTL_MORE))
 		return 3;
-
+#ifdef CONFIG_KVM
+	return 5;
+#else
 	return 4;
+#endif
 }
 
 static int n_counters(void)
@@ -790,6 +843,11 @@ static void reset_counters(void *arg)
 {
 	int counters = (int)(long)arg;
 	switch (counters) {
+#ifdef CONFIG_KVM
+	case 5:
+		mipsxx_pmu_write_control(4, 0);
+		mipspmu.write_counter(4, 0);
+#endif
 	case 4:
 		mipsxx_pmu_write_control(3, 0);
 		mipspmu.write_counter(3, 0);
@@ -847,6 +905,9 @@ static const struct mips_perf_event xlp_event_map[PERF_COUNT_HW_MAX] = {
 	[PERF_COUNT_HW_CACHE_MISSES] = { 0x07, CNTR_ALL }, /* PAPI_L1_ICM */
 	[PERF_COUNT_HW_BRANCH_INSTRUCTIONS] = { 0x1b, CNTR_ALL }, /* PAPI_BR_CN */
 	[PERF_COUNT_HW_BRANCH_MISSES] = { 0x1c, CNTR_ALL }, /* PAPI_BR_MSP */
+#ifdef CONFIG_KVM
+	[PERF_COUNT_HW_FRC] = {0x0, CNTR_FRC }, /* FRC */
+#endif
 };
 
 /* 24K/34K/1004K cores can share the same cache event map. */
@@ -1200,6 +1261,14 @@ static int __hw_perf_event_init(struct perf_event *event)
 	if (PERF_TYPE_HARDWARE == event->attr.type) {
 		if (event->attr.config >= PERF_COUNT_HW_MAX)
 			return -EINVAL;
+#ifdef CONFIG_KVM
+		if ((attr->config == PERF_COUNT_HW_FRC) && 
+			hwc->sample_period) {
+			pr_err ("Event FRC doesn't support sampling!\n");
+			/* FRC doesn't support sampling */
+			return -EINVAL;
+		}
+#endif
 		pev = mipspmu_map_general_event(event->attr.config);
 	} else if (PERF_TYPE_HW_CACHE == event->attr.type) {
 		pev = mipspmu_map_cache_event(event->attr.config);
@@ -1241,6 +1310,16 @@ static int __hw_perf_event_init(struct perf_event *event)
 	}
 	if (!attr->exclude_hv)
 		hwc->config_base |= M_PERFCTL_SUPERVISOR;
+#ifdef CONFIG_KVM
+	hwc->config_base &= ~M_PERFCTL_EC_MASK; 
+	if (!(attr->exclude_guest ^
+		attr->exclude_host))
+		hwc->config_base |= M_PERFCTL_EC_0;
+	else if (attr->exclude_host)
+		hwc->config_base |= M_PERFCTL_EC_1;
+	else if (attr->exclude_guest)
+		hwc->config_base |= M_PERFCTL_EC_0;
+#endif
 
 	hwc->config_base &= M_PERFCTL_CONFIG_MASK;
 	/*
@@ -1332,6 +1411,9 @@ static int mipsxx_pmu_handle_shared_irq(void)
 				handled = IRQ_HANDLED;			\
 			}						\
 		}
+#ifdef CONFIG_KVM
+	HANDLE_COUNTER(4)
+#endif
 	HANDLE_COUNTER(3)
 	HANDLE_COUNTER(2)
 	HANDLE_COUNTER(1)
diff --git a/include/uapi/linux/perf_event.h b/include/uapi/linux/perf_event.h
index 1517442..c065ed8 100644
--- a/include/uapi/linux/perf_event.h
+++ b/include/uapi/linux/perf_event.h
@@ -56,6 +56,9 @@ enum perf_hw_id {
 	PERF_COUNT_HW_STALLED_CYCLES_BACKEND	= 8,
 	PERF_COUNT_HW_REF_CPU_CYCLES		= 9,
 
+#ifdef CONFIG_CPU_XLP
+	PERF_COUNT_HW_FRC				= 10, /* Free running counter */
+#endif
 	PERF_COUNT_HW_MAX,			/* non-ABI */
 };
 
diff --git a/tools/perf/Makefile b/tools/perf/Makefile
index c0237b4..6f28208 100644
--- a/tools/perf/Makefile
+++ b/tools/perf/Makefile
@@ -110,7 +110,8 @@ ifdef NO_NEWT
 	NO_SLANG=1
 endif
 
-CFLAGS = -fno-omit-frame-pointer -ggdb3 -funwind-tables -Wall -Wextra -std=gnu99 $(CFLAGS_WERROR) $(CFLAGS_OPTIMIZE) $(EXTRA_WARNINGS) $(EXTRA_CFLAGS) $(PARSER_DEBUG_CFLAGS)
+CFLAGS = -fno-omit-frame-pointer -ggdb3 -funwind-tables -Wall -Wextra -std=gnu99 $(CFLAGS_WERROR) $(CFLAGS_OPTIMIZE) -DCONFIG_CPU_XLP \
+		 $(EXTRA_WARNINGS) $(EXTRA_CFLAGS) $(PARSER_DEBUG_CFLAGS)
 EXTLIBS = -lpthread -lrt -lelf -lm
 ALL_CFLAGS = $(CFLAGS) -D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64 -D_GNU_SOURCE
 ALL_LDFLAGS = $(LDFLAGS)
diff --git a/tools/perf/builtin-kvm.c b/tools/perf/builtin-kvm.c
index 533501e..9aac679 100644
--- a/tools/perf/builtin-kvm.c
+++ b/tools/perf/builtin-kvm.c
@@ -1001,16 +1001,30 @@ int cmd_kvm(int argc, const char **argv, const char *prefix __maybe_unused)
 		NULL
 	};
 
+#ifdef CONFIG_CPU_XLP
+	perf_host  = false;
+	perf_guest = false;
+#else
 	perf_host  = 0;
 	perf_guest = 1;
-
+#endif
 	argc = parse_options(argc, argv, kvm_options, kvm_usage,
 			PARSE_OPT_STOP_AT_NON_OPTION);
 	if (!argc)
 		usage_with_options(kvm_usage, kvm_options);
 
+#ifdef CONFIG_CPU_XLP
+	if (!perf_host && !perf_guest)
+		perf_host  = 1;
+
+	if (perf_host && perf_guest) {
+		pr_err ("Only one of host/guest is allowed!\n");
+		return -EINVAL;
+	}
+#else
 	if (!perf_host)
 		perf_guest = 1;
+#endif
 
 	if (!file_name) {
 		if (perf_host && !perf_guest)
@@ -1039,6 +1053,11 @@ int cmd_kvm(int argc, const char **argv, const char *prefix __maybe_unused)
 #if defined(__i386__) || defined(__x86_64__)
 	else if (!strncmp(argv[0], "stat", 4))
 		return kvm_cmd_stat(file_name, argc, argv);
+#else
+#ifdef CONFIG_CPU_XLP
+	else if (!strncmp(argv[0], "stat", 4))
+		return cmd_stat(argc, argv, "kvm");
+#endif
 #endif
 	else
 		usage_with_options(kvm_usage, kvm_options);
diff --git a/tools/perf/builtin-stat.c b/tools/perf/builtin-stat.c
index 7e910ba..00af02d 100644
--- a/tools/perf/builtin-stat.c
+++ b/tools/perf/builtin-stat.c
@@ -903,6 +903,20 @@ static void abs_printout(int cpu, int nr, struct perf_evsel *evsel, double avg)
 			ratio = 1.0 * avg / total;
 
 		fprintf(output, " # %8.3f GHz                    ", ratio);
+#ifdef CONFIG_CPU_XLP
+	} else if (perf_evsel__match(evsel, HARDWARE, HW_FRC)) {
+		total = avg_stats(&runtime_cycles_stats[cpu]);
+
+		if (total)
+			ratio = 1.0 * total / avg;
+		fprintf(output, " # %8.3f (cycle/frc),", ratio);
+
+		total = avg_stats(&runtime_nsecs_stats[cpu]);
+
+		if (total)
+			ratio = 1.0 * avg / total;
+		fprintf(output, " %8.3f GHz", ratio);
+#endif
 	} else if (runtime_nsecs_stats[cpu].n != 0) {
 		char unit = 'M';
 
@@ -1491,6 +1505,22 @@ int cmd_stat(int argc, const char **argv, const char *prefix __maybe_unused)
 	if (add_default_attributes())
 		goto out;
 
+#ifdef CONFIG_CPU_XLP
+	if (prefix && strncmp(prefix, "kvm", 3) == 0) {
+		list_for_each_entry(pos, &evsel_list->entries, node) {
+			if (pos->attr.config == PERF_COUNT_HW_CPU_CYCLES) {
+				struct perf_event_attr frc_attr [] = {
+					{	.type = PERF_TYPE_HARDWARE,
+						.config = PERF_COUNT_HW_FRC },
+				};
+				if (perf_evlist__add_default_attrs(evsel_list, frc_attr) < 0)
+					return -1;
+				break;
+			}
+		}
+	}
+#endif
+
 	perf_target__validate(&target);
 
 	if (perf_evlist__create_maps(evsel_list, &target) < 0) {
diff --git a/tools/perf/util/evsel.c b/tools/perf/util/evsel.c
index 63b6f8c..d362893 100644
--- a/tools/perf/util/evsel.c
+++ b/tools/perf/util/evsel.c
@@ -184,6 +184,9 @@ const char *perf_evsel__hw_names[PERF_COUNT_HW_MAX] = {
 	"stalled-cycles-frontend",
 	"stalled-cycles-backend",
 	"ref-cycles",
+#ifdef CONFIG_CPU_XLP
+	"free-runnning-counter",
+#endif
 };
 
 static const char *__perf_evsel__hw_name(u64 config)
diff --git a/tools/perf/util/parse-events.c b/tools/perf/util/parse-events.c
index 1f19e3b..1ff41b8 100644
--- a/tools/perf/util/parse-events.c
+++ b/tools/perf/util/parse-events.c
@@ -69,6 +69,12 @@ static struct event_symbol event_symbols_hw[PERF_COUNT_HW_MAX] = {
 		.symbol = "ref-cycles",
 		.alias  = "",
 	},
+#ifdef CONFIG_CPU_XLP
+	[PERF_COUNT_HW_FRC] = {
+		.symbol = "free-runnning-counter",
+		.alias  = "frc",
+	},
+#endif
 };
 
 static struct event_symbol event_symbols_sw[PERF_COUNT_SW_MAX] = {
diff --git a/tools/perf/util/parse-events.l b/tools/perf/util/parse-events.l
index e9d1134..27f5198 100644
--- a/tools/perf/util/parse-events.l
+++ b/tools/perf/util/parse-events.l
@@ -135,6 +135,7 @@ branch-instructions|branches			{ return sym(yyscanner, PERF_TYPE_HARDWARE, PERF_
 branch-misses					{ return sym(yyscanner, PERF_TYPE_HARDWARE, PERF_COUNT_HW_BRANCH_MISSES); }
 bus-cycles					{ return sym(yyscanner, PERF_TYPE_HARDWARE, PERF_COUNT_HW_BUS_CYCLES); }
 ref-cycles					{ return sym(yyscanner, PERF_TYPE_HARDWARE, PERF_COUNT_HW_REF_CPU_CYCLES); }
+free-running-counter|frc	{ return sym(yyscanner, PERF_TYPE_HARDWARE, PERF_COUNT_HW_FRC); }
 cpu-clock					{ return sym(yyscanner, PERF_TYPE_SOFTWARE, PERF_COUNT_SW_CPU_CLOCK); }
 task-clock					{ return sym(yyscanner, PERF_TYPE_SOFTWARE, PERF_COUNT_SW_TASK_CLOCK); }
 page-faults|faults				{ return sym(yyscanner, PERF_TYPE_SOFTWARE, PERF_COUNT_SW_PAGE_FAULTS); }
-- 
1.9.1

