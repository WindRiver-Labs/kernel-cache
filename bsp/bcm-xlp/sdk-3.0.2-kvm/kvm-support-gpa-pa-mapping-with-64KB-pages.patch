From ba6d87e4143e1be618254a82201a68e53776e6ff Mon Sep 17 00:00:00 2001
From: Yonghong Song <ysong@broadcom.com>
Date: Tue, 14 May 2013 10:24:05 -0700
Subject: [PATCH] kvm: support gpa->pa mapping with 64KB pages

Commit 28778daac29967ec3400e61fccb397a8edcc682a from Broadcom SDK 3.0.2

Signed-off-by: Yonghong Song <ysong@broadcom.com>
Signed-off-by: Nam Ninh <nam.ninh@windriver.com>

diff --git a/arch/mips/kvm/kvm.c b/arch/mips/kvm/kvm.c
index 507054a..0fac718 100644
--- a/arch/mips/kvm/kvm.c
+++ b/arch/mips/kvm/kvm.c
@@ -117,6 +117,7 @@ static void kvm_sync_gpa_map(struct kvm *kvm)
 			/* map gpa to pte in page table pointed to by gpa_pgd */
 			pgdp = (pgd_t *)gpa_pgd + __pgd_offset(gpa);
 			pudp = (pud_t *)pgdp;
+#ifndef __PAGETABLE_PMD_FOLDED
 			if (*(unsigned long *)pudp == (unsigned long)invalid_pmd_table) {
 				/* allocate a page for pmd and initialize it */
 				ptr = (unsigned long *)__get_free_page(GFP_KERNEL|GFP_DMA);
@@ -125,7 +126,6 @@ static void kvm_sync_gpa_map(struct kvm *kvm)
 				*(unsigned long *)pudp = (unsigned long)ptr;
 
 			}
-
 			pmdp = (pmd_t *)*(unsigned long *)pudp + __pmd_offset(gpa);
 			if (*(unsigned long *)pmdp == (unsigned long)invalid_pte_table) {
 				/* allocate a page for pmd and initialize it */
@@ -134,8 +134,18 @@ static void kvm_sync_gpa_map(struct kvm *kvm)
 					ptr[i] = 0;
 				*(unsigned long *)pmdp = (unsigned long)ptr;
 			}
-
 			ptep = (pte_t *)*(unsigned long *)pmdp + __pte_offset(gpa);
+#else
+			if (*(unsigned long *)pudp == (unsigned long)invalid_pte_table) {
+				/* allocate a page for pmd and initialize it */
+				ptr = (unsigned long *)__get_free_page(GFP_KERNEL|GFP_DMA);
+				for (i = 0; i < PTRS_PER_PTE; i++)
+					ptr[i] = 0;
+				*(unsigned long *)pudp = (unsigned long)ptr;
+
+			}
+			ptep = (pte_t *)*(unsigned long *)pudp + __pte_offset(gpa);
+#endif
 			*ptep = pte;
 
 			/* flush the Reset Vector region as it will be accessed as uncached. */
@@ -425,7 +435,9 @@ int kvm_arch_vcpu_init(struct kvm_vcpu *vcpu)
 	vcpu->arch.hva_pgd = 0;
 	vcpu->arch.gpa_pgd = 0;
 	vcpu->arch.nmi = 0;
+#if 0
 	printk("Guest vcpu %p initialization\n", vcpu);
+#endif
 	return 0;
 }
 
diff --git a/arch/mips/kvm/xlp.c b/arch/mips/kvm/xlp.c
index 41314cc..ebf43e6 100644
--- a/arch/mips/kvm/xlp.c
+++ b/arch/mips/kvm/xlp.c
@@ -233,14 +233,15 @@ static int kvm_get_new_guest_id(void)
 static void xlp_kvm_free_gpa_pgd(pgd_t *gpa_pgd)
 {
 	unsigned long *p, *end;
-	int i;
 
 	p = (unsigned long *)gpa_pgd;
 	end = p + PTRS_PER_PGD;
 
 	for(; p < end; p++) {
+#ifndef __PAGETABLE_PMD_FOLDED
 		if (*p != (unsigned long)invalid_pmd_table) {
 			unsigned long *p1 = (unsigned long*)*p;
+			int i;
 
 			for (i = 0; i < PTRS_PER_PMD; i++) {
 				if (p1[i] != (unsigned long)invalid_pte_table) {
@@ -249,6 +250,11 @@ static void xlp_kvm_free_gpa_pgd(pgd_t *gpa_pgd)
 			}
 			__free_page((void *)*p);
 		}
+#else
+		if (*p != (unsigned long)invalid_pte_table) {
+			__free_page((void *)*p);
+		}
+#endif
 	}
 
 	/* free pgd table page */
diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 59d104f..aef2b18 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -59,6 +59,7 @@ static void nlm_kvm_populate_page(struct pt_regs *regs, unsigned long address,
 	vcpu = (struct kvm_vcpu *)regs->cp0_osscratch7;
 	pgdp = (pgd_t *)vcpu->arch.gpa_pgd + __pgd_offset(gpa_address);
 	pudp = (pud_t *)pgdp;
+#ifndef __PAGETABLE_PMD_FOLDED
 	if (*(unsigned long *)pudp == (unsigned long)invalid_pmd_table) {
 		/* allocate a page for pmd and initialize it */
 		ptr = (unsigned long *)__get_free_page(GFP_KERNEL|GFP_DMA);
@@ -66,17 +67,25 @@ static void nlm_kvm_populate_page(struct pt_regs *regs, unsigned long address,
 			ptr[i] = (unsigned long)invalid_pte_table;
 		*(unsigned long *)pudp = (unsigned long)ptr;
 	}
-
 	pmdp = pmd_offset(pudp, gpa_address);
 	if (*(unsigned long *)pmdp == (unsigned long)invalid_pte_table) {
-		/* allocate a page for pmd and initialize it */
+		/* allocate a page for pte table and initialize it */
 		ptr = (unsigned long *)__get_free_page(GFP_KERNEL|GFP_DMA);
 		for (i = 0; i < PTRS_PER_PTE; i++)
 			ptr[i] = 0;
 		*(unsigned long *)pmdp = (unsigned long)ptr;
 	}
-
 	ptep = pte_offset(pmdp, gpa_address);
+#else
+	if (*(unsigned long *)pudp == (unsigned long)invalid_pte_table) {
+		/* allocate a page for pte table and initialize it */
+		ptr = (unsigned long *)__get_free_page(GFP_KERNEL|GFP_DMA);
+		for (i = 0; i < PTRS_PER_PTE; i++)
+			ptr[i] = 0;
+		*(unsigned long *)pudp = (unsigned long)ptr;
+	}
+	ptep = pte_offset((pmd_t *)pudp, gpa_address);
+#endif
 	*page_size = PAGE_SIZE;
 	*ptep = pte;
 	*pa_address = (pte_val(pte) >> (_PAGE_GLOBAL_SHIFT + 6)) << 12;
-- 
1.9.1

