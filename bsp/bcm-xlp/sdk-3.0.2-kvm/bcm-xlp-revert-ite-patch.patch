From 86743f9217ebf9656c9805f49432a222a055be67 Mon Sep 17 00:00:00 2001
From: Nam Ninh <nam.ninh@windriver.com>
Date: Wed, 26 Nov 2014 12:57:00 -0500
Subject: [PATCH] bcm-xlp: revert ite patch.

Revert [bcm-xlp: rt and cgl: import ite.c from SDK 2.2.7]

This patch was imported from SDK 2.2.7 into the base bcm-xlp BSP.
We remove this patch for 2 reasons:
- The patch was removed in SDK 3.0.2
- The patch causes  the guest to hang after IRQ is initialized with
  this log:

[    0.000000] Dentry cache hash table entries: 65536 (order: 3, 524288 bytes)
[    0.000000] Inode-cache hash table entries: 32768 (order: 2, 262144 bytes)
[    0.000000] Memory: 504064k/523136k available (7111k kernel code, 19072k reserved, 3147k data, 448k init, 0k highmem)
[    0.000000] SLUB: HWalign=32, Order=0-3, MinObjects=0, CPUs=16, Nodes=1
[    0.000000] Hierarchical RCU implementation.
[    0.000000] 	RCU restricting CPUs from NR_CPUS=128 to nr_cpu_ids=16.
[    0.000000] RCU: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=16
[    0.000000] NR_IRQS:1024
[    0.000000] Init IRQ for node 0

Signed-off-by: Nam Ninh <nam.ninh@windriver.com>

diff --git a/arch/mips/include/asm/netlogic/xlp-hal/pic.h b/arch/mips/include/asm/netlogic/xlp-hal/pic.h
index 2761297698a6..b1df770e761d 100644
--- a/arch/mips/include/asm/netlogic/xlp-hal/pic.h
+++ b/arch/mips/include/asm/netlogic/xlp-hal/pic.h
@@ -152,9 +152,6 @@
 #define PIC_IRT0                0x74
 #define PIC_IRT(i)              (PIC_IRT0 + ((i) * 2))
 
-#define PIC_MEMACCESS		0x12
-#define PIC_ITEPOINTER(i)	(0x54 + (i) * 2)
-
 #define PIC_9XX_PENDING_0	0x6
 #define PIC_9XX_PENDING_1	0x8
 #define PIC_9XX_PENDING_2	0xa
@@ -227,35 +224,6 @@
 
 #define PIC_CLOCK_TIMER			7
 
-#define NLM_MAX_NODES			4
-#define NLM_MAX_CPU_PER_NODE		64
-#define XLP_2XX_ITE_ENTRIES		8
-#define XLP_9XX_ITE_ENTRIES		64
-#define XLP_9XX_ITEPTR_ENTRIES		16
-#define xlp_ite_cpu_set(base, cpu, ite) xlp_ite_cpu_op(base, cpu, ite, 1)
-#define xlp_ite_cpu_clear(base, cpu, ite) xlp_ite_cpu_op(base, cpu, ite, 0)
-
-#define XLP_2XX_IRTENT_ENABLE	(1ULL << 31)
-#define XLP_2XX_IRTENT_NMI		(1ULL << 29)
-#define XLP_2XX_IRTENT_SCH_LCL	(1ULL << 28)
-#define XLP_2XX_IRTENT_RVEC(x)	(((x) & 0x3fULL) << 20)
-#define XLP_2XX_IRTENT_DT		(1ULL << 19)
-#define XLP_2XX_IRTENT_DB(x)	((x & 7) << 16)
-#define XLP_2XX_IRTENT_DTE(x)	((x) & 0xffff)
-
-#define XLP_9XX_IRTENT_ENABLE	(1ULL << 22)
-#define XLP_9XX_IRTENT_NMI		(1ULL << 23)
-#define XLP_9XX_IRTENT_SCH_LCL	(1ULL)
-#define XLP_9XX_IRTENT_RVEC(x)	(((x) & 0x3fULL) << 24)
-#define XLP_9XX_IRTENT_DT		(1ULL << 21)
-#define XLP_9XX_IRTPOINTERENT_DB(x)	((x & 15) << 16)
-#define XLP_IRTENT_DTE(x)	((x) & 0xffff)
-extern int xlp_span_multiple_nodes(const struct cpumask *mask);
-extern void constrict_mask_to_node(u8 node, struct cpumask *dst,
-					const struct cpumask *src);
-extern void xlp_set_cpumask_on_node(int node, uint64_t base, int irq,
-				int irt, const struct cpumask *m);
-
 #if !defined(LOCORE) && !defined(__ASSEMBLY__)
 
 /*
@@ -290,20 +258,6 @@ nlm_9xx_pic_write_irt(uint64_t base, int irt_num, int en, int nmi,
 }
 
 static inline void
-nlm_9xx_pic_write_irt_ite(uint64_t base, int irt_num, int en, int nmi,
-	int sch, int vec, int dt, int db, int iteptr)
-{
-	uint64_t val;
-
-	val = (((uint64_t)en & 0x1) << 22) | ((nmi & 0x1) << 23) |
-			((0 /*mc*/) << 20) | ((vec & 0x3f) << 24) |
-			((dt & 0x1) << 21) | (iteptr << 16) | sch;
-
-	nlm_write_pic_reg(base, PIC_9XX_IRT(irt_num), val);
-}
-
-
-static inline void
 nlm_pic_write_irt(uint64_t base, int irt_num, int en, int nmi,
 	int sch, int vec, int dt, int db, int dte)
 {
@@ -318,19 +272,6 @@ nlm_pic_write_irt(uint64_t base, int irt_num, int en, int nmi,
 }
 
 static inline void
-nlm_pic_write_irt_ite(uint64_t base, int irt_num, int en, int nmi,
-	int sch, int vec, int dt, int db, int dte)
-{
-	uint64_t val;
-
-	val = (((uint64_t)en & 0x1) << 31) | ((nmi & 0x1) << 29) |
-			((sch & 0x1) << 28) | ((vec & 0x3f) << 20) |
-			((dt & 0x1) << 19) | ((dte & 0x7) << 16);
-
-	nlm_write_pic_reg(base, PIC_IRT(irt_num), val);
-}
-
-static inline void
 nlm_pic_write_irt_direct(uint64_t base, int irt_num, int en, int nmi,
 	int sch, int vec, int cpu)
 {
@@ -343,19 +284,6 @@ nlm_pic_write_irt_direct(uint64_t base, int irt_num, int en, int nmi,
 			1 << (cpu & 0xf));	/* thread mask */
 }
 
-static inline void
-nlm_pic_write_irt_direct_ite(uint64_t base, int irt_num, int en, int nmi,
-	int sch, int vec, int ite)
-{
-	if (cpu_is_xlp9xx())
-		nlm_9xx_pic_write_irt_ite(base, irt_num, en, nmi, sch, vec,
-							0, 0, ite);
-	else
-		nlm_pic_write_irt_ite(base, irt_num, en, nmi, sch, vec, 0,
-			0, ite);
-}
-
-
 static inline uint64_t
 nlm_pic_read_timer(uint64_t base, int timer)
 {
@@ -451,12 +379,6 @@ nlm_pic_init_irt(uint64_t base, int irt, int irq, int hwt, int en)
 	nlm_pic_write_irt_direct(base, irt, en, 0, 0, irq, hwt);
 }
 
-static inline void
-nlm_pic_init_irt_ite(uint64_t base, int irt, int irq, int ite, int en)
-{
-	nlm_pic_write_irt_direct_ite(base, irt, en, 0, 1, irq, ite);
-}
-
 int nlm_irq_to_irt(int irq);
 
 #endif /* __ASSEMBLY__ */
diff --git a/arch/mips/netlogic/common/Makefile b/arch/mips/netlogic/common/Makefile
index 7d9726d97002..97a715adf4b5 100644
--- a/arch/mips/netlogic/common/Makefile
+++ b/arch/mips/netlogic/common/Makefile
@@ -1,4 +1,3 @@
-obj-y				+= ite.o #zjy add
 obj-y				+= irq.o time.o reset.o memory.o io.o
 obj-y				+= nlm_fs_tbl.o	nlm_fs_handler.o
 obj-y				+= nlm-dma.o
diff --git a/arch/mips/netlogic/common/irq.c b/arch/mips/netlogic/common/irq.c
index f853177af965..657c1859be91 100644
--- a/arch/mips/netlogic/common/irq.c
+++ b/arch/mips/netlogic/common/irq.c
@@ -131,55 +131,12 @@ static void xlp_pic_unmask(struct irq_data *d)
 	nlm_pic_ack(pd->node->picbase, pd->irt);
 }
 
-/*
- * Set affinity for the intx for chips
- *
- * When an interrupt is setup, its EIMR bit is set in all online cpus. That is,
- * any cpu _can_ receive that interrupt. But it is the IRT entry that decides
- * whether to send that interrupt (i.e, whether to set EIRR bit or not) to any
- * particular CPU.
- *
- * IRT has two modes to decide the target CPUs for one interrupt.
- * Method 1 : Using IRT table entry bits DT and DTE
- * If DT==1, this interrupt can be routed to a max of 16 CPUs (well, hw threads)
- * If DT==1, there is one more level of indirection called DTE. Each DTE entry
- * has 128 bits and there are a total of 8 DTE entries. Each DTE entry contains
- * the bitmask of target CPU for an interrupt. One of them is chosen based
- * on the specified cpumask.
- *
- * The actual bitmask can be different from the specified bitmask based
- * on the logic of xlp_closest_match_cpumask()
- */
-static int xlp_pic_set_affinity(struct irq_data *d,
-			const struct cpumask *dest, bool force)
-{
-	struct cpumask m;
-	unsigned long flags;
-	struct nlm_pic_irq *pd = irq_data_get_irq_handler_data(d);
-	int node = pd->node - nlm_nodes;
-
-	if (xlp_span_multiple_nodes(dest) != 0) {
-		/* this is the policy for MSI. Change later TODO */
-		constrict_mask_to_node(node, &m, dest);
-	} else {
-		cpumask_copy(&m, dest);
-	}
-	raw_spin_lock_irqsave(&pd->node->piclock, flags);
-	/* Note : node == 0 passed for link_irq*/
-	xlp_set_cpumask_on_node(node, pd->node->picbase,
-		pd->picirq, pd->irt, &m);
-	raw_spin_unlock_irqrestore(&pd->node->piclock, flags);
-
-	return 0;
-}
-
 static struct irq_chip xlp_pic = {
 	.name		= "XLP-PIC",
 	.irq_enable	= xlp_pic_enable,
 	.irq_disable	= xlp_pic_disable,
 	.irq_mask_ack	= xlp_pic_mask_ack,
 	.irq_unmask	= xlp_pic_unmask,
-	.irq_set_affinity = xlp_pic_set_affinity,
 	.flags		= IRQCHIP_ONESHOT_SAFE,
 };
 
@@ -259,8 +216,7 @@ void nlm_set_pic_extra_ack(int node, int irq, void (*xack)(struct irq_data *))
 static void nlm_init_node_irqs(int node)
 {
 	struct nlm_soc_info *nodep;
-	int i, irt, ite;
-	extern void xlp_pic_init(uint64_t base);
+	int i, irt;
 
 	pr_info("Init IRQ for node %d\n", node);
 	nodep = nlm_get_node(node);
@@ -273,12 +229,10 @@ static void nlm_init_node_irqs(int node)
 		if (irt == -2)		/* not a direct PIC irq */
 			continue;
 
-		ite = cpu_is_xlp9xx() ? 8 : 5;
-		nlm_pic_init_irt_ite(nodep->picbase, irt, i,
-				ite, 0);
+		nlm_pic_init_irt(nodep->picbase, irt, i,
+				node * nlm_threads_per_node(), 0);
 		nlm_setup_pic_irq(node, i, i, irt);
 	}
-	xlp_pic_init(nodep->picbase);
 }
 
 void nlm_smp_irq_init(int hwcpuid)
diff --git a/arch/mips/netlogic/common/ite.c b/arch/mips/netlogic/common/ite.c
deleted file mode 100644
index 499985787800..000000000000
--- a/arch/mips/netlogic/common/ite.c
+++ /dev/null
@@ -1,538 +0,0 @@
-/*-
- * Copyright (c) 2003-2012 Broadcom Corporation
- * All Rights Reserved
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- * 1. Redistributions of source code must retain the above copyright
- *    notice, this list of conditions and the following disclaimer.
- * 2. Redistributions in binary form must reproduce the above copyright
- *    notice, this list of conditions and the following disclaimer in
- *    the documentation and/or other materials provided with the
- *    distribution.
- *
- * THIS SOFTWARE IS PROVIDED BY BROADCOM ``AS IS'' AND ANY EXPRESS OR
- * IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
- * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
- * ARE DISCLAIMED. IN NO EVENT SHALL BROADCOM OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
- * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
- * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
- * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
- * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
- * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
- * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- *
- * #BRCM_2# */
-
-#include <linux/types.h>
-#include <linux/init.h>
-#include <linux/smp.h>
-#include <linux/interrupt.h>
-#include <linux/spinlock.h>
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/timer.h>
-#include <linux/cpumask.h>
-#include <linux/nodemask.h>
-#include <linux/netdevice.h>
-
-#include <asm/netlogic/mips-extns.h>
-#include <asm/netlogic/interrupt.h>
-#include <asm/netlogic/haldefs.h>
-#include <asm/netlogic/common.h>
-
-#if defined(CONFIG_CPU_XLP)
-#include <asm/netlogic/xlp-hal/iomap.h>
-#include <asm/netlogic/xlp-hal/xlp.h>
-#include <asm/netlogic/xlp-hal/pic.h>
-#elif defined(CONFIG_CPU_XLR)
-#include <asm/netlogic/xlr/iomap.h>
-#include <asm/netlogic/xlr/pic.h>
-#include <asm/netlogic/xlr/fmn.h>
-#endif
-/*
- * xlp_ites[node][0-3] = {0x1, 0xffffffff, 0x0000ffff, 0xffff0000};//local only
- */
-static struct cpumask xlp_ites[NLM_MAX_NODES][XLP_9XX_ITE_ENTRIES];
-static DEFINE_SPINLOCK(xlp_ites_lock);
-
-/* Modifications below to read actual programmed values
- * instead of just dumping table */
-void dump_all_ites(uint64_t base)
-{
-	u8 node, i;
-	u32 ite3, ite2, ite1, ite0;
-	u64 tmp, reg, val;
-	char buf[140];
-	unsigned long flags;
-
-	for_each_online_node(node) {
-		if (!cpu_is_xlp9xx()) {
-			for (i = 0; i < XLP_2XX_ITE_ENTRIES; i++) {
-				cpumask_scnprintf(buf, 140, &xlp_ites[node][i]);
-				spin_lock_irqsave(&xlp_ites_lock, flags);
-				reg = PIC_ITE0_N2_N3 + 4 * i;
-				tmp = nlm_read_pic_reg(base, reg);
-				ite3 = tmp >> 32;
-				ite2 = tmp & 0xffffffffULL;
-				reg = PIC_ITE0_N0_N1 + 4 * i;
-				tmp = nlm_read_pic_reg(base, reg);
-				ite1 = tmp >> 32;
-				ite0 = tmp & 0xffffffffULL;
-				spin_unlock_irqrestore(&xlp_ites_lock, flags);
-			}
-		} else {
-			for (i = 0; i < XLP_9XX_ITE_ENTRIES; i++) {
-				cpumask_scnprintf(
-				buf, 140, &xlp_ites[node][i]);
-				spin_lock_irqsave(&xlp_ites_lock, flags);
-				reg = PIC_MEMACCESS;
-				val = 0;
-				val |= ((u64)i << 48) | (1ULL << 61);
-				nlm_write_pic_reg(base, reg, val);
-				val = nlm_read_pic_reg(base, reg);
-				tmp = val & 0xffffffffffULL;
-				val = (1UL << 56);
-				val |= ((u64)i << 48) | (1ULL << 61);
-				nlm_write_pic_reg(base, reg, val);
-				val = nlm_read_pic_reg(base, reg);
-				val &= 0xffffffULL;
-				tmp |= (val << 40);
-				ite0 = tmp & 0xffffffffULL;
-				ite1 = (tmp >> 32) & 0xffffffffULL;
-				ite2 = ite3 = 0;
-				spin_unlock_irqrestore(&xlp_ites_lock, flags);
-			}
-		}
-	}
-
-	return;
-}
-
-
-/* This function sets the given ITE's cpu bit on node node.
- *
- * @node	: node on which ITE is to be set
- * @cpu		: target cpu id
- * @ite		: ITE index
- * @bitval	: 0 to clear, 1 to set
- */
-void xlp_ite_cpu_op(uint64_t base, u8 cpu, u8 ite, u8 bitval)
-{
-	unsigned long flags;
-	u64 val, reg;
-	u8 bit;
-
-	/* No param checking, must be checked before calling.
-	 * Target cpu id decices whether to use THREADEN01 or THREADEN23
-	 * i.e., if target cpu < 64, use THREADEN01 as base else THREADEN23 */
-	if (!cpu_is_xlp9xx()) {
-		reg = (cpu < 64) ? PIC_ITE_N0_N1(ite) :
-						PIC_ITE_N2_N3(ite);
-		bit = cpu % 64;
-		spin_lock_irqsave(&xlp_ites_lock, flags);
-		val = nlm_read_pic_reg(base, reg);
-		val = (bitval == 0) ?
-			(val & ~(1ULL << bit)) :
-			(val | (1ULL << bit));
-		nlm_write_pic_reg(base, reg, val);
-		spin_unlock_irqrestore(&xlp_ites_lock, flags);
-	} else {
-		reg = PIC_MEMACCESS;
-		val = (cpu < 40) ? 0 : (1ULL << 56);
-		val |= ((u64)ite << 48) | (1ULL << 61);
-		spin_lock_irqsave(&xlp_ites_lock, flags);
-		nlm_write_pic_reg(base, reg, val);
-		mb();
-		val = nlm_read_pic_reg(base, reg);
-		bit = (cpu < 40) ? cpu : (cpu - 40);
-		val = (bitval == 0) ?
-			(val & ~(1ULL << bit)) :
-			(val | (1ULL << bit));
-		val &= 0xffffffffffULL;
-		val |= (1ULL << 63) | (1ULL << 61);
-		val |= (cpu < 40) ? 0 : (1ULL << 56);
-		val |= ((u64)ite << 48);
-		nlm_write_pic_reg(base, reg, val);
-		mb();
-		val = (cpu < 40) ? 0 : (1ULL << 56);
-		val |= ((u64)ite << 48) | (1ULL << 61);
-		nlm_write_pic_reg(base, reg, val);
-		mb();
-		val = nlm_read_pic_reg(base, reg);
-		spin_unlock_irqrestore(&xlp_ites_lock, flags);
-	}
-}
-extern struct cpumask nlm_cpumask;
-/* This function would program ITE values on node given by the cpumask
- * @cpumask	: cpumask to program on ITE
- * @node	: node on which ITE should be programmed
- * @ite		: ITE to program
- * @scope	: program ITE only on the given node (0) or all nodes (1)
- */
-void xlp_cpumask_to_node_ite(const struct cpumask *m,
-				uint64_t base, u8 ite, u8 scope)
-{
-	__label__ prog_all;
-	struct cpumask t;
-	int cpu = 0, last;
-
-	if (scope != 0)
-		goto prog_all;
-
-	/* When the scope is 0, program node ITEs with target as
-	 * local cpus only */
-	last = cpu + NLM_MAX_CPU_PER_NODE - 1;
-	if (last >= NR_CPUS)
-		return;
-	cpumask_and(&t, m, &nlm_cpumask);
-	for (; cpu <= last; cpu++)
-		cpumask_test_cpu(cpu, &t) ?
-			xlp_ite_cpu_set(base, cpu, ite) :
-			xlp_ite_cpu_clear(base, cpu, ite);
-	return;
-prog_all:
-	/* Here we program the specified ITE in all nodes with the cpumask
-	 * passed. */
-	/* TBD TODO */
-	return;
-}
-
-/* Once all CPUs are up, walk through the node mask and program all
- * ITEs in the PICs */
-void xlp_prog_all_node_ites(uint64_t base)
-{
-	u8 i, node;
-
-	for_each_online_node(node) {
-		if (!cpu_is_xlp9xx()) {
-			/* 4 is the ITE that redirects int.s to all cpus */
-			for (i = 0; i < XLP_2XX_ITE_ENTRIES; i++)
-				xlp_cpumask_to_node_ite(&xlp_ites[node][i],
-					base, i, (i == 4));
-		} else {
-			/* 4 is the ITE that redirects int.s to all cpus */
-			for (i = 0; i < XLP_9XX_ITE_ENTRIES; i++)
-				xlp_cpumask_to_node_ite(&xlp_ites[node][i],
-					base, i, (i == 4));
-			for (i = 0; i < XLP_9XX_ITEPTR_ENTRIES; i++)
-				nlm_write_pic_reg(base,  PIC_ITEPOINTER(i), i);
-		}
-	}
-	dump_all_ites(base);
-}
-
-/* Checks if a mask spans multiple nodes
- *
- * @mask	: cpumask to check for multiple node span
- */
-int xlp_span_multiple_nodes(const struct cpumask *mask)
-{
-	int l, f;
-	f = cpumask_first(mask);
-	l = find_last_bit(cpumask_bits(mask), NR_CPUS);
-	if ((f/NLM_MAX_CPU_PER_NODE) != (l/NLM_MAX_CPU_PER_NODE))
-		return -EINVAL;
-	return 0;
-}
-
-/*
- * In XLP cpu mask for setting affinity of an interrupt cannot span multiple
- * nodes. Although this is not a h/w restriction, the effort to implement
- * this feature does not justify the potential benefit; not only that handling
- * non local interrupts are slightly slower, it could be expensive in terms of
- * memory access and other resource utilization
- *
- * @node	: node to which mask `mask` to be restricted
- * @src		: mask to restrict
- * @dst		: restricted mask (result)
- */
-void constrict_mask_to_node(u8 node, struct cpumask *dst,
-				const struct cpumask *src)
-{
-	int i;
-
-	cpumask_clear(dst);
-	for (i = NLM_MAX_CPU_PER_NODE * node;
-		i < (NLM_MAX_CPU_PER_NODE * (node + 1)); i++)
-		cpumask_set_cpu(i, dst);
-	cpumask_and(dst, dst, &nlm_cpumask);
-	cpumask_and(dst, dst, src);
-	return;
-}
-
-
-/*
- * This function returns closest match cpumask among the supported bitmasks
- * in XLP
- * Logic is moot, need to improve it later.
- *
- * @m	: user supplied cpumask
- */
-static int xlp_closest_match_cpumask(u8 node, const struct cpumask *m)
-{
-	int i;
-	char buf[72];
-	struct cpumask t, a;
-	int ite_count;
-	/* m will be a logical cpu mask.
-	 * If all threads are enabled, this will
-	 * match the physical cpu mask.
-	 * If not, this won't match and this function
-	 * won't work, however the fall-back is to route
-	 * interrupts to all CPUs so the system will still work,
-	 * just not necessarily with the desired affinity.
-	 * So we have to convert the logical cpu mask to a
-	 * physical mask first. */
-	cpumask_scnprintf(buf, 72, m);
-	cpumask_clear(&a);
-	for_each_cpu(i, m)
-		cpumask_set_cpu(cpu_logical_map(i), &a);
-	cpumask_and(&a, &a, &nlm_cpumask);
-	constrict_mask_to_node(node, &t, &a);
-	cpumask_clear(&a);
-
-	if (cpu_is_xlp9xx())
-		ite_count = XLP_9XX_ITEPTR_ENTRIES;
-	else
-		ite_count = XLP_2XX_ITE_ENTRIES;
-
-	for (i = 0; i < ite_count; i++) {
-		cpumask_and(&a, &xlp_ites[node][i], &nlm_cpumask);
-		if (cpumask_equal(&t, &a)) {
-			cpumask_scnprintf(buf, 72, m);
-			if (i == 4)
-				continue;
-			return i;
-		}
-	}
-	cpumask_scnprintf(buf, 72, m);
-	cpumask_scnprintf(buf, 72, &t);
-	return 1; /* if no match, point to all local cpus */
-}
-
-/*
- * This function programs the ITE on the IRT entry
- * on all online nodes
- * @m	: CPU mask resulting from xlp_closest_match_cpumask()
- * call
- */
-void xlp_set_cpumask_on_node(int node, uint64_t base, int irq,
-				int irt, const struct cpumask *m)
-{
-	u8 ite;
-	u64 val;
-
-	ite = xlp_closest_match_cpumask(node, m);
-	if (!cpu_is_xlp9xx()) {
-		/* xlp_pic_init() has set default values.
-		 * Override them */
-		val = XLP_2XX_IRTENT_ENABLE |
-			XLP_2XX_IRTENT_SCH_LCL |
-			XLP_2XX_IRTENT_RVEC(irq) |
-			XLP_2XX_IRTENT_DB(ite);
-		nlm_write_pic_reg(base, PIC_IRT(irt), val);
-	} else {
-		val = XLP_9XX_IRTENT_ENABLE |
-			XLP_9XX_IRTENT_RVEC(irq) |
-			XLP_9XX_IRTPOINTERENT_DB(ite) |
-			XLP_9XX_IRTENT_SCH_LCL;
-		nlm_write_pic_reg(base, PIC_9XX_IRT(irt), val);
-	}
-
-	return;
-}
-
-
-/* helper function to create cpumask from unsigned long
- * Easiest way is to create it directly using bitmap_copy.
- * For some reason, this was not successful.
- *
- * @m	: cpumask pointer to populate. Lower 32 bits must be 0
- * @u	: u32 variable pointer with bitmask
- */
-void u32_to_cpumask(struct cpumask *m, u32 bm)
-{
-	u8 bit = 0;
-
-	/* should not clear the mask passed */
-	for (; bit < sizeof(u32) * BITS_PER_BYTE; bit++) {
-		if (bm & (1 << bit))
-			cpumask_set_cpu(bit, m);
-		else
-			cpumask_clear_cpu(bit, m);
-	}
-}
-
-void u64_to_cpumask(struct cpumask *m, u64 bm)
-{
-	u8 bit = 0;
-
-	/* should not clear the mask passed */
-	for (; bit < sizeof(u64) * BITS_PER_BYTE; bit++) {
-		if (bm & (1ULL << bit))
-			cpumask_set_cpu(bit, m);
-		else
-			cpumask_clear_cpu(bit, m);
-	}
-}
-/*
- * Initializes PIC ITE entries PRM 9.5.6.26
- * XLP restricts CPU affinity to 8 groups. Though configurable, they are
- * programmed to have the following patterns.
- * 0 =>	Only 0th cpu on the node
- * 1 => All local threads in node; mask = (0xffffffff) on node
- * 2 => cpu0-15 on node; mask = 0x0000ffff & online_cpu_mask on nodes
- * 3 => cpu15-31 on node; mask = 0xffff0000 & online_cpu_mask on node
- * 4 => All cpus on all nodes; i.e.,
- * mask = (0xffffffff_ffffffff_ffffffff_ffffffff & physical online cpu map)
- * These are programmer defined groups and can be changed as warranted.
- * Added 5 => CPUs 0-11
- * Added 6 => CPUs 0-7
- * Added 7 => CPUs 0-3
- * Actual programmed value will take into consideration cpu_online_mask.
- *
- * There is a major issue that needs addressing when run in multi node mode
- * Number of nodes must be determined and programmed correctly, if a bit in ITE
- * is programmed without physical thread being present, when interrupt is
- * dispatched to that CPU under global scheme, system would hang. Thus this
- * scenario should be avoided. That is why nlm_cpumask is used
- *
- * This function simply initializes the xlp_ites entries with proposed
- * CPUmasks.  */
-static void xlp_ites_init(void)
-{
-	u64 bm = 0x1;
-	u8 node;
-	struct cpumask m;
-
-	cpumask_clear(&m);
-	for_each_online_node(node) {
-	/* Simply set the static pattern in all */
-		bm = 1;
-		u32_to_cpumask(&xlp_ites[node][0], bm);
-		/* directs to specified cpus of node*/
-		cpumask_shift_left(&xlp_ites[node][0],
-			&xlp_ites[node][0],
-			NLM_MAX_CPU_PER_NODE * node);
-
-		bm = 0xffffffff;
-		u32_to_cpumask(&xlp_ites[node][1], bm);
-		/* directs to specified cpus of node*/
-		cpumask_shift_left(&xlp_ites[node][1],
-				&xlp_ites[node][1],
-				NLM_MAX_CPU_PER_NODE * node);
-		if (!cpu_is_xlp9xx())
-			cpumask_or(&m, &m, &xlp_ites[node][1]);
-
-		bm = 0x0000ffff;
-		u32_to_cpumask(&xlp_ites[node][2], bm);
-		/* directs to specified cpus of node*/
-		cpumask_shift_left(&xlp_ites[node][2],
-				&xlp_ites[node][2],
-				NLM_MAX_CPU_PER_NODE * node);
-
-		bm = 0xffff0000;
-		u32_to_cpumask(&xlp_ites[node][3], bm);
-		/* directs to specified cpus of node*/
-		cpumask_shift_left(&xlp_ites[node][3],
-				&xlp_ites[node][3],
-				NLM_MAX_CPU_PER_NODE * node);
-
-		bm = 0x000000ff;
-		u32_to_cpumask(&xlp_ites[node][5], bm);
-		/* directs to specified cpus of node*/
-		cpumask_shift_left(&xlp_ites[node][5],
-				&xlp_ites[node][5],
-				NLM_MAX_CPU_PER_NODE * node);
-
-		bm = 0x000000f0;
-		u32_to_cpumask(&xlp_ites[node][6], bm);
-		/* directs to specified cpus of node*/
-		cpumask_shift_left(&xlp_ites[node][6],
-			&xlp_ites[node][6],
-			NLM_MAX_CPU_PER_NODE * node);
-
-		bm = 0x0000000f;
-		/* directs to specified cpus of node*/
-		u32_to_cpumask(&xlp_ites[node][7], bm);
-		cpumask_shift_left(&xlp_ites[node][7],
-			&xlp_ites[node][7],
-			NLM_MAX_CPU_PER_NODE * node);
-
-		if (cpu_is_xlp9xx()) {
-			bm = 0xffffffffffffffffULL;
-			u64_to_cpumask(&xlp_ites[node][8], bm);
-			/* directs to specified cpus of node*/
-			cpumask_shift_left(&xlp_ites[node][8],
-			&xlp_ites[node][8],
-			NLM_MAX_CPU_PER_NODE * node);
-			cpumask_or(&m, &m, &xlp_ites[node][8]);
-			bm = 0xffffffff00000000ULL;
-			u64_to_cpumask(&xlp_ites[node][9], bm);
-			/* directs to specified cpus of node*/
-			cpumask_shift_left(&xlp_ites[node][9],
-				&xlp_ites[node][9],
-				NLM_MAX_CPU_PER_NODE * node);
-
-			bm = 0xffff00000000ULL;
-			u64_to_cpumask(&xlp_ites[node][10], bm);
-			/* directs to specified cpus of node */
-			cpumask_shift_left(&xlp_ites[node][10],
-				&xlp_ites[node][10],
-				 NLM_MAX_CPU_PER_NODE * node);
-
-			bm = 0xffff000000000000ULL;
-			u64_to_cpumask(&xlp_ites[node][11], bm);
-			/* directs to specified cpus of node*/
-			cpumask_shift_left(&xlp_ites[node][11],
-				&xlp_ites[node][11],
-				NLM_MAX_CPU_PER_NODE * node);
-
-			bm = 0xff00000000ULL;
-			u64_to_cpumask(&xlp_ites[node][12], bm);
-			/* directs to specified cpus of node*/
-			cpumask_shift_left(&xlp_ites[node][12],
-				&xlp_ites[node][12],
-				NLM_MAX_CPU_PER_NODE * node);
-
-			bm = 0xf000000000ULL;
-			u64_to_cpumask(&xlp_ites[node][13], bm);
-			/* directs to specified cpus of node*/
-			cpumask_shift_left(&xlp_ites[node][13],
-				&xlp_ites[node][13],
-				NLM_MAX_CPU_PER_NODE * node);
-
-			bm = 0xf00000000ULL;
-			u64_to_cpumask(&xlp_ites[node][14], bm);
-			/* directs to specified cpus of node*/
-			cpumask_shift_left(&xlp_ites[node][14],
-				&xlp_ites[node][14],
-				NLM_MAX_CPU_PER_NODE * node);
-
-			bm = 0x100000000ULL;
-			u64_to_cpumask(&xlp_ites[node][15], bm);
-			/* directs to specified cpus of node*/
-			cpumask_shift_left(&xlp_ites[node][15],
-				&xlp_ites[node][15],
-				NLM_MAX_CPU_PER_NODE * node);
-		}
-	}
-	for_each_online_node(node) {
-		cpumask_copy(&xlp_ites[node][4], &m);
-	}
-}
-
-/* Initializes the PIC
- * Mainly sets up the IRT entries default values
- * called from on_chip.c:pic_init()
- * */
-void xlp_pic_init(uint64_t base)
-{
-	xlp_ites_init();
-	xlp_prog_all_node_ites(base);
-}
-
-- 
2.1.0

