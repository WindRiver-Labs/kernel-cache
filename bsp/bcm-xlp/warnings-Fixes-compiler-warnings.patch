From 3dcb6790f94859d8fb2fdd1f7922f69eca398cbf Mon Sep 17 00:00:00 2001
From: Ashok Kumar <ashoks@broadcom.com>
Date: Mon, 10 Dec 2012 16:37:45 +0530
Subject: [PATCH 642/761] warnings: Fixes compiler warnings.

	  Fixes the below two types of compiler warnings
	  warning: cast to pointer from integer of different size [-Wint-to-pointer-cast]
	  warning: cast from pointer to integer of different size [-Wpointer-to-int-cast]

Based on Broadcom SDK 2.3.

Signed-off-by: Ashok Kumar <ashoks@broadcom.com>
Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
---
 arch/mips/include/asm/netlogic/xlp8xx/cpu.h |    2 +-
 arch/mips/netlogic/common/pic_hal.c         |    8 +++---
 arch/mips/netlogic/xlp/cpu_control.c        |    2 +-
 arch/mips/netlogic/xlp/mmu.c                |    2 +-
 arch/mips/netlogic/xlp/pic/xlp_irq_map.c    |    9 ++++---
 arch/mips/netlogic/xlp/pic/xlp_pic.c        |    6 ++---
 arch/mips/netlogic/xlp/platform.c           |    2 +-
 arch/mips/netlogic/xlp/setup.c              |    8 +++---
 arch/mips/netlogic/xlp/xlp_nor.c            |    2 +-
 arch/mips/pci/pci-xlp.c                     |    2 +-
 drivers/dma/nlm_adma.c                      |   36 +++++++++++++--------------
 11 files changed, 40 insertions(+), 39 deletions(-)

diff --git a/arch/mips/include/asm/netlogic/xlp8xx/cpu.h b/arch/mips/include/asm/netlogic/xlp8xx/cpu.h
index f71c9b7..c4a9ca1 100644
--- a/arch/mips/include/asm/netlogic/xlp8xx/cpu.h
+++ b/arch/mips/include/asm/netlogic/xlp8xx/cpu.h
@@ -146,7 +146,7 @@
 				HDR_OFFSET + (y<<18) + (BRIDGE) + 0x300)
 
 #ifndef __ASSEMBLY__
-#define cpu_io_mmio(node,offset)	((__u32 *)((u64)DEFAULT_CPU_IO_BASE + \
+#define cpu_io_mmio(node,offset)	((__u32 *)(uintptr_t)((u64)DEFAULT_CPU_IO_BASE + \
 					(node<<18) + (offset) + HDR_OFFSET))
 
 #define dmc_io_mmio(node,offset)\
diff --git a/arch/mips/netlogic/common/pic_hal.c b/arch/mips/netlogic/common/pic_hal.c
index e161149..ca2f8aa 100644
--- a/arch/mips/netlogic/common/pic_hal.c
+++ b/arch/mips/netlogic/common/pic_hal.c
@@ -63,25 +63,25 @@ int retrieve_node_pic_dev(u32 node, struct pic_dev **in)
 
 u64 __pic_r64o(void *base, u64 offset)
 {
-	return ld_40bit_phys(((u64)base + offset), CCA_UNCACHED);
+	return ld_40bit_phys(((uintptr_t)base + offset), CCA_UNCACHED);
 }
 EXPORT_SYMBOL(__pic_r64o);
 
 void __pic_w64o(void *base, u64 offset, u64 val)
 {
-	sd_40bit_phys(((u64)base + offset), CCA_UNCACHED, val);
+	sd_40bit_phys(((uintptr_t)base + offset), CCA_UNCACHED, val);
 }
 EXPORT_SYMBOL(__pic_w64o);
 
 u32 __pic_r32o(void *base, u64 offset)
 {
-	return lw_40bit_phys(((u64)base + offset), CCA_UNCACHED);
+	return lw_40bit_phys(((uintptr_t)base + offset), CCA_UNCACHED);
 }
 EXPORT_SYMBOL(__pic_r32o);
 
 void __pic_w32o(void *base, u64 offset, u32 val)
 {
-	sw_40bit_phys(((u64)base + offset), CCA_UNCACHED, val);
+	sw_40bit_phys(((uintptr_t)base + offset), CCA_UNCACHED, val);
 }
 EXPORT_SYMBOL(__pic_w32o);
 
diff --git a/arch/mips/netlogic/xlp/cpu_control.c b/arch/mips/netlogic/xlp/cpu_control.c
index 667a58f..8f9a645 100644
--- a/arch/mips/netlogic/xlp/cpu_control.c
+++ b/arch/mips/netlogic/xlp/cpu_control.c
@@ -231,7 +231,7 @@ u32 get_core_dfs(int cpu_num)
 	volatile u32 *mmio;
 
 	mmio = (volatile u32 *) cpu_io_mmio(cpu_num/32,SYS);
-	core_dfs = nlm_hal_read_32bit_reg((uint64_t)mmio, SYS_COREDFSDIVCTRL);
+	core_dfs = nlm_hal_read_32bit_reg((uint64_t)(uintptr_t)mmio, SYS_COREDFSDIVCTRL);
 	dfs  = SYS_CORE_DFS(core_dfs, (cpu_num >> 2));
 	return dfs;
 }
diff --git a/arch/mips/netlogic/xlp/mmu.c b/arch/mips/netlogic/xlp/mmu.c
index 8e4c493..33e57b8 100644
--- a/arch/mips/netlogic/xlp/mmu.c
+++ b/arch/mips/netlogic/xlp/mmu.c
@@ -166,7 +166,7 @@ static void pgwalker_init_mips_compliant(void)
 		get_cpu_var(pgd_bases)[i] = (unsigned long)swapper_pg_dir;
 		put_cpu_var(pgd_bases);
 	}
-	pwbase_val = (uint64_t)&(__get_cpu_var(pgd_bases)[0]);
+	pwbase_val = (uintptr_t)&(__get_cpu_var(pgd_bases)[0]);
 
 	/* enable page walker */
 	pwctl_val |= ((uint32_t)1) << PWCTL_PW_EN_O;
diff --git a/arch/mips/netlogic/xlp/pic/xlp_irq_map.c b/arch/mips/netlogic/xlp/pic/xlp_irq_map.c
index 9b581ba..1d2a964 100644
--- a/arch/mips/netlogic/xlp/pic/xlp_irq_map.c
+++ b/arch/mips/netlogic/xlp/pic/xlp_irq_map.c
@@ -654,14 +654,14 @@ void __xlp_irq_mask(struct pic_dev *pic, unsigned int irq)
 	}
 	if (read_64bit_cp0_eimr() & (1ULL << rvec)) {
 		/* We do not clear eimr, this is a TODO for later time */
-		//on_each_cpu(xlp_clear_eimr, (void *) (1ULL << rvec), 1);
+		//on_each_cpu(xlp_clear_eimr, (void *) (rvec), 1);
 	}
 	return;
 }
 
 static void xlp_set_eimr(void *param)
 {
-	u64 bitmask = (u64) param;
+	u64 bitmask = (u64)(1ULL << (uintptr_t)param);
 	u64 eimr;
 
 	eimr = read_64bit_cp0_eimr();
@@ -674,10 +674,11 @@ static void xlp_set_eimr(void *param)
  * Clear some eimr bits on each cpu
  * This function will be called on each cpu by on_each_cpu()
  * @bitmask	: bitmask to clear in EIMR
+ * @param : rvec value
  */
 static void __maybe_unused xlp_clear_eimr(void *param)
 {
-	u64 bitmask = (u64) param;
+	u64 bitmask = (u64)(1ULL << (uintptr_t) param);
 	u64 eimr = read_64bit_cp0_eimr();
 	eimr &= ~bitmask;
 	write_64bit_cp0_eimr(eimr);
@@ -701,7 +702,7 @@ void __xlp_irq_unmask(struct pic_dev *pic, int irq)
 	} else if (((1ULL << rvec) & read_64bit_cp0_eimr()) == 0) {
 		/* This is only for those interrupts which are not statically
 		 * set in EIMR. Could dump stack if spin lock held */
-		 on_each_cpu(xlp_set_eimr, (void *) (1ULL << rvec), 1);
+		 on_each_cpu(xlp_set_eimr, (void *)(uintptr_t) (rvec), 1);
 	}
 	return;
 }
diff --git a/arch/mips/netlogic/xlp/pic/xlp_pic.c b/arch/mips/netlogic/xlp/pic/xlp_pic.c
index 262069a..d926d05 100644
--- a/arch/mips/netlogic/xlp/pic/xlp_pic.c
+++ b/arch/mips/netlogic/xlp/pic/xlp_pic.c
@@ -469,13 +469,13 @@ static u64 xlp_pic_base[NLM_MAX_CPU_NODE] = {XLP_BDF_BASE(0,0,4),
 
 u64 __nlh_pic_r64o(u8 nid, u64 offset)
 {
-	return (__pic_r64o((void *)xlp_pic_base[nid], offset));
+	return (__pic_r64o((void *)(uintptr_t)xlp_pic_base[nid], offset));
 }
 EXPORT_SYMBOL(__nlh_pic_r64o);
 
 void __nlh_pic_w64o(u8 nid, u64 offset, u64 val)
 {
-	__pic_w64o((void *)xlp_pic_base[nid], offset, val);
+	__pic_w64o((void *)(uintptr_t)xlp_pic_base[nid], offset, val);
 }
 EXPORT_SYMBOL(__nlh_pic_w64o);
 
@@ -507,7 +507,7 @@ void xlp_pic_init(u8 node)
 	struct pic_dev *pic = &xlp_pic_dev[node];
 
 	pic->node = node;
-	pic->base = (void *)xlp_pic_base[node];
+	pic->base = (void *)(uintptr_t)xlp_pic_base[node];
 	xlp_init_irqmap(pic);
 	register_pic_dev(node, pic);
 	if (node == 0) {
diff --git a/arch/mips/netlogic/xlp/platform.c b/arch/mips/netlogic/xlp/platform.c
index a483588..0679833 100644
--- a/arch/mips/netlogic/xlp/platform.c
+++ b/arch/mips/netlogic/xlp/platform.c
@@ -130,7 +130,7 @@ static void xlp_init_uart(int port_id)
 {
         xlp_uart_port[port_id].mapbase       = DEFAULT_NETLOGIC_IO_BASE
 						+ NETLOGIC_IO_UART_0_OFFSET + port_id * XLP_UART_PORTIO_OFFSET;
-        xlp_uart_port[port_id].membase       = (void __iomem *)xlp_uart_port[port_id].mapbase;
+        xlp_uart_port[port_id].membase       = (void __iomem *)(uintptr_t)xlp_uart_port[port_id].mapbase;
         xlp_uart_port[port_id].irq           = xlp_irt_to_irq(0, 133 + port_id);
 
         xlp_uart_port[port_id].uartclk       = XLP_PIT_TICK_RATE;
diff --git a/arch/mips/netlogic/xlp/setup.c b/arch/mips/netlogic/xlp/setup.c
index 1baaebe..3360154 100644
--- a/arch/mips/netlogic/xlp/setup.c
+++ b/arch/mips/netlogic/xlp/setup.c
@@ -167,7 +167,7 @@ struct nlm_ici_config
 {
 	int enable_config;
 	int total_credits;
-	int node_link_mask[MAX_NUMNODES];
+	int node_link_mask[MAX_NODES];
 	struct nlm_ici_vc_param gcu_vc[ICI_MAX_GCU_VC];
 	struct nlm_ici_vc_param fmn_vc[ICI_MAX_FMN_VC];
 	struct nlm_ici_vc_param pic_vc[ICI_MAX_PIC_VC];
@@ -232,9 +232,9 @@ void read_node_bars(int node)
         uint32_t *membase = cpu_io_mmio(node, BRIDGE);
 
         for (i = 0; i < NLM_MAX_DRAM_REGION; i++) {
-                uint64_t base_reg  = nlm_hal_read_32bit_reg((uint64_t)membase, NLM_DRAM_BASE_REG_0 + i);
-                uint64_t limit_reg = nlm_hal_read_32bit_reg((uint64_t)membase, NLM_DRAM_LIMIT_REG_0 + i);
-                uint32_t node_reg =  nlm_hal_read_32bit_reg((uint64_t)membase, NLM_DRAM_NODEADDR_XLAT + i);
+                uint64_t base_reg  = nlm_hal_read_32bit_reg((uintptr_t)membase, NLM_DRAM_BASE_REG_0 + i);
+                uint64_t limit_reg = nlm_hal_read_32bit_reg((uintptr_t)membase, NLM_DRAM_LIMIT_REG_0 + i);
+                uint32_t node_reg =  nlm_hal_read_32bit_reg((uintptr_t)membase, NLM_DRAM_NODEADDR_XLAT + i);
 
                 if(((node_reg >> 1) & 0x3) != node) {
                         continue;
diff --git a/arch/mips/netlogic/xlp/xlp_nor.c b/arch/mips/netlogic/xlp/xlp_nor.c
index df3d3eb..2a4fe1c 100644
--- a/arch/mips/netlogic/xlp/xlp_nor.c
+++ b/arch/mips/netlogic/xlp/xlp_nor.c
@@ -89,7 +89,7 @@ int xlp_nor_flash_dev_init(void){
 	uint32_t base, limit;
 	u32 nor_cs;
 	volatile u32 *mmio = cpu_io_mmio(0, SYS);
-	nor_cs = (nlm_hal_read_32bit_reg((uint64_t)mmio,1) & 0xF) == 6 ? 1 : 0;
+	nor_cs = (nlm_hal_read_32bit_reg((uintptr_t)mmio,1) & 0xF) == 6 ? 1 : 0;
 
 	if(nor_cs)	{
 		base = nor_reg_read(0,XLP_NOR_CS1_BASEADDRESS_REG);
diff --git a/arch/mips/pci/pci-xlp.c b/arch/mips/pci/pci-xlp.c
index 810ed82..91cb955 100644
--- a/arch/mips/pci/pci-xlp.c
+++ b/arch/mips/pci/pci-xlp.c
@@ -561,7 +561,7 @@ struct pci_fixup pcibios_fixups[] = {
 /*
  * some ide specific io routines on PCI
  */
-#define pci_ide_phys_to_virt(x) (((x) - (xlp_io_resource.start)) + (unsigned long)pci_io_base )
+#define pci_ide_phys_to_virt(x) ((unsigned long)(((x) - (xlp_io_resource.start)) + (unsigned long)pci_io_base ))
 
 inline void nlm_ide_mm_insw(unsigned long port, void *addr, u32 count)
 {
diff --git a/drivers/dma/nlm_adma.c b/drivers/dma/nlm_adma.c
index 0c4cc50..0fd85f8 100644
--- a/drivers/dma/nlm_adma.c
+++ b/drivers/dma/nlm_adma.c
@@ -122,12 +122,12 @@ uint64_t gen_dtr_raid_msg_format_2 (const void * ret_entry)
 
 
 static __inline__
-uint64_t gen_dtr_xfer_msg_format_0 (const unsigned long len, const uint64_t src)
+uint64_t gen_dtr_xfer_msg_format_0 (const unsigned long len, const volatile uint64_t src)
 {
 	return (1ULL << 63)
 		| shift_lower_bits(0, 60, 3)  /* msgtype 0 for transfer */
 		| shift_lower_bits(len, 40, 20)
-		| shift_lower_bits ((volatile void *)src, 0, 40);
+		| shift_lower_bits (src, 0, 40);
 }
 
 static __inline__
@@ -140,11 +140,11 @@ uint64_t gen_dtr_xfer_msg_format_1 (const uint32_t dest_id)
 }
 
 static __inline__
-uint64_t gen_dtr_xfer_msg_format_2 (const uint64_t dst)
+uint64_t gen_dtr_xfer_msg_format_2 (const volatile uint64_t dst)
 {
 	return (0ULL << 63)
 		| shift_lower_bits (1, 40, 1) /* perform transfer */
-		| shift_lower_bits ((volatile void *)dst, 0, 40);
+		| shift_lower_bits (dst, 0, 40);
 }
 
 static __inline__
@@ -155,12 +155,12 @@ uint64_t gen_dtr_xfer_msg_format_3 (const void * ret_entry)
 }
 
 static __inline__
-uint64_t gen_dtr_xfer_p2pmsg_format_0 (const uint32_t len, const uint64_t src)
+uint64_t gen_dtr_xfer_p2pmsg_format_0 (const uint32_t len, const volatile uint64_t src)
 {
 	return (1ULL << 63)
 		| shift_lower_bits (7, 60, 3) /* msgtype 7 for p2p */
 		| shift_lower_bits (len, 40, 20)
-		| shift_lower_bits ((volatile void *)src, 0, 40);
+		| shift_lower_bits (src, 0, 40);
 }
 
 static __inline__
@@ -193,7 +193,7 @@ static void nlm_dtre_msgring_handler(uint32_t vc, uint32_t src_id,
 	uint64_t addr = (unsigned long) (msg1<<1);
 
 
-	desc = (struct nlm_tx_desc *)addr;
+	desc = (struct nlm_tx_desc *)(uintptr_t)addr;
 
 	if (desc == NULL)
 	{
@@ -738,7 +738,7 @@ nlm_adma_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dma_dest,
 	struct nlm_adma_chan *nlm_chan = to_nlm_adma_chan(chan);
 
 	if (nlm_dtre_debug) {
-		printk("prep_dma_memcpy len 0x%lx.\n", len);
+		printk("prep_dma_memcpy len %#zx.\n", len);
 	}
 
 	desc = alloc_tx_desc(nlm_chan);
@@ -781,7 +781,7 @@ nlm_adma_prep_dma_memset(struct dma_chan *chan, dma_addr_t dma_dest,
 	struct nlm_adma_chan *nlm_chan = to_nlm_adma_chan(chan);
 
 	if (nlm_dtre_debug) {
-		printk("prep_dma_memset len 0x%lx.\n", len);
+		printk("prep_dma_memset len %#zx.\n", len);
 	}
 
 	desc = alloc_tx_desc(nlm_chan);
@@ -825,7 +825,7 @@ nlm_adma_prep_dma_xor(struct dma_chan *chan, dma_addr_t dma_dest,
 	uint64_t * ent;
 
 	if (nlm_dtre_debug) {
-		printk("dma_xor src_cnt %d len 0x%lx.\n", src_cnt, len);
+		printk("dma_xor src_cnt %d len %#zx.\n", src_cnt, len);
 	}
 
 	disks = src_cnt + 1;
@@ -908,10 +908,10 @@ nlm_adma_prep_dma_xor(struct dma_chan *chan, dma_addr_t dma_dest,
 
 		/* segment address */
 		if (i < src_cnt)
-			ent[disks + i] |= shift_lower_bits(virt_to_phys ((volatile void *) dma_src[i]), 0, 40);
+			ent[disks + i] |= shift_lower_bits(virt_to_phys ((volatile void *) (uintptr_t)dma_src[i]), 0, 40);
 
 		if ((i+1) == p_device_id)
-			ent[disks + i] |= shift_lower_bits(virt_to_phys ((volatile void *) dma_dest), 0, 40);
+			ent[disks + i] |= shift_lower_bits(virt_to_phys ((volatile void *) (uintptr_t)dma_dest), 0, 40);
 
 		desc->entries_count++;
 	}
@@ -937,7 +937,7 @@ nlm_adma_prep_dma_xor_val(struct dma_chan *chan, dma_addr_t *dma_src,
 	uint64_t * ent;
 
 	if (nlm_dtre_debug) {
-		printk("* fn dma_xor_val src_cnt %d len 0x%lx.\n", src_cnt, len);
+		printk("* fn dma_xor_val src_cnt %d len %#zx.\n", src_cnt, len);
 	}
 
 	/* assume last dev is p_device_id */
@@ -1021,7 +1021,7 @@ nlm_adma_prep_dma_xor_val(struct dma_chan *chan, dma_addr_t *dma_src,
 
 		/* segment address */
 		if (i < src_cnt)
-			ent[disks + i] |= shift_lower_bits(virt_to_phys ((volatile void *) dma_src[i]), 0, 40);
+			ent[disks + i] |= shift_lower_bits(virt_to_phys ((volatile void *) (uintptr_t)dma_src[i]), 0, 40);
 
 		desc->entries_count++;
 	}
@@ -1063,7 +1063,7 @@ nlm_adma_prep_dma_pq(struct dma_chan *chan, dma_addr_t *dst, dma_addr_t *src,
 		local_src_cnt = src_cnt;
 
 	if (nlm_dtre_debug) {
-		printk(" fn dma_pq src_cnt %d new_src_cnt %d len 0x%lx flags 0x%lx.\n", 
+		printk(" fn dma_pq src_cnt %d new_src_cnt %d len %#zx flags 0x%lx.\n", 
 				src_cnt, local_src_cnt, len, flags);
 	}
 
@@ -1114,7 +1114,7 @@ nlm_adma_prep_dma_pq(struct dma_chan *chan, dma_addr_t *dst, dma_addr_t *src,
 			printk("DTRE error: page allocation failed.\n");
 			return NULL;
 		}
-		pgaddr = (void *)page_to_phys(desc->pg);
+		pgaddr = (void *)(uintptr_t)page_to_phys(desc->pg);
 	}
 
 	/* specify valid address for disabled result */
@@ -1250,7 +1250,7 @@ nlm_adma_prep_dma_pq_val(struct dma_chan *chan, dma_addr_t *pq, dma_addr_t *src,
 	void * pgaddr = NULL;
 
 	if (nlm_dtre_debug) {
-		printk("* fn dma_pq_val src_cnt %d len 0x%lx flags 0x%lx.\n", 
+		printk("* fn dma_pq_val src_cnt %d len %#zx flags 0x%lx.\n", 
 				src_cnt, len, flags);
 	}
 
@@ -1301,7 +1301,7 @@ nlm_adma_prep_dma_pq_val(struct dma_chan *chan, dma_addr_t *pq, dma_addr_t *src,
 			printk("DTRE error: page allocation failed.\n");
 			return NULL;
 		}
-		pgaddr = (void *) page_to_phys(desc->pg);
+		pgaddr = (void *) (uintptr_t)page_to_phys(desc->pg);
 	}
 
 	for (i=0; i<DTRE_RAID_MAX_ENTRIES; i++)
-- 
1.7.10.4

