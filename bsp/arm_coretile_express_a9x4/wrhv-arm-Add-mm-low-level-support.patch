From 59dc4facd472cac00ab43378642ed11d3702fb4c Mon Sep 17 00:00:00 2001
From: Jim Somerville <Jim.Somerville@windriver.com>
Date: Wed, 3 Aug 2011 13:32:37 -0400
Subject: [PATCH 06/10] wrhv: arm:  Add mm low-level support

Notable changes:
Early in abort routines we must use hv supplied
fault registers in status space rather than going
directly to the hardware registers.
Asid is always 0 for now.

Signed-off-by: Jim Somerville <Jim.Somerville@windriver.com>
---
 arch/arm/mm/Kconfig     |    2 +-
 arch/arm/mm/abort-ev7.S |   11 +++++++++++
 arch/arm/mm/context.c   |   14 ++++++++++++++
 arch/arm/mm/pabort-v7.S |   12 +++++++++++-
 arch/arm/mm/proc-v7.S   |    7 +++++++
 5 files changed, 44 insertions(+), 2 deletions(-)

diff --git a/arch/arm/mm/Kconfig b/arch/arm/mm/Kconfig
index 9d635f8..731b19b 100644
--- a/arch/arm/mm/Kconfig
+++ b/arch/arm/mm/Kconfig
@@ -718,7 +718,7 @@ config TLS_REG_EMUL
 config HAS_TLS_REG
 	bool
 	depends on !TLS_REG_EMUL
-	default y if SMP || CPU_32v7
+	default y if (SMP || CPU_32v7) && !WRHV
 	help
 	  This selects support for the CP15 thread register.
 	  It is defined to be available on some ARMv6 processors (including
diff --git a/arch/arm/mm/abort-ev7.S b/arch/arm/mm/abort-ev7.S
index 2e6dc04..142a54d 100644
--- a/arch/arm/mm/abort-ev7.S
+++ b/arch/arm/mm/abort-ev7.S
@@ -1,5 +1,9 @@
 #include <linux/linkage.h>
 #include <asm/assembler.h>
+#ifdef CONFIG_WRHV
+#include <asm/asm-offsets.h>
+#endif
+
 /*
  * Function: v7_early_abort
  *
@@ -22,8 +26,15 @@ ENTRY(v7_early_abort)
 	 */
 	clrex
 
+#ifdef CONFIG_WRHV
+	ldr	r1, =wr_status			@ ptr to hv status region
+	ldr	r1, [r1]
+	ldr	r0, [r1, #STAT_SPACE_DFAR]	@ get dfar
+	ldr	r1, [r1, #STAT_SPACE_DFSR]	@ get dfsr
+#else
 	mrc	p15, 0, r1, c5, c0, 0		@ get FSR
 	mrc	p15, 0, r0, c6, c0, 0		@ get FAR
+#endif
 
 	/*
 	 * V6 code adjusts the returned DFSR.
diff --git a/arch/arm/mm/context.c b/arch/arm/mm/context.c
index b0ee9ba..fc750c9 100644
--- a/arch/arm/mm/context.c
+++ b/arch/arm/mm/context.c
@@ -34,6 +34,7 @@ void __init_new_context(struct task_struct *tsk, struct mm_struct *mm)
 	spin_lock_init(&mm->context.id_lock);
 }
 
+#ifndef CONFIG_WRHV
 static void flush_context(void)
 {
 	/* set the reserved ASID before flushing the TLB */
@@ -45,6 +46,7 @@ static void flush_context(void)
 		dsb();
 	}
 }
+#endif
 
 #ifdef CONFIG_SMP
 
@@ -52,6 +54,9 @@ static void set_mm_context(struct mm_struct *mm, unsigned int asid)
 {
 	unsigned long flags;
 
+#ifdef CONFIG_WRHV
+	asid = 0;
+#endif
 	/*
 	 * Locking needed for multi-threaded applications where the
 	 * same mm->context.id could be set from different CPUs during
@@ -75,6 +80,7 @@ static void set_mm_context(struct mm_struct *mm, unsigned int asid)
 	cpumask_set_cpu(smp_processor_id(), mm_cpumask(mm));
 }
 
+#ifndef CONFIG_WRHV
 /*
  * Reset the ASID on the current CPU. This function call is broadcast
  * from the CPU handling the ASID rollover and holding cpu_asid_lock.
@@ -102,11 +108,15 @@ static void reset_context(void *info)
 	asm("mcr	p15, 0, %0, c13, c0, 1\n" : : "r" (mm->context.id));
 	isb();
 }
+#endif
 
 #else
 
 static inline void set_mm_context(struct mm_struct *mm, unsigned int asid)
 {
+#ifdef CONFIG_WRHV
+	asid = 0;
+#endif
 	mm->context.id = asid;
 	cpumask_copy(mm_cpumask(mm), cpumask_of(smp_processor_id()));
 }
@@ -118,6 +128,7 @@ void __new_context(struct mm_struct *mm)
 	unsigned int asid;
 
 	spin_lock(&cpu_asid_lock);
+#ifndef CONFIG_WRHV
 #ifdef CONFIG_SMP
 	/*
 	 * Check the ASID again, in case the change was broadcast from
@@ -152,6 +163,9 @@ void __new_context(struct mm_struct *mm)
 		cpu_last_asid += NR_CPUS;
 	}
 
+#else
+	asid = 0;
+#endif
 	set_mm_context(mm, asid);
 	spin_unlock(&cpu_asid_lock);
 }
diff --git a/arch/arm/mm/pabort-v7.S b/arch/arm/mm/pabort-v7.S
index a8b3b30..3e79a30 100644
--- a/arch/arm/mm/pabort-v7.S
+++ b/arch/arm/mm/pabort-v7.S
@@ -1,8 +1,11 @@
 #include <linux/linkage.h>
 #include <asm/assembler.h>
+#ifdef CONFIG_WRHV
+#include <asm/asm-offsets.h>
+#endif
 
 /*
- * Function: v6_pabort
+ * Function: v7_pabort
  *
  * Params  : r0 = address of aborted instruction
  *
@@ -14,7 +17,14 @@
 
 	.align	5
 ENTRY(v7_pabort)
+#ifdef CONFIG_WRHV
+	ldr	r1, =wr_status			@ ptr to hv status region
+	ldr	r1, [r1]
+	ldr	r0, [r1, #STAT_SPACE_IFAR]	@ get ifar
+	ldr	r1, [r1, #STAT_SPACE_IFSR]	@ get ifsr
+#else
 	mrc	p15, 0, r0, c6, c0, 2		@ get IFAR
 	mrc	p15, 0, r1, c5, c0, 1		@ get IFSR
+#endif
 	mov	pc, lr
 ENDPROC(v7_pabort)
diff --git a/arch/arm/mm/proc-v7.S b/arch/arm/mm/proc-v7.S
index 7aaf88a..a5aff9d 100644
--- a/arch/arm/mm/proc-v7.S
+++ b/arch/arm/mm/proc-v7.S
@@ -190,6 +190,13 @@ cpu_v7_name:
  *	- cache type register is implemented
  */
 __v7_setup:
+#ifdef CONFIG_WRHV
+	@ The hypervisor controls most of processor initialization, so not
+	@ much to do here.
+	@ This routine needs the control register content returned.
+	mrc	p15, 0, r0, c1, c0, 0		@ read control register
+	mov	pc, lr				@ return to head.S:__ret
+#endif
 #ifdef CONFIG_SMP
 	mrc	p15, 0, r0, c1, c0, 1
 	tst	r0, #(1 << 6)			@ SMP/nAMP mode enabled?
-- 
1.7.0.4

