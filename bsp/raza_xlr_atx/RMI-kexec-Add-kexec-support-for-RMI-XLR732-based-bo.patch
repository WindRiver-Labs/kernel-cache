From 7ddbc10130d5f70e2e98cac2a4e6e78a71d6b8e6 Mon Sep 17 00:00:00 2001
From: Benjamin Walsh <benjamin.walsh@windriver.com>
Date: Mon, 13 Jul 2009 10:10:19 -0400
Subject: [PATCH] RMI/kexec: Add kexec support for RMI XLR732-based boards

Main feature needed is the specific SMP support. Secondary
cores/threads spin on tight loops in the bootloader memory:
kexec support has to mimic this when doing the handoff from
the first kernel to the second. Unfortunately, this has the
side-effect of preventing from booting a second kernel with
more CPUs than the first one. The opposite works though, as
a crash dump kernel should really be booted with only one CPU
to use an amount of memory as small as possible.

Signed-off-by: Benjamin Walsh <benjamin.walsh@windriver.com>
---
 arch/mips/kernel/relocate_kernel.S    |  197 ++++++++++++++++++++---
 arch/mips/rmi/phoenix/Makefile        |    2 +
 arch/mips/rmi/phoenix/phoenix_kexec.c |  282 +++++++++++++++++++++++++++++++++
 arch/mips/rmi/ptr/setup.c             |    8 +
 4 files changed, 462 insertions(+), 27 deletions(-)
 create mode 100644 arch/mips/rmi/phoenix/phoenix_kexec.c

diff --git a/arch/mips/kernel/relocate_kernel.S b/arch/mips/kernel/relocate_kernel.S
index 4324671..f9202a5 100644
--- a/arch/mips/kernel/relocate_kernel.S
+++ b/arch/mips/kernel/relocate_kernel.S
@@ -14,12 +14,25 @@
 #include <asm/stackframe.h>
 #include <asm/addrspace.h>
 
+/* These are taken from linux/kexec.h and should always be in sync */
+#ifndef IND_DESTINATION
+#define IND_DESTINATION  0x1
+#endif
+#ifndef IND_INDIRECTION
+#define IND_INDIRECTION  0x2
+#endif
+#ifndef IND_DONE
+#define IND_DONE         0x4
+#endif
+#ifndef IND_SOURCE
+#define IND_SOURCE       0x8
+#endif
 
 LEAF(relocate_new_kernel)
-     PTR_L a0,    arg0
-     PTR_L a1,    arg1
-     PTR_L a2,    arg2
-     PTR_L a3,    arg3
+	PTR_L 		a0, arg0
+	PTR_L 		a1, arg1
+	PTR_L 		a2, arg2
+	PTR_L 		a3, arg3
 
 	PTR_LA		s0, kexec_indirection_page
 	PTR_L		s1, kexec_start_address
@@ -28,44 +41,37 @@ process_entry:
 	PTR_L		s2, (s0)
 	PTR_ADD		s0, s0, SZREG
 
-	/* destination page */
-	and		s3, s2, 0x1
+	/* destination page, store it in s4 */
+	and		s3, s2, IND_DESTINATION
 	beq		s3, zero, 1f
 	nop
-	and		s4, s2, ~0x1	/* store destination addr in s4 */
-
-	nop
+	and		s4, s2, ~IND_DESTINATION
 	b		process_entry
 	nop
 
 1:
 	/* indirection page, update s0  */
-	and		s3, s2, 0x2
+	and		s3, s2, IND_INDIRECTION
 	beq		s3, zero, 1f
 	nop
-	and		s0, s2, ~0x2
-
-	nop
-
+	and		s0, s2, ~IND_INDIRECTION
 	b		process_entry
 	nop
 
 1:
-	/* done page */
-	and		s3, s2, 0x4
+	/* done page, stop */
+	and		s3, s2, IND_DONE
 	beq		s3, zero, 1f
 	nop
-
-	nop
 	b		done
 	nop
 
 1:
-	/* source page */
-	and		s3, s2, 0x8
+	/* source page?: copy; if not, skip it (we somehow got crap) */
+	and		s3, s2, IND_SOURCE
 	beq		s3, zero, process_entry
 	nop
-	and		s2, s2, ~0x8
+	and		s2, s2, ~IND_SOURCE
 	li		s6, (1 << PAGE_SHIFT) / SZREG
 
 copy_word:
@@ -81,7 +87,6 @@ copy_word:
 	nop
 
 1:
-	nop
 	b 		process_entry
 	nop
 
@@ -92,7 +97,7 @@ done:
         of kexec_flag.  */
 
 	.align	3
-	bal	1f
+	bal	1f	/* MUST be first instruction in done: */
 	nop
 1:
 	.align	3
@@ -100,8 +105,8 @@ done:
 	move		t1, ra;
 	PTR_LA		t2, done
 	PTR_LA		t0, kexec_flag
-	PTR_SUB		t0, t0, t2;
-	PTR_ADD		t0, t1, t0;
+	PTR_SUBU	t0, t0, t2;
+	PTR_ADDU	t0, t1, t0;
 	LONG_S		zero, (t0)
 #endif
 
@@ -111,13 +116,45 @@ done:
 #ifdef CONFIG_CPU_CAVIUM_OCTEON
 	cache	0, 0($0)
 #endif
+#ifdef	CONFIG_RMI_PHOENIX
+	bal	kexec_phoenix_flush_cache
+	nop
+#endif
 
 	/* jump to kexec_start_address */
 	j		s1
 	nop
+END(relocate_new_kernel)
+
+#ifdef	CONFIG_RMI_PHOENIX
+LEAF(kexec_phoenix_flush_cache)
+	/* From RMI's boot1/cache.S, but implemented with only 2 regs. */
+	/* FIXME: Obtain size and num cache lines from CP0 config1 reg.
+	 *        (Try to do the following with 2 regs in that case!)
+	 */
+	li		t9,0
+1:
+	li		t8,0x80000000
+	sll		t9,t9,5
+	add		t8,t8,t9
+	sra		t9,t9,5
+	cache		0,0(t8)
+	cache		1,0(t8)
+	addiu		t9,1
+	slti		t8,t9,1024
+	bnez		t8,1b
+	nop
+	nop
+	nop
+	nop
+	nop
 	nop
 	nop
-	END(relocate_new_kernel)
+	nop
+	jr		ra
+	nop
+END(kexec_phoenix_flush_cache)
+#endif /* CONFIG_RMI_PHOENIX */
 
 #ifdef CONFIG_SMP
 /*
@@ -161,8 +198,114 @@ wait:
 	j        s1
 	nop
 	END(kexec_smp_wait)
-#endif
 
+#ifdef CONFIG_RMI_PHOENIX
+/* OK, RMI is interesting. The secondary CPUs do NOT start at the kernel entry,
+ * but rather are signalled to jump to an address in the second kernel, which
+ * is part of the RMI-specific init sequence called from within setup_arch().
+ *
+ * The boot CPU calls a routine installed by the boot loader in boot loader
+ * memory. We have to mimic this by installing a routine in the control page.
+ * This routine will simply set a variable to 1, signalling the secondary CPUs
+ * that they can get out of their spin. The routine also installs a function
+ * pointer that tells the secondary CPUs to jump to a routine (namely
+ * prom_pre_boot_secondary_cpus()) in the second kernel.
+ *
+ * When computing addresses of relocated symbols here, we need the functions
+ * to be double-word aligned, since the pointers are 64-bit, to avoid taking
+ * non-aligned exceptions (the exception handlers are invalid at this point).
+ * The computations are done relative to the start of the functions so that
+ * the start point is aligned. We cannot perform computation based on return
+ * addresses and forward symbols since the assembler might add NOPs after
+ * branches and thus throw the computation off, possibly giving a 4-byte
+ * aligned address instead of an 8-byte aligned one.
+ */
+
+LEAF(kexec_rmi_secondary_cpu_spin)
+	.align	3
+	bal	1f	/* MUST be first instruction */
+	nop
+1:
+	.align	3
+	PTR_ADDIU	ra,ra,-8 /* -8 *if* bal is first instruction */
+	PTR_LA		t0,kexec_rmi_secondary_cpu_spin
+	PTR_LA		v0,kexec_secondary_cpu_spin_var
+	PTR_SUBU	t1,v0,t0 /* t1 <= offset to relocated spin_var */
+	PTR_ADDU	v0,ra,t1 /* v0 now contains the relocated variable addr */
+2:
+	LONG_L		t1,(v0)
+	beq		t1,zero,2b
+	nop
+
+	/* out of the spin loop, kexec_secondary_cpu_next_kernel_entry_point
+	 * now contains the address where to jump to in the second kernel
+	 *
+	 * t0 still contains address of non-relocated
+	 * kexec_rmi_secondary_cpu_spin()
+	 */
+	PTR_LA		v0,kexec_secondary_cpu_next_kernel_entry_point
+	PTR_SUBU	t1,v0,t0 /* t1 <= offset to relocated entry_pt */
+	PTR_ADDU	v0,ra,t1 /* v0 now contains the relocated variable addr */
+	PTR_L		t1,(v0)
+	bal		kexec_phoenix_flush_cache
+	nop
+	jr		t1
+	nop
+END(kexec_rmi_secondary_cpu_spin)
+
+LEAF(kexec_rmi_boot_cpu_wakeup_secondary_cpus)
+	/* a0 contains the address the secondary CPUs will jump to in the
+	 * second kernel
+	 */
+	.align	3
+	move		t3,ra	/* save ra from the second kernel */
+
+	bal		1f	/* MUST be second instruction */
+	nop
+1:
+	.align	3
+	PTR_ADDIU	ra,ra,-12 /* -12 *if* bal is second instruction */
+	PTR_LA		t0,kexec_rmi_boot_cpu_wakeup_secondary_cpus
+	PTR_LA		v0,kexec_secondary_cpu_next_kernel_entry_point
+	PTR_SUBU	t1,v0,t0 /* t1 <= offset to relocated _wakeup_ */
+	PTR_ADDU	v0,ra,t1 /* v0 now contains the relocated var addr */
+	PTR_S		a0,(v0)	/* store addr in 2nd kernel where to jump */
+
+	sync
+	nop
+	nop
+	nop
+	nop
+	nop
+
+	/* t0 still contains address of non-relocated
+	 * kexec_rmi_secondary_cpu_spin()
+	 */
+	PTR_LA		v0,kexec_secondary_cpu_spin_var
+	PTR_SUBU	t1,v0,t0 /* t1 <= offset to relocated spin_var */
+	PTR_ADDU	v0,ra,t1 /* v0 now contains the relocated variable addr */
+	dli		t1,0x1
+	PTR_S		t1,(v0)
+
+	jr		t3
+	nop
+END(kexec_rmi_boot_cpu_wakeup_secondary_cpus)
+
+	.align 3
+kexec_secondary_cpu_spin_var:
+EXPORT(kexec_secondary_cpu_spin_var)
+	LONG	0x0
+	.size	kexec_secondary_cpu_spin_var, PTRSIZE
+
+	.align 3
+kexec_secondary_cpu_next_kernel_entry_point:
+EXPORT(kexec_secondary_cpu_next_kernel_entry_point)
+	PTR	0x0
+	.size	kexec_secondary_cpu_next_kernel_entry_point, PTRSIZE
+
+#endif	/* CONFIG_RMI_PHOENIX */
+
+#endif	/* CONFIG_SMP */
 
 #ifdef __mips64
        /* all PTR's must be aligned to 8 byte in 64-bit mode */
diff --git a/arch/mips/rmi/phoenix/Makefile b/arch/mips/rmi/phoenix/Makefile
index dfa2ac1..d67aea8 100644
--- a/arch/mips/rmi/phoenix/Makefile
+++ b/arch/mips/rmi/phoenix/Makefile
@@ -6,4 +6,6 @@ obj-$(CONFIG_PHOENIX_IP_OVER_PCI) += dma.o
 
 obj-$(CONFIG_SMP)		+= smp.o smpboot.o
 
+obj-$(CONFIG_KEXEC) += phoenix_kexec.o
+
 EXTRA_AFLAGS := $(CFLAGS)
diff --git a/arch/mips/rmi/phoenix/phoenix_kexec.c b/arch/mips/rmi/phoenix/phoenix_kexec.c
new file mode 100644
index 0000000..b3285df
--- /dev/null
+++ b/arch/mips/rmi/phoenix/phoenix_kexec.c
@@ -0,0 +1,282 @@
+/*
+ * phoenix_kexec.c, kexec support for RMI XLR732-based boards
+ *
+ * Copyright (c) 2009 Wind River Systems, Inc.
+ *
+ * Author:     Benjamin Walsh <benjamin.walsh@windriver.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ */
+
+#include <linux/kexec.h>
+#include <asm/kexec.h>
+#include <asm/rmi/sim.h>
+#include <asm/bootinfo.h>
+#include <asm/uaccess.h>
+#include <linux/mm.h>
+#include <asm/page.h>
+#include <asm/rmi/mips-exts.h>
+#include <linux/delay.h>
+#include <linux/ctype.h>
+
+#define WAIT_TIME_FOR_OTHER_CPUS_IN_MSECS 10000
+
+extern struct psb_info prom_info_copy;
+extern struct boot_mem_map boot_physaddr_info;
+extern struct boot_mem_map psb_mem_map_copy;
+extern struct boot_mem_map avail_mem_map_copy;
+extern struct boot_mem_map *avail_mem_map_copy_ptr;
+
+static int phoenix_kexec_prepare(struct kimage*);
+static void phoenix_kexec_shutdown(void);
+static void phoenix_smp_handle_restart(unsigned long reloc);
+static void phoenix_crash_shutdown(struct pt_regs *regs);
+static void phoenix_dont_do_cache_flush(void);
+extern void phnx_local_flush_tlb_all(void);
+
+static int rebooting_cpu = -1;
+static cpumask_t cpus_in_reboot = CPU_MASK_NONE;
+
+#ifdef CONFIG_SMP
+void rmi_patch_bootloader_wakeup_fn(ulong reboot_code_buffer);
+void (*relocated_kexec_rmi_secondary_cpu_spin)(void);
+atomic_t kexec_relocate_kernel_ready = ATOMIC_INIT(0);
+extern void kexec_rmi_secondary_cpu_spin(void);
+#endif
+
+extern const unsigned char relocate_new_kernel[];
+extern const size_t relocate_new_kernel_size;
+extern void kexec_rmi_boot_cpu_wakeup_secondary_cpus(void *callback);
+
+extern int  (*_machine_kexec_prepare)(struct kimage *);
+extern void (*_machine_kexec_shutdown)(void);
+extern void (*_machine_crash_shutdown)(struct pt_regs *regs);
+extern void (*_machine_cache_flush)(void);
+extern void (*_machine_smp_handle_restart)(unsigned long reloc);
+
+void phoenix_kexec_init(void)
+{
+	_machine_kexec_prepare      = phoenix_kexec_prepare;
+	_machine_kexec_shutdown     = phoenix_kexec_shutdown;
+	_machine_crash_shutdown     = phoenix_crash_shutdown;
+	_machine_cache_flush	    = phoenix_dont_do_cache_flush;
+	_machine_smp_handle_restart = phoenix_smp_handle_restart;
+}
+
+static void phoenix_dont_do_cache_flush(void)
+{
+	/* don't do anything */
+}
+
+static void shutdown_secondary_cpus(void *crash)
+{
+	struct pt_regs *regs = NULL;
+	int cpu;
+
+	if((unsigned long)crash) {
+		regs = task_pt_regs(current);
+	}
+
+	local_irq_disable();
+	cpu = smp_processor_id();
+
+	if (!cpu_online(cpu)) {
+		return;
+	}
+
+	if (!cpu_isset(cpu, cpus_in_reboot)) {
+		if(regs) {
+			crash_save_cpu(regs, cpu);
+		}
+		cpu_set(cpu, cpus_in_reboot);
+	}
+
+	while(!atomic_read(&kexec_relocate_kernel_ready)) {
+		cpu_relax();
+	}
+	phnx_local_flush_tlb_all();
+	relocated_kexec_rmi_secondary_cpu_spin();
+	/* NOTREACHED */
+}
+
+static void prepare_cpus(const unsigned long crash)
+{
+	smp_call_function(shutdown_secondary_cpus, (void*)crash, 0);
+	smp_wmb();
+	local_irq_disable();
+}
+
+static void wait_for_cpus(void)
+{
+	unsigned int msecs;
+	unsigned int ncpus = num_online_cpus();
+	unsigned int rebooting_cpus;
+
+	rebooting_cpu = smp_processor_id();
+	cpu_set(rebooting_cpu, cpus_in_reboot);
+
+	msecs = WAIT_TIME_FOR_OTHER_CPUS_IN_MSECS;
+	while((rebooting_cpus = cpus_weight(cpus_in_reboot)) < ncpus) {
+		if(--msecs <= 0) {
+			break;
+		}
+		cpu_relax();
+		mdelay(1);
+	}
+}
+
+static int phoenix_kexec_prepare(struct kimage* kimage)
+{
+	struct page *boot_info;
+	struct psb_info *next_kernel_psb_info;
+	void *copy_va;
+	struct kexec_segment *s;
+	char buffer[32], *c;
+	int len, ii, pos, new_argc;
+	int32_t *new_argv;
+	int slurping_spaces;
+
+	/* we have to copy the boot information in a temporary page that is
+	 * available to the second kernel after the first kernel's data/bss
+	 * has been overwritten */
+	boot_info = alloc_pages(GFP_KERNEL, 0);
+	if(!boot_info) {
+		printk(KERN_EMERG "Cannot allocate page for boot info\n");
+		return -ENOMEM;
+	}
+	boot_info->mapping = NULL;
+	set_page_private(boot_info, 0);
+	SetPageReserved(boot_info);
+	copy_va = (void*)page_to_pfn(boot_info);
+	copy_va = (void *)((ulong)copy_va << PAGE_SHIFT);
+	copy_va = (void *)phys_to_virt((ulong)copy_va);
+
+	kexec_args[3] = (unsigned long)copy_va;
+	next_kernel_psb_info = (void *)kexec_args[3];
+
+	memcpy(copy_va, (void*)&prom_info_copy, sizeof(prom_info_copy));
+	copy_va = PTR_ALIGN(((void*)copy_va)+sizeof(prom_info_copy),sizeof(void*));
+
+	memcpy(copy_va, (void*)&boot_physaddr_info, sizeof(boot_physaddr_info));
+	next_kernel_psb_info->psb_physaddr_map = (uint64_t)copy_va;
+	copy_va = PTR_ALIGN(((void*)copy_va)+sizeof(boot_physaddr_info),sizeof(void*));
+
+	memcpy(copy_va, (void*)&psb_mem_map_copy, sizeof(psb_mem_map_copy));
+	next_kernel_psb_info->psb_mem_map = (uint64_t)copy_va;
+	copy_va = PTR_ALIGN(((void*)copy_va)+sizeof(psb_mem_map_copy),sizeof(void*));
+
+	if(avail_mem_map_copy_ptr) {
+		memcpy(copy_va, (void*)&avail_mem_map_copy,
+			sizeof(avail_mem_map_copy));
+		next_kernel_psb_info->avail_mem_map = (uint64_t)copy_va;
+		copy_va = PTR_ALIGN(((void*)copy_va)+sizeof(avail_mem_map_copy),
+					sizeof(void*));
+	} else {
+		next_kernel_psb_info->avail_mem_map = (uint64_t)NULL;
+	}
+	for(ii = 0; ii < kimage->nr_segments; ii++) {
+		s = &kimage->segment[ii];
+		len = min(32, (int)s->bufsz);
+		copy_from_user((void*)buffer, s->buf, len);
+		buffer[len] = 0; /* just in case... */
+		if(strncmp(buffer, "kexec ", 6) == 0) {
+			break;
+		}
+	}
+	if(ii == kimage->nr_segments) {
+		return -1;
+	}
+
+	new_argv = (void*)copy_va;
+	new_argc = 1;
+	new_argv[0] = s->mem|0x80000000;	/* program name: 'kexec' */
+	slurping_spaces = 0; /* 'kexec' string at the beginning, always */
+	for(pos = 0; pos < s->bufsz; pos += len) {
+		len = min(32, (int)s->bufsz - pos);
+		copy_from_user((void*)buffer, s->buf+pos, len);
+		c = buffer;
+		while(c < (buffer + len)) {
+			int buf_offset = (int)(c - buffer);
+			if(slurping_spaces) {
+				if(!isspace(*c)) {
+					new_argv[new_argc] =
+						(int)(s->mem + pos +
+							buf_offset);
+					new_argv[new_argc] |= 0x80000000;
+					++new_argc;
+					slurping_spaces = 0;
+				}
+			} else {
+				if(isspace(*c)) {
+					copy_to_user(s->buf+pos+buf_offset,
+							"", 1);
+					slurping_spaces = 1;
+				}
+			}
+			++c;
+		}
+	}
+	kexec_args[0] = new_argc;
+	kexec_args[1] = (unsigned long)new_argv;
+	kexec_args[2] = 0;	/* no envp */
+
+	return 0;
+}
+
+static void phoenix_kexec_shutdown(void)
+{
+	prepare_cpus(0);
+	wait_for_cpus();
+	phnx_local_flush_tlb_all();
+}
+
+static void phoenix_crash_shutdown(struct pt_regs *regs)
+{
+	crash_save_cpu(regs, smp_processor_id());
+	prepare_cpus(1);
+	wait_for_cpus();
+	phnx_local_flush_tlb_all();
+}
+
+#ifdef CONFIG_SMP
+void rmi_patch_bootloader_wakeup_fn(unsigned long reloc)
+{
+	void (*relocated_wakeup_callback)(void *);
+
+	relocated_wakeup_callback = (void *)(reloc +
+		((ulong)kexec_rmi_boot_cpu_wakeup_secondary_cpus -
+			(ulong)relocate_new_kernel));
+
+	((struct psb_info *)kexec_args[3])->wakeup =
+		(uint64_t)relocated_wakeup_callback;
+}
+
+static void phoenix_smp_handle_restart(unsigned long reloc)
+{
+	/* All secondary cpus now may jump to kexec_wait cycle */
+	relocated_kexec_smp_wait =
+		(void *)(reloc + (kexec_smp_wait - relocate_new_kernel));
+	rmi_patch_bootloader_wakeup_fn(reloc);
+	relocated_kexec_rmi_secondary_cpu_spin =
+		(void *)(reloc + ((ulong)kexec_rmi_secondary_cpu_spin -
+				(ulong)relocate_new_kernel));
+	smp_wmb();
+	atomic_set(&kexec_relocate_kernel_ready, 1);
+}
+#else
+static void phoenix_smp_handle_restart(unsigned long reloc)
+{
+}
+#endif /* CONFIG_SMP */
+
diff --git a/arch/mips/rmi/ptr/setup.c b/arch/mips/rmi/ptr/setup.c
index 0ff7e08..41a5a31 100644
--- a/arch/mips/rmi/ptr/setup.c
+++ b/arch/mips/rmi/ptr/setup.c
@@ -119,6 +119,10 @@ extern uint64_t fdt_get_wakeup_ptr(void );
 extern int fdt_get_core_tlb_size(int core);
 extern void *rmi_get_usermac_addr(int size);
 
+#ifdef CONFIG_KEXEC
+extern void phoenix_kexec_init(void);
+#endif
+
 #define RMI_RMIK_MAGIC 0xfee1900dULL
 #define RMI_MAX_ARGS 64
 #define RMI_MAX_ENVS 32
@@ -1495,6 +1499,10 @@ void __init prom_init(void)
 	on_chip_init();
 	prom_reconfigure_thr_resources();
 	register_smp_ops(&phoenix_smp_ops);
+
+#ifdef CONFIG_KEXEC
+	phoenix_kexec_init();
+#endif
 }
 
 void prom_free_prom_memory(void)
-- 
1.6.0.4

