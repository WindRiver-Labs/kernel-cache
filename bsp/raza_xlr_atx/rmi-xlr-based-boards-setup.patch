From 040c9e076313e157622e5df22bdcb5e64846c192 Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Tue, 16 Dec 2008 19:07:12 +0800
Subject: [PATCH] rmi xlr based boards setup

RMI XLR based board setup code.

Mainly parse board specific parameter from rmi bootloader.

Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 arch/mips/rmi/ptr/Makefile     |   14 +
 arch/mips/rmi/ptr/rmik_utils.c |   78 ++
 arch/mips/rmi/ptr/setup.c      | 1711 ++++++++++++++++++++++++++++++++++++++++
 3 files changed, 1803 insertions(+), 0 deletions(-)
 create mode 100644 arch/mips/rmi/ptr/Makefile
 create mode 100644 arch/mips/rmi/ptr/rmik_utils.c
 create mode 100644 arch/mips/rmi/ptr/setup.c

diff --git a/arch/mips/rmi/ptr/Makefile b/arch/mips/rmi/ptr/Makefile
new file mode 100644
index 0000000..049b6a9
--- /dev/null
+++ b/arch/mips/rmi/ptr/Makefile
@@ -0,0 +1,14 @@
+obj-y = setup.o rmik_utils.o
+
+obj-y += loader/ dtb/
+
+EXTRA_AFLAGS := $(CFLAGS)
+
+ifdef CONFIG_RMICRF
+RMICRF_ROOT := $(if $(filter-out "",$(CONFIG_RMICRF_ROOT)), \
+			$(shell echo $(CONFIG_RMICRF_ROOT)),-d)
+
+EXTRA_CFLAGS += -I$(RMICRF_ROOT)/include
+endif
+
+
diff --git a/arch/mips/rmi/ptr/rmik_utils.c b/arch/mips/rmi/ptr/rmik_utils.c
new file mode 100644
index 0000000..7f0c2ee
--- /dev/null
+++ b/arch/mips/rmi/ptr/rmik_utils.c
@@ -0,0 +1,78 @@
+/*********************************************************************
+
+  Copyright 2007-2008 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/init.h>
+#include <asm/rmi/phnx_user_mac.h>
+#ifdef CONFIG_RMICRF
+#include <rmicrf/types.h>
+#include <rmicrf/api.h>
+#endif
+
+void *rmi_get_usermac_addr(int size)
+{
+#ifdef CONFIG_RMICRF
+		uint64_t ret;
+		ret = rmi_mem_alloc(RMI_MALLOC_UNMAPPED, size, PAGE_SIZE);
+		return (void *)(long)(ret + CKSEG0);
+#else
+		return ((void *)CKSEG0 + PHNX_USER_MAC_MMAP_PHYS_START);
+#endif
+		
+}
+
+void *rmi_frin_mem_alloc(int size)
+{
+#ifdef CONFIG_RMICRF
+		uint64_t ret;
+		ret = rmi_mem_alloc(RMI_MALLOC_UNMAPPED, size, PAGE_SIZE);
+		if(ret == 0x0ULL)
+			panic("Out of memory\n");
+		return (void *)(long)(ret + CKSEG0);
+#else
+		return NULL;
+#endif
+}
+
+void *rmi_spill_mem_alloc(int spill_size)
+{
+#ifdef CONFIG_RMICRF
+		uint64_t ret;
+		ret = rmi_mem_alloc(RMI_MALLOC_UNMAPPED, spill_size, PAGE_SIZE);
+		if(ret == 0x0ULL)
+			panic("Out of memory\n");
+		return (void *)(long)(ret + CKSEG0);
+#else
+		return NULL;
+#endif
+}
+
diff --git a/arch/mips/rmi/ptr/setup.c b/arch/mips/rmi/ptr/setup.c
new file mode 100644
index 0000000..4ad2492
--- /dev/null
+++ b/arch/mips/rmi/ptr/setup.c
@@ -0,0 +1,1711 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/*
+ * Setup code for RMI's XLR-based boards
+*/
+
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/init.h>
+#include <linux/pm.h>
+
+#include <asm/irq.h>
+#include <asm/io.h>
+#include <asm/bootinfo.h>
+#include <asm/addrspace.h>
+#include <asm/reboot.h>
+#include <asm/time.h>
+#include <linux/interrupt.h>
+#include <asm/atomic.h>
+
+#include <asm/rmi/sim.h>
+#include <asm/mipsregs.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/debug.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/pic.h>
+
+#include <asm/rmi/phnx_loader.h>
+#include <asm/rmi/user/phnx_loader.h>
+#include <asm/rmi/rmi_pcix_gen_dev.h>
+#include <asm/rmi/memory-exclusion.h>
+
+#include <linux/serial.h>
+#include <linux/serial_8250.h>
+#include <linux/serial_core.h>
+
+#ifdef CONFIG_BTLB_LOADER
+#include <linux/btlb.h>
+#endif
+
+#ifdef RMI_BRIDGE_WKAROUND
+#include <asm/rmi/rmi_rw_lock.h>
+#include <asm/rmi/global_shmem.h>
+rmi_rwlock_t *rmi_bridge_lock;
+int rmi_enable_br_wrkaround = 0;
+#endif
+
+unsigned long long phnx_tlb_stats[32] __cacheline_aligned;
+unsigned long long phnx_btlb_stats[32] __cacheline_aligned;
+
+spinlock_t atomic_lock = SPIN_LOCK_UNLOCKED;
+
+__u8 phoenix_base_mac_addr[6];
+volatile phnx_loader_shared_struct_t *phnx_loader_sh_mem = NULL;
+
+/* used for command line parsing */
+uint32_t phnx_loader_kseg_start, phnx_loader_kseg_size;
+uint32_t phnx_loader_mask;
+
+/* Size of the shared memory b/w Linux userapp and rmios apps */
+uint32_t phnx_app_sh_mem_sz;
+unsigned long  phnx_app_shmem_start;
+static int index = 0;
+
+/*Environment Vairables*/
+struct environment xlr_bldr_env;
+
+__u32 xlr_board_major_version = RMI_PHOENIX_BOARD_ARIZONA_I;
+__u32 xlr_board_minor_version = 0;
+
+#define DEFAULT_LINUX_CPU_MASK 0x1
+#define DEFAULT_LOADER_MASK ~DEFAULT_LINUX_CPU_MASK
+
+struct kuseg_mem_info kuseg_mem_map[MAX_NUM_KUSEG_BLOCKS];
+
+void prom_init_xlr_loader_setup(struct psb_info *prom_info);
+
+void *phoenix_psb_shm = 0;
+unsigned long phoenix_psb_shm_size = 0;
+static int dyna_exc_index=0;
+extern unsigned long _text[];
+
+extern uint32_t dev_tree_en;
+extern int fdt_init(char *start, char *end);
+extern void fdt_fill_prom_info( struct psb_info *p_info);
+extern void fdt_parse_args(void);
+extern uint64_t fdt_get_wakeup_ptr(void );
+extern int fdt_get_core_tlb_size(int core);
+extern void *rmi_get_usermac_addr(int size);
+
+#define RMI_RMIK_MAGIC 0xfee1900dULL
+#define RMI_MAX_ARGS 64
+#define RMI_MAX_ENVS 32
+
+uint64_t *rmi_kernel_args = NULL;
+uint32_t *rmi_call_table;
+char *rmi_fdt_buf;
+uint32_t rmi_fdt_buf_size;
+void *rmi_dom;
+void (*rmi_rmik_entry)(int);
+void *rmi_pcpu_info;
+
+
+struct psb_info *prom_info = 0;
+struct psb_info prom_info_copy; /* Bootloader prom_info is saved here */
+
+static struct psb_info default_prom_info = {
+	.boot_level              = 2,
+	.io_base                 = DEFAULT_PHOENIX_IO_BASE,
+	.output_device           = 2,
+	.cpu_online_map          = 0x01,
+	.magic_dword             = (((__u64)0x900dbeef << 32)|PSB_INFO_VERSION),
+	.size                    = sizeof(struct psb_info),
+	.mac_addr                = 0x000102030405ULL,
+	.cpu_frequency           = 1200000000,
+	.board_version           = 1,
+	.board_major_version     = 1,
+	.board_minor_version     = 0,
+};
+
+static struct physmap_info {
+	int type;
+	char *name;
+} psb_physmap_info[] =
+{
+	{ 0x01 , "Memory" },
+	{ 0x02 , " *** HOLE ***" },
+	{ 0x10 , "Phoenix IO Space" },
+	{ 0x11 , "PCIX IO Space"    },
+	{ 0x12 , "PCIX CFG Space"   },
+	{ 0x13 , "PCIX Memory Space"},
+	{ 0x14 , "HT IO Space"      },
+	{ 0x15 , "HT CFG Space" },
+	{ 0x16 , "HT Memory Space" },
+	{ 0x17 , "SRAM (QDR) Space" },
+	{ 0x18 , "Flash Controller Space" },
+	{ 0xff , "Unknown type" }
+};
+
+struct boot_mem_map boot_physaddr_info;
+
+/* 
+ * The below regions should be in ascending order of the starting physical 
+ * addresses
+*/
+static struct boot_mem_map_exclude_region dynamic_exclude_regions[] = {
+	[0] = {0, 0}, /* PCI Shared Mem Or RMIOS Lib Memory*/
+	[1] = {0, 0}, /* PCI Shared Mem Or RMIOS Lib Memory*/
+	[2] = {0, 0}, /* Loader KSEG0 region */
+	[3] = {0, 0}, /* Loader KUSEG region Block 1*/
+	[4] = {0, 0}, /* Loader KUSEG region Block 2 or Hybrid Mode exclusion */
+	[5] = {0, 0}, /* Loader KUSEG region Block 3 or Hybrid Mode exclusion */
+	[6] = {0, 0}, /* Loader KUSEG region Block 4 or Hybrid Mode exclusion */
+	[7] = {0, 0}, /* Hybrid Mode exclusion*/
+	[8] = {0, 0}, /* END of the list - MUST be the last entry always */
+};
+
+static char *get_psb_physmap_name(int type)
+{
+	int i = 0;
+	int tsize = sizeof(psb_physmap_info) / sizeof(struct physmap_info);
+
+	for( i = 0; i < tsize; i++ )
+	{
+		if( (psb_physmap_info[i].type == type ) ||
+		    (psb_physmap_info[i].type == 0xff ) )
+			return psb_physmap_info[i].name;
+	}
+	return ("Unknown type");
+}
+
+/* returns 1 for IO and 0 for mem 1 for not found */
+int phnx_get_pgprot(unsigned long address)
+{
+	int i;
+	__u64 start=0, end=0;
+	char *name = NULL;
+
+	for(i=0; i < boot_physaddr_info.nr_map; i++) 
+	{
+		start = boot_physaddr_info.map[i].addr;
+		end = boot_physaddr_info.map[i].addr + boot_physaddr_info.map[i].size;
+		if((address >= start) && (address < end)) 
+		{
+			name = get_psb_physmap_name(boot_physaddr_info.map[i].type);
+			if(!(strcmp(name, "Memory"))) 
+				return 0;
+			else
+				return 1;
+		}
+	}
+
+	return 1;	
+}
+
+/* TODO FIXME - replace with correct */
+static inline void *rmi_mem_alloc_x(int type, uint64_t size, int align)
+{
+	return (void *)(long)0x82000000;
+}
+
+int usermac_mmap_size = 0x00800000;
+
+#define RMI_MALLOC_UNMAPPED 0x01
+
+/* memory needed by the rmi kernel for teach cpu */
+#define XLR_PCPU_AREA_SIZE          (8*1024)
+#define XLR_EXCEPTION_FRAME_OFFSET      (XLR_PCPU_AREA_SIZE-400)
+#define RMI_MANAGEMENT_IPI 42
+#define XLR_TF_A0 4
+#define XLR_TF_RA 31
+
+static inline void xlr_send_nmi_ipi(int cpu, int vector)
+{       
+    int thread = cpu & 0x3;
+    int core = (cpu >> 2) & 0x7;
+    
+    uint32_t val = (core<<20) | (thread<<16) | (1<<8) | vector;
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
+
+    phoenix_write_reg(mmio, PIC_IPI, val);
+}  
+
+void rmik_wakeup_cpus(void *fn, void *args, uint32_t cpu_mask)
+{
+    int i = 0;
+    int cpuid;
+	uint64_t *trap_frame;
+	void *pcpumem;
+	uint32_t *data_area;
+
+    cpuid = phoenix_cpu_id();
+    cpu_mask &= ~(1 << cpuid);
+    for (i = 0; i < NR_CPUS; i++) {
+        if (!(cpu_mask & (1 << i)))
+			continue;
+
+		data_area = (uint32_t *)rmi_pcpu_info + 4 * i;
+		pcpumem = (void *)(long)(int)(*data_area); 
+		trap_frame = (uint64_t *)pcpumem + XLR_EXCEPTION_FRAME_OFFSET
+						/ sizeof(uint64_t);
+		trap_frame[XLR_TF_A0] = (uint64_t)(long)args;
+		trap_frame[XLR_TF_RA] =  (uint64_t)(long)fn;
+		barrier();
+		xlr_send_nmi_ipi(i, RMI_MANAGEMENT_IPI);
+    }
+	return ;
+}
+
+/* return 1 for success and 0 for failure */
+int valid_mmap_phnx_addr_range(unsigned long pfn)
+{
+	int i;
+	__u64 end=0;
+
+	for(i=0; i < boot_physaddr_info.nr_map; i++) 
+	{
+		end = boot_physaddr_info.map[i].addr + boot_physaddr_info.map[i].size;
+		end = end >> PAGE_SHIFT;
+		if(pfn <= (unsigned long)end)
+			return 1;
+	}
+	return 0;
+}
+
+static int sanity_check_prom_info(struct psb_info *info)
+{
+	if (!prom_info) return 0;
+  
+	if ((prom_info->magic_dword & 0xffffffffULL) != 0x900dbeef) return 0;
+	if ((prom_info->magic_dword >> 32) != PSB_INFO_VERSION) return 0;
+
+	return 1;
+}
+
+const char *DEFAULT_CONSOLE_BOOT_PARAMS = "console=ttyS0,38400 ";
+const char *DEFAULT_INITRD_BOOT_PARAMS = "rdinit=/sbin/init ";
+
+const char *get_system_type(void)
+{
+	return "RMI XLR";
+}
+
+#ifdef CONFIG_SMP
+atomic_t cpus_rebooted = ATOMIC_INIT(0);
+#endif
+
+#define GPIO_SWRESET_REG 8
+
+static void ptr_linux_exit(void)
+{
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_GPIO_OFFSET);
+
+	/* trigger a chip reset */
+	phoenix_write_reg(mmio, GPIO_SWRESET_REG, 1);
+	for(;;) cpu_wait();
+}
+
+void __init bus_error_init(void)
+{
+}
+
+void prom_reconfigure_thr_resources(void)
+{
+	unsigned int mmu_setup = 0;
+	int value = 0;
+	__u32 online_map = prom_info->cpu_online_map;
+	__u32 thr_mask = online_map >> (phoenix_cpu_id()<<2);
+	int i=0, count=0;
+	int dis_contig=0;
+
+	if(dev_tree_en) {
+		return;
+		/* rmi kernel configures this */
+	}
+
+	 if (phoenix_thr_id()==0 ) { 
+
+		for(i=0;i<4;i++) {
+			if (thr_mask & (1<<i)) {
+				if(i != count)
+					dis_contig = 1;
+				count++;
+			}
+		}
+		switch(count) {
+			case 1: value = 0x00; break;
+			case 2: value = 0x02; break;
+			default:
+				value = 0x03; break;
+		}
+		if(dis_contig)
+			value = 0x3; 
+
+		mmu_setup = read_32bit_phnx_ctrl_reg(4, 0);
+		mmu_setup = mmu_setup & ~0x06;
+		mmu_setup |= (value << 1);
+
+		write_32bit_phnx_ctrl_reg(4, 0, mmu_setup);
+	 } 
+}
+
+int xlr_hybrid;
+int xlr_loader_support=0;
+int xlr_loader_sharedcore=0;
+int xlr_loader_own_gmac=0;
+int xlr_loader_own_dma=0;
+
+uint32_t xlr_linux_cpu_mask;
+int xlr_console_pci_con_dev = 0;
+int xlr_console_pci_con_baud = 0;
+int xlr_boot_over_nfs = 0;
+
+unsigned long phnx_ebase = 0x0;
+
+static void xlr_initialize_setups(void)
+{
+	xlr_hybrid = XLR_HYBRID_NONE;
+	xlr_user_mac.l4_extract = 0;
+	xlr_user_mac.fast_syscall = 1;
+	xlr_loader_support = 0;
+	xlr_loader_sharedcore = 0;
+	xlr_loader_own_gmac = 0;
+	xlr_loader_own_dma = 0;
+	xlr_linux_cpu_mask = DEFAULT_LINUX_CPU_MASK; 
+	phnx_loader_kseg_start = 0;
+
+	for ( index = 0 ; index < MAX_NUM_KUSEG_BLOCKS ; index++) {
+		kuseg_mem_map[index].start_addr = 0;
+		kuseg_mem_map[index].size = 0;
+	}
+
+	phnx_loader_kseg_size = 0;
+	phnx_loader_mask = DEFAULT_LOADER_MASK;
+	phnx_app_sh_mem_sz = 2*1024*1024;
+}
+
+void exclude_hybrid_mem_region(void)
+{
+    if(xlr_loader_support) {
+        return;
+    }
+
+    dynamic_exclude_regions[dyna_exc_index].start = 1<<20;
+    dynamic_exclude_regions[dyna_exc_index].end = 
+        (unsigned long long)(((unsigned long)&_text) & 0x1fffffffUL);
+    dyna_exc_index++;
+}
+
+static void xlr_early_hybrid_setup(char *str)
+{
+    if ((strcmp(str, "=rmios_ipsec") == 0)||
+		 (strcmp(str, "rmios_ipsec") == 0)){
+        exclude_hybrid_mem_region();
+	}
+	else if ((strcmp(str, "=rmios_tcpip_stack") == 0)||
+		 (strcmp(str, "rmios_tcpip_stack") == 0)) {
+        exclude_hybrid_mem_region();
+	}
+}
+
+static int xlr_hybrid_setup(char *str)
+{
+	uint32_t loader_reg;
+    uint64_t kernel_start;
+
+	if ((strcmp(str, "=user_mac_xgmac") == 0)||
+					(strcmp(str, "user_mac_xgmac") == 0)) {
+		if(xlr_board_atx_ii()){
+			xlr_hybrid = XLR_HYBRID_USER_MAC_XGMAC;
+			printk("Configured for Hybrid mode with USER_MAC_XGMAC\n");
+			phnx_msgring_config();
+		}else{
+			printk("user_mac_xgmac hybrid mode is available only on ATX-II\n");
+		}
+	}
+	else if ((strcmp(str, "=user_mac") == 0)||(strcmp(str, "user_mac") == 0)) {
+		xlr_hybrid = XLR_HYBRID_USER_MAC;
+		printk("Configured for Hybrid mode with USER_MAC\n");
+		phnx_msgring_config();
+	}
+	else if ((strcmp(str, "=rmios_ipsec") == 0)||
+		 (strcmp(str, "rmios_ipsec") == 0)){
+		xlr_hybrid = XLR_HYBRID_RMIOS_IPSEC;
+		printk("Configured for Hybrid mode with RMIOS IPSEC\n");
+	}
+	else if ((strcmp(str, "=rmios_tcpip_stack") == 0)||
+		 (strcmp(str, "rmios_tcpip_stack") == 0)) {
+		xlr_hybrid = XLR_HYBRID_RMIOS_TCPIP_STACK;
+        kernel_start = (uint64_t)(((unsigned long)&_text) & 0x1fffffffUL);
+        if(kernel_start < PHNX_RMIOS_TCPIP_END){
+            panic("Build kernel with loadaddress above %#x\n",
+                    PHNX_RMIOS_TCPIP_END);
+        }
+		printk("Configured for Hybrid mode with RMIOS_TCPIP_STACK\n");
+	}
+	else {
+		xlr_hybrid = XLR_HYBRID_NONE;
+		printk("Configured for Hybrid mode with None\n");
+	}
+	if((xlr_hybrid != XLR_HYBRID_NONE) && (xlr_loader_support)) {
+		/* 
+		 * Don't allow loader feature if hybrid app and loader are
+		 * using same memory region
+		*/
+		loader_reg = phnx_loader_kseg_start + phnx_loader_kseg_size;
+        if(xlr_hybrid_user_mac() || xlr_hybrid_user_mac_xgmac()){
+		    if(((PHNX_USER_MAC_MMAP_PHYS_START >= phnx_loader_kseg_start) &&
+			    (PHNX_USER_MAC_MMAP_PHYS_START < loader_reg)) ||
+    	       	  ((phnx_loader_kseg_start >= PHNX_USER_MAC_MMAP_PHYS_START) &&
+	    	   (phnx_loader_kseg_start < PHNX_USER_MAC_MMAP_PHYS_END)))	{
+		    	xlr_loader_support=0;
+			    printk("Disabling Loader support as hybrid mode is selected\n");
+    			printk("Use different memory range for loader KSEG region if "
+						"hybrid mode needs to be enabled.\n");
+	    	}
+        }else if(xlr_hybrid == XLR_HYBRID_RMIOS_IPSEC){
+            if(((PHNX_RMIOS_IPSEC_START >= phnx_loader_kseg_start) &&
+	    		(PHNX_RMIOS_IPSEC_END< loader_reg)) ||
+	           	  ((phnx_loader_kseg_start >= PHNX_RMIOS_IPSEC_START) &&
+    		   (phnx_loader_kseg_start < PHNX_RMIOS_IPSEC_END)))	{
+	    		xlr_loader_support=0;
+		    	printk("Disabling Loader support as hybrid mode is selected\n");
+    			printk("Use different memory range for loader KSEG region if "
+						"hybrid mode needs to be enabled.\n");
+	    	}
+        }else if(xlr_hybrid == XLR_HYBRID_RMIOS_TCPIP_STACK){
+            if(((PHNX_RMIOS_TCPIP_START >= phnx_loader_kseg_start) &&
+			    (PHNX_RMIOS_TCPIP_END< loader_reg)) ||
+    	       	  ((phnx_loader_kseg_start >= PHNX_RMIOS_TCPIP_START) &&
+	    	   (phnx_loader_kseg_start < PHNX_RMIOS_TCPIP_END)))	{
+		    	xlr_loader_support=0;
+			    printk("Disabling Loader support as hybrid mode is selected\n");
+    			printk("Use different memory range for loader KSEG region if "
+						"hybrid mode needs to be enabled.\n");
+	    	}
+        }
+	}
+	return 1;
+}
+
+early_param("xlr_hybrid", xlr_hybrid_setup);
+
+void __init plat_mem_setup(void)
+{
+	extern int panic_timeout;
+  
+	panic_timeout = 5;  
+  
+	_machine_restart   = (void (*)(char *))ptr_linux_exit;
+	_machine_halt      = ptr_linux_exit;
+	pm_power_off = ptr_linux_exit;
+
+	return;
+}  
+
+#define PER_CPU_THREAD_SIZE	(THREAD_SIZE >> 2)
+#define TOTAL_THREAD_SIZE	(PER_CPU_THREAD_SIZE * (NR_CPUS - 1))
+
+/* 
+ * This structure is used for changing sp and gp of secondary CPUs from that
+ * of the bootloader and used until Linux kernel allocates one for them
+*/
+struct xlr_stack_pages {
+    unsigned long stack[(TOTAL_THREAD_SIZE)/sizeof(long)];
+};
+
+struct xlr_stack_pages xlr_stack_pages_temp
+                __attribute__((__section__(".data.init_task"),
+                __aligned__(THREAD_SIZE)));
+
+
+extern void prom_pre_boot_secondary_cpus(void *);
+
+#define BOOT_LOADER_REGION_SZ 0x04000000
+#define LOADER_KSEG_END 0x10000000
+
+/* 
+ * arg -> arg passed by user
+ * name - pointer to the start of name=value string
+ * base - conversion base 
+ * res - converted number is stored here 
+ * NOTE: returned value is a 32 bit number always
+ * Returns 0 on success, -1 otherwise
+*/
+static int get_name_value(char *arg, char *name, int base, uint32_t *res)
+{
+	char *ptr;
+
+	if((ptr = strstr(arg, name)) == NULL)
+		return -1;
+
+	ptr = strrchr(ptr, '=');
+	dprintk("ptr after strrchr = %s\n", ptr);
+	ptr++;
+	*res = (uint32_t)simple_strtol(ptr, (char **)NULL, base);
+	return 0;
+
+}
+
+struct phnx_name_value_struct {
+	char *name;
+	uint32_t *val;
+};
+
+static struct phnx_name_value_struct phnx_name_value_args[] = {
+	{"linux_cpu_mask=", &xlr_linux_cpu_mask },
+	{"kseg0_start=", &phnx_loader_kseg_start}, 
+	{"kseg0_size=", &phnx_loader_kseg_size},
+	{"app_sh_mem_sz=", &phnx_app_sh_mem_sz},
+	{NULL, NULL}
+};
+
+void parse_kuseg_mem_args(char *p)
+{
+	static int count = 0;
+	uint64_t start = 0, size= 0;
+
+	if ( count == MAX_NUM_KUSEG_BLOCKS ) {
+		printk("The maximun number of kuseg block that can be allocated is %d"
+				"so ignoring this %s\n",MAX_NUM_KUSEG_BLOCKS,p);
+		return;
+	}
+	p = p + strlen("kumem=");
+	size = memparse(p, &p);
+
+	if ( (size == 0) || ((size & (((uint64_t)2 << 20) - 1)) == (1 << 20 ) ))
+		return;
+
+
+	kuseg_mem_map[count].size = size;
+
+	if (*p == '@'){
+		start = memparse(p + 1, &p);
+		
+		/* start Addr should be the multiple of 2M */
+		if (((size & (((uint64_t)2 << 20) - 1)) == (1 << 20 ) ) ) 
+			return;
+	}
+	
+	kuseg_mem_map[count].start_addr = start;
+        count++;
+
+
+}
+void prom_parse_args(int argc, char *argv[]) 
+{
+	int i, j;
+	int ret;
+    char *tmp = NULL;
+
+	/* Check if loader support needs to be enabled */
+	for(i=1;i<argc;i++) {
+		if (argv && argv[i]) {
+			if(strcmp(argv[i], "xlr_loader") == 0){
+				xlr_loader_support = 1;
+				printk("Enabling XLR Linux Loader support\n");
+			}else if(strcmp(argv[i], "shared_core") == 0) {
+				xlr_loader_sharedcore = 1;
+				printk("Linux and RMIOS applications can run"
+						"on same core\n");
+			}else if(strstr(argv[i],"kumem=") != NULL){
+				parse_kuseg_mem_args(argv[i]);
+			}else if(strcmp(argv[i],"console=/dev/pci_co0") == 0){
+				xlr_console_pci_con_dev = 1;
+			}else if(strcmp(argv[i],"console=pci_co,38400") == 0){
+				xlr_console_pci_con_baud = 1;
+			}
+			else if(strcmp(argv[i],"root=/dev/nfs") == 0){
+				xlr_boot_over_nfs = 1;
+			}else if(strcmp(argv[i], "own_gmac") == 0) {
+				xlr_loader_own_gmac = 1;
+				printk("Linux will own gmac ports\n");	
+			}else if(strncmp(argv[i],"xlr_hybrid=",strlen("xlr_hybrid=")) == 0){
+                /*
+				 * Will parse this after loader arguments are parsed, as this
+                 * has memory dependency on loader
+				*/
+                tmp = argv[i]+strlen("xlr_hybrid=");
+            }else{
+				j=0;
+				while(phnx_name_value_args[j].name != NULL) {
+					ret = get_name_value(argv[i],
+											phnx_name_value_args[j].name,
+											16, phnx_name_value_args[j].val);
+					if(ret == 0)
+						break;
+					j++;
+				}
+			}
+		}
+	}
+    if(tmp){
+        xlr_early_hybrid_setup(tmp);
+    }
+}
+
+void check_cpu_mask(void) 
+{
+	uint32_t tmask,i;
+
+	if(!xlr_linux_cpu_mask)
+		xlr_linux_cpu_mask = 0x1;
+	
+	/* trim to what is available */
+	xlr_linux_cpu_mask &= prom_info->cpu_online_map;
+
+	/* Exclude CPUs that boot linux from the loader CPU mask */
+	phnx_loader_mask = ~xlr_linux_cpu_mask;
+	phnx_loader_mask &= prom_info->cpu_online_map;
+
+	/* 
+	 * Loader should not run on the same core, unless "sharedcore" option
+	 * is enabled 
+	*/
+	if(xlr_loader_sharedcore == 0) {
+		tmask = 0xf;
+		for(i=0; i < 8; i++) {
+			if(tmask & xlr_linux_cpu_mask)
+				phnx_loader_mask &= ~tmask;
+			tmask = tmask << 4;
+		}
+	}
+
+	if(phnx_loader_mask == 0){
+		xlr_loader_support = 0;
+		printk("Disabling loader support as loader mask is 0\n");
+		return;
+	}
+
+	printk("Using 0x%08x as linux cpu mask\n", xlr_linux_cpu_mask);
+	printk("Using 0x%08x as loader cpu mask\n", phnx_loader_mask);
+}
+
+#define LOADER_KSEG_DEFAULTS phnx_loader_kseg_start = PHNX_LOADER_KSEG0_START;\
+				phnx_loader_kseg_size = PHNX_LOADER_KSEG0_SIZE;
+
+extern char _end;
+
+void check_kseg_args(void)
+{
+	if((phnx_loader_kseg_start == 0) ||(phnx_loader_kseg_size == 0)) {
+		LOADER_KSEG_DEFAULTS;
+		printk("No KSEG args passed. Using defaults\n");
+		return;
+	}
+
+	dprintk("Checking kseg start %x with _end %p\n", phnx_loader_kseg_start,
+			&_end);
+
+	if(((phnx_loader_kseg_start | CKSEG0) < (unsigned long)&_end) || 
+		(phnx_loader_kseg_start >= LOADER_KSEG_END)) {
+		printk("Invalid KSEG args passed. Using defaults\n");
+		printk("Start cannot overlap with image or bootloader region\n");
+		LOADER_KSEG_DEFAULTS;
+		return;
+	}
+
+	if(phnx_loader_kseg_start & ((2 << 20) - 1)) {
+		/* Start not aligned at 2MB boundry */
+		printk("Invalid KSEG args passed. Using defaults\n");
+		printk("Start address not aligned at 2MB boundry\n");
+		LOADER_KSEG_DEFAULTS;
+		return;
+	}
+
+	if((phnx_loader_kseg_start + phnx_loader_kseg_size) > 
+					LOADER_KSEG_END) {
+		printk("Invalid KSEG args passed. Using defaults\n");
+		printk("Bootloader region cannot be used\n");
+		LOADER_KSEG_DEFAULTS;
+		return;
+	}
+
+	printk("Using 0x%08x as KSEG0 load start and 0x%08x as size\n",
+			phnx_loader_kseg_start, phnx_loader_kseg_size);
+
+}
+
+#define LOADER_KUSEG_DEFAULTS		\
+	memset (kuseg_mem_map, 0, (sizeof(struct kuseg_mem_info) * 4));		\
+	kuseg_mem_map[0].start_addr = PHNX_LOADER_KUSEG_PHYS_START;			\
+	kuseg_mem_map[0].size = PHNX_LOADER_KUSEG_PHYS_SIZE;
+
+void check_kuseg_args(struct boot_mem_map *map)
+{
+	int i,j;
+	uint64_t end1, end2;
+
+	for (j = 0; j < MAX_NUM_KUSEG_BLOCKS; j++) {
+		/* if size is 0 ignore the entry */
+		if (kuseg_mem_map[j].size == 0)
+			continue;
+
+		if (kuseg_mem_map[j].start_addr < (512 << 20)) { 
+			/* cannot be < 512MB */
+			printk("Kuseg start should be > 512MB. Using defaults for start "
+					"addr %lx\n",kuseg_mem_map[j].start_addr);
+			LOADER_KUSEG_DEFAULTS;
+			return;
+		}
+
+		end1 = kuseg_mem_map[j].start_addr + kuseg_mem_map[j].size;
+
+		for(i=0; i < map->nr_map; i++) {
+			if(map->map[i].type != BOOT_MEM_RAM) continue;
+			end2 = map->map[i].addr +  map->map[i].size;
+			if(( kuseg_mem_map[j].start_addr >= map->map[i].addr) &&
+			(end1 <= end2)) break;
+		}
+
+		if(i == map->nr_map) {
+			printk("Invalid KUSEG range passed. Using defaults\n");
+			LOADER_KUSEG_DEFAULTS;
+			return;
+		}
+
+		printk("Using 0x%llx as KUSEG start and 0x%llx as KUSEG size\n",
+			(unsigned long long)kuseg_mem_map[j].start_addr,
+			(unsigned long long)kuseg_mem_map[j].size);
+	}
+	/* if no input is given , then use the default */
+	if ( kuseg_mem_map[0].start_addr == 0 )	{
+		LOADER_KUSEG_DEFAULTS;
+	}
+}
+
+uint32_t align_shared_mem(uint32_t shared_mem)
+{
+	if(shared_mem < (2<<20))
+		return (2<<20);
+	if(shared_mem < (8 << 20))
+		return (8<<20);
+	if(shared_mem < (32 << 20))
+		return (32<<20);
+	if(shared_mem < (128 << 20))
+		return (128<<20);
+	if(shared_mem < (512 << 20))
+		return (512<<20);
+	return (2<<20);
+}
+
+void prom_validate_shmem_size(void)
+{
+	int i = 0;
+	uint32_t new_shared_mem_size = 0;
+
+	if(phnx_app_sh_mem_sz > PHNX_APP_SHMEM_MAX_SZ) {
+		printk("phnx_loader: RMIOS-APP shared memory size cannot be\n"
+				" more than 0x%08x\n", PHNX_APP_SHMEM_MAX_SZ);
+		phnx_app_sh_mem_sz = 2*1024*1024;
+	}
+
+	new_shared_mem_size = align_shared_mem(phnx_app_sh_mem_sz);
+
+	if(new_shared_mem_size != phnx_app_sh_mem_sz){
+		printk("phnx_loader:Can not fit shared memory in single tlb\n");
+		printk("phnx_loader:Using aligned shared memory %#x\n",
+			new_shared_mem_size);
+		phnx_app_sh_mem_sz = new_shared_mem_size;
+	}
+	
+	for(i=0; i<MAX_NUM_KUSEG_BLOCKS; i++){
+		if(phnx_app_sh_mem_sz <= kuseg_mem_map[i].size)
+			break;
+	}
+
+	if(i == MAX_NUM_KUSEG_BLOCKS){
+		printk("phnx_loader: Can not reserve %x size shared memory\n"
+			"  from available kuseg memory\n",phnx_app_sh_mem_sz);
+		phnx_app_sh_mem_sz = 2*1024*1024;
+		printk("phnx_loader: Defaulting to 2MB\n");
+	}
+
+	printk("phnx_loader: RMIOS-APP shared memory size=0x%08x\n",
+			phnx_app_sh_mem_sz);
+}
+
+void prom_validate_loader_args(struct boot_mem_map *map)
+{
+	if(!xlr_loader_support) 
+		return;
+
+	if (xlr_loader_own_gmac && (!xlr_board_atx_ii()|| is_xls())) {
+		printk("own_gmac option is valid only on ATX II XLR boards."
+			   " Ignoring option.\n");
+		xlr_loader_own_gmac = 0;
+	}
+
+	check_cpu_mask();
+	check_kseg_args();
+	check_kuseg_args(map);
+}
+
+/* 
+ * The below regions should be in ascending order of the starting physical
+ * addresses
+*/
+static struct boot_mem_map_exclude_region 
+				_exclude_regions[2][MAX_EXCLUDE + 2];
+
+static struct boot_mem_map_exclude_region *
+				exclude_regions = _exclude_regions[1];
+
+#ifdef CONFIG_BTLB_LOADER
+#include <linux/btlb.h>
+static struct boot_mem_map_exclude_region static_exclude_regions[] = {
+    [0] = { PHNX_USER_MAC_MMAP_PHYS_START, PHNX_USER_MAC_MMAP_PHYS_END},
+    [1] = {0, 0}, /* END of the list - MUST be the last entry always */
+};
+struct boot_mem_map_exclude_region btlb_mem_map[(MAX_EXCLUDE << 2) + 1];
+#else
+static struct boot_mem_map_exclude_region static_exclude_regions[] = {
+	[0] = { PHNX_USER_MAC_MMAP_PHYS_START, PHNX_USER_MAC_MMAP_PHYS_END},
+	[1] = {0, 0}, /* END of the list - MUST be the last entry always */
+};
+#endif
+
+static __inline__ uint64_t load_c0_scratch0(void)
+{
+  __u32 high, low;
+  __asm__ __volatile__ (
+	    ".set push\n"
+        ".set noreorder\n"
+		".set noat\n"
+        ".set mips64\n" 
+		"dmfc0 $1, $22, 0 \n\t"
+		"nop			\n\t"
+		"dsra32 %0, $1, 0  \n\t"
+		"sll    %1, $1, 0  \n\t"
+		".set pop\n"
+		: "=r" (high), "=r" (low)
+		);
+
+  return ( ((__u64)high) << 32) | low;
+}		
+
+void prom_exclude_kseg(void)
+{
+   	dynamic_exclude_regions[dyna_exc_index].start = (unsigned long long)
+    					1<<20;
+   	dynamic_exclude_regions[dyna_exc_index].end = (unsigned long long)
+                (((unsigned long)&_text) & 0x1fffffffUL);
+   	dyna_exc_index++;
+
+	dynamic_exclude_regions[dyna_exc_index].start = (unsigned long long)
+						phnx_loader_kseg_start;
+	dynamic_exclude_regions[dyna_exc_index].end = (unsigned long long)
+			(phnx_loader_kseg_start + phnx_loader_kseg_size);
+	dyna_exc_index++;
+}
+
+void sort_kuseg_region(void)
+{
+	int i,j;
+	uint64_t temp_addr;
+	uint64_t temp_size;
+
+	for (i = 1; i < 4; i++) {
+		for (j = 0; j < i; j++){
+			if (kuseg_mem_map[i].start_addr <  kuseg_mem_map[j].start_addr){
+				temp_addr = kuseg_mem_map[j].start_addr;
+				temp_size = kuseg_mem_map[j].size;
+				kuseg_mem_map[j].start_addr = kuseg_mem_map[i].start_addr;
+				kuseg_mem_map[j].size = kuseg_mem_map[i].size;
+				kuseg_mem_map[i].start_addr = temp_addr;
+				kuseg_mem_map[i].size = temp_size;
+			}
+		}
+	}
+}
+
+void check_kuseg_region_overlap(void)
+{
+	int i,max;
+	uint64_t end1, end2;
+
+	max = MAX_NUM_KUSEG_BLOCKS - 1;
+
+	sort_kuseg_region();
+	for (i = 0 ;i < max; i++) {
+		end1 = kuseg_mem_map[i].start_addr + kuseg_mem_map[i].size;
+		if ((kuseg_mem_map[i+1].start_addr <= end1) 
+			&& (kuseg_mem_map[i].start_addr != 0)) {
+			end2 = kuseg_mem_map[i+1].start_addr + kuseg_mem_map[i+1].size;
+			if (end2 > end1)
+				kuseg_mem_map[i].size = end2 - kuseg_mem_map[i].start_addr;
+			kuseg_mem_map[i+1].start_addr = 0;
+			kuseg_mem_map[i+1].size = 0;
+			sort_kuseg_region();
+		}
+	}
+}
+
+void prom_exclude_kuseg(void)
+{
+	int i = 0;
+	check_kuseg_region_overlap();
+
+	for (i = 0 ; i < MAX_NUM_KUSEG_BLOCKS ; i++) {
+		if ((kuseg_mem_map[i].start_addr != 0) && (kuseg_mem_map[i].size != 0)){
+			dynamic_exclude_regions[dyna_exc_index].start 
+				= kuseg_mem_map[i].start_addr;
+			dynamic_exclude_regions[dyna_exc_index].end 
+				= kuseg_mem_map[i].start_addr + kuseg_mem_map[i].size;
+			dyna_exc_index++;
+		}
+	}
+}
+
+void prom_exclude_pci_shmem(void)
+{
+	dynamic_exclude_regions[dyna_exc_index].start =
+				 PHNX_PCIX_SHARED_MEM_START;
+	dynamic_exclude_regions[dyna_exc_index].end = PHNX_PCIX_SHARED_MEM_END; 
+	dyna_exc_index++;
+	printk("Excluding PCI Shared Memory\n");
+}
+
+void sort_dynamic_exclude_region(void)
+{
+    int i=0;
+    int j=0;
+    int max=0;
+    struct boot_mem_map_exclude_region *list = dynamic_exclude_regions;
+
+    uint64_t start = 0;
+	uint64_t end = 0;
+
+    while (list[max].start != 0)
+        max++;
+
+    for(i = 0; i < max; i++){
+        for(j = i; j < max; j++){
+            if (list[i].start > list[j].start){
+               start = list[i].start;
+               end = list[i].end;
+               list[i].start = list[j].start;
+               list[i].end = list[j].end;
+               list[j].start = start;
+               list[j].end = end;
+            }
+        }
+    }
+}
+
+static int merge_exclude_regions(struct boot_mem_map_exclude_region *,
+                                 struct boot_mem_map_exclude_region *);
+
+void prom_update_exclude_region(void)
+{
+	int i;
+
+#ifdef CONFIG_PHOENIX_PCIX_GEN_DRIVER
+	if(xlr_get_pci_mode() == XLR_PCI_DEV_MODE){
+		prom_exclude_pci_shmem();
+	}
+#endif
+
+	if (xlr_loader_support) {
+		prom_exclude_kseg();
+		prom_exclude_kuseg();
+	}
+    
+	sort_dynamic_exclude_region();
+	
+    exclude_regions = _exclude_regions[0];
+	
+    /*
+     * we assume that all exclude regions are sorted
+     * to start with.
+    */
+    merge_exclude_regions(exclude_regions, static_exclude_regions);
+    merge_exclude_regions(exclude_regions, dynamic_exclude_regions);
+
+#ifdef CONFIG_BTLB_LOADER
+    merge_exclude_regions(exclude_regions, btlb_mem_map);
+#endif
+	
+	dprintk("Final exclude regions ----->\n");
+	for (i = 0; exclude_regions[i].start; i++) {
+		dprintk("%d: Start 0x%llx End 0x%llx\n", i, 
+				exclude_regions[i].start,
+				exclude_regions[i].end);
+	}
+}
+
+#define TRUE 1
+#define FALSE 0
+
+struct boot_mem_map prom_map;
+int use_default_phymem = FALSE;
+
+void read_prom_memory(void)
+{
+	struct boot_mem_map *map;
+
+    /* sanity check prom_info and it's mem_map fields */
+	if (!prom_info || (!prom_info->psb_mem_map && !prom_info->avail_mem_map)) 
+        goto use_default;
+
+	/* copy the mem_map from bootloader */
+    if (sizeof(*prom_info) <= prom_info->size && prom_info->avail_mem_map)
+		map = (struct boot_mem_map *)((unsigned long)prom_info->avail_mem_map);
+	else
+		map = (struct boot_mem_map *)((unsigned long)prom_info->psb_mem_map);
+	
+	if (!(map->nr_map > 0 && map->nr_map <= 32))
+		goto use_default;
+	memcpy(&prom_map, map, sizeof(struct boot_mem_map));
+	
+	return;
+
+use_default:
+	use_default_phymem = TRUE;
+	return;
+}
+
+#define DEF_PHYMEM_START_ADDR 0x100000
+#define DEF_PHYMEM_SIZE 0x0ff00000
+
+static void prom_add_memory(void)
+{
+	int i = 0, j = 0;
+	__u64 start = 0, end = 0, exc_start = 0, exc_end = 0;
+
+	if (use_default_phymem)
+		goto use_default;
+
+	prom_validate_loader_args(&prom_map);
+	
+	prom_update_exclude_region();
+	
+	/* 
+	 * TODO: Need to remove this brain damaged hack. The bootloader passed 
+	 * memory map should indicate the bootloader memory as available.
+	*/
+	if (prom_map.map[0].size == 0x0c000000)
+		prom_map.map[0].size = 0x0ff00000;
+	
+	for (i = 0; i < prom_map.nr_map; i++) {
+		start = prom_map.map[i].addr;
+		end = prom_map.map[i].addr + prom_map.map[i].size;
+
+		for (j = 0; j < MAX_EXCLUDE; j++) {
+			exc_start = exclude_regions[j].start;
+			exc_end = exclude_regions[j].end;
+			
+			if ((exc_start == 0) && (exc_end == 0)) /* Empty slot */
+				continue;
+
+			if (exc_start >= start && exc_start < end) {
+				if(exc_start == start) { /* Continuous exclude */
+					start = exc_end;
+					continue;
+				}
+				if (prom_map.map[i].type == BOOT_MEM_RAM){
+					add_memory_region(start,
+									  exc_start-start, 
+									  (long)prom_map.map[i].type);
+					start = exc_end;
+				}
+			} 
+			else if ((exc_start < start) && (exc_end > start)) {
+				/* Overlapping excludes */
+				start = exc_end;
+			}
+		}
+		if (start != end)
+			if (prom_map.map[i].type == BOOT_MEM_RAM)
+				add_memory_region(start, end-start, (long)prom_map.map[i].type);
+	}
+	
+	return;
+	
+ use_default:
+	printk("Using default physical memory map\n");
+	add_memory_region (DEF_PHYMEM_START_ADDR, DEF_PHYMEM_SIZE, 
+						(long)BOOT_MEM_RAM); // 255m@1m
+	xlr_loader_support = 0;
+}
+
+static void psb_print_physmap(void)
+{
+	struct boot_mem_map *physaddr_map = 
+		(struct boot_mem_map *)((unsigned long)prom_info->psb_physaddr_map);
+	char *name;
+	int i = 0;
+	int max;
+
+	if(physaddr_map == NULL)
+		return;
+
+	max = physaddr_map->nr_map;
+
+	prom_dbg_msg("Physical Address Map\n");
+	for(i=0 ; i <max ; i++)
+	{
+		name = get_psb_physmap_name(physaddr_map->map[i].type);
+
+		prom_dbg_msg("\t%010llx --> %010llx ( %s )\n",
+			     (unsigned long long)physaddr_map->map[i].addr,
+			     (unsigned long long)(physaddr_map->map[i].addr +
+                                      physaddr_map->map[i].size -1),
+			     name);
+	}
+
+}
+
+static void save_physaddr_info(void)
+{
+  struct boot_mem_map *physaddr_map = 
+    (struct boot_mem_map *)((unsigned long)prom_info->psb_physaddr_map);
+
+	if(physaddr_map == NULL)
+		return;
+
+	memcpy(&boot_physaddr_info,  physaddr_map, sizeof(struct boot_mem_map));
+	return;
+}
+
+#define RMIK_ARGS_OFFSET 8
+void rmik_init(char *g_argv[], int *argc, char *g_envp[])
+{
+	int i;
+	char *strarea;
+	int g_argc = 0;
+	uint64_t *bootargs;
+
+	bootargs = (uint64_t *)(unsigned long)load_c0_scratch0();
+	if(bootargs == NULL) 
+		return;
+
+ 	if(bootargs[-1] != RMI_RMIK_MAGIC)
+		return;
+
+	rmi_kernel_args = bootargs - RMIK_ARGS_OFFSET;
+	rmi_dom = (void *) (long) rmi_kernel_args[0];
+	strarea = (char *) (long) rmi_kernel_args[1];
+	
+	/* create argv array, don't copy args as it is in domain mem */
+	while (1) {
+		if (*strarea == '\0')
+			break;
+		if (g_argc != RMI_MAX_ARGS)
+			g_argv[g_argc++] = strarea;	
+
+		while(*strarea++);
+	}
+	if (g_argc == RMI_MAX_ARGS)
+		printk("*** Too many args ***, only %d used\n", g_argc);
+	g_argv[g_argc]  = NULL;
+
+	i = 0;
+	while (1) {
+		if (*strarea == '\0')
+			break;
+		if (i != RMI_MAX_ENVS) 
+			g_argv[i++] = strarea;	
+		while(*strarea++);
+	}
+	if (i == RMI_MAX_ENVS) 
+		printk("*** Too many envs ***, only %d used\n", i);
+	g_envp[i]  = NULL;
+
+	*argc = g_argc;
+	rmi_fdt_buf = (char *)(long)rmi_kernel_args[2];
+	rmi_fdt_buf_size = rmi_kernel_args[3];
+	rmi_call_table = (uint32_t *)(long)(rmi_kernel_args[4]);
+	rmi_rmik_entry =  (void (*)(int))(long)(int)rmi_call_table[0];
+	rmi_pcpu_info = (void *)(long)rmi_kernel_args[5];
+
+	dev_tree_en = 1;
+
+	if(fdt_init(rmi_fdt_buf, rmi_fdt_buf + rmi_fdt_buf_size) != 0x0)
+            panic("Fdt init failed \n"); 
+
+	return;
+}
+
+extern struct plat_smp_ops phoenix_smp_ops;
+
+/*
+ * prom_init is called just after the cpu type is determined, from setup_arch()
+*/
+void __init prom_init(void)
+{
+	int i=0;
+	int argc = (int)fw_arg0;
+    long temp ;
+	char **argv;
+    char **envp;
+    int t_argc = argc;
+    char *n_argv[RMI_MAX_ARGS] = {NULL};
+    char *n_envp[RMI_MAX_ENVS] = {NULL};
+    struct psb_info *t_prom_info;
+
+	void (*wakeup)(void *, void *, __u32);
+	__u32 wakeup_mask;
+
+    temp = (int)fw_arg1;
+    argv = (char **)temp;
+
+    temp = (int)fw_arg2;
+    envp = (char **)temp;
+
+	xlr_initialize_setups();
+
+	/* initialise from rmi-kernel if booted with */
+	rmik_init(n_argv, &argc, n_envp);
+
+	/* default mac addr */
+	phoenix_base_mac_addr[0] = 0x00;
+	phoenix_base_mac_addr[1] = 0x01;
+	phoenix_base_mac_addr[2] = 0x02;
+	phoenix_base_mac_addr[3] = 0x03;
+	phoenix_base_mac_addr[4] = 0x04;
+	phoenix_base_mac_addr[5] = 0x05;
+
+	phoenix_psb_shm = 0;
+  
+	if(dev_tree_en) {
+		prom_info = &prom_info_copy;
+	} else {
+	    temp = (int)fw_arg3;
+    	prom_info = &prom_info_copy;
+		t_prom_info = (struct psb_info *)temp;
+	    memcpy((void *)prom_info, (void *)t_prom_info, sizeof(struct psb_info));
+	}
+
+#ifdef RMI_BRIDGE_WKAROUND
+	if(prom_info->global_shmem_size == GLOBAL_SHMEM_SIZE) {
+		rmi_bridge_lock = 
+		(rmi_rwlock_t *)(unsigned long)
+		(prom_info->global_shmem_addr + BRIDGE_WKAROUND_AREA_OFFSET);
+		rmi_enable_br_wrkaround = 1;
+		printk("Enabling Bridge Workaround \n");
+	}
+#endif
+	 /* set the prom_info  */
+    fdt_fill_prom_info(prom_info);
+
+	if(!dev_tree_en)
+	{
+		/* Get the right 64bit pointers from bootloader args */
+        int32_t *t_argv;
+
+        t_argv = (int32_t *)argv;
+        for(i=0; i < t_argc; i++, t_argv++) {
+            n_argv[i] = (char *)(unsigned long)(*t_argv);
+        }
+		argc = t_argc;
+
+		/* Get the right env pointers */
+		if(envp != NULL)
+		{
+			int32_t *t_envp;
+			t_envp = (int32_t *)envp;
+			for(i=0; *t_envp; i++) {
+				n_envp[i] = (char *)(unsigned long)(*t_envp);
+				t_envp++;
+			}
+		}
+	} /* devtree en */
+
+	if (!dev_tree_en && !sanity_check_prom_info(prom_info)) {
+		printk("Sanity Check failed on prom_info @ %p\n", prom_info);
+		if (prom_info) {
+			printk("sizeof(psb_info) = %d, psb_info_version = %x, "
+			       "prom_info->magic_dword = %llx, prom_info->size = %llx\n", 
+			       (unsigned int)sizeof(struct psb_info), PSB_INFO_VERSION, 
+			       (unsigned long long)prom_info->magic_dword, 
+                   (unsigned long long)prom_info->size);
+		}
+		prom_info = &default_prom_info;
+		goto parse_args;
+	}
+
+	/*Copy Environment variable*/
+	if(prom_info->bldr_envp)
+		memcpy(&xlr_bldr_env,
+			(void *)(unsigned long)prom_info->bldr_envp,
+			sizeof(xlr_bldr_env));
+
+
+	xlr_board_major_version = prom_info->board_major_version;
+	xlr_board_minor_version = prom_info->board_minor_version;
+	prom_parse_args(argc, n_argv);
+
+	/* 
+	 * This call should be after prom_parse args , should not change
+     * the positions 
+	*/
+    fdt_parse_args();
+
+	read_prom_memory(); /* btlb_mem_init() needs this. Do not move it */
+
+#ifdef CONFIG_BTLB_LOADER      
+       btlb_mem_init(argc, n_argv);
+#endif
+	
+	phnx_ebase = read_c0_ebase() & (~((1 << 12) - 1));	
+
+	psb_print_physmap();
+
+	save_physaddr_info();
+
+	prom_add_memory();
+
+	if(xlr_loader_support){
+		/*validate phnx_app_sh_mem_sz*/
+		prom_validate_shmem_size();
+		if (xlr_loader_sharedcore && 
+				(xlr_board_atx_iii() || xlr_board_atx_v())) {
+			xlr_loader_own_dma = 1;
+		}
+		prom_init_xlr_loader_setup(prom_info);
+	}
+	/* update the phoenix mac addr */
+	phoenix_base_mac_addr[0] = (prom_info->mac_addr >> 40) & 0xff;
+	phoenix_base_mac_addr[1] = (prom_info->mac_addr >> 32) & 0xff;
+	phoenix_base_mac_addr[2] = (prom_info->mac_addr >> 24) & 0xff;
+	phoenix_base_mac_addr[3] = (prom_info->mac_addr >> 16) & 0xff;
+	phoenix_base_mac_addr[4] = (prom_info->mac_addr >> 8) & 0xff;
+	phoenix_base_mac_addr[5] = (prom_info->mac_addr >> 0) & 0xff;
+
+	/* 
+	 * Pull all the cpus out of the bootloader and force them to spin in 
+	 * prom_pre_boot_secondary_cpus
+	*/
+	if(!dev_tree_en)
+		wakeup = ((void (*)(void *, void *, __u32))
+					(unsigned long)(prom_info->wakeup));
+	else {
+		wakeup = ((void (*)(void *, void *, __u32))
+					(unsigned long)(&rmik_wakeup_cpus));
+	}
+
+	smp_boot.online_map = (1 << hard_smp_processor_id());
+
+	if(xlr_loader_support) {
+		wakeup_mask = xlr_linux_cpu_mask | phnx_loader_mask;
+		if(wakeup != 0x0)
+		wakeup(prom_pre_boot_secondary_cpus, 0, wakeup_mask);
+	} else {
+		if(wakeup != 0x0)
+			wakeup(prom_pre_boot_secondary_cpus, 0, 
+					(__u32)prom_info->cpu_online_map & (~smp_boot.online_map));
+	}
+
+	if(!dev_tree_en) {
+		/* MOD */
+		phoenix_psb_shm = (void *)CKSEG0 + PHNX_USER_MAC_MMAP_PHYS_START;
+		phoenix_psb_shm_size = PHNX_USER_MAC_MMAP_PHYS_END 
+								- PHNX_USER_MAC_MMAP_PHYS_START;
+	} else {
+		phoenix_psb_shm = rmi_get_usermac_addr(usermac_mmap_size);
+		phoenix_psb_shm_size = usermac_mmap_size;
+	}
+
+ parse_args:
+
+	for(i=1;i<argc;i++) {
+		if (n_argv[i]) {
+			strcat(arcs_cmdline, n_argv[i]);
+			strcat(arcs_cmdline, " ");
+		}
+		else {
+			prom_dbg_msg("bad args, i=%d\n", i);
+		}
+	}
+	strcat(arcs_cmdline, " ");
+
+#ifdef CONFIG_PHOENIX_CONSOLE_OVER_PCI
+	if(!(xlr_board_atx_iii() || xlr_board_atx_v()) || 
+           !(xlr_console_pci_con_baud && 
+	   xlr_console_pci_con_dev))
+		strcat(arcs_cmdline, DEFAULT_CONSOLE_BOOT_PARAMS);
+#else
+	strcat(arcs_cmdline, DEFAULT_CONSOLE_BOOT_PARAMS);
+#endif
+	strcat(arcs_cmdline, " ");
+
+#ifdef CONFIG_ROOT_NFS
+	if(!xlr_boot_over_nfs)
+		strcat(arcs_cmdline, DEFAULT_INITRD_BOOT_PARAMS);
+#else
+	strcat(arcs_cmdline, DEFAULT_INITRD_BOOT_PARAMS);
+#endif
+	strcat(arcs_cmdline, " ");
+
+	for(i=0; n_envp[i];i++) {
+		if (strcmp(n_envp[i], "") == 0) break;
+	}
+
+#ifdef DEBUG
+	printk("MAC ADDR BASE: %02x:%02x:%02x:%02x:%02x:%02x\n",
+	       phoenix_base_mac_addr[0], phoenix_base_mac_addr[1],
+		   phoenix_base_mac_addr[2], phoenix_base_mac_addr[3],
+		   phoenix_base_mac_addr[4], phoenix_base_mac_addr[5]);
+#endif
+	on_chip_init();
+	prom_reconfigure_thr_resources();
+	register_smp_ops(&phoenix_smp_ops);
+}
+
+void prom_free_prom_memory(void)
+{
+	/* nothing to free */
+}
+
+void read_cp0_regs(void)
+{
+	printk("[%s]: count = 0x%x, compare = 0x%x\n"
+	       "status = 0x%x, cause = 0x%x\n"
+	       "eimr = 0x%llx, eirr = 0x%llx\n",
+	       __func__, 
+	       read_c0_count(),
+	       read_c0_compare(),
+	       read_c0_status(),
+	       read_c0_cause(),
+	       (unsigned long long)read_64bit_cp0_eimr(),
+	       (unsigned long long)read_64bit_cp0_eirr()
+		);
+}
+
+static struct plat_serial8250_port uart8250_data[] = {
+	{
+		.membase	= (void __iomem *)(DEFAULT_PHOENIX_IO_BASE +
+				  PHOENIX_IO_UART_0_OFFSET),
+		.irq		= PIC_UART_0_IRQ,
+		.uartclk	= 66000000,
+		.iotype		= UPIO_AU,
+		.flags		= UPF_BOOT_AUTOCONF | UPF_SKIP_TEST,
+		.regshift	= 2,
+	},
+	{
+		.membase	= (void __iomem *)(DEFAULT_PHOENIX_IO_BASE +
+				  PHOENIX_IO_UART_1_OFFSET),
+		.irq		= PIC_UART_1_IRQ,
+		.uartclk	= 66000000,
+		.iotype		= UPIO_AU,
+		.flags		= UPF_BOOT_AUTOCONF | UPF_SKIP_TEST,
+		.regshift	= 2,
+	},
+	{ },
+};
+
+static struct platform_device uart8250_device = {
+	.name			= "serial8250",
+	.id			= PLAT8250_DEV_PLATFORM,
+	.dev			= {
+		.platform_data	= uart8250_data,
+	},
+};
+
+static int __init uart8250_init(void)
+{
+	return platform_device_register(&uart8250_device);
+}
+module_init(uart8250_init);
+
+struct boot_mem_map_entry *psb_get_physaddr_base_address(unsigned long type)
+{
+	struct boot_mem_map *physaddr_map = 
+		(struct boot_mem_map *)((unsigned long)prom_info->psb_physaddr_map);
+
+	int i = 0;
+	int max = physaddr_map->nr_map;
+
+	for(i=0 ; i <max ; i++)
+	{
+		if (physaddr_map->map[i].type == type)
+			return (physaddr_map->map);
+	}
+	return NULL;
+}
+
+#ifdef CONFIG_BTLB_LOADER
+int btlb_mem_init(int argc, char **argv)
+{
+	uint64_t addr = 0, size = 0;
+	char *cptr, *rptr;
+	int i = 0, nmap = 0;
+
+	for ( ; *argv; ++argv) {
+		if (strstr(*argv, "btlb_mem=") == *argv) {
+			cptr = *argv + strlen("btlb_mem=");
+			if (!cptr)
+				continue;
+			size = simple_strtoll(cptr, &rptr, 0);
+			if (size == 0 && rptr == cptr)
+				continue;
+			if ((*rptr != '@') || !(++rptr))
+				continue;
+			addr = simple_strtoll(rptr, &cptr, 0);
+			if (addr == 0 && rptr == cptr)
+				continue;
+
+			/*
+			 * check that the specified btlb area falls
+			 * within physical memory regions, as opposed
+			 * to some IO space or other regions. Also
+			 * check that the current region does not
+			 * overlap previously specified btlb regions
+			 * 
+			 * We do it crudely using an O(n^2) loop. 'n'
+			 * is a very small number. Usually, between
+			 * 2-4. So, no point in spending time on an
+			 * O(n.logn) loop
+			*/
+			for (i = 0; i < nmap; ++i) {
+				if (((addr << 20) >= btlb_mem_map[nmap].start) &&
+					((addr << 20) < btlb_mem_map[nmap].end))
+					break;
+			}
+
+			if (i < nmap) {
+				printk("\n*** btlb_region [0x%llx - 0x%llx] overlapping with "
+						"another btlb region ***\n",
+						(addr << 20), (addr + size) << 20);
+				printk("discounting it from btlb memory regions\n\n");
+				continue;
+			}
+
+			for (i = 0; i < prom_map.nr_map; i++)
+				if (prom_map.map[i].type == BOOT_MEM_RAM
+					&& ((addr << 20) >= prom_map.map[i].addr) 
+					&& (((addr + size) << 20) <= 
+						(prom_map.map[i].addr + prom_map.map[i].size)))
+					break;
+
+			if (i == prom_map.nr_map) {
+				printk("\n*** btlb_region [0x%llx - 0x%llx] (partly/completely)"
+						" not within DRAM ***\n",
+						(addr << 20), (addr + size) << 20);
+				printk("*** run print_physmap on the bootloader shell/prompt "
+						"for available memory regions ***\n\n");
+				continue;
+			}
+
+			btlb_mem_map[nmap].start = (addr << 20);
+			btlb_mem_map[nmap].end = ((addr + size) << 20);
+			++nmap;
+		}
+	}
+
+	if (nmap == 0) {
+		printk("Using Default BTLB Memory Region: 0x%llx - 0x%llx\n",
+			   BTLB_PADDR_START, BTLB_PADDR_END);
+
+		for (i = 0; i < prom_map.nr_map; i++)
+			if (prom_map.map[i].type == BOOT_MEM_RAM
+				&& (BTLB_PADDR_START >= prom_map.map[i].addr) 
+				&& (BTLB_PADDR_END <= 
+					(prom_map.map[i].addr + prom_map.map[i].size)))
+				break;
+		
+		if (i == prom_map.nr_map) {
+			printk("\n*** btlb_region [0x%llx - 0x%llx] (partly/completely) "
+					"not within DRAM ***\n",
+					(addr << 20), (addr + size) << 20);
+			printk("*** run print_physmap on the bootloader shell/prompt for "
+					"available memory regions ***\n\n");
+			btlb_memory_error = 1;
+		}
+		else {
+			btlb_mem_map[nmap].start = BTLB_PADDR_START;
+			btlb_mem_map[nmap].end = BTLB_PADDR_END;
+			++nmap;
+		}
+	}
+
+	if (nmap > 0) {
+		printk("Big TLB Memory Regions\n");
+		for (i = 0; i < nmap; ++i)
+			printk("Start: 0x%llx, End: 0x%llx\n", 
+					(unsigned long long) btlb_mem_map[i].start,
+					(unsigned long long) btlb_mem_map[i].end);
+	}
+
+	return 0;
+}
+#endif
+
+void static add_region(struct boot_mem_map_exclude_region *x, int *k,
+					   uint64_t start, uint64_t end)
+{
+	if (*k > MAX_EXCLUDE) {
+		printk("No of exclude regions = %d; Cannot add more\n", MAX_EXCLUDE);
+		return;
+	}
+
+	if (start < x[*k-1].end) {
+		return;
+	}
+
+	x[*k].start = start;
+    x[*k].end = end;
+	++*k;
+}
+
+static int merge_exclude_regions(struct boot_mem_map_exclude_region *x,
+								struct boot_mem_map_exclude_region *y)
+{
+	static int _index = 0;
+	int i, j, k;
+
+	i = j = 0;
+	k = 1;
+
+	while (x[i].start != 0 && y[j].start != 0) {
+		if (x[i].start < y[j].start) {
+			add_region(_exclude_regions[_index], &k, x[i].start, x[i].end);
+			++i;
+		}
+		else {
+			add_region(_exclude_regions[_index], &k, y[j].start, y[j].end);
+			++j;
+		}
+	}
+
+	if (x[i].start == 0) {
+		while (y[j].start) {
+			add_region(_exclude_regions[_index], &k, y[j].start, y[j].end);
+			++j;
+		}
+	}
+	else if (y[j].start == 0) {
+		while (x[i].start) {
+			add_region(_exclude_regions[_index], &k, x[i].start, x[i].end);
+			++i;
+		}
+	}
+
+	exclude_regions = &_exclude_regions[_index][1];
+	_index = _index ? 0 : 1;
+
+	return 0;
+}
-- 
1.6.0.4

