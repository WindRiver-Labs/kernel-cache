From b6e4b7558a825645b655db2bf7daa7cc8e2f7855 Mon Sep 17 00:00:00 2001
From: Tony Liu <Bo.Liu@windriver.com>
Date: Tue, 30 Mar 2010 17:28:49 +0800
Subject: [PATCH 13/13] lsi_app: add ethernet support

The ethernet solution of APP3300 MSBG is consisting of on-chip RMII +
ethernel Fast Ethernet PHY MICREL ksz8271bl. Merge the implementation
from vendor drop -- Agere APP Linux Version 2.6.1.5.pre10 05/07/2009.

Signed-off-by: Tonyliu <Bo.Liu@windriver.com>
---
 arch/arm/mach-app/mach-app3k.c |   28 +
 drivers/net/arm/Kconfig        |   39 +
 drivers/net/arm/Makefile       |    1 +
 drivers/net/arm/appnic.c       | 2037 ++++++++++++++++++++++++++++++++++++++++
 drivers/net/arm/appnic.h       |  626 ++++++++++++
 5 files changed, 2731 insertions(+), 0 deletions(-)
 create mode 100644 drivers/net/arm/appnic.c
 create mode 100644 drivers/net/arm/appnic.h

diff --git a/arch/arm/mach-app/mach-app3k.c b/arch/arm/mach-app/mach-app3k.c
index f13c31d..2ed0b5d 100644
--- a/arch/arm/mach-app/mach-app3k.c
+++ b/arch/arm/mach-app/mach-app3k.c
@@ -99,6 +99,33 @@ static struct amba_device uart0_device = {
 	.periphid	= 0x00041011,
 };
 
+static struct resource appnic_resources[] = {
+	{
+		.start  = APP3K_PHYS_MAC_RX_BASE,
+		.end    = APP3K_PHYS_MAC_RX_BASE + 0xfff,
+		.flags  = IORESOURCE_MEM,
+	}, {
+		.start  = APP3K_PHYS_MAC_TX_BASE,
+		.end    = APP3K_PHYS_MAC_TX_BASE + 0xfff,
+		.flags  = IORESOURCE_MEM,
+	}, {
+		.start  = APP3K_PHYS_MAC_DMA_BASE,
+		.end    = APP3K_PHYS_MAC_DMA_BASE + 0xfff,
+		.flags  = IORESOURCE_MEM,
+	}, {
+		.start  = INT_MAC_DMA,
+		.end    = INT_MAC_DMA,
+		.flags  = IORESOURCE_IRQ,
+	},
+};
+
+static struct platform_device appnic_dev = {
+	.name   = "appnic",
+    .id     = -1,
+    .num_resources  = ARRAY_SIZE(appnic_resources),
+    .resource   = appnic_resources,
+};
+
 static void app3k_mach_init(void)
 {
 	/*register amba device*/
@@ -106,6 +133,7 @@ static void app3k_mach_init(void)
 
 	/*register platform devices*/
 	platform_device_register(&app3k_flash_dev);
+	platform_device_register(&appnic_dev);
 }
 
 MACHINE_START(APP33OO_MSBG, "LSI APP3300 MSBG")
diff --git a/drivers/net/arm/Kconfig b/drivers/net/arm/Kconfig
index 39e1c0d..74192c5 100644
--- a/drivers/net/arm/Kconfig
+++ b/drivers/net/arm/Kconfig
@@ -24,6 +24,45 @@ config ARM_ETHER3
 	  If you have an Acorn system with one of these network cards, you
 	  should say Y to this option if you wish to use it with Linux.
 
+config ARM_APPNIC
+	tristate "LSI APP Ether support"
+	depends on ARM && ARCH_APP3K
+	help
+	  If you wish to compile a kernel for the LSI APP3K and enable
+	  ethernet support. Say Y if you want it compiled into the kernel.
+
+	  To compile this driver as a module, choose M here and read
+	  <file:Documentation/networking/net-modules.txt>. The module will
+	  be called appnic.
+
+config APP_NIC_NUM_RX_DESC
+	int "APPNIC: Number of receive descriptors"
+	depends on ARM_APPNIC
+	default "4"
+	help
+	  The number of receive descriptors to allocate.
+
+config APP_NIC_RX_BUF_SZ
+	int "APPNIC: Size of the receive buffer"
+	depends on ARM_APPNIC
+	default "32768"
+	help
+	  The size of the receive buffer.
+
+config APP_NIC_NUM_TX_DESC
+	int "APPNIC: Number of transmit descriptors"
+	depends on ARM_APPNIC
+	default "4"
+	help
+	  The number of transmit descriptors to allocate.
+
+config APP_NIC_TX_BUF_SZ
+	int "APPNIC: Size of the transmit buffer"
+	depends on ARM_APPNIC
+	default "32768"
+	help
+	  The size of the transmit buffer.
+
 config ARM_ETHERH
 	tristate "I-cubed EtherH/ANT EtherM support"
 	depends on ARM && ARCH_ACORN
diff --git a/drivers/net/arm/Makefile b/drivers/net/arm/Makefile
index 303171f..2ea796c 100644
--- a/drivers/net/arm/Makefile
+++ b/drivers/net/arm/Makefile
@@ -4,6 +4,7 @@
 #
 
 obj-$(CONFIG_ARM_AM79C961A)	+= am79c961a.o
+obj-$(CONFIG_ARM_APPNIC)	+= appnic.o
 obj-$(CONFIG_ARM_ETHERH)	+= etherh.o
 obj-$(CONFIG_ARM_ETHER3)	+= ether3.o
 obj-$(CONFIG_ARM_ETHER1)	+= ether1.o
diff --git a/drivers/net/arm/appnic.c b/drivers/net/arm/appnic.c
new file mode 100644
index 0000000..08abc73
--- /dev/null
+++ b/drivers/net/arm/appnic.c
@@ -0,0 +1,2037 @@
+/*
+ * linux/drivers/net/app3k-nic.c
+ *
+ * Copyright (C) 2004 Agere Systems Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/socket.h>
+#include <linux/if.h>
+#include <linux/io.h>
+#include <linux/init.h>
+#include <linux/irq.h>
+#include <linux/delay.h>
+#include <linux/skbuff.h>
+#include <linux/time.h>
+#include <linux/timer.h>
+#include <linux/ethtool.h>
+#include <linux/dma-mapping.h>
+#include <linux/platform_device.h>
+
+#include <mach/hardware.h>
+#include <mach/pll.h>
+
+#include "appnic.h"
+
+extern int ubootenv_get(const char *, char *);
+
+/*
+ * Optimizations
+ */
+
+#define DISABLE_TX_INTERRUPTS
+
+static int phy_address = PHY_ADDRESS;
+static int phy_type = UNKNOWN_PHY;
+
+static int phy_read(int, int, unsigned short *);
+static int phy_write(int, int, unsigned short);
+static int phy_link(int);
+static int phy_speed(int);
+static int phy_duplex(int);
+static int phy_scan(void);
+static int phy_reset(int);
+static int phy_renegotiate(int);
+static int phy_enable(int);
+
+/*
+ * Receiver
+ */
+int rx_num_desc = (CONFIG_APP_NIC_NUM_RX_DESC * DESCRIPTOR_GRANULARITY);
+module_param(rx_num_desc, int, 0);
+MODULE_PARM_DESC(rx_num_desc, "appnic : Number of receive descriptors");
+
+int rx_buf_sz = CONFIG_APP_NIC_RX_BUF_SZ;
+module_param(rx_buf_sz, int, 0);
+MODULE_PARM_DESC(rx_buf_sz, "appnic : Receive buffer size");
+
+/*
+ * Transmitter
+ */
+int tx_num_desc = (CONFIG_APP_NIC_NUM_TX_DESC * DESCRIPTOR_GRANULARITY);
+module_param(tx_num_desc, int, 0);
+MODULE_PARM_DESC(tx_num_desc, "appnic : Number of transmit descriptors");
+
+int tx_buf_sz = CONFIG_APP_NIC_TX_BUF_SZ;
+module_param(tx_buf_sz, int, 0);
+MODULE_PARM_DESC(tx_buf_sz, "Appnic : Transmit buffer size");
+
+/*
+ * Timeout, if a transmit takes longer than this
+ * value in jiffies it has timed out.
+ */
+int tx_timeout = DEFAULT_TX_TIMEOUT;
+module_param(tx_timeout, int, 0);
+MODULE_PARM_DESC(tx_timeout, "appnic : Transmit timeout (in jiffies)");
+
+static unsigned long dropped_by_stack;
+static unsigned long out_of_tx_descriptors;
+static unsigned long transmit_interrupts;
+
+static struct timer_list appnic_timer;
+
+/*
+ * Locking...
+ */
+
+#ifdef CONFIG_SMP
+/*
+ * On SMP we have the following problem:
+ *
+ * A and B can never be executed simultaneously.  However, at least on UP,
+ * it is possible (and even desirable) for C to interrupt execution of
+ * A or B in order to have better RX reliability and avoid overruns.
+ * C, just like A and B, must have exclusive access to the chip and
+ * each of them must lock against any other concurrent access.
+ * Unfortunately this is not possible to have C suspend execution of A or
+ * B taking place on another CPU. On UP this is no an issue since A and B
+ * are run from softirq context and C from hard IRQ context, and there is
+ * no other CPU where concurrent access can happen.
+ * If ever there is a way to force at least B and C to always be executed
+ * on the same CPU then we could use read/write locks to protect against
+ * any other concurrent access and C would always interrupt B. But life
+ * isn't that easy in a SMP world...
+ */
+
+#define appnic_special_trylock(lock)            \
+	({                                            \
+	 int ret;                                  \
+	 local_irq_disable();						\
+	 ret = spin_trylock(lock);					\
+	 if (!ret)                                 \
+	 local_irq_enable();                       \
+	 ret;                                      \
+	 })
+#define appnic_special_lock(lock)               spin_lock_irq(lock)
+#define appnic_special_unlock(lock)             spin_unlock_irq(lock)
+#else
+#define appnic_special_trylock(lock)            (1)
+#define appnic_special_lock(lock)		        do { } while (0)
+#define appnic_special_unlock(lock)	            do { } while (0)
+#endif
+
+/*
+ * Utility Functions
+ */
+
+static void clear_statistics(struct appnic_device_t *device)
+{
+	int waste;
+
+	/*
+	 * Clear memory.
+	 */
+	memset((void *)&(device->stats), 0,
+			sizeof(struct net_device_stats));
+
+	/*
+	 * Clear counters.
+	 */
+
+	waste = __raw_readl(APPNIC_RX_STAT_PACKET_OK); /* rx_packets */
+	waste = __raw_readl(APPNIC_TX_STAT_PACKET_OK); /* tx_packets */
+
+	/* rx_bytes kept by driver. */
+	/* tx_bytes kept by driver. */
+	/* rx_errors will be the sum of the rx errors available. */
+	/* tx_errors will be the sum of the tx errors available. */
+	/* multicast */
+	waste = __raw_readl(APPNIC_RX_STAT_MULTICAST);
+
+	/* collisions will be the sum of the three following. */
+	waste = __raw_readl(APPNIC_TX_STATUS_LATE_COLLISION);
+	waste = __raw_readl(APPNIC_TX_STATUS_EXCESSIVE_COLLISION);
+	waste = __raw_readl(APPNIC_TX_STAT_COLLISION_ABOVE_WATERMARK);
+
+	/* rx_length_errors will be the sum of the two following. */
+	waste = __raw_readl(APPNIC_RX_STAT_UNDERSIZE);
+	waste = __raw_readl(APPNIC_RX_STAT_OVERSIZE);
+
+	/* rx_over_errors (out of descriptors?) maintained by the driver. */
+	/* rx_crc_errors */
+	waste = __raw_readl(APPNIC_RX_STAT_CRC_ERROR);
+
+	/* rx_frame_errors */
+	waste = __raw_readl(APPNIC_RX_STAT_ALIGN_ERROR);
+
+	/* rx_fifo_errors */
+	waste = __raw_readl(APPNIC_RX_STAT_OVERFLOW);
+
+	/* rx_missed will not be maintained. */
+	/* tx_aborted_errors will be maintained by the driver. */
+	/* tx_carrier_errors will not be maintained. */
+	/* tx_fifo_errors */
+	waste = __raw_readl(APPNIC_TX_STAT_UNDERRUN);
+
+	return;
+}
+
+/*
+ * The hardware clears the statistics registers after a read.
+ */
+static void get_hw_statistics(struct appnic_device_t *device)
+{
+	unsigned long flags;
+
+	/* tx_packets */
+	device->stats.tx_packets += __raw_readl(APPNIC_TX_STAT_PACKET_OK);
+
+	/* multicast */
+	device->stats.multicast += __raw_readl(APPNIC_RX_STAT_MULTICAST);
+
+	/* collision */
+	device->stats.collisions +=
+		__raw_readl(APPNIC_TX_STATUS_LATE_COLLISION);
+	device->stats.collisions +=
+		__raw_readl(APPNIC_TX_STATUS_EXCESSIVE_COLLISION);
+	device->stats.collisions +=
+		__raw_readl(APPNIC_TX_STAT_COLLISION_ABOVE_WATERMARK);
+
+	/* rx_length_errors */
+	device->stats.rx_length_errors += __raw_readl(APPNIC_RX_STAT_UNDERSIZE);
+	device->stats.rx_length_errors += __raw_readl(APPNIC_RX_STAT_OVERSIZE);
+
+	/* tx_fifo_errors */
+	device->stats.tx_fifo_errors += __raw_readl(APPNIC_TX_STAT_UNDERRUN);
+
+	/*
+	 * Lock this section out so the statistics maintained by the driver
+	 * don't get clobbered.
+	 */
+	spin_lock_irqsave(&device->lock, flags);
+
+	device->stats.rx_errors +=
+		(device->stats.rx_length_errors +
+		 device->stats.rx_crc_errors +
+		 device->stats.rx_frame_errors +
+		 device->stats.rx_fifo_errors +
+		 device->stats.rx_dropped +
+		 device->stats.rx_over_errors);
+
+	device->stats.rx_dropped = 0;
+	device->stats.rx_over_errors = 0;
+
+	device->stats.tx_errors +=
+		(device->stats.tx_fifo_errors +
+		device->stats.tx_aborted_errors);
+
+	device->stats.tx_aborted_errors = 0;
+
+	spin_unlock_irqrestore(&device->lock, flags);
+
+	return;
+}
+
+/*
+ * Returns the number of descriptors that are ready to receive packets
+ * or are waiting to transmit packets.  (from tail to head).
+ */
+static int queue_initialized(unsigned long queue_head,
+	unsigned long queue_tail, int size)
+{
+	int allocated;
+	union appnic_queue_pointer_t tail;
+	union appnic_queue_pointer_t head;
+
+	tail.raw = queue_tail;
+	head.raw = queue_head;
+
+	/*calculate the number of descriptors currently allocated*/
+	if (head.bits.generation_bit == tail.bits.generation_bit)
+		/*same generation*/
+		allocated = (head.bits.offset - tail.bits.offset);
+	else
+		/*different generation*/
+		allocated = head.bits.offset +
+			(size * sizeof(struct appnic_dma_descriptor_t)
+			 - tail.bits.offset);
+
+	/*number of descriptors is offset / sizeof(a descriptor)*/
+	allocated /= sizeof(struct appnic_dma_descriptor_t);
+
+	return allocated;
+}
+
+/*
+ * Returns the number of unused/uninitialized descriptors.
+ * from head to tail.
+ */
+static int queue_uninitialized(union appnic_queue_pointer_t head,
+		union appnic_queue_pointer_t tail, int size)
+{
+	int allocated;
+
+	/*calculate the number of descriptors currently unused/uninitialized*/
+	if (head.bits.generation_bit == tail.bits.generation_bit) {
+		/*same generation.*/
+		allocated =
+			((size * sizeof(struct appnic_dma_descriptor_t)) -
+			 head.bits.offset) + tail.bits.offset;
+	} else
+		/* different generation. */
+		allocated = tail.bits.offset - head.bits.offset;
+
+	/*number of descriptors is offset / sizeof(a descriptor).*/
+	allocated /= sizeof(struct appnic_dma_descriptor_t);
+
+	return allocated;
+}
+
+static void queue_increment(union appnic_queue_pointer_t *queue,
+		int number_of_descriptors)
+{
+	queue->bits.offset += sizeof(struct appnic_dma_descriptor_t);
+
+	if ((number_of_descriptors * sizeof(struct appnic_dma_descriptor_t)) ==
+			queue->bits.offset) {
+		queue->bits.offset = 0;
+		queue->bits.generation_bit =
+			(0 == queue->bits.generation_bit) ? 1 : 0;
+	}
+
+	return;
+}
+
+static void queue_decrement(union appnic_queue_pointer_t *queue,
+		int number_of_descriptors)
+{
+	if (0 == queue->bits.offset) {
+		queue->bits.offset =
+			((number_of_descriptors - 1) *
+			 sizeof(struct appnic_dma_descriptor_t));
+		queue->bits.generation_bit =
+			(0 == queue->bits.generation_bit) ? 1 : 0;
+	} else
+		queue->bits.offset -= sizeof(struct appnic_dma_descriptor_t);
+
+	return;
+}
+
+static void appnic_timer_handler(unsigned long opaque)
+{
+	struct net_device *device = (struct net_device *)opaque;
+
+	appnic_timer.expires = jiffies + (APPNIC_TIMER_PERIOD * HZ);
+	add_timer(&appnic_timer);
+	enable(device);
+}
+
+/*
+ * Does not change the default values in the extended and
+ * half-duplex configuration registers.
+ */
+static int enable(struct net_device *device)
+{
+	int ret;
+	unsigned long rx_configuration;
+	unsigned long tx_configuration;
+	union phy_status_t phy_status;
+	int carrier_state = 0;
+
+	DEBUG_PRINT("Enabling the interface.\n");
+
+	/*
+	 * Setup the receive and transmit configuration registers (using smii
+	 * status to set speed/duplex and check the link status).
+	 */
+	rx_configuration = APPNIC_RX_CONF_STRIPCRC;
+	tx_configuration =
+		(APPNIC_TX_CONF_ENABLE_SWAP_SA |
+		  APPNIC_TX_CONF_APP_CRC_ENABLE |
+		  APPNIC_TX_CONF_PAD_ENABLE);
+	TX_CONF_SET_IFG(tx_configuration, 0xf);
+
+	if ((0 == phy_read(phy_address, PHY_STATUS, &phy_status.raw)) &&
+		(0 == phy_read(phy_address, PHY_STATUS, &phy_status.raw))) {
+
+		PHY_DEBUG_PRINT("phy_status.raw=0x%x\n", phy_status.raw);
+
+		if (1 == phy_status.bits.autoneg_comp) {
+			if (1 == phy_status.bits.link_status) {
+
+				if (1 == phy_speed(phy_address)) {
+					rx_configuration |= APPNIC_RX_CONF_SPEED;
+					tx_configuration |= APPNIC_TX_CONF_SPEED;
+				}
+
+				if (1 == phy_duplex(phy_address)) {
+					rx_configuration |= APPNIC_RX_CONF_DUPLEX;
+					tx_configuration |= APPNIC_TX_CONF_DUPLEX;
+				}
+
+				rx_configuration |=
+					(APPNIC_RX_CONF_ENABLE | APPNIC_RX_CONF_LINK);
+				tx_configuration |=
+					(APPNIC_TX_CONF_LINK | APPNIC_TX_CONF_ENABLE);
+				ret = 0;
+				carrier_state = 1;
+			} else
+				netif_carrier_off(device);
+		} else
+			netif_carrier_off(device);
+	}
+
+	if (rx_configuration != __raw_readl(APPNIC_RX_CONF))
+		__raw_writel(rx_configuration, APPNIC_RX_CONF);
+
+
+	if (tx_configuration != __raw_readl(APPNIC_TX_CONF))
+		__raw_writel(tx_configuration, APPNIC_TX_CONF);
+
+	if (0 != carrier_state)
+		netif_carrier_on(device);
+	else
+		netif_carrier_off(device);
+
+	return ret;
+}
+
+static void disable(void)
+{
+	unsigned long tx_configuration;
+	unsigned long rx_configuration;
+
+	DEBUG_PRINT("Disabling the interface.\n");
+
+	rx_configuration = __raw_readl(APPNIC_RX_CONF);
+	rx_configuration &= ~APPNIC_RX_CONF_ENABLE;
+	__raw_writel(rx_configuration, APPNIC_RX_CONF);
+
+	tx_configuration = __raw_readl(APPNIC_TX_CONF);
+	tx_configuration &= ~APPNIC_TX_CONF_ENABLE;
+	__raw_writel(tx_configuration, APPNIC_TX_CONF);
+
+	return;
+}
+
+void disable_nic(void)
+{
+	disable();
+}
+
+/*
+ * PHY interface (BCM5221)
+ */
+
+/*
+ * Returns -1 if unsuccessful, the (short) value otherwise.
+ */
+static int phy_read(int phy, int reg, unsigned short *value)
+{
+	int ret = -1;
+	unsigned long command;
+	unsigned long status;
+
+	/*
+	 * Sometimes the MDIO_STATACK bit is already set before
+	 * starting a read.  This bit should be cleared by reading
+	 * (as in the loop that checks for it below).
+	 * Reading the bit before starting the read (by writing the
+	 * read command to the command register) keeps the following
+	 * code from thinking the read is complete prematurly).
+	 *
+	 * To use the 'phy test' command (see common/cmd_phy.c)
+	 * comment out the following read!
+	 */
+
+	status = __raw_readl(MDIO_STAT);
+
+	command = (MDIO_CMDTYPE_MDIO | MDIO_CMDOP_READ |
+		(phy << 4) | (reg << 9));
+	__raw_writel(command, MDIO_CMD);
+
+	do {
+		status = __raw_readl(MDIO_STAT);
+	} while (0 == (status & MDIO_STATACK));
+
+	/* Once the acknowledge bit is set (without an error)
+	 * read the data.
+	 */
+	if (0 == (status & MDIO_STATERR)) {
+		*value = __raw_readl(MDIO_DATA);
+		ret = 0;
+	}
+
+	return ret;
+}
+
+static int phy_write(int phy, int reg, unsigned short value)
+{
+	int ret = -1;
+	unsigned long command;
+	unsigned long status;
+
+	/*
+	 * Sometimes the MDIO_STATACK bit is already set before starting a
+	 * read.  This bit should be cleared by reading (as in the loop that
+	 * checks for it below).  Reading the bit before starting the read (by
+	 * writing the read command to the command register) keeps the following
+	 * code from thinking the read is complete prematurly).
+	 *
+	 * To use the 'phy test' command (see common/cmd_phy.c) comment out the
+	 * following read!
+	 */
+	status = __raw_readl(MDIO_STAT);
+
+	__raw_writel(value, MDIO_DATA);
+
+	command = (MDIO_CMDTYPE_MDIO | MDIO_CMDOP_WRITE |
+			(phy << 4) | (reg << 9));
+	__raw_writel(command, MDIO_CMD);
+
+	do {
+		status = __raw_readl(MDIO_STAT);
+	} while (0 == (status & MDIO_STATACK));
+
+	if (0 == (status & MDIO_STATERR))
+		ret = 0;
+
+	return ret;
+}
+
+static int phy_link(int phy)
+{
+	union phy_status_t phy_status_1, phy_status_2;
+
+	if ((0 != phy_read(phy, PHY_STATUS, &phy_status_1.raw)) ||
+			(0 != phy_read(phy, PHY_STATUS, &phy_status_2.raw)))
+		return -EINVAL;
+
+	return phy_status_2.bits.link_status;
+
+}
+
+/*
+ * Returns the speed (1=100, 0=10) or an error (-1).
+ */
+static int phy_speed(int phy)
+{
+	union bc_phy_auxiliary_control_status_t bc_phy_auxiliary_control_status;
+	union m_phy_auxiliary_control_status_t m_phy_auxiliary_control_status;
+
+	if (BCM5221_PHY == phy_type) {
+		if (0 != phy_read(phy_address, PHY_AUXILIARY_CONTROL_STATUS,
+					&bc_phy_auxiliary_control_status.raw))
+			return -EIO;
+
+		return bc_phy_auxiliary_control_status.bits.speed;
+
+	} else if (MICREL_PHY == phy_type) {
+		if (0 != phy_read(phy_address, M_PHY_AUXILIARY_CONTROL_STATUS,
+					&m_phy_auxiliary_control_status.raw))
+			return -EIO;
+
+		if ((m_phy_auxiliary_control_status.bits.op_mode_indication & 0x3)
+				== 0x2)
+			return 1; /* 100 */
+		else if ((m_phy_auxiliary_control_status.bits.op_mode_indication
+					& 0x3) == 0x1)
+			return 0; /* 10 */
+		else
+			return -EIO;
+
+	}
+
+	/*if phy_type_ is not set...*/
+	ERROR_PRINT("PHY type is not specified (0x%x)\n", phy_type);
+
+	return -ENODEV;
+
+}
+
+/*
+ * Returns duplex status (1=full duplex, 0=half duplex) or an error (-1).
+ */
+static int phy_duplex(int phy)
+{
+	union bc_phy_auxiliary_control_status_t bc_phy_auxiliary_control_status;
+	union m_phy_auxiliary_control_status_t m_phy_auxiliary_control_status;
+
+	if (BCM5221_PHY == phy_type) {
+
+		if (0 != phy_read(phy_address, PHY_AUXILIARY_CONTROL_STATUS,
+					&bc_phy_auxiliary_control_status.raw))
+			return -EIO;
+
+		return bc_phy_auxiliary_control_status.bits.full_duplex;
+
+	}  else if (MICREL_PHY == phy_type) {
+
+		if (0 != phy_read(phy_address, M_PHY_AUXILIARY_CONTROL_STATUS,
+					&m_phy_auxiliary_control_status.raw))
+			return -EIO;
+
+		return (m_phy_auxiliary_control_status.bits.op_mode_indication >> 2)
+				& 0x1;
+	}
+
+	/*if phy_type_ is not set...*/
+	ERROR_PRINT("PHY type is not specified (0x%x)\n", phy_type);
+	return -ENODEV;
+}
+
+static int phy_scan(void)
+{
+	int phy = -1;
+	int index;
+	union phy_id_high_t phy_id_high;
+	union phy_id_low_t phy_id_low;
+
+	for (index = 31; index > -1; --index) {
+
+		if (0 != phy_read(index, PHY_ID_HIGH, &phy_id_high.raw))
+			continue;
+
+		if (0 != phy_read(index, PHY_ID_LOW, &phy_id_low.raw))
+			continue;
+
+		if ((BC_PHY_ID_HIGH_ID == phy_id_high.bits.id) &&
+			(BC_PHY_ID_LOW_ID == phy_id_low.bits.id) &&
+			(BC_PHY_ID_LOW_MODEL == phy_id_low.bits.model)) {
+			phy = index;
+			printk(KERN_INFO "Found a Broadcom PHY at 0x%x,"
+					"revision %d.\n",
+					(phy << 4), phy_id_low.bits.revision);
+			break;
+		} else if ((M_PHY_ID_HIGH_ID == phy_id_high.bits.id) &&
+				(M_PHY_ID_LOW_ID == phy_id_low.bits.id)) {
+			phy = index;
+			printk(KERN_INFO "Found a Micrel PHY at 0x%x,"
+					"model 0x%x revision %d.\n",
+					(phy << 4), phy_id_low.bits.model,
+					phy_id_low.bits.revision);
+			break;
+		} else {
+			phy_type = UNKNOWN_PHY;
+			printk(KERN_INFO "Unknown PHY at 0x%x.  0x%x 0x%x 0x%x\n",
+					(phy << 4), phy_id_high.bits.id, phy_id_low.bits.id,
+					phy_id_low.bits.model);
+		}
+	}
+
+	return phy;
+}
+
+static int phy_reset(int phy)
+{
+	int retries = 10;
+	union bc_phy_control_t bc_phy_control;
+
+	if (0 != phy_read(phy, PHY_CONTROL, &bc_phy_control.raw))
+		return -EIO;
+
+	bc_phy_control.bits.soft_reset = 1;
+
+	if (0 != phy_write(phy, PHY_CONTROL, bc_phy_control.raw))
+		return -EIO;
+
+
+	do {
+		if (0 != phy_read(phy, PHY_CONTROL, &bc_phy_control.raw))
+			return -EIO;
+
+		--retries;
+
+	} while ((0 < retries) && (0 != bc_phy_control.bits.soft_reset));
+
+	if (0 != bc_phy_control.bits.soft_reset)
+		return -EBUSY;
+
+	return 0;
+}
+
+static int phy_renegotiate(int phy)
+{
+	int autoneg_retries = 10;
+	int autoneg_complete_retries = 10;
+	union bc_phy_control_t bc_phy_control;
+	union phy_status_t phy_status;
+
+	do {
+
+		if (0 != phy_read(phy, PHY_CONTROL, &bc_phy_control.raw))
+			return -EIO;
+
+		bc_phy_control.bits.restart_autoneg = 1;
+
+		if (0 != phy_write(phy, PHY_CONTROL, bc_phy_control.raw))
+			return -EIO;
+
+		do {
+			mdelay(500);
+
+			if (0 != phy_read(phy, PHY_STATUS, &phy_status.raw))
+				return -EIO;
+
+			--autoneg_complete_retries;
+		} while ((0 < autoneg_complete_retries) &&
+				(0 == phy_status.bits.autoneg_comp));
+
+		if (0 != phy_status.bits.autoneg_comp)
+			break;
+
+		--autoneg_retries;
+	} while (0 < autoneg_retries);
+
+	if (0 == phy_status.bits.autoneg_comp) {
+		WARN_PRINT("Giving up on negotiation\n");
+		return -EAGAIN;
+	}
+
+	return 0;
+}
+
+static int phy_enable(int phy)
+{
+	char mdio_clock_speed_string[256];
+	char phy_address_string[256];
+	char ad_value_string[40];
+	unsigned long mdio_clock_speed;
+	unsigned long mdio_divisor;
+	unsigned short ad_value;
+	int link_status_retries = 10;
+	union phy_id_high_t phy_id_high;
+	union phy_id_low_t phy_id_low;
+	union phy_status_t phy_status;
+
+
+	/*
+	 * Set up the MDIO clock.
+	 */
+
+	if (0 != ubootenv_get("mdio_clock", mdio_clock_speed_string))
+		mdio_clock_speed = 1250000;
+	else
+		mdio_clock_speed = simple_strtoul(mdio_clock_speed_string, NULL, 0);
+
+
+	mdio_divisor = ((get_core_speed() / 2) / mdio_clock_speed);
+
+	printk(KERN_INFO "Setting the MDIO clock to %lu Hz (divisor=%lu)\n",
+			mdio_clock_speed, mdio_divisor);
+	writel(mdio_divisor, MDIO_CLK);
+
+	/*
+	 * Get the PHY address.
+	 */
+	if (0 != ubootenv_get("phy_address", phy_address_string))
+		phy_address = phy_scan();
+	else
+		phy_address = simple_strtoul(phy_address_string, NULL, 0);
+
+
+	if (31 < phy_address || 0 > phy_address) {
+		ERROR_PRINT("Unable to get valid PHY address!\n");
+		return -EBUSY;
+	}
+
+	/*
+	 * Get PHY type.
+	 */
+	if (0 != phy_read(phy_address, PHY_ID_HIGH, &phy_id_high.raw))
+		return -EIO;
+
+	if (0 != phy_read(phy_address, PHY_ID_LOW, &phy_id_low.raw))
+		return -EIO;
+
+	if ((BC_PHY_ID_HIGH_ID == phy_id_high.bits.id) &&
+			(BC_PHY_ID_LOW_ID == phy_id_low.bits.id) &&
+			(BC_PHY_ID_LOW_MODEL == phy_id_low.bits.model)) {
+
+		phy_type = BCM5221_PHY;
+		printk(KERN_INFO "Broadcomm 5221 PHY at 0x%x\n", phy_address);
+
+	} else if ((M_PHY_ID_HIGH_ID == phy_id_high.bits.id) &&
+			(M_PHY_ID_LOW_ID == phy_id_low.bits.id)) {
+
+		phy_type = MICREL_PHY;
+		printk(KERN_INFO "Micrel PHY at 0x%x, Model 0x%x\n",
+				phy_address, phy_id_low.bits.model);
+
+	} else {
+
+		phy_type = UNKNOWN_PHY;
+		printk(KERN_INFO "Unknown PHY at 0x%x.  0x%x 0x%x 0x%x\n",
+				phy_address, phy_id_high.bits.id,
+				phy_id_low.bits.id,	phy_id_low.bits.model);
+
+	}
+
+	if (-1 != phy_address) {
+
+		if (0 != phy_reset(phy_address))
+			return -EBUSY;
+
+		/*
+		 * 0x1e1 - 10/100 half/full
+		 * 0xe1 - 100 half, 10 half/full
+		 * 0x61 - 10 half/full
+		 * 0x41 - 10 half
+		 */
+		if (0 != ubootenv_get("ad_value", ad_value_string)) {
+
+			if ((IS_ASIC) &&
+				(0 == (APP3XX_REVISION_REGISTER & 0x1f)))
+				/*10M does not work on ASIC v1.0*/
+				ad_value = 0x0181;
+			else
+				/* For FGPA loads and any ASIC after v1.0,
+				 * default to 10 full/half
+				 */
+				ad_value = 0x061;
+
+		} else
+			ad_value = simple_strtoul(ad_value_string, NULL, 0);
+
+		if (0 != phy_write(phy_address, PHY_AUTONEG_ADVERTISE,
+					ad_value))
+			return -EIO;
+
+		phy_renegotiate(phy_address);
+
+
+		do {
+
+			if (0 != phy_read(phy_address, PHY_STATUS,
+						&phy_status.raw))
+				return -EIO;
+
+			mdelay(10);
+			--link_status_retries;
+
+		} while ((0 == phy_status.bits.link_status) &&
+				(0 < link_status_retries));
+
+		if (0 != phy_status.bits.link_status)
+
+			printk(KERN_INFO "PHY: link=%s speed=%d Mbs duplex=%s\n",
+				(1 == phy_link(phy_address)) ? "up" : "down",
+				(1 == phy_speed(phy_address)) ? 100 : 10,
+				(1 == phy_duplex(phy_address)) ? "full" : "half");
+
+	}
+
+	return 0;
+}
+
+static void handle_transmit_interrupt(struct net_device *device)
+{
+	struct appnic_device_t *dev =
+		(struct appnic_device_t *)netdev_priv(device);
+
+	DEBUG_PRINT("tail=0x%lx tail_copy=0x%lx head=0x%lx\n",
+			dev->tx_tail->raw, dev->tx_tail_copy.raw,
+			dev->tx_head.raw);
+
+	/*
+	 * The hardware's tail pointer should be one descriptor (or more)
+	 * ahead of software's copy.
+	 */
+
+	while (0 < queue_initialized(dev->tx_tail->raw,
+				dev->tx_tail_copy.raw,
+				dev->tx_num_desc))
+		queue_increment(&dev->tx_tail_copy, dev->tx_num_desc);
+
+
+	DEBUG_PRINT("tail=0x%lx tail_copy=0x%lx head=0x%lx\n",
+			dev->tx_tail->raw, dev->tx_tail_copy.raw,
+			dev->tx_head.raw);
+
+	return;
+}
+
+static DECLARE_MUTEX(rpm);
+
+static void receive_packet(struct net_device *device)
+{
+
+	struct appnic_device_t *dev =
+		(struct appnic_device_t *)netdev_priv(device);
+	struct appnic_dma_descriptor_t *descriptor;
+	struct sk_buff *sk_buff;
+	struct ethhdr *ethhdr;
+	unsigned char broadcast[] = {0xff, 0xff, 0xff, 0xff, 0xff, 0xff};
+	unsigned char multicast[] = {0x01, 0x00};
+	unsigned bytes_copied = 0;
+	unsigned error = 0;
+	unsigned long ok, overflow, crc, align;
+	int ret;
+
+
+	/*
+	 * should use down_interruptible
+	 */
+	spin_lock(&dev->extra_lock);
+
+	DEBUG_PRINT("head=0x%lx tail=0x%lx tail_copy=0x%lx\n",
+			dev->rx_head.raw, dev->rx_tail->raw,
+			dev->rx_tail_copy.raw);
+
+	descriptor = &(dev->rx_desc[(dev->rx_tail_copy.bits.offset /
+				sizeof(struct appnic_dma_descriptor_t))]);
+
+	sk_buff = dev_alloc_skb(1600);
+	if (sk_buff) {
+		ok = __raw_readl(APPNIC_RX_STAT_PACKET_OK);
+		overflow = __raw_readl(APPNIC_RX_STAT_OVERFLOW);
+		crc = __raw_readl(APPNIC_RX_STAT_CRC_ERROR);
+		align = __raw_readl(APPNIC_RX_STAT_ALIGN_ERROR);
+
+		/*
+		 * Copy the received packet into the skb.
+		 */
+		while (0 < queue_initialized(dev->rx_tail->raw,
+					dev->rx_tail_copy.raw,
+					dev->rx_num_desc)) {
+
+			memcpy((void *)skb_put(sk_buff, descriptor->pdu_length),
+				(void *)(descriptor->host_data_memory_pointer +
+				dev->dma_alloc_offset),	descriptor->pdu_length);
+
+			bytes_copied += descriptor->pdu_length;
+			descriptor->data_transfer_length = dev->rx_buf_per_desc;
+
+			if (0 != descriptor->error)
+				error = 1;
+
+			queue_increment(&dev->rx_tail_copy, dev->rx_num_desc);
+
+			if (0 != descriptor->end_of_packet)
+				break;
+
+			descriptor = &(dev->rx_desc[(dev->rx_tail_copy.bits.offset /
+						sizeof(struct appnic_dma_descriptor_t))]);
+		}
+
+		if (0 == descriptor->end_of_packet)
+			dev_kfree_skb(sk_buff);
+		else {
+
+			if (0 == error) {
+				ethhdr = (struct ethhdr *)sk_buff->data;
+
+				if ((0 == memcmp((const void *)&(ethhdr->h_dest[0]),
+								(const void *)&(device->dev_addr[0]),
+								sizeof(ethhdr->h_dest))) ||
+					(0 == memcmp((const void *)&(ethhdr->h_dest[0]),
+								   (const void *)&(broadcast[0]),
+								   sizeof(ethhdr->h_dest))) ||
+					(0 == memcmp((const void *)&(ethhdr->h_dest[0]),
+								   (const void *)&(multicast[0]),
+								   sizeof(multicast)))) {
+
+					dev->stats.rx_bytes += bytes_copied;
+					++dev->stats.rx_packets;
+					sk_buff->dev = device;
+					sk_buff->protocol = eth_type_trans(sk_buff, device);
+
+					ret = netif_rx(sk_buff);
+
+					if ((NET_RX_DROP == ret) ||
+						(NET_RX_SUCCESS != ret)) {
+						++dropped_by_stack;
+					}
+				} else
+					dev_kfree_skb(sk_buff);
+
+			} else {
+				dev_kfree_skb(sk_buff);
+
+				if (0 != overflow)
+					++dev->stats.rx_fifo_errors;
+				else if (0 != crc)
+					++dev->stats.rx_crc_errors;
+				else if (0 != align)
+					++dev->stats.rx_frame_errors;
+
+			}
+		}
+
+	}
+
+	DEBUG_PRINT("head=0x%lx tail=0x%lx tail_copy=0x%lx\n",
+			dev->rx_head.raw, dev->rx_tail->raw,
+			dev->rx_tail_copy.raw);
+
+	spin_unlock(&dev->extra_lock);
+
+	return;
+}
+
+static void handle_receive_interrupt(struct net_device *device)
+{
+	struct appnic_device_t *dev =
+		(struct appnic_device_t *)netdev_priv(device);
+	union appnic_queue_pointer_t queue;
+	struct appnic_dma_descriptor_t *descriptor;
+	int updated_head_pointer = 0;
+
+	DEBUG_PRINT("head=0x%lx tail=0x%lx tail_copy=0x%lx\n",
+			dev->rx_head.raw, dev->rx_tail->raw,
+			dev->rx_tail_copy.raw);
+	queue.raw = dev->rx_tail_copy.raw;
+
+	while (0 < queue_initialized(dev->rx_tail->raw,
+				queue.raw, dev->rx_num_desc)) {
+		descriptor = &(dev->rx_desc[(queue.bits.offset /
+				sizeof(struct appnic_dma_descriptor_t))]);
+
+		if (0 != descriptor->end_of_packet) {
+
+			receive_packet(device);
+			queue.raw = dev->rx_tail_copy.raw;
+
+		} else
+			queue_increment(&queue, dev->rx_num_desc);
+	}
+
+	/*
+	 * Update the head pointer
+	 */
+
+	while (1 < queue_uninitialized(dev->rx_head,
+				dev->rx_tail_copy, dev->rx_num_desc)) {
+
+		descriptor = &(dev->rx_desc[(dev->rx_head.bits.offset /
+				sizeof(struct appnic_dma_descriptor_t))]);
+		descriptor->data_transfer_length = dev->rx_buf_per_desc;
+		descriptor->write = 1;
+		descriptor->pdu_length = 0;
+		descriptor->start_of_packet = 0;
+		descriptor->end_of_packet = 0;
+		descriptor->interrupt_on_completion = 1;
+		queue_increment(&dev->rx_head, dev->rx_num_desc);
+		updated_head_pointer = 1;
+	}
+
+	if (0 != updated_head_pointer)
+		__raw_writel(dev->rx_head.raw, APPNIC_DMA_RX_HEAD_POINTER);
+
+	DEBUG_PRINT("head=0x%lx tail=0x%lx tail_copy=0x%lx\n",
+			dev->rx_head.raw, dev->rx_tail->raw,
+			dev->rx_tail_copy.raw);
+
+	return;
+
+}
+
+static irqreturn_t appnic_isr(int irq, void *device_id)
+{
+	struct net_device *device = (struct net_device *)device_id;
+	struct appnic_device_t *dev =
+			(struct appnic_device_t *)netdev_priv(device);
+	union bc_phy_interrupt_t bc_phy_interrupt;
+	union m_phy_interrupt_t m_phy_interrupt;
+	unsigned long dma_interrupt_status;
+	unsigned long flags;
+
+	/* acquire the lock */
+	spin_lock_irqsave(&dev->lock, flags);
+
+	if (INT_MAC_RX == irq) {
+		PHY_DEBUG_PRINT("Handling PHY interrupt.\n");
+
+		if (BCM5221_PHY == phy_type) {
+			phy_read(phy_address,
+				BC_PHY_INTERRUPT, &bc_phy_interrupt.raw);
+			bc_phy_interrupt.raw = 0;
+			bc_phy_interrupt.bits.enable = 1;
+			phy_write(phy_address,
+					BC_PHY_INTERRUPT, bc_phy_interrupt.raw);
+
+		} else if (MICREL_PHY == phy_type) {
+			phy_read(phy_address,
+					M_PHY_INTERRUPT, &m_phy_interrupt.raw);
+			phy_write(phy_address,
+					M_PHY_INTERRUPT, m_phy_interrupt.raw);
+		}
+
+		__raw_writel(0, APPNIC_RX_INTERRUPT_STATUS);
+		enable(device);
+	} else {
+		/* get the status */
+		dma_interrupt_status =
+		__raw_readl(APPNIC_DMA_INTERRUPT_STATUS);
+
+		__raw_writel(0, APPNIC_DMA_INTERRUPT_STATUS);
+
+		/* handle interrupts */
+		if (TX_INTERRUPT(dma_interrupt_status)) {
+			/* transmition complete */
+			++transmit_interrupts;
+			handle_transmit_interrupt(device);
+		}
+
+		if (RX_INTERRUPT(dma_interrupt_status))
+			/* receive complete */
+			handle_receive_interrupt(device);
+	}
+
+	/* release the lock */
+	spin_unlock_irqrestore(&dev->lock, flags);
+
+	return IRQ_HANDLED;
+}
+
+/*
+ * Opens the interface.  The interface is opened whenever ifconfig
+ * activates it.  The open method should register any system resource
+ * it needs (I/O ports, IRQ, DMA, etc.) turn on the hardware, and
+ * increment the module usage count.
+ */
+int appnic_open(struct net_device *device)
+{
+	int ret = 0;
+	char phy_string[256];
+	int use_interrupts = 1;
+	struct appnic_device_t *dev =
+		(struct appnic_device_t *)netdev_priv(device);
+	union bc_phy_interrupt_t bc_phy_interrupt;
+	union m_phy_interrupt_t m_phy_interrupt;
+
+	/* enable the receiver and transmitter */
+	if (0 != enable(device)) {
+		ERROR_PRINT("Unable to enable the interface.\n");
+		disable();
+		return -EBUSY;
+	}
+
+	/* install the interrupt handlers */
+	ret = request_irq(device->irq, appnic_isr, 0,
+			APPNIC_NAME, device);
+	if (ret)
+		return ret;
+
+	/* enable interrupts */
+	__raw_writel((APPNIC_DMA_INTERRUPT_ENABLE_RECEIVE |
+				APPNIC_DMA_INTERRUPT_ENABLE_TRANSMIT),
+			APPNIC_DMA_INTERRUPT_ENABLE);
+
+	if ((0 != ubootenv_get("phy_mode", phy_string)) ||
+			(0 == strncmp(phy_string, "poll", strlen("poll"))))
+		use_interrupts = 0;
+
+	PHY_DEBUG_PRINT("use_interrupts=%d\n", use_interrupts);
+
+	if (1 == use_interrupts) {
+		if (BCM5221_PHY == phy_type) {
+
+			bc_phy_interrupt.raw = 0;
+			bc_phy_interrupt.bits.enable = 1;
+
+			if (0 != phy_write(phy_address, BC_PHY_INTERRUPT,
+						bc_phy_interrupt.raw))
+				return -EBUSY;
+
+			if (0 != phy_read(phy_address, BC_PHY_INTERRUPT,
+						&bc_phy_interrupt.raw))
+				return -EBUSY;
+
+		} else if (MICREL_PHY == phy_type) {
+
+			m_phy_interrupt.raw = 0;
+			m_phy_interrupt.bits.enable_link_up = 1;
+
+			if (0 != phy_write(phy_address, M_PHY_INTERRUPT,
+						m_phy_interrupt.raw))
+				return -EBUSY;
+		}
+
+		ret = request_irq(INT_MAC_RX, appnic_isr, 0,
+				APPNIC_NAME "(phy)", device);
+		if (ret)
+			return ret;
+
+
+		__raw_writel((APPNIC_RX_EXTERNAL_INTERRUPT_CONTROL_MAC_0),
+				APPNIC_RX_EXTERNAL_INTERRUPT_CONTROL);
+		dev->polling = 0;
+
+	} else {
+		WARN_PRINT("PHY is in polling mode.\n");
+		init_timer(&appnic_timer);
+		appnic_timer.expires = jiffies + (APPNIC_TIMER_PERIOD * HZ);
+		appnic_timer.data = (unsigned long)device;
+		appnic_timer.function = appnic_timer_handler;
+		add_timer(&appnic_timer);
+		dev->polling = 1;
+	}
+
+	/* let the OS know we are ready to send packets */
+	netif_start_queue(device);
+
+	return 0;
+}
+
+/*
+ *
+ * Stops the interface.  The interface is stopped when it is brought
+ * down; operations performed at open time should be reversed.
+ */
+
+int appnic_stop(struct net_device *device)
+{
+	struct appnic_device_t *dev =
+			(struct appnic_device_t *)netdev_priv(device);
+
+	DEBUG_PRINT("Stopping the interface.\n");
+
+	/*
+	 * Indicate to the OS that no more packets should be sent.
+	 */
+	netif_stop_queue(device);
+
+	/*
+	 * Stop the receiver and transmitter.
+	 */
+	disable();
+
+	/*
+	 * Free the interrupts.
+	 */
+	free_irq(device->irq, device);
+
+	if (0 != dev->polling)
+		del_timer(&appnic_timer);
+	else
+		free_irq(INT_MAC_RX, device);
+
+	return 0;
+}
+
+/*
+ * The method initiates the transmission of a packet.  The full packet
+ * (protocol headers and all) is contained in a socket buffer (sk_buff)
+ * structure.
+ * ----- NOTES -----
+ * This will not get called by the kernel until it returns.
+ */
+int appnic_hard_start_xmit(struct sk_buff *skb,
+		struct net_device *device)
+{
+	struct appnic_device_t *dev =
+			(struct appnic_device_t *)netdev_priv(device);
+	struct appnic_dma_descriptor_t *descriptor;
+	int length;
+	int buf_per_desc;
+	int bytes_copied = 0;
+
+	appnic_special_lock(&dev->lock);
+
+	length = skb->len < ETH_ZLEN ? ETH_ZLEN : skb->len;
+	buf_per_desc = dev->tx_buf_sz / dev->tx_num_desc;
+
+	/*
+	 * If enough transmit descriptors are available, copy and transmit.
+	 */
+
+	if (((length / buf_per_desc) + 1) >=
+			queue_uninitialized(dev->tx_head, *dev->tx_tail,
+				dev->tx_num_desc))
+		handle_transmit_interrupt(device);
+
+	if (((length / buf_per_desc) + 1) <
+			queue_uninitialized(dev->tx_head, *dev->tx_tail,
+				dev->tx_num_desc)) {
+
+		descriptor = &(dev->tx_desc[(dev->tx_head.bits.offset /
+					sizeof(struct appnic_dma_descriptor_t))]);
+
+		descriptor->start_of_packet = 1;
+
+		while (bytes_copied < length) {
+			descriptor->write = 1;
+			descriptor->pdu_length = length;
+
+			if ((length - bytes_copied) > buf_per_desc) {
+
+				memcpy((void *)(descriptor->host_data_memory_pointer +
+					dev->dma_alloc_offset),
+					(void *)((unsigned long)skb->data + bytes_copied),
+					buf_per_desc);
+				descriptor->data_transfer_length = buf_per_desc;
+				descriptor->end_of_packet = 0;
+				descriptor->interrupt_on_completion = 0;
+				bytes_copied += buf_per_desc;
+			} else {
+				memcpy((void *)(descriptor->host_data_memory_pointer +
+					dev->dma_alloc_offset),
+					(void *)((unsigned long)skb->data + bytes_copied),
+					(length - bytes_copied));
+
+				descriptor->data_transfer_length = (length - bytes_copied);
+				descriptor->end_of_packet = 1;
+#ifdef DISABLE_TX_INTERRUPTS
+				descriptor->interrupt_on_completion = 0;
+#else  /* DISABLE_TX_INTERRUPTS */
+				descriptor->interrupt_on_completion = 1;
+#endif /* DISABLE_TX_INTERRUPTS */
+				bytes_copied = length;
+
+			}
+
+			dev->stats.tx_bytes += bytes_copied;
+			queue_increment(&dev->tx_head, dev->tx_num_desc);
+			descriptor = &(dev->tx_desc[(dev->tx_head.bits.offset /
+					sizeof(struct appnic_dma_descriptor_t))]);
+			descriptor->start_of_packet = 0;
+		}
+
+		__raw_writel(dev->tx_head.raw, APPNIC_DMA_TX_HEAD_POINTER);
+		device->trans_start = jiffies;
+
+	} else
+		++out_of_tx_descriptors;
+
+	/* free the socket buffer */
+	dev_kfree_skb(skb);
+
+	appnic_special_unlock(&dev->lock);
+
+	return 0;
+}
+
+/*
+ * This method is called when a packet transmission fails to complete
+ * within a resonable period, on the assumption that an interrupt has
+ * been missed or the interface has locked up.  It should handle the
+ * problem and resume packet transmission.
+ */
+void appnic_tx_timeout(struct net_device *device)
+{
+	struct appnic_device_t *dev =
+			(struct appnic_device_t *)netdev_priv(device);
+	struct appnic_dma_descriptor_t *descriptor;
+
+	WARN_PRINT("Transmission timed out!\n");
+
+	if (0 == queue_initialized(dev->tx_tail->raw,
+				dev->tx_tail_copy.raw,
+				dev->tx_num_desc)) {
+
+		/*
+		 * If tx_tail is still the same as tx_tail_copy
+		 * then restart the transmission.
+		 */
+		__raw_writel(dev->tx_head.raw,
+					APPNIC_DMA_TX_HEAD_POINTER);
+	} else {
+		/*
+		 * If tx_tail has moved on, just increment tx_tail_copy.
+		 */
+		descriptor = &((dev->tx_desc)
+				[(dev->tx_tail_copy.bits.offset /
+				sizeof(struct appnic_dma_descriptor_t))]);
+		dev->stats.tx_bytes += descriptor->pdu_length;
+
+		kfree((void *)descriptor->host_data_memory_pointer);
+		queue_increment(&dev->tx_tail_copy,
+				dev->tx_num_desc);
+	}
+
+	return;
+}
+
+/*
+ * Whenever an application needs to get statistics for the interface,
+ * this method is called.  This happens, for example, when ifconfig or
+ * nstat -i is run.
+ */
+struct net_device_stats *appnic_get_stats(struct net_device *device)
+{
+	struct appnic_device_t *dev =
+			(struct appnic_device_t *)netdev_priv(device);
+
+	/*
+	 * Update the statistics structure.
+	 */
+	get_hw_statistics(dev);
+
+	return &dev->stats;
+}
+
+static int appnic_do_ioctl(struct net_device *device,
+		struct ifreq *request, int command)
+{
+	int ret = 0;
+	u16 *data = (u16 *)&(request->ifr_data);
+
+	switch (command) {
+	/* Get the speed. */
+	case 0x8946:
+		break;
+
+	/* Get the PHY (defined in 2.5.x kernels) */
+	case 0x89f0:
+		data[0] = phy_address;
+		break;
+
+	/* Read PHY (defined in 2.5.x kernels) */
+	case 0x89f1:
+		if (0 != phy_read(data[0], data[1],
+					&(data[3])))
+			ret = -EIO;
+		break;
+
+	/* Write PHY (defined in 2.5.x kernels) */
+	case 0x89f2:
+		if (0 != phy_write(data[0], data[1], data[2]))
+			ret = -EIO;
+		break;
+
+	default:
+		ERROR_PRINT("Unknown Command: 0x%x\n", command);
+		break;
+	}
+
+	return ret;
+}
+
+static int appnic_set_mac_address(struct net_device *device, void *data)
+{
+	struct sockaddr *address = data;
+	unsigned long swap_source_address;
+
+	if (netif_running(device))
+		return -EBUSY;
+
+	DEBUG_PRINT("Setting MAC to %02x:%02x:%02x:%02x:%02x:%02x\n",
+			address->sa_data[0], address->sa_data[1],
+			address->sa_data[2], address->sa_data[3],
+			address->sa_data[4], address->sa_data[5]);
+
+	swap_source_address =
+		((address->sa_data[4]) << 8) | address->sa_data[5];
+	__raw_writel(swap_source_address, APPNIC_SWAP_SOURCE_ADDRESS_2);
+
+	swap_source_address =
+		((address->sa_data[2]) << 8) | address->sa_data[3];
+	__raw_writel(swap_source_address, APPNIC_SWAP_SOURCE_ADDRESS_1);
+
+	swap_source_address =
+		((address->sa_data[0]) << 8) | address->sa_data[1];
+	__raw_writel(swap_source_address, APPNIC_SWAP_SOURCE_ADDRESS_0);
+
+	memcpy(device->dev_addr, address->sa_data, device->addr_len);
+
+	return 0;
+}
+
+/*
+ * ETHTOOL Operations
+ */
+static int appnic_get_settings(struct net_device *device,
+		struct ethtool_cmd *command)
+{
+	struct appnic_device_t *dev =
+			(struct appnic_device_t *)netdev_priv(device);
+	unsigned short ad_value;
+	int speed, duplex;
+
+	memset(command, 0, sizeof(struct ethtool_cmd));
+
+	/* What the hardware supports. */
+	command->supported =
+		(SUPPORTED_10baseT_Half |
+		  SUPPORTED_10baseT_Full |
+		  SUPPORTED_100baseT_Half |
+		  SUPPORTED_100baseT_Full);
+
+	/* Acquire the device lock. */
+	appnic_special_lock(&dev->lock);
+
+	/* What is currently advertised. */
+	if (0 != phy_read(phy_address, PHY_AUTONEG_ADVERTISE, &ad_value)) {
+		ERROR_PRINT("PHY read failed!");
+		appnic_special_unlock(&dev->lock);
+		return -EIO;
+	}
+
+	switch (ad_value) {
+	case 0x1e1:
+		command->advertising =
+			(ADVERTISED_100baseT_Full | ADVERTISED_100baseT_Half |
+			  ADVERTISED_10baseT_Full | ADVERTISED_10baseT_Half);
+		break;
+
+	case 0xe1:
+		command->advertising =
+			(ADVERTISED_100baseT_Half |
+			  ADVERTISED_10baseT_Full | ADVERTISED_10baseT_Half);
+		break;
+
+	case 0x61:
+		command->advertising =
+			(ADVERTISED_10baseT_Full | ADVERTISED_10baseT_Half);
+		break;
+
+	case 0x41:
+		command->advertising =
+			(ADVERTISED_10baseT_Half);
+		break;
+
+	default:
+		break;
+	}
+
+	/* The current speed. */
+	speed = phy_speed(phy_address);
+	if (-1 == speed) {
+		ERROR_PRINT("PHY read failed!");
+		appnic_special_unlock(&dev->lock);
+		return -EIO;
+	}
+
+	if (1 == speed)
+		command->speed = SPEED_100;
+	else
+		command->speed = SPEED_10;
+
+	/* Is the current link duplex? */
+	duplex = phy_duplex(phy_address);
+	if (-1 == duplex) {
+		ERROR_PRINT("PHY read failed!");
+		appnic_special_unlock(&dev->lock);
+		return -EIO;
+	}
+
+	if (1 == duplex)
+		command->duplex = DUPLEX_FULL;
+	else
+		command->duplex = DUPLEX_HALF;
+
+	/* Is autoneg enabled? */
+	command->autoneg = AUTONEG_ENABLE;
+
+	/* Unlock and return success. */
+	appnic_special_unlock(&dev->lock);
+
+	return 0;
+}
+
+/*
+ * Fill in the struture...
+ */
+static const struct ethtool_ops appnic_ethtool_ops = {
+	.get_settings = appnic_get_settings,
+};
+
+static const struct net_device_ops appnic_netdev_ops = {
+	.ndo_open   = appnic_open,
+	.ndo_stop   = appnic_stop,
+	.ndo_start_xmit = appnic_hard_start_xmit,
+	.ndo_get_stats  = appnic_get_stats,
+	.ndo_do_ioctl   = appnic_do_ioctl,
+	.ndo_set_mac_address    = appnic_set_mac_address,
+	.ndo_tx_timeout         = appnic_tx_timeout,
+};
+
+
+int appnic_setup(struct net_device *device)
+{
+	struct appnic_device_t *dev =
+		(struct appnic_device_t *)netdev_priv(device);
+	struct appnic_dma_descriptor_t *desc;
+	unsigned char ethaddr_string[40];
+	void *dma_offset;
+	int index;
+	unsigned long buf;
+	char *string;
+	char *value;
+	int ret;
+
+	/*
+	 * Reset the MAC
+	 */
+	__raw_writel(0x80000000, APPNIC_DMA_PCI_CONTROL);
+
+	/*
+	 * -- WORKAROUND --
+	 * This is the software work around for defect 15129.  Use 64 byte
+	 * buffers for receive descriptors for all dma.
+	 */
+	if (1 >= (APP3XX_REVISION_REGISTER & 0x1f)) {
+		printk(KERN_INFO "Using work around for defect 15129\n");
+		rx_num_desc = (8 * DESCRIPTOR_GRANULARITY);
+		rx_buf_sz = 32768;
+	}
+
+	/*
+	 * Allocate memory and initialize the descriptors
+	 */
+	if (0 != (rx_num_desc % DESCRIPTOR_GRANULARITY)) {
+
+		WARN_PRINT("rx_num_desc was not a multiple of %d.\n",
+				DESCRIPTOR_GRANULARITY);
+		rx_num_desc += DESCRIPTOR_GRANULARITY -
+				(rx_num_desc % DESCRIPTOR_GRANULARITY);
+	}
+
+	dev->rx_num_desc = rx_num_desc;
+
+	if (0 != (tx_num_desc % DESCRIPTOR_GRANULARITY)) {
+
+		WARN_PRINT("tx_num_desc was not a multiple of %d.\n",
+				DESCRIPTOR_GRANULARITY);
+		tx_num_desc += DESCRIPTOR_GRANULARITY -
+				(tx_num_desc % DESCRIPTOR_GRANULARITY);
+	}
+
+	dev->tx_num_desc = tx_num_desc;
+
+	DEBUG_PRINT("rx_num_desc=%d tx_num_desc=%d\n",
+				rx_num_desc, tx_num_desc);
+
+	/*
+	 * Fix up [rt]x_buf_sz.  Must be some multiple of
+	 * 64 bytes per descriptor.
+	 */
+	if (0 != (rx_buf_sz % (BUFFER_ALIGNMENT * rx_num_desc))) {
+
+		WARN_PRINT("rx_buf_sz was not a multiple of %d.\n",
+				(BUFFER_ALIGNMENT * rx_num_desc));
+		rx_buf_sz +=
+			(BUFFER_ALIGNMENT * rx_num_desc) -
+			(rx_buf_sz % (BUFFER_ALIGNMENT *
+			rx_num_desc));
+	}
+
+	dev->rx_buf_sz = rx_buf_sz;
+
+	if (0 != (tx_buf_sz % (BUFFER_ALIGNMENT * tx_num_desc))) {
+
+		WARN_PRINT("tx_buf_sz was not a multiple of %d.\n",
+				(BUFFER_ALIGNMENT * tx_num_desc));
+		tx_buf_sz +=
+			(BUFFER_ALIGNMENT * tx_num_desc) -
+			(tx_buf_sz % (BUFFER_ALIGNMENT *
+			tx_num_desc));
+
+	}
+
+	dev->tx_buf_sz = tx_buf_sz;
+
+	DEBUG_PRINT("rx_buf_sz=%d tx_buf_sz=%d\n",
+			rx_buf_sz, tx_buf_sz);
+
+	/*
+	 * Allocate dma-able memory
+	 */
+	dev->dma_alloc_size =
+		/* The tail pointers (rx and tx) */
+		(sizeof(union appnic_queue_pointer_t) * 2) +
+		/* The RX descriptor ring (and padding to allow
+		   64 byte alignment) */
+		(sizeof(struct appnic_dma_descriptor_t) *
+		  dev->rx_num_desc) +
+		(DESCRIPTOR_GRANULARITY) +
+		/* The TX descriptor ring (and padding...) */
+		(sizeof(struct appnic_dma_descriptor_t) *
+		 dev->tx_num_desc) +
+		(DESCRIPTOR_GRANULARITY) +
+		/* The RX buffer (and padding...) */
+		(dev->rx_buf_sz) + (BUFFER_ALIGNMENT) +
+		/* The TX buffer (and padding...) */
+		(dev->tx_buf_sz) + (BUFFER_ALIGNMENT);
+
+	dev->dma_alloc = (void *)dma_alloc_coherent(NULL,
+		dev->dma_alloc_size, &dev->dma_alloc_dma, GFP_KERNEL);
+
+	if (!dev->dma_alloc) {
+		ERROR_PRINT("Could not allocate %d bytes of "
+			"DMA-able memory!\n",
+			dev->dma_alloc_size);
+		return -ENOMEM;
+	} else
+		dev->dma_alloc_offset = (dma_addr_t)dev->dma_alloc -
+			dev->dma_alloc_dma;
+
+	dma_offset = dev->dma_alloc;
+
+	DEBUG_PRINT("Allocated %d bytes at 0x%08lx(0x%08lx),"
+		"offset=0x%x.\n",
+		dev->dma_alloc_size,
+		(unsigned long)dev->dma_alloc,
+		(unsigned long)dev->dma_alloc_dma,
+		dev->dma_alloc_offset);
+
+	/*
+	 * Initialize the tail pointers
+	 */
+	dev->rx_tail = (union appnic_queue_pointer_t *)dma_offset;
+	dev->rx_tail_dma = (dma_addr_t)dev->rx_tail -
+		dev->dma_alloc_offset;
+	dma_offset += sizeof(union appnic_queue_pointer_t);
+
+	memset((void *) dev->rx_tail, 0,
+			sizeof(union appnic_queue_pointer_t));
+
+	DEBUG_PRINT("rx_tail=0x%08lx\n",
+			(unsigned long)dev->rx_tail);
+
+	dev->tx_tail = (union appnic_queue_pointer_t *)dma_offset;
+	dev->tx_tail_dma = (dma_addr_t)dev->tx_tail -
+			dev->dma_alloc_offset;
+	dma_offset += sizeof(union appnic_queue_pointer_t);
+
+	memset((void *)dev->tx_tail, 0,
+			sizeof(union appnic_queue_pointer_t));
+
+	DEBUG_PRINT("tx_tail=0x%08lx\n",
+			(unsigned long)dev->tx_tail);
+
+	/*
+	 * Initialize the descriptor pointers
+	 */
+	dev->rx_desc = (struct appnic_dma_descriptor_t *)
+		ALIGN64B(dma_offset);
+	dev->rx_desc_dma = (dma_addr_t)dev->rx_desc -
+		dev->dma_alloc_offset;
+	dma_offset += (sizeof(struct appnic_dma_descriptor_t) *
+			dev->rx_num_desc) + (DESCRIPTOR_GRANULARITY);
+
+	memset((void *)dev->rx_desc, 0,
+			(sizeof(struct appnic_dma_descriptor_t) *
+			  dev->rx_num_desc));
+
+	dev->tx_desc = (struct appnic_dma_descriptor_t *)
+		ALIGN64B(dma_offset);
+	dev->tx_desc_dma = (dma_addr_t) dev->tx_desc -
+		dev->dma_alloc_offset;
+	dma_offset += (sizeof(struct appnic_dma_descriptor_t) *
+			dev->tx_num_desc) + (DESCRIPTOR_GRANULARITY);
+
+	memset((void *)dev->tx_desc, 0,
+		(sizeof(struct appnic_dma_descriptor_t) *
+		  dev->tx_num_desc));
+
+	/*
+	 * Initialize the buffer pointers
+	 */
+	dev->rx_buf = (void *)ALIGN64B(dma_offset);
+	dev->rx_buf_dma = (dma_addr_t) dev->rx_buf -
+		dev->dma_alloc_offset;
+	dev->rx_buf_per_desc = dev->rx_buf_sz / dev->rx_num_desc;
+
+	dma_offset += (dev->rx_buf_sz) + (BUFFER_ALIGNMENT);
+
+	dev->tx_buf = (void *)ALIGN64B(dma_offset);
+	dev->tx_buf_dma = (dma_addr_t) dev->tx_buf -
+		dev->dma_alloc_offset;
+	dev->tx_buf_per_desc = dev->tx_buf_sz / dev->tx_num_desc;
+	dma_offset += (dev->tx_buf_sz) + (BUFFER_ALIGNMENT);
+
+	/*
+	 * Initialize the descriptors
+	 */
+	buf = (unsigned long)dev->rx_buf_dma;
+
+	for (index = 0; index < dev->rx_num_desc; ++index) {
+		desc = &(dev->rx_desc[index]);
+		desc->write = 1;
+		desc->interrupt_on_completion = 1;
+		desc->host_data_memory_pointer = buf;
+		desc->data_transfer_length =
+			dev->rx_buf_per_desc;
+		buf += dev->rx_buf_per_desc;
+	}
+
+	buf = (unsigned long)dev->tx_buf_dma;
+
+	for (index = 0; index < dev->tx_num_desc; ++index) {
+		desc = &(dev->tx_desc[index]);
+		desc->write = 1;
+		desc->interrupt_on_completion = 1;
+		desc->host_data_memory_pointer = buf;
+			buf += dev->tx_buf_per_desc;
+	}
+
+	/*
+	 * Initialize the spin lock.
+	 */
+	spin_lock_init(&dev->lock);
+	spin_lock_init(&dev->extra_lock);
+
+	/*
+	 * Initialize the semaphores
+	 */
+	init_MUTEX(&dev->rx_sem);
+	init_MUTEX(&dev->tx_sem);
+	init_MUTEX(&dev->poll_sem);
+
+	/*
+	 *  Take MAC out of reset
+	 */
+	__raw_writel(0x0, APPNIC_RX_SOFT_RESET);
+	__raw_writel(0x1, APPNIC_RX_MODE);
+	__raw_writel(0x0, APPNIC_TX_SOFT_RESET);
+	__raw_writel(0x1, APPNIC_TX_MODE);
+	__raw_writel(0x300a, APPNIC_TX_WATERMARK);
+	__raw_writel(0x1, APPNIC_TX_HALF_DUPLEX_CONF);
+	__raw_writel(0xffff, APPNIC_TX_TIME_VALUE_CONF);
+	__raw_writel(0x1, APPNIC_TX_INTERRUPT_CONTROL);
+	__raw_writel(0x5275, APPNIC_TX_EXTENDED_CONF);
+	__raw_writel(0x1, APPNIC_RX_INTERNAL_INTERRUPT_CONTROL);
+	__raw_writel(0x1, APPNIC_RX_EXTERNAL_INTERRUPT_CONTROL);
+	__raw_writel(0x40010000, APPNIC_DMA_PCI_CONTROL);
+	__raw_writel(0x30000, APPNIC_DMA_CONTROL);
+
+	/*
+	 *  Set the MAC address
+	 */
+	if (0 != ubootenv_get("ethaddr", ethaddr_string)) {
+		ERROR_PRINT("Could not read ethernet address!\n");
+		ret = -EBUSY;
+		goto free;
+	} else {
+		string = ethaddr_string;
+
+		while ((0 != string) && (6 > index)) {
+			value = strsep(&string, ":");
+			device->dev_addr[index++] =
+				simple_strtoul(value, NULL, 16);
+
+		}
+
+		device->addr_len = 6;
+	}
+
+	__raw_writel(((device->dev_addr[4]) << 8) |
+			(device->dev_addr[5]),
+			APPNIC_SWAP_SOURCE_ADDRESS_2);
+	__raw_writel(((device->dev_addr[2]) << 8) |
+			(device->dev_addr[3]),
+			APPNIC_SWAP_SOURCE_ADDRESS_1);
+	__raw_writel(((device->dev_addr[0]) << 8) |
+			(device->dev_addr[1]),
+			APPNIC_SWAP_SOURCE_ADDRESS_0);
+
+	/*
+	 * Initialize the queue pointers.
+	 */
+
+	/*
+	 * Receiver
+	 */
+	memset((void *)&dev->rx_tail_copy,
+			0, sizeof(union appnic_queue_pointer_t));
+	memset((void *)&dev->rx_head,
+			0, sizeof(union appnic_queue_pointer_t));
+
+	__raw_writel(dev->rx_desc_dma, APPNIC_DMA_RX_QUEUE_BASE_ADDRESS);
+	__raw_writel((dev->rx_num_desc *
+				sizeof(struct appnic_dma_descriptor_t)) / 1024,
+			APPNIC_DMA_RX_QUEUE_SIZE);
+
+	/* indicate that all of the receive descriptors are ready */
+	dev->rx_head.bits.offset =
+		(dev->rx_num_desc - 1) * sizeof(struct appnic_dma_descriptor_t);
+	__raw_writel(dev->rx_tail_dma, APPNIC_DMA_RX_TAIL_POINTER_ADDRESS);
+
+	/*
+	 * N.B.
+	 * The boot loader may have used the NIC.  If so, the
+	 * tail pointer must be read and the head pointer (and
+	 * local copy of the tail) based on it.
+	 */
+	dev->rx_tail->raw =
+		__raw_readl(APPNIC_DMA_RX_TAIL_POINTER_LOCAL_COPY);
+	dev->rx_tail_copy.raw = dev->rx_tail->raw;
+	dev->rx_head.raw = dev->rx_tail->raw;
+	queue_decrement(&dev->rx_head, dev->rx_num_desc);
+	dev->rx_head.bits.generation_bit =
+		(0 == dev->rx_head.bits.generation_bit) ? 1 : 0;
+	__raw_writel(dev->rx_head.raw, APPNIC_DMA_RX_HEAD_POINTER);
+
+	/*
+	 *  Transmitter
+	 */
+	memset((void *)&dev->tx_tail_copy,
+			0, sizeof(union appnic_queue_pointer_t));
+	memset((void *)&dev->tx_head,
+			0, sizeof(union appnic_queue_pointer_t));
+
+	__raw_writel(dev->tx_desc_dma,
+			APPNIC_DMA_TX_QUEUE_BASE_ADDRESS);
+	__raw_writel((dev->tx_num_desc *
+				sizeof(struct appnic_dma_descriptor_t)) / 1024,
+			APPNIC_DMA_TX_QUEUE_SIZE);
+
+	DEBUG_PRINT("Writing 0x%x to "
+			"APPNIC_DMA_TX_TAIL_POINTER_ADDRESS\n",
+			dev->tx_tail_dma);
+
+	__raw_writel(dev->tx_tail_dma,
+			APPNIC_DMA_TX_TAIL_POINTER_ADDRESS);
+
+	/*
+	 * N.B.
+	 * The boot loader may have used the NIC.  If so, the
+	 * tail pointer must be read and the head pointer (and
+	 * local copy of the tail) based on it.
+	 */
+
+	dev->tx_tail->raw =
+		__raw_readl(APPNIC_DMA_TX_TAIL_POINTER_LOCAL_COPY);
+	dev->tx_tail_copy.raw = dev->tx_tail->raw;
+	dev->tx_head.raw = dev->tx_tail->raw;
+	__raw_writel(dev->tx_head.raw, APPNIC_DMA_TX_HEAD_POINTER);
+
+	/* clear statistics */
+	clear_statistics(dev);
+
+
+	/* initialize the PHY */
+	if (0 != phy_enable(phy_address))
+		WARN_PRINT("Failed to initialize the PHY!\n");
+
+
+	/* fill in the net_device structure */
+
+	ether_setup(device);
+	device->netdev_ops	= &appnic_netdev_ops;
+	device->ethtool_ops	= &appnic_ethtool_ops;
+
+	ret = register_netdev(device);
+	if (ret)
+		goto free;
+
+	return 0;
+
+free:
+	dma_free_coherent(NULL, dev->dma_alloc_size,
+			dev->dma_alloc, dev->dma_alloc_dma);
+
+	return ret;
+}
+
+static int __devinit appnic_probe(struct platform_device *pdev)
+{
+	struct net_device *ndev;
+	struct appnic_device_t *priv;
+	struct resource *res;
+	unsigned long size;
+	int i, ret;
+
+	ndev = alloc_etherdev(sizeof(struct appnic_device_t));
+	if (!ndev)
+		ret = -ENOMEM;
+
+	SET_NETDEV_DEV(ndev, &pdev->dev);
+
+	priv = netdev_priv(ndev);
+
+	for (i = 0; i < pdev->num_resources - 1; i++) {
+		res = platform_get_resource(pdev, IORESOURCE_MEM, i);
+		size = res->end - res->start + 1;
+
+		res = request_mem_region(res->start, size, "appnic");
+		if (!res) {
+			ret = -EBUSY;
+			goto release;
+		}
+	}
+
+	ndev->irq = platform_get_irq(pdev, 0);
+
+	platform_set_drvdata(pdev, ndev);
+
+	ret = appnic_setup(ndev);
+	if (ret)
+		goto release;
+
+	return 0;
+
+release:
+	for (; i >= 0; i--) {
+		res = platform_get_resource(pdev, IORESOURCE_MEM, i);
+		size = res->end - res->start + 1;
+		release_mem_region(res->start, size);
+	}
+
+	kfree(ndev);
+
+	return ret;
+}
+
+static int __devexit appnic_remove(struct platform_device *pdev)
+{
+	struct net_device *ndev = platform_get_drvdata(pdev);
+	struct appnic_device_t *priv =
+		(struct appnic_device_t *)netdev_priv(ndev);
+	struct resource *res;
+	unsigned long size;
+	int i;
+
+	for (i = 0; i < pdev->num_resources - 1; i++) {
+		res = platform_get_resource(pdev, IORESOURCE_MEM, i);
+		size = res->end - res->start + 1;
+
+		release_mem_region(res->start, size);
+	}
+
+	if (priv->dma_alloc)
+		dma_free_coherent(NULL, priv->dma_alloc_size,
+			priv->dma_alloc, priv->dma_alloc_dma);
+
+	unregister_netdev(ndev);
+
+	kfree(ndev);
+
+	return 0;
+}
+
+static struct platform_driver appnic_drv = {
+	.probe = appnic_probe,
+	.remove = __devexit_p(appnic_remove),
+	.driver = {
+		.name = APPNIC_NAME,
+	},
+};
+
+static int __init appnic_init(void)
+{
+	return platform_driver_register(&appnic_drv);
+}
+
+static void __exit appnic_exit(void)
+{
+	platform_driver_unregister(&appnic_drv);
+}
+
+module_init(appnic_init);
+module_exit(appnic_exit);
+
+MODULE_AUTHOR("John Jacques");
+MODULE_DESCRIPTION("Agere APP3xx ethernet driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/net/arm/appnic.h b/drivers/net/arm/appnic.h
new file mode 100644
index 0000000..2ded0ec
--- /dev/null
+++ b/drivers/net/arm/appnic.h
@@ -0,0 +1,626 @@
+/*
+ * appnic.h
+ *
+ * Copyright (C) 2007 Agere Systems
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#ifndef __APPNIC_H
+#define __APPNIC_H
+
+#include <mach/io.h>
+#include <mach/hardware.h>
+
+#if defined(DEBUG)
+#define DEBUG_PRINT(format, args...) do { \
+	printk(KERN_DEBUG "appnic:%d - DEBUG - ", __LINE__); \
+	printk(KERN_DEBUG format, ##args); \
+} while (0);
+#else
+#define DEBUG_PRINT(format, args...)
+#endif
+
+#if defined(PHY_DEBUG)
+#define PHY_DEBUG_PRINT(format, args...) do { \
+	printk(KERN_DEBUG "nic:%d - PHY_DEBUG - ", __LINE__); \
+	printk(KERN_DEBUG format, ##args); \
+} while (0);
+#else
+#define PHY_DEBUG_PRINT(format, args...)
+#endif
+
+#if defined(WARN)
+#define WARN_PRINT(format, args...) do { \
+	printk(KERN_WARNING "appnic:%d - WARN - ", __LINE__); \
+	printk(KERN_WARNING format, ##args); \
+} while (0);
+#else
+#define WARN_PRINT(format, args...)
+#endif
+
+#define ERROR_PRINT(format, args...) do { \
+	printk(KERN_ERR "%s:%s:%d - ERROR - ", __FILE__, __func__, __LINE__); \
+	printk(KERN_ERR format, ##args); \
+} while (0);
+
+#define APPNIC_NAME "appnic"
+
+#define DEFAULT_TX_TIMEOUT 10
+
+#define APPNIC_TIMER_PERIOD 5
+
+/* MDIO Registers */
+#ifdef CONFIG_ARCH_APP3K
+#define MDIO_DATA	(APP_AEI_BASE + 0x28)
+#define MDIO_CLK	(APP_AEI_BASE + 0x30)
+#define MDIO_CMD	(APP_AEI_BASE + 0x24)
+#define MDIO_STAT	(APP_AEI_BASE + 0x2c)
+#endif
+
+/*MDIO Command Register*/
+#define MDIO_CMDTYPE_INACTIVE	0x1
+#define MDIO_CMDTYPE_MDIO		0x2
+
+#define MDIO_CMDOP_READ			0x4
+#define MDIO_CMDOP_WRITE		0x8
+
+/*MDIO Status Register*/
+
+#define MDIO_STATACK	0x1
+#define MDIO_STATERR	0x2
+
+/*PHY types*/
+#define PHY_ADDRESS	-1
+#define UNKNOWN_PHY	0x0
+#define BCM5221_PHY	0x1
+#define MICREL_PHY	0x2
+
+#define DESCRIPTOR_GRANULARITY 64
+#define BUFFER_ALIGNMENT 64
+
+#define ALIGN64B(address) \
+	((((unsigned long)(address) + (64UL - 1UL)) & ~(64UL - 1UL)))
+
+#define ALIGN64B_OFFSET(address) \
+	(ALIGN64B(address) - (unsigned long)(address))
+
+#define APP3K_NIC_NAME "app3k_nic"
+
+/*
+ * Overview
+ * --------
+ *
+ * Register offset decoding is as follows:
+ *
+ * Bit(s) Description
+
+ * 16:15  define the Channel.  There is only one; therefore, 00.
+ * 14:12  define the MAC within the channel.  Only one so 000.
+ * 11:10  define the register "space" as follows:
+ * 00 = fast ethernet MAC
+ * 10 = global
+ * 11 = interrupt
+ * 9: 2  register
+ * 1: 0  always 00, 32 bit registers only.
+
+ * Receive registers start at the base address.  Transmit registers start
+ * at 0x20000 above the base address.  DMA start at a completely different
+ * base address (in this case 0x8000000 above the base).
+ */
+
+/*
+ * Registers.
+ */
+
+/*SMII Status*/
+
+#define APPNIC_RX_SMII_STATUS			(APP3XX_NIC_RX_BASE + 0x10)
+#define APPNIC_RX_SMII_STATUS_SPEED		0x01
+#define APPNIC_RX_SMII_STATUS_DUPLEX	0x02
+#define APPNIC_RX_SMII_STATUS_LINK		0x04
+#define APPNIC_RX_SMII_STATUS_JABBER	0x08
+#define APPNIC_RX_SMII_STATUS_FCD		0x10 /* False Carrier Detect */
+
+#define SMII_SPEED_100(smii_status) \
+	(0 != (smii_status & APPNIC_RX_SMII_STATUS_SPEED))
+#define SMII_DUPLEX(smii_status) \
+	(0 != (smii_status & APPNIC_RX_SMII_STATUS_DUPLEX))
+#define SMII_LINK(smii_status) \
+	(0 != (smii_status & APPNIC_RX_SMII_STATUS_LINK))
+#define SMII_JABBER(smii_status) \
+	(0 != (smii_status & APPNIC_RX_SMII_STATUS_JABBER))
+
+/*Receive Configuration*/
+
+#define APPNIC_RX_CONF          (APP3XX_NIC_RX_BASE + 0x004c)
+#define APPNIC_RX_CONF_ENABLE   0x0001
+/* Pass Any Packet */
+#define APPNIC_RX_CONF_PAP      0x0002
+#define APPNIC_RX_CONF_JUMBO9K  0x0008
+#define APPNIC_RX_CONF_STRIPCRC 0x0010
+/* Accept All MAC Types */
+#define APPNIC_RX_CONF_AMT      0x0020
+/* Accept Flow Control */
+#define APPNIC_RX_CONF_AFC      0x0040
+/* Enable VLAN */
+#define APPNIC_RX_CONF_VLAN     0x0200
+/* RX MAC Speed, 1=100MBS */
+#define APPNIC_RX_CONF_SPEED    0x0800
+/* 1=Duplex Mode */
+#define APPNIC_RX_CONF_DUPLEX   0x1000
+/* 1=Enable */
+#define APPNIC_RX_CONF_LINK     0x2000
+/* Determines the action taken when the FE MAC
+   receives an FC packet in FD mode.*/
+#define APPNIC_RX_CONF_RXFCE    0x4000
+/* Controls the insertion of FC packets
+   by the MAC transmitter. */
+#define APPNIC_RX_CONF_TXFCE    0x8000
+
+/*Receive Stat Overflow*/
+#define APPNIC_RX_STAT_OVERFLOW (APP3XX_NIC_RX_BASE + 0x278)
+
+/*Receive Stat Undersize*/
+#define APPNIC_RX_STAT_UNDERSIZE (APP3XX_NIC_RX_BASE + 0x280)
+
+/*Receive Stat Oversize*/
+
+#define APPNIC_RX_STAT_OVERSIZE (APP3XX_NIC_RX_BASE + 0x2b8)
+
+/*Receive Stat Multicast*/
+#define APPNIC_RX_STAT_MULTICAST (APP3XX_NIC_RX_BASE + 0x2d0)
+
+/*Receive Stat Packet OK*/
+#define APPNIC_RX_STAT_PACKET_OK (APP3XX_NIC_RX_BASE + 0x2c0)
+
+/*Receive Stat CRC Error*/
+#define APPNIC_RX_STAT_CRC_ERROR (APP3XX_NIC_RX_BASE + 0x2c8)
+
+/*Receive Stat Align Error*/
+#define APPNIC_RX_STAT_ALIGN_ERROR (APP3XX_NIC_RX_BASE + 0x2e8)
+
+/*Receive Ethernet Mode*/
+#define APPNIC_RX_MODE (APP3XX_NIC_RX_BASE + 0x0800)
+#define APPNIC_RX_MODE_ETHERNET_MODE_ENABLE 0x00001
+
+/*Receive Soft Reset*/
+#define APPNIC_RX_SOFT_RESET (APP3XX_NIC_RX_BASE + 0x0808)
+#define APPNIC_RX_SOFT_RESET_MAC_0 0x00001
+
+/*Receive Internal Interrupt Control*/
+#define APPNIC_RX_INTERNAL_INTERRUPT_CONTROL (APP3XX_NIC_RX_BASE + 0xc00)
+#define APPNIC_RX_INTERNAL_INTERRUPT_CONTROL_MAC_0 0x1
+
+/*Receive External Interrupt Control*/
+#define APPNIC_RX_EXTERNAL_INTERRUPT_CONTROL (APP3XX_NIC_RX_BASE + 0xc04)
+#define APPNIC_RX_EXTERNAL_INTERRUPT_CONTROL_MAC_0_HIGH_LOW 0x10
+#define APPNIC_RX_EXTERNAL_INTERRUPT_CONTROL_MAC_0 0x1
+
+/*Receive Interrupt Status*/
+#define APPNIC_RX_INTERRUPT_STATUS (APP3XX_NIC_RX_BASE + 0xc20)
+#define APPNIC_RX_INTERRUPT_EXTERNAL_STATUS_MAC_0 0x10
+#define APPNIC_RX_INTERRUPT_INTERNAL_STATUS_MAC_0 0x1
+
+/*Transmit Watermark*/
+#define APPNIC_TX_WATERMARK (APP3XX_NIC_TX_BASE + 0x18)
+#define APPNIC_TX_WATERMARK_TXCONFIG_DTPA_ASSERT 0x8000
+#define APPNIC_TX_WATERMARK_TXCONFIG_DTPA_DISABLE 0x4000
+#define APPNIC_TX_WATERMARK_TXCONFIG_DTPA_WATER_MARK_HIGH 0x3f00
+#define APPNIC_TX_WATERMARK_TXCONFIG_DTPA_WATER_MARK_LOW 0x3f
+
+/*Swap Source Address Registers*/
+#define APPNIC_SWAP_SOURCE_ADDRESS_2 (APP3XX_NIC_TX_BASE + 0x20)
+#define APPNIC_SWAP_SOURCE_ADDRESS_1 (APP3XX_NIC_TX_BASE + 0x24)
+#define APPNIC_SWAP_SOURCE_ADDRESS_0 (APP3XX_NIC_TX_BASE + 0x28)
+
+/*Transmit Extended Configuration*/
+#define APPNIC_TX_EXTENDED_CONF (APP3XX_NIC_TX_BASE + 0x30)
+#define APPNIC_TX_EXTENDED_CONF_TRANSMIT_COLLISION_WATERMARK_LEVEL 0xf000
+#define APPNIC_TX_EXTENDED_CONF_EXCESSIVE_DEFFERED_PACKET_DROP 0x200
+#define APPNIC_TX_EXTENDED_CONF_JUMBO9K 0x100
+#define APPNIC_TX_EXTENDED_CONF_LATE_COLLISION_WINDOW_COUNT 0xff
+
+/*Transmit Half Duplex Configuration*/
+#define APPNIC_TX_HALF_DUPLEX_CONF (APP3XX_NIC_TX_BASE + 0x34)
+#define APPNIC_TX_HALF_DUPLEX_CONF_RANDOM_SEED_VALUE 0xff
+
+/*Transmit Configuration*/
+#define APPNIC_TX_CONF (APP3XX_NIC_TX_BASE + 0x0050)
+#define APPNIC_TX_CONF_ENABLE_SWAP_SA 0x8000
+#define APPNIC_TX_CONF_LINK           0x2000
+#define APPNIC_TX_CONF_DUPLEX         0x1000
+#define APPNIC_TX_CONF_SPEED          0x0800
+#define APPNIC_TX_CONF_XBK_RST_RX_NTX 0x0600
+#define APPNIC_TX_CONF_IFG            0x01f0
+#define APPNIC_TX_CONF_APP_CRC_ENABLE 0x0004
+#define APPNIC_TX_CONF_PAD_ENABLE     0x0002
+#define APPNIC_TX_CONF_ENABLE         0x0001
+
+#define TX_CONF_SET_IFG(tx_configuration, ifg) do { \
+	(tx_configuration) &= ~APPNIC_TX_CONF_IFG; \
+	(tx_configuration) |= ((ifg & 0x1f) << 4); \
+} while (0);
+
+/*Transmit Time Value Configuration*/
+#define APPNIC_TX_TIME_VALUE_CONF (APP3XX_NIC_TX_BASE + 0x5c)
+#define APPNIC_TX_TIME_VALUE_CONF_PAUSE_VALUE 0xffff
+
+/*Transmit Stat Underrun*/
+#define APPNIC_TX_STAT_UNDERRUN (APP3XX_NIC_TX_BASE + 0x300)
+
+/*Transmit Stat Packet OK*/
+#define APPNIC_TX_STAT_PACKET_OK (APP3XX_NIC_TX_BASE + 0x318)
+
+/*Transmit Stat Undersize*/
+#define APPNIC_TX_STAT_UNDERSIZE (APP3XX_NIC_TX_BASE + 0x350)
+
+/*Transmit Status Late Collision*/
+#define APPNIC_TX_STATUS_LATE_COLLISION (APP3XX_NIC_TX_BASE + 0x368)
+
+/*Transmit Status Excessive Collision*/
+#define APPNIC_TX_STATUS_EXCESSIVE_COLLISION (APP3XX_NIC_TX_BASE + 0x370)
+
+/*Transmit Stat Collision Above Watermark*/
+#define APPNIC_TX_STAT_COLLISION_ABOVE_WATERMARK (APP3XX_NIC_TX_BASE + 0x380)
+
+/*Transmit Mode*/
+#define APPNIC_TX_MODE (APP3XX_NIC_TX_BASE + 0x800)
+#define APPNIC_TX_MODE_ETHERNET_MODE_ENABLE 0x1
+
+/*Transmit Soft Reset*/
+#define APPNIC_TX_SOFT_RESET (APP3XX_NIC_TX_BASE + 0x808)
+#define APPNIC_TX_SOFT_RESET_MAC_0 0x1
+
+/*Transmit Interrupt Control*/
+#define APPNIC_TX_INTERRUPT_CONTROL (APP3XX_NIC_TX_BASE + 0xc00)
+#define APPNIC_TX_INTERRUPT_CONTROL_MAC_0 0x1
+
+/*Transmit Interrupt Status*/
+#define APPNIC_TX_INTERRUPT_STATUS (APP3XX_NIC_TX_BASE + 0xc20)
+#define APPNIC_TX_INTERRUPT_STATUS_MAC_0 0x1
+
+#define APPNIC_DMA_PCI_CONTROL (APP3XX_NIC_DMA_BASE + 0x00)
+#define APPNIC_DMA_CONTROL (APP3XX_NIC_DMA_BASE + 0x08)
+
+/*DMA Interrupt Status*/
+#define APPNIC_DMA_INTERRUPT_STATUS (APP3XX_NIC_DMA_BASE + 0x18)
+#define APPNIC_DMA_INTERRUPT_STATUS_RX 0x2
+#define APPNIC_DMA_INTERRUPT_STATUS_TX 0x1
+
+#define RX_INTERRUPT(dma_interrupt_status) \
+	(0 != (dma_interrupt_status & APPNIC_DMA_INTERRUPT_STATUS_RX))
+#define TX_INTERRUPT(dma_interrupt_status) \
+	(0 != (dma_interrupt_status & APPNIC_DMA_INTERRUPT_STATUS_TX))
+
+/*DMA Interrupt Enable*/
+
+#define APPNIC_DMA_INTERRUPT_ENABLE (APP3XX_NIC_DMA_BASE + 0x1c)
+#define APPNIC_DMA_INTERRUPT_ENABLE_RECEIVE 0x2
+#define APPNIC_DMA_INTERRUPT_ENABLE_TRANSMIT 0x1
+
+/*DMA Receive Queue Base Address*/
+#define APPNIC_DMA_RX_QUEUE_BASE_ADDRESS (APP3XX_NIC_DMA_BASE + 0x30)
+
+/*DMA Receive Queue Size*/
+#define APPNIC_DMA_RX_QUEUE_SIZE (APP3XX_NIC_DMA_BASE + 0x34)
+
+/*DMA Transmit Queue Base Address*/
+#define APPNIC_DMA_TX_QUEUE_BASE_ADDRESS (APP3XX_NIC_DMA_BASE + 0x38)
+
+/*DMA Transmit Queue Size*/
+#define APPNIC_DMA_TX_QUEUE_SIZE (APP3XX_NIC_DMA_BASE + 0x3c)
+
+/*DMA Recevie Tail Pointer Address*/
+#define APPNIC_DMA_RX_TAIL_POINTER_ADDRESS (APP3XX_NIC_DMA_BASE + 0x48)
+
+/*DMA Transmit Tail Pointer Address*/
+#define APPNIC_DMA_TX_TAIL_POINTER_ADDRESS (APP3XX_NIC_DMA_BASE + 0x4c)
+
+/*DMA Receive Head Pointer*/
+#define APPNIC_DMA_RX_HEAD_POINTER (APP3XX_NIC_DMA_BASE + 0x50)
+#define APPNIC_DMA_RX_HEAD_POINTER_GB      0x100000
+#define APPNIC_DMA_RX_HEAD_POINTER_POINTER 0x0fffff
+
+/*DMA Receive Tail Pointer Local Copy*/
+#define APPNIC_DMA_RX_TAIL_POINTER_LOCAL_COPY (APP3XX_NIC_DMA_BASE + 0x54)
+#define APPNIC_DMA_RX_TAIL_POINTER_LOCAL_COPY_GB      0x100000
+#define APPNIC_DMA_RX_TAIL_POINTER_LOCAL_COPY_POINTER 0x0fffff
+
+/*DMA Transmit Head Pointer*/
+#define APPNIC_DMA_TX_HEAD_POINTER (APP3XX_NIC_DMA_BASE + 0x58)
+#define APPNIC_DMA_TX_HEAD_POINTER_GB      0x100000
+#define APPNIC_DMA_TX_HEAD_POINTER_POINTER 0x0fffff
+
+/*DMA Transmit Tail Pointer Local Copy*/
+#define APPNIC_DMA_TX_TAIL_POINTER_LOCAL_COPY (APP3XX_NIC_DMA_BASE + 0x5c)
+#define APPNIC_DMA_TX_TAIL_POINTER_LOCAL_COPY_GB      0x100000
+#define APPNIC_DMA_TX_TAIL_POINTER_LOCAL_COPY_POINTER 0x0fffff
+
+
+/*PHY Registers*/
+/*control*/
+#define PHY_CONTROL		0x00
+
+union bc_phy_control_t {
+	unsigned short raw;
+
+	struct {
+		unsigned short:7;
+		unsigned short collision_test:1;
+		unsigned short full_duplex:1;
+		unsigned short restart_autoneg:1;
+		unsigned short isolate:1;
+		unsigned short power_down:1;
+		unsigned short autoneg_enable:1;
+		unsigned short force100:1;
+		unsigned short loop_back:1;
+		unsigned short soft_reset:1;
+	} __attribute__ ((packed)) bits;
+} __attribute__ ((packed));
+
+
+/*status*/
+#define PHY_STATUS 0x01
+
+union phy_status_t {
+	unsigned short raw;
+	struct {
+		unsigned short extd_reg_capable:1;
+		unsigned short jabber_detect:1;
+		unsigned short link_status:1;
+		unsigned short autoneg_capable:1;
+		unsigned short remote_fault:1;
+		unsigned short autoneg_comp:1;
+		unsigned short mf_pream_suppress:1;
+		unsigned short pads:4;
+		unsigned short tenbt_capable:1;
+		unsigned short bt_fdx_capable:1;
+		unsigned short tx_capable:1;
+		unsigned short tx_fdx_capable:1;
+		unsigned short t4_capable:1;
+	} __attribute__ ((packed)) bits;
+} __attribute__ ((packed));
+
+/*id_high*/
+#define PHY_ID_HIGH 0x02
+
+union phy_id_high_t {
+	unsigned short raw;
+	struct {
+		unsigned short id:16;
+	} __attribute__ ((packed)) bits;
+} __attribute__ ((packed));
+
+#define BC_PHY_ID_HIGH_ID	0x40
+#define M_PHY_ID_HIGH_ID	0x22
+
+/*id_low*/
+#define PHY_ID_LOW	0x03
+
+union phy_id_low_t {
+	unsigned short raw;
+	struct {
+		unsigned short revision:4;
+		unsigned short model:6;
+		unsigned short id:6;
+	} __attribute__ ((packed)) bits;
+} __attribute__ ((packed));
+
+#define BC_PHY_ID_LOW_ID		0x18
+#define BC_PHY_ID_LOW_MODEL		0x1e
+#define M_PHY_ID_LOW_ID			0x05
+#define M_PHY_ID_LOW_MODEL		0x20
+
+/*autoneg_advertise*/
+#define PHY_AUTONEG_ADVERTISE	0x04
+
+/*link_partner_ability*/
+#define PHY_LINK_PARTNER_ABILITY	0x05
+
+/*autoneg_expansion*/
+#define PHY_AUTONEG_EXPANSION		0x06
+
+#define PHY_AUXILIARY_CONTROL_STATUS	0x18
+
+union bc_phy_auxiliary_control_status_t {
+	unsigned short raw;
+	struct {
+		unsigned short full_duplex:1;
+		unsigned short speed:1;
+		unsigned short force_speed:1;
+		unsigned short autoneg_indication:1;
+		unsigned short edge_rate:2;
+		unsigned short hsq_lsq:2;
+		unsigned short pads:6;
+		unsigned short force_link:1;
+		unsigned short jabber_disable:1;
+	} __attribute__ ((packed)) bits;
+} __attribute__ ((packed));
+
+#define BC_PHY_INTERRUPT 0x1a
+
+union bc_phy_interrupt_t {
+	unsigned short raw;
+	struct {
+		unsigned short status:1;
+		unsigned short link_change:1;
+		unsigned short speed_change:1;
+		unsigned short duplex_change:1;
+		unsigned short pads:4;
+		unsigned short mask:1;
+		unsigned short link_mask:1;
+		unsigned short speed_mask:1;
+		unsigned short duplex_mask:1;
+		unsigned short pads1:2;
+		unsigned short enable:1;
+		unsigned short duplex_led_enable:1;
+	} __attribute__ ((packed)) bits;
+} __attribute__ ((packed)) bc_phy_interrupt_t;
+
+#define M_PHY_INTERRUPT 0x1b
+
+union m_phy_interrupt_t {
+	unsigned short raw;
+	struct {
+		unsigned short link_up:1;
+		unsigned short remote_fault:1;
+		unsigned short link_down:1;
+		unsigned short link_partner_ack:1;
+		unsigned short parallel_detect:1;
+		unsigned short page_receive:1;
+		unsigned short receive_error:1;
+		unsigned short jabber:1;
+		unsigned short enable_link_up:1;
+		unsigned short enable_remote_fault:1;
+		unsigned short enable_link_down:1;
+		unsigned short enable_link_partner_ack:1;
+		unsigned short enable_parallel_detect:1;
+		unsigned short enable_page_receive:1;
+		unsigned short enable_receive_error:1;
+		unsigned short enable_jabber:1;
+	} __attribute__ ((packed)) bits;
+} __attribute__ ((packed));
+
+#define M_PHY_AUXILIARY_CONTROL_STATUS 0x1f
+
+union m_phy_auxiliary_control_status_t {
+	unsigned short raw;
+	struct {
+		unsigned short bit0:1;   /*bit 0*/
+		unsigned short bit1:1;   /*bit 1*/
+		unsigned short op_mode_indication:3;   /*bit 2-4*/
+		unsigned short bit5:1;   /*bit 5*/
+		unsigned short bit6:1;   /*bit 6*/
+		unsigned short autoneg_indication:1;   /*bit 7*/
+		unsigned short jabber_enable:1;   /*bit 8*/
+		unsigned short bit9:1;   /*bit 9*/
+		unsigned short bit10:1;   /*bit 10*/
+		unsigned short force_link:1;   /*bit 11*/
+		unsigned short bit12:1;   /*bit 12*/
+		unsigned short bit13:1;   /*bit 13*/
+	} __attribute__ ((packed)) bits;
+} __attribute__ ((packed));
+
+/*
+ * Device Data Structures
+ */
+struct appnic_dma_descriptor_t {
+	/* Word 0 */
+	unsigned long transfer_type:2; /* 00=Fill|01=Block|10=Scatter */
+	unsigned long write:1;
+	unsigned long start_of_packet:1;
+	unsigned long end_of_packet:1;
+	unsigned long interrupt_on_completion:1;
+	unsigned long error:1;
+	unsigned long byte_swapping_on:1; /* big endian to little endian */
+	unsigned long pads:24;
+
+	/* Word 1 */
+	unsigned long data_transfer_length:16;
+	unsigned long pdu_length:16;
+
+	/* Word 2 */
+	unsigned long target_memory_address;
+
+	/* Word 3 */
+	unsigned long host_data_memory_pointer;
+} __attribute__ ((packed));
+
+union appnic_queue_pointer_t {
+	unsigned long raw;
+	struct {
+		unsigned long offset:20;
+		unsigned long generation_bit:1;
+		unsigned long pads:11;
+	} __attribute__ ((packed)) bits;
+} __attribute__ ((packed));
+
+struct appnic_device_t {
+
+	struct net_device *ndev;
+
+	/*
+	 * Device statistics.
+	 */
+	struct net_device_stats stats;
+
+	/*
+	 * DMA-able memory.
+	 */
+	int dma_alloc_size;
+	void *dma_alloc;
+	dma_addr_t dma_alloc_dma;
+	int dma_alloc_offset;
+
+	/*tail pointers*/
+	union appnic_queue_pointer_t *rx_tail;
+	dma_addr_t rx_tail_dma;
+	union appnic_queue_pointer_t *tx_tail;
+	dma_addr_t tx_tail_dma;
+
+	/*descriptors*/
+	struct appnic_dma_descriptor_t *rx_desc;
+	dma_addr_t rx_desc_dma;
+	unsigned rx_num_desc;
+	struct appnic_dma_descriptor_t *tx_desc;
+	dma_addr_t tx_desc_dma;
+	unsigned tx_num_desc;
+
+	/*buffers*/
+	unsigned rx_buf_sz;
+	unsigned rx_buf_per_desc;
+	void *rx_buf;
+	dma_addr_t rx_buf_dma;
+	unsigned tx_buf_sz;
+	unsigned tx_buf_per_desc;
+	void *tx_buf;
+	dma_addr_t tx_buf_dma;
+
+	/*
+	 * The local pointers
+	 */
+	union appnic_queue_pointer_t rx_tail_copy;
+	union appnic_queue_pointer_t rx_head;
+	union appnic_queue_pointer_t tx_tail_copy;
+	union appnic_queue_pointer_t tx_head;
+
+	/*
+	 * Polling Mode
+	 */
+	int polling;
+
+	/*
+	 * Spin Lock
+	 */
+	spinlock_t lock;
+	spinlock_t extra_lock;
+
+	/*
+	 * TEMP: semaphores for locking Tx/Rx operations
+	 */
+	struct semaphore tx_sem;
+	struct semaphore rx_sem;
+	struct semaphore poll_sem;
+
+};
+
+
+/*
+ * NIC Interface
+ */
+static int enable(struct net_device *);
+
+#endif /*__APPNIC_H*/
-- 
1.6.5.2

