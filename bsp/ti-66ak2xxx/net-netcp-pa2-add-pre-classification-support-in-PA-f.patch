From 0a9153900b48d9a51b1c2c7d36450cd4aa81afb1 Mon Sep 17 00:00:00 2001
From: Murali Karicheri <m-karicheri2@ti.com>
Date: Wed, 3 Aug 2016 11:38:10 -0400
Subject: [PATCH 283/347] net: netcp: pa2: add pre-classification support in
 PA firmware

This patch comes from:
  git://git.ti.com/processor-sdk/processor-sdk-linux.git

Pre-classification of BC and MC in PA firmware helps avoiding explicit
LUT rules in LUT1-0 and free up the same to other use. This patch add this
capability in PA2 firmware and remove code to add LUT rules for the same.

Signed-off-by: Murali Karicheri <m-karicheri2@ti.com>
Signed-off-by: Jacob Stiffler <j-stiffler@ti.com>
(cherry picked from commit 714024210653064561e678b242a526083d451fb6)
Signed-off-by: Zumeng Chen <zumeng.chen@windriver.com>
---
 drivers/net/ethernet/ti/netcp_pa.c      |    2 +-
 drivers/net/ethernet/ti/netcp_pa2.c     |  155 +++++++++++++++++++++++++++++--
 drivers/net/ethernet/ti/netcp_pa2_fw.h  |  114 ++++++++++++++++++++--
 drivers/net/ethernet/ti/netcp_pa_core.c |   68 ++++++++------
 drivers/net/ethernet/ti/netcp_pa_core.h |    1 +
 5 files changed, 288 insertions(+), 52 deletions(-)

diff --git a/drivers/net/ethernet/ti/netcp_pa.c b/drivers/net/ethernet/ti/netcp_pa.c
index 6344dce..1d4c489 100644
--- a/drivers/net/ethernet/ti/netcp_pa.c
+++ b/drivers/net/ethernet/ti/netcp_pa.c
@@ -1038,7 +1038,7 @@ pa_config_ingress_port_def_route(struct pa_intf *pa_intf,
 	size = (sizeof(struct pa_frm_command) +
 		sizeof(struct pa_frm_command_sys_config_pa) + 4);
 
-	tx = core_ops->alloc_packet(core_dev, size, PA_CLUSTER_1);
+	tx = core_ops->alloc_packet(core_dev, size, PA_CLUSTER_0);
 	if (!tx) {
 		dev_err(core_dev->dev,
 			"%s: could not allocate cmd tx packet\n",
diff --git a/drivers/net/ethernet/ti/netcp_pa2.c b/drivers/net/ethernet/ti/netcp_pa2.c
index fa504d0..53e40e6 100644
--- a/drivers/net/ethernet/ti/netcp_pa2.c
+++ b/drivers/net/ethernet/ti/netcp_pa2.c
@@ -641,27 +641,27 @@ static void pa2_rx_packet_handler(void *param)
 		swizfcmd(fcmd);
 
 		if (fcmd->command_result != PA2FRM_COMMAND_RESULT_SUCCESS) {
-			dev_dbg(core_dev->dev, "Command Result = 0x%x\n",
+			dev_err(core_dev->dev, "Command Result = 0x%x\n",
 				fcmd->command_result);
-			dev_dbg(core_dev->dev, "Command = 0x%x\n",
+			dev_err(core_dev->dev, "Command = 0x%x\n",
 				fcmd->command);
-			dev_dbg(core_dev->dev, "Magic = 0x%x\n", fcmd->magic);
-			dev_dbg(core_dev->dev, "Com ID = 0x%x\n", fcmd->com_id);
-			dev_dbg(core_dev->dev, "ret Context = 0x%x\n",
+			dev_err(core_dev->dev, "Magic = 0x%x\n", fcmd->magic);
+			dev_err(core_dev->dev, "Com ID = 0x%x\n", fcmd->com_id);
+			dev_err(core_dev->dev, "ret Context = 0x%x\n",
 				fcmd->ret_context);
-			dev_dbg(core_dev->dev, "Flow ID = 0x%x\n",
+			dev_err(core_dev->dev, "Flow ID = 0x%x\n",
 				fcmd->flow_id);
-			dev_dbg(core_dev->dev, "reply Queue = 0x%x\n",
+			dev_err(core_dev->dev, "reply Queue = 0x%x\n",
 				fcmd->reply_queue);
-			dev_dbg(core_dev->dev, "reply dest = 0x%x\n",
+			dev_err(core_dev->dev, "reply dest = 0x%x\n",
 				fcmd->reply_dest);
 		}
 		dev_dbg(core_dev->dev, "command response complete\n");
 		break;
 
 	default:
-		dev_warn(core_dev->dev, "bad response context, got 0x%08x\n",
-			 p_info->epib[1]);
+		dev_err(core_dev->dev, "bad response context, got 0x%08x\n",
+			p_info->epib[1]);
 		break;
 	}
 }
@@ -1038,6 +1038,138 @@ static int pa2_add_mac_rule(struct pa_intf *pa_intf, int index,
 	return core_ops->submit_packet(tx, PA2_CLUSTER_0);
 }
 
+static inline void swiz_command_config(struct pa2_frm_command_config_pa *cfg)
+{
+	cfg->pkt_ctrl.ctrl_bit_map = cpu_to_be16(cfg->pkt_ctrl.ctrl_bit_map);
+	cfg->pkt_ctrl.valid_bit_map = cpu_to_be16(cfg->pkt_ctrl.valid_bit_map);
+	cfg->valid_flag = cpu_to_be16(cfg->valid_flag);
+}
+
+static int pa2_config_pre_classify(struct pa_core_device *core_dev,
+				   bool enable)
+{
+	struct pa_frm_packet_ctrl_config *packet_ctrl_cfg;
+	struct pa2_frm_command_config_pa *pa_cfg;
+	struct pa2_frm_command *fcmd;
+	struct pa_packet *tx;
+	int size;
+
+	size = (sizeof(struct pa2_frm_command) +
+		sizeof(struct pa2_frm_command_config_pa) - sizeof(u32));
+	tx = core_ops->alloc_packet(core_dev, size, PA2_CLUSTER_5);
+	if (!tx) {
+		dev_err(core_dev->dev,
+			"%s: could not allocate cmd tx packet\n",
+			__func__);
+		return -ENOMEM;
+	}
+
+	fcmd = pa2_format_fcmd_hdr((void *)tx->data,
+				   core_dev,
+				   PA2FRM_CONFIG_COMMAND_CONFIG_PA,
+				   0,
+				   0,
+				   size);
+	pa_cfg = (struct pa2_frm_command_config_pa *)&fcmd->cmd;
+	memset(pa_cfg, 0, sizeof(*pa_cfg));
+	pa_cfg->valid_flag = PAFRM_COMMAND_CONFIG_VALID_PKT_CTRL;
+
+	packet_ctrl_cfg = &pa_cfg->pkt_ctrl;
+	packet_ctrl_cfg->valid_bit_map =
+		PA_PKT_CTRL_EMAC_IF_INGRESS_DEFAULT_ROUTE;
+	packet_ctrl_cfg->ctrl_bit_map = enable ?
+		PA_PKT_CTRL_EMAC_IF_INGRESS_DEFAULT_ROUTE : 0;
+
+	swizfcmd(fcmd);
+	swiz_command_config(pa_cfg);
+	tx->psdata[0] = BIT(31);
+
+	return core_ops->submit_packet(tx, PA2_CLUSTER_5);
+}
+
+static int
+pa2_config_ingress_port_def_route(struct pa_intf *pa_intf,
+				  bool enable)
+{
+	struct pa_core_device *core_dev = pa_intf->core_dev;
+	struct pa_frm_def_route_info *port_route_cfg;
+	struct pa2_frm_def_route_cfg *def_route_cfg;
+	struct pa2_frm_command_sys_config_pa *cpa;
+	struct pa_frm_forward_host *fwd_host;
+	struct pa2_frm_command *fcmd;
+	struct pa_packet *tx;
+	int size;
+
+	/* There is a overlap of 1 32 bit word between struct pa2_frm_command
+	 * and pa2_frm_command_sys_config_pa. So subtract that from size
+	 */
+	size = (sizeof(struct pa2_frm_command) +
+		sizeof(struct pa2_frm_command_sys_config_pa) - sizeof(u32));
+
+	tx = core_ops->alloc_packet(core_dev, size, PA2_CLUSTER_5);
+	if (!tx) {
+		dev_err(core_dev->dev,
+			"%s: could not allocate cmd tx packet\n",
+			__func__);
+		return -ENOMEM;
+	}
+
+	fcmd = pa2_format_fcmd_hdr((void *)tx->data,
+				   core_dev,
+				   PA2FRM_CONFIG_COMMAND_CMD_SYS_CONFIG,
+				   0,
+				   0,
+				   size);
+	cpa = (struct pa2_frm_command_sys_config_pa *)&fcmd->cmd;
+	memset(cpa, 0, sizeof(*cpa));
+	cpa->cfg_code = PAFRM_SYSTEM_CONFIG_CODE_DEFAULT_ROUTE;
+	def_route_cfg = &cpa->u.def_route_cfg;
+	def_route_cfg->num_ports = 1;
+
+	/* we use one port at a time. So use entry at index 0 */
+	port_route_cfg = &def_route_cfg->route_cfg[0];
+	port_route_cfg->port = pa_intf->eth_port - 1;
+	port_route_cfg->ctrl_bit_map =
+		PA_EMAC_IF_DEF_ROUTE_MC_ENABLE |
+		PA_EMAC_IF_DEF_ROUTE_MC_PRE_CLASSIFY_ENABLE |
+		PA_EMAC_IF_DEF_ROUTE_BC_ENABLE |
+		PA_EMAC_IF_DEF_ROUTE_BC_PRE_CLASSIFY_ENABLE;
+
+	/* populate default route information for multicast packet */
+	port_route_cfg->def_route[DROUTE_MULTICAST].forward_type =
+		enable ? PA2FRM_FORWARD_TYPE_HOST : PA2FRM_FORWARD_TYPE_DISCARD;
+	port_route_cfg->def_route[DROUTE_MULTICAST].flow_id =
+		pa_intf->data_flow_num;
+	port_route_cfg->def_route[DROUTE_MULTICAST].queue =
+		pa_intf->data_queue_num;
+
+	fwd_host = &port_route_cfg->def_route[DROUTE_MULTICAST].u.host;
+	fwd_host->context = PA2_CONTEXT_CONFIG;
+	fwd_host->ps_flags = (pa_intf->eth_port & GENMASK(4, 0))
+				<< PA2FRM_ETH_PS_FLAGS_PORT_SHIFT;
+
+	/* populate default route information for broadcast packet */
+	port_route_cfg->def_route[DROUTE_BROADCAST].forward_type =
+		enable ? PA2FRM_FORWARD_TYPE_HOST : PA2FRM_FORWARD_TYPE_DISCARD;
+	port_route_cfg->def_route[DROUTE_BROADCAST].flow_id =
+		pa_intf->data_flow_num;
+	port_route_cfg->def_route[DROUTE_BROADCAST].queue =
+		pa_intf->data_queue_num;
+
+	fwd_host = &port_route_cfg->def_route[DROUTE_BROADCAST].u.host;
+	fwd_host->context = PA2_CONTEXT_CONFIG;
+	/* TODO check if mask is 0xf or 0x7 */
+	fwd_host->ps_flags = (pa_intf->eth_port & GENMASK(4, 0))
+				<< PA2FRM_ETH_PS_FLAGS_PORT_SHIFT;
+	swizfcmd(fcmd);
+	swizfwd(&port_route_cfg->def_route[DROUTE_MULTICAST]);
+	swizfwd(&port_route_cfg->def_route[DROUTE_BROADCAST]);
+
+	tx->psdata[0] = BIT(31);
+
+	return core_ops->submit_packet(tx, PA2_CLUSTER_5);
+}
+
 static int pa2_fmtcmd_next_route(struct netcp_packet *p_info, int eth_port)
 {
 	u8 ps_flags = (eth_port & PA2_EMAC_CTRL_PORT_MASK) <<
@@ -1326,6 +1458,7 @@ static struct pa_hw netcp_pa2_hw = {
 	.num_pdsps = PA2_NUM_PDSPS,
 	.ingress_l2_cluster_id = PA2_CLUSTER_0,
 	.ingress_l3_cluster_id = PA2_CLUSTER_1,
+	.post_cluster_id = PA2_CLUSTER_5,
 	.egress_cluster_id = PA2_CLUSTER_6,
 	.streaming_pdsp = PSTREAM_ROUTE_INGRESS0,
 	.map_resources	= pa2_map_resources,
@@ -1335,6 +1468,8 @@ static struct pa_hw netcp_pa2_hw = {
 	.set_firmware = pa2_set_firmware,
 	.rx_packet_handler = pa2_rx_packet_handler,
 	.add_mac_rule = pa2_add_mac_rule,
+	.config_ingress_port_def_route = pa2_config_ingress_port_def_route,
+	.config_pre_classify = pa2_config_pre_classify,
 	.set_streaming_switch = pa2_set_streaming_switch,
 	.get_streaming_switch = pa2_get_streaming_switch,
 };
diff --git a/drivers/net/ethernet/ti/netcp_pa2_fw.h b/drivers/net/ethernet/ti/netcp_pa2_fw.h
index cd03cdb..8b691240 100644
--- a/drivers/net/ethernet/ti/netcp_pa2_fw.h
+++ b/drivers/net/ethernet/ti/netcp_pa2_fw.h
@@ -180,7 +180,7 @@ enum pa2_route_pri_info {
 #define PA2_CMD_SPLIT				17
 #define PA2_CMD_EF_OP				18
 
-struct pa2_frm_forward_host {
+struct pa_frm_forward_host {
 	/* Context returned as swInfo0 for matched packet */
 	u32	context;
 	/* Control bitmap, 1 for enable, 0 for disable
@@ -295,7 +295,7 @@ struct pa2_frm_forward  {
 				 * via PKTDMA
 				 */
 	union {
-		struct pa2_frm_forward_host	host;    /* Host specific
+		struct pa_frm_forward_host	host;    /* Host specific
 							  * routing
 							  * information
 							  */
@@ -947,15 +947,6 @@ struct pa2_frm_config_crc {
 #define PA2FRM_CFG_CMD_STATUS_PROC		0
 #define PA2FRM_CFG_CMD_STATUS_DONE		1
 
-struct pa2_frm_command_cmd_hdr {
-	/* Command Header of each command within the multiple command packet */
-	u8	command;
-	/* Offset to the next command, 0: Indicate the last command */
-	u8	offset;
-	/* general parameter used by host only */
-	u16	com_id;
-};
-
 /* Commands to PA */
 struct pa2_frm_command {
 	/* Command Status (used by firmware only) */
@@ -1338,4 +1329,105 @@ struct pa2_cmd_reply {
 	/*  Flow ID used on command reply from PASS */
 };
 
+#define PAFRM_PKT_CAP_MAX_PORT			9
+#define PAFRM_MAX_EMAC_PORT	(PAFRM_PKT_CAP_MAX_PORT - 1)
+
+enum  {
+	DROUTE_MULTICAST,  /* default multicast route */
+	DROUTE_BROADCAST,  /* default broadcast route */
+	DROUTE_UNICAST,    /* default unicast route */
+	DROUTE_N_MAX
+};
+
+struct pa_frm_def_route_info {
+	/* Control Bit Map
+	 * b0: enable/disable route config for MC packets
+	 * b1: enable/disable route config for BC packets
+	 * b2: enable/disable route config for UC packets
+	 * b3: Pre classification enabled for default route
+	 *     otherwise post classification for default route
+	 */
+	u8	ctrl_bit_map;
+	/* ingress port. This is zero based. 0 - for first ethernet
+	 * slave port, 1 for second and so forth
+	 */
+	u8	port;
+	u16	rsvd;
+	struct pa2_frm_forward def_route[DROUTE_N_MAX];
+};
+
+/* Default route configuration */
+struct pa2_frm_def_route_cfg {
+	u8	num_ports; /* number of ports to be configured */
+	u8	rsvd1;
+	u16	rsvd2;
+	struct pa_frm_def_route_info route_cfg[PAFRM_MAX_EMAC_PORT];
+};
+
+/* PA system configuration codes */
+#define PAFRM_SYSTEM_CONFIG_CODE_DEFAULT_ROUTE  8
+
+/* PA system configuration command struct. Used by
+ * PAFRM_CONFIG_COMMAND_SYS_CONFIG command
+ */
+struct pa2_frm_command_sys_config_pa {
+	/* system configuration code as defined below */
+	u8	cfg_code;
+	u8	rsvd1;
+	/* reserved for alignment */
+	u16	rsvd2;
+
+	union {
+		/* Default route configuration for interface */
+		struct pa2_frm_def_route_cfg def_route_cfg;
+	} u;
+};
+
+/* PA global configuration command struct. Used by
+ * PA2FRM_CONFIG_COMMAND_CONFIG_PA
+ */
+struct pa_frm_packet_ctrl_config {
+	u16	ctrl_bit_map;
+	u16	valid_bit_map;
+	/* Below fields are not used by linux driver. So keeping it as reseved
+	 * for now for alignment and may be enhanced later as and when feature
+	 * is required in linux.
+	 */
+	u32	rsvd[2];
+};
+
+struct pa2_frm_command_config_pa {
+	u16	valid_flag;
+	u16	rsvd2;
+	/* Below fields are not used by linux driver. So keeping it as reseved
+	 * for now for alignment and may be enhanced later as and when feature
+	 * is required in linux.
+	 */
+	u32	rsvd3[6];
+	struct	pa_frm_packet_ctrl_config pkt_ctrl;
+	/* reserved because linux driver doesn't use the feature */
+	u32	rsvd4[12];
+};
+
+/* Definitions below is used for valid_flag field of packet control command.
+ * Ingress default route is to be enabled for Pre-classification. This
+ * requires PA_PKT_CTRL_EMAC_IF_INGRESS_DEFAULT_ROUTE with valid_flag set
+ * or reset at bit position below.
+ */
+#define PAFRM_COMMAND_CONFIG_VALID_PKT_CTRL		BIT(6)
+
+/* Definitions below are used for Pre-Classify feature enablement for BC and
+ * MC at the ingress
+ */
+/* Set/Clear: default route enable for multicast */
+#define PA_EMAC_IF_DEF_ROUTE_MC_ENABLE			BIT(0)
+/* Set/Clear: default route enable for broadcast */
+#define PA_EMAC_IF_DEF_ROUTE_BC_ENABLE			BIT(1)
+/* Set/Clear: default route for multicast pre classification enable */
+#define PA_EMAC_IF_DEF_ROUTE_MC_PRE_CLASSIFY_ENABLE	BIT(3)
+/* Set/Clear:  default route for broadcast pre classification enable */
+#define PA_EMAC_IF_DEF_ROUTE_BC_PRE_CLASSIFY_ENABLE	BIT(4)
+/* Ingress default route enable/enable for mac interface */
+#define PA_PKT_CTRL_EMAC_IF_INGRESS_DEFAULT_ROUTE	BIT(7)
+
 #endif /* KEYSTONE_PA2_FW_H */
diff --git a/drivers/net/ethernet/ti/netcp_pa_core.c b/drivers/net/ethernet/ti/netcp_pa_core.c
index a8d0d3f..b4c4fc07 100644
--- a/drivers/net/ethernet/ti/netcp_pa_core.c
+++ b/drivers/net/ethernet/ti/netcp_pa_core.c
@@ -483,19 +483,16 @@ static void pa_tx_compl_work_handler(unsigned long data)
 	knav_queue_enable_notify(cfg->tx_cmd_cmpl_queue);
 }
 
-static int pa_core_init_ingress_tx_resources(struct pa_core_device *core_dev,
-					     bool l2_cluster)
+static int pa_core_init_command_tx_resources(struct pa_core_device *core_dev,
+					     int cluster_id)
 {
 	struct knav_queue_notify_config notify_cfg;
 	struct device *dev = core_dev->dev;
 	struct knav_dma_cfg config;
 	struct pa_cluster_config *cfg;
-	int ret = 0, cluster_id;
+	int ret = 0;
 	char name[32];
 
-	cluster_id = (l2_cluster) ? core_dev->hw->ingress_l2_cluster_id :
-				    core_dev->hw->ingress_l3_cluster_id;
-
 	/* Open the PA Command transmit channel */
 	memset(&config, 0, sizeof(config));
 	config.direction = DMA_MEM_TO_DEV;
@@ -772,14 +769,10 @@ static void pa_core_cleanup_common_rx_resources(struct pa_core_device *core_dev)
 }
 
 static void
-pa_core_cleanup_ingress_tx_resources(struct pa_core_device *core_dev,
-				     bool l2_cluster)
+pa_core_cleanup_command_tx_resources(struct pa_core_device *core_dev,
+				     int cluster_id)
 {
 	struct pa_cluster_config *cfg;
-	int cluster_id;
-
-	cluster_id = (l2_cluster) ? core_dev->hw->ingress_l2_cluster_id :
-				    core_dev->hw->ingress_l3_cluster_id;
 
 	cfg = &core_dev->cluster_config[cluster_id];
 	if (cfg->tx_chan)
@@ -795,21 +788,27 @@ pa_core_cleanup_ingress_tx_resources(struct pa_core_device *core_dev,
 		knav_queue_close(cfg->tx_cmd_cmpl_queue);
 		tasklet_kill(&cfg->tx_task);
 	}
-
-	/* clean up tx cmd pool last, when l3_cluster resources are cleaned */
-	if (core_dev->tx_cmd_pool && !l2_cluster)
-		knav_pool_destroy(core_dev->tx_cmd_pool);
 }
 
 int pa_core_remove(struct netcp_device *netcp_device, void *inst_priv)
 {
 	struct pa_core_device *core_dev = inst_priv;
+	struct pa_hw *hw = core_dev->hw;
 
 	netcp_txpipe_close(&core_dev->tx_pipe);
 	/* clean up ingress L2 cluster tx resources */
-	pa_core_cleanup_ingress_tx_resources(core_dev, true);
+	pa_core_cleanup_command_tx_resources(core_dev,
+					     hw->ingress_l2_cluster_id);
 	/* clean up ingress L3 cluster tx resources */
-	pa_core_cleanup_ingress_tx_resources(core_dev, false);
+	pa_core_cleanup_command_tx_resources(core_dev,
+					     hw->ingress_l3_cluster_id);
+	if (hw->post_cluster_id)
+		pa_core_cleanup_command_tx_resources(core_dev,
+						     hw->post_cluster_id);
+	/* clean up tx cmd pool */
+	if (core_dev->tx_cmd_pool)
+		knav_pool_destroy(core_dev->tx_cmd_pool);
+
 	/* clean up common rx resources */
 	pa_core_cleanup_common_rx_resources(core_dev);
 	device_remove_file(core_dev->dev,
@@ -1095,16 +1094,6 @@ int pa_core_open(void *intf_priv,
 						 PA_INVALID_PORT);
 			}
 
-			/* Enable global pre-classify feature in PA firmware
-			 * once
-			 */
-			if (!core_dev->disable_pre_classify) {
-				ret =
-				hw->config_pre_classify(core_dev, true);
-				if (ret)
-					goto fail;
-			}
-
 			/* make IP LUT entries invalid */
 			for (i = 0; i < core_dev->ip_lut_size; i++) {
 				if (!core_dev->ip_lut[i].valid)
@@ -1122,6 +1111,15 @@ int pa_core_open(void *intf_priv,
 			if (ret)
 				goto fail;
 		}
+
+		/* Enable global pre-classify feature in PA firmware
+		 * once
+		 */
+		if (!core_dev->disable_pre_classify) {
+			ret = hw->config_pre_classify(core_dev, true);
+				if (ret)
+					goto fail;
+		}
 	}
 
 	/* Configure pre-classify rule for the interface so that all BC and MC
@@ -1310,15 +1308,25 @@ static void *pa_core_init(struct netcp_device *netcp_device,
 		goto cleanup;
 
 	/* initialize tx resources for L2 ingress cluster */
-	*error = pa_core_init_ingress_tx_resources(core_dev, true);
+	*error = pa_core_init_command_tx_resources(core_dev,
+						   hw->ingress_l2_cluster_id);
 	if (*error)
 		goto cleanup;
 
 	/* initialize tx resources for L3 ingress cluster */
-	*error = pa_core_init_ingress_tx_resources(core_dev, false);
+	*error = pa_core_init_command_tx_resources(core_dev,
+						   hw->ingress_l3_cluster_id);
 	if (*error)
 		goto cleanup;
 
+	if (hw->post_cluster_id) {
+		*error =
+			pa_core_init_command_tx_resources(core_dev,
+							  hw->post_cluster_id);
+		if (*error)
+			goto cleanup;
+	}
+
 	/* initialize common rx resources */
 	*error = pa_core_init_common_rx_resources(core_dev);
 	if (*error)
diff --git a/drivers/net/ethernet/ti/netcp_pa_core.h b/drivers/net/ethernet/ti/netcp_pa_core.h
index b87b028..3c6f31d 100644
--- a/drivers/net/ethernet/ti/netcp_pa_core.h
+++ b/drivers/net/ethernet/ti/netcp_pa_core.h
@@ -132,6 +132,7 @@ struct pa_hw {
 	int num_pdsps;
 	int ingress_l2_cluster_id;
 	int ingress_l3_cluster_id;
+	int post_cluster_id;
 	int egress_cluster_id;
 	int streaming_pdsp;
 	/* To protect against concurrent accesses */
-- 
1.7.5.4

