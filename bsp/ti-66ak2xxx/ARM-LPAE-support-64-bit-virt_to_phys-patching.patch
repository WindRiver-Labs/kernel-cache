From 35f112f7ef11052a52a2626205dea95e310f7d3d Mon Sep 17 00:00:00 2001
From: Zumeng Chen <zumeng.chen@windriver.com>
Date: Thu, 16 Apr 2015 10:55:56 +0800
Subject: [PATCH 130/256] ARM: LPAE: support 64-bit virt_to_phys patching

This patch comes from:
  git://git.ti.com/keystone-linux/linux.git

This patch adds support for 64-bit physical addresses in virt_to_phys()
patching.  This does not do real 64-bit add/sub, but instead patches in the
upper 32-bits of the phys_offset directly into the output of virt_to_phys.

There is no corresponding change on the phys_to_virt() side, because
computations on the upper 32-bits would be discarded anyway.

Signed-off-by: Cyril Chemparathy <cyril@ti.com>
Reviewed-by: Nicolas Pitre <nico@linaro.org>
Signed-off-by: Zumeng Chen <zumeng.chen@windriver.com>
---
 arch/arm/include/asm/memory.h |   58 +++++++++++++++++++++++++++++++++++++++++
 1 files changed, 58 insertions(+), 0 deletions(-)

diff --git a/arch/arm/include/asm/memory.h b/arch/arm/include/asm/memory.h
index 4afb376..6c939f6 100644
--- a/arch/arm/include/asm/memory.h
+++ b/arch/arm/include/asm/memory.h
@@ -19,6 +19,7 @@
 #include <linux/sizes.h>
 
 #include <asm/cache.h>
+#include <asm/runtime-patch.h>
 
 #ifdef CONFIG_NEED_MACH_MEMORY_H
 #include <mach/memory.h>
@@ -170,6 +171,62 @@
 #ifndef __virt_to_phys
 #ifdef CONFIG_ARM_PATCH_PHYS_VIRT
 
+#ifdef CONFIG_ARCH_KEYSTONE
+
+extern unsigned long	__pv_offset;
+extern phys_addr_t	__pv_phys_offset;
+#define PHYS_OFFSET	__virt_to_phys(PAGE_OFFSET)
+
+static inline phys_addr_t __virt_to_phys(unsigned long x)
+{
+	phys_addr_t t;
+
+#ifndef CONFIG_ARM_LPAE
+	early_runtime_patch_imm8("add", t, x, __pv_offset);
+#else
+	unsigned long __tmp;
+
+#ifndef __ARMEB__
+#define PV_PHYS_HIGH	"(__pv_phys_offset + 4)"
+#else
+#define PV_PHYS_HIGH	"__pv_phys_offset"
+#endif
+
+	early_runtime_patch_stub(
+	/* type */		RUNTIME_PATCH_TYPE_IMM8,
+	/* code */
+		"ldr		%[tmp], =__pv_offset\n"
+		"ldr		%[tmp], [%[tmp]]\n"
+		"add		%Q[to], %[from], %[tmp]\n"
+		"ldr		%[tmp], =" PV_PHYS_HIGH "\n"
+		"ldr		%[tmp], [%[tmp]]\n"
+		"mov		%R[to], %[tmp]\n",
+	/* pad */		4,
+	/* patch_data */
+		".long		__pv_offset\n"
+		"add		%Q[to], %[from], %[imm]\n"
+		".long	"	PV_PHYS_HIGH "\n"
+		"mov		%R[to], %[imm]\n",
+	/* operands */
+		: [to]	 "=r"	(t),
+		  [tmp]	 "=&r"	(__tmp)
+		: [from] "r"	(x),
+		  [imm]	 "I"	(__IMM8_CONST_DUMMY),
+			 "i"	(&__pv_offset),
+			 "i"	(&__pv_phys_offset));
+#endif
+	return t;
+}
+
+static inline unsigned long __phys_to_virt(phys_addr_t x)
+{
+	unsigned long t, xlo = x;
+	early_runtime_patch_imm8("sub", t, xlo, __pv_offset);
+	return t;
+}
+
+#else  // CONFIG_ARCH_KEYSTONE
+
 /*
  * Constants used to force the right instruction encodings and shifts
  * so that all we need to do is modify the 8-bit constant field.
@@ -239,6 +296,7 @@ static inline unsigned long __phys_to_virt(phys_addr_t x)
 	__pv_stub((unsigned long) x, t, "sub", __PV_BITS_31_24);
 	return t;
 }
+#endif // #ifdef CONFIG_ARCH_KEYSTONE
 
 #else
 
-- 
1.7.5.4

