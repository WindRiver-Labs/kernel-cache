From e8bced6339f4be28991836e6931e45c86f44e268 Mon Sep 17 00:00:00 2001
From: Sandeep Paulraj <s-paulraj@ti.com>
Date: Tue, 30 Apr 2013 11:28:10 -0400
Subject: [PATCH 088/257] hwqueue: keystone: multi qos tree support

This commit adds initial multiple qos tree support.
At this time each qos tree is implemented in 1 pdsp.
The main change in this patch is that all operations
are now performed on a per qos tree basis instead of being
based on the keystone hardware queue device.

Signed-off-by: Sandeep Paulraj <s-paulraj@ti.com>
(cherry picked from commit 37d98873ce9330b8998be755ef69a963853db0fe)
Signed-off-by: Zumeng Chen <zumeng.chen@windriver.com>
---
 drivers/hwqueue/keystone_hwqueue_qos.c | 301 +++++++++++++++------------------
 drivers/hwqueue/keystone_qos.h         |  52 +++---
 2 files changed, 163 insertions(+), 190 deletions(-)

diff --git a/drivers/hwqueue/keystone_hwqueue_qos.c b/drivers/hwqueue/keystone_hwqueue_qos.c
index bca07d7..4ddbf10 100644
--- a/drivers/hwqueue/keystone_hwqueue_qos.c
+++ b/drivers/hwqueue/keystone_hwqueue_qos.c
@@ -336,24 +336,23 @@ static int khwq_program_drop_policy(struct khwq_qos_info *info,
 				    struct khwq_qos_drop_policy *policy,
 				    bool sync)
 {
-	struct khwq_device *kdev = info->kdev;
 	int error;
 	u32 val, time_constant, diff;
 	u32 thresh_recip;
 
 	val = (policy->acct == QOS_BYTE_ACCT) ? BIT(0) : 0;
 
-	error = khwq_qos_set_drop_cfg_unit_flags(kdev, policy->drop_cfg_idx,
+	error = khwq_qos_set_drop_cfg_unit_flags(info, policy->drop_cfg_idx,
 						 val, false);
 	if (error)
 		return error;
 
-	error = khwq_qos_set_drop_cfg_mode(kdev, policy->drop_cfg_idx,
+	error = khwq_qos_set_drop_cfg_mode(info, policy->drop_cfg_idx,
 					   policy->mode, false);
 	if (error)
 		return error;
 
-	error = khwq_qos_set_drop_cfg_tail_thresh(kdev, policy->drop_cfg_idx,
+	error = khwq_qos_set_drop_cfg_tail_thresh(info, policy->drop_cfg_idx,
 						  policy->limit, false);
 	if (error)
 		return error;
@@ -361,18 +360,18 @@ static int khwq_program_drop_policy(struct khwq_qos_info *info,
 	if (policy->mode == QOS_TAILDROP)
 		return 0;
 
-	error = khwq_qos_set_drop_cfg_red_low(kdev, policy->drop_cfg_idx,
+	error = khwq_qos_set_drop_cfg_red_low(info, policy->drop_cfg_idx,
 					      policy->red_low, false);
 	if (error)
 		return error;
 
-	error = khwq_qos_set_drop_cfg_red_high(kdev, policy->drop_cfg_idx,
+	error = khwq_qos_set_drop_cfg_red_high(info, policy->drop_cfg_idx,
 					       policy->red_high, false);
 
 	val = policy->half_life / 100;
 	time_constant = ilog2((3 * val) + 1);
 
-	error = khwq_qos_set_drop_cfg_time_const(kdev, policy->drop_cfg_idx,
+	error = khwq_qos_set_drop_cfg_time_const(info, policy->drop_cfg_idx,
 						   time_constant, false);
 
 	diff = ((policy->red_high - policy->red_low) >> time_constant);
@@ -380,7 +379,7 @@ static int khwq_program_drop_policy(struct khwq_qos_info *info,
 	thresh_recip = 1 << 31;
 	thresh_recip /= (diff >> 1);
 
-	error = khwq_qos_set_drop_cfg_thresh_recip(kdev, policy->drop_cfg_idx,
+	error = khwq_qos_set_drop_cfg_thresh_recip(info, policy->drop_cfg_idx,
 						   thresh_recip, false);
 
 	return error;
@@ -458,7 +457,7 @@ static ssize_t khwq_qos_drop_policy_attr_store(struct kobject *kobj,
 		return error;
 	}
 
-	error = khwq_qos_sync_drop_cfg(kdev, -1);
+	error = khwq_qos_sync_drop_cfg(info, -1);
 	if (error)
 		dev_err(kdev->dev, "failed to sync drop configs\n");
 
@@ -491,7 +490,7 @@ static int khwq_program_drop_policies(struct khwq_qos_info *info)
 		if (!policy->usecount && policy != info->default_drop_policy)
 			continue;
 
-		policy->drop_cfg_idx = khwq_qos_alloc_drop_cfg(kdev);
+		policy->drop_cfg_idx = khwq_qos_alloc_drop_cfg(info);
 		if (policy->drop_cfg_idx < 0) {
 			dev_err(kdev->dev, "too many drop policies\n");
 			error = -EOVERFLOW;
@@ -509,7 +508,7 @@ static int khwq_program_drop_policies(struct khwq_qos_info *info)
 	}
 
 	if (!error) {
-		error = khwq_qos_sync_drop_cfg(kdev, -1);
+		error = khwq_qos_sync_drop_cfg(info, -1);
 		if (error)
 			dev_err(kdev->dev, "failed to sync drop configs\n");
 	}
@@ -745,21 +744,12 @@ static int khwq_qos_get_drop_policies(struct khwq_device *kdev,
 }
 
 static struct khwq_qos_shadow *
-khwq_find_shadow(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
+khwq_find_shadow(struct khwq_qos_info *info, enum khwq_qos_shadow_type type,
 		 int idx, int offset, bool internal)
 {
 	struct khwq_qos_shadow *shadow;
-	struct khwq_pdsp_info *pdsp;
-	struct khwq_qos_info *info;
-
-	pdsp = khwq_find_pdsp(kdev, khwq_qos_id_to_pdsp(idx));
-	if (!pdsp || !pdsp->qos_info) {
-		dev_err(kdev->dev, "cannot shadow, type %d, pdsp %p, info %p\n",
-			type, pdsp, pdsp ? pdsp->qos_info : NULL);
-		return NULL;
-	}
+	struct khwq_device *kdev = info->kdev;
 
-	info = pdsp->qos_info;
 	shadow = &info->shadows[type];
 
 	idx = khwq_qos_id_to_idx(idx);
@@ -778,14 +768,15 @@ khwq_find_shadow(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
 	return shadow;
 }
 
-int khwq_qos_get(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
+int khwq_qos_get(struct khwq_qos_info *info, enum khwq_qos_shadow_type type,
 		   const char *name, int idx, int offset, int startbit,
 		   int nbits, u32 *value)
 {
+	struct khwq_device *kdev = info->kdev;
 	struct khwq_qos_shadow *shadow;
 	u32 *element;
 
-	shadow = khwq_find_shadow(kdev, type, idx, offset, false);
+	shadow = khwq_find_shadow(info, type, idx, offset, false);
 	if (WARN_ON(!shadow))
 		return -EINVAL;
 
@@ -797,15 +788,16 @@ int khwq_qos_get(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
 	return 0;
 }
 
-int khwq_qos_set(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
+int khwq_qos_set(struct khwq_qos_info *info, enum khwq_qos_shadow_type type,
 		   const char *name, int idx, int offset, int startbit,
 		   int nbits, bool sync, u32 value, bool internal)
 {
+	struct khwq_device *kdev = info->kdev;
 	struct khwq_qos_shadow *shadow;
 	u32 *element;
 	u32 outval;
 
-	shadow = khwq_find_shadow(kdev, type, idx, offset, internal);
+	shadow = khwq_find_shadow(info, type, idx, offset, internal);
 	if (WARN_ON(!shadow))
 		return -EINVAL;
 
@@ -825,13 +817,13 @@ int khwq_qos_set(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
 	return 0;
 }
 
-int khwq_qos_control(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
+int khwq_qos_control(struct khwq_qos_info *info, enum khwq_qos_shadow_type type,
 		       enum khwq_qos_control_type ctrl, int idx, u32 arg,
 		       bool internal)
 {
 	struct khwq_qos_shadow *shadow;
 
-	shadow = khwq_find_shadow(kdev, type, idx, 0, internal);
+	shadow = khwq_find_shadow(info, type, idx, 0, internal);
 	if (WARN_ON(!shadow))
 		return -EINVAL;
 
@@ -841,12 +833,12 @@ int khwq_qos_control(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
 	return shadow->control(shadow, ctrl, idx, arg);
 }
 
-int khwq_qos_sync(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
+int khwq_qos_sync(struct khwq_qos_info *info, enum khwq_qos_shadow_type type,
 		    int idx, bool internal)
 {
 	struct khwq_pdsp_info *pdsp;
 	struct khwq_qos_shadow *shadow;
-	struct khwq_qos_info *info;
+	struct khwq_device *kdev = info->kdev;
 	int error = 0;
 
 	if (type < 0 || type >= QOS_MAX_SHADOW) {
@@ -855,7 +847,7 @@ int khwq_qos_sync(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
 	}
 
 	if (idx >= 0) {
-		shadow = khwq_find_shadow(kdev, type, idx, 0, internal);
+		shadow = khwq_find_shadow(info, type, idx, 0, internal);
 		if (WARN_ON(!shadow))
 			return -EINVAL;
 		idx = khwq_qos_id_to_idx(idx);
@@ -877,40 +869,33 @@ int khwq_qos_sync(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
 	return error;
 }
 
-int khwq_qos_alloc(struct khwq_device *kdev, enum khwq_qos_shadow_type type)
+int khwq_qos_alloc(struct khwq_qos_info *info, enum khwq_qos_shadow_type type)
 {
-	struct khwq_pdsp_info *pdsp;
-	struct khwq_qos_info *info;
+	struct khwq_pdsp_info *pdsp = info->pdsp;
 	struct khwq_qos_shadow *shadow;
 	int idx;
 
-	for_each_pdsp(kdev, pdsp) {
-		info = pdsp->qos_info;
-		if (!info)
-			continue;
-
-		shadow = &info->shadows[type];
-		spin_lock_bh(&info->lock);
-
-		idx = find_last_bit(shadow->avail, shadow->count);
-		if (idx < shadow->count) {
-			clear_bit(idx, shadow->avail);
-			spin_unlock_bh(&info->lock);
-			return khwq_qos_make_id(pdsp->id, idx);
-		}
+	shadow = &info->shadows[type];
+	spin_lock_bh(&info->lock);
 
+	idx = find_last_bit(shadow->avail, shadow->count);
+	if (idx < shadow->count) {
+		clear_bit(idx, shadow->avail);
 		spin_unlock_bh(&info->lock);
+		return khwq_qos_make_id(pdsp->id, idx);
 	}
 
+	spin_unlock_bh(&info->lock);
+
 	return -ENOSPC;
 }
 
-int khwq_qos_free(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
+int khwq_qos_free(struct khwq_qos_info *info, enum khwq_qos_shadow_type type,
 		    int idx)
 {
 	struct khwq_qos_shadow *shadow;
 
-	shadow = khwq_find_shadow(kdev, type, idx, 0, false);
+	shadow = khwq_find_shadow(info, type, idx, 0, false);
 	if (WARN_ON(!shadow))
 		return -EINVAL;
 
@@ -925,38 +910,30 @@ int khwq_qos_free(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
 	return 0;
 }
 
-static int khwq_qos_alloc_drop_queue(struct khwq_device *kdev, int _idx)
+static int khwq_qos_alloc_drop_queue(struct khwq_qos_info *info, int _idx)
 {
-	struct khwq_pdsp_info *pdsp;
-	struct khwq_qos_info *info;
+	struct khwq_pdsp_info *pdsp = info->pdsp;
 	struct khwq_qos_shadow *shadow;
 	int idx, base, count;
 
-	for_each_pdsp(kdev, pdsp) {
-		info = pdsp->qos_info;
-		if (!info)
-			continue;
+	shadow = &info->shadows[QOS_DROP_QUEUE_CFG];
+	base   = info->drop_sched_queue_base;
+	count  = shadow->count;
 
-		shadow = &info->shadows[QOS_DROP_QUEUE_CFG];
-		base   = info->drop_sched_queue_base;
-		count  = shadow->count;
 
-		if (base > _idx || base + count < _idx)
-			continue;
+	idx = _idx - base;
 
-		idx = _idx - base;
+	if (test_and_clear_bit(idx, shadow->avail))
+		return khwq_qos_make_id(pdsp->id, idx);
+	else
+		return -EBUSY;
 
-		if (test_and_clear_bit(idx, shadow->avail))
-			return khwq_qos_make_id(pdsp->id, idx);
-		else
-			return -EBUSY;
-	}
 	return -ENODEV;
 }
 
-static int khwq_qos_free_drop_queue(struct khwq_device *kdev, int idx)
+static int khwq_qos_free_drop_queue(struct khwq_qos_info *info, int idx)
 {
-	return khwq_qos_free(kdev, QOS_DROP_QUEUE_CFG, idx);
+	return khwq_qos_free(info, QOS_DROP_QUEUE_CFG, idx);
 }
 
 static int khwq_qos_sched_port_enable(struct khwq_qos_shadow *shadow, int idx,
@@ -1482,12 +1459,12 @@ static ssize_t qnode_input_queues_store(struct khwq_qos_tree_node *qnode,
 		for (i = 0; i < QOS_MAX_INPUTS; i++) {
 			if (qnode->input_queue[i].queue == -field) {
 				qnode->input_queue[i].valid = false;
-				khwq_qos_free_drop_queue(kdev,
+				khwq_qos_free_drop_queue(info,
 					qnode->input_queue[i].drop_queue_idx);
 			}
 		}
 	} else {
-		error = khwq_qos_alloc_drop_queue(kdev, field);
+		error = khwq_qos_alloc_drop_queue(info, field);
 		if (error < 0) {
 		dev_err(kdev->dev,
 			"failed to alloc input queue %d on node %s\n",
@@ -2031,7 +2008,7 @@ static int khwq_qos_tree_alloc_nodes(struct ktree_node *node, void *arg)
 	int error, i;
 
 	if (qnode->has_sched_port) {
-		error = khwq_qos_alloc_sched_port(kdev);
+		error = khwq_qos_alloc_sched_port(info);
 		if (error < 0) {
 			dev_err(kdev->dev, "node %s: failed to alloc sched port [%d]\n",
 				qnode->name, error);
@@ -2047,7 +2024,7 @@ static int khwq_qos_tree_alloc_nodes(struct ktree_node *node, void *arg)
 			return -EINVAL;
 		if (parent->type == QOS_NODE_DEFAULT)
 			qnode->parent_input = qnode->parent->parent_input;
-		error = khwq_qos_control_sched_port(kdev, QOS_CONTROL_GET_INPUT,
+		error = khwq_qos_control_sched_port(info, QOS_CONTROL_GET_INPUT,
 						    parent->sched_port_idx,
 						    qnode->parent_input);
 		if (WARN_ON(error < 0))
@@ -2060,7 +2037,7 @@ static int khwq_qos_tree_alloc_nodes(struct ktree_node *node, void *arg)
 		khwq_qos_id_to_idx(qnode->sched_port_idx));
 
 	if (qnode->drop_policy) {
-		error = khwq_qos_alloc_drop_out(kdev);
+		error = khwq_qos_alloc_drop_out(info);
 		if (error < 0) {
 			dev_err(kdev->dev, "node %s: failed to alloc sched port [%d]\n",
 				qnode->name, error);
@@ -2077,7 +2054,7 @@ static int khwq_qos_tree_alloc_nodes(struct ktree_node *node, void *arg)
 			qnode->drop_out_idx = parent->drop_out_idx;
 
 		for (i = 0; i < qnode->num_input_queues; i++) {
-			error = khwq_qos_alloc_drop_queue(kdev,
+			error = khwq_qos_alloc_drop_queue(info,
 							  qnode->input_queue[i].queue);
 			if (error < 0) {
 				dev_err(kdev->dev,
@@ -2114,26 +2091,26 @@ static int khwq_qos_tree_start_port(struct khwq_qos_info *info,
 		khwq_qos_id_to_idx(idx), qnode->name);
 
 	val = (qnode->acct == QOS_BYTE_ACCT) ? 0xf : 0;
-	error = khwq_qos_set_sched_unit_flags(kdev, idx, val, sync);
+	error = khwq_qos_set_sched_unit_flags(info, idx, val, sync);
 	if (WARN_ON(error))
 		return error;
 
-	error = khwq_qos_set_sched_group_count(kdev, idx, 1, sync);
+	error = khwq_qos_set_sched_group_count(info, idx, 1, sync);
 	if (WARN_ON(error))
 		return error;
 
 	val = qnode->output_queue;
-	error = khwq_qos_set_sched_out_queue(kdev, idx, val, sync);
+	error = khwq_qos_set_sched_out_queue(info, idx, val, sync);
 	if (WARN_ON(error))
 		return error;
 
 	val = qnode->overhead_bytes;
-	error = khwq_qos_set_sched_overhead_bytes(kdev, idx, val, sync);
+	error = khwq_qos_set_sched_overhead_bytes(info, idx, val, sync);
 	if (WARN_ON(error))
 		return error;
 
 	val = qnode->output_rate / info->ticks_per_sec;
-	error = khwq_qos_set_sched_out_throttle(kdev, idx, val, sync);
+	error = khwq_qos_set_sched_out_throttle(info, idx, val, sync);
 	if (WARN_ON(error))
 		return error;
 
@@ -2141,7 +2118,7 @@ static int khwq_qos_tree_start_port(struct khwq_qos_info *info,
 	val = (qnode->acct == QOS_BYTE_ACCT) ?
 		(temp << QOS_CREDITS_BYTE_SHIFT) :
 		(temp << QOS_CREDITS_PACKET_SHIFT);
-	error = khwq_qos_set_sched_cir_credit(kdev, idx, val, sync);
+	error = khwq_qos_set_sched_cir_credit(info, idx, val, sync);
 	if (WARN_ON(error))
 		return error;
 
@@ -2149,29 +2126,29 @@ static int khwq_qos_tree_start_port(struct khwq_qos_info *info,
 	val = (qnode->acct == QOS_BYTE_ACCT) ?
 		(temp << QOS_CREDITS_BYTE_SHIFT) :
 		(temp << QOS_CREDITS_PACKET_SHIFT);
-	error = khwq_qos_set_sched_cir_max(kdev, idx, val, sync);
+	error = khwq_qos_set_sched_cir_max(info, idx, val, sync);
 	if (WARN_ON(error))
 		return error;
 
 	inputs = (qnode->type == QOS_NODE_DEFAULT) ? 1 : qnode->child_count;
 
-	error = khwq_qos_set_sched_total_q_count(kdev, idx, inputs, sync);
+	error = khwq_qos_set_sched_total_q_count(info, idx, inputs, sync);
 	if (WARN_ON(error))
 		return error;
 
 	val = (qnode->type == QOS_NODE_PRIO) ? inputs : 0;
-	error = khwq_qos_set_sched_sp_q_count(kdev, idx, val, sync);
+	error = khwq_qos_set_sched_sp_q_count(info, idx, val, sync);
 	if (WARN_ON(error))
 		return error;
 
 	val = (qnode->type == QOS_NODE_WRR) ? inputs : 0;
-	error = khwq_qos_set_sched_wrr_q_count(kdev, idx, val, sync);
+	error = khwq_qos_set_sched_wrr_q_count(info, idx, val, sync);
 	if (WARN_ON(error))
 		return error;
 
 	for (i = 0; i < inputs; i++) {
 		val = 0;
-		error = khwq_qos_set_sched_cong_thresh(kdev, idx, i, val, sync);
+		error = khwq_qos_set_sched_cong_thresh(info, idx, i, val, sync);
 		if (WARN_ON(error))
 			return error;
 
@@ -2201,19 +2178,19 @@ static int khwq_qos_tree_start_port(struct khwq_qos_info *info,
 				 "credits = %d\n", qnode->child_weight[i], val);
 		}
 
-		error = khwq_qos_set_sched_wrr_credit(kdev, idx, i, val, sync);
+		error = khwq_qos_set_sched_wrr_credit(info, idx, i, val, sync);
 		if (WARN_ON(error))
 			return error;
 	}
 
-	error = khwq_qos_sync_sched_port(kdev, idx);
+	error = khwq_qos_sync_sched_port(info, idx);
 	if (error) {
 		dev_err(kdev->dev, "error writing sched config for %s\n",
 			qnode->name);
 		return error;
 	}
 
-	error = khwq_qos_control_sched_port(kdev, QOS_CONTROL_ENABLE, idx,
+	error = khwq_qos_control_sched_port(info, QOS_CONTROL_ENABLE, idx,
 					    true);
 	if (error) {
 		dev_err(kdev->dev, "error enabling sched port for %s\n",
@@ -2238,25 +2215,25 @@ static int khwq_qos_tree_start_drop_out(struct khwq_qos_info *info,
 		khwq_qos_id_to_idx(idx), qnode->name);
 
 	val = qnode->output_queue;
-	error = khwq_qos_set_drop_out_queue_number(kdev, idx, val, sync);
+	error = khwq_qos_set_drop_out_queue_number(info, idx, val, sync);
 	if (WARN_ON(error))
 		return error;
 
 	val = (policy->max_drop_prob << 16) / 100;
-	error = khwq_qos_set_drop_out_red_prob(kdev, idx, val, sync);
+	error = khwq_qos_set_drop_out_red_prob(info, idx, val, sync);
 	if (WARN_ON(error))
 		return error;
 
 	val = khwq_qos_id_to_idx(policy->drop_cfg_idx);
-	error = khwq_qos_set_drop_out_cfg_prof_idx(kdev, idx, val, sync);
+	error = khwq_qos_set_drop_out_cfg_prof_idx(info, idx, val, sync);
 	if (WARN_ON(error))
 		return error;
 
-	error = khwq_qos_set_drop_out_enable(kdev, idx, 1, sync);
+	error = khwq_qos_set_drop_out_enable(info, idx, 1, sync);
 	if (WARN_ON(error))
 		return error;
 
-	error = khwq_qos_set_drop_out_avg_depth(kdev, idx, 0, sync);
+	error = khwq_qos_set_drop_out_avg_depth(info, idx, 0, sync);
 	if (WARN_ON(error))
 		return error;
 
@@ -2285,23 +2262,23 @@ static int khwq_qos_tree_start_drop_queue(struct khwq_qos_info *info,
 			khwq_qos_id_to_idx(idx), qnode->name);
 
 		val = khwq_qos_id_to_idx(qnode->drop_out_idx);
-		error = khwq_qos_set_drop_q_out_prof_idx(kdev, idx, val, sync);
+		error = khwq_qos_set_drop_q_out_prof_idx(info, idx, val, sync);
 		if (WARN_ON(error))
 			return error;
 
-		error = khwq_qos_set_drop_q_stat_blk_idx(kdev, idx,
+		error = khwq_qos_set_drop_q_stat_blk_idx(info, idx,
 							 class->stats_block_idx,
 							 sync);
 		if (WARN_ON(error))
 			return error;
 
-		error = khwq_qos_set_drop_q_stat_irq_pair_idx(kdev, idx,
+		error = khwq_qos_set_drop_q_stat_irq_pair_idx(info, idx,
 							      1, sync);
 		if (WARN_ON(error))
 			return error;
 
 
-		error = khwq_qos_set_drop_q_valid(kdev, idx, 1, sync);
+		error = khwq_qos_set_drop_q_valid(info, idx, 1, sync);
 		if (WARN_ON(error))
 			return error;
 	}
@@ -2372,13 +2349,13 @@ int khwq_qos_tree_start(struct khwq_qos_info *info)
 	if (WARN_ON(error))
 		goto bail;
 
-	error = khwq_qos_sync_drop_queue(info->kdev, -1);
+	error = khwq_qos_sync_drop_queue(info, -1);
 	if (error) {
 		dev_err(info->kdev->dev, "error syncing drop queues\n");
 		goto bail;
 	}
 
-	error = khwq_qos_sync_drop_out(info->kdev, -1);
+	error = khwq_qos_sync_drop_out(info, -1);
 	if (error) {
 		dev_err(info->kdev->dev, "error syncing drop outs\n");
 		goto bail;
@@ -2402,28 +2379,28 @@ static int khwq_qos_stop_drop_queues(struct khwq_qos_info *info)
 	for (i = shadow->start; i < (shadow->start + shadow->count); i++) {
 		if (!test_bit(i, shadow->avail)) {
 			idx = khwq_qos_make_id(pdsp->id, i);
-			error = khwq_qos_set_drop_q_valid(kdev, idx, 0, false);
+			error = khwq_qos_set_drop_q_valid(info, idx, 0, false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_drop_q_stat_blk_idx(kdev, idx, 0,
+			error = khwq_qos_set_drop_q_stat_blk_idx(info, idx, 0,
 								 false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_drop_q_stat_irq_pair_idx(kdev, idx,
+			error = khwq_qos_set_drop_q_stat_irq_pair_idx(info, idx,
 								      0, false);
 			if (WARN_ON(error))
 			return error;
 
-			error = khwq_qos_set_drop_q_out_prof_idx(kdev, idx, 0,
+			error = khwq_qos_set_drop_q_out_prof_idx(info, idx, 0,
 								 false);
 			if (WARN_ON(error))
 				return error;
 		}
 	}
 
-	error = khwq_qos_sync_drop_queue(info->kdev, -1);
+	error = khwq_qos_sync_drop_queue(info, -1);
 	if (error) {
 		dev_err(kdev->dev, "error syncing drop queues\n");
 		return error;
@@ -2444,34 +2421,34 @@ static int khwq_qos_stop_drop_outs(struct khwq_qos_info *info)
 	for (i = shadow->start; i < (shadow->start + shadow->count); i++) {
 		if (!test_bit(i, shadow->avail)) {
 			idx = khwq_qos_make_id(pdsp->id, i);
-			error = khwq_qos_set_drop_out_enable(kdev, idx, 0,
+			error = khwq_qos_set_drop_out_enable(info, idx, 0,
 							     false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_drop_out_queue_number(kdev, idx, 0,
+			error = khwq_qos_set_drop_out_queue_number(info, idx, 0,
 							     false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_drop_out_red_prob(kdev, idx, 0,
+			error = khwq_qos_set_drop_out_red_prob(info, idx, 0,
 							     false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_drop_out_cfg_prof_idx(kdev, idx, 0,
+			error = khwq_qos_set_drop_out_cfg_prof_idx(info, idx, 0,
 							     false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_drop_out_avg_depth(kdev, idx, 0,
+			error = khwq_qos_set_drop_out_avg_depth(info, idx, 0,
 							     false);
 			if (WARN_ON(error))
 				return error;
 		}
 	}
 
-	error = khwq_qos_sync_drop_out(info->kdev, -1);
+	error = khwq_qos_sync_drop_out(info, -1);
 	if (error) {
 		dev_err(kdev->dev, "error syncing drop out\n");
 		return error;
@@ -2493,79 +2470,79 @@ static int khwq_qos_stop_sched_port_queues(struct khwq_qos_info *info)
 	for (i = shadow->start; i < (shadow->start + shadow->count); i++) {
 		if (!test_bit(i, shadow->avail)) {
 			idx = khwq_qos_make_id(pdsp->id, i);
-			error = khwq_qos_set_sched_unit_flags(kdev, idx, 0xf,
+			error = khwq_qos_set_sched_unit_flags(info, idx, 0xf,
 							      false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_get_sched_total_q_count(kdev, idx,
+			error = khwq_qos_get_sched_total_q_count(info, idx,
 								&queues);
 			if (WARN_ON(error))
 				return error;
 
 			for (j = 0; j < queues; j++) {
-				error = khwq_qos_set_sched_cong_thresh(kdev,
+				error = khwq_qos_set_sched_cong_thresh(info,
 								       idx, j,
 								       1, false);
 				if (WARN_ON(error))
 					return error;
 
-				error = khwq_qos_set_sched_wrr_credit(kdev, idx,
+				error = khwq_qos_set_sched_wrr_credit(info, idx,
 								      j, 0,
 								      false);
 				if (WARN_ON(error))
 					return error;
 			}
 
-			error = khwq_qos_set_sched_out_queue(kdev, idx, 0,
+			error = khwq_qos_set_sched_out_queue(info, idx, 0,
 							     false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_sched_overhead_bytes(kdev, idx, 0,
+			error = khwq_qos_set_sched_overhead_bytes(info, idx, 0,
 								  false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_sched_out_throttle(kdev, idx, 0,
+			error = khwq_qos_set_sched_out_throttle(info, idx, 0,
 								false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_sched_cir_credit(kdev, idx, 0,
+			error = khwq_qos_set_sched_cir_credit(info, idx, 0,
 							      false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_sched_cir_max(kdev, idx, 0, false);
+			error = khwq_qos_set_sched_cir_max(info, idx, 0, false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_sched_out_throttle(kdev, idx, 0,
+			error = khwq_qos_set_sched_out_throttle(info, idx, 0,
 								false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_sched_total_q_count(kdev, idx, 0,
+			error = khwq_qos_set_sched_total_q_count(info, idx, 0,
 								false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_sched_sp_q_count(kdev, idx, 0,
+			error = khwq_qos_set_sched_sp_q_count(info, idx, 0,
 								false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_set_sched_wrr_q_count(kdev, idx, 0,
+			error = khwq_qos_set_sched_wrr_q_count(info, idx, 0,
 								false);
 			if (WARN_ON(error))
 				return error;
 
-			error = khwq_qos_sync_sched_port(kdev, idx);
+			error = khwq_qos_sync_sched_port(info, idx);
 			if (error)
 				return error;
 
-			error = khwq_qos_control_sched_port(kdev,
+			error = khwq_qos_control_sched_port(info,
 							    QOS_CONTROL_ENABLE,
 							    idx,
 							    false);
@@ -2669,7 +2646,6 @@ static ssize_t khwq_qos_out_prof_read(struct file *filp, char __user *buffer,
 				   size_t count, loff_t *ppos)
 {
 	struct khwq_qos_info *info = filp->private_data;
-	struct khwq_device *kdev = info->kdev;
 	struct khwq_qos_shadow *shadow = &info->shadows[QOS_DROP_OUT_PROF];
 	struct khwq_pdsp_info *pdsp;
 	int i, buf_len = 8192, idx, error;
@@ -2699,7 +2675,7 @@ static ssize_t khwq_qos_out_prof_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"output profile %d ", i);
 
-			error = khwq_qos_get_drop_out_queue_number(kdev, idx,
+			error = khwq_qos_get_drop_out_queue_number(info, idx,
 								   &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2707,7 +2683,7 @@ static ssize_t khwq_qos_out_prof_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"output q # %d ", temp);
 
-			error = khwq_qos_get_drop_out_red_prob(kdev, idx,
+			error = khwq_qos_get_drop_out_red_prob(info, idx,
 							       &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2715,14 +2691,14 @@ static ssize_t khwq_qos_out_prof_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"red prob %d ", temp);
 
-			error = khwq_qos_get_drop_out_enable(kdev, idx, &temp);
+			error = khwq_qos_get_drop_out_enable(info, idx, &temp);
 			if (WARN_ON(error))
 				goto free;
 
 			len += snprintf(buf + len, buf_len - len,
 					"enable %d ", temp);
 
-			error = khwq_qos_get_drop_out_cfg_prof_idx(kdev, idx,
+			error = khwq_qos_get_drop_out_cfg_prof_idx(info, idx,
 								   &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2730,7 +2706,7 @@ static ssize_t khwq_qos_out_prof_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"config profile %d ", temp);
 
-			error = khwq_qos_get_drop_out_avg_depth(kdev, idx,
+			error = khwq_qos_get_drop_out_avg_depth(info, idx,
 								   &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2753,7 +2729,6 @@ static ssize_t khwq_qos_q_cfg_read(struct file *filp, char __user *buffer,
 				   size_t count, loff_t *ppos)
 {
 	struct khwq_qos_info *info = filp->private_data;
-	struct khwq_device *kdev = info->kdev;
 	struct khwq_qos_shadow *shadow = &info->shadows[QOS_DROP_QUEUE_CFG];
 	struct khwq_pdsp_info *pdsp;
 	int i, buf_len = 4096, idx, error;
@@ -2783,7 +2758,7 @@ static ssize_t khwq_qos_q_cfg_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"q cfg %d ", i);
 
-			error = khwq_qos_get_drop_q_stat_irq_pair_idx(kdev, idx,
+			error = khwq_qos_get_drop_q_stat_irq_pair_idx(info, idx,
 								      &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2791,7 +2766,7 @@ static ssize_t khwq_qos_q_cfg_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"stats q pair # %d ", temp);
 
-			error = khwq_qos_get_drop_q_stat_blk_idx(kdev, idx,
+			error = khwq_qos_get_drop_q_stat_blk_idx(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2799,7 +2774,7 @@ static ssize_t khwq_qos_q_cfg_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"block %d ", temp);
 
-			error = khwq_qos_get_drop_q_out_prof_idx(kdev, idx,
+			error = khwq_qos_get_drop_q_out_prof_idx(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2822,7 +2797,6 @@ static ssize_t khwq_qos_drop_prof_read(struct file *filp, char __user *buffer,
 				   size_t count, loff_t *ppos)
 {
 	struct khwq_qos_info *info = filp->private_data;
-	struct khwq_device *kdev = info->kdev;
 	struct khwq_qos_shadow *shadow = &info->shadows[QOS_DROP_CFG_PROF];
 	struct khwq_pdsp_info *pdsp;
 	int i, buf_len = 4096, idx, error;
@@ -2852,7 +2826,7 @@ static ssize_t khwq_qos_drop_prof_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"drop cfg prof %d ", i);
 
-			error = khwq_qos_get_drop_cfg_unit_flags(kdev, idx,
+			error = khwq_qos_get_drop_cfg_unit_flags(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2860,14 +2834,14 @@ static ssize_t khwq_qos_drop_prof_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"unit flags %d ", temp);
 
-			error = khwq_qos_get_drop_cfg_mode(kdev, idx, &temp);
+			error = khwq_qos_get_drop_cfg_mode(info, idx, &temp);
 			if (WARN_ON(error))
 				goto free;
 
 			len += snprintf(buf + len, buf_len - len,
 					"mode %d ", temp);
 
-			error = khwq_qos_get_drop_cfg_time_const(kdev, idx,
+			error = khwq_qos_get_drop_cfg_time_const(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2875,7 +2849,7 @@ static ssize_t khwq_qos_drop_prof_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"time const %d ", temp);
 
-			error = khwq_qos_get_drop_cfg_tail_thresh(kdev, idx,
+			error = khwq_qos_get_drop_cfg_tail_thresh(info, idx,
 								  &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2883,14 +2857,14 @@ static ssize_t khwq_qos_drop_prof_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"tail thresh %d ", temp);
 
-			error = khwq_qos_get_drop_cfg_red_low(kdev, idx, &temp);
+			error = khwq_qos_get_drop_cfg_red_low(info, idx, &temp);
 			if (WARN_ON(error))
 				goto free;
 
 			len += snprintf(buf + len, buf_len - len,
 					"red low %d ", temp);
 
-			error = khwq_qos_get_drop_cfg_red_high(kdev, idx,
+			error = khwq_qos_get_drop_cfg_red_high(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2898,7 +2872,7 @@ static ssize_t khwq_qos_drop_prof_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"red high %d ", temp);
 
-			error = khwq_qos_get_drop_cfg_thresh_recip(kdev, idx,
+			error = khwq_qos_get_drop_cfg_thresh_recip(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2921,7 +2895,6 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 				   size_t count, loff_t *ppos)
 {
 	struct khwq_qos_info *info = filp->private_data;
-	struct khwq_device *kdev = info->kdev;
 	struct khwq_qos_shadow *shadow = &info->shadows[QOS_SCHED_PORT_CFG];
 	struct khwq_pdsp_info *pdsp;
 	int i, j, buf_len = 4096, idx, error;
@@ -2951,7 +2924,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"port %d\n", i);
 
-			error = khwq_qos_get_sched_unit_flags(kdev, idx,
+			error = khwq_qos_get_sched_unit_flags(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2959,7 +2932,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"unit flags %d ", temp);
 
-			error = khwq_qos_get_sched_group_count(kdev, idx,
+			error = khwq_qos_get_sched_group_count(info, idx,
 							       &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2967,7 +2940,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"group # %d ", temp);
 
-			error = khwq_qos_get_sched_out_queue(kdev, idx,
+			error = khwq_qos_get_sched_out_queue(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2975,7 +2948,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"out q %d ", temp);
 
-			error = khwq_qos_get_sched_overhead_bytes(kdev, idx,
+			error = khwq_qos_get_sched_overhead_bytes(info, idx,
 								  &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2983,7 +2956,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"overhead bytes %d ", temp);
 
-			error = khwq_qos_get_sched_out_throttle(kdev, idx,
+			error = khwq_qos_get_sched_out_throttle(info, idx,
 								&temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2991,7 +2964,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"throttle thresh %d ", temp);
 
-			error = khwq_qos_get_sched_cir_credit(kdev, idx,
+			error = khwq_qos_get_sched_cir_credit(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -2999,7 +2972,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"cir credit %d ", temp);
 
-			error = khwq_qos_get_sched_cir_max(kdev, idx,
+			error = khwq_qos_get_sched_cir_max(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -3007,7 +2980,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"cir max %d\n", temp);
 
-			error = khwq_qos_get_sched_total_q_count(kdev, idx,
+			error = khwq_qos_get_sched_total_q_count(info, idx,
 								 &queues);
 			if (WARN_ON(error))
 				goto free;
@@ -3015,7 +2988,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"total q's %d ", queues);
 
-			error = khwq_qos_get_sched_sp_q_count(kdev, idx,
+			error = khwq_qos_get_sched_sp_q_count(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -3023,7 +2996,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 			len += snprintf(buf + len, buf_len - len,
 					"sp q's %d ", temp);
 
-			error = khwq_qos_get_sched_wrr_q_count(kdev, idx,
+			error = khwq_qos_get_sched_wrr_q_count(info, idx,
 								 &temp);
 			if (WARN_ON(error))
 				goto free;
@@ -3035,7 +3008,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 				len += snprintf(buf + len, buf_len - len,
 					"queue %d ", j);
 
-				error = khwq_qos_get_sched_cong_thresh(kdev,
+				error = khwq_qos_get_sched_cong_thresh(info,
 								       idx, j,
 								       &temp);
 				if (WARN_ON(error))
@@ -3044,7 +3017,7 @@ static ssize_t khwq_qos_sched_port_read(struct file *filp, char __user *buffer,
 				len += snprintf(buf + len, buf_len - len,
 					"cong thresh %d ", temp);
 
-				error = khwq_qos_get_sched_wrr_credit(kdev, idx,
+				error = khwq_qos_get_sched_wrr_credit(info, idx,
 								      j, &temp);
 				if (WARN_ON(error))
 					return error;
@@ -3210,28 +3183,28 @@ static int khwq_qos_free_range(struct khwq_range_info *range)
 	for (i = shadow->start; i < (shadow->start + shadow->count); i++)
 		if (!test_bit(i, shadow->avail)) {
 			idx = khwq_qos_make_id(pdsp->id, i);
-			khwq_qos_free_sched_port(kdev, idx);
+			khwq_qos_free_sched_port(info, idx);
 		}
 
 	shadow = &info->shadows[QOS_DROP_OUT_PROF];
 	for (i = shadow->start; i < (shadow->start + shadow->count); i++)
 		if (!test_bit(i, shadow->avail)) {
 			idx = khwq_qos_make_id(pdsp->id, i);
-			khwq_qos_free_drop_out(kdev, idx);
+			khwq_qos_free_drop_out(info, idx);
 		}
 
 	shadow = &info->shadows[QOS_DROP_QUEUE_CFG];
 	for (i = shadow->start; i < (shadow->start + shadow->count); i++)
 		if (!test_bit(i, shadow->avail)) {
 			idx = khwq_qos_make_id(pdsp->id, i);
-			khwq_qos_free_drop_queue(kdev, idx);
+			khwq_qos_free_drop_queue(info, idx);
 		}
 
 	shadow = &info->shadows[QOS_DROP_CFG_PROF];
 	for (i = shadow->start; i < (shadow->start + shadow->count); i++)
 		if (!test_bit(i, shadow->avail)) {
 			idx = khwq_qos_make_id(pdsp->id, i);
-			khwq_qos_free_drop_cfg(kdev, idx);
+			khwq_qos_free_drop_cfg(info, idx);
 		}
 
 	return 0;
@@ -3309,14 +3282,14 @@ static int khwq_qos_init_range(struct khwq_range_info *range)
 
 	for (i = 0 ; i < info->shadows[QOS_SCHED_PORT_CFG].count; i++) {
 		idx = khwq_qos_make_id(pdsp->id, i);
-		__khwq_qos_set_sched_overhead_bytes(kdev, idx,
+		__khwq_qos_set_sched_overhead_bytes(info, idx,
 						    QOS_DEFAULT_OVERHEAD_BYTES,
 						    false);
 	}
 
 	for (i = 0 ; i < info->shadows[QOS_DROP_CFG_PROF].count; i++) {
 		idx = khwq_qos_make_id(pdsp->id, i);
-		__khwq_qos_set_drop_cfg_tail_thresh(kdev, idx, -1, false);
+		__khwq_qos_set_drop_cfg_tail_thresh(info, idx, -1, false);
 	}
 
 	/* command for drop scheduler base */
diff --git a/drivers/hwqueue/keystone_qos.h b/drivers/hwqueue/keystone_qos.h
index ec926df..251673e 100644
--- a/drivers/hwqueue/keystone_qos.h
+++ b/drivers/hwqueue/keystone_qos.h
@@ -260,32 +260,32 @@ struct khwq_query_stats_regs {
 #define khwq_qos_id_to_queue(info, idx)		\
 	((info)->drop_sched_queue_base + khwq_qos_id_to_idx(idx))
 
-int khwq_qos_alloc(struct khwq_device *kdev, enum khwq_qos_shadow_type type);
-int khwq_qos_free(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
+int khwq_qos_alloc(struct khwq_qos_info *info, enum khwq_qos_shadow_type type);
+int khwq_qos_free(struct khwq_qos_info *info, enum khwq_qos_shadow_type type,
 		    int idx);
-int khwq_qos_control(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
+int khwq_qos_control(struct khwq_qos_info *info, enum khwq_qos_shadow_type type,
 		       enum khwq_qos_control_type ctrl, int idx, u32 arg,
 		       bool internal);
-int khwq_qos_sync(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
+int khwq_qos_sync(struct khwq_qos_info *info, enum khwq_qos_shadow_type type,
 		    int idx, bool internal);
-int khwq_qos_get(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
+int khwq_qos_get(struct khwq_qos_info *info, enum khwq_qos_shadow_type type,
 		   const char *name, int idx, int offset, int startbit,
 		   int nbits, u32 *value);
-int khwq_qos_set(struct khwq_device *kdev, enum khwq_qos_shadow_type type,
+int khwq_qos_set(struct khwq_qos_info *info, enum khwq_qos_shadow_type type,
 		   const char *name, int idx, int offset, int startbit,
 		   int nbits, bool sync, u32 value, bool internal);
 
 #define DEFINE_SHADOW(_type, _field)					       \
-static inline int khwq_qos_control_##_field(struct khwq_device *kdev,          \
+static inline int khwq_qos_control_##_field(struct khwq_qos_info *info,        \
 					    enum khwq_qos_control_type ctrl,   \
 					    int idx, u32 arg)		       \
 {									       \
-	return khwq_qos_control(kdev, _type, ctrl, idx, arg, false);	       \
+	return khwq_qos_control(info, _type, ctrl, idx, arg, false);	       \
 }									       \
-static inline int khwq_qos_sync_##_field(struct khwq_device *kdev,	       \
+static inline int khwq_qos_sync_##_field(struct khwq_qos_info *info,	       \
 					 int idx)			       \
 {									       \
-	return khwq_qos_sync(kdev, _type, idx, false);		       \
+	return khwq_qos_sync(info, _type, idx, false);		       \
 }
 
 DEFINE_SHADOW(QOS_DROP_CFG_PROF,	drop_cfg);
@@ -294,14 +294,14 @@ DEFINE_SHADOW(QOS_SCHED_PORT_CFG,	sched_port);
 DEFINE_SHADOW(QOS_DROP_QUEUE_CFG,	drop_queue);
 
 #define DEFINE_ALLOC(_type, _field)					       \
-static inline int khwq_qos_alloc_##_field(struct khwq_device *kdev)	       \
+static inline int khwq_qos_alloc_##_field(struct khwq_qos_info *info)	       \
 {									       \
-	return khwq_qos_alloc(kdev, _type);				       \
+	return khwq_qos_alloc(info, _type);				       \
 }									       \
-static inline int khwq_qos_free_##_field(struct khwq_device *kdev,	       \
+static inline int khwq_qos_free_##_field(struct khwq_qos_info *info,	       \
 					 int idx)			       \
 {									       \
-	return khwq_qos_free(kdev, _type, idx);			       \
+	return khwq_qos_free(info, _type, idx);			       \
 }
 
 DEFINE_ALLOC(QOS_DROP_CFG_PROF,	 drop_cfg);
@@ -309,45 +309,45 @@ DEFINE_ALLOC(QOS_DROP_OUT_PROF,	 drop_out);
 DEFINE_ALLOC(QOS_SCHED_PORT_CFG, sched_port);
 
 #define DEFINE_FIELD_U32(_type, _field, _offset, _startbit, _nbits)	 \
-static inline int khwq_qos_get_##_field(struct khwq_device *kdev,	 \
+static inline int khwq_qos_get_##_field(struct khwq_qos_info *info,	 \
 					int idx, u32 *value)		 \
 {									 \
-	return khwq_qos_get(kdev, _type, #_field, idx, _offset,	 \
+	return khwq_qos_get(info, _type, #_field, idx, _offset,	 \
 			      _startbit, _nbits, value);		 \
 }									 \
-static inline int khwq_qos_set_##_field(struct khwq_device *kdev,	 \
+static inline int khwq_qos_set_##_field(struct khwq_qos_info *info,	 \
 					int idx, u32 value, bool sync)	 \
 {									 \
-	return khwq_qos_set(kdev, _type, #_field, idx, _offset,	 \
+	return khwq_qos_set(info, _type, #_field, idx, _offset,	 \
 			      _startbit, _nbits, sync, value, false);	 \
 }									 \
-static inline int __khwq_qos_set_##_field(struct khwq_device *kdev,	 \
+static inline int __khwq_qos_set_##_field(struct khwq_qos_info *info,	 \
 					int idx, u32 value, bool sync)	 \
 {									 \
-	return khwq_qos_set(kdev, _type, #_field, idx, _offset,	 \
+	return khwq_qos_set(info, _type, #_field, idx, _offset,	 \
 			      _startbit, _nbits, sync, value, true);	 \
 }
 
 #define DEFINE_FIELD_U32_ARRAY(_type, _field, _offset, _size)		 \
-static inline int khwq_qos_get_##_field(struct khwq_device *kdev,	 \
+static inline int khwq_qos_get_##_field(struct khwq_qos_info *info,	 \
 					int idx, int elem, u32 *value)	 \
 {									 \
 	int ofs = _offset + elem * _size;				 \
-	return khwq_qos_get(kdev, _type, #_field, idx, ofs, 0, 32,	 \
+	return khwq_qos_get(info, _type, #_field, idx, ofs, 0, 32,	 \
 			      value);					 \
 }									 \
-static inline int khwq_qos_set_##_field(struct khwq_device *kdev,	 \
+static inline int khwq_qos_set_##_field(struct khwq_qos_info *info,	 \
 				int idx, int elem, u32 value, bool sync) \
 {									 \
 	int ofs = _offset + elem * _size;				 \
-	return khwq_qos_set(kdev, _type, #_field, idx, ofs, 0, 32,	 \
+	return khwq_qos_set(info, _type, #_field, idx, ofs, 0, 32,	 \
 			      sync, value, false);			 \
 }									 \
-static inline int __khwq_qos_set_##_field(struct khwq_device *kdev,	 \
+static inline int __khwq_qos_set_##_field(struct khwq_qos_info *info,	 \
 				int idx, int elem, u32 value, bool sync) \
 {									 \
 	int ofs = _offset + elem * _size;				 \
-	return khwq_qos_set(kdev, _type, #_field, idx, ofs, 0, 32,	 \
+	return khwq_qos_set(info, _type, #_field, idx, ofs, 0, 32,	 \
 			      sync, value, true);			 \
 }
 
-- 
2.7.4

