From 21ea007d6ccc8256bac53f5981995c7f8dee3995 Mon Sep 17 00:00:00 2001
From: Zumeng Chen <zumeng.chen@windriver.com>
Date: Tue, 5 May 2015 16:10:28 +0800
Subject: [PATCH 015/257] net: keystone: add packet accelerator driver support

This patch comes from:
  git://git.ti.com/keystone-linux/linux.git

Signed-off-by: Zumeng Chen <zumeng.chen@windriver.com>
---
 drivers/net/ethernet/ti/keystone_pa.c        | 2864 +++++++++++++++++++++++
 drivers/net/ethernet/ti/keystone_pa.h        |  859 +++++++
 drivers/net/ethernet/ti/keystone_pa2.c       | 3169 ++++++++++++++++++++++++++
 drivers/net/ethernet/ti/keystone_pa2.h       | 1205 ++++++++++
 drivers/net/ethernet/ti/keystone_pasahost.h  |  390 ++++
 drivers/net/ethernet/ti/keystone_pasahost2.h |  507 ++++
 6 files changed, 8994 insertions(+)
 create mode 100644 drivers/net/ethernet/ti/keystone_pa.c
 create mode 100644 drivers/net/ethernet/ti/keystone_pa.h
 create mode 100644 drivers/net/ethernet/ti/keystone_pa2.c
 create mode 100644 drivers/net/ethernet/ti/keystone_pa2.h
 create mode 100644 drivers/net/ethernet/ti/keystone_pasahost.h
 create mode 100644 drivers/net/ethernet/ti/keystone_pasahost2.h

diff --git a/drivers/net/ethernet/ti/keystone_pa.c b/drivers/net/ethernet/ti/keystone_pa.c
new file mode 100644
index 0000000..5b4875f
--- /dev/null
+++ b/drivers/net/ethernet/ti/keystone_pa.c
@@ -0,0 +1,2864 @@
+/*
+ * Copyright (C) 2012 Texas Instruments Incorporated
+ * Authors: Sandeep Paulraj <s-paulraj@ti.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation version 2.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/clk.h>
+#include <linux/slab.h>
+#include <linux/delay.h>
+#include <linux/types.h>
+#include <linux/module.h>
+#include <linux/delay.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/of_address.h>
+#include <linux/firmware.h>
+#include <linux/spinlock.h>
+#include <linux/highmem.h>
+#include <linux/interrupt.h>
+#include <linux/dmaengine.h>
+#include <linux/net_tstamp.h>
+#include <linux/dma-mapping.h>
+#include <linux/scatterlist.h>
+#include <linux/byteorder/generic.h>
+#include <linux/platform_device.h>
+#include <linux/keystone-dma.h>
+#include <linux/phy.h>
+#include <linux/errqueue.h>
+#include <linux/ptp_classify.h>
+#include <net/sctp/checksum.h>
+#include <linux/clocksource.h>
+
+#include "keystone_net.h"
+#include "keystone_pa.h"
+#include "keystone_pasahost.h"
+
+#define BITS(x) (BIT(x) - 1)
+
+#define BITS(x)			(BIT(x) - 1)
+
+#define	PA_NETIF_FEATURES	(NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM)
+
+#define PSTREAM_ROUTE_PDSP0	0
+
+#define PA_PDSP_ALREADY_ACTIVE	0
+#define PA_PDSP_RESET_RELEASED	1
+#define PA_PDSP_NO_RESTART	2
+#define PA_MAX_PDSP_ENABLE_LOOP_COUNT	100000
+
+#define PA_INVALID_PORT			0xff
+
+#define PA_STATE_RESET			0  /* Sub-system state reset */
+#define PA_STATE_ENABLE			1  /* Sub-system state enable  */
+#define PA_STATE_QUERY			2  /* Query the Sub-system state */
+#define PA_STATE_INCONSISTENT		3  /* Sub-system is partially enabled */
+#define PA_STATE_INVALID_REQUEST	4  /* Invalid state command to the Sub-system */
+#define PA_STATE_ENABLE_FAILED		5  /*  The Sub-system did not respond after restart */
+
+/* System Timestamp */
+#define PAFRM_SRAM_SIZE			0x2000
+#define PAFRM_SYS_TIMESTAMP_ADDR	0x6460
+
+/* PDSP Versions */
+#define PAFRM_PDSP_VERSION_BASE		0x7F04
+
+#define DEVICE_PA_BASE				0x02000000
+#define DEVICE_PA_REGION_SIZE			0x48000
+#define DEVICE_PA_NUM_PDSPS			6
+
+#define PA_MEM_PDSP_IRAM(pdsp)			((pdsp) * 0x8000)
+#define PA_MEM_PDSP_SRAM(num)			((num) * 0x2000)
+#define PA_REG_PKTID_SOFT_RESET	                0x00404
+#define PA_REG_LUT2_SOFT_RESET	                0x00504
+#define PA_REG_STATS_SOFT_RESET	                0x06004
+
+#define PA_PDSP_CONST_REG_INDEX_C25_C24     0
+#define PA_PDSP_CONST_REG_INDEX_C27_C26     1
+#define PA_PDSP_CONST_REG_INDEX_C29_C28     2
+#define PA_PDSP_CONST_REG_INDEX_C31_C30     3
+
+/* The pdsp control register */
+#define PA_REG_VAL_PDSP_CTL_DISABLE_PDSP	1
+#define PA_REG_VAL_PDSP_CTL_RESET_PDSP	        0
+#define PA_REG_VAL_PDSP_CTL_STATE               (1 << 15)
+#define PA_REG_VAL_PDSP_CTL_ENABLE              (1 << 1)
+#define PA_REG_VAL_PDSP_CTL_SOFT_RESET          (1 << 0)
+#define PA_REG_VAL_PDSP_CTL_ENABLE_PDSP(pcval)	(((pcval) << 16)	\
+						 | PA_REG_VAL_PDSP_CTL_ENABLE \
+						 | PA_REG_VAL_PDSP_CTL_SOFT_RESET)
+
+/* Number of mailbox slots for each PDPS */
+#define PA_NUM_MAILBOX_SLOTS	4
+#define TEST_SWINFO0_TIMESTAMP	0x12340002
+
+#define PACKET_DROP	0
+#define PACKET_PARSE	1
+#define PACKET_HST	2
+
+#define NT 32
+
+#define PA_SGLIST_SIZE	3
+
+const u32 pap_pdsp_const_reg_map[DEVICE_PA_NUM_PDSPS][4] =
+{
+	/* PDSP0: C24-C31 */
+	{
+		0x0000007F,		/* C25-C24 */
+		0x0000006E,		/* C27-C26 */
+		0x00000000,		/* C29-C28 */
+		0x00000473		/* C31-C30 */
+	},
+	/* PDSP1: C24-C31 */
+	{
+		0x0001007F,		/* C25-C24 */
+		0x00480040,		/* C27-C26 */
+		0x00000000,		/* C29-C28 */
+		0x00000473		/* C31-C30 */
+	},
+	/* PDSP2: C24-C31 */
+	{
+		0x0002007F,		/* C25-C24 */
+		0x00490044,		/* C27-C26 */
+		0x00000000,		/* C29-C28 */
+		0x00000473		/* C31-C30 */
+	},
+	/* PDSP3: C24-C31 */
+	{
+		0x0003007F,		/* C25-C24 */
+		0x0000006E,		/* C27-C26 */
+		0x00000000,		/* C29-C28 */
+		0x00000473		/* C31-C30 */
+	},
+	/* PDSP4: C24-C31 */
+	{
+		0x0070007F,		/* C25-C24 */
+		0x00000003,		/* C27-C26 */
+		0x04080404,		/* C29-C28 */
+		0x00000473		/* C31-C30 */
+	},
+	/* PDSP5: C24-C31 */
+	{
+		0x0071007F,		/* C25-C24 */
+		0x00000003,		/* C27-C26 */
+		0x04080404,		/* C29-C28 */
+		0x00000473		/* C31-C30 */
+	}
+};
+
+struct pa_mailbox_regs {
+	u32 pdsp_mailbox_slot0;
+	u32 pdsp_mailbox_slot1;
+	u32 pdsp_mailbox_slot2;
+	u32 pdsp_mailbox_slot3;
+};
+
+struct pa_packet_id_alloc_regs {
+	u32 revision;
+	u32 soft_reset;
+	u32 range_limit;
+	u32 idvalue;
+};
+
+struct pa_lut2_control_regs {
+	u32 revision;
+	u32 soft_reset;
+	u32 rsvd[6];
+	u32 add_data0;
+	u32 add_data1;
+	u32 add_data2;
+	u32 add_data3;
+	u32 add_del_key;
+	u32 add_del_control;
+};
+
+struct pa_pdsp_control_regs {
+	u32 control;
+	u32 status;
+	u32 wakeup_enable;
+	u32 cycle_count;
+	u32 stall_count;
+	u32 rsvd[3];
+	u32 const_tbl_blk_index0;
+	u32 const_tbl_blk_index1;
+	u32 const_tbl_prog_pointer0;
+	u32 const_tbl_prog_pointer1;
+	u32 rsvd1[52];
+};
+
+struct pa_pdsp_timer_regs {
+	u32 timer_control;
+	u32 timer_load;
+	u32 timer_value;
+	u32 timer_interrupt;
+	u32 rsvd[60];
+};
+
+struct pa_statistics_regs {
+	u32 revision;
+	u32 soft_reset;
+	u32 incr_flags;
+	u32 stats_capture;
+	u32 rsvd[4];
+	u32 stats_red[32];
+};
+
+#define	CSUM_OFFLOAD_NONE	0
+#define	CSUM_OFFLOAD_HARD	1
+#define	CSUM_OFFLOAD_SOFT	2
+
+#define	PA_TXHOOK_ORDER	10
+#define	PA_RXHOOK_ORDER	10
+
+static DEFINE_MUTEX(pa_modules_lock);
+
+enum pa_lut_type {
+	PA_LUT_MAC,
+	PA_LUT_IP
+};
+
+struct pa_lut_entry {
+	int			index;
+	bool			valid, in_use;
+	union {
+		struct netcp_addr	*naddr;
+		u8			ip_proto;
+	} u;
+};
+
+struct pa_timestamp_info {
+	u32	mult;
+	u32	shift;
+	u64	system_offset;
+};
+
+struct pa_intf {
+	struct pa_device		*pa_device;
+	struct net_device		*net_device;
+	bool				 tx_timestamp_enable;
+	bool				 rx_timestamp_enable;
+	struct netcp_tx_pipe		 tx_pipe;
+	unsigned			 data_flow_num;
+	unsigned			 data_queue_num;
+	u32				 saved_ss_state;
+	char				 tx_chan_name[24];
+};
+
+struct pa_device {
+	int				force_no_hwtstamp;
+	u32				csum_offload;
+	struct pa_timestamp_info	timestamp_info;
+	u32				multi_if;
+	u32				mark_mcast_match[2];
+	unsigned			cmd_flow_num;
+	unsigned			cmd_queue_num;
+
+	struct netcp_device		*netcp_device;
+	struct device			*dev;
+	struct clk			*clk;
+	struct dma_chan			*pdsp0_tx_channel;
+	struct dma_chan			*pdsp1_tx_channel;
+	struct dma_chan			*rx_channel;
+	const char			*rx_chan_name;
+	unsigned			 rx_flow_base;
+	unsigned			 rx_queue_base;
+
+	struct pa_mailbox_regs __iomem		*reg_mailbox;
+	struct pa_packet_id_alloc_regs __iomem	*reg_packet_id;
+	struct pa_lut2_control_regs __iomem	*reg_lut2;
+	struct pa_pdsp_control_regs __iomem	*reg_control;
+	struct pa_pdsp_timer_regs   __iomem	*reg_timer;
+	struct pa_statistics_regs   __iomem	*reg_stats;
+	void __iomem				*pa_sram;
+	void __iomem				*pa_iram;
+
+	u8				*mc_list;
+	u8				 addr_count;
+	struct tasklet_struct		 task;
+	spinlock_t			 lock;
+
+	u32				 tx_cmd_queue_depth;
+	u32				 tx_data_queue_depth;
+	u32				 rx_pool_depth;
+	u32				 rx_buffer_size;
+	u32				 txhook_order;
+	u32				 txhook_softcsum;
+	u32				 rxhook_order;
+	u32				 inuse_if_count;
+	u32				 lut_inuse_count;
+	struct pa_lut_entry		 *lut;
+	u32				 lut_size;
+	struct pa_lut_entry		 *ip_lut;
+	u32				 ip_lut_size;
+	netdev_features_t		 netif_features;
+	const char			*pdsp_fw[DEVICE_PA_NUM_PDSPS];
+};
+
+#define pa_from_module(data)	container_of(data, struct pa_device, module)
+#define pa_to_module(pa)	(&(pa)->module)
+
+struct pa_packet {
+	struct scatterlist		 sg[PA_SGLIST_SIZE];
+	int				 sg_ents;
+	struct pa_device		*priv;
+	struct dma_chan			*chan;
+	struct dma_async_tx_descriptor	*desc;
+	dma_cookie_t			 cookie;
+	u32				 epib[4];
+	u32				 psdata[6];
+	struct completion		 complete;
+	void				*data;
+};
+
+static void pdsp_fw_put(u32 *dest, const u32 *src, u32 wc)
+{
+	int i;
+
+	for (i = 0; i < wc; i++)
+		*dest++ = be32_to_cpu(*src++);
+}
+
+static inline void swiz_fwd(struct pa_frm_forward *fwd)
+{
+	fwd->flow_id = fwd->flow_id;
+	fwd->queue   = cpu_to_be16(fwd->queue);
+
+	if (fwd->forward_type == PAFRM_FORWARD_TYPE_HOST) {
+		fwd->u.host.context      = cpu_to_be32(fwd->u.host.context);
+		fwd->u.host.ctrl_bm  = fwd->u.host.ctrl_bm;
+		fwd->u.host.multi_idx    = fwd->u.host.multi_idx;
+		fwd->u.host.pa_pdsp_router = fwd->u.host.pa_pdsp_router;
+	} else if (fwd->forward_type == PAFRM_FORWARD_TYPE_SA) {
+		fwd->u.sa.sw_info_0 = cpu_to_be32(fwd->u.sa.sw_info_0);
+		fwd->u.sa.sw_info_1 = cpu_to_be32(fwd->u.sa.sw_info_1);
+	} else if (fwd->forward_type == PAFRM_FORWARD_TYPE_SRIO) {
+		fwd->u.srio.ps_info0 = cpu_to_be32(fwd->u.srio.ps_info0);
+		fwd->u.srio.ps_info1 = cpu_to_be32(fwd->u.srio.ps_info1);
+		fwd->u.srio.pkt_type = fwd->u.srio.pkt_type;
+	} else if (fwd->forward_type == PAFRM_FORWARD_TYPE_ETH) {
+		fwd->u.eth.ps_flags	= fwd->u.eth.ps_flags;
+	} else if (fwd->forward_type == PAFRM_FORWARD_TYPE_PA) {
+		fwd->u.pa.pa_dest	= fwd->u.pa.pa_dest;
+		fwd->u.pa.custom_type	= fwd->u.pa.custom_type;
+		fwd->u.pa.custom_idx	= fwd->u.pa.custom_idx;
+	}
+
+	fwd->forward_type = fwd->forward_type;
+}
+
+static inline void swizFcmd (struct pa_frm_command *fcmd)
+{
+	fcmd->command_result =  cpu_to_be32(fcmd->command_result);
+	fcmd->command	     =  fcmd->command;
+	fcmd->magic          =  fcmd->magic;
+	fcmd->com_id         =  cpu_to_be16(fcmd->com_id);
+	fcmd->ret_context    =  cpu_to_be32(fcmd->ret_context);
+	fcmd->reply_queue    =  cpu_to_be16(fcmd->reply_queue);
+	fcmd->reply_dest     =  fcmd->reply_dest;
+	fcmd->flow_id        =  fcmd->flow_id;
+}
+
+static inline void swizAl1 (struct pa_frm_cmd_add_lut1 *al1)
+{
+	al1->index         =  al1->index;
+	al1->type          =  al1->type;
+	al1->cust_index    =  al1->cust_index;
+
+	if (al1->type == PAFRM_COM_ADD_LUT1_STANDARD) {
+		al1->u.eth_ip.etype = cpu_to_be16(al1->u.eth_ip.etype);
+		al1->u.eth_ip.vlan  = cpu_to_be16(al1->u.eth_ip.vlan);
+		al1->u.eth_ip.spi   = cpu_to_be32(al1->u.eth_ip.spi);
+		al1->u.eth_ip.flow  = cpu_to_be32(al1->u.eth_ip.flow);
+
+		if (al1->u.eth_ip.key & PAFRM_LUT1_KEY_MPLS)
+			al1->u.eth_ip.pm.mpls     =  cpu_to_be32(al1->u.eth_ip.pm.mpls);
+		else {
+			al1->u.eth_ip.pm.ports[0] =  cpu_to_be16(al1->u.eth_ip.pm.ports[0]);
+			al1->u.eth_ip.pm.ports[1] =  cpu_to_be16(al1->u.eth_ip.pm.ports[1]);
+		}
+
+		al1->u.eth_ip.proto_next  =  al1->u.eth_ip.proto_next;
+		al1->u.eth_ip.tos_tclass  =  al1->u.eth_ip.tos_tclass;
+		al1->u.eth_ip.inport      =  al1->u.eth_ip.inport;
+		al1->u.eth_ip.key         =  al1->u.eth_ip.key;
+		al1->u.eth_ip.match_flags =  cpu_to_be16(al1->u.eth_ip.match_flags);
+	} else if (al1->type == PAFRM_COM_ADD_LUT1_SRIO) {
+		al1->u.srio.src_id	= cpu_to_be16(al1->u.srio.src_id);
+		al1->u.srio.dest_id	= cpu_to_be16(al1->u.srio.dest_id);
+		al1->u.srio.etype	= cpu_to_be16(al1->u.srio.etype);
+		al1->u.srio.vlan	= cpu_to_be16(al1->u.srio.vlan);
+		al1->u.srio.pri         = al1->u.srio.pri;
+		al1->u.srio.type_param1 = cpu_to_be16(al1->u.srio.type_param1);
+		al1->u.srio.type_param2 = al1->u.srio.type_param2;
+		al1->u.srio.key         = al1->u.srio.key;
+		al1->u.srio.match_flags = cpu_to_be16(al1->u.srio.match_flags);
+		al1->u.srio.next_hdr    = al1->u.srio.next_hdr;
+		al1->u.srio.next_hdr_offset = cpu_to_be16(al1->u.srio.next_hdr_offset);
+	} else {
+		al1->u.custom.etype		=  cpu_to_be16(al1->u.custom.etype);
+		al1->u.custom.vlan		=  cpu_to_be16(al1->u.custom.vlan);
+		al1->u.custom.key		=  al1->u.custom.key;
+		al1->u.custom.match_flags	=  cpu_to_be16(al1->u.custom.match_flags);
+	}
+
+	swiz_fwd(&(al1->match));
+	swiz_fwd(&(al1->next_fail));
+}
+
+static int pa_conv_routing_info(struct	pa_frm_forward *fwd_info,
+			 struct	pa_route_info *route_info,
+			 int cmd_dest, u16 fail_route)
+{
+	u8 *pcmd = NULL;
+	fwd_info->flow_id = route_info->flow_id;
+	fwd_info->queue   = route_info->queue;
+
+	if (route_info->dest == PA_DEST_HOST) {
+		fwd_info->forward_type   = PAFRM_FORWARD_TYPE_HOST;
+		fwd_info->u.host.context = route_info->sw_info_0;
+
+		if (route_info->route_type)
+			fwd_info->u.host.ctrl_bm |=
+				PAFRM_ROUTING_IF_DEST_SELECT_ENABLE;
+
+		if (route_info->route_type == PA_ROUTE_INTF_FLOW)
+			fwd_info->u.host.ctrl_bm |=
+				PAFRM_ROUTING_FLOW_IF_BASE_ENABLE;
+
+		if (route_info->m_route_index >= 0) {
+			if (route_info->m_route_index >=
+			    PA_MAX_MULTI_ROUTE_SETS)
+				return (PA_ERR_CONFIG);
+
+			fwd_info->u.host.ctrl_bm |= PAFRM_MULTIROUTE_ENABLE;
+			fwd_info->u.host.multi_idx = route_info->m_route_index;
+			fwd_info->u.host.pa_pdsp_router	= PAFRM_DEST_PA_M_0;
+		}
+		pcmd = fwd_info->u.host.cmd;
+	} else if (route_info->dest == PA_DEST_DISCARD)	{
+		fwd_info->forward_type = PAFRM_FORWARD_TYPE_DISCARD;
+	} else if (route_info->dest == PA_DEST_EMAC) {
+		fwd_info->forward_type = PAFRM_FORWARD_TYPE_ETH;
+		fwd_info->u.eth.ps_flags = (route_info->pkt_type_emac_ctrl &
+					    PA_EMAC_CTRL_CRC_DISABLE)?
+			PAFRM_ETH_PS_FLAGS_DISABLE_CRC:0;
+		fwd_info->u.eth.ps_flags |= ((route_info->pkt_type_emac_ctrl &
+					      PA_EMAC_CTRL_PORT_MASK) <<
+					     PAFRM_ETH_PS_FLAGS_PORT_SHIFT);
+	} else if (fail_route) {
+		return (PA_ERR_CONFIG);
+
+	} else if (((route_info->dest == PA_DEST_CONTINUE_PARSE_LUT1) &&
+		    (route_info->custom_type != PA_CUSTOM_TYPE_LUT2)) ||
+		   ((route_info->dest == PA_DEST_CONTINUE_PARSE_LUT2) &&
+		    (route_info->custom_type != PA_CUSTOM_TYPE_LUT1))) {
+
+		/* Custom Error check */
+		if (((route_info->custom_type == PA_CUSTOM_TYPE_LUT1) &&
+		     (route_info->custom_index >= PA_MAX_CUSTOM_TYPES_LUT1)) ||
+		    ((route_info->custom_type == PA_CUSTOM_TYPE_LUT2) &&
+		     (route_info->custom_index >= PA_MAX_CUSTOM_TYPES_LUT2)))
+			return(PA_ERR_CONFIG);
+
+		fwd_info->forward_type = PAFRM_FORWARD_TYPE_PA;
+		fwd_info->u.pa.custom_type = (u8)route_info->custom_type;
+		fwd_info->u.pa.custom_idx  = route_info->custom_index;
+
+		if (route_info->dest == PA_DEST_CONTINUE_PARSE_LUT2) {
+			fwd_info->u.pa.pa_dest = PAFRM_DEST_PA_C2;
+		} else {
+			/*
+			 * cmd_dest is provided by calling function
+			 * There is no need to check error case
+			 */
+			fwd_info->u.pa.pa_dest = (cmd_dest == PA_CMD_TX_DEST_0)?
+				PAFRM_DEST_PA_C1_1:PAFRM_DEST_PA_C1_2;
+		}
+	} else if (route_info->dest == PA_DEST_SASS) {
+		fwd_info->forward_type   = PAFRM_FORWARD_TYPE_SA;
+		fwd_info->u.sa.sw_info_0 = route_info->sw_info_0;
+		fwd_info->u.sa.sw_info_1 = route_info->sw_info_1;
+		pcmd = fwd_info->u.sa.cmd;
+	} else if (route_info->dest == PA_DEST_SRIO) {
+		fwd_info->forward_type		= PAFRM_FORWARD_TYPE_SRIO;
+		fwd_info->u.srio.ps_info0	= route_info->sw_info_0;
+		fwd_info->u.srio.ps_info1	= route_info->sw_info_1;
+		fwd_info->u.srio.pkt_type	= route_info->pkt_type_emac_ctrl;
+	} else {
+		return (PA_ERR_CONFIG);
+	}
+
+	if (pcmd && route_info->pcmd) {
+		struct pa_cmd_info *pacmd = route_info->pcmd;
+		struct pa_patch_info *patch_info;
+		struct pa_cmd_set *cmd_set;
+
+		switch (pacmd->cmd) {
+		case PA_CMD_PATCH_DATA:
+			patch_info = &pacmd->params.patch;
+			if ((patch_info->n_patch_bytes > 2) ||
+			    (patch_info->overwrite) ||
+			    (patch_info->patch_data == NULL))
+				return (PA_ERR_CONFIG);
+
+			pcmd[0] = PAFRM_RX_CMD_CMDSET;
+			pcmd[1] = patch_info->n_patch_bytes;
+			pcmd[2] = patch_info->patch_data[0];
+			pcmd[3] = patch_info->patch_data[1];
+			break;
+
+		case PA_CMD_CMDSET:
+			cmd_set = &pacmd->params.cmd_set;
+			if(cmd_set->index >= PA_MAX_CMD_SETS)
+				return (PA_ERR_CONFIG);
+
+			pcmd[0] = PAFRM_RX_CMD_CMDSET;
+			pcmd[1] = (u8)cmd_set->index;
+			break;
+		default:
+			return(PA_ERR_CONFIG);
+		}
+	}
+	return (PA_OK);
+}
+
+static int keystone_pa_reset(struct pa_device *pa_dev)
+{
+	struct pa_packet_id_alloc_regs __iomem	*packet_id_regs = pa_dev->reg_packet_id;
+	struct pa_lut2_control_regs __iomem	*lut2_regs = pa_dev->reg_lut2;
+	struct pa_statistics_regs   __iomem	*stats_regs = pa_dev->reg_stats;
+	u32 i;
+
+	/* Reset and disable all PDSPs */
+	for (i = 0; i < DEVICE_PA_NUM_PDSPS; i++) {
+		struct pa_pdsp_control_regs __iomem *ctrl_reg = &pa_dev->reg_control[i];
+		__raw_writel(PA_REG_VAL_PDSP_CTL_RESET_PDSP,
+			     &ctrl_reg->control);
+		wmb();
+
+		while((__raw_readl(&ctrl_reg->control) &
+				PA_REG_VAL_PDSP_CTL_STATE))
+			rmb();
+	}
+
+	/* Reset packet Id */
+	__raw_writel(1, &packet_id_regs->soft_reset);
+
+	/* Reset LUT2 */
+	__raw_writel(1, &lut2_regs->soft_reset);
+
+	/* Reset statistic */
+	__raw_writel(1, &stats_regs->soft_reset);
+
+	/* Reset timers */
+	for (i = 0; i < DEVICE_PA_NUM_PDSPS; i++) {
+		struct pa_pdsp_timer_regs __iomem *timer_reg = &pa_dev->reg_timer[i];
+		__raw_writel(0, &timer_reg->timer_control);
+	}
+
+	wmb();
+	return 0;
+}
+
+/*
+ *  Convert a raw PA timer count to nanoseconds
+ */
+static inline u64 tstamp_raw_to_ns(struct pa_device *pa_dev, u32 lo, u32 hi)
+{
+	u32 mult = pa_dev->timestamp_info.mult;
+	u32 shift = pa_dev->timestamp_info.shift;
+	u64 result;
+
+	/* Minimize overflow errors by doing this in pieces */
+	result  = ((u64)lo * mult) >> shift;
+	result += ((u64)hi << (32 - shift)) * mult;
+
+	return result;
+}
+
+static u64 pa_to_sys_time(struct pa_device *pa_dev, u64 pa_ns)
+{
+	s64 temp;
+	u64 result;
+
+	/* we need to compute difference from wallclock
+	*  to time from boot dynamically since
+	*  it will change whenever absolute time is adjusted by
+	*  protocols above (ntp, ptpv2)
+	*/
+
+	temp = ktime_to_ns(ktime_get_monotonic_offset());
+	result = (u64)((s64)pa_dev->timestamp_info.system_offset - temp +
+			(s64)pa_ns);
+
+	return result;
+}
+
+/*
+ * calibrate the PA timer to the system time
+ * ktime_get gives montonic time 
+ * ktime_to_ns converts ktime to ns
+ * this needs to be called before doing conversions
+ */
+static void pa_calibrate_with_system_timer(struct pa_device *pa_dev)
+{
+	struct pa_pdsp_timer_regs __iomem *timer_reg = &pa_dev->reg_timer[0];
+	ktime_t ktime1, ktime2;
+	u32 timer, low1, low2, high;
+	u32 pa_lo, pa_hi;
+	u64 pa_ns, sys_ns1, sys_ns2;
+	int count;
+
+	/* Obtain the internal PA timestamp counter values */
+	count = 0;
+	do {
+		__iormb();
+		ktime1 = ktime_get();
+		low1  = __raw_readl(pa_dev->pa_sram + 0x6460);
+		__iormb();
+		high  = __raw_readl(pa_dev->pa_sram + 0x6464);
+		timer = __raw_readl(&timer_reg->timer_value);
+		__iormb();
+		low2  = __raw_readl(pa_dev->pa_sram + 0x6460);
+		ktime2 = ktime_get();
+	} while (unlikely(low1 != low2) && (++count < 32));
+
+	/* Convert the PA timestamp to nanoseconds */
+	pa_lo = (low1 << 16) | (0x0000ffff - (timer & 0x0000ffff));
+	pa_hi = (high << 16) | (low1 >> 16);
+	pa_ns   = tstamp_raw_to_ns(pa_dev, pa_lo, pa_hi);
+
+	/* Convert the system time values to nanoseconds */
+	sys_ns1 = ktime_to_ns(ktime1);
+	sys_ns2 = ktime_to_ns(ktime2);
+
+	/* Compute the PA-to-system offset */
+	pa_dev->timestamp_info.system_offset = sys_ns1 +
+		((sys_ns2 - sys_ns1) / 2) - pa_ns;
+}
+
+static void pa_get_version(struct pa_device *pa_dev)
+{
+	u32 version;
+
+	version = __raw_readl(pa_dev->pa_sram + PAFRM_PDSP_VERSION_BASE);
+
+	dev_info(pa_dev->dev, "Using Packet Accelerator Firmware version "
+				"0x%08x\n", version);
+}
+
+static int pa_pdsp_run(struct pa_device *pa_dev, int pdsp)
+{
+	struct pa_pdsp_control_regs __iomem *ctrl_reg = &pa_dev->reg_control[pdsp];
+	struct pa_mailbox_regs __iomem *mailbox_reg = &pa_dev->reg_mailbox[pdsp];
+	u32 i, v;
+
+	/* Check for enabled PDSP */
+	v = __raw_readl(&ctrl_reg->control);
+	if ((v & PA_REG_VAL_PDSP_CTL_ENABLE) ==
+	    PA_REG_VAL_PDSP_CTL_ENABLE) {
+		/* Already enabled */
+		return (PA_PDSP_ALREADY_ACTIVE);
+	}
+
+	/* Clear the mailbox */
+	__raw_writel(0, &mailbox_reg->pdsp_mailbox_slot0);
+
+	/* Set PDSP PC to 0, enable the PDSP */
+	__raw_writel(PA_REG_VAL_PDSP_CTL_ENABLE |
+		     PA_REG_VAL_PDSP_CTL_SOFT_RESET,
+		     &ctrl_reg->control);
+
+	/* Wait for the mailbox to become non-zero */
+	for (i = 0; i < PA_MAX_PDSP_ENABLE_LOOP_COUNT; i++)
+		v = __raw_readl(&mailbox_reg->pdsp_mailbox_slot0);
+		if (v != 0)
+			return (PA_PDSP_RESET_RELEASED);
+
+	return (PA_PDSP_NO_RESTART);
+}
+
+static int keystone_pa_reset_control(struct pa_device *pa_dev, int new_state)
+{
+	struct pa_mailbox_regs __iomem *mailbox_reg = &pa_dev->reg_mailbox[0];
+	int do_global_reset = 1;
+	int i, res;
+	int ret;
+
+	if (new_state == PA_STATE_ENABLE) {
+		ret = PA_STATE_ENABLE;
+
+		/*
+		 * Do nothing if a pdsp is already out of reset.
+		 * If any PDSPs are out of reset
+		 * a global init is not performed
+		 */
+		for (i = 0; i < DEVICE_PA_NUM_PDSPS; i++) {
+			res = pa_pdsp_run(pa_dev, i);
+
+			if (res == PA_PDSP_ALREADY_ACTIVE)
+				do_global_reset = 0;
+
+			if (res == PA_PDSP_NO_RESTART) {
+				ret = PA_STATE_ENABLE_FAILED;
+				do_global_reset = 0;
+			}
+		}
+
+		/* If global reset is required any PDSP can do it */
+		if (do_global_reset) {
+			__raw_writel(1, &mailbox_reg->pdsp_mailbox_slot1);
+			wmb();
+			__raw_writel(0, &mailbox_reg->pdsp_mailbox_slot0);
+			mb();
+
+			while (__raw_readl(&mailbox_reg->pdsp_mailbox_slot1) != 0)
+				rmb();
+
+			for (i = 1; i < DEVICE_PA_NUM_PDSPS; i++) {
+				struct pa_mailbox_regs __iomem *mbox_reg =
+					&pa_dev->reg_mailbox[i];
+				__raw_writel(0,
+					     &mbox_reg->pdsp_mailbox_slot0);
+			}
+			wmb();
+		} else {
+			for (i = 0; i < DEVICE_PA_NUM_PDSPS; i++) {
+				struct pa_mailbox_regs __iomem *mbox_reg =
+					&pa_dev->reg_mailbox[i];
+				__raw_writel(0,
+					     &mbox_reg->pdsp_mailbox_slot0);
+			}
+			wmb();
+		}
+
+		return (ret);
+	}
+
+	return (PA_STATE_INVALID_REQUEST);
+}
+
+static int keystone_pa_set_firmware(struct pa_device *pa_dev,
+			     int pdsp, const unsigned int *buffer, int len)
+{
+	struct pa_pdsp_control_regs __iomem *ctrl_reg = &pa_dev->reg_control[pdsp];
+
+	if ((pdsp < 0) || (pdsp >= DEVICE_PA_NUM_PDSPS))
+		return -EINVAL;
+
+	pdsp_fw_put((u32 *)(pa_dev->pa_iram + PA_MEM_PDSP_IRAM(pdsp)), buffer,
+		    len >> 2);
+
+	__raw_writel(pap_pdsp_const_reg_map[pdsp][PA_PDSP_CONST_REG_INDEX_C25_C24],
+		     &ctrl_reg->const_tbl_blk_index0);
+
+	__raw_writel(pap_pdsp_const_reg_map[pdsp][PA_PDSP_CONST_REG_INDEX_C27_C26],
+		     &ctrl_reg->const_tbl_blk_index1);
+
+	__raw_writel(pap_pdsp_const_reg_map[pdsp][PA_PDSP_CONST_REG_INDEX_C29_C28],
+		     &ctrl_reg->const_tbl_prog_pointer0);
+
+	__raw_writel(pap_pdsp_const_reg_map[pdsp][PA_PDSP_CONST_REG_INDEX_C31_C30],
+		     &ctrl_reg->const_tbl_prog_pointer1);
+
+	return 0;
+}
+
+static inline void pa_free_packet(struct pa_device *pa_dev, void *pkt)
+{
+	devm_kfree(pa_dev->dev, pkt);
+}
+
+static struct pa_packet *pa_alloc_packet(struct pa_device *pa_dev,
+					 unsigned cmd_size,
+					 struct dma_chan *dma_chan)
+{
+	struct pa_packet *p_info;
+
+	p_info = devm_kzalloc(pa_dev->dev, sizeof(*p_info) + cmd_size,
+			      GFP_ATOMIC);
+	if (!p_info)
+		return NULL;
+
+	p_info->priv = pa_dev;
+	p_info->data = p_info + 1;
+	p_info->chan = dma_chan;
+
+	sg_init_table(p_info->sg, PA_SGLIST_SIZE);
+	sg_set_buf(&p_info->sg[0], p_info->epib, sizeof(p_info->epib));
+	sg_set_buf(&p_info->sg[1], p_info->psdata, sizeof(p_info->psdata));
+	sg_set_buf(&p_info->sg[2], p_info->data, cmd_size);
+	return p_info;
+}
+
+static void pa_tx_dma_callback(void *data)
+{
+	struct pa_packet *p_info = data;
+	struct pa_device *pa_dev = p_info->priv;
+	enum dma_status status;
+	unsigned long irqsave;
+	dma_cookie_t cookie;
+
+	spin_lock_irqsave(&pa_dev->lock, irqsave);
+	cookie = p_info->cookie;
+	spin_unlock_irqrestore(&pa_dev->lock, irqsave);
+
+	if (unlikely(cookie <= 0))
+		WARN(1, "invalid dma cookie == %d", cookie);
+	else {
+		status = dma_async_is_tx_complete(p_info->chan,
+						  cookie, NULL, NULL);
+		WARN((status != DMA_SUCCESS),
+				"dma completion failure, status == %d", status);
+	}
+
+	dma_unmap_sg(pa_dev->dev, &p_info->sg[2], 1, DMA_TO_DEVICE);
+	p_info->desc = NULL;
+	pa_free_packet(pa_dev, p_info);
+}
+
+static int pa_submit_tx_packet(struct pa_packet *p_info)
+{
+	unsigned flags = DMA_HAS_EPIB | DMA_HAS_PSINFO;
+	struct pa_device *pa_dev = p_info->priv;
+	unsigned long irqsave;
+	int ret;
+
+	ret = dma_map_sg(pa_dev->dev, &p_info->sg[2], 1, DMA_TO_DEVICE);
+	if (ret < 0)
+		return ret;
+
+	p_info->desc = dmaengine_prep_slave_sg(p_info->chan, p_info->sg, 3,
+					       DMA_TO_DEVICE, flags);
+	if (IS_ERR_OR_NULL(p_info->desc)) {
+		dma_unmap_sg(pa_dev->dev, &p_info->sg[2], 1, DMA_TO_DEVICE);
+		return PTR_ERR(p_info->desc);
+	}
+
+	p_info->desc->callback = pa_tx_dma_callback;
+	p_info->desc->callback_param = p_info;
+
+	spin_lock_irqsave(&pa_dev->lock, irqsave);
+	p_info->cookie = dmaengine_submit(p_info->desc);
+	spin_unlock_irqrestore(&pa_dev->lock, irqsave);
+
+	return dma_submit_error(p_info->cookie) ? p_info->cookie : 0;
+}
+
+#define	PA_CONTEXT_MASK		0xffff0000
+#define	PA_CONTEXT_CONFIG	0xdead0000
+#define	PA_CONTEXT_TSTAMP	0xbeef0000
+
+#define	TSTAMP_TIMEOUT	(HZ * 5)	/* 5 seconds (arbitrary) */
+
+struct tstamp_pending {
+	struct list_head	 list;
+	u32			 context;
+	struct sock		*sock;
+	struct sk_buff		*skb;
+	struct pa_device	*pa_dev;
+	struct timer_list	 timeout;
+};
+
+static spinlock_t		 tstamp_lock;
+static atomic_t			 tstamp_sequence = ATOMIC_INIT(0);
+static struct list_head		 tstamp_pending = LIST_HEAD_INIT(tstamp_pending);
+
+static struct tstamp_pending *tstamp_remove_pending(u32 context)
+{
+	struct tstamp_pending	*pend;
+
+	spin_lock(&tstamp_lock);
+	list_for_each_entry(pend, &tstamp_pending, list) {
+		if (pend->context == context) {
+			del_timer(&pend->timeout);
+			list_del(&pend->list);
+			spin_unlock(&tstamp_lock);
+			return pend;
+		}
+	}
+	spin_unlock(&tstamp_lock);
+
+	return NULL;
+}
+
+static void tstamp_complete(u32, struct pa_packet *);
+
+static void tstamp_purge_pending(struct pa_device *pa_dev)
+{
+	struct tstamp_pending	*pend;
+	int			 found;
+
+	/* This is ugly and inefficient, but very rarely executed */
+	do {
+		found = 0;
+
+		spin_lock(&tstamp_lock);
+		list_for_each_entry(pend, &tstamp_pending, list) {
+			if (pend->pa_dev == pa_dev) {
+				found = 1;
+				break;
+			}
+		}
+		spin_unlock(&tstamp_lock);
+
+		if (found)
+			tstamp_complete(pend->context, NULL);
+	} while(found);
+}
+
+static void tstamp_timeout(unsigned long context)
+{
+	tstamp_complete((u32)context, NULL);
+}
+
+static int tstamp_add_pending(struct tstamp_pending *pend)
+{
+	init_timer(&pend->timeout);
+	pend->timeout.expires = jiffies + TSTAMP_TIMEOUT;
+	pend->timeout.function = tstamp_timeout;
+	pend->timeout.data = (unsigned long)pend->context;
+
+	spin_lock(&tstamp_lock);
+	add_timer(&pend->timeout);
+	list_add_tail(&pend->list, &tstamp_pending);
+	spin_unlock(&tstamp_lock);
+
+	return 0;
+}
+
+static void tstamp_complete(u32 context, struct pa_packet *p_info)
+{
+	struct pa_device	*pa_dev;
+	struct tstamp_pending	*pend;
+	struct sock_exterr_skb 	*serr;
+	struct sk_buff 		*skb;
+	struct skb_shared_hwtstamps *sh_hw_tstamps;
+	u64			 pa_ns;
+	u64			 sys_time;
+	int			 err;
+
+	pend = tstamp_remove_pending(context);
+	if (!pend)
+		return;
+
+	pa_dev = pend->pa_dev;
+	skb = pend->skb;
+	if (!p_info) {
+		dev_warn(pa_dev->dev, "Timestamp completion timeout\n");
+		kfree_skb(skb);
+	} else {
+		pa_ns = tstamp_raw_to_ns(pa_dev,
+				p_info->epib[0], p_info->epib[2]);
+		sys_time = pa_to_sys_time(pa_dev, pa_ns);
+
+		sh_hw_tstamps = skb_hwtstamps(skb);
+		memset(sh_hw_tstamps, 0, sizeof(*sh_hw_tstamps));
+		sh_hw_tstamps->hwtstamp = ns_to_ktime(pa_ns);
+		sh_hw_tstamps->syststamp = ns_to_ktime(sys_time);
+
+		serr = SKB_EXT_ERR(skb);
+		memset(serr, 0, sizeof(*serr));
+		serr->ee.ee_errno = ENOMSG;
+		serr->ee.ee_origin = SO_EE_ORIGIN_TIMESTAMPING;
+
+		err = sock_queue_err_skb(pend->sock, skb);
+		if (err)
+			kfree_skb(skb);
+	}
+
+	kfree(pend);
+}
+
+static void pa_rx_complete(void *param)
+{
+	struct pa_packet *p_info = param;
+	struct pa_device *pa_dev = p_info->priv;
+	struct pa_frm_command *fcmd;
+
+	dma_unmap_sg(pa_dev->dev, &p_info->sg[2], 1, DMA_FROM_DEVICE);
+
+	switch (p_info->epib[1] & PA_CONTEXT_MASK) {
+	case PA_CONTEXT_CONFIG:
+		fcmd = p_info->data;
+		swizFcmd(fcmd);
+
+		if (fcmd->command_result != PAFRM_COMMAND_RESULT_SUCCESS) {
+			dev_dbg(pa_dev->dev, "Command Result = 0x%x\n", fcmd->command_result);
+			dev_dbg(pa_dev->dev, "Command = 0x%x\n", fcmd->command);
+			dev_dbg(pa_dev->dev, "Magic = 0x%x\n", fcmd->magic);
+			dev_dbg(pa_dev->dev, "Com ID = 0x%x\n", fcmd->com_id);
+			dev_dbg(pa_dev->dev, "ret Context = 0x%x\n", fcmd->ret_context);
+			dev_dbg(pa_dev->dev, "Flow ID = 0x%x\n", fcmd->flow_id);
+			dev_dbg(pa_dev->dev, "reply Queue = 0x%x\n", fcmd->reply_queue);
+			dev_dbg(pa_dev->dev, "reply dest = 0x%x\n", fcmd->reply_dest);
+		}
+		dev_dbg(pa_dev->dev, "command response complete\n");
+		break;
+
+	case PA_CONTEXT_TSTAMP:
+		tstamp_complete(p_info->epib[1], p_info);
+		break;
+
+	default:
+		dev_warn(pa_dev->dev, "bad response context, got 0x%08x\n", p_info->epib[1]);
+		break;
+	}
+
+	p_info->desc = NULL;
+	pa_free_packet(pa_dev, p_info);
+}
+
+/* Release a free receive buffer */
+static void pa_rxpool_free(void *arg, unsigned q_num, unsigned bufsize,
+		struct dma_async_tx_descriptor *desc)
+{
+	struct pa_device *pa_dev = arg;
+	struct pa_packet *p_info = desc->callback_param;
+
+	dma_unmap_sg(pa_dev->dev, &p_info->sg[2], 1, DMA_FROM_DEVICE);
+	p_info->desc = NULL;
+	pa_free_packet(pa_dev, p_info);
+}
+
+static void pa_chan_work_handler(unsigned long data)
+{
+	struct pa_device *pa_dev = (struct pa_device *)data;
+
+	dma_poll(pa_dev->rx_channel, -1);
+	dma_rxfree_refill(pa_dev->rx_channel);
+	dmaengine_resume(pa_dev->rx_channel);
+}
+
+static void pa_chan_notify(struct dma_chan *dma_chan, void *arg)
+{
+	struct pa_device *pa_dev = arg;
+
+	dmaengine_pause(pa_dev->rx_channel);
+	tasklet_schedule(&pa_dev->task);
+	return;
+}
+
+/* Allocate a free receive buffer */
+static struct dma_async_tx_descriptor *pa_rxpool_alloc(void *arg,
+		unsigned q_num, unsigned bufsize)
+{
+	struct pa_device *pa_dev = arg;
+	struct dma_async_tx_descriptor *desc;
+	struct dma_device *device;
+	u32 err = 0;
+
+	struct pa_packet *rx;
+
+	rx = pa_alloc_packet(pa_dev, bufsize, pa_dev->rx_channel);
+	if (!rx) {
+		dev_err(pa_dev->dev, "could not allocate cmd rx packet\n");
+		return NULL;
+	}
+
+	rx->sg_ents = 2 + dma_map_sg(pa_dev->dev, &rx->sg[2],
+				1, DMA_FROM_DEVICE);
+	if (rx->sg_ents != 3) {
+		dev_err(pa_dev->dev, "dma map failed\n");
+		pa_free_packet(pa_dev, rx);
+		return NULL;
+	}
+
+	device = rx->chan->device;
+	desc = dmaengine_prep_slave_sg(rx->chan, rx->sg, 3, DMA_DEV_TO_MEM,
+				       DMA_HAS_EPIB | DMA_HAS_PSINFO);
+	if (IS_ERR_OR_NULL(desc)) {
+		dma_unmap_sg(pa_dev->dev, &rx->sg[2], 1, DMA_FROM_DEVICE);
+		pa_free_packet(pa_dev, rx);
+		err = PTR_ERR(desc);
+		if (err != -ENOMEM) {
+			dev_err(pa_dev->dev,
+				"dma prep failed, error %d\n", err);
+		}
+		return NULL;
+	}
+
+	desc->callback_param = rx;
+	desc->callback = pa_rx_complete;
+	rx->cookie = desc->cookie;
+	return desc;
+}
+
+static struct pa_lut_entry *pa_lut_alloc(struct pa_device *pa_dev,
+					 enum pa_lut_type type, bool backwards)
+{
+	struct pa_lut_entry *lut_table, *entry;
+	u32 lut_size;
+	int i;
+
+	if (type == PA_LUT_MAC) {
+		lut_table = pa_dev->lut;
+		lut_size = pa_dev->lut_size;
+	} else {
+		lut_table = pa_dev->ip_lut;
+		lut_size = pa_dev->ip_lut_size;
+	}
+
+	if (!backwards) {
+		for (i = 0; i < lut_size; i++) {
+			entry = lut_table + i;
+			if (!entry->valid || entry->in_use)
+				continue;
+			entry->in_use = true;
+			return entry;
+		}
+	} else {
+		for (i = lut_size - 1; i >= 0; i--) {
+			entry = lut_table + i;
+			if (!entry->valid || entry->in_use)
+				continue;
+			entry->in_use = true;
+			return entry;
+		}
+	}
+
+	return NULL;
+}
+
+static inline int pa_lut_entry_count(enum netcp_addr_type type)
+{
+	return (type == ADDR_DEV || type == ADDR_UCAST || type == ADDR_ANY) ?
+		3 : 1;
+}
+
+static void pa_format_cmd_hdr(struct pa_device *dev,
+		struct pa_frm_command *fcmd, u8 cmd, u16 cmd_id, u32 ctx)
+{
+	memset(fcmd, 0, sizeof(*fcmd));
+	fcmd->command		= cmd;
+	fcmd->magic		= PAFRM_CONFIG_COMMAND_SEC_BYTE;
+	fcmd->com_id		= cpu_to_be16(cmd_id);
+	fcmd->ret_context	= cpu_to_be32(ctx);
+	fcmd->flow_id		= dev->cmd_flow_num;
+	fcmd->reply_queue	= cpu_to_be16(dev->cmd_queue_num);
+	fcmd->reply_dest	= PAFRM_DEST_PKTDMA;
+}
+
+static int keystone_pa_add_ip_proto(struct pa_device *pa_dev, int index,
+					u8 proto, int rule)
+{
+	struct pa_route_info route_info, fail_info;
+	struct pa_frm_cmd_add_lut1 *al1;
+	u32 context = PA_CONTEXT_CONFIG;
+	struct pa_frm_command *fcmd;
+	unsigned flow_num, q_num;
+	struct pa_packet *tx;
+	int size, ret;
+
+	dev_dbg(pa_dev->dev, "%s: index %d, rule %d, proto %d\n",
+		 __func__, index, rule, proto);
+
+	memset(&fail_info, 0, sizeof(fail_info));
+	memset(&route_info, 0, sizeof(route_info));
+
+	q_num = pa_dev->rx_queue_base;
+	flow_num = pa_dev->rx_flow_base;
+
+	if (rule == PACKET_HST) {
+		route_info.dest			= PA_DEST_HOST;
+		route_info.flow_id		= flow_num;
+		route_info.queue		= q_num;
+		route_info.m_route_index	= -1;
+		route_info.route_type		= PA_ROUTE_INTF_FLOW;
+		fail_info.dest			= PA_DEST_HOST;
+		fail_info.flow_id		= flow_num;
+		fail_info.queue			= q_num;
+		fail_info.m_route_index		= -1;
+		fail_info.route_type		= PA_ROUTE_INTF_FLOW;
+	} else if (rule == PACKET_PARSE) {
+		route_info.dest			= PA_DEST_CONTINUE_PARSE_LUT2;
+		route_info.m_route_index	= -1;
+		fail_info.dest			= PA_DEST_HOST;
+		fail_info.flow_id		= flow_num;
+		fail_info.queue			= q_num;
+		fail_info.m_route_index		= -1;
+		fail_info.route_type		= PA_ROUTE_INTF_FLOW;
+	} else if (rule == PACKET_DROP) {
+		route_info.dest			= PA_DEST_DISCARD;
+		route_info.m_route_index	= -1;
+		fail_info.dest			= PA_DEST_DISCARD;
+		fail_info.m_route_index		= -1;
+	}
+
+	size = (sizeof(struct pa_frm_command) +
+		sizeof(struct pa_frm_cmd_add_lut1) + 4);
+	tx = pa_alloc_packet(pa_dev, size, pa_dev->pdsp1_tx_channel);
+	if (!tx) {
+		dev_err(pa_dev->dev, "%s: could not allocate cmd tx packet\n",
+			__func__);
+		return -ENOMEM;
+	}
+
+	fcmd = tx->data;
+	al1 = (struct pa_frm_cmd_add_lut1 *) &(fcmd->cmd);
+	memset(al1, 0, sizeof(*al1));
+
+	pa_format_cmd_hdr(pa_dev, fcmd, PAFRM_CONFIG_COMMAND_ADDREP_LUT1,
+			PA_COMID_L3, context);
+
+	al1->index = index;
+	al1->type = PAFRM_COM_ADD_LUT1_STANDARD;
+
+	al1->u.eth_ip.proto_next = proto;
+	al1->u.eth_ip.match_flags |= PAFRM_LUT1_MATCH_PROTO;
+	al1->u.eth_ip.match_flags = cpu_to_be16(al1->u.eth_ip.match_flags);
+
+	ret = pa_conv_routing_info(&al1->match, &route_info, 0, 0);
+	if (ret != 0) {
+		dev_err(pa_dev->dev, "%s:route info config failed\n", __func__);
+		goto fail;
+	}
+
+	ret = pa_conv_routing_info(&al1->next_fail, &fail_info, 0, 1);
+	if (ret != 0) {
+		dev_err(pa_dev->dev, "%s:fail info config failed\n", __func__);
+		goto fail;
+	}
+
+	swiz_fwd(&(al1->match));
+	swiz_fwd(&(al1->next_fail));
+
+	/* Indicate that it is a configuration command */
+	tx->psdata[0] = ((u32)(4 << 5) << 24);
+
+	pa_submit_tx_packet(tx);
+	dev_dbg(pa_dev->dev, "%s: waiting for command transmit complete\n",
+		__func__);
+	return 0;
+
+fail:
+	pa_free_packet(pa_dev, tx);
+	return ret;
+}
+
+/* Configure route for exception packets in PA
+ * All exceptions will be routed to Linux
+ */
+static int pa_config_exception_route(struct pa_device *pa_dev)
+{
+	struct pa_route_info eroutes[EROUTE_N_MAX];
+	struct pa_frm_command_sys_config_pa *cpa;
+	u32 context = PA_CONTEXT_CONFIG;
+	struct pa_frm_command *fcmd;
+	struct pa_packet *tx;
+	int i, size, ret;
+
+	memset(eroutes, 0, sizeof(eroutes));
+	size = (sizeof(struct pa_frm_command) +
+		sizeof(struct pa_frm_command_sys_config_pa) + 4);
+
+	tx = pa_alloc_packet(pa_dev, size, pa_dev->pdsp1_tx_channel);
+	if (!tx) {
+		dev_err(pa_dev->dev, "%s: could not allocate cmd tx packet\n",
+			__func__);
+		ret = -ENOMEM;
+		goto fail;
+	}
+
+	fcmd = tx->data;
+	cpa = (struct pa_frm_command_sys_config_pa *) &(fcmd->cmd);
+	memset(cpa, 0, sizeof(*cpa));
+	pa_format_cmd_hdr(pa_dev, fcmd, PAFRM_CONFIG_COMMAND_SYS_CONFIG,
+			0, context);
+	cpa->cfg_code = PAFRM_SYSTEM_CONFIG_CODE_EROUTE;
+
+	for (i = 0; i < EROUTE_N_MAX; i++) {
+		eroutes[i].dest			= PA_DEST_HOST;
+		eroutes[i].flow_id		= pa_dev->rx_flow_base;
+		eroutes[i].queue		= pa_dev->rx_queue_base;
+		eroutes[i].m_route_index	= -1;
+		eroutes[i].route_type		= PA_ROUTE_INTF_FLOW;
+		cpa->u.eroute.route_bitmap |= (1 << i);
+
+		ret =  pa_conv_routing_info(&cpa->u.eroute.eroute[i],
+					    &eroutes[i], PA_CMD_TX_DEST_5, 0);
+		if (ret != 0) {
+			dev_err(pa_dev->dev, "%s: route info config failed\n",
+				__func__);
+			goto fail;
+		}
+		swiz_fwd(&cpa->u.eroute.eroute[i]);
+	}
+
+	cpa->u.eroute.route_bitmap = cpu_to_be32(cpa->u.eroute.route_bitmap);
+
+	/* Indicate that it is a configuration command */
+	tx->psdata[0] = ((u32)(4 << 5) << 24);
+	pa_submit_tx_packet(tx);
+	dev_dbg(pa_dev->dev, "%s: waiting for command transmit complete\n",
+		__func__);
+	return 0;
+
+fail:
+	pa_free_packet(pa_dev, tx);
+	return ret;
+}
+
+static int keystone_pa_add_mac(struct pa_intf *pa_intf, int index,
+			       const u8 *smac, const u8 *dmac, int rule,
+			       unsigned etype, int port)
+{
+	struct pa_route_info route_info, fail_info;
+	struct pa_frm_command *fcmd;
+	struct pa_frm_cmd_add_lut1 *al1;
+	struct pa_packet *tx;
+	struct pa_device *priv = pa_intf->pa_device;
+	u32 context = PA_CONTEXT_CONFIG;
+	int size, ret;
+
+	dev_dbg(priv->dev, "add mac, index %d, smac %pM, dmac %pM, rule %d, "
+		"type %04x, port %d\n", index, smac, dmac, rule, etype, port);
+
+	memset(&fail_info, 0, sizeof(fail_info));
+	memset(&route_info, 0, sizeof(route_info));
+
+	if (rule == PACKET_HST) {
+		route_info.dest			= PA_DEST_HOST;
+		route_info.flow_id		= pa_intf->data_flow_num;
+		route_info.queue		= pa_intf->data_queue_num;
+		route_info.m_route_index	= -1;
+		fail_info.dest			= PA_DEST_HOST;
+		fail_info.flow_id		= pa_intf->data_flow_num;
+		fail_info.queue			= pa_intf->data_queue_num;
+		fail_info.m_route_index		= -1;
+	} else if (rule == PACKET_PARSE) {
+		route_info.dest			= PA_DEST_CONTINUE_PARSE_LUT1;
+		route_info.m_route_index	= -1;
+		fail_info.dest			= PA_DEST_HOST;
+		fail_info.flow_id		= pa_intf->data_flow_num;
+		fail_info.queue			= pa_intf->data_queue_num;
+		fail_info.m_route_index		= -1;
+	} else if (rule == PACKET_DROP) {
+		route_info.dest			= PA_DEST_DISCARD;
+		route_info.m_route_index	= -1;
+		fail_info.dest			= PA_DEST_DISCARD;
+		fail_info.m_route_index		= -1;
+	}
+
+	size = (sizeof(struct pa_frm_command) +
+		sizeof(struct pa_frm_cmd_add_lut1) + 4);
+	tx = pa_alloc_packet(priv, size, priv->pdsp0_tx_channel);
+	if (!tx) {
+		dev_err(priv->dev, "could not allocate cmd tx packet\n");
+		return -ENOMEM;
+	}
+
+	fcmd = tx->data;
+	al1 = (struct pa_frm_cmd_add_lut1 *) &(fcmd->cmd);
+
+	fcmd->command_result	= 0;
+	fcmd->command		= PAFRM_CONFIG_COMMAND_ADDREP_LUT1;
+	fcmd->magic		= PAFRM_CONFIG_COMMAND_SEC_BYTE;
+	fcmd->com_id		= PA_COMID_L2;
+	fcmd->ret_context	= context;
+	fcmd->flow_id		= priv->cmd_flow_num;
+	fcmd->reply_queue	= priv->cmd_queue_num;
+	fcmd->reply_dest	= PAFRM_DEST_PKTDMA;
+
+	al1->index		= index;
+	al1->type		= PAFRM_COM_ADD_LUT1_STANDARD;
+
+	if (etype) {
+		al1->u.eth_ip.etype	= etype;
+		al1->u.eth_ip.match_flags |= PAFRM_LUT1_MATCH_ETYPE;
+	}
+
+	al1->u.eth_ip.vlan	= 0;
+	al1->u.eth_ip.pm.mpls	= 0;
+	if (port) {
+		al1->u.eth_ip.inport    = port;
+		al1->u.eth_ip.match_flags |= PAFRM_LUT1_MATCH_PORT;
+	}
+
+	if (dmac) {
+		al1->u.eth_ip.dmac[0] = dmac[0];
+		al1->u.eth_ip.dmac[1] = dmac[1];
+		al1->u.eth_ip.dmac[2] = dmac[2];
+		al1->u.eth_ip.dmac[3] = dmac[3];
+		al1->u.eth_ip.dmac[4] = dmac[4];
+		al1->u.eth_ip.dmac[5] = dmac[5];
+		al1->u.eth_ip.match_flags |= PAFRM_LUT1_MATCH_DMAC;
+	}
+	if (smac) {
+		al1->u.eth_ip.smac[0] = smac[0];
+		al1->u.eth_ip.smac[1] = smac[1];
+		al1->u.eth_ip.smac[2] = smac[2];
+		al1->u.eth_ip.smac[3] = smac[3];
+		al1->u.eth_ip.smac[4] = smac[4];
+		al1->u.eth_ip.smac[5] = smac[5];
+		al1->u.eth_ip.match_flags |= PAFRM_LUT1_MATCH_SMAC;
+	}
+
+	al1->u.eth_ip.key |= PAFRM_LUT1_KEY_MAC;
+	al1->u.eth_ip.match_flags |= PAFRM_LUT1_CUSTOM_MATCH_KEY;
+
+	ret = pa_conv_routing_info(&al1->match, &route_info, 0, 0);
+	if (ret) {
+		dev_err(priv->dev, "route info config failed\n");
+		goto fail;
+	}
+
+	ret = pa_conv_routing_info(&al1->next_fail, &fail_info, 0, 1);
+	if (ret) {
+		dev_err(priv->dev, "fail info config failed\n");
+		goto fail;
+	}
+
+	swizFcmd(fcmd);
+	swizAl1((struct pa_frm_cmd_add_lut1 *)&(fcmd->cmd));
+
+	tx->psdata[0] = ((u32)(4 << 5) << 24);
+
+	tx->epib[1] = 0x11112222;
+	tx->epib[2] = 0x33334444;
+	tx->epib[3] = 0;
+
+	pa_submit_tx_packet(tx);
+	dev_dbg(priv->dev, "waiting for command transmit complete\n");
+	return 0;
+
+fail:
+	pa_free_packet(priv, tx);
+	return ret;
+}
+
+static void pa_init_crc_table4(u32 polynomial, u32 *crc_table4)
+{
+	int i, bit;
+
+	/* 16 values representing all possible 4-bit values */
+	for(i = 0; i < PARAM_CRC_TABLE_SIZE; i++) {
+		crc_table4[i] = i << 28;
+		for (bit = 0; bit < 4; bit++) {
+			/* If shifting out a zero, then just shift */
+			if (!(crc_table4[i] & 0x80000000))
+				crc_table4[i] = (crc_table4[i] << 1);
+			/* Else add in the polynomial as well */
+			else
+				crc_table4[i] = (crc_table4[i] << 1) ^ polynomial;
+		}
+		crc_table4[i] = cpu_to_be32(crc_table4[i]);
+	}
+}
+
+#define	CRC32C_POLYNOMIAL	0x1EDC6F41
+#define	SCTP_CRC_INITVAL	0xFFFFFFFF
+static int pa_config_crc_engine(struct pa_device *priv)
+{
+	struct pa_frm_command *fcmd;
+	struct pa_frm_config_crc *ccrc;
+	struct pa_packet *tx;
+	int size;
+
+	/* Verify that there is enough room to create the command */
+	size = sizeof(*fcmd) + sizeof(*ccrc) - sizeof(u32);
+	tx = pa_alloc_packet(priv, size, priv->pdsp0_tx_channel);
+	if (!tx) {
+		dev_err(priv->dev, "could not allocate cmd tx packet\n");
+		return -ENOMEM;
+	}
+
+	/* Create the command */
+	fcmd = tx->data;
+	fcmd->command_result	= 0;
+	fcmd->command		= PAFRM_CONFIG_COMMAND_CRC_ENGINE;
+	fcmd->magic		= PAFRM_CONFIG_COMMAND_SEC_BYTE;
+	fcmd->com_id		= 0;
+	fcmd->ret_context	= PA_CONTEXT_CONFIG;
+	fcmd->flow_id		= priv->cmd_flow_num;
+	fcmd->reply_queue	= priv->cmd_queue_num;
+	fcmd->reply_dest	= PAFRM_DEST_PKTDMA;
+	swizFcmd(fcmd);
+
+	ccrc = (struct pa_frm_config_crc *)&(fcmd->cmd);
+	ccrc->ctrl_bitmap  = PARAM_CRC_SIZE_32;
+	ccrc->ctrl_bitmap |= PARAM_CRC_CTRL_RIGHT_SHIFT;
+	ccrc->ctrl_bitmap |= PARAM_CRC_CTRL_INV_RESULT;
+	ccrc->init_val = cpu_to_be32(SCTP_CRC_INITVAL);
+
+	/* Magic polynomial value is CRC32c defined by RFC4960 */
+	pa_init_crc_table4(CRC32C_POLYNOMIAL, ccrc->crc_tbl);
+
+	tx->psdata[0] = ((u32)(4 << 5) << 24);
+
+	tx->epib[1] = 0x11112222;
+	tx->epib[2] = 0x33334444;
+	tx->epib[3] = 0;
+
+	pa_submit_tx_packet(tx);
+	dev_dbg(priv->dev, "waiting for command transmit complete\n");
+
+	return 0;
+}
+
+
+static inline int pa_fmtcmd_tx_csum(struct netcp_packet *p_info)
+{
+	struct sk_buff *skb = p_info->skb;
+	struct pasaho_com_chk_crc *ptx;
+	int start, len;
+	int size;
+
+	size = sizeof(*ptx);
+	ptx = (struct pasaho_com_chk_crc *)netcp_push_psdata(p_info, size);
+
+	start = skb_checksum_start_offset(skb);
+	len = skb->len - start;
+
+	ptx->word0 = 0;
+	ptx->word1 = 0;
+	ptx->word2 = 0;
+	PASAHO_SET_CMDID(ptx, PASAHO_PAMOD_CMPT_CHKSUM);
+	PASAHO_CHKCRC_SET_START(ptx, start);
+	PASAHO_CHKCRC_SET_LEN(ptx, len);
+	PASAHO_CHKCRC_SET_RESULT_OFF(ptx, skb->csum_offset);
+	PASAHO_CHKCRC_SET_INITVAL(ptx, 0);
+	PASAHO_CHKCRC_SET_NEG0(ptx, 0);
+
+	return size;
+}
+
+static inline int pa_fmtcmd_tx_crc32c(struct netcp_packet *p_info)
+{
+	struct sk_buff *skb = p_info->skb;
+	struct pasaho_com_chk_crc *ptx;
+	int start, len;
+	int size;
+
+	size = sizeof(*ptx);
+	ptx = (struct pasaho_com_chk_crc *)netcp_push_psdata(p_info, size);
+
+	start = skb_checksum_start_offset(skb);
+	len = skb->len - start;
+
+	ptx->word0 = 0;
+	ptx->word1 = 0;
+	ptx->word2 = 0;
+	PASAHO_SET_CMDID             (ptx, PASAHO_PAMOD_CMPT_CRC);
+	PASAHO_CHKCRC_SET_START      (ptx, start);
+	PASAHO_CHKCRC_SET_LEN        (ptx, len);
+	PASAHO_CHKCRC_SET_CTRL       (ptx, PAFRM_CRC_FLAG_CRC_OFFSET_VALID);
+	PASAHO_CHKCRC_SET_RESULT_OFF (ptx, skb->csum_offset);
+
+	return size;
+}
+
+static inline int pa_fmtcmd_next_route(struct netcp_packet *p_info, u8 ps_flags)
+{
+	struct pasaho_next_route *nr;
+
+	nr = (struct pasaho_next_route *)netcp_push_psdata(p_info, sizeof(*nr));
+	if (!nr)
+		return -ENOMEM;
+
+	/* Construct word0 */
+	nr->word0 = 0;
+	PASAHO_SET_CMDID(nr, PASAHO_PAMOD_NROUTE);
+	PASAHO_SET_E(nr, 1);
+	PASAHO_SET_DEST(nr, PAFRM_DEST_ETH);
+	PASAHO_SET_FLOW(nr, 0);
+	PASAHO_SET_QUEUE (nr, 0);
+
+	/* Construct sw_info0 and sw_info1 */
+	nr->sw_info0 = 0;
+	nr->sw_info1 = 0;
+
+	/* Construct word1 */
+	nr->word1 = 0;
+	PASAHO_SET_PKTTYPE(nr, ps_flags);
+	
+	return sizeof(*nr);
+}
+
+static inline int pa_fmtcmd_tx_timestamp(struct netcp_packet *p_info, const struct pa_cmd_tx_timestamp *tx_ts)
+{
+	struct pasaho_report_timestamp	*rt_info;
+	int				 size;
+
+	size = sizeof(*rt_info);
+	rt_info = (struct pasaho_report_timestamp *)netcp_push_psdata(p_info, size);
+	if (!rt_info)
+		return -ENOMEM;
+
+	rt_info->word0 = 0;
+	PASAHO_SET_CMDID(rt_info, PASAHO_PAMOD_REPORT_TIMESTAMP);
+	PASAHO_SET_REPORT_FLOW(rt_info, (u8)tx_ts->flow_id);
+	PASAHO_SET_REPORT_QUEUE(rt_info, tx_ts->dest_queue);
+	rt_info->sw_info0 = tx_ts->sw_info0;
+
+	return size;
+}
+
+static inline int pa_fmtcmd_align(struct netcp_packet *p_info, const unsigned bytes)
+{
+	struct pasaho_cmd_info	*paCmdInfo;
+	int i;
+
+	if ((bytes & 0x03) != 0)
+		return -EINVAL;
+
+	paCmdInfo = (struct pasaho_cmd_info *)netcp_push_psdata(p_info, bytes);
+
+	for (i = bytes/sizeof(u32); i > 0; --i ) {
+		paCmdInfo->word0 = 0;
+		PASAHO_SET_CMDID(paCmdInfo, PASAHO_PAMOD_DUMMY);
+		++paCmdInfo;
+	}
+
+	return bytes;
+}
+
+static inline int extract_l4_proto(struct netcp_packet *p_info)
+{
+	struct sk_buff *skb = p_info->skb;
+	int l4_proto = 0;
+	__be16 l3_proto;
+
+	l3_proto = skb->protocol;
+	if (l3_proto == __constant_htons(ETH_P_8021Q)) {
+		/* Can't use vlan_eth_hdr() here, skb->mac_header isn't valid */
+		struct vlan_ethhdr *vhdr = (struct vlan_ethhdr *)skb->data;
+		l3_proto = vhdr->h_vlan_encapsulated_proto;
+	}
+
+	switch (l3_proto) {
+	case __constant_htons(ETH_P_IP):
+		l4_proto = ip_hdr(skb)->protocol;
+		break;
+	case __constant_htons(ETH_P_IPV6):
+		l4_proto = ipv6_hdr(skb)->nexthdr;
+		break;
+	default:
+		if (unlikely(net_ratelimit())) {
+			dev_warn(p_info->netcp->dev,
+				 "partial checksum but L3 proto = 0x%04hx!\n",
+				 ntohs(l3_proto));
+		}
+	}
+
+	return l4_proto;
+}
+
+static int pa_add_ip_proto(struct pa_device *pa_dev, u8 proto)
+{
+	struct pa_lut_entry *entry;
+	int ret;
+
+	entry = pa_lut_alloc(pa_dev, PA_LUT_IP, 1);
+	if (entry == NULL)
+		return -1;
+	entry->u.ip_proto = proto;
+
+	ret = keystone_pa_add_ip_proto(pa_dev, entry->index, proto,
+				       PACKET_PARSE);
+	if (ret)
+		dev_err(pa_dev->dev, "failed to add IP proto(%d) rule\n",
+			proto);
+	return ret;
+}
+
+static int pa_del_ip_proto(struct pa_device *pa_dev, u8 proto)
+{
+	struct pa_lut_entry *entry;
+	int idx, ret = 0;
+
+	for (idx = 0; idx < pa_dev->ip_lut_size; idx++) {
+		entry = pa_dev->ip_lut + idx;
+		if (!entry->valid || !entry->in_use || entry->u.ip_proto != proto)
+			continue;
+		ret = keystone_pa_add_ip_proto(pa_dev, entry->index, 0,
+					       PACKET_DROP);
+		if (ret)
+			dev_err(pa_dev->dev,
+				"failed to del IP proto(%d) rule\n", proto);
+		entry->in_use = false;
+		entry->u.ip_proto = 0;
+	}
+	return ret;
+}
+
+static int pa_tx_hook(int order, void *data, struct netcp_packet *p_info)
+{
+	struct pa_intf *pa_intf = data;
+	struct pa_device *pa_dev = pa_intf->pa_device;
+	struct netcp_priv *netcp_priv = netdev_priv(pa_intf->net_device);
+	struct sk_buff *skb = p_info->skb;
+	struct sock *sk = skb->sk;
+	struct pa_cmd_tx_timestamp tx_ts;
+	int size, total = 0;
+	u8 ps_flags;
+	struct tstamp_pending *pend;
+
+	ps_flags = 0;
+	if (pa_dev->multi_if) {
+		if (likely(skb->mark == 0) ||
+		    likely((skb->mark & pa_dev->mark_mcast_match[1]) !=
+				pa_dev->mark_mcast_match[0])) {
+			/* normal port-specific output packet */
+			ps_flags |= (netcp_priv->cpsw_port & BITS(3)) <<
+					PAFRM_ETH_PS_FLAGS_PORT_SHIFT;
+		} else {
+			/* Drop packet if port not in mask */
+			if ((skb->mark & BIT(netcp_priv->cpsw_port - 1)) == 0) {
+				return NETCP_TX_DROP;
+			}
+		}
+	}
+
+	/* Generate the next route command */
+	size = pa_fmtcmd_next_route(p_info, ps_flags);
+	if (unlikely(size < 0))
+		return size;
+	total += size;
+
+	/* If TX Timestamp required, request it */
+	if (unlikely(pa_intf->tx_timestamp_enable &&
+		     !pa_dev->force_no_hwtstamp &&
+		     sk && 
+		     (skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP) &&
+		     !(skb_shinfo(skb)->tx_flags & SKBTX_IN_PROGRESS))) {
+		pend = kzalloc(sizeof(*pend), GFP_ATOMIC);
+		if (pend) {
+			void *saved_sp;
+			if (!atomic_inc_not_zero(&sk->sk_refcnt))
+				return -ENODEV;
+
+			/* The SA module may have reused skb->sp */
+			saved_sp = skb->sp;
+			skb->sp = NULL;
+			pend->skb = skb_clone(skb, GFP_ATOMIC);
+			skb->sp = saved_sp;
+
+			if (!pend->skb) {
+				sock_put(sk);
+				kfree(pend);
+				return -ENOMEM;
+			} else {
+				pend->sock = sk;
+				pend->pa_dev = pa_dev;
+				pend->context =  PA_CONTEXT_TSTAMP |
+					(~PA_CONTEXT_MASK &
+					 atomic_inc_return(&tstamp_sequence));
+				tstamp_add_pending(pend);
+
+				memset(&tx_ts, 0, sizeof(tx_ts));
+				tx_ts.dest_queue = pa_dev->cmd_queue_num;
+				tx_ts.flow_id    = pa_dev->cmd_flow_num;
+				tx_ts.sw_info0   = pend->context;
+
+				size = pa_fmtcmd_tx_timestamp(p_info,
+							      &tx_ts);
+				if (unlikely(size < 0))
+					return size;
+				total += size;
+			}
+		}
+	}
+
+	/* If checksum offload required, request it */
+	if ((skb->ip_summed == CHECKSUM_PARTIAL) &&
+	    (pa_dev->csum_offload == CSUM_OFFLOAD_HARD)) {
+		int l4_proto;
+
+		l4_proto = extract_l4_proto(p_info);
+		switch (l4_proto) {
+		case IPPROTO_TCP:
+		case IPPROTO_UDP:
+			size = pa_fmtcmd_tx_csum(p_info);
+			break;
+		case IPPROTO_SCTP:
+			size = pa_fmtcmd_tx_crc32c(p_info);
+			break;
+		default:
+			if (unlikely(net_ratelimit())) {
+				dev_warn(p_info->netcp->dev,
+					 "partial checksum but L4 proto = %d!\n",
+					 l4_proto);
+			}
+			size = 0;
+			break;
+		}
+
+		if (unlikely(size < 0))
+			return size;
+		total += size;
+	}
+
+	/* The next hook may require the command stack to be 8-byte aligned */
+	size = netcp_align_psdata(p_info, 8);
+	if (unlikely(size < 0))
+		return size;
+	if (size > 0) {
+		size = pa_fmtcmd_align(p_info, size);
+		if (unlikely(size < 0))
+			return size;
+		total += size;
+	}
+
+	p_info->tx_pipe = &pa_intf->tx_pipe;
+	return 0;
+}
+
+
+/* This code adapted from net/core/skbuff.c:skb_checksum() */
+static __wsum skb_sctp_csum(struct sk_buff *skb, int offset,
+			  int len, __wsum csum)
+{
+	int start = skb_headlen(skb);
+	int i, copy = start - offset;
+	struct sk_buff *frag_iter;
+
+	/* Checksum header. */
+	if (copy > 0) {
+		if (copy > len)
+			copy = len;
+		csum = sctp_update_cksum(skb->data + offset, copy, csum);
+		if ((len -= copy) == 0)
+			return csum;
+		offset += copy;
+	}
+
+	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
+		int end;
+		skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
+
+		WARN_ON(start > offset + len);
+
+		end = start + skb_frag_size(frag);
+		if ((copy = end - offset) > 0) {
+			u8 *vaddr;
+			skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
+
+			if (copy > len)
+				copy = len;
+			vaddr = kmap_atomic(skb_frag_page(frag));
+			csum = sctp_update_cksum(vaddr + frag->page_offset +
+					 offset - start, copy, csum);
+			kunmap_atomic(vaddr);
+			if (!(len -= copy))
+				return csum;
+			offset += copy;
+		}
+		start = end;
+	}
+
+	skb_walk_frags(skb, frag_iter) {
+		int end;
+
+		WARN_ON(start > offset + len);
+
+		end = start + frag_iter->len;
+		if ((copy = end - offset) > 0) {
+			if (copy > len)
+				copy = len;
+			csum = skb_sctp_csum(frag_iter,
+						offset - start, copy, csum);
+			if ((len -= copy) == 0)
+				return csum;
+			offset += copy;
+		}
+		start = end;
+	}
+	BUG_ON(len);
+
+	return csum;
+}
+
+static void skb_warn_bad_offload(const struct sk_buff *skb)
+{
+	static const netdev_features_t null_features = 0;
+	struct net_device *dev = skb->dev;
+	const char *driver = "";
+
+	if (dev && dev->dev.parent)
+		driver = dev_driver_string(dev->dev.parent);
+
+	WARN(1, "%s: caps=(%pNF, %pNF) len=%d data_len=%d gso_size=%d "
+	     "gso_type=%d ip_summed=%d\n",
+	     driver, dev ? &dev->features : &null_features,
+	     skb->sk ? &skb->sk->sk_route_caps : &null_features,
+	     skb->len, skb->data_len, skb_shinfo(skb)->gso_size,
+	     skb_shinfo(skb)->gso_type, skb->ip_summed);
+}
+
+/* This code adapted from net/core/dev.c:skb_checksum_help() */
+static int skb_sctp_csum_help(struct sk_buff *skb)
+{
+	__wsum csum;
+	int ret = 0, offset;
+
+	if (skb->ip_summed == CHECKSUM_COMPLETE)
+		goto out_set_summed;
+
+	if (unlikely(skb_shinfo(skb)->gso_size)) {
+		skb_warn_bad_offload(skb);
+		return -EINVAL;
+	}
+
+	offset = skb_checksum_start_offset(skb);
+	BUG_ON(offset >= skb_headlen(skb));
+	csum = skb_sctp_csum(skb, offset, skb->len - offset, ~0);
+
+	offset += skb->csum_offset;
+	BUG_ON(offset + sizeof(__le32) > skb_headlen(skb));
+
+	if (skb_cloned(skb) &&
+	    !skb_clone_writable(skb, offset + sizeof(__le32))) {
+		ret = pskb_expand_head(skb, 0, 0, GFP_ATOMIC);
+		if (ret)
+			goto out;
+	}
+
+	*(__le32 *)(skb->data + offset) = sctp_end_cksum(csum);
+out_set_summed:
+	skb->ip_summed = CHECKSUM_NONE;
+out:
+	return ret;
+}
+
+static int pa_txhook_softcsum(int order, void *data, struct netcp_packet *p_info)
+{
+	struct pa_intf *pa_intf = data;
+	struct pa_device *pa_dev = pa_intf->pa_device;
+	struct sk_buff *skb = p_info->skb;
+	int l4_proto;
+	int ret = 0;
+
+	if ((skb->ip_summed != CHECKSUM_PARTIAL) ||
+	    (pa_dev->csum_offload != CSUM_OFFLOAD_SOFT))
+		return 0;
+
+	l4_proto = extract_l4_proto(p_info);
+	if (unlikely(!l4_proto))
+		return 0;
+
+	switch (l4_proto) {
+	case IPPROTO_TCP:
+	case IPPROTO_UDP:
+		ret = skb_checksum_help(skb);
+		break;
+	case IPPROTO_SCTP:
+		ret = skb_sctp_csum_help(skb);
+		break;
+	default:
+		if (unlikely(net_ratelimit())) {
+			dev_warn(p_info->netcp->dev,
+				 "partial checksum but L4 proto = %d!\n",
+				 l4_proto);
+		}
+		return 0;
+	}
+
+	return ret;
+}
+
+
+static inline int pa_rx_timestamp(struct pa_intf *pa_intf,
+				  struct netcp_packet *p_info)
+{
+	struct pa_device *pa_dev = pa_intf->pa_device;
+	struct sk_buff *skb = p_info->skb;
+	struct skb_shared_hwtstamps *sh_hw_tstamps;
+	u64 pa_ns;
+	u64 sys_time;
+
+	if (!pa_intf->rx_timestamp_enable)
+		return 0;
+
+	if (p_info->rxtstamp_complete)
+		return 0;
+
+	pa_ns = tstamp_raw_to_ns(pa_dev, p_info->epib[0], p_info->psdata[6]);
+	sys_time = pa_to_sys_time(pa_dev, pa_ns);
+
+	sh_hw_tstamps = skb_hwtstamps(skb);
+	memset(sh_hw_tstamps, 0, sizeof(*sh_hw_tstamps));
+	sh_hw_tstamps->hwtstamp = ns_to_ktime(pa_ns);
+	sh_hw_tstamps->syststamp = ns_to_ktime(sys_time);
+
+	p_info->rxtstamp_complete = true;
+
+	return 0;
+}
+
+/*  The NETCP sub-system performs IPv4 header checksum, UDP/TCP checksum and
+ *  SCTP CRC-32c checksum autonomously.
+ *  The checksum and CRC verification results are recorded at the 4-bit error
+ *  flags in the CPPI packet descriptor as described below:
+ *  bit 3: IPv4 header checksum error
+ *  bit 2: UDP/TCP or SCTP CRC-32c checksum error
+ *  bit 1: Custom CRC checksum error
+ *  bit 0: reserved
+ */
+static inline void pa_rx_checksum(struct netcp_packet *p_info)
+{
+	struct pasaho_long_info *linfo =
+		(struct pasaho_long_info *)p_info->psdata;
+	/* L4 Checksum is verified only if the packet was sent for LUT-2
+	 * processing. This can be confirmed by presence of payload offset.
+	 */
+	if (likely(PASAHO_LINFO_READ_L5_OFFSET(linfo))) {
+		/* check for L3 & L4 checksum error */
+		if (likely(!((p_info->eflags >> 2) & BITS(2))))
+			p_info->skb->ip_summed = CHECKSUM_UNNECESSARY;
+	}
+}
+
+static int pa_rx_hook(int order, void *data, struct netcp_packet *p_info)
+{
+	struct pa_intf *pa_intf = data;
+	struct pa_device *pa_dev = pa_intf->pa_device;
+
+	/* Timestamping on Rx packets */
+	if (!pa_dev->force_no_hwtstamp)
+		pa_rx_timestamp(pa_intf, p_info);
+
+	/* Checksum offload on Rx packets */
+	if (pa_dev->csum_offload == CSUM_OFFLOAD_HARD)
+		pa_rx_checksum(p_info);
+
+	return 0;
+}
+
+static int pa_close(void *intf_priv, struct net_device *ndev)
+{
+	struct pa_intf *pa_intf = intf_priv;
+	struct pa_device *pa_dev = pa_intf->pa_device;
+	struct netcp_priv *netcp_priv = netdev_priv(ndev);
+
+	netcp_unregister_txhook(netcp_priv, pa_dev->txhook_order,
+				pa_tx_hook, intf_priv);
+	if (pa_dev->csum_offload == CSUM_OFFLOAD_SOFT)
+		netcp_unregister_txhook(netcp_priv, pa_dev->txhook_softcsum,
+					pa_txhook_softcsum, intf_priv);
+
+	if ((!pa_dev->force_no_hwtstamp) ||
+	     (pa_dev->csum_offload == CSUM_OFFLOAD_HARD))
+		netcp_unregister_rxhook(netcp_priv, pa_dev->rxhook_order,
+					pa_rx_hook, intf_priv);
+
+	netcp_txpipe_close(&pa_intf->tx_pipe);
+
+	/* De-Configure the streaming switch */
+	netcp_set_streaming_switch(pa_dev->netcp_device,
+				   netcp_priv->cpsw_port,
+				   pa_intf->saved_ss_state);
+
+
+	mutex_lock(&pa_modules_lock);
+	if (!--pa_dev->inuse_if_count) {
+		/* Do pa disable related stuff only if this is the last
+		 * interface to go down
+		 */
+		if (pa_dev->csum_offload == CSUM_OFFLOAD_HARD) {
+			pa_del_ip_proto(pa_dev, IPPROTO_TCP);
+			pa_del_ip_proto(pa_dev, IPPROTO_UDP);
+		}
+
+		if (pa_dev->pdsp1_tx_channel) {
+			dma_release_channel(pa_dev->pdsp1_tx_channel);
+			pa_dev->pdsp1_tx_channel = NULL;
+		}
+		if (pa_dev->pdsp0_tx_channel) {
+			dma_release_channel(pa_dev->pdsp0_tx_channel);
+			pa_dev->pdsp0_tx_channel = NULL;
+		}
+		if (pa_dev->rx_channel) {
+			dmaengine_pause(pa_dev->rx_channel);
+			tasklet_kill(&pa_dev->task);
+			dma_rxfree_flush(pa_dev->rx_channel);
+			dma_poll(pa_dev->rx_channel, -1);
+			dma_release_channel(pa_dev->rx_channel);
+			pa_dev->rx_channel = NULL;
+		}
+
+		tstamp_purge_pending(pa_dev);
+
+		if (pa_dev->clk) {
+			clk_disable_unprepare(pa_dev->clk);
+			clk_put(pa_dev->clk);
+		}
+		pa_dev->clk = NULL;
+	}
+
+	mutex_unlock(&pa_modules_lock);
+	return 0;
+}
+
+static int pa_open(void *intf_priv, struct net_device *ndev)
+{
+	struct pa_intf *pa_intf = intf_priv;
+	struct pa_device *pa_dev = pa_intf->pa_device;
+	struct netcp_priv *netcp_priv = netdev_priv(ndev);
+	struct dma_keystone_info config;
+	struct pa_pdsp_timer_regs __iomem *timer_reg = &pa_dev->reg_timer[0];
+	const struct firmware *fw;
+	struct dma_chan *chan;
+	dma_cap_mask_t mask;
+	int i, ret, err;
+	unsigned long pa_rate;
+	u64 max_sec;
+
+	/* The first time an open is being called */
+	mutex_lock(&pa_modules_lock);
+
+	dev_dbg(pa_dev->dev, "pa_open() called for port: %d\n",
+		 netcp_priv->cpsw_port);
+
+	chan = netcp_get_rx_chan(netcp_priv);
+	pa_intf->data_flow_num = dma_get_rx_flow(chan);
+	pa_intf->data_queue_num = dma_get_rx_queue(chan);
+
+	dev_dbg(pa_dev->dev, "configuring data receive flow %d, queue %d\n",
+		 pa_intf->data_flow_num, pa_intf->data_queue_num);
+
+	if (++pa_dev->inuse_if_count == 1) {
+
+		/* Do pa enable, load firmware only for the first interface
+		 * that comes up
+		 */
+		dev_dbg(pa_dev->dev, "pa_open() called for first time"
+			" initializing per dev stuff\n");
+
+		pa_dev->clk = clk_get(pa_dev->dev, "clk_pa");
+		if (IS_ERR_OR_NULL(pa_dev->clk)) {
+			dev_warn(pa_dev->dev, "unable to get Packet Accelerator clock\n");
+			pa_dev->clk = NULL;
+		}
+
+		if (pa_dev->clk)
+			clk_prepare_enable(pa_dev->clk);
+
+		keystone_pa_reset(pa_dev);
+
+		for (i = 0; i < DEVICE_PA_NUM_PDSPS; ++i) {
+			if (!pa_dev->pdsp_fw[i])
+				continue;
+
+			ret = request_firmware(&fw, pa_dev->pdsp_fw[i],
+					pa_dev->dev);
+			if (ret != 0) {
+				dev_err(pa_dev->dev, "cant find fw for pdsp %d",
+					i);
+				ret = -ENODEV;
+				goto fail;
+			}
+
+			/* Download the firmware to the PDSP */
+			keystone_pa_set_firmware(pa_dev, i,
+					(const unsigned int *) fw->data,
+					fw->size);
+
+			release_firmware(fw);
+		}
+
+		ret = keystone_pa_reset_control(pa_dev, PA_STATE_ENABLE);
+		if (ret != 1) {
+			dev_err(pa_dev->dev, "enable failed, ret = %d\n", ret);
+			ret = -ENODEV;
+			goto fail;
+		}
+
+		pa_get_version(pa_dev);
+
+		/* Start PDSP timer at a prescaler of divide by 2 */
+		__raw_writel(0xffff, &timer_reg->timer_load);
+		__raw_writel((PA_SS_TIMER_CNTRL_REG_GO |
+			      PA_SS_TIMER_CNTRL_REG_MODE |
+			      PA_SS_TIMER_CNTRL_REG_PSE |
+			      (0 << PA_SS_TIMER_CNTRL_REG_PRESCALE_SHIFT)),
+			      &timer_reg->timer_control);
+
+		/* calculate the multiplier/shift to
+		 * convert PA counter ticks to ns. */
+		pa_rate = clk_get_rate(pa_dev->clk) / 2;
+
+		max_sec = ((1ULL << 48) - 1) + (pa_rate - 1);
+		do_div(max_sec, pa_rate);
+
+		clocks_calc_mult_shift(&pa_dev->timestamp_info.mult,
+				&pa_dev->timestamp_info.shift, pa_rate,
+				NSEC_PER_SEC, max_sec);
+
+		dev_info(pa_dev->dev, "pa_clk_rate(%lu HZ),mult(%u),shift(%u)\n",
+				pa_rate, pa_dev->timestamp_info.mult,
+				pa_dev->timestamp_info.shift);
+
+		pa_dev->timestamp_info.system_offset = 0;
+
+		pa_calibrate_with_system_timer(pa_dev);
+
+		dma_cap_zero(mask);
+		dma_cap_set(DMA_SLAVE, mask);
+
+		/* Open the PA Command transmit channel */
+		pa_dev->pdsp0_tx_channel = dma_request_channel_by_name(mask,
+								"patx-pdsp0");
+		if (IS_ERR_OR_NULL(pa_dev->pdsp0_tx_channel)) {
+			dev_err(pa_dev->dev, "Couldnt get PATX cmd channel\n");
+			pa_dev->pdsp0_tx_channel = NULL;
+			ret = -ENODEV;
+			goto fail;
+		}
+
+		pa_dev->pdsp1_tx_channel = dma_request_channel_by_name(mask,
+								"patx-pdsp1");
+		if (IS_ERR_OR_NULL(pa_dev->pdsp1_tx_channel)) {
+			dev_err(pa_dev->dev,
+				"Couldnt get PATX LUT-1 cmd channel\n");
+			pa_dev->pdsp1_tx_channel = NULL;
+			ret = -ENODEV;
+			goto fail;
+		}
+
+		memset(&config, 0, sizeof(config));
+		config.direction	= DMA_MEM_TO_DEV;
+		config.tx_queue_depth	= pa_dev->tx_cmd_queue_depth;
+
+		err = dma_keystone_config(pa_dev->pdsp0_tx_channel, &config);
+		if (err)
+			goto fail;
+
+		err = dma_keystone_config(pa_dev->pdsp1_tx_channel, &config);
+		if (err)
+			goto fail;
+
+		/* Open the PA common response channel */
+		pa_dev->rx_channel = dma_request_channel_by_name(mask, "parx");
+		if (IS_ERR_OR_NULL(pa_dev->rx_channel)) {
+			dev_err(pa_dev->dev, "Could not get PA RX channel\n");
+			pa_dev->rx_channel = NULL;
+			ret = -ENODEV;
+			goto fail;
+		}
+
+		memset(&config, 0, sizeof(config));
+
+		config.direction		= DMA_DEV_TO_MEM;
+		config.scatterlist_size		= PA_SGLIST_SIZE;
+		config.rxpool_allocator		= pa_rxpool_alloc;
+		config.rxpool_destructor	= pa_rxpool_free;
+		config.rxpool_param		= pa_dev;
+		config.rxpool_count		= 1;
+		config.rxpool_thresh_enable	= DMA_THRESH_NONE;
+		config.rxpools[0].pool_depth	= pa_dev->rx_pool_depth;
+		config.rxpools[0].buffer_size	= pa_dev->rx_buffer_size;
+
+		err = dma_keystone_config(pa_dev->rx_channel, &config);
+		if (err)
+			goto fail;
+
+		tasklet_init(&pa_dev->task, pa_chan_work_handler,
+			     (unsigned long) pa_dev);
+		dma_set_notify(pa_dev->rx_channel, pa_chan_notify, pa_dev);
+		pa_dev->cmd_flow_num = dma_get_rx_flow(pa_dev->rx_channel);
+		pa_dev->cmd_queue_num = dma_get_rx_queue(pa_dev->rx_channel);
+		dev_dbg(pa_dev->dev, "command receive flow %d, queue %d\n",
+			pa_dev->cmd_flow_num, pa_dev->cmd_queue_num);
+		pa_dev->addr_count = 0;
+		dma_rxfree_refill(pa_dev->rx_channel);
+		ret = pa_config_exception_route(pa_dev);
+		if (ret < 0)
+			goto fail;
+
+		if (pa_dev->csum_offload == CSUM_OFFLOAD_HARD) {
+			ret = pa_config_crc_engine(pa_dev);
+			if (ret < 0)
+				goto fail;
+
+			/* make lut entries invalid */
+			for (i = 0; i < pa_dev->lut_size; i++) {
+				if (!pa_dev->lut[i].valid)
+					continue;
+				keystone_pa_add_mac(pa_intf, i, NULL, NULL,
+						    PACKET_DROP, 0,
+						    PA_INVALID_PORT);
+			}
+
+			/* make IP LUT entries invalid */
+			for (i = 0; i < pa_dev->ip_lut_size; i++) {
+				if (!pa_dev->ip_lut[i].valid)
+					continue;
+				keystone_pa_add_ip_proto(pa_dev, i, 0,
+							 PACKET_DROP);
+			}
+
+			/* if Rx checksum is enabled, add IP LUT entries for
+			 * Rx checksumming
+			 */
+			ret = pa_add_ip_proto(pa_dev, IPPROTO_TCP);
+			if (ret)
+				goto fail;
+			ret = pa_add_ip_proto(pa_dev, IPPROTO_UDP);
+			if (ret)
+				goto fail;
+		}
+	}
+	mutex_unlock(&pa_modules_lock);
+
+	pa_intf->saved_ss_state = netcp_get_streaming_switch(
+						     pa_dev->netcp_device,
+						     netcp_priv->cpsw_port);
+	dev_dbg(pa_dev->dev, "saved_ss_state for port %d is %d\n",
+		 netcp_priv->cpsw_port, pa_intf->saved_ss_state);
+
+	/* Configure the streaming switch */
+	netcp_set_streaming_switch(pa_dev->netcp_device, netcp_priv->cpsw_port,
+				   PSTREAM_ROUTE_PDSP0);
+
+	/* Open the PA Data transmit channel */
+	ret = netcp_txpipe_open(&pa_intf->tx_pipe);
+	if (ret)
+		goto fail;
+
+	netcp_register_txhook(netcp_priv, pa_dev->txhook_order,
+			      pa_tx_hook, intf_priv);
+	if (pa_dev->csum_offload == CSUM_OFFLOAD_SOFT)
+		netcp_register_txhook(netcp_priv, pa_dev->txhook_softcsum,
+				      pa_txhook_softcsum, intf_priv);
+
+	if ((!pa_dev->force_no_hwtstamp) ||
+	     (pa_dev->csum_offload == CSUM_OFFLOAD_HARD))
+		netcp_register_rxhook(netcp_priv, pa_dev->rxhook_order,
+				      pa_rx_hook, intf_priv);
+
+	return 0;
+
+fail:
+	mutex_unlock(&pa_modules_lock);
+	pa_close(intf_priv, ndev);
+	return ret;
+}
+
+int pa_add_addr(void *intf_priv, struct netcp_addr *naddr)
+{
+	struct pa_intf *pa_intf = intf_priv;
+	struct pa_device *pa_dev = pa_intf->pa_device;
+	struct netcp_priv *netcp_priv = netdev_priv(pa_intf->net_device);
+	int count = pa_lut_entry_count(naddr->type);
+	struct pa_lut_entry *entries[count];
+	int port = netcp_priv->cpsw_port;
+	int idx, error;
+	const u8 *addr;
+
+	for (idx = 0; idx < count; idx++) {
+		entries[idx] = pa_lut_alloc(pa_dev, PA_LUT_MAC,
+						naddr->type == ADDR_ANY);
+		if (!entries[idx])
+			goto fail_alloc;
+		entries[idx]->u.naddr = naddr;
+	}
+
+	addr = (naddr->type == ADDR_ANY) ? NULL : naddr->addr;
+	idx = 0;
+
+	if (naddr->type == ADDR_ANY) {
+		error = keystone_pa_add_mac(pa_intf, entries[idx++]->index,
+					    NULL, addr, PACKET_HST, 0, port);
+		if (error)
+			return error;
+	}
+
+	if (count > 1) {
+		error = keystone_pa_add_mac(pa_intf, entries[idx++]->index,
+					    NULL, addr, PACKET_PARSE,
+					    0x0800, port);
+		if (error)
+			return error;
+
+		error = keystone_pa_add_mac(pa_intf, entries[idx++]->index,
+					    NULL, addr, PACKET_PARSE,
+					    0x86dd, port);
+		if (error)
+			return error;
+	}
+
+	if (naddr->type != ADDR_ANY) {
+		error = keystone_pa_add_mac(pa_intf, entries[idx++]->index,
+					    NULL, addr, PACKET_HST, 0, port);
+		if (error)
+			return error;
+	}
+
+	return error;
+
+fail_alloc:
+	for (idx--; idx >= 0; idx--)
+		entries[idx]->in_use = false;
+	return -ENOMEM;
+}
+
+static int pa_del_addr(void *intf_priv, struct netcp_addr *naddr)
+{
+	struct pa_intf *pa_intf = intf_priv;
+	struct pa_device *pa_dev = pa_intf->pa_device;
+	struct pa_lut_entry *entry;
+	int idx;
+
+	for (idx = 0; idx < pa_dev->lut_size; idx++) {
+		entry = pa_dev->lut + idx;
+		if (!entry->valid || !entry->in_use || entry->u.naddr != naddr)
+			continue;
+		keystone_pa_add_mac(pa_intf, entry->index, NULL, NULL,
+				    PACKET_DROP, 0, PA_INVALID_PORT);
+		entry->in_use = false;
+		entry->u.naddr = NULL;
+	}
+
+	return 0;
+}
+
+static int pa_hwtstamp_ioctl(struct pa_intf *pa_intf,
+			     struct ifreq *ifr, int cmd)
+{
+	struct hwtstamp_config cfg;
+
+	if (pa_intf->pa_device->force_no_hwtstamp)
+		return -EOPNOTSUPP;
+
+	if (copy_from_user(&cfg, ifr->ifr_data, sizeof(cfg)))
+		return -EFAULT;
+
+	if (cfg.flags)
+		return -EINVAL;
+
+	switch (cfg.tx_type) {
+	case HWTSTAMP_TX_OFF:
+		pa_intf->tx_timestamp_enable = false;
+		break;
+	case HWTSTAMP_TX_ON:
+		pa_intf->tx_timestamp_enable = true;
+		break;
+	default:
+		return -ERANGE;
+	}
+
+	switch (cfg.rx_filter) {
+	case HWTSTAMP_FILTER_NONE:
+		pa_intf->rx_timestamp_enable = false;
+		break;
+	default:
+		pa_intf->rx_timestamp_enable = true;
+		break;
+	}
+
+	return copy_to_user(ifr->ifr_data, &cfg, sizeof(cfg)) ? -EFAULT : 0;
+}
+
+int pa_ioctl(void *intf_priv, struct ifreq *req, int cmd)
+{
+	struct pa_intf *pa_intf = intf_priv;
+
+	if (cmd == SIOCSHWTSTAMP)
+		return pa_hwtstamp_ioctl(pa_intf, req, cmd);
+
+	return -EOPNOTSUPP;
+}
+
+static int pa_attach(void *inst_priv, struct net_device *ndev, void **intf_priv)
+{
+	struct pa_device *pa_dev = inst_priv;
+	struct netcp_priv *netcp_priv = netdev_priv(ndev);
+	struct pa_intf *pa_intf;
+	int chan_id = 0;
+
+	if (netcp_priv->cpsw_port)
+		pa_dev->multi_if = 1;
+
+	dev_dbg(pa_dev->dev, "pa_attach, port %d\n", netcp_priv->cpsw_port);
+	pa_intf = devm_kzalloc(pa_dev->dev, sizeof(struct pa_intf), GFP_KERNEL);
+	if (!pa_intf) {
+		dev_err(pa_dev->dev, "memory allocation failed\n");
+		return -ENOMEM;
+	}
+
+	pa_intf->net_device = ndev;
+	pa_intf->pa_device = pa_dev;
+	*intf_priv = pa_intf;
+
+	/* Use pdsp5 with 0 as base */
+	if (netcp_priv->cpsw_port)
+		chan_id = netcp_priv->cpsw_port - 1;
+
+	snprintf(pa_intf->tx_chan_name, sizeof(pa_intf->tx_chan_name),
+		 "patx-pdsp5-%d", chan_id);
+	netcp_txpipe_init(&pa_intf->tx_pipe, netdev_priv(ndev),
+			  pa_intf->tx_chan_name, pa_dev->tx_data_queue_depth);
+
+	if (pa_dev->csum_offload) {
+		rtnl_lock();
+		ndev->features		|= pa_dev->netif_features;
+		ndev->hw_features	|= pa_dev->netif_features;
+		ndev->wanted_features	|= pa_dev->netif_features;
+		netdev_update_features(ndev);
+		rtnl_unlock();
+	}
+	return 0;
+}
+
+static int pa_release(void *intf_priv)
+{
+	struct pa_intf *pa_intf = intf_priv;
+	struct pa_device *pa_dev = pa_intf->pa_device;
+	struct net_device *ndev = pa_intf->net_device;
+
+	mutex_lock(&pa_modules_lock);
+	if ((!--pa_dev->inuse_if_count) && (pa_dev->csum_offload)) {
+		rtnl_lock();
+		ndev->features		&= ~pa_dev->netif_features;
+		ndev->hw_features	&= ~pa_dev->netif_features;
+		ndev->wanted_features	&= ~pa_dev->netif_features;
+		netdev_update_features(ndev);
+		rtnl_unlock();
+	}
+	mutex_unlock(&pa_modules_lock);
+	devm_kfree(pa_dev->dev, pa_intf);
+	return 0;
+}
+
+#define pa_cond_unmap(field)					\
+	do {							\
+		if (pa_dev->field)				\
+			devm_iounmap(dev, pa_dev->field);	\
+	} while(0)
+
+static int pa_remove(struct netcp_device *netcp_device, void *inst_priv)
+{
+	struct pa_device *pa_dev = inst_priv;
+	struct device *dev = pa_dev->dev;
+
+	pa_cond_unmap(reg_mailbox);
+	pa_cond_unmap(reg_packet_id);
+	pa_cond_unmap(reg_lut2);
+	pa_cond_unmap(reg_control);
+	pa_cond_unmap(reg_timer);
+	pa_cond_unmap(reg_stats);
+	pa_cond_unmap(pa_iram);
+	pa_cond_unmap(pa_sram);
+
+	devm_kfree(dev, pa_dev->lut);
+	devm_kfree(dev, pa_dev->ip_lut);
+	devm_kfree(dev, pa_dev);
+	return 0;
+}
+
+static int pa_probe(struct netcp_device *netcp_device,
+		    struct device *dev,
+		    struct device_node *node,
+		    void **inst_priv)
+{
+	struct pa_device *pa_dev;
+	int ret, len = 0, start, end, i, j;
+	int table_size, num_ranges;
+	u32 *prange, tmp[2];
+
+	if (!node) {
+		dev_err(dev, "device tree info unavailable\n");
+		return -ENODEV;
+	}
+
+	pa_dev = devm_kzalloc(dev, sizeof(struct pa_device), GFP_KERNEL);
+	if (!pa_dev) {
+		dev_err(dev, "memory allocation failed\n");
+		return -ENOMEM;
+	}
+	*inst_priv = pa_dev;
+
+	pa_dev->netcp_device = netcp_device;
+	pa_dev->dev = dev;
+
+	for (i = 0; i < DEVICE_PA_NUM_PDSPS; ++i) {
+		ret = of_property_read_string_index(node, "firmware",
+				i, &pa_dev->pdsp_fw[i]);
+		if (ret < 0) {
+			dev_warn(dev, "no firmware for pdsp %d\n", i);
+			pa_dev->pdsp_fw[i] = NULL;
+		} else {
+			/*FIXME: make me dev_dbg*/
+			dev_info(dev, "pdsp %d firmware: %s\n",
+					i, pa_dev->pdsp_fw[i]);
+		}
+	}
+
+	ret = of_property_read_u32(node, "tx_cmd_queue_depth",
+				   &pa_dev->tx_cmd_queue_depth);
+	if (ret < 0) {
+		dev_err(dev, "missing tx_cmd_queue_depth parameter, err %d\n",
+			ret);
+		pa_dev->tx_cmd_queue_depth = 32;
+	}
+	dev_dbg(dev, "tx_cmd_queue_depth %u\n", pa_dev->tx_cmd_queue_depth);
+
+	ret = of_property_read_u32(node, "tx_data_queue_depth",
+				   &pa_dev->tx_data_queue_depth);
+	if (ret < 0) {
+		dev_err(dev, "missing tx_data_queue_depth parameter, err %d\n",
+			ret);
+		pa_dev->tx_data_queue_depth = 32;
+	}
+	dev_dbg(dev, "tx_data_queue_depth %u\n", pa_dev->tx_data_queue_depth);
+
+	ret = of_property_read_u32(node, "rx_pool_depth",
+				   &pa_dev->rx_pool_depth);
+	if (ret < 0) {
+		dev_err(dev, "missing rx_pool_depth parameter, err %d\n",
+			ret);
+		pa_dev->rx_pool_depth = 32;
+	}
+	dev_dbg(dev, "rx_pool_depth %u\n", pa_dev->rx_pool_depth);
+
+	ret = of_property_read_u32(node, "rx_buffer_size",
+				   &pa_dev->rx_buffer_size);
+	if (ret < 0) {
+		dev_err(dev, "missing rx_buffer_size parameter, err %d\n",
+			ret);
+		pa_dev->rx_buffer_size = 128;
+	}
+	dev_dbg(dev, "rx_buffer_size %u\n", pa_dev->rx_buffer_size);
+
+	pa_dev->reg_mailbox	= devm_ioremap(dev, 0x2000000, 0x60);
+	pa_dev->reg_packet_id	= devm_ioremap(dev, 0x2000400, 0x10);
+	pa_dev->reg_lut2	= devm_ioremap(dev, 0x2000500, 0x40);
+	pa_dev->reg_control	= devm_ioremap(dev, 0x2001000, 0x600);
+	pa_dev->reg_timer	= devm_ioremap(dev, 0x2003000, 0x600);
+	pa_dev->reg_stats	= devm_ioremap(dev, 0x2006000, 0x100);
+	pa_dev->pa_iram		= devm_ioremap(dev, 0x2010000, 0x30000);
+	pa_dev->pa_sram		= devm_ioremap(dev, 0x2040000, 0x8000);
+
+	if (!pa_dev->reg_mailbox || !pa_dev->reg_packet_id ||
+	    !pa_dev->reg_lut2 || !pa_dev->reg_control ||
+	    !pa_dev->reg_timer || !pa_dev->reg_stats ||
+	    !pa_dev->pa_sram || !pa_dev->pa_iram) {
+		dev_err(dev, "failed to set up register areas\n");
+		ret = -ENOMEM;
+		goto exit;
+	}
+
+	ret = of_property_read_u32(node, "checksum-offload",
+				   &pa_dev->csum_offload);
+	if (ret < 0) {
+		dev_warn(dev, "missing checksum-offload parameter, err %d\n",
+			ret);
+		pa_dev->csum_offload = CSUM_OFFLOAD_NONE;
+	}
+	if (pa_dev->csum_offload > CSUM_OFFLOAD_SOFT) {
+		dev_err(dev, "invalid checksum-offload parameter %d, err %d\n",
+			ret, pa_dev->csum_offload);
+		pa_dev->csum_offload = CSUM_OFFLOAD_NONE;
+	}
+	dev_dbg(dev, "checksum-offload %u\n", pa_dev->csum_offload);
+
+	ret = of_property_read_u32(node, "txhook-order",
+				   &pa_dev->txhook_order);
+	if (ret < 0) {
+		dev_err(dev, "missing txhook-order parameter, err %d\n",
+			ret);
+		pa_dev->txhook_order = PA_TXHOOK_ORDER;
+	}
+	dev_dbg(dev, "txhook-order %u\n", pa_dev->txhook_order);
+
+	if (pa_dev->csum_offload == CSUM_OFFLOAD_SOFT) {
+		ret = of_property_read_u32(node, "txhook-softcsum",
+					   &pa_dev->txhook_softcsum);
+		if (ret < 0) {
+			dev_err(dev, "missing txhook-softcsum parameter, err %d\n",
+				ret);
+			pa_dev->csum_offload = CSUM_OFFLOAD_NONE;
+			pa_dev->txhook_order = ~0;
+		}
+		dev_dbg(dev, "txhook-softcsum %u\n", pa_dev->txhook_softcsum);
+	}
+
+	if (pa_dev->csum_offload != CSUM_OFFLOAD_NONE)
+		pa_dev->netif_features = PA_NETIF_FEATURES;
+
+	if (pa_dev->csum_offload == CSUM_OFFLOAD_HARD)
+		pa_dev->netif_features |= NETIF_F_RXCSUM;
+
+	ret = of_property_read_u32(node, "rxhook-order",
+				   &pa_dev->rxhook_order);
+	if (ret < 0) {
+		dev_err(dev, "missing rxhook-order parameter, err %d\n",
+			ret);
+		pa_dev->rxhook_order = PA_RXHOOK_ORDER;
+	}
+	dev_dbg(dev, "rxhook-order %u\n", pa_dev->rxhook_order);
+
+	ret = of_property_read_u32_array(node, "mark_mcast_match",
+					pa_dev->mark_mcast_match, 2);
+	if (ret < 0) {
+		if (ret != -EINVAL) {
+			dev_err(dev, "Error parsing \"mark_mcast_match\" value"
+				" -- parameter ignored\n");
+		}
+		pa_dev->mark_mcast_match[0] = 0;
+		pa_dev->mark_mcast_match[1] = 0;
+	} else if (((pa_dev->mark_mcast_match[0] & 0xff) != 0) ||
+		   ((pa_dev->mark_mcast_match[1] & 0xff) != 0) ||
+		   ((pa_dev->mark_mcast_match[0] & ~pa_dev->mark_mcast_match[1]) != 0)) {
+		dev_err(dev, "Error in \"mark_mcast_match\" value"
+				" -- parameter ignored\n");
+		pa_dev->mark_mcast_match[0] = 0;
+		pa_dev->mark_mcast_match[1] = 0;
+	}
+	dev_dbg(dev, "mark_mcast_match = <%08x %08x>\n",
+		 pa_dev->mark_mcast_match[0], pa_dev->mark_mcast_match[1]);
+
+	if (!of_get_property(node, "lut-ranges", &len)) {
+		dev_err(dev, "No lut-entry array in dt bindings for PA\n");
+		return -ENODEV;
+	}
+
+	if (of_find_property(node, "force_no_hwtstamp", NULL)) {
+		pa_dev->force_no_hwtstamp = 1;
+		dev_warn(dev, "***** No PA timestamping *****\n");
+	}
+
+	prange = devm_kzalloc(dev, len, GFP_KERNEL);
+	if (!prange) {
+		dev_err(dev, "memory allocation failed at PA lut entry range\n");
+		return -ENOMEM;
+	}
+	len = len / sizeof(u32);
+	if ((len % 2) != 0) {
+		dev_err(dev, "invalid address map in dt binding\n");
+		return -EINVAL;
+	}
+	num_ranges = len / 2;
+	if (of_property_read_u32_array(node, "lut-ranges", prange, len)) {
+		dev_err(dev, "No range-map array  in dt bindings\n");
+		return -ENODEV;
+	}
+
+	table_size = prange[2 * num_ranges - 1] + 1;
+	dev_dbg(dev, "lut size = %d\n", table_size);
+
+	/* Initialize a table for storing entry listings locally */
+	len = table_size * sizeof(struct pa_lut_entry);
+	pa_dev->lut  = devm_kzalloc(dev, len, GFP_KERNEL);
+	if (!pa_dev->lut) {
+		dev_err(dev, "devm_kzalloc mapping failed\n");
+		return -ENOMEM;
+	}
+	pa_dev->lut_size = table_size;
+	dev_dbg(dev, "lut size = %d\n", table_size);
+
+	for (i = 0; i < num_ranges; i++) {
+		start = prange[i * 2];
+		end   = prange[i * 2 + 1];
+		for (j = start; j <= end; j++) {
+			pa_dev->lut[j].valid = true;
+			pa_dev->lut[j].index = j;
+			dev_dbg(dev, "setting entry %d to valid\n", j);
+		}
+	}
+
+	devm_kfree(dev, prange);
+
+	/* NOTE: DTS configuration MUST ensure that the completion queue &
+	 * Rx flow for each interface is sequential.
+	 */
+	ret = of_property_read_u32_array(node, "rx-route", tmp, 2);
+	if (ret) {
+		dev_err(dev, "Couldn't get rx-route from dt bindings\n");
+		return -ENODEV;
+	} else {
+		pa_dev->rx_queue_base = tmp[0];
+		pa_dev->rx_flow_base = tmp[1];
+	}
+
+	/* Get IP lut ranges */
+	if (!of_get_property(node, "ip-lut-ranges", &len)) {
+		dev_err(dev,
+		"No ip-lut-entry array in dt bindings for PA\n");
+		return -ENODEV;
+	}
+
+	prange = devm_kzalloc(dev, len, GFP_KERNEL);
+	if (!prange) {
+		dev_err(dev,
+		"memory allocation failed for IP lut entry range\n");
+		return -ENOMEM;
+	}
+	len = len / sizeof(u32);
+	if ((len % 2) != 0) {
+		dev_err(dev, "invalid address map in dt binding\n");
+		return -EINVAL;
+	}
+	num_ranges = len / 2;
+	if (of_property_read_u32_array(node, "ip-lut-ranges", prange, len)) {
+		dev_err(dev, "No range-map array  in dt bindings\n");
+		return -ENODEV;
+	}
+	table_size = prange[2 * num_ranges - 1] + 1;
+	pa_dev->ip_lut_size = table_size;
+	dev_dbg(dev, "IP lut size = %d\n", pa_dev->ip_lut_size);
+
+	len = pa_dev->ip_lut_size * sizeof(struct pa_lut_entry);
+	pa_dev->ip_lut  = devm_kzalloc(dev, len, GFP_KERNEL);
+
+	for (i = 0; i < num_ranges; i++) {
+		start = prange[i * 2];
+		end   = prange[i * 2 + 1];
+		for (j = start; j <= end; j++) {
+			pa_dev->ip_lut[j].valid = true;
+			pa_dev->ip_lut[j].index = j;
+			dev_dbg(dev, "setting entry %d to valid\n", j);
+		}
+	}
+
+	devm_kfree(pa_dev->dev, prange);
+	spin_lock_init(&pa_dev->lock);
+	spin_lock_init(&tstamp_lock);
+	return 0;
+
+exit:
+	pa_remove(netcp_device, pa_dev);
+	*inst_priv = NULL;
+	return ret;
+}
+
+
+static struct netcp_module pa_module = {
+	.name		= "keystone-pa",
+	.owner		= THIS_MODULE,
+	.probe		= pa_probe,
+	.open		= pa_open,
+	.close		= pa_close,
+	.remove		= pa_remove,
+	.attach		= pa_attach,
+	.release	= pa_release,
+	.add_addr	= pa_add_addr,
+	.del_addr	= pa_del_addr,
+	.ioctl		= pa_ioctl,
+};
+
+static int __init keystone_pa_init(void)
+{
+	return netcp_register_module(&pa_module);
+}
+module_init(keystone_pa_init);
+
+static void __exit keystone_pa_exit(void)
+{
+	netcp_unregister_module(&pa_module);
+}
+module_exit(keystone_pa_exit);
+
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("Sandeep Paulraj <s-paulraj@ti.com>");
+MODULE_DESCRIPTION("Packet Accelerator driver for Keystone devices");
diff --git a/drivers/net/ethernet/ti/keystone_pa.h b/drivers/net/ethernet/ti/keystone_pa.h
new file mode 100644
index 0000000..1804cfd
--- /dev/null
+++ b/drivers/net/ethernet/ti/keystone_pa.h
@@ -0,0 +1,859 @@
+/*
+ * Copyright (C) 2012 Texas Instruments Incorporated
+ * Author: Sandeep Paulraj <s-paulraj@ti.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation version 2.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef KEYSTONE_PA_H
+#define KEYSTONE_PA_H
+
+#ifdef __KERNEL__
+
+
+struct pa_pdsp_config {
+
+	u32 pdsp[6];
+
+	char *pdsp_fw[6];
+};
+
+#define PAFRM_MAX_CMD_SET_SIZE		124
+
+#define	PA_DEST_DISCARD  3  /**< Packet is discarded */
+
+/** 
+ *  @def  PA_DEST_CONTINUE_PARSE_LUT1
+ *        packet remains in PA sub-system for more parsing and LUT1 classification
+ */
+#define PA_DEST_CONTINUE_PARSE_LUT1  4 /**< Packet remains in PA sub-system for more parsing and LUT1 classification */
+
+/** 
+ *  @def  PA_DEST_CONTINUE_PARSE_LUT2
+ *        packet remains in PA sub-system for more parsing and LUT2 classification. 
+ */
+#define PA_DEST_CONTINUE_PARSE_LUT2  5  /**< Packet remains in PA sub-system for more parsing and LUT2 classification */
+
+/**
+ *  @def  PA_DEST_HOST
+ *        host thread 
+ */
+#define PA_DEST_HOST   6   /**< Packet is routed to host */
+
+/** 
+ *  @def  PA_DEST_EMAC
+ *        ethernet mac port (of the switch)
+ */
+#define PA_DEST_EMAC   7   /**< Packet is routed to  EMAC */
+
+/** 
+ *  @def  PA_DEST_SASS
+ *        security accelerator destination 
+ */
+#define PA_DEST_SASS   8   /**< Packet is routed to SA */
+
+#define PA_DEST_SRIO   9
+
+#define PA_NO_MULTI_ROUTE		-1
+#define PA_MAX_MULTI_ROUTE_SETS		32
+#define PA_MAX_MULTI_ROUTE_ENTRIES	8
+#define PA_MULTI_ROUTE_DESCRIPTOR_ONLY	0x01
+
+#define PA_EMAC_CTRL_PORT_MASK		0x0F 
+#define PA_EMAC_CTRL_CRC_DISABLE	0x80 
+#define PA_CUSTOM_TYPE_NONE		0   
+#define PA_CUSTOM_TYPE_LUT1		1   
+#define PA_CUSTOM_TYPE_LUT2		2   
+#define PA_MAX_CUSTOM_TYPES_LUT1	4
+#define PA_MAX_CUSTOM_TYPES_LUT2	4
+
+#define PA_CMD_TX_DEST_0	0  /* Packet is sent to PDSP0 */
+#define PA_CMD_TX_DEST_1	1  /* Packet is sent to PDSP1 */
+#define PA_CMD_TX_DEST_2	2  /* Packet is sent to PDSP2 */
+#define PA_CMD_TX_DEST_3	3  /* Packet is sent to PDSP3 */
+#define PA_CMD_TX_DEST_4	4  /* Packet is sent to PDSP4 */
+#define PA_CMD_TX_DEST_5	5  /* Packet is sent to PDSP5 */
+
+#define PA_CMD_NONE			0   
+#define PA_CMD_NEXT_ROUTE		1   
+#define PA_CMD_CRC_OP			2   
+#define PA_CMD_COPY_DATA_TO_PSINFO	3
+#define PA_CMD_PATCH_DATA		4  
+#define PA_CMD_TX_CHECKSUM		5 
+#define PA_CMD_MULTI_ROUTE		6  
+#define PA_CMD_REPORT_TX_TIMESTAMP	7 
+#define PA_CMD_REMOVE_HEADER		8 
+#define PA_CMD_REMOVE_TAIL		9 
+#define PA_CMD_CMDSET			10   
+#define PA_CMD_SA_PAYLOAD		11
+#define PA_CMD_IP_FRAGMENT		12
+#define PA_CMD_USR_STATS		13
+#define PA_CMD_CMDSET_AND_USR_STATS	14
+
+/* Interface based routing modes */
+#define PA_ROUTE_INTF_NONE	0 /* No interface based routing */
+#define PA_ROUTE_INTF_QUEUE	1 /* Route by interface number as dest queue
+				     offset */
+#define PA_ROUTE_INTF_FLOW	2 /* Route by interface number as both dest
+				     queue & CPPI flow offset */
+
+struct pa_frm_forward_host {
+
+	u32	context; /* Context returned as swInfo0 for matched packet */
+	/*  Control bitmap, 1 for enable, 0 for disable
+	 *  /-----------------------------------------------------\
+	 *  | 7           |       2     |      1      |     0     |
+	 *  | Selection   |             |Flow IF Dest |           |
+	 *  | 0: Priority |             |    OR       |           |
+	 *  | 1: IF dest  |DSCP priority|VLAN priority| multiRoute|
+	 *  \-----------------------------------------------------/
+	 */
+	u8	ctrl_bm;
+	u8	multi_idx;	/* Index of the multiple destination set */
+	u8	pa_pdsp_router; /* PA PDSP number used as multi-route router */
+	u8	ps_flags;	/* use the bits 7:4.
+				   bit 7: Disable CRC,
+				   bit 6:4 port number (0/1/2),
+				   bit 3:0 errflags = 0
+				   psFlags may be required when the packet is
+				   forwarded through QoS queue */
+	u8	cmd[4];		/* optional simple command:0 means no command */
+}; /* 12 bytes */
+#define PAFRM_MULTIROUTE_ENABLE			0x1
+#define PAFRM_ROUTING_PRIORITY_DSCP_ENABLE	0x2
+#define PAFRM_ROUTING_PRIORITY_VLAN_ENABLE	0x4
+#define PAFRM_ROUTING_FLOW_IF_BASE_ENABLE	0x2 /* 0: queue-based only
+						       1: queue & flow-based */
+#define PAFRM_ROUTING_IF_DEST_SELECT_ENABLE	0x80
+
+
+/* Routing information used to forward packets to the SA (via PKTDMA) */
+struct pa_frm_forward_sa {
+
+	u32	sw_info_0;	/* Packet descriptor swInfo0 required by SA
+				   operation */
+	u32	sw_info_1;	/* Packet descriptor swInfo1 required by SA
+				   operation */
+	u8	cmd[4];		/* optional simple command:0 means no command */
+};
+
+/* Routing information used to forward packets to the SRIO (via PKTDMA) */
+struct pa_frm_forward_srio {
+
+	u32  ps_info0;		/* 8-byte protocol-specific information
+				   required by SRIO  */
+	u32  ps_info1;		/* routing */
+	u8   pkt_type;		/* Packet type specified for SRIO operation */
+	u8   rsv4[3];
+};
+
+/* Routing information used to forward packets to the Ethernet port */
+struct pa_frm_forward_eth {
+	u8	ps_flags;  /* use the bit 7:4
+			      bit 7: Disable CRC,
+			      bit 6:4 port number (0/1/2)
+			      bit 3:0 errflags = 0*/
+	u8	rsvd1;
+	u16	rsvd2;
+	u32	rsvd3;
+	u32	rsvd4;
+};
+
+#define PAFRM_ETH_PS_FLAGS_DISABLE_CRC          0x80
+#define PAFRM_ETH_PS_FLAGS_PORT_MASK            0x70
+#define PAFRM_ETH_PS_FLAGS_PORT_SHIFT              4
+
+
+/* Routing information used to forward packets within PA */
+struct pa_frm_forward_pa {
+
+	u8	pa_dest;      /* PDSP destination */
+	u8	custom_type;  /* None, LUT1, LUT2 */
+	u8	custom_idx;   /* Index of the custom type if LUT1 or LUT2
+				 custom */
+	u8	rsvd2;
+	u32	rsvd3;
+	u32	rsvd4;
+};
+
+#define PAFRM_CUSTOM_TYPE_NONE PA_CUSTOM_TYPE_NONE    /* 0 */
+#define PAFRM_CUSTOM_TYPE_LUT1 PA_CUSTOM_TYPE_LUT1    /* 1 */
+#define PAFRM_CUSTOM_TYPE_LUT2 PA_CUSTOM_TYPE_LUT2    /* 2 */
+
+/* Routing information used to forward packets fromm PA sub-system to various
+ * destinations
+ */
+struct pa_frm_forward  {
+
+	u8 forward_type;	/* Forwarding type as defined below */
+	u8 flow_id;		/* PKTDMA flow Id, valid if forwarding via
+				   PKTDMA */
+	u16 queue;		/* Destination queue number, valid if
+				   forwarding via PKTDMA */
+  
+	union {
+		struct pa_frm_forward_host	host; /* Host specific routing
+							 information */
+		struct pa_frm_forward_sa	sa;   /* SA specific routing
+							 information */
+		struct pa_frm_forward_srio	srio; /* SRIO specific routing
+							 information */
+		struct pa_frm_forward_eth	eth;  /* Ethernet specific
+							 routing information */
+		struct pa_frm_forward_pa	pa;   /* PA internal routing
+							 information */
+	} u;
+};
+
+enum {
+	PAFRM_FORWARD_TYPE_HOST = 0,	/* use PAFRM_DEST_CDMA */
+	PAFRM_FORWARD_TYPE_SA,		/* use PAFRM_DEST_CDMA */
+	PAFRM_FORWARD_TYPE_PA,		/* use pa.paDest */
+	PAFRM_FORWARD_TYPE_ETH,		/* use PAFRM_DEST_ETH */
+	PAFRM_FORWARD_TYPE_SRIO,	/* use PAFRM_DEST_CDMA */
+	PAFRM_FORWARD_TYPE_DISCARD
+};
+
+/* Custom match flag bits */
+#define	PAFRM_LUT1_CUSTOM_MATCH_ETYPE	(1 << 2)
+#define	PAFRM_LUT1_CUSTOM_MATCH_VLAN	(1 << 3)
+#define	PAFRM_LUT1_CUSTOM_MATCH_MATCH	(3 << 4)  /* Ipv6 source and dest entries */
+#define	PAFRM_LUT1_CUSTOM_MATCH_KEY	(1 << 13)
+#define	PAFRM_LUT1_CUSTOM_MATCH_VALID	(1 << 15)
+
+/* Key values. The PDSP will set these bits as it parses the SRIO header */
+#define PAFRM_LUT1_CUSTOM_KEY_CUSTOM		PAFRM_LUT1_KEY_CUSTOM
+#define PAFRM_LUT1_CUSTOM_KEY_INDEX(index)	((index) << 0)  /* Vaild if custom type is set */
+
+/* Add entry to LUT1 */
+/* if PA_LUT1_INDEX_LAST_FREE is used then when the command returns, the value of index
+ * will be replaced with the actual index used */
+#define PAFRM_HW_LUT1_ENTRIES		64
+#define PAFRM_LUT1_INDEX_LAST_FREE	PAFRM_HW_LUT1_ENTRIES
+
+/* Standard match flag bits */
+#define PAFRM_LUT1_MATCH_DMAC		(1 << 0)
+#define PAFRM_LUT1_MATCH_SMAC		(1 << 1)
+#define PAFRM_LUT1_MATCH_ETYPE		(1 << 2)
+#define PAFRM_LUT1_MATCH_VLAN		(1 << 3)
+#define PAFRM_LUT1_MATCH_SIP		(1 << 4)
+#define PAFRM_LUT1_MATCH_DIP		(1 << 5)
+#define PAFRM_LUT1_MATCH_SPI_GRE_SCTP	(1 << 6)
+#define PAFRM_LUT1_MATCH_FLOW		(1 << 7)
+#define PAFRM_LUT1_MATCH_SPORT		(1 << 8)
+#define PAFRM_LUT1_MATCH_DPORT		(1 << 9)
+#define PAFRM_LUT1_MATCH_PROTO		(1 << 10)
+#define PAFRM_LUT1_MATCH_TOS		(1 << 11)
+#define PAFRM_LUT1_MATCH_PORT		(1 << 12)
+#define PAFRM_LUT1_MATCH_KEY		(1 << 13)
+#define PAFRM_LUT1_MATCH_VALID		(1 << 15)
+
+#define PAFRM_LUT1_MATCH_MPLS		(PAFRM_LUT1_MATCH_SPORT | PAFRM_LUT1_MATCH_DPORT)
+
+/* Key values. The PDSP will set these bits as it parses the headers. */
+/* LUT1_1 and LUT1_2 (L3): The following bit fields are used */
+#define PAFRM_LUT1_KEY_SPI	(1 << 0)
+#define PAFRM_LUT1_KEY_GRE	(1 << 1)
+#define PAFRM_LUT1_KEY_MPLS	(1 << 2)
+#define PAFRM_LUT1_KEY_IPV4	(1 << 3)
+#define PAFRM_LUT1_KEY_IPV6	(1 << 4)
+#define PAFRM_LUT1_KEY_SCTP	(1 << 5)
+
+/* LUT1: Custom  (L3) */
+#define PAFRM_LUT1_KEY_CUSTOM	(1 << 7)     
+
+/* LUT1_0: MAC and SRIO (L0-l2): The following bit fields are used */
+#define PAFRM_LUT1_KEY_SRIO	(1 << 7)
+
+#define PAFRM_LUT1_KEY_MAC    (1 << 0)
+
+struct pa_frm_com_l1_standard {
+
+	/* LUT1 view 1 */
+	u8	dmac[6];	/* Destination mac */
+	u8	smac[6];	/* Source mac */
+	u16	etype;		/* Ethernrt type, the field is also used for the previous match PDSP number */
+	u16	vlan;		/* VLAN tag, the field is also used for the previous match LUT1 index */
+  
+	/* LUT1 view 2 */
+	u8	src_ip[16];	/* Source IP address */
+	u8	dst_ip[16];	/* Destination IP address */
+  
+	/* LUT1 view 3 */
+	u32	spi;		/* ESP or AH header Security Parameters Index */
+				/* The field is also used for GRE protocol or SCTP destination port */
+	u32	flow;		/* IPv6 flow label in 20 lsbs */
+  
+	union {
+		u16	ports[2];   /* UDP/TCP Source port (0), destination port (1) */
+		u32	mpls;       /* mpls label in 20 Lsbs */
+	} pm;
+  
+	u8	proto_next;	/* Ipv4 Protocol fields, IPv6 next */
+	u8	tos_tclass;	/* Ipv4 TOS, Ipv6 traffic class */
+	u8	inport;		/* reserved field: not used */
+	u8	key;		/* IP: Distinguishs spi/gre and mpls and ports
+					* LUT1_0: MAC/SRIO, 
+					* LUT1_1/LUT1_2: custom or standard 
+					*/
+	/* end LUT1 view 3 */
+  
+	/* Lookup cares/don't cares */
+	u16	match_flags;	/* lookup matching valid flags as defined below */
+	u16	rsvd;		/* reserved for alignment */
+};
+
+struct pa_frm_com_l1_srio {
+
+	/* LUT1 view 1 */
+	u8	rsvd1[4];	/* unused field: All zero's */
+	u16	src_id;	/* Source ID */
+	u16	dest_id;	/* Destination ID */
+	u8	rsvd2[4];	/* unused field: All zero's */
+	u16	etype;	/* upper link (previous match PDSP number) */
+	u16	vlan;	/* upper link (previous match LUT1 index) */
+  
+	/* LUT1 view 2 */
+	u8	rsvd3[16];		/* unused field: All zero's */
+	u8	rsvd4[14];		/* unused field: All zero's */
+	u16	type_param1;	/* stream ID or mailbox */
+  
+	/* LUT1 view 3 */
+	u32	spi;	/* unused field: All zero's */
+	u32	flow;	/* unused field: All zero's */
+  
+	u16	next_hdr_offset;	/* unused field: All zero's */
+	u8	next_hdr;		/* place holder for nextHdr and nextOffset */
+	u8	rsvd5;			/* unused field: All zero's */
+	u8	pri;			/* 3-bit Priority */
+	u8	type_param2;		/* cos or letter */
+	u8	inport;			/* unused field: All zero's */
+	u8	key;			/* IP: Distinguishs spi/gre and mpls and ports
+					 * LUT1_0: MAC/SRIO, 
+					 * LUT1_1/LUT1_2: custom or standard 
+					 */
+	/* end LUT1 view 3 */
+	/* Lookup cares/don't cares */
+	u16	match_flags;		/* lookup matching valid flags as defined below */
+	u16	rsvd;			/* reserved for alignment */
+};
+
+struct pa_frm_com_l1_custom{
+
+	/* LUT1 view 1 */
+	u8	dmac[6];	/* unused field: All zero's */
+	u8	smac[6];	/* unused field: All zero's */
+	u16	etype;		/* upper link (previous match PDSP number) */
+	u16	vlan;		/* upper link (previous match LUT1 index) */
+  
+	/* LUT1 view 2 */
+	u8	match_values[32];	/* 32 bytes to match   */
+  
+	/* LUT1 view 3 - offset from start */
+	u32	rsvd0;		/* unused field: All zero's */
+	u32	rsvd1;		/* unused field: All zero's */
+	u32	rsvd2;		/* unused field: All zero's */
+  
+	u8	rsvd3;		/* unused field: All zero's */
+	u8	rsvd4;		/* unused field: All zero's */
+	u8	inport;		/* unused field: All zero's */
+	u8	key;		/* IP: Distinguishs spi/gre and mpls and ports
+				 * LUT1_0: MAC/SRIO, 
+				 * LUT1_1/LUT1_2: custom or standard 
+				 */
+  
+	/* Lookup cares/dont cares */
+	u16	match_flags;	/* lookup matching valid flags as defined below */
+	u16	rsvd5;		/* reserved for alignment */ 
+};
+
+enum {
+	PAFRM_CONFIG_COMMAND_RSVD	= 0,
+	PAFRM_CONFIG_COMMAND_ADDREP_LUT1,
+	PAFRM_CONFIG_COMMAND_DEL_LUT1,
+	PAFRM_CONFIG_COMMAND_ADDREP_LUT2,
+	PAFRM_CONFIG_COMMAND_DEL_LUT2,
+	PAFRM_CONFIG_COMMAND_CONFIG_PA,
+	PAFRM_CONFIG_COMMAND_REQ_STATS,
+	PAFRM_CONFIG_COMMAND_REQ_VERSION,
+	PAFRM_CONFIG_COMMAND_MULTI_ROUTE,
+	PAFRM_CONFIG_COMMAND_CRC_ENGINE,
+	PAFRM_CONFIG_COMMAND_CMD_SET,
+	PAFRM_CONFIG_COMMAND_USR_STATS,
+	PAFRM_CONFIG_COMMAND_SYS_CONFIG
+};
+
+/* Command magic value */
+#define PAFRM_CONFIG_COMMAND_SEC_BYTE  0xce
+
+/* Command return values */
+enum {
+
+	PAFRM_COMMAND_RESULT_SUCCESS = 0,              /* Must be 0 */
+	PAFRM_COMMAND_RESULT_NO_COMMAND_MAGIC,         /* Command magic value not found */
+  
+	PAFRM_COMMAND_RESULT_INVALID_CMD,              /* Invalid command identifier */
+  
+	/* Add entry to LUT1 fails */
+	PAFRM_COMMAND_RESULT_LUT1_TYPE_INVALID,        /* Invalid type, custom or standard IP/ethernet */
+	PAFRM_COMMAND_RESULT_LUT1_INDEX_INVALID,       /* Invalid LUT1 index (0-63) or no free indices available */
+	PAFRM_COMMAND_RESULT_LUT1_MATCH_DEST_INVALID,  /* Sent a match packet to q0 on c1 or c2 - this is illegal. */
+	PAFRM_COMMAND_RESULT_LUT1_NMATCH_INVALID,      /* Previous match forward info was somewhere in chunk domain */
+	PAFRM_COMMAND_RESULT_LUT1_INVALID_KEYS,        /* Invalid combination found in the key value */
+  
+	/* Lut 2 entry warnings since the lut can be configured without pdsp */
+	PAFRM_COMMAND_RESULT_WARN_OVER_MAX_ENTRIES,
+	PAFRM_COMMAND_RESULT_WARN_NEGATIVE_ENTRY_COUNT,
+  
+	/* Lut 2 entry failures */
+	PAFRM_COMMAND_RESULT_LUT2_ADD_BUSY,            /* LUT2 had a lookup and pending config */
+  
+	/* Not enough room in stats request packet for the reply */
+	PAFRM_COMMAND_RESULT_WARN_STATS_REPLY_SIZE,
+  
+	/* Command sent to PDSP which couldn't handle it */
+	PAFRM_COMMAND_RESULT_INVALID_DESTINATION,
+  
+	/* Add/Delete/Read entries to multi route table */
+	PAFRM_COMMAND_RESULT_MULTI_ROUTE_NO_FREE_ENTRIES,    /* Asked to use a free entry, but none found */
+	PAFRM_COMMAND_RESULT_MULTI_ROUTE_INVALID_IDX,        /* Illegal index value used */
+	PAFRM_COMMAND_RESULT_MULTI_ROUTE_INVALID_MODE,       /* Illegal multi route mode used */
+  
+	/* Packet size didn't match command */
+	PAFRM_COMMAND_RESULT_INVALID_PKT_SIZE,
+  
+	/* Coustom and Command set index */
+	PAFRM_COMMAND_RESULT_INVALID_C1_CUSTOM_IDX,          /* Illegal Custom LUT1 index value used */
+	PAFRM_COMMAND_RESULT_INVALID_C2_CUSTOM_IDX,          /* Illegal Custom LUT2 index value used */
+	PAFRM_COMMAND_RESULT_INVALID_CMDSET_IDX              /* Illegal Custom Command Set index value used */
+};
+
+#define PA_SS_TIMER_CNTRL_REG_GO		0x00000001u
+#define PA_SS_TIMER_CNTRL_REG_MODE		0x00000002u
+#define PA_SS_TIMER_CNTRL_REG_PSE		0x00008000u
+#define PA_SS_TIMER_CNTRL_REG_PRESCALE_SHIFT	0x00000002u
+
+/* Destination (route) values */
+#define PAFRM_DEST_PDSP0	0
+#define PAFRM_DEST_PDSP1	1
+#define PAFRM_DEST_PDSP2	2
+#define PAFRM_DEST_PDSP3	3
+#define PAFRM_DEST_PDSP4	4
+#define PAFRM_DEST_PDSP5	5
+#define PAFRM_DEST_PKTDMA	6   
+#define PAFRM_DEST_ETH		7
+
+#define PAFRM_DEST_DISCARD	10
+
+/* Assigning names based on PDSP functions */
+#define PAFRM_DEST_PA_C1_0	PAFRM_DEST_PDSP0
+#define PAFRM_DEST_PA_C1_1	PAFRM_DEST_PDSP1
+#define PAFRM_DEST_PA_C1_2	PAFRM_DEST_PDSP2 
+#define PAFRM_DEST_PA_C2	PAFRM_DEST_PDSP3
+#define PAFRM_DEST_PA_M_0	PAFRM_DEST_PDSP4
+#define PAFRM_DEST_PA_M_1	PAFRM_DEST_PDSP5
+
+/* The default queue for packets that arrive at the PA and don't match in
+ * classify1 (right at init time) */
+#define PAFRM_DEFAULT_INIT_Q	0x100
+
+/* Ethertypes recognized by the firmware. */
+#define PAFRM_ETHERTYPE_IP		0x0800
+#define PAFRM_ETHERTYPE_IPV6		0x86dd
+#define PAFRM_ETHERTYPE_VLAN		0x8100
+#define PAFRM_ETHERTYPE_SPVLAN		0x88a8
+#define PAFRM_ETHERTYPE_MPLS		0x8847
+#define PAFRM_ETHERTYPE_MPLS_MULTI	0x8848
+
+/* Next header type values  */
+#define PAFRM_HDR_MAC			0
+#define PAFRM_HDR_VLAN			1
+#define PAFRM_HDR_MPLS			2
+#define PAFRM_HDR_IPv4			3
+#define PAFRM_HDR_IPv6			4
+#define PAFRM_HDR_IPv6_EXT_HOP		5
+#define PAFRM_HDR_IPv6_EXT_ROUTE	6
+#define PAFRM_HDR_IPv6_EXT_FRAG		7
+#define PAFRM_HDR_IPv6_EXT_DEST		8
+#define PAFRM_HDR_GRE			9
+#define PAFRM_HDR_ESP			10
+#define PAFRM_HDR_ESP_DECODED		11
+#define PAFRM_HDR_AUTH			12
+#define PAFRM_HDR_CUSTOM_C1		13
+#define PAFRM_HDR_FORCE_LOOKUP		14   /* A contrived header type used with custom SRIO to force
+                                           a parse after looking at only the RIO L0-L2 */
+#define PAFRM_HDR_SCTP			15
+#define PAFRM_HDR_UNKNOWN		16
+#define PAFRM_HDR_UDP			17
+#define PAFRM_HDR_UDP_LITE		18
+#define PAFRM_HDR_TCP			19
+#define PAFRM_HDR_GTPU			20
+#define PAFRM_HDR_ESP_DECODED_C2	21
+#define PAFRM_HDR_CUSTOM_C2		22
+
+/* Command related definitions */
+#define PAFRM_CRC_FLAG_CRC_OFFSET_VALID		0x01
+#define PAFRM_CRC_FLAG_CRC_OFFSET_FROM_DESC	0x02
+#define PAFRM_CHKSUM_FALG_NEGATIVE		0x01
+
+#define PA_NEXT_ROUTE_PARAM_PRESENT		0x0001
+#define PA_NEXT_ROUTE_PROC_NEXT_CMD		0x0002
+#define PA_NEXT_ROUTE_PROC_MULTI_ROUTE		0x0004
+
+/* PAFRM receive commands related definitions */
+
+/* 
+ * There are the following two groups of PAFRM receive commands:
+ * PAFRM short commands which can be used as part of the routing info 
+ * PAFRM commands which can be used within a command set
+ */
+ 
+#define PAFRM_RX_CMD_NONE		0           /* Dummy command */
+
+/* short commands */
+#define PAFRM_RX_CMD_CMDSET		1           /* Execute a command set */
+#define PAFRM_RX_CMD_INSERT		2           /* Insert up to two types at the current location */
+
+/* command set commands */
+#define PAFRM_RX_CMD_NEXT_ROUTE		3           /* Specify the next route */
+#define PAFRM_RX_CMD_CRC_OP		4           /* CRC generation or verification */
+#define PAFRM_RX_CMD_COPY_DATA		5           /* Copy data to the PS Info section */
+#define PAFRM_RX_CMD_PATCH_DATA		6           /* Insert or pacth packet data at the specific location */
+#define PAFRM_RX_CMD_REMOVE_HDR		7           /* Remove the parsed packet header */
+#define PAFRM_RX_CMD_REMOVE_TAIL	8           /* Remove the parsed packet tail */
+#define PAFRM_RX_CMD_MULTI_ROUTE	9           /* Duplicate packet to multiple destinations */
+
+/*
+ * PASS command ID formatting
+ * Bit 15 is used to distinguish the L2 table from
+ * the L3 table in the command comId field
+ */
+#define PA_COMID_L2		(0 << 15)
+#define PA_COMID_L3		(1 << 15)
+#define PA_COMID_L_MASK		(1 << 15)
+#define PA_COMID_IDX_MASK	(~(1 << 15))
+
+/* define LUT1 entry types */
+#define PAFRM_COM_ADD_LUT1_STANDARD	0	/* MAC/IP */
+#define PAFRM_COM_ADD_LUT1_SRIO		1	/* SRIO */
+#define PAFRM_COM_ADD_LUT1_CUSTOM	2   /* Custom LUT1 */
+
+struct pa_frm_cmd_add_lut1 {
+
+	u8	index;		/* LUT1 index. */
+	u8	type;		/* Custom or standard */
+	u8	rsvd;		/* reserved for alignment */
+	u8	cust_index;     /* Vaild only if type is custom */
+	
+	union {
+		struct	pa_frm_com_l1_standard	eth_ip;   /* matching information for MAC/IP entry */
+		struct	pa_frm_com_l1_srio	srio;
+		struct	pa_frm_com_l1_custom	custom;
+	} u;
+
+	struct	pa_frm_forward match;	/* Routing information when a match is found */
+  
+	/*
+	 * Routing information when subsequent match fails - a fragmented
+	 * packet orinner route
+	 */
+	struct	pa_frm_forward next_fail;
+};
+
+/* CRC Engine Configuration */
+#define PARAM_CRC_TABLE_SIZE    16
+
+struct pa_frm_config_crc {
+	u8	ctrl_bitmap;			/* Control bit maps as defined below */
+#define PARAM_CRC_SIZE_8         0
+#define PARAM_CRC_SIZE_16        1
+#define PARAM_CRC_SIZE_24        2
+#define PARAM_CRC_SIZE_32        3
+
+#define PARAM_CRC_CTRL_CRC_SIZE_MASK    0x3
+#define PARAM_CRC_CTRL_LEFT_SHIFT       0x0
+#define PARAM_CRC_CTRL_RIGHT_SHIFT      0x4
+#define PARAM_CRC_CTRL_INV_RESULT       0x8
+
+	u8	rsvd1;				/* reserved for alignment */
+	u16	rsvd2;				/* reserved for alignment */
+	u32	init_val;			/* Initial value to use in the CRC calcualtion */
+	u32	crc_tbl[PARAM_CRC_TABLE_SIZE];	/* CRC table */
+};
+
+/* Commands to PA */
+struct pa_frm_command {
+
+	u32	command_result; /* Returned to the host, ignored on entry to the PASS */
+	u8	command;	/* Command value */
+	u8	magic;		/* Magic value */
+	u16	com_id;		/* Used by the host to identify command results */
+	u32	ret_context;	/* Returned in swInfo to identify packet as a command */
+	u16	reply_queue;	/* Specifies the queue number for the message reply. 0xffff to toss the reply */
+	u8	reply_dest;	/* Reply destination (host0, host1, discard are the only valid values) */
+	u8	flow_id;	/* Flow ID used to assign packet at reply */
+	u32	cmd;		/* First word of the command */
+};
+
+struct pa_cmd_next_route {
+	u16	ctrl_bit_field;		/* Routing control information as defined at @ref routeCtrlInfo */	
+	int	dest;			/* Packet destination as defined at @ref pktDest */
+	u8	pkt_type_emac_ctrl;	/*  For destination SRIO, specify the 5-bit packet type toward SRIO 
+                                     For destination EMAC, specify the EMAC control @ref emcOutputCtrlBits to the network */
+	u8	flow_id;	/* For host, SA or SRIO destinations, specifies return free descriptor setup */
+	u16	queue;		/*For host, SA or SRIO destinations, specifies the dest queue */
+	u32	sw_info_0;	/* Placed in SwInfo0 for packets to host or SA */
+	u32	sw_info_1;         /* Placed in SwInfo1 for packets to the SA */
+	u16	multi_route_index; /* Multi-route index. It is valid in the from-network direction only */
+};
+
+struct pa_cmd_crcOp {
+	u16	ctrl_bit_field;    /* CRC operation control information as defined at @ref crcOpCtrlInfo */
+	u16	start_offset;     /* Byte location, from SOP/Protocol Header, where the CRC computation begins 
+                                    if frame type is not specified
+                                    Byte location, from SOP/Protocol header, where the specific frame header begins
+                                    if frame type is specified
+                                    In to-network direction: offset from SOP
+                                    In from-network direction: offset from the current parsed header 
+                                    */
+	u16	len;             /* Number of bytes covered by the CRC computation 
+                                    valid only if pa_CRC_OP_PAYLOAD_LENGTH_IN_HEADER is clear */
+	u16	len_offset;       /* Payload length field offset in the custom header */
+	u16	len_mask;         /* Payload length field mask */
+	u16	len_adjust;       /* Payload length adjustment: valid only if PA_CRC_OP_PAYLOAD_LENGTH_IN_HEADER is set */
+	u16	crc_offset;       /* Offset from SOP/Protocol Header to the CRC field 
+                                    In to-network direction: offset from SOP
+                                    In from-network direction: offset from the current parsed header */
+	u16	frame_yype;       /* Frame type @ref crcFrameTypes, vaild if
+			    PA_CRC_OP_CRC_FRAME_TYPE is set */
+};
+
+/**
+ *  @ingroup palld_api_structures
+ *  @brief  Transmit checksum configuration
+ *
+ *  @details  paTxChksum_t is used in the call to @ref Pa_formatTxRoute or @ref Pa_formatTxCmd to create a tx 
+ *            command header that instructs the packet accelerator sub-system to generate ones' complement
+ *             checksums into network packets. The checksums are typically used for TCP and UDP payload checksums as
+ *            well as IPv4 header checksums. In the case of TCP and UDP payload checksums the psuedo header
+ *            checksum must be pre-calculated and provided, the sub-system does not calculate it.
+ */
+struct pa_tx_chksum {
+	u16	start_offset;   /* Byte location, from SOP, where the checksum calculation begins */
+	u16	length_bytes;   /* Number of bytes covered by the checksum. Must be even */
+	u16	result_offset;  /* Byte offset, from startOffset, to place the resulting checksum */
+	u16	initial_sum;    /* Initial value of the checksum */
+	u16	negative_0;     /* If TRUE, a computed value of 0 is written as -0 */
+};
+
+struct pa_cmd_copy {
+	u16	ctrl_bitfield;    /* Copy operation control information as defined at @ref copyCtrlInfo */
+	u16	src_offset;       /* Offset from the start of current protocol header for the data copy to begin */
+	u16	dest_offset;      /* Offset from the top of the PSInfo for the data to be copied to */
+	u16	num_bytes;        /* Number of bytes to be copied */   
+};
+
+struct pa_patch_info{
+	unsigned int	n_patch_bytes;              /**<  The number of bytes to be patched */
+	unsigned int	total_patch_size;           /**<  The number of patch bytes in the patch command, must be >= to nPatchBytes and a multiple of 4 bytes */
+	unsigned int	offset;                   /**<  Offset from the start of the packet for the patch to begin in the to-network direction 
+                                                 Offset from the start of the current header for the patch to begin in the from-network direction */
+	u16		overwrite;                /**<  If TRUE the patch data replaces existing packet data. If false the data is added */
+	u8		*patch_data;                /**<  Pointer to the patch data */
+};
+
+
+/**
+ *  @ingroup palld_api_structures
+ *  @brief  paPayloadInfo_t defines the packet payload information in the short format.
+ *          It is required by the Security Accelerator sub-system (SASS)
+ *
+ *  @details paPayloadInfo_t defines the packet parsing information in terms of
+ *           payload offset and payload length as described below
+ *  @li      SRTP:      offset to the RTP header; RTP payload length including ICV
+ *  @li      IPSEC AH:  offset to the Outer IP; IP payload length
+ *  @li      IPSEC ESP: offset to the ESP header; ESP papload length including ICV
+ */
+
+struct pa_payload_info  {
+	u16	offset;	/* The offset to where the SA packet parsing starts */
+	u16	len;	/* The total length of the protocal payload to be processed by SA */
+};
+
+struct pa_cmd_multi_route {
+	u16	index;        /*  Multi-route set Index */
+};
+
+/**
+ *   @def  PA_MAX_CMD_SETS
+ *         The maximum number of command sets supported
+ */
+#define PA_MAX_CMD_SETS     8
+
+#define PA_OK					0
+#define PA_ERR_CONFIG				-10
+#define PA_INSUFFICIENT_CMD_BUFFER_SIZE		-11
+#define PA_INVALID_CMD_REPLY_DEST		-12
+
+/**
+ *  @ingroup palld_api_structures
+ *  @brief  Command Set Command
+ *
+ *  @details paCmdSet_t is used to specify the desired PA command set. The command set command 
+ *           instructs the PASS to execute a list of commands after a LUT1 or LUT2 match occurs. 
+ *           It is one of the command which can be embedded within the @ref paRouteInfo_t. 
+ */
+struct pa_cmd_set {
+	u16	index;        /*Command Set Index */
+};
+
+struct pa_cmd_tx_timestamp {
+	u16	dest_queue;	/* Host queue for the tx timestamp reporting packet */
+	u16	flow_id;	/* CPPI flow */
+	u32	sw_info0;	/* 32 bit value returned in the descriptor */
+};
+
+struct pa_cmd_ip_frag {
+	u16	ip_offset;	/* Offset to the IP header. */
+	u16	mtu_size;	/* Size of the maximum transmission unit (>= 68) */
+};
+
+struct pa_cmd_usr_stats {
+	u16	index;		/* User-defined statistics index */
+};
+
+struct pa_cmd_set_usr_stats {
+	u16	set_index;	/* Commad Set Index */
+	u16	stats_index;    /* User-defined statistics index */
+};
+
+struct pa_cmd_info {
+	u16	cmd;			/*Specify the PA command code as defined at @ref paCmdCode */
+	union {
+		struct pa_cmd_next_route route;	/* Specify nextRoute command specific parameters */
+		struct pa_tx_chksum	chksum;	/* Specify Tx Checksum command specific parameters */
+		struct pa_cmd_crcOp     crcOp;    /* Specify CRC operation command specific parameters */
+		struct pa_cmd_copy	copy;     /* Specify Copy command specific parameters */
+		struct pa_patch_info	patch;    /* Specify Patch command specific parameters */
+		struct pa_payload_info	payload;  /* Specify the payload information required by SA */
+		struct pa_cmd_set	cmd_set;   /* Specify Command Set command specific parameters */
+		struct pa_cmd_multi_route m_route;   /* Specify Multi-route command specific parameters */
+		struct pa_cmd_tx_timestamp tx_ts;     /*Specify Report Tx Timestamp command specific parameters */
+		struct pa_cmd_ip_frag	ip_frag;   /* Specify IP fragmentation command specific parameters */
+		struct pa_cmd_usr_stats usr_stats; /* Specify User-defined Statistics command specific parameters */
+		struct pa_cmd_set_usr_stats cmd_set_usr_stats;  
+	} params;
+};
+
+#define PAFRM_ROUTE_
+struct pa_route_info {
+	int	dest;
+	u8	flow_id;
+	u16	queue;
+	int	m_route_index;
+	u32	sw_info_0;
+	u32	sw_info_1;
+	int	custom_type;
+	u8	custom_index;                                    
+	u8	pkt_type_emac_ctrl;
+	u8	route_type;
+	struct pa_cmd_info *pcmd;
+};
+
+struct pa_cmd_reply {
+	int	dest;		/* Packet destination, must be pa_DEST_HOST or PA_DEST_DISCARD, see @ref pktDest */
+	u32	reply_id;	/*  Value placed in swinfo0 in reply packet */
+	u16	queue;		/*  Destination queue for destination PA_DEST_HOST */
+	u8	flow_id;	/*  Flow ID used on command reply from PASS */
+};
+
+/* Exception routing enumeration */
+enum pa_eroutes {
+	EROUTE_LUT1_FAIL = 0,  /* packet failed to match in LUT1 table */
+	EROUTE_VLAN_MAX_DEPTH, /* packet exceeded maximum number of VLAN tags */
+	EROUTE_IP_MAX_DEPTH,   /* packet exceeded maximum number of IP
+				  headers */
+	EROUTE_MPLS_MAX_DEPTH, /* packet exceeded maximum number of MPLS
+				  headers */
+	EROUTE_GRE_MAX_DEPTH,  /* packet exceeded maximum number of GRE
+				  headers */
+	EROUTE_PARSE_FAIL,     /* packet failed to parse */
+	EROUTE_LUT2_FAIL,      /* packet failed to match in LUT2 table */
+	EROUTE_IP_FRAG,        /* IP fragmented packet found in classify2
+				  lookup */
+	EROUTE_IPV6_OPT_FAIL,  /* Packet failed due to unsupported IPV6 option
+				  header */
+	EROUTE_UDP_LITE_FAIL,  /* Udp lite checksum coverage invalid */
+	EROUTE_ROUTE_OPTION,   /* IPv4 strict source route or IPv6 routing
+				  extension header */
+	EROUTE_SYSTEM_FAIL,    /* Unknown system failure - should never
+				  happen */
+	EROUTE_MAC_BROADCAST,  /* MAC broadcast packet */
+	EROUTE_MAC_MULTICAST,  /* MAC multicast packet */
+	EROUTE_IP_BROADCAST,   /* IP broadcast packet */
+	EROUTE_IP_MULTICAST,   /* IP multicast packet */
+	EROUTE_GTPU_MESSAGE_TYPE_1,   /* GTP-U PING Request packet */
+	EROUTE_GTPU_MESSAGE_TYPE_2,   /* GTP-U PING Response packet */
+	EROUTE_GTPU_MESSAGE_TYPE_26,  /* GTP-U Error Indication packet */
+	EROUTE_GTPU_MESSAGE_TYPE_31,  /* GTP-U Supported Header Notification
+					 packet */
+	EROUTE_GTPU_MESSAGE_TYPE_254, /* GTP-U End Markr packet */
+	EROUTE_GTPU_FAIL,             /* packet failed due to GTPU parsing
+					 error or unsupporte dmessage types */
+	EROUTE_PPPOE_FAIL,            /* Packet failed due to PPPoE session
+					 packet parsing error */
+	EROUTE_PPPOE_CTRL,            /* PPPoE session stage non-IP packets */
+	EROUTE_802_1ag,               /* 802.1ag Packet*/
+	EROUTE_IP_FAIL,               /* Packet failed due to invalid IP
+					 header */
+	EROUTE_NAT_T_KEEPALIVE,       /* NAT-T Keep Alive packet where UDP
+					 Length = 9, data = 0xFF */
+	EROUTE_NAT_T_CTRL,            /* NAT-T control packet where UDP Length
+					 > 12 and the first 4 payload bytes are
+					 equal to 0 */
+	EROUTE_NAT_T_DATA,            /* NAT-T IPSEC ESP data packet where UDP
+					 Length > 12 and the first 4 payload
+					 bytes are not equal to 0 */
+	EROUTE_NAT_T_FAIL,            /* Invalid NAT-T packet */
+	EROUTE_GTPU_MATCH_FAIL,       /* Packet failed to match GTPU */
+	EROUTE_N_MAX                  /* Number of error routes */
+};
+
+/* exception route configuration */
+struct pa_frm_com_eroute {
+	/* Exception route vaild bitmap */
+	u32			route_bitmap;
+	/* Array of exception routing information */
+	struct pa_frm_forward	eroute[EROUTE_N_MAX];
+};
+
+/* PA system configuration command */
+struct pa_frm_command_sys_config_pa {
+	u8	cfg_code; /* system configuration code as defined below */
+	u8	rsvd1;
+	u16	rsvd2;    /* reserved for alignment */
+
+	union {
+		/* Exception routes configuration */
+		struct pa_frm_com_eroute eroute;
+	} u;
+};
+
+/* PA system configuration codes */
+#define PAFRM_SYSTEM_CONFIG_CODE_EROUTE         0
+#define PAFRM_SYSTEM_CONFIG_CODE_CUSTOM_LUT1    1
+#define PAFRM_SYSTEM_CONFIG_CODE_CUSTOM_LUT2    2
+#define PAFRM_SYSTEM_CONFIG_CODE_802_1AG        3
+#define PAFRM_SYSTEM_CONFIG_CODE_IPSEC_NAT_T    4
+#define PAFRM_SYSTEM_CONFIG_CODE_GTPU           5
+
+#endif /* __KERNEL__ */
+
+#endif /* KEYSTONE_PA_H */
diff --git a/drivers/net/ethernet/ti/keystone_pa2.c b/drivers/net/ethernet/ti/keystone_pa2.c
new file mode 100644
index 0000000..caca6ff
--- /dev/null
+++ b/drivers/net/ethernet/ti/keystone_pa2.c
@@ -0,0 +1,3169 @@
+/*
+ * Copyright (C) 2014 Texas Instruments Incorporated
+ * Authors: Hao Zhang <hzhang@ti.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation version 2.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#include <linux/io.h>
+#include <linux/clk.h>
+#include <linux/slab.h>
+#include <linux/delay.h>
+#include <linux/types.h>
+#include <linux/module.h>
+#include <linux/delay.h>
+#include <linux/of.h>
+#include <linux/of_device.h>
+#include <linux/of_address.h>
+#include <linux/firmware.h>
+#include <linux/spinlock.h>
+#include <linux/highmem.h>
+#include <linux/interrupt.h>
+#include <linux/dmaengine.h>
+#include <linux/dma-mapping.h>
+#include <linux/scatterlist.h>
+#include <linux/byteorder/generic.h>
+#include <linux/platform_device.h>
+#include <linux/keystone-dma.h>
+#include <linux/phy.h>
+#include <linux/errqueue.h>
+#include <linux/ptp_classify.h>
+#include <net/sctp/checksum.h>
+#include <linux/clocksource.h>
+
+#include "keystone_net.h"
+#include "keystone_pa2.h"
+#include "keystone_pasahost2.h"
+
+/* PA system registers */
+#define PA2_MAILBOX_REGS_OFFSET			0x00000
+#define PA2_RA_BRIDGE_REGS_OFFSET		0x00400
+#define PA2_THREAD_MAPPER_REGS_OFFSET		0x00500
+#define PA2_RA_REGS_OFFSET			0x00800
+#define PA2_STATS_CTL_REGS_OFFSET		0x06000
+#define PA2_QUERY_STATS_REGS_OFFSET		0x08000
+#define PA2_COLLECT_STATS_REGS_OFFSET		0x0c000
+#define PA2_SRAM_OFFSET				0x20000
+#define PA2_SRAM_SIZE				0x08000
+
+#define PA2_MAX_NUM_MAILBOX			16
+#define PA2_STATS_CTL_ENABLE_ALLOC_MASK		BIT(31)
+
+/* PA cluster registers */
+#define PA2_CLUSTER_REGS_OFFSET			0x00400000
+#define PA2_CLUSTER_REGS_SIZE			0x00100000
+#define PA2_CLUSTER_REGS(x)			(PA2_CLUSTER_REGS_OFFSET + \
+						 (PA2_CLUSTER_REGS_SIZE * x))
+#define PA2_CLUSTER_SPLITTER_REGS_OFFSET	0x09800
+#define PA2_CLUSTER_SPLITTER_REGS(x)	(PA2_CLUSTER_SPLITTER_REGS_OFFSET \
+					 + PA2_CLUSTER_REGS(x))
+#define PA2_CLUSTER_SRAM_OFFSET			0x80000
+#define PA2_CLUSTER_SRAM_SIZE			0x10000
+#define PA2_CLUSTER_SRAM_REGS(x)		(PA2_CLUSTER_SRAM_OFFSET \
+						 + PA2_CLUSTER_REGS(x))
+enum {
+	PA2_CLUSTER0 = 0,
+	PA2_CLUSTER1,
+	PA2_CLUSTER2,
+	PA2_CLUSTER3,
+	PA2_CLUSTER4,
+	PA2_CLUSTER5,
+	PA2_CLUSTER6,
+	PA2_CLUSTER7,
+	PA2_CLUSTER8,
+	PA2_NUM_CLUSTERS
+};
+
+#define PA2_CLUSTER_INGRESS0		PA2_CLUSTER0
+#define PA2_CLUSTER_INGRESS1		PA2_CLUSTER1
+#define PA2_CLUSTER_INGRESS2		PA2_CLUSTER2
+#define PA2_CLUSTER_INGRESS3		PA2_CLUSTER3
+#define PA2_CLUSTER_INGRESS4		PA2_CLUSTER4
+#define PA2_CLUSTER_POST		PA2_CLUSTER5
+#define PA2_CLUSTER_EGRESS0		PA2_CLUSTER6
+#define PA2_CLUSTER_EGRESS1		PA2_CLUSTER7
+#define PA2_CLUSTER_EGRESS2		PA2_CLUSTER8
+
+#define PA2_CLUSTER_EF_REC1		PA2_CLUSTER_EGRESS0
+#define PA2_CLUSTER_EF_REC2		PA2_CLUSTER_EGRESS0
+#define PA2_CLUSTER_EF_REC3		PA2_CLUSTER_EGRESS1
+#define PA2_CLUSTER_EF_REC4		PA2_CLUSTER_EGRESS2
+
+/* PA Cluster Splitter
+ * to avoid hardware bug: SOP + EOP + 32 + Control size <= 128
+ * Restrict control size to 96, the SOP should be 896 - 128 */
+#define PA2_SPLITTER_SOP_CTL_ENABLE_MASK		(0x80000000)
+
+#define PA2_CLUSTER_SPLITTER_EOP_CTL		128
+#define PA2_CLUSTER_SPLITTER_EOP_BUF_SIZE(x)	((x == 0) ? 0x4000 : 0x10000)
+#define PA2_CLUSTER_SPLITTER_MOP_BUF_PTR		0xFFFC0000
+#define PA2_CLUSTER_SPLITTER_SOP_CTL \
+	(PA2_SPLITTER_SOP_CTL_ENABLE_MASK | (896 - 128))
+
+
+/* PA Packet Processing Unit registers */
+enum pa2_pdsp {
+	PA2_PDSP0 = 0,
+	PA2_PDSP1,
+	PA2_PDSP2,
+	PA2_PDSP3,
+	PA2_PDSP4,
+	PA2_PDSP5,
+	PA2_PDSP6,
+	PA2_PDSP7,
+	PA2_PDSP8,
+	PA2_PDSP9,
+	PA2_PDSP10,
+	PA2_PDSP11,
+	PA2_PDSP12,
+	PA2_PDSP13,
+	PA2_PDSP14,
+	PA2_NUM_PDSPS
+};
+
+#define PA2_INGRESS0_PDSP0		PA2_PDSP0
+#define PA2_INGRESS0_PDSP1		PA2_PDSP1
+#define PA2_INGRESS1_PDSP0		PA2_PDSP2
+#define PA2_INGRESS1_PDSP1		PA2_PDSP3
+#define PA2_INGRESS2_PDSP0		PA2_PDSP4
+#define PA2_INGRESS3_PDSP0		PA2_PDSP5
+#define PA2_INGRESS4_PDSP0		PA2_PDSP6
+#define PA2_INGRESS4_PDSP1		PA2_PDSP7
+#define PA2_POST_PDSP0			PA2_PDSP8
+#define PA2_POST_PDSP1			PA2_PDSP9
+#define PA2_EGRESS0_PDSP0		PA2_PDSP10
+#define PA2_EGRESS0_PDSP1		PA2_PDSP11
+#define PA2_EGRESS0_PDSP2		PA2_PDSP12
+#define PA2_EGRESS1_PDSP0		PA2_PDSP13
+#define PA2_EGRESS2_PDSP0		PA2_PDSP14
+
+#define PA2_PPU_REGS_OFFSET		0x08000
+#define PA2_PPU_REGS_SIZE		0x10000
+#define PA2_PPU_REGS(x, y)		(PA2_CLUSTER_REGS(x) + \
+					 (PA2_PPU_REGS_OFFSET + \
+					 (PA2_PPU_REGS_SIZE * y)))
+#define PA2_PPU_CTL_STATUS_REGS_OFFSET	0x0000
+#define PA2_PPU_DEBUG_REGS_OFFSET	0x0400
+#define PA2_PPU_CP_TIMER_REGS_OFFSET	0x0800
+#define PA2_PPU_LUT1_REGS_OFFSET	0x1000
+#define PA2_PPU_LUT2_REGS_OFFSET	0x1400
+#define PA2_PPU_PCHECK_REGS_OFFSET	0x1c00
+#define PA2_PPU_IRAM_OFFSET		0x4000
+#define PA2_PPU_IRAM_SIZE		0x3000
+
+struct pa2_cluster_pdsp_map {
+	u32 cluster;
+	u32 pdsp;
+	u32 ver_base_addr;
+};
+
+#define PA2_PDSP_VERSION_SIZE		0x20
+#define PA2_PDSP_VERSION_OFFSET(x, y)	(x + (y * PA2_PDSP_VERSION_SIZE))
+
+/* PDSP/Cluster Mapping */
+static const struct pa2_cluster_pdsp_map pa2_cluster_pdsp_map[PA2_NUM_PDSPS] = {
+	{PA2_CLUSTER_INGRESS0, 0, 0x3f04},
+	{PA2_CLUSTER_INGRESS0, 1, 0x3f04},
+	{PA2_CLUSTER_INGRESS1, 0, 0x3f04},
+	{PA2_CLUSTER_INGRESS1, 1, 0x3f04},
+	{PA2_CLUSTER_INGRESS2, 0, 0x1f04},
+	{PA2_CLUSTER_INGRESS3, 0, 0x1f04},
+	{PA2_CLUSTER_INGRESS4, 0, 0x3f04},
+	{PA2_CLUSTER_INGRESS4, 1, 0x3f04},
+	{PA2_CLUSTER_POST, 0, 0x3f04},
+	{PA2_CLUSTER_POST, 1, 0x3f04},
+	{PA2_CLUSTER_EGRESS0, 0, 0x1f04},
+	{PA2_CLUSTER_EGRESS0, 1, 0x1f04},
+	{PA2_CLUSTER_EGRESS0, 2, 0x1f04},
+	{PA2_CLUSTER_EGRESS1, 0, 0x0f04},
+	{PA2_CLUSTER_EGRESS2, 0, 0x0f04}
+};
+
+#define	PA2_NETIF_FEATURES	(NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM)
+
+#define PSTREAM_ROUTE_INGRESS0	2
+
+#define PA2_PDSP_ALREADY_ACTIVE	0
+#define PA2_PDSP_RESET_RELEASED	1
+#define PA2_PDSP_NO_RESTART	2
+#define PA2_MAX_PDSP_ENABLE_LOOP_COUNT	50000
+
+#define PA2_INVALID_PORT		0xff
+
+#define PA2_STATE_RESET			0  /* Sub-system state reset */
+#define PA2_STATE_ENABLE		1  /* Sub-system state enable  */
+#define PA2_STATE_QUERY			2  /* Query the Sub-system state */
+#define PA2_STATE_INCONSISTENT		3  /* Sub-system is partially enabled */
+#define PA2_STATE_INVALID_REQUEST	4  /* Invalid state command to the
+					      Sub-system */
+#define PA2_STATE_ENABLE_FAILED		5  /* The Sub-system did not respond
+					      after restart */
+
+/* pdsp LUT2 register */
+#define PA2_REG_VAL_PDSP_LUT2_CLR_TABLE_GO	BIT(0)
+
+/* pdsp control status register */
+#define PA2_REG_VAL_PDSP_CTL_DISABLE_PDSP	1
+#define PA2_REG_VAL_PDSP_CTL_RESET_PDSP	        0
+#define PA2_REG_VAL_PDSP_CTL_STATE               BIT(15)
+#define PA2_REG_VAL_PDSP_CTL_ENABLE              BIT(1)
+#define PA2_REG_VAL_PDSP_CTL_SOFT_RESET          BIT(0)
+#define PA2_REG_VAL_PDSP_CTL_ENABLE_PDSP(pcval)	(((pcval) << 16) | \
+						 PA2_REG_VAL_PDSP_CTL_ENABLE | \
+						PA2_REG_VAL_PDSP_CTL_SOFT_RESET)
+
+#define PACKET_DROP	0
+#define PACKET_PARSE	1
+#define PACKET_HST	2
+
+#define NT 32
+
+#define PA2_SGLIST_SIZE	3
+
+static const u32 pa2_ppu_regs_offset[PA2_NUM_PDSPS] = {
+	PA2_PPU_REGS(PA2_CLUSTER_INGRESS0, 0),
+	PA2_PPU_REGS(PA2_CLUSTER_INGRESS0, 1),
+	PA2_PPU_REGS(PA2_CLUSTER_INGRESS1, 0),
+	PA2_PPU_REGS(PA2_CLUSTER_INGRESS1, 1),
+	PA2_PPU_REGS(PA2_CLUSTER_INGRESS2, 0),
+	PA2_PPU_REGS(PA2_CLUSTER_INGRESS3, 0),
+	PA2_PPU_REGS(PA2_CLUSTER_INGRESS4, 0),
+	PA2_PPU_REGS(PA2_CLUSTER_INGRESS4, 1),
+	PA2_PPU_REGS(PA2_CLUSTER_POST, 0),
+	PA2_PPU_REGS(PA2_CLUSTER_POST, 1),
+	PA2_PPU_REGS(PA2_CLUSTER_EGRESS0, 0),
+	PA2_PPU_REGS(PA2_CLUSTER_EGRESS0, 1),
+	PA2_PPU_REGS(PA2_CLUSTER_EGRESS0, 2),
+	PA2_PPU_REGS(PA2_CLUSTER_EGRESS1, 0),
+	PA2_PPU_REGS(PA2_CLUSTER_EGRESS2, 0)
+};
+
+/*
+ * PASS command ID formatting
+ * Bit 14-15 is used to identify the type of table in the command comId field
+ */
+#define PA2_COMID_L2		(0 << 14)
+#define PA2_COMID_L3		(1 << 14)
+#define PA2_COMID_ACL		(2 << 14)
+#define PA2_COMID_FC		(3 << 14)
+
+#define PA2_COMID_L_MASK		(3 << 14)
+#define PA2_COMID_IDX_MASK	(~(3 << 14))
+
+#define PA2_PDSP_CONST_NUM_REG		32
+static const u32 pa2_pdsp_const_reg_map[PA2_NUM_PDSPS][PA2_PDSP_CONST_NUM_REG] \
+		= {
+	/* Ingress0 PDSP0: Classify1 */
+	{
+		0xFFF84000,	/* C0: LUT1 Info */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF000000,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF04000,	/* C6: CDE new packet input region */
+		0xFFF00100,	/* C7: CDE new packet output region */
+		0xFFF00200,	/* C8: CDE held packet region */
+		0xFFF08800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF09000,	/* C10: LUT1 Registers */
+		0xFFF09400,	/* C11: LUT2 Registers */
+		0x00000000,	/* C12: Reserved*/
+		0x00000000,	/* C13: Reserved*/
+		0xFFF80000,	/* C14: PDSP Context */
+		0x00000000,	/* C15: Reserved*/
+		0xFFF80400,	/* C16: IP Traffic Flow */
+		0xFFF80800,	/* C17: IP Reassembly Control Block */
+		0xFFF80C00,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF81000,	/* C21: Classify1 Parsing Call Table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF83F00,	/* C23: PDSP Info */
+		0xFFF81400,	/* C24: Next Route Global address table */
+		0xFF980000,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0x00000000,	/* C26: Reserved*/
+		0x00000000,	/* C27: Reserved*/
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Ingress0 PDSP1: Classify1 */
+	{
+		0xFFF88000,	/* C0: LUT1 Info */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF000010,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF14000,	/* C6: CDE new packet input region */
+		0xFFF10100,	/* C7: CDE new packet output region */
+		0xFFF10200,	/* C8: CDE held packet region */
+		0xFFF18800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF19000,	/* C10: LUT1 Registers */
+		0xFFF19400,	/* C11: LUT2 Registers */
+		0x00000000,	/* C12: Reserved*/
+		0x00000000,	/* C13: Reserved*/
+		0xFFF80100,	/* C14: PDSP Context */
+		0x00000000,	/* C15: Reserved*/
+		0xFFF80400,	/* C16: IP Traffic Flow */
+		0xFFF80800,	/* C17: IP Reassembly Control Block */
+		0xFFF80D00,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF81100,	/* C21: Classify1 Parsing Call Table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF83F20,	/* C23: PDSP Info */
+		0xFFF81400,	/* C24: Next Route Global address table */
+		0xFF980040,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0x00000000,	/* C26: Reserved*/
+		0x00000000,	/* C27: Reserved*/
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+},
+	/* Ingress1 PDSP0: Classify1 */
+	{
+		0xFFF84000,	/* C0: LUT1 Info */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF000020,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF04000,	/* C6: CDE new packet input region */
+		0xFFF00100,	/* C7: CDE new packet output region */
+		0xFFF00200,	/* C8: CDE held packet region */
+		0xFFF08800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF09000,	/* C10: LUT1 Registers */
+		0xFFF09400,	/* C11: LUT2 Registers */
+		0x00000000,	/* C12: Reserved*/
+		0x00000000,	/* C13: Reserved*/
+		0xFFF80000,	/* C14: PDSP Context */
+		0x00000000,	/* C15: Reserved*/
+		0xFFF80400,	/* C16: IP Traffic Flow */
+		0xFFF80800,	/* C17: IP Reassembly Control Block */
+		0xFFF80C00,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF81000,	/* C21: Classify1 Parsing Call Table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF83F00,	/* C23: PDSP Info */
+		0xFFF81400,	/* C24: Next Route Global address table */
+		0xFF980080,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0x00000000,	/* C26: Reserved*/
+		0x00000000,	/* C27: Reserved*/
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Ingress1 PDSP1: Classify1 */
+	{
+		0xFFF88000,	/* C0: LUT1 Info */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF000030,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF14000,	/* C6: CDE new packet input region */
+		0xFFF10100,	/* C7: CDE new packet output region */
+		0xFFF10200,	/* C8: CDE held packet region */
+		0xFFF18800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF19000,	/* C10: LUT1 Registers */
+		0xFFF19400,	/* C11: LUT2 Registers */
+		0x00000000,	/* C12: Reserved*/
+		0x00000000,	/* C13: Reserved*/
+		0xFFF80100,	/* C14: PDSP Context */
+		0x00000000,	/* C15: Reserved*/
+		0xFFF80400,	/* C16: IP Traffic Flow */
+		0xFFF80800,	/* C17: IP Reassembly Control Block */
+		0xFFF80D00,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF81100,	/* C21: Classify1 Parsing Call Table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF83F20,	/* C23: PDSP Info */
+		0xFFF81400,	/* C24: Next Route Global address table */
+		0xFF9800C0,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0x00000000,	/* C26: Reserved*/
+		0x00000000,	/* C27: Reserved*/
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Ingress2 PDSP0: Classify1 */
+	{
+		0xFFF82000,	/* C0: LUT1 Info */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF000040,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF04000,	/* C6: CDE new packet input region */
+		0xFFF00100,	/* C7: CDE new packet output region */
+		0xFFF00200,	/* C8: CDE held packet region */
+		0xFFF08800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF09000,	/* C10: LUT1 Registers */
+		0xFFF09400,	/* C11: LUT2 Registers */
+		0x00000000,	/* C12: Reserved*/
+		0x00000000,	/* C13: Reserved*/
+		0xFFF80000,	/* C14: PDSP Context */
+		0x00000000,	/* C15: Reserved*/
+		0xFFF80400,	/* C16: IP Traffic Flow */
+		0xFFF80800,	/* C17: IP Reassembly Control Block */
+		0xFFF80C00,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF81000,	/* C21: Classify1 Parsing Call Table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF81F00,	/* C23: PDSP Info */
+		0xFFF81400,	/* C24: Next Route Global address table */
+		0xFF980100,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0x00000000,	/* C26: Reserved*/
+		0x00000000,	/* C27: Reserved*/
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Ingress3 PDSP0: Classify1 */
+	{
+		0xFFF82000,	/* C0: LUT1 Info */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF000050,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF04000,	/* C6: CDE new packet input region */
+		0xFFF00100,	/* C7: CDE new packet output region */
+		0xFFF00200,	/* C8: CDE held packet region */
+		0xFFF08800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF09000,	/* C10: LUT1 Registers */
+		0xFFF09400,	/* C11: LUT2 Registers */
+		0x00000000,	/* C12: Reserved*/
+		0x00000000,	/* C13: Reserved*/
+		0xFFF80000,	/* C14: PDSP Context */
+		0x00000000,	/* C15: Reserved*/
+		0xFFF80400,	/* C16: IP Traffic Flow */
+		0xFFF80800,	/* C17: IP Reassembly Control Block */
+		0xFFF80C00,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF81000,	/* C21: Classify1 Parsing Call Table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF81F00,	/* C23: PDSP Info */
+		0xFFF81400,	/* C24: Next Route Global address table */
+		0xFF980140,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0x00000000,	/* C26: Reserved*/
+		0x00000000,	/* C27: Reserved*/
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Ingress4 PDSP0: Classify1 */
+	{
+		0xFFF84000,	/* C0: LUT1 Info */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF000060,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF04000,	/* C6: CDE new packet input region */
+		0xFFF00100,	/* C7: CDE new packet output region */
+		0xFFF00200,	/* C8: CDE held packet region */
+		0xFFF08800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF09000,	/* C10: LUT1 Registers */
+		0xFFF09400,	/* C11: LUT2 Registers */
+		0x00000000,	/* C12: Reserved*/
+		0x00000000,	/* C13: Reserved*/
+		0xFFF80000,	/* C14: PDSP Context */
+		0x00000000,	/* C15: Reserved*/
+		0xFFF80400,	/* C16: IP Traffic Flow */
+		0xFFF80800,	/* C17: IP Reassembly Control Block */
+		0xFFF80C00,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF81000,	/* C21: Classify1 Parsing Call Table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF83F00,	/* C23: PDSP Info */
+		0xFFF81400,	/* C24: Next Route Global address table */
+		0xFF980180,	/* C25: User Stats CB and FIFO
+				   (Global address of Post Cluster) */
+		0x00000000,	/* C26: Reserved*/
+		0x00000000,	/* C27: Reserved*/
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Ingress4 PDSP1: Classify2 */
+	{
+		0xFFF88000,	/* C0: LUT1 Info */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF000070,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF14000,	/* C6: CDE new packet input region */
+		0xFFF10100,	/* C7: CDE new packet output region */
+		0xFFF10200,	/* C8: CDE held packet region */
+		0xFFF18800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF19000,	/* C10: LUT1 Registers */
+		0xFFF19400,	/* C11: LUT2 Registers */
+		0x00000000,	/* C12: Reserved*/
+		0x00000000,	/* C13: Reserved*/
+		0x00000000,	/* C14: Reserved*/
+		0x00000000,	/* C15: Reserved*/
+		0xFFF81800,	/* C16: Custom2 Info */
+		0x00000000,	/* C17: Reserved*/
+		0x00000000,	/* C18: Reserved*/
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF81100,	/* C21: Classify2 Parsing Call Table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF83F20,	/* C23: PDSP Info */
+		0xFFF81400,	/* C24: Next Route Global address table */
+		0xFF9801C0,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0x00000000,	/* C26: Reserved*/
+		0x00000000,	/* C27: Reserved*/
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Post PDSP0: Modifier */
+	{
+		0xFFF80000,	/* C0: User Stats FIFO Base */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF000080,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF04000,	/* C6: CDE new packet input region */
+		0xFFF00100,	/* C7: CDE new packet output region */
+		0xFFF00200,	/* C8: CDE held packet region */
+		0xFFF08800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF09000,	/* C10: LUT1 Registers */
+		0xFFF09400,	/* C11: LUT2 Registers */
+		0x00000000,	/* C12: Reserved*/
+		0x00000000,	/* C13: Reserved*/
+		0x00000000,	/* C14: Reserved*/
+		0xFFF80400,	/* C15: User Stats Control Block */
+		0xFFF80800,	/* C16: User Stats  */
+		0xFFF81000,	/* C17: Command Set Table */
+		0xFFF81800,	/* C18: Multi-route table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF82800,	/* C21: CRC Verify FIFO */
+		0xFFF82900,	/* C22: Split Context FIFO */
+		0xFFF83F00,	/* C23: PDSP Info*/
+		0x00000000,	/* C24: Reserved */
+		0xFFF80200,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0x00000000,	/* C26: Reserved*/
+		0x00000000,	/* C27: Reserved*/
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Post PDSP1: Modifier */
+	{
+		0xFFF80000,	/* C0: User Stats FIFO Base */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF000090,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF14000,	/* C6: CDE new packet input region */
+		0xFFF10100,	/* C7: CDE new packet output region */
+		0xFFF10200,	/* C8: CDE held packet region */
+		0xFFF18800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF19000,	/* C10: LUT1 Registers */
+		0xFFF19400,	/* C11: LUT2 Registers */
+		0x00000000,	/* C12: Reserved*/
+		0x00000000,	/* C13: Reserved*/
+		0x00000000,	/* C14: Reserved*/
+		0xFFF80400,	/* C15: User Stats Control Block */
+		0xFFF80800,	/* C16: User Stats  */
+		0xFFF81000,	/* C17: Command Set Table */
+		0xFFF82000,	/* C18: Multi-route table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF82800,	/* C21: CRC Verify FIFO */
+		0xFFF82900,	/* C22: Split Context FIFO */
+		0xFFF83F20,	/* C23: PDSP Info*/
+		0x00000000,	/* C24: Reserved */
+		0xFFF80240,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0x00000000,	/* C26: Reserved*/
+		0x00000000,	/* C27: Reserved*/
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Egress0 PDSP0: Flow Cache */
+	{
+		0xFFF82000,	/* C0: LUT1 Info */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF0000A0,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF04000,	/* C6: CDE new packet input region */
+		0xFFF00100,	/* C7: CDE new packet output region */
+		0xFFF00200,	/* C8: CDE held packet region */
+		0xFFF08800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF09000,	/* C10: LUT1 Registers */
+		0xFFF09400,	/* C11: LUT2 Registers */
+		0xFFF84000,	/* C12: Egress Flow Record0 */
+		0xFFF88000,	/* C13: Egress Flow Record1 */
+		0xFFF80000,	/* C14: PDSP Context */
+		0xFF980400,	/* C15: User Stats Control Block */
+		0xFF980800,	/* C16: User Stats  */
+		0xFFF81000,	/* C17: Modify Context */
+		0xFFF80200,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF80500,	/* C21: Parse table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF81F00,	/* C23: PDSP Info */
+		0xFFF80A00,	/* C24: Temporary Buffer */
+		0xFF980280,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0xFF020400,	/* C26: Eflow Exception route */
+		0x00000000,	/* C27: Reserved*/
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Egress0 PDSP1: Flow Cache */
+	{
+		0x00000000,	/* C0: Reserved */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF0000B0,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF14000,	/* C6: CDE new packet input region */
+		0xFFF10100,	/* C7: CDE new packet output region */
+		0xFFF10200,	/* C8: CDE held packet region */
+		0xFFF18800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF19000,	/* C10: LUT1 Registers */
+		0xFFF19400,	/* C11: LUT2 Registers */
+		0xFFF84000,	/* C12: Egress Flow Record0 */
+		0xFFF88000,	/* C13: Egress Flow Record1 */
+		0x00000000,	/* C14: Reserved */
+		0xFF980400,	/* C15: User Stats Control Block */
+		0xFF980800,	/* C16: User Stats  */
+		0xFFF81000,	/* C17: Modify Context */
+		0xFFF80300,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF80600,	/* C21: Parse table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF81F20,	/* C23: PDSP Info */
+		0xFFF80A00,	/* C24: Temporary Buffer */
+		0xFF9802C0,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0xFF020400,	/* C26: Eflow Exception route */
+		0xFFF80800,	/* C27: Command Buffer */
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Egress0 PDSP2: Flow Cache */
+	{
+		0x00000000,	/* C0: Reserved */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF0000C0,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF24000,	/* C6: CDE new packet input region */
+		0xFFF20100,	/* C7: CDE new packet output region */
+		0xFFF20200,	/* C8: CDE held packet region */
+		0xFFF28800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF29000,	/* C10: LUT1 Registers */
+		0xFFF29400,	/* C11: LUT2 Registers */
+		0xFFF84000,	/* C12: Egress Flow Record0 */
+		0xFFF88000,	/* C13: Egress Flow Record1 */
+		0x00000000,	/* C14: Reserved */
+		0xFF980400,	/* C15: User Stats Control Block */
+		0xFF980800,	/* C16: User Stats  */
+		0xFFF81000,	/* C17: Modify Context */
+		0xFFF80400,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Exception Routes */
+		0xFFF80700,	/* C21: Parse table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF81F40,	/* C23: PDSP Info */
+		0xFFF80A00,	/* C24: Temporary Buffer */
+		0xFF980300,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0xFF020400,	/* C26: Eflow Exception route */
+		0xFFF80900,	/* C27: Command Buffer */
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Egress1 PDSP0: Flow Cache */
+	{
+		0x00000000,	/* C0: Reserved */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF0000D0,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF04000,	/* C6: CDE new packet input region */
+		0xFFF00100,	/* C7: CDE new packet output region */
+		0xFFF00200,	/* C8: CDE held packet region */
+		0xFFF08800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF09000,	/* C10: LUT1 Registers */
+		0xFFF09400,	/* C11: LUT2 Registers */
+		0xFFF81000,	/* C12: Egress Flow Record2 */
+		0x00000000,	/* C13: Reserved*/
+		0xFFF80000,	/* C14: PDSP Context */
+		0xFF980400,	/* C15: User Stats Control Block */
+		0xFF980800,	/* C16: User Stats  */
+		0xFFF81000,	/* C17: Modify Context */
+		0xFFF80200,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Egress Exception Routes */
+		0xFFF80500,	/* C21: Parse table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF80F00,	/* C23: PDSP Info */
+		0xFFF80A00,	/* C24: Temporary Buffer */
+		0xFF980340,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0xFF020400,	/* C26: Eflow Exception route */
+		0xFFF80800,	/* C27: Command Buffer */
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000	/* C31: Reserved*/
+	},
+	/* Egress2 PDSP0: Flow Cache */
+	{
+		0x00000000,	/* C0: Reserved */
+		0xFFF80000,	/* C1: Loacl SRAM */
+		0xFF020000,	/* C2: Global SRAM */
+		0xFF408800,	/* C3: System Timer (PDSP0 Timer) */
+		0xFF0000E0,	/* C4: MailBox */
+		0x00000000,	/* C5: Reserved*/
+		0xFFF04000,	/* C6: CDE new packet input region */
+		0xFFF00100,	/* C7: CDE new packet output region */
+		0xFFF00200,	/* C8: CDE held packet region */
+		0xFFF08800,	/* C9: PDSP Timer (PDSP specific) */
+		0xFFF09000,	/* C10: LUT1 Registers */
+		0xFFF09400,	/* C11: LUT2 Registers */
+		0xFFF81000,	/* C12: Egress Flow Record3 */
+		0x00000000,	/* C13: Reserved*/
+		0xFFF80000,	/* C14: PDSP Context */
+		0xFF980400,	/* C15: User Stats Control Block */
+		0xFF980800,	/* C16: User Stats  */
+		0xFFF81000,	/* C17: Modify Context */
+		0xFFF80200,	/* C18: IP Protocol Table */
+		0xFF020000,	/* C19: Custom LUT1 and global configuration */
+		0xFF020200,	/* C20: Egress Exception Routes */
+		0xFFF80500,	/* C21: Parse table */
+		0x00000000,	/* C22: Reserved */
+		0xFFF80F00,	/* C23: PDSP Info */
+		0xFFF80A00,	/* C24: Temporary Buffer */
+		0xFF980380,	/* C25: User Stats CB and FIFO
+				   (Global address of Post cluster) */
+		0xFF020400,	/* C26: Eflow Exception route */
+		0xFFF80800,	/* C27: Command Buffer */
+		0xFF020500,	/* C28: Port (Interface-based) configurations */
+		0x00000000,	/* C29: Reserved*/
+		0x00000000,	/* C30: Reserved*/
+		0x00000000 	/* C31: Reserved*/
+	}
+};
+
+/* Offset 0x0000 */
+struct pa2_mailbox_regs {
+	u32 pdsp_mailbox_slot0;
+	u32 pdsp_mailbox_slot1;
+	u32 pdsp_mailbox_slot2;
+	u32 pdsp_mailbox_slot3;
+};
+
+/* Offset 0x0400 */
+struct pa2_ra_bridge_regs {
+	u32 rsvd0;
+	u32 config;
+};
+
+/* Offset 0x0500 */
+struct pa2_thread_mapper_regs {
+	u32 map[16];
+};
+
+/* Offset 0x0400 */
+struct pa2_ra_heap_region_regs {
+	u32 low;
+	u32 high;
+};
+
+struct pa2_ra_flow_override_regs {
+	u32 timeout;
+	u32 critical_err;
+	u32 non_critical_err;
+	u32 rsvd0;
+};
+
+struct pa2_ra_stats_regs {
+	u32 pkts_reasm;
+	u32 total_frags;
+	u32 total_pkts;
+	u32 context_timeout_w_sop;
+	u32 context_timeout_w_sop_bytes;
+	u32 context_timeout_wo_sop;
+	u32 context_timeout_wo_sop_bytes;
+	u32 rsvd0[2];
+	u32 overlap_ipv6_discard;
+	u32 overlap_ipv6_discard_bytes;
+	u32 large_pkts;
+	u32 ipv4_tcp_err;
+	u32 frag_len_err;
+	u32 illegal_ipv4_ihl;
+	u32 illegal_small_pkt;
+	u32 illegal_frag_len;
+	u32 already_completed_discard;
+	u32 already_completed_discard_bytes;
+	u32 rsvd1[5];
+};
+
+/* Offset 0x0800 */
+struct pa2_ra_regs {
+	u32 revision;
+	u32 config;
+	u32 total_contexts;
+	u32 discard_thresh;
+	u32 timeout_val;
+	u32 tick_val;
+	u32 vbusm_config;
+	u32 heap_region_thresh;
+	struct pa2_ra_heap_region_regs heap_region[2];
+	u32 rsvd0[4];
+	struct pa2_ra_flow_override_regs flow_override[2];
+	u32 rsvd1[12];
+	u32 context_forced_timeout;
+	u32 rsvd2[3];
+	struct pa2_ra_stats_regs stats[2];
+};
+
+/* Offset 0x6000 */
+struct pa2_stats_ctl_regs {
+	u32 revision;
+	u32 soft_reset;
+	u32 enable_alloc;
+	u32 counter_update;
+	u32 timer_ctl;
+	u32 timer_load;
+	u32 timer_val;
+	u32 pkt_routing_info;
+};
+
+/* Offset 0x8000 */
+struct pa2_query_stats_regs {
+	u32 stats[0x1000];
+};
+
+/* Offset 0xc000 */
+struct pa2_collect_stats_regs {
+	u32 stats[0x1000];
+};
+
+struct pa2_cl_splitter_regs {
+	u32 revision;
+	u32 rsvd0[3];
+	u32 sop_ctl;
+	u32 eop_ctl;
+	u32 rsvd1[2];
+	u32 mop_buf_size;
+	u32 mop_buf_ptr;
+};
+
+/* PA Cluster registers, offset 0x0040_0000 + (clNum)*0x0010_0000 */
+struct pa2_cluster {
+	/* PA Cluster splitter regs, offset 0x9800 + cluster base */
+	struct pa2_cl_splitter_regs __iomem	*splitter;
+	/* PA SRAM, offset 0x80000 + PPU base */
+	void __iomem				*sram;
+};
+
+
+struct pa2_ppu_ctl_status_regs {
+	u32 control;
+	u32 status;
+	u32 wakeup_enable;
+	u32 cycle_count;
+	u32 stall_count;
+	u32 rsvd[3];
+	u32 const_tbl_blk_index0;
+	u32 const_tbl_blk_index1;
+	u32 const_tbl_prog_pointer0;
+	u32 const_tbl_prog_pointer1;
+};
+
+struct pa2_ppu_debug_regs {
+	u32 igp[32];	/* Internal General Purpose Register */
+	u32 icte[32];	/* Internal Contants Table Entry Register */
+};
+
+struct pa2_ppu_cp_timer_regs {
+	u32 timer_control;
+	u32 timer_load;
+	u32 timer_value;
+	u32 timer_interrupt;
+};
+
+struct pa2_ppu_lut1_regs {
+	u32 revision;
+	u32 control;
+	u32 config;
+};
+
+struct pa2_ppu_lut2_regs {
+	u32 revision;
+	u32 clr_table;
+	u32 rsvd0[2];
+	u32 max_entry_count;
+	u32 curr_entry_count;
+	u32 rsvd1[2];
+	u32 add_data[4];
+	u32 add_del_key[2];
+	u32 add_del_control;
+};
+
+/* PA pcheck recipe control */
+#define PA2_PCHECK_CONTROL_RSHIFT_MASK		(0x00000002u)
+#define PA2_PCHECK_CONTROL_RSHIFT_SHIFT		(0x00000001u)
+#define PA2_PCHECK_CONTROL_RSHIFT_RESETVAL	(0x00000000u)
+
+#define PA2_PCHECK_CONTROL_FINAL_NOT_MASK	(0x00000001u)
+#define PA2_PCHECK_CONTROL_FINAL_NOT_SHIFT	(0x00000000u)
+#define PA2_PCHECK_CONTROL_FINAL_NOT_RESETVAL	(0x00000000u)
+
+#define PA2_PCHECK_CONTROL_RESETVAL		(0x00000000u)
+
+struct pa2_pcheck_recipe_regs {
+	u32 control;
+	u32 table[15];
+};
+
+struct pa2_ppu_pcheck_regs {
+	u32 revision;
+	u32 rsvd0[15];
+	struct pa2_pcheck_recipe_regs recipe[4];
+};
+
+/* PA PPU registers, offset: 0x8000 + (pdspNum)*0x10000 + cluster offset */
+struct pa2_ppu {
+	/* PPU PDSP control/status regs, offset 0x0000 + PPU base */
+	struct pa2_ppu_ctl_status_regs __iomem	*ctl_status;
+	/* PPU PDSP debug regs, offset 0x0400 + PPU base */
+	struct pa2_ppu_debug_regs __iomem	*debug;
+	/* PPU CP Timer regs, offset 0x0800 + PPU base */
+	struct pa2_ppu_cp_timer_regs __iomem	*cp_timer;
+	/* PPU LUT1 regs, offset 0x1000 + PPU base */
+	struct pa2_ppu_lut1_regs __iomem	*lut1;
+	/* PPU LUT2 regs, offset 0x1400 + PPU base */
+	struct pa2_ppu_lut2_regs __iomem	*lut2;
+	/* PPU pcheck regs, offset 0x1c00 + PPU base */
+	struct pa2_ppu_pcheck_regs __iomem	*pcheck;
+	void __iomem				*iram;
+};
+
+#define	CSUM_OFFLOAD_NONE	0
+#define	CSUM_OFFLOAD_HARD	1
+#define	CSUM_OFFLOAD_SOFT	2
+
+#define	PA2_TXHOOK_ORDER	10
+#define	PA2_RXHOOK_ORDER	10
+
+static DEFINE_MUTEX(pa2_modules_lock);
+
+struct pa2_lut_entry {
+	int			index;
+	bool			valid, in_use;
+	struct netcp_addr	*naddr;
+};
+
+struct pa2_intf {
+	struct pa2_device		*pa_device;
+	struct net_device		*net_device;
+	struct netcp_tx_pipe		 tx_pipe;
+	unsigned			 data_flow_num;
+	unsigned			 data_queue_num;
+	u32				 saved_ss_state;
+	char				 tx_chan_name[24];
+};
+
+struct pa2_device {
+	struct netcp_device		*netcp_device;
+	struct device			*dev;
+	struct clk			*clk;
+	struct dma_chan			*pdsp0_tx_channel;
+	struct dma_chan			*rx_channel;
+	const char			*rx_chan_name;
+	unsigned			 cmd_flow_num;
+	unsigned			 cmd_queue_num;
+
+	struct pa2_mailbox_regs __iomem		*reg_mailbox;
+	struct pa2_ra_bridge_regs __iomem	*reg_ra_bridge;
+	struct pa2_thread_mapper_regs __iomem	*reg_thread_mapper;
+	struct pa2_ra_regs __iomem		*reg_ra;
+	struct pa2_stats_ctl_regs   __iomem	*reg_stats_ctl;
+	struct pa2_query_stats_regs   __iomem	*reg_query_stats;
+	struct pa2_collect_stats_regs   __iomem	*reg_collect_stats;
+	void __iomem				*pa_sram;
+
+	struct pa2_cluster		cluster[PA2_NUM_CLUSTERS];
+	struct pa2_ppu			ppu[PA2_NUM_PDSPS];
+	u8				*mc_list;
+	u8				 addr_count;
+	struct tasklet_struct		 task;
+	spinlock_t			 lock;
+
+	u32				 tx_cmd_queue_depth;
+	u32				 tx_data_queue_depth;
+	u32				 rx_pool_depth;
+	u32				 rx_buffer_size;
+	u32				 csum_offload;
+	u32				 txhook_order;
+	u32				 txhook_softcsum;
+	u32				 rxhook_order;
+	u32				 multi_if;
+	u32				 mark_mcast_match[2];
+	u32				 inuse_if_count;
+	u32				 lut_inuse_count;
+	struct pa2_lut_entry		 *lut;
+	u32				 lut_size;
+
+	const char			*pdsp_fw[PA2_NUM_PDSPS];
+};
+
+#define pa2_from_module(data)	container_of(data, struct pa2_device, module)
+#define pa2_to_module(pa)	(&(pa)->module)
+
+struct pa2_packet {
+	struct scatterlist		 sg[PA2_SGLIST_SIZE];
+	int				 sg_ents;
+	struct pa2_device		*priv;
+	struct dma_chan			*chan;
+	struct dma_async_tx_descriptor	*desc;
+	dma_cookie_t			 cookie;
+	u32				 epib[4];
+	u32				 psdata[6];
+	struct completion		 complete;
+	void				*data;
+};
+
+#define pa2_cond_unmap(field)				\
+	do {						\
+		if (field) {				\
+			devm_iounmap(dev, field);	\
+			field = NULL;			\
+		}					\
+	} while (0)
+
+static void pdsp_fw_put(u32 *dest, const u32 *src, u32 wc)
+{
+	int i;
+
+	for (i = 0; i < wc; i++)
+		*dest++ = be32_to_cpu(*src++);
+}
+
+static inline void swizFwd(struct pa2_frm_forward *fwd)
+{
+	fwd->forward_type	= fwd->forward_type;
+	fwd->flow_id		= fwd->flow_id;
+	fwd->queue		= cpu_to_be16(fwd->queue);
+
+	if (fwd->forward_type == PA2FRM_FORWARD_TYPE_HOST) {
+		fwd->u.host.context      = cpu_to_be32(fwd->u.host.context);
+		fwd->u.host.ctrl_bitmap  = fwd->u.host.ctrl_bitmap;
+		fwd->u.host.multi_idx    = fwd->u.host.multi_idx;
+		fwd->u.host.pa_pdsp_router = fwd->u.host.pa_pdsp_router;
+	} else if (fwd->forward_type == PA2FRM_FORWARD_TYPE_SA) {
+		fwd->u.sa.sw_info_0 = cpu_to_be32(fwd->u.sa.sw_info_0);
+		fwd->u.sa.sw_info_1 = cpu_to_be32(fwd->u.sa.sw_info_1);
+	} else if (fwd->forward_type == PA2FRM_FORWARD_TYPE_SRIO) {
+		fwd->u.srio.ps_info0 = cpu_to_be32(fwd->u.srio.ps_info0);
+		fwd->u.srio.ps_info1 = cpu_to_be32(fwd->u.srio.ps_info1);
+		fwd->u.srio.pkt_type = fwd->u.srio.pkt_type;
+	} else if (fwd->forward_type == PA2FRM_FORWARD_TYPE_ETH) {
+		fwd->u.eth.ps_flags	= fwd->u.eth.ps_flags;
+	} else if (fwd->forward_type == PA2FRM_FORWARD_TYPE_PA) {
+		fwd->u.pa.pa_dest	= fwd->u.pa.pa_dest;
+		fwd->u.pa.custom_type	= fwd->u.pa.custom_type;
+		fwd->u.pa.custom_idx	= fwd->u.pa.custom_idx;
+		fwd->u.pa.flags		= fwd->u.pa.flags;
+	}
+}
+
+static inline void swizFcmd(struct pa2_frm_command *fcmd)
+{
+	fcmd->status		=  fcmd->status;
+	fcmd->pdsp_index	=  fcmd->pdsp_index;
+	fcmd->command_result	=  cpu_to_be16(fcmd->command_result);
+	fcmd->com_id		=  cpu_to_be16(fcmd->com_id);
+	fcmd->command		=  fcmd->command;
+	fcmd->magic		=  fcmd->magic;
+	fcmd->ret_context	=  cpu_to_be32(fcmd->ret_context);
+	fcmd->reply_queue	=  cpu_to_be16(fcmd->reply_queue);
+	fcmd->reply_dest	=  fcmd->reply_dest;
+	fcmd->flow_id		=  fcmd->flow_id;
+}
+
+static inline void swizAl1(struct pa2_frm_cmd_add_lut1 *al1)
+{
+	al1->index		=  cpu_to_be16(al1->index);
+	al1->type		=  al1->type;
+	al1->cust_index		=  al1->cust_index;
+	al1->vlink_num		=  cpu_to_be16(al1->vlink_num);
+	al1->stats_index	=  cpu_to_be16(al1->stats_index);
+
+	if (al1->type == PA2FRM_COM_ADD_LUT1_STANDARD) {
+		al1->u.mac.etype	= cpu_to_be16(al1->u.mac.etype);
+		al1->u.mac.session_id	= cpu_to_be16(al1->u.mac.session_id);
+		al1->u.mac.mpls		= cpu_to_be32(al1->u.mac.mpls);
+		al1->u.mac.pkt_flags	= al1->u.mac.pkt_flags;
+		al1->u.mac.dst_mac5	= al1->u.mac.dst_mac5;
+		al1->u.mac.vlan_id1	= cpu_to_be16(al1->u.mac.vlan_id1);
+		al1->u.mac.vlan_id2	= cpu_to_be16(al1->u.mac.vlan_id2);
+		al1->u.mac.pkt_type	= al1->u.mac.pkt_type;
+		al1->u.mac.in_port	= al1->u.mac.in_port;
+		al1->u.mac.vlan_pri1	= cpu_to_be16(al1->u.mac.vlan_pri1);
+		al1->u.mac.vlan_pri2	= cpu_to_be16(al1->u.mac.vlan_pri2);
+		al1->u.mac.src_vc	= cpu_to_be16(al1->u.mac.src_vc);
+	} else if (al1->type == PA2FRM_COM_ADD_LUT1_SRIO) {
+		al1->u.srio.next_hdr_offset =
+			cpu_to_be16(al1->u.srio.next_hdr_offset);
+		al1->u.srio.next_hdr	= al1->u.srio.next_hdr;
+		al1->u.srio.pkt_flags	= al1->u.srio.pkt_flags;
+		al1->u.srio.type_param2	= al1->u.srio.type_param2;
+		al1->u.srio.type_param1	= cpu_to_be16(al1->u.srio.type_param1);
+		al1->u.srio.src_id	= cpu_to_be16(al1->u.srio.src_id);
+		al1->u.srio.dest_id	= cpu_to_be16(al1->u.srio.dest_id);
+		al1->u.srio.pkt_type	= al1->u.srio.pkt_type;
+		al1->u.srio.cc		= al1->u.srio.cc;
+		al1->u.srio.pri		= cpu_to_be16(al1->u.srio.pri);
+		al1->u.srio.src_vc	= cpu_to_be16(al1->u.srio.src_vc);
+	} else {
+		al1->u.custom.pkt_type	=  al1->u.custom.pkt_type;
+		al1->u.custom.src_vc	=  cpu_to_be16(al1->u.custom.src_vc);
+	}
+
+	al1->range1_hi	=  cpu_to_be16(al1->range1_hi);
+	al1->range0_hi	=  cpu_to_be16(al1->range0_hi);
+	al1->cbwords0	=  cpu_to_be32(al1->cbwords0);
+	al1->cbwords1	=  cpu_to_be32(al1->cbwords1);
+	al1->bit_mask	=  cpu_to_be16(al1->bit_mask);
+	al1->priority	=  cpu_to_be16(al1->priority);
+
+	swizFwd(&(al1->match));
+	swizFwd(&(al1->next_fail));
+}
+
+static int pa2_conv_fc_routing_info(struct pa2_frm_forward *fwd_info,
+				   struct pa2_ef_op_info *ef_info)
+{
+	if (ef_info == NULL)
+		return PA2_ERR_CONFIG;
+
+	fwd_info->forward_type = PA2FRM_FORWARD_TYPE_EFLOW;
+
+	if (ef_info->ctrl_flags & PA2_EF_OP_CONTROL_FLAG_FC_LOOKUP)
+		/* Trigger Flow cache operation */
+		fwd_info->u.ef.ctrl_flags = PA2FRM_EF_CTRL_FC_LOOKUP;
+	else {
+		/* Use Egress Flow records directly */
+		fwd_info->u.ef.valid_bitmap  = (u8)ef_info->valid_bitmap;
+		fwd_info->u.ef.lvl1_rec_idx = (u8)ef_info->lvl1_index;
+		fwd_info->u.ef.lvl2_rec_idx = (u8)ef_info->lvl2_index;
+		fwd_info->u.ef.lvl3_rec_idx = (u8)ef_info->lvl3_index;
+		fwd_info->u.ef.lvl4_rec_idx = (u8)ef_info->lvl4_index;
+	}
+
+	return 0;
+}
+
+static int pa2_conv_routing_info(struct pa2_frm_forward *fwd_info,
+			 struct pa2_route_info2 *route_info,
+			 int cmd_dest, u16 fail_route,
+			 u16 dest_pdsp, u8 pa_flags)
+{
+	u8 *pcmd = fwd_info->u.host.cmd;
+	u8 ps_flags = 0;
+	u32 no_fcmd = 0;
+	fwd_info->flow_id = route_info->flow_id;
+	fwd_info->queue   = route_info->queue;
+
+	if ((route_info->dest == PA2_DEST_HOST) ||
+	    (route_info->dest == PA2_DEST_EMAC)) {
+		if (route_info->valid_bitmap & \
+		    PA2_ROUTE_INFO_VALID_PKTTYPE_EMAC) {
+			ps_flags = (route_info->pkt_type_emac_ctrl & \
+				    PA2_EMAC_CTRL_CRC_DISABLE) ? \
+				    PA2FRM_ETH_PS_FLAGS_DISABLE_CRC : 0;
+			ps_flags |= ((route_info->pkt_type_emac_ctrl & \
+				      PA2_EMAC_CTRL_PORT_MASK) << \
+				     PA2FRM_ETH_PS_FLAGS_PORT_SHIFT);
+		}
+	}
+	if (route_info->dest == PA2_DEST_HOST) {
+		fwd_info->forward_type   = PA2FRM_FORWARD_TYPE_HOST;
+		fwd_info->u.host.context = route_info->sw_info_0;
+		fwd_info->u.host.ps_flags = ps_flags;
+
+		if (route_info->valid_bitmap & \
+		    PA2_ROUTE_INFO_VALID_PRIORITY_TYPE) {
+			if (route_info->priority_type == \
+				PA2_ROUTE_PRIORITY_VLAN)
+				fwd_info->u.host.ctrl_bitmap |=
+					PA2FRM_ROUTING_PRIORITY_VLAN_ENABLE;
+			else if (route_info->priority_type == \
+				PA2_ROUTE_PRIORITY_DSCP)
+				fwd_info->u.host.ctrl_bitmap |=
+					PA2FRM_ROUTING_PRIORITY_DSCP_ENABLE;
+			else if (route_info->priority_type == PA2_ROUTE_INTF)
+				fwd_info->u.host.ctrl_bitmap |=
+					PA2FRM_ROUTING_IF_DEST_SELECT_ENABLE;
+			else if (route_info->priority_type == \
+				 PA2_ROUTE_INTF_W_FLOW)
+				fwd_info->u.host.ctrl_bitmap |=
+					(PA2FRM_ROUTING_IF_DEST_SELECT_ENABLE |\
+					 PA2FRM_ROUTING_FLOW_IF_BASE_ENABLE);
+			else
+				return PA2_ERR_CONFIG;
+		}
+
+		if (route_info->valid_bitmap & \
+		    PA2_ROUTE_INFO_VALID_MROUTEINDEX) {
+			if (route_info->m_route_index >= 0) {
+				if (route_info->m_route_index >= \
+					PA2_MAX_MULTI_ROUTE_SETS)
+					return PA2_ERR_CONFIG;
+				fwd_info->u.host.ctrl_bitmap |=
+					PA2FRM_MULTIROUTE_ENABLE;
+				fwd_info->u.host.multi_idx =
+					route_info->m_route_index;
+				fwd_info->u.host.pa_pdsp_router	=
+					PA2FRM_DEST_PA_M_0;
+			}
+		}
+	} else if (route_info->dest == PA2_DEST_DISCARD)	{
+		fwd_info->forward_type = PA2FRM_FORWARD_TYPE_DISCARD;
+	} else if (route_info->dest == PA2_DEST_EMAC) {
+		fwd_info->forward_type = PA2FRM_FORWARD_TYPE_ETH;
+		fwd_info->u.eth.ps_flags = ps_flags;
+	} else if (fail_route) {
+		return PA2_ERR_CONFIG;
+
+	} else if (((route_info->dest == PA2_DEST_CONTINUE_PARSE_LUT1) &&
+		    (route_info->custom_type != PA2_CUSTOM_TYPE_LUT2)) ||
+		   ((route_info->dest == PA2_DEST_CONTINUE_PARSE_LUT2) &&
+		    (route_info->custom_type != PA2_CUSTOM_TYPE_LUT1))) {
+
+		/* Custom Error check */
+		if (((route_info->custom_type == PA2_CUSTOM_TYPE_LUT1) &&
+		     (route_info->custom_index >= PA2_MAX_CUSTOM_TYPES_LUT1)) ||
+		    ((route_info->custom_type == PA2_CUSTOM_TYPE_LUT2) &&
+		     (route_info->custom_index >= PA2_MAX_CUSTOM_TYPES_LUT2)))
+			return PA2_ERR_CONFIG;
+
+		fwd_info->forward_type = PA2FRM_FORWARD_TYPE_PA;
+		fwd_info->u.pa.custom_type = (u8)route_info->custom_type;
+		fwd_info->u.pa.custom_idx  = route_info->custom_index;
+		fwd_info->u.pa.flags  = pa_flags;
+
+		if (route_info->dest == PA2_DEST_CONTINUE_PARSE_LUT2) {
+			fwd_info->u.pa.pa_dest = PA2FRM_DEST_INGRESS4;
+		} else {
+			/*
+			 * cmd_dest is provided by calling function
+			 * There is no need to check error case
+			 */
+			if (cmd_dest == PA2_CMD_TX_DEST_0)
+				/* Layer 2 entry */
+				fwd_info->u.pa.pa_dest = PA2FRM_DEST_INGRESS1;
+			else if (cmd_dest == PA2_CMD_TX_DEST_1) {
+				fwd_info->u.pa.pa_dest = (dest_pdsp == 0) ? \
+				  PA2FRM_DEST_INGRESS1 : PA2FRM_DEST_INGRESS3;
+				if (route_info->custom_type == \
+						PA2_CUSTOM_TYPE_LUT1)
+					fwd_info->u.pa.pa_dest =
+						PA2FRM_DEST_INGRESS3;
+			} else if (cmd_dest == PA2_CMD_TX_DEST_3)
+				fwd_info->u.pa.pa_dest = PA2FRM_DEST_INGRESS4;
+			else
+				return PA2_ERR_CONFIG;
+		}
+		no_fcmd = 1;
+	} else if (route_info->dest == PA2_DEST_CASCADED_FORWARDING_LUT1) {
+		fwd_info->forward_type = PA2FRM_FORWARD_TYPE_PA;
+		fwd_info->u.pa.pa_dest = (cmd_dest == PA2_CMD_TX_DEST_0) ? \
+				PA2FRM_DEST_INGRESS1 : PA2FRM_DEST_INGRESS4;
+		fwd_info->u.pa.flags   |= PA2FRM_CASCADED_FORWARDING;
+		no_fcmd = 1;
+	} else if (route_info->dest == PA2_DEST_SASS) {
+		fwd_info->forward_type = PA2FRM_FORWARD_TYPE_SA;
+		fwd_info->u.sa.sw_info_0 = route_info->sw_info_0;
+		fwd_info->u.sa.sw_info_1 = route_info->sw_info_1;
+	} else if (route_info->dest == PA2_DEST_SASS_LOC_DMA) {
+		fwd_info->forward_type	= PA2FRM_FORWARD_TYPE_SA | \
+					  PA2FRM_FORWARD_CONTROL_USE_LOC_DMA;
+		fwd_info->u.sa.sw_info_0 = route_info->sw_info_0;
+		fwd_info->u.sa.sw_info_1 = route_info->sw_info_1;
+	} else if ((route_info->dest == PA2_DEST_RES_1) || \
+		   (route_info->dest == PA2_DEST_RES_2)) {
+		fwd_info->forward_type	= PA2FRM_FORWARD_TYPE_SA_DIRECT;
+		fwd_info->flow_id = (route_info->dest == PA2_DEST_RES_1) ? \
+					  PA2FRM_DEST_ACE0 : PA2FRM_DEST_ACE1;
+		fwd_info->u.sa.sw_info_0 = route_info->sw_info_0;
+		fwd_info->u.sa.sw_info_1 = route_info->sw_info_1;
+	} else if (route_info->dest == PA2_DEST_SRIO) {
+		fwd_info->forward_type = PA2FRM_FORWARD_TYPE_SRIO;
+		fwd_info->u.srio.ps_info0 = route_info->sw_info_0;
+		fwd_info->u.srio.ps_info1 = route_info->sw_info_1;
+		fwd_info->u.srio.pkt_type = route_info->pkt_type_emac_ctrl;
+		pcmd = NULL;
+	} else if (route_info->dest == PA2_DEST_EFLOW) {
+		return pa2_conv_fc_routing_info(fwd_info,
+						route_info->ef_op);
+	} else {
+		return PA2_ERR_CONFIG;
+	}
+
+	if (pcmd && (route_info->valid_bitmap & PA2_ROUTE_INFO_VALID_PCMD)) {
+		struct pa2_cmd_info *pacmd = route_info->pcmd;
+		struct pa2_patch_info *patch_info;
+		struct pa2_cmd_set *cmd_set;
+		struct pa2_cmd_usr_stats *usr_stats;
+		struct pa2_cmd_set_usr_stats *cmd_set_usr_stats;
+
+		switch (pacmd->cmd) {
+		case PA2_CMD_PATCH_DATA:
+			patch_info = &pacmd->params.patch;
+			if ((patch_info->n_patch_bytes > 2) || \
+				(!(patch_info->ctrl_bit_field & \
+				PA2_PATCH_OP_INSERT)) || \
+				(patch_info->patch_data == NULL))
+				return PA2_ERR_CONFIG;
+
+			pcmd[0] = PA2FRM_RX_CMD_PATCH_DATA;
+			pcmd[1] = patch_info->n_patch_bytes;
+			pcmd[2] = patch_info->patch_data[0];
+			pcmd[3] = patch_info->patch_data[1];
+			break;
+
+		case PA2_CMD_CMDSET:
+			cmd_set = &pacmd->params.cmd_set;
+			if (no_fcmd || (cmd_set->index >= PA2_MAX_CMD_SETS))
+				return PA2_ERR_CONFIG;
+
+			pcmd[0] = PA2FRM_RX_CMD_CMDSET;
+			pcmd[1] = (u8)cmd_set->index;
+			break;
+
+		case PA2_CMD_USR_STATS:
+			usr_stats = &pacmd->params.usr_stats;
+			if (usr_stats->index >= 512)
+				return PA2_ERR_CONFIG;
+
+			pcmd[0] = PA2FRM_RX_CMD_USR_STATS;
+			pcmd[1] = 4;
+			pcmd[2] = usr_stats->index >> 8;
+			pcmd[3] = usr_stats->index & 0xFF;
+			break;
+
+		case PA2_CMD_CMDSET_AND_USR_STATS:
+			cmd_set_usr_stats = &pacmd->params.cmd_set_usr_stats;
+			if ((no_fcmd) ||
+			   (cmd_set_usr_stats->set_index >= PA2_MAX_CMD_SETS) ||
+			   (cmd_set_usr_stats->stats_index >= 512))
+				return PA2_ERR_CONFIG;
+
+			pcmd[0] = PA2FRM_RX_CMD_CMDSET_USR_STATS;
+			pcmd[1] = (u8)cmd_set_usr_stats->set_index;
+			pcmd[2] = cmd_set_usr_stats->stats_index >> 8;
+			pcmd[3] = cmd_set_usr_stats->stats_index & 0xFF;
+			break;
+
+		default:
+			return PA2_ERR_CONFIG;
+		}
+	}
+	return PA2_OK;
+}
+
+static void pa2_get_version(struct pa2_device *pa_dev)
+{
+	u32 version, i;
+
+	for (i = 0; i < PA2_NUM_PDSPS; i++) {
+		u32 cluster = pa2_cluster_pdsp_map[i].cluster;
+		void __iomem *sram = pa_dev->cluster[cluster].sram;
+		u32 base = pa2_cluster_pdsp_map[i].ver_base_addr;
+		u32 pdsp = pa2_cluster_pdsp_map[i].pdsp;
+		version = __raw_readl(sram +
+				PA2_PDSP_VERSION_OFFSET(base, pdsp));
+
+		dev_info(pa_dev->dev,
+			 "Packet Accelerator PDSP %d Firmware Version 0x%08x\n",
+			 i, version);
+	}
+}
+
+static int pa2_pdsp_run(struct pa2_device *pa_dev, int pdsp)
+{
+	struct pa2_ppu_ctl_status_regs __iomem *ctrl_reg =
+						pa_dev->ppu[pdsp].ctl_status;
+	struct pa2_mailbox_regs __iomem *mailbox_reg =
+						&pa_dev->reg_mailbox[pdsp];
+	u32 i, v;
+
+	/* Check for enabled PDSP */
+	v = __raw_readl(&ctrl_reg->control);
+	if ((v & PA2_REG_VAL_PDSP_CTL_ENABLE) ==
+	    PA2_REG_VAL_PDSP_CTL_ENABLE) {
+		/* Already enabled */
+		return PA2_PDSP_ALREADY_ACTIVE;
+	}
+
+	/* Clear the mailbox */
+	__raw_writel(0, &mailbox_reg->pdsp_mailbox_slot0);
+
+	/* Set PDSP PC to 0, enable the PDSP */
+	__raw_writel(PA2_REG_VAL_PDSP_CTL_ENABLE |
+		     PA2_REG_VAL_PDSP_CTL_SOFT_RESET,
+		     &ctrl_reg->control);
+
+	/* Wait for the mailbox to become non-zero */
+	for (i = 0; i < PA2_MAX_PDSP_ENABLE_LOOP_COUNT; i++) {
+		v = __raw_readl(&mailbox_reg->pdsp_mailbox_slot0);
+		if (v != 0)
+			return PA2_PDSP_RESET_RELEASED;
+	}
+
+	return PA2_PDSP_NO_RESTART;
+}
+
+static int keystone_pa2_reset_control(struct pa2_device *pa_dev, int new_state)
+{
+	int i, res;
+	int ret;
+
+	if (new_state == PA2_STATE_RESET) {
+		/* Put each of the PDSPs into reset (PC = 0) and reset timers */
+		for (i = 0; i < PA2_NUM_PDSPS; i++)  {
+			__raw_writel(0, &pa_dev->ppu[i].ctl_status->control);
+			__raw_writel(0,
+				     &pa_dev->ppu[i].cp_timer->timer_control);
+		}
+
+		/* Reset LUT2 */
+		__raw_writel(PA2_REG_VAL_PDSP_LUT2_CLR_TABLE_GO,
+			     &pa_dev->ppu[PA2_INGRESS4_PDSP1].lut2->clr_table);
+		ret = PA2_STATE_RESET;
+	} else if (new_state == PA2_STATE_ENABLE) {
+		ret = PA2_STATE_ENABLE;
+
+		/*
+		 * Do nothing if a pdsp is already out of reset.
+		 * If any PDSPs are out of reset
+		 * a global init is not performed
+		 */
+		for (i = 0; i < PA2_NUM_PDSPS; i++) {
+			res = pa2_pdsp_run(pa_dev, i);
+
+			if (res == PA2_PDSP_NO_RESTART)
+				ret = PA2_STATE_ENABLE_FAILED;
+		}
+
+		for (i = 0; i < PA2_NUM_PDSPS; i++) {
+			struct pa2_mailbox_regs __iomem *mbox_reg =
+					&pa_dev->reg_mailbox[i];
+			__raw_writel(0, &mbox_reg->pdsp_mailbox_slot0);
+		}
+	} else
+		ret = PA2_STATE_INVALID_REQUEST;
+
+	return ret;
+}
+
+static int keystone_pa2_set_firmware(struct pa2_device *pa_dev,
+			     int pdsp, const unsigned int *buffer, int len)
+{
+	struct pa2_ppu_debug_regs __iomem *debug_reg = pa_dev->ppu[pdsp].debug;
+	u32 i;
+
+	if ((pdsp < 0) || (pdsp >= PA2_NUM_PDSPS))
+		return -EINVAL;
+
+	if (len > PA2_PPU_IRAM_SIZE)
+		return -ENODEV;
+
+	pdsp_fw_put((u32 *)(pa_dev->ppu[pdsp].iram), buffer,
+		    len >> 2);
+
+	for (i = 0; i < PA2_PDSP_CONST_NUM_REG; i++)
+		__raw_writel(pa2_pdsp_const_reg_map[pdsp][i],
+		     &debug_reg->icte[i]);
+	return 0;
+}
+
+static struct pa2_packet *pa2_alloc_packet(struct pa2_device *pa_dev,
+					 unsigned cmd_size,
+					 struct dma_chan *dma_chan)
+{
+	struct pa2_packet *p_info;
+
+	p_info = kzalloc(sizeof(*p_info) + cmd_size, GFP_ATOMIC);
+	if (!p_info)
+		return NULL;
+
+	p_info->priv = pa_dev;
+	p_info->data = p_info + 1;
+	p_info->chan = dma_chan;
+
+	sg_init_table(p_info->sg, PA2_SGLIST_SIZE);
+	sg_set_buf(&p_info->sg[0], p_info->epib, sizeof(p_info->epib));
+	sg_set_buf(&p_info->sg[1], p_info->psdata, sizeof(p_info->psdata));
+	sg_set_buf(&p_info->sg[2], p_info->data, cmd_size);
+
+	return p_info;
+}
+
+static void pa2_tx_dma_callback(void *data)
+{
+	struct pa2_packet *p_info = data;
+	struct pa2_device *pa_dev = p_info->priv;
+	enum dma_status status;
+	unsigned long irqsave;
+	dma_cookie_t cookie;
+
+	spin_lock_irqsave(&pa_dev->lock, irqsave);
+	cookie = p_info->cookie;
+	spin_unlock_irqrestore(&pa_dev->lock, irqsave);
+
+	if (unlikely(cookie <= 0))
+		WARN(1, "invalid dma cookie == %d", cookie);
+	else {
+		status = dma_async_is_tx_complete(p_info->chan,
+						  cookie, NULL, NULL);
+		WARN((status != DMA_SUCCESS),
+				"dma completion failure, status == %d", status);
+	}
+
+	dma_unmap_sg(pa_dev->dev, &p_info->sg[2], 1, DMA_TO_DEVICE);
+
+	p_info->desc = NULL;
+
+	kfree(p_info);
+}
+
+static int pa2_submit_tx_packet(struct pa2_packet *p_info)
+{
+	unsigned flags = DMA_HAS_EPIB | DMA_HAS_PSINFO;
+	struct pa2_device *pa_dev = p_info->priv;
+	unsigned long irqsave;
+	int ret;
+
+	ret = dma_map_sg(pa_dev->dev, &p_info->sg[2], 1, DMA_TO_DEVICE);
+	if (ret < 0)
+		return ret;
+
+	p_info->desc = dmaengine_prep_slave_sg(p_info->chan, p_info->sg, 3,
+					       DMA_TO_DEVICE, flags);
+	if (IS_ERR_OR_NULL(p_info->desc)) {
+		dma_unmap_sg(pa_dev->dev, &p_info->sg[2], 1, DMA_TO_DEVICE);
+		return PTR_ERR(p_info->desc);
+	}
+
+	p_info->desc->callback = pa2_tx_dma_callback;
+	p_info->desc->callback_param = p_info;
+
+	spin_lock_irqsave(&pa_dev->lock, irqsave);
+	p_info->cookie = dmaengine_submit(p_info->desc);
+	spin_unlock_irqrestore(&pa_dev->lock, irqsave);
+
+	return dma_submit_error(p_info->cookie) ? p_info->cookie : 0;
+}
+
+#define	PA2_CONTEXT_MASK	0xffff0000
+#define	PA2_CONTEXT_CONFIG	0xdead0000
+
+static void pa2_rx_complete(void *param)
+{
+	struct pa2_packet *p_info = param;
+	struct pa2_device *pa_dev = p_info->priv;
+	struct pa2_frm_command *fcmd;
+
+	dma_unmap_sg(pa_dev->dev, &p_info->sg[2], 1, DMA_FROM_DEVICE);
+
+	switch (p_info->epib[1] & PA2_CONTEXT_MASK) {
+	case PA2_CONTEXT_CONFIG:
+		fcmd = p_info->data;
+		swizFcmd(fcmd);
+
+		if (fcmd->command_result != PA2FRM_COMMAND_RESULT_SUCCESS) {
+			dev_dbg(pa_dev->dev, "Command Result = 0x%x\n",
+				fcmd->command_result);
+			dev_dbg(pa_dev->dev, "Command = 0x%x\n", fcmd->command);
+			dev_dbg(pa_dev->dev, "Magic = 0x%x\n", fcmd->magic);
+			dev_dbg(pa_dev->dev, "Com ID = 0x%x\n", fcmd->com_id);
+			dev_dbg(pa_dev->dev, "ret Context = 0x%x\n",
+				fcmd->ret_context);
+			dev_dbg(pa_dev->dev, "Flow ID = 0x%x\n", fcmd->flow_id);
+			dev_dbg(pa_dev->dev, "reply Queue = 0x%x\n",
+				fcmd->reply_queue);
+			dev_dbg(pa_dev->dev, "reply dest = 0x%x\n",
+				fcmd->reply_dest);
+		}
+		dev_dbg(pa_dev->dev, "command response complete\n");
+		break;
+
+	default:
+		dev_warn(pa_dev->dev, "bad response context, got 0x%08x\n",
+			 p_info->epib[1]);
+		break;
+	}
+
+	p_info->desc = NULL;
+	kfree(p_info);
+}
+
+/* Release a free receive buffer */
+static void pa2_rxpool_free(void *arg, unsigned q_num, unsigned bufsize,
+		struct dma_async_tx_descriptor *desc)
+{
+	struct pa2_device *pa_dev = arg;
+	struct pa2_packet *p_info = desc->callback_param;
+
+	dma_unmap_sg(pa_dev->dev, &p_info->sg[2], 1, DMA_FROM_DEVICE);
+
+	p_info->desc = NULL;
+
+	kfree(p_info);
+}
+
+static void pa2_chan_work_handler(unsigned long data)
+{
+	struct pa2_device *pa_dev = (struct pa2_device *)data;
+
+	dma_poll(pa_dev->rx_channel, -1);
+
+	dma_rxfree_refill(pa_dev->rx_channel);
+
+	dmaengine_resume(pa_dev->rx_channel);
+}
+
+static void pa2_chan_notify(struct dma_chan *dma_chan, void *arg)
+{
+	struct pa2_device *pa_dev = arg;
+
+	dmaengine_pause(pa_dev->rx_channel);
+
+	tasklet_schedule(&pa_dev->task);
+
+	return;
+}
+
+/* Allocate a free receive buffer */
+static struct dma_async_tx_descriptor *pa2_rxpool_alloc(void *arg,
+		unsigned q_num, unsigned bufsize)
+{
+	struct pa2_device *pa_dev = arg;
+	struct dma_async_tx_descriptor *desc;
+	struct dma_device *device;
+	u32 err = 0;
+
+	struct pa2_packet *rx;
+
+	rx = pa2_alloc_packet(pa_dev, bufsize, pa_dev->rx_channel);
+	if (!rx) {
+		dev_err(pa_dev->dev, "could not allocate cmd rx packet\n");
+		kfree(rx);
+		return NULL;
+	}
+
+	rx->sg_ents = 2 + dma_map_sg(pa_dev->dev, &rx->sg[2],
+				1, DMA_FROM_DEVICE);
+	if (rx->sg_ents != 3) {
+		dev_err(pa_dev->dev, "dma map failed\n");
+
+		kfree(rx);
+		return NULL;
+	}
+
+	device = rx->chan->device;
+
+	desc = dmaengine_prep_slave_sg(rx->chan, rx->sg, 3, DMA_DEV_TO_MEM,
+				       DMA_HAS_EPIB | DMA_HAS_PSINFO);
+
+	if (IS_ERR_OR_NULL(desc)) {
+		dma_unmap_sg(pa_dev->dev, &rx->sg[2], 1, DMA_FROM_DEVICE);
+		kfree(rx);
+		err = PTR_ERR(desc);
+		if (err != -ENOMEM) {
+			dev_err(pa_dev->dev,
+				"dma prep failed, error %d\n", err);
+		}
+
+		return NULL;
+	}
+
+	desc->callback_param = rx;
+	desc->callback = pa2_rx_complete;
+	rx->cookie = desc->cookie;
+
+	return desc;
+}
+
+static struct pa2_frm_command *pa2_format_fcmd_hdr(void *p_cmd,
+						 struct pa2_device *priv,
+						 u8 cmd,
+						 u16 com_id,
+						 u8 first_pdsp,
+						 u16 cmd_Size)
+{
+	struct pa2_frm_command *fcmd;
+
+	memset(p_cmd, 0, cmd_Size);
+	fcmd			= (struct pa2_frm_command *)p_cmd;
+	fcmd->status		= PA2FRM_CFG_CMD_STATUS_PROC;
+	fcmd->pdsp_index	= first_pdsp;
+	fcmd->command		= cmd;
+	fcmd->magic		= PA2FRM_CONFIG_COMMAND_SEC_BYTE;
+	fcmd->com_id		= com_id;
+	fcmd->ret_context	= PA2_CONTEXT_CONFIG;
+	fcmd->flow_id		= priv->cmd_flow_num;
+	fcmd->reply_queue	= priv->cmd_queue_num;
+	fcmd->reply_dest	= PA2FRM_DEST_PKTDMA;
+
+	return fcmd;
+}
+
+static int keystone_pa2_add_mac(struct pa2_intf *pa_intf, int index,
+			       const u8 *smac, const u8 *dmac, int rule,
+			       unsigned etype, int port)
+{
+	struct pa2_route_info2 route_info, fail_info;
+	struct pa2_frm_command *fcmd;
+	struct pa2_frm_cmd_add_lut1 *al1;
+	struct pa2_packet *tx;
+	struct pa2_device *priv = pa_intf->pa_device;
+	int size, ret;
+	u16 priority, bit_mask = 0;
+	u32 cbwords0, cbwords1;
+
+	dev_dbg(priv->dev, "add mac, index %d, smac %pM, dmac %pM, rule %d, "
+		"type %04x, port %d\n", index, smac, dmac, rule, etype, port);
+
+	memset(&fail_info, 0, sizeof(fail_info));
+
+	memset(&route_info, 0, sizeof(route_info));
+
+	if (rule == PACKET_HST) {
+		route_info.dest			= PA2_DEST_HOST;
+		route_info.flow_id		= pa_intf->data_flow_num;
+		route_info.queue		= pa_intf->data_queue_num;
+		route_info.m_route_index	= PA2_NO_MULTI_ROUTE;
+		fail_info.dest			= PA2_DEST_HOST;
+		fail_info.flow_id		= pa_intf->data_flow_num;
+		fail_info.queue			= pa_intf->data_queue_num;
+		fail_info.m_route_index		= PA2_NO_MULTI_ROUTE;
+	} else if (rule == PACKET_PARSE) {
+		route_info.dest			= PA2_DEST_CONTINUE_PARSE_LUT1;
+		route_info.m_route_index	= PA2_NO_MULTI_ROUTE;
+		fail_info.dest			= PA2_DEST_HOST;
+		fail_info.flow_id		= pa_intf->data_flow_num;
+		fail_info.queue			= pa_intf->data_queue_num;
+		fail_info.m_route_index		= PA2_NO_MULTI_ROUTE;
+	} else if (rule == PACKET_DROP) {
+		route_info.dest			= PA2_DEST_DISCARD;
+		route_info.m_route_index	= PA2_NO_MULTI_ROUTE;
+		fail_info.dest			= PA2_DEST_DISCARD;
+		fail_info.m_route_index		= PA2_NO_MULTI_ROUTE;
+	}
+
+	if (route_info.m_route_index != PA2_NO_MULTI_ROUTE)
+		route_info.valid_bitmap |= PA2_ROUTE_INFO_VALID_MROUTEINDEX;
+	if (route_info.pkt_type_emac_ctrl)
+		route_info.valid_bitmap |= PA2_ROUTE_INFO_VALID_PKTTYPE_EMAC;
+	if (route_info.pcmd)
+		route_info.valid_bitmap |= PA2_ROUTE_INFO_VALID_PCMD;
+	if (fail_info.m_route_index != PA2_NO_MULTI_ROUTE)
+		fail_info.valid_bitmap |= PA2_ROUTE_INFO_VALID_MROUTEINDEX;
+	if (fail_info.pkt_type_emac_ctrl)
+		fail_info.valid_bitmap |= PA2_ROUTE_INFO_VALID_PKTTYPE_EMAC;
+	if (fail_info.pcmd)
+		fail_info.valid_bitmap |= PA2_ROUTE_INFO_VALID_PCMD;
+
+	size = (sizeof(struct pa2_frm_command) +
+		sizeof(struct pa2_frm_cmd_add_lut1) - sizeof(u32));
+	tx = pa2_alloc_packet(priv, size, priv->pdsp0_tx_channel);
+	if (!tx) {
+		dev_err(priv->dev, "could not allocate cmd tx packet\n");
+		return -ENOMEM;
+	}
+
+	fcmd = pa2_format_fcmd_hdr((void *)tx->data,
+				   priv,
+				   PA2FRM_CONFIG_COMMAND_ADDREP_LUT1,
+				   PA2_COMID_L2,
+				   0,
+				   size);
+
+	al1		= (struct pa2_frm_cmd_add_lut1 *) &(fcmd->cmd);
+	al1->index	= index;
+	al1->type	= PA2FRM_COM_ADD_LUT1_STANDARD;
+
+	cbwords0	= PA2FRM_LUT1_CLASS_STANDARD << PA2FRM_LUT1_CLASS_SHIFT;
+	cbwords1	= PA2FRM_LUT1_VALID_PKTTYPE;
+	priority	= 0;
+
+	al1->u.mac.pkt_type = PA2FRM_L2_PKT_TYPE_MAC;
+
+	if (etype) {
+		al1->u.mac.etype = etype;
+		cbwords0 |=  PA2FRM_LUT1_VALID_ETHERTYPE;
+		priority += 10;
+	}
+
+	al1->u.mac.vlan_id1 = 0;
+	al1->u.mac.mpls	= 0;
+	if (port) {
+		al1->u.mac.in_port = port;
+		cbwords1 |=  PA2FRM_LUT1_VALID_INPORT;
+		priority += 10;
+	}
+
+	if (dmac) {
+		memcpy(al1->u.mac.dmac, dmac, 6);
+		cbwords0 |= PA2FRM_LUT1_VALID_DMAC_ALL;
+		priority += 10;
+	}
+	if (smac) {
+		memcpy(al1->u.mac.smac, smac, 6);
+		cbwords0 |= PA2FRM_LUT1_VALID_SMAC;
+		priority += 10;
+	}
+
+	al1->cbwords0 = cbwords0;
+	al1->cbwords1 = cbwords1;
+	al1->priority = priority;
+	al1->bit_mask = bit_mask;
+
+	ret = pa2_conv_routing_info(&al1->match, &route_info, 0, 0, 0, 0);
+	if (ret != 0)
+		dev_err(priv->dev, "route info config failed\n");
+
+	ret = pa2_conv_routing_info(&al1->next_fail, &fail_info, 0, 1, 0, 0);
+	if (ret != 0)
+		dev_err(priv->dev, "fail info config failed\n");
+
+	swizFcmd(fcmd);
+	swizAl1((struct pa2_frm_cmd_add_lut1 *)&(fcmd->cmd));
+
+	tx->psdata[0] = PASAHO2_PACFG_CMD;
+
+	tx->epib[1] = 0;
+	tx->epib[2] = 0;
+	tx->epib[3] = 0;
+
+	pa2_submit_tx_packet(tx);
+	dev_dbg(priv->dev, "waiting for command transmit complete\n");
+
+	return 0;
+}
+
+static void pa2_init_crc_table4(u32 polynomial, u32 *crc_table4)
+{
+	int i, bit;
+
+	/* 16 values representing all possible 4-bit values */
+	for (i = 0; i < PARAM_CRC_TABLE_SIZE; i++) {
+		crc_table4[i] = i << 28;
+		for (bit = 0; bit < 4; bit++) {
+			/* If shifting out a zero, then just shift */
+			if (!(crc_table4[i] & 0x80000000))
+				crc_table4[i] = (crc_table4[i] << 1);
+			/* Else add in the polynomial as well */
+			else
+				crc_table4[i] =
+					(crc_table4[i] << 1) ^ polynomial;
+		}
+	}
+}
+
+static int pa2_config_crc_engine(struct pa2_device *priv,
+				enum pa2_crc_inst inst,
+				struct pa2_crc_config *cfg_info,
+				u32 recipe_idx)
+{
+	struct pa2_ppu_pcheck_regs __iomem *pcheck_regs;
+	u32 i, pdsp, control, crc_tbl[16];
+
+	switch (inst) {
+	case PA2_CRC_INST_0_0:
+		pdsp = PA2_INGRESS0_PDSP1;
+		break;
+
+	case PA2_CRC_INST_1_0:
+		pdsp = PA2_INGRESS1_PDSP1;
+		break;
+
+	case PA2_CRC_INST_4_0:
+		pdsp = PA2_INGRESS4_PDSP1;
+		break;
+
+	case PA2_CRC_INST_5_0:
+		pdsp = PA2_POST_PDSP1;
+		break;
+
+	case PA2_CRC_INST_6_0:
+		pdsp = PA2_EGRESS0_PDSP1;
+		break;
+
+	case PA2_CRC_INST_6_1:
+		pdsp = PA2_EGRESS0_PDSP2;
+		break;
+
+	default:
+		return PA2_ERR_CONFIG;
+	}
+
+	pcheck_regs = priv->ppu[pdsp].pcheck;
+	control = (cfg_info->ctrl_bits & PA2_CRC_CONFIG_RIGHT_SHIFT) \
+		  ? PA2_PCHECK_CONTROL_RSHIFT_MASK : 0;
+	__raw_writel(control, &pcheck_regs->recipe[recipe_idx].control);
+	control = __raw_readl(&pcheck_regs->recipe[recipe_idx].control);
+	control |= (cfg_info->ctrl_bits & PA2_CRC_CONFIG_INVERSE_RESULT) ? \
+		   PA2_PCHECK_CONTROL_FINAL_NOT_MASK : 0;
+
+	pa2_init_crc_table4(cfg_info->polynomial, crc_tbl);
+	for (i = 0; i < (PARAM_CRC_TABLE_SIZE - 1); i++)
+		__raw_writel(crc_tbl[i+1],
+			     &pcheck_regs->recipe[recipe_idx].table[i]);
+
+	return 0;
+}
+
+#define	CRC32C_POLYNOMIAL	0x1EDC6F41
+#define	SCTP_CRC_INITVAL	0xFFFFFFFF
+/* SCTP TX CRC configuration data */
+static struct pa2_crc_config sctp_tx_crc_cfg = {
+	PA2_CRC_CONFIG_INVERSE_RESULT | PA2_CRC_CONFIG_RIGHT_SHIFT,
+	PA2_CRC_SIZE_32,
+	CRC32C_POLYNOMIAL,
+	SCTP_CRC_INITVAL
+};
+
+static int pa2_config_sctp_crc_engine(struct pa2_device *priv)
+{
+	int ret;
+
+	/* Configure CRC engine for SCTP TX, there are 4 recipes for each CRC
+	 * engine, currently use recipe 0 */
+	ret = pa2_config_crc_engine(priv, PA2_CRC_INST_6_1, &sctp_tx_crc_cfg,
+				0);
+
+	return ret;
+}
+
+
+static inline int pa2_fmtcmd_tx_csum(struct netcp_packet *p_info)
+{
+	struct sk_buff *skb = p_info->skb;
+	struct pasaho2_com_chk_crc *ptx;
+	int start, len;
+	int size;
+
+	size = sizeof(*ptx);
+	ptx = (struct pasaho2_com_chk_crc *)netcp_push_psdata(p_info, size);
+
+	start = skb_checksum_start_offset(skb);
+	len = skb->len - start;
+
+	ptx->word0 = 0;
+	ptx->word1 = 0;
+	ptx->word2 = 0;
+	PASAHO2_SET_CMDID(ptx, PASAHO2_PAMOD_CMPT_CHKSUM);
+	PASAHO2_CHKCRC_SET_START(ptx, start);
+	PASAHO2_CHKCRC_SET_LEN(ptx, len);
+	PASAHO2_CHKCRC_SET_RESULT_OFF(ptx, skb->csum_offset);
+	PASAHO2_CHKCRC_SET_INITVAL(ptx, 0);
+	PASAHO2_CHKCRC_SET_NEG0(ptx, 0);
+
+	return size;
+}
+
+static inline int pa2_fmtcmd_tx_crc32c(struct netcp_packet *p_info)
+{
+	struct sk_buff *skb = p_info->skb;
+	struct pasaho2_com_chk_crc *ptx;
+	int start, len;
+	int size;
+
+	size = sizeof(*ptx);
+	ptx = (struct pasaho2_com_chk_crc *)netcp_push_psdata(p_info, size);
+
+	start = skb_checksum_start_offset(skb);
+	len = skb->len - start;
+
+	ptx->word0 = 0;
+	ptx->word1 = 0;
+	ptx->word2 = 0;
+	PASAHO2_SET_CMDID(ptx, PASAHO2_PAMOD_CMPT_CRC);
+	PASAHO2_CHKCRC_SET_CTRL(ptx, PA2FRM_CRC_FLAG_CRC_OFFSET_VALID);
+	PASAHO2_CHKCRC_SET_CRCSIZE(ptx, 2);
+	PASAHO2_CHKCRC_SET_START(ptx, start);
+	PASAHO2_CHKCRC_SET_LEN(ptx, len);
+	PASAHO2_CHKCRC_SET_RESULT_OFF(ptx, skb->csum_offset);
+	PASAHO2_CHKCRC_SET_INITVAL32(ptx, 0);
+
+	return size;
+}
+
+static inline int pa2_fmtcmd_next_route(struct netcp_packet *p_info,
+					u8 ps_flags)
+{
+	struct pasaho2_next_route *nr;
+
+	nr = (struct pasaho2_next_route *)netcp_push_psdata(p_info,
+							sizeof(*nr));
+	if (!nr)
+		return -ENOMEM;
+
+	/* Construct word0 */
+	nr->word0 = 0;
+	PASAHO2_SET_CMDID(nr, PASAHO2_PAMOD_NROUTE);
+	PASAHO2_SET_E(nr, 1);
+	PASAHO2_SET_DEST(nr, PA2FRM_DEST_ETH);
+	PASAHO2_SET_FLOW(nr, 0);
+	PASAHO2_SET_QUEUE(nr, 0);
+
+	/* Construct sw_info0 and sw_info1 */
+	nr->sw_info0 = 0;
+	nr->sw_info1 = 0;
+
+	/* Construct word1 */
+	nr->word1 = 0;
+	PASAHO2_SET_PKTTYPE(nr, ps_flags);
+
+	return sizeof(*nr);
+}
+
+static inline int pa2_fmtcmd_align(struct netcp_packet *p_info,
+		const unsigned bytes)
+{
+	struct pasaho2_cmd_info	*paCmdInfo;
+	int i;
+
+	if ((bytes & 0x03) != 0)
+		return -EINVAL;
+
+	paCmdInfo = (struct pasaho2_cmd_info *)netcp_push_psdata(p_info, bytes);
+
+	for (i = bytes/sizeof(u32); i > 0; --i) {
+		paCmdInfo->word0 = 0;
+		PASAHO2_SET_CMDID(paCmdInfo, PASAHO2_PAMOD_DUMMY);
+		++paCmdInfo;
+	}
+
+	return bytes;
+}
+
+static inline int extract_l4_proto(struct netcp_packet *p_info)
+{
+	struct sk_buff *skb = p_info->skb;
+	int l4_proto = 0;
+	__be16 l3_proto;
+
+	l3_proto = skb->protocol;
+	if (l3_proto == __constant_htons(ETH_P_8021Q)) {
+		/* Can't use vlan_eth_hdr() here, skb->mac_header isn't valid */
+		struct vlan_ethhdr *vhdr = (struct vlan_ethhdr *)skb->data;
+		l3_proto = vhdr->h_vlan_encapsulated_proto;
+	}
+
+	switch (l3_proto) {
+	case __constant_htons(ETH_P_IP):
+		l4_proto = ip_hdr(skb)->protocol;
+		break;
+	case __constant_htons(ETH_P_IPV6):
+		l4_proto = ipv6_hdr(skb)->nexthdr;
+		break;
+	default:
+		if (unlikely(net_ratelimit())) {
+			dev_warn(p_info->netcp->dev,
+				 "partial checksum but L3 proto = 0x%04hx!\n",
+				 ntohs(l3_proto));
+		}
+	}
+
+	return l4_proto;
+}
+
+static int pa2_tx_hook(int order, void *data, struct netcp_packet *p_info)
+{
+	struct	pa2_intf *pa_intf = data;
+	struct pa2_device *pa_dev = pa_intf->pa_device;
+	struct netcp_priv *netcp_priv = netdev_priv(pa_intf->net_device);
+	struct sk_buff *skb = p_info->skb;
+	int size, total = 0;
+	u8 ps_flags = 0;
+
+	if (pa_dev->multi_if) {
+		if (likely(skb->mark == 0) ||
+		    likely((skb->mark & pa_dev->mark_mcast_match[1]) !=
+				pa_dev->mark_mcast_match[0])) {
+			/* normal port-specific output packet */
+			ps_flags |= (netcp_priv->cpsw_port & \
+				     PA2_EMAC_CTRL_PORT_MASK) << \
+				     PA2FRM_ETH_PS_FLAGS_PORT_SHIFT;
+		} else {
+			/* Drop packet if port not in mask */
+			if ((skb->mark & BIT(netcp_priv->cpsw_port - 1)) == 0)
+				return NETCP_TX_DROP;
+		}
+	}
+
+	/* Generate the next route command */
+	size = pa2_fmtcmd_next_route(p_info, ps_flags);
+	if (unlikely(size < 0))
+		return size;
+	total += size;
+
+	/* If checksum offload required, request it */
+	if ((skb->ip_summed == CHECKSUM_PARTIAL) &&
+	    (pa_dev->csum_offload == CSUM_OFFLOAD_HARD)) {
+		int l4_proto;
+
+		l4_proto = extract_l4_proto(p_info);
+		switch (l4_proto) {
+		case IPPROTO_TCP:
+		case IPPROTO_UDP:
+			size = pa2_fmtcmd_tx_csum(p_info);
+			break;
+		case IPPROTO_SCTP:
+			size = pa2_fmtcmd_tx_crc32c(p_info);
+			break;
+		default:
+			if (unlikely(net_ratelimit())) {
+				dev_warn(p_info->netcp->dev,
+					"partial checksum but L4 proto = %d!\n",
+					l4_proto);
+			}
+			size = 0;
+			break;
+		}
+
+		if (unlikely(size < 0))
+			return size;
+		total += size;
+	}
+
+	/* The next hook may require the command stack to be 8-byte aligned */
+	size = netcp_align_psdata(p_info, 8);
+	if (unlikely(size < 0))
+		return size;
+	if (size > 0) {
+		size = pa2_fmtcmd_align(p_info, size);
+		if (unlikely(size < 0))
+			return size;
+		total += size;
+	}
+
+	p_info->tx_pipe = &pa_intf->tx_pipe;
+	return 0;
+}
+
+
+/* This code adapted from net/core/skbuff.c:skb_checksum() */
+static __wsum skb_sctp_csum(struct sk_buff *skb, int offset,
+			  int len, __wsum csum)
+{
+	int start = skb_headlen(skb);
+	int i, copy = start - offset;
+	struct sk_buff *frag_iter;
+
+	/* Checksum header. */
+	if (copy > 0) {
+		if (copy > len)
+			copy = len;
+		csum = sctp_update_cksum(skb->data + offset, copy, csum);
+		len -= copy;
+		if (len == 0)
+			return csum;
+		offset += copy;
+	}
+
+	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
+		int end;
+		skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
+
+		WARN_ON(start > offset + len);
+
+		end = start + skb_frag_size(frag);
+		copy = end - offset;
+		if (copy > 0) {
+			u8 *vaddr;
+			skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
+
+			if (copy > len)
+				copy = len;
+			vaddr = kmap_atomic(skb_frag_page(frag));
+			csum = sctp_update_cksum(vaddr + frag->page_offset +
+					 offset - start, copy, csum);
+			kunmap_atomic(vaddr);
+			len -= copy;
+			if (!len)
+				return csum;
+			offset += copy;
+		}
+		start = end;
+	}
+
+	skb_walk_frags(skb, frag_iter) {
+		int end;
+
+		WARN_ON(start > offset + len);
+
+		end = start + frag_iter->len;
+		copy = end - offset;
+		if (copy > 0) {
+			if (copy > len)
+				copy = len;
+			csum = skb_sctp_csum(frag_iter,
+						offset - start, copy, csum);
+			len -= copy;
+			if (len == 0)
+				return csum;
+			offset += copy;
+		}
+		start = end;
+	}
+	BUG_ON(len);
+
+	return csum;
+}
+
+static void skb_warn_bad_offload(const struct sk_buff *skb)
+{
+	static const netdev_features_t null_features = 0;
+	struct net_device *dev = skb->dev;
+	const char *driver = "";
+
+	if (dev && dev->dev.parent)
+		driver = dev_driver_string(dev->dev.parent);
+
+	WARN(1, "%s: caps=(%pNF, %pNF) len=%d data_len=%d gso_size=%d "
+	     "gso_type=%d ip_summed=%d\n",
+	     driver, dev ? &dev->features : &null_features,
+	     skb->sk ? &skb->sk->sk_route_caps : &null_features,
+	     skb->len, skb->data_len, skb_shinfo(skb)->gso_size,
+	     skb_shinfo(skb)->gso_type, skb->ip_summed);
+}
+
+/* This code adapted from net/core/dev.c:skb_checksum_help() */
+static int skb_sctp_csum_help(struct sk_buff *skb)
+{
+	__wsum csum;
+	int ret = 0, offset;
+
+	if (skb->ip_summed == CHECKSUM_COMPLETE)
+		goto out_set_summed;
+
+	if (unlikely(skb_shinfo(skb)->gso_size)) {
+		skb_warn_bad_offload(skb);
+		return -EINVAL;
+	}
+
+	offset = skb_checksum_start_offset(skb);
+	BUG_ON(offset >= skb_headlen(skb));
+	csum = skb_sctp_csum(skb, offset, skb->len - offset, ~0);
+
+	offset += skb->csum_offset;
+	BUG_ON(offset + sizeof(__le32) > skb_headlen(skb));
+
+	if (skb_cloned(skb) &&
+	    !skb_clone_writable(skb, offset + sizeof(__le32))) {
+		ret = pskb_expand_head(skb, 0, 0, GFP_ATOMIC);
+		if (ret)
+			goto out;
+	}
+
+	*(__le32 *)(skb->data + offset) = sctp_end_cksum(csum);
+out_set_summed:
+	skb->ip_summed = CHECKSUM_NONE;
+out:
+	return ret;
+}
+
+static int pa2_txhook_softcsum(int order, void *data,
+			      struct netcp_packet *p_info)
+{
+	struct pa2_intf *pa_intf = data;
+	struct pa2_device *pa_dev = pa_intf->pa_device;
+	struct sk_buff *skb = p_info->skb;
+	int l4_proto;
+	int ret = 0;
+
+	if ((skb->ip_summed != CHECKSUM_PARTIAL) ||
+	    (pa_dev->csum_offload != CSUM_OFFLOAD_SOFT))
+		return 0;
+
+	l4_proto = extract_l4_proto(p_info);
+	if (unlikely(!l4_proto))
+		return 0;
+
+	switch (l4_proto) {
+	case IPPROTO_TCP:
+	case IPPROTO_UDP:
+		ret = skb_checksum_help(skb);
+		break;
+	case IPPROTO_SCTP:
+		ret = skb_sctp_csum_help(skb);
+		break;
+	default:
+		if (unlikely(net_ratelimit())) {
+			dev_warn(p_info->netcp->dev,
+				 "partial checksum but L4 proto = %d!\n",
+				 l4_proto);
+		}
+		return 0;
+	}
+
+	return ret;
+}
+
+
+static int pa2_close(void *intf_priv, struct net_device *ndev)
+{
+	struct pa2_intf *pa_intf = intf_priv;
+	struct pa2_device *pa_dev = pa_intf->pa_device;
+	struct netcp_priv *netcp_priv = netdev_priv(ndev);
+
+	netcp_unregister_txhook(netcp_priv, pa_dev->txhook_order,
+				pa2_tx_hook, intf_priv);
+	if (pa_dev->csum_offload == CSUM_OFFLOAD_SOFT)
+		netcp_unregister_txhook(netcp_priv, pa_dev->txhook_softcsum,
+					pa2_txhook_softcsum, intf_priv);
+
+	netcp_txpipe_close(&pa_intf->tx_pipe);
+
+	/* De-Configure the streaming switch */
+	netcp_set_streaming_switch2(pa_dev->netcp_device,
+				    netcp_priv->cpsw_port,
+				    pa_intf->saved_ss_state);
+
+
+	mutex_lock(&pa2_modules_lock);
+	if (!--pa_dev->inuse_if_count) {
+		/* Do pa disable related stuff only if this is the last
+		 * interface to go down
+		 */
+
+		if (pa_dev->pdsp0_tx_channel) {
+			dma_release_channel(pa_dev->pdsp0_tx_channel);
+			pa_dev->pdsp0_tx_channel = NULL;
+		}
+		if (pa_dev->rx_channel) {
+			dmaengine_pause(pa_dev->rx_channel);
+			tasklet_kill(&pa_dev->task);
+			dma_rxfree_flush(pa_dev->rx_channel);
+			dma_poll(pa_dev->rx_channel, -1);
+			dma_release_channel(pa_dev->rx_channel);
+			pa_dev->rx_channel = NULL;
+		}
+
+		if (pa_dev->clk) {
+			clk_disable_unprepare(pa_dev->clk);
+			clk_put(pa_dev->clk);
+		}
+		pa_dev->clk = NULL;
+	}
+
+	mutex_unlock(&pa2_modules_lock);
+	return 0;
+}
+
+static int pa2_open(void *intf_priv, struct net_device *ndev)
+{
+	struct pa2_intf *pa_intf = intf_priv;
+	struct pa2_device *pa_dev = pa_intf->pa_device;
+	struct netcp_priv *netcp_priv = netdev_priv(ndev);
+	struct dma_keystone_info config;
+	const struct firmware *fw;
+	struct dma_chan *chan;
+	dma_cap_mask_t mask;
+	int i, ret, err;
+
+	/* The first time an open is being called */
+	mutex_lock(&pa2_modules_lock);
+
+	dev_dbg(pa_dev->dev, "pa2_open() called for port: %d\n",
+		 netcp_priv->cpsw_port);
+
+	if (++pa_dev->inuse_if_count == 1) {
+
+		/* Do pa enable, load firmware only for the first interface
+		 * that comes up
+		 */
+		dev_dbg(pa_dev->dev, "pa2_open() called for first time"
+			" initializing per dev stuff\n");
+
+		pa_dev->clk = clk_get(pa_dev->dev, "clk_pa");
+		if (IS_ERR_OR_NULL(pa_dev->clk)) {
+			dev_warn(pa_dev->dev,
+				 "unable to get Packet Accelerator clock\n");
+			pa_dev->clk = NULL;
+		}
+
+		if (pa_dev->clk)
+			clk_prepare_enable(pa_dev->clk);
+
+		/* System Statistics initialization */
+		__raw_writel(PA2_STATS_CTL_ENABLE_ALLOC_MASK,
+				&pa_dev->reg_stats_ctl->enable_alloc);
+		__raw_writel(1, &pa_dev->reg_stats_ctl->soft_reset);
+
+		/* Initialize all clusters */
+		for (i = 0; i < PA2_NUM_CLUSTERS; i++) {
+			__raw_writel(PA2_CLUSTER_SPLITTER_EOP_CTL,
+				&pa_dev->cluster[i].splitter->eop_ctl);
+			__raw_writel(PA2_CLUSTER_SPLITTER_EOP_BUF_SIZE(i),
+				&pa_dev->cluster[i].splitter->mop_buf_size);
+			__raw_writel(PA2_CLUSTER_SPLITTER_MOP_BUF_PTR,
+				&pa_dev->cluster[i].splitter->mop_buf_ptr);
+			__raw_writel(PA2_CLUSTER_SPLITTER_SOP_CTL,
+				&pa_dev->cluster[i].splitter->sop_ctl);
+		}
+
+		keystone_pa2_reset_control(pa_dev, PA2_STATE_RESET);
+
+		for (i = 0; i < PA2_NUM_PDSPS; i++) {
+			if (!pa_dev->pdsp_fw[i])
+				continue;
+
+			ret = request_firmware(&fw, pa_dev->pdsp_fw[i],
+						pa_dev->dev);
+			if (ret != 0) {
+				dev_err(pa_dev->dev,
+					"can't find fw for pdsp %d", i);
+				ret = -ENODEV;
+				goto fail;
+			}
+
+			/* Download the firmware to the PDSP */
+			ret = keystone_pa2_set_firmware(pa_dev, i,
+						(const unsigned int *) fw->data,
+						fw->size);
+			if (ret != 0) {
+				dev_err(pa_dev->dev,
+					"failed to download fw for pdsp %d", i);
+				ret = -ENODEV;
+				goto fail;
+			}
+
+
+			release_firmware(fw);
+		}
+
+		ret = keystone_pa2_reset_control(pa_dev, PA2_STATE_ENABLE);
+		if (ret != 1) {
+			dev_err(pa_dev->dev, "enable failed, ret = %d\n", ret);
+			ret = -ENODEV;
+			goto fail;
+		}
+
+		pa2_get_version(pa_dev);
+
+		dma_cap_zero(mask);
+		dma_cap_set(DMA_SLAVE, mask);
+
+		/* Open the PA Command transmit channel */
+		pa_dev->pdsp0_tx_channel = dma_request_channel_by_name(mask,
+								"patx-pdsp0");
+		if (IS_ERR_OR_NULL(pa_dev->pdsp0_tx_channel)) {
+			dev_err(pa_dev->dev, "Couldnt get PATX cmd channel\n");
+			pa_dev->pdsp0_tx_channel = NULL;
+			ret = -ENODEV;
+			goto fail;
+		}
+
+		memset(&config, 0, sizeof(config));
+		config.direction	= DMA_MEM_TO_DEV;
+		config.tx_queue_depth	= pa_dev->tx_cmd_queue_depth;
+
+		err = dma_keystone_config(pa_dev->pdsp0_tx_channel, &config);
+		if (err)
+			goto fail;
+
+		/* Open the PA common response channel */
+		pa_dev->rx_channel = dma_request_channel_by_name(mask, "parx");
+		if (IS_ERR_OR_NULL(pa_dev->rx_channel)) {
+			dev_err(pa_dev->dev, "Could not get PA RX channel\n");
+			pa_dev->rx_channel = NULL;
+			ret = -ENODEV;
+			goto fail;
+		}
+
+		memset(&config, 0, sizeof(config));
+
+		config.direction		= DMA_DEV_TO_MEM;
+		config.scatterlist_size		= PA2_SGLIST_SIZE;
+		config.rxpool_allocator		= pa2_rxpool_alloc;
+		config.rxpool_destructor	= pa2_rxpool_free;
+		config.rxpool_param		= pa_dev;
+		config.rxpool_count		= 1;
+		config.rxpool_thresh_enable	= DMA_THRESH_NONE;
+		config.rxpools[0].pool_depth	= pa_dev->rx_pool_depth;
+		config.rxpools[0].buffer_size	= pa_dev->rx_buffer_size;
+
+		err = dma_keystone_config(pa_dev->rx_channel, &config);
+		if (err)
+			goto fail;
+
+		tasklet_init(&pa_dev->task, pa2_chan_work_handler,
+			     (unsigned long) pa_dev);
+
+		dma_set_notify(pa_dev->rx_channel, pa2_chan_notify, pa_dev);
+
+		pa_dev->cmd_flow_num = dma_get_rx_flow(pa_dev->rx_channel);
+		pa_dev->cmd_queue_num = dma_get_rx_queue(pa_dev->rx_channel);
+
+		dev_dbg(pa_dev->dev, "command receive flow %d, queue %d\n",
+			pa_dev->cmd_flow_num, pa_dev->cmd_queue_num);
+
+		pa_dev->addr_count = 0;
+
+		dma_rxfree_refill(pa_dev->rx_channel);
+
+		ret = pa2_config_sctp_crc_engine(pa_dev);
+		if (ret < 0)
+			goto fail;
+
+		/* make lut entries invalid */
+		/* for (i = 0; i < pa_dev->lut_size; i++) {
+			if (!pa_dev->lut[i].valid)
+				continue;
+			keystone_pa2_add_mac(pa_intf, i, NULL, NULL,
+					PACKET_DROP, 0, PA2_INVALID_PORT);
+		} */
+	}
+	mutex_unlock(&pa2_modules_lock);
+
+	pa_intf->saved_ss_state = netcp_get_streaming_switch2(
+						     pa_dev->netcp_device,
+						     netcp_priv->cpsw_port);
+	dev_dbg(pa_dev->dev, "saved_ss_state for port %d is %d\n",
+		 netcp_priv->cpsw_port, pa_intf->saved_ss_state);
+
+	chan = netcp_get_rx_chan(netcp_priv);
+	pa_intf->data_flow_num = dma_get_rx_flow(chan);
+	pa_intf->data_queue_num = dma_get_rx_queue(chan);
+
+	dev_dbg(pa_dev->dev, "configuring data receive flow %d, queue %d\n",
+		 pa_intf->data_flow_num, pa_intf->data_queue_num);
+
+	/* Configure the streaming switch */
+	netcp_set_streaming_switch2(pa_dev->netcp_device, netcp_priv->cpsw_port,
+				    PSTREAM_ROUTE_INGRESS0);
+
+	/* Open the PA Data transmit channel */
+	ret = netcp_txpipe_open(&pa_intf->tx_pipe);
+	if (ret)
+		goto fail;
+
+	netcp_register_txhook(netcp_priv, pa_dev->txhook_order,
+			      pa2_tx_hook, intf_priv);
+	if (pa_dev->csum_offload == CSUM_OFFLOAD_SOFT)
+		netcp_register_txhook(netcp_priv, pa_dev->txhook_softcsum,
+				      pa2_txhook_softcsum, intf_priv);
+
+	return 0;
+
+fail:
+	mutex_unlock(&pa2_modules_lock);
+	pa2_close(intf_priv, ndev);
+	return ret;
+}
+
+static struct pa2_lut_entry *pa2_lut_alloc(struct pa2_device *pa_dev,
+					 bool backwards)
+{
+	struct pa2_lut_entry *entry;
+	int i;
+
+	if (!backwards) {
+		for (i = 0; i < pa_dev->lut_size; i++) {
+			entry = pa_dev->lut + i;
+			if (!entry->valid || entry->in_use)
+				continue;
+			entry->in_use = true;
+			return entry;
+		}
+	} else {
+		for (i = pa_dev->lut_size - 1; i >= 0; i--) {
+			entry = pa_dev->lut + i;
+			if (!entry->valid || entry->in_use)
+				continue;
+			entry->in_use = true;
+			return entry;
+		}
+	}
+	return NULL;
+}
+
+static inline int pa2_lut_entry_count(enum netcp_addr_type type)
+{
+	return (type == ADDR_DEV || type == ADDR_UCAST || type == ADDR_ANY) ? \
+		3 : 1;
+}
+
+static int pa2_add_addr(void *intf_priv, struct netcp_addr *naddr)
+{
+	struct pa2_intf *pa_intf = intf_priv;
+	struct pa2_device *pa_dev = pa_intf->pa_device;
+	struct netcp_priv *netcp_priv = netdev_priv(pa_intf->net_device);
+	int count = pa2_lut_entry_count(naddr->type);
+	struct pa2_lut_entry *entries[count];
+	int port = netcp_priv->cpsw_port;
+	int idx, error;
+	const u8 *addr;
+
+	for (idx = 0; idx < count; idx++) {
+		entries[idx] = pa2_lut_alloc(pa_dev, naddr->type == ADDR_ANY);
+		if (!entries[idx])
+			goto fail_alloc;
+		entries[idx]->naddr = naddr;
+	}
+
+	addr = (naddr->type == ADDR_ANY) ? NULL : naddr->addr;
+	idx = 0;
+
+	if (naddr->type == ADDR_ANY) {
+		error = keystone_pa2_add_mac(pa_intf, entries[idx++]->index,
+					    NULL, addr, PACKET_HST, 0, port);
+		if (error)
+			return error;
+	}
+
+	if (count > 1) {
+		error = keystone_pa2_add_mac(pa_intf, entries[idx++]->index,
+					    NULL, addr, PACKET_PARSE,
+					    0x0800, port);
+		if (error)
+			return error;
+
+		error = keystone_pa2_add_mac(pa_intf, entries[idx++]->index,
+					    NULL, addr, PACKET_PARSE,
+					    0x86dd, port);
+		if (error)
+			return error;
+	}
+
+	if (naddr->type != ADDR_ANY) {
+		error = keystone_pa2_add_mac(pa_intf, entries[idx++]->index,
+					    NULL, addr, PACKET_HST, 0, port);
+		if (error)
+			return error;
+	}
+
+	return error;
+
+fail_alloc:
+	for (idx--; idx >= 0; idx--)
+		entries[idx]->in_use = false;
+	return -ENOMEM;
+}
+
+static int pa2_del_addr(void *intf_priv, struct netcp_addr *naddr)
+{
+	struct pa2_intf *pa_intf = intf_priv;
+	struct pa2_device *pa_dev = pa_intf->pa_device;
+	struct pa2_lut_entry *entry;
+	int idx;
+
+	for (idx = 0; idx < pa_dev->lut_size; idx++) {
+		entry = pa_dev->lut + idx;
+		if (!entry->valid || !entry->in_use || entry->naddr != naddr)
+			continue;
+		keystone_pa2_add_mac(pa_intf, entry->index, NULL, NULL,
+				    PACKET_DROP, 0, PA2_INVALID_PORT);
+		entry->in_use = false;
+		entry->naddr = NULL;
+	}
+
+	return 0;
+}
+
+static int pa2_ioctl(void *intf_priv, struct ifreq *req, int cmd)
+{
+	return -EOPNOTSUPP;
+}
+
+static int pa2_attach(void *inst_priv, struct net_device *ndev,
+			void **intf_priv)
+{
+	struct pa2_device *pa_dev = inst_priv;
+	struct netcp_priv *netcp_priv = netdev_priv(ndev);
+	struct pa2_intf *pa_intf;
+	int chan_id = 0;
+
+	if (netcp_priv->cpsw_port)
+		pa_dev->multi_if = 1;
+
+	dev_dbg(pa_dev->dev, "pa2_attach, port %d\n", netcp_priv->cpsw_port);
+	pa_intf = devm_kzalloc(pa_dev->dev, sizeof(struct pa2_intf),
+				GFP_KERNEL);
+	if (!pa_intf) {
+		dev_err(pa_dev->dev, "memory allocation failed\n");
+		return -ENOMEM;
+	}
+
+	pa_intf->net_device = ndev;
+	pa_intf->pa_device = pa_dev;
+	*intf_priv = pa_intf;
+
+	/* Use pdsp5 with 0 as base */
+	if (netcp_priv->cpsw_port)
+		chan_id = netcp_priv->cpsw_port - 1;
+
+	snprintf(pa_intf->tx_chan_name, sizeof(pa_intf->tx_chan_name),
+		 "patx-pdsp5-%d", chan_id);
+	netcp_txpipe_init(&pa_intf->tx_pipe, netdev_priv(ndev),
+			  pa_intf->tx_chan_name, pa_dev->tx_data_queue_depth);
+
+	if (pa_dev->csum_offload) {
+		rtnl_lock();
+		ndev->features		|= PA2_NETIF_FEATURES;
+		ndev->hw_features	|= PA2_NETIF_FEATURES;
+		ndev->wanted_features	|= PA2_NETIF_FEATURES;
+		netdev_update_features(ndev);
+		rtnl_unlock();
+	}
+	return 0;
+}
+
+static int pa2_release(void *intf_priv)
+{
+	struct pa2_intf *pa_intf = intf_priv;
+	struct pa2_device *pa_dev = pa_intf->pa_device;
+	struct net_device *ndev = pa_intf->net_device;
+
+	mutex_lock(&pa2_modules_lock);
+	if ((!--pa_dev->inuse_if_count) && (pa_dev->csum_offload)) {
+		rtnl_lock();
+		ndev->features		&= ~PA2_NETIF_FEATURES;
+		ndev->hw_features	&= ~PA2_NETIF_FEATURES;
+		ndev->wanted_features	&= ~PA2_NETIF_FEATURES;
+		netdev_update_features(ndev);
+		rtnl_unlock();
+	}
+	mutex_unlock(&pa2_modules_lock);
+
+	devm_kfree(pa_dev->dev, pa_intf);
+	return 0;
+}
+
+static int pa2_remove(struct netcp_device *netcp_device, void *inst_priv)
+{
+	struct pa2_device *pa_dev = inst_priv;
+	struct device *dev = pa_dev->dev;
+	u32 i;
+
+	pa2_cond_unmap(pa_dev->reg_mailbox);
+	pa2_cond_unmap(pa_dev->reg_ra_bridge);
+	pa2_cond_unmap(pa_dev->reg_thread_mapper);
+	pa2_cond_unmap(pa_dev->reg_ra);
+	pa2_cond_unmap(pa_dev->reg_stats_ctl);
+	pa2_cond_unmap(pa_dev->reg_query_stats);
+	pa2_cond_unmap(pa_dev->reg_collect_stats);
+	pa2_cond_unmap(pa_dev->pa_sram);
+
+	for (i = 0; i < PA2_NUM_CLUSTERS; i++) {
+		pa2_cond_unmap(pa_dev->cluster[i].splitter);
+		pa2_cond_unmap(pa_dev->cluster[i].sram);
+	}
+
+	for (i = 0; i < PA2_NUM_PDSPS; i++) {
+		pa2_cond_unmap(pa_dev->ppu[i].ctl_status);
+		pa2_cond_unmap(pa_dev->ppu[i].debug);
+		pa2_cond_unmap(pa_dev->ppu[i].cp_timer);
+		pa2_cond_unmap(pa_dev->ppu[i].lut1);
+		pa2_cond_unmap(pa_dev->ppu[i].lut2);
+		pa2_cond_unmap(pa_dev->ppu[i].pcheck);
+		pa2_cond_unmap(pa_dev->ppu[i].iram);
+	}
+
+	kfree(pa_dev);
+
+	return 0;
+}
+
+static int pa2_probe(struct netcp_device *netcp_device,
+		    struct device *dev,
+		    struct device_node *node,
+		    void **inst_priv)
+{
+	struct pa2_device *pa_dev;
+	int ret, len = 0, start, end, i, j;
+	int table_size, num_ranges;
+	u32 *prange;
+	u32 regs_base;
+
+	if (!node) {
+		dev_err(dev, "device tree info unavailable\n");
+		return -ENODEV;
+	}
+
+	pa_dev = devm_kzalloc(dev, sizeof(struct pa2_device), GFP_KERNEL);
+	if (!pa_dev) {
+		dev_err(dev, "memory allocation failed\n");
+		return -ENOMEM;
+	}
+	*inst_priv = pa_dev;
+
+	pa_dev->netcp_device = netcp_device;
+	pa_dev->dev = dev;
+
+	ret = of_property_read_u32(node, "reg_base",
+				   &regs_base);
+	if (ret < 0) {
+		dev_err(dev, "missing reg_base parameter, err %d\n",
+			ret);
+		goto exit;
+	}
+	dev_dbg(dev, "reg_base 0x%x\n", regs_base);
+
+	for (i = 0; i < PA2_NUM_PDSPS; ++i) {
+		ret = of_property_read_string_index(node, "firmware",
+				i, &pa_dev->pdsp_fw[i]);
+		if (ret < 0) {
+			dev_warn(dev, "no firmware for pdsp %d\n", i);
+			pa_dev->pdsp_fw[i] = NULL;
+		} else {
+			/*FIXME: make me dev_dbg*/
+			dev_info(dev, "pdsp %d firmware: %s\n",
+					i, pa_dev->pdsp_fw[i]);
+		}
+	}
+
+	ret = of_property_read_u32(node, "tx_cmd_queue_depth",
+				   &pa_dev->tx_cmd_queue_depth);
+	if (ret < 0) {
+		dev_err(dev, "missing tx_cmd_queue_depth parameter, err %d\n",
+			ret);
+		pa_dev->tx_cmd_queue_depth = 32;
+	}
+	dev_dbg(dev, "tx_cmd_queue_depth %u\n", pa_dev->tx_cmd_queue_depth);
+
+	ret = of_property_read_u32(node, "tx_data_queue_depth",
+				   &pa_dev->tx_data_queue_depth);
+	if (ret < 0) {
+		dev_err(dev, "missing tx_data_queue_depth parameter, err %d\n",
+			ret);
+		pa_dev->tx_data_queue_depth = 32;
+	}
+	dev_dbg(dev, "tx_data_queue_depth %u\n", pa_dev->tx_data_queue_depth);
+
+	ret = of_property_read_u32(node, "rx_pool_depth",
+				   &pa_dev->rx_pool_depth);
+	if (ret < 0) {
+		dev_err(dev, "missing rx_pool_depth parameter, err %d\n",
+			ret);
+		pa_dev->rx_pool_depth = 32;
+	}
+	dev_dbg(dev, "rx_pool_depth %u\n", pa_dev->rx_pool_depth);
+
+	ret = of_property_read_u32(node, "rx_buffer_size",
+				   &pa_dev->rx_buffer_size);
+	if (ret < 0) {
+		dev_err(dev, "missing rx_buffer_size parameter, err %d\n",
+			ret);
+		pa_dev->rx_buffer_size = 128;
+	}
+	dev_dbg(dev, "rx_buffer_size %u\n", pa_dev->rx_buffer_size);
+
+	pa_dev->reg_mailbox =
+		devm_ioremap(dev, regs_base + PA2_MAILBOX_REGS_OFFSET,
+			sizeof(struct pa2_mailbox_regs) * PA2_MAX_NUM_MAILBOX);
+	pa_dev->reg_ra_bridge =
+		devm_ioremap(dev, regs_base + PA2_RA_BRIDGE_REGS_OFFSET,
+			     sizeof(struct pa2_ra_bridge_regs));
+	pa_dev->reg_thread_mapper =
+		devm_ioremap(dev, regs_base + PA2_THREAD_MAPPER_REGS_OFFSET,
+			     sizeof(struct pa2_thread_mapper_regs));
+	pa_dev->reg_ra =
+		devm_ioremap(dev, regs_base + PA2_RA_REGS_OFFSET,
+		sizeof(struct pa2_ra_regs));
+	pa_dev->reg_stats_ctl =
+		devm_ioremap(dev, regs_base + PA2_STATS_CTL_REGS_OFFSET,
+			     sizeof(struct pa2_stats_ctl_regs));
+	pa_dev->reg_query_stats =
+		devm_ioremap(dev, regs_base + PA2_QUERY_STATS_REGS_OFFSET,
+			     sizeof(struct pa2_query_stats_regs));
+	pa_dev->reg_collect_stats =
+		devm_ioremap(dev, regs_base + PA2_COLLECT_STATS_REGS_OFFSET,
+			     sizeof(struct pa2_collect_stats_regs));
+	pa_dev->pa_sram =
+		devm_ioremap(dev, regs_base + PA2_SRAM_OFFSET, PA2_SRAM_SIZE);
+	if (!pa_dev->reg_mailbox || !pa_dev->reg_ra_bridge ||
+	    !pa_dev->reg_thread_mapper || !pa_dev->reg_ra ||
+	    !pa_dev->reg_stats_ctl || !pa_dev->reg_query_stats ||
+	    !pa_dev->reg_collect_stats || !pa_dev->pa_sram) {
+		dev_err(dev, "failed to set up PA system register areas\n");
+		ret = -ENOMEM;
+		goto exit;
+	}
+
+	for (i = 0; i < PA2_NUM_CLUSTERS; i++) {
+		pa_dev->cluster[i].splitter = devm_ioremap(dev,
+				regs_base + PA2_CLUSTER_SPLITTER_REGS(i),
+				sizeof(struct pa2_cl_splitter_regs));
+		if (!pa_dev->cluster[i].splitter)
+			break;
+		pa_dev->cluster[i].sram = devm_ioremap(dev,
+					regs_base + PA2_CLUSTER_SRAM_REGS(i),
+					PA2_CLUSTER_SRAM_SIZE);
+		if (!pa_dev->cluster[i].sram)
+			break;
+	}
+
+	if (i != PA2_NUM_CLUSTERS) {
+		dev_err(dev, "failed to set up PA Cluster register areas\n");
+		ret = -ENOMEM;
+		goto exit;
+	}
+
+	for (i = 0; i < PA2_NUM_PDSPS; i++) {
+		pa_dev->ppu[i].ctl_status = devm_ioremap(dev,
+			regs_base + pa2_ppu_regs_offset[i] + \
+			PA2_PPU_CTL_STATUS_REGS_OFFSET,
+			sizeof(struct pa2_ppu_ctl_status_regs));
+		if (!pa_dev->ppu[i].ctl_status)
+			break;
+		pa_dev->ppu[i].debug = devm_ioremap(dev,
+			regs_base + pa2_ppu_regs_offset[i] + \
+			PA2_PPU_DEBUG_REGS_OFFSET,
+			sizeof(struct pa2_ppu_debug_regs));
+		if (!pa_dev->ppu[i].debug)
+			break;
+		pa_dev->ppu[i].cp_timer = devm_ioremap(dev,
+			regs_base + pa2_ppu_regs_offset[i] + \
+			PA2_PPU_CP_TIMER_REGS_OFFSET,
+			sizeof(struct pa2_ppu_cp_timer_regs));
+		if (!pa_dev->ppu[i].cp_timer)
+			break;
+		pa_dev->ppu[i].lut1 = devm_ioremap(dev,
+			regs_base + pa2_ppu_regs_offset[i] + \
+			PA2_PPU_LUT1_REGS_OFFSET,
+			sizeof(struct pa2_ppu_lut1_regs));
+		if (!pa_dev->ppu[i].lut1)
+			break;
+		pa_dev->ppu[i].lut2 = devm_ioremap(dev,
+			regs_base + pa2_ppu_regs_offset[i] + \
+			PA2_PPU_LUT2_REGS_OFFSET,
+			sizeof(struct pa2_ppu_lut2_regs));
+		if (!pa_dev->ppu[i].lut2)
+			break;
+		pa_dev->ppu[i].pcheck = devm_ioremap(dev,
+			regs_base + pa2_ppu_regs_offset[i] + \
+			PA2_PPU_PCHECK_REGS_OFFSET,
+			sizeof(struct pa2_ppu_pcheck_regs));
+		if (!pa_dev->ppu[i].pcheck)
+			break;
+		pa_dev->ppu[i].iram = devm_ioremap(dev,
+		       regs_base + pa2_ppu_regs_offset[i] + PA2_PPU_IRAM_OFFSET,
+			PA2_PPU_IRAM_SIZE);
+		if (!pa_dev->ppu[i].iram)
+			break;
+	}
+	if (i != PA2_NUM_PDSPS) {
+		dev_err(dev, "failed to set up PA PPU register areas\n");
+		ret = -ENOMEM;
+		goto exit;
+	}
+
+	ret = of_property_read_u32(node, "checksum-offload",
+				   &pa_dev->csum_offload);
+	if (ret < 0) {
+		dev_warn(dev, "missing checksum-offload parameter, err %d\n",
+			ret);
+		pa_dev->csum_offload = CSUM_OFFLOAD_NONE;
+	}
+	if (pa_dev->csum_offload > CSUM_OFFLOAD_SOFT) {
+		dev_err(dev, "invalid checksum-offload parameter %d, err %d\n",
+			ret, pa_dev->csum_offload);
+		pa_dev->csum_offload = CSUM_OFFLOAD_NONE;
+	}
+	dev_dbg(dev, "checksum-offload %u\n", pa_dev->csum_offload);
+
+	ret = of_property_read_u32(node, "txhook-order",
+				   &pa_dev->txhook_order);
+	if (ret < 0) {
+		dev_err(dev, "missing txhook-order parameter, err %d\n",
+			ret);
+		pa_dev->txhook_order = PA2_TXHOOK_ORDER;
+	}
+	dev_dbg(dev, "txhook-order %u\n", pa_dev->txhook_order);
+
+	if (pa_dev->csum_offload == CSUM_OFFLOAD_SOFT) {
+		ret = of_property_read_u32(node, "txhook-softcsum",
+					   &pa_dev->txhook_softcsum);
+		if (ret < 0) {
+			dev_err(dev, "missing txhook-softcsum param, err %d\n",
+				ret);
+			pa_dev->csum_offload = CSUM_OFFLOAD_NONE;
+			pa_dev->txhook_order = ~0;
+		}
+		dev_dbg(dev, "txhook-softcsum %u\n", pa_dev->txhook_softcsum);
+	}
+
+	ret = of_property_read_u32(node, "rxhook-order",
+				   &pa_dev->rxhook_order);
+	if (ret < 0) {
+		dev_err(dev, "missing rxhook-order parameter, err %d\n",
+			ret);
+		pa_dev->rxhook_order = PA2_RXHOOK_ORDER;
+	}
+	dev_dbg(dev, "rxhook-order %u\n", pa_dev->rxhook_order);
+
+	ret = of_property_read_u32_array(node, "mark_mcast_match",
+					pa_dev->mark_mcast_match, 2);
+	if (ret < 0) {
+		if (ret != -EINVAL) {
+			dev_err(dev, "Error parsing \"mark_mcast_match\" value"
+				" -- parameter ignored\n");
+		}
+		pa_dev->mark_mcast_match[0] = 0;
+		pa_dev->mark_mcast_match[1] = 0;
+	} else if (((pa_dev->mark_mcast_match[0] & 0xff) != 0) ||
+		   ((pa_dev->mark_mcast_match[1] & 0xff) != 0) ||
+		   ((pa_dev->mark_mcast_match[0] & \
+		     ~pa_dev->mark_mcast_match[1]) != 0)) {
+		dev_err(dev, "Error in \"mark_mcast_match\" value"
+				" -- parameter ignored\n");
+		pa_dev->mark_mcast_match[0] = 0;
+		pa_dev->mark_mcast_match[1] = 0;
+	}
+	dev_dbg(dev, "mark_mcast_match = <%08x %08x>\n",
+		 pa_dev->mark_mcast_match[0], pa_dev->mark_mcast_match[1]);
+
+	if (!of_get_property(node, "lut-ranges", &len)) {
+		dev_err(dev, "No lut-entry array in dt bindings for PA\n");
+		return -ENODEV;
+	}
+
+	prange = devm_kzalloc(dev, len, GFP_KERNEL);
+	if (!prange) {
+		dev_err(dev, "memory alloc failed at PA lut entry range\n");
+		return -ENOMEM;
+	}
+	len = len / sizeof(u32);
+	if ((len % 2) != 0) {
+		dev_err(dev, "invalid address map in dt binding\n");
+		return -EINVAL;
+	}
+	num_ranges = len / 2;
+	if (of_property_read_u32_array(node, "lut-ranges", prange, len)) {
+		dev_err(dev, "No range-map array  in dt bindings\n");
+		return -ENODEV;
+	}
+
+	table_size = prange[2 * num_ranges - 1] + 1;
+	dev_dbg(dev, "lut size = %d\n", table_size);
+
+	/* Initialize a table for storing entry listings locally */
+	len = table_size * sizeof(struct pa2_lut_entry);
+	pa_dev->lut  = devm_kzalloc(dev, len, GFP_KERNEL);
+	if (!pa_dev->lut) {
+		dev_err(dev, "devm_kzalloc mapping failed\n");
+		return -ENOMEM;
+	}
+	pa_dev->lut_size = table_size;
+	dev_dbg(dev, "lut size = %d\n", table_size);
+
+	for (i = 0; i < num_ranges; i++) {
+		start = prange[i * 2];
+		end   = prange[i * 2 + 1];
+		for (j = start; j <= end; j++) {
+			pa_dev->lut[j].valid = true;
+			pa_dev->lut[j].index = j;
+			dev_dbg(dev, "setting entry %d to valid\n", j);
+		}
+	}
+
+	devm_kfree(pa_dev->dev, prange);
+
+	spin_lock_init(&pa_dev->lock);
+
+	return 0;
+
+exit:
+	pa2_remove(netcp_device, pa_dev);
+	*inst_priv = NULL;
+	return ret;
+}
+
+
+static struct netcp_module pa2_module = {
+	.name		= "keystone-pa2",
+	.owner		= THIS_MODULE,
+	.probe		= pa2_probe,
+	.open		= pa2_open,
+	.close		= pa2_close,
+	.remove		= pa2_remove,
+	.attach		= pa2_attach,
+	.release	= pa2_release,
+	.add_addr	= pa2_add_addr,
+	.del_addr	= pa2_del_addr,
+	.ioctl		= pa2_ioctl,
+};
+
+static int __init keystone_pa2_init(void)
+{
+	return netcp_register_module(&pa2_module);
+}
+module_init(keystone_pa2_init);
+
+static void __exit keystone_pa2_exit(void)
+{
+	netcp_unregister_module(&pa2_module);
+}
+module_exit(keystone_pa2_exit);
+
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("Hao Zhang <hzhang@ti.com>");
+MODULE_DESCRIPTION("Packet Accelerator 2 driver for Keystone devices");
diff --git a/drivers/net/ethernet/ti/keystone_pa2.h b/drivers/net/ethernet/ti/keystone_pa2.h
new file mode 100644
index 0000000..d015cba
--- /dev/null
+++ b/drivers/net/ethernet/ti/keystone_pa2.h
@@ -0,0 +1,1205 @@
+/*
+ * Copyright (C) 2013 - 2014 Texas Instruments Incorporated
+ * Author: Hao Zhang <hzhang@ti.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation version 2.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef KEYSTONE_PA2_H
+#define KEYSTONE_PA2_H
+
+#ifdef __KERNEL__
+
+/* PA Timer */
+enum pa2_timerstamp_scaler_factor {
+	PA2_TIMESTAMP_SCALER_FACTOR_1 = -1,
+	PA2_TIMESTAMP_SCALER_FACTOR_2 = 0,
+	PA2_TIMESTAMP_SCALER_FACTOR_4,
+	PA2_TIMESTAMP_SCALER_FACTOR_8,
+	PA2_TIMESTAMP_SCALER_FACTOR_16,
+	PA2_TIMESTAMP_SCALER_FACTOR_32,
+	PA2_TIMESTAMP_SCALER_FACTOR_64,
+	PA2_TIMESTAMP_SCALER_FACTOR_128,
+	PA2_TIMESTAMP_SCALER_FACTOR_256,
+	PA2_TIMESTAMP_SCALER_FACTOR_512,
+	PA2_TIMESTAMP_SCALER_FACTOR_1024,
+	PA2_TIMESTAMP_SCALER_FACTOR_2048,
+	PA2_TIMESTAMP_SCALER_FACTOR_4096,
+	PA2_TIMESTAMP_SCALER_FACTOR_8192
+};
+
+#define PA2_SS_TIMER_CNTRL_REG_GO		0x00000001u
+#define PA2_SS_TIMER_CNTRL_REG_MODE		0x00000002u
+#define PA2_SS_TIMER_CNTRL_REG_PSE		0x00008000u
+#define PA2_SS_TIMER_CNTRL_REG_PRESCALE_SHIFT	0x00000002u
+
+#define PA2_SYS_TIMESTAMP_ADDR_OFFSET		0xf0
+
+/* PA Commands */
+#define PA2FRM_MAX_CMD_SET_SIZE			124
+
+/* Routed Packet Destinations */
+#define	PA2_DEST_DISCARD		3	/* Packet is discarded */
+#define PA2_DEST_CONTINUE_PARSE_LUT1	4	/* Packet remains in PA
+						   sub-system for more parsing
+						   and LUT1 classification */
+#define PA2_DEST_CONTINUE_PARSE_LUT2	5	/* Packet remains in PA
+						   sub-system for more parsing
+						   and LUT2 classification */
+#define PA2_DEST_HOST			6	/* Packet is routed to host */
+#define PA2_DEST_EMAC			7	/* Packet is routed to  EMAC */
+#define PA2_DEST_SASS			8	/* Packet is routed to SA */
+#define PA2_DEST_SRIO			9	/* Packet is routed to SRIO */
+#define PA2_DEST_CASCADED_FORWARDING_LUT1 10	/* Cascaded forwarding packet
+						   remains in PA sub-system
+						   for next LUT1 (IP) parsing.
+						   Those packets are expected
+						   to be delivered to QoS
+						   queues based on the
+						   VLAN/DSCP priority at the
+						   next stage so that some
+						   PASS actions such as IP
+						   reassembly and IP fragment
+						   exception route will be
+						   disabled. */
+#define PA2_DEST_SASS_LOC_DMA		11	/* Packet is routed to SA
+						   through local DMA */
+#define PA2_DEST_EFLOW			12	/* Packet is routed to Egress
+						   Flow Path */
+#define PA2_DEST_RES_1			20	/* Reseved destination for
+						   internal usage */
+#define PA2_DEST_RES_2			21	/* Reseved destination for
+						   internal usage */
+
+/* Multi Route */
+#define PA2_NO_MULTI_ROUTE		-1
+#define PA2_MAX_MULTI_ROUTE_SETS	32
+#define PA2_MAX_MULTI_ROUTE_ENTRIES	8
+
+#define PA2_MULTI_ROUTE_DESCRIPTOR_ONLY	0x01
+#define PA2_MULTI_ROUTE_REPLACE_SWINFO	0x02
+
+/* Egress FLOW Operation */
+#define PA2_EF_OP_CONTROL_FLAG_FC_LOOKUP	0x0001
+
+#define PA2_EF_OP_INFO_VALID_LVL1	0x0001
+#define PA2_EF_OP_INFO_VALID_LVL2	0x0002
+#define PA2_EF_OP_INFO_VALID_LVL3	0x0004
+#define PA2_EF_OP_INFO_VALID_LVL4	0x0008
+
+struct pa2_ef_op_info {
+	u16	ctrl_flags;	/* Specify Egress flow control flags as defined
+				   at paEfOpInfoCtrlFlags */
+	u16	valid_bitmap;	/* Specify valid parameters as defined at
+				   paEfOpInfoValidBit */
+	u16	lvl1_index;	/* Specify egress flow level 1 record index */
+	u16	lvl2_index;	/* Specify egress flow level 2 record index */
+	u16	lvl3_index;	/* Specify egress flow level 3 record index */
+	u16	lvl4_index;	/* Specify egress flow level 4 record index */
+};
+
+enum pa2_route_pri_info {
+	PA2_ROUTE_PRIORITY_VLAN = 1,	/* Route by using VLAN bits as pri */
+	PA2_ROUTE_PRIORITY_DSCP,	/* Route by using DSCP bits as pri */
+	PA2_ROUTE_INTF,			/* Route by using EMAC port (interface)
+					   number as destination queue offset */
+	PA2_ROUTE_INTF_W_FLOW		/* Route by using EMAC port (interface)
+					   number as both destination queue and
+					   CPPI flow offset */
+};
+
+/* EMAC Control */
+#define PA2_EMAC_CTRL_PORT_MASK		0x0F
+#define PA2_EMAC_CTRL_CRC_DISABLE	0x80
+
+/* Custom Classification Types */
+#define PA2_CUSTOM_TYPE_NONE		0
+#define PA2_CUSTOM_TYPE_LUT1		1
+#define PA2_CUSTOM_TYPE_LUT2		2
+#define PA2_MAX_CUSTOM_TYPES_LUT1	4
+#define PA2_MAX_CUSTOM_TYPES_LUT2	16
+
+/* Command Transmit Packet Destinations */
+#define PA2_CMD_TX_DEST_0	0  /* Packet is sent to INGRESS0/PDSP0 */
+#define PA2_CMD_TX_DEST_1	1  /* Packet is sent to INGRESS1/PDSP1 */
+#define PA2_CMD_TX_DEST_2	2  /* Packet is sent to INGRESS2/PDSP2 */
+#define PA2_CMD_TX_DEST_3	3  /* Packet is sent to INGRESS3/PDSP3 */
+#define PA2_CMD_TX_DEST_4	4  /* Packet is sent to INGRESS4/PDSP4 */
+#define PA2_CMD_TX_DEST_5	5  /* Packet is sent to POST/PDSP5 */
+#define PA2_CMD_TX_DEST_6	6  /* Packet is sent to EGRESS0 */
+#define PA2_CMD_TX_DEST_7	7  /* Packet is sent to EGRESS1 */
+#define PA2_CMD_TX_DEST_8	8  /* Packet is sent to EGRESS2 */
+
+/* PA Command Code */
+#define PA2_CMD_NONE			0
+#define PA2_CMD_NEXT_ROUTE		1
+#define PA2_CMD_CRC_OP			2
+#define PA2_CMD_COPY_DATA_TO_PSINFO	3
+#define PA2_CMD_PATCH_DATA		4
+#define PA2_CMD_TX_CHECKSUM		5
+#define PA2_CMD_MULTI_ROUTE		6
+#define PA2_CMD_REPORT_TX_TIMESTAMP	7
+#define PA2_CMD_REMOVE_HEADER		8
+#define PA2_CMD_REMOVE_TAIL		9
+#define PA2_CMD_CMDSET			10
+#define PA2_CMD_SA_PAYLOAD		11
+#define PA2_CMD_IP_FRAGMENT		12
+#define PA2_CMD_USR_STATS		13
+#define PA2_CMD_CMDSET_AND_USR_STATS	14
+#define PA2_CMD_PATCH_MSG_LEN		15
+#define PA2_CMD_VERIFY_PKT_ERROR	16
+#define PA2_CMD_SPLIT			17
+#define PA2_CMD_EF_OP			18
+
+struct pa2_frm_forward_host {
+	u32	context;	/* Context returned as swInfo0 for matched
+				   packet */
+/* Control bitmap, 1 for enable, 0 for disable
+ * // /------------------------------------------------------------------\
+ * // | 7                 |    |       2     |      1      |     0       |
+ * // | Selection         |    |DSCP priority|VLAN priority| multiRoute  |
+ * // | 0: Priority Select|    |             |    OR       |             |
+ * // | 1: IF Dest Select |    |             |Flow IF Dest |             |
+ * // \------------------------------------------------------------------/
+ */
+	u8	ctrl_bitmap;	/* True if multiple destination enabled */
+	u8	multi_idx;	/* Index of the multiple destination set */
+	u8	pa_pdsp_router; /* PA PDSP number used as multi-route router */
+	u8	ps_flags;	/* use the bit 7:4, bit 7: Disable CRC, bit 6:4
+				   port number (0/1/2), bit 3:0 errflags = 0 */
+	u8	cmd[4];		/* optional simple command: 0 means no
+				   command */
+}; /* 12 bytes */
+
+#define PA2FRM_MULTIROUTE_ENABLE		0x1
+#define PA2FRM_ROUTING_PRIORITY_DSCP_ENABLE	0x2
+#define PA2FRM_ROUTING_PRIORITY_VLAN_ENABLE	0x4
+#define PA2FRM_ROUTING_FLOW_IF_BASE_ENABLE	0x2 /* 0: queue-based only;
+						     1: queue- and flow-based */
+#define PA2FRM_ROUTING_IF_DEST_SELECT_ENABLE	0x80
+
+/* Routing information used to forward packets to the SA (via PKTDMA) */
+struct pa2_frm_forward_sa {
+	u32	sw_info_0;	/* Packet descriptor swInfo0 required by SA
+				   operation */
+	u32	sw_info_1;	/* Packet descriptor swInfo1 required by SA
+				   operation */
+	u8	cmd[4];		/* optional simple command: 0 means no
+				   command */
+};
+
+/* Routing information used to forward packets to the SRIO (via PKTDMA) */
+struct pa2_frm_forward_srio {
+	u32  ps_info0;		/* 8-byte protocol-specific information required
+				   by SRIO  */
+	u32  ps_info1;		/* routing */
+	u8   pkt_type;		/* Packet type specified for SRIO operation */
+	u8   rsv4[3];
+};
+
+/* Routing information used to forward packets to the Ethernet port */
+struct pa2_frm_forward_eth {
+	u8	ps_flags;	/* use the bit 7:4 bit 7: Disable CRC, bit 6:4
+				   port number (0/1/2), bit 3:0 errflags = 0*/
+	u8	priority;
+	u16	rsvd2;
+	u32	rsvd3;
+	u8	cmd[4];
+};
+
+#define PA2FRM_ETH_PS_FLAGS_DISABLE_CRC		0x80
+#define PA2FRM_ETH_PS_FLAGS_PORT_MASK		PA2_EMAC_CTRL_PORT_MASK
+#define PA2FRM_ETH_PS_FLAGS_PORT_SHIFT		0
+
+
+/* Routing information used to forward packets within PA */
+struct pa2_frm_forward_pa {
+	u8	pa_dest;      /* PDSP destination */
+	u8	custom_type;  /* None, LUT1, LUT2 */
+	u8	custom_idx;   /* Index of the custom type if LUT1 or LUT2
+				 custom */
+	u8	flags;
+	u32	rsvd1;
+	u8	cmd[4];
+};
+
+#define PA2FRM_CASCADED_FORWARDING	0x01
+#define PA2FRM_PA_CTRL_PKT_MARK		0x02  /* Mark the entry per ACL rule */
+#define PA2FRM_PA_CTRL_PKT_DROP		0x04  /* Indicate that the packet should
+						 be dropped after reassembly per
+						 ACL rule */
+
+/* Routing information used to forward packets in egress flow */
+struct pa2_frm_forward_ef {
+	u8	ctrl_flags;	/* various control flags */
+	u8	valid_bitmap;	/* Egress record valid bit map, if flow cache
+				   lookup is not enabled */
+	u16	rsvd1;		/* reserved for alignment */
+	u8	lvl1_rec_idx;	/* Egress Flow level one record index */
+	u8	lvl2_rec_idx;	/* Egress Flow level two record index */
+	u8	lvl3_rec_idx;	/* Egress Flow level three record index */
+	u8	lvl4_rec_idx;	/* Egress Flow level four record index */
+	u32	rsvd2;
+};
+
+#define PA2FRM_EF_CTRL_FC_LOOKUP		0x01	/* Flow Cache lookup */
+#define PA2FRM_EF_VALID_REC_LVL1		0x01
+#define PA2FRM_EF_VALID_REC_LVL2		0x02
+#define PA2FRM_EF_VALID_REC_LVL3		0x04
+#define PA2FRM_EF_VALID_REC_LVL4		0x08
+
+/* Routing information used to drop the packet */
+struct pa2_frm_discard {
+	u32	rsvd1;
+	u32	rsvd2;
+	u8	cmd[4];
+};
+
+#define PA2FRM_CUSTOM_TYPE_NONE		PA2_CUSTOM_TYPE_NONE	/* 0 */
+#define PA2FRM_CUSTOM_TYPE_LUT1		PA2_CUSTOM_TYPE_LUT1	/* 1 */
+#define PA2FRM_CUSTOM_TYPE_LUT2		PA2_CUSTOM_TYPE_LUT2	/* 2 */
+
+/* Routing information used to forward packets fromm PA sub-system to various
+ * destinations */
+struct pa2_frm_forward  {
+	u8 forward_type;	/* Forwarding type as defined below */
+	u8 flow_id;		/* PKTDMA flow Id, valid if forwarding via
+				   PKTDMA */
+	u16 queue;		/* Destination queue number, valid if forwarding
+				   via PKTDMA */
+	union {
+		struct pa2_frm_forward_host	host;    /* Host specific
+							    routing
+							    information */
+		struct pa2_frm_forward_sa	sa;      /* SA specific routing
+							    information */
+		struct pa2_frm_forward_srio	srio;    /* SRIO specific
+							    routing
+							    information */
+		struct pa2_frm_forward_eth	eth;     /* Ethernet specific
+							    routing
+							    information */
+		struct pa2_frm_forward_pa	pa;      /* PA internal routing
+							    information */
+		struct pa2_frm_forward_ef	ef;      /* PA Egress Flow
+							    information */
+		struct pa2_frm_discard		discard; /* Discard specific
+							    routing
+							    information */
+	} u;
+};
+
+enum {
+	PA2FRM_FORWARD_TYPE_HOST = 0,	/* use PA2FRM_DEST_CDMA */
+	PA2FRM_FORWARD_TYPE_SA,		/* use PA2FRM_DEST_CDMA */
+	PA2FRM_FORWARD_TYPE_PA,		/* use pa.paDest */
+	PA2FRM_FORWARD_TYPE_ETH,	/* use PA2FRM_DEST_ETH */
+	PA2FRM_FORWARD_TYPE_SRIO,	/* use PA2FRM_DEST_CDMA */
+	PA2FRM_FORWARD_TYPE_SA_DIRECT,	/* use flowId as stream ID  */
+	PA2FRM_FORWARD_TYPE_DISCARD,
+	PA2FRM_FORWARD_TYPE_EFLOW
+};
+
+#define PA2FRM_FORWARD_CONTROL_USE_LOC_DMA	0x80	/* SASS only: Use local
+							   DMA */
+#define PA2FRM_FORWARD_TYPE_MASK		0x0F
+
+/* LUT1 classification mode */
+#define PA2FRM_LUT1_CLASS_NONE		0
+#define PA2FRM_LUT1_CLASS_STANDARD	1
+#define PA2FRM_LUT1_CLASS_IPV4		2
+#define PA2FRM_LUT1_CLASS_IPV6		3
+#define PA2FRM_LUT1_CLASS_IPSEC		PA2FRM_LUT1_CLASS_IPV6
+
+#define PA2FRM_LUT1_CLASS_SHIFT		30	/*  Care0 [31:30] */
+
+/* LUT1 Range mode fot two range parameters */
+#define PA2FRM_LUT1_RANGE_MODE_NORMAL	0	/* Normal comparsion */
+#define PA2FRM_LUT1_RANGE_MODE_RANGE	1	/* Use RangeLo and RangeHi for
+						   range compare */
+#define PA2FRM_LUT1_RANGE_MODE_NOT	2	/* NOT comparsion */
+
+#define PA2FRM_LUT1_CLASS_SHIFT0	28	/* Care0 [29:28]: Byte 42-43*/
+#define PA2FRM_LUT1_CLASS_SHIFT1	26	/* Care0 [27:26]: Byte 44-45*/
+
+/* LUT1 NOT operation for byte 41 */
+#define PA2FRM_LUT1_CMP_OP_NORMAL	0	/* Normal Comparsion */
+#define PA2FRM_LUT1_CMP_OP_NOT		1	/* Not cpmpare (byte 41) */
+
+#define PA2FRM_LUT1_CMP_OP_SHIFT	25	/* Care 0 [25]: Byte 41 */
+
+
+/* LUT1 Entries (MAC/SRIO/Custom) */
+/* Layer 2 packet Type */
+#define PA2FRM_L2_PKT_TYPE_MAC		0x80
+#define PA2FRM_L2_PKT_TYPE_SRIO		0x40
+#define PA2FRM_L2_PKT_TYPE_CUSTOM	0x20
+
+#define PA2FRM_LUT1_VALID_DMAC_ALL   0x001F8000  /* Care0: [20:15] byte 4-9 */
+#define PA2FRM_LUT1_VALID_DMAC_MINUS_BYTE5 0x001F0000
+#define PA2FRM_LUT1_VALID_SMAC	    0x00007E00  /* Care0: [14:9]  byte 10-15 */
+#define PA2FRM_LUT1_VALID_ETHERTYPE  0x00000180  /* Care0: [8:7]   byte 16-17 */
+#define PA2FRM_LUT1_VALID_SESSION_ID 0x00000060  /* Care0: [6:5]   byte 18-19 */
+#define PA2FRM_LUT1_VALID_MPLS	    0x0000001E  /* Care0: [4:1]   byte 20-23 */
+#define PA2FRM_LUT1_VALID_PKTFLAGS   0x01000000  /* Care0: [24:24] Byte 0 */
+#define PA2FRM_LUT1_VALID_DMAC5	    0x00800000  /* Care0: [23:23] Byte 1 */
+
+#define PA2FRM_LUT1_VALID_VLANID1    0x00180000  /* Care1: [20:19] Byte 36-37 */
+#define PA2FRM_LUT1_VALID_VLANID2    0x00060000  /* Care1: [18:17] Byte 38-39 */
+#define PA2FRM_LUT1_VALID_PKTTYPE    0x00010000  /* Care1: [16:16] Byte 40    */
+#define PA2FRM_LUT1_VALID_INPORT    0x00008000  /* Care1: [15:15] Byte 41    */
+#define PA2FRM_LUT1_VALID_VLAN_PRI1  0x00006000  /* Care1: [14:13] Byte 42-43 */
+#define PA2FRM_LUT1_VALID_VLAN_PRI2  0x00001800  /* Care1: [12:11] Byte 44-45 */
+#define PA2FRM_LUT1_VALID_SRC_VC    0x00000600  /* Care1: [10: 9] Byte 46-47 */
+
+#define PA2FRM_MK_SRC_VC(pdsp, lutIndex)	(((pdsp) << 10) + (lutIndex))
+#define PA2FRM_GET_PDSPID_FROM_LINK(lnk)	((lnk) >> 10)
+#define PA2FRM_GET_LUTIDX_FROM_LINK(lnk)	((lnk) & 0x3FF)
+
+/* Add MAC entry to LUT1 */
+struct pa2_frm_com_l1_mac {
+	/* LUT1 view 1 */
+	u8	dmac[6];	/* Destination mac */
+	u8	smac[6];	/* Source mac */
+	u16	etype;		/* Ethernrt type, the field is also used for the
+				   previous match PDSP number */
+	u16	session_id;	/* PPPoE session ID */
+
+	/* LUT1 view 2 */
+	u32	mpls;		/* MPLS label */
+	u32	rsvd2_2;
+	u32	rsvd2_3;
+	u32	rsvd2_4;
+
+	/* LUT1 view 3 */
+	u8	pkt_flags;     /* Various packet flags */
+#define PA2FRM_MAC_FLAG_VLAN1		0x01
+#define PA2FRM_MAC_FLAG_VLAN2		0x02
+#define PA2FRM_MAC_FLAG_MCAST		0x04
+#define PA2FRM_MAC_FLAG_BCAST		0x08
+#define PA2FRM_MAC_FLAG_PPPoE		0x10
+#define PA2FRM_MAC_FLAG_802p3		0x20
+#define PA2FRM_MAC_FLAG_MPLS		0x40
+
+	u8	dst_mac5;	/* Destination MAC address if bitMask is
+				   required */
+	u16	rsvd4;
+	u16	vlan_id1;	/* 12-bit ID of inner VLAN (0x8100) */
+	u16	vlan_id2;	/* 12-bit ID of outer VLAN */
+	u8	pkt_type;	/* Common filed to indicate packet type */
+	u8	in_port;	/* One-base input EMAC port number */
+	u16	vlan_pri1;	/* 3-bit priority of inner VLAN (0x8100) */
+	u16	vlan_pri2;	/* 3-bit priority of outer VLAN */
+	u16	src_vc;		/* virtual or physical link */
+};
+
+struct pa2_frm_com_l1_srio {
+	/* LUT1 view 1 */
+	u32	rsvd1[4];		/* unused field: All zero's */
+
+	/* LUT1 view 2 */
+	u16	next_hdr_offset;	/* place holder for nextHdr and
+					   nextOffset not used for
+					   classification */
+	u8	next_hdr;
+	u8	rsvd2_1;
+	u32	rsvd2_2;
+	u32	rsvd2_3;
+	u32	rsvd2_4;
+
+	/* LUT1 view 3 */
+	u8	pkt_flags;	/* Various packet flags */
+#define PA2FRM_SRIO_FLAG_TYPE9		0x01
+#define PA2FRM_SRIO_FLAG_TYPE11		0x02
+#define PA2FRM_SRIO_FLAG_PORT8		0x04
+
+	u8	type_param2;    /* cos or letter */
+	u16	type_param1;    /* stream ID or mailbox */
+	u16	src_id;		/* Device Source ID */
+	u16	dest_id;	/* Device Destination ID */
+	u8	pkt_type;	/* Common filed to indicate packet type */
+	u8	cc;		/* Completion code */
+	u16	pri;		/* 3-bit priority */
+	u16	rsvd3_1;
+	u16	src_vc;		/* virtual or physical link */
+};
+
+struct pa2_frm_com_l1_custom {
+	/* LUT1 view 1 & 2 */
+	u8	match[32];
+
+	/* LUT1 view 3 - offset from start */
+	u32	rsvd3_1;
+	u32	rsvd3_2;
+	u8	pkt_type;	/* Common filed to indicate packet type */
+	u8	rsvd3_3;
+	u16	rsvd3_4;
+	u16	rsvd3_5;
+	u16	src_vc;		/* virtual or physical link */
+};
+
+struct pa2_frm_com_l1_ipv4 {
+	/* LUT1 view 1 */
+	u32	dst_ip;		/* Destination IP address */
+	u32	src_ip;		/* Source IP address */
+	u32	rsvd1_3;
+	u32	rsvd1_4;
+
+	/* LUT1 view 2 */
+	u32	rsvd2_1;
+	u32	rsvd2_2;
+	u32	rsvd2_3;
+	u32	rsvd2_4;
+
+	/* LUT1 view 3 */
+	u16	pkt_flags;	/* Various packet flags */
+#define PA2FRM_IP_FLAG_IP_TYPE		0x8000
+#define PA2FRM_IP_FLAG_V4		0x8000
+#define PA2FRM_IP_FLAG_GRE		0x4000
+#define PA2FRM_IP_FLAG_SCTP		0x2000
+#define PA2FRM_IP_FLAG_TCP_DATA		0x1000
+#define PA2FRM_IP_FLAG_OPTIONS		0x0800
+#define PA2FRM_IP_FLAG_FRAG		0x0400
+#define PA2FRM_IP_FLAG_CONTAIN_L4	0x0200
+#define PA2FRM_IP_FLAG_HOP_LIMIT	0x0100
+#define PA2FRM_IP_FLAG_IPSEC		0x0080
+
+	u8	dscp;
+	u8	rsvd3_1;
+	u32	rsvd3_2;
+	u8	pkt_type;	/* Common filed to indicate packet type */
+	u8	protocol;	/* Next Layer protocol */
+	u16	src_port;	/* Layer 4 source port number */
+	u16	dst_port;	/* Layer 4 destination port number */
+	u16	src_vc;		/* virtual or physical link */
+};
+
+struct pa2_frm_com_l1_ipv6 {
+	/* LUT1 view 1 */
+	u32	src_ip0;	/* Source IP address */
+	u32	src_ip1;
+	u32	src_ip2;
+	u32	src_ip3;
+
+	/* LUT1 view 2 */
+	u32	dst_ip0;	/* Destination IP address */
+	u32	dst_ip1;
+	u32	dst_ip2;
+	u32	dst_ip3;
+
+	/* LUT1 view 3 */
+	u16	pkt_flags;	/* Various packet flags */
+#define PA2FRM_IP_FLAG_V6	0x4000
+	u8	dscp;
+	u8	rsvd8a;
+	u32	flow_label;	/* 20-bit Flow Label in the header */
+	u8	pkt_type;	/* Common filed to indicate packet type */
+	u8	protocol;	/* Next Layer protocol */
+	u16	src_port;	/* Layer 4 source port number */
+	u16	dst_port;	/* Layer 4 destination port number */
+	u16	src_vc;		/* virtual or physical link */
+};
+
+struct pa2_frm_com_l1_ipsec  {
+	/* LUT1 view 1 */
+	u32	rsvd1_1;
+	u32	rsvd1_2;
+	u32	rsvd1_3;
+	u32	rsvd1_4;
+
+	/* LUT1 view 2 */
+	u32	rsvd2_1;
+	u32	rsvd2_2;
+	u32	rsvd2_3;
+	u32	rsvd2_4;
+
+	/* LUT1 view 3 */
+	u16	pkt_flags;	/* Various packet flags */
+#define PA2FRM_IPSEC_FLAG_ESP	0x8000
+#define PA2FRM_IPSEC_FLAG_AH	0x4000
+	u16	rsvd3_1;
+	u32	spi;		/* SPI value */
+	u8	pkt_type;	/* Common filed to indicate packet type */
+	u8	rsvd3_2;
+	u16	rsvd3_3;
+	u16	rsvd3_4;
+	u16	src_vc;		/* virtual or physical link */
+} ;
+
+enum {
+	PA2FRM_CONFIG_COMMAND_RSVD	= 0,
+	PA2FRM_CONFIG_COMMAND_ADDREP_LUT1,
+	PA2FRM_CONFIG_COMMAND_DEL_LUT1,
+	PA2FRM_CONFIG_COMMAND_ADDREP_LUT2,
+	PA2FRM_CONFIG_COMMAND_DEL_LUT2,
+	PA2FRM_CONFIG_COMMAND_CONFIG_PA,
+	PA2FRM_CONFIG_COMMAND_REQ_STATS,
+	PA2FRM_CONFIG_COMMAND_REQ_VERSION,
+	PA2FRM_CONFIG_COMMAND_MULTI_ROUTE,
+	PA2FRM_CONFIG_COMMAND_CRC_ENGINE,
+	PA2FRM_CONFIG_COMMAND_CMD_SET,
+	PA2FRM_CONFIG_COMMAND_CMD_USR_STATS,
+	PA2FRM_CONFIG_COMMAND_CMD_SYS_CONFIG,
+	PA2FRM_CONFIG_COMMAND_CMD_MULTI_CMDS
+};
+
+/* Command magic value */
+#define PA2FRM_CONFIG_COMMAND_SEC_BYTE  0xce
+
+/* Command return values */
+enum {
+	PA2FRM_COMMAND_RESULT_SUCCESS = 0,		/* Must be 0 */
+	PA2FRM_COMMAND_RESULT_NO_COMMAND_MAGIC,		/* Command magic value
+							   not found */
+
+	PA2FRM_COMMAND_RESULT_INVALID_CMD,		/* Invalid command
+							   identifier */
+
+	/* Add entry to LUT1 fails */
+	PA2FRM_COMMAND_RESULT_LUT1_TYPE_INVALID,	/* Invalid type, custom
+							   or standard
+							   IP/ethernet */
+	PA2FRM_COMMAND_RESULT_LUT1_INDEX_INVALID,	/* Invalid LUT1 index
+							   (0-63) or no free
+							   indices available */
+	PA2FRM_COMMAND_RESULT_LUT1_MATCH_DEST_INVALID,	/* Sent a match packet
+							   to q0 on c1 or c2 -
+							   this is illegal. */
+	PA2FRM_COMMAND_RESULT_LUT1_NMATCH_INVALID,	/* Previous match fwd
+							   info was somewhere in
+							   chunk domain */
+	PA2FRM_COMMAND_RESULT_LUT1_INVALID_KEYS,	/* Invalid combination
+							   found in the key
+							   value */
+
+	/* Lut 2 entry warnings since the lut can be configured without pdsp */
+	PA2FRM_COMMAND_RESULT_WARN_OVER_MAX_ENTRIES,
+	PA2FRM_COMMAND_RESULT_WARN_NEGATIVE_ENTRY_COUNT,
+
+	/* Lut 2 entry failures */
+	PA2FRM_COMMAND_RESULT_LUT2_ADD_BUSY,		/* LUT2 had a lookup and
+							   pending config */
+
+	/* Not enough room in stats request packet for the reply */
+	PA2FRM_COMMAND_RESULT_WARN_STATS_REPLY_SIZE,
+
+	/* Command sent to PDSP which couldn't handle it */
+	PA2FRM_COMMAND_RESULT_INVALID_DESTINATION,
+
+	/* Add/Delete/Read entries to multi route table */
+	PA2FRM_COMMAND_RESULT_MULTI_ROUTE_NO_FREE_ENTRIES, /* Asked to use a
+							     free entry, but
+							     none found */
+	PA2FRM_COMMAND_RESULT_MULTI_ROUTE_INVALID_IDX,	/* Illegal index value
+							   used */
+	PA2FRM_COMMAND_RESULT_MULTI_ROUTE_INVALID_MODE,	/* Illegal multi route
+							   mode used */
+
+	/* Packet size didn't match command */
+	PA2FRM_COMMAND_RESULT_INVALID_PKT_SIZE,
+
+	/* Coustom and Command set index */
+	PA2FRM_COMMAND_RESULT_INVALID_C1_CUSTOM_IDX,	/* Illegal Custom LUT1
+							   index value used */
+	PA2FRM_COMMAND_RESULT_INVALID_C2_CUSTOM_IDX,	/* Illegal Custom LUT2
+							   index value used */
+	PA2FRM_COMMAND_RESULT_INVALID_CMDSET_IDX,	/* Illegal Custom Cmd
+							   Set index value
+							   used */
+	PA2FRM_COMMAND_RESULT_USR_STATS_INVALID_CONFIG	/* Illegal User Stats
+							   Configuration */
+};
+
+/* Destination (route) values */
+#define PA2FRM_DEST_CDMA0	0	/* Packets to Global CDMA */
+#define PA2FRM_DEST_CDMA1	1	/* Packets to Local CDMA */
+#define PA2FRM_DEST_ETHERNET1	2	/* Packets to Ethernet TX */
+#define PA2FRM_DEST_ETHERNET2	3	/* Packets to Ethernet TX */
+#define PA2FRM_DEST_ETHERNET3	4	/* Packets to Ethernet TX */
+#define PA2FRM_DEST_ETHERNET4	5	/* Packets to Ethernet TX */
+#define PA2FRM_DEST_ETHERNET5	6	/* Packets to Ethernet TX */
+#define PA2FRM_DEST_ETHERNET6	7	/* Packets to Ethernet TX */
+#define PA2FRM_DEST_ETHERNET7	8	/* Packets to Ethernet TX */
+#define PA2FRM_DEST_ETHERNET8	9	/* Packets to Ethernet TX */
+#define PA2FRM_DEST_INGRESS0	10	/* Packets to Cluster Ingress 0 */
+#define PA2FRM_DEST_INGRESS1	11	/* Packets to Cluster Ingress 1 */
+#define PA2FRM_DEST_INGRESS2	12	/* Packets to Cluster Ingress 2 */
+#define PA2FRM_DEST_INGRESS3	13	/* Packets to Cluster Ingress 3 */
+#define PA2FRM_DEST_INGRESS4	14	/* Packets to Cluster Ingress 4 */
+#define PA2FRM_DEST_POST	15	/* Packets to Cluster Post
+					   Processings */
+#define PA2FRM_DEST_EGRESS0	16	/* Packets to Cluster Egress 0 */
+#define PA2FRM_DEST_EGRESS1	17	/* Packets to Cluster Egress 1 */
+#define PA2FRM_DEST_EGRESS2	18	/* Packets to Cluster Egress 2 */
+#define PA2FRM_DEST_REASM	19	/* Packets to Reasm Accelerator */
+#define PA2FRM_DEST_ACE0	20	/* Placeholder for model */
+#define PA2FRM_DEST_ACE1	21	/* Placeholder for model */
+#define PA2FRM_DEST_STATSBLOC	22	/* Packets to Statsbloc */
+
+#define PA2FRM_DEST_PKTDMA	PA2FRM_DEST_CDMA0
+#define PA2FRM_DEST_PKTDMA_LOC	PA2FRM_DEST_CDMA1
+#define PA2FRM_DEST_ETH		PA2FRM_DEST_ETHERNET1
+
+#define PA2FRM_DEST_DISCARD	0xff
+
+/* Assigning names based on PDSP functions */
+#define PA2FRM_DEST_PA_C1_0	PA2FRM_DEST_INGRESS0
+#define PA2FRM_DEST_PA_C1_1	PA2FRM_DEST_INGRESS1
+#define PA2FRM_DEST_PA_C1_2	PA2FRM_DEST_INGRESS4
+#define PA2FRM_DEST_PA_C2	PA2FRM_DEST_INGRESS4
+#define PA2FRM_DEST_PA_M_0	PA2FRM_DEST_POST
+#define PA2FRM_DEST_PA_M_1	PA2FRM_DEST_EGRESS2
+
+/* The default queue for packets that arrive at the PA and don't match in
+ * classify1 (right at init time) */
+#define PA2FRM_DEFAULT_INIT_Q	0x100
+
+/* Ethertypes recognized by the firmware. */
+#define PA2FRM_ETHERTYPE_IP		0x0800
+#define PA2FRM_ETHERTYPE_IPV6		0x86dd
+#define PA2FRM_ETHERTYPE_VLAN		0x8100
+#define PA2FRM_ETHERTYPE_SPVLAN		0x88a8
+#define PA2FRM_ETHERTYPE_MPLS		0x8847
+#define PA2FRM_ETHERTYPE_MPLS_MULTI	0x8848
+
+/* Next header type values  */
+#define PA2FRM_HDR_MAC			0
+#define PA2FRM_HDR_VLAN			1
+#define PA2FRM_HDR_MPLS			2
+#define PA2FRM_HDR_IPv4			3
+#define PA2FRM_HDR_IPv6			4
+#define PA2FRM_HDR_IPv6_EXT_HOP		5
+#define PA2FRM_HDR_IPv6_EXT_ROUTE	6
+#define PA2FRM_HDR_IPv6_EXT_FRAG	7
+#define PA2FRM_HDR_IPv6_EXT_DEST	8
+#define PA2FRM_HDR_GRE			9
+#define PA2FRM_HDR_ESP			10
+#define PA2FRM_HDR_ESP_DECODED		11
+#define PA2FRM_HDR_AUTH			12
+#define PA2FRM_HDR_CUSTOM_C1		13
+#define PA2FRM_HDR_FORCE_LOOKUP		14   /* A contrived header type used
+						with custom SRIO to force a
+						parse after looking at only
+						the RIO L0-L2 */
+#define PA2FRM_HDR_SCTP			15
+#define PA2FRM_HDR_UNKNOWN		16
+#define PA2FRM_HDR_UDP			17
+#define PA2FRM_HDR_UDP_LITE		18
+#define PA2FRM_HDR_TCP			19
+#define PA2FRM_HDR_GTPU			20
+#define PA2FRM_HDR_ESP_DECODED_C2	21
+#define PA2FRM_HDR_CUSTOM_C2		22
+
+/* Command related definitions */
+#define PA2FRM_CRC_FLAG_CRC_OFFSET_VALID	0x01
+#define PA2FRM_CRC_FLAG_CRC_OFFSET_FROM_DESC	0x02
+#define PA2FRM_CHKSUM_FALG_NEGATIVE		0x01
+
+#define PA2_NEXT_ROUTE_PARAM_PRESENT		0x0001
+#define PA2_NEXT_ROUTE_PROC_NEXT_CMD		0x0002
+#define PA2_NEXT_ROUTE_PROC_MULTI_ROUTE		0x0004
+
+/* PAFRM receive commands related definitions */
+
+/*
+ * There are the following two groups of PAFRM receive commands:
+ * PAFRM short commands which can be used as part of the routing info
+ * PAFRM commands which can be used within a command set
+ */
+#define PA2FRM_RX_CMD_NONE		0	/* Dummy command */
+
+/* short commands */
+#define PA2FRM_RX_CMD_CMDSET		1	/* Execute a command set */
+#define PA2FRM_RX_CMD_INSERT		2	/* Insert up to two types at the
+						   current location */
+#define PA2FRM_RX_CMD_USR_STATS         3	/* Increment the specific
+						   user-statistics chain */
+#define PA2FRM_RX_CMD_CMDSET_USR_STATS	4	/* Increment User-defined Stats
+						   chain and  execute \
+						   the command set */
+
+/* command set commands */
+#define PA2FRM_RX_CMD_NEXT_ROUTE	11	/* Specify the next route */
+#define PA2FRM_RX_CMD_CRC_OP		12	/* CRC generation or
+						   verification */
+#define PA2FRM_RX_CMD_COPY_DATA		13	/* Copy data to the PS Info
+						   section */
+#define PA2FRM_RX_CMD_PATCH_DATA	14	/* Insert or pacth packet data
+						   at the specific location */
+#define PA2FRM_RX_CMD_REMOVE_HDR	15	/* Remove the parsed packet
+						   header */
+#define PA2FRM_RX_CMD_REMOVE_TAIL	16	/* Remove the parsed packet
+						   tail */
+#define PA2FRM_RX_CMD_MULTI_ROUTE	17	/* Duplicate packet to multiple
+						   destinations */
+#define PA2FRM_RX_CMD_VERIFY_PKT_ERROR	18	/* Verify packet error based on
+						   error flags */
+#define PA2FRM_RX_CMD_SPLIT		19	/* Payload splitting */
+
+/* define LUT1 entry types */
+#define PA2FRM_COM_ADD_LUT1_STANDARD	0	/* MAC/IP/IPSEC/ACL/FC */
+#define PA2FRM_COM_ADD_LUT1_SRIO	1	/* SRIO */
+#define PA2FRM_COM_ADD_LUT1_CUSTOM	2	/* Custom LUT1 */
+#define PA2FRM_COM_ADD_LUT1_VLINK	3	/* Standard entry with virtual
+						   Link */
+
+/* LUT1 Entries */
+/* if PA2_LUT1_INDEX_LAST_FREE is used then when the command returns,
+ * the value of index will be replaced with the actual index used */
+#define PA2FRM_HW_LUT1_ENTRIES		256
+#define PA2FRM_LUT1_INDEX_LAST_FREE	PA2FRM_HW_LUT1_ENTRIES
+
+struct pa2_frm_cmd_add_lut1 {
+	u16	index;		/* LUT1 index. */
+	u8	type;		/* Custom or standard */
+	u8	cust_index;	/* Vaild only if type is custom */
+	u16	vlink_num;	/* Virtual Link number if used */
+	u16	stats_index;	/* entry statistics index (Flow Cache only) */
+
+	/* LUT1 views */
+	union {
+		struct pa2_frm_com_l1_mac	mac;   /* matching information
+							  for MAC/IP entry */
+		struct pa2_frm_com_l1_srio	srio;
+		struct pa2_frm_com_l1_custom	custom;
+		struct pa2_frm_com_l1_ipv4	ipv4;	/* matching information
+							   for IPv4 entry*/
+		struct pa2_frm_com_l1_ipv6	ipv6;	/* matching information
+							   for IPv6 entry */
+		struct pa2_frm_com_l1_ipsec	ipsec;	/* matching information
+							   for IPSEC entry */
+	} u;
+
+	/* Command header */
+	u16	range1_hi;	/* Range High for bytes 44-45 */
+	u16	range0_hi;	/* Range High for bytes 42-43 */
+	u32	cbwords0;	/* Care Bits Word0 */
+	u32	cbwords1;	/* Care Bits Word1 */
+	u16	bit_mask;	/* BitMask for Bytes 0-1 */
+	u16	priority;	/* Record priority "score", relative index */
+
+	struct pa2_frm_forward match;	/* Routing information when a match is
+					   found */
+
+	/*
+	 * Routing information when subsequent match fails - a fragmented
+	 * packet orinner route
+	 */
+	struct pa2_frm_forward next_fail;
+};
+
+/* PA CRC Engine Instance Destinations */
+enum pa2_crc_inst {
+	PA2_CRC_INST_0_0 = 0,	/* CRC Engine between Ingress0, CDE0 and CED1 */
+	PA2_CRC_INST_1_0,	/* CRC Engine between Ingress1, CDE0 and CED1 */
+	PA2_CRC_INST_4_0,	/* Engine between Ingress4, CDE0 and CED1 */
+	PA2_CRC_INST_5_0,	/* Engine between Post, CDE0 and CED1 */
+	PA2_CRC_INST_6_0,	/* Engine between Egress0, CDE0 and CED1 */
+	PA2_CRC_INST_6_1,	/* Engine between Egress0, CDE1 and CED2 */
+	PA2_CRC_INST_MAX
+};
+
+#define PARAM_CRC_TABLE_SIZE    16
+
+enum pa2_crc_size {
+	PA2_CRC_SIZE_8 = 0,	/* 8-bit CRC */
+	PA2_CRC_SIZE_16,		/* 16-bit CRC */
+	PA2_CRC_SIZE_24,		/* 24-bit CRC */
+	PA2_CRC_SIZE_32		/* 32-bit CRC */
+};
+
+struct pa2_crc_config {
+	u16			ctrl_bits;	/* CRC configuration control
+						   info as defined below */
+/* Set: Right shift CRC (b0 to b7), Clear: Left shift CRC (b7 to b0) */
+#define PA2_CRC_CONFIG_RIGHT_SHIFT	0x0001
+/* Set: a 'NOT' operation is applied to the final CRC result */
+#define PA2_CRC_CONFIG_INVERSE_RESULT	0x0002
+
+	enum pa2_crc_size	size;
+	u32			polynomial;	/* CRC polynomial in the format
+						   of 0xabcdefgh. For example,
+						   x32+x28+x27+x26+x25+x23+x22+
+						   x20+x19+x18+x14+x13+x11+x10+
+						   x9+x8+x6+1 ==> 0x1EDC6F41
+						   x16+x15+x2+1 ==>0x80050000 */
+	u32			init_value;	/* CRC initial value */
+};
+
+
+struct pa2_frm_config_crc {
+	u8	ctrl_bitmap;			/* Control bit maps as defined
+						   below */
+#define PARAM_CRC_CTRL_CRC_SIZE_MASK    0x3
+#define PARAM_CRC_CTRL_LEFT_SHIFT       0x0
+#define PARAM_CRC_CTRL_RIGHT_SHIFT      0x4
+#define PARAM_CRC_CTRL_INV_RESULT       0x8
+
+	u8	rsvd1;				/* reserved for alignment */
+	u16	rsvd2;				/* reserved for alignment */
+	u32	init_val;			/* Initial value to use in the
+						   CRC calcualtion */
+	u32	crc_tbl[PARAM_CRC_TABLE_SIZE];	/* CRC table */
+};
+
+#define PA2FRM_CFG_CMD_STATUS_PROC	0
+#define PA2FRM_CFG_CMD_STATUS_DONE	1
+
+struct pa2_frm_command_cmd_hdr {
+	u8	command;	/* Command Header of each command within the
+				   multiple command packet */
+	u8	offset;		/* Offset to the next command, 0: Indicate the
+				   last command */
+	u16	comId;		/* general parameter used by host only */
+};
+
+
+/* Commands to PA */
+struct pa2_frm_command {
+	u8	status;		/* Command Status (used by firmware only) */
+	u8	pdsp_index;	/* index of the first targeted PDSP in a
+				  clsuter */
+	u16	command_result;	/* Returned to the host, ignored on entry to the
+				   PASS */
+	u16	com_id;		/* Used by the host to identify command
+				   results */
+	u8	command;	/* Command value */
+	u8	magic;		/* Magic value */
+	u32	ret_context;	/* Returned in swInfo to identify packet as a
+				   command */
+	u16	reply_queue;	/* Specifies the queue number for the message
+				   reply. 0xffff to toss the reply */
+	u8	reply_dest;	/* Reply destination (host0, host1, discard are
+				   the only valid values) */
+	u8	flow_id;	/* Flow ID used to assign packet at reply */
+	u32	cmd;		/* First word of the command */
+};
+
+struct pa2_cmd_next_route {
+	u16	ctrl_bit_field;		/* Routing control information as
+					   defined at routeCtrlInfo */
+	int	dest;			/* Packet destination as defined at
+					   pktDest */
+	u8	pkt_type_emac_ctrl;	/* For destination SRIO, specify the
+					   5-bit packet type toward SRIO for
+					   destination EMAC, specify the EMAC
+					   control @ref emcOutputCtrlBits to
+					   the network */
+	u8	flow_id;		/* For host, SA or SRIO destinations,
+					   specifies return free descriptor
+					   setup */
+	u16	queue;			/* For host, SA or SRIO destinations,
+					   specifies the dest queue */
+	u32	sw_info_0;		/* Placed in SwInfo0 for packets to
+					   host or SA */
+	u32	sw_info_1;		/* Placed in SwInfo1 for packets to
+					   the SA */
+	u16	multi_route_index;	/* Multi-route index. It is valid in the
+					   from-network direction only */
+	u16	statsIndex;		/* Index of the first user-defined
+					   statistics to be updated. This
+					   optional parameter is valid in the
+					   to-network direction only */
+};
+
+struct pa2_cmd_crcOp {
+	u16	ctrl_bit_field;		/* CRC operation control information as
+					   defined at @ref crcOpCtrlInfo */
+	u16	start_offset;		/* Byte location, from SOP/Protocol
+					   Header, where the CRC computation
+					   begins if frame type is not specified
+					   Byte location, from SOP/Protocol
+					   header, where the specific frame
+					   header begins if frame type is
+					   specified In to-network direction:
+					   offset from SOP In from-network
+					   direction: offset from the current
+					   parsed header */
+	u16	len;			/* Number of bytes covered by the CRC
+					   computation valid only if
+					   pa_CRC_OP_PAYLOAD_LENGTH_IN_HEADER
+					   is clear */
+	u16	len_offset;		/* Payload length field offset in the
+					   custom header */
+	u16	len_mask;		/* Payload length field mask */
+	u16	len_adjust;		/* Payload length adjustment: valid only
+					  if PA2_CRC_OP_PAYLOAD_LENGTH_IN_HEADER
+					   is set */
+	u16	crc_offset;		/* Offset from SOP/Protocol Header to
+					   the CRC field In to-network
+					   direction: offset from SOP In
+					   from-network direction: offset from
+					   the current parsed header */
+	u16	crcSize;		/* Size of CRC in bytes */
+	u16	frame_yype;		/* Frame type @ref crcFrameTypes, vaild
+					  if PA2_CRC_OP_CRC_FRAME_TYPE is set */
+	u32	initValue;		/* CRC initial value */
+};
+
+/* Transmit checksum configuration
+ * pa_tx_chksum is used in the call to @ref Pa_formatTxRoute or @ref
+ * Pa_formatTxCmd to create a tx command header that instructs the packet
+ * accelerator sub-system to generate ones' complement checksums into network
+ * packets. The checksums are typically used for TCP and UDP payload checksums
+ * as well as IPv4 header checksums. In the case of TCP and UDP payload
+ * checksums the psuedo header checksum must be pre-calculated and provided,
+ * the sub-system does not calculate it. */
+struct pa2_tx_chksum {
+	u16	start_offset;		/* Byte location, from SOP, where the
+					   checksum calculation begins */
+	u16	length_bytes;		/* Number of bytes covered by the
+					   checksum. Must be even */
+	u16	result_offset;		/* Byte offset, from startOffset,
+					   to place the resulting checksum */
+	u16	initial_sum;		/* Initial value of the checksum */
+	u16	negative_0;		/* If TRUE, a computed value of 0 is
+					   written as -0 */
+};
+
+struct pa2_cmd_copy {
+	u16	ctrl_bit_field;		/* Copy operation control information as
+					   defined at @ref copyCtrlInfo */
+	u16	src_offset;		/* Offset from the start of current
+					   protocol header for the data copy to
+					   begin */
+	u16	dest_offset;		/* Offset from the top of the PSInfo for
+					   the data to be copied to */
+	u16	num_bytes;		/* Number of bytes to be copied */
+};
+
+struct pa2_cmd_multi_route {
+
+	u16	index;			/*  Multi-route set Index */
+};
+
+#define PA2_MAX_PATCH_BYTES	16 /* PATCH Command in to-netweok direction */
+#define PA2_MAX_RX_PATCH_BYTES	32 /* PATCH Command within a command set */
+
+#define PA2_PATCH_OP_INSERT	0x0001
+#define PA2_PATCH_OP_MAC_HDR	0x0002
+#define PA2_PATCH_OP_DELETE	0x0004
+struct pa2_patch_info{
+	u16	ctrl_bit_field;		/* Patch operation control information
+					   as defined at @ref patchCtrlInfo */
+	u16	n_patch_bytes;		/* The number of bytes to be patched */
+	u16	total_patch_size;	/* The number of patch bytes in the
+					   patch cmd, must be >= to nPatchBytes
+					   and a multiple of 4 bytes */
+	u16	offset;			/* Offset from the start of the packet
+					   for the patch to begin in the
+					   to-network direction Offset from the
+					   start of the current header for the
+					   patch to begin in the from-network
+					   direction */
+	u8	*patch_data;		/* Pointer to the patch data */
+};
+
+
+/* pa_payload_info defines the packet payload information in the short format.
+ * It is required by the Security Accelerator sub-system (SASS)
+ *
+ * pa_payload_info defines the packet parsing information in terms of payload
+ * offset and payload length as described below
+ * SRTP:      offset to the RTP header; RTP payload length including ICV
+ * IPSEC AH:  offset to the Outer IP; IP payload length
+ * IPSEC ESP: offset to the ESP header; ESP papload length including ICV
+ */
+
+struct pa2_payload_info  {
+	u16	offset;		/* The offset to where the SA packet parsing
+				   starts */
+	u16	len;		/* The total length of the protocal payload
+				   to be processed by SA */
+	u32	sup_data;	/* Optional supplement data such as the 32-bit
+				   CountC for some 3GPP operation modes */
+};
+
+/* The maximum number of command sets supported */
+#define PA2_MAX_CMD_SETS			64
+
+#define PA2_OK					0
+#define PA2_ERR_CONFIG				-10
+#define PA2_INSUFFICIENT_CMD_BUFFER_SIZE	-11
+#define PA2_INVALID_CMD_REPLY_DEST		-12
+
+/* Command Set Command
+ *
+ * pa_cmd_set is used to specify the desired PA command set. The command set
+ * command instructs the PASS to execute a list of commands after a LUT1 or
+ * LUT2 match occurs. It is one of the command which can be embedded within
+ * the @ref paRouteInfo_t.
+ */
+struct pa2_cmd_set {
+	u16	index;		/*Command Set Index */
+};
+
+struct pa2_cmd_tx_timestamp {
+	u16	dest_queue;	/* Host queue for the tx timestamp reporting
+				   packet */
+	u16	flow_id;	/* CPPI flow */
+	u32	sw_info0;	/* 32 bit value returned in the descriptor */
+};
+
+struct pa2_cmd_ip_frag {
+	u16	ip_offset;	/* Offset to the IP header. */
+	u16	mtu_size;	/* Size of the maximum transmission unit
+				   (>= 68) */
+};
+
+struct pa2_cmd_usr_stats {
+	u16	index;		/* User-defined statistics index */
+};
+
+struct pa2_cmd_set_usr_stats {
+	u16	set_index;	/* Commad Set Index */
+	u16	stats_index;    /* User-defined statistics index */
+};
+
+struct pa2_cmd_info {
+	u16	cmd;	/*Specify the PA command code as defined at paCmdCode */
+	union {
+		struct pa2_cmd_next_route route; /* Specify nextRoute command
+						   specific parameters */
+		struct pa2_tx_chksum	chksum;	/* Specify Tx Checksum command
+						   specific parameters */
+		struct pa2_cmd_crcOp	crcOp;	/* Specify CRC operation command
+						   specific parameters */
+		struct pa2_cmd_copy	copy;	/* Specify Copy command specific
+						   parameters */
+		struct pa2_patch_info	patch;	/* Specify Patch command
+						   specific parameters */
+		struct pa2_payload_info	payload; /* Specify the payload info
+						    required by SA */
+		struct pa2_cmd_set	cmd_set; /* Specify Command Set command
+						    specific parameters */
+		struct pa2_cmd_multi_route m_route; /* Specify Multi-route cmd
+						      specific parameters */
+		struct pa2_cmd_tx_timestamp tx_ts; /* Report Tx Timestamp
+						  command specific parameters */
+		struct pa2_cmd_ip_frag	ip_frag; /* Specify IP fragmentation
+						  command specific parameters */
+		struct pa2_cmd_usr_stats usr_stats; /* User-defined stats
+						  command specific parameters */
+		struct pa2_cmd_set_usr_stats cmd_set_usr_stats;
+	} params;
+};
+
+struct pa2_route_info {
+	int	dest;			/* Packet destination as defined at
+					   pktDest */
+	u8	flow_id;		/* For host, SA or SRIO destinations,
+					   specifies CPPI flow which defines
+					   free queues are used for receiving
+					   packets */
+	u16	queue;			/* For host, SA or SRIO destinations,
+					   specifies the destination queue */
+	int	m_route_index;		/* For host, Multi-queue routing index
+					   (0 to (pa_MAX_MULTI_ROUTE_SETS - 1))
+					   or pa_NO_MULTI_ROUTE if multi routing
+					   not used */
+	u32	sw_info_0;		/* Placed in SwInfo0 for packets to host
+					   or SA; Placed in the PS Info for
+					   packets to SRIO */
+	u32	sw_info_1;		/* Placed in SwInfo1 for packets to the
+					   SA; Placed in the PS Info for packets
+					   to SRIO */
+	int	custom_type;		/* For CONTINUE_PARSE_LUT1/LUT2 only,
+					   specifies the custom type as defined
+					   at @ref customType */
+	u8	custom_index;		/* For CONTINUE_PARSE_LUT1/LUT2 only,
+					   specifies the custom classification
+					   entry index */
+	u8	pkt_type_emac_ctrl;	/* For destination SRIO, specify the
+					   5-bit packet type toward SRIO
+					   For destination HOST, EMAC, specify
+					   the EMAC control emcOutputCtrlBits
+					   to the network */
+	struct pa2_cmd_info *pcmd;	/* Pointer to the Command info to be
+					   executed prior to the packet
+					   forwarding.
+					   Note only the following commands are
+					   supported within paRouteInfo_t
+					   - pa_CMD_PATCH_DATA (up to two bytes
+					   only) (LUT2 only)
+					   - pa_CMD_CMDSET
+					   - pa_CMD_USR_STATS
+					   - pa_CMD_CMDSET_AND_USR_STATS */
+};
+
+/* PA Route Info Valid Bit Definitions */
+#define PA2_ROUTE_INFO_VALID_MROUTEINDEX	(1 << 0)
+#define PA2_ROUTE_INFO_VALID_PKTTYPE_EMAC	(1 << 1)
+#define PA2_ROUTE_INFO_VALID_PCMD		(1 << 2)
+#define PA2_ROUTE_INFO_VALID_PRIORITY_TYPE	(1 << 3)
+
+struct pa2_route_info2 {
+	u32	valid_bitmap;		/* 32-bit valid bitmap corresponding to
+					    each optional field as defined at
+					    paRouteInfoValidBits */
+	int	dest;			/* Packet destination as defined at
+					   pktDest */
+	u8	flow_id;		/* For host, SA or SRIO destinations,
+					   specifies CPPI flow which defines
+					   free queues are used for receiving
+					   packets */
+	u16	queue;			/* For host, SA or SRIO destinations,
+					   specifies the destination queue */
+	int	m_route_index;		/* For host, Multi-queue routing index
+					   (0 to (pa_MAX_MULTI_ROUTE_SETS - 1))
+					   or pa_NO_MULTI_ROUTE if multi routing
+					   not used */
+	u32	sw_info_0;		/* Placed in SwInfo0 for packets to host
+					   or SA; Placed in the PS Info for
+					   packets to SRIO */
+	u32	sw_info_1;		/* Placed in SwInfo1 for packets to the
+					   SA; Placed in the PS Info for packets
+					   to SRIO */
+	int	custom_type;		/* For CONTINUE_PARSE_LUT1/LUT2 only,
+					   specifies the custom type as defined
+					   at @ref customType */
+	u8	custom_index;		/* For CONTINUE_PARSE_LUT1/LUT2 only,
+					   specifies the custom classification
+					   entry index */
+	u8	pkt_type_emac_ctrl;	/* For destination SRIO, specify the
+					   5-bit packet type toward SRIO
+					   For destination HOST, EMAC, specify
+					   the EMAC control emcOutputCtrlBits
+					   to the network */
+	struct pa2_cmd_info *pcmd;	/* Pointer to the Command info to be
+					   executed prior to the packet
+					   forwarding.
+					   Note only the following commands are
+					   supported within paRouteInfo_t
+					   - pa_CMD_PATCH_DATA (up to two bytes
+					   only) (LUT2 only)
+					   - pa_CMD_CMDSET
+					   - pa_CMD_USR_STATS
+					   - pa_CMD_CMDSET_AND_USR_STATS */
+	u8	priority_type;		/* validBitMap[t3]: For Host only,
+					   specify priority-based and/or
+					   interfcae-based routing mode as
+					   defined at paRoutePriIntf_e */
+	struct pa2_ef_op_info *ef_op;	/* For EFLOW only, egress flow operation
+					   info (PAGG Gen2 only) */
+};
+
+struct pa2_cmd_reply {
+	int	dest;		/* Packet destination, must be pa_DEST_HOST or
+				   PA2_DEST_DISCARD, see @ref pktDest */
+	u32	reply_id;	/*  Value placed in swinfo0 in reply packet */
+	u16	queue;		/*  Destination queue for destination
+				    PA2_DEST_HOST */
+	u8	flow_id;	/*  Flow ID used on command reply from PASS */
+};
+
+#endif /* __KERNEL__ */
+
+#endif /* KEYSTONE_PA2_H */
+
diff --git a/drivers/net/ethernet/ti/keystone_pasahost.h b/drivers/net/ethernet/ti/keystone_pasahost.h
new file mode 100644
index 0000000..33e21f8
--- /dev/null
+++ b/drivers/net/ethernet/ti/keystone_pasahost.h
@@ -0,0 +1,390 @@
+/*
+ * Copyright (C) 2012 Texas Instruments Incorporated
+ * Author: Sandeep Paulraj <s-paulraj@ti.com> 
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation version 2.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef KEYSTONE_PASAHOST_H
+#define KEYSTONE_PASAHOST_H
+
+#ifdef __KERNEL__
+
+#define	PASAHO_CONFIGURE		4
+#define PASAHO_PARX_PARSECMD		0
+#define PASAHO_PARX_MULTI_ROUTE		5
+#define PASAHO_PAMOD_CMPT_CHKSUM	0
+#define PASAHO_PAMOD_CMPT_CRC		1
+#define PASAHO_PAMOD_PATCH		2
+#define PASAHO_PAMOD_NROUTE		3
+#define PASAHO_PAMOD_MULTI_ROUTE	5
+#define PASAHO_PAMOD_REPORT_TIMESTAMP	6   
+#define PASAHO_PAMOD_GROUP_7		7   
+#define PASAHO_PAMOD_DUMMY		PASAHO_PAMOD_GROUP_7
+#define PASAHO_PAMOD_IP_FRAGMENT	PASAHO_PAMOD_GROUP_7
+#define PASAHO_SA_LONG_INFO		0
+#define PASAHO_SA_SHORT_INFO		1
+#define PASAHO_SA_AIR_INFO		2
+
+#define PASAHO_READ_BITFIELD(a,b,c)	(((a)>>(b)) & ((1UL<<(c))-1))
+
+#define PASAHO_SET_BITFIELD(a,x,b,c)	(a) &= ~(((1UL<<(c))-1)<<(b)), \
+					(a) |= (((x) & ((1UL<<(c))-1))<<(b))
+
+#define PASAHO_SET_CMDID(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 29,3)
+
+#define PASAHO_PACFG_CMD	(((u32)PASAHO_CONFIGURE << 5) << 24)
+
+enum pasaho_header_type {
+	PASAHO_HDR_MAC        = 0,        /* MAC */
+	PASAHO_HDR_VLAN,                  /* VLAN */
+	PASAHO_HDR_MPLS,                  /* MPLS */
+	PASAHO_HDR_IPv4,                  /* IPv4 */
+	PASAHO_HDR_IPv6,                  /* IPv6 */
+	PASAHO_HDR_IPv6_EXT_HOP,          /* IPv6 hop by hop extenstion header */
+	PASAHO_HDR_IPv6_EXT_ROUTE,        /* IPv6 routing extenstion header */
+	PASAHO_HDR_IPv6_EXT_FRAG,         /* IPv6 fragmentation extention header */
+	PASAHO_HDR_IPv6_EXT_DEST,         /* IPv6 destination options header */
+	PASAHO_HDR_GRE,                   /* Generic Routing Encapsulation header */
+	PASAHO_HDR_ESP,                   /* Encapsulating Security Payload header */
+	PASAHO_HDR_ESP_DECODED,           /* Decoded Encapsulating Security Payload header */
+	PASAHO_HDR_AUTH,                  /* Authentication header */
+	PASAHO_HDR_CUSTOM_C1,             /* Custom classify 1 header */
+	PASAHO_HDR_FORCE_LOOKUP,          /* A contrived header type used with custom SRIO to force
+                                        a parse after looking at only the SRIO L0-L2 */
+	PASAHO_HDR_UNKNOWN,               /* Next header type is unknown */
+	PASAHO_HDR_UDP,                   /* User Datagram Protocol header */
+	PASAHO_HDR_UDP_LITE,              /* Lightweight User Datagram Protocol header */
+	PASAHO_HDR_TCP,                   /* Transmission Control Protocol header */
+	PASAHO_HDR_CUSTOM_C2              /* Custom classify 2 header */
+};
+
+/**
+ *  @defgroup pasahoSubCmdCode PASS Sub-Command Code
+ *  @ingroup pasaho_if_constants
+ *  @{
+ *
+ *  @name PASS Sub-Command Code
+ *  Definition of the 5-bit sub-command codes which is used to specify the group 7 commands. 
+ */ 
+
+enum pasaho_sub_cmd_code {
+	PASAHO_SUB_CMD_DUMMY	= 0,	/* Dummy */
+	PASAHO_SUB_CMD_IP_FRAG		/* IPv4 fragmentation */
+};
+
+/**
+ *  @ingroup pasaho_if_structures
+ *  @brief  pasahoCmdInfo_t defines the general short command information
+ *
+ */
+struct pasaho_cmd_info {
+	u32	word0;		/* Control block word 0 */
+};
+
+/**
+ *  @ingroup pasaho_if_structures
+ *  @brief  pasahoLongInfo_t defines the packet parsing information in the long format. 
+ *          The information is structured as an array of 32 bit values. These values
+ *          are broken down through macros. This allows the representation to be
+ *          endian independent to the hardware which operates only on 32 bit values.
+ *
+ *  @details  
+ */
+struct pasaho_long_info {
+	u32   word0;	/* Control block word 0 */
+	u32   word1;	/* Control block word 1 */
+	u32   word2;	/* Control block word 2 */
+	u32   word3;	/* Control block word 3 */
+	u32   word4;	/* Control block word 4 */
+};
+
+/** 
+ *  @defgroup PASAHO_long_info_command_macros  PASAHO Long Info Command Macros
+ *  @ingroup pasaho_if_macros
+ *  @{
+ *  @name PASAHO Long Info Command Macros
+ *  Macros used by the PASAHO Long Info Command
+ */
+
+/* Extract the command ID defined at */
+#define PASAHO_LINFO_READ_CMDID(x)		PASAHO_READ_BITFIELD((x)->word0,29,3)
+
+/* Extract the block length */
+#define PASAHO_LINFO_READ_RECLEN(x)		PASAHO_READ_BITFIELD((x)->word0,24,5)
+
+/* Extract the next parse start offset */
+#define PASAHO_LINFO_READ_START_OFFSET(x)	PASAHO_READ_BITFIELD((x)->word0,0,16)
+
+/* Extract the end of packet parse offset */
+#define PASAHO_LINFO_READ_END_OFFSET(x)		PASAHO_READ_BITFIELD((x)->word1,16,16)
+
+/* Extract the error index */
+#define PASAHO_LINFO_READ_EIDX(x)		PASAHO_READ_BITFIELD((x)->word1,11,5)
+
+/* Extract the previous match flag */
+#define PASAHO_LINFO_READ_PMATCH(x)		PASAHO_READ_BITFIELD((x)->word1,10,1)
+
+/* Extract the custom classify flag */
+#define PASAHO_LINFO_READ_C2C(x)		PASAHO_READ_BITFIELD((x)->word1,9,1)
+
+/* Extract the first parse module ID */
+#define PASAHO_LINFO_READ_L1_PDSP_ID(x)		PASAHO_READ_BITFIELD((x)->word1,6,3)
+
+/* Extract the first parse module match index */
+#define PASAHO_LINFO_READ_L1_IDX(x)		PASAHO_READ_BITFIELD((x)->word1,0,6)
+
+/* Extract the offset to the level 3 header */
+#define PASAHO_LINFO_READ_L3_OFFSET(x)		PASAHO_READ_BITFIELD((x)->word2,24,8)
+
+/* Extract the offset to the level 4 header */
+#define PASAHO_LINFO_READ_L4_OFFSET(x)		PASAHO_READ_BITFIELD((x)->word2,16,8)
+
+/* Extract the offset to the level 5 header */
+#define PASAHO_LINFO_READ_L5_OFFSET(x)		PASAHO_READ_BITFIELD((x)->word2,8,8)
+
+/* Extract the offset to the security header */
+#define PASAHO_LINFO_READ_ESP_AH_OFFSET(x)	PASAHO_READ_BITFIELD((x)->word2,0,8)
+
+/* Extract the bitmask of parsed header types */
+#define PASAHO_LINFO_READ_HDR_BITMASK(x)	PASAHO_READ_BITFIELD((x)->word3,21,11)
+
+/* Extract the next header to parse type */
+#define PASAHO_LINFO_READ_NXT_HDR_TYPE(x)	PASAHO_READ_BITFIELD((x)->word3,16,5)
+
+/* Extract the number of VLAN tags found */
+#define PASAHO_LINFO_READ_VLAN_COUNT(x)		PASAHO_READ_BITFIELD((x)->word3,12,4)
+
+/* Extract the number of IP headers found */
+#define PASAHO_LINFO_READ_IP_COUNT(x)		PASAHO_READ_BITFIELD((x)->word3,8,4)
+
+/* Extract the number of GRE headers found */
+#define PASAHO_LINFO_READ_GRE_COUNT(x)		PASAHO_READ_BITFIELD((x)->word3,4,4)
+
+/* Extract the fragmentation found flag */
+#define PASAHO_LINFO_READ_FLAG_FRAG(x)		PASAHO_READ_BITFIELD((x)->word3,3,1)
+
+/* Extract the incomplete IP route flag */
+#define PASAHO_LINFO_READ_FLAG_ROUTE(x)		PASAHO_READ_BITFIELD((x)->word3,2,1)
+
+/* Extract the (1-based) input EMAC port number */
+/*  0: Indicates that the packet does not enter PASS through CPSW */
+#define PASAHO_LINFO_READ_INPORT(x)		PASAHO_READ_BITFIELD((x)->word3,0,3)
+
+/* Extract the last pseudo-header checksum computed */
+#define PASAHO_LINFO_READ_PSEUDO_CHKSM(x)	PASAHO_READ_BITFIELD((x)->word4,16,16)
+
+#define PASAHO_LINFO_READ_TSTAMP_MSB(x)		PASAHO_READ_BITFIELD((x)->word4,0,16)
+
+/* Extract the IP Reassembly Traffic Flow Index */
+#define PASAHO_LINFO_READ_TFINDEX(x)		PASAHO_READ_BITFIELD((x)->word4,24,8)
+
+/* Extract the IP Reassembly Fragment count */
+#define PASAHO_LINFO_READ_FRANCNT(x)		PASAHO_READ_BITFIELD((x)->word4,16,8)
+
+/* Set the IP Reassembly Traffic Flow Index */
+#define PASAHO_LINFO_SET_TFINDEX(x, v)		PASAHO_SET_BITFIELD((x)->word4,(v),24,8)
+
+/* Set the IP Reassembly Fragment count */
+#define PASAHO_LINFO_SET_FRANCNT(x, v)		PASAHO_SET_BITFIELD((x)->word4,(v),16,8)
+
+/* Indicate whether it is an IPSEC packet */
+#define PASAHO_LINFO_IS_IPSEC(x)		PASAHO_READ_BITFIELD((x)->word3,25,2)
+
+/* Indicate whether it is an IPSEC ESP packet */
+#define PASAHO_LINFO_IS_IPSEC_ESP(x)		PASAHO_READ_BITFIELD((x)->word3,26,1)
+
+/* Indicate whether it is an IPSEC AH packet */
+#define PASAHO_LINFO_IS_IPSEC_AH(x)		PASAHO_READ_BITFIELD((x)->word3,25,1)
+
+/* Clear IPSEC indication bits */
+#define PASAHO_LINFO_CLR_IPSEC(x)		PASAHO_SET_BITFIELD((x)->word3,0,25,2)
+
+/* Clear IPSEC ESP indication bit */
+#define PASAHO_LINFO_CLR_IPSEC_ESP(x)		PASAHO_SET_BITFIELD((x)->word3,0,26,1)
+
+/* Clear IPSEC AH indication bit */
+#define PASAHO_LINFO_CLR_IPSEC_AH(x)		PASAHO_SET_BITFIELD((x)->word3,0,25,1)
+
+/* Clear the fragmentation found flag */
+#define PASAHO_LINFO_CLR_FLAG_FRAG(x)		PASAHO_SET_BITFIELD((x)->word3,0,3,1)
+
+/* Update the next parse start offset */
+#define PASAHO_LINFO_SET_START_OFFSET(x, v)	PASAHO_SET_BITFIELD((x)->word0,(v),0,16)
+
+/* Update the end of packet parse offset */
+#define PASAHO_LINFO_SET_END_OFFSET(x, v)	PASAHO_SET_BITFIELD((x)->word1,(v),16,16)
+
+
+/*
+ * Set the null packet flag which indicates that the packet should be dropped.
+ * This flag should be set for the null packet to be delivered to PASS when
+ * the reassembly timeout occurs
+ */
+#define PASAHO_LINFO_SET_NULL_PKT_IND(x, v)	PASAHO_SET_BITFIELD((x)->word0,(v),21,1)
+
+/*
+ * PA_INV_TF_INDEX
+ * PASS-asssited IP reassembly traffic flow index to indicate
+ * that no traffic flow is available
+ */
+#define PA_INV_TF_INDEX		0xFF
+
+struct pasaho_short_info {
+	u32	word0;
+	u32	word1;
+};
+
+/* Extract the command ID defined at */
+#define PASAHO_SINFO_READ_CMDID(x)		PASAHO_READ_BITFIELD((x)->word0,29,3)
+
+/* Extract the offset to the packet payload */
+#define PASAHO_SINFO_RESD_PAYLOAD_OFFSET(x)	PASAHO_READ_BITFIELD((x)->word0,16,8)
+
+/* Extract the byte length of the payload */
+#define PASAHO_SINFO_READ_PAYLOAD_LENGTH(x)	PASAHO_READ_BITFIELD((x)->word0,0,16)
+
+/* Set the offset to the payload */
+#define PASAHO_SINFO_SET_PAYLOAD_OFFSET(x, v)	PASAHO_SET_BITFIELD((x)->word0, (v), 16, 8)
+
+/* Set the payload length */
+#define PASAHO_SINFO_SET_PAYLOAD_LENGTH(x, v)	PASAHO_SET_BITFIELD((x)->word0, (v), 0,  16)
+
+/* Format the entire short info command */
+#define PASAHO_SINFO_FORMAT_CMD(offset, len)	(((offset) << 16) | (len) | (PASAHO_SA_SHORT_INFO << 29))
+
+#define PASAHO_HDR_BITMASK_MAC		(1 << 0)	/* MAC present */
+#define PASAHO_HDR_BITMASK_VLAN		(1 << 1)	/* VLAN present */
+#define PASAHO_HDR_BITMASK_MPLS		(1 << 2)	/* MPLS present */
+#define PASAHO_HDR_BITMASK_IP		(1 << 3)	/* IP present */
+#define PASAHO_HDR_BITMASK_ESP		(1 << 4)	/* IPSEC/ESP present */
+#define PASAHO_HDR_BITMASK_AH		(1 << 5)	/* IPSEC/AH present */
+#define PASAHO_HDR_BITMASK_UDP		(1 << 6)	/* UDP present */
+#define PASAHO_HDR_BITMASK_UDPLITE	(1 << 7)	/* UDPLITE present */
+#define PASAHO_HDR_BITMASK_TCP		(1 << 8)	/* TCP present */
+#define PASAHO_HDR_BITMASK_GRE		(1 << 9)	/* GRE present */
+#define PASAHO_HDR_BITMASK_CUSTOM	(1 << 10)	/* Custom header */
+
+struct pasaho_next_route {
+	u32  word0;          
+	u32  sw_info0;        
+	u32  sw_info1;        
+	u32  word1;          
+};
+
+/*
+ * Sets the N bit which indicates the next command
+ * should be executed prior to the route command
+ */
+#define PASAHO_SET_N(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 28, 1)
+
+/*
+ * Sets the E bit which indicates the extened
+ * parameters (packet type) are present for SRIO
+ */
+#define PASAHO_SET_E(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 27, 1)
+
+/*
+ * Sets the destination of the route defined */
+#define PASAHO_SET_DEST(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 24, 3)
+
+/* Specifies the flow to use for packets sent to the host */
+#define PASAHO_SET_FLOW(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 16, 8)
+
+/* Specifies the queue to use for packets send to the host */
+#define PASAHO_SET_QUEUE(x,v)   PASAHO_SET_BITFIELD((x)->word0, (v), 0,  16)
+
+/* Specifies the packet type to use for packets send to the SRIO */
+#define PASAHO_SET_PKTTYPE(x,v) PASAHO_SET_BITFIELD((x)->word1, (v), 24, 8)
+
+struct pasaho_com_chk_crc {
+	u32	word0;		/* PASAHO_chksum_command_macros */
+	u32	word1;		/* PASAHO_chksum_command_macros */
+	u32	word2;		/* PASAHO_chksum_command_macros */
+};
+
+/*
+ * Sets the negative 0 flag - if set a
+ * checksum computed as 0 will be sent as 0xffff
+ */
+#define PASAHO_CHKCRC_SET_NEG0(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 23, 1)
+
+/* Sets the optional flags of the CRC/Checksum command */
+#define PASAHO_CHKCRC_SET_CTRL(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 16, 8)
+
+/* Sets the start offset of the checksum/crc */
+#define PASAHO_CHKCRC_SET_START(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 0,  16)
+
+/* Sets the length of the checksum/crc */
+#define PASAHO_CHKCRC_SET_LEN(x,v)	PASAHO_SET_BITFIELD((x)->word1, (v), 16, 16)
+
+/* Sets the offset to where to paste the checksum/crc into the packet */
+#define PASAHO_CHKCRC_SET_RESULT_OFF(x,v)	PASAHO_SET_BITFIELD((x)->word1, (v), 0,  16)
+
+/* Sets the initial value of the checksum/crc */
+#define PASAHO_CHKCRC_SET_INITVAL(x,v)	PASAHO_SET_BITFIELD((x)->word2, (v), 16, 16)
+
+#define PASAHO_BPATCH_MAX_PATCH_WORDS	4
+
+struct pasaho_com_blind_patch {
+	u32	word0;
+	u32	patch[PASAHO_BPATCH_MAX_PATCH_WORDS];
+};
+
+
+#define PASAHO_BPATCH_SET_PATCH_NBYTES(x,v)	PASAHO_SET_BITFIELD((x)->word0, v, 24,  5)
+
+/* Sets the number of bytes to patch */
+#define PASAHO_BPATCH_SET_PATCH_CMDSIZE(x,v)	PASAHO_SET_BITFIELD((x)->word0, v, 20, 4)
+
+/* Sets the size of the command in 32 bit word units */                        
+#define PASAHO_BPATCH_SET_OVERWRITE(x,v)	PASAHO_SET_BITFIELD((x)->word0, v, 19, 1)
+
+/*
+ * Sets the overwrite flag. If set the patch will
+ * overwrite existing packet data, otherwise data is inserted
+ */                         
+#define PASAHO_BPATCH_SET_OFFSET(x,v)		PASAHO_SET_BITFIELD((x)->word0, v, 0,  16)
+
+/* Sets the offset to the start of the patch */
+#define PASAHO_BPATCH_SET_PATCH_BYTE(x, byteNum, byte)  (x)->patch[(byteNum) >> 2] = \
+		PASAHO_SET_BITFIELD((x)->patch[(byteNum) >> 2], byte, ((3 - (byteNum & 0x3)) << 3), 8)
+
+
+struct pasaho_report_timestamp {
+	u32	word0;
+	u32	sw_info0;
+};
+
+/* Specifies the flow to use for report packets sent to the host */
+
+#define PASAHO_SET_REPORT_FLOW(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 16, 8)
+
+/* Specifies the queue to use for report packets send to the host */
+#define PASAHO_SET_REPORT_QUEUE(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 0,  16)
+
+struct pasaho_ip_frag {
+	u32	word0;
+};
+
+/* Set sub-command code to indicate IP Fragmentation command */
+#define PASAHO_SET_SUB_CODE_IP_FRAG(x) PASAHO_SET_BITFIELD((x)->word0, PASAHO_SUB_CMD_IP_FRAG, 24, 5)
+
+/* Specifies the sub-command code */
+#define PASAHO_SET_SUB_CODE(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 24, 5)
+
+/* Specifies the offset to the IP header to be fragmented */
+#define PASAHO_SET_IP_OFFSET(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 16, 8)
+
+/* Specifies the MTU size */
+#define PASAHO_SET_MTU_SIZE(x,v)	PASAHO_SET_BITFIELD((x)->word0, (v), 0,  16)
+
+#endif /* __KERNEL__ */
+#endif /* KEYSTONE_PASAHOST_H */
diff --git a/drivers/net/ethernet/ti/keystone_pasahost2.h b/drivers/net/ethernet/ti/keystone_pasahost2.h
new file mode 100644
index 0000000..f5e7e8b
--- /dev/null
+++ b/drivers/net/ethernet/ti/keystone_pasahost2.h
@@ -0,0 +1,507 @@
+/*
+ * Copyright (C) 2013 Texas Instruments Incorporated
+ * Author: Hao Zhang <hzhang@ti.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation version 2.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef KEYSTONE_PASAHOST2_H
+#define KEYSTONE_PASAHOST2_H
+
+#ifdef __KERNEL__
+
+#define	PASAHO2_CONFIGURE		4
+#define PASAHO2_PARX_PARSECMD		0
+#define PASAHO2_PARX_MULTI_ROUTE		5
+#define PASAHO2_PAMOD_CMPT_CHKSUM	0
+#define PASAHO2_PAMOD_CMPT_CRC		1
+#define PASAHO2_PAMOD_PATCH		2
+#define PASAHO2_PAMOD_NROUTE		3
+#define PASAHO2_PAMOD_EF_OP		5
+#define PASAHO2_PAMOD_REPORT_TIMESTAMP	6
+#define PASAHO2_PAMOD_GROUP_7		7
+#define PASAHO2_PAMOD_DUMMY		PASAHO2_PAMOD_GROUP_7
+#define PASAHO2_PAMOD_IP_FRAGMENT	PASAHO2_PAMOD_GROUP_7
+#define PASAHO2_SA_LONG_INFO		0
+#define PASAHO2_SA_SHORT_INFO		1
+#define PASAHO2_SA_AIR_INFO		2
+
+#define PASAHO2_READ_BITFIELD(a, b, c)	(((a) >> (b)) & ((1 << (c)) - 1))
+
+#define PASAHO2_SET_BITFIELD(a, x, b, c) (a) &= ~(((1 << (c)) - 1) << (b)), \
+					(a) |= (((x) & ((1 << (c)) - 1)) << (b))
+
+#define PASAHO2_SET_CMDID(x, v)	PASAHO2_SET_BITFIELD((x)->word0, (v), 29, 3)
+
+#define PASAHO2_PACFG_CMD	(((u32)PASAHO2_CONFIGURE << 5) << 24)
+
+enum pasaho2_header_type {
+	PASAHO2_HDR_MAC	= 0,		/* MAC */
+	PASAHO2_HDR_VLAN,		/* VLAN */
+	PASAHO2_HDR_MPLS,		/* MPLS */
+	PASAHO2_HDR_IPv4,		/* IPv4 */
+	PASAHO2_HDR_IPv6,		/* IPv6 */
+	PASAHO2_HDR_IPv6_EXT_HOP,	/* IPv6 hop by hop extenstion header */
+	PASAHO2_HDR_IPv6_EXT_ROUTE,	/* IPv6 routing extenstion header */
+	PASAHO2_HDR_IPv6_EXT_FRAG,	/* IPv6 fragmentation extention hdr */
+	PASAHO2_HDR_IPv6_EXT_DEST,	/* IPv6 destination options header */
+	PASAHO2_HDR_GRE,		/* Generic Routing Encapsulation
+					   header */
+	PASAHO2_HDR_ESP,		/* Encapsulating Security Payload
+					   header */
+	PASAHO2_HDR_ESP_DECODED,	/* Decoded Encapsulating Security
+					   Payload header */
+	PASAHO2_HDR_AUTH,		/* Authentication header */
+	PASAHO2_HDR_CUSTOM_C1,		/* Custom classify 1 header */
+	PASAHO2_HDR_PPPoE,		/* PPPoE Header */
+	PASAHO2_HDR_SCTP,		/* SCTP Header */
+	PASAHO2_HDR_UNKNOWN,		/* Next header type is unknown */
+	PASAHO2_HDR_UDP,		/* User Datagram Protocol header */
+	PASAHO2_HDR_UDP_LITE,		/* Lightweight User Datagram Protocol
+					   header */
+	PASAHO2_HDR_TCP,		/* Transmission Control Protocol
+					   header */
+	PASAHO2_HDR_GTPU,		/* GTPU header */
+	PASAHO2_HDR_ESP_DECODED_C2,	/* Decoded Encapsulating Security
+					   Payload header at Classifyer2 */
+	PASAHO2_HDR_CUSTOM_C2		/* Custom classify 2 header */
+};
+
+/* Definition of the 5-bit sub-command codes which is used to specify the group
+   7 commands. */
+enum pasaho2_sub_cmd_code {
+	PASAHO2_SUB_CMD_DUMMY	= 0,	/* Dummy */
+	PASAHO2_SUB_CMD_IP_FRAG,		/* IPv4 fragmentation */
+	PASAHO2_SUB_CMD_PATCH_MSG_LEN	/* Message length Patching */
+};
+
+/* pasaho2_cmd_info defines the general short command information */
+struct pasaho2_cmd_info {
+	u32	word0;		/* Control block word 0 */
+};
+
+/* pasaho2_long_info defines the packet parsing information in the long format.
+ * The information is structured as an array of 32 bit values. These values
+ * are broken down through macros. This allows the representation to be
+ * endian independent to the hardware which operates only on 32 bit values. */
+struct pasaho2_long_info {
+	u32   word0;	/* Control block word 0 */
+	u32   word1;	/* Control block word 1 */
+	u32   word2;	/* Control block word 2 */
+	u32   word3;	/* Control block word 3 */
+	u32   word4;	/* Control block word 4 */
+};
+
+/* Macros used by the PASAHO Long Info Command */
+
+/* Extract the command ID defined at */
+#define PASAHO2_LINFO_READ_CMDID(x)	PASAHO2_READ_BITFIELD((x)->word0, 29, 3)
+
+/* Extract the block length */
+#define PASAHO2_LINFO_READ_RECLEN(x)	PASAHO2_READ_BITFIELD((x)->word0, 24, 5)
+
+/* Extract the next parse start offset */
+#define PASAHO2_LINFO_READ_START_OFFSET(x) \
+	PASAHO2_READ_BITFIELD((x)->word0, 0, 8)
+
+/* Indicate whether it is a broadcast MAC packet */
+#define PASAHO2_LINFO_IS_MAC_BROADCAST(x) \
+	PASAHO2_READ_BITFIELD((x)->word0, 16, 1)
+
+/* Indicate whether it is a multicast MAC packet */
+#define PASAHO2_LINFO_IS_MAC_MULTICAST(x) \
+	PASAHO2_READ_BITFIELD((x)->word0, 17, 1)
+
+/* Extract the MAC packet type */
+#define PASAHO2_LINFO_READ_MAC_PKTTYPE(x) \
+	PASAHO2_READ_BITFIELD((x)->word0, 16, 2)
+
+/* Indicate whether it is a broadcast IP packet */
+#define PASAHO2_LINFO_IS_IP_BROADCAST(x) \
+	PASAHO2_READ_BITFIELD((x)->word0, 16, 1)
+
+/* Indicate whether it is a multicast IP packet */
+#define PASAHO2_LINFO_IS_IP_MULTICAST(x) \
+	PASAHO2_READ_BITFIELD((x)->word0, 17, 1)
+
+/* Extract the IP packet type */
+#define PASAHO2_LINFO_READ_IP_PKTTYPE(x) \
+	PASAHO2_READ_BITFIELD((x)->word0, 16, 2)
+
+/* Extract the previous match flag */
+#define PASAHO2_LINFO_READ_PMATCH(x)	PASAHO2_READ_BITFIELD((x)->word0, 23, 1)
+
+/* Extract the fragmentation found flag */
+#define PASAHO2_LINFO_READ_FLAG_FRAG(x)	PASAHO2_READ_BITFIELD((x)->word0, 19, 1)
+
+/* Extract the end of packet parse offset */
+#define PASAHO2_LINFO_READ_END_OFFSET(x) \
+	PASAHO2_READ_BITFIELD((x)->word1, 16, 16)
+
+/* Extract the error index */
+#define PASAHO2_LINFO_READ_EIDX(x)	PASAHO2_READ_BITFIELD((x)->word1, 10, 6)
+
+/* Extract the next header to parse type */
+#define PASAHO2_LINFO_READ_NXT_HDR_TYPE(x) \
+	PASAHO2_READ_BITFIELD((x)->word1, 0, 6)
+
+/* Extract the (1-based) input EMAC port number through CPSW */
+#define PASAHO2_LINFO_READ_INPORT(x)	PASAHO2_READ_BITFIELD((x)->word1, 6, 4)
+
+/* Extract the offset to the level 3 header */
+#define PASAHO2_LINFO_READ_L3_OFFSET(x)	PASAHO2_READ_BITFIELD((x)->word2, 24, 8)
+
+/* Extract the offset to the level 4 header */
+#define PASAHO2_LINFO_READ_L4_OFFSET(x)	PASAHO2_READ_BITFIELD((x)->word2, 16, 8)
+
+/* Extract the offset to the level 5 header */
+#define PASAHO2_LINFO_READ_L5_OFFSET(x)	PASAHO2_READ_BITFIELD((x)->word2, 8, 8)
+
+/* Extract the offset to the security header */
+#define PASAHO2_LINFO_READ_ESP_AH_OFFSET(x) \
+	PASAHO2_READ_BITFIELD((x)->word2, 0, 8)
+
+/* Extract the first parse module ID */
+#define PASAHO2_LINFO_READ_L1_PDSP_ID(x) \
+	PASAHO2_READ_BITFIELD((x)->word3, 26, 6)
+
+/* Extract the first parse module match index */
+#define PASAHO2_LINFO_READ_L1_IDX(x) \
+	PASAHO2_READ_BITFIELD((x)->word3, 16, 10)
+
+/* Extract the bitmask of parsed header types */
+#define PASAHO2_LINFO_READ_HDR_BITMASK(x) \
+	PASAHO2_READ_BITFIELD((x)->word3, 0, 16)
+
+/* Extract the number of VLAN tags found */
+#define PASAHO2_LINFO_READ_VLAN_COUNT(x) PASAHO2_READ_BITFIELD((x)->word4, 6, 2)
+
+/* Extract the number of IP headers found */
+#define PASAHO2_LINFO_READ_IP_COUNT(x)	PASAHO2_READ_BITFIELD((x)->word4, 0, 3)
+
+/* Extract the number of GRE headers found */
+#define PASAHO2_LINFO_READ_GRE_COUNT(x)	PASAHO2_READ_BITFIELD((x)->word4, 3, 3)
+
+/*  Extract the last pseudo-header checksum computed (depreciated) */
+#define PASAHO2_LINFO_READ_PSEUDO_CHKSM(x) \
+	PASAHO2_READ_BITFIELD((x)->word5, 16, 16)
+
+/**< Extract the offset to the inner IP header */
+#define PASAHO2_LINFO_READ_INNER_IP_OFFSET(x) \
+	PASAHO2_READ_BITFIELD((x)->word5, 24, 8)
+
+/* Extract the most significant 16-bit of the 48-bit timestamp */
+#define PASAHO2_LINFO_READ_TSTAMP_MSB(x) \
+	PASAHO2_READ_BITFIELD((x)->word5, 0, 16)
+
+
+/* Indicate whether it is a MAC packet */
+#define PASAHO2_LINFO_IS_MAC(x)		PASAHO2_READ_BITFIELD((x)->word3, 0, 1)
+
+/* Indicate whether it is a MAC packet with VLAN */
+#define PASAHO2_LINFO_IS_WITH_VLAN(x)	PASAHO2_LINFO_READ_VLAN_COUNT(x)
+
+/* Indicate whether it is a MAC packet with MPLS */
+#define PASAHO2_LINFO_IS_WITH_MPLS(x)	PASAHO2_READ_BITFIELD((x)->word3, 2, 1)
+
+/* Indicate whether it is a 802.3 packet */
+#define PASAHO2_LINFO_IS_802_3(x)	PASAHO2_READ_BITFIELD((x)->word3, 3, 1)
+
+/* Indicate whether it is a PPPoE packet */
+#define PASAHO2_LINFO_IS_PPPoE(x)	PASAHO2_READ_BITFIELD((x)->word3, 4, 1)
+
+/* Indicate whether it is an IP packet */
+#define PASAHO2_LINFO_IS_IP(x)		PASAHO2_LINFO_READ_IP_COUNT(x)
+
+/* Indicate whether it is an IPv4 packet */
+#define PASAHO2_LINFO_IS_IPv4(x)	PASAHO2_READ_BITFIELD((x)->word3, 5, 1)
+
+/* Indicate whether it is an IPv4 packet */
+#define PASAHO2_LINFO_IS_IPv6(x)	PASAHO2_READ_BITFIELD((x)->word3, 6, 1)
+
+/* Indicate whether there are IPV4 options or IPv6 extention headers */
+#define PASAHO2_LINFO_IS_IP_OPTIONS(x)	PASAHO2_READ_BITFIELD((x)->word3, 7, 1)
+
+/* Indicate whether it is an IPSEC packet */
+#define PASAHO2_LINFO_IS_IPSEC(x)	PASAHO2_READ_BITFIELD((x)->word3, 8, 2)
+
+/* Indicate whether it is an IPSEC ESP packet */
+#define PASAHO2_LINFO_IS_IPSEC_ESP(x)	PASAHO2_READ_BITFIELD((x)->word3, 8, 1)
+
+/* Indicate whether it is an IPSEC AH packet */
+#define PASAHO2_LINFO_IS_IPSEC_AH(x)	PASAHO2_READ_BITFIELD((x)->word3, 9, 1)
+
+/* Indicate whether it is a SCTP packet */
+#define PASAHO2_LINFO_IS_SCTP(x)	PASAHO2_READ_BITFIELD((x)->word3, 10, 1)
+
+/* Indicate whether it is an UDP packet */
+#define PASAHO2_LINFO_IS_UDP(x)		PASAHO2_READ_BITFIELD((x)->word3, 11, 1)
+
+/* Indicate whether it is an UDP Lite packet */
+#define PASAHO2_LINFO_IS_UDP_LITE(x)	PASAHO2_READ_BITFIELD((x)->word3, 11, 1)
+
+/* Indicate whether it is a TCP packet */
+#define PASAHO2_LINFO_IS_TCP(x)		PASAHO2_READ_BITFIELD((x)->word3, 12, 1)
+
+/* Indicate whether it is a GRE packet */
+#define PASAHO2_LINFO_IS_GRE(x)		PASAHO2_LINFO_READ_GRE_COUNT(x)
+
+/* Indicate whether it is a GTPU packet */
+#define PASAHO2_LINFO_IS_GTPU(x)	PASAHO2_READ_BITFIELD((x)->word3, 13, 1)
+
+/* Indicate whether it is a Custom packet */
+#define PASAHO2_LINFO_IS_CUSTOM(x)	PASAHO2_READ_BITFIELD((x)->word3, 14, 1)
+
+/* Indicate whether it is an IPSEC NAT-T packet */
+#define PASAHO2_LINFO_IS_IPSEC_NAT_T(x)	PASAHO2_READ_BITFIELD((x)->word3, 15, 1)
+
+
+/* Extract the IP Reassembly Traffic Flow Index */
+#define PASAHO2_LINFO_READ_TFINDEX(x)	PASAHO2_READ_BITFIELD((x)->word5, 24, 8)
+
+/* Extract the IP Reassembly Fragment count */
+#define PASAHO2_LINFO_READ_FRANCNT(x)	PASAHO2_READ_BITFIELD((x)->word5, 16, 8)
+
+/* Set the IP Reassembly Traffic Flow Index */
+#define PASAHO2_LINFO_SET_TFINDEX(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word5, (v), 24, 8)
+
+/* Set the IP Reassembly Fragment count */
+#define PASAHO2_LINFO_SET_FRANCNT(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word5, (v), 16, 8)
+
+
+/* Clear IPSEC indication bits */
+#define PASAHO2_LINFO_CLR_IPSEC(x) \
+	PASAHO2_SET_BITFIELD((x)->word3, 0, 8, 2)
+
+/* Clear IPSEC ESP indication bit */
+#define PASAHO2_LINFO_CLR_IPSEC_ESP(x) \
+	PASAHO2_SET_BITFIELD((x)->word3, 0, 8, 1)
+
+/* Claer IPSEC AH indication bit */
+#define PASAHO2_LINFO_CLR_IPSEC_AH(x) \
+	PASAHO2_SET_BITFIELD((x)->word3, 0, 9, 1)
+
+/* Clear the fragmentation found flag */
+#define PASAHO2_LINFO_CLR_FLAG_FRAG(x) \
+	PASAHO2_SET_BITFIELD((x)->word1, 0, 19, 1)
+
+/* Update the next parse start offset */
+#define PASAHO2_LINFO_SET_START_OFFSET(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, (v), 0, 8)
+
+/* Update the end of packet parse offset */
+#define PASAHO2_LINFO_SET_END_OFFSET(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word1, (v), 16, 16)
+
+/* Update the next header to parse type */
+#define PASAHO2_LINFO_SET_NXT_HDR_TYPE(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word1, (v), 0, 6)
+
+/* Set the null packet flag which indicates that the packet should be dropped.
+ * This flag should be set for the null packet to be delivered to PASS when the
+ * reassembly timeout occurs */
+#define PASAHO2_LINFO_SET_NULL_PKT_IND(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, (v), 21, 1)
+
+/*
+ * PA_INV_TF_INDEX
+ * PASS-asssited IP reassembly traffic flow index to indicate
+ * that no traffic flow is available
+ */
+#define PA_INV_TF_INDEX		0xFF
+
+struct pasaho2_short_info {
+	u32	word0;
+	u32	word1;
+};
+
+/* Extract the command ID defined at */
+#define PASAHO2_SINFO_READ_CMDID(x)	PASAHO2_READ_BITFIELD((x)->word0, 29, 3)
+
+/* Extract the offset to the packet payload */
+#define PASAHO2_SINFO_RESD_PAYLOAD_OFFSET(x) \
+	PASAHO2_READ_BITFIELD((x)->word0, 16, 8)
+
+/* Extract the byte length of the payload */
+#define PASAHO2_SINFO_READ_PAYLOAD_LENGTH(x) \
+	PASAHO2_READ_BITFIELD((x)->word0, 0, 16)
+
+/* Set the offset to the payload */
+#define PASAHO2_SINFO_SET_PAYLOAD_OFFSET(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, (v), 16, 8)
+
+/* Set the payload length */
+#define PASAHO2_SINFO_SET_PAYLOAD_LENGTH(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, (v), 0,  16)
+
+/* Format the entire short info command */
+#define PASAHO2_SINFO_FORMAT_CMD(offset, len) \
+	(((offset) << 16) | (len) | (PASAHO2_SA_SHORT_INFO << 29))
+
+#define PASAHO2_HDR_BITMASK_MAC		(1 << 0)  /* MAC present */
+#define PASAHO2_HDR_BITMASK_VLAN		(1 << 1)  /* VLAN present */
+#define PASAHO2_HDR_BITMASK_MPLS		(1 << 2)  /* MPLS present */
+#define PASAHO2_HDR_BITMASK_802_3	(1 << 3)  /* 802.3 present */
+#define PASAHO2_HDR_BITMASK_PPPoE	(1 << 4)  /* PPPoE present */
+#define PASAHO2_HDR_BITMASK_IPv4		(1 << 5)  /* IPv4 present */
+#define PASAHO2_HDR_BITMASK_IPv6		(1 << 6)  /* IPv6 present */
+#define PASAHO2_HDR_BITMASK_IP_OPTS	(1 << 7)  /* IPv4 options or IPv6
+						     extension headers esent */
+#define PASAHO2_HDR_BITMASK_ESP		(1 << 8)  /* IPSEC/ESP present */
+#define PASAHO2_HDR_BITMASK_AH		(1 << 9)  /* IPSEC/AH present */
+#define PASAHO2_HDR_BITMASK_SCTP		(1 << 10) /* SCTP present */
+#define PASAHO2_HDR_BITMASK_UDP		(1 << 11) /* UDP present */
+#define PASAHO2_HDR_BITMASK_UDPLITE	(1 << 11) /* UDPLITE present */
+#define PASAHO2_HDR_BITMASK_TCP		(1 << 12) /* TCP present */
+#define PASAHO2_HDR_BITMASK_GTPU		(1 << 13) /* GTPU present */
+#define PASAHO2_HDR_BITMASK_CUSTOM	(1 << 14) /* Custom header present */
+#define PASAHO2_HDR_BITMASK_IPSEC_NAT_T	(1 << 15) /* IPSEC NAT-T present */
+
+struct pasaho2_next_route {
+	u32  word0;
+	u32  sw_info0;
+	u32  sw_info1;
+	u32  word1;
+};
+
+/*
+ * Sets the N bit which indicates the next command
+ * should be executed prior to the route command
+ */
+#define PASAHO2_SET_N(x, v)	PASAHO2_SET_BITFIELD((x)->word0, (v), 28, 1)
+
+/*
+ * Sets the E bit which indicates the extened
+ * parameters (packet type) are present for SRIO
+ */
+#define PASAHO2_SET_E(x, v)	PASAHO2_SET_BITFIELD((x)->word0, (v), 27, 1)
+
+/*
+ * Sets the destination of the route defined */
+#define PASAHO2_SET_DEST(x, v)	PASAHO2_SET_BITFIELD((x)->word0, (v), 24, 3)
+
+/* Specifies the flow to use for packets sent to the host */
+#define PASAHO2_SET_FLOW(x, v)	PASAHO2_SET_BITFIELD((x)->word0, (v), 16, 8)
+
+/* Specifies the queue to use for packets send to the host */
+#define PASAHO2_SET_QUEUE(x, v)   PASAHO2_SET_BITFIELD((x)->word0, (v), 0,  16)
+
+/* Specifies the packet type to use for packets send to the SRIO */
+#define PASAHO2_SET_PKTTYPE(x, v) PASAHO2_SET_BITFIELD((x)->word1, (v), 24, 8)
+
+struct pasaho2_com_chk_crc {
+	u32	word0;		/* PASAHO2_chksum_command_macros */
+	u32	word1;		/* PASAHO2_chksum_command_macros */
+	u32	word2;		/* PASAHO2_chksum_command_macros */
+};
+
+/*
+ * Sets the negative 0 flag - if set a
+ * checksum computed as 0 will be sent as 0xffff
+ */
+#define PASAHO2_CHKCRC_SET_NEG0(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, (v), 23, 1)
+
+/* Sets the optional flags of the CRC/Checksum command */
+#define PASAHO2_CHKCRC_SET_CTRL(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, (v), 16, 4)
+
+/* Sets the size of the crc in bytes */
+#define PASAHO2_CHKCRC_SET_CRCSIZE(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, (v), 8,  8)
+
+/* Sets the start offset of the checksum/crc */
+#define PASAHO2_CHKCRC_SET_START(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, (v), 0,  8)
+
+/* Sets the length of the checksum/crc */
+#define PASAHO2_CHKCRC_SET_LEN(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word1, (v), 16, 16)
+
+/* Sets the offset to where to paste the checksum/crc into the packet */
+#define PASAHO2_CHKCRC_SET_RESULT_OFF(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word1, (v), 0,  16)
+
+/* Sets the initial value of the checksum/crc */
+#define PASAHO2_CHKCRC_SET_INITVAL(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word2, (v), 16, 16)
+
+/* Sets the initial value of the 32-bit crc */
+#define PASAHO2_CHKCRC_SET_INITVAL32(x, v)	((x)->word2) = (v)
+
+
+#define PASAHO2_BPATCH_MAX_PATCH_WORDS	4
+
+struct pasaho2_com_blind_patch {
+	u32	word0;
+	u32	patch[PASAHO2_BPATCH_MAX_PATCH_WORDS];
+};
+
+
+#define PASAHO2_BPATCH_SET_PATCH_NBYTES(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, v, 24,  5)
+
+/* Sets the number of bytes to patch */
+#define PASAHO2_BPATCH_SET_PATCH_CMDSIZE(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, v, 20, 4)
+
+/* Sets the size of the command in 32 bit word units */
+#define PASAHO2_BPATCH_SET_OVERWRITE(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, v, 19, 1)
+
+/*
+ * Sets the overwrite flag. If set the patch will
+ * overwrite existing packet data, otherwise data is inserted
+ */
+#define PASAHO2_BPATCH_SET_OFFSET(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, v, 0,  16)
+
+/* Sets the offset to the start of the patch */
+#define PASAHO2_BPATCH_SET_PATCH_BYTE(x, byteNum, byte) \
+	((x)->patch[(byteNum) >> 2]) = \
+	PASAHO2_SET_BITFIELD((x)->patch[(byteNum) >> 2], \
+	byte, ((3 - (byteNum & 0x3)) << 3), 8)
+
+
+struct pasaho2_report_timestamp {
+	u32	word0;
+	u32	sw_info0;
+};
+
+/* Specifies the flow to use for report packets sent to the host */
+
+#define PASAHO2_SET_REPORT_FLOW(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, (v), 16, 8)
+
+/* Specifies the queue to use for report packets send to the host */
+#define PASAHO2_SET_REPORT_QUEUE(x, v) \
+	PASAHO2_SET_BITFIELD((x)->word0, (v), 0,  16)
+
+struct pasaho2_ip_frag {
+	u32	word0;
+};
+
+/* Set sub-command code to indicate IP Fragmentation command */
+#define PASAHO2_SET_SUB_CODE_IP_FRAG(x) \
+	PASAHO2_SET_BITFIELD((x)->word0, PASAHO2_SUB_CMD_IP_FRAG, 24, 5)
+
+/* Specifies the sub-command code */
+#define PASAHO2_SET_SUB_CODE(x, v) PASAHO2_SET_BITFIELD((x)->word0, (v), 24, 5)
+
+/* Specifies the offset to the IP header to be fragmented */
+#define PASAHO2_SET_IP_OFFSET(x, v) PASAHO2_SET_BITFIELD((x)->word0, (v), 16, 8)
+
+/* Specifies the MTU size */
+#define PASAHO2_SET_MTU_SIZE(x, v) PASAHO2_SET_BITFIELD((x)->word0, (v), 0,  16)
+
+#endif /* __KERNEL__ */
+#endif /* KEYSTONE_PASAHOST2_H */
-- 
2.7.4

