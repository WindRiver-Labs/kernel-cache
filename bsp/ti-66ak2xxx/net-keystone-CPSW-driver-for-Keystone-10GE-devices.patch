From 66c17229fea3e58d1335b856a109fe1da0365aac Mon Sep 17 00:00:00 2001
From: Zumeng Chen <zumeng.chen@windriver.com>
Date: Tue, 5 May 2015 16:13:50 +0800
Subject: [PATCH 017/256] net: keystone: CPSW driver for Keystone 10GE devices

This patch comes from:
  git://git.ti.com/keystone-linux/linux.git

Signed-off-by: Zumeng Chen <zumeng.chen@windriver.com>
---
 drivers/net/ethernet/ti/keystone_xgemdio.c |  525 ++++++
 drivers/net/ethernet/ti/keystone_xgepcsr.c | 1434 ++++++++++++++++
 drivers/net/ethernet/ti/keystone_xgess.c   | 2553 ++++++++++++++++++++++++++++
 3 files changed, 4512 insertions(+), 0 deletions(-)
 create mode 100644 drivers/net/ethernet/ti/keystone_xgemdio.c
 create mode 100644 drivers/net/ethernet/ti/keystone_xgepcsr.c
 create mode 100644 drivers/net/ethernet/ti/keystone_xgess.c

diff --git a/drivers/net/ethernet/ti/keystone_xgemdio.c b/drivers/net/ethernet/ti/keystone_xgemdio.c
new file mode 100644
index 0000000..6ef634e
--- /dev/null
+++ b/drivers/net/ethernet/ti/keystone_xgemdio.c
@@ -0,0 +1,525 @@
+/*
+ * Keystone MDIO Module driver
+ *
+ * Copyright (C) 2013 Texas Instruments.
+ *
+ * Shamelessly cloned from davinci_mdio.c, original copyrights follow:
+ *
+ * Copyright (C) 2009 Texas Instruments.
+ *
+ * ---------------------------------------------------------------------------
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ * ---------------------------------------------------------------------------
+ */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+#include <linux/delay.h>
+#include <linux/sched.h>
+#include <linux/slab.h>
+#include <linux/phy.h>
+#include <linux/clk.h>
+#include <linux/err.h>
+#include <linux/io.h>
+#include <linux/pm_runtime.h>
+#include <linux/davinci_emac.h>
+#include <linux/of.h>
+#include <linux/of_mdio.h>
+#include <linux/of_device.h>
+#include "keystone_net.h"
+
+/*
+ * This timeout definition is a worst-case ultra defensive measure against
+ * unexpected controller lock ups.  Ideally, we should never ever hit this
+ * scenario in practice.
+ */
+#define MDIO_TIMEOUT		100 /* msecs */
+
+#define PHY_REG_MASK		0x1f
+#define PHY_ID_MASK		0x1f
+
+#define DEF_OUT_FREQ		2200000		/* 2.2 MHz */
+
+struct keystone_mdiox_regs {
+	u32	version;
+	u32	control;
+#define CONTROL_IDLE		BIT(31)
+#define CONTROL_ENABLE		BIT(30)
+#define CONTROL_MAX_DIV		(0xffff)
+
+	u32	alive;
+	u32	link;
+	u32	linkintraw;
+	u32	linkintmasked;
+	u32	__reserved_0[2];
+	u32	userintraw;
+	u32	userintmasked;
+	u32	userintmaskset;
+	u32	userintmaskclr;
+	u32	__reserved_1[20];
+
+	struct {
+		u32	access;
+#define USERACCESS_GO		BIT(31)
+#define USERACCESS_WRITE	BIT(30)
+#define USERACCESS_ACK		BIT(29)
+#define USERACCESS_READ		(0)
+#define USERACCESS_DATA		(0xffff)
+
+		u32	physel;
+	}	user[0];
+};
+
+struct mdio_platform_data k_default_pdata = {
+	.bus_freq = DEF_OUT_FREQ,
+};
+
+struct keystone_mdiox_data {
+	struct mdio_platform_data pdata;
+	struct keystone_mdiox_regs __iomem *regs;
+	spinlock_t	lock;
+	struct clk	*clk;
+	struct device	*dev;
+	struct mii_bus	*bus;
+	bool		suspended;
+	unsigned long	access_time; /* jiffies */
+};
+
+static void __keystone_mdiox_reset(struct keystone_mdiox_data *data)
+{
+	u32 mdio_in, div, mdio_out_khz, access_time;
+
+	mdio_in = clk_get_rate(data->clk);
+	div = (mdio_in / data->pdata.bus_freq) - 1;
+	if (div > CONTROL_MAX_DIV)
+		div = CONTROL_MAX_DIV;
+
+	/* set enable and clock divider */
+	__raw_writel(div | CONTROL_ENABLE, &data->regs->control);
+
+	/*
+	 * One mdio transaction consists of:
+	 *	32 bits of preamble
+	 *	32 bits of transferred data
+	 *	24 bits of bus yield (not needed unless shared?)
+	 */
+	mdio_out_khz = mdio_in / (1000 * (div + 1));
+	access_time  = (88 * 1000) / mdio_out_khz;
+
+	/*
+	 * In the worst case, we could be kicking off a user-access immediately
+	 * after the mdio bus scan state-machine triggered its own read.  If
+	 * so, our request could get deferred by one access cycle.  We
+	 * defensively allow for 4 access cycles.
+	 */
+	data->access_time = usecs_to_jiffies(access_time * 4);
+	if (!data->access_time)
+		data->access_time = 1;
+}
+
+static int keystone_mdiox_reset(struct mii_bus *bus)
+{
+	struct keystone_mdiox_data *data = bus->priv;
+	u32 phy_mask, ver;
+
+	__keystone_mdiox_reset(data);
+
+	/* wait for scan logic to settle */
+	msleep(PHY_MAX_ADDR * data->access_time);
+
+	/* dump hardware version info */
+	ver = __raw_readl(&data->regs->version);
+	dev_info(data->dev, "keystone mdio revision %d.%d\n",
+		 (ver >> 8) & 0xff, ver & 0xff);
+
+	/* OF explicitly registers phy devices without a bus scan */
+	if (data->dev->of_node)
+		return 0;
+
+	/* get phy mask from the alive register */
+	phy_mask = __raw_readl(&data->regs->alive);
+	if (phy_mask) {
+		/* restrict mdio bus to live phys only */
+		dev_info(data->dev, "detected phy mask %x\n", ~phy_mask);
+		phy_mask = ~phy_mask;
+	} else {
+		/* desperately scan all phys */
+		dev_warn(data->dev, "no live phy, scanning all\n");
+		phy_mask = 0;
+	}
+	data->bus->phy_mask = phy_mask;
+
+	return 0;
+}
+
+/* wait until hardware is ready for another user access */
+static inline int wait_for_user_access(struct keystone_mdiox_data *data)
+{
+	struct keystone_mdiox_regs __iomem *regs = data->regs;
+	unsigned long timeout = jiffies + msecs_to_jiffies(MDIO_TIMEOUT);
+	u32 reg;
+
+	while (time_after(timeout, jiffies)) {
+		reg = __raw_readl(&regs->user[0].access);
+		if ((reg & USERACCESS_GO) == 0)
+			return 0;
+
+		reg = __raw_readl(&regs->control);
+		if ((reg & CONTROL_IDLE) == 0)
+			continue;
+
+		/*
+		 * An emac soft_reset may have clobbered the mdio controller's
+		 * state machine.  We need to reset and retry the current
+		 * operation
+		 */
+		dev_warn(data->dev, "resetting idled controller\n");
+		__keystone_mdiox_reset(data);
+		return -EAGAIN;
+	}
+
+	reg = __raw_readl(&regs->user[0].access);
+	if ((reg & USERACCESS_GO) == 0)
+		return 0;
+
+	dev_err(data->dev, "timed out waiting for user access\n");
+	return -ETIMEDOUT;
+}
+
+/* wait until hardware state machine is idle */
+static inline int wait_for_idle(struct keystone_mdiox_data *data)
+{
+	struct keystone_mdiox_regs __iomem *regs = data->regs;
+	unsigned long timeout = jiffies + msecs_to_jiffies(MDIO_TIMEOUT);
+
+	while (time_after(timeout, jiffies)) {
+		if (__raw_readl(&regs->control) & CONTROL_IDLE)
+			return 0;
+	}
+	dev_err(data->dev, "timed out waiting for idle\n");
+	return -ETIMEDOUT;
+}
+
+static int keystone_mdiox_read(struct mii_bus *bus, int phy_id, int phy_reg)
+{
+	struct keystone_mdiox_data *data = bus->priv;
+	u32 reg;
+	int ret;
+
+	if (phy_reg & ~PHY_REG_MASK || phy_id & ~PHY_ID_MASK)
+		return -EINVAL;
+
+	spin_lock(&data->lock);
+
+	if (data->suspended) {
+		spin_unlock(&data->lock);
+		return -ENODEV;
+	}
+
+	reg = (USERACCESS_GO | USERACCESS_READ | (phy_reg << 21) |
+	       (phy_id << 16));
+
+	while (1) {
+		ret = wait_for_user_access(data);
+		if (ret == -EAGAIN)
+			continue;
+		if (ret < 0)
+			break;
+
+		__raw_writel(reg, &data->regs->user[0].access);
+
+		ret = wait_for_user_access(data);
+		if (ret == -EAGAIN)
+			continue;
+		if (ret < 0)
+			break;
+
+		reg = __raw_readl(&data->regs->user[0].access);
+		ret = (reg & USERACCESS_ACK) ? (reg & USERACCESS_DATA) : -EIO;
+		break;
+	}
+
+	spin_unlock(&data->lock);
+
+	return ret;
+}
+
+static int keystone_mdiox_write(struct mii_bus *bus, int phy_id,
+			      int phy_reg, u16 phy_data)
+{
+	struct keystone_mdiox_data *data = bus->priv;
+	u32 reg;
+	int ret;
+
+	if (phy_reg & ~PHY_REG_MASK || phy_id & ~PHY_ID_MASK)
+		return -EINVAL;
+
+	spin_lock(&data->lock);
+
+	if (data->suspended) {
+		spin_unlock(&data->lock);
+		return -ENODEV;
+	}
+
+	reg = (USERACCESS_GO | USERACCESS_WRITE | (phy_reg << 21) |
+		   (phy_id << 16) | (phy_data & USERACCESS_DATA));
+
+	while (1) {
+		ret = wait_for_user_access(data);
+		if (ret == -EAGAIN)
+			continue;
+		if (ret < 0)
+			break;
+
+		__raw_writel(reg, &data->regs->user[0].access);
+
+		ret = wait_for_user_access(data);
+		if (ret == -EAGAIN)
+			continue;
+		break;
+	}
+
+	spin_unlock(&data->lock);
+
+	return 0;
+}
+
+static int keystone_mdiox_probe_dt(struct mdio_platform_data *data,
+			 struct platform_device *pdev)
+{
+	struct device_node *node = pdev->dev.of_node;
+	u32 prop;
+
+	if (!node)
+		return -EINVAL;
+
+	if (of_property_read_u32(node, "bus_freq", &prop)) {
+		pr_err("Missing bus_freq property in the DT.\n");
+		return -EINVAL;
+	}
+	data->bus_freq = prop;
+
+	return 0;
+}
+
+
+static int keystone_mdiox_probe(struct platform_device *pdev)
+{
+	struct mdio_platform_data *pdata = pdev->dev.platform_data;
+	struct device_node *node = pdev->dev.of_node;
+	struct device *dev = &pdev->dev;
+	struct keystone_mdiox_data *data;
+	struct resource *res;
+	struct phy_device *phy;
+	int ret, addr;
+
+	data = kzalloc(sizeof(*data), GFP_KERNEL);
+	if (!data) {
+		dev_err(dev, "failed to alloc device data\n");
+		return -ENOMEM;
+	}
+
+	data->bus = mdiobus_alloc();
+	if (!data->bus) {
+		dev_err(dev, "failed to alloc mii bus\n");
+		ret = -ENOMEM;
+		goto bail_out;
+	}
+
+	if (dev->of_node) {
+		if (keystone_mdiox_probe_dt(&data->pdata, pdev))
+			data->pdata = k_default_pdata;
+		snprintf(data->bus->id, MII_BUS_ID_SIZE, "%s", pdev->name);
+	} else {
+		data->pdata = pdata ? (*pdata) : k_default_pdata;
+		snprintf(data->bus->id, MII_BUS_ID_SIZE, "%s-%x",
+			 pdev->name, pdev->id);
+	}
+
+	data->bus->name		= dev_name(dev);
+	data->bus->read		= keystone_mdiox_read,
+	data->bus->write	= keystone_mdiox_write,
+	data->bus->reset	= keystone_mdiox_reset,
+	data->bus->parent	= dev;
+	data->bus->priv		= data;
+	data->dev = dev;
+
+	pm_runtime_enable(&pdev->dev);
+	data->clk = clk_get(&pdev->dev, "fck");
+	if (IS_ERR(data->clk)) {
+		dev_err(dev, "failed to get device clock\n");
+		ret = PTR_ERR(data->clk);
+		data->clk = NULL;
+		goto bail_out;
+	}
+
+	clk_prepare(data->clk);
+	pm_runtime_get_sync(&pdev->dev);
+	dev_set_drvdata(dev, data);
+	spin_lock_init(&data->lock);
+
+	xge_serdes_init_156p25Mhz();
+
+	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!res) {
+		dev_err(dev, "could not find register map resource\n");
+		ret = -ENOENT;
+		goto bail_out;
+	}
+
+	res = devm_request_mem_region(dev, res->start, resource_size(res),
+					    dev_name(dev));
+	if (!res) {
+		dev_err(dev, "could not allocate register map resource\n");
+		ret = -ENXIO;
+		goto bail_out;
+	}
+
+	data->regs = devm_ioremap_nocache(dev, res->start, resource_size(res));
+	if (!data->regs) {
+		dev_err(dev, "could not map mdio registers\n");
+		ret = -ENOMEM;
+		goto bail_out;
+	}
+
+	/* register the mii bus */
+	ret = of_mdiobus_register(data->bus, node);
+	if (ret)
+		goto bail_out;
+
+	/* scan and dump the bus */
+	for (addr = 0; addr < PHY_MAX_ADDR; addr++) {
+		phy = data->bus->phy_map[addr];
+		if (phy) {
+			dev_info(dev, "phy[%d]: device %s, driver %s\n",
+				 phy->addr, dev_name(&phy->dev),
+				 phy->drv ? phy->drv->name : "unknown");
+		}
+	}
+	return 0;
+
+bail_out:
+	if (data->bus)
+		mdiobus_free(data->bus);
+
+	if (data->clk)
+		clk_put(data->clk);
+	pm_runtime_put_sync(&pdev->dev);
+	pm_runtime_disable(&pdev->dev);
+
+	kfree(data);
+
+	return ret;
+
+}
+
+static int keystone_mdiox_remove(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct keystone_mdiox_data *data = dev_get_drvdata(dev);
+
+	if (data->bus) {
+		mdiobus_unregister(data->bus);
+		mdiobus_free(data->bus);
+	}
+
+	if (data->clk)
+		clk_put(data->clk);
+	pm_runtime_put_sync(&pdev->dev);
+	pm_runtime_disable(&pdev->dev);
+
+	dev_set_drvdata(dev, NULL);
+
+	kfree(data);
+
+	return 0;
+}
+
+static int keystone_mdiox_suspend(struct device *dev)
+{
+	struct keystone_mdiox_data *data = dev_get_drvdata(dev);
+	u32 ctrl;
+
+	spin_lock(&data->lock);
+
+	/* shutdown the scan state machine */
+	ctrl = __raw_readl(&data->regs->control);
+	ctrl &= ~CONTROL_ENABLE;
+	__raw_writel(ctrl, &data->regs->control);
+	wait_for_idle(data);
+
+	pm_runtime_put_sync(data->dev);
+
+	data->suspended = true;
+	spin_unlock(&data->lock);
+
+	return 0;
+}
+
+static int keystone_mdiox_resume(struct device *dev)
+{
+	struct keystone_mdiox_data *data = dev_get_drvdata(dev);
+	u32 ctrl;
+
+	spin_lock(&data->lock);
+	pm_runtime_put_sync(data->dev);
+
+	/* restart the scan state machine */
+	ctrl = __raw_readl(&data->regs->control);
+	ctrl |= CONTROL_ENABLE;
+	__raw_writel(ctrl, &data->regs->control);
+
+	data->suspended = false;
+	spin_unlock(&data->lock);
+
+	return 0;
+}
+
+static const struct dev_pm_ops keystone_mdiox_pm_ops = {
+	.suspend	= keystone_mdiox_suspend,
+	.resume		= keystone_mdiox_resume,
+};
+
+static const struct of_device_id keystone_mdiox_of_mtable[] = {
+	{ .compatible = "ti,keystone_mdiox", },
+	{ /* sentinel */ },
+};
+
+static struct platform_driver keystone_mdiox_driver = {
+	.driver = {
+		.name	 = "keystone_mdiox",
+		.owner	 = THIS_MODULE,
+		.pm	 = &keystone_mdiox_pm_ops,
+		.of_match_table = of_match_ptr(keystone_mdiox_of_mtable),
+	},
+	.probe = keystone_mdiox_probe,
+	.remove = keystone_mdiox_remove,
+};
+
+static int __init keystone_mdiox_init(void)
+{
+	return platform_driver_register(&keystone_mdiox_driver);
+}
+device_initcall(keystone_mdiox_init);
+
+static void __exit keystone_mdiox_exit(void)
+{
+	platform_driver_unregister(&keystone_mdiox_driver);
+}
+module_exit(keystone_mdiox_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("Keystone XGE MDIO driver");
diff --git a/drivers/net/ethernet/ti/keystone_xgepcsr.c b/drivers/net/ethernet/ti/keystone_xgepcsr.c
new file mode 100644
index 0000000..2ca0beb
--- /dev/null
+++ b/drivers/net/ethernet/ti/keystone_xgepcsr.c
@@ -0,0 +1,1434 @@
+/*
+ * Copyright (C) 2012 Texas Instruments Incorporated
+ * Author: WingMan Kwok <w-kwok2@ti.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation version 2.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/io.h>
+#include <linux/of.h>
+#include <linux/err.h>
+#include <linux/delay.h>
+
+#include "keystone_net.h"
+
+#define XGE_SERDES_BASE		0x0231e000
+#define XGE_SERDES_SIZE		0x2000
+
+#define XGE_SW_BASE		0x02f00000
+#define XGE_SW_SIZE		0x00001000
+
+#define XGE_CTRL_OFFSET		0x0c
+#define XGE_SGMII_1_OFFSET	0x0114
+#define XGE_SGMII_2_OFFSET	0x0214
+
+/*
+ * Keystone2 SERDES registers
+ */
+/* 0x1fc0 - 0x1fff */
+#define K2SERDES_SS_OFFSET	0x1fc0
+/* 0x1fc0 */
+#define MOD_VER_REG		(K2SERDES_SS_OFFSET + 0x00)
+/* 0x1fd0 */
+#define CPU_CTRL_REG		(K2SERDES_SS_OFFSET + 0x10)
+/* 0x1ff4 */
+#define PLL_CTRL_REG		(K2SERDES_SS_OFFSET + 0x34)
+/* 0x1fe0, 0x1fe4 */
+#define LANE_CTRL_STS_REG(x)	(K2SERDES_SS_OFFSET + 0x20 + (x * 0x04))
+
+/* CMU0 SS 0x0000 - 0x01ff */
+#define CMU0_SS_OFFSET		0x0000
+#define CMU0_REG(x)		(CMU0_SS_OFFSET + x)
+
+/* LANE SS 0x0200 - 0x03ff, 0x0400 - 0x05ff, ... */
+#define LANE0_SS_OFFSET		0x0200
+#define LANEX_SS_OFFSET(x)	(LANE0_SS_OFFSET * (x + 1))
+#define LANEX_REG(x, y)		(LANEX_SS_OFFSET(x) + y)
+
+/* CML SS 0x0a00 - 0x0bff */
+#define CML_SS_OFFSET		0x0a00
+#define CML_REG(x)		(CML_SS_OFFSET + x)
+
+/* CMU1 SS 0x0c00 - 0x0dff */
+#define CMU1_SS_OFFSET		0x0c00
+#define CMU1_REG(x)		(CMU1_SS_OFFSET + x)
+
+/*
+ * PCS-R registers
+ */
+#define PCSR_OFFSET(x)		(0x600 + (x * 0x80))
+
+#define PCSR_TX_CTL(x)		(PCSR_OFFSET(x) + 0x00)
+#define PCSR_TX_STATUS(x)	(PCSR_OFFSET(x) + 0x04)
+#define PCSR_RX_CTL(x)		(PCSR_OFFSET(x) + 0x08)
+#define PCSR_RX_STATUS(x)	(PCSR_OFFSET(x) + 0x0C)
+
+#define PCSR_SEED_A_LO(x)	(PCSR_OFFSET(x) + 0x10)
+#define PCSR_SEED_A_HI(x)	(PCSR_OFFSET(x) + 0x14)
+#define PCSR_SEED_B_LO(x)	(PCSR_OFFSET(x) + 0x18)
+#define PCSR_SEED_B_HI(x)	(PCSR_OFFSET(x) + 0x1C)
+
+#define PCSR_FEC(x)		(PCSR_OFFSET(x) + 0x20)
+#define PCSR_CTL(x)		(PCSR_OFFSET(x) + 0x24)
+#define PCSR_RX_FEC_CNT(x)	(PCSR_OFFSET(x) + 0x28)
+#define PCSR_RX_ERR_FIFO(x)	(PCSR_OFFSET(x) + 0x2C)
+
+#define PCSR_SIGNAL_OK_EN	BIT(1)
+
+#define reg_rmw(addr, value, mask) \
+	__raw_writel(((__raw_readl(addr) & (~(mask))) | \
+			(value & (mask))), (addr))
+
+/* bit mask from bit-a to bit-b inclusive */
+#define MASK(msb, lsb) \
+	((((msb) - (lsb)) == 31) ? 0xffffffff :  \
+		((((u32)1 << ((msb) - (lsb) + 1)) - 1) << (lsb)))
+
+#define FINSR(base, offset, msb, lsb, val) \
+	reg_rmw((base) + (offset), ((val) << (lsb)), MASK((msb), (lsb)))
+
+#define PHY_A(serdes) \
+	(0x4eba != ((k2serdes_readl(serdes, MOD_VER_REG) >> 16) & 0xffff))
+
+#define MOD_VER(serdes) \
+	((k2serdes_readl(serdes, MOD_VER_REG) >> 16) & 0xffff)
+
+#define FOUR_LANE(serdes) \
+	((0x4eb9 == MOD_VER(serdes)) || (0x4ebd == MOD_VER(serdes)))
+
+#define K2SERDES_REF_CLOCK_156P25M	0
+
+#define K2SERDES_LINK_RATE_10P3125G	0
+#define K2SERDES_LINK_RATE_1P25G	1
+
+#define K2SERDES_PHY_XGE		0
+#define K2SERDES_PHY_SGMII		1
+#define K2SERDES_PHY_PCIE		2
+
+#define MAX_LANES			4
+#define MAX_COMPARATORS			5
+
+#define DFE_OFFSET_SAMPLES		100
+
+struct k2serdes_comparator_tap_offsets {
+	u32 cmp;
+	u32 tap1;
+	u32 tap2;
+	u32 tap3;
+	u32 tap4;
+	u32 tap5;
+};
+
+struct k2serdes_lane_offsets {
+	struct k2serdes_comparator_tap_offsets ct_ofs[MAX_COMPARATORS];
+};
+
+struct k2serdes_offsets {
+	struct k2serdes_lane_offsets lane_ofs[MAX_LANES];
+};
+
+struct hw_specific {
+	u32 ref_clock_rate;
+	u32 link_rate;
+	u32 lanes;
+	u32 phy_type;
+	u32 c1;
+	u32 c2;
+	u32 cm;
+	u32 tx_att;
+	u32 tx_vreg;
+	u32 eq_vreg_enable;
+	u32 eq_cdfe_enable;
+	u32 eq_offset_enable;
+};
+
+struct serdes_cfg {
+	u32 ofs;
+	u32 msb;
+	u32 lsb;
+	u32 val;
+};
+
+/* offset w.r.t. CMU0 SS 0x0000 */
+struct serdes_cfg cfg_phyb_1p25g_156p25mhz_cmu0[] = {
+	{0x0000,	 7, 0,		0x02},
+	{0x0000,	23, 16,		0x80},
+	{0x0014,	 7, 0,		0x38},
+	{0x0014,	15, 8,		0x38},
+	{0x0060,	 7, 0,		0x38},
+	{0x0060,	15, 8,		0xe4},
+	{0x0060,	23, 16,		0x44},
+	{0x0060,	31, 24,		0x1c},
+	{0x0064,	 7, 0,		0x00},
+	{0x0064,	15, 8,		0x84},
+	{0x0064,	23, 16,		0xc1},
+	{0x0068,	15, 8,		0x82},
+	{0x0068,	23, 16,		0x07},
+	{0x0068,	31, 24,		0x17},
+	{0x006c,	 7, 0,		0x14},
+	{0x0078,	15, 8,		0xc0},
+	{0x0000,	 7, 0,		0x03},
+};
+
+/* offset w.r.t. CMU1 SS 0x0c00 */
+struct serdes_cfg cfg_phyb_10p3125g_156p25mhz_cmu1[] = {
+	{0x0000,	 7, 0,		0x02},
+	{0x0000,	23, 16,		0x03},
+	{0x0014,	 7, 0,		0x52},
+	{0x0014,	15, 8,		0x52},
+	{0x0028,	31, 24,		0x80},
+	{0x002c,	 7, 0,		0xf6},
+	{0x003c,	 7, 0,		0x05},
+	{0x003c,	15, 8,		0x04},
+	{0x003c,	31, 24,		0x04},
+	{0x0040,	23, 16,		0x80},
+	{0x0040,	31, 16,		0xc0},
+	{0x0044,	 7, 0,		0x62},
+	{0x0044,	15, 8,		0x20},
+	{0x0044,	23, 16,		0x20},
+	{0x0044,	31, 24,		0x5a},
+	{0x0048,	 7, 0,		0x24},
+	{0x0048,	15, 8,		0x04},
+	{0x0048,	23, 16,		0x04},
+	{0x0048,	31, 24,		0x40},
+	{0x004c,	 7, 0,		0x02},
+	{0x004c,	15, 8,		0x40},
+	{0x0050,	15, 8,		0x1c},
+	{0x0050,	31, 24,		0x19},
+	{0x0054,	15, 8,		0x21},
+	{0x0058,	 7, 0,		0x60},
+	{0x0060,	 7, 0,		0x7c},
+	{0x0060,	15, 8,		0x1e},
+	{0x0060,	23, 16,		0x13},
+	{0x0060,	31, 24,		0x80},
+	{0x0064,	 7, 0,		0x02},
+	{0x0064,	15, 8,		0xcb},
+	{0x0064,	31, 24,		0x84},
+	{0x0068,	15, 8,		0x82},
+	{0x0068,	23, 16,		0x07},
+	{0x0068,	31, 24,		0x17},
+	{0x006c,	 7, 0,		0x16},
+	{0x0074,	15, 8,		0x04},
+	{0x0078,	15, 8,		0xc0},
+	{0x0000,	 7, 0,		0x03},
+};
+
+/* offset w.r.t. LaneX SS 0x0200, 0x0400, ... */
+struct serdes_cfg cfg_phyb_10p3125g_16bit_lane[] = {
+	{0x0004,	 7, 0,		0x80},
+	{0x0008,	 7, 0,		0x0d},
+	{0x0008,	15, 8,		0x92},
+	{0x0004,	31, 24,		0xfc},
+	{0x0008,	 7, 0,		0x04},
+	{0x0008,	15, 8,		0x91},
+	{0x0010,	31, 24,		0x1a},
+	{0x0014,	 7, 0,		0x58},
+	{0x0014,	15, 8,		0x6b},
+	{0x0014,	23, 16,		0x00},
+	{0x0018,	 7, 0,		0x84},
+	{0x0018,	23, 16,		0x80},
+	{0x0018,	31, 24,		0x75},
+	{0x002c,	23, 16,		0x30},
+	{0x0030,	15, 8,		0x38},
+	{0x004c,	23, 16,		0x8f},
+	{0x0050,	31, 24,		0x30},
+	{0x0060,	 7, 0,		0x02},
+	{0x0064,	 7, 0,		0x57},
+	{0x0068,	15, 8,		0x57},
+	{0x0068,	23, 16,		0x57},
+	{0x0078,	31, 24,		0xff},
+	{0x0080,	 7, 0,		0x50},
+	{0x0080,	23, 16,		0x50},
+	{0x0084,	 7, 0,		0x15},
+	{0x0084,	15, 8,		0x1f},
+	{0x008c,	15, 8,		0x6f},
+	{0x0094,	15, 8,		0x00},
+	{0x0094,	23, 16,		0x00},
+	{0x0094,	31, 24,		0x00},
+	{0x0098,	 7, 0,		0x40},
+	{0x0098,	15, 8,		0x26},
+	{0x0098,	31, 24,		0x00},
+	{0x009c,	 7, 0,		0x03},
+	{0x00a4,	 7, 0,		0x13},
+	{0x00a4,	15, 8,		0x0f},
+	{0x00a8,	15, 8,		0xb6},
+	{0x00a8,	23, 16,		0x01},
+	{0x0180,	 7, 0,		0x30},
+	{0x01c0,	15, 8,		0x02},
+	{0x01cc,	 7, 0,		0x18},
+	{0x01cc,	 7, 0,		0x00},
+};
+
+/* offset w.r.t. LaneX SS 0x0200, 0x0400, ... */
+struct serdes_cfg cfg_phyb_aneg_lane[] = {
+	{0x0004,	 7, 0,		0x80},
+	{0x0004,	31, 24,		0x70},
+	{0x0008,	 7, 0,		0x00},
+	{0x0008,	15, 8,		0x00},
+	{0x0010,	31, 24,		0x1b},
+	{0x0014,	 7, 0,		0xf8},
+	{0x0014,	15, 8,		0x6b},
+	{0x0014,	23, 16,		0x00},
+	{0x0018,	 7, 0,		0x74},
+	{0x0018,	23, 16,		0x80},
+	{0x0018,	31, 24,		0x75},
+	{0x0030,	15, 8,		0x00},
+	{0x004c,	23, 16,		0x8f},
+	{0x0050,	31, 24,		0x00},
+	{0x0060,	 7, 0,		0x00},
+	{0x0064,	 7, 0,		0x57},
+	{0x0068,	15, 8,		0x57},
+	{0x0068,	23, 16,		0x57},
+	{0x0078,	31, 24,		0xff},
+	{0x0080,	 7, 0,		0x50},
+	{0x0080,	23, 16,		0x50},
+	{0x0084,	 7, 0,		0x05},
+	{0x0094,	15, 8,		0x00},
+	{0x0094,	23, 16,		0x00},
+	{0x0094,	31, 24,		0x00},
+	{0x0098,	 7, 0,		0x00},
+	{0x0098,	15, 8,		0x00},
+	{0x0098,	31, 24,		0x00},
+	{0x009c,	 7, 0,		0x01},
+	{0x00a4,	 7, 0,		0x0a},
+	{0x00a4,	15, 8,		0x00},
+	{0x00a8,	15, 8,		0xb6},
+	{0x00a8,	23, 16,		0x01},
+	{0x0180,	 7, 0,		0xb0},
+	{0x0180,	 7, 0,		0x30},
+	{0x01c0,	15, 8,		0x00},
+	{0x01cc,	 7, 0,		0x18},
+};
+
+/* offset w.r.t. CML SS 0x0a00 */
+struct serdes_cfg cfg_phyb_10p3125g_cml[] = {
+	{0x0000,	15, 8,		0x08},
+	{0x0084,	 7, 0,		0x00},
+	{0x008c,	23, 16,		0x13},
+	{0x0090,	23, 16,		0xa0},
+	{0x0090,	31, 24,		0x77},
+	{0x0094,	 7, 0,		0x77},
+	{0x0094,	15, 8,		0x77},
+	{0x0108,	23, 16,		0x0f},
+	{0x0108,	31, 24,		0x00},
+	{0x010c,	 7, 0,		0x00},
+	{0x010c,	15, 8,		0x00},
+	{0x010c,	23, 16,		0x0f},
+	{0x0110,	31, 24,		0xbe},
+	{0x0114,	 7, 0,		0xff},
+	{0x0118,	 7, 0,		0x14},
+	{0x015c,	23, 16,		0x1b},
+	{0x015c,	31, 24,		0x98},
+	{0x0164,	15, 8,		0x11},
+	{0x0178,	15, 8,		0x0c},
+	{0x00bc,	31, 24,		0xff},
+	{0x00c0,	 7, 0,		0x8b},
+};
+
+/* offset w.r.t. CML SS 0x0a00 */
+struct serdes_cfg cfg_phyb_1p25g_156p25mhz_cml[] = {
+	{0x0000,	15, 8,		0x08},
+	{0x0084,	 7, 0,		0x00},
+	{0x0090,	23, 16,		0xa0},
+	{0x0090,	31, 24,		0x77},
+	{0x0094,	 7, 0,		0x77},
+	{0x0094,	15, 8,		0x77},
+	{0x0108,	23, 16,		0x00},
+	{0x0108,	31, 24,		0x00},
+	{0x010c,	 7, 0,		0x00},
+	{0x010c,	15, 8,		0x00},
+	{0x010c,	23, 16,		0x00},
+	{0x0110,	31, 24,		0xbe},
+	{0x0114,	 7, 0,		0xff},
+	{0x0118,	 7, 0,		0x14},
+	{0x015c,	23, 16,		0x1b},
+	{0x015c,	31, 24,		0x98},
+	{0x0164,	15, 8,		0x11},
+	{0x0178,	15, 8,		0x0c},
+	{0x00bc,	31, 24,		0xff},
+	{0x00c0,	 7, 0,		0x8b},
+	{0x0048,	15, 8,		0x8c},
+	{0x0048,	23, 16,		0xfd},
+	{0x0054,	 7, 0,		0x72},
+	{0x0054,	15, 8,		0xec},
+	{0x0054,	23, 16,		0x2f},
+	{0x0058,	15, 8,		0x21},
+	{0x0058,	23, 16,		0xf9},
+	{0x0058,	31, 24,		0x00},
+	{0x005c,	 7, 0,		0x60},
+	{0x005c,	15, 8,		0x00},
+	{0x005c,	23, 16,		0x04},
+	{0x005c,	31, 24,		0x00},
+	{0x0060,	 7, 0,		0x00},
+	{0x0060,	15, 8,		0x80},
+	{0x0060,	23, 16,		0x00},
+	{0x0060,	31, 24,		0x00},
+	{0x0064,	 7, 0,		0x20},
+	{0x0064,	15, 8,		0x12},
+	{0x0064,	23, 16,		0x58},
+	{0x0064,	31, 24,		0x0c},
+	{0x0068,	 7, 0,		0x02},
+	{0x0068,	15, 8,		0x06},
+	{0x0068,	23, 16,		0x3b},
+	{0x0068,	31, 24,		0xe1},
+	{0x006c,	 7, 0,		0xc1},
+	{0x006c,	15, 8,		0x4c},
+	{0x006c,	23, 16,		0x07},
+	{0x006c,	31, 24,		0xb8},
+	{0x0070,	 7, 0,		0x89},
+	{0x0070,	15, 8,		0xe9},
+	{0x0070,	23, 16,		0x02},
+	{0x0070,	31, 24,		0x3f},
+	{0x0074,	 7, 0,		0x01},
+	{0x011c,	31, 24,		0x37},
+	{0x0120,	 7, 0,		0x5d},
+	{0x0120,	23, 16,		0x37},
+};
+
+static inline u32 k2serdes_readl(void __iomem *base, u32 offset)
+{
+	return readl(base + offset);
+}
+
+static inline void k2serdes_writel(void __iomem *base, u32 offset, u32 value)
+{
+	writel(value, base + offset);
+}
+
+static inline u32 k2serdes_read_tbus_val(void __iomem *serdes)
+{
+	u32 tmp;
+
+	if (PHY_A(serdes)) {
+		tmp  = ((k2serdes_readl(serdes, CMU0_REG(0xec))) >> 24) & 0x0ff;
+		tmp |= ((k2serdes_readl(serdes, CMU0_REG(0xfc))) >> 16) & 0xf00;
+	} else
+		tmp  = ((k2serdes_readl(serdes, CMU0_REG(0xf8))) >> 16) & 0xfff;
+
+	return tmp;
+}
+
+static void k2serdes_write_tbus_addr(void __iomem *serdes, int select, int ofs)
+{
+	if (select && !FOUR_LANE(serdes))
+		++select;
+
+	if (PHY_A(serdes))
+		FINSR(serdes, CMU0_REG(0x8), 31, 24, ((select << 5) + ofs));
+	else
+		FINSR(serdes, CMU0_REG(0xfc), 26, 16, ((select << 8) + ofs));
+}
+
+u32 k2serdes_read_select_tbus(void __iomem *serdes,
+				int select, int ofs)
+{
+	/* set tbus address */
+	k2serdes_write_tbus_addr(serdes, select, ofs);
+	/* get tbus value */
+	return k2serdes_read_tbus_val(serdes);
+}
+
+static inline void k2serdes_config_ss(void __iomem *ss_base,
+				struct serdes_cfg *serdes_cfg,
+				int serdes_cfg_num)
+{
+	int i;
+
+	for (i = 0; i < serdes_cfg_num; i++) {
+		FINSR(ss_base, serdes_cfg[i].ofs,
+			serdes_cfg[i].msb,
+			serdes_cfg[i].lsb,
+			serdes_cfg[i].val);
+	}
+}
+
+static inline void k2serdes_phyb_rst_clr(void __iomem *serdes)
+{
+	FINSR(serdes, CML_REG(0), 5, 0, 0x1f);
+}
+
+static inline int k2serdes_phyb_in_rst(void __iomem *serdes)
+{
+	u32 val;
+
+	/* read CML_00[4:0] */
+	val = k2serdes_readl(serdes, CML_REG(0));
+	return ((val & 0x1f) == 0x00);
+}
+
+static inline void k2serdes_pll_disable(void __iomem *serdes)
+{
+	FINSR(serdes, PLL_CTRL_REG, 31, 29, 0x4);
+	FINSR(serdes, PLL_CTRL_REG, 27, 25, 0x4);
+}
+
+static inline void k2serdes_pll_enable_10p3125g(void __iomem *serdes)
+{
+	FINSR(serdes, PLL_CTRL_REG, 31, 29, 0x7);
+	FINSR(serdes, PLL_CTRL_REG, 27, 25, 0x7);
+}
+
+static inline void k2serdes_pll_enable_1p25g(void __iomem *serdes)
+{
+	k2serdes_writel(serdes, PLL_CTRL_REG, 0xe0000000);
+}
+
+static inline void k2serdes_pll_enable(void __iomem *serdes,
+					struct hw_specific *hw)
+{
+	k2serdes_phyb_rst_clr(serdes);
+
+	if (hw->link_rate == K2SERDES_LINK_RATE_10P3125G)
+		k2serdes_pll_enable_10p3125g(serdes);
+	else if (hw->link_rate == K2SERDES_LINK_RATE_1P25G)
+		k2serdes_pll_enable_1p25g(serdes);
+}
+
+static int k2serdes_init(void __iomem *serdes,
+				struct hw_specific *hw)
+{
+	struct serdes_cfg *serdes_cfg;
+	void __iomem *base;
+	int a_size;
+
+	if (hw->ref_clock_rate != K2SERDES_REF_CLOCK_156P25M)
+		return -EINVAL;
+
+	if ((hw->link_rate != K2SERDES_LINK_RATE_10P3125G) &&
+		(hw->link_rate != K2SERDES_LINK_RATE_1P25G))
+		return -EINVAL;
+
+	k2serdes_pll_disable(serdes);
+
+	/* cmu0 setup */
+	a_size		= ARRAY_SIZE(cfg_phyb_1p25g_156p25mhz_cmu0);
+	serdes_cfg	= &cfg_phyb_1p25g_156p25mhz_cmu0[0];
+	base		= serdes + CMU0_SS_OFFSET;
+	k2serdes_config_ss(base, serdes_cfg, a_size);
+
+	/* cmu1 setup */
+	a_size		= ARRAY_SIZE(cfg_phyb_10p3125g_156p25mhz_cmu1);
+	serdes_cfg	= &cfg_phyb_10p3125g_156p25mhz_cmu1[0];
+	base		= serdes + CMU1_SS_OFFSET;
+	k2serdes_config_ss(base, serdes_cfg, a_size);
+
+	return 0;
+}
+
+/* lane is 0 based */
+static inline void k2serdes_lane_10p3125g_config(void __iomem *serdes,
+						int lane)
+{
+	struct serdes_cfg *serdes_cfg;
+	void __iomem *base;
+	int a_size;
+
+	/* lane setup */
+	a_size		= ARRAY_SIZE(cfg_phyb_10p3125g_16bit_lane);
+	serdes_cfg	= &cfg_phyb_10p3125g_16bit_lane[0];
+	base		= serdes + LANEX_SS_OFFSET(lane);
+	k2serdes_config_ss(base, serdes_cfg, a_size);
+
+	/* disable auto negotiation*/
+	FINSR(serdes, LANEX_REG(lane, 0x180), 4, 4, 0x0);
+
+	/* disable link training */
+	FINSR(serdes, LANEX_REG(lane, 0x1c0), 9, 9, 0x0);
+}
+
+static inline void k2serdes_lane_1p25g_config(void __iomem *serdes,
+						int lane)
+{
+	struct serdes_cfg *serdes_cfg;
+	void __iomem *base;
+	int a_size;
+
+	/* lane setup */
+	a_size		= ARRAY_SIZE(cfg_phyb_aneg_lane);
+	serdes_cfg	= &cfg_phyb_aneg_lane[0];
+	base		= serdes + LANEX_SS_OFFSET(lane);
+	k2serdes_config_ss(base, serdes_cfg, a_size);
+
+	/* disable auto negotiation*/
+	FINSR(serdes, LANEX_REG(lane, 0x180), 4, 4, 0x0);
+}
+
+static inline void k2serdes_lane_config(void __iomem *serdes,
+				int lane, struct hw_specific *hw)
+{
+	if (hw->ref_clock_rate != K2SERDES_REF_CLOCK_156P25M)
+		return;
+
+	if (hw->link_rate == K2SERDES_LINK_RATE_10P3125G)
+		k2serdes_lane_10p3125g_config(serdes, lane);
+	else if (hw->link_rate == K2SERDES_LINK_RATE_1P25G)
+		k2serdes_lane_1p25g_config(serdes, lane);
+}
+
+
+static inline void k2serdes_com_enable(void __iomem *serdes,
+					struct hw_specific *hw)
+{
+	struct serdes_cfg *serdes_cfg;
+	void __iomem *base;
+	int a_size;
+
+	if (hw->link_rate == K2SERDES_LINK_RATE_10P3125G) {
+		a_size		= ARRAY_SIZE(cfg_phyb_10p3125g_cml);
+		serdes_cfg	= &cfg_phyb_10p3125g_cml[0];
+	} else if (hw->link_rate == K2SERDES_LINK_RATE_1P25G) {
+		a_size		= ARRAY_SIZE(cfg_phyb_1p25g_156p25mhz_cml);
+		serdes_cfg	= &cfg_phyb_1p25g_156p25mhz_cml[0];
+	} else
+		return;
+
+	base = serdes + CML_SS_OFFSET;
+	k2serdes_config_ss(base, serdes_cfg, a_size);
+}
+
+
+static inline void k2serdes_eq_vreg_enable(void __iomem *serdes,
+					struct hw_specific *hw)
+{
+	u32 i;
+
+	for (i = 0; i < hw->lanes; i++) {
+		/* pma_ln_vreg */
+		FINSR(serdes, LANEX_REG(i, 0x18), 25, 24, 0x2);
+		/* pma_ln_vregh */
+		FINSR(serdes, LANEX_REG(i, 0x18), 27, 26, 0x2);
+	}
+}
+
+static inline void k2serdes_eq_cdfe_enable(void __iomem *serdes,
+					struct hw_specific *hw)
+{
+	u32 i;
+
+	if (hw->phy_type != K2SERDES_PHY_XGE)
+		return;
+
+	for (i = 0; i < hw->lanes; i++)
+		FINSR(serdes, LANEX_REG(i, 0x94), 24, 24, 0x1);
+
+	/* setting initial cdfe */
+	FINSR(serdes, CML_REG(0x108), 23, 16, 0xff);
+
+	/* turn on ei exit recal */
+	FINSR(serdes, CML_REG(0x10c), 7, 0, 0xff);
+
+	for (i = 0; i < hw->lanes; i++) {
+		/* enable ei exit cal for cdfe */
+		FINSR(serdes, LANEX_REG(i, 0x98), 2, 2, 0x0);
+		/* enable cdfe_ln_force_cal for cdfe */
+		FINSR(serdes, LANEX_REG(i, 0x98), 0, 0, 0x1);
+	}
+
+	/* setting rx tap */
+	FINSR(serdes, CML_REG(0xbc), 28, 24, 0x0);
+}
+
+static void k2serdes_tx_rx_set_equalizer(void __iomem *serdes,
+					struct hw_specific *hw)
+{
+	u32 i;
+
+	/* set tx output swing voltage */
+	if (hw->eq_vreg_enable)
+		k2serdes_eq_vreg_enable(serdes, hw);
+
+	/* enable cdfe */
+	if (hw->eq_cdfe_enable)
+		k2serdes_eq_cdfe_enable(serdes, hw);
+
+	/* set att and boost start */
+	for (i = 0; i < hw->lanes; i++) {
+		/* att start -1 for short channel */
+		FINSR(serdes, LANEX_REG(i, 0x8c), 11, 8, 0x4);
+		/* boost start -3 for short channel */
+		FINSR(serdes, LANEX_REG(i, 0x8c), 15, 12, 0xa);
+	}
+}
+
+static inline void k2serdes_lane_enable(void __iomem *serdes,
+				int lane, struct hw_specific *hw)
+{
+	/* Set Lane Control Rate */
+	if (hw->link_rate == K2SERDES_LINK_RATE_10P3125G) {
+		FINSR(serdes, LANE_CTRL_STS_REG(lane), 28, 26, 0x4);
+		FINSR(serdes, LANE_CTRL_STS_REG(lane), 12, 10, 0x4);
+	} else if (hw->link_rate == K2SERDES_LINK_RATE_1P25G)
+		k2serdes_writel(serdes, LANE_CTRL_STS_REG(lane), 0xf800f8c0);
+
+	/* set bus-width */
+	FINSR(serdes, LANE_CTRL_STS_REG(lane), 23, 21, 0x7);
+	FINSR(serdes, LANE_CTRL_STS_REG(lane),  5,  3, 0x7);
+
+	/* enable PCS overlay and lane select 10GKR */
+	FINSR(serdes, LANE_CTRL_STS_REG(lane), 16, 16, 0x1);
+	FINSR(serdes, LANE_CTRL_STS_REG(lane), 19, 19, 0x1);
+
+	/* enable lanes */
+	FINSR(serdes, LANE_CTRL_STS_REG(lane), 31, 29, 0x7);
+	FINSR(serdes, LANE_CTRL_STS_REG(lane), 15, 13, 0x7);
+}
+
+static inline int k2serdes_get_lane_status(void __iomem *serdes,
+				struct hw_specific *hw, int lane)
+{
+	u32 val;
+
+	if (hw->phy_type != K2SERDES_PHY_XGE)
+		return 0;
+
+	val = k2serdes_readl(serdes, CML_REG(0x1f8));
+	return (val >> (29 + lane)) & 0x1;
+}
+
+static int k2serdes_get_status(void __iomem *serdes,
+			      struct hw_specific *hw)
+{
+	u32 lanes_ok = 1;
+	int i;
+
+	for (i = 0; i < hw->lanes; i++) {
+		lanes_ok &= k2serdes_get_lane_status(serdes, hw, i);
+		cpu_relax();
+	}
+
+	return lanes_ok;
+}
+
+static int k2serdes_wait_pll_locked(void __iomem *serdes,
+				      struct hw_specific *hw)
+{
+	unsigned long timeout;
+	int ret = 0;
+	u32 status;
+
+	timeout = jiffies + msecs_to_jiffies(500);
+	do {
+		status = k2serdes_get_status(serdes, hw);
+
+		if (status)
+			return 0;
+
+		if (time_after(jiffies, timeout)) {
+			ret = -ETIMEDOUT;
+			break;
+		}
+		cpu_relax();
+	} while (true);
+
+	pr_info("XGE serdes not locked: time out.\n");
+	return ret;
+}
+
+static void k2serdes_assert_reset(void __iomem *serdes, struct hw_specific *hw)
+{
+	u32 i;
+
+	for (i = 0; i < MAX_LANES; i++)
+		FINSR(serdes, LANEX_REG(i, 0x028), 29, 15, 0x4260);
+}
+
+static inline void k2serdes_deassert_reset_poll_xge(void __iomem *serdes,
+						struct hw_specific *hw)
+{
+	u32 lanes_ok = MASK((hw->lanes - 1), 0);
+	u32 val;
+
+	do {
+		val = k2serdes_readl(serdes, CML_REG(0x1f8));
+		cpu_relax();
+	} while (((val >> 29) & lanes_ok) != lanes_ok);
+}
+
+static inline void k2serdes_deassert_reset_poll_pcie(void __iomem *serdes,
+						struct hw_specific *hw)
+{
+	u32 tmp, i;
+
+	for (i = 0; i < 4; i++)
+		do {
+			tmp = k2serdes_read_select_tbus(serdes, i + 1, 0x02);
+		} while ((tmp & BIT(4)) != 0);
+}
+
+static inline void k2serdes_deassert_reset_poll_others(void __iomem *serdes,
+						struct hw_specific *hw)
+{
+	u32 lanes_ok = MASK((hw->lanes - 1), 0);
+	u32 val;
+
+	/* 4 lane PHY-A */
+	do {
+		val = k2serdes_readl(serdes, CML_REG(0x1f8));
+		cpu_relax();
+	} while (((val >> 28) & lanes_ok) != lanes_ok);
+}
+
+static int k2serdes_deassert_reset(void __iomem *serdes,
+			struct hw_specific *hw, int poll)
+{
+	u32 i;
+
+	for (i = 0; i < hw->lanes; i++) {
+		if (hw->phy_type == K2SERDES_PHY_XGE)
+			/* set pma_cmu_sel to 1 */
+			FINSR(serdes, LANEX_REG(i, 0x60), 0, 0, 0x1);
+		/* release reset */
+		FINSR(serdes, LANEX_REG(i, 0x28), 29, 29, 0x0);
+	}
+
+	if (!poll)
+		goto out;
+
+	if (hw->phy_type == K2SERDES_PHY_XGE)
+		k2serdes_deassert_reset_poll_xge(serdes, hw);
+	else if (hw->phy_type == K2SERDES_PHY_PCIE)
+		k2serdes_deassert_reset_poll_pcie(serdes, hw);
+	else
+		k2serdes_deassert_reset_poll_others(serdes, hw);
+
+out:
+	return 0;
+}
+
+/* lane is 0-based */
+static void k2serdes_get_cmp_tap_offsets_xge(void __iomem *serdes,
+	u32 lane, u32 cmp, struct k2serdes_comparator_tap_offsets *ofs)
+{
+	/* set comparator number */
+	FINSR(serdes, CML_REG(0x8c), 23, 21, cmp);
+
+	/* read offsets */
+	FINSR(serdes, CMU0_REG(0xfc), 26, 16, ((lane + 2) << 8) + 0x11);
+	ofs->cmp = (k2serdes_read_tbus_val(serdes) & 0x0ff0) >> 4;
+
+	FINSR(serdes, CMU0_REG(0xfc), 26, 16, ((lane + 2) << 8) + 0x11);
+	ofs->tap1 = (k2serdes_read_tbus_val(serdes) & 0x000f) << 3;
+
+	FINSR(serdes, CMU0_REG(0xfc), 26, 16, ((lane + 2) << 8) + 0x12);
+	ofs->tap1 |= (k2serdes_read_tbus_val(serdes) & 0x0e00) >> 9;
+	ofs->tap2  = (k2serdes_read_tbus_val(serdes) & 0x01f8) >> 3;
+	ofs->tap3  = (k2serdes_read_tbus_val(serdes) & 0x0007) << 3;
+
+	FINSR(serdes, CMU0_REG(0xfc), 26, 16, ((lane + 2) << 8) + 0x13);
+	ofs->tap3 |= (k2serdes_read_tbus_val(serdes) & 0x0e00) >> 9;
+	ofs->tap4  = (k2serdes_read_tbus_val(serdes) & 0x01f8) >> 3;
+	ofs->tap5  = (k2serdes_read_tbus_val(serdes) & 0x0007) << 3;
+
+	FINSR(serdes, CMU0_REG(0xfc), 26, 16, ((lane + 2) << 8) + 0x14);
+	ofs->tap5 |= (k2serdes_read_tbus_val(serdes) & 0x0e00) >> 9;
+}
+
+static void k2serdes_add_offsets_xge(void __iomem *serdes,
+	struct hw_specific *hw, struct k2serdes_offsets *sofs)
+{
+	struct k2serdes_comparator_tap_offsets *ctofs;
+	struct k2serdes_comparator_tap_offsets sample;
+	struct k2serdes_lane_offsets *lofs;
+	u32 lane, cmp;
+
+	for (lane = 0; lane < hw->lanes; lane++) {
+		lofs = &(sofs->lane_ofs[lane]);
+		/* yes cmp starts from 1 */
+		for (cmp = 1; cmp < MAX_COMPARATORS; cmp++) {
+			ctofs = &(lofs->ct_ofs[cmp]);
+
+			k2serdes_get_cmp_tap_offsets_xge(serdes,
+						lane, cmp, &sample);
+
+			ctofs->cmp  += sample.cmp;
+			ctofs->tap1 += sample.tap1;
+			ctofs->tap2 += sample.tap2;
+			ctofs->tap3 += sample.tap3;
+			ctofs->tap4 += sample.tap4;
+			ctofs->tap5 += sample.tap5;
+		}
+	}
+}
+
+/* lane is 0-based */
+static void k2serdes_get_cmp_tap_offsets_non_xge(void __iomem *serdes,
+	u32 lane, u32 cmp, struct k2serdes_comparator_tap_offsets *ofs)
+{
+	/* set comparator number */
+	FINSR(serdes, CML_REG(0x8c), 23, 21, cmp);
+
+	/* read offsets */
+	FINSR(serdes, CMU0_REG(0x8), 31, 24, ((lane + 1) << 5) + 0x12);
+	ofs->cmp = (k2serdes_read_tbus_val(serdes) & 0x0ff0) >> 4;
+}
+
+static void k2serdes_add_offsets_non_xge(void __iomem *serdes,
+	struct hw_specific *hw, struct k2serdes_offsets *sofs)
+{
+	struct k2serdes_comparator_tap_offsets *ctofs;
+	struct k2serdes_comparator_tap_offsets sample;
+	struct k2serdes_lane_offsets *lofs;
+	u32 lane, cmp;
+
+	for (lane = 0; lane < hw->lanes; lane++) {
+		lofs = &(sofs->lane_ofs[lane]);
+		/* yes cmp starts from 1 */
+		for (cmp = 1; cmp < MAX_COMPARATORS; cmp++) {
+			ctofs = &(lofs->ct_ofs[cmp]);
+
+			k2serdes_get_cmp_tap_offsets_non_xge(serdes,
+					lane, cmp, &sample);
+
+			ctofs->cmp  += sample.cmp;
+		}
+	}
+}
+
+static void k2serdes_get_average_offsets(void __iomem *serdes, u32 samples,
+		struct hw_specific *hw, struct k2serdes_offsets *sofs)
+{
+	struct k2serdes_comparator_tap_offsets *ctofs;
+	struct k2serdes_lane_offsets *lofs;
+	u32 i, lane, cmp;
+
+	memset(sofs, 0, sizeof(*sofs));
+
+	/* get the total of each offset for specified number of samples */
+	for (i = 0; i < samples; i++) {
+		k2serdes_assert_reset(serdes, hw);
+		k2serdes_deassert_reset(serdes, hw, 1);
+
+		if (hw->phy_type == K2SERDES_PHY_XGE)
+			k2serdes_add_offsets_xge(serdes, hw, sofs);
+		else
+			k2serdes_add_offsets_non_xge(serdes, hw, sofs);
+	}
+
+	/* take the average */
+	for (lane = 0; lane < hw->lanes; lane++) {
+		lofs = &(sofs->lane_ofs[lane]);
+		/* yes cmp starts from 1 */
+		for (cmp = 1; cmp < MAX_COMPARATORS; cmp++) {
+			ctofs = &(lofs->ct_ofs[cmp]);
+			if (hw->phy_type == K2SERDES_PHY_XGE) {
+				ctofs->cmp  /= samples;
+				ctofs->tap1 /= samples;
+				ctofs->tap2 /= samples;
+				ctofs->tap3 /= samples;
+				ctofs->tap4 /= samples;
+				ctofs->tap5 /= samples;
+			} else
+				ctofs->cmp  /= samples;
+		}
+	}
+}
+
+static void k2serdes_override_cmp_tap_offsets(void __iomem *serdes,
+	u32 lane, u32 cmp, struct k2serdes_comparator_tap_offsets *ofs)
+{
+	/* set dfe_shadow_lane_sel */
+	FINSR(serdes, CML_REG(0xf0), 27, 26, (lane + 1));
+
+	/* set cmp_offset_ovr_en to 1 */
+	FINSR(serdes, CML_REG(0x98), 24, 24, 0x1);
+
+	/* set rxeq_ovr_en to 0x1 */
+	FINSR(serdes, LANEX_REG(lane, 0x2c), 2, 2, 0x1);
+
+	/* set rxeq_dfe_cmp_sel_ovr to comp_no */
+	FINSR(serdes, LANEX_REG(lane, 0x30), 7, 5, cmp);
+
+	/* set dfe_tap_ovr_en to 1 */
+	FINSR(serdes, LANEX_REG(lane, 0x5c), 31, 31, 0x1);
+
+	/* set cmp offset override */
+	FINSR(serdes, CML_REG(0x9c), 7, 0, ofs->cmp);
+	/* set tap offset overrides */
+	FINSR(serdes, LANEX_REG(lane, 0x58), 30, 24, ofs->tap1);
+	FINSR(serdes, LANEX_REG(lane, 0x5c),  5,  0, ofs->tap2);
+	FINSR(serdes, LANEX_REG(lane, 0x5c), 13,  8, ofs->tap3);
+	FINSR(serdes, LANEX_REG(lane, 0x5c), 21, 16, ofs->tap4);
+	FINSR(serdes, LANEX_REG(lane, 0x5c), 29, 24, ofs->tap5);
+
+	/* set rxeq_ovr_latch_o = 0x1 */
+	FINSR(serdes, LANEX_REG(lane, 0x2c), 10, 10, 0x1);
+	/* set rxeq_ovr_latch_o = 0x0 */
+	FINSR(serdes, LANEX_REG(lane, 0x2c), 10, 10, 0x0);
+
+	/* set cmp_offset_ovr_en to 0 */
+	FINSR(serdes, CML_REG(0x98), 24, 24, 0x0);
+	/* set rxeq_ovr_en to 0x0 */
+	FINSR(serdes, LANEX_REG(lane, 0x2c), 2, 2, 0x0);
+	/* set dfe_tap_ovr_en to 0 */
+	FINSR(serdes, LANEX_REG(lane, 0x5c), 31, 31, 0x0);
+}
+
+static inline void k2serdes_override_cmp_offset_cdfe(void __iomem *serdes,
+					u32 lane, u32 cmp, u32 cmp_offset)
+{
+	/* enable comparator offset calibrate */
+	FINSR(serdes, LANEX_REG(lane, 0x58), 18, 18, 0x1);
+
+	/* set gcfsm sel override to comparator */
+	FINSR(serdes, LANEX_REG(lane, 0x4c), 5, 2, (0x1 << (cmp - 1)));
+	/* set comparator offset */
+	FINSR(serdes, LANEX_REG(lane, 0x48), 24, 17, cmp_offset);
+	/* latch in value */
+	FINSR(serdes, LANEX_REG(lane, 0x48), 29, 29, 0x1);
+	FINSR(serdes, LANEX_REG(lane, 0x48), 29, 29, 0x0);
+
+	/* disable comparator offset calibrate */
+	FINSR(serdes, LANEX_REG(lane, 0x58), 18, 18, 0x0);
+}
+
+static inline void k2serdes_override_tap_offset_cdfe(void __iomem *serdes,
+	u32 lane, u32 tap, u32 width, u32 tap_offset)
+{
+	/* enable tap */
+	FINSR(serdes, LANEX_REG(lane, 0x58), 23, 19, BIT(tap - 1));
+	/* set tap offset */
+	FINSR(serdes, LANEX_REG(lane, 0x48), 17 + (width - 1), 17, tap_offset);
+	/* latch in value */
+	FINSR(serdes, LANEX_REG(lane, 0x48), 29, 29, 0x1);
+	FINSR(serdes, LANEX_REG(lane, 0x48), 29, 29, 0x0);
+}
+
+static void k2serdes_override_cmp_tap_offsets_cdfe(void __iomem *serdes,
+	u32 lane, u32 cmp, struct k2serdes_comparator_tap_offsets *ofs)
+{
+	/* enable overrides */
+	FINSR(serdes, LANEX_REG(lane, 0x58), 16, 16, 0x1);
+	FINSR(serdes, LANEX_REG(lane, 0x48), 16, 16, 0x1);
+
+	k2serdes_override_cmp_offset_cdfe(serdes, lane, cmp, ofs->cmp);
+
+	/* enable tap offset calibrate */
+	FINSR(serdes, LANEX_REG(lane, 0x58), 17, 17, 0x1);
+
+	/* set tap offsets */
+	k2serdes_override_tap_offset_cdfe(serdes, lane, 1, 7, ofs->tap1);
+	k2serdes_override_tap_offset_cdfe(serdes, lane, 2, 6, ofs->tap2);
+	k2serdes_override_tap_offset_cdfe(serdes, lane, 3, 6, ofs->tap3);
+	k2serdes_override_tap_offset_cdfe(serdes, lane, 4, 6, ofs->tap4);
+	k2serdes_override_tap_offset_cdfe(serdes, lane, 5, 6, ofs->tap5);
+
+	/* disable overrides */
+	FINSR(serdes, LANEX_REG(lane, 0x58), 16, 16, 0x0);
+	FINSR(serdes, LANEX_REG(lane, 0x48), 16, 16, 0x0);
+	FINSR(serdes, LANEX_REG(lane, 0x58), 18, 18, 0x0);
+	FINSR(serdes, LANEX_REG(lane, 0x58), 17, 17, 0x0);
+}
+
+static void k2serdes_set_offsets_xge(void __iomem *serdes,
+	struct hw_specific *hw, struct k2serdes_offsets *sofs)
+{
+	struct k2serdes_comparator_tap_offsets *ctofs;
+	struct k2serdes_lane_offsets *lofs;
+	u32 lane, cmp;
+
+	for (lane = 0; lane < hw->lanes; lane++) {
+		lofs = &(sofs->lane_ofs[lane]);
+		for (cmp = 1; cmp < MAX_COMPARATORS; cmp++) {
+			ctofs = &(lofs->ct_ofs[cmp]);
+			k2serdes_override_cmp_tap_offsets(serdes,
+						lane, cmp, ctofs);
+			k2serdes_override_cmp_tap_offsets_cdfe(serdes,
+						lane, cmp, ctofs);
+		}
+	}
+}
+
+static void k2serdes_set_offsets_non_xge(void __iomem *serdes,
+	struct hw_specific *hw, struct k2serdes_offsets *sofs)
+{
+	struct k2serdes_comparator_tap_offsets *ctofs;
+	struct k2serdes_lane_offsets *lofs;
+	u32 lane, cmp;
+
+	for (lane = 0; lane < hw->lanes; lane++) {
+		lofs = &(sofs->lane_ofs[lane]);
+		for (cmp = 1; cmp < MAX_COMPARATORS; cmp++) {
+			ctofs = &(lofs->ct_ofs[cmp]);
+			k2serdes_override_cmp_tap_offsets(serdes,
+						lane, cmp, ctofs);
+		}
+	}
+}
+
+static void k2serdes_set_offsets(void __iomem *serdes,
+	struct hw_specific *hw, struct k2serdes_offsets *sofs)
+{
+	if (hw->phy_type == K2SERDES_PHY_XGE)
+		k2serdes_set_offsets_xge(serdes, hw, sofs);
+	else
+		k2serdes_set_offsets_non_xge(serdes, hw, sofs);
+}
+
+static inline void k2serdes_config_c1_c2_cm(void __iomem *serdes,
+				int lane, struct hw_specific *hw)
+{
+	u32 c1, c2, cm;
+
+	c1 = hw->c1;
+	c2 = hw->c2;
+	cm = hw->cm;
+
+	if (hw->phy_type == K2SERDES_PHY_XGE) {
+		/* TX Control override enable */
+		FINSR(serdes, LANEX_REG(lane, 0x8), 4, 0, (c1 & 0x1f));
+
+		/* TX Control override enable */
+		FINSR(serdes, LANEX_REG(lane, 0x4), 18, 18, ((c2 >> 3) & 0x1));
+
+		/* TX Control override enable */
+		FINSR(serdes, LANEX_REG(lane, 0x8), 7, 5, (c2 & 0x7));
+
+		/* TX Control override enable */
+		FINSR(serdes, LANEX_REG(lane, 0x8), 11, 8, (cm & 0xf));
+	} else {
+		FINSR(serdes, LANEX_REG(lane, 0x8), 4, 0, (c1 & 0x1f));
+		FINSR(serdes, LANEX_REG(lane, 0x8), 11, 8, (c2 & 0xf));
+		FINSR(serdes, LANEX_REG(lane, 0x8), 15, 12, (cm & 0xf));
+	}
+}
+
+static void k2serdes_dfe_offset_calibrate(void __iomem *serdes,
+					struct hw_specific *hw)
+{
+	struct k2serdes_offsets sofs;
+	u32 i;
+
+	/* force serdes signal detect low (reset CDR, Att and Boost) */
+	for (i = 0; i < hw->lanes; i++)
+		FINSR(serdes, LANEX_REG(i, 0x004), 2, 1, 0x2);
+
+	udelay(10);
+
+	k2serdes_get_average_offsets(serdes, DFE_OFFSET_SAMPLES, hw, &sofs);
+
+	/* assert reset to apply tx FIR coeff */
+	k2serdes_assert_reset(serdes, hw);
+
+	/* set tx swing */
+	for (i = 0; i < hw->lanes; i++)
+		if (hw->phy_type == K2SERDES_PHY_XGE)
+			FINSR(serdes, LANEX_REG(i, 0x4),
+				29, 26, (hw->tx_att & 0xf));
+		else
+			FINSR(serdes, LANEX_REG(i, 0x4),
+				28, 25, (hw->tx_att & 0xf));
+
+	/* set regulator setting for tx driver */
+	for (i = 0; i < hw->lanes; i++)
+		FINSR(serdes, LANEX_REG(i, 0x84), 7, 5, (hw->tx_vreg & 0x7));
+
+	/* apply the tx FIR coeff to the lanes */
+	for (i = 0; i < hw->lanes; i++)
+		k2serdes_config_c1_c2_cm(serdes, i, hw);
+
+	k2serdes_deassert_reset(serdes, hw, 1);
+
+	/* offset compensation patch */
+	k2serdes_set_offsets(serdes, hw, &sofs);
+
+	udelay(10);
+
+	/* re-acquire signal detect */
+	for (i = 0; i < hw->lanes; i++)
+		FINSR(serdes, LANEX_REG(i, 0x4), 2, 1, 0x0);
+
+	udelay(10);
+}
+
+static inline void k2serdes_enable_xgmii_port(void __iomem *sw_regs)
+{
+	k2serdes_writel(sw_regs, XGE_CTRL_OFFSET, 0x03);
+}
+
+void k2serdes_reset_cdr(void __iomem *serdes, int lane)
+{
+	/* toggle signal detect */
+	FINSR(serdes, LANEX_REG(lane, 0x04), 2, 1, 0x2);
+	mdelay(1);
+	FINSR(serdes, LANEX_REG(lane, 0x04), 2, 1, 0x0);
+}
+
+/* Call every 10 ms */
+int k2serdes_check_link_status(void __iomem *serdes,
+			      void __iomem *sw_regs,
+			      u32 lanes,
+			      u32 *current_state,
+			      u32 *lane_down)
+{
+	u32 pcsr_rx_stat, blk_lock, blk_errs;
+	int loss, i, status = 1;
+
+	for (i = 0; i < lanes; i++) {
+		/* Rx Signal Loss bit in serdes lane control and status reg*/
+		loss = (k2serdes_readl(serdes, LANE_CTRL_STS_REG(i))) & 0x01;
+
+		/* Block Errors and Block Lock bits in PCSR rx status reg */
+		pcsr_rx_stat = k2serdes_readl(sw_regs, PCSR_RX_STATUS(i));
+		blk_lock = (pcsr_rx_stat >> 30) & 0x1;
+		blk_errs = (pcsr_rx_stat >> 16) & 0x0ff;
+/*pr_info("++++++ lane %d pcsr_rx_stat=0x%08x\n", i, pcsr_rx_stat);*/
+
+		/* If Block error, attempt recovery! */
+		if (blk_errs)
+			blk_lock = 0;
+
+		switch (current_state[i]) {
+		case 0:
+			/* if good link lock the signal detect ON! */
+			if (!loss && blk_lock) {
+				pr_debug("XGE PCSR Linked Lane: %d\n", i);
+				FINSR(serdes, LANEX_REG(i, 0x04), 2, 1, 0x3);
+				current_state[i] = 1;
+			} else {
+				/* if no lock, then reset CDR */
+				if (!blk_lock) {
+					pr_debug("XGE PCSR Recover Lane: %d\n",
+						i);
+
+					k2serdes_reset_cdr(serdes, i);
+				}
+			}
+			break;
+		case 1:
+			if (!blk_lock) {
+				/* Link Lost? */
+				lane_down[i] = 1;
+				current_state[i] = 2;
+			}
+			break;
+		case 2:
+			if (blk_lock)
+				/* Nope just noise */
+				current_state[i] = 1;
+			else {
+				/* Lost the block lock, reset CDR if it is
+				   not centered and go back to sync state
+				 */
+				k2serdes_reset_cdr(serdes, i);
+
+				current_state[i] = 0;
+			}
+			break;
+		default:
+			pr_info("XGE: unknown current_state[%d] %d\n",
+				i, current_state[i]);
+			break;
+		}
+
+		if (blk_errs) {
+			/* Reset the Error counts! */
+			FINSR(sw_regs, PCSR_RX_CTL(i), 7, 0, 0x19);
+			FINSR(sw_regs, PCSR_RX_CTL(i), 7, 0, 0x00);
+		}
+
+		status &= (current_state[i] == 1);
+	}
+
+	return status;
+}
+
+static int k2serdes_check_lane(void __iomem *serdes,
+		  void __iomem *sw_regs, u32 lanes)
+{
+	u32 current_state[2] = {0, 0};
+	int retries = 0, link_up;
+	u32 lane_down[2];
+
+	do {
+		mdelay(10);
+		lane_down[0] = 0;
+		lane_down[1] = 0;
+
+		link_up = k2serdes_check_link_status(serdes, sw_regs,
+					   lanes, current_state, lane_down);
+
+		/* if we did not get link up then wait 100ms
+		   before calling it again
+		 */
+		if (link_up)
+			break;
+
+		if (lane_down[0])
+			pr_debug("XGE: detected link down on lane 0\n");
+
+		if (lanes > 1 && lane_down[1])
+			pr_debug("XGE: detected link down on lane 1\n");
+
+		if (++retries > 100) {
+			pr_err("XGE: timeout waiting for serdes link up\n");
+			return -ETIMEDOUT;
+		}
+	} while (!link_up);
+
+	pr_info("XGE: serdes link up: retried %d times\n", retries);
+	return 0;
+}
+
+static inline void k2serdes_reset(void __iomem *serdes)
+{
+	/* Toggle POR_EN bit */
+	FINSR(serdes, CPU_CTRL_REG, 29, 29, 0x1);
+	udelay(10);
+	FINSR(serdes, CPU_CTRL_REG, 29, 29, 0x0);
+	udelay(10);
+}
+
+static inline void k2serdes_txb_clk_mode(void __iomem *serdes,
+					      struct hw_specific *hw)
+{
+	if (hw->link_rate != K2SERDES_LINK_RATE_1P25G)
+		return;
+
+	k2serdes_writel(serdes, CPU_CTRL_REG, 0x20000000);
+	k2serdes_writel(serdes, PLL_CTRL_REG, 0x00380000);
+	k2serdes_writel(serdes, CPU_CTRL_REG, 0x00000000);
+}
+
+static int k2serdes_config(void __iomem *serdes,
+			      void __iomem *sw_regs,
+			      struct hw_specific *hw)
+{
+	u32 ret, i, lanes = hw->lanes;
+
+	k2serdes_txb_clk_mode(serdes, hw);
+
+	ret = k2serdes_init(serdes, hw);
+	if (ret)
+		return ret;
+
+	for (i = 0; i < lanes; i++)
+		k2serdes_lane_config(serdes, i, hw);
+
+	k2serdes_com_enable(serdes, hw);
+
+	k2serdes_tx_rx_set_equalizer(serdes, hw);
+
+	k2serdes_pll_enable(serdes, hw);
+
+	for (i = 0; i < lanes; i++)
+		k2serdes_lane_enable(serdes, i, hw);
+
+	/* SB PLL Status Poll */
+	ret = k2serdes_wait_pll_locked(serdes, hw);
+	if (ret)
+		return ret;
+
+	k2serdes_dfe_offset_calibrate(serdes, hw);
+
+	k2serdes_enable_xgmii_port(sw_regs);
+
+	k2serdes_check_lane(serdes, sw_regs, lanes);
+
+	return ret;
+}
+
+static int k2serdes_start(struct hw_specific *hw)
+{
+	void __iomem *serdes, *xge_sw_regs;
+	int ret;
+
+	serdes = ioremap(XGE_SERDES_BASE, XGE_SERDES_SIZE);
+	xge_sw_regs = ioremap(XGE_SW_BASE, XGE_SW_SIZE);
+
+	pr_info("XGE: serdes reset\n");
+	k2serdes_reset(serdes);
+
+	ret = k2serdes_config(serdes, xge_sw_regs, hw);
+
+	iounmap(serdes);
+	iounmap(xge_sw_regs);
+	return ret;
+}
+
+static int k2_xge_serdes_configured;  /* FIXME */
+
+int xge_serdes_init(struct device_node *node)
+{
+	int ret;
+	struct hw_specific *hw = NULL;
+
+	hw = kzalloc(sizeof(*hw), GFP_KERNEL);
+
+	if (!hw) {
+		pr_err("xge serdes mem alloc failed\n");
+		return -ENOMEM;
+	}
+
+	if (of_property_read_u32(node, "ref_clock",
+					&hw->ref_clock_rate))
+		hw->ref_clock_rate = K2SERDES_REF_CLOCK_156P25M;
+
+	if (of_property_read_u32(node, "link_rate",
+					&hw->link_rate))
+		hw->link_rate = K2SERDES_LINK_RATE_10P3125G;
+
+	if (of_property_read_u32_array(node, "tx_ctrl_override",
+					&hw->c1, 5)) {
+		hw->c1		= 2;
+		hw->c2		= 0;
+		hw->cm		= 2;
+		hw->tx_att	= 12;
+		hw->tx_vreg	= 4;
+	}
+
+	if (of_property_read_u32_array(node, "equalizer_flags",
+					&hw->eq_vreg_enable, 3)) {
+		hw->eq_vreg_enable	= 1;
+		hw->eq_cdfe_enable	= 1;
+		hw->eq_offset_enable	= 1;
+	}
+
+	hw->lanes = 2;
+	hw->phy_type = K2SERDES_PHY_XGE;
+
+	if (hw->ref_clock_rate != K2SERDES_REF_CLOCK_156P25M) {
+		pr_err("XGE serdes invalid ref_clock code %d",
+			hw->ref_clock_rate);
+		return -EINVAL;
+	}
+
+	if (hw->link_rate != K2SERDES_LINK_RATE_10P3125G) {
+		pr_err("XGE serdes invalid link_rate code %d", hw->link_rate);
+		return -EINVAL;
+	}
+
+	if (!k2_xge_serdes_configured) {
+		pr_info("XGE serdes config:\n");
+		pr_info("  ref_clk=%s, link_rate=%s, lanes=%u\n",
+			(hw->ref_clock_rate == K2SERDES_REF_CLOCK_156P25M) ?
+				"156.25MHz" : "not 156.25MHz",
+			(hw->link_rate == K2SERDES_LINK_RATE_10P3125G) ?
+				"10.3125G" : "1.25G",
+			hw->lanes);
+		pr_info("  c1=%u, c2=%u, cm=%u, tx_att=%u, tx_vreg=%u\n",
+			hw->c1, hw->c2, hw->cm, hw->tx_att, hw->tx_vreg);
+		pr_info("  eq flags: vreg=%u, cdfe=%u, offset=%u\n",
+			hw->eq_vreg_enable, hw->eq_cdfe_enable,
+			hw->eq_offset_enable);
+	}
+
+	ret = k2serdes_start(hw);
+	if (!ret)
+		++k2_xge_serdes_configured;
+
+	kfree(hw);
+	return ret;
+}
+
+int keystone_pcsr_config(void __iomem *pcsr_ofs, int port, u32 interface)
+{
+	return 0;
+}
diff --git a/drivers/net/ethernet/ti/keystone_xgess.c b/drivers/net/ethernet/ti/keystone_xgess.c
new file mode 100644
index 0000000..a09de90
--- /dev/null
+++ b/drivers/net/ethernet/ti/keystone_xgess.c
@@ -0,0 +1,2553 @@
+/*
+ * Copyright (C) 2012 Texas Instruments Incorporated
+ * Authors: Sandeep Paulraj <s-paulraj@ti.com>
+ * Authors: WingMan Kwok <w-kwok2@ti.com>
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation version 2.
+ *
+ * This program is distributed "as is" WITHOUT ANY WARRANTY of any
+ * kind, whether express or implied; without even the implied warranty
+ * of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+#include <linux/io.h>
+#include <linux/of.h>
+#include <linux/clk.h>
+#include <linux/phy.h>
+#include <linux/timer.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/uaccess.h>
+#include <linux/if_vlan.h>
+#include <linux/of_mdio.h>
+#include <linux/ethtool.h>
+#include <linux/if_ether.h>
+#include <linux/net_tstamp.h>
+#include <linux/netdevice.h>
+#include <linux/interrupt.h>
+#include <linux/dmaengine.h>
+#include <linux/dma-mapping.h>
+#include <linux/scatterlist.h>
+#include <linux/etherdevice.h>
+#include <linux/platform_device.h>
+
+#include "cpsw_ale.h"
+#include "keystone_net.h"
+
+#define CPSW_MODULE_NAME	"keystone-cpswx"
+#define NETCP_DRIVER_NAME	"TI KeyStone XGE Driver"
+#define NETCP_DRIVER_VERSION	"v0.0.0"
+
+#define CPSW_IDENT(reg)			((reg >> 16) & 0xffff)
+#define CPSW_MAJOR_VERSION(reg)		(reg >> 8 & 0x7)
+#define CPSW_MINOR_VERSION(reg)		(reg & 0xff)
+#define CPSW_RTL_VERSION(reg)		((reg >> 11) & 0x1f)
+
+#define DEVICE_N_GMACSL_PORTS			2
+#define DEVICE_EMACSL_RESET_POLL_COUNT		100
+
+#define	CPSW_TIMER_INTERVAL			(HZ / 10)
+
+/* Soft reset register values */
+#define SOFT_RESET_MASK				BIT(0)
+#define SOFT_RESET				BIT(0)
+
+#define MACSL_RX_ENABLE_CSF			BIT(23)
+#define MACSL_RX_ENABLE_EXT_CTL			BIT(18)
+#define MACSL_XGMII_ENABLE			BIT(13)
+#define MACSL_XGIG_MODE				BIT(8)
+#define MACSL_GMII_ENABLE			BIT(5)
+#define GMACSL_RET_WARN_RESET_INCOMPLETE	-2
+
+#define SLAVE_LINK_IS_XGMII(s) \
+	((s)->link_interface >= XGMII_LINK_MAC_PHY)
+
+#define MACSL_SIG_ENABLE(s) \
+		(SLAVE_LINK_IS_XGMII((s)) ?   \
+		(MACSL_XGMII_ENABLE | MACSL_XGIG_MODE) : \
+		MACSL_GMII_ENABLE)
+
+#define CPSW_NUM_PORTS		                3
+#define CPSW_CTL_P0_ENABLE			BIT(2)
+#define CPSW_CTL_VLAN_AWARE			BIT(1)
+#define CPSW_REG_VAL_STAT_ENABLE_ALL		0xf
+
+#define CPSW_MASK_ALL_PORTS			7
+#define CPSW_MASK_PHYS_PORTS			6
+#define CPSW_MASK_NO_PORTS			0
+
+#define CPSW_STATS0_MODULE			0
+#define CPSW_STATS1_MODULE			1
+#define CPSW_STATS2_MODULE			2
+
+#define HOST_TX_PRI_MAP_DEFAULT			0x00000000
+#define MAX_SIZE_STREAM_BUFFER		        9504
+
+struct cpswx_slave {
+	struct cpswx_slave_regs __iomem		*regs;
+	struct cpswx_sliver_regs __iomem	*sliver;
+	int				 slave_num;
+	int				 port_num;
+	u32				 mac_control;
+	struct phy_device		*phy;
+	const char			*phy_id;
+	struct cpsw_ale			*ale;
+	u32				 link_interface;
+	u8				 phy_port_t;
+};
+
+/* 0x0000 */
+struct cpswx_ss_regs {
+	u32	id_ver;
+	u32	synce_count;
+	u32	synce_mux;
+	u32	control;
+};
+
+/* 0x1000 */
+struct cpswx_regs {
+	u32	id_ver;
+	u32	control;
+	u32	emcontrol;
+	u32	stat_port_en;
+	u32	ptype;
+	u32	soft_idle;
+	u32	thru_rate;
+	u32	gap_thresh;
+	u32	tx_start_wds;
+	u32	flow_control;
+	u32	cppi_thresh;
+};
+
+/* 0x1064, 0x1094 */
+struct cpswx_slave_regs {
+	u32	blk_cnt;
+	u32	port_vlan;
+	u32	tx_pri_map;
+	u32	sa_lo;
+	u32	sa_hi;
+	u32	ts_ctl;
+	u32	ts_seq_ltype;
+	u32	ts_vlan;
+	u32	ts_ctl_ltype2;
+	u32	ts_ctl2;
+	u32	control;
+};
+
+/* 0x1034 */
+struct cpswx_host_regs {
+	u32	blk_cnt;
+	u32	port_vlan;
+	u32	tx_pri_map;
+	u32	src_id;
+	u32	rx_pri_map;
+	u32	rx_maxlen;
+};
+
+/* 0x1400, 0x1440 */
+struct cpswx_sliver_regs {
+	u32	id_ver;
+	u32	mac_control;
+	u32	mac_status;
+	u32	soft_reset;
+	u32	rx_maxlen;
+	u32	__reserved_0;
+	u32	rx_pause;
+	u32	tx_pause;
+	u32	em_control;
+	u32	__reserved_1;
+	u32	tx_gap;
+	u32	rsvd[4];
+};
+
+struct cpswx_host_hw_stats {
+	u32	rx_good_frames;
+	u32	rx_broadcast_frames;
+	u32	rx_multicast_frames;
+	u32	__rsvd_0[3];
+	u32	rx_oversized_frames;
+	u32	__rsvd_1;
+	u32	rx_undersized_frames;
+	u32	__rsvd_2;
+	u32	overrun_type4;
+	u32	overrun_type5;
+	u32	rx_bytes;
+	u32	tx_good_frames;
+	u32	tx_broadcast_frames;
+	u32	tx_multicast_frames;
+	u32	__rsvd_3[9];
+	u32	tx_bytes;
+	u32	tx_64byte_frames;
+	u32	tx_65_to_127byte_frames;
+	u32	tx_128_to_255byte_frames;
+	u32	tx_256_to_511byte_frames;
+	u32	tx_512_to_1023byte_frames;
+	u32	tx_1024byte_frames;
+	u32	net_bytes;
+	u32	rx_sof_overruns;
+	u32	rx_mof_overruns;
+	u32	rx_dma_overruns;
+};
+
+/* 0x1900, 0x1a00 */
+struct cpswx_hw_stats {
+	u32	rx_good_frames;
+	u32	rx_broadcast_frames;
+	u32	rx_multicast_frames;
+	u32	rx_pause_frames;
+	u32	rx_crc_errors;
+	u32	rx_align_code_errors;
+	u32	rx_oversized_frames;
+	u32	rx_jabber_frames;
+	u32	rx_undersized_frames;
+	u32	rx_fragments;
+	u32	overrun_type4;
+	u32	overrun_type5;
+	u32	rx_bytes;
+	u32	tx_good_frames;
+	u32	tx_broadcast_frames;
+	u32	tx_multicast_frames;
+	u32	tx_pause_frames;
+	u32	tx_deferred_frames;
+	u32	tx_collision_frames;
+	u32	tx_single_coll_frames;
+	u32	tx_mult_coll_frames;
+	u32	tx_excessive_collisions;
+	u32	tx_late_collisions;
+	u32	tx_underrun;
+	u32	tx_carrier_sense_errors;
+	u32	tx_bytes;
+	u32	tx_64byte_frames;
+	u32	tx_65_to_127byte_frames;
+	u32	tx_128_to_255byte_frames;
+	u32	tx_256_to_511byte_frames;
+	u32	tx_512_to_1023byte_frames;
+	u32	tx_1024byte_frames;
+	u32	net_bytes;
+	u32	rx_sof_overruns;
+	u32	rx_mof_overruns;
+	u32	rx_dma_overruns;
+};
+
+/* 0x1700 */
+struct cpswx_ale_regs {
+	u32	ale_idver;
+	u32	__rsvd0;
+	u32	ale_control;
+	u32	__rsvd1;
+	u32	ale_prescale;
+	u32	ale_aging_timer;  /* +++FIXME: no description found in manual */
+	u32	ale_unknown_vlan;
+	u32	__rsvd3;
+	u32	ale_tblctl;
+	u32	__rsvd4[4];
+	u32	ale_tblw2;
+	u32	ale_tblw1;
+	u32	ale_tblw0;
+	u32	ale_portctl[3];
+};
+
+struct cpswx_priv {
+	struct device			*dev;
+	struct clk			*clk;
+	struct netcp_device		*netcp_device;
+	u32				 num_slaves;
+	u32				 ale_ageout;
+	u32				 ale_entries;
+	u32				 ale_ports;
+	u32				 sgmii_module_ofs;
+	u32				 pcsr_module_ofs;
+	u32				 switch_module_ofs;
+	u32				 host_port_reg_ofs;
+	u32				 slave_reg_ofs;
+	u32				 sliver_reg_ofs;
+	u32				 hw_stats_reg_ofs;
+	u32				 ale_reg_ofs;
+
+	int				 host_port;
+	u32				 rx_packet_max;
+
+	struct cpswx_regs __iomem		*regs;
+	struct cpswx_ss_regs __iomem		*ss_regs;
+	struct cpswx_host_hw_stats __iomem	*host_hw_stats_regs;
+	struct cpswx_hw_stats __iomem		*hw_stats_regs[2];
+	struct cpswx_host_regs __iomem		*host_port_regs;
+	struct cpswx_ale_regs __iomem		*ale_reg;
+
+	void __iomem			*sgmii_port_regs;
+	void __iomem			*pcsr_port_regs;
+
+	struct cpsw_ale			*ale;
+	atomic_t			 ale_refcnt;
+
+	u32				 link[5];
+	struct device_node		*phy_node[4];
+
+	u32				 intf_tx_queues;
+
+	u32				 multi_if;
+	u32				 slaves_per_interface;
+	u32				 num_interfaces;
+	struct device_node		*interfaces;
+	struct list_head		 cpsw_intf_head;
+
+	u64				 hw_stats[96];
+	int				 init_serdes_at_probe;
+	struct kobject			kobj;
+	struct kobject			tx_pri_kobj;
+	struct kobject			pvlan_kobj;
+	struct kobject			stats_kobj;
+	spinlock_t			hw_stats_lock;
+	struct device_node              *serdes;
+};
+
+struct cpswx_intf {
+	struct net_device	*ndev;
+	struct device		*dev;
+	struct cpswx_priv	*cpsw_priv;
+	struct device_node	*phy_node;
+	u32			 num_slaves;
+	u32			 slave_port;
+	struct cpswx_slave	*slaves;
+	u32			 intf_tx_queues;
+	const char		*tx_chan_name;
+	u32			 tx_queue_depth;
+	struct netcp_tx_pipe	 tx_pipe;
+	u32			 multi_if;
+	struct list_head	 cpsw_intf_list;
+	struct timer_list	 timer;
+	u32			 sgmii_link;
+};
+
+/*
+ * Statistic management
+ */
+struct netcp_ethtool_stat {
+	char desc[ETH_GSTRING_LEN];
+	int type;
+	u32 size;
+	int offset;
+};
+
+/* +++FIXME: do we need the port?? */
+#define for_each_slave(priv, func, arg...)				\
+	do {								\
+		int idx, port;						\
+		port = (priv)->slave_port;				\
+		if ((priv)->multi_if)					\
+			(func)((priv)->slaves, ##arg);			\
+		else							\
+			for (idx = 0; idx < (priv)->num_slaves; idx++)	\
+				(func)((priv)->slaves + idx, ##arg);	\
+	} while (0)
+
+#define FIELDINFO(_struct, field) FIELD_SIZEOF(_struct, field), \
+					offsetof(_struct, field)
+
+#define CPSW_STATS0_INFO(field)	"CPSW_0:"#field, CPSW_STATS0_MODULE, \
+				FIELDINFO(struct cpswx_host_hw_stats, field)
+
+#define CPSW_STATSA_INFO(field)	"CPSW_1:"#field, CPSW_STATS1_MODULE, \
+				FIELDINFO(struct cpswx_hw_stats, field)
+#define CPSW_STATSB_INFO(field)	"CPSW_2:"#field, CPSW_STATS2_MODULE, \
+				FIELDINFO(struct cpswx_hw_stats, field)
+
+static const struct netcp_ethtool_stat et_stats[] = {
+	/* CPSW module 0 */
+	{CPSW_STATS0_INFO(rx_good_frames)},
+	{CPSW_STATS0_INFO(rx_broadcast_frames)},
+	{CPSW_STATS0_INFO(rx_multicast_frames)},
+	{CPSW_STATS0_INFO(rx_oversized_frames)},
+	{CPSW_STATS0_INFO(rx_undersized_frames)},
+	{CPSW_STATS0_INFO(overrun_type4)},
+	{CPSW_STATS0_INFO(overrun_type5)},
+	{CPSW_STATS0_INFO(rx_bytes)},
+	{CPSW_STATS0_INFO(tx_good_frames)},
+	{CPSW_STATS0_INFO(tx_broadcast_frames)},
+	{CPSW_STATS0_INFO(tx_multicast_frames)},
+	{CPSW_STATS0_INFO(tx_bytes)},
+	{CPSW_STATS0_INFO(tx_64byte_frames)},
+	{CPSW_STATS0_INFO(tx_65_to_127byte_frames)},
+	{CPSW_STATS0_INFO(tx_128_to_255byte_frames)},
+	{CPSW_STATS0_INFO(tx_256_to_511byte_frames)},
+	{CPSW_STATS0_INFO(tx_512_to_1023byte_frames)},
+	{CPSW_STATS0_INFO(tx_1024byte_frames)},
+	{CPSW_STATS0_INFO(net_bytes)},
+	{CPSW_STATS0_INFO(rx_sof_overruns)},
+	{CPSW_STATS0_INFO(rx_mof_overruns)},
+	{CPSW_STATS0_INFO(rx_dma_overruns)},
+	/* CPSW module 1 */
+	{CPSW_STATSA_INFO(rx_good_frames)},
+	{CPSW_STATSA_INFO(rx_broadcast_frames)},
+	{CPSW_STATSA_INFO(rx_multicast_frames)},
+	{CPSW_STATSA_INFO(rx_pause_frames)},
+	{CPSW_STATSA_INFO(rx_crc_errors)},
+	{CPSW_STATSA_INFO(rx_align_code_errors)},
+	{CPSW_STATSA_INFO(rx_oversized_frames)},
+	{CPSW_STATSA_INFO(rx_jabber_frames)},
+	{CPSW_STATSA_INFO(rx_undersized_frames)},
+	{CPSW_STATSA_INFO(rx_fragments)},
+	{CPSW_STATSA_INFO(overrun_type4)},
+	{CPSW_STATSA_INFO(overrun_type5)},
+	{CPSW_STATSA_INFO(rx_bytes)},
+	{CPSW_STATSA_INFO(tx_good_frames)},
+	{CPSW_STATSA_INFO(tx_broadcast_frames)},
+	{CPSW_STATSA_INFO(tx_multicast_frames)},
+	{CPSW_STATSA_INFO(tx_pause_frames)},
+	{CPSW_STATSA_INFO(tx_deferred_frames)},
+	{CPSW_STATSA_INFO(tx_collision_frames)},
+	{CPSW_STATSA_INFO(tx_single_coll_frames)},
+	{CPSW_STATSA_INFO(tx_mult_coll_frames)},
+	{CPSW_STATSA_INFO(tx_excessive_collisions)},
+	{CPSW_STATSA_INFO(tx_late_collisions)},
+	{CPSW_STATSA_INFO(tx_underrun)},
+	{CPSW_STATSA_INFO(tx_carrier_sense_errors)},
+	{CPSW_STATSA_INFO(tx_bytes)},
+	{CPSW_STATSA_INFO(tx_64byte_frames)},
+	{CPSW_STATSA_INFO(tx_65_to_127byte_frames)},
+	{CPSW_STATSA_INFO(tx_128_to_255byte_frames)},
+	{CPSW_STATSA_INFO(tx_256_to_511byte_frames)},
+	{CPSW_STATSA_INFO(tx_512_to_1023byte_frames)},
+	{CPSW_STATSA_INFO(tx_1024byte_frames)},
+	{CPSW_STATSA_INFO(net_bytes)},
+	{CPSW_STATSA_INFO(rx_sof_overruns)},
+	{CPSW_STATSA_INFO(rx_mof_overruns)},
+	{CPSW_STATSA_INFO(rx_dma_overruns)},
+	/* CPSW module 2 */
+	{CPSW_STATSB_INFO(rx_good_frames)},
+	{CPSW_STATSB_INFO(rx_broadcast_frames)},
+	{CPSW_STATSB_INFO(rx_multicast_frames)},
+	{CPSW_STATSB_INFO(rx_pause_frames)},
+	{CPSW_STATSB_INFO(rx_crc_errors)},
+	{CPSW_STATSB_INFO(rx_align_code_errors)},
+	{CPSW_STATSB_INFO(rx_oversized_frames)},
+	{CPSW_STATSB_INFO(rx_jabber_frames)},
+	{CPSW_STATSB_INFO(rx_undersized_frames)},
+	{CPSW_STATSB_INFO(rx_fragments)},
+	{CPSW_STATSB_INFO(overrun_type4)},
+	{CPSW_STATSB_INFO(overrun_type5)},
+	{CPSW_STATSB_INFO(rx_bytes)},
+	{CPSW_STATSB_INFO(tx_good_frames)},
+	{CPSW_STATSB_INFO(tx_broadcast_frames)},
+	{CPSW_STATSB_INFO(tx_multicast_frames)},
+	{CPSW_STATSB_INFO(tx_pause_frames)},
+	{CPSW_STATSB_INFO(tx_deferred_frames)},
+	{CPSW_STATSB_INFO(tx_collision_frames)},
+	{CPSW_STATSB_INFO(tx_single_coll_frames)},
+	{CPSW_STATSB_INFO(tx_mult_coll_frames)},
+	{CPSW_STATSB_INFO(tx_excessive_collisions)},
+	{CPSW_STATSB_INFO(tx_late_collisions)},
+	{CPSW_STATSB_INFO(tx_underrun)},
+	{CPSW_STATSB_INFO(tx_carrier_sense_errors)},
+	{CPSW_STATSB_INFO(tx_bytes)},
+	{CPSW_STATSB_INFO(tx_64byte_frames)},
+	{CPSW_STATSB_INFO(tx_65_to_127byte_frames)},
+	{CPSW_STATSB_INFO(tx_128_to_255byte_frames)},
+	{CPSW_STATSB_INFO(tx_256_to_511byte_frames)},
+	{CPSW_STATSB_INFO(tx_512_to_1023byte_frames)},
+	{CPSW_STATSB_INFO(tx_1024byte_frames)},
+	{CPSW_STATSB_INFO(net_bytes)},
+	{CPSW_STATSB_INFO(rx_sof_overruns)},
+	{CPSW_STATSB_INFO(rx_mof_overruns)},
+	{CPSW_STATSB_INFO(rx_dma_overruns)},
+};
+
+#define ETHTOOL_STATS_NUM ARRAY_SIZE(et_stats)
+
+struct cpswx_attribute {
+	struct attribute attr;
+	ssize_t (*show)(struct cpswx_priv *cpsw_dev,
+		struct cpswx_attribute *attr, char *buf);
+	ssize_t	(*store)(struct cpswx_priv *cpsw_dev,
+		struct cpswx_attribute *attr, const char *, size_t);
+	const struct cpswx_mod_info *info;
+	ssize_t info_size;
+	void *context;
+};
+#define to_cpswx_attr(_attr) container_of(_attr, struct cpswx_attribute, attr)
+
+#define to_cpswx_dev(obj) container_of(obj, struct cpswx_priv, kobj)
+
+#define tx_pri_to_cpswx_dev(obj) \
+	container_of(obj, struct cpswx_priv, tx_pri_kobj)
+
+#define pvlan_to_cpswx_dev(obj) \
+	container_of(obj, struct cpswx_priv, pvlan_kobj)
+
+#define stats_to_cpswx_dev(obj) \
+	container_of(obj, struct cpswx_priv, stats_kobj)
+
+#define BITS(x)			(BIT(x) - 1)
+#define BITMASK(n, s)		(BITS(n) << (s))
+#define cpsw_mod_info_field_val(r, i) \
+	((r & BITMASK(i->bits, i->shift)) >> i->shift)
+
+#define for_each_intf(i, priv) \
+	list_for_each_entry((i), &(priv)->cpsw_intf_head, cpsw_intf_list)
+
+#define __CPSW_ATTR_FULL(_name, _mode, _show, _store, _info,	\
+				_info_size, _ctxt)		\
+	{ \
+		.attr = {.name = __stringify(_name), .mode = _mode },	\
+		.show	= _show,		\
+		.store	= _store,		\
+		.info	= _info,		\
+		.info_size = _info_size,	\
+		.context = (_ctxt),		\
+	}
+
+#define __CPSW_ATTR(_name, _mode, _show, _store, _info) \
+		__CPSW_ATTR_FULL(_name, _mode, _show, _store, _info, \
+					(ARRAY_SIZE(_info)), NULL)
+
+#define __CPSW_CTXT_ATTR(_name, _mode, _show, _store, _info, _ctxt) \
+		__CPSW_ATTR_FULL(_name, _mode, _show, _store, _info, \
+					(ARRAY_SIZE(_info)), _ctxt)
+
+struct cpswx_mod_info {
+	const char	*name;
+	int		shift;
+	int		bits;
+};
+
+struct cpswx_parse_result {
+	int control;
+	int port;
+	u32 value;
+};
+
+static ssize_t cpsw_attr_info_show(const struct cpswx_mod_info *info,
+				int info_size, u32 reg, char *buf)
+{
+	int i, len = 0;
+
+	for (i = 0; i < info_size; i++, info++) {
+		len += snprintf(buf + len, PAGE_SIZE - len,
+			"%s=%d\n", info->name,
+			(int)cpsw_mod_info_field_val(reg, info));
+	}
+
+	return len;
+}
+
+static ssize_t cpsw_attr_parse_set_command(struct cpswx_priv *cpsw_dev,
+			      struct cpswx_attribute *attr,
+			      const char *buf, size_t count,
+				struct cpswx_parse_result *res)
+{
+	char ctrl_str[33], tmp_str[9];
+	int port = -1, value, len, control;
+	unsigned long end;
+	const struct cpswx_mod_info *info = attr->info;
+
+	len = strcspn(buf, ".=");
+	if (len >= 32)
+		return -ENOMEM;
+
+	strncpy(ctrl_str, buf, len);
+	ctrl_str[len] = '\0';
+	buf += len;
+
+	if (*buf == '.') {
+		++buf;
+		len = strcspn(buf, "=");
+		if (len >= 8)
+			return -ENOMEM;
+		strncpy(tmp_str, buf, len);
+		tmp_str[len] = '\0';
+		if (kstrtoul(tmp_str, 0, &end))
+			return -EINVAL;
+		port = (int)end;
+		buf += len;
+	}
+
+	if (*buf != '=')
+		return -EINVAL;
+
+	if (kstrtoul(buf + 1, 0, &end))
+		return -EINVAL;
+
+	value = (int)end;
+
+	for (control = 0; control < attr->info_size; control++)
+		if (strcmp(ctrl_str, info[control].name) == 0)
+			break;
+
+	if (control >= attr->info_size)
+		return -ENOENT;
+
+	res->control = control;
+	res->port = port;
+	res->value = value;
+
+	dev_info(cpsw_dev->dev, "parsed command %s.%d=%d\n",
+		attr->info[control].name, port, value);
+
+	return 0;
+}
+
+static inline void cpsw_info_set_reg_field(void __iomem *r,
+		const struct cpswx_mod_info *info, int val)
+{
+	u32 rv;
+
+	rv = __raw_readl(r);
+	rv = ((rv & ~BITMASK(info->bits, info->shift)) | (val << info->shift));
+	__raw_writel(rv, r);
+}
+
+static ssize_t cpsw_version_show(struct cpswx_priv *cpsw_dev,
+		     struct cpswx_attribute *attr,
+		     char *buf)
+{
+	u32 reg;
+
+	reg = __raw_readl(&cpsw_dev->regs->id_ver);
+
+	return snprintf(buf, PAGE_SIZE,
+		"cpsw version %d.%d (%d) SGMII identification value 0x%x\n",
+		 CPSW_MAJOR_VERSION(reg), CPSW_MINOR_VERSION(reg),
+		 CPSW_RTL_VERSION(reg), CPSW_IDENT(reg));
+}
+
+static struct cpswx_attribute cpsw_version_attribute =
+	__ATTR(version, S_IRUGO, cpsw_version_show, NULL);
+
+static const struct cpswx_mod_info cpsw_controls[] = {
+	{
+		.name		= "fifo_loopback",
+		.shift		= 0,
+		.bits		= 1,
+	},
+	{
+		.name		= "vlan_aware",
+		.shift		= 1,
+		.bits		= 1,
+	},
+	{
+		.name		= "p0_enable",
+		.shift		= 2,
+		.bits		= 1,
+	},
+	{
+		.name		= "p0_pass_pri_tagged",
+		.shift		= 3,
+		.bits		= 1,
+	},
+	{
+		.name		= "p1_pass_pri_tagged",
+		.shift		= 4,
+		.bits		= 1,
+	},
+	{
+		.name		= "p2_pass_pri_tagged",
+		.shift		= 5,
+		.bits		= 1,
+	},
+	{
+		.name		= "p0_tx_crc_type",
+		.shift		= 12,
+		.bits		= 1,
+	},
+};
+
+static ssize_t cpsw_control_show(struct cpswx_priv *cpsw_dev,
+		     struct cpswx_attribute *attr,
+		     char *buf)
+{
+	u32 reg;
+
+	reg = __raw_readl(&cpsw_dev->regs->control);
+	return cpsw_attr_info_show(attr->info, attr->info_size, reg, buf);
+}
+
+static ssize_t cpsw_control_store(struct cpswx_priv *cpsw_dev,
+			      struct cpswx_attribute *attr,
+			      const char *buf, size_t count)
+{
+	const struct cpswx_mod_info *i;
+	struct cpswx_parse_result res;
+	void __iomem *r = NULL;
+	int ret;
+
+
+	ret = cpsw_attr_parse_set_command(cpsw_dev, attr, buf, count, &res);
+	if (ret)
+		return ret;
+
+	i = &(attr->info[res.control]);
+	r = &cpsw_dev->regs->control;
+
+	cpsw_info_set_reg_field(r, i, res.value);
+	return count;
+}
+
+static struct cpswx_attribute cpsw_control_attribute =
+	__CPSW_ATTR(control, S_IRUGO | S_IWUSR,
+		cpsw_control_show, cpsw_control_store, cpsw_controls);
+
+static const struct cpswx_mod_info cpsw_ptypes[] = {
+	{
+		.name		= "escalate_pri_load_val",
+		.shift		= 0,
+		.bits		= 5,
+	},
+	{
+		.name		= "port0_pri_type_escalate",
+		.shift		= 8,
+		.bits		= 1,
+	},
+	{
+		.name		= "port1_pri_type_escalate",
+		.shift		= 9,
+		.bits		= 1,
+	},
+	{
+		.name		= "port2_pri_type_escalate",
+		.shift		= 10,
+		.bits		= 1,
+	},
+};
+
+static ssize_t cpsw_pri_type_show(struct cpswx_priv *cpsw_dev,
+		     struct cpswx_attribute *attr,
+		     char *buf)
+{
+	u32 reg;
+
+	reg = __raw_readl(&cpsw_dev->regs->ptype);
+
+	return cpsw_attr_info_show(attr->info, attr->info_size, reg, buf);
+}
+
+static ssize_t cpsw_pri_type_store(struct cpswx_priv *cpsw_dev,
+			      struct cpswx_attribute *attr,
+			      const char *buf, size_t count)
+{
+	const struct cpswx_mod_info *i;
+	struct cpswx_parse_result res;
+	void __iomem *r = NULL;
+	int ret;
+
+
+	ret = cpsw_attr_parse_set_command(cpsw_dev, attr, buf, count, &res);
+	if (ret)
+		return ret;
+
+	i = &(attr->info[res.control]);
+	r = &cpsw_dev->regs->ptype;
+
+	cpsw_info_set_reg_field(r, i, res.value);
+	return count;
+}
+
+static struct cpswx_attribute cpsw_pri_type_attribute =
+	__CPSW_ATTR(priority_type, S_IRUGO | S_IWUSR,
+			cpsw_pri_type_show,
+			cpsw_pri_type_store,
+			cpsw_ptypes);
+
+static const struct cpswx_mod_info cpsw_flow_controls[] = {
+	{
+		.name		= "port0_flow_control_en",
+		.shift		= 0,
+		.bits		= 1,
+	},
+	{
+		.name		= "port1_flow_control_en",
+		.shift		= 1,
+		.bits		= 1,
+	},
+	{
+		.name		= "port2_flow_control_en",
+		.shift		= 2,
+		.bits		= 1,
+	},
+};
+
+static ssize_t cpsw_flow_control_show(struct cpswx_priv *cpsw_dev,
+		     struct cpswx_attribute *attr, char *buf)
+{
+	u32 reg;
+
+	reg = __raw_readl(&cpsw_dev->regs->flow_control);
+
+	return cpsw_attr_info_show(attr->info, attr->info_size, reg, buf);
+}
+
+static ssize_t cpsw_flow_control_store(struct cpswx_priv *cpsw_dev,
+			      struct cpswx_attribute *attr,
+			      const char *buf, size_t count)
+{
+	const struct cpswx_mod_info *i;
+	struct cpswx_parse_result res;
+	void __iomem *r = NULL;
+	int ret;
+
+
+	ret = cpsw_attr_parse_set_command(cpsw_dev, attr, buf, count, &res);
+	if (ret)
+		return ret;
+
+	i = &(attr->info[res.control]);
+	r = &cpsw_dev->regs->flow_control;
+
+	cpsw_info_set_reg_field(r, i, res.value);
+	return count;
+}
+
+static struct cpswx_attribute cpsw_flow_control_attribute =
+	__CPSW_ATTR(flow_control, S_IRUGO | S_IWUSR,
+		cpsw_flow_control_show,
+		cpsw_flow_control_store,
+		cpsw_flow_controls);
+
+static const struct cpswx_mod_info cpsw_port_tx_pri_maps[] = {
+	{
+		.name		= "port_tx_pri_0",
+		.shift		= 0,
+		.bits		= 3,
+	},
+	{
+		.name		= "port_tx_pri_1",
+		.shift		= 4,
+		.bits		= 3,
+	},
+	{
+		.name		= "port_tx_pri_2",
+		.shift		= 8,
+		.bits		= 3,
+	},
+	{
+		.name		= "port_tx_pri_3",
+		.shift		= 12,
+		.bits		= 3,
+	},
+	{
+		.name		= "port_tx_pri_4",
+		.shift		= 16,
+		.bits		= 3,
+	},
+	{
+		.name		= "port_tx_pri_5",
+		.shift		= 20,
+		.bits		= 3,
+	},
+	{
+		.name		= "port_tx_pri_6",
+		.shift		= 24,
+		.bits		= 3,
+	},
+	{
+		.name		= "port_tx_pri_7",
+		.shift		= 28,
+		.bits		= 3,
+	},
+};
+
+static ssize_t cpsw_port_tx_pri_map_show(struct cpswx_priv *cpsw_dev,
+		     struct cpswx_attribute *attr,
+		     char *buf)
+{
+	int idx, len = 0, total_len = 0, port;
+	struct cpswx_intf *cpsw_intf;
+	struct cpswx_slave *slave;
+	u32 reg;
+
+	port = (int)(attr->context);
+
+	/* Host port */
+	if (port == cpsw_dev->host_port) {
+		reg = __raw_readl(&cpsw_dev->host_port_regs->tx_pri_map);
+		len = cpsw_attr_info_show(attr->info, attr->info_size,
+					reg, buf);
+		return len;
+	}
+
+	for_each_intf(cpsw_intf, cpsw_dev) {
+		if (cpsw_intf->multi_if) {
+			slave = cpsw_intf->slaves;
+			if (slave->port_num != port)
+				continue;
+			reg = __raw_readl(&slave->regs->tx_pri_map);
+			len = cpsw_attr_info_show(attr->info, attr->info_size,
+						reg, buf+total_len);
+			total_len += len;
+		} else {
+			for (idx = 0; idx < cpsw_intf->num_slaves; idx++) {
+				slave = cpsw_intf->slaves + idx;
+				if (slave->port_num != port)
+					continue;
+				reg = __raw_readl(&slave->regs->tx_pri_map);
+				len = cpsw_attr_info_show(attr->info,
+					attr->info_size, reg, buf+total_len);
+				total_len += len;
+			}
+		}
+	}
+	return total_len;
+}
+
+static ssize_t cpsw_port_tx_pri_map_store(struct cpswx_priv *cpsw_dev,
+			      struct cpswx_attribute *attr,
+			      const char *buf, size_t count)
+{
+	const struct cpswx_mod_info *i;
+	struct cpswx_parse_result res;
+	struct cpswx_intf *cpsw_intf;
+	struct cpswx_slave *slave;
+	void __iomem *r = NULL;
+	int ret, idx, port;
+
+	port = (int)(attr->context);
+
+	ret = cpsw_attr_parse_set_command(cpsw_dev, attr, buf, count, &res);
+	if (ret)
+		return ret;
+
+	i = &(attr->info[res.control]);
+
+	/* Host port */
+	if (port == cpsw_dev->host_port) {
+		r = &cpsw_dev->host_port_regs->tx_pri_map;
+		goto set;
+	}
+
+	/* Slave port */
+	for_each_intf(cpsw_intf, cpsw_dev) {
+		if (cpsw_intf->multi_if) {
+			slave = cpsw_intf->slaves;
+			if (slave->port_num == port) {
+				r = &slave->regs->tx_pri_map;
+				goto set;
+			}
+		} else
+			for (idx = 0; idx < cpsw_intf->num_slaves; idx++) {
+				slave = cpsw_intf->slaves + idx;
+				if (slave->port_num == port) {
+					r = &slave->regs->tx_pri_map;
+					goto set;
+				}
+			}
+	}
+
+	if (!r)
+		return  -ENOENT;
+
+set:
+	cpsw_info_set_reg_field(r, i, res.value);
+	return count;
+}
+
+static struct cpswx_attribute cpsw_tx_pri_0_attribute =
+	__CPSW_CTXT_ATTR(0, S_IRUGO | S_IWUSR,
+			cpsw_port_tx_pri_map_show,
+			cpsw_port_tx_pri_map_store,
+			cpsw_port_tx_pri_maps, (void *)0);
+
+static struct cpswx_attribute cpsw_tx_pri_1_attribute =
+	__CPSW_CTXT_ATTR(1, S_IRUGO | S_IWUSR,
+			cpsw_port_tx_pri_map_show,
+			cpsw_port_tx_pri_map_store,
+			cpsw_port_tx_pri_maps, (void *)1);
+
+static struct cpswx_attribute cpsw_tx_pri_2_attribute =
+	__CPSW_CTXT_ATTR(2, S_IRUGO | S_IWUSR,
+			cpsw_port_tx_pri_map_show,
+			cpsw_port_tx_pri_map_store,
+			cpsw_port_tx_pri_maps, (void *)2);
+
+static struct attribute *cpsw_tx_pri_default_attrs[] = {
+	&cpsw_tx_pri_0_attribute.attr,
+	&cpsw_tx_pri_1_attribute.attr,
+	&cpsw_tx_pri_2_attribute.attr,
+	NULL
+};
+
+static ssize_t cpsw_tx_pri_attr_show(struct kobject *kobj,
+			struct attribute *attr, char *buf)
+{
+	struct cpswx_attribute *attribute = to_cpswx_attr(attr);
+	struct cpswx_priv *cpsw_dev = tx_pri_to_cpswx_dev(kobj);
+
+	if (!attribute->show)
+		return -EIO;
+
+	return attribute->show(cpsw_dev, attribute, buf);
+}
+
+static ssize_t cpsw_tx_pri_attr_store(struct kobject *kobj,
+			struct attribute *attr, const char *buf, size_t count)
+{
+	struct cpswx_attribute *attribute = to_cpswx_attr(attr);
+	struct cpswx_priv *cpsw_dev = tx_pri_to_cpswx_dev(kobj);
+
+	if (!attribute->store)
+		return -EIO;
+
+	return attribute->store(cpsw_dev, attribute, buf, count);
+}
+
+static const struct sysfs_ops cpsw_tx_pri_sysfs_ops = {
+	.show = cpsw_tx_pri_attr_show,
+	.store = cpsw_tx_pri_attr_store,
+};
+
+static struct kobj_type cpsw_tx_pri_ktype = {
+	.sysfs_ops = &cpsw_tx_pri_sysfs_ops,
+	.default_attrs = cpsw_tx_pri_default_attrs,
+};
+
+static const struct cpswx_mod_info cpsw_port_vlans[] = {
+	{
+		.name		= "port_vlan_id",
+		.shift		= 0,
+		.bits		= 12,
+	},
+	{
+		.name		= "port_cfi",
+		.shift		= 12,
+		.bits		= 1,
+	},
+	{
+		.name		= "port_vlan_pri",
+		.shift		= 13,
+		.bits		= 3,
+	},
+};
+
+static ssize_t cpsw_port_vlan_show(struct cpswx_priv *cpsw_dev,
+		     struct cpswx_attribute *attr,
+		     char *buf)
+{
+	int idx, len = 0, total_len = 0, port;
+	struct cpswx_intf *cpsw_intf;
+	struct cpswx_slave *slave;
+	u32 reg;
+
+	port = (int)(attr->context);
+
+	if (port == cpsw_dev->host_port) {
+		/* Host port */
+		reg = __raw_readl(&cpsw_dev->host_port_regs->port_vlan);
+		len = cpsw_attr_info_show(attr->info, attr->info_size,
+					reg, buf);
+		return len;
+	}
+
+	/* Slave ports */
+	for_each_intf(cpsw_intf, cpsw_dev) {
+		if (cpsw_intf->multi_if) {
+			slave = cpsw_intf->slaves;
+			if (slave->port_num != port)
+				continue;
+			reg = __raw_readl(&slave->regs->port_vlan);
+			len = cpsw_attr_info_show(attr->info, attr->info_size,
+					reg, buf+total_len);
+			total_len += len;
+		} else {
+			for (idx = 0; idx < cpsw_intf->num_slaves; idx++) {
+				slave = cpsw_intf->slaves + idx;
+				if (slave->port_num != port)
+					continue;
+				reg = __raw_readl(&slave->regs->port_vlan);
+				len = cpsw_attr_info_show(attr->info,
+					attr->info_size, reg, buf+total_len);
+				total_len += len;
+			}
+		}
+	}
+	return total_len;
+}
+
+static ssize_t cpsw_port_vlan_store(struct cpswx_priv *cpsw_dev,
+			      struct cpswx_attribute *attr,
+			      const char *buf, size_t count)
+{
+	const struct cpswx_mod_info *i;
+	struct cpswx_parse_result res;
+	struct cpswx_intf *cpsw_intf;
+	struct cpswx_slave *slave;
+	void __iomem *r = NULL;
+	int ret, idx, port;
+
+	port = (int)(attr->context);
+
+	ret = cpsw_attr_parse_set_command(cpsw_dev, attr, buf, count, &res);
+	if (ret)
+		return ret;
+
+	i = &(attr->info[res.control]);
+
+	/* Host port */
+	if (port == cpsw_dev->host_port) {
+		r = &cpsw_dev->host_port_regs->port_vlan;
+		goto set;
+	}
+
+	/* Slave port */
+	for_each_intf(cpsw_intf, cpsw_dev) {
+		if (cpsw_intf->multi_if) {
+			slave = cpsw_intf->slaves;
+			if (slave->port_num == port) {
+				r = &slave->regs->port_vlan;
+				goto set;
+			}
+		} else
+			for (idx = 0; idx < cpsw_intf->num_slaves; idx++) {
+				slave = cpsw_intf->slaves + idx;
+				if (slave->port_num == port) {
+					r = &slave->regs->port_vlan;
+					goto set;
+				}
+			}
+	}
+
+	if (!r)
+		return  -ENOENT;
+
+set:
+	cpsw_info_set_reg_field(r, i, res.value);
+	return count;
+}
+
+static struct cpswx_attribute cpsw_pvlan_0_attribute =
+	__CPSW_CTXT_ATTR(0, S_IRUGO | S_IWUSR,
+			cpsw_port_vlan_show,
+			cpsw_port_vlan_store,
+			cpsw_port_vlans, (void *)0);
+
+static struct cpswx_attribute cpsw_pvlan_1_attribute =
+	__CPSW_CTXT_ATTR(1, S_IRUGO | S_IWUSR,
+			cpsw_port_vlan_show,
+			cpsw_port_vlan_store,
+			cpsw_port_vlans, (void *)1);
+
+static struct cpswx_attribute cpsw_pvlan_2_attribute =
+	__CPSW_CTXT_ATTR(2, S_IRUGO | S_IWUSR,
+			cpsw_port_vlan_show,
+			cpsw_port_vlan_store,
+			cpsw_port_vlans, (void *)2);
+
+static struct attribute *cpsw_pvlan_default_attrs[] = {
+	&cpsw_pvlan_0_attribute.attr,
+	&cpsw_pvlan_1_attribute.attr,
+	&cpsw_pvlan_2_attribute.attr,
+	NULL
+};
+
+static ssize_t cpsw_pvlan_attr_show(struct kobject *kobj,
+			struct attribute *attr, char *buf)
+{
+	struct cpswx_attribute *attribute = to_cpswx_attr(attr);
+	struct cpswx_priv *cpsw_dev = pvlan_to_cpswx_dev(kobj);
+
+	if (!attribute->show)
+		return -EIO;
+
+	return attribute->show(cpsw_dev, attribute, buf);
+}
+
+static ssize_t cpsw_pvlan_attr_store(struct kobject *kobj,
+			struct attribute *attr, const char *buf, size_t count)
+{
+	struct cpswx_attribute *attribute = to_cpswx_attr(attr);
+	struct cpswx_priv *cpsw_dev = pvlan_to_cpswx_dev(kobj);
+
+	if (!attribute->store)
+		return -EIO;
+
+	return attribute->store(cpsw_dev, attribute, buf, count);
+}
+
+static const struct sysfs_ops cpsw_pvlan_sysfs_ops = {
+	.show = cpsw_pvlan_attr_show,
+	.store = cpsw_pvlan_attr_store,
+};
+
+static struct kobj_type cpsw_pvlan_ktype = {
+	.sysfs_ops = &cpsw_pvlan_sysfs_ops,
+	.default_attrs = cpsw_pvlan_default_attrs,
+};
+
+static void cpsw_reset_mod_stats(struct cpswx_priv *cpsw_dev, int stat_mod)
+{
+	struct cpswx_host_hw_stats __iomem *cpsw_stats0;
+	struct cpswx_hw_stats __iomem *cpsw_statsa;
+	struct cpswx_hw_stats __iomem *cpsw_statsb;
+	void __iomem *base;
+	u32  __iomem *p;
+	int i;
+
+	cpsw_stats0 = cpsw_dev->host_hw_stats_regs;
+	cpsw_statsa = cpsw_dev->hw_stats_regs[0];
+	cpsw_statsb = cpsw_dev->hw_stats_regs[1];
+
+	switch (stat_mod) {
+	case CPSW_STATS0_MODULE:
+		base = cpsw_stats0;
+		break;
+	case CPSW_STATS1_MODULE:
+		base = cpsw_statsa;
+		break;
+	case CPSW_STATS2_MODULE:
+		base  = cpsw_statsb;
+		break;
+	default:
+		dev_err(cpsw_dev->dev, "Unknown stat module %d\n", stat_mod);
+		return;
+	}
+
+	for (i = 0; i < ETHTOOL_STATS_NUM; i++) {
+		if (et_stats[i].type == stat_mod) {
+			cpsw_dev->hw_stats[i] = 0;
+			p = base + et_stats[i].offset;
+			*p = 0xffffffff;
+		}
+	}
+	return;
+}
+
+static ssize_t cpsw_stats_mod_store(struct cpswx_priv *cpsw_dev,
+			      struct cpswx_attribute *attr,
+			      const char *buf, size_t count)
+{
+	unsigned long end;
+	int stat_mod;
+
+	if (kstrtoul(buf, 0, &end) != 0 || (end != 0))
+		return -EINVAL;
+
+	stat_mod = (int)(attr->context);
+	spin_lock_bh(&cpsw_dev->hw_stats_lock);
+	cpsw_reset_mod_stats(cpsw_dev, stat_mod);
+	spin_unlock_bh(&cpsw_dev->hw_stats_lock);
+	return count;
+}
+
+static struct cpswx_attribute cpsw_stats_0_attribute =
+	__CPSW_ATTR_FULL(0, S_IWUSR, NULL, cpsw_stats_mod_store,
+			NULL, 0, (void *)CPSW_STATS0_MODULE);
+
+static struct cpswx_attribute cpsw_stats_1_attribute =
+	__CPSW_ATTR_FULL(1, S_IWUSR, NULL, cpsw_stats_mod_store,
+			NULL, 0, (void *)CPSW_STATS1_MODULE);
+
+static struct cpswx_attribute cpsw_stats_2_attribute =
+	__CPSW_ATTR_FULL(2, S_IWUSR, NULL, cpsw_stats_mod_store,
+			NULL, 0, (void *)CPSW_STATS2_MODULE);
+
+static struct attribute *cpsw_stats_default_attrs[] = {
+	&cpsw_stats_0_attribute.attr,
+	&cpsw_stats_1_attribute.attr,
+	&cpsw_stats_2_attribute.attr,
+	NULL
+};
+
+static ssize_t cpsw_stats_attr_store(struct kobject *kobj,
+			struct attribute *attr, const char *buf, size_t count)
+{
+	struct cpswx_attribute *attribute = to_cpswx_attr(attr);
+	struct cpswx_priv *cpsw_dev = stats_to_cpswx_dev(kobj);
+
+	if (!attribute->store)
+		return -EIO;
+
+	return attribute->store(cpsw_dev, attribute, buf, count);
+}
+
+static const struct sysfs_ops cpsw_stats_sysfs_ops = {
+	.store = cpsw_stats_attr_store,
+};
+
+static struct kobj_type cpsw_stats_ktype = {
+	.sysfs_ops = &cpsw_stats_sysfs_ops,
+	.default_attrs = cpsw_stats_default_attrs,
+};
+static struct attribute *cpsw_default_attrs[] = {
+	&cpsw_version_attribute.attr,
+	&cpsw_control_attribute.attr,
+	&cpsw_pri_type_attribute.attr,
+	&cpsw_flow_control_attribute.attr,
+	NULL
+};
+
+static ssize_t cpsw_attr_show(struct kobject *kobj, struct attribute *attr,
+				  char *buf)
+{
+	struct cpswx_attribute *attribute = to_cpswx_attr(attr);
+	struct cpswx_priv *cpsw_dev = to_cpswx_dev(kobj);
+
+	if (!attribute->show)
+		return -EIO;
+
+	return attribute->show(cpsw_dev, attribute, buf);
+}
+
+static ssize_t cpsw_attr_store(struct kobject *kobj, struct attribute *attr,
+				   const char *buf, size_t count)
+{
+	struct cpswx_attribute *attribute = to_cpswx_attr(attr);
+	struct cpswx_priv *cpsw_dev = to_cpswx_dev(kobj);
+
+	if (!attribute->store)
+		return -EIO;
+
+	return attribute->store(cpsw_dev, attribute, buf, count);
+}
+
+static const struct sysfs_ops cpsw_sysfs_ops = {
+	.show = cpsw_attr_show,
+	.store = cpsw_attr_store,
+};
+
+static struct kobj_type cpsw_ktype = {
+	.sysfs_ops = &cpsw_sysfs_ops,
+	.default_attrs = cpsw_default_attrs,
+};
+
+static void keystone_get_drvinfo(struct net_device *ndev,
+			     struct ethtool_drvinfo *info)
+{
+	strncpy(info->driver, NETCP_DRIVER_NAME, sizeof(info->driver));
+	strncpy(info->version, NETCP_DRIVER_VERSION, sizeof(info->version));
+}
+
+static u32 keystone_get_msglevel(struct net_device *ndev)
+{
+	struct netcp_priv *netcp = netdev_priv(ndev);
+	return netcp->msg_enable;
+}
+
+static void keystone_set_msglevel(struct net_device *ndev, u32 value)
+{
+	struct netcp_priv *netcp = netdev_priv(ndev);
+	netcp->msg_enable = value;
+}
+
+static void keystone_get_stat_strings(struct net_device *ndev,
+				   uint32_t stringset, uint8_t *data)
+{
+	int i;
+
+	switch (stringset) {
+	case ETH_SS_STATS:
+		for (i = 0; i < ETHTOOL_STATS_NUM; i++) {
+			memcpy(data, et_stats[i].desc, ETH_GSTRING_LEN);
+			data += ETH_GSTRING_LEN;
+		}
+		break;
+	case ETH_SS_TEST:
+		break;
+	}
+}
+
+static int keystone_get_sset_count(struct net_device *ndev, int stringset)
+{
+	switch (stringset) {
+	case ETH_SS_TEST:
+		return 0;
+	case ETH_SS_STATS:
+		return ETHTOOL_STATS_NUM;
+	default:
+		return -EINVAL;
+	}
+}
+
+static void cpswx_update_stats(struct cpswx_priv *cpsw_dev, uint64_t *data)
+{
+	struct cpswx_host_hw_stats __iomem *cpsw_stats0;
+	struct cpswx_hw_stats __iomem *cpsw_statsa;
+	struct cpswx_hw_stats __iomem *cpsw_statsb;
+	void __iomem *base = NULL;
+	u32  __iomem *p;
+	u32 tmp = 0;
+	int i;
+
+	cpsw_stats0 = cpsw_dev->host_hw_stats_regs;
+	cpsw_statsa = cpsw_dev->hw_stats_regs[0];
+	cpsw_statsb = cpsw_dev->hw_stats_regs[1];
+
+	for (i = 0; i < ETHTOOL_STATS_NUM; i++) {
+		switch (et_stats[i].type) {
+		case CPSW_STATS0_MODULE:
+			base = cpsw_stats0;
+			break;
+		case CPSW_STATS1_MODULE:
+			base = cpsw_statsa;
+			break;
+		case CPSW_STATS2_MODULE:
+			base = cpsw_statsb;
+			break;
+		default:
+			dev_err(cpsw_dev->dev, "Unknown stat module %d\n",
+				et_stats[i].type);
+			return;
+		}
+
+		p = base + et_stats[i].offset;
+		tmp = *p;
+		cpsw_dev->hw_stats[i] = cpsw_dev->hw_stats[i] + tmp;
+		if (data)
+			data[i] = cpsw_dev->hw_stats[i];
+		*p = tmp;
+	}
+
+	return;
+}
+
+static void keystone_get_ethtool_stats(struct net_device *ndev,
+				       struct ethtool_stats *stats,
+				       uint64_t *data)
+{
+	struct netcp_priv *netcp = netdev_priv(ndev);
+	struct netcp_device *netcp_device = netcp->netcp_device;
+	struct cpswx_priv *priv;
+
+	/* find the instance of the module registered to the netcp_device */
+	priv = (struct cpswx_priv *)netcp_device_find_module(netcp_device,
+							CPSW_MODULE_NAME);
+	if (priv) {
+		spin_lock_bh(&priv->hw_stats_lock);
+		cpswx_update_stats(priv, data);
+		spin_unlock_bh(&priv->hw_stats_lock);
+	}
+
+	return;
+}
+
+static int keystone_get_settings(struct net_device *ndev,
+			      struct ethtool_cmd *cmd)
+{
+	struct phy_device *phy = ndev->phydev;
+	struct cpswx_slave *slave;
+	int ret;
+
+	if (!phy)
+		return -EINVAL;
+
+	slave = (struct cpswx_slave *)phy->context;
+	if (!slave)
+		return -EINVAL;
+
+	ret = phy_ethtool_gset(phy, cmd);
+	if (!ret)
+		cmd->port = slave->phy_port_t;
+
+	return ret;
+}
+
+static int keystone_set_settings(struct net_device *ndev,
+				struct ethtool_cmd *cmd)
+{
+	struct phy_device *phy = ndev->phydev;
+	struct cpswx_slave *slave;
+	u32 features = cmd->advertising & cmd->supported;
+
+	if (!phy)
+		return -EINVAL;
+
+	slave = (struct cpswx_slave *)phy->context;
+	if (!slave)
+		return -EINVAL;
+
+	if (cmd->port != slave->phy_port_t) {
+		if ((cmd->port == PORT_TP) && !(features & ADVERTISED_TP))
+			return -EINVAL;
+
+		if ((cmd->port == PORT_AUI) && !(features & ADVERTISED_AUI))
+			return -EINVAL;
+
+		if ((cmd->port == PORT_BNC) && !(features & ADVERTISED_BNC))
+			return -EINVAL;
+
+		if ((cmd->port == PORT_MII) && !(features & ADVERTISED_MII))
+			return -EINVAL;
+
+		if ((cmd->port == PORT_FIBRE) && !(features & ADVERTISED_FIBRE))
+			return -EINVAL;
+	}
+
+	slave->phy_port_t = cmd->port;
+
+	return phy_ethtool_sset(phy, cmd);
+}
+
+static const struct ethtool_ops keystone_ethtool_ops = {
+	.get_drvinfo		= keystone_get_drvinfo,
+	.get_link		= ethtool_op_get_link,
+	.get_msglevel		= keystone_get_msglevel,
+	.set_msglevel		= keystone_set_msglevel,
+	.get_strings		= keystone_get_stat_strings,
+	.get_sset_count		= keystone_get_sset_count,
+	.get_ethtool_stats	= keystone_get_ethtool_stats,
+	.get_settings		= keystone_get_settings,
+	.set_settings		= keystone_set_settings,
+};
+
+#define mac_hi(mac)	(((mac)[0] << 0) | ((mac)[1] << 8) |	\
+			 ((mac)[2] << 16) | ((mac)[3] << 24))
+#define mac_lo(mac)	(((mac)[4] << 0) | ((mac)[5] << 8))
+
+static void cpsw_set_slave_mac(struct cpswx_slave *slave,
+			       struct cpswx_intf *cpsw_intf)
+{
+	struct net_device *ndev = cpsw_intf->ndev;
+
+	__raw_writel(mac_hi(ndev->dev_addr), &slave->regs->sa_hi);
+	__raw_writel(mac_lo(ndev->dev_addr), &slave->regs->sa_lo);
+}
+
+static inline int cpsw_get_slave_port(struct cpswx_priv *priv, u32 slave_num)
+{
+	if (priv->host_port == 0)
+		return slave_num + 1;
+	else
+		return slave_num;
+}
+
+static void _cpsw_adjust_link(struct cpswx_slave *slave, bool *link)
+{
+	struct phy_device *phy = slave->phy;
+	u32 mac_control = 0;
+	u32 slave_port;
+
+	if (!phy)
+		return;
+
+	if (!slave->ale)
+		return;
+
+	slave_port = slave->port_num;
+
+	if (phy->link) {
+		mac_control = slave->mac_control;
+		mac_control |= MACSL_SIG_ENABLE(slave) |
+				MACSL_RX_ENABLE_EXT_CTL |
+				MACSL_RX_ENABLE_CSF;
+		/* enable forwarding */
+		cpsw_ale_control_set(slave->ale, slave_port,
+				     ALE_PORT_STATE, ALE_PORT_STATE_FORWARD);
+
+		if (phy->duplex)
+			mac_control |= BIT(0);	/* FULLDUPLEXEN	*/
+		else
+			mac_control &= ~0x1;
+
+		*link = true;
+	} else {
+		mac_control = 0;
+		/* disable forwarding */
+		cpsw_ale_control_set(slave->ale, slave_port,
+				     ALE_PORT_STATE, ALE_PORT_STATE_DISABLE);
+	}
+
+	if (mac_control != slave->mac_control) {
+		phy_print_status(phy);
+		__raw_writel(mac_control, &slave->sliver->mac_control);
+	}
+
+	slave->mac_control = mac_control;
+}
+
+static void cpsw_adjust_link(struct net_device *n_dev, void *context)
+{
+	struct cpswx_slave *slave = (struct cpswx_slave *)context;
+	struct netcp_priv *netcp = netdev_priv(n_dev);
+	bool link = false;
+
+	_cpsw_adjust_link(slave, &link);
+
+	if (link)
+		netcp->link_state |= BIT(slave->slave_num);
+	else
+		netcp->link_state &= ~BIT(slave->slave_num);
+}
+
+/*
+ * Reset the the mac sliver
+ * Soft reset is set and polled until clear, or until a timeout occurs
+ */
+static int cpsw_port_reset(struct cpswx_slave *slave)
+{
+	u32 i, v;
+
+	/* Set the soft reset bit */
+	__raw_writel(SOFT_RESET,
+		     &slave->sliver->soft_reset);
+
+	/* Wait for the bit to clear */
+	for (i = 0; i < DEVICE_EMACSL_RESET_POLL_COUNT; i++) {
+		v = __raw_readl(&slave->sliver->soft_reset);
+		if ((v & SOFT_RESET_MASK) !=
+		    SOFT_RESET)
+			return 0;
+	}
+
+	/* Timeout on the reset */
+	return GMACSL_RET_WARN_RESET_INCOMPLETE;
+}
+
+/*
+ * Configure the mac sliver
+ */
+static void cpsw_port_config(struct cpswx_slave *slave, int max_rx_len)
+{
+	u32 mac_control;
+
+	if (max_rx_len > MAX_SIZE_STREAM_BUFFER)
+		max_rx_len = MAX_SIZE_STREAM_BUFFER;
+
+	__raw_writel(max_rx_len, &slave->sliver->rx_maxlen);
+
+	mac_control = (MACSL_SIG_ENABLE(slave) |
+			MACSL_RX_ENABLE_EXT_CTL |
+			MACSL_RX_ENABLE_CSF);
+	__raw_writel(mac_control, &slave->sliver->mac_control);
+}
+
+static void cpsw_slave_stop(struct cpswx_slave *slave, struct cpswx_priv *priv)
+{
+	cpsw_port_reset(slave);
+
+	if (!slave->phy)
+		return;
+
+	phy_stop(slave->phy);
+	phy_disconnect(slave->phy);
+	slave->phy = NULL;
+}
+
+static void cpsw_slave_link(struct cpswx_slave *slave,
+			    struct cpswx_intf *cpsw_intf)
+{
+	struct netcp_priv *netcp = netdev_priv(cpsw_intf->ndev);
+
+	if ((slave->link_interface == SGMII_LINK_MAC_PHY) ||
+		(slave->link_interface == XGMII_LINK_MAC_PHY)) {
+		if (netcp->link_state)
+			cpsw_intf->sgmii_link |= BIT(slave->slave_num);
+		else
+			cpsw_intf->sgmii_link &= ~BIT(slave->slave_num);
+	} else if (slave->link_interface == XGMII_LINK_MAC_MAC_FORCED)
+		cpsw_intf->sgmii_link |= BIT(slave->slave_num);
+}
+
+static void cpsw_slave_open(struct cpswx_slave *slave,
+			    struct cpswx_intf *cpsw_intf)
+{
+	struct cpswx_priv *priv = cpsw_intf->cpsw_priv;
+	char name[32];		/* FIXME: Unused variable */
+	u32 slave_port;
+	int has_phy = 0;
+	phy_interface_t phy_mode;
+
+	snprintf(name, sizeof(name), "slave-%d", slave->slave_num);
+
+	if (!SLAVE_LINK_IS_XGMII(slave)) {
+		keystone_sgmii_reset(priv->sgmii_port_regs, slave->slave_num);
+
+		keystone_sgmii_config(priv->sgmii_port_regs, slave->slave_num,
+				slave->link_interface);
+	} else
+		keystone_pcsr_config(priv->pcsr_port_regs, slave->slave_num,
+				slave->link_interface);
+
+	cpsw_port_reset(slave);
+
+	cpsw_port_config(slave, priv->rx_packet_max);
+
+	cpsw_set_slave_mac(slave, cpsw_intf);
+
+	slave->mac_control = MACSL_SIG_ENABLE(slave) | MACSL_RX_ENABLE_EXT_CTL |
+				MACSL_RX_ENABLE_CSF;
+
+	slave_port = cpsw_get_slave_port(priv, slave->slave_num);
+
+	slave->port_num = slave_port;
+	slave->ale = priv->ale;
+
+	/* enable forwarding */
+	cpsw_ale_control_set(priv->ale, slave_port,
+			     ALE_PORT_STATE, ALE_PORT_STATE_FORWARD);
+
+	cpsw_ale_add_mcast(priv->ale, cpsw_intf->ndev->broadcast,
+			   1 << slave_port, 0, 0, ALE_MCAST_FWD_2);
+
+	if (slave->link_interface == SGMII_LINK_MAC_PHY) {
+		has_phy = 1;
+		phy_mode = PHY_INTERFACE_MODE_SGMII;
+		slave->phy_port_t = PORT_MII;
+	} else if (slave->link_interface == XGMII_LINK_MAC_PHY) {
+		has_phy = 1;
+		/* +++FIXME: PHY_INTERFACE_MODE_XGMII ?? */
+		phy_mode = PHY_INTERFACE_MODE_NA;
+		slave->phy_port_t = PORT_FIBRE;
+	}
+
+	if (has_phy) {
+		slave->phy = of_phy_connect(cpsw_intf->ndev,
+					    cpsw_intf->phy_node,
+					    &cpsw_adjust_link, 0,
+					    phy_mode,
+					    slave);
+		if (IS_ERR_OR_NULL(slave->phy)) {
+			dev_err(priv->dev, "phy not found on slave %d\n",
+				slave->slave_num);
+			slave->phy = NULL;
+		} else {
+			dev_info(priv->dev, "phy found: id is: %s, drv: %s\n",
+				 dev_name(&slave->phy->dev),
+				 (slave->phy->drv ?
+				   (slave->phy->drv->name ?
+					slave->phy->drv->name : "") : ""));
+			cpsw_intf->ndev->phydev = slave->phy;
+			phy_start(slave->phy);
+		}
+	}
+}
+
+static int cpsw_init_ale(struct cpswx_priv *cpsw_dev,
+				struct cpswx_intf *cpsw_intf)
+{
+	struct cpsw_ale_params ale_params;
+
+	memset(&ale_params, 0, sizeof(ale_params));
+
+	ale_params.dev		= cpsw_dev->dev;
+	ale_params.ale_regs	= (void *)((u32)cpsw_dev->ale_reg);
+	ale_params.ale_ageout	= cpsw_dev->ale_ageout;
+	ale_params.ale_entries	= cpsw_dev->ale_entries;
+	ale_params.ale_ports	= cpsw_dev->ale_ports;
+
+	cpsw_dev->ale = cpsw_ale_create(&ale_params);
+	if (!cpsw_dev->ale) {
+		dev_err(cpsw_dev->dev, "error initializing ale engine\n");
+		return -ENODEV;
+	}
+
+	dev_info(cpsw_dev->dev, "Created a cpsw ale engine\n");
+	
+	cpsw_ale_start(cpsw_dev->ale);
+
+	cpsw_ale_control_set(cpsw_dev->ale, 0, ALE_BYPASS,
+			cpsw_dev->multi_if ? 1 : 0);
+
+	cpsw_ale_control_set(cpsw_dev->ale, 0, ALE_NO_PORT_VLAN, 1);
+
+	cpsw_ale_control_set(cpsw_dev->ale, cpsw_dev->host_port,
+			     ALE_PORT_STATE, ALE_PORT_STATE_FORWARD);
+
+	cpsw_ale_control_set(cpsw_dev->ale, 0,
+			     ALE_PORT_UNKNOWN_VLAN_MEMBER,
+			     CPSW_MASK_ALL_PORTS);
+
+	cpsw_ale_control_set(cpsw_dev->ale, 0,
+			     ALE_PORT_UNKNOWN_MCAST_FLOOD,
+			     CPSW_MASK_PHYS_PORTS);
+
+	cpsw_ale_control_set(cpsw_dev->ale, 0,
+			     ALE_PORT_UNKNOWN_REG_MCAST_FLOOD,
+			     CPSW_MASK_ALL_PORTS);
+
+	cpsw_ale_control_set(cpsw_dev->ale, 0,
+			     ALE_PORT_UNTAGGED_EGRESS,
+			     CPSW_MASK_ALL_PORTS);
+
+	return 0;
+}
+
+static void cpsw_init_host_port(struct cpswx_priv *priv,
+				struct cpswx_intf *cpsw_intf)
+{
+	/* Host Tx Pri */
+	__raw_writel(HOST_TX_PRI_MAP_DEFAULT,
+		     &priv->host_port_regs->tx_pri_map);
+
+	/* Max length register */
+	__raw_writel(MAX_SIZE_STREAM_BUFFER,
+		     &priv->host_port_regs->rx_maxlen);
+}
+
+static void cpsw_slave_init(struct cpswx_slave *slave, struct cpswx_priv *priv)
+{
+	void __iomem		*regs = priv->ss_regs;
+	int			slave_num = slave->slave_num;
+
+	slave->regs	= regs + priv->slave_reg_ofs + (0x30 * slave_num);
+	slave->sliver	= regs + priv->sliver_reg_ofs + (0x40 * slave_num);
+}
+
+static void cpsw_add_mcast_addr(struct cpswx_intf *cpsw_intf, u8 *addr)
+{
+	struct cpswx_priv *cpsw_dev = cpsw_intf->cpsw_priv;
+
+	cpsw_ale_add_mcast(cpsw_dev->ale, addr, CPSW_MASK_ALL_PORTS, 0, 0,
+			   ALE_MCAST_FWD_2);
+}
+
+static void cpsw_add_ucast_addr(struct cpswx_intf *cpsw_intf, u8 *addr)
+{
+	struct cpswx_priv *cpsw_dev = cpsw_intf->cpsw_priv;
+
+	cpsw_ale_add_ucast(cpsw_dev->ale, addr, cpsw_dev->host_port, 0, 0);
+}
+
+static void cpsw_del_mcast_addr(struct cpswx_intf *cpsw_intf, u8 *addr)
+{
+	struct cpswx_priv *cpsw_dev = cpsw_intf->cpsw_priv;
+
+	cpsw_ale_del_mcast(cpsw_dev->ale, addr, 0, 0, 0);
+}
+
+static void cpsw_del_ucast_addr(struct cpswx_intf *cpsw_intf, u8 *addr)
+{
+	struct cpswx_priv *cpsw_dev = cpsw_intf->cpsw_priv;
+
+	cpsw_ale_del_ucast(cpsw_dev->ale, addr, cpsw_dev->host_port, 0, 0);
+}
+
+static int cpswx_add_addr(void *intf_priv, struct netcp_addr *naddr)
+{
+	struct cpswx_intf *cpsw_intf = intf_priv;
+	struct cpswx_priv *cpsw_dev = cpsw_intf->cpsw_priv;
+
+	dev_dbg(cpsw_dev->dev, "xgess adding address %pM, type %d\n",
+		naddr->addr, naddr->type);
+
+	switch (naddr->type) {
+	case ADDR_MCAST:
+	case ADDR_BCAST:
+		cpsw_add_mcast_addr(cpsw_intf, naddr->addr);
+		break;
+	case ADDR_UCAST:
+	case ADDR_DEV:
+		cpsw_add_ucast_addr(cpsw_intf, naddr->addr);
+		break;
+	case ADDR_ANY:
+		/* nothing to do for promiscuous */
+	default:
+		break;
+	}
+
+	return 0;
+}
+
+static int cpswx_del_addr(void *intf_priv, struct netcp_addr *naddr)
+{
+	struct cpswx_intf *cpsw_intf = intf_priv;
+	struct cpswx_priv *cpsw_dev = cpsw_intf->cpsw_priv;
+
+	dev_dbg(cpsw_dev->dev, "xgess deleting address %pM, type %d\n",
+		naddr->addr, naddr->type);
+
+	switch (naddr->type) {
+	case ADDR_MCAST:
+	case ADDR_BCAST:
+		cpsw_del_mcast_addr(cpsw_intf, naddr->addr);
+		break;
+	case ADDR_UCAST:
+	case ADDR_DEV:
+		cpsw_del_ucast_addr(cpsw_intf, naddr->addr);
+		break;
+	case ADDR_ANY:
+		/* nothing to do for promiscuous */
+	default:
+		break;
+	}
+
+	return 0;
+}
+
+static int cpswx_ioctl(void *intf_priv, struct ifreq *req, int cmd)
+{
+	struct cpswx_intf *cpsw_intf = intf_priv;
+	struct cpswx_slave *slave = cpsw_intf->slaves;
+	struct phy_device *phy = slave->phy;
+	int ret;
+
+	if (!phy)
+		return -EOPNOTSUPP;
+
+	ret = phy_mii_ioctl(phy, req, cmd);
+	if ((cmd == SIOCSHWTSTAMP) && (ret == -ERANGE))
+		ret = -EOPNOTSUPP;
+
+	return ret;
+}
+
+static void cpswx_timer(unsigned long arg)
+{
+	struct cpswx_intf *cpsw_intf = (struct cpswx_intf *)arg;
+	struct cpswx_priv *cpsw_dev = cpsw_intf->cpsw_priv;
+
+	/*
+	 * if the slave's link_interface is not XGMII, sgmii_link bit
+	 * will not be set
+	 */
+	if (cpsw_dev->multi_if)
+		cpsw_intf->sgmii_link =
+			keystone_sgmii_get_port_link(cpsw_dev->sgmii_port_regs,
+						     cpsw_intf->slave_port);
+	else
+		cpsw_intf->sgmii_link =
+			keystone_sgmii_link_status(cpsw_dev->sgmii_port_regs,
+						   cpsw_intf->num_slaves);
+
+	for_each_slave(cpsw_intf, cpsw_slave_link, cpsw_intf);
+
+	/* FIXME: Don't aggregate link statuses in multi-interface case */
+	if (cpsw_intf->sgmii_link) {
+		/* link ON */
+		if (!netif_carrier_ok(cpsw_intf->ndev))
+			netif_carrier_on(cpsw_intf->ndev);
+	} else {
+		/* link OFF */
+		if (netif_carrier_ok(cpsw_intf->ndev))
+			netif_carrier_off(cpsw_intf->ndev);
+	}
+
+	spin_lock_bh(&cpsw_dev->hw_stats_lock);
+	cpswx_update_stats(cpsw_dev, NULL);
+	spin_unlock_bh(&cpsw_dev->hw_stats_lock);
+
+	cpsw_intf->timer.expires = jiffies + (HZ/10);
+	add_timer(&cpsw_intf->timer);
+
+	return;
+}
+
+static int cpsw_tx_hook(int order, void *data, struct netcp_packet *p_info)
+{
+	struct cpswx_intf *cpsw_intf = data;
+
+	p_info->tx_pipe = &cpsw_intf->tx_pipe;
+	return 0;
+}
+
+#define	CPSW_TXHOOK_ORDER	0
+
+static int cpswx_open(void *intf_mod_priv, struct net_device *ndev)
+{
+	struct cpswx_intf *cpsw_intf = intf_mod_priv;
+	struct cpswx_priv *cpsw_dev = cpsw_intf->cpsw_priv;
+	struct netcp_priv *netcp = netdev_priv(ndev);
+	u32 xgmii_mode = 0;
+	int ret = 0;
+	u32 reg, i;
+
+	cpsw_dev->clk = clk_get(cpsw_dev->dev, "clk_xge");
+	if (IS_ERR(cpsw_dev->clk)) {
+		ret = PTR_ERR(cpsw_dev->clk);
+		cpsw_dev->clk = NULL;
+		dev_err(cpsw_dev->dev,
+			"unable to get Keystone XGE clock: %d\n", ret);
+		return ret;
+	}
+
+	ret = clk_prepare_enable(cpsw_dev->clk);
+	if (ret)
+		goto clk_fail;
+
+	reg = __raw_readl(&cpsw_dev->regs->id_ver);
+
+	dev_info(cpsw_dev->dev,
+	 "initialize cpsw version %d.%d (%d) CPSW identification value 0x%x\n",
+	 CPSW_MAJOR_VERSION(reg), CPSW_MINOR_VERSION(reg),
+	 CPSW_RTL_VERSION(reg), CPSW_IDENT(reg));
+
+	ret = netcp_txpipe_open(&cpsw_intf->tx_pipe);
+	if (ret)
+		goto txpipe_fail;
+
+	dev_dbg(cpsw_dev->dev, "opened TX channel %s: %p with psflags %d\n",
+		cpsw_intf->tx_pipe.dma_chan_name,
+		cpsw_intf->tx_pipe.dma_channel,
+		cpsw_intf->tx_pipe.dma_psflags);
+
+	/* initialize host and slave ports */
+	if (atomic_inc_return(&cpsw_dev->ale_refcnt) == 1) {
+		ret = cpsw_init_ale(cpsw_dev, cpsw_intf);
+		if (ret < 0) {
+			atomic_dec(&cpsw_dev->ale_refcnt);
+			goto ale_fail;
+		}
+		cpsw_init_host_port(cpsw_dev, cpsw_intf);
+	}
+
+	for_each_slave(cpsw_intf, cpsw_slave_init, cpsw_dev);
+
+	for_each_slave(cpsw_intf, cpsw_slave_stop, cpsw_dev);
+
+	/* Enable correct MII mode at SS level */
+	for (i = 0; i < cpsw_dev->num_slaves; i++)
+		if (cpsw_dev->link[i] >= XGMII_LINK_MAC_PHY)
+			xgmii_mode |= (1 << i);
+	__raw_writel(xgmii_mode, &cpsw_dev->ss_regs->control);
+
+	/* disable priority elevation and enable statistics on all ports */
+	__raw_writel(0, &cpsw_dev->regs->ptype);
+
+	/* Control register */
+	__raw_writel(CPSW_CTL_P0_ENABLE, &cpsw_dev->regs->control);
+
+	/* All statistics enabled by default */
+	__raw_writel(CPSW_REG_VAL_STAT_ENABLE_ALL,
+		     &cpsw_dev->regs->stat_port_en);
+
+	for_each_slave(cpsw_intf, cpsw_slave_open, cpsw_intf);
+
+	init_timer(&cpsw_intf->timer);
+	cpsw_intf->timer.data		= (unsigned long)cpsw_intf;
+	cpsw_intf->timer.function	= cpswx_timer;
+	cpsw_intf->timer.expires	= jiffies + CPSW_TIMER_INTERVAL;
+	add_timer(&cpsw_intf->timer);
+	dev_dbg(cpsw_dev->dev,
+		"%s(): cpswx_timer = %p\n", __func__, cpswx_timer);
+
+	netcp_register_txhook(netcp, CPSW_TXHOOK_ORDER,
+			      cpsw_tx_hook, cpsw_intf);
+
+#if 0
+	/* Configure the streaming switch */
+#define	PSTREAM_ROUTE_DMA	6
+	netcp_set_streaming_switch(cpsw_dev->netcp_device, netcp->cpsw_port,
+				   PSTREAM_ROUTE_DMA);
+#endif
+
+	return 0;
+
+ale_fail:
+	netcp_txpipe_close(&cpsw_intf->tx_pipe);
+txpipe_fail:
+	clk_disable_unprepare(cpsw_dev->clk);
+clk_fail:
+	clk_put(cpsw_dev->clk);
+	cpsw_dev->clk = NULL;
+	return ret;
+}
+
+static int cpswx_close(void *intf_modpriv, struct net_device *ndev)
+{
+	struct cpswx_intf *cpsw_intf = intf_modpriv;
+	struct cpswx_priv *cpsw_dev = cpsw_intf->cpsw_priv;
+	struct netcp_priv *netcp = netdev_priv(ndev);
+
+	del_timer_sync(&cpsw_intf->timer);
+
+	for_each_slave(cpsw_intf, cpsw_slave_stop, cpsw_dev);
+
+	if (atomic_dec_return(&cpsw_dev->ale_refcnt) == 0) {
+		cpsw_ale_destroy(cpsw_dev->ale);
+		cpsw_dev->ale = NULL;
+	}
+
+	netcp_unregister_txhook(netcp, CPSW_TXHOOK_ORDER, cpsw_tx_hook,
+				cpsw_intf);
+	netcp_txpipe_close(&cpsw_intf->tx_pipe);
+
+	clk_disable_unprepare(cpsw_dev->clk);
+	clk_put(cpsw_dev->clk);
+
+	return 0;
+}
+
+static int cpswx_remove(struct netcp_device *netcp_device, void *inst_priv)
+{
+	struct cpswx_priv *cpsw_dev = inst_priv;
+	struct cpswx_intf *cpsw_intf, *tmp;
+
+	of_node_put(cpsw_dev->interfaces);
+
+	list_for_each_entry_safe(cpsw_intf, tmp, &cpsw_dev->cpsw_intf_head,
+				 cpsw_intf_list) {
+		netcp_delete_interface(netcp_device, cpsw_intf->ndev);
+	}
+	BUG_ON(!list_empty(&cpsw_dev->cpsw_intf_head));
+
+	iounmap(cpsw_dev->ss_regs);
+	memset(cpsw_dev, 0x00, sizeof(*cpsw_dev));	/* FIXME: Poison */
+	kfree(cpsw_dev);
+	return 0;
+}
+
+static int init_slave(struct cpswx_priv *cpsw_dev,
+		      struct device_node *node, int slave_num)
+{
+	int ret = 0;
+
+	ret = of_property_read_u32(node, "link-interface",
+				   &cpsw_dev->link[slave_num]);
+	if (ret < 0) {
+		dev_err(cpsw_dev->dev,
+			"missing link-interface value"
+			"defaulting to mac-phy link\n");
+		cpsw_dev->link[slave_num] = XGMII_LINK_MAC_PHY;
+	}
+
+	if (cpsw_dev->link[slave_num] == XGMII_LINK_MAC_PHY)
+		cpsw_dev->phy_node[slave_num] =
+			of_parse_phandle(node, "phy-handle", 0);
+
+	return 0;
+}
+
+static int cpsw_create_sysfs_entries(struct cpswx_priv *cpsw_dev)
+{
+	struct device *dev = cpsw_dev->dev;
+	int ret;
+
+	ret = kobject_init_and_add(&cpsw_dev->kobj, &cpsw_ktype,
+		kobject_get(&dev->kobj), "cpsw");
+
+	if (ret) {
+		dev_err(dev, "failed to create cpsw sysfs entry\n");
+		kobject_put(&cpsw_dev->kobj);
+		kobject_put(&dev->kobj);
+		return ret;
+	}
+
+	ret = kobject_init_and_add(&cpsw_dev->tx_pri_kobj,
+		&cpsw_tx_pri_ktype,
+		kobject_get(&cpsw_dev->kobj), "port_tx_pri_map");
+
+	if (ret) {
+		dev_err(dev, "failed to create sysfs port_tx_pri_map entry\n");
+		kobject_put(&cpsw_dev->tx_pri_kobj);
+		kobject_put(&cpsw_dev->kobj);
+		return ret;
+	}
+
+	ret = kobject_init_and_add(&cpsw_dev->pvlan_kobj,
+		&cpsw_pvlan_ktype,
+		kobject_get(&cpsw_dev->kobj), "port_vlan");
+
+	if (ret) {
+		dev_err(dev, "failed to create sysfs port_vlan entry\n");
+		kobject_put(&cpsw_dev->pvlan_kobj);
+		kobject_put(&cpsw_dev->kobj);
+		return ret;
+	}
+
+	ret = kobject_init_and_add(&cpsw_dev->stats_kobj,
+		&cpsw_stats_ktype,
+		kobject_get(&cpsw_dev->kobj), "stats");
+
+	if (ret) {
+		dev_err(dev, "failed to create sysfs stats entry\n");
+		kobject_put(&cpsw_dev->stats_kobj);
+		kobject_put(&cpsw_dev->kobj);
+		return ret;
+	}
+
+	return 0;
+}
+
+
+static int cpswx_probe(struct netcp_device *netcp_device,
+			struct device *dev,
+			struct device_node *node,
+			void **inst_priv)
+{
+	struct cpswx_priv *cpsw_dev;
+	struct device_node *slaves, *slave, *interfaces;
+	void __iomem *regs = NULL;
+	struct net_device *ndev;
+	int slave_num = 0;
+	int i, ret = 0;
+	u32 temp[4];
+
+	cpsw_dev = devm_kzalloc(dev, sizeof(struct cpswx_priv), GFP_KERNEL);
+	if (!cpsw_dev) {
+		dev_err(dev, "cpsw_dev memory allocation failed\n");
+		return -ENOMEM;
+	}
+	*inst_priv = cpsw_dev;
+	dev_dbg(dev, "%s(): cpsw_priv = %p\n", __func__, cpsw_dev);
+
+	if (!node) {
+		dev_err(dev, "device tree info unavailable\n");
+		ret = -ENODEV;
+		goto exit;
+	}
+
+	cpsw_dev->dev = dev;
+	cpsw_dev->netcp_device = netcp_device;
+
+	ret = of_property_read_u32(node, "serdes_at_probe",
+				   &cpsw_dev->init_serdes_at_probe);
+	if (ret < 0) {
+		dev_err(dev,
+			"missing serdes_at_probe parameter, err %d\n", ret);
+		cpsw_dev->init_serdes_at_probe = 0;
+	}
+	dev_dbg(dev, "serdes_at_probe %u\n", cpsw_dev->init_serdes_at_probe);
+
+	ret = of_property_read_u32(node, "sgmii_module_ofs",
+				   &cpsw_dev->sgmii_module_ofs);
+	if (ret < 0)
+		dev_err(dev, "missing sgmii module offset, err %d\n", ret);
+
+	ret = of_property_read_u32(node, "pcsr_module_ofs",
+				   &cpsw_dev->pcsr_module_ofs);
+	if (ret < 0)
+		dev_err(dev, "missing pcsr module offset, err %d\n", ret);
+
+	ret = of_property_read_u32(node, "switch_module_ofs",
+				   &cpsw_dev->switch_module_ofs);
+	if (ret < 0)
+		dev_err(dev, "missing switch module offset, err %d\n", ret);
+
+	ret = of_property_read_u32(node, "host_port_reg_ofs",
+				   &cpsw_dev->host_port_reg_ofs);
+	if (ret < 0)
+		dev_err(dev, "missing host port reg offset, err %d\n", ret);
+
+	ret = of_property_read_u32(node, "slave_reg_ofs",
+				   &cpsw_dev->slave_reg_ofs);
+	if (ret < 0)
+		dev_err(dev, "missing slave reg offset, err %d\n", ret);
+
+	ret = of_property_read_u32(node, "sliver_reg_ofs",
+				   &cpsw_dev->sliver_reg_ofs);
+	if (ret < 0)
+		dev_err(dev, "missing sliver reg offset, err %d\n", ret);
+
+	ret = of_property_read_u32(node, "hw_stats_reg_ofs",
+				   &cpsw_dev->hw_stats_reg_ofs);
+	if (ret < 0)
+		dev_err(dev, "missing hw stats reg offset, err %d\n", ret);
+
+	ret = of_property_read_u32(node, "ale_reg_ofs",
+				   &cpsw_dev->ale_reg_ofs);
+	if (ret < 0)
+		dev_err(dev, "missing ale reg offset, err %d\n", ret);
+
+
+	ret = of_property_read_u32(node, "num_slaves", &cpsw_dev->num_slaves);
+	if (ret < 0) {
+		dev_err(dev, "missing num_slaves parameter, err %d\n", ret);
+		cpsw_dev->num_slaves = 2;
+	}
+
+	ret = of_property_read_u32(node, "ale_ageout", &cpsw_dev->ale_ageout);
+	if (ret < 0) {
+		dev_err(dev, "missing ale_ageout parameter, err %d\n", ret);
+		cpsw_dev->ale_ageout = 10;
+	}
+
+	ret = of_property_read_u32(node, "ale_entries", &cpsw_dev->ale_entries);
+	if (ret < 0) {
+		dev_err(dev, "missing ale_entries parameter, err %d\n", ret);
+		cpsw_dev->ale_entries = 1024;
+	}
+
+	ret = of_property_read_u32(node, "ale_ports", &cpsw_dev->ale_ports);
+	if (ret < 0) {
+		dev_err(dev, "missing ale_ports parameter, err %d\n", ret);
+		cpsw_dev->ale_ports = 2;
+	}
+
+	ret = of_property_read_u32(node,
+				   "intf_tx_queues", &cpsw_dev->intf_tx_queues);
+	if (ret < 0) {
+		dev_err(dev, "missing intf_tx_queues parameter, err %d\n", ret);
+		cpsw_dev->intf_tx_queues = 1;
+	}
+
+	if (of_find_property(node, "multi-interface", NULL))
+		cpsw_dev->multi_if = 1;
+
+	ret = of_property_read_u32(node, "num-interfaces",
+				   &cpsw_dev->num_interfaces);
+	if (ret < 0) {
+		dev_err(dev, "missing num-interfaces parameter\n");
+		cpsw_dev->num_interfaces = 1;
+	}
+
+	ret = of_property_read_u32(node, "slaves-per-interface",
+				   &cpsw_dev->slaves_per_interface);
+	if (ret < 0) {
+		dev_err(dev, "missing slaves-per_interface parameter\n");
+		cpsw_dev->slaves_per_interface = 2;
+	}
+
+	/* Sub-sys regs base */
+	if (of_property_read_u32_array(node, "reg", (u32 *)&(temp[0]), 2))
+		dev_err(dev, "No reg defined\n");
+	else
+		regs = ioremap(temp[0], temp[1]);
+	BUG_ON(!regs);
+
+	cpsw_dev->ss_regs = regs;
+	cpsw_dev->sgmii_port_regs	= regs + cpsw_dev->sgmii_module_ofs;
+	cpsw_dev->pcsr_port_regs	= regs + cpsw_dev->pcsr_module_ofs;
+	cpsw_dev->regs			= regs + cpsw_dev->switch_module_ofs;
+	cpsw_dev->host_port_regs	= regs + cpsw_dev->host_port_reg_ofs;
+	cpsw_dev->host_hw_stats_regs	= regs + cpsw_dev->hw_stats_reg_ofs;
+	cpsw_dev->hw_stats_regs[0] = regs + cpsw_dev->hw_stats_reg_ofs + 0x100;
+	cpsw_dev->hw_stats_regs[1] = regs + cpsw_dev->hw_stats_reg_ofs + 0x200;
+	cpsw_dev->ale_reg		= regs + cpsw_dev->ale_reg_ofs;
+
+	ret = of_property_read_u32(node, "host_port", &cpsw_dev->host_port);
+	if (ret < 0) {
+		dev_err(dev, "missing host_port parameter\n");
+		cpsw_dev->host_port = 0;
+	}
+	cpsw_dev->rx_packet_max = NETCP_MAX_FRAME_SIZE;
+
+	dev_dbg(dev, "num_slaves = %d\n", cpsw_dev->num_slaves);
+	dev_dbg(dev, "ale_ageout = %d\n", cpsw_dev->ale_ageout);
+	dev_dbg(dev, "ale_entries = %d\n", cpsw_dev->ale_entries);
+	dev_dbg(dev, "ale_ports = %d\n", cpsw_dev->ale_ports);
+
+	slaves = of_get_child_by_name(node, "slaves");
+	if (!slaves) {
+		dev_err(dev, "could not find slaves\n");
+		ret = -ENODEV;
+		goto exit;
+	}
+
+	for_each_child_of_node(slaves, slave) {
+		init_slave(cpsw_dev, slave, slave_num);
+		slave_num++;
+	}
+
+	of_node_put(slaves);
+
+	interfaces = of_get_child_by_name(node, "interfaces");
+	if (!interfaces)
+		dev_err(dev, "could not find interfaces\n");
+
+	cpsw_dev->interfaces = interfaces;
+
+	cpsw_dev->serdes = of_get_child_by_name(node, "serdes");
+
+	if (cpsw_dev->init_serdes_at_probe == 1) {
+		cpsw_dev->clk = clk_get(cpsw_dev->dev, "clk_xge");
+		if (IS_ERR(cpsw_dev->clk)) {
+			ret = PTR_ERR(cpsw_dev->clk);
+			cpsw_dev->clk = NULL;
+			dev_err(cpsw_dev->dev,
+				"unable to get Keystone XGE clock: %d\n", ret);
+			return ret;
+		}
+
+		ret = clk_prepare_enable(cpsw_dev->clk);
+		if (ret)
+			goto exit;
+
+		/* needs the serdes pll to acces switch regs */
+		ret = xge_serdes_init(cpsw_dev->serdes);
+		if (ret)
+			goto exit;
+	}
+
+	/* Create the interface */
+	INIT_LIST_HEAD(&cpsw_dev->cpsw_intf_head);
+	if (cpsw_dev->multi_if)
+		for (i = 0; i < cpsw_dev->num_interfaces; i++)
+			netcp_create_interface(netcp_device, &ndev,
+					       NULL, cpsw_dev->intf_tx_queues,
+					       1, (i + 1));
+	else
+		netcp_create_interface(netcp_device, &ndev,
+					       NULL, cpsw_dev->intf_tx_queues,
+					       1, 0);
+
+	/* init the hw stats lock */
+	spin_lock_init(&cpsw_dev->hw_stats_lock);
+
+	ret = cpsw_create_sysfs_entries(cpsw_dev);
+	if (ret)
+		goto exit;
+
+	return 0;
+
+exit:
+	if (cpsw_dev->ss_regs)
+		iounmap(cpsw_dev->ss_regs);
+	*inst_priv = NULL;
+	kfree(cpsw_dev);
+	return ret;
+}
+
+static int cpswx_attach_serdes(struct cpswx_slave *slave,
+			       struct cpswx_intf *cpsw_intf)
+{
+	struct cpswx_priv *cpsw_dev = cpsw_intf->cpsw_priv;
+	phy_interface_t phy_mode;
+	int has_phy = 0;
+	int ret;
+
+	if (slave->link_interface == SGMII_LINK_MAC_PHY) {
+		has_phy = 1;
+		phy_mode = PHY_INTERFACE_MODE_SGMII;
+		slave->phy_port_t = PORT_MII;
+	} else if (slave->link_interface == XGMII_LINK_MAC_PHY) {
+		has_phy = 1;
+		/* +++FIXME: PHY_INTERFACE_MODE_XGMII ?? */
+		phy_mode = PHY_INTERFACE_MODE_NA;
+		slave->phy_port_t = PORT_FIBRE;
+	}
+
+	if (has_phy) {
+		/* init the PHY to facilitate serdes link training */
+		slave->phy = of_phy_connect(cpsw_intf->ndev,
+					    cpsw_intf->phy_node,
+					    &cpsw_adjust_link, 0,
+					    phy_mode,
+					    slave);
+	}
+
+	ret = xge_serdes_init(cpsw_dev->serdes);
+	return ret;
+}
+
+static int cpswx_attach(void *inst_priv, struct net_device *ndev,
+		       void **intf_priv)
+{
+	struct cpswx_priv *cpsw_dev = inst_priv;
+	struct cpswx_intf *cpsw_intf;
+	struct netcp_priv *netcp = netdev_priv(ndev);
+	struct device_node *interface;
+	int i = 0, ret = 0;
+	char node_name[24];
+
+	cpsw_intf = devm_kzalloc(cpsw_dev->dev,
+				 sizeof(struct cpswx_intf), GFP_KERNEL);
+	if (!cpsw_intf) {
+		dev_err(cpsw_dev->dev,
+			"cpswx interface memory allocation failed\n");
+		return -ENOMEM;
+	}
+	cpsw_intf->ndev = ndev;
+	cpsw_intf->dev = cpsw_dev->dev;
+	cpsw_intf->cpsw_priv = cpsw_dev;
+	cpsw_intf->multi_if = cpsw_dev->multi_if;
+
+	if (cpsw_dev->multi_if)
+		snprintf(node_name, sizeof(node_name), "interface-%d",
+			 netcp->cpsw_port - 1);
+	else
+		snprintf(node_name, sizeof(node_name), "interface-%d",
+			 0);
+
+	interface = of_get_child_by_name(cpsw_dev->interfaces, node_name);
+	if (!interface) {
+		dev_err(cpsw_dev->dev, "interface data not available\n");
+		devm_kfree(cpsw_dev->dev, cpsw_intf);
+		return -ENODEV;
+	}
+	ret = of_property_read_u32(interface, "slave_port",
+				   &cpsw_intf->slave_port);
+	if (ret < 0) {
+		dev_err(cpsw_dev->dev, "missing slave_port paramater\n");
+		return -EINVAL;
+	}
+
+	ret = of_property_read_string(interface, "tx-channel",
+				      &cpsw_intf->tx_chan_name);
+	if (ret < 0) {
+		dev_err(cpsw_dev->dev,
+			"missing tx-channel parameter, err %d\n", ret);
+		cpsw_intf->tx_chan_name = "nettx";
+	}
+	dev_info(cpsw_dev->dev, "dma_chan_name %s\n", cpsw_intf->tx_chan_name);
+
+	ret = of_property_read_u32(interface, "tx_queue_depth",
+				   &cpsw_intf->tx_queue_depth);
+	if (ret < 0) {
+		dev_err(cpsw_dev->dev,
+			"missing tx_queue_depth parameter, err %d\n", ret);
+		cpsw_intf->tx_queue_depth = 32;
+	}
+	dev_dbg(cpsw_dev->dev, "tx_queue_depth %u\n",
+		cpsw_intf->tx_queue_depth);
+
+	of_node_put(interface);
+
+	cpsw_intf->num_slaves = cpsw_dev->slaves_per_interface;
+
+	cpsw_intf->slaves = devm_kzalloc(cpsw_dev->dev,
+					 sizeof(struct cpswx_slave) *
+					 cpsw_intf->num_slaves, GFP_KERNEL);
+
+	if (!cpsw_intf->slaves) {
+		dev_err(cpsw_dev->dev,
+			"cpsw interface slave memory allocation failed\n");
+		devm_kfree(cpsw_dev->dev, cpsw_intf);
+		return -ENOMEM;
+	}
+
+	if (cpsw_dev->multi_if) {
+		cpsw_intf->slaves[i].slave_num = cpsw_intf->slave_port;
+		cpsw_intf->slaves[i].link_interface =
+			cpsw_dev->link[cpsw_intf->slave_port];
+		cpsw_intf->phy_node = cpsw_dev->phy_node[cpsw_intf->slave_port];
+	} else {
+		for (i = 0; i < cpsw_intf->num_slaves; i++) {
+			cpsw_intf->slaves[i].slave_num = i;
+			cpsw_intf->slaves[i].link_interface = cpsw_dev->link[i];
+		}
+	}
+
+	netcp_txpipe_init(&cpsw_intf->tx_pipe, netdev_priv(ndev),
+			  cpsw_intf->tx_chan_name, cpsw_intf->tx_queue_depth);
+
+	cpsw_intf->tx_pipe.dma_psflags	= netcp->cpsw_port;
+
+	SET_ETHTOOL_OPS(ndev, &keystone_ethtool_ops);
+
+	list_add(&cpsw_intf->cpsw_intf_list, &cpsw_dev->cpsw_intf_head);
+
+	*intf_priv = cpsw_intf;
+
+	for_each_slave(cpsw_intf, cpswx_attach_serdes, cpsw_intf);
+	return ret;
+}
+
+static int cpswx_release(void *intf_modpriv)
+{
+	struct cpswx_intf *cpsw_intf = intf_modpriv;
+
+	SET_ETHTOOL_OPS(cpsw_intf->ndev, NULL);
+
+	list_del(&cpsw_intf->cpsw_intf_list);
+
+	devm_kfree(cpsw_intf->dev, cpsw_intf->slaves);
+	devm_kfree(cpsw_intf->dev, cpsw_intf);
+
+	return 0;
+}
+
+
+static struct netcp_module cpsw_module = {
+	.name		= CPSW_MODULE_NAME,
+	.owner		= THIS_MODULE,
+	.probe		= cpswx_probe,
+	.open		= cpswx_open,
+	.close		= cpswx_close,
+	.remove		= cpswx_remove,
+	.attach		= cpswx_attach,
+	.release	= cpswx_release,
+	.add_addr	= cpswx_add_addr,
+	.del_addr	= cpswx_del_addr,
+	.ioctl		= cpswx_ioctl,
+};
+
+int __init keystone_cpswx_init(void)
+{
+	return netcp_register_module(&cpsw_module);
+}
+
+void __exit keystone_cpswx_exit(void)
+{
+	netcp_unregister_module(&cpsw_module);
+}
+
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("Sandeep Paulraj <s-paulraj@ti.com>");
+MODULE_DESCRIPTION("CPSW driver for Keystone 10GE devices");
-- 
1.7.5.4

