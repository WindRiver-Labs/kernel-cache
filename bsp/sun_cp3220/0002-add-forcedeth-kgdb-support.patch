From 28d4be0303f4a54e9ac4cad47fbcd22e92965a0b Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Mon, 1 Sep 2008 16:40:44 +0800
Subject: [PATCH] add forcedeth kgdb support

This change forcedeth.c to adapt kgdboe, including:

I. wrap dev_kfree_skb_any, to make it not lock the runqueue's lock
II. add support for CONFIG_NET_POLL_CONTROLLER, which is used for kgdboe.

Signed-off-by: Jack Tan <jack.tan@windriver.com>
Signed-off-by: Fei Wu <fei.wu@windriver.com>
---
 drivers/net/forcedeth.c |   52 +++++++++++++++++++++++++++++++++-------------
 1 files changed, 37 insertions(+), 15 deletions(-)

diff --git a/drivers/net/forcedeth.c b/drivers/net/forcedeth.c
index 053971e..184ea8e 100644
--- a/drivers/net/forcedeth.c
+++ b/drivers/net/forcedeth.c
@@ -70,6 +70,20 @@
 #define dprintk(x...)		do { } while (0)
 #endif
 
+#ifdef CONFIG_KGDBOE
+#include <linux/kgdb.h>
+#define _kgdb_dev_kfree_skb_any(skb)		\
+do {						\
+	if (atomic_read(&kgdb_active))	        \
+		dev_kfree_skb(skb);		\
+	else					\
+		dev_kfree_skb_any(skb);		\
+} while (0)
+
+#else
+#define _kgdb_dev_kfree_skb_any(skb) dev_kfree_skb_any(skb)
+#endif
+
 #define TX_WORK_PER_LOOP  64
 #define RX_WORK_PER_LOOP  64
 
@@ -1886,7 +1900,7 @@ static int nv_release_txskb(struct net_device *dev, struct nv_skb_map* tx_skb)
 		tx_skb->dma = 0;
 	}
 	if (tx_skb->skb) {
-		dev_kfree_skb_any(tx_skb->skb);
+		_kgdb_dev_kfree_skb_any(tx_skb->skb);
 		tx_skb->skb = NULL;
 		return 1;
 	} else {
@@ -2394,7 +2408,7 @@ static void nv_tx_done(struct net_device *dev)
 					dev->stats.tx_packets++;
 					dev->stats.tx_bytes += np->get_tx_ctx->skb->len;
 				}
-				dev_kfree_skb_any(np->get_tx_ctx->skb);
+				_kgdb_dev_kfree_skb_any(np->get_tx_ctx->skb);
 				np->get_tx_ctx->skb = NULL;
 			}
 		} else {
@@ -2411,7 +2425,7 @@ static void nv_tx_done(struct net_device *dev)
 					dev->stats.tx_packets++;
 					dev->stats.tx_bytes += np->get_tx_ctx->skb->len;
 				}
-				dev_kfree_skb_any(np->get_tx_ctx->skb);
+				_kgdb_dev_kfree_skb_any(np->get_tx_ctx->skb);
 				np->get_tx_ctx->skb = NULL;
 			}
 		}
@@ -2456,7 +2470,7 @@ static void nv_tx_done_optimized(struct net_device *dev, int limit)
 				}
 			}
 
-			dev_kfree_skb_any(np->get_tx_ctx->skb);
+			_kgdb_dev_kfree_skb_any(np->get_tx_ctx->skb);
 			np->get_tx_ctx->skb = NULL;
 
 			if (np->tx_limit) {
@@ -3984,6 +3998,10 @@ static int nv_request_irq(struct net_device *dev, int intr_test)
 
 	}
 
+#ifdef CONFIG_NET_POLL_CONTROLLER
+       dev->irq = np->pci_dev->irq;
+#endif
+
 	return 0;
 out_free_tx:
 	free_irq(np->msi_x_entry[NV_MSI_X_VECTOR_TX].vector, dev);
@@ -4011,6 +4029,10 @@ static void nv_free_irq(struct net_device *dev)
 			np->msi_flags &= ~NV_MSI_ENABLED;
 		}
 	}
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+       dev->irq = 0;
+#endif
 }
 
 static void nv_do_nic_poll(unsigned long data)
@@ -4028,21 +4050,21 @@ static void nv_do_nic_poll(unsigned long data)
 
 	if (!using_multi_irqs(dev)) {
 		if (np->msi_flags & NV_MSI_X_ENABLED)
-			disable_irq_lockdep(np->msi_x_entry[NV_MSI_X_VECTOR_ALL].vector);
+			disable_irq(np->msi_x_entry[NV_MSI_X_VECTOR_ALL].vector);
 		else
-			disable_irq_lockdep(np->pci_dev->irq);
+			disable_irq(np->pci_dev->irq);
 		mask = np->irqmask;
 	} else {
 		if (np->nic_poll_irq & NVREG_IRQ_RX_ALL) {
-			disable_irq_lockdep(np->msi_x_entry[NV_MSI_X_VECTOR_RX].vector);
+			disable_irq(np->msi_x_entry[NV_MSI_X_VECTOR_RX].vector);
 			mask |= NVREG_IRQ_RX_ALL;
 		}
 		if (np->nic_poll_irq & NVREG_IRQ_TX_ALL) {
-			disable_irq_lockdep(np->msi_x_entry[NV_MSI_X_VECTOR_TX].vector);
+			disable_irq(np->msi_x_entry[NV_MSI_X_VECTOR_TX].vector);
 			mask |= NVREG_IRQ_TX_ALL;
 		}
 		if (np->nic_poll_irq & NVREG_IRQ_OTHER) {
-			disable_irq_lockdep(np->msi_x_entry[NV_MSI_X_VECTOR_OTHER].vector);
+			disable_irq(np->msi_x_entry[NV_MSI_X_VECTOR_OTHER].vector);
 			mask |= NVREG_IRQ_OTHER;
 		}
 	}
@@ -4095,21 +4117,21 @@ static void nv_do_nic_poll(unsigned long data)
 		else
 			nv_nic_irq(0, dev);
 		if (np->msi_flags & NV_MSI_X_ENABLED)
-			enable_irq_lockdep(np->msi_x_entry[NV_MSI_X_VECTOR_ALL].vector);
+			enable_irq(np->msi_x_entry[NV_MSI_X_VECTOR_ALL].vector);
 		else
-			enable_irq_lockdep(np->pci_dev->irq);
+			enable_irq(np->pci_dev->irq);
 	} else {
 		if (np->nic_poll_irq & NVREG_IRQ_RX_ALL) {
 			nv_nic_irq_rx(0, dev);
-			enable_irq_lockdep(np->msi_x_entry[NV_MSI_X_VECTOR_RX].vector);
+			enable_irq(np->msi_x_entry[NV_MSI_X_VECTOR_RX].vector);
 		}
 		if (np->nic_poll_irq & NVREG_IRQ_TX_ALL) {
 			nv_nic_irq_tx(0, dev);
-			enable_irq_lockdep(np->msi_x_entry[NV_MSI_X_VECTOR_TX].vector);
+			enable_irq(np->msi_x_entry[NV_MSI_X_VECTOR_TX].vector);
 		}
 		if (np->nic_poll_irq & NVREG_IRQ_OTHER) {
 			nv_nic_irq_other(0, dev);
-			enable_irq_lockdep(np->msi_x_entry[NV_MSI_X_VECTOR_OTHER].vector);
+			enable_irq(np->msi_x_entry[NV_MSI_X_VECTOR_OTHER].vector);
 		}
 	}
 }
@@ -5006,7 +5028,7 @@ static int nv_loopback_test(struct net_device *dev)
 	pci_unmap_page(np->pci_dev, test_dma_addr,
 		       (skb_end_pointer(tx_skb) - tx_skb->data),
 		       PCI_DMA_TODEVICE);
-	dev_kfree_skb_any(tx_skb);
+	_kgdb_dev_kfree_skb_any(tx_skb);
  out:
 	/* stop engines */
 	nv_stop_rxtx(dev);
-- 
1.5.5.4

