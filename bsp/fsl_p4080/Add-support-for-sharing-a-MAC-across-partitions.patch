From 2f8201116b7d306397d8ae4b5e0a82d81686056f Mon Sep 17 00:00:00 2001
From: Andy Fleming <afleming@freescale.com>
Date: Wed, 7 Oct 2009 03:32:01 -0500
Subject: [PATCH 051/148] Add support for sharing a MAC across partitions

In order to share a MAC, we add support for specifying which frame
queues to use even for MAC-connected ethernet nodes.  This allows
all partitions to share the same TX queues so they can all transmit
through the MAC.  For RX to work, fmc needs to be run with appropriate
settings.

In the process, I cleaned up a few things in the neighborhood, and
started moving some of this code toward refactoring.  Also, removed
some driver-specific conditions around error prints so that errors
are reported always.

Signed-off-by: Andy Fleming <afleming@freescale.com>
[Cleanly applied the FSL SDK 2.0.3 patch:
"kernel-2.6.30-Add-support-for-sharing-a-MAC-across-partiti.patch"]
Integrated-by: Yuri Nedel <Yuri.Nedel@windriver.com>
---
 drivers/net/dpa/dpa.c |  636 ++++++++++++++++++++++++++++++++-----------------
 1 files changed, 423 insertions(+), 213 deletions(-)

diff --git a/drivers/net/dpa/dpa.c b/drivers/net/dpa/dpa.c
index e30fcf6..c028f69 100644
--- a/drivers/net/dpa/dpa.c
+++ b/drivers/net/dpa/dpa.c
@@ -127,7 +127,8 @@ struct dpa_bp {
 };
 
 static const size_t dpa_bp_size[] __devinitconst = {
-	DPA_BP_SIZE(128), DPA_BP_SIZE(512), DPA_BP_SIZE(1536)	/* Keep these sorted */
+	/* Keep these sorted */
+	DPA_BP_SIZE(128), DPA_BP_SIZE(512), DPA_BP_SIZE(1536)
 };
 
 static unsigned int dpa_hash_rxaddr(const struct dpa_bp *bp, dma_addr_t a)
@@ -170,10 +171,14 @@ static void dpa_hash_page(struct dpa_bp *bp, struct page *page, dma_addr_t base)
 	BUG();
 }
 
-static void bmb_free(const struct dpa_priv_s *priv, struct dpa_bp *bp, struct bm_buffer *bmb)
+static void bmb_free(const struct dpa_priv_s *priv, struct dpa_bp *bp,
+		struct bm_buffer *bmb)
 {
 	int i;
-	/* Go through the bmb array, and free/unmap every buffer remaining in it */
+	/*
+	 * Go through the bmb array, and free/unmap every buffer remaining
+	 * in it
+	 */
 	for (i = 0; i < 8; i++) {
 		struct page **pageptr;
 		struct page *page;
@@ -265,7 +270,7 @@ static void dpa_bp_refill(const struct dpa_priv_s *priv, struct dpa_bp *bp,
 		}
 	}
 
-	/* Take care of the leftovers ('i' will be one past the last block done) */
+	/* Take care of the leftovers ('i' will be one past the last block) */
 	if ((i % 8) != 0) {
 		err = bman_release(bp->pool, bmb, i % 8,
 				BMAN_RELEASE_FLAG_WAIT_INT);
@@ -294,7 +299,8 @@ static void __cold dpa_bp_depletion(struct bman_portal	*portal,
 }
 
 static int __devinit __must_check __cold __attribute__((nonnull))
-_dpa_bp_alloc(struct net_device *dev, struct list_head *list, struct dpa_bp *dpa_bp)
+_dpa_bp_alloc(struct net_device *dev, struct list_head *list,
+		struct dpa_bp *dpa_bp)
 {
 	int			 _errno;
 	struct bman_pool_params	 bp_params;
@@ -314,8 +320,9 @@ _dpa_bp_alloc(struct net_device *dev, struct list_head *list, struct dpa_bp *dpa
 
 	dpa_bp->pool = bman_new_pool(&bp_params);
 	if (unlikely(dpa_bp->pool == NULL)) {
-		cpu_dev_err(dev->dev.parent, "%s:%hu:%s(): bman_new_pool() failed\n",
-			    __file__, __LINE__, __func__);
+		cpu_dev_err(dev->dev.parent,
+				"%s:%hu:%s(): bman_new_pool() failed\n",
+				__file__, __LINE__, __func__);
 		_errno = -ENOMEM;
 		goto _return_bm_pool_free;
 	}
@@ -344,11 +351,13 @@ _dpa_bp_alloc(struct net_device *dev, struct list_head *list, struct dpa_bp *dpa
 		devm_request_mem_region(dev->dev.parent, dpa_bp->paddr,
 					dpa_bp->size * dpa_bp->count,
 					KBUILD_MODNAME);
-		dpa_bp->vaddr = devm_ioremap_prot(dev->dev.parent, dpa_bp->paddr,
+		dpa_bp->vaddr = devm_ioremap_prot(dev->dev.parent,
+					dpa_bp->paddr,
 					dpa_bp->size * dpa_bp->count, 0);
 		if (unlikely(dpa_bp->vaddr == NULL)) {
-			cpu_dev_err(dev->dev.parent, "%s:%hu:%s(): devm_ioremap() failed\n",
-				    __file__, __LINE__, __func__);
+			cpu_dev_err(dev->dev.parent,
+					"%s:%hu:%s(): devm_ioremap() failed\n",
+					__file__, __LINE__, __func__);
 			_errno = -EIO;
 			goto _return_bman_free_pool;
 		}
@@ -419,7 +428,8 @@ _dpa_bp_free(struct device *dev, struct dpa_bp *dpa_bp)
 	if (dpa_bp->kernel_pool) {
 		kfree(dpa_bp->rxhash);
 	} else {
-		dma_unmap_single(dev, dpa_bp->paddr, dpa_bp->size * dpa_bp->count, DMA_BIDIRECTIONAL);
+		dma_unmap_single(dev, dpa_bp->paddr,
+			dpa_bp->size * dpa_bp->count, DMA_BIDIRECTIONAL);
 		free_pages_exact(dpa_bp->vaddr, dpa_bp->size * dpa_bp->count);
 	}
 	bpid = dpa_pool2bpid(dpa_bp);
@@ -475,8 +485,9 @@ _dpa_fq_alloc(struct list_head		*list,
 	_errno = qman_create_fq(fqid, flags, &dpa_fq->fq_base);
 	if (unlikely(_errno)) {
 		if (netif_msg_probe(priv))
-			cpu_dev_err(dev, "%s:%hu:%s(): qman_create_fq() failed\n",
-				    __file__, __LINE__, __func__);
+			cpu_dev_err(dev,
+				"%s:%hu:%s(): qman_create_fq() failed\n",
+				__file__, __LINE__, __func__);
 		return ERR_PTR(_errno);
 	}
 	fq = &dpa_fq->fq_base;
@@ -489,8 +500,10 @@ _dpa_fq_alloc(struct list_head		*list,
 		_errno = qman_init_fq(fq, QMAN_INITFQ_FLAG_SCHED, &initfq);
 		if (unlikely(_errno < 0)) {
 			if (netif_msg_probe(priv))
-				cpu_dev_err(dev, "%s:%hu:%s(): qman_init_fq(%u) = %d\n",
-					    __file__, __LINE__, __func__, qman_fq_fqid(fq), _errno);
+				cpu_dev_err(dev,
+					"%s:%hu:%s(): qman_init_fq(%u) = %d\n",
+					__file__, __LINE__, __func__,
+					qman_fq_fqid(fq), _errno);
 			qman_destroy_fq(fq, 0);
 			return ERR_PTR(_errno);
 		}
@@ -513,13 +526,16 @@ _dpa_fq_free(struct device *dev, struct qman_fq *fq)
 	if (dpa_fq->init) {
 		_errno = qman_retire_fq(fq, NULL);
 		if (unlikely(_errno < 0))
-			cpu_dev_err(dev, "%s:%hu:%s(): qman_retire_fq(%u) = %d\n",
-				    __file__, __LINE__, __func__, qman_fq_fqid(fq), _errno);
+			cpu_dev_err(dev,
+				"%s:%hu:%s(): qman_retire_fq(%u) = %d\n",
+				__file__, __LINE__, __func__, qman_fq_fqid(fq),
+				_errno);
 
 		__errno = qman_oos_fq(fq);
 		if (unlikely(__errno < 0)) {
 			cpu_dev_err(dev, "%s:%hu:%s(): qman_oos_fq(%u) = %d\n",
-				    __file__, __LINE__, __func__, qman_fq_fqid(fq), __errno);
+					__file__, __LINE__, __func__,
+					qman_fq_fqid(fq), __errno);
 			if (_errno >= 0)
 				_errno = __errno;
 		}
@@ -615,7 +631,8 @@ dpa_fd_release(const struct net_device *net_dev, const struct qm_fd *fd)
 			page = *pageptr;
 			spin_unlock_irqrestore(&_dpa_bp->lock, flags);
 
-			sgt = (typeof(sgt))(kmap(page) + (_bmb->lo & ~PAGE_MASK) + dpa_fd_offset(fd));
+			sgt = (typeof(sgt))(kmap(page) +
+				(_bmb->lo & ~PAGE_MASK) + dpa_fd_offset(fd));
 		} else
 #endif
 		{
@@ -637,13 +654,17 @@ dpa_fd_release(const struct net_device *net_dev, const struct qm_fd *fd)
 				bmb[j].lo	= sgt[i].addr_lo;
 				j++; i++;
 			} while (j < ARRAY_SIZE(bmb) &&
-				 !sgt[i-1].final && sgt[i-1].bpid == sgt[i].bpid);
+					!sgt[i-1].final &&
+					sgt[i-1].bpid == sgt[i].bpid);
 
-			__errno = bman_release(dpa_bp->pool, bmb, j, BMAN_RELEASE_FLAG_WAIT_INT);
+			__errno = bman_release(dpa_bp->pool, bmb, j,
+					BMAN_RELEASE_FLAG_WAIT_INT);
 			if (unlikely(__errno < 0)) {
-				cpu_netdev_err(net_dev, "%s:%hu:%s(): bman_release(%hu) = %d\n",
-					       __file__, __LINE__, __func__,
-					       bman_get_params(dpa_bp->pool)->bpid, _errno);
+				cpu_netdev_err(net_dev,
+					"%s:%hu:%s(): bman_release(%hu) = %d\n",
+					__file__, __LINE__, __func__,
+					bman_get_params(dpa_bp->pool)->bpid,
+					_errno);
 				if (_errno >= 0)
 					_errno = __errno;
 			}
@@ -655,11 +676,12 @@ dpa_fd_release(const struct net_device *net_dev, const struct qm_fd *fd)
 #endif
 	}
 
-	__errno = bman_release(_dpa_bp->pool, _bmb, 1, BMAN_RELEASE_FLAG_WAIT_INT);
+	__errno = bman_release(_dpa_bp->pool, _bmb, 1,
+			BMAN_RELEASE_FLAG_WAIT_INT);
 	if (unlikely(__errno < 0)) {
 		cpu_netdev_err(net_dev, "%s:%hu:%s(): bman_release(%hu) = %d\n",
-			       __file__, __LINE__, __func__,
-			       bman_get_params(_dpa_bp->pool)->bpid, _errno);
+				__file__, __LINE__, __func__,
+				bman_get_params(_dpa_bp->pool)->bpid, _errno);
 		if (_errno >= 0)
 			_errno = __errno;
 	}
@@ -679,9 +701,9 @@ dpa_fd_release(const struct net_device *net_dev, const struct qm_fd *fd)
 	min(sizeof(struct icmphdr), min(sizeof(struct udphdr), sizeof(struct tcphdr)))
 #endif
 
-static enum qman_cb_dqrr_result ingress_rx_error_dqrr(struct qman_portal		*portal,
-							struct qman_fq			*fq,
-							const struct qm_dqrr_entry	*dq)
+static enum qman_cb_dqrr_result
+ingress_rx_error_dqrr(struct qman_portal *portal, struct qman_fq *fq,
+		const struct qm_dqrr_entry *dq)
 {
 	int			 _errno;
 	struct net_device	*net_dev;
@@ -699,8 +721,9 @@ static enum qman_cb_dqrr_result ingress_rx_error_dqrr(struct qman_portal		*porta
 
 	BUG_ON((dq->fd.status & FM_FD_STAT_ERRORS) == 0);
 
-	cpu_netdev_err(net_dev, "%s:%hu:%s(): FD status = 0x%08x\n", __file__, __LINE__, __func__,
-		       dq->fd.status & FM_FD_STAT_ERRORS);
+	cpu_netdev_err(net_dev, "%s:%hu:%s(): FD status = 0x%08x\n",
+			__file__, __LINE__, __func__,
+			dq->fd.status & FM_FD_STAT_ERRORS);
 
 #ifdef CONFIG_FSL_FMAN_TEST
 {
@@ -824,7 +847,8 @@ ingress_rx_default_dqrr(struct qman_portal		*portal,
 
 	if (fqid == FMT_RX_DFLT_Q) {
 		list_for_each_entry(dpa_fq, priv->dpa_fq_list + RX, list) {
-			if (dq->fqid == qman_fq_fqid((struct qman_fq *)dpa_fq)) {
+			if (dq->fqid ==
+				qman_fq_fqid((struct qman_fq *)dpa_fq)) {
 				fqid = FMT_RX_ERR_Q;
 				break;
 			}
@@ -855,11 +879,13 @@ ingress_rx_default_dqrr(struct qman_portal		*portal,
 }
 #endif /* CONFIG_FSL_FMAN_TEST */
 
-	dpa_fd = (typeof(dpa_fd))devm_kzalloc(net_dev->dev.parent, sizeof(*dpa_fd), GFP_ATOMIC);
+	dpa_fd = (typeof(dpa_fd))devm_kzalloc(net_dev->dev.parent,
+			sizeof(*dpa_fd), GFP_ATOMIC);
 	if (unlikely(dpa_fd == NULL)) {
 		if (netif_msg_rx_err(priv))
-			cpu_netdev_err(net_dev, "%s:%hu:%s(): devm_kzalloc() failed\n",
-				       __file__, __LINE__, __func__);
+			cpu_netdev_err(net_dev,
+				"%s:%hu:%s(): devm_kzalloc() failed\n",
+				__file__, __LINE__, __func__);
 		goto _return;
 	}
 
@@ -936,9 +962,9 @@ static void ingress_rx_default_fqs(struct qman_portal		*portal,
 		cpu_netdev_dbg(net_dev, "%s:%s() ->\n", __file__, __func__);
 }
 
-static enum qman_cb_dqrr_result ingress_tx_error_dqrr(struct qman_portal		*portal,
-						      struct qman_fq			*fq,
-						      const struct qm_dqrr_entry	*dq)
+static enum qman_cb_dqrr_result
+ingress_tx_error_dqrr(struct qman_portal *portal, struct qman_fq *fq,
+		const struct qm_dqrr_entry *dq)
 {
 	const struct net_device	*net_dev;
 	const struct dpa_priv_s	*priv;
@@ -1026,9 +1052,10 @@ static void ingress_tx_error_fqs(struct qman_portal		*portal,
 		cpu_netdev_dbg(net_dev, "%s:%s() ->\n", __file__, __func__);
 }
 
-static enum qman_cb_dqrr_result ingress_tx_default_dqrr(struct qman_portal		*portal,
-							struct qman_fq			*fq,
-							const struct qm_dqrr_entry	*dq)
+static enum qman_cb_dqrr_result
+ingress_tx_default_dqrr(struct qman_portal		*portal,
+			struct qman_fq			*fq,
+			const struct qm_dqrr_entry	*dq)
 {
 	const struct net_device	*net_dev;
 	const struct dpa_priv_s	*priv;
@@ -1056,7 +1083,8 @@ static enum qman_cb_dqrr_result ingress_tx_default_dqrr(struct qman_portal		*por
 
 	BUG_ON(net_dev != skb->dev);
 
-	dma_unmap_single(net_dev->dev.parent, dq->fd.addr_lo, skb_headlen(skb), DMA_TO_DEVICE);
+	dma_unmap_single(net_dev->dev.parent, dq->fd.addr_lo, skb_headlen(skb),
+			DMA_TO_DEVICE);
 
 	dev_kfree_skb_irq(skb);
 
@@ -1164,8 +1192,8 @@ static void egress_ern(struct qman_portal	*portal,
 
 		BUG_ON(net_dev != skb->dev);
 
-		dma_unmap_single(net_dev->dev.parent, msg->ern.fd.addr_lo, skb_headlen(skb),
-				 DMA_TO_DEVICE);
+		dma_unmap_single(net_dev->dev.parent, msg->ern.fd.addr_lo,
+				skb_headlen(skb), DMA_TO_DEVICE);
 
 		dev_kfree_skb_irq(skb);
 	} else {
@@ -1224,15 +1252,19 @@ static void egress_fqs(struct qman_portal	*portal,
 static const struct qman_fq ingress_fqs[][2] __devinitconst = {
 	[RX] = {
 		/* Error */
-		{.cb = {ingress_rx_error_dqrr, ingress_rx_error_ern, ingress_rx_error_dc_ern, ingress_rx_error_fqs}},
+		{.cb = {ingress_rx_error_dqrr, ingress_rx_error_ern,
+			ingress_rx_error_dc_ern, ingress_rx_error_fqs} },
 		 /* Default */
-		{.cb = {ingress_rx_default_dqrr, ingress_rx_default_ern, ingress_rx_default_dc_ern, ingress_rx_default_fqs}}
+		{.cb = {ingress_rx_default_dqrr, ingress_rx_default_ern,
+			ingress_rx_default_dc_ern, ingress_rx_default_fqs} }
 	},
 	[TX] = {
 		/* Error */
-		{.cb = {ingress_tx_error_dqrr, ingress_tx_error_ern, ingress_tx_error_dc_ern, ingress_tx_error_fqs}},
+		{.cb = {ingress_tx_error_dqrr, ingress_tx_error_ern,
+			ingress_tx_error_dc_ern, ingress_tx_error_fqs} },
 		 /* Default */
-		{.cb = {ingress_tx_default_dqrr, ingress_tx_default_ern, ingress_tx_default_dc_ern, ingress_tx_default_fqs}}
+		{.cb = {ingress_tx_default_dqrr, ingress_tx_default_ern,
+			ingress_tx_default_dc_ern, ingress_tx_default_fqs} }
 	}
 };
 
@@ -1293,7 +1325,8 @@ static int init_phy(struct net_device *net_dev)
 	return 0;
 }
 
-static struct net_device_stats * __cold dpa_get_stats(struct net_device *net_dev)
+static struct net_device_stats * __cold
+dpa_get_stats(struct net_device *net_dev)
 {
 	cpu_netdev_dbg(net_dev, "-> %s:%s()\n", __file__, __func__);
 
@@ -1314,8 +1347,9 @@ static void __cold dpa_change_rx_flags(struct net_device *net_dev, int flags)
 	if ((flags & IFF_PROMISC) != 0 && priv->mac_dev != NULL) {
 		_errno = priv->mac_dev->change_promisc(priv->mac_dev);
 		if (unlikely(_errno < 0))
-			cpu_netdev_err(net_dev, "%s:%hu:%s(): mac_dev->change_promisc() = %d\n",
-				       __file__, __LINE__, __func__, _errno);
+			cpu_netdev_err(net_dev,
+				"%s:%hu:%s(): mac_dev->change_promisc() = %d\n",
+				__file__, __LINE__, __func__, _errno);
 	}
 
 	cpu_netdev_dbg(net_dev, "%s:%s() ->\n", __file__, __func__);
@@ -1350,9 +1384,10 @@ static void __hot dpa_rx(struct work_struct *fd_work)
 
 		if (unlikely(dpa_fd->fd.status & FM_FD_STAT_ERRORS) != 0) {
 			if (netif_msg_rx_err(priv))
-				cpu_netdev_err(net_dev, "%s:%hu:%s(): FD status = 0x%08x\n",
-					       __file__, __LINE__, __func__,
-					       dpa_fd->fd.status & FM_FD_STAT_ERRORS);
+				cpu_netdev_err(net_dev,
+					"%s:%hu:%s(): FD status = 0x%08x\n",
+					__file__, __LINE__, __func__,
+					dpa_fd->fd.status & FM_FD_STAT_ERRORS);
 
 			net_dev->stats.rx_errors++;
 
@@ -1382,8 +1417,8 @@ static void __hot dpa_rx(struct work_struct *fd_work)
 			pageptr = dpa_find_rxpage(dpa_bp, bmb->lo);
 
 			if (!pageptr)
-				cpu_pr_emerg("Aaaaaaah, no page for addr %x in pool %d!\n",
-					     bmb->lo, bmb->bpid);
+				cpu_pr_emerg("No page found for addr %x!\n",
+						bmb->lo);
 
 			page = *pageptr;
 			*pageptr = NULL;
@@ -1392,7 +1427,8 @@ static void __hot dpa_rx(struct work_struct *fd_work)
 			spin_unlock_irqrestore(&dpa_bp->lock, flags);
 
 			head = sizeof(*bmb) + NET_IP_ALIGN;
-			size = ETH_HLEN + NN_ALLOCATED_SPACE(net_dev) + TT_ALLOCATED_SPACE(net_dev);
+			size = ETH_HLEN + NN_ALLOCATED_SPACE(net_dev) +
+				TT_ALLOCATED_SPACE(net_dev);
 		} else
 #endif
 		{
@@ -1404,8 +1440,8 @@ static void __hot dpa_rx(struct work_struct *fd_work)
 		if (unlikely(skb == NULL)) {
 			if (netif_msg_rx_err(priv))
 				cpu_netdev_err(net_dev,
-					       "%s:%hu:%s(): netdev_alloc_skb() failed\n",
-					       __file__, __LINE__, __func__);
+					"%s:%hu: netdev_alloc_skb failed\n",
+					__file__, __LINE__);
 
 			net_dev->stats.rx_dropped++;
 
@@ -1435,13 +1471,13 @@ static void __hot dpa_rx(struct work_struct *fd_work)
 					dpa_bp->size, DMA_FROM_DEVICE);
 
 			if (unlikely(!__pskb_pull_tail(skb,
-						       ETH_HLEN +
-						       NN_RESERVED_SPACE(net_dev) +
-						       TT_RESERVED_SPACE(net_dev)))) {
+						ETH_HLEN +
+						NN_RESERVED_SPACE(net_dev) +
+						TT_RESERVED_SPACE(net_dev)))) {
 				if (netif_msg_rx_err(priv))
 					cpu_netdev_err(net_dev,
-						       "%s:%hu:%s(): __pskb_pull_tail() failed\n",
-						       __file__, __LINE__, __func__);
+					"%s:%hu: __pskb_pull_tail() failed\n",
+						       __file__, __LINE__);
 
 				net_dev->stats.rx_dropped++;
 
@@ -1458,7 +1494,7 @@ static void __hot dpa_rx(struct work_struct *fd_work)
 			_errno = dpa_fd_release(net_dev, &dpa_fd->fd);
 			if (unlikely(_errno < 0)) {
 				dump_stack();
-				panic("Can't release buffer to the BM during RX\n");
+				panic("Can't release buffer to BM during RX\n");
 			}
 		}
 
@@ -1597,10 +1633,12 @@ static int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
 	if (priv->mac_dev) {
 		*((typeof(&skb))skb_push(skb, DPA_BP_HEAD)) = skb;
 
-		fd.addr_lo	= dma_map_single(dev, skb->data, skb_headlen(skb), DMA_TO_DEVICE);
+		fd.addr_lo = dma_map_single(dev, skb->data, skb_headlen(skb),
+				DMA_TO_DEVICE);
 		if (unlikely(fd.addr_lo == 0)) {
-			cpu_netdev_err(net_dev, "%s:%hu:%s(): dma_map_single() failed\n",
-				       __file__, __LINE__, __func__);
+			cpu_netdev_err(net_dev,
+				"%s:%hu:%s(): dma_map_single() failed\n",
+				__file__, __LINE__, __func__);
 			_errno = -EIO;
 			goto _return_dev_kfree_skb;
 		}
@@ -1615,8 +1653,9 @@ static int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
 		_errno = bman_acquire(dpa_bp->pool, bmb, 1, 0);
 		if (unlikely(_errno <= 0)) {
 			if (netif_msg_tx_err(priv))
-				cpu_netdev_err(net_dev, "%s:%hu:%s(): bman_acquire() = %d\n",
-					       __file__, __LINE__, __func__, _errno);
+				cpu_netdev_err(net_dev,
+					"%s:%hu:%s(): bman_acquire() = %d\n",
+					__file__, __LINE__, __func__, _errno);
 			net_dev->stats.tx_errors++;
 			goto _return_dev_kfree_skb;
 		}
@@ -1625,15 +1664,18 @@ static int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
 		fd.cmd		= FM_FD_CMD_FCO;
 
 		/* Copy the packet payload */
-		skb_copy_from_linear_data(skb, dpa_phys2virt(dpa_bp, bmb) + dpa_fd_offset(&fd),
-					  dpa_fd_length(&fd));
+		skb_copy_from_linear_data(skb,
+			dpa_phys2virt(dpa_bp, bmb) + dpa_fd_offset(&fd),
+			dpa_fd_length(&fd));
 	}
 
-	_errno = qman_enqueue(priv->egress_fqs[skb_get_queue_mapping(skb)], &fd, 0);
+	_errno = qman_enqueue(priv->egress_fqs[skb_get_queue_mapping(skb)],
+			&fd, 0);
 	if (unlikely(_errno < 0)) {
 		if (netif_msg_tx_err(priv))
-			cpu_netdev_err(net_dev, "%s:%hu:%s(): qman_enqueue() = %d\n",
-				       __file__, __LINE__, __func__, _errno);
+			cpu_netdev_err(net_dev,
+				"%s:%hu:%s(): qman_enqueue() = %d\n",
+				__file__, __LINE__, __func__, _errno);
 		net_dev->stats.tx_errors++;
 		net_dev->stats.tx_fifo_errors++;
 		goto _return_buffer;
@@ -1651,7 +1693,8 @@ static int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
 
 _return_buffer:
 	if (priv->mac_dev)
-		dma_unmap_single(dev, fd.addr_lo, skb_headlen(skb), DMA_TO_DEVICE);
+		dma_unmap_single(dev, fd.addr_lo, skb_headlen(skb),
+			DMA_TO_DEVICE);
 	else {
 		__errno = dpa_fd_release(net_dev, &fd);
 		if (unlikely(__errno < 0)) {
@@ -1682,8 +1725,9 @@ static int __cold dpa_start(struct net_device *net_dev)
 		_errno = init_phy(net_dev);
 		if(_errno) {
 			if (netif_msg_ifup(priv))
-				cpu_netdev_err(net_dev, "%s:%hu:%s(): init_phy() = %d\n",
-					       __file__, __LINE__, __func__, _errno);
+				cpu_netdev_err(net_dev,
+					"%s:%hu:%s(): init_phy() = %d\n",
+					__file__, __LINE__, __func__, _errno);
 			goto _return_port_dev_stop;
 		}
 
@@ -1693,8 +1737,9 @@ static int __cold dpa_start(struct net_device *net_dev)
 		_errno = priv->mac_dev->start(priv->mac_dev);
 		if (unlikely(_errno < 0)) {
 			if (netif_msg_ifup(priv))
-				cpu_netdev_err(net_dev, "%s:%hu:%s(): mac_dev->start() = %d\n",
-					       __file__, __LINE__, __func__, _errno);
+				cpu_netdev_err(net_dev,
+					"%s:%hu:%s(): mac_dev->start() = %d\n",
+					__file__, __LINE__, __func__, _errno);
 			goto _return_port_dev_stop;
 		}
 		phy_start(priv->mac_dev->phy_dev);
@@ -1734,8 +1779,9 @@ static int __cold dpa_stop(struct net_device *net_dev)
 		__errno = priv->mac_dev->stop(priv->mac_dev);
 		if (unlikely(__errno < 0)) {
 			if (netif_msg_ifdown(priv))
-				cpu_netdev_err(net_dev, "%s:%hu:%s(): mac_dev->stop() = %d\n",
-					       __file__, __LINE__, __func__, __errno);
+				cpu_netdev_err(net_dev,
+					"%s:%hu:%s(): mac_dev->stop() = %d\n",
+					__file__, __LINE__, __func__, __errno);
 			if (likely(_errno >= 0))
 				_errno = __errno;
 		}
@@ -1773,7 +1819,8 @@ static void __cold dpa_timeout(struct net_device *net_dev)
 static int __devinit __cold __pure __must_check __attribute__((nonnull))
 dpa_bp_cmp(const void *dpa_bp0, const void *dpa_bp1)
 {
-	return ((struct dpa_bp *)dpa_bp0)->size - ((struct dpa_bp *)dpa_bp1)->size;
+	return ((struct dpa_bp *)dpa_bp0)->size -
+			((struct dpa_bp *)dpa_bp1)->size;
 }
 
 static struct dpa_bp * __devinit __cold __must_check __attribute__((nonnull))
@@ -1789,8 +1836,8 @@ dpa_bp_probe(struct of_device *_of_dev, size_t *count)
 	dev = &_of_dev->dev;
 
 	/* Get the buffer pools to be used */
-	phandle_prop = (typeof(phandle_prop))of_get_property(_of_dev->node, "fsl,bman-buffer-pools",
-							     &lenp);
+	phandle_prop = (typeof(phandle_prop))of_get_property(_of_dev->node,
+					"fsl,bman-buffer-pools", &lenp);
 	if (phandle_prop == NULL) {
 		dpa_bp = NULL;
 		goto _return_count;
@@ -1807,8 +1854,9 @@ dpa_bp_probe(struct of_device *_of_dev, size_t *count)
 
 	dev_node = of_find_node_by_path("/");
 	if (unlikely(dev_node == NULL)) {
-		cpu_dev_err(dev, "%s:%hu:%s(): of_find_node_by_path(/) failed\n",
-			    __file__, __LINE__, __func__);
+		cpu_dev_err(dev,
+			"%s:%hu:%s(): of_find_node_by_path(/) failed\n",
+			__file__, __LINE__, __func__);
 		dpa_bp = ERR_PTR(-EINVAL);
 		goto _return_count;
 	}
@@ -1820,8 +1868,9 @@ dpa_bp_probe(struct of_device *_of_dev, size_t *count)
 	for (i = 0; i < *count; i++) {
 		dev_node = of_find_node_by_phandle(phandle_prop[i]);
 		if (unlikely(dev_node == NULL)) {
-			cpu_dev_err(dev, "%s:%hu:%s(): of_find_node_by_phandle() failed\n",
-				    __file__, __LINE__, __func__);
+			cpu_dev_err(dev,
+				"%s:%hu:%s(): of_find_node_by_phandle failed\n",
+				__file__, __LINE__, __func__);
 			return ERR_PTR(-EFAULT);
 		}
 
@@ -1848,7 +1897,8 @@ dpa_bp_probe(struct of_device *_of_dev, size_t *count)
 
 			dpa_bp[i].count	= of_read_number(uint32_prop, ns);
 			dpa_bp[i].size	= of_read_number(uint32_prop + ns, ns);
-			dpa_bp[i].paddr	= of_read_number(uint32_prop + 2 * ns, na);
+			dpa_bp[i].paddr	= of_read_number(uint32_prop + 2 * ns,
+						na);
 		}
 
 		of_node_put(dev_node);
@@ -1866,7 +1916,8 @@ _return:
 	return dpa_bp;
 }
 
-static struct mac_device * __devinit __cold __must_check __attribute__((nonnull))
+static struct mac_device * __devinit __cold __must_check
+__attribute__((nonnull))
 dpa_mac_probe(struct of_device *_of_dev)
 {
 	struct device		*dpa_dev, *dev;
@@ -1876,7 +1927,8 @@ dpa_mac_probe(struct of_device *_of_dev)
 	struct of_device	*of_dev;
 	struct mac_device	*mac_dev;
 
-	phandle_prop = (typeof(phandle_prop))of_get_property(_of_dev->node, "fsl,fman-mac", &lenp);
+	phandle_prop = (typeof(phandle_prop))of_get_property(_of_dev->node,
+				"fsl,fman-mac", &lenp);
 	if (phandle_prop == NULL)
 		return NULL;
 
@@ -1886,15 +1938,17 @@ dpa_mac_probe(struct of_device *_of_dev)
 
 	mac_node = of_find_node_by_phandle(*phandle_prop);
 	if (unlikely(mac_node == NULL)) {
-		cpu_dev_err(dpa_dev, "%s:%hu:%s(): of_find_node_by_phandle() failed\n",
-			    __file__, __LINE__, __func__);
+		cpu_dev_err(dpa_dev,
+			"%s:%hu:%s(): of_find_node_by_phandle() failed\n",
+			__file__, __LINE__, __func__);
 		return ERR_PTR(-EFAULT);
 	}
 
 	of_dev = of_find_device_by_node(mac_node);
 	if (unlikely(of_dev == NULL)) {
-		cpu_dev_err(dpa_dev, "%s:%hu:%s(): of_find_device_by_node(%s) failed\n",
-			    __file__, __LINE__, __func__, mac_node->full_name);
+		cpu_dev_err(dpa_dev,
+			"%s:%hu:%s(): of_find_device_by_node(%s) failed\n",
+			__file__, __LINE__, __func__, mac_node->full_name);
 		of_node_put(mac_node);
 		return ERR_PTR(-EINVAL);
 	}
@@ -1904,8 +1958,9 @@ dpa_mac_probe(struct of_device *_of_dev)
 
 	mac_dev = (typeof(mac_dev))dev_get_drvdata(dev);
 	if (unlikely(mac_dev == NULL)) {
-		cpu_dev_err(dpa_dev, "%s:%hu:%s(): dev_get_drvdata(%s) failed\n",
-			    __file__, __LINE__, __func__, dev_name(dev));
+		cpu_dev_err(dpa_dev,
+			"%s:%hu:%s(): dev_get_drvdata(%s) failed\n",
+			__file__, __LINE__, __func__, dev_name(dev));
 		return ERR_PTR(-EINVAL);
 	}
 
@@ -1934,11 +1989,11 @@ static int __devinit __cold dpa_alloc_pcd_fqids(struct device	*dev,
 	net_dev = (typeof(net_dev))dev_get_drvdata(dev);
 	priv = (typeof(priv))netdev_priv(net_dev);
 
-	dpa_fq = (typeof(dpa_fq))devm_kzalloc(dev, total_num_fqs * sizeof(*dpa_fq), GFP_KERNEL);
+	dpa_fq = devm_kzalloc(dev, total_num_fqs * sizeof(*dpa_fq), GFP_KERNEL);
 	if (unlikely(dpa_fq == NULL)) {
 		if (netif_msg_probe(priv))
 			cpu_dev_err(dev, "%s:%hu:%s(): devm_kzalloc() failed\n",
-				    __file__, __LINE__, __func__);
+					__file__, __LINE__, __func__);
 		_errno = -ENOMEM;
 		goto _return;
 	}
@@ -1948,7 +2003,7 @@ static int __devinit __cold dpa_alloc_pcd_fqids(struct device	*dev,
 		dpa_fq->net_dev	= net_dev;
 		prev_fqid = (ingress_fq ? qman_fq_fqid(ingress_fq) : 0);
 		ingress_fq = _dpa_fq_alloc(priv->dpa_fq_list + RX, dpa_fq, 0,
-					   QMAN_FQ_FLAG_NO_ENQUEUE, priv->channel, 7);
+				QMAN_FQ_FLAG_NO_ENQUEUE, priv->channel, 7);
 		if (IS_ERR(ingress_fq)) {
 			_errno = PTR_ERR(ingress_fq);
 			goto _return;
@@ -1977,7 +2032,8 @@ static int __devinit __cold dpa_alloc_pcd_fqids(struct device	*dev,
 	priv->ranges[priv->num++].count = num;
 #endif /* CONFIG_FSL_FMAN_TEST */
 
-	cpu_dev_dbg(dev, "%s:%s(): pcd_fqs base %u\n",__file__, __func__,*base_fqid);
+	cpu_dev_dbg(dev, "%s:%s(): pcd_fqs base %u\n", __file__, __func__,
+			*base_fqid);
 
 	_errno = 0;
 
@@ -1987,7 +2043,8 @@ _return:
 	return _errno;
 }
 
-static int __devinit __cold __attribute__((nonnull)) dpa_init_probe(struct of_device *_of_dev)
+static int __devinit __cold __attribute__((nonnull))
+dpa_init_probe(struct of_device *_of_dev)
 {
 	int				 _errno, i, j, lenp;
 	struct device			*dev;
@@ -1999,7 +2056,7 @@ static int __devinit __cold __attribute__((nonnull)) dpa_init_probe(struct of_de
 	size_t				 count;
 	struct device_node		*dpa_node;
 	const uint32_t			*uint32_prop;
-	uint32_t			 ingress_fqids[ARRAY_SIZE(fsl_qman_frame_queues)][2];
+	uint32_t	ingress_fqids[ARRAY_SIZE(fsl_qman_frame_queues)][2];
 
 	dev = &_of_dev->dev;
 
@@ -2014,8 +2071,9 @@ static int __devinit __cold __attribute__((nonnull)) dpa_init_probe(struct of_de
 		_errno = PTR_ERR(mac_dev);
 		goto _return;
 	} else if(mac_dev == NULL) {
-		cpu_dev_err(dev, "%s:%hu:%s(): Missing the %s/fsl,fman-mac property\n",
-			    __file__, __LINE__, __func__, dpa_node->full_name);
+		cpu_dev_err(dev,
+			"%s:%hu:%s(): Missing the %s/fsl,fman-mac property\n",
+			__file__, __LINE__, __func__, dpa_node->full_name);
 		_errno = -EINVAL;
 		goto _return;
 	}
@@ -2027,8 +2085,9 @@ static int __devinit __cold __attribute__((nonnull)) dpa_init_probe(struct of_de
 		_errno = PTR_ERR(dpa_bp);
 		goto _return;
 	} else if (unlikely(dpa_bp == NULL)) {
-		cpu_dev_err(dev, "%s:%hu:%s(): Missing the %s/fsl,bman-buffer-pools property\n",
-			    __file__, __LINE__, __func__, dpa_node->full_name);
+		cpu_dev_err(dev,
+			"%s:%hu: Missing %s/fsl,bman-buffer-pools property\n",
+			__file__, __LINE__, dpa_node->full_name);
 		_errno = -EINVAL;
 		goto _return;
 	}
@@ -2039,8 +2098,9 @@ static int __devinit __cold __attribute__((nonnull)) dpa_init_probe(struct of_de
 		rx_port_param.pool_param[i].size = dpa_bp[i].size;
 
 		cpu_dev_dbg(dev, "%s:%s(): dpa_bp[%d] = {%hu, %u}\n",
-			    __file__, __func__,
-			    i, rx_port_param.pool_param[i].id, rx_port_param.pool_param[i].size);
+				__file__, __func__, i,
+				rx_port_param.pool_param[i].id,
+				rx_port_param.pool_param[i].size);
 	}
 	devm_kfree(dev, dpa_bp);
 
@@ -2048,12 +2108,12 @@ static int __devinit __cold __attribute__((nonnull)) dpa_init_probe(struct of_de
 
 	for (i = 0; i < ARRAY_SIZE(ingress_fqids); i++) {
 		uint32_prop = (typeof(uint32_prop))of_get_property(dpa_node,
-								   fsl_qman_frame_queues[i],
-								   &lenp);
+				fsl_qman_frame_queues[i], &lenp);
 		if (unlikely(uint32_prop == NULL)) {
-			cpu_dev_info(dev, "%s:%hu:%s(): of_get_property(%s, %s) failed\n",
-				     __file__, __LINE__, __func__,
-				     dpa_node->full_name, fsl_qman_frame_queues[i]);
+			cpu_dev_info(dev,
+				"%s:%hu:%s(): of_get_property(%s, %s) failed\n",
+				__file__, __LINE__, __func__,
+				dpa_node->full_name, fsl_qman_frame_queues[i]);
 			_errno = -EINVAL;
 			goto _return;
 		}
@@ -2096,7 +2156,38 @@ _return:
 	return _errno;
 }
 
-static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device *_of_dev)
+static const uint32_t *dpa_get_fqids(struct device_node *dpa_node,
+					const char *match, int *num)
+{
+	const uint32_t *fqids;
+
+	fqids = of_get_property(dpa_node, match, num);
+	if (unlikely(!fqids)) {
+		printk(KERN_ERR "%s: of_get_property(%s) failed\n",
+				dpa_node->full_name, match);
+
+		*num = 0;
+		return NULL;
+	}
+
+	*num /= (2 * sizeof(*fqids));
+
+	return fqids;
+}
+
+static int dpa_count_fqs(const uint32_t *fqids, int num)
+{
+	int i;
+	int count = 0;
+
+	for (i = 0; i < num; i++)
+		count += fqids[2 * i + 1];
+
+	return count;
+}
+
+static int __devinit __cold __attribute__((nonnull))
+dpa_probe(struct of_device *_of_dev)
 {
 	int				 _errno, i, j, lenp;
 	struct device			*dev;
@@ -2114,8 +2205,13 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 	const uint32_t			*uint32_prop;
 	const uint8_t			*mac_addr;
 	struct qman_fq			*ingress_fq;
-	uint32_t			 ingress_fqids[ARRAY_SIZE(ingress_fqs)][2];
-	uint32_t			 fqids[ARRAY_SIZE(priv->dpa_fq_list)];
+	uint32_t		ingress_fqids[ARRAY_SIZE(ingress_fqs)][2];
+	const uint32_t		default_tx_fqids[6] = {0, 1, 0, 1, 0, 8};
+	const uint32_t		default_rx_fqids[6] = {0, 1, 0, 1, 0, 8};
+	const uint32_t		*tx_fqids;
+	const uint32_t		*rx_fqids;
+	int			num_tx_fqids, num_tx_fqs;
+	int			num_rx_fqids, num_rx_fqs;
 
 	dev = &_of_dev->dev;
 
@@ -2123,11 +2219,15 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 
 	dpa_node = _of_dev->node;
 
-	/* Allocate this early, so we can store relevant information in the private area */
-	net_dev = alloc_etherdev_mq(sizeof(*priv), ARRAY_SIZE(priv->egress_fqs));
+	/*
+	 * Allocate this early, so we can store relevant information in
+	 * the private area
+	 */
+	net_dev = alloc_etherdev_mq(sizeof(*priv),
+			ARRAY_SIZE(priv->egress_fqs));
 	if (unlikely(net_dev == NULL)) {
 		cpu_dev_err(dev, "%s:%hu:%s(): alloc_etherdev_mq() failed\n",
-			    __file__, __LINE__, __func__);
+				__file__, __LINE__, __func__);
 		_errno = -ENOMEM;
 		goto _return;
 	}
@@ -2149,14 +2249,15 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 		goto _return_free_netdev;
 	} else if (dpa_bp == NULL) {
 		if (netif_msg_probe(priv))
-			cpu_dev_info(dev, "%s:%hu:%s(): Using private BM buffer pools\n",
-				     __file__, __LINE__, __func__);
+			cpu_dev_info(dev,
+				"%s:%hu:%s(): Using private BM buffer pools\n",
+				__file__, __LINE__, __func__);
 
 		count = ARRAY_SIZE(dpa_bp_size);
-		dpa_bp = (typeof(dpa_bp))devm_kzalloc(dev, count * sizeof(*dpa_bp), GFP_KERNEL);
+		dpa_bp = devm_kzalloc(dev, count * sizeof(*dpa_bp), GFP_KERNEL);
 		if (unlikely(dpa_bp == NULL)) {
 			cpu_dev_err(dev, "%s:%hu:%s(): devm_kzalloc() failed\n",
-				    __file__, __LINE__, __func__);
+					__file__, __LINE__, __func__);
 			_errno = -ENOMEM;
 			goto _return_free_netdev;
 		}
@@ -2167,7 +2268,8 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 		}
 	} else if (count == ARRAY_SIZE(dpa_bp_size)) {
 		for (i = 0, j = 0; i < count; i++) {
-			if (dpa_bp[i].count == 0 && dpa_bp[i].size == 0 && dpa_bp[i].paddr == 0) {
+			if (dpa_bp[i].count == 0 && dpa_bp[i].size == 0 &&
+					dpa_bp[i].paddr == 0) {
 				dpa_bp[i].count	= 128;
 				dpa_bp[i].size	= dpa_bp_size[i];
 				j++;
@@ -2186,7 +2288,8 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 
 	/* QM */
 
-	phandle_prop = (typeof(phandle_prop))of_get_property(dpa_node, "fsl,qman-channel", &lenp);
+	phandle_prop = (typeof(phandle_prop))of_get_property(dpa_node,
+				"fsl,qman-channel", &lenp);
 	if (unlikely(phandle_prop == NULL)) {
 		if (netif_msg_probe(priv))
 			cpu_dev_err(dev, "%s:%hu:%s(): of_get_property(%s, fsl,qman-channel) failed\n",
@@ -2199,13 +2302,15 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 	dev_node = of_find_node_by_phandle(*phandle_prop);
 	if (unlikely(dev_node == NULL)) {
 		if (netif_msg_probe(priv))
-			cpu_dev_err(dev, "%s:%hu:%s(): of_find_node_by_phandle() failed\n",
-				    __file__, __LINE__, __func__);
+			cpu_dev_err(dev,
+				"%s:%hu:%s: of_find_node_by_phandle() failed\n",
+				__file__, __LINE__, __func__);
 		_errno = -EFAULT;
 		goto _return_dpa_bp_free;
 	}
 
-	uint32_prop = (typeof(uint32_prop))of_get_property(dev_node, "fsl,qman-channel-id", &lenp);
+	uint32_prop = (typeof(uint32_prop))of_get_property(dev_node,
+			"fsl,qman-channel-id", &lenp);
 	if (unlikely(uint32_prop == NULL)) {
 		if (netif_msg_probe(priv))
 			cpu_dev_err(dev, "%s:%hu:%s(): of_get_property(%s, fsl,qman-channel-id) failed\n",
@@ -2223,12 +2328,13 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 
 	INIT_WORK(&priv->fd_work, dpa_rx);
 
-	priv->fd_list = (typeof(priv->fd_list))__alloc_percpu(sizeof(*priv->fd_list),
-							      __alignof__(*priv->fd_list));
+	priv->fd_list = __alloc_percpu(sizeof(*priv->fd_list),
+				__alignof__(*priv->fd_list));
 	if (unlikely(priv->fd_list == NULL)) {
 		if (netif_msg_probe(priv))
-			cpu_dev_err(dev, "%s:%hu:%s(): __alloc_percpu() failed\n",
-				    __file__, __LINE__, __func__);
+			cpu_dev_err(dev,
+				"%s:%hu:%s(): __alloc_percpu() failed\n",
+				__file__, __LINE__, __func__);
 		_errno = -ENOMEM;
 		goto _return_dpa_bp_free;
 	}
@@ -2249,17 +2355,28 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 		goto _return_free_percpu;
 	}
 
+	tx_fqids = dpa_get_fqids(dpa_node, "fsl,qman-frame-queues-tx",
+					&num_tx_fqids);
+	num_tx_fqs = dpa_count_fqs(tx_fqids, num_tx_fqids);
+	rx_fqids = dpa_get_fqids(dpa_node, "fsl,qman-frame-queues-rx",
+					&num_rx_fqids);
+	num_rx_fqs = dpa_count_fqs(rx_fqids, num_rx_fqids);
+
 	if(priv->mac_dev == NULL) {
 		if (netif_msg_probe(priv))
-			cpu_dev_info(dev, "%s:%hu:%s(): Missing the %s/fsl,fman-mac property. "
+			cpu_dev_info(dev,
+				"%s:%hu: Missing the %s/fsl,fman-mac property. "
 					  "This is a MAC-less interface\n",
-				     __file__, __LINE__, __func__, dpa_node->full_name);
+					  __file__, __LINE__,
+					  dpa_node->full_name);
 
 		/* Get the MAC address */
 		mac_addr = of_get_mac_address(dpa_node);
 		if (unlikely(mac_addr == NULL)) {
-			cpu_dev_err(dev, "%s:%hu:%s(): of_get_mac_address(%s) failed\n",
-				    __file__, __LINE__, __func__, dpa_node->full_name);
+			cpu_dev_err(dev,
+				"%s:%hu:%s(): of_get_mac_address(%s) failed\n",
+				__file__, __LINE__, __func__,
+				dpa_node->full_name);
 			_errno = -EINVAL;
 			goto _return_free_percpu;
 		}
@@ -2269,113 +2386,159 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 
 		/* QM */
 
-		for (i = 0; i < ARRAY_SIZE(priv->dpa_fq_list); i++) {
-			uint32_prop = (typeof(uint32_prop))of_get_property(dpa_node,
-									   fsl_qman_frame_queues[i],
-									   &lenp);
-			if (unlikely(uint32_prop == NULL)) {
-				if (netif_msg_probe(priv))
-					cpu_dev_err(dev,
-						    "%s:%hu:%s(): of_get_property(%s, %s) failed\n",
-						    __file__, __LINE__, __func__,
-						    dpa_node->full_name, fsl_qman_frame_queues[i]);
-				_errno = -EINVAL;
-				goto _return_free_percpu;
-			}
-			BUG_ON(lenp != 2 * sizeof(uint32_t) ||
-			       uint32_prop[1] != ARRAY_SIZE(priv->egress_fqs));
-
-			fqids[i] = *uint32_prop;
+		/* For now, stick to the idea that we have to have
+		 * static declarations on macless devices */
+		if (!tx_fqids || !rx_fqids) {
+			cpu_dev_err(dev,
+				"macless devices require fq declarations\n");
+			_errno = -EINVAL;
+			goto _return_free_percpu;
 		}
 
-		dpa_fq = (typeof(dpa_fq))devm_kzalloc(
-			dev,
-			ARRAY_SIZE(priv->dpa_fq_list) * ARRAY_SIZE(priv->egress_fqs) * sizeof(*dpa_fq),
-			GFP_KERNEL);
+		dpa_fq = devm_kzalloc(dev, sizeof(*dpa_fq) * num_rx_fqs,
+					GFP_KERNEL);
 		if (unlikely(dpa_fq == NULL)) {
-			if (netif_msg_probe(priv))
-				cpu_dev_err(dev, "%s:%hu:%s(): devm_kzalloc() failed\n",
-					    __file__, __LINE__, __func__);
+			cpu_dev_err(dev, "%s:%hu:%s(): devm_kzalloc() failed\n",
+					__file__, __LINE__, __func__);
 			_errno = -ENOMEM;
 			goto _return_free_percpu;
 		}
 
-		for (i = 0; i < ARRAY_SIZE(priv->egress_fqs); i++, dpa_fq++) {
-			dpa_fq->fq_base = ingress_fqs[RX][1];
-			dpa_fq->net_dev	= net_dev;
-			ingress_fq = _dpa_fq_alloc(priv->dpa_fq_list + RX, dpa_fq, fqids[RX] + i,
-						   QMAN_FQ_FLAG_NO_ENQUEUE, priv->channel, i);
-			if (IS_ERR(ingress_fq)) {
-				_errno = PTR_ERR(ingress_fq);
-				goto _return_dpa_fq_free;
+		for (i = 0; i < num_rx_fqids; i++) {
+			for (j = 0; j < rx_fqids[2 * i + 1]; j++, dpa_fq++) {
+				uint32_t fqid =
+					rx_fqids[2 * i] ?
+					rx_fqids[2 * i] + j : 0;
+				/* The work queue will be set to the value
+				 * of the fqid mod 8.  This way, system
+				 * architects can choose the priority
+				 * of the frame queue by statically
+				 * assigning the fqid
+				 */
+				int wq = fqid ? fqid % 8 : 7;
+
+				dpa_fq->fq_base = ingress_fqs[RX][1];
+				dpa_fq->net_dev	= net_dev;
+				ingress_fq = _dpa_fq_alloc(
+						priv->dpa_fq_list + RX,
+						dpa_fq, fqid,
+						QMAN_FQ_FLAG_NO_ENQUEUE,
+						priv->channel, wq);
+				if (IS_ERR(ingress_fq)) {
+					_errno = PTR_ERR(ingress_fq);
+					goto _return_dpa_fq_free;
+				}
+
+
+				cpu_dev_dbg(dev,
+					"%s:%s(): ingress_fqs[%d][%d] = %u\n",
+					__file__, __func__, i, j,
+					qman_fq_fqid(ingress_fq));
 			}
+		}
 
+		/* Right now, we maintain the requirement that we have 8 */
+		BUG_ON(num_tx_fqs != 8);
 
-			cpu_dev_dbg(dev, "%s:%s(): ingress_fqs[%d] = %u\n",
-				    __file__, __func__, i, qman_fq_fqid(ingress_fq));
+		/* FIXME: Horribly leaky */
+		dpa_fq = devm_kzalloc(dev, sizeof(*dpa_fq) * num_tx_fqs,
+					GFP_KERNEL);
+		if (unlikely(dpa_fq == NULL)) {
+			cpu_dev_err(dev, "%s:%hu:%s(): devm_kzalloc() failed\n",
+					__file__, __LINE__, __func__);
+			_errno = -ENOMEM;
+			goto _return_free_percpu;
 		}
 
-		for (i = 0; i < ARRAY_SIZE(priv->egress_fqs); i++, dpa_fq++) {
+		for (i = 0; i < tx_fqids[1]; i++, dpa_fq++) {
+			uint32_t fqid = tx_fqids[0] ? tx_fqids[0] + i : 0;
+
 			dpa_fq->fq_base = _egress_fqs;
 			dpa_fq->net_dev	= net_dev;
-			priv->egress_fqs[i] = _dpa_fq_alloc(priv->dpa_fq_list + TX, dpa_fq,
-							    fqids[TX] + i,
-							    QMAN_FQ_FLAG_NO_MODIFY, 0, 0);
+			priv->egress_fqs[i] = _dpa_fq_alloc(
+					priv->dpa_fq_list + TX, dpa_fq, fqid,
+					QMAN_FQ_FLAG_NO_MODIFY, 0, 0);
 			if (IS_ERR(priv->egress_fqs[i])) {
 				_errno = PTR_ERR(priv->egress_fqs[i]);
 				goto _return_dpa_fq_free;
 			}
 
 			cpu_dev_dbg(dev, "%s:%s(): egress_fqs[%d] = %u\n",
-				    __file__, __func__, i, qman_fq_fqid(priv->egress_fqs[i]));
+					__file__, __func__, i,
+					qman_fq_fqid(priv->egress_fqs[i]));
 		}
 	} else {
+		uint32_t ingress_fq_cfg[2][2];
+
 		net_dev->mem_start	= priv->mac_dev->res->start;
 		net_dev->mem_end	= priv->mac_dev->res->end;
 
-		memcpy(net_dev->perm_addr, priv->mac_dev->addr, net_dev->addr_len);
-		memcpy(net_dev->dev_addr, priv->mac_dev->addr, net_dev->addr_len);
+		memcpy(net_dev->perm_addr, priv->mac_dev->addr,
+			net_dev->addr_len);
+		memcpy(net_dev->dev_addr, priv->mac_dev->addr,
+			net_dev->addr_len);
 
 		/* BM */
-		rx_port_param.num_pools = min(ARRAY_SIZE(rx_port_param.pool_param), count);
+		rx_port_param.num_pools =
+			min(ARRAY_SIZE(rx_port_param.pool_param), count);
 		i = 0;
 		list_for_each_entry(dpa_bp, &priv->dpa_bp_list, list) {
 			if (i >= rx_port_param.num_pools)
 				break;
 
-			rx_port_param.pool_param[i].id	 = dpa_pool2bpid(dpa_bp);
+			rx_port_param.pool_param[i].id = dpa_pool2bpid(dpa_bp);
 			rx_port_param.pool_param[i].size = dpa_bp->size;
 
 			cpu_dev_dbg(dev, "%s:%s(): dpa_bp[%d] = {%hu, %u}\n",
-				    __file__, __func__,
-				    i, rx_port_param.pool_param[i].id,
-				    rx_port_param.pool_param[i].size);
+					__file__, __func__,
+					i, rx_port_param.pool_param[i].id,
+					rx_port_param.pool_param[i].size);
 
 			i++;
 		}
 
 		/* QM */
 
-		dpa_fq = (typeof(dpa_fq))devm_kzalloc(
-			dev,
-			(ARRAY2_SIZE(ingress_fqs) + ARRAY_SIZE(priv->egress_fqs)) * sizeof(*dpa_fq),
-			GFP_KERNEL);
+		if (!tx_fqids) {
+			tx_fqids = &default_tx_fqids[0];
+			num_tx_fqids = ARRAY_SIZE(default_tx_fqids) / 2;
+			num_tx_fqs = dpa_count_fqs(tx_fqids, num_tx_fqids);
+		}
+
+		if (!rx_fqids) {
+			rx_fqids = &default_rx_fqids[0];
+			num_rx_fqids = ARRAY_SIZE(default_rx_fqids) / 2;
+			num_rx_fqs = dpa_count_fqs(rx_fqids, num_rx_fqids);
+		}
+
+		/* FIXME: Horribly leaky */
+		dpa_fq = devm_kzalloc(dev,
+				sizeof(*dpa_fq) * (num_tx_fqs + num_rx_fqs),
+				GFP_KERNEL);
 		if (unlikely(dpa_fq == NULL)) {
-			if (netif_msg_probe(priv))
-				cpu_dev_err(dev, "%s:%hu:%s(): devm_kzalloc() failed\n",
-					    __file__, __LINE__, __func__);
+			cpu_dev_err(dev, "%s:%hu:%s(): devm_kzalloc() failed\n",
+					__file__, __LINE__, __func__);
 			_errno = -ENOMEM;
 			goto _return_free_percpu;
 		}
 
+		/* device tree has default,error, but local array is reversed */
+		ingress_fq_cfg[0][1] = rx_fqids[0];
+		ingress_fq_cfg[0][0] = rx_fqids[2];
+		ingress_fq_cfg[1][1] = tx_fqids[0];
+		ingress_fq_cfg[1][0] = tx_fqids[2];
+
 		for (i = 0; i < ARRAY_SIZE(ingress_fqs); i++) {
 			/* Error, default */
-			for (j = 0; j < ARRAY_SIZE(ingress_fqs[i]); j++, dpa_fq++) {
+			for (j = 0; j < ARRAY_SIZE(ingress_fqs[i]); j++,
+					dpa_fq++) {
 				dpa_fq->fq_base	= ingress_fqs[i][j];
 				dpa_fq->net_dev	= net_dev;
-				ingress_fq = _dpa_fq_alloc(priv->dpa_fq_list + RX, dpa_fq, 0,
-							   QMAN_FQ_FLAG_NO_ENQUEUE,
-							   priv->channel, 7);
+				ingress_fq = _dpa_fq_alloc(
+						priv->dpa_fq_list + RX,
+						dpa_fq, ingress_fq_cfg[i][j],
+						QMAN_FQ_FLAG_NO_ENQUEUE,
+						priv->channel, 7);
 				if (IS_ERR(ingress_fq)) {
 					_errno = PTR_ERR(ingress_fq);
 					goto _return_dpa_fq_free;
@@ -2383,16 +2546,51 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 
 				ingress_fqids[i][j] = qman_fq_fqid(ingress_fq);
 
-				cpu_dev_dbg(dev, "%s:%s(): ingress_fqs[%s][%d] = %u\n",
-					    __file__, __func__, rtx[i], j, ingress_fqids[i][j]);
+				cpu_dev_dbg(dev,
+					"%s:%s(): ingress_fqs[%s][%d] = %u\n",
+					__file__, __func__, rtx[i], j,
+					ingress_fqids[i][j]);
+			}
+		}
+
+		/* Loop through the remaining fq assignments */
+		for (i = 2; i < num_rx_fqids; i++) {
+			for (j = 0; j < rx_fqids[2 * i + 1]; j++, dpa_fq++) {
+				uint32_t fqid =
+					rx_fqids[2 * i] ?
+					rx_fqids[2 * i] + j : 0;
+				int wq = fqid ? fqid % 8 : 7;
+
+				dpa_fq->fq_base = ingress_fqs[RX][1];
+				dpa_fq->net_dev	= net_dev;
+				ingress_fq = _dpa_fq_alloc(
+						priv->dpa_fq_list + RX,
+						dpa_fq, fqid,
+						QMAN_FQ_FLAG_NO_ENQUEUE,
+						priv->channel, wq);
+				if (IS_ERR(ingress_fq)) {
+					_errno = PTR_ERR(ingress_fq);
+					goto _return_dpa_fq_free;
+				}
+
+				cpu_dev_dbg(dev,
+					"%s:%s(): ingress_fqs[%d][%d] = %u\n",
+					__file__, __func__, i, j,
+					qman_fq_fqid(ingress_fq));
 			}
 		}
 
+		/* We only support 8 for now */
+		BUG_ON(tx_fqids[5] != 8);
+
 		for (i = 0; i < ARRAY_SIZE(priv->egress_fqs); i++, dpa_fq++) {
+			uint32_t fqid = tx_fqids[4] ? tx_fqids[4] + i : 0;
+
 			dpa_fq->fq_base	= _egress_fqs;
 			dpa_fq->net_dev	= net_dev;
 			priv->egress_fqs[i] = _dpa_fq_alloc(
-				priv->dpa_fq_list + TX, dpa_fq, 0, QMAN_FQ_FLAG_TO_DCPORTAL,
+				priv->dpa_fq_list + TX, dpa_fq, fqid,
+				QMAN_FQ_FLAG_TO_DCPORTAL,
 				fm_get_tx_port_channel(priv->mac_dev->port_dev[TX]), i);
 			if (IS_ERR(priv->egress_fqs[i])) {
 				_errno = PTR_ERR(priv->egress_fqs[i]);
@@ -2400,14 +2598,17 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 			}
 
 			cpu_dev_dbg(dev, "%s:%s(): egress_fqs[%d] = %u\n",
-				    __file__, __func__, i, qman_fq_fqid(priv->egress_fqs[i]));
+					__file__, __func__, i,
+					qman_fq_fqid(priv->egress_fqs[i]));
 		}
 
 		net_dev->mem_start	= priv->mac_dev->res->start;
 		net_dev->mem_end	= priv->mac_dev->res->end;
 
-		memcpy(net_dev->perm_addr, priv->mac_dev->addr, net_dev->addr_len);
-		memcpy(net_dev->dev_addr, priv->mac_dev->addr, net_dev->addr_len);
+		memcpy(net_dev->perm_addr, priv->mac_dev->addr,
+			net_dev->addr_len);
+		memcpy(net_dev->dev_addr, priv->mac_dev->addr,
+			net_dev->addr_len);
 
 		/* Set error FQs */
 		rx_port_param.errq	= ingress_fqids[RX][0];
@@ -2417,17 +2618,22 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 		rx_port_param.defq	= ingress_fqids[RX][1];
 		tx_port_param.defq	= ingress_fqids[TX][1];
 
-		rx_port_param.priv_data_size	= tx_port_param.priv_data_size	= 32;
-		rx_port_param.parse_results	= tx_port_param.parse_results	= true;
+		rx_port_param.priv_data_size =
+			 tx_port_param.priv_data_size = 32;
+		rx_port_param.parse_results =
+			tx_port_param.parse_results = true;
 
-		fm_set_rx_port_params(priv->mac_dev->port_dev[RX], &rx_port_param);
+		fm_set_rx_port_params(priv->mac_dev->port_dev[RX],
+			&rx_port_param);
 
 		/* Set PCD FQs */
 		rx_port_pcd_param.cb	= dpa_alloc_pcd_fqids;
 		rx_port_pcd_param.dev	= dev;
-		fm_port_pcd_bind(priv->mac_dev->port_dev[RX], &rx_port_pcd_param);
+		fm_port_pcd_bind(priv->mac_dev->port_dev[RX],
+			&rx_port_pcd_param);
 
-		fm_set_tx_port_params(priv->mac_dev->port_dev[TX], &tx_port_param);
+		fm_set_tx_port_params(priv->mac_dev->port_dev[TX],
+			&tx_port_param);
 	}
 
 	net_dev->features		|= DPA_NETIF_FEATURES;
@@ -2444,8 +2650,9 @@ static int __devinit __cold __attribute__((nonnull)) dpa_probe(struct of_device
 	_errno = register_netdev(net_dev);
 	if (unlikely(_errno < 0)) {
 		if (netif_msg_probe(priv))
-			cpu_dev_err(dev, "%s:%hu:%s(): register_netdev() = %d\n",
-				    __file__, __LINE__, __func__, _errno);
+			cpu_dev_err(dev,
+				"%s:%hu:%s(): register_netdev() = %d\n",
+				__file__, __LINE__, __func__, _errno);
 		goto _return_dpa_fq_free;
 	}
 
@@ -2478,9 +2685,11 @@ static const struct of_device_id dpa_match[] __devinitconst = {
 };
 MODULE_DEVICE_TABLE(of, dpa_match);
 
-static int __devinit __cold _dpa_probe(struct of_device *_of_dev, const struct of_device_id *match)
+static int __devinit __cold
+_dpa_probe(struct of_device *_of_dev, const struct of_device_id *match)
 {
-	return match == dpa_match ? dpa_init_probe(_of_dev) : dpa_probe(_of_dev);
+	return match ==
+		dpa_match ? dpa_init_probe(_of_dev) : dpa_probe(_of_dev);
 }
 
 static int __devexit __cold dpa_remove(struct of_device *of_dev)
@@ -2535,8 +2744,9 @@ static int __init __cold dpa_load(void)
 
 	_errno = of_register_platform_driver(&dpa_driver);
 	if (unlikely(_errno < 0)) {
-		cpu_pr_err(KBUILD_MODNAME ": %s:%hu:%s(): of_register_platform_driver() = %d\n",
-			   __file__, __LINE__, __func__, _errno);
+		cpu_pr_err(KBUILD_MODNAME
+			": %s:%hu:%s(): of_register_platform_driver() = %d\n",
+			__file__, __LINE__, __func__, _errno);
 		goto _return;
 	}
 
-- 
1.6.5.2

