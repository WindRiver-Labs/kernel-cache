From ca6698df1b6f35f6e0f88a63cc83c32d990a9639 Mon Sep 17 00:00:00 2001
From: Yongli He <yongli.he@windriver.com>
Date: Thu, 10 Dec 2009 21:35:26 -0800
Subject: [PATCH 2/7] fsl-p4080/smp: setup own start secondary

Create a guest OS specific wrhv_start_secondary, since the guest OS
has different requirements than a native secondary cpu startup.

In particular, the guest OS doesn't need the secondary cpu timer and
the guest doesn't need the decrementer initialization.

Signed-off-by: Yongli He <yongli.he@windriver.com>
---
 arch/powerpc/kernel/head_wrhv.S |    4 +-
 arch/powerpc/kernel/smp.c       |    6 ++-
 arch/powerpc/kernel/vbi/wrhv.c  |   97 +++++++++++++++++++++++++++++++++++++++
 3 files changed, 104 insertions(+), 3 deletions(-)

diff --git a/arch/powerpc/kernel/head_wrhv.S b/arch/powerpc/kernel/head_wrhv.S
index af6006c..604be90 100644
--- a/arch/powerpc/kernel/head_wrhv.S
+++ b/arch/powerpc/kernel/head_wrhv.S
@@ -1350,8 +1350,8 @@ __secondary_start:
 	/* Jump to start_secondary */
 	lis	r4,MSR_KERNEL@h
 	ori	r4,r4,MSR_KERNEL@l
-	lis	r3,start_secondary@h
-	ori	r3,r3,start_secondary@l
+	lis	r3,wrhv_start_secondary@h
+	ori	r3,r3,wrhv_start_secondary@l
 	mtspr	SPRN_SRR0,r3
 	mtspr	SPRN_SRR1,r4
 	sync
diff --git a/arch/powerpc/kernel/smp.c b/arch/powerpc/kernel/smp.c
index 8f26474..6256f29 100644
--- a/arch/powerpc/kernel/smp.c
+++ b/arch/powerpc/kernel/smp.c
@@ -73,7 +73,11 @@ EXPORT_PER_CPU_SYMBOL(cpu_core_map);
 /* SMP operations for this machine */
 struct smp_ops_t *smp_ops;
 
-static volatile unsigned int cpu_callin_map[NR_CPUS];
+#ifdef CONFIG_WRHV
+ volatile unsigned int cpu_callin_map[NR_CPUS];
+#else
+ static volatile unsigned int cpu_callin_map[NR_CPUS];
+#endif
 
 int smt_enabled_at_boot = 1;
 
diff --git a/arch/powerpc/kernel/vbi/wrhv.c b/arch/powerpc/kernel/vbi/wrhv.c
index e3d6cda..b7d5b41 100644
--- a/arch/powerpc/kernel/vbi/wrhv.c
+++ b/arch/powerpc/kernel/vbi/wrhv.c
@@ -115,6 +115,8 @@
 #include <linux/clocksource.h>
 #include <linux/hwtimer.h>
 
+#include <asm/cputhreads.h>
+
 static struct vb_config __wr_config;
 struct vb_config *wr_config;		/* TODO kernel relocation friendly ? */
 struct vb_control *wr_control;
@@ -1051,3 +1053,98 @@ int fsl8572_get_pci_intr_wrhv(struct pci_dev *dev)
 	return irq;
 }
 #endif /* CONFIG_WRHV_8572 & CONFIG_PCI*/
+
+#ifdef CONFIG_SMP
+extern struct smp_ops_t *smp_ops;
+extern volatile unsigned int cpu_callin_map[NR_CPUS];
+
+static void __devinit smp_store_cpu_info(int id)
+{
+	per_cpu(pvr, id) = get_pvr();
+}
+
+/* Must be called when no change can occur to cpu_present_map,
+ * i.e. during cpu online or offline.
+ */
+static struct device_node *cpu_to_l2cache(int cpu)
+{
+	struct device_node *np;
+	const phandle *php;
+	phandle ph;
+
+	if (!cpu_present(cpu))
+		return NULL;
+
+	np = of_get_cpu_node(cpu, NULL);
+	if (np == NULL)
+		return NULL;
+
+	php = of_get_property(np, "l2-cache", NULL);
+	if (php == NULL)
+		return NULL;
+	ph = *php;
+	of_node_put(np);
+
+	return of_find_node_by_phandle(ph);
+}
+
+
+/* Activate a secondary processor. */
+int __devinit wrhv_start_secondary(void *unused)
+{
+	unsigned int cpu = smp_processor_id();
+	struct device_node *l2_cache;
+	int i, base;
+
+	atomic_inc(&init_mm.mm_count);
+	current->active_mm = &init_mm;
+
+	smp_store_cpu_info(cpu);
+	preempt_disable();
+	cpu_callin_map[cpu] = 1;
+
+	smp_ops->setup_cpu(cpu);
+	if (smp_ops->take_timebase)
+		smp_ops->take_timebase();
+
+	if (system_state > SYSTEM_BOOTING)
+		snapshot_timebase();
+
+	ipi_call_lock();
+	cpu_set(cpu, cpu_online_map);
+	/* Update sibling maps */
+	base = cpu_first_thread_in_core(cpu);
+	for (i = 0; i < threads_per_core; i++) {
+		if (cpu_is_offline(base + i))
+			continue;
+		cpu_set(cpu, per_cpu(cpu_sibling_map, base + i));
+		cpu_set(base + i, per_cpu(cpu_sibling_map, cpu));
+
+		/* cpu_core_map should be a superset of
+		 * cpu_sibling_map even if we don't have cache
+		 * information, so update the former here, too.
+		 */
+		cpu_set(cpu, per_cpu(cpu_core_map, base +i));
+		cpu_set(base + i, per_cpu(cpu_core_map, cpu));
+	}
+	l2_cache = cpu_to_l2cache(cpu);
+	for_each_online_cpu(i) {
+		struct device_node *np = cpu_to_l2cache(i);
+		if (!np)
+			continue;
+		if (np == l2_cache) {
+			cpu_set(cpu, per_cpu(cpu_core_map, i));
+			cpu_set(i, per_cpu(cpu_core_map, cpu));
+		}
+		of_node_put(np);
+	}
+	of_node_put(l2_cache);
+	ipi_call_unlock();
+
+	local_irq_enable();
+
+	cpu_idle();
+	return 0;
+}
+
+#endif
-- 
1.6.5.2

