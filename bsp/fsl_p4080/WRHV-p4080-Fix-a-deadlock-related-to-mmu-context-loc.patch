From f89173089b189392790a72865c86bfa6a99fbdca Mon Sep 17 00:00:00 2001
From: Tiejun Chen <tiejun.chen@windriver.com>
Date: Fri, 5 Feb 2010 23:00:11 -0800
Subject: [PATCH 4/4] WRHV/p4080: Fix a deadlock related to mmu context lock

The mmu context lock will dead lock with the lock of run queue when:
CPU A: running in function switch_mm, then an interrupt raised and turned to get
       the run queue lock;
CPU B: hold the run queue lock, then call function switch_mm and try to get the
       mmu context lock.

Signed-off-by: Zhang Xiao <xiao.zhang@windriver.com>
Integrated-by: Tiejun Chen <tiejun.chen@windriver.com>
---
 arch/powerpc/include/asm/mmu_context.h |    5 +++--
 arch/powerpc/mm/mmu_context_32.c       |    7 +++----
 2 files changed, 6 insertions(+), 6 deletions(-)

diff --git a/arch/powerpc/include/asm/mmu_context.h b/arch/powerpc/include/asm/mmu_context.h
index a44e136..8df8064 100644
--- a/arch/powerpc/include/asm/mmu_context.h
+++ b/arch/powerpc/include/asm/mmu_context.h
@@ -169,18 +169,19 @@ static inline int init_new_context(struct task_struct *t, struct mm_struct *mm)
 static inline void destroy_context(struct mm_struct *mm)
 {
 	unsigned int id;
+	unsigned long flags;
 
 	if (mm->context.id == NO_CONTEXT)
 		return;
 
-	spin_lock(&context_lock);
+	spin_lock_irqsave(&context_lock, flags);
 	id = mm->context.id;
 	if (id != NO_CONTEXT) {
 		__clear_bit(id, context_map);
 		mm->context.id = NO_CONTEXT;
 		nr_free_contexts++;
 	}
-	spin_unlock(&context_lock);
+	spin_unlock_irqrestore(&context_lock, flags);
 }
 #else
 static inline void destroy_context(struct mm_struct *mm)
diff --git a/arch/powerpc/mm/mmu_context_32.c b/arch/powerpc/mm/mmu_context_32.c
index 27a8137..98978b1 100644
--- a/arch/powerpc/mm/mmu_context_32.c
+++ b/arch/powerpc/mm/mmu_context_32.c
@@ -128,9 +128,7 @@ static unsigned int steal_context_smp(unsigned int id)
 	/* This will happen if you have more CPUs than available contexts,
 	 * all we can do here is wait a bit and try again
 	 */
-	spin_unlock(&context_lock);
 	cpu_relax();
-	spin_lock(&context_lock);
 	goto again;
 }
 #endif  /* CONFIG_SMP */
@@ -167,9 +165,10 @@ void switch_mmu_context(struct mm_struct *prev,
 {
 	unsigned int id, cpu = smp_processor_id();
 	unsigned long *map;
+	unsigned long flags;
 
 	/* No lockless fast path .. yet */
-	spin_lock(&context_lock);
+	spin_lock_irqsave(&context_lock, flags);
 
 #ifdef CONFIG_SMP
 	/* Mark us active and the previous one not anymore */
@@ -234,7 +233,7 @@ void switch_mmu_context(struct mm_struct *prev,
 
 	/* Flick the MMU and release lock */
 	set_context(id, next->pgd);
-	spin_unlock(&context_lock);
+	spin_unlock_irqrestore(&context_lock, flags);
 }
 #else
 void
-- 
1.6.5.2

