From df2a6ce12e4d3e0e9df779e102b76c2d1fe60054 Mon Sep 17 00:00:00 2001
From: Tiejun Chen <tiejun.chen@windriver.com>
Date: Wed, 12 May 2010 16:39:49 +0800
Subject: [PATCH 09/15] WRHV/fsl_p4080: Restore BOOKE PTE

Restore BOOKE PTE since it's not necessary to use VMMU/64bit-PTE for
fsl_p4080.

Signed-off-by: Tiejun Chen <tiejun.chen@windriver.com>
---
 arch/powerpc/include/asm/page_32.h       |    4 ++--
 arch/powerpc/include/asm/pgalloc-32.h    |    2 +-
 arch/powerpc/include/asm/pgtable-ppc32.h |   12 ++++++------
 arch/powerpc/kvm/Kconfig                 |    9 ++++++++-
 4 files changed, 17 insertions(+), 10 deletions(-)

diff --git a/arch/powerpc/include/asm/page_32.h b/arch/powerpc/include/asm/page_32.h
index 9558b0c..9a6bd5a 100644
--- a/arch/powerpc/include/asm/page_32.h
+++ b/arch/powerpc/include/asm/page_32.h
@@ -13,7 +13,7 @@
 #define ARCH_KMALLOC_MINALIGN	L1_CACHE_BYTES
 #endif
 
-#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_PARAVIRT)
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_PARAVIRT_PTE)
 #define PTE_FLAGS_OFFSET	4	/* offset of PTE flags, in bytes */
 #else
 #define PTE_FLAGS_OFFSET	0
@@ -30,7 +30,7 @@
  * The basic type of a PTE - 64 bits for those CPUs with > 32 bit
  * physical addressing.
  */
-#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_PARAVIRT)
+#if defined(CONFIG_PTE_64BIT) || defined(CONFIG_PARAVIRT_PTE)
 typedef unsigned long long pte_basic_t;
 #else
 typedef unsigned long pte_basic_t;
diff --git a/arch/powerpc/include/asm/pgalloc-32.h b/arch/powerpc/include/asm/pgalloc-32.h
index f1b14d2..4099dff 100644
--- a/arch/powerpc/include/asm/pgalloc-32.h
+++ b/arch/powerpc/include/asm/pgalloc-32.h
@@ -20,7 +20,7 @@ extern void pgd_free(struct mm_struct *mm, pgd_t *pgd);
 #define __pmd_free_tlb(tlb,x,a)		do { } while (0)
 /* #define pgd_populate(mm, pmd, pte)      BUG() */
 
-#if !defined(CONFIG_BOOKE) || defined (CONFIG_PARAVIRT)
+#if !defined(CONFIG_BOOKE) || defined(CONFIG_PARAVIRT_PTE)
 #define pmd_populate_kernel(mm, pmd, pte)	\
 		(pmd_val(*(pmd)) = __pa(pte) | _PMD_PRESENT)
 #define pmd_populate(mm, pmd, pte)	\
diff --git a/arch/powerpc/include/asm/pgtable-ppc32.h b/arch/powerpc/include/asm/pgtable-ppc32.h
index f98fe3f..e42638a 100644
--- a/arch/powerpc/include/asm/pgtable-ppc32.h
+++ b/arch/powerpc/include/asm/pgtable-ppc32.h
@@ -112,7 +112,7 @@ extern int icache_44x_need_flush;
  * (hardware-defined) PowerPC PTE as closely as possible.
  */
 
-#if defined(CONFIG_PARAVIRT)
+#if defined(CONFIG_PARAVIRT_PTE)
 #include <asm/pv_pgtable-ppc32.h>
 #elif defined(CONFIG_40x)
 #include <asm/pte-40x.h>
@@ -120,7 +120,7 @@ extern int icache_44x_need_flush;
 #include <asm/pte-44x.h>
 #elif defined(CONFIG_FSL_BOOKE) && defined(CONFIG_PTE_64BIT)
 #include <asm/pte-book3e.h>
-#elif defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT)
+#elif defined(CONFIG_FSL_BOOKE) && !defined(CONFIG_PARAVIRT_PTE)
 #include <asm/pte-fsl-booke.h>
 #elif defined(CONFIG_8xx)
 #include <asm/pte-8xx.h>
@@ -171,7 +171,7 @@ extern void flush_hash_entry(struct mm_struct *mm, pte_t *ptep,
  * to properly flush the virtually tagged instruction cache of
  * those implementations.
  */
-#if !defined(CONFIG_PTE_64BIT) && !defined(CONFIG_PARAVIRT)
+#if !defined(CONFIG_PTE_64BIT) && !defined(CONFIG_PARAVIRT_PTE)
 static inline unsigned long pte_update(pte_t *p,
 				       unsigned long clr,
 				       unsigned long set)
@@ -200,7 +200,7 @@ static inline unsigned long pte_update(pte_t *p,
 #endif
 	return old;
 }
-#else /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT */
+#else /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT_PTE */
 static inline unsigned long long pte_update(pte_t *p,
 					    unsigned long clr,
 					    unsigned long set)
@@ -231,7 +231,7 @@ static inline unsigned long long pte_update(pte_t *p,
 #endif
 	return old;
 }
-#endif /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT */
+#endif /* CONFIG_PTE_64BIT && CONFIG_PARAVIRT_PTE */
 
 /*
  * 2.6 calls this without flushing the TLB entry; this is wrong
@@ -311,7 +311,7 @@ static inline void __ptep_set_access_flags(pte_t *ptep, pte_t entry)
  * handler).  On everything else the pmd contains the physical address
  * of the pte page.  -- paulus
  */
-#if !defined(CONFIG_BOOKE) || defined(CONFIG_PARAVIRT)
+#if !defined(CONFIG_BOOKE) || defined(CONFIG_PARAVIRT_PTE)
 #define pmd_page_vaddr(pmd)	\
 	((unsigned long) __va(pmd_val(pmd) & PAGE_MASK))
 #define pmd_page(pmd)		\
diff --git a/arch/powerpc/kvm/Kconfig b/arch/powerpc/kvm/Kconfig
index 60e1505..dc3df9b 100644
--- a/arch/powerpc/kvm/Kconfig
+++ b/arch/powerpc/kvm/Kconfig
@@ -26,7 +26,14 @@ config PARAVIRT
           over full virtualization.  However, when run without a hypervisor
           the kernel is theoretically slower and slightly larger.
 
-          CONFIG_PARAVIRT assume a E500 like core and use 64 bit PTE.
+          CONFIG_PARAVIRT assume a E500 like core.
+
+config PARAVIRT_PTE
+        bool "Enable 64 Bit PTE to support VMMU"
+        default n
+        depends on !X86_VOYAGER
+        help
+          CONFIG_PARAVIRT will use 64 bit PTE for VMMU.
 
 config PARAVIRT_CLOCK
         bool
-- 
1.6.5.2

