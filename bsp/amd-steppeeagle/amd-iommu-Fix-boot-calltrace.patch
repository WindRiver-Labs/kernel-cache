From 6ac122b3db112ecc8e3db8dd09126f151bdb99bb Mon Sep 17 00:00:00 2001
From: chunguang yang <chunguang.yang@windriver.com>
Date: Mon, 28 Sep 2015 14:25:35 +0800
Subject: [PATCH] amd-iommu: Fix boot calltrace

amd-iommu uses spinlock to lock irq table, so when used in
preempt-rt kernel, the following calltrace will appear if
it's called in atomic context.
preemption  is disabled  at  __irq_set_affinity, which is
a core kernel irq function. the set_affinity function is
amd bsp specific and try to get spinlock, so it better
to change lock in this bsp specific function.

amd_steppeeagle-wrs-linux/linux-windriver/3.10-r0/linux/kernel/rtmutex.c:797
[   25.799270] in_atomic(): 1, irqs_disabled(): 1, pid: 875, name: irqbalance
[   25.799284] Preemption disabled at:[<ffffffff810d1254>] __irq_set_affinity+0x34/0x80

[   25.799291] CPU: 1 PID: 875 Comm: irqbalance Not tainted 3.10.62-ltsi-rt55-WR6.0.0.0_preempt-rt #2
[   25.799294] Hardware name: To be filled by O.E.M. To be filled by O.E.M./Larne CRB, BIOS 4.6.5.4 05/18/2015
[   25.799301]  0000000000000100 ffff8801123a5d30 ffffffff8187bef4 ffff8801123a5d48
[   25.799306]  ffffffff8107a0cf ffffffff81e0cb00 ffff8801123a5d60 ffffffff81881260
[   25.799311]  ffff880112cf4740 ffff8801123a5d70 ffffffff8188148e ffff8801123a5dc0
[   25.799312] Call Trace:
[   25.799323]  [<ffffffff8187bef4>] dump_stack+0x19/0x1b
[   25.799331]  [<ffffffff8107a0cf>] __might_sleep+0xef/0x180
[   25.799337]  [<ffffffff81881260>] __rt_spin_lock+0x20/0x60
[   25.799342]  [<ffffffff8188148e>] rt_write_lock_irqsave+0xe/0x20
[   25.799349]  [<ffffffff816bc5b1>] get_irq_table+0x31/0x380
[   25.799354]  [<ffffffff816bcc8d>] set_affinity+0x4d/0x160
[   25.799362]  [<ffffffff816c1063>] set_remapped_irq_affinity+0x23/0x40
[   25.799366]  [<ffffffff810d0fdc>] irq_do_set_affinity+0x1c/0x60
[   25.799371]  [<ffffffff810d11b8>] irq_set_affinity_locked+0xd8/0x140
[   25.799375]  [<ffffffff810d1266>] __irq_set_affinity+0x46/0x80
[   25.799381]  [<ffffffff810d454c>] write_irq_affinity.isra.6+0xcc/0x100
[   25.799386]  [<ffffffff810d45b9>] irq_affinity_proc_write+0x19/0x20
[   25.799392]  [<ffffffff811ced3d>] proc_reg_write+0x3d/0x80
[   25.799400]  [<ffffffff8116e13a>] vfs_write+0xba/0x1e0
[   25.799405]  [<ffffffff8116ea89>] SyS_write+0x49/0xa0
[   25.799412]  [<ffffffff81882662>] system_call_fastpath+0x16/0x1b
Signed-off-by: chunguang yang <chunguang.yang@windriver.com>
---
 drivers/iommu/amd_iommu.c       |   54 +++++++++++++++++++-------------------
 drivers/iommu/amd_iommu_init.c  |    2 +-
 drivers/iommu/amd_iommu_types.h |    4 +-
 3 files changed, 30 insertions(+), 30 deletions(-)

diff --git a/drivers/iommu/amd_iommu.c b/drivers/iommu/amd_iommu.c
index dfb401c..38fe78c 100644
--- a/drivers/iommu/amd_iommu.c
+++ b/drivers/iommu/amd_iommu.c
@@ -62,7 +62,7 @@
  */
 #define AMD_IOMMU_PGSIZES	((~0xFFFUL) & ~(2ULL << 38))
 
-static DEFINE_RWLOCK(amd_iommu_devtable_lock);
+static DEFINE_RAW_SPINLOCK(amd_iommu_devtable_lock);
 
 /* A list of preallocated protection domains */
 static LIST_HEAD(iommu_pd_list);
@@ -1022,7 +1022,7 @@ static int iommu_queue_command_sync(struct amd_iommu *iommu,
 	WARN_ON(iommu->cmd_buf_size & CMD_BUFFER_UNINITIALIZED);
 
 again:
-	spin_lock_irqsave(&iommu->lock, flags);
+	raw_spin_lock_irqsave(&iommu->lock, flags);
 
 	head      = readl(iommu->mmio_base + MMIO_CMD_HEAD_OFFSET);
 	tail      = readl(iommu->mmio_base + MMIO_CMD_TAIL_OFFSET);
@@ -1037,7 +1037,7 @@ again:
 		build_completion_wait(&sync_cmd, (u64)&sem);
 		copy_cmd_to_buffer(iommu, &sync_cmd, tail);
 
-		spin_unlock_irqrestore(&iommu->lock, flags);
+		raw_spin_unlock_irqrestore(&iommu->lock, flags);
 
 		if ((ret = wait_on_sem(&sem)) != 0)
 			return ret;
@@ -1050,7 +1050,7 @@ again:
 	/* We need to sync now to make sure all commands are processed */
 	iommu->need_sync = sync;
 
-	spin_unlock_irqrestore(&iommu->lock, flags);
+	raw_spin_unlock_irqrestore(&iommu->lock, flags);
 
 	return 0;
 }
@@ -1875,14 +1875,14 @@ static u16 domain_id_alloc(void)
 	unsigned long flags;
 	int id;
 
-	write_lock_irqsave(&amd_iommu_devtable_lock, flags);
+	raw_spin_lock_irqsave(&amd_iommu_devtable_lock, flags);
 	id = find_first_zero_bit(amd_iommu_pd_alloc_bitmap, MAX_DOMAIN_ID);
 	BUG_ON(id == 0);
 	if (id > 0 && id < MAX_DOMAIN_ID)
 		__set_bit(id, amd_iommu_pd_alloc_bitmap);
 	else
 		id = 0;
-	write_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
+	raw_spin_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
 
 	return id;
 }
@@ -1891,10 +1891,10 @@ static void domain_id_free(int id)
 {
 	unsigned long flags;
 
-	write_lock_irqsave(&amd_iommu_devtable_lock, flags);
+	raw_spin_lock_irqsave(&amd_iommu_devtable_lock, flags);
 	if (id > 0 && id < MAX_DOMAIN_ID)
 		__clear_bit(id, amd_iommu_pd_alloc_bitmap);
-	write_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
+	raw_spin_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
 }
 
 static void free_pagetable(struct protection_domain *domain)
@@ -2317,9 +2317,9 @@ static int attach_device(struct device *dev,
 		dev_data->ats.qdep    = pci_ats_queue_depth(pdev);
 	}
 
-	write_lock_irqsave(&amd_iommu_devtable_lock, flags);
+	raw_spin_lock_irqsave(&amd_iommu_devtable_lock, flags);
 	ret = __attach_device(dev_data, domain);
-	write_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
+	raw_spin_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
 
 	/*
 	 * We might boot into a crash-kernel here. The crashed kernel
@@ -2380,9 +2380,9 @@ static void detach_device(struct device *dev)
 	domain   = dev_data->domain;
 
 	/* lock device table */
-	write_lock_irqsave(&amd_iommu_devtable_lock, flags);
+	raw_spin_lock_irqsave(&amd_iommu_devtable_lock, flags);
 	__detach_device(dev_data);
-	write_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
+	raw_spin_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
 
 	if (domain->flags & PD_IOMMUV2_MASK)
 		pdev_iommuv2_disable(to_pci_dev(dev));
@@ -2410,12 +2410,12 @@ static struct protection_domain *domain_for_device(struct device *dev)
 	if (dev_data->alias_data != NULL) {
 		struct iommu_dev_data *alias_data = dev_data->alias_data;
 
-		read_lock_irqsave(&amd_iommu_devtable_lock, flags);
+		raw_spin_lock_irqsave(&amd_iommu_devtable_lock, flags);
 		if (alias_data->domain != NULL) {
 			__attach_device(dev_data, alias_data->domain);
 			dom = alias_data->domain;
 		}
-		read_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
+		raw_spin_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
 	}
 
 	return dom;
@@ -3190,7 +3190,7 @@ static void cleanup_domain(struct protection_domain *domain)
 	struct iommu_dev_data *entry;
 	unsigned long flags;
 
-	write_lock_irqsave(&amd_iommu_devtable_lock, flags);
+	raw_spin_lock_irqsave(&amd_iommu_devtable_lock, flags);
 
 	while (!list_empty(&domain->dev_list)) {
 		entry = list_first_entry(&domain->dev_list,
@@ -3199,7 +3199,7 @@ static void cleanup_domain(struct protection_domain *domain)
 		atomic_set(&entry->bind, 0);
 	}
 
-	write_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
+	raw_spin_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
 }
 
 static void protection_domain_free(struct protection_domain *domain)
@@ -3909,7 +3909,7 @@ static struct irq_remap_table *get_irq_table(u16 devid, bool ioapic)
 	unsigned long flags;
 	u16 alias;
 
-	write_lock_irqsave(&amd_iommu_devtable_lock, flags);
+	raw_spin_lock_irqsave(&amd_iommu_devtable_lock, flags);
 
 	iommu = amd_iommu_rlookup_table[devid];
 	if (!iommu)
@@ -3934,7 +3934,7 @@ static struct irq_remap_table *get_irq_table(u16 devid, bool ioapic)
 		goto out;
 
 	/* Initialize table spin-lock */
-	spin_lock_init(&table->lock);
+	raw_spin_lock_init(&table->lock);
 
 	if (ioapic)
 		/* Keep the first 32 indexes free for IOAPIC interrupts */
@@ -3969,7 +3969,7 @@ out:
 	iommu_completion_wait(iommu);
 
 out_unlock:
-	write_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
+	raw_spin_unlock_irqrestore(&amd_iommu_devtable_lock, flags);
 
 	return table;
 }
@@ -3984,7 +3984,7 @@ static int alloc_irq_index(struct irq_cfg *cfg, u16 devid, int count)
 	if (!table)
 		return -ENODEV;
 
-	spin_lock_irqsave(&table->lock, flags);
+	raw_spin_lock_irqsave(&table->lock, flags);
 
 	/* Scan table for free entries */
 	for (c = 0, index = table->min_index;
@@ -4015,7 +4015,7 @@ static int alloc_irq_index(struct irq_cfg *cfg, u16 devid, int count)
 	index = -ENOSPC;
 
 out:
-	spin_unlock_irqrestore(&table->lock, flags);
+	raw_spin_unlock_irqrestore(&table->lock, flags);
 
 	return index;
 }
@@ -4029,9 +4029,9 @@ static int get_irte(u16 devid, int index, union irte *irte)
 	if (!table)
 		return -ENOMEM;
 
-	spin_lock_irqsave(&table->lock, flags);
+	raw_spin_lock_irqsave(&table->lock, flags);
 	irte->val = table->table[index];
-	spin_unlock_irqrestore(&table->lock, flags);
+	raw_spin_unlock_irqrestore(&table->lock, flags);
 
 	return 0;
 }
@@ -4050,9 +4050,9 @@ static int modify_irte(u16 devid, int index, union irte irte)
 	if (!table)
 		return -ENOMEM;
 
-	spin_lock_irqsave(&table->lock, flags);
+	raw_spin_lock_irqsave(&table->lock, flags);
 	table->table[index] = irte.val;
-	spin_unlock_irqrestore(&table->lock, flags);
+	raw_spin_unlock_irqrestore(&table->lock, flags);
 
 	iommu_flush_irt(iommu, devid);
 	iommu_completion_wait(iommu);
@@ -4074,9 +4074,9 @@ static void free_irte(u16 devid, int index)
 	if (!table)
 		return;
 
-	spin_lock_irqsave(&table->lock, flags);
+	raw_spin_lock_irqsave(&table->lock, flags);
 	table->table[index] = 0;
-	spin_unlock_irqrestore(&table->lock, flags);
+	raw_spin_unlock_irqrestore(&table->lock, flags);
 
 	iommu_flush_irt(iommu, devid);
 	iommu_completion_wait(iommu);
diff --git a/drivers/iommu/amd_iommu_init.c b/drivers/iommu/amd_iommu_init.c
index bf51abb..5c95031 100644
--- a/drivers/iommu/amd_iommu_init.c
+++ b/drivers/iommu/amd_iommu_init.c
@@ -1064,7 +1064,7 @@ static int __init init_iommu_one(struct amd_iommu *iommu, struct ivhd_header *h)
 {
 	int ret;
 
-	spin_lock_init(&iommu->lock);
+	raw_spin_lock_init(&iommu->lock);
 
 	/* Add IOMMU to internal data structures */
 	list_add_tail(&iommu->list, &amd_iommu_list);
diff --git a/drivers/iommu/amd_iommu_types.h b/drivers/iommu/amd_iommu_types.h
index 0285a21..de9e7f1 100644
--- a/drivers/iommu/amd_iommu_types.h
+++ b/drivers/iommu/amd_iommu_types.h
@@ -341,7 +341,7 @@ extern bool amd_iommu_iotlb_sup;
 #define IRQ_TABLE_ALIGNMENT	128
 
 struct irq_remap_table {
-	spinlock_t lock;
+	raw_spinlock_t lock;
 	unsigned min_index;
 	u32 *table;
 };
@@ -497,7 +497,7 @@ struct amd_iommu {
 	int index;
 
 	/* locks the accesses to the hardware */
-	spinlock_t lock;
+	raw_spinlock_t lock;
 
 	/* Pointer to PCI device of this IOMMU */
 	struct pci_dev *dev;
-- 
1.7.5.4

