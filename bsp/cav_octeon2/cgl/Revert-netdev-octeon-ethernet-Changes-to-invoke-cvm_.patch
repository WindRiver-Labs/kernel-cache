From 6450dc2af28e3882697dcbc69ffa5fb5be871f27 Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Thu, 15 Sep 2011 15:43:24 -0700
Subject: [PATCH 149/238] Revert "netdev: octeon-ethernet: Changes to invoke cvm_oct_enable_one_cpu() from worker thread."

Source: Cavium SDK 2.2-414

This reverts commit fda4db7bed11b44f310547a4b36cc216d01236c7.

Signed-off-by: David Daney <david.daney@cavium.com>
Integrated-by: Yang Shi <yang.shi@windriver.com>
---
 drivers/net/octeon/ethernet-napi.c   |    5 ++-
 drivers/net/octeon/ethernet-rx.c     |   45 +++++----------------------------
 drivers/net/octeon/ethernet.c        |   19 ++------------
 drivers/net/octeon/octeon-ethernet.h |    1 -
 4 files changed, 13 insertions(+), 57 deletions(-)

diff --git a/drivers/net/octeon/ethernet-napi.c b/drivers/net/octeon/ethernet-napi.c
index ed811f2..e25aa5c 100644
--- a/drivers/net/octeon/ethernet-napi.c
+++ b/drivers/net/octeon/ethernet-napi.c
@@ -127,9 +127,10 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 				counts.u64 = cvmx_read_csr(CVMX_POW_WQ_INT_CNTX(pow_receive_group));
 				backlog = counts.s.iq_cnt + counts.s.ds_cnt;
 			}
-			if (backlog > budget * cores_in_use && napi != NULL &&
+			if (backlog > budget * cores_in_use &&
+			    napi != NULL &&
 			    cores_in_use < core_state.baseline_cores)
-				queue_work(cvm_oct_enable_cpu_queue, &cvm_oct_enable_one_cpu_work);
+				cvm_oct_enable_one_cpu();
 		}
 
 		/*
diff --git a/drivers/net/octeon/ethernet-rx.c b/drivers/net/octeon/ethernet-rx.c
index 8f08edf..794178d 100644
--- a/drivers/net/octeon/ethernet-rx.c
+++ b/drivers/net/octeon/ethernet-rx.c
@@ -84,14 +84,6 @@ struct cvm_oct_core_state {
 	 * consistent with this lock.
 	 */
 	spinlock_t lock;
-	/*
-	 * When a decision is made to re-enable interrupts there could
-	 * be an entry in the work queue which could cause a CPU to be
-	 * enabled. No CPUs should be enabled till the first 
-         * interrupt happens again. This is used to keep track of this window  
-	 * and skip acting on any work queue entries during this period.
-	 */
-	int skip_enable_cpu_wqe;
 } ____cacheline_aligned_in_smp;
 
 static struct cvm_oct_core_state core_state __cacheline_aligned_in_smp;
@@ -110,11 +102,6 @@ static void cvm_oct_enable_one_cpu(void)
 
 	spin_lock_irqsave(&core_state.lock, flags);
 	/* ... if a CPU is available, Turn on NAPI polling for that CPU.  */
-	if (core_state.skip_enable_cpu_wqe) {
-		spin_unlock_irqrestore(&core_state.lock, flags);
-		goto out;
-	}
-
 	for_each_online_cpu(cpu) {
 		if (cvm_oct_napi[cpu].available > 0) {
 			cvm_oct_napi[cpu].available--;
@@ -132,16 +119,6 @@ out:
 	return;
 }
 
-
-
-static void cvm_oct_enable_one_cpu_worker(struct work_struct *work)
-{
-	cvm_oct_enable_one_cpu();
-}
-
-static DECLARE_WORK(cvm_oct_enable_one_cpu_work,
-		    &cvm_oct_enable_one_cpu_worker);
-
 static void cvm_oct_no_more_work(struct napi_struct *napi)
 {
 	struct cvm_napi_wrapper *nr = container_of(napi, struct cvm_napi_wrapper, napi);
@@ -156,13 +133,15 @@ static void cvm_oct_no_more_work(struct napi_struct *napi)
 	nr->available++;
 	BUG_ON(nr->available != 1);
 
+	spin_unlock_irqrestore(&core_state.lock, flags);
+
 	if (current_active == 0) {
 		/*
 		 * No more CPUs doing processing, enable interrupts so
 		 * we can start processing again when there is
 		 * something to do.
 		 */
-		core_state.skip_enable_cpu_wqe = 1;
+
 		if (OCTEON_IS_MODEL(OCTEON_CN68XX)) {
 			union cvmx_sso_wq_int_thrx int_thr;
 			int_thr.u64 = 0;
@@ -187,7 +166,6 @@ static void cvm_oct_no_more_work(struct napi_struct *napi)
 				       int_thr.u64);
 		}
 	}
-	spin_unlock_irqrestore(&core_state.lock, flags);
 }
 
 /**
@@ -220,21 +198,13 @@ static irqreturn_t cvm_oct_do_interrupt(int cpl, void *dev_id)
 	spin_lock_irqsave(&core_state.lock, flags);
 
 	/* ... and NAPI better not be running on this CPU.  */
-	if (cvm_oct_napi[cpu].available != 1) {
-		pr_err("BUG : CPU=%d available=%d \n", cpu,
-		       cvm_oct_napi[cpu].available);
-		BUG_ON(1);
-	}
-
+	BUG_ON(cvm_oct_napi[cpu].available != 1);
 	cvm_oct_napi[cpu].available--;
+
 	/* There better be cores available...  */
 	core_state.active_cores++;
-	if (core_state.active_cores > core_state.baseline_cores) {
-		pr_err("BUG : CPU=%d active_cores=%d baseline_cores =%d \n",
-		       cpu, core_state.active_cores, core_state.baseline_cores);
-		BUG_ON(1);
-	}
-	core_state.skip_enable_cpu_wqe = 0;
+	BUG_ON(core_state.active_cores > core_state.baseline_cores);
+
 	spin_unlock_irqrestore(&core_state.lock, flags);
 
 	cvm_oct_enable_napi(&cvm_oct_napi[cpu].napi);
@@ -397,7 +367,6 @@ void cvm_oct_rx_initialize(int num_wqe)
 	else
 		core_state.baseline_cores = num_online_cpus();
 
-	core_state.skip_enable_cpu_wqe = 0;
 	for_each_possible_cpu(i) {
 		cvm_oct_napi[i].available = 1;
 		netif_napi_add(dev_for_napi, &cvm_oct_napi[i].napi,
diff --git a/drivers/net/octeon/ethernet.c b/drivers/net/octeon/ethernet.c
index c64f8ca..b798b94 100644
--- a/drivers/net/octeon/ethernet.c
+++ b/drivers/net/octeon/ethernet.c
@@ -98,11 +98,6 @@ MODULE_PARM_DESC(rx_napi_weight, "The NAPI WEIGHT parameter.");
 struct workqueue_struct *cvm_oct_poll_queue;
 
 /**
- * cvm_oct_enable_cpu - Workqueue for enable cpu operations
- */
-struct workqueue_struct *cvm_oct_enable_cpu_queue;
-
-/**
  * cvm_oct_poll_queue_stopping - flag to indicate polling should stop.
  *
  * Set to one right before cvm_oct_poll_queue is destroyed.
@@ -775,16 +770,9 @@ static int __init cvm_oct_init_module(void)
 
 	cvmx_override_pko_queue_priority = cvm_oct_override_pko_queue_priority;
 
-	cvm_oct_poll_queue = create_singlethread_workqueue("oct-eth-wq1");
+	cvm_oct_poll_queue = create_singlethread_workqueue("octeon-ethernet");
 	if (cvm_oct_poll_queue == NULL) {
-		pr_err("oct-eth-wq1 : Cannot create workqueue");
-		rv = -ENOMEM;
-		goto err_cleanup;
-	}
-
-	cvm_oct_enable_cpu_queue = create_singlethread_workqueue("oct-eth-wq2");
-	if (cvm_oct_enable_cpu_queue == NULL) {
-		pr_err("oct-eth-wq2 : Cannot create workqueue");
+		pr_err("octeon-ethernet: Cannot create workqueue");
 		rv = -ENOMEM;
 		goto err_cleanup;
 	}
@@ -1063,8 +1051,7 @@ static void __exit cvm_oct_cleanup_module(void)
 	cvm_oct_rx_shutdown1();
 
 	destroy_workqueue(cvm_oct_poll_queue);
-	if (cvm_oct_enable_cpu_queue != 0)
-		destroy_workqueue(cvm_oct_enable_cpu_queue);
+
 	cvm_oct_proc_shutdown();
 
 	/* Free the HW pools */
diff --git a/drivers/net/octeon/octeon-ethernet.h b/drivers/net/octeon/octeon-ethernet.h
index 6bc3401..4a642ea 100644
--- a/drivers/net/octeon/octeon-ethernet.h
+++ b/drivers/net/octeon/octeon-ethernet.h
@@ -147,7 +147,6 @@ extern struct octeon_ethernet *cvm_oct_by_pkind[];
 extern struct octeon_ethernet *cvm_oct_by_srio_mbox[4][4];
 
 extern struct workqueue_struct *cvm_oct_poll_queue;
-extern struct workqueue_struct *cvm_oct_enable_cpu_queue;
 extern atomic_t cvm_oct_poll_queue_stopping;
 
 extern int max_rx_cpus;
-- 
1.7.0

