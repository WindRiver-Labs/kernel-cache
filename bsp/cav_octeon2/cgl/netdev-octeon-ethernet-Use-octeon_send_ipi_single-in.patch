From ad6b3fd6de3234824bcf7badda83ddf6337644ef Mon Sep 17 00:00:00 2001
From: David Daney <david.daney@cavium.com>
Date: Fri, 16 Sep 2011 10:26:33 -0700
Subject: [PATCH 151/238] netdev: octeon-ethernet: Use octeon_send_ipi_single() instead of smp_call_function_single()

Source: Cavium SDK 2.2-414

Since octeon_send_ipi_single() is lockless, deadlocks are impossible.

This should really fix the issue of:

cvm_oct_enable_one_cpu() uses smp_call_function_single() and this
cannot be invoked from softirq. Invoking it from softirq could cause
deadlocks.  The deadlock was seen it tests with tasklist_lock but
could have been any other rw lock.

       CPU X                                   CPU Y

1. Acquires read_lock(&tasklist_lock)

2. Gets interrupted and                  2. spins trying to do
   calls smp_call_function_single           write_lock_irq(&tasklist_lock)
   on CPU Y

3. Calls smp_call_function_single on CPU Z

smp_call_function_single use a per CPU data structure, the second
smp_call_function_single will wait until the remote call from the
first smp_call_function_single is completed. In the deadlock scenario
above the first remote call will never get a chance to execute as CPU
Y has interrupts disabled and waiting for CPU X to release the read
lock.  CPU X is spinning waiting for the first remote call from
smp_call_function_single to complete.

Signed-off-by: David Daney <david.daney@cavium.com>
Integrated-by: Yang Shi <yang.shi@windriver.com>
---
 drivers/net/octeon/ethernet-rx.c |   23 ++++++++++++++---------
 1 files changed, 14 insertions(+), 9 deletions(-)

diff --git a/drivers/net/octeon/ethernet-rx.c b/drivers/net/octeon/ethernet-rx.c
index 794178d..03d35ca 100644
--- a/drivers/net/octeon/ethernet-rx.c
+++ b/drivers/net/octeon/ethernet-rx.c
@@ -88,15 +88,17 @@ struct cvm_oct_core_state {
 
 static struct cvm_oct_core_state core_state __cacheline_aligned_in_smp;
 
-static void cvm_oct_enable_napi(void *arg)
+static int cvm_oct_enable_one_message;
+
+static void cvm_oct_enable_napi(void)
 {
-	struct napi_struct *napi = arg;
-	napi_schedule(napi);
+	int cpu = smp_processor_id();
+
+	napi_schedule(&cvm_oct_napi[cpu].napi);
 }
 
 static void cvm_oct_enable_one_cpu(void)
 {
-	int v;
 	int cpu;
 	unsigned long flags;
 
@@ -107,10 +109,7 @@ static void cvm_oct_enable_one_cpu(void)
 			cvm_oct_napi[cpu].available--;
 			core_state.active_cores++;
 			spin_unlock_irqrestore(&core_state.lock, flags);
-			v = smp_call_function_single(cpu, cvm_oct_enable_napi,
-						     &cvm_oct_napi[cpu].napi, 0);
-			if (v)
-				panic("Can't enable NAPI.");
+			octeon_send_ipi_single(cpu, cvm_oct_enable_one_message);
 			goto out;
 		}
 	}
@@ -207,7 +206,7 @@ static irqreturn_t cvm_oct_do_interrupt(int cpl, void *dev_id)
 
 	spin_unlock_irqrestore(&core_state.lock, flags);
 
-	cvm_oct_enable_napi(&cvm_oct_napi[cpu].napi);
+	cvm_oct_enable_napi();
 
 	return IRQ_HANDLED;
 }
@@ -353,6 +352,10 @@ void cvm_oct_rx_initialize(int num_wqe)
 	if (list_empty(&cvm_oct_list))
 		panic("No net_devices were allocated.");
 
+	cvm_oct_enable_one_message = octeon_request_ipi_handler(cvm_oct_enable_napi);
+	if (cvm_oct_enable_one_message < 0)
+		panic("cvm_oct_rx_initialize: No IPI handler handles available\n");
+
 	if (OCTEON_IS_MODEL(OCTEON_CN68XX))
 		cvm_oct_napi_poll = cvm_oct_napi_poll_68;
 	else
@@ -487,6 +490,8 @@ void cvm_oct_rx_shutdown0(void)
 	/* Free the interrupt handler */
 	free_irq(OCTEON_IRQ_WORKQ0 + pow_receive_group, &cvm_oct_list);
 
+	octeon_release_ipi_handler(cvm_oct_enable_one_message);
+
 	/* Shutdown all of the NAPIs */
 	for_each_possible_cpu(i)
 		netif_napi_del(&cvm_oct_napi[i].napi);
-- 
1.7.0

