From b56c0c6030509e7874f3b7f1da08ec186abab28b Mon Sep 17 00:00:00 2001
From: Yang Shi <yang.shi@windriver.com>
Date: Wed, 16 Nov 2011 10:48:23 -0800
Subject: [PATCH 162/236] net: octeon: Coding style update from SDK 2.2

Source: Cavium SDK 2.2-414

Misc coding style correct from SDK 2.2

Signed-off-by: Yang Shi <yang.shi@windriver.com>
---
 drivers/net/octeon/ethernet-defines.h    |    2 +-
 drivers/net/octeon/ethernet-mdio.c       |  127 +++++++++++++++---------------
 drivers/net/octeon/ethernet-mem.c        |   32 ++++----
 drivers/net/octeon/ethernet-mem.h        |    2 -
 drivers/net/octeon/ethernet-napi.c       |  114 +++++++++++++++++++--------
 drivers/net/octeon/ethernet-proc.c       |    2 +-
 drivers/net/octeon/ethernet-rx.c         |   21 +++---
 drivers/net/octeon/ethernet-srio.c       |   17 ++--
 drivers/net/octeon/ethernet-tx.c         |    3 -
 drivers/net/octeon/ethernet-util.h       |    9 ++-
 drivers/net/octeon/ethernet-xmit.c       |   80 ++++++++++++------
 drivers/net/octeon/ethernet.c            |   12 ++--
 drivers/net/octeon/octeon-ethernet.h     |   10 +--
 drivers/net/octeon/octeon-pow-ethernet.c |    8 +-
 14 files changed, 254 insertions(+), 185 deletions(-)

diff --git a/drivers/net/octeon/ethernet-defines.h b/drivers/net/octeon/ethernet-defines.h
index 3828344..61edd39 100644
--- a/drivers/net/octeon/ethernet-defines.h
+++ b/drivers/net/octeon/ethernet-defines.h
@@ -118,7 +118,7 @@
 /* Maximum number of SKBs to try to free per xmit packet. */
 #define MAX_OUT_QUEUE_DEPTH 1000
 
-#define FAU_NUM_PACKET_BUFFERS_TO_FREE (CVMX_FAU_REG_END - sizeof(uint32_t))
+#define FAU_NUM_PACKET_BUFFERS_TO_FREE (CVMX_FAU_REG_END - sizeof(u32))
 
 #define TOTAL_NUMBER_OF_PORTS       (CVMX_PIP_NUM_INPUT_PORTS+1)
 
diff --git a/drivers/net/octeon/ethernet-mdio.c b/drivers/net/octeon/ethernet-mdio.c
index b7b3b5e..d183024 100644
--- a/drivers/net/octeon/ethernet-mdio.c
+++ b/drivers/net/octeon/ethernet-mdio.c
@@ -138,8 +138,7 @@ static int cvm_oct_ioctl_hwtstamp(struct net_device *dev,
 			unsigned long long clock_comp = (NSEC_PER_SEC << 32) /
 				octeon_get_io_clock_rate();
 			if (!ptp.s.ptp_en)
-				cvmx_write_csr(CVMX_MIO_PTP_CLOCK_COMP,
-					       clock_comp);
+				cvmx_write_csr(CVMX_MIO_PTP_CLOCK_COMP, clock_comp);
 			pr_info("PTP Clock: Using sclk reference at %lld Hz\n",
 				(NSEC_PER_SEC << 32) / clock_comp);
 		} else {
@@ -173,71 +172,71 @@ static int cvm_oct_ioctl_hwtstamp(struct net_device *dev,
 		return -EINVAL;
 
 	switch (config.tx_type) {
-	case HWTSTAMP_TX_OFF:
-		priv->tx_timestamp_sw = 0;
-		priv->tx_timestamp_hw = 0;
-		break;
-	case HWTSTAMP_TX_ON:
-		if (have_hw_timestamps)
-			priv->tx_timestamp_hw = 1;
-		else
-			priv->tx_timestamp_sw = 1;
-		break;
-	default:
-		return -ERANGE;
+		case HWTSTAMP_TX_OFF:
+			priv->tx_timestamp_sw = 0;
+			priv->tx_timestamp_hw = 0;
+			break;
+		case HWTSTAMP_TX_ON:
+			if (have_hw_timestamps)
+				priv->tx_timestamp_hw = 1;
+			else
+				priv->tx_timestamp_sw = 1;
+			break;
+		default:
+			return -ERANGE;
 	}
 
 	switch (config.rx_filter) {
-	case HWTSTAMP_FILTER_NONE:
-		priv->rx_timestamp_hw = 0;
-		priv->rx_timestamp_sw = 0;
-		if (have_hw_timestamps) {
-			union cvmx_gmxx_rxx_frm_ctl gmxx_rxx_frm_ctl;
-			union cvmx_pip_prt_cfgx pip_prt_cfgx;
-
-			gmxx_rxx_frm_ctl.u64 = cvmx_read_csr(CVMX_GMXX_RXX_FRM_CTL(priv->interface_port, priv->interface));
-			gmxx_rxx_frm_ctl.s.ptp_mode = 0;
-			cvmx_write_csr(CVMX_GMXX_RXX_FRM_CTL(priv->interface_port, priv->interface), gmxx_rxx_frm_ctl.u64);
-
-			pip_prt_cfgx.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(priv->ipd_pkind));
-			pip_prt_cfgx.s.skip = 0;
-			cvmx_write_csr(CVMX_PIP_PRT_CFGX(priv->ipd_pkind), pip_prt_cfgx.u64);
-		}
-		break;
-	case HWTSTAMP_FILTER_ALL:
-	case HWTSTAMP_FILTER_SOME:
-	case HWTSTAMP_FILTER_PTP_V1_L4_EVENT:
-	case HWTSTAMP_FILTER_PTP_V1_L4_SYNC:
-	case HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:
-	case HWTSTAMP_FILTER_PTP_V2_L4_EVENT:
-	case HWTSTAMP_FILTER_PTP_V2_L4_SYNC:
-	case HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:
-	case HWTSTAMP_FILTER_PTP_V2_L2_EVENT:
-	case HWTSTAMP_FILTER_PTP_V2_L2_SYNC:
-	case HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:
-	case HWTSTAMP_FILTER_PTP_V2_EVENT:
-	case HWTSTAMP_FILTER_PTP_V2_SYNC:
-	case HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:
-		if (have_hw_timestamps)
-			priv->rx_timestamp_hw = 1;
-		else
-			priv->rx_timestamp_sw = 1;
-		config.rx_filter = HWTSTAMP_FILTER_ALL;
-		if (have_hw_timestamps) {
-			union cvmx_gmxx_rxx_frm_ctl gmxx_rxx_frm_ctl;
-			union cvmx_pip_prt_cfgx pip_prt_cfgx;
-
-			gmxx_rxx_frm_ctl.u64 = cvmx_read_csr(CVMX_GMXX_RXX_FRM_CTL(priv->interface_port, priv->interface));
-			gmxx_rxx_frm_ctl.s.ptp_mode = 1;
-			cvmx_write_csr(CVMX_GMXX_RXX_FRM_CTL(priv->interface_port, priv->interface), gmxx_rxx_frm_ctl.u64);
-
-			pip_prt_cfgx.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(priv->ipd_pkind));
-			pip_prt_cfgx.s.skip = 8;
-			cvmx_write_csr(CVMX_PIP_PRT_CFGX(priv->ipd_pkind), pip_prt_cfgx.u64);
-		}
-		break;
-	default:
-		return -ERANGE;
+		case HWTSTAMP_FILTER_NONE:
+			priv->rx_timestamp_hw = 0;
+			priv->rx_timestamp_sw = 0;
+			if (have_hw_timestamps) {
+				union cvmx_gmxx_rxx_frm_ctl gmxx_rxx_frm_ctl;
+				union cvmx_pip_prt_cfgx pip_prt_cfgx;
+
+				gmxx_rxx_frm_ctl.u64 = cvmx_read_csr(CVMX_GMXX_RXX_FRM_CTL(priv->interface_port, priv->interface));
+				gmxx_rxx_frm_ctl.s.ptp_mode = 0;
+				cvmx_write_csr(CVMX_GMXX_RXX_FRM_CTL(priv->interface_port, priv->interface), gmxx_rxx_frm_ctl.u64);
+
+				pip_prt_cfgx.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(priv->ipd_pkind));
+				pip_prt_cfgx.s.skip = 0;
+				cvmx_write_csr(CVMX_PIP_PRT_CFGX(priv->ipd_pkind), pip_prt_cfgx.u64);
+			}
+			break;
+		case HWTSTAMP_FILTER_ALL:
+		case HWTSTAMP_FILTER_SOME:
+		case HWTSTAMP_FILTER_PTP_V1_L4_EVENT:
+		case HWTSTAMP_FILTER_PTP_V1_L4_SYNC:
+		case HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:
+		case HWTSTAMP_FILTER_PTP_V2_L4_EVENT:
+		case HWTSTAMP_FILTER_PTP_V2_L4_SYNC:
+		case HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:
+		case HWTSTAMP_FILTER_PTP_V2_L2_EVENT:
+		case HWTSTAMP_FILTER_PTP_V2_L2_SYNC:
+		case HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:
+		case HWTSTAMP_FILTER_PTP_V2_EVENT:
+		case HWTSTAMP_FILTER_PTP_V2_SYNC:
+		case HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:
+			if (have_hw_timestamps)
+				priv->rx_timestamp_hw = 1;
+			else
+				priv->rx_timestamp_sw = 1;
+			config.rx_filter = HWTSTAMP_FILTER_ALL;
+			if (have_hw_timestamps) {
+				union cvmx_gmxx_rxx_frm_ctl gmxx_rxx_frm_ctl;
+				union cvmx_pip_prt_cfgx pip_prt_cfgx;
+
+				gmxx_rxx_frm_ctl.u64 = cvmx_read_csr(CVMX_GMXX_RXX_FRM_CTL(priv->interface_port, priv->interface));
+				gmxx_rxx_frm_ctl.s.ptp_mode = 1;
+				cvmx_write_csr(CVMX_GMXX_RXX_FRM_CTL(priv->interface_port, priv->interface), gmxx_rxx_frm_ctl.u64);
+
+				pip_prt_cfgx.u64 = cvmx_read_csr(CVMX_PIP_PRT_CFGX(priv->ipd_pkind));
+				pip_prt_cfgx.s.skip = 8;
+				cvmx_write_csr(CVMX_PIP_PRT_CFGX(priv->ipd_pkind), pip_prt_cfgx.u64);
+			}
+			break;
+		default:
+			return -ERANGE;
 	}
 
 	if (copy_to_user(rq->ifr_data, &config, sizeof(config)))
diff --git a/drivers/net/octeon/ethernet-mem.c b/drivers/net/octeon/ethernet-mem.c
index adf68cc..31cdabe 100644
--- a/drivers/net/octeon/ethernet-mem.c
+++ b/drivers/net/octeon/ethernet-mem.c
@@ -32,6 +32,7 @@
 #include <asm/octeon/cvmx-fpa.h>
 
 #include "ethernet-defines.h"
+#include "ethernet-util.h"
 
 #if USE_32BIT_SHARED
 #include <asm/octeon/cvmx-bootmem.h>
@@ -52,16 +53,19 @@ static struct kmem_cache *cvm_oct_kmem_1024;
 static int cvm_oct_fill_hw_skbuff(int pool, int size, int elements)
 {
 	int freed = elements;
+	int padding = 128 + sizeof(void *) + NET_SKB_PAD - 1;
 	while (freed) {
-
-		struct sk_buff *skb = dev_alloc_skb(size + 256);
+		int extra_reserve;
+		unsigned char *desired_data;
+		struct sk_buff *skb = alloc_skb(size + padding, GFP_ATOMIC);
 		if (unlikely(skb == NULL)) {
 			pr_warning("Failed to allocate skb for hardware pool %d\n", pool);
 			break;
 		}
-
-		skb_reserve(skb, 256 - (((unsigned long)skb->data) & 0x7f));
-		*(struct sk_buff **)(skb->data - sizeof(void *)) = skb;
+		desired_data = (unsigned char *)((unsigned long)(skb->data + padding) & ~0x7fUl);
+		extra_reserve = desired_data - skb->data;
+		skb_reserve(skb, extra_reserve);
+		*(struct sk_buff **)(skb->data - NET_SKB_PAD - sizeof(void *)) = skb;
 		cvmx_fpa_free(skb->data, pool, DONT_WRITEBACK(size / 128));
 		freed--;
 	}
@@ -81,8 +85,7 @@ static void cvm_oct_free_hw_skbuff(int pool, int size, int elements)
 	do {
 		memory = cvmx_fpa_alloc(pool);
 		if (memory) {
-			struct sk_buff *skb =
-			    *(struct sk_buff **)(memory - sizeof(void *));
+			struct sk_buff *skb = *cvm_oct_packet_to_skb(memory);
 			elements--;
 			dev_kfree_skb(skb);
 		}
@@ -108,14 +111,14 @@ static int cvm_oct_fill_hw_memory(int pool, int size, int elements)
 	int freed = elements;
 
 	if (USE_32BIT_SHARED) {
-		extern uint64_t octeon_reserve32_memory;
+		extern u64 octeon_reserve32_memory;
 		memory = cvmx_bootmem_alloc_range(elements*size, 128, octeon_reserve32_memory,
 			    octeon_reserve32_memory + (CONFIG_CAVIUM_RESERVE32<<20) - 1);
 
 		if (memory == NULL)
 			panic("Unable to allocate %u bytes for FPA pool %d\n", elements*size, pool);
 
-		printk(KERN_INFO "Memory range %p - %p reserved for hardware\n",
+		printk("Memory range %p - %p reserved for hardware\n",
 			memory, memory + elements*size - 1);
 
 		while (freed) {
@@ -135,8 +138,7 @@ static int cvm_oct_fill_hw_memory(int pool, int size, int elements)
 				break;
 			}
 		} else if (size == 1024) {
-			memory = kmem_cache_alloc(cvm_oct_kmem_1024,
-						  GFP_KERNEL);
+			memory = kmem_cache_alloc(cvm_oct_kmem_1024, GFP_KERNEL);
 			if (unlikely(memory == NULL)) {
 				pr_warning("Unable to allocate %u bytes for FPA pool %d\n",
 					elements * size, pool);
@@ -161,7 +163,7 @@ static void cvm_oct_free_hw_memory(int pool, int size, int elements)
 {
 	char *fpa;
 	if (USE_32BIT_SHARED) {
-		printk(KERN_WARNING "Warning: 32 shared memory is not freeable\n");
+		printk("Warning: 32 shared memory is not freeable\n");
 		return;
 	}
 	do {
@@ -240,15 +242,13 @@ static int __init cvm_oct_mem_init(void)
 	if (USE_32BIT_SHARED)
 		goto out;
 
-	cvm_oct_kmem_128 = kmem_cache_create("octeon_ethernet-128",
-					     128, 128, 0, NULL);
+	cvm_oct_kmem_128 = kmem_cache_create("octeon_ethernet-128", 128, 128, 0, NULL);
 	if (!cvm_oct_kmem_128) {
 		r = -ENOMEM;
 		goto out;
 	}
 
-	cvm_oct_kmem_1024 = kmem_cache_create("octeon_ethernet-1024",
-					      1024, 128, 0, NULL);
+	cvm_oct_kmem_1024 = kmem_cache_create("octeon_ethernet-1024", 1024, 128, 0, NULL);
 	if (!cvm_oct_kmem_1024) {
 		r = -ENOMEM;
 		goto err;
diff --git a/drivers/net/octeon/ethernet-mem.h b/drivers/net/octeon/ethernet-mem.h
index ecd0d6a..89cdda4 100644
--- a/drivers/net/octeon/ethernet-mem.h
+++ b/drivers/net/octeon/ethernet-mem.h
@@ -29,5 +29,3 @@ int cvm_oct_mem_fill_fpa(int pool, int size, int elements);
 void cvm_oct_mem_empty_fpa(int pool, int size, int elements);
 void cvm_oct_mem_cleanup(void);
 void cvm_oct_mem_uninit(void);
-void cvm_oct_mem_cleanup(void);
-void cvm_oct_mem_uninit(void);
diff --git a/drivers/net/octeon/ethernet-napi.c b/drivers/net/octeon/ethernet-napi.c
index e25aa5c..c5e8593 100644
--- a/drivers/net/octeon/ethernet-napi.c
+++ b/drivers/net/octeon/ethernet-napi.c
@@ -46,11 +46,11 @@
 static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 {
 	const int	coreid = cvmx_get_core_num();
-	uint64_t	old_group_mask;
-	uint64_t	old_scratch;
+	u64		old_group_mask;
+	u64		old_scratch;
 	int		rx_count = 0;
-	int		did_work_request = 0;
-	int		packet_not_copied;
+	bool		did_work_request = false;
+	bool		packet_copied;
 
 	char		*p = (char *)cvm_oct_by_pkind;
 	/* Prefetch cvm_oct_device since we know we need it soon */
@@ -79,7 +79,7 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 
 	if (USE_ASYNC_IOBDMA) {
 		cvmx_pow_work_request_async(CVMX_SCR_SCRATCH, CVMX_POW_NO_WAIT);
-		did_work_request = 1;
+		did_work_request = true;
 	}
 
 	while (rx_count < budget) {
@@ -87,9 +87,13 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 		struct sk_buff **pskb = NULL;
 		struct octeon_ethernet *priv;
 		enum cvm_oct_callback_result callback_result;
-		int skb_in_hw;
+		bool skb_in_hw;
 		cvmx_wqe_t *work;
 		int port;
+		unsigned int segments;
+		int packets_to_replace = 0;
+		unsigned int packet_len;
+		union cvmx_buf_ptr  packet_ptr;
 
 		if (USE_ASYNC_IOBDMA && did_work_request)
 			work = cvmx_pow_work_response_async(CVMX_SCR_SCRATCH);
@@ -97,17 +101,17 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 			work = cvmx_pow_work_request_sync(CVMX_POW_NO_WAIT);
 
 		prefetch(work);
-		did_work_request = 0;
+		did_work_request = false;
 
 		if (unlikely(work == NULL))
 			break;
-
-		pskb = (struct sk_buff **)(cvm_oct_get_buffer_ptr(work->packet_ptr) - sizeof(void *));
+		packet_ptr = work->packet_ptr;
+		pskb = cvm_oct_packet_to_skb(cvm_oct_get_buffer_ptr(packet_ptr));
 		prefetch(pskb);
 
 		if (USE_ASYNC_IOBDMA && rx_count < (budget - 1)) {
 			cvmx_pow_work_request_async_nocheck(CVMX_SCR_SCRATCH, CVMX_POW_NO_WAIT);
-			did_work_request = 1;
+			did_work_request = true;
 		}
 
 		if (rx_count == 0) {
@@ -141,21 +145,21 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 			struct octeon_ethernet *priv;
 			union skb_shared_tx *shtx;
 			int packet_qos = work->word0.raw.unused;
-			skb = (struct sk_buff *)work->packet_ptr.u64;
+			skb = (struct sk_buff *)packet_ptr.u64;
 			priv = netdev_priv(skb->dev);
 			if (!netif_running(skb->dev))
 				netif_wake_queue(skb->dev);
 			shtx = skb_tx(skb);
 			if (unlikely(shtx->hardware)) {
 				if (priv->tx_timestamp_hw) {
-					uint64_t ns = *(uint64_t *)work->packet_data;
+					u64 ns = *(u64 *)work->packet_data;
 					struct skb_shared_hwtstamps ts;
 					ts.syststamp = cvm_oct_ptp_to_ktime(ns);
 					ts.hwtstamp = ns_to_ktime(ns);
 					skb_tstamp_tx(skb, &ts);
 				}
 				if (priv->tx_timestamp_sw) {
-					uint64_t ns = *(uint64_t *)work->packet_data;
+					u64 ns = *(u64 *)work->packet_data;
 					struct skb_shared_hwtstamps ts;
 					ts.syststamp = ns_to_ktime(ns);
 					ts.hwtstamp = ns_to_ktime(0);
@@ -174,8 +178,8 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 			cvmx_fau_atomic_add32(priv->tx_queue[packet_qos].fau, -1);
 			continue;
 		}
-
-		skb_in_hw = USE_SKBUFFS_IN_HW && work->word2.s.bufs == 1;
+		segments = work->word2.s.bufs;
+		skb_in_hw = USE_SKBUFFS_IN_HW && segments > 0;
 		if (likely(skb_in_hw)) {
 			skb = *pskb;
 			prefetch(&skb->head);
@@ -200,19 +204,64 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 		 * in the FPA pool and the packet fits in a single
 		 * buffer.
 		 */
+		packet_len = work->word1.len;
 		if (likely(skb_in_hw)) {
-			skb->data = phys_to_virt(work->packet_ptr.s.addr);
+			skb->data = phys_to_virt(packet_ptr.s.addr);
 			prefetch(skb->data);
-			skb->len = work->word1.len;
-			skb_set_tail_pointer(skb, skb->len);
-			packet_not_copied = 1;
+			skb->len = packet_len;
+			packets_to_replace = segments;
+			if (likely(segments == 1)) {
+				skb_set_tail_pointer(skb, skb->len);
+			} else {
+				struct sk_buff *current_skb = skb;
+				struct sk_buff *next_skb = NULL;
+				unsigned int segment_size;
+				bool first_frag = true;
+
+				skb_frag_list_init(skb);
+				/* Multi-segment packet. */
+				for (;;) {
+					/*
+					 * Octeon Errata PKI-100: The segment size is
+					 * wrong. Until it is fixed, calculate the
+					 * segment size based on the packet pool
+					 * buffer size. When it is fixed, the
+					 * following line should be replaced with this
+					 * one: int segment_size =
+					 * segment_ptr.s.size;
+					 */
+					segment_size = CVMX_FPA_PACKET_POOL_SIZE -
+						(packet_ptr.s.addr - (((packet_ptr.s.addr >> 7) - packet_ptr.s.back) << 7));
+					if (segment_size > packet_len)
+						segment_size = packet_len;
+					if (!first_frag)
+						current_skb->len = segment_size;
+					skb_set_tail_pointer(current_skb, segment_size);
+					packet_len -= segment_size;
+					segments--;
+					if (segments == 0)
+						break;
+					packet_ptr = *(union cvmx_buf_ptr *)phys_to_virt(packet_ptr.s.addr - 8);
+					next_skb = *cvm_oct_packet_to_skb(cvm_oct_get_buffer_ptr(packet_ptr));
+					if (first_frag) {
+						skb_frag_add_head(current_skb, next_skb);
+					} else {
+						current_skb->next = next_skb;
+						next_skb->next = NULL;
+					}
+					current_skb = next_skb;
+					first_frag = false;
+					current_skb->data = phys_to_virt(packet_ptr.s.addr);
+				}
+
+			}
+			packet_copied = false;
 		} else {
-			int len = work->word1.len;
 			/*
 			 * We have to copy the packet. First allocate
 			 * an skbuff for it.
 			 */
-			skb = dev_alloc_skb(len);
+			skb = dev_alloc_skb(packet_len);
 			if (!skb) {
 				DEBUGPRINT("Port %d failed to allocate skbuff, packet dropped\n",
 					   port);
@@ -224,8 +273,8 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 			 * Check if we've received a packet that was
 			 * entirely stored in the work entry.
 			 */
-			if (unlikely(work->word2.s.bufs == 0)) {
-				uint8_t *ptr = work->packet_data;
+			if (unlikely(segments == 0)) {
+				u8 *ptr = work->packet_data;
 
 				if (likely(!work->word2.s.not_IP)) {
 					/*
@@ -237,10 +286,9 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 					else
 						ptr += 6;
 				}
-				memcpy(skb_put(skb, len), ptr, len);
+				memcpy(skb_put(skb, packet_len), ptr, packet_len);
 				/* No packet buffers to free */
 			} else {
-				int segments = work->word2.s.bufs;
 				union cvmx_buf_ptr segment_ptr = work->packet_ptr;
 
 				while (segments--) {
@@ -264,17 +312,17 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 					 * Don't copy more than what
 					 * is left in the packet.
 					 */
-					if (segment_size > len)
-						segment_size = len;
+					if (segment_size > packet_len)
+						segment_size = packet_len;
 					/* Copy the data into the packet */
 					memcpy(skb_put(skb, segment_size),
 					       phys_to_virt(segment_ptr.s.addr),
 					       segment_size);
-					len -= segment_size;
+					packet_len -= segment_size;
 					segment_ptr = next_ptr;
 				}
 			}
-			packet_not_copied = 0;
+			packet_copied = true;
 		}
 
 		if (CVM_OCT_NAPI_HAS_CN68XX_SSO) {
@@ -315,7 +363,7 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 				}
 				if (priv->rx_timestamp_hw) {
 					/* The first 8 bytes are the timestamp */
-					uint64_t ns = *(uint64_t*)skb->data;
+					u64 ns = *(u64 *)skb->data;
 					struct skb_shared_hwtstamps *ts;
 					ts = skb_hwtstamps(skb);
 					ts->hwtstamp = ns_to_ktime(ns);
@@ -353,7 +401,7 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 						 * need to free the
 						 * skbuff
 						 */
-						if (USE_SKBUFFS_IN_HW && likely(packet_not_copied)) {
+						if (USE_SKBUFFS_IN_HW && likely(!packet_copied)) {
 							/*
 							 * We can't free the skbuff since its data is
 							 * the same as the work. In this case we don't
@@ -399,13 +447,13 @@ static int CVM_OCT_NAPI_POLL(struct napi_struct *napi, int budget)
 			 * Check to see if the skbuff and work share
 			 * the same packet buffer.
 			 */
-			if (USE_SKBUFFS_IN_HW && likely(packet_not_copied)) {
+			if (USE_SKBUFFS_IN_HW && likely(!packet_copied)) {
 				/*
 				 * This buffer needs to be replaced,
 				 * increment the number of buffers we
 				 * need to free by one.
 				 */
-				cvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 1);
+				cvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, packets_to_replace);
 				cvmx_fpa_free(work, CVMX_FPA_WQE_POOL, DONT_WRITEBACK(1));
 			} else {
 				cvm_oct_free_work(work);
diff --git a/drivers/net/octeon/ethernet-proc.c b/drivers/net/octeon/ethernet-proc.c
index e9da7cb..1bb540f 100644
--- a/drivers/net/octeon/ethernet-proc.c
+++ b/drivers/net/octeon/ethernet-proc.c
@@ -46,7 +46,7 @@
 static unsigned long long cvm_oct_stats_read_switch(struct mii_bus *mii_bus, int phy_id, int offset)
 {
 	mii_bus->write(mii_bus, phy_id, 0, 0x1d, 0xcc00 | offset);
-	return ((uint64_t)mii_bus->read(mii_bus, phy_id, 0, 0x1e)<<16) | (uint64_t)mii_bus->read(mii_bus, phy_id, 0, 0x1f);
+	return ((u64)mii_bus->read(mii_bus, phy_id, 0, 0x1e)<<16) | (u64)mii_bus->read(mii_bus, phy_id, 0, 0x1f);
 }
 
 static int cvm_oct_stats_switch_show(struct octeon_ethernet *priv, struct seq_file *m, void *v)
diff --git a/drivers/net/octeon/ethernet-rx.c b/drivers/net/octeon/ethernet-rx.c
index 1e1fb73..1f65383 100644
--- a/drivers/net/octeon/ethernet-rx.c
+++ b/drivers/net/octeon/ethernet-rx.c
@@ -257,7 +257,7 @@ static inline int cvm_oct_check_rcv_error(cvmx_wqe_t *work)
 		gmxx_rxx_frm_ctl.u64 = cvmx_read_csr(CVMX_GMXX_RXX_FRM_CTL(index, interface));
 		if (gmxx_rxx_frm_ctl.s.pre_chk == 0) {
 
-			uint8_t *ptr = phys_to_virt(work->packet_ptr.s.addr);
+			u8 *ptr = phys_to_virt(work->packet_ptr.s.addr);
 			int i = 0;
 
 			while (i < work->word1.len - 1) {
@@ -308,26 +308,27 @@ static inline int cvm_oct_check_rcv_error(cvmx_wqe_t *work)
  *
  * @return ktime_t
  */
-static ktime_t cvm_oct_ptp_to_ktime(uint64_t ptptime)
+static ktime_t cvm_oct_ptp_to_ktime(u64 ptptime)
 {
 	ktime_t ktimebase;
-	uint64_t ptpbase;
+	u64 ptpbase;
 	unsigned long flags;
 
 	local_irq_save(flags);
-	/* Fill the icache with the code */
-	ktime_get_real();
-	/* Flush all pending operations */
-	CVMX_SYNC;
-	/* Read the time and PTP clock as close together as possible. It is
-	   important that this sequence take the same amount of time to
-	   reduce jitter */
+        /* Fill the icache with the code */
+        ktime_get_real();
+        /* Flush all pending operations */
+        CVMX_SYNC;
+        /* Read the time and PTP clock as close together as possible. It is
+            important that this sequence take the same amount of time to
+            reduce jitter */
 	ktimebase = ktime_get_real();
 	ptpbase = octeon_read_ptp_csr(CVMX_MIO_PTP_CLOCK_HI);
 	local_irq_restore(flags);
 
 	return ktime_sub_ns(ktimebase, ptpbase - ptptime);
 }
+
 #undef CVM_OCT_NAPI_68
 #include "ethernet-napi.c"
 
diff --git a/drivers/net/octeon/ethernet-srio.c b/drivers/net/octeon/ethernet-srio.c
index 68791b2..a08ef13 100644
--- a/drivers/net/octeon/ethernet-srio.c
+++ b/drivers/net/octeon/ethernet-srio.c
@@ -93,7 +93,7 @@ int cvm_oct_srio_change_mtu(struct net_device *dev, int new_mtu)
 	 * 1 byte and 4096-14 bytes.
 	 */
 	if ((new_mtu < 1) || (new_mtu > 4096 - 14)) {
-		printk(KERN_WARNING "%s: MTU must be between %d and %d.\n", dev->name, 1, 4096-14);
+		printk("%s: MTU must be between %d and %d.\n", dev->name, 1, 4096-14);
 		return -EINVAL;
 	}
 	dev->mtu = new_mtu;
@@ -112,7 +112,7 @@ int cvm_oct_xmit_srio(struct sk_buff *skb, struct net_device *dev)
 {
 	struct octeon_ethernet *priv = netdev_priv(dev);
 	cvmx_srio_tx_message_header_t tx_header;
-	uint64_t dest_mac;
+	u64 dest_mac;
 
 	if (unlikely(skb->len > 4096)) {
 		dev_kfree_skb(skb);
@@ -139,7 +139,7 @@ int cvm_oct_xmit_srio(struct sk_buff *skb, struct net_device *dev)
 	}
 
 	/* Extract the destination MAC address from the packet */
-	dest_mac = *(uint64_t *)skb->data >> 16;
+	dest_mac = *(u64 *)skb->data >> 16;
 
 	/* If this is a broadcast/multicast we must manually send to everyone */
 	if (dest_mac>>40) {
@@ -160,7 +160,7 @@ int cvm_oct_xmit_srio(struct sk_buff *skb, struct net_device *dev)
 			new_skb = skb_copy(skb, GFP_ATOMIC);
 			if (new_skb) {
 				tx_header.s.did = rdev->destid;
-				*(uint64_t *)__skb_push(new_skb, 8) = tx_header.u64;
+				*(u64 *)__skb_push(new_skb, 8) = tx_header.u64;
 				cvm_oct_xmit(new_skb, dev);
 			} else {
 				DEBUGPRINT("%s: SKB allocation failed\n", dev->name);
@@ -175,7 +175,7 @@ int cvm_oct_xmit_srio(struct sk_buff *skb, struct net_device *dev)
 		return NETDEV_TX_OK;
 	} else {
 		/* Use the low two bytes of the destination MAC as the SRIO destination */
-		//tx_header.s.did = *(uint16_t *)(skb->data + 4);
+//		tx_header.s.did = *(u16 *)(skb->data + 4);
 		tx_header.s.did = *(u8 *)(skb->data + 5);
 		if (unlikely(skb_headroom(skb) < 8)) {
 			struct sk_buff *new_skb = skb_copy(skb, GFP_ATOMIC);
@@ -189,7 +189,7 @@ int cvm_oct_xmit_srio(struct sk_buff *skb, struct net_device *dev)
 
 		dev->stats.tx_packets++;
 		dev->stats.tx_bytes += skb->len;
-		*(uint64_t *)__skb_push(skb, 8) = tx_header.u64;
+		*(u64 *)__skb_push(skb, 8) = tx_header.u64;
 		return cvm_oct_xmit(skb, dev);
 	}
 }
@@ -205,7 +205,7 @@ int cvm_oct_srio_init(struct net_device *dev)
 {
 	struct octeon_ethernet *priv = netdev_priv(dev);
 	int srio_port = (priv->ipd_port - 40) >> 1;
-	uint32_t devid;
+	u32 devid;
 	struct sockaddr sa;
 	cvmx_sriox_status_reg_t srio_status_reg;
 
@@ -218,8 +218,7 @@ int cvm_oct_srio_init(struct net_device *dev)
 	if (!srio_status_reg.s.access)
 		return 0;
 
-	cvmx_srio_config_read32(srio_port, 0, -1, 1, 0,
-				CVMX_SRIOMAINTX_PRI_DEV_ID(srio_port), &devid);
+	cvmx_srio_config_read32(srio_port, 0, -1, 1, 0, CVMX_SRIOMAINTX_PRI_DEV_ID(srio_port), &devid);
 
 	sa.sa_data[0] = 0;
 	sa.sa_data[1] = 0;
diff --git a/drivers/net/octeon/ethernet-tx.c b/drivers/net/octeon/ethernet-tx.c
index 2b6486a..65aab1c 100644
--- a/drivers/net/octeon/ethernet-tx.c
+++ b/drivers/net/octeon/ethernet-tx.c
@@ -51,9 +51,6 @@
 #include "ethernet-tx.h"
 #include "ethernet-util.h"
 
-
-#define CVM_OCT_SKB_CB(skb)	((u64 *)((skb)->cb))
-
 /*
  * You can define GET_SKBUFF_QOS() to override how the skbuff output
  * function determines which output queue is used. The default
diff --git a/drivers/net/octeon/ethernet-util.h b/drivers/net/octeon/ethernet-util.h
index 22244ca..c275113 100644
--- a/drivers/net/octeon/ethernet-util.h
+++ b/drivers/net/octeon/ethernet-util.h
@@ -24,10 +24,11 @@
  * This file may also be available under a different license from Cavium.
  * Contact Cavium Networks for more information
 *********************************************************************/
+#include <linux/skbuff.h>
 
 #include <asm/octeon/cvmx-pip.h>
 
-#define DEBUGPRINT(format, ...) do { if (printk_ratelimit())		\
+#define DEBUGPRINT(format, ...) do { if (printk_ratelimit()) 		\
 					printk(format, ##__VA_ARGS__);	\
 				} while (0)
 
@@ -41,3 +42,9 @@ static inline void *cvm_oct_get_buffer_ptr(union cvmx_buf_ptr pd)
 {
 	return phys_to_virt(((pd.s.addr >> 7) - pd.s.back) << 7);
 }
+
+static inline struct sk_buff **cvm_oct_packet_to_skb(void *packet)
+{
+	char *p = packet;
+	return (struct sk_buff **)(p - NET_SKB_PAD - sizeof(void *));
+}
diff --git a/drivers/net/octeon/ethernet-xmit.c b/drivers/net/octeon/ethernet-xmit.c
index e7282e0..2edd476 100644
--- a/drivers/net/octeon/ethernet-xmit.c
+++ b/drivers/net/octeon/ethernet-xmit.c
@@ -47,16 +47,18 @@ int
 CVM_OCT_XMIT
 (struct sk_buff *skb, struct net_device *dev)
 {
+	struct sk_buff *skb_tmp;
 	cvmx_pko_command_word0_t pko_command;
 	union cvmx_buf_ptr hw_buffer;
-	uint64_t old_scratch;
-	uint64_t old_scratch2;
+	u64 old_scratch;
+	u64 old_scratch2;
 	int qos;
 	int i;
+	int frag_count;
 	enum {QUEUE_HW, QUEUE_WQE, QUEUE_DROP} queue_type;
 	struct octeon_ethernet *priv = netdev_priv(dev);
-	int32_t queue_depth;
-	int32_t buffers_to_free;
+	s32 queue_depth;
+	s32 buffers_to_free;
 	unsigned long flags;
 	cvmx_wqe_t *work = NULL;
 #if REUSE_SKBUFFS_WITHOUT_FREE
@@ -109,11 +111,15 @@ CVM_OCT_XMIT
 					       priv->tx_queue[qos].fau, 1);
 	}
 
+	frag_count = 0;
+	if (skb_has_frags(skb))
+		skb_walk_frags(skb, skb_tmp)
+			frag_count++;
 	/*
-	 * We have space for 6 segment pointers, If there will be more
+	 * We have space for 12 segment pointers, If there will be more
 	 * than that, we must linearize.
 	 */
-	if (unlikely(skb_shinfo(skb)->nr_frags > 5)) {
+	if (unlikely(skb_shinfo(skb)->nr_frags + frag_count > 11)) {
 		if (unlikely(__skb_linearize(skb))) {
 			queue_type = QUEUE_DROP;
 			goto skip_xmit;
@@ -138,6 +144,12 @@ CVM_OCT_XMIT
 			gmx_prt_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(priv->interface_port, priv->interface));
 			if (gmx_prt_cfg.s.duplex == 0) {
 				int add_bytes = 64 - skb->len;
+				if (skb_shinfo(skb)->nr_frags || frag_count) {
+					if (unlikely(__skb_linearize(skb))) {
+						queue_type = QUEUE_DROP;
+						goto skip_xmit;
+					}
+				}
 				if ((skb_tail_pointer(skb) + add_bytes) <= skb_end_pointer(skb))
 					memset(__skb_put(skb, add_bytes), 0, add_bytes);
 			}
@@ -157,24 +169,38 @@ CVM_OCT_XMIT
 
 	/* Build the PKO buffer pointer */
 	hw_buffer.u64 = 0;
-	if (skb_shinfo(skb)->nr_frags == 0) {
-		hw_buffer.s.addr = XKPHYS_TO_PHYS((u64)skb->data);
+	if (skb_shinfo(skb)->nr_frags == 0 && frag_count == 0) {
+		hw_buffer.s.addr = virt_to_phys(skb->data);
 		hw_buffer.s.pool = 0;
 		hw_buffer.s.size = skb->len;
 	} else {
-		hw_buffer.s.addr = XKPHYS_TO_PHYS((u64)skb->data);
+		u64 *hw_buffer_list;
+		work = cvmx_fpa_alloc(CVMX_FPA_TX_WQE_POOL);
+		if (unlikely(!work)) {
+			DEBUGPRINT("%s: Failed WQE allocate\n", dev->name);
+			queue_type = QUEUE_DROP;
+			goto skip_xmit;
+		}
+		hw_buffer_list = (u64 *)work->packet_data;
+		hw_buffer.s.addr = virt_to_phys(skb->data);
 		hw_buffer.s.pool = 0;
 		hw_buffer.s.size = skb_headlen(skb);
-		CVM_OCT_SKB_CB(skb)[0] = hw_buffer.u64;
+		hw_buffer_list[0] = hw_buffer.u64;
 		for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
 			struct skb_frag_struct *fs = skb_shinfo(skb)->frags + i;
-			hw_buffer.s.addr = XKPHYS_TO_PHYS((u64)(page_address(fs->page) + fs->page_offset));
+			hw_buffer.s.addr = virt_to_phys((u8 *)page_address(fs->page) + fs->page_offset);
 			hw_buffer.s.size = fs->size;
-			CVM_OCT_SKB_CB(skb)[i + 1] = hw_buffer.u64;
+			hw_buffer_list[i + 1] = hw_buffer.u64;
+		}
+		skb_walk_frags(skb, skb_tmp) {
+			hw_buffer.s.addr = virt_to_phys(skb_tmp->data);
+			hw_buffer.s.size = skb_tmp->len;
+			hw_buffer_list[i + 1] = hw_buffer.u64;
+			i++;
 		}
-		hw_buffer.s.addr = XKPHYS_TO_PHYS((u64)CVM_OCT_SKB_CB(skb));
+		hw_buffer.s.addr = virt_to_phys(hw_buffer_list);
 		hw_buffer.s.size = skb_shinfo(skb)->nr_frags + 1;
-		pko_command.s.segs = skb_shinfo(skb)->nr_frags + 1;
+		pko_command.s.segs = hw_buffer.s.size;
 		pko_command.s.gather = 1;
 		goto dont_put_skbuff_in_hw;
 	}
@@ -194,7 +220,7 @@ CVM_OCT_XMIT
 	if (unlikely(priv->tx_timestamp_sw || priv->tx_timestamp_hw))
 		goto dont_put_skbuff_in_hw;
 
-	fpa_head = skb->head + 256 - ((unsigned long)skb->head & 0x7f);
+	fpa_head = (unsigned char*)((unsigned long)(skb->head + 128 + sizeof(void *) + NET_SKB_PAD - 1) & ~0x7fUl);
 	if (unlikely(skb->data < fpa_head)) {
 		/*
 		 * printk("TX buffer beginning can't meet FPA
@@ -252,7 +278,7 @@ CVM_OCT_XMIT
 	pko_command.s.dontfree = 0;
 
 	hw_buffer.s.back = ((unsigned long)skb->data >> 7) - ((unsigned long)fpa_head >> 7);
-	*(struct sk_buff **)(fpa_head - sizeof(void *)) = skb;
+	*(struct sk_buff **)(fpa_head - NET_SKB_PAD - sizeof(void *)) = skb;
 
 	/*
 	 * The skbuff will be reused without ever being freed. We must
@@ -322,11 +348,13 @@ dont_put_skbuff_in_hw:
 		queue_type = QUEUE_HW;
 
 	if (queue_type == QUEUE_WQE) {
-		work = cvmx_fpa_alloc(CVMX_FPA_TX_WQE_POOL);
-		if (unlikely(!work)) {
-			DEBUGPRINT("%s: Failed WQE allocate\n", dev->name);
-			queue_type = QUEUE_DROP;
-			goto skip_xmit;
+		if (!work) {
+			work = cvmx_fpa_alloc(CVMX_FPA_TX_WQE_POOL);
+			if (unlikely(!work)) {
+				DEBUGPRINT("%s: Failed WQE allocate\n", dev->name);
+				queue_type = QUEUE_DROP;
+				goto skip_xmit;
+			}
 		}
 
 		pko_command.s.rsp = 1;
@@ -339,15 +367,13 @@ dont_put_skbuff_in_hw:
 		 */
 		pko_command.s.reg0 = 0;
 		work->word0.u64 = 0;
-		work->word0.raw.unused = (uint8_t)qos;
+		work->word0.raw.unused = (u8)qos;
 
 		work->word1.u64 = 0;
 		work->word1.tag_type = CVMX_POW_TAG_TYPE_NULL;
 		work->word1.tag = 0;
 		work->word2.u64 = 0;
 		work->word2.s.software = 1;
-		cvmx_wqe_set_port(work, priv->ipd_port);
-		cvmx_wqe_set_qos(work, ((~priv->ipd_port) & 7));
 		cvmx_wqe_set_grp(work, pow_receive_group);
 		work->packet_ptr.u64 = (unsigned long)skb;
 	}
@@ -358,14 +384,14 @@ dont_put_skbuff_in_hw:
 
 	/* Send the packet to the output queue */
 	if (queue_type == QUEUE_WQE) {
-		uint64_t word2 = virt_to_phys(work);
+		u64 word2 = virt_to_phys(work);
 		if (priv->tx_timestamp_sw) {
 			/* The first 8 bytes work->packet_data will get the timestamp */
-			*(uint64_t *)work->packet_data = ktime_to_ns(ktime_get_real());
+			*(u64 *)work->packet_data = ktime_to_ns(ktime_get_real());
 		}
 		if (priv->tx_timestamp_hw) {
 			/* The first 8 bytes work->packet_data will get the timestamp */
-			*(uint64_t *)work->packet_data = 0;
+			*(u64 *)work->packet_data = 0;
 			word2 |= 1ull<<40; /* Bit 40 controls timestamps */
 		}
 		if (unlikely(cvmx_pko_send_packet_finish3_pkoid(priv->pko_port,
diff --git a/drivers/net/octeon/ethernet.c b/drivers/net/octeon/ethernet.c
index b798b94..c980eb8 100644
--- a/drivers/net/octeon/ethernet.c
+++ b/drivers/net/octeon/ethernet.c
@@ -424,10 +424,10 @@ static int cvm_oct_common_set_mac_address(struct net_device *dev, void *addr)
 
 	if (priv->has_gmx_regs) {
 		int i;
-		uint8_t *ptr = addr;
-		uint64_t mac = 0;
+		u8 *ptr = addr;
+		u64 mac = 0;
 		for (i = 0; i < 6; i++)
-			mac = (mac << 8) | (uint64_t) (ptr[i + 2]);
+			mac = (mac << 8) | (u64) (ptr[i + 2]);
 
 		gmx_cfg.u64 =
 		    cvmx_read_csr(CVMX_GMXX_PRTX_CFG(priv->interface_port, priv->interface));
@@ -470,7 +470,7 @@ int cvm_oct_common_init(struct net_device *dev)
 		random_ether_addr(sa.sa_data);
 
 	if (priv->num_tx_queues) {
-		dev->features |= NETIF_F_SG;
+		dev->features |= NETIF_F_SG | NETIF_F_FRAGLIST;
 		if (USE_HW_TCPUDP_CHECKSUM)
 			dev->features |= NETIF_F_IP_CSUM;
 	}
@@ -656,7 +656,7 @@ extern void octeon_mdiobus_force_mod_depencency(void);
 static int num_devices_extra_wqe;
 #define PER_DEVICE_EXTRA_WQE (MAX_OUT_QUEUE_DEPTH)
 
-static void cvm_oct_override_pko_queue_priority(int pko_port, uint64_t priorities[16])
+static void cvm_oct_override_pko_queue_priority(int pko_port, u64 priorities[16])
 {
 	int i;
 
@@ -876,7 +876,7 @@ static int __init cvm_oct_init_module(void)
 
 			for (qos = 0; qos < priv->num_tx_queues; qos++) {
 				priv->tx_queue[qos].queue = base_queue + qos;
-				fau = fau - sizeof(uint32_t);
+				fau = fau - sizeof(u32);
 				priv->tx_queue[qos].fau = fau;
 				cvmx_fau_atomic_write32(priv->tx_queue[qos].fau, 0);
 			}
diff --git a/drivers/net/octeon/octeon-ethernet.h b/drivers/net/octeon/octeon-ethernet.h
index 4a642ea..5d0671d 100644
--- a/drivers/net/octeon/octeon-ethernet.h
+++ b/drivers/net/octeon/octeon-ethernet.h
@@ -74,7 +74,7 @@ struct octeon_ethernet {
 	int                     num_tx_queues;
 
 	/* SRIO ports add this header for the SRIO block */
-	uint64_t                srio_tx_header;
+	u64 srio_tx_header;
 
 	struct {
 		/* PKO hardware queue for the port */
@@ -88,7 +88,7 @@ struct octeon_ethernet {
 	struct mii_bus *mii_bus;
 	unsigned int last_link;
 	/* Last negotiated link state */
-	uint64_t link_info;
+	u64 link_info;
 	/* Called periodically to check link status */
 	void (*poll) (struct net_device *dev);
 	struct delayed_work	port_periodic_work;
@@ -125,12 +125,6 @@ extern int cvm_oct_srio_set_mac_address(struct net_device *dev, void *addr);
 extern int cvm_oct_srio_change_mtu(struct net_device *dev, int new_mtu);
 extern struct net_device_stats *cvm_oct_srio_get_stats(struct net_device *dev);
 
-extern int cvm_oct_srio_init(struct net_device *dev);
-extern int cvm_oct_xmit_srio(struct sk_buff *skb, struct net_device *dev);
-extern int cvm_oct_srio_set_mac_address(struct net_device *dev, void *addr);
-extern int cvm_oct_srio_change_mtu(struct net_device *dev, int new_mtu);
-extern struct net_device_stats *cvm_oct_srio_get_stats(struct net_device *dev);
-
 extern int cvm_oct_common_init(struct net_device *dev);
 extern void cvm_oct_common_uninit(struct net_device *dev);
 
diff --git a/drivers/net/octeon/octeon-pow-ethernet.c b/drivers/net/octeon/octeon-pow-ethernet.c
index 35e9eeb..331912c 100644
--- a/drivers/net/octeon/octeon-pow-ethernet.c
+++ b/drivers/net/octeon/octeon-pow-ethernet.c
@@ -26,7 +26,7 @@
 
 #define VIRTUAL_PORT    63	/* Value to put in work->ipprt */
 
-#define DEBUGPRINT(format, ...) do { if (printk_ratelimit())		\
+#define DEBUGPRINT(format, ...) do { if (printk_ratelimit()) 		\
 					printk(format, ##__VA_ARGS__);	\
 				} while (0)
 
@@ -606,7 +606,7 @@ static int __init octeon_pow_mod_init(void)
 	/* Setup is complete, create the virtual ethernet devices */
 	octeon_pow_oct_dev = alloc_etherdev(sizeof(struct octeon_pow));
 	if (octeon_pow_oct_dev == NULL) {
-		pr_err(DEV_NAME "ERROR: Failed to allocate ethernet device\n");
+		pr_err(DEV_NAME " ERROR: Failed to allocate ethernet device\n");
 		return -1;
 	}
 
@@ -619,11 +619,11 @@ static int __init octeon_pow_mod_init(void)
 	priv->tx_mask = broadcast_groups;
 
 	/* Spin waiting for another core to setup all the hardware */
-	printk(KERN_DEBUG "Waiting for another core to setup the IPD hardware...");
+	printk("Waiting for another core to setup the IPD hardware...");
 	while ((cvmx_read_csr(CVMX_IPD_CTL_STATUS) & 1) == 0)
 		mdelay(100);
 
-	printk(KERN_INFO "Done\n");
+	printk("Done\n");
 
 	/* Read the configured size of the FPA packet buffers. This way we
 	   don't need changes if someone chooses to use a different buffer size */
-- 
1.7.0

