From e0b18b588ec46dc554da40adac0c92eaffe9bf46 Mon Sep 17 00:00:00 2001
From: John Jacques <john.jacques@intel.com>
Date: Wed, 18 Nov 2015 13:41:37 +0200
Subject: [PATCH 112/213] mach-axxia: Clean Up the Mapping of Dickens

Dickens was mapped in a number of places, and inconsistently at that.
This commit changes that; Dickens is mapped in one place.

Signed-off-by: John Jacques <john.jacques@intel.com>
---
 arch/arm/mach-axxia/axxia.c         |  51 +++++-----
 arch/arm/mach-axxia/axxia.h         |  11 +++
 arch/arm/mach-axxia/ddr_retention.c | 183 +++++++++++++++---------------------
 arch/arm/mach-axxia/platsmp.c       |  29 +++---
 4 files changed, 127 insertions(+), 147 deletions(-)

diff --git a/arch/arm/mach-axxia/axxia.c b/arch/arm/mach-axxia/axxia.c
index c628bf2..a578b969 100644
--- a/arch/arm/mach-axxia/axxia.c
+++ b/arch/arm/mach-axxia/axxia.c
@@ -12,7 +12,7 @@
  *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
  * GNU General Public License for more details.
  *
  * You should have received a copy of the GNU General Public License
@@ -35,37 +35,38 @@
 #include <linux/smsc911x.h>
 #include <linux/clk-provider.h>
 #include <linux/clkdev.h>
+#include <linux/sizes.h>
+#include <linux/pmu.h>
+#include <linux/kexec.h>
 #ifdef CONFIG_ARM_ARCH_TIMER
 #include <asm/arch_timer.h>
 #endif
-#include <asm/sizes.h>
-#include <asm/pmu.h>
 #include <asm/mach/arch.h>
 #include <asm/mach/map.h>
-#include <asm/kexec.h>
 #include <asm/mach/time.h>
 #include <asm/hardware/cache-l2x0.h>
 #include <mach/hardware.h>
 #include <mach/timers.h>
 #include <mach/axxia-gic.h>
 #include <linux/irqchip/arm-gic.h>
-#include <linux/lsi-ncr.h>
 #include "axxia.h"
 #include "pci.h"
 #ifdef CONFIG_AXXIA_RIO
 #include <mach/rio.h>
 #endif
 
-static const char *const axxia_dt_match[] __initconst = {
+static const char *axxia_dt_match[] __initconst = {
 	"lsi,axm5500",
 	NULL
 };
 
 static void __iomem *base;
+void __iomem *dickens;
 
-#ifdef CONFIG_KEXEC
-
-//static void __iomem *dickens;
+#ifdef AXXIA_NCR_RESET_CHECK
+int ncr_reset_active;
+EXPORT_SYMBOL(ncr_reset_active);
+#endif
 
 static void set_l3_pstate(u32 newstate)
 {
@@ -80,7 +81,6 @@ static void set_l3_pstate(u32 newstate)
 
 	for (i = 0; i < ARRAY_SIZE(hnf); ++i) {
 		int retry;
-
 		for (retry = 10000; retry > 0; --retry) {
 			status = readl(dickens + (hnf[i] << 16) + 0x18);
 			if (((status >> 2) & 3) == newstate)
@@ -91,7 +91,7 @@ static void set_l3_pstate(u32 newstate)
 	}
 }
 
-static void
+void
 flush_l3(void)
 {
 	/* Switch to SFONLY to flush */
@@ -100,8 +100,6 @@ static void set_l3_pstate(u32 newstate)
 	set_l3_pstate(3);
 }
 
-#endif
-
 static struct map_desc axxia_static_mappings[] __initdata = {
 #ifdef CONFIG_DEBUG_LL
 	{
@@ -120,7 +118,7 @@ void __init axxia_dt_map_io(void)
 
 void __init axxia_dt_init_early(void)
 {
-	 init_dma_coherent_pool_size(SZ_1M);
+	init_dma_coherent_pool_size(SZ_1M);
 }
 
 static struct of_device_id axxia_irq_match[] __initdata = {
@@ -157,21 +155,21 @@ void __init axxia_dt_timer_init(void)
 
 static struct of_dev_auxdata axxia_auxdata_lookup[] __initdata = {
 	OF_DEV_AUXDATA("arm,primecell", 0x20101E0000ULL,
-		       "mmci",  &mmc_plat_data),
+		       "mmci",	&mmc_plat_data),
 	{}
 };
 
 static struct resource axxia_pmu_resources[] = {
 	[0] = {
-		.start  = IRQ_PMU,
-		.end    = IRQ_PMU,
-		.flags  = IORESOURCE_IRQ,
+		.start	= IRQ_PMU,
+		.end	= IRQ_PMU,
+		.flags	= IORESOURCE_IRQ,
 	},
 };
 
 static struct platform_device pmu_device = {
 	.name			= "arm-pmu",
-	.id                     = -1,
+	.id			= -1,
 	.num_resources		= ARRAY_SIZE(axxia_pmu_resources),
 	.resource		= axxia_pmu_resources,
 };
@@ -203,11 +201,16 @@ void __init axxia_dt_timer_init(void)
 void __init axxia_dt_init(void)
 {
 	base = ioremap(0x2010000000, 0x40000);
-#ifdef CONFIG_KEXEC
 	if (!of_find_compatible_node(NULL, NULL, "lsi,axm5500-sim")) {
-		dickens = ioremap(0x2000000000, SZ_4M);
+		dickens = ioremap(0x2000000000, SZ_16M);
+#ifdef CONFIG_KEXEC
 		kexec_reinit = flush_l3;
+#endif
+		flush_l3();
 	}
+
+#ifdef AXXIA_NCR_RESET_CHECK
+	ncr_reset_active = 0;
 #endif
 
 	bus_register_notifier(&platform_bus_type, &axxia_platform_nb);
@@ -226,7 +229,7 @@ void __init axxia_dt_init(void)
 	platform_device_register(&pmu_device);
 }
 
-static void axxia_restart(enum reboot_mode reboot, const char *cmd)
+static void axxia_restart(char str, const char *cmd)
 {
 	writel(0x000000ab, base + 0x31000); /* Access Key */
 	writel(0x00000040, base + 0x31004); /* Intrnl Boot, 0xffff0000 Target */
@@ -235,7 +238,7 @@ static void axxia_restart(enum reboot_mode reboot, const char *cmd)
 }
 
 DT_MACHINE_START(AXXIA_DT, "LSI Axxia")
-	.dt_compat	= axxia_dt_match,
+.dt_compat	= axxia_dt_match,
 	.smp		= smp_ops(axxia_smp_ops),
 	.map_io		= axxia_dt_map_io,
 	.init_early	= axxia_dt_init_early,
@@ -246,4 +249,4 @@ static void axxia_restart(enum reboot_mode reboot, const char *cmd)
 #if defined(CONFIG_ZONE_DMA) && defined(CONFIG_ARM_LPAE)
 	.dma_zone_size	= (4ULL * SZ_1G) - 1,
 #endif
-MACHINE_END
+	MACHINE_END
diff --git a/arch/arm/mach-axxia/axxia.h b/arch/arm/mach-axxia/axxia.h
index c46b76d..5b83378 100644
--- a/arch/arm/mach-axxia/axxia.h
+++ b/arch/arm/mach-axxia/axxia.h
@@ -4,11 +4,22 @@
 void axxia_ddr_retention_init(void);
 void axxia_platform_cpu_die(unsigned int cpu);
 int axxia_platform_cpu_kill(unsigned int cpu);
+void ncp_ddr_shutdown(void *, void *, unsigned long);
+void flush_l3(void);
 
 extern void axxia_secondary_startup(void);
 
 extern struct smp_operations axxia_smp_ops;
 
+/*
+ * when defined, the RTE driver module will set/clear
+ * the ncr_reset_active flag to indicate when Axxia device
+ * reset is in progress. This flag will be checked by the
+ * kernel lsi-ncr driver and ddr_retention code.
+ */
+#define AXXIA_NCR_RESET_CHECK
+extern int ncr_reset_active;
+
 extern void __iomem *syscon;
 extern void __iomem *dickens;
 
diff --git a/arch/arm/mach-axxia/ddr_retention.c b/arch/arm/mach-axxia/ddr_retention.c
index 4649832..e74bb03 100644
--- a/arch/arm/mach-axxia/ddr_retention.c
+++ b/arch/arm/mach-axxia/ddr_retention.c
@@ -25,19 +25,15 @@
 #include <linux/proc_fs.h>
 #include <linux/prefetch.h>
 #include <linux/delay.h>
+
 #include <linux/of.h>
+#include <linux/io.h>
 #include <linux/lsi-ncr.h>
-
-#include <asm/io.h>
 #include <asm/cacheflush.h>
 #include "axxia.h"
 
 static void __iomem *nca;
 static void __iomem *apb;
-#ifndef CONFIG_SMP
-void __iomem *dickens;
-#endif
-
 static int ddr_retention_enabled;
 
 enum {
@@ -79,72 +75,12 @@ enum {
 	NCP_REGION_ID(0xff, 0xff)
 };
 
-
-/*
-  ------------------------------------------------------------------------------
-  flush_l3
-
-  This is NOT a general function to flush the L3 cache.  There are a number of
-  assumptions that are not usually true...
-
-  1) All other cores are " quiesced".
-  2) There is no need to worry about preemption or interrupts.
-*/
-
-static void
-flush_l3(void)
-{
-
-	unsigned long hnf_offsets[] = {
-		0x20, 0x21, 0x22, 0x23, 0x24, 0x25, 0x26, 0x27
-	};
-
-	int i;
-	unsigned long status;
-	int retries;
-
-	for (i = 0; i < (sizeof(hnf_offsets) / sizeof(unsigned long)); ++i)
-		writel(0x0, dickens + (0x10000 * hnf_offsets[i]) + 0x10);
-
-	for (i = 0; i < (sizeof(hnf_offsets) / sizeof(unsigned long)); ++i) {
-		retries = 10000;
-
-		do {
-			status = readl(dickens +
-				       (0x10000 * hnf_offsets[i]) + 0x18);
-			udelay(1);
-		} while ((0 < --retries) && (0x0 != (status & 0xf)));
-
-		if (0 == retries)
-			BUG();
-	}
-
-	for (i = 0; i < (sizeof(hnf_offsets) / sizeof(unsigned long)); ++i)
-		writel(0x3, dickens + (0x10000 * hnf_offsets[i]) + 0x10);
-
-	for (i = 0; i < (sizeof(hnf_offsets) / sizeof(unsigned long)); ++i) {
-		retries = 10000;
-
-		do {
-			status = readl(dickens +
-				       (0x10000 * hnf_offsets[i]) + 0x18);
-			udelay(1);
-		} while ((0 < --retries) && (0xc != (status & 0xf)));
-
-		if (0 == retries)
-			BUG();
-	}
-
-	asm volatile ("dsb" : : : "memory");
-
-}
-
 static void
-quiesce_vp_engine(int engineType)
+quiesce_vp_engine(int engine_type)
 {
-	unsigned long *pEngineRegions;
-	unsigned long ortOff, owtOff;
-	unsigned long *pRegion;
+	unsigned long *engine_regions;
+	unsigned long ort_off, owt_off;
+	unsigned long *region;
 	unsigned ort, owt;
 	unsigned long buf = 0;
 	unsigned short node, target;
@@ -152,58 +88,60 @@ enum {
 
 	pr_info("quiescing VP engines...\n");
 
-	switch (engineType) {
+	switch (engine_type) {
 	case AXXIA_ENGINE_CNAL:
-		pEngineRegions = ncp_cnal_regions_acp55xx;
-		ortOff = 0x1c0;
-		owtOff = 0x1c4;
+		engine_regions = ncp_cnal_regions_acp55xx;
+		ort_off = 0x1c0;
+		owt_off = 0x1c4;
 		break;
 
 	case AXXIA_ENGINE_CAAL:
-		pEngineRegions = ncp_caal_regions_acp55xx;
-		ortOff = 0xf8;
-		owtOff = 0xfc;
+		engine_regions = ncp_caal_regions_acp55xx;
+		ort_off = 0xf8;
+		owt_off = 0xfc;
 		break;
 
 	default:
 		return;
 	}
 
-	pRegion = pEngineRegions;
+	region = engine_regions;
 
-	while (*pRegion != NCP_REGION_ID(0xff, 0xff)) {
+	while (*region != NCP_REGION_ID(0xff, 0xff)) {
 		/* set read/write transaction limits to zero */
-		ncr_write(*pRegion, 0x8, 4, &buf);
-		ncr_write(*pRegion, 0xc, 4, &buf);
-		pRegion++;
+		ncr_write_nolock(*region, 0x8, 4, &buf);
+		ncr_write_nolock(*region, 0xc, 4, &buf);
+		region++;
 	}
 
-	pRegion = pEngineRegions;
+	region = engine_regions;
 	loop = 0;
 
-	while (*pRegion != NCP_REGION_ID(0xff, 0xff)) {
-		node = (*pRegion & 0xffff0000) >> 16;
-		target = *pRegion & 0x0000ffff;
+	while (*region != NCP_REGION_ID(0xff, 0xff)) {
+		node = (*region & 0xffff0000) >> 16;
+		target = *region & 0x0000ffff;
 		/* read the number of outstanding read/write transactions */
-		ncr_read(*pRegion, ortOff, 4, &ort);
-		ncr_read(*pRegion, owtOff, 4, &owt);
+		ncr_read_nolock(*region, ort_off, 4, &ort);
+		ncr_read_nolock(*region, owt_off, 4, &owt);
 
 		if ((ort == 0) && (owt == 0)) {
 			/* this engine has been quiesced, move on to the next */
 			pr_info("quiesced region 0x%02x.0x%02x\n",
 					node, target);
-			pRegion++;
+			region++;
 		} else {
 			if (loop++ > 10000) {
 				pr_info(
 						"Unable to quiesce region 0x%02x.0x%02x ort=0x%x, owt=0x%x\n",
 						node, target, ort, owt);
-				pRegion++;
+				region++;
 				loop = 0;
 				continue;
 			}
 		}
 	}
+
+	return;
 }
 
 static inline void cpu_disable_l2_prefetch(void)
@@ -243,7 +181,34 @@ static inline void cpu_disable_l2_prefetch(void)
 }
 
 
-extern void ncp_ddr_shutdown(void *, void *,  unsigned long);
+/*
+ * shutdown the system in preparation for a DDR retention reset.
+ * This is only needed if initiating the retention reset while the
+ * system is running in normal state (i.e. via the /proc filesystem.)
+ * If the retention reset is called from within a restart function
+ * this should not be necessary.
+ */
+void
+retention_reset_prepare(void)
+{
+	/*
+	 * If the axxia device is in reset then DDR retention is not
+	 * possible. Just do an emergency_restart instead.
+	 */
+	if (ncr_reset_active)
+		emergency_restart();
+
+	preempt_disable();
+
+	/* send stop message to other CPUs */
+	local_irq_disable();
+	local_fiq_disable();
+	asm volatile ("dsb" : : : "memory");
+	asm volatile ("dmb" : : : "memory");
+	system_state = SYSTEM_RESTART;
+	smp_send_stop();
+	udelay(1000);
+}
 
 
 void
@@ -252,30 +217,27 @@ static inline void cpu_disable_l2_prefetch(void)
 	unsigned long ctl_244 = 0;
 	unsigned long value;
 	unsigned cpu_id;
-
+    /*
+     * in order to preload the DDR shutdown function into cache
+     * we use these variables to do a word-by-word copy of the
+     * memory where the function resides. The 'tmp' variable
+     * must be declared as volatile to ensure the compiler
+     * doesn't optimize this out.
+     * Removal of this volatile to resolve the checkpatch warning
+     * will break the operation!
+     */
 	volatile long tmp;
-	volatile long *ptmp;
+	long *ptmp;
 
 	if (0 == ddr_retention_enabled) {
 		pr_info("DDR Retention Reset is Not Enabled\n");
 		return;
 	}
 
-	if (NULL == nca || NULL == apb || NULL == dickens)
+	if (NULL == nca || NULL == apb)
 		BUG();
 
 	preempt_disable();
-	cpu_id = smp_processor_id();
-
-	/* send stop message to other CPUs */
-	local_irq_disable();
-	local_fiq_disable();
-	asm volatile ("dsb" : : : "memory");
-	asm volatile ("dmb" : : : "memory");
-	system_state = SYSTEM_RESTART;
-	smp_send_stop();
-	udelay(1000);
-
 	flush_cache_all();
 	flush_l3();
 
@@ -289,10 +251,11 @@ static inline void cpu_disable_l2_prefetch(void)
 
 	/* prepare to put DDR in self refresh power-down mode */
 	/* first read the CTL_244 register and OR in the LP_CMD value */
-	ncr_read(NCP_REGION_ID(34, 0), 0x3d0, 4, &ctl_244);
+	ncr_read_nolock(NCP_REGION_ID(34, 0), 0x3d0, 4, &ctl_244);
 	ctl_244 |= 0x000a0000;
 
 	/* belts & braces: put secondary CPUs into reset */
+	cpu_id = smp_processor_id();
 	value = ~(1 << cpu_id);
 	value &= 0xffff;
 	ncr_register_write(htonl(value), (unsigned *) (apb + 0x31030));
@@ -303,7 +266,7 @@ static inline void cpu_disable_l2_prefetch(void)
 		tmp += *ptmp++;
 	} while (ptmp < (long *) (ncp_ddr_shutdown + 0x1000));
 
-	asm volatile ("isb" : : : "memory");
+	isb();
 
 	/* disable L2 prefetching */
 	cpu_disable_l2_prefetch();
@@ -313,6 +276,8 @@ static inline void cpu_disable_l2_prefetch(void)
 
 	/* call cache resident ddr shutdown function */
 	ncp_ddr_shutdown(nca, apb, ctl_244);
+
+	return;
 }
 EXPORT_SYMBOL(initiate_retention_reset);
 
@@ -320,6 +285,7 @@ static inline void cpu_disable_l2_prefetch(void)
 axxia_ddr_retention_trigger(struct file *file, const char __user *buf,
 			    size_t count, loff_t *ppos)
 {
+	retention_reset_prepare();
 	initiate_retention_reset();
 	return 0;
 }
@@ -344,11 +310,12 @@ static inline void cpu_disable_l2_prefetch(void)
 		} else {
 			apb = ioremap(0x2010000000, 0x80000);
 			nca = ioremap(0x002020100000ULL, 0x20000);
-			dickens = ioremap(0x2000000000, 0x1000000);
 			ddr_retention_enabled = 1;
 			pr_info("DDR Retention Reset Initialized\n");
 		}
 	} else {
 		pr_info("DDR Retention Reset is Not Available\n");
 	}
+
+	return;
 }
diff --git a/arch/arm/mach-axxia/platsmp.c b/arch/arm/mach-axxia/platsmp.c
index 3b7db9d..0e7dde0 100644
--- a/arch/arm/mach-axxia/platsmp.c
+++ b/arch/arm/mach-axxia/platsmp.c
@@ -27,19 +27,19 @@
 #include <mach/axxia-gic.h>
 
 #define SYSCON_PHYS_ADDR 0x002010030000ULL
-#define DICKENS_PHYS_ADDR 0x2000000000
 
 static int __cpuinitdata wfe_fixup;
 static int wfe_available;
 
 void __iomem *syscon;
-void __iomem *dickens;
 
 inline void
 __axxia_arch_wfe(void)
 {
 	if (0 != wfe_available)
 		wfe();
+
+	return;
 }
 EXPORT_SYMBOL(__axxia_arch_wfe);
 
@@ -77,11 +77,9 @@ static void  do_fixup_sev(void)
  * observers, irrespective of whether they're taking part in coherency
  * or not.  This is necessary for the hotplug code to work reliably.
  */
-static void __cpuinit write_pen_release(int val)
+static void  write_pen_release(int val)
 {
 	pen_release = val;
-
-	/* Set up memory barrier */
 	smp_wmb();
 	__cpuc_flush_dcache_area((void *)&pen_release, sizeof(pen_release));
 	outer_clean_range(__pa(&pen_release), __pa(&pen_release + 1));
@@ -141,6 +139,8 @@ int  axxia_boot_secondary(unsigned int cpu, struct task_struct *idle)
 	int phys_cpu, cluster;
 	unsigned long timeout;
 	unsigned long powered_down_cpu;
+	u32 i;
+	u32 dummy;
 
 
 	/*
@@ -185,15 +185,18 @@ int  axxia_boot_secondary(unsigned int cpu, struct task_struct *idle)
 	/* Send a wakeup IPI to get the idled cpu out of WFI state */
 	arch_send_wakeup_ipi_mask(cpumask_of(cpu));
 
+
 	/* Wait for so long, then give up if nothing happens ... */
 	timeout = jiffies + (1 * HZ);
 	while (time_before(jiffies, timeout)) {
-		/* Remove memroy barrier */
 		smp_rmb();
+
 		if (pen_release == -1)
 			break;
 
-		udelay(10);
+		/* Wait 10 cycles */
+		for (i = 0; i < 10; i++)
+			dummy = i;
 	}
 
 	/*
@@ -211,7 +214,6 @@ static __init struct device_node *get_cpu_node(int cpu)
 
 	for_each_node_by_type(np, "cpu") {
 		u32 reg;
-
 		if (of_property_read_u32(np, "reg", &reg))
 			continue;
 		if (reg == cpu_logical_map(cpu))
@@ -230,10 +232,6 @@ static void __init axxia_smp_prepare_cpus(unsigned int max_cpus)
 	if (WARN_ON(!syscon))
 		return;
 
-	dickens = ioremap(DICKENS_PHYS_ADDR, SZ_4M);
-	if (WARN_ON(!dickens))
-		return;
-
 	check_fixup_sev(syscon);
 	do_fixup_sev();
 
@@ -266,7 +264,6 @@ static void __init axxia_smp_prepare_cpus(unsigned int max_cpus)
 		if (cpu != 0) {
 			u32 phys_cpu = cpu_logical_map(cpu);
 			u32 tmp = readl(syscon + 0x1010);
-
 			writel(0xab, syscon + 0x1000);
 			tmp &= ~(1 << phys_cpu);
 			writel(tmp, syscon + 0x1010);
@@ -289,10 +286,12 @@ static void __init axxia_smp_prepare_cpus(unsigned int max_cpus)
 				release_virt = phys_to_virt(release_phys);
 			else
 				release_virt = ioremap(release_phys, PAGE_SIZE);
-			*release_virt = virt_to_phys(axxia_secondary_startup);
-			/* Setup memory barrier */
+
+			writel_relaxed(virt_to_phys(axxia_secondary_startup),
+				       release_virt);
 			smp_wmb();
 			__cpuc_flush_dcache_area(release_virt, sizeof(u32));
+
 			if (!is_kmapped)
 				iounmap(release_virt);
 		}
-- 
1.9.1

