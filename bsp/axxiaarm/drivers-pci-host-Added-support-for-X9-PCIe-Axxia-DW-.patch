From d76407b4c42735795ca4fba93a65e0db5129d50e Mon Sep 17 00:00:00 2001
From: SangeethaRao <sangeetha.rao@intel.com>
Date: Thu, 24 Sep 2015 19:39:03 +0300
Subject: [PATCH 42/59] drivers/pci/host: Added support for X9 PCIe Axxia DW
 MSI

git://git.yoctoproject.org/linux-yocto-4.1 standard/axxia/base
	commit 2d0d6ee7556adbd0f61cda059faa54a963ed729b

Signed-off-by: SangeethaRao <sangeetha.rao@intel.com>
Signed-off-by: Xulin Sun <xulin.sun@windriver.com>
---
 drivers/pci/host/pcie-axxia.c |  299 ++++++++++++++++++++++++++++++++++++++++-
 drivers/pci/host/pcie-axxia.h |   18 +--
 2 files changed, 301 insertions(+), 16 deletions(-)

diff --git a/drivers/pci/host/pcie-axxia.c b/drivers/pci/host/pcie-axxia.c
index 1c0b12c..446abb7 100644
--- a/drivers/pci/host/pcie-axxia.c
+++ b/drivers/pci/host/pcie-axxia.c
@@ -76,6 +76,26 @@
 #define PCIE_ATU_FUNC(x)                (((x) & 0x7) << 16)
 #define PCIE_ATU_UPPER_TARGET           0x91C
 
+#define CC_GPREG_EDG_IRQ_STAT                    0x210
+#define CC_GPREG_EDG_IRQ_MASK                    0x214
+#define CC_GPREG_EDG_IRQ_STAT_HI                 0x250
+#define CC_GPREG_EDG_IRQ_MASK_HI                 0x254
+#define MSI_ASSERTED                    (0x1 << 24)
+#define RADM_INTD_DEASSERTED            (0x1 << 9)
+#define RADM_INTC_DEASSERTED            (0x1 << 8)
+#define RADM_INTB_DEASSERTED            (0x1 << 7)
+#define RADM_INTA_DEASSERTED            (0x1 << 6)
+#define RADM_INTD_ASSERTED              (0x1 << 5)
+#define RADM_INTC_ASSERTED              (0x1 << 4)
+#define RADM_INTB_ASSERTED              (0x1 << 3)
+#define RADM_INTA_ASSERTED              (0x1 << 2)
+
+#define CC_GPREG_LVL_IRQ_MASK	0x204
+#define MSI_CNTRL_INT              (0x1 << 9)
+
+#define AXI_GPREG_MSTR		0x0
+#define CFG_MSI_MODE		(0x1 << 29)
+
 struct axxia_pcie {
 	struct pcie_port	pp;
 };
@@ -352,6 +372,91 @@ static struct pci_ops axxia_pciex_pci_ops = {
 	.write = axxia_pciex_write_config,
 };
 
+static struct irq_chip axxia_dw_msi_irq_chip = {
+	.name = "PCI-MSI",
+	.irq_enable = pci_msi_unmask_irq,
+	.irq_disable = pci_msi_mask_irq,
+	.irq_mask = pci_msi_mask_irq,
+	.irq_unmask = pci_msi_unmask_irq,
+};
+
+static int axxia_dw_pcie_msi_map(struct irq_domain *domain, unsigned int irq,
+	irq_hw_number_t hwirq)
+{
+	irq_set_chip_and_handler(irq, &axxia_dw_msi_irq_chip,
+		handle_simple_irq);
+	irq_set_chip_data(irq, domain->host_data);
+	set_irq_flags(irq, IRQF_VALID);
+
+return 0;
+}
+
+static const struct irq_domain_ops axxia_msi_domain_ops = {
+	.map = axxia_dw_pcie_msi_map,
+};
+
+
+void axxia_dw_pcie_msi_init(struct pcie_port *pp)
+{
+	pp->msi_data = __get_free_pages(GFP_KERNEL, 0);
+
+	/* program the msi_data */
+	axxia_pcie_wr_own_conf(pp, PCIE_MSI_ADDR_LO, 4,
+		virt_to_phys((void *)pp->msi_data));
+	axxia_pcie_wr_own_conf(pp, PCIE_MSI_ADDR_HI, 4, 0);
+}
+
+/* MSI int handler */
+irqreturn_t axxia_dw_handle_msi_irq(struct pcie_port *pp)
+{
+	unsigned long val;
+	int i, pos, irq;
+	irqreturn_t ret = IRQ_NONE;
+
+	for (i = 0; i < MAX_MSI_CTRLS; i++) {
+		axxia_pcie_rd_own_conf(pp, PCIE_MSI_INTR0_STATUS + i * 12, 4,
+			(u32 *)&val);
+		if (val) {
+			ret = IRQ_HANDLED;
+			pos = 0;
+			while ((pos = find_next_bit(&val, 32, pos)) != 32) {
+				irq = irq_find_mapping(pp->irq_domain,
+					i * 32 + pos);
+				axxia_pcie_wr_own_conf(pp,
+				PCIE_MSI_INTR0_STATUS + i * 12,
+				4, 1 << pos);
+				generic_handle_irq(irq);
+				pos++;
+			}
+		}
+	}
+	return ret;
+}
+
+static void axxia_pcie_msi_init(struct pcie_port *pp)
+{
+	axxia_dw_pcie_msi_init(pp);
+}
+
+static void axxia_pcie_enable_interrupts(struct pcie_port *pp)
+{
+	u32 val;
+
+	/* Unmask */
+	axxia_cc_gpreg_readl(pp, CC_GPREG_EDG_IRQ_MASK, &val);
+	val |= (RADM_INTD_DEASSERTED | RADM_INTC_DEASSERTED |
+		RADM_INTB_DEASSERTED | RADM_INTA_DEASSERTED |
+		RADM_INTD_ASSERTED | RADM_INTC_ASSERTED |
+		RADM_INTB_ASSERTED | RADM_INTA_ASSERTED);
+	axxia_cc_gpreg_writel(pp, val, CC_GPREG_EDG_IRQ_MASK);
+	if (IS_ENABLED(CONFIG_PCI_MSI)) {
+		/* unmask MSI */
+		axxia_cc_gpreg_readl(pp, CC_GPREG_EDG_IRQ_MASK_HI, &val);
+		val |= MSI_ASSERTED;
+		axxia_cc_gpreg_writel(pp, val, CC_GPREG_EDG_IRQ_MASK_HI);
+		axxia_pcie_msi_init(pp);
+	}
+}
 
 int axxia_pcie_link_up(struct pcie_port *pp)
 {
@@ -451,6 +556,155 @@ static int axxia_pcie_establish_link(struct pcie_port *pp)
 	return 0;
 }
 
+static irqreturn_t axxia_pcie_irq_handler(int irq, void *arg)
+{
+	struct pcie_port *pp = arg;
+	u32 val;
+	irqreturn_t ret;
+
+	axxia_cc_gpreg_readl(pp, CC_GPREG_EDG_IRQ_STAT, &val);
+	if (val & RADM_INTD_DEASSERTED)
+		pr_info("RADM_INTD_DEASSERTED\n");
+	if (val & RADM_INTC_DEASSERTED)
+		pr_info("RADM_INTC_DEASSERTED\n");
+	if (val & RADM_INTB_DEASSERTED)
+		pr_info("RADM_INTB_DEASSERTED\n");
+	if (val & RADM_INTA_DEASSERTED)
+		pr_info("RADM_INTA_DEASSERTED\n");
+	if (val & RADM_INTD_ASSERTED)
+		pr_info("RADM_INTD_ASSERTED\n");
+	if (val & RADM_INTC_ASSERTED)
+		pr_info("RADM_INTC_ASSERTED\n");
+	if (val & RADM_INTB_ASSERTED)
+		pr_info("RADM_INTB_ASSERTED\n");
+	if (val & RADM_INTA_ASSERTED)
+		pr_info("RADM_INTA_ASSERTED\n");
+
+	if (IS_ENABLED(CONFIG_PCI_MSI)) {
+		axxia_cc_gpreg_readl(pp, CC_GPREG_EDG_IRQ_STAT_HI, &val);
+		if (val & MSI_ASSERTED) {
+			ret = axxia_dw_handle_msi_irq(pp);
+			axxia_cc_gpreg_writel(pp, MSI_ASSERTED,
+				CC_GPREG_EDG_IRQ_STAT_HI);
+			return ret;
+		}
+	}
+	return IRQ_HANDLED;
+}
+
+static void axxia_dw_pcie_msi_clear_irq(struct pcie_port *pp, int irq)
+{
+	unsigned int res, bit, val;
+
+	res = (irq / 32) * 12;
+	bit = irq % 32;
+	axxia_pcie_rd_own_conf(pp, PCIE_MSI_INTR0_ENABLE + res, 4, &val);
+	val &= ~(1 << bit);
+	axxia_pcie_wr_own_conf(pp, PCIE_MSI_INTR0_ENABLE + res, 4, val);
+}
+
+
+static void clear_irq_range(struct pcie_port *pp, unsigned int irq_base,
+	unsigned int nvec, unsigned int pos)
+{
+	unsigned int i;
+
+	for (i = 0; i < nvec; i++) {
+		irq_set_msi_desc_off(irq_base, i, NULL);
+		/* Disable corresponding interrupt on MSI controller */
+		if (pp->ops->msi_clear_irq)
+			pp->ops->msi_clear_irq(pp, pos + i);
+		else
+			axxia_dw_pcie_msi_clear_irq(pp, pos + i);
+	}
+
+	bitmap_release_region(pp->msi_irq_in_use, pos, order_base_2(nvec));
+}
+
+static void axxia_dw_pcie_msi_set_irq(struct pcie_port *pp, int irq)
+{
+	unsigned int res, bit, val;
+
+	res = (irq / 32) * 12;
+	bit = irq % 32;
+	axxia_pcie_rd_own_conf(pp, PCIE_MSI_INTR0_ENABLE + res, 4, &val);
+	val |= 1 << bit;
+	axxia_pcie_wr_own_conf(pp, PCIE_MSI_INTR0_ENABLE + res, 4, val);
+}
+
+static int assign_irq(int no_irqs, struct msi_desc *desc, int *pos)
+{
+	int irq, pos0, i;
+	struct pcie_port *pp = desc->dev->bus->sysdata;
+
+	pos0 = bitmap_find_free_region(pp->msi_irq_in_use, MAX_MSI_IRQS,
+	order_base_2(no_irqs));
+	if (pos0 < 0)
+		goto no_valid_irq;
+
+	irq = irq_find_mapping(pp->irq_domain, pos0);
+	if (!irq)
+		goto no_valid_irq;
+
+	/*
+	 * irq_create_mapping (called from dw_pcie_host_init) pre-allocates
+	 * descs so there is no need to allocate descs here. We can therefore
+	 * assume that if irq_find_mapping above returns non-zero, then the
+	 * descs are also successfully allocated.
+	 */
+	for (i = 0; i < no_irqs; i++) {
+		if (irq_set_msi_desc_off(irq, i, desc) != 0) {
+			clear_irq_range(pp, irq, i, pos0);
+			goto no_valid_irq;
+		}
+		/*Enable corresponding interrupt in MSI interrupt controller */
+		axxia_dw_pcie_msi_set_irq(pp, pos0 + i);
+	}
+
+	*pos = pos0;
+	return irq;
+
+no_valid_irq:
+	*pos = pos0;
+	return -ENOSPC;
+}
+
+static int axxia_dw_msi_setup_irq(struct msi_controller *chip,
+	struct pci_dev *pdev,
+	struct msi_desc *desc)
+{
+	int irq, pos;
+	struct msi_msg msg;
+	struct pcie_port *pp = pdev->bus->sysdata;
+
+	irq = assign_irq(1, desc, &pos);
+	if (irq < 0)
+		return irq;
+
+	msg.address_lo = virt_to_phys((void *)pp->msi_data);
+	msg.address_hi = 0x0;
+	msg.data = pos;
+
+	pci_write_msi_msg(irq, &msg);
+
+	return 0;
+}
+
+static void axxia_dw_msi_teardown_irq(struct msi_controller *chip,
+	unsigned int irq)
+{
+	struct irq_data *data = irq_get_irq_data(irq);
+	struct msi_desc *msi = irq_data_get_msi(data);
+	struct pcie_port *pp = msi->dev->bus->sysdata;
+
+	clear_irq_range(pp, irq, 1, data->hwirq);
+}
+
+static struct msi_controller axxia_dw_pcie_msi_chip = {
+	.setup_irq = axxia_dw_msi_setup_irq,
+	.teardown_irq = axxia_dw_msi_teardown_irq,
+};
+
 int __init axxia_pcie_host_init(struct pcie_port *pp)
 {
 	struct device_node *np = pp->dev->of_node;
@@ -462,6 +716,7 @@ int __init axxia_pcie_host_init(struct pcie_port *pp)
 	struct pci_bus *bus;
 	unsigned long mem_offset;
 	LIST_HEAD(res);
+	int i;
 
 	/* Find the address cell size and the number of cells in order to get
 	 * the untranslated address.
@@ -556,8 +811,38 @@ int __init axxia_pcie_host_init(struct pcie_port *pp)
 	}
 
 
-	axxia_pcie_establish_link(pp);
+	if (axxia_pcie_establish_link(pp)) {
+		dev_err(pp->dev, "axxia_pcie_establish_link failed\n");
+		return -EINVAL;
+	}
 
+	/* Legacy interrupts */
+	pp->irq[0] = platform_get_irq(pdev, 0);
+	if (!pp->irq[0]) {
+		dev_err(pp->dev, "failed to get irq\n");
+		return -ENODEV;
+	}
+	ret = devm_request_irq(pp->dev, pp->irq[0], axxia_pcie_irq_handler,
+		IRQF_SHARED, "axxia-pcie", pp);
+	if (ret) {
+		dev_err(pp->dev, "failed to request irq\n");
+		return ret;
+	}
+
+	if (IS_ENABLED(CONFIG_PCI_MSI)) {
+		pp->irq_domain = irq_domain_add_linear(pp->dev->of_node,
+			MAX_MSI_IRQS, &axxia_msi_domain_ops,
+			&axxia_dw_pcie_msi_chip);
+		if (!pp->irq_domain) {
+			dev_err(pp->dev, "irq domain init failed\n");
+			return -ENXIO;
+		}
+
+		for (i = 0; i < MAX_MSI_IRQS; i++)
+			irq_create_mapping(pp->irq_domain, i);
+	}
+
+	axxia_pcie_enable_interrupts(pp);
 
 	/* program correct class for RC */
 	axxia_pcie_wr_own_conf(pp, PCI_CLASS_DEVICE, 2, PCI_CLASS_BRIDGE_PCI);
@@ -566,17 +851,21 @@ int __init axxia_pcie_host_init(struct pcie_port *pp)
 	val |= PORT_LOGIC_SPEED_CHANGE;
 	axxia_pcie_wr_own_conf(pp, PCIE_LINK_WIDTH_SPEED_CONTROL, 4, val);
 
-	bus = pci_create_root_bus(&pdev->dev, 0,
+	bus = pci_create_root_bus(&pdev->dev, pp->root_bus_nr,
 		&axxia_pciex_pci_ops, pp, &res);
 	if (!bus)
 		return 1;
+#ifdef CONFIG_PCI_MSI
+	axxia_axi_gpreg_readl(pp, AXI_GPREG_MSTR, &val);
+	val |= CFG_MSI_MODE;
+	axxia_axi_gpreg_writel(pp, val, AXI_GPREG_MSTR);
+	bus->msi = &axxia_dw_pcie_msi_chip;
+#endif
 
 	pci_scan_child_bus(bus);
 	pci_assign_unassigned_bus_resources(bus);
 	pci_bus_add_devices(bus);
 
-	platform_set_drvdata(pdev, pp);
-
 	return 0;
 }
 
@@ -612,6 +901,8 @@ static int __init axxia_pcie_probe(struct platform_device *pdev)
 	if (IS_ERR(pp->cc_gpreg_base))
 		return PTR_ERR(pp->cc_gpreg_base);
 
+	pp->root_bus_nr = 0;
+
 	ret = axxia_pcie_host_init(pp);
 	if (ret) {
 		dev_err(&pdev->dev, "failed to initialize host\n");
diff --git a/drivers/pci/host/pcie-axxia.h b/drivers/pci/host/pcie-axxia.h
index 4618258..a195c60 100644
--- a/drivers/pci/host/pcie-axxia.h
+++ b/drivers/pci/host/pcie-axxia.h
@@ -14,7 +14,6 @@
 #ifndef _PCIE_AXXIA_H
 #define _PCIE_AXXIA_H
 
-#if 0
 /*
  * Maximum number of MSI IRQs can be 256 per controller. But keep
  * it 32 as of now. Probably we will never need more than 32. If needed,
@@ -22,7 +21,6 @@
  */
 #define MAX_MSI_IRQS			32
 #define MAX_MSI_CTRLS			(MAX_MSI_IRQS / 32)
-#endif
 
 struct pcie_port {
 	struct device		*dev;
@@ -52,14 +50,14 @@ struct pcie_port {
 	struct resource		busn;
 	u32			lanes;
 	struct pcie_host_ops	*ops;
+	int			irq[34];
+	unsigned long		msi_data;
+	struct irq_domain	*irq_domain;
+	struct msi_controller chip;
+	DECLARE_BITMAP(msi_irq_in_use, MAX_MSI_IRQS);
 #if 0
-	int			irq;
 	u32			lanes;
-	struct pcie_host_ops	*ops;
 	int			msi_irq;
-	struct irq_domain	*irq_domain;
-	unsigned long		msi_data;
-	DECLARE_BITMAP(msi_irq_in_use, MAX_MSI_IRQS);
 #endif
 };
 
@@ -81,15 +79,11 @@ struct pcie_host_ops {
 	u32 (*get_msi_addr)(struct pcie_port *pp);
 	u32 (*get_msi_data)(struct pcie_port *pp, int pos);
 	void (*scan_bus)(struct pcie_port *pp);
-	int (*msi_host_init)(struct pcie_port *pp, struct msi_chip *chip);
+	int (*msi_host_init)(struct pcie_port *pp, struct msi_controller *chip);
 };
 
 int axxia_pcie_cfg_read(void __iomem *addr, int where, int size, u32 *val);
 int axxia_pcie_cfg_write(void __iomem *addr, int where, int size, u32 val);
-#if 0
-irqreturn_t dw_handle_msi_irq(struct pcie_port *pp);
-void dw_pcie_msi_init(struct pcie_port *pp);
-#endif
 int axxia_pcie_link_up(struct pcie_port *pp);
 void axxia_pcie_setup_rc(struct pcie_port *pp);
 int axxia_pcie_host_init(struct pcie_port *pp);
-- 
1.7.5.4

