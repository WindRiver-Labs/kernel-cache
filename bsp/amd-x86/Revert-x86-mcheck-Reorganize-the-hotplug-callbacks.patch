From 44326394679489ceb09ae4018831498b3ef6bc25 Mon Sep 17 00:00:00 2001
From: Liwei Song <liwei.song@windriver.com>
Date: Thu, 20 Sep 2018 03:09:50 +0000
Subject: [PATCH 3/3] Revert "x86/mcheck: Reorganize the hotplug callbacks"

This reverts commit ff78103011d741955d716ce76ceb9fa12edcafb1.
"x86/mcheck: Reorganize the hotplug callbacks"

Since RT kernel has change to use hrtimer, so these series patch
was not suitable for RT kernel, for revert them to aviod compile
error on preempt-rt kernel.

Signed-off-by: Liwei Song <liwei.song@windriver.com>
---
 arch/x86/kernel/cpu/mcheck/mce.c |   35 +++++++++++++++--------------------
 1 file changed, 15 insertions(+), 20 deletions(-)

diff --git a/arch/x86/kernel/cpu/mcheck/mce.c b/arch/x86/kernel/cpu/mcheck/mce.c
index ab775a2..09d0a8e 100644
--- a/arch/x86/kernel/cpu/mcheck/mce.c
+++ b/arch/x86/kernel/cpu/mcheck/mce.c
@@ -1767,14 +1767,6 @@ static void mce_start_timer(unsigned int cpu, struct hrtimer *t)
 			0, HRTIMER_MODE_REL_PINNED);
 }
 
-static void __mcheck_cpu_setup_timer(void)
-{
-	struct timer_list *t = this_cpu_ptr(&mce_timer);
-	unsigned int cpu = smp_processor_id();
-
-	setup_pinned_timer(t, mce_timer_fn, cpu);
-}
-
 static void __mcheck_cpu_init_timer(void)
 {
 	struct hrtimer *t = this_cpu_ptr(&mce_timer);
@@ -1827,7 +1819,7 @@ void mcheck_cpu_init(struct cpuinfo_x86 *c)
 	__mcheck_cpu_init_generic();
 	__mcheck_cpu_init_vendor(c);
 	__mcheck_cpu_init_clear_banks();
-	__mcheck_cpu_setup_timer();
+	__mcheck_cpu_init_timer();
 }
 
 /*
@@ -2519,27 +2511,30 @@ static void mce_device_remove(unsigned int cpu)
 }
 
 /* Make sure there are no machine checks on offlined CPUs. */
-static void mce_disable_cpu(void)
+static void mce_disable_cpu(void *h)
 {
+	unsigned long action = *(unsigned long *)h;
+
 	if (!mce_available(raw_cpu_ptr(&cpu_info)))
 		return;
 
 	hrtimer_cancel(this_cpu_ptr(&mce_timer));
 
-	if (!cpuhp_tasks_frozen)
+	if (!(action & CPU_TASKS_FROZEN))
 		cmci_clear();
 
 	vendor_disable_error_reporting();
 }
 
-static void mce_reenable_cpu(void)
+static void mce_reenable_cpu(void *h)
 {
+	unsigned long action = *(unsigned long *)h;
 	int i;
 
 	if (!mce_available(raw_cpu_ptr(&cpu_info)))
 		return;
 
-	if (!cpuhp_tasks_frozen)
+	if (!(action & CPU_TASKS_FROZEN))
 		cmci_reenable();
 	for (i = 0; i < mca_cfg.banks; i++) {
 		struct mce_bank *b = &mce_banks[i];
@@ -2558,7 +2553,6 @@ mce_cpu_callback(struct notifier_block *nfb, unsigned long action, void *hcpu)
 
 	switch (action & ~CPU_TASKS_FROZEN) {
 	case CPU_ONLINE:
-	case CPU_DOWN_FAILED:
 
 		mce_device_create(cpu);
 
@@ -2566,10 +2560,11 @@ mce_cpu_callback(struct notifier_block *nfb, unsigned long action, void *hcpu)
 			mce_device_remove(cpu);
 			return NOTIFY_BAD;
 		}
-		mce_reenable_cpu();
-		mce_start_timer(cpu, t);
+
 		break;
 	case CPU_DEAD:
+		mce_threshold_remove_device(cpu);
+		mce_device_remove(cpu);
 		mce_intel_hcpu_update(cpu);
 
 		/* intentionally ignoring frozen here */
@@ -2577,10 +2572,10 @@ mce_cpu_callback(struct notifier_block *nfb, unsigned long action, void *hcpu)
 			cmci_rediscover();
 		break;
 	case CPU_DOWN_PREPARE:
-		mce_disable_cpu();
-
-		mce_threshold_remove_device(cpu);
-		mce_device_remove(cpu);
+		smp_call_function_single(cpu, mce_disable_cpu, &action, 1);
+		break;
+	case CPU_DOWN_FAILED:
+		smp_call_function_single(cpu, mce_reenable_cpu, &action, 1);
 		break;
 	}
 
-- 
1.7.9.5

