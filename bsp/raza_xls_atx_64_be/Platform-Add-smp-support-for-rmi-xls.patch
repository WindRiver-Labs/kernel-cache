From 5a3a3379202d31c455dbd3bacecf6e218e758559 Mon Sep 17 00:00:00 2001
From: Liu Changhui <changhui.liu@windriver.com>
Date: Fri, 29 Jan 2010 13:27:41 +0800
Subject: [PATCH] Platform: Add smp support for rmi xls

RMI XLS416 has 4 cores and 4 hardware threads per core. Add smp
 support for it.

source: from RMI SDK1.7

Signed-off-by: shuo.kang <shuo.kang@windriver.com>
---
 arch/mips/kernel/smp.c         |   25 ++++-
 arch/mips/rmi/phoenix/Makefile |    2 +-
 arch/mips/rmi/phoenix/smp.c    |  129 +++++++++++++++++++++++
 arch/mips/rmi/ptr/Makefile     |    6 +
 arch/mips/rmi/ptr/smp.c        |  220 ++++++++++++++++++++++++++++++++++++++++
 arch/mips/rmi/ptr/smpboot.S    |   70 +++++++++++++
 include/asm-mips/smp.h         |   17 +++
 7 files changed, 466 insertions(+), 3 deletions(-)
 create mode 100644 arch/mips/rmi/phoenix/smp.c
 create mode 100644 arch/mips/rmi/ptr/Makefile
 create mode 100644 arch/mips/rmi/ptr/smp.c
 create mode 100644 arch/mips/rmi/ptr/smpboot.S

diff --git a/arch/mips/kernel/smp.c b/arch/mips/kernel/smp.c
index 5b3c1d7..c00892a 100644
--- a/arch/mips/kernel/smp.c
+++ b/arch/mips/kernel/smp.c
@@ -44,6 +44,7 @@
 #include <asm/mipsmtregs.h>
 #endif /* CONFIG_MIPS_MT_SMTC */
 
+cpumask_t cpu_possible_map;
 cpumask_t phys_cpu_present_map;		/* Bitmask of available CPUs */
 volatile cpumask_t cpu_callin_map;	/* Bitmask of started secondaries */
 cpumask_t cpu_online_map;		/* Bitmask of currently online CPUs */
@@ -52,6 +53,8 @@ int __cpu_logical_map[NR_CPUS];		/* Map logical to physical */
 
 EXPORT_SYMBOL(phys_cpu_present_map);
 EXPORT_SYMBOL(cpu_online_map);
+EXPORT_SYMBOL(cpu_possible_map);
+EXPORT_SYMBOL(__cpu_number_map);
 
 extern void cpu_idle(void);
 
@@ -99,7 +102,7 @@ __cpuinit void register_smp_ops(struct plat_smp_ops *ops)
  */
 asmlinkage __cpuinit void start_secondary(void)
 {
-	unsigned int cpu;
+	unsigned int cpu = smp_processor_id();
 
 #ifdef CONFIG_MIPS_MT_SMTC
 	/* Only do cpu_probe for first TC of CPU */
@@ -115,7 +118,13 @@ asmlinkage __cpuinit void start_secondary(void)
 	 * XXX parity protection should be folded in here when it's converted
 	 * to an option instead of something based on .cputype
 	 */
-
+#ifdef CONFIG_RMI_PHOENIX
+	/*
+	 * Since we use pic timer of the platform as the jiffie, we
+	 * need to enable interrupt here before calibrate_delay.
+	 */
+	local_irq_enable();
+#endif
 	calibrate_delay();
 	preempt_disable();
 	cpu = smp_processor_id();
@@ -136,6 +145,8 @@ void arch_send_call_function_ipi(cpumask_t mask)
 	mp_ops->send_ipi_mask(mask, SMP_CALL_FUNCTION);
 }
 
+#include <asm/rmi/debug.h>
+#include <asm/rmi/mips-exts.h>
 /*
  * We reuse the same vector for the single IPI
  */
@@ -193,6 +204,15 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 /* preload SMP state for boot cpu */
 void __devinit smp_prepare_boot_cpu(void)
 {
+
+#ifdef CONFIG_RMI_PHOENIX
+	__u32 boot_cpu;
+	boot_cpu = hard_smp_processor_id();
+
+	__cpu_number_map[boot_cpu] = 0;
+	__cpu_logical_map[0] = boot_cpu;
+	cpu_set(boot_cpu, phys_cpu_present_map);
+#else
 	/*
 	 * This assumes that bootup is always handled by the processor
 	 * with the logic and physical number 0.
@@ -200,6 +220,7 @@ void __devinit smp_prepare_boot_cpu(void)
 	__cpu_number_map[0] = 0;
 	__cpu_logical_map[0] = 0;
 	cpu_set(0, phys_cpu_present_map);
+#endif
 	cpu_set(0, cpu_online_map);
 	cpu_set(0, cpu_callin_map);
 }
diff --git a/arch/mips/rmi/phoenix/Makefile b/arch/mips/rmi/phoenix/Makefile
index 15bc689..e04f0cb 100644
--- a/arch/mips/rmi/phoenix/Makefile
+++ b/arch/mips/rmi/phoenix/Makefile
@@ -1,4 +1,4 @@
 EXTRA_CFLAGS := -Werror
 obj-y := irq.o time.o
-
+obj-$(CONFIG_SMP)       += smp.o
 EXTRA_AFLAGS := $(CFLAGS)
diff --git a/arch/mips/rmi/phoenix/smp.c b/arch/mips/rmi/phoenix/smp.c
new file mode 100644
index 0000000..c09bdd0
--- /dev/null
+++ b/arch/mips/rmi/phoenix/smp.c
@@ -0,0 +1,129 @@
+/*********************************************************************
+
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+
+#include <asm/rmi/64bit.h>
+#include <asm/addrspace.h>
+#include <asm/smp.h>
+#include <linux/sched.h>
+#include <linux/types.h>
+#include <linux/hardirq.h>
+#include <linux/module.h>
+
+
+#include <asm/rmi/sim.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/pic.h>
+#include <asm/rmi/msgring.h>
+
+//#define IPI_PRINTK_DEBUG
+
+/* ipi statistics counters for debugging */
+__u32 ipi_3_counter_tx[NR_CPUS][NR_CPUS];
+__u32 ipi_3_counter_rx[NR_CPUS];
+
+extern void save_epc(unsigned long *epc);
+extern void smp_call_function_interrupt(void);
+extern void phoenix_smp_time_init(void);
+
+static int phoenix_ipi_stats[NR_CPUS];
+static unsigned long phoenix_ipi_epc[NR_CPUS];
+
+void core_send_ipi(int logical_cpu, unsigned int action)
+{
+	int cpu = cpu_logical_map(logical_cpu);
+	__u32 ipi = 0;
+	__u32 tid = cpu & 0x3;
+	__u32 pid = (cpu >> 2) & 0x07;
+
+	if (action & SMP_CALL_FUNCTION){
+		ipi = (tid << 16) | (pid << 20) | IRQ_IPI_SMP_FUNCTION;
+#ifdef IPI_PRINTK_DEBUG
+		printk("[%s]: cpu_%d sending ipi_3 to cpu_%d \t\t\t[->%u] \n", __FUNCTION__, 
+			smp_processor_id(), cpu, ipi_3_counter_tx[smp_processor_id()][cpu]+1);
+#endif
+	++ipi_3_counter_tx[smp_processor_id()][cpu]; 
+
+  	}
+	else if (action & SMP_RESCHEDULE_YOURSELF) {
+		ipi = (tid << 16) | (pid << 20) | IRQ_IPI_SMP_RESCHEDULE;
+#ifdef IPI_PRINTK_DEBUG
+		printk("[%s]: cpu_%d sending ipi_4 to cpu_%d\n", __FUNCTION__,
+			smp_processor_id(), cpu);     
+#endif
+	}else if (action & SMP_CALL_KGDB_HOOK) {
+#ifdef CONFIG_RMI_PHOENIX
+		ipi = (tid << 16) | (pid << 20) | (1 << 8) | IRQ_IPI_SMP_KGDB;
+#else
+		ipi = (tid << 16) | (pid << 20) | IRQ_IPI_SMP_KGDB;
+#endif
+#ifdef IPI_PRINTK_DEBUG
+		printk("Sending KGDB IPI 0x%08x to tid %d pid %d\n", ipi, tid, pid);
+#endif
+	} else if (action & SMP_OPROFILE_IPI){
+		ipi = (tid << 16) | (pid << 20) | IRQ_IPI_OPROFILE;
+#ifdef IPI_PRINTK_DEBUG
+		printk("Sending OPROFILE IPI 0x%08x to tid %d pid %d\n", ipi, tid, pid);
+#endif
+	}
+	else
+		BUG();
+  
+	pic_send_ipi(ipi);
+}
+
+extern __u64 phnx_irq_mask;
+
+void phoenix_ipi_handler(int irq, struct pt_regs *regs)
+{
+	phoenix_ipi_stats[smp_processor_id()]++;
+	save_epc(&phoenix_ipi_epc[smp_processor_id()]);
+
+	if (irq == IRQ_IPI_SMP_FUNCTION) {
+#ifdef IPI_PRINTK_DEBUG
+		printk("[%s]: cpu_%d processing ipi_%d [->%u]\n", __FUNCTION__, 
+		smp_processor_id(), irq, ipi_3_counter_rx[smp_processor_id()]++);
+#endif
+		++ipi_3_counter_rx[smp_processor_id()];
+		smp_call_function_interrupt();
+	}
+
+	else {
+#ifdef IPI_PRINTK_DEBUG
+		printk("[%s]: cpu_%d processing ipi_%d\n", __FUNCTION__, 
+		smp_processor_id(), irq);
+#endif
+
+	/* Announce that we are for reschduling */
+		set_need_resched();
+
+	}
+	phoenix_ipi_stats[smp_processor_id()]--;
+}
diff --git a/arch/mips/rmi/ptr/Makefile b/arch/mips/rmi/ptr/Makefile
new file mode 100644
index 0000000..8310361
--- /dev/null
+++ b/arch/mips/rmi/ptr/Makefile
@@ -0,0 +1,6 @@
+EXTRA_CFLAGS := -Werror
+obj-$(CONFIG_SMP)      += smp.o smpboot.o 
+EXTRA_AFLAGS := $(CFLAGS)
+EXTRA_CFLAGS += -I$(srctree)/include/asm/rmi
+
+
diff --git a/arch/mips/rmi/ptr/smp.c b/arch/mips/rmi/ptr/smp.c
new file mode 100644
index 0000000..a2d19ee
--- /dev/null
+++ b/arch/mips/rmi/ptr/smp.c
@@ -0,0 +1,220 @@
+/*********************************************************************
+
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+
+#include <asm/mipsregs.h>
+#include <asm/mmu_context.h>
+#include <asm/atomic.h>
+//#include <asm/cpumask.h>
+
+#include <asm/rmi/sim.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/phnx_user_mac.h>
+
+#include <asm/asm.h>
+#include <asm/mipsregs.h>
+#include <asm/processor.h>
+#include <asm/rmi/phnx_loader.h>
+#include <user/rmi/phnx_loader.h>
+extern volatile cpumask_t cpu_callin_map;
+extern void __init phoenix_smp_init(void); 
+extern void phoenix_smp_finish(void);
+
+extern void smp_tune_scheduling (void);
+extern void ptr_smp_boot(unsigned long, unsigned long, unsigned long);
+struct smp_boot_info smp_boot;
+extern void prom_reconfigure_thr_resources(void);
+extern unsigned long phnx_ebase;
+
+
+int phys_proc_id[NR_CPUS]; /* cpuid+thrid of each logical CPU */
+
+extern void asmlinkage smp_bootstrap(void);
+extern void core_send_ipi(int cpu, unsigned int action);
+
+void rmi_send_ipi_single(int cpu, unsigned int action)
+{
+    core_send_ipi(cpu, action);
+}
+
+void rmi_send_ipi_mask(cpumask_t mask, unsigned int action)
+{
+    int cpu;
+    for_each_cpu_mask(cpu, mask){
+		core_send_ipi(cpu, action);
+    }
+}
+
+/*
+ * Code to run on secondary just after probing the CPU
+ */
+static void __cpuinit rmi_init_secondary(void)
+{
+    extern void rmi_smp_irq_init(void);
+
+    rmi_smp_irq_init();
+    /* Time init for this cpu is done in mips_clockevent_init() */
+}
+
+void rmi_smp_finish(void)
+{
+    phoenix_msgring_cpu_init();
+}
+
+void rmi_cpus_done(void)
+{
+}
+
+/* Boot all other cpus in the system, initialize them, and
+   bring them into the boot fn */
+void rmi_boot_secondary(int logical_cpu, struct task_struct *idle)
+{
+	unsigned long gp = (unsigned long)task_thread_info(idle);
+	unsigned long sp = (unsigned long)__KSTK_TOS(idle);
+	int cpu = cpu_logical_map(logical_cpu);
+
+	dbg_msg("(PROM): waking up phys cpu# %d, gp = %lx\n", cpu, gp);
+  
+	smp_boot.boot_info[cpu].sp = sp;
+	smp_boot.boot_info[cpu].gp = gp;
+	smp_boot.boot_info[cpu].fn = (unsigned long)&smp_bootstrap;  
+	/* barrier */
+	__sync();
+	smp_boot.boot_info[cpu].ready = 1;
+  
+	dbg_msg("(PROM): sent a wakeup message to cpu %d\n", cpu);
+}
+
+unsigned int fast_syscall_cpumask_phy = 0x1;
+
+void __init rmi_smp_setup(void)
+{
+	int num_cpus = 1;
+	__u32 boot_cpu_online_map = 0, boot_cpu = 0x0;
+
+
+	extern __u32 ipi_3_counter_tx[NR_CPUS][NR_CPUS];
+	extern __u32 ipi_3_counter_rx[NR_CPUS];
+	int i = 0, j = 0;
+
+	boot_cpu = hard_smp_processor_id();
+
+	cpus_clear(phys_cpu_present_map);
+	/*	cpu_set(0, phys_cpu_present_map);
+	__cpu_number_map[0] = 0;
+	__cpu_logical_map[0] = 0;  
+	dev_tree_en fix , and also not required for the existing case also */
+
+	cpus_clear(cpu_possible_map);
+	/* cpu_set(0, cpu_possible_map); */
+
+	/* Initialize the ipi debug stat variables */
+	for (i = 0; i < NR_CPUS; i++) {
+		for (j = 0; j < NR_CPUS; j++)
+			ipi_3_counter_tx[i][j] = 0;
+  
+		ipi_3_counter_rx[i] = 0;
+	}
+
+
+	boot_cpu_online_map = smp_boot.online_map;
+	printk("(PROM) CPU present map: %x\n", boot_cpu_online_map);
+
+	/* 0th entry in the logical_map should be the bootcpu and all
+       others proceeds after that */
+	/* Fill the entries for boot cpu */
+	boot_cpu_online_map &= (~(1 << boot_cpu));
+	cpu_set(boot_cpu, phys_cpu_present_map);
+	__cpu_number_map[boot_cpu] = 0;
+	__cpu_logical_map[0] = boot_cpu;
+	cpu_set(0, cpu_possible_map);
+
+	for(i = 0; i < NR_CPUS; i++) {
+		if (boot_cpu_online_map & (1<<i)) {
+			cpu_set(i, phys_cpu_present_map);
+			__cpu_number_map[i] = num_cpus;
+			__cpu_logical_map[num_cpus] = i;
+			cpu_set(num_cpus, cpu_possible_map);
+			++num_cpus;
+		}
+	}
+
+
+	fast_syscall_cpumask_phy = (unsigned int)phys_cpu_present_map.bits[0];
+
+	printk("Phys CPU present map: %lx, possible map %lx\n", 
+	       (unsigned long)phys_cpu_present_map.bits[0], 
+	       (unsigned long)cpu_possible_map.bits[0]);
+
+	printk("Detected %i Slave CPU(s)\n", num_cpus);
+}
+
+void rmi_prepare_cpus(unsigned int max_cpus)
+{
+}
+
+
+struct plat_smp_ops rmi_smp_ops = {
+    .send_ipi_single    = rmi_send_ipi_single,
+    .send_ipi_mask      = rmi_send_ipi_mask,
+    .init_secondary     = rmi_init_secondary,
+    .smp_finish     = rmi_smp_finish,
+    .cpus_done      = rmi_cpus_done,
+    .boot_secondary     = rmi_boot_secondary,
+    .smp_setup      = rmi_smp_setup,
+    .prepare_cpus       = rmi_prepare_cpus,
+};
+
+
+
+void prom_boot_cpus_secondary(void *args)
+{
+	int cpu = hard_smp_processor_id();
+  
+	write_c0_ebase((uint32_t)phnx_ebase);
+	atomic_add((1<<cpu), (atomic_t *)&smp_boot.online_map);
+	for(;;){
+		if (smp_boot.boot_info[cpu].ready) break;
+	}
+	__sync();
+
+	prom_reconfigure_thr_resources();
+
+	ptr_smp_boot(smp_boot.boot_info[cpu].fn, smp_boot.boot_info[cpu].sp, 
+		     smp_boot.boot_info[cpu].gp);
+}
+
+
+
diff --git a/arch/mips/rmi/ptr/smpboot.S b/arch/mips/rmi/ptr/smpboot.S
new file mode 100644
index 0000000..9e4a504
--- /dev/null
+++ b/arch/mips/rmi/ptr/smpboot.S
@@ -0,0 +1,70 @@
+/*********************************************************************
+ *
+ * Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+ * reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ * 1. Redistributions of source code must retain the above copyright
+ * notice, this list of conditions and the following disclaimer.
+ * 2. Redistributions in binary form must reproduce the above copyright
+ * notice, this list of conditions and the following disclaimer in
+ * the documentation and/or other materials provided with the
+ * distribution.
+ *
+ * THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+ * PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+ * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+ * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+ * THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ ******************************#RMI_2#**********************************/
+
+#include <asm/asm.h>
+#include <asm/asm-offsets.h>
+#include <asm/regdef.h>
+#include <asm/mipsregs.h>
+
+NESTED(ptr_smp_boot, 16, sp)
+
+	move	sp, a1
+	move	gp, a2
+	jal	a0
+	nop
+	
+END(ptr_smp_boot)
+	
+/* Don't jump to linux function from Bootloader stack. Change it 
+ * here. Kernel might allocate bootloader memory before all the CPUs are 
+ * brought up (eg: Inode cache region) and we better don't overwrite this 
+ * memory
+ */
+NESTED(prom_pre_boot_secondary_cpus, 16, sp)
+	.set mips64
+	mfc0 t0, $15, 1 #read ebase
+	andi t0, 0x1f #t0 has the processor_id()
+	PTR_LA	t1, xlr_stack_pages_temp
+	li   t2, _THREAD_SIZE
+	srl  t2, 2
+	mul  t3, t2, t0
+	nop
+	nop
+	nop
+	nop
+	nop
+	nop
+	PTR_ADDU  gp, t1, t3
+	PTR_ADDU       sp, gp, t2
+	PTR_ADDI       sp, sp, -32
+	PTR_LA t0, prom_boot_cpus_secondary
+	jr t0
+	nop
+END(prom_pre_boot_secondary_cpus)
diff --git a/include/asm-mips/smp.h b/include/asm-mips/smp.h
index 220c18c..0f27545 100644
--- a/include/asm-mips/smp.h
+++ b/include/asm-mips/smp.h
@@ -1,3 +1,15 @@
+/************************************************************************
+
+  Copyright 2003-2006 RMI Corporation, Inc.(RMI).
+
+  This is a derived work from software originally provided by the external
+  entity identified below. The licensing terms and warranties specified in
+  the header of the original work apply to this derived work.
+
+  Contribution by RMI:
+
+ *****************************#RMI_1#************************************/
+
 /*
  * This file is subject to the terms and conditions of the GNU General
  * Public License.  See the file "COPYING" in the main directory of this
@@ -40,9 +52,14 @@ extern int __cpu_logical_map[NR_CPUS];
 
 extern volatile cpumask_t cpu_callin_map;
 extern cpumask_t phys_cpu_present_map;
+#ifdef CONFIG_RMI_PHOENIX
+extern cpumask_t cpu_possible_map;
+#else
 #define cpu_possible_map	phys_cpu_present_map
+#endif
 
 extern void asmlinkage smp_bootstrap(void);
+extern void core_send_ipi(int cpu, unsigned int action);
 
 /*
  * this function sends a 'reschedule' IPI to another CPU.
-- 
1.6.0.4

