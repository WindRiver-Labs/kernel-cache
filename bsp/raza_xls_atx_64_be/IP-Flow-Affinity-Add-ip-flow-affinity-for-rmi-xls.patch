From ead3dcd0ede5bdea89369b31e4f4b78da82cb61b Mon Sep 17 00:00:00 2001
From: Liu Changhui <changhui.liu@windriver.com>
Date: Fri, 29 Jan 2010 13:28:04 +0800
Subject: [PATCH] IP Flow Affinity: Add ip flow affinity for rmi xls

Add ip flow affinity for rmi xls.

Experimental feature of GMAC driver guranteeing that IP flows are processed
 on logical CPUs corresponding to buckets assigned by packet classifier engine.
E.g. for XLR core #X, packets arriving to buckets 0 & 4 are processed by thread 0,
 packets arriving to buckets 1 & 5 are processed by thread 1 and so on..
Such feature might be important for applications which require IP flows
be seen on one logcal CPUs. Use of this feature involves performance cost.

source: from RMI SDK1.7

Signed-off-by: shuo.kang <shuo.kang@windriver.com>
---
 arch/mips/rmi/Kconfig            |   14 ++++++
 arch/mips/rmi/phoenix/irq.c      |   10 ++++
 arch/mips/rmi/phoenix/smp.c      |   24 ++++++++++
 drivers/net/phoenix_mac.c        |   92 ++++++++++++++++++++++++++++++++++++++
 include/asm-mips/rmi/interrupt.h |    7 +++
 5 files changed, 147 insertions(+), 0 deletions(-)

diff --git a/arch/mips/rmi/Kconfig b/arch/mips/rmi/Kconfig
index 1f01c2e..2fe10de 100644
--- a/arch/mips/rmi/Kconfig
+++ b/arch/mips/rmi/Kconfig
@@ -73,6 +73,20 @@ config PHOENIX_HW_BUFFER_MGMT
 	  If in doubt, say N.
 
 
+config PHOENIX_IP_FLOW_AFFINITY
+	bool "Enable support for IP flow affinity"
+	depends on RMI_PHOENIX
+	default n
+	help
+	  Experimental feature of GMAC driver guranteeing that IP flows are processed 
+	  on logical CPUs corresponding to buckets assigned by packet classifier engine.
+	  E.g. for XLR core #X, packets arriving to buckets 0 & 4 are processed by thread 0,
+	  packets arriving to buckets 1 & 5 are processed by thread 1 and so on..
+	  Such feature might be important for applications which require IP flows 
+	  be seen on one logcal CPUs. Use of this feature involves performance cost.
+
+	  If in doubt, say N.
+
 config RMI_PHOENIX_LOAD_ADDRESS
 	hex "RMI Linux kernel start address"
 	depends on RMI_PHOENIX
diff --git a/arch/mips/rmi/phoenix/irq.c b/arch/mips/rmi/phoenix/irq.c
index 0fa03a0..872c71e 100644
--- a/arch/mips/rmi/phoenix/irq.c
+++ b/arch/mips/rmi/phoenix/irq.c
@@ -384,6 +384,12 @@ void __init init_phoenix_irqs(void)
 	irq_desc[IRQ_IPI_SMP_RESCHEDULE].action = &phnx_rsvd_action;
 
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	/* PR: New IPI added here for netrx balancing */
+	irq_desc[IRQ_IPI_NETRX].chip = &phnx_rsvd_pic;
+	irq_desc[IRQ_IPI_NETRX].action = &phnx_rsvd_action;
+	phnx_irq_mask |= (1ULL<<IRQ_IPI_NETRX);
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
 
 	phnx_irq_mask |= ((1ULL<<IRQ_IPI_SMP_FUNCTION)|(1ULL<<IRQ_IPI_SMP_RESCHEDULE));
 #endif
@@ -429,7 +435,11 @@ void do_phnx_IRQ(unsigned int irq, struct pt_regs *regs)
 
 #ifdef CONFIG_SMP
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	if  (irq == IRQ_IPI_SMP_FUNCTION || irq == IRQ_IPI_SMP_RESCHEDULE || irq== IRQ_IPI_NETRX) {
+#else
 	if  (irq == IRQ_IPI_SMP_FUNCTION || irq == IRQ_IPI_SMP_RESCHEDULE) {
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
 		phoenix_ipi_handler(irq, regs);
 		return;
 	}
diff --git a/arch/mips/rmi/phoenix/smp.c b/arch/mips/rmi/phoenix/smp.c
index c09bdd0..ffc54fe 100644
--- a/arch/mips/rmi/phoenix/smp.c
+++ b/arch/mips/rmi/phoenix/smp.c
@@ -37,6 +37,9 @@
 #include <linux/hardirq.h>
 #include <linux/module.h>
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+extern void skb_transfer_finish(void);
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
 
 #include <asm/rmi/sim.h>
 #include <asm/rmi/mips-exts.h>
@@ -93,6 +96,17 @@ void core_send_ipi(int logical_cpu, unsigned int action)
 		printk("Sending OPROFILE IPI 0x%08x to tid %d pid %d\n", ipi, tid, pid);
 #endif
 	}
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	else if (action & SMP_NETRX_IPI)
+	{
+		ipi = (tid << 16) | (pid << 20) | IRQ_IPI_NETRX;
+#ifdef IPI_PRINTK_DEBUG
+		printk(KERN_ALERT "%s: Sending NETRX IPI 0x%08x to tid %d pid %d\n",
+                 __FUNCTION__, ipi, tid, pid);
+#endif /* IPI_PRINTK_DEBUG */
+	}
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
 	else
 		BUG();
   
@@ -114,7 +128,17 @@ void phoenix_ipi_handler(int irq, struct pt_regs *regs)
 		++ipi_3_counter_rx[smp_processor_id()];
 		smp_call_function_interrupt();
 	}
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	else if (irq == IRQ_IPI_NETRX)
+	{
+		irq_enter();
 
+		skb_transfer_finish();
+
+		/* run soft IRQ at the end */
+		irq_exit();
+	}
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
 	else {
 #ifdef IPI_PRINTK_DEBUG
 		printk("[%s]: cpu_%d processing ipi_%d\n", __FUNCTION__, 
diff --git a/drivers/net/phoenix_mac.c b/drivers/net/phoenix_mac.c
index c1967f4..dd11f63 100644
--- a/drivers/net/phoenix_mac.c
+++ b/drivers/net/phoenix_mac.c
@@ -318,6 +318,30 @@ static inline void prefetch_local(const void *addr)
 
 
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+/* skb transfer statistics */
+unsigned long long skb_transfer_stat[NR_CPUS][NR_CPUS];
+void skb_transfer_finish(void);
+static void skb_transfer(int bucket, struct sk_buff *skb);
+
+
+/* skb transfer queues, one per CPU */
+static struct sk_buff_head cpu_skb_tqueue[NR_CPUS];
+
+static void
+cpu_tx_queue_init(void)
+{
+	int i;
+
+	for (i = 0; i < NR_CPUS; i++)
+	{
+		skb_queue_head_init(&(cpu_skb_tqueue[i]));
+	}
+}
+
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
+
 /* This message ring interrupt type, can be adjusted by NAPI setup callback */
 extern int msgring_int_type;
 extern struct user_mac_data *user_mac;
@@ -2619,8 +2643,12 @@ do { \
 				 (read_c0_count() - msgrng_msg_cycles));
 
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+		skb_transfer(bucket, skb);
+#else
 		skb->dev->last_rx = jiffies;
 		netif_rx(skb);
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
 
 	} else {
 		printk("[%s]: unrecognized ctrl=%d!\n", __FUNCTION__,
@@ -2745,6 +2773,66 @@ void rmi_phnx_station_unowned_msgring_handler(int bucket, int size,
 }
 
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+extern void core_send_ipi(int cpu, unsigned int action);
+
+static void
+skb_transfer(int bucket, struct sk_buff *skb)
+{
+	u_long my_cpu_no, my_thread_no, my_core_no, target_cpu_no, target_thread_no;
+
+
+	target_thread_no = bucket & 0x3;
+	my_cpu_no = smp_processor_id();
+	my_thread_no = phoenix_thr_id();
+	my_core_no = phoenix_cpu_id();
+	target_cpu_no = cpu_number_map((my_core_no << 2) | target_thread_no);
+
+  /*
+   * Version with NETRX IPI aggregation
+  */
+	if (target_thread_no != my_thread_no && cpu_isset(target_cpu_no, cpu_online_map))
+	{
+		unsigned long flags;
+		struct sk_buff_head *ptqueue = &cpu_skb_tqueue[target_cpu_no];
+
+		spin_lock_irqsave(&ptqueue->lock, flags);
+		if (ptqueue->qlen)
+		{
+			__skb_queue_tail(ptqueue, skb);
+		}
+		else{
+			__skb_queue_tail(ptqueue, skb);
+			core_send_ipi(target_cpu_no, SMP_NETRX_IPI);
+		}
+		spin_unlock_irqrestore(&ptqueue->lock, flags);
+
+		skb_transfer_stat[my_cpu_no][target_cpu_no]++;
+	}
+	else{
+		skb_transfer_stat[my_cpu_no][my_cpu_no]++;
+
+		skb_queue_tail(&cpu_skb_tqueue[my_cpu_no], skb);
+		skb_transfer_finish();
+	}
+}
+
+
+/* second part of SKB transfer logic, called from IRQ_IPI_NETRX handler */
+void
+skb_transfer_finish(void)
+{
+	struct sk_buff *skb;
+	u_long cpu = smp_processor_id();
+
+	while ((skb = skb_dequeue(&cpu_skb_tqueue[cpu])) != NULL)
+	{
+		skb->dev->last_rx = jiffies;
+		netif_rx(skb);
+	}
+}
+
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
 
 
 /**********************************************************************
@@ -4385,6 +4473,10 @@ int rmi_phnx_mac_init_module(void)
 		priv->phy.serdes_addr =
 		    mac_addr_to_ptr(port_cfg->serdes_addr);
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+		/* initialize cpu skb queues */
+		cpu_tx_queue_init();
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
 
 		phnx_mac_get_hwaddr(dev);
 
diff --git a/include/asm-mips/rmi/interrupt.h b/include/asm-mips/rmi/interrupt.h
index 5e44062..4fa6fcd 100644
--- a/include/asm-mips/rmi/interrupt.h
+++ b/include/asm-mips/rmi/interrupt.h
@@ -47,6 +47,13 @@
 #define IRQ_IPI_CRF_MGMT_IPI	45 /* */
 #define IRQ_IPI_CRF_EVENTQ_IPI 46 
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+
+#define IRQ_IPI_NETRX           49
+#define SMP_NETRX_IPI           32
+
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
 
 #define SMP_CALL_KGDB_HOOK 	8
 #define SMP_OPROFILE_IPI        16
-- 
1.6.0.4

