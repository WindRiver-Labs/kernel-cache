From 40a8a6809f32bd5d2a0731cb4e87f7e198194cc8 Mon Sep 17 00:00:00 2001
From: Liu Changhui <changhui.liu@windriver.com>
Date: Fri, 29 Jan 2010 13:28:02 +0800
Subject: [PATCH] Ethernet: Add ethernet driver for rmi xls

Add ethernet driver for rmi xls.

source: from RMI SDK1.7

Signed-off-by: shuo.kang <shuo.kang@windriver.com>
---
 drivers/net/Makefile               |    1 +
 drivers/net/phoenix_mac.c          | 4474 ++++++++++++++++++++++++++++++++++++
 drivers/net/phoenix_user_mac.c     | 1457 ++++++++++++
 include/asm-mips/rmi/phoenix_mac.h | 1163 ++++++++++
 include/asm-mips/rmi/xgmac_mdio.h  |  119 +
 include/user/rmi/phnx_user_mac.h   |  132 ++
 6 files changed, 7346 insertions(+), 0 deletions(-)
 create mode 100644 drivers/net/phoenix_mac.c
 create mode 100644 drivers/net/phoenix_user_mac.c
 create mode 100644 include/asm-mips/rmi/phoenix_mac.h
 create mode 100644 include/asm-mips/rmi/xgmac_mdio.h
 create mode 100644 include/user/rmi/phnx_user_mac.h

diff --git a/drivers/net/Makefile b/drivers/net/Makefile
index 0818ce2..7405ef2 100644
--- a/drivers/net/Makefile
+++ b/drivers/net/Makefile
@@ -120,6 +120,7 @@ obj-$(CONFIG_ES3210) += es3210.o 8390.o
 obj-$(CONFIG_LNE390) += lne390.o 8390.o
 obj-$(CONFIG_NE3210) += ne3210.o 8390.o
 obj-$(CONFIG_SB1250_MAC) += sb1250-mac.o
+obj-$(CONFIG_PHOENIX_MAC) += phoenix_mac.o phoenix_user_mac.o
 obj-$(CONFIG_B44) += b44.o
 obj-$(CONFIG_FORCEDETH) += forcedeth.o
 obj-$(CONFIG_NE_H8300) += ne-h8300.o
diff --git a/drivers/net/phoenix_mac.c b/drivers/net/phoenix_mac.c
new file mode 100644
index 0000000..58cf758
--- /dev/null
+++ b/drivers/net/phoenix_mac.c
@@ -0,0 +1,4474 @@
+/*********************************************************************
+
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/types.h>
+#include <linux/string.h>
+#include <linux/socket.h>
+#include <linux/errno.h>
+#include <linux/fcntl.h>
+#include <linux/in.h>
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/workqueue.h>
+#include <linux/kernel.h>
+#include <linux/inet.h>
+#include <linux/netdevice.h>
+#include <linux/ethtool.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <net/sock.h>
+#include <linux/if_ether.h>	/* For the statistics structure. */
+#include <linux/if_arp.h>	/* For ARPHRD_ETHER */
+#include <linux/autoconf.h>
+#include <linux/proc_fs.h>
+#include <linux/mii.h>
+#include <linux/delay.h>
+#include <asm/system.h>
+#include <asm/uaccess.h>
+#include <asm/io.h>
+#include <asm/cache.h>
+
+#include <asm/rmi/debug.h>
+#include <asm/rmi/pci.h>
+#include <asm/rmi/pic.h>
+#include <asm/rmi/phoenix_mac.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/atx_cpld.h>
+#include <asm/rmi/xgmac_mdio.h>
+#include <asm/rmi/proc.h>
+#include <asm/smp.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/gpio.h>
+#include <user/rmi/phnx_user_mac.h>
+
+#define DRV_NAME	"rmi_phnx_mac"
+#define DRV_VERSION	"0.1"
+/* #define DEBUG */
+
+#ifdef DEBUG
+#undef dbg_msg
+int mac_debug = 1;
+#define dbg_msg(fmt, args...) \
+        do {\
+            if (mac_debug) {\
+                printk("[%s@%d|%s]: cpu_%d: " fmt, \
+                __FILE__, __LINE__, __FUNCTION__,  smp_processor_id(), ##args);\
+            }\
+        } while(0);
+
+#define DUMP_PACKETS
+#else
+#undef dbg_msg
+#define dbg_msg(fmt, args...)
+int mac_debug = 0;
+#endif
+extern int xlr_loader_support;
+extern int xlr_loader_sharedcore;
+extern int xlr_loader_own_gmac;
+
+
+extern struct proc_dir_entry *rmi_root_proc;
+extern int xlsb0_in_xaui(int block);
+
+
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+void dump_all_interface(unsigned int reg);
+void (*p_ptp_set_ts) (u32, u32, ktime_t *, u32);
+#endif
+/* 
+ *  Packet dump tools
+*/
+#define dump_packet(skb) \
+do \
+{ \
+	int i = 0; \
+	printk("%s: Packet: length=%d\n", __FUNCTION__, skb->len); \
+	for (i = 0; i < 64; i++) { \
+		printk("%02x ", skb->data[i]); \
+		if (i && (i % 16) == 0) \
+			printk("\n"); \
+	} \
+	printk("\n"); \
+} while (0)
+
+
+
+/*
+ * This macro returns non-zero if any of the upper buckets (4-7) is non-empty
+*/
+#define upper_buckets_nonempty() ((~msgrng_read_status() >> 28) & 0xf)
+
+
+extern __u32 cpu_to_frstid[];
+extern __u32 cpu_to_bktmask[];
+extern uint32_t hard_cpu_online_map;
+uint64_t free_back_stid_map = 0ULL;
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+
+/* XLR_NAPI global data strucutre */
+struct net_device xlr_napi_dummy_dev;
+DEFINE_PER_CPU(struct napi_struct, xlr_napi_poll_struct);
+EXPORT_SYMBOL(xlr_napi_dummy_dev);
+EXPORT_PER_CPU_SYMBOL(xlr_napi_poll_struct);
+
+/* XLR NAPI per CPU packet counter */
+DEFINE_PER_CPU(unsigned long long, xlr_napi_rx_count);
+
+/* NAPI is disabled by default */
+int rmi_msgring_napi = 0;
+int rmi_on_chip_napi = 0;
+EXPORT_SYMBOL(rmi_on_chip_napi);
+int xlr_napi_ready = 0;
+EXPORT_SYMBOL(xlr_napi_ready);
+static inline void rmi_phnx_free_skb(struct msgrng_msg *msg);
+
+struct napi_control_s {
+	/* core-wide lock */
+	spinlock_t xlr_napi_msgrng_lock
+	    __attribute__ ((aligned(SMP_CACHE_BYTES)));
+
+	/* Mask tracking if NetRx SoftIRQ is scheduled on core's threads
+	 *
+	 * Only bits 0-3 are used:
+	 *
+	 *   i-th bit 0:  iff netrx SoftIRQ has been scheduled for thread i
+	 *   i-th bit 1:  iff netrx SoftIRQ has NOT been scheduled for thread i
+	 */
+	unsigned long netrx_mask;
+};
+
+__aligned(SMP_CACHE_BYTES)
+struct napi_control_s napi_control[NR_CPUS / 4];
+
+
+/* We need this little hack to improve handler speed */
+static int *rxstn_to_txstn_ptr;
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+
+#define MAC_B2B_IPG             88
+
+/* 
+ * Weight for GMAC/XGMAC NAPI polls. We override standard value of 300 
+ * to improve packet forwarding rate 
+*/
+#define XLR_NAPI_WEIGHT		1200
+static int napi_weight = XLR_NAPI_WEIGHT;
+
+
+/* 
+ * TCP stack termination in NAPI mode requires spill area for FreeOut's of 
+ * considerable size. We always set it to 15K descriptors which traslates into
+ * 15K * 8 bytes kernel memory alloc.
+*/
+#define XLR_FROUT_JUMBO_SPILL	(15 * 1024)
+
+
+/* NOTE:
+   Don't change this threshold to > 15 if MAX_NUM_DESC is 512. 
+   When msgring_thread_mask is 0xf, each cpu could receive 16 packets 
+   and replenishment may never happen.
+   THRESHOLD should be less than 
+   max_num_desc / (number of threads processing msgring * number of cores)
+   */
+#define MAC_FRIN_TO_BE_SENT_THRESHOLD max_frin_threshold
+#define MAC_FRIN_WORK_NUM 32
+
+/* Computed as described above */
+static int max_frin_threshold;
+
+/* Total Nr of Free Descriptors to GMACs > 2816 for Usermac 
+ * If configuring max_num_desc use at least 2816/4.
+ */
+
+static struct net_device *dev_mac[PHOENIX_MAX_MACS];
+struct net_device *dev_mac_type[MAX_NET_TYPES][PHOENIX_MAX_MACS];
+#define mac_addr_to_ptr(x) ((void *)(long)x)
+
+#define PHNX_NUM_REG_DUMP 9	/* Register 0xa0 to 0xa8 */
+#define PHNX_ETHTOOL_REG_LEN (PHNX_NUM_REG_DUMP * 4)
+
+static void xlr_get_mac_stats(struct net_device *dev,
+			      struct net_device_stats *stats);
+
+/*
+ * New message assembly toolbox: newer, faster versions of messge send functions!
+ *
+ * NB: Please be advised that they require interrupts be off
+ *
+ * TODO: move them into msgring.h, if all goes well here
+*/
+static inline int
+message_send_fast_1(unsigned int code,
+		    unsigned int stid, unsigned long long msg0)
+{
+	int ret, retry = 16;
+
+
+	msgrng_load_tx_msg0(msg0);
+
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     ".set mips64\n"
+			     "move $8, %1\n"
+			     "1: c2 0x80001\n"
+			     "mfc2 $8, " STR(MSGRNG_MSG_STATUS_REG) "\n"
+			     "andi $8, $8, 0x6\n"
+			     "beqz $8, 2f\n"
+			     "addi %2, -1\n"
+			     "bnez %2, 1b\n"
+			     "move $8, %1\n"
+			     "addiu $8, $0, 4\n"
+			     "2: move %0, $8\n" ".set pop\n":"=r"(ret)
+			     :"r"((code << 8) | stid), "r"(retry)
+			     :"$8");
+	return ret;
+}
+
+
+static inline int
+message_send_fast_2(unsigned int code,
+		    unsigned int stid,
+		    unsigned long long msg0, unsigned long long msg1)
+{
+	int ret, retry = 16;
+
+
+	msgrng_load_tx_msg0(msg0);
+	msgrng_load_tx_msg1(msg1);
+
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     ".set mips64\n"
+			     "move $8, %1\n"
+			     "1: c2 0x80001\n"
+			     "mfc2 $8, " STR(MSGRNG_MSG_STATUS_REG) "\n"
+			     "andi $8, $8, 0x6\n"
+			     "beqz $8, 2f\n"
+			     "addi %2, -1\n"
+			     "bnez %2, 1b\n"
+			     "move $8, %1\n"
+			     "addiu $8, $0, 4\n"
+			     "2: move %0, $8\n" ".set pop\n":"=r"(ret)
+			     :"r"((1 << 16) | (code << 8) | stid),
+			     "r"(retry)
+			     :"$8");
+	return ret;
+}
+
+
+#define message_receive_fast_1(bucket, size, code, stid, msg0)   \
+        ( { unsigned int _status=0, _tmp=0;                     \
+           msgrng_receive(bucket);                              \
+           while ( (_status=msgrng_read_status()) & 0x08) ;     \
+           _tmp = _status & 0x30;                               \
+           if (likely(!_tmp)) {                                 \
+                 (size)=((_status & 0xc0)>>6)+1;                \
+                 (code)=(_status & 0xff00)>>8;                  \
+                 (stid)=(_status & 0x7f0000)>>16;               \
+                 (msg0)=msgrng_load_rx_msg0();                  \
+                 _tmp=0;                                        \
+                }                                               \
+           _tmp;                                                \
+        } )
+
+
+static inline void prefetch_local(const void *addr)
+{
+	__asm__ __volatile__("	.set	mips4		\n"
+			     "	pref	%0, (%1)	\n"
+			     "	.set	mips0		\n"::"i"
+			     (Pref_StoreStreamed), "r"(addr));
+}
+
+
+
+/* This message ring interrupt type, can be adjusted by NAPI setup callback */
+extern int msgring_int_type;
+extern struct user_mac_data *user_mac;
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+static int rmi_phnx_napi_setup(void);
+#endif
+
+
+/* global flag for automatic hardware buffer management, disabled by default */
+int rmi_auto_buffer_mgmt = 0;
+
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+void xlr_napi_rx_schedule(void);
+static int mac_frin_replenish_one_msg(struct net_device *dev);
+static int rmi_phnx_napi_mac_xmit(struct sk_buff *skb,
+				  struct net_device *dev);
+
+/*
+ * get_adjusted_bucket_index: returns index of the highest bit set incremented by 4
+ * 
+ * E.g.: get_adjusted_bucket_index(1) = 4
+ *       get_adjusted_bucket_index(2) = 5
+ *       get_adjusted_bucket_index(3) = 5
+ *
+*/
+static inline int get_adjusted_bucket_index(int word)
+{
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     ".set mips64\n"
+			     "clz %0, %1\n"
+			     ".set pop\n":"=r"(word):"r"(word));
+	return 35 - word;
+}
+
+
+/*
+ * The following function checks if bucket/freeback allocation scheme is NAPI-compatible
+ *
+ * Returns 0 if napi compatibility fails and != 0 otherwise
+*/
+static int rmi_napi_compatibility_check(void)
+{
+	__u32 freeback, i;
+
+
+	printk("MSGRING_NAPI: HARD_CPU_ONLINE_MAP: 0x%08x\n",
+	       hard_cpu_online_map);
+
+
+	for (i = 0; i < NR_CPUS; i++) {
+
+		if ((hard_cpu_online_map & (1 << i)) == 0) {
+			continue;
+		}
+
+		freeback = i / 4 * 8 + i % 4 + 4;
+
+		if (cpu_to_frstid[i] != freeback) {
+
+			printk
+			    ("MSGRING_NAPI: Bucket allocation is not compatible with NAPI mode\n");
+			printk
+			    ("MSGRING_NAPI: Conflict detected: thread %d, freeback %d\n",
+			     i, cpu_to_frstid[i]);
+			printk("MSGRING_NAPI: Expected freeback %d\n",
+			       freeback);
+
+			return 0;
+		}
+	}
+	return 1;
+}
+
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+/*****************************************************************
+ * Phoenix Generic Mac driver
+ *****************************************************************/
+
+typedef enum { phnx_mac_speed_10, phnx_mac_speed_100,
+	phnx_mac_speed_1000, phnx_mac_speed_rsvd
+} phnx_mac_speed_t;
+
+typedef enum { phnx_mac_duplex_auto, phnx_mac_duplex_half,
+	phnx_mac_duplex_full
+} phnx_mac_duplex_t;
+
+typedef enum { phnx_mac_fc_auto, phnx_mac_fc_disabled, phnx_mac_fc_frame,
+	phnx_mac_fc_collision, phnx_mac_fc_carrier
+} phnx_mac_fc_t;
+
+/* These 2 structures are always indexed by "hard_smp_processor_id()" */
+static struct work_struct mac_frin_replenish_work[MAC_FRIN_WORK_NUM];
+static struct tasklet_struct mac_frin_replenish_task[MAC_FRIN_WORK_NUM];
+
+struct cpu_stat {
+	unsigned long tx_packets;
+	unsigned long txc_packets;
+	unsigned long rx_packets;
+	unsigned long interrupts;
+};
+
+struct phy_info {
+	int addr;
+	int mode;
+	phoenix_reg_t *mii_addr;
+	phoenix_reg_t *pcs_addr;
+	phoenix_reg_t *serdes_addr;
+};
+
+struct driver_data {
+
+	/* Let these be the first fields in this structure 
+	 * the structure is cacheline aligned when allocated in 
+	 * init_etherdev
+	 */
+	struct fr_desc *frin_spill;
+	struct fr_desc *frout_spill;
+	union rx_tx_desc *class_0_spill;
+	union rx_tx_desc *class_1_spill;
+	union rx_tx_desc *class_2_spill;
+	union rx_tx_desc *class_3_spill;
+
+	struct net_device *dev;	/* pointer to linux device */
+	struct timer_list link_timer;	/* for monitoring MII */
+	struct net_device_stats stats;
+	spinlock_t lock;
+
+	phoenix_reg_t *mmio;
+
+	__u8 hwaddr[6];
+	int phy_oldbmsr;
+	int phy_oldanlpar;
+	int phy_oldk1stsr;
+	int phy_oldlinkstat;
+	unsigned char phys_addr[2];
+
+	phnx_mac_speed_t speed;	/* current speed */
+	phnx_mac_duplex_t duplex;	/* current duplex */
+	phnx_mac_fc_t flow_ctrl;	/* current flow control setting */
+	int advertising;
+
+	int id;
+	int type;
+	int instance;
+	uint32_t cfg_flag;
+
+	int spill_init;
+	int config_pde;
+	int num_desc;
+
+	struct phy_info phy;
+
+	atomic_t frin_to_be_sent[MAC_FRIN_WORK_NUM];
+	int init_frin_desc;
+
+	struct cpu_stat cpu_stats[NR_CPUS];
+
+	int fr_stid;
+	int tx_stid;
+	int frstid_rsvd;
+};
+
+enum {
+	PORT_TX,
+	PORT_TX_COMPLETE,
+	PORT_STARTQ,
+	PORT_STOPQ,
+	PORT_START_DEV_STATE,
+	PORT_STOP_DEV_STATE,
+};
+
+#define port_inc_counter(port, counter) 	atomic_inc(&port_counters[port][(counter)])
+#define port_set_counter(port, counter, value) 	atomic_set(&port_counters[port][(counter)], (value))
+static atomic_t port_counters[8][8] __cacheline_aligned;
+static spinlock_t pending_tx_lock[PHOENIX_MAX_MACS] __cacheline_aligned;
+static volatile int pending_tx[PHOENIX_MAX_MACS] __cacheline_aligned;
+
+int mac_xmit(struct sk_buff *skb, struct net_device *dev,
+	     struct driver_data *priv, int txq);
+
+static __inline__ unsigned int rmi_ldadd_wu(unsigned int value,
+					    unsigned long *addr)
+{
+	__asm__ __volatile__(".set push\n"
+			     ".set noreorder\n"
+			     ".set mips64\n"
+			     "move $8, %2\n" "move $9, %3\n"
+#ifdef CONFIG_64BIT
+			     //"ldadd $8, $9\n"
+			     ".dword 0x71280012\n"
+#else
+			     //"ldaddwu $8, $9\n"
+			     ".word 0x71280011\n"
+#endif
+			     "move %0, $8\n"
+			     ".set pop\n":"=&r"(value), "+m"(*addr)
+			     :"0"(value), "r"((unsigned long) addr)
+			     :"$8", "$9");
+	return value;
+}
+
+#define mac_stats_add(x, val) rmi_ldadd_wu(val, &x)
+
+void mac_stats_update(int pkts, struct sk_buff *skb)
+{
+	struct driver_data *priv;
+	priv = netdev_priv(skb->dev);
+	mac_stats_add(priv->stats.rx_packets, pkts);
+	mac_stats_add(priv->stats.rx_bytes, skb->len);
+}
+
+void rmi_phnx_mac_set_enable(struct driver_data *priv, int flag);
+static void phnx_mac_set_rx_mode(struct net_device *dev);
+void rmi_phnx_mac_msgring_handler(int bucket, int size, int code,
+				  int stid, struct msgrng_msg *msg,
+				  void *data);
+static irqreturn_t rmi_phnx_mac_int_handler(int irq, void *dev_id);
+static int rmi_phnx_mac_open(struct net_device *dev);
+static int rmi_phnx_mac_xmit(struct sk_buff *skb, struct net_device *dev);
+static int rmi_phnx_mac_close(struct net_device *dev);
+static void rmi_phnx_mac_timer(unsigned long data);
+static struct net_device_stats *rmi_phnx_mac_get_stats(struct net_device
+						       *dev);
+static void rmi_phnx_mac_set_multicast_list(struct net_device *dev);
+static int rmi_phnx_mac_do_ioctl(struct net_device *dev,
+				 struct ifreq *rq, int cmd);
+static void rmi_phnx_mac_tx_timeout(struct net_device *dev);
+static int rmi_phnx_mac_change_mtu(struct net_device *dev, int new_mtu);
+static int rmi_phnx_mac_fill_rxfr(struct net_device *dev);
+static void rmi_phnx_config_spill_area(struct driver_data *priv);
+static int mac_frin_replenish_one_msg(struct net_device *dev);
+
+
+
+#define MSGRING_PROCESS_FROUT_START_BUCKET 4
+#define MSGRING_PROCESS_FROUT_END_BUCKET 8
+#define MSGRING_PROCESS_FROUT_POP_BUCKET_MASK 0xf0
+void msgring_process_rx_msgs(int start_bucket, int end_bucket,
+			     __u32 pop_bucket_mask);
+
+
+
+/*****************************************************************
+ * Driver Helper Functions
+ *****************************************************************/
+
+static __inline__ struct sk_buff *mac_get_skb_back_ptr(unsigned long addr)
+{
+	unsigned long *back_ptr =
+	    (unsigned long *) (addr - MAC_SKB_BACK_PTR_SIZE);
+	dbg_msg("addr = %lx,  skb = %lx\n", addr, *back_ptr);
+	/* this function should be used only for newly allocated packets. It assumes
+	 * the first cacheline is for the back pointer related book keeping info
+	 */
+	return (struct sk_buff *) (*back_ptr);
+}
+
+static __inline__ void mac_put_skb_back_ptr(struct sk_buff *skb)
+{
+	unsigned long *back_ptr = (unsigned long *) skb->data;
+
+	/* this function should be used only for newly allocated packets. It assumes
+	 * the first cacheline is for the back pointer related book keeping info
+	 */
+	skb_reserve(skb, MAC_SKB_BACK_PTR_SIZE);
+	*back_ptr = (unsigned long) skb;
+	dbg_msg("p=%p, skb=%p\n", back_ptr, skb);
+}
+
+#define CACHELINE_ALIGNED_ADDR(addr) (((unsigned long)(addr)) & ~(SMP_CACHE_BYTES-1))
+
+static __inline__ void *cacheline_aligned_kmalloc(int size, int gfp_mask)
+{
+	void *buf = kmalloc(size + SMP_CACHE_BYTES, gfp_mask);
+	if (buf)
+		buf =
+		    (void
+		     *) (CACHELINE_ALIGNED_ADDR((unsigned long) buf +
+						SMP_CACHE_BYTES));
+	return buf;
+}
+
+static __inline__ struct sk_buff *rmi_phnx_alloc_skb(void)
+{
+	int offset = 0;
+	struct sk_buff *skb =
+	    __dev_alloc_skb(PHNX_RX_BUF_SIZE, GFP_KERNEL);
+
+	if (!skb) {
+		return NULL;
+	}
+
+	/* align the data to the next cache line */
+	offset = ((unsigned long) skb->data + SMP_CACHE_BYTES) &
+	    ~(SMP_CACHE_BYTES - 1);
+	skb_reserve(skb, (offset - (unsigned long) skb->data));
+
+	return skb;
+}
+
+/**********************************************************************
+ **********************************************************************/
+void rmi_phnx_mac_set_enable(struct driver_data *priv, int flag)
+{
+	uint32_t regval;
+	int tx_threshold = 1518;
+
+	if (!(PORT_EN(priv->cfg_flag)))
+		return;
+
+
+	if (flag) {
+		regval = phoenix_read_reg(priv->mmio, R_TX_CONTROL);
+		regval |= (1 << O_TX_CONTROL__TxEnable) |
+		    (tx_threshold << O_TX_CONTROL__TxThreshold);
+
+		phoenix_write_reg(priv->mmio, R_TX_CONTROL, regval);
+
+		regval = phoenix_read_reg(priv->mmio, R_RX_CONTROL);
+		regval |= 1 << O_RX_CONTROL__RxEnable;
+		if (priv->phy.serdes_addr != 0
+		    && (priv->phy.mode & PHY_MODE_RGMII))
+			regval |= 1 << O_RX_CONTROL__RGMII;
+		phoenix_write_reg(priv->mmio, R_RX_CONTROL, regval);
+	} else {
+		regval = phoenix_read_reg(priv->mmio, R_TX_CONTROL);
+		regval &= ~((1 << O_TX_CONTROL__TxEnable) |
+			    (tx_threshold << O_TX_CONTROL__TxThreshold));
+
+		phoenix_write_reg(priv->mmio, R_TX_CONTROL, regval);
+
+		regval = phoenix_read_reg(priv->mmio, R_RX_CONTROL);
+		regval &= ~(1 << O_RX_CONTROL__RxEnable);
+		phoenix_write_reg(priv->mmio, R_RX_CONTROL, regval);
+	}
+}
+
+
+
+/**********************************************************************
+ **********************************************************************/
+static __inline__ int phnx_mac_send_fr(struct driver_data *priv,
+				       unsigned long addr, int len)
+{
+	int stid = 0;
+	struct msgrng_msg msg;
+
+	stid = priv->fr_stid;
+	msg.msg0 = (uint64_t) addr & 0xffffffffe0ULL;
+	msg.msg1 = msg.msg2 = msg.msg3 = 0;
+
+	/* Send the packet to MAC */
+	dbg_msg("mac_%d: Sending free packet to stid %d\n",
+		priv->instance, stid);
+	__sync();
+	if (priv->type == TYPE_XGMAC) {
+		while (message_send_fast_1
+		       (MSGRNG_CODE_XGMAC, stid, msg.msg0));
+	} else {
+		while (message_send_fast_1
+		       (MSGRNG_CODE_MAC, stid, msg.msg0));
+	}
+
+	/* Let the mac keep the free descriptor */
+	return 0;
+}
+
+
+
+
+
+/*
+ * Configure and send SKB to device free-in ring
+*/
+static int mac_frin_send_skb(struct net_device *dev, struct sk_buff *skb)
+{
+	int offset = 0;
+	unsigned long msgrng_flags = 0;
+	struct driver_data *priv;
+
+
+	priv = netdev_priv(dev);
+
+	/* align the data to the next cache line */
+	offset =
+	    (((unsigned long) skb->data +
+	      SMP_CACHE_BYTES) & ~(SMP_CACHE_BYTES - 1));
+	skb_reserve(skb, (offset - (unsigned long) skb->data));
+
+
+	mac_put_skb_back_ptr(skb);
+	msgrng_access_enable(msgrng_flags);
+	if (phnx_mac_send_fr(priv, virt_to_bus(skb->data), skb->len)) {
+		dev_kfree_skb(skb);
+		printk("[%s]: rx free message_send failed!\n",
+		       __FUNCTION__);
+	}
+	msgrng_access_disable(msgrng_flags);
+
+	return 0;
+}
+
+
+/*
+ * Allocates new SKB for a particular device and queues it
+ * up to the device Rx ring
+*/
+static int mac_frin_replenish_one_msg(struct net_device *dev)
+{
+	struct sk_buff *skb = 0;
+
+
+	if (!dev) {
+		return 0;
+	}
+
+	skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE, GFP_ATOMIC);
+	if (!skb) {
+		printk(KERN_ALERT "%s: can't alloc skb\n", __FUNCTION__);
+		return 0;
+	}
+	phnx_inc_counter(REPLENISH_FRIN);
+
+	return mac_frin_send_skb(dev, skb);
+}
+
+
+
+
+
+
+
+/**************************************************************/
+
+static void xgmac_mdio_setup(volatile unsigned int *_mmio)
+{
+	int i;
+	uint32_t rd_data;
+
+	for (i = 0; i < 4; i++) {
+		rd_data = xmdio_read(_mmio, 1, 0x8000 + i);
+		rd_data = rd_data & 0xffffdfff;	// clear isolate bit
+		xmdio_write(_mmio, 1, 0x8000 + i, rd_data);
+	}
+}
+
+/**********************************************************************
+ *  Init MII interface
+ *  
+ *  Input parameters: 
+ *  	   s - priv structure
+ ********************************************************************* */
+#define PHY_STATUS_RETRIES 25000
+
+static void rmi_phnx_mac_mii_init(struct driver_data *priv)
+{
+	/* use the lowest clock divisor - divisor 28 */
+	phoenix_write_reg(priv->phy.mii_addr, R_MII_MGMT_CONFIG, 0x07);
+}
+
+/**********************************************************************
+ *  Read a PHY register.
+ *  
+ *  Input parameters: 
+ *  	   phyaddr - PHY's address
+ *  	   regidx = index of register to read
+ *  	   
+ *  Return value:
+ *  	   value read (16 bits), or 0xffffffff if an error occurred.
+ ********************************************************************* */
+static unsigned int rmi_phnx_mac_mii_read(phoenix_reg_t * mmio,
+					  int phyaddr, int regidx)
+{
+	int i;
+	/* setup the phy reg to be used */
+	phoenix_write_reg(mmio, R_MII_MGMT_ADDRESS,
+			  (phyaddr << 8) | (regidx << 0));
+
+	/* Issue the read command */
+	phoenix_write_reg(mmio, R_MII_MGMT_COMMAND,
+			  (1 << O_MII_MGMT_COMMAND__rstat));
+
+	/* poll for the read cycle to complete */
+	for (i = 0; i < PHY_STATUS_RETRIES; i++) {
+		if (phoenix_read_reg(mmio, R_MII_MGMT_INDICATORS) == 0)
+			break;
+	}
+
+	/* clear the read cycle */
+	phoenix_write_reg(mmio, R_MII_MGMT_COMMAND, 0);
+
+	if (i == PHY_STATUS_RETRIES) {
+		return 0xffffffff;
+	}
+
+	/* Read the data back */
+	return phoenix_read_reg(mmio, R_MII_MGMT_STATUS);
+}
+
+/**********************************************************************
+ *  Write a value to a PHY register.
+ *  
+ *  Input parameters: 
+ *  	   s - priv structure
+ *  	   phyaddr - PHY to use
+ *  	   regidx - register within the PHY
+ *  	   regval - data to write to register
+ *  	   
+ *  Return value:
+ *  	   nothing
+ ********************************************************************* */
+static void rmi_phnx_mac_mii_write(phoenix_reg_t * mmio, int phyaddr,
+				   int regidx, unsigned int regval)
+{
+	int i = 0;
+
+	phoenix_write_reg(mmio, R_MII_MGMT_ADDRESS,
+			  (phyaddr << 8) | (regidx << 0));
+
+	/* Write the data which starts the write cycle */
+	phoenix_write_reg(mmio, R_MII_MGMT_WRITE_DATA, regval);
+
+	/* poll for the write cycle to complete */
+	for (i = 0; i < PHY_STATUS_RETRIES; i++) {
+		if (phoenix_read_reg(mmio, R_MII_MGMT_INDICATORS) == 0)
+			break;
+	}
+
+	return;
+}
+
+
+/*****************************************************************
+ * Initialize GMAC
+ *****************************************************************/
+static void rmi_phnx_config_pde(struct driver_data *priv)
+{
+	int i = 0, cpu = 0, bucket = 0;
+	__u64 bucket_map = 0;
+
+	for (i = 0; i < 32; i++) {
+		if (cpu_isset(i, cpu_online_map)) {
+			cpu = cpu_logical_map(i);
+			bucket = ((cpu >> 2) << 3) | (cpu & 0x03);
+			bucket_map |= (1ULL << bucket);
+			dbg_msg
+			    ("i=%d, cpu=%d, bucket = %d, bucket_map=%llx\n",
+			     i, cpu, bucket, bucket_map);
+		}
+	}
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_0,
+			  (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_0 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_1,
+			  (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_1 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_2,
+			  (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_2 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_3,
+			  (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_3 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+}
+
+static void rmi_phnx_config_parser(struct driver_data *priv)
+{
+	/* Mark it as no classification 
+	 * The parser extract is gauranteed to be zero with no classfication
+	 */
+	phoenix_write_reg(priv->mmio, R_L2TYPE_0, 0x00);
+
+}
+
+static void rmi_phnx_config_classifier(struct driver_data *priv)
+{
+	int i = 0;
+
+	if (priv->type == TYPE_XGMAC) {
+		/* xgmac translation table doesn't have sane values on reset */
+		for (i = 0; i < 64; i++)
+			phoenix_write_reg(priv->mmio, R_TRANSLATETABLE + i,
+					  0x0);
+
+		/* use upper 7 bits of the parser extract to index the translate
+		 * table
+		 */
+		phoenix_write_reg(priv->mmio, R_PARSERCONFIGREG, 0x0);
+	}
+}
+
+static void rmi_phnx_gmac_clr_pending_intr(struct driver_data *phy_priv)
+{
+	phoenix_reg_t *mmio = NULL;
+
+	if (!xlr_board_atx_vii())
+		return;
+
+	if (phy_priv->instance == 0) {
+		/*All MDIO interrupts goes to mdio 0 - ack mac 0 */
+		mmio = phy_priv->mmio;
+		phoenix_write_reg(mmio, R_INTREG, 0xffffffff);
+	}
+}
+
+static void rmi_phnx_gmac_config_speed(struct driver_data *priv)
+{
+	phoenix_reg_t *mmio = priv->mmio;
+	int id = priv->instance;
+
+	priv->speed =
+	    rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr, 28);
+	priv->speed = (priv->speed >> 3) & 0x03;
+
+	if (priv->speed == phnx_mac_speed_10) {
+		if (priv->phy.serdes_addr)
+			phoenix_write_reg(mmio, R_INTERFACE_CONTROL,
+					  SGMII_SPEED_10);
+		phoenix_write_reg(mmio, R_MAC_CONFIG_2, 0x7117);
+		phoenix_write_reg(mmio, R_CORECONTROL, 0x02);
+		printk("configuring gmac_%d in 10Mbps mode\n", id);
+	} else if (priv->speed == phnx_mac_speed_100) {
+		if (priv->phy.serdes_addr)
+			phoenix_write_reg(mmio, R_INTERFACE_CONTROL,
+					  SGMII_SPEED_100);
+		phoenix_write_reg(mmio, R_MAC_CONFIG_2, 0x7117);
+		phoenix_write_reg(mmio, R_CORECONTROL, 0x01);
+		printk("configuring gmac_%d in 100Mbps mode\n", id);
+	} else {
+		if (priv->phy.serdes_addr)
+			phoenix_write_reg(mmio, R_INTERFACE_CONTROL,
+					  SGMII_SPEED_1000);
+		if (priv->speed != phnx_mac_speed_1000) {
+			printk("gmac_%d phy reported unknown mac speed,"
+			       " defaulting to 100Mbps mode\n", id);
+			phoenix_write_reg(mmio, R_MAC_CONFIG_2, 0x7117);
+			phoenix_write_reg(mmio, R_CORECONTROL, 0x01);
+		} else {
+			phoenix_write_reg(mmio, R_MAC_CONFIG_2, 0x7217);
+			phoenix_write_reg(mmio, R_CORECONTROL, 0x00);
+			printk("configuring gmac_%d in 1000Mbps mode\n",
+			       id);
+		}
+	}
+}
+
+/*****************************************************************
+ * Initialize XGMAC
+ *****************************************************************/
+static void rmi_phnx_xgmac_init(struct driver_data *priv,
+				struct port_cfg *pcfg)
+{
+	int i = 0;
+	phoenix_reg_t *mmio = priv->mmio;
+	int id = priv->instance;
+	volatile unsigned short *cpld;
+	uint32_t rx_control;
+	bucket_t *bucket;
+	struct stn_cc *credit;
+
+	cpld =
+	    (volatile unsigned short *) (unsigned long)
+	    0xffffffffBD840000ULL;
+	phoenix_write_reg(priv->mmio, R_DESC_PACK_CTRL,
+			  (MAC_MAX_FRAME_SIZE <<
+			   O_DESC_PACK_CTRL__RegularSize) | (4 << 20));
+	phoenix_write_reg(priv->mmio, R_BYTEOFFSET0, BYTE_OFFSET);
+
+	if (priv->config_pde) {
+		rmi_phnx_config_pde(priv);
+		rmi_phnx_config_parser(priv);
+		rmi_phnx_config_classifier(priv);
+	}
+
+	phoenix_write_reg(priv->mmio, R_MSG_TX_THRESHOLD, 1);
+
+	/* configure the XGMAC Registers */
+	phoenix_write_reg(mmio, R_XGMAC_CONFIG_1, 0x50000026);
+
+	/* configure the XGMAC_GLUE Registers */
+	phoenix_write_reg(mmio, R_DMACR0, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR1, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR2, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR3, 0xffffffff);
+	phoenix_write_reg(mmio, R_STATCTRL, 0x04);
+	phoenix_write_reg(mmio, R_L2ALLOCCTRL, 0xffffffff);
+
+	phoenix_write_reg(mmio, R_XGMACPADCALIBRATION, 0x030);
+	phoenix_write_reg(mmio, R_EGRESSFIFOCARVINGSLOTS, 0x0f);
+	phoenix_write_reg(mmio, R_L2ALLOCCTRL, 0xffffffff);
+	phoenix_write_reg(mmio, R_XGMAC_MIIM_CONFIG, 0x3e);
+
+	/* take XGMII phy out of reset 
+	 */
+	/* we are pulling everything out of reset because writing a 0 would
+	 * reset other devices on the chip
+	 */
+	cpld[ATX_CPLD_RESET_1] = 0xffff;
+	cpld[ATX_CPLD_MISC_CTRL] = 0xffff;
+	cpld[ATX_CPLD_RESET_2] = 0xffff;
+
+	xgmac_mdio_setup(mmio);
+
+	rmi_phnx_config_spill_area(priv);
+
+	bucket = pcfg->bucket;
+	credit = pcfg->credit;
+
+	if (id == 0) {
+		for (i = 0; i < 16; i++) {
+			phoenix_write_reg(mmio, R_XGS_TX0_BUCKET_SIZE + i,
+					  bucket[MSGRNG_STNID_XGS0_TX +
+						 i]);
+		}
+
+		phoenix_write_reg(mmio, R_XGS_RFR_BUCKET_SIZE,
+				  bucket[MSGRNG_STNID_XMAC0RFR]);
+
+	} else if (id == 1) {
+		for (i = 0; i < 16; i++) {
+			phoenix_write_reg(mmio, R_XGS_TX0_BUCKET_SIZE + i,
+					  bucket[MSGRNG_STNID_XGS1_TX +
+						 i]);
+		}
+
+		phoenix_write_reg(mmio, R_XGS_RFR_BUCKET_SIZE,
+				  bucket[MSGRNG_STNID_XMAC1RFR]);
+
+	}
+	for (i = 0; i < MAX_NUM_MSGRNG_STN_CC; i++) {
+		phoenix_write_reg(mmio, R_CC_CPU0_0 + i,
+				  credit->counters[i >> 3][i & 0x07]);
+	}
+
+	priv->init_frin_desc = 1;
+
+	/* Clear the flagging of rx length check errors */
+	rx_control = phoenix_read_reg(mmio, R_RX_CONTROL);
+	rx_control &= ~(1 << 9);
+	phoenix_write_reg(mmio, R_RX_CONTROL, rx_control);
+}
+
+
+void sgmii_serdes_reset(void)
+{
+	int i;
+	volatile unsigned int *mmio_gpio;
+	mmio_gpio =
+	    (unsigned int *) (phoenix_io_base + PHOENIX_IO_GPIO_OFFSET);
+
+	for (i = 0; i < 1000000; i++);
+
+	// use 125 Mhz instead of 156.25Mhz ref clock
+	if (!xlsb0_in_xaui(0)) {
+		mmio_gpio[0x10] = 0x7103;
+	}
+
+	if (!xlsb0_in_xaui(1)) {
+		mmio_gpio[0x21] = 0x7103;
+	}
+
+	for (i = 0; i < 1000000; i++);
+}
+
+
+
+static void serdes_regs_init(struct driver_data *priv)
+{
+	int i;
+	volatile unsigned int *mmio_gpio;
+	mmio_gpio =
+	    (unsigned int *) (phoenix_io_base + PHOENIX_IO_GPIO_OFFSET);
+	/*
+	   P Reg   Val
+	   -------------
+	   26 0     6DB0
+	   26 1     0FFF
+	   26 2     B6D0
+	   26 3     00FF
+	   26 4     0000
+	   26 5     0000
+	   26 6     0005
+	   26 7     0001
+	   26 8     0000
+	   26 9     0000
+	   26 10    0000
+	 */
+	rmi_phnx_mac_mii_write(priv->phy.serdes_addr, 26, 0, 0x6DB0);
+	rmi_phnx_mac_mii_write(priv->phy.serdes_addr, 26, 1, 0xFFFF);
+	rmi_phnx_mac_mii_write(priv->phy.serdes_addr, 26, 2, 0xB6D0);
+	rmi_phnx_mac_mii_write(priv->phy.serdes_addr, 26, 3, 0x00FF);
+	rmi_phnx_mac_mii_write(priv->phy.serdes_addr, 26, 4, 0x0000);
+	rmi_phnx_mac_mii_write(priv->phy.serdes_addr, 26, 5, 0x0000);
+	rmi_phnx_mac_mii_write(priv->phy.serdes_addr, 26, 6, 0x0005);
+	rmi_phnx_mac_mii_write(priv->phy.serdes_addr, 26, 7, 0x0001);
+	rmi_phnx_mac_mii_write(priv->phy.serdes_addr, 26, 8, 0x0000);
+	rmi_phnx_mac_mii_write(priv->phy.serdes_addr, 26, 9, 0x0000);
+	rmi_phnx_mac_mii_write(priv->phy.serdes_addr, 26, 10, 0x0000);
+
+	for (i = 0; i < 10000000; i++) {
+	}
+
+	/* program  GPIO values for serdes init parameters */
+	mmio_gpio[0x20] = 0x7e6802;
+	mmio_gpio[0x10] = 0x7104;
+	for (i = 0; i < 100000000; i++) {
+	}
+
+	if (xlr_board_atx_xaui_rework())
+		sgmii_serdes_reset();
+}
+
+static void serdes_autoconfig(struct driver_data *priv)
+{
+	int delay = 100;
+
+	/* Enable Auto negotiation in the PCS Layer */
+	if ((priv->instance == 0) || (priv->instance == 4)) {
+		rmi_phnx_mac_mii_write(priv->phy.pcs_addr, 27, 0, 0x1000);
+		mdelay(delay);
+		rmi_phnx_mac_mii_write(priv->phy.pcs_addr, 27, 0, 0x0200);
+		mdelay(delay);
+	}
+
+	if ((priv->instance == 1) || (priv->instance == 5)) {
+		rmi_phnx_mac_mii_write(priv->phy.pcs_addr, 28, 0, 0x1000);
+		mdelay(delay);
+		rmi_phnx_mac_mii_write(priv->phy.pcs_addr, 28, 0, 0x0200);
+		mdelay(delay);
+	}
+
+	if ((priv->instance == 2) || (priv->instance == 6)) {
+		rmi_phnx_mac_mii_write(priv->phy.pcs_addr, 29, 0, 0x1000);
+		mdelay(delay);
+		rmi_phnx_mac_mii_write(priv->phy.pcs_addr, 29, 0, 0x0200);
+		mdelay(delay);
+	}
+
+	if ((priv->instance == 3) || (priv->instance == 7)) {
+		rmi_phnx_mac_mii_write(priv->phy.pcs_addr, 30, 0, 0x1000);
+		mdelay(delay);
+		rmi_phnx_mac_mii_write(priv->phy.pcs_addr, 30, 0, 0x0200);
+		mdelay(delay);
+	}
+
+	return;
+}
+
+void xaui_serdes_reset(void)
+{
+	int i;
+	volatile unsigned int *mmio_gpio;
+	mmio_gpio = (unsigned int *) (phoenix_io_base +
+				      PHOENIX_IO_GPIO_OFFSET);
+
+	for (i = 0; i < 1000000; i++);
+
+	// disable serdes pll for both serdes
+	mmio_gpio[0x20] = 0x007e6804;
+	mmio_gpio[0x22] = 0x007e6804;
+	for (i = 0; i < 1000000; i++);
+
+	// use 156.25Mhz ref clock instead of 125Mhz
+	// ref clk
+	mmio_gpio[0x10] = 0x7104;
+	mmio_gpio[0x21] = 0x7104;
+	for (i = 0; i < 1000000; i++);
+
+	// re-enable serdes pll
+	mmio_gpio[0x20] = 0x007e6801;
+	mmio_gpio[0x22] = 0x007e6801;
+
+	for (i = 0; i < 1000000; i++);
+}
+
+
+static void rmi_phnx_xaui_init(struct driver_data *priv,
+			       struct port_cfg *pcfg)
+{
+	int i = 0;
+	phoenix_reg_t *mmio = priv->mmio;
+	__u32 value = 0;
+	bucket_t *bucket;
+	struct stn_cc *credit;
+
+	value = phoenix_read_reg(mmio, R_XGMAC_CONFIG_1);
+	phoenix_write_reg(mmio, R_XGMAC_CONFIG_1, (value | 0x50000020));
+	phoenix_write_reg(mmio, R_XGMAC_MAX_FRAME_LEN, 0x0A000A00);
+
+	rmi_phnx_config_spill_area(priv);
+
+	phoenix_write_reg(priv->mmio, R_DESC_PACK_CTRL,
+			  (BYTE_OFFSET << O_DESC_PACK_CTRL__ByteOffset) |
+			  (1 << O_DESC_PACK_CTRL__MaxEntry) |
+			  (MAC_MAX_FRAME_SIZE <<
+			   O_DESC_PACK_CTRL__RegularSize));
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+	phoenix_write_reg(priv->mmio, R_DESC_PACK_CTRL,
+			  phoenix_read_reg(priv->mmio, R_DESC_PACK_CTRL) |
+			  (1 << O_DESC_PACK_CTRL__PrePadEnable));
+#endif
+
+	if (priv->config_pde) {
+		rmi_phnx_config_pde(priv);
+		rmi_phnx_config_parser(priv);
+		rmi_phnx_config_classifier(priv);
+	}
+
+	phoenix_write_reg(priv->mmio, R_MSG_TX_THRESHOLD, 3);
+
+	phoenix_write_reg(mmio, R_RX_CONTROL, (0x7 << 6));
+
+	phoenix_write_reg(mmio, R_DMACR0, (7 << 28) | (7 << 24));
+	phoenix_write_reg(mmio, R_DMACR3,
+			  (2 << 21) | (2 << 18) | (2 << 15) | (2 << 12) |
+			  (2 << 9) | (2 << 6) | (2 << 3) | (2 << 0));
+	phoenix_write_reg(mmio, R_L2ALLOCCTRL, 0xffffffff);
+	phoenix_write_reg(mmio, 0x221, (224 << 16));
+	phoenix_write_reg(mmio, R_STATCTRL, 0x04);
+	phoenix_write_reg(mmio, R_INTMASK, 0);
+	phoenix_write_reg(mmio, R_FREEQCARVE, 0);
+
+	priv->init_frin_desc = 1;
+	bucket = pcfg->bucket;
+	credit = pcfg->credit;
+
+	if (bucket != NULL) {
+		phoenix_write_reg(mmio, R_GMAC_RFR0_BUCKET_SIZE,
+				  bucket[1]);
+		phoenix_write_reg(mmio, R_GMAC_TX0_BUCKET_SIZE, bucket[2]);
+		phoenix_write_reg(mmio, R_GMAC_TX1_BUCKET_SIZE, bucket[3]);
+		phoenix_write_reg(mmio, R_GMAC_TX2_BUCKET_SIZE, bucket[4]);
+		phoenix_write_reg(mmio, R_GMAC_TX3_BUCKET_SIZE, bucket[5]);
+		phoenix_write_reg(mmio, R_GMAC_RFR1_BUCKET_SIZE,
+				  bucket[7]);
+	}
+
+	if (credit != NULL) {
+		for (i = 0; i < MAX_NUM_MSGRNG_STN_CC; i++) {
+			phoenix_write_reg(mmio, R_CC_CPU0_0 + i,
+					  credit->
+					  counters[i >> 3][i & 0x07]);
+		}
+	}
+	return;
+}
+
+/*******************************************************
+ * Initialization gmac
+ *******************************************************/
+static void rmi_phnx_gmac_init(struct driver_data *priv,
+			       struct port_cfg *pcfg)
+{
+	int i = 0;
+	phoenix_reg_t *mmio = priv->mmio;
+	__u32 value = 0;
+	bucket_t *bucket;
+	struct stn_cc *credit;
+
+	rmi_phnx_config_spill_area(priv);
+
+	phoenix_write_reg(priv->mmio, R_DESC_PACK_CTRL,
+			  (BYTE_OFFSET << O_DESC_PACK_CTRL__ByteOffset) |
+			  (1 << O_DESC_PACK_CTRL__MaxEntry) |
+			  (MAC_MAX_FRAME_SIZE <<
+			   O_DESC_PACK_CTRL__RegularSize));
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+	phoenix_write_reg(priv->mmio, R_DESC_PACK_CTRL,
+			  phoenix_read_reg(priv->mmio, R_DESC_PACK_CTRL) |
+			  (1 << O_DESC_PACK_CTRL__PrePadEnable));
+#endif
+
+	if (priv->config_pde) {
+		rmi_phnx_config_pde(priv);
+		rmi_phnx_config_parser(priv);
+		rmi_phnx_config_classifier(priv);
+	}
+
+	phoenix_write_reg(priv->mmio, R_MSG_TX_THRESHOLD, 3);
+
+	phoenix_write_reg(mmio, R_MAC_CONFIG_1, 0x35);
+
+	phoenix_write_reg(mmio, R_RX_CONTROL, (0x7 << 6));
+
+	if (priv->phy.serdes_addr != 0
+	    && (priv->phy.mode & PHY_MODE_RGMII)) {
+		value = phoenix_read_reg(priv->mmio, R_RX_CONTROL);
+		value |= 1 << O_RX_CONTROL__RGMII;
+		phoenix_write_reg(priv->mmio, R_RX_CONTROL, value);
+	}
+
+	rmi_phnx_mac_mii_init(priv);
+
+	priv->advertising =
+	    ADVERTISED_10baseT_Full | ADVERTISED_10baseT_Half |
+	    ADVERTISED_100baseT_Full | ADVERTISED_100baseT_Half |
+	    ADVERTISED_1000baseT_Full | ADVERTISED_Autoneg |
+	    ADVERTISED_MII;
+
+	/*Clear pending mdio interrupt */
+	rmi_phnx_gmac_clr_pending_intr(priv);
+
+
+	/* Enable all MDIO interrupts in the phy 
+	 * RX_ER bit seems to be get set about every 1 sec in GigE mode,
+	 * ignore it for now...
+	 */
+	rmi_phnx_mac_mii_write(priv->phy.mii_addr, priv->phy.addr, 25,
+			       0xfffffffe);
+	if (priv->phy.serdes_addr) {
+		serdes_regs_init(priv);
+		mdelay(10);
+		serdes_autoconfig(priv);
+	}
+	rmi_phnx_gmac_config_speed(priv);
+
+	value = phoenix_read_reg(mmio, R_IPG_IFG);
+	phoenix_write_reg(mmio, R_IPG_IFG,
+			  ((value & ~0x7f) | MAC_B2B_IPG));
+	phoenix_write_reg(mmio, R_DMACR0, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR1, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR2, 0xffffffff);
+	phoenix_write_reg(mmio, R_DMACR3, 0xffffffff);
+	phoenix_write_reg(mmio, R_STATCTRL, 0x04);
+	phoenix_write_reg(mmio, R_L2ALLOCCTRL, 0xffffffff);
+	phoenix_write_reg(mmio, R_INTMASK, 0);
+	phoenix_write_reg(mmio, R_FREEQCARVE, 0);
+
+	priv->init_frin_desc = 1;
+	bucket = pcfg->bucket;
+	credit = pcfg->credit;
+
+	if (bucket != NULL) {
+		phoenix_write_reg(mmio, R_GMAC_RFR0_BUCKET_SIZE,
+				  bucket[1]);
+		phoenix_write_reg(mmio, R_GMAC_TX0_BUCKET_SIZE, bucket[2]);
+		phoenix_write_reg(mmio, R_GMAC_TX1_BUCKET_SIZE, bucket[3]);
+		phoenix_write_reg(mmio, R_GMAC_TX2_BUCKET_SIZE, bucket[4]);
+		phoenix_write_reg(mmio, R_GMAC_TX3_BUCKET_SIZE, bucket[5]);
+		phoenix_write_reg(mmio, R_GMAC_RFR1_BUCKET_SIZE,
+				  bucket[7]);
+	}
+
+	if (credit != NULL) {
+		for (i = 0; i < MAX_NUM_MSGRNG_STN_CC; i++) {
+			phoenix_write_reg(mmio, R_CC_CPU0_0 + i,
+					  credit->
+					  counters[i >> 3][i & 0x07]);
+		}
+	}
+	return;
+}
+
+/**********************************************************************
+ * Set promiscuous mode
+ **********************************************************************/
+static void phnx_mac_set_rx_mode(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	uint32_t regval;
+
+	regval = phoenix_read_reg(priv->mmio, R_MAC_FILTER_CONFIG);
+
+	if (dev->flags & IFF_PROMISC) {
+		regval |= (1 << O_MAC_FILTER_CONFIG__BROADCAST_EN) |
+		    (1 << O_MAC_FILTER_CONFIG__PAUSE_FRAME_EN) |
+		    (1 << O_MAC_FILTER_CONFIG__ALL_MCAST_EN) |
+		    (1 << O_MAC_FILTER_CONFIG__ALL_UCAST_EN);
+	} else {
+		regval &= ~((1 << O_MAC_FILTER_CONFIG__PAUSE_FRAME_EN) |
+			    (1 << O_MAC_FILTER_CONFIG__ALL_UCAST_EN));
+#ifdef PA10401_1_GMAC_PKT_DISCARD
+		if (!is_xls()) {
+			regval |=
+			    (1 << O_MAC_FILTER_CONFIG__ALL_MCAST_EN) | (1
+									<<
+									O_MAC_FILTER_CONFIG__ALL_UCAST_EN);
+		}
+#endif
+	}
+
+	phoenix_write_reg(priv->mmio, R_MAC_FILTER_CONFIG, regval);
+}
+
+/**********************************************************************
+ *  Configure LAN speed for the specified MAC.
+ ********************************************************************* */
+static int rmi_phnx_mac_set_speed(struct driver_data *s,
+				  phnx_mac_speed_t speed)
+{
+	return 0;
+}
+
+/**********************************************************************
+ *  Set Ethernet duplex and flow control options for this MAC
+ ********************************************************************* */
+static int rmi_phnx_mac_set_duplex(struct driver_data *s,
+				   phnx_mac_duplex_t duplex,
+				   phnx_mac_fc_t fc)
+{
+	return 0;
+}
+
+/*****************************************************************
+ * Kernel Net Stack <-> MAC Driver Interface
+ *****************************************************************/
+/**********************************************************************
+ **********************************************************************/
+#define MAC_TX_PASS NETDEV_TX_OK
+#define MAC_TX_FAIL NETDEV_TX_BUSY
+
+static inline int phnx_netif_queue_tx(struct net_device *dev,
+				      struct sk_buff *skb, int txq)
+{
+	unsigned long flags, mflags;
+	int port = ((struct driver_data *) netdev_priv(dev))->id;
+	struct driver_data *priv = netdev_priv(dev);
+	int ret;
+
+	spin_lock_irqsave(&pending_tx_lock[port], flags);
+	/* try xmit once again. This should take care of the race b/w stopq 
+	   here and wakeup in tx complete 
+	 */
+
+	msgrng_access_enable(mflags);
+	ret = mac_xmit(skb, dev, priv, txq);
+	msgrng_access_disable(mflags);
+
+	if (ret == MAC_TX_PASS) {
+		mac_stats_add(priv->cpu_stats[txq].tx_packets, 1);
+		spin_unlock_irqrestore(&pending_tx_lock[port], flags);
+		return ret;
+	}
+	pending_tx[port]++;
+	netif_tx_stop_queue(netdev_get_tx_queue(dev, smp_processor_id()));
+	priv->stats.tx_dropped++;
+	ret = MAC_TX_FAIL;
+	spin_unlock_irqrestore(&pending_tx_lock[port], flags);
+	return ret;
+}
+
+static inline void phnx_netif_queue_tx_complete(struct net_device *dev)
+{
+	int port = ((struct driver_data *) netdev_priv(dev))->id;
+	struct driver_data *priv = netdev_priv(dev);
+	int end_port = 0;
+	if (port < PHOENIX_MAX_GMACS) {
+		port = (port / 4) * 4;
+		end_port = port + 4;
+		for (; port < end_port; port++) {
+			if (pending_tx[port]) {
+				priv = netdev_priv(dev_mac[port]);
+				spin_lock(&pending_tx_lock[port]);
+				if (pending_tx[port]) {
+					pending_tx[port] = 0;
+					/* is there a easy way to wake up only stopped queues ? */
+					netif_tx_wake_all_queues(dev);
+				}
+				spin_unlock(&pending_tx_lock[port]);
+			}
+		}
+	} else {
+		if (pending_tx[port]) {
+			spin_lock(&pending_tx_lock[port]);
+			if (pending_tx[port]) {
+				pending_tx[port] = 0;
+				/* is there a easy way to wake up only stopped queues ? */
+				netif_tx_wake_all_queues(dev);
+			}
+			spin_unlock(&pending_tx_lock[port]);
+		}
+	}
+}
+
+
+
+static int mac_fill_tx_stid(int id, int type)
+{
+	int tx_stid;
+	if (type == TYPE_XGMAC) {
+		tx_stid = msgrng_xgmac_stid_tx(id);
+	} else {
+		tx_stid = msgrng_gmac_stid_tx(id);
+	}
+	return tx_stid;
+}
+
+
+static inline int mac_make_desc_b0_tx(struct msgrng_msg *msg,
+				      struct driver_data *priv,
+				      unsigned long addr,
+				      struct sk_buff *skb,
+				      unsigned long desc_id)
+{
+	int tx_stid = 0;
+	int fr_stid = 0;
+	int cpu = (phoenix_cpu_id() << 2) | phoenix_thr_id();
+	int len = skb->len;
+
+	fr_stid = cpu_to_frstid[cpu];
+	tx_stid = priv->tx_stid;
+
+
+	msg->msg0 = (((uint64_t) 1 << 63) |
+		     (((uint64_t) desc_id) << 54) |
+		     ((uint64_t) len << 40) | ((uint64_t) addr)
+	    );
+
+	{
+		msg->msg1 = (((uint64_t) 1 << 63) |
+			     ((uint64_t) fr_stid << 54) |
+			     ((uint64_t) 0 << 40) |
+#ifdef CONFIG_64BIT
+			     ((uint64_t) virt_to_phys(skb))
+#else
+			     ((unsigned long) (skb) & 0xffffffffUL)
+#endif
+		    );
+	}
+
+	msg->msg2 = msg->msg3 = 0;
+
+	return tx_stid;
+}
+
+int
+mac_xmit(struct sk_buff *skb, struct net_device *dev,
+	 struct driver_data *priv, int txq)
+{
+	struct msgrng_msg msg;
+	int stid = 0;
+	int cpu = (phoenix_cpu_id() << 2) | phoenix_thr_id();
+
+	if (cpu_to_bktmask[cpu] == 0) {
+		printk
+		    ("Tx fail : No buckets are allocated for this cpu\n");
+		return MAC_TX_FAIL;
+	}
+#ifdef  CONFIG_PHOENIX_PTP_SUPPORT
+	if (skb->sk && sock_flag(skb->sk, SOCK_TIMESTAMP)) {
+		dbg_msg("transmit timestamp packet \n");
+		stid =
+		    mac_make_desc_b0_tx(&msg, priv,
+					virt_to_phys(skb->data), skb, 126);
+	} else
+#endif
+	{
+		stid =
+		    mac_make_desc_b0_tx(&msg, priv,
+					virt_to_phys(skb->data), skb, 127);
+	}
+
+	__sync();
+
+	if (message_send_fast_2(MSGRNG_CODE_MAC, stid, msg.msg0, msg.msg1))
+		return MAC_TX_FAIL;
+
+	port_inc_counter(priv->instance, PORT_TX);
+
+	/* Send the packet to MAC */
+	dbg_msg("Sent tx packet to stid %d, msg0=%llx, msg1=%llx \n", stid,
+		msg.msg0, msg.msg1);
+#ifdef DUMP_PACKETS
+	dump_packet(skb);
+#endif
+
+	phnx_inc_counter(NETIF_TX);
+
+	dev->trans_start = jiffies;
+
+	return MAC_TX_PASS;
+}
+
+
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+
+/* 
+ * NAPI poll function on upper four buckets 
+*/
+void xlr_napi_poll_upper(struct net_device *dummy_dev, int budget)
+{
+	struct msgrng_msg msg_body, *msg = &msg_body;
+	int bucket, stid = 0, length;
+	unsigned long mflags = 0;
+	unsigned int status;
+	int data_rx_bucket;
+	int size = 0, code = 0;
+	struct tx_stn_handler *handler;
+	int tx_stid, rcv_mask;
+#ifdef CONFIG_64BIT
+//      unsigned long tmp;
+#endif				/* CONFIG_64BIT */
+
+
+	data_rx_bucket = phoenix_thr_id() + 4;
+
+	msg_body.msg0 = 0;	// Keep compiler happy
+	while (1) {
+
+		msgrng_access_enable(mflags);
+		if ((rcv_mask = (~msgrng_read_status() >> 28) & 0xf))
+			bucket = get_adjusted_bucket_index(rcv_mask);
+		else {
+			msgrng_access_disable(mflags);
+			break;
+		}
+
+		if (rmi_on_chip_napi) {
+			status =
+			    message_receive(bucket, &size, &code, &stid,
+					    msg);
+		} else {
+			status =
+			    message_receive_fast_1(bucket, size, code,
+						   stid, msg_body.msg0);
+		}
+
+		msgrng_access_disable(mflags);
+
+		if (status) {
+			continue;
+		}
+
+		if (rmi_on_chip_napi) {
+			/* this block is a quick check for messages arriving from non GMAC/XGMAC stations */
+			tx_stid = rxstn_to_txstn_ptr[stid];
+			if (tx_stns[tx_stid].handler.action !=
+			    rmi_phnx_mac_msgring_handler) {
+				handler = &tx_stns[tx_stid].handler;
+				if (handler->action) {
+					(handler->action) (bucket, size,
+							   code, stid, msg,
+							   handler->
+							   dev_id);
+				}
+				continue;
+			}
+		}
+
+		length = (msg->msg0 >> 40) & 0x3fff;
+
+		if (length) {
+			printk
+			    ("%s: message with non-zero length from buckets 4-7\n",
+			     __FUNCTION__);
+			continue;
+		}
+
+		rmi_phnx_free_skb(msg);
+	}			/* closing while (1) */
+}
+
+EXPORT_SYMBOL(xlr_napi_poll_upper);
+
+/* 
+ * NAPI poll function on lower four buckets 
+*/
+int napi_poll_lower(struct net_device *dummy_dev, int budget)
+{
+	struct msgrng_msg msg_body, *msg = &msg_body;
+	int stid = 0, length;
+	int port;
+	struct sk_buff *skb;
+	int received = 0;
+	unsigned int data_rx_bucket;
+	unsigned long addr;
+	unsigned long mflags = 0;
+	unsigned int status;
+	int size = 0, code = 0;
+	int cpu = hard_smp_processor_id();
+	struct driver_data *priv;
+	unsigned int rxStatus;
+	struct tx_stn_handler *handler;
+	int tx_stid;
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+	unsigned char *prepad = NULL;
+#endif				/* CONFIG_PHOENIX_PTP_SUPPORT */
+
+	data_rx_bucket = phoenix_thr_id();
+	msg_body.msg0 = 0;
+
+	while (1) {
+		msgrng_access_enable(mflags);
+
+		if ((msgrng_read_status() >> (data_rx_bucket + 24)) & 0x1) {
+			msgrng_access_disable(mflags);
+			break;
+		}
+
+		if (rmi_on_chip_napi) {
+			status =
+			    message_receive(data_rx_bucket, &size, &code,
+					    &stid, msg);
+		} else {
+			status =
+			    message_receive_fast_1(data_rx_bucket, size,
+						   code, stid,
+						   msg_body.msg0);
+		}
+
+		msgrng_access_disable(mflags);
+
+		if (status) {
+			continue;
+		}
+
+		if (rmi_on_chip_napi) {
+			/* quick check for messages arriving from stations different from GMAC/XGMAC */
+			tx_stid = rxstn_to_txstn_ptr[stid];
+			if (tx_stns[tx_stid].handler.action !=
+			    rmi_phnx_mac_msgring_handler) {
+				handler = &tx_stns[tx_stid].handler;
+				if (handler->action) {
+					(handler->action) (data_rx_bucket,
+							   size, code,
+							   stid, msg,
+							   handler->
+							   dev_id);
+				}
+				continue;
+			}
+		}
+
+		length = (msg->msg0 >> 40) & 0x3fff;
+		if (length == 0) {
+			printk
+			    ("%s: message from data buckets with zero length...\n",
+			     __FUNCTION__);
+			continue;
+		}
+
+		/* we got a rx buffer with data from the MAC */
+		addr =
+		    (unsigned long) bus_to_virt(msg->
+						msg0 & 0xffffffffe0ULL);
+		length = length - BYTE_OFFSET - MAC_CRC_LEN - MAC_PREPAD;
+		port = msg->msg0 & 0x0f;
+		skb = mac_get_skb_back_ptr(addr);
+
+		prefetch_local(skb->data);
+
+		if (is_xls()) {
+			if (stid == MSGRNG_STNID_GMAC0)
+				skb->dev = dev_mac_type[TYPE_GMAC][port];
+			else if (stid == MSGRNG_STNID_GMAC1)
+				skb->dev =
+				    dev_mac_type[TYPE_GMAC][4 + port];
+			else {
+				printk
+				    ("[%s]: desc (0x%lx) for unknown station %d? dropping\n",
+				     __FUNCTION__, addr, stid);
+				continue;
+			}
+		} else {
+			if (stid == MSGRNG_STNID_XGS0FR)
+				skb->dev = dev_mac_type[TYPE_XGMAC][0];
+			else if (stid == MSGRNG_STNID_XGS1FR)
+				skb->dev = dev_mac_type[TYPE_XGMAC][1];
+			else
+				skb->dev = dev_mac_type[TYPE_GMAC][port];
+		}
+
+		priv = netdev_priv(skb->dev);
+
+		if (msg->msg0 & (0x40ULL << 56)) {
+			rxStatus = (msg->msg0 >> 56) & 0x7f;
+			dbg_msg("Rx err 0x%x\n", rxStatus);
+			mac_stats_add(priv->stats.rx_errors, 1);
+			if (rxStatus & 0x02)
+				mac_stats_add(priv->stats.rx_crc_errors,
+					      1);
+			if (rxStatus & 0x01)
+				mac_stats_add(priv->stats.rx_length_errors,
+					      1);
+
+			if (!rmi_auto_buffer_mgmt) {
+				mac_frin_replenish_one_msg(skb->dev);
+			}
+			dev_kfree_skb(skb);
+
+			continue;
+		}
+#ifdef PA10401_1_GMAC_PKT_DISCARD
+		if ((!is_xls()) && (!(skb->dev->flags & IFF_PROMISC))) {
+			if (!(msg->msg0 & (0x20ULL << 56))) {
+				if ((*(uint64_t *)
+				     (skb->data + MAC_PREPAD +
+				      BYTE_OFFSET) >> 16) !=
+				    ((*(uint64_t *) skb->dev->
+				      dev_addr) >> 16)) {
+					if (!rmi_auto_buffer_mgmt) {
+						mac_frin_replenish_one_msg
+						    (skb->dev);
+					}
+					dev_kfree_skb(skb);
+					continue;
+				}
+			}
+		}
+#endif
+
+		skb_reserve(skb, MAC_PREPAD + BYTE_OFFSET);
+
+		skb_put(skb, length);
+		skb->protocol = eth_type_trans(skb, skb->dev);
+// 1588
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+		prepad = (unsigned char *) addr;
+		if (p_ptp_set_ts)
+			p_ptp_set_ts(*((unsigned int *) prepad),
+				     *((unsigned int *) prepad + 1),
+				     &skb->tstamp, 1);
+#endif
+
+		mac_stats_add(priv->stats.rx_packets, 1);
+		mac_stats_add(priv->stats.rx_bytes, skb->len);
+		mac_stats_add(priv->cpu_stats[cpu].rx_packets, 1);
+
+		phnx_inc_counter(NETIF_RX);
+		phnx_set_counter(NETIF_RX_CYCLES,
+				 (read_c0_count() - msgrng_msg_cycles));
+
+		if (!rmi_auto_buffer_mgmt) {
+			mac_frin_replenish_one_msg(skb->dev);
+		}
+
+		skb->dev->last_rx = jiffies;
+		netif_receive_skb(skb);
+
+		__get_cpu_var(xlr_napi_rx_count)++;
+
+		/* If number of received packets is exceeding poll weight we exit */
+		if (++received >= budget) {
+			break;
+		}
+	}			/* end of while loop */
+
+	return received;
+}
+
+
+
+/*
+ *  Version of transmit used in conjunction with NAPI mode
+*/
+static int
+rmi_phnx_napi_mac_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	unsigned long mflags = 0;
+	int txq = hard_smp_processor_id();
+	int count = 0, ret;
+
+
+	phnx_inc_counter(NETIF_STACK_TX);
+
+	do {
+		msgrng_access_enable(mflags);
+
+		if (upper_buckets_nonempty()) {
+			msgrng_access_disable(mflags);
+			xlr_napi_poll_upper(dev, 0);
+			msgrng_access_enable(mflags);
+		}
+
+		ret = mac_xmit(skb, dev, priv, txq);
+		msgrng_access_disable(mflags);
+
+		if (ret == MAC_TX_PASS) {
+			mac_stats_add(priv->cpu_stats[txq].tx_packets, 1);
+			return ret;
+		}
+
+		count++;
+
+		if (count < 16)
+			continue;
+
+		ret = phnx_netif_queue_tx(dev, skb, txq);
+		break;
+
+	} while (1);
+
+	if (ret == MAC_TX_FAIL) {
+		/* FULL */
+		dbg_msg("Msg Ring Full. Stopping upper layer Q\n");
+		port_inc_counter(priv->instance, PORT_STOPQ);
+	}
+
+	return ret;
+}
+
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+
+/*
+ * Version of transmit used in regular interrupt-driven mode
+*/
+static int rmi_phnx_mac_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	int ret = -ENOSPC;
+	unsigned long mflags = 0;
+	int txq = hard_smp_processor_id();
+	int count = 0;
+
+
+	phnx_inc_counter(NETIF_STACK_TX);
+
+	do {
+		msgrng_access_enable(mflags);
+
+		if (priv->frstid_rsvd == 1 && upper_buckets_nonempty()) {
+
+			irq_enter();
+			msgring_process_rx_msgs
+			    (MSGRING_PROCESS_FROUT_START_BUCKET,
+			     MSGRING_PROCESS_FROUT_END_BUCKET,
+			     MSGRING_PROCESS_FROUT_POP_BUCKET_MASK);
+			irq_exit();
+		}
+		ret = mac_xmit(skb, dev, priv, txq);
+		msgrng_access_disable(mflags);
+
+		if (ret == MAC_TX_PASS) {
+			mac_stats_add(priv->cpu_stats[txq].tx_packets, 1);
+			break;
+		}
+
+		count++;
+
+		if (count < 16)
+			continue;
+
+		ret = phnx_netif_queue_tx(dev, skb, txq);
+		break;
+	} while (1);
+
+	return ret;
+}
+
+
+/* If allocation fails in the replenish tasklet, this function will replenish
+   the RX buffers from the workqueue context. Replenish tasklet is disabled
+   until this function is done with replenishment.
+   */
+static void mac_frin_replenish_wq(struct work_struct *args /* ignored */ )
+{
+	int cpu = hard_smp_processor_id();
+	int done = 0;
+	int i = 0;
+
+	phnx_inc_counter(REPLENISH_ENTER);
+	//phnx_set_counter(REPLENISH_ENTER_COUNT, atomic_read(frin_to_be_sent));
+	phnx_set_counter(REPLENISH_CPU, hard_smp_processor_id());
+
+	for (;;) {
+
+		done = 0;
+
+		for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+			int offset = 0;
+			unsigned long msgrng_flags;
+			struct sk_buff *skb = 0;
+			__u32 cycles;
+			struct net_device *dev;
+			struct driver_data *priv;
+			atomic_t *frin_to_be_sent;
+
+			dev = dev_mac[i];
+			if (dev == 0)
+				goto skip;
+
+			priv = netdev_priv(dev);
+			frin_to_be_sent = &priv->frin_to_be_sent[cpu];
+
+			if (!(MSGRNG_OWN(priv->cfg_flag)))
+				goto skip;
+
+			if (atomic_read(frin_to_be_sent) < 0) {
+				panic
+				    ("BUG?: [%s]: gmac_%d illegal value for frin_to_be_sent=%d\n",
+				     __FUNCTION__, i,
+				     atomic_read(frin_to_be_sent));
+			}
+
+			if (!atomic_read(frin_to_be_sent))
+				goto skip;
+
+			cycles = read_c0_count();
+			{
+				skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE,
+						      GFP_ATOMIC |
+						      __GFP_REPEAT |
+						      __GFP_NOWARN);
+
+				if (!skb) {
+					skb =
+					    __dev_alloc_skb
+					    (PHNX_RX_BUF_SIZE, GFP_KERNEL);
+					if (!skb)
+						panic
+						    ("[%s]:Unable to allocate skb!\n",
+						     __FUNCTION__);
+				}
+			}
+			phnx_inc_counter(REPLENISH_FRIN);
+
+			/* align the data to the next cache line */
+			offset =
+			    (((unsigned long) skb->data +
+			      SMP_CACHE_BYTES) & ~(SMP_CACHE_BYTES - 1));
+			skb_reserve(skb,
+				    (offset - (unsigned long) skb->data));
+
+			//skb->dev = dev;
+
+			msgrng_access_enable(msgrng_flags);
+			mac_put_skb_back_ptr(skb);
+
+			if (phnx_mac_send_fr
+			    (priv, virt_to_bus(skb->data), skb->len)) {
+				dev_kfree_skb(skb);
+				printk
+				    ("[%s]: rx free message_send failed!\n",
+				     __FUNCTION__);
+				break;
+			}
+			msgrng_access_disable(msgrng_flags);
+
+			phnx_set_counter(REPLENISH_CYCLES,
+					 (read_c0_count() - cycles));
+
+			atomic_dec(frin_to_be_sent);
+
+			continue;
+		      skip:
+			done++;
+		}
+		if (done == PHOENIX_MAX_MACS)
+			break;
+	}
+	tasklet_enable(&mac_frin_replenish_task[cpu]);
+}
+
+
+static void mac_frin_replenish(unsigned long arg /* ignored */ )
+{
+	int cpu = hard_smp_processor_id();
+	int done = 0;
+	int i = 0;
+
+	phnx_inc_counter(REPLENISH_ENTER);
+	//phnx_set_counter(REPLENISH_ENTER_COUNT, atomic_read(frin_to_be_sent));
+	phnx_set_counter(REPLENISH_CPU, hard_smp_processor_id());
+
+	for (;;) {
+
+		done = 0;
+
+		for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+			int offset = 0;
+			unsigned long msgrng_flags;
+			struct sk_buff *skb = 0;
+			__u32 cycles;
+			struct net_device *dev;
+			struct driver_data *priv;
+			atomic_t *frin_to_be_sent;
+
+			dev = dev_mac[i];
+			if (dev == 0)
+				goto skip;
+
+			priv = netdev_priv(dev);
+			frin_to_be_sent = &priv->frin_to_be_sent[cpu];
+
+			if (!(MSGRNG_OWN(priv->cfg_flag)))
+				goto skip;
+
+			if (atomic_read(frin_to_be_sent) < 0) {
+				panic
+				    ("BUG?: [%s]: gmac_%d illegal value for frin_to_be_sent=%d\n",
+				     __FUNCTION__, i,
+				     atomic_read(frin_to_be_sent));
+			}
+
+			if (!atomic_read(frin_to_be_sent))
+				goto skip;
+
+			cycles = read_c0_count();
+			{
+				skb =
+				    __dev_alloc_skb(PHNX_RX_BUF_SIZE,
+						    GFP_ATOMIC |
+						    __GFP_REPEAT |
+						    __GFP_NOWARN);
+				if (!skb) {
+					tasklet_disable_nosync
+					    (&mac_frin_replenish_task
+					     [cpu]);
+					schedule_work
+					    (&mac_frin_replenish_work
+					     [cpu]);
+					return;
+				}
+			}
+			phnx_inc_counter(REPLENISH_FRIN);
+
+			/* align the data to the next cache line */
+			offset =
+			    (((unsigned long) skb->data +
+			      SMP_CACHE_BYTES) & ~(SMP_CACHE_BYTES - 1));
+			skb_reserve(skb,
+				    (offset - (unsigned long) skb->data));
+
+			//skb->dev = dev;
+
+			msgrng_access_enable(msgrng_flags);
+			mac_put_skb_back_ptr(skb);
+
+			if (phnx_mac_send_fr
+			    (priv, virt_to_bus(skb->data), skb->len)) {
+				dev_kfree_skb(skb);
+				printk
+				    ("[%s]: rx free message_send failed!\n",
+				     __FUNCTION__);
+				break;
+			}
+			msgrng_access_disable(msgrng_flags);
+
+			phnx_set_counter(REPLENISH_CYCLES,
+					 (read_c0_count() - cycles));
+
+			atomic_dec(frin_to_be_sent);
+
+			continue;
+		      skip:
+			done++;
+		}
+		if (done == PHOENIX_MAX_MACS)
+			break;
+	}
+}
+
+/*
+ * Send a packet back to the station
+ */
+void rmi_phnx_drop_message_unowned(int fbid, uint64_t physaddr, int cop_en)
+{
+	struct msgrng_msg msg;
+	unsigned long msgrng_flags = 0;
+
+	/*printk(" rmi_phnx_drop_message_unowned fbid = %d physaddr=%llx\n",
+	   fbid, physaddr); */
+
+	if (cop_en)
+		msgrng_access_enable(msgrng_flags);
+
+	msg.msg0 =
+	    ((u64) CTRL_REG_FREE << 61) | ((u64) fbid << 52) | (u64)
+	    physaddr;
+	msg.msg1 = msg.msg2 = msg.msg3 = 0;
+	while (message_send(1, MSGRNG_CODE_MAC, fbid, &msg));
+
+	if (cop_en)
+		msgrng_access_disable(msgrng_flags);
+}
+
+
+
+
+static inline void rmi_phnx_free_skb(struct msgrng_msg *msg)
+{
+	struct sk_buff *skb;
+	struct driver_data *priv;
+	int cpu = hard_smp_processor_id();
+#ifdef CONFIG_64BIT
+	unsigned long tmp;
+	tmp = (unsigned long) (msg->msg0 & 0xffffffffffULL);
+	skb = (struct sk_buff *) phys_to_virt(tmp);
+#else
+	skb = (struct sk_buff *) (unsigned long) msg->msg0;
+#endif
+	/* Tx Complete */
+	phnx_inc_counter(NETIF_TX_COMPLETE);
+
+	dbg_msg("skb = %p\n", skb);
+	/* release the skb and update statistics outside the spinlock */
+	priv = netdev_priv(skb->dev);
+	mac_stats_add(priv->stats.tx_packets, 1);
+	mac_stats_add(priv->stats.tx_bytes, skb->len);
+	mac_stats_add(priv->cpu_stats[cpu].txc_packets, 1);
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+	if (skb->sk) {
+		if (sock_flag(skb->sk, SOCK_TIMESTAMP)) {
+//               dump_all_interface(0x75); 
+			if (p_ptp_set_ts) {
+
+				p_ptp_set_ts(phoenix_read_reg
+					     (priv->mmio, 0x76),
+					     phoenix_read_reg(priv->mmio,
+							      0x75), NULL,
+					     1);
+			}
+		}
+	}
+#endif
+
+
+	port_inc_counter(priv->instance, PORT_TX_COMPLETE);
+	phnx_netif_queue_tx_complete(skb->dev);
+
+	phnx_set_counter(NETIF_TX_COMPLETE_CYCLES,
+			 (read_c0_count() - msgrng_msg_cycles));
+	dev_kfree_skb_any(skb);
+}
+
+
+/*
+ * Send a packet back to ipsec rmios
+ */
+static void ipsec_drop_packet(IPSEC_PACKET * pbuf)
+{
+	int stid = 0;
+	u32 addr;
+	struct msgrng_msg msg;
+	if (is_xls()) {
+		if (pbuf->src_id == MSGRNG_STNID_GMAC0)
+			stid = MSGRNG_STNID_GMAC0_FR;
+		else if (pbuf->src_id == MSGRNG_STNID_GMAC1)
+			stid = MSGRNG_STNID_GMAC1_FR;
+		else {
+			printk
+			    ("[%s]: rx packet (0x%p) for unknown station %d? dropping packet\n",
+			     __FUNCTION__, pbuf, stid);
+			return;
+		}
+	} else {
+		if (pbuf->src_id == MSGRNG_STNID_XGS0FR)
+			stid = MSGRNG_STNID_XMAC0RFR;
+		else if (pbuf->src_id == MSGRNG_STNID_XGS1FR)
+			stid = MSGRNG_STNID_XMAC1RFR;
+		else
+			stid = MSGRNG_STNID_GMACRFR_0;
+	}
+	addr = virt_to_phys(pbuf->packet_data + SKBUF_HEAD);
+	msg.msg0 =
+	    ((u64) CTRL_REG_FREE << 61) | ((u64) stid << 52) | (u64) addr;
+	msg.msg1 = msg.msg2 = msg.msg3 = 0;
+	while (message_send(1, MSGRNG_CODE_MAC, stid, &msg));
+}
+
+/*
+ * Receive a packet from rmios ipsec. This function is called by the message
+ * ring driver when the message source is a CPU and the message code indicates
+ * a packet from rmios. The message ring driver can also receive a fifo message
+ * from a CPU sending an event or response to a user space process.
+ */
+void rmi_phnx_rmios_msgring_handler(int bucket, int size, int code,
+				    int stid, struct msgrng_msg *msg,
+				    void *data /* ignored */ )
+{
+	unsigned long addr;
+	__u32 length;
+	int port;
+	struct sk_buff *skb;
+	struct driver_data *priv;
+	IPSEC_PACKET *ipsec_packet;
+	/*
+	 * Find the ipsec packet
+	 */
+	addr = (unsigned long) bus_to_virt(msg->msg0 & 0xffffffffe0ULL);
+	ipsec_packet = (IPSEC_PACKET *) (addr - SKBUF_HEAD -
+					 offsetof(IPSEC_PACKET,
+						  packet_data));
+	/*
+	 * Do nothing during the boot.
+	 */
+	if (system_state != SYSTEM_RUNNING) {
+		ipsec_drop_packet(ipsec_packet);
+		return;
+	}
+	/*
+	 * Allocate an skbuff, initialize it, and copy the data to it.
+	 */
+	length =
+	    ((msg->msg0 >> 40) & 0x3fff) - BYTE_OFFSET - MAC_CRC_LEN -
+	    MAC_PREPAD;
+	skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE, GFP_ATOMIC);
+	if (!skb) {
+		printk("[%s] - no skbuff\n", __FUNCTION__);
+		ipsec_drop_packet(ipsec_packet);
+		return;
+	}
+	port = code >> 4;
+	skb->dev = dev_mac_type[TYPE_GMAC][port];
+	skb_put(skb, length);
+	memcpy(skb->data, (char *) addr + 2, length);
+	ipsec_drop_packet(ipsec_packet);
+	skb->protocol = eth_type_trans(skb, skb->dev);
+	/*
+	 * Increment the driver stats counters.
+	 */
+	priv = netdev_priv(skb->dev);
+	mac_stats_add(priv->stats.rx_packets, 1);
+	mac_stats_add(priv->stats.rx_bytes, skb->len);
+	/*
+	 * Queue the packet to the upper layer.
+	 */
+	skb->dev->last_rx = jiffies;
+	netif_rx(skb);
+}
+
+
+
+/* This function is called from an interrupt handler */
+void rmi_phnx_mac_msgring_handler(int bucket, int size, int code,
+				  int stid, struct msgrng_msg *msg,
+				  void *data /* ignored */ )
+{
+
+	unsigned long addr = 0;
+	__u32 length = 0;
+	int ctrl = 0, port = 0;
+	struct sk_buff *skb = 0;
+	int cpu = hard_smp_processor_id();
+
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+	unsigned char *prepad = NULL;
+#endif				/* CONFIG_PHOENIX_PTP_SUPPORT */
+
+	dbg_msg
+	    ("mac: bucket=%d, size=%d, code=%d, stid=%d, msg0=%llx msg1=%llx\n",
+	     bucket, size, code, stid, msg->msg0, msg->msg1);
+
+	addr = (unsigned long) bus_to_virt(msg->msg0 & 0xffffffffe0ULL);
+	length = (msg->msg0 >> 40) & 0x3fff;
+	if (length == 0) {
+		ctrl = CTRL_REG_FREE;
+		port = (msg->msg0 >> 54) & 0x0f;
+	} else {
+		ctrl = CTRL_SNGL;
+		length = length - BYTE_OFFSET - MAC_CRC_LEN - MAC_PREPAD;
+		port = msg->msg0 & 0x0f;
+	}
+
+	dbg_msg
+	    ("msg0 = %llx, msg1 = %llx, stid = %d, port = %d, addr=%lx, length=%d, ctrl=%d\n",
+	     msg->msg0, msg->msg1, stid, port, addr, length, ctrl);
+
+	if (ctrl == CTRL_REG_FREE) {
+		/* free the message , freeback should be the 
+		   packets send by linux */
+		rmi_phnx_free_skb(msg);
+
+	} else if (ctrl == CTRL_SNGL || ctrl == CTRL_START) {
+		/* Rx Packet */
+
+		struct driver_data *priv = 0;
+		unsigned int rxStatus = 0;
+
+		dbg_msg("Received packet, port = %d\n", port);
+
+		skb = mac_get_skb_back_ptr(addr);
+		if (!skb) {
+			printk
+			    ("[%s]: rx desc (0x%lx) for unknown skb? dropping packet\n",
+			     __FUNCTION__, addr);
+			return;
+		}
+
+		if (is_xls()) {
+			if (stid == MSGRNG_STNID_GMAC0)
+				skb->dev = dev_mac_type[TYPE_GMAC][port];
+			else if (stid == MSGRNG_STNID_GMAC1)
+				skb->dev =
+				    dev_mac_type[TYPE_GMAC][4 + port];
+			else {
+				printk
+				    ("[%s]: rx desc (0x%lx) for unknown station %d? dropping packet\n",
+				     __FUNCTION__, addr, stid);
+				return;
+			}
+		} else {
+			if (stid == MSGRNG_STNID_XGS0FR)
+				skb->dev = dev_mac_type[TYPE_XGMAC][0];
+			else if (stid == MSGRNG_STNID_XGS1FR)
+				skb->dev = dev_mac_type[TYPE_XGMAC][1];
+			else
+				skb->dev = dev_mac_type[TYPE_GMAC][port];
+		}
+
+		priv = netdev_priv(skb->dev);
+
+		rxStatus = (msg->msg0 >> 56) & 0x7f;
+		if (rxStatus & 0x40) {
+			dbg_msg("Rx err 0x%x\n", rxStatus);
+			mac_stats_add(priv->stats.rx_errors, 1);
+			if (rxStatus & 0x02)
+				mac_stats_add(priv->stats.rx_crc_errors,
+					      1);
+			if (rxStatus & 0x01)
+				mac_stats_add(priv->stats.rx_length_errors,
+					      1);
+
+			discard_rx_frame(skb->dev, skb, cpu);
+			return;
+		}
+#ifdef PA10401_1_GMAC_PKT_DISCARD
+		if ((!is_xls()) && (!(skb->dev->flags & IFF_PROMISC))) {
+			if (!(rxStatus & 0x20)) {
+				if ((*(uint64_t *)
+				     (skb->data + MAC_PREPAD +
+				      BYTE_OFFSET) >> 16) !=
+				    ((*(uint64_t *) skb->dev->
+				      dev_addr) >> 16)) {
+					discard_rx_frame(skb->dev, skb,
+							 cpu);
+					return;
+				}
+			}
+		}
+#endif
+
+		/* if num frins to be sent exceeds threshold, wake up the helper thread */
+		if (!rmi_auto_buffer_mgmt &&
+		    atomic_inc_return(&priv->frin_to_be_sent[cpu]) >
+		    MAC_FRIN_TO_BE_SENT_THRESHOLD) {
+			tasklet_schedule(&mac_frin_replenish_task[cpu]);
+		}
+#ifdef DUMP_PACKETS
+		dump_packet(skb);
+#endif				/* DUMP_PACKETS */
+
+		/* compensate for the prepend data, byte offset */
+		skb_reserve(skb, MAC_PREPAD + BYTE_OFFSET);
+
+		skb_put(skb, length);
+		skb->protocol = eth_type_trans(skb, skb->dev);
+
+		dbg_msg
+		    ("gmac_%d: rx packet: addr = %lx, length = %x, protocol=%d\n",
+		     priv->instance, addr, length, skb->protocol);
+
+		mac_stats_add(priv->stats.rx_packets, 1);
+		mac_stats_add(priv->stats.rx_bytes, skb->len);
+		mac_stats_add(priv->cpu_stats[cpu].rx_packets, 1);
+
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+		prepad = (unsigned char *) addr;
+		if (p_ptp_set_ts)
+			p_ptp_set_ts(*((unsigned int *) prepad),
+				     *((unsigned int *) prepad + 1),
+				     &skb->tstamp, 1);
+#endif
+
+		phnx_inc_counter(NETIF_RX);
+		phnx_set_counter(NETIF_RX_CYCLES,
+				 (read_c0_count() - msgrng_msg_cycles));
+
+
+		skb->dev->last_rx = jiffies;
+		netif_rx(skb);
+
+	} else {
+		printk("[%s]: unrecognized ctrl=%d!\n", __FUNCTION__,
+		       ctrl);
+	}
+}
+
+/* message ring handler where mac is owned by apps not linux */
+void rmi_phnx_station_unowned_msgring_handler(int bucket, int size,
+					      int code, int stid,
+					      struct msgrng_msg *msg,
+					      void *data /* ignored */ )
+{
+	unsigned long addr;
+	__u32 length;
+	int port;
+	struct sk_buff *skb = NULL;
+	struct driver_data *priv;
+	int fbstid = 0x0;
+
+	addr = (unsigned long) bus_to_virt(msg->msg0 & 0xffffffffe0ULL);
+	port = ((msg->msg0) & 0x0f);
+	length = ((msg->msg0 >> 40) & 0x3fff);
+
+	/* printk("[%s] : port=%d length=%d\n", __FUNCTION__, port, length); */
+
+	/* free back should be the packets send by linux */
+	if (length == 0x0) {
+		/* free the message , freeback should be the 
+		   packets send by linux */
+		rmi_phnx_free_skb(msg);
+		return;
+	}
+
+
+	/*
+	 * Allocate an skbuff, initialize it, and copy the data to it.
+	 */
+	skb = __dev_alloc_skb(PHNX_RX_BUF_SIZE, GFP_ATOMIC);
+	if (!skb) {
+		printk("[%s] - no skbuff\n", __FUNCTION__);
+		goto err_exit;
+	}
+
+	if (is_xls()) {
+		if (stid == MSGRNG_STNID_GMAC0) {
+			skb->dev = dev_mac_type[TYPE_GMAC][port];
+			fbstid = MSGRNG_STNID_GMAC0_FR;
+		} else if (stid == MSGRNG_STNID_GMAC1) {
+			skb->dev = dev_mac_type[TYPE_GMAC][4 + port];
+			fbstid = MSGRNG_STNID_GMAC1_FR;
+		} else {
+			printk
+			    ("[%s]: rx desc (0x%lx) for unknown station %d? dropping packet\n",
+			     __FUNCTION__, addr, stid);
+			goto err_exit;
+		}
+	} else {
+		if (stid == MSGRNG_STNID_XGS0FR) {
+			skb->dev = dev_mac_type[TYPE_XGMAC][0];
+			fbstid = MSGRNG_STNID_XMAC0RFR;
+		} else if (stid == MSGRNG_STNID_XGS1FR) {
+			skb->dev = dev_mac_type[TYPE_XGMAC][1];
+			fbstid = MSGRNG_STNID_XMAC1RFR;
+		} else {
+			skb->dev = dev_mac_type[TYPE_GMAC][port];
+			fbstid = MSGRNG_STNID_GMACRFR_0;
+		}
+	}
+
+#if 0
+	printk
+	    ("rmi_phnx_station_unowned_msgring_handler ingress port=%d stid=%d\n",
+	     port, stid);
+#endif
+	if (skb->dev == 0) {
+		printk("[%s] - no dev\n", __FUNCTION__);
+		goto err_exit;
+	}
+
+	length = length - (BYTE_OFFSET + MAC_CRC_LEN);
+	skb_put(skb, length);
+	memcpy(skb->data, (char *) addr + 2, length);
+
+	//if(rmik_queue_pkt_mem(fbstid, msg->msg0 & 0xffffffffe0ULL) < 0)
+	//      rmi_phnx_drop_message_unowned(fbstid, msg->msg0 & 0xffffffffe0ULL, 1);
+
+#if 0
+	{
+		int i = 0;
+		printk("Rx Packet: length=%d\n", length);
+		for (i = 0; i < 64; i++) {
+			printk("%02x ", skb->data[i]);
+			if (i && (i % 16) == 0)
+				printk("\n");
+		}
+		printk("\n");
+	}
+#endif
+
+	skb->protocol = eth_type_trans(skb, skb->dev);
+	/*
+	 * Increment the driver stats counters.
+	 */
+	priv = netdev_priv(skb->dev);
+	mac_stats_add(priv->stats.rx_packets, 1);
+	mac_stats_add(priv->stats.rx_bytes, skb->len);
+	/*
+	 * Queue the packet to the upper layer.
+	 */
+	skb->dev->last_rx = jiffies;
+	netif_rx(skb);
+	return;
+
+      err_exit:
+	rmi_phnx_drop_message_unowned(fbstid, msg->msg0 & 0xffffffffe0ULL,
+				      1);
+	if (skb)
+		kfree_skb(skb);
+	return;
+
+}
+
+
+
+
+/**********************************************************************
+ **********************************************************************/
+static irqreturn_t rmi_phnx_mac_int_handler(int irq, void *dev_id)
+{
+	struct net_device *dev = (struct net_device *) dev_id;
+	struct driver_data *priv = netdev_priv(dev);
+	phoenix_reg_t *mmio = priv->mmio;
+	__u32 intreg = phoenix_read_reg(mmio, R_INTREG);
+	int cpu = hard_smp_processor_id();
+
+	mac_stats_add(priv->cpu_stats[cpu].interrupts, 1);
+
+	if (intreg & (1 << O_INTREG__MDInt)) {
+		__u32 phy_int_status = 0;
+		int i = 0;
+
+		for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+			struct net_device *phy_dev = 0;
+			struct driver_data *phy_priv = 0;
+			uint32_t config_val = 0;
+
+			phy_dev = dev_mac[i];
+			if (phy_dev == 0)
+				continue;
+
+			phy_priv = netdev_priv(phy_dev);
+
+			if (phy_priv->type == TYPE_XGMAC)
+				continue;
+			if (phy_priv->phy.mode == PHY_MODE_XAUI)
+				continue;
+
+			phy_int_status =
+			    rmi_phnx_mac_mii_read(phy_priv->phy.mii_addr,
+						  phy_priv->phy.addr, 26);
+
+			/*printk(KERN_DEBUG"[%s]: Received MDIO interrupt from mac_%d (type=%d), "
+			   "phy_int_status = 0x%08x reconfiguring gmac speed \n",
+			   __FUNCTION__, phy_priv->instance, phy_priv->type,
+			   phy_int_status); */
+			if (!phy_priv->instance
+			    && phy_priv->phy.serdes_addr != 0x0
+			    && phy_priv->phy.mode & PHY_MODE_SELECTABLE) {
+				int phyaddr;
+				unsigned long mii_addr, temp;
+				int mode = PHY_MODE_RGMII;
+				if (phy_priv->phy.mode & PHY_MODE_RGMII)
+					mode = PHY_MODE_SGMII;
+
+				phyaddr =
+				    phnx_get_phy_info(phy_priv->instance,
+						      mode, &mii_addr,
+						      &temp, &temp);
+				phy_int_status =
+				    rmi_phnx_mac_mii_read((phoenix_reg_t *)
+							  mii_addr,
+							  phyaddr, 26);
+				/*ack rgmii/sgmii mac */
+				phoenix_write_reg((phoenix_reg_t *)
+						  mii_addr, R_INTREG,
+						  0xffffffff);
+
+				/*      printk(KERN_DEBUG"[%s]: Received MDIO interrupt from mac_%d (type=%d), "
+				   "phy_int_status = 0x%08x reconfiguring gmac speed \n",
+				   __FUNCTION__, phy_priv->instance, phy_priv->type,
+				   phy_int_status); */
+			}
+			config_val =
+			    phoenix_read_reg(phy_priv->mmio,
+					     R_MAC_CONFIG_1);
+			phoenix_write_reg(phy_priv->mmio, R_MAC_CONFIG_1,
+					  (config_val & ~(0x35)));
+
+			if (phy_priv->phy.serdes_addr) {
+				serdes_autoconfig(phy_priv);
+			}
+			rmi_phnx_gmac_config_speed(phy_priv);
+			phoenix_write_reg(phy_priv->mmio, R_MAC_CONFIG_1,
+					  config_val);
+		}
+	} else {
+		printk("[%s]: mac type = %d, instance %d error "
+		       "interrupt: INTREG = 0x%08x\n",
+		       __FUNCTION__, priv->type, priv->instance, intreg);
+	}
+
+	/* clear all interrupts and hope to make progress */
+	phoenix_write_reg(mmio, R_INTREG, 0xffffffff);
+	//phnx_set_counter(NETIF_INT_REG, intreg);
+
+	/* on A0 and B0, xgmac interrupts are routed only to xgs_1 irq */
+	if ((xlr_revision_b0()) && (priv->type == TYPE_XGMAC)) {
+		struct net_device *xgs0_dev = dev_mac_type[TYPE_XGMAC][0];
+		struct driver_data *xgs0_priv = netdev_priv(xgs0_dev);
+		phoenix_reg_t *xgs0_mmio = xgs0_priv->mmio;
+		__u32 xgs0_intreg = phoenix_read_reg(xgs0_mmio, R_INTREG);
+
+		if (xgs0_intreg) {
+			printk("[%s]: mac type = %d, instance %d error "
+			       "interrupt: INTREG = 0x%08x\n",
+			       __FUNCTION__, xgs0_priv->type,
+			       xgs0_priv->instance, xgs0_intreg);
+
+			phoenix_write_reg(xgs0_mmio, R_INTREG, 0xffffffff);
+		}
+	}
+
+	return IRQ_HANDLED;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static int rmi_phnx_mac_open(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+
+	dbg_msg("IN\n");
+
+	if (rmi_phnx_mac_fill_rxfr(dev)) {
+		return -1;
+	}
+
+	spin_lock_bh(&priv->lock);
+	if (PORT_INIT(priv->cfg_flag))
+		phnx_mac_set_rx_mode(dev);
+
+
+	if (PORT_INT_ATTACH(priv->cfg_flag)) {
+		phoenix_write_reg(priv->mmio, R_INTMASK,
+				  (1 << O_INTMASK__TxIllegal) |
+				  (((priv->instance & 0x3) ==
+				    0) << O_INTMASK__MDInt) | (1 <<
+							       O_INTMASK__TxFetchError)
+				  | (1 << O_INTMASK__P2PSpillEcc) | (1 <<
+								     O_INTMASK__TagFull)
+				  | (1 << O_INTMASK__Underrun) | (1 <<
+								  O_INTMASK__Abort)
+		    );
+	}
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	if (rmi_msgring_napi) {
+		xlr_napi_ready = 1;
+	}
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+	if (PORT_INIT(priv->cfg_flag)) {
+		/*
+		 * Configure the speed, duplex, and flow control
+		 */
+		rmi_phnx_mac_set_speed(priv, priv->speed);
+		rmi_phnx_mac_set_duplex(priv, priv->duplex,
+					priv->flow_ctrl);
+		rmi_phnx_mac_set_enable(priv, 1);
+	}
+
+	spin_unlock_bh(&priv->lock);
+	netif_tx_start_all_queues(dev);
+
+	/* Set the timer to check for link beat. */
+	init_timer(&priv->link_timer);
+	priv->link_timer.expires = jiffies + 2 * HZ / 100;
+	priv->link_timer.data = (unsigned long) dev;
+	priv->link_timer.function = &rmi_phnx_mac_timer;
+	priv->phy_oldlinkstat = -1;	/* set link state to undefined */
+	add_timer(&priv->link_timer);
+
+	return 0;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static int rmi_phnx_mac_close(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	spin_lock_irq(&priv->lock);
+
+	/* There may have left over skbs in the ring as well as in free in 
+	 * they will be reused next time open is called 
+	 */
+
+	rmi_phnx_mac_set_enable(priv, 0);
+
+	del_timer_sync(&priv->link_timer);
+	netif_tx_stop_all_queues(dev);
+	phnx_inc_counter(NETIF_STOP_Q);
+	port_inc_counter(priv->instance, PORT_STOPQ);
+
+	spin_unlock_irq(&priv->lock);
+
+	return 0;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static void rmi_phnx_mac_timer(unsigned long data)
+{
+	struct net_device *dev = (struct net_device *) data;
+	struct driver_data *priv = netdev_priv(dev);
+	int next_tick = HZ;
+	int mii_status;
+
+	spin_lock_irq(&priv->lock);
+
+	if ((priv->type == TYPE_GMAC) && (priv->phy.mode != PHY_MODE_XAUI))
+		/* read flag "Link established" (0x04) of MII status register (1) */
+		mii_status =
+		    rmi_phnx_mac_mii_read(priv->phy.mii_addr,
+					  priv->phy.addr, 1) & 0x04;
+	else
+		mii_status = 1;
+
+	if (mii_status != priv->phy_oldlinkstat) {
+		priv->phy_oldlinkstat = mii_status;
+		if (mii_status) {
+			netif_carrier_on(dev);
+		} else {
+			netif_carrier_off(dev);
+		}
+	}
+
+	spin_unlock_irq(&priv->lock);
+	priv->link_timer.expires = jiffies + next_tick;
+	add_timer(&priv->link_timer);
+}
+
+/**********************************************************************
+ **********************************************************************/
+static struct net_device_stats *rmi_phnx_mac_get_stats(struct net_device
+						       *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	xlr_get_mac_stats(dev, &priv->stats);
+
+	/* XXX update other stats here */
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return &priv->stats;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static void rmi_phnx_mac_set_multicast_list(struct net_device *dev)
+{
+	/* 
+	 * Clear out entire multicast table.  We do this by nuking
+	 * the entire hash table and all the direct matches except
+	 * the first one, which is used for our station address 
+	 */
+
+	/*
+	 * Clear the filter to say we don't want any multicasts.
+	 */
+
+	if (dev->flags & IFF_ALLMULTI) {
+		/* 
+		 * Enable ALL multicasts.  Do this by inverting the 
+		 * multicast enable bit. 
+		 */
+		return;
+	}
+
+	/* 
+	 * Progam new multicast entries.  For now, only use the
+	 * perfect filter.  In the future we'll need to use the
+	 * hash filter if the perfect filter overflows
+	 */
+}
+
+
+
+/**********************************************************************
+ **********************************************************************/
+static int
+rmi_phnx_mac_do_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
+{
+	int rc = 0;
+	switch (cmd) {
+	default:
+		rc = -EOPNOTSUPP;
+		break;
+	}
+
+	return rc;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static void rmi_phnx_mac_tx_timeout(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+
+	spin_lock_irq(&priv->lock);
+
+	dev->trans_start = jiffies;
+	mac_stats_add(priv->stats.tx_errors, 1);
+
+	spin_unlock_irq(&priv->lock);
+
+	netif_tx_wake_all_queues(dev);
+	phnx_inc_counter(NETIF_START_Q);
+	port_inc_counter(priv->instance, PORT_STARTQ);
+
+	printk(KERN_WARNING "%s: Transmit timed out\n", dev->name);
+}
+
+/**********************************************************************
+ **********************************************************************/
+static int rmi_phnx_mac_change_mtu(struct net_device *dev, int new_mtu)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	if ((new_mtu > 1500) || (new_mtu < 64)) {
+		return -EINVAL;
+	}
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	dev->mtu = new_mtu;
+
+	if (netif_running(dev)) {
+		/* Disable MAC TX/RX */
+		rmi_phnx_mac_set_enable(priv, 0);
+
+		/* Flush RX FR IN */
+		/* Flush TX IN */
+		rmi_phnx_mac_set_enable(priv, 1);
+	}
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return 0;
+}
+
+/**********************************************************************
+ **********************************************************************/
+static int rmi_phnx_mac_fill_rxfr(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	struct sk_buff *skb = 0;
+	unsigned long msgrng_flags;
+	int i;
+	int ret = 0;
+
+	dbg_msg("\n");
+	if (!priv->init_frin_desc)
+		return ret;
+	priv->init_frin_desc = 0;
+
+	if (!(MSGRNG_OWN(priv->cfg_flag)))
+		return ret;
+
+	for (i = 0; i < priv->num_desc; i++) {
+		skb = rmi_phnx_alloc_skb();
+		if (!skb) {
+			ret = -ENOMEM;
+			break;
+		}
+
+		skb->dev = dev;
+
+
+		/* Send the free Rx desc to the MAC */
+		msgrng_access_enable(msgrng_flags);
+		mac_put_skb_back_ptr(skb);
+		if (phnx_mac_send_fr
+		    (priv, virt_to_bus(skb->data), skb->len)) {
+			dev_kfree_skb(skb);
+			printk
+			    ("message_send failed!, unable to send free desc to mac\n");
+			ret = -EIO;
+			break;
+		}
+		msgrng_access_disable(msgrng_flags);
+	}
+
+	for (i = 0; i < MAC_FRIN_WORK_NUM; i++)
+		atomic_set(&priv->frin_to_be_sent[i], 0);
+	return ret;
+}
+
+
+/**********************************************************************
+ **********************************************************************/
+static __inline__ void *rmi_phnx_config_spill(phoenix_reg_t * mmio,
+					      int reg_start_0,
+					      int reg_start_1,
+					      int reg_size, int size)
+{
+	__u32 spill_size = CACHELINE_ALIGNED_ADDR(size);
+	void *spill = cacheline_aligned_kmalloc(spill_size, GFP_KERNEL);
+	__u64 phys_addr = 0;
+
+	if (!spill) {
+		panic("Unable to allocate memory for spill area!\n");
+	}
+	phys_addr = virt_to_phys(spill);
+	phoenix_write_reg(mmio, reg_start_0,
+			  (phys_addr >> 5) & 0xffffffff);
+	phoenix_write_reg(mmio, reg_start_1, (phys_addr >> 37) & 0x07);
+	phoenix_write_reg(mmio, reg_size, spill_size);
+
+	return spill;
+}
+
+static void rmi_phnx_config_spill_area(struct driver_data *priv)
+{
+	int max_frin_spill = 0;
+	int max_frout_spill = 0;
+	int max_class_0_spill = 0;
+	int max_class_1_spill = 0;
+	int max_class_2_spill = 0;
+	int max_class_3_spill = 0;
+
+	if (!priv->num_desc || !priv->spill_init)
+		return;
+
+	if (!(MSGRNG_OWN(priv->cfg_flag)))
+		return;
+
+	max_frin_threshold = (priv->num_desc / NR_CPUS);
+	if (max_frin_threshold)
+		max_frin_threshold -= 1;
+
+
+	/* 
+	 * This is new approach to set up spill sizes. TCP stack termination in
+	 * the NAPI mode requires spill area for FreeOut's of considerable size.
+	 * We set frout spill here always to 15K descriptors which traslates into
+	 * 15K * 8 bytes kernel memory alloc.
+	 */
+	max_frin_spill = priv->num_desc << 2;
+	max_frout_spill = XLR_FROUT_JUMBO_SPILL;	/* 15K  */
+	max_class_0_spill = priv->num_desc;
+	max_class_1_spill = priv->num_desc;
+	max_class_2_spill = priv->num_desc;
+	max_class_3_spill = priv->num_desc;
+
+	priv->frin_spill =
+	    rmi_phnx_config_spill(priv->mmio,
+				  R_REG_FRIN_SPILL_MEM_START_0,
+				  R_REG_FRIN_SPILL_MEM_START_1,
+				  R_REG_FRIN_SPILL_MEM_SIZE,
+				  max_frin_spill * sizeof(struct fr_desc));
+
+	priv->class_0_spill =
+	    rmi_phnx_config_spill(priv->mmio,
+				  R_CLASS0_SPILL_MEM_START_0,
+				  R_CLASS0_SPILL_MEM_START_1,
+				  R_CLASS0_SPILL_MEM_SIZE,
+				  max_class_0_spill *
+				  sizeof(union rx_tx_desc));
+	priv->class_1_spill =
+	    rmi_phnx_config_spill(priv->mmio,
+				  R_CLASS1_SPILL_MEM_START_0,
+				  R_CLASS1_SPILL_MEM_START_1,
+				  R_CLASS1_SPILL_MEM_SIZE,
+				  max_class_1_spill *
+				  sizeof(union rx_tx_desc));
+
+	priv->frout_spill =
+	    rmi_phnx_config_spill(priv->mmio, R_FROUT_SPILL_MEM_START_0,
+				  R_FROUT_SPILL_MEM_START_1,
+				  R_FROUT_SPILL_MEM_SIZE,
+				  max_frout_spill *
+				  sizeof(struct fr_desc));
+
+	priv->class_2_spill =
+	    rmi_phnx_config_spill(priv->mmio,
+				  R_CLASS2_SPILL_MEM_START_0,
+				  R_CLASS2_SPILL_MEM_START_1,
+				  R_CLASS2_SPILL_MEM_SIZE,
+				  max_class_2_spill *
+				  sizeof(union rx_tx_desc));
+	priv->class_3_spill =
+	    rmi_phnx_config_spill(priv->mmio,
+				  R_CLASS3_SPILL_MEM_START_0,
+				  R_CLASS3_SPILL_MEM_START_1,
+				  R_CLASS3_SPILL_MEM_SIZE,
+				  max_class_3_spill *
+				  sizeof(union rx_tx_desc));
+}
+
+/*****************************************************************
+ * Write the MAC address to the PHNX registers
+ * All 4 addresses are the same for now
+ *****************************************************************/
+static void phnx_mac_setup_hwaddr(struct driver_data *priv)
+{
+	struct net_device *dev = priv->dev;
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR0,
+			  ((dev->dev_addr[5] << 24) | (dev->
+						       dev_addr[4] << 16)
+			   | (dev->dev_addr[3] << 8) | (dev->dev_addr[2]))
+	    );
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR0 + 1,
+			  ((dev->
+			    dev_addr[1] << 24) | (dev->dev_addr[0] <<
+						  16)));
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR_MASK2, 0xffffffff);
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR_MASK2 + 1, 0xffffffff);
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR_MASK3, 0xffffffff);
+
+	phoenix_write_reg(priv->mmio, R_MAC_ADDR_MASK3 + 1, 0xffffffff);
+
+	phoenix_write_reg(priv->mmio, R_MAC_FILTER_CONFIG,
+			  (1 << O_MAC_FILTER_CONFIG__BROADCAST_EN) |
+			  (1 << O_MAC_FILTER_CONFIG__ALL_MCAST_EN) |
+			  (1 << O_MAC_FILTER_CONFIG__MAC_ADDR0_VALID)
+	    );
+
+}
+
+/*****************************************************************
+ * Read the MAC address from the PHNX registers
+ * All 4 addresses are the same for now
+ *****************************************************************/
+static void phnx_mac_get_hwaddr(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+
+	dev->dev_addr[0] = phoenix_base_mac_addr[0];
+	dev->dev_addr[1] = phoenix_base_mac_addr[1];
+	dev->dev_addr[2] = phoenix_base_mac_addr[2];
+	dev->dev_addr[3] = phoenix_base_mac_addr[3];
+	dev->dev_addr[4] = phoenix_base_mac_addr[4];
+	dev->dev_addr[5] = phoenix_base_mac_addr[5] + priv->id;
+}
+
+/**********************************************************************
+ * Set a new Ethernet address for the interface.
+ **********************************************************************/
+static int rmi_phnx_set_mac_address(struct net_device *dev, void *addr)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	struct sockaddr *p_sockaddr = (struct sockaddr *) addr;
+
+	memcpy(dev->dev_addr, p_sockaddr->sa_data, 6);
+	phnx_mac_setup_hwaddr(priv);
+	return 0;
+}
+
+/*****************************************************************
+ * Mac Module Initialization
+ *****************************************************************/
+static void mac_common_init(struct driver_data *priv)
+{
+	int i = 0, stid;
+	void (*handler) (int, int, int, int, struct msgrng_msg *, void *);
+
+
+	for (i = 0; i < MAC_FRIN_WORK_NUM; i++) {
+		if (mac_frin_replenish_work[i].func == 0)
+			INIT_WORK(&mac_frin_replenish_work[i],
+				  mac_frin_replenish_wq);
+		if (mac_frin_replenish_task[i].func == 0)
+			tasklet_init(&mac_frin_replenish_task[i],
+				     mac_frin_replenish, 0UL);
+	}
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	/* Cached pointer to station ID translation table, needed for NAPI */
+	if (is_xls())
+		rxstn_to_txstn_ptr = &xls_rxstn_to_txstn_map[0];
+	else
+		rxstn_to_txstn_ptr = &rxstn_to_txstn_map[0];
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+
+	if (priv->type == TYPE_GMAC) {
+		if (is_xls()) {
+			if (priv->instance < PHOENIX_GMAC_PORTS_PER_CTRL)
+				stid = TX_STN_GMAC0;
+			else
+				stid = TX_STN_GMAC1;
+		} else
+			stid = TX_STN_GMAC;
+	} else if (priv->type == TYPE_XGMAC) {
+		if (priv->instance == 0)
+			stid = TX_STN_XGS_0;
+		else
+			stid = TX_STN_XGS_1;
+	} else {
+		printk("Invalid type %d\n", priv->type);
+		return;
+	}
+
+	if ((MSGRNG_OWN(priv->cfg_flag)))
+		handler = rmi_phnx_mac_msgring_handler;
+	else
+		handler = rmi_phnx_station_unowned_msgring_handler;
+
+	if (register_msgring_handler(stid, handler, NULL))
+		panic
+		    ("Couldn't register msgring handler for TX_STN_GMAC0\n");
+
+	return;
+}
+
+
+
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+/*
+ * Function covering only gmac/xgmac NAPI statistics
+*/
+static int
+xlr_napi_proc_read(char *page, char **start, off_t off, int count,
+		   int *eof, void *data)
+{
+	int len = 0;
+	off_t begin = 0;
+	int cpu = 0;
+
+
+	if (rmi_msgring_napi) {
+		len += sprintf(page + len, "NAPI Poll Weight=%u\n",
+			       napi_weight);
+		len +=
+		    sprintf(page + len,
+			    "         CPU          RX_COUNT\n");
+
+		for (cpu = 0; cpu < NR_CPUS; cpu++) {
+			if (!cpu_isset(cpu, cpu_online_map)) {
+				continue;
+			}
+			len +=
+			    sprintf(page + len, "napi: cpu=%02d: %16lld\n",
+				    cpu, per_cpu(xlr_napi_rx_count, cpu));
+
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;
+		}
+
+		/* Clear on read */
+		for (cpu = 0; cpu < NR_CPUS; cpu++) {
+			per_cpu(xlr_napi_rx_count, cpu) = 0;
+		}
+	}
+	*eof = 1;
+
+      out:
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;
+}
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+static int __init rmi_napi_poll_weight(const char *str)
+{
+	unsigned int wt = simple_strtoul(str, 0, 10);
+	if (wt < 1200) {
+		napi_weight = wt;
+	}
+	return 0;
+}
+
+early_param("rmi_napi_poll_weight", rmi_napi_poll_weight);
+
+static int
+xlr_mac_proc_read(char *page, char **start, off_t off,
+		  int count, int *eof, void *data)
+{
+	int len = 0;
+	off_t begin = 0;
+	int i = 0, cpu = 0;
+	struct net_device *dev = 0;
+	struct driver_data *priv = 0;
+
+
+	for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+		dev = dev_mac[i];
+		if (dev == 0)
+			continue;
+
+		priv = netdev_priv(dev);
+
+		for (cpu = 0; cpu < 32; cpu++) {
+
+			if (!cpu_isset(cpu, cpu_online_map))
+				continue;
+
+			len +=
+			    sprintf(page + len,
+				    "per_cpu: %d %d %d %d %lx %lx %lx %lx\n",
+				    i, cpu,
+				    user_mac ? user_mac->time.hi : 0,
+				    user_mac ? user_mac->time.lo : 0,
+				    priv->cpu_stats[cpu].tx_packets,
+				    priv->cpu_stats[cpu].txc_packets,
+				    priv->cpu_stats[cpu].rx_packets,
+				    priv->cpu_stats[cpu].interrupts);
+			if (!proc_pos_check(&begin, &len, off, count))
+				goto out;
+		}
+
+		len += sprintf(page + len,
+			       "per_port: %d %d %d %lx %lx %lx %lx\n",
+			       i,
+			       user_mac ? user_mac->time.hi : 0,
+			       user_mac ? user_mac->time.lo : 0,
+			       priv->stats.rx_packets,
+			       priv->stats.rx_bytes,
+			       priv->stats.tx_packets,
+			       priv->stats.tx_bytes);
+		if (!proc_pos_check(&begin, &len, off, count))
+			goto out;
+	}
+
+	*eof = 1;
+
+      out:
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;
+}
+
+
+
+
+
+
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+/*
+ * This function is used upon the exit from NAPI poll to re-enable interrupts
+*/
+static void xlr_napi_enable_ints(void)
+{
+	unsigned int msgring_config;
+	unsigned long flags = 0, mflags = 0;
+	struct napi_control_s *p = &napi_control[phoenix_cpu_id()];
+	unsigned long rcv_bmask;
+	unsigned long this_thread_bmask = (1 << phoenix_thr_id());
+
+
+	msgrng_access_save(&p->xlr_napi_msgrng_lock, flags, mflags);
+	p->netrx_mask |= this_thread_bmask;
+
+
+	/* Read message ring status */
+	rcv_bmask = (~(msgrng_read_status() >> 24)) & 0xff;
+	rcv_bmask = ((rcv_bmask & 0xf) | (rcv_bmask >> 4));
+
+	rcv_bmask &= p->netrx_mask;
+
+	if (rcv_bmask) {
+		/* rewrite the interrupt mask */
+		msgring_config = msgrng_read_config();
+		msgring_config |= (rcv_bmask << 8);
+		msgrng_write_config(msgring_config);
+	} else {
+
+		/* rewrite the interrupt mask */
+		msgring_config = msgrng_read_config();
+		msgring_config |= (this_thread_bmask << 8);
+		msgrng_write_config(msgring_config);
+	}
+	msgrng_access_restore(&p->xlr_napi_msgrng_lock, flags, mflags);
+}
+
+
+/* called from msgring_process_rx_msgs() from on_chip.c  */
+void xlr_napi_rx_schedule(void)
+{
+	unsigned int msgring_config;
+	unsigned long flags = 0, mflags = 0;
+	struct napi_struct *napi;
+	unsigned long rcv_bmask;	// bit array: bmask[i] is 1 iff bucket[i] or bucket[i + 4] non-empty 
+	unsigned long this_thread_bmask;	// non-zero if THIS thread has packets in its buckets
+	struct napi_control_s *p = &napi_control[phoenix_cpu_id()];
+
+	if (!xlr_napi_ready)
+		return;
+
+	/* rewrite the interrupt mask */
+	msgrng_access_save(&p->xlr_napi_msgrng_lock, flags, mflags);
+
+	/* Read message ring status */
+	rcv_bmask = (~(msgrng_read_status() >> 24)) & 0xff;
+	rcv_bmask = ((rcv_bmask & 0xf) | (rcv_bmask >> 4));
+
+	if (rcv_bmask == 0) {
+		msgrng_access_restore(&p->xlr_napi_msgrng_lock, flags,
+				      mflags);
+		write_64bit_cp0_eirr(1ULL << IRQ_MSGRING);
+		return;
+	}
+
+	this_thread_bmask = rcv_bmask & (1 << phoenix_thr_id());
+	p->netrx_mask &= ~this_thread_bmask;
+	rcv_bmask = rcv_bmask & p->netrx_mask;	// & ~(1 << phoenix_thr_id());
+
+	msgring_config = msgrng_read_config();
+	msgring_config = (msgring_config & 0xfffff0ff) | (rcv_bmask << 8);
+
+	msgrng_write_config(msgring_config);
+
+	msgrng_access_restore(&p->xlr_napi_msgrng_lock, flags, mflags);
+
+	/* Acknowledge interrupt in eirr */
+	write_64bit_cp0_eirr(1ULL << IRQ_MSGRING);
+
+	if (this_thread_bmask) {
+		/* schedule polling for this cpu using dummy_dev */
+		napi = &__get_cpu_var(xlr_napi_poll_struct);
+		netif_rx_schedule(&xlr_napi_dummy_dev, napi);
+	}
+}
+
+
+/*
+ * Main NAPI poll loop
+*/
+int xlr_napi_poll(struct napi_struct *napi, int budget)
+{
+	int rx_pkts = 0;
+	xlr_napi_poll_upper(&xlr_napi_dummy_dev, budget);
+	rx_pkts = napi_poll_lower(&xlr_napi_dummy_dev, budget);
+
+	if (rx_pkts < budget) {
+		netif_rx_complete(&xlr_napi_dummy_dev, napi);
+		/* enable message ring interrupts */
+		xlr_napi_enable_ints();
+	}
+	return rx_pkts;
+}
+
+
+/*
+ * Setup for XLR/XLS msgring NAPI parameter. 
+*/
+static int __init rmi_msgring_napi_setup(char *str)
+{
+	if (str == NULL || !strcmp(str, "yes") || !strcmp(str, "y")) {
+		rmi_msgring_napi = 1;
+		rmi_on_chip_napi = 1;
+	} else if (!strcmp(str, "no") || !strcmp(str, "n")) {
+		rmi_msgring_napi = 0;
+		rmi_on_chip_napi = 0;
+	}
+
+	return 0;
+}
+
+/* for compatibility we use "xlr_" prefix for the option */
+early_param("xlr_msgring_napi", rmi_msgring_napi_setup);
+
+
+/*
+ * Setup for XLR/XLS msgring NAPI parameter. 
+*/
+static int __init rmi_deprecated_napi_setup(char *str)
+{
+	if (str == NULL || !strcmp(str, "yes") || !strcmp(str, "y")) {
+		rmi_msgring_napi = 1;
+		rmi_on_chip_napi = 1;
+	}
+	return 0;
+}
+
+/* Deprecated setup option for NAPI */
+early_param("xlr_napi", rmi_deprecated_napi_setup);
+
+
+
+/*
+ * NAPI setup for non-networking on-chip devices. 
+*/
+static int __init rmi_on_chip_napi_setup(char *str)
+{
+	if (str == NULL || !strcmp(str, "yes") || !strcmp(str, "y")) {
+		if (rmi_msgring_napi == 0) {
+			printk
+			    ("MSGRING_NAPI:*****************************************************************\n");
+			printk
+			    ("MSGRING_NAPI:  Can't enable on_chip NAPI: enable xlr_msgring_napi first      *\n");
+			printk
+			    ("MSGRING_NAPI:*****************************************************************\n");
+			rmi_on_chip_napi = 0;
+		} else {
+			rmi_on_chip_napi = 1;
+		}
+	} else if (!strcmp(str, "no") || !strcmp(str, "n")) {
+		rmi_on_chip_napi = 0;
+	}
+
+	return 0;
+}
+
+/* for compatibility we use "xlr_" prefix for the option */
+early_param("xlr_on_chip_napi", rmi_on_chip_napi_setup);
+
+
+
+/*
+ * Setup XLR/XLS NAPI subsystem 
+*/
+static int rmi_phnx_napi_setup(void)
+{
+	int i, cpu_count;
+	struct napi_struct *napi;
+	int weight_p = napi_weight;
+
+	/* napi required msgring interrupt to be enabled, 
+	 * but it can be enabled only if both gmac and xgmac/spi4
+	 * are owned by linux 
+	 */
+	if (xlr_hybrid_user_mac_xgmac())
+		return 0;
+
+	printk
+	    ("MSGRING_NAPI: Initializing RMI GMAC/XGMAC NAPI subsystem\n");
+
+	msgring_int_type = 0x01;
+
+	atomic_set(&(xlr_napi_dummy_dev.refcnt), 1);
+	set_bit(__LINK_STATE_START, &xlr_napi_dummy_dev.state);
+
+	for (cpu_count = 0; cpu_count < NR_CPUS; cpu_count++) {
+		napi = &per_cpu(xlr_napi_poll_struct, cpu_count);
+		memset(napi, 0, sizeof(napi));
+		netif_napi_add(&xlr_napi_dummy_dev, napi, xlr_napi_poll,
+			       weight_p);
+		napi_enable(napi);
+	}
+
+	for (i = 0; i < NR_CPUS; i++) {
+		per_cpu(xlr_napi_rx_count, i) = 0;
+	}
+
+	return 0;
+}
+
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+
+
+
+static int xlr_get_settings(struct net_device *dev,
+			    struct ethtool_cmd *cmd)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	int mii_status;
+
+	if ((priv->type == TYPE_XGMAC)
+	    || (priv->phy.mode == PHY_MODE_XAUI)) {
+		cmd->supported =
+		    SUPPORTED_FIBRE | SUPPORTED_10000baseT_Full;
+		cmd->advertising =
+		    SUPPORTED_FIBRE | SUPPORTED_10000baseT_Full;
+		cmd->speed = SPEED_10000;
+		cmd->port = PORT_FIBRE;
+		cmd->duplex = DUPLEX_FULL;
+		cmd->phy_address = priv->instance;
+		cmd->autoneg = AUTONEG_DISABLE;
+		cmd->maxtxpkt = 0;
+		cmd->maxrxpkt = 0;
+
+	} else {
+
+		cmd->supported = SUPPORTED_10baseT_Full |
+		    SUPPORTED_10baseT_Half |
+		    SUPPORTED_100baseT_Full | SUPPORTED_100baseT_Half |
+		    SUPPORTED_1000baseT_Full | SUPPORTED_MII |
+		    SUPPORTED_Autoneg | SUPPORTED_TP;
+
+		cmd->advertising = priv->advertising;
+
+		mii_status =
+		    rmi_phnx_mac_mii_read(priv->phy.mii_addr,
+					  priv->phy.addr, MII_NCONFIG);
+		priv->speed = (mii_status >> 3) & 0x03;
+
+		cmd->speed =
+		    (priv->speed ==
+		     phnx_mac_speed_1000) ? SPEED_1000 : (priv->speed ==
+							  phnx_mac_speed_100)
+		    ? SPEED_100 : SPEED_10;
+
+		cmd->duplex = (mii_status >> 5) & 0x1;
+		cmd->port = PORT_TP;
+		cmd->phy_address = priv->instance;
+		cmd->transceiver = XCVR_INTERNAL;
+		cmd->autoneg = (~(mii_status >> 14)) & 0x1;
+		cmd->maxtxpkt = 0;
+		cmd->maxrxpkt = 0;
+	}
+
+	return 0;
+}
+
+static int xlr_enable_autoneg(struct net_device *dev, u32 adv)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	int mii_status;
+	u32 adv1, adv2;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	rmi_phnx_mac_set_enable(priv, 0);
+	/* advertising for 10/100 Mbps */
+	adv1 =
+	    rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr,
+				  MII_ADVERTISE);
+	adv1 &= ~(ADVERTISE_ALL | ADVERTISE_100BASE4);
+	/* advertising for 1000 Mbps */
+	adv2 =
+	    rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr, 0x9);
+	adv2 &= ~(0x300);
+
+	if (adv & ADVERTISED_10baseT_Half)
+		adv1 |= ADVERTISE_10HALF;
+	if (adv & ADVERTISED_10baseT_Full)
+		adv1 |= ADVERTISE_10FULL;
+	if (adv & ADVERTISED_100baseT_Full)
+		adv1 |= ADVERTISE_100FULL;
+	if (adv & ADVERTISED_100baseT_Half)
+		adv1 |= ADVERTISE_100HALF;
+
+	if (adv & ADVERTISED_1000baseT_Full)
+		adv2 |= 0x200;
+	if (adv & ADVERTISED_1000baseT_Half)
+		adv2 |= 0x100;
+
+	/* Set the advertising parameters */
+	rmi_phnx_mac_mii_write(priv->phy.mii_addr, priv->phy.addr,
+			       MII_ADVERTISE, adv1);
+	rmi_phnx_mac_mii_write(priv->phy.mii_addr, priv->phy.addr, 0x9,
+			       adv2);
+
+	priv->advertising = adv1 | adv2;
+
+	mii_status =
+	    rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr,
+				  MII_BMCR);
+	/* enable autoneg and force restart autoneg */
+	mii_status |= (BMCR_ANENABLE | BMCR_ANRESTART);
+	rmi_phnx_mac_mii_write(priv->phy.mii_addr, priv->phy.addr,
+			       MII_BMCR, mii_status);
+
+	rmi_phnx_mac_set_enable(priv, 1);
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+
+static int xlr_set_link_speed(struct net_device *dev, int speed,
+			      int duplex)
+{
+	u32 adv;
+	int ret = 0;
+
+	switch (speed) {
+	case SPEED_10:
+		if (duplex == DUPLEX_FULL)
+			adv = ADVERTISED_10baseT_Full;
+		else
+			adv = ADVERTISED_10baseT_Half;
+		break;
+	case SPEED_100:
+		if (duplex == DUPLEX_FULL)
+			adv = ADVERTISED_100baseT_Full;
+		else
+			adv = ADVERTISED_100baseT_Half;
+		break;
+	case SPEED_1000:
+		if (duplex == DUPLEX_FULL)
+			adv = ADVERTISED_1000baseT_Full;
+		else
+			adv = ADVERTISED_1000baseT_Half;
+		break;
+	default:
+		ret = -EINVAL;
+		return ret;
+	}
+	ret = xlr_enable_autoneg(dev, adv);
+	return ret;
+
+}
+
+static int xlr_set_settings(struct net_device *dev,
+			    struct ethtool_cmd *cmd)
+{
+	int ret;
+	struct driver_data *priv = netdev_priv(dev);
+
+	if ((priv->type == TYPE_XGMAC)
+	    || (priv->phy.mode == PHY_MODE_XAUI)) {
+		return -EIO;
+	}
+	if (cmd->autoneg == AUTONEG_ENABLE) {
+		ret = xlr_enable_autoneg(dev, cmd->advertising);
+	} else {
+		ret = xlr_set_link_speed(dev, cmd->speed, cmd->duplex);
+	}
+	return ret;
+}
+
+static void xlr_get_drvinfo(struct net_device *dev,
+			    struct ethtool_drvinfo *info)
+{
+	strcpy(info->driver, DRV_NAME);
+	strcpy(info->version, DRV_VERSION);
+}
+
+static int xlr_get_regs_len(struct net_device *dev)
+{
+	return PHNX_ETHTOOL_REG_LEN;
+}
+
+static void xlr_get_regs(struct net_device *dev,
+			 struct ethtool_regs *regs, void *p)
+{
+	u32 *data = (u32 *) p;
+	int i;
+	struct driver_data *priv = netdev_priv(dev);
+	unsigned long flags;
+
+	memset((void *) data, 0, PHNX_ETHTOOL_REG_LEN);
+
+	spin_lock_irqsave(&priv->lock, flags);
+	for (i = 0; i <= PHNX_NUM_REG_DUMP; i++)
+		*(data + i) =
+		    phoenix_read_reg(priv->mmio, R_TX_CONTROL + i);
+	spin_unlock_irqrestore(&priv->lock, flags);
+}
+
+static u32 xlr_get_msglevel(struct net_device *dev)
+{
+	return mac_debug;
+}
+
+static void xlr_set_msglevel(struct net_device *dev, u32 value)
+{
+	mac_debug = value;
+}
+
+static int xlr_nway_reset(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	int mii_status;
+	unsigned long flags;
+	int ret = -EINVAL;
+
+	if ((priv->type == TYPE_XGMAC)
+	    || (priv->phy.mode == PHY_MODE_XAUI))
+		return -EIO;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	mii_status =
+	    rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr,
+				  MII_BMCR);
+	if (mii_status & BMCR_ANENABLE) {
+		rmi_phnx_mac_mii_write(priv->phy.mii_addr, priv->phy.addr,
+				       MII_BMCR,
+				       BMCR_ANRESTART | mii_status);
+		ret = 0;
+	}
+	spin_unlock_irqrestore(&priv->lock, flags);
+	return ret;
+}
+
+static u32 xlr_get_link(struct net_device *dev)
+{
+	struct driver_data *priv = netdev_priv(dev);
+	int mii_status;
+	unsigned long flags;
+
+	if ((priv->type == TYPE_XGMAC)
+	    || (priv->phy.mode == PHY_MODE_XAUI))
+		return -EIO;
+
+	spin_lock_irqsave(&priv->lock, flags);
+	mii_status =
+	    rmi_phnx_mac_mii_read(priv->phy.mii_addr, priv->phy.addr,
+				  MII_BMSR);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	if (mii_status & BMSR_LSTATUS)
+		return 1;
+	return 0;
+}
+
+#define PHNX_STATS_KEY_LEN  \
+		(sizeof(struct net_device_stats) / sizeof(unsigned long))
+static struct {
+	const char string[ETH_GSTRING_LEN];
+} phnx_ethtool_stats_keys[PHNX_STATS_KEY_LEN] = {
+	{
+	"rx_packets"}, {
+	"tx_packets"}, {
+	"rx_bytes"}, {
+	"tx_bytes"}, {
+	"rx_errors"}, {
+	"tx_errors"}, {
+	"rx_dropped"}, {
+	"tx_dropped"}, {
+	"multicast"}, {
+	"collisions"}, {
+	"rx_length_errors"}, {
+	"rx_over_errors"}, {
+	"rx_crc_errors"}, {
+	"rx_frame_errors"}, {
+	"rx_fifo_errors"}, {
+	"rx_missed_errors"}, {
+	"tx_aborted_errors"}, {
+	"tx_carrier_errors"}, {
+	"tx_fifo_errors"}, {
+	"tx_heartbeat_errors"}, {
+	"tx_window_errors"}, {
+	"rx_compressed"}, {
+	"tx_compressed"}
+};
+
+static int xlr_get_stats_count(struct net_device *dev)
+{
+	return PHNX_STATS_KEY_LEN;
+}
+
+static void xlr_get_strings(struct net_device *dev, u32 stringset,
+			    u8 * buf)
+{
+	switch (stringset) {
+	case ETH_SS_STATS:
+		memcpy(buf, &phnx_ethtool_stats_keys,
+		       sizeof(phnx_ethtool_stats_keys));
+		break;
+	default:
+		printk(KERN_WARNING "%s: Invalid stringset %d\n",
+		       __FUNCTION__, stringset);
+		break;
+	}
+}
+
+static void xlr_get_mac_stats(struct net_device *dev,
+			      struct net_device_stats *stats)
+{
+	struct driver_data *priv = netdev_priv(dev);
+
+	stats->tx_errors =
+	    phoenix_read_reg(priv->mmio, TX_FCS_ERROR_COUNTER);
+	stats->rx_dropped =
+	    phoenix_read_reg(priv->mmio, RX_DROP_PACKET_COUNTER);
+	stats->tx_dropped =
+	    phoenix_read_reg(priv->mmio, TX_DROP_FRAME_COUNTER);
+
+	stats->multicast = phoenix_read_reg(priv->mmio,
+					    RX_MULTICAST_PACKET_COUNTER);
+	stats->collisions = phoenix_read_reg(priv->mmio,
+					     TX_TOTAL_COLLISION_COUNTER);
+
+	stats->rx_length_errors = phoenix_read_reg(priv->mmio,
+						   RX_FRAME_LENGTH_ERROR_COUNTER);
+	stats->rx_over_errors = phoenix_read_reg(priv->mmio,
+						 RX_DROP_PACKET_COUNTER);
+	stats->rx_crc_errors = phoenix_read_reg(priv->mmio,
+						RX_FCS_ERROR_COUNTER);
+	stats->rx_frame_errors = phoenix_read_reg(priv->mmio,
+						  RX_ALIGNMENT_ERROR_COUNTER);
+
+	stats->rx_fifo_errors = phoenix_read_reg(priv->mmio,
+						 RX_DROP_PACKET_COUNTER);
+	stats->rx_missed_errors = phoenix_read_reg(priv->mmio,
+						   RX_CARRIER_SENSE_ERROR_COUNTER);
+
+	stats->rx_errors = (stats->rx_over_errors + stats->rx_crc_errors +
+			    stats->rx_frame_errors +
+			    stats->rx_fifo_errors +
+			    stats->rx_missed_errors);
+
+	stats->tx_aborted_errors = phoenix_read_reg(priv->mmio,
+						    TX_EXCESSIVE_COLLISION_PACKET_COUNTER);
+	stats->tx_carrier_errors = phoenix_read_reg(priv->mmio,
+						    TX_DROP_FRAME_COUNTER);
+	stats->tx_fifo_errors = phoenix_read_reg(priv->mmio,
+						 TX_DROP_FRAME_COUNTER);
+
+}
+
+static void xlr_get_ethtool_stats(struct net_device *dev,
+				  struct ethtool_stats *estats,
+				  u64 * stats)
+{
+	int i;
+	struct driver_data *priv = netdev_priv(dev);
+	unsigned long flags;
+	unsigned long *tmp_stats;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	xlr_get_mac_stats(dev, &priv->stats);
+
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	tmp_stats = &priv->stats;
+	for (i = 0; i < PHNX_STATS_KEY_LEN; i++) {
+		*stats = (u64) * tmp_stats;
+		stats++;
+		tmp_stats++;
+	}
+}
+
+static struct ethtool_ops xlr_ethtool_ops = {
+	.get_settings = xlr_get_settings,
+	.set_settings = xlr_set_settings,
+	.get_drvinfo = xlr_get_drvinfo,
+	.get_regs_len = xlr_get_regs_len,
+	.get_regs = xlr_get_regs,
+	.get_msglevel = xlr_get_msglevel,
+	.set_msglevel = xlr_set_msglevel,
+	.nway_reset = xlr_nway_reset,
+	.get_link = xlr_get_link,
+	.get_strings = xlr_get_strings,
+	.get_stats_count = xlr_get_stats_count,
+	.get_ethtool_stats = xlr_get_ethtool_stats,
+};
+
+void rmi_reset_gmac(phoenix_reg_t * mmio)
+{
+	volatile uint32_t val;
+
+	/* Disable MAC RX */
+	val = phoenix_read_reg(mmio, R_MAC_CONFIG_1);
+	val &= ~0x4;
+	phoenix_write_reg(mmio, R_MAC_CONFIG_1, val);
+
+	/* Disable Core RX */
+	val = phoenix_read_reg(mmio, R_RX_CONTROL);
+	val &= ~0x1;
+	phoenix_write_reg(mmio, R_RX_CONTROL, val);
+
+	/* wait for rx to halt */
+	while (1) {
+		val = phoenix_read_reg(mmio, R_RX_CONTROL);
+		if (val & 0x2)
+			break;
+		mdelay(1);
+	}
+
+	/* Issue a soft reset */
+	val = phoenix_read_reg(mmio, R_RX_CONTROL);
+	val |= 0x4;
+	phoenix_write_reg(mmio, R_RX_CONTROL, val);
+
+	/* wait for reset to complete */
+	while (1) {
+		val = phoenix_read_reg(mmio, R_RX_CONTROL);
+		if (val & 0x8)
+			break;
+		mdelay(1);
+	}
+
+	/* Clear the soft reset bit */
+	val = phoenix_read_reg(mmio, R_RX_CONTROL);
+	val &= ~0x4;
+	phoenix_write_reg(mmio, R_RX_CONTROL, val);
+}
+
+void rmi_reset_xaui(phoenix_reg_t * mmio)
+{
+	volatile uint32_t val;
+
+	/* Disable Core RX */
+	val = phoenix_read_reg(mmio, R_RX_CONTROL);
+	val &= ~0x1;
+	phoenix_write_reg(mmio, R_RX_CONTROL, val);
+
+	/* wait for rx to halt */
+	while (1) {
+		val = phoenix_read_reg(mmio, R_RX_CONTROL);
+		if (val & 0x2)
+			break;
+		mdelay(1);
+	}
+
+	/* Issue a soft reset */
+	val = phoenix_read_reg(mmio, R_RX_CONTROL);
+	val |= 0x4;
+	phoenix_write_reg(mmio, R_RX_CONTROL, val);
+
+	/* wait for reset to complete */
+	while (1) {
+		val = phoenix_read_reg(mmio, R_RX_CONTROL);
+		if (val & 0x8)
+			break;
+		mdelay(1);
+	}
+
+	/* Clear the soft reset bit */
+	val = phoenix_read_reg(mmio, R_RX_CONTROL);
+	val &= ~0x4;
+	phoenix_write_reg(mmio, R_RX_CONTROL, val);
+}
+
+u16 rmi_select_tx_queue(struct net_device *dev, struct sk_buff *skb)
+{
+	return (u16) smp_processor_id();
+}
+
+
+int rmi_phnx_mac_init_module(void)
+{
+	struct net_device *dev = 0;
+	struct driver_data *priv = 0;
+	unsigned long mmio_start = 0;
+	int i = 0, num_desc = 0, num_desc_total = 0;
+	int ret = 0, port_type;
+	struct proc_dir_entry *entry;
+	struct port_cfg *port_cfg;
+	extern struct net_device_cfg phnx_net_dev_cfg;
+	struct net_device_cfg *net_cfg = &phnx_net_dev_cfg;
+	int port_xaui = 0;
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+
+	/* Run NAPI compatibility test */
+	if (!rmi_napi_compatibility_check()) {
+		rmi_msgring_napi = 0;
+		rmi_on_chip_napi = 0;
+	}
+
+	if (rmi_msgring_napi) {
+		rmi_phnx_napi_setup();
+	} else {
+		printk("MSGRING_NAPI: NAPI is not enabled!\n");
+	}
+
+	/* Initialize spinlock protecting NAPI msgring_config access */
+	for (i = 0; i < NR_CPUS / 4; i++) {
+		spin_lock_init(&napi_control[i].xlr_napi_msgrng_lock);
+		napi_control[i].netrx_mask = 0xf;
+	}
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+	for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+		spin_lock_init(&pending_tx_lock[i]);
+	}
+
+	chip_is_xls = is_xls();
+
+	entry = create_proc_read_entry("rmi_mac_stats", 0 /* def mode */ ,
+				       rmi_root_proc /* parent */ ,
+				       xlr_mac_proc_read
+				       /* proc read function */ ,
+				       0	/* no client data */
+	    );
+	if (!entry) {
+		printk
+		    ("[%s]: Unable to create proc read entry for xlr_mac!\n",
+		     __FUNCTION__);
+	}
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	if (rmi_msgring_napi) {
+		entry =
+		    create_proc_read_entry("rmi_napi_stats",
+					   0 /* def mode */ ,
+					   rmi_root_proc /* parent */ ,
+					   xlr_napi_proc_read
+					   /* proc read function */ ,
+					   0	/* no client data */
+		    );
+		if (!entry) {
+			printk
+			    ("[%s]: Unable to create proc read entry for xlr_napi!\n",
+			     __FUNCTION__);
+		}
+	}
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+	for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+
+		if (i < PHOENIX_MAX_GMACS) {
+			port_cfg = &net_cfg->gmac_port[i];
+			port_type = TYPE_GMAC;
+			port_xaui = (port_cfg->phy_mode == PHY_MODE_XAUI);
+		} else if (net_cfg->xgs_type[i - PHOENIX_MAX_GMACS] ==
+			   TYPE_XGMAC) {
+			port_cfg =
+			    &net_cfg->xgs_port[i - PHOENIX_MAX_GMACS];
+			port_type = TYPE_XGMAC;
+		} else
+			continue;
+
+		if (port_cfg->cfg_flag == 0)
+			continue;
+
+		dbg_msg("Registering phnx_mac[%d]\n", i);
+
+		dev = alloc_etherdev_mq(sizeof(struct driver_data), 32);
+		if (!dev) {
+			ret = -ENOMEM;
+			goto out;
+		}
+
+		priv = netdev_priv(dev);
+		priv->dev = dev;
+		priv->cfg_flag = port_cfg->cfg_flag;
+
+		priv->mmio = (phoenix_reg_t *) port_cfg->mmio_addr;
+		if (!priv->mmio) {
+			dbg_panic
+			    ("Unable to ioremap MMIO region of size %x @ %lx\n",
+			     PHOENIX_IO_SIZE, mmio_start);
+		}
+
+		dbg_msg(" priv->mmio=%p\n", priv->mmio);
+
+		if (port_type == TYPE_GMAC && PORT_INIT(priv->cfg_flag)) {
+			if (port_xaui)
+				rmi_reset_xaui(priv->mmio);
+			else
+				rmi_reset_gmac(priv->mmio);
+		}
+
+		/* Initialize the net_device */
+		if (PORT_INT_ATTACH(priv->cfg_flag)) {
+			dev->irq = port_cfg->irqno;
+			if (request_irq(dev->irq, rmi_phnx_mac_int_handler,
+					IRQF_DISABLED, dev->name, dev)) {
+				ret = -EBUSY;
+				panic
+				    ("Couldn't get mac interrupt line (%d)",
+				     dev->irq);
+			}
+		}
+
+		ether_setup(dev);
+
+		dev->base_addr = (long) priv->mmio;
+		dev->mem_end = (long) priv->mmio + PHOENIX_IO_SIZE - 1;
+
+		dev->open = rmi_phnx_mac_open;
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+		if (rmi_msgring_napi) {
+			dev->hard_start_xmit = rmi_phnx_napi_mac_xmit;
+		} else {
+			dev->hard_start_xmit = rmi_phnx_mac_xmit;
+		}
+#else
+		dev->hard_start_xmit = rmi_phnx_mac_xmit;
+
+#endif				/* CONFIG_PHOENIX_MSGRING_NAPI */
+
+		dev->stop = rmi_phnx_mac_close;
+		dev->get_stats = rmi_phnx_mac_get_stats;
+		dev->set_multicast_list = rmi_phnx_mac_set_multicast_list;
+		dev->set_mac_address = rmi_phnx_set_mac_address;
+		dev->do_ioctl = rmi_phnx_mac_do_ioctl;
+		dev->tx_timeout = rmi_phnx_mac_tx_timeout;
+		dev->watchdog_timeo = (1000 * HZ);
+		dev->change_mtu = rmi_phnx_mac_change_mtu;
+
+		dev->features |= NETIF_F_LLTX;
+		dev->select_queue = rmi_select_tx_queue;
+
+		SET_ETHTOOL_OPS(dev, &xlr_ethtool_ops);
+		/* Initialize the device specific driver data */
+		spin_lock_init(&priv->lock);
+
+		priv->id = i;
+		priv->instance = port_cfg->instance;
+		priv->type = port_type;
+		if (port_cfg->num_desc) {
+			num_desc = port_cfg->num_desc;
+			priv->spill_init = 1;
+		} else
+			priv->spill_init = 0;
+
+		dev->tx_queue_len = (num_desc / 32) - 1;
+		priv->num_desc = num_desc;
+		priv->config_pde = port_cfg->config_pde;
+
+		num_desc_total += num_desc;
+
+		/* Caching FRF and TX station IDs */
+		priv->fr_stid =
+		    msgrng_stid_rfr(priv->instance, priv->type);
+		priv->tx_stid =
+		    mac_fill_tx_stid(priv->instance, priv->type);
+
+		/* fill the phy info */
+		priv->phy.addr = port_cfg->phy_addr;
+		priv->phy.mode = port_cfg->phy_mode;
+		priv->phy.mii_addr = mac_addr_to_ptr(port_cfg->mii_addr);
+		priv->phy.pcs_addr = mac_addr_to_ptr(port_cfg->pcs_addr);
+		priv->phy.serdes_addr =
+		    mac_addr_to_ptr(port_cfg->serdes_addr);
+
+
+		phnx_mac_get_hwaddr(dev);
+
+		if (PORT_INIT(priv->cfg_flag)) {
+			if (priv->type == TYPE_GMAC) {
+				if (port_xaui)
+					rmi_phnx_xaui_init(priv, port_cfg);
+				else
+					rmi_phnx_gmac_init(priv, port_cfg);
+			} else if (priv->type == TYPE_XGMAC)
+				rmi_phnx_xgmac_init(priv, port_cfg);
+
+			phnx_mac_setup_hwaddr(priv);
+		}
+
+		if (PORT_ATTACH(priv->cfg_flag)) {
+			ret = register_netdev(dev);
+			if (ret) {
+				dbg_panic
+				    ("Unable to register net device\n");
+			} else {
+				if (priv->type == TYPE_GMAC)
+					printk
+					    ("GMAC_%d initialized as %s\n",
+					     priv->instance,
+					     priv->dev->name);
+				else if (priv->type == TYPE_XGMAC)
+					printk
+					    ("XGMAC_%d initialized as %s\n",
+					     priv->instance,
+					     priv->dev->name);
+			}
+		}
+		//if(PORT_INIT(priv->cfg_flag)) 
+		//      rmik_config_pde(priv->type, priv->instance, priv->mmio);
+
+		priv->frstid_rsvd = 1;
+
+
+		mac_common_init(priv);
+		rmi_phnx_mac_set_enable(priv, 0);
+
+		dbg_msg("%s: Phoenix Mac at 0x%p (mtu=%d)\n",
+			dev->name, priv->mmio, dev->mtu);
+
+		dev_mac_type[priv->type][priv->instance] = dev;
+		dev_mac[i] = dev;
+	}
+
+	//rmik_init_replenish_work(num_desc);
+	//rmik_register_net_events();
+
+	dbg_msg("port_counters = %p\n", port_counters);
+	dbg_msg("pending_tx_lock = %p, pending_tx = %p\n", port_counters,
+		pending_tx);
+
+
+
+      out:
+	if ((xlr_board_atx_v() || xlr_board_atx_iv_b())) {
+		/* on atx-v and atx-iv-b read rgmii interrupt at least once */
+		dev = dev_mac_type[TYPE_GMAC][0];
+		if (dev != 0) {
+			priv = netdev_priv(dev);
+			rmi_phnx_mac_mii_read(priv->phy.mii_addr, 3, 26);
+		}
+	}
+
+	for (i = 0; i < PHOENIX_MAX_GMACS; i++) {
+		if (dev_mac[i] == 0)
+			continue;
+
+		priv = netdev_priv(dev_mac[i]);
+		if (PORT_INIT(priv->cfg_flag))
+			phnx_mac_set_rx_mode(dev_mac[i]);
+
+		if (PORT_INT_ATTACH(priv->cfg_flag)) {
+			phoenix_write_reg(priv->mmio, R_INTMASK,
+					  (1 << O_INTMASK__TxIllegal) |
+					  (((priv->instance & 0x3) ==
+					    0) << O_INTMASK__MDInt) | (1 <<
+								       O_INTMASK__TxFetchError)
+					  | (1 << O_INTMASK__P2PSpillEcc) |
+					  (1 << O_INTMASK__TagFull) | (1 <<
+								       O_INTMASK__Underrun)
+					  | (1 << O_INTMASK__Abort));
+		}
+	}
+	if (ret < 0) {
+		dbg_panic("Error, ret = %d\n", ret);
+	}
+	return ret;
+}
+
+/**********************************************************************
+ **********************************************************************/
+void rmi_phnx_mac_exit_module(void)
+{
+	struct net_device *dev;
+	int idx;
+
+	for (idx = 0; idx < PHOENIX_MAX_MACS; idx++) {
+		dev = dev_mac[idx];
+		if (dev == 0)
+			continue;
+
+		unregister_netdev(dev);
+		free_netdev(dev);
+	}
+}
+
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+
+int rmi_macreg_set(int inf, unsigned int reg, unsigned int val)
+{
+	struct driver_data *priv = NULL;
+	struct net_device *dev = NULL;
+
+	dev = dev_mac[inf];
+
+	if (!dev)
+		return -1;
+
+	priv = netdev_priv(dev);
+	phoenix_write_reg(priv->mmio, reg,
+			  phoenix_read_reg(priv->mmio, reg) | val);
+	return 0;
+}
+
+u32 rmi_macreg_get(int inf, unsigned int reg)
+{
+	struct driver_data *priv = NULL;
+	struct net_device *dev = NULL;
+
+	dev = dev_mac[inf];
+
+	if (!dev)
+		return -1;
+
+	priv = netdev_priv(dev);
+	return phoenix_read_reg(priv->mmio, reg);
+}
+
+int rmi_mac_get_inf_idx(char *infname)
+{
+	int i = 0;
+	struct net_device *dev = NULL;
+	u32 rc = -1;
+	for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+		if (!strncmp(infname, dev[i].name, sizeof(infname))) {
+			rc = i;
+			break;
+		}
+	}
+	return rc;
+}
+
+int rmi_macreg_clr_set(int inf, u32 reg, u32 val, u32 mask)
+{
+	struct driver_data *priv = NULL;
+	struct net_device *dev = NULL;
+	u32 curr_val = 0;
+
+	dev = dev_mac[inf];
+
+	if (!dev)
+		return -1;
+
+	priv = netdev_priv(dev);
+	curr_val = phoenix_read_reg(priv->mmio, reg) & (~mask);
+//    printk("reg %x curval %x reg %x\n", reg, curr_val, phoenix_read_reg(priv->mmio,reg));
+//    printk("wr reg %x curval %x val %x mask %x\n", reg, curr_val| (val& mask), val , mask);
+	phoenix_write_reg(priv->mmio, reg, curr_val | (val & mask));
+
+	//printk("reg %x rdval %x\n", reg, phoenix_read_reg(priv->mmio,reg));
+	return 0;
+}
+
+void rmi_macreg_set_all(u32 reg, u32 val, u32 mask)
+{
+	int i = 0;
+
+	for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+		rmi_macreg_clr_set(i, reg, val, mask);
+		//rmi_macreg_set(i, reg, val);        
+	}
+}
+
+void rmi_macreg_clr_set_all(u32 reg, u32 val, u32 mask)
+{
+	int i = 0;
+
+	for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+		rmi_macreg_clr_set(i, reg, val, mask);
+//        rmi_macreg_set(i, reg, val);        
+	}
+}
+
+void dump_all_interface(unsigned int reg)
+{
+	int i = 0;
+	struct net_device *dev;
+	struct driver_data *priv;
+	u32 curr_val = 0;
+
+	for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+
+		dev = dev_mac[i];
+		if (!dev)
+			continue;
+		priv = netdev_priv(dev);
+		curr_val = phoenix_read_reg(priv->mmio, reg);
+//        printk("interface %x    val %x name %s\n", priv->mmio,  curr_val, dev->name); 
+	}
+
+}
+
+void rmi_register_ptp_ts_fp(void (*fp) (u32, u32, ktime_t *, u32))
+{
+	printk("register ptp\n");
+	p_ptp_set_ts = fp;
+}
+
+void rmi_clr_ptp_ts_fp(void)
+{
+	p_ptp_set_ts = NULL;
+}
+
+EXPORT_SYMBOL(rmi_macreg_set_all);
+EXPORT_SYMBOL(dump_all_interface);
+EXPORT_SYMBOL(rmi_register_ptp_ts_fp);
+#endif
+module_init(rmi_phnx_mac_init_module);
+module_exit(rmi_phnx_mac_exit_module);
+
+/*************************************************************************
+ * TODO:
+ *     o Currently, if Tx completes do not come back, Tx hangs for ever. Though it is good
+ *       for debugging, there should be a timeout mechanism.
+ *     o Right now, all cpu-threads across cpus are serialized for transmitting
+ *       packets. However, message_send is "atomic", hence all of them should
+ *       transmit without contending for the lock. some like per-cpu, per device lock 
+ *       and handling tx complete on the cpu that did the transmit
+ *     o use fetchadd for stat variable. currently, it not even atomic
+ *************************************************************************/
diff --git a/drivers/net/phoenix_user_mac.c b/drivers/net/phoenix_user_mac.c
new file mode 100644
index 0000000..f5c1877
--- /dev/null
+++ b/drivers/net/phoenix_user_mac.c
@@ -0,0 +1,1457 @@
+/*********************************************************************
+
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/vmalloc.h>
+#include <linux/poll.h>
+#include <linux/workqueue.h>
+#include <linux/proc_fs.h>
+#include <linux/cpumask.h>
+
+#include <asm/uaccess.h>
+#include <asm/mman.h>
+#include <asm/atomic.h>
+#include <asm/smp.h>
+
+#include <asm/rmi/pic.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/debug.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/devices.h>
+#include <asm/rmi/phoenix_mac.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/gpio.h>
+#include <asm/rmi/proc.h>
+#include <asm/page.h>
+#include <user/rmi/phnx_user_mac.h>
+#include <linux/hugetlb.h>
+#include <linux/bootmem.h>
+
+#define MB(x)	(x<<20)
+#define	KB(x)	(x<<10)
+#ifdef dbg_msg
+#undef dbg_msg
+#endif
+#define dbg_msg(fmt, args...)	//printk(fmt, ##args)
+#define Message(a, b...)	//printk("\nFunc[%s], Line[%d], "a"\n",__FUNCTION__,__LINE__,##b)
+
+/* this flag will be set by rmi spi4 driver, it indicates
+   whether spi4 daughter cards are present on the board or not
+*/
+#ifdef CONFIG_PHOENIX_SPI4
+//extern unsigned int g_spi4_card_flag;
+#else				/* CONFIG_PHOENIX_SPI4 */
+//static unsigned int g_spi4_card_flag;
+#endif				/* CONFIG_PHOENIX_SPI4 */
+
+//#define USER_MAC_LOOPBACK
+extern int xlr_loader_support, xlr_loader_sharedcore;
+//extern void spi4_enable_tx_rx(unsigned int  *mmio);
+//extern void spi4_disable_tx_rx(unsigned int  *mmio);
+
+extern void *phoenix_psb_shm;
+extern unsigned long phoenix_psb_shm_size;
+
+static unsigned long long phoenix_psb_shm_paddr;
+static int user_mac_major;
+struct user_mac_data *user_mac;
+/* use per cpu data structures for the Queues below */
+extern int xlr_hybrid;
+extern struct proc_dir_entry *rmi_root_proc;
+
+#define USER_MAC_TX_THRESHOLD 1
+
+#define MAC_CRC_LEN 4
+#define BYTE_OFFSET 2
+#define MAC_PREPAD_LEN 32
+
+#define MAC_DEV_NULL_BUCKET 127
+
+struct usermac_priv {
+	int num_desc;
+	int type;
+	phoenix_reg_t *mmio;
+	void *frin_spill;
+	void *frout_spill;
+	void *class_0_spill;
+	void *class_1_spill;
+	void *class_2_spill;
+	void *class_3_spill;
+};
+
+struct usermac_dev {
+	uint32_t gmac_list;
+	int xgmac_present;
+	int spi4_present;
+	struct usermac_priv priv[32];
+};
+
+static struct usermac_dev usermac_dev;
+static int hybrid_mem_init = 1;
+
+/*Hugetlb usermac data structures*/
+static struct page **page_array;
+static void *htlb_kvaddr = NULL;
+static phys_t htlb_kpaddr = 0ULL;
+static void user_mac_mem_init(void);
+
+
+static unsigned long long user_mac_vaddr_to_phys(void *addr)
+{
+	if (htlb_kvaddr) {
+		return ((unsigned long) addr -
+			(unsigned long) htlb_kvaddr + htlb_kpaddr);
+	} else {
+		return __pa(addr);
+	}
+}
+
+static __inline__ int user_mac_ptr2index(unsigned long long addr)
+{
+	int index =
+	    (addr -
+	     user_mac_vaddr_to_phys(user_mac->pkt_data)) /
+	    USER_MAC_PKT_BUF_SIZE;
+
+	if (index < 0 || index >= MAX_USER_MAC_PKTS) {
+		printk("[%s]: bad index=%d, addr=%llx, pkt_data=%p\n",
+		       __FUNCTION__, index, addr, &user_mac->pkt_data);
+		return -1;
+	}
+	return index;
+}
+
+#ifdef MAC_TX_DESC_ALIGNMENT
+#undef MAC_TX_DESC_ALIGNMENT
+#endif
+#define MAC_TX_DESC_ALIGNMENT (SMP_CACHE_BYTES + MAC_PREPAD_LEN - 1)
+
+#define CTRL_RES0           0
+#define CTRL_RES1           1
+#define CTRL_REG_FREE       2
+#define CTRL_CONT           4
+#define CTRL_EOP            5
+#define CTRL_START          6
+#define CTRL_SNGL           7
+
+static __inline__ int user_mac_send_frin_num_xgs_pkts(void)
+{
+	int num_xgmac_pkts = MAX_USER_MAC_FRIN_PKTS / 2.5;
+
+	return num_xgmac_pkts;
+}
+
+static __inline__ int user_mac_send_frin_num_gmac_pkts(void)
+{
+	return user_mac_send_frin_num_xgs_pkts() / 2;
+}
+
+static __inline__ int user_mac_send_frin_is_desc_gmac(int index)
+{
+	int start_index = 0, end_index = 0;
+
+	start_index = 0;
+	end_index = start_index + user_mac_send_frin_num_gmac_pkts();
+	return ((index >= start_index) && (index < end_index)) ? 1 : 0;
+}
+
+static __inline__ int user_mac_send_frin_is_desc_xgs0(int index)
+{
+	int start_index = 0, end_index = 0;
+
+	start_index = user_mac_send_frin_num_gmac_pkts();
+	end_index = start_index + user_mac_send_frin_num_xgs_pkts();
+	return ((index >= start_index) && (index < end_index)) ? 1 : 0;
+}
+
+static __inline__ int user_mac_send_frin_is_desc_xgs1(int index)
+{
+	int start_index = 0, end_index = 0;
+
+	start_index =
+	    user_mac_send_frin_num_gmac_pkts() +
+	    user_mac_send_frin_num_xgs_pkts();
+	end_index = start_index + user_mac_send_frin_num_xgs_pkts();
+	return ((index >= start_index) && (index < end_index)) ? 1 : 0;
+}
+
+static __inline__ int user_mac_send_frin_stid(int index)
+{
+	if (is_xls()) {
+		/* If only gmac-block 0 is active , Or only gmac-block1 is active */
+		if ((usermac_dev.gmac_list & 0x0f)
+		    && (!(usermac_dev.gmac_list & 0xf0)))
+			return MSGRNG_STNID_GMAC0_FR;
+		else if ((usermac_dev.gmac_list & 0xf0)
+			 && (!(usermac_dev.gmac_list & 0x0f)))
+			return MSGRNG_STNID_GMAC1_FR;
+		if ((index >= 0) && (index < (MAX_USER_MAC_FRIN_PKTS / 2)))
+			return MSGRNG_STNID_GMAC0_FR;
+		return MSGRNG_STNID_GMAC1_FR;
+	}
+	/* xlr case */
+	if (usermac_dev.gmac_list & 0x0f) {
+		switch (usermac_dev.xgmac_present | usermac_dev.
+			spi4_present) {
+		case 0x03:
+			if (user_mac_send_frin_is_desc_gmac(index))
+				return MSGRNG_STNID_GMACRFR_0;
+			if (user_mac_send_frin_is_desc_xgs0(index))
+				return MSGRNG_STNID_XMAC0RFR;
+			if (user_mac_send_frin_is_desc_xgs1(index))
+				return MSGRNG_STNID_XMAC1RFR;
+			return MSGRNG_STNID_GMACRFR_0;
+		case 0x01:
+			if ((index >= 0)
+			    && (index < (MAX_USER_MAC_FRIN_PKTS / 4)))
+				return MSGRNG_STNID_GMACRFR_0;
+			return MSGRNG_STNID_XMAC0RFR;
+		case 0x02:
+			if ((index >= 0)
+			    && (index < (MAX_USER_MAC_FRIN_PKTS / 4)))
+				return MSGRNG_STNID_GMACRFR_0;
+			return MSGRNG_STNID_XMAC1RFR;
+		default:
+			return MSGRNG_STNID_GMACRFR_0;
+		}
+	} else {
+		/* xgmac should be present, this function should not be called when
+		   all the gmac & xgmac stations are not owned by linux */
+		switch (usermac_dev.xgmac_present | usermac_dev.
+			spi4_present) {
+		case 0x03:
+			if ((index >= 0)
+			    && (index < (MAX_USER_MAC_FRIN_PKTS / 2)))
+				return MSGRNG_STNID_XMAC0RFR;
+			return MSGRNG_STNID_XMAC1RFR;
+		case 0x01:
+			return MSGRNG_STNID_XMAC0RFR;
+		case 0x02:
+			return MSGRNG_STNID_XMAC1RFR;
+		default:
+			return -1;
+
+
+		}
+	}
+}
+
+static void user_mac_send_frin(void)
+{
+	struct msgrng_msg msg;
+	struct packet_data *packet_data = user_mac->pkt_data;
+	int i = 0;
+	int cnt[4] = { 0, 0, 0, 0 };
+	uint64_t addr = 0;
+	unsigned long mflags = 0;
+	int stid = 0;
+	int host_gen_num_pkts =
+	    (MAX_USER_MAC_PKTS - MAX_USER_MAC_FRIN_PKTS) / 32;
+
+	if (usermac_dev.gmac_list == 0 && usermac_dev.xgmac_present == 0 &&
+	    usermac_dev.spi4_present == 0)
+		return;
+
+
+	msgrng_flags_save(mflags);
+
+	for (i = 0; i < MAX_USER_MAC_FRIN_PKTS; i++) {
+		addr = user_mac_vaddr_to_phys(&packet_data[i].data);
+		user_mac->pkt_desc[i].free = 0;
+
+		msg.msg0 = (uint64_t) addr & ~(SMP_CACHE_BYTES - 1);
+		msg.msg1 = msg.msg2 = msg.msg3 = 0;
+
+		stid = user_mac_send_frin_stid(i);
+/*
+		if (usermac_dev.spi4_present){
+            		if((stid == MSGRNG_STNID_XMAC0RFR) && (!(g_spi4_card_flag & 0x01))){
+                		//spi4-0 card is not present
+						Message("SPI4-0 Card not present - %d index not send",i);
+                		continue;
+            		}
+            		else if((stid == MSGRNG_STNID_XMAC1RFR) && (!(g_spi4_card_flag & 0x02))){
+                		//spi4-1 card is not present
+						Message("SPI4-1 Card not present - %d index not send",i);
+                		continue;
+            		}
+       	}
+	*/
+
+		do {
+			if (!message_send_retry
+			    (1, MSGRNG_CODE_MAC, stid, &msg)) {
+				if (stid == MSGRNG_STNID_XMAC0RFR) {
+					Message
+					    ("Index %d, Phys Addr [%#llx] sent to Station XGMAC0",
+					     i,
+					     (unsigned long long) (addr &
+								   ~
+								   (SMP_CACHE_BYTES
+								    - 1)));
+					cnt[2]++;
+				} else if (stid == MSGRNG_STNID_XMAC1RFR) {
+					Message
+					    ("Index %d, Phys Addr [%#llx] sent to Station XGMAC1",
+					     i,
+					     (unsigned long long) (addr &
+								   ~
+								   (SMP_CACHE_BYTES
+								    - 1)));
+					cnt[3]++;
+				} else if (stid == MSGRNG_STNID_GMACRFR_0) {
+					Message
+					    ("Index %d Phys Addr [%#llx] sent to Station GMAC0",
+					     i,
+					     (unsigned long long) (addr &
+								   ~
+								   (SMP_CACHE_BYTES
+								    - 1)));
+					cnt[0]++;
+				} else if (stid == MSGRNG_STNID_GMAC1_FR) {
+					Message
+					    ("Index %d Phys Addr [%#llx] sent to Station GMAC1",
+					     i,
+					     (unsigned long long) (addr &
+								   ~
+								   (SMP_CACHE_BYTES
+								    - 1)));
+					cnt[1]++;
+
+				} else {
+					Message
+					    ("Index %d sent to unknown station!!! %d ",
+					     i, stid);
+				}
+				break;
+			}
+			printk
+			    ("[%s:%d]: retrying free_desc[%d] message send to stid=%d, [status gmac0=%d xmac0=%d xmac1=%d\n",
+			     __FUNCTION__, __LINE__, i, stid, cnt[0],
+			     cnt[2], cnt[3]);
+		} while (1);
+
+		phnx_inc_counter(USER_MAC_FRIN);
+	}
+	msgrng_flags_restore(mflags);
+	printk
+	    ("[%s]:...done[Free descriptors gmac0=%d gmac1=%d xgmac0=%d xgmac1=%d\n",
+	     __FUNCTION__, cnt[0], cnt[1], cnt[2], cnt[3]);
+
+	for (i = 0; i < 32; i++) {
+		user_mac->host_pkt_next_free[i] =
+		    MAX_USER_MAC_FRIN_PKTS + (i * host_gen_num_pkts);
+	}
+
+	for (i = MAX_USER_MAC_FRIN_PKTS; i < MAX_USER_MAC_PKTS; i++)
+		user_mac->pkt_desc[i].free = 1;
+
+	printk
+	    ("[%s]: packet_data[first].data=%llx, packet_data[last].data=%llx\n",
+	     __FUNCTION__, user_mac_vaddr_to_phys(&packet_data[0].data),
+	     user_mac_vaddr_to_phys(&packet_data[MAX_USER_MAC_PKTS - 1].
+				    data));
+}
+
+static void user_mac_send_frin_xgmac(void)
+{
+	struct msgrng_msg msg;
+	struct packet_data *packet_data = user_mac->pkt_data;
+	int i = 0;
+	unsigned long addr = 0, mflags = 0;
+	int stid = 0;
+	int cnt[2] = { 0, 0 };
+	int host_gen_num_pkts =
+	    (MAX_USER_MAC_PKTS - MAX_USER_MAC_FRIN_PKTS) / 32;
+
+	if (usermac_dev.xgmac_present == 0
+	    && usermac_dev.spi4_present == 0)
+		return;
+
+	msgrng_flags_save(mflags);
+
+	for (i = 0; i < MAX_USER_MAC_FRIN_PKTS; i++) {
+
+		stid = user_mac_send_frin_stid(i);
+
+		if (stid == MSGRNG_STNID_XMAC0RFR)
+			cnt[0]++;
+		else if (stid == MSGRNG_STNID_XMAC1RFR)
+			cnt[1]++;
+		else
+			continue;
+
+		addr = user_mac_vaddr_to_phys(&packet_data[i].data);
+		user_mac->pkt_desc[i].free = 0;
+
+		msg.msg0 = (uint64_t) addr & ~(SMP_CACHE_BYTES - 1);
+		msg.msg1 = msg.msg2 = msg.msg3 = 0;
+
+		do {
+			if (!message_send_retry
+			    (1, MSGRNG_CODE_MAC, stid, &msg))
+				break;
+			printk
+			    ("[%s:%d]: retrying free_desc[%d] message send to stid=%d\n",
+			     __FUNCTION__, __LINE__, i, stid);
+		} while (1);
+
+		phnx_inc_counter(USER_MAC_FRIN);
+	}
+	msgrng_flags_restore(mflags);
+	printk("[%s]:...done, Free descriptors xgmac0=%d xgmac1=%d\n",
+	       __FUNCTION__, cnt[0], cnt[1]);
+
+	for (i = 0; i < 32; i++) {
+		user_mac->host_pkt_next_free[i] =
+		    MAX_USER_MAC_FRIN_PKTS + (i * host_gen_num_pkts);
+	}
+
+	for (i = MAX_USER_MAC_FRIN_PKTS; i < MAX_USER_MAC_PKTS; i++)
+		user_mac->pkt_desc[i].free = 1;
+
+	printk
+	    ("[%s]: packet_data[first].data=%llx, packet_data[last].data=%llx\n",
+	     __FUNCTION__, user_mac_vaddr_to_phys(&packet_data[0].data),
+	     user_mac_vaddr_to_phys(&packet_data[MAX_USER_MAC_PKTS - 1].
+				    data));
+}
+
+struct xlr_cpu_stat {
+	unsigned long long msgring_pic_int;
+	unsigned long long msgring_int;
+	unsigned long long msgring_cycles;
+};
+static struct xlr_cpu_stat xlr_cpu_stats[32];
+
+void phoenix_cpu_stat_update_msgring_int(void)
+{
+	int cpu = hard_smp_processor_id();
+
+	xlr_cpu_stats[cpu].msgring_int++;
+}
+
+void phoenix_cpu_stat_update_msgring_cycles(__u32 cycles)
+{
+	int cpu = hard_smp_processor_id();
+
+	xlr_cpu_stats[cpu].msgring_cycles += cycles;
+}
+
+void phoenix_cpu_stat_update_msgring_pic_int(void)
+{
+	int cpu = hard_smp_processor_id();
+	xlr_cpu_stats[cpu].msgring_pic_int++;
+}
+
+void phoenix_user_mac_update_time(void)
+{
+	if (user_mac) {
+		user_mac->time.lo++;
+		if (!user_mac->time.lo)
+			user_mac->time.hi++;
+	}
+}
+
+void phoenix_user_mac_update_ktime(void)
+{
+	if (user_mac) {
+		user_mac->ktime = current_kernel_time();
+	}
+}
+
+static int user_mac_open(struct inode *inode, struct file *filp)
+{
+	//printk("user_mac_open() invoked\n");
+
+	filp->private_data = NULL;
+
+	return 0;
+}
+
+static int user_mac_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	unsigned long offset = vma->vm_pgoff << PAGE_SHIFT;
+	unsigned long long shm_addr = phoenix_psb_shm_paddr;
+	unsigned long shm_size = phoenix_psb_shm_size;
+	unsigned long size = 0;
+	unsigned long vm_size = vma->vm_end - vma->vm_start;
+
+	dbg_msg
+	    ("[%s]: shm_addr=%lx, shm_size=%lx, offset = %lx, vm_start=%lx, vm_size=%lx, vm_flags=%lx, "
+	     "vm_page_prot=%lx\n", __FUNCTION__, shm_addr, shm_size,
+	     offset, vma->vm_start, vm_size, vma->vm_flags,
+	     pgprot_val(vma->vm_page_prot));
+
+	if (vma->vm_start != (unsigned long) PHNX_USER_MAC_MMAP_VIRT_START)
+		return -EINVAL;
+
+	if (!shm_addr)
+		return -ENXIO;
+
+	if (offset >= shm_size)
+		return -ESPIPE;
+
+	if (vma->vm_flags & VM_LOCKED)
+		return -EPERM;
+
+	size = shm_size - offset;
+	if (vm_size > size)
+		return -ENOSPC;
+
+	vma->vm_flags |= (VM_RESERVED | VM_IO);
+
+	if (remap_pfn_range
+	    (vma, vma->vm_start, (shm_addr >> PAGE_SHIFT), size,
+	     vma->vm_page_prot))
+		return -EAGAIN;
+
+	return 0;
+}
+
+/*****************************************************************
+ * Initialize GMAC
+ *****************************************************************/
+static void rmi_usermac_config_pde(struct usermac_priv *priv)
+{
+	int i = 0, cpu = 0, bucket = 0;
+	__u64 bucket_map = 0;
+
+	for (i = 0; i < 32; i++) {
+		if (cpu_isset(i, cpu_online_map)) {
+			cpu = cpu_logical_map(i);
+			bucket = 4 + (((cpu >> 2) << 3) | (cpu & 0x03));
+			bucket_map |= (1ULL << bucket);
+			dbg_msg
+			    ("i=%d, cpu=%d, bucket = %d, bucket_map=%llx\n",
+			     i, cpu, bucket, bucket_map);
+		}
+	}
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_0,
+			  (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_0 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_1,
+			  (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_1 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_2,
+			  (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_2 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_3,
+			  (bucket_map & 0xffffffff));
+	phoenix_write_reg(priv->mmio, R_PDE_CLASS_3 + 1,
+			  ((bucket_map >> 32) & 0xffffffff));
+}
+
+static void rmi_usermac_config_parser(struct usermac_priv *priv)
+{
+	/* Mark it as no classification 
+	 * The parser extract is gauranteed to be zero with no classfication
+	 */
+
+	phoenix_write_reg(priv->mmio, R_L2TYPE_0, 0x01);
+
+	/* configure the parser : L2 Type is configured in the bootloader */
+	/* extract IP: src, dest protocol */
+	phoenix_write_reg(priv->mmio, R_L3CTABLE,
+			  (9 << 20) | (1 << 19) | (1 << 18) | (0x01 << 16)
+			  | (0x0800 << 0));
+	phoenix_write_reg(priv->mmio, R_L3CTABLE + 1,
+			  (12 << 25) | (4 << 21) | (16 << 14) | (4 << 10));
+
+	if (xlr_user_mac_l4_extract()) {
+		/* extract TCP: src port, dest port */
+		phoenix_write_reg(priv->mmio, R_L4CTABLE, (6 << 0));
+		phoenix_write_reg(priv->mmio, R_L4CTABLE + 1,
+				  (0 << 21) | (2 << 17) | (2 << 11) | (2 <<
+								       7));
+		/* extract UDP: src port, dest port */
+		phoenix_write_reg(priv->mmio, R_L4CTABLE + 2, (17 << 0));
+		phoenix_write_reg(priv->mmio, R_L4CTABLE + 3,
+				  (0 << 21) | (2 << 17) | (2 << 11) | (2 <<
+								       7));
+	}
+}
+
+static void rmi_usermac_port_enable(struct usermac_priv *priv, int flag)
+{
+	uint32_t regval;
+	int tx_threshold = 1518;
+
+
+	phoenix_write_reg(priv->mmio, R_MAC_FILTER_CONFIG,
+			  (1 << O_MAC_FILTER_CONFIG__BROADCAST_EN) |
+			  (1 << O_MAC_FILTER_CONFIG__ALL_MCAST_EN) |
+			  (1 << O_MAC_FILTER_CONFIG__ALL_UCAST_EN) |
+			  (1 << O_MAC_FILTER_CONFIG__MAC_ADDR0_VALID));
+
+
+	if (flag) {
+
+		regval = phoenix_read_reg(priv->mmio, R_TX_CONTROL);
+		regval |= (1 << O_TX_CONTROL__TxEnable) |
+		    (tx_threshold << O_TX_CONTROL__TxThreshold);
+
+		phoenix_write_reg(priv->mmio, R_TX_CONTROL, regval);
+
+		regval = phoenix_read_reg(priv->mmio, R_RX_CONTROL);
+		regval |= 1 << O_RX_CONTROL__RxEnable;
+		phoenix_write_reg(priv->mmio, R_RX_CONTROL, regval);
+
+		//      if(priv->type == TYPE_SPI4)
+		//spi4_enable_tx_rx((uint32_t *)priv->mmio);
+
+
+	} else {
+
+		//      if(priv->type == TYPE_SPI4)
+		//spi4_disable_tx_rx((uint32_t *)priv->mmio);
+
+		regval = phoenix_read_reg(priv->mmio, R_TX_CONTROL);
+		regval &= ~((1 << O_TX_CONTROL__TxEnable) |
+			    (tx_threshold << O_TX_CONTROL__TxThreshold));
+
+		phoenix_write_reg(priv->mmio, R_TX_CONTROL, regval);
+
+		regval = phoenix_read_reg(priv->mmio, R_RX_CONTROL);
+		regval &= ~(1 << O_RX_CONTROL__RxEnable);
+		phoenix_write_reg(priv->mmio, R_RX_CONTROL, regval);
+
+	}
+}
+
+#define CACHELINE_ALIGNED_ADDR(addr) (((unsigned long)(addr)) & ~(SMP_CACHE_BYTES-1))
+static __inline__ void *cacheline_aligned_kmalloc(int size, int gfp_mask)
+{
+	void *buf = kmalloc(size + SMP_CACHE_BYTES, gfp_mask);
+	if (buf)
+		buf =
+		    (void
+		     *) (CACHELINE_ALIGNED_ADDR((unsigned long) buf +
+						SMP_CACHE_BYTES));
+	return buf;
+}
+
+static __inline__ void *rmi_usermac_config_spill(phoenix_reg_t * mmio,
+						 int reg_start_0,
+						 int reg_start_1,
+						 int reg_size, int size)
+{
+	__u32 spill_size = CACHELINE_ALIGNED_ADDR(size);
+	void *spill = cacheline_aligned_kmalloc(spill_size, GFP_KERNEL);
+	__u64 phys_addr = 0;
+
+	if (!spill) {
+		panic("Unable to allocate memory for spill area!\n");
+	}
+	phys_addr = user_mac_vaddr_to_phys(spill);
+	phoenix_write_reg(mmio, reg_start_0,
+			  (phys_addr >> 5) & 0xffffffff);
+	phoenix_write_reg(mmio, reg_start_1, (phys_addr >> 37) & 0x07);
+	phoenix_write_reg(mmio, reg_size, spill_size);
+
+	return spill;
+}
+
+static void rmi_usermac_config_spill_area(struct usermac_priv *priv)
+{
+	/* */
+	int max_frin_spill = 0;
+	int max_frout_spill = 0;
+	int max_class_0_spill = 0;
+	int max_class_1_spill = 0;
+	int max_class_2_spill = 0;
+	int max_class_3_spill = 0;
+
+	if (!priv->num_desc)
+		return;
+
+	max_frin_spill = priv->num_desc << 2;
+	max_frout_spill = priv->num_desc << 2;
+
+	max_class_0_spill = priv->num_desc;
+	max_class_1_spill = priv->num_desc;
+	max_class_2_spill = priv->num_desc;
+	max_class_3_spill = priv->num_desc;
+
+
+	priv->frin_spill =
+	    rmi_usermac_config_spill(priv->mmio,
+				     R_REG_FRIN_SPILL_MEM_START_0,
+				     R_REG_FRIN_SPILL_MEM_START_1,
+				     R_REG_FRIN_SPILL_MEM_SIZE,
+				     max_frin_spill *
+				     sizeof(struct fr_desc));
+
+	priv->class_0_spill =
+	    rmi_usermac_config_spill(priv->mmio,
+				     R_CLASS0_SPILL_MEM_START_0,
+				     R_CLASS0_SPILL_MEM_START_1,
+				     R_CLASS0_SPILL_MEM_SIZE,
+				     max_class_0_spill *
+				     sizeof(union rx_tx_desc));
+	priv->class_1_spill =
+	    rmi_usermac_config_spill(priv->mmio,
+				     R_CLASS1_SPILL_MEM_START_0,
+				     R_CLASS1_SPILL_MEM_START_1,
+				     R_CLASS1_SPILL_MEM_SIZE,
+				     max_class_1_spill *
+				     sizeof(union rx_tx_desc));
+
+	priv->frout_spill =
+	    rmi_usermac_config_spill(priv->mmio, R_FROUT_SPILL_MEM_START_0,
+				     R_FROUT_SPILL_MEM_START_1,
+				     R_FROUT_SPILL_MEM_SIZE,
+				     max_frout_spill *
+				     sizeof(struct fr_desc));
+
+	priv->class_2_spill =
+	    rmi_usermac_config_spill(priv->mmio,
+				     R_CLASS2_SPILL_MEM_START_0,
+				     R_CLASS2_SPILL_MEM_START_1,
+				     R_CLASS2_SPILL_MEM_SIZE,
+				     max_class_2_spill *
+				     sizeof(union rx_tx_desc));
+	priv->class_3_spill =
+	    rmi_usermac_config_spill(priv->mmio,
+				     R_CLASS3_SPILL_MEM_START_0,
+				     R_CLASS3_SPILL_MEM_START_1,
+				     R_CLASS3_SPILL_MEM_SIZE,
+				     max_class_3_spill *
+				     sizeof(union rx_tx_desc));
+}
+
+
+/*Translate user space vaddr to page*/
+static struct page *user_vaddr_to_page(unsigned long addr,
+				       unsigned long size)
+{
+	pgd_t *pgd;
+	pud_t *pud;
+	pmd_t *pmd;
+	pte_t *pte = NULL;
+	pte_t pteval;
+	unsigned long pfn = 0;
+	struct mm_struct *mm = current->mm;
+	struct vm_area_struct *vma = NULL;
+
+	/*Check whether address falls in user space or not */
+	if (addr >= PAGE_OFFSET) {
+		printk("\nInvalid Userspace address\n");
+		return NULL;
+	}
+
+	/*Make sure addr doesn't overlap */
+	if (addr > (addr + size)) {
+		printk("\nAddress overlaps!!!\n");
+		return NULL;
+	}
+
+	/*Make sure address is already present in VMA */
+	vma = find_vma(mm, addr + size - 1);
+	if (!vma) {
+		printk("\nNo VMA found!!!\n");
+		return NULL;
+	}
+
+	if (vma->vm_start > addr) {
+		/*`addr` doesn't fall under vma */
+		printk("\nAddress doesn't fall under vma!!\n");
+		printk("\nvma_start = %#lx, vma_end = %#lx\n",
+		       vma->vm_start, vma->vm_end);
+		return NULL;
+	}
+#ifdef CONFIG_HUGETLBFS
+	if (!is_vm_hugetlb_page(vma))
+		return NULL;
+#else
+	return NULL;
+#endif
+	/*Acquire pagetable sem */
+	down_read(&mm->mmap_sem);
+	pgd = pgd_offset(mm, addr);
+	if (!pgd_none(*pgd)) {
+		pud = pud_offset(pgd, addr);
+		if (!pud_none(*pud)) {
+			pmd = pmd_offset(pud, addr);
+			if (!pmd_none(*pmd)) {
+				pte = pte_offset_map(pmd, addr);
+			}
+		}
+	}
+	/*Release pagetable sem */
+	up_read(&mm->mmap_sem);
+
+	if (!pte) {
+		printk("\nHugepage is not allocated yet\n");
+		return NULL;
+	}
+	pteval = *pte;
+	if (pte_none(pteval)) {
+		printk("\nPTE not allocated yet\n");
+		return NULL;
+	}
+	pfn = (pte_val(pteval) & 0xffffffffffULL) >> PAGE_SHIFT;
+	Message("User virt Addr [%#lx], PTE VAL [%#llx], pfn [%#lx]",
+		(unsigned long) addr, (unsigned long long) pte_val(pteval),
+		(unsigned long) pfn);
+	return pfn_to_page(pfn);
+}
+
+int user_mac_ioctl(struct inode *inode, struct file *filp,
+		   unsigned int cmd, unsigned long arg)
+{
+	extern struct net_device_cfg phnx_net_dev_cfg;
+	struct net_device_cfg *net_cfg = &phnx_net_dev_cfg;
+
+	switch (cmd) {
+	case USER_MAC_IOC_HUGETLB_SHM_VIRT_ADDR:{
+			__u64 *ptr = (__u64 *) arg;
+			__u64 user_vaddr;
+			__u64 user_vaddr_len;
+			int no_of_pages = 0;
+			int i = 0;
+
+			if (htlb_kvaddr)
+				/*Usermac memory already initialized */
+				return 0;
+
+			copy_from_user(&user_vaddr, ptr, sizeof(*ptr));
+			copy_from_user(&user_vaddr_len, ptr + 1,
+				       sizeof(*ptr));
+
+			if (user_vaddr_len < MB(8ULL)) {
+				printk
+				    ("\nCan't init usermac buffers with < 8MB buffer\n");
+				return -ENOMEM;
+			} else {
+				no_of_pages = MB(8ULL) / KB(4);
+				page_array = (struct page **) kmalloc
+				    (sizeof(struct page *) * (no_of_pages),
+				     GFP_KERNEL);
+				if (!page_array) {
+					printk
+					    ("\nCan't allocate memory for page_array\n");
+					return -ENOMEM;
+				}
+				Message
+				    ("User Space Virtual ADdress [%#lx]",
+				     (unsigned long) user_vaddr);
+				for (i = 0; i < no_of_pages;
+				     i++, user_vaddr += KB(4)) {
+					page_array[i] =
+					    user_vaddr_to_page((unsigned
+								long)
+							       user_vaddr,
+							       KB(4));
+					if (!page_array[i]) {
+						kfree(page_array);
+						printk
+						    ("\nuser_vaddr_to_page returned NULL!!\n");
+						return -ENOMEM;
+					}
+				}
+				/*vmap this page range in kernel address space */
+				htlb_kvaddr =
+				    vmap(page_array, no_of_pages, VM_MAP,
+					 PAGE_KERNEL);
+				if (!htlb_kvaddr) {
+					printk
+					    ("\nNot enough virtual address space available to map the hugepage in kernel\n");
+					kfree(page_array);
+					return -ENOMEM;
+				}
+				htlb_kpaddr =
+				    ((unsigned long long)
+				     vmalloc_to_pfn((const void *)
+						    htlb_kvaddr)) <<
+				    PAGE_SHIFT;
+				Message("HugeTlb Physical Address [%#llx]",
+					(unsigned long long) htlb_kpaddr);
+			}
+			phoenix_psb_shm = htlb_kvaddr;
+			/*Init user mac descriptors now!! */
+			user_mac_mem_init();
+		}
+		break;
+	case USER_MAC_IOC_EARLY_MEM_INIT:{
+			put_user((unsigned int) hybrid_mem_init,
+				 (unsigned int *) arg);
+		}
+		break;
+	case USER_MAC_IOC_GSHMPHYS:{
+			put_user((unsigned long long)
+				 phoenix_psb_shm_paddr,
+				 (unsigned long long *) arg);
+		}
+		break;
+
+	case USER_MAC_IOC_GSHMVIRT:{
+			put_user((unsigned long long) (unsigned long)
+				 phoenix_psb_shm,
+				 (unsigned long long *) arg);
+		}
+		break;
+
+	case USER_MAC_IOC_GSHMSIZE:{
+			put_user((unsigned int) phoenix_psb_shm_size,
+				 (unsigned int *) arg);
+		}
+		break;
+
+	case USER_MAC_IOC_GMMAP_START:{
+			put_user((unsigned int)
+				 PHNX_USER_MAC_MMAP_VIRT_START,
+				 (unsigned int *) arg);
+		}
+		break;
+
+	case USER_MAC_IOC_GREAD_REG:{
+			__u32 *ptr = (__u32 *) arg;
+			__u32 dev = 0, reg = 0, value = 0;
+			phoenix_reg_t *mmio = 0;
+
+			get_user(dev, ptr + 0);
+			get_user(reg, ptr + 1);
+
+			if (dev < 31)
+				mmio = usermac_dev.priv[dev].mmio;
+
+			if (mmio == NULL || (reg > (0x1000 >> 2))) {
+				printk
+				    ("[%s]: bad args, dev=0x%x, reg=0x%x\n",
+				     __FUNCTION__, dev, reg);
+				value = 0xdeadbeef;
+			} else {
+				printk("\nMMIO %#lx, REG %#lx\n",
+				       (unsigned long) mmio,
+				       (unsigned long) reg);
+				printk("\nReading @ Address %#lx-->%#x\n",
+				       (unsigned long) &mmio[reg],
+				       mmio[reg]);
+				value = phoenix_read_reg(mmio, reg);
+				dbg_msg
+				    ("[%s]: dev=0x%x, reg=0x%x, value=0x%x\n",
+				     __FUNCTION__, dev, reg, value);
+			}
+			put_user(value, ptr + 2);
+		}
+		break;
+
+	case USER_MAC_IOC_SWRITE_REG:{
+			__u32 *ptr = (__u32 *) arg;
+			__u32 dev = 0, reg = 0, value = 0;
+			phoenix_reg_t *mmio = 0;
+
+			get_user(dev, ptr + 0);
+			get_user(reg, ptr + 1);
+			get_user(value, ptr + 2);
+			if (dev < 31)
+				mmio = usermac_dev.priv[dev].mmio;
+			if (mmio == NULL || (reg > (0x1000 >> 2))) {
+				printk
+				    ("[%s]: bad args, dev=0x%x, reg=0x%x\n",
+				     __FUNCTION__, dev, reg);
+			} else {
+				dbg_msg
+				    ("[%s]: dev=0x%x, reg=0x%x, value=0x%x\n",
+				     __FUNCTION__, dev, reg, value);
+
+				phoenix_write_reg(mmio, reg, value);
+			}
+
+		}
+		break;
+
+	case USER_MAC_IOC_GPHYS_CPU_PRESENT_MAP:{
+			put_user((unsigned int) phys_cpu_present_map.
+				 bits[0], (unsigned int *) arg);
+		}
+		break;
+
+	case USER_MAC_IOC_GCPU_ONLINE_MAP:{
+			put_user((unsigned int) cpu_online_map.bits[0],
+				 (unsigned int *) arg);
+		}
+		break;
+	case USER_MAC_IOC_HYBRID_MODE_SETUP:{
+			if (xlr_hybrid_user_mac()) {
+				if (net_cfg->xgs_type[0] == TYPE_XGMAC
+				    || net_cfg->xgs_type[1] ==
+				    TYPE_XGMAC) {
+					/*ATX-II */
+					put_user((unsigned int)
+						 XLR_HYBRID_USER_MAC_GMAC_XGMAC,
+						 (unsigned int *) arg);
+				} else if (net_cfg->xgs_type[0] ==
+					   TYPE_SPI4
+					   || net_cfg->xgs_type[1] ==
+					   TYPE_SPI4) {
+					/*ATX-I */
+					put_user((unsigned int)
+						 XLR_HYBRID_USER_MAC_GMAC_SPI4,
+						 (unsigned int *) arg);
+				} else {
+					/*All remaining XLR and XLS boards. */
+					put_user((unsigned int)
+						 XLR_HYBRID_USER_MAC_GMAC,
+						 (unsigned int *) arg);
+				}
+			} else {
+				put_user((unsigned int) xlr_hybrid,
+					 (unsigned int *) arg);
+			}
+		}
+		break;
+	default:{
+			printk("ioctl(): invalid command=0x%x\n", cmd);
+			//return -EINVAL;
+			return 0;
+		}
+
+	}
+
+	return 0;
+}
+
+long user_mac_compat_ioctl(struct file *filp, unsigned int cmd,
+			   unsigned long arg)
+{
+	unsigned long ret = -1;
+	lock_kernel();
+	ret = user_mac_ioctl(NULL, filp, cmd, arg);
+	unlock_kernel();
+	if (ret) {
+		printk("user_mac_ioctl returned with an error.\n");
+		return -ENOIOCTLCMD;
+	}
+	return ret;
+}
+
+  // called only when the reference count (maintained in inode) is zero
+static int user_mac_release(struct inode *inode, struct file *filp)
+{
+
+	return 0;
+}
+
+struct file_operations user_mac_fops = {
+	.mmap = user_mac_mmap,
+	.open = user_mac_open,
+	.ioctl = user_mac_ioctl,
+	.compat_ioctl = user_mac_compat_ioctl,
+	.release = user_mac_release,
+};
+
+static int proc_read_count;
+
+extern unsigned long long phnx_tlb_stats[];
+extern void rmi_update_tlb_stats(void *ignored);
+
+extern unsigned long long nr_cpu_context_switches(int cpu);
+
+extern struct psb_info *prom_info;
+__u64 xlr_cp2_exceptions[32];
+static int xlr_cpu_proc_read(char *page, char **start, off_t off,
+			     int count, int *eof, void *data)
+{
+	int i = 0;
+	int len = 0;
+	off_t begin = 0;
+
+	/* Update the TLB stats from other CPUs */
+	on_each_cpu(rmi_update_tlb_stats, NULL, 1);
+
+	len += sprintf(page + len,
+		       "CPU Frequency: %d HZ\n",
+		       (unsigned int) prom_info->cpu_frequency);
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	for (i = 0; i < 32; i++) {
+
+		if (!xlr_cp2_exceptions[i])
+			continue;
+
+		len += sprintf(page + len,
+			       "cop2_exp: %d %d %d %llx\n",
+			       i, user_mac->time.hi, user_mac->time.lo,
+			       (unsigned long long) xlr_cp2_exceptions[i]);
+		if (!proc_pos_check(&begin, &len, off, count))
+			goto out;
+	}
+
+	for (i = 0; i < 32; i++) {
+
+		if (!xlr_cpu_stats[i].msgring_pic_int
+		    && !xlr_cpu_stats[i].msgring_int)
+			continue;
+
+		len += sprintf(page + len,
+			       "msgring: %d %d %d %llx %llx %llx\n",
+			       i, user_mac->time.hi, user_mac->time.lo,
+			       xlr_cpu_stats[i].msgring_pic_int,
+			       xlr_cpu_stats[i].msgring_int,
+			       xlr_cpu_stats[i].msgring_cycles);
+		if (!proc_pos_check(&begin, &len, off, count))
+			goto out;
+	}
+
+	for (i = 0; i < 32; i++) {
+
+		if (!phnx_tlb_stats[i])
+			continue;
+
+		len += sprintf(page + len,
+			       "tlb: %d %d %d %llx \n",
+			       i, user_mac->time.hi, user_mac->time.lo,
+			       phnx_tlb_stats[i]);
+		if (!proc_pos_check(&begin, &len, off, count))
+			goto out;
+	}
+
+	*eof = 1;
+
+      out:
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;
+}
+
+static int user_mac_proc_read(char *page, char **start, off_t off,
+			      int count, int *eof, void *data)
+{
+	int i = 0;
+	int len = 0;
+	off_t begin = 0;
+
+	proc_read_count++;
+	/* Update the TLB stats from other CPUs */
+	on_each_cpu(rmi_update_tlb_stats, NULL, 1);
+
+	len += sprintf(page + len,
+		       "\n*************** USER MAC STATISTICS ****************\n"
+		       "cpu_%d: proc_read_count = %d\n",
+		       smp_processor_id(), proc_read_count);
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	len +=
+	    sprintf(page + len,
+		    "\nshm_paddr=%llx, shm_size=%lx, mmap_virt_start=%x\n"
+		    "sizeof(user_mac_data)=0x%x\n", phoenix_psb_shm_paddr,
+		    phoenix_psb_shm_size, PHNX_USER_MAC_MMAP_VIRT_START,
+		    (unsigned int) sizeof(struct user_mac_data));
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	len += sprintf(page + len, "\nPer CPU TLB Stats: \n");
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	for (i = 0; i < 32; i++) {
+		if (!phnx_tlb_stats[i])
+			continue;
+
+		len +=
+		    sprintf(page + len,
+			    "cpu_%d: reg tlb = %llu.0 \n", i,
+			    phnx_tlb_stats[i]);
+		if (!proc_pos_check(&begin, &len, off, count))
+			goto out;
+	}
+
+	len +=
+	    sprintf(page + len,
+		    "\noffsetof(time)=0x%x, time.hi=%u, time.lo=%u\n",
+		    (unsigned int) offsetof(struct user_mac_data, time),
+		    (unsigned int) user_mac->time.hi,
+		    (unsigned int) user_mac->time.lo);
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	len += sprintf(page + len, "\n");
+	if (!proc_pos_check(&begin, &len, off, count))
+		goto out;
+
+	*eof = 1;
+
+      out:
+	*start = page + (off - begin);
+	len -= (off - begin);
+	if (len > count)
+		len = count;
+	if (len < 0)
+		len = 0;
+
+	return len;
+}
+
+struct xlr_user_mac_config xlr_user_mac;
+
+static int __init xlr_user_mac_setup(char *str)
+{
+	if ((strcmp(str, "=fast_syscall") == 0)
+	    || (strcmp(str, "fast_syscall") == 0)) {
+		xlr_user_mac.fast_syscall = 1;
+		printk("XLR: user_mac configured with fast syscalls\n");
+	} else {
+		printk
+		    ("XLR: user_mac configured with unknown args \"%s\"\n",
+		     str);
+	}
+
+	return 1;
+}
+
+early_param("xlr_user_mac", xlr_user_mac_setup);
+
+static void user_mac_mem_init(void)
+{
+	int i = 0;
+	static int init_mem = 0;
+
+	if (init_mem) {
+		printk("\nUser Mac Memory is already initialized\n");
+		return;
+	}
+
+	user_mac = (struct user_mac_data *) phoenix_psb_shm;
+	if (!user_mac) {
+		printk("[%s]: Null Shared Memory Pointer?\n",
+		       __FUNCTION__);
+		printk("\nInvalid user mac shared memory !!\n");
+		return;
+	}
+	printk("\nUserMac Data structures Starts @ %#lx\n",
+	       (unsigned long) phoenix_psb_shm);
+	if (sizeof(struct user_mac_data) > phoenix_psb_shm_size) {
+		printk
+		    ("[%s]: psb shared memory is too small: user_mac_data=0x%x, psb_shm_size=0x%lx\n",
+		     __FUNCTION__,
+		     (unsigned int) sizeof(struct user_mac_data),
+		     (unsigned long) phoenix_psb_shm_size);
+		printk("User Mac Memory initialization failed!!\n");
+		return;
+	}
+
+	for (i = 0; i < MAX_USER_MAC_PKTS; i++)
+		user_mac->pkt_desc[i].free = 1;
+
+	if (htlb_kpaddr) {
+		phoenix_psb_shm_paddr = htlb_kpaddr;
+	} else {
+		phoenix_psb_shm_paddr =
+		    user_mac_vaddr_to_phys(phoenix_psb_shm);
+	}
+
+	if (xlr_hybrid_user_mac()) {
+		Message("Calling User Mac Send FRIN ");
+		user_mac_send_frin();
+	} else if (xlr_hybrid_user_mac_xgmac())
+		user_mac_send_frin_xgmac();
+
+	for (i = 0; i < PHOENIX_MAX_MACS; i++) {
+		if (usermac_dev.priv[i].mmio != 0)
+			rmi_usermac_port_enable(&usermac_dev.priv[i], 1);
+	}
+	init_mem = 1;
+	return;
+}
+
+
+#ifdef CONFIG_HUGETLBFS
+static int __init xlr_hybrid_early_init(char *str)
+{
+	if (HPAGE_SIZE < MB(8)) {
+		printk
+		    ("Hugetlb user mac is not supported with < 8MB huge page size\n");
+		return 0;
+	}
+	if (strcmp(str, "no") == 0) {
+		hybrid_mem_init = 0;
+	}
+	return 0;
+}
+
+early_param("xlr_hybrid_early_init", xlr_hybrid_early_init);
+#endif
+
+static int user_mac_init(void)
+{
+	int i = 0, next = 0;
+	struct proc_dir_entry *entry;
+	extern struct net_device_cfg phnx_net_dev_cfg;
+	struct net_device_cfg *net_cfg = &phnx_net_dev_cfg;
+
+	usermac_dev.gmac_list = 0;
+	usermac_dev.xgmac_present = 0;
+	usermac_dev.spi4_present = 0;
+
+	/* if support for loading apps on same core as Linux is enabled */
+	if (xlr_loader_support && xlr_loader_sharedcore)
+		return -EINVAL;
+
+	if (xlr_hybrid_user_mac()) {
+		for (i = 0; i < PHOENIX_MAX_GMACS; i++) {
+			if (net_cfg->gmac_port[i].mmio_addr == 0
+			    || net_cfg->gmac_port[i].cfg_flag == 0)
+				continue;
+			usermac_dev.gmac_list |= (1 << i);
+			usermac_dev.priv[i].mmio =
+			    (void *) net_cfg->gmac_port[i].mmio_addr;
+			usermac_dev.priv[i].type = TYPE_GMAC;
+
+			/* Need to call only once, num_desc will be nonzero for only the first
+			   port of every gmac block */
+			if (net_cfg->gmac_port[i].num_desc != 0) {
+				usermac_dev.priv[i].num_desc =
+				    MAX_USER_MAC_FRIN_PKTS;
+				rmi_usermac_config_spill_area(&usermac_dev.
+							      priv[i]);
+				rmi_usermac_config_parser(&usermac_dev.
+							  priv[i]);
+				rmi_usermac_config_pde(&usermac_dev.
+						       priv[i]);
+			}
+			next = i + 1;
+		}
+		if (usermac_dev.gmac_list == 0)
+			printk
+			    ("Skipping usermac configuration on gmac ports..\n");
+	}
+
+	if (xlr_hybrid_user_mac() || xlr_hybrid_user_mac_xgmac()) {
+		for (i = 0; i < PHOENIX_MAX_XGMACS; i++) {
+			if (net_cfg->xgs_port[i].mmio_addr == 0
+			    || net_cfg->xgs_port[i].cfg_flag == 0)
+				continue;
+			if (net_cfg->xgs_type[i] == TYPE_XGMAC)
+				usermac_dev.xgmac_present |= (1 << i);
+			else
+				usermac_dev.spi4_present |= (1 << i);
+			usermac_dev.priv[next + i].mmio =
+			    (void *) net_cfg->xgs_port[i].mmio_addr;
+			usermac_dev.priv[next + i].type =
+			    net_cfg->xgs_type[i];
+			usermac_dev.priv[next + i].num_desc =
+			    MAX_USER_MAC_FRIN_PKTS;
+			rmi_usermac_config_spill_area(&usermac_dev.
+						      priv[next + i]);
+			rmi_usermac_config_parser(&usermac_dev.
+						  priv[next + i]);
+			rmi_usermac_config_pde(&usermac_dev.
+					       priv[next + i]);
+		}
+		if (usermac_dev.xgmac_present == 0
+		    && usermac_dev.spi4_present == 0)
+			printk
+			    ("Skipping usermac configuration on xgmac ports..\n");
+	}
+
+	if (usermac_dev.gmac_list != 0 || usermac_dev.xgmac_present != 0 ||
+	    usermac_dev.spi4_present != 0) {
+		user_mac_major =
+		    register_chrdev(XLR_USER_MAC_MAJOR,
+				    PHNX_USER_MAC_CHRDEV_NAME,
+				    &user_mac_fops);
+		if (user_mac_major < 0) {
+			printk
+			    ("user_mac_init() register_chrdev() failed\n");
+			return user_mac_major;
+		}
+		printk("Registered user_mac driver: major=%d\n",
+		       XLR_USER_MAC_MAJOR);
+	}
+
+	entry =
+	    create_proc_read_entry(PHNX_USER_MAC_CHRDEV_NAME,
+				   0 /* def mode */ ,
+				   rmi_root_proc /* parent directory */ ,
+				   user_mac_proc_read
+				   /* proc read function */ ,
+				   0	/* no client data */
+	    );
+
+	if (!entry) {
+		printk("[%s]: Unable to create proc read entry for %s!\n",
+		       __FUNCTION__, PHNX_USER_MAC_CHRDEV_NAME);
+	}
+
+	entry = create_proc_read_entry("xlr_cpu", 0 /* def mode */ ,
+				       rmi_root_proc /* parent directory */
+				       ,
+				       xlr_cpu_proc_read
+				       /* proc read function */ ,
+				       0	/* no client data */
+	    );
+
+	if (!entry) {
+		printk
+		    ("[%s]: Unable to create proc read entry for xlr_cpu!\n",
+		     __FUNCTION__);
+	}
+
+
+	if (hybrid_mem_init) {
+		user_mac_mem_init();
+		return 0;
+	}
+	printk("Memory init for hybrid mode is not done.\n");
+	return 0;
+}
+
+static void user_mac_exit(void)
+{
+	unregister_chrdev(user_mac_major, PHNX_USER_MAC_CHRDEV_NAME);
+}
+
+static void user_mac_mem(void)
+{
+	phoenix_psb_shm = alloc_bootmem_low(PHNX_USER_MAC_SIZE);
+	phoenix_psb_shm_size = PHNX_USER_MAC_SIZE;
+}
+
+module_init(user_mac_init);
+console_initcall(user_mac_mem);
+module_exit(user_mac_exit);
diff --git a/include/asm-mips/rmi/phoenix_mac.h b/include/asm-mips/rmi/phoenix_mac.h
new file mode 100644
index 0000000..3be5acc
--- /dev/null
+++ b/include/asm-mips/rmi/phoenix_mac.h
@@ -0,0 +1,1163 @@
+/*********************************************************************
+
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef _ASM_RMI_MAC_H
+#define _ASM_RMI_MAC_H
+
+#include <linux/types.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/iomap.h>
+#include <linux/skbuff.h>
+#include <asm/rmi/phoenix_sec.h>
+#include <asm/rmi/config_net.h>
+
+#define IPSEC_PACKET_PAYLOAD_SIZE 1696
+#define PHXSEC_HMAC_LENGTH 64
+#define SKBUF_HEAD (32 * 2)    // 2 cachelines reserved before payload
+
+//#define MAC_SPLIT_MODE
+
+#define MAC_SPACING                 0x400
+#define XGMAC_SPACING               0x400
+
+/* PE-MCXMAC register and bit field definitions */
+#define R_MAC_CONFIG_1                                              0x00
+#define   O_MAC_CONFIG_1__srst                                      31
+#define   O_MAC_CONFIG_1__simr                                      30
+#define   O_MAC_CONFIG_1__hrrmc                                     18
+#define   W_MAC_CONFIG_1__hrtmc                                      2
+#define   O_MAC_CONFIG_1__hrrfn                                     16
+#define   W_MAC_CONFIG_1__hrtfn                                      2
+#define   O_MAC_CONFIG_1__intlb                                      8
+#define   O_MAC_CONFIG_1__rxfc                                       5
+#define   O_MAC_CONFIG_1__txfc                                       4
+#define   O_MAC_CONFIG_1__srxen                                      3
+#define   O_MAC_CONFIG_1__rxen                                       2
+#define   O_MAC_CONFIG_1__stxen                                      1
+#define   O_MAC_CONFIG_1__txen                                       0
+#define R_MAC_CONFIG_2                                              0x01
+#define   O_MAC_CONFIG_2__prlen                                     12
+#define   W_MAC_CONFIG_2__prlen                                      4
+#define   O_MAC_CONFIG_2__speed                                      8
+#define   W_MAC_CONFIG_2__speed                                      2
+#define   O_MAC_CONFIG_2__hugen                                      5
+#define   O_MAC_CONFIG_2__flchk                                      4
+#define   O_MAC_CONFIG_2__crce                                       1
+#define   O_MAC_CONFIG_2__fulld                                      0
+#define R_IPG_IFG                                                   0x02
+#define   O_IPG_IFG__ipgr1                                          24
+#define   W_IPG_IFG__ipgr1                                           7
+#define   O_IPG_IFG__ipgr2                                          16
+#define   W_IPG_IFG__ipgr2                                           7
+#define   O_IPG_IFG__mifg                                            8
+#define   W_IPG_IFG__mifg                                            8
+#define   O_IPG_IFG__ipgt                                            0
+#define   W_IPG_IFG__ipgt                                            7
+#define R_HALF_DUPLEX                                               0x03
+#define   O_HALF_DUPLEX__abebt                                      24
+#define   W_HALF_DUPLEX__abebt                                       4
+#define   O_HALF_DUPLEX__abebe                                      19
+#define   O_HALF_DUPLEX__bpnb                                       18
+#define   O_HALF_DUPLEX__nobo                                       17
+#define   O_HALF_DUPLEX__edxsdfr                                    16
+#define   O_HALF_DUPLEX__retry                                      12
+#define   W_HALF_DUPLEX__retry                                       4
+#define   O_HALF_DUPLEX__lcol                                        0
+#define   W_HALF_DUPLEX__lcol                                       10
+#define R_MAXIMUM_FRAME_LENGTH                                      0x04
+#define   O_MAXIMUM_FRAME_LENGTH__maxf                               0
+#define   W_MAXIMUM_FRAME_LENGTH__maxf                              16
+#define R_TEST                                                      0x07
+#define   O_TEST__mbof                                               3
+#define   O_TEST__rthdf                                              2
+#define   O_TEST__tpause                                             1
+#define   O_TEST__sstct                                              0
+#define R_MII_MGMT_CONFIG                                           0x08
+#define   O_MII_MGMT_CONFIG__scinc                                   5
+#define   O_MII_MGMT_CONFIG__spre                                    4
+#define   O_MII_MGMT_CONFIG__clks                                    3
+#define   W_MII_MGMT_CONFIG__clks                                    3
+#define R_MII_MGMT_COMMAND                                          0x09
+#define   O_MII_MGMT_COMMAND__scan                                   1
+#define   O_MII_MGMT_COMMAND__rstat                                  0
+#define R_MII_MGMT_ADDRESS                                          0x0A
+#define   O_MII_MGMT_ADDRESS__fiad                                   8
+#define   W_MII_MGMT_ADDRESS__fiad                                   5
+#define   O_MII_MGMT_ADDRESS__fgad                                   5
+#define   W_MII_MGMT_ADDRESS__fgad                                   0
+#define R_MII_MGMT_WRITE_DATA                                       0x0B
+#define   O_MII_MGMT_WRITE_DATA__ctld                                0
+#define   W_MII_MGMT_WRITE_DATA__ctld                               16
+#define R_MII_MGMT_STATUS                                           0x0C
+#define R_MII_MGMT_INDICATORS                                       0x0D
+#define   O_MII_MGMT_INDICATORS__nvalid                              2
+#define   O_MII_MGMT_INDICATORS__scan                                1
+#define   O_MII_MGMT_INDICATORS__busy                                0
+#define R_INTERFACE_CONTROL                                         0x0E
+#define   O_INTERFACE_CONTROL__hrstint                              31
+#define   O_INTERFACE_CONTROL__tbimode                              27
+#define   O_INTERFACE_CONTROL__ghdmode                              26
+#define   O_INTERFACE_CONTROL__lhdmode                              25
+#define   O_INTERFACE_CONTROL__phymod                               24
+#define   O_INTERFACE_CONTROL__hrrmi                                23
+#define   O_INTERFACE_CONTROL__rspd                                 16
+#define   O_INTERFACE_CONTROL__hr100                                15
+#define   O_INTERFACE_CONTROL__frcq                                 10
+#define   O_INTERFACE_CONTROL__nocfr                                 9
+#define   O_INTERFACE_CONTROL__dlfct                                 8
+#define   O_INTERFACE_CONTROL__enjab                                 0
+#define R_INTERFACE_STATUS                                         0x0F
+#define   O_INTERFACE_STATUS__xsdfr                                  9
+#define   O_INTERFACE_STATUS__ssrr                                   8
+#define   W_INTERFACE_STATUS__ssrr                                   5
+#define   O_INTERFACE_STATUS__miilf                                  3
+#define   O_INTERFACE_STATUS__locar                                  2
+#define   O_INTERFACE_STATUS__sqerr                                  1
+#define   O_INTERFACE_STATUS__jabber                                 0
+#define R_STATION_ADDRESS_LS                                       0x10
+#define R_STATION_ADDRESS_MS                                       0x11
+
+/* A-XGMAC register and bit field definitions */
+#define R_XGMAC_CONFIG_0    0x00
+#define   O_XGMAC_CONFIG_0__hstmacrst               31
+#define   O_XGMAC_CONFIG_0__hstrstrctl              23
+#define   O_XGMAC_CONFIG_0__hstrstrfn               22
+#define   O_XGMAC_CONFIG_0__hstrsttctl              18
+#define   O_XGMAC_CONFIG_0__hstrsttfn               17
+#define   O_XGMAC_CONFIG_0__hstrstmiim              16
+#define   O_XGMAC_CONFIG_0__hstloopback             8
+#define R_XGMAC_CONFIG_1    0x01
+#define   O_XGMAC_CONFIG_1__hsttctlen               31
+#define   O_XGMAC_CONFIG_1__hsttfen                 30
+#define   O_XGMAC_CONFIG_1__hstrctlen               29
+#define   O_XGMAC_CONFIG_1__hstrfen                 28
+#define   O_XGMAC_CONFIG_1__tfen                    26
+#define   O_XGMAC_CONFIG_1__rfen                    24
+#define   O_XGMAC_CONFIG_1__hstrctlshrtp            12
+#define   O_XGMAC_CONFIG_1__hstdlyfcstx             10
+#define   W_XGMAC_CONFIG_1__hstdlyfcstx              2
+#define   O_XGMAC_CONFIG_1__hstdlyfcsrx              8
+#define   W_XGMAC_CONFIG_1__hstdlyfcsrx              2
+#define   O_XGMAC_CONFIG_1__hstppen                  7
+#define   O_XGMAC_CONFIG_1__hstbytswp                6
+#define   O_XGMAC_CONFIG_1__hstdrplt64               5
+#define   O_XGMAC_CONFIG_1__hstprmscrx               4
+#define   O_XGMAC_CONFIG_1__hstlenchk                3
+#define   O_XGMAC_CONFIG_1__hstgenfcs                2
+#define   O_XGMAC_CONFIG_1__hstpadmode               0
+#define   W_XGMAC_CONFIG_1__hstpadmode               2
+#define R_XGMAC_CONFIG_2    0x02
+#define   O_XGMAC_CONFIG_2__hsttctlfrcp             31
+#define   O_XGMAC_CONFIG_2__hstmlnkflth             27
+#define   O_XGMAC_CONFIG_2__hstalnkflth             26
+#define   O_XGMAC_CONFIG_2__rflnkflt                24
+#define   W_XGMAC_CONFIG_2__rflnkflt                 2                          
+#define   O_XGMAC_CONFIG_2__hstipgextmod            16
+#define   W_XGMAC_CONFIG_2__hstipgextmod             5
+#define   O_XGMAC_CONFIG_2__hstrctlfrcp             15
+#define   O_XGMAC_CONFIG_2__hstipgexten              5
+#define   O_XGMAC_CONFIG_2__hstmipgext               0
+#define   W_XGMAC_CONFIG_2__hstmipgext               5
+#define R_XGMAC_CONFIG_3    0x03
+#define   O_XGMAC_CONFIG_3__hstfltrfrm              31
+#define   W_XGMAC_CONFIG_3__hstfltrfrm              16
+#define   O_XGMAC_CONFIG_3__hstfltrfrmdc            15
+#define   W_XGMAC_CONFIG_3__hstfltrfrmdc            16
+#define R_XGMAC_STATION_ADDRESS_LS      0x04
+#define   O_XGMAC_STATION_ADDRESS_LS__hstmacadr0    0
+#define   W_XGMAC_STATION_ADDRESS_LS__hstmacadr0    32
+#define R_XGMAC_STATION_ADDRESS_MS      0x05
+#define R_XGMAC_MAX_FRAME_LEN           0x08
+#define   O_XGMAC_MAX_FRAME_LEN__hstmxfrmwctx       16
+#define   W_XGMAC_MAX_FRAME_LEN__hstmxfrmwctx       14
+#define   O_XGMAC_MAX_FRAME_LEN__hstmxfrmbcrx        0
+#define   W_XGMAC_MAX_FRAME_LEN__hstmxfrmbcrx       16
+#define R_XGMAC_REV_LEVEL               0x0B
+#define   O_XGMAC_REV_LEVEL__revlvl                  0
+#define   W_XGMAC_REV_LEVEL__revlvl                 15
+#define R_XGMAC_MIIM_COMMAND            0x10
+#define   O_XGMAC_MIIM_COMMAND__hstldcmd             3
+#define   O_XGMAC_MIIM_COMMAND__hstmiimcmd           0
+#define   W_XGMAC_MIIM_COMMAND__hstmiimcmd           3
+#define R_XGMAC_MIIM_FILED              0x11
+#define   O_XGMAC_MIIM_FILED__hststfield            30
+#define   W_XGMAC_MIIM_FILED__hststfield             2
+#define   O_XGMAC_MIIM_FILED__hstopfield            28
+#define   W_XGMAC_MIIM_FILED__hstopfield             2
+#define   O_XGMAC_MIIM_FILED__hstphyadx             23
+#define   W_XGMAC_MIIM_FILED__hstphyadx              5
+#define   O_XGMAC_MIIM_FILED__hstregadx             18
+#define   W_XGMAC_MIIM_FILED__hstregadx              5
+#define   O_XGMAC_MIIM_FILED__hsttafield            16
+#define   W_XGMAC_MIIM_FILED__hsttafield             2
+#define   O_XGMAC_MIIM_FILED__miimrddat              0
+#define   W_XGMAC_MIIM_FILED__miimrddat             16
+#define R_XGMAC_MIIM_CONFIG             0x12
+#define   O_XGMAC_MIIM_CONFIG__hstnopram             7
+#define   O_XGMAC_MIIM_CONFIG__hstclkdiv             0
+#define   W_XGMAC_MIIM_CONFIG__hstclkdiv             7
+#define R_XGMAC_MIIM_LINK_FAIL_VECTOR   0x13
+#define   O_XGMAC_MIIM_LINK_FAIL_VECTOR__miimlfvec   0
+#define   W_XGMAC_MIIM_LINK_FAIL_VECTOR__miimlfvec  32
+#define R_XGMAC_MIIM_INDICATOR          0x14
+#define   O_XGMAC_MIIM_INDICATOR__miimphylf          4
+#define   O_XGMAC_MIIM_INDICATOR__miimmoncplt        3
+#define   O_XGMAC_MIIM_INDICATOR__miimmonvld         2
+#define   O_XGMAC_MIIM_INDICATOR__miimmon            1
+#define   O_XGMAC_MIIM_INDICATOR__miimbusy           0
+
+/* Glue logic register and bit field definitions */
+#define R_MAC_ADDR0                                                 0x50
+#define R_MAC_ADDR1                                                 0x52
+#define R_MAC_ADDR2                                                 0x54
+#define R_MAC_ADDR3                                                 0x56
+#define R_MAC_ADDR_MASK2                                            0x58
+#define R_MAC_ADDR_MASK3                                            0x5A
+#define R_MAC_FILTER_CONFIG                                         0x5C
+#define   O_MAC_FILTER_CONFIG__BROADCAST_EN                         10
+#define   O_MAC_FILTER_CONFIG__PAUSE_FRAME_EN                       9
+#define   O_MAC_FILTER_CONFIG__ALL_MCAST_EN                         8
+#define   O_MAC_FILTER_CONFIG__ALL_UCAST_EN                         7
+#define   O_MAC_FILTER_CONFIG__HASH_MCAST_EN                        6
+#define   O_MAC_FILTER_CONFIG__HASH_UCAST_EN                        5
+#define   O_MAC_FILTER_CONFIG__ADDR_MATCH_DISC                      4
+#define   O_MAC_FILTER_CONFIG__MAC_ADDR3_VALID                      3
+#define   O_MAC_FILTER_CONFIG__MAC_ADDR2_VALID                      2
+#define   O_MAC_FILTER_CONFIG__MAC_ADDR1_VALID                      1
+#define   O_MAC_FILTER_CONFIG__MAC_ADDR0_VALID                      0
+#define R_HASH_TABLE_VECTOR                                         0x30
+#define R_TX_CONTROL                                                 0x0A0
+#define   O_TX_CONTROL__Tx15Halt                                     31
+#define   O_TX_CONTROL__Tx14Halt                                     30
+#define   O_TX_CONTROL__Tx13Halt                                     29
+#define   O_TX_CONTROL__Tx12Halt                                     28
+#define   O_TX_CONTROL__Tx11Halt                                     27
+#define   O_TX_CONTROL__Tx10Halt                                     26
+#define   O_TX_CONTROL__Tx9Halt                                      25
+#define   O_TX_CONTROL__Tx8Halt                                      24
+#define   O_TX_CONTROL__Tx7Halt                                      23
+#define   O_TX_CONTROL__Tx6Halt                                      22
+#define   O_TX_CONTROL__Tx5Halt                                      21
+#define   O_TX_CONTROL__Tx4Halt                                      20
+#define   O_TX_CONTROL__Tx3Halt                                      19
+#define   O_TX_CONTROL__Tx2Halt                                      18
+#define   O_TX_CONTROL__Tx1Halt                                      17
+#define   O_TX_CONTROL__Tx0Halt                                      16
+#define   O_TX_CONTROL__TxIdle                                       15
+#define   O_TX_CONTROL__TxEnable                                     14
+#define   O_TX_CONTROL__TxThreshold                                  0
+#define   W_TX_CONTROL__TxThreshold                                  14
+#define R_RX_CONTROL                                                 0x0A1
+#define   O_RX_1588_TS                                               11
+#define   O_RX_CONTROL__RGMII                                        10
+#define   O_RX_CONTROL__RxHalt                                       1
+#define   O_RX_CONTROL__RxEnable                                     0
+#define R_DESC_PACK_CTRL                                            0x0A2
+#define   O_DESC_PACK_CTRL__ByteOffset                              17
+#define   W_DESC_PACK_CTRL__ByteOffset                              3
+#define   O_DESC_PACK_CTRL__PrePadEnable                            16
+#define   O_DESC_PACK_CTRL__MaxEntry                                14
+#define   W_DESC_PACK_CTRL__MaxEntry                                2
+#define   O_DESC_PACK_CTRL__RegularSize                             0
+#define   W_DESC_PACK_CTRL__RegularSize                             14
+#define R_STATCTRL                                                  0x0A3
+#define   O_STATCTRL__OverFlowEn                                    4
+#define   O_STATCTRL__GIG                                           3
+#define   O_STATCTRL__Sten                                          2
+#define   O_STATCTRL__ClrCnt                                        1
+#define   O_STATCTRL__AutoZ                                         0
+#define R_L2ALLOCCTRL                                               0x0A4
+#define   O_L2ALLOCCTRL__TxL2Allocate                               9
+#define   W_L2ALLOCCTRL__TxL2Allocate                               9
+#define   O_L2ALLOCCTRL__RxL2Allocate                               0
+#define   W_L2ALLOCCTRL__RxL2Allocate                               9
+#define R_INTMASK                                                   0x0A5
+#define   O_INTMASK__Spi4TxError                                     28
+#define   O_INTMASK__Spi4RxError                                     27
+#define   O_INTMASK__RGMIIHalfDupCollision                           27
+#define   O_INTMASK__Abort                                           26
+#define   O_INTMASK__Underrun                                        25
+#define   O_INTMASK__DiscardPacket                                   24
+#define   O_INTMASK__AsyncFifoFull                                   23
+#define   O_INTMASK__TagFull                                         22
+#define   O_INTMASK__Class3Full                                      21
+#define   O_INTMASK__C3EarlyFull                                     20
+#define   O_INTMASK__Class2Full                                      19
+#define   O_INTMASK__C2EarlyFull                                     18
+#define   O_INTMASK__Class1Full                                      17
+#define   O_INTMASK__C1EarlyFull                                     16
+#define   O_INTMASK__Class0Full                                      15
+#define   O_INTMASK__C0EarlyFull                                     14
+#define   O_INTMASK__RxDataFull                                      13
+#define   O_INTMASK__RxEarlyFull                                     12
+#define   O_INTMASK__RFreeEmpty                                      9
+#define   O_INTMASK__RFEarlyEmpty                                    8
+#define   O_INTMASK__P2PSpillEcc                                     7
+#define   O_INTMASK__FreeDescFull                                    5
+#define   O_INTMASK__FreeEarlyFull                                   4
+#define   O_INTMASK__TxFetchError                                    3
+#define   O_INTMASK__StatCarry                                       2
+#define   O_INTMASK__MDInt                                           1
+#define   O_INTMASK__TxIllegal                                       0
+#define R_INTREG                                                    0x0A6
+#define   O_INTREG__Spi4TxError                                     28
+#define   O_INTREG__Spi4RxError                                     27
+#define   O_INTREG__RGMIIHalfDupCollision                           27
+#define   O_INTREG__Abort                                           26
+#define   O_INTREG__Underrun                                        25
+#define   O_INTREG__DiscardPacket                                   24
+#define   O_INTREG__AsyncFifoFull                                   23
+#define   O_INTREG__TagFull                                         22
+#define   O_INTREG__Class3Full                                      21
+#define   O_INTREG__C3EarlyFull                                     20
+#define   O_INTREG__Class2Full                                      19
+#define   O_INTREG__C2EarlyFull                                     18
+#define   O_INTREG__Class1Full                                      17
+#define   O_INTREG__C1EarlyFull                                     16
+#define   O_INTREG__Class0Full                                      15
+#define   O_INTREG__C0EarlyFull                                     14
+#define   O_INTREG__RxDataFull                                      13
+#define   O_INTREG__RxEarlyFull                                     12
+#define   O_INTREG__RFreeEmpty                                      9
+#define   O_INTREG__RFEarlyEmpty                                    8
+#define   O_INTREG__P2PSpillEcc                                     7
+#define   O_INTREG__FreeDescFull                                    5
+#define   O_INTREG__FreeEarlyFull                                   4
+#define   O_INTREG__TxFetchError                                    3
+#define   O_INTREG__StatCarry                                       2
+#define   O_INTREG__MDInt                                           1
+#define   O_INTREG__TxIllegal                                       0
+#define R_TXRETRY                                                   0x0A7
+#define   O_TXRETRY__CollisionRetry                                 6
+#define   O_TXRETRY__BusErrorRetry                                  5
+#define   O_TXRETRY__UnderRunRetry                                  4
+#define   O_TXRETRY__Retries                                        0
+#define   W_TXRETRY__Retries                                        4
+#define R_CORECONTROL                                               0x0A8
+#define   O_CORECONTROL__ErrorThread                                4
+#define   W_CORECONTROL__ErrorThread                                7
+#define   O_CORECONTROL__Shutdown                                   2
+#define   O_CORECONTROL__Speed                                      0
+#define   W_CORECONTROL__Speed                                      2
+#define R_BYTEOFFSET0                                               0x0A9
+#define R_BYTEOFFSET1                                               0x0AA
+#define R_L2TYPE_0                                                  0x0F0
+#define   O_L2TYPE__ExtraHdrProtoSize                               26
+#define   W_L2TYPE__ExtraHdrProtoSize                               5
+#define   O_L2TYPE__ExtraHdrProtoOffset                             20
+#define   W_L2TYPE__ExtraHdrProtoOffset                             6
+#define   O_L2TYPE__ExtraHeaderSize                                 14
+#define   W_L2TYPE__ExtraHeaderSize                                 6
+#define   O_L2TYPE__ProtoOffset                                     8
+#define   W_L2TYPE__ProtoOffset                                     6
+#define   O_L2TYPE__L2HdrOffset                                     2
+#define   W_L2TYPE__L2HdrOffset                                     6
+#define   O_L2TYPE__L2Proto                                         0
+#define   W_L2TYPE__L2Proto                                         2
+#define R_L2TYPE_1                                                  0xF0
+#define R_L2TYPE_2                                                  0xF0
+#define R_L2TYPE_3                                                  0xF0
+#define R_PARSERCONFIGREG                                           0x100
+#define   O_PARSERCONFIGREG__CRCHashPoly                            8
+#define   W_PARSERCONFIGREG__CRCHashPoly                            7
+#define   O_PARSERCONFIGREG__PrePadOffset                           4
+#define   W_PARSERCONFIGREG__PrePadOffset                           4
+#define   O_PARSERCONFIGREG__UseCAM                                 2
+#define   O_PARSERCONFIGREG__UseHASH                                1
+#define   O_PARSERCONFIGREG__UseProto                               0
+#define R_L3CTABLE                                                  0x140
+#define   O_L3CTABLE__Offset0                                       25
+#define   W_L3CTABLE__Offset0                                       7
+#define   O_L3CTABLE__Len0                                          21
+#define   W_L3CTABLE__Len0                                          4
+#define   O_L3CTABLE__Offset1                                       14
+#define   W_L3CTABLE__Offset1                                       7
+#define   O_L3CTABLE__Len1                                          10
+#define   W_L3CTABLE__Len1                                          4
+#define   O_L3CTABLE__Offset2                                       4
+#define   W_L3CTABLE__Offset2                                       6
+#define   O_L3CTABLE__Len2                                          0
+#define   W_L3CTABLE__Len2                                          4
+#define   O_L3CTABLE__L3HdrOffset                                   26
+#define   W_L3CTABLE__L3HdrOffset                                   6
+#define   O_L3CTABLE__L4ProtoOffset                                 20
+#define   W_L3CTABLE__L4ProtoOffset                                 6
+#define   O_L3CTABLE__IPChksumCompute                               19
+#define   O_L3CTABLE__L4Classify                                    18
+#define   O_L3CTABLE__L2Proto                                       16
+#define   W_L3CTABLE__L2Proto                                       2
+#define   O_L3CTABLE__L3ProtoKey                                    0
+#define   W_L3CTABLE__L3ProtoKey                                    16
+#define R_L4CTABLE                                                  0x160
+#define   O_L4CTABLE__Offset0                                       21
+#define   W_L4CTABLE__Offset0                                       6
+#define   O_L4CTABLE__Len0                                          17
+#define   W_L4CTABLE__Len0                                          4
+#define   O_L4CTABLE__Offset1                                       11
+#define   W_L4CTABLE__Offset1                                       6
+#define   O_L4CTABLE__Len1                                          7
+#define   W_L4CTABLE__Len1                                          4
+#define   O_L4CTABLE__TCPChksumEnable                               0
+#define R_CAM4X128TABLE                                             0x172
+#define   O_CAM4X128TABLE__ClassId                                  7
+#define   W_CAM4X128TABLE__ClassId                                  2
+#define   O_CAM4X128TABLE__BucketId                                 1
+#define   W_CAM4X128TABLE__BucketId                                 6
+#define   O_CAM4X128TABLE__UseBucket                                0
+#define R_CAM4X128KEY                                               0x180
+#define R_TRANSLATETABLE                                            0x1A0
+#define R_DMACR0                                                    0x200
+#define   O_DMACR0__Data0WrMaxCr                                    27
+#define   W_DMACR0__Data0WrMaxCr                                    3
+#define   O_DMACR0__Data0RdMaxCr                                    24
+#define   W_DMACR0__Data0RdMaxCr                                    3
+#define   O_DMACR0__Data1WrMaxCr                                    21
+#define   W_DMACR0__Data1WrMaxCr                                    3
+#define   O_DMACR0__Data1RdMaxCr                                    18
+#define   W_DMACR0__Data1RdMaxCr                                    3
+#define   O_DMACR0__Data2WrMaxCr                                    15
+#define   W_DMACR0__Data2WrMaxCr                                    3
+#define   O_DMACR0__Data2RdMaxCr                                    12
+#define   W_DMACR0__Data2RdMaxCr                                    3
+#define   O_DMACR0__Data3WrMaxCr                                    9
+#define   W_DMACR0__Data3WrMaxCr                                    3
+#define   O_DMACR0__Data3RdMaxCr                                    6
+#define   W_DMACR0__Data3RdMaxCr                                    3
+#define   O_DMACR0__Data4WrMaxCr                                    3
+#define   W_DMACR0__Data4WrMaxCr                                    3
+#define   O_DMACR0__Data4RdMaxCr                                    0
+#define   W_DMACR0__Data4RdMaxCr                                    3
+#define R_DMACR1                                                    0x201
+#define   O_DMACR1__Data5WrMaxCr                                    27
+#define   W_DMACR1__Data5WrMaxCr                                    3
+#define   O_DMACR1__Data5RdMaxCr                                    24
+#define   W_DMACR1__Data5RdMaxCr                                    3
+#define   O_DMACR1__Data6WrMaxCr                                    21
+#define   W_DMACR1__Data6WrMaxCr                                    3
+#define   O_DMACR1__Data6RdMaxCr                                    18
+#define   W_DMACR1__Data6RdMaxCr                                    3
+#define   O_DMACR1__Data7WrMaxCr                                    15
+#define   W_DMACR1__Data7WrMaxCr                                    3
+#define   O_DMACR1__Data7RdMaxCr                                    12
+#define   W_DMACR1__Data7RdMaxCr                                    3
+#define   O_DMACR1__Data8WrMaxCr                                    9
+#define   W_DMACR1__Data8WrMaxCr                                    3
+#define   O_DMACR1__Data8RdMaxCr                                    6
+#define   W_DMACR1__Data8RdMaxCr                                    3
+#define   O_DMACR1__Data9WrMaxCr                                    3
+#define   W_DMACR1__Data9WrMaxCr                                    3
+#define   O_DMACR1__Data9RdMaxCr                                    0
+#define   W_DMACR1__Data9RdMaxCr                                    3
+#define R_DMACR2                                                    0x202
+#define   O_DMACR2__Data10WrMaxCr                                   27
+#define   W_DMACR2__Data10WrMaxCr                                   3
+#define   O_DMACR2__Data10RdMaxCr                                   24
+#define   W_DMACR2__Data10RdMaxCr                                   3
+#define   O_DMACR2__Data11WrMaxCr                                   21
+#define   W_DMACR2__Data11WrMaxCr                                   3
+#define   O_DMACR2__Data11RdMaxCr                                   18
+#define   W_DMACR2__Data11RdMaxCr                                   3
+#define   O_DMACR2__Data12WrMaxCr                                   15
+#define   W_DMACR2__Data12WrMaxCr                                   3
+#define   O_DMACR2__Data12RdMaxCr                                   12
+#define   W_DMACR2__Data12RdMaxCr                                   3
+#define   O_DMACR2__Data13WrMaxCr                                   9
+#define   W_DMACR2__Data13WrMaxCr                                   3
+#define   O_DMACR2__Data13RdMaxCr                                   6
+#define   W_DMACR2__Data13RdMaxCr                                   3
+#define   O_DMACR2__Data14WrMaxCr                                   3
+#define   W_DMACR2__Data14WrMaxCr                                   3
+#define   O_DMACR2__Data14RdMaxCr                                   0
+#define   W_DMACR2__Data14RdMaxCr                                   3
+#define R_DMACR3                                                    0x203
+#define   O_DMACR3__Data15WrMaxCr                                   27
+#define   W_DMACR3__Data15WrMaxCr                                   3
+#define   O_DMACR3__Data15RdMaxCr                                   24
+#define   W_DMACR3__Data15RdMaxCr                                   3
+#define   O_DMACR3__SpClassWrMaxCr                                  21
+#define   W_DMACR3__SpClassWrMaxCr                                  3
+#define   O_DMACR3__SpClassRdMaxCr                                  18
+#define   W_DMACR3__SpClassRdMaxCr                                  3
+#define   O_DMACR3__JumFrInWrMaxCr                                  15
+#define   W_DMACR3__JumFrInWrMaxCr                                  3
+#define   O_DMACR3__JumFrInRdMaxCr                                  12
+#define   W_DMACR3__JumFrInRdMaxCr                                  3
+#define   O_DMACR3__RegFrInWrMaxCr                                  9
+#define   W_DMACR3__RegFrInWrMaxCr                                  3
+#define   O_DMACR3__RegFrInRdMaxCr                                  6
+#define   W_DMACR3__RegFrInRdMaxCr                                  3
+#define   O_DMACR3__FrOutWrMaxCr                                    3
+#define   W_DMACR3__FrOutWrMaxCr                                    3
+#define   O_DMACR3__FrOutRdMaxCr                                    0
+#define   W_DMACR3__FrOutRdMaxCr                                    3
+#define R_REG_FRIN_SPILL_MEM_START_0                                0x204
+#define   O_REG_FRIN_SPILL_MEM_START_0__RegFrInSpillMemStart0        0
+#define   W_REG_FRIN_SPILL_MEM_START_0__RegFrInSpillMemStart0       32
+#define R_REG_FRIN_SPILL_MEM_START_1                                0x205
+#define   O_REG_FRIN_SPILL_MEM_START_1__RegFrInSpillMemStart1        0
+#define   W_REG_FRIN_SPILL_MEM_START_1__RegFrInSpillMemStart1        3
+#define R_REG_FRIN_SPILL_MEM_SIZE                                   0x206
+#define   O_REG_FRIN_SPILL_MEM_SIZE__RegFrInSpillMemSize             0
+#define   W_REG_FRIN_SPILL_MEM_SIZE__RegFrInSpillMemSize            32
+#define R_FROUT_SPILL_MEM_START_0                                   0x207
+#define   O_FROUT_SPILL_MEM_START_0__FrOutSpillMemStart0             0
+#define   W_FROUT_SPILL_MEM_START_0__FrOutSpillMemStart0            32
+#define R_FROUT_SPILL_MEM_START_1                                   0x208
+#define   O_FROUT_SPILL_MEM_START_1__FrOutSpillMemStart1             0
+#define   W_FROUT_SPILL_MEM_START_1__FrOutSpillMemStart1             3
+#define R_FROUT_SPILL_MEM_SIZE                                      0x209
+#define   O_FROUT_SPILL_MEM_SIZE__FrOutSpillMemSize                  0
+#define   W_FROUT_SPILL_MEM_SIZE__FrOutSpillMemSize                 32
+#define R_CLASS0_SPILL_MEM_START_0                                  0x20A
+#define   O_CLASS0_SPILL_MEM_START_0__Class0SpillMemStart0           0
+#define   W_CLASS0_SPILL_MEM_START_0__Class0SpillMemStart0          32
+#define R_CLASS0_SPILL_MEM_START_1                                  0x20B
+#define   O_CLASS0_SPILL_MEM_START_1__Class0SpillMemStart1           0
+#define   W_CLASS0_SPILL_MEM_START_1__Class0SpillMemStart1           3
+#define R_CLASS0_SPILL_MEM_SIZE                                     0x20C
+#define   O_CLASS0_SPILL_MEM_SIZE__Class0SpillMemSize                0
+#define   W_CLASS0_SPILL_MEM_SIZE__Class0SpillMemSize               32
+#define R_JUMFRIN_SPILL_MEM_START_0                                 0x20D
+#define   O_JUMFRIN_SPILL_MEM_START_0__JumFrInSpillMemStar0          0
+#define   W_JUMFRIN_SPILL_MEM_START_0__JumFrInSpillMemStar0         32
+#define R_JUMFRIN_SPILL_MEM_START_1                                 0x20E
+#define   O_JUMFRIN_SPILL_MEM_START_1__JumFrInSpillMemStart1         0
+#define   W_JUMFRIN_SPILL_MEM_START_1__JumFrInSpillMemStart1         3
+#define R_JUMFRIN_SPILL_MEM_SIZE                                    0x20F
+#define   O_JUMFRIN_SPILL_MEM_SIZE__JumFrInSpillMemSize              0
+#define   W_JUMFRIN_SPILL_MEM_SIZE__JumFrInSpillMemSize             32
+#define R_CLASS1_SPILL_MEM_START_0                                  0x210
+#define   O_CLASS1_SPILL_MEM_START_0__Class1SpillMemStart0           0
+#define   W_CLASS1_SPILL_MEM_START_0__Class1SpillMemStart0          32
+#define R_CLASS1_SPILL_MEM_START_1                                  0x211
+#define   O_CLASS1_SPILL_MEM_START_1__Class1SpillMemStart1           0
+#define   W_CLASS1_SPILL_MEM_START_1__Class1SpillMemStart1           3
+#define R_CLASS1_SPILL_MEM_SIZE                                     0x212
+#define   O_CLASS1_SPILL_MEM_SIZE__Class1SpillMemSize                0
+#define   W_CLASS1_SPILL_MEM_SIZE__Class1SpillMemSize               32
+#define R_CLASS2_SPILL_MEM_START_0                                  0x213
+#define   O_CLASS2_SPILL_MEM_START_0__Class2SpillMemStart0           0
+#define   W_CLASS2_SPILL_MEM_START_0__Class2SpillMemStart0          32
+#define R_CLASS2_SPILL_MEM_START_1                                  0x214
+#define   O_CLASS2_SPILL_MEM_START_1__Class2SpillMemStart1           0
+#define   W_CLASS2_SPILL_MEM_START_1__Class2SpillMemStart1           3
+#define R_CLASS2_SPILL_MEM_SIZE                                     0x215
+#define   O_CLASS2_SPILL_MEM_SIZE__Class2SpillMemSize                0
+#define   W_CLASS2_SPILL_MEM_SIZE__Class2SpillMemSize               32
+#define R_CLASS3_SPILL_MEM_START_0                                  0x216
+#define   O_CLASS3_SPILL_MEM_START_0__Class3SpillMemStart0           0
+#define   W_CLASS3_SPILL_MEM_START_0__Class3SpillMemStart0          32
+#define R_CLASS3_SPILL_MEM_START_1                                  0x217
+#define   O_CLASS3_SPILL_MEM_START_1__Class3SpillMemStart1           0
+#define   W_CLASS3_SPILL_MEM_START_1__Class3SpillMemStart1           3
+#define R_CLASS3_SPILL_MEM_SIZE                                     0x218
+#define   O_CLASS3_SPILL_MEM_SIZE__Class3SpillMemSize                0
+#define   W_CLASS3_SPILL_MEM_SIZE__Class3SpillMemSize               32
+#define R_REG_FRIN1_SPILL_MEM_START_0                               0x219
+#define R_REG_FRIN1_SPILL_MEM_START_1                               0x21a
+#define R_REG_FRIN1_SPILL_MEM_SIZE                                  0x21b
+#define R_SPIHNGY0                                                  0x219
+#define   O_SPIHNGY0__EG_HNGY_THRESH_0                              24
+#define   W_SPIHNGY0__EG_HNGY_THRESH_0                              7
+#define   O_SPIHNGY0__EG_HNGY_THRESH_1                              16
+#define   W_SPIHNGY0__EG_HNGY_THRESH_1                              7
+#define   O_SPIHNGY0__EG_HNGY_THRESH_2                              8
+#define   W_SPIHNGY0__EG_HNGY_THRESH_2                              7
+#define   O_SPIHNGY0__EG_HNGY_THRESH_3                              0
+#define   W_SPIHNGY0__EG_HNGY_THRESH_3                              7
+#define R_SPIHNGY1                                                  0x21A
+#define   O_SPIHNGY1__EG_HNGY_THRESH_4                              24
+#define   W_SPIHNGY1__EG_HNGY_THRESH_4                              7
+#define   O_SPIHNGY1__EG_HNGY_THRESH_5                              16
+#define   W_SPIHNGY1__EG_HNGY_THRESH_5                              7
+#define   O_SPIHNGY1__EG_HNGY_THRESH_6                              8
+#define   W_SPIHNGY1__EG_HNGY_THRESH_6                              7
+#define   O_SPIHNGY1__EG_HNGY_THRESH_7                              0
+#define   W_SPIHNGY1__EG_HNGY_THRESH_7                              7
+#define R_SPIHNGY2                                                  0x21B
+#define   O_SPIHNGY2__EG_HNGY_THRESH_8                              24
+#define   W_SPIHNGY2__EG_HNGY_THRESH_8                              7
+#define   O_SPIHNGY2__EG_HNGY_THRESH_9                              16
+#define   W_SPIHNGY2__EG_HNGY_THRESH_9                              7
+#define   O_SPIHNGY2__EG_HNGY_THRESH_10                             8
+#define   W_SPIHNGY2__EG_HNGY_THRESH_10                             7
+#define   O_SPIHNGY2__EG_HNGY_THRESH_11                             0
+#define   W_SPIHNGY2__EG_HNGY_THRESH_11                             7
+#define R_SPIHNGY3                                                  0x21C
+#define   O_SPIHNGY3__EG_HNGY_THRESH_12                             24
+#define   W_SPIHNGY3__EG_HNGY_THRESH_12                             7
+#define   O_SPIHNGY3__EG_HNGY_THRESH_13                             16
+#define   W_SPIHNGY3__EG_HNGY_THRESH_13                             7
+#define   O_SPIHNGY3__EG_HNGY_THRESH_14                             8
+#define   W_SPIHNGY3__EG_HNGY_THRESH_14                             7
+#define   O_SPIHNGY3__EG_HNGY_THRESH_15                             0
+#define   W_SPIHNGY3__EG_HNGY_THRESH_15                             7
+#define R_SPISTRV0                                                  0x21D
+#define   O_SPISTRV0__EG_STRV_THRESH_0                              24
+#define   W_SPISTRV0__EG_STRV_THRESH_0                              7
+#define   O_SPISTRV0__EG_STRV_THRESH_1                              16
+#define   W_SPISTRV0__EG_STRV_THRESH_1                              7
+#define   O_SPISTRV0__EG_STRV_THRESH_2                              8
+#define   W_SPISTRV0__EG_STRV_THRESH_2                              7
+#define   O_SPISTRV0__EG_STRV_THRESH_3                              0
+#define   W_SPISTRV0__EG_STRV_THRESH_3                              7
+#define R_SPISTRV1                                                  0x21E
+#define   O_SPISTRV1__EG_STRV_THRESH_4                              24
+#define   W_SPISTRV1__EG_STRV_THRESH_4                              7
+#define   O_SPISTRV1__EG_STRV_THRESH_5                              16
+#define   W_SPISTRV1__EG_STRV_THRESH_5                              7
+#define   O_SPISTRV1__EG_STRV_THRESH_6                              8
+#define   W_SPISTRV1__EG_STRV_THRESH_6                              7
+#define   O_SPISTRV1__EG_STRV_THRESH_7                              0
+#define   W_SPISTRV1__EG_STRV_THRESH_7                              7
+#define R_SPISTRV2                                                  0x21F
+#define   O_SPISTRV2__EG_STRV_THRESH_8                              24
+#define   W_SPISTRV2__EG_STRV_THRESH_8                              7
+#define   O_SPISTRV2__EG_STRV_THRESH_9                              16
+#define   W_SPISTRV2__EG_STRV_THRESH_9                              7
+#define   O_SPISTRV2__EG_STRV_THRESH_10                             8
+#define   W_SPISTRV2__EG_STRV_THRESH_10                             7
+#define   O_SPISTRV2__EG_STRV_THRESH_11                             0
+#define   W_SPISTRV2__EG_STRV_THRESH_11                             7
+#define R_SPISTRV3                                                  0x220
+#define   O_SPISTRV3__EG_STRV_THRESH_12                             24
+#define   W_SPISTRV3__EG_STRV_THRESH_12                             7
+#define   O_SPISTRV3__EG_STRV_THRESH_13                             16
+#define   W_SPISTRV3__EG_STRV_THRESH_13                             7
+#define   O_SPISTRV3__EG_STRV_THRESH_14                             8
+#define   W_SPISTRV3__EG_STRV_THRESH_14                             7
+#define   O_SPISTRV3__EG_STRV_THRESH_15                             0
+#define   W_SPISTRV3__EG_STRV_THRESH_15                             7
+#define R_TXDATAFIFO0                                               0x221
+#define   O_TXDATAFIFO0__Tx0DataFifoStart                           24
+#define   W_TXDATAFIFO0__Tx0DataFifoStart                           7
+#define   O_TXDATAFIFO0__Tx0DataFifoSize                            16
+#define   W_TXDATAFIFO0__Tx0DataFifoSize                            7
+#define   O_TXDATAFIFO0__Tx1DataFifoStart                           8
+#define   W_TXDATAFIFO0__Tx1DataFifoStart                           7
+#define   O_TXDATAFIFO0__Tx1DataFifoSize                            0
+#define   W_TXDATAFIFO0__Tx1DataFifoSize                            7
+#define R_TXDATAFIFO1                                               0x222
+#define   O_TXDATAFIFO1__Tx2DataFifoStart                           24
+#define   W_TXDATAFIFO1__Tx2DataFifoStart                           7
+#define   O_TXDATAFIFO1__Tx2DataFifoSize                            16
+#define   W_TXDATAFIFO1__Tx2DataFifoSize                            7
+#define   O_TXDATAFIFO1__Tx3DataFifoStart                           8
+#define   W_TXDATAFIFO1__Tx3DataFifoStart                           7
+#define   O_TXDATAFIFO1__Tx3DataFifoSize                            0
+#define   W_TXDATAFIFO1__Tx3DataFifoSize                            7
+#define R_TXDATAFIFO2                                               0x223
+#define   O_TXDATAFIFO2__Tx4DataFifoStart                           24
+#define   W_TXDATAFIFO2__Tx4DataFifoStart                           7
+#define   O_TXDATAFIFO2__Tx4DataFifoSize                            16
+#define   W_TXDATAFIFO2__Tx4DataFifoSize                            7
+#define   O_TXDATAFIFO2__Tx5DataFifoStart                           8
+#define   W_TXDATAFIFO2__Tx5DataFifoStart                           7
+#define   O_TXDATAFIFO2__Tx5DataFifoSize                            0
+#define   W_TXDATAFIFO2__Tx5DataFifoSize                            7
+#define R_TXDATAFIFO3                                               0x224
+#define   O_TXDATAFIFO3__Tx6DataFifoStart                           24
+#define   W_TXDATAFIFO3__Tx6DataFifoStart                           7
+#define   O_TXDATAFIFO3__Tx6DataFifoSize                            16
+#define   W_TXDATAFIFO3__Tx6DataFifoSize                            7
+#define   O_TXDATAFIFO3__Tx7DataFifoStart                           8
+#define   W_TXDATAFIFO3__Tx7DataFifoStart                           7
+#define   O_TXDATAFIFO3__Tx7DataFifoSize                            0
+#define   W_TXDATAFIFO3__Tx7DataFifoSize                            7
+#define R_TXDATAFIFO4                                               0x225
+#define   O_TXDATAFIFO4__Tx8DataFifoStart                           24
+#define   W_TXDATAFIFO4__Tx8DataFifoStart                           7
+#define   O_TXDATAFIFO4__Tx8DataFifoSize                            16
+#define   W_TXDATAFIFO4__Tx8DataFifoSize                            7
+#define   O_TXDATAFIFO4__Tx9DataFifoStart                           8
+#define   W_TXDATAFIFO4__Tx9DataFifoStart                           7
+#define   O_TXDATAFIFO4__Tx9DataFifoSize                            0
+#define   W_TXDATAFIFO4__Tx9DataFifoSize                            7
+#define R_TXDATAFIFO5                                               0x226
+#define   O_TXDATAFIFO5__Tx10DataFifoStart                          24
+#define   W_TXDATAFIFO5__Tx10DataFifoStart                          7
+#define   O_TXDATAFIFO5__Tx10DataFifoSize                           16
+#define   W_TXDATAFIFO5__Tx10DataFifoSize                           7
+#define   O_TXDATAFIFO5__Tx11DataFifoStart                          8
+#define   W_TXDATAFIFO5__Tx11DataFifoStart                          7
+#define   O_TXDATAFIFO5__Tx11DataFifoSize                           0
+#define   W_TXDATAFIFO5__Tx11DataFifoSize                           7
+#define R_TXDATAFIFO6                                               0x227
+#define   O_TXDATAFIFO6__Tx12DataFifoStart                          24
+#define   W_TXDATAFIFO6__Tx12DataFifoStart                          7
+#define   O_TXDATAFIFO6__Tx12DataFifoSize                           16
+#define   W_TXDATAFIFO6__Tx12DataFifoSize                           7
+#define   O_TXDATAFIFO6__Tx13DataFifoStart                          8
+#define   W_TXDATAFIFO6__Tx13DataFifoStart                          7
+#define   O_TXDATAFIFO6__Tx13DataFifoSize                           0
+#define   W_TXDATAFIFO6__Tx13DataFifoSize                           7
+#define R_TXDATAFIFO7                                               0x228
+#define   O_TXDATAFIFO7__Tx14DataFifoStart                          24
+#define   W_TXDATAFIFO7__Tx14DataFifoStart                          7
+#define   O_TXDATAFIFO7__Tx14DataFifoSize                           16
+#define   W_TXDATAFIFO7__Tx14DataFifoSize                           7
+#define   O_TXDATAFIFO7__Tx15DataFifoStart                          8
+#define   W_TXDATAFIFO7__Tx15DataFifoStart                          7
+#define   O_TXDATAFIFO7__Tx15DataFifoSize                           0
+#define   W_TXDATAFIFO7__Tx15DataFifoSize                           7
+#define R_RXDATAFIFO0                                               0x229
+#define   O_RXDATAFIFO0__Rx0DataFifoStart                           24
+#define   W_RXDATAFIFO0__Rx0DataFifoStart                           7
+#define   O_RXDATAFIFO0__Rx0DataFifoSize                            16
+#define   W_RXDATAFIFO0__Rx0DataFifoSize                            7
+#define   O_RXDATAFIFO0__Rx1DataFifoStart                           8
+#define   W_RXDATAFIFO0__Rx1DataFifoStart                           7
+#define   O_RXDATAFIFO0__Rx1DataFifoSize                            0
+#define   W_RXDATAFIFO0__Rx1DataFifoSize                            7
+#define R_RXDATAFIFO1                                               0x22A
+#define   O_RXDATAFIFO1__Rx2DataFifoStart                           24
+#define   W_RXDATAFIFO1__Rx2DataFifoStart                           7
+#define   O_RXDATAFIFO1__Rx2DataFifoSize                            16
+#define   W_RXDATAFIFO1__Rx2DataFifoSize                            7
+#define   O_RXDATAFIFO1__Rx3DataFifoStart                           8
+#define   W_RXDATAFIFO1__Rx3DataFifoStart                           7
+#define   O_RXDATAFIFO1__Rx3DataFifoSize                            0
+#define   W_RXDATAFIFO1__Rx3DataFifoSize                            7
+#define R_RXDATAFIFO2                                               0x22B
+#define   O_RXDATAFIFO2__Rx4DataFifoStart                           24
+#define   W_RXDATAFIFO2__Rx4DataFifoStart                           7
+#define   O_RXDATAFIFO2__Rx4DataFifoSize                            16
+#define   W_RXDATAFIFO2__Rx4DataFifoSize                            7
+#define   O_RXDATAFIFO2__Rx5DataFifoStart                           8
+#define   W_RXDATAFIFO2__Rx5DataFifoStart                           7
+#define   O_RXDATAFIFO2__Rx5DataFifoSize                            0
+#define   W_RXDATAFIFO2__Rx5DataFifoSize                            7
+#define R_RXDATAFIFO3                                               0x22C
+#define   O_RXDATAFIFO3__Rx6DataFifoStart                           24
+#define   W_RXDATAFIFO3__Rx6DataFifoStart                           7
+#define   O_RXDATAFIFO3__Rx6DataFifoSize                            16
+#define   W_RXDATAFIFO3__Rx6DataFifoSize                            7
+#define   O_RXDATAFIFO3__Rx7DataFifoStart                           8
+#define   W_RXDATAFIFO3__Rx7DataFifoStart                           7
+#define   O_RXDATAFIFO3__Rx7DataFifoSize                            0
+#define   W_RXDATAFIFO3__Rx7DataFifoSize                            7
+#define R_RXDATAFIFO4                                               0x22D
+#define   O_RXDATAFIFO4__Rx8DataFifoStart                           24
+#define   W_RXDATAFIFO4__Rx8DataFifoStart                           7
+#define   O_RXDATAFIFO4__Rx8DataFifoSize                            16
+#define   W_RXDATAFIFO4__Rx8DataFifoSize                            7
+#define   O_RXDATAFIFO4__Rx9DataFifoStart                           8
+#define   W_RXDATAFIFO4__Rx9DataFifoStart                           7
+#define   O_RXDATAFIFO4__Rx9DataFifoSize                            0
+#define   W_RXDATAFIFO4__Rx9DataFifoSize                            7
+#define R_RXDATAFIFO5                                               0x22E
+#define   O_RXDATAFIFO5__Rx10DataFifoStart                          24
+#define   W_RXDATAFIFO5__Rx10DataFifoStart                          7
+#define   O_RXDATAFIFO5__Rx10DataFifoSize                           16
+#define   W_RXDATAFIFO5__Rx10DataFifoSize                           7
+#define   O_RXDATAFIFO5__Rx11DataFifoStart                          8
+#define   W_RXDATAFIFO5__Rx11DataFifoStart                          7
+#define   O_RXDATAFIFO5__Rx11DataFifoSize                           0
+#define   W_RXDATAFIFO5__Rx11DataFifoSize                           7
+#define R_RXDATAFIFO6                                               0x22F
+#define   O_RXDATAFIFO6__Rx12DataFifoStart                          24
+#define   W_RXDATAFIFO6__Rx12DataFifoStart                          7
+#define   O_RXDATAFIFO6__Rx12DataFifoSize                           16
+#define   W_RXDATAFIFO6__Rx12DataFifoSize                           7
+#define   O_RXDATAFIFO6__Rx13DataFifoStart                          8
+#define   W_RXDATAFIFO6__Rx13DataFifoStart                          7
+#define   O_RXDATAFIFO6__Rx13DataFifoSize                           0
+#define   W_RXDATAFIFO6__Rx13DataFifoSize                           7
+#define R_RXDATAFIFO7                                               0x230
+#define   O_RXDATAFIFO7__Rx14DataFifoStart                          24
+#define   W_RXDATAFIFO7__Rx14DataFifoStart                          7
+#define   O_RXDATAFIFO7__Rx14DataFifoSize                           16
+#define   W_RXDATAFIFO7__Rx14DataFifoSize                           7
+#define   O_RXDATAFIFO7__Rx15DataFifoStart                          8
+#define   W_RXDATAFIFO7__Rx15DataFifoStart                          7
+#define   O_RXDATAFIFO7__Rx15DataFifoSize                           0
+#define   W_RXDATAFIFO7__Rx15DataFifoSize                           7
+#define R_XGMACPADCALIBRATION                                       0x231
+#define R_FREEQCARVE                                                0x233
+#define R_SPI4STATICDELAY0                                          0x240
+#define   O_SPI4STATICDELAY0__DataLine7                             28
+#define   W_SPI4STATICDELAY0__DataLine7                             4
+#define   O_SPI4STATICDELAY0__DataLine6                             24
+#define   W_SPI4STATICDELAY0__DataLine6                             4
+#define   O_SPI4STATICDELAY0__DataLine5                             20
+#define   W_SPI4STATICDELAY0__DataLine5                             4
+#define   O_SPI4STATICDELAY0__DataLine4                             16
+#define   W_SPI4STATICDELAY0__DataLine4                             4
+#define   O_SPI4STATICDELAY0__DataLine3                             12
+#define   W_SPI4STATICDELAY0__DataLine3                             4
+#define   O_SPI4STATICDELAY0__DataLine2                             8
+#define   W_SPI4STATICDELAY0__DataLine2                             4
+#define   O_SPI4STATICDELAY0__DataLine1                             4
+#define   W_SPI4STATICDELAY0__DataLine1                             4
+#define   O_SPI4STATICDELAY0__DataLine0                             0
+#define   W_SPI4STATICDELAY0__DataLine0                             4
+#define R_SPI4STATICDELAY1                                          0x241
+#define   O_SPI4STATICDELAY1__DataLine15                            28
+#define   W_SPI4STATICDELAY1__DataLine15                            4
+#define   O_SPI4STATICDELAY1__DataLine14                            24
+#define   W_SPI4STATICDELAY1__DataLine14                            4
+#define   O_SPI4STATICDELAY1__DataLine13                            20
+#define   W_SPI4STATICDELAY1__DataLine13                            4
+#define   O_SPI4STATICDELAY1__DataLine12                            16
+#define   W_SPI4STATICDELAY1__DataLine12                            4
+#define   O_SPI4STATICDELAY1__DataLine11                            12
+#define   W_SPI4STATICDELAY1__DataLine11                            4
+#define   O_SPI4STATICDELAY1__DataLine10                            8
+#define   W_SPI4STATICDELAY1__DataLine10                            4
+#define   O_SPI4STATICDELAY1__DataLine9                             4
+#define   W_SPI4STATICDELAY1__DataLine9                             4
+#define   O_SPI4STATICDELAY1__DataLine8                             0
+#define   W_SPI4STATICDELAY1__DataLine8                             4
+#define R_SPI4STATICDELAY2                                          0x242
+#define   O_SPI4STATICDELAY0__TxStat1                               8
+#define   W_SPI4STATICDELAY0__TxStat1                               4
+#define   O_SPI4STATICDELAY0__TxStat0                               4
+#define   W_SPI4STATICDELAY0__TxStat0                               4
+#define   O_SPI4STATICDELAY0__RxControl                             0
+#define   W_SPI4STATICDELAY0__RxControl                             4
+#define R_SPI4CONTROL                                               0x243
+#define   O_SPI4CONTROL__StaticDelay                                2
+#define   O_SPI4CONTROL__LVDS_LVTTL                                 1
+#define   O_SPI4CONTROL__SPI4Enable                                 0
+#define R_CLASSWATERMARKS                                           0x244
+#define   O_CLASSWATERMARKS__Class0Watermark                        24
+#define   W_CLASSWATERMARKS__Class0Watermark                        5
+#define   O_CLASSWATERMARKS__Class1Watermark                        16
+#define   W_CLASSWATERMARKS__Class1Watermark                        5
+#define   O_CLASSWATERMARKS__Class3Watermark                        0
+#define   W_CLASSWATERMARKS__Class3Watermark                        5
+#define R_RXWATERMARKS1                                              0x245
+#define   O_RXWATERMARKS__Rx0DataWatermark                          24
+#define   W_RXWATERMARKS__Rx0DataWatermark                          7
+#define   O_RXWATERMARKS__Rx1DataWatermark                          16
+#define   W_RXWATERMARKS__Rx1DataWatermark                          7
+#define   O_RXWATERMARKS__Rx3DataWatermark                          0
+#define   W_RXWATERMARKS__Rx3DataWatermark                          7
+#define R_RXWATERMARKS2                                              0x246
+#define   O_RXWATERMARKS__Rx4DataWatermark                          24
+#define   W_RXWATERMARKS__Rx4DataWatermark                          7
+#define   O_RXWATERMARKS__Rx5DataWatermark                          16
+#define   W_RXWATERMARKS__Rx5DataWatermark                          7
+#define   O_RXWATERMARKS__Rx6DataWatermark                          8
+#define   W_RXWATERMARKS__Rx6DataWatermark                          7
+#define   O_RXWATERMARKS__Rx7DataWatermark                          0
+#define   W_RXWATERMARKS__Rx7DataWatermark                          7
+#define R_RXWATERMARKS3                                              0x247
+#define   O_RXWATERMARKS__Rx8DataWatermark                          24
+#define   W_RXWATERMARKS__Rx8DataWatermark                          7
+#define   O_RXWATERMARKS__Rx9DataWatermark                          16
+#define   W_RXWATERMARKS__Rx9DataWatermark                          7
+#define   O_RXWATERMARKS__Rx10DataWatermark                         8
+#define   W_RXWATERMARKS__Rx10DataWatermark                         7
+#define   O_RXWATERMARKS__Rx11DataWatermark                         0
+#define   W_RXWATERMARKS__Rx11DataWatermark                         7
+#define R_RXWATERMARKS4                                              0x248
+#define   O_RXWATERMARKS__Rx12DataWatermark                         24
+#define   W_RXWATERMARKS__Rx12DataWatermark                         7
+#define   O_RXWATERMARKS__Rx13DataWatermark                         16
+#define   W_RXWATERMARKS__Rx13DataWatermark                         7
+#define   O_RXWATERMARKS__Rx14DataWatermark                         8
+#define   W_RXWATERMARKS__Rx14DataWatermark                         7
+#define   O_RXWATERMARKS__Rx15DataWatermark                         0
+#define   W_RXWATERMARKS__Rx15DataWatermark                         7
+#define R_FREEWATERMARKS                                            0x249
+#define   O_FREEWATERMARKS__FreeOutWatermark                        16
+#define   W_FREEWATERMARKS__FreeOutWatermark                        16
+#define   O_FREEWATERMARKS__JumFrWatermark                          8
+#define   W_FREEWATERMARKS__JumFrWatermark                          7
+#define   O_FREEWATERMARKS__RegFrWatermark                          0
+#define   W_FREEWATERMARKS__RegFrWatermark                          7
+#define R_EGRESSFIFOCARVINGSLOTS                                    0x24a
+
+
+#define CTRL_RES0           0
+#define CTRL_RES1           1
+#define CTRL_REG_FREE       2
+#define CTRL_CONT           4
+#define CTRL_EOP            5
+#define CTRL_START          6
+#define CTRL_SNGL           7
+
+#define CTRL_B0_NOT_EOP     0
+#define CTRL_B0_EOP         1
+
+#define R_ROUND_ROBIN_TABLE                 0
+#define R_PDE_CLASS_0                       0x300
+#define R_PDE_CLASS_1                       0x302
+#define R_PDE_CLASS_2                       0x304
+#define R_PDE_CLASS_3                       0x306
+
+#define R_MSG_TX_THRESHOLD                  0x308
+
+#define R_GMAC_RFR0_BUCKET_SIZE              0x321
+#define R_GMAC_TX0_BUCKET_SIZE              0x322
+#define R_GMAC_TX1_BUCKET_SIZE              0x323
+#define R_GMAC_TX2_BUCKET_SIZE              0x324
+#define R_GMAC_TX3_BUCKET_SIZE              0x325
+#define R_GMAC_RFR1_BUCKET_SIZE              0x327
+
+#define R_XGS_TX0_BUCKET_SIZE               0x320
+#define R_XGS_TX1_BUCKET_SIZE               0x321
+#define R_XGS_TX2_BUCKET_SIZE               0x322
+#define R_XGS_TX3_BUCKET_SIZE               0x323
+#define R_XGS_TX4_BUCKET_SIZE               0x324
+#define R_XGS_TX5_BUCKET_SIZE               0x325
+#define R_XGS_TX6_BUCKET_SIZE               0x326
+#define R_XGS_TX7_BUCKET_SIZE               0x327
+#define R_XGS_TX8_BUCKET_SIZE               0x328
+#define R_XGS_TX9_BUCKET_SIZE               0x329
+#define R_XGS_TX10_BUCKET_SIZE              0x32A
+#define R_XGS_TX11_BUCKET_SIZE              0x32B
+#define R_XGS_TX12_BUCKET_SIZE              0x32C
+#define R_XGS_TX13_BUCKET_SIZE              0x32D
+#define R_XGS_TX14_BUCKET_SIZE              0x32E
+#define R_XGS_TX15_BUCKET_SIZE              0x32F
+#define R_XGS_RFR_BUCKET_SIZE               0x331
+
+#define R_CC_CPU0_0                         0x380
+#define R_CC_CPU1_0                         0x388
+#define R_CC_CPU2_0                         0x390
+#define R_CC_CPU3_0                         0x398
+#define R_CC_CPU4_0                         0x3a0
+#define R_CC_CPU5_0                         0x3a8
+#define R_CC_CPU6_0                         0x3b0
+#define R_CC_CPU7_0                         0x3b8
+
+/* frame sizes need to be cacheline aligned */
+#define MAC_MAX_FRAME_SIZE          1600
+#define MAC_SKB_BACK_PTR_SIZE   SMP_CACHE_BYTES
+
+
+#ifdef CONFIG_PHOENIX_PTP_SUPPORT
+#define MAC_PREPAD             32
+#else 
+#define MAC_PREPAD             0 
+#endif 
+
+#define BYTE_OFFSET             2
+#define PHNX_RX_BUF_SIZE (MAC_MAX_FRAME_SIZE+BYTE_OFFSET+MAC_PREPAD+MAC_SKB_BACK_PTR_SIZE+SMP_CACHE_BYTES)
+#define MAC_CRC_LEN             4
+
+
+enum {
+        SGMII_SPEED_10   = 0x00000000,
+        SGMII_SPEED_100  = 0x02000000,
+        SGMII_SPEED_1000 = 0x04000000,
+};
+
+enum tsv_rsv_reg{
+  TX_RX_64_BYTE_FRAME = 0x20,
+  TX_RX_64_127_BYTE_FRAME,
+  TX_RX_128_255_BYTE_FRAME,
+  TX_RX_256_511_BYTE_FRAME,
+  TX_RX_512_1023_BYTE_FRAME,
+  TX_RX_1024_1518_BYTE_FRAME,
+  TX_RX_1519_1522_VLAN_BYTE_FRAME,
+
+  RX_BYTE_COUNTER = 0x27,
+  RX_PACKET_COUNTER,
+  RX_FCS_ERROR_COUNTER,
+  RX_MULTICAST_PACKET_COUNTER,
+  RX_BROADCAST_PACKET_COUNTER,
+  RX_CONTROL_FRAME_PACKET_COUNTER,
+  RX_PAUSE_FRAME_PACKET_COUNTER,
+  RX_UNKNOWN_OP_CODE_COUNTER,
+  RX_ALIGNMENT_ERROR_COUNTER,
+  RX_FRAME_LENGTH_ERROR_COUNTER,
+  RX_CODE_ERROR_COUNTER,
+  RX_CARRIER_SENSE_ERROR_COUNTER,
+  RX_UNDERSIZE_PACKET_COUNTER,
+  RX_OVERSIZE_PACKET_COUNTER,
+  RX_FRAGMENTS_COUNTER,
+  RX_JABBER_COUNTER,
+  RX_DROP_PACKET_COUNTER,
+
+  TX_BYTE_COUNTER   = 0x38,
+  TX_PACKET_COUNTER,
+  TX_MULTICAST_PACKET_COUNTER,
+  TX_BROADCAST_PACKET_COUNTER,
+  TX_PAUSE_CONTROL_FRAME_COUNTER,
+  TX_DEFERRAL_PACKET_COUNTER,
+  TX_EXCESSIVE_DEFERRAL_PACKET_COUNTER,
+  TX_SINGLE_COLLISION_PACKET_COUNTER,
+  TX_MULTI_COLLISION_PACKET_COUNTER,
+  TX_LATE_COLLISION_PACKET_COUNTER,
+  TX_EXCESSIVE_COLLISION_PACKET_COUNTER,
+  TX_TOTAL_COLLISION_COUNTER,
+  TX_PAUSE_FRAME_HONERED_COUNTER,
+  TX_DROP_FRAME_COUNTER,
+  TX_JABBER_FRAME_COUNTER,
+  TX_FCS_ERROR_COUNTER,
+  TX_CONTROL_FRAME_COUNTER,
+  TX_OVERSIZE_FRAME_COUNTER,
+  TX_UNDERSIZE_FRAME_COUNTER,
+  TX_FRAGMENT_FRAME_COUNTER,
+
+  CARRY_REG_1 = 0x4c,
+  CARRY_REG_2 = 0x4d,
+};
+
+struct size_1_desc {
+  uint64_t entry0;
+};
+
+struct size_2_desc {
+  uint64_t entry0;
+  uint64_t entry1;
+};
+
+struct size_3_desc {
+  uint64_t entry0;
+  uint64_t entry1;
+  uint64_t entry2;
+};
+
+struct size_4_desc {
+  uint64_t entry0;
+  uint64_t entry1;
+  uint64_t entry2;
+  uint64_t entry3;
+};
+
+struct fr_desc {
+  struct size_1_desc d1;
+};
+
+union rx_tx_desc {
+  struct size_1_desc d1;
+};
+
+static inline int mac_make_desc_rfr(struct msgrng_msg *msg, int id, int type,
+				    unsigned long addr)
+{
+  int stid = 0;
+  
+  if (type == TYPE_XGMAC) stid = msgrng_xgmac_stid_rfr(id);
+  else  {
+#ifdef MAC_SPLIT_MODE
+    stid =  msgrng_gmac_stid_rfr_split_mode(id);
+#else
+    stid = msgrng_gmac_stid_rfr(id);
+#endif 
+  }
+  msg->msg0 = (((uint64_t)CTRL_REG_FREE << 61) | 
+	       ((uint64_t)stid<<52) | 
+	       (uint64_t)addr);
+  msg->msg1 = msg->msg2 = msg->msg3 = 0;
+  return stid;
+}
+
+
+
+static inline int
+msgrng_stid_rfr(int id, int type)
+{
+    int stid = 0;
+
+  if (type == TYPE_XGMAC) 
+    stid = msgrng_xgmac_stid_rfr(id);
+    else  {
+        if (id < 4) {
+#ifdef MAC_SPLIT_MODE
+            stid =  msgrng_gmac_stid_rfr_split_mode(id);
+#else
+            stid = msgrng_gmac_stid_rfr(id);
+#endif 
+        }
+        else
+            stid = msgrng_gmac1_stid_rfr(id);
+    }
+  return stid;
+}
+
+
+
+static inline int mac_make_desc_b0_rfr(struct msgrng_msg *msg, int id, int type,
+        unsigned long addr)
+{
+    int stid = msgrng_stid_rfr(id, type);
+
+    msg->msg0 = (uint64_t)addr & 0xffffffffe0ULL;
+    msg->msg1 = msg->msg2 = msg->msg3 = 0;
+
+    return stid;
+}
+
+#define MAC_TX_DESC_ALIGNMENT (SMP_CACHE_BYTES - 1)
+static inline int mac_make_desc_tx(struct msgrng_msg *msg, int id, int type,
+        unsigned long addr, int len)
+{
+    int tx_stid = 0;
+    int fr_stid = 0;
+    int desc_offset = addr & MAC_TX_DESC_ALIGNMENT;
+
+    if (type == TYPE_XGMAC) {
+        tx_stid = msgrng_xgmac_stid_tx(id);
+        fr_stid = 0;
+    }
+    else {
+        int cpu = phoenix_cpu_id();
+        if (id < 4)
+            tx_stid = msgrng_gmac_stid_tx(id);
+        else
+            tx_stid = msgrng_gmac1_stid_tx(id);
+        fr_stid = (cpu << 3) + phoenix_thr_id();
+    }
+
+    msg->msg0 = ( ((uint64_t)CTRL_SNGL << 61) | 
+            ((uint64_t)desc_offset << 40) | 
+            ((uint64_t)tx_stid << 52) |
+            ((uint64_t)addr & ~MAC_TX_DESC_ALIGNMENT)
+            );
+    msg->msg1 = ( ( (uint64_t)CTRL_EOP << 61) |  
+            ( ((uint64_t)fr_stid) << 54) | 
+            ( (uint64_t)len << 40)
+            );
+
+    msg->msg2 = msg->msg3 = 0;
+
+    return tx_stid;
+}
+
+extern __u8 phoenix_base_mac_addr[];
+/*
+ * Structure of an rmios ipsec packet
+ */
+typedef struct tagIPSEC_PACKET {
+    // cacheline-aligned portion
+    PacketDescriptor_t packet_desc; // multiple of 32 (32)
+    PacketDescriptor_t particle_desc;// second particle (GCM)
+    unsigned char auth_dest[PHXSEC_HMAC_LENGTH];    // multiple of 32 (32)
+    unsigned char packet_data[IPSEC_PACKET_PAYLOAD_SIZE];
+    // end of cacheline-aligned portion
+    int src_id;
+} IPSEC_PACKET ____cacheline_aligned;
+
+#endif
diff --git a/include/asm-mips/rmi/xgmac_mdio.h b/include/asm-mips/rmi/xgmac_mdio.h
new file mode 100644
index 0000000..ff0454f
--- /dev/null
+++ b/include/asm-mips/rmi/xgmac_mdio.h
@@ -0,0 +1,119 @@
+/*********************************************************************
+
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+// MDIO Low level Access routines
+// All Phy's accessed from GMAC0 base
+
+#ifndef _XGMAC_MDIO
+#define _XGMAC_MDIO
+
+static inline int xmdio_read  (volatile unsigned int *_mmio,
+		uint32_t phy_addr, uint32_t address) ;
+static inline void xmdio_write (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t address, uint32_t data) ;
+static inline void xmdio_address (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t dev_ad, uint32_t address) ;
+
+// function prototypes
+static inline int xmdio_read  (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t address) {
+	uint32_t st_field = 0x0 ;
+	uint32_t op_type  = 0x3 ; // read operation
+	uint32_t ta_field = 0x2 ; // ta field
+	uint32_t data = 0 ;
+
+        xmdio_address (_mmio, phy_addr, 5, address) ;
+	_mmio [0x11] =  ( ( st_field & 0x3    ) << 30 ) |
+		( ( op_type  & 0x3    ) << 28 ) | 
+		( ( phy_addr & 0x1F   ) << 23 ) | 
+		( ( 5  & 0x1F   ) << 18 ) | 
+		( ( ta_field & 0x3    ) << 16 ) | 
+		( ( data     & 0xffff ) <<  0 ) ;
+
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x1 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+
+	// wait for write cycle to complete
+	while (_mmio [0x14] & 0x1) {
+	} ; 
+
+	data = _mmio [0x11] & 0xffff ;
+	return (data);
+}
+ 
+static inline void xmdio_write (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t address, uint32_t data) {
+	uint32_t st_field = 0x0 ;
+	uint32_t op_type  = 0x1 ; // write operation
+	uint32_t ta_field = 0x2 ; // ta field
+
+        xmdio_address ( _mmio, phy_addr, 5, address) ;
+	_mmio [0x11] =  ( ( st_field & 0x3    ) << 30 ) |
+		( ( op_type  & 0x3    ) << 28 ) | 
+		( ( phy_addr & 0x1F   ) << 23 ) | 
+		( ( 5  & 0x1F   ) << 18 ) | 
+		( ( ta_field & 0x3    ) << 16 ) | 
+		( ( data     & 0xffff ) <<  0 ) ;
+
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x1 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+
+	// wait for write cycle to complete
+	while (_mmio [0x14] & 0x1) {
+	} ; 
+
+}
+
+static inline void xmdio_address (volatile unsigned int *_mmio, 
+		uint32_t phy_addr, uint32_t dev_ad, uint32_t address) {
+	uint32_t st_field = 0x0 ;
+	uint32_t op_type  = 0x0 ; // address operation
+	uint32_t ta_field = 0x2 ; // ta field
+
+	_mmio [0x11] =  ( ( st_field & 0x3    ) << 30 ) |
+		( ( op_type  & 0x3    ) << 28 ) | 
+		( ( phy_addr & 0x1F   ) << 23 ) | 
+		( ( dev_ad  & 0x1F   ) << 18 ) | 
+		( ( ta_field & 0x3    ) << 16 ) | 
+		( ( address  & 0xffff ) <<  0 ) ;
+
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x1 << 3 ) | 0x5 ;
+	_mmio [0x10] =  ( 0x0 << 3 ) | 0x5 ;
+
+	// wait for dev_ad cycle to complete
+	while (_mmio [0x14] & 0x1) {
+	} ; 
+
+}
+ 
+#endif
diff --git a/include/user/rmi/phnx_user_mac.h b/include/user/rmi/phnx_user_mac.h
new file mode 100644
index 0000000..4b622cc
--- /dev/null
+++ b/include/user/rmi/phnx_user_mac.h
@@ -0,0 +1,132 @@
+/*********************************************************************
+
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#ifndef __USER_RMI_PHNX_USER_MAC_H
+#define __USER_RMI_PHNX_USER_MAC_H
+
+#include <asm/ioctl.h>
+
+#define USER_MAC_IOC_MAGIC 'M'
+
+#define    USER_MAC_IOC_GSHMPHYS            _IOR(USER_MAC_IOC_MAGIC, 1, unsigned int)
+#define    USER_MAC_IOC_GSHMVIRT            _IOR(USER_MAC_IOC_MAGIC, 2, unsigned int)
+#define    USER_MAC_IOC_GSHMSIZE            _IOR(USER_MAC_IOC_MAGIC, 3, unsigned int)
+#define    USER_MAC_IOC_GMMAP_START         _IOR(USER_MAC_IOC_MAGIC, 4, unsigned int)
+#define    USER_MAC_IOC_SWRITE_REG          _IOW(USER_MAC_IOC_MAGIC, 10, unsigned int)
+#define    USER_MAC_IOC_GREAD_REG           _IOR(USER_MAC_IOC_MAGIC, 11, unsigned int)
+#define    USER_MAC_IOC_SPERF               _IOW(USER_MAC_IOC_MAGIC, 12, unsigned int)
+#define    USER_MAC_IOC_GPHYS_CPU_PRESENT_MAP _IOR(USER_MAC_IOC_MAGIC, 13, unsigned int)
+#define    USER_MAC_IOC_GCPU_ONLINE_MAP     _IOR(USER_MAC_IOC_MAGIC, 14, unsigned int)
+#define    USER_MAC_IOC_HYBRID_MODE_SETUP   _IOR(USER_MAC_IOC_MAGIC, 15, unsigned int)
+#define    USER_MAC_IOC_HUGETLB_SHM_VIRT_ADDR _IOR(USER_MAC_IOC_MAGIC, 16, unsigned int)
+#define    USER_MAC_IOC_EARLY_MEM_INIT		_IOR(USER_MAC_IOC_MAGIC, 17, unsigned int)
+
+#define PHNX_USER_MAC_CHRDEV_NAME "xlr_user_mac"
+
+#define MAX_USER_MAC_PKTS 3072
+#define MAX_USER_MAC_FRIN_PKTS (MAX_USER_MAC_PKTS - 256)
+#define USER_MAC_FIFO_SIZE 128
+#define USER_MAC_PKT_BUF_SIZE 1600
+
+struct packet_data {
+  unsigned char data[USER_MAC_PKT_BUF_SIZE];
+};
+
+struct packet_desc {
+  unsigned int offset;
+  int len;
+  int port;
+  int type;
+  int xgmac; //ignore in gmac. 1 xgmac loopback, 2, xgmac crossover
+  int device; //0 xgmac0, 1 xgmac1
+  int free;
+  unsigned char priv[48];
+  uint64_t priv_ptr;	//uint32_t *priv_ptr;
+};
+
+#define USER_MAC_TXQ_FREE 0
+#define USER_MAC_TXQ_TX 1
+#define USER_MAC_TXQ_HOST 2
+
+struct user_mac_time {
+  unsigned int hi;
+  unsigned int lo;
+};
+struct user_mac_data {
+  struct packet_data pkt_data[MAX_USER_MAC_PKTS];
+  struct packet_desc pkt_desc[MAX_USER_MAC_PKTS];
+  struct user_mac_time time;
+  struct timespec ktime;
+  int host_pkt_next_free[32];
+};
+
+static __inline__ unsigned char *user_mac_host_pkt_alloc(struct user_mac_data *user_mac, int cpu)
+{
+	int num_pkts = (MAX_USER_MAC_PKTS - MAX_USER_MAC_FRIN_PKTS) / 32;
+	int start_index = MAX_USER_MAC_FRIN_PKTS + (cpu * num_pkts);
+	int next_free = user_mac->host_pkt_next_free[cpu];
+	int i=0;
+
+	if (next_free < start_index || next_free >= (start_index + num_pkts)) 
+		return NULL;
+	
+	for (i=next_free; i<(start_index+num_pkts) ;i++) {
+		if (user_mac->pkt_desc[i].free) {
+			user_mac->pkt_desc[i].free = 0;
+			user_mac->host_pkt_next_free[cpu] = i;
+			return user_mac->pkt_data[i].data;
+		}
+	}
+	
+	for (i=start_index; i<next_free; i++) {
+		if (user_mac->pkt_desc[i].free) {
+			user_mac->pkt_desc[i].free = 0;
+			user_mac->host_pkt_next_free[cpu] = i;
+			return user_mac->pkt_data[i].data;
+		}		
+	}
+
+	return NULL;
+}
+
+static __inline__ int user_mac_host_pkt_free(struct user_mac_data *user_mac, int index, int cpu)
+{
+	/* This function can be called from any cpu */
+	if (index < MAX_USER_MAC_FRIN_PKTS || index >= MAX_USER_MAC_PKTS)
+		return -1;
+	
+	if (user_mac->pkt_desc[index].free) return -1;
+
+	user_mac->pkt_desc[index].free = 1;
+
+	return 0;
+}
+
+#endif
-- 
1.6.0.4

