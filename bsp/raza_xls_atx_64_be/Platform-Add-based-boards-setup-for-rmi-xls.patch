From a48151376a8c71c40729bcab256f686e855bff98 Mon Sep 17 00:00:00 2001
From: Liu Changhui <changhui.liu@windriver.com>
Date: Fri, 29 Jan 2010 13:27:51 +0800
Subject: [PATCH] Platform: Add based boards setup for rmi xls

RMI XLS based board setup code. Mainly parse board specific
parameter from rmi bootloader.

source: from RMI SDK1.7

Signed-off-by: shuo.kang <shuo.kang@windriver.com>
---
 arch/mips/rmi/ptr/Makefile |    1 +
 arch/mips/rmi/ptr/setup.c  | 1544 ++++++++++++++++++++++++++++++++++++++++++++
 2 files changed, 1545 insertions(+), 0 deletions(-)
 create mode 100644 arch/mips/rmi/ptr/setup.c

diff --git a/arch/mips/rmi/ptr/Makefile b/arch/mips/rmi/ptr/Makefile
index 8310361..36c74d0 100644
--- a/arch/mips/rmi/ptr/Makefile
+++ b/arch/mips/rmi/ptr/Makefile
@@ -1,5 +1,6 @@
 EXTRA_CFLAGS := -Werror
 obj-$(CONFIG_SMP)      += smp.o smpboot.o 
+obj-y                   = setup.o
 EXTRA_AFLAGS := $(CFLAGS)
 EXTRA_CFLAGS += -I$(srctree)/include/asm/rmi
 
diff --git a/arch/mips/rmi/ptr/setup.c b/arch/mips/rmi/ptr/setup.c
new file mode 100644
index 0000000..c9a8fda
--- /dev/null
+++ b/arch/mips/rmi/ptr/setup.c
@@ -0,0 +1,1544 @@
+/*********************************************************************
+
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/*
+ * Setup code for RMI's XLR-based boards
+ */
+
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+#include <linux/bootmem.h>
+#include <linux/init.h>
+#include <linux/pm.h>
+
+#include <asm/irq.h>
+#include <asm/io.h>
+#include <asm/bootinfo.h>
+#include <asm/addrspace.h>
+#include <asm/reboot.h>
+#include <asm/time.h>
+#include <linux/interrupt.h>
+#include <asm/atomic.h>
+#include <asm/cacheflush.h>
+
+#include <asm/rmi/sim.h>
+#include <asm/mipsregs.h>
+#include <asm/rmi/mips-exts.h>
+#include <asm/rmi/iomap.h>
+#include <asm/rmi/debug.h>
+#include <asm/rmi/phnx_user_mac.h>
+#include <asm/rmi/msgring.h>
+
+#include <asm/rmi/phnx_loader.h>
+#include <user/rmi/phnx_loader.h>
+#include <asm/rmi/rmi_pcix_gen_dev.h>
+#include <asm/rmi/memory-exclusion.h>
+
+#include <linux/serial.h>
+#include <linux/serial_core.h>
+#include <linux/module.h>
+#include <linux/proc_fs.h>
+
+#ifdef RMI_BRIDGE_WKAROUND
+#include <asm/rmi/rmi_rw_lock.h>
+rmi_rwlock_t *rmi_bridge_lock;
+EXPORT_SYMBOL(rmi_bridge_lock);
+int rmi_enable_br_wrkaround = 0;
+EXPORT_SYMBOL(rmi_enable_br_wrkaround);
+struct proc_dir_entry *rmi_root_proc;
+EXPORT_SYMBOL(rmi_root_proc);
+#endif
+unsigned long long phnx_tlb_stats[32] __cacheline_aligned;
+
+spinlock_t atomic_lock = SPIN_LOCK_UNLOCKED;
+extern void config_net_init(void);
+__u8 phoenix_base_mac_addr[6];
+volatile phnx_loader_shared_struct_t *phnx_loader_sh_mem = NULL;
+/* used for command line parsing */
+uint32_t phnx_loader_kseg_start, phnx_loader_kseg_size;
+uint32_t phnx_loader_mask;
+/* Size of the shared memory b/w Linux userapp and rmios apps */
+uint32_t phnx_app_sh_mem_sz;
+unsigned long phnx_app_shmem_start;
+static int index = 0;
+static char *hybrid_str = NULL;
+
+/* xls chip family variables */
+int chip_is_xls6xx = 0;
+int chip_is_xls4xx = 0;
+int chip_is_xls2xx = 0;
+int chip_is_xls1xx = 0;
+int chip_is_xls = 0;
+int chip_is_xls_b0 = 0;
+int chip_is_xls6xx_b0 = 0;
+int chip_is_xls4xx_b0 = 0;
+EXPORT_SYMBOL(chip_is_xls6xx);
+EXPORT_SYMBOL(chip_is_xls4xx);
+EXPORT_SYMBOL(chip_is_xls2xx);
+EXPORT_SYMBOL(chip_is_xls1xx);
+EXPORT_SYMBOL(chip_is_xls);
+EXPORT_SYMBOL(chip_is_xls_b0);
+EXPORT_SYMBOL(chip_is_xls6xx_b0);
+EXPORT_SYMBOL(chip_is_xls4xx_b0);
+
+/*Environment Vairables*/
+struct environment xlr_bldr_env;
+
+__u32 xlr_board_major_version = RMI_PHOENIX_BOARD_ARIZONA_I;
+__u32 xlr_board_minor_version = 0;
+
+#define DEFAULT_LINUX_CPU_MASK 0x1
+#define DEFAULT_LOADER_MASK ~DEFAULT_LINUX_CPU_MASK
+
+struct kuseg_mem_info kuseg_mem_map[MAX_NUM_KUSEG_BLOCKS];
+
+
+void *phoenix_psb_shm = 0;
+unsigned long phoenix_psb_shm_size = 0;
+static int dyna_exc_index = 0;
+extern unsigned long _text[];
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+unsigned long rmi_asid_mask = 0x3f;
+unsigned int rmi_shtlb = 1;	/* by default shared TLB is enabled */
+#endif
+
+extern struct psb_info *rmi_boot_info;
+struct psb_info *prom_info = 0;
+struct psb_info prom_info_copy;	/* Bootloader prom_info is saved here */
+static struct psb_info default_prom_info = {
+	.boot_level = 2,
+	.io_base = DEFAULT_PHOENIX_IO_BASE,
+	.output_device = 2,
+	.cpu_online_map = 0x01,
+	.magic_dword = (((__u64) 0x900dbeef << 32) | PSB_INFO_VERSION),
+	.size = sizeof(struct psb_info),
+	.mac_addr = 0x000102030405ULL,
+	.cpu_frequency = 1200000000,
+	.board_version = 1,
+	.board_major_version = 1,
+	.board_minor_version = 0,
+};
+
+static struct physmap_info {
+	int type;
+	char *name;
+} psb_physmap_info[] = {
+	{
+	0x01, "Memory"}, {
+	0x02, " *** HOLE ***"}, {
+	0x10, "Phoenix IO Space"}, {
+	0x11, "PCIX IO Space"}, {
+	0x12, "PCIX CFG Space"}, {
+	0x13, "PCIX Memory Space"}, {
+	0x14, "HT IO Space"}, {
+	0x15, "HT CFG Space"}, {
+	0x16, "HT Memory Space"}, {
+	0x17, "SRAM (QDR) Space"}, {
+	0x18, "Flash Controller Space"}, {
+	0xff, "Unknown type"}
+};
+
+struct boot_mem_map boot_physaddr_info;
+
+/* The below regions should be in ascending order of the starting physical addresses */
+static struct boot_mem_map_exclude_region dynamic_exclude_regions[] = {
+	[0] = {0, 0},		/* PCI Shared Mem Or RMIOS Lib Memory */
+	[1] = {0, 0},		/* PCI Shared Mem Or RMIOS Lib Memory */
+	[2] = {0, 0},		/* Loader KSEG0 region */
+	[3] = {0, 0},		/* Loader KUSEG region Block 1 */
+	[4] = {0, 0},		/* Loader KUSEG region Block 2 or Hybrid Mode exclusion */
+	[5] = {0, 0},		/* Loader KUSEG region Block 3 or Hybrid Mode exclusion */
+	[6] = {0, 0},		/* Loader KUSEG region Block 4 or Hybrid Mode exclusion */
+	[7] = {0, 0},		/* Hybrid Mode exclusion */
+	[8] = {0, 0},		/* END of the list - MUST be the last entry always */
+};
+
+static char *get_psb_physmap_name(int type)
+{
+	int i = 0;
+	int tsize = sizeof(psb_physmap_info) / sizeof(struct physmap_info);
+
+	for (i = 0; i < tsize; i++) {
+		if ((psb_physmap_info[i].type == type) ||
+		    (psb_physmap_info[i].type == 0xff))
+			return psb_physmap_info[i].name;
+	}
+	return ("Unknown type");
+}
+
+/* returns 1 for IO and 0 for mem 1 for not found */
+int phnx_get_pgprot(unsigned long address)
+{
+	int i;
+	__u64 start = 0, end = 0;
+	char *name = NULL;
+
+	for (i = 0; i < boot_physaddr_info.nr_map; i++) {
+		start = boot_physaddr_info.map[i].addr;
+		end =
+		    boot_physaddr_info.map[i].addr +
+		    boot_physaddr_info.map[i].size;
+		if ((address >= start) && (address < end)) {
+			name =
+			    get_psb_physmap_name(boot_physaddr_info.map[i].
+						 type);
+			if (!(strcmp(name, "Memory"))) {
+				return 0;
+			} else {
+				return 1;
+			}
+		}
+
+	}
+	return 1;
+}
+
+
+/* return 1 for success and 0 for failure */
+int valid_mmap_phnx_addr_range(unsigned long pfn)
+{
+	int i;
+	__u64 end = 0;
+	for (i = 0; i < boot_physaddr_info.nr_map; i++) {
+		end =
+		    boot_physaddr_info.map[i].addr +
+		    boot_physaddr_info.map[i].size;
+		end = end >> PAGE_SHIFT;
+		if (pfn <= (unsigned long) end)
+			return 1;
+	}
+	return 0;
+}
+
+static int sanity_check_prom_info(struct psb_info *info)
+{
+	if (!prom_info)
+		return 0;
+
+	if ((prom_info->magic_dword & 0xffffffffULL) != 0x900dbeef)
+		return 0;
+	if ((prom_info->magic_dword >> 32) != PSB_INFO_VERSION)
+		return 0;
+
+	return 1;
+}
+
+const char *DEFAULT_CONSOLE_BOOT_PARAMS = "console=ttyS0,38400 ";
+const char *DEFAULT_INITRD_BOOT_PARAMS = "rdinit=/sbin/init ";
+
+const char *get_system_type(void)
+{
+	if ( is_xls() )
+		return "RMI XLS";
+	return "RMI XLR";
+}
+
+
+#ifdef CONFIG_SMP
+atomic_t cpus_rebooted = ATOMIC_INIT(0);
+#endif
+
+#define GPIO_SWRESET_REG 8
+
+static void ptr_linux_exit(void)
+{
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_GPIO_OFFSET);
+
+	/* trigger a chip reset */
+	phoenix_write_reg(mmio, GPIO_SWRESET_REG, 1);
+	for (;;)
+		cpu_wait();
+}
+
+void __init bus_error_init(void)
+{
+}
+
+void prom_reconfigure_thr_resources(void)
+{
+	unsigned int mmu_setup = 0;
+	int value = 0;
+	__u32 online_map = prom_info->cpu_online_map;
+	__u32 thr_mask = online_map >> (phoenix_cpu_id() << 2);
+	int i = 0, count = 0;
+	int dis_contig = 0;
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+	uint32_t map;
+#endif
+
+
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+	/* rmi kernel configures this */
+
+
+	if (rmi_shtlb && (rmi_asid_mask == 0x3f)) {
+		/* global TLB will work only if all the cores enabled
+		   have all the threads owned by Linux. If not, fall back to
+		   the default mode.
+		 */
+		map = online_map;
+		for (i = 0; i < NR_CPUS; i += 4) {
+			if ((map & 0xf) && ((map & 0xf) != 0xf)) {
+				rmi_asid_mask = 0xff;
+				rmi_shtlb = 0;
+				printk("Disabling Shared TLB mode\n");
+				break;
+			}
+			map >>= 4;
+		}
+		if ((rmi_asid_mask == 0x3f) && (phoenix_thr_id() == 0)) {
+			mmu_setup = read_32bit_phnx_ctrl_reg(4, 0);
+			mmu_setup = mmu_setup | 0x1;
+			write_32bit_phnx_ctrl_reg(4, 0, mmu_setup);
+
+			printk("CPU %d: Enabled Shared TLB mode \n",
+			       phoenix_cpu_id());
+			return;
+		}
+	}
+	return;
+#endif
+
+	if (phoenix_thr_id() == 0) {
+
+		for (i = 0; i < 4; i++) {
+			if (thr_mask & (1 << i)) {
+				if (i != count)
+					dis_contig = 1;
+				count++;
+			}
+		}
+		switch (count) {
+		case 1:
+			value = 0x00;
+			break;
+		case 2:
+			value = 0x02;
+			break;
+		default:
+			value = 0x03;
+			break;
+		}
+		if (dis_contig)
+			value = 0x3;
+
+		mmu_setup = read_32bit_phnx_ctrl_reg(4, 0);
+		mmu_setup = mmu_setup & ~0x06;
+		mmu_setup |= (value << 1);
+
+		write_32bit_phnx_ctrl_reg(4, 0, mmu_setup);
+	}
+}
+
+int xlr_hybrid;
+int xlr_loader_support = 0;
+int xlr_loader_sharedcore = 0;
+int xlr_loader_own_gmac = 0;
+int xlr_loader_own_dma = 0;
+
+uint32_t xlr_linux_cpu_mask;
+static int xlr_console_pci_con_dev = 0;
+static int xlr_console_pci_con_baud = 0;
+static int xlr_boot_over_nfs = 0;
+
+unsigned long phnx_ebase = 0x0;
+
+static void xlr_initialize_setups(void)
+{
+	xlr_hybrid = XLR_HYBRID_NONE;
+	xlr_user_mac.l4_extract = 0;
+	xlr_user_mac.fast_syscall = 1;
+	xlr_loader_support = 0;
+	xlr_loader_sharedcore = 0;
+	xlr_loader_own_gmac = 0;
+	xlr_loader_own_dma = 0;
+	xlr_linux_cpu_mask = DEFAULT_LINUX_CPU_MASK;
+	phnx_loader_kseg_start = 0;
+	for (index = 0; index < MAX_NUM_KUSEG_BLOCKS; index++) {
+		kuseg_mem_map[index].start_addr = 0;
+		kuseg_mem_map[index].size = 0;
+	}
+	phnx_loader_kseg_size = 0;
+	phnx_loader_mask = DEFAULT_LOADER_MASK;
+}
+
+void exclude_hybrid_mem_region(void)
+{
+	if (xlr_loader_support)
+		return;
+	dynamic_exclude_regions[dyna_exc_index].start = 1 << 20;
+	dynamic_exclude_regions[dyna_exc_index].end =
+	    (unsigned long long) (((unsigned long) &_text) & 0x1fffffffUL);
+	dyna_exc_index++;
+}
+
+static void xlr_early_hybrid_setup(char *str)
+{
+
+	hybrid_str = str;
+
+	if ((strcmp(str, "=rmios_ipsec") == 0) ||
+	    (strcmp(str, "rmios_ipsec") == 0)) {
+		exclude_hybrid_mem_region();
+	} else if ((strcmp(str, "=rmios_tcpip_stack") == 0) ||
+		   (strcmp(str, "rmios_tcpip_stack") == 0)) {
+		exclude_hybrid_mem_region();
+	}
+}
+
+static int xlr_hybrid_setup(char *str)
+{
+	uint32_t loader_reg;
+	uint64_t kernel_start;
+
+	if ((strcmp(str, "=user_mac_xgmac") == 0) ||
+	    (strcmp(str, "user_mac_xgmac") == 0)) {
+		if (xlr_board_atx_ii()) {
+			xlr_hybrid = XLR_HYBRID_USER_MAC_XGMAC;
+			printk
+			    ("Configured for Hybrid mode with USER_MAC_XGMAC\n");
+		} else if (xlr_board_atx_i()) {
+			xlr_hybrid = XLR_HYBRID_USER_MAC_SPI4;
+			printk
+			    ("Configured for Hybrid mode with USER_MAC_SPI4\n");
+		} else {
+			printk
+			    ("user_mac_xgmac hybrid mode is available only on ATX-II\n");
+		}
+	} else if ((strcmp(str, "=user_mac") == 0)
+		   || (strcmp(str, "user_mac") == 0)) {
+		xlr_hybrid = XLR_HYBRID_USER_MAC;
+		printk("Configured for Hybrid mode with USER_MAC\n");
+	} else if ((strcmp(str, "=rmios_ipsec") == 0) ||
+		   (strcmp(str, "rmios_ipsec") == 0)) {
+		xlr_hybrid = XLR_HYBRID_RMIOS_IPSEC;
+		printk("Configured for Hybrid mode with RMIOS IPSEC\n");
+	} else if ((strcmp(str, "=rmios_tcpip_stack") == 0) ||
+		   (strcmp(str, "rmios_tcpip_stack") == 0)) {
+		xlr_hybrid = XLR_HYBRID_RMIOS_TCPIP_STACK;
+		kernel_start =
+		    (uint64_t) (((unsigned long) &_text) & 0x1fffffffUL);
+		if (kernel_start < PHNX_RMIOS_TCPIP_END) {
+			panic("Build kernel with loadaddress above %#x\n",
+			      PHNX_RMIOS_TCPIP_END);
+		}
+		printk
+		    ("Configured for Hybrid mode with RMIOS_TCPIP_STACK\n");
+	} else {
+		xlr_hybrid = XLR_HYBRID_NONE;
+		printk("Configured for Hybrid mode with None\n");
+	}
+
+	/* usermac or usermac xgmac cannot work with shared core */
+	if (xlr_hybrid_user_mac() || xlr_hybrid_user_mac_xgmac()) {
+		if (xlr_loader_support && xlr_loader_sharedcore) {
+			printk
+			    ("Disabling USER_MAC support:Cannot be enabled with shared_core option\n");
+			xlr_hybrid = XLR_HYBRID_NONE;
+		}
+	}
+
+	if ((xlr_hybrid != XLR_HYBRID_NONE) && (xlr_loader_support)) {
+		/* Don't allow loader feature if hybrid app and loader are
+		   using same memory region
+		 */
+		loader_reg =
+		    phnx_loader_kseg_start + phnx_loader_kseg_size;
+		if (xlr_hybrid == XLR_HYBRID_RMIOS_IPSEC) {
+			if (((PHNX_RMIOS_IPSEC_START >=
+			      phnx_loader_kseg_start)
+			     && (PHNX_RMIOS_IPSEC_END < loader_reg))
+			    ||
+			    ((phnx_loader_kseg_start >=
+			      PHNX_RMIOS_IPSEC_START)
+			     && (phnx_loader_kseg_start <
+				 PHNX_RMIOS_IPSEC_END))) {
+				xlr_loader_support = 0;
+				printk
+				    ("Disabling Loader support as hybrid mode is selected\n");
+				printk
+				    ("Use different memory range for loader KSEG region if hybrid mode needs to be enabled.\n");
+			}
+		} else if (xlr_hybrid == XLR_HYBRID_RMIOS_TCPIP_STACK) {
+			if (((PHNX_RMIOS_TCPIP_START >=
+			      phnx_loader_kseg_start)
+			     && (PHNX_RMIOS_TCPIP_END < loader_reg))
+			    ||
+			    ((phnx_loader_kseg_start >=
+			      PHNX_RMIOS_TCPIP_START)
+			     && (phnx_loader_kseg_start <
+				 PHNX_RMIOS_TCPIP_END))) {
+				xlr_loader_support = 0;
+				printk
+				    ("Use different memory range for loader KSEG region if hybrid mode needs to be enabled.\n");
+			}
+		}
+	}
+
+
+
+	return 1;
+}
+
+
+unsigned int __cpuinit get_c0_compare_int(void)
+{
+	return IRQ_TIMER;
+}
+
+void plat_time_init(void)
+{
+	extern void phoenix_timer_setup(void);
+	/* only needed for use cpu counter timer interrupt source */
+	mips_hpt_frequency = (unsigned int) prom_info->cpu_frequency;
+
+	phoenix_timer_setup();
+	dbg_msg("mips_hpt_frequency = %u\n", mips_hpt_frequency);
+}
+
+
+void __init plat_mem_setup(void)
+{
+	extern int panic_timeout;
+
+	panic_timeout = 5;
+
+	_machine_restart = (void (*)(char *)) ptr_linux_exit;
+	_machine_halt = ptr_linux_exit;
+	pm_power_off = ptr_linux_exit;
+
+	return;
+}
+
+/* Don't need a really big stack here */
+#define PER_CPU_THREAD_SIZE (THREAD_SIZE >> 2)
+#define TOTAL_THREAD_SIZE       (PER_CPU_THREAD_SIZE * (NR_CPUS - 1))
+/* This structure is used for changing sp and gp of secondary CPUs from that
+   of the bootloader and used until Linux kernel allocates one for them
+ */
+struct xlr_stack_pages {
+	unsigned long stack[(TOTAL_THREAD_SIZE) / sizeof(long)];
+};
+
+struct xlr_stack_pages xlr_stack_pages_temp
+    __attribute__ ((__section__(".data.init_task"),
+		    __aligned__(THREAD_SIZE)));
+
+
+extern void prom_pre_boot_secondary_cpus(void *);
+#define BOOT_LOADER_REGION_SZ 0x04000000
+#define LOADER_KSEG_END 0x10000000
+
+/* arg -> arg passed by user
+   name - pointer to the start of name=value string
+   base - conversion base 
+   res - converted number is stored here 
+	NOTE: returned value is a 32 bit number always
+   
+   Returns 0 on success, -1 otherwise
+   */
+static int get_name_value(char *arg, char *name, int base, uint32_t * res)
+{
+	char *ptr;
+
+	if ((ptr = strstr(arg, name)) == NULL)
+		return -1;
+
+	if (!strcmp("app_sh_mem_sz=", name)) {
+
+		printk
+		    ("WARNING: \"app_sh_mem_sz\"  option  is  deprecated\n");
+		printk
+		    ("WARNING: Use ./userapp shmem option to reserve app "
+		     "shared memory\n");
+		return -1;
+	}
+
+	ptr = strrchr(ptr, '=');
+	dprintk("ptr after strrchr = %s\n", ptr);
+	ptr++;
+	*res = (uint32_t) simple_strtol(ptr, (char **) NULL, base);
+	return 0;
+
+}
+
+struct phnx_name_value_struct {
+	char *name;
+	uint32_t *val;
+};
+static struct phnx_name_value_struct phnx_name_value_args[] = {
+	{"linux_cpu_mask=", &xlr_linux_cpu_mask},
+	{"kseg0_start=", &phnx_loader_kseg_start},
+	{"kseg0_size=", &phnx_loader_kseg_size},
+	{"app_sh_mem_sz=", &phnx_app_sh_mem_sz},
+	{NULL, NULL}
+};
+
+void parse_kuseg_mem_args(char *p)
+{
+	static int count = 0;
+	uint64_t start = 0, size = 0;
+
+	if (count == MAX_NUM_KUSEG_BLOCKS) {
+		printk
+		    ("The maximun number of kuseg block that can be allocated is %d so ignoring this %s\n",
+		     MAX_NUM_KUSEG_BLOCKS, p);
+		return;
+	}
+	p = p + strlen("kumem=");
+	size = memparse(p, &p);
+
+	if ((size == 0)
+	    || ((size & (((uint64_t) 2 << 20) - 1)) == (1 << 20)))
+		return;
+
+
+	kuseg_mem_map[count].size = size;
+
+	if (*p == '@') {
+		start = memparse(p + 1, &p);
+
+		/* start Addr should be the multiple of 2M */
+		if (((size & (((uint64_t) 2 << 20) - 1)) == (1 << 20)))
+			return;
+	}
+
+	kuseg_mem_map[count].start_addr = start;
+	count++;
+
+
+}
+
+void prom_parse_args(int argc, char *argv[])
+{
+	int i, j;
+	int ret;
+	char *tmp = NULL;
+	/* Check if loader support needs to be enabled */
+	for (i = 1; i < argc; i++) {
+		if (argv && argv[i]) {
+			if (strcmp(argv[i], "rmi_no_shtlb") == 0) {
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+				rmi_shtlb = 0;
+				rmi_asid_mask = 0xff;
+				printk("Disabling Shared TLB Support\n");
+#endif
+			} else if (strcmp(argv[i], "xlr_loader") == 0) {
+				xlr_loader_support = 1;
+#ifdef CONFIG_PHOENIX_GLOBAL_TLB_SPLIT_ASID
+				rmi_shtlb = 0;
+				rmi_asid_mask = 0xff;
+#endif
+				printk
+				    ("Enabling XLR Linux Loader support\n");
+			} else if (strcmp(argv[i], "shared_core") == 0) {
+				xlr_loader_sharedcore = 1;
+				printk
+				    ("Linux and RMIOS applications can run"
+				     "on same core\n");
+			} else if (strstr(argv[i], "kumem=") != NULL) {
+				parse_kuseg_mem_args(argv[i]);
+			} else if (strcmp(argv[i], "console=/dev/pci_co0")
+				   == 0) {
+				xlr_console_pci_con_dev = 1;
+			} else if (strcmp(argv[i], "console=pci_co,38400")
+				   == 0) {
+				xlr_console_pci_con_baud = 1;
+			} else if (strcmp(argv[i], "root=/dev/nfs") == 0) {
+				xlr_boot_over_nfs = 1;
+			} else if (strcmp(argv[i], "own_gmac") == 0) {
+				xlr_loader_own_gmac = 1;
+				printk("Linux will own gmac ports\n");
+			} else
+			    if (strncmp
+				(argv[i], "xlr_hybrid=",
+				 strlen("xlr_hybrid=")) == 0) {
+				/*Will parse this after loader arguments are parsed, as this
+				   has memory dependency on loader */
+				tmp = argv[i] + strlen("xlr_hybrid=");
+			} else {
+				j = 0;
+				while (phnx_name_value_args[j].name !=
+				       NULL) {
+					ret =
+					    get_name_value(argv[i],
+							   phnx_name_value_args
+							   [j].name, 16,
+							   phnx_name_value_args
+							   [j].val);
+					if (ret == 0)
+						break;
+					j++;
+				}
+			}
+		}
+	}
+	if (tmp) {
+		xlr_early_hybrid_setup(tmp);
+	}
+}
+
+void check_cpu_mask(void)
+{
+	uint32_t tmask, i;
+
+	if (!xlr_linux_cpu_mask)
+		xlr_linux_cpu_mask = 0x1;
+
+	/* trim to what is available */
+	xlr_linux_cpu_mask &= prom_info->cpu_online_map;
+	xlr_linux_cpu_mask |= (1U << hard_smp_processor_id());
+
+	/* Exclude CPUs that boot linux from the loader CPU mask */
+	phnx_loader_mask = ~xlr_linux_cpu_mask;
+	phnx_loader_mask &= prom_info->cpu_online_map;
+	/* Loader should not run on the same core, unless "sharedcore" option
+	   is enabled */
+	if (xlr_loader_sharedcore == 0) {
+		tmask = 0xf;
+		for (i = 0; i < 8; i++) {
+			if (tmask & xlr_linux_cpu_mask)
+				phnx_loader_mask &= ~tmask;
+			tmask = tmask << 4;
+		}
+	}
+	if (phnx_loader_mask == 0) {
+		xlr_loader_support = 0;
+		printk("Disabling loader support as loader mask is 0\n");
+		return;
+	}
+	printk("Using 0x%08x as linux cpu mask\n", xlr_linux_cpu_mask);
+	printk("Using 0x%08x as loader cpu mask\n", phnx_loader_mask);
+}
+
+#define LOADER_KSEG_DEFAULTS phnx_loader_kseg_start = PHNX_LOADER_KSEG0_START;\
+				phnx_loader_kseg_size = PHNX_LOADER_KSEG0_SIZE;
+extern char _end;
+static void check_kseg_args(void)
+{
+	if ((phnx_loader_kseg_start == 0) || (phnx_loader_kseg_size == 0)) {
+		/* no args passed */
+		LOADER_KSEG_DEFAULTS;
+		printk("No KSEG args passed. Using defaults\n");
+		return;
+	}
+	dprintk("Checking kseg start %x with _end %p\n",
+		phnx_loader_kseg_start, &_end);
+	if (((phnx_loader_kseg_start | CKSEG0) < (unsigned long) &_end)
+	    || (phnx_loader_kseg_start >= LOADER_KSEG_END)) {
+		printk("Invalid KSEG args passed. Using defaults\n");
+		printk
+		    ("Start cannot overlap with image or bootloader region\n");
+		LOADER_KSEG_DEFAULTS;
+		return;
+	}
+	if (phnx_loader_kseg_start & ((2 << 20) - 1)) {
+		/* Start not aligned at 2MB boundry */
+		printk("Invalid KSEG args passed. Using defaults\n");
+		printk("Start address not aligned at 2MB boundry\n");
+		LOADER_KSEG_DEFAULTS;
+		return;
+	}
+	if ((phnx_loader_kseg_start + phnx_loader_kseg_size) >
+	    LOADER_KSEG_END) {
+		printk("Invalid KSEG args passed. Using defaults\n");
+		printk("Bootloader region cannot be used\n");
+		LOADER_KSEG_DEFAULTS;
+		return;
+	}
+	printk("Using 0x%08x as KSEG0 load start and 0x%08x as size\n",
+	       phnx_loader_kseg_start, phnx_loader_kseg_size);
+
+}
+
+static void use_kuseg_defaults(struct boot_mem_map *map)
+{
+	int i = 0;
+	uint64_t start = PHNX_LOADER_KUSEG_PHYS_START;
+	uint64_t size = PHNX_LOADER_KUSEG_PHYS_SIZE;
+
+	for (i = 0; i < map->nr_map; i++) {
+		if (map->map[i].type != BOOT_MEM_RAM)
+			continue;
+		if (map->map[i].addr >= start)
+			break;
+	}
+	if (i == map->nr_map) {
+		/*found no memory!!! */
+		printk("\n***********WARNING**************");
+		printk("\nNO LOADER KUSEG REGION FOUND\n");
+		return;
+	}
+	start = map->map[i].addr;
+	size = map->map[i].size > size ? size : map->map[i].size;
+	kuseg_mem_map[0].start_addr = start;
+	kuseg_mem_map[0].size = size;
+	printk("\nUsing Kuseg Region %#llx@%#llx\n",
+	       (unsigned long long) kuseg_mem_map[0].size,
+	       (unsigned long long) kuseg_mem_map[0].start_addr);
+}
+
+#define LOADER_KUSEG_DEFAULTS   memset (kuseg_mem_map, 0, (sizeof(struct kuseg_mem_info) * 4));\
+				use_kuseg_defaults(map);
+
+static void check_kuseg_args(struct boot_mem_map *map)
+{
+	int i, j;
+	uint64_t end1, end2;
+
+	for (j = 0; j < MAX_NUM_KUSEG_BLOCKS; j++) {
+		/* if size is 0 ignore the entry */
+		if (kuseg_mem_map[j].size == 0)
+			continue;
+
+		if (kuseg_mem_map[j].start_addr < (512 << 20)) {	/* cannot be < 512MB */
+			printk
+			    ("Kuseg start should be > 512MB. Using defaults for start addr %llx\n",
+			     (unsigned long long) kuseg_mem_map[j].
+			     start_addr);
+			LOADER_KUSEG_DEFAULTS;
+			return;
+		}
+
+		end1 = kuseg_mem_map[j].start_addr + kuseg_mem_map[j].size;
+
+		for (i = 0; i < map->nr_map; i++) {
+			if (map->map[i].type != BOOT_MEM_RAM)
+				continue;
+			end2 = map->map[i].addr + map->map[i].size;
+			if ((kuseg_mem_map[j].start_addr >=
+			     map->map[i].addr) && (end1 <= end2))
+				break;
+		}
+		if (i == map->nr_map) {
+			printk
+			    ("Invalid KUSEG range passed. Using defaults\n");
+			LOADER_KUSEG_DEFAULTS;
+			return;
+		}
+		printk
+		    ("Using 0x%llx as KUSEG start and 0x%llx as KUSEG size\n",
+		     (unsigned long long) kuseg_mem_map[j].start_addr,
+		     (unsigned long long) kuseg_mem_map[j].size);
+	}
+	/* if no input is given , then use the default */
+	if (kuseg_mem_map[0].start_addr == 0) {
+		LOADER_KUSEG_DEFAULTS;
+	}
+}
+
+uint32_t align_shared_mem(uint32_t shared_mem)
+{
+	if (shared_mem <= (2 << 20))
+		return (2 << 20);
+	if (shared_mem <= (8 << 20))
+		return (8 << 20);
+	if (shared_mem <= (32 << 20))
+		return (32 << 20);
+	if (shared_mem <= (128 << 20))
+		return (128 << 20);
+	if (shared_mem <= (512 << 20))
+		return (512 << 20);
+	return (2 << 20);
+}
+
+static void prom_validate_loader_args(struct boot_mem_map *map)
+{
+	if (!xlr_loader_support)
+		return;
+	check_cpu_mask();
+	check_kseg_args();
+	check_kuseg_args(map);
+
+}
+
+/* The below regions should be in ascending order of the starting physical addresses */
+
+static struct boot_mem_map_exclude_region _exclude_regions[2][MAX_EXCLUDE +
+							      2];
+
+static struct boot_mem_map_exclude_region *exclude_regions =
+    _exclude_regions[1];
+
+static struct boot_mem_map_exclude_region static_exclude_regions[] = {
+	[0] = {0, 0},		/* END of the list - MUST be the last entry always */
+};
+
+static void prom_exclude_kseg(void)
+{
+	dynamic_exclude_regions[dyna_exc_index].start =
+	    (unsigned long long)
+	    1 << 20;
+	dynamic_exclude_regions[dyna_exc_index].end = (unsigned long long)
+	    (((unsigned long) &_text) & 0x1fffffffUL);
+	dyna_exc_index++;
+
+	dynamic_exclude_regions[dyna_exc_index].start =
+	    (unsigned long long)
+	    phnx_loader_kseg_start;
+	dynamic_exclude_regions[dyna_exc_index].end = (unsigned long long)
+	    (phnx_loader_kseg_start + phnx_loader_kseg_size);
+	dyna_exc_index++;
+}
+
+static void sort_kuseg_region(void)
+{
+	int i, j;
+	uint64_t temp_addr;
+	uint64_t temp_size;
+
+	for (i = 1; i < 4; i++) {
+		for (j = 0; j < i; j++) {
+			if (kuseg_mem_map[i].start_addr <
+			    kuseg_mem_map[j].start_addr) {
+				temp_addr = kuseg_mem_map[j].start_addr;
+				temp_size = kuseg_mem_map[j].size;
+				kuseg_mem_map[j].start_addr =
+				    kuseg_mem_map[i].start_addr;
+				kuseg_mem_map[j].size =
+				    kuseg_mem_map[i].size;
+				kuseg_mem_map[i].start_addr = temp_addr;
+				kuseg_mem_map[i].size = temp_size;
+			}
+		}
+	}
+}
+
+static void check_kuseg_region_overlap(void)
+{
+	int i, max;
+	uint64_t end1, end2;
+
+	max = MAX_NUM_KUSEG_BLOCKS - 1;
+
+	sort_kuseg_region();
+	for (i = 0; i < max; i++) {
+		end1 = kuseg_mem_map[i].start_addr + kuseg_mem_map[i].size;
+		if ((kuseg_mem_map[i + 1].start_addr <= end1)
+		    && (kuseg_mem_map[i].start_addr != 0)) {
+			end2 =
+			    kuseg_mem_map[i + 1].start_addr +
+			    kuseg_mem_map[i + 1].size;
+			if (end2 > end1)
+				kuseg_mem_map[i].size =
+				    end2 - kuseg_mem_map[i].start_addr;
+			kuseg_mem_map[i + 1].start_addr = 0;
+			kuseg_mem_map[i + 1].size = 0;
+			sort_kuseg_region();
+		}
+	}
+}
+
+static void prom_exclude_kuseg(void)
+{
+	int i = 0;
+	check_kuseg_region_overlap();
+
+	for (i = 0; i < MAX_NUM_KUSEG_BLOCKS; i++) {
+		if ((kuseg_mem_map[i].start_addr != 0)
+		    && (kuseg_mem_map[i].size != 0)) {
+			dynamic_exclude_regions[dyna_exc_index].start =
+			    kuseg_mem_map[i].start_addr;
+			dynamic_exclude_regions[dyna_exc_index].end =
+			    kuseg_mem_map[i].start_addr +
+			    kuseg_mem_map[i].size;
+			dyna_exc_index++;
+		}
+	}
+}
+
+void prom_exclude_pci_shmem(void)
+{
+	dynamic_exclude_regions[dyna_exc_index].start =
+	    PHNX_PCIX_SHARED_MEM_START;
+	dynamic_exclude_regions[dyna_exc_index].end =
+	    PHNX_PCIX_SHARED_MEM_END;
+	dyna_exc_index++;
+	printk("Excluding PCI Shared Memory\n");
+}
+
+void sort_dynamic_exclude_region(void)
+{
+	int i = 0;
+	int j = 0;
+	int max = 0;
+	struct boot_mem_map_exclude_region *list = dynamic_exclude_regions;
+
+	uint64_t start = 0;
+	uint64_t end = 0;
+
+	while (list[max].start != 0)
+		max++;
+
+	for (i = 0; i < max; i++) {
+		for (j = i; j < max; j++) {
+			if (list[i].start > list[j].start) {
+				start = list[i].start;
+				end = list[i].end;
+				list[i].start = list[j].start;
+				list[i].end = list[j].end;
+				list[j].start = start;
+				list[j].end = end;
+			}
+		}
+	}
+}
+
+static int merge_exclude_regions(struct boot_mem_map_exclude_region *,
+				 struct boot_mem_map_exclude_region *);
+
+void prom_update_exclude_region(void)
+{
+	int i;
+
+#ifdef CONFIG_PHOENIX_PCIX_GEN_DRIVER
+	if (xlr_get_pci_mode() == XLR_PCI_DEV_MODE) {
+		prom_exclude_pci_shmem();
+	}
+#endif
+
+	if (xlr_loader_support) {
+		prom_exclude_kseg();
+		prom_exclude_kuseg();
+	}
+
+	sort_dynamic_exclude_region();
+
+	exclude_regions = _exclude_regions[0];
+
+	/*
+	 * we assume that all exclude regions are sorted
+	 * to start with.
+	 */
+
+	merge_exclude_regions(exclude_regions, static_exclude_regions);
+	merge_exclude_regions(exclude_regions, dynamic_exclude_regions);
+
+	dprintk("Final exclude regions ----->\n");
+	for (i = 0; exclude_regions[i].start; i++) {
+		dprintk("%d: Start 0x%llx End 0x%llx\n", i,
+			exclude_regions[i].start, exclude_regions[i].end);
+	}
+}
+
+struct boot_mem_map prom_map;
+int use_default_phymem = 0;
+
+void read_prom_memory(void)
+{
+	struct boot_mem_map *map;
+
+	/* sanity check prom_info and it's mem_map fields */
+	if (!prom_info
+	    || (!prom_info->psb_mem_map && !prom_info->avail_mem_map))
+		goto use_default;
+
+	/* copy the mem_map from bootloader */
+	if (sizeof(*prom_info) <= prom_info->size
+	    && prom_info->avail_mem_map)
+		map =
+		    (struct boot_mem_map *) ((unsigned long) prom_info->
+					     avail_mem_map);
+	else
+		map =
+		    (struct boot_mem_map *) ((unsigned long) prom_info->
+					     psb_mem_map);
+
+	if (!(map->nr_map > 0 && map->nr_map <= 32))
+		goto use_default;
+	memcpy(&prom_map, map, sizeof(struct boot_mem_map));
+
+	return;
+
+      use_default:
+	use_default_phymem = 1;
+	return;
+}
+
+#define DEF_PHYMEM_START_ADDR 0x100000
+#define DEF_PHYMEM_SIZE 0x0ff00000
+
+static void prom_add_memory(void)
+{
+	int i = 0, j = 0;
+	__u64 start = 0, end = 0, exc_start = 0, exc_end = 0;
+	__u64 pref_backup = 512;
+
+	if (use_default_phymem)
+		goto use_default;
+
+	prom_validate_loader_args(&prom_map);
+
+	prom_update_exclude_region();
+
+	/* 
+	 * TODO: Need to remove this brain damaged hack. The bootloader passed 
+	 * memory map should indicate the bootloader memory as available.
+	 */
+	if (prom_map.map[0].size == 0x0c000000)
+		prom_map.map[0].size = 0x0ff00000;
+
+	for (i = 0; i < prom_map.nr_map; i++) {
+		start = prom_map.map[i].addr;
+		end = prom_map.map[i].addr + prom_map.map[i].size;
+
+		for (j = 0; j < MAX_EXCLUDE; j++) {
+			exc_start = exclude_regions[j].start;
+			exc_end = exclude_regions[j].end;
+
+			if ((exc_start == 0) && (exc_end == 0))	/* Empty slot */
+				continue;
+
+			if (exc_start >= start && exc_start < end) {
+				if (exc_start == start) {	/* Continuous exclude */
+					start = exc_end;
+					continue;
+				}
+				if (prom_map.map[i].type == BOOT_MEM_RAM) {
+					/*
+					 * memcpy/__copy_user prefetch, which
+					 * will cause a bus error for
+					 * KSEG/KUSEG addrs not backed by RAM.
+					 * Hence, reserve some padding for the
+					 * prefetch distance.
+					 */
+					if (exc_start - start >
+					    pref_backup) {
+						add_memory_region(start,
+								  exc_start
+								  - start -
+								  pref_backup,
+								  (long)
+								  prom_map.
+								  map[i].
+								  type);
+					}
+					start = exc_end;
+				}
+			} else if ((exc_start < start)
+				   && (exc_end > start)) {
+				/* Overlapping excludes */
+				start = exc_end;
+			}
+		}
+		if (start != end)
+			if (prom_map.map[i].type == BOOT_MEM_RAM) {
+				if (end - start > pref_backup)
+					add_memory_region(start,
+							  end - start -
+							  pref_backup,
+							  (long) prom_map.
+							  map[i].type);
+			}
+	}
+
+	return;
+
+      use_default:
+	printk("Using default physical memory map\n");
+	add_memory_region(DEF_PHYMEM_START_ADDR, DEF_PHYMEM_SIZE - pref_backup, (long) BOOT_MEM_RAM);	// 255m@1m
+	xlr_loader_support = 0;
+}
+
+static void psb_print_physmap(void)
+{
+	struct boot_mem_map *physaddr_map =
+	    (struct boot_mem_map *) ((unsigned long) prom_info->
+				     psb_physaddr_map);
+	char *name;
+	int i = 0;
+	int max;
+
+	if (physaddr_map == NULL)
+		return;
+
+	max = physaddr_map->nr_map;
+
+	prom_dbg_msg("Physical Address Map\n");
+	for (i = 0; i < max; i++) {
+		name = get_psb_physmap_name(physaddr_map->map[i].type);
+
+		prom_dbg_msg("\t%010llx --> %010llx ( %s )\n",
+			     (unsigned long long) physaddr_map->map[i].
+			     addr,
+			     (unsigned long long) (physaddr_map->map[i].
+						   addr +
+						   physaddr_map->map[i].
+						   size - 1), name);
+	}
+
+}
+
+static void save_physaddr_info(void)
+{
+	struct boot_mem_map *physaddr_map =
+	    (struct boot_mem_map *) ((unsigned long) prom_info->
+				     psb_physaddr_map);
+
+	if (physaddr_map == NULL)
+		return;
+
+	memcpy(&boot_physaddr_info, physaddr_map,
+	       sizeof(struct boot_mem_map));
+	return;
+}
+
+/* disable dedicated interrupt vector for virtual mips mode */
+void disable_divec(void)
+{
+	int i;
+	for (i = 0; i < NR_CPUS; i++)
+		cpu_data[i].options &= ~MIPS_CPU_DIVEC;
+
+	return;
+}
+
+extern void (*board_nmi_handler_setup) (void);
+
+void __init rmi_nmi_setup(void)
+{
+	/* setup nmi handler only if KGDB is enabled */
+}
+
+
+extern struct plat_smp_ops rmi_smp_ops;
+/*
+ * prom_init is called just after the cpu type is determined, from setup_arch()
+ */
+void __init prom_init(void)
+{
+	int i = 0;
+	int argc = (int) fw_arg0;
+	long temp;
+	char **argv;
+	char **envp;
+	int t_argc = argc;
+	char *n_argv[RMI_MAX_ARGS] = { NULL };
+	char *n_envp[RMI_MAX_ENVS] = { NULL };
+	struct psb_info *t_prom_info;
+	int32_t *t_argv;
+
+	void (*wakeup) (void *, void *, __u32);
+	__u32 wakeup_mask;
+
+	temp = (int) fw_arg1;
+	argv = (char **) temp;
+
+	temp = (int) fw_arg2;
+	envp = (char **) temp;
+
+	xlr_initialize_setups();
+
+	/* default mac addr */
+	phoenix_base_mac_addr[0] = 0x00;
+	phoenix_base_mac_addr[1] = 0x01;
+	phoenix_base_mac_addr[2] = 0x02;
+	phoenix_base_mac_addr[3] = 0x03;
+	phoenix_base_mac_addr[4] = 0x04;
+	phoenix_base_mac_addr[5] = 0x05;
+
+	phoenix_psb_shm = 0;
+
+	prom_info = &prom_info_copy;
+	temp = (int) fw_arg3;
+	prom_info = &prom_info_copy;
+	t_prom_info = (struct psb_info *) temp;
+	memcpy((void *) prom_info, (void *) t_prom_info,
+	       sizeof(struct psb_info));
+
+#ifdef RMI_BRIDGE_WKAROUND
+	if (prom_info->global_shmem_size == 0x1000) {
+		rmi_bridge_lock = (rmi_rwlock_t *) (unsigned long)
+		    (prom_info->global_shmem_addr + 0);
+		rmi_enable_br_wrkaround = 1;
+		printk("Enabling Bridge Workaround \n");
+	}
+#endif
+
+	/* Get the right 64bit pointers from bootloader args */
+	
+
+	t_argv = (int32_t *) argv;
+	for (i = 0; i < t_argc; i++, t_argv++) {
+		n_argv[i] =
+		    (char *) (unsigned long) (*t_argv);
+	}
+		
+	argc = t_argc;
+
+	/* Get the right env pointers */
+	if (envp != NULL) {
+		int32_t *t_envp;
+		t_envp = (int32_t *) envp;
+		for (i = 0; *t_envp; i++) {
+			n_envp[i] =
+			    (char *) (unsigned long) (*t_envp);
+			t_envp++;
+		}
+	}
+	
+
+	if (!sanity_check_prom_info(prom_info)) {
+		printk("Sanity Check failed on prom_info @ %p\n",
+		       prom_info);
+		if (prom_info) {
+			printk
+			    ("sizeof(psb_info) = %d, psb_info_version = %x, "
+			     "prom_info->magic_dword = %llx, prom_info->size = %llx\n",
+			     (unsigned int) sizeof(struct psb_info),
+			     PSB_INFO_VERSION,
+			     (unsigned long long) prom_info->magic_dword,
+			     (unsigned long long) prom_info->size);
+		}
+		prom_info = &default_prom_info;
+		goto parse_args;
+	}
+
+	/*Copy Environment variable */
+	if (prom_info->bldr_envp)
+		memcpy(&xlr_bldr_env,
+		       (void *) (unsigned long) prom_info->bldr_envp,
+		       sizeof(xlr_bldr_env));
+
+
+	xlr_board_major_version = prom_info->board_major_version;
+	xlr_board_minor_version = prom_info->board_minor_version;
+	prom_parse_args(argc, n_argv);
+
+	read_prom_memory();
+
+	phnx_ebase = read_c0_ebase() & (~((1 << 12) - 1));
+
+	psb_print_physmap();
+
+	save_physaddr_info();
+
+	prom_add_memory();
+
+	/* update the phoenix mac addr */
+	phoenix_base_mac_addr[0] = (prom_info->mac_addr >> 40) & 0xff;
+	phoenix_base_mac_addr[1] = (prom_info->mac_addr >> 32) & 0xff;
+	phoenix_base_mac_addr[2] = (prom_info->mac_addr >> 24) & 0xff;
+	phoenix_base_mac_addr[3] = (prom_info->mac_addr >> 16) & 0xff;
+	phoenix_base_mac_addr[4] = (prom_info->mac_addr >> 8) & 0xff;
+	phoenix_base_mac_addr[5] = (prom_info->mac_addr >> 0) & 0xff;
+
+	/* pull all the cpus out of the bootloader and force them to spin in 
+	 * prom_pre_boot_secondary_cpus
+	 */
+	wakeup =
+	    ((void (*)(void *, void *, __u32)) (unsigned long)
+	     (prom_info->wakeup));
+
+	smp_boot.online_map = (1 << hard_smp_processor_id());
+
+	if (xlr_loader_support) {
+		wakeup_mask = xlr_linux_cpu_mask | phnx_loader_mask;
+		if (wakeup != 0x0)
+			wakeup(prom_pre_boot_secondary_cpus, 0,
+			       wakeup_mask);
+	} else {
+		if (wakeup != 0x0)
+			wakeup(prom_pre_boot_secondary_cpus, 0,
+			       (__u32) prom_info->
+			       cpu_online_map & (~smp_boot.online_map));
+	}
+
+      parse_args:
+
+	for (i = 1; i < argc; i++) {
+		if (n_argv[i]) {
+			strcat(arcs_cmdline, n_argv[i]);
+			strcat(arcs_cmdline, " ");
+		} else
+			prom_dbg_msg("bad args, i=%d\n", i);
+	}
+	strcat(arcs_cmdline, " ");
+
+#ifdef CONFIG_PHOENIX_CONSOLE_OVER_PCI
+	if (!(xlr_board_atx_iii() || xlr_board_atx_v()) ||
+	    !(xlr_console_pci_con_baud && xlr_console_pci_con_dev))
+		strcat(arcs_cmdline, DEFAULT_CONSOLE_BOOT_PARAMS);
+#else
+	if ((strstr(arcs_cmdline, "console=")) == NULL)
+		strcat(arcs_cmdline, DEFAULT_CONSOLE_BOOT_PARAMS);
+#endif
+	strcat(arcs_cmdline, " ");
+
+#ifdef CONFIG_ROOT_NFS
+	if (!xlr_boot_over_nfs)
+		strcat(arcs_cmdline, DEFAULT_INITRD_BOOT_PARAMS);
+#else
+	strcat(arcs_cmdline, DEFAULT_INITRD_BOOT_PARAMS);
+#endif
+	strcat(arcs_cmdline, " ");
+
+	for (i = 0; n_envp[i]; i++) {
+		if (strcmp(n_envp[i], "") == 0)
+			break;
+	}
+
+#ifdef DEBUG
+	printk("MAC ADDR BASE: %02x:%02x:%02x:%02x:%02x:%02x\n",
+	       phoenix_base_mac_addr[0], phoenix_base_mac_addr[1],
+	       phoenix_base_mac_addr[2], phoenix_base_mac_addr[3],
+	       phoenix_base_mac_addr[4], phoenix_base_mac_addr[5]);
+#endif
+	if (hybrid_str != NULL)
+		xlr_hybrid_setup(hybrid_str);
+
+	config_net_init();
+	board_nmi_handler_setup = rmi_nmi_setup;
+
+	on_chip_init();
+	prom_reconfigure_thr_resources();
+
+	register_smp_ops(&rmi_smp_ops);
+}
+
+void prom_free_prom_memory(void)
+{
+	/* nothing to free */
+}
+
+void read_cp0_regs(void)
+{
+	printk("[%s]: count = 0x%x, compare = 0x%x\n"
+	       "status = 0x%x, cause = 0x%x\n"
+	       "eimr = 0x%llx, eirr = 0x%llx\n",
+	       __FUNCTION__,
+	       read_c0_count(),
+	       read_c0_compare(),
+	       read_c0_status(),
+	       read_c0_cause(),
+	       (unsigned long long) read_64bit_cp0_eimr(),
+	       (unsigned long long) read_64bit_cp0_eirr()
+	    );
+}
+
+struct boot_mem_map_entry *psb_get_physaddr_base_address(unsigned long
+							 type)
+{
+	struct boot_mem_map *physaddr_map =
+	    (struct boot_mem_map *) ((unsigned long) prom_info->
+				     psb_physaddr_map);
+
+	int i = 0;
+	int max = physaddr_map->nr_map;
+
+	for (i = 0; i < max; i++) {
+		if (physaddr_map->map[i].type == type)
+			return (physaddr_map->map);
+	}
+	return NULL;
+}
+
+void static add_region(struct boot_mem_map_exclude_region *x, int *k,
+		       uint64_t start, uint64_t end)
+{
+	if (*k > MAX_EXCLUDE) {
+		printk("No of exclude regions = %d; Cannot add more\n",
+		       MAX_EXCLUDE);
+		return;
+	}
+
+	if (start < x[*k - 1].end) 
+		return;
+
+	x[*k].start = start;
+	x[*k].end = end;
+	++*k;
+}
+
+static int merge_exclude_regions(struct boot_mem_map_exclude_region *x,
+				 struct boot_mem_map_exclude_region *y)
+{
+	static int _index = 0;
+	int i, j, k;
+
+	i = j = 0;
+	k = 1;
+
+	while (x[i].start != 0 && y[j].start != 0) {
+		if (x[i].start < y[j].start) {
+			add_region(_exclude_regions[_index], &k,
+				   x[i].start, x[i].end);
+			++i;
+		} else {
+			add_region(_exclude_regions[_index], &k,
+				   y[j].start, y[j].end);
+			++j;
+		}
+	}
+
+	if (x[i].start == 0) {
+		while (y[j].start) {
+			add_region(_exclude_regions[_index], &k,
+				   y[j].start, y[j].end);
+			++j;
+		}
+	} else if (y[j].start == 0) {
+		while (x[i].start) {
+			add_region(_exclude_regions[_index], &k,
+				   x[i].start, x[i].end);
+			++i;
+		}
+	}
+
+	exclude_regions = &_exclude_regions[_index][1];
+	_index = _index ? 0 : 1;
+
+	return 0;
+}
+
+
+#ifdef CONFIG_EARLY_PRINTK
+void prom_putchar(char c)
+{
+	void (*putchar) (char);
+	putchar =
+	    ((void (*)(char c)) (unsigned long) (prom_info->uart_putchar));
+	putchar(c);
+}
+
+#endif
+
+static int __init rmi_proc_setup(void)
+{
+
+	rmi_root_proc = proc_mkdir("rmi", 0);
+
+	if (!rmi_root_proc)
+		return -ENOMEM;
+
+	return 0;
+}
+
+rootfs_initcall(rmi_proc_setup);
-- 
1.6.0.4

