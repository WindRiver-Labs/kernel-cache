From 4c4cfdbf7a053a18cadf4f04825e9d4b2ce23a38 Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Fri, 21 May 2010 13:07:28 +0800
Subject: [PATCH 36/38] nlm_xls_atx_64_be: feature ip flow affinity

Experimental feature of GMAC driver guranteeing that IP flows are processed
on logical CPUs corresponding to buckets assigned by packet classifier engine.

E.g. for XLR core N, packets arriving to buckets 0 & 4 are processed by
thread 0, packets arriving to buckets 1 & 5 are processed by thread 1 and
so on..

Such feature might be important for applications which require IP flows
be seen on one logcal CPUs. Use of this feature involves performance cost.

This patch is from RMI SDK 1.7.0

Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 arch/mips/include/asm/rmi/interrupt.h |    7 +++
 arch/mips/rmi/Kconfig                 |   14 +++++
 arch/mips/rmi/phoenix/irq.c           |   14 +++++
 arch/mips/rmi/phoenix/smp.c           |   25 +++++++++-
 drivers/net/phoenix_mac.c             |   92 +++++++++++++++++++++++++++++++++
 5 files changed, 151 insertions(+), 1 deletions(-)

diff --git a/arch/mips/include/asm/rmi/interrupt.h b/arch/mips/include/asm/rmi/interrupt.h
index 5e44062..4fa6fcd 100644
--- a/arch/mips/include/asm/rmi/interrupt.h
+++ b/arch/mips/include/asm/rmi/interrupt.h
@@ -47,6 +47,13 @@
 #define IRQ_IPI_CRF_MGMT_IPI	45 /* */
 #define IRQ_IPI_CRF_EVENTQ_IPI 46 
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+
+#define IRQ_IPI_NETRX           49
+#define SMP_NETRX_IPI           32
+
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
 
 #define SMP_CALL_KGDB_HOOK 	8
 #define SMP_OPROFILE_IPI        16
diff --git a/arch/mips/rmi/Kconfig b/arch/mips/rmi/Kconfig
index f78d74b..c9d9d1c 100644
--- a/arch/mips/rmi/Kconfig
+++ b/arch/mips/rmi/Kconfig
@@ -71,6 +71,20 @@ config PHOENIX_HW_BUFFER_MGMT
 	  If in doubt, say N.
 
 
+config PHOENIX_IP_FLOW_AFFINITY
+	bool "Enable support for IP flow affinity"
+	depends on RMI_PHOENIX
+	default n
+	help
+	  Experimental feature of GMAC driver guranteeing that IP flows are processed 
+	  on logical CPUs corresponding to buckets assigned by packet classifier engine.
+	  E.g. for XLR core #X, packets arriving to buckets 0 & 4 are processed by thread 0,
+	  packets arriving to buckets 1 & 5 are processed by thread 1 and so on..
+	  Such feature might be important for applications which require IP flows 
+	  be seen on one logcal CPUs. Use of this feature involves performance cost.
+
+	  If in doubt, say N.
+
 config RMI_PHOENIX_LOAD_ADDRESS
 	hex "RMI Linux kernel start address"
 	depends on RMI_PHOENIX
diff --git a/arch/mips/rmi/phoenix/irq.c b/arch/mips/rmi/phoenix/irq.c
index de80aed..38505f8 100644
--- a/arch/mips/rmi/phoenix/irq.c
+++ b/arch/mips/rmi/phoenix/irq.c
@@ -421,6 +421,14 @@ void __init init_phoenix_irqs(void)
 
 	phnx_irq_mask |=
 		((1ULL << IRQ_IPI_SMP_FUNCTION) | (1ULL << IRQ_IPI_SMP_RESCHEDULE));
+
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	/* PR: New IPI added here for netrx balancing */
+	irq_desc[IRQ_IPI_NETRX].chip = &phnx_rsvd_pic;
+	irq_desc[IRQ_IPI_NETRX].action = &phnx_rsvd_action;
+	phnx_irq_mask |= (1ULL<<IRQ_IPI_NETRX);
+#endif
+
 #endif
 
 	/* msgring interrupt */
@@ -454,7 +462,13 @@ extern irqreturn_t xlr_kgdb_ipi_handler(int irq, struct pt_regs *regs);
 void do_phnx_IRQ(unsigned int irq, struct pt_regs *regs)
 {
 #ifdef CONFIG_SMP
+
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	if (irq == IRQ_IPI_SMP_FUNCTION || irq == IRQ_IPI_SMP_RESCHEDULE 
+			|| irq== IRQ_IPI_NETRX) {
+#else
 	if (irq == IRQ_IPI_SMP_FUNCTION || irq == IRQ_IPI_SMP_RESCHEDULE) {
+#endif
 		phoenix_ipi_handler(irq, regs);
 		return;
 	}
diff --git a/arch/mips/rmi/phoenix/smp.c b/arch/mips/rmi/phoenix/smp.c
index 3a0adae..baf5b7c 100644
--- a/arch/mips/rmi/phoenix/smp.c
+++ b/arch/mips/rmi/phoenix/smp.c
@@ -43,6 +43,10 @@
 
 /* #define IPI_PRINTK_DEBUG */
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+extern void skb_transfer_finish(void);
+#endif
+
 /* ipi statistics counters for debugging */
 __u32 ipi_3_counter_tx[NR_CPUS][NR_CPUS];
 __u32 ipi_3_counter_rx[NR_CPUS];
@@ -86,6 +90,17 @@ void core_send_ipi(int logical_cpu, unsigned int action)
 		printk("Sending KGDB IPI 0x%08x to tid %d pid %d\n", ipi, tid, pid);
 #endif
 	}
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	else if (action & SMP_NETRX_IPI)
+	{
+		ipi = (tid << 16) | (pid << 20) | IRQ_IPI_NETRX;
+#ifdef IPI_PRINTK_DEBUG
+		printk(KERN_ALERT "%s: Sending NETRX IPI 0x%08x to tid %d pid %d\n",
+                 __FUNCTION__, ipi, tid, pid);
+#endif /* IPI_PRINTK_DEBUG */
+	}
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
 	else
 		BUG();
   
@@ -107,7 +122,15 @@ void phoenix_ipi_handler(int irq, struct pt_regs *regs)
 		++ipi_3_counter_rx[smp_processor_id()];
 		smp_call_function_interrupt();
 	}
-
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+	else if (irq == IRQ_IPI_NETRX)
+	{
+		irq_enter();
+		skb_transfer_finish();
+		/* run soft IRQ at the end */
+		irq_exit();
+	}
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
 	else {
 #ifdef IPI_PRINTK_DEBUG
 		printk("[%s]: cpu_%d processing ipi_%d\n", __FUNCTION__, 
diff --git a/drivers/net/phoenix_mac.c b/drivers/net/phoenix_mac.c
index 4d14378..bf6b90d 100644
--- a/drivers/net/phoenix_mac.c
+++ b/drivers/net/phoenix_mac.c
@@ -332,6 +332,30 @@ static inline void prefetch_local(const void *addr)
 
 
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+/* skb transfer statistics */
+unsigned long long skb_transfer_stat[NR_CPUS][NR_CPUS];
+void skb_transfer_finish(void);
+static void skb_transfer(int bucket, struct sk_buff *skb);
+
+
+/* skb transfer queues, one per CPU */
+static struct sk_buff_head cpu_skb_tqueue[NR_CPUS];
+
+static void
+cpu_tx_queue_init(void)
+{
+	int i;
+
+	for (i = 0; i < NR_CPUS; i++)
+	{
+		skb_queue_head_init(&(cpu_skb_tqueue[i]));
+	}
+}
+
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
+
+
 /* This message ring interrupt type, can be adjusted by NAPI setup callback */
 extern int msgring_int_type;
 extern struct user_mac_data *user_mac;
@@ -2632,8 +2656,12 @@ do { \
 				 (read_c0_count() - msgrng_msg_cycles));
 
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+		skb_transfer(bucket, skb);
+#else
 		skb->dev->last_rx = jiffies;
 		netif_rx(skb);
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
 
 	} else {
 		printk("[%s]: unrecognized ctrl=%d!\n", __FUNCTION__,
@@ -2758,6 +2786,66 @@ void rmi_phnx_station_unowned_msgring_handler(int bucket, int size,
 }
 
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+extern void core_send_ipi(int cpu, unsigned int action);
+
+static void
+skb_transfer(int bucket, struct sk_buff *skb)
+{
+	u_long my_cpu_no, my_thread_no, my_core_no, target_cpu_no, target_thread_no;
+
+
+	target_thread_no = bucket & 0x3;
+	my_cpu_no = smp_processor_id();
+	my_thread_no = phoenix_thr_id();
+	my_core_no = phoenix_cpu_id();
+	target_cpu_no = cpu_number_map((my_core_no << 2) | target_thread_no);
+
+  /*
+   * Version with NETRX IPI aggregation
+  */
+	if (target_thread_no != my_thread_no && cpu_isset(target_cpu_no, cpu_online_map))
+	{
+		unsigned long flags;
+		struct sk_buff_head *ptqueue = &cpu_skb_tqueue[target_cpu_no];
+
+		spin_lock_irqsave(&ptqueue->lock, flags);
+		if (ptqueue->qlen)
+		{
+			__skb_queue_tail(ptqueue, skb);
+		}
+		else{
+			__skb_queue_tail(ptqueue, skb);
+			core_send_ipi(target_cpu_no, SMP_NETRX_IPI);
+		}
+		spin_unlock_irqrestore(&ptqueue->lock, flags);
+
+		skb_transfer_stat[my_cpu_no][target_cpu_no]++;
+	}
+	else{
+		skb_transfer_stat[my_cpu_no][my_cpu_no]++;
+
+		skb_queue_tail(&cpu_skb_tqueue[my_cpu_no], skb);
+		skb_transfer_finish();
+	}
+}
+
+
+/* second part of SKB transfer logic, called from IRQ_IPI_NETRX handler */
+void
+skb_transfer_finish(void)
+{
+	struct sk_buff *skb;
+	u_long cpu = smp_processor_id();
+
+	while ((skb = skb_dequeue(&cpu_skb_tqueue[cpu])) != NULL)
+	{
+		skb->dev->last_rx = jiffies;
+		netif_rx(skb);
+	}
+}
+
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
 
 
 /**********************************************************************
@@ -4388,6 +4476,10 @@ int rmi_phnx_mac_init_module(void)
 		priv->phy.serdes_addr =
 		    mac_addr_to_ptr(port_cfg->serdes_addr);
 
+#ifdef CONFIG_PHOENIX_IP_FLOW_AFFINITY
+		/* initialize cpu skb queues */
+		cpu_tx_queue_init();
+#endif /* CONFIG_PHOENIX_IP_FLOW_AFFINITY */
 
 		phnx_mac_get_hwaddr(dev);
 
-- 
1.6.5.2

