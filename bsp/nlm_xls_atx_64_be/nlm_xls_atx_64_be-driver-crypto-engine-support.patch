From 0baa29fec1467829b12e3b25c166e03395d2322c Mon Sep 17 00:00:00 2001
From: Jack Tan <jack.tan@windriver.com>
Date: Fri, 21 May 2010 13:07:28 +0800
Subject: [PATCH 32/38] nlm_xls_atx_64_be: driver crypto engine support

Crypto engine driver

This patch is from RMI SDK 1.7.0

Signed-off-by: Jack Tan <jack.tan@windriver.com>
---
 arch/mips/rmi/phoenix/on_chip.c             |    4 +
 arch/mips/rmi/ptr/setup.c                   |    4 +
 crypto/Makefile                             |    1 +
 crypto/phoenix_sec.c                        |  224 ++
 drivers/crypto/Kconfig                      |   11 +
 drivers/crypto/Makefile                     |    1 +
 drivers/crypto/rmi/Makefile                 |   31 +
 drivers/crypto/rmi/common/rmisae.h          |  493 ++++
 drivers/crypto/rmi/common/rmisec_internal.h |  968 +++++++
 drivers/crypto/rmi/common/sec_api.c         | 3898 +++++++++++++++++++++++++++
 drivers/crypto/rmi/common/utils.h           |   85 +
 drivers/crypto/rmi/ecc_ucode_data.h         |  363 +++
 drivers/crypto/rmi/rmi_state_info.h         |  144 +
 drivers/crypto/rmi/rmisec.c                 | 2286 ++++++++++++++++
 14 files changed, 8513 insertions(+), 0 deletions(-)
 create mode 100644 crypto/phoenix_sec.c
 create mode 100644 drivers/crypto/rmi/Makefile
 create mode 100644 drivers/crypto/rmi/common/rmisae.h
 create mode 100644 drivers/crypto/rmi/common/rmisec_internal.h
 create mode 100644 drivers/crypto/rmi/common/sec_api.c
 create mode 100644 drivers/crypto/rmi/common/utils.h
 create mode 100644 drivers/crypto/rmi/ecc_ucode_data.h
 create mode 100644 drivers/crypto/rmi/rmi_state_info.h
 create mode 100644 drivers/crypto/rmi/rmisec.c

diff --git a/arch/mips/rmi/phoenix/on_chip.c b/arch/mips/rmi/phoenix/on_chip.c
index b5463a0..329911d 100644
--- a/arch/mips/rmi/phoenix/on_chip.c
+++ b/arch/mips/rmi/phoenix/on_chip.c
@@ -108,6 +108,7 @@ __u32 pop_bucket_start[NR_CORES];
 __u32 pop_bucket_end[NR_CORES];
 __u32 cpu_to_bktmask[NR_CPUS];
 __u32 cpu_to_frstid[NR_CPUS];
+EXPORT_SYMBOL(cpu_to_frstid);
 
 uint32_t hard_cpu_online_map = 0;
 uint32_t msgring_global_thread_mask = 0;
@@ -117,6 +118,8 @@ spinlock_t msgrng_lock;
 static phnx_atomic_t msgring_registered;
 
 int msgring_int_type;
+EXPORT_SYMBOL(msgring_int_type);
+
 int msgring_int_en;
 int msgring_watermark_count;
 static __u32 msgring_thread_mask;
@@ -582,6 +585,7 @@ void phnx_msgring_int_handler(unsigned int irq, struct pt_regs *regs)
 	/* Call the msg callback */
 	irq_exit();
 }
+EXPORT_SYMBOL(phnx_msgring_int_handler);
 
 static void enable_msgring_int(void *info)
 {
diff --git a/arch/mips/rmi/ptr/setup.c b/arch/mips/rmi/ptr/setup.c
index a83da7a..7fb2742 100644
--- a/arch/mips/rmi/ptr/setup.c
+++ b/arch/mips/rmi/ptr/setup.c
@@ -358,8 +358,12 @@ void prom_reconfigure_thr_resources(void)
 }
 
 int xlr_hybrid;
+
 int xlr_loader_support = 0;
 int xlr_loader_sharedcore = 0;
+EXPORT_SYMBOL(xlr_loader_support);
+EXPORT_SYMBOL(xlr_loader_sharedcore);
+
 int xlr_loader_own_gmac = 0;
 int xlr_loader_own_dma = 0;
 
diff --git a/crypto/Makefile b/crypto/Makefile
index e8f2c61..6552a58 100644
--- a/crypto/Makefile
+++ b/crypto/Makefile
@@ -85,6 +85,7 @@ obj-$(CONFIG_CRYPTO_RNG2) += krng.o
 obj-$(CONFIG_CRYPTO_ANSI_CPRNG) += ansi_cprng.o
 obj-$(CONFIG_CRYPTO_TEST) += tcrypt.o
 obj-$(CONFIG_CRYPTO_GHASH) += ghash-generic.o
+obj-$(CONFIG_PHOENIX_IPSEC_SEC_OFFLOAD) += phoenix_sec.o
 
 obj-$(CONFIG_OCF_OCF) += ocf/
 
diff --git a/crypto/phoenix_sec.c b/crypto/phoenix_sec.c
new file mode 100644
index 0000000..796c71e
--- /dev/null
+++ b/crypto/phoenix_sec.c
@@ -0,0 +1,224 @@
+/*********************************************************************
+
+  Copyright 2003-2006 RMI Corporation, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+#include <net/ip.h>
+#include <net/xfrm.h>
+#include <net/ah.h>
+#include <net/icmp.h>
+#include <linux/crypto.h>
+
+#include <asm/io.h>
+
+#include <asm/rmi/debug.h>
+#include <asm/rmi/phoenix_sec.h>
+
+#define NUM_CHUNKS(size, bits) ( ((size)>>(bits)) + (((size)&((1<<(bits))-1))?1:0) )
+//#define DEBUG
+
+static u8 tmp_auth_data[MAX_AH_AUTH_LEN] __cacheline_aligned;
+static PacketDescriptor_t pkt_descs[NR_CPUS] __cacheline_aligned;
+static ControlDescriptor_t ctrl_descs[NR_CPUS] __cacheline_aligned;
+
+static spinlock_t msgrng_lock;
+
+void phoenix_ah_hmac_digest(struct ah_data *ahp, struct sk_buff *skb, u8 *auth_data)
+{
+	struct crypto_tfm *tfm = ahp->tfm;
+	u8 *key = ahp->key;
+	unsigned int keylen = ahp->key_len;
+	
+	int len_dwords=0;
+	PacketDescriptor_t *pkt_desc = &pkt_descs[smp_processor_id()];
+	ControlDescriptor_t *ctrl_desc = &ctrl_descs[smp_processor_id()];
+	unsigned long addr = virt_to_phys(skb->data);
+	int offset = addr - (addr & ~(SMP_CACHE_BYTES - 1));
+	int len=0, len_lastdword_remainder=0;
+	int ctrl_desc_size=0, ctrl_len_cachelines=0;
+	int i=0;
+	struct msgrng_msg msg;
+	int size=0, code=0, stid=0;
+	unsigned long flags=0, msgrng_flags=0;
+
+#ifdef DEBUG
+        {
+	  dbg_msg("Expected auth result:\n");
+	  for(i=0;i<ahp->icv_trunc_len;i++) {
+	    printk("%02x ", auth_data[i]);
+	    if (i && (i % 16) == 0) printk("\n");
+	  }
+	  printk("\n");
+        }
+#endif	
+	/* zero out the destination auth field */
+	memset(auth_data, 0, ahp->icv_trunc_len);
+
+	/* zero out the tmp auth field */
+	//memset(tmp_auth_data, 0, ahp->icv_trunc_len);
+	
+	/* no big keys support */
+	if ( (keylen > crypto_tfm_alg_blocksize(tfm)) || (keylen & 0x07) ) {
+	  dbg_msg("keylen(=%d) > algo_blocksize(%d) or unaligned keylen\n", 
+		 keylen, crypto_tfm_alg_blocksize(tfm));
+	  return;
+	}
+#if 0
+	/* no packet fragments support */
+	if (skb_shinfo(skb)->nr_frags != 1) {
+	  dbg_msg("fragmented packets (#frags=%d) not supported\n", 
+		  skb_shinfo(skb)->nr_frags);
+	  return;
+	}
+#endif	
+	len = skb->len + offset;
+	len_dwords = NUM_CHUNKS(len, 3);
+	len_lastdword_remainder = len & 0x07;
+
+#ifdef DEBUG
+	dbg_msg("ctrl_desc=%p, pkt_desc=%p, addr=%lx, offset=%d, len=%d, len_dwords=%d\n", 
+		ctrl_desc, pkt_desc, addr, offset, skb->len, len_dwords);
+#endif
+
+	/* Construct the packet descriptor */
+	pkt_desc->srcLengthIVOffUseIVNext = ( ((uint64_t)1 << 63) | 
+					      ((uint64_t)1 << 62) |
+					      ((uint64_t)len_lastdword_remainder << 59) |
+					      (((uint64_t)len_dwords & 0xeff)<<43) |  
+					      ((uint64_t)addr & ~(SMP_CACHE_BYTES - 1)) |
+					      ((uint64_t)offset & 0x07)
+					      );
+	pkt_desc->dstLLWMask = 0;
+	pkt_desc->authDst = (uint64_t)virt_to_phys(tmp_auth_data);
+	pkt_desc->ckSumDst = 0;
+  
+	memset(ctrl_desc, 0, sizeof(ControlDescriptor_t));
+	/* Construct the control descriptor */
+	ctrl_desc->instruction = ( ((uint64_t)(offset >> 3) << 18) |
+				   ((uint64_t)1 << 20) |
+				   ((uint64_t)HASH_MD5 << 21) |
+				   ((uint64_t)1 << 23) |
+				   ((uint64_t)1 << 36)
+				   );
+	len_dwords = NUM_CHUNKS(keylen, 3);
+	for(i=0;i<len_dwords;i++)
+	  ctrl_desc->cipherHashInfo.infoDwords[i] = *((uint64_t *)&key[i<<3]);
+	ctrl_desc_size = 9<<3;
+
+#ifdef DEBUG
+	{      
+	  dbg_msg("ctrl_desc_size=%d, ctrl_desc->instr=%llx, pkt_desc<%llx,%llx,%llx,%llx>\n",
+		  ctrl_desc_size, ctrl_desc->instruction, 
+		  pkt_desc->srcLengthIVOffUseIVNext, pkt_desc->dstLLWMask,
+		  pkt_desc->authDst, pkt_desc->ckSumDst);
+	}
+#endif
+	
+	/* Send the message to the sec_engine */
+	ctrl_len_cachelines = NUM_CHUNKS(ctrl_desc_size, 5);
+	stid = make_sec_desc(&msg, ctrl_desc, ctrl_len_cachelines, pkt_desc);	  
+
+#ifdef DEBUG	
+	dbg_msg("cachelines=%d, ctrl_desc=%p, pkt_desc=%p, ctrl_desc->instr=%llx, "
+		"pkt_desc<%llx,%llx,%llx,%llx>\n",
+		ctrl_len_cachelines, ctrl_desc, pkt_desc, ctrl_desc->instruction, 
+		pkt_desc->srcLengthIVOffUseIVNext, pkt_desc->dstLLWMask,
+		pkt_desc->authDst, pkt_desc->ckSumDst);
+#endif
+	
+	msgrng_access_save(&msgrng_lock, flags, msgrng_flags);
+
+	while (message_send(2, MSGRNG_CODE_SEC, stid, &msg));
+	
+	/* Wait for the response */
+	for(;;) {
+	  int bucket = (cpu_logical_map(smp_processor_id()) & 0x03) + 4;
+	  int ctrl_err=0, pkt_err=0;
+#ifdef DEBUG	  
+	  dbg_msg("waiting for a response from sec engine (bucket=%x)...\n", bucket);
+#endif
+	  msgrng_wait(1 << bucket);
+
+	  if (message_receive(bucket, &size, &code, &stid, &msg)) 
+	    continue;
+
+	  ctrl_desc = (ControlDescriptor_t *)phys_to_virt(msg.msg0 & 0xffffffffe0ULL);
+	  pkt_desc = (PacketDescriptor_t *)phys_to_virt(msg.msg1 & 0xffffffffe0ULL);
+	  
+	  ctrl_err = (msg.msg0 >> 40) & 0x1ff;
+	  pkt_err = (msg.msg1 >> 40) & 0x1ff;
+	  if (ctrl_err || pkt_err) {
+	    dbg_msg("error (ctrl_err=%x, pkt_err=%x) reported by sec_engine\n", 
+		   ctrl_err, pkt_err);
+	    goto out;
+	  }
+
+	  /* copy the auth result */
+	  if (pkt_desc->authDst != (uint64_t)virt_to_phys(tmp_auth_data)) {
+	    dbg_msg("bad authDst in sec engine response\n");
+	    goto out;
+	  }
+	  
+	  memcpy(auth_data, tmp_auth_data, ahp->icv_trunc_len);
+#ifdef DEBUG
+	  {
+	    dbg_msg("sec engine auth result:\n");
+	    for(i=0;i<ahp->icv_trunc_len;i++) {
+	      printk("%02x ", auth_data[i]);
+	      if (i && (i % 16) == 0) printk("\n");
+	    }
+	    printk("\n");
+	  }
+#endif	  
+	  break;
+	}
+ out:
+	msgrng_access_restore(&msgrng_lock, flags, msgrng_flags);
+} 
+
+static int __init phoenix_sec_init(void)
+{
+  int i=0;
+  phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_SECURITY_OFFSET);
+
+  spin_lock_init(&msgrng_lock);
+
+  phoenix_write_reg(mmio, SEC_DMA_CREDIT, 0x00924924);
+  
+  for(i=0;i<8;i++)
+    phoenix_write_reg(mmio, SEC_MSG_BUCKET0_SIZE + i, bucket_sizes.bucket[MSGRNG_STNID_SEC + i]);
+  
+  for(i=0;i<128;i++)
+    phoenix_write_reg(mmio, SEC_CC_CPU0_0 + i, cc_table_sec.counters[i>>3][i&0x07]);
+
+  dbg_msg("Intialized Phoenix security engine\n");
+
+  return 0;
+}
+
+module_init(phoenix_sec_init);
diff --git a/drivers/crypto/Kconfig b/drivers/crypto/Kconfig
index b08403d..f7cd728 100644
--- a/drivers/crypto/Kconfig
+++ b/drivers/crypto/Kconfig
@@ -222,4 +222,15 @@ config CRYPTO_DEV_PPC4XX
 	help
 	  This option allows you to have support for AMCC crypto acceleration.
 
+config CRYPTO_XLR
+	tristate "Support for the XLR Security engine"
+	depends on CRYPTO && RMI_PHOENIX 
+	default Y
+	help
+	  Say 'Y' here to use the XLR hardware Security engine for the 
+	  Crypto operations.
+
+	  To compile this driver as a module, choose M here: the module
+	  will be called xlr_sec.
+
 endif # CRYPTO_HW
diff --git a/drivers/crypto/Makefile b/drivers/crypto/Makefile
index 6ffcb3f..c4c1577 100644
--- a/drivers/crypto/Makefile
+++ b/drivers/crypto/Makefile
@@ -5,4 +5,5 @@ obj-$(CONFIG_CRYPTO_DEV_HIFN_795X) += hifn_795x.o
 obj-$(CONFIG_CRYPTO_DEV_MV_CESA) += mv_cesa.o
 obj-$(CONFIG_CRYPTO_DEV_TALITOS) += talitos.o
 obj-$(CONFIG_CRYPTO_DEV_IXP4XX) += ixp4xx_crypto.o
+obj-$(CONFIG_CRYPTO_XLR) += rmi/
 obj-$(CONFIG_CRYPTO_DEV_PPC4XX) += amcc/
diff --git a/drivers/crypto/rmi/Makefile b/drivers/crypto/rmi/Makefile
new file mode 100644
index 0000000..cff9e73
--- /dev/null
+++ b/drivers/crypto/rmi/Makefile
@@ -0,0 +1,31 @@
+#/*********************************************************************
+#
+#  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+#  reserved.
+#
+#  Redistribution and use in source and binary forms, with or without
+#  modification, are permitted provided that the following conditions
+#  are met:
+#
+#  1. Redistributions of source code must retain the above copyright
+#  notice, this list of conditions and the following disclaimer.
+#  2. Redistributions in binary form must reproduce the above copyright
+#  notice, this list of conditions and the following disclaimer in
+#  the documentation and/or other materials provided with the
+#  distribution.
+#
+#  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+#  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+#  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+#  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+#  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+#  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+#  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+#  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+#  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+#  THE POSSIBILITY OF SUCH DAMAGE.
+#
+#  *****************************#RMI_2#**********************************/
+obj-$(CONFIG_CRYPTO_XLR) += xlr_sec.o
+xlr_sec-objs := common/sec_api.o rmisec.o
diff --git a/drivers/crypto/rmi/common/rmisae.h b/drivers/crypto/rmi/common/rmisae.h
new file mode 100644
index 0000000..473f0f6
--- /dev/null
+++ b/drivers/crypto/rmi/common/rmisae.h
@@ -0,0 +1,493 @@
+/***********************************************************************
+Copyright 2003-2008 RMI Corporation (RMI) All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY RMI Corporation. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************_ RMI_2_**********************************/
+#ifndef _RMISAE_H_
+#define _RMISAE_H_
+
+#ifdef __cplusplus
+extern "C" {
+#endif /* __cpluscplus */
+
+#define RMISAE_NOWAIT  0
+#define RMISAE_SUCCESS 16
+
+#define IS_SUCCESS_SAEOP(x) (x == RMISAE_SUCCESS)
+#define IS_ASYNC_SUCCESS_SAEOP(x) (x == RMISAE_NOWAIT)
+
+typedef unsigned long op_handle_t, *op_handle_pt;
+#define RMISAE_HANDLE_INITIALIZER 0UL
+
+typedef enum CipherAlgo {
+	CIPHER_BYPASS = 0,
+	RMI_DES,
+	RMI_DES3,
+	RMI_AES128,
+	RMI_AES192,
+	RMI_AES256,
+	RMI_ARC4,
+	RMI_KASUMI_F8,
+	MAX_CIPHER_ALGO
+} CipherAlgo_t;
+
+typedef enum CipherMode {
+	RMI_ECB = 0,
+	RMI_CBC,
+	RMI_CFB,
+	RMI_OFB,
+	RMI_CTR,
+	RMI_F8,
+	RMI_CCM,
+	MAX_CIPHER_MODE
+} CipherMode_t;
+
+typedef enum HashAlgo {
+	HASH_BYPASS = 0,
+	RMI_MD5,
+	RMI_SHA1,
+	RMI_SHA256,
+	RMI_SHA384,
+	RMI_SHA512,
+	RMI_GCM,
+	RMI_KASUMI_F9,
+	RMI_DES3_CMAC,
+	RMI_AES_CMAC,
+	MAX_HASH_ALGO
+} HashAlgo_t;
+
+typedef enum {
+	NO_MASK = 0,
+	ONE_BIT_MASK = 1,
+	TWO_BIT_MASK = 2,
+	FOUR_BIT_MASK = 4,
+	EIGHT_BIT_MASK = 8,
+	SIXTEEN_BIT_MASK = 16,
+	THIRTHYTWO_BIT_MASK = 32,
+	SIXTYFOUR_BIT_MASK = 64,
+	ONETWENTYEIGHT_BIT_MASK = 128,
+	MASK_MAX
+} CipherMask_t;
+
+typedef enum {
+	RMI_ECC_PRIME_160 = 0,
+	RMI_ECC_PRIME_192 = 1,
+	RMI_ECC_PRIME_224 = 2,
+	RMI_ECC_PRIME_256 = 3,
+	RMI_ECC_PRIME_384 = 4,
+	RMI_ECC_PRIME_512 = 5,
+	RMI_ECC_PRIME_CURVE_MAX = 6,
+
+	RMI_ECC_BINARY_163 = 0x20,
+	RMI_ECC_BINARY_191 = 0x21,
+	RMI_ECC_BINARY_233 = 0x22,
+} ECC_Mode_t;
+
+#define RMI_ECC_BINARY_CURVE_MAX 3
+
+typedef enum {
+	RMI_ECC_PRIME_P_MUL = 0,
+	RMI_ECC_PRIME_P_ADD = 1,
+	RMI_ECC_PRIME_P_2X =  2,
+	RMI_ECC_PRIME_P_VFY = 3,
+	RMI_ECC_PRIME_M_ADD = 4,
+	RMI_ECC_PRIME_M_SUB = 5,
+	RMI_ECC_PRIME_M_MUL = 6,
+	RMI_ECC_PRIME_M_DIV = 7,
+	RMI_ECC_PRIME_M_INV = 8,
+	RMI_ECC_PRIME_M_RED = 9,
+	RMI_ECC_PRIME_OP_MAX = 10,
+
+	RMI_ECC_BINARY_P_MUL  = 0,
+	RMI_ECC_BINARY_GF_INV  = 1,
+	RMI_ECC_BINARY_GF_MUL  = 2,
+	RMI_ECC_BINARY_GF_ADD  = 3,
+	RMI_ECC_BINARY_OP_MAX = 4
+} ECC_Op_t;
+
+typedef enum {
+	CIPHER_SAVE_STATE=1,
+	CIPHER_LOAD_STATE=2,
+	CIPHER_WAIT_SAVE=4
+} Cipher_Box_Action_t;
+
+typedef enum {
+	CIPHER_DECRYPT=0,
+	CIPHER_ENCRYPT
+} Cipher_Function_t;
+
+typedef enum CTR_MASK {
+	NO_CTR_MASK = 0,
+	MASK_96_LSB,
+	MASK_64_LSB,
+	MASK_32_LSB
+} LLW_Mask_t;
+
+/* Operation flag bit field descriptions */
+enum op_flags_type {
+	OP_NO_WAIT=1, /* The function will return immediately and the message
+		       * to the SAE will be processed asynchronously.
+		       */
+	OP_NO_INPUT_DATA_COPY = 2, /* This flag may be specified if the input
+				    * data is cache-line aligned and the memory
+				    * will not get swapped, so, this address
+				    * will be translated to physical address
+				    * and sent to the security engine.  This
+				    * means that IV also has to be inside the
+				    * the data block.  The address that is passed
+				    * as input data should be the physical address
+				    */
+	OP_NO_OUTPUT_DATA_COPY = 4, /* This flag may be specified if the output
+				     * data is cache-line aligned and the memory
+				     * will not get swapped.  The address value
+				     * for the destination buffer must be the
+				     * physical address.  It will be sent as is
+				     * to the security engine.
+				     */
+};
+
+
+/* Queue interfaces: available in kernel mode */
+#ifdef __KERNEL__
+typedef unsigned long op_queue_t, *op_queue_pt;
+typedef unsigned long op_callback_t, *op_callback_pt;
+typedef void (*op_callback_func_t)(int result, unsigned long arg);
+#define DUMMY_QUEUE 0
+
+/* Queuing features */
+/* Create a completion queue.   Operations associated with the queue will be added to the
+ * queue after completion.  An operation may be associated with a queue by calling
+ * rmisec_op_setup.
+ * Params:
+ * op_queue_pt - queue to be created.
+ * Returns:
+ * 0     - on successful creation of the queue.
+ * non-0 - error while creating the queue.
+ */
+int rmisec_create_operation_queue(op_queue_pt);
+
+int rmisec_destroy_operation_queue(op_queue_pt);
+
+/* Callback features */
+/* Create a callback handler.  This is method of notification is in-lieu of
+ * operation queues.  Instead of depositing completed operations in queue, the
+ * driver will invoke callback for each completed operation.  The callback handler
+ * may be in the hardware interrupt handler context or software IRQ context.
+ * Returns:
+ * 0      - on successful creation of queue.
+ * non-0  - error while creating queue.
+ */
+int rmisec_create_operation_callback(op_callback_pt handle, op_callback_func_t);
+
+int rmisec_destroy_operation_callback(op_callback_pt handle);
+
+/**
+ * Params:
+ * qhandle - The queue to fetch the completed operations from.
+ * presult - Result of the cipher operation, this is different from the return
+ *           parameter of this API.  This value has valid result code, only if the
+ *           API returns success(0) value.  This reason for error must be decoded
+ *           based on the error section in the PRM for SAE.
+ * phandle - Pointer to where the handle will be stored.
+ * Result:
+ * 0      - if the API retrieved an operation from queue successfully
+ * non-0  - if no operation was returned.
+ */
+int rmisec_op_queue_dequeue(op_queue_t qhandle, int *presult, op_handle_pt phandle);
+
+/**
+ * Function returns the number of entries in the queue.
+ * Params:
+ * qhandle - The queue for which size is retrieved.
+ *
+ * Result:
+ * <value> - positive integer value of the number of entries in the queue.
+ */
+unsigned int rmisec_op_queue_size(op_queue_t qhandle);
+
+unsigned long rmisec_op_get_arg(op_handle_t);
+
+/**
+ * This function creates an operation context for performing security operation.
+ * If this function returns success, the op_handle_t will be a valid handle.
+ * The caller must call rmisec_op_cleanup in order to free the operation context
+ * prior to discarding its value.
+ * Params:
+ * handle - The pointer to the security operation that needs to be created.
+ * Returns:
+ * 0    :  upon successful creation of context
+ * ENOMEM: No memory
+ */
+int rmisec_op_init(op_handle_pt handle);
+#else
+
+#define OP_NO_WAIT 1
+
+extern const char *devname;
+
+/**
+ * Init the instance of this library.  This is a userspace function and must be
+ * called before calling any functions in this header file.
+ * Returns:
+ * int   - The value is the file descriptor that was created.
+ */
+int rmisec_lib_init(void);
+
+void rmisec_lib_cleanup(void);
+
+int rmisec_op_init(int fd, op_handle_pt handle);
+#endif /* KERNEL */
+
+#ifdef __KERNEL__
+/*
+ * Params:
+ * handle      - operation handle
+ * async_queue - If the parameter is not DUMMY_QUEUE, the operation will be processed
+ *               asynchronously and upon completion, the queue will be updated with
+ *               the completed operation.  If DUMMY_QUEUE is processed the crypto
+ *               operation will block until the operation is completed
+ * arg         - arbitary data that may be used by caller to store data, which may
+ *               be retrieved by rmisec_op_get_arg function
+ * op_flags    - Flags used to control administrative behavior of operations
+ * Returns:
+ * 0     - operation successful.
+ * non-0 - Error performing operation.
+ */
+int rmisec_op_setup(op_handle_t handle, op_queue_t async_queue, unsigned long arg,
+		    int op_flags);
+
+int rmisec_op_callback_setup(op_handle_t handle, op_callback_t async_callback,
+			     unsigned long arg, int op_flags);
+#endif /* KERNEL */
+
+void rmisec_op_cleanup(op_handle_pt);
+
+int rmisec_bytes_to_bits(const unsigned char *, int bytes);
+
+int rmisec_bits_to_bytes(int numbits);
+
+/* Hash function */
+int get_hash_output_bytes(HashAlgo_t);
+
+/*
+ * Params:
+ * handle         - handle that was created by calling rmisec_op_init
+ * message        - data on which the crypto operation is to be performed on
+ * message_length - length of the input data
+ * digest         -  MD5 digest of the input message
+ * Returns:
+ * 0     - operation is successful, if non dummy async_queue is specified, the
+ *         operation returns success if the operation was successfully sent
+ *         to the security engine.
+ * non-0 - Error performing operation
+ */
+int rmisec_md5(op_handle_t handle, const unsigned char *message,
+	       unsigned int message_length, unsigned char *digest);
+
+int rmisec_sha1(op_handle_t handle, const unsigned char *message,
+		unsigned int message_length, unsigned char *digest);
+
+int rmisec_sha256 (op_handle_t handle, const unsigned char *message,
+		    unsigned int message_length,
+		    unsigned char *digest);
+
+int rmisec_sha384 (op_handle_t handle, const unsigned char *message,
+		   unsigned int message_length,
+		   unsigned char *digest);
+
+int rmisec_sha512 (op_handle_t handle, const unsigned char *message,
+		   unsigned int message_length,
+		   unsigned char *digest);
+
+int rmisec_hash_hmac(op_handle_t handle, HashAlgo_t algo, const unsigned char *hmac,
+		     const unsigned char *message,
+		     unsigned int message_length,
+		     unsigned char *digest);
+
+/* Ciphers */
+int rmisec_aes128_cipher (op_handle_t handle, const unsigned char *key,
+                          const unsigned char *iv, Cipher_Function_t encrypt,
+                          const unsigned char *input, unsigned int  input_len,
+			  unsigned char *output);
+
+int rmisec_aes192_cipher (op_handle_t handle, const unsigned char *key,
+			  const unsigned char *iv, Cipher_Function_t encrypt,
+			  const unsigned char *input,
+			  unsigned int  input_len,
+			  unsigned char *output);
+
+int rmisec_aes256_cipher (op_handle_t handle, const unsigned char *key,
+			  const unsigned char *iv, Cipher_Function_t encrypt,
+			  const unsigned char *input,
+			  unsigned int  input_len,
+			  unsigned char *output);
+
+int rmisec_des_cipher (op_handle_t handle, const unsigned char *key,
+		       const unsigned char *iv, Cipher_Function_t encrypt,
+		       const unsigned char *input,
+		       unsigned int  input_len,
+		       unsigned char *output);
+
+int rmisec_3des_cipher (op_handle_t handle, const unsigned char *key,
+			const unsigned char *iv, Cipher_Function_t encrypt,
+			const unsigned char *input,
+			unsigned int  input_len,
+			unsigned char *output);
+
+int rmisec_cipher_and_hash(op_handle_t handle, CipherAlgo_t c, CipherMode_t m,
+			   const unsigned char *key, const unsigned char *iv,
+			   unsigned int cipher_dwords_to_skip,
+			   Cipher_Function_t encrypt, HashAlgo_t h,
+			   const unsigned char *hmac, int hash_src,
+			   unsigned hash_bytes_to_skip,
+			   const unsigned char *input, unsigned int input_len,
+			   unsigned char *cipher_output, unsigned char *hash_output);
+
+/* RSA Function */
+int rmisec_mod_exp (op_handle_t handle,
+		    const unsigned char *x, int x_len,
+		    const unsigned char *m, int m_len,
+		    const unsigned char *e, int e_len,
+		    const unsigned char *c, int c_len,
+		    unsigned char *y, int *y_len);
+
+/* ECC Functions */
+int
+rmisec_ecc_gfp_mul (op_handle_t handle,
+		    ECC_Mode_t degree,
+		    const unsigned char *x, int x_len,
+		    const unsigned char *y, int y_len,
+		    const unsigned char *a, int a_len,
+		    const unsigned char *k, int k_len,
+		    const unsigned char *n, int n_len,
+		    const unsigned char *c, int c_len,
+		    unsigned char *r_x, int *r_x_len,
+		    unsigned char *r_y, int *r_y_len);
+
+int
+rmisec_ecc_gfp_add (op_handle_t handle,
+		    int degree,
+		    unsigned char *x1, int x1_len,
+		    unsigned char *y1, int y1_len,
+		    unsigned char *x2, int x2_len,
+		    unsigned char *y2, int y2_len,
+		    unsigned char *a, int a_len,
+		    unsigned char *n, int n_len,
+		    unsigned char *c, int c_len,
+		    unsigned char *r_x, int *r_x_len,
+		    unsigned char *r_y, int *r_y_len);
+
+int
+rmisec_ecc_gfp_dbl (op_handle_t handle,
+		    int degree,
+		    unsigned char *x, int x_len,
+		    unsigned char *y, int y_len,
+		    unsigned char *a, int a_len,
+		    unsigned char *n, int n_len,
+		    unsigned char *c, int c_len,
+		    unsigned char *r_x, int *r_x_len,
+		    unsigned char *r_y, int *r_y_len);
+
+
+int
+rmisec_ecc_gfp_vfy (op_handle_t handle,
+		    int degree,
+		    unsigned char *x, int x_len,
+		    unsigned char *y, int y_len,
+		    unsigned char *a, int a_len,
+		    unsigned char *b, int b_len,
+		    unsigned char *n, int n_len,
+		    unsigned char *c, int c_len,
+		    unsigned int *s);
+
+int
+rmisec_ecc_gfp_field_add (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *y, int y_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *r, int *r_len);
+
+int
+rmisec_ecc_gfp_field_sub (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *y, int y_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *r, int *r_len);
+
+int
+rmisec_ecc_gfp_field_mul (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *y, int y_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *c, int c_len,
+			  unsigned char *r, int *r_len);
+
+int
+rmisec_ecc_gfp_field_div (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *y, int y_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *r, int *r_len);
+
+int
+rmisec_ecc_gfp_field_inv (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *r, int *r_len);
+
+int
+rmisec_ecc_gfp_field_red (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *r, int *r_len);
+
+int
+rmisec_ecc_gf2m_mul (op_handle_t handle, int degree,
+                unsigned char *x, int x_len,
+                unsigned char *y, int y_len,
+                unsigned char *b, int b_len,
+                unsigned char *k, int k_len,
+                unsigned char *r_x, int *r_x_len,
+		     unsigned char *r_y, int *r_y_len);
+
+int
+rmisec_ecc_gf2m_field_inv (op_handle_t handle, int degree,
+			   unsigned char *x, int x_len,
+			   unsigned char *r_x, int *r_x_len);
+
+int
+rmisec_ecc_gf2m_field_mul (op_handle_t handle, int degree,
+			   unsigned char *x, int x_len,
+			   unsigned char *y, int y_len,
+			   unsigned char *r_x, int *r_x_len);
+
+int
+rmisec_ecc_gf2m_field_add (op_handle_t handle, int degree,
+			   unsigned char *x, int x_len,
+			   unsigned char *y, int y_len,
+			   unsigned char *r_x, int *r_x_len);
+
+#ifdef __cplusplus
+}
+#endif /* __cplusplus */
+
+#endif /* _RMISEC_H_ */
diff --git a/drivers/crypto/rmi/common/rmisec_internal.h b/drivers/crypto/rmi/common/rmisec_internal.h
new file mode 100644
index 0000000..741843a
--- /dev/null
+++ b/drivers/crypto/rmi/common/rmisec_internal.h
@@ -0,0 +1,968 @@
+/***********************************************************************
+Copyright 2003-2008 RMI Corporation (RMI) All rights
+reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY RMI Corporation. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************_ RMI_2_**********************************/
+#ifndef _RMI_SECDESC_INTERNAL_H_
+#define _RMI_SECDESC_INTERNAL_H_
+#ifdef __KERNEL__
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/timer.h>
+#include <linux/list.h>
+#include <asm/rmi/msgring.h>
+#include "rmisae.h"
+#include <linux/uio.h>
+typedef struct kvec IOVEC;
+#else
+#include <sys/uio.h>
+#include "rmisae.h"
+typedef struct iovec IOVEC;
+#endif
+
+#define DRIVER_NAME "rmisae"
+#define DRIVER_MAGIC 0xDEADFADEBABECAFEULL
+
+typedef enum OpType {
+	NOP = 0,
+	RMI_CRYPTO_OP,
+	RMI_RSA_OP,
+	RMI_ECC_OP,
+	OP_ALL
+} OpType_t;
+
+#ifdef __KERNEL__
+typedef enum call_ctx_type {
+	PROCESS_CTX = 1,
+	KERNEL_CTX,
+	INIT_CTX
+} CALL_CTX;
+
+typedef struct process_memlist *proc_memlist_pt;
+typedef struct meminfo *meminfo_pt;
+typedef struct secop_queue *secop_queue_pt;
+#endif /* KERNEL */
+
+/* keep this structure at cacheline size */
+typedef struct control_struct *control_struct_pt;
+typedef struct control_struct {
+	uint64_t magic;
+	uint32_t version;
+	uint32_t owner;
+	uint64_t phy_addr;
+	uint64_t mem_addr;
+	uint32_t op_type;
+	uint16_t resv16bit;
+	uint8_t rsa_algo;
+	uint8_t ecc_algo;
+	uint8_t ecc_degree;
+	uint8_t cipher_algo;
+	uint8_t cipher_mode;
+	uint8_t hash_algo;
+	uint32_t data_size;
+	uint64_t msg0;
+	uint64_t msg1;
+} __attribute__ ((packed)) control_struct_t;
+
+#define RMISEC_IOCTL_GET_MEMINFO 1
+typedef struct operation *operation_pt;
+
+#ifdef __KERNEL__
+typedef struct list_head memlist_t, *memlist_pt;
+#define IS_ASYNC_OP(m) ((m)->op_flags & OP_NO_WAIT)
+typedef struct meminfo {
+	memlist_t memlist; /* used if mem object is in process list */
+        unsigned long long magic;
+	int order;
+	int owner;
+	void *ptr;
+	struct vm_area_struct *vma;
+	int in_progress;
+	wait_queue_t wqe;
+	wait_queue_head_t wq;
+	proc_memlist_pt proc;
+	CALL_CTX ctx;
+	secop_queue_pt return_queue;
+	unsigned long return_value;
+	uint64_t msg0;
+	uint64_t msg1;
+	OpType_t op_type;
+	uint32_t op_flags;
+	int result;
+	uint64_t resp0;
+	uint64_t resp1;
+	meminfo_pt async_next; /* used when the operation is waiting in async
+				* dispatch queue.
+				*/
+} meminfo_t;
+
+typedef enum secop_resp_type {
+	SECOP_Q = 0,
+	SECOP_CB
+} secop_resp_type_t;
+
+typedef struct secop_queue {
+	secop_resp_type_t response_type;
+	union {
+		struct {
+			unsigned int length;
+			int max_length;
+			unsigned int stats_max_length;
+			meminfo_t head;
+			meminfo_pt tail;
+			spinlock_t lock;
+		} q;
+		struct {
+			op_callback_func_t cbfunc;
+		} cb;
+	};
+} secop_queue_t;
+
+#define INIT_SECOP_QUEUE(p, l) \
+do { \
+        (p)->response_type = SECOP_Q;\
+	(p)->q.length = 0; \
+        (p)->q.max_length = l; \
+        spin_lock_init(&(p)->q.lock); \
+	(p)->q.tail = (p)->q.head.async_next = &((p)->q.head); \
+} while(0)
+
+#define INIT_SECOP_CB(q, f) \
+do { \
+        (q)->response_type = SECOP_CB; \
+        (q)->cb.cbfunc = func; \
+} while(0)
+
+#endif /* KERNEL */
+
+typedef struct Crypto_Operation {
+	/* cipher input parameters */
+	CipherAlgo_t c;
+	CipherMode_t m;
+	const unsigned char *key;
+	unsigned int key_len;
+	const unsigned char *iv;
+	unsigned int iv_len;
+	const unsigned char *aux_param1;
+	unsigned int ap1;
+	Cipher_Function_t encrypt;
+	unsigned int nonce;
+	unsigned int cipher_dwords_to_skip;
+	unsigned char *cipher_box;
+	int cipher_box_action;
+	CipherMask_t cipher_mask;
+	LLW_Mask_t llw_mask;
+
+	/* hash input parameters */
+	HashAlgo_t h;
+	const unsigned char *hmac;
+	int hmac_len;
+	int hash_src;
+	unsigned int hash_bytes_to_skip;
+
+	/* checksum input parameters */
+	int cksum_src;
+	unsigned int cksum_words_to_skip;
+
+	/* input data */
+	const unsigned char *input;
+	unsigned int  input_len;
+	IOVEC *input_vec;
+	int input_vec_len;
+
+	/* output pointers */
+	unsigned char *output;
+	IOVEC *output_vec;
+	int output_vec_len;
+
+	unsigned char *digest;
+	unsigned int *cksum_output;
+} Crypto_Operation_t, *Crypto_Operation_pt;
+
+typedef struct operation {
+	control_struct_t meta;
+	void *ptr;
+	unsigned int nr_pages;
+	uint64_t *ctrl_msg;
+	uint64_t *data_msg;
+	OpType_t *op_type;
+	uint64_t *ctrl_instr;
+	uint64_t *ctrl_data;
+	uint64_t *data_desc;
+	int nr_ddesc;
+	unsigned char *iv;
+	unsigned int iv_length;
+	unsigned char *aad;
+	unsigned int aad_length;
+        unsigned char *data;
+	unsigned int length;
+
+	unsigned char *output;
+	unsigned int output_length;
+
+	unsigned char *hash_output;
+	unsigned int hash_length;
+
+	unsigned char *cksum;
+
+	Crypto_Operation_t cop_instance;
+	uint32_t op_flags;
+	unsigned long arg;
+#ifdef __KERNEL__
+	secop_queue_pt return_queue;
+#else
+	int fd;
+#endif /* KERNEL */
+} operation_t;
+
+#ifdef __KERNEL__
+typedef struct process_memlist {
+	struct list_head elem;
+	wait_queue_t wqe;
+	pid_t tgid;
+	secop_queue_t async_queue;
+	memlist_t mem;
+} proc_memlist_t;
+
+#endif /* KERNEL */
+
+int
+rmisec_cipher_digest_hmac_cksum(op_handle_t handle, Crypto_Operation_pt cop);
+
+int
+rmisec_cmac(op_handle_t handle, HashAlgo_t h, const unsigned char *key,
+	    const unsigned char *in, unsigned int size, unsigned char *out);
+
+#define OFFSET_OF(x, y)  (unsigned int)(&((x *)(0))->y)
+#define PTR_DIFF(x, y)   (((unsigned long)x) - ((unsigned long)(y)))
+#define HAS_REMINDER(x, y)  (((uint64_t)(x) & ((1ULL << (y)) - 1))?1:0)
+#define PTR_OFFSET(a,b) (unsigned long)((((unsigned long)a) + (b)))
+#define CEIL(n, bits) ((n + ((1 << bits) - 1)) >> bits)
+#define CEIL_BYTES(m,n) ((CEIL(m,n))<<(n))
+#define CEIL_VALUE(m,n) CEIL_BYTES(m,n)
+#define CEIL_BY_DIV(a,b) (((a)/b) + ((a%b)?1:0))
+
+#define CACHELINE_BITS 5
+#define CACHELINE_SIZE (1 << CACHELINE_BITS)
+#define CACHELINE_MASK   (~((1ULL << CACHELINE_BITS) - 1))
+#define NEXT_CACHELINE(x) (unsigned long)(((unsigned long)(x) + CACHELINE_SIZE) & CACHELINE_MASK)
+#define CURR_CACHELINE(x) (((uint64_t)x) & CACHELINE_MASK)
+#define NUM_CACHELINES(m) CEIL((m), CACHELINE_BITS)
+#define CACHELINE_ALIGN(m) (unsigned long)(CEIL_BYTES(m, CACHELINE_BITS))
+
+#define ADDR_BITS 40
+#define ADDR_MASK ((1ULL << (ADDR_BITS)) - 1)
+#define ADDR_CACHELINE_MASK ((ADDR_MASK) & CACHELINE_MASK)
+
+#define NUM_FRAG_FIELD_BITS 11
+#define NUM_CHUNK_BITS 3
+#define FRAG_CHUNK_SIZE (1 << NUM_CHUNK_BITS)
+
+#define MAX_FRAG_FIELD_SIZE ((1 << NUM_FRAG_FIELD_BITS) - 1)
+#define MAX_FRAG_TOT_SIZE 16320
+#define MAX_PER_FRAG_SIZE ((MAX_FRAG_TOT_SIZE) & CACHELINE_MASK)
+#define MAX_PER_FRAG_FIELD_SIZE (MAX_PER_FRAG_SIZE >> 3)
+#define FRAG_SIZE_MASK ~(((1 << NUM_FRAG_FIELD_BITS)-1))
+
+#ifdef __KERNEL__
+#define get_phy_addr_absolute(x) (uint64_t)(unsigned long)virt_to_phys(x)
+#else
+#define get_phy_addr_absolute(x) 0
+#endif
+
+#define get_phy_addr(x, y) ((x)->meta.phy_addr + PTR_DIFF(y, (x)->ptr))
+
+#define RSA_BLOCK_SIZE_BYTES 64
+#define RSA_BLOCK_SIZE 512
+typedef enum PKOp_Size {
+	BIT_512 = 1,
+	BIT_1024,
+	BIT_SIZE_MAX
+} PKOp_Size_t;
+
+/**
+ * SIZES of control data in bytes
+ */
+#define CTRL_DESC_VECTOR_SIZE 8
+#define CTRL_INSTR_SIZE 8
+#define MAX_CTRL_DATA_SIZE 472
+#define DATA_DESC_VECTOR_SIZE 8
+#define DATA_DESC_SIZE 32
+
+/* sizes of algorithms */
+#define AES256_SIZE            32
+#define AES192_SIZE            24
+#define AES128_SIZE            16
+
+#define ECB_FACTOR             1
+#define CBC_FACTOR             1
+#define CFB_FACTOR             1
+#define OFB_FACTOR             2
+#define CTR_FACTOR             1
+#define F8_FACTOR              1
+
+#define DES_SIZE                8
+#define DES3_SIZE               (DES_SIZE * 3)
+
+#define ARC4_SIZE               32
+#define ARC4_SBOX_SIZE          264
+#define PAD3_SIZE               24
+
+#define ARC4_STATE_SIZE (ARC4_SIZE+(2 * PAD3_SIZE)+ARC4_SBOX_SIZE)
+
+#define KASUMI_F8_SIZE          16
+
+#define HMAC_SIZE               64
+#define MD5_SIZE                HMAC_SIZE
+#define SHA1_SIZE               HMAC_SIZE
+#define SHA256_SIZE             HMAC_SIZE
+
+#define HMAC2_SIZE              128
+#define SHA384_SIZE             HMAC2_SIZE
+#define SHA512_SIZE             HMAC2_SIZE
+
+#define GCM_SIZE                16
+#define KASUMI_F9_SIZE          16
+#define DES3_CMAC_SIZE          8
+#define AES_CMAC_SIZE           16
+
+#ifdef __KERNEL__
+/* Device configuration */
+/*
+ *
+ *
+ * rwR      31  30 29     27 26    24 23      21 20     18
+ *         |  NA  | RSA0Out | Rsa0In | Pipe3Out | Pipe3In | ...
+ *
+ *          17       15 14     12 11      9 8       6 5        3 2       0
+ *         |  Pipe2Out | Pipe2In | Pipe1In | Pipe1In | Pipe0Out | Pipe0In |
+ *
+ * DMA CREDIT REG -
+ *   NUMBER OF CREDITS PER PIPE
+ */
+#define SEC_DMA_CREDIT_RSA0_OUT_FOUR   0x20000000
+#define SEC_DMA_CREDIT_RSA0_OUT_TWO    0x10000000
+#define SEC_DMA_CREDIT_RSA0_OUT_ONE    0x08000000
+
+#define SEC_DMA_CREDIT_RSA0_IN_FOUR    0x04000000
+#define SEC_DMA_CREDIT_RSA0_IN_TWO     0x02000000
+#define SEC_DMA_CREDIT_RSA0_IN_ONE     0x01000000
+
+#define SEC_DMA_CREDIT_PIPE3_OUT_FOUR  0x00800000
+#define SEC_DMA_CREDIT_PIPE3_OUT_TWO   0x00400000
+#define SEC_DMA_CREDIT_PIPE3_OUT_ONE   0x00200000
+
+#define SEC_DMA_CREDIT_PIPE3_IN_FOUR   0x00100000
+#define SEC_DMA_CREDIT_PIPE3_IN_TWO    0x00080000
+#define SEC_DMA_CREDIT_PIPE3_IN_ONE    0x00040000
+
+#define SEC_DMA_CREDIT_PIPE2_OUT_FOUR  0x00020000
+#define SEC_DMA_CREDIT_PIPE2_OUT_TWO   0x00010000
+#define SEC_DMA_CREDIT_PIPE2_OUT_ONE   0x00008000
+
+#define SEC_DMA_CREDIT_PIPE2_IN_FOUR   0x00004000
+#define SEC_DMA_CREDIT_PIPE2_IN_TWO    0x00002000
+#define SEC_DMA_CREDIT_PIPE2_IN_ONE    0x00001000
+
+#define SEC_DMA_CREDIT_PIPE1_OUT_FOUR  0x00000800
+#define SEC_DMA_CREDIT_PIPE1_OUT_TWO   0x00000400
+#define SEC_DMA_CREDIT_PIPE1_OUT_ONE   0x00000200
+
+#define SEC_DMA_CREDIT_PIPE1_IN_FOUR   0x00000100
+#define SEC_DMA_CREDIT_PIPE1_IN_TWO    0x00000080
+#define SEC_DMA_CREDIT_PIPE1_IN_ONE    0x00000040
+
+#define SEC_DMA_CREDIT_PIPE0_OUT_FOUR  0x00000020
+#define SEC_DMA_CREDIT_PIPE0_OUT_TWO   0x00000010
+#define SEC_DMA_CREDIT_PIPE0_OUT_ONE   0x00000008
+
+#define SEC_DMA_CREDIT_PIPE0_IN_FOUR   0x00000004
+#define SEC_DMA_CREDIT_PIPE0_IN_TWO    0x00000002
+#define SEC_DMA_CREDIT_PIPE0_IN_ONE    0x00000001
+
+/*
+ *  Currently, FOUR credits per PIPE
+ *  0x24924924
+ */
+#define SEC_DMA_CREDIT_CONFIG          SEC_DMA_CREDIT_RSA0_OUT_FOUR | \
+                                       SEC_DMA_CREDIT_RSA0_IN_FOUR | \
+                                       SEC_DMA_CREDIT_PIPE3_OUT_FOUR | \
+                                       SEC_DMA_CREDIT_PIPE3_IN_FOUR | \
+                                       SEC_DMA_CREDIT_PIPE2_OUT_FOUR | \
+                                       SEC_DMA_CREDIT_PIPE2_IN_FOUR | \
+                                       SEC_DMA_CREDIT_PIPE1_OUT_FOUR | \
+                                       SEC_DMA_CREDIT_PIPE1_IN_FOUR | \
+                                       SEC_DMA_CREDIT_PIPE0_OUT_FOUR | \
+                                       SEC_DMA_CREDIT_PIPE0_IN_FOUR
+enum sec_config {
+  SEC_DMA_CREDIT = 0x140,
+  SEC_CONFIG1,
+  SEC_CONFIG2,
+  SEC_CONFIG3,
+};
+
+/*
+ * CONFIG2
+ *    31   5         4                   3
+ *   |  NA  | PIPE3_DEF_DBL_ISS | PIPE2_DEF_DBL_ISS | ...
+ *
+ *                 2                   1                   0
+ *   ... | PIPE1_DEF_DBL_ISS | PIPE0_DEF_DBL_ISS | ROUND_ROBIN_MODE |
+ *
+ *  DBL_ISS - mode for SECENG and DMA controller which slows down transfers
+ *             (to be conservativei; 0=Disable,1=Enable).
+ *  ROUND_ROBIN - mode where SECENG dispatches operations to PIPE0-PIPE3
+ *                and all messages are sent to PIPE0.
+ *
+ */
+
+#define SEC_CFG2_PIPE3_DBL_ISS_ON      0x00000010
+#define SEC_CFG2_PIPE3_DBL_ISS_OFF     0x00000000
+#define SEC_CFG2_PIPE2_DBL_ISS_ON      0x00000008
+#define SEC_CFG2_PIPE2_DBL_ISS_OFF     0x00000000
+#define SEC_CFG2_PIPE1_DBL_ISS_ON      0x00000004
+#define SEC_CFG2_PIPE1_DBL_ISS_OFF     0x00000000
+#define SEC_CFG2_PIPE0_DBL_ISS_ON      0x00000002
+#define SEC_CFG2_PIPE0_DBL_ISS_OFF     0x00000000
+#define SEC_CFG2_ROUND_ROBIN_ON        0x00000001
+#define SEC_CFG2_ROUND_ROBIN_OFF       0x00000000
+
+enum sec_msgring_bucket_config {
+
+  SEC_BIU_CREDITS = 0x308,
+
+  SEC_MSG_BUCKET0_SIZE = 0x320,
+  SEC_MSG_BUCKET1_SIZE,
+  SEC_MSG_BUCKET2_SIZE,
+  SEC_MSG_BUCKET3_SIZE,
+  SEC_MSG_BUCKET4_SIZE,
+  SEC_MSG_BUCKET5_SIZE,
+  SEC_MSG_BUCKET6_SIZE,
+  SEC_MSG_BUCKET7_SIZE,
+};
+
+enum sec_msgring_credit_config {
+
+  SEC_CC_CPU0_0                        = 0x380,
+  SEC_CC_CPU1_0                        = 0x388,
+  SEC_CC_CPU2_0                        = 0x390,
+  SEC_CC_CPU3_0                        = 0x398,
+  SEC_CC_CPU4_0                        = 0x3a0,
+  SEC_CC_CPU5_0                        = 0x3a8,
+  SEC_CC_CPU6_0                        = 0x3b0,
+  SEC_CC_CPU7_0                        = 0x3b8
+
+};
+#endif /* __KERNEL__ */
+
+/* Macros to access operation header */
+#define OP_VERSION(x)            ((x)->meta.version)
+#define OP_MAGIC(x)              ((x)->meta.magic)
+#define OP_PHY_ADDR(x)           ((x)->meta.phy_addr)
+#define OP_CTRL_ADDR(x)          ((x)->meta.ctrl_addr)
+
+/* Macros for fields in Control Descriptor Vector */
+#define SET_CTRL_SOP(x)          ((x) |= (6ULL << 61))
+#define CTRL_SOP(x)              ((((x)->ctrl_msg[0]) >> 61) & 0x1f)
+
+#define SET_READ_L2_ALLOC(x)     ((x) |= (1ULL << 53))
+#define RESET_READ_L2_ALLOC(x)   ((x) &= ~(1ULL << 53))
+#define IS_READ_L2_ALLOC_SET(x)  (((x)->ctrl_msg[0]) & (1ULL << 53))
+
+#define SET_CTRL_LENGTH(x, y)    ((x) |= ((uint64_t)(y & 0xf) << 45))
+#define CLEAR_CTRL_LENGTH(x)     ((x) &= ~((uint64_t)0xf << 45))
+#define CTRL_LENGTH(x)           ((((x)->ctrl_msg[0]) >> 45) & 0xf)
+
+#define SET_CTRL_ADDR(x, y)      ((x) |= (y & ADDR_CACHELINE_MASK))
+#define CLEAR_CTRL_ADDR(x, y)    ((x) &= ~(ADDR_CACHELINE_MASK))
+#define CTRL_ADDR(x)             (((x)->ctrl_msg[0]) & ADDR_CACHELINE_MASK)
+
+/* Use bits[8:5] 4 bits of the context number, bit 10 is left as 0 for
+ * crypto operations.  For PK operation the Bit 10 is bit 3 free-out
+ * descriptor.  For PK Ops the bit 3 is set to 1.
+ */
+#define SET_CTRL_SCRATCH_VALUE(x, y)  ((x) |= (((uint64_t)y >> 5) & 0xf))
+#define CLEAR_SCRATCH_VALUE(x)        ((x) &= (~((uint64_t)0x1f)))
+#define CTRL_SCRATCH_VALUE(x)         ((((x)->ctrl_msg[0]) >> 0xf) << 5)
+
+#define CTRL_DESC_TEMPLATE (6ULL << 61)
+
+/* Set Macros for fields in CONTROL instruction */
+#define SET_OVERRIDE_CIPHER(x) (  (x) |= (1ULL << 43))
+#define RESET_OVERRIDE_CIPHER(x)  ((x) &= ~(1ULL << 43))
+#define IS_OVERRIDE_CIPHER_SET(x) (((x)->ctrl_instr[0]) & (1ULL << 43))
+
+#define SET_CIPHER_BOX_ACTION(x, y) ((x) |= (((uint64_t)y & 0x7) << 40))
+
+#define SET_ARC4_WAIT4SAVE(x) ((x) |= (1ULL << 42))
+#define RESET_ARC4_WAIT4SAVE(x) ((x) &= ~(1ULL << 42))
+#define IS_ARC4_WAIT4SAVE_SET(x) (((x)->ctrl_instr[0]) & (1ULL << 42))
+
+#define SET_ARC4_SAVESTATE(x) ((x) |= (1ULL << 41))
+#define RESET_ARC4_SAVESTATE(x) ((x) &= ~(1ULL << 41))
+#define IS_ARC4_SAVESTATE_SET(x) (((x)->ctrl_instr[0]) & (1ULL << 41))
+
+#define SET_ARC4_LOADSTATE(x) ((x) |= (1ULL << 40))
+#define RESET_ARC4_LOADSTATE(x) ((x) &= ~(1ULL << 40))
+#define IS_ARC4_LOADSAVE_SET(x) (((x)->ctrl_instr[0]) & (1ULL << 40))
+
+#define SET_ARC4_KEYLEN(x, y) ((x) |= ((uint64_t)(y & 0x1f) << 35))
+#define CLEAR_ARC4_KEYLEN(x) ((x) &= (~((uint64_t)0x1f << 35)))
+#define ARC4_KEYLEN(x) ((((x)->ctrl_instr[0]) >> 35) & 0x1f)
+
+#define SET_CIPHER_BYPASS(x)      ((x) &= ~(7ULL << 32))
+#define CLEAR_CIPHER_ALGO(x)      ((x) &= ~(7ULL << 32))
+#define SET_CIPHER_DES(x)         ((x) |= (1ULL << 32))
+#define SET_CIPHER_DES3(x)        ((x) |= (2ULL << 32))
+#define SET_CIPHER_AES128(x)      ((x) |= (3ULL << 32))
+#define SET_CIPHER_AES192(x)      ((x) |= (4ULL << 32))
+#define SET_CIPHER_AES256(x)      ((x) |= (5ULL << 32))
+#define SET_CIPHER_ARC4(x)        ((x) |= (6ULL << 32))
+#define SET_CIPHER_KASUMI_F8(x)   ((x) |= (6ULL << 32))
+#define SET_CIPHER_ALGO(x, y)     ((x) |= ((uint64_t)(y & 0x7) << 32))
+#define CIPHER_ALGO(x)            ((((x)->ctrl_instr[0]) >> 32) & 0x7)
+#define CIPHER_ALGO_STR(x)        (cipher_str[CIPHER_ALGO(x)])
+
+/*
+ * MD5 - RFC 1321
+ * HMAC - RFC 2104, 2202
+ * Various Crypto Algorithm RFCs
+ * DES-CBC  - RFC 2405
+ * DES3-CBC - RFC 2451
+ * AES-CBC - RFC 3602
+ * AES-CTR - RFC 3686
+ * AES-CMAC - RFC 4493
+ * AES-KW   - RFC 3394
+ * AES-F8   - RFC 3711
+ * TDES-KW  - RFC 3217
+ * Camellia - RFC 3713 & 4312
+
+ * IPSEC Specific:
+ * HMAC-MD5-96 - RFC 2403
+ * HMAC-SHA1-96 - RFC 2404
+ *
+ * Related:
+ * PKCS #1: RSA Cryptography Specs RFC 3447
+ * More MODP DH groups - RFC 3526
+ */
+#define SET_CIPHER_MODE_EBC(x) ((x) &= ~(7ULL << 29))
+#define SET_CIPHER_MODE_CBC(x) ((x) |= (1ULL << 29))
+#define SET_CIPHER_MODE_CFB(x) ((x) |= (2ULL << 29))
+#define SET_CIPHER_MODE_OFB(x) ((x) |= (3ULL << 29))
+#define SET_CIPHER_MODE_CTR(x) ((x) |= (4ULL << 29))
+#define SET_CIPHER_MODE_F8(x)  ((x) |= (5ULL << 29))
+#define SET_CIPHER_MODE(x,y)   ((x) |= ((uint64_t)(y & 7)<< 29))
+#define CIPHER_MODE(x)         ((((x)->ctrl_instr[0]) >> 29) & 0x7)
+#define CIPHER_MODE_STR(x)     (mode_str[CIPHER_MODE(x)])
+
+
+static inline void set_cipher(CipherAlgo_t c, CipherMode_t m, operation_pt op)
+{
+	SET_CIPHER_ALGO(*op->ctrl_instr, c);
+	if(m == RMI_CCM) {
+		m = RMI_CTR;
+	}
+
+	SET_CIPHER_MODE(*op->ctrl_instr, m);
+
+	return;
+}
+
+#define SET_INCP_KEY(x)           ((x) |= (1ULL << 28))
+#define RESET_INCP_KEY(x)         ((x) &= ~(1ULL << 28))
+#define IS_INCP_KEY_SET(x)        (((x)->ctrl_instr[0]) & (1ULL << 28))
+
+#define SET_HMAC(x)            ((x) |= (1ULL << 23))
+#define RESET_HMAC(x)          ((x) &= ~(1ULL << 23))
+#define IS_HMAC_SET(x)         (((x)->ctrl_instr[0]) & (1ULL << 23))
+
+#define SET_HASH_BYPASS(x)     ((x) &= ~((uint64_t)0xf << 21))
+#define SET_HASH_ALGO(x, y)    ((x) |= ((uint64_t)hash_num[y] << 21))
+#define HASH_ALGO(x)           ((((x)->ctrl_instr[0]) >> 21) & 0xb)
+#define HASH_ALGO_STR(x)       ((hash_map[x]<MAX_HASH_ALGO)?hash_str[hash_map[x]]:"UNKNOWN_HASH")
+
+#define SET_INHS_KEY(x)        ((x) |= (1ULL << 20))
+#define RESET_INHS_KEY(x)      ((x) &= ~(1ULL << 20))
+#define IS_INHS_KEY_SET(x)     (((x)->ctrl_instr[0]) & (1ULL << 20))
+
+#define SET_CKSUM(x)           ((x) |= (1ULL << 16))
+#define RESET_CKSUM(x)         ((x) &= ~(1ULL << 16))
+#define IS_CKSUM_SET(x)        (((x)->ctrl_instr[0]) & (1ULL << 16))
+
+
+/* Macros for fields in Data Descriptor Vector */
+#define SET_DATA_EOP(x)          ((x) |= (5ULL << 61))
+#define DATA_EOP(x)              ((((x)->data_msg[0]) >> 61) & 0x7)
+
+#define SET_FREEBACK_STN(x, y)   ((x) |= ((uint64_t)((y) & 0x7f) << 54))
+#define CLEAR_FREEBACK_STN(x)    ((x) &= ~((uint64_t)0x7f << 54))
+#define FREEBACK_STN(x)          ((((x)->data_msg[0]) >> 54) & 0x7f)
+
+#define SET_WRB_COH(x)      ((x) |= (1ULL << 52))
+#define RESET_WRB_COH(x)    ((x) &= ~(1ULL << 52))
+#define IS_WRB_COH_SET(x)   (((x)->data_msg[0]) & (1ULL << 52))
+
+#define SET_WRB_L2_ALLOC(x)      ((x) |= (1ULL << 52))
+#define RESET_WRB_L2_ALLOC(x)    ((x) &= ~(1ULL << 52))
+#define IS_WRB_L2_ALLOC_SET(x)   (((x)->data_msg[0]) & (1ULL << 52))
+
+#define SET_DF_PTR_L2_ALLOC(x)    ((x) |= (1ULL << 51))
+#define RESET_DF_PTR_L2_ALLOC(x)  ((x) &= ~(1ULL << 51))
+#define IS_DF_PTR_L2_ALLOC_SET(x) (((x)->data_msg[0]) & (1ULL << 51))
+
+#define SET_RD_L2_ALLOC(x)       ((x) |= (1ULL << 51))
+#define RESET_RD_L2_ALLOC(x)     ((x) &= ~(1ULL << 51))
+#define IS_RD_L2_ALLOC_SET(x)    (((x)->data_msg[0]) & (1ULL << 51))
+
+#define SET_DATA_ADDR(x, y)      ((x) |= ((uint64_t)y & ADDR_CACHELINE_MASK))
+#define CLEAR_DATA_ADDR(x, y)    ((x) &= ~(ADDR_CACHELINE_MASK))
+#define DATA_ADDR(x)             ((((x)->data_msg[0])) & ADDR_CACHELINE_MASK)
+
+#define SET_DATA_SCRATCH_VALUE(x, y)  ((x) |= ((uint64_t)y & 0x1f))
+#define DATA_SCRATCH_VALUE(x)         (((x)->data_msg[0]) & 0x1f)
+
+#define DATA_DESC_VECTOR_TEMPLATE         ((5ULL << 61) | (1ULL << 45))
+
+/* Macros for srcLengthIVOffUseIVNext */
+#define SET_LOAD_HMAC_KEY(x)        ((x) |= (1ULL << 63))
+#define RESET_LOAD_HMAC_KEY(x)      ((x) &= ~(1ULL << 63))
+#define IS_LOAD_HMAC_KEY_SET(x, y)  (((x)->data_desc[y*4+0]) & (1ULL << 63))
+
+#define SET_PAD_HASH(x)          ((x) |= (1ULL << 62))
+#define RESET_PAD_HASH(x)        ((x) &= ~(1ULL << 62))
+#define IS_PAD_HASH_SET(x,y)     (((x)->data_desc[y*4+0]) & (1ULL << 62))
+
+#define SET_HASH_BYTE_CNT(x, y)  ((x) |= ((uint64_t)(y & 0x7) << 59))
+#define CLEAR_HASH_BYTE_CNT(x)   ((x) &= ~((uint64_t)0x7 << 59))
+#define HASH_BYTE_CNT(x,y)         (((x)->data_desc[y*4+0] >> 59) & 0x7)
+
+#define SET_NEXT(x)              ((x) |= (1ULL << 58))
+#define RESET_NEXT(x)            ((x) &= ~(1ULL << 58))
+#define IS_NEXT_SET(x,y)           (((x)->data_desc[y*4+0]) & (1ULL << 58))
+
+#define SET_USEIV(x)             ((x) |= (1ULL << 57))
+#define RESET_USEIV(x)           ((x) &= ~(1ULL << 57))
+#define IS_USEIV_SET(x,y)        (((x)->data_desc[y*4+0]) & (1ULL << 57))
+
+#define SET_IVOFFSET(x, y) \
+do { \
+	uint64_t *x3 = &(x) + 3; \
+        x |= (((uint64_t)y & 0x7) << 54); \
+	*x3 |= ((uint64_t)(y >> 3) & 0x1f); \
+} while(0)
+
+#define CLEAR_IVOFFSET(x) \
+do { \
+	uint64_t *x3 = &(x) + 3; \
+	x &= ~((uint64_t)0x7 << 54); \
+	*x3 &= ~((uint64_t)0x1f); \
+} while(0)
+
+static inline unsigned int
+IV_OFFSET(operation_pt op, int frag)
+{
+	uint64_t *ddesc = op->data_desc + frag * 4;
+	int ret = (ddesc[0] >> 54) & 0x7;
+	ret |= (ddesc[3] & 0x1f) << 3;
+	return ret;
+}
+
+#define SET_PKT_LENGTH(x, y)       ((x) |= (((uint64_t)y & 0x7ff) << 43))
+#define CLEAR_PKT_LENGTH(x, y)     ((x) &= ~((uint64_t)0x7ff << 43))
+#define PKT_LENGTH(x, y)           (((x)->data_desc[y*4+0] >> 43) & 0x7ff)
+
+#define SET_NLHMAC(x)              ((x) |= (1ULL << 42))
+#define RESET_NLHMAC(x)            ((x) &= ~(1ULL << 42))
+#define IS_NLHMAC_SET(x,y)         ((x)->data_desc[y*4+0] & (1ULL << 42))
+
+#define SET_BREAK(x)               ((x) |= (1ULL << 41))
+#define RESET_BREAK(x)             ((x) &= ~(1ULL << 41))
+#define IS_BREAK_SET(x,y)          ((x)->data_desc[y*4+0] & (1ULL << 41))
+
+#define SET_WAIT(x)                ((x) |= (1ULL << 40))
+#define RESET_WAIT(x)              ((x) &= ~(1ULL << 40))
+#define IS_WAIT_SET(x,y)           ((x)->data_desc[y*4+0] & (1ULL << 40))
+
+#define SET_SEGMENT_ADDR(x, y)     ((x) |= ((uint64_t)y & ADDR_CACHELINE_MASK))
+#define CLEAR_SEGMENT_ADDR(x, y)   ((x) &= ~(ADDR_CACHELINE_MASK))
+#define SEGMENT_ADDR(x,y)          ((x)->data_desc[y*4+0] & ADDR_CACHELINE_MASK)
+
+#define SET_SRTCP(x)               ((x) |= (1ULL << 4))
+#define RESET_SRTCP(x)             ((x) &= ~(1ULL << 4))
+#define IS_SRTCP_SET(x,y)          ((x)->data_desc[y*4+0] & (1ULL << 4))
+
+#define SET_HASH_OFFSET(x, y) \
+do { \
+	uint64_t *x1 = &(x) + 1; \
+	uint64_t *x3 = &(x) + 3; \
+        int dword_off = y >> 3; \
+        *x3 |= ((uint64_t)y & 0x7) << 61; \
+	*x1 |= (uint64_t)(dword_off & 3) << 54; \
+	x |= ((uint64_t)(dword_off >> 2) & 1)  << 3; \
+} while(0)
+#define CLEAR_HASH_OFFSET(x) \
+do { \
+	uint64_t *x1 = &(x) + 1; \
+	uint64_t *x3 = &(x) + 3; \
+        *x3 = ~(7ULL << 61); \
+	x &= ~(1ULL << 3); \
+	*x1 &= ~(3ULL << 54); \
+}while(0)
+static inline unsigned int HASH_OFFSET(operation_pt op, int frag)
+{
+	uint64_t *ddesc = op->data_desc + frag * 4;
+	unsigned int ret = ((ddesc[0] << 2) & (1 << 5));
+	ret |= (ddesc[1] >> 51) & (3 << 3);
+	ret |= (ddesc[3] >> 61) & 7;
+	return ret;
+}
+
+#define SET_GLOBAL_SRC_DATA_OFFSET(x, y)    ((x) |= ((uint64_t)y & 7))
+#define CLEAR_GLOBAL_SRC_DATA_OFFSET(x, y)  ((x) &= ~(7ULL))
+#define GLOBAL_SRC_DATA_OFFSET(x,y)         ((x)->data_desc[y*4+0] & 7)
+
+/* Macros for fields in Cipher Destination (dstDataSettings) */
+#define SET_CIPHER_PREFIX(x)       ((x) |= (1ULL << 63))
+#define RESET_CIPHER_PREFIX(x)     ((x) &= ~(1ULL << 64))
+#define IS_CIPHER_PREFIX_SET(x,y)  ((x)->data_desc[y*4+1] & (1ULL << 63))
+
+#define SET_ENCRYPT(x)             ((x) |= (1ULL << 59))
+#define SET_DECRYPT(x)             ((x) &= ~(1ULL << 59))
+#define IS_ENCRYPT_SET(x,y)        ((x)->data_desc[y*4+1] & (1ULL << 59))
+
+#define SET_HASH_SRC(x)            ((x) |= (1ULL << 53))
+#define RESET_HASH_SRC(x)          ((x) &= ~(1ULL << 53))
+#define IS_HASH_SRC_SET(x,y)       ((x)->data_desc[y*4+1] & (1ULL << 53))
+
+#define SET_CIPHER_OFFSET(x, y)    \
+do { \
+	uint64_t *x1 = &(x) + 1; \
+	x |= ((uint64_t)(y & 0x7) << 56); \
+	if(y & (~0xf8)) { \
+		*x1 |= (((uint64_t)y >> 3) & 0x1f); \
+	} \
+} while(0)
+
+#define CLEAR_CIPHER_OFFSET(x)     \
+do { \
+	uint64_t *x1 = &(x) + 1; \
+	x &= ~((uint64_t)7 << 56); \
+	RESET_HASH_SRC(x); \
+	*x1 &= ~((uint64_t)0x1f); \
+} while(0)
+static inline uint64_t CIPHER_OFFSET(operation_pt op, int frag)
+{
+	uint64_t *ddesc = op->data_desc + frag * 4;
+	uint64_t ret = (ddesc[1] >> 56) & 7ULL;
+	ret |= (ddesc[2] & 0x1f) << 3;
+	return ret;
+}
+
+#define SET_CKSUM_OFFSET(x, y)      ((x) |= ((uint64_t)(y & 0xfff) << 41))
+#define CLEAR_CKSUM_OFFSET(x)       ((x) &= ~((uint64_t)0xfff << 41))
+#define CKSUM_OFFSET(x,y)           (((x)->data_desc[y*4+1] >> 41) & 0xfff)
+
+#define SET_CKSUM_SRC(x)            ((x) |= (1ULL << 40))
+#define RESET_CKSUM_SRC(x)          ((x) &= ~(1ULL << 40))
+#define IS_CKSUM_SRC_SET(x,y)       ((x)->data_desc[y*4+1] & (1ULL << 40))
+
+#define SET_CIPHER_DST_ADDR(x, y)   ((x) |= ((uint64_t)y & ADDR_CACHELINE_MASK))
+#define CLEAR_CIPHER_DST_ADDR(x, y) ((x) &= ~(ADDR_CACHELINE_MASK))
+#define DST_ADDR(x,y)               ((x)->data_desc[y*4+1] & ADDR_CACHELINE_MASK)
+
+/* Macros for fields in Authentication Destination (authDstNonceLow) */
+#define SET_NONCE(x, y) \
+do { \
+	uint64_t *x1 = &(x) + 1; \
+	x |= (((uint64_t)y & 0xffffff) << 40); \
+	*x1 |= ((uint64_t)(y & 0xff000000) << 16); \
+}while(0)
+
+#define CLEAR_NONCE(x, y) \
+do { \
+	uint64_t *x1 = &(x) + 1; \
+	x &= ~((uint64_t)0xffffff << 40); \
+	*x1 &= ~((uint64_t)0xff << 40); \
+} while(0)
+static inline uint64_t NONCE(operation_pt op, int frag)
+{
+	uint64_t *ddesc = op->data_desc + (frag << 2);
+	unsigned int ret = (ddesc[2] >> 40) & 0xffffff;
+	ret |= (ddesc[3] >> 16) & 0x00ff000000;
+	return ret;
+}
+
+#define SET_AUTH_DST_ADDR(x, y)   ((x) |= ((uint64_t)y & ADDR_CACHELINE_MASK))
+#define CLEAR_AUTH_DST_ADDR(x, y) ((x) &= ~(ADDR_CACHELINE_MASK))
+#define AUTH_DST_ADDR(x,y)        ((x)->data_desc[y*4+2] & ADDR_CACHELINE_MASK)
+
+/* Macros for fields in Cksum Dst Address (ckSumDstNonceHiCFBMaskLLWMask) */
+#define SET_HASH_BYTE_OFFSET(x, y)  ((x) |= ((uint64_t)(y & 0x7) << 61))
+#define CLEAR_HASH_BYTE_OFFSET(x)   ((x) &= ~((uint64_t)0x7 << 61))
+#define HASH_BYTE_OFFSET(x,y)       (((x)->data_desc[y*4+3] >> 61) & 7)
+
+#define SET_FRAG_PKT_LENGTH(x, y)   ((x) |= ((uint64_t)(y & 0x7) << 58))
+#define CLEAR_FRAG_PKT_LENGTH(x)    ((x) &= ~((uint64_t)0x7 << 58))
+#define FRAG_PKT_LENGTH(x,y)        (((x)->data_desc[y*4+3] >> 58) & 7)
+
+#define SET_LLW_MASK(x, y)          ((x) |= ((uint64_t)(y & 0x3) << 56))
+#define CLEAR_LLW_MASK(x)           ((x) &= ~((uint64_t)0x3 << 56))
+#define LLW_MASK(x,y)               (((x)->data_desc[y*4+3] >> 56) & 3)
+
+#define SET_CFB_MASK(x, y)          ((x) |= ((uint64_t)(y & 0xff) << 48))
+#define CLEAR_CFB_MASK(x)           ((x) &= ~((uint64_t)0xff << 48))
+#define CFB_MASK(x,y)               (((x)->data_desc[y*4+3] >> 48) & 0xff)
+
+#define SET_CCM(x)                  ((x) &= ~((uint64_t)0xff << 48), x |= (1ULL << 48))
+#define RESET_CCM(x)                ((x) &= ~((uint64_t)0xff << 48))
+#define IS_CCM_SET(x,y)             ((x)->data_desc[y*4+3] & (1ULL << 48))
+
+#define SET_CKSUM_DST_ADDR(x, y)    ((x) |= ((uint64_t)y & ADDR_CACHELINE_MASK))
+#define CLEAR_CKSUM_DST_ADDR(x, y)  ((x) &= ~(ADDR_CACHELINE_MASK))
+#define CKSUM_DST_ADDR(x,y)         ((x)->data_desc[y*4+3] & ADDR_CACHELINE_MASK)
+
+/* Security Free out Descriptor macros */
+#define CTRL_HEAD(x)                (((x)>>61)&0x3)
+#define CTRL_DEST_ID(x)             (((x)>>54)&0x7f)
+#define CTRL_DEST_CTRL(x)           (((x)>>49)&0x7)
+#define CTRL_ERROR(x)               (((x)>>40)&0x1ff)
+#define CTRL_RESP_ADDR(x)           ((x) & ADDR_CACHELINE_MASK)
+#define SCRATCH_VALUE(x)            ((x) & 0x1f)
+
+#define DATA_HEAD(x)                (((x)>>61)&0x3)
+#define DATA_DEST_ID(x)             (((x)>>54)&0x7f)
+#define DATA_DEST_CTRL(x)           (((x)>>49)&0x7)
+#define DATA_ERROR(x)               (((x)>>40)&0x1ff)
+#define DATA_RESP_ADDR(x)           ((x) & ADDR_CACHELINE_MASK)
+
+#define BOOL_STR(x)  ((x)?"TRUE":"FALSE")
+
+
+/**
+ * XLR RSA Security and Freeback Descriptors
+ */
+/**
+ * Control Descriptor
+ * This definition is previously defined
+ * SOP, SRC_ADDR, DestID
+ */
+#define SET_OP_CLASS(x, y)         ((x) |= ((uint64_t)(y & 0x1) << 54))
+#define CLEAR_OP_CLASS(x)          ((x) &= ~((uint64_t)0x7f << 54))
+#define OP_CLASS(x)                ((((x)->ctrl_msg[0]) >> 54) & 0x1)
+
+#define SET_VALID_OP(x)            ((x) |= (1ULL << 53))
+#define RESET_VALID_OP(x)          ((x) &= ~(1ULL << 53))
+#define IS_VALID_OP_SET(x)         (((x)->ctrl_msg[0]) & (1ULL << 53))
+
+#define SET_BLOCK_1024(x)          ((x) |= (1ULL << 52))
+#define RESET_BLOCK_1024(x)        ((x) &= ~(1ULL << 52))
+#define IS_BLOCK_1024_SET(x)       (((x)->ctrl_msg[0]) & (1ULL << 52))
+
+#define SET_LOAD_CONST(x)          ((x) |= (1ULL << 51))
+#define RESET_LOAD_CONST(x)        ((x) &= ~(1ULL << 51))
+#define IS_LOAD_CONST_SET(x)       (((x)->ctrl_msg[0]) & (1ULL << 51))
+
+#define SET_EXPONENT_WIDTH(x, y)   ((x) |= ((uint64_t)(y & 0x7ff) << 40))
+#define CLEAR_EXPONENT_WIDTH(x)    ((x) &= ~((uint64_t)0x7ff << 40))
+#define EXPONENT_WIDTH(x)          ((((x)->ctrl_msg[0]) >> 40) & 0x7ff)
+
+/* ECC fields */
+#define CLEAR_OP_CTRL0(x)          ((x) &= ~((uint64_t)0x1fff << 40))
+#define SET_ECC_CURVE(x, y)         ((x) |= ((uint64_t)(y & 0x7f) << 46))
+#define ECC_CURVE(x)                ((((x)->ctrl_msg[0]) >> 46) & 0x7f)
+
+#define SET_ECC_FUNCTION(x, y)     ((x) |= ((uint64_t)(y & 0x3f) << 40))
+#define ECC_FUNCTION(x)            ((((x)->ctrl_msg[0]) >> 40) & 0x3f)
+
+#define IS_PRIME_MODE_OP(x) (x < RMI_ECC_PRIME_CURVE_MAX)
+#define IS_BINARY_MODE_OP(x) (!(IS_PRIME_MODE_OP(x)))
+
+#define IS_PRIME_MODE(op) (IS_PRIME_MODE_OP(ECC_CURVE(op)))
+#define ECC_CURVE_STR(m)  \
+(IS_PRIME_MODE(m)?ecc_prime_curve_str[ECC_CURVE(m)]:ecc_binary_curve_str[ECC_CURVE(m) - \
+									 RMI_ECC_BINARY_163])
+
+#define ECC_FUNCTION_STR(op) \
+(IS_PRIME_MODE(op)?ecc_prime_func_str[ECC_FUNCTION(op)]:ecc_binary_func_str[ECC_FUNCTION(op)])
+
+#define SET_PKOP_SRC_ADDR(x, y)    ((x) |= ((uint64_t)y & ADDR_CACHELINE_MASK))
+#define CLEAR_PKOP_SRC_ADDR(x, y)  ((x) &= ~(ADDR_CACHELINE_MASK))
+#define PKOP_SRC_ADDR(x)           ((x)->ctrl_msg[0] & ADDR_CACHELINE_MASK)
+
+#define SET_PKOP_GLOBAL_SRC_OFFSET(x,y)   ((x) |= ((uint64_t)(y & 0x7)))
+#define CLEAR_PKOP_GLOBAL_SRC_OFFSET(x)   ((x) &= ~((uint64_t)0x7))
+#define PKOP_GLOBAL_SRC_OFFSET(x)         (((x)->ctrl_msg[0]) & 0x7)
+
+#define SET_CTRL_PK_SCRATCH_VALUE(x, y)   ((x) |= (((uint64_t)y & 0xc) << 1))
+#define CLEAR_PK_SCRATCH_VALUE(x)         ((x) &= (~((uint64_t)0x3 << 3)))
+#define CTRL_PK_SCRATCH_VALUE(x)          ((((x)->ctrl_msg[0]) & 0x18) >> 1)
+
+/**
+ * Data Descriptor
+ * EOP, DST_ADDR, DestStnId, WRB_COH, WRB_L2ALLOC, DF_L2ALLOC
+ */
+#define SET_MODULO_WIDTH(x, y)   ((x) |= ((uint64_t)(y & 0x7ff) << 40))
+#define CLEAR_MODULO_WIDTH(x)    ((x) &= ~((uint64_t)0x7ff << 40))
+#define MODULO_WIDTH(x)          ((((x)->data_msg[0]) >> 40) & 0x7ff)
+
+#define SET_PKOP_DST_ADDR(x, y)    ((x) |= ((uint64_t)y & ADDR_CACHELINE_MASK))
+#define CLEAR_PKOP_DST_ADDR(x, y)  ((x) &= ~(ADDR_CACHELINE_MASK))
+#define PKOP_DST_ADDR(x)         ((x)->data_msg[0] & ADDR_CACHELINE_MASK)
+
+#define SET_PKOP_GLOBAL_DST_OFFSET(x,y)   ((x) |= ((uint64_t)(y & 0x7)))
+#define CLEAR_PKOP_GLOBAL_DST_OFFSET(x)   ((x) &= ~((uint64_t)0x7))
+#define PKOP_GLOBAL_DST_OFFSET(x)         (((x)->data_msg[0]) & 0x7)
+
+#define SET_DATA_PK_SCRATCH_VALUE(x, y)   ((x) |= (((uint64_t)y & 0x3) << 3))
+#define DATA_PK_SCRATCH_VALUE(x)          ((((x)->data_msg[0]) >> 3) & 0x3)
+
+#ifdef __KERNEL__
+
+meminfo_pt alloc_meminfo_kernel_ctx(int order);
+
+int post_process_op(int result, operation_pt handle);
+
+void free_meminfo(meminfo_pt mem);
+
+int send_to_sae(meminfo_pt mem, int allow_async);
+
+void add_stats_count(control_struct_pt ctrl, int cpu);
+
+void xlr_inc_auth_stat(int hash_algo, int data_size);
+void xlr_inc_enc_stat(int cipher_algo, int cipher_mode, int data_size);
+
+#define getpagesize() PAGE_SIZE
+
+extern const unsigned int hash_map[];
+extern const char *cipher_str[MAX_CIPHER_ALGO];
+extern const char *mode_str[MAX_CIPHER_MODE];
+extern const char *hash_str[MAX_HASH_ALGO];
+extern const int valid_cipher_algo_mode_matrix[MAX_CIPHER_ALGO][MAX_CIPHER_MODE];
+extern const char *ecc_prime_curve_str[];
+extern const char *ecc_prime_func_str[];
+extern const char *ecc_binary_curve_str[];
+extern const char *ecc_binary_func_str[];
+extern const char *rsa_mod_str[];
+
+#endif /* __KERNEL__ */
+
+#endif /* _RMI_SECDESC_INTERNAL_H_ */
diff --git a/drivers/crypto/rmi/common/sec_api.c b/drivers/crypto/rmi/common/sec_api.c
new file mode 100644
index 0000000..79fe807
--- /dev/null
+++ b/drivers/crypto/rmi/common/sec_api.c
@@ -0,0 +1,3898 @@
+/***********************************************************************
+Copyright 2003-2009 RMI Corporation (RMI) All rights reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY RMI Corporation. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************_ RMI_2_**********************************/
+#ifdef __KERNEL__
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/hardirq.h>
+#include <linux/slab.h>
+
+#include <asm/rmi/sim.h>
+#include <asm/rmi/utils.h>
+#include <asm/rmi/msgring.h>
+
+#define SEC_PRINT(fmt, ...) \
+        printk(fmt, ## __VA_ARGS__)
+#define SEC_PRINTN(fmt, ...) \
+        printk("%s:%d " fmt, __FUNCTION__, __LINE__, ## __VA_ARGS__)
+#define MAP_FAILED ((void *) -1)
+#else
+#include <stdio.h>
+#include <assert.h>
+#include <stdlib.h>
+#include <errno.h>
+#include <unistd.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <fcntl.h>
+#include <sys/mman.h>
+#include <sys/ioctl.h>
+#include <string.h>
+#include <stdint.h>
+#include <utils.h>
+#include <xlr_fast_syscall.h>
+
+#if defined(MEM_CACHE) || defined(MEM_STATS)
+#include <pthread.h>
+#endif /* MEM_CACHE */
+
+#define SEC_PRINT(fmt, ...) \
+        fprintf(stderr, fmt, ## __VA_ARGS__)
+#define SEC_PRINTN(fmt, ...) \
+        fprintf(stderr, "%s:%d " fmt, __FUNCTION__, __LINE__, ## __VA_ARGS__)
+#endif /* __KERNEL__ */
+
+#include "rmisec_internal.h"
+
+#ifdef MEM_STATS
+static pthread_mutex_t mstat_lock = PTHREAD_MUTEX_INITIALIZER;
+static uint64_t malloc_cnt = 0;
+static uint64_t free_cnt = 0;
+#endif /* MEM_STATS */
+
+
+/* All the definitions below are used in rmisec.c, and so are not declared
+ * static.
+ */
+const char *devname="/dev/" DRIVER_NAME;
+
+const char *op_type_str[OP_ALL] = {
+	"NOP",
+	"CRYPTO",
+	"RSA",
+	"ECC"
+};
+
+const char *cipher_str[MAX_CIPHER_ALGO] __attribute__((unused)) = {
+	"CIPHER_BYPASS",
+	"DES",
+	"3DES",
+	"AES128",
+	"AES192",
+	"AES256",
+	"ARC4",
+	"KASUMI_F8",
+};
+
+unsigned int cipher_sizes[MAX_CIPHER_ALGO] __attribute__((unused)) = {
+	0,
+	DES_SIZE,
+	DES3_SIZE,
+	AES128_SIZE,
+	AES192_SIZE,
+	AES256_SIZE,
+	ARC4_SIZE,
+	KASUMI_F8_SIZE
+};
+
+const char *mode_str[MAX_CIPHER_MODE] __attribute__((unused)) = {
+	"ECB",
+	"CBC",
+	"CFB",
+	"OFB",
+	"CTR",
+	"F8",
+	"CCM"
+};
+
+const char *rsa_mod_str[2] = {
+	"RSA 512",
+	"RSA 1024"
+};
+
+unsigned int cipher_mode_factors[MAX_CIPHER_MODE] __attribute__((unused)) = {
+	ECB_FACTOR,
+	CBC_FACTOR,
+	CFB_FACTOR,
+	OFB_FACTOR,
+	CTR_FACTOR,
+	F8_FACTOR,
+	CTR_FACTOR /* CCM is same as CTR */
+};
+
+unsigned int key_sizes[MAX_CIPHER_ALGO][MAX_CIPHER_MODE] = {
+	{0},                          /* BYPASS */
+	{8, 8, 8, 8, 8, 8, 8},        /* DES */
+	{24, 24, 24, 24, 24, 24, 24}, /* 3DES */
+	{16, 16, 16, 16, 16, 32, 16}, /* AES128 */
+	{24, 24, 24, 24, 24, 48, 24}, /* AES192 */
+	{32, 32, 32, 32, 32, 64, 32}, /* AES256 */
+	{32, 32, 32, 32, 32, 32, 32}, /* ARC4 */
+	{16, 16, 16, 16, 16, 16, 16}, /* Kasumi-F8 */
+};
+
+int iv_sizes[MAX_CIPHER_ALGO][MAX_CIPHER_MODE] = {
+	{0},                      /* BYPASS */
+	{0, 8, 8, 8, 8, 8, 8},       /* DES */
+	{0, 8, 8, 8, 8, 8, 8},       /* DES3 */
+	{8, 16, 16, 16, 16, 8, 16},   /* AES128 */
+	{8, 16, 16, 16, 16, 8, 16},   /* AES192 */
+	{8, 16, 16, 16, 16, 8, 16},   /* AES256 */
+	{0},                          /* ARC4 */
+	{16, 16, 16, 16, 16, 16, 16},   /* KASUMI F8 */
+};
+
+const char *hash_str[MAX_HASH_ALGO] __attribute__((unused)) = {
+	"HASH_BYPASS",
+	"MD5",
+	"SHA1",
+	"SHA256",
+	"SHA384",
+	"SHA512",
+	"GCM",
+	"KASUMI_F9",
+	"3DES-CMAC",
+	"AES-CMAC"
+};
+
+const unsigned int hash_num[MAX_HASH_ALGO] = {
+	0,
+	1,
+	2,
+	3,
+	8,
+	9,
+	10,
+	11,
+	12,
+	13
+};
+
+const unsigned int hash_map[] = {
+	HASH_BYPASS,
+	RMI_MD5,
+	RMI_SHA1,
+	RMI_SHA256,
+	-1, -1, -1, -1,
+	RMI_SHA384,
+	RMI_SHA512,
+	RMI_GCM,
+	RMI_KASUMI_F9,
+	RMI_DES3_CMAC,
+	RMI_AES_CMAC
+};
+
+const unsigned int hash_input_sizes[MAX_HASH_ALGO] = {
+	0,
+	MD5_SIZE,
+	SHA1_SIZE,
+	SHA256_SIZE,
+	SHA384_SIZE,
+	SHA512_SIZE,
+	GCM_SIZE,
+	KASUMI_F9_SIZE,
+	DES3_CMAC_SIZE,
+	AES_CMAC_SIZE
+};
+
+const unsigned int arc4_padding_sizes[MAX_HASH_ALGO] = {
+	0,
+	6,
+	6,
+	6,
+	6,
+	6,
+	6,
+	6,
+	6,
+	6
+};
+
+const int valid_cipher_algo_mode_matrix[MAX_CIPHER_ALGO][MAX_CIPHER_MODE] =
+{{0}, /* CIPHER_BYPASS */
+ {1, 1, 0, 0, 0, 0, 0}, /* RMI_DES */
+ {1, 1, 0, 0, 0, 0, 0}, /* RMI_DES3 */
+ {1, 1, 1, 1, 1, 1, 1}, /* RMI_AES128 */
+ {1, 1, 1, 1, 1, 1, 1}, /* RMI_AES192 */
+ {1, 1, 1, 1, 1, 1, 1}, /* RMI_AES256 */
+ {1, 0, 0, 0, 0, 0, 0}, /* RMI_ARC4 */
+ {1, 1, 1, 1, 1, 1, 1}, /* RMI_F8 */
+};
+
+int ecc_prime_data_size[6] = {3, 3, 4, 4, 6, 8};
+int ecc_prime_k_size[6] = {4, 4, 4, 4, 8, 8};
+int ecc_binary_data_size[3] = {3, 3, 4};
+
+int ecc_prime_output_bytes[6] = {20, 24, 28, 32, 48, 64};
+int ecc_binary_output_bytes[3] = {21, 24, 30};
+
+const char *ecc_prime_curve_str[RMI_ECC_PRIME_CURVE_MAX] = {
+	"PRIME_160",
+	"PRIME_192",
+	"PRIME_224",
+	"PRIME_256",
+	"PRIME_384",
+	"PRIME_512"
+};
+
+const char *ecc_binary_curve_str[RMI_ECC_BINARY_CURVE_MAX] = {
+	"BINARY_163",
+	"BINARY_191",
+	"BINARY_233"
+};
+
+const char *ecc_prime_func_str[RMI_ECC_PRIME_OP_MAX] = {
+	"PRIME_P_MUL",
+	"PRIME_P_ADD",
+	"PRIME_P_2X",
+	"PRIME_P_VFY",
+	"PRIME_M_ADD",
+	"PRIME_M_SUB",
+	"PRIME_M_MUL",
+	"PRIME_M_DIV",
+	"PRIME_M_INV",
+	"PRIME_M_RED"
+};
+
+const char *ecc_binary_func_str[RMI_ECC_BINARY_OP_MAX] = {
+	"BINARY_P_MUL",
+	"BINARY_GF_INV",
+	"BINARY_GF_MUL",
+	"BINARY_GF_ADD"
+};
+
+#ifdef USER_SPACE_STATS
+uint32_t stats_cnt[MAX_CIPHER_ALGO][MAX_CIPHER_MODE] ={{0}};
+uint32_t hash_stats_cnt[MAX_HASH_ALGO] ={0};
+uint32_t fail_cnt[MAX_CIPHER_ALGO][MAX_CIPHER_MODE] ={{0}};
+uint32_t mod_exp_called = 0;
+uint32_t mod_exp_failed = 0;
+uint32_t mod_exp_completed = 0;
+
+int print_stats(unsigned char *buf, int len)
+{
+	int x = len, i, j, t;
+	unsigned char *m = buf;
+	t = snprintf((char *)m, x, "Successful / Failed operations:\n");
+	x -= t;
+	m += t;
+	if(x <= 0) {
+		goto end;
+	}
+
+	for(i = 1; i < MAX_CIPHER_ALGO; ++i) {
+		t = snprintf((char *)m, x, "%-9s:", cipher_str[i]);
+		x -= t;
+		m += t;
+		if(x <= 0) {
+			goto end;
+		}
+		for(j = 0; j < MAX_CIPHER_MODE; ++j) {
+			t = snprintf((char *)m, x, "%4s =%8u / %-6u ",
+				     mode_str[j], stats_cnt[i][j], fail_cnt[i][j]);
+			x -= t;
+			m += t;
+			if(x <= 0) {
+				goto end;
+			}
+		}
+		t = snprintf((char *)m, x, "\n");
+		x -= t;
+		m += t;
+		if(x <= 0) {
+			goto end;
+		}
+	}
+
+	t = snprintf((char *)m, x, "Hash Algorithms\n");
+	x -= t;
+	m += t;
+	if(x <= 0) {
+		goto end;
+	}
+
+	for(i = 1; i < MAX_HASH_ALGO; ++i) {
+		t = snprintf((char *)m, x, "%-9s\t:\t%u\n",
+			     hash_str[i], hash_stats_cnt[i]);
+		x -= t;
+		m += t;
+		if(x <= 0) {
+			goto end;
+		}
+	}
+
+	t = snprintf((char *)m, x, "Mod Exp stats:\n");
+	x -= t;
+	m += t;
+	if(x <= 0) {
+		goto end;
+	}
+
+	t = snprintf((char *)m, x, "Mod exp called=%u\n", mod_exp_called);
+	x -= t;
+	m += t;
+	if(x <= 0) {
+		goto end;
+	}
+
+	t = snprintf((char *)m, x, "Mod exp failed=%u\n", mod_exp_failed);
+	x -= t;
+	m += t;
+	if(x <= 0) {
+		goto end;
+	}
+
+	t = snprintf((char *)m, x, "Mod exp completed=%u\n", mod_exp_completed);
+	x -= t;
+	m += t;
+	if(x <= 0) {
+		goto end;
+	}
+
+ end:
+	return (m - buf);
+}
+
+#endif /* USER_SPACE_STATS */
+
+void print_hext_string(const unsigned char *y, int len)
+{
+	int i;
+	char buf[1025] = {0};
+
+	for (i = 0; i < len; ++i) {
+		sprintf(buf + (i << 1), "%02x", (unsigned char)y[i]);
+	}
+	buf[i << 1] = '\0';
+	SEC_PRINT("%s", buf);
+	return;
+}
+
+#if 0
+void
+print_buf(const char *name, unsigned char *buf, unsigned int len)
+{
+	unsigned int i;
+	fprintf(stderr, "%s[%u]=[\n", name, len);
+	for(i = 0; i < len; ++i) {
+		fprintf(stderr, "%02x%c", buf[i], (((i+1)%32))?' ':'\n');
+	}
+	fprintf(stderr, "]\n");
+}
+#endif
+
+void
+print_4k(unsigned char *ptr, unsigned long addr)
+{
+#define NUM_PER_LINE 32
+#define PR_BYTES (128 * 10)
+#define BUF_LEN 1023
+	int y, l = 0;
+	int i = PR_BYTES/NUM_PER_LINE;
+	char buf[BUF_LEN + 1], *tmp = &buf[0];
+	int x = BUF_LEN;
+	buf[0] = '\0';
+	addr &= 0xfff;
+
+	for(i = 0; i < PR_BYTES/NUM_PER_LINE; ++i) {
+		l = snprintf(tmp, x, "%3lx : ", (addr + i * NUM_PER_LINE));
+		tmp += l;
+		x -= l;
+		if(x <= 0) goto disp;
+
+		for(y = 0; y < NUM_PER_LINE; ++y) {
+			l = snprintf(tmp, x, "%02hx ", ptr[i*NUM_PER_LINE + y]);
+			tmp += l;
+			x -= l;
+			if(x <= 0) goto disp;
+
+		}
+		l = snprintf(tmp, x, "\n");
+		tmp += l;
+		x -= l;
+disp:
+		SEC_PRINT(buf);
+		tmp = &buf[0];
+		x = BUF_LEN;
+		l = 0;
+		buf[0] = '\0';
+	}
+	return;
+}
+
+#ifdef __KERNEL__
+void *
+get_mem_from_pool(operation_pt op)
+{
+	meminfo_pt mem;
+	int pages = op->nr_pages;
+	int order = 31 - find_32bit_1st_one_bit(pages);
+
+	if(pages < 1) {
+		return NULL;
+	}
+
+	order += HAS_REMINDER(pages, order);
+
+	mem = alloc_meminfo_kernel_ctx(order);
+	if(mem) {
+		return mem->ptr;
+	} else {
+		return NULL;
+	}
+}
+
+#define free_mem_to_pool(a, b)
+
+#else
+#ifdef MEM_CACHE
+typedef struct mem_entry {
+	struct mem_entry *next;
+	int order;
+	void *ptr;
+	pid_t pid;
+} mem_entry_t, *mem_entry_pt;
+
+
+#define MAX_ORDER 10
+int mem_max_size[MAX_ORDER] = {10, 10, 5, 4, 3, 2, 1, 1, 1, 1};
+int mem_count[MAX_ORDER] = {0};
+mem_entry_pt mem_cache[MAX_ORDER] = {0};
+pid_t mem_cache_owner[MAX_ORDER] = {0};
+static pthread_mutex_t c_lock[MAX_ORDER] = {PTHREAD_MUTEX_INITIALIZER};
+
+static mem_entry_pt free_list = NULL;
+static pid_t free_list_owner = 0;
+static pthread_mutex_t f_lock = PTHREAD_MUTEX_INITIALIZER;
+
+static inline void
+clean_memlist(mem_entry_pt list)
+{
+	mem_entry_pt memptr = list, tmp = list;
+	while(tmp) {
+		tmp = memptr->next;
+		free(memptr);
+#ifdef MEM_STATS
+		pthread_mutex_lock(&mstat_lock);
+		free_cnt++;
+		pthread_mutex_unlock(&mstat_lock);
+#endif /* MEM_STATS */
+		memptr = tmp;
+	}
+	return;
+}
+
+void *
+get_mem_from_pool(operation_pt op)
+{
+	void *ret = NULL;
+	int fd = op->fd;
+	int pages = op->nr_pages;
+	int order = 31 - find_32bit_1st_one_bit(pages);
+	unsigned int size;
+	mem_entry_pt tmp = NULL;
+	pid_t pid = getpid();
+
+	if(fd < 0 || pages < 1) {
+		return NULL;
+	}
+
+	order = 31 - find_32bit_1st_one_bit(pages);
+	order += HAS_REMINDER(pages, order);
+
+	if(order < MAX_ORDER) {
+		pthread_mutex_lock(&c_lock[order]);
+		if(mem_cache_owner[order] != pid) {
+			clean_memlist(mem_cache[order]);
+			mem_cache[order] = NULL;
+			mem_count[order] = 0;
+			mem_cache_owner[order] = pid;
+		}
+#ifdef MEMPOOL_DEBUG
+		SEC_PRINT("%s:%d Memory available in pool order=%d mem_count=%u "
+			  "mem_cache_ptr=%p mem_cache_addr=%p\n", __FUNCTION__,
+			  __LINE__, order,
+			  mem_count[order], mem_cache[order], &mem_cache[order]);
+#endif /* MEMPOOL_DEBUG */
+		if(mem_cache[order] != NULL && mem_count[order] > 0) {
+			tmp = mem_cache[order];
+			mem_cache[order] = tmp->next;
+			tmp->next = NULL;
+			ret = tmp->ptr;
+			mem_count[order]--;
+		}
+		pthread_mutex_unlock(&c_lock[order]);
+
+		if(tmp) {
+			pthread_mutex_lock(&f_lock);
+			if(free_list_owner != pid) {
+				clean_memlist(free_list);
+				free_list = NULL;
+				free_list_owner = pid;
+			}
+			tmp->ptr = NULL;
+			tmp->order = -1;
+			tmp->next = free_list;
+			free_list = tmp;
+			pthread_mutex_unlock(&f_lock);
+		}
+	}
+
+	if(ret) {
+		control_struct_pt ctrl = (control_struct_pt)ret;
+		if(ctrl->magic != DRIVER_MAGIC && ctrl->owner != pid) {
+			SEC_PRINT("%s:%d Bad magic or owner ptr=%p magic=%" LLX_FMT
+				  " owner=0x%x pid=0x%x\n",
+			       __FUNCTION__, __LINE__, ret, ctrl->magic, ctrl->owner, pid);
+			ret = NULL;
+		}
+	} else {
+#ifdef MEMPOOL_DEBUG
+		SEC_PRINT("%s:%d No memory available in pool.  Get it from "
+			  "kernel pages=%d order=%d\n", __FUNCTION__, __LINE__,
+			  pages, order);
+#endif
+		size = (1 << order) * getpagesize();
+		ret = mmap(0, size, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);
+		if(ret != MAP_FAILED) {
+			control_struct_pt ctrl = (control_struct_pt)ret;
+			/* 
+			 * critical to memset, so that MMU maps the physical page
+			 * to the VM.  Otherwise ioctl will not see it.
+			*/
+			memset(ctrl, 0, sizeof(control_struct_t));
+			if((ioctl(fd, RMISEC_IOCTL_GET_MEMINFO, ret) < 0) ||
+			   (ctrl->mem_addr == 0)) {
+				SEC_PRINT("%s:%d fd=%d ret=%p mem=%" LLX_FMT "\n", __FUNCTION__,
+					  __LINE__, fd, ret, ctrl->mem_addr);
+				munmap(ret, size);
+				ret = MAP_FAILED;
+			}
+		}
+	}
+	return ret;
+}
+
+void
+free_mem_to_pool(int pages, void *ptr)
+{
+	mem_entry_pt memptr = NULL;
+	control_struct_pt ctrl = (control_struct_pt)ptr;
+	int order;
+	pid_t pid = getpid();
+
+	if(ptr == NULL || ptr == MAP_FAILED) {
+		return;
+	}
+
+	if(pages < 1) {
+		return;
+	}
+
+	if(ctrl->magic != DRIVER_MAGIC || ctrl->owner != pid) {
+		SEC_PRINT("%s:%d Invalid magic %" LLX_FMT " or owner (0x%x/0x%x) ptr=%p\n",
+			  __FUNCTION__, __LINE__, ctrl->magic, ctrl->owner, pid, ptr);
+		return;
+	}
+
+	order = 31 - find_32bit_1st_one_bit(pages);
+	order += HAS_REMINDER(pages, order);
+
+	if(order < MAX_ORDER && ctrl->magic == DRIVER_MAGIC) {
+		pthread_mutex_lock(&f_lock);
+		memptr = free_list;
+		if(pid != free_list_owner) {
+			clean_memlist(free_list);
+			free_list = memptr = NULL;
+			free_list_owner = pid;
+		}
+
+		if(memptr) {
+			free_list = memptr->next;
+			memptr->next = NULL;
+		}
+		pthread_mutex_unlock(&f_lock);
+
+		if(memptr == NULL) {
+			memptr = (mem_entry_pt)malloc(sizeof(mem_entry_pt));
+#ifdef MEM_STATS
+			pthread_mutex_lock(&mstat_lock);
+			malloc_cnt++;
+			pthread_mutex_unlock(&mstat_lock);
+#endif /* MEM_STATS */
+		}
+
+		if(memptr) {
+			memptr->ptr = ptr;
+			memptr->order = order;
+			pthread_mutex_lock(&c_lock[order]);
+			if(mem_count[order] < mem_max_size[order]) {
+				memptr->next = mem_cache[order];
+				mem_cache[order] = memptr;
+				mem_count[order]++;
+#ifdef MEMPOOL_DEBUG
+				SEC_PRINT("%s:%d Adding memory to pool order=%d ptr=%p "
+					  "mem_count=%u memcache_ptr=%p memcache_addr=%p\n",
+					  __FUNCTION__, __LINE__, order, ptr,
+					  mem_count[order], mem_cache[order],
+					  &mem_cache[order]);
+#endif /* MEMPOOL_DEBUG */
+				ptr = NULL;
+			} else {
+				free(memptr);
+#ifdef MEM_STATS
+				pthread_mutex_lock(&mstat_lock);
+				free_cnt++;
+				pthread_mutex_unlock(&mstat_lock);
+#endif /* MEM_STATS */
+			}
+			pthread_mutex_unlock(&c_lock[order]);
+		}
+	}
+
+	if(ptr != NULL) {
+#ifdef MEMPOOL_DEBUG
+		SEC_PRINT("%s:%d Max memory in cache reached.  Freeing memory "
+			  "to kernel pages=%d ptr=%p\n", __FUNCTION__, __LINE__,
+			  pages, ptr);
+#endif /* MEMPOOL_DEBUG */
+		munmap(ptr, (1 << order) * getpagesize());
+	}
+	return;
+}
+
+#else
+void *
+get_mem_from_pool(operation_pt op)
+{
+	int fd = op->fd;
+	int pages = op->nr_pages;
+	int order = 31 - find_32bit_1st_one_bit(pages);
+	size_t size = 0;
+	void *ret = NULL;
+
+	if(fd < 0 || pages < 1) {
+		errno = -EINVAL;
+		return 0;
+	}
+
+	order += HAS_REMINDER(pages, order);
+
+	size = (1 << order) * getpagesize();
+	ret = mmap(0, size, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);
+	if(ret != MAP_FAILED) {
+		control_struct_pt ctrl = (control_struct_pt)ret;
+		/* 
+		 * critical to memset, so that MMU maps the physical page
+		 * to the VM.  Otherwise ioctl will not see it.
+		*/
+		memset(ctrl, 0, sizeof(control_struct_t));
+		if((ioctl(fd, RMISEC_IOCTL_GET_MEMINFO, ret) < 0) ||
+		   (ctrl->mem_addr == 0)) {
+			SEC_PRINT("%s:%d fd=%d ret=%p mem=%llx\n", __FUNCTION__, __LINE__,
+				  fd, ret, ctrl->mem_addr);
+			munmap(ret, size);
+			ret = MAP_FAILED;
+		}
+	} else {
+		SEC_PRINT("%s:%d fd=%d size=%zu, ret=%p\n", __FUNCTION__, __LINE__,
+				  fd, size, ret);
+	}
+	return ret;
+}
+
+void
+free_mem_to_pool(int pages, void *ptr)
+{
+	int order = 31 - find_32bit_1st_one_bit(pages);
+	size_t size;
+
+	if(pages < 1) {
+		return;
+	}
+
+	order += HAS_REMINDER(pages, order);
+	size = (1 << order) * getpagesize();
+	munmap(ptr, size);
+	return;
+}
+
+#endif /* MEM_CACHE */
+#endif /* __KERNEL__ */
+
+int hash_output_sizes[MAX_HASH_ALGO] = {
+	0,
+	16,
+	20,
+	32,
+	48,
+	64,
+	16,
+	8,   /* Based on ETSI F9 Test vector data */
+	8,
+	16
+};
+
+int get_hash_output_bytes(HashAlgo_t h)
+{
+	return hash_output_sizes[h];
+}
+
+/**
+ * Function: rsa_data_copy
+ * copies 64 byte data quantities in reverse order.
+ * dst: destination pointer
+ * src: source pointer
+ * len: source len in bytes
+ * dlen: destination len in dwords (optional: value < 1 is ignored)
+ */
+int dword_data_copy(uint64_t *dst, uint64_t *src, int len, int dlen)
+{
+	int idx = len >> 3;
+	int dword_size, i, ret = (idx + HAS_REMINDER(len, 3));
+	char *tmp;
+
+	if(len & 0x7) {
+		tmp = (char *)(dst + idx);
+		tmp += (8 - (len & 0x7));
+		memcpy(tmp, src, (len & 0x7));
+
+		tmp = (char *)src;
+		src = (uint64_t *)(tmp + (len & 0x7));
+	}
+
+	dword_size = idx;
+	idx --;
+
+	for(i = 0; i < dword_size; ++i) {
+		dst[idx--] = src[i];
+	}
+
+	if(ret < dlen) {
+		ret = dlen;
+	}
+
+	return ret;
+}
+
+int result_copy(uint64_t *dst, uint64_t *src, int len, int dlen)
+{
+	int idx = len-1;
+	int dword_size = len << 3, i = 0;
+	unsigned char *tmp, *tmp2 = (unsigned char *)dst;
+
+	if(dlen > 0 && dword_size > dlen) {
+		int off = (dword_size - dlen);
+		tmp = (unsigned char *)(src + idx);
+		tmp += off;
+
+		memcpy(tmp2, tmp, (8 - off));
+		tmp2 += (8 - off);
+		idx--;
+		dword_size = dlen;
+
+	}
+
+	for(i = 0; i <= idx; ++i) {
+		 memcpy((tmp2+(i*8)), src+(idx-i), 8);
+	}
+
+
+	return dword_size;
+}
+
+void
+print_crypto_coperation(Crypto_Operation_pt cop)
+{
+	SEC_PRINT(
+	       "Cipher Algo=%s "
+	       "Cipher Mode=%s "
+	       "Key=%p "
+	       "key_len=%u "
+	       "iv=%p "
+	       "iv_len=%u "
+	       "encrypt=%s "
+	       "Hash Algo=%s "
+	       "HMAC=%p "
+	       "HMAC len=%u\n"
+	       "Input=%p "
+	       "Input len=%u "
+	       "Input vec=%p "
+	       "Input vec len=%u\n"
+	       "Output=%p "
+	       "Digest output=%p\n",
+	       cipher_str[cop->c], mode_str[cop->m],
+	       cop->key, cop->key_len, cop->iv, cop->iv_len,
+	       BOOL_STR(cop->encrypt), HASH_ALGO_STR(cop->h),
+	       cop->hmac, cop->hmac_len, cop->input, cop->input_len, cop->input_vec,
+	       cop->input_vec_len, cop->output, cop->digest);
+	return;
+}
+
+void
+print_crypto_operation(operation_pt op)
+{
+#ifndef FUNCTION_TRACE
+	int i;
+	SEC_PRINT("FIELD_SIZE=%d FRAG_CUNK_SIZE=%d TOTAL SIZE=%d\n",
+		  MAX_FRAG_FIELD_SIZE, FRAG_CHUNK_SIZE, MAX_FRAG_TOT_SIZE);
+
+	SEC_PRINT(
+	       "VERSION        =%x\n"
+	       "MAGIC          =0x%016" LLX_FMT "\n"
+	       "PHY_ADDR       =0x%016" LLX_FMT "\n"
+	       "VIRT_ADDR      =%p\n"
+	       "CTRL_INSTR_ADDR=%p\n"
+	       "CTRL_INSTR     =0x%016" LLX_FMT "\n"
+	       "CTRL_MSG       =0x%016" LLX_FMT "\n"
+	       "CTRL_LENGTH    =%" LLD_FMT "\n"
+	       "DATA_MSG       =0x%016" LLX_FMT "\n"
+	       "DATA_DESC_ADDR =%p\n"
+	       "NR PAGES       =%d\n"
+	       "NR FRAGMENTS   =%d\n"
+	       "INPUT LENGTH   =%d\n"
+	       "OUTPUT_LENGTH  =%d\n"
+	       "HASH_LENGTH    =%d\n",
+	       OP_VERSION(op), OP_MAGIC(op), OP_PHY_ADDR(op), op->ptr,
+	       op->ctrl_instr, op->ctrl_instr[0], op->ctrl_msg[0],
+	       CTRL_LENGTH(op), op->data_msg[0], op->data_desc,
+	       op->nr_pages, op->nr_ddesc, op->length, op->output_length,
+	       op->hash_length);
+
+	SEC_PRINT("Input         =%p\n"
+	       "Output        =%p\n"
+	       "Hash Output   =%p\n"
+	       "Cksum Output  =%p\n",
+	       op->data, op->output, op->hash_output, op->cksum);
+#endif /* FUNCTION_TRACE */
+	SEC_PRINT("CIPHER_ALGO=%s CIPHER_MODE=%s INCP_KEY=%s "
+		  "ARC4_KEYLEN=%" LLX_FMT" HASH_ALGO=%s(%" LLX_FMT
+		  ") HMAC=%s INHS_KEY=%s CKSUM=%s OVERRIDE_CIPHER=%s\n",
+		  CIPHER_ALGO_STR(op), CIPHER_MODE_STR(op),
+		  BOOL_STR(IS_INCP_KEY_SET(op)), ARC4_KEYLEN(op),
+		  HASH_ALGO_STR(HASH_ALGO(op)), HASH_ALGO(op),
+		  BOOL_STR(IS_HMAC_SET(op)), BOOL_STR(IS_INHS_KEY_SET(op)),
+		  BOOL_STR(IS_CKSUM_SET(op)),BOOL_STR(IS_OVERRIDE_CIPHER_SET(op)));
+
+#ifndef FUNCTION_TRACE
+
+	for(i = 0; i < op->nr_ddesc; ++i) {
+		SEC_PRINT("FRAGMENT: %d\n", i);
+		SEC_PRINT("srcLengthIVOffUseIVNext      = 0x%016" LLX_FMT "\n"
+			  "dstDataSettings              = 0x%016" LLX_FMT "\n"
+			  "authDstNonceLow              = 0x%016" LLX_FMT "\n"
+			  "cksumDstNonceHiCFBMaskLLWMask= 0x%016" LLX_FMT "\n",
+			  op->data_desc[i*4+0], op->data_desc[i*4+1],
+			  op->data_desc[i*4+2], op->data_desc[i*4+3]);
+
+		SEC_PRINT("CIPHER_PREFIX=%s CIPHER_SRC_ADDR=0x%016llx "
+			  "CIPHER_DST_ADDR=0x%016llx "
+			  "CIPHER_OFFSET=%" LLD_FMT " dwords ENCRYPT=%s "
+			  "PKT_LENGTH=%" LLU_FMT " dwords\nNONCE=%" LLX_FMT
+			  " HASH_SRC=%s HASH_SRC_ADDR=0x%016llx "
+			  "HASH_OFFSET=%d bytes HASH_DST_ADDR=0x%016llx "
+			  "PAD_HASH=%s HASH_BYTE_CNT=%" LLX_FMT " LOAD_HMAC_KEY=%s "
+			  "USE_IV=%s IV/AAD_OFFSET=%x\n",
+			  BOOL_STR(IS_CIPHER_PREFIX_SET(op, i)),
+			  SEGMENT_ADDR(op,i), DST_ADDR(op,i), CIPHER_OFFSET(op,i),
+			  BOOL_STR(IS_ENCRYPT_SET(op,i)),
+			  PKT_LENGTH(op,i), NONCE(op,i),
+			  BOOL_STR(IS_HASH_SRC_SET(op, i)), SEGMENT_ADDR(op,i),
+			  HASH_OFFSET(op,i),
+			  AUTH_DST_ADDR(op,i), BOOL_STR(IS_PAD_HASH_SET(op,i)),
+			  HASH_BYTE_CNT(op,i),
+			  BOOL_STR(IS_LOAD_HMAC_KEY_SET(op, i)),
+			  BOOL_STR(IS_USEIV_SET(op, i)),
+			  IV_OFFSET(op, i));
+
+		SEC_PRINT("CKSUM_OFFSET = %" LLD_FMT " words "
+			  "CKSUM_DST_ADDR = 0x%016llx\n",
+			  CKSUM_OFFSET(op,i), CKSUM_DST_ADDR(op,i));
+
+		SEC_PRINT("CFBMASK=%" LLX_FMT "\n", CFB_MASK(op,i));
+	}
+
+#endif /* FUNCTION_TRACE */
+
+	return;
+}
+
+static inline void
+print_rsa_operation(operation_pt op)
+{
+	SEC_PRINT("CTRL_MSG=0x%016" LLX_FMT "\n"
+	       "DATA_MSG=0x%016" LLX_FMT "\n",
+	       op->ctrl_msg[0], op->data_msg[0]);
+
+	SEC_PRINT("PHY_ADDR=0x%016" LLX_FMT "\n"
+	       "CTRL_SOP=%" LLX_FMT "\n"
+	       "VALILD OP=%s\n"
+	       "OP_CLASS=%s\n"
+	       "BLOCK_SIZE(F-512, T-1024)=%s\n"
+	       "LOAD_CONST=%s\n"
+	       "PKOP_SRC_ADDR=0x%016llx\n"
+	       "EXPONENT_WIDTH=0x%" LLX_FMT "\n"
+	       "GLOBAL_SRC_OFFSET=%" LLX_FMT "\n",
+	       OP_PHY_ADDR(op), CTRL_SOP(op), BOOL_STR(IS_VALID_OP_SET(op)),
+	       (OP_CLASS(op)==1ULL)?"ECC":"RSA",
+	       BOOL_STR(IS_BLOCK_1024_SET(op)),
+	       BOOL_STR(IS_LOAD_CONST_SET(op)),
+	       PKOP_SRC_ADDR(op),
+	       EXPONENT_WIDTH(op),
+	       PKOP_GLOBAL_SRC_OFFSET(op));
+
+	SEC_PRINT("DATA_EOP=%" LLX_FMT "\n"
+	       "MODULO_WIDTH=0x%" LLX_FMT "\n"
+	       "PKOP_DST_ADDR=0x%016llx\n"
+	       "PKOP_GLOBAL_DST_OFFSET=%" LLX_FMT "\n",
+	       DATA_EOP(op), MODULO_WIDTH(op),
+	       PKOP_DST_ADDR(op), PKOP_GLOBAL_DST_OFFSET(op));
+	return;
+}
+
+static inline void
+print_ecc_operation(operation_pt op)
+{
+	SEC_PRINT("CTRL_MSG=0x%016" LLX_FMT "\n"
+	       "DATA_MSG=0x%016" LLX_FMT "\n",
+	       op->ctrl_msg[0], op->data_msg[0]);
+
+	SEC_PRINT("PHY_ADDR=0x%016" LLX_FMT "\n"
+	       "CTRL_SOP=%" LLX_FMT "\n"
+	       "VALILD OP=%s\n"
+	       "OP_CLASS=%s\n"
+	       "ECC_CURVE=%s\n"
+	       "ECC_FUNC=%s\n"
+	       "PKOP_SRC_ADDR=0x%016llx\n"
+	       "GLOBAL_SRC_OFFSET=%" LLX_FMT "\n",
+	       OP_PHY_ADDR(op), CTRL_SOP(op), BOOL_STR(IS_VALID_OP_SET(op)),
+	       (OP_CLASS(op)==1ULL)?"ECC":"RSA",
+	       ECC_CURVE_STR(op),
+	       ECC_FUNCTION_STR(op),
+	       PKOP_SRC_ADDR(op),
+	       PKOP_GLOBAL_SRC_OFFSET(op));
+
+	SEC_PRINT("DATA_EOP=%" LLX_FMT "\n"
+	       "PKOP_DST_ADDR=0x%016llx\n"
+	       "PKOP_GLOBAL_DST_OFFSET=%" LLX_FMT "\n",
+	       DATA_EOP(op),
+	       PKOP_DST_ADDR(op), PKOP_GLOBAL_DST_OFFSET(op));
+	return;
+}
+
+static inline void calc_num_pages(Crypto_Operation_pt cop, operation_pt op)
+{
+	CipherAlgo_t c = cop->c;
+	CipherMode_t m = cop->m;
+	HashAlgo_t h = cop->h;
+	int d = cop->input_len;
+	int useiv = (iv_sizes[cop->c][cop->m] != 0) || (cop->h == RMI_KASUMI_F9);
+	int cksum = (cop->cksum_output != NULL);
+
+	unsigned int size = sizeof(control_struct_t) +
+		cipher_sizes[c] * cipher_mode_factors[m];
+#ifdef __KERNEL__
+	int page_size = PAGE_SIZE;
+#else
+	int page_size = getpagesize();
+#endif /* KERNEL */
+
+	/* IV offset is calculated in number of 64 byte words from
+	 * the beginning of the packet.
+	 */
+	unsigned int data_size = 0;
+	if(useiv) {
+		op->iv_length = iv_sizes[c][m];
+		if(cop->h == RMI_KASUMI_F9) {
+			op->iv_length += KASUMI_F9_SIZE;
+		}
+	}
+
+/* 	if(cop->h == RMI_GCM) { */
+/* 		op->iv_length += CEIL_BYTES(cop->hmac_len, 3); */
+/* 	} */
+
+	if(!(op->op_flags & OP_NO_INPUT_DATA_COPY)) {
+		if(useiv) {
+			data_size = CACHELINE_ALIGN(d +
+						    CEIL_BYTES(op->iv_length, 3));
+		} else {
+			data_size = CACHELINE_ALIGN(d);
+		}
+	}
+
+	size += CTRL_DESC_VECTOR_SIZE +
+		DATA_DESC_VECTOR_SIZE +
+		CTRL_INSTR_SIZE +
+		MAX_CTRL_DATA_SIZE +
+		data_size; /* IV + data */
+
+	/* 
+	 * Even in case of cipher bypass, the SAE transfers clear text
+	 * data to the cipher dest address.  So, we need to keep the
+	 * space
+	 */
+	op->output_length = d;
+	if(!(op->op_flags & OP_NO_OUTPUT_DATA_COPY)) {
+		size += CACHELINE_ALIGN(d);
+	}
+
+	if(h != HASH_BYPASS) {
+		op->hash_length = hash_output_sizes[h];
+		size += CACHELINE_ALIGN(op->hash_length);
+	}
+
+	/* 
+	 * calculate size required for data descriptors
+	 * one data descriptor per fragment
+	 */
+	op->nr_ddesc = 1;
+	if((d + op->iv_length) > MAX_FRAG_TOT_SIZE) {
+		op->nr_ddesc = CEIL_BY_DIV((d + op->iv_length), MAX_PER_FRAG_SIZE);
+	}
+	op->length = d;
+
+	/* 
+	 * calculating data descriptor size.
+	 * this calc to round data descriptor to next cache line
+	 * is redundant since DATA_DESC_VECTOR_SIZE is 32 bytes = 1 cache line,
+	 * but for XLP the cache line size is different
+	*/
+	size += CACHELINE_ALIGN(op->nr_ddesc * DATA_DESC_VECTOR_SIZE);
+
+	if(cksum) {
+		/* 
+		 * two bytes for checksum value, but requires
+		 * a cache line to be set.
+		*/
+		size += CACHELINE_SIZE;
+	}
+
+	op->nr_pages = size/page_size;
+	if(size > (page_size * op->nr_pages)) {
+		op->nr_pages++;
+	}
+
+	return;
+}
+
+/**
+ * Function calculates the size of control data following control instruction.
+ * @param c Cipher algorithm
+ * @param m Cipher Mode
+ * @param h Hash algorithm
+ * @param hmac If HMAC keys are to be used or not
+ * @param extra If c is ARC4, then extra has 3 values 1 - Load state, 2 - save state
+ * @return int size of control data following control instruction (excluding 8 bytes for control
+ * instr itself)
+ */
+static inline int get_ctrl_desc_size(CipherAlgo_t c, CipherMode_t m,
+				     HashAlgo_t h, int hmac,
+				     Cipher_Box_Action_t cipher_box_action)
+{
+	int ret = CTRL_INSTR_SIZE;
+	if(c != CIPHER_BYPASS) {
+		ret += cipher_sizes[c] * cipher_mode_factors[m];
+	}
+
+	if(h != HASH_BYPASS && hmac) {
+		ret += hash_input_sizes[h];
+		/* GCM requires H=E(k,0^128) to be appended to the end of the key
+		 * that is required by the algorithm. Since GCM is supported in AES,
+		 * AES block output is 128 bits (16 bytes)
+		 */
+	}
+	if(h == RMI_GCM) {
+		ret += GCM_SIZE;
+	}
+
+	if(c == RMI_ARC4 && (cipher_box_action)) {
+		ret += arc4_padding_sizes[h];
+		ret += ARC4_SBOX_SIZE;
+	}
+
+	return ret;
+}
+
+int
+construct_ddesc_fragments(const Crypto_Operation_pt cop, operation_pt op)
+{
+	int i;
+	int hmac = (cop->hmac != NULL);
+	int do_cksum = (cop->cksum_output != NULL);
+	uint64_t *ddesc = op->data_desc;
+	unsigned char *data = op->iv;
+	unsigned char *cdest = op->output;
+	unsigned int l = op->length;
+	unsigned int ckoff = cop->cksum_words_to_skip << 2;
+	int nr_bytes_in_last_frag_dword;
+
+	if(cop->c != CIPHER_BYPASS) {
+		l += iv_sizes[cop->c][cop->m];
+	}
+
+	/* Kasumi F9 vector size */
+	if(cop->h == RMI_KASUMI_F9) {
+		l += KASUMI_F9_SIZE;
+	}
+
+	/* add AAD size, present to data length */
+	if(cop->h == RMI_GCM && op->aad != NULL) {
+		l += (op->aad_length << 3);
+	}
+
+#ifdef DEBUG_GCM
+	SEC_PRINTN("phy=0x%llx ptr=%p data=%p\n", op->meta.phy_addr, op->ptr, data);
+#endif /* DEBUG_GCM */
+	/* This is the number of bytes in the last fragment dword, which
+	 * has to be set in each fragment except the last one
+	 */
+	nr_bytes_in_last_frag_dword = l & 7;
+
+	if(data == NULL) {
+		data = op->data;
+	}
+
+#if 0
+	/* verification:
+	 * 1. if length is greater than 16k, then the # frags should
+	 *    be greater than 1
+	 */
+	if(op->length > MAX_FRAG_TOT_SIZE && op->nr_ddesc < 2) {
+		SEC_PRINT("%s:%d l=%u Max=%u nr_ddesc=%u\n", __FUNCTION__, __LINE__,
+		       op->length, MAX_FRAG_TOT_SIZE, op->nr_ddesc);
+		return -1;
+	}
+#endif
+
+	for(i = 0; i < op->nr_ddesc; ++i, ddesc += 4) {
+
+		/* srcLengthIVOffUseIVNext: *ddesc */
+		/* All fragments */
+		if(op->op_flags & OP_NO_INPUT_DATA_COPY) {
+			SET_SEGMENT_ADDR(*ddesc, (unsigned long)data);
+		} else {
+			SET_SEGMENT_ADDR(*ddesc, get_phy_addr(op, data));
+		}
+
+		if(cop->h != HASH_BYPASS) {
+			SET_PAD_HASH(*ddesc);
+		}
+
+/* 		SEC_PRINTN("data=%p op->length=%d iv=%d l=%d max_tot_size=%u\n", */
+/* 			   data, op->length, iv_sizes[cop->c][cop->m], l, */
+/* 			   MAX_FRAG_TOT_SIZE); */
+
+		if(l > MAX_FRAG_TOT_SIZE) {
+			SET_PKT_LENGTH(*ddesc, MAX_FRAG_TOT_SIZE >> 3);
+			l -= MAX_FRAG_TOT_SIZE;
+			data += MAX_FRAG_TOT_SIZE;
+		} else {
+			unsigned int pkt_len = CEIL(l,3);
+
+			if(cop->h != HASH_BYPASS) {
+				SET_HASH_BYTE_CNT(*ddesc, nr_bytes_in_last_frag_dword);
+			}
+			SET_PKT_LENGTH(*ddesc, pkt_len);
+		}
+
+		/* first fragment */
+		if(i == 0) {
+			uint32_t ivoff = cop->cipher_dwords_to_skip;
+			if(cop->h != HASH_BYPASS) {
+				uint32_t hoff = cop->hash_bytes_to_skip;
+				if(cop->h == RMI_KASUMI_F9) {
+					hoff += KASUMI_F9_SIZE;
+				}
+				SET_HASH_OFFSET(*ddesc, hoff);
+				if(hmac) {
+					SET_LOAD_HMAC_KEY(*ddesc);
+				}
+			}
+			if(cop->c == RMI_KASUMI_F8 || cop->h == RMI_KASUMI_F9 ||
+			   (cop->c != CIPHER_BYPASS && cop->m != RMI_ECB)) {
+				/* Use IV needs to be set, even if IV is not
+				 * used, since not setting it means using old
+				 * IV.
+				 */
+				SET_USEIV(*ddesc);
+			}
+
+			if(cop->iv != NULL && cop->h != RMI_GCM) {
+				SET_IVOFFSET(*ddesc, ivoff);
+			}
+		}
+
+		/* All except last fragment */
+		if(i != (op->nr_ddesc - 1)) {
+			SET_NEXT(*ddesc);
+		}
+
+
+		/* dstDataSettings: ddesc[1]*/
+		/* first fragment */
+		if(i == 0) {
+			unsigned int c_off = 0;
+			if(cop->c != CIPHER_BYPASS || cop->h == RMI_KASUMI_F9) {
+				/* if IV is present, cipher offset must start
+				 * after IV
+				 */
+				if(op->iv != NULL) {
+					c_off = (cop->cipher_dwords_to_skip +
+						 CEIL(op->iv_length,3));
+				} else {
+					c_off =  cop->cipher_dwords_to_skip;
+				}
+			}
+			if(cop->h == RMI_GCM) {
+				c_off += op->aad_length;
+				SET_CIPHER_PREFIX(ddesc[1]);
+			}
+#ifdef DEBUG_GCM
+			SEC_PRINT("Coff = %u aad_length=%u dw2s=%u op->iv=%p "
+				  "iv_len=%u\n", c_off,
+				  op->aad_length, cop->cipher_dwords_to_skip, op->iv,
+			       op->iv_length);
+#endif
+			SET_CIPHER_OFFSET(ddesc[1], c_off);
+		}
+
+		/* All fragments */
+		if(cop->encrypt) {
+			SET_ENCRYPT(ddesc[1]);
+		}
+
+		if(cop->h != HASH_BYPASS) {
+			if(cop->hash_src) {
+				SET_HASH_SRC(ddesc[1]);
+			}
+		}
+
+		if(op->op_flags & OP_NO_OUTPUT_DATA_COPY) {
+			SET_CIPHER_DST_ADDR(ddesc[1], (unsigned long)cdest);
+		} else {
+			SET_CIPHER_DST_ADDR(ddesc[1],
+					    get_phy_addr(op, cdest));
+		}
+
+		if(i != (op->nr_ddesc - 1)) {
+			cdest += MAX_FRAG_TOT_SIZE;
+		}
+
+		if(do_cksum && ckoff) {
+			if(cop->cksum_src) {
+				SET_CKSUM_SRC(ddesc[1]);
+			}
+
+			if(ckoff >= MAX_PER_FRAG_SIZE) {
+				ckoff -= MAX_PER_FRAG_SIZE;
+				SET_CKSUM_OFFSET(ddesc[1], (MAX_PER_FRAG_SIZE >> 2));
+			} else {
+				SET_CKSUM_OFFSET(ddesc[1], (ckoff >> 2));
+			}
+		}
+
+		/* Last fragment */
+
+		/* authDstNonceLow: ddesc[2]*/
+		/* All fragments */
+		if(cop->h != HASH_BYPASS) {
+			SET_AUTH_DST_ADDR(ddesc[2],
+			  get_phy_addr(op, op->hash_output));
+			if(cop->h == RMI_GCM) {
+				SET_HASH_SRC(ddesc[1]);
+			}
+		}
+
+		/* first fragment */
+		if(i == 0) {
+			if(cop->c != CIPHER_BYPASS && cop->m == RMI_CTR) {
+				SET_NONCE(ddesc[2], cop->nonce);
+			}
+		}
+
+
+		/* ckSumDstNonceHiCFBMaskLLWMask: ddesc[3] */
+		/* All fragments */
+		if(cop->c != CIPHER_BYPASS) {
+			if(cop->m == RMI_CCM) {
+				SET_CCM(ddesc[3]);
+			}
+
+			if(cop->m == RMI_CFB) {
+				SET_CFB_MASK(ddesc[3], cop->cipher_mask);
+			}
+
+			SET_LLW_MASK(ddesc[3], cop->llw_mask);
+
+		}
+
+		if(do_cksum) {
+			SET_CKSUM_DST_ADDR(ddesc[3],
+					   get_phy_addr(op, op->cksum));
+		}
+
+#if 0
+		/* Last fragment set the number of bytes in the last dword */
+		if(i == (op->nr_ddesc - 1)) {
+			if(cop->c != CIPHER_BYPASS) {
+				SET_FRAG_PKT_LENGTH(ddesc[3],
+						    nr_bytes_in_last_frag_dword);
+			}
+		}
+#endif
+	}
+
+	return 0;
+}
+
+#ifndef __KERNEL__
+
+int
+rmisec_lib_init()
+{
+	init_cached_proc_id();
+	return 0;
+}
+
+void
+rmisec_lib_cleanup(void)
+{
+#ifdef USER_SPACE_STATS
+	unsigned char buf[2049];
+#endif /*  USER_SPACE_STATS */
+#ifdef MEM_CACHE
+	mem_entry_pt mem;
+	int i, order;
+	pid_t pid = getpid();
+	control_struct_pt ctrl;
+
+	pthread_mutex_lock(&f_lock);
+	mem = free_list;
+	while(mem) {
+		free_list = free_list->next;
+		free(mem);
+#ifdef MEM_STATS
+		pthread_mutex_lock(&mstat_lock);
+		free_cnt++;
+		pthread_mutex_unlock(&mstat_lock);
+#endif /* MEM_STATS */
+		mem = free_list;
+	}
+
+	for(i = 0; i < MAX_ORDER; ++i) {
+		pthread_mutex_unlock(&c_lock[i]);
+		mem = mem_cache[i];
+		while(mem) {
+			mem_cache[i] = mem_cache[i]->next;
+			if(mem->ptr != NULL && mem->ptr != MAP_FAILED && mem->order > -1) {
+				order = mem->order;
+				ctrl = (control_struct_pt)mem->ptr;
+				if(ctrl->owner == pid) {
+					munmap(mem->ptr, (1 << order) * getpagesize());
+				}
+				mem->ptr = NULL;
+				mem->order = -1;
+			}
+			free(mem);
+#ifdef MEM_STATS
+			pthread_mutex_lock(&mstat_lock);
+			free_cnt++;
+			pthread_mutex_unlock(&mstat_lock);
+#endif /* MEM_STATS */
+			mem = mem_cache[i];
+		}
+		pthread_mutex_unlock(&c_lock[i]);
+	}
+#endif /* MEM_CACHE */
+#ifdef MEM_STATS
+	SEC_PRINT("malloc_cnt = %llx free_cnt=%llx\n", malloc_cnt,
+		  free_cnt);
+#endif /* MEM_STATS */
+
+#ifdef USER_SPACE_STATS
+	print_stats(buf, sizeof(buf) - 1);
+	SEC_PRINT("%s", buf);
+#endif /* USER_SPACE_STATS */
+	return;
+}
+#endif
+
+#ifdef __KERNEL__
+int
+rmisec_op_init(op_handle_pt p_handle)
+{
+	operation_pt op;
+	if(in_atomic() || in_interrupt()) {
+		op = (operation_pt)kmalloc(sizeof(operation_t), GFP_ATOMIC);
+	} else {
+		op = (operation_pt)kmalloc(sizeof(operation_t), GFP_KERNEL);
+	}
+	if(op == NULL) {
+		return -ENOMEM;
+	}
+
+	memset(op, 0, sizeof(operation_t));
+	*p_handle = (op_handle_t)op;
+	return 0;
+}
+#else
+int
+rmisec_op_init(int fd, op_handle_pt p_handle)
+{
+	operation_pt op;
+
+	*p_handle = 0;
+
+	op = (operation_pt)malloc(sizeof(operation_t));
+	if(op == NULL) {
+		return -1;
+	}
+#ifdef MEM_STATS
+	pthread_mutex_lock(&mstat_lock);
+	malloc_cnt++;
+	pthread_mutex_unlock(&mstat_lock);
+#endif /* MEM_STATS */
+	memset(op, 0, sizeof(operation_t));
+
+	op->fd = fd;
+
+	*p_handle = (op_handle_t)op;
+	return 0;
+}
+#endif
+
+
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_op_init);
+#endif /* KERNEL */
+
+void
+rmisec_op_cleanup(op_handle_pt handle)
+{
+	operation_pt op;
+#ifdef __KERNEL__
+	meminfo_pt mem;
+#endif /* KERNEL */
+	if(handle == NULL || *handle == 0) {
+		return;
+	}
+
+	op = (operation_pt)(*handle);
+	*handle = 0;
+#ifdef __KERNEL__
+	if(op != NULL) {
+		mem = (meminfo_pt)((unsigned long)op->meta.mem_addr);
+		free_meminfo(mem);
+		kfree(op);
+	}
+#else
+	free_mem_to_pool(op->nr_pages, op->ptr);
+	free(op);
+#ifdef MEM_STATS
+	pthread_mutex_lock(&mstat_lock);
+	free_cnt++;
+	pthread_mutex_unlock(&mstat_lock);
+#endif /* MEM_STATS */
+#endif /* KERNEL */
+	return;
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_op_cleanup);
+#endif /* KERNEL */
+
+static inline
+int
+send_to_driver(operation_pt op)
+{
+	int ret = RMISAE_SUCCESS;
+	control_struct_pt ctrl;
+#ifdef __KERNEL__
+	meminfo_pt mem;
+#else
+	int fd = op->fd;
+#endif
+
+	ctrl = (control_struct_pt)op->ptr;
+	if(ctrl->magic != DRIVER_MAGIC) {
+		SEC_PRINT("%s:%d Invalid driver magic magic=%" LLX_FMT " ptr=%p\n",
+		       __FUNCTION__, __LINE__, ctrl->magic, op->ptr);
+		ret = -1;
+	} else {
+#ifdef __KERNEL__
+		mem = (meminfo_pt)((unsigned long)op->meta.mem_addr);
+		mem->msg0 = ctrl->msg0;
+		mem->msg1 = ctrl->msg1;
+		mem->op_type = ctrl->op_type;
+		mem->op_flags = op->op_flags;
+		mem->result = RMISAE_SUCCESS;
+		mem->return_queue = op->return_queue;
+		mem->return_value = (unsigned long)op;
+		if((ret = send_to_sae(mem, 1)) < 0) {
+			if(ret != -EAGAIN) {
+				SEC_PRINT("%s:%d Invalid value returned from driver=%d "
+					  "mem=0x%" LLX_FMT "\n",
+					  __FUNCTION__, __LINE__, ret, op->meta.mem_addr);
+			}
+			return ret;
+		}
+
+		if(!IS_ASYNC_OP(mem)) {
+			ctrl->msg0 = mem->resp0;
+			ctrl->msg1 = mem->resp1;
+			ret = mem->result;
+			if(IS_SUCCESS_SAEOP(ret)) {
+				add_stats_count(ctrl, hard_smp_processor_id());
+			}
+		}
+#else
+		ret = read(fd, (char *)op->ptr, sizeof(control_struct_t));
+		if(!IS_SUCCESS_SAEOP(ret)) {
+			SEC_PRINT("%s:%d Invalid value returned from driver=%d "
+				  "mem=0x%" LLX_FMT " error=(%x)\n",
+				  __FUNCTION__, __LINE__, ret, op->meta.mem_addr, errno);
+			return ret;
+		}
+#endif
+	}
+
+/*
+	if(ctrl->magic != DRIVER_MAGIC) {
+		SEC_PRINT("%s:%d Invalid driver magic magic=%" LLX_FMT " ptr=%p\n",
+		       __FUNCTION__, __LINE__, ctrl->magic, op->ptr);
+		ret = -1;
+	}
+*/
+
+	return ret;
+}
+
+int
+map_memory(operation_pt op)
+{
+
+	control_struct_pt ctrl;
+
+	/* op->nr_pages is set in calc_num_pages */
+	ctrl = (control_struct_pt)(op->ptr = get_mem_from_pool(op));
+
+	if(op->ptr == MAP_FAILED || op->ptr == NULL ||
+	   ctrl->magic != DRIVER_MAGIC) {
+#ifdef __KERNEL__
+		SEC_PRINT("%s:%d Error mmap failed for size=%lu or "
+			  "magic match failed=%"LLX_FMT "\n", __FUNCTION__, __LINE__,
+			  op->nr_pages * getpagesize(), ctrl->magic);
+#else
+		SEC_PRINT("%s:%d Error mmap failed for size=%u or "
+			  "ptr=%p magic=%" LLX_FMT " fd=%d err=%d\n",
+			  __FUNCTION__, __LINE__, op->nr_pages * getpagesize(),
+			  ctrl, (ctrl != NULL && ctrl != MAP_FAILED)?ctrl->magic:0,
+			  op->fd, errno);
+#endif
+		if(op->ptr != MAP_FAILED && op->ptr != NULL) {
+			free_mem_to_pool(op->nr_pages, op->ptr);
+		}
+		op->ptr = NULL;
+		return -1;
+	}
+
+	memcpy(&op->meta, op->ptr, sizeof(control_struct_t));
+
+	return 0;
+}
+
+static inline int
+init_ctrl_pointers(operation_pt op)
+{
+	op->ctrl_msg = &(((control_struct_pt)op->ptr)->msg0);
+
+	op->data_msg = &(((control_struct_pt)op->ptr)->msg1);
+	op->op_type =  &(((control_struct_pt)op->ptr)->op_type);
+
+	return 0;
+}
+
+/*
+ * UGLY way to work around emacs indentation logic.  Otherwise the
+ * ifdef KERNEL block below confuses the indentation.
+ */
+#define OPENIF if(
+
+/**
+ * This function initializes the operation data structure.  This involves
+ * following steps:
+ * 1. Calculate size of message, control instruction and data descriptors
+ * sizes
+ * 2. Allocate the required pages from the driver
+ * 3, Copy over the meta information provided by the driver
+ * 4. Initialize pointers in the operation structure appropriately
+ * 5. Based on algorithms specified, setup bit fields in the message
+ * and data descriptors and set addresses to data
+ */
+static
+int init_crypto_operation(const Crypto_Operation_pt cop, operation_pt op)
+{
+	int usehmac = (cop->h != HASH_BYPASS && cop->h != RMI_GCM && cop->hmac != NULL);
+	int useiv = (iv_sizes[cop->c][cop->m] || cop->h == RMI_KASUMI_F9);
+	int ctrl_size, t = 0;
+	int nr_ctrl_clines;
+	unsigned char *next;
+
+	/* chip dependent checks */
+#ifdef __KERNEL__
+	OPENIF!(is_xls() || xlr_revision_c()) &&
+#else
+        if((is_xlr() && !is_xlr_step_c()) &&
+#endif
+	    ((cop->c > RMI_KASUMI_F8) || (cop->m > RMI_CTR) ||
+	     (cop->h > RMI_SHA256))) {
+		SEC_PRINT("Operation supported on XLS or XLR Stepping C Rev 0 onwards\n");
+		return -EINVAL;
+	}
+
+	/* check pointers and length fields */
+	if((t = ((cop->input == NULL && cop->input_vec == NULL) ||
+	   (cop->input == NULL && cop->input_vec_len == 0) ||
+	   (cop->input_vec == NULL && cop->input_len == 0))?1:0) ||
+	   /* check if cipher operation is specified and output parameter
+	    * is NULL
+	    */
+	   (t = (cop->c != CIPHER_BYPASS && ((cop->output == NULL &&
+					cop->output_vec == NULL) ||
+					(cop->output == NULL &&
+					 cop->output_vec_len == 0)))?2:0) ||
+
+	   /*
+	    * If cipher is not AES and mode should only be ECB or CBC
+	    */
+	   (t = ((cop->c < RMI_AES128 && cop->c > RMI_AES192) &&
+	    (cop->m != RMI_ECB && cop->m != RMI_CBC))?3:0) ||
+
+	   /* CBC, CFB and OFB, CTR, always requires an IV */
+	   (t = ((cop->m == RMI_CBC || cop->m == RMI_OFB || cop->m == RMI_CFB ||
+		  cop->m == RMI_CTR) && cop->iv == NULL)?4:0) ||
+
+	   /* GCM requires algo to be AES and mode to be CTR */
+	   (t = (cop->h == RMI_GCM && (cop->c < RMI_AES128 || cop->c > RMI_AES256 ||
+				  cop->m != RMI_CTR))?5:0) ||
+
+	   /* GCM supports IV size of 96 bytes of which
+	    * lowest 8 bytes are copied to IV and the higher 4 bytes are set
+	    * as nonce
+	    */
+	   (t = (cop->h == RMI_GCM && (cop->iv_len != 12))?6:0) ||
+
+	   /**
+	    * If operation is ARC4, key length should be -le 32
+	    */
+	   (t = (cop->c == RMI_ARC4 && cop->key_len > 32)?7:0) ||
+
+	   /* Check hash operation is within the range */
+	   (t = (cop->h < HASH_BYPASS || cop->h > MAX_HASH_ALGO)?8:0) ||
+
+	   /* If hash operation is specified, digest pointer should
+	    * not be NULL */
+	   (t = (cop->h != HASH_BYPASS && cop->digest == NULL)?9:0) ||
+
+	   /* Hash offset must be less than 64 bytes and must be
+	    * less than input data */
+	   (t = (cop->h < HASH_BYPASS || (cop->hash_bytes_to_skip > 63) ||
+	    (cop->hash_bytes_to_skip > cop->input_len))?10:0) ||
+
+	   /* Bytes to skip for checksum should not be greater than
+	    * than input bytes
+	    */
+	   (t = (cop->cksum_output != NULL &&
+	    ((cop->cksum_words_to_skip << 2) >= (cop->input_len)))?11:0)) {
+		SEC_PRINT("%s:%d One of the input parameters failed validation t=%d\n",
+			  __FUNCTION__, __LINE__, t);
+		print_crypto_coperation(cop);
+		if(t == 1) {
+			SEC_PRINT("%s:%d input=%p input_len=%u input_vector=%p "
+				  "input_vector_len=%u\n", __FUNCTION__, __LINE__,
+				  cop->input, cop->input_len, cop->input_vec,
+				  cop->input_vec_len);
+		}
+		return -EINVAL;
+	}
+
+	ctrl_size  =  get_ctrl_desc_size(cop->c, cop->m, cop->h,
+					 usehmac, cop->cipher_box_action);
+	nr_ctrl_clines = NUM_CACHELINES(ctrl_size);
+
+	calc_num_pages(cop, op);
+
+	if(map_memory(op)) {
+		return -1;
+	}
+
+	/* the two message fields are sent to security engine
+	 * over the FMN
+	 */
+
+	init_ctrl_pointers(op);
+
+	op->ctrl_instr = (uint64_t *)CACHELINE_ALIGN(PTR_OFFSET(op->ptr,
+								sizeof(control_struct_t)));
+
+	if(usehmac || (cop->c != CIPHER_BYPASS)) {
+		op->ctrl_data = op->ctrl_instr + 1;
+	}
+
+	/* max ctrl size is 472 */
+	op->data_desc =
+		(uint64_t *)CACHELINE_ALIGN(PTR_OFFSET(op->ctrl_instr,
+						       ctrl_size));
+
+	next = (unsigned char *)CACHELINE_ALIGN(PTR_OFFSET(op->data_desc,
+							   (op->nr_ddesc *
+							    DATA_DESC_SIZE)));
+
+	if(op->op_flags & OP_NO_INPUT_DATA_COPY) {
+		op->iv = (unsigned char *)cop->input;
+	} else {
+		op->iv = next;
+	}
+
+	if(useiv) {
+		/* 
+		 * IV offset is calculated in number of 64 byte words from
+		 * the beginning of the packet.
+		*/
+		op->data = (unsigned char *)PTR_OFFSET(op->iv, CEIL_BYTES(op->iv_length,
+									  3));
+	} else {
+		op->data = op->iv;
+		op->iv = NULL;
+	}
+
+        if(cop->h == RMI_GCM) {
+		op->aad = (unsigned char *)PTR_OFFSET(op->data,
+						      (CEIL_BYTES(cop->hmac_len, 3) -
+						       cop->hmac_len));
+		op->aad_length = CEIL(cop->hmac_len, 3);
+		op->data = (unsigned char *)PTR_OFFSET(op->aad, cop->hmac_len);
+#ifdef DEBUG_GCM
+		SEC_PRINT("aad=%p data=%p aad_len=%d hmac_len=%d\n", op->aad, op->data,
+			  op->aad_length, cop->hmac_len);
+#endif /* DEBUG_GCM */
+	}
+
+	/* zero out message and descriptors */
+	memset(op->ctrl_msg, 0, PTR_DIFF(next, op->ctrl_msg));
+
+	if(!(op->op_flags & OP_NO_INPUT_DATA_COPY)) {
+		next = (unsigned char *)CACHELINE_ALIGN(PTR_OFFSET(op->data,
+								   cop->input_len));
+	}
+
+	if(op->op_flags & OP_NO_OUTPUT_DATA_COPY) {
+		op->output = cop->output;
+	} else {
+		op->output = next;
+		next = (unsigned char *)CACHELINE_ALIGN(PTR_OFFSET(op->output,
+								   cop->input_len));
+	}
+
+	if(cop->h == RMI_GCM) {
+		op->output = (unsigned char *)PTR_OFFSET(op->output, (op->aad_length<<3));
+	}
+
+	if(cop->h != HASH_BYPASS) {
+		if(cop->c != CIPHER_BYPASS) {
+
+			cop->hash_bytes_to_skip += op->iv_length;
+
+			if(cop->h == RMI_GCM && cop->hmac_len) {
+				cop->hash_bytes_to_skip += (CEIL_BYTES(cop->hmac_len, 3) -
+							    cop->hmac_len);
+			}
+		}
+
+		op->hash_output = next;
+
+		if(cop->cksum_output) {
+			next = (unsigned char *)CACHELINE_ALIGN(
+				PTR_OFFSET(op->hash_output, hash_output_sizes[cop->h]));
+		}
+	}
+
+	if(cop->cksum_output) {
+		op->cksum = next;
+	}
+
+	/* SET Operation Type */
+	op->op_type[0] = RMI_CRYPTO_OP;
+
+	/* Set ctrl msg values */
+	SET_CTRL_SOP(*op->ctrl_msg);
+	SET_CTRL_LENGTH(*op->ctrl_msg, nr_ctrl_clines);
+	SET_CTRL_ADDR(*op->ctrl_msg,
+		      get_phy_addr(op, op->ctrl_instr));
+
+	/* Set data msg values */
+	*op->data_msg = DATA_DESC_VECTOR_TEMPLATE;
+	SET_DATA_ADDR(*op->data_msg,
+		      get_phy_addr(op, op->data_desc));
+	SET_WRB_L2_ALLOC(*op->data_msg);
+	SET_DF_PTR_L2_ALLOC(*op->data_msg);
+
+	/* Set ctrl instr values*/
+	if(cop->c != CIPHER_BYPASS) {
+		set_cipher(cop->c, cop->m, op);
+		SET_INCP_KEY(*op->ctrl_instr);
+		if(cop->c == RMI_ARC4) {
+			SET_CIPHER_BOX_ACTION(*op->ctrl_instr, cop->cipher_box_action);
+			SET_ARC4_KEYLEN(*op->ctrl_instr, cop->key_len);
+		}
+	}
+
+	if(cop->h != HASH_BYPASS) {
+		SET_INHS_KEY(*op->ctrl_instr);
+		SET_HASH_ALGO(*op->ctrl_instr, cop->h);
+		if(usehmac) {
+			SET_HMAC(*op->ctrl_instr);
+		}
+	}
+
+	if(cop->cksum_output) {
+		SET_CKSUM(*op->ctrl_instr);
+	}
+
+	if(construct_ddesc_fragments(cop, op) < 0) {
+		return -1;
+	}
+
+	return 0;
+}
+
+void
+print_response(control_struct_pt ctrl)
+{
+	SEC_PRINT("%s:%d CTRL_RESP=0x%016" LLX_FMT " DATA_RESP=0x%016" LLX_FMT "\n",
+	       __FUNCTION__, __LINE__,
+	       ctrl->msg0, ctrl->msg1);
+
+	SEC_PRINT("CTRL_HEAD=%" LLX_FMT " CTRL_DEST_ID=%" LLX_FMT
+		  " CTRL_DEST_CTRL=%" LLX_FMT
+		  " CTRL_ERROR=0x%" LLX_FMT " MSG0_ADDR=0x%016llx\n",
+		  CTRL_HEAD(ctrl->msg0), CTRL_DEST_ID(ctrl->msg0),
+		  CTRL_DEST_CTRL(ctrl->msg0),
+		  CTRL_ERROR(ctrl->msg0), CTRL_RESP_ADDR(ctrl->msg0));
+
+	SEC_PRINT("DATA_HEAD=%" LLX_FMT " DATA_DEST_ID=%" LLX_FMT " DATA_DEST_CTRL=%" LLX_FMT
+	       " DATA_ERROR=0x%" LLX_FMT " DATA_RESP_ADDR=0x%016llx\n",
+	       DATA_HEAD(ctrl->msg1),
+	       DATA_DEST_ID(ctrl->msg1),
+	       DATA_DEST_CTRL(ctrl->msg1),
+	       DATA_ERROR(ctrl->msg1), DATA_RESP_ADDR(ctrl->msg1));
+	return;
+}
+
+int
+post_process_op(int result, operation_pt op)
+{
+	Crypto_Operation_pt cop = &op->cop_instance;
+	int ret = result;
+	uint64_t *c_data = op->ctrl_data;
+#ifdef __KERNEL__
+	meminfo_pt mem;
+#endif /* KERNEL */
+
+	control_struct_pt ctrl = (control_struct_pt)op->ptr;
+
+	if(op->meta.magic != DRIVER_MAGIC) {
+		SEC_PRINT("%s:%d Invalid driver magic: %"LLX_FMT"\n", __FUNCTION__,
+			  __LINE__, op->meta.magic);
+		return -1;
+	}
+
+#ifdef __KERNEL__
+	mem = (meminfo_pt)((unsigned long)ctrl->mem_addr);
+	ctrl->msg0 = mem->resp0;
+	ctrl->msg1 = mem->resp1;
+#else
+	/* call the system call and get the status for async operations */
+#endif /* __KERNEL__ */
+
+	if(!IS_SUCCESS_SAEOP(ret) || CTRL_ERROR(ctrl->msg0) != 0 ||
+	   DATA_ERROR(ctrl->msg1) != 0) {
+		SEC_PRINT("<<<RESULT=%x>>>\n", result);
+		print_4k((unsigned char *)op->ptr, 0);
+		print_crypto_operation(op);
+		print_response(ctrl);
+	} else {
+#ifdef __KERNEL__
+		add_stats_count(ctrl, hard_smp_processor_id());
+#endif /* KERNEL */
+
+		/* copy sbox if ARC4 and Save State */
+		if(cop->c == RMI_ARC4 && (cop->cipher_box_action &
+					  CIPHER_SAVE_STATE)) {
+			memcpy(cop->cipher_box, c_data, ARC4_SBOX_SIZE);
+		}
+
+		/* copy result */
+		if(cop->c != CIPHER_BYPASS &&
+		   !(op->op_flags & OP_NO_OUTPUT_DATA_COPY)) {
+			memcpy(cop->output,
+			       op->output + iv_sizes[cop->c][cop->m],
+			       cop->input_len);
+		}
+
+		/* copy hash if enabled */
+		if(cop->h != HASH_BYPASS) {
+			memcpy(cop->digest, op->hash_output,
+			       hash_output_sizes[cop->h]);
+		}
+
+		/* copy checksum, if enabled */
+		if(cop->cksum_output) {
+			memcpy(cop->cksum_output, op->cksum, sizeof(int));
+		}
+	}
+	return ret;
+}
+
+int pk_post_process_op(int result, int m_len, unsigned char *y, int *y_len,
+		       operation_pt op)
+{
+	int ret = result;
+	control_struct_pt ctrl = (control_struct_pt)op->ptr;
+
+	if(ret < 0 || CTRL_ERROR(ctrl->msg0) != 0 ||
+	   DATA_ERROR(ctrl->msg1) != 0) {
+		print_response(ctrl);
+		*y_len = 0;
+		ret = -1;
+	} else if(IS_SUCCESS_SAEOP(result)) {
+		op->output_length = m_len;
+		dword_data_copy((uint64_t *)y, (uint64_t *)op->output,
+				CEIL(m_len, 3), -1);
+		*y_len = op->output_length;
+	}
+
+	return ret;
+
+}
+
+int rmisec_hash_hmac(op_handle_t handle, HashAlgo_t hash,
+		     const unsigned char *hmac,
+		     const unsigned char *in,
+		     unsigned int size, unsigned char *out);
+
+static inline int
+rmisec_hash(op_handle_t handle, HashAlgo_t hash, const unsigned char *in,
+		unsigned int size, unsigned char *out)
+{
+	return rmisec_hash_hmac(handle, hash, NULL, in, size, out);
+}
+
+int rmisec_md5(op_handle_t handle, const unsigned char *in, unsigned int size,
+	       unsigned char *out)
+{
+	return rmisec_hash(handle, RMI_MD5, in, size, out);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_md5);
+#endif /* KERNEL */
+
+int rmisec_sha1(op_handle_t handle, const unsigned char *in, unsigned int size,
+		unsigned char *out)
+{
+	return rmisec_hash(handle, RMI_SHA1, in, size, out);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_sha1);
+#endif /* KERNEL */
+
+int
+rmisec_sha256(op_handle_t handle, const unsigned char *in, unsigned int size,
+	      unsigned char *out)
+{
+	return rmisec_hash(handle, RMI_SHA256, in, size, out);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_sha256);
+#endif /* KERNEL */
+
+int
+rmisec_sha384(op_handle_t handle, const unsigned char *in, unsigned int size,
+	      unsigned char *out)
+{
+	return rmisec_hash(handle, RMI_SHA384, in, size, out);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_sha384);
+#endif /* KERNEL */
+
+int
+rmisec_sha512(op_handle_t handle, const unsigned char *in, unsigned int size,
+	      unsigned char *out)
+{
+	return rmisec_hash(handle, RMI_SHA512, in, size, out);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_sha512);
+#endif /* KERNEL */
+
+static inline void
+left_shift(unsigned char *dst, const unsigned char *src, unsigned int len)
+{
+	int i = (len >> 3) - 1;
+	uint64_t *stmp = (uint64_t *)src, *dtmp = (uint64_t *)dst;
+	int c = 0;
+
+	for(; i >= 0; --i) {
+		dtmp[i] = stmp[i] << 1;
+		if(c) {
+			dtmp[i] |= 0x1ULL;
+		}
+		c = ((stmp[i] & 0x8000000000000000ULL) != 0);
+	}
+	return;
+}
+
+static inline void
+cmac_xor(unsigned char *dst, const unsigned char *src, unsigned int len)
+{
+	int i, c=len >> 3;
+	uint64_t *stmp = (uint64_t *)src, *dtmp = (uint64_t *)dst;
+
+	for(i = 0; i < c; ++i) {
+		dtmp[i] ^= stmp[i];
+	}
+	return;
+}
+
+int
+rmisec_cmac_keygen(op_handle_t handle, HashAlgo_t h, const unsigned char *key,
+		   unsigned char *outkey)
+{
+	unsigned int bsize, ret;
+	unsigned char c0[16] = {0};
+	unsigned char *c1;
+	unsigned char iv[16] = {0};
+
+	unsigned char k0[16], k1[16], k2[16];
+
+	const unsigned char rb_32[8] = {0, 0, 0, 0, 0, 0, 0, 0x1b};
+	const unsigned char rb_64[16] = {0, 0, 0, 0, 0, 0, 0, 0,
+					 0, 0, 0, 0, 0, 0, 0, 0x87ULL};
+	const unsigned char *rb;
+	op_handle_t cmac_handle = RMISAE_HANDLE_INITIALIZER;
+	operation_pt op = (operation_pt)handle;
+
+	if(!(op == NULL || h == RMI_AES_CMAC || h == RMI_DES3_CMAC) ||
+	   key == NULL || outkey == NULL) {
+		return -EINVAL;
+	}
+
+#ifndef __KERNEL__
+	ret = rmisec_op_init(op->fd, &cmac_handle);
+#else
+	ret = rmisec_op_init(&cmac_handle);
+#endif
+
+	if(ret) {
+		return -EFAULT;
+	}
+
+	c1 = (unsigned char *)&k0;
+	if(h == RMI_DES3_CMAC) {
+		bsize = 8;
+		rb = (unsigned char *)&rb_32;
+		ret = rmisec_3des_cipher (cmac_handle, key, iv, CIPHER_ENCRYPT,
+					  c0, bsize, c1);
+	} else {
+		bsize = 16;
+		rb = (unsigned char *)&rb_64;
+		ret = rmisec_aes128_cipher(cmac_handle, key, iv, CIPHER_ENCRYPT,
+					   c0, bsize, c1);
+	}
+
+	rmisec_op_cleanup(&cmac_handle);
+
+	if(!IS_SUCCESS_SAEOP(ret)) {
+		SEC_PRINT("Error creating key: ret=%d\n", ret);
+		return ret;
+	}
+
+#if 0
+	SEC_PRINT("K0=[");
+	print_hext_string(c1, bsize);
+	SEC_PRINT("]\n");
+#endif
+
+	left_shift(k1, k0, bsize);
+	if(k0[0] & 0x80) {
+		cmac_xor(k1, rb, bsize);
+	}
+
+	left_shift(k2, k1, bsize);
+
+	if(k1[0] & 0x80) {
+		cmac_xor(k2, rb, bsize);
+	}
+
+
+	memcpy(outkey, key, bsize);
+	memcpy(&outkey[bsize], &k1, bsize);
+	memcpy(&outkey[bsize * 2], &k2, bsize);
+
+#if 0
+	SEC_PRINT("K1=[");
+	print_hext_string(&outkey[bsize], bsize);
+	SEC_PRINT("]\n");
+
+	SEC_PRINT("K2=[");
+	print_hext_string(&outkey[bsize*2], bsize);
+	SEC_PRINT("]\n");
+#endif
+	return 0;
+}
+
+int
+rmisec_cmac(op_handle_t handle, HashAlgo_t h, const unsigned char *key,
+	    const unsigned char *in, unsigned int size, unsigned char *out)
+{
+	int ret;
+	unsigned char *k1, *k2;
+	unsigned int bcount, rem, i, idx, off, bsize;
+	Crypto_Operation_t cop_instance;
+	operation_pt op;
+	control_struct_pt ctrl;
+	unsigned char keys[48];
+	unsigned char iv[16] = {0};
+
+	if(!(h == RMI_AES_CMAC || h == RMI_DES3_CMAC) || key == NULL ||
+	   in == NULL || out == NULL) {
+		return -EINVAL;
+	}
+
+	op = (operation_pt)handle;
+
+	ret = rmisec_cmac_keygen(handle, h, key, keys);
+	if(ret < 0) {
+		SEC_PRINT("Error generating subkeys\n");
+		return ret;
+	}
+
+	memset(&cop_instance, 0, sizeof(Crypto_Operation_t));
+
+	if(h == RMI_DES3_CMAC) {
+		cop_instance.c = RMI_DES3;
+		off = 7;
+		bcount = CEIL_BYTES(size, 3);
+	} else {
+		cop_instance.c = RMI_AES128;
+		off = 15;
+		bcount = CEIL_BYTES(size, 4);
+	}
+
+	cop_instance.m = RMI_CBC;
+	cop_instance.key = keys;
+	cop_instance.iv = iv;
+	cop_instance.encrypt = 1;
+	cop_instance.input = in;
+	cop_instance.input_len = bcount;
+	cop_instance.output = out;
+
+	bsize = off+1;
+	rem = size & off;
+	idx = size & ~(off);
+	if(!rem) {
+		idx -= bsize;
+	}
+
+	k1 = &keys[bsize];
+	k2 = &k1[bsize];
+
+#ifndef __KERNEL__
+	/* disabling the copy optimizations in user space since it will not
+	 * work.
+	 */
+	op->op_flags &= ~(OP_NO_INPUT_DATA_COPY|OP_NO_OUTPUT_DATA_COPY);
+#endif /* __KERNEL__*/
+
+	if(init_crypto_operation(&cop_instance, op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	/* copy data */
+	memcpy(op->data, in, size);
+
+	if(rem) {
+		/* pad data */
+		op->data[size] = 0x80;
+		for(i = size + 1; i < bcount; ++i) {
+			op->data[i] = 0;
+		}
+
+		/* xor key2 */
+		cmac_xor(&op->data[idx], k2, bsize);
+	} else {
+		/* xor key1 */
+		cmac_xor(&op->data[idx], k1, bsize);
+	}
+
+	/* copy key */
+	memcpy(op->ctrl_data, key, key_sizes[cop_instance.c][cop_instance.m]);
+
+	ret = send_to_driver(op);
+
+	if(ret < 0 || CTRL_ERROR(ctrl->msg0) != 0 ||
+	   DATA_ERROR(ctrl->msg1) != 0) {
+		print_4k((unsigned char *)op->ptr, 0);
+		print_crypto_operation(op);
+		print_response(ctrl);
+		ret = -1;
+	} else {
+		memcpy(out, &op->output[key_sizes[cop_instance.c][cop_instance.m] +
+						idx],
+		       key_sizes[cop_instance.c][cop_instance.m]);
+	}
+
+	return ret;
+}
+
+/* Cipher operations */
+int
+rmisec_cipher_digest_hmac_cksum(op_handle_t handle, Crypto_Operation_pt cop)
+{
+	operation_pt op;
+	int ret = RMISAE_SUCCESS;
+	int usehmac = (cop->h != HASH_BYPASS) &&  (cop->h != RMI_GCM) &&
+		(cop->hmac != NULL);
+	uint64_t *c_data;
+
+	control_struct_pt ctrl;
+
+	if(!handle) {
+		SEC_PRINT("%s:%d Invalid handle passed to operation\n",
+			  __FUNCTION__, __LINE__);
+		return -1;
+	}
+
+	op = (operation_pt)handle;
+
+	if(init_crypto_operation(cop, op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	c_data = op->ctrl_data;
+
+	/* copy key */
+	if(cop->c != CIPHER_BYPASS) {
+		uint32_t keyoff = key_sizes[cop->c][cop->m];
+
+		if(cop->c != RMI_ARC4) {
+			if(cop->c == RMI_DES3 && cop->encrypt == CIPHER_DECRYPT) {
+				dword_data_copy((uint64_t *)c_data,
+						(uint64_t *)cop->key,
+						key_sizes[cop->c][cop->m], 0);
+			} else if(cop->h == RMI_GCM) {
+				keyoff += GCM_SIZE;
+				memcpy(c_data, cop->key, keyoff);
+			}  else {
+				memcpy(c_data, cop->key,
+				       key_sizes[cop->c][cop->m]);
+			}
+		} else {
+			memcpy(c_data, cop->key, cop->key_len);
+		}
+		c_data = (uint64_t *)PTR_OFFSET(c_data, keyoff);
+	}
+
+	/* copy hmac if present */
+	if(usehmac) {
+		memcpy(c_data, cop->hmac, hash_input_sizes[cop->h]);
+		c_data = (uint64_t *)PTR_OFFSET(c_data,
+						(hash_input_sizes[cop->h] + 3));
+	}
+
+	/* copy sbox if ARC4 and stateful */
+	if(cop->c == RMI_ARC4 && cop->cipher_box != NULL &&
+	   (cop->cipher_box_action & CIPHER_LOAD_STATE)) {
+		memcpy(c_data, cop->cipher_box, ARC4_SBOX_SIZE);
+	}
+
+	if(!(op->op_flags & OP_NO_INPUT_DATA_COPY)) {
+		int copy_len = cop->input_len;
+
+		/* copy iv */
+		if(cop->h != RMI_GCM) {
+			if((cop->h == RMI_KASUMI_F9 || cop->c != CIPHER_BYPASS) &&
+			   cop->iv != NULL) {
+				memcpy(op->iv, cop->iv, op->iv_length);
+			}
+		} else {
+			/* 
+			 * for GCM, the IV is 12 bytes, of which 8 is specified
+			 * in IV and the rest is specified in nonce
+			*/
+			memcpy(op->iv, cop->iv + 4, op->iv_length);
+			memcpy(op->aad, cop->hmac, cop->hmac_len);
+		}
+
+		/* copy input data */
+		if(cop->input_len > (CEIL_BYTES(cop->input_len, 3))) {
+			memset(&op->data[cop->input_len], 0,
+			       ((CEIL_BYTES(cop->input_len, 3)) - cop->input_len));
+		}
+
+		if(cop->h == RMI_KASUMI_F9) {
+			copy_len += CEIL_BYTES(cop->input_len, 3);
+		}
+
+		memcpy(op->data, cop->input, copy_len);
+	}
+
+#ifdef SAE_STATS
+	ctrl->cipher_algo = cop->c;
+	ctrl->cipher_mode = cop->m;
+	ctrl->hash_algo = cop->h;
+	ctrl->data_size = cop->input_len;
+#endif /* SAE_STATS */
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		ret = post_process_op(ret, op);
+#ifdef USER_SPACE_STATS
+		if(cop->c != CIPHER_BYPASS) {
+			stats_cnt[cop->c][cop->m]++;
+		}
+		if(cop->h != HASH_BYPASS) {
+			hash_stats_cnt[cop->h]++;
+		}
+#endif /* USER_SPACE_STATS */
+
+#ifdef USER_SPACE_STATS
+	} else {
+		if(!(IS_ASYNC_SUCCESS_SAEOP(ret))) {
+			if(cop->c == CIPHER_BYPASS) {
+				fail_cnt[cop->c][cop->m]++;
+			}
+		}
+#endif /* USER_SPACE_STATS */
+	}
+	return ret;
+}
+
+int rmisec_cipher_and_hash(op_handle_t handle, CipherAlgo_t c, CipherMode_t m,
+			   const unsigned char *key, const unsigned char *iv,
+			   unsigned int cipher_dwords_to_skip,
+			   Cipher_Function_t encrypt, HashAlgo_t h,
+			   const unsigned char *hmac, int hash_src,
+			   unsigned hash_bytes_to_skip,
+			   const unsigned char *input, unsigned int input_len,
+			   unsigned char *cipher_output, unsigned char *hash_output)
+{
+	operation_pt op = (operation_pt) handle;
+	Crypto_Operation_pt cop;
+
+	if(!handle) {
+		SEC_PRINT("%s:%d Invalid handle passed to operation\n",
+			  __FUNCTION__, __LINE__);
+		return -1;
+	}
+	cop = &op->cop_instance;
+	cop->c = c;
+	cop->m = m;
+	cop->key = key;
+	cop->iv = iv;
+	cop->cipher_dwords_to_skip = cipher_dwords_to_skip;
+	cop->encrypt = encrypt;
+	cop->input = input;
+	cop->input_len = input_len;
+	cop->output = cipher_output;
+
+	cop->h = h;
+	cop->hmac = hmac;
+	cop->hash_bytes_to_skip = hash_bytes_to_skip;
+	cop->digest = hash_output;
+	cop->hash_src = hash_src;
+	return rmisec_cipher_digest_hmac_cksum(handle, cop);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_cipher_and_hash);
+#endif /* KERNEL */
+
+int rmisec_aes128_cipher (op_handle_t handle, const unsigned char *key,
+                          const unsigned char *iv, Cipher_Function_t encrypt,
+                          const unsigned char *input, unsigned int  input_len,
+			  unsigned char *output)
+{
+	operation_pt op = (operation_pt) handle;
+	Crypto_Operation_pt cop;
+
+	if(!handle) {
+		SEC_PRINT("%s:%d Invalid handle passed to operation\n",
+			  __FUNCTION__, __LINE__);
+		return -1;
+	}
+	cop = &op->cop_instance;
+
+	cop->c = RMI_AES128;
+	cop->m = RMI_CBC;
+	cop->key = key;
+	cop->iv = iv;
+	cop->encrypt = encrypt;
+	cop->input = input;
+	cop->input_len = input_len;
+	cop->output = output;
+
+	return rmisec_cipher_digest_hmac_cksum(handle, cop);
+
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_aes128_cipher);
+#endif /* KERNEL */
+
+int rmisec_hash_hmac(op_handle_t handle, HashAlgo_t hash,
+		     const unsigned char *hmac,
+		     const unsigned char *in,
+		     unsigned int size, unsigned char *out)
+{
+	operation_pt op = (operation_pt)handle;
+	Crypto_Operation_pt cop;
+
+	if(!handle) {
+		SEC_PRINT("%s:%d Invalid handle passed to operation\n",
+			  __FUNCTION__, __LINE__);
+		return -1;
+	}
+
+	if(!out || hash < HASH_BYPASS ||
+	   (hash > RMI_SHA512 && hash < RMI_GCM) || !in) {
+		return -EINVAL;
+	}
+
+	cop = &op->cop_instance;
+	cop->h = hash;
+	cop->hmac = hmac;
+	cop->input = in;
+	cop->input_len = size;
+	cop->digest = out;
+
+	return rmisec_cipher_digest_hmac_cksum(handle, cop);
+}
+
+int rmisec_aes192_cipher (op_handle_t handle, const unsigned char *key,
+			  const unsigned char *iv, Cipher_Function_t encrypt,
+			  const unsigned char *input,
+			  unsigned int  input_len,
+			  unsigned char *output)
+{
+	operation_pt op = (operation_pt) handle;
+	Crypto_Operation_pt cop;
+
+	if(!handle) {
+		SEC_PRINT("%s:%d Invalid handle passed to operation\n",
+			  __FUNCTION__, __LINE__);
+		return -1;
+	}
+	cop = &op->cop_instance;
+
+	cop->c = RMI_AES192;
+	cop->m = RMI_CBC;
+	cop->key = key;
+	cop->iv = iv;
+	cop->encrypt = encrypt;
+	cop->input = input;
+	cop->input_len = input_len;
+	cop->output = output;
+
+	return rmisec_cipher_digest_hmac_cksum(handle, cop);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_aes192_cipher);
+#endif /* KERNEL */
+
+int rmisec_aes256_cipher (op_handle_t handle, const unsigned char *key,
+			  const unsigned char *iv, Cipher_Function_t encrypt,
+			  const unsigned char *input,
+			  unsigned int  input_len,
+			  unsigned char *output)
+{
+	operation_pt op = (operation_pt) handle;
+	Crypto_Operation_pt cop;
+
+	if(!handle) {
+		SEC_PRINT("%s:%d Invalid handle passed to operation\n",
+			  __FUNCTION__, __LINE__);
+		return -1;
+	}
+	cop = &op->cop_instance;
+
+	cop->c = RMI_AES256;
+	cop->m = RMI_CBC;
+	cop->key = key;
+	cop->iv = iv;
+	cop->encrypt = encrypt;
+	cop->input = input;
+	cop->input_len = input_len;
+	cop->output = output;
+
+	return rmisec_cipher_digest_hmac_cksum(handle, cop);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_aes256_cipher);
+#endif /* KERNEL */
+
+int rmisec_des_cipher (op_handle_t handle, const unsigned char *key,
+		       const unsigned char *iv, Cipher_Function_t encrypt,
+		       const unsigned char *input,
+		       unsigned int  input_len,
+		       unsigned char *output)
+{
+	operation_pt op = (operation_pt) handle;
+	Crypto_Operation_pt cop;
+
+	if(!handle) {
+		SEC_PRINT("%s:%d Invalid handle passed to operation\n",
+			  __FUNCTION__, __LINE__);
+		return -1;
+	}
+	cop = &op->cop_instance;
+
+	cop->c = RMI_DES;
+	cop->m = RMI_CBC;
+	cop->key = key;
+	cop->iv = iv;
+	cop->encrypt = encrypt;
+	cop->input = input;
+	cop->input_len = input_len;
+	cop->output = output;
+
+	return rmisec_cipher_digest_hmac_cksum(handle, cop);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_des_cipher);
+#endif /* KERNEL */
+
+int rmisec_3des_cipher (op_handle_t handle, const unsigned char *key,
+			const unsigned char *iv, Cipher_Function_t encrypt,
+			const unsigned char *input,
+			unsigned int  input_len,
+			unsigned char *output)
+{
+	operation_pt op = (operation_pt) handle;
+	Crypto_Operation_pt cop;
+
+	if(!handle) {
+		SEC_PRINT("%s:%d Invalid handle passed to operation\n",
+			  __FUNCTION__, __LINE__);
+		return -1;
+	}
+	cop = &op->cop_instance;
+
+	cop->c = RMI_DES3;
+	cop->m = RMI_CBC;
+	cop->key = key;
+	cop->iv = iv;
+	cop->encrypt = encrypt;
+	cop->input = input;
+	cop->input_len = input_len;
+	cop->output = output;
+
+	return rmisec_cipher_digest_hmac_cksum(handle, cop);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_3des_cipher);
+#endif /* KERNEL */
+
+int rmisec_arc4_cipher (op_handle_t handle,
+			const unsigned char *key, int key_len,
+			const unsigned char *input, unsigned int input_len,
+                        unsigned char *output,
+                        int load_state, int save_state,
+                        unsigned char *state)
+{
+	operation_pt op = (operation_pt) handle;
+	Crypto_Operation_pt cop;
+
+	if(!handle) {
+		SEC_PRINT("%s:%d Invalid handle passed to operation\n",
+			  __FUNCTION__, __LINE__);
+		return -1;
+	}
+	cop = &op->cop_instance;
+
+	cop->c = RMI_ARC4;
+	cop->m = RMI_ECB;
+	cop->key = key;
+	cop->key_len = key_len;
+	cop->input = input;
+	cop->input_len = input_len;
+	cop->cipher_box = state;
+	cop->cipher_box_action = load_state?(CIPHER_LOAD_STATE):0;
+	cop->cipher_box_action |= save_state?(CIPHER_SAVE_STATE):0;
+	cop->output = output;
+
+	return rmisec_cipher_digest_hmac_cksum(handle, cop);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_arc4_cipher);
+#endif /* KERNEL */
+
+/* mod_exp_operations */
+static int
+init_rsa_operation(OpType_t t, PKOp_Size_t op_size, int x_len,
+		   int m_len, int e_len, int c_len, operation_pt op)
+{
+
+	int input_size;
+
+	/* e, m and x sizes are 8 times op_size each */
+	input_size = 3 * RSA_BLOCK_SIZE_BYTES * op_size; 
+
+	/* if constant is to be loaded, add it to the input size */
+	if(c_len > 0) {
+		input_size += (RSA_BLOCK_SIZE_BYTES * op_size);
+	}
+
+	op->nr_pages = 1;
+
+	if(map_memory(op)) {
+		return -1;
+	}
+
+	init_ctrl_pointers(op);
+
+	op->data = (unsigned char *)NEXT_CACHELINE(PTR_OFFSET(op->ptr,
+							      sizeof(control_struct_t)));
+
+	op->output = (unsigned char *)CACHELINE_ALIGN(PTR_OFFSET(op->data, input_size));
+
+	memset(op->ctrl_msg, 0, PTR_DIFF(op->output, op->ctrl_msg));
+
+	/* Set Operation Type */
+	op->op_type[0] = RMI_RSA_OP;
+
+	SET_CTRL_SOP(op->ctrl_msg[0]);
+	SET_VALID_OP(op->ctrl_msg[0]);
+
+	SET_DATA_EOP(op->data_msg[0]);
+	SET_WRB_L2_ALLOC(op->data_msg[0]);
+
+	return 0;
+}
+
+/* RSA Modular Exponentiation Operation */
+int
+rmisec_mod_exp (op_handle_t handle,
+                const unsigned char *x, int x_len,
+                const unsigned char *m, int m_len,
+                const unsigned char *e, int e_len,
+                const unsigned char *c, int c_len,
+                unsigned char *y, int *y_len)
+{
+	operation_pt op;
+	uint64_t *dst;
+	uint32_t *tmp;
+	PKOp_Size_t op_size = BIT_1024;
+	int ret, expo_width, mod_width, t, i;
+	control_struct_pt ctrl;
+	int x_size = CEIL(x_len, 3), m_size = CEIL(m_len, 3),
+		e_size = CEIL(e_len, 3), c_size = CEIL(c_len, 3);
+
+#ifdef USER_SPACE_STATS
+	mod_exp_called++;
+#endif /* USER_SPACE_STATS */
+
+	/* calculating input data size */
+	if(m_len <= RSA_BLOCK_SIZE) {
+		op_size = BIT_512;
+	}
+
+	if(m_len > (RSA_BLOCK_SIZE << 1)) {
+		SEC_PRINT("%s:%d Invalid block size m_len=%d\n", __FUNCTION__,
+		       __LINE__, m_len);
+#ifdef USER_SPACE_STATS
+		mod_exp_failed++;
+#endif /* USER_SPACE_STATS */
+		return -1;
+	}
+
+	if(!handle) {
+		SEC_PRINT("%s:%d Invalid handle passed to operation\n",
+			  __FUNCTION__, __LINE__);
+#ifdef USER_SPACE_STATS
+		mod_exp_failed++;
+#endif /* USER_SPACE_STATS */
+		return -1;
+	}
+
+	op = (operation_pt)handle;
+
+	if(init_rsa_operation(RMI_RSA_OP, op_size, x_size, m_size,
+			      e_size, c_size, op)) {
+		SEC_PRINT("%s:%d Operation initialization failed.\n",
+		       __FUNCTION__, __LINE__);
+#ifdef USER_SPACE_STATS
+		mod_exp_failed++;
+#endif /* USER_SPACE_STATS */
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	if(op_size == BIT_1024) {
+		SET_BLOCK_1024(op->ctrl_msg[0]);
+	}
+
+	if(c_size > 0) {
+		SET_LOAD_CONST(op->ctrl_msg[0]);
+	}
+
+	SET_PKOP_SRC_ADDR(op->ctrl_msg[0],
+			  get_phy_addr(op, op->data));
+	SET_PKOP_DST_ADDR(op->data_msg[0],
+			  get_phy_addr(op, op->output));
+
+	dst = (uint64_t *)op->data;
+
+	expo_width = CEIL_VALUE(e_len, 3);
+	tmp = (uint32_t *)e;
+	for(i = 0; i < expo_width; ++i) {
+		t = find_32bit_1st_one_bit(tmp[i]);
+		expo_width -= t;
+		if(t < 32 || expo_width <= 0) {
+			break;
+		}
+	}
+	if(expo_width <= 0) {
+		SEC_PRINT("%s:%d Invalid expo width=%d\n", __FUNCTION__,
+			  __LINE__, expo_width);
+#ifdef USER_SPACE_STATS
+		mod_exp_failed++;
+#endif /* USER_SPACE_STATS */
+		return -1;
+	}
+
+	mod_width = CEIL_VALUE(m_len, 3);
+	tmp = (uint32_t *)m;
+	for(i = 0; i < mod_width; ++i) {
+		t = find_32bit_1st_one_bit(tmp[i]);
+		mod_width -= t;
+		if(t < 32 || mod_width <= 0) {
+			break;
+		}
+	}
+	if(mod_width <= 0) {
+		SEC_PRINT("%s:%d Invalid mod width=%d\n", __FUNCTION__,
+			  __LINE__, mod_width);
+#ifdef USER_SPACE_STATS
+		mod_exp_failed++;
+#endif /* USER_SPACE_STATS */
+		return -1;
+	}
+
+	SET_EXPONENT_WIDTH(op->ctrl_msg[0], expo_width);
+	SET_MODULO_WIDTH(op->data_msg[0], mod_width);
+
+	/* copy constant: c */
+	if(c_len > 0) {
+		dst += dword_data_copy(dst, (uint64_t *)c, c_size, -1);
+	}
+
+	/* copy exponent: e */
+	dst += dword_data_copy(dst, (uint64_t *)e, e_size, -1);
+
+	/* copy modulo: m */
+	dst += dword_data_copy(dst, (uint64_t *)m, m_size, -1);
+
+	/* copy data: x */
+	dword_data_copy(dst, (uint64_t *)x, x_size, -1);
+
+#ifdef SAE_STATS
+	ctrl->rsa_algo = op_size;
+#endif /* SAE_STATS */
+	ret = send_to_driver(op);
+	if(IS_SUCCESS_SAEOP(ret)) {
+		ret = pk_post_process_op(ret, m_len, y, y_len, op);
+	}
+#ifdef USER_SPACE_STATS
+	mod_exp_completed++;
+#endif /* USER_SPACE_STATS */
+	return ret;
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_mod_exp);
+#endif /* KERNEL */
+
+/* ECC Prime Functions */
+static int
+init_ecc_operation(operation_pt op)
+{
+	int input_size;
+
+	if(!is_xls()) {
+		SEC_PRINT("Operation not supported on XLR.\n");
+		return -EINVAL;
+	}
+
+	input_size = 64*8; /* Maximum size of ECC operation */
+
+	op->nr_pages = 1;
+	if(map_memory(op)) {
+		return -1;
+	}
+
+	init_ctrl_pointers(op);
+
+	op->data = (unsigned char *)NEXT_CACHELINE(PTR_OFFSET(op->ptr,
+							      sizeof(control_struct_t)));
+
+	op->output = (unsigned char *)CACHELINE_ALIGN(
+		PTR_OFFSET(op->data, input_size));
+
+	memset(op->ctrl_msg, 0, PTR_DIFF(op->output, op->ctrl_msg));
+
+	/* Set Operation Type */
+	op->op_type[0] = RMI_ECC_OP;
+	SET_OP_CLASS(op->ctrl_msg[0], 1);
+
+	SET_CTRL_SOP(op->ctrl_msg[0]);
+	SET_VALID_OP(op->ctrl_msg[0]);
+
+	SET_DATA_EOP(op->data_msg[0]);
+	SET_WRB_L2_ALLOC(op->data_msg[0]);
+
+	SET_PKOP_SRC_ADDR(op->ctrl_msg[0], get_phy_addr(op, op->data));
+	SET_PKOP_DST_ADDR(op->data_msg[0], get_phy_addr(op, op->output));
+	return 0;
+}
+
+int
+ecc_num_dwords(ECC_Mode_t degree, int k)
+{
+	int ret = 0;
+	if(degree >= RMI_ECC_PRIME_160 && degree <= RMI_ECC_PRIME_512) {
+		if(k) {
+			ret = ecc_prime_k_size[degree];
+		} else {
+			ret = ecc_prime_data_size[degree];
+		}
+	} else if(degree >= RMI_ECC_BINARY_163 && degree <= RMI_ECC_BINARY_233) {
+		ret = ecc_binary_data_size[degree - 0x20];
+	} else {
+		ret = -1;
+	}
+	return ret;
+}
+
+void
+set_ecc_stats(control_struct_pt ctrl, uint8_t ecc_algo, uint8_t degree)
+{
+	ctrl->ecc_algo = ecc_algo;
+	ctrl->ecc_degree = degree;
+	return;
+}
+
+/*
+ * ECC_PRIME_P_MUL = 0,
+ */
+int
+rmisec_ecc_gfp_mul (op_handle_t handle,
+		    ECC_Mode_t degree,
+		    const unsigned char *x, int x_len,
+		    const unsigned char *y, int y_len,
+		    const unsigned char *a, int a_len,
+		    const unsigned char *k, int k_len,
+		    const unsigned char *n, int n_len,
+		    const unsigned char *c, int c_len,
+		    unsigned char *r_x, int *r_x_len,
+		    unsigned char *r_y, int *r_y_len)
+{
+	operation_pt op;
+	uint64_t *dst;
+	control_struct_pt ctrl;
+	int data_size, k_size, ret = -1;
+	int x_l = CEIL(x_len, 3);
+	int y_l = CEIL(y_len, 3);
+	int a_l = CEIL(a_len, 3);
+	int k_l = CEIL(k_len, 3);
+	int n_l = CEIL(n_len, 3);
+	int c_l = CEIL(c_len, 3);
+
+	op = (operation_pt)handle;
+
+	if(init_ecc_operation(op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	data_size = ecc_num_dwords(degree, 0);
+	k_size = ecc_num_dwords(degree, 1);
+/* 	SEC_PRINTN("data_size=%d x_l=%d y_l=%d a_l=%d k_l=%d n_l=%d ecc_output=%d\n", data_size, */
+/* 		   x_l, y_l, a_l, k_l, n_l, ecc_prime_output_bytes[degree]); */
+
+	if(data_size < 3 || k_size < 3) {
+		SEC_PRINT("Invalid degree=[%d].  Could not determine "
+		       "input data sizes. data_size[%d] k_size=[%d]\n",
+		       degree, data_size, k_size);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	SET_ECC_CURVE(op->ctrl_msg[0], degree);
+
+	SET_ECC_FUNCTION(op->ctrl_msg[0], RMI_ECC_PRIME_P_MUL);
+
+	dst = (uint64_t *)op->data;
+
+	/* copy x_p twice */
+	dst += dword_data_copy(dst, (uint64_t *)x, x_l, data_size);
+	dst += dword_data_copy(dst, (uint64_t *)x, x_l, data_size);
+
+	/* copy x_q twice */
+	dst += dword_data_copy(dst, (uint64_t *)y, y_l, data_size);
+	dst += dword_data_copy(dst, (uint64_t *)y, y_l, data_size);
+
+	/* copy a */
+	dst += dword_data_copy(dst, (uint64_t *)a, a_l, data_size);
+
+	/* copy k */
+	dst += dword_data_copy(dst, (uint64_t *)k, k_l, k_size);
+
+	/* copy  n */
+	dst += dword_data_copy(dst, (uint64_t *)n, n_l, data_size);
+
+	/* copy  c */
+	dst += dword_data_copy(dst, (uint64_t *)c, c_l, data_size);
+
+#ifdef SAE_STATS
+	set_ecc_stats(ctrl, RMI_ECC_PRIME_P_MUL, degree);
+#endif /* SAE_STATS */
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		op->output_length = ecc_prime_output_bytes[degree];
+		*r_x_len = *r_y_len = op->output_length << 3;
+
+		result_copy((uint64_t *)r_x, (uint64_t *)op->output,
+			    data_size, ecc_prime_output_bytes[degree]);
+
+		result_copy((uint64_t *)r_y, (uint64_t *)(op->output +
+							  (data_size << 3)),
+			    data_size, ecc_prime_output_bytes[degree]);
+	}
+ bail:
+	return ret;
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gfp_mul);
+#endif /* KERNEL */
+
+/*
+ * ECC_PRIME_P_ADD = 1,
+ */
+int
+rmisec_ecc_gfp_add (op_handle_t handle,
+                int degree,
+                unsigned char *x1, int x1_len,
+                unsigned char *y1, int y1_len,
+                unsigned char *x2, int x2_len,
+                unsigned char *y2, int y2_len,
+                unsigned char *a, int a_len,
+                unsigned char *n, int n_len,
+                unsigned char *c, int c_len,
+                unsigned char *r_x, int *r_x_len,
+                unsigned char *r_y, int *r_y_len)
+{
+	operation_pt op;
+	uint64_t *dst;
+	control_struct_pt ctrl;
+	int data_size, ret = -1;
+	int x1_l = CEIL(x1_len, 3);
+	int y1_l = CEIL(y1_len, 3);
+	int x2_l = CEIL(x2_len, 3);
+	int y2_l = CEIL(y2_len, 3);
+	int a_l = CEIL(a_len, 3);
+	int n_l = CEIL(n_len, 3);
+	int c_l = CEIL(c_len, 3);
+
+	op = (operation_pt)handle;
+
+	if(init_ecc_operation(op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	data_size = ecc_num_dwords(degree, 0);
+
+	if(data_size < 3) {
+		SEC_PRINT("Invalid degree=[%d].  Could not determine "
+		       "input data sizes. data_size[%d]\n",
+		       degree, data_size);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	SET_ECC_CURVE(op->ctrl_msg[0], degree);
+
+	SET_ECC_FUNCTION(op->ctrl_msg[0], RMI_ECC_PRIME_P_ADD);
+
+	dst = (uint64_t *)op->data;
+
+	/* copy x_p */
+	dst += dword_data_copy(dst, (uint64_t *)x1, x1_l, data_size);
+
+	/* copy y_p */
+	dst += dword_data_copy(dst, (uint64_t *)y1, y1_l, data_size);
+
+	/* copy x_p */
+	dst += dword_data_copy(dst, (uint64_t *)x2, x2_l, data_size);
+
+	/* copy y_p */
+	dst += dword_data_copy(dst, (uint64_t *)y2, y2_l, data_size);
+
+	/* copy a */
+	dst += dword_data_copy(dst, (uint64_t *)a, a_l, data_size);
+
+	/* copy  n */
+	dst += dword_data_copy(dst, (uint64_t *)n, n_l, data_size);
+
+	/* copy  c */
+	dst += dword_data_copy(dst, (uint64_t *)c, c_l, data_size);
+
+#ifdef SAE_STATS
+	set_ecc_stats(ctrl, RMI_ECC_PRIME_P_ADD, degree);
+#endif /* SAE_STATS */
+
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		op->output_length = ecc_prime_output_bytes[degree];
+		*r_x_len = *r_y_len = op->output_length << 3;
+
+		result_copy((uint64_t *)r_x, (uint64_t *)op->output,
+			    data_size, ecc_prime_output_bytes[degree]);
+
+		result_copy((uint64_t *)r_y,
+			    (uint64_t *)(op->output + data_size * 8),
+			    data_size, ecc_prime_output_bytes[degree]);
+	}
+ bail:
+	return ret;
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gfp_add);
+#endif /* KERNEL */
+
+/*
+ * ECC_PRIME_P_2X =  2,
+ */
+int
+rmisec_ecc_gfp_dbl (op_handle_t handle,
+                int degree,
+                unsigned char *x, int x_len,
+                unsigned char *y, int y_len,
+                unsigned char *a, int a_len,
+                unsigned char *n, int n_len,
+                unsigned char *c, int c_len,
+                unsigned char *r_x, int *r_x_len,
+                unsigned char *r_y, int *r_y_len)
+{
+	operation_pt op;
+	uint64_t *dst;
+	control_struct_pt ctrl;
+	int data_size, ret = -1;
+	int x_l = CEIL(x_len, 3);
+	int y_l = CEIL(x_len, 3);
+	int a_l = CEIL(x_len, 3);
+	int n_l = CEIL(x_len, 3);
+	int c_l = CEIL(x_len, 3);
+
+	op = (operation_pt)handle;
+
+	if(init_ecc_operation(op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	data_size = ecc_num_dwords(degree, 0);
+
+	if(data_size < 3) {
+		SEC_PRINT("Invalid degree=[%d].  Could not determine "
+		       "input data sizes. data_size[%d]\n",
+		       degree, data_size);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	SET_ECC_CURVE(op->ctrl_msg[0], degree);
+
+	SET_ECC_FUNCTION(op->ctrl_msg[0], RMI_ECC_PRIME_P_2X);
+
+	dst = (uint64_t *)op->data;
+
+	/* copy x_p */
+	dst += dword_data_copy(dst, (uint64_t *)x, x_l, data_size);
+
+	/* copy y_p */
+	dst += dword_data_copy(dst, (uint64_t *)y, y_l, data_size);
+
+	/* copy a */
+	dst += dword_data_copy(dst, (uint64_t *)a, a_l, data_size);
+
+	/* copy  n */
+	dst += dword_data_copy(dst, (uint64_t *)n, n_l, data_size);
+
+	/* copy  c */
+	dst += dword_data_copy(dst, (uint64_t *)c, c_l, data_size);
+
+#ifdef SAE_STATS
+	set_ecc_stats(ctrl, RMI_ECC_PRIME_P_2X, degree);
+#endif /* SAE_STATS */
+
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		op->output_length = ecc_prime_output_bytes[degree];
+		*r_x_len = *r_y_len = op->output_length << 3;
+
+		result_copy((uint64_t *)r_x, (uint64_t *)op->output,
+			    data_size, ecc_prime_output_bytes[degree]);
+
+		result_copy((uint64_t *)r_y, (uint64_t *)(op->output +
+							  (data_size << 3)),
+			    data_size, ecc_prime_output_bytes[degree]);
+	}
+ bail:
+	return ret;
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gfp_dbl);
+#endif /* KERNEL */
+
+/*
+ * ECC_PRIME_P_VER = 3,
+ */
+int
+rmisec_ecc_gfp_vfy (op_handle_t handle,
+                int degree,
+                unsigned char *x, int x_len,
+                unsigned char *y, int y_len,
+                unsigned char *a, int a_len,
+                unsigned char *b, int b_len,
+                unsigned char *n, int n_len,
+                unsigned char *c, int c_len,
+                unsigned int *s)
+{
+	operation_pt op;
+	uint64_t *dst;
+	control_struct_pt ctrl;
+	int data_size, ret = -1;
+	int x_l = CEIL(x_len, 3);
+	int y_l = CEIL(y_len, 3);
+	int a_l = CEIL(a_len, 3);
+	int b_l = CEIL(b_len, 3);
+	int n_l = CEIL(n_len, 3);
+	int c_l = CEIL(c_len, 3);
+
+	op = (operation_pt)handle;
+
+	if(init_ecc_operation(op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	data_size = ecc_num_dwords(degree, 0);
+
+	if(data_size < 3) {
+		SEC_PRINT("Invalid degree=[%d].  Could not determine "
+		       "input data sizes. data_size[%d]\n",
+		       degree, data_size);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	SET_ECC_CURVE(op->ctrl_msg[0], degree);
+
+	SET_ECC_FUNCTION(op->ctrl_msg[0], RMI_ECC_PRIME_P_VFY);
+
+	dst = (uint64_t *)op->data;
+
+	/* copy x_p */
+	dst += dword_data_copy(dst, (uint64_t *)x, x_l, data_size);
+
+	/* copy y_p */
+	dst += dword_data_copy(dst, (uint64_t *)y, y_l, data_size);
+
+	/* copy a */
+	dst += dword_data_copy(dst, (uint64_t *)a, a_l, data_size);
+
+	/* copy b */
+	dst += dword_data_copy(dst, (uint64_t *)b, b_l, data_size);
+
+	/* copy  n */
+	dst += dword_data_copy(dst, (uint64_t *)n, n_l, data_size);
+
+	/* copy  c */
+	dst += dword_data_copy(dst, (uint64_t *)c, c_l, data_size);
+
+#ifdef SAE_STATS
+	set_ecc_stats(ctrl, RMI_ECC_PRIME_P_VFY, degree);
+#endif /* SAE_STATS */
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		op->output_length = 8;
+
+		*s = (int)*((uint64_t *)op->output);
+	}
+bail:
+	return ret;
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gfp_vfy);
+#endif /* KERNEL */
+
+int
+rmisec_ecc_gfp_field_add_sub (op_handle_t handle, ECC_Op_t ec_op, int degree,
+			      unsigned char *x, int x_len,
+			      unsigned char *y, int y_len,
+			      unsigned char *n, int n_len,
+			      unsigned char *r_x, int *r_x_len)
+{
+	operation_pt op;
+	uint64_t *dst;
+	control_struct_pt ctrl;
+	int data_size, ret = -1;
+	int x_l = CEIL(x_len, 3);
+	int y_l = CEIL(y_len, 3);
+	int n_l = CEIL(n_len, 3);
+
+	op = (operation_pt)handle;
+
+	if(init_ecc_operation(op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	data_size = ecc_num_dwords(degree, 0);
+
+	if(data_size < 3) {
+		SEC_PRINT("Invalid degree=[%d].  Could not determine "
+		       "input data sizes. data_size[%d]\n",
+		       degree, data_size);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	SET_ECC_CURVE(op->ctrl_msg[0], degree);
+
+	SET_ECC_FUNCTION(op->ctrl_msg[0], ec_op);
+
+	dst = (uint64_t *)op->data;
+
+	/* copy x_p */
+	dst += dword_data_copy(dst, (uint64_t *)x, x_l, data_size);
+
+	/* copy y_p */
+	dst += dword_data_copy(dst, (uint64_t *)y, y_l, data_size);
+
+	/* copy  n */
+	dst += dword_data_copy(dst, (uint64_t *)n, n_l, data_size);
+
+#ifdef SAE_STATS
+	set_ecc_stats(ctrl, ec_op, degree);
+#endif /* SAE_STATS */
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		*r_x_len = ecc_prime_output_bytes[degree] << 3;
+		result_copy((uint64_t *)r_x, (uint64_t *)op->output,
+			    data_size, ecc_prime_output_bytes[degree]);
+	}
+ bail:
+	return ret;
+}
+
+/*
+ * ECC_PRIME_M_ADD
+ */
+int
+rmisec_ecc_gfp_field_add (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *y, int y_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *r_x, int *r_x_len)
+{
+	return rmisec_ecc_gfp_field_add_sub(handle, RMI_ECC_PRIME_M_ADD, degree,
+					    x, x_len, y, y_len, n, n_len,
+					    r_x, r_x_len);
+
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gfp_field_add);
+#endif /* KERNEL */
+
+/*
+ * ECC_PRIME_M_SUB
+ */
+int
+rmisec_ecc_gfp_field_sub (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *y, int y_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *r_x, int *r_x_len)
+{
+	return rmisec_ecc_gfp_field_add_sub(handle, RMI_ECC_PRIME_M_SUB, degree,
+					    x, x_len, y, y_len, n, n_len,
+					    r_x, r_x_len);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gfp_field_sub);
+#endif /* KERNEL */
+
+/*
+ * ECC_PRIME_M_MUL
+ */
+int
+rmisec_ecc_gfp_field_mul (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *y, int y_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *c, int c_len,
+			  unsigned char *r_x, int *r_x_len)
+{
+	operation_pt op;
+	uint64_t *dst;
+	control_struct_pt ctrl;
+	int data_size, ret = -1;
+	int x_l = CEIL(x_len, 3);
+	int y_l = CEIL(y_len, 3);
+	int n_l = CEIL(n_len, 3);
+	int c_l = CEIL(c_len, 3);
+
+	op = (operation_pt)handle;
+
+	if(init_ecc_operation(op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	data_size = ecc_num_dwords(degree, 0);
+
+	if(data_size < 3) {
+		SEC_PRINT("Invalid degree=[%d].  Could not determine "
+		       "input data sizes. data_size[%d]\n",
+		       degree, data_size);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	SET_ECC_CURVE(op->ctrl_msg[0], degree);
+
+	SET_ECC_FUNCTION(op->ctrl_msg[0], RMI_ECC_PRIME_M_MUL);
+
+	dst = (uint64_t *)op->data;
+
+	/* copy x_p */
+	dst += dword_data_copy(dst, (uint64_t *)x, x_l, data_size);
+
+	/* copy y_p */
+	dst += dword_data_copy(dst, (uint64_t *)y, y_l, data_size);
+
+	/* copy  n */
+	dst += dword_data_copy(dst, (uint64_t *)n, n_l, data_size);
+
+	/* copy  c */
+	dst += dword_data_copy(dst, (uint64_t *)c, c_l, data_size);
+
+#ifdef SAE_STATS
+	set_ecc_stats(ctrl, RMI_ECC_PRIME_M_MUL, degree);
+#endif /* SAE_STATS */
+
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		*r_x_len = ecc_prime_output_bytes[degree] << 3;
+		result_copy((uint64_t *)r_x, (uint64_t *)op->output,
+			    data_size, ecc_prime_output_bytes[degree]);
+	}
+bail:
+	return ret;
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gfp_field_mul);
+#endif /* KERNEL */
+
+/*
+ * ECC_PRIME_M_DIV
+ */
+int
+rmisec_ecc_gfp_field_div (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *y, int y_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *r_x, int *r_x_len)
+{
+	operation_pt op;
+	uint64_t *dst;
+	control_struct_pt ctrl;
+	int data_size, ret = -1;
+	int x_l = CEIL(x_len, 3);
+	int y_l = CEIL(y_len, 3);
+	int n_l = CEIL(n_len, 3);
+
+	op = (operation_pt)handle;
+
+	if(init_ecc_operation(op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	data_size = ecc_num_dwords(degree, 0);
+
+	if(data_size < 3) {
+		SEC_PRINT("Invalid degree=[%d].  Could not determine "
+		       "input data sizes. data_size[%d]\n",
+		       degree, data_size);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	SET_ECC_CURVE(op->ctrl_msg[0], degree);
+
+	SET_ECC_FUNCTION(op->ctrl_msg[0], RMI_ECC_PRIME_M_DIV);
+
+	dst = (uint64_t *)op->data;
+
+	/* copy x_p */
+	dst += dword_data_copy(dst, (uint64_t *)x, x_l, data_size);
+
+	/* copy y_p */
+	dst += dword_data_copy(dst, (uint64_t *)y, y_l, data_size);
+
+	/* copy  n */
+	dst += dword_data_copy(dst, (uint64_t *)n, n_l, data_size);
+
+#ifdef SAE_STATS
+	set_ecc_stats(ctrl, RMI_ECC_PRIME_M_DIV, degree);
+#endif /* SAE_STATS */
+
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		*r_x_len = ecc_prime_output_bytes[degree];
+		result_copy((uint64_t *)r_x, (uint64_t *)op->output,
+			    data_size, *r_x_len);
+		*r_x_len <<= 3;
+	}
+ bail:
+	return ret;
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gfp_field_div);
+#endif /* KERNEL */
+
+int
+rmisec_ecc_gfp_field_inv_red (op_handle_t handle, ECC_Op_t ec_op, int degree,
+			      unsigned char *x, int x_len,
+			      unsigned char *n, int n_len,
+			      unsigned char *r_x, int *r_x_len)
+{
+	operation_pt op;
+	uint64_t *dst;
+	control_struct_pt ctrl;
+	int data_size, ret = -1;
+	int x_l = CEIL(x_len, 3);
+	int n_l = CEIL(n_len, 3);
+
+	op = (operation_pt)handle;
+
+	if(init_ecc_operation(op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	data_size = ecc_num_dwords(degree, 0);
+
+	if(data_size < 3) {
+		SEC_PRINT("Invalid degree=[%d].  Could not determine "
+		       "input data sizes. data_size[%d]\n",
+		       degree, data_size);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	SET_ECC_CURVE(op->ctrl_msg[0], degree);
+
+	SET_ECC_FUNCTION(op->ctrl_msg[0], ec_op);
+
+	dst = (uint64_t *)op->data;
+
+	/* copy x_p */
+	dst += dword_data_copy(dst, (uint64_t *)x, x_l, data_size);
+
+	/* copy  n */
+	dst += dword_data_copy(dst, (uint64_t *)n, n_l, data_size);
+
+#ifdef SAE_STATS
+	set_ecc_stats(ctrl, ec_op, degree);
+#endif /* SAE_STATS */
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		*r_x_len = ecc_prime_output_bytes[degree];
+		result_copy((uint64_t *)r_x, (uint64_t *)op->output,
+			    data_size, *r_x_len);
+		*r_x_len <<= 3;
+	}
+ bail:
+	return ret;
+}
+
+/*
+ * ECC_PRIME_M_INV
+ */
+int
+rmisec_ecc_gfp_field_inv (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *r_x, int *r_x_len)
+{
+	return rmisec_ecc_gfp_field_inv_red(handle, RMI_ECC_PRIME_M_INV, degree,
+					    x, x_len, n, n_len, r_x, r_x_len);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gfp_field_inv);
+#endif /* KERNEL */
+
+
+/*
+ * ECC_PRIME_M_RED
+ */
+int
+rmisec_ecc_gfp_field_red (op_handle_t handle, int degree,
+			  unsigned char *x, int x_len,
+			  unsigned char *n, int n_len,
+			  unsigned char *r_x, int *r_x_len)
+{
+	return rmisec_ecc_gfp_field_inv_red(handle, RMI_ECC_PRIME_M_RED, degree,
+					    x, x_len, n, n_len, r_x, r_x_len);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gfp_field_red);
+#endif /* KERNEL */
+
+/* ECC Binary Functions */
+/*
+ * ECC_BINARY_MUL
+ */
+int
+rmisec_ecc_gf2m_mul (op_handle_t handle, int degree,
+		     unsigned char *x, int x_len,
+		     unsigned char *y, int y_len,
+		     unsigned char *b, int b_len,
+		     unsigned char *k, int k_len,
+		     unsigned char *r_x, int *r_x_len,
+		     unsigned char *r_y, int *r_y_len)
+{
+	operation_pt op;
+	uint64_t *dst;
+	control_struct_pt ctrl;
+	int data_size, ret = -1;
+	int x_l = CEIL(x_len, 3);
+	int y_l = CEIL(y_len, 3);
+	int b_l = CEIL(b_len, 3);
+	int k_l = CEIL(k_len, 3);
+
+	op = (operation_pt)handle;
+
+	if(init_ecc_operation(op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	data_size = ecc_num_dwords(degree, 0);
+
+	if(data_size < 3) {
+		SEC_PRINT("Invalid degree=[%d].  Could not determine "
+		       "input data sizes. data_size[%d]\n",
+		       degree, data_size);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	SET_ECC_CURVE(op->ctrl_msg[0], degree);
+
+	SET_ECC_FUNCTION(op->ctrl_msg[0], RMI_ECC_BINARY_P_MUL);
+
+	dst = (uint64_t *)op->data;
+
+	/* copy b */
+	dst += dword_data_copy(dst, (uint64_t *)b, b_l, data_size);
+
+	/* copy  k */
+	dst += dword_data_copy(dst, (uint64_t *)k, k_l, data_size);
+
+	/* copy x_p */
+	dst += dword_data_copy(dst, (uint64_t *)x, x_l, data_size);
+
+	/* copy y_p */
+	dst += dword_data_copy(dst, (uint64_t *)y, y_l, data_size);
+
+#ifdef SAE_STATS
+	set_ecc_stats(ctrl, RMI_ECC_BINARY_P_MUL, degree);
+#endif /* SAE_STATS */
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		*r_x_len = ecc_binary_output_bytes[degree - RMI_ECC_BINARY_163];
+		result_copy((uint64_t *)r_x, (uint64_t *)op->output,
+			    data_size, *r_x_len);
+
+		*r_y_len = ecc_binary_output_bytes[degree - RMI_ECC_BINARY_163];
+		result_copy((uint64_t *)r_y,
+			    (uint64_t *)op->output+data_size,
+			    data_size, *r_y_len);
+		*r_x_len <<= 3;
+		*r_y_len <<= 3;
+	}
+ bail:
+	return ret;
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gf2m_mul);
+#endif /* KERNEL */
+
+/*
+ * ECC_BINARY_INV
+ */
+int
+rmisec_ecc_gf2m_field_inv (op_handle_t handle, int degree,
+			   unsigned char *x, int x_len,
+			   unsigned char *r_x, int *r_x_len)
+{
+	operation_pt op;
+	uint64_t *dst;
+	control_struct_pt ctrl;
+	int data_size, ret = -1;
+	int x_l = CEIL(x_len, 3);
+
+	op = (operation_pt)handle;
+
+	if(init_ecc_operation(op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	data_size = ecc_num_dwords(degree, 0);
+
+	if(data_size < 3) {
+		SEC_PRINT("Invalid degree=[%d].  Could not determine "
+		       "input data sizes. data_size[%d]\n",
+		       degree, data_size);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	SET_ECC_CURVE(op->ctrl_msg[0], degree);
+
+	SET_ECC_FUNCTION(op->ctrl_msg[0], RMI_ECC_BINARY_GF_INV);
+
+	dst = (uint64_t *)op->data;
+
+	/* copy x_p */
+	dst += dword_data_copy(dst, (uint64_t *)x, x_l, data_size);
+
+#ifdef SAE_STATS
+	set_ecc_stats(ctrl, RMI_ECC_BINARY_GF_INV, degree);
+#endif /* SAE_STATS */
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		*r_x_len = ecc_binary_output_bytes[degree - RMI_ECC_BINARY_163];
+		result_copy((uint64_t *)r_x, (uint64_t *)op->output,
+			    data_size, *r_x_len);
+		*r_x_len <<= 3;
+	}
+ bail:
+	return ret;
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gf2m_field_inv);
+#endif /* KERNEL */
+
+int rmisec_ecc_gf2m_field_mul_add(op_handle_t handle, ECC_Op_t ec_op,
+				  int degree,
+				  unsigned char *x, int x_len,
+				  unsigned char *y, int y_len,
+				  unsigned char *r_x, int *r_x_len)
+{
+	operation_pt op;
+	uint64_t *dst;
+	control_struct_pt ctrl;
+	int data_size, ret = -1;
+	int x_l = CEIL(x_len, 3);
+	int y_l = CEIL(y_len, 3);
+
+	op = (operation_pt)handle;
+
+	if(init_ecc_operation(op)) {
+		return -1;
+	}
+
+	ctrl = (control_struct_pt)op->ptr;
+
+	data_size = ecc_num_dwords(degree, 0);
+
+	if(data_size < 3) {
+		SEC_PRINT("Invalid degree=[%d].  Could not determine "
+		       "input data sizes. data_size[%d]\n",
+		       degree, data_size);
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	SET_ECC_CURVE(op->ctrl_msg[0], degree);
+
+	SET_ECC_FUNCTION(op->ctrl_msg[0], ec_op);
+
+	dst = (uint64_t *)op->data;
+
+	/* copy x_p */
+	dst += dword_data_copy(dst, (uint64_t *)x, x_l, data_size);
+
+	/* copy y_p */
+	dst += dword_data_copy(dst, (uint64_t *)y, y_l, data_size);
+
+#ifdef SAE_STATS
+	set_ecc_stats(ctrl, ec_op, degree);
+#endif /* SAE_STATS */
+
+	ret = send_to_driver(op);
+
+	if(IS_SUCCESS_SAEOP(ret)) {
+		*r_x_len = ecc_binary_output_bytes[degree-0x20];
+		result_copy((uint64_t *)r_x, (uint64_t *)op->output,
+			    data_size, *r_x_len);
+		*r_x_len <<= 3;
+	}
+ bail:
+	return ret;
+}
+
+/*
+ * ECC_BINARY_MUL
+ */
+int
+rmisec_ecc_gf2m_field_mul (op_handle_t handle, int degree,
+			   unsigned char *x, int x_len,
+			   unsigned char *y, int y_len,
+			   unsigned char *r_x, int *r_x_len)
+{
+	return rmisec_ecc_gf2m_field_mul_add(handle, RMI_ECC_BINARY_GF_MUL,
+					     degree, x, x_len, y, y_len,
+					     r_x, r_x_len);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gf2m_field_mul);
+#endif /* KERNEL */
+
+/*
+ * ECC_BINARY_ADD
+ */
+int
+rmisec_ecc_gf2m_field_add (op_handle_t handle, int degree,
+			   unsigned char *x, int x_len,
+			   unsigned char *y, int y_len,
+			   unsigned char *r_x, int *r_x_len)
+{
+	return rmisec_ecc_gf2m_field_mul_add(handle, RMI_ECC_BINARY_GF_ADD,
+					     degree, x, x_len, y, y_len,
+					     r_x, r_x_len);
+}
+#ifdef __KERNEL__
+EXPORT_SYMBOL(rmisec_ecc_gf2m_field_add);
+#endif /* KERNEL */
+
+
+int
+rmisec_bits_to_bytes(int numbits)
+{
+	return CEIL(numbits, 3);
+}
+
+int
+rmisec_bytes_to_bits(const unsigned char *n, int bytes)
+{
+	uint32_t *p;
+	int i = 0, t, ret = bytes << 3, len = bytes >> 2, rem = bytes & 0x3;
+
+	if(rem) {
+		t = find_32bit_1st_one_bit(((uint32_t *)n)[0]);
+		if(t < 32) {
+			ret -= t;
+			return (ret < 0)?0:ret;
+		}
+		ret -= (rem << 3);
+	}
+
+	p = (uint32_t *)&n[rem];
+
+	for(i = 0; i < len; ++i) {
+		t = find_32bit_1st_one_bit(p[i]);
+		if(t < 32) {
+			return ret - t;
+		}
+		ret -= 32;
+	}
+
+	return ret;
+}
+
+void
+print_cipher_output(operation_pt op)
+{
+	int i;
+	SEC_PRINT("Cipher output size=%d ptr=%p\n",
+	       op->output_length, op->output);
+	for(i = 0; i < op->output_length; ++i) {
+		SEC_PRINT("%x", (unsigned)op->output[i]);
+	}
+	SEC_PRINT("\n");
+}
+
+void
+print_hash_output(operation_pt op)
+{
+	int i;
+/* 	SEC_PRINT("Hash output size=%d ptr=%p\n", */
+/* 	       op->hash_length, op->hash_output); */
+	for(i = 0; i < op->hash_length; ++i) {
+		SEC_PRINT("%x", (unsigned)op->hash_output[i]);
+	}
+	SEC_PRINT("\n");
+}
diff --git a/drivers/crypto/rmi/common/utils.h b/drivers/crypto/rmi/common/utils.h
new file mode 100644
index 0000000..c3c2783
--- /dev/null
+++ b/drivers/crypto/rmi/common/utils.h
@@ -0,0 +1,85 @@
+/*********************************************************************
+
+  Copyright 2003-2008 RMI Corporation (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY RMI Corporation, ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+
+/* Common utils */
+#ifdef CONFIG_64BIT
+#define LLX_FMT "lx"
+#define LLD_FMT "ld"
+#define LLU_FMT "lu"
+#else
+#define LLX_FMT "llx"
+#define LLD_FMT "lld"
+#define LLU_FMT "llu"
+#endif
+
+#define find_32bit_1st_one_bit(source)    \
+({ unsigned int __res;                    \
+    __asm__ __volatile__(                 \
+	".set\tpush\n\t"                  \
+	".set\tnoreorder\n\t"             \
+        ".set\tmips32\n\t"                \
+	"clz\t%0,%1\n\t"                  \
+	".set\tpop"                       \
+	: "=r"(__res): "r"(source));   \
+    __res;})
+
+#define find_32bit_1st_zero_bit(source)   \
+({ unsigned int __res;                    \
+    __asm__ __volatile__(                 \
+	".set\tpush\n\t"                  \
+	".set\tnoreorder\n\t"             \
+        ".set\tmips32\n\t"                \
+	"clo\t%0,%1\n\t"                  \
+	".set\tpop"                       \
+	: "=r"(__res): "r"(source));      \
+    __res;})
+
+#define find_64bit_1st_one_bit(source)    \
+({ unsigned int __res;                    \
+    __asm__ __volatile__(                 \
+	".set\tpush\n\t"                  \
+	".set\tnoreorder\n\t"             \
+        ".set\tmips64\n\t"                \
+	"dclz\t%0,%1\n\t"                 \
+	".set\tpop"                       \
+	: "=r"(__res): "r"(source) );      \
+    __res;})
+
+#define find_64bit_1st_zero_bit(source)    \
+({ unsigned int __res;                    \
+    __asm__ __volatile__(                 \
+	".set\tpush\n\t"                  \
+	".set\tnoreorder\n\t"             \
+        ".set\tmips64\n\t"                \
+	"dclo\t%0,%1\n\t"                 \
+	".set\tpop"                       \
+	: "=r"(__res): "r"(source));      \
+    __res;})
+
diff --git a/drivers/crypto/rmi/ecc_ucode_data.h b/drivers/crypto/rmi/ecc_ucode_data.h
new file mode 100644
index 0000000..6a99a9d
--- /dev/null
+++ b/drivers/crypto/rmi/ecc_ucode_data.h
@@ -0,0 +1,363 @@
+/***********************************************************************
+Copyright 2003-2009 RMI Corporation (RMI) All rights reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY RMI Corporation. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************_ RMI_2_**********************************/
+#ifndef ECC_UCODE_DATA_H
+#define ECC_UCODE_DATA_H
+static const uint64_t ecc_msg0 = 0xc07c000000000010ULL;
+static const uint64_t ecc_msg1 = 0xa000000000000000ULL;
+
+static uint64_t ecc_uc_data [] __attribute__((aligned(32))) = {
+    0x0000000022000006ULL,
+    0x0000000022000009ULL,
+    0x0000000022000288ULL,
+    0x220000232200028fULL,
+    0x2200028f24000000ULL,
+    0x2400000022000062ULL,
+    0x0000000022000240ULL,
+    0x000000002200022fULL,
+    0x0000000022000213ULL,
+    0x0000000022000225ULL,
+    0x0000000022000239ULL,
+    0x0000000022000248ULL,
+    0x000000002200025eULL,
+    0x000000002200001eULL,
+    0x000000002200027eULL,
+    0x4518400008c00001ULL,
+    0x4308868044184400ULL,
+    0x220000ae2000010dULL,
+    0x4500c3c0220000bcULL,
+    0x10c0000050d07e00ULL,
+    0x08a0010043004780ULL,
+    0x21a0003415ba8000ULL,
+    0x15ba800008a00200ULL,
+    0x68d0fa0021a00034ULL,
+    0x4400478031600032ULL,
+    0x3100003650b0f200ULL,
+    0x2000003b50b0fa00ULL,
+    0x50d07e004500c3c0ULL,
+    0x14ba800010c00000ULL,
+    0x3300006120000040ULL,
+    0x2200015028a00040ULL,
+    0x2000005f22000084ULL,
+    0x68b0fa0028a00048ULL,
+    0x08c0000131600045ULL,
+    0x220001ad2000004eULL,
+    0x2000005f2200008bULL,
+    0x08c0000110a00000ULL,
+    0x68f0fa0008e00000ULL,
+    0x08c000003360004eULL,
+    0x220001ad10a00000ULL,
+    0x11a000002200007dULL,
+    0x6890fa0008800001ULL,
+    0x23c000593160005bULL,
+    0x08c000012200008bULL,
+    0x220001502000005bULL,
+    0x220001ad22000084ULL,
+    0x108000002200007dULL,
+    0x2200009228a00053ULL,
+    0x24000000220000a0ULL,
+    0x220000ae4008dc00ULL,
+    0x2200020040185000ULL,
+    0x4018120040180380ULL,
+    0x2200020040184000ULL,
+    0x220001f940181200ULL,
+    0x4018320040180340ULL,
+    0x220001f94010d800ULL,
+    0x220001f940181200ULL,
+    0x40183a00401802c0ULL,
+    0x220001f94010d800ULL,
+    0x22000248d0005c00ULL,
+    0x22000248d0006c00ULL,
+    0x50988000d8007400ULL,
+    0x40182a0024000000ULL,
+    0x40186800401840c0ULL,
+    0x4018a800401802c0ULL,
+    0x24000000401804c0ULL,
+    0x4018408040182200ULL,
+    0x4018028040186000ULL,
+    0x401804804018a000ULL,
+    0x40182a0024000000ULL,
+    0x4018680040184080ULL,
+    0x4018a80040180280ULL,
+    0x2400000040180480ULL,
+    0x4418400040181200ULL,
+    0x40180200220001f9ULL,
+    0x4018500040184080ULL,
+    0x220001f944180200ULL,
+    0x4018900040180280ULL,
+    0x220001f944180200ULL,
+    0x2400000040180480ULL,
+    0x4018900040181400ULL,
+    0x40188080220000a9ULL,
+    0x4018900040185400ULL,
+    0x40188280220000a9ULL,
+    0x08c0000024000000ULL,
+    0x430887004010c200ULL,
+    0x24000000220000caULL,
+    0x4010d80040181200ULL,
+    0x40180200220001f9ULL,
+    0x4018500040184080ULL,
+    0x220001f94010da00ULL,
+    0x4018900040180280ULL,
+    0x220001f94010da00ULL,
+    0x2400000040180480ULL,
+    0x4010d80040181a00ULL,
+    0x40180200220001f9ULL,
+    0x40185800401840c0ULL,
+    0x220001f94010da00ULL,
+    0x40189800401802c0ULL,
+    0x220001f94010da00ULL,
+    0x24000000401804c0ULL,
+    0x4010c20008800000ULL,
+    0x200000d023c000ceULL,
+    0x200000d708c00000ULL,
+    0x50a18a00d8004440ULL,
+    0x688804003300010cULL,
+    0x41180440336000dfULL,
+    0x6888860040188800ULL,
+    0x41008240336000dcULL,
+    0x200000d040014c00ULL,
+    0x41180c00d010c040ULL,
+    0x68804400200000d0ULL,
+    0x41184440336000ecULL,
+    0x6888e40040188a00ULL,
+    0x4100e440336000e8ULL,
+    0x200000d040018f00ULL,
+    0xd011c0404000e440ULL,
+    0x200000d041110f00ULL,
+    0x334000fcd8004440ULL,
+    0xd810e04041088800ULL,
+    0x314000f440090c00ULL,
+    0x40180c00d010c040ULL,
+    0x336000f968888700ULL,
+    0x40180c0041188040ULL,
+    0xd010c040200000d0ULL,
+    0x200000d041180c00ULL,
+    0x41008a00d8080440ULL,
+    0x40090f00d81c8040ULL,
+    0xd001c44031400103ULL,
+    0x6888e40040018f00ULL,
+    0x4100e44033600108ULL,
+    0x200000d040018f00ULL,
+    0xd011c0404000e440ULL,
+    0x200000d041100f00ULL,
+    0x0880000024000000ULL,
+    0x23c001114010c200ULL,
+    0x08c0000020000113ULL,
+    0xd80044402000011aULL,
+    0x3300014f50a18a00ULL,
+    0x3360012268880400ULL,
+    0x4018880041180440ULL,
+    0x3360011f68888600ULL,
+    0x40014c0041008240ULL,
+    0xd010c04020000113ULL,
+    0x2000011341180c00ULL,
+    0x3360012f68804400ULL,
+    0x40188a0041184440ULL,
+    0x3360012b6888d400ULL,
+    0x40018e804100d440ULL,
+    0x4000d44020000113ULL,
+    0x41110e80d011c040ULL,
+    0xd800444020000113ULL,
+    0x410888003340013fULL,
+    0x40090c00d810d040ULL,
+    0xd010c04031400137ULL,
+    0x6888868040180c00ULL,
+    0x411880403360013cULL,
+    0x2000011340180c00ULL,
+    0x41180c00d010c040ULL,
+    0xd808044020000113ULL,
+    0xd81a804041008a00ULL,
+    0x3140014640090e80ULL,
+    0x40018e80d001c440ULL,
+    0x3360014b6888d400ULL,
+    0x40018e804100d440ULL,
+    0x4000d44020000113ULL,
+    0x41100e80d011c040ULL,
+    0x2400000020000113ULL,
+    0x4018980040101200ULL,
+    0x40080700220001f9ULL,
+    0x4008900040101a00ULL,
+    0x40100300220001f9ULL,
+    0x22000207d80ce400ULL,
+    0xd00ce40040180500ULL,
+    0x4008054022000248ULL,
+    0x220002004018a000ULL,
+    0x4000a20040100740ULL,
+    0x40080780220001f9ULL,
+    0x4000aa004010e800ULL,
+    0x40100340220001f9ULL,
+    0x40189a0040185000ULL,
+    0x40180580220001f9ULL,
+    0x4018920040185800ULL,
+    0x40100700220001f9ULL,
+    0x40187400d81cb380ULL,
+    0x4010038022000207ULL,
+    0x40180400d01cb000ULL,
+    0x401003c022000248ULL,
+    0x2200020040107000ULL,
+    0x401845c040100200ULL,
+    0x40189a0040189000ULL,
+    0x40100700220001f9ULL,
+    0x220001f94018ba00ULL,
+    0xd8006c0040080740ULL,
+    0x4018a20022000207ULL,
+    0x40180200220001f9ULL,
+    0x4210680040184100ULL,
+    0x2200024840180400ULL,
+    0x22000248d00d0400ULL,
+    0x4208ec0040180500ULL,
+    0x4018020022000248ULL,
+    0x40180400d8144000ULL,
+    0x4018020022000207ULL,
+    0x220001f940187000ULL,
+    0x4018780040180500ULL,
+    0x220001f94000f200ULL,
+    0x4000ec00d8140740ULL,
+    0x4010074022000207ULL,
+    0x68f0e80008e00000ULL,
+    0x200001a7336001a4ULL,
+    0xd008e8004010c200ULL,
+    0x4110eb0040100740ULL,
+    0x4010f2004008e000ULL,
+    0x40080500220001f9ULL,
+    0x40009a0024000000ULL,
+    0x220001f940185800ULL,
+    0x2200024842080400ULL,
+    0x40101a0040080540ULL,
+    0x2200020040104000ULL,
+    0x4210020040100780ULL,
+    0x2200024840004400ULL,
+    0x22000248d000f400ULL,
+    0x4018980040180580ULL,
+    0x401804c022000200ULL,
+    0x4010d80040183200ULL,
+    0x40189a00220001f9ULL,
+    0xd0160200220001f9ULL,
+    0x2200024840004400ULL,
+    0x40101a0040180580ULL,
+    0x220001f940105800ULL,
+    0x4018b000401805c0ULL,
+    0x4010038022000200ULL,
+    0x4018ba004018a800ULL,
+    0x401003c0220001f9ULL,
+    0x220002004018a800ULL,
+    0x42187c0040080700ULL,
+    0x4010074022000248ULL,
+    0x2200024842180400ULL,
+    0x40187000401803c0ULL,
+    0x22000207d8007c00ULL,
+    0x220001f94018aa00ULL,
+    0x4018814040180400ULL,
+    0x22000248d00fec00ULL,
+    0x22000207d8007400ULL,
+    0x220001f94018b200ULL,
+    0x40185800401803c0ULL,
+    0x4010e20022000200ULL,
+    0x42180400220001f9ULL,
+    0xd80f040022000248ULL,
+    0x4018034022000207ULL,
+    0x4000e2004018a800ULL,
+    0x40180540220001f9ULL,
+    0xc800440024000000ULL,
+    0xc808c000c910ca00ULL,
+    0x40184c00d1008200ULL,
+    0x2400000022000248ULL,
+    0xc910ca00ca004400ULL,
+    0xd1008200c808c000ULL,
+    0x2200024840184c00ULL,
+    0x3340020924000000ULL,
+    0xd010c0002000020bULL,
+    0x400880002000020cULL,
+    0x3340020f24000000ULL,
+    0xd010c00020000211ULL,
+    0x4008800020000212ULL,
+    0x3340021c24000000ULL,
+    0x08c0000133200220ULL,
+    0xd000440022000257ULL,
+    0xd800c40022000248ULL,
+    0x2000022431400218ULL,
+    0x4310024043104040ULL,
+    0x20000217d0014c00ULL,
+    0x4310024043104040ULL,
+    0x20000217d8014c00ULL,
+    0x2200025724000000ULL,
+    0x3340022b22000251ULL,
+    0x40188000d8188040ULL,
+    0xd81880002000022eULL,
+    0x2000022e40188040ULL,
+    0x4010468024000000ULL,
+    0x4008040022000240ULL,
+    0x400086804010d000ULL,
+    0x4010d20022000240ULL,
+    0x22000244220001f9ULL,
+    0x4018820024000000ULL,
+    0x4018440022000257ULL,
+    0x08c0000043104680ULL,
+    0x240000002200010dULL,
+    0x4010d80040180200ULL,
+    0x24000000220001f9ULL,
+    0x08c000014410c200ULL,
+    0x24000000220001f9ULL,
+    0x2000024c3320024aULL,
+    0x40080c00d810c040ULL,
+    0xd800c40040088000ULL,
+    0x4008800033400250ULL,
+    0xd800440024000000ULL,
+    0x2000025633400254ULL,
+    0xd8004440d8080400ULL,
+    0x4010068024000000ULL,
+    0x2200024840184400ULL,
+    0x4008d40040100200ULL,
+    0x2400000022000248ULL,
+    0x43180a00f8000000ULL,
+    0x4318404043080e40ULL,
+    0x4110c24044184000ULL,
+    0x6a8044005180c400ULL,
+    0xd100440008c00000ULL,
+    0x3340026ed91a88c0ULL,
+    0x401880003300027aULL,
+    0x6a80cc0040188840ULL,
+    0x6b004c0008c00001ULL,
+    0x08c0000033600272ULL,
+    0x41004c4041004400ULL,
+    0x40008a4040008200ULL,
+    0x6d20440021c00278ULL,
+    0x2000026711800000ULL,
+    0x3100026e51c08600ULL,
+    0x240000006a80cc00ULL,
+    0x6b10020008c00003ULL,
+    0xd000c20031600283ULL,
+    0x4118020040184000ULL,
+    0x28c0027f40184000ULL,
+    0x24000000400806c0ULL,
+    0x401032002200028fULL,
+    0x40103a0040104000ULL,
+    0x2200022f40104040ULL,
+    0x2200027e24000000ULL,
+    0x400086802200001eULL,
+    0x440044802200025eULL,
+    0x24000000440044c0ULL,
+    0x0000000000000000ULL,
+};
+#endif /* ECC_UCODE_DATA_H */
diff --git a/drivers/crypto/rmi/rmi_state_info.h b/drivers/crypto/rmi/rmi_state_info.h
new file mode 100644
index 0000000..59b96a4
--- /dev/null
+++ b/drivers/crypto/rmi/rmi_state_info.h
@@ -0,0 +1,144 @@
+/*********************************************************************
+
+  Copyright 2003-2006 Raza Microelectronics, Inc. (RMI). All rights
+  reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+  1. Redistributions of source code must retain the above copyright
+  notice, this list of conditions and the following disclaimer.
+  2. Redistributions in binary form must reproduce the above copyright
+  notice, this list of conditions and the following disclaimer in
+  the documentation and/or other materials provided with the
+  distribution.
+
+  THIS SOFTWARE IS PROVIDED BY Raza Microelectronics, Inc. ``AS IS'' AND
+  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+  PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+  FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+  THE POSSIBILITY OF SUCH DAMAGE.
+
+  *****************************#RMI_2#**********************************/
+struct xlr_crypt_state {
+
+	void *src;
+	void *dst;
+	void *auth_dst;
+	void *auth_src;
+	
+	u32 cipher;
+	u32 hash;
+
+	u32 mode;
+	u32 dir;
+	u32 flags;
+	int len;
+	int iv_len;
+	int block_size;
+	u8 *iv_ptr;
+	u8 *data_ptr;
+	u8 *out_data_ptr;
+	u8 *auth_ptr;
+	int hmac;
+	int hmac_keylen;
+	void *malloc_ptr;
+	int nr_data_desc;
+	//sandip -> check data_desc ptr...
+	uint64_t *cipher_desc;
+	uint64_t *cipher_key_hash_info;
+	uint64_t *data_desc;
+	int key_len;
+
+	u8 key[32]; // max key length
+	u8 iv[32]; // max iv length
+	u8 hmac_key[128]; // max hmac key length //sandip -> Check this length
+	u8 hash_result[128];
+	uint32_t nonce;
+//	u8 nonce[16];
+//	int nonce_len;
+	uint64_t data_msg;
+	uint64_t ctrl_msg;
+};
+
+#ifdef SANDIP
+
+/**
+ * SIZES of control data in bytes
+ */
+#define CTRL_DESC_VECTOR_SIZE 8
+#define CTRL_INSTR_SIZE 8
+#define MAX_CTRL_DATA_SIZE 472
+#define DATA_DESC_VECTOR_SIZE 8
+#define DATA_DESC_SIZE 32
+#define CEIL_BY_DIV(a,b) (((a)/b) + ((a%b)?1:0))
+#define ADDR_MASK 0xffffffffe0ULL
+#define DATA_DESC_VECTOR_TEMPLATE         ((5ULL << 61) | (1ULL << 45))
+#define MAX_FRAG_TOT_SIZE (((1 << 11) -1) * 8) /* 16 K - 8 */
+#define MAX_PER_FRAG_FIELD_SIZE (MAX_FRAG_TOT_SIZE >> 5 << 2)
+#define MAX_PER_FRAG_SIZE (MAX_FRAG_TOT_SIZE >> 5 << 5);
+
+#define PTR_OFFSET(a,b) (unsigned long)((((unsigned long)a) + (b)))
+#define HAS_REMINDER(x, y)  (((uint64_t)(x) & ((1ULL << (y)) - 1))?1:0)
+#define CEIL(n, bits) ((((uint64_t)n)>>(bits)) + HAS_REMINDER(n,bits))
+#define CEIL_BYTES(m,n) ((CEIL(m,n))<<(n))
+#define NEXT_CACHELINE_ALIGN(m) (unsigned long)(CEIL_BYTES(m, 5))
+#define CACHELINE_ALIGN(m) ((unsigned long long)(unsigned long)(m) >> 5 << 5)
+#define PTR_DIFF(x, y)   (((unsigned long)x) - ((unsigned long)(y)))
+
+#define APPLY_ADDR_MASK(phys,mask) ((unsigned long long)(phys) & (mask))
+
+typedef enum CipherAlgo {
+	CIPHER_BYPASS = 0,
+	RMI_DES,
+	RMI_DES3,
+	RMI_AES128,
+	RMI_AES192,
+	RMI_AES256,
+	RMI_ARC4,
+	RMI_KASUMI_F8,
+	MAX_CIPHER_ALGO
+} CipherAlgo_t;
+
+typedef enum CipherMode {
+	RMI_ECB = 0,
+	RMI_CBC,
+	RMI_CFB,
+	RMI_OFB,
+	RMI_CTR,
+	RMI_F8,
+	RMI_CCM,
+	MAX_CIPHER_MODE
+} CipherMode_t;
+
+typedef enum HashAlgo {
+	HASH_BYPASS = 0,
+	RMI_MD5,
+	RMI_SHA1,
+	RMI_SHA256,
+	RMI_SHA384,
+	RMI_SHA512,
+	RMI_GCM,
+	RMI_KASUMI_F9,
+	RMI_DES3_CMAC,
+	RMI_AES_CMAC,
+	MAX_HASH_ALGO
+} HashAlgo_t;
+
+typedef enum {
+	CIPHER_DECRYPT=0,
+	CIPHER_ENCRYPT
+} Cipher_Function_t;
+
+#endif /* SANDIP */
+
+//extern unsigned int xlr_digest(struct xlr_sae_op *op);
+//extern unsigned int xlr_crypt(struct xlr_sae_op *op);
+//extern int xlr_sec_init(void);
diff --git a/drivers/crypto/rmi/rmisec.c b/drivers/crypto/rmi/rmisec.c
new file mode 100644
index 0000000..e93351f
--- /dev/null
+++ b/drivers/crypto/rmi/rmisec.c
@@ -0,0 +1,2286 @@
+/***********************************************************************
+Copyright 2003-2009 RMI Corporation (RMI) All rights reserved.
+Redistribution and use in source and binary forms, with or without
+modification, are permitted provided that the following conditions are
+met:
+1. Redistributions of source code must retain the above copyright
+notice, this list of conditions and the following disclaimer.
+2. Redistributions in binary form must reproduce the above copyright
+notice, this list of conditions and the following disclaimer in
+the documentation and/or other materials provided with the
+distribution.
+THIS SOFTWARE IS PROVIDED BY RMI Corporation. ``AS IS'' AND
+ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
+IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL RMI OR CONTRIBUTORS BE LIABLE
+FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
+INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
+CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
+ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF
+THE POSSIBILITY OF SUCH DAMAGE.
+*****************************_ RMI_2_**********************************/
+
+#ifndef AUTOCONF_INCLUDED
+#include <linux/config.h>
+#endif
+
+#include <linux/types.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/sched.h>
+#include <linux/cdev.h>
+#include <linux/list.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <linux/highmem.h>
+#include <linux/proc_fs.h>
+#include <linux/kernel.h>
+#include <linux/hardirq.h>
+#include <linux/netdevice.h>
+#include <asm/current.h>
+#include <asm/atomic.h>
+#include <asm/rmi/msgring.h>
+#include <asm/rmi/sim.h>
+#include <asm/rmi/utils.h>
+#include <asm/rmi/mips-exts.h>
+
+#ifdef CONFIG_OCF_OCF_MODULE
+#include <linux/crypto.h>
+#include <cryptodev.h>
+#endif
+
+#include "common/rmisec_internal.h"
+#include "ecc_ucode_data.h"
+
+#define	ECC_UC_LOAD 0x70
+MODULE_AUTHOR("RMI Corporation");
+MODULE_DESCRIPTION("XLS/XLR SAE Driver");
+MODULE_LICENSE("Dual BSD/GPL");
+
+typedef struct device_info *device_info_pt;
+
+enum progress_type
+{
+	NOT_IN_PROGRESS = 0,
+	IN_PROGRESS,
+	IN_WAIT_QUEUE
+};
+
+#define IS_IN_PROGRESS(m) ((m)->in_progress == IN_PROGRESS)
+#define IS_IN_WAIT_QUEUE(m) ((m)->in_progress == IN_WAIT_QUEUE)
+
+#define NR_CRYPTO_BITS 9
+#define NR_PK_BITS 3
+/* 
+ * we use only the last 8 bits, so we offet result of
+ * clz with this offset 
+*/
+#define PK_BITMAP_OFFSET 24
+
+#define NR_CRYPTO_OPS (1 << NR_CRYPTO_BITS)
+#define NR_PK_OPS     (1 << NR_PK_BITS)
+
+#define MAX_CRYPTO_OPS_INDEX   (NR_CRYPTO_OPS >> 5)
+
+#define CRYPTO_BITMAP_INDEX(x) (x >> 5)
+#define BITMAP_OFF_MASK(x)     ~(0x80000000 >> ((x) & 0x1f))
+#define BITMAP_ON_MASK(x)       (0x80000000 >> ((x) & 0x1f))
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+DECLARE_PER_CPU(struct napi_struct, xlr_napi_poll_struct);
+extern struct net_device xlr_napi_dummy_dev;
+void xlr_napi_poll_upper(struct net_device *dummy_dev, int *budget);
+extern int xlr_napi_ready, rmi_on_chip_napi;
+#define upper_buckets_nonempty() ((~msgrng_read_status() >> 28) & 0xf)
+#endif
+
+extern __u32 cpu_to_frstid[];
+static char driver_name[] = DRIVER_NAME;
+static char debug_name[] __attribute__ ((unused)) = "debug";
+static char stats_name[] = "stats";
+static char RMISAE_BUILD_VERSION[] = "1.7";
+static const char *versionstr = RMISAE_BUILD_VERSION;
+extern int xlr_loader_support;
+extern int xlr_loader_sharedcore;
+
+static atomic_t vma_count __cacheline_aligned;
+static uint64_t msgs_sent[NR_CPUS] __cacheline_aligned;
+static uint64_t resp_recieved[NR_CPUS] __cacheline_aligned;
+static uint64_t wait_count[NR_CPUS] __cacheline_aligned;
+static uint64_t mmap_cnt[NR_CPUS]
+		 __cacheline_aligned __attribute__ ((unused));
+static uint64_t mmapfree[NR_CPUS]
+		__cacheline_aligned __attribute__ ((unused));
+static uint64_t cipher_cnt[NR_CPUS][MAX_CIPHER_ALGO][MAX_CIPHER_MODE]
+		 __cacheline_aligned;
+static uint64_t cipher_data_cnt[NR_CPUS][MAX_CIPHER_ALGO][MAX_CIPHER_MODE]
+		 __cacheline_aligned;
+static uint64_t hash_cnt[NR_CPUS][MAX_HASH_ALGO] __cacheline_aligned;
+static uint64_t hash_data_cnt[NR_CPUS][MAX_HASH_ALGO]
+		 __cacheline_aligned;
+static uint64_t mod_exp_cnt[NR_CPUS][2] __cacheline_aligned;
+static uint64_t ecc_prime_cnt[NR_CPUS][RMI_ECC_PRIME_CURVE_MAX][RMI_ECC_PRIME_OP_MAX]
+		__cacheline_aligned __attribute__ ((unused));
+static uint64_t ecc_binary_cnt[NR_CPUS][RMI_ECC_BINARY_CURVE_MAX][RMI_ECC_BINARY_OP_MAX]
+		__cacheline_aligned __attribute__ ((unused));
+
+static struct device_info
+{
+	int version;
+	dev_t device;
+	struct proc_dir_entry *pdir;
+	struct proc_dir_entry *pdebug;
+	struct proc_dir_entry *pstats;
+	struct cdev rmisec_cdev;
+#ifdef CONFIG_OCF_OCF_MODULE
+	op_callback_t ocf_cb;
+	softc_device_decl ocf_dev;
+	int32_t ocf_id;
+#endif
+	spinlock_t mem_lock;
+	struct list_head pmem_list;
+
+	spinlock_t crypto_lock;
+	atomic_t crypto_used_slots;
+	unsigned int max_crypto_used_slots;
+	meminfo_pt crypto_ops_slot[NR_CRYPTO_OPS];
+	unsigned int pk_used_slots;
+	unsigned int max_pk_used_slots;
+	uint32_t crypto_ops_bitmap[MAX_CRYPTO_OPS_INDEX];
+	unsigned int bitmap_start;
+
+	spinlock_t pkops_lock;
+	volatile uint32_t pk_ops_bitmap;
+	meminfo_pt pk_ops_slot[NR_PK_OPS];
+	wait_queue_head_t crypto_queue;
+	wait_queue_head_t pkop_queue;
+	int exit_driver;
+} dev_info;
+
+extern void phnx_msgring_int_handler(unsigned int irq,
+								  struct pt_regs *regs);
+extern int msgring_int_type;
+
+static inline void remote_napi_poll_upper(void)
+{
+	unsigned long flags;
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	if (xlr_napi_ready && rmi_on_chip_napi && upper_buckets_nonempty()) {
+		xlr_napi_poll_upper(&xlr_napi_dummy_dev, 0);
+	}
+	else if (in_softirq() && (!msgring_int_type)) {
+		local_irq_save(flags);
+		phnx_msgring_int_handler(-1, NULL);
+		local_irq_restore(flags);
+	}
+#else
+	if (in_softirq() && (!msgring_int_type)) {
+		local_irq_save(flags);
+		phnx_msgring_int_handler(-1, NULL);
+		local_irq_restore(flags);
+	}
+	return;
+#endif
+}
+
+#ifdef CONFIG_OCF_OCF_MODULE
+int rmisae_ocf_newsession(device_t dev, u_int64_t * sidp,
+						  struct cryptoini *cri);
+int rmisae_ocf_freesession(device_t dev, u_int64_t sid);
+int rmisae_ocf_process(device_t dev, struct cryptop *crp, int hint);
+
+static device_method_t rmisae_ocf_methods = {
+	DEVMETHOD(cryptodev_newsession, rmisae_ocf_newsession),
+	DEVMETHOD(cryptodev_freesession, rmisae_ocf_freesession),
+	DEVMETHOD(cryptodev_process, rmisae_ocf_process)
+};
+
+static struct
+{
+	int ocf_algo_num;
+	CipherAlgo_t c;
+	CipherMode_t m;
+	HashAlgo_t h;
+	int hmac;
+} algo_mapper[] = {
+	{CRYPTO_DES_CBC, RMI_DES, RMI_CBC, HASH_BYPASS, 0},
+	{CRYPTO_3DES_CBC, RMI_DES3, RMI_CBC, HASH_BYPASS, 0}, 
+	{-1},						/* CRYPTO_BLF_CBC */
+	{-1},						/* CRYPTO_CAST_CBC */
+	{-1},						/* CRYPTO_SKIPJACK_CBC */
+	{CRYPTO_MD5_HMAC, CIPHER_BYPASS, RMI_ECB, RMI_MD5, 1},
+	{CRYPTO_SHA1_HMAC, CIPHER_BYPASS, RMI_ECB, RMI_SHA1, 1}, 
+	{-1},						/* CRYPTO_RIPEMD160_HMAC */
+	{-1},						/* CRYPTO_MD5_KPDK */
+	{-1},						/* CRYPTO_SHA1_KPDK */
+	{CRYPTO_AES_CBC, RMI_AES128, RMI_CBC, HASH_BYPASS, 0}, 
+	{-1},						/* ARC4 */
+	{CRYPTO_MD5, CIPHER_BYPASS, RMI_ECB, RMI_MD5, 0},
+	{CRYPTO_SHA1, CIPHER_BYPASS, RMI_ECB, RMI_SHA1, 0}, 
+	{-1},						/* CRYPTO_NULL_HMAC */
+	{-1},						/* CRYPTO_NULL_CBC */
+	{-1},						/* CRYPTO_DEFLATE_COMP */
+	{CRYPTO_SHA2_256_HMAC, CIPHER_BYPASS, RMI_ECB, RMI_SHA256, 1}, 
+	{CRYPTO_SHA2_384_HMAC, CIPHER_BYPASS, RMI_ECB, RMI_SHA384, 1}, 
+	{CRYPTO_SHA2_512_HMAC, CIPHER_BYPASS, RMI_ECB, RMI_SHA512, 1}, 
+	{-1},						/* CRYPTO_CAMELLIA_CBC */i
+	{CRYPTO_SHA2_256, CIPHER_BYPASS, RMI_ECB, RMI_SHA256, 0}, 
+	{CRYPTO_SHA2_384, CIPHER_BYPASS, RMI_ECB, RMI_SHA384, 0}, 
+	{CRYPTO_SHA2_512, CIPHER_BYPASS, RMI_ECB, RMI_SHA512, 0}, 
+	{-1},						/* CRYPTO_RIPEMD160 */
+};
+
+int rmisae_ocf_newsession(device_t dev, u_int64_t * sidp,
+						  struct cryptoini *cri)
+{
+	Crypto_Operation_pt cop;
+	if (in_atomic() || in_interrupt()) {
+		cop = (Crypto_Operation_pt) kmalloc(sizeof(Crypto_Operation_t),
+											GFP_ATOMIC);
+	}
+	else {
+		cop = (Crypto_Operation_pt) kmalloc(sizeof(Crypto_Operation_t),
+											GFP_KERNEL);
+	}
+	if (cop == NULL) {
+		return -ENOMEM;
+	}
+
+	memset(cop, 0, sizeof(Crypto_Operation_t));
+
+	/* populate all crypto fields here */
+	cop->c = algo_mapper[cri->cri_alg].c;
+	cop->m = algo_mapper[cri->cri_alg].m;
+	cop->key = cri->key;
+	cop->key_len = cri->klen;
+	cop->iv = cri->cri_iv;
+	if (crp->flags & CRYPTO_OP_ENCRYPT) {
+		cop->encrypt = CIPHER_ENCRYPT;
+	}
+
+	/* authentication parameters */
+	if (cri->cri_next != NULL) {
+		cri = cri->next;
+		cop->h = algo_mapper[cri->cri_alg].h;
+		if (algo_mapper[cri->cri_alg].hmac) {
+			cop->hmac = (unsigned char *) cri->cri_key;
+			cop->hmac_len = cri->cri_klen;
+		}
+	}
+
+	*sidp = (u_int64_t) op;
+	return 0;
+}
+
+int rmisae_ocf_freesession(device_t dev, u_int64_t sid)
+{
+	op_handle_t op = (op_handle_t) sid;
+	return rmisec_op_cleanup(&op);
+}
+
+int rmisae_ocf_process(device_t dev, struct cryptop *crp, int hint)
+{
+	Crypto_Operation_pt *cop = (Crypto_Operation_pt) crp->crp_sid;
+	op_handle_t op;
+	int ret = RMISAE_SUCCESS;
+
+	ret = rmisec_op_init(&op);
+	if (ret) {
+		goto bail;
+	}
+
+	if ((ret = rmisec_op_callback_setup(op, &dev_info.ocf_cb,
+										(unsigned long) op, 0))) {
+		printk(KERN_ALERT "%s:%d Error while submitting operation to SAE.",
+			   __FUNCTION__, __LINE__);
+		rmisec_op_cleanup(&op);
+		goto bail;
+	}
+
+	ret = rmisec_cipher_and_hash(op, cop->c, cop->m, cop->key, cop->iv, 
+			0, (crp->crp_desc.crd_flags & CRD_F_ENCRYPT), cop->h, cop->hmac, 
+			0,	/* hash_src */
+			0,	/* hash_bytes_to_skip */
+			crp->crp_buf, crp->crp_ilen,);
+	crypto_copyback(crp->crp_flags, crp->crp_buf,
+					crd->crd_inject, sw->u.hmac.sw_mlen, result);
+
+	if (!IS_ASYNC_SUCCESS_SAEOP(ret)) {
+		rmisec_op_cleanup(&op);
+	}
+
+bail:
+	return ret;
+}
+
+void rmisae_ocf_callback(int result, unsigned long arg)
+{
+}
+
+#endif /* CONFIG_OCF_OCF_MODULE */
+
+#ifdef CONFIG_64BIT
+static __inline__ void ldadd_d_noread(long long value, uint64_t * addr)
+{
+	__asm__ __volatile__(
+					".set push\n"
+					 ".set noreorder\n" "move $8, %2\n" "move $9, %3\n"
+					 /* "ldaddd $8, $9\n" */
+					 ".word 0x71280012\n"
+					 ".set pop\n":"=&r"(value), "+m"(*addr)
+					 :"0"(value), "r"((unsigned long) addr)
+					 :"$8", "$9"
+				);
+}
+#endif /* CONFIG_64BIT */
+
+static inline int
+message_send_fast_2(unsigned int code,
+					unsigned int stid,
+					unsigned long long msg0, unsigned long long msg1)
+{
+	int ret;
+
+
+	msgrng_load_tx_msg0(msg0);
+	msgrng_load_tx_msg1(msg1);
+
+	__asm__ __volatile__(
+					".set push\n"
+					 ".set noreorder\n"
+					 ".set mips64\n"
+					 "sync\n"
+					 "1:move $8, %1\n"
+					 "c2 0x80001\n"
+					 "nop\n"
+					 "nop\n"
+					 "nop\n"
+					 "nop\n"
+					 "nop\n"
+					 "mfc2 $8, " STR(MSGRNG_MSG_STATUS_REG) "\n"
+					 "andi $8, $8, 0x6\n"
+					 "beqz $8, 2f\n"
+					 "andi $8, 2\n"
+					 "bnez $8, 1b\n"
+					 "2:move %0, $8\n" ".set pop\n":"=r"(ret)
+					 :"r"((1 << 16) | (code << 8) | stid)
+					 :"$8"
+					);
+	return ret;
+}
+
+static inline int add_meminfo_to_queue(secop_queue_pt q, meminfo_pt mem)
+{
+	unsigned long flags = 0;
+	if (q->response_type == SECOP_Q) {
+		spin_lock_irqsave(&q->q.lock, flags);
+
+		if (q->q.max_length != -1 && q->q.length >= q->q.max_length) {
+			spin_unlock_irqrestore(&q->q.lock, flags);
+			return -EAGAIN;
+		}
+
+		q->q.length++;
+#ifdef SAE_STATS
+		if (q->q.length > q->q.stats_max_length) {
+			q->q.stats_max_length = q->q.length;
+		}
+#endif /* SAE_STATS */
+		mem->async_next = &q->q.head;
+		q->q.tail->async_next = mem;
+		q->q.tail = mem;
+
+#ifdef DEBUG_QUEUE
+		printk("%s:%d q=%p q->head=%p q->length=%d q->tail=%p "
+			   "h->next=%p t->next=%p\n", __FILE__, __LINE__, q,
+			   &q->q.head, q->q.length, q->q.tail, q->q.head.async_next,
+			   q->q.tail->async_next);
+#endif /* DEBUG_QUEUE */
+
+		spin_unlock_irqrestore(&q->q.lock, flags);
+	}
+	else {
+		q->cb.cbfunc(mem->result, mem->return_value);
+	}
+
+	return 0;
+}
+
+static inline meminfo_pt remove_meminfo_from_queue(secop_queue_pt q)
+{
+	meminfo_pt ret = NULL;
+	unsigned long flags;
+
+	if (q->response_type == SECOP_Q) {
+		spin_lock_irqsave(&q->q.lock, flags);
+
+		if (q->q.head.async_next != &q->q.head) {
+			ret = q->q.head.async_next;
+			q->q.length--;
+			q->q.head.async_next = ret->async_next;
+
+			if (ret->async_next == &q->q.head) {
+				q->q.tail = &q->q.head;
+			}
+			ret->async_next = NULL;
+		}
+
+		spin_unlock_irqrestore(&q->q.lock, flags);
+	}
+	return ret;
+}
+
+#define ALL_SEC_STN 120
+#define PK_STN 124
+struct
+{
+	wait_queue_head_t *wq;
+	int stid;
+} op_data[OP_ALL] = {
+	{0, 0},
+	{&dev_info.crypto_queue, ALL_SEC_STN},
+	{&dev_info.pkop_queue, PK_STN}, 
+	{&dev_info.pkop_queue, PK_STN}
+};
+
+struct page *rmisec_vma_nopage(struct vm_area_struct *vma,
+							   unsigned long address, int *type);
+
+void rmisec_vma_open(struct vm_area_struct *vma);
+void rmisec_vma_close(struct vm_area_struct *vma);
+void write_magic(meminfo_pt mem, char __user * buf);
+
+struct vm_operations_struct vmops = {
+	.open = rmisec_vma_open,
+	.close = rmisec_vma_close,
+};
+
+#define MEMINFO_MATCHED_PTR(m, ptr) ((m)->ptr == ptr)
+#define MEMINFO_MATCHED_VMA(m, vma) ((m)->vma == vma)
+
+/*
+ * Ops slot functions
+ */
+static int inline find_free_crypto_slot(device_info_pt dinfo)
+{
+	unsigned int start = dinfo->bitmap_start % MAX_CRYPTO_OPS_INDEX, i, j;
+	uint32_t *ptr = &dinfo->crypto_ops_bitmap[0];
+
+	i = start;
+	do {
+		j = find_32bit_1st_zero_bit(ptr[i]);
+		if (j < 32) {
+			ptr[i] |= BITMAP_ON_MASK(j);
+			dinfo->bitmap_start = i;
+			atomic_inc(&dinfo->crypto_used_slots);
+			return ((i << 5) + j);
+		}
+		i = ((i + 1) % MAX_CRYPTO_OPS_INDEX);
+	} while (i != start);
+
+	return -1;
+}
+
+static int inline alloc_crypto_op_slot(device_info_pt dinfo, meminfo_pt mem)
+{
+	unsigned long flags;
+	int i;
+	spin_lock_irqsave(&dinfo->crypto_lock, flags);
+	i = find_free_crypto_slot(dinfo);
+	spin_unlock_irqrestore(&dinfo->crypto_lock, flags);
+	if (i > -1) {
+		dinfo->crypto_ops_slot[i] = mem;
+#ifdef SAE_STATS
+		if (dinfo->max_crypto_used_slots < dinfo->crypto_used_slots.counter) {
+			dinfo->max_crypto_used_slots = dinfo->crypto_used_slots.counter;
+		}
+#endif /* SAE_STATS */
+	}
+	return i;
+}
+
+static int inline alloc_pk_ops_slot(device_info_pt dinfo, meminfo_pt mem)
+{
+	int j;
+	unsigned long flags;
+	spin_lock_irqsave(&dinfo->pkops_lock, flags);
+	j = find_32bit_1st_zero_bit(dinfo->pk_ops_bitmap);
+
+	if (j < 32) {
+		dinfo->pk_ops_bitmap |= BITMAP_ON_MASK(j);
+	}
+	spin_unlock_irqrestore(&dinfo->pkops_lock, flags);
+
+	if (j < 32) {
+		j = j - PK_BITMAP_OFFSET;
+		dinfo->pk_ops_slot[j] = mem;
+		/* for PK Ops bit 3 needs to be set to 1 */
+		j |= 0x8;
+		ldadd_wu_no_read(1, &dinfo->pk_used_slots);
+#ifdef SAE_STATS
+		if (dinfo->max_pk_used_slots < dinfo->pk_used_slots) {
+			dinfo->max_pk_used_slots = dinfo->pk_used_slots;
+		}
+#endif /* SAE_STATS */
+	}
+	else {
+		j = -1;
+	}
+	return j;
+}
+
+static int inline alloc_op_slot(device_info_pt dinfo, meminfo_pt mem)
+{
+	if (mem->op_type == RMI_CRYPTO_OP) {
+		return alloc_crypto_op_slot(dinfo, mem);
+	}
+	else if (mem->op_type > RMI_CRYPTO_OP && mem->op_type < OP_ALL) {
+		return alloc_pk_ops_slot(dinfo, mem);
+	}
+	else {
+		printk("%s:%d Unknown op_type=%d\n", __FUNCTION__, __LINE__,
+			   mem->op_type);
+	}
+	return -1;
+}
+
+static void inline
+clear_op_slot(device_info_pt dinfo, OpType_t op_type, int cs)
+{
+	unsigned long flags;
+
+	if (op_type == RMI_CRYPTO_OP) {
+		spin_lock_irqsave(&dinfo->crypto_lock, flags);
+		dinfo->crypto_ops_bitmap[CRYPTO_BITMAP_INDEX(cs)] &=
+			BITMAP_OFF_MASK(cs);
+		atomic_dec(&dinfo->crypto_used_slots);
+		spin_unlock_irqrestore(&dinfo->crypto_lock, flags);
+	}
+	else if (op_type > RMI_CRYPTO_OP && op_type < OP_ALL) {
+		spin_lock_irqsave(&dinfo->pkops_lock, flags);
+		dinfo->pk_ops_bitmap &= BITMAP_OFF_MASK(cs + PK_BITMAP_OFFSET);
+		ldadd_w_no_read(-1, &dinfo->pk_used_slots);
+		spin_unlock_irqrestore(&dinfo->pkops_lock, flags);
+	}
+	else {
+		printk("%s:%d Unknown op_type=%d crypto=%d cs=%d\n", __FUNCTION__,
+			   __LINE__, op_type, RMI_CRYPTO_OP, cs);
+	}
+	return;
+}
+
+/*
+ * Proc memlist functions
+ */
+static void inline
+free_proc_memlist(device_info_pt dinfo, proc_memlist_pt proc_info)
+{
+	meminfo_pt mem;
+	memlist_pt tmp, m;
+	int i = 0;
+
+	if (proc_info == NULL) {
+		printk(KERN_ALERT "%s:%d Invalid proc_memlist passed for "
+			   "freeing.\n", __FUNCTION__, __LINE__);
+		return;
+	}
+
+	list_for_each_safe(m, tmp, &proc_info->mem) {
+		mem = (meminfo_pt) m;
+		if (mem->owner != current->tgid) {
+			printk(KERN_ALERT "%s:%d Memory attempted to be freed by "
+				   "non-owner. owner=%d tgid=%d\n", __FUNCTION__, __LINE__,
+				   mem->owner, current->tgid);
+			return;
+		}
+		/*
+		 * Waiting for existing operation to complete.
+		 */
+		while (IS_IN_PROGRESS(mem)) {
+			i = 0;
+			while (IS_IN_PROGRESS(mem) && i < 100000)
+				++i;
+			if (IS_IN_PROGRESS(mem)) {
+				printk(KERN_NOTICE "%s:%d Waiting for meminfo "
+					   "in_progress state to change mem=%p\n",
+					   __FUNCTION__, __LINE__, mem);
+			}
+		}
+		free_meminfo(mem);
+	}
+
+	INIT_LIST_HEAD(&proc_info->mem);
+
+	kfree(proc_info);
+	return;
+}
+
+static proc_memlist_pt inline find_proc_memlist(device_info_pt dev)
+{
+	proc_memlist_pt proc_info = (proc_memlist_pt) dev->pmem_list.next;
+	while (proc_info != (proc_memlist_pt) & dev->pmem_list) {
+		if (proc_info->tgid == current->tgid) {
+			return proc_info;
+		}
+		proc_info = (proc_memlist_pt) proc_info->elem.next;
+	}
+	return NULL;
+}
+
+/*
+ * Meminfo functions
+ */
+static inline meminfo_pt
+find_meminfo_for_virt_addr(proc_memlist_pt proc_info,
+						   unsigned long start_addr)
+{
+	memlist_pt tmp;
+	meminfo_pt mem;
+	list_for_each(tmp, &proc_info->mem) {
+		mem = (meminfo_pt) tmp;
+		if (mem->owner == current->tgid) {
+			if (mem->vma->vm_start == start_addr) {
+				return mem;
+			}
+		}
+		else {
+			printk(KERN_ALERT "%s:%d Memory attempted to be freed by "
+				   "non-owner. owner=%d tgid=%d\n", __FUNCTION__, __LINE__,
+				   mem->owner, current->tgid);
+		}
+	}
+	return 0;
+}
+
+void free_meminfo(meminfo_pt mem)
+{
+	if (!mem)
+		return;
+	mem->magic = 0xBADBADBADBADBADAULL;
+#ifdef SAE_STATS
+#ifdef SYSTEM_CALL_STATS
+	dev_info.mmapfree[hard_smp_processor_id()]++;
+#endif /* SYSTEM_CALL_STATS */
+#endif /* SAE_STATS */
+	if (mem->ptr && mem->order > -1) {
+		if (mem->ctx == PROCESS_CTX) {
+			__free_pages((struct page *) mem->ptr, mem->order);
+		}
+		else {
+			free_pages((unsigned long) mem->ptr, mem->order);
+		}
+	}
+	mem->memlist.next = mem->memlist.prev = NULL;
+	mem->ptr = NULL;
+	mem->proc = NULL;
+	mem->async_next = NULL;
+	mem->owner = 0;
+	mem->order = -1;
+	kfree(mem);
+	return;
+}
+
+static void inline insert_meminfo(proc_memlist_pt proc_info, meminfo_pt mem)
+{
+	list_add_tail((memlist_pt) mem, &proc_info->mem);
+	return;
+}
+
+static void inline
+free_meminfo_for_proc(proc_memlist_pt proc_info, meminfo_pt mem)
+{
+	if (mem->owner == current->tgid) {
+		list_del((memlist_pt) mem);
+		free_meminfo(mem);
+	}
+	else {
+		printk(KERN_ALERT "%s:%d Memory attempted to be freed by "
+			   "non-owner. owner=%d tgid=%d\n", __FUNCTION__, __LINE__,
+			   mem->owner, current->tgid);
+	}
+	return;
+}
+
+void rmisec_vma_open(struct vm_area_struct *vma)
+{
+#ifdef DEBUG_2
+	printk(KERN_NOTICE "%s:%d\n", __FUNCTION__, __LINE__);
+#endif /* DEBUG */
+	atomic_inc(&vma_count);
+	return;
+}
+
+static meminfo_pt inline
+alloc_meminfo(proc_memlist_pt proc_info, CALL_CTX c_ctx,
+			  struct vm_area_struct *vma, int korder)
+{
+	unsigned long size;
+	unsigned int nrpages, order;
+	void *page_or_addr;
+	gfp_t gfp_flags = GFP_KERNEL;
+	int in_asi = (in_atomic() || in_softirq() || in_interrupt());
+
+	meminfo_pt ret;
+
+	if (c_ctx == PROCESS_CTX) {
+		/* find required size */
+		size = vma->vm_end - vma->vm_start;
+
+		/* find next higher order of 2 */
+		nrpages = CEIL(size, PAGE_SHIFT);
+
+		order = (31 - find_32bit_1st_one_bit(nrpages));
+
+		order += HAS_REMINDER(nrpages, order);
+		if (order) {
+			page_or_addr = alloc_pages(GFP_HIGHUSER | __GFP_COMP, order);
+		}
+		else {
+			page_or_addr = alloc_pages(GFP_HIGHUSER, order);
+		}
+		if (!page_or_addr) {
+			printk("%s:%d No memory allocated to kernel %p\n", __FUNCTION__,
+				   __LINE__, page_or_addr);
+		}
+	}
+	else {
+		if (in_asi) {
+			gfp_flags = GFP_ATOMIC;
+		}
+		order = korder;
+		if (order) {
+			page_or_addr = (void *) __get_free_pages(gfp_flags | __GFP_COMP,
+													 order);
+		}
+		else {
+			page_or_addr = (void *) __get_free_page(gfp_flags);
+		}
+	}
+
+	if (page_or_addr != NULL) {
+		ret = (meminfo_pt) kmalloc(sizeof(meminfo_t), gfp_flags);
+		if (ret == NULL) {
+			if (c_ctx == PROCESS_CTX) {
+				__free_pages((struct page *) page_or_addr, order);
+			}
+			else {
+				free_pages((unsigned long) page_or_addr, order);
+			}
+			printk(KERN_ALERT "%s:%d Error allocating meminfo "
+				   "structure.\n", __FUNCTION__, __LINE__);
+			return NULL;
+		}
+	}
+	else {
+		printk(KERN_ALERT "%s:%d Error allocating pages "
+			   "order=%d\n", __FUNCTION__, __LINE__, order);
+		return NULL;
+	}
+
+	memset(ret, 0, sizeof(meminfo_t));
+	ret->magic = DRIVER_MAGIC;
+	ret->order = order;
+	ret->ptr = page_or_addr;
+	ret->ctx = c_ctx;
+	ret->vma = vma;
+	ret->memlist.next = ret->memlist.prev = NULL;
+	ret->async_next = NULL;
+	ret->in_progress = NOT_IN_PROGRESS;
+	init_waitqueue_head(&ret->wq);
+
+	if (c_ctx == PROCESS_CTX) {
+		ret->return_queue = &proc_info->async_queue;
+		ret->return_value = vma->vm_start;
+		ret->owner = current->tgid;
+		ret->proc = proc_info;
+		vma->vm_ops = &vmops;
+		vma->vm_private_data = ret;
+		vma->vm_flags |= VM_DONTCOPY;
+		rmisec_vma_open(vma);
+	}
+
+#ifdef DEBUG_MEMINFO
+	printk(KERN_NOTICE "%s:%d mem=%p order=%d page=%p\n",
+		   __FUNCTION__, __LINE__, ret, ret->order, ret->ptr);
+#endif /* DEBUG_MEMINFO */
+
+	return ret;
+}
+
+meminfo_pt alloc_meminfo_kernel_ctx(int order)
+{
+	meminfo_pt ret = alloc_meminfo(NULL, KERNEL_CTX, NULL, order);
+	if (ret) {
+		write_magic(ret, NULL);
+	}
+	return ret;
+}
+
+static meminfo_pt inline
+alloc_meminfo_process_ctx(proc_memlist_pt proc_info,
+						  struct vm_area_struct *vma)
+{
+	return alloc_meminfo(proc_info, PROCESS_CTX, vma, 0);
+}
+
+void rmisec_vma_close(struct vm_area_struct *vma)
+{
+	meminfo_pt mem = (meminfo_pt) vma->vm_private_data;
+	proc_memlist_pt proc_info;
+	int i;
+
+#ifdef DEBUG_2
+	printk(KERN_NOTICE "%s:%d\n", __FUNCTION__, __LINE__);
+#endif /* DEBUG */
+
+	if (mem != NULL && mem->magic == DRIVER_MAGIC &&
+		mem->owner == current->tgid && mem->ptr != NULL && mem->order > -1) {
+		proc_info = mem->proc;
+		mem->proc = NULL;
+		if (proc_info && proc_info->tgid == current->tgid) {
+			do {
+				i = 0;
+				while (IS_IN_PROGRESS(mem) && i < 100000)
+					++i;
+				if (IS_IN_PROGRESS(mem)) {
+					printk(KERN_NOTICE "%s:%d Waiting for meminfo "
+						   "in_progress state to change mem=%p\n",
+						   __FUNCTION__, __LINE__, mem);
+				}
+			} while (IS_IN_PROGRESS(mem));
+			spin_lock_bh(&dev_info.mem_lock);
+			free_meminfo_for_proc(proc_info, mem);
+			spin_unlock_bh(&dev_info.mem_lock);
+
+			vma->vm_ops = NULL;
+			vma->vm_private_data = NULL;
+			atomic_dec(&vma_count);
+		}
+	}
+	return;
+}
+
+void insert_proc_memlist(device_info_pt dinfo, proc_memlist_pt proc_info)
+{
+	proc_info->elem.prev = dinfo->pmem_list.prev;
+	proc_info->elem.next = &dinfo->pmem_list;
+
+	dinfo->pmem_list.prev->next = (struct list_head *) proc_info;
+	dinfo->pmem_list.prev = (struct list_head *) proc_info;
+}
+
+int rmisec_open(struct inode *iptr, struct file *fptr)
+{
+#ifdef DEBUG_SYSTEM_CALL
+	printk(KERN_NOTICE "%s:%d pid=%d tgid=%d ftpr=%p\n",
+		   __FUNCTION__, __LINE__, current->pid, current->tgid, fptr);
+#endif /* DEBUG_SYSTEM_CALL */
+	fptr->private_data = (void *) &dev_info;
+	return 0;
+}
+
+int rmisec_flush(struct file *fptr, fl_owner_t id)
+{
+#ifdef DEBUG_SYSTEM_CALL
+	printk(KERN_NOTICE "%s:%d pid=%d tgid=%d\n", __FUNCTION__, __LINE__,
+		   current->pid, current->tgid);
+#endif /* DEBUG_SYSTEM_CALL */
+	return 0;
+}
+
+int rmisec_release(struct inode *iptr, struct file *fptr)
+{
+	proc_memlist_pt proc_info;
+	device_info_pt dinfo = (device_info_pt) fptr->private_data;
+	if (current->pid != current->tgid) {
+		printk(KERN_DEBUG "%s:%d thread exit pid=%d tgid=%d\n",
+			   __FUNCTION__, __LINE__, current->pid, current->tgid);
+		return 0;
+	}
+
+	if (dinfo) {
+		fptr->private_data = NULL;
+		spin_lock_bh(&dinfo->mem_lock);
+		proc_info = find_proc_memlist(dinfo);
+		if (proc_info) {
+			/* dequeue proc_info */
+			proc_info->elem.prev->next = proc_info->elem.next;
+			proc_info->elem.next->prev = proc_info->elem.prev;
+			proc_info->elem.prev = proc_info->elem.next = NULL;
+		}
+		spin_unlock_bh(&dinfo->mem_lock);
+		if (proc_info)
+			free_proc_memlist(dinfo, proc_info);
+	}
+
+#ifdef DEBUG_SYSTEM_CALL
+	printk(KERN_NOTICE "%s:%d pid=%d tgid=%d\n", __FUNCTION__, __LINE__,
+		   current->pid, current->tgid);
+#endif /* DEBUG_SYSTEM_CALL */
+	return 0;
+}
+
+void write_magic(meminfo_pt mem, char __user * buf)
+{
+	uint64_t ptr2 = 0;
+	control_struct_t ctrl;
+	control_struct_t *ptr;
+
+	if (mem->ctx == PROCESS_CTX) {
+		ptr = &ctrl;
+	}
+	else {
+		ptr = mem->ptr;
+	}
+
+	memset(ptr, 0, sizeof(control_struct_t));
+	if (ptr != NULL) {
+		ptr->version = dev_info.version;
+		ptr->owner = current->tgid;
+		if (mem->ctx == PROCESS_CTX && ptr->owner == 0) {
+			printk("%s:%d tgid=0x%x\n", __FUNCTION__, __LINE__,
+				   current->tgid);
+/* 		} else { */
+/* 			printk("%s:%d tgid=0x%x\n", __FUNCTION__, __LINE__, */
+/* 			       current->tgid); */
+		}
+		ptr->magic = DRIVER_MAGIC;
+		if (mem->ctx == PROCESS_CTX) {
+			ptr2 = page_to_pfn((struct page *) (mem->ptr));
+			ptr2 <<= PAGE_SHIFT;
+		}
+		else {
+			ptr2 = virt_to_phys(mem->ptr);
+		}
+		ptr->phy_addr = ptr2;
+		ptr->mem_addr = (uint64_t) ((unsigned long) mem);
+		ptr->msg0 = ptr->msg1 = 0ULL;
+	}
+	else {
+		printk(KERN_ALERT "%s:%d mem=%p ctx=%d ptr=NULL\n",
+			   __FUNCTION__, __LINE__, mem, mem->ctx);
+		return;
+	}
+
+	ptr = NULL;
+	if (mem->ctx == PROCESS_CTX) {
+		copy_to_user(buf, &ctrl, sizeof(control_struct_t));
+	}
+
+#ifdef DEBUG_MEMINFO
+	printk(KERN_NOTICE "%s:%d version=%x mem=%p ctx=%d buf=%p mptr=%p "
+		   "ptr2=0x%" LLX_FMT "\n",
+		   __FUNCTION__, __LINE__, dev_info.version, mem, mem ? mem->ctx : -1,
+		   buf, mem->ptr, ptr2);
+#endif /* DEBUG_MEMINFO */
+	return;
+}
+
+
+int rmisec_mmap(struct file *fptr, struct vm_area_struct *vma)
+{
+	proc_memlist_pt proc_info;
+	meminfo_pt mem;
+	device_info_pt dinfo = (device_info_pt) fptr->private_data;
+	int ret = 0;
+	unsigned long pfn;
+
+	if (!dinfo) {
+		printk(KERN_NOTICE "%s:%d pid=%d tgid=%d ftpr=%p\n",
+			   __FUNCTION__, __LINE__, current->pid, current->tgid, fptr);
+		return -EINVAL;
+	}
+#ifdef DEBUG_SYSTEM_CALL
+	printk(KERN_NOTICE "%s:%d pid=%d tgid=%d ftpr=%p\n",
+		   __FUNCTION__, __LINE__, current->pid, current->tgid, fptr);
+#endif /* DEBUG_SYSTEM_CALL */
+
+	spin_lock_bh(&dinfo->mem_lock);
+
+	proc_info = find_proc_memlist(dinfo);
+#ifdef SAE_STATS
+#ifdef SYSTEM_CALL_STATS
+	dinfo->mmapcnt[hard_smp_processor_id()]++;
+#endif /* SYSTEM_CALL */
+#endif /* SAE_STATS */
+	spin_unlock_bh(&dev_info.mem_lock);
+
+	if (proc_info == NULL) {
+		proc_info = (proc_memlist_pt) kmalloc(sizeof(proc_memlist_t),
+											  GFP_KERNEL);
+		if (proc_info != NULL) {
+			INIT_SECOP_QUEUE(&proc_info->async_queue, -1);
+			proc_info->tgid = current->tgid;
+			INIT_LIST_HEAD(&proc_info->mem);
+			insert_proc_memlist(dinfo, proc_info);
+		}
+		else {
+			printk("%s:%d Error allocating proc_memlist.\n",
+				   __FUNCTION__, __LINE__);
+			ret = -ENOMEM;
+			goto bail;
+		}
+	}
+
+	mem = alloc_meminfo_process_ctx(proc_info, vma);
+	if (mem == NULL) {
+		printk("%s:%d Error allocating meminfo.\n", __FUNCTION__, __LINE__);
+		ret = -ENOMEM;
+		goto bail;
+	}
+
+	spin_lock_bh(&dinfo->mem_lock);
+	insert_meminfo(proc_info, mem);
+#if 1
+	pfn = page_to_pfn((struct page *) mem->ptr);
+	if ((ret = remap_pfn_range(vma, vma->vm_start,
+							   pfn, vma->vm_end - vma->vm_start,
+							   vma->vm_page_prot)) < 0) {
+		printk("%s:%d ret=%d\n", __FUNCTION__, __LINE__, ret);
+	}
+#endif
+	spin_unlock_bh(&dinfo->mem_lock);
+
+
+  bail:
+	return ret;
+}
+
+/*
+ * Send the operation pointed by meminfo to the crypto engine.
+ * Params:
+ * mem - Memory structure where the operation exists
+ * allow_sync - If asynchronous dispatch of this operation is allowed
+ * Returns:
+ * EAGAIN         : if the operation could not be sent to security engine
+ *                  due to credit failure
+ * RMISAE_SUCCESS : If the operation succeded
+ */
+
+int send_to_sae(meminfo_pt mem, int allow_async)
+{
+	device_info_pt dinfo = &dev_info;
+	int ret = RMISAE_SUCCESS;
+	int cs, stid;
+	unsigned long flags;
+	OpType_t op_type = mem->op_type;
+	struct msgrng_msg msg = { 0ULL };
+	unsigned int t, hcpuid;
+	int in_asi = (in_atomic() || in_softirq() || in_interrupt());
+
+	if ((op_type != RMI_CRYPTO_OP) && (op_type != RMI_RSA_OP) &&
+		(op_type != RMI_ECC_OP)) {
+		printk(KERN_ALERT "%s:%d Invalid op_type=%d mem=%p page=%p\n",
+			   __FUNCTION__, __LINE__, op_type, mem, mem->ptr);
+		return -EINVAL;
+	}
+
+	do {
+		cs = alloc_op_slot(dinfo, mem);
+		if (cs < 0) {
+			if (!in_asi && waitqueue_active(op_data[op_type].wq)) {
+				init_waitqueue_entry(&mem->wqe, current);
+				add_wait_queue_exclusive(&mem->wq, &mem->wqe);
+				schedule_timeout(1);
+				remove_wait_queue(op_data[op_type].wq, &mem->wqe);
+			}
+		}
+	} while (cs < 0);
+
+	/* set response bucket and callslot.  That's the only
+	 * information userspace driver can't set.
+	 */
+	msg.msg0 = mem->msg0;
+	msg.msg1 = mem->msg1;
+
+	if (op_type == RMI_CRYPTO_OP) {
+		SET_CTRL_SCRATCH_VALUE(msg.msg0, cs);
+		SET_DATA_SCRATCH_VALUE(msg.msg1, cs);
+	}
+	else if (op_type == RMI_RSA_OP || op_type == RMI_ECC_OP) {
+		/* bit 3 needs to be set to 1 for public key ops */
+		SET_CTRL_PK_SCRATCH_VALUE(msg.msg0, cs);
+		SET_DATA_PK_SCRATCH_VALUE(msg.msg1, cs);
+	}
+
+	stid = op_data[op_type].stid;
+
+	if (is_xls() && op_type != RMI_CRYPTO_OP) {
+		stid = MSGRNG_STNID_XLS_PK0;
+	}
+
+
+#ifdef DEBUG_MSGRNG
+	printk(KERN_NOTICE "%s:%d stid=%d ctrl_msg=0x%016" LLX_FMT
+		   " data_msg=0x%016" LLX_FMT " mem=%p cs=0x%x op_type=%d\n",
+		   __FUNCTION__, __LINE__, stid, msg.msg0, msg.msg1, mem,
+		   cs, op_type);
+#endif /* DEBUG_MSGRNG */
+
+	mem->resp0 = mem->resp1 = 0ULL;
+	mem->in_progress = IN_PROGRESS;
+
+	if (!in_asi) {
+		init_waitqueue_entry(&mem->wqe, current);
+		add_wait_queue(&mem->wq, &mem->wqe);
+	}
+
+	do {
+		t = 0;
+		msgrng_access_enable(flags);
+		hcpuid = hard_smp_processor_id();
+		remote_napi_poll_upper();
+		SET_FREEBACK_STN(msg.msg1, (cpu_to_frstid[hcpuid]));
+
+		ret = message_send_fast_2(0, stid, msg.msg0, msg.msg1);
+		if (ret != 0) {
+#ifdef DEBUG
+			printk(KERN_WARNING "%s:%d Error returned=%d cs=%d op_type=%d\n",
+				   __FUNCTION__, __LINE__, ret, cs, op_type);
+#endif /* DEBUG */
+#ifdef SAE_STATS
+			wait_count[hcpuid]++;
+#endif /* SAE_STATS */
+			if (allow_async && IS_ASYNC_OP(mem)) {
+				msgrng_access_disable(flags);
+				clear_op_slot(dinfo, op_type, cs);
+				ret = -EAGAIN;
+				mem->in_progress = NOT_IN_PROGRESS;
+				goto out;
+			}
+			else {
+				if (++t == 100000) {
+					printk(KERN_WARNING
+						   "%s:%d Waiting to send message to SAE "
+						   "op_type=%d stid=%x ret=0x%x\n",
+						   __FUNCTION__, __LINE__, op_type, stid, ret);
+					t = 0;
+				}
+			}
+		}
+		msgrng_access_disable(flags);
+	} while (ret);
+#ifdef SAE_STATS
+	msgs_sent[hcpuid]++;
+#endif
+	t = 0;
+
+	if (!IS_ASYNC_OP(mem)) {
+		if (op_type == RMI_CRYPTO_OP) {
+			while (IS_IN_PROGRESS(mem)) {
+				if (dinfo->crypto_used_slots.counter > 60 && !in_asi) {
+					schedule();
+				}
+				msgrng_access_enable(flags);
+				remote_napi_poll_upper();
+				msgrng_access_disable(flags);
+				if (++t == 10000000) {
+					printk("Stuck here\n");
+					t = 0;
+				}
+			}
+		}
+		else {
+			while (IS_IN_PROGRESS(mem)) {
+				if (dinfo->pk_used_slots > 4 && !in_asi) {
+					schedule();
+				}
+				if (++t == 10000000) {
+					printk("Stuck here\n");
+					t = 0;
+				}
+				msgrng_access_enable(flags);
+				remote_napi_poll_upper();
+				msgrng_access_disable(flags);
+			}
+
+		}
+		ret = mem->result;
+	}
+
+  out:
+	if (!in_asi) {
+		remove_wait_queue(&mem->wq, &mem->wqe);
+	}
+	return ret;
+}
+
+static long
+rmisec_ioctl(struct file *fptr, unsigned int type, unsigned long val)
+{
+	char __user *buf = (char __user *) val;
+	device_info_pt dinfo = (device_info_pt) fptr->private_data;
+	proc_memlist_pt proc_info;
+	meminfo_pt mem = NULL;
+	int ret = 0;
+
+	if (type == RMISEC_IOCTL_GET_MEMINFO) {
+		spin_lock_bh(&dinfo->mem_lock);
+		proc_info = find_proc_memlist(dinfo);
+
+		mem = find_meminfo_for_virt_addr(proc_info, val);
+		if (mem) {
+			write_magic(mem, buf);
+		}
+		else {
+			ret = -2;
+		}
+		spin_unlock_bh(&dinfo->mem_lock);
+	}
+	else {
+		ret = -1;
+	}
+
+#ifdef DEBUG
+	printk("%s:%d type=%d val=%lx ret=%d\n", __FUNCTION__, __LINE__, type,
+		   val, ret);
+#endif /* DEBUG */
+	return ret;
+}
+
+void xlr_inc_enc_stat(int cipher_algo, int cipher_mode, int data_size)
+{
+	int cpu = hard_smp_processor_id();
+
+	if (cipher_algo != CIPHER_BYPASS) {
+		cipher_cnt[cpu][cipher_algo][cipher_mode]++;
+		cipher_data_cnt[cpu][cipher_algo][cipher_mode] += data_size;
+	}
+}
+
+void xlr_inc_auth_stat(int hash_algo, int data_size)
+{
+	int cpu = hard_smp_processor_id();
+
+	if (hash_algo != HASH_BYPASS) {
+		hash_cnt[cpu][hash_algo]++;
+		hash_data_cnt[cpu][hash_algo] += data_size;
+	}
+}
+
+void add_stats_count(control_struct_pt ctrl, int cpu)
+{
+	if (ctrl->op_type == RMI_CRYPTO_OP) {
+		if (ctrl->cipher_algo != CIPHER_BYPASS) {
+			cipher_cnt[cpu][ctrl->cipher_algo][ctrl->cipher_mode]++;
+			cipher_data_cnt[cpu][ctrl->cipher_algo][ctrl->cipher_mode] +=
+				ctrl->data_size;
+		}
+
+		if (ctrl->hash_algo != HASH_BYPASS) {
+			hash_cnt[cpu][ctrl->hash_algo]++;
+			hash_data_cnt[cpu][ctrl->hash_algo] += ctrl->data_size;
+		}
+	}
+
+	if (ctrl->op_type == RMI_RSA_OP) {
+		if (ctrl->rsa_algo == BIT_512 || ctrl->rsa_algo == BIT_1024) {
+			mod_exp_cnt[cpu][ctrl->rsa_algo - 1]++;
+		}
+	}
+
+	if (ctrl->op_type == RMI_ECC_OP) {
+		if (ctrl->ecc_degree < RMI_ECC_PRIME_CURVE_MAX) {
+			ecc_prime_cnt[cpu][ctrl->ecc_degree][ctrl->ecc_algo]++;
+		}
+		else {
+			ecc_binary_cnt[cpu][ctrl->ecc_degree -
+								RMI_ECC_BINARY_163][ctrl->ecc_algo]++;
+		}
+	}
+
+	return;
+}
+
+static ssize_t
+rmisec_read(struct file *fptr, char __user * cptr, size_t size, loff_t * off)
+{
+	uint64_t magic;
+	pid_t owner_pid;
+	int ret = 0;
+	meminfo_pt mem = NULL;
+	device_info_pt dinfo = (device_info_pt) fptr->private_data;
+	control_struct_t ctrl;
+	int async = 0;
+
+	if (size != sizeof(control_struct_t)) {
+		printk(KERN_ALERT "%s:%d Incorrect operation attempted.\n",
+			   __FUNCTION__, __LINE__);
+		return -EFAULT;
+	}
+
+	copy_from_user(&ctrl, cptr, sizeof(control_struct_t));
+
+	if (ctrl.magic != DRIVER_MAGIC) {
+		printk(KERN_ALERT "%s:%d Invalid call to write system call id=%"
+			   LLX_FMT "\n", __FUNCTION__, __LINE__, ctrl.magic);
+		return -EINVAL;
+	}
+
+
+	mem = (meminfo_pt) ((unsigned long) ctrl.mem_addr);
+
+#ifdef DEBUG
+	printk(KERN_NOTICE "%s:%d tgid=0x%x pid=0x%x ptr=%p size=%u magic=%llx "
+		   "owner=0x%x mem=%p\n",
+		   __FUNCTION__, __LINE__, current->tgid, current->pid, cptr,
+		   (unsigned int) size, ctrl.magic, ctrl.owner, mem);
+#endif /* DEBUG */
+
+	spin_lock_bh(&dinfo->mem_lock);
+
+	if (mem == NULL || mem->ptr == NULL || mem->magic != DRIVER_MAGIC) {
+		printk(KERN_ALERT
+			   "%s:%d Unknown operation structure mem=%p magic=%llx\n",
+			   __FUNCTION__, __LINE__, mem, mem ? mem->magic : 0ULL);
+
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	if (mem->owner != current->tgid) {
+		printk(KERN_ALERT "%s:%d The memory region was allocated by "
+			   "another process pid=%d and now being accessed by process %d",
+			   __FUNCTION__, __LINE__, mem->owner, current->tgid);
+		ret = -EFAULT;
+		goto bail;
+	}
+
+	magic = ctrl.magic;
+	mem->msg0 = ctrl.msg0;
+	mem->msg1 = ctrl.msg1;
+	if (async) {
+		mem->op_flags = OP_NO_WAIT;
+	}
+	mem->result = RMISAE_SUCCESS;
+	mem->op_type = ctrl.op_type;
+	mem->in_progress = IN_PROGRESS;
+	owner_pid = ctrl.owner;
+  bail:
+	spin_unlock_bh(&dinfo->mem_lock);
+	if (ret) {
+		printk("%s:%d Aborting operation due to error=%d\n",
+			   __FUNCTION__, __LINE__, ret);
+		return ret;
+	}
+
+	ret = -1;
+	/* Check magic of the memory passed to kernel */
+	if ((magic != DRIVER_MAGIC) || (current->tgid != owner_pid) ||
+		((mem->op_type != RMI_CRYPTO_OP) &&
+		 (mem->op_type != RMI_RSA_OP) && (mem->op_type != RMI_ECC_OP))) {
+
+		printk(KERN_ALERT "%s:%d magic=%" LLX_FMT
+			   " pid=0x%x owner=0x%x op_type=%x mem=%p page=%p, msg0=%"
+			   LLX_FMT ", msg1=%" LLX_FMT "\n", __FUNCTION__, __LINE__, magic,
+			   current->tgid, owner_pid, mem->op_type, mem, mem->ptr,
+			   mem->msg0, mem->msg1);
+		mem->in_progress = NOT_IN_PROGRESS;
+		return -EFAULT;
+	}
+
+	ret = send_to_sae(mem, async);
+
+#ifdef DEBUG_3
+	copy_from_user(&junk_buf[0], cptr, 4096);
+	print_4k(&junk_buf[0], 0);
+#endif /* DEBUG_2 */
+	if (IS_SUCCESS_SAEOP(ret)) {
+		add_stats_count(&ctrl, hard_smp_processor_id());
+		/* copying response back */
+		ctrl.msg0 = mem->resp0;
+		ctrl.msg1 = mem->resp1;
+		copy_to_user(cptr, &ctrl, sizeof(control_struct_t));
+		ret = mem->result;
+	}
+
+	return ret;
+}
+
+struct file_operations fops = {
+	.owner = THIS_MODULE,
+	.open = rmisec_open,
+	.mmap = rmisec_mmap,
+	.read = rmisec_read,
+	.unlocked_ioctl = rmisec_ioctl,
+	.release = rmisec_release,
+};
+
+static int print_stats_info(device_info_pt dinfo, char *buf, int size)
+{
+	int i, x, t = size, p, q;
+	uint64_t m_sent = 0, r_received = 0, w_count = 0;
+	uint64_t c_cnt[MAX_CIPHER_ALGO][MAX_CIPHER_MODE] = { {0} };
+	uint64_t c_data_cnt[MAX_CIPHER_ALGO][MAX_CIPHER_MODE] = { {0} };
+	uint64_t h_cnt[MAX_HASH_ALGO] = { 0 };
+	uint64_t h_data_cnt[MAX_HASH_ALGO] = { 0 };
+	uint64_t m_exp_cnt[2] = { 0 };
+	uint64_t ec_p_cnt[RMI_ECC_PRIME_CURVE_MAX][RMI_ECC_PRIME_OP_MAX] =
+		{ {0} };
+	uint64_t ec_b_cnt[RMI_ECC_BINARY_CURVE_MAX][RMI_ECC_BINARY_OP_MAX] =
+		{ {0} };
+
+#ifdef SYSTEM_CALL_STATS
+	uint64_t map_cnt = 0, map_free = 0;
+#endif /* SYSTEM_CALL_STATS */
+	x = snprintf(buf, t, "CPU\t\tSent\t\tReceived\n");
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+	for (i = 0; i < NR_CPUS; ++i) {
+		x = snprintf(buf, t, "%d\t\t%" LLU_FMT "\t\t%" LLU_FMT "\n", i,
+					 msgs_sent[i], resp_recieved[i]);
+		t -= x;
+		buf += x;
+		if (t <= 0) {
+			goto end;
+		}
+
+		m_sent += msgs_sent[i];
+		r_received += resp_recieved[i];
+		w_count += wait_count[i];
+		for (p = 1; p < MAX_CIPHER_ALGO; ++p) {
+			for (q = 0; q < MAX_CIPHER_MODE; ++q) {
+				if (valid_cipher_algo_mode_matrix[p][q]) {
+					c_cnt[p][q] += cipher_cnt[i][p][q];
+					c_data_cnt[p][q] += cipher_data_cnt[i][p][q];
+				}
+			}
+		}
+
+		for (p = 1; p < MAX_HASH_ALGO - 2; ++p) {
+			h_cnt[p] += hash_cnt[i][p];
+			h_data_cnt[p] += hash_data_cnt[i][p];
+		}
+
+		if (is_xls()) {
+			for (p = RMI_ECC_PRIME_160; p < RMI_ECC_PRIME_CURVE_MAX; ++p) {
+				for (q = RMI_ECC_PRIME_P_MUL; q < RMI_ECC_PRIME_OP_MAX; ++q) {
+					ec_p_cnt[p][q] += ecc_prime_cnt[i][p][q];
+				}
+			}
+
+			for (p = 0; p < RMI_ECC_BINARY_CURVE_MAX; ++p) {
+				for (q = RMI_ECC_BINARY_P_MUL; q < RMI_ECC_BINARY_OP_MAX; ++q) {
+					ec_b_cnt[p][q] += ecc_binary_cnt[i][p][q];
+				}
+			}
+		}
+#ifdef SYSTEM_CALL_STATS
+		map_cnt += mmapcnt[i];
+		map_free += mmapfree[i];
+		mmapcnt[i] = mmapfree[i] =
+#endif /* SYSTEM_CALL_STATS */
+	}
+
+	x = snprintf(buf, t, "Total msgs\t\t%" LLU_FMT "\t\t%" LLU_FMT "\n",
+				 m_sent, r_received);
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "Cipher Algorithms:\n");
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+	for (p = 1; p < MAX_CIPHER_ALGO; ++p) {
+		for (q = 0; q < MAX_CIPHER_MODE; ++q) {
+			if (valid_cipher_algo_mode_matrix[p][q] && c_cnt[p][q]) {
+				x = snprintf(buf, t,
+							 "%11s-%-4s Count: %16" LLU_FMT
+							 " Size: %16" LLU_FMT "\n",
+							 cipher_str[p], mode_str[q], c_cnt[p][q],
+							 c_data_cnt[p][q]);
+				t -= x;
+				buf += x;
+				if (t <= 0) {
+					goto end;
+				}
+			}
+		}
+	}
+
+	x = snprintf(buf, t, "Hash Algorithms:\n");
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+	for (p = 1; p < MAX_HASH_ALGO - 2; ++p) {
+		if (h_cnt[p]) {
+			x = snprintf(buf, t, "%11s Count: %16" LLU_FMT " Size: %16"
+						 LLU_FMT "\n", hash_str[p], h_cnt[p], h_data_cnt[p]);
+			t -= x;
+			buf += x;
+			if (t <= 0) {
+				goto end;
+			}
+		}
+	}
+
+	x = snprintf(buf, t, "RSA Mod Exp Algorithms:\n");
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+	for (p = BIT_512; p < BIT_SIZE_MAX; ++p) {
+		for (i = 0; i < NR_CPUS; ++i) {
+			m_exp_cnt[p - 1] += mod_exp_cnt[i][p - 1];
+		}
+		if (m_exp_cnt[p - 1]) {
+			x = snprintf(buf, t, "%11s: %11" LLU_FMT "\n",
+						 rsa_mod_str[p - 1], m_exp_cnt[p - 1]);
+			t -= x;
+			buf += x;
+			if (t <= 0) {
+				goto end;
+			}
+		}
+	}
+
+	if (is_xls()) {
+		x = snprintf(buf, t, "ECC Algorithms:\n");
+		t -= x;
+		buf += x;
+		if (t <= 0) {
+			goto end;
+		}
+
+
+		for (p = RMI_ECC_PRIME_160; p < RMI_ECC_PRIME_CURVE_MAX; ++p) {
+			for (q = RMI_ECC_PRIME_P_MUL; q < RMI_ECC_PRIME_OP_MAX; ++q) {
+				if (ec_p_cnt[p][q]) {
+					x = snprintf(buf, t,
+								 "%11s-%-11s: %11" LLU_FMT "\n",
+								 ecc_prime_curve_str[p],
+								 ecc_prime_func_str[q], ec_p_cnt[p][q]);
+					t -= x;
+					buf += x;
+					if (t <= 0) {
+						goto end;
+					}
+				}
+			}
+		}
+
+		for (p = 0; p < RMI_ECC_BINARY_CURVE_MAX; ++p) {
+			for (q = RMI_ECC_BINARY_P_MUL; q < RMI_ECC_BINARY_OP_MAX; ++q) {
+				if (ec_b_cnt[p][q]) {
+					x = snprintf(buf, t,
+								 "%11s-%-11s: %11" LLU_FMT "\n",
+								 ecc_binary_curve_str[p],
+								 ecc_binary_func_str[q], ec_b_cnt[p][q]);
+					t -= x;
+					buf += x;
+					if (t <= 0) {
+						goto end;
+					}
+				}
+			}
+		}
+	}
+
+	x = snprintf(buf, t, "Current Crypto outstanding msg=%u\n",
+				 dinfo->crypto_used_slots.counter);
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "Max Crypto outstanding msg=%u\n",
+				 dinfo->max_crypto_used_slots);
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "Current Pk outstanding msg=%u\n",
+				 dinfo->pk_used_slots);
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "Max Pk outstanding msg=%u\n",
+				 dinfo->max_pk_used_slots);
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "Wait count =%" LLU_FMT "\n", w_count);
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "VMA count =%u\n", vma_count.counter);
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+#ifdef SYSTEM_CALL_STATS
+	x = snprintf(buf, t, "MMap count =%" LLU_FMT "\n", map_cnt);
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+
+	x = snprintf(buf, t, "MMap free =%" LLU_FMT "\n", map_free);
+	t -= x;
+	buf += x;
+	if (t <= 0) {
+		goto end;
+	}
+#endif /* SYSTEM_CALL_STATS */
+  end:
+	return size - t;
+}
+
+#ifdef ENABLE_DEBUG_PROC
+static int print_page_info(device_info_pt dinfo, char *buf, int size)
+{
+	proc_memlist_pt proc_info;
+	memlist_pt m;
+	meminfo_pt mem;
+	int t = size, x;
+
+	if (!spin_trylock_bh(&dinfo->mem_lock)) {
+		return snprintf(buf, t, "Lock not acquired.  Please try later.\n");
+	}
+
+	x = snprintf(buf, t, "Build version: %s\n", versionstr);
+	t -= x;
+	buf += x;
+
+	x = snprintf(buf, t, "pid\torder\tpage addr\t\tpfn\n");
+	t -= x;
+	buf += x;
+
+	proc_info = (proc_memlist_pt) dinfo->pmem_list.next;
+	while (proc_info != (proc_memlist_pt) & dinfo->pmem_list) {
+		list_for_each(m, &proc_info->mem) {
+			mem = (meminfo_pt) m;
+			x = snprintf(buf, t, "%d\t%d\t%p\t\t%lx\n", proc_info->tgid,
+						 mem->order, mem->ptr,
+						 page_to_pfn((struct page *) (mem->ptr)));
+			t -= x;
+			buf += x;
+			if (t <= 0) {
+				break;
+			}
+		}
+		proc_info = (proc_memlist_pt) proc_info->elem.next;
+	}
+
+	spin_unlock_bh(&dinfo->mem_lock);
+	return size - t;
+}
+#endif /* ENABLE_DEBUG_PROC */
+
+static inline
+	meminfo_pt get_meminfo(device_info_pt dinfo, uint64_t msg0, uint64_t msg1)
+{
+#define CRYPTO_SCRATCH_VALUE(x,y)     ((((x) & 0xfULL) << 5) | \
+				       ((y) & 0x1fULL))
+
+#define PK_SCRATCH_VALUE(x,y)         ((((x) & 0x8ULL) >> 1) | \
+				       (((y) >> 3) & 0x3ULL))
+	int cs;
+	meminfo_pt mem = NULL;
+
+	if (msg0 & 0x10) {			/* PK OP Condition */
+		cs = PK_SCRATCH_VALUE(msg0, msg1);
+		mem = dinfo->pk_ops_slot[cs];
+		dinfo->pk_ops_slot[cs] = NULL;
+		clear_op_slot(dinfo, RMI_RSA_OP, cs);
+	}
+	else {						/* Crypto Condition */
+		cs = CRYPTO_SCRATCH_VALUE(msg0, msg1);
+		mem = dinfo->crypto_ops_slot[cs];
+		dinfo->crypto_ops_slot[cs] = NULL;
+		clear_op_slot(dinfo, RMI_CRYPTO_OP, cs);
+	}
+
+	/* Added this to catch a problem observed a few times when
+	 * response comes back, but mem ptr is NULL. */
+	if (mem == NULL) {
+		int i;
+		printk("%s:%d MEMPTR is NULL. OpType=%" LLX_FMT " msg0=%" LLX_FMT
+			   " msg1=%" LLX_FMT " cs=%d mem=%p\n", __FUNCTION__, __LINE__,
+			   (msg0 & 0x10), msg0, msg1, cs, mem);
+		if (msg0 & 0x10) {
+			for (i = 0; i < 8; ++i) {
+				printk("%d=[%p] ", i, dinfo->pk_ops_slot[i]);
+			}
+		}
+		else {
+			for (i = 0; i < 8; ++i) {
+				printk(" %d=[%p] ", i, dinfo->crypto_ops_slot[i]);
+			}
+		}
+		printk("\n");
+	}
+
+	return mem;
+}
+
+void rmisec_msgring_handler(int bucket, int size, int code, int stid,
+							struct msgrng_msg *msg, void *data)
+{
+	device_info_pt dinfo = (device_info_pt) data;
+	volatile meminfo_pt mem;
+	int ret = RMISAE_SUCCESS;
+	control_struct_pt ctrl;
+#ifdef SAE_STATS
+	resp_recieved[hard_smp_processor_id()]++;
+#endif /* SAE_STATS */
+
+#ifdef DEBUG_MSGRNG
+	printk("%s:%d msg0=%016" LLX_FMT " msg1=%016" LLX_FMT "\n", __FUNCTION__,
+		   __LINE__, msg->msg0, msg->msg1);
+#endif
+
+	if (CTRL_HEAD(msg->msg0) != 2ULL ||
+		CTRL_DEST_CTRL(msg->msg0) != 6ULL ||
+		DATA_HEAD(msg->msg1) != 2ULL ||
+		DATA_DEST_CTRL(msg->msg1) != 5ULL ||
+		CTRL_ERROR(msg->msg0) != 0ULL || DATA_ERROR(msg->msg1) != 0ULL) {
+		printk(KERN_ALERT "%s:%d Invalid/Error response from SAE "
+			   "msg0=%016" LLX_FMT " msg1=%016" LLX_FMT " ctrl_head=%"
+			   LLX_FMT " ctrl_error=%" LLX_FMT " ctrl_ctrl=%" LLX_FMT
+			   " data_head=%" LLX_FMT " data_error=%" LLX_FMT
+			   " dest_ctrl=%" LLX_FMT "\n",
+			   __FUNCTION__, __LINE__,
+			   msg->msg0, msg->msg1, CTRL_HEAD(msg->msg0),
+			   CTRL_ERROR(msg->msg0),
+			   CTRL_DEST_CTRL(msg->msg0), DATA_HEAD(msg->msg1),
+			   DATA_ERROR(msg->msg1), DATA_DEST_CTRL(msg->msg1));
+		ret = -CTRL_ERROR(msg->msg0);
+		if (!ret)
+			ret = -DATA_ERROR(msg->msg1);
+	}
+
+	mem = get_meminfo(dinfo, msg->msg0, msg->msg1);
+#ifdef DEBUG_MSGRNG
+	printk(KERN_NOTICE "%s:%d stid=%d code=%d meminfo=%p\n",
+		   __FUNCTION__, __LINE__, stid, code, mem);
+#endif /* DEBUG_MSGRNG */
+
+	if (mem != NULL && mem->magic == DRIVER_MAGIC) {
+		mem->resp0 = msg->msg0;
+		mem->resp1 = msg->msg1;
+
+		if (mem->ctx == PROCESS_CTX) {
+			mem->resp0 = msg->msg0;
+			mem->resp1 = msg->msg1;
+		}
+		else if (mem->ctx == KERNEL_CTX) {
+			ctrl = (control_struct_pt) (mem->ptr);
+			ctrl->msg0 = msg->msg0;
+			ctrl->msg1 = msg->msg1;
+		}
+
+		ctrl = NULL;
+
+		mem->result = ret;
+
+		if (IS_ASYNC_OP(mem)) {
+			add_meminfo_to_queue(mem->return_queue, mem);
+		}
+		else {
+			if (waitqueue_active(&mem->wq)) {
+				wake_up(&mem->wq);
+			}
+
+			if (waitqueue_active(op_data[mem->op_type].wq)) {
+				wake_up_interruptible(op_data[mem->op_type].wq);
+			}
+		}
+
+		mem->in_progress = NOT_IN_PROGRESS;
+		wmb();
+
+#ifdef DEBUG
+	}
+	else {
+		printk(KERN_NOTICE "%s:%d Operation completed but, "
+			   "no meminfo found.\n", __FUNCTION__, __LINE__);
+#endif /* DEBUG */
+	}
+
+	return;
+}
+
+static int
+rmisec_read_stats_proc(char *page, char **start, off_t offset, int count,
+					   int *eof, void *data)
+{
+	device_info_pt dinfo = (device_info_pt) data;
+	int len = 0;
+	if (offset == 0) {
+		len = print_stats_info(dinfo, page, count);
+	}
+	*eof = 1;
+	return len;
+}
+
+#ifdef ENABLE_DEBUG_PROC
+static int
+rmisec_read_proc(char *page, char **start, off_t offset, int count,
+				 int *eof, void *data)
+{
+	device_info_pt dinfo = (device_info_pt) data;
+	int len = 0;
+	if (offset == 0) {
+		len = print_page_info(dinfo, page, count);
+	}
+	*eof = 1;
+	return len;
+}
+#endif /* ENABLE_DEBUG_PROC */
+
+static void rmisec_driver_exit(void)
+{
+	unsigned long flags;
+
+	/* device cleanup */
+	dev_info.exit_driver = 1;
+	unregister_chrdev_region(dev_info.device, 1);
+
+	cdev_del(&dev_info.rmisec_cdev);
+
+	spin_lock_irqsave(&dev_info.mem_lock, flags);
+	remove_proc_entry(stats_name, dev_info.pdir);
+#ifdef ENABLE_DEBUG_PROC
+	remove_proc_entry(debug_name, dev_info.pdir);
+#endif /* ENABLE_DEBUG_PROC */
+	remove_proc_entry(driver_name, (struct proc_dir_entry *) NULL);
+	spin_unlock_irqrestore(&dev_info.mem_lock, flags);
+
+
+	printk(KERN_NOTICE "Unloading driver\n");
+
+	return;
+}
+
+
+static int ecc_init(void)
+{
+	meminfo_t mem;
+	struct page *page;
+	unsigned char *ecc;
+	unsigned long flags, phy;
+
+	memset(&mem, 0, sizeof(meminfo_t));
+
+	mem.msg0 = ecc_msg0;
+	mem.msg1 = ecc_msg1;
+	mem.magic = DRIVER_MAGIC;
+	mem.ctx = INIT_CTX;
+	mem.op_type = RMI_ECC_OP;
+	mem.in_progress = IN_PROGRESS;
+	mem.result = RMISAE_SUCCESS;
+	mem.return_value = (unsigned long) &mem;
+	init_waitqueue_head(&mem.wq);
+
+	page = alloc_pages(GFP_ATOMIC | __GFP_ZERO, 0);
+
+	local_irq_save(flags);
+	ecc = (unsigned char *) kmap_atomic(page, KM_USER0);
+	mem.ptr = ecc;
+	memcpy(ecc, ecc_uc_data, sizeof(ecc_uc_data));
+	kunmap_atomic(page, KM_USER0);
+	local_irq_restore(flags);
+	ecc = NULL;
+
+	phy = page_to_pfn(page);
+	phy <<= PAGE_SHIFT;
+	SET_SEGMENT_ADDR(mem.msg0, phy);
+	send_to_sae(&mem, 0);
+
+	__free_page(page);
+
+	if (mem.result != RMISAE_SUCCESS) {
+		printk(KERN_ALERT "%s:%d ECC init failed with error=%x\n",
+			   __FUNCTION__, __LINE__, mem.result);
+		return -1;
+	}
+	return 0;
+}
+
+static int msgring_config_init(void)
+{
+	int i;
+
+	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_SECURITY_OFFSET);
+
+	phoenix_write_reg(mmio, SEC_DMA_CREDIT, SEC_DMA_CREDIT_CONFIG);
+
+	phoenix_write_reg(mmio, SEC_CONFIG2, SEC_CFG2_ROUND_ROBIN_ON);
+
+
+	if (!is_xls()) {
+		for (i = 0; i < 8; i++)
+			phoenix_write_reg(mmio, SEC_MSG_BUCKET0_SIZE + i,
+							  bucket_sizes.bucket[MSGRNG_STNID_SEC + i]);
+		for (i = 0; i < 128; i++)
+			phoenix_write_reg(mmio, SEC_CC_CPU0_0 + i,
+							  cc_table_sec.counters[i >> 3][i & 0x07]);
+	}
+	else {
+		for (i = 0; i < 8; i++)
+			phoenix_write_reg(mmio, SEC_MSG_BUCKET0_SIZE + i,
+							  xls_bucket_sizes.bucket[MSGRNG_STNID_SEC + i]);
+		for (i = 0; i < 128; i++)
+			phoenix_write_reg(mmio, SEC_CC_CPU0_0 + i,
+							  xls_cc_table_sec.counters[i >> 3][i & 0x07]);
+	}
+	return 0;
+}
+
+extern int xlr_loader_support;
+extern int xlr_loader_sharedcore;
+static int __init rmisec_driver_init(void)
+{
+	int ret;
+	int major, minor;
+
+
+	if (xlr_loader_support && xlr_loader_sharedcore)
+		return -ENODEV;
+
+	/* init device_info strucuture */
+	memset(&dev_info, 0, sizeof(struct device_info));
+	dev_info.version = MKDEV(2, 0);
+
+	/* the pk ops bitmap uses only 8 bits, rest are marked used */
+	dev_info.pk_ops_bitmap = 0xffffff00;
+
+	init_waitqueue_head(&dev_info.crypto_queue);
+	init_waitqueue_head(&dev_info.pkop_queue);
+	spin_lock_init(&dev_info.pkops_lock);
+	spin_lock_init(&dev_info.crypto_lock);
+
+	spin_lock_init(&dev_info.mem_lock);
+	dev_info.pmem_list.next = &dev_info.pmem_list;
+	dev_info.pmem_list.prev = &dev_info.pmem_list;
+
+	/* registering device */
+	dev_info.device = MKDEV(0, 0);
+	ret = alloc_chrdev_region(&dev_info.device, 0, 1, driver_name);
+	if (ret < 0) {
+		printk(KERN_ALERT "%s:%d device could not get major number\n",
+			   __FILE__, __LINE__);
+		goto bail;
+	}
+
+	major = MAJOR(dev_info.device);
+	minor = MINOR(dev_info.device);
+
+	cdev_init(&dev_info.rmisec_cdev, &fops);
+	dev_info.rmisec_cdev.owner = THIS_MODULE;
+
+#ifdef CONFIG_OCF_OCF_MODULE
+	/* create a asyncrhonous queue to process OCF operations */
+	if (rmisec_create_operation_callback
+		(&dev_info.ocf_cb, rmisae_ocf_callback)) {
+		unregister_chrdev_region(dev_info.device, 1);
+		printk(KERN_ALERT "%s:%d OCF async queue initialization failed.",
+			   __FUNCTION__, __LINE__);
+		goto bail;
+	}
+
+	softc_device_init(&dev_info.ocf_dev, "rmisae", 0, rmisae_methods);
+	dev_info.ocf_id = crypto_get_driverid(softc_get_device(&dev_info.ocf_dev),
+										  CRYPTOCAP_F_HARDWARE);
+	if (dev_info.ocf_id < 0) {
+		unregister_chrdev_region(dev_info.device, 1);
+		printk(KERN_ALERT "%s:%d RMISAE cannot initialize into OCF.",
+			   __FUNCTION__, __LINE__);
+		goto bail;
+	}
+	else {
+#define	REGISTER(alg) \
+	crypto_register(dev_info.ocf_id,alg,0,0)
+		REGISTER(CRYPTO_DES_CBC);
+		REGISTER(CRYPTO_3DES_CBC);
+		REGISTER(CRYPTO_RIJNDAEL128_CBC);
+		REGISTER(CRYPTO_MD5);
+		REGISTER(CRYPTO_SHA1);
+		REGISTER(CRYPTO_MD5_HMAC);
+		REGISTER(CRYPTO_SHA1_HMAC);
+	}
+#endif /* CONFIG_OCF_OCF_MODULE */
+
+	ret = cdev_add(&dev_info.rmisec_cdev, dev_info.device, 1);
+	if (ret < 0) {
+		unregister_chrdev_region(dev_info.device, 1);
+#ifdef CONFIG_OCF_OCF_MODULE
+		crypto_unregister_all(dev_info.ocf_id);
+#endif /* CONFIG_OCF_OCF_MODULE */
+		printk(KERN_ALERT "%s:%d Error adding char driver err=%d.\n",
+			   __FUNCTION__, __LINE__, ret);
+		goto bail;
+	}
+
+	msgring_config_init();
+
+	dev_info.pdir = proc_mkdir("rmi/" DRIVER_NAME, NULL);
+	if (dev_info.pdir == NULL) {
+		printk("%s:%d failed creating proc directory: %s\n",
+			   __FUNCTION__, __LINE__, driver_name);
+		ret = -ENOMEM;
+		goto bail;
+	}
+	else {
+#ifdef ENABLE_DEBUG_PROC
+		dev_info.pdebug = create_proc_read_entry(debug_name, 0, dev_info.pdir,
+												 rmisec_read_proc, &dev_info);
+		if (dev_info.pdebug == NULL) {
+			remove_proc_entry(driver_name, NULL);
+			printk("%s:%d failed creating debug entry: %s/%s\n",
+				   __FUNCTION__, __LINE__, driver_name, debug_name);
+			ret = -EINVAL;
+			goto bail;
+		}
+#endif /* ENABLE_DEBUG_PROC */
+
+		dev_info.pstats = create_proc_read_entry(stats_name, 0, dev_info.pdir,
+												 rmisec_read_stats_proc,
+												 &dev_info);
+
+		if (dev_info.pstats == NULL) {
+#ifdef ENABLE_DEBUG_PROC
+			remove_proc_entry(debug_name, dev_info.pdir);
+#endif /* ENABLE_DEBUG_PROC */
+			remove_proc_entry("rmi/" DRIVER_NAME, NULL);
+			printk("%s:%d failed creating stats entry: %s/%s\n",
+				   __FUNCTION__, __LINE__, driver_name, stats_name);
+			ret = -EINVAL;
+			goto bail;
+		}
+
+	}
+
+#ifdef CONFIG_PHOENIX_MSGRING_NAPI
+	if (rmi_on_chip_napi) {
+		printk(KERN_NOTICE "SAE NAPI-compatible Subsystem.\n");
+	}
+#endif
+
+	if ((ret = register_msgring_handler(TX_STN_SEC,
+										rmisec_msgring_handler, &dev_info))) {
+		rmisec_driver_exit();
+		ret = -EINVAL;
+		goto bail;
+	}
+
+	if (is_xls()) {
+		ecc_init();
+	}
+
+#ifdef DEBUG
+	printk(KERN_NOTICE "%s:%d SEC handler=%p\n", __FUNCTION__, __LINE__,
+		   rmisec_msgring_handler);
+#endif /* DEBUG */
+	printk(KERN_NOTICE "Loaded SAE driver version=[%s] major=%d minor=%d\n",
+		   versionstr, major, minor);
+
+	return 0;
+  bail:
+	rmisec_driver_exit();
+	return ret;
+}
+
+/* Queuing functions */
+int rmisec_op_setup(op_handle_t handle, op_queue_t async_queue,
+					unsigned long arg, int op_flags)
+{
+	operation_pt op = (operation_pt) handle;
+
+	if (op == NULL)
+		return -1;
+
+	op->return_queue = (secop_queue_pt) async_queue;
+	op->op_flags = op_flags;
+
+	if (op->return_queue != NULL) {
+		op->op_flags |= OP_NO_WAIT;
+	}
+	else {
+		op->op_flags &= ~(OP_NO_WAIT);
+	}
+
+	op->arg = arg;
+	return 0;
+}
+
+EXPORT_SYMBOL(rmisec_op_setup);
+
+int
+rmisec_op_callback_setup(op_handle_t handle, op_callback_t async_callback,
+						 unsigned long arg, int op_flags)
+{
+	return rmisec_op_setup(handle, (op_queue_t) async_callback, arg,
+						   op_flags);
+}
+
+EXPORT_SYMBOL(rmisec_op_callback_setup);
+
+int rmisec_create_operation_queue(op_queue_pt handle)
+{
+	secop_queue_pt ret;
+	gfp_t flg;
+	if (in_atomic() || in_softirq() || in_interrupt()) {
+		flg = GFP_ATOMIC;
+	}
+	else {
+		flg = GFP_KERNEL;
+	}
+
+	ret = (secop_queue_pt) kmalloc(sizeof(secop_queue_t), flg);
+	if (ret == NULL) {
+		return -ENOMEM;
+	}
+	INIT_SECOP_QUEUE(ret, -1);
+	*handle = (op_queue_t) ret;
+
+	return 0;
+}
+
+EXPORT_SYMBOL(rmisec_create_operation_queue);
+
+int rmisec_destroy_operation_queue(op_queue_pt handle)
+{
+	secop_queue_pt ret = (secop_queue_pt) (*handle);
+	if (ret && ret->response_type == SECOP_Q) {
+		if (ret->q.length != 0) {
+			printk(KERN_INFO "%s:%d Error queue not empty: %d\n",
+				   __FUNCTION__, __LINE__, ret->q.length);
+			return -1;
+		}
+
+		kfree(ret);
+		*handle = 0;
+	}
+	return 0;
+}
+
+EXPORT_SYMBOL(rmisec_destroy_operation_queue);
+
+int rmisec_create_operation_callback(op_callback_pt handle,
+									 op_callback_func_t func)
+{
+	secop_queue_pt ret;
+	gfp_t flg;
+	if (in_atomic() || in_softirq() || in_interrupt()) {
+		flg = GFP_ATOMIC;
+	}
+	else {
+		flg = GFP_KERNEL;
+	}
+
+	ret = (secop_queue_pt) kmalloc(sizeof(secop_queue_t), flg);
+	if (ret == NULL) {
+		return -ENOMEM;
+	}
+	INIT_SECOP_CB(ret, func);
+	*handle = (op_queue_t) ret;
+
+	return 0;
+}
+
+EXPORT_SYMBOL(rmisec_create_operation_callback);
+
+int rmisec_destroy_operation_callback(op_callback_pt handle)
+{
+	secop_queue_pt queue = (secop_queue_pt) handle;
+	if (queue && queue->response_type == SECOP_CB) {
+		kfree(queue);
+		*handle = (op_callback_t) NULL;
+	}
+	return 0;
+}
+
+EXPORT_SYMBOL(rmisec_destroy_operation_callback);
+
+int rmisec_op_queue_dequeue(op_queue_t qhandle, int *result,
+							op_handle_pt phandle)
+{
+	secop_queue_pt queue = (secop_queue_pt) qhandle;
+	operation_pt op;
+	meminfo_pt mem = remove_meminfo_from_queue(queue);
+
+	if (mem != NULL) {
+		if (mem->magic == DRIVER_MAGIC) {
+			*result = mem->result;
+			op = (operation_pt) mem->return_value;
+			if (mem->ctx == KERNEL_CTX) {
+				*result = post_process_op(*result, op);
+			}
+			else {
+				printk(KERN_WARNING "%s:%d Meminfo Not kernel context\n",
+					   __FUNCTION__, __LINE__);
+			}
+			*phandle = (op_handle_t) op;
+			return 0;
+		}
+		else {
+			printk(KERN_WARNING "%s:%d Invalid mem=%p magic=%llx\n",
+				   __FUNCTION__, __LINE__, mem, mem->magic);
+		}
+	}
+	return -1;
+}
+
+EXPORT_SYMBOL(rmisec_op_queue_dequeue);
+
+unsigned int rmisec_op_queue_size(op_queue_t qhandle)
+{
+	int ret = 0;
+	secop_queue_pt queue = (secop_queue_pt) qhandle;
+	if (queue && queue->response_type == SECOP_Q) {
+		ret = queue->q.length;
+	}
+	return ret;
+}
+
+EXPORT_SYMBOL(rmisec_op_queue_size);
+
+unsigned long rmisec_op_get_arg(op_handle_t handle)
+{
+	operation_pt op;
+	if (handle != 0UL) {
+		op = (operation_pt) handle;
+		return op->arg;
+	}
+	return 0;
+}
+
+EXPORT_SYMBOL(rmisec_op_get_arg);
+
+module_init(rmisec_driver_init);
+module_exit(rmisec_driver_exit);
-- 
1.6.5.2

