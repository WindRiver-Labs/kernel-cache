From 43d3769fbb4901b32e1f09191151f9ef6d511ff5 Mon Sep 17 00:00:00 2001
From: Wu Zhangjin <zhangjin.wu@windriver.com>
Date: Mon, 7 Mar 2011 10:51:07 +0800
Subject: [PATCH 2/3] nlm_xls_atx_64_be: Fixed setting of IRQ affinity.

Assigning an interrupt to a group of CPU was miscalculated if the boot CPU was
not core0/thread0 and if not all CPUs were online, such as in the case of a
kdump kernel. Logical CPU0 was considered to be core0/thread0, which is not
necessarily true. If rebooting and only using one CPU, but not core0/thread0,
interrupts being assigned an affinity would be directed to core0/thread0 and
never serviced.

Signed-off-by: Benjamin Walsh <benjamin.walsh@windriver.com>
Signed-off-by: Wu Zhangjin <zhangjin.wu@windriver.com>
---
 arch/mips/rmi/phoenix/irq.c |   17 +++++++----------
 arch/mips/rmi/ptr/smp.c     |   20 ++++++++++++++++++++
 2 files changed, 27 insertions(+), 10 deletions(-)

diff --git a/arch/mips/rmi/phoenix/irq.c b/arch/mips/rmi/phoenix/irq.c
index 07743bb..a9a30a4 100644
--- a/arch/mips/rmi/phoenix/irq.c
+++ b/arch/mips/rmi/phoenix/irq.c
@@ -288,26 +288,23 @@ static void pic_shutdown(unsigned int irq)
 	spin_unlock_irqrestore(&phnx_pic_lock, flags);
 }
 
+extern uint32_t phoenix_smp_logical_to_hw_mask(const cpumask_t *mask);
+
 static int pic_set_affinity(unsigned int irq, const struct cpumask *mask)
 {
 	phoenix_reg_t *mmio = phoenix_io_mmio(PHOENIX_IO_PIC_OFFSET);
 	unsigned long flags;
-	uint32_t physmap = 0, logmap = 0, i;
+	uint32_t hw_mask;
+	cpumask_t mask0 = cpumask_of_cpu(0);
 
 	if (!PIC_IRQ_IS_IRT(irq))
 		return -1;
 
-	/* Set affinity comes with logical cpu ids, move this to physical cpu ids */
-	for (i = 0; i < NR_CPUS; i++) {
-		if ((1 << i) & (uint32_t) mask->bits[0]) {
-			logmap |= (1 << i);
-			physmap |= (1 << cpu_logical_map(i));
-		}
-	}
-
 	spin_lock_irqsave(&phnx_pic_lock, flags);
 
-	phoenix_write_reg(mmio, PIC_IRT_0_BASE + irq - PIC_IRQ_BASE, physmap);
+	hw_mask = phoenix_smp_logical_to_hw_mask(mask) |
+		phoenix_smp_logical_to_hw_mask(&mask0);
+	phoenix_write_reg(mmio, PIC_IRT_0_BASE + irq - PIC_IRQ_BASE, hw_mask);
 
 	spin_unlock_irqrestore(&phnx_pic_lock, flags);
 
diff --git a/arch/mips/rmi/ptr/smp.c b/arch/mips/rmi/ptr/smp.c
index 8ba3f89..197afb0 100644
--- a/arch/mips/rmi/ptr/smp.c
+++ b/arch/mips/rmi/ptr/smp.c
@@ -121,6 +121,23 @@ unsigned int fast_syscall_cpumask_phy = 0x1;
 extern __u32 ipi_3_counter_tx[NR_CPUS][NR_CPUS];
 extern __u32 ipi_3_counter_rx[NR_CPUS];
 
+static uint32_t phoenix_logical_hi_mask;
+
+uint32_t phoenix_smp_logical_to_hw_mask(const cpumask_t *mask)
+{
+	uint32_t hw_mask, logical_mask;
+
+	/* The boot cpu is always at index 0 of the logical map; following
+	* are CPUs 0 to <boot cpu-1>, then CPUs <boot cpu+1> to 31.
+	* We have to take that map and find the map of physical CPUs that
+	* are online.
+	*/
+	logical_mask = (uint32_t)(mask->bits[0]);
+	hw_mask = (logical_mask & ~phoenix_logical_hi_mask) >> 1;
+	hw_mask |= logical_mask & phoenix_logical_hi_mask;
+	return hw_mask;
+}
+
 void __init rmi_smp_setup(void)
 {
 	cpumask_t phys_cpu_present_map;	/* Bitmask of available CPUs */
@@ -162,6 +179,9 @@ void __init rmi_smp_setup(void)
 	}
 	cpu_present_map = cpu_possible_map;
 
+	for (i = boot_cpu + 1; i < NR_CPUS; i++)
+		phoenix_logical_hi_mask |= (1 << i);
+
 	fast_syscall_cpumask_phy = (unsigned int)phys_cpu_present_map.bits[0];
 
 	printk("Phys CPU present map: %lx, possible map %lx\n", 
-- 
1.6.5.2

