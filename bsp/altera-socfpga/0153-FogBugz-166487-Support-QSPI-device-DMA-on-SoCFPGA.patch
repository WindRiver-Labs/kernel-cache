From daf867ab0afa10c2aa908467d89bbc3d5ba234d9 Mon Sep 17 00:00:00 2001
From: Graham Moore <grmoore@altera.com>
Date: Thu, 7 Nov 2013 11:32:07 -0600
Subject: [PATCH 153/248] FogBugz #166487: Support QSPI device DMA on SoCFPGA

Support for DMA transfers was added to the Cadence QSPI driver.
There is a fair amount of new code, but the flow of the driver
was minimally changed.
If the code is unable to initialize DMA channels, it falls
back to non-DMA operation.
Enabling of the DMA transfers is done through the device tree.
Peripheral Request IDs for the QSPI are specified in the device tree.
Device tree documentation was updated.

V2:
Check error return from device_prep_slave_sg
Use #defines for request byte counts
Replaced pr_debug/pr_err with dev_dbg/dev_err

[Original patch taken from
git://git.rocketboards.org/linux-socfpga.git socfpga-3.14]

Signed-off-by: Yanjiang Jin <yanjiang.jin@windriver.com>
Signed-off-by: Graham Moore <grmoore@altera.com>
---
 .../devicetree/bindings/spi/spi-cadence-qspi.txt   |   7 +-
 drivers/spi/spi-cadence-qspi-apb.c                 | 293 ++++++++++++++++++++-
 drivers/spi/spi-cadence-qspi.c                     |  81 ++++++
 drivers/spi/spi-cadence-qspi.h                     |   8 +
 4 files changed, 385 insertions(+), 4 deletions(-)

diff --git a/Documentation/devicetree/bindings/spi/spi-cadence-qspi.txt b/Documentation/devicetree/bindings/spi/spi-cadence-qspi.txt
index d4dda9a..7d7678b 100644
--- a/Documentation/devicetree/bindings/spi/spi-cadence-qspi.txt
+++ b/Documentation/devicetree/bindings/spi/spi-cadence-qspi.txt
@@ -15,7 +15,9 @@ Required properties:
 - bus-num : Number of the SPI bus to which the controller is connected.
 
 Optional properties:
-No optional properties
+- enable-dma : boolean, if present, then DMA is used for reads and writes
+- tx-dma-peri-id : peripheral request id for tx dma channel, required if enable-dma is present
+- rx-dma-peri-id : peripheral request id for rx dma channel, required if enable-dma is present
 
 Example:
 
@@ -31,4 +33,7 @@ Example:
 		num-chipselect = <4>;
 		fifo-depth = <128>;
 		bus-num = <2>;
+		enable-dma;
+		tx-dma-peri-id = <24>;
+		rx-dma-peri-id = <25>;
 	}
diff --git a/drivers/spi/spi-cadence-qspi-apb.c b/drivers/spi/spi-cadence-qspi-apb.c
index 9a1488c..4a4dad5 100644
--- a/drivers/spi/spi-cadence-qspi-apb.c
+++ b/drivers/spi/spi-cadence-qspi-apb.c
@@ -36,6 +36,8 @@
 #include <linux/platform_device.h>
 #include <linux/io.h>
 #include <linux/spi/spi.h>
+#include <linux/dma-mapping.h>
+#include <linux/dmaengine.h>
 #include "spi-cadence-qspi.h"
 #include "spi-cadence-qspi-apb.h"
 
@@ -91,6 +93,8 @@ static void __hex_dump(unsigned int address_to_print,
 
 /****************************************************************************/
 
+#define CQSPI_NUMSGLREQBYTES (0)
+#define CQSPI_NUMBURSTREQBYTES (4)
 
 void cadence_qspi_apb_delay(struct struct_cqspi *cadence_qspi,
 	unsigned int ref_clk, unsigned int sclk_hz);
@@ -400,6 +404,183 @@ static int cadence_qspi_apb_command_write(void *reg_base, unsigned txlen,
 	return cadence_qspi_apb_exec_flash_cmd(reg_base, reg);
 }
 
+static void cadence_qspi_dma_done(void *arg)
+{
+	struct struct_cqspi *cadence_qspi = arg;
+	cadence_qspi->dma_done = 1;
+	wake_up(&cadence_qspi->waitqueue);
+}
+
+#define CQSPI_IS_DMA_READ (true)
+#define CQSPI_IS_DMA_WRITE (false)
+
+static void cadence_qspi_apb_dma_cleanup(
+	struct struct_cqspi *cadence_qspi,
+	unsigned datalen, bool do_read)
+{
+	struct platform_device *pdev = cadence_qspi->pdev;
+	dma_unmap_single(&pdev->dev, cadence_qspi->dma_addr,
+			datalen, do_read ? DMA_FROM_DEVICE : DMA_TO_DEVICE);
+}
+
+static int cadence_qspi_apb_dma_start(
+	struct struct_cqspi *cadence_qspi,
+	unsigned datalen, unsigned char *databuf,
+	bool do_read)
+{
+	struct platform_device *pdev = cadence_qspi->pdev;
+	struct cqspi_platform_data *pdata = pdev->dev.platform_data;
+	struct dma_chan *dmachan;
+	struct dma_slave_config dmaconf;
+	struct dma_async_tx_descriptor *dmadesc = NULL;
+	struct scatterlist sgl;
+	enum dma_data_direction data_direction;
+
+	if (do_read) {
+		dmachan = cadence_qspi->rxchan;
+		data_direction = DMA_FROM_DEVICE;
+		dmaconf.direction = DMA_DEV_TO_MEM;
+		dmaconf.src_addr = pdata->qspi_ahb_phy;
+		dmaconf.src_addr_width = 4;
+	} else {
+		dmachan = cadence_qspi->txchan;
+		data_direction = DMA_TO_DEVICE;
+		dmaconf.direction = DMA_MEM_TO_DEV;
+		dmaconf.dst_addr = pdata->qspi_ahb_phy;
+		dmaconf.dst_addr_width = 4;
+	}
+
+	/* map the buffer address */
+	cadence_qspi->dma_addr = dma_map_single(&pdev->dev,
+			databuf, datalen, data_direction);
+	if (dma_mapping_error(&pdev->dev, cadence_qspi->dma_addr)) {
+		dev_err(&pdev->dev, "dma_map_single failed\n");
+		return -EINVAL;
+	}
+
+	/* set up slave config */
+	dmachan->device->device_control(dmachan, DMA_SLAVE_CONFIG,
+		(unsigned long) &dmaconf);
+
+	/* get dmadesc, we use scatterlist API, with one
+		memory buffer in the list */
+	memset(&sgl, 0, sizeof(sgl));
+	sgl.dma_address = cadence_qspi->dma_addr;
+	sgl.length = datalen;
+
+	dmadesc = dmachan->device->device_prep_slave_sg(dmachan,
+				&sgl,
+				1,
+				dmaconf.direction,
+				DMA_PREP_INTERRUPT,
+				NULL);
+	if (!dmadesc) {
+		cadence_qspi_apb_dma_cleanup(cadence_qspi, datalen, do_read);
+		return -ENOMEM;
+	}
+	dmadesc->callback = cadence_qspi_dma_done;
+	dmadesc->callback_param = cadence_qspi;
+
+	/* start DMA */
+	cadence_qspi->dma_done = 0;
+	dmadesc->tx_submit(dmadesc);
+	dma_async_issue_pending(dmachan);
+
+	return 0;
+}
+
+static int cadence_qspi_apb_indirect_read_dma(
+	struct struct_cqspi *cadence_qspi,
+	unsigned rxlen, unsigned char *rxbuf)
+{
+	int ret = 0;
+	struct platform_device *pdev = cadence_qspi->pdev;
+	struct cqspi_platform_data *pdata = pdev->dev.platform_data;
+	void *reg_base = cadence_qspi->iobase;
+	unsigned int reg;
+	unsigned int timeout;
+	unsigned int watermark = CQSPI_REG_SRAM_THRESHOLD_BYTES;
+
+	if (rxlen < watermark)
+		watermark = rxlen;
+
+	ret = cadence_qspi_apb_dma_start(cadence_qspi,
+		rxlen, rxbuf, CQSPI_IS_DMA_READ);
+	if (ret)
+		return ret;
+
+	/* Set up qspi dma */
+	reg = CQSPI_READL(reg_base + CQSPI_REG_CONFIG);
+	reg |= CQSPI_REG_CONFIG_DMA_MASK;
+	CQSPI_WRITEL(reg, reg_base + CQSPI_REG_CONFIG);
+
+	reg = (CQSPI_NUMBURSTREQBYTES << CQSPI_REG_DMA_BURST_LSB)
+		| (CQSPI_NUMSGLREQBYTES << CQSPI_REG_DMA_SINGLE_LSB);
+	CQSPI_WRITEL(reg, reg_base + CQSPI_REG_DMA);
+
+	/* Set up QSPI transfer */
+	CQSPI_WRITEL(watermark, reg_base + CQSPI_REG_INDIRECTRDWATERMARK);
+	CQSPI_WRITEL(rxlen, reg_base + CQSPI_REG_INDIRECTRDBYTES);
+	CQSPI_WRITEL(pdata->fifo_depth - CQSPI_REG_SRAM_RESV_WORDS,
+		reg_base + CQSPI_REG_SRAMPARTITION);
+
+	/* Clear all interrupts. */
+	CQSPI_WRITEL(CQSPI_IRQ_STATUS_MASK, reg_base + CQSPI_REG_IRQSTATUS);
+
+	CQSPI_WRITEL(CQSPI_IRQ_MASK_RD, reg_base + CQSPI_REG_IRQMASK);
+
+	/* Start qspi */
+	reg = CQSPI_READL(reg_base + CQSPI_REG_INDIRECTRD);
+	CQSPI_WRITEL(reg, reg_base + CQSPI_REG_INDIRECTRD);
+	CQSPI_WRITEL(CQSPI_REG_INDIRECTRD_START_MASK,
+			reg_base + CQSPI_REG_INDIRECTRD);
+
+	/* Wait for dma to finish */
+	if (!wait_event_interruptible_timeout(cadence_qspi->waitqueue,
+		cadence_qspi->dma_done, CQSPI_TIMEOUT_MS)) {
+		pr_err("QSPI: Indirect read DMA timeout\n");
+		ret = -ETIMEDOUT;
+	}
+
+	/* Check indirect done status */
+	timeout = cadence_qspi_init_timeout(CQSPI_TIMEOUT_MS);
+	while (cadence_qspi_check_timeout(timeout)) {
+		reg = CQSPI_READL(reg_base + CQSPI_REG_INDIRECTRD);
+		if (reg & CQSPI_REG_INDIRECTRD_DONE_MASK)
+			break;
+	}
+
+	if (!(reg & CQSPI_REG_INDIRECTRD_DONE_MASK)) {
+		pr_err("QSPI : Indirect read completion status error with reg 0x%08x\n",
+			reg);
+		ret = -ETIMEDOUT;
+	}
+
+	if (ret != 0) {
+		/* We had an error, cancel the indirect read */
+		CQSPI_WRITEL(CQSPI_REG_INDIRECTWR_CANCEL_MASK,
+			reg_base + CQSPI_REG_INDIRECTRD);
+		/* and cancel DMA */
+		dmaengine_terminate_all(cadence_qspi->rxchan);
+	}
+
+	/* Disable interrupt */
+	CQSPI_WRITEL(0, reg_base + CQSPI_REG_IRQMASK);
+
+	/* Clear indirect completion status */
+	CQSPI_WRITEL(CQSPI_REG_INDIRECTRD_DONE_MASK,
+		reg_base + CQSPI_REG_INDIRECTRD);
+
+	cadence_qspi_apb_dma_cleanup(cadence_qspi, rxlen, CQSPI_IS_DMA_READ);
+
+	/* Turn off qspi dma */
+	reg = CQSPI_READL(reg_base + CQSPI_REG_CONFIG);
+	reg &= ~(CQSPI_REG_CONFIG_DMA_MASK);
+	CQSPI_WRITEL(reg, reg_base + CQSPI_REG_CONFIG);
+
+	return ret;
+}
+
 static int cadence_qspi_apb_indirect_read_setup(void *reg_base,
 	unsigned int ahb_phy_addr, unsigned txlen, const unsigned char *txbuf,
 	unsigned int addr_bytes)
@@ -601,6 +782,100 @@ static int cadence_qspi_apb_indirect_write_setup(void *reg_base,
 	return 0;
 }
 
+static int cadence_qspi_apb_indirect_write_dma(
+	struct struct_cqspi *cadence_qspi,
+	unsigned txlen, unsigned char *txbuf)
+{
+	int ret = 0;
+	void *reg_base = cadence_qspi->iobase;
+	unsigned int reg;
+	unsigned int timeout;
+
+	struct platform_device *pdev = cadence_qspi->pdev;
+	struct cqspi_platform_data *pdata = pdev->dev.platform_data;
+	struct cqspi_flash_pdata *f_pdata =
+			&(pdata->f_pdata[cadence_qspi->current_cs]);
+
+	pr_debug("%s txlen %d txbuf %p\n", __func__, txlen, txbuf);
+
+	ret = cadence_qspi_apb_dma_start(cadence_qspi,
+		txlen, txbuf, CQSPI_IS_DMA_WRITE);
+	if (ret)
+		return ret;
+
+	/* Set up qspi dma */
+	reg = CQSPI_READL(reg_base + CQSPI_REG_CONFIG);
+	reg |= CQSPI_REG_CONFIG_DMA_MASK;
+	CQSPI_WRITEL(reg, reg_base + CQSPI_REG_CONFIG);
+
+	reg = (CQSPI_NUMBURSTREQBYTES << CQSPI_REG_DMA_BURST_LSB)
+		| (CQSPI_NUMSGLREQBYTES << CQSPI_REG_DMA_SINGLE_LSB);
+	CQSPI_WRITEL(reg, reg_base + CQSPI_REG_DMA);
+
+	/* Set up QSPI transfer */
+	CQSPI_WRITEL(f_pdata->page_size,
+		reg_base + CQSPI_REG_INDIRECTWRWATERMARK);
+	CQSPI_WRITEL(txlen, reg_base + CQSPI_REG_INDIRECTWRBYTES);
+	CQSPI_WRITEL(CQSPI_REG_SRAM_PARTITION_WR,
+		reg_base + CQSPI_REG_SRAMPARTITION);
+
+	/* Clear all interrupts. */
+	CQSPI_WRITEL(CQSPI_IRQ_STATUS_MASK, reg_base + CQSPI_REG_IRQSTATUS);
+
+	CQSPI_WRITEL(CQSPI_IRQ_MASK_WR, reg_base + CQSPI_REG_IRQMASK);
+
+	/* Start qspi */
+	reg = CQSPI_READL(reg_base + CQSPI_REG_INDIRECTWR);
+	CQSPI_WRITEL(reg, reg_base + CQSPI_REG_INDIRECTWR);
+	CQSPI_WRITEL(CQSPI_REG_INDIRECTWR_START_MASK,
+			reg_base + CQSPI_REG_INDIRECTWR);
+
+	/* Wait for dma to finish */
+	if (!wait_event_interruptible_timeout(cadence_qspi->waitqueue,
+		cadence_qspi->dma_done, CQSPI_TIMEOUT_MS)) {
+		pr_err("QSPI: Indirect write DMA timeout\n");
+		ret = -ETIMEDOUT;
+	}
+
+	/* Check indirect done status */
+	timeout = cadence_qspi_init_timeout(CQSPI_TIMEOUT_MS);
+	while (cadence_qspi_check_timeout(timeout)) {
+		reg = CQSPI_READL(reg_base + CQSPI_REG_INDIRECTWR);
+		if (reg & CQSPI_REG_INDIRECTWR_DONE_MASK)
+			break;
+	}
+
+	if (!(reg & CQSPI_REG_INDIRECTWR_DONE_MASK)) {
+		pr_err("QSPI : Indirect write completion status error with reg 0x%08x\n",
+			reg);
+		ret = -ETIMEDOUT;
+	}
+
+	if (ret != 0) {
+		/* We had an error, cancel the indirect write */
+		CQSPI_WRITEL(CQSPI_REG_INDIRECTWR_CANCEL_MASK,
+			reg_base + CQSPI_REG_INDIRECTWR);
+		/* and cancel DMA */
+		dmaengine_terminate_all(cadence_qspi->txchan);
+	}
+
+	/* Disable interrupt */
+	CQSPI_WRITEL(0, reg_base + CQSPI_REG_IRQMASK);
+
+	/* Clear indirect completion status */
+	CQSPI_WRITEL(CQSPI_REG_INDIRECTWR_DONE_MASK,
+		reg_base + CQSPI_REG_INDIRECTWR);
+
+	cadence_qspi_apb_dma_cleanup(cadence_qspi, txlen, CQSPI_IS_DMA_WRITE);
+
+	/* Turn off qspi dma */
+	reg = CQSPI_READL(reg_base + CQSPI_REG_CONFIG);
+	reg &= ~(CQSPI_REG_CONFIG_DMA_MASK);
+	CQSPI_WRITEL(reg, reg_base + CQSPI_REG_CONFIG);
+
+	return ret;
+}
+
 static int cadence_qspi_apb_indirect_write_execute(
 	struct struct_cqspi *cadence_qspi, unsigned txlen,
 	const unsigned char *txbuf)
@@ -901,17 +1176,29 @@ int cadence_qspi_apb_process_queue(struct struct_cqspi *cadence_qspi,
 			 ret = cadence_qspi_apb_indirect_read_setup(iobase,
 				 pdata->qspi_ahb_phy, cmd_xfer->len,
 				 cmd_xfer->tx_buf, spi->addr_width);
+			if (pdata->enable_dma) {
+				ret = cadence_qspi_apb_indirect_read_dma(
+					cadence_qspi, data_xfer->len,
+					data_xfer->rx_buf);
+			} else {
 			 ret = cadence_qspi_apb_indirect_read_execute(
 				cadence_qspi, data_xfer->len,
 				data_xfer->rx_buf);
+			}
 		 } else {
 			 /* Indirect write */
 			 ret = cadence_qspi_apb_indirect_write_setup(
 				 iobase, pdata->qspi_ahb_phy,
 				 cmd_xfer->len, cmd_xfer->tx_buf);
-			ret = cadence_qspi_apb_indirect_write_execute(
-				cadence_qspi, data_xfer->len,
-				data_xfer->tx_buf);
+			if (pdata->enable_dma) {
+				ret = cadence_qspi_apb_indirect_write_dma(
+					cadence_qspi, data_xfer->len,
+					(unsigned char *)data_xfer->tx_buf);
+			} else {
+				ret = cadence_qspi_apb_indirect_write_execute(
+					cadence_qspi, data_xfer->len,
+					data_xfer->tx_buf);
+			}
 		 }
 	 } else {
 		pr_err("QSPI : Unknown SPI transfer.\n");
diff --git a/drivers/spi/spi-cadence-qspi.c b/drivers/spi/spi-cadence-qspi.c
index 21617ed..a2bc893 100644
--- a/drivers/spi/spi-cadence-qspi.c
+++ b/drivers/spi/spi-cadence-qspi.c
@@ -29,6 +29,8 @@
 #include <linux/of_platform.h>
 #include <linux/of_address.h>
 #include <linux/of_irq.h>
+#include <linux/dma-mapping.h>
+#include <linux/dmaengine.h>
 #include "spi-cadence-qspi.h"
 #include "spi-cadence-qspi-apb.h"
 
@@ -260,6 +262,24 @@ static int cadence_qspi_of_get_pdata(struct platform_device *pdev)
 	}
 	pdata->fifo_depth = prop;
 
+	pdata->enable_dma = of_property_read_bool(np, "enable-dma");
+	dev_info(&pdev->dev, "DMA %senabled\n",
+		pdata->enable_dma ? "" : "NOT ");
+
+	if (pdata->enable_dma) {
+		if (of_property_read_u32(np, "tx-dma-peri-id", &prop)) {
+			dev_err(&pdev->dev, "couldn't determine tx-dma-peri-id\n");
+			return -ENXIO;
+		}
+		pdata->tx_dma_peri_id = prop;
+
+		if (of_property_read_u32(np, "rx-dma-peri-id", &prop)) {
+			dev_err(&pdev->dev, "couldn't determine rx-dma-peri-id\n");
+			return -ENXIO;
+		}
+		pdata->rx_dma_peri_id = prop;
+	}
+
 	/* Get flash devices platform data */
 	for_each_child_of_node(np, nc) {
 		if (of_property_read_u32(nc, "reg", &cs)) {
@@ -314,6 +334,62 @@ static int cadence_qspi_of_get_pdata(struct platform_device *pdev)
 	return 0;
 }
 
+static void cadence_qspi_dma_shutdown(struct struct_cqspi *cadence_qspi)
+{
+	struct platform_device *pdev = cadence_qspi->pdev;
+	struct cqspi_platform_data *pdata = pdev->dev.platform_data;
+	if (cadence_qspi->txchan)
+		dma_release_channel(cadence_qspi->txchan);
+	if (cadence_qspi->rxchan)
+		dma_release_channel(cadence_qspi->rxchan);
+	pdata->enable_dma = 0;
+	cadence_qspi->rxchan = cadence_qspi->txchan = NULL;
+}
+
+static bool dma_channel_filter(struct dma_chan *chan, void *param)
+{
+	return (chan->chan_id == (unsigned int)param);
+}
+
+static void cadence_qspi_dma_init(struct struct_cqspi *cadence_qspi)
+{
+	struct platform_device *pdev = cadence_qspi->pdev;
+	struct cqspi_platform_data *pdata = pdev->dev.platform_data;
+	dma_cap_mask_t mask;
+	unsigned int channel_num;
+
+	dma_cap_zero(mask);
+	dma_cap_set(DMA_SLAVE, mask);
+
+	channel_num = pdata->tx_dma_peri_id;
+	cadence_qspi->txchan = dma_request_channel(mask,
+		dma_channel_filter, (void *)channel_num);
+	if (cadence_qspi->txchan)
+		dev_dbg(&pdev->dev, "TX channel %s %d selected\n",
+			dma_chan_name(cadence_qspi->txchan),
+			cadence_qspi->txchan->chan_id);
+	else
+		dev_err(&pdev->dev, "could not get dma channel %d\n",
+			channel_num);
+
+	channel_num = pdata->rx_dma_peri_id;
+	cadence_qspi->rxchan = dma_request_channel(mask,
+		dma_channel_filter, (void *)channel_num);
+	if (cadence_qspi->rxchan)
+		dev_dbg(&pdev->dev, "RX channel %s %d selected\n",
+			dma_chan_name(cadence_qspi->rxchan),
+			cadence_qspi->rxchan->chan_id);
+	else
+		dev_err(&pdev->dev, "could not get dma channel %d\n",
+			channel_num);
+
+	if (!cadence_qspi->rxchan  || !cadence_qspi->txchan) {
+		/* Error, fall back to non-dma mode */
+		cadence_qspi_dma_shutdown(cadence_qspi);
+		dev_info(&pdev->dev, "falling back to non-DMA operation\n");
+	}
+}
+
 static int cadence_qspi_probe(struct platform_device *pdev)
 {
 	struct spi_master *master;
@@ -448,6 +524,9 @@ static int cadence_qspi_probe(struct platform_device *pdev)
 		goto err_of;
 	}
 
+	if (pdata->enable_dma)
+		cadence_qspi_dma_init(cadence_qspi);
+
 	dev_info(&pdev->dev, "Cadence QSPI controller driver\n");
 	return 0;
 
@@ -477,6 +556,8 @@ static int cadence_qspi_remove(struct platform_device *pdev)
 	struct spi_master *master = platform_get_drvdata(pdev);
 	struct struct_cqspi *cadence_qspi = spi_master_get_devdata(master);
 
+	cadence_qspi_dma_shutdown(cadence_qspi);
+
 	cadence_qspi_apb_controller_disable(cadence_qspi->iobase);
 
 	platform_set_drvdata(pdev, NULL);
diff --git a/drivers/spi/spi-cadence-qspi.h b/drivers/spi/spi-cadence-qspi.h
index ce9b360..29fd7d6 100644
--- a/drivers/spi/spi-cadence-qspi.h
+++ b/drivers/spi/spi-cadence-qspi.h
@@ -43,6 +43,9 @@ struct cqspi_platform_data {
 	unsigned int master_ref_clk_hz;
 	unsigned int ext_decoder;
 	unsigned int fifo_depth;
+	unsigned int enable_dma;
+	unsigned int tx_dma_peri_id;
+	unsigned int rx_dma_peri_id;
 	struct cqspi_flash_pdata f_pdata[CQSPI_MAX_CHIP_SELECT];
 };
 
@@ -72,6 +75,11 @@ struct struct_cqspi
 	int current_cs;
 	/* Is queue running */
 	bool running;
+	/* DMA support */
+	struct dma_chan *txchan;
+	struct dma_chan *rxchan;
+	dma_addr_t dma_addr;
+	int dma_done;
 };
 
 /* Kernel function hook */
-- 
1.9.1

