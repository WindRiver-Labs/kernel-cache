From fb334aa0b9eb7bcdd5bd175eb488d605dc19805c Mon Sep 17 00:00:00 2001
From: ltian <le.tian@windriver.com>
Date: Mon, 15 Nov 2010 14:16:39 +0800
Subject: [PATCH 081/132] RapidIO: Octeon: Update SRIO interrupt handling to avoid race with CIU_INTX_SUM0[RML].

SRIO interrupts propagate to CIU_INT_SUM1[SRIO*] with a mask, and
CIU_INTX_SUM0[RML] without a mask. This causes issues when SRIO
interrupts are used with any code that uses CIU_INTX_SUM0[RML] for
error handling.  This change cleans up the rapidio driver to only
change the status of interrupts it is using while not interfearing
with RML processing.

Signed-off-by: Chad Reese <kreese@caviumnetworks.com>
Signed-off-by: ltian <le.tian@windriver.com>
---
 arch/mips/cavium-octeon/octeon-rapidio.c |   86 +++++++++++++++++++----------
 1 files changed, 56 insertions(+), 30 deletions(-)

diff --git a/arch/mips/cavium-octeon/octeon-rapidio.c b/arch/mips/cavium-octeon/octeon-rapidio.c
index 4e8d428..0fcef1d 100644
--- a/arch/mips/cavium-octeon/octeon-rapidio.c
+++ b/arch/mips/cavium-octeon/octeon-rapidio.c
@@ -441,6 +441,35 @@ static void octeon_rio_tx_doorbell(struct rio_mport *mport)
 }
 
 /**
+ * Since SRIO interrupts also propagate to CIU_INTX_SUM0[RML] without
+ * any mask bits, we need to manually enable and disable SRIO interrupts
+ * as a set. This macro sets the bits we care about in the enable and
+ * status register.
+ */
+#define SET_IRQ_FIELD_BITS(reg, value)  \
+	reg.s.link_dwn = value;         \
+	reg.s.link_up = value;          \
+	reg.s.rxbell = value;           \
+	reg.s.bell_err = value;         \
+	reg.s.txbell = value;           \
+	reg.s.soft_rx = value;
+
+/**
+ * Enable or disable SRIO interrupts this driver cares about.
+ *
+ * @param mport  SRIO master port to enable/disable is for
+ * @param enable
+ */
+static void octeon_rio_irq_set_enable(struct rio_mport *mport, int enable)
+{
+	cvmx_sriox_int_enable_t int_enable;
+	/* Enable the interrupts we care about */
+	int_enable.u64 = cvmx_read_csr(CVMX_SRIOX_INT_ENABLE(mport->id));
+	SET_IRQ_FIELD_BITS(int_enable, enable);
+	cvmx_write_csr(CVMX_SRIOX_INT_ENABLE(mport->id), int_enable.u64);
+}
+
+/**
  * Delayed work handler for SRIO.
  *
  * @param work   Work to process
@@ -449,36 +478,45 @@ static void octeon_rio_work(struct work_struct *work)
 {
 	struct octeon_rio_port *my_port = container_of(work, struct octeon_rio_port, work);
 	struct rio_mport *mport = &my_port->mport;
-	cvmx_sriox_int_reg_t srio_int_reg;
-
-	/* Get which interrupt fired. Ignore disabled interrupts */
-	srio_int_reg.u64 = cvmx_read_csr(CVMX_SRIOX_INT_REG(mport->id));
-	srio_int_reg.u64 &= cvmx_read_csr(CVMX_SRIOX_INT_ENABLE(mport->id));
-
-	/* Clear the interrupts before we start processing them */
-	cvmx_write_csr(CVMX_SRIOX_INT_REG(mport->id), srio_int_reg.u64);
+	cvmx_sriox_int_reg_t int_reg;
+	cvmx_sriox_int_reg_t int_reg_clear;
+
+	/* Get which interrupt fired */
+	int_reg.u64 = cvmx_read_csr(CVMX_SRIOX_INT_REG(mport->id));
+
+	/* Clear the interrupts before we start processing them. SRIO
+	    interrupts also propagate to CIU_INTX_SUM0[RML] without
+	    any masks. This handler cares about some of these interrupts,
+	    but not others. It must be careful to clear enables and status
+	    for the bits it cares about to stop a possble interrupt lockup
+	    where other SRIO error handlers off of CIU_INTX_SUM0[RML] run
+	    at interrupt context */
+	int_reg_clear.u64 = 0;
+	SET_IRQ_FIELD_BITS(int_reg_clear, 1);
+	int_reg_clear.u64 &= int_reg.u64;
+	cvmx_write_csr(CVMX_SRIOX_INT_REG(mport->id), int_reg_clear.u64);
 
 	/* SRIO Link transitioned up */
-	if (srio_int_reg.s.link_up)
+	if (int_reg.s.link_up)
 		DEBUG_IRQ(mport, "Link up\n");
 
 	/* SRIO Link transitioned down */
-	if (srio_int_reg.s.link_dwn)
+	if (int_reg.s.link_dwn)
 		DEBUG_IRQ(mport, "Link down\n");
 
 	/* Received a doorbell */
-	if (srio_int_reg.s.rxbell)
+	if (int_reg.s.rxbell)
 		octeon_rio_rx_doorbell(mport);
 
 	/* Received a packet to the soft fifo */
-	if (srio_int_reg.s.soft_rx)
+	if (int_reg.s.soft_rx)
 		octeon_rio_rx_soft_fifo(mport);
 
 	/* TX doorbell */
-	if (srio_int_reg.s.bell_err || srio_int_reg.s.txbell)
+	if (int_reg.s.bell_err || int_reg.s.txbell)
 		octeon_rio_tx_doorbell(mport);
 
-	enable_irq(OCTEON_IRQ_SRIO0 + mport->id);
+	octeon_rio_irq_set_enable(mport, 1);
 }
 
 /**
@@ -495,7 +533,7 @@ static irqreturn_t octeon_rio_irq(int irq, void *irq_arg)
 	struct octeon_rio_port *my_port = container_of(mport, struct octeon_rio_port, mport);
 
 	DEBUG_IRQ(mport, "Interrupt\n");
-	disable_irq(irq);
+	octeon_rio_irq_set_enable(mport, 0);
 	schedule_work(&my_port->work);
 	return IRQ_HANDLED;
 }
@@ -523,8 +561,7 @@ static int __init octeon_rio_init(void)
 	srio_ops.unmap = octeon_rio_mem_unmap;
 
 	memset(srio_ports, 0, sizeof(srio_ports));
-	for (srio_port = 0; srio_port < 1; srio_port++) {
-		cvmx_sriox_int_enable_t int_enable;
+	for (srio_port = 0; srio_port < 2; srio_port++) {
 		cvmx_sriox_status_reg_t sriox_status_reg;
 		cvmx_mio_rst_ctlx_t mio_rst_ctl;
 		sriox_status_reg.u64 =
@@ -567,19 +604,8 @@ static int __init octeon_rio_init(void)
 				&srio_ports[srio_port].mport)) {
 				RIO_PRINTK(&srio_ports[srio_port].mport,
 					"Failed to register IRQ handler\n");
-			} else {
-				/* Enable the interrupts we care about */
-				int_enable.u64 = cvmx_read_csr(
-					CVMX_SRIOX_INT_ENABLE(srio_port));
-				int_enable.s.link_dwn = 1;
-				int_enable.s.link_up = 1;
-				int_enable.s.rxbell = 1;
-				int_enable.s.bell_err = 1;
-				int_enable.s.txbell = 1;
-				int_enable.s.soft_rx = 1;
-				cvmx_write_csr(CVMX_SRIOX_INT_ENABLE(srio_port),
-					int_enable.u64);
-			}
+			} else
+				octeon_rio_irq_set_enable(&srio_ports[srio_port].mport, 1);
 		}
 	}
 	return rio_init_mports();
-- 
1.6.5.2

