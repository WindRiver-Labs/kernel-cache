From 1630970643589fa821c64d7269f183de4a4b4e0f Mon Sep 17 00:00:00 2001
From: Phil Staub <Phil.Staub@windriver.com>
Date: Thu, 24 Sep 2009 17:34:38 -0700
Subject: [PATCH] MIPS: Enable Cavium BSP hooks

Install hooks to build Cavium SDK 1.9-based BSP.

The current state of these files reflects an ongoing development
process, and as such implies an extensive modification history that is
not cited in detail here. It is worth noting, however, that this
collection represents the work of the following people who were
involved in that history:

Tomaso Paoletti <tpaoletti@caviumnetworks.com>
David Daney <ddaney@caviumnetworks.com>
Vlad Malov <Vlad.Malov@caviumnetworks.com>
Paul Gortmaker <Paul.Gortmaker@windriver.com>
Yang Shi <yang.shi@windriver.com>
Ralf Baechle <ralf.baechle@windriver.com>
Phil Staub <Phil.Staub@windriver.com>

Signed-off-by: Phil Staub <Phil.Staub@windriver.com>
---
 Makefile                                      |    2 +
 arch/mips/Kconfig                             |   89 ++++++++++++++-
 arch/mips/Kconfig.debug                       |   10 ++
 arch/mips/Makefile                            |   26 ++++-
 arch/mips/cavium-octeon/watchdog_nmi.S        |    2 +-
 arch/mips/kernel/Makefile                     |   14 ++-
 arch/mips/kernel/asm-offsets.c                |   32 +++++
 arch/mips/kernel/binfmt_elfn32.c              |    4 +
 arch/mips/kernel/binfmt_elfo32.c              |    4 +
 arch/mips/kernel/branch.c                     |   30 +++++
 arch/mips/kernel/cevt-r4k.c                   |   22 +++-
 arch/mips/kernel/cpu-probe.c                  |   58 ++++++++--
 arch/mips/kernel/genex.S                      |   19 +++-
 arch/mips/kernel/head.S                       |   16 +++-
 arch/mips/kernel/linux32.c                    |   25 ++++
 arch/mips/kernel/proc.c                       |   25 ++++-
 arch/mips/kernel/ptrace.c                     |  155 ++++++++++++++++++++++++-
 arch/mips/kernel/ptrace32.c                   |   10 ++
 arch/mips/kernel/smp.c                        |    6 +
 arch/mips/kernel/syscall.c                    |   28 +++++
 arch/mips/kernel/traps.c                      |  109 ++++++++++++++++--
 arch/mips/kernel/unaligned.c                  |   37 ++++++
 arch/mips/kernel/vmlinux.lds.S                |   22 ++++
 arch/mips/lib/Makefile                        |    1 +
 arch/mips/lib/iomap.c                         |   14 +++
 arch/mips/math-emu/cp1emu.c                   |   96 +++++++++++++++-
 arch/mips/math-emu/dsemul.c                   |   12 ++
 arch/mips/mm/Makefile                         |   25 ++++-
 arch/mips/mm/c-r4k.c                          |    7 +-
 arch/mips/mm/fault.c                          |   26 ++++
 arch/mips/mm/pgtable-64.c                     |   10 ++
 arch/mips/mm/sc-mips.c                        |    3 +
 arch/mips/mm/uasm.c                           |   90 ++++++++++++++-
 arch/mips/oprofile/Makefile                   |    2 +
 arch/mips/oprofile/common.c                   |    4 +
 crypto/crypto_null.c                          |    4 +
 include/asm-mips/asmmacro.h                   |   10 ++
 include/asm-mips/atomic.h                     |   50 ++++++++
 include/asm-mips/barrier.h                    |   38 ++++++-
 include/asm-mips/bitops.h                     |   33 +++++-
 include/asm-mips/cmpxchg.h                    |    1 +
 include/asm-mips/cpu-info.h                   |    6 +
 include/asm-mips/cpu.h                        |   14 +++
 include/asm-mips/delay.h                      |   35 ++++++
 include/asm-mips/dma.h                        |    7 +
 include/asm-mips/fpu_emulator.h               |    5 +
 include/asm-mips/hazards.h                    |    4 +-
 include/asm-mips/io.h                         |   14 +++
 include/asm-mips/mach-generic/dma-coherence.h |    7 +
 include/asm-mips/mach-generic/mc146818rtc.h   |    2 +
 include/asm-mips/mipsmtregs.h                 |    1 +
 include/asm-mips/module.h                     |    2 +
 include/asm-mips/processor.h                  |   81 +++++++++++++
 include/asm-mips/ptrace.h                     |   50 ++++++++
 include/asm-mips/smp.h                        |    3 +
 include/asm-mips/spinlock.h                   |  128 ++++++++++++++++++++
 include/asm-mips/spinlock_types.h             |    9 ++
 include/asm-mips/stackframe.h                 |   48 ++++++++
 include/asm-mips/sysmips.h                    |    3 +
 include/asm-mips/system.h                     |    4 +
 include/linux/skbuff.h                        |   41 +++++++
 ipc/msg.c                                     |   70 +++++++++++
 lib/hweight.c                                 |    3 +-
 lib/sort.c                                    |   21 ++++
 64 files changed, 1670 insertions(+), 59 deletions(-)

diff --git a/Makefile b/Makefile
index a6cda51..65de76b 100644
--- a/Makefile
+++ b/Makefile
@@ -589,8 +589,10 @@ ifneq ($(KCFLAGS),)
 endif
 
 # Use --build-id when available.
+ifndef CONFIG_BUILD_ID_DISABLE
 LDFLAGS_BUILD_ID = $(patsubst -Wl$(comma)%,%,\
 			      $(call ld-option, -Wl$(comma)--build-id,))
+endif
 LDFLAGS_MODULE += $(LDFLAGS_BUILD_ID)
 LDFLAGS_vmlinux += $(LDFLAGS_BUILD_ID)
 
diff --git a/arch/mips/Kconfig b/arch/mips/Kconfig
index 1b6c98f..d17e0a4 100644
--- a/arch/mips/Kconfig
+++ b/arch/mips/Kconfig
@@ -598,6 +598,55 @@ config WR_PPMC
 	  This enables support for the Wind River MIPS32 4KC PPMC evaluation
 	  board, which is based on GT64120 bridge chip.
 
+config CAVIUM_OCTEON_SIMULATOR
+	bool "Support for the Cavium Networks Octeon Simulator"
+	select CEVT_R4K
+	select 64BIT_PHYS_ADDR
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_HIGHMEM
+	select SYS_SUPPORTS_HOTPLUG_CPU
+	select SYS_SUPPORTS_KGDB
+	select SYS_HAS_EARLY_PRINTK
+	select CPU_CAVIUM_OCTEON
+	help
+	  The Octeon simulator is software performance model of the Cavium
+	  Octeon Processor. It supports simulating Octeon processors on x86
+	  hardware.
+
+config CAVIUM_OCTEON_REFERENCE_BOARD
+	bool "Support for the Cavium Networks Octeon reference board"
+	select CEVT_R4K
+	select 64BIT_PHYS_ADDR
+	select SYS_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_BIG_ENDIAN
+	select SYS_SUPPORTS_EDAC
+	select SYS_SUPPORTS_HIGHMEM
+	select SYS_SUPPORTS_HOTPLUG_CPU
+	select SYS_R4K_CVET_HWTIMER 
+	select SYS_SUPPORTS_KGDB
+	select SYS_HAS_EARLY_PRINTK
+	select CPU_CAVIUM_OCTEON
+	select SWAP_IO_SPACE
+	select HW_HAS_PCI
+	select ARCH_SUPPORTS_MSI
+	select ISA
+	select GENERIC_ISA_DMA
+	select ARCH_MAY_HAVE_PC_FDC
+	help
+	  This option supports all of the Octeon reference boards from Cavium
+	  Networks. It builds a kernel that dynamically determines the Octeon
+	  CPU type and supports all known board reference implementations.
+	  Some of the supported boards are:
+		EBT3000
+		EBH3000
+		EBH3100
+		Asus NA-038
+		Thunder
+		Kodama
+		Hikari
+	  Say Y here for most Octeon reference boards.
+
 endchoice
 
 source "arch/mips/au1000/Kconfig"
@@ -609,6 +658,7 @@ source "arch/mips/sgi-ip27/Kconfig"
 source "arch/mips/sibyte/Kconfig"
 source "arch/mips/txx9/Kconfig"
 source "arch/mips/vr41xx/Kconfig"
+source "arch/mips/cavium-octeon/Kconfig"
 
 endmenu
 
@@ -854,6 +904,9 @@ config IRQ_GT641XX
 config IRQ_GIC
 	bool
 
+config IRQ_CPU_OCTEON
+	bool
+
 config MIPS_BOARDS_GEN
 	bool
 
@@ -928,7 +981,7 @@ config BOOT_ELF32
 config MIPS_L1_CACHE_SHIFT
 	int
 	default "4" if MACH_DECSTATION || MIKROTIK_RB532
-	default "7" if SGI_IP22 || SGI_IP27 || SGI_IP28 || SNI_RM
+	default "7" if SGI_IP22 || SGI_IP27 || SGI_IP28 || SNI_RM || CPU_CAVIUM_OCTEON
 	default "4" if PMC_MSP4200_EVAL
 	default "5"
 
@@ -1179,6 +1232,22 @@ config CPU_SB1
 	select CPU_SUPPORTS_HIGHMEM
 	select WEAK_ORDERING
 
+config CPU_CAVIUM_OCTEON
+	bool "Cavium Octeon processor"
+	select IRQ_CPU
+	select IRQ_CPU_OCTEON
+	select CPU_HAS_PREFETCH
+	select CPU_SUPPORTS_64BIT_KERNEL
+	select SYS_SUPPORTS_SMP
+	select NR_CPUS_DEFAULT_16
+	select WEAK_ORDERING
+	select CPU_SUPPORTS_HIGHMEM
+	help
+	  The Cavium Octeon processor is a highly integrated chip containing
+	  many ethernet hardware widgets for networking tasks. The processor
+	  can have up to 16 Mips64v2 cores and 8 integrated gigabit ethernets.
+	  Full details can be found at http://www.caviumnetworks.com.
+
 endchoice
 
 config SYS_HAS_CPU_LOONGSON2
@@ -1278,7 +1347,7 @@ config CPU_MIPSR1
 
 config CPU_MIPSR2
 	bool
-	default y if CPU_MIPS32_R2 || CPU_MIPS64_R2
+	default y if CPU_MIPS32_R2 || CPU_MIPS64_R2 || CPU_CAVIUM_OCTEON
 
 config SYS_SUPPORTS_32BIT_KERNEL
 	bool
@@ -1289,6 +1358,13 @@ config CPU_SUPPORTS_32BIT_KERNEL
 config CPU_SUPPORTS_64BIT_KERNEL
 	bool
 
+#
+# Set to y for ptrace access to watch registers.
+#
+config HARDWARE_WATCHPOINTS
+       bool
+       default y if CPU_MIPSR1 || CPU_MIPSR2
+
 menu "Kernel type"
 
 choice
@@ -1908,6 +1984,15 @@ config SECCOMP
 
 	  If unsure, say Y. Only embedded should say N here.
 
+config MIPS_FPU_EMULATOR_STATS_ENABLED
+	bool "Enable FPU emulator statics"
+	depends on SMP
+	default n
+	help
+	  On SMP systems the FPU emulator statistics cause huge amounts of cross CPU
+	  memory traffic that isn't really needed. Nobody actually has any way of
+	  reading these statistics.
+
 endmenu
 
 config RWSEM_GENERIC_SPINLOCK
diff --git a/arch/mips/Kconfig.debug b/arch/mips/Kconfig.debug
index 765c8e2..3121668 100644
--- a/arch/mips/Kconfig.debug
+++ b/arch/mips/Kconfig.debug
@@ -42,6 +42,16 @@ config SB1XXX_CORELIS
 	  Select compile flags that produce code that can be processed by the
 	  Corelis mksym utility and UDB Emulator.
 
+config CAVIUM_GDB
+	bool "Remote GDB debugging using the Cavium Networks Multicore GDB"
+	depends on DEBUG_KERNEL
+	depends on CPU_CAVIUM_OCTEON
+	select DEBUG_INFO
+	help
+	  If you say Y here, it will be possible to remotely debug the MIPS
+	  kernel using the Cavium Networks GDB with extended SMP support.
+	  This is only useful for kernel hackers. If unsure, say N.
+
 config RUNTIME_DEBUG
 	bool "Enable run-time debugging"
 	depends on DEBUG_KERNEL
diff --git a/arch/mips/Makefile b/arch/mips/Makefile
index 84b5241..37f6e8e 100644
--- a/arch/mips/Makefile
+++ b/arch/mips/Makefile
@@ -15,7 +15,8 @@
 KBUILD_DEFCONFIG := ip22_defconfig
 
 ifndef CONFIG_FTRACE
-cflags-y := -ffunction-sections
+#cflags-y := -ffunction-sections
+cflags-y :=
 endif
 
 #
@@ -144,6 +145,7 @@ cflags-$(CONFIG_CPU_SB1)	+= $(call cc-option,-march=sb1,-march=r5000) \
 cflags-$(CONFIG_CPU_R8000)	+= -march=r8000 -Wa,--trap
 cflags-$(CONFIG_CPU_R10000)	+= $(call cc-option,-march=r10000,-march=r8000) \
 			-Wa,--trap
+cflags-$(CONFIG_CPU_CAVIUM_OCTEON) += -march=octeon -Wa,--trap
 
 cflags-$(CONFIG_CPU_R4000_WORKAROUNDS)	+= $(call cc-option,-mfix-r4000,)
 cflags-$(CONFIG_CPU_R4400_WORKAROUNDS)	+= $(call cc-option,-mfix-r4400,)
@@ -579,6 +581,28 @@ core-$(CONFIG_TOSHIBA_RBTX4927)	+= arch/mips/txx9/rbtx4927/
 #
 core-$(CONFIG_TOSHIBA_RBTX4938) += arch/mips/txx9/rbtx4938/
 
+#
+# Cavium Octeon
+#
+ifdef CONFIG_CPU_CAVIUM_OCTEON
+# first choice is to use headers from sysroot (if present), else from
+# kernel tree 
+OCTEON_ROOT_IN_KERNEL = $(srctree)/arch/mips/cavium-octeon
+OCTEON_ROOT = $(srctree)/../../host-cross/mips-wrs-linux-gnu/sysroot/usr/include/simple_exec_open
+
+CAVIUM_INCLUDES := -I$(OCTEON_ROOT)/target/include \
+		   -I$(OCTEON_ROOT_IN_KERNEL)/executive
+endif
+
+core-$(CONFIG_CPU_CAVIUM_OCTEON)	+= arch/mips/cavium-octeon/
+cflags-$(CONFIG_CPU_CAVIUM_OCTEON)	+= -I$(srctree)/include/asm-mips/mach-cavium-octeon ${CAVIUM_INCLUDES}
+core-$(CONFIG_CPU_CAVIUM_OCTEON)	+= arch/mips/cavium-octeon/gpl-executive/
+ifdef CONFIG_CAVIUM_OCTEON_2ND_KERNEL
+load-$(CONFIG_CPU_CAVIUM_OCTEON)	+= 0xffffffff84100000
+else
+load-$(CONFIG_CPU_CAVIUM_OCTEON) 	+= 0xffffffff81100000
+endif
+
 cflags-y			+= -Iinclude/asm-mips/mach-generic
 drivers-$(CONFIG_PCI)		+= arch/mips/pci/
 
diff --git a/arch/mips/cavium-octeon/watchdog_nmi.S b/arch/mips/cavium-octeon/watchdog_nmi.S
index 8861d29..08dff56 100644
--- a/arch/mips/cavium-octeon/watchdog_nmi.S
+++ b/arch/mips/cavium-octeon/watchdog_nmi.S
@@ -21,7 +21,7 @@
 	// For the next few instructions running the debugger may cause
 	// corruption of k0 in the saved registers. Since we're about to
 	// crash, nobody probably cares.
-        dmtc0	k0, CP0_DESAVE			// Save K0 into the debug
+	dmtc0	k0, CP0_DESAVE			// Save K0 into the debug
 						//  scratch register
 	dmfc0	k0, CP0_CVMMEMCTL		// Use K0 to do a
 						//  read/modify/write of
diff --git a/arch/mips/kernel/Makefile b/arch/mips/kernel/Makefile
index 8972f5e..5d58445 100644
--- a/arch/mips/kernel/Makefile
+++ b/arch/mips/kernel/Makefile
@@ -6,7 +6,7 @@ extra-y		:= head.o init_task.o vmlinux.lds
 
 obj-y		+= cpu-probe.o branch.o entry.o genex.o irq.o process.o \
 		   ptrace.o reset.o setup.o signal.o syscall.o \
-		   time.o topology.o traps.o unaligned.o
+		   time.o topology.o traps.o unaligned.o watch.o
 
 obj-$(CONFIG_CEVT_BCM1480)	+= cevt-bcm1480.o
 obj-$(CONFIG_CEVT_R4K)		+= cevt-r4k.o
@@ -42,6 +42,7 @@ obj-$(CONFIG_CPU_SB1)		+= r4k_fpu.o r4k_switch.o
 obj-$(CONFIG_CPU_TX39XX)	+= r2300_fpu.o r2300_switch.o
 obj-$(CONFIG_CPU_TX49XX)	+= r4k_fpu.o r4k_switch.o
 obj-$(CONFIG_CPU_VR41XX)	+= r4k_fpu.o r4k_switch.o
+obj-$(CONFIG_CPU_CAVIUM_OCTEON)	+= octeon_switch.o
 
 obj-$(CONFIG_DYNAMIC_FTRACE)	+= ftrace.o
 
@@ -67,6 +68,7 @@ obj-$(CONFIG_MIPS_MSC)		+= irq-msc01.o
 obj-$(CONFIG_IRQ_TXX9)		+= irq_txx9.o
 obj-$(CONFIG_IRQ_GT641XX)	+= irq-gt641xx.o
 obj-$(CONFIG_IRQ_GIC)		+= irq-gic.o
+obj-$(CONFIG_IRQ_CPU_OCTEON)	+= irq-octeon.o
 
 obj-$(CONFIG_32BIT)		+= scall32-o32.o
 obj-$(CONFIG_64BIT)		+= scall64-64.o
@@ -92,3 +94,13 @@ CFLAGS_cpu-bugs64.o	= $(shell if $(CC) $(KBUILD_CFLAGS) -Wa,-mdaddi -c -o /dev/n
 obj-$(CONFIG_HAVE_STD_PC_SERIAL_PORT)	+= 8250-platform.o
 
 #EXTRA_CFLAGS += -Werror
+
+ifdef CONFIG_CPU_CAVIUM_OCTEON
+OCTEON_ROOT_IN_KERNEL = $(srctree)/arch/mips/cavium-octeon
+OCTEON_ROOT = $(srctree)/../../host-cross/mips-wrs-linux-gnu/sysroot/usr/include/simple_exec_open
+
+CFLAGS_irq-octeon.o    = -I$(OCTEON_ROOT)/target/include \
+			 -I$(OCTEON_ROOT_IN_KERNEL)/executive
+CFLAGS_ptrace.o        = -I$(OCTEON_ROOT)/target/include \
+			 -I$(OCTEON_ROOT_IN_KERNEL)/executive
+endif
diff --git a/arch/mips/kernel/asm-offsets.c b/arch/mips/kernel/asm-offsets.c
index 8674829..0bdf5ac 100644
--- a/arch/mips/kernel/asm-offsets.c
+++ b/arch/mips/kernel/asm-offsets.c
@@ -65,6 +65,10 @@ void output_ptreg_defines(void)
 #ifdef CONFIG_MIPS_MT_SMTC
 	OFFSET(PT_TCSTATUS, pt_regs, cp0_tcstatus);
 #endif /* CONFIG_MIPS_MT_SMTC */
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	OFFSET(PT_MPL, pt_regs, mpl);
+	OFFSET(PT_MTP, pt_regs, mtp);
+#endif /* CONFIG_CPU_CAVIUM_OCTEON */
 	DEFINE(PT_SIZE, sizeof(struct pt_regs));
 	BLANK();
 }
@@ -297,6 +301,34 @@ void output_irq_cpustat_t_defines(void)
 	BLANK();
 }
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+void output_octeon_cop2_state_defines(void)
+{
+	COMMENT("Octeon specific octeon_cop2_state offsets.");
+	OFFSET(OCTEON_CP2_CRC_IV,	octeon_cop2_state, cop2_crc_iv);
+	OFFSET(OCTEON_CP2_CRC_LENGTH,	octeon_cop2_state, cop2_crc_length);
+	OFFSET(OCTEON_CP2_CRC_POLY,	octeon_cop2_state, cop2_crc_poly);
+	OFFSET(OCTEON_CP2_LLM_DAT,	octeon_cop2_state, cop2_llm_dat);
+	OFFSET(OCTEON_CP2_3DES_IV,	octeon_cop2_state, cop2_3des_iv);
+	OFFSET(OCTEON_CP2_3DES_KEY,	octeon_cop2_state, cop2_3des_key);
+	OFFSET(OCTEON_CP2_3DES_RESULT,	octeon_cop2_state, cop2_3des_result);
+	OFFSET(OCTEON_CP2_AES_INP0,	octeon_cop2_state, cop2_aes_inp0);
+	OFFSET(OCTEON_CP2_AES_IV,	octeon_cop2_state, cop2_aes_iv);
+	OFFSET(OCTEON_CP2_AES_KEY,	octeon_cop2_state, cop2_aes_key);
+	OFFSET(OCTEON_CP2_AES_KEYLEN,	octeon_cop2_state, cop2_aes_keylen);
+	OFFSET(OCTEON_CP2_AES_RESULT,	octeon_cop2_state, cop2_aes_result);
+	OFFSET(OCTEON_CP2_GFM_MULT,	octeon_cop2_state, cop2_gfm_mult);
+	OFFSET(OCTEON_CP2_GFM_POLY,	octeon_cop2_state, cop2_gfm_poly);
+	OFFSET(OCTEON_CP2_GFM_RESULT,	octeon_cop2_state, cop2_gfm_result);
+	OFFSET(OCTEON_CP2_HSH_DATW,	octeon_cop2_state, cop2_hsh_datw);
+	OFFSET(OCTEON_CP2_HSH_IVW,	octeon_cop2_state, cop2_hsh_ivw);
+	OFFSET(THREAD_CP2,	task_struct, thread.cp2);
+	OFFSET(THREAD_CVMSEG,	task_struct, thread.cvmseg.cvmseg);
+	BLANK();
+}
+#endif
+
+
 #ifdef CONFIG_HIBERNATION
 void output_pbe_defines(void)
 {
diff --git a/arch/mips/kernel/binfmt_elfn32.c b/arch/mips/kernel/binfmt_elfn32.c
index ddb854a..65f934f 100644
--- a/arch/mips/kernel/binfmt_elfn32.c
+++ b/arch/mips/kernel/binfmt_elfn32.c
@@ -46,7 +46,11 @@ typedef elf_fpreg_t elf_fpregset_t[ELF_NFPREG];
 	__res;								\
 })
 
+#ifdef CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB
+#define TASK32_SIZE		(0x7fff8000UL - (CONFIG_CAVIUM_RESERVE32<<20))
+#else
 #define TASK32_SIZE		0x7fff8000UL
+#endif
 #undef ELF_ET_DYN_BASE
 #define ELF_ET_DYN_BASE         (TASK32_SIZE / 3 * 2)
 
diff --git a/arch/mips/kernel/binfmt_elfo32.c b/arch/mips/kernel/binfmt_elfo32.c
index 515c43a..83616e3 100644
--- a/arch/mips/kernel/binfmt_elfo32.c
+++ b/arch/mips/kernel/binfmt_elfo32.c
@@ -48,7 +48,11 @@ typedef elf_fpreg_t elf_fpregset_t[ELF_NFPREG];
 	__res;								\
 })
 
+#ifdef CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB
+#define TASK32_SIZE		(0x7fff8000UL - (CONFIG_CAVIUM_RESERVE32<<20))
+#else
 #define TASK32_SIZE		0x7fff8000UL
+#endif
 #undef ELF_ET_DYN_BASE
 #define ELF_ET_DYN_BASE         (TASK32_SIZE / 3 * 2)
 
diff --git a/arch/mips/kernel/branch.c b/arch/mips/kernel/branch.c
index 6b5df8b..15256c6 100644
--- a/arch/mips/kernel/branch.c
+++ b/arch/mips/kernel/branch.c
@@ -205,6 +205,36 @@ int __compute_return_epc(struct pt_regs *regs)
 			break;
 		}
 		break;
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	case lwc2_op: /* This is bbit0 on Octeon */
+		if ((regs->regs[insn.i_format.rs] & (1ull<<insn.i_format.rt)) == 0)
+			epc = epc + 4 + (insn.i_format.simmediate << 2);
+		else
+			epc += 8;
+		regs->cp0_epc = epc;
+		break;
+	case ldc2_op: /* This is bbit032 on Octeon */
+		if ((regs->regs[insn.i_format.rs] & (1ull<<(insn.i_format.rt+32))) == 0)
+			epc = epc + 4 + (insn.i_format.simmediate << 2);
+		else
+			epc += 8;
+		regs->cp0_epc = epc;
+		break;
+	case swc2_op: /* This is bbit1 on Octeon */
+		if (regs->regs[insn.i_format.rs] & (1ull<<insn.i_format.rt))
+			epc = epc + 4 + (insn.i_format.simmediate << 2);
+		else
+			epc += 8;
+		regs->cp0_epc = epc;
+		break;
+	case sdc2_op: /* This is bbit132 on Octeon */
+		if (regs->regs[insn.i_format.rs] & (1ull<<(insn.i_format.rt+32)))
+			epc = epc + 4 + (insn.i_format.simmediate << 2);
+		else
+			epc += 8;
+		regs->cp0_epc = epc;
+		break;
+#endif
 	}
 
 	return 0;
diff --git a/arch/mips/kernel/cevt-r4k.c b/arch/mips/kernel/cevt-r4k.c
index 9e5a8d3..845690c 100644
--- a/arch/mips/kernel/cevt-r4k.c
+++ b/arch/mips/kernel/cevt-r4k.c
@@ -48,6 +48,7 @@ static struct hwtimer mips_hwtimer = {
 	.hook = NULL,
 	.hook_data = NULL
 };
+static atomic_t hwtimer_cpu_trigger[NR_CPUS];
 #endif
 
 static int mips_next_event(unsigned long delta,
@@ -104,10 +105,15 @@ irqreturn_t c0_compare_interrupt(int irq, void *dev_id)
 	}
 
 #if defined (CONFIG_SYS_R4K_CVET_HWTIMER) && defined (CONFIG_HWTIMER_HOOKS)
-	spin_lock(mips_hwtimer.lock);
-	if (mips_hwtimer.hook != NULL)
-		(mips_hwtimer.hook)(mips_hwtimer.hook_data);
-	spin_unlock(mips_hwtimer.lock);
+	if (atomic_dec_and_test(&hwtimer_cpu_trigger[smp_processor_id()])) {
+		atomic_set(&hwtimer_cpu_trigger[smp_processor_id()],
+			   num_online_cpus());
+
+		spin_lock(mips_hwtimer.lock);
+		if (mips_hwtimer.hook != NULL)
+			(mips_hwtimer.hook)(mips_hwtimer.hook_data);
+		spin_unlock(mips_hwtimer.lock);
+	}
 #endif
 out:
 	return IRQ_HANDLED;
@@ -209,7 +215,13 @@ int __cpuinit mips_clockevent_init(void)
 		return -ENXIO;
 
 #if defined (CONFIG_SYS_R4K_CVET_HWTIMER) && defined (CONFIG_HWTIMER_HOOKS)
-	register_hwtimer(&mips_hwtimer);
+	if (smp_processor_id() == 0) {
+		unsigned int i;
+		for_each_possible_cpu(i)
+			atomic_set(&hwtimer_cpu_trigger[i], i + 1);
+
+		register_hwtimer(&mips_hwtimer);
+	}
 #endif
 	/*
 	 * With vectored interrupts things are getting platform specific.
diff --git a/arch/mips/kernel/cpu-probe.c b/arch/mips/kernel/cpu-probe.c
index ef7ed93..b68e14e 100644
--- a/arch/mips/kernel/cpu-probe.c
+++ b/arch/mips/kernel/cpu-probe.c
@@ -21,6 +21,7 @@
 #include <asm/fpu.h>
 #include <asm/mipsregs.h>
 #include <asm/system.h>
+#include <asm/watch.h>
 
 /*
  * Not all of the MIPS CPUs have the "wait" instruction available. Moreover,
@@ -155,6 +156,7 @@ void __init check_wait(void)
 	case CPU_25KF:
 	case CPU_PR4450:
 	case CPU_BCM3302:
+	case CPU_CAVIUM_OCTEON:
 		cpu_wait = r4k_wait;
 		break;
 
@@ -653,21 +655,24 @@ static inline unsigned int decode_config3(struct cpuinfo_mips *c)
 
 static void __cpuinit decode_configs(struct cpuinfo_mips *c)
 {
+	int ok;
+
 	/* MIPS32 or MIPS64 compliant CPU.  */
 	c->options = MIPS_CPU_4KEX | MIPS_CPU_4K_CACHE | MIPS_CPU_COUNTER |
 	             MIPS_CPU_DIVEC | MIPS_CPU_LLSC | MIPS_CPU_MCHECK;
 
 	c->scache.flags = MIPS_CACHE_NOT_PRESENT;
 
-	/* Read Config registers.  */
-	if (!decode_config0(c))
-		return;			/* actually worth a panic() */
-	if (!decode_config1(c))
-		return;
-	if (!decode_config2(c))
-		return;
-	if (!decode_config3(c))
-		return;
+	ok = decode_config0(c);			/* Read Config registers.  */
+	BUG_ON(!ok);				/* Arch spec violation!  */
+	if (ok)
+		ok = decode_config1(c);
+	if (ok)
+		ok = decode_config2(c);
+	if (ok)
+		ok = decode_config3(c);
+
+	mips_probe_watch_registers(c);
 }
 
 #ifdef CONFIG_CPU_MIPSR2
@@ -815,6 +820,36 @@ static inline void cpu_probe_broadcom(struct cpuinfo_mips *c)
 	}
 }
 
+static inline void cpu_probe_cavium(struct cpuinfo_mips *c)
+{
+	switch (c->processor_id & 0xff00) {
+	case PRID_IMP_CAVIUM_CN38XX:
+	case PRID_IMP_CAVIUM_CN31XX:
+	case PRID_IMP_CAVIUM_CN30XX:
+	case PRID_IMP_CAVIUM_CN58XX:
+	case PRID_IMP_CAVIUM_CN56XX:
+	case PRID_IMP_CAVIUM_CN50XX:
+	case PRID_IMP_CAVIUM_CN52XX:
+		c->cputype = CPU_CAVIUM_OCTEON;
+		break;
+	default:
+		printk(KERN_INFO "Unknown Octeon chip!\n");
+		c->cputype = CPU_UNKNOWN;
+		break;
+	}
+
+	c->isa_level = MIPS_CPU_ISA_M64R2;
+	c->options = MIPS_CPU_TLB |     /* CPU has TLB */
+		     MIPS_CPU_4KEX |    /* "R4K" exception model */
+		     MIPS_CPU_COUNTER | /* Cycle count/compare */
+		     MIPS_CPU_WATCH |   /* watchpoint registers */
+		     MIPS_CPU_DIVEC |   /* dedicated int vector */
+		     MIPS_CPU_EJTAG |   /* EJTAG exception */
+		     MIPS_CPU_LLSC;     /* CPU has ll/sc instructions */
+	decode_config1(c);
+	mips_probe_watch_registers(c);
+}
+
 const char *__cpu_name[NR_CPUS];
 
 /*
@@ -896,6 +931,8 @@ static __cpuinit const char *cpu_to_name(struct cpuinfo_mips *c)
 	case CPU_BCM4710:	name = "Broadcom BCM4710"; break;
 	case CPU_PR4450:	name = "Philips PR4450"; break;
 	case CPU_LOONGSON2:	name = "ICT Loongson-2"; break;
+	case CPU_CAVIUM_OCTEON:	name = "Cavium Octeon"; break;
+
 	default:
 		BUG();
 	}
@@ -938,6 +975,9 @@ __cpuinit void cpu_probe(void)
 	case PRID_COMP_NXP:
 		cpu_probe_nxp(c);
 		break;
+	case PRID_COMP_CAVIUM:
+		cpu_probe_cavium(c);
+		break;
 	default:
 		c->cputype = CPU_UNKNOWN;
 	}
diff --git a/arch/mips/kernel/genex.S b/arch/mips/kernel/genex.S
index 01dcbe3..691ec3f 100644
--- a/arch/mips/kernel/genex.S
+++ b/arch/mips/kernel/genex.S
@@ -190,6 +190,9 @@ NESTED(handle_int, PT_SIZE, sp)
 	and	k0, ST0_IE
 	bnez	k0, 1f
 
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	LONG_L	k0, FAST_ACCESS_THREAD_OFFSET($0)
+#endif
 	eret
 #endif
 1:
@@ -365,10 +368,7 @@ NESTED(nmi_handler, PT_SIZE, sp)
 	SAVE_ALL
  	move	a0, sp
 	jal	nmi_exception_handler
-	RESTORE_ALL
-	.set	mips3
-	eret
-	.set	pop
+	RESTORE_ALL_AND_RET
 	END(nmi_handler)
 
 	.macro	__build_clear_none
@@ -453,7 +453,15 @@ NESTED(nmi_handler, PT_SIZE, sp)
 	BUILD_HANDLER tr tr sti silent			/* #13 */
 	BUILD_HANDLER fpe fpe fpe silent		/* #15 */
 	BUILD_HANDLER mdmx mdmx sti silent		/* #22 */
+#ifdef 	CONFIG_HARDWARE_WATCHPOINTS
+	/*
+	 * For watch, interrupts will be enabled after the watch
+	 * registers are read.
+	 */
+	BUILD_HANDLER watch watch cli silent		/* #23 */
+#else
 	BUILD_HANDLER watch watch sti verbose		/* #23 */
+#endif
 	BUILD_HANDLER mcheck mcheck cli verbose		/* #24 */
 	BUILD_HANDLER mt mt sti silent			/* #25 */
 	BUILD_HANDLER dsp dsp sti silent		/* #26 */
@@ -520,6 +528,9 @@ NESTED(nmi_handler, PT_SIZE, sp)
 	ori	k1, _THREAD_MASK
 	xori	k1, _THREAD_MASK
 	LONG_L	v1, TI_TP_VALUE(k1)
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	move	k0, v1
+#endif
 	.set	mips3
 	eret
 	.set	mips0
diff --git a/arch/mips/kernel/head.S b/arch/mips/kernel/head.S
index 492a0a8..c820a80 100644
--- a/arch/mips/kernel/head.S
+++ b/arch/mips/kernel/head.S
@@ -106,7 +106,11 @@
 	.endm
 
 	.macro	setup_c0_status_pri
-#ifdef CONFIG_64BIT
+#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_CAVIUM_OCTEON)
+	/*
+	 * Note: We always set ST0_KX on Octeon since IO addresses are at
+	 * 64bit addresses. Keep in mind this also moves the TLB handler.
+	 */
 	setup_c0_status ST0_KX 0
 #else
 	setup_c0_status 0 0
@@ -114,7 +118,11 @@
 	.endm
 
 	.macro	setup_c0_status_sec
-#ifdef CONFIG_64BIT
+#if defined(CONFIG_64BIT) || defined(CONFIG_CPU_CAVIUM_OCTEON)
+	/*
+	 * Note: We always set ST0_KX on Octeon since IO addresses are at
+	 * 64bit addresses. Keep in mind this also moves the TLB handler.
+	 */
 	setup_c0_status ST0_KX ST0_BEV
 #else
 	setup_c0_status 0 ST0_BEV
@@ -196,7 +204,11 @@ NESTED(kernel_entry, 16, sp)			# kernel entry point
 	j		start_kernel
 	END(kernel_entry)
 
+/* You can't do this on Cavium (or maybe all MIPS64 SMP) or you will error on:
+   relocation truncated to fit: R_MIPS_PC16 against `smp_bootstrap'  */
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
 	__CPUINIT
+#endif
 
 #ifdef CONFIG_SMP
 /*
diff --git a/arch/mips/kernel/linux32.c b/arch/mips/kernel/linux32.c
index 645f6d2..2369ea1 100644
--- a/arch/mips/kernel/linux32.c
+++ b/arch/mips/kernel/linux32.c
@@ -365,6 +365,31 @@ SYSCALL_DEFINE5(n32_msgrcv, int, msqid, u32, msgp, size_t, msgsz,
 	return compat_sys_msgrcv(msqid, msgsz, msgtyp, msgflg, IPC_64,
 				 compat_ptr(msgp));
 }
+
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+asmlinkage long sysn32_rt_sigtimedwait(const uint32_t __user *uthese,
+	siginfo_t __user *uinfo, const struct compat_timespec __user *uts32,
+	size_t sigsetsize)
+{
+	struct timespec __user *uts = NULL;
+	sigset_t __user *these = compat_alloc_user_space(sizeof(sigset_t));
+
+	if (uts32) {
+		struct timespec ts;
+		uts = compat_alloc_user_space(sizeof(struct timespec));
+		if (get_user(ts.tv_sec, &uts32->tv_sec) ||
+			get_user(ts.tv_nsec, &uts32->tv_nsec) ||
+			copy_to_user (uts, &ts, sizeof (ts)))
+			return -EFAULT;
+	}
+	/* Fix signal mask. Userspace filled in 32bit numbers, Kernel expects
+	   64bit numbers */
+	these->sig[0] = (uint64_t)uthese[0] | ((uint64_t)uthese[1]<<32);
+	these->sig[1] = (uint64_t)uthese[2] | ((uint64_t)uthese[3]<<32);
+	return sys_rt_sigtimedwait(these, uinfo, uts, sigsetsize);
+}
+#endif	/* CAVIUM */
+
 #endif
 
 struct sysctl_args32
diff --git a/arch/mips/kernel/proc.c b/arch/mips/kernel/proc.c
index 72382aa..a1eadcb 100644
--- a/arch/mips/kernel/proc.c
+++ b/arch/mips/kernel/proc.c
@@ -19,15 +19,23 @@ unsigned int vced_count, vcei_count;
 
 static int show_cpuinfo(struct seq_file *m, void *v)
 {
+	unsigned int version;
+	unsigned int fp_vers;
 	unsigned long n = (unsigned long) v - 1;
-	unsigned int version = cpu_data[n].processor_id;
-	unsigned int fp_vers = cpu_data[n].fpu_id;
 	char fmt [64];
+	int i;
 	int cpu;
 
+	preempt_disable();
+	version = current_cpu_data.processor_id;
+	fp_vers = current_cpu_data.fpu_id;
+
 #ifdef CONFIG_SMP
 	if (!cpu_isset(n, cpu_online_map))
+	{
+		preempt_enable();
 		return 0;
+	}
 #endif
 
 	/*
@@ -53,8 +61,16 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 	seq_printf(m, "tlb_entries\t\t: %d\n", cpu_data[n].tlbsize);
 	seq_printf(m, "extra interrupt vector\t: %s\n",
 	              cpu_has_divec ? "yes" : "no");
-	seq_printf(m, "hardware watchpoint\t: %s\n",
-	              cpu_has_watch ? "yes" : "no");
+	seq_printf(m, "hardware watchpoint\t: %s",
+		   cpu_has_watch ? "yes, " : "no\n");
+	if (cpu_has_watch) {
+		seq_printf(m, "count: %d, address/irw mask: [",
+			   cpu_data[n].watch_reg_count);
+		for (i = 0; i < cpu_data[n].watch_reg_count; i++)
+			seq_printf(m, "%s0x%04x", i ? ", " : "" ,
+				   cpu_data[n].watch_reg_masks[i]);
+		seq_printf(m, "]\n");
+	}
 	seq_printf(m, "ASEs implemented\t:%s%s%s%s%s%s\n",
 		      cpu_has_mips16 ? " mips16" : "",
 		      cpu_has_mdmx ? " mdmx" : "",
@@ -73,6 +89,7 @@ static int show_cpuinfo(struct seq_file *m, void *v)
 	seq_printf(m, fmt, 'I', vcei_count);
 	seq_printf(m, "\n");
 
+	preempt_enable();
 	return 0;
 }
 
diff --git a/arch/mips/kernel/ptrace.c b/arch/mips/kernel/ptrace.c
index e838ef2..adcef26 100644
--- a/arch/mips/kernel/ptrace.c
+++ b/arch/mips/kernel/ptrace.c
@@ -40,6 +40,11 @@
 #include <asm/bootinfo.h>
 #include <asm/reg.h>
 
+#if defined(CONFIG_CPU_CAVIUM_OCTEON) && defined(CONFIG_64BIT)
+#include "cvmx-app-init.h"
+extern cvmx_bootinfo_t *octeon_bootinfo;
+#endif
+
 /*
  * Called by kernel/ptrace.c when detaching..
  *
@@ -47,7 +52,8 @@
  */
 void ptrace_disable(struct task_struct *child)
 {
-	/* Nothing to do.. */
+	/* Don't load the watchpoint registers for the ex-child. */
+	clear_tsk_thread_flag(child, TIF_LOAD_WATCH);
 }
 
 /*
@@ -168,6 +174,93 @@ int ptrace_setfpregs(struct task_struct *child, __u32 __user *data)
 	return 0;
 }
 
+int ptrace_get_watch_regs(struct task_struct *child,
+			  struct pt_watch_regs __user *addr)
+{
+	enum pt_watch_style style;
+	int i;
+
+	if (!cpu_has_watch || current_cpu_data.watch_reg_use_cnt == 0)
+		return -EIO;
+	if (!access_ok(VERIFY_WRITE, addr, sizeof(struct pt_watch_regs)))
+		return -EIO;
+
+#ifdef CONFIG_32BIT
+	style = pt_watch_style_mips32;
+#define WATCH_STYLE mips32
+#else
+	style = pt_watch_style_mips64;
+#define WATCH_STYLE mips64
+#endif
+
+	__put_user(style, &addr->style);
+	__put_user(current_cpu_data.watch_reg_use_cnt,
+		   &addr->WATCH_STYLE.num_valid);
+	for (i = 0; i < current_cpu_data.watch_reg_use_cnt; i++) {
+		__put_user(child->thread.watch.mips3264.watchlo[i],
+			   &addr->WATCH_STYLE.watchlo[i]);
+		__put_user(child->thread.watch.mips3264.watchhi[i] & 0xfff,
+			   &addr->WATCH_STYLE.watchhi[i]);
+		__put_user(current_cpu_data.watch_reg_masks[i],
+			   &addr->WATCH_STYLE.watch_masks[i]);
+	}
+	for (; i < 8; i++) {
+		__put_user(0, &addr->WATCH_STYLE.watchlo[i]);
+		__put_user(0, &addr->WATCH_STYLE.watchhi[i]);
+		__put_user(0, &addr->WATCH_STYLE.watch_masks[i]);
+	}
+
+	return 0;
+}
+
+int ptrace_set_watch_regs(struct task_struct *child,
+			  struct pt_watch_regs __user *addr)
+{
+	int i;
+	int watch_active = 0;
+	unsigned long lt[NUM_WATCH_REGS];
+	u16 ht[NUM_WATCH_REGS];
+
+	if (!cpu_has_watch || current_cpu_data.watch_reg_use_cnt == 0)
+		return -EIO;
+	if (!access_ok(VERIFY_READ, addr, sizeof(struct pt_watch_regs)))
+		return -EIO;
+	/* Check the values. */
+	for (i = 0; i < current_cpu_data.watch_reg_use_cnt; i++) {
+		__get_user(lt[i], &addr->WATCH_STYLE.watchlo[i]);
+#ifdef CONFIG_32BIT
+		if (lt[i] & __UA_LIMIT)
+			return -EINVAL;
+#else
+		if (test_tsk_thread_flag(child, TIF_32BIT_ADDR)) {
+			if (lt[i] & 0xffffffff80000000UL)
+				return -EINVAL;
+		} else {
+			if (lt[i] & __UA_LIMIT)
+				return -EINVAL;
+		}
+#endif
+		__get_user(ht[i], &addr->WATCH_STYLE.watchhi[i]);
+		if (ht[i] & ~0xff8)
+			return -EINVAL;
+	}
+	/* Install them. */
+	for (i = 0; i < current_cpu_data.watch_reg_use_cnt; i++) {
+		if (lt[i] & 7)
+			watch_active = 1;
+		child->thread.watch.mips3264.watchlo[i] = lt[i];
+		/* Set the G bit. */
+		child->thread.watch.mips3264.watchhi[i] = ht[i];
+	}
+
+	if (watch_active)
+		set_tsk_thread_flag(child, TIF_LOAD_WATCH);
+	else
+		clear_tsk_thread_flag(child, TIF_LOAD_WATCH);
+
+	return 0;
+}
+
 long arch_ptrace(struct task_struct *child, long request, long addr, long data)
 {
 	int ret;
@@ -175,9 +268,57 @@ long arch_ptrace(struct task_struct *child, long request, long addr, long data)
 	switch (request) {
 	/* when I and D space are separate, these will need to be fixed. */
 	case PTRACE_PEEKTEXT: /* read word at location addr. */
-	case PTRACE_PEEKDATA:
+	case PTRACE_PEEKDATA: {
+#if !defined(CAVIUM_OCTEON_USER_IO_DISABLED) && defined(CONFIG_64BIT)
+		/* check whether its a XKPHYS IO addr (we only allow the 0x80xx.. alias) */
+		if (((unsigned long)addr >> 48) == 0x8001) {
+#ifdef CAVIUM_OCTEON_USER_IO_PER_PROCESS
+			struct task_struct *group_leader;
+			group_leader = child->group_leader;
+			if (!test_tsk_thread_flag(group_leader,
+						  TIF_XKPHYS_IO_EN))
+				break;
+#endif
+			ret = put_user(*(unsigned long*)addr, (unsigned long __user *) data);
+			break;
+		}
+#endif /* !defined(CAVIUM_OCTEON_USER_IO_DISABLED) */
+#if !defined(CAVIUM_OCTEON_USER_MEM_DISABLED)
+		/* check whether its a XKPHYS MEM addr */
+		if (((unsigned long)addr >> 48) == 0x8000) {
+			unsigned long tmp;
+#ifdef CAVIUM_OCTEON_USER_MEM_PER_PROCESS
+			struct task_struct *group_leader;
+			group_leader = child->group_leader;
+			if (!test_tsk_thread_flag(group_leader,
+						  TIF_XKPHYS_MEM_EN))
+				break;
+#endif
+			ret = -EIO;
+			/* ensure that task is 64 bit */
+			if (test_tsk_thread_flag(child, TIF_32BIT_ADDR))
+				break;
+
+			/* extract phy addr from XKPHYS alias */
+			tmp = (unsigned long)addr - 0x8000000000000000ull;
+
+			/* check for boot-bus addr range */
+			if ((tmp >= 0x10000000) && (tmp < 0x20000000))
+				break;
+			/* this is for the dram_size comparison below */
+			if ((tmp >= 0x410000000ull) && (tmp < 0x420000000ull))
+				tmp -= 0x400000000ull;
+
+			/* verify that "addr" is within installed dram */
+			if (tmp <= ((octeon_bootinfo->dram_size<<20) - sizeof(tmp)))  {
+				ret = put_user(*(unsigned long*)addr, (unsigned long __user *) data);
+			}
+			break;
+		}
+#endif /*  defined(CONFIG_CAVIUM_OCTEON_USER_MEM) */
 		ret = generic_ptrace_peekdata(child, addr, data);
 		break;
+	}
 
 	/* Read the word at location addr in the USER area. */
 	case PTRACE_PEEKUSR: {
@@ -441,6 +582,16 @@ long arch_ptrace(struct task_struct *child, long request, long addr, long data)
 				(unsigned long __user *) data);
 		break;
 
+	case PTRACE_GET_WATCH_REGS:
+		ret = ptrace_get_watch_regs(child,
+					(struct pt_watch_regs __user *) addr);
+		break;
+
+	case PTRACE_SET_WATCH_REGS:
+		ret = ptrace_set_watch_regs(child,
+					(struct pt_watch_regs __user *) addr);
+		break;
+
 	default:
 		ret = ptrace_request(child, request, addr, data);
 		break;
diff --git a/arch/mips/kernel/ptrace32.c b/arch/mips/kernel/ptrace32.c
index 76818be..13554ca 100644
--- a/arch/mips/kernel/ptrace32.c
+++ b/arch/mips/kernel/ptrace32.c
@@ -410,6 +410,16 @@ asmlinkage int sys32_ptrace(int request, int pid, int addr, int data)
 				(unsigned long __user *) (unsigned long) data);
 		break;
 
+	case PTRACE_GET_WATCH_REGS:
+		ret = ptrace_get_watch_regs(child,
+			(struct pt_watch_regs __user *) (unsigned long) addr);
+		break;
+
+	case PTRACE_SET_WATCH_REGS:
+		ret = ptrace_set_watch_regs(child,
+			(struct pt_watch_regs __user *) (unsigned long) addr);
+		break;
+
 	default:
 		ret = ptrace_request(child, request, addr, data);
 		break;
diff --git a/arch/mips/kernel/smp.c b/arch/mips/kernel/smp.c
index 5b3c1d7..2986f9f 100644
--- a/arch/mips/kernel/smp.c
+++ b/arch/mips/kernel/smp.c
@@ -116,7 +116,11 @@ asmlinkage __cpuinit void start_secondary(void)
 	 * to an option instead of something based on .cputype
 	 */
 
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
+	/* There is no reason to waste time doing this on Octeon. All the cores
+	    are on the same chip and are the same speed by definition */
 	calibrate_delay();
+#endif
 	preempt_disable();
 	cpu = smp_processor_id();
 	cpu_data[cpu].udelay_val = loops_per_jiffy;
@@ -193,12 +197,14 @@ void __init smp_prepare_cpus(unsigned int max_cpus)
 /* preload SMP state for boot cpu */
 void __devinit smp_prepare_boot_cpu(void)
 {
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
 	/*
 	 * This assumes that bootup is always handled by the processor
 	 * with the logic and physical number 0.
 	 */
 	__cpu_number_map[0] = 0;
 	__cpu_logical_map[0] = 0;
+#endif
 	cpu_set(0, phys_cpu_present_map);
 	cpu_set(0, cpu_online_map);
 	cpu_set(0, cpu_callin_map);
diff --git a/arch/mips/kernel/syscall.c b/arch/mips/kernel/syscall.c
index c576845..4d5fb6a 100644
--- a/arch/mips/kernel/syscall.c
+++ b/arch/mips/kernel/syscall.c
@@ -41,6 +41,11 @@
 #include <asm/sysmips.h>
 #include <asm/uaccess.h>
 
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS) || \
+	defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
+#include <asm/processor.h>
+#endif
+
 /*
  * For historic reasons the pipe(2) syscall on MIPS has an unusual calling
  * convention.  It returns results in registers $v0 / $v1 which means there
@@ -81,13 +86,25 @@ unsigned long arch_get_unmapped_area(struct file *filp, unsigned long addr,
 
 	task_size = STACK_TOP;
 
+#ifndef CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB
 	if (len > task_size)
 		return -ENOMEM;
+#endif
 
 	if (flags & MAP_FIXED) {
+#ifdef CONFIG_CAVIUM_RESERVE32
+		/* This resolves problems with Cavium's
+		   CONFIG_CAVIUM_RESERVE32 and
+		   CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB support. It prevents
+		   mappings from overwriting the virtual address range used
+		   by the fixed RESERVE32 mappings. */
+		if (TASK_SIZE - len < addr)
+			return -EINVAL;
+#else
 		/* Even MAP_FIXED mappings must reside within task_size.  */
 		if (task_size - len < addr)
 			return -EINVAL;
+#endif
 
 		/*
 		 * We do not accept a shared mapping if it would violate
@@ -294,6 +311,9 @@ SYSCALL_DEFINE1(set_thread_area, unsigned long, addr)
 	if (cpu_has_userlocal)
 		write_c0_userlocal(addr);
 
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	FAST_ACCESS_THREAD_REGISTER = addr;
+#endif
 	return 0;
 }
 
@@ -322,6 +342,14 @@ asmlinkage int _sys_sysmips(long cmd, long arg1, long arg2, long arg3)
 	case FLUSH_CACHE:
 		__flush_cache_all();
 		return 0;
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS) || \
+	defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
+	case MIPS_CAVIUM_XKPHYS_READ:
+		return xkphys_usermem_read(arg1);
+
+	case MIPS_CAVIUM_XKPHYS_WRITE:
+		return xkphys_usermem_write(arg1, arg2);
+#endif
 	}
 
 	return -EINVAL;
diff --git a/arch/mips/kernel/traps.c b/arch/mips/kernel/traps.c
index 6fa59ac..be6b593 100644
--- a/arch/mips/kernel/traps.c
+++ b/arch/mips/kernel/traps.c
@@ -44,9 +44,11 @@
 #include <asm/tlbdebug.h>
 #include <asm/traps.h>
 #include <asm/uaccess.h>
+#include <asm/watch.h>
 #include <asm/mmu_context.h>
 #include <asm/types.h>
 #include <asm/stacktrace.h>
+#include <asm/irq.h>
 
 extern void check_wait(void);
 extern asmlinkage void r4k_wait(void);
@@ -78,6 +80,22 @@ extern asmlinkage void handle_reserved(void);
 extern int fpu_emulator_cop1Handler(struct pt_regs *xcp,
 	struct mips_fpu_struct *ctx, int has_fpu);
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+extern asmlinkage void octeon_cop2_restore(struct octeon_cop2_state *task);
+#endif
+
+#ifdef CONFIG_REPLACE_EMULATED_ACCESS_TO_THREAD_POINTER
+/* 	0 - Use the normal kernel emulation without any changes.
+	1 - Replace emulated instructions with direct accesses to the thread
+		register.
+	2 - Replace emulated instructions and log the replacement PC.
+	3 - Replace emulated instructions with break instructions. This will
+		cause programs to fail, but makes it easy to stop gdb on the
+		instruction. */
+static int thread_pointer_mode = 0;
+module_param(thread_pointer_mode, int, 0644);
+#endif
+
 void (*board_be_init)(void);
 int (*board_be_handler)(struct pt_regs *regs, int is_fixup);
 void (*board_nmi_handler_setup)(void);
@@ -569,6 +587,9 @@ static int simulate_llsc(struct pt_regs *regs, unsigned int opcode)
 static int simulate_rdhwr(struct pt_regs *regs, unsigned int opcode)
 {
 	struct thread_info *ti = task_thread_info(current);
+#ifdef CONFIG_REPLACE_EMULATED_ACCESS_TO_THREAD_POINTER
+	unsigned int __user *epc = (unsigned int __user *)regs->cp0_epc + ((regs->cp0_cause & CAUSEF_BD) != 0);
+#endif
 
 	if ((opcode & OPCODE) == SPEC3 && (opcode & FUNC) == RDHWR) {
 		int rd = (opcode & RD) >> 11;
@@ -596,12 +617,36 @@ static int simulate_rdhwr(struct pt_regs *regs, unsigned int opcode)
 			return 0;
 		case 29:
 			regs->regs[rt] = ti->tp_value;
+#ifdef CONFIG_REPLACE_EMULATED_ACCESS_TO_THREAD_POINTER
+			if (thread_pointer_mode) {
+				unsigned int new_instruction = 0x00000025 | (26 << 21) | (rt << 11); /* move [rt], k0 */
+				if (thread_pointer_mode == 3)
+					new_instruction = 0x0000000d; /* break */
+				if (access_process_vm(current, (unsigned long)epc, &new_instruction, sizeof(new_instruction), 1) != sizeof(new_instruction))
+					printk(KERN_ERR "Failed to replaced emulated RDHWR at PC=%p\n", epc);
+				if (thread_pointer_mode == 2)
+					printk(KERN_INFO "Replaced emulated RDHWR at PC=%p with \"move $%d, k0\"\n", epc, rt);
+				else if (thread_pointer_mode == 3)
+					printk(KERN_INFO "Replaced emulated RDHWR at PC=%p with \"break\"\n", epc);
+			}
+#endif
 			return 0;
 		default:
 			return -1;
 		}
 	}
 
+#ifdef CONFIG_REPLACE_EMULATED_ACCESS_TO_THREAD_POINTER
+	else if (opcode == (0x00000025 | (26 << 21) | (3 << 11)) /* move v1, k0 */)
+	{
+		/* We need to flush the icache, not emulate an instruction. The EPC is wrong,
+			so we need to put it back to the old instruction */
+		//printk(KERN_INFO "Already replaced emulated RDHWR at PC=%p\n", epc);
+		regs->cp0_epc = (unsigned long)epc;
+		flush_cache_sigtramp((unsigned long)epc);
+		return 0;
+	}
+#endif
 	/* Not ours.  */
 	return -1;
 }
@@ -906,6 +951,21 @@ asmlinkage void do_cpu(struct pt_regs *regs)
 		return;
 
 	case 2:
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	{
+		unsigned long flags;
+		int status;
+		prefetch(&current->thread.cp2);
+		local_irq_save(flags);
+		KSTK_STATUS(current) |= ST0_CU2;
+		status = read_c0_status();
+		write_c0_status(status | ST0_CU2);
+		octeon_cop2_restore(&(current->thread.cp2));
+		write_c0_status(status & ~ST0_CU2);
+		local_irq_restore(flags);
+		return;
+	}
+#endif
 	case 3:
 		break;
 	}
@@ -919,15 +979,34 @@ asmlinkage void do_mdmx(struct pt_regs *regs)
 	force_sig(SIGILL, current);
 }
 
+/*
+ * Called with interrupts disabled.
+ */
 asmlinkage void do_watch(struct pt_regs *regs)
 {
+	u32 cause;
+
 	/*
-	 * We use the watch exception where available to detect stack
-	 * overflows.
+	 * Clear WP (bit 22) bit of cause register so we don't loop
+	 * forever.
 	 */
-	dump_tlb_all();
-	show_regs(regs);
-	panic("Caught WATCH exception - probably caused by stack overflow.");
+	cause = read_c0_cause();
+	cause &= ~(1 << 22);
+	write_c0_cause(cause);
+
+	/*
+	 * If the current thread has the watch registers loaded, save
+	 * their values and send SIGTRAP.  Otherwise another thread
+	 * left the registers set, clear them and continue.
+	 */
+	if (test_tsk_thread_flag(current, TIF_LOAD_WATCH)) {
+		mips_read_watch_registers();
+		local_irq_enable();
+		force_sig(SIGTRAP, current);
+	} else {
+		mips_clear_watch_registers();
+		local_irq_enable();
+	}
 }
 
 asmlinkage void do_mcheck(struct pt_regs *regs)
@@ -1450,6 +1529,13 @@ void __cpuinit per_cpu_trap_init(void)
 #ifdef CONFIG_64BIT
 	status_set |= ST0_FR|ST0_KX|ST0_SX|ST0_UX;
 #endif
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	/*
+	 * Note: We always set ST0_KX on Octeon since IO addresses are at
+	 * 64bit addresses. Keep in mind this also moves the TLB handler.
+	 */
+	status_set |= ST0_KX;
+#endif
 	if (current_cpu_data.isa_level == MIPS_CPU_ISA_IV)
 		status_set |= ST0_XX;
 	if (cpu_has_dsp)
@@ -1466,6 +1552,9 @@ void __cpuinit per_cpu_trap_init(void)
 
 		write_c0_hwrena(enable);
 	}
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	write_c0_hwrena (0xc000000f); /* Octeon has register 30 and 31 */
+#endif
 
 #ifdef CONFIG_MIPS_MT_SMTC
 	if (!secondaryTC) {
@@ -1584,7 +1673,11 @@ void __init trap_init(void)
 	if (cpu_has_veic || cpu_has_vint)
 		ebase = (unsigned long) alloc_bootmem_low_pages(0x200 + VECTORSPACING*64);
 	else
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		ebase = CAC_BASE + (read_c0_ebase() & 0x3ffff000);
+#else
 		ebase = CAC_BASE;
+#endif
 
 	per_cpu_trap_init();
 
@@ -1692,11 +1785,11 @@ void __init trap_init(void)
 
 	if (cpu_has_vce)
 		/* Special exception: R4[04]00 uses also the divec space. */
-		memcpy((void *)(CAC_BASE + 0x180), &except_vec3_r4000, 0x100);
+		memcpy((void *)(ebase + 0x180), &except_vec3_r4000, 0x100);
 	else if (cpu_has_4kex)
-		memcpy((void *)(CAC_BASE + 0x180), &except_vec3_generic, 0x80);
+		memcpy((void *)(ebase + 0x180), &except_vec3_generic, 0x80);
 	else
-		memcpy((void *)(CAC_BASE + 0x080), &except_vec3_generic, 0x80);
+		memcpy((void *)(ebase + 0x080), &except_vec3_generic, 0x80);
 
 	signal_init();
 #ifdef CONFIG_MIPS32_COMPAT
diff --git a/arch/mips/kernel/unaligned.c b/arch/mips/kernel/unaligned.c
index 1b636d3..c3b06a7 100644
--- a/arch/mips/kernel/unaligned.c
+++ b/arch/mips/kernel/unaligned.c
@@ -531,6 +531,43 @@ asmlinkage void do_ade(struct pt_regs *regs)
 		return;
 	}
 
+#if defined(CONFIG_CPU_CAVIUM_OCTEON) && (CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE > 0)
+{
+    /* This section of code allows tasks to access CVMSEG addresses. These are
+        special addresses into the Octeon L1 Cache that can be used as fast
+        scratch memory. By default access to this memory is disabled so we
+        don't have to save it on context switch. When a userspace task
+        references one of these addresses, we enable the region and size it
+        to match the app */
+    const unsigned long CVMSEG_BASE  = (short)0x8000;
+    const unsigned long CVMSEG_IO    = (short)0xa200;
+    uint64_t cvmmemctl               = __read_64bit_c0_register($11, 7);
+    unsigned long cvmseg_size        = (cvmmemctl&0x3f) * 128;
+
+    if ((regs->cp0_badvaddr==CVMSEG_IO) ||
+        ((regs->cp0_badvaddr>=CVMSEG_BASE) && (regs->cp0_badvaddr<CVMSEG_BASE + cvmseg_size)))
+    {
+        /* Make sure all async operations are done */
+        asm volatile ("synciobdma" ::: "memory");
+        /* Enable userspace access to CVMSEG */
+        cvmmemctl |= 1<<6;
+        __write_64bit_c0_register($11, 7, cvmmemctl);
+
+        //printk("Enabling CVMSEG access for task %p (%lu lines)\n", current, cvmmemctl&0x3f);
+
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+        /* Restore the processes CVMSEG data. Leave off the last 8 bytes since
+            the kernel stores the thread pointer there */
+        memcpy((void*)CVMSEG_BASE, current->thread.cvmseg.cvmseg, cvmseg_size-8);
+#else
+        /* Restore the processes CVMSEG data */
+        memcpy((void*)CVMSEG_BASE, current->thread.cvmseg.cvmseg, cvmseg_size);
+#endif
+        return;
+    }
+}
+#endif
+
 	/* Otherwise handle as normal */
 
 	/*
diff --git a/arch/mips/kernel/vmlinux.lds.S b/arch/mips/kernel/vmlinux.lds.S
index afb119f..0174e45 100644
--- a/arch/mips/kernel/vmlinux.lds.S
+++ b/arch/mips/kernel/vmlinux.lds.S
@@ -76,6 +76,20 @@ SECTIONS
 		 * of ‘init_thread_union’ is greater than maximum
 		 * object file alignment.  Using 32768
 		 */
+		 /* We align swapper_pg_dir to 64K boundry so the XTLB
+		  * handler user fewer instructions to load its address
+		  */
+#ifdef CONFIG_HUGETLB_PAGE
+		. = ALIGN(0x10000);
+#endif
+		. = ALIGN(_PAGE_SIZE << _PGD_ORDER);
+		*(.data.swapper_pg_dir)
+		. = ALIGN(_PAGE_SIZE << _PGD_ORDER);
+		*(.data.module_pg_dir)
+		. = ALIGN(_PAGE_SIZE << _PMD_ORDER);
+		*(.data.invalid_pmd_table)
+		. = ALIGN(_PAGE_SIZE << _PTE_ORDER);
+		*(.data.invalid_pte_table)
 		. = ALIGN(_PAGE_SIZE);
 		*(.data.init_task)
 
@@ -104,7 +118,11 @@ SECTIONS
 	. = ALIGN(_PAGE_SIZE);
 	__nosave_end = .;
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	. = ALIGN(128);
+#else
 	. = ALIGN(32);
+#endif
 	.data.cacheline_aligned : {
 		*(.data.cacheline_aligned)
 	}
@@ -159,7 +177,11 @@ SECTIONS
 	}
 #endif
 	PERCPU(_PAGE_SIZE)
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	. = ALIGN(128);
+#else
 	. = ALIGN(_PAGE_SIZE);
+#endif
 	__init_end = .;
 	/* freed after init ends here */
 
diff --git a/arch/mips/lib/Makefile b/arch/mips/lib/Makefile
index b9efb3e..f4a2e7b 100644
--- a/arch/mips/lib/Makefile
+++ b/arch/mips/lib/Makefile
@@ -28,6 +28,7 @@ obj-$(CONFIG_CPU_SB1)		+= dump_tlb.o
 obj-$(CONFIG_CPU_TX39XX)	+= r3k_dump_tlb.o
 obj-$(CONFIG_CPU_TX49XX)	+= dump_tlb.o
 obj-$(CONFIG_CPU_VR41XX)	+= dump_tlb.o
+obj-$(CONFIG_CPU_CAVIUM_OCTEON)	+= dump_tlb.o
 
 # libgcc-style stuff needed in the kernel
 obj-y += ashldi3.o ashrdi3.o cmpdi2.o lshrdi3.o ucmpdi2.o
diff --git a/arch/mips/lib/iomap.c b/arch/mips/lib/iomap.c
index e3acb2d..9abbfe5 100644
--- a/arch/mips/lib/iomap.c
+++ b/arch/mips/lib/iomap.c
@@ -210,8 +210,22 @@ static void __iomem *ioport_map_legacy(unsigned long port, unsigned int nr)
 
 void __iomem *ioport_map(unsigned long port, unsigned int nr)
 {
+	/* Octeon chips with PCIe have two independent PCIe ports with
+		two different IO base addresses. Since the kernel only
+		supplies a single IO base in mips_io_port_base, we play
+		games with the IO offset for the 2nd PCIe port. The
+		io_resource->start address for the 2nd port is set to the
+		difference between the IO base addresses for port 0 and 1.
+		This allows ioport_map_legacy() to work for the 2nd port.
+		Unfortunately this delta is a large 64bit number, so
+		PIO_MASK doesn't have a meaning. This ifdef needs to be
+		removed if the kernel ever supports multiple
+		mips_io_port_base port values. "cavium-octeon/pcie.c"
+		has the code that calculates the IO offset */
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
 	if (port > PIO_MASK)
 		return NULL;
+#endif
 
 	return ioport_map_legacy(port, nr);
 }
diff --git a/arch/mips/math-emu/cp1emu.c b/arch/mips/math-emu/cp1emu.c
index 7ec0b21..252a9a8 100644
--- a/arch/mips/math-emu/cp1emu.c
+++ b/arch/mips/math-emu/cp1emu.c
@@ -209,7 +209,11 @@ static int cop1Emulate(struct pt_regs *xcp, struct mips_fpu_struct *ctx)
 	unsigned int cond;
 
 	if (get_user(ir, (mips_instruction __user *) xcp->cp0_epc)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		FPUEMUSTATS_INC(errors);
+#else
 		fpuemustats.errors++;
+#endif
 		return SIGBUS;
 	}
 
@@ -240,7 +244,11 @@ static int cop1Emulate(struct pt_regs *xcp, struct mips_fpu_struct *ctx)
 			return SIGILL;
 		}
 		if (get_user(ir, (mips_instruction __user *) emulpc)) {
-			fpuemustats.errors++;
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		FPUEMUSTATS_INC(errors);
+#else
+		fpuemustats.errors++;
+#endif
 			return SIGBUS;
 		}
 		/* __compute_return_epc() will have updated cp0_epc */
@@ -253,16 +261,28 @@ static int cop1Emulate(struct pt_regs *xcp, struct mips_fpu_struct *ctx)
 	}
 
       emul:
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	FPUEMUSTATS_INC(emulated);
+#else
 	fpuemustats.emulated++;
+#endif
 	switch (MIPSInst_OPCODE(ir)) {
 	case ldc1_op:{
 		u64 __user *va = (u64 __user *) (xcp->regs[MIPSInst_RS(ir)] +
 			MIPSInst_SIMM(ir));
 		u64 val;
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		FPUEMUSTATS_INC(loads);
+#else
 		fpuemustats.loads++;
+#endif
 		if (get_user(val, va)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+			FPUEMUSTATS_INC(errors);
+#else
 			fpuemustats.errors++;
+#endif
 			return SIGBUS;
 		}
 		DITOREG(val, MIPSInst_RT(ir));
@@ -274,10 +294,18 @@ static int cop1Emulate(struct pt_regs *xcp, struct mips_fpu_struct *ctx)
 			MIPSInst_SIMM(ir));
 		u64 val;
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		FPUEMUSTATS_INC(stores);
+#else
 		fpuemustats.stores++;
+#endif
 		DIFROMREG(val, MIPSInst_RT(ir));
 		if (put_user(val, va)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+			FPUEMUSTATS_INC(errors);
+#else
 			fpuemustats.errors++;
+#endif
 			return SIGBUS;
 		}
 		break;
@@ -288,9 +316,17 @@ static int cop1Emulate(struct pt_regs *xcp, struct mips_fpu_struct *ctx)
 			MIPSInst_SIMM(ir));
 		u32 val;
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		FPUEMUSTATS_INC(loads);
+#else
 		fpuemustats.loads++;
+#endif
 		if (get_user(val, va)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+			FPUEMUSTATS_INC(errors);
+#else
 			fpuemustats.errors++;
+#endif
 			return SIGBUS;
 		}
 		SITOREG(val, MIPSInst_RT(ir));
@@ -302,10 +338,18 @@ static int cop1Emulate(struct pt_regs *xcp, struct mips_fpu_struct *ctx)
 			MIPSInst_SIMM(ir));
 		u32 val;
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		FPUEMUSTATS_INC(stores);
+#else
 		fpuemustats.stores++;
+#endif
 		SIFROMREG(val, MIPSInst_RT(ir));
 		if (put_user(val, va)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+			FPUEMUSTATS_INC(errors);
+#else
 			fpuemustats.errors++;
+#endif
 			return SIGBUS;
 		}
 		break;
@@ -432,7 +476,11 @@ static int cop1Emulate(struct pt_regs *xcp, struct mips_fpu_struct *ctx)
 
 				if (get_user(ir,
 				    (mips_instruction __user *) xcp->cp0_epc)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+					FPUEMUSTATS_INC(errors);
+#else
 					fpuemustats.errors++;
+#endif
 					return SIGBUS;
 				}
 
@@ -598,7 +646,11 @@ static int fpux_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 {
 	unsigned rcsr = 0;	/* resulting csr */
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	FPUEMUSTATS_INC(cp1xops);
+#else
 	fpuemustats.cp1xops++;
+#endif
 
 	switch (MIPSInst_FMA_FFMT(ir)) {
 	case s_fmt:{		/* 0 */
@@ -612,10 +664,17 @@ static int fpux_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 		case lwxc1_op:
 			va = (void __user *) (xcp->regs[MIPSInst_FR(ir)] +
 				xcp->regs[MIPSInst_FT(ir)]);
-
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+			FPUEMUSTATS_INC(loads);
+#else
 			fpuemustats.loads++;
+#endif
 			if (get_user(val, va)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+				FPUEMUSTATS_INC(errors);
+#else
 				fpuemustats.errors++;
+#endif
 				return SIGBUS;
 			}
 			SITOREG(val, MIPSInst_FD(ir));
@@ -625,11 +684,18 @@ static int fpux_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 			va = (void __user *) (xcp->regs[MIPSInst_FR(ir)] +
 				xcp->regs[MIPSInst_FT(ir)]);
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+			FPUEMUSTATS_INC(stores);
+#else
 			fpuemustats.stores++;
-
+#endif
 			SIFROMREG(val, MIPSInst_FS(ir));
 			if (put_user(val, va)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+				FPUEMUSTATS_INC(errors);
+#else
 				fpuemustats.errors++;
+#endif
 				return SIGBUS;
 			}
 			break;
@@ -690,9 +756,17 @@ static int fpux_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 			va = (void __user *) (xcp->regs[MIPSInst_FR(ir)] +
 				xcp->regs[MIPSInst_FT(ir)]);
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+			FPUEMUSTATS_INC(loads);
+#else
 			fpuemustats.loads++;
+#endif
 			if (get_user(val, va)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+				FPUEMUSTATS_INC(errors);
+#else
 				fpuemustats.errors++;
+#endif
 				return SIGBUS;
 			}
 			DITOREG(val, MIPSInst_FD(ir));
@@ -702,10 +776,18 @@ static int fpux_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 			va = (void __user *) (xcp->regs[MIPSInst_FR(ir)] +
 				xcp->regs[MIPSInst_FT(ir)]);
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+			FPUEMUSTATS_INC(stores);
+#else
 			fpuemustats.stores++;
+#endif
 			DIFROMREG(val, MIPSInst_FS(ir));
 			if (put_user(val, va)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+				FPUEMUSTATS_INC(errors);
+#else
 				fpuemustats.errors++;
+#endif
 				return SIGBUS;
 			}
 			break;
@@ -772,7 +854,11 @@ static int fpu_emu(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 #endif
 	} rv;			/* resulting value */
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	FPUEMUSTATS_INC(cp1ops);
+#else
 	fpuemustats.cp1ops++;
+#endif
 	switch (rfmt = (MIPSInst_FFMT(ir) & 0xf)) {
 	case s_fmt:{		/* 0 */
 		union {
@@ -1243,7 +1329,11 @@ int fpu_emulator_cop1Handler(struct pt_regs *xcp, struct mips_fpu_struct *ctx,
 		prevepc = xcp->cp0_epc;
 
 		if (get_user(insn, (mips_instruction __user *) xcp->cp0_epc)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+			FPUEMUSTATS_INC(errors);
+#else
 			fpuemustats.errors++;
+#endif
 			return SIGBUS;
 		}
 		if (insn == 0)
diff --git a/arch/mips/math-emu/dsemul.c b/arch/mips/math-emu/dsemul.c
index 653e325..f7b42ac 100644
--- a/arch/mips/math-emu/dsemul.c
+++ b/arch/mips/math-emu/dsemul.c
@@ -98,8 +98,16 @@ int mips_dsemul(struct pt_regs *regs, mips_instruction ir, unsigned long cpc)
 	err |= __put_user((mips_instruction)BD_COOKIE, &fr->cookie);
 	err |= __put_user(cpc, &fr->epc);
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	mb(); /* Make sure the write made it to memory so the icache can load it */
+#endif
+
 	if (unlikely(err)) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		FPUEMUSTATS_INC(errors);
+#else
 		fpuemustats.errors++;
+#endif
 		return SIGBUS;
 	}
 
@@ -137,7 +145,11 @@ int do_dsemulret(struct pt_regs *xcp)
 	err |= __get_user(cookie, &fr->cookie);
 
 	if (unlikely(err || (insn != BADINST) || (cookie != BD_COOKIE))) {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		FPUEMUSTATS_INC(errors);
+#else
 		fpuemustats.errors++;
+#endif
 		return 0;
 	}
 
diff --git a/arch/mips/mm/Makefile b/arch/mips/mm/Makefile
index 44e8dd8..15b54da 100644
--- a/arch/mips/mm/Makefile
+++ b/arch/mips/mm/Makefile
@@ -2,8 +2,24 @@
 # Makefile for the Linux/MIPS-specific parts of the memory manager.
 #
 
-obj-y				+= cache.o dma-default.o extable.o fault.o \
-				   init.o tlbex.o tlbex-fault.o uasm.o page.o
+OCTEON_ROOT_IN_KERNEL = $(srctree)/arch/mips/cavium-octeon
+OCTEON_ROOT = $(srctree)/../../host-cross/mips-wrs-linux-gnu/sysroot/usr/include/simple_exec_open
+
+obj-y				+= cache.o extable.o fault.o \
+				   init.o tlbex.o tlbex-fault.o uasm.o
+
+ifeq ($(CONFIG_CPU_CAVIUM_OCTEON), y)
+obj-y  += pg-octeon.o
+else
+obj-y  += page.o
+endif
+
+ifndef CONFIG_CPU_CAVIUM_OCTEON
+# The Octeon uses its own version of the DMA mapping routines
+# to allow 32bit devices to access memory higher than 4GB. The
+# Octeon version of this file is arch/mips/cavium-octeon/dma-octeon.c
+obj-y				+= dma-default.o
+endif
 
 obj-$(CONFIG_32BIT)		+= ioremap.o pgtable-32.o
 obj-$(CONFIG_64BIT)		+= pgtable-64.o
@@ -26,6 +42,7 @@ obj-$(CONFIG_CPU_SB1)		+= c-r4k.o cerr-sb1.o cex-sb1.o tlb-r4k.o
 obj-$(CONFIG_CPU_TX39XX)	+= c-tx39.o tlb-r3k.o
 obj-$(CONFIG_CPU_TX49XX)	+= c-r4k.o cex-gen.o tlb-r4k.o
 obj-$(CONFIG_CPU_VR41XX)	+= c-r4k.o cex-gen.o tlb-r4k.o
+obj-$(CONFIG_CPU_CAVIUM_OCTEON)	+= c-octeon.o cex-oct.o tlb-r4k.o
 
 obj-$(CONFIG_IP22_CPU_SCACHE)	+= sc-ip22.o
 obj-$(CONFIG_R5000_CPU_SCACHE)  += sc-r5k.o
@@ -33,3 +50,7 @@ obj-$(CONFIG_RM7000_CPU_SCACHE)	+= sc-rm7k.o
 obj-$(CONFIG_MIPS_CPU_SCACHE)	+= sc-mips.o
 
 EXTRA_CFLAGS += -Werror
+
+CFLAGS_c-octeon.o	= -I$(OCTEON_ROOT)/target/include \
+			  -I$(OCTEON_ROOT_IN_KERNEL)/executive
+
diff --git a/arch/mips/mm/c-r4k.c b/arch/mips/mm/c-r4k.c
index b8317c6..1b4e6e0 100644
--- a/arch/mips/mm/c-r4k.c
+++ b/arch/mips/mm/c-r4k.c
@@ -1269,8 +1269,11 @@ __setup("cca=", cca_setup);
 
 static void __cpuinit coherency_setup(void)
 {
-	if (cca < 0 || cca > 7)
-		cca = read_c0_config() & CONF_CM_CMASK;
+	cca = read_c0_config() & CONF_CM_CMASK;
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	if (cca != 7)
+		panic("PAGE CACHABLE DEFAULT is not 7\n");
+#endif /* CONFIG_CPU_CAVIUM_OCTEON */
 	_page_cachable_default = cca << _CACHE_SHIFT;
 
 	pr_debug("Using cache attribute %d\n", cca);
diff --git a/arch/mips/mm/fault.c b/arch/mips/mm/fault.c
index 868cf98..bc6cf0c 100644
--- a/arch/mips/mm/fault.c
+++ b/arch/mips/mm/fault.c
@@ -33,6 +33,9 @@ int (*is_oprofile_fault)(struct pt_regs *regs) = 0;
 EXPORT_SYMBOL_GPL(is_oprofile_fault);
 #endif
 
+#ifdef CONFIG_CAVIUM_OCTEON_HW_FIX_UNALIGNED
+extern int do_dsemulret(struct pt_regs *);
+#endif
 
 #ifdef CONFIG_PAX_PAGEEXEC
 void pax_report_insns(void *pc)
@@ -66,6 +69,19 @@ asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long write,
 	siginfo_t info;
 	int fault;
 
+#ifdef CONFIG_CAVIUM_OCTEON_HW_FIX_UNALIGNED
+	/*
+     * Normally the FPU emulator uses a load word from address one to retake
+     * control of the CPU after executing the instruction in the delay slot
+     * of an emulated branch. The Octeon hardware unaligned access fix changes
+     * this from an address exception into a TLB exception. This code checks
+     * to see if this page fault was caused by an FPU emulation.
+     *
+	 * Terminate if exception was recognized as a delay slot return */
+	if (do_dsemulret(regs))
+		return;
+#endif
+
 #if defined(CONFIG_64BIT) && \
 		(defined(CONFIG_OPROFILE_MODULE) || defined(CONFIG_OPROFILE))
 	/* for stack and frame pointer validity checking */
@@ -126,8 +142,18 @@ good_area:
 		if (!(vma->vm_flags & VM_WRITE))
 			goto bad_area;
 	} else {
+#ifdef CONFIG_USE_RI_XI_PAGE_BITS
+		if (address == regs->cp0_epc) {
+			if (!(vma->vm_flags & VM_EXEC))
+				goto bad_area;
+		} else
+			if (!(vma->vm_flags & VM_READ))
+				goto bad_area;
+
+#else
 		if (!(vma->vm_flags & (VM_READ | VM_WRITE | VM_EXEC)))
 			goto bad_area;
+#endif
 	}
 
 survive:
diff --git a/arch/mips/mm/pgtable-64.c b/arch/mips/mm/pgtable-64.c
index e4b565a..2951e08 100644
--- a/arch/mips/mm/pgtable-64.c
+++ b/arch/mips/mm/pgtable-64.c
@@ -27,8 +27,13 @@ void pgd_init(unsigned long page)
 		p[4] = (unsigned long) invalid_pmd_table;
 		p[5] = (unsigned long) invalid_pmd_table;
 		p[6] = (unsigned long) invalid_pmd_table;
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
 		p[7] = (unsigned long) invalid_pmd_table;
+#endif
 		p += 8;
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		p[-1] = (unsigned long) invalid_pmd_table;
+#endif
 	}
 }
 
@@ -47,8 +52,13 @@ void pmd_init(unsigned long addr, unsigned long pagetable)
 		p[4] = (unsigned long)pagetable;
 		p[5] = (unsigned long)pagetable;
 		p[6] = (unsigned long)pagetable;
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
 		p[7] = (unsigned long)pagetable;
+#endif
 		p += 8;
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		p[-1] = (unsigned long)pagetable;
+#endif
 	}
 }
 
diff --git a/arch/mips/mm/sc-mips.c b/arch/mips/mm/sc-mips.c
index b55c2d1..c46f86c 100644
--- a/arch/mips/mm/sc-mips.c
+++ b/arch/mips/mm/sc-mips.c
@@ -15,6 +15,9 @@
 #include <asm/mmu_context.h>
 #include <asm/r4kcache.h>
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+struct bcache_ops *bcops;
+#endif
 /*
  * MIPS32/MIPS64 L2 cache handling
  */
diff --git a/arch/mips/mm/uasm.c b/arch/mips/mm/uasm.c
index 8224faa..acbc720 100644
--- a/arch/mips/mm/uasm.c
+++ b/arch/mips/mm/uasm.c
@@ -60,12 +60,16 @@ enum opcode {
 	insn_beql, insn_bgez, insn_bgezl, insn_bltz, insn_bltzl,
 	insn_bne, insn_cache, insn_daddu, insn_daddiu, insn_dmfc0,
 	insn_dmtc0, insn_dsll, insn_dsll32, insn_dsra, insn_dsrl,
-	insn_dsrl32, insn_dsubu, insn_eret, insn_j, insn_jal, insn_jr,
+	insn_drotr, insn_dsrl32, insn_dsubu, insn_eret, insn_j, insn_jal, insn_jr,
 	insn_ld, insn_ll, insn_lld, insn_lui, insn_lw, insn_mfc0,
 	insn_mtc0, insn_or, insn_ori, insn_pref, insn_rfe, insn_sc,
 	insn_scd, insn_sd, insn_sll, insn_sra, insn_srl, insn_subu,
-	insn_sw, insn_tlbp, insn_tlbwi, insn_tlbwr, insn_xor,
-	insn_xori
+	insn_sw, insn_tlbp, insn_tlbr, insn_tlbwi, insn_tlbwr, insn_xor,
+	insn_xori,
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	insn_nor, insn_bbit1, insn_bbit132, insn_bbit0, insn_bbit032,
+	insn_dins, insn_dinsu
+#endif
 };
 
 struct insn {
@@ -104,6 +108,7 @@ static struct insn insn_table[] __cpuinitdata = {
 	{ insn_dsll32, M(spec_op, 0, 0, 0, 0, dsll32_op), RT | RD | RE },
 	{ insn_dsra, M(spec_op, 0, 0, 0, 0, dsra_op), RT | RD | RE },
 	{ insn_dsrl, M(spec_op, 0, 0, 0, 0, dsrl_op), RT | RD | RE },
+	{ insn_drotr, M(spec_op, 1, 0, 0, 0, dsrl_op), RT | RD | RE },
 	{ insn_dsrl32, M(spec_op, 0, 0, 0, 0, dsrl32_op), RT | RD | RE },
 	{ insn_dsubu, M(spec_op, 0, 0, 0, 0, dsubu_op), RS | RT | RD },
 	{ insn_eret,  M(cop0_op, cop_op, 0, 0, 0, eret_op),  0 },
@@ -130,10 +135,20 @@ static struct insn insn_table[] __cpuinitdata = {
 	{ insn_subu,  M(spec_op, 0, 0, 0, 0, subu_op),  RS | RT | RD },
 	{ insn_sw,  M(sw_op, 0, 0, 0, 0, 0),  RS | RT | SIMM },
 	{ insn_tlbp,  M(cop0_op, cop_op, 0, 0, 0, tlbp_op),  0 },
+	{ insn_tlbr,  M(cop0_op, cop_op, 0, 0, 0, tlbr_op),  0 },
 	{ insn_tlbwi,  M(cop0_op, cop_op, 0, 0, 0, tlbwi_op),  0 },
 	{ insn_tlbwr,  M(cop0_op, cop_op, 0, 0, 0, tlbwr_op),  0 },
 	{ insn_xor,  M(spec_op, 0, 0, 0, 0, xor_op),  RS | RT | RD },
 	{ insn_xori,  M(xori_op, 0, 0, 0, 0, 0),  RS | RT | UIMM },
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	{ insn_nor, M(spec_op, 0, 0, 0, 0, nor_op), RS | RT | RD },
+	{ insn_bbit1, M(swc2_op, 0, 0, 0, 0, 0), RS | RT | BIMM },
+	{ insn_bbit132, M(sdc2_op, 0, 0, 0, 0, 0), RS | RT | BIMM },
+	{ insn_bbit0, M(lwc2_op, 0, 0, 0, 0, 0), RS | RT | BIMM },
+	{ insn_bbit032, M(ldc2_op, 0, 0, 0, 0, 0), RS | RT | BIMM },
+	{ insn_dins, M(spec3_op, 0, 0, 0, 0, dins_op), RS | RT | RD | RE },
+	{ insn_dinsu, M(spec3_op, 0, 0, 0, 0, dinsu_op), RS | RT | RD | RE },
+#endif
 	{ insn_invalid, 0, 0 }
 };
 
@@ -270,6 +285,12 @@ static void __cpuinit build_insn(u32 **buf, enum opcode opc, ...)
 	(*buf)++;
 }
 
+/*
+ * You might think when you see u3u1u2 -- that would mean all unsigned,
+ * and positioning 3,1,2 --> (c, a, b), however that is not the case.
+ * Instead it is a in 3rd, b in 1st and c in 2nd, which gives (b, c, a).
+ */
+
 #define I_u1u2u3(op)					\
 Ip_u1u2u3(op)						\
 {							\
@@ -330,6 +351,24 @@ Ip_0(op)						\
 	build_insn(buf, insn##op);			\
 }
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+/* FIXME: These functions for dins/dinsu don't share like the above.
+   They should really use Ip_u2u1u4u3(op) and do the u4/u3 arg
+   blending in the callee and not here in the build_insn() itself. */
+
+#define I_u2u1msbu3(op)					\
+Ip_u2u1msbu3(op)					\
+{							\
+	build_insn(buf, insn##op, b, a, c+d-1, c);	\
+}
+
+#define I_u2u1msb33u3(op)					\
+Ip_u2u1msb33u3(op)						\
+{								\
+	build_insn(buf, insn##op, rs, rt, pos+size-33, pos-32);	\
+}
+#endif
+
 I_u2u1s3(_addiu)
 I_u3u1u2(_addu)
 I_u2u1u3(_andi)
@@ -350,6 +389,7 @@ I_u2u1u3(_dsll)
 I_u2u1u3(_dsll32)
 I_u2u1u3(_dsra)
 I_u2u1u3(_dsrl)
+I_u2u1u3(_drotr)
 I_u2u1u3(_dsrl32)
 I_u3u1u2(_dsubu)
 I_0(_eret)
@@ -376,10 +416,20 @@ I_u2u1u3(_srl)
 I_u3u1u2(_subu)
 I_u2s3u1(_sw)
 I_0(_tlbp)
+I_0(_tlbr)
 I_0(_tlbwi)
 I_0(_tlbwr)
 I_u3u1u2(_xor)
 I_u2u1u3(_xori)
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+I_u3u1u2(_nor);
+I_u1u2s3(_bbit1);
+I_u1u2s3(_bbit132);
+I_u1u2s3(_bbit0);
+I_u1u2s3(_bbit032);
+I_u2u1msbu3(_dins);
+I_u2u1msb33u3(_dinsu);
+#endif
 
 /* Handle labels. */
 void __cpuinit uasm_build_label(struct uasm_label **lab, u32 *addr, int lid)
@@ -589,3 +639,37 @@ uasm_il_bgez(u32 **p, struct uasm_reloc **r, unsigned int reg, int lid)
 	uasm_r_mips_pc16(r, *p, lid);
 	uasm_i_bgez(p, reg, 0);
 }
+
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+void __cpuinit
+uasm_il_bbit1(u32 **p, struct uasm_reloc **r, unsigned int reg,
+				unsigned int bit, int lid)
+{
+	uasm_r_mips_pc16(r, *p, lid);
+	uasm_i_bbit1(p, reg, bit, 0);
+}
+
+void __cpuinit
+uasm_il_bbit132(u32 **p, struct uasm_reloc **r, unsigned int reg,
+				unsigned int bit, int lid)
+{
+	uasm_r_mips_pc16(r, *p, lid);
+	uasm_i_bbit132(p, reg, bit-32, 0);
+}
+
+void __cpuinit
+uasm_il_bbit032(u32 **p, struct uasm_reloc **r, unsigned int reg,
+				unsigned int bit, int lid)
+{
+	uasm_r_mips_pc16(r, *p, lid);
+	uasm_i_bbit032(p, reg, bit-32, 0);
+}
+
+void __cpuinit
+uasm_il_bbit0(u32 **p, struct uasm_reloc **r, unsigned int reg,
+				unsigned int bit, int lid)
+{
+	uasm_r_mips_pc16(r, *p, lid);
+	uasm_i_bbit0(p, reg, bit, 0);
+}
+#endif	/* CONFIG_CPU_CAVIUM_OCTEON */
diff --git a/arch/mips/oprofile/Makefile b/arch/mips/oprofile/Makefile
index 977a828..10b0f4b 100644
--- a/arch/mips/oprofile/Makefile
+++ b/arch/mips/oprofile/Makefile
@@ -16,3 +16,5 @@ oprofile-$(CONFIG_CPU_R10000)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_SB1)		+= op_model_mipsxx.o
 oprofile-$(CONFIG_CPU_VR5500)		+= op_model_vr5500.o
 oprofile-$(CONFIG_CPU_RM9000)		+= op_model_rm9000.o
+oprofile-$(CONFIG_CPU_CAVIUM_OCTEON)	+= op_model_cavium_octeon.o
+
diff --git a/arch/mips/oprofile/common.c b/arch/mips/oprofile/common.c
index 68aad99..6f912d2 100644
--- a/arch/mips/oprofile/common.c
+++ b/arch/mips/oprofile/common.c
@@ -18,6 +18,7 @@
 extern struct op_mips_model op_model_mipsxx_ops __attribute__((weak));
 extern struct op_mips_model op_model_rm9000_ops __attribute__((weak));
 extern struct op_mips_model op_model_vr5500_ops __attribute__((weak));
+extern struct op_mips_model op_model_octeon __attribute__((weak));
 
 static struct op_mips_model *model;
 
@@ -99,6 +100,9 @@ int __init oprofile_arch_init(struct oprofile_operations *ops)
 	case CPU_R5500:
 		lmodel = &op_model_vr5500_ops;
 		break;
+	case CPU_CAVIUM_OCTEON:
+		lmodel = &op_model_octeon;
+		break;
 	};
 
 
diff --git a/crypto/crypto_null.c b/crypto/crypto_null.c
index 1f7d530..be7a20e 100644
--- a/crypto/crypto_null.c
+++ b/crypto/crypto_null.c
@@ -24,7 +24,11 @@
 #include <linux/string.h>
 
 #define NULL_KEY_SIZE		0
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#define NULL_BLOCK_SIZE		4   /* Using a 1 byte block creates absurd overhead */
+#else
 #define NULL_BLOCK_SIZE		1
+#endif
 #define NULL_DIGEST_SIZE	0
 #define NULL_IV_SIZE		0
 
diff --git a/include/asm-mips/asmmacro.h b/include/asm-mips/asmmacro.h
index 7a88175..5408149 100644
--- a/include/asm-mips/asmmacro.h
+++ b/include/asm-mips/asmmacro.h
@@ -35,6 +35,16 @@
 	mtc0	\reg, CP0_TCSTATUS
 	_ehb
 	.endm
+#elif defined(CONFIG_CPU_CAVIUM_OCTEON)
+	.macro	local_irq_enable reg=t0
+	ei
+	irq_enable_hazard
+	.endm
+
+	.macro	local_irq_disable reg=t0
+	di
+	irq_disable_hazard
+	.endm
 #else
 	.macro	local_irq_enable reg=t0
 	mfc0	\reg, CP0_STATUS
diff --git a/include/asm-mips/atomic.h b/include/asm-mips/atomic.h
index 1232be3..9d1f030 100644
--- a/include/asm-mips/atomic.h
+++ b/include/asm-mips/atomic.h
@@ -50,6 +50,17 @@ typedef struct { volatile int counter; } atomic_t;
  */
 static __inline__ void atomic_add(int i, atomic_t * v)
 {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	if (cpu_has_saa) {
+		__asm__ __volatile__(
+		".set	push\n"
+		".set	arch=octeon\n"
+		"saa    %1, (%2)\n"
+		".set	pop\n"
+		: "+m" (v->counter)
+		: "r" (i), "r" (v));
+	} else
+#endif
 	if (cpu_has_llsc && R10000_LLSC_WAR) {
 		unsigned long temp;
 
@@ -95,6 +106,17 @@ static __inline__ void atomic_add(int i, atomic_t * v)
  */
 static __inline__ void atomic_sub(int i, atomic_t * v)
 {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	if (cpu_has_saa) {
+		__asm__ __volatile__(
+		".set	push\n"
+		".set	arch=octeon\n"
+		"saa    %1, (%2)\n"
+		".set	pop\n"
+		: "+m" (v->counter)
+		: "r" (-i), "r" (v));
+	} else
+#endif
 	if (cpu_has_llsc && R10000_LLSC_WAR) {
 		unsigned long temp;
 
@@ -158,6 +180,7 @@ static __inline__ int atomic_add_return(int i, atomic_t * v)
 		unsigned long temp;
 
 		__asm__ __volatile__(
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	ll	%1, %2		# atomic_add_return	\n"
 		"	addu	%0, %1, %3				\n"
@@ -210,6 +233,7 @@ static __inline__ int atomic_sub_return(int i, atomic_t * v)
 		unsigned long temp;
 
 		__asm__ __volatile__(
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	ll	%1, %2		# atomic_sub_return	\n"
 		"	subu	%0, %1, %3				\n"
@@ -274,6 +298,7 @@ static __inline__ int atomic_sub_if_positive(int i, atomic_t * v)
 		unsigned long temp;
 
 		__asm__ __volatile__(
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	ll	%1, %2		# atomic_sub_if_positive\n"
 		"	subu	%0, %1, %3				\n"
@@ -431,6 +456,17 @@ typedef struct { volatile long counter; } atomic64_t;
  */
 static __inline__ void atomic64_add(long i, atomic64_t * v)
 {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	if (cpu_has_saa) {
+		__asm__ __volatile__(
+		".set	push\n"
+		".set	arch=octeon\n"
+		"saad   %1, (%2)\n"
+		".set	pop\n"
+		: "+m" (v->counter)
+		: "r" (i), "r" (v));
+	} else
+#endif
 	if (cpu_has_llsc && R10000_LLSC_WAR) {
 		unsigned long temp;
 
@@ -476,6 +512,17 @@ static __inline__ void atomic64_add(long i, atomic64_t * v)
  */
 static __inline__ void atomic64_sub(long i, atomic64_t * v)
 {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	if (cpu_has_saa) {
+		__asm__ __volatile__(
+		".set	push\n"
+		".set	arch=octeon\n"
+		"saad    %1, (%2)\n"
+		".set	pop\n"
+		: "+m" (v->counter)
+		: "r" (-i), "r" (v));
+	} else
+#endif
 	if (cpu_has_llsc && R10000_LLSC_WAR) {
 		unsigned long temp;
 
@@ -539,6 +586,7 @@ static __inline__ long atomic64_add_return(long i, atomic64_t * v)
 		unsigned long temp;
 
 		__asm__ __volatile__(
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	lld	%1, %2		# atomic64_add_return	\n"
 		"	addu	%0, %1, %3				\n"
@@ -591,6 +639,7 @@ static __inline__ long atomic64_sub_return(long i, atomic64_t * v)
 		unsigned long temp;
 
 		__asm__ __volatile__(
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	lld	%1, %2		# atomic64_sub_return	\n"
 		"	subu	%0, %1, %3				\n"
@@ -655,6 +704,7 @@ static __inline__ long atomic64_sub_if_positive(long i, atomic64_t * v)
 		unsigned long temp;
 
 		__asm__ __volatile__(
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	lld	%1, %2		# atomic64_sub_if_positive\n"
 		"	dsubu	%0, %1, %3				\n"
diff --git a/include/asm-mips/barrier.h b/include/asm-mips/barrier.h
index 8e9ac31..d4acd61 100644
--- a/include/asm-mips/barrier.h
+++ b/include/asm-mips/barrier.h
@@ -78,6 +78,18 @@
 #define __sync()	do { } while(0)
 #endif
 
+
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#define __syncw() 	__asm__ __volatile__(OCTEON_SYNCW_STR ::: "memory")
+#define __fast_iob()	do { } while(0)
+
+#define fast_wmb()	__syncw()
+#define fast_rmb()	do { } while(0)
+#define fast_mb()	__syncw()
+#define fast_iob()	do { } while(0)
+
+#else /* !CONFIG_CPU_CAVIUM_OCTEON */
+
 #define __fast_iob()				\
 	__asm__ __volatile__(			\
 		".set	push\n\t"		\
@@ -104,13 +116,14 @@
 		: /* no output */		\
 		: "m" (*(int *)CKSEG1ADDR(0x1fa00004)) \
 		: "memory")
-#else
+#else /* !CONFIG_SGI_IP28 */
 #define fast_iob()				\
 	do {					\
 		__sync();			\
 		__fast_iob();			\
 	} while (0)
-#endif
+#endif /* !CONFIG_SGI_IP28 */
+#endif /* !CONFIG_CPU_CAVIUM_OCTEON */
 
 #ifdef CONFIG_CPU_HAS_WB
 
@@ -131,19 +144,38 @@
 #endif /* !CONFIG_CPU_HAS_WB */
 
 #if defined(CONFIG_WEAK_ORDERING) && defined(CONFIG_SMP)
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+/* We actually use two syncw instructions in a row when we need a write memory
+   barrier. This is because the CN3XXX series of Octeons have errata Core-401.
+   This can cause a single syncw to not enforce ordering under very rare
+   conditions. Even if it is rare, better safe than sorry */
+#define __WEAK_ORDERING_MB	".set push\n.set arch=octeon\nsyncw\nsyncw\n.set pop\n"
+#define OCTEON_SYNCW_STR	__WEAK_ORDERING_MB
+#define __WEAK_LLSC_MB __WEAK_ORDERING_MB
+#else /* !CONFIG_CPU_CAVIUM_OCTEON */
 #define __WEAK_ORDERING_MB	"       sync	\n"
+#define OCTEON_SYNCW_STR	"		\n"
+#endif
 #else
 #define __WEAK_ORDERING_MB	"		\n"
+#define OCTEON_SYNCW_STR	"		\n"
 #endif
+
+#ifndef __WEAK_LLSC_MB
 #if defined(CONFIG_WEAK_REORDERING_BEYOND_LLSC) && defined(CONFIG_SMP)
 #define __WEAK_LLSC_MB		"       sync	\n"
 #else
 #define __WEAK_LLSC_MB		"		\n"
 #endif
+#endif
 
 #define smp_mb()	__asm__ __volatile__(__WEAK_ORDERING_MB : : :"memory")
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#define smp_rmb()	barrier()
+#else
 #define smp_rmb()	__asm__ __volatile__(__WEAK_ORDERING_MB : : :"memory")
-#define smp_wmb()	__asm__ __volatile__(__WEAK_ORDERING_MB : : :"memory")
+#endif
+#define smp_wmb()	__asm__ __volatile__(__WEAK_ORDERING_MB : : : "memory")
 
 #define set_mb(var, value) \
 	do { var = value; smp_mb(); } while (0)
diff --git a/include/asm-mips/bitops.h b/include/asm-mips/bitops.h
index 49df8c4..36cee80 100644
--- a/include/asm-mips/bitops.h
+++ b/include/asm-mips/bitops.h
@@ -282,6 +282,7 @@ static inline int test_and_set_bit(unsigned long nr,
 		__asm__ __volatile__(
 		"	.set	push					\n"
 		"	.set	noreorder				\n"
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	" __LL "%0, %1		# test_and_set_bit	\n"
 		"	or	%2, %0, %3				\n"
@@ -350,6 +351,7 @@ static inline int test_and_set_bit_lock(unsigned long nr,
 		__asm__ __volatile__(
 		"	.set	push					\n"
 		"	.set	noreorder				\n"
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	" __LL "%0, %1		# test_and_set_bit	\n"
 		"	or	%2, %0, %3				\n"
@@ -419,6 +421,7 @@ static inline int test_and_clear_bit(unsigned long nr,
 		unsigned long temp;
 
 		__asm__ __volatile__(
+		OCTEON_SYNCW_STR
 		"1:	" __LL	"%0, %1		# test_and_clear_bit	\n"
 		"	" __EXT "%2, %0, %3, 1				\n"
 		"	" __INS	"%0, $0, %3, 1				\n"
@@ -438,6 +441,7 @@ static inline int test_and_clear_bit(unsigned long nr,
 		__asm__ __volatile__(
 		"	.set	push					\n"
 		"	.set	noreorder				\n"
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	" __LL	"%0, %1		# test_and_clear_bit	\n"
 		"	or	%2, %0, %3				\n"
@@ -509,6 +513,7 @@ static inline int test_and_change_bit(unsigned long nr,
 		__asm__ __volatile__(
 		"	.set	push					\n"
 		"	.set	noreorder				\n"
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	" __LL	"%0, %1		# test_and_change_bit	\n"
 		"	xor	%2, %0, %3				\n"
@@ -542,7 +547,6 @@ static inline int test_and_change_bit(unsigned long nr,
 }
 
 #include <asm-generic/bitops/non-atomic.h>
-
 /*
  * __clear_bit_unlock - Clears a bit in memory
  * @nr: Bit to clear
@@ -558,7 +562,7 @@ static inline void __clear_bit_unlock(unsigned long nr, volatile unsigned long *
 	__clear_bit(nr, addr);
 }
 
-#if defined(CONFIG_CPU_MIPS32) || defined(CONFIG_CPU_MIPS64)
+#if defined(CONFIG_CPU_MIPS32) || defined(CONFIG_CPU_MIPS64) || defined(CONFIG_CPU_CAVIUM_OCTEON)
 
 /*
  * Return the bit position (0..63) of the most significant 1 bit in a word
@@ -619,7 +623,7 @@ static inline int fls(int word)
 	return 32 - word;
 }
 
-#if defined(CONFIG_64BIT) && defined(CONFIG_CPU_MIPS64)
+#if defined(CONFIG_64BIT) && (defined(CONFIG_CPU_MIPS64) || defined(CONFIG_CPU_CAVIUM_OCTEON))
 static inline int fls64(__u64 word)
 {
 	__asm__("dclz %0, %1" : "=r" (word) : "r" (word));
@@ -662,11 +666,32 @@ static inline int ffs(int word)
 #ifdef __KERNEL__
 
 #include <asm-generic/bitops/sched.h>
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+static inline int hweight64(unsigned long x)
+{
+     return __builtin_popcountl(x);
+}
+
+static inline int hweight32(unsigned int x)
+{
+     return __builtin_popcount(x);
+}
+
+static inline int hweight16(unsigned short x)
+{
+     return __builtin_popcount(x);
+}
+
+static inline int hweight8(unsigned char x)
+{
+     return __builtin_popcount(x);
+}
+#else
 #include <asm-generic/bitops/hweight.h>
+#endif
 #include <asm-generic/bitops/ext2-non-atomic.h>
 #include <asm-generic/bitops/ext2-atomic.h>
 #include <asm-generic/bitops/minix.h>
 
 #endif /* __KERNEL__ */
-
 #endif /* _ASM_BITOPS_H */
diff --git a/include/asm-mips/cmpxchg.h b/include/asm-mips/cmpxchg.h
index 4a812c3..b07cd50 100644
--- a/include/asm-mips/cmpxchg.h
+++ b/include/asm-mips/cmpxchg.h
@@ -35,6 +35,7 @@
 		: "memory");						\
 	} else if (cpu_has_llsc) {					\
 		__asm__ __volatile__(					\
+		OCTEON_SYNCW_STR					\
 		"	.set	push				\n"	\
 		"	.set	noat				\n"	\
 		"	.set	mips3				\n"	\
diff --git a/include/asm-mips/cpu-info.h b/include/asm-mips/cpu-info.h
index 2de73db..744cd8f 100644
--- a/include/asm-mips/cpu-info.h
+++ b/include/asm-mips/cpu-info.h
@@ -12,6 +12,8 @@
 #ifndef __ASM_CPU_INFO_H
 #define __ASM_CPU_INFO_H
 
+#include <linux/types.h>
+
 #include <asm/cache.h>
 
 /*
@@ -69,6 +71,10 @@ struct cpuinfo_mips {
 	int			tc_id;   /* Thread Context number */
 #endif
 	void 			*data;	/* Additional data */
+	unsigned int		watch_reg_count;   /* Number that exist */
+	unsigned int		watch_reg_use_cnt; /* Usable by ptrace */
+#define NUM_WATCH_REGS 4
+	u16			watch_reg_masks[NUM_WATCH_REGS];
 } __attribute__((aligned(SMP_CACHE_BYTES)));
 
 extern struct cpuinfo_mips cpu_data[];
diff --git a/include/asm-mips/cpu.h b/include/asm-mips/cpu.h
index 229a786..c018727 100644
--- a/include/asm-mips/cpu.h
+++ b/include/asm-mips/cpu.h
@@ -33,6 +33,7 @@
 #define PRID_COMP_TOSHIBA	0x070000
 #define PRID_COMP_LSI		0x080000
 #define PRID_COMP_LEXRA		0x0b0000
+#define PRID_COMP_CAVIUM	0x0d0000
 
 
 /*
@@ -114,6 +115,18 @@
 #define PRID_IMP_BCM3302	0x9000
 
 /*
+ * These are the PRID's for when 23:16 == PRID_COMP_CAVIUM
+ */
+
+#define PRID_IMP_CAVIUM_CN38XX 0x0000
+#define PRID_IMP_CAVIUM_CN31XX 0x0100
+#define PRID_IMP_CAVIUM_CN30XX 0x0200
+#define PRID_IMP_CAVIUM_CN58XX 0x0300
+#define PRID_IMP_CAVIUM_CN56XX 0x0400
+#define PRID_IMP_CAVIUM_CN50XX 0x0600
+#define PRID_IMP_CAVIUM_CN52XX 0x0700
+
+/*
  * Definitions for 7:0 on legacy processors
  */
 
@@ -203,6 +216,7 @@ enum cpu_type_enum {
 	 * MIPS64 class processors
 	 */
 	CPU_5KC, CPU_20KC, CPU_25KF, CPU_SB1, CPU_SB1A, CPU_LOONGSON2,
+	CPU_CAVIUM_OCTEON,
 
 	CPU_LAST
 };
diff --git a/include/asm-mips/delay.h b/include/asm-mips/delay.h
index b0bccd2..d0742cc 100644
--- a/include/asm-mips/delay.h
+++ b/include/asm-mips/delay.h
@@ -16,6 +16,7 @@
 
 #include <asm/compiler.h>
 #include <asm/war.h>
+#include <asm/time.h>
 
 static inline void __delay(unsigned long loops)
 {
@@ -48,6 +49,38 @@ static inline void __delay(unsigned long loops)
 		: "0" (loops), "r" (1));
 }
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+
+/*
+ * Replacement for what was being done in get_cycles()
+ * which is being phased out.  If the custom udelay()
+ * goes away, then the octeon_get_cycles should just
+ * revert to using read_c0_count()
+ */
+static inline unsigned long octeon_get_cycles(void)
+{
+	unsigned long result;
+	asm volatile ("rdhwr %0,$31\n"
+#ifndef CONFIG_64BIT
+			"sll %0,0\n"
+#endif
+			: "=r" (result));
+	return result;
+}
+
+/* Implementation of udelay, which unlike the default will actually delay
+    the correct amount of time. Among the other problems with the default
+    spin loop implementation, it overflows at 1ms */
+static inline void udelay(unsigned long usecs)
+{
+	unsigned long cycles = octeon_get_cycles();
+	unsigned long end_cycles = cycles + usecs * (mips_hpt_frequency/1000000);
+	do {
+		cycles = octeon_get_cycles();
+	} while (cycles < end_cycles);
+}
+
+#else
 
 /*
  * Division by multiplication: you don't have to worry about
@@ -109,4 +142,6 @@ static inline void __udelay(unsigned long usecs, unsigned long lpj)
 #define MAX_UDELAY_MS	(1000 / HZ)
 #endif
 
+#endif /* CONFIG_CPU_CAVIUM_OCTEON */
+
 #endif /* _ASM_DELAY_H */
diff --git a/include/asm-mips/dma.h b/include/asm-mips/dma.h
index 1353c81..1706089 100644
--- a/include/asm-mips/dma.h
+++ b/include/asm-mips/dma.h
@@ -87,6 +87,13 @@
 #if defined(CONFIG_SGI_IP22) || defined(CONFIG_SGI_IP28)
 /* don't care; ISA bus master won't work, ISA slave DMA supports 32bit addr */
 #define MAX_DMA_ADDRESS		PAGE_OFFSET
+#elif defined(CONFIG_CPU_CAVIUM_OCTEON)
+/* Octeon can support DMA to any memory installed */
+#ifdef CONFIG_64BIT
+#define MAX_DMA_ADDRESS		(PAGE_OFFSET + (1ull<<32))
+#else
+#define MAX_DMA_ADDRESS		(PAGE_OFFSET + (1ul<<30))
+#endif
 #else
 #define MAX_DMA_ADDRESS		(PAGE_OFFSET + 0x01000000)
 #endif
diff --git a/include/asm-mips/fpu_emulator.h b/include/asm-mips/fpu_emulator.h
index 2731c38..4917cbd 100644
--- a/include/asm-mips/fpu_emulator.h
+++ b/include/asm-mips/fpu_emulator.h
@@ -33,5 +33,10 @@ struct mips_fpu_emulator_stats {
 };
 
 extern struct mips_fpu_emulator_stats fpuemustats;
+#ifdef CONFIG_MIPS_FPU_EMULATOR_STATS_ENABLED
+#define FPUEMUSTATS_INC(field) fpuemustats.field++
+#else
+#define FPUEMUSTATS_INC(field) do {} while (0)
+#endif
 
 #endif /* _ASM_FPU_EMULATOR_H */
diff --git a/include/asm-mips/hazards.h b/include/asm-mips/hazards.h
index 2de638f..43baed1 100644
--- a/include/asm-mips/hazards.h
+++ b/include/asm-mips/hazards.h
@@ -42,7 +42,7 @@ ASMMACRO(_ehb,
 /*
  * TLB hazards
  */
-#if defined(CONFIG_CPU_MIPSR2)
+#if defined(CONFIG_CPU_MIPSR2) && !defined(CONFIG_CPU_CAVIUM_OCTEON)
 
 /*
  * MIPSR2 defines ehb for hazard avoidance
@@ -138,7 +138,7 @@ do {									\
 		__instruction_hazard();					\
 } while (0)
 
-#elif defined(CONFIG_CPU_R10000)
+#elif defined(CONFIG_CPU_R10000) || defined(CONFIG_CPU_CAVIUM_OCTEON)
 
 /*
  * R10000 rocks - all hazards handled in hardware, so this becomes a nobrainer.
diff --git a/include/asm-mips/io.h b/include/asm-mips/io.h
index 501a40b..8c89749 100644
--- a/include/asm-mips/io.h
+++ b/include/asm-mips/io.h
@@ -295,6 +295,12 @@ static inline void iounmap(const volatile void __iomem *addr)
 #undef __IS_KSEG1
 }
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#define war_octeon_io_reorder_wmb()  		wmb()
+#else
+#define war_octeon_io_reorder_wmb()		do { } while(0)
+#endif
+
 #define __BUILD_MEMORY_SINGLE(pfx, bwlq, type, irq)			\
 									\
 static inline void pfx##write##bwlq(type val,				\
@@ -303,6 +309,8 @@ static inline void pfx##write##bwlq(type val,				\
 	volatile type *__mem;						\
 	type __val;							\
 									\
+	war_octeon_io_reorder_wmb();					\
+									\
 	__mem = (void *)__swizzle_addr_##bwlq((unsigned long)(mem));	\
 									\
 	__val = pfx##ioswab##bwlq(__mem, val);				\
@@ -370,6 +378,8 @@ static inline void pfx##out##bwlq##p(type val, unsigned long port)	\
 	volatile type *__addr;						\
 	type __val;							\
 									\
+	war_octeon_io_reorder_wmb();					\
+									\
 	__addr = (void *)__swizzle_addr_##bwlq(mips_io_port_base + port); \
 									\
 	__val = pfx##ioswab##bwlq(__addr, val);				\
@@ -504,8 +514,12 @@ BUILDSTRING(q, u64)
 #endif
 
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#define mmiowb() wmb()
+#else
 /* Depends on MIPS II instruction set */
 #define mmiowb() asm volatile ("sync" ::: "memory")
+#endif
 
 static inline void memset_io(volatile void __iomem *addr, unsigned char val, int count)
 {
diff --git a/include/asm-mips/mach-generic/dma-coherence.h b/include/asm-mips/mach-generic/dma-coherence.h
index 76e04e7..bdafa8c 100644
--- a/include/asm-mips/mach-generic/dma-coherence.h
+++ b/include/asm-mips/mach-generic/dma-coherence.h
@@ -40,6 +40,13 @@ static inline int plat_device_is_coherent(struct device *dev)
 #ifdef CONFIG_DMA_NONCOHERENT
 	return 0;
 #endif
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	/* The Cavium Octeon has fully coherent DMA but doesn't use
+		CONFIG_DMA_COHERENT so it can replace the normally DMA
+		mapping functions with ones supporting 64bit mappings
+		specific to Octeon */
+	return 1;
+#endif
 }
 
 #endif /* __ASM_MACH_GENERIC_DMA_COHERENCE_H */
diff --git a/include/asm-mips/mach-generic/mc146818rtc.h b/include/asm-mips/mach-generic/mc146818rtc.h
index 0b9a942..0c8359e 100644
--- a/include/asm-mips/mach-generic/mc146818rtc.h
+++ b/include/asm-mips/mach-generic/mc146818rtc.h
@@ -13,7 +13,9 @@
 #include <asm/io.h>
 
 #define RTC_PORT(x)	(0x70 + (x))
+#ifndef RTC_IRQ
 #define RTC_IRQ		8
+#endif
 
 static inline unsigned char CMOS_READ(unsigned long addr)
 {
diff --git a/include/asm-mips/mipsmtregs.h b/include/asm-mips/mipsmtregs.h
index c9420aa..389712c 100644
--- a/include/asm-mips/mipsmtregs.h
+++ b/include/asm-mips/mipsmtregs.h
@@ -9,6 +9,7 @@
 
 #include <asm/mipsregs.h>
 #include <asm/war.h>
+#include <asm/hazards.h>
 
 #ifndef __ASSEMBLY__
 
diff --git a/include/asm-mips/module.h b/include/asm-mips/module.h
index de6d09e..7b24183 100644
--- a/include/asm-mips/module.h
+++ b/include/asm-mips/module.h
@@ -114,6 +114,8 @@ search_module_dbetables(unsigned long addr)
 #define MODULE_PROC_FAMILY "SB1 "
 #elif defined CONFIG_CPU_LOONGSON2
 #define MODULE_PROC_FAMILY "LOONGSON2 "
+#elif defined CONFIG_CPU_CAVIUM_OCTEON
+#define MODULE_PROC_FAMILY "OCTEON "
 #else
 #error MODULE_PROC_FAMILY undefined for your processor configuration
 #endif
diff --git a/include/asm-mips/processor.h b/include/asm-mips/processor.h
index a1e4453..e5aa3a6 100644
--- a/include/asm-mips/processor.h
+++ b/include/asm-mips/processor.h
@@ -56,7 +56,11 @@ extern unsigned int vced_count, vcei_count;
  * support 16TB; the architectural reserve for future expansion is
  * 8192EB ...
  */
+#ifdef CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB
+#define TASK_SIZE32	(0x7fff8000UL - (CONFIG_CAVIUM_RESERVE32<<20))
+#else
 #define TASK_SIZE32	0x7fff8000UL
+#endif
 #define TASK_SIZE	0x10000000000UL
 #define STACK_TOP	\
       (test_thread_flag(TIF_32BIT_ADDR) ? TASK_SIZE32 : TASK_SIZE)
@@ -105,6 +109,52 @@ struct mips_dsp_state {
 	{0,} \
 }
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+
+struct octeon_cop2_state {
+	unsigned long   cop2_crc_iv;        /* DMFC2 rt, 0x0201 */
+	unsigned long   cop2_crc_length;    /* DMFC2 rt, 0x0202 (Set with DMTC2 rt, 0x1202) */
+	unsigned long   cop2_crc_poly;      /* DMFC2 rt, 0x0200 (set with DMTC2 rt, 0x4200) */
+
+	unsigned long   cop2_llm_dat[2];    /* DMFC2 rt, 0x0402; DMFC2 rt, 0x040A */
+
+	unsigned long   cop2_3des_iv;       /* DMFC2 rt, 0x0084 */
+	unsigned long   cop2_3des_key[3];   /* DMFC2 rt, 0x0080; DMFC2 rt, 0x0081; DMFC2 rt, 0x0082 */
+	unsigned long   cop2_3des_result;   /* DMFC2 rt, 0x0088 (Set with DMTC2 rt, 0x0098) */
+	unsigned long   cop2_aes_inp0;      /* DMFC2 rt, 0x0111 (FIXME: Read Pass1 Errata) */
+	unsigned long   cop2_aes_iv[2];     /* DMFC2 rt, 0x0102; DMFC2 rt, 0x0103 */
+	unsigned long   cop2_aes_key[4];    /* DMFC2 rt, 0x0104; DMFC2 rt, 0x0105; DMFC2 rt, 0x0106; DMFC2 rt, 0x0107 */
+	unsigned long   cop2_aes_keylen;    /* DMFC2 rt, 0x0110 */
+	unsigned long   cop2_aes_result[2]; /* DMFC2 rt, 0x0100; DMFC2 rt, 0x0101 */
+
+	unsigned long   cop2_hsh_datw[15];  /* DMFC2 rt, 0x0240; DMFC2 rt, 0x0241; DMFC2 rt, 0x0242; DMFC2 rt, 0x0243; DMFC2 rt, 0x0244; DMFC2 rt, 0x0245; DMFC2 rt, 0x0246; DMFC2 rt, 0x0247; DMFC2 rt, 0x0248; DMFC2 rt, 0x0249; DMFC2 rt, 0x024A; DMFC2 rt, 0x024B; DMFC2 rt, 0x024C; DMFC2 rt, 0x024D; DMFC2 rt, 0x024E - Pass2 */
+	unsigned long   cop2_hsh_ivw[8];    /* DMFC2 rt, 0x0250; DMFC2 rt, 0x0251; DMFC2 rt, 0x0252; DMFC2 rt, 0x0253; DMFC2 rt, 0x0254; DMFC2 rt, 0x0255; DMFC2 rt, 0x0256; DMFC2 rt, 0x0257 - Pass2 */
+	unsigned long   cop2_gfm_mult[2];   /* DMFC2 rt, 0x0258; DMFC2 rt, 0x0259 - Pass2 */
+	unsigned long   cop2_gfm_poly;      /* DMFC2 rt, 0x025E - Pass2 */
+	unsigned long   cop2_gfm_result[2]; /* DMFC2 rt, 0x025A; DMFC2 rt, 0x025B - Pass2 */
+};
+#define INIT_OCTEON_COP2 {0,}
+
+struct octeon_cvmseg_state {
+    unsigned long   cvmseg[CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE][cpu_dcache_line_size()/sizeof(unsigned long)];
+};
+#define INIT_OCTEON_CVMSEG {{{0,},}}
+
+#endif
+
+struct mips3264_watch_reg_state {
+	/* The width of watchlo is 32 in a 32 bit kernel and 64 in a
+	   64 bit kernel.  We use unsigned long as it has the same
+	   property. */
+	unsigned long watchlo[NUM_WATCH_REGS];
+	/* Only the mask and IRW bits from watchhi. */
+	u16 watchhi[NUM_WATCH_REGS];
+};
+
+union mips_watch_reg_state {
+	struct mips3264_watch_reg_state mips3264;
+};
+
 typedef struct {
 	unsigned long seg;
 } mm_segment_t;
@@ -137,6 +187,9 @@ struct thread_struct {
 	/* Saved state of the DSP ASE, if available. */
 	struct mips_dsp_state dsp;
 
+	/* Saved watch register state, if available. */
+	union mips_watch_reg_state watch;
+
 	/* Other stuff associated with the thread. */
 	unsigned long cp0_badvaddr;	/* Last user fault */
 	unsigned long cp0_baduaddr;	/* Last kernel fault accessing USEG */
@@ -144,6 +197,10 @@ struct thread_struct {
 	unsigned long trap_no;
 	unsigned long irix_trampoline;  /* Wheee... */
 	unsigned long irix_oldctx;
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+    struct octeon_cop2_state cp2 __attribute__ ((__aligned__(128)));
+    struct octeon_cvmseg_state cvmseg __attribute__ ((__aligned__(128)));
+#endif
 	struct mips_abi *abi;
 };
 
@@ -155,6 +212,14 @@ struct thread_struct {
 #define FPAFF_INIT
 #endif /* CONFIG_MIPS_MT_FPAFF */
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#define OCTEON_INIT						\
+	.cp2			= INIT_OCTEON_COP2,		\
+	.cvmseg			= INIT_OCTEON_CVMSEG,
+#else
+#define OCTEON_INIT
+#endif /* CONFIG_CPU_CAVIUM_OCTEON */
+
 #define INIT_THREAD  {						\
         /*							\
          * Saved main processor registers			\
@@ -193,6 +258,10 @@ struct thread_struct {
 		.dspcontrol	= 0,				\
 	},							\
 	/*							\
+	 * saved watch register stuff				\
+	 */							\
+	.watch = {{{0,},},},					\
+	/*							\
 	 * Other stuff associated with the process		\
 	 */							\
 	.cp0_badvaddr		= 0,				\
@@ -201,6 +270,10 @@ struct thread_struct {
 	.trap_no		= 0,				\
 	.irix_trampoline	= 0,				\
 	.irix_oldctx		= 0,				\
+	/*							\
+	 * Cavium Octeon specifics (null if not Octeon)		\
+	 */							\
+	OCTEON_INIT						\
 }
 
 struct task_struct;
@@ -260,4 +333,12 @@ static inline void prefetch(const void *addr)
 
 #endif
 
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS) || \
+	defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
+#define prepare_arch_switch(next)  cavium_prepare_arch_switch(next)
+extern void cavium_prepare_arch_switch(struct task_struct *next);
+extern int xkphys_usermem_read(long pid);
+extern int xkphys_usermem_write(long pid, int value);
+#endif
+
 #endif /* _ASM_PROCESSOR_H */
diff --git a/include/asm-mips/ptrace.h b/include/asm-mips/ptrace.h
index 97ae5bb..c6a3324 100644
--- a/include/asm-mips/ptrace.h
+++ b/include/asm-mips/ptrace.h
@@ -49,6 +49,10 @@ struct pt_regs {
 #ifdef CONFIG_MIPS_MT_SMTC
 	unsigned long cp0_tcstatus;
 #endif /* CONFIG_MIPS_MT_SMTC */
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	unsigned long long mpl[3];        /* MTM{0,1,2} */
+	unsigned long long mtp[3];        /* MTP{0,1,2} */
+#endif
 } __attribute__ ((aligned (8)));
 
 #ifdef __KERNEL__
@@ -73,11 +77,57 @@ struct pt_regs {
 #define PTRACE_POKEDATA_3264	0xc3
 #define PTRACE_GET_THREAD_AREA_3264	0xc4
 
+/* Read and write watchpoint registers.  */
+enum pt_watch_style {
+	pt_watch_style_mips32,
+	pt_watch_style_mips64
+};
+struct mips32_watch_regs {
+	unsigned int watchlo[8];
+	/* Lower 16 bits of watchhi. */
+	unsigned short watchhi[8];
+	/* Valid mask and I R W bits.
+	 * bit 0 -- 1 if W bit is usable.
+	 * bit 1 -- 1 if R bit is usable.
+	 * bit 2 -- 1 if I bit is usable.
+	 * bits 3 - 11 -- Valid watchhi mask bits.
+	 */
+	unsigned short watch_masks[8];
+	/* The number of valid watch register pairs.  */
+	unsigned int num_valid;
+} __attribute__((aligned(8)));
+
+struct mips64_watch_regs {
+	unsigned long long watchlo[8];
+	unsigned short watchhi[8];
+	unsigned short watch_masks[8];
+	unsigned int num_valid;
+} __attribute__((aligned(8)));
+
+struct pt_watch_regs {
+	enum pt_watch_style style;
+	union {
+		struct mips32_watch_regs mips32;
+		struct mips64_watch_regs mips64;
+	};
+};
+
+#define PTRACE_GET_WATCH_REGS	0xd0
+#define PTRACE_SET_WATCH_REGS	0xd1
+
 #ifdef __KERNEL__
 
+#include <linux/compiler.h>
 #include <linux/linkage.h>
 #include <asm/isadep.h>
 
+struct task_struct;
+
+extern int ptrace_get_watch_regs(struct task_struct *child,
+	struct pt_watch_regs __user *addr);
+extern int ptrace_set_watch_regs(struct task_struct *child,
+	struct pt_watch_regs __user *addr);
+
 /*
  * Does the process account for user or for system time?
  */
diff --git a/include/asm-mips/smp.h b/include/asm-mips/smp.h
index 220c18c..edd3837 100644
--- a/include/asm-mips/smp.h
+++ b/include/asm-mips/smp.h
@@ -37,6 +37,9 @@ extern int __cpu_logical_map[NR_CPUS];
 
 #define SMP_RESCHEDULE_YOURSELF	0x1	/* XXX braindead */
 #define SMP_CALL_FUNCTION	0x2
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#define SMP_ICACHE_FLUSH	0x4     /* Octeon - Tell another core to flush its icache */
+#endif
 
 extern volatile cpumask_t cpu_callin_map;
 extern cpumask_t phys_cpu_present_map;
diff --git a/include/asm-mips/spinlock.h b/include/asm-mips/spinlock.h
index bb89701..19720c1 100644
--- a/include/asm-mips/spinlock.h
+++ b/include/asm-mips/spinlock.h
@@ -16,10 +16,17 @@
  * Your basic SMP spinlocks, allowing only a single CPU anywhere
  */
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#define __raw_spin_is_locked(x) ((x)->now_serving != (x)->ticket)
+#define __raw_spin_lock_flags(lock, flags) __raw_spin_lock(lock)
+#define __raw_spin_unlock_wait(x) \
+	do { cpu_relax(); } while (__raw_spin_is_locked(x))
+#else
 #define __raw_spin_is_locked(x)       ((x)->lock != 0)
 #define __raw_spin_lock_flags(lock, flags) __raw_spin_lock(lock)
 #define __raw_spin_unlock_wait(x) \
 	do { cpu_relax(); } while ((x)->lock)
+#endif
 
 /*
  * Simple spin lock operations.  There are two variants, one clears IRQ's
@@ -30,6 +37,44 @@
 
 static inline void __raw_spin_lock(raw_spinlock_t *lock)
 {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	int tmp;
+	int my_ticket;
+	__asm__ __volatile__ (
+	"	.set push					\n"
+	"	.set noreorder					\n"
+	"1:							\n"
+	"	ll	%[my_ticket], %[ticket_ptr]		\n"
+	"	li	%[ticket], 1				\n"
+	"	addu	%[ticket], %[my_ticket]			\n"
+	"	sc	%[ticket], %[ticket_ptr]		\n"
+	"	beqz	%[ticket], 1b				\n"
+	"	 syncw						\n"
+	"	syncw						\n"
+	"	lw	%[ticket], %[now_serving]		\n"
+	"	bne	%[ticket], %[my_ticket], 2f		\n"
+	"	 subu	%[ticket], %[my_ticket], %[ticket]	\n"
+	"4:							\n"
+	"	.subsection 2					\n"
+	"2:							\n"
+	"	subu	%[ticket], 1				\n"
+	"	sll	%[ticket], 5				\n"
+	"3:							\n"
+	"	bnez	%[ticket], 3b				\n"
+	"	 subu	%[ticket], 1				\n"
+	"	lw	%[ticket], %[now_serving]		\n"
+	"	beq	%[ticket], %[my_ticket], 4b		\n"
+	"	 subu	%[ticket], %[my_ticket], %[ticket]	\n"
+	"	subu	%[ticket], 1				\n"
+	"	b	3b					\n"
+	"	 sll	%[ticket], 5				\n"
+	"	.previous					\n"
+	"	.set pop					\n"
+	: [ticket_ptr] "=m" (lock->ticket),
+	[now_serving] "=m" (lock->now_serving),
+	[ticket] "=r" (tmp),
+	[my_ticket] "=r" (my_ticket));
+#else
 	unsigned int tmp;
 
 	if (R10000_LLSC_WAR) {
@@ -68,10 +113,18 @@ static inline void __raw_spin_lock(raw_spinlock_t *lock)
 	}
 
 	smp_llsc_mb();
+#endif
 }
 
 static inline void __raw_spin_unlock(raw_spinlock_t *lock)
 {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	int now_serving = lock->now_serving;
+	wmb();
+	if (likely(now_serving != lock->ticket))
+		lock->now_serving = now_serving+1;
+	wmb();
+#else
 	smp_mb();
 
 	__asm__ __volatile__(
@@ -81,10 +134,17 @@ static inline void __raw_spin_unlock(raw_spinlock_t *lock)
 	: "=m" (lock->lock)
 	: "m" (lock->lock)
 	: "memory");
+#endif
 }
 
 static inline unsigned int __raw_spin_trylock(raw_spinlock_t *lock)
 {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	if (__raw_spin_is_locked(lock))
+		return 0;
+	__raw_spin_lock(lock);
+	return 1;
+#else
 	unsigned int temp, res;
 
 	if (R10000_LLSC_WAR) {
@@ -121,6 +181,7 @@ static inline unsigned int __raw_spin_trylock(raw_spinlock_t *lock)
 	smp_llsc_mb();
 
 	return res == 0;
+#endif
 }
 
 /*
@@ -162,6 +223,21 @@ static inline void __raw_read_lock(raw_rwlock_t *rw)
 		: "m" (rw->lock)
 		: "memory");
 	} else {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		__asm__ __volatile__(
+		"	.set	noreorder	# _raw_read_lock	\n"
+		OCTEON_SYNCW_STR
+		"1:	ll	%1, %2					\n"
+		"	bltz	%1, 1b					\n"
+		"	 addu	%1, 1					\n"
+		"	sc	%1, %0			# This will go out after the syncw completes\n"
+		"	beqz	%1, 1b					\n"
+		"	 nop # No syncw is needed here since the sc goes out immediately\n"
+		"	.set	reorder					\n"
+		: "=m" (rw->lock), "=&r" (tmp)
+		: "m" (rw->lock)
+		: "memory");
+#else
 		__asm__ __volatile__(
 		"	.set	noreorder	# __raw_read_lock	\n"
 		"1:	ll	%1, %2					\n"
@@ -181,6 +257,7 @@ static inline void __raw_read_lock(raw_rwlock_t *rw)
 		: "=m" (rw->lock), "=&r" (tmp)
 		: "m" (rw->lock)
 		: "memory");
+#endif
 	}
 
 	smp_llsc_mb();
@@ -205,6 +282,20 @@ static inline void __raw_read_unlock(raw_rwlock_t *rw)
 		: "m" (rw->lock)
 		: "memory");
 	} else {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		__asm__ __volatile__(
+		"	.set	noreorder	# _raw_read_unlock	\n"
+		OCTEON_SYNCW_STR
+		"1:	ll	%1, %2					\n"
+		"	sub	%1, 1					\n"
+		"	sc	%1, %0					\n"
+		"	beqz	%1, 1b					\n"
+		"	 nop						\n"
+		"	.set	reorder					\n"
+		: "=m" (rw->lock), "=&r" (tmp)
+		: "m" (rw->lock)
+		: "memory");
+#else
 		__asm__ __volatile__(
 		"	.set	noreorder	# __raw_read_unlock	\n"
 		"1:	ll	%1, %2					\n"
@@ -220,6 +311,7 @@ static inline void __raw_read_unlock(raw_rwlock_t *rw)
 		: "=m" (rw->lock), "=&r" (tmp)
 		: "m" (rw->lock)
 		: "memory");
+#endif
 	}
 }
 
@@ -241,6 +333,21 @@ static inline void __raw_write_lock(raw_rwlock_t *rw)
 		: "m" (rw->lock)
 		: "memory");
 	} else {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		__asm__ __volatile__(
+		"	.set	noreorder	# _raw_write_lock	\n"
+		OCTEON_SYNCW_STR
+		"1:	ll	%1, %2					\n"
+		"	bnez	%1, 1b					\n"
+		"	 lui	%1, 0x8000				\n"
+		"	sc	%1, %0			# This will go out after the syncw completes\n"
+		"	beqz	%1, 1b					\n"
+		"	 nop # No syncw is needed here since the sc goes out immediately\n"
+		"	.set	reorder					\n"
+		: "=m" (rw->lock), "=&r" (tmp)
+		: "m" (rw->lock)
+		: "memory");
+#else
 		__asm__ __volatile__(
 		"	.set	noreorder	# __raw_write_lock	\n"
 		"1:	ll	%1, %2					\n"
@@ -260,6 +367,7 @@ static inline void __raw_write_lock(raw_rwlock_t *rw)
 		: "=m" (rw->lock), "=&r" (tmp)
 		: "m" (rw->lock)
 		: "memory");
+#endif
 	}
 
 	smp_llsc_mb();
@@ -272,6 +380,7 @@ static inline void __raw_write_unlock(raw_rwlock_t *rw)
 	__asm__ __volatile__(
 	"				# __raw_write_unlock	\n"
 	"	sw	$0, %0					\n"
+	OCTEON_SYNCW_STR
 	: "=m" (rw->lock)
 	: "m" (rw->lock)
 	: "memory");
@@ -344,6 +453,24 @@ static inline int __raw_write_trylock(raw_rwlock_t *rw)
 		: "m" (rw->lock)
 		: "memory");
 	} else {
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		__asm__ __volatile__(
+		"	.set	noreorder	# _raw_write_trylock	\n"
+		OCTEON_SYNCW_STR
+		"	li	%2, 0					\n"
+		"1:	ll	%1, %3					\n"
+		"	bnez	%1, 2f					\n"
+		"	lui	%1, 0x8000				\n"
+		"	sc	%1, %0			# This will go out after the syncw completes\n"
+		"	beqz	%1, 1b					\n"
+		"	 nop # No syncw is needed here since the sc goes out immediately\n"
+		"	li	%2, 1					\n"
+		"	.set	reorder					\n"
+		"2:							\n"
+		: "=m" (rw->lock), "=&r" (tmp), "=&r" (ret)
+		: "m" (rw->lock)
+		: "memory");
+#else
 		__asm__ __volatile__(
 		"	.set	noreorder	# __raw_write_trylock	\n"
 		"	li	%2, 0					\n"
@@ -363,6 +490,7 @@ static inline int __raw_write_trylock(raw_rwlock_t *rw)
 		: "=m" (rw->lock), "=&r" (tmp), "=&r" (ret)
 		: "m" (rw->lock)
 		: "memory");
+#endif
 	}
 
 	return ret;
diff --git a/include/asm-mips/spinlock_types.h b/include/asm-mips/spinlock_types.h
index ce26c50..362f3e2 100644
--- a/include/asm-mips/spinlock_types.h
+++ b/include/asm-mips/spinlock_types.h
@@ -5,11 +5,20 @@
 # error "please don't include this file directly"
 #endif
 
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+typedef struct {
+	volatile unsigned int ticket;
+	volatile unsigned int now_serving;
+} raw_spinlock_t;
+
+#define __RAW_SPIN_LOCK_UNLOCKED	{ 0, 0 }
+#else
 typedef struct {
 	volatile unsigned int lock;
 } raw_spinlock_t;
 
 #define __RAW_SPIN_LOCK_UNLOCKED	{ 0 }
+#endif
 
 typedef struct {
 	volatile unsigned int lock;
diff --git a/include/asm-mips/stackframe.h b/include/asm-mips/stackframe.h
index 4c37c4e..ee81b3f 100644
--- a/include/asm-mips/stackframe.h
+++ b/include/asm-mips/stackframe.h
@@ -51,10 +51,12 @@
 		LONG_S	v1, PT_ACX(sp)
 #else
 		mfhi	v1
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
 		LONG_S	v1, PT_HI(sp)
 		mflo	v1
 		LONG_S	v1, PT_LO(sp)
 #endif
+#endif
 #ifdef CONFIG_32BIT
 		LONG_S	$8, PT_R8(sp)
 		LONG_S	$9, PT_R9(sp)
@@ -62,10 +64,17 @@
 		LONG_S	$10, PT_R10(sp)
 		LONG_S	$11, PT_R11(sp)
 		LONG_S	$12, PT_R12(sp)
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		LONG_S	v1, PT_HI(sp)
+		mflo	v1
+#endif
 		LONG_S	$13, PT_R13(sp)
 		LONG_S	$14, PT_R14(sp)
 		LONG_S	$15, PT_R15(sp)
 		LONG_S	$24, PT_R24(sp)
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		LONG_S	v1, PT_LO(sp)
+#endif
 		.endm
 
 		.macro	SAVE_STATIC
@@ -166,7 +175,9 @@
 		LONG_S	$0, PT_R0(sp)
 		mfc0	v1, CP0_STATUS
 		LONG_S	$2, PT_R2(sp)
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
 		LONG_S	v1, PT_STATUS(sp)
+#endif
 #ifdef CONFIG_MIPS_MT_SMTC
 		/*
 		 * Ideally, these instructions would be shuffled in
@@ -178,22 +189,52 @@
 		LONG_S	v1, PT_TCSTATUS(sp)
 #endif /* CONFIG_MIPS_MT_SMTC */
 		LONG_S	$4, PT_R4(sp)
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
 		mfc0	v1, CP0_CAUSE
+#endif
 		LONG_S	$5, PT_R5(sp)
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		LONG_S	v1, PT_STATUS(sp)
+		mfc0	v1, CP0_CAUSE
+#else
 		LONG_S	v1, PT_CAUSE(sp)
+#endif
 		LONG_S	$6, PT_R6(sp)
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
 		MFC0	v1, CP0_EPC
+#endif
 		LONG_S	$7, PT_R7(sp)
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		LONG_S	v1, PT_CAUSE(sp)
+		MFC0	v1, CP0_EPC
+#endif
 #ifdef CONFIG_64BIT
 		LONG_S	$8, PT_R8(sp)
 		LONG_S	$9, PT_R9(sp)
 #endif
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
 		LONG_S	v1, PT_EPC(sp)
+#endif
 		LONG_S	$25, PT_R25(sp)
 		LONG_S	$28, PT_R28(sp)
 		LONG_S	$31, PT_R31(sp)
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		LONG_S	v1, PT_EPC(sp)
+#endif
 		ori	$28, sp, _THREAD_MASK
 		xori	$28, _THREAD_MASK
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		.set    mips64
+		pref    0, 0($28)       /* Prefetch the current pointer */
+		pref    0, PT_R31(sp)   /* Prefetch the $31(ra) */
+		/* The Octeon multiplier state is affected by general multiply
+		    instructions. It must be saved before and kernel code might
+		    corrupt it */
+		jal     octeon_mult_save
+		LONG_L  v1, 0($28)  /* Load the current pointer */
+		LONG_L  ra, PT_R31(sp)      /* Restore $31(ra) that was changed by the jal */
+		pref    0, 0(v1)    /* Prefetch the current thread */
+#endif
 		.set	pop
 		.endm
 
@@ -324,6 +365,10 @@
 		DVPE	5				# dvpe a1
 		jal	mips_ihb
 #endif /* CONFIG_MIPS_MT_SMTC */
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+		/* Restore the Octeon multiplier state */
+		jal	octeon_mult_restore
+#endif
 		mfc0	a0, CP0_STATUS
 		ori	a0, STATMASK
 		xori	a0, STATMASK
@@ -409,6 +454,9 @@
 		.macro	RESTORE_SP_AND_RET
 		LONG_L	sp, PT_R29(sp)
 		.set	mips3
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+		LONG_L	k0, FAST_ACCESS_THREAD_OFFSET($0) /* K0 = thread pointer */
+#endif
 		eret
 		.set	mips0
 		.endm
diff --git a/include/asm-mips/sysmips.h b/include/asm-mips/sysmips.h
index 4f47b7d..8fb8df8 100644
--- a/include/asm-mips/sysmips.h
+++ b/include/asm-mips/sysmips.h
@@ -22,4 +22,7 @@
 #define MIPS_RDNVRAM              10	/* read NVRAM */
 #define MIPS_ATOMIC_SET		2001	/* atomically set variable       */
 
+#define MIPS_CAVIUM_XKPHYS_READ	   2010	/* XKPHYS */
+#define MIPS_CAVIUM_XKPHYS_WRITE	   2011	/* XKPHYS */
+
 #endif /* _ASM_SYSMIPS_H */
diff --git a/include/asm-mips/system.h b/include/asm-mips/system.h
index 5009e54..cdf96c9 100644
--- a/include/asm-mips/system.h
+++ b/include/asm-mips/system.h
@@ -20,6 +20,7 @@
 #include <asm/cmpxchg.h>
 #include <asm/cpu-features.h>
 #include <asm/dsp.h>
+#include <asm/watch.h>
 #include <asm/war.h>
 #include <asm/asm.h>
 
@@ -77,6 +78,7 @@ do {									\
 		__restore_dsp(current);					\
 	if (cpu_has_userlocal)						\
 		write_c0_userlocal(current_thread_info()->tp_value);	\
+	__restore_watch();						\
 } while (0)
 
 static inline unsigned long __xchg_u32(volatile int * m, unsigned int val)
@@ -102,6 +104,7 @@ static inline unsigned long __xchg_u32(volatile int * m, unsigned int val)
 		unsigned long dummy;
 
 		__asm__ __volatile__(
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	ll	%0, %3			# xchg_u32	\n"
 		"	.set	mips0					\n"
@@ -152,6 +155,7 @@ static inline __u64 __xchg_u64(volatile __u64 * m, __u64 val)
 		unsigned long dummy;
 
 		__asm__ __volatile__(
+		OCTEON_SYNCW_STR
 		"	.set	mips3					\n"
 		"1:	lld	%0, %3			# xchg_u64	\n"
 		"	move	%2, %z4					\n"
diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index 588eef0..f08a886 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -250,6 +250,43 @@ typedef unsigned char *sk_buff_data_t;
  *	@vlan_tci: vlan tag control information
  */
 
+#ifdef CONFIG_CAVIUM_OCTEON_IPFWD_OFFLOAD
+
+/* Mirror the definition in ip.h so we don't have to pull in the entire
+   include file */
+struct __iphdr {
+#if defined(__LITTLE_ENDIAN_BITFIELD)
+	__u8	ihl:4,
+		version:4;
+#elif defined(__BIG_ENDIAN_BITFIELD)
+	__u8	version:4,
+		ihl:4;
+#else
+#error	"Please fix <asm/byteorder.h>"
+#endif
+	__u8	tos;
+	__be16	tot_len;
+	__be16	id;
+	__be16	frag_off;
+	__u8	ttl;
+	__u8	protocol;
+	__sum16	check;
+	__be32	saddr;
+	__be32	daddr;
+	/*The options start here. */
+};
+
+typedef struct {
+	uint64_t	cookie;		/* magic number */
+	void		*bucket;	/* bucket ptr */
+	uint32_t	seq;		/* TCP sequence number (if present) */
+	uint32_t	ack_seq;	/* TCP ack number (if present) */
+	uint32_t	reserved1;
+	struct __iphdr	ip;		/* IP header */
+	uint64_t	reserved2[4];	/* L4 ports and reserved */
+} cvm_packet_info_t;
+#endif
+
 struct sk_buff {
 	/* These two members must be first. */
 	struct sk_buff		*next;
@@ -334,6 +371,10 @@ struct sk_buff {
 
 	__u32			mark;
 
+#ifdef CONFIG_CAVIUM_OCTEON_IPFWD_OFFLOAD
+	cvm_packet_info_t	cvm_info;
+#endif
+
 	__u16			vlan_tci;
 
 	sk_buff_data_t		transport_header;
diff --git a/ipc/msg.c b/ipc/msg.c
index c840080..7cbe8c7 100644
--- a/ipc/msg.c
+++ b/ipc/msg.c
@@ -43,6 +43,11 @@
 
 #include <asm/current.h>
 #include <asm/uaccess.h>
+
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#include <asm/compat.h>
+#endif
+
 #include "util.h"
 
 /*
@@ -740,6 +745,41 @@ SYSCALL_DEFINE4(msgsnd, int, msqid, struct msgbuf __user *, msgp, size_t, msgsz,
 	return do_msgsnd(msqid, mtype, msgp->mtext, msgsz, msgflg);
 }
 
+#if defined(CONFIG_CPU_CAVIUM_OCTEON) && defined(CONFIG_SYSVIPC_COMPAT) && defined(CONFIG_64BIT)
+/**
+ * This function is used for Mips64 N32 ABI when the kernel
+ * is 64bit. This is a hack. I'm not sure where it should be
+ * in the kernel.
+ *
+ * @param msqid
+ * @param msgp
+ * @param msgsz
+ * @param msgflg
+ * @return
+ */
+asmlinkage long sys_msgsnd32(int msqid, void __user *msgp, size_t msgsz, int msgflg)
+{
+	struct msgbuf *copy;
+	int32_t mtype;
+
+	if (msgsz > MSGMAX || (long) msgsz < 0 || msqid < 0)
+               return -EINVAL;
+
+	copy = (struct msgbuf *)compat_alloc_user_space(msgsz+8);
+
+	if (get_user(mtype, ((int*)msgp)) ||
+        put_user(mtype, &copy->mtype))
+		return -EFAULT;
+	if (mtype < 1)
+		return -EINVAL;
+
+	if (copy_in_user(copy->mtext, msgp + 4, msgsz))
+		return -EFAULT;
+
+	return sys_msgsnd(msqid, copy, msgsz, msgflg);
+}
+#endif
+
 static inline int convert_mode(long *msgtyp, int msgflg)
 {
 	/*
@@ -926,6 +966,36 @@ out:
 	return err;
 }
 
+#if defined(CONFIG_CPU_CAVIUM_OCTEON) && defined(CONFIG_SYSVIPC_COMPAT) && defined(CONFIG_64BIT)
+/**
+ * This function is used for Mips64 N32 ABI when the kernel
+ * is 64bit. This is a hack. I'm not sure where it should be
+ * in the kernel.
+ *
+ * @param msqid
+ * @param msgp
+ * @param msgsz
+ * @param msgtyp
+ * @param msgflg
+ * @return
+ */
+asmlinkage long sys_msgrcv32 (int msqid, struct msgbuf __user *msgp, size_t msgsz,
+	                      long msgtyp, int msgflg)
+{
+	long result = sys_msgrcv(msqid, msgp, msgsz, msgtyp, msgflg);
+	if (result > 0)
+	{
+		char *ptr = (char*)msgp;
+		copy_in_user(ptr, ptr+4, result+4);
+		put_user(0, ptr+result+4);
+		put_user(0, ptr+result+5);
+		put_user(0, ptr+result+6);
+		put_user(0, ptr+result+7);
+	}
+	return result;
+}
+#endif
+
 #ifdef CONFIG_PROC_FS
 static int sysvipc_msg_proc_show(struct seq_file *s, void *it)
 {
diff --git a/lib/hweight.c b/lib/hweight.c
index 389424e..088fa5c 100644
--- a/lib/hweight.c
+++ b/lib/hweight.c
@@ -8,7 +8,7 @@
  *
  * The Hamming Weight of a number is the total number of bits set in it.
  */
-
+#ifndef CONFIG_CPU_CAVIUM_OCTEON
 unsigned int hweight32(unsigned int w)
 {
 	unsigned int res = w - ((w >> 1) & 0x55555555);
@@ -57,3 +57,4 @@ unsigned long hweight64(__u64 w)
 #endif
 }
 EXPORT_SYMBOL(hweight64);
+#endif
diff --git a/lib/sort.c b/lib/sort.c
index 6abbaf3..cc184cf 100644
--- a/lib/sort.c
+++ b/lib/sort.c
@@ -18,6 +18,26 @@ static void u32_swap(void *a, void *b, int size)
 
 static void generic_swap(void *a, void *b, int size)
 {
+#if defined(CONFIG_CPU_CAVIUM_OCTEON)
+	/* I'm tired of waiting for a slow copy in simulation. I'll
+	   leave the old slow way for other processors in case they
+	   don't handle possible unaligned loads and stores well */
+	while (size>=8) {
+		u64 t = *(u64 *)a;
+		size-=8;
+		*(u64 *)a = *(u64 *)b;
+		a += sizeof(u64);
+		*(u64 *)b = t;
+		b += sizeof(u64);
+	}
+
+	while (size) {
+		char t = *(char *)a;
+		size--;
+		*(char *)a++ = *(char *)b;
+		*(char *)b++ = t;
+	}
+#else
 	char t;
 
 	do {
@@ -25,6 +45,7 @@ static void generic_swap(void *a, void *b, int size)
 		*(char *)a++ = *(char *)b;
 		*(char *)b++ = t;
 	} while (--size > 0);
+#endif
 }
 
 /**
-- 
1.5.5.1

