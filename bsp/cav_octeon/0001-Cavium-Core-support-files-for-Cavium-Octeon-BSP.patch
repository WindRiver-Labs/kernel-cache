From 3a9306a8905f3e07e29ee84558bd86145d8b92e3 Mon Sep 17 00:00:00 2001
From: Phil Staub <Phil.Staub@windriver.com>
Date: Thu, 24 Sep 2009 14:10:58 -0700
Subject: [PATCH] Cavium: Core support files for Cavium Octeon BSP

This is the core set of files added with Cavium's SDK 1.9 BSP. The
current state of these files reflects an ongoing development process,
and as such implies an extensive modification history that is not
cited in detail here. It is worth noting, however, that this
collection represents the work of the following people who were
involved in that history:

Tomaso Paoletti <tpaoletti@caviumnetworks.com>
David Daney <ddaney@caviumnetworks.com>
Chandrakala Chavva <cchavva@caviumnetworks.com>
Vlad Malov <Vlad.Malov@caviumnetworks.com>
Benjamin Walsh <benjamin.walsh@windriver.com>
Chunbo Luo <chunbo.luo@windriver.com>
Greg Moffatt <greg.moffatt@windriver.com>
Guijin Gao <guijin.gao@windriver.com>
Paul Gortmaker <Paul.Gortmaker@windriver.com>
Phil Staub <Phil.Staub@windriver.com>
Ralf Baechle <ralf.baechle@windriver.com>
Yang Shi <yang.shi@windriver.com>

Signed-off-by: Phil Staub <Phil.Staub@windriver.com>
---
 arch/mips/cavium-octeon/Kconfig                    |  353 +++++
 arch/mips/cavium-octeon/Makefile                   |   45 +
 arch/mips/cavium-octeon/console.c                  |   84 ++
 arch/mips/cavium-octeon/dma-octeon.c               |  496 +++++++
 arch/mips/cavium-octeon/gpl-executive/Makefile     |   81 ++
 .../gpl-executive/config/executive-config.h        |  115 ++
 .../gpl-executive/cvmx-linux-kernel-exports.c      |  142 ++
 arch/mips/cavium-octeon/hal.c                      |  980 ++++++++++++++
 arch/mips/cavium-octeon/hal.h                      |  155 +++
 arch/mips/cavium-octeon/i8259.c                    |  175 +++
 arch/mips/cavium-octeon/irq.c                      |   61 +
 arch/mips/cavium-octeon/octeon-memcpy.S            |  521 ++++++++
 arch/mips/cavium-octeon/octeon-platform.c          |   24 +
 arch/mips/cavium-octeon/octeon-tra.c               |  181 +++
 arch/mips/cavium-octeon/octeon_boot.h              |   69 +
 arch/mips/cavium-octeon/octeon_info.c              |  127 ++
 arch/mips/cavium-octeon/perf_counters.c            |  788 +++++++++++
 arch/mips/cavium-octeon/serial.c                   |  159 +++
 arch/mips/cavium-octeon/setup.c                    |  636 +++++++++
 arch/mips/cavium-octeon/simulator.c                |   30 +
 arch/mips/cavium-octeon/smp.c                      |  464 +++++++
 arch/mips/cavium-octeon/sync-octeon.c              |   38 +
 arch/mips/cavium-octeon/userio.c                   |  252 ++++
 arch/mips/cavium-octeon/watchdog.c                 |  300 +++++
 arch/mips/cavium-octeon/watchdog_nmi.S             |   96 ++
 arch/mips/configs/cavium-octeon_defconfig          | 1370 ++++++++++++++++++++
 arch/mips/kernel/irq-octeon.c                      |  527 ++++++++
 arch/mips/kernel/octeon_switch.S                   |  516 ++++++++
 arch/mips/kernel/watch.c                           |  188 +++
 arch/mips/mm/c-octeon.c                            |  303 +++++
 arch/mips/mm/cex-oct.S                             |   73 +
 arch/mips/mm/pg-octeon.c                           |  120 ++
 arch/mips/oprofile/op_model_cavium_octeon.c        |  143 ++
 .../mach-cavium-octeon/cpu-feature-overrides.h     |   62 +
 include/asm-mips/mach-cavium-octeon/i2c-octeon.h   |   20 +
 include/asm-mips/mach-cavium-octeon/irq.h          |  253 ++++
 .../mach-cavium-octeon/kernel-entry-init.h         |  121 ++
 .../mach-cavium-octeon/octeon-hal-read-write.h     |   38 +
 .../asm-mips/mach-cavium-octeon/perf_counters.h    |   24 +
 include/asm-mips/mach-cavium-octeon/war.h          |   26 +
 include/asm-mips/watch.h                           |   32 +
 41 files changed, 10187 insertions(+), 0 deletions(-)
 create mode 100644 arch/mips/cavium-octeon/Kconfig
 create mode 100644 arch/mips/cavium-octeon/Makefile
 create mode 100644 arch/mips/cavium-octeon/console.c
 create mode 100644 arch/mips/cavium-octeon/dma-octeon.c
 create mode 100644 arch/mips/cavium-octeon/gpl-executive/Makefile
 create mode 100644 arch/mips/cavium-octeon/gpl-executive/config/executive-config.h
 create mode 100644 arch/mips/cavium-octeon/gpl-executive/cvmx-linux-kernel-exports.c
 create mode 100644 arch/mips/cavium-octeon/hal.c
 create mode 100644 arch/mips/cavium-octeon/hal.h
 create mode 100644 arch/mips/cavium-octeon/i8259.c
 create mode 100644 arch/mips/cavium-octeon/irq.c
 create mode 100644 arch/mips/cavium-octeon/octeon-memcpy.S
 create mode 100644 arch/mips/cavium-octeon/octeon-platform.c
 create mode 100644 arch/mips/cavium-octeon/octeon-tra.c
 create mode 100644 arch/mips/cavium-octeon/octeon_boot.h
 create mode 100644 arch/mips/cavium-octeon/octeon_info.c
 create mode 100644 arch/mips/cavium-octeon/perf_counters.c
 create mode 100644 arch/mips/cavium-octeon/serial.c
 create mode 100644 arch/mips/cavium-octeon/setup.c
 create mode 100644 arch/mips/cavium-octeon/simulator.c
 create mode 100644 arch/mips/cavium-octeon/smp.c
 create mode 100644 arch/mips/cavium-octeon/sync-octeon.c
 create mode 100644 arch/mips/cavium-octeon/userio.c
 create mode 100644 arch/mips/cavium-octeon/watchdog.c
 create mode 100644 arch/mips/cavium-octeon/watchdog_nmi.S
 create mode 100644 arch/mips/configs/cavium-octeon_defconfig
 create mode 100644 arch/mips/kernel/irq-octeon.c
 create mode 100644 arch/mips/kernel/octeon_switch.S
 create mode 100644 arch/mips/kernel/watch.c
 create mode 100644 arch/mips/mm/c-octeon.c
 create mode 100644 arch/mips/mm/cex-oct.S
 create mode 100644 arch/mips/mm/pg-octeon.c
 create mode 100644 arch/mips/oprofile/op_model_cavium_octeon.c
 create mode 100644 include/asm-mips/mach-cavium-octeon/cpu-feature-overrides.h
 create mode 100644 include/asm-mips/mach-cavium-octeon/i2c-octeon.h
 create mode 100644 include/asm-mips/mach-cavium-octeon/irq.h
 create mode 100644 include/asm-mips/mach-cavium-octeon/kernel-entry-init.h
 create mode 100644 include/asm-mips/mach-cavium-octeon/octeon-hal-read-write.h
 create mode 100644 include/asm-mips/mach-cavium-octeon/perf_counters.h
 create mode 100644 include/asm-mips/mach-cavium-octeon/war.h
 create mode 100644 include/asm-mips/watch.h

diff --git a/arch/mips/cavium-octeon/Kconfig b/arch/mips/cavium-octeon/Kconfig
new file mode 100644
index 0000000..5a6cdc5
--- /dev/null
+++ b/arch/mips/cavium-octeon/Kconfig
@@ -0,0 +1,353 @@
+config CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	bool "Enable Octeon specific options"
+	depends on CPU_CAVIUM_OCTEON
+	default "y"
+
+config USE_RI_XI_PAGE_BITS
+	bool "Enable RI/XI extended page table bits"
+	depends on CPU_CAVIUM_OCTEON
+	default "n"
+	help
+	  This option enables the use of the Read Inhibit (RI) and Execute
+	  Inhibit (XI) on page table entries. These bits are only effective
+	  on processors that support them. Currently, only the CN5XXX series
+	  of Octeon processors support them.
+
+config CAVIUM_OCTEON_2ND_KERNEL
+	bool "Build the kernel to be used as a 2nd kernel on the same chip"
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	default "n"
+	help
+	  This option configures this kernel to be linked at a different
+	  address and use the 2nd uart for output. This allows a kernel built
+	  with this option to be run at the same time as one built without this
+	  option.
+
+config CAVIUM_OCTEON_BOOTBUS_COMPACT_FLASH
+	bool "Enable support for Compact flash hooked to the Octeon Boot Bus"
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	default "y"
+	help
+	  This option enables a polled compact flash driver for use with
+	  compact flash cards attached to the Octeon boot bus. This interface
+	  is quite slow. It has a maximum rate of about 1.5 MB/s.
+
+config CAVIUM_OCTEON_HW_FIX_UNALIGNED
+	bool "Enable hardware fixups of unaligned loads and stores"
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	default "y"
+	help
+	  Configure the Octeon hardware to automatically fix unaligned loads
+	  and stores. Normally unaligned accesses are fixed using a kernel
+	  exception handler. This option enables the hardware automatic fixups,
+	  which requires only an extra 3 cycles. Disable this option if you
+	  are running code that relies on address exceptions on unaligned
+	  accesses.
+
+config CAVIUM_OCTEON_CVMSEG_SIZE
+	int "Number of L1 cache lines reserved for CVMSEG memory"
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	range 0 54
+	default 1
+	help
+	  CVMSEG LM is a segment that accesses portions of the dcache as a
+	  local memory; the larger CVMSEG is, the smaller the cache is.
+	  This selects the size of CVMSEG LM, which is in cache blocks. The
+	  legally range is from zero to 54 cache blocks (i.e. CVMSEG LM is
+	  between zero and 6192 bytes).
+
+config FAST_ACCESS_TO_THREAD_POINTER
+	bool "Enable fast access to the thread pointer"
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	default "y"
+	help
+	  For Mips, normally the TLS thread pointer is accessed by the
+	  userspace program executing a "rdhwr" from register $29. This
+	  register doesn't exist, so the kernel emulates the instruction
+	  assigning the thread pointer to the value register. This option
+	  supplies an alternate, faster access to the thread pointer. A
+	  side effect of this option is that the highest 8 bytes of CVMSEG
+	  is used by the kernel to save and restore the thread pointer during
+	  the TLB fault handlers. This CVMSEG address isn't available to user
+	  applications.
+	
+config REPLACE_EMULATED_ACCESS_TO_THREAD_POINTER
+	bool "Support dynamically replacing emulated thread pointer accesses"
+	depends on FAST_ACCESS_TO_THREAD_POINTER
+	default "y"
+	help
+	  When this option is set, the kernel can dynamically replace slower
+	  references to the thread pointer with fast accesses. This involves
+	  replacing userspace instructions at runtime, so it may not work with
+	  all programs. It is advised to use a toolchain that creates code for
+	  FAST_ACCESS_TO_THREAD_POINTER instead of this option. If you have
+	  code compiled with a Cavium compiler prior to release 1.5, or are
+	  using a non Cavium compiler, this option may allow you to receive
+	  most of the benefit of direct access to the thread pointer. It may
+	  also cause programs to fail.
+	
+	  Instruction replacement is disabled on boot. It can be controlled by
+	  writing a mode to /sys/module/traps/parameters/thread_pointer_mode.
+	  The supported modes are:
+	
+	  0 - Use the normal kernel emulation without any changes.
+	  1 - Replace emulated instructions with direct accesses to the thread
+		register.
+	  2 - Replace emulated instructions and log the replacement PC.
+	  3 - Replace emulated instructions with break instructions. This will
+		cause programs to fail, but makes it easy to stop gdb on the
+		instruction.
+
+config TEMPORARY_SCRATCHPAD_FOR_KERNEL
+	int "Number of 64-bit words in CVMSEG LM reserved for temporary use by the kernel"
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	range 0 2
+	default 1
+	help
+	  For Mips, performance-critical kernel routines (like the TLB
+	  miss handlers) can normally only use registers K0 and K1 ($26
+	  and $27) from the main register file. This option allocates
+	  space in CVMSEG LM for the same function. This can make the
+	  kernel routines run faster. A side effect of
+	  this is that the kernel will trash the CVMSEG LM locations,
+	  which are placed as high as possible in CVMSEG LM space, but
+	  below the space allocated for the FAST_ACCESS_TO_THREAD_POINTER
+	  option. Like FAST_ACCESS_TO_THREAD_POINTER, these CVMSEG
+          locations are not available to user applications.
+
+config CAVIUM_OCTEON_LOCK_L2
+	bool "Lock often used kernel code in the L2"
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	default "y"
+	help
+	  Enable locking parts of the kernel into the L2 cache.
+
+config CAVIUM_OCTEON_LOCK_L2_TLB
+	bool "Lock the TLB handler in L2"
+	depends on CAVIUM_OCTEON_LOCK_L2
+	default "y"
+	help
+	  Lock the low level TLB fast path into L2.
+
+config CAVIUM_OCTEON_LOCK_L2_EXCEPTION
+	bool "Lock the exception handler in L2"
+	depends on CAVIUM_OCTEON_LOCK_L2
+	default "y"
+	help
+	  Lock the low level exception handler into L2.
+
+config CAVIUM_OCTEON_LOCK_L2_LOW_LEVEL_INTERRUPT
+	bool "Lock the interrupt handler in L2"
+	depends on CAVIUM_OCTEON_LOCK_L2
+	default "y"
+	help
+	  Lock the low level interrupt handler into L2.
+
+config CAVIUM_OCTEON_LOCK_L2_INTERRUPT
+	bool "Lock the 2nd level interrupt handler in L2"
+	depends on CAVIUM_OCTEON_LOCK_L2
+	default "y"
+	help
+	  Lock the 2nd level interrupt handler in L2.
+
+config CAVIUM_OCTEON_LOCK_L2_MEMCPY
+	bool "Lock memcpy() in L2"
+	depends on CAVIUM_OCTEON_LOCK_L2
+	default "y"
+	help
+	  Lock the kernel's implementation of memcpy() into L2.
+
+choice
+	prompt "Allow User space to access hardware IO directly"
+	default CAVIUM_OCTEON_USER_IO
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+
+config CAVIUM_OCTEON_USER_IO
+	bool "Allowed"
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	help
+	  Allows user applications to directly access the Octeon hardware
+	  IO addresses (0x1000000000000 - 0x1ffffffffffff). This allows high
+	  performance networking applications to run in user space with minimal
+	  performance penalties. This also means a user application can bring
+	  down the entire system. Only use this option on embedded devices
+	  where all user applications are strictly controlled.
+
+config CAVIUM_OCTEON_USER_IO_PER_PROCESS
+	bool "Per process"
+	help
+	  Allows user applications to use XKPHYS addresses directly to IO.
+	  This option dynamically enable/disable with sysmips syscall,
+          by a process with root privilege. Without root privilege you can only remove access.
+
+config CAVIUM_OCTEON_USER_IO_DISABLED
+	bool "Disabled"
+
+endchoice
+
+choice
+	prompt "Allow User space to access memory directly"
+	default OCTEON_USER_MEM
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+
+config CAVIUM_OCTEON_USER_MEM
+	bool "Allowed"
+	help
+	  Allows user applications to use XKPHYS addresses directly to memory.
+	  This allows user space direct access to shared memory not in use by
+	  Linux. This memory is suitable for use with the Octeon hardware.
+	  Cavium simple executive applications also share this memory. Since
+	  this bypass all of the Linux memory protection, only use this option
+	  on embedded devices where all user applications are strictly
+	  controlled.
+
+config CAVIUM_OCTEON_USER_MEM_PER_PROCESS
+	bool "Per process"
+	help
+	  Allows user applications to use XKPHYS addresses directly to memory.
+	  This option dynamically enable/disable with sysmips syscall,
+          by a process with root privilege. Without root privilege you can only remove access.
+
+config CAVIUM_OCTEON_USER_MEM_DISABLED
+	bool "Disabled"
+
+endchoice
+
+config CAVIUM_RESERVE32
+	int "Memory to reserve for user processes shared region (MB)"
+	range 0 1536
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	default "0"
+	help
+	  Reserve a shared memory region for user processes to use for hardware
+	  memory buffers. This is required for 32bit applications to be able to
+	  send and receive packets directly. Applications access this memory by
+	  memory mapping /dev/mem for the addresses in /proc/octeon_info. For
+	  optimal performance with HugeTLBs, keep this size an even number of
+	  megabytes.
+
+config CAVIUM_RESERVE32_USE_WIRED_TLB
+	bool "Use wired TLB entries to access the reserved memory region"
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	default "n"
+	help
+	  When this option is set, the memory reserved for the user process
+	  shared region (CONFIG_CAVIUM_RESERVE32) is globally mapped to all
+	  userspace programs using wired TLB entries. The userspace addresses
+	  beginning at 2GB-CONFIG_CAVIUM_RESERVE32 and ending at 2GB are hard
+	  wired to always map to the reserved memory region. This has the
+	  benefit of completely eliminating TLB overhead to the region, but may
+	  cause unwanted side affect. Since all memory in this region is shared
+	  across all userspace applications, any application attempting to
+	  mmap() these virtual address will fail in strange ways. In
+	  particular, be careful of shared libraries being mapped into this
+	  region. If this happens, the entire system may become unstable.
+
+	  Note: When this option is selected, CONFIG_CAVIUM_RESERVE32 must be
+	  512MB, 1024MB, or 1536MB. Any other valid will fail on boot.
+
+config CAVIUM_OCTEON_NUM_PACKET_BUFFERS
+	int "Number of packet buffers (and work queue entries) for the Ethernet driver"
+	range 0 8192
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	default "1024"
+	help
+	  Number of packet buffers (and work queue entries) to allocate for
+	  the ethernet driver. Zero is treated as 1024.
+
+config ARCH_SPARSEMEM_ENABLE
+	def_bool y
+	select SPARSEMEM_STATIC
+	depends on CPU_CAVIUM_OCTEON
+
+config CAVIUM_OCTEON_POW_ONLY_ETHERNET
+	tristate "POW based internal only ethernet driver"
+	default m
+	help
+	  This option enables a very simple ethernet driver for internal core
+	  to core traffic. It relies on another driver, cavium-ethernet,
+	  to perform all hardware setup. This driver's purpose is to supply
+	  basic networking between different Linux images running on the same
+	  chip. A single core loads the cavium-ethernet module, all other cores
+	  load this driver. On load, the driver waits for some other core to
+	  perform hardware setup.
+
+config CAVIUM_OCTEON_MGMT_PORT_ETHERNET
+	tristate "Management port ethernet driver (CN5XXX)"
+	default y
+	help
+	  This option enables the ethernet driver for the management port on
+	  CN57XX, CN56XX, CN55XX, and CN54XX chips.
+
+config CAVIUM_OCTEON_WATCHDOG
+	bool "Octeon watchdog driver"
+	default n
+	help
+	  This option enables a watchdog driver for all cores running Linux. It
+	  installs a NMI handler and pokes the watchdog based on an interrupt.
+	  On first expiration of the watchdog, the interrupt handler pokes it.
+	  The second expiration causes an NMI that prints a message and resets
+	  the chip. The third expiration causes a global soft reset.
+
+config CAVIUM_OCTEON_TRA
+	tristate "Octeon trace buffer (TRA) driver"
+	default n
+	help
+	  This option enables a driver for the Octeon trace buffer. By default
+	  it enables interrupts on some illegal memory accesses. See
+	  octeon-tra.c for information on customizing this driver to find
+	  specific problems.
+
+config CAVIUM_OCTEON_NAND
+	tristate "Octeon NAND driver"
+	depends on MTD_NAND && CPU_CAVIUM_OCTEON
+	default m
+	help
+	  This option enables a MTD driver for the NAND controller introduced
+	  in the Octeon CN52XX pass 2 processor. It supports up to 8 NAND
+	  devices connected directly to Octeon's boot bus.
+
+config CAVIUM_OCTEON_USB
+	tristate "Octeon usb host driver"
+	depends on USB
+	default n
+	help
+	  This option enables an alternative driver for the Octeon USB as a
+	  host controller. This driver is a replacement for the DWC_OTG driver
+	  using the cvmx-usb interface. It currently does not support the
+	  CN31XX and CN3020 chips. All other Octeon based chips with USB are
+	  supported.
+
+config CAVIUM_OCTEON_IPSEC
+   bool "Enable enhancements to the IPSec stack to allow procotol offload."
+   depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+   default "n"
+   help
+     This enables enhancements to the IPSec stack to allow some of the
+     processing required for IPSec to be performed on another processor
+     which must be running the ipsec-filter application.
+
+config FORCE_MAX_ZONEORDER
+	int
+	depends on HUGETLB_PAGE && (PAGE_SIZE_16KB || PAGE_SIZE_32KB || PAGE_SIZE_64KB)
+	default 12 if PAGE_SIZE_16KB
+	default 13 if PAGE_SIZE_32KB
+	default 14 if PAGE_SIZE_64KB
+
+config CAVIUM_OCTEON_IPFWD_OFFLOAD
+	bool "Enable Cavium Octeon ip-offload module"
+	default "n"
+	help
+	  This enables Cavium Octeon ip-offload module.
+
+config BUILD_ID_DISABLE
+	bool "Disable the build-id feature of the linker"
+	default "y"
+	help
+	   Currently, the u-boot bootloader does not know how to
+	   handle the presence of a non-empty NOTES program header
+	   in the kernel load file. This occurs when the linker 
+	   option '--build-id' is specified. Setting this option
+	   to 'y' prevents use of the build-id feature and allows
+	   u-boot to load the kernel.
+
diff --git a/arch/mips/cavium-octeon/Makefile b/arch/mips/cavium-octeon/Makefile
new file mode 100644
index 0000000..54c1651
--- /dev/null
+++ b/arch/mips/cavium-octeon/Makefile
@@ -0,0 +1,45 @@
+#
+# Makefile for the Cavium Octeon specific kernel interface routines
+# under Linux.
+#
+# This file is subject to the terms and conditions of the GNU General Public
+# License.  See the file "COPYING" in the main directory of this archive
+# for more details.
+#
+# Copyright (C) 2005-2007 Cavium Networks
+#
+
+OCTEON_ROOT_IN_KERNEL = $(srctree)/arch/mips/cavium-octeon
+OCTEON_ROOT = $(srctree)/../../host-cross/mips-wrs-linux-gnu/sysroot/usr/include/simple_exec_open
+
+CAVIUM_INCLUDES := -I$(OCTEON_ROOT)/target/include \
+		   -I$(OCTEON_ROOT_IN_KERNEL)/executive
+
+# Common flags
+EXTRA_CFLAGS += ${CAVIUM_INCLUDES}
+
+
+obj-y := setup.o serial.o irq.o hal.o perf_counters.o octeon_info.o
+obj-y += dma-octeon.o userio.o sync-octeon.o
+obj-y += octeon-memcpy.o
+obj-y += console.o
+obj-y += octeon-platform.o
+
+obj-$(CONFIG_SMP)                     += smp.o
+obj-$(CONFIG_CAVIUM_OCTEON_BOOTBUS_COMPACT_FLASH) += ebt3000_cf.o
+obj-$(CONFIG_PCI)                     += pci-common.o pci_console.o
+obj-$(CONFIG_PCI)                     += pci.o pci_chips.o i8259.o
+obj-$(CONFIG_PCI_MSI)                 += msi.o
+ifndef CONFIG_CAVIUM_OCTEON_2ND_KERNEL
+obj-$(CONFIG_PCI)                     += pcie.o
+endif
+obj-$(CONFIG_CAVIUM_OCTEON_WATCHDOG)  += watchdog.o watchdog_nmi.o
+obj-$(CONFIG_CAVIUM_OCTEON_TRA)       += octeon-tra.o
+obj-$(CONFIG_CAVIUM_OCTEON_USB)       += octeon-usb-host.o
+obj-$(CONFIG_CAVIUM_OCTEON_MGMT_PORT_ETHERNET) += ethernet-mgmt-port.o
+obj-$(CONFIG_CAVIUM_OCTEON_POW_ONLY_ETHERNET) += ethernet-pow.o
+obj-$(CONFIG_CAVIUM_OCTEON_NAND)      += octeon-nand.o
+
+clean:
+	rm -f *.o
+
diff --git a/arch/mips/cavium-octeon/console.c b/arch/mips/cavium-octeon/console.c
new file mode 100644
index 0000000..8af1cfa
--- /dev/null
+++ b/arch/mips/cavium-octeon/console.c
@@ -0,0 +1,84 @@
+/*
+ * Carsten Langgaard, carstenl@mips.com
+ * Copyright (C) 1999,2000 MIPS Technologies, Inc.  All rights reserved.
+ *
+ *  This program is free software; you can distribute it and/or modify it
+ *  under the terms of the GNU General Public License (Version 2) as
+ *  published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ *  for more details.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
+ *
+ * Putting things on the screen/serial line using YAMONs facilities.
+ */
+#include <linux/console.h>
+#include <linux/init.h>
+#include <linux/serial_reg.h>
+#include <asm/io.h>
+#include "hal.h"
+
+#if 0
+#ifdef CONFIG_MIPS_ATLAS
+#include <asm/mips-boards/atlas.h>
+
+#ifdef CONFIG_CPU_LITTLE_ENDIAN
+#define PORT(offset) (ATLAS_UART_REGS_BASE     + ((offset)<<3))
+#else
+#define PORT(offset) (ATLAS_UART_REGS_BASE + 3 + ((offset)<<3))
+#endif
+
+#elif defined(CONFIG_MIPS_SEAD)
+
+#include <asm/mips-boards/sead.h>
+
+#ifdef CONFIG_CPU_LITTLE_ENDIAN
+#define PORT(offset) (SEAD_UART0_REGS_BASE     + ((offset)<<3))
+#else
+#define PORT(offset) (SEAD_UART0_REGS_BASE + 3 + ((offset)<<3))
+#endif
+
+#else
+
+#define PORT(offset) (0x3f8 + (offset))
+
+#endif
+
+static inline unsigned int serial_in(int offset)
+{
+	return inb(PORT(offset));
+}
+
+static inline void serial_out(int offset, int value)
+{
+	outb(value, PORT(offset));
+}
+#endif
+
+int prom_putchar(char c)
+{
+#if 0
+	while ((serial_in(UART_LSR) & UART_LSR_THRE) == 0)
+		;
+
+	serial_out(UART_TX, c);
+#endif
+
+	uint64_t lsrval;
+
+	/* Spin until there is room */
+	do
+	{
+		lsrval = cvmx_read_csr(CVMX_MIO_UARTX_LSR(0));
+	}
+	while ((lsrval & 0x20) == 0);
+
+	/* Write the byte */
+	cvmx_write_csr(CVMX_MIO_UARTX_THR(0), c);
+	return 1;
+}
diff --git a/arch/mips/cavium-octeon/dma-octeon.c b/arch/mips/cavium-octeon/dma-octeon.c
new file mode 100644
index 0000000..187a016
--- /dev/null
+++ b/arch/mips/cavium-octeon/dma-octeon.c
@@ -0,0 +1,496 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2000  Ani Joshi <ajoshi@unixbox.com>
+ * Copyright (C) 2000, 2001  Ralf Baechle <ralf@gnu.org>
+ * Copyright (C) 2005 Ilya A. Volynets-Evenbakh <ilya@total-knowledge.com>
+ * swiped from i386, and cloned for MIPS by Geert, polished by Ralf.
+ * IP32 changes by Ilya.
+ * Cavium Networks: Create new dma setup for Cavium Networks Octeon based on
+ * the kernels original.
+ */
+#include <linux/types.h>
+#include <linux/mm.h>
+#include <linux/module.h>
+#include <linux/string.h>
+#include <linux/dma-mapping.h>
+#include <linux/platform_device.h>
+#include <linux/scatterlist.h>
+
+#include <linux/cache.h>
+#include <linux/io.h>
+
+#include "hal.h"
+#ifdef CONFIG_PCI
+#include "pci-common.h"
+#endif
+
+#define BAR2_PCI_ADDRESS 0x8000000000ul
+
+struct bar1_index_state {
+	int16_t ref_count;	/* Number of PCI mappings using this index */
+	int16_t address_bits;	/* Upper bits of physical address. This is
+				   shifted 22 bits */
+};
+
+#ifdef CONFIG_PCI
+static DEFINE_SPINLOCK(bar1_lock);
+static struct bar1_index_state bar1_state[32] = { {0, 0}, };
+#endif
+
+void *dma_alloc_noncoherent(struct device *dev, size_t size,
+			    dma_addr_t *dma_handle, unsigned int __nocast gfp)
+	__attribute__ ((alias("dma_alloc_coherent")));
+
+EXPORT_SYMBOL(dma_alloc_noncoherent);
+
+
+void *dma_alloc_coherent(struct device *dev, size_t size,
+			 dma_addr_t *dma_handle, unsigned int __nocast gfp)
+{
+	void *ret;
+	/* Ignore region specifiers. The Octeon Bar1 register can be used to
+	   map any memory on the system. As long as we don't fill up the 32
+	   entry table, memory can be anywhere */
+	gfp &= ~(__GFP_DMA | __GFP_HIGHMEM);
+
+	ret = (void *) __get_free_pages(gfp, get_order(size));
+	if (likely(ret != NULL)) {
+		memset(ret, 0, size);
+		/* By default, PCI devices can't get to memory. dma_map_single
+		   changes the Bar mapping to allow access to this region */
+		*dma_handle = dma_map_single(dev, ret, size, DMA_BIDIRECTIONAL);
+	}
+
+	return ret;
+}
+
+EXPORT_SYMBOL(dma_alloc_coherent);
+
+
+void dma_free_noncoherent(struct device *dev, size_t size, void *vaddr,
+			  dma_addr_t dma_handle)
+	__attribute__ ((alias("dma_free_coherent")));
+
+EXPORT_SYMBOL(dma_free_noncoherent);
+
+
+void dma_free_coherent(struct device *dev, size_t size, void *vaddr,
+		       dma_addr_t dma_handle)
+{
+	/* Free the Bar mappings */
+	dma_unmap_single(dev, dma_handle, size, DMA_BIDIRECTIONAL);
+	free_pages((unsigned long) vaddr, get_order(size));
+}
+
+EXPORT_SYMBOL(dma_free_coherent);
+
+
+dma_addr_t dma_map_single(struct device *dev, void *ptr, size_t size,
+			  enum dma_data_direction direction)
+{
+#ifndef CONFIG_PCI
+	/* Without PCI/PCIe this function can be called for Octeon internal
+	   devices such as USB. These devices all support 64bit addressing */
+	return virt_to_phys(ptr);
+#else
+	unsigned long flags;
+	uint64_t dma_mask;
+	int64_t start_index;
+	dma_addr_t result = -1;
+	uint64_t physical = virt_to_phys(ptr);
+	int64_t index;
+
+	BUG_ON(direction == DMA_NONE);
+
+	/* Use the DMA masks to determine the allowed memory region. For us it
+	   doesn't limit the actual memory, just the address visible over PCI.
+	   Devices with limits need to use lower indexed Bar1 entries. */
+	if (dev) {
+		dma_mask = dev->coherent_dma_mask;
+		if (dev->dma_mask)
+			dma_mask = *dev->dma_mask;
+	} else
+		dma_mask = 0xfffffffful;
+
+	/* Platform devices, such as the internal USB, skip all translation and
+	   use Octeon physical addresses directly */
+	if (dev->bus == &platform_bus_type)
+		return physical;
+
+	switch (octeon_dma_bar_type) {
+	case OCTEON_DMA_BAR_TYPE_PCIE:
+		if (unlikely(physical < (16ul << 10)))
+			panic("dma_map_single: Not allowed to map first 16KB. It interferes with BAR0 special area\n");
+		else if ((physical + size >= (256ul << 20)) &&
+			 (physical < (512ul << 20)))
+			panic("dma_map_single: Not allowed to map bootbus\n");
+		else if ((physical + size >= 0x400000000ull) &&
+			 physical < 0x410000000ull)
+			panic("dma_map_single: Attempt to map illegal memory address 0x%lx\n", physical);
+		else if (physical >= 0x420000000ull)
+			panic("dma_map_single: Attempt to map illegal memory address 0x%lx\n", physical);
+		else if ((physical + size >= (4ull<<30) - (OCTEON_PCI_BAR1_HOLE_SIZE<<20)) &&
+			 physical < (4ull<<30))
+			pr_warning("dma_map_single: Warning: Mapping memory address that might conflict with devices 0x%lx-0x%lx\n", physical, physical+size-1);
+		/* The 2nd 256MB is mapped at 256<<20 instead of 0x410000000 */
+		if ((physical >= 0x410000000ull) && physical < 0x420000000ull)
+			result = physical - 0x400000000ull;
+		else
+			result = physical;
+		if (((result+size-1) & dma_mask) != result+size-1)
+			panic("dma_map_single: Attempt to map address 0x%lx-0x%lx, which can't be accessed according to the dma mask 0x%lx\n", physical, physical+size-1, dma_mask);
+		goto done;
+
+	case OCTEON_DMA_BAR_TYPE_BIG:
+#ifdef CONFIG_64BIT
+		/* If the device supports 64bit addressing, then use BAR2 */
+		if (dma_mask > BAR2_PCI_ADDRESS) {
+			result = physical + BAR2_PCI_ADDRESS;
+			goto done;
+		}
+#endif
+		if (unlikely(physical < (4ul << 10))) {
+			panic("dma_map_single: Not allowed to map first 4KB. It interferes with BAR0 special area\n");
+		} else if (physical < (256ul << 20)) {
+			if (unlikely(physical + size > (256ul << 20)))
+				panic("dma_map_single: Requested memory spans Bar0 0:256MB and bootbus\n");
+			result = physical;
+			goto done;
+		} else if (unlikely(physical < (512ul << 20))) {
+			panic("dma_map_single: Not allowed to map bootbus\n");
+		} else if (physical < (2ul << 30)) {
+			if (unlikely(physical + size > (2ul << 30)))
+				panic("dma_map_single: Requested memory spans Bar0 512MB:2GB and BAR1\n");
+			result = physical;
+			goto done;
+		} else if (physical < (2ul << 30) + (128 << 20)) {
+			/* Fall through */
+		} else if (physical <
+			   (4ul << 30) - (OCTEON_PCI_BAR1_HOLE_SIZE << 20)) {
+			if (unlikely
+			    (physical + size >
+			     (4ul << 30) - (OCTEON_PCI_BAR1_HOLE_SIZE << 20)))
+				panic("dma_map_single: Requested memory extends past Bar1 (4GB-%luMB)\n", OCTEON_PCI_BAR1_HOLE_SIZE);
+			result = physical;
+			goto done;
+		} else if ((physical >= 0x410000000ull) &&
+			   (physical < 0x420000000ull)) {
+			if (unlikely(physical + size > 0x420000000ull))
+				panic("dma_map_single: Requested memory spans non existant memory\n");
+			result = physical - 0x400000000ull;	/* BAR0 fixed
+								   mapping
+								   256MB:512MB
+								   ->
+								   16GB+256MB:16GB+512MB
+								 */
+			goto done;
+		} else {
+			/* Continued below switch statement */
+		}
+		break;
+
+	case OCTEON_DMA_BAR_TYPE_SMALL:
+#ifdef CONFIG_64BIT
+		/* If the device supports 64bit addressing, then use BAR2 */
+		if (dma_mask > BAR2_PCI_ADDRESS) {
+			result = physical + BAR2_PCI_ADDRESS;
+			goto done;
+		}
+#endif
+		/* Continued below switch statement */
+		break;
+
+	default:
+		panic("dma_map_single: Invalid octeon_dma_bar_type\n");
+	}
+
+	/* Don't allow mapping to span multiple Bar entries. The hardware guys
+	   won't guarantee that DMA across boards work */
+	if (unlikely((physical >> 22) != ((physical + size - 1) >> 22)))
+		panic("dma_map_single: Requested memory spans more than one Bar1 entry\n");
+
+	if (octeon_dma_bar_type == OCTEON_DMA_BAR_TYPE_BIG)
+		start_index = 31;
+	else if (unlikely(dma_mask < (1ul << 27)))
+		start_index = (dma_mask >> 22);
+	else
+		start_index = 31;
+
+	/* Only one processor can access the Bar register at once */
+	spin_lock_irqsave(&bar1_lock, flags);
+
+	/* Look through Bar1 for existing mapping that will work */
+	for (index = start_index; index >= 0; index--) {
+		if ((bar1_state[index].address_bits == physical >> 22) &&
+		    (bar1_state[index].ref_count)) {
+			/* An existing mapping will work, use it */
+			bar1_state[index].ref_count++;
+			if (unlikely(bar1_state[index].ref_count < 0))
+				panic("dma_map_single: Bar1[%d] reference count overflowed\n", (int) index);
+			result = (index << 22) | (physical & ((1 << 22) - 1));
+			/* Large BAR1 is offset at 2GB */
+			if (octeon_dma_bar_type == OCTEON_DMA_BAR_TYPE_BIG)
+				result += 2ul << 30;
+			goto done_unlock;
+		}
+	}
+
+	/* No existing mappings, look for a free entry */
+	for (index = start_index; index >= 0; index--) {
+		if (unlikely(bar1_state[index].ref_count == 0)) {
+			cvmx_pci_bar1_indexx_t bar1_index;
+			/* We have a free entry, use it */
+			bar1_state[index].ref_count = 1;
+			bar1_state[index].address_bits = physical >> 22;
+			bar1_index.u32 = 0;
+			bar1_index.s.addr_idx = physical >> 22;	/* Address bits
+								   [35:22] sent
+								   to L2C */
+			bar1_index.s.ca = 1;	/* Don't put PCI accesses in
+						   L2. */
+			bar1_index.s.end_swp = 1;	/* Endian Swap Mode */
+			bar1_index.s.addr_v = 1;	/* Set '1' when the
+							   selected address
+							   range is valid. */
+			octeon_npi_write32(CVMX_NPI_PCI_BAR1_INDEXX(index),
+					   bar1_index.u32);
+			/* An existing mapping will work, use it */
+			result = (index << 22) | (physical & ((1 << 22) - 1));
+			/* Large BAR1 is offset at 2GB */
+			if (octeon_dma_bar_type == OCTEON_DMA_BAR_TYPE_BIG)
+				result += 2ul << 30;
+			goto done_unlock;
+		}
+	}
+
+	pr_err("dma_map_single: Can't find empty BAR1 index for physical mapping 0x%llx\n", (unsigned long long) physical);
+
+      done_unlock:
+	spin_unlock_irqrestore(&bar1_lock, flags);
+      done:
+	/* pr_debug("dma_map_single 0x%lx->0x%lx\n", physical, result); */
+	return result;
+#endif
+}
+
+EXPORT_SYMBOL(dma_map_single);
+
+
+void dma_unmap_single(struct device *dev, dma_addr_t dma_addr, size_t size,
+		      enum dma_data_direction direction)
+{
+#ifndef CONFIG_PCI
+	/* Without PCI/PCIe this function can be called for Octeon internal
+	   devices such as USB. These devices all support 64bit addressing */
+	return;
+#else
+	unsigned long flags;
+	uint64_t index;
+
+	BUG_ON(direction == DMA_NONE);
+
+	/* Platform devices, such as the internal USB, skip all translation and
+	   use Octeon physical addresses directly */
+	if (!dev || dev->bus == &platform_bus_type)
+		return;
+
+	switch (octeon_dma_bar_type) {
+	case OCTEON_DMA_BAR_TYPE_PCIE:
+		/* Nothing to do, all mappings are static */
+		goto done;
+
+	case OCTEON_DMA_BAR_TYPE_BIG:
+#ifdef CONFIG_64BIT
+		/* Nothing to do for addresses using BAR2 */
+		if (dma_addr >= BAR2_PCI_ADDRESS)
+			goto done;
+#endif
+		if (unlikely(dma_addr < (4ul << 10)))
+			panic("dma_unmap_single: Unexpect DMA address 0x%lx\n",
+			      dma_addr);
+		else if (dma_addr < (2ul << 30))
+			goto done;	/* Nothing to do for addresses using
+					   BAR0 */
+		else if (dma_addr < (2ul << 30) + (128ul << 20))
+			index = (dma_addr - (2ul << 30)) >> 22;	/* Need to
+								   unmap, fall
+								   through */
+		else if (dma_addr <
+			 (4ul << 30) - (OCTEON_PCI_BAR1_HOLE_SIZE << 20))
+			goto done;	/* Nothing to do for the rest of BAR1 */
+		else
+			panic("dma_unmap_single: Unexpect DMA address 0x%lx\n",
+			      dma_addr);
+		/* Continued below switch statement */
+		break;
+
+	case OCTEON_DMA_BAR_TYPE_SMALL:
+#ifdef CONFIG_64BIT
+		/* Nothing to do for addresses using BAR2 */
+		if (dma_addr >= BAR2_PCI_ADDRESS)
+			goto done;
+#endif
+		index = dma_addr >> 22;
+		/* Continued below switch statement */
+		break;
+
+	default:
+		panic("dma_unmap_single: Invalid octeon_dma_bar_type\n");
+	}
+
+	if (unlikely(index > 31))
+		panic("dma_unmap_single: Attempt to unmap an invalid address (0x%llx)\n", (unsigned long long) dma_addr);
+
+	spin_lock_irqsave(&bar1_lock, flags);
+	bar1_state[index].ref_count--;
+	if (bar1_state[index].ref_count == 0)
+		octeon_npi_write32(CVMX_NPI_PCI_BAR1_INDEXX(index), 0);
+	else if (unlikely(bar1_state[index].ref_count < 0))
+		panic("dma_unmap_single: Bar1[%u] reference count < 0\n",
+		      (int) index);
+	spin_unlock_irqrestore(&bar1_lock, flags);
+      done:
+	/* pr_debug("dma_unmap_single 0x%lx\n", dma_addr); */
+	return;
+#endif
+}
+
+EXPORT_SYMBOL(dma_unmap_single);
+
+
+int dma_map_sg(struct device *dev, struct scatterlist *sg, int nents,
+	       enum dma_data_direction direction)
+{
+	int i;
+	for (i = 0; i < nents; i++, sg++)
+		sg->dma_address =
+			dma_map_page(dev, sg_page(sg), sg->offset, sg->length,
+				     direction);
+
+	return nents;
+}
+
+EXPORT_SYMBOL(dma_map_sg);
+
+
+dma_addr_t dma_map_page(struct device *dev, struct page *page,
+			unsigned long offset, size_t size,
+			enum dma_data_direction direction)
+{
+	return dma_map_single(dev, page_address(page) + offset, size,
+			      direction);
+}
+
+EXPORT_SYMBOL(dma_map_page);
+
+
+void dma_unmap_page(struct device *dev, dma_addr_t dma_address, size_t size,
+		    enum dma_data_direction direction)
+{
+	dma_unmap_single(dev, dma_address, size, direction);
+}
+
+EXPORT_SYMBOL(dma_unmap_page);
+
+
+void dma_unmap_sg(struct device *dev, struct scatterlist *sg, int nhwentries,
+		  enum dma_data_direction direction)
+{
+	int i;
+	for (i = 0; i < nhwentries; i++, sg++)
+		dma_unmap_page(dev, sg->dma_address, sg->length, direction);
+}
+
+EXPORT_SYMBOL(dma_unmap_sg);
+
+
+void dma_sync_single_for_cpu(struct device *dev, dma_addr_t dma_handle,
+			     size_t size, enum dma_data_direction direction)
+{
+	mb();
+}
+
+EXPORT_SYMBOL(dma_sync_single_for_cpu);
+
+
+void dma_sync_single_for_device(struct device *dev, dma_addr_t dma_handle,
+				size_t size, enum dma_data_direction direction)
+{
+	mb();
+}
+
+EXPORT_SYMBOL(dma_sync_single_for_device);
+
+
+void dma_sync_single_range_for_cpu(struct device *dev, dma_addr_t dma_handle,
+				   unsigned long offset, size_t size,
+				   enum dma_data_direction direction)
+{
+	mb();
+}
+
+EXPORT_SYMBOL(dma_sync_single_range_for_cpu);
+
+
+void dma_sync_single_range_for_device(struct device *dev, dma_addr_t dma_handle,
+				      unsigned long offset, size_t size,
+				      enum dma_data_direction direction)
+{
+	mb();
+}
+
+EXPORT_SYMBOL(dma_sync_single_range_for_device);
+
+
+void dma_sync_sg_for_cpu(struct device *dev, struct scatterlist *sg, int nelems,
+			 enum dma_data_direction direction)
+{
+	mb();
+}
+
+EXPORT_SYMBOL(dma_sync_sg_for_cpu);
+
+
+void dma_sync_sg_for_device(struct device *dev, struct scatterlist *sg,
+			    int nelems, enum dma_data_direction direction)
+{
+	mb();
+}
+
+EXPORT_SYMBOL(dma_sync_sg_for_device);
+
+
+int dma_mapping_error(struct device *dev, dma_addr_t dma_addr)
+{
+	return dma_addr == -1;
+}
+
+EXPORT_SYMBOL(dma_mapping_error);
+
+
+int dma_supported(struct device *dev, u64 mask)
+{
+	return 1;
+}
+
+EXPORT_SYMBOL(dma_supported);
+
+
+int dma_is_consistent(struct device *dev, dma_addr_t dma_addr)
+{
+	return 1;
+}
+
+EXPORT_SYMBOL(dma_is_consistent);
+
+
+void dma_cache_sync(struct device *dev, void *vaddr, size_t size,
+		    enum dma_data_direction direction)
+{
+	mb();
+}
+
+EXPORT_SYMBOL(dma_cache_sync);
diff --git a/arch/mips/cavium-octeon/gpl-executive/Makefile b/arch/mips/cavium-octeon/gpl-executive/Makefile
new file mode 100644
index 0000000..e2fc0b6
--- /dev/null
+++ b/arch/mips/cavium-octeon/gpl-executive/Makefile
@@ -0,0 +1,81 @@
+#
+# Makefile for the Cavium Octeon specific kernel interface routines
+# under Linux.
+#
+# This file is subject to the terms and conditions of the GNU General Public
+# License.  See the file "COPYING" in the main directory of this archive
+# for more details.
+#
+# Copyright (C) 2005-2007 Cavium Networks
+#
+
+OCTEON_ROOT_IN_KERNEL = $(srctree)/arch/mips/cavium-octeon
+
+# make this visible to the cvmx-config script
+export OCTEON_ROOT = $(srctree)/../../host-cross/mips-wrs-linux-gnu/sysroot/usr/include/simple_exec_open
+
+CAVIUM_INCLUDES := -I$(OCTEON_ROOT)/target/include \
+		   -I$(OCTEON_ROOT_IN_KERNEL)/executive
+
+# Common flags
+EXTRA_CFLAGS += ${CAVIUM_INCLUDES}
+
+source:=$(srctree)/$(src)
+
+EXTRA_CFLAGS += -I $(obj)/config -I $(source)/config
+
+executive-files := cvmx-bootmem.o
+executive-files += cvmx-cmd-queue.o
+executive-files += cvmx-dma-engine.o
+executive-files += cvmx-fpa.o
+executive-files += cvmx-helper.o
+executive-files += cvmx-helper-board.o
+executive-files += cvmx-helper-errata.o
+executive-files += cvmx-helper-fpa.o
+executive-files += cvmx-helper-loop.o
+executive-files += cvmx-helper-npi.o
+executive-files += cvmx-helper-rgmii.o
+executive-files += cvmx-helper-sgmii.o
+executive-files += cvmx-helper-spi.o
+executive-files += cvmx-helper-util.o
+executive-files += cvmx-helper-xaui.o
+executive-files += cvmx-interrupt-decodes.o
+executive-files += cvmx-interrupt-rsl.o
+executive-files += cvmx-l2c.o
+executive-files += cvmx-mgmt-port.o
+executive-files += cvmx-nand.o
+executive-files += cvmx-pcie.o
+executive-files += cvmx-pko.o
+executive-files += cvmx-raid.o
+executive-files += cvmx-spi4000.o
+executive-files += cvmx-spi.o
+executive-files += cvmx-sysinfo.o
+executive-files += cvmx-tra.o
+executive-files += cvmx-twsi.o
+executive-files += cvmx-warn.o
+executive-files += cvmx-compactflash.o
+executive-files += octeon-model.o
+executive-files += octeon-pci-console.o
+executive-files += cvmx-usb.o
+
+obj-y := $(executive-files) cvmx-linux-kernel-exports.o 
+
+executive-obj-files := $(executive-files:%=$(obj)/%)
+executive-src-files := $(executive-obj-files:%.o=%.c)
+cvmx-linux-kernel-exports.o $(executive-src-files): $(obj)/config/cvmx-config.h
+
+$(executive-src-files):
+	$(Q)if [ -d ${OCTEON_ROOT} ] ; then \
+		ln -fs $(@:$(obj)/%.c=${OCTEON_ROOT}/executive/%.c) $@ ; \
+	else \
+		ln -fs $(@:$(obj)/%.c=${OCTEON_ROOT_IN_KERNEL}/executive/%.c) $@ ; \
+	fi;
+
+$(obj)/config/cvmx-config.h: $(source)/config/executive-config.h
+	if [ -d ${OCTEON_ROOT} ] ; then \
+		cd $(obj) && ${OCTEON_ROOT}/host/bin/cvmx-config $< ; \
+	fi;
+
+clean:
+	rm -f *.o $(executive-src-files)
+
diff --git a/arch/mips/cavium-octeon/gpl-executive/config/executive-config.h b/arch/mips/cavium-octeon/gpl-executive/config/executive-config.h
new file mode 100644
index 0000000..2fe77fd
--- /dev/null
+++ b/arch/mips/cavium-octeon/gpl-executive/config/executive-config.h
@@ -0,0 +1,115 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2005-2007 Cavium Networks
+ */
+/*
+ * File version info: $Id: executive-config.h 25756 2007-07-02 23:25:50Z kreese $
+ */
+#ifndef __EXECUTIVE_CONFIG_H__
+#define __EXECUTIVE_CONFIG_H__
+
+/* Define to enable the use of simple executive DFA functions */
+//#define CVMX_ENABLE_DFA_FUNCTIONS
+
+/* Define to enable the use of simple executive packet output functions.
+** For packet I/O setup enable the helper functions below.
+*/
+#define CVMX_ENABLE_PKO_FUNCTIONS
+
+/* Define to enable the use of simple executive timer bucket functions.
+** Refer to cvmx-tim.[ch] for more information
+*/
+//#define CVMX_ENABLE_TIMER_FUNCTIONS
+
+/* Define to enable the use of simple executive helper functions. These
+** include many harware setup functions.  See cvmx-helper.[ch] for
+** details.
+*/
+#define CVMX_ENABLE_HELPER_FUNCTIONS
+
+/* CVMX_HELPER_FIRST_MBUFF_SKIP is the number of bytes to reserve before
+** the beginning of the packet. If necessary, override the default
+** here.  See the IPD section of the hardware manual for MBUFF SKIP
+** details.*/
+#define CVMX_HELPER_FIRST_MBUFF_SKIP 184
+
+/* CVMX_HELPER_NOT_FIRST_MBUFF_SKIP is the number of bytes to reserve in each
+** chained packet element. If necessary, override the default here */
+#define CVMX_HELPER_NOT_FIRST_MBUFF_SKIP 0
+
+/* CVMX_HELPER_ENABLE_BACK_PRESSURE controls whether back pressure is enabled
+** for all input ports. This controls if IPD sends backpressure to all ports if
+** Octeon's FPA pools don't have enough packet or work queue entries. Even when
+** this is off, it is still possible to get backpressure from individual
+** hardware ports. When configuring backpressure, also check
+** CVMX_HELPER_DISABLE_*_BACKPRESSURE below. If necessary, override the default
+** here */
+#define CVMX_HELPER_ENABLE_BACK_PRESSURE 1
+
+/* CVMX_HELPER_ENABLE_IPD controls if the IPD is enabled in the helper
+**  function. Once it is enabled the hardware starts accepting packets. You
+**  might want to skip the IPD enable if configuration changes are need
+**  from the default helper setup. If necessary, override the default here */
+#define CVMX_HELPER_ENABLE_IPD 0
+
+/* CVMX_HELPER_INPUT_TAG_TYPE selects the type of tag that the IPD assigns
+** to incoming packets. */
+#define CVMX_HELPER_INPUT_TAG_TYPE CVMX_POW_TAG_TYPE_ORDERED
+
+/* The following select which fields are used by the PIP to generate
+** the tag on INPUT
+** 0: don't include
+** 1: include */
+#define CVMX_HELPER_INPUT_TAG_IPV6_SRC_IP	0
+#define CVMX_HELPER_INPUT_TAG_IPV6_DST_IP   	0
+#define CVMX_HELPER_INPUT_TAG_IPV6_SRC_PORT 	0
+#define CVMX_HELPER_INPUT_TAG_IPV6_DST_PORT 	0
+#define CVMX_HELPER_INPUT_TAG_IPV6_NEXT_HEADER 	0
+#define CVMX_HELPER_INPUT_TAG_IPV4_SRC_IP	0
+#define CVMX_HELPER_INPUT_TAG_IPV4_DST_IP   	0
+#define CVMX_HELPER_INPUT_TAG_IPV4_SRC_PORT 	0
+#define CVMX_HELPER_INPUT_TAG_IPV4_DST_PORT 	0
+#define CVMX_HELPER_INPUT_TAG_IPV4_PROTOCOL	0
+#define CVMX_HELPER_INPUT_TAG_INPUT_PORT	1
+
+/* Select skip mode for input ports */
+#define CVMX_HELPER_INPUT_PORT_SKIP_MODE	CVMX_PIP_PORT_CFG_MODE_SKIPL2
+
+/* Define the number of queues per output port */
+#define CVMX_HELPER_PKO_QUEUES_PER_PORT_INTERFACE0	1
+#define CVMX_HELPER_PKO_QUEUES_PER_PORT_INTERFACE1	1
+
+/* Force backpressure to be disabled.  This overrides all other
+** backpressure configuration */
+#define CVMX_HELPER_DISABLE_RGMII_BACKPRESSURE 0
+
+/* Disable the SPI4000's processing of backpressure packets and backpressure
+** generation. When this is 1, the SPI4000 will not stop sending packets when
+** receiving backpressure. It will also not generate backpressure packets when
+** its internal FIFOs are full. */
+#define CVMX_HELPER_DISABLE_SPI4000_BACKPRESSURE 0
+
+/* Select the number of low latency memory ports (interfaces) that
+** will be configured.  Valid values are 1 and 2.
+*/
+#define CVMX_LLM_CONFIG_NUM_PORTS 1
+
+/* Enable the fix for PKI-100 errata ("Size field is 8 too large in WQE and next
+** pointers"). If CVMX_ENABLE_LEN_M8_FIX is not enabled the fix for this errats will 
+** not be enabled. 
+** 0: Fix is not enabled
+** 1: Fix is enabled, if supported by hardware
+*/
+#define CVMX_ENABLE_LEN_M8_FIX  1
+
+#if defined(CVMX_ENABLE_HELPER_FUNCTIONS) && !defined(CVMX_ENABLE_PKO_FUNCTIONS)
+#define CVMX_ENABLE_PKO_FUNCTIONS
+#endif
+
+/* Executive resource descriptions provided in cvmx-resources.config */
+#include "cvmx-resources.config"
+
+#endif
diff --git a/arch/mips/cavium-octeon/gpl-executive/cvmx-linux-kernel-exports.c b/arch/mips/cavium-octeon/gpl-executive/cvmx-linux-kernel-exports.c
new file mode 100644
index 0000000..e772b8c
--- /dev/null
+++ b/arch/mips/cavium-octeon/gpl-executive/cvmx-linux-kernel-exports.c
@@ -0,0 +1,142 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2005-2007 Cavium Networks
+ */
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include "cvmx.h"
+#include "cvmx-bootmem.h"
+#include "cvmx-cmd-queue.h"
+#include "cvmx-helper.h"
+#include "cvmx-helper-board.h"
+#include "cvmx-helper-util.h"
+#include "cvmx-mgmt-port.h"
+#include "cvmx-nand.h"
+#include "cvmx-pko.h"
+#include "cvmx-spi.h"
+#include "cvmx-sysinfo.h"
+#include "cvmx-tra.h"
+#include "cvmx-warn.h"
+#include "cvmx-usb.h"
+
+extern CVMX_SHARED __cvmx_cmd_queue_all_state_t *__cvmx_cmd_queue_state_ptr;
+
+/* Exports for cvmx-bootmem.c */
+EXPORT_SYMBOL(cvmx_bootmem_alloc);
+EXPORT_SYMBOL(cvmx_bootmem_alloc_address);
+EXPORT_SYMBOL(cvmx_bootmem_alloc_range);
+EXPORT_SYMBOL(cvmx_bootmem_alloc_named);
+EXPORT_SYMBOL(cvmx_bootmem_alloc_named_address);
+EXPORT_SYMBOL(cvmx_bootmem_alloc_named_range);
+EXPORT_SYMBOL(cvmx_bootmem_free_named);
+EXPORT_SYMBOL(cvmx_bootmem_find_named_block);
+EXPORT_SYMBOL(cvmx_bootmem_available_mem);
+
+/* Exports for cvmx-cmd-queue.c */
+EXPORT_SYMBOL(cvmx_cmd_queue_initialize);
+EXPORT_SYMBOL(cvmx_cmd_queue_shutdown);
+EXPORT_SYMBOL(cvmx_cmd_queue_length);
+EXPORT_SYMBOL(cvmx_cmd_queue_buffer);
+EXPORT_SYMBOL(__cvmx_cmd_queue_state_ptr);
+
+/* Exports for cvmx-helper.c */
+EXPORT_SYMBOL(cvmx_helper_ipd_and_packet_input_enable);
+EXPORT_SYMBOL(cvmx_helper_initialize_packet_io_global);
+EXPORT_SYMBOL(cvmx_helper_initialize_packet_io_local);
+EXPORT_SYMBOL(cvmx_helper_ports_on_interface);
+EXPORT_SYMBOL(cvmx_helper_get_number_of_interfaces);
+EXPORT_SYMBOL(cvmx_helper_interface_get_mode);
+EXPORT_SYMBOL(cvmx_helper_link_autoconf);
+EXPORT_SYMBOL(cvmx_helper_link_get);
+EXPORT_SYMBOL(cvmx_helper_link_set);
+
+/* Exports for cvmx-helper-board.c */
+EXPORT_SYMBOL(cvmx_helper_board_get_mii_address);
+EXPORT_SYMBOL(__cvmx_helper_board_usb_get_clock_type);
+
+/* Exports for cvmx-helper-util.c */
+EXPORT_SYMBOL(cvmx_helper_interface_mode_to_string);
+EXPORT_SYMBOL(cvmx_helper_dump_packet);
+EXPORT_SYMBOL(cvmx_helper_setup_red_queue);
+EXPORT_SYMBOL(cvmx_helper_setup_red);
+EXPORT_SYMBOL(cvmx_helper_get_version);
+EXPORT_SYMBOL(cvmx_helper_get_ipd_port);
+EXPORT_SYMBOL(cvmx_helper_get_interface_num);
+EXPORT_SYMBOL(cvmx_helper_get_interface_index_num);
+
+/* Exports for cvmx-mgmt-port.c */
+EXPORT_SYMBOL(cvmx_mgmt_port_initialize);
+EXPORT_SYMBOL(cvmx_mgmt_port_shutdown);
+EXPORT_SYMBOL(cvmx_mgmt_port_enable);
+EXPORT_SYMBOL(cvmx_mgmt_port_disable);
+EXPORT_SYMBOL(cvmx_mgmt_port_send);
+EXPORT_SYMBOL(cvmx_mgmt_port_receive);
+EXPORT_SYMBOL(cvmx_mgmt_port_get_link);
+EXPORT_SYMBOL(cvmx_mgmt_port_set_mac);
+EXPORT_SYMBOL(cvmx_mgmt_port_get_mac);
+EXPORT_SYMBOL(cvmx_mgmt_port_set_multicast_list);
+
+/* Exports for cvmx-nand.c */
+EXPORT_SYMBOL(cvmx_nand_initialize);
+EXPORT_SYMBOL(cvmx_nand_shutdown);
+EXPORT_SYMBOL(cvmx_nand_get_active_chips);
+EXPORT_SYMBOL(cvmx_nand_set_timing);
+EXPORT_SYMBOL(cvmx_nand_submit);
+EXPORT_SYMBOL(cvmx_nand_page_read);
+EXPORT_SYMBOL(cvmx_nand_page_write);
+EXPORT_SYMBOL(cvmx_nand_block_erase);
+EXPORT_SYMBOL(cvmx_nand_read_id);
+EXPORT_SYMBOL(cvmx_nand_get_status);
+EXPORT_SYMBOL(cvmx_nand_get_page_size);
+EXPORT_SYMBOL(cvmx_nand_get_pages_per_block);
+EXPORT_SYMBOL(cvmx_nand_get_blocks);
+EXPORT_SYMBOL(cvmx_nand_get_oob_size);
+EXPORT_SYMBOL(cvmx_nand_reset);
+
+/* Exports for cvmx-pko.c */
+EXPORT_SYMBOL(cvmx_pko_initialize_global);
+EXPORT_SYMBOL(cvmx_pko_initialize_local);
+EXPORT_SYMBOL(cvmx_pko_enable);
+EXPORT_SYMBOL(cvmx_pko_disable);
+EXPORT_SYMBOL(cvmx_pko_shutdown);
+EXPORT_SYMBOL(cvmx_pko_config_port);
+
+/* Exports for cvmx-spi.c and cvmx-spi4000.c */
+EXPORT_SYMBOL(cvmx_spi_restart_interface);
+EXPORT_SYMBOL(cvmx_spi4000_check_speed);
+
+/* Exports for cvmx-sysinfo.c */
+EXPORT_SYMBOL(cvmx_sysinfo_get);
+
+/* Exports for cvmx-tra.c */
+EXPORT_SYMBOL(cvmx_tra_setup);
+EXPORT_SYMBOL(cvmx_tra_trig_setup);
+EXPORT_SYMBOL(cvmx_tra_read);
+EXPORT_SYMBOL(cvmx_tra_decode_text);
+EXPORT_SYMBOL(cvmx_tra_display);
+
+/* Exports for cvmx-warn.c */
+EXPORT_SYMBOL(cvmx_warn);
+
+/* Exports for cvmx-usb.c */
+EXPORT_SYMBOL(cvmx_usb_get_num_ports);
+EXPORT_SYMBOL(cvmx_usb_initialize);
+EXPORT_SYMBOL(cvmx_usb_shutdown);
+EXPORT_SYMBOL(cvmx_usb_enable);
+EXPORT_SYMBOL(cvmx_usb_disable);
+EXPORT_SYMBOL(cvmx_usb_get_status);
+EXPORT_SYMBOL(cvmx_usb_set_status);
+EXPORT_SYMBOL(cvmx_usb_open_pipe);
+EXPORT_SYMBOL(cvmx_usb_submit_bulk);
+EXPORT_SYMBOL(cvmx_usb_submit_interrupt);
+EXPORT_SYMBOL(cvmx_usb_submit_control);
+EXPORT_SYMBOL(cvmx_usb_submit_isochronous);
+EXPORT_SYMBOL(cvmx_usb_cancel);
+EXPORT_SYMBOL(cvmx_usb_cancel_all);
+EXPORT_SYMBOL(cvmx_usb_close_pipe);
+EXPORT_SYMBOL(cvmx_usb_register_callback);
+EXPORT_SYMBOL(cvmx_usb_get_frame_number);
+EXPORT_SYMBOL(cvmx_usb_poll);
diff --git a/arch/mips/cavium-octeon/hal.c b/arch/mips/cavium-octeon/hal.c
new file mode 100644
index 0000000..ce9bff4
--- /dev/null
+++ b/arch/mips/cavium-octeon/hal.c
@@ -0,0 +1,980 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004 - 2007 Cavium Networks
+ */
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/mii.h>
+#include <asm/time.h>
+#include <octeon-app-init.h>
+#include <asm-generic/sections.h>
+#include <linux/kexec.h>
+
+#ifndef CONFIG_CAVIUM_RESERVE32
+#define CONFIG_CAVIUM_RESERVE32 0
+#endif
+
+#include "hal.h"
+
+#include "cvmx-bootmem.h"
+#include "cvmx-app-init.h"
+#include "cvmx-sysinfo.h"
+#include "cvmx-l2c.h"
+#include "cvmx-spinlock.h"
+#include "cvmx-csr-addresses.h"
+#include "octeon-model.h"
+#include "cvmx-pow.h"
+#include "cvmx-fpa.h"
+
+extern void add_wired_entry(unsigned long entrylo0,
+			    unsigned long entrylo1,
+			    unsigned long entryhi,
+			    unsigned long pagemask);
+extern asmlinkage void handle_int(void);
+extern asmlinkage void plat_irq_dispatch(void);
+
+/* Set to non-zero, so it is not in .bss section and is not zeroed */
+volatile octeon_boot_descriptor_t *octeon_boot_desc_ptr = (void *) 0xEADBEEFULL;
+cvmx_bootinfo_t *octeon_bootinfo;
+
+/* This must not be static since inline functions access it */
+spinlock_t octeon_led_lock;
+
+#if CONFIG_CAVIUM_RESERVE32
+uint64_t octeon_reserve32_memory;
+#endif
+
+#ifdef CONFIG_KEXEC
+/* machine-specific function pointers for kexec */
+extern int (*_machine_kexec_prepare)(struct kimage *);
+extern void (*_machine_kexec_shutdown)(void);
+extern void (*_machine_crash_shutdown)(struct pt_regs *);
+#endif
+
+#ifdef CONFIG_CRASH_DUMP
+extern int (*_machine_check_pfn_validity)(unsigned long pfn);
+static int octeon_check_pfn_validity(unsigned long pfn)
+{
+	return (pfn_present(pfn) && pfn_valid(pfn));
+}
+#endif
+
+/**
+ * Write to the LCD display connected to the bootbus. This display
+ * exists on most Cavium evaluation boards. If it doesn't exist, then
+ * this function doesn't do anything.
+ *
+ * @param s      String to write
+ */
+void octeon_write_lcd(const char *s)
+{
+	if (octeon_bootinfo->led_display_base_addr) {
+		volatile char *lcd_address =
+			cvmx_phys_to_ptr(octeon_bootinfo->
+					 led_display_base_addr);
+		int i;
+		for (i = 0; i < 8; i++) {
+			if (*s)
+				lcd_address[i] = *s++;
+			else
+				lcd_address[i] = ' ';
+		}
+	}
+}
+
+
+/**
+ * Check the hardware BIST results for a CPU
+ */
+void octeon_check_cpu_bist(void)
+{
+	const int coreid = cvmx_get_core_num();
+	unsigned long long mask;
+	unsigned long long bist_val;
+
+	/* Check BIST results for COP0 registers */
+	mask = 0x1f00000000ull;
+	bist_val = __read_64bit_c0_register($27, 0);
+	if (bist_val & mask)
+		pr_err("Core%d BIST Failure: CacheErr(icache) = 0x%llx\n",
+		       coreid, bist_val);
+
+	bist_val = __read_64bit_c0_register($27, 1);
+	if (bist_val & 1)
+		pr_err("Core%d L1 Dcache parity error: CacheErr(dcache) = 0x%llx\n", coreid, bist_val);
+
+	mask = 0xfc00000000000000ull;
+	bist_val = __read_64bit_c0_register($11, 7);
+	if (bist_val & mask)
+		pr_err("Core%d BIST Failure: COP0_CVM_MEM_CTL = 0x%llx\n",
+		       coreid, bist_val);
+
+	__write_64bit_c0_register($27, 1, 0);
+}
+
+
+/**
+ * Return non zero if we are currently running in the Octeon simulator
+ *
+ * @return
+ */
+int octeon_is_simulation(void)
+{
+	return octeon_bootinfo->board_type == CVMX_BOARD_TYPE_SIM;
+}
+
+
+/**
+ * Return true if Octeon is in PCI Host mode. This means
+ * Linux can control the PCI bus.
+ *
+ * @return Non zero if Octeon in host mode
+ */
+int octeon_is_pci_host(void)
+{
+#ifdef CONFIG_PCI
+	return octeon_bootinfo->config_flags & CVMX_BOOTINFO_CFG_FLAG_PCI_HOST;
+#else
+	return 0;
+#endif
+}
+
+
+/**
+ * This function returns if the USB clock uses 12/24/48MHz 3.3V
+ * reference clock at the USB_REF_CLK pin. Result is non zero
+ * if it does, If it uses 12MHz crystal as clock source at USB_XO
+ * and USB_XI, then the return value is zero. This function will
+ * need update for new boards.
+ *
+ * @return True is USB is using a reference clock
+ */
+int octeon_usb_is_ref_clk(void)
+{
+	switch (octeon_bootinfo->board_type) {
+	case CVMX_BOARD_TYPE_BBGW_REF:
+		return 0;
+	}
+	return 1;
+}
+
+
+/**
+ * Get the clock rate of Octeon
+ *
+ * @return Clock rate in HZ
+ */
+uint64_t octeon_get_clock_rate(void)
+{
+	if (octeon_is_simulation())
+		octeon_bootinfo->eclock_hz = 6000000;
+	return octeon_bootinfo->eclock_hz;
+}
+
+
+/**
+ * Return the board name as a constant string
+ *
+ * @return board name
+ */
+const char *octeon_board_type_string(void)
+{
+	static char name[80];
+	sprintf(name, "%s (%s)",
+		cvmx_board_type_to_string(octeon_bootinfo->board_type),
+		octeon_model_get_string(read_c0_prid()));
+	return name;
+}
+
+
+/**
+ * Return the mapping of PCI device number to IRQ line. Each
+ * character in the return string represents the interrupt
+ * line for the device at that position. Device 1 maps to the
+ * first character, etc. The characters A-D are used for PCI
+ * interrupts.
+ *
+ * @return PCI interrupt mapping
+ */
+const char *octeon_get_pci_interrupts(void)
+{
+	/* Returning an empty string causes the interrupts to be routed based
+	   on the PCI specification. From the PCI spec:
+
+	   INTA# of Device Number 0 is connected to IRQW on the system board.
+	   (Device Number has no significance regarding being located on the
+	   system board or in a connector.) INTA# of Device Number 1 is
+	   connected to IRQX on the system board. INTA# of Device Number 2 is
+	   connected to IRQY on the system board. INTA# of Device Number 3 is
+	   connected to IRQZ on the system board. The table below describes how
+	   each agent's INTx# lines are connected to the system board interrupt
+	   lines. The following equation can be used to determine to which
+	   INTx# signal on the system board a given device's INTx# line(s) is
+	   connected.
+
+	   MB = (D + I) MOD 4 MB = System board Interrupt (IRQW = 0, IRQX = 1,
+	   IRQY = 2, and IRQZ = 3) D = Device Number I = Interrupt Number
+	   (INTA# = 0, INTB# = 1, INTC# = 2, and INTD# = 3) */
+	switch (octeon_bootinfo->board_type) {
+	/* Device ID              1111111111222222222233 */
+	/*              01234567890123456789012345678901 */
+	case CVMX_BOARD_TYPE_NAO38:
+		return "AAAAADABAAAAAAAAAAAAAAAAAAAAAAAA";	/* This is
+								   really the
+								   NAC38 */
+	case CVMX_BOARD_TYPE_THUNDER:
+		return "";
+	case CVMX_BOARD_TYPE_EBH3000:
+		return "";
+	case CVMX_BOARD_TYPE_EBH3100:
+	case CVMX_BOARD_TYPE_CN3010_EVB_HS5:
+	case CVMX_BOARD_TYPE_CN3005_EVB_HS5:
+		return "AAABAAAAAAAAAAAAAAAAAAAAAAAAAAAA";
+	case CVMX_BOARD_TYPE_BBGW_REF:
+		return "AABCD";
+	default:
+		return "";
+	}
+}
+
+
+/**
+ * Return the interrupt line for the i8259 in the southbridge
+ *
+ * @return
+ */
+int octeon_get_southbridge_interrupt(void)
+{
+	switch (octeon_bootinfo->board_type) {
+	case CVMX_BOARD_TYPE_EBH3000:
+		return 47;	/* PCI INDD */
+	case CVMX_BOARD_TYPE_NAC38:
+		return 39;	/* GPIO 15 */
+	default:
+		return 0;	/* No southbridge */
+	}
+}
+
+
+/**
+ * Get the coremask Linux was booted on.
+ *
+ * @return Core mask
+ */
+int octeon_get_boot_coremask(void)
+{
+	return octeon_boot_desc_ptr->core_mask;
+}
+
+
+/**
+ * Return the number of arguments we got from the bootloader
+ *
+ * @return argc
+ */
+int octeon_get_boot_num_arguments(void)
+{
+	return octeon_boot_desc_ptr->argc;
+}
+
+
+/**
+ * Return the console uart passed by the bootloader
+ *
+ * @return uart   (0 or 1)
+ */
+int octeon_get_boot_uart(void)
+{
+#if OCTEON_APP_INIT_H_VERSION >= 1	/* The UART1 flag is new */
+	return !!(octeon_boot_desc_ptr->flags & OCTEON_BL_FLAG_CONSOLE_UART1);
+#else
+	return 0;
+#endif
+}
+
+/**
+ * Return the debug flag passed by the bootloader
+ *
+ * @return debug flag (0 or 1)
+ */
+int octeon_get_boot_debug_flag(void)
+{
+	return !!(octeon_boot_desc_ptr->flags & OCTEON_BL_FLAG_DEBUG);
+}
+
+/**
+ * Get an argument from the bootloader
+ *
+ * @param arg    argument to get
+ * @return argument
+ */
+const char *octeon_get_boot_argument(int arg)
+{
+	return cvmx_phys_to_ptr(octeon_boot_desc_ptr->argv[arg]);
+}
+
+
+/**
+ * Called very early in the initial C code to initialize the Octeon
+ * HAL layer.
+ */
+void octeon_hal_init(void)
+{
+	cvmx_sysinfo_t *sysinfo;
+
+	/* Make sure we got the boot descriptor block */
+	if ((octeon_boot_desc_ptr == (void *) 0xEADBEEFULL))
+		panic("Boot descriptor block wasn't passed properly\n");
+
+	octeon_bootinfo =
+		cvmx_phys_to_ptr(octeon_boot_desc_ptr->cvmx_desc_vaddr);
+	cvmx_bootmem_init(cvmx_phys_to_ptr(octeon_bootinfo->phy_mem_desc_addr));
+
+	spin_lock_init(&octeon_led_lock);
+	/* Only enable the LED controller if we're running on a CN38XX, CN58XX,
+	   or CN56XX. The CN30XX and CN31XX don't have an LED controller */
+	if (!octeon_is_simulation() &&
+	    octeon_has_feature(OCTEON_FEATURE_LED_CONTROLLER)) {
+		cvmx_write_csr(CVMX_LED_EN, 0);
+		cvmx_write_csr(CVMX_LED_PRT, 0);
+		cvmx_write_csr(CVMX_LED_DBG, 0);
+		cvmx_write_csr(CVMX_LED_PRT_FMT, 0);
+		cvmx_write_csr(CVMX_LED_UDD_CNTX(0), 32);
+		cvmx_write_csr(CVMX_LED_UDD_CNTX(1), 32);
+		cvmx_write_csr(CVMX_LED_UDD_DATX(0), 0);
+		cvmx_write_csr(CVMX_LED_UDD_DATX(1), 0);
+		cvmx_write_csr(CVMX_LED_EN, 1);
+	}
+#if CONFIG_CAVIUM_RESERVE32
+	{
+		int64_t addr = -1;
+		/* We need to temporarily allocate all memory in the reserve32
+		   region. This makes sure the kernel doesn't allocate this
+		   memory when it is getting memory from the bootloader. Later,
+		   after the memory allocations are complete, the reserve32
+		   will be freed */
+#ifdef CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB
+		if (CONFIG_CAVIUM_RESERVE32 & 0x1ff)
+			pr_err("CAVIUM_RESERVE32 isn't a multiple of 512MB. This is required if CAVIUM_RESERVE32_USE_WIRED_TLB is set\n");
+		else
+			addr = cvmx_bootmem_phy_named_block_alloc
+				(CONFIG_CAVIUM_RESERVE32 << 20, 0, 0, 512 << 20,
+				 "CAVIUM_RESERVE32", 0);
+#else
+		/* Allocate memory for RESERVED32 aligned on 2MB boundary. This
+		   is in case we later use hugetlb entries with it */
+		addr = cvmx_bootmem_phy_named_block_alloc
+			(CONFIG_CAVIUM_RESERVE32 << 20, 0, 0, 2 << 20,
+			 "CAVIUM_RESERVE32", 0);
+#endif
+		if (addr < 0)
+			pr_err("Failed to allocate CAVIUM_RESERVE32 memory area\n");
+		else
+			octeon_reserve32_memory = addr;
+
+	}
+#endif
+
+#ifdef CONFIG_CAVIUM_OCTEON_LOCK_L2
+	if (cvmx_read_csr(CVMX_L2D_FUS3) & (3ull << 34)) {
+		pr_info("Skipping L2 locking due to reduced L2 cache size\n");
+	} else {
+		uint32_t ebase = read_c0_ebase() & 0x3ffff000;
+#ifdef CONFIG_CAVIUM_OCTEON_LOCK_L2_TLB
+		cvmx_l2c_lock_mem_region(ebase, 0x100);	/* TLB refill */
+#endif
+#ifdef CONFIG_CAVIUM_OCTEON_LOCK_L2_EXCEPTION
+		cvmx_l2c_lock_mem_region(ebase + 0x180, 0x80);	/* General
+								   exception */
+#endif
+#ifdef CONFIG_CAVIUM_OCTEON_LOCK_L2_LOW_LEVEL_INTERRUPT
+		cvmx_l2c_lock_mem_region(ebase + 0x200, 0x80);	/* Interrupt
+								   handler */
+#endif
+#ifdef CONFIG_CAVIUM_OCTEON_LOCK_L2_INTERRUPT
+		cvmx_l2c_lock_mem_region(__pa_symbol(handle_int), 0x100);
+		cvmx_l2c_lock_mem_region(__pa_symbol(plat_irq_dispatch), 0x80);
+#endif
+#ifdef CONFIG_CAVIUM_OCTEON_LOCK_L2_MEMCPY
+		cvmx_l2c_lock_mem_region(__pa_symbol(memcpy), 0x480);
+#endif
+	}
+#endif
+
+	sysinfo = cvmx_sysinfo_get();
+	memset(sysinfo, 0, sizeof(*sysinfo));
+	sysinfo->system_dram_size = (uint64_t)octeon_bootinfo->dram_size << 20;
+	sysinfo->phy_mem_desc_ptr =
+		cvmx_phys_to_ptr(octeon_bootinfo->phy_mem_desc_addr);
+	sysinfo->core_mask = octeon_bootinfo->core_mask;
+	sysinfo->exception_base_addr = octeon_bootinfo->exception_base_addr;
+	sysinfo->cpu_clock_hz = octeon_bootinfo->eclock_hz;
+	sysinfo->dram_data_rate_hz = octeon_bootinfo->dclock_hz * 2;
+	sysinfo->board_type = octeon_bootinfo->board_type;
+	sysinfo->board_rev_major = octeon_bootinfo->board_rev_major;
+	sysinfo->board_rev_minor = octeon_bootinfo->board_rev_minor;
+	memcpy(sysinfo->mac_addr_base, octeon_bootinfo->mac_addr_base,
+	       sizeof(sysinfo->mac_addr_base));
+	sysinfo->mac_addr_count = octeon_bootinfo->mac_addr_count;
+	memcpy(sysinfo->board_serial_number,
+	       octeon_bootinfo->board_serial_number,
+	       sizeof(sysinfo->board_serial_number));
+	sysinfo->compact_flash_common_base_addr =
+		octeon_bootinfo->compact_flash_common_base_addr;
+	sysinfo->compact_flash_attribute_base_addr =
+		octeon_bootinfo->compact_flash_attribute_base_addr;
+	sysinfo->led_display_base_addr = octeon_bootinfo->led_display_base_addr;
+	sysinfo->dfa_ref_clock_hz = octeon_bootinfo->dfa_ref_clock_hz;
+	sysinfo->bootloader_config_flags = octeon_bootinfo->config_flags;
+}
+
+
+#ifdef CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB
+/**
+ * Called on every core to setup the wired tlb entry needed
+ * if CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB is set.
+ *
+ * @param unused
+ */
+static void octeon_hal_setup_per_cpu_reserved32(void *unused)
+{
+	/* The config has selected to wire the reserve32 memory for all
+	   userspace applications. We need to put a wired TLB entry in for each
+	   512MB of reserve32 memory. We only handle double 256MB pages here,
+	   so reserve32 must be multiple of 512MB */
+	uint32_t size = CONFIG_CAVIUM_RESERVE32;
+	uint32_t entrylo0 =
+		0x7 | ((octeon_reserve32_memory & ((1ul << 40) - 1)) >> 6);
+	uint32_t entrylo1 = entrylo0 + (256 << 14);
+	uint32_t entryhi = (0x80000000UL - (CONFIG_CAVIUM_RESERVE32 << 20));
+	while (size >= 512) {
+		/*
+		pr_info("CPU%d: Adding double wired TLB entry for 0x%lx\n",
+		       smp_processor_id(), entryhi);
+		*/
+		add_wired_entry(entrylo0, entrylo1, entryhi, PM_256M);
+		entrylo0 += 512 << 14;
+		entrylo1 += 512 << 14;
+		entryhi += 512 << 20;
+		size -= 512;
+	}
+}
+#endif				/* CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB */
+
+/**
+ * Called to release the named block which was used to made sure
+ * that nobody used the memory for something else during
+ * init. Now we'll free it so userspace apps can use this
+ * memory region with bootmem_alloc.
+ *
+ * This function is called only once from prom_free_prom_memory().
+ */
+void octeon_hal_setup_reserved32(void)
+{
+#ifdef CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB
+	on_each_cpu(octeon_hal_setup_per_cpu_reserved32, NULL, 1);
+#endif
+}
+
+
+/**
+ * Poweroff the Octeon board if possible.
+ */
+void octeon_poweroff(void)
+{
+	switch (octeon_bootinfo->board_type) {
+	case CVMX_BOARD_TYPE_NAO38:
+		/* Driving a 1 to GPIO 12 shuts off this board */
+		cvmx_write_csr(CVMX_GPIO_BIT_CFGX(12), 1);
+		cvmx_write_csr(CVMX_GPIO_TX_SET, 0x1000);
+		break;
+	default:
+		octeon_write_lcd("PowerOff");
+		break;
+	}
+}
+
+
+/**
+ * Enable access to Octeon's COP2 crypto hardware for kernel use.
+ * Wrap any crypto operations in calls to
+ * octeon_crypto_enable/disable in order to make sure the state of
+ * COP2 isn't corrupted if userspace is also performing hardware
+ * crypto operations. Allocate the state parameter on the stack.
+ *
+ * @param state  State structure to store current COP2 state in
+ *
+ * @return Flags to be passed to octeon_crypto_disable()
+ */
+unsigned long octeon_crypto_enable(struct octeon_cop2_state *state)
+{
+	extern void octeon_cop2_save(struct octeon_cop2_state *);
+	int status;
+	unsigned long flags;
+
+	local_irq_save(flags);
+	status = read_c0_status();
+	write_c0_status(status | ST0_CU2);
+	if (KSTK_STATUS(current) & ST0_CU2) {
+		octeon_cop2_save(&(current->thread.cp2));
+		KSTK_STATUS(current) &= ~ST0_CU2;
+		status &= ~ST0_CU2;
+	} else if (status & ST0_CU2)
+		octeon_cop2_save(state);
+	local_irq_restore(flags);
+	return status & ST0_CU2;
+}
+EXPORT_SYMBOL(octeon_crypto_enable);
+
+
+/**
+ * Disable access to Octeon's COP2 crypto hardware in the kernel.
+ * This must be called after an octeon_crypto_enable() before any
+ * context switch or return to userspace.
+ *
+ * @param state  COP2 state to restore
+ * @param flags  Return value from octeon_crypto_enable()
+ */
+void octeon_crypto_disable(struct octeon_cop2_state *state, unsigned long crypto_flags)
+{
+	extern void octeon_cop2_restore(struct octeon_cop2_state *);
+	unsigned long flags;
+
+	local_irq_save(flags);
+	if (crypto_flags & ST0_CU2)
+		octeon_cop2_restore(state);
+	else
+		write_c0_status(read_c0_status() & ~ST0_CU2);
+	local_irq_restore(flags);
+}
+EXPORT_SYMBOL(octeon_crypto_disable);
+
+
+
+/* Misc exports */
+EXPORT_SYMBOL(octeon_is_simulation);
+EXPORT_SYMBOL(octeon_bootinfo);
+#if CONFIG_CAVIUM_RESERVE32
+EXPORT_SYMBOL(octeon_reserve32_memory);
+#endif
+
+EXPORT_SYMBOL(octeon_get_clock_rate);
+
+#ifdef CONFIG_KEXEC
+/* externs for network shutdown during kexec */
+extern struct net_device *cvm_oct_device[];
+typedef struct {
+	int                     port;
+	int                     queue;
+	int                     imode;
+	struct sk_buff_head     tx_free_list[16];
+	struct net_device_stats stats;
+	struct mii_if_info      mii_info;
+	int (*intercept_cb)(void);
+	uint64_t                link_info;
+	void (*poll)(struct net_device *dev);
+} cvm_oct_private_t;
+
+typedef struct {
+	uint8_t now_serving;
+	uint64_t unused1:24;
+	uint64_t fpa_pool:3;
+	uint64_t base_ptr_div128:29;
+	uint64_t unused2:6;
+	uint64_t pool_size_m1:13;
+	uint64_t index:13;
+} __cvmx_cmd_queue_state_t;
+
+static inline void cvmx_helper_free_packet_data(cvmx_wqe_t * work) {
+	uint64_t number_buffers;
+	cvmx_buf_ptr_t buffer_ptr;
+	cvmx_buf_ptr_t next_buffer_ptr;
+	uint64_t start_of_buffer;
+
+	buffer_ptr = work->packet_ptr;
+	number_buffers = work->word2.s.bufs;
+
+	while (number_buffers--) {
+		/* Remember the back pointer is in cache lines, not 64bit words */
+		start_of_buffer =
+		    ((buffer_ptr.s.addr >> 7) - buffer_ptr.s.back) << 7;
+		/* Read pointer to next buffer before we free the current buffer. */
+		next_buffer_ptr =
+		    *(cvmx_buf_ptr_t *) cvmx_phys_to_ptr(buffer_ptr.s.addr - 8);
+		cvmx_fpa_free(cvmx_phys_to_ptr(start_of_buffer),
+			      buffer_ptr.s.pool, 0);
+		buffer_ptr = next_buffer_ptr;
+	}
+}
+
+#define CVMX_CMD_QUEUE_END 0x50000
+typedef struct {
+	uint64_t ticket[(CVMX_CMD_QUEUE_END >> 16) * 256];
+	__cvmx_cmd_queue_state_t state[(CVMX_CMD_QUEUE_END >> 16) * 256];
+} __cvmx_cmd_queue_all_state_t;
+
+typedef union {
+	uint64_t u64;
+	struct {
+		uint64_t reserved_20_63:44;
+		uint64_t link_up:1; /**< Is the physical link up? */
+		uint64_t full_duplex:1;
+				    /**< 1 if the link is full duplex */
+		uint64_t speed:18;  /**< Speed of the link in Mbps */
+	} s;
+} cvmx_helper_link_info_t;
+
+#define CVMX_FPA_WQE_POOL (1)
+#define CVMX_HELPER_INTERFACE_MODE_RGMII (1)
+#define CVMX_HELPER_INTERFACE_MODE_GMII (2)
+
+extern void cvmx_pko_disable(void);
+extern void cvmx_pko_shutdown(void);
+extern void cvmx_cmd_queue_shutdown(int);
+extern void* cvmx_cmd_queue_buffer(int);
+extern int cvmx_helper_get_number_of_interfaces(void);
+extern int cvmx_helper_interface_get_mode(int interface);
+extern int cvmx_helper_interface_probe(int interface);
+extern int cvmx_helper_ports_on_interface(int interface);
+extern cvmx_helper_link_info_t cvmx_helper_link_get(int ipd_port);
+extern int cvmx_helper_get_ipd_port(int interface, int port);
+extern int cvmx_helper_link_set(int ipd_port, cvmx_helper_link_info_t link_info);
+
+void octeon_shutdown_network_hw(void)
+{
+	cvmx_helper_link_info_t link_info;
+	cvmx_wqe_t *work = NULL;
+	int ipd_port = 0;
+	int num_ints = 0;
+	int interface = 0;
+	int num_ports = 0;
+	int port = 0;
+	cvmx_pko_reg_flags_t pko_reg_flags;
+	cvmx_fpa_ctl_status_t fpa_status;
+	cvmx_smix_en_t smix_en;
+	cvmx_ipd_ctl_status_t ipd_ctl_status;
+	cvmx_pip_sft_rst_t pip_sft_rst;
+
+	/* free up the work queue associated with this core */
+	work = cvmx_pow_get_current_wqp();
+	if (NULL != work) {
+		/* drain the work queue and free it */
+		cvmx_helper_free_packet_data(work);
+		cvmx_fpa_free(work, CVMX_FPA_WQE_POOL, 0);
+	}
+
+	/* halt the interfaces */
+	num_ints = cvmx_helper_get_number_of_interfaces();
+	if (num_ints > 2)
+		num_ints = 2;
+
+	/* Check to see what interface and ports we should use */
+	for (interface = 0; interface < num_ints; interface++) {
+		if ((CVMX_HELPER_INTERFACE_MODE_RGMII ==
+			cvmx_helper_interface_get_mode(interface)) ||
+			(CVMX_HELPER_INTERFACE_MODE_GMII ==
+				cvmx_helper_interface_get_mode(interface))) {
+			/* get the ports for this interface */
+			cvmx_helper_interface_probe(interface);
+			num_ports = cvmx_helper_ports_on_interface(interface);
+
+			for (port = 0; port < num_ports; port++) {
+				ipd_port = cvmx_helper_get_ipd_port(interface, port);
+
+				link_info = cvmx_helper_link_get(ipd_port);
+				link_info.s.link_up = 0;
+				cvmx_helper_link_set(ipd_port, link_info);
+			}
+		}
+	}
+
+	/* disable the SMI */
+	smix_en.u64 = cvmx_read_csr(CVMX_SMIX_EN(0));
+	if (smix_en.s.en) {
+		smix_en.s.en = 0;
+		cvmx_write_csr(CVMX_SMIX_EN(0), smix_en.u64);
+	}
+
+	/* Newer chips actually have two SMI/MDIO interfaces */
+	if (!OCTEON_IS_MODEL(OCTEON_CN3XXX) &&
+		!OCTEON_IS_MODEL(OCTEON_CN58XX) &&
+		!OCTEON_IS_MODEL(OCTEON_CN50XX)) {
+		smix_en.u64 = cvmx_read_csr(CVMX_SMIX_EN(1));
+		if (smix_en.s.en) {
+			smix_en.s.en = 0;
+			cvmx_write_csr(CVMX_SMIX_EN(1), smix_en.u64);
+		}
+	}
+
+	/* Reset the IPD to get all buffers out of it */
+	ipd_ctl_status.u64 = cvmx_read_csr(CVMX_IPD_CTL_STATUS);
+	ipd_ctl_status.s.reset = 1;
+	cvmx_write_csr(CVMX_IPD_CTL_STATUS, ipd_ctl_status.u64);
+
+	/* Reset the PIP */
+	pip_sft_rst.u64 = cvmx_read_csr(CVMX_PIP_SFT_RST);
+	pip_sft_rst.s.rst = 1;
+	cvmx_write_csr(CVMX_PIP_SFT_RST, pip_sft_rst.u64);
+
+	/* disable the PKO */
+	pko_reg_flags.u64 = cvmx_read_csr(CVMX_PKO_REG_FLAGS);
+	pko_reg_flags.s.ena_pko = 0;
+	cvmx_write_csr(CVMX_PKO_REG_FLAGS, pko_reg_flags.u64);
+
+	/* reset the PKO */
+	pko_reg_flags.u64 = cvmx_read_csr(CVMX_PKO_REG_FLAGS);
+	pko_reg_flags.s.reset = 1;
+	cvmx_write_csr(CVMX_PKO_REG_FLAGS, pko_reg_flags.u64);
+
+	/* disable the FPA */
+	fpa_status.u64 = cvmx_read_csr(CVMX_FPA_CTL_STATUS);
+	fpa_status.s.enb = 0;
+	cvmx_write_csr(CVMX_FPA_CTL_STATUS, fpa_status.u64);
+
+	/* reset the FPA */
+	fpa_status.u64 = cvmx_read_csr(CVMX_FPA_CTL_STATUS);
+	fpa_status.s.reset = 1;
+	cvmx_write_csr(CVMX_FPA_CTL_STATUS, fpa_status.u64);
+
+	/* free the cvmx_cmd_queues from bootmemory */
+	cvmx_bootmem_free_named("cvmx_cmd_queues");
+}
+
+#ifdef CONFIG_SMP
+static cpumask_t kexec_cpus = CPU_MASK_NONE;
+
+static void octeon_kexec_shutdown_other_cpus(void *ignore)
+{
+	/* for each CPU except CPU0 go into a loop until we've relocated
+	 * the kernel and then jump to that page
+	 */
+	int cpu = smp_processor_id();
+	if (!cpu_online(cpu))
+		return;
+
+	local_irq_disable();
+
+	cpu_set(cpu, kexec_cpus);
+
+	while (!atomic_read(&kexec_ready_to_reboot)) {
+		cpu_relax();
+	}
+	relocated_kexec_smp_wait(NULL);
+}
+#endif /* CONFIG_SMP */
+
+/* externs for USB shutdown */
+#define MAX_USB_PORTS   10
+extern struct platform_device *pdev_glob[MAX_USB_PORTS];
+extern void platform_device_unregister(struct platform_device *pdev);
+
+extern int cvmx_mgmt_port_shutdown(int port);
+
+void octeon_kexec_shutdown(void)
+{
+#ifdef CONFIG_SMP
+	unsigned int msecs;
+	unsigned int ncpus;
+
+	/* proceed to shutdown the other CPUs */
+	ncpus = num_online_cpus() - 1; /* exclude this CPU */
+	cpus_clear(kexec_cpus);
+
+	printk(KERN_EMERG "Sending IPI to other cpus...\n");
+	if (smp_call_function(&octeon_kexec_shutdown_other_cpus, NULL, 0))
+		printk(KERN_EMERG "failed to send IPI\n");
+	smp_wmb();
+
+	msecs = 10000;
+	while ((cpus_weight(kexec_cpus) < ncpus) && (--msecs > 0)) {
+		cpu_relax();
+		mdelay(1);
+	}
+#endif /* CONFIG_SMP */
+
+	/* shutdown all USB ports */
+	int i=0;
+	for(i=0; i < MAX_USB_PORTS; i++) {
+		if(pdev_glob[i]) {
+			platform_device_unregister(pdev_glob[i]);
+			pdev_glob[i] = NULL;
+		}
+	}
+
+	/* shutdown all mgmt ports */
+	int port;
+	int num_ports;
+	struct net_device dev;
+	struct net_device *mgmt_port;
+	struct net        *net;
+
+	if(OCTEON_IS_MODEL(OCTEON_CN52XX))
+		num_ports = 2;
+	else if(OCTEON_IS_MODEL(OCTEON_CN56XX))
+		num_ports = 1;
+	else
+		num_ports = 0;
+
+	for(port=0; port < num_ports; port++)
+	{
+		memset(&dev, 0, sizeof(dev));
+		net = dev_net(&dev);
+		if(!net)
+			continue;
+
+		mgmt_port = dev_get_by_name(net, (port==0 ? "mgmt0" : "mgmt1"));
+		if(!mgmt_port)
+			continue;
+
+		cvmx_write_csr(CVMX_MIXX_IRHWM(port), 0);
+		cvmx_write_csr(CVMX_MIXX_INTENA(port), 0);
+		cvmx_mgmt_port_shutdown(port);
+		free_irq(mgmt_port->irq, mgmt_port);
+
+		/* flag the new kernel to query for the mgmt port mac address */
+		uint64_t *prev_mac_ptr = cvmx_bootmem_alloc_named(sizeof(uint64_t), 64, "kexec_previous_mac");
+		if(!prev_mac_ptr) {
+			uint64_t *prev_mac_ptr_phys = 
+				cvmx_bootmem_find_named_block("kexec_previous_mac");
+			if(prev_mac_ptr_phys)
+				prev_mac_ptr = cvmx_phys_to_ptr(prev_mac_ptr_phys);
+		}
+	}
+}
+
+void octeon_crash_shutdown(struct pt_regs *regs)
+{
+#ifdef CONFIG_SMP
+	/* just use the normal shutdown() mechanism */
+	octeon_kexec_shutdown();
+#endif /* CONFIG_SMP */
+}
+
+/*
+ * the arguments passed into the new kernel
+ * kexec_args[0] = register a0 = argc
+ * kexec_args[1] = register a1 = argv at a kseg0 compatible address
+ * kexec_args[2] = register a2 = 1 if init core, zero otherwise
+ * kexec_args[3] = register a3 = address of boot descriptor block
+ */
+extern unsigned long kexec_args[4];
+#ifdef CONFIG_SMP
+extern unsigned long secondary_kexec_args[4];
+#endif /* CONFIG_SMP */
+
+int octeon_kexec_prepare(struct kimage *kimage)
+{
+	unsigned long argv = 0;
+	int i = 0;
+	char *kbuf = NULL;
+	const unsigned long KBUF_SIZE = 1024;
+	int buflen = 0;
+	void *userbuf = NULL;
+	char *kexec = "kexec";
+
+	/* setup the boot descriptor pointer */
+	for (i=0; i < OCTEON_ARGV_MAX_ARGS; i++) {
+		/* invalidate all entries in the boot ptr */
+		octeon_boot_desc_ptr->argv[i] = 0;
+	}
+	octeon_boot_desc_ptr->argc = 0;
+
+	/* get the argc and argv */
+	/* search through the source pages looking for a page that starts
+	 * with the string "kexec"
+	 */
+	kbuf = kmalloc(KBUF_SIZE, GFP_KERNEL);
+
+	/* find the cmdline buffer in the kimage */
+	for (i=0; (!argv) && (i < kimage->nr_segments); i++) {
+		memset(kbuf, 0, KBUF_SIZE);
+		copy_from_user(kbuf, kimage->segment[i].buf,
+			(kimage->segment[i].bufsz > KBUF_SIZE ?
+			KBUF_SIZE :  kimage->segment[i].bufsz));
+
+		/* see if this buffer starts with "kexec" */
+		if (memcmp(kbuf, kexec, 5) == 0) {
+			/* this is the buffer */
+			userbuf = kimage->segment[i].buf;
+			argv = (unsigned long)kimage->segment[i].mem;
+		}
+	}
+
+	if (argv) {
+		/* argv is the location of argv at a kseg0 address */
+		kexec_args[1] = argv;
+
+		/* parse the buffer and copy into the boot descriptor */
+		char *p = kbuf;
+		int looking_for_space = 0;
+		while (*p) {
+			if (1 == looking_for_space) {
+				if (*p == ' ') {
+					looking_for_space = 0;
+					*p='\0';
+				}
+			} else {
+				if (*p != ' ') {
+					/* found another token */
+					octeon_boot_desc_ptr->argv[(octeon_boot_desc_ptr->argc)++] = argv;
+					looking_for_space = 1;
+				} else {
+					*p = '\0';
+				}
+			}
+			p++;
+			argv++;
+		}
+
+		buflen = (int)(p - kbuf);
+		kexec_args[0] = octeon_boot_desc_ptr->argc;
+	}
+
+	/* now copy the modified cmdline buffer back to userspace */
+	copy_to_user(userbuf, kbuf, buflen);
+
+	if (kbuf)
+		kfree(kbuf);
+
+	/* setup the rest of the args */
+	kexec_args[2] = 1;
+	kexec_args[3] = (unsigned long)octeon_boot_desc_ptr;
+
+#ifdef CONFIG_SMP
+	/* copy the kexec_args to the secondary_args for the secondary
+	 * CPUs
+	 */
+	secondary_kexec_args[0] = kexec_args[0];
+	secondary_kexec_args[1] = kexec_args[1];
+	secondary_kexec_args[2] = 0; /* this is NOT the init core */
+	secondary_kexec_args[3] = kexec_args[3];
+#endif /* CONFIG_SMP */
+
+	return 0;
+}
+
+/*
+ * Perform any setup actions necessary to setup this unit for kexec
+ * Currently this primarily means registering the cavium-specific targets
+ * for the kexec functions
+ */
+void octeon_kexec_setup(void)
+{
+	_machine_kexec_shutdown = &octeon_kexec_shutdown;
+	_machine_kexec_prepare = &octeon_kexec_prepare;
+	_machine_crash_shutdown = &octeon_crash_shutdown;
+}
+#endif /* CONFIG_KEXEC */
+
+#ifdef CONFIG_CRASH_DUMP
+void octeon_crash_dump_setup(void)
+{
+	_machine_check_pfn_validity = octeon_check_pfn_validity;
+}
+#endif
+
diff --git a/arch/mips/cavium-octeon/hal.h b/arch/mips/cavium-octeon/hal.h
new file mode 100644
index 0000000..f4ecbf2
--- /dev/null
+++ b/arch/mips/cavium-octeon/hal.h
@@ -0,0 +1,155 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2007 Cavium Networks
+ */
+#ifndef __CAVIUM_OCTEON_HAL_H
+#define __CAVIUM_OCTEON_HAL_H
+
+#include "octeon-hal-read-write.h"
+
+#ifndef __BYTE_ORDER
+#  error "__BYTE_ORDER not set"
+#endif
+#ifndef __BIG_ENDIAN
+#  error "__BIG_ENDIAN not set"
+#endif
+
+extern uint64_t octeon_bootmem_alloc_range_phys(uint64_t size,
+						uint64_t alignment,
+						uint64_t min_addr,
+						uint64_t max_addr,
+						int do_locking);
+extern void *octeon_bootmem_alloc(uint64_t size, uint64_t alignment,
+				  int do_locking);
+extern void *octeon_bootmem_alloc_range(uint64_t size, uint64_t alignment,
+					uint64_t min_addr, uint64_t max_addr,
+					int do_locking);
+extern void *octeon_bootmem_alloc_named(uint64_t size, uint64_t alignment,
+					char *name);
+extern void *octeon_bootmem_alloc_named_range(uint64_t size, uint64_t min_addr,
+					      uint64_t max_addr, uint64_t align,
+					      char *name);
+extern void *octeon_bootmem_alloc_named_address(uint64_t size, uint64_t address,
+						char *name);
+extern int octeon_bootmem_free_named(char *name);
+extern void octeon_bootmem_lock(void);
+extern void octeon_bootmem_unlock(void);
+
+extern int octeon_is_simulation(void);
+extern int octeon_is_pci_host(void);
+extern uint64_t octeon_get_clock_rate(void);
+extern const char *octeon_board_type_string(void);
+extern const char *octeon_get_pci_interrupts(void);
+extern int octeon_get_southbridge_interrupt(void);
+extern int octeon_get_boot_coremask(void);
+extern int octeon_get_boot_num_arguments(void);
+extern const char *octeon_get_boot_argument(int arg);
+extern void octeon_hal_setup_reserved32(void);
+extern unsigned long octeon_crypto_enable(struct octeon_cop2_state *state);
+extern void octeon_crypto_disable(struct octeon_cop2_state *state, unsigned long flags);
+
+typedef union {
+	uint64_t u64;
+	struct {
+		uint64_t tlbbist:1;	    /**< RO 1 = BIST fail, 0 = BIST pass */
+		uint64_t l1cbist:1;	    /**< RO 1 = BIST fail, 0 = BIST pass */
+		uint64_t l1dbist:1;	    /**< RO 1 = BIST fail, 0 = BIST pass */
+		uint64_t dcmbist:1;	    /**< RO 1 = BIST fail, 0 = BIST pass */
+		uint64_t ptgbist:1;	    /**< RO 1 = BIST fail, 0 = BIST pass */
+		uint64_t wbfbist:1;	    /**< RO 1 = BIST fail, 0 = BIST pass */
+		uint64_t reserved:22;	    /**< Reserved */
+		uint64_t dismarkwblongto:1; /**< R/W If set, marked write-buffer entries time out the same as
+						as other entries; if clear, marked write-buffer entries use the
+						maximum timeout. */
+		uint64_t dismrgclrwbto:1;   /**< R/W If set, a merged store does not clear the write-buffer entry
+						timeout state. */
+		uint64_t iobdmascrmsb:2;    /**< R/W Two bits that are the MSBs of the resultant CVMSEG LM word
+						location for an IOBDMA. The other 8 bits come from the SCRADDR
+						field of the IOBDMA. */
+		uint64_t syncwsmarked:1;    /**< R/W If set, SYNCWS and SYNCS only order marked stores; if clear,
+						SYNCWS and SYNCS only order unmarked stores. SYNCWSMARKED has no
+						effect when DISSYNCWS is set. */
+		uint64_t dissyncws:1;	    /**< R/W If set, SYNCWS acts as SYNCW and SYNCS acts as SYNC. */
+		uint64_t diswbfst:1;	    /**< R/W If set, no stall happens on write buffer full. */
+		uint64_t xkmemenas:1;	    /**< R/W If set (and SX set), supervisor-level loads/stores can use
+						XKPHYS addresses with VA<48>==0 */
+		uint64_t xkmemenau:1;	    /**< R/W If set (and UX set), user-level loads/stores can use XKPHYS
+						addresses with VA<48>==0 */
+		uint64_t xkioenas:1;	    /**< R/W If set (and SX set), supervisor-level loads/stores can use
+						XKPHYS addresses with VA<48>==1 */
+		uint64_t xkioenau:1;	    /**< R/W If set (and UX set), user-level loads/stores can use XKPHYS
+						addresses with VA<48>==1 */
+		uint64_t allsyncw:1;	    /**< R/W If set, all stores act as SYNCW (NOMERGE must be set when
+						this is set) RW, reset to 0. */
+		uint64_t nomerge:1;	    /**< R/W If set, no stores merge, and all stores reach the coherent
+						bus in order. */
+		uint64_t didtto:2;	    /**< R/W Selects the bit in the counter used for DID time-outs
+						0 = 231, 1 = 230, 2 = 229, 3 = 214. Actual time-out is between
+						1 and 2 this interval. For example, with DIDTTO=3, expiration
+						interval is between 16K and 32K. */
+		uint64_t csrckalwys:1;	    /**< R/W If set, the (mem) CSR clock never turns off. */
+		uint64_t mclkalwys:1;	    /**< R/W If set, mclk never turns off. */
+		uint64_t wbfltime:3;	    /**< R/W Selects the bit in the counter used for write buffer flush
+						time-outs (WBFLT+11) is the bit position in an internal counter
+						used to determine expiration. The write buffer expires between
+						1 and 2 this interval. For example, with WBFLT = 0, a write
+						buffer expires between 2K and 4K cycles after the write buffer
+						entry is allocated. */
+		uint64_t istrnol2:1;	    /**< R/W If set, do not put Istream in the L2 cache. */
+		uint64_t wbthresh:4;	    /**< R/W The write buffer threshold. */
+		uint64_t reserved2:2;	    /**< Reserved */
+		uint64_t cvmsegenak:1;	    /**< R/W If set, CVMSEG is available for loads/stores in kernel/debug mode. */
+		uint64_t cvmsegenas:1;	    /**< R/W If set, CVMSEG is available for loads/stores in supervisor mode. */
+		uint64_t cvmsegenau:1;	    /**< R/W If set, CVMSEG is available for loads/stores in user mode. */
+		uint64_t lmemsz:6;	    /**< R/W Size of local memory in cache blocks, 54 (6912 bytes) is max legal value. */
+	} s;
+} octeon_cvmemctl_t;
+
+struct octeon_cf_data {
+	unsigned long	base_region_bias;
+	unsigned int	base_region;	/* The chip select region used by CF */
+	int		is16bit;	/* 0 - 8bit, !0 - 16bit */
+	int		dma_engine;	/* -1 for no DMA */
+};
+
+static inline void octeon_led_write(int bank, uint32_t data)
+{
+	cvmx_write_csr(CVMX_LED_UDD_DATX(bank), data);
+}
+
+static inline uint32_t octeon_led_read(int bank)
+{
+	return cvmx_read_csr(CVMX_LED_UDD_DATX(bank));
+}
+
+static inline void octeon_led_set(int bank, int bit)
+{
+	cvmx_write_csr(CVMX_LED_UDD_DAT_SETX(bank), 1 << bit);
+}
+
+static inline void octeon_led_clear(int bank, int bit)
+{
+	cvmx_write_csr(CVMX_LED_UDD_DAT_CLRX(bank), 1 << bit);
+}
+
+extern void octeon_write_lcd(const char *s);
+extern void octeon_check_cpu_bist(void);
+extern void octeon_hal_init(void);
+extern int octeon_get_boot_uart(void);
+extern int octeon_get_boot_debug_flag(void);
+extern void octeon_poweroff(void);
+extern void octeon_shutdown_network_hw(void);
+#ifdef CONFIG_KEXEC
+extern void octeon_kexec_shutdown(void);
+extern void octeon_kexec_setup(void);
+#endif
+#ifdef CONFIG_CRASH_DUMP
+void octeon_crash_dump_setup(void);
+#endif
+
+extern cvmx_bootinfo_t *octeon_bootinfo;
+
+#endif
diff --git a/arch/mips/cavium-octeon/i8259.c b/arch/mips/cavium-octeon/i8259.c
new file mode 100644
index 0000000..1b01b96
--- /dev/null
+++ b/arch/mips/cavium-octeon/i8259.c
@@ -0,0 +1,175 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2006-2007 Cavium Networks
+ */
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <linux/interrupt.h>
+#include "hal.h"
+
+#define SLAVE           (0xa0 - 0x20)
+
+/* Initialization Command Word 1 (ICW1 address 0x20 or 0xa0) */
+/* 7:5 Interrupt Vector Addresses for MCS-80/85 Mode. */
+#define ICW1_ADDRESS    0x20
+#define ICW1            0x10	/* 4 Must be set to 1 for ICW1 */
+#define ICW1_LEVEL_TRIG (1<<3)	/* 3 1 Level Triggered Interrupts, 0 Edge
+				   Triggered Interrupts */
+#define ICW1_INTERVAL4  (1<<2)	/* 2 1 Call Address Interval of 4, 0 Call
+				   Address Interval of 8 */
+#define ICW1_SINGLE_PIC (1<<1)	/* 1 1 Single PIC, 0 Cascaded PICs */
+#define ICW1_NEED_ICW4  (1<<0)	/* 0 1 Will be Sending ICW4,
+				   0 Don't need ICW4 */
+
+/* Initialization Command Word 2 (ICW2 address 0x21 or 0xa1) */
+#define ICW2_ADDRESS    0x21
+/* Bit 8086/8080 Mode MCS 80/85 Mode 7 I7 A15 6 I6 A14 5 I5 A13 4 I4 A12 3 I3
+   A11 2 - A10 1 - A9 0 - A8 */
+
+/* Initialization Command Word 3 (ICW3 address 0x21 or 0xa1) For the master,
+   this is a bitfield saying which line is hooked to a slave. For a slave, this
+   is the slave's ID, the line it is hooked to */
+#define ICW3_ADDRESS    0x21
+
+/* Initialization Command Word 4 (ICW4 address 0x21 or 0xa1) */
+/* Bits 7-5 are reserved */
+#define ICW4_ADDRESS        0x21
+#define ICW4_FULLY_NESTED   (1<<4)	/* 4 1 Special Fully Nested Mode, 0 Not
+					   Special Fully Nested Mode */
+#define ICW4_BUFFERED       (3<<2)	/* 3 1 Buffered Mode, 0 Unbuffered */
+#define ICW4_MASTER         (2<<2)	/* 2 1 Master, 0 Slave */
+#define ICW4_AUTO_EOI       (1<<1)	/* 1 1 Auto EOI, 0 Normal EOI */
+#define ICW4_8086           (1<<0)	/* 0 1 8086/8080 Mode, 0 MCS-80/85 */
+
+/* Operation Control Word 1 (OCW1 address 0x21 or 0xa1) This is a bitmask for
+   each interrupt */
+#define OCW1_ADDRESS    0x21
+
+/* Operation Control Word 2 (OCW2 address 0x20 or 0xa0) */
+#define OCW2_ADDRESS    0x20
+#define OCW2            0x00	/* Bits 4:3 must be zero */
+#define OCW2_ROTATE_AUTO_EOI_CLEAR  (0<<5)	/* 7:5 000 Rotate in Auto EOI
+						   Mode (Clear) */
+#define OCW2_NON_SPECIFIC_EOI       (1<<5)	/* 001 Non Specific EOI */
+#define OCW2_NOP                    (2<<5)	/* 010 NOP */
+#define OCW2_SPECIFIC_EOI           (3<<5)	/* 011 Specific EOI */
+#define OCW2_ROTATE_AUTO_EOI_SET    (4<<5)	/* 100 Rotate in Auto EOI Mode
+						   (Set) */
+#define OCW2_ROTATE_NON_SPECIFIC_EOI (5<<5)	/* 101 Rotate on Non-Specific
+						   EOI */
+#define OCW2_SET_PRIORITY           (6<<5)	/* 110 Set Priority Command
+						   (Use Bits 2:0) */
+#define OCW2_ROTATE_SPECIFIC_EOI    (7<<5)	/* 111 Rotate on Specific EOI
+						   (Use Bits 2:0) */
+
+/* Operation Control Word 3 (OCW3 address 0x20 or 0xa0) */
+/* Bit 7 Must be set to 0 */
+#define OCW3_ADDRESS    0x20
+#define OCW3            0x08	/* 4:3 Must be set to 01 */
+#define OCW3_RESET_SPECIAL_MASK (2<<5)	/* 6:5 00 Reserved, 01 Reserved, 10
+					   Reset Special Mask */
+#define OCW3_SET_SPECIAL_MASK   (3<<5)	/* 11 Set Special Mask */
+#define OCW3_POLL               (1<<2)	/* 2 1 Poll Command,
+					   0 No Poll Command */
+#define OCW3_READ_IRR           (2<<0)	/* 1:0 00 Reserved, 01 Reserved, 10
+					   Next Read Returns Interrupt Request
+					   Register */
+#define OCW3_READ_ISR           (3<<0)	/* 11 Next Read Returns In-Service
+					   Register */
+
+
+static irqreturn_t octeon_i8259_interrupt(int cpl, void *dev_id)
+{
+	u8 master_isr;
+	u8 slave_isr;
+
+	outb(OCW3 | OCW3_POLL, OCW3_ADDRESS);
+	master_isr = inb(OCW3_ADDRESS);
+	if (master_isr & 0x80) {	/* Top bit is set if the master
+					   requested the interrupt */
+		if ((master_isr & 0x7) == 2) {
+			outb(OCW3 | OCW3_POLL, OCW3_ADDRESS + SLAVE);
+			slave_isr = inb(OCW3_ADDRESS + SLAVE);
+			if (slave_isr & 0x80) {	/* Top bit is set if the slave
+						   requested the interrupt */
+				int irq = (slave_isr & 7) + OCTEON_IRQ_I8259S0;
+				/*
+				pr_debug("8259: Interrupt %d from slave\n", irq);
+				*/
+				if (irq_desc[irq].action)
+					do_IRQ(irq);
+
+				/* Ack the slave */
+				outb(OCW2 | OCW2_SPECIFIC_EOI | (slave_isr & 7),
+				     OCW2_ADDRESS + SLAVE);
+			} else
+				pr_err("8259: Spurious interrupt from master for slave\n");
+		} else {
+			int irq = (master_isr & 7) + OCTEON_IRQ_I8259M0;
+			/*
+			pr_debug("8259: Interrupt %d from master\n", irq);
+			*/
+			if (irq_desc[irq].action)
+				do_IRQ(irq);
+		}
+
+		/* Ack the master */
+		outb(OCW2 | OCW2_SPECIFIC_EOI | (master_isr & 7), OCW2_ADDRESS);
+
+		return IRQ_HANDLED;
+	} else {
+		pr_err("8259: Spurious interrupt from master\n");
+		return IRQ_NONE;
+	}
+}
+
+void octeon_i8259_setup(int irq_line)
+{
+	/* Setup the Master 8259 */
+	outb(ICW1 | ICW1_NEED_ICW4, ICW1_ADDRESS);	/* Begin the init
+							   sequence */
+	outb(0, ICW2_ADDRESS);	/* Master base address is zero, interrupts 0-7 */
+	outb(1 << 2, ICW3_ADDRESS);	/* Slave is connected to line 2 */
+	/* Set the mode to buffered with edge triggering */
+	outb(ICW4_FULLY_NESTED | ICW4_MASTER | ICW4_BUFFERED | ICW4_8086, ICW4_ADDRESS);
+	outb(OCW3 | OCW3_READ_ISR, OCW3_ADDRESS);	/* Read ISR */
+
+	/* Setup the Slave 8259 */
+	outb(ICW1 | ICW1_NEED_ICW4, ICW1_ADDRESS + SLAVE);	/* Begin the
+								   init
+								   sequence */
+	outb(8, ICW2_ADDRESS + SLAVE);	/* Slave base address is 8, interrupts
+					   8-15 */
+	outb(2, ICW3_ADDRESS + SLAVE);	/* Slave is connected to line 2 */
+	outb(ICW4_BUFFERED | ICW4_8086, ICW4_ADDRESS + SLAVE);	/* Set the mode
+								   to buffered
+								   with edge
+								   triggering */
+	outb(OCW3 | OCW3_READ_ISR, OCW3_ADDRESS + SLAVE);	/* Read ISR */
+
+	/* Set interrupt mask to disable all interrupts */
+	outb(0xfb, OCW1_ADDRESS);
+	outb(0xff, OCW1_ADDRESS + SLAVE);
+
+	/* Setup the GPIO pin if the interrupt is hooked to it */
+	if ((irq_line >= 24) && (irq_line <= 39)) {
+		pr_notice("8259: Setting GPIO %d for the interrupt\n",
+			  irq_line - 24);
+		cvmx_write_csr(CVMX_GPIO_BIT_CFGX(irq_line - 24), 0x114);
+		if (request_irq(irq_line, octeon_i8259_interrupt, IRQF_SHARED,
+				"8259", octeon_i8259_interrupt)) {
+		}
+	} else if ((irq_line >= 44) && (irq_line <= 47)) {
+		pr_notice("8259: Using PCI INT-%c\n", irq_line - 44 + 'A');
+		if (request_irq(irq_line, octeon_i8259_interrupt, IRQF_SHARED,
+				"8259", octeon_i8259_interrupt)) {
+		}
+	} else {
+		panic("8259: Don't know how to setup the interrupt IRQ %d\n",
+		      irq_line);
+	}
+}
diff --git a/arch/mips/cavium-octeon/irq.c b/arch/mips/cavium-octeon/irq.c
new file mode 100644
index 0000000..0e1f5e1
--- /dev/null
+++ b/arch/mips/cavium-octeon/irq.c
@@ -0,0 +1,61 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2008 Cavium Networks
+ */
+#include "linux/irq.h"
+#include "linux/hardirq.h"
+#include "linux/kernel_stat.h"
+#include "hal.h"
+
+asmlinkage void plat_irq_dispatch(void)
+{
+	const unsigned long core_id = cvmx_get_core_num();
+	const uint64_t ciu_sum0_address = CVMX_CIU_INTX_SUM0(core_id * 2);
+	const uint64_t ciu_en0_address = CVMX_CIU_INTX_EN0(core_id * 2);
+	const uint64_t ciu_sum1_address = CVMX_CIU_INT_SUM1;
+	const uint64_t ciu_en1_address = CVMX_CIU_INTX_EN1(core_id * 2 + 1);
+	unsigned long cop0_cause;
+	unsigned long cop0_status;
+	uint64_t ciu_en;
+	uint64_t ciu_sum;
+
+	while (1) {
+		cop0_cause = read_c0_cause();
+		cop0_status = read_c0_status();
+		cop0_cause &= cop0_status;
+		cop0_cause &= ST0_IM;
+
+		if (unlikely(cop0_cause & STATUSF_IP2)) {
+			asm volatile ("ld	%[sum], 0(%[sum_address])\n"
+				      "ld	%[en], 0(%[en_address])\n" :
+				      [sum] "=r"(ciu_sum),
+				      [en] "=r"(ciu_en) :
+				      [sum_address] "r"(ciu_sum0_address),
+				      [en_address] "r"(ciu_en0_address));
+			ciu_sum &= ciu_en;
+			if (likely(ciu_sum))
+				do_IRQ(fls64(ciu_sum) + OCTEON_IRQ_WORKQ0 - 1);
+			else
+				spurious_interrupt();
+		} else if (unlikely(cop0_cause & STATUSF_IP3)) {
+			asm volatile ("ld	%[sum], 0(%[sum_address])\n"
+				      "ld	%[en], 0(%[en_address])\n" :
+				      [sum] "=r"(ciu_sum),
+				      [en] "=r"(ciu_en) :
+				      [sum_address] "r"(ciu_sum1_address),
+				      [en_address] "r"(ciu_en1_address));
+			ciu_sum &= ciu_en;
+			if (likely(ciu_sum))
+				do_IRQ(fls64(ciu_sum) + OCTEON_IRQ_WDOG0 - 1);
+			else
+				spurious_interrupt();
+		} else if (likely(cop0_cause)) {
+			do_IRQ(fls(cop0_cause) - 9);
+		} else {
+			break;
+		}
+	}
+}
diff --git a/arch/mips/cavium-octeon/octeon-memcpy.S b/arch/mips/cavium-octeon/octeon-memcpy.S
new file mode 100644
index 0000000..e083d5c
--- /dev/null
+++ b/arch/mips/cavium-octeon/octeon-memcpy.S
@@ -0,0 +1,521 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Unified implementation of memcpy, memmove and the __copy_user backend.
+ *
+ * Copyright (C) 1998, 99, 2000, 01, 2002 Ralf Baechle (ralf@gnu.org)
+ * Copyright (C) 1999, 2000, 01, 2002 Silicon Graphics, Inc.
+ * Copyright (C) 2002 Broadcom, Inc.
+ *   memcpy/copy_user author: Mark Vandevoorde
+ *
+ * Mnemonic names for arguments to memcpy/__copy_user
+ */
+
+#include <asm/asm.h>
+#include <asm/asm-offsets.h>
+#include <asm/regdef.h>
+
+#define dst a0
+#define src a1
+#define len a2
+
+/*
+ * Spec
+ *
+ * memcpy copies len bytes from src to dst and sets v0 to dst.
+ * It assumes that
+ *   - src and dst don't overlap
+ *   - src is readable
+ *   - dst is writable
+ * memcpy uses the standard calling convention
+ *
+ * __copy_user copies up to len bytes from src to dst and sets a2 (len) to
+ * the number of uncopied bytes due to an exception caused by a read or write.
+ * __copy_user assumes that src and dst don't overlap, and that the call is
+ * implementing one of the following:
+ *   copy_to_user
+ *     - src is readable  (no exceptions when reading src)
+ *   copy_from_user
+ *     - dst is writable  (no exceptions when writing dst)
+ * __copy_user uses a non-standard calling convention; see
+ * include/asm-mips/uaccess.h
+ *
+ * When an exception happens on a load, the handler must
+ # ensure that all of the destination buffer is overwritten to prevent
+ * leaking information to user mode programs.
+ */
+
+/*
+ * Implementation
+ */
+
+/*
+ * The exception handler for loads requires that:
+ *  1- AT contain the address of the byte just past the end of the source
+ *     of the copy,
+ *  2- src_entry <= src < AT, and
+ *  3- (dst - src) == (dst_entry - src_entry),
+ * The _entry suffix denotes values when __copy_user was called.
+ *
+ * (1) is set up up by uaccess.h and maintained by not writing AT in copy_user
+ * (2) is met by incrementing src by the number of bytes copied
+ * (3) is met by not doing loads between a pair of increments of dst and src
+ *
+ * The exception handlers for stores adjust len (if necessary) and return.
+ * These handlers do not need to overwrite any data.
+ *
+ * For __rmemcpy and memmove an exception is always a kernel bug, therefore
+ * they're not protected.
+ */
+
+#define EXC(inst_reg,addr,handler)		\
+9:	inst_reg, addr;				\
+	.section __ex_table,"a";		\
+	PTR	9b, handler;			\
+	.previous
+
+/*
+ * Only on the 64-bit kernel we can made use of 64-bit registers.
+ */
+#ifdef CONFIG_64BIT
+#define USE_DOUBLE
+#endif
+
+#ifdef USE_DOUBLE
+
+#define LOAD   ld
+#define LOADL  ldl
+#define LOADR  ldr
+#define STOREL sdl
+#define STORER sdr
+#define STORE  sd
+#define ADD    daddu
+#define SUB    dsubu
+#define SRL    dsrl
+#define SRA    dsra
+#define SLL    dsll
+#define SLLV   dsllv
+#define SRLV   dsrlv
+#define NBYTES 8
+#define LOG_NBYTES 3
+
+/*
+ * As we are sharing code base with the mips32 tree (which use the o32 ABI
+ * register definitions). We need to redefine the register definitions from
+ * the n64 ABI register naming to the o32 ABI register naming.
+ */
+#undef t0
+#undef t1
+#undef t2
+#undef t3
+#define t0	$8
+#define t1	$9
+#define t2	$10
+#define t3	$11
+#define t4	$12
+#define t5	$13
+#define t6	$14
+#define t7	$15
+
+#else
+
+#define LOAD   lw
+#define LOADL  lwl
+#define LOADR  lwr
+#define STOREL swl
+#define STORER swr
+#define STORE  sw
+#define ADD    addu
+#define SUB    subu
+#define SRL    srl
+#define SLL    sll
+#define SRA    sra
+#define SLLV   sllv
+#define SRLV   srlv
+#define NBYTES 4
+#define LOG_NBYTES 2
+
+#endif /* USE_DOUBLE */
+
+#ifdef CONFIG_CPU_LITTLE_ENDIAN
+#define LDFIRST LOADR
+#define LDREST  LOADL
+#define STFIRST STORER
+#define STREST  STOREL
+#define SHIFT_DISCARD SLLV
+#else
+#define LDFIRST LOADL
+#define LDREST  LOADR
+#define STFIRST STOREL
+#define STREST  STORER
+#define SHIFT_DISCARD SRLV
+#endif
+
+#define FIRST(unit) ((unit)*NBYTES)
+#define REST(unit)  (FIRST(unit)+NBYTES-1)
+#define UNIT(unit)  FIRST(unit)
+
+#define ADDRMASK (NBYTES-1)
+
+	.text
+	.set	noreorder
+	.set	noat
+
+/*
+ * A combined memcpy/__copy_user
+ * __copy_user sets len to 0 for success; else to an upper bound of
+ * the number of uncopied bytes.
+ * memcpy sets v0 to dst.
+ */
+	.align	5
+LEAF(memcpy)					/* a0=dst a1=src a2=len */
+	move	v0, dst				/* return value */
+__memcpy:
+FEXPORT(__copy_user)
+	/*
+	 * Note: dst & src may be unaligned, len may be 0
+	 * Temps
+	 */
+	#
+	# Octeon doesn't care if the destination is unaligned. The hardware
+	# can fix it faster than we can special case the assembly.
+	#
+	pref	0, 0(src)
+	sltu	t0, len, NBYTES		# Check if < 1 word
+	bnez	t0, copy_bytes_checklen
+	 and	t0, src, ADDRMASK	# Check if src unaligned
+	bnez	t0, src_unaligned
+	 sltu	t0, len, 4*NBYTES	# Check if < 4 words
+	bnez	t0, less_than_4units
+	 sltu	t0, len, 8*NBYTES	# Check if < 8 words
+	bnez	t0, less_than_8units
+	 sltu	t0, len, 16*NBYTES	# Check if < 16 words
+	bnez	t0, cleanup_both_aligned
+	 sltu	t0, len, 128+1		# Check if len < 129
+	bnez	t0, 1f			# Skip prefetch if len is too short
+	 sltu	t0, len, 256+1		# Check if len < 257
+	bnez	t0, 1f			# Skip prefetch if len is too short
+	 pref	0, 128(src)		# We must not prefetch invalid addresses
+	#
+	# This is where we loop if there is more than 128 bytes left
+2:	pref	0, 256(src)		# We must not prefetch invalid addresses
+	#
+	# This is where we loop if we can't prefetch anymore
+1:
+EXC(	LOAD	t0, UNIT(0)(src),	l_exc)
+EXC(	LOAD	t1, UNIT(1)(src),	l_exc_copy)
+EXC(	LOAD	t2, UNIT(2)(src),	l_exc_copy)
+EXC(	LOAD	t3, UNIT(3)(src),	l_exc_copy)
+	SUB	len, len, 16*NBYTES
+EXC(	STORE	t0, UNIT(0)(dst),	s_exc_p16u)
+EXC(	STORE	t1, UNIT(1)(dst),	s_exc_p15u)
+EXC(	STORE	t2, UNIT(2)(dst),	s_exc_p14u)
+EXC(	STORE	t3, UNIT(3)(dst),	s_exc_p13u)
+EXC(	LOAD	t0, UNIT(4)(src),	l_exc_copy)
+EXC(	LOAD	t1, UNIT(5)(src),	l_exc_copy)
+EXC(	LOAD	t2, UNIT(6)(src),	l_exc_copy)
+EXC(	LOAD	t3, UNIT(7)(src),	l_exc_copy)
+EXC(	STORE	t0, UNIT(4)(dst),	s_exc_p12u)
+EXC(	STORE	t1, UNIT(5)(dst),	s_exc_p11u)
+EXC(	STORE	t2, UNIT(6)(dst),	s_exc_p10u)
+	ADD	src, src, 16*NBYTES
+EXC(	STORE	t3, UNIT(7)(dst),	s_exc_p9u)
+	ADD	dst, dst, 16*NBYTES
+EXC(	LOAD	t0, UNIT(-8)(src),	l_exc_copy)
+EXC(	LOAD	t1, UNIT(-7)(src),	l_exc_copy)
+EXC(	LOAD	t2, UNIT(-6)(src),	l_exc_copy)
+EXC(	LOAD	t3, UNIT(-5)(src),	l_exc_copy)
+EXC(	STORE	t0, UNIT(-8)(dst),	s_exc_p8u)
+EXC(	STORE	t1, UNIT(-7)(dst),	s_exc_p7u)
+EXC(	STORE	t2, UNIT(-6)(dst),	s_exc_p6u)
+EXC(	STORE	t3, UNIT(-5)(dst),	s_exc_p5u)
+EXC(	LOAD	t0, UNIT(-4)(src),	l_exc_copy)
+EXC(	LOAD	t1, UNIT(-3)(src),	l_exc_copy)
+EXC(	LOAD	t2, UNIT(-2)(src),	l_exc_copy)
+EXC(	LOAD	t3, UNIT(-1)(src),	l_exc_copy)
+EXC(	STORE	t0, UNIT(-4)(dst),	s_exc_p4u)
+EXC(	STORE	t1, UNIT(-3)(dst),	s_exc_p3u)
+EXC(	STORE	t2, UNIT(-2)(dst),	s_exc_p2u)
+EXC(	STORE	t3, UNIT(-1)(dst),	s_exc_p1u)
+	sltu	t0, len, 256+1		# See if we can prefetch more
+	beqz	t0, 2b
+	 sltu	t0, len, 128		# See if we can loop more time
+	beqz	t0, 1b
+	 nop
+	#
+	# Jump here if there are less than 16*NBYTES left.
+	#
+cleanup_both_aligned:
+	beqz	len, done
+	 sltu	t0, len, 8*NBYTES
+	bnez	t0, less_than_8units
+	 nop
+EXC(	LOAD	t0, UNIT(0)(src),	l_exc)
+EXC(	LOAD	t1, UNIT(1)(src),	l_exc_copy)
+EXC(	LOAD	t2, UNIT(2)(src),	l_exc_copy)
+EXC(	LOAD	t3, UNIT(3)(src),	l_exc_copy)
+	SUB	len, len, 8*NBYTES
+EXC(	STORE	t0, UNIT(0)(dst),	s_exc_p8u)
+EXC(	STORE	t1, UNIT(1)(dst),	s_exc_p7u)
+EXC(	STORE	t2, UNIT(2)(dst),	s_exc_p6u)
+EXC(	STORE	t3, UNIT(3)(dst),	s_exc_p5u)
+EXC(	LOAD	t0, UNIT(4)(src),	l_exc_copy)
+EXC(	LOAD	t1, UNIT(5)(src),	l_exc_copy)
+EXC(	LOAD	t2, UNIT(6)(src),	l_exc_copy)
+EXC(	LOAD	t3, UNIT(7)(src),	l_exc_copy)
+EXC(	STORE	t0, UNIT(4)(dst),	s_exc_p4u)
+EXC(	STORE	t1, UNIT(5)(dst),	s_exc_p3u)
+EXC(	STORE	t2, UNIT(6)(dst),	s_exc_p2u)
+EXC(	STORE	t3, UNIT(7)(dst),	s_exc_p1u)
+	ADD	src, src, 8*NBYTES
+	beqz	len, done
+	 ADD	dst, dst, 8*NBYTES
+	#
+	# Jump here if there are less than 8*NBYTES left.
+	#
+less_than_8units:
+	sltu	t0, len, 4*NBYTES
+	bnez	t0, less_than_4units
+	 nop
+EXC(	LOAD	t0, UNIT(0)(src),	l_exc)
+EXC(	LOAD	t1, UNIT(1)(src),	l_exc_copy)
+EXC(	LOAD	t2, UNIT(2)(src),	l_exc_copy)
+EXC(	LOAD	t3, UNIT(3)(src),	l_exc_copy)
+	SUB	len, len, 4*NBYTES
+EXC(	STORE	t0, UNIT(0)(dst),	s_exc_p4u)
+EXC(	STORE	t1, UNIT(1)(dst),	s_exc_p3u)
+EXC(	STORE	t2, UNIT(2)(dst),	s_exc_p2u)
+EXC(	STORE	t3, UNIT(3)(dst),	s_exc_p1u)
+	ADD	src, src, 4*NBYTES
+	beqz	len, done
+	 ADD	dst, dst, 4*NBYTES
+	#
+	# Jump here if there are less than 4*NBYTES left. This means
+	# we may need to copy up to 3 NBYTES words.
+	#
+less_than_4units:
+	sltu	t0, len, 1*NBYTES
+	bnez	t0, copy_bytes_checklen
+	 nop
+	#
+	# 1) Copy NBYTES, then check length again
+	#
+EXC(	LOAD	t0, 0(src),		l_exc)
+	SUB	len, len, NBYTES
+	sltu	t1, len, 8
+EXC(	STORE	t0, 0(dst),		s_exc_p1u)
+	ADD	src, src, NBYTES
+	bnez	t1, copy_bytes_checklen
+	 ADD	dst, dst, NBYTES
+	#
+	# 2) Copy NBYTES, then check length again
+	#
+EXC(	LOAD	t0, 0(src),		l_exc)
+	SUB	len, len, NBYTES
+	sltu	t1, len, 8
+EXC(	STORE	t0, 0(dst),		s_exc_p1u)
+	ADD	src, src, NBYTES
+	bnez	t1, copy_bytes_checklen
+	 ADD	dst, dst, NBYTES
+	#
+	# 3) Copy NBYTES, then check length again
+	#
+EXC(	LOAD	t0, 0(src),		l_exc)
+	SUB	len, len, NBYTES
+	ADD	src, src, NBYTES
+	ADD	dst, dst, NBYTES
+	b copy_bytes_checklen
+EXC(	 STORE	t0, -8(dst),		s_exc_p1u)
+
+src_unaligned:
+#define rem t8
+	SRL	t0, len, LOG_NBYTES+2    # +2 for 4 units/iter
+	beqz	t0, cleanup_src_unaligned
+	 and	rem, len, (4*NBYTES-1)   # rem = len % 4*NBYTES
+1:
+/*
+ * Avoid consecutive LD*'s to the same register since some mips
+ * implementations can't issue them in the same cycle.
+ * It's OK to load FIRST(N+1) before REST(N) because the two addresses
+ * are to the same unit (unless src is aligned, but it's not).
+ */
+EXC(	LDFIRST	t0, FIRST(0)(src),	l_exc)
+EXC(	LDFIRST	t1, FIRST(1)(src),	l_exc_copy)
+	SUB     len, len, 4*NBYTES
+EXC(	LDREST	t0, REST(0)(src),	l_exc_copy)
+EXC(	LDREST	t1, REST(1)(src),	l_exc_copy)
+EXC(	LDFIRST	t2, FIRST(2)(src),	l_exc_copy)
+EXC(	LDFIRST	t3, FIRST(3)(src),	l_exc_copy)
+EXC(	LDREST	t2, REST(2)(src),	l_exc_copy)
+EXC(	LDREST	t3, REST(3)(src),	l_exc_copy)
+	ADD	src, src, 4*NBYTES
+EXC(	STORE	t0, UNIT(0)(dst),	s_exc_p4u)
+EXC(	STORE	t1, UNIT(1)(dst),	s_exc_p3u)
+EXC(	STORE	t2, UNIT(2)(dst),	s_exc_p2u)
+EXC(	STORE	t3, UNIT(3)(dst),	s_exc_p1u)
+	bne	len, rem, 1b
+	 ADD	dst, dst, 4*NBYTES
+
+cleanup_src_unaligned:
+	beqz	len, done
+	 and	rem, len, NBYTES-1  # rem = len % NBYTES
+	beq	rem, len, copy_bytes
+	 nop
+1:
+EXC(	LDFIRST t0, FIRST(0)(src),	l_exc)
+EXC(	LDREST	t0, REST(0)(src),	l_exc_copy)
+	SUB	len, len, NBYTES
+EXC(	STORE	t0, 0(dst),		s_exc_p1u)
+	ADD	src, src, NBYTES
+	bne	len, rem, 1b
+	 ADD	dst, dst, NBYTES
+
+copy_bytes_checklen:
+	beqz	len, done
+	 nop
+copy_bytes:
+	/* 0 < len < NBYTES  */
+#define COPY_BYTE(N)			\
+EXC(	lb	t0, N(src), l_exc);	\
+	SUB	len, len, 1;		\
+	beqz	len, done;		\
+EXC(	 sb	t0, N(dst), s_exc_p1)
+
+	COPY_BYTE(0)
+	COPY_BYTE(1)
+#ifdef USE_DOUBLE
+	COPY_BYTE(2)
+	COPY_BYTE(3)
+	COPY_BYTE(4)
+	COPY_BYTE(5)
+#endif
+EXC(	lb	t0, NBYTES-2(src), l_exc)
+	SUB	len, len, 1
+	jr	ra
+EXC(	 sb	t0, NBYTES-2(dst), s_exc_p1)
+done:
+	jr	ra
+	 nop
+	END(memcpy)
+
+l_exc_copy:
+	/*
+	 * Copy bytes from src until faulting load address (or until a
+	 * lb faults)
+	 *
+	 * When reached by a faulting LDFIRST/LDREST, THREAD_BUADDR($28)
+	 * may be more than a byte beyond the last address.
+	 * Hence, the lb below may get an exception.
+	 *
+	 * Assumes src < THREAD_BUADDR($28)
+	 */
+	LOAD	t0, TI_TASK($28)
+	 nop
+	LOAD	t0, THREAD_BUADDR(t0)
+1:
+EXC(	lb	t1, 0(src),	l_exc)
+	ADD	src, src, 1
+	sb	t1, 0(dst)	# can't fault -- we're copy_from_user
+	bne	src, t0, 1b
+	 ADD	dst, dst, 1
+l_exc:
+	LOAD	t0, TI_TASK($28)
+	 nop
+	LOAD	t0, THREAD_BUADDR(t0)	# t0 is just past last good address
+	 nop
+	SUB	len, AT, t0		# len number of uncopied bytes
+	/*
+	 * Here's where we rely on src and dst being incremented in tandem,
+	 *   See (3) above.
+	 * dst += (fault addr - src) to put dst at first byte to clear
+	 */
+	ADD	dst, t0			# compute start address in a1
+	SUB	dst, src
+	/*
+	 * Clear len bytes starting at dst.  Can't call __bzero because it
+	 * might modify len.  An inefficient loop for these rare times...
+	 */
+	beqz	len, done
+	 SUB	src, len, 1
+1:	sb	zero, 0(dst)
+	ADD	dst, dst, 1
+	bnez	src, 1b
+	 SUB	src, src, 1
+	jr	ra
+	 nop
+
+
+#define SEXC(n)				\
+s_exc_p ## n ## u:			\
+	jr	ra;			\
+	 ADD	len, len, n*NBYTES
+
+SEXC(16)
+SEXC(15)
+SEXC(14)
+SEXC(13)
+SEXC(12)
+SEXC(11)
+SEXC(10)
+SEXC(9)
+SEXC(8)
+SEXC(7)
+SEXC(6)
+SEXC(5)
+SEXC(4)
+SEXC(3)
+SEXC(2)
+SEXC(1)
+
+s_exc_p1:
+	jr	ra
+	 ADD	len, len, 1
+s_exc:
+	jr	ra
+	 nop
+
+	.align	5
+LEAF(memmove)
+	ADD	t0, a0, a2
+	ADD	t1, a1, a2
+	sltu	t0, a1, t0			# dst + len <= src -> memcpy
+	sltu	t1, a0, t1			# dst >= src + len -> memcpy
+	and	t0, t1
+	beqz	t0, __memcpy
+	 move	v0, a0				/* return value */
+	beqz	a2, r_out
+	END(memmove)
+
+	/* fall through to __rmemcpy */
+LEAF(__rmemcpy)					/* a0=dst a1=src a2=len */
+	 sltu	t0, a1, a0
+	beqz	t0, r_end_bytes_up		# src >= dst
+	 nop
+	ADD	a0, a2				# dst = dst + len
+	ADD	a1, a2				# src = src + len
+
+r_end_bytes:
+	lb	t0, -1(a1)
+	SUB	a2, a2, 0x1
+	sb	t0, -1(a0)
+	SUB	a1, a1, 0x1
+	bnez	a2, r_end_bytes
+	 SUB	a0, a0, 0x1
+
+r_out:
+	jr	ra
+	 move	a2, zero
+
+r_end_bytes_up:
+	lb	t0, (a1)
+	SUB	a2, a2, 0x1
+	sb	t0, (a0)
+	ADD	a1, a1, 0x1
+	bnez	a2, r_end_bytes_up
+	 ADD	a0, a0, 0x1
+
+	jr	ra
+	 move	a2, zero
+	END(__rmemcpy)
diff --git a/arch/mips/cavium-octeon/octeon-platform.c b/arch/mips/cavium-octeon/octeon-platform.c
new file mode 100644
index 0000000..be686d9
--- /dev/null
+++ b/arch/mips/cavium-octeon/octeon-platform.c
@@ -0,0 +1,24 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2009 Cavium Networks
+ */
+
+#include <linux/init.h>
+#include <linux/i2c.h>
+
+
+static struct i2c_board_info __initdata octeon_i2c_devices[] = {
+	{
+		I2C_BOARD_INFO("ds1337", 0x68),
+	},
+};
+
+static int __init octeon_i2c_devices_init(void)
+{
+	return i2c_register_board_info(0, octeon_i2c_devices,
+				       ARRAY_SIZE(octeon_i2c_devices));
+}
+arch_initcall(octeon_i2c_devices_init);
diff --git a/arch/mips/cavium-octeon/octeon-tra.c b/arch/mips/cavium-octeon/octeon-tra.c
new file mode 100644
index 0000000..59eaead
--- /dev/null
+++ b/arch/mips/cavium-octeon/octeon-tra.c
@@ -0,0 +1,181 @@
+/*
+ *   Octeon TRA (trace buffer) driver
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2008 Cavium Networks
+ */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/interrupt.h>
+#include <asm/tlbdebug.h>
+#include "hal.h"
+#include "cvmx-tra.h"
+
+/* This define control whether every core is stopped to display its state
+   when a trace buffer interrupt occurs. Doing this could cause deadlock,
+   so it is off by default */
+#define OCTEON_TRA_DUMP_CORES_ON_INTERRUPT 0
+
+
+/**
+ * Called when OCTEON_TRA_DUMP_CORES_ON_INTERRUPT is set to
+ * dump the state of each core. Be careful what is put in here
+ * since the system might be in a broken state.
+ *
+ * @param unused
+ */
+static void octeon_tra_dump_regs(void *unused)
+{
+	static DEFINE_SPINLOCK(lock);
+	/* This lock is so the core output doesn't intermix with other cores */
+	spin_lock(&lock);
+	show_regs(get_irq_regs());
+	dump_tlb_all();
+	spin_unlock(&lock);
+}
+
+
+/**
+ * This function is called when the trace buffer hits a trigger
+ * or fills. We don't enable the fill interrupt, so it should
+ * only be on triggers.
+ *
+ * @param cpl    Interrupt number
+ * @param dev_id unused
+ *
+ * @return IRQ status, should always be IRQ_HANDLED
+ */
+static irqreturn_t octeon_tra_interrupt(int cpl, void *dev_id)
+{
+	/* Stop the trace buffer in case it is still running. A trigger
+	   should have already stopped it */
+	cvmx_tra_enable(0);
+	/* Clear the trace buffer interrupt status */
+	cvmx_write_csr(CVMX_TRA_INT_STATUS, cvmx_read_csr(CVMX_TRA_INT_STATUS));
+
+	/* We can optionally stop the other cores */
+	if (OCTEON_TRA_DUMP_CORES_ON_INTERRUPT) {
+		pr_info("Octeon Trace Buffer Dumping Core state\n");
+		on_each_cpu(octeon_tra_dump_regs, NULL, 1);
+	}
+
+	pr_info("Octeon Trace Buffer Start\n");
+	cvmx_tra_display();
+	pr_info("Octeon Trace Buffer End\n");
+
+	/* Restart the trace buffer */
+	cvmx_tra_enable(1);
+	return IRQ_HANDLED;
+}
+
+
+/**
+ * Module/ driver initialization.
+ *
+ * @return Zero on success
+ */
+static int __init octeon_tra_init(void)
+{
+	cvmx_tra_ctl_t control;
+	cvmx_tra_filt_cmd_t filter;
+	cvmx_tra_filt_sid_t source_filter;
+	cvmx_tra_filt_did_t dest_filter;
+	cvmx_tra_trig0_did_t trig0_did;
+	uint64_t address;
+	uint64_t address_mask;
+
+	/* If this chip doesn't have a TRA, silently do nothing */
+	if (!octeon_has_feature(OCTEON_FEATURE_TRA))
+		return 0;
+
+	control.u64 = 0;
+	control.s.ignore_o = 1; /* We interpret wrap as being allowed to overwrite data */
+	control.s.ciu_trg = 1;  /* Trigger a CIU interrupt when even happen */
+	control.s.full_thr = 2; /* 3/4 full threshhold, but we don't use this for anything */
+	control.s.time_grn = 1; /* Make timestamps very accurate */
+	control.s.trig_ctl = 3; /* Use both triggers as stops */
+	control.s.wrap = 1;     /* We don't want the TRA to stop when full */
+	control.s.ena = 0;      /* It has to be disabled during setup */
+
+	/* Setup the TRA filter to capture everything. The easiest way to do this
+	   is to set all bits except the reserved ones */
+	filter.u64 = -1;
+	filter.s.reserved_17_63 = 0;
+	source_filter.u64 = -1;
+	source_filter.s.reserved_20_63 = 0;
+	dest_filter.u64 = -1;
+	dest_filter.s.reserved_32_63 = 0;
+	cvmx_tra_setup(control, filter, source_filter, dest_filter, 0, 0);
+
+	/* Lets set the first trigger to match invalid accesses after the 2nd
+	   256MB. This is anything after 0x420000000. Since we can only really
+	   pick powers of two, we use the addressmask to ignore bits 63-35,33-30,
+	   and 28-0. If we were monitoring a lower address we couldn't ignore
+	   so many bits */
+	address = 0x420000000ull;
+	address_mask = 0x420000000ull;
+
+	/* Setup the trigger 0 to stop the TRA when a specific memory address
+	    matches */
+	filter.u64 = 0;
+	filter.s.saa = 1;       /* Atomic operations can change memory */
+	filter.s.iobdma = 0;    /* IO bus DMA accesses can't affect memory */
+	filter.s.iobst = 0;     /* IO bus stores (CSRs) can't affect memory */
+	filter.s.iobld64 = 0;   /* 64bit IO bus reads (CSRs) can't affect memory */
+	filter.s.iobld32 = 0;   /* 32bit IO bus reads (CSRs) can't affect memory */
+	filter.s.iobld16 = 0;   /* 16bit IO bus reads (CSRs) can't affect memory */
+	filter.s.iobld8 = 0;    /* 8bit IO bus reads (CSRs) can't affect memory */
+	filter.s.stt = 1;       /* Store full skipping L2 can change memory */
+	filter.s.stp = 1;       /* Store partial can change memory */
+	filter.s.stc = 1;       /* Store conditional can change memory */
+	filter.s.stf = 1;       /* Store full can change memory */
+	filter.s.ldt = 1;       /* Icache fills, skipping L2, may be of interest */
+	filter.s.ldi = 1;       /* Icache fills may be of interest */
+	filter.s.ldd = 1;       /* Dcache fills may be of interest */
+	filter.s.psl1 = 1;      /* Dcache fills, skipping L2, may be of interest */
+	filter.s.pl2 = 1;       /* Prefetch into L2 may be of interest */
+	filter.s.dwb = 1;       /* Don't write back can change memory */
+
+	/* Allow all destinations to match the trigger */
+	trig0_did.u64 = -1;
+	trig0_did.s.reserved_32_63 = 0;
+
+	cvmx_tra_trig_setup(0, filter, source_filter, trig0_did, address, address_mask);
+
+	/* Setup the 2nd trigger to match a different address. Lets try
+	    the region 0x400000000-0x40fffffff. Everything else is the same */
+	address = 0x400000000ull;
+	address_mask = 0xfffffffff0000000ull;
+	cvmx_tra_trig_setup(1, filter, source_filter, trig0_did, address, address_mask);
+
+	/* Hook up to the trace buffer interrupt so we know when a trigger happens */
+	if (request_irq(OCTEON_IRQ_TRACE, octeon_tra_interrupt, IRQF_SHARED,
+			"Trace buffer", octeon_tra_interrupt))
+		pr_err("Octeon TRA: failed to reserve TRACE IRQ\n");
+
+	/* All setup is complete. Enable the trace buffer */
+	cvmx_tra_enable(1);
+	pr_notice("Octeon TRA driver loaded.\n");
+	return 0;
+}
+
+
+/**
+ * Module / driver shutdown
+ */
+static void __exit octeon_tra_cleanup(void)
+{
+	if (!octeon_has_feature(OCTEON_FEATURE_TRA))
+		return;
+	cvmx_tra_enable(0);
+	free_irq(OCTEON_IRQ_TRACE, octeon_tra_interrupt);
+}
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Cavium Networks <support@caviumnetworks.com>");
+MODULE_DESCRIPTION("Cavium Networks Octeon TRA driver.");
+module_init(octeon_tra_init);
+module_exit(octeon_tra_cleanup);
diff --git a/arch/mips/cavium-octeon/octeon_boot.h b/arch/mips/cavium-octeon/octeon_boot.h
new file mode 100644
index 0000000..8cd28a4
--- /dev/null
+++ b/arch/mips/cavium-octeon/octeon_boot.h
@@ -0,0 +1,69 @@
+/*
+ * (C) Copyright 2004,2005
+ * Cavium Networks
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of
+ * the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston,
+ * MA 02111-1307 USA
+ */
+
+#ifndef __OCTEON_BOOT_H__
+#define __OCTEON_BOOT_H__
+
+struct boot_init_vector {
+	uint32_t stack_addr;
+	uint32_t code_addr;
+	uint32_t app_start_func_addr;
+	uint32_t k0_val;
+	uint32_t flags;
+	uint32_t boot_info_addr;
+	uint32_t pad;
+	uint32_t pad2;
+};
+
+/* similar to bootloader's linux_app_boot_info but without global data */
+struct linux_app_boot_info {
+	uint32_t labi_signature;
+	uint32_t start_core0_addr;
+	uint32_t avail_coremask;
+	uint32_t pci_console_active;
+	uint32_t icache_prefetch_disable;
+	uint32_t InitTLBStart_addr;
+	uint32_t start_app_addr;
+	uint32_t cur_exception_base;
+	uint32_t no_mark_private_data;
+	uint32_t compact_flash_common_base_addr;
+	uint32_t compact_flash_attribute_base_addr;
+	uint32_t led_display_base_addr;
+};
+
+/* If not to copy a lot of bootloader's structures
+   here is only offset of requested member */
+#define AVAIL_COREMASK_OFFSET_IN_LINUX_APP_BOOT_BLOCK    0x765c
+
+/* hardcoded in bootloader */
+#define  LABI_ADDR_IN_BOOTLOADER                         0x700
+
+#define LINUX_APP_BOOT_BLOCK_NAME "linux-app-boot"
+
+#define LABI_SIGNATURE 0xAABBCCDD
+
+/*  from uboot-headers/octeon_mem_map.h */
+#define EXCEPTION_BASE_INCR     (4*1024)
+			       /* Increment size for exception base addresses (4k minimum) */
+#define EXCEPTION_BASE_BASE     0
+#define BOOTLOADER_PRIV_DATA_BASE       (EXCEPTION_BASE_BASE + 0x800)
+#define BOOTLOADER_BOOT_VECTOR          (BOOTLOADER_PRIV_DATA_BASE)
+
+#endif				/* __OCTEON_BOOT_H__ */
diff --git a/arch/mips/cavium-octeon/octeon_info.c b/arch/mips/cavium-octeon/octeon_info.c
new file mode 100644
index 0000000..80e24dc
--- /dev/null
+++ b/arch/mips/cavium-octeon/octeon_info.c
@@ -0,0 +1,127 @@
+/*
+ * Simple /proc interface to Octeon Information
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2007 Cavium Networks
+ */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/seq_file.h>
+#include <linux/proc_fs.h>
+#include "hal.h"
+#include "cvmx-app-init.h"
+
+extern cvmx_bootinfo_t *octeon_bootinfo;
+#if defined(CONFIG_CAVIUM_RESERVE32) && CONFIG_CAVIUM_RESERVE32
+extern uint64_t octeon_reserve32_memory;
+#endif
+
+/**
+ * User is reading /proc/octeon_info
+ *
+ * @param m
+ * @param v
+ * @return
+ */
+static int octeon_info_show(struct seq_file *m, void *v)
+{
+
+	seq_printf(m, "processor_id:        0x%x\n", read_c0_prid());
+	seq_printf(m, "boot_flags:          0x%x\n", octeon_bootinfo->flags);
+	seq_printf(m, "dram_size:           %u\n", octeon_bootinfo->dram_size);
+	seq_printf(m, "phy_mem_desc_addr:   0x%x\n",
+		   octeon_bootinfo->phy_mem_desc_addr);
+	seq_printf(m, "eclock_hz:           %u\n", octeon_bootinfo->eclock_hz);
+	seq_printf(m, "dclock_hz:           %u\n", octeon_bootinfo->dclock_hz);
+	seq_printf(m, "board_type:          %u\n", octeon_bootinfo->board_type);
+	seq_printf(m, "board_rev_major:     %u\n",
+		   octeon_bootinfo->board_rev_major);
+	seq_printf(m, "board_rev_minor:     %u\n",
+		   octeon_bootinfo->board_rev_minor);
+	seq_printf(m, "board_serial_number: %s\n",
+		   octeon_bootinfo->board_serial_number);
+	seq_printf(m, "mac_addr_base:       %02x:%02x:%02x:%02x:%02x:%02x\n",
+		   (int) octeon_bootinfo->mac_addr_base[0],
+		   (int) octeon_bootinfo->mac_addr_base[1],
+		   (int) octeon_bootinfo->mac_addr_base[2],
+		   (int) octeon_bootinfo->mac_addr_base[3],
+		   (int) octeon_bootinfo->mac_addr_base[4],
+		   (int) octeon_bootinfo->mac_addr_base[5]);
+	seq_printf(m, "mac_addr_count:      %u\n",
+		   octeon_bootinfo->mac_addr_count);
+#if CONFIG_CAVIUM_RESERVE32
+	seq_printf(m, "32bit_shared_mem_base: 0x%lx\n",
+		   octeon_reserve32_memory);
+	seq_printf(m, "32bit_shared_mem_size: 0x%x\n",
+		   octeon_reserve32_memory ? CONFIG_CAVIUM_RESERVE32 << 20 : 0);
+#else
+	seq_printf(m, "32bit_shared_mem_base: 0x%lx\n", 0ul);
+	seq_printf(m, "32bit_shared_mem_size: 0x%x\n", 0);
+#endif
+#ifdef CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB
+	seq_printf(m, "32bit_shared_mem_wired: 1\n");
+#else
+	seq_printf(m, "32bit_shared_mem_wired: 0\n");
+#endif
+	return 0;
+}
+
+
+/**
+ * /proc/octeon_info was openned. Use the single_open iterator
+ *
+ * @param inode
+ * @param file
+ * @return
+ */
+static int octeon_info_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, octeon_info_show, NULL);
+}
+
+
+static struct file_operations octeon_info_operations = {
+	.open = octeon_info_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release,
+};
+
+
+/**
+ * Module initialization
+ *
+ * @return
+ */
+static int __init octeon_info_init(void)
+{
+	struct proc_dir_entry *entry =
+		create_proc_entry("octeon_info", 0, NULL);
+	if (entry == NULL)
+		return -1;
+
+	entry->proc_fops = &octeon_info_operations;
+	return 0;
+}
+
+
+/**
+ * Module cleanup
+ *
+ * @return
+ */
+static void __exit octeon_info_cleanup(void)
+{
+	remove_proc_entry("octeon_info", NULL);
+}
+
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Cavium Networks <support@caviumnetworks.com>");
+MODULE_DESCRIPTION("Cavium Networks Octeon information interface.");
+module_init(octeon_info_init);
+module_exit(octeon_info_cleanup);
diff --git a/arch/mips/cavium-octeon/perf_counters.c b/arch/mips/cavium-octeon/perf_counters.c
new file mode 100644
index 0000000..8ccff64
--- /dev/null
+++ b/arch/mips/cavium-octeon/perf_counters.c
@@ -0,0 +1,788 @@
+/*
+ * Simple /proc interface to the Octeon Performance Counters
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2007 Cavium Networks
+ */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/seq_file.h>
+#include <linux/proc_fs.h>
+#include <linux/ioctl.h>
+#include <asm/mach-cavium-octeon/perf_counters.h>
+#include "hal.h"
+
+/**
+ * The types of counters supported per cpu
+ */
+enum proc_perf_core {
+	PROC_PERF_CORE_NONE = 0,	/* Turn off the performance counter */
+	PROC_PERF_CORE_CLK = 1,	/* Conditionally clocked cycles (as opposed to
+				   count/cvm_count which count even with no
+				   clocks) */
+	PROC_PERF_CORE_ISSUE = 2,	/* Instructions issued but not retired */
+	PROC_PERF_CORE_RET = 3,	/* Instructions retired */
+	PROC_PERF_CORE_NISSUE = 4,	/* Cycles no issue */
+	PROC_PERF_CORE_SISSUE = 5,	/* Cycles single issue */
+	PROC_PERF_CORE_DISSUE = 6,	/* Cycles dual issue */
+	PROC_PERF_CORE_IFI = 7,	/* Cycle ifetch issued (but not necessarily
+				   commit to pp_mem) */
+	PROC_PERF_CORE_BR = 8,	/* Branches retired */
+	PROC_PERF_CORE_BRMIS = 9,	/* Branch mispredicts */
+	PROC_PERF_CORE_J = 10,	/* Jumps retired */
+	PROC_PERF_CORE_JMIS = 11,	/* Jumps mispredicted */
+	PROC_PERF_CORE_REPLAY = 12,	/* Mem Replays */
+	PROC_PERF_CORE_IUNA = 13,	/* Cycles idle due to unaligned_replays
+					 */
+	PROC_PERF_CORE_TRAP = 14,	/* trap_6a signal */
+	PROC_PERF_CORE_UULOAD = 16,	/* Unexpected unaligned loads (REPUN=1)
+					 */
+	PROC_PERF_CORE_UUSTORE = 17,	/* Unexpected unaligned store (REPUN=1)
+					 */
+	PROC_PERF_CORE_ULOAD = 18,	/* Unaligned loads (REPUN=1 or USEUN=1)
+					 */
+	PROC_PERF_CORE_USTORE = 19,	/* Unaligned store (REPUN=1 or USEUN=1)
+					 */
+	PROC_PERF_CORE_EC = 20,	/* Exec clocks(must set CvmCtl[DISCE] for
+				   accurate timing) */
+	PROC_PERF_CORE_MC = 21,	/* Mul clocks(must set CvmCtl[DISCE] for
+				   accurate timing) */
+	PROC_PERF_CORE_CC = 22,	/* Crypto clocks(must set CvmCtl[DISCE] for
+				   accurate timing) */
+	PROC_PERF_CORE_CSRC = 23,	/* Issue_csr clocks(must set
+					   CvmCtl[DISCE] for accurate timing) */
+	PROC_PERF_CORE_CFETCH = 24,	/* Icache committed fetches
+					   (demand+prefetch) */
+	PROC_PERF_CORE_CPREF = 25,	/* Icache committed prefetches */
+	PROC_PERF_CORE_ICA = 26,	/* Icache aliases */
+	PROC_PERF_CORE_II = 27,	/* Icache invalidates */
+	PROC_PERF_CORE_IP = 28,	/* Icache parity error */
+	PROC_PERF_CORE_CIMISS = 29,	/* Cycles idle due to imiss (must set
+					   CvmCtl[DISCE] for accurate timing) */
+	PROC_PERF_CORE_WBUF = 32,	/* Number of write buffer entries
+					   created */
+	PROC_PERF_CORE_WDAT = 33,	/* Number of write buffer data cycles
+					   used (may need to set CvmCtl[DISCE]
+					   for accurate counts) */
+	PROC_PERF_CORE_WBUFLD = 34,	/* Number of write buffer entries
+					   forced out by loads */
+	PROC_PERF_CORE_WBUFFL = 35,	/* Number of cycles that there was no
+					   available write buffer entry (may
+					   need to set CvmCtl[DISCE] and
+					   CvmMemCtl[MCLK] for accurate counts)
+					 */
+	PROC_PERF_CORE_WBUFTR = 36,	/* Number of stores that found no
+					   available write buffer entries */
+	PROC_PERF_CORE_BADD = 37,	/* Number of address bus cycles used
+					   (may need to set CvmCtl[DISCE] for
+					   accurate counts) */
+	PROC_PERF_CORE_BADDL2 = 38,	/* Number of address bus cycles not
+					   reflected (i.e. destined for L2)
+					   (may need to set CvmCtl[DISCE] for
+					   accurate counts) */
+	PROC_PERF_CORE_BFILL = 39,	/* Number of fill bus cycles used (may
+					   need to set CvmCtl[DISCE] for
+					   accurate counts) */
+	PROC_PERF_CORE_DDIDS = 40,	/* Number of Dstream DIDs created */
+	PROC_PERF_CORE_IDIDS = 41,	/* Number of Istream DIDs created */
+	PROC_PERF_CORE_DIDNA = 42,	/* Number of cycles that no DIDs were
+					   available (may need to set
+					   CvmCtl[DISCE] and CvmMemCtl[MCLK]
+					   for accurate counts) */
+	PROC_PERF_CORE_LDS = 43,	/* Number of load issues */
+	PROC_PERF_CORE_LMLDS = 44,	/* Number of local memory load */
+	PROC_PERF_CORE_IOLDS = 45,	/* Number of I/O load issues */
+	PROC_PERF_CORE_DMLDS = 46,	/* Number of loads that were not
+					   prefetches and missed in the cache */
+	PROC_PERF_CORE_STS = 48,	/* Number of store issues */
+	PROC_PERF_CORE_LMSTS = 49,	/* Number of local memory store issues */
+	PROC_PERF_CORE_IOSTS = 50,	/* Number of I/O store issues */
+	PROC_PERF_CORE_IOBDMA = 51,	/* Number of IOBDMAs */
+	PROC_PERF_CORE_DTLB = 53,	/* Number of dstream TLB refill,
+					   invalid, or modified exceptions */
+	PROC_PERF_CORE_DTLBAD = 54,	/* Number of dstream TLB address errors
+					 */
+	PROC_PERF_CORE_ITLB = 55,	/* Number of istream TLB refill,
+					   invalid, or address error exceptions
+					 */
+	PROC_PERF_CORE_SYNC = 56,	/* Number of SYNC stall cycles (may
+					   need to set CvmCtl[DISCE] for
+					   accurate counts) */
+	PROC_PERF_CORE_SYNCIOB = 57,	/* Number of SYNCIOBDMA stall cycles
+					   (may need to set CvmCtl[DISCE] for
+					   accurate counts) */
+	PROC_PERF_CORE_SYNCW = 58,	/* Number of SYNCWs */
+	PROC_PERF_CORE_MAX
+};
+
+/**
+ * The types of counters supported for L2
+ */
+enum proc_perf_l2 {
+	PROC_PERF_L2_CYCLES,	/* Cycles */
+	PROC_PERF_L2_IMISS,	/* L2 Instruction Miss */
+	PROC_PERF_L2_IHIT,	/* L2 Instruction Hit */
+	PROC_PERF_L2_DMISS,	/* L2 Data Miss */
+	PROC_PERF_L2_DHIT,	/* L2 Data Hit */
+	PROC_PERF_L2_MISS,	/* L2 Miss (I/D) */
+	PROC_PERF_L2_HIT,	/* L2 Hit (I/D) */
+	PROC_PERF_L2_VICTIM_BUFFER_HIT,	/* L2 Victim Buffer Hit (Retry Probe) */
+	PROC_PERF_L2_LFB_NQ_INDEX_CONFLICT,	/* LFB-NQ Index Conflict */
+	PROC_PERF_L2_TAG_PROBE,	/* L2 Tag Probe (issued - could be VB-Retried) */
+	PROC_PERF_L2_TAG_UPDATE,	/* L2 Tag Update (completed). Note:
+					   Some CMD types do not update */
+	PROC_PERF_L2_TAG_PROBE_COMPLETED,	/* L2 Tag Probe Completed
+						   (beyond VB-RTY window) */
+	PROC_PERF_L2_TAG_DIRTY_VICTIM,	/* L2 Tag Dirty Victim */
+	PROC_PERF_L2_DATA_STORE_NOP,	/* L2 Data Store NOP */
+	PROC_PERF_L2_DATA_STORE_READ,	/* L2 Data Store READ */
+	PROC_PERF_L2_DATA_STORE_WRITE,	/* L2 Data Store WRITE */
+	PROC_PERF_L2_MEMORY_FILL_DATA_VALID,	/* Memory Fill Data valid */
+	PROC_PERF_L2_MEMORY_WRITE_REQUEST,	/* Memory Write Request */
+	PROC_PERF_L2_MEMORY_READ_REQUEST,	/* Memory Read Request */
+	PROC_PERF_L2_MEMORY_WRITE_DATA_VALID,	/* Memory Write Data valid */
+	PROC_PERF_L2_XMC_NOP,	/* XMC NOP */
+	PROC_PERF_L2_XMC_LDT,	/* XMC LDT */
+	PROC_PERF_L2_XMC_LDI,	/* XMC LDI */
+	PROC_PERF_L2_XMC_LDD,	/* XMC LDD */
+	PROC_PERF_L2_XMC_STF,	/* XMC STF */
+	PROC_PERF_L2_XMC_STT,	/* XMC STT */
+	PROC_PERF_L2_XMC_STP,	/* XMC STP */
+	PROC_PERF_L2_XMC_STC,	/* XMC STC */
+	PROC_PERF_L2_XMC_DWB,	/* XMC DWB */
+	PROC_PERF_L2_XMC_PL2,	/* XMC PL2 */
+	PROC_PERF_L2_XMC_PSL1,	/* XMC PSL1 */
+	PROC_PERF_L2_XMC_IOBLD,	/* XMC IOBLD */
+	PROC_PERF_L2_XMC_IOBST,	/* XMC IOBST */
+	PROC_PERF_L2_XMC_IOBDMA,	/* XMC IOBDMA */
+	PROC_PERF_L2_XMC_IOBRSP,	/* XMC IOBRSP */
+	PROC_PERF_L2_XMD_BUS_VALID,	/* XMD Bus valid (all) */
+	PROC_PERF_L2_XMD_BUS_VALID_DST_L2C,	/* XMD Bus valid (DST=L2C)
+						   Memory */
+	PROC_PERF_L2_XMD_BUS_VALID_DST_IOB,	/* XMD Bus valid (DST=IOB) REFL
+						   Data */
+	PROC_PERF_L2_XMD_BUS_VALID_DST_PP,	/* XMD Bus valid (DST=PP)
+						   IOBRSP Data */
+	PROC_PERF_L2_RSC_NOP,	/* RSC NOP */
+	PROC_PERF_L2_RSC_STDN,	/* RSC STDN */
+	PROC_PERF_L2_RSC_FILL,	/* RSC FILL */
+	PROC_PERF_L2_RSC_REFL,	/* RSC REFL */
+	PROC_PERF_L2_RSC_STIN,	/* RSC STIN */
+	PROC_PERF_L2_RSC_SCIN,	/* RSC SCIN */
+	PROC_PERF_L2_RSC_SCFL,	/* RSC SCFL */
+	PROC_PERF_L2_RSC_SCDN,	/* RSC SCDN */
+	PROC_PERF_L2_RSD_DATA_VALID,	/* RSD Data Valid */
+	PROC_PERF_L2_RSD_DATA_VALID_FILL,	/* RSD Data Valid (FILL) */
+	PROC_PERF_L2_RSD_DATA_VALID_STRSP,	/* RSD Data Valid (STRSP) */
+	PROC_PERF_L2_RSD_DATA_VALID_REFL,	/* RSD Data Valid (REFL) */
+	PROC_PERF_L2_LRF_REQ,	/* LRF-REQ (LFB-NQ) */
+	PROC_PERF_L2_DT_RD_ALLOC,	/* DT RD-ALLOC */
+	PROC_PERF_L2_DT_WR_INVA,	/* DT WR-INVA */
+	PROC_PERF_L2_MAX
+};
+
+/**
+ * IO addresses for L2 registers
+ */
+#define  OCTEON_L2C_PFCTL   0x8001180080000090ull
+#define  OCTEON_L2C_PFC0    0x8001180080000098ull
+#define  OCTEON_L2C_PFC1    0x80011800800000A0ull
+#define  OCTEON_L2C_PFC2    0x80011800800000A8ull
+#define  OCTEON_L2C_PFC3    0x80011800800000B0ull
+#define  OCTEON_LMC_DCLK_CNT_HI 0x8001180088000070ull
+#define  OCTEON_LMC_DCLK_CNT_LO 0x8001180088000068ull
+#define  OCTEON_LMC_OPS_CNT_HI  0x8001180088000060ull
+#define  OCTEON_LMC_OPS_CNT_LO  0x8001180088000058ull
+
+/**
+ * Bit description of the core counters control register
+ */
+union proc_perf_core_control {
+	uint32_t u32;
+	struct {
+		uint32_t M:1;
+		uint32_t W:1;
+		uint32_t reserved:19;
+		enum proc_perf_core event:6;
+		uint32_t IE:1;
+		uint32_t U:1;
+		uint32_t S:1;
+		uint32_t K:1;
+		uint32_t EX:1;
+	} s;
+};
+
+/**
+ * Bit description of the L2 counters control register
+ */
+union proc_perf_l2_control {
+	uint64_t u64;
+	struct {
+		uint64_t reserved:32;
+		uint64_t cnt3ena:1;
+		uint64_t cnt3clr:1;
+		enum proc_perf_l2 cnt3sel:6;
+		uint64_t cnt2ena:1;
+		uint64_t cnt2clr:1;
+		enum proc_perf_l2 cnt2sel:6;
+		uint64_t cnt1ena:1;
+		uint64_t cnt1clr:1;
+		enum proc_perf_l2 cnt1sel:6;
+		uint64_t cnt0ena:1;
+		uint64_t cnt0clr:1;
+		enum proc_perf_l2 cnt0sel:6;
+	} s;
+};
+
+/**
+ * Module parameters used to control the counters. Can be
+ * changed on the fly through sysfs or ioctls.
+ */
+static char counter0[32] = "sissue";
+static char counter1[32] = "dissue";
+module_param_string(counter0, counter0, sizeof(counter0), 0644);
+module_param_string(counter1, counter1, sizeof(counter1), 0644);
+
+static char l2counter0[32] = "imiss";
+static char l2counter1[32] = "ihit";
+static char l2counter2[32] = "dmiss";
+static char l2counter3[32] = "dhit";
+module_param_string(l2counter0, l2counter0, sizeof(l2counter0), 0644);
+module_param_string(l2counter1, l2counter1, sizeof(l2counter1), 0644);
+module_param_string(l2counter2, l2counter2, sizeof(l2counter2), 0644);
+module_param_string(l2counter3, l2counter3, sizeof(l2counter3), 0644);
+
+static struct proc_dir_entry *proc_perf_entry;
+static uint64_t proc_perf_counter_control[2];
+static uint64_t proc_perf_counter_data[NR_CPUS][2];
+static uint64_t proc_perf_l2counter_control[4];
+static uint64_t proc_perf_l2counter_data[4];
+static const char *proc_perf_label[PROC_PERF_CORE_MAX];
+static const char *proc_perf_l2label[PROC_PERF_L2_MAX];
+static uint64_t proc_perf_dram_clocks;
+static uint64_t proc_perf_dram_operations;
+static int proc_perf_in_use;
+
+
+/**
+ * Setup the core counters. Called on each core
+ *
+ * @param arg
+ */
+static void proc_perf_setup_counters(void *arg)
+{
+	union proc_perf_core_control control;
+	uint64_t cvmctl;
+
+	if (proc_perf_in_use) {
+		/* Disable the issue and exec conditional clock support so we get
+			better results */
+		cvmctl = __read_64bit_c0_register($9, 7);
+		cvmctl |= 3 << 16;
+		__write_64bit_c0_register($9, 7, cvmctl);
+	}
+
+	control.u32 = 0;
+	control.s.event = proc_perf_counter_control[0];
+	control.s.U = 1;
+	control.s.S = 1;
+	control.s.K = 1;
+	control.s.EX = 1;
+	__write_32bit_c0_register($25, 0, control.u32);
+
+	control.s.event = proc_perf_counter_control[1];
+	__write_32bit_c0_register($25, 2, control.u32);
+
+	__write_32bit_c0_register($25, 1, 0);
+	__write_32bit_c0_register($25, 3, 0);
+}
+
+
+/**
+ * Update the counters for each core.
+ *
+ * @param arg
+ */
+static void proc_perf_update_counters(void *arg)
+{
+	int cpu = smp_processor_id();
+
+	proc_perf_counter_data[cpu][0] = __read_64bit_c0_register($25, 1);
+	proc_perf_counter_data[cpu][1] = __read_64bit_c0_register($25, 3);
+	mb();
+}
+
+
+/**
+ * Cleanup the input of sysfs
+ *
+ * @param str
+ * @param len
+ */
+static inline void clean_string(char *str, int len)
+{
+	int i;
+	for (i = 0; i < len; i++)
+		if (str[i] <= 32)
+			str[i] = 0;
+}
+
+
+/**
+ * Setup the counters using the current config
+ */
+static void proc_perf_setup(void)
+{
+	int i;
+	union proc_perf_l2_control l2control;
+
+	proc_perf_counter_control[0] = 0;
+	proc_perf_counter_control[1] = 0;
+	proc_perf_l2counter_control[0] = 0;
+	proc_perf_l2counter_control[1] = 0;
+	proc_perf_l2counter_control[2] = 0;
+	proc_perf_l2counter_control[3] = 0;
+
+	/* Cleanup junk on end of param strings */
+	clean_string(counter0, sizeof(counter0));
+	clean_string(counter1, sizeof(counter1));
+	clean_string(l2counter0, sizeof(l2counter0));
+	clean_string(l2counter1, sizeof(l2counter1));
+	clean_string(l2counter2, sizeof(l2counter2));
+	clean_string(l2counter3, sizeof(l2counter3));
+
+	/* Set the core counters to match the string parameters */
+	for (i = 0; i < PROC_PERF_CORE_MAX; i++) {
+		if (proc_perf_label[i]) {
+			if (strcmp(proc_perf_label[i], counter0) == 0)
+				proc_perf_counter_control[0] = i;
+			if (strcmp(proc_perf_label[i], counter1) == 0)
+				proc_perf_counter_control[1] = i;
+		}
+	}
+
+	/* Set the L2 counters to match the string parameters */
+	for (i = 0; i < PROC_PERF_L2_MAX; i++) {
+		if (proc_perf_l2label[i]) {
+			if (strcmp(proc_perf_l2label[i], l2counter0) == 0)
+				proc_perf_l2counter_control[0] = i;
+			if (strcmp(proc_perf_l2label[i], l2counter1) == 0)
+				proc_perf_l2counter_control[1] = i;
+			if (strcmp(proc_perf_l2label[i], l2counter2) == 0)
+				proc_perf_l2counter_control[2] = i;
+			if (strcmp(proc_perf_l2label[i], l2counter3) == 0)
+				proc_perf_l2counter_control[3] = i;
+		}
+	}
+
+	/* Update strings to match final config */
+	strcpy(counter0, proc_perf_label[proc_perf_counter_control[0]]);
+	strcpy(counter1, proc_perf_label[proc_perf_counter_control[1]]);
+	strcpy(l2counter0, proc_perf_l2label[proc_perf_l2counter_control[0]]);
+	strcpy(l2counter1, proc_perf_l2label[proc_perf_l2counter_control[1]]);
+	strcpy(l2counter2, proc_perf_l2label[proc_perf_l2counter_control[2]]);
+	strcpy(l2counter3, proc_perf_l2label[proc_perf_l2counter_control[3]]);
+
+	on_each_cpu(proc_perf_setup_counters, NULL, 1);
+
+	l2control.u64 = 0;
+	l2control.s.cnt3ena = 1;
+	l2control.s.cnt3clr = 1;
+	l2control.s.cnt3sel = proc_perf_l2counter_control[3];
+	l2control.s.cnt2ena = 1;
+	l2control.s.cnt2clr = 1;
+	l2control.s.cnt2sel = proc_perf_l2counter_control[2];
+	l2control.s.cnt1ena = 1;
+	l2control.s.cnt1clr = 1;
+	l2control.s.cnt1sel = proc_perf_l2counter_control[1];
+	l2control.s.cnt0ena = 1;
+	l2control.s.cnt0clr = 1;
+	l2control.s.cnt0sel = proc_perf_l2counter_control[0];
+
+	cvmx_write_csr(OCTEON_L2C_PFCTL, l2control.u64);
+}
+
+
+static void proc_perf_update(void)
+{
+	on_each_cpu(proc_perf_update_counters, NULL, 1);
+	mb();
+	proc_perf_l2counter_data[0] = cvmx_read_csr(OCTEON_L2C_PFC0);
+	proc_perf_l2counter_data[1] = cvmx_read_csr(OCTEON_L2C_PFC1);
+	proc_perf_l2counter_data[2] = cvmx_read_csr(OCTEON_L2C_PFC2);
+	proc_perf_l2counter_data[3] = cvmx_read_csr(OCTEON_L2C_PFC3);
+}
+
+
+/**
+ * Show the counters to the user
+ *
+ * @param m
+ * @param v
+ * @return
+ */
+static int proc_perf_show(struct seq_file *m, void *v)
+{
+	int cpu;
+	int i;
+	uint64_t dram_clocks;
+	uint64_t dram_operations;
+	union proc_perf_core_control control0;
+	union proc_perf_core_control control1;
+
+	proc_perf_update();
+
+	control0.u32 = __read_32bit_c0_register($25, 0);
+	control1.u32 = __read_32bit_c0_register($25, 2);
+	seq_printf(m, "       %16s %16s\n",
+		   proc_perf_label[control0.s.event],
+		   proc_perf_label[control1.s.event]);
+	for (cpu = 0; cpu < NR_CPUS; cpu++) {
+		if (cpu_online(cpu))
+			seq_printf(m, "CPU%2d: %16llu %16llu\n", cpu,
+				   (unsigned long long)
+				   proc_perf_counter_data[cpu][0],
+				   (unsigned long long)
+				   proc_perf_counter_data[cpu][1]);
+	}
+
+	seq_printf(m, "\n");
+	for (i = 0; i < 4; i++)
+		seq_printf(m, "%s: %llu\n",
+			   proc_perf_l2label[proc_perf_l2counter_control[i]],
+			   (unsigned long long) proc_perf_l2counter_data[i]);
+
+	/* Compute DRAM utilization */
+	dram_operations =
+		(cvmx_read_csr(OCTEON_LMC_OPS_CNT_HI) << 32) |
+		cvmx_read_csr(OCTEON_LMC_OPS_CNT_LO);
+	dram_clocks =
+		(cvmx_read_csr(OCTEON_LMC_DCLK_CNT_HI) << 32) |
+		cvmx_read_csr(OCTEON_LMC_DCLK_CNT_LO);
+#ifndef _ABIO32
+	if (dram_clocks > proc_perf_dram_clocks) {
+		uint64_t delta_clocks = dram_clocks - proc_perf_dram_clocks;
+		uint64_t delta_operations =
+			dram_operations - proc_perf_dram_operations;
+		uint64_t percent_x100 = 10000 * delta_operations / delta_clocks;
+		seq_printf(m,
+			   "\nDRAM ops count: %lu, dclk count: %lu, utilization: %lu.%02lu%%\n",
+			   delta_operations, delta_clocks, percent_x100 / 100,
+			   percent_x100 % 100);
+	}
+#endif
+	proc_perf_dram_operations = dram_operations;
+	proc_perf_dram_clocks = dram_clocks;
+
+	seq_printf(m,
+		   "\n"
+		   "Configuration of the performance counters is controller by writing\n"
+		   "one of the following values to:\n"
+		   "    /sys/module/perf_counters/parameters/counter{0,1}\n"
+		   "    /sys/module/perf_counters/parameters/l2counter{0-3}\n"
+		   "\n" "Possible CPU counters:");
+	for (i = 0; i < PROC_PERF_CORE_MAX; i++) {
+		if ((i & 7) == 0)
+			seq_printf(m, "\n    ");
+		if (proc_perf_label[i])
+			seq_printf(m, "%s ", proc_perf_label[i]);
+	}
+
+	seq_printf(m, "\n\nPossible L2 counters:");
+	for (i = 0; i < PROC_PERF_L2_MAX; i++) {
+		if ((i & 3) == 0)
+			seq_printf(m, "\n    ");
+		if (proc_perf_l2label[i])
+			seq_printf(m, "%s ", proc_perf_l2label[i]);
+	}
+	seq_printf(m,
+		   "\nWarning: Counter configuration doesn't update till you access /proc/octeon_perf.\n");
+
+	proc_perf_setup();
+	return 0;
+}
+
+
+/**
+ * /proc/octeon_perf was openned. Use the single_open iterator
+ *
+ * @param inode
+ * @param file
+ * @return
+ */
+static int proc_perf_open(struct inode *inode, struct file *file)
+{
+	proc_perf_in_use = 1;
+	return single_open(file, proc_perf_show, NULL);
+}
+
+
+/**
+ * IOCTL on /proc/octeon_perf
+ *
+ * @param inode
+ * @param file
+ * @param cmd
+ * @param arg
+ * @return
+ */
+static int proc_perf_ioctl(struct inode *inode, struct file *file,
+			   unsigned int cmd, unsigned long arg)
+{
+	/*
+	pr_debug("proc_perf_ioctl(cmd=0x%x(%u), arg=0x%lx)\n", cmd, cmd, arg);
+	*/
+	switch (cmd) {
+	case PROC_PERF_IOCTL_SETUP_COUNTER0:
+		if ((arg <= PROC_PERF_CORE_MAX) && proc_perf_label[arg]) {
+			strcpy(counter0, proc_perf_label[arg]);
+			proc_perf_setup();
+			return 0;
+		}
+		return -EINVAL;
+	case PROC_PERF_IOCTL_SETUP_COUNTER1:
+		if ((arg <= PROC_PERF_CORE_MAX) && proc_perf_label[arg]) {
+			strcpy(counter1, proc_perf_label[arg]);
+			proc_perf_setup();
+			return 0;
+		}
+		return -EINVAL;
+	case PROC_PERF_IOCTL_SETUP_L2COUNTER0:
+		if ((arg <= PROC_PERF_L2_MAX) && proc_perf_l2label[arg]) {
+			strcpy(l2counter0, proc_perf_l2label[arg]);
+			proc_perf_setup();
+			return 0;
+		}
+		return -EINVAL;
+	case PROC_PERF_IOCTL_SETUP_L2COUNTER1:
+		if ((arg <= PROC_PERF_L2_MAX) && proc_perf_l2label[arg]) {
+			strcpy(l2counter1, proc_perf_l2label[arg]);
+			proc_perf_setup();
+			return 0;
+		}
+		return -EINVAL;
+	case PROC_PERF_IOCTL_SETUP_L2COUNTER2:
+		if ((arg <= PROC_PERF_L2_MAX) && proc_perf_l2label[arg]) {
+			strcpy(l2counter2, proc_perf_l2label[arg]);
+			proc_perf_setup();
+			return 0;
+		}
+		return -EINVAL;
+	case PROC_PERF_IOCTL_SETUP_L2COUNTER3:
+		if ((arg <= PROC_PERF_L2_MAX) && proc_perf_l2label[arg]) {
+			strcpy(l2counter3, proc_perf_l2label[arg]);
+			proc_perf_setup();
+			return 0;
+		}
+		return -EINVAL;
+	case PROC_PERF_IOCTL_READ_COUNTER0:
+		proc_perf_update();
+		copy_to_user((void *) arg,
+			     proc_perf_counter_data[smp_processor_id()] + 0,
+			     sizeof(long long));
+		return 0;
+	case PROC_PERF_IOCTL_READ_COUNTER1:
+		proc_perf_update();
+		copy_to_user((void *) arg,
+			     proc_perf_counter_data[smp_processor_id()] + 1,
+			     sizeof(long long));
+		return 0;
+	case PROC_PERF_IOCTL_READ_L2COUNTER0:
+		proc_perf_update();
+		copy_to_user((void *) arg, proc_perf_l2counter_data + 0,
+			     sizeof(long long));
+		return 0;
+	case PROC_PERF_IOCTL_READ_L2COUNTER1:
+		proc_perf_update();
+		copy_to_user((void *) arg, proc_perf_l2counter_data + 1,
+			     sizeof(long long));
+		return 0;
+	case PROC_PERF_IOCTL_READ_L2COUNTER2:
+		proc_perf_update();
+		copy_to_user((void *) arg, proc_perf_l2counter_data + 2,
+			     sizeof(long long));
+		return 0;
+	case PROC_PERF_IOCTL_READ_L2COUNTER3:
+		proc_perf_update();
+		copy_to_user((void *) arg, proc_perf_l2counter_data + 3,
+			     sizeof(long long));
+		return 0;
+	default:
+		return -EINVAL;
+	}
+}
+
+
+static struct file_operations proc_perf_operations = {
+	.open = proc_perf_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release,
+	.ioctl = proc_perf_ioctl,
+};
+
+
+/**
+ * Module initialization
+ *
+ * @return
+ */
+static int __init proc_perf_init(void)
+{
+	pr_notice("/proc/octeon_perf: Octeon performace counter interface loaded\n");
+
+	memset(proc_perf_label, 0, sizeof(proc_perf_label));
+	memset(proc_perf_l2label, 0, sizeof(proc_perf_l2label));
+
+	proc_perf_label[PROC_PERF_CORE_NONE] = "none";
+	proc_perf_label[PROC_PERF_CORE_CLK] = "clk";
+	proc_perf_label[PROC_PERF_CORE_ISSUE] = "issue";
+	proc_perf_label[PROC_PERF_CORE_RET] = "ret";
+	proc_perf_label[PROC_PERF_CORE_NISSUE] = "nissue";
+	proc_perf_label[PROC_PERF_CORE_SISSUE] = "sissue";
+	proc_perf_label[PROC_PERF_CORE_DISSUE] = "dissue";
+	proc_perf_label[PROC_PERF_CORE_IFI] = "ifi";
+	proc_perf_label[PROC_PERF_CORE_BR] = "br";
+	proc_perf_label[PROC_PERF_CORE_BRMIS] = "brmis";
+	proc_perf_label[PROC_PERF_CORE_J] = "j";
+	proc_perf_label[PROC_PERF_CORE_JMIS] = "jmis";
+	proc_perf_label[PROC_PERF_CORE_REPLAY] = "replay";
+	proc_perf_label[PROC_PERF_CORE_IUNA] = "iuna";
+	proc_perf_label[PROC_PERF_CORE_TRAP] = "trap";
+	proc_perf_label[PROC_PERF_CORE_UULOAD] = "uuload";
+	proc_perf_label[PROC_PERF_CORE_UUSTORE] = "uustore";
+	proc_perf_label[PROC_PERF_CORE_ULOAD] = "uload";
+	proc_perf_label[PROC_PERF_CORE_USTORE] = "ustore";
+	proc_perf_label[PROC_PERF_CORE_EC] = "ec";
+	proc_perf_label[PROC_PERF_CORE_MC] = "mc";
+	proc_perf_label[PROC_PERF_CORE_CC] = "cc";
+	proc_perf_label[PROC_PERF_CORE_CSRC] = "csrc";
+	proc_perf_label[PROC_PERF_CORE_CFETCH] = "cfetch";
+	proc_perf_label[PROC_PERF_CORE_CPREF] = "cpref";
+	proc_perf_label[PROC_PERF_CORE_ICA] = "ica";
+	proc_perf_label[PROC_PERF_CORE_II] = "ii";
+	proc_perf_label[PROC_PERF_CORE_IP] = "ip";
+	proc_perf_label[PROC_PERF_CORE_CIMISS] = "cimiss";
+	proc_perf_label[PROC_PERF_CORE_WBUF] = "wbuf";
+	proc_perf_label[PROC_PERF_CORE_WDAT] = "wdat";
+	proc_perf_label[PROC_PERF_CORE_WBUFLD] = "wbufld";
+	proc_perf_label[PROC_PERF_CORE_WBUFFL] = "wbuffl";
+	proc_perf_label[PROC_PERF_CORE_WBUFTR] = "wbuftr";
+	proc_perf_label[PROC_PERF_CORE_BADD] = "badd";
+	proc_perf_label[PROC_PERF_CORE_BADDL2] = "baddl2";
+	proc_perf_label[PROC_PERF_CORE_BFILL] = "bfill";
+	proc_perf_label[PROC_PERF_CORE_DDIDS] = "ddids";
+	proc_perf_label[PROC_PERF_CORE_IDIDS] = "idids";
+	proc_perf_label[PROC_PERF_CORE_DIDNA] = "didna";
+	proc_perf_label[PROC_PERF_CORE_LDS] = "lds";
+	proc_perf_label[PROC_PERF_CORE_LMLDS] = "lmlds";
+	proc_perf_label[PROC_PERF_CORE_IOLDS] = "iolds";
+	proc_perf_label[PROC_PERF_CORE_DMLDS] = "dmlds";
+	proc_perf_label[PROC_PERF_CORE_STS] = "sts";
+	proc_perf_label[PROC_PERF_CORE_LMSTS] = "lmsts";
+	proc_perf_label[PROC_PERF_CORE_IOSTS] = "iosts";
+	proc_perf_label[PROC_PERF_CORE_IOBDMA] = "iobdma";
+	proc_perf_label[PROC_PERF_CORE_DTLB] = "dtlb";
+	proc_perf_label[PROC_PERF_CORE_DTLBAD] = "dtlbad";
+	proc_perf_label[PROC_PERF_CORE_ITLB] = "itlb";
+	proc_perf_label[PROC_PERF_CORE_SYNC] = "sync";
+	proc_perf_label[PROC_PERF_CORE_SYNCIOB] = "synciob";
+	proc_perf_label[PROC_PERF_CORE_SYNCW] = "syncw";
+
+	proc_perf_l2label[PROC_PERF_L2_CYCLES] = "cycles";
+	proc_perf_l2label[PROC_PERF_L2_IMISS] = "imiss";
+	proc_perf_l2label[PROC_PERF_L2_IHIT] = "ihit";
+	proc_perf_l2label[PROC_PERF_L2_DMISS] = "dmiss";
+	proc_perf_l2label[PROC_PERF_L2_DHIT] = "dhit";
+	proc_perf_l2label[PROC_PERF_L2_MISS] = "miss";
+	proc_perf_l2label[PROC_PERF_L2_HIT] = "hit";
+	proc_perf_l2label[PROC_PERF_L2_VICTIM_BUFFER_HIT] = "victim-buffer-hit";
+	proc_perf_l2label[PROC_PERF_L2_LFB_NQ_INDEX_CONFLICT] =
+		"lfb-nq-index-conflict";
+	proc_perf_l2label[PROC_PERF_L2_TAG_PROBE] = "tag-probe";
+	proc_perf_l2label[PROC_PERF_L2_TAG_UPDATE] = "tag-update";
+	proc_perf_l2label[PROC_PERF_L2_TAG_PROBE_COMPLETED] =
+		"tag-probe-completed";
+	proc_perf_l2label[PROC_PERF_L2_TAG_DIRTY_VICTIM] = "tag-dirty-victim";
+	proc_perf_l2label[PROC_PERF_L2_DATA_STORE_NOP] = "data-store-nop";
+	proc_perf_l2label[PROC_PERF_L2_DATA_STORE_READ] = "data-store-read";
+	proc_perf_l2label[PROC_PERF_L2_DATA_STORE_WRITE] = "data-store-write";
+	proc_perf_l2label[PROC_PERF_L2_MEMORY_FILL_DATA_VALID] =
+		"memory-fill-data-valid";
+	proc_perf_l2label[PROC_PERF_L2_MEMORY_WRITE_REQUEST] =
+		"memory-write-request";
+	proc_perf_l2label[PROC_PERF_L2_MEMORY_READ_REQUEST] =
+		"memory-read-request";
+	proc_perf_l2label[PROC_PERF_L2_MEMORY_WRITE_DATA_VALID] =
+		"memory-write-data-valid";
+	proc_perf_l2label[PROC_PERF_L2_XMC_NOP] = "xmc-nop";
+	proc_perf_l2label[PROC_PERF_L2_XMC_LDT] = "xmc-ldt";
+	proc_perf_l2label[PROC_PERF_L2_XMC_LDI] = "xmc-ldi";
+	proc_perf_l2label[PROC_PERF_L2_XMC_LDD] = "xmc-ldd";
+	proc_perf_l2label[PROC_PERF_L2_XMC_STF] = "xmc-stf";
+	proc_perf_l2label[PROC_PERF_L2_XMC_STT] = "xmc-stt";
+	proc_perf_l2label[PROC_PERF_L2_XMC_STP] = "xmc-stp";
+	proc_perf_l2label[PROC_PERF_L2_XMC_STC] = "xmc-stc";
+	proc_perf_l2label[PROC_PERF_L2_XMC_DWB] = "xmc-dwb";
+	proc_perf_l2label[PROC_PERF_L2_XMC_PL2] = "xmc-pl2";
+	proc_perf_l2label[PROC_PERF_L2_XMC_PSL1] = "xmc-psl1";
+	proc_perf_l2label[PROC_PERF_L2_XMC_IOBLD] = "xmc-iobld";
+	proc_perf_l2label[PROC_PERF_L2_XMC_IOBST] = "xmc-iobst";
+	proc_perf_l2label[PROC_PERF_L2_XMC_IOBDMA] = "xmc-iobdma";
+	proc_perf_l2label[PROC_PERF_L2_XMC_IOBRSP] = "xmc-iobrsp";
+	proc_perf_l2label[PROC_PERF_L2_XMD_BUS_VALID] = "xmd-bus-valid";
+	proc_perf_l2label[PROC_PERF_L2_XMD_BUS_VALID_DST_L2C] =
+		"xmd-bus-valid-dst-l2c";
+	proc_perf_l2label[PROC_PERF_L2_XMD_BUS_VALID_DST_IOB] =
+		"xmd-bus-valid-dst-iob";
+	proc_perf_l2label[PROC_PERF_L2_XMD_BUS_VALID_DST_PP] =
+		"xmd-bus-valid-dst-pp";
+	proc_perf_l2label[PROC_PERF_L2_RSC_NOP] = "rsc-nop";
+	proc_perf_l2label[PROC_PERF_L2_RSC_STDN] = "rsc-stdn";
+	proc_perf_l2label[PROC_PERF_L2_RSC_FILL] = "rsc-fill";
+	proc_perf_l2label[PROC_PERF_L2_RSC_REFL] = "rsc-refl";
+	proc_perf_l2label[PROC_PERF_L2_RSC_STIN] = "rsc-stin";
+	proc_perf_l2label[PROC_PERF_L2_RSC_SCIN] = "rsc-scin";
+	proc_perf_l2label[PROC_PERF_L2_RSC_SCFL] = "rsc-scfl";
+	proc_perf_l2label[PROC_PERF_L2_RSC_SCDN] = "rsc-scdn";
+	proc_perf_l2label[PROC_PERF_L2_RSD_DATA_VALID] = "rsd-data-valid";
+	proc_perf_l2label[PROC_PERF_L2_RSD_DATA_VALID_FILL] =
+		"rsd-data-valid-fill";
+	proc_perf_l2label[PROC_PERF_L2_RSD_DATA_VALID_STRSP] =
+		"rsd-data-valid-strsp";
+	proc_perf_l2label[PROC_PERF_L2_RSD_DATA_VALID_REFL] =
+		"rsd-data-valid-refl";
+	proc_perf_l2label[PROC_PERF_L2_LRF_REQ] = "lrf-req";
+	proc_perf_l2label[PROC_PERF_L2_DT_RD_ALLOC] = "dt-rd-alloc";
+	proc_perf_l2label[PROC_PERF_L2_DT_WR_INVA] = "dt-wr-inva";
+
+	proc_perf_entry = create_proc_entry("octeon_perf", 0, NULL);
+	if (proc_perf_entry)
+		proc_perf_entry->proc_fops = &proc_perf_operations;
+
+	proc_perf_setup();
+	return 0;
+}
+
+
+/**
+ * Module cleanup
+ *
+ * @return
+ */
+static void __exit proc_perf_cleanup(void)
+{
+	if (proc_perf_entry)
+		remove_proc_entry("octeon_perf", NULL);
+}
+
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Cavium Networks <support@caviumnetworks.com>");
+MODULE_DESCRIPTION("Cavium Networks Octeon performance counter interface.");
+module_init(proc_perf_init);
+module_exit(proc_perf_cleanup);
diff --git a/arch/mips/cavium-octeon/serial.c b/arch/mips/cavium-octeon/serial.c
new file mode 100644
index 0000000..0c57e54
--- /dev/null
+++ b/arch/mips/cavium-octeon/serial.c
@@ -0,0 +1,159 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2007 Cavium Networks
+ */
+#include <linux/console.h>
+#include <linux/serial.h>
+#include <linux/tty.h>
+#include <asm/time.h>
+#include <linux/serial_8250.h>
+#include "hal.h"
+
+#if defined(CONFIG_CAVIUM_GDB)
+static int cavium_gdb_active = 0;
+
+static int __init opt_cavium_gdb(void)
+{
+	cavium_gdb_active = 1;
+	return 0;
+}
+
+early_param("cavium_gdb", opt_cavium_gdb);
+
+#ifdef CONFIG_GDB_CONSOLE
+#define DEBUG_UART 0
+#else
+#define DEBUG_UART 1
+#endif
+
+static irqreturn_t interruptDebugChar(int cpl, void *dev_id)
+{
+	unsigned long lsrval;
+	lsrval = cvmx_read_csr(CVMX_MIO_UARTX_LSR(1));
+	if (lsrval & 1) {
+		unsigned long tmp;
+		/* Pulse MCD0 signal on Ctrl-C to stop all the cores. Also set
+		   the MCD0 to be not masked by this core so we know the signal
+		   is received by someone */
+		octeon_write_lcd("brk");
+		asm volatile ("dmfc0 %0, $22\n"
+			      "ori   %0, %0, 0x10\n"
+			      "dmtc0 %0, $22\n" : "=r" (tmp));
+		octeon_write_lcd("");
+		return IRQ_HANDLED;
+	}
+	return IRQ_NONE;
+}
+
+/* Enable uart1 interrupts for debugger Control-C processing */
+
+static int octeon_setup_debug_uart(void)
+{
+	/* cavium_gdb_active is true if 'cavium_gdb' was detected on
+	   kernel command line */
+	if (cavium_gdb_active) {
+		if (request_irq(OCTEON_IRQ_UART0 + DEBUG_UART,
+				interruptDebugChar, IRQF_SHARED, "KGDB",
+				interruptDebugChar)) {
+		panic("request_irq(%d) failed.", OCTEON_IRQ_UART0 + DEBUG_UART);
+		}
+
+		/* Enable uart1 interrupts for debugger Control-C processing */
+		cvmx_write_csr(CVMX_MIO_UARTX_IER(DEBUG_UART),
+			cvmx_read_csr(CVMX_MIO_UARTX_IER(DEBUG_UART)) | 1);
+	}
+	return 0;
+}
+
+/* Install this as early as possible to be able to debug the boot
+   sequence.  */
+core_initcall(octeon_setup_debug_uart);
+
+#endif	/* CONFIG_CAVIUM_GDB */
+
+static int octeon_serial_init(void)
+{
+	struct uart_port octeon_port;
+	int enable_uart0;
+	int enable_uart1;
+	int enable_uart2;
+
+#ifdef CONFIG_CAVIUM_OCTEON_2ND_KERNEL
+	/* If we are configured to run as the second of two kernels, disable
+	   uart0 and enable uart1. Uart0 is owned by the first kernel */
+	enable_uart0 = 0;
+	enable_uart1 = 1;
+#else
+	/* We are configured for the first kernel. We'll enable uart0 if the
+	   bootloader told us to use 0, otherwise will enable uart 1 */
+	enable_uart0 = (octeon_get_boot_uart() == 0);
+	enable_uart1 = (octeon_get_boot_uart() == 1);
+	/* Uncomment the following line if you'd like uart1 to be enable as
+	   well as uart 0 when the bootloader tells us to use uart0 */
+	/*
+	enable_uart1 = 1;
+	*/
+#endif
+
+	/* The second port isn't enabled by default because a simple
+	   exec application might be running on another core. Linux control
+	   of the second uart breaks the simple exec debugger interface
+	   through the second uart. */
+
+#if defined(CONFIG_CAVIUM_GDB)
+	/* As a special case forcibly disable uart1 if cavium gdb is in use */
+
+	/* cavium_gdb_active is true if 'cavium_gdb' was detected on
+	   kernel command line */
+	if (cavium_gdb_active)
+		enable_uart1 = 0;
+#endif
+
+	/* Right now CN52XX is the only chip with a third uart */
+	enable_uart2 = OCTEON_IS_MODEL(OCTEON_CN52XX);
+
+	/* These fields are common to all Octeon UARTs */
+	memset(&octeon_port, 0, sizeof(octeon_port));
+	octeon_port.flags = ASYNC_SKIP_TEST | UPF_SHARE_IRQ;
+	octeon_port.iotype = UPIO_MEM;
+	octeon_port.regshift = 3;	/* I/O addresses are every 8 bytes */
+	octeon_port.uartclk = mips_hpt_frequency;
+	octeon_port.fifosize = 64;
+
+	/* Add a ttyS device for hardware uart 0 */
+	if (enable_uart0) {
+		octeon_port.membase = (void *) CVMX_MIO_UARTX_RBR(0);
+		octeon_port.mapbase =
+			CVMX_MIO_UARTX_RBR(0) & ((1ull << 49) - 1);
+		/* Only CN38XXp{1,2} has errata with uart interrupt */
+		if (!OCTEON_IS_MODEL(OCTEON_CN38XX_PASS2))
+			octeon_port.irq = OCTEON_IRQ_UART0;
+		serial8250_register_port(&octeon_port);
+	}
+
+	/* Add a ttyS device for hardware uart 1 */
+	if (enable_uart1) {
+		octeon_port.membase = (void *) CVMX_MIO_UARTX_RBR(1);
+		octeon_port.mapbase =
+			CVMX_MIO_UARTX_RBR(1) & ((1ull << 49) - 1);
+		/* Only CN38XXp{1,2} has errata with uart interrupt */
+		if (!OCTEON_IS_MODEL(OCTEON_CN38XX_PASS2))
+			octeon_port.irq = OCTEON_IRQ_UART1;
+		serial8250_register_port(&octeon_port);
+	}
+
+	/* Add a ttyS device for hardware uart 2 */
+	if (enable_uart2) {
+		octeon_port.membase = (void *) CVMX_MIO_UART2_RBR;
+		octeon_port.mapbase = CVMX_MIO_UART2_RBR & ((1ull << 49) - 1);
+		octeon_port.irq = OCTEON_IRQ_UART2;
+		serial8250_register_port(&octeon_port);
+	}
+
+	return 0;
+}
+
+late_initcall(octeon_serial_init);
diff --git a/arch/mips/cavium-octeon/setup.c b/arch/mips/cavium-octeon/setup.c
new file mode 100644
index 0000000..696fb84
--- /dev/null
+++ b/arch/mips/cavium-octeon/setup.c
@@ -0,0 +1,636 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2007 Cavium Networks
+ * Copyright (C) 2008 Wind River Systems
+ * Copyright (C) 2009 Wind River Systems
+ *   written by Ralf Baechle
+ */
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/delay.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <linux/serial.h>
+#include <linux/types.h>
+#include <linux/string.h>	/* for memset */
+#include <linux/console.h>
+#include <linux/serial.h>
+#include <linux/tty.h>
+#include <linux/time.h>
+#include <linux/serial_core.h>
+#include <linux/serial_8250.h>
+#include <linux/string.h>
+
+#include <asm/reboot.h>
+#include <asm/io.h>
+#include <asm/time.h>
+#include <asm/processor.h>
+#include <asm/smp-ops.h>
+#include <linux/reboot.h>
+#include <asm/system.h>
+#include <asm/irq_cpu.h>
+#include <asm/mipsregs.h>
+#include <asm/bootinfo.h>
+#include "hal.h"
+#include "cvmx-l2c.h"
+#include "cvmx-bootmem.h"
+#include <asm-generic/sections.h>
+
+extern void cvmx_interrupt_rsl_decode(void);
+extern int __cvmx_interrupt_ecc_report_single_bit_errors;
+extern void cvmx_interrupt_rsl_enable(void);
+
+extern struct plat_smp_ops octeon_smp_ops;
+extern void octeon_user_io_init(void);
+#ifdef CONFIG_PCI
+extern void pci_console_init(const char *arg);
+#endif
+extern void putDebugChar(char ch);
+
+#ifdef CONFIG_CAVIUM_OCTEON_BOOTBUS_COMPACT_FLASH
+extern void ebt3000_cf_enable_dma(void);
+#endif
+
+#if CONFIG_CAVIUM_RESERVE32
+extern uint64_t octeon_reserve32_memory;
+#endif
+extern asmlinkage void kernel_entry(void);
+
+static unsigned long long MAX_MEMORY = 512ull << 20;
+
+
+
+/**
+ * Reboot Octeon
+ *
+ * @param command Command to pass to the bootloader. Currently ignored.
+ */
+static void octeon_restart(char *command)
+{
+	/* Disable all watchdogs before soft reset. They don't get cleared */
+#ifdef CONFIG_SMP
+	int cpu;
+	for (cpu = 0; cpu < NR_CPUS; cpu++)
+		if (cpu_online(cpu))
+			cvmx_write_csr(CVMX_CIU_WDOGX(cpu_logical_map(cpu)), 0);
+#else
+	cvmx_write_csr(CVMX_CIU_WDOGX(cvmx_get_core_num()), 0);
+#endif
+
+	mb();
+	while (1)
+		cvmx_write_csr(CVMX_CIU_SOFT_RST, 1);
+}
+
+
+/**
+ * Permanently stop a core.
+ *
+ * @param arg
+ */
+static void octeon_kill_core(void *arg)
+{
+	mb();
+	if (octeon_is_simulation()) {
+		/* The simulator needs the watchdog to stop for dead cores */
+		cvmx_write_csr(CVMX_CIU_WDOGX(cvmx_get_core_num()), 0);
+		/* A break instruction causes the simulator stop a core */
+		asm volatile ("sync\nbreak");
+	}
+}
+
+
+/**
+ * Halt the system
+ */
+static void octeon_halt(void)
+{
+	smp_call_function(octeon_kill_core, NULL, 0);
+	octeon_poweroff();
+	octeon_kill_core(NULL);
+}
+
+
+/**
+ * Handle all the error condition interrupts that might occur.
+ *
+ * @param cpl
+ * @param dev_id
+ * @return
+ */
+static irqreturn_t octeon_rlm_interrupt(int cpl, void *dev_id)
+{
+	cvmx_interrupt_rsl_decode();
+	return IRQ_HANDLED;
+}
+
+
+/**
+ * Return a string representing the system type
+ *
+ * @return
+ */
+const char *get_system_type(void)
+{
+	return octeon_board_type_string();
+}
+
+
+/**
+ * Early entry point for arch setup
+ */
+void __init prom_init(void)
+{
+	const int coreid = cvmx_get_core_num();
+	int i;
+	int argc;
+	struct uart_port octeon_port;
+	int octeon_uart;
+
+	octeon_hal_init();
+	octeon_check_cpu_bist();
+#ifdef CONFIG_CAVIUM_OCTEON_2ND_KERNEL
+	octeon_uart = 1;
+#else
+	octeon_uart = octeon_get_boot_uart();
+#endif
+
+	/* Disable All CIU Interrupts. The ones we need will be enabled later.
+	   Read the SUM register so we know the write completed. */
+	cvmx_write_csr(CVMX_CIU_INTX_EN0((coreid * 2)), 0);
+	cvmx_write_csr(CVMX_CIU_INTX_EN0((coreid * 2 + 1)), 0);
+	cvmx_write_csr(CVMX_CIU_INTX_EN1((coreid * 2)), 0);
+	cvmx_write_csr(CVMX_CIU_INTX_EN1((coreid * 2 + 1)), 0);
+	cvmx_read_csr(CVMX_CIU_INTX_SUM0((coreid * 2)));
+
+#ifdef CONFIG_SMP
+#ifdef CONFIG_CRASH_DUMP
+	octeon_write_lcd("CrashSMP");
+#else
+	octeon_write_lcd("LinuxSMP");
+#endif
+#else
+#ifdef CONFIG_CRASH_DUMP
+	octeon_write_lcd("Crash");
+#else
+	octeon_write_lcd("Linux");
+#endif
+#endif
+
+#ifdef CONFIG_CAVIUM_GDB
+	/* When debugging the linux kernel, force the cores to enter the debug
+	   exception handler to break in.  */
+	if (octeon_get_boot_debug_flag()) {
+		cvmx_write_csr(CVMX_CIU_DINT, 1 << cvmx_get_core_num());
+		cvmx_read_csr(CVMX_CIU_DINT);
+	}
+#endif
+
+	/* BIST should always be enabled when doing a soft reset. L2 Cache
+	   locking for instance is not cleared unless BIST is enabled.
+	   Unfortunately due to a chip errata G-200 for Cn38XX and CN31XX, BIST
+	   msut be disabled on these parts */
+	if (OCTEON_IS_MODEL(OCTEON_CN38XX_PASS2) ||
+	    OCTEON_IS_MODEL(OCTEON_CN31XX))
+		cvmx_write_csr(CVMX_CIU_SOFT_BIST, 0);
+	else
+		cvmx_write_csr(CVMX_CIU_SOFT_BIST, 1);
+
+	/* Default to 64MB in the simulator to speed things up */
+	if (octeon_is_simulation())
+		MAX_MEMORY = 64ull << 20;
+
+	arcs_cmdline[0] = 0;
+	argc = octeon_get_boot_num_arguments();
+	/* The INIT code in Debian rootfs looks for value "0 - 6" in all the
+	   arguments passed for runlevel. And passing "0" for "address" is
+	   valid. Skip the first two arguments, "bootoctlinux address", as not
+	   used by the kernel. */
+	for (i = 2; i < argc; i++) {
+		const char *arg = octeon_get_boot_argument(i);
+		if (strcmp(arg, "ecc_verbose") == 0) {
+			__cvmx_interrupt_ecc_report_single_bit_errors = 1;
+			pr_notice("Reporting of single bit ECC errors is turned on\n");
+		} else if (strlen(arcs_cmdline) + strlen(arg) + 1 <
+			   sizeof(arcs_cmdline) - 1) {
+			strcat(arcs_cmdline, " ");
+			strcat(arcs_cmdline, arg);
+		}
+	}
+
+#ifdef CONFIG_PCI
+	if (strstr(arcs_cmdline, "console=pci"))
+		pci_console_init(strstr(arcs_cmdline, "console=pci") + 8);
+#endif
+
+	if (strstr(arcs_cmdline, "console=") == NULL) {
+#ifdef CONFIG_GDB_CONSOLE
+		strcat(arcs_cmdline, " console=gdb");
+#else
+#ifdef CONFIG_CAVIUM_OCTEON_2ND_KERNEL
+		strcat(arcs_cmdline, " console=ttyS0,115200");
+#else
+		if (octeon_uart == 1)
+			strcat(arcs_cmdline, " console=ttyS1,115200");
+		else
+			strcat(arcs_cmdline, " console=ttyS0,115200");
+#endif
+#endif
+	}
+
+	if (octeon_is_simulation()) {
+		/* The simulator uses a mtdram device pre filled with the
+		   filesystem. Also specify the calibration delay to avoid
+		   calculating it every time */
+		strcat(arcs_cmdline,
+		       " rw root=1f00 lpj=60176 slram=root,0x40000000,+1073741824");
+	}
+
+	mips_hpt_frequency = octeon_get_clock_rate();
+
+	_machine_restart = octeon_restart;
+	_machine_halt = octeon_halt;
+
+	memset(&octeon_port, 0, sizeof(octeon_port));
+	octeon_port.flags = ASYNC_SKIP_TEST | UPF_SHARE_IRQ;
+	octeon_port.iotype = UPIO_MEM;
+	octeon_port.regshift = 3;	/* I/O addresses are every 8 bytes */
+	octeon_port.uartclk = mips_hpt_frequency;	/* Clock rate of the
+							   chip */
+	octeon_port.fifosize = 64;
+	octeon_port.mapbase = 0x0001180000000800ull + (1024 * octeon_uart);
+	octeon_port.membase = cvmx_phys_to_ptr(octeon_port.mapbase);
+#ifdef CONFIG_CAVIUM_OCTEON_2ND_KERNEL
+	octeon_port.line = 0;
+#else
+	octeon_port.line = octeon_uart;
+#endif
+	octeon_port.irq = OCTEON_IRQ_UART0 + octeon_uart;
+	early_serial_setup(&octeon_port);
+/* 
+ *  If KGDB is enabled we need second UART 
+ *  to be functional as early as possible
+ */
+#ifdef CONFIG_KGDB 
+	octeon_uart = !octeon_uart;
+	octeon_port.mapbase = 0x0001180000000800ull + (1024 * octeon_uart);
+	octeon_port.membase = cvmx_phys_to_ptr(octeon_port.mapbase);
+	octeon_port.line = octeon_uart;
+	octeon_port.irq = OCTEON_IRQ_UART0 + octeon_uart;
+	early_serial_setup(&octeon_port);
+#ifdef CONFIG_KGDB_8250_NOMODULE
+	kgdb8250_add_port(octeon_uart, &octeon_port);
+#endif
+#endif 
+
+	octeon_user_io_init();
+	register_smp_ops(&octeon_smp_ops);
+#ifdef CONFIG_KEXEC
+	octeon_kexec_setup();
+	octeon_shutdown_network_hw();
+#endif
+#ifdef CONFIG_CRASH_DUMP
+	octeon_crash_dump_setup();
+#endif
+}
+
+/* constants for memory initialization */
+#define OCTEON_DDR0_BASE    (0x0ULL)
+#define OCTEON_DDR0_SIZE    (0x010000000ULL)
+#define OCTEON_DDR1_BASE    (0x410000000ULL)
+#define OCTEON_DDR1_SIZE    (0x010000000ULL)
+#define OCTEON_DDR2_BASE    (0x020000000ULL)
+#define OCTEON_DDR2_SIZE    (0x3e0000000ULL)
+#define OCTEON_MAX_PHY_MEM_SIZE (16*1024*1024*1024ULL)
+#define OCTEON_LINUX_RESERVED_MEM_NAME    "__tmp_reserved_linux"
+
+void cleanup_phy_mem(void)
+{
+	/* Ensure all memory is cleaned up.
+	 * Assume nothing has been put before the kernel
+	 * and assume that the kernel lands in the DDR0 region
+	 */
+	uint64_t 	freemem;
+	cvmx_sysinfo_t 	*sysinfo;
+	uint64_t 	memory;
+	uint64_t 	kernel_size;
+	uint64_t 	delta;
+	uint64_t 	curr_addr;
+
+	/* get the amount of DRAM on the board */
+	sysinfo = cvmx_sysinfo_get();
+	memory = sysinfo->system_dram_size;
+
+	/* do a few calculations */
+	kernel_size = (uint64_t)__bss_stop - (uint64_t)_text;
+	freemem = cvmx_bootmem_phy_available_mem(0x100000);
+	delta = (memory > freemem ? (memory - freemem) : (freemem - memory));
+
+	if (delta < MAX_MEMORY) {
+		/* we haven't allocated any memory yet = no need to
+		 * continue free'ing
+		 */
+		printk(KERN_NOTICE "...no need to free any memory\n");
+		return;
+	}
+
+	/* calculate the current address which is the next address after
+	 * the end of the kernel, on a boundary of 0x100000 (1MB)
+	 * the shift needs to match the value used in plat_mem_setup()
+	 */
+	curr_addr = (uint64_t)__bss_stop;
+	curr_addr &= 0x7fffffffULL;
+	curr_addr = curr_addr >> 20;
+	curr_addr += 1;
+	curr_addr = curr_addr << 20;
+
+	memory -= kernel_size;
+
+	if (memory <= (OCTEON_DDR0_SIZE - curr_addr)) {
+		__cvmx_bootmem_phy_free(curr_addr, memory, 0);
+	} else {
+		__cvmx_bootmem_phy_free(curr_addr,
+			OCTEON_DDR0_SIZE - curr_addr, 0);
+
+		memory -= (OCTEON_DDR0_SIZE - curr_addr);
+
+		if (memory > OCTEON_DDR1_SIZE) {
+			__cvmx_bootmem_phy_free(OCTEON_DDR1_BASE,
+				OCTEON_DDR1_SIZE, 0);
+			__cvmx_bootmem_phy_free(OCTEON_DDR2_BASE,
+				memory - OCTEON_DDR1_SIZE, 0);
+		} else {
+			__cvmx_bootmem_phy_free(OCTEON_DDR1_BASE, memory, 0);
+		}
+	}
+}
+
+void __init plat_mem_setup(void)
+{
+	uint64_t mem_alloc_size;
+	uint64_t total = 0;
+	int      i;
+
+	/* see if a memory map was already specified */
+	if (boot_mem_map.nr_map > 0) {
+		/* a pre-defined (probably from the user) memory
+		 * map has been already specified
+		 * allocate the memory from those segments
+		 */
+
+		/* determine where the kernel is */
+		uint64_t kernel_start = __pa_symbol(_text);
+		uint64_t kernel_end = __pa_symbol(__bss_stop);
+
+		/* round the end of the kernel up to the next 1MB boundary
+		 * since that is what we allocate as the
+		 * minimum size
+		 */
+		kernel_end = kernel_end >> 20;
+		kernel_end += 1;
+		kernel_end = kernel_end << 20;
+		kernel_end -= 1;
+
+		cvmx_bootmem_lock();
+		for (i=0; i < boot_mem_map.nr_map; i++) {
+			if (boot_mem_map.map[i].type == BOOT_MEM_RAM) {
+				/* see if this segment will fall
+				 * somewhere on the kernel.  If so, attempt
+				 * to resize it so it fits after the
+				 * kernel
+				 */
+				uint64_t pa = __pa(boot_mem_map.map[i].addr);
+				uint64_t sz = boot_mem_map.map[i].size;
+				if (((pa+sz) < kernel_start) ||
+					(pa > kernel_end)) {
+					/* this segment lies outside */
+				} else if ((pa+sz) > kernel_end) {
+					/* this segment goes past the kernel
+					 * just resize it
+					 */
+					boot_mem_map.map[i].addr =
+						kernel_end + 1;
+					boot_mem_map.map[i].size =
+						pa + sz - kernel_end + 1;
+					sz = boot_mem_map.map[i].size;
+				} else {
+					/* this segment cannot be managed */
+					octeon_write_lcd("BAD_MEM=");
+					panic("Unable to allocate memory for " \
+					    "bad segment (%lu @ 0x%08lx)\n",
+					    sz, pa);
+				}
+				total += sz;
+			}
+		}
+		cvmx_bootmem_unlock();
+	} else {
+		cleanup_phy_mem();
+
+		/*
+		 * The Mips memory init uses the first memory location for some memory
+		 * vectors. When SPARSEMEM is in use, it doesn't verify that the size
+		 * is big enough for the final vectors. Making the smallest chuck 4MB
+		 * seems to be enough to consistantly work. This needs to be debugged
+		 * more
+		 */
+		mem_alloc_size = 4 << 20;
+		total = 0;
+		if (mem_alloc_size > MAX_MEMORY)
+			mem_alloc_size = MAX_MEMORY;
+
+		/*
+		 * When allocating memory, we want incrementing addresses from
+		 * bootmem_alloc so the code in add_memory_region can merge regions
+		 * next to each other
+		 */
+
+		cvmx_bootmem_lock();
+		while ((boot_mem_map.nr_map < BOOT_MEM_MAP_MAX) && (total < MAX_MEMORY)) {
+#if defined(CONFIG_64BIT) || defined(CONFIG_64BIT_PHYS_ADDR)
+		int64_t memory =
+			cvmx_bootmem_phy_alloc(mem_alloc_size,
+					       __pa_symbol(kernel_entry), -1,
+					       0x100000,
+					       CVMX_BOOTMEM_FLAG_NO_LOCKING);
+#elif defined(CONFIG_HIGHMEM)
+		int64_t memory =
+			cvmx_bootmem_phy_alloc(mem_alloc_size, 0, 1ull << 31,
+					       0x100000,
+					       CVMX_BOOTMEM_FLAG_NO_LOCKING);
+#else
+		int64_t memory =
+			cvmx_bootmem_phy_alloc(mem_alloc_size, 0, 512 << 20,
+					       0x100000,
+					       CVMX_BOOTMEM_FLAG_NO_LOCKING);
+#endif
+		if (memory >= 0) {
+			/* This function automatically merges address regions
+			   next to each other if they are received in
+			   incrementing order */
+			add_memory_region(memory, mem_alloc_size, BOOT_MEM_RAM);
+			total += mem_alloc_size;
+		} else
+			break;
+		}
+		cvmx_bootmem_unlock();
+	}
+
+#if CONFIG_CAVIUM_RESERVE32
+	/* Now that we've allocated the kernel memory it is safe to free the
+		reserved region. We free it here so that builtin drivers can
+		use the memory */
+	if (octeon_reserve32_memory)
+		cvmx_bootmem_free_named("CAVIUM_RESERVE32");
+#endif /* CONFIG_CAVIUM_RESERVE32 */
+
+	if (total == 0)
+		panic("Unable to allocate memory from cvmx_bootmem_phy_alloc\n");
+}
+
+
+void prom_free_prom_memory(void)
+{
+	cvmx_interrupt_rsl_enable();
+
+	/* Add an interrupt handler for general failures. */
+	if (request_irq(OCTEON_IRQ_RML, octeon_rlm_interrupt, IRQF_SHARED, "RML/RSL",
+			octeon_rlm_interrupt)) {
+	}
+
+	/* This call is here so that it is performed after any TLB
+	   initializations. It needs to be after these in case the
+	   CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB option is set */
+	octeon_hal_setup_reserved32();
+}
+
+static struct octeon_cf_data octeon_cf_data;
+
+static int __init octeon_cf_device_init(void)
+{
+	cvmx_mio_boot_reg_cfgx_t mio_boot_reg_cfg;
+	unsigned long base_ptr, region_base, region_size;
+	struct platform_device *pd;
+	struct resource cf_resources[3];
+	unsigned int num_resources;
+	int i;
+	int ret = 0;
+
+	/* Setup octeon-cf platform device if present. */
+	base_ptr = 0;
+	if (octeon_bootinfo->major_version == 1
+		&& octeon_bootinfo->minor_version >= 1) {
+		if (octeon_bootinfo->compact_flash_common_base_addr)
+			base_ptr =
+				octeon_bootinfo->compact_flash_common_base_addr;
+	} else {
+		base_ptr = 0x1d000800;
+	}
+
+	if (!base_ptr)
+		return ret;
+
+	/* Find CS0 region. */
+	for (i = 0; i < 8; i++) {
+		mio_boot_reg_cfg.u64 = cvmx_read_csr(CVMX_MIO_BOOT_REG_CFGX(i));
+		region_base = mio_boot_reg_cfg.s.base << 16;
+		region_size = (mio_boot_reg_cfg.s.size + 1) << 16;
+		if (mio_boot_reg_cfg.s.en && base_ptr >= region_base
+		    && base_ptr < region_base + region_size)
+			break;
+	}
+	if (i >= 7) {
+		/* i and i + 1 are CS0 and CS1, both must be less than 8. */
+		goto out;
+	}
+	octeon_cf_data.base_region = i;
+	octeon_cf_data.is16bit = mio_boot_reg_cfg.s.width;
+	octeon_cf_data.base_region_bias = base_ptr - region_base;
+	memset(cf_resources, 0, sizeof(cf_resources));
+	num_resources = 0;
+	cf_resources[num_resources].flags	= IORESOURCE_MEM;
+	cf_resources[num_resources].start	= region_base;
+	cf_resources[num_resources].end	= region_base + region_size - 1;
+	num_resources++;
+
+
+	if (!(base_ptr & 0xfffful)) {
+		/*
+		 * Boot loader signals availability of DMA (true_ide
+		 * mode) by setting low order bits of base_ptr to
+		 * zero.
+		 */
+
+		/* Asume that CS1 immediately follows. */
+		mio_boot_reg_cfg.u64 =
+			cvmx_read_csr(CVMX_MIO_BOOT_REG_CFGX(i + 1));
+		region_base = mio_boot_reg_cfg.s.base << 16;
+		region_size = (mio_boot_reg_cfg.s.size + 1) << 16;
+		if (!mio_boot_reg_cfg.s.en)
+			goto out;
+
+		cf_resources[num_resources].flags	= IORESOURCE_MEM;
+		cf_resources[num_resources].start	= region_base;
+		cf_resources[num_resources].end	= region_base + region_size - 1;
+		num_resources++;
+
+		octeon_cf_data.dma_engine = 0;
+		cf_resources[num_resources].flags	= IORESOURCE_IRQ;
+		cf_resources[num_resources].start	= OCTEON_IRQ_BOOTDMA;
+		cf_resources[num_resources].end	= OCTEON_IRQ_BOOTDMA;
+		num_resources++;
+	} else {
+		octeon_cf_data.dma_engine = -1;
+	}
+
+	pd = platform_device_alloc("pata_octeon_cf", -1);
+	if (!pd) {
+		ret = -ENOMEM;
+		goto out;
+	}
+	pd->dev.platform_data = &octeon_cf_data;
+
+	ret = platform_device_add_resources(pd, cf_resources, num_resources);
+	if (ret)
+		goto fail;
+
+	ret = platform_device_add(pd);
+	if (ret)
+		goto fail;
+
+	return ret;
+fail:
+	platform_device_put(pd);
+out:
+	return ret;
+}
+device_initcall(octeon_cf_device_init);
+
+static char *edac_device_names[] = {
+	"co_l2c_edac",
+	"co_lmc_edac",
+	"co_pc_edac",
+};
+
+static int __init edac_devinit(void)
+{
+	struct platform_device *dev;
+	int i, err = 0;
+	char *name;
+
+	for (i = 0; i < ARRAY_SIZE(edac_device_names); i++) {
+		name = edac_device_names[i];
+		dev = platform_device_register_simple(name, -1, NULL, 0);
+		if (IS_ERR(dev)) {
+			pr_err("Registation of %s failed!\n", name);
+		err = PTR_ERR(dev);
+		}
+	}
+
+	return err;
+}
+
+device_initcall(edac_devinit);
diff --git a/arch/mips/cavium-octeon/simulator.c b/arch/mips/cavium-octeon/simulator.c
new file mode 100644
index 0000000..d8e5053
--- /dev/null
+++ b/arch/mips/cavium-octeon/simulator.c
@@ -0,0 +1,30 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2007 Cavium Networks
+ */
+
+
+/**
+ * Octeon Simulator magic printf interface. Generates printf
+ * style output on the simulator console. Format arguments
+ * must all be %ll?. Nothing other than 64bit numbers can
+ * be displayed.
+ *
+ * @param fmt    Format string
+ */
+void octeon_simprintf(const char *fmt, ...)
+{
+	asm volatile ("\
+		      .set mips64\n\
+		      sync\n\
+		      add $25, $0, 6\n\
+		      dli $15,0x8000000feffe0000\n\
+		      dadd $24, $31, $0\n\
+		      jalr $15\n\
+		      dadd $31, $24, $0\n\
+		      .set mips0\n\
+		      " : : );
+}
diff --git a/arch/mips/cavium-octeon/smp.c b/arch/mips/cavium-octeon/smp.c
new file mode 100644
index 0000000..21d3185
--- /dev/null
+++ b/arch/mips/cavium-octeon/smp.c
@@ -0,0 +1,464 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2008 Cavium Networks
+ */
+#include <linux/cpu.h>
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/smp.h>
+#include <linux/interrupt.h>
+#include <linux/kernel_stat.h>
+#include <linux/sched.h>
+#include <linux/module.h>
+#include <asm/mmu_context.h>
+#include <linux/time.h>
+#include <asm/system.h>
+
+#include "cvmx-bootmem.h"
+#include "octeon_boot.h"
+#include "hal.h"
+
+extern void octeon_user_io_init(void);
+
+extern void  __cpuinit oct_synchronise_count_master(void);
+extern void  __cpuinit oct_synchronise_count_slave(void);
+
+volatile unsigned long octeon_processor_boot = 0xff;
+volatile unsigned long octeon_processor_cycle;
+volatile unsigned long octeon_processor_sp;
+volatile unsigned long octeon_processor_gp;
+#ifdef CONFIG_HOTPLUG_CPU
+static unsigned int InitTLBStart_addr;
+#endif
+
+static irqreturn_t mailbox_interrupt(int irq, void *dev_id)
+{
+	const int coreid = cvmx_get_core_num();
+	uint64_t action;
+
+	/* Load the mailbox register to figure out what we're supposed to do */
+	action = cvmx_read_csr(CVMX_CIU_MBOX_CLRX(coreid));
+
+	/* Clear the mailbox to clear the interrupt */
+	cvmx_write_csr(CVMX_CIU_MBOX_CLRX(coreid), action);
+
+	if (action & SMP_CALL_FUNCTION)
+		smp_call_function_interrupt();
+
+	/* Check if we've been told to flush the icache */
+	if (action & SMP_ICACHE_FLUSH)
+		asm volatile ("synci 0($0)\n");
+	return IRQ_HANDLED;
+}
+
+
+/**
+ * Cause the function described by call_data to be executed on the passed
+ * cpu.  When the function has finished, increment the finished field of
+ * call_data.
+ *
+ * @param cpu
+ * @param action
+ */
+static void octeon_send_ipi_single(int cpu, unsigned int action)
+{
+	int coreid = cpu_logical_map(cpu);
+	/*
+	pr_info("SMP: Mailbox send cpu=%d, coreid=%d, action=%u\n", cpu,
+	       coreid, action);
+	*/
+	cvmx_write_csr(CVMX_CIU_MBOX_SETX(coreid), action);
+}
+
+static inline void octeon_send_ipi_mask(cpumask_t mask, unsigned int action)
+{
+	unsigned int i;
+
+	for_each_cpu_mask(i, mask)
+		octeon_send_ipi_single(i, action);
+}
+
+/**
+ * Detect available CPUs, populate phys_cpu_present_map
+ */
+static void octeon_smp_hotplug_setup(void)
+{
+#ifdef CONFIG_HOTPLUG_CPU
+	uint32_t labi_signature;
+
+       labi_signature =
+	   cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
+					   LABI_ADDR_IN_BOOTLOADER +
+					   offsetof(struct linux_app_boot_info,
+						    labi_signature)));
+	if (labi_signature != LABI_SIGNATURE)
+		pr_err("The bootloader version on this board is incorrect\n");
+	InitTLBStart_addr =
+		cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
+				   LABI_ADDR_IN_BOOTLOADER +
+					   offsetof(struct linux_app_boot_info,
+						    InitTLBStart_addr)));
+#endif
+}
+
+static void __cpuinit octeon_smp_setup(void)
+{
+	const int coreid = cvmx_get_core_num();
+	int cpus;
+	int id;
+
+	int core_mask = octeon_get_boot_coremask();
+
+	cpus_clear(phys_cpu_present_map);
+	__cpu_number_map[coreid] = 0;
+	__cpu_logical_map[0] = coreid;
+	cpu_set(0, phys_cpu_present_map);
+
+	cpus = 1;
+	for (id = 0; id < 16; id++) {
+		if ((id != coreid) && (core_mask & (1 << id))) {
+			cpu_set(cpus, phys_cpu_present_map);
+			__cpu_number_map[id] = cpus;
+			__cpu_logical_map[cpus] = id;
+			cpus++;
+		}
+	}
+	cpu_present_map = phys_cpu_present_map;
+
+	octeon_smp_hotplug_setup();
+}
+
+
+/**
+ * Firmware CPU startup hook
+ *
+ * @param cpu
+ * @param idle
+ */
+static void octeon_boot_secondary(int cpu, struct task_struct *idle)
+{
+	int count;
+
+	pr_info("SMP: Booting CPU%02d (CoreId %2d)...", cpu,
+		cpu_logical_map(cpu));
+
+	__sync();
+	octeon_processor_sp = __KSTK_TOS(idle);
+	octeon_processor_gp = (unsigned long)(task_thread_info(idle));
+	__sync();		/* Use sync so all ops are done. This makes the
+				   cycle counter propagate in a more bounded
+				   amount of time */
+	octeon_processor_cycle = octeon_get_cycles();
+	octeon_processor_boot = cpu_logical_map(cpu);
+	mb();
+
+	count = 10000;
+	while (octeon_processor_sp && count) {
+		/* Waiting for processor to get the SP and GP */
+		udelay(1);
+		count--;
+	}
+	if (count == 0)
+		pr_err("Secondary boot timeout\n");
+}
+
+
+/**
+ * After we've done initial boot, this function is called to allow the
+ * board code to clean up state, if needed
+ */
+static void octeon_init_secondary(void)
+{
+	const int coreid = cvmx_get_core_num();
+	cvmx_ciu_intx0_t interrupt_enable;
+
+	unsigned int cur_exception_base;
+#ifdef CONFIG_HOTPLUG_CPU
+	cur_exception_base = cvmx_read64_uint32(
+		CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
+			     LABI_ADDR_IN_BOOTLOADER +
+			     offsetof(struct linux_app_boot_info,
+				      cur_exception_base)));
+	/* cur_exception_base is incremented in bootloader after setting */
+	write_c0_ebase((unsigned int)(cur_exception_base - EXCEPTION_BASE_INCR));
+#endif
+	octeon_check_cpu_bist();
+
+	/*
+	pr_info("SMP: CPU%d (CoreId %lu) started\n", cpu, coreid);
+	*/
+	/* Enable Mailbox interrupts to this core. These are the only
+	   interrupts allowed on line 3 */
+	cvmx_write_csr(CVMX_CIU_MBOX_CLRX(coreid), 0xffffffff);
+	interrupt_enable.u64 = 0;
+	interrupt_enable.s.mbox = 0x3;
+	cvmx_write_csr(CVMX_CIU_INTX_EN0((coreid * 2)), interrupt_enable.u64);
+	cvmx_write_csr(CVMX_CIU_INTX_EN0((coreid * 2 + 1)), 0);
+	cvmx_write_csr(CVMX_CIU_INTX_EN1((coreid * 2)), 0);
+	cvmx_write_csr(CVMX_CIU_INTX_EN1((coreid * 2 + 1)), 0);
+	set_c0_status(0x8c01);	/* Enable core interrupt processing for 2,3 and
+				   7 */
+}
+
+
+/**
+ * Callout to firmware before smp_init
+ *
+ * @param max_cpus
+ */
+void octeon_prepare_cpus(unsigned int max_cpus)
+{
+	cvmx_write_csr(CVMX_CIU_MBOX_CLRX(cvmx_get_core_num()), 0xffffffff);
+	if (request_irq(OCTEON_IRQ_MBOX0, mailbox_interrupt, IRQF_SHARED, "mailbox0",
+		    mailbox_interrupt)) {
+	}
+	if (request_irq(OCTEON_IRQ_MBOX1, mailbox_interrupt, IRQF_SHARED, "mailbox1",
+		    mailbox_interrupt)) {
+	}
+}
+
+
+/**
+ * Last chance for the board code to finish SMP initialization before
+ * the CPU is "online".
+ */
+static void __cpuinit octeon_smp_finish(void)
+{
+#ifdef CONFIG_CAVIUM_GDB
+	unsigned long tmp;
+	/* Have this core enter debug exception handler on MDC0. */
+	asm volatile ("dmfc0 %0, $22\n"
+		"\tori   %0, %0, 0x9100\n"
+		"\tdmtc0 %0, $22\n" : "=r" (tmp));
+#endif
+
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM) || \
+	defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS)
+	octeon_user_io_init();
+#endif
+	/* to generate the first CPU timer interrupt */
+	write_c0_compare(read_c0_count() + mips_hpt_frequency / HZ);
+}
+
+
+/**
+ * Hook for after all CPUs are online
+ */
+static void octeon_cpus_done(void)
+{
+#ifdef CONFIG_CAVIUM_GDB
+	unsigned long tmp;
+	/* Have this core enter debug exception handler on MDC0. */
+	asm volatile ("dmfc0 %0, $22\n"
+		"\tori   %0, %0, 0x9100\n"
+		"\tdmtc0 %0, $22\n" : "=r" (tmp));
+#endif
+}
+
+#ifdef CONFIG_HOTPLUG_CPU
+
+/* State of each CPU. */
+DEFINE_PER_CPU(int, cpu_state) = { 0 };
+
+extern void fixup_irqs(void);
+
+static DEFINE_SPINLOCK(smp_reserve_lock);
+
+static int octeon_cpu_disable(void)
+{
+	unsigned int cpu = smp_processor_id();
+
+	spin_lock(&smp_reserve_lock);
+
+	if (cpu == 0 /* boot_cpuid */) {
+		spin_unlock(&smp_reserve_lock);
+		return -EBUSY;
+	}
+
+	cpu_clear(cpu, cpu_online_map);
+	cpu_clear(cpu, cpu_callin_map);
+	local_irq_disable();
+	fixup_irqs();
+	local_irq_enable();
+
+	flush_cache_all();
+	local_flush_tlb_all();
+
+	spin_unlock(&smp_reserve_lock);
+
+	return 0;
+}
+
+static void octeon_cpu_die(unsigned int cpu)
+{
+	int coreid = cpu_logical_map(cpu);
+	uint32_t avail_coremask;
+	cvmx_bootmem_named_block_desc_t *block_desc;
+
+#ifdef CONFIG_CAVIUM_OCTEON_WATCHDOG
+	/* Disable the watchdog */
+	cvmx_ciu_wdogx_t ciu_wdog;
+	ciu_wdog.u64 = cvmx_read_csr(CVMX_CIU_WDOGX(cpu));
+	ciu_wdog.s.mode = 0;
+	cvmx_write_csr(CVMX_CIU_WDOGX(cpu), ciu_wdog.u64);
+#endif
+
+	while (per_cpu(cpu_state, cpu) != CPU_DEAD)
+		cpu_relax();
+
+	/*
+	 * This is a bit complicated strategics of getting/settig available
+	 * cores mask, copied from bootloader
+	 */
+	/* LINUX_APP_BOOT_BLOCK is initialized in bootoct binary */
+	block_desc = cvmx_bootmem_find_named_block(LINUX_APP_BOOT_BLOCK_NAME);
+
+	if (!block_desc) {
+		avail_coremask =
+			cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
+						   LABI_ADDR_IN_BOOTLOADER +
+						   offsetof
+						   (struct linux_app_boot_info,
+						    avail_coremask)));
+	} else {		       /* alternative, already initialized */
+	       avail_coremask =
+		   cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
+						   block_desc->base_addr +
+						  AVAIL_COREMASK_OFFSET_IN_LINUX_APP_BOOT_BLOCK));
+	}
+
+	avail_coremask |= 1 << coreid;
+
+	/* Setting avail_coremask for bootoct binary */
+	if (!block_desc) {
+		cvmx_write64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
+						LABI_ADDR_IN_BOOTLOADER +
+						offsetof(struct linux_app_boot_info,
+							 avail_coremask)),
+				   avail_coremask);
+	} else {
+		cvmx_write64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
+						block_desc->base_addr +
+						AVAIL_COREMASK_OFFSET_IN_LINUX_APP_BOOT_BLOCK),
+				   avail_coremask);
+	}
+
+	printk(KERN_INFO "Reset core %d. Available Coremask = %x \n", coreid,
+	       avail_coremask);
+	cvmx_write_csr(CVMX_CIU_PP_RST, 1 << coreid);
+	cvmx_write_csr(CVMX_CIU_PP_RST, 0);
+}
+
+void play_dead(void)
+{
+	int coreid = cvmx_get_core_num();
+
+	idle_task_exit();
+	octeon_processor_boot = 0xff;
+	per_cpu(cpu_state, coreid) = CPU_DEAD;
+
+	while (1)	/* core will be reset here */
+		;
+}
+
+extern void kernel_entry(unsigned long arg1, ...);
+
+static void start_after_reset(void)
+{
+	kernel_entry(0, 0, 0);  /* set a2 = 0 for secondary core */
+}
+
+int octeon_update_boot_vector(unsigned int cpu)
+{
+
+	int coreid = cpu_logical_map(cpu);
+	unsigned int avail_coremask;
+	cvmx_bootmem_named_block_desc_t *block_desc;
+	struct boot_init_vector *boot_vect =
+		(struct boot_init_vector *) cvmx_phys_to_ptr(0x0 +
+						  BOOTLOADER_BOOT_VECTOR);
+
+	block_desc = cvmx_bootmem_find_named_block(LINUX_APP_BOOT_BLOCK_NAME);
+
+	if (!block_desc) {
+		avail_coremask =
+			cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
+					   LABI_ADDR_IN_BOOTLOADER +
+						offsetof(struct linux_app_boot_info,
+						avail_coremask)));
+	} else {		       /* alternative, already initialized */
+	       avail_coremask =
+		   cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
+						   block_desc->base_addr +
+						   AVAIL_COREMASK_OFFSET_IN_LINUX_APP_BOOT_BLOCK));
+	}
+
+	if (!(avail_coremask & (1 << coreid))) {
+		/* core not available, assume, that catched by simple-executive */
+		cvmx_write_csr(CVMX_CIU_PP_RST, 1 << coreid);
+		cvmx_write_csr(CVMX_CIU_PP_RST, 0);
+	}
+
+	boot_vect[coreid].app_start_func_addr = (uint32_t) start_after_reset;
+	boot_vect[coreid].code_addr = InitTLBStart_addr;
+
+	CVMX_SYNC;
+
+	cvmx_write_csr(CVMX_CIU_NMI, (1 << coreid) & avail_coremask);
+
+	return 0;
+}
+
+static int __cpuinit octeon_cpu_callback(struct notifier_block *nfb,
+	unsigned long action, void *hcpu)
+{
+	unsigned int cpu = (unsigned long)hcpu;
+
+	switch (action) {
+	case CPU_UP_PREPARE:
+		octeon_update_boot_vector(cpu);
+		break;
+	case CPU_ONLINE:
+		printk(KERN_INFO "Cpu %d online\n", cpu);
+		break;
+	case CPU_DEAD:
+		break;
+	}
+
+	return NOTIFY_OK;
+}
+
+static struct notifier_block __cpuinitdata octeon_cpu_notifier = {
+	.notifier_call = octeon_cpu_callback,
+};
+
+static int __cpuinit register_cavium_notifier(void)
+{
+	register_hotcpu_notifier(&octeon_cpu_notifier);
+
+	return 0;
+}
+
+late_initcall(register_cavium_notifier);
+
+#endif  /* CONFIG_HOTPLUG_CPU */
+
+struct plat_smp_ops octeon_smp_ops = {
+	.send_ipi_single	= octeon_send_ipi_single,
+	.send_ipi_mask		= octeon_send_ipi_mask,
+	.init_secondary		= octeon_init_secondary,
+	.smp_finish		= octeon_smp_finish,
+	.cpus_done		= octeon_cpus_done,
+	.boot_secondary		= octeon_boot_secondary,
+	.smp_setup		= octeon_smp_setup,
+	.prepare_cpus		= octeon_prepare_cpus,
+#ifdef CONFIG_HOTPLUG_CPU
+	.cpu_disable		= octeon_cpu_disable,
+	.cpu_die		= octeon_cpu_die,
+#endif
+};
+
+EXPORT_SYMBOL(__cpu_logical_map);
diff --git a/arch/mips/cavium-octeon/sync-octeon.c b/arch/mips/cavium-octeon/sync-octeon.c
new file mode 100644
index 0000000..3842157
--- /dev/null
+++ b/arch/mips/cavium-octeon/sync-octeon.c
@@ -0,0 +1,38 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2007 by Ralf Baechle
+ * Copyright (C) 2004-2009 Cavium Networks
+ */
+#include <linux/clocksource.h>
+#include <linux/init.h>
+
+#include <asm/time.h>
+
+static cycle_t octeon_cvmcount_read(void)
+{
+	return read_c0_cvmcount();
+}
+
+static struct clocksource clocksource_mips = {
+	.name		= "OCTEON_CVMCOUNT",
+	.read		= octeon_cvmcount_read,
+	.mask		= CLOCKSOURCE_MASK(64),
+	.flags		= CLOCK_SOURCE_IS_CONTINUOUS,
+};
+
+void __init plat_time_init(void)
+{
+	clocksource_mips.rating = 300;
+	clocksource_set_clock(&clocksource_mips, mips_hpt_frequency);
+	clocksource_register(&clocksource_mips);
+}
+
+
+
+
+
+
+
diff --git a/arch/mips/cavium-octeon/userio.c b/arch/mips/cavium-octeon/userio.c
new file mode 100644
index 0000000..cb4bc8d
--- /dev/null
+++ b/arch/mips/cavium-octeon/userio.c
@@ -0,0 +1,252 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2007 Cavium Networks
+ */
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/irq.h>
+#include <linux/interrupt.h>
+#include <linux/serial.h>
+#include <linux/types.h>
+#include <linux/string.h>	/* for memset */
+#include <linux/console.h>
+#include <linux/serial.h>
+#include <linux/tty.h>
+#include <linux/time.h>
+#include <linux/serial_core.h>
+#include <linux/reboot.h>
+#include <linux/io.h>
+
+#include <asm/processor.h>
+#include <asm/system.h>
+#include <asm/irq_cpu.h>
+#include <asm/mipsregs.h>
+#include <asm/bootinfo.h>
+
+#include "hal.h"
+
+
+/**
+ *
+ * @return
+ */
+void octeon_user_io_init(void)
+{
+	octeon_cvmemctl_t cvmmemctl;
+	cvmx_iob_fau_timeout_t fau_timeout;
+	cvmx_pow_nw_tim_t nm_tim;
+	uint64_t cvmctl;
+
+	/* Get the current settings for CP0_CVMMEMCTL_REG */
+	cvmmemctl.u64 = __read_64bit_c0_register($11, 7);
+
+	cvmmemctl.s.dismarkwblongto = 1;	/* R/W If set, marked
+						   write-buffer entries time
+						   out the same as as other
+						   entries; if clear, marked
+						   write-buffer entries use the
+						   maximum timeout. */
+	cvmmemctl.s.dismrgclrwbto = 0;	/* R/W If set, a merged store does not
+					   clear the write-buffer entry timeout
+					   state. */
+	cvmmemctl.s.iobdmascrmsb = 0;	/* R/W Two bits that are the MSBs of
+					   the resultant CVMSEG LM word
+					   location for an IOBDMA. The other 8
+					   bits come from the SCRADDR field of
+					   the IOBDMA. */
+	cvmmemctl.s.syncwsmarked = 0;	/* R/W If set, SYNCWS and SYNCS only
+					   order marked stores; if clear,
+					   SYNCWS and SYNCS only order unmarked
+					   stores. SYNCWSMARKED has no effect
+					   when DISSYNCWS is set. */
+	cvmmemctl.s.dissyncws = 0;	/* R/W If set, SYNCWS acts as SYNCW and
+					   SYNCS acts as SYNC. */
+	if (OCTEON_IS_MODEL(OCTEON_CN38XX_PASS2))
+		cvmmemctl.s.diswbfst = 1;	/* R/W If set, no stall happens
+						   on write buffer full. */
+	else
+		cvmmemctl.s.diswbfst = 0;	/* R/W If set, no stall happens
+						   on write buffer full. */
+	cvmmemctl.s.xkmemenas = 0;	/* R/W If set (and SX set),
+					   supervisor-level loads/stores can
+					   use XKPHYS addresses with VA<48>==0 */
+#ifdef CONFIG_CAVIUM_OCTEON_USER_MEM
+	cvmmemctl.s.xkmemenau = 1;	/* R/W If set (and UX set), user-level
+					   loads/stores can use XKPHYS
+					   addresses with VA<48>==0 */
+#else
+	cvmmemctl.s.xkmemenau = 0;
+#endif
+	cvmmemctl.s.xkioenas = 0;	/* R/W If set (and SX set),
+					   supervisor-level loads/stores can
+					   use XKPHYS addresses with VA<48>==1 */
+#ifdef CONFIG_CAVIUM_OCTEON_USER_IO
+	cvmmemctl.s.xkioenau = 1;	/* R/W If set (and UX set), user-level
+					   loads/stores can use XKPHYS
+					   addresses with VA<48>==1 */
+#else
+	cvmmemctl.s.xkioenau = 0;
+#endif
+	cvmmemctl.s.allsyncw = 0;	/* R/W If set, all stores act as SYNCW
+					   (NOMERGE must be set when this is
+					   set) RW, reset to 0. */
+	cvmmemctl.s.nomerge = 0;	/* R/W If set, no stores merge, and all
+					   stores reach the coherent bus in
+					   order. */
+	cvmmemctl.s.didtto = 0;	/* R/W Selects the bit in the counter used for
+				   DID time-outs 0 = 231, 1 = 230, 2 = 229, 3 =
+				   214. Actual time-out is between 1 and 2
+				   this interval. For example, with DIDTTO=3,
+				   expiration interval is between 16K and 32K. */
+	cvmmemctl.s.csrckalwys = 0;	/* R/W If set, the (mem) CSR clock
+					   never turns off. */
+	cvmmemctl.s.mclkalwys = 0;	/* R/W If set, mclk never turns off. */
+	cvmmemctl.s.wbfltime = 0;	/* R/W Selects the bit in the counter
+					   used for write buffer flush
+					   time-outs (WBFLT+11) is the bit
+					   position in an internal counter used
+					   to determine expiration. The write
+					   buffer expires between 1 and 2
+					   this interval. For example, with
+					   WBFLT = 0, a write buffer expires
+					   between 2K and 4K cycles after the
+					   write buffer entry is allocated. */
+	cvmmemctl.s.istrnol2 = 0;	/* R/W If set, do not put Istream in
+					   the L2 cache. */
+	cvmmemctl.s.wbthresh = 10;	/* R/W The write buffer threshold. */
+#if CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE > 0
+	cvmmemctl.s.cvmsegenak = 1;	/* R/W If set, CVMSEG is available for
+					   loads/stores in kernel/debug mode. */
+#else
+	cvmmemctl.s.cvmsegenak = 0;
+#endif
+	cvmmemctl.s.cvmsegenas = 0;	/* R/W If set, CVMSEG is available for
+					   loads/stores in supervisor mode. */
+	cvmmemctl.s.cvmsegenau = 0;	/* R/W If set, CVMSEG is available for
+					   loads/stores in user mode. */
+	cvmmemctl.s.lmemsz = CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE;
+	/* R/W Size of local memory in cache blocks, 54 (6912 bytes) is max
+	   legal value. */
+
+	if (smp_processor_id() == 0)
+		pr_notice("CVMSEG size: %d cache lines (%d bytes)\n",
+			  CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE,
+			  CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE * 128);
+
+	__write_64bit_c0_register($11, 7, cvmmemctl.u64);
+
+	/* Move the performance counter interrupts to IRQ 6 */
+	cvmctl = __read_64bit_c0_register($9, 7);
+	cvmctl &= ~(7 << 7);
+	cvmctl |= 6 << 7;
+	__write_64bit_c0_register($9, 7, cvmctl);
+
+	/* Set a default for the hardware timeouts */
+	fau_timeout.u64 = 0;
+	fau_timeout.s.tout_val = 0xfff;
+	fau_timeout.s.tout_enb = 0;	/* Disable tagwait FAU timeout */
+	cvmx_write_csr(CVMX_IOB_FAU_TIMEOUT, fau_timeout.u64);
+
+	nm_tim.u64 = 0;
+	nm_tim.s.nw_tim = 3;	/* 4096 cycles */
+	cvmx_write_csr(CVMX_POW_NW_TIM, nm_tim.u64);
+
+	write_c0_cacheerr(0);
+	write_c0_derraddr1(0);
+}
+
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS) || \
+	defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
+
+void cavium_prepare_arch_switch(struct task_struct *next)
+{
+	struct task_struct *group_leader = next->group_leader;
+	octeon_cvmemctl_t cvmmemctl;
+	cvmmemctl.u64 = __read_64bit_c0_register($11, 7);
+
+#if defined(CONFIG_CAVIUM_OCTEON_USER_MEM_PER_PROCESS)
+	cvmmemctl.s.xkmemenau = test_tsk_thread_flag(group_leader,
+						     TIF_XKPHYS_MEM_EN) ? 1 : 0;
+#endif
+
+#if defined(CONFIG_CAVIUM_OCTEON_USER_IO_PER_PROCESS)
+	cvmmemctl.s.xkioenau = test_tsk_thread_flag(group_leader,
+						    TIF_XKPHYS_IO_EN) ? 1 : 0;
+#endif
+	__write_64bit_c0_register($11, 7, cvmmemctl.u64);
+}
+
+static struct task_struct *xkphys_get_task(pid_t pid)
+{
+	struct task_struct *task, *group_leader;
+
+	read_lock(&tasklist_lock);
+	task = find_task_by_vpid(pid);
+	if (!task) {
+		read_unlock(&tasklist_lock);
+		return NULL;
+	}
+	group_leader = task->group_leader;
+	get_task_struct(group_leader);
+
+	read_unlock(&tasklist_lock);
+	return group_leader;
+}
+
+int xkphys_usermem_read(long pid)
+{
+	struct task_struct *task;
+	int io, mem;
+
+	task = xkphys_get_task(pid);
+	if (!task)
+		return -ESRCH;
+	io = test_tsk_thread_flag(task, TIF_XKPHYS_IO_EN);
+	mem = test_tsk_thread_flag(task, TIF_XKPHYS_MEM_EN);
+	put_task_struct(task);
+	return (io ? 2 : 0) | (mem ? 1 : 0);
+}
+
+int xkphys_usermem_write(long pid, int value)
+{
+	struct task_struct *task, *group_leader;
+
+	task = xkphys_get_task(pid);
+	group_leader = task->group_leader;
+
+	if (!task)
+		return -ESRCH;
+
+	if (task->uid != current->euid &&
+			task->euid != current->euid &&
+			!(capable(CAP_SYS_RAWIO) || value == 0)) {
+		put_task_struct(task);
+		return -EPERM;
+	}
+
+	if (value & 1)
+		set_tsk_thread_flag(group_leader, TIF_XKPHYS_MEM_EN);
+	else
+		clear_tsk_thread_flag(group_leader, TIF_XKPHYS_MEM_EN);
+
+	if (value & 2)
+		set_tsk_thread_flag(group_leader, TIF_XKPHYS_IO_EN);
+	else
+		clear_tsk_thread_flag(group_leader, TIF_XKPHYS_IO_EN);
+
+	preempt_disable();
+
+	/* If we are adjusting ourselves, make the change effective
+	   immediatly.  */
+	if (group_leader == current->group_leader)
+		cavium_prepare_arch_switch(current);
+
+	preempt_enable();
+
+	put_task_struct(task);
+	return 0;
+}
+#endif
diff --git a/arch/mips/cavium-octeon/watchdog.c b/arch/mips/cavium-octeon/watchdog.c
new file mode 100644
index 0000000..ab4557a
--- /dev/null
+++ b/arch/mips/cavium-octeon/watchdog.c
@@ -0,0 +1,300 @@
+/*
+ *   Octeon Watchdog driver
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2007 Cavium Networks
+ */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/ip.h>
+#include <linux/string.h>
+#include <linux/smp.h>
+#include <linux/cpumask.h>
+#include <linux/delay.h>
+#include "hal.h"
+
+extern void octeon_watchdog_nmi(void);
+
+int timeout;		/* A zero value is replaced with the max timeout */
+module_param(timeout, int, 0444);
+MODULE_PARM_DESC(timeout,
+		 " Watchdog timeout in milliseconds. First timeout causes a poke, \n"
+		 "\t\tthe second causes an NMI, and the third causes a soft reset.");
+
+/**
+ * Poke the watchdog when an interrupt is received
+ *
+ * @param cpl
+ * @param dev_id
+ * @param regs
+ *
+ * @return
+ */
+static irqreturn_t watchdog_poke_irq(int cpl, void *dev_id)
+{
+	/* We're alive, poke the watchdog */
+	/*
+	printk("Poking watchdog on core %d\n", cvmx_get_core_num());
+	*/
+	cvmx_write_csr(CVMX_CIU_PP_POKEX(cvmx_get_core_num()), 1);
+	return IRQ_HANDLED;
+}
+
+
+/**
+ * In the NMI handler we assume everything is broken. This
+ * routine is used to send a raw byte out the serial port
+ * with as minimal dependencies as possible.
+ *
+ * @param uart_index Uart to write to (0 or 1)
+ * @param ch         Byte to write
+ */
+static inline void uart_write_byte(int uart_index, uint8_t ch)
+{
+	cvmx_uart_lsr_t lsrval;
+
+	/* Spin until there is room */
+	do {
+		lsrval.u64 = cvmx_read_csr(CVMX_MIO_UARTX_LSR(uart_index));
+	} while (lsrval.s.thre == 0);
+
+	/* Write the byte */
+	cvmx_write_csr(CVMX_MIO_UARTX_THR(uart_index), ch);
+}
+
+
+/**
+ * Write a string to the uart
+ *
+ * @param uart_index Uart to use (0 or 1)
+ * @param str        String to write
+ */
+static void uart_write_string(int uart_index, const char *str)
+{
+	/* Just loop writing one byte at a time */
+	while (*str)
+		uart_write_byte(uart_index, *str++);
+}
+
+
+/**
+ * Write a hex number out of the uart
+ *
+ * @param uart_index Uart to use (0 or 1)
+ * @param value      Number to display
+ * @param digits     Number of digits to print (1 to 16)
+ */
+static void uart_write_hex(int uart_index, uint64_t value, int digits)
+{
+	int d;
+	int v;
+	for (d = 0; d < digits; d++) {
+		v = (value >> ((digits - d - 1) * 4)) & 0xf;
+		if (v >= 10)
+			uart_write_byte(0, 'a' + v - 10);
+		else
+			uart_write_byte(0, '0' + v);
+	}
+}
+
+
+/**
+ * NMI stage 3 handler. NMIs are handled in the following manner:
+ * 1) The first NMI handler enables CVMSEG and transfers from
+ * the bootbus region into normal memory. It is careful to not
+ * destroy any registers.
+ * 2) The second stage handler uses CVMSEG to save the registers
+ * and create a stack for C code. It then calls the third level
+ * handler with one argument, a pointer to the register values.
+ * 3) The third, and final, level handler is the following C
+ * function that prints out some useful infomration.
+ *
+ * @param reg    Pointer to register state before the NMI
+ */
+void octeon_watchdog_nmi_stage3(uint64_t reg[32])
+{
+	const char *reg_name[] =
+		{ "$0", "at", "v0", "v1", "a0", "a1", "a2", "a3",
+		"a4", "a5", "a6", "a7", "t0", "t1", "t2", "t3",
+		"s0", "s1", "s2", "s3", "s4", "s5", "s6", "s7",
+		"t8", "t9", "k0", "k1", "gp", "sp", "s8", "ra"
+	};
+	uint64_t i;
+	/* Save status and cause early to get them before any changes might
+	   happen */
+	uint64_t cp0_cause = read_c0_cause();
+	uint64_t cp0_status = read_c0_status();
+
+	/* Delay so all cores output is jumbled */
+	cvmx_wait(100000000ull * cvmx_get_core_num());
+
+	uart_write_string(0, "\r\n*** NMI Watchdog interrupt on Core 0x");
+	uart_write_hex(0, cvmx_get_core_num(), 1);
+	uart_write_string(0, " ***\r\n");
+	for (i = 0; i < 32; i++) {
+		uart_write_string(0, "\t");
+		uart_write_string(0, reg_name[i]);
+		uart_write_string(0, "\t0x");
+		uart_write_hex(0, reg[i], 16);
+		if (i & 1)
+			uart_write_string(0, "\r\n");
+	}
+	uart_write_string(0, "\tepc\t0x");
+	uart_write_hex(0, read_c0_epc(), 16);
+	uart_write_string(0, "\r\n");
+
+	uart_write_string(0, "\tstatus\t0x");
+	uart_write_hex(0, cp0_status, 16);
+	uart_write_string(0, "\tcause\t0x");
+	uart_write_hex(0, cp0_cause, 16);
+	uart_write_string(0, "\r\n");
+
+	uart_write_string(0, "\tsum0\t0x");
+	uart_write_hex(0,
+		       cvmx_read_csr(CVMX_CIU_INTX_SUM0
+				     (cvmx_get_core_num() * 2)), 16);
+	uart_write_string(0, "\ten0\t0x");
+	uart_write_hex(0,
+		       cvmx_read_csr(CVMX_CIU_INTX_EN0
+				     (cvmx_get_core_num() * 2)), 16);
+	uart_write_string(0, "\r\n");
+#if 0
+	uart_write_string(0, "Code around epc\r\n");
+	clear_c0_status(0x00400004);
+	for (i = read_c0_epc() - 16; i < read_c0_epc() + 20; i += 4) {
+		uart_write_string(0, "\t0x");
+		uart_write_hex(0, i, 16);
+		uart_write_string(0, "\t");
+		uart_write_hex(0, *(uint32_t *) i, 16);
+		uart_write_string(0, "\r\n");
+	}
+#endif
+#if 0
+	uart_write_string(0, "TLB\r\n");
+	for (i = 0; i < 64; i++) {
+		write_c0_index(i);
+		asm volatile ("tlbr");
+		uart_write_string(0, "\tHi 0x");
+		uart_write_hex(0, read_c0_entryhi(), 16);
+		uart_write_string(0, "\tPageMask 0x");
+		uart_write_hex(0, read_c0_pagemask(), 16);
+		uart_write_string(0, "\tLo0 0x");
+		uart_write_hex(0, read_c0_entrylo0(), 16);
+		uart_write_string(0, "\tLo1 0x");
+		uart_write_hex(0, read_c0_entrylo1(), 16);
+		uart_write_string(0, "\r\n");
+	}
+#endif
+	uart_write_string(0, "*** Chip soft reset soon ***\r\n");
+}
+
+
+static void setup_interrupt(int cpu, unsigned long threshold)
+{
+	cvmx_ciu_wdogx_t ciu_wdog;
+	int core;
+	unsigned int irq;
+
+#ifdef CONFIG_SMP
+	core = cpu_logical_map(cpu);
+#else
+	core = cvmx_get_core_num();
+#endif
+
+	irq = OCTEON_IRQ_WDOG0 + core;
+	if (request_irq(irq, watchdog_poke_irq, IRQF_SHARED,
+		    "watchdog", watchdog_poke_irq)) {
+		panic("watchdog couldn't obtain irq %u", irq);
+	}
+
+#ifdef CONFIG_SMP
+	/* Set the affinity to this cpu. */
+	irq_set_affinity(irq, cpumask_of_cpu(cpu));
+#endif
+	/* Poke the watchdog to clear out its state */
+	cvmx_write_csr(CVMX_CIU_PP_POKEX(core), 1);
+
+	/* Finally enable the watchdog now that all handlers are installed */
+	ciu_wdog.u64 = 0;
+	ciu_wdog.s.len = threshold;
+	ciu_wdog.s.mode = 3;	/* 3 = Interrupt + NMI + Soft-Reset */
+	cvmx_write_csr(CVMX_CIU_WDOGX(core), ciu_wdog.u64);
+}
+
+/**
+ * Module/ driver initialization.
+ *
+ * @return Zero on success
+ */
+static int __init watchdog_init(void)
+{
+	uint64_t threshold;
+	int i;
+	int cpu;
+
+	/* Watchdog time expiration length = The 16 bits of LEN represent the
+	   most significant bits of a 24 bit decrementer that decrements every
+	   256 cycles. */
+	if (timeout)
+		threshold = timeout * octeon_get_clock_rate() / 1000 >> (8 + 8);
+	else {
+		threshold = 65535;
+		timeout =
+			(65535ull << (8 + 8)) * 1000 / octeon_get_clock_rate();
+	}
+	if ((threshold < 10) || (threshold >= 65536)) {
+		printk("Illegal watchdog timeout. Timeout must be between %u and %u.\n", (int) ((10ull << (8 + 8)) * 1000 / octeon_get_clock_rate()), (int) ((65535ull << (8 + 8)) * 1000 / octeon_get_clock_rate()));
+		return -1;
+	}
+
+	/* Install the NMI handler */
+	for (i = 0; i < 16; i++) {
+		uint64_t *ptr = (uint64_t *) octeon_watchdog_nmi;
+		cvmx_write_csr(CVMX_MIO_BOOT_LOC_ADR, i * 8);
+		cvmx_write_csr(CVMX_MIO_BOOT_LOC_DAT, ptr[i]);
+	}
+	cvmx_write_csr(CVMX_MIO_BOOT_LOC_CFGX(0), 0x81fc0000);
+
+	for_each_online_cpu(cpu)
+		setup_interrupt(cpu, threshold);
+
+	printk("Octeon watchdog driver loaded with a timeout of %d ms.\n",
+	       timeout);
+	return 0;
+}
+
+
+/**
+ * Module / driver shutdown
+ */
+static void __exit watchdog_cleanup(void)
+{
+	int cpu;
+	preempt_disable();
+	for (cpu = 0; cpu < NR_CPUS; cpu++) {
+		if (cpu_online(cpu)) {
+#ifdef CONFIG_SMP
+			int core = cpu_logical_map(cpu);
+#else
+			int core = cvmx_get_core_num();
+#endif
+			/* Disable the watchdog */
+			cvmx_write_csr(CVMX_CIU_WDOGX(core), 0);
+			/* Free the interrupt handler */
+			free_irq(OCTEON_IRQ_WDOG0 + core, watchdog_poke_irq);
+		}
+	}
+	preempt_enable();
+
+}
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Cavium Networks <support@caviumnetworks.com>");
+MODULE_DESCRIPTION("Cavium Networks Octeon Watchdog driver.");
+module_init(watchdog_init);
+module_exit(watchdog_cleanup);
diff --git a/arch/mips/cavium-octeon/watchdog_nmi.S b/arch/mips/cavium-octeon/watchdog_nmi.S
new file mode 100644
index 0000000..8861d29
--- /dev/null
+++ b/arch/mips/cavium-octeon/watchdog_nmi.S
@@ -0,0 +1,96 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2007 Cavium Networks
+ */
+#include <asm/asm.h>
+#include <asm/mipsregs.h>
+#include <asm/addrspace.h>
+#include <asm/regdef.h>
+#include <asm/stackframe.h>
+
+#define CP0_CVMMEMCTL $11,7
+
+	.text
+	.set 	push
+	.set 	noreorder
+	.set 	noat
+        NESTED(octeon_watchdog_nmi, PT_SIZE, sp)
+	// For the next few instructions running the debugger may cause
+	// corruption of k0 in the saved registers. Since we're about to
+	// crash, nobody probably cares.
+        dmtc0	k0, CP0_DESAVE			// Save K0 into the debug
+						//  scratch register
+	dmfc0	k0, CP0_CVMMEMCTL		// Use K0 to do a
+						//  read/modify/write of
+						//  CVMMEMCTL
+	dins	k0, $0, 0, 6			// Clear out the size of CVMSEG
+	ori	k0, 54				// Set CVMSEG to its largest
+						//  value
+	dmtc0	k0, CP0_CVMMEMCTL		// Store the CVMMEMCTL value
+	PTR_LA	k0, octeon_watchdog_nmi_stage2	// Load the address of the
+						//  second stage handler
+	jr	k0				// Jump to the second stage
+						//  handler
+	 dmfc0	k0, CP0_DESAVE			// Restore K0 from DESAVE
+						//  (delay slot)
+	.set pop
+        END(octeon_watchdog_nmi)
+
+#define SAVE_REG(r)	sd $r, -32768+6912-(32-r)*8($0)
+
+        NESTED(octeon_watchdog_nmi_stage2, PT_SIZE, sp)
+	.set 	push
+	.set 	noreorder
+	.set 	noat
+	// Save all regosters to the top CVMSEG. This
+	// shouldn't corrupt any state used by the kernel. Also
+	// all registers should have the value right before the NMI.
+	SAVE_REG(0)
+	SAVE_REG(1)
+	SAVE_REG(2)
+	SAVE_REG(3)
+	SAVE_REG(4)
+	SAVE_REG(5)
+	SAVE_REG(6)
+	SAVE_REG(7)
+	SAVE_REG(8)
+	SAVE_REG(9)
+	SAVE_REG(10)
+	SAVE_REG(11)
+	SAVE_REG(12)
+	SAVE_REG(13)
+	SAVE_REG(14)
+	SAVE_REG(15)
+	SAVE_REG(16)
+	SAVE_REG(17)
+	SAVE_REG(18)
+	SAVE_REG(19)
+	SAVE_REG(20)
+	SAVE_REG(21)
+	SAVE_REG(22)
+	SAVE_REG(23)
+	SAVE_REG(24)
+	SAVE_REG(25)
+	SAVE_REG(26)
+	SAVE_REG(27)
+	SAVE_REG(28)
+	SAVE_REG(29)
+	SAVE_REG(30)
+	SAVE_REG(31)
+	li	sp, -32768+6912-32*8		// Set the stack to begin
+						// right below the registers
+	PTR_LA	a0, octeon_watchdog_nmi_stage3	// Load the address of the
+						// third stage handler
+	jal	a0				// Call the third stage
+						// handler
+	 move	a0, sp				// a0 is the address of the
+						// saved registers
+1:	b	1b				// Loop forvever if we get
+						// here.
+	 nop
+	.set pop
+        END(octeon_watchdog_nmi_stage2)
+
diff --git a/arch/mips/configs/cavium-octeon_defconfig b/arch/mips/configs/cavium-octeon_defconfig
new file mode 100644
index 0000000..a15aa8f
--- /dev/null
+++ b/arch/mips/configs/cavium-octeon_defconfig
@@ -0,0 +1,1370 @@
+#
+# Automatically generated make config: don't edit
+# Linux kernel version: 2.6.27-rc6
+# Fri Sep 26 17:18:11 2008
+#
+CONFIG_MIPS=y
+
+#
+# Machine selection
+#
+CONFIG_ZONE_DMA=y
+# CONFIG_MACH_ALCHEMY is not set
+# CONFIG_BASLER_EXCITE is not set
+# CONFIG_BCM47XX is not set
+# CONFIG_MIPS_COBALT is not set
+# CONFIG_MACH_DECSTATION is not set
+# CONFIG_MACH_JAZZ is not set
+# CONFIG_LASAT is not set
+# CONFIG_LEMOTE_FULONG is not set
+# CONFIG_MIPS_MALTA is not set
+# CONFIG_MIPS_SIM is not set
+# CONFIG_MARKEINS is not set
+# CONFIG_MACH_VR41XX is not set
+# CONFIG_PNX8550_JBS is not set
+# CONFIG_PNX8550_STB810 is not set
+# CONFIG_PMC_MSP is not set
+# CONFIG_PMC_YOSEMITE is not set
+# CONFIG_SGI_IP22 is not set
+# CONFIG_SGI_IP27 is not set
+# CONFIG_SGI_IP28 is not set
+# CONFIG_SGI_IP32 is not set
+# CONFIG_SIBYTE_CRHINE is not set
+# CONFIG_SIBYTE_CARMEL is not set
+# CONFIG_SIBYTE_CRHONE is not set
+# CONFIG_SIBYTE_RHONE is not set
+# CONFIG_SIBYTE_SWARM is not set
+# CONFIG_SIBYTE_LITTLESUR is not set
+# CONFIG_SIBYTE_SENTOSA is not set
+# CONFIG_SIBYTE_BIGSUR is not set
+# CONFIG_SNI_RM is not set
+# CONFIG_MACH_TX39XX is not set
+# CONFIG_MACH_TX49XX is not set
+# CONFIG_MIKROTIK_RB532 is not set
+# CONFIG_WR_PPMC is not set
+# CONFIG_CAVIUM_OCTEON_SIMULATOR is not set
+CONFIG_CAVIUM_OCTEON_REFERENCE_BOARD=y
+CONFIG_CAVIUM_OCTEON_SPECIFIC_OPTIONS=y
+# CONFIG_USE_RI_XI_PAGE_BITS is not set
+# CONFIG_CAVIUM_OCTEON_2ND_KERNEL is not set
+CONFIG_CAVIUM_OCTEON_BOOTBUS_COMPACT_FLASH=y
+CONFIG_CAVIUM_OCTEON_HW_FIX_UNALIGNED=y
+CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE=2
+CONFIG_FAST_ACCESS_TO_THREAD_POINTER=y
+CONFIG_REPLACE_EMULATED_ACCESS_TO_THREAD_POINTER=y
+CONFIG_TEMPORARY_SCRATCHPAD_FOR_KERNEL=1
+CONFIG_CAVIUM_OCTEON_LOCK_L2=y
+CONFIG_CAVIUM_OCTEON_LOCK_L2_TLB=y
+CONFIG_CAVIUM_OCTEON_LOCK_L2_EXCEPTION=y
+CONFIG_CAVIUM_OCTEON_LOCK_L2_LOW_LEVEL_INTERRUPT=y
+CONFIG_CAVIUM_OCTEON_LOCK_L2_INTERRUPT=y
+CONFIG_CAVIUM_OCTEON_LOCK_L2_MEMCPY=y
+CONFIG_CAVIUM_OCTEON_USER_IO=y
+CONFIG_CAVIUM_OCTEON_USER_MEM=y
+CONFIG_CAVIUM_RESERVE32=0
+# CONFIG_CAVIUM_RESERVE32_USE_WIRED_TLB is not set
+CONFIG_CAVIUM_OCTEON_NUM_PACKET_BUFFERS=1024
+CONFIG_ARCH_SPARSEMEM_ENABLE=y
+CONFIG_CAVIUM_OCTEON_POW_ONLY_ETHERNET=m
+CONFIG_CAVIUM_OCTEON_MGMT_PORT_ETHERNET=y
+CONFIG_CAVIUM_OCTEON_WATCHDOG=y
+# CONFIG_CAVIUM_OCTEON_TRA is not set
+# CONFIG_CAVIUM_OCTEON_IPSEC is not set
+# CONFIG_CAVIUM_OCTEON_IPFWD_OFFLOAD is not set
+CONFIG_CAVIUM_OCTEON_SYNC=y
+CONFIG_GENERIC_LOCKBREAK=y
+CONFIG_RWSEM_GENERIC_SPINLOCK=y
+# CONFIG_ARCH_HAS_ILOG2_U32 is not set
+# CONFIG_ARCH_HAS_ILOG2_U64 is not set
+CONFIG_ARCH_SUPPORTS_OPROFILE=y
+CONFIG_GENERIC_FIND_NEXT_BIT=y
+CONFIG_GENERIC_HWEIGHT=y
+CONFIG_GENERIC_CALIBRATE_DELAY=y
+CONFIG_GENERIC_CLOCKEVENTS=y
+CONFIG_GENERIC_TIME=y
+CONFIG_GENERIC_CMOS_UPDATE=y
+CONFIG_SCHED_NO_NO_OMIT_FRAME_POINTER=y
+# CONFIG_GENERIC_HARDIRQS_NO__DO_IRQ is not set
+CONFIG_ARCH_MAY_HAVE_PC_FDC=y
+CONFIG_CEVT_R4K=y
+CONFIG_CSRC_R4K=y
+# CONFIG_HOTPLUG_CPU is not set
+# CONFIG_NO_IOPORT is not set
+CONFIG_GENERIC_ISA_DMA=y
+CONFIG_CPU_BIG_ENDIAN=y
+# CONFIG_CPU_LITTLE_ENDIAN is not set
+CONFIG_SYS_SUPPORTS_BIG_ENDIAN=y
+CONFIG_IRQ_CPU=y
+CONFIG_IRQ_CPU_OCTEON=y
+CONFIG_SWAP_IO_SPACE=y
+CONFIG_MIPS_L1_CACHE_SHIFT=7
+
+#
+# CPU selection
+#
+# CONFIG_CPU_LOONGSON2 is not set
+# CONFIG_CPU_MIPS32_R1 is not set
+# CONFIG_CPU_MIPS32_R2 is not set
+# CONFIG_CPU_MIPS64_R1 is not set
+# CONFIG_CPU_MIPS64_R2 is not set
+# CONFIG_CPU_R3000 is not set
+# CONFIG_CPU_TX39XX is not set
+# CONFIG_CPU_VR41XX is not set
+# CONFIG_CPU_R4300 is not set
+# CONFIG_CPU_R4X00 is not set
+# CONFIG_CPU_TX49XX is not set
+# CONFIG_CPU_R5000 is not set
+# CONFIG_CPU_R5432 is not set
+# CONFIG_CPU_R6000 is not set
+# CONFIG_CPU_NEVADA is not set
+# CONFIG_CPU_R8000 is not set
+# CONFIG_CPU_R10000 is not set
+# CONFIG_CPU_RM7000 is not set
+# CONFIG_CPU_RM9000 is not set
+# CONFIG_CPU_SB1 is not set
+CONFIG_CPU_CAVIUM_OCTEON=y
+CONFIG_WEAK_ORDERING=y
+CONFIG_CPU_MIPSR2=y
+CONFIG_SYS_SUPPORTS_64BIT_KERNEL=y
+CONFIG_CPU_SUPPORTS_64BIT_KERNEL=y
+
+#
+# Kernel type
+#
+# CONFIG_32BIT is not set
+CONFIG_64BIT=y
+CONFIG_PAGE_SIZE_4KB=y
+# CONFIG_PAGE_SIZE_8KB is not set
+# CONFIG_PAGE_SIZE_16KB is not set
+# CONFIG_PAGE_SIZE_32KB is not set
+# CONFIG_PAGE_SIZE_64KB is not set
+CONFIG_CPU_HAS_PREFETCH=y
+CONFIG_MIPS_MT_DISABLED=y
+# CONFIG_MIPS_MT_SMP is not set
+# CONFIG_MIPS_MT_SMTC is not set
+CONFIG_64BIT_PHYS_ADDR=y
+CONFIG_CPU_HAS_SYNC=y
+CONFIG_GENERIC_HARDIRQS=y
+CONFIG_GENERIC_IRQ_PROBE=y
+CONFIG_IRQ_PER_CPU=y
+CONFIG_CPU_SUPPORTS_HIGHMEM=y
+CONFIG_SYS_SUPPORTS_HIGHMEM=y
+CONFIG_ARCH_FLATMEM_ENABLE=y
+CONFIG_ARCH_POPULATES_NODE_MAP=y
+CONFIG_SELECT_MEMORY_MODEL=y
+# CONFIG_FLATMEM_MANUAL is not set
+# CONFIG_DISCONTIGMEM_MANUAL is not set
+CONFIG_SPARSEMEM_MANUAL=y
+CONFIG_SPARSEMEM=y
+CONFIG_HAVE_MEMORY_PRESENT=y
+CONFIG_SPARSEMEM_STATIC=y
+# CONFIG_SPARSEMEM_VMEMMAP_ENABLE is not set
+CONFIG_PAGEFLAGS_EXTENDED=y
+CONFIG_SPLIT_PTLOCK_CPUS=4
+CONFIG_RESOURCES_64BIT=y
+CONFIG_ZONE_DMA_FLAG=1
+CONFIG_BOUNCE=y
+CONFIG_VIRT_TO_BUS=y
+CONFIG_SMP=y
+CONFIG_SYS_SUPPORTS_SMP=y
+CONFIG_NR_CPUS_DEFAULT_16=y
+CONFIG_NR_CPUS=16
+# CONFIG_MIPS_CMP is not set
+# CONFIG_TICK_ONESHOT is not set
+# CONFIG_NO_HZ is not set
+# CONFIG_HIGH_RES_TIMERS is not set
+CONFIG_GENERIC_CLOCKEVENTS_BUILD=y
+# CONFIG_HZ_48 is not set
+# CONFIG_HZ_100 is not set
+# CONFIG_HZ_128 is not set
+CONFIG_HZ_250=y
+# CONFIG_HZ_256 is not set
+# CONFIG_HZ_1000 is not set
+# CONFIG_HZ_1024 is not set
+CONFIG_SYS_SUPPORTS_ARBIT_HZ=y
+CONFIG_HZ=250
+# CONFIG_PREEMPT_NONE is not set
+# CONFIG_PREEMPT_VOLUNTARY is not set
+CONFIG_PREEMPT=y
+# CONFIG_PREEMPT_RCU is not set
+# CONFIG_KEXEC is not set
+CONFIG_SECCOMP=y
+# CONFIG_MIPS_FPU_EMULATOR_STATS_ENABLED is not set
+CONFIG_LOCKDEP_SUPPORT=y
+CONFIG_STACKTRACE_SUPPORT=y
+CONFIG_DEFCONFIG_LIST="/lib/modules/$UNAME_RELEASE/.config"
+
+#
+# General setup
+#
+CONFIG_EXPERIMENTAL=y
+CONFIG_LOCK_KERNEL=y
+CONFIG_INIT_ENV_ARG_LIMIT=32
+CONFIG_LOCALVERSION=""
+CONFIG_LOCALVERSION_AUTO=y
+CONFIG_SWAP=y
+CONFIG_SYSVIPC=y
+CONFIG_SYSVIPC_SYSCTL=y
+CONFIG_POSIX_MQUEUE=y
+CONFIG_BSD_PROCESS_ACCT=y
+CONFIG_BSD_PROCESS_ACCT_V3=y
+# CONFIG_TASKSTATS is not set
+# CONFIG_AUDIT is not set
+CONFIG_IKCONFIG=y
+CONFIG_IKCONFIG_PROC=y
+CONFIG_LOG_BUF_SHIFT=14
+# CONFIG_CGROUPS is not set
+CONFIG_GROUP_SCHED=y
+CONFIG_FAIR_GROUP_SCHED=y
+# CONFIG_RT_GROUP_SCHED is not set
+CONFIG_USER_SCHED=y
+# CONFIG_CGROUP_SCHED is not set
+CONFIG_SYSFS_DEPRECATED=y
+CONFIG_SYSFS_DEPRECATED_V2=y
+CONFIG_RELAY=y
+# CONFIG_NAMESPACES is not set
+CONFIG_BLK_DEV_INITRD=y
+CONFIG_INITRAMFS_SOURCE=""
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+CONFIG_SYSCTL=y
+CONFIG_EMBEDDED=y
+CONFIG_SYSCTL_SYSCALL=y
+CONFIG_KALLSYMS=y
+# CONFIG_KALLSYMS_ALL is not set
+# CONFIG_KALLSYMS_EXTRA_PASS is not set
+CONFIG_HOTPLUG=y
+CONFIG_PRINTK=y
+CONFIG_BUG=y
+CONFIG_ELF_CORE=y
+# CONFIG_PCSPKR_PLATFORM is not set
+CONFIG_COMPAT_BRK=y
+CONFIG_BASE_FULL=y
+CONFIG_FUTEX=y
+CONFIG_ANON_INODES=y
+CONFIG_EPOLL=y
+CONFIG_SIGNALFD=y
+CONFIG_TIMERFD=y
+CONFIG_EVENTFD=y
+CONFIG_SHMEM=y
+CONFIG_VM_EVENT_COUNTERS=y
+CONFIG_SLAB=y
+# CONFIG_SLUB is not set
+# CONFIG_SLOB is not set
+# CONFIG_PROFILING is not set
+# CONFIG_MARKERS is not set
+CONFIG_HAVE_OPROFILE=y
+# CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS is not set
+# CONFIG_HAVE_IOREMAP_PROT is not set
+# CONFIG_HAVE_KPROBES is not set
+# CONFIG_HAVE_KRETPROBES is not set
+# CONFIG_HAVE_ARCH_TRACEHOOK is not set
+# CONFIG_HAVE_DMA_ATTRS is not set
+CONFIG_USE_GENERIC_SMP_HELPERS=y
+# CONFIG_HAVE_CLK is not set
+CONFIG_PROC_PAGE_MONITOR=y
+# CONFIG_HAVE_GENERIC_DMA_COHERENT is not set
+CONFIG_SLABINFO=y
+CONFIG_RT_MUTEXES=y
+# CONFIG_TINY_SHMEM is not set
+CONFIG_BASE_SMALL=0
+CONFIG_MODULES=y
+# CONFIG_MODULE_FORCE_LOAD is not set
+CONFIG_MODULE_UNLOAD=y
+# CONFIG_MODULE_FORCE_UNLOAD is not set
+# CONFIG_MODVERSIONS is not set
+# CONFIG_MODULE_SRCVERSION_ALL is not set
+CONFIG_KMOD=y
+CONFIG_STOP_MACHINE=y
+CONFIG_BLOCK=y
+# CONFIG_BLK_DEV_IO_TRACE is not set
+# CONFIG_BLK_DEV_BSG is not set
+# CONFIG_BLK_DEV_INTEGRITY is not set
+CONFIG_BLOCK_COMPAT=y
+
+#
+# IO Schedulers
+#
+CONFIG_IOSCHED_NOOP=y
+CONFIG_IOSCHED_AS=y
+CONFIG_IOSCHED_DEADLINE=y
+CONFIG_IOSCHED_CFQ=y
+# CONFIG_DEFAULT_AS is not set
+# CONFIG_DEFAULT_DEADLINE is not set
+CONFIG_DEFAULT_CFQ=y
+# CONFIG_DEFAULT_NOOP is not set
+CONFIG_DEFAULT_IOSCHED="cfq"
+CONFIG_CLASSIC_RCU=y
+# CONFIG_PROBE_INITRD_HEADER is not set
+
+#
+# Bus options (PCI, PCMCIA, EISA, ISA, TC)
+#
+CONFIG_HW_HAS_PCI=y
+CONFIG_PCI=y
+CONFIG_PCI_DOMAINS=y
+# CONFIG_ARCH_SUPPORTS_MSI is not set
+CONFIG_PCI_LEGACY=y
+# CONFIG_PCI_DEBUG is not set
+CONFIG_ISA=y
+CONFIG_MMU=y
+# CONFIG_PCCARD is not set
+# CONFIG_HOTPLUG_PCI is not set
+
+#
+# Executable file formats
+#
+CONFIG_BINFMT_ELF=y
+# CONFIG_BINFMT_MISC is not set
+CONFIG_MIPS32_COMPAT=y
+CONFIG_COMPAT=y
+CONFIG_SYSVIPC_COMPAT=y
+CONFIG_MIPS32_O32=y
+CONFIG_MIPS32_N32=y
+CONFIG_BINFMT_ELF32=y
+
+#
+# Power management options
+#
+# CONFIG_PM is not set
+CONFIG_NET=y
+
+#
+# Networking options
+#
+CONFIG_PACKET=y
+CONFIG_PACKET_MMAP=y
+CONFIG_UNIX=y
+CONFIG_XFRM=y
+# CONFIG_XFRM_USER is not set
+# CONFIG_XFRM_SUB_POLICY is not set
+# CONFIG_XFRM_MIGRATE is not set
+# CONFIG_XFRM_STATISTICS is not set
+# CONFIG_NET_KEY is not set
+CONFIG_INET=y
+CONFIG_IP_MULTICAST=y
+CONFIG_IP_ADVANCED_ROUTER=y
+CONFIG_ASK_IP_FIB_HASH=y
+# CONFIG_IP_FIB_TRIE is not set
+CONFIG_IP_FIB_HASH=y
+CONFIG_IP_MULTIPLE_TABLES=y
+CONFIG_IP_ROUTE_MULTIPATH=y
+CONFIG_IP_ROUTE_VERBOSE=y
+CONFIG_IP_PNP=y
+CONFIG_IP_PNP_DHCP=y
+CONFIG_IP_PNP_BOOTP=y
+CONFIG_IP_PNP_RARP=y
+# CONFIG_NET_IPIP is not set
+# CONFIG_NET_IPGRE is not set
+CONFIG_IP_MROUTE=y
+CONFIG_IP_PIMSM_V1=y
+CONFIG_IP_PIMSM_V2=y
+# CONFIG_ARPD is not set
+CONFIG_SYN_COOKIES=y
+# CONFIG_INET_AH is not set
+# CONFIG_INET_ESP is not set
+# CONFIG_INET_IPCOMP is not set
+# CONFIG_INET_XFRM_TUNNEL is not set
+# CONFIG_INET_TUNNEL is not set
+CONFIG_INET_XFRM_MODE_TRANSPORT=y
+CONFIG_INET_XFRM_MODE_TUNNEL=y
+CONFIG_INET_XFRM_MODE_BEET=y
+# CONFIG_INET_LRO is not set
+CONFIG_INET_DIAG=y
+CONFIG_INET_TCP_DIAG=y
+# CONFIG_TCP_CONG_ADVANCED is not set
+CONFIG_TCP_CONG_CUBIC=y
+CONFIG_DEFAULT_TCP_CONG="cubic"
+# CONFIG_TCP_MD5SIG is not set
+# CONFIG_IP_VS is not set
+# CONFIG_IPV6 is not set
+# CONFIG_NETLABEL is not set
+# CONFIG_NETWORK_SECMARK is not set
+CONFIG_NETFILTER=y
+# CONFIG_NETFILTER_DEBUG is not set
+CONFIG_NETFILTER_ADVANCED=y
+
+#
+# Core Netfilter Configuration
+#
+# CONFIG_NETFILTER_NETLINK_QUEUE is not set
+# CONFIG_NETFILTER_NETLINK_LOG is not set
+# CONFIG_NF_CONNTRACK is not set
+# CONFIG_NETFILTER_XTABLES is not set
+
+#
+# IP: Netfilter Configuration
+#
+# CONFIG_IP_NF_QUEUE is not set
+# CONFIG_IP_NF_IPTABLES is not set
+# CONFIG_IP_NF_ARPTABLES is not set
+# CONFIG_IP_DCCP is not set
+# CONFIG_IP_SCTP is not set
+# CONFIG_TIPC is not set
+# CONFIG_ATM is not set
+# CONFIG_BRIDGE is not set
+# CONFIG_VLAN_8021Q is not set
+# CONFIG_DECNET is not set
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_ECONET is not set
+# CONFIG_WAN_ROUTER is not set
+CONFIG_NET_SCHED=y
+
+#
+# Queueing/Scheduling
+#
+# CONFIG_NET_SCH_CBQ is not set
+# CONFIG_NET_SCH_HTB is not set
+# CONFIG_NET_SCH_HFSC is not set
+# CONFIG_NET_SCH_PRIO is not set
+# CONFIG_NET_SCH_RED is not set
+# CONFIG_NET_SCH_SFQ is not set
+# CONFIG_NET_SCH_TEQL is not set
+# CONFIG_NET_SCH_TBF is not set
+# CONFIG_NET_SCH_GRED is not set
+# CONFIG_NET_SCH_DSMARK is not set
+# CONFIG_NET_SCH_NETEM is not set
+
+#
+# Classification
+#
+# CONFIG_NET_CLS_BASIC is not set
+# CONFIG_NET_CLS_TCINDEX is not set
+# CONFIG_NET_CLS_ROUTE4 is not set
+# CONFIG_NET_CLS_FW is not set
+# CONFIG_NET_CLS_U32 is not set
+# CONFIG_NET_CLS_RSVP is not set
+# CONFIG_NET_CLS_RSVP6 is not set
+# CONFIG_NET_CLS_FLOW is not set
+# CONFIG_NET_EMATCH is not set
+# CONFIG_NET_CLS_ACT is not set
+CONFIG_NET_SCH_FIFO=y
+
+#
+# Network testing
+#
+# CONFIG_NET_PKTGEN is not set
+# CONFIG_HAMRADIO is not set
+# CONFIG_CAN is not set
+# CONFIG_IRDA is not set
+# CONFIG_BT is not set
+# CONFIG_AF_RXRPC is not set
+CONFIG_FIB_RULES=y
+
+#
+# Wireless
+#
+# CONFIG_CFG80211 is not set
+# CONFIG_WIRELESS_EXT is not set
+# CONFIG_MAC80211 is not set
+# CONFIG_IEEE80211 is not set
+# CONFIG_RFKILL is not set
+# CONFIG_NET_9P is not set
+
+#
+# Device Drivers
+#
+
+#
+# Generic Driver Options
+#
+CONFIG_UEVENT_HELPER_PATH="/sbin/hotplug"
+CONFIG_STANDALONE=y
+CONFIG_PREVENT_FIRMWARE_BUILD=y
+# CONFIG_FW_LOADER is not set
+# CONFIG_DEBUG_DRIVER is not set
+# CONFIG_DEBUG_DEVRES is not set
+# CONFIG_SYS_HYPERVISOR is not set
+# CONFIG_CONNECTOR is not set
+CONFIG_MTD=y
+# CONFIG_MTD_DEBUG is not set
+# CONFIG_MTD_CONCAT is not set
+CONFIG_MTD_PARTITIONS=y
+# CONFIG_MTD_REDBOOT_PARTS is not set
+# CONFIG_MTD_CMDLINE_PARTS is not set
+# CONFIG_MTD_AR7_PARTS is not set
+
+#
+# User Modules And Translation Layers
+#
+CONFIG_MTD_CHAR=y
+CONFIG_MTD_BLKDEVS=y
+CONFIG_MTD_BLOCK=y
+# CONFIG_FTL is not set
+# CONFIG_NFTL is not set
+# CONFIG_INFTL is not set
+# CONFIG_RFD_FTL is not set
+# CONFIG_SSFDC is not set
+# CONFIG_MTD_OOPS is not set
+
+#
+# RAM/ROM/Flash chip drivers
+#
+CONFIG_MTD_CFI=y
+# CONFIG_MTD_JEDECPROBE is not set
+CONFIG_MTD_GEN_PROBE=y
+# CONFIG_MTD_CFI_ADV_OPTIONS is not set
+CONFIG_MTD_MAP_BANK_WIDTH_1=y
+CONFIG_MTD_MAP_BANK_WIDTH_2=y
+CONFIG_MTD_MAP_BANK_WIDTH_4=y
+# CONFIG_MTD_MAP_BANK_WIDTH_8 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_16 is not set
+# CONFIG_MTD_MAP_BANK_WIDTH_32 is not set
+CONFIG_MTD_CFI_I1=y
+CONFIG_MTD_CFI_I2=y
+# CONFIG_MTD_CFI_I4 is not set
+# CONFIG_MTD_CFI_I8 is not set
+# CONFIG_MTD_CFI_INTELEXT is not set
+CONFIG_MTD_CFI_AMDSTD=y
+# CONFIG_MTD_CFI_STAA is not set
+CONFIG_MTD_CFI_UTIL=y
+# CONFIG_MTD_RAM is not set
+# CONFIG_MTD_ROM is not set
+# CONFIG_MTD_ABSENT is not set
+
+#
+# Mapping drivers for chip access
+#
+# CONFIG_MTD_COMPLEX_MAPPINGS is not set
+CONFIG_MTD_PHYSMAP=y
+CONFIG_MTD_PHYSMAP_START=0x8000000
+CONFIG_MTD_PHYSMAP_LEN=0x0
+CONFIG_MTD_PHYSMAP_BANKWIDTH=2
+# CONFIG_MTD_INTEL_VR_NOR is not set
+# CONFIG_MTD_PLATRAM is not set
+CONFIG_MTD_CAVIUM_FLASH=y
+
+#
+# Self-contained MTD device drivers
+#
+# CONFIG_MTD_PMC551 is not set
+# CONFIG_MTD_SLRAM is not set
+# CONFIG_MTD_PHRAM is not set
+# CONFIG_MTD_MTDRAM is not set
+# CONFIG_MTD_BLOCK2MTD is not set
+
+#
+# Disk-On-Chip Device Drivers
+#
+# CONFIG_MTD_DOC2000 is not set
+# CONFIG_MTD_DOC2001 is not set
+# CONFIG_MTD_DOC2001PLUS is not set
+# CONFIG_MTD_NAND is not set
+# CONFIG_MTD_ONENAND is not set
+
+#
+# UBI - Unsorted block images
+#
+# CONFIG_MTD_UBI is not set
+# CONFIG_PARPORT is not set
+# CONFIG_PNP is not set
+CONFIG_BLK_DEV=y
+# CONFIG_BLK_DEV_FD is not set
+# CONFIG_BLK_CPQ_DA is not set
+# CONFIG_BLK_CPQ_CISS_DA is not set
+# CONFIG_BLK_DEV_DAC960 is not set
+# CONFIG_BLK_DEV_UMEM is not set
+# CONFIG_BLK_DEV_COW_COMMON is not set
+CONFIG_BLK_DEV_LOOP=y
+# CONFIG_BLK_DEV_CRYPTOLOOP is not set
+# CONFIG_BLK_DEV_NBD is not set
+# CONFIG_BLK_DEV_SX8 is not set
+CONFIG_BLK_DEV_RAM=y
+CONFIG_BLK_DEV_RAM_COUNT=16
+CONFIG_BLK_DEV_RAM_SIZE=4096
+# CONFIG_BLK_DEV_XIP is not set
+# CONFIG_CDROM_PKTCDVD is not set
+# CONFIG_ATA_OVER_ETH is not set
+# CONFIG_BLK_DEV_HD is not set
+CONFIG_MISC_DEVICES=y
+# CONFIG_PHANTOM is not set
+# CONFIG_EEPROM_93CX6 is not set
+# CONFIG_SGI_IOC4 is not set
+# CONFIG_TIFM_CORE is not set
+# CONFIG_ENCLOSURE_SERVICES is not set
+# CONFIG_HP_ILO is not set
+CONFIG_HAVE_IDE=y
+CONFIG_IDE=y
+CONFIG_BLK_DEV_IDE=y
+
+#
+# Please see Documentation/ide/ide.txt for help/info on IDE drives
+#
+# CONFIG_BLK_DEV_IDE_SATA is not set
+CONFIG_BLK_DEV_IDEDISK=y
+# CONFIG_IDEDISK_MULTI_MODE is not set
+# CONFIG_BLK_DEV_IDECD is not set
+# CONFIG_BLK_DEV_IDETAPE is not set
+# CONFIG_BLK_DEV_IDEFLOPPY is not set
+# CONFIG_IDE_TASK_IOCTL is not set
+CONFIG_IDE_PROC_FS=y
+
+#
+# IDE chipset support/bugfixes
+#
+CONFIG_IDE_GENERIC=y
+# CONFIG_BLK_DEV_PLATFORM is not set
+
+#
+# PCI IDE chipsets support
+#
+# CONFIG_BLK_DEV_GENERIC is not set
+# CONFIG_BLK_DEV_OPTI621 is not set
+# CONFIG_BLK_DEV_AEC62XX is not set
+# CONFIG_BLK_DEV_ALI15X3 is not set
+# CONFIG_BLK_DEV_AMD74XX is not set
+# CONFIG_BLK_DEV_CMD64X is not set
+# CONFIG_BLK_DEV_TRIFLEX is not set
+# CONFIG_BLK_DEV_CS5520 is not set
+# CONFIG_BLK_DEV_CS5530 is not set
+# CONFIG_BLK_DEV_HPT366 is not set
+# CONFIG_BLK_DEV_JMICRON is not set
+# CONFIG_BLK_DEV_SC1200 is not set
+# CONFIG_BLK_DEV_PIIX is not set
+# CONFIG_BLK_DEV_IT8213 is not set
+# CONFIG_BLK_DEV_IT821X is not set
+# CONFIG_BLK_DEV_NS87415 is not set
+# CONFIG_BLK_DEV_PDC202XX_OLD is not set
+# CONFIG_BLK_DEV_PDC202XX_NEW is not set
+# CONFIG_BLK_DEV_SVWKS is not set
+# CONFIG_BLK_DEV_SIIMAGE is not set
+# CONFIG_BLK_DEV_SLC90E66 is not set
+# CONFIG_BLK_DEV_TRM290 is not set
+# CONFIG_BLK_DEV_VIA82CXXX is not set
+# CONFIG_BLK_DEV_TC86C001 is not set
+
+#
+# Other IDE chipsets support
+#
+
+#
+# Note: most of these also require special kernel boot parameters
+#
+# CONFIG_BLK_DEV_4DRIVES is not set
+# CONFIG_BLK_DEV_ALI14XX is not set
+# CONFIG_BLK_DEV_DTC2278 is not set
+# CONFIG_BLK_DEV_HT6560B is not set
+# CONFIG_BLK_DEV_QD65XX is not set
+# CONFIG_BLK_DEV_UMC8672 is not set
+# CONFIG_BLK_DEV_IDEDMA is not set
+
+#
+# SCSI device support
+#
+# CONFIG_RAID_ATTRS is not set
+# CONFIG_SCSI is not set
+# CONFIG_SCSI_DMA is not set
+# CONFIG_SCSI_NETLINK is not set
+# CONFIG_ATA is not set
+CONFIG_MD=y
+CONFIG_BLK_DEV_MD=y
+CONFIG_MD_LINEAR=y
+CONFIG_MD_RAID0=y
+CONFIG_MD_RAID1=y
+CONFIG_MD_RAID10=y
+# CONFIG_MD_RAID456 is not set
+CONFIG_MD_MULTIPATH=y
+CONFIG_MD_FAULTY=y
+CONFIG_BLK_DEV_DM=y
+# CONFIG_DM_DEBUG is not set
+CONFIG_DM_CRYPT=y
+CONFIG_DM_SNAPSHOT=y
+CONFIG_DM_MIRROR=y
+CONFIG_DM_ZERO=y
+# CONFIG_DM_MULTIPATH is not set
+# CONFIG_DM_DELAY is not set
+# CONFIG_DM_UEVENT is not set
+# CONFIG_FUSION is not set
+
+#
+# IEEE 1394 (FireWire) support
+#
+
+#
+# Enable only one of the two stacks, unless you know what you are doing
+#
+# CONFIG_FIREWIRE is not set
+# CONFIG_IEEE1394 is not set
+# CONFIG_I2O is not set
+CONFIG_NETDEVICES=y
+# CONFIG_DUMMY is not set
+# CONFIG_BONDING is not set
+# CONFIG_MACVLAN is not set
+# CONFIG_EQUALIZER is not set
+# CONFIG_TUN is not set
+# CONFIG_VETH is not set
+# CONFIG_ARCNET is not set
+# CONFIG_PHYLIB is not set
+CONFIG_NET_ETHERNET=y
+CONFIG_MII=y
+# CONFIG_AX88796 is not set
+# CONFIG_HAPPYMEAL is not set
+# CONFIG_SUNGEM is not set
+# CONFIG_CASSINI is not set
+# CONFIG_NET_VENDOR_3COM is not set
+# CONFIG_NET_VENDOR_SMC is not set
+# CONFIG_DM9000 is not set
+# CONFIG_NET_VENDOR_RACAL is not set
+# CONFIG_NET_TULIP is not set
+# CONFIG_AT1700 is not set
+# CONFIG_DEPCA is not set
+# CONFIG_HP100 is not set
+# CONFIG_NET_ISA is not set
+# CONFIG_IBM_NEW_EMAC_ZMII is not set
+# CONFIG_IBM_NEW_EMAC_RGMII is not set
+# CONFIG_IBM_NEW_EMAC_TAH is not set
+# CONFIG_IBM_NEW_EMAC_EMAC4 is not set
+CONFIG_NET_PCI=y
+# CONFIG_PCNET32 is not set
+# CONFIG_AMD8111_ETH is not set
+# CONFIG_ADAPTEC_STARFIRE is not set
+# CONFIG_AC3200 is not set
+# CONFIG_APRICOT is not set
+# CONFIG_B44 is not set
+# CONFIG_FORCEDETH is not set
+# CONFIG_CS89x0 is not set
+# CONFIG_TC35815 is not set
+# CONFIG_EEPRO100 is not set
+# CONFIG_E100 is not set
+# CONFIG_FEALNX is not set
+# CONFIG_NATSEMI is not set
+# CONFIG_NE2K_PCI is not set
+# CONFIG_8139CP is not set
+# CONFIG_8139TOO is not set
+# CONFIG_R6040 is not set
+# CONFIG_SIS900 is not set
+# CONFIG_EPIC100 is not set
+# CONFIG_SUNDANCE is not set
+# CONFIG_TLAN is not set
+# CONFIG_VIA_RHINE is not set
+# CONFIG_SC92031 is not set
+CONFIG_CAVIUM_ETHERNET=y
+CONFIG_NETDEV_1000=y
+# CONFIG_ACENIC is not set
+# CONFIG_DL2K is not set
+# CONFIG_E1000 is not set
+# CONFIG_E1000E is not set
+# CONFIG_IP1000 is not set
+# CONFIG_IGB is not set
+# CONFIG_NS83820 is not set
+# CONFIG_HAMACHI is not set
+# CONFIG_YELLOWFIN is not set
+# CONFIG_R8169 is not set
+# CONFIG_SIS190 is not set
+# CONFIG_SKGE is not set
+# CONFIG_SKY2 is not set
+# CONFIG_VIA_VELOCITY is not set
+# CONFIG_TIGON3 is not set
+# CONFIG_BNX2 is not set
+# CONFIG_QLA3XXX is not set
+# CONFIG_ATL1 is not set
+# CONFIG_ATL1E is not set
+CONFIG_NETDEV_10000=y
+# CONFIG_CHELSIO_T1 is not set
+# CONFIG_CHELSIO_T3 is not set
+# CONFIG_IXGBE is not set
+# CONFIG_IXGB is not set
+# CONFIG_S2IO is not set
+# CONFIG_MYRI10GE is not set
+# CONFIG_NETXEN_NIC is not set
+# CONFIG_NIU is not set
+# CONFIG_MLX4_CORE is not set
+# CONFIG_TEHUTI is not set
+# CONFIG_BNX2X is not set
+# CONFIG_SFC is not set
+# CONFIG_TR is not set
+
+#
+# Wireless LAN
+#
+# CONFIG_WLAN_PRE80211 is not set
+# CONFIG_WLAN_80211 is not set
+# CONFIG_IWLWIFI_LEDS is not set
+# CONFIG_WAN is not set
+# CONFIG_FDDI is not set
+# CONFIG_HIPPI is not set
+# CONFIG_PPP is not set
+# CONFIG_SLIP is not set
+CONFIG_NETCONSOLE=y
+# CONFIG_NETCONSOLE_DYNAMIC is not set
+CONFIG_NETPOLL=y
+CONFIG_NETPOLL_TRAP=y
+CONFIG_NET_POLL_CONTROLLER=y
+# CONFIG_ISDN is not set
+# CONFIG_PHONE is not set
+
+#
+# Input device support
+#
+# CONFIG_INPUT is not set
+
+#
+# Hardware I/O ports
+#
+# CONFIG_SERIO is not set
+# CONFIG_GAMEPORT is not set
+
+#
+# Character devices
+#
+# CONFIG_VT is not set
+CONFIG_DEVKMEM=y
+# CONFIG_SERIAL_NONSTANDARD is not set
+# CONFIG_NOZOMI is not set
+
+#
+# Serial drivers
+#
+CONFIG_SERIAL_8250=y
+CONFIG_SERIAL_8250_CONSOLE=y
+CONFIG_SERIAL_8250_PCI=y
+CONFIG_SERIAL_8250_NR_UARTS=2
+CONFIG_SERIAL_8250_RUNTIME_UARTS=2
+# CONFIG_SERIAL_8250_EXTENDED is not set
+
+#
+# Non-8250 serial port support
+#
+CONFIG_SERIAL_CORE=y
+CONFIG_SERIAL_CORE_CONSOLE=y
+# CONFIG_SERIAL_JSM is not set
+CONFIG_UNIX98_PTYS=y
+CONFIG_LEGACY_PTYS=y
+CONFIG_LEGACY_PTY_COUNT=256
+# CONFIG_IPMI_HANDLER is not set
+# CONFIG_HW_RANDOM is not set
+# CONFIG_DTLK is not set
+# CONFIG_R3964 is not set
+# CONFIG_APPLICOM is not set
+# CONFIG_RAW_DRIVER is not set
+# CONFIG_TCG_TPM is not set
+CONFIG_DEVPORT=y
+CONFIG_I2C=m
+CONFIG_I2C_BOARDINFO=y
+CONFIG_I2C_CHARDEV=m
+CONFIG_I2C_HELPER_AUTO=y
+
+#
+# I2C Hardware Bus support
+#
+
+#
+# PC SMBus host controller drivers
+#
+# CONFIG_I2C_ALI1535 is not set
+# CONFIG_I2C_ALI1563 is not set
+# CONFIG_I2C_ALI15X3 is not set
+# CONFIG_I2C_AMD756 is not set
+# CONFIG_I2C_AMD8111 is not set
+# CONFIG_I2C_I801 is not set
+# CONFIG_I2C_ISCH is not set
+# CONFIG_I2C_PIIX4 is not set
+# CONFIG_I2C_NFORCE2 is not set
+# CONFIG_I2C_SIS5595 is not set
+# CONFIG_I2C_SIS630 is not set
+# CONFIG_I2C_SIS96X is not set
+# CONFIG_I2C_VIA is not set
+# CONFIG_I2C_VIAPRO is not set
+
+#
+# I2C system bus drivers (mostly embedded / system-on-chip)
+#
+# CONFIG_I2C_OCORES is not set
+# CONFIG_I2C_SIMTEC is not set
+
+#
+# External I2C/SMBus adapter drivers
+#
+# CONFIG_I2C_PARPORT_LIGHT is not set
+# CONFIG_I2C_TAOS_EVM is not set
+
+#
+# Graphics adapter I2C/DDC channel drivers
+#
+# CONFIG_I2C_VOODOO3 is not set
+
+#
+# Other I2C/SMBus bus drivers
+#
+# CONFIG_I2C_PCA_ISA is not set
+# CONFIG_I2C_PCA_PLATFORM is not set
+# CONFIG_I2C_STUB is not set
+CONFIG_I2C_OCTEON_TWSI=m
+
+#
+# Miscellaneous I2C Chip support
+#
+# CONFIG_DS1682 is not set
+# CONFIG_AT24 is not set
+CONFIG_SENSORS_EEPROM=m
+# CONFIG_SENSORS_PCF8574 is not set
+# CONFIG_PCF8575 is not set
+# CONFIG_SENSORS_PCA9539 is not set
+# CONFIG_SENSORS_PCF8591 is not set
+# CONFIG_SENSORS_MAX6875 is not set
+# CONFIG_SENSORS_TSL2550 is not set
+# CONFIG_I2C_DEBUG_CORE is not set
+# CONFIG_I2C_DEBUG_ALGO is not set
+# CONFIG_I2C_DEBUG_BUS is not set
+# CONFIG_I2C_DEBUG_CHIP is not set
+# CONFIG_SPI is not set
+# CONFIG_W1 is not set
+# CONFIG_POWER_SUPPLY is not set
+CONFIG_HWMON=y
+# CONFIG_HWMON_VID is not set
+# CONFIG_SENSORS_AD7414 is not set
+# CONFIG_SENSORS_AD7418 is not set
+# CONFIG_SENSORS_ADM1021 is not set
+# CONFIG_SENSORS_ADM1025 is not set
+# CONFIG_SENSORS_ADM1026 is not set
+# CONFIG_SENSORS_ADM1029 is not set
+# CONFIG_SENSORS_ADM1031 is not set
+# CONFIG_SENSORS_ADM9240 is not set
+# CONFIG_SENSORS_ADT7470 is not set
+# CONFIG_SENSORS_ADT7473 is not set
+# CONFIG_SENSORS_ATXP1 is not set
+# CONFIG_SENSORS_DS1621 is not set
+# CONFIG_SENSORS_I5K_AMB is not set
+# CONFIG_SENSORS_F71805F is not set
+# CONFIG_SENSORS_F71882FG is not set
+# CONFIG_SENSORS_F75375S is not set
+# CONFIG_SENSORS_GL518SM is not set
+# CONFIG_SENSORS_GL520SM is not set
+# CONFIG_SENSORS_IT87 is not set
+# CONFIG_SENSORS_LM63 is not set
+# CONFIG_SENSORS_LM75 is not set
+# CONFIG_SENSORS_LM77 is not set
+# CONFIG_SENSORS_LM78 is not set
+# CONFIG_SENSORS_LM80 is not set
+# CONFIG_SENSORS_LM83 is not set
+# CONFIG_SENSORS_LM85 is not set
+# CONFIG_SENSORS_LM87 is not set
+# CONFIG_SENSORS_LM90 is not set
+# CONFIG_SENSORS_LM92 is not set
+# CONFIG_SENSORS_LM93 is not set
+# CONFIG_SENSORS_MAX1619 is not set
+# CONFIG_SENSORS_MAX6650 is not set
+# CONFIG_SENSORS_PC87360 is not set
+# CONFIG_SENSORS_PC87427 is not set
+# CONFIG_SENSORS_SIS5595 is not set
+# CONFIG_SENSORS_DME1737 is not set
+# CONFIG_SENSORS_SMSC47M1 is not set
+# CONFIG_SENSORS_SMSC47M192 is not set
+# CONFIG_SENSORS_SMSC47B397 is not set
+# CONFIG_SENSORS_ADS7828 is not set
+# CONFIG_SENSORS_THMC50 is not set
+# CONFIG_SENSORS_VIA686A is not set
+# CONFIG_SENSORS_VT1211 is not set
+# CONFIG_SENSORS_VT8231 is not set
+# CONFIG_SENSORS_W83781D is not set
+# CONFIG_SENSORS_W83791D is not set
+# CONFIG_SENSORS_W83792D is not set
+# CONFIG_SENSORS_W83793 is not set
+# CONFIG_SENSORS_W83L785TS is not set
+# CONFIG_SENSORS_W83L786NG is not set
+# CONFIG_SENSORS_W83627HF is not set
+# CONFIG_SENSORS_W83627EHF is not set
+# CONFIG_HWMON_DEBUG_CHIP is not set
+CONFIG_THERMAL=y
+# CONFIG_THERMAL_HWMON is not set
+CONFIG_WATCHDOG=y
+# CONFIG_WATCHDOG_NOWAYOUT is not set
+
+#
+# Watchdog Device Drivers
+#
+# CONFIG_SOFT_WATCHDOG is not set
+# CONFIG_ALIM7101_WDT is not set
+
+#
+# ISA-based Watchdog Cards
+#
+# CONFIG_PCWATCHDOG is not set
+# CONFIG_MIXCOMWD is not set
+# CONFIG_WDT is not set
+
+#
+# PCI-based Watchdog Cards
+#
+# CONFIG_PCIPCWATCHDOG is not set
+# CONFIG_WDTPCI is not set
+
+#
+# Sonics Silicon Backplane
+#
+CONFIG_SSB_POSSIBLE=y
+# CONFIG_SSB is not set
+
+#
+# Multifunction device drivers
+#
+# CONFIG_MFD_CORE is not set
+# CONFIG_MFD_SM501 is not set
+# CONFIG_HTC_PASIC3 is not set
+# CONFIG_MFD_TMIO is not set
+
+#
+# Multimedia devices
+#
+
+#
+# Multimedia core support
+#
+# CONFIG_VIDEO_DEV is not set
+# CONFIG_DVB_CORE is not set
+# CONFIG_VIDEO_MEDIA is not set
+
+#
+# Multimedia drivers
+#
+# CONFIG_DAB is not set
+
+#
+# Graphics support
+#
+# CONFIG_DRM is not set
+# CONFIG_VGASTATE is not set
+# CONFIG_VIDEO_OUTPUT_CONTROL is not set
+# CONFIG_FB is not set
+# CONFIG_BACKLIGHT_LCD_SUPPORT is not set
+
+#
+# Display device support
+#
+# CONFIG_DISPLAY_SUPPORT is not set
+# CONFIG_SOUND is not set
+CONFIG_USB_SUPPORT=y
+CONFIG_USB_ARCH_HAS_HCD=y
+CONFIG_USB_ARCH_HAS_OHCI=y
+CONFIG_USB_ARCH_HAS_EHCI=y
+# CONFIG_USB is not set
+# CONFIG_USB_OTG_WHITELIST is not set
+# CONFIG_USB_OTG_BLACKLIST_HUB is not set
+
+#
+# Enable Host or Gadget support to see Inventra options
+#
+
+#
+# NOTE: USB_STORAGE enables SCSI, and 'SCSI disk support'
+#
+# CONFIG_USB_GADGET is not set
+# CONFIG_MMC is not set
+# CONFIG_MEMSTICK is not set
+# CONFIG_NEW_LEDS is not set
+# CONFIG_ACCESSIBILITY is not set
+# CONFIG_INFINIBAND is not set
+CONFIG_RTC_LIB=y
+# CONFIG_RTC_CLASS is not set
+# CONFIG_DMADEVICES is not set
+# CONFIG_UIO is not set
+
+#
+# File systems
+#
+CONFIG_EXT2_FS=y
+CONFIG_EXT2_FS_XATTR=y
+CONFIG_EXT2_FS_POSIX_ACL=y
+# CONFIG_EXT2_FS_SECURITY is not set
+# CONFIG_EXT2_FS_XIP is not set
+CONFIG_EXT3_FS=y
+CONFIG_EXT3_FS_XATTR=y
+CONFIG_EXT3_FS_POSIX_ACL=y
+# CONFIG_EXT3_FS_SECURITY is not set
+# CONFIG_EXT4DEV_FS is not set
+CONFIG_JBD=y
+# CONFIG_JBD_DEBUG is not set
+CONFIG_FS_MBCACHE=y
+# CONFIG_REISERFS_FS is not set
+# CONFIG_JFS_FS is not set
+CONFIG_FS_POSIX_ACL=y
+# CONFIG_XFS_FS is not set
+# CONFIG_GFS2_FS is not set
+# CONFIG_OCFS2_FS is not set
+CONFIG_DNOTIFY=y
+CONFIG_INOTIFY=y
+CONFIG_INOTIFY_USER=y
+# CONFIG_QUOTA is not set
+# CONFIG_AUTOFS_FS is not set
+# CONFIG_AUTOFS4_FS is not set
+# CONFIG_FUSE_FS is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+# CONFIG_ISO9660_FS is not set
+# CONFIG_UDF_FS is not set
+
+#
+# DOS/FAT/NT Filesystems
+#
+CONFIG_FAT_FS=y
+# CONFIG_MSDOS_FS is not set
+CONFIG_VFAT_FS=y
+CONFIG_FAT_DEFAULT_CODEPAGE=437
+CONFIG_FAT_DEFAULT_IOCHARSET="iso8859-1"
+# CONFIG_NTFS_FS is not set
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+CONFIG_PROC_KCORE=y
+CONFIG_PROC_SYSCTL=y
+CONFIG_SYSFS=y
+CONFIG_TMPFS=y
+# CONFIG_TMPFS_POSIX_ACL is not set
+# CONFIG_HUGETLBFS is not set
+# CONFIG_HUGETLB_PAGE is not set
+# CONFIG_CONFIGFS_FS is not set
+
+#
+# Miscellaneous filesystems
+#
+# CONFIG_ADFS_FS is not set
+# CONFIG_AFFS_FS is not set
+# CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
+# CONFIG_BEFS_FS is not set
+# CONFIG_BFS_FS is not set
+# CONFIG_EFS_FS is not set
+# CONFIG_JFFS2_FS is not set
+# CONFIG_CRAMFS is not set
+# CONFIG_VXFS_FS is not set
+# CONFIG_MINIX_FS is not set
+# CONFIG_OMFS_FS is not set
+# CONFIG_HPFS_FS is not set
+# CONFIG_QNX4FS_FS is not set
+# CONFIG_ROMFS_FS is not set
+# CONFIG_SYSV_FS is not set
+# CONFIG_UFS_FS is not set
+CONFIG_NETWORK_FILESYSTEMS=y
+CONFIG_NFS_FS=y
+CONFIG_NFS_V3=y
+# CONFIG_NFS_V3_ACL is not set
+CONFIG_NFS_V4=y
+CONFIG_ROOT_NFS=y
+# CONFIG_NFSD is not set
+CONFIG_LOCKD=y
+CONFIG_LOCKD_V4=y
+CONFIG_NFS_COMMON=y
+CONFIG_SUNRPC=y
+CONFIG_SUNRPC_GSS=y
+CONFIG_RPCSEC_GSS_KRB5=y
+# CONFIG_RPCSEC_GSS_SPKM3 is not set
+# CONFIG_SMB_FS is not set
+# CONFIG_CIFS is not set
+# CONFIG_NCP_FS is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_AFS_FS is not set
+
+#
+# Partition Types
+#
+# CONFIG_PARTITION_ADVANCED is not set
+CONFIG_MSDOS_PARTITION=y
+CONFIG_NLS=y
+CONFIG_NLS_DEFAULT="iso8859-1"
+CONFIG_NLS_CODEPAGE_437=y
+# CONFIG_NLS_CODEPAGE_737 is not set
+# CONFIG_NLS_CODEPAGE_775 is not set
+# CONFIG_NLS_CODEPAGE_850 is not set
+# CONFIG_NLS_CODEPAGE_852 is not set
+# CONFIG_NLS_CODEPAGE_855 is not set
+# CONFIG_NLS_CODEPAGE_857 is not set
+# CONFIG_NLS_CODEPAGE_860 is not set
+# CONFIG_NLS_CODEPAGE_861 is not set
+# CONFIG_NLS_CODEPAGE_862 is not set
+# CONFIG_NLS_CODEPAGE_863 is not set
+# CONFIG_NLS_CODEPAGE_864 is not set
+# CONFIG_NLS_CODEPAGE_865 is not set
+# CONFIG_NLS_CODEPAGE_866 is not set
+# CONFIG_NLS_CODEPAGE_869 is not set
+# CONFIG_NLS_CODEPAGE_936 is not set
+# CONFIG_NLS_CODEPAGE_950 is not set
+# CONFIG_NLS_CODEPAGE_932 is not set
+# CONFIG_NLS_CODEPAGE_949 is not set
+# CONFIG_NLS_CODEPAGE_874 is not set
+# CONFIG_NLS_ISO8859_8 is not set
+# CONFIG_NLS_CODEPAGE_1250 is not set
+# CONFIG_NLS_CODEPAGE_1251 is not set
+# CONFIG_NLS_ASCII is not set
+CONFIG_NLS_ISO8859_1=y
+# CONFIG_NLS_ISO8859_2 is not set
+# CONFIG_NLS_ISO8859_3 is not set
+# CONFIG_NLS_ISO8859_4 is not set
+# CONFIG_NLS_ISO8859_5 is not set
+# CONFIG_NLS_ISO8859_6 is not set
+# CONFIG_NLS_ISO8859_7 is not set
+# CONFIG_NLS_ISO8859_9 is not set
+# CONFIG_NLS_ISO8859_13 is not set
+# CONFIG_NLS_ISO8859_14 is not set
+# CONFIG_NLS_ISO8859_15 is not set
+# CONFIG_NLS_KOI8_R is not set
+# CONFIG_NLS_KOI8_U is not set
+# CONFIG_NLS_UTF8 is not set
+# CONFIG_DLM is not set
+
+#
+# Kernel hacking
+#
+CONFIG_TRACE_IRQFLAGS_SUPPORT=y
+# CONFIG_PRINTK_TIME is not set
+CONFIG_ENABLE_WARN_DEPRECATED=y
+CONFIG_ENABLE_MUST_CHECK=y
+CONFIG_FRAME_WARN=2048
+CONFIG_MAGIC_SYSRQ=y
+# CONFIG_UNUSED_SYMBOLS is not set
+CONFIG_DEBUG_FS=y
+# CONFIG_HEADERS_CHECK is not set
+CONFIG_DEBUG_KERNEL=y
+# CONFIG_DEBUG_SHIRQ is not set
+CONFIG_DETECT_SOFTLOCKUP=y
+# CONFIG_BOOTPARAM_SOFTLOCKUP_PANIC is not set
+CONFIG_BOOTPARAM_SOFTLOCKUP_PANIC_VALUE=0
+CONFIG_SCHED_DEBUG=y
+# CONFIG_SCHEDSTATS is not set
+# CONFIG_TIMER_STATS is not set
+# CONFIG_DEBUG_OBJECTS is not set
+# CONFIG_DEBUG_SLAB is not set
+CONFIG_DEBUG_PREEMPT=y
+# CONFIG_DEBUG_RT_MUTEXES is not set
+# CONFIG_RT_MUTEX_TESTER is not set
+# CONFIG_DEBUG_SPINLOCK is not set
+# CONFIG_DEBUG_MUTEXES is not set
+# CONFIG_DEBUG_LOCK_ALLOC is not set
+# CONFIG_PROVE_LOCKING is not set
+# CONFIG_LOCK_STAT is not set
+# CONFIG_DEBUG_SPINLOCK_SLEEP is not set
+# CONFIG_DEBUG_LOCKING_API_SELFTESTS is not set
+# CONFIG_DEBUG_KOBJECT is not set
+CONFIG_DEBUG_INFO=y
+# CONFIG_DEBUG_VM is not set
+# CONFIG_DEBUG_WRITECOUNT is not set
+CONFIG_DEBUG_MEMORY_INIT=y
+# CONFIG_DEBUG_LIST is not set
+# CONFIG_DEBUG_SG is not set
+# CONFIG_BOOT_PRINTK_DELAY is not set
+# CONFIG_RCU_TORTURE_TEST is not set
+# CONFIG_BACKTRACE_SELF_TEST is not set
+# CONFIG_FAULT_INJECTION is not set
+CONFIG_SYSCTL_SYSCALL_CHECK=y
+# CONFIG_SAMPLES is not set
+CONFIG_HAVE_ARCH_KGDB=y
+# CONFIG_KGDB is not set
+CONFIG_CMDLINE=""
+# CONFIG_DEBUG_STACK_USAGE is not set
+# CONFIG_CAVIUM_GDB is not set
+# CONFIG_RUNTIME_DEBUG is not set
+
+#
+# Security options
+#
+# CONFIG_KEYS is not set
+CONFIG_SECURITY=y
+CONFIG_SECURITY_NETWORK=y
+# CONFIG_SECURITY_NETWORK_XFRM is not set
+# CONFIG_SECURITY_FILE_CAPABILITIES is not set
+CONFIG_SECURITY_DEFAULT_MMAP_MIN_ADDR=0
+CONFIG_CRYPTO=y
+
+#
+# Crypto core or helper
+#
+CONFIG_CRYPTO_ALGAPI=y
+CONFIG_CRYPTO_BLKCIPHER=y
+CONFIG_CRYPTO_HASH=y
+CONFIG_CRYPTO_MANAGER=y
+# CONFIG_CRYPTO_GF128MUL is not set
+# CONFIG_CRYPTO_NULL is not set
+# CONFIG_CRYPTO_CRYPTD is not set
+# CONFIG_CRYPTO_AUTHENC is not set
+# CONFIG_CRYPTO_TEST is not set
+
+#
+# Authenticated Encryption with Associated Data
+#
+# CONFIG_CRYPTO_CCM is not set
+# CONFIG_CRYPTO_GCM is not set
+# CONFIG_CRYPTO_SEQIV is not set
+
+#
+# Block modes
+#
+CONFIG_CRYPTO_CBC=y
+# CONFIG_CRYPTO_CTR is not set
+# CONFIG_CRYPTO_CTS is not set
+# CONFIG_CRYPTO_ECB is not set
+# CONFIG_CRYPTO_LRW is not set
+# CONFIG_CRYPTO_PCBC is not set
+# CONFIG_CRYPTO_XTS is not set
+
+#
+# Hash modes
+#
+CONFIG_CRYPTO_HMAC=y
+# CONFIG_CRYPTO_XCBC is not set
+
+#
+# Digest
+#
+# CONFIG_CRYPTO_CRC32C is not set
+# CONFIG_CRYPTO_MD4 is not set
+CONFIG_CRYPTO_MD5=y
+# CONFIG_CRYPTO_MICHAEL_MIC is not set
+# CONFIG_CRYPTO_RMD128 is not set
+# CONFIG_CRYPTO_RMD160 is not set
+# CONFIG_CRYPTO_RMD256 is not set
+# CONFIG_CRYPTO_RMD320 is not set
+# CONFIG_CRYPTO_SHA1 is not set
+# CONFIG_CRYPTO_SHA256 is not set
+# CONFIG_CRYPTO_SHA512 is not set
+# CONFIG_CRYPTO_TGR192 is not set
+# CONFIG_CRYPTO_WP512 is not set
+
+#
+# Ciphers
+#
+# CONFIG_CRYPTO_AES is not set
+# CONFIG_CRYPTO_ANUBIS is not set
+# CONFIG_CRYPTO_ARC4 is not set
+# CONFIG_CRYPTO_BLOWFISH is not set
+# CONFIG_CRYPTO_CAMELLIA is not set
+# CONFIG_CRYPTO_CAST5 is not set
+# CONFIG_CRYPTO_CAST6 is not set
+CONFIG_CRYPTO_DES=y
+# CONFIG_CRYPTO_FCRYPT is not set
+# CONFIG_CRYPTO_KHAZAD is not set
+# CONFIG_CRYPTO_SALSA20 is not set
+# CONFIG_CRYPTO_SEED is not set
+# CONFIG_CRYPTO_SERPENT is not set
+# CONFIG_CRYPTO_TEA is not set
+# CONFIG_CRYPTO_TWOFISH is not set
+
+#
+# Compression
+#
+# CONFIG_CRYPTO_DEFLATE is not set
+# CONFIG_CRYPTO_LZO is not set
+CONFIG_CRYPTO_HW=y
+# CONFIG_CRYPTO_DEV_HIFN_795X is not set
+
+#
+# Library routines
+#
+CONFIG_BITREVERSE=y
+# CONFIG_GENERIC_FIND_FIRST_BIT is not set
+# CONFIG_CRC_CCITT is not set
+# CONFIG_CRC16 is not set
+# CONFIG_CRC_T10DIF is not set
+# CONFIG_CRC_ITU_T is not set
+CONFIG_CRC32=y
+# CONFIG_CRC7 is not set
+# CONFIG_LIBCRC32C is not set
+CONFIG_PLIST=y
+CONFIG_HAS_IOMEM=y
+CONFIG_HAS_IOPORT=y
+CONFIG_HAS_DMA=y
diff --git a/arch/mips/kernel/irq-octeon.c b/arch/mips/kernel/irq-octeon.c
new file mode 100644
index 0000000..27b28ab
--- /dev/null
+++ b/arch/mips/kernel/irq-octeon.c
@@ -0,0 +1,527 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2007 Cavium Networks
+ */
+#include <linux/init.h>
+#include <linux/interrupt.h>
+#include <linux/kernel.h>
+#include <linux/pci.h>
+
+#include <asm/irq_cpu.h>
+#include <asm/mipsregs.h>
+#include <asm/system.h>
+
+#include "../cavium-octeon/hal.h"
+
+DEFINE_RWLOCK(octeon_irq_ciu0_rwlock);
+DEFINE_RWLOCK(octeon_irq_ciu1_rwlock);
+DEFINE_SPINLOCK(octeon_irq_msi_lock);
+
+static void octeon_irq_core_ack(unsigned int irq)
+{
+	/* We don't need to disable IRQs to make these atomic since they are
+	   already disabled earlier in the low level interrupt code */
+	clear_c0_status(0x100 << irq);
+	/* The two user interrupts must be cleared manually */
+	if (irq < 2)
+		clear_c0_cause(0x100 << irq);
+}
+
+static void octeon_irq_core_eoi(unsigned int irq)
+{
+	irq_desc_t *desc = irq_desc + irq;
+	/* If an IRQ is being processed while we are disabling it the handler
+	   will attempt to unmask the interrupt after it has been disabled */
+	if (desc->status & IRQ_DISABLED)
+		return;
+	/* We don't need to disable IRQs to make these atomic since they are
+	   already disabled earlier in the low level interrupt code */
+	set_c0_status(0x100 << irq);
+}
+
+static void octeon_irq_core_enable(unsigned int irq)
+{
+	/* We need to disable interrupts to make sure our updates are atomic */
+	unsigned long flags;
+	local_irq_save(flags);
+	set_c0_status(0x100 << irq);
+	local_irq_restore(flags);
+}
+
+static void octeon_irq_core_disable_local(unsigned int irq)
+{
+	/* We need to disable interrupts to make sure our updates are atomic */
+	unsigned long flags;
+	local_irq_save(flags);
+	clear_c0_status(0x100 << irq);
+	local_irq_restore(flags);
+}
+
+static void octeon_irq_core_disable(unsigned int irq)
+{
+#ifdef CONFIG_SMP
+	on_each_cpu((void (*)(void *)) octeon_irq_core_disable_local,
+		    (void *) (long) irq, 1);
+#else
+	octeon_irq_core_disable_local(irq);
+#endif
+}
+
+struct irq_chip octeon_irq_chip_core = {
+	.name = "Core",
+	.enable = octeon_irq_core_enable,
+	.disable = octeon_irq_core_disable,
+	.ack = octeon_irq_core_ack,
+	.eoi = octeon_irq_core_eoi,
+};
+
+
+static void octeon_irq_ciu0_ack(unsigned int irq)
+{
+	/* In order to avoid any locking accessing the CIU, we acknowledge CIU
+	   interrupts by disabling all of them. This way we can use a per core
+	   register and avoid any out of core locking requirements. This has
+	   the side affect that CIU interrupts can't be processed recursively */
+	/* We don't need to disable IRQs to make these atomic since they are
+	   already disabled earlier in the low level interrupt code */
+	clear_c0_status(0x100 << 2);
+}
+
+static void octeon_irq_ciu0_eoi(unsigned int irq)
+{
+	/* Enable all CIU interrupts again */
+	/* We don't need to disable IRQs to make these atomic since they are
+	   already disabled earlier in the low level interrupt code */
+	set_c0_status(0x100 << 2);
+}
+
+static void octeon_irq_ciu0_enable(unsigned int irq)
+{
+	int coreid = cvmx_get_core_num();
+	unsigned long flags;
+	uint64_t en0;
+	int bit = irq - OCTEON_IRQ_WORKQ0;	/* Bit 0-63 of EN0 */
+
+	/* A read lock is used here to make sure only one core is ever updating
+	   the CIU enable bits at a time. During an enable the cores don't
+	   interfere with each other. During a disable the write lock stops any
+	   enables that might cause a problem */
+	read_lock_irqsave(&octeon_irq_ciu0_rwlock, flags);
+	en0 = cvmx_read_csr(CVMX_CIU_INTX_EN0(coreid * 2));
+	en0 |= 1ull << bit;
+	cvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), en0);
+	cvmx_read_csr(CVMX_CIU_INTX_EN0(coreid * 2));
+	read_unlock_irqrestore(&octeon_irq_ciu0_rwlock, flags);
+}
+
+static void octeon_irq_ciu0_disable(unsigned int irq)
+{
+	int bit = irq - OCTEON_IRQ_WORKQ0;	/* Bit 0-63 of EN0 */
+	unsigned long flags;
+	uint64_t en0;
+#ifdef CONFIG_SMP
+	int cpu;
+	write_lock_irqsave(&octeon_irq_ciu0_rwlock, flags);
+	for (cpu = 0; cpu < NR_CPUS; cpu++) {
+		if (cpu_present(cpu)) {
+			int coreid = cpu_logical_map(cpu);
+			en0 = cvmx_read_csr(CVMX_CIU_INTX_EN0(coreid * 2));
+			en0 &= ~(1ull << bit);
+			cvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), en0);
+		}
+	}
+	/* We need to do a read after the last update to make sure all of them
+	   are done */
+	cvmx_read_csr(CVMX_CIU_INTX_EN0(cvmx_get_core_num() * 2));
+	write_unlock_irqrestore(&octeon_irq_ciu0_rwlock, flags);
+#else
+	int coreid = cvmx_get_core_num();
+	local_irq_save(flags);
+	en0 = cvmx_read_csr(CVMX_CIU_INTX_EN0(coreid * 2));
+	en0 &= ~(1ull << bit);
+	cvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), en0);
+	cvmx_read_csr(CVMX_CIU_INTX_EN0(coreid * 2));
+	local_irq_restore(flags);
+#endif
+}
+
+#ifdef CONFIG_SMP
+static void octeon_irq_ciu0_set_affinity(unsigned int irq, cpumask_t dest)
+{
+	int cpu;
+	int bit = irq - OCTEON_IRQ_WORKQ0;	/* Bit 0-63 of EN0 */
+
+	write_lock(&octeon_irq_ciu0_rwlock);
+	for (cpu = 0; cpu < NR_CPUS; cpu++) {
+		if (cpu_present(cpu)) {
+			int coreid = cpu_logical_map(cpu);
+			uint64_t en0 =
+				cvmx_read_csr(CVMX_CIU_INTX_EN0(coreid * 2));
+			if (cpu_isset(cpu, dest))
+				en0 |= 1ull << bit;
+			else
+				en0 &= ~(1ull << bit);
+			cvmx_write_csr(CVMX_CIU_INTX_EN0(coreid * 2), en0);
+		}
+	}
+	/* We need to do a read after the last update to make sure all of them
+	   are done */
+	cvmx_read_csr(CVMX_CIU_INTX_EN0(cvmx_get_core_num() * 2));
+	write_unlock(&octeon_irq_ciu0_rwlock);
+}
+#endif
+
+struct irq_chip octeon_irq_chip_ciu0 = {
+	.name = "CIU0",
+	.enable = octeon_irq_ciu0_enable,
+	.disable = octeon_irq_ciu0_disable,
+	.ack = octeon_irq_ciu0_ack,
+	.eoi = octeon_irq_ciu0_eoi,
+#ifdef CONFIG_SMP
+	.set_affinity = octeon_irq_ciu0_set_affinity,
+#endif
+};
+
+
+static void octeon_irq_ciu1_ack(unsigned int irq)
+{
+	/* In order to avoid any locking accessing the CIU, we acknowledge CIU
+	   interrupts by disabling all of them. This way we can use a per core
+	   register and avoid any out of core locking requirements. This has
+	   the side affect that CIU interrupts can't be processed recursively */
+	/* We don't need to disable IRQs to make these atomic since they are
+	   already disabled earlier in the low level interrupt code */
+	clear_c0_status(0x100 << 3);
+}
+
+static void octeon_irq_ciu1_eoi(unsigned int irq)
+{
+	/* Enable all CIU interrupts again */
+	/* We don't need to disable IRQs to make these atomic since they are
+	   already disabled earlier in the low level interrupt code */
+	set_c0_status(0x100 << 3);
+}
+
+static void octeon_irq_ciu1_enable(unsigned int irq)
+{
+	int coreid = cvmx_get_core_num();
+	unsigned long flags;
+	uint64_t en1;
+	int bit = irq - OCTEON_IRQ_WDOG0;	/* Bit 0-63 of EN1 */
+
+	/* A read lock is used here to make sure only one core is ever updating
+	   the CIU enable bits at a time. During an enable the cores don't
+	   interfere with each other. During a disable the write lock stops any
+	   enables that might cause a problem */
+	read_lock_irqsave(&octeon_irq_ciu1_rwlock, flags);
+	en1 = cvmx_read_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1));
+	en1 |= 1ull << bit;
+	cvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), en1);
+	cvmx_read_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1));
+	read_unlock_irqrestore(&octeon_irq_ciu1_rwlock, flags);
+}
+
+static void octeon_irq_ciu1_disable(unsigned int irq)
+{
+	int bit = irq - OCTEON_IRQ_WDOG0;	/* Bit 0-63 of EN1 */
+	unsigned long flags;
+	uint64_t en1;
+#ifdef CONFIG_SMP
+	int cpu;
+	write_lock_irqsave(&octeon_irq_ciu1_rwlock, flags);
+	for (cpu = 0; cpu < NR_CPUS; cpu++) {
+		if (cpu_present(cpu)) {
+			int coreid = cpu_logical_map(cpu);
+			en1 = cvmx_read_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1));
+			en1 &= ~(1ull << bit);
+			cvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), en1);
+		}
+	}
+	/* We need to do a read after the last update to make sure all of them
+	   are done */
+	cvmx_read_csr(CVMX_CIU_INTX_EN1(cvmx_get_core_num() * 2 + 1));
+	write_unlock_irqrestore(&octeon_irq_ciu1_rwlock, flags);
+#else
+	int coreid = cvmx_get_core_num();
+	local_irq_save(flags);
+	en1 = cvmx_read_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1));
+	en1 &= ~(1ull << bit);
+	cvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), en1);
+	cvmx_read_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1));
+	local_irq_restore(flags);
+#endif
+}
+
+#ifdef CONFIG_SMP
+static void octeon_irq_ciu1_set_affinity(unsigned int irq, cpumask_t dest)
+{
+	int cpu;
+	int bit = irq - OCTEON_IRQ_WDOG0;	/* Bit 0-63 of EN1 */
+
+	write_lock(&octeon_irq_ciu1_rwlock);
+	for (cpu = 0; cpu < NR_CPUS; cpu++) {
+		if (cpu_present(cpu)) {
+			int coreid = cpu_logical_map(cpu);
+			uint64_t en1 =
+				cvmx_read_csr(CVMX_CIU_INTX_EN1
+					      (coreid * 2 + 1));
+			if (cpu_isset(cpu, dest))
+				en1 |= 1ull << bit;
+			else
+				en1 &= ~(1ull << bit);
+			cvmx_write_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1), en1);
+		}
+	}
+	/* We need to do a read after the last update to make sure all of them
+	   are done */
+	cvmx_read_csr(CVMX_CIU_INTX_EN1(cvmx_get_core_num() * 2 + 1));
+	write_unlock(&octeon_irq_ciu1_rwlock);
+}
+#endif
+
+struct irq_chip octeon_irq_chip_ciu1 = {
+	.name = "CIU1",
+	.enable = octeon_irq_ciu1_enable,
+	.disable = octeon_irq_ciu1_disable,
+	.ack = octeon_irq_ciu1_ack,
+	.eoi = octeon_irq_ciu1_eoi,
+#ifdef CONFIG_SMP
+	.set_affinity = octeon_irq_ciu1_set_affinity,
+#endif
+};
+
+
+static void octeon_irq_i8289_master_unmask(unsigned int irq)
+{
+	unsigned long flags;
+	local_irq_save(flags);
+	outb(inb(0x21) & ~(1 << (irq - OCTEON_IRQ_I8259M0)), 0x21);
+	local_irq_restore(flags);
+}
+
+static void octeon_irq_i8289_master_mask(unsigned int irq)
+{
+	unsigned long flags;
+	local_irq_save(flags);
+	outb(inb(0x21) | (1 << (irq - OCTEON_IRQ_I8259M0)), 0x21);
+	local_irq_restore(flags);
+}
+
+struct irq_chip octeon_irq_chip_i8259_master = {
+	.name = "i8259M",
+	.mask = octeon_irq_i8289_master_mask,
+	.mask_ack = octeon_irq_i8289_master_mask,
+	.unmask = octeon_irq_i8289_master_unmask,
+	.eoi = octeon_irq_i8289_master_unmask,
+};
+
+
+static void octeon_irq_i8289_slave_unmask(unsigned int irq)
+{
+	outb(inb(0xa1) & ~(1 << (irq - OCTEON_IRQ_I8259S0)), 0xa1);
+}
+
+static void octeon_irq_i8289_slave_mask(unsigned int irq)
+{
+	outb(inb(0xa1) | (1 << (irq - OCTEON_IRQ_I8259S0)), 0xa1);
+}
+
+struct irq_chip octeon_irq_chip_i8259_slave = {
+	.name = "i8259S",
+	.mask = octeon_irq_i8289_slave_mask,
+	.mask_ack = octeon_irq_i8289_slave_mask,
+	.unmask = octeon_irq_i8289_slave_unmask,
+	.eoi = octeon_irq_i8289_slave_unmask,
+};
+
+#ifdef CONFIG_PCI_MSI
+
+static void octeon_irq_msi_ack(unsigned int irq)
+{
+	if (!octeon_has_feature(OCTEON_FEATURE_PCIE)) {
+		/* These chips have PCI */
+		cvmx_write_csr(CVMX_NPI_NPI_MSI_RCV,
+			       1ull << (irq - OCTEON_IRQ_MSI_BIT0));
+	} else {
+		/* These chips have PCIe. Thankfully the ACK doesn't need any
+		   locking */
+		cvmx_write_csr(CVMX_PEXP_NPEI_MSI_RCV0,
+			       1ull << (irq - OCTEON_IRQ_MSI_BIT0));
+	}
+}
+
+static void octeon_irq_msi_eoi(unsigned int irq)
+{
+	/* Nothing needed */
+}
+
+static void octeon_irq_msi_enable(unsigned int irq)
+{
+	if (!octeon_has_feature(OCTEON_FEATURE_PCIE)) {
+		/* Octeon PCI doesn't have the ability to mask/unmask MSI
+		   interrupts individually. Instead of masking/unmasking them
+		   in groups of 16, we simple assume MSI devices are well
+		   behaved. MSI interrupts are always enable and the ACK is
+		   assumed to be enough */
+	} else {
+		/* These chips have PCIe. Note that we only support the first
+		   64 MSI interrupts. Unfortunately all the MSI enables are in
+		   the same register. We use MSI0's lock to control access to
+		   them all. */
+		uint64_t en;
+		unsigned long flags;
+		spin_lock_irqsave(&octeon_irq_msi_lock, flags);
+		en = cvmx_read_csr(CVMX_PEXP_NPEI_MSI_ENB0);
+		en |= 1ull << (irq - OCTEON_IRQ_MSI_BIT0);
+		cvmx_write_csr(CVMX_PEXP_NPEI_MSI_ENB0, en);
+		cvmx_read_csr(CVMX_PEXP_NPEI_MSI_ENB0);
+		spin_unlock_irqrestore(&octeon_irq_msi_lock, flags);
+	}
+}
+
+static void octeon_irq_msi_disable(unsigned int irq)
+{
+	if (!octeon_has_feature(OCTEON_FEATURE_PCIE)) {
+		/* See comment in enable */
+	} else {
+		/* These chips have PCIe. Note that we only support the first
+		   64 MSI interrupts. Unfortunately all the MSI enables are in
+		   the same register. We use MSI0's lock to control access to
+		   them all. */
+		uint64_t en;
+		unsigned long flags;
+		spin_lock_irqsave(&octeon_irq_msi_lock, flags);
+		en = cvmx_read_csr(CVMX_PEXP_NPEI_MSI_ENB0);
+		en &= ~(1ull << (irq - OCTEON_IRQ_MSI_BIT0));
+		cvmx_write_csr(CVMX_PEXP_NPEI_MSI_ENB0, en);
+		cvmx_read_csr(CVMX_PEXP_NPEI_MSI_ENB0);
+		spin_unlock_irqrestore(&octeon_irq_msi_lock, flags);
+	}
+}
+
+struct irq_chip octeon_irq_chip_msi = {
+	.name = "MSI",
+	.enable = octeon_irq_msi_enable,
+	.disable = octeon_irq_msi_disable,
+	.ack = octeon_irq_msi_ack,
+	.eoi = octeon_irq_msi_eoi,
+};
+#endif
+
+void __init arch_init_irq(void)
+{
+	int irq;
+
+#ifdef CONFIG_SMP
+	/* Set the default affinity to the boot cpu. */
+	irq_default_affinity = cpumask_of_cpu(smp_processor_id());
+#endif
+	if (NR_IRQS < OCTEON_IRQ_LAST)
+		pr_err("octeon_irq_init: NR_IRQS is set too low\n");
+
+	/* 0-7 Mips internal */
+	for (irq = OCTEON_IRQ_SW0; irq <= OCTEON_IRQ_TIMER; irq++) {
+		set_irq_chip_and_handler(irq, &octeon_irq_chip_core,
+					 handle_percpu_irq);
+	}
+
+	/* 8-71 CIU_INT_SUM0 */
+	for (irq = OCTEON_IRQ_WORKQ0; irq <= OCTEON_IRQ_BOOTDMA; irq++) {
+		set_irq_chip_and_handler(irq, &octeon_irq_chip_ciu0,
+					 handle_percpu_irq);
+	}
+
+	/* 72-135 CIU_INT_SUM1 */
+	for (irq = OCTEON_IRQ_WDOG0; irq <= OCTEON_IRQ_RESERVED135; irq++) {
+		set_irq_chip_and_handler(irq, &octeon_irq_chip_ciu1,
+					 handle_percpu_irq);
+	}
+
+	/* 136 - 143 are reserved to align the i8259 in a multiple of 16. This
+	   alignment is necessary since old style ISA interrupts hanging off
+	   the i8259 have internal alignment assumptions */
+
+	/* 144-151 i8259 master controller */
+	for (irq = OCTEON_IRQ_I8259M0; irq <= OCTEON_IRQ_I8259M7; irq++) {
+		set_irq_chip_and_handler(irq, &octeon_irq_chip_i8259_master,
+					 handle_level_irq);
+	}
+
+	/* 152-159 i8259 slave controller */
+	for (irq = OCTEON_IRQ_I8259S0; irq <= OCTEON_IRQ_I8259S7; irq++) {
+		set_irq_chip_and_handler(irq, &octeon_irq_chip_i8259_slave,
+					 handle_level_irq);
+	}
+
+#ifdef CONFIG_PCI_MSI
+	/* 160-223 PCI/PCIe MSI interrupts */
+	for (irq = OCTEON_IRQ_MSI_BIT0; irq <= OCTEON_IRQ_MSI_BIT63; irq++) {
+		set_irq_chip_and_handler(irq, &octeon_irq_chip_msi,
+					 handle_percpu_irq);
+	}
+#endif
+
+	set_c0_status(0x300 << 2);
+}
+
+#ifdef CONFIG_HOTPLUG_CPU
+static int is_irq_enabled_on_cpu(unsigned int irq, unsigned int cpu)
+{
+       unsigned int isset;
+#ifdef CONFIG_SMP
+       int coreid = cpu_logical_map(cpu);
+#else
+	int coreid = cvmx_get_core_num();
+#endif
+	int bit = (irq < OCTEON_IRQ_WDOG0) ?
+		irq - OCTEON_IRQ_WORKQ0 : irq - OCTEON_IRQ_WDOG0;
+       if (irq < 64) {
+		isset = (cvmx_read_csr(CVMX_CIU_INTX_EN0(coreid * 2)) &
+			(1ull << bit)) >> bit;
+       } else {
+	       isset = (cvmx_read_csr(CVMX_CIU_INTX_EN1(coreid * 2 + 1)) &
+			(1ull << bit)) >> bit;
+       }
+       return isset;
+}
+
+void fixup_irqs(void)
+{
+       int irq;
+
+	for (irq = OCTEON_IRQ_SW0; irq <= OCTEON_IRQ_TIMER; irq++)
+		octeon_irq_core_disable_local(irq);
+
+	for (irq = OCTEON_IRQ_WORKQ0; irq <= OCTEON_IRQ_GPIO15; irq++) {
+		if (is_irq_enabled_on_cpu(irq, smp_processor_id())) {
+			/* ciu irq migrates to next cpu */
+			octeon_irq_chip_ciu0.disable(irq);
+			octeon_irq_ciu0_set_affinity(irq, cpu_online_map);
+		}
+	}
+
+#if 0
+	for (irq = OCTEON_IRQ_MBOX0; irq <= OCTEON_IRQ_MBOX1; irq++)
+		octeon_irq_mailbox_mask(irq);
+#endif
+	for (irq = OCTEON_IRQ_UART0; irq <= OCTEON_IRQ_BOOTDMA; irq++) {
+		if (is_irq_enabled_on_cpu(irq, smp_processor_id())) {
+			/* ciu irq migrates to next cpu */
+			octeon_irq_chip_ciu0.disable(irq);
+			octeon_irq_ciu0_set_affinity(irq, cpu_online_map);
+		}
+	}
+
+	for (irq = OCTEON_IRQ_UART2; irq <= OCTEON_IRQ_RESERVED135; irq++) {
+		if (is_irq_enabled_on_cpu(irq, smp_processor_id())) {
+			/* ciu irq migrates to next cpu */
+			octeon_irq_chip_ciu1.disable(irq);
+			octeon_irq_ciu1_set_affinity(irq, cpu_online_map);
+		}
+	}
+}
+
+#endif /* CONFIG_HOTPLUG_CPU */
diff --git a/arch/mips/kernel/octeon_switch.S b/arch/mips/kernel/octeon_switch.S
new file mode 100644
index 0000000..f3ac934
--- /dev/null
+++ b/arch/mips/kernel/octeon_switch.S
@@ -0,0 +1,516 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 1994, 1995, 1996, 1998, 1999, 2002, 2003 Ralf Baechle
+ * Copyright (C) 1996 David S. Miller (dm@engr.sgi.com)
+ * Copyright (C) 1994, 1995, 1996, by Andreas Busse
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ * Copyright (C) 2000 MIPS Technologies, Inc.
+ *    written by Carsten Langgaard, carstenl@mips.com
+ */
+#include <asm/asm.h>
+#include <asm/cachectl.h>
+#include <asm/fpregdef.h>
+#include <asm/mipsregs.h>
+#include <asm/asm-offsets.h>
+#include <asm/page.h>
+#include <asm/pgtable-bits.h>
+#include <asm/regdef.h>
+#include <asm/stackframe.h>
+#include <asm/thread_info.h>
+
+#include <asm/asmmacro.h>
+
+/*
+ * Offset to the current process status flags, the first 32 bytes of the
+ * stack are not used.
+ */
+#define ST_OFF (_THREAD_SIZE - 32 - PT_SIZE + PT_STATUS)
+
+/*
+ * task_struct *resume(task_struct *prev, task_struct *next,
+ *                     struct thread_info *next_ti)
+ */
+	.align	7
+	LEAF(resume)
+	.set arch=octeon
+#ifndef CONFIG_CPU_HAS_LLSC
+	sw	zero, ll_bit
+#endif
+	mfc0	t1, CP0_STATUS
+	LONG_S	t1, THREAD_STATUS(a0)
+	cpu_save_nonscratch a0
+	LONG_S	ra, THREAD_REG31(a0)
+
+	/* check if we need to save COP2 registers */
+	PTR_L	t2, TASK_THREAD_INFO(a0)
+	/* if we are a kernel thread, TI_ADDR_LIMIT is
+	   KERNEL_DS  ((mm_segment_t) { 0UL }) and we can't
+	   be using COP2, so jump around the save */
+	LONG_L  t0, TI_ADDR_LIMIT(t2)
+	beqz    t0, 1f
+	LONG_L	t0, ST_OFF(t2)
+	bbit0	t0, 30, 1f
+
+	/* Disable COP2 in the stored process state */
+	li	t1, ST0_CU2
+	xor	t0, t1
+	LONG_S	t0, ST_OFF(t2)
+
+	/* Enable COP2 so we can save it */
+	mfc0	t0, CP0_STATUS
+	or	t0, t1
+	mtc0	t0, CP0_STATUS
+
+	/* Save COP2 */
+	daddu	a0, THREAD_CP2
+	jal octeon_cop2_save
+	dsubu	a0, THREAD_CP2
+
+	/* Disable COP2 now that we are done */
+	mfc0	t0, CP0_STATUS
+	li	t1, ST0_CU2
+	xor	t0, t1
+	mtc0	t0, CP0_STATUS
+
+1:
+#if CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE > 0
+	/* Check if we need to store CVMSEG state */
+	mfc0	t0, $11,7 	/* CvmMemCtl */
+	bbit0	t0, 6, 3f	/* Is user access enabled? */
+
+	/* Store the CVMSEG state */
+	andi	t0, 0x3f	/* Extract the size of CVMSEG */
+	sll	t0, 7-LONGLOG-1	/* Multiply * (cache line size/sizeof(long)/2) */
+	li	t1, -32768 	/* Base address of CVMSEG */
+	LONG_ADDI t2, a0, THREAD_CVMSEG	/* Where to store CVMSEG to */
+	synciobdma
+2:
+	.set noreorder
+	LONG_L	t8, 0(t1)	/* Load from CVMSEG */
+	subu	t0, 1		/* Decrement loop var */
+	LONG_L	t9, LONGSIZE(t1)/* Load from CVMSEG */
+	LONG_ADDU t1, LONGSIZE*2 /* Increment loc in CVMSEG */
+	LONG_S	t8, 0(t2)	/* Store CVMSEG to thread storage */
+	LONG_ADDU t2, LONGSIZE*2 /* Increment loc in thread storage */
+	bnez	t0, 2b		/* Loop until we've copied it all */
+	 LONG_S	t9, -LONGSIZE(t2)/* Store CVMSEG to thread storage */
+	.set reorder
+
+	/* Disable access to CVMSEG */
+	mfc0	t0, $11,7 	/* CvmMemCtl */
+	xori	t0, t0, 0x40	/* Bit 6 is CVMSEG user enable */
+	mtc0	t0, $11,7 	/* CvmMemCtl */
+#endif
+3:
+	/*
+	 * The order of restoring the registers takes care of the race
+	 * updating $28, $29 and kernelsp without disabling ints.
+	 */
+	move	$28, a2
+	cpu_restore_nonscratch a1
+
+#if (_THREAD_SIZE - 32) < 0x8000
+	PTR_ADDIU	t0, $28, _THREAD_SIZE - 32
+#else
+	PTR_LI		t0, _THREAD_SIZE - 32
+	PTR_ADDU	t0, $28
+#endif
+	set_saved_sp	t0, t1, t2
+
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	/* We need to put the thread pointer in CVMMEM immediately. The
+		kernel will use this value during TLB exceptions even
+		though userspace hasn't accessed CVMMEM */
+	LONG_L	t1, TI_TP_VALUE($28)
+	LONG_S	t1, FAST_ACCESS_THREAD_OFFSET($0)
+#endif
+
+	mfc0	t1, CP0_STATUS		/* Do we really need this? */
+	li	a3, 0xff01
+	and	t1, a3
+	LONG_L	a2, THREAD_STATUS(a1)
+	nor	a3, $0, a3
+	and	a2, a3
+	or	a2, t1
+	mtc0	a2, CP0_STATUS
+	move	v0, a0
+	jr	ra
+	END(resume)
+
+/*
+ * void octeon_cop2_save(struct octeon_cop2_state *a0)
+ */
+	.align	7
+	LEAF(octeon_cop2_save)
+
+	dmfc0	t9, $9,7	/* CvmCtl register. */
+
+        /* Save the COP2 CRC state */
+	dmfc2	t0, 0x0201
+	dmfc2	t1, 0x0202
+	dmfc2	t2, 0x0200
+	sd	t0, OCTEON_CP2_CRC_IV(a0)
+	sd	t1, OCTEON_CP2_CRC_LENGTH(a0)
+	sd	t2, OCTEON_CP2_CRC_POLY(a0)
+
+	bbit1	t9, 28, 1f	/* Skip next instructions if CvmCtl[NODFA_CP2] set */
+
+	/* Save the LLM state */
+	dmfc2	t0, 0x0402
+	dmfc2	t1, 0x040A
+	sd	t0, OCTEON_CP2_LLM_DAT(a0)
+	sd	t1, OCTEON_CP2_LLM_DAT+8(a0)
+
+1:      bbit1	t9, 26, 3f	/* done if CvmCtl[NOCRYPTO] set */
+
+	/* Save the COP2 crypto state */
+        /* this part is mostly common to both pass 1 and later revisions */
+	dmfc2 	t0, 0x0084
+	dmfc2 	t1, 0x0080
+	dmfc2 	t2, 0x0081
+	dmfc2 	t3, 0x0082
+	sd	t0, OCTEON_CP2_3DES_IV(a0)
+	dmfc2 	t0, 0x0088
+	sd	t1, OCTEON_CP2_3DES_KEY(a0)
+	dmfc2 	t1, 0x0111                      /* only necessary for pass 1 */
+	sd	t2, OCTEON_CP2_3DES_KEY+8(a0)
+	dmfc2 	t2, 0x0102
+	sd	t3, OCTEON_CP2_3DES_KEY+16(a0)
+	dmfc2 	t3, 0x0103
+	sd	t0, OCTEON_CP2_3DES_RESULT(a0)
+	dmfc2 	t0, 0x0104
+	sd	t1, OCTEON_CP2_AES_INP0(a0)     /* only necessary for pass 1 */
+	dmfc2 	t1, 0x0105
+	sd	t2, OCTEON_CP2_AES_IV(a0)
+	dmfc2	t2, 0x0106
+	sd	t3, OCTEON_CP2_AES_IV+8(a0)
+	dmfc2 	t3, 0x0107
+	sd	t0, OCTEON_CP2_AES_KEY(a0)
+	dmfc2	t0, 0x0110
+	sd	t1, OCTEON_CP2_AES_KEY+8(a0)
+	dmfc2	t1, 0x0100
+	sd	t2, OCTEON_CP2_AES_KEY+16(a0)
+	dmfc2	t2, 0x0101
+	sd	t3, OCTEON_CP2_AES_KEY+24(a0)
+	mfc0	t3, $15,0 	/* Get the processor ID register */
+	sd	t0, OCTEON_CP2_AES_KEYLEN(a0)
+	li	t0, 0x000d0000	/* This is the processor ID of Octeon Pass1 */
+	sd	t1, OCTEON_CP2_AES_RESULT(a0)
+	sd	t2, OCTEON_CP2_AES_RESULT+8(a0)
+
+	beq	t3, t0, 2f	/* Skip to the Pass1 version of the remainder of the COP2 state */
+
+        /* the non-pass1 state when !CvmCtl[NOCRYPTO] */
+	dmfc2	t1, 0x0240
+	dmfc2	t2, 0x0241
+	dmfc2	t3, 0x0242
+	dmfc2	t0, 0x0243
+	sd	t1, OCTEON_CP2_HSH_DATW(a0)
+	dmfc2	t1, 0x0244
+	sd	t2, OCTEON_CP2_HSH_DATW+8(a0)
+	dmfc2	t2, 0x0245
+	sd	t3, OCTEON_CP2_HSH_DATW+16(a0)
+	dmfc2	t3, 0x0246
+	sd	t0, OCTEON_CP2_HSH_DATW+24(a0)
+	dmfc2	t0, 0x0247
+	sd	t1, OCTEON_CP2_HSH_DATW+32(a0)
+	dmfc2	t1, 0x0248
+	sd	t2, OCTEON_CP2_HSH_DATW+40(a0)
+	dmfc2	t2, 0x0249
+	sd	t3, OCTEON_CP2_HSH_DATW+48(a0)
+	dmfc2	t3, 0x024A
+	sd	t0, OCTEON_CP2_HSH_DATW+56(a0)
+	dmfc2	t0, 0x024B
+	sd	t1, OCTEON_CP2_HSH_DATW+64(a0)
+	dmfc2	t1, 0x024C
+	sd	t2, OCTEON_CP2_HSH_DATW+72(a0)
+	dmfc2	t2, 0x024D
+	sd	t3, OCTEON_CP2_HSH_DATW+80(a0)
+	dmfc2 	t3, 0x024E
+	sd	t0, OCTEON_CP2_HSH_DATW+88(a0)
+	dmfc2	t0, 0x0250
+	sd	t1, OCTEON_CP2_HSH_DATW+96(a0)
+	dmfc2	t1, 0x0251
+	sd	t2, OCTEON_CP2_HSH_DATW+104(a0)
+	dmfc2	t2, 0x0252
+	sd	t3, OCTEON_CP2_HSH_DATW+112(a0)
+	dmfc2	t3, 0x0253
+	sd	t0, OCTEON_CP2_HSH_IVW(a0)
+	dmfc2	t0, 0x0254
+	sd	t1, OCTEON_CP2_HSH_IVW+8(a0)
+	dmfc2	t1, 0x0255
+	sd	t2, OCTEON_CP2_HSH_IVW+16(a0)
+	dmfc2	t2, 0x0256
+	sd	t3, OCTEON_CP2_HSH_IVW+24(a0)
+	dmfc2	t3, 0x0257
+	sd	t0, OCTEON_CP2_HSH_IVW+32(a0)
+	dmfc2 	t0, 0x0258
+	sd	t1, OCTEON_CP2_HSH_IVW+40(a0)
+	dmfc2 	t1, 0x0259
+	sd	t2, OCTEON_CP2_HSH_IVW+48(a0)
+	dmfc2	t2, 0x025E
+	sd	t3, OCTEON_CP2_HSH_IVW+56(a0)
+	dmfc2	t3, 0x025A
+	sd	t0, OCTEON_CP2_GFM_MULT(a0)
+	dmfc2	t0, 0x025B
+	sd	t1, OCTEON_CP2_GFM_MULT+8(a0)
+	sd	t2, OCTEON_CP2_GFM_POLY(a0)
+	sd	t3, OCTEON_CP2_GFM_RESULT(a0)
+	sd	t0, OCTEON_CP2_GFM_RESULT+8(a0)
+	jr	ra
+
+2:      /* pass 1 special stuff when !CvmCtl[NOCRYPTO] */
+	dmfc2	t3, 0x0040
+	dmfc2	t0, 0x0041
+	dmfc2	t1, 0x0042
+	dmfc2	t2, 0x0043
+	sd	t3, OCTEON_CP2_HSH_DATW(a0)
+	dmfc2	t3, 0x0044
+	sd	t0, OCTEON_CP2_HSH_DATW+8(a0)
+	dmfc2	t0, 0x0045
+	sd	t1, OCTEON_CP2_HSH_DATW+16(a0)
+	dmfc2	t1, 0x0046
+	sd	t2, OCTEON_CP2_HSH_DATW+24(a0)
+	dmfc2	t2, 0x0048
+	sd	t3, OCTEON_CP2_HSH_DATW+32(a0)
+	dmfc2	t3, 0x0049
+	sd	t0, OCTEON_CP2_HSH_DATW+40(a0)
+	dmfc2	t0, 0x004A
+	sd	t1, OCTEON_CP2_HSH_DATW+48(a0)
+	sd	t2, OCTEON_CP2_HSH_IVW(a0)
+	sd	t3, OCTEON_CP2_HSH_IVW+8(a0)
+	sd	t0, OCTEON_CP2_HSH_IVW+16(a0)
+
+3:      /* pass 1 or CvmCtl[NOCRYPTO] set */
+	jr	ra
+	END(octeon_cop2_save)
+
+/*
+ * void octeon_cop2_restore(struct octeon_cop2_state *a0)
+ */
+	.align	7
+	.set push
+	.set noreorder
+	LEAF(octeon_cop2_restore)
+        /* First cache line was prefetched before the call */
+        pref    4,  128(a0)
+	dmfc0	t9, $9,7	/* CvmCtl register. */
+
+        pref    4,  256(a0)
+	ld	t0, OCTEON_CP2_CRC_IV(a0)
+        pref    4,  384(a0)
+	ld	t1, OCTEON_CP2_CRC_LENGTH(a0)
+	ld	t2, OCTEON_CP2_CRC_POLY(a0)
+
+	/* Restore the COP2 CRC state */
+	dmtc2	t0, 0x0201
+	dmtc2 	t1, 0x1202
+	bbit1	t9, 28, 2f	/* Skip LLM if CvmCtl[NODFA_CP2] is set */
+	 dmtc2	t2, 0x4200
+
+	/* Restore the LLM state */
+	ld	t0, OCTEON_CP2_LLM_DAT(a0)
+	ld	t1, OCTEON_CP2_LLM_DAT+8(a0)
+	dmtc2	t0, 0x0402
+	dmtc2	t1, 0x040A
+
+2:
+	bbit1	t9, 26, done_restore	/* done if CvmCtl[NOCRYPTO] set */
+	 nop
+
+	/* Restore the COP2 crypto state common to pass 1 and pass 2 */
+	ld	t0, OCTEON_CP2_3DES_IV(a0)
+	ld	t1, OCTEON_CP2_3DES_KEY(a0)
+	ld	t2, OCTEON_CP2_3DES_KEY+8(a0)
+	dmtc2 	t0, 0x0084
+	ld	t0, OCTEON_CP2_3DES_KEY+16(a0)
+	dmtc2 	t1, 0x0080
+	ld	t1, OCTEON_CP2_3DES_RESULT(a0)
+	dmtc2 	t2, 0x0081
+	ld	t2, OCTEON_CP2_AES_INP0(a0)       /* only really needed for pass 1 */
+	dmtc2	t0, 0x0082
+	ld	t0, OCTEON_CP2_AES_IV(a0)
+	dmtc2 	t1, 0x0098
+	ld	t1, OCTEON_CP2_AES_IV+8(a0)
+	dmtc2 	t2, 0x010A                        /* only really needed for pass 1 */
+	ld	t2, OCTEON_CP2_AES_KEY(a0)
+	dmtc2 	t0, 0x0102
+	ld	t0, OCTEON_CP2_AES_KEY+8(a0)
+	dmtc2	t1, 0x0103
+	ld	t1, OCTEON_CP2_AES_KEY+16(a0)
+	dmtc2	t2, 0x0104
+	ld	t2, OCTEON_CP2_AES_KEY+24(a0)
+	dmtc2	t0, 0x0105
+	ld	t0, OCTEON_CP2_AES_KEYLEN(a0)
+	dmtc2	t1, 0x0106
+	ld	t1, OCTEON_CP2_AES_RESULT(a0)
+	dmtc2	t2, 0x0107
+	ld	t2, OCTEON_CP2_AES_RESULT+8(a0)
+	mfc0	t3, $15,0 	/* Get the processor ID register */
+	dmtc2	t0, 0x0110
+	li	t0, 0x000d0000	/* This is the processor ID of Octeon Pass1 */
+	dmtc2	t1, 0x0100
+	bne	t0, t3, 3f	/* Skip the next stuff for non-pass1 */
+	 dmtc2	t2, 0x0101
+
+        /* this code is specific for pass 1 */
+	ld	t0, OCTEON_CP2_HSH_DATW(a0)
+	ld	t1, OCTEON_CP2_HSH_DATW+8(a0)
+	ld	t2, OCTEON_CP2_HSH_DATW+16(a0)
+	dmtc2	t0, 0x0040
+	ld	t0, OCTEON_CP2_HSH_DATW+24(a0)
+	dmtc2	t1, 0x0041
+	ld	t1, OCTEON_CP2_HSH_DATW+32(a0)
+	dmtc2	t2, 0x0042
+	ld	t2, OCTEON_CP2_HSH_DATW+40(a0)
+	dmtc2	t0, 0x0043
+	ld	t0, OCTEON_CP2_HSH_DATW+48(a0)
+	dmtc2	t1, 0x0044
+	ld	t1, OCTEON_CP2_HSH_IVW(a0)
+	dmtc2	t2, 0x0045
+	ld	t2, OCTEON_CP2_HSH_IVW+8(a0)
+	dmtc2	t0, 0x0046
+	ld	t0, OCTEON_CP2_HSH_IVW+16(a0)
+	dmtc2	t1, 0x0048
+	dmtc2	t2, 0x0049
+        b done_restore   /* unconditional branch */
+	 dmtc2	t0, 0x004A
+
+3:      /* this is post-pass1 code */
+	ld	t2, OCTEON_CP2_HSH_DATW(a0)
+	ld	t0, OCTEON_CP2_HSH_DATW+8(a0)
+	ld	t1, OCTEON_CP2_HSH_DATW+16(a0)
+	dmtc2	t2, 0x0240
+	ld	t2, OCTEON_CP2_HSH_DATW+24(a0)
+	dmtc2	t0, 0x0241
+	ld	t0, OCTEON_CP2_HSH_DATW+32(a0)
+	dmtc2	t1, 0x0242
+	ld	t1, OCTEON_CP2_HSH_DATW+40(a0)
+	dmtc2	t2, 0x0243
+	ld	t2, OCTEON_CP2_HSH_DATW+48(a0)
+	dmtc2	t0, 0x0244
+	ld	t0, OCTEON_CP2_HSH_DATW+56(a0)
+	dmtc2	t1, 0x0245
+	ld	t1, OCTEON_CP2_HSH_DATW+64(a0)
+	dmtc2	t2, 0x0246
+	ld	t2, OCTEON_CP2_HSH_DATW+72(a0)
+	dmtc2	t0, 0x0247
+	ld	t0, OCTEON_CP2_HSH_DATW+80(a0)
+	dmtc2	t1, 0x0248
+	ld	t1, OCTEON_CP2_HSH_DATW+88(a0)
+	dmtc2	t2, 0x0249
+	ld	t2, OCTEON_CP2_HSH_DATW+96(a0)
+	dmtc2	t0, 0x024A
+	ld	t0, OCTEON_CP2_HSH_DATW+104(a0)
+	dmtc2	t1, 0x024B
+	ld	t1, OCTEON_CP2_HSH_DATW+112(a0)
+	dmtc2	t2, 0x024C
+	ld	t2, OCTEON_CP2_HSH_IVW(a0)
+	dmtc2	t0, 0x024D
+	ld	t0, OCTEON_CP2_HSH_IVW+8(a0)
+	dmtc2	t1, 0x024E
+	ld	t1, OCTEON_CP2_HSH_IVW+16(a0)
+	dmtc2	t2, 0x0250
+	ld	t2, OCTEON_CP2_HSH_IVW+24(a0)
+	dmtc2	t0, 0x0251
+	ld	t0, OCTEON_CP2_HSH_IVW+32(a0)
+	dmtc2	t1, 0x0252
+	ld	t1, OCTEON_CP2_HSH_IVW+40(a0)
+	dmtc2	t2, 0x0253
+	ld	t2, OCTEON_CP2_HSH_IVW+48(a0)
+	dmtc2	t0, 0x0254
+	ld	t0, OCTEON_CP2_HSH_IVW+56(a0)
+	dmtc2	t1, 0x0255
+	ld	t1, OCTEON_CP2_GFM_MULT(a0)
+	dmtc2	t2, 0x0256
+	ld	t2, OCTEON_CP2_GFM_MULT+8(a0)
+	dmtc2	t0, 0x0257
+	ld	t0, OCTEON_CP2_GFM_POLY(a0)
+	dmtc2	t1, 0x0258
+	ld	t1, OCTEON_CP2_GFM_RESULT(a0)
+	dmtc2	t2, 0x0259
+	ld	t2, OCTEON_CP2_GFM_RESULT+8(a0)
+	dmtc2	t0, 0x025E
+	dmtc2	t1, 0x025A
+	dmtc2	t2, 0x025B
+
+done_restore:
+	jr	ra
+	 nop
+	END(octeon_cop2_restore)
+	.set pop
+
+/*
+ * void octeon_mult_save()
+ * sp is assumed to point to a struct pt_regs
+ *
+ * NOTE: This is called in SAVE_SOME in stackframe.h. It can only
+ *       safely modify k0 and k1.
+ */
+	.align	7
+	.set push
+	.set noreorder
+	LEAF(octeon_mult_save)
+	dmfc0	k0, $9,7	/* CvmCtl register. */
+	bbit1	k0, 27, 1f	/* Skip CvmCtl[NOMUL] */
+	 nop
+
+	/* Save the multiplier state */
+	v3mulu	k0, $0, $0
+	v3mulu	k1, $0, $0
+	sd	k0, PT_MTP(sp)        /* PT_MTP    has P0 */
+	v3mulu	k0, $0, $0
+	sd	k1, PT_MTP+8(sp)      /* PT_MTP+8  has P1 */
+	ori	k1, $0, 1
+	v3mulu	k1, k1, $0
+	sd	k0, PT_MTP+16(sp)     /* PT_MTP+16 has P2 */
+	v3mulu	k0, $0, $0
+	sd	k1, PT_MPL(sp)        /* PT_MPL    has MPL0 */
+	v3mulu	k1, $0, $0
+	sd	k0, PT_MPL+8(sp)      /* PT_MPL+8  has MPL1 */
+	jr	ra
+	 sd	k1, PT_MPL+16(sp)     /* PT_MPL+16 has MPL2 */
+
+1:	/* Resume here if CvmCtl[NOMUL] */
+	jr	ra
+	END(octeon_mult_save)
+	.set pop
+
+/*
+ * void octeon_mult_restore()
+ * sp is assumed to point to a struct pt_regs
+ *
+ * NOTE: This is called in RESTORE_SOME in stackframe.h.
+ */
+	.align	7
+	.set push
+	.set noreorder
+	LEAF(octeon_mult_restore)
+	dmfc0	k1, $9,7		/* CvmCtl register. */
+	ld	v0, PT_MPL(sp)        	/* MPL0 */
+	ld	v1, PT_MPL+8(sp)      	/* MPL1 */
+	ld	k0, PT_MPL+16(sp)     	/* MPL2 */
+	bbit1	k1, 27, 1f		/* Skip CvmCtl[NOMUL] */
+	 nop				/* Normally falls through, so no time wasted here */
+
+	/* Restore the multiplier state */
+	ld	k1, PT_MTP+16(sp)     	/* P2 */
+	MTM0	v0			/* MPL0 */
+	ld	v0, PT_MTP+8(sp)	/* P1 */
+	MTM1	v1			/* MPL1 */
+	ld	v1, PT_MTP(sp)   	/* P0 */
+	MTM2	k0			/* MPL2 */
+	MTP2	k1			/* P2 */
+	MTP1	v0			/* P1 */
+	jr	ra
+	 MTP0	v1			/* P0 */
+
+1:	/* Resume here if CvmCtl[NOMUL] */
+	jr	ra
+	 nop
+	END(octeon_mult_restore)
+	.set pop
+
diff --git a/arch/mips/kernel/watch.c b/arch/mips/kernel/watch.c
new file mode 100644
index 0000000..c154069
--- /dev/null
+++ b/arch/mips/kernel/watch.c
@@ -0,0 +1,188 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2008 David Daney
+ */
+
+#include <linux/sched.h>
+
+#include <asm/processor.h>
+#include <asm/watch.h>
+
+/*
+ * Install the watch registers for the current thread.  A maximum of
+ * four registers are installed although the machine may have more.
+ */
+void mips_install_watch_registers(void)
+{
+	struct mips3264_watch_reg_state *watches =
+		&current->thread.watch.mips3264;
+	switch (current_cpu_data.watch_reg_use_cnt) {
+	default:
+		BUG();
+	case 4:
+		write_c0_watchlo3(watches->watchlo[3]);
+		/* Write 1 to the I, R, and W bits to clear them, and
+		   1 to G so all ASIDs are trapped. */
+		write_c0_watchhi3(0x40000007 | watches->watchhi[3]);
+	case 3:
+		write_c0_watchlo2(watches->watchlo[2]);
+		write_c0_watchhi2(0x40000007 | watches->watchhi[2]);
+	case 2:
+		write_c0_watchlo1(watches->watchlo[1]);
+		write_c0_watchhi1(0x40000007 | watches->watchhi[1]);
+	case 1:
+		write_c0_watchlo0(watches->watchlo[0]);
+		write_c0_watchhi0(0x40000007 | watches->watchhi[0]);
+	}
+}
+
+/*
+ * Read back the watchhi registers so the user space debugger has
+ * access to the I, R, and W bits.  A maximum of four registers are
+ * read although the machine may have more.
+ */
+void mips_read_watch_registers(void)
+{
+	struct mips3264_watch_reg_state *watches =
+		&current->thread.watch.mips3264;
+	switch (current_cpu_data.watch_reg_use_cnt) {
+	default:
+		BUG();
+	case 4:
+		watches->watchhi[3] = (read_c0_watchhi3() & 0x0fff);
+	case 3:
+		watches->watchhi[2] = (read_c0_watchhi2() & 0x0fff);
+	case 2:
+		watches->watchhi[1] = (read_c0_watchhi1() & 0x0fff);
+	case 1:
+		watches->watchhi[0] = (read_c0_watchhi0() & 0x0fff);
+	}
+	if (current_cpu_data.watch_reg_use_cnt == 1 &&
+	    (watches->watchhi[0] & 7) == 0) {
+		/* Pathological case of release 1 architecture that
+		 * doesn't set the condition bits.  We assume that
+		 * since we got here, the watch condition was met and
+		 * signal that the conditions requested in watchlo
+		 * were met.  */
+		watches->watchhi[0] |= (watches->watchlo[0] & 7);
+	}
+ }
+
+/*
+ * Disable all watch registers.  Although only four registers are
+ * installed, all are cleared to eliminate the possibility of endless
+ * looping in the watch handler.
+ */
+void mips_clear_watch_registers(void)
+{
+	switch (current_cpu_data.watch_reg_count) {
+	default:
+		BUG();
+	case 8:
+		write_c0_watchlo7(0);
+	case 7:
+		write_c0_watchlo6(0);
+	case 6:
+		write_c0_watchlo5(0);
+	case 5:
+		write_c0_watchlo4(0);
+	case 4:
+		write_c0_watchlo3(0);
+	case 3:
+		write_c0_watchlo2(0);
+	case 2:
+		write_c0_watchlo1(0);
+	case 1:
+		write_c0_watchlo0(0);
+	}
+}
+
+__cpuinit void mips_probe_watch_registers(struct cpuinfo_mips *c)
+{
+	unsigned int t;
+
+	if ((c->options & MIPS_CPU_WATCH) == 0)
+		return;
+	/*
+	 * Check which of the I,R and W bits are supported, then
+	 * disable the register.
+	 */
+	write_c0_watchlo0(7);
+	t = read_c0_watchlo0();
+	write_c0_watchlo0(0);
+	c->watch_reg_masks[0] = t & 7;
+
+	/* Write the mask bits and read them back to determine which
+	 * can be used. */
+	c->watch_reg_count = 1;
+	c->watch_reg_use_cnt = 1;
+	t = read_c0_watchhi0();
+	write_c0_watchhi0(t | 0xff8);
+	t = read_c0_watchhi0();
+	c->watch_reg_masks[0] |= (t & 0xff8);
+	if ((t & 0x80000000) == 0)
+		return;
+
+	write_c0_watchlo1(7);
+	t = read_c0_watchlo1();
+	write_c0_watchlo1(0);
+	c->watch_reg_masks[1] = t & 7;
+
+	c->watch_reg_count = 2;
+	c->watch_reg_use_cnt = 2;
+	t = read_c0_watchhi1();
+	write_c0_watchhi1(t | 0xff8);
+	t = read_c0_watchhi1();
+	c->watch_reg_masks[1] |= (t & 0xff8);
+	if ((t & 0x80000000) == 0)
+		return;
+
+	write_c0_watchlo2(7);
+	t = read_c0_watchlo2();
+	write_c0_watchlo2(0);
+	c->watch_reg_masks[2] = t & 7;
+
+	c->watch_reg_count = 3;
+	c->watch_reg_use_cnt = 3;
+	t = read_c0_watchhi2();
+	write_c0_watchhi2(t | 0xff8);
+	t = read_c0_watchhi2();
+	c->watch_reg_masks[2] |= (t & 0xff8);
+	if ((t & 0x80000000) == 0)
+		return;
+
+	write_c0_watchlo3(7);
+	t = read_c0_watchlo3();
+	write_c0_watchlo3(0);
+	c->watch_reg_masks[3] = t & 7;
+
+	c->watch_reg_count = 4;
+	c->watch_reg_use_cnt = 4;
+	t = read_c0_watchhi3();
+	write_c0_watchhi3(t | 0xff8);
+	t = read_c0_watchhi3();
+	c->watch_reg_masks[3] |= (t & 0xff8);
+	if ((t & 0x80000000) == 0)
+		return;
+
+	/* We use at most 4, but probe and report up to 8. */
+	c->watch_reg_count = 5;
+	t = read_c0_watchhi4();
+	if ((t & 0x80000000) == 0)
+		return;
+
+	c->watch_reg_count = 6;
+	t = read_c0_watchhi5();
+	if ((t & 0x80000000) == 0)
+		return;
+
+	c->watch_reg_count = 7;
+	t = read_c0_watchhi6();
+	if ((t & 0x80000000) == 0)
+		return;
+
+	c->watch_reg_count = 8;
+}
diff --git a/arch/mips/mm/c-octeon.c b/arch/mips/mm/c-octeon.c
new file mode 100644
index 0000000..ba18003
--- /dev/null
+++ b/arch/mips/mm/c-octeon.c
@@ -0,0 +1,303 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2005-2007 Cavium Networks
+ */
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/mm.h>
+#include <linux/bitops.h>
+#include <linux/cpu.h>
+#include <linux/io.h>
+
+#include <asm/bcache.h>
+#include <asm/bootinfo.h>
+#include <asm/cacheops.h>
+#include <asm/cpu-features.h>
+#include <asm/page.h>
+#include <asm/pgtable.h>
+#include <asm/r4kcache.h>
+#include <asm/system.h>
+#include <asm/mmu_context.h>
+#include <asm/war.h>
+#include "../cavium-octeon/hal.h"
+
+unsigned long long cache_err_dcache[NR_CPUS];
+EXPORT_SYMBOL_GPL(cache_err_dcache);
+
+extern struct plat_smp_ops *mp_ops;	/* private */
+
+/**
+ * Octeon automatically flushes the dcache on tlb changes, so
+ * from Linux's viewpoint it acts much like a physically
+ * tagged cache. No flushing is needed
+ *
+ * @param addr
+ */
+static void octeon_flush_data_cache_page(unsigned long addr)
+{
+    /* Nothing to do */
+}
+
+/* Flush local I-cache for the specified range.
+ */
+static inline void local_octeon_flush_icache_range(unsigned long start,
+						   unsigned long end)
+{
+	asm volatile ("synci 0($0)\n");
+}
+
+/**
+ * Flush caches as necessary for all cores affected by a
+ * vma. If no vma is supplied, all cores are flushed.
+ *
+ * @param vma    VMA to flush or NULL to flush all icaches.
+ */
+static void octeon_flush_icache_all_cores(struct vm_area_struct *vma)
+{
+#ifdef CONFIG_SMP
+	int i;
+	int cpu;
+#endif
+	
+	preempt_disable();
+#ifdef CONFIG_SMP
+	cpu = smp_processor_id();
+#endif
+	mb();
+
+	/* If we have a vma structure, we only need to worry about cores it
+	   has been used on */
+	if (vma) {
+#ifdef CONFIG_SMP
+		for (i = 0; i < NR_CPUS; i++)
+			if (cpu_isset(i, vma->vm_mm->cpu_vm_mask) && i != cpu)
+				mp_ops->send_ipi_single(i, SMP_ICACHE_FLUSH);
+#endif
+		asm volatile ("synci 0($0)\n");
+	} else {
+		/* No extra info available. Flush the icache on all cores that
+		   are online */
+#ifdef CONFIG_SMP
+		for (i = 0; i < NR_CPUS; i++)
+			if (cpu_online(i) && i != cpu)
+				mp_ops->send_ipi_single(i, SMP_ICACHE_FLUSH);
+#endif
+		asm volatile ("synci 0($0)\n");
+	}
+	preempt_enable();
+}
+
+
+/**
+ * Called to flush the icache on all cores
+ */
+static void octeon_flush_icache_all(void)
+{
+	octeon_flush_icache_all_cores(NULL);
+}
+
+
+/**
+ * Called to flush all memory associated with a memory
+ * context.
+ *
+ * @param mm     Memory context to flush
+ */
+static void octeon_flush_cache_mm(struct mm_struct *mm)
+{
+	/* According to the R4K version of this file, CPUs without
+	   dcache aliases don't need to do anything here */
+}
+
+
+/**
+ * Flush a range of kernel addresses out of the icache
+ *
+ * @param start
+ * @param end
+ */
+static void octeon_flush_icache_range(unsigned long start, unsigned long end)
+{
+	octeon_flush_icache_all_cores(NULL);
+}
+
+
+/**
+ * Flush the icache for a trampoline. These are used for interrupt
+ * and exception hooking.
+ *
+ * @param addr   Address to flush
+ */
+static void octeon_flush_cache_sigtramp(unsigned long addr)
+{
+	struct vm_area_struct *vma;
+
+	vma = find_vma(current->mm, addr);
+	octeon_flush_icache_all_cores(vma);
+}
+
+
+/**
+ * Flush a range out of a vma
+ *
+ * @param vma    VMA to flush
+ * @param start
+ * @param end
+ */
+static void octeon_flush_cache_range(struct vm_area_struct *vma, unsigned long start, unsigned long end)
+{
+	if (vma->vm_flags & (VM_EXEC|VM_EXECUTABLE))
+		octeon_flush_icache_all_cores(vma);
+}
+
+
+/**
+ * Flush a specific page of a vma
+ *
+ * @param vma    VMA to flush page for
+ * @param page   Page to flush
+ * @param pfn
+ */
+static void octeon_flush_cache_page(struct vm_area_struct *vma, unsigned long page, unsigned long pfn)
+{
+	if (vma->vm_flags & (VM_EXEC|VM_EXECUTABLE))
+		octeon_flush_icache_all_cores(vma);
+}
+
+
+/**
+ * Probe Octeon's caches
+ *
+ * @return
+ */
+static void __devinit probe_octeon(void)
+{
+	unsigned long icache_size;
+	unsigned long dcache_size;
+	unsigned int config1;
+	struct cpuinfo_mips *c = &current_cpu_data;
+
+	switch (c->cputype) {
+	case CPU_CAVIUM_OCTEON:
+		config1 = read_c0_config1();
+		c->icache.linesz = 2 << ((config1 >> 19) & 7);
+		c->icache.sets = 64 << ((config1 >> 22) & 7);
+		c->icache.ways = 1 + ((config1 >> 16) & 7);
+		c->icache.flags |= MIPS_CACHE_VTAG;
+		icache_size = c->icache.sets * c->icache.ways * c->icache.linesz;
+		c->icache.waybit = ffs(icache_size / c->icache.ways) - 1;
+		c->dcache.linesz = 128;
+		if (OCTEON_IS_MODEL(OCTEON_CN3XXX))
+			c->dcache.sets = 1; /* CN3XXX has one Dcache set */
+		else
+			c->dcache.sets = 2; /* CN5XXX has two Dcache sets */
+		c->dcache.ways = 64;
+		dcache_size = c->dcache.sets * c->dcache.ways * c->dcache.linesz;
+		c->dcache.waybit = ffs(dcache_size / c->dcache.ways) - 1;
+		c->options |= MIPS_CPU_PREFETCH;
+		break;
+
+	default:
+		panic("Unsupported Cavium Networks CPU type\n");
+		break;
+	}
+
+	/* compute a couple of other cache variables */
+	c->icache.waysize = icache_size / c->icache.ways;
+	c->dcache.waysize = dcache_size / c->dcache.ways;
+
+	c->icache.sets = icache_size / (c->icache.linesz * c->icache.ways);
+	c->dcache.sets = dcache_size / (c->dcache.linesz * c->dcache.ways);
+
+	if (smp_processor_id() == 0) {
+		pr_notice("Primary instruction cache %ldkB, %s, %d way, "
+			  "%d sets, linesize %d bytes.\n",
+			  icache_size >> 10,
+			  cpu_has_vtag_icache ?
+			  	"virtually tagged" : "physically tagged",
+			  c->icache.ways, c->icache.sets, c->icache.linesz);
+
+		pr_notice("Primary data cache %ldkB, %d-way, %d sets, "
+			  "linesize %d bytes.\n",
+			  dcache_size >> 10, c->dcache.ways,
+			  c->dcache.sets, c->dcache.linesz);
+	}
+}
+
+
+/**
+ * Setup the Octeon cache flush routines
+ *
+ * @return
+ */
+void __devinit octeon_cache_init(void)
+{
+	extern unsigned long ebase;
+	extern char except_vec2_octeon;
+
+	memcpy((void *)(ebase + 0x100), &except_vec2_octeon, 0x80);
+	octeon_flush_cache_sigtramp(ebase + 0x100);
+
+	probe_octeon();
+
+	shm_align_mask = PAGE_SIZE - 1;
+
+	flush_cache_all         = octeon_flush_icache_all;
+	__flush_cache_all       = octeon_flush_icache_all;
+	flush_cache_mm          = octeon_flush_cache_mm;
+	flush_cache_page        = octeon_flush_cache_page;
+	flush_cache_range       = octeon_flush_cache_range;
+	flush_cache_sigtramp    = octeon_flush_cache_sigtramp;
+	flush_icache_all        = octeon_flush_icache_all;
+	flush_data_cache_page   = octeon_flush_data_cache_page;
+	flush_icache_range      = octeon_flush_icache_range;
+	local_flush_icache_range= local_octeon_flush_icache_range;
+}
+
+/**
+ * Handle a cache error exception
+ */
+
+static RAW_NOTIFIER_HEAD(co_cache_error_chain);
+
+int register_co_cache_error_notifier(struct notifier_block *nb)
+{
+	return raw_notifier_chain_register(&co_cache_error_chain, nb);
+}
+EXPORT_SYMBOL_GPL(register_co_cache_error_notifier);
+
+int unregister_co_cache_error_notifier(struct notifier_block *nb)
+{
+	return raw_notifier_chain_unregister(&co_cache_error_chain, nb);
+}
+EXPORT_SYMBOL_GPL(unregister_co_cache_error_notifier);
+
+static inline int co_cache_error_call_notifiers(unsigned long val)
+{
+	return raw_notifier_call_chain(&co_cache_error_chain, val, NULL);
+}
+
+/**
+ * Called when the the exception is not recoverable
+ *
+ * The issue not that the cache error exception itself was non-recoverable
+ * but that due to nesting of exception may have lost some state so can't
+ * continue.
+ */
+asmlinkage void cache_parity_error_octeon_recoverable(void)
+{
+	co_cache_error_call_notifiers(0);
+}
+
+/**
+ * Called when the the exception is recoverable
+ */
+asmlinkage void cache_parity_error_octeon_non_recoverable(void)
+{
+	co_cache_error_call_notifiers(1);
+	panic("Can't handle cache error: nested exception");
+}
diff --git a/arch/mips/mm/cex-oct.S b/arch/mips/mm/cex-oct.S
new file mode 100644
index 0000000..6546f26
--- /dev/null
+++ b/arch/mips/mm/cex-oct.S
@@ -0,0 +1,73 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2006 Cavium Networks
+ * Cache error handler
+ */
+
+#include <asm/asm.h>
+#include <asm/regdef.h>
+#include <asm/mipsregs.h>
+#include <asm/stackframe.h>
+
+/*
+ * Handle cache error. Indicate to the second level handler whether
+ * the exception is recoverable.
+ */
+	LEAF(except_vec2_octeon)
+
+	.set    push
+	.set	mips64r2
+	.set	noreorder
+	.set	noat
+
+
+	/* due to an errata we need to read the COP0 CacheErr (Dcache) before any
+	 * cache/DRAM access
+	 */
+
+	rdhwr   k0, $0        /* get core_id */
+	PTR_LA  k1, cache_err_dcache
+	sll     k0, k0, 3
+	PTR_ADDU k1, k0, k1    /* k1 = &cache_err_dcache[core_id] */
+
+	dmfc0   k0, CP0_CACHEERR, 1
+	sd      k0, (k1)
+	dmtc0   $0, CP0_CACHEERR, 1
+
+        /* check whether this is a nested exception */
+	mfc0    k1, CP0_STATUS
+	andi    k1, k1, ST0_EXL
+	beqz    k1, 1f
+	 nop
+	j	cache_parity_error_octeon_non_recoverable
+	 nop
+
+	/* exception is recoverable */
+1:	j	handle_cache_err
+	 nop
+
+	.set    pop
+	END(except_vec2_octeon)
+
+/*
+ * We need to jump to handle_cache_err so that the previous handler can fit
+ * within 0x80 bytes. We also move from 0xFFFFFFFFAXXXXXXX space (uncached) to the
+ * 0xFFFFFFFF8XXXXXXX space (cached).
+ */
+	LEAF(handle_cache_err)
+	.set    push
+        .set    noreorder
+        .set    noat
+
+	SAVE_ALL
+	KMODE
+	jal     cache_parity_error_octeon_recoverable
+	nop
+	j       ret_from_exception
+	nop
+
+	.set pop
+	END(handle_cache_err)
diff --git a/arch/mips/mm/pg-octeon.c b/arch/mips/mm/pg-octeon.c
new file mode 100644
index 0000000..b457955
--- /dev/null
+++ b/arch/mips/mm/pg-octeon.c
@@ -0,0 +1,120 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2005-2007 Cavium Networks
+ */
+#include <linux/module.h>
+
+
+void clear_page(void *page)
+{
+	void *end = page + PAGE_SIZE;
+
+	asm volatile (
+		"   .set	push		\n"
+		"   .set	mips64		\n"
+		"   .set	noreorder	\n"
+		"1: sd      $0, 0(%0)   \n" /* Write zeros to the cache line */
+		"   sd      $0, 8(%0)   \n"
+		"   sd      $0, 16(%0)  \n"
+		"   sd      $0, 24(%0)  \n"
+		"   sd      $0, 32(%0)  \n"
+		"   sd      $0, 40(%0)  \n"
+		"   sd      $0, 48(%0)  \n"
+		"   sd      $0, 56(%0)  \n"
+		"   sd      $0, 64(%0)  \n"
+		"   sd      $0, 72(%0)  \n"
+		"   sd      $0, 80(%0)  \n"
+		"   sd      $0, 88(%0)  \n"
+		"   sd      $0, 96(%0)  \n"
+		"   sd      $0, 104(%0) \n"
+#ifdef CONFIG_64BIT
+		"   daddu   %0, 128     \n" /* Increment to the next address. Will be dual issued */
+#else
+		"   addu    %0, 128     \n"
+#endif
+		"   sd      $0, -16(%0) \n"
+		"   blt     %0, %1, 1b  \n" /* Loop until we've completed the page */
+		"    sd     $0, -8(%0)  \n"
+		"   .set	pop		\n"
+		: "+r" (page)
+		: "r" (end)
+		: "memory"
+	);
+}
+
+
+void copy_page(void *to, void *from)
+{
+#ifdef _ABIO32
+    memcpy(to, from, PAGE_SIZE);
+#else
+	void *end = to + PAGE_SIZE;
+
+	/* Warning: Bad thing can happen if you prefetch an address that doesn't
+	   exist in memory. With Octeon, this can happen at 256MB, 0x420000000,
+	   and the top of memory. To avoid this, we stop prefetching during the
+	   last two iterations of this loop */
+	asm volatile (
+		"   .set	push		\n"
+		"   .set	mips64		\n"
+		"   .set	noreorder	\n"
+		"   pref    0,  0(%1)   \n" /* Prefetch the first cache line of "from" */
+		"   pref    0,  128(%1) \n" /* Prefetch the next "from" cache line for the next iteration */
+		"1: pref    0,  256(%1) \n" /* Prefetch for two loops ahead */
+		"2:                     \n" /* This is the entry point for the last two loops to skip the prefetch */
+		"   ld      $12, 0(%1)  \n" /* Copy 32 bytes at a time */
+		"   ld      $13, 8(%1)  \n"
+		"   ld      $14, 16(%1) \n"
+		"   ld      $15, 24(%1) \n"
+		"   daddu   %1, 32      \n" /* Dual issued */
+		"   sd      $12, 0(%0)  \n"
+		"   sd      $13, 8(%0)  \n"
+		"   sd      $14, 16(%0) \n"
+		"   sd      $15, 24(%0) \n"
+		"   daddu   %0, 32      \n" /* Dual issued */
+		"   ld      $12, 0(%1)  \n" /* Copy 32 bytes at a time */
+		"   ld      $13, 8(%1)  \n"
+		"   ld      $14, 16(%1) \n"
+		"   ld      $15, 24(%1) \n"
+		"   daddu   %1, 32      \n" /* Dual issued */
+		"   sd      $12, 0(%0)  \n"
+		"   sd      $13, 8(%0)  \n"
+		"   sd      $14, 16(%0) \n"
+		"   sd      $15, 24(%0) \n"
+		"   daddu   %0, 32      \n" /* Dual issued */
+		"   ld      $12, 0(%1)  \n" /* Copy 32 bytes at a time */
+		"   ld      $13, 8(%1)  \n"
+		"   ld      $14, 16(%1) \n"
+		"   ld      $15, 24(%1) \n"
+		"   daddu   %1, 32      \n" /* Dual issued */
+		"   sd      $12, 0(%0)  \n"
+		"   sd      $13, 8(%0)  \n"
+		"   sd      $14, 16(%0) \n"
+		"   sd      $15, 24(%0) \n"
+		"   daddu   %0, 32      \n" /* Dual issued */
+		"   ld      $12, 0(%1)  \n" /* Copy 32 bytes at a time */
+		"   ld      $13, 8(%1)  \n"
+		"   ld      $14, 16(%1) \n"
+		"   ld      $15, 24(%1) \n"
+		"   daddu   %1, 32      \n" /* Dual issued */
+		"   sd      $12, 0(%0)  \n"
+		"   sd      $13, 8(%0)  \n"
+		"   daddu   %0, 32      \n" /* Dual issued */
+		"   sd      $14, -16(%0)\n"
+		"   blt     %0, %3, 1b  \n" /* Loop until we've gotten to the last 256 bytes */
+		"    sd     $15, -8(%0) \n"
+		"   blt     %0, %2, 2b  \n" /* Loop until we've completed the last 256 bytes, skip the prefetch */
+		"    nop                \n"
+		"   .set	pop		\n"
+		: "+r" (to), "+r" (from)
+		: "r" (end), "r" (end-256)
+		: "$12", "$13", "$14", "$15", "memory"
+	);
+#endif
+}
+
+EXPORT_SYMBOL(clear_page);
+EXPORT_SYMBOL(copy_page);
diff --git a/arch/mips/oprofile/op_model_cavium_octeon.c b/arch/mips/oprofile/op_model_cavium_octeon.c
new file mode 100644
index 0000000..b4ff92e
--- /dev/null
+++ b/arch/mips/oprofile/op_model_cavium_octeon.c
@@ -0,0 +1,143 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004 by Ralf Baechle
+ */
+#include <linux/oprofile.h>
+#include <linux/interrupt.h>
+#include <linux/smp.h>
+
+#include "op_impl.h"
+
+/**
+ * Bit description of the core counters control register
+ */
+typedef union {
+	uint32_t u32;
+	struct {
+		uint32_t M:1;
+		uint32_t W:1;
+		uint32_t reserved:19;
+		uint32_t event:6;
+		uint32_t IE:1;
+		uint32_t U:1;
+		uint32_t S:1;
+		uint32_t K:1;
+		uint32_t EX:1;
+	} s;
+} core_control_t;
+
+static struct {
+	core_control_t control[2];
+	uint64_t reset_value[2];
+} octeon_config;
+
+/* Compute all of the registers in preparation for enabling profiling.  */
+
+static void octeon_reg_setup(struct op_counter_config *ctr)
+{
+	int i;
+	for (i = 0; i < 2; i++) {
+		octeon_config.control[i].u32 = 0;
+		if (ctr[i].enabled) {
+			octeon_config.control[i].s.event = ctr[i].event;
+			octeon_config.control[i].s.IE = 1;
+			octeon_config.control[i].s.U = ctr[i].user;
+			octeon_config.control[i].s.S = 1;
+			octeon_config.control[i].s.K = ctr[i].kernel;
+			octeon_config.control[i].s.EX = ctr[i].exl;
+			octeon_config.reset_value[i] =
+				(1ull << 63) - ctr[i].count;
+		}
+	}
+}
+
+/* Program all of the registers in preparation for enabling profiling.  */
+
+static void octeon_cpu_setup(void *args)
+{
+	__write_64bit_c0_register($25, 1, octeon_config.reset_value[0]);
+	__write_64bit_c0_register($25, 3, octeon_config.reset_value[1]);
+}
+
+static void octeon_cpu_start(void *args)
+{
+	uint64_t cvmctl;
+
+	/* Disable the issue and exec conditional clock support so we get
+		better results */
+	cvmctl = __read_64bit_c0_register($9, 7);
+	cvmctl |= 3 << 16;
+	__write_64bit_c0_register($9, 7, cvmctl);
+
+	/* Start all counters on current CPU */
+	__write_32bit_c0_register($25, 0, octeon_config.control[0].u32);
+	__write_32bit_c0_register($25, 2, octeon_config.control[1].u32);
+}
+
+static void octeon_cpu_stop(void *args)
+{
+	uint64_t cvmctl;
+
+	/* Stop all counters on current CPU */
+	__write_32bit_c0_register($25, 0, 0);
+	__write_32bit_c0_register($25, 2, 0);
+
+	/* Enable the issue and exec conditional clock support so we use
+		less power */
+	cvmctl = __read_64bit_c0_register($9, 7);
+	cvmctl &= ~(3 << 16);
+	__write_64bit_c0_register($9, 7, cvmctl);
+}
+
+static irqreturn_t octeon_perfcount_handler(int irq, void *dev_id)
+{
+	uint64_t counter;
+
+	counter = __read_64bit_c0_register($25, 1);
+	if (counter & (1ull << 63)) {
+		oprofile_add_sample(get_irq_regs(), 0);
+		__write_64bit_c0_register($25, 1, octeon_config.reset_value[0]);
+	}
+
+	counter = __read_64bit_c0_register($25, 3);
+	if (counter & (1ull << 63)) {
+		oprofile_add_sample(get_irq_regs(), 1);
+		__write_64bit_c0_register($25, 3, octeon_config.reset_value[1]);
+	}
+
+	return IRQ_HANDLED;
+}
+
+static int octeon_init(void)
+{
+	int result =
+		request_irq(6, octeon_perfcount_handler, IRQF_SHARED,
+			    "Perfcounter", octeon_perfcount_handler);
+#ifdef CONFIG_SMP
+	if (result == 0) {
+		irq_desc_t *desc = irq_desc + 6;
+		smp_call_function((void (*)(void *)) desc->chip->enable,
+				  (void *) (long) 6, 1);
+	}
+#endif
+	return result;
+}
+
+static void octeon_exit(void)
+{
+	free_irq(6, octeon_perfcount_handler);
+}
+
+struct op_mips_model op_model_octeon = {
+	.reg_setup = octeon_reg_setup,
+	.cpu_setup = octeon_cpu_setup,
+	.init = octeon_init,
+	.exit = octeon_exit,
+	.cpu_start = octeon_cpu_start,
+	.cpu_stop = octeon_cpu_stop,
+	.cpu_type = "mips/octeon",
+	.num_counters = 2
+};
diff --git a/include/asm-mips/mach-cavium-octeon/cpu-feature-overrides.h b/include/asm-mips/mach-cavium-octeon/cpu-feature-overrides.h
new file mode 100644
index 0000000..227f148
--- /dev/null
+++ b/include/asm-mips/mach-cavium-octeon/cpu-feature-overrides.h
@@ -0,0 +1,62 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004 Cavium Networks
+ */
+#ifndef __ASM_MACH_CAVIUM_OCTEON_CPU_FEATURE_OVERRIDES_H
+#define __ASM_MACH_CAVIUM_OCTEON_CPU_FEATURE_OVERRIDES_H
+
+#include <linux/types.h>
+#include <asm/mipsregs.h>
+
+/*
+ * Cavium Octeons are MIPS64v2 processors
+ */
+#define cpu_dcache_line_size()	128
+#define cpu_icache_line_size()	128
+
+#ifdef CONFIG_SMP
+#define cpu_has_llsc		1
+#else
+/* Disable LL/SC on non SMP systems. It is faster to disable interrupts for
+   atomic access than a LL/SC */
+#define cpu_has_llsc		0
+#endif
+#define cpu_has_prefetch  	1
+#define cpu_has_dc_aliases      0
+#define cpu_has_fpu             0
+#define cpu_has_64bits          1
+#define cpu_has_octeon_cache    1
+#define cpu_has_saa             octeon_has_saa()
+#define cpu_has_mips64r2        1
+#define cpu_has_counter         1
+#define ARCH_HAS_READ_CURRENT_TIMER 1
+#define ARCH_HAS_IRQ_PER_CPU 1
+#define ARCH_HAS_SPINLOCK_PREFETCH 1
+#define spin_lock_prefetch(x) prefetch(x)
+#define PREFETCH_STRIDE 128
+
+static inline int read_current_timer(unsigned long *result)
+{
+	asm volatile ("rdhwr %0,$31\n"
+#ifndef CONFIG_64BIT
+		      "sll %0, 0\n"
+#endif
+		      : "=r" (*result));
+	return 0;
+}
+
+static inline int octeon_has_saa(void)
+{
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	int id;
+	asm volatile ("mfc0 %0, $15,0" : "=r" (id));
+	return id >= 0x000d0300;
+#else
+	return 0;
+#endif
+}
+
+#endif
diff --git a/include/asm-mips/mach-cavium-octeon/i2c-octeon.h b/include/asm-mips/mach-cavium-octeon/i2c-octeon.h
new file mode 100644
index 0000000..5b04aa0
--- /dev/null
+++ b/include/asm-mips/mach-cavium-octeon/i2c-octeon.h
@@ -0,0 +1,20 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2009 Cavium Networks <support@caviumnetworks.com>
+ */
+
+#ifndef _I2C_OCTEON_H_
+#define _I2C_OCTEON_H_
+
+#define I2C_MAX_TIMEOUT 10000   // 10ms
+
+#define OCT_MAX_IFACES 2        /* up to two twsi interfaces as of today */
+
+int octeon_i2c_num_ifaces(void);
+void* octeon_i2c_get_algo_data(int iface);
+int octeon_i2c_xfer_msg(struct i2c_adapter *adap, struct i2c_msg *msg, int combined);
+
+#endif /*_I2C_OCTEON_H_ */
diff --git a/include/asm-mips/mach-cavium-octeon/irq.h b/include/asm-mips/mach-cavium-octeon/irq.h
new file mode 100644
index 0000000..3dc0e0b
--- /dev/null
+++ b/include/asm-mips/mach-cavium-octeon/irq.h
@@ -0,0 +1,253 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2007 Cavium Networks
+ */
+#ifndef __OCTEON_IRQ_H__
+#define __OCTEON_IRQ_H__
+
+#define NR_IRQS OCTEON_IRQ_LAST
+#define MIPS_CPU_IRQ_BASE 0
+
+/* 0 - 7 represent the 8 MIPS standard interrupt sources */
+#define OCTEON_IRQ_SW0          0
+#define OCTEON_IRQ_SW1          1
+#define OCTEON_IRQ_CIU0         2
+#define OCTEON_IRQ_CIU1         3
+#define OCTEON_IRQ_CIU4         4
+#define OCTEON_IRQ_5            5
+#define OCTEON_IRQ_PERF         6
+#define OCTEON_IRQ_TIMER        7
+/* 8 - 71 represent the sources in CIU_INTX_EN0 */
+#define OCTEON_IRQ_WORKQ0       8
+#define OCTEON_IRQ_WORKQ1       9
+#define OCTEON_IRQ_WORKQ2       10
+#define OCTEON_IRQ_WORKQ3       11
+#define OCTEON_IRQ_WORKQ4       12
+#define OCTEON_IRQ_WORKQ5       13
+#define OCTEON_IRQ_WORKQ6       14
+#define OCTEON_IRQ_WORKQ7       15
+#define OCTEON_IRQ_WORKQ8       16
+#define OCTEON_IRQ_WORKQ9       17
+#define OCTEON_IRQ_WORKQ10      18
+#define OCTEON_IRQ_WORKQ11      19
+#define OCTEON_IRQ_WORKQ12      20
+#define OCTEON_IRQ_WORKQ13      21
+#define OCTEON_IRQ_WORKQ14      22
+#define OCTEON_IRQ_WORKQ15      23
+#define OCTEON_IRQ_GPIO0        24
+#define OCTEON_IRQ_GPIO1        25
+#define OCTEON_IRQ_GPIO2        26
+#define OCTEON_IRQ_GPIO3        27
+#define OCTEON_IRQ_GPIO4        28
+#define OCTEON_IRQ_GPIO5        29
+#define OCTEON_IRQ_GPIO6        30
+#define OCTEON_IRQ_GPIO7        31
+#define OCTEON_IRQ_GPIO8        32
+#define OCTEON_IRQ_GPIO9        33
+#define OCTEON_IRQ_GPIO10       34
+#define OCTEON_IRQ_GPIO11       35
+#define OCTEON_IRQ_GPIO12       36
+#define OCTEON_IRQ_GPIO13       37
+#define OCTEON_IRQ_GPIO14       38
+#define OCTEON_IRQ_GPIO15       39
+#define OCTEON_IRQ_MBOX0        40
+#define OCTEON_IRQ_MBOX1        41
+#define OCTEON_IRQ_UART0        42
+#define OCTEON_IRQ_UART1        43
+#define OCTEON_IRQ_PCI_INT0     44
+#define OCTEON_IRQ_PCI_INT1     45
+#define OCTEON_IRQ_PCI_INT2     46
+#define OCTEON_IRQ_PCI_INT3     47
+#define OCTEON_IRQ_PCI_MSI0     48
+#define OCTEON_IRQ_PCI_MSI1     49
+#define OCTEON_IRQ_PCI_MSI2     50
+#define OCTEON_IRQ_PCI_MSI3     51
+#define OCTEON_IRQ_RESERVED52   52	/* Summary of CIU_INT_SUM1 */
+#define OCTEON_IRQ_TWSI         53
+#define OCTEON_IRQ_RML          54
+#define OCTEON_IRQ_TRACE        55
+#define OCTEON_IRQ_GMX_DRP0     56
+#define OCTEON_IRQ_GMX_DRP1     57
+#define OCTEON_IRQ_IPD_DRP      58
+#define OCTEON_IRQ_KEY_ZERO     59
+#define OCTEON_IRQ_TIMER0       60
+#define OCTEON_IRQ_TIMER1       61
+#define OCTEON_IRQ_TIMER2       62
+#define OCTEON_IRQ_TIMER3       63
+#define OCTEON_IRQ_USB0         64
+#define OCTEON_IRQ_PCM          65
+#define OCTEON_IRQ_MPI          66
+#define OCTEON_IRQ_TWSI2        67
+#define OCTEON_IRQ_POWIQ        68
+#define OCTEON_IRQ_IPDPPTHR     69
+#define OCTEON_IRQ_MII0         70
+#define OCTEON_IRQ_BOOTDMA      71
+/* 72 - 135 represent the sources in CIU_INTX_EN1 */
+#define OCTEON_IRQ_WDOG0        72
+#define OCTEON_IRQ_WDOG1        73
+#define OCTEON_IRQ_WDOG2        74
+#define OCTEON_IRQ_WDOG3        75
+#define OCTEON_IRQ_WDOG4        76
+#define OCTEON_IRQ_WDOG5        77
+#define OCTEON_IRQ_WDOG6        78
+#define OCTEON_IRQ_WDOG7        79
+#define OCTEON_IRQ_WDOG8        80
+#define OCTEON_IRQ_WDOG9        81
+#define OCTEON_IRQ_WDOG10       82
+#define OCTEON_IRQ_WDOG11       83
+#define OCTEON_IRQ_WDOG12       84
+#define OCTEON_IRQ_WDOG13       85
+#define OCTEON_IRQ_WDOG14       86
+#define OCTEON_IRQ_WDOG15       87
+#define OCTEON_IRQ_UART2        88
+#define OCTEON_IRQ_USB1         89
+#define OCTEON_IRQ_MII1         90
+#define OCTEON_IRQ_RESERVED91   91
+#define OCTEON_IRQ_RESERVED92   92
+#define OCTEON_IRQ_RESERVED93   93
+#define OCTEON_IRQ_RESERVED94   94
+#define OCTEON_IRQ_RESERVED95   95
+#define OCTEON_IRQ_RESERVED96   96
+#define OCTEON_IRQ_RESERVED97   97
+#define OCTEON_IRQ_RESERVED98   98
+#define OCTEON_IRQ_RESERVED99   99
+#define OCTEON_IRQ_RESERVED100  100
+#define OCTEON_IRQ_RESERVED101  101
+#define OCTEON_IRQ_RESERVED102  102
+#define OCTEON_IRQ_RESERVED103  103
+#define OCTEON_IRQ_RESERVED104  104
+#define OCTEON_IRQ_RESERVED105  105
+#define OCTEON_IRQ_RESERVED106  106
+#define OCTEON_IRQ_RESERVED107  107
+#define OCTEON_IRQ_RESERVED108  108
+#define OCTEON_IRQ_RESERVED109  109
+#define OCTEON_IRQ_RESERVED110  110
+#define OCTEON_IRQ_RESERVED111  111
+#define OCTEON_IRQ_RESERVED112  112
+#define OCTEON_IRQ_RESERVED113  113
+#define OCTEON_IRQ_RESERVED114  114
+#define OCTEON_IRQ_RESERVED115  115
+#define OCTEON_IRQ_RESERVED116  116
+#define OCTEON_IRQ_RESERVED117  117
+#define OCTEON_IRQ_RESERVED118  118
+#define OCTEON_IRQ_RESERVED119  119
+#define OCTEON_IRQ_RESERVED120  120
+#define OCTEON_IRQ_RESERVED121  121
+#define OCTEON_IRQ_RESERVED122  122
+#define OCTEON_IRQ_RESERVED123  123
+#define OCTEON_IRQ_RESERVED124  124
+#define OCTEON_IRQ_RESERVED125  125
+#define OCTEON_IRQ_RESERVED126  126
+#define OCTEON_IRQ_RESERVED127  127
+#define OCTEON_IRQ_RESERVED128  128
+#define OCTEON_IRQ_RESERVED129  129
+#define OCTEON_IRQ_RESERVED130  130
+#define OCTEON_IRQ_RESERVED131  131
+#define OCTEON_IRQ_RESERVED132  132
+#define OCTEON_IRQ_RESERVED133  133
+#define OCTEON_IRQ_RESERVED134  134
+#define OCTEON_IRQ_RESERVED135  135
+/* 136 - 143 are reserved to align the i8259 in a multiple of 16. This
+   alignment is necessary since old style ISA interrupts hanging off the i8259
+   have internal alignment assumptions */
+#define OCTEON_IRQ_RESERVED136  136
+#define OCTEON_IRQ_RESERVED137  137
+#define OCTEON_IRQ_RESERVED138  138
+#define OCTEON_IRQ_RESERVED139  139
+#define OCTEON_IRQ_RESERVED140  140
+#define OCTEON_IRQ_RESERVED141  141
+#define OCTEON_IRQ_RESERVED142  142
+#define OCTEON_IRQ_RESERVED143  143
+/* 144 - 151 represent the i8259 master */
+#define OCTEON_IRQ_I8259M0      144
+#define OCTEON_IRQ_I8259M1      145
+#define OCTEON_IRQ_I8259M2      146
+#define OCTEON_IRQ_I8259M3      147
+#define OCTEON_IRQ_I8259M4      148
+#define OCTEON_IRQ_I8259M5      149
+#define OCTEON_IRQ_I8259M6      150
+#define OCTEON_IRQ_I8259M7      151
+/* 152 - 159 represent the i8259 slave */
+#define OCTEON_IRQ_I8259S0      152
+#define OCTEON_IRQ_I8259S1      153
+#define OCTEON_IRQ_I8259S2      154
+#define OCTEON_IRQ_I8259S3      155
+#define OCTEON_IRQ_I8259S4      156
+#define OCTEON_IRQ_I8259S5      157
+#define OCTEON_IRQ_I8259S6      158
+#define OCTEON_IRQ_I8259S7      159
+#ifdef CONFIG_PCI_MSI
+/* 160 - 223 represent the MSI interrupts 0-63 */
+#define OCTEON_IRQ_MSI_BIT0     160
+#define OCTEON_IRQ_MSI_BIT1     161
+#define OCTEON_IRQ_MSI_BIT2     162
+#define OCTEON_IRQ_MSI_BIT3     163
+#define OCTEON_IRQ_MSI_BIT4     164
+#define OCTEON_IRQ_MSI_BIT5     165
+#define OCTEON_IRQ_MSI_BIT6     166
+#define OCTEON_IRQ_MSI_BIT7     167
+#define OCTEON_IRQ_MSI_BIT8     168
+#define OCTEON_IRQ_MSI_BIT9     169
+#define OCTEON_IRQ_MSI_BIT10    170
+#define OCTEON_IRQ_MSI_BIT11    171
+#define OCTEON_IRQ_MSI_BIT12    172
+#define OCTEON_IRQ_MSI_BIT13    173
+#define OCTEON_IRQ_MSI_BIT14    174
+#define OCTEON_IRQ_MSI_BIT15    175
+#define OCTEON_IRQ_MSI_BIT16    176
+#define OCTEON_IRQ_MSI_BIT17    177
+#define OCTEON_IRQ_MSI_BIT18    178
+#define OCTEON_IRQ_MSI_BIT19    179
+#define OCTEON_IRQ_MSI_BIT20    180
+#define OCTEON_IRQ_MSI_BIT21    181
+#define OCTEON_IRQ_MSI_BIT22    182
+#define OCTEON_IRQ_MSI_BIT23    183
+#define OCTEON_IRQ_MSI_BIT24    184
+#define OCTEON_IRQ_MSI_BIT25    185
+#define OCTEON_IRQ_MSI_BIT26    186
+#define OCTEON_IRQ_MSI_BIT27    187
+#define OCTEON_IRQ_MSI_BIT28    188
+#define OCTEON_IRQ_MSI_BIT29    189
+#define OCTEON_IRQ_MSI_BIT30    190
+#define OCTEON_IRQ_MSI_BIT31    191
+#define OCTEON_IRQ_MSI_BIT32    192
+#define OCTEON_IRQ_MSI_BIT33    193
+#define OCTEON_IRQ_MSI_BIT34    194
+#define OCTEON_IRQ_MSI_BIT35    195
+#define OCTEON_IRQ_MSI_BIT36    196
+#define OCTEON_IRQ_MSI_BIT37    197
+#define OCTEON_IRQ_MSI_BIT38    198
+#define OCTEON_IRQ_MSI_BIT39    199
+#define OCTEON_IRQ_MSI_BIT40    200
+#define OCTEON_IRQ_MSI_BIT41    201
+#define OCTEON_IRQ_MSI_BIT42    202
+#define OCTEON_IRQ_MSI_BIT43    203
+#define OCTEON_IRQ_MSI_BIT44    204
+#define OCTEON_IRQ_MSI_BIT45    205
+#define OCTEON_IRQ_MSI_BIT46    206
+#define OCTEON_IRQ_MSI_BIT47    207
+#define OCTEON_IRQ_MSI_BIT48    208
+#define OCTEON_IRQ_MSI_BIT49    209
+#define OCTEON_IRQ_MSI_BIT50    210
+#define OCTEON_IRQ_MSI_BIT51    211
+#define OCTEON_IRQ_MSI_BIT52    212
+#define OCTEON_IRQ_MSI_BIT53    213
+#define OCTEON_IRQ_MSI_BIT54    214
+#define OCTEON_IRQ_MSI_BIT55    215
+#define OCTEON_IRQ_MSI_BIT56    216
+#define OCTEON_IRQ_MSI_BIT57    217
+#define OCTEON_IRQ_MSI_BIT58    218
+#define OCTEON_IRQ_MSI_BIT59    219
+#define OCTEON_IRQ_MSI_BIT60    220
+#define OCTEON_IRQ_MSI_BIT61    221
+#define OCTEON_IRQ_MSI_BIT62    222
+#define OCTEON_IRQ_MSI_BIT63    223
+#define OCTEON_IRQ_LAST         224
+#else
+#define OCTEON_IRQ_LAST         160
+#endif
+
+#endif
diff --git a/include/asm-mips/mach-cavium-octeon/kernel-entry-init.h b/include/asm-mips/mach-cavium-octeon/kernel-entry-init.h
new file mode 100644
index 0000000..e06cf2e
--- /dev/null
+++ b/include/asm-mips/mach-cavium-octeon/kernel-entry-init.h
@@ -0,0 +1,121 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2005-2008 Cavium Networks, Inc
+ */
+#ifndef __ASM_MACH_CAVIUM_OCTEON_KERNEL_ENTRY_H
+#define __ASM_MACH_CAVIUM_OCTEON_KERNEL_ENTRY_H
+
+
+#define CP0_CYCLE_COUNTER $9,6
+#define CP0_CVMCTL_REG $9,7
+#define CP0_CVMMEMCTL_REG $11,7
+#define CP0_STATUS_REG $12,0
+#define CP0_PRID_REG $15,0
+#define CP0_PRID_OCTEON_PASS1 0x000d0000
+#define CP0_PRID_OCTEON_CN30XX 0x000d0200
+
+.macro  kernel_entry_setup
+    # Registers set by bootloader:
+    # (only 32 bits set by bootloader, all addresses are physical addresses, and need
+    #   to have the appropriate memory region set by the kernel
+    # a0 = argc
+    # a1 = argv (kseg0 compat addr )
+    # a2 = 1 if init core, zero otherwise
+    # a3 = address of boot descriptor block
+    .set push
+    .set arch=octeon
+	mfc0	v0, CP0_STATUS_REG	# Read C0_Status
+	ins	v0, $0, 29, 3		# Clear CU1, CU2, CU3
+	ins	v0, $0, 19, 1		# Clear NMI
+	mtc0	v0, CP0_STATUS_REG	# Write it back out.
+    dmfc0   v0, CP0_CVMMEMCTL_REG       # Read the cavium mem control register
+    dins    v0, $0, 0, 6                # Clear the lower 6 bits, the CVMSEG size
+    ori     v0, CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE
+    dmtc0   v0, CP0_CVMMEMCTL_REG       # Write the cavium mem control register
+    dmfc0   v0, CP0_CVMCTL_REG          # Read the cavium control register
+#ifdef CONFIG_CAVIUM_OCTEON_HW_FIX_UNALIGNED
+    or  v0, v0, 0x5001                  # Disable unaligned load/store support but leave HW fixup enabled
+    xor v0, v0, 0x1001
+#else
+    or  v0, v0, 0x5001                  # Disable unaligned load/store and HW fixup support
+    xor v0, v0, 0x5001
+#endif
+    mfc0 v1, CP0_PRID_REG               # Read the processor ID register
+    or  v0, v0, 0x2000                  # Disable instruction prefetching (Octeon Pass1 errata)
+    beq v1, CP0_PRID_OCTEON_PASS1,skip  # Skip reenable of prefetching for Octeon Pass1
+     nop
+    xor v0, v0, 0x2000                  # Reenable instruction prefetching, not on Pass1
+    srl v1, 8                           # Strip off pass number off of processor id
+    sll v1, 8
+    bne v1, CP0_PRID_OCTEON_CN30XX,skip # CN30XX needs some extra stuff turned off for better performance
+     nop
+    or  v0, v0, 0x400                   # CN30XX Use random Icache replacement
+    or  v0, v0, 0x2000                  # CN30XX Disable instruction prefetching
+skip:
+    dmtc0   v0, CP0_CVMCTL_REG          # Write the cavium control register
+    sync
+    cache   9, 0($0)                    # Flush dcache after config change
+
+    PTR_LA  t2, octeon_boot_desc_ptr    # Store the boot descriptor pointer
+    LONG_S  a3, (t2)
+
+    rdhwr   v0, $0                      # Get my core id
+    bne     a2, zero, octeon_main_processor # Jump the master to kernel_entry
+    nop
+
+#ifdef CONFIG_SMP
+
+    #
+    # All cores other than the master need to wait here for SMP bootstrap
+    # to begin
+    #
+    PTR_LA  t0, octeon_processor_boot   # This is the variable where the next core to boot os stored
+octeon_spin_wait_boot:
+    LONG_L  t1, (t0)                    # Get the core id of the next to be booted
+    bne t1, v0, octeon_spin_wait_boot   # Keep looping if it isn't me
+    nop
+    PTR_LA  t0, octeon_processor_cycle  # Synchronize the cycle counters
+    LONG_L  t0, (t0)
+    LONG_ADDU t0, 122                   # Aproximately how many cycles we will be off
+    MTC0    t0, CP0_CYCLE_COUNTER
+    PTR_LA  t0, octeon_processor_gp     # Get my GP from the global variable
+    LONG_L  gp, (t0)
+    PTR_LA  t0, octeon_processor_sp     # Get my SP from the global variable
+    LONG_L  sp, (t0)
+    LONG_S  zero, (t0)                  # Set the SP global variable to zero so the master knows we've started
+#ifdef __OCTEON__
+    syncw
+    syncw
+#else
+    sync
+#endif
+    b   smp_bootstrap                   # Jump to the normal Linux SMP entry point
+    nop
+
+#else /* CONFIG_SMP */
+
+    #
+    # Someone tried to boot SMP with a non SMP kernel. All extra cores
+    # will halt here.
+    #
+octeon_wait_forever:
+    wait
+    b   octeon_wait_forever
+    nop
+
+#endif /* CONFIG_SMP */
+octeon_main_processor:
+    .set pop
+.endm
+
+/*
+ * Do SMP slave processor setup necessary before we can savely execute C code.
+ */
+    .macro  smp_slave_setup
+    .endm
+
+
+#endif /* __ASM_MACH_CAVIUM_OCTEON_KERNEL_ENTRY_H */
diff --git a/include/asm-mips/mach-cavium-octeon/octeon-hal-read-write.h b/include/asm-mips/mach-cavium-octeon/octeon-hal-read-write.h
new file mode 100644
index 0000000..8c1dfc8
--- /dev/null
+++ b/include/asm-mips/mach-cavium-octeon/octeon-hal-read-write.h
@@ -0,0 +1,38 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004-2007 Cavium Networks
+ */
+#ifndef __CAVIUM_OCTEON_HAL_READ_WRITE_H__
+#define __CAVIUM_OCTEON_HAL_READ_WRITE_H__
+
+#include "cvmx.h"
+
+
+/**
+ * Write a 32bit value to the Octeon NPI register space
+ *
+ * @param address Address to write to
+ * @param val     Value to write
+ */
+static inline void octeon_npi_write32(uint64_t address, uint32_t val)
+{
+	cvmx_write64_uint32(address ^ 4, val);
+	cvmx_read64_uint32(address ^ 4);
+}
+
+
+/**
+ * Read a 32bit value from the Octeon NPI register space
+ *
+ * @param address Address to read
+ * @return The result
+ */
+static inline uint32_t octeon_npi_read32(uint64_t address)
+{
+	return cvmx_read64_uint32(address ^ 4);
+}
+
+#endif
diff --git a/include/asm-mips/mach-cavium-octeon/perf_counters.h b/include/asm-mips/mach-cavium-octeon/perf_counters.h
new file mode 100644
index 0000000..f52a511
--- /dev/null
+++ b/include/asm-mips/mach-cavium-octeon/perf_counters.h
@@ -0,0 +1,24 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2004 Cavium Networks
+ */
+
+/**
+ * The IOCTL numbers supported on /proc/octeon_perf
+ */
+#define PROC_PERF_IOCTL_SETUP_COUNTER0      _IOW(0x81, 0, int)
+#define PROC_PERF_IOCTL_SETUP_COUNTER1      _IOW(0x81, 1, int)
+#define PROC_PERF_IOCTL_SETUP_L2COUNTER0    _IOW(0x81, 2, int)
+#define PROC_PERF_IOCTL_SETUP_L2COUNTER1    _IOW(0x81, 3, int)
+#define PROC_PERF_IOCTL_SETUP_L2COUNTER2    _IOW(0x81, 4, int)
+#define PROC_PERF_IOCTL_SETUP_L2COUNTER3    _IOW(0x81, 5, int)
+#define PROC_PERF_IOCTL_READ_COUNTER0       _IOR(0x81, 6, long long)
+#define PROC_PERF_IOCTL_READ_COUNTER1       _IOR(0x81, 7, long long)
+#define PROC_PERF_IOCTL_READ_L2COUNTER0     _IOR(0x81, 8, long long)
+#define PROC_PERF_IOCTL_READ_L2COUNTER1     _IOR(0x81, 9, long long)
+#define PROC_PERF_IOCTL_READ_L2COUNTER2     _IOR(0x81, 10, long long)
+#define PROC_PERF_IOCTL_READ_L2COUNTER3     _IOR(0x81, 11, long long)
+
diff --git a/include/asm-mips/mach-cavium-octeon/war.h b/include/asm-mips/mach-cavium-octeon/war.h
new file mode 100644
index 0000000..c4712d7
--- /dev/null
+++ b/include/asm-mips/mach-cavium-octeon/war.h
@@ -0,0 +1,26 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2002, 2004, 2007 by Ralf Baechle <ralf@linux-mips.org>
+ * Copyright (C) 2008 Cavium Networks <support@caviumnetworks.com>
+ */
+#ifndef __ASM_MIPS_MACH_CAVIUM_OCTEON_WAR_H
+#define __ASM_MIPS_MACH_CAVIUM_OCTEON_WAR_H
+
+#define R4600_V1_INDEX_ICACHEOP_WAR	0
+#define R4600_V1_HIT_CACHEOP_WAR	0
+#define R4600_V2_HIT_CACHEOP_WAR	0
+#define R5432_CP0_INTERRUPT_WAR		0
+#define BCM1250_M3_WAR			0
+#define SIBYTE_1956_WAR			0
+#define MIPS4K_ICACHE_REFILL_WAR	0
+#define MIPS_CACHE_SYNC_WAR		0
+#define TX49XX_ICACHE_INDEX_INV_WAR	0
+#define RM9000_CDEX_SMP_WAR		0
+#define ICACHE_REFILLS_WORKAROUND_WAR	0
+#define R10000_LLSC_WAR			0
+#define MIPS34K_MISSED_ITLB_WAR		0
+
+#endif /* __ASM_MIPS_MACH_CAVIUM_OCTEON_WAR_H */
diff --git a/include/asm-mips/watch.h b/include/asm-mips/watch.h
new file mode 100644
index 0000000..20126ec
--- /dev/null
+++ b/include/asm-mips/watch.h
@@ -0,0 +1,32 @@
+/*
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2008 David Daney
+ */
+#ifndef _ASM_WATCH_H
+#define _ASM_WATCH_H
+
+#include <linux/bitops.h>
+
+#include <asm/mipsregs.h>
+
+void mips_install_watch_registers(void);
+void mips_read_watch_registers(void);
+void mips_clear_watch_registers(void);
+void mips_probe_watch_registers(struct cpuinfo_mips *c);
+
+#ifdef CONFIG_HARDWARE_WATCHPOINTS
+#define __restore_watch() do {						\
+	if (unlikely(test_bit(TIF_LOAD_WATCH,				\
+			      &current_thread_info()->flags))) {	\
+		mips_install_watch_registers();				\
+	}								\
+} while (0)
+
+#else
+#define __restore_watch() do {} while (0)
+#endif
+
+#endif /* _ASM_WATCH_H */
-- 
1.5.5.1

