From 4dd2a7ae3401b5c9a7d9786675ad2a12abca1480 Mon Sep 17 00:00:00 2001
From: Hui Wang <Hui.Wang@windriver.com>
Date: Mon, 21 Feb 2011 16:18:42 +0800
Subject: [PATCH] Cavium: Hotplug CPU modifications

Source: SDK 2.0.0-366

Cleanup hotplug cpu code:

For CONFIG_HOTPLUG_CPU, we set the 'possible' cpus to the set of all
cores present, even if they are not in the boot_coremask.

Update the avail_coremask when the core is plugged in, so that it will
not be available for spawning other applications.

Improve HOTPLUG_CPU related panic messages

Signed-off-by: ltian <le.tian@windriver.com>
---
 arch/mips/cavium-octeon/setup.c |   15 +++
 arch/mips/cavium-octeon/smp.c   |  235 ++++++++++++++++++++-------------------
 arch/mips/kernel/smp.c          |    3 +
 3 files changed, 141 insertions(+), 112 deletions(-)

diff --git a/arch/mips/cavium-octeon/setup.c b/arch/mips/cavium-octeon/setup.c
index aa3335b..b31fc87 100644
--- a/arch/mips/cavium-octeon/setup.c
+++ b/arch/mips/cavium-octeon/setup.c
@@ -35,6 +35,8 @@
 #include <asm/time.h>
 
 #include <asm/octeon/octeon.h>
+#include <asm/octeon/octeon-boot-info.h>
+
 #include <asm/octeon/cvmx-clock.h>
 #include <asm/octeon/cvmx-error.h>
 #include <asm/octeon/cvmx-debug.h>
@@ -111,6 +113,13 @@ extern asmlinkage void plat_irq_dispatch(void);
 struct mii_bus *octeon_mdiobuses[2];
 EXPORT_SYMBOL(octeon_mdiobuses);
 
+/*
+ * If set to a non-zero value, the bootloader entry point for
+ * HOTPLUG_CPU and other tricks.
+ */
+u64 octeon_bootloader_entry_addr;
+EXPORT_SYMBOL(octeon_bootloader_entry_addr);
+
 /* If an initrd named block is specified, its name goes here. */
 static char __initdata rd_name[64];
 
@@ -612,6 +621,7 @@ int xkphys_usermem_write(long pid, int value)
 void __init prom_init(void)
 {
 	struct cvmx_sysinfo *sysinfo;
+	struct linux_app_boot_info *labi;
 	const int coreid = cvmx_get_core_num();
 	int i;
 	int argc;
@@ -822,6 +832,11 @@ void __init prom_init(void)
 
 	octeon_user_io_init();
 	register_smp_ops(&octeon_smp_ops);
+
+	labi = (struct linux_app_boot_info *)PHYS_TO_XKSEG_CACHED(LABI_ADDR_IN_BOOTLOADER);
+	if (labi->labi_signature == LABI_SIGNATURE)
+		octeon_bootloader_entry_addr = labi->InitTLBStart_addr;
+
 #ifdef CONFIG_KEXEC
 	octeon_kexec_setup();
 #endif
diff --git a/arch/mips/cavium-octeon/smp.c b/arch/mips/cavium-octeon/smp.c
index d203af9..d7a6171 100644
--- a/arch/mips/cavium-octeon/smp.c
+++ b/arch/mips/cavium-octeon/smp.c
@@ -20,15 +20,20 @@
 
 #include <asm/octeon/octeon.h>
 
-#include "octeon_boot.h"
+#include <asm/octeon/octeon-boot-info.h>
+#include <asm/octeon/cvmx-app-hotplug.h>
+
+#include <asm/octeon/cvmx-debug.h>
 
 volatile unsigned long octeon_processor_boot = 0xff;
 volatile unsigned long octeon_processor_sp;
 volatile unsigned long octeon_processor_gp;
 
 #ifdef CONFIG_HOTPLUG_CPU
-static unsigned int InitTLBStart_addr;
+static uint32_t octeon_hotplug_entry_addr;
+extern void octeon_hotplug_entry(void);
 #endif
+struct cvmx_app_hotplug_global *octeon_hotplug_global_ptr;
 
 static irqreturn_t mailbox_interrupt(int irq, void *dev_id)
 {
@@ -74,54 +79,81 @@ static inline void octeon_send_ipi_mask(const struct cpumask *mask,
 		octeon_send_ipi_single(i, action);
 }
 
-/**
- * Detect available CPUs, populate cpu_possible_map
- */
-static void octeon_smp_hotplug_setup(void)
-{
-#ifdef CONFIG_HOTPLUG_CPU
-	uint32_t labi_signature;
-
-	labi_signature =
-		cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
-					LABI_ADDR_IN_BOOTLOADER +
-					offsetof(struct linux_app_boot_info,
-						    labi_signature)));
-	if (labi_signature != LABI_SIGNATURE)
-		pr_err("The bootloader version on this board is incorrect\n");
-	InitTLBStart_addr =
-		cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
-				   LABI_ADDR_IN_BOOTLOADER +
-					   offsetof(struct linux_app_boot_info,
-						    InitTLBStart_addr)));
-#endif
-}
-
 static void octeon_smp_setup(void)
 {
 	const int coreid = cvmx_get_core_num();
 	int cpus;
 	int id;
-
 	int core_mask = octeon_get_boot_coremask();
+#ifdef CONFIG_HOTPLUG_CPU
+	unsigned int num_cores = cvmx_octeon_num_cores();
+#endif
+	struct linux_app_boot_info *labi;
+
+	/* The present CPUs are initially just the boot cpu (CPU 0). */
+	for (id = 0; id < NR_CPUS; id++) {
+		set_cpu_possible(id, id == 0);
+		set_cpu_present(id, id == 0);
+	}
 
-	cpus_clear(cpu_possible_map);
 	__cpu_number_map[coreid] = 0;
 	__cpu_logical_map[0] = coreid;
-	cpu_set(0, cpu_possible_map);
 
+	/* The present CPUs get the lowest CPU numbers. */
 	cpus = 1;
-	for (id = 0; id < 16; id++) {
+	for (id = 0; id < NR_CPUS; id++) {
 		if ((id != coreid) && (core_mask & (1 << id))) {
-			cpu_set(cpus, cpu_possible_map);
+			set_cpu_possible(cpus, true);
+			set_cpu_present(cpus, true);
 			__cpu_number_map[id] = cpus;
 			__cpu_logical_map[cpus] = id;
 			cpus++;
 		}
 	}
-	cpu_present_map = cpu_possible_map;
 
-	octeon_smp_hotplug_setup();
+#ifdef CONFIG_HOTPLUG_CPU
+
+	/*
+	 * HOTPLUG_CPU not possible if we don't know the bootloader
+	 * entrypoint.  Stop now before lulling people into thinking
+	 * it might work.
+	 */
+	if (!octeon_bootloader_entry_addr) {
+		if ((octeon_bootinfo->core_mask & 1) == 0)
+			panic("Linux not booted on core 0 with HOTPLUG_CPU");
+		else
+			panic("The bootloader version on this board is not compatible with HOTPLUG_CPU.");
+	}
+
+	/*
+	 * The possible CPUs are all those present on the chip.  We
+	 * will assign CPU numbers for possible cores as well.  Cores
+	 * are always consecutively numberd from 0.
+	 */
+	for (id = 0; id < num_cores && id < NR_CPUS; id++) {
+		if (!(core_mask & (1 << id))) {
+			set_cpu_possible(cpus, true);
+			__cpu_number_map[id] = cpus;
+			__cpu_logical_map[cpus] = id;
+			cpus++;
+		}
+	}
+#endif
+	octeon_hotplug_global_ptr =
+		(struct cvmx_app_hotplug_global *) cvmx_bootmem_alloc_named_range(
+			CVMX_APP_HOTPLUG_INFO_REGION_SIZE, 0x0, 0x0, 0,
+			CVMX_APP_HOTPLUG_INFO_REGION_NAME);
+	if (!octeon_hotplug_global_ptr) {
+		pr_err("Failed to allocate memory for Hotplug memory block\n");
+		return;
+	}
+	memset(octeon_hotplug_global_ptr, 0, CVMX_APP_HOTPLUG_INFO_REGION_SIZE);
+
+	labi = (struct linux_app_boot_info *)PHYS_TO_XKSEG_CACHED(LABI_ADDR_IN_BOOTLOADER);
+	octeon_hotplug_global_ptr->avail_coremask = labi->avail_coremask;
+
+	pr_info("Cavium Hotplug: Available coremask 0x%x\n",
+		octeon_hotplug_global_ptr->avail_coremask);
 }
 
 /**
@@ -140,7 +172,7 @@ static void octeon_boot_secondary(int cpu, struct task_struct *idle)
 	octeon_processor_boot = cpu_logical_map(cpu);
 	mb();
 
-	count = 10000;
+	count = 100000;
 	while (octeon_processor_sp && count) {
 		/* Waiting for processor to get the SP and GP */
 		udelay(1);
@@ -159,17 +191,8 @@ static void octeon_init_secondary(void)
 	const int coreid = cvmx_get_core_num();
 	union cvmx_ciu_intx_sum0 interrupt_enable;
 
-#ifdef CONFIG_HOTPLUG_CPU
-	unsigned int cur_exception_base;
-
-	cur_exception_base = cvmx_read64_uint32(
-		CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
-			     LABI_ADDR_IN_BOOTLOADER +
-			     offsetof(struct linux_app_boot_info,
-				      cur_exception_base)));
-	/* cur_exception_base is incremented in bootloader after setting */
-	write_c0_ebase((unsigned int)(cur_exception_base - EXCEPTION_BASE_INCR));
-#endif
+	write_c0_ebase((u32)ebase);
+
 	octeon_check_cpu_bist();
 	octeon_init_cvmcount();
 	/*
@@ -194,6 +217,23 @@ static void octeon_init_secondary(void)
  */
 void octeon_prepare_cpus(unsigned int max_cpus)
 {
+#ifdef CONFIG_HOTPLUG_CPU
+	unsigned long t;
+	struct linux_app_boot_info *labi;
+
+	labi = (struct linux_app_boot_info *)PHYS_TO_XKSEG_CACHED(LABI_ADDR_IN_BOOTLOADER);
+
+	if (labi->labi_signature != LABI_SIGNATURE)
+		panic("The bootloader version on this board is incorrect.");
+
+	t = __pa_symbol(octeon_hotplug_entry);
+
+	if (t >= 0x20000000)
+		panic("The kernel physical load address (%lx) is not compatible with CONFIG_HOTPLUG_CPU.\n", t);
+
+	octeon_hotplug_entry_addr = (uint32_t)CKSEG0ADDR(t);
+#endif
+
 	cvmx_write_csr(CVMX_CIU_MBOX_CLRX(cvmx_get_core_num()), 0xffffffff);
 	if (request_irq(OCTEON_IRQ_MBOX0, mailbox_interrupt, IRQF_DISABLED|IRQF_NODELAY,
 			"mailbox0", mailbox_interrupt)) {
@@ -276,8 +316,8 @@ static int octeon_cpu_disable(void)
 static void octeon_cpu_die(unsigned int cpu)
 {
 	int coreid = cpu_logical_map(cpu);
-	uint32_t avail_coremask;
-	struct cvmx_bootmem_named_block_desc *block_desc;
+	uint32_t mask, new_mask;
+	const struct cvmx_bootmem_named_block_desc *block_desc;
 
 	while (per_cpu(cpu_state, cpu) != CPU_DEAD)
 		cpu_relax();
@@ -286,100 +326,75 @@ static void octeon_cpu_die(unsigned int cpu)
 	 * This is a bit complicated strategics of getting/settig available
 	 * cores mask, copied from bootloader
 	 */
+
+	mask = 1 << coreid;
+	octeon_hotplug_global_ptr->avail_coremask |= mask;
+
 	/* LINUX_APP_BOOT_BLOCK is initialized in bootoct binary */
 	block_desc = cvmx_bootmem_find_named_block(LINUX_APP_BOOT_BLOCK_NAME);
 
 	if (!block_desc) {
-		avail_coremask =
-			cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
-						   LABI_ADDR_IN_BOOTLOADER +
-						   offsetof
-						   (struct linux_app_boot_info,
-						    avail_coremask)));
-	} else {		       /* alternative, already initialized */
-	       avail_coremask =
-		   cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
-						   block_desc->base_addr +
-						  AVAIL_COREMASK_OFFSET_IN_LINUX_APP_BOOT_BLOCK));
-	}
+		struct linux_app_boot_info *labi;
 
-	avail_coremask |= 1 << coreid;
+		labi = (struct linux_app_boot_info *)PHYS_TO_XKSEG_CACHED(LABI_ADDR_IN_BOOTLOADER);
 
-	/* Setting avail_coremask for bootoct binary */
-	if (!block_desc) {
-		cvmx_write64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
-						LABI_ADDR_IN_BOOTLOADER +
-						offsetof(struct linux_app_boot_info,
-							 avail_coremask)),
-				   avail_coremask);
-	} else {
-		cvmx_write64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
-						block_desc->base_addr +
-						AVAIL_COREMASK_OFFSET_IN_LINUX_APP_BOOT_BLOCK),
-				   avail_coremask);
+		labi->avail_coremask |= mask;
+		new_mask = labi->avail_coremask;
+	} else {		       /* alternative, already initialized */
+		new_mask = octeon_hotplug_global_ptr->avail_coremask;
 	}
 
-	pr_info("Reset core %d. Available Coremask = %x\n", coreid,
-		avail_coremask);
-	cvmx_write_csr(CVMX_CIU_PP_RST, 1 << coreid);
-	cvmx_write_csr(CVMX_CIU_PP_RST, 0);
+	mb();
+
+	pr_info("Reset core %d. Available Coremask = 0x%x\n", coreid, new_mask);
+	cvmx_write_csr(CVMX_CIU_NMI, 1 << coreid);
 }
 
 void play_dead(void)
 {
-	int coreid = cvmx_get_core_num();
+	int cpu = cpu_number_map(cvmx_get_core_num());
 
 	idle_task_exit();
 	octeon_processor_boot = 0xff;
-	per_cpu(cpu_state, coreid) = CPU_DEAD;
+	per_cpu(cpu_state, cpu) = CPU_DEAD;
+
+	wmb(); /* nudge writeback */
 
 	while (1)	/* core will be reset here */
 		;
 }
 
-extern void kernel_entry(unsigned long arg1, ...);
-
-static void start_after_reset(void)
-{
-	kernel_entry(0, 0, 0);  /* set a2 = 0 for secondary core */
-}
-
-int octeon_update_boot_vector(unsigned int cpu)
+static int octeon_update_boot_vector(unsigned int cpu)
 {
 
 	int coreid = cpu_logical_map(cpu);
 	unsigned int avail_coremask;
-	struct cvmx_bootmem_named_block_desc *block_desc;
-	struct boot_init_vector *boot_vect =
-		(struct boot_init_vector *) cvmx_phys_to_ptr(0x0 +
+	const struct cvmx_bootmem_named_block_desc *block_desc;
+	boot_init_vector_t *boot_vect =
+		(boot_init_vector_t *) cvmx_phys_to_ptr(0x0 +
 						  BOOTLOADER_BOOT_VECTOR);
 
 	block_desc = cvmx_bootmem_find_named_block(LINUX_APP_BOOT_BLOCK_NAME);
 
 	if (!block_desc) {
-		avail_coremask =
-			cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
-					   LABI_ADDR_IN_BOOTLOADER +
-						offsetof(struct linux_app_boot_info,
-						avail_coremask)));
-	} else {		       /* alternative, already initialized */
-	       avail_coremask =
-		   cvmx_read64_uint32(CVMX_ADD_SEG(CVMX_MIPS_SPACE_XKPHYS,
-						   block_desc->base_addr +
-						   AVAIL_COREMASK_OFFSET_IN_LINUX_APP_BOOT_BLOCK));
-	}
+		struct linux_app_boot_info *labi;
 
-	if (!(avail_coremask & (1 << coreid))) {
-		/* core not available, assume, that catched by simple-executive */
-		cvmx_write_csr(CVMX_CIU_PP_RST, 1 << coreid);
-		cvmx_write_csr(CVMX_CIU_PP_RST, 0);
+		labi = (struct linux_app_boot_info *)PHYS_TO_XKSEG_CACHED(LABI_ADDR_IN_BOOTLOADER);
+
+		avail_coremask = labi->avail_coremask;
+		labi->avail_coremask &= ~(1 << coreid);
+	} else {		       /* alternative, already initialized */
+		avail_coremask = octeon_hotplug_global_ptr->avail_coremask;
+		if (!(avail_coremask & (1<<coreid)))
+			return -1;
 	}
+	/* This core is no longer available */
+	octeon_hotplug_global_ptr->avail_coremask &= ~(1<<coreid);
 
-	boot_vect[coreid].app_start_func_addr =
-		(uint32_t) (unsigned long) start_after_reset;
-	boot_vect[coreid].code_addr = InitTLBStart_addr;
+	boot_vect[coreid].app_start_func_addr = octeon_hotplug_entry_addr;
+	boot_vect[coreid].code_addr = octeon_bootloader_entry_addr;
 
-	CVMX_SYNC;
+	mb();
 
 	cvmx_write_csr(CVMX_CIU_NMI, (1 << coreid) & avail_coremask);
 
@@ -405,13 +420,9 @@ static int __cpuinit octeon_cpu_callback(struct notifier_block *nfb,
 	return NOTIFY_OK;
 }
 
-static struct notifier_block __cpuinitdata octeon_cpu_notifier = {
-	.notifier_call = octeon_cpu_callback,
-};
-
 static int __cpuinit register_cavium_notifier(void)
 {
-	register_hotcpu_notifier(&octeon_cpu_notifier);
+	hotcpu_notifier(octeon_cpu_callback, 0);
 
 	return 0;
 }
diff --git a/arch/mips/kernel/smp.c b/arch/mips/kernel/smp.c
index 0aaa22b..8beed94 100644
--- a/arch/mips/kernel/smp.c
+++ b/arch/mips/kernel/smp.c
@@ -48,7 +48,10 @@
 
 volatile cpumask_t cpu_callin_map;	/* Bitmask of started secondaries */
 int __cpu_number_map[NR_CPUS];		/* Map physical to logical */
+EXPORT_SYMBOL(__cpu_number_map);
+
 int __cpu_logical_map[NR_CPUS];		/* Map logical to physical */
+EXPORT_SYMBOL(__cpu_logical_map);
 
 /* Number of TCs (or siblings in Intel speak) per CPU core */
 int smp_num_siblings = 1;
-- 
1.6.5.2

