From 9d596af647f2ca6d9a6a52ddc3b00d71ec1b62ea Mon Sep 17 00:00:00 2001
From: Yang Shi <yang.shi@windriver.com>
Date: Thu, 25 Nov 2010 14:48:37 +0800
Subject: [PATCH 04/38] WRHV: MIPS: Add MIPS specific VBI

Add MIPS specific VBI from HYP 1.3.

Signed-off-by: Yang Shi <yang.shi@windriver.com>
---
 arch/mips/include/asm/arch_vbi.h |  258 +++++++++
 arch/mips/include/asm/reg_vbi.h  |  236 ++++++++
 arch/mips/include/asm/vbi.h      |  618 +++++++++++++++++++++
 arch/mips/kernel/Makefile        |    2 +
 arch/mips/kernel/vbi/Makefile    |    4 +
 arch/mips/kernel/vbi/syscalls.S  | 1128 ++++++++++++++++++++++++++++++++++++++
 6 files changed, 2246 insertions(+), 0 deletions(-)
 create mode 100644 arch/mips/include/asm/arch_vbi.h
 create mode 100755 arch/mips/include/asm/reg_vbi.h
 create mode 100755 arch/mips/include/asm/vbi.h
 create mode 100644 arch/mips/kernel/vbi/Makefile
 create mode 100644 arch/mips/kernel/vbi/syscalls.S

diff --git a/arch/mips/include/asm/arch_vbi.h b/arch/mips/include/asm/arch_vbi.h
new file mode 100644
index 0000000..249027d
--- /dev/null
+++ b/arch/mips/include/asm/arch_vbi.h
@@ -0,0 +1,258 @@
+/*
+ * arch_vbi.h - MIPS64 architecture specific definitions
+ *
+ * Copyright 2009-2011 Wind River Systems, Inc.
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ */
+
+#ifndef _ASM_ARCH_VBI_H
+#define _ASM_ARCH_VBI_H
+
+/* MIPS uses big endian byte ordering */
+
+#define __VBI_BYTE_ORDER __VBI_BIG_ENDIAN
+
+/* VIOAPIC number of entries */
+
+#define VB_VIOAPIC_ENTRIES_SIZE		    64 
+
+#define _WRHV_ARCH_HAS_STATUS_REGS	    1
+#define _WRHV_ARCH_HAS_CTRL_REGS	    1
+
+#ifndef _WRS_INT_REGISTER_SIZE
+#define _WRS_INT_REGISTER_SIZE  8
+#endif
+
+/* #define _RTypeSize _WRS_INT_REGISTER_SIZE*/
+#define _RTypeSize 8
+
+#if (_WRS_INT_REGISTER_SIZE == 4)
+#define VB_N32_REG_OFFSET 4
+#else
+#define VB_N32_REG_OFFSET 0
+#endif
+
+#define VB_CONTROL_REGS_OFFSET_BASE	 0
+#define VB_CONTROL_EPC			((_RTypeSize * (VB_CONTROL_REGS_OFFSET_BASE + 0)) + VB_N32_REG_OFFSET)
+#define VB_CONTROL_SR			((_RTypeSize * (VB_CONTROL_REGS_OFFSET_BASE + 1))  + VB_N32_REG_OFFSET)
+#define VB_CONTROL_K0			((_RTypeSize * (VB_CONTROL_REGS_OFFSET_BASE + 2))  + VB_N32_REG_OFFSET)
+#define VB_CONTROL_K1			((_RTypeSize * (VB_CONTROL_REGS_OFFSET_BASE + 3))  + VB_N32_REG_OFFSET)
+#define VB_CONTROL_V0			((_RTypeSize * (VB_CONTROL_REGS_OFFSET_BASE + 4))  + VB_N32_REG_OFFSET)
+#define VB_CONTROL_ASID			((_RTypeSize * (VB_CONTROL_REGS_OFFSET_BASE + 5))  + VB_N32_REG_OFFSET)
+#define VB_CONTROL_VMMU_HANDLE		((_RTypeSize * (VB_CONTROL_REGS_OFFSET_BASE + 6))  + VB_N32_REG_OFFSET)
+
+#define VB_CONTROL_REG_STRUCT_END	((_RTypeSize * (VB_CONTROL_REGS_OFFSET_BASE + 15)))
+
+#define VB_STATUS_REGS_OFFSET_BASE	 0
+#define VB_STATUS_EPC			((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +0)) + VB_N32_REG_OFFSET)
+#define VB_STATUS_SR			((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +1)) + VB_N32_REG_OFFSET)
+#define VB_STATUS_CAUSE			((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +2)) + VB_N32_REG_OFFSET)
+#define VB_STATUS_RA			((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +3)) + VB_N32_REG_OFFSET)
+#define VB_STATUS_K0			((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +4)) + VB_N32_REG_OFFSET)
+#define VB_STATUS_K1			((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +5)) + VB_N32_REG_OFFSET)
+#define VB_STATUS_CIU_SUM		((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +6)) + VB_N32_REG_OFFSET)
+#define VB_STATUS_V0			((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +7)) + VB_N32_REG_OFFSET)
+#define VB_STATUS_BADVA			((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +8)) + VB_N32_REG_OFFSET)
+#define VB_STATUS_ASID			((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +9)) + VB_N32_REG_OFFSET)
+#define VB_STATUS_VMMU_HANDLE		((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +10)) + VB_N32_REG_OFFSET)
+
+#define VB_STATUS_REG_STRUCT_END	((_RTypeSize * (VB_STATUS_REGS_OFFSET_BASE +11)))
+
+#ifndef	_ASMLANGUAGE
+
+
+#define VB_STATUS_REGS_ACCESS(base, field)	\
+	base->vb_status_regs.field		
+
+#define VB_CONTROL_REGS_ACCESS(base, field)	\
+	base->vb_control_regs.field		
+
+/*
+ * vb_arch_crtl_regs - Virtual core MIPS64 control structure
+ *
+ * Virtual board emulated control registers. These registers are used
+ * by a guest running on hypervisor to configure the virtual CPU register.
+ *
+ */
+
+struct vb_arch_ctrl_regs
+{
+	uint64_t epc; 	/* 0: PC to be restored by sys_load_ctx  */
+	uint64_t sr;  	/* 1: SR to be restored by sys_load_ctx */
+	uint64_t k0;  	/* 2: K0 to be restored by sys_load_ctx */
+	uint64_t k1;  	/* 3: K1 to be restored by sys_load_ctx */
+	uint64_t v0;  	/* 4: V0 is used to make syscall, so restore it in sys_load_ctx */
+
+	/* Registers to be restored by the VDK_SYS_ctx_load fast system call */
+
+	uint64_t     asid;		/* 5 - Emulated ASID */
+	uint64_t     vmmu_handle;    /* 6 - vmmuHandle */
+
+	uint64_t reserved[8];      
+};
+
+/*
+ * vb_arch_stat_regs - Virtual core MIPS64 emulated status registers
+ *
+ * Virtual board emulated CPU status registers
+ *
+ * MIPS64 Status structure graphical illustration
+ *
+ */
+
+struct vb_arch_stat_regs
+{
+
+	/* 
+	 * registers saved by Hypervisor for all interrupts exceptions
+	 * before setting the PC in the virtual board to the exception/interrupt
+	 * vector address
+	 */
+
+	uint64_t epc; 	/* 0: PC at time of the interrupt */
+	uint64_t sr;  	/* 1: SR at time of the interrupt */
+	uint64_t cause;	/* 2: cause registers at time of the interrupt */
+	uint64_t ra;	/* 3: Return Address at time of the interrupt */
+	uint64_t k0;	/* 4: K0 at time of the interrupt */
+	uint64_t k1;	/* 5: R1 at time of the interrupt */
+	uint64_t ciu_sum;	/* 6: CIU Interrupt Summary at time of the interrupt */
+	uint64_t v0;	/* 7: V0 at time of the interrupt */
+	uint64_t badva;	/* 8: badva at time of the interrupt */
+	uint64_t asid;	/* 9: badva at time of the interrupt */
+	uint64_t vmmu_handle;/* 10: badva at time of the interrupt */
+}; 
+
+/*
+ * VB_HREG_SET - hardware register set, for read/write
+ *
+ * Used by vbi_vb_read_reg/vbivb_write_reg to read/write registers in 
+ * another VB
+ */
+
+typedef struct		/* REG_SET - MIPS architecture register set */
+{
+	uint64_t sr;			/* process status register */
+	uint64_t *pc;			/* program counter - really epc! */
+	uint64_t lo;			/* divide lo register */
+	uint64_t hi;			/* divide hi register */
+	uint64_t gpreg[32];		/* data registers */
+
+	/* cause & fpcsr are only set for wdb traps, from ESFMIPS */
+
+	uint64_t cause;                /* cause reg for branch bit in getNpc() */
+	uint64_t fpcsr;                /* fp cause reg for getNpc() */
+
+	uint64_t intCtrl;              /* extended interrupt control */
+	uint64_t _ULextra1;            /* extra */
+	uint64_t tlbhi;				/* current address space storage */
+	uint64_t intDisable;           /* intDisable */
+	uint64_t _RTextra3;           /* extra */
+	uint64_t _RTextra4;           /* extra */
+	uint64_t _RTextra5;           /* extra */
+	uint64_t _RTextra6;           /* extra */
+	uint64_t _RTextra7;           /* extra */
+	uint64_t _RTextra8;           /* extra */
+	uint64_t _RTextra9;           /* extra */
+	uint64_t _RTextra10;          /* extra */
+ 
+	uint64_t badvaddr;			/* c0_badvaddr */
+} VBI_HREG_SET;
+
+
+/* complex register set definition */
+
+/* it is always 64-bit in mips64 */
+
+typedef union
+{
+	VBI_HREG_SET    hreg32;	/* 64 bit register set */
+	VBI_HREG_SET    hreg64;     /* 64 bit register set */
+} VBI_HREG_SET_CMPLX;
+
+typedef struct
+{
+	uint32_t vbiRegType;
+	VBI_HREG_SET_CMPLX vbiRegSet;
+} VBI_HREG_SET_CMPLX_QUALIFIED;
+
+/* mdio messages */
+#define MDIO_READ               1
+#define MDIO_WRITE              2
+#define MDIO_INT_ENABLE         3
+#define MDIO_INT_DISABLE        4
+#define BSP_CLK_FREQ            5
+#define BSP_CORE_FREQ           6
+
+/* mdio messages */
+#define VBI_MDIO_READ           MDIO_READ
+#define VBI_MDIO_WRITE          MDIO_WRITE
+#define VBI_BSP_CLK_FREQ        BSP_CLK_FREQ
+#define VBI_BSP_CORE_FREQ       BSP_CORE_FREQ
+
+/* common system wide message header structure */
+
+typedef struct vbi_msg_header {
+	uint32_t msg_id; /* message type identification */
+	uint32_t msg_arg;        /* argument associated with message type */
+} VBI_MSG_HEADER;
+/* common system wide message header structure */
+
+/* request message */
+
+typedef struct
+{
+	VBI_MSG_HEADER hdr;                     /* message header */
+	uint32_t   request;                     /* request type */
+
+	union
+	{
+		struct
+		{
+			uint32_t bus;
+			uint32_t phyAddr;
+			uint32_t regNum;
+			uint32_t page;
+		} mdioRead;
+		struct
+		{
+			uint32_t bus;
+			uint32_t phyAddr;
+			uint32_t regNum;
+			uint32_t page;
+			uint32_t dataVal;
+		} mdioWrite;
+#if 0 /* not supported for now */
+		struct
+		{
+			uint32_t bus;
+			uint32_t vbIntNum;
+			HY_CTX *pCtx;
+		} mdioIntEnable;
+		struct
+		{
+			uint32_t bus;
+			uint32_t vbIntNum;
+			HY_CTX *pCtx;
+		} mdioIntDisable;
+#endif
+	} arg;
+} VBI_BSP_MSG;
+
+typedef struct
+{
+	VBI_MSG_HEADER hdr;                     /* message header */
+	uint32_t   status;                      /* request completion status */
+	uint32_t   dataVal;
+} VBI_BSP_MSG_REPLY;
+
+#endif /* _ASMLANGUAGE */
+
+#endif /* _ASM_ARCH_VBI_H */
diff --git a/arch/mips/include/asm/reg_vbi.h b/arch/mips/include/asm/reg_vbi.h
new file mode 100755
index 0000000..bd22e40
--- /dev/null
+++ b/arch/mips/include/asm/reg_vbi.h
@@ -0,0 +1,236 @@
+/*
+ *  MIPS64 reg_vbi.h - MIPS64 cpu registers
+ *
+ * Copyright (c) 2010 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ */
+
+#ifndef __INCregsMipsh
+#define __INCregsMipsh
+
+/* register type size has to be 8, because hypervisor always uses 8 */
+
+#define SIZEOF_RTYPE 8
+
+#ifndef	_ASMLANGUAGE
+
+typedef struct		/* REG_SET - MIPS architecture register set */
+    {
+    ULONG sr;			/* process status register */
+    INSTR *pc;			/* program counter - really epc! */
+    _RType lo;			/* divide lo register */
+    _RType hi;			/* divide hi register */
+    _RType gpreg[32];		/* data registers */
+
+    /* cause & fpcsr are only set for wdb traps, from ESFMIPS */
+
+    ULONG cause;                /* cause reg for branch bit in getNpc() */
+    ULONG fpcsr;                /* fp cause reg for getNpc() */
+
+    ULONG intCtrl;              /* extended interrupt control */
+    ULONG _ULextra1;            /* extra */
+    _RType tlbhi;		/* current address space storage */
+    _RType intDisable;          /* intDisable */
+    _RType _RTextra3;           /* extra */
+    _RType _RTextra4;           /* extra */
+    _RType _RTextra5;           /* extra */
+    _RType _RTextra6;           /* extra */
+    _RType _RTextra7;           /* extra */
+    _RType _RTextra8;           /* extra */
+    _RType _RTextra9;           /* extra */
+    _RType _RTextra10;          /* extra */
+    _RType c0_context;          /* coprocessor0 context, ptebase */
+    _RType badvaddr;		/* c0_badvaddr */
+    } HREG_SET;
+
+#ifdef CONFIG_CPU_CAVIUM_OCTEON 
+    /* use "extra" registers for the multiplier context */
+#define regP0	_RTextra3
+#define regP1	_RTextra4
+#define regP2	_RTextra5
+#define regMPL0	_RTextra6
+#define regMPL1	_RTextra7
+#define regMPL2	_RTextra8
+#define regTlo	_RTextra9
+#define regThi	_RTextra10
+#endif /* CONFIG_CPU_CAVIUM_OCTEON */
+
+/* Used to describe the register state of a cpu. May ultimately be
+ * replaced by using REG_SET directly if no other elements are needed */
+
+typedef struct wind_cpu_state
+    {
+    HREG_SET	regs;
+    } WIND_CPU_STATE;
+
+/* some common names for registers */
+#define zeroReg		gpreg[0]	/* wired zero */
+#define atReg		gpreg[1]	/* assembler temp */
+#define v0Reg		gpreg[2]	/* function return 0 */
+#define v1Reg		gpreg[3]	/* function return 1 */
+#define a0Reg		gpreg[4]	/* parameter 0 */
+#define a1Reg		gpreg[5]	/* parameter 1 */
+#define a2Reg		gpreg[6]	/* parameter 2 */
+#define a3Reg		gpreg[7]	/* parameter 3 */
+#define t0Reg		gpreg[8]	/* caller saved 0 */
+#define t1Reg		gpreg[9]	/* caller saved 1 */
+#define t2Reg		gpreg[10]	/* caller saved 2 */
+#define t3Reg		gpreg[11]	/* caller saved 3 */
+#define t4Reg		gpreg[12]	/* caller saved 4 */
+#define t5Reg		gpreg[13]	/* caller saved 5 */
+#define t6Reg		gpreg[14]	/* caller saved 6 */
+#define t7Reg		gpreg[15]	/* caller saved 7 */
+#define s0Reg		gpreg[16]	/* callee saved 0 */
+#define s1Reg		gpreg[17]	/* callee saved 1 */
+#define s2Reg		gpreg[18]	/* callee saved 2 */
+#define s3Reg		gpreg[19]	/* callee saved 3 */
+#define s4Reg		gpreg[20]	/* callee saved 4 */
+#define s5Reg		gpreg[21]	/* callee saved 5 */
+#define s6Reg		gpreg[22]	/* callee saved 6 */
+#define s7Reg		gpreg[23]	/* callee saved 7 */
+#define t8Reg		gpreg[24]	/* caller saved 8 */
+#define t9Reg		gpreg[25]	/* caller saved 8 */
+#define k0Reg		gpreg[26]	/* kernal reserved 0 */
+#define k1Reg		gpreg[27]	/* kernal reserved 1 */
+#define gpReg		gpreg[28]	/* global pointer */
+#define spReg		gpreg[29]	/* stack pointer */
+#define s8Reg		gpreg[30]	/* callee saved 8 */
+#define fpReg           s8Reg           /* gcc says this is frame pointer */
+#define raReg		gpreg[31]	/* return address */
+#define reg_pc		pc		/* program counter */
+#define reg_sp		spReg		/* stack pointer */
+#define reg_fp		fpReg		/* frame pointer */	
+
+#define SR_OFFSET	(0*SIZEOF_RTYPE)	/* sr register offset */
+#define PC_OFFSET	(1*SIZEOF_RTYPE)	/* pc register offset */
+
+#endif	/* _ASMLANGUAGE */
+
+#define _RTypeSize 8
+
+#if (_WRS_INT_REGISTER_SIZE == 4)
+#define N32_REG_OFFSET 0
+#else
+#define N32_REG_OFFSET 0
+#endif
+
+#define GREG_BASE	((2*SIZEOF_RTYPE+2*_RTypeSize) + N32_REG_OFFSET)
+#define GREG_OFFSET(n)  (GREG_BASE + (n)*_RTypeSize)
+
+#define	SRREG		((0*SIZEOF_RTYPE) + N32_REG_OFFSET)		/* process status register */
+#define PCREG		((1*SIZEOF_RTYPE) + N32_REG_OFFSET)		/* program counter */
+#define	LOREG		((2*SIZEOF_RTYPE+0*_RTypeSize) + N32_REG_OFFSET)	/* lo register */
+#define	HIREG		((2*SIZEOF_RTYPE+1*_RTypeSize) + N32_REG_OFFSET)	/* hi register */
+#define ZEROREG		GREG_OFFSET(0)		/* wired zero */
+#define ATREG		GREG_OFFSET(1)		/* assembler temp */
+#define V0REG		GREG_OFFSET(2)		/* function return 0 */
+#define V1REG		GREG_OFFSET(3)		/* function return 1 */
+#define A0REG		GREG_OFFSET(4)		/* parameter 0 */
+#define A1REG		GREG_OFFSET(5)		/* parameter 1 */
+#define A2REG		GREG_OFFSET(6)		/* parameter 2 */
+#define A3REG		GREG_OFFSET(7)		/* parameter 3 */
+#define T0REG		GREG_OFFSET(8)		/* caller saved 0 */
+#define T1REG		GREG_OFFSET(9)		/* caller saved 1 */
+#define T2REG		GREG_OFFSET(10)		/* caller saved 2 */
+#define T3REG		GREG_OFFSET(11)		/* caller saved 3 */
+#define T4REG		GREG_OFFSET(12)		/* caller saved 4 */
+#define T5REG		GREG_OFFSET(13)		/* caller saved 5 */
+#define T6REG		GREG_OFFSET(14)		/* caller saved 6 */
+#define T7REG		GREG_OFFSET(15)		/* caller saved 7 */
+#define S0REG		GREG_OFFSET(16)		/* callee saved 0 */
+#define S1REG		GREG_OFFSET(17)		/* callee saved 1 */
+#define S2REG		GREG_OFFSET(18)		/* callee saved 2 */
+#define S3REG		GREG_OFFSET(19)		/* callee saved 3 */
+#define S4REG		GREG_OFFSET(20)		/* callee saved 4 */
+#define S5REG		GREG_OFFSET(21)		/* callee saved 5 */
+#define S6REG		GREG_OFFSET(22)		/* callee saved 6 */
+#define S7REG		GREG_OFFSET(23)		/* callee saved 7 */
+#define T8REG		GREG_OFFSET(24)		/* caller saved 8 */
+#define T9REG		GREG_OFFSET(25)		/* caller saved 8 */
+#define K0REG		GREG_OFFSET(26)		/* kernal reserved 0 */
+#define K1REG		GREG_OFFSET(27)		/* kernal reserved 1 */
+#define GPREG		GREG_OFFSET(28)		/* global pointer */
+#define SPREG		GREG_OFFSET(29)		/* stack pointer */
+#define S8REG		GREG_OFFSET(30)		/* callee saved 8 */
+#define RAREG		GREG_OFFSET(31)		/* return address */
+#define GREG_END        (GREG_BASE+32*_RTypeSize)
+
+#define CAUSEREG	(GREG_END+0*SIZEOF_RTYPE)          /* Cause reg (for wdb) */
+#define FPCSRREG	(GREG_END+1*SIZEOF_RTYPE)          /* FPCSR reg (for wdb) */
+#define INTCTRLREG	(GREG_END+2*SIZEOF_RTYPE)          /* ext intr control reg */
+#define ULEXTRA1	(GREG_END+3*SIZEOF_RTYPE)          /* extra - 4 bytes pad */
+#define TLBHIREG	(GREG_END+4*SIZEOF_RTYPE+0*_RTypeSize) /* adrs spc id reg */
+#define RTEXTRA2	(GREG_END+4*SIZEOF_RTYPE+1*_RTypeSize) /* extra */
+#define INT_DISABLE	RTEXTRA2
+#define RTEXTRA3	(GREG_END+4*SIZEOF_RTYPE+2*_RTypeSize) /* extra */
+#define RTEXTRA4	(GREG_END+4*SIZEOF_RTYPE+3*_RTypeSize) /* extra */
+#define RTEXTRA5	(GREG_END+4*SIZEOF_RTYPE+4*_RTypeSize) /* extra */
+#define RTEXTRA6	(GREG_END+4*SIZEOF_RTYPE+5*_RTypeSize) /* extra */
+#define RTEXTRA7	(GREG_END+4*SIZEOF_RTYPE+6*_RTypeSize) /* extra */
+#define RTEXTRA8	(GREG_END+4*SIZEOF_RTYPE+7*_RTypeSize) /* extra */
+#define RTEXTRA9	(GREG_END+4*SIZEOF_RTYPE+8*_RTypeSize) /* extra */
+#define RTEXTRA10	(GREG_END+4*SIZEOF_RTYPE+9*_RTypeSize) /* extra */
+#define C0CONTEXT	(GREG_END+4*SIZEOF_RTYPE+10*_RTypeSize)
+#define BADVADDR	(GREG_END+4*SIZEOF_RTYPE+11*_RTypeSize)
+
+
+#ifdef CONFIG_CPU_CAVIUM_OCTEON 
+#define P0REG		RTEXTRA3
+#define P1REG		RTEXTRA4
+#define P2REG		RTEXTRA5
+#define MPL0REG		RTEXTRA6
+#define MPL1REG		RTEXTRA7
+#define MPL2REG		RTEXTRA8
+#define TLOREG		RTEXTRA9
+#define THIREG		RTEXTRA10
+#endif /* CONFIG_CPU_CAVIUM_OCTEON */
+
+#define REG_SET_SIZE	(GREG_END+4*SIZEOF_RTYPE+12*_RTypeSize)
+
+#define	HREG_REGS	(0 + N32_REG_OFFSET)
+#define HREG_GREG_BASE	(HREG_REGS+2*SIZEOF_RTYPE+2*_RTypeSize)
+#define HREG_GREG_OFFSET(n) (HREG_GREG_BASE + (n)*_RTypeSize)
+#define	HREG_SR 		(HREG_REGS + 0*SIZEOF_RTYPE)
+#define	HREG_PC 		(HREG_REGS + 1*SIZEOF_RTYPE)
+#define	HREG_LO		(HREG_REGS + 2*SIZEOF_RTYPE+0*_RTypeSize)
+#define	HREG_HI		(HREG_REGS + 2*SIZEOF_RTYPE+1*_RTypeSize)
+#define	HREG_ZERO		HREG_GREG_OFFSET(0)
+#define HREG_GREG_END	(HREG_GREG_BASE+32*_RTypeSize)
+#define HREG_WDB_CAUSE      (HREG_GREG_END + 0*SIZEOF_RTYPE)
+#define HREG_WDB_FPCSR      (HREG_GREG_END + 1*SIZEOF_RTYPE)
+#define HREG_INTCTRL        (HREG_GREG_END + 2*SIZEOF_RTYPE)
+#define HREG_EXTRA1         (HREG_GREG_END + 3*SIZEOF_RTYPE)
+#define HREG_TLBHI          (HREG_GREG_END + 4*SIZEOF_RTYPE + 0*_RTypeSize)
+#define HREG_EXTRA2         (HREG_GREG_END + 4*SIZEOF_RTYPE + 1*_RTypeSize)
+#define HREG_INTDISABLE     HREG_EXTRA2
+#define HREG_EXTRA3         (HREG_GREG_END + 4*SIZEOF_RTYPE + 2*_RTypeSize)
+#define HREG_EXTRA4         (HREG_GREG_END + 4*SIZEOF_RTYPE + 3*_RTypeSize)
+#define HREG_EXTRA5         (HREG_GREG_END + 4*SIZEOF_RTYPE + 4*_RTypeSize)
+#define HREG_EXTRA6         (HREG_GREG_END + 4*SIZEOF_RTYPE + 5*_RTypeSize)
+#define HREG_EXTRA7         (HREG_GREG_END + 4*SIZEOF_RTYPE + 6*_RTypeSize)
+#define HREG_EXTRA8         (HREG_GREG_END + 4*SIZEOF_RTYPE + 7*_RTypeSize)
+#define HREG_EXTRA9         (HREG_GREG_END + 4*SIZEOF_RTYPE + 8*_RTypeSize)
+#define HREG_EXTRA10        (HREG_GREG_END + 4*SIZEOF_RTYPE + 9*_RTypeSize)
+#define HREG_C0_CONTEXT     (HREG_GREG_END + 4*SIZEOF_RTYPE + 10*_RTypeSize)
+
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+#define HREG_P0		HREG_EXTRA3
+#define HREG_P1		HREG_EXTRA4
+#define HREG_P2		HREG_EXTRA5
+#define HREG_MPL0		HREG_EXTRA6
+#define HREG_MPL1		HREG_EXTRA7
+#define HREG_MPL2		HREG_EXTRA8
+#define HREG_TLO		HREG_EXTRA9
+#define HREG_THI		HREG_EXTRA10
+#endif /* CONFIG_CPU_CAVIUM_OCTEON */
+
+#endif /* __INCregsMipsh */
diff --git a/arch/mips/include/asm/vbi.h b/arch/mips/include/asm/vbi.h
new file mode 100755
index 0000000..8c0e1c4
--- /dev/null
+++ b/arch/mips/include/asm/vbi.h
@@ -0,0 +1,618 @@
+/*
+ * asm/vbi.h - MIPS64 tool dependent headers
+ *
+ * Copyright 2011 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ */
+#ifndef __INCsysMips64Asmh
+#define __INCsysMips64Asmh
+
+#ifndef SOFT_FLOAT
+#define SOFT_FLOAT
+#endif
+
+#ifndef _WRS_NO_BITS_PHYS_ADDR
+#define _WRS_NO_BITS_PHYS_ADDR	(32)
+#endif
+
+#ifndef _WRS_INT_REGISTER_SIZE
+#define _WRS_INT_REGISTER_SIZE  8
+#endif
+
+#ifndef _WRS_FP_REGISTER_SIZE
+#define _WRS_FP_REGISTER_SIZE  8
+#endif
+
+#define HIADJ(arg)	arg@ha
+#define HI(arg)		arg@h
+#define LO(arg)		arg@l
+
+/*
+ * The LEADING_UNDERSCORE macro should be defined to TRUE for toolchains
+ * that do NOT prefix a leading underscore character, i.e. "_", to
+ * symbols.  Define the macro to FALSE when using a toolchain that
+ * does add a leading underscore character to symbols.
+ */
+
+#define LEADING_UNDERSCORE	0 
+
+#if (LEADING_UNDERSCORE == 1)
+#define FUNC(func)          _##func
+#define FUNC_LABEL(func)    _##func:
+#else
+#define FUNC(func)          func
+#define FUNC_LABEL(func)    func:
+#endif
+
+#define FUNC_DECL(range,func)
+#define VAR_DECL(var)   var
+#define VAR(var)        var(r0)
+
+/*
+ * These macros are used to declare assembly language symbols that need
+ * to be typed properly(func or data) to be visible to the OMF tool.  
+ * So that the build tool could mark them as an entry point to be linked
+ * by another PD.
+ */
+
+#define GTEXT(sym) FUNC(sym) ;  .type   FUNC(sym),@function
+#define GDATA(sym) FUNC(sym) ;  .type   FUNC(sym),@object
+
+#define FUNCREF(func)	func
+
+
+/*
+ * These macros are used to declare assembly language symbols that need
+ * to be typed properly(func or data) to be visible to the OMF tool.  
+ * So that the build tool could mark them as an entry point to be linked
+ * by another PD.
+ */
+
+/* Introduced to abstract assembler idiosyncrasies */
+
+#define	FUNC_EXPORT(func)	.globl	GTEXT(func)
+#define	DATA_EXPORT(var)	.globl	GDATA(var)
+#define	FUNC_IMPORT(func)	.extern	FUNC(func)
+#define	DATA_IMPORT(var)	.extern	VAR_DECL(var)
+#define	FUNC_BEGIN(func)	FUNC_LABEL(func)
+#define	FUNC_END(func)		.size	FUNC(func), . - FUNC(func)
+
+
+/*
+*  MIPS register definitions
+*/
+
+#define zero	$0	/* wired zero */
+#define AT	$at	/* assembler temp */
+#define v0	$2	/* return reg 0 */
+#define v1	$3	/* return reg 1 */
+#define a0	$4	/* arg reg 0 */
+#define a1	$5	/* arg reg 1 */
+#define a2	$6	/* arg reg 2 */
+#define a3	$7	/* arg reg 3 */
+#define t0	$8	/* caller saved 0 */
+#define t1	$9	/* caller saved 1 */
+#define t2	$10	/* caller saved 2 */
+#define t3	$11	/* caller saved 3 */
+#define t4	$12	/* caller saved 4 */
+#define t5	$13	/* caller saved 5 */
+#define t6	$14	/* caller saved 6 */
+#define t7	$15	/* caller saved 7 */
+#define s0	$16	/* callee saved 0 */
+#define s1	$17	/* callee saved 1 */
+#define s2	$18	/* callee saved 2 */
+#define s3	$19	/* callee saved 3 */
+#define s4	$20	/* callee saved 4 */
+#define s5	$21	/* callee saved 5 */
+#define s6	$22	/* callee saved 6 */
+#define s7	$23	/* callee saved 7 */
+#define t8	$24	/* caller saved 8 */
+#define t9	$25	/* caller saved 9 */
+#define k0	$26	/* kernel temp 0 */
+#define k1	$27	/* kernel temp 1 */
+#define gp	$28	/* global pointer */
+#define sp	$29	/* stack pointer */
+#define s8	$30	/* callee saved 8 */
+#define ra	$31	/* return address */
+
+
+#if defined(_WRS_MIPS_N32_ABI) || defined(LP64) /* N64 */
+
+#define a4	$8	/* arg register 4 (== t0 in OABI) */
+#define a5	$9	/* arg register 5 (== t1 in OABI)*/
+#define a6	$10	/* arg register 6 (== t2 in OABI) */
+#define a7	$11	/* arg register 7 (== t3 in OABI) */
+
+#endif /* _wRS_MIPS_N32_ABI */
+
+/*
+* MIPS Coprocessor 0 regs
+*/
+#define C0_IBASE	$0	/* R4650: instruction base xlate address */
+#define C0_IBOUND	$1	/* R4650: instruction xlate address bound */
+#define C0_DBASE	$2	/* R4650: data base xlate address */
+#define C0_DBOUND	$3	/* R4650: data xlate address bound */
+#define	C0_INX		$0	/* tlb index */
+#define	C0_RAND		$1	/* tlb random */
+
+/* Begin CPUs: R3000, CW4000, CW4011 */
+#define	C0_TLBLO	$2	/* tlb entry low */
+/* End R3000, CW4000, CW4011 */
+
+/* Begin CPUs: R4000, VR5000, VR5400, VR4100 */
+#define C0_TLBLO0	$2	/* tlb entry low 0 */
+#define C0_TLBLO1	$3	/* tlb entry low 1 */
+/* End R4000, VR5000, VR5400, VR4100 */
+
+#define	C0_CTXT		$4	/* tlb context */
+
+/* Begin CPUs: R4000, VR5000, VR5400, VR4100 */
+#define C0_PAGEMASK	$5	/* page mask */
+#define C0_WIRED	$6	/* lb wired entries */
+/* End R4000, VR5000, VR5400, VR4100 */
+
+#define	C0_BADVADDR	$8		/* bad virtual address */
+
+/* Begin CPUs: R4000, R4650, VR5000, VR5400, CW4011, VR4100 */
+#define	C0_COUNT	$9	/* count */
+/* End R4000, R4650, VR5000, VR5400, CW4011, VR4100 */
+#ifdef CONFIG_CPU_CAVIUM_OCTEON 
+#define C0_CVMCOUNT	$9,6
+#define C0_CAVCNTL	$9,7
+#endif /* CONFIG_CPU_CAVIUM_OCTEON */
+
+/* Begin CPUs: R4000, VR5000, VR5400, R3000, CW4000, CW4011, VR4100 */
+#define	C0_TLBHI	$10	/* tlb entry hi */
+/* End R4000, VR5000, VR5400, R3000, CW4000, CW4011, VR4100 */
+
+/* Begin CPUs: R4000, VR5000, VR5400, R4650, CW4011, VR4100 */
+#define	C0_COMPARE	$11	/* compare */
+/* End R4000, VR5000, VR5400, R4650, CW4011, VR4100*/
+
+#define	C0_SR		$12	/* status register */
+#define	C0_CAUSE	$13	/* exception cause */
+#define	C0_EPC		$14	/* exception pc */
+
+#define C0_PRID		$15
+
+/* Begin CPUs: R4000, R4650, VR5000, VR5400, VR4100, CW4011 */
+#define C0_CONFIG	$16
+
+#define C0_CALG		$17	/* R4650: cache algorithm register */
+#define C0_LLADDR	$17
+
+#define C0_IWATCH	$18	/* R4650: instruction virt addr for watch */
+#define C0_WATCHLO	$18
+
+#define C0_DWATCH	$19	/* R4650: data virt addr for watch */
+#define C0_WATCHHI	$19
+
+#define C0_ECC		$26
+#define C0_CACHEERR	$27
+#define C0_TAGLO	$28
+
+/* Begin CPUs: R4000, VR5000, VR5400, VR4100 */
+#define C0_TAGHI	$29
+/* End R4000, VR5000, VR5400, VR4100 */
+
+#define C0_ERRPC	$30
+/* End R4000, R4650, VR5000, VR5400, VR4100, CW4011 */
+
+/*
+*  MIPS floating point coprocessor register definitions
+*/
+
+#define fp0	$f0	/* return reg 0 */
+#define fp1	$f1	/* return reg 1 */
+#define fp2	$f2	/* return reg 2 */
+#define fp3	$f3	/* return reg 3 */
+#define fp4	$f4	/* caller saved 0 */
+#define fp5	$f5	/* caller saved 1 */
+#define fp6	$f6	/* caller saved 2 */
+#define fp7	$f7	/* caller saved 3 */
+#define fp8	$f8	/* caller saved 4 */
+#define fp9	$f9	/* caller saved 5 */
+#define fp10	$f10	/* caller saved 6 */
+#define fp11	$f11	/* caller saved 7 */
+#define fp12	$f12	/* arg reg 0 */
+#define fp13	$f13	/* arg reg 1 */
+#define fp14	$f14	/* arg reg 2 */
+#define fp15	$f15	/* arg reg 3 */
+#define fp16	$f16	/* caller saved 8 */
+#define fp17	$f17	/* caller saved 9 */
+#define fp18	$f18	/* caller saved 10 */
+#define fp19	$f19	/* caller saved 11 */
+#define fp20	$f20	/* callee saved 0 */
+#define fp21	$f21	/* callee saved 1 */
+#define fp22	$f22	/* callee saved 2 */
+#define fp23	$f23	/* callee saved 3 */
+#define fp24	$f24	/* callee saved 4 */
+#define fp25	$f25	/* callee saved 5 */
+#define fp26	$f26	/* callee saved 6 */
+#define fp27	$f27	/* callee saved 7 */
+#define fp28	$f28	/* callee saved 8 */
+#define fp29	$f29	/* callee saved 9 */
+#define fp30	$f30	/* callee saved 10 */
+#define fp31	$f31	/* callee saved 11 */
+
+#define C1_IR $0	/* implementation/revision reg */
+#define C1_SR $31	/* control/status reg */
+
+/*
+* define aliases for operations that are different in 64bit mode
+*/
+#if (_WRS_INT_REGISTER_SIZE == 4)
+#define SW	sw
+#define LW	lw
+#define MFC0	mfc0
+#define MTC0	mtc0
+#define LI	li
+#define LA	la
+#elif (_WRS_INT_REGISTER_SIZE == 8)
+#define SW	sd		/* storing machine registers */
+#define LW	ld		/* loading machine registers */
+#define MFC0	dmfc0		/* reading wide cop0 register */
+#define MTC0	dmtc0		/* writing wide cop0 register */
+#define LI	dli
+#define LA	dla
+#else	/* _WRS_INT_REGISTER_SIZE */
+#error "invalid _WRS_INT_REGISTER_SIZE value"
+#endif	/* _WRS_INT_REGISTER_SIZE */
+
+/* #define _RTypeSize _WRS_INT_REGISTER_SIZE*/
+#define _RTypeSize 8
+
+#if (_WRS_FP_REGISTER_SIZE == 4)
+#define SWC1	swc1
+#define LWC1	lwc1
+#define MFC1	mfc1
+#define MTC1	mtc1
+#elif (_WRS_FP_REGISTER_SIZE == 8)
+#define SWC1	sdc1
+#define LWC1	ldc1
+#define MFC1	dmfc1		/* reading wide fp register */
+#define MTC1	dmtc1		/* writing wide fp register */
+#else /* _WRS_FP_REGISTER_SIZE */
+#error "invalid _WRS_FP_REGISTER_SIZE value"
+#endif /* _WRS_FP_REGISTER_SIZE */
+
+/* Hazard definitions */
+
+/* A MIPS Hazard is defined as any combination of instructions which
+ * would cause unpredictable behavior in terms of pipeline delays,
+ * cache misses, and exceptions.  Hazards are defined by the number
+ * of CPU cycles that must pass between certain combinations of
+ * instructions.  Because some MIPS CPUs single-issue nop instructions
+ * while others dual-issue, the CPU cycles defined below are done so
+ * according to the instruction issue mechanism available.
+ */
+#define SINGLE_ISSUE 0 	
+#define DUAL_ISSUE   1 
+#define CPU_CYCLES              DUAL_ISSUE
+
+/* Using the issue mechanism definitions above, the MIPS CPU cycles
+ * are defined below.
+ */
+
+#define	ssnop		.word 0x00000040
+
+#if (CPU_CYCLES == SINGLE_ISSUE)
+#define CPU_CYCLES_ONE          ssnop
+#define CPU_CYCLES_TWO          ssnop; ssnop
+#elif (CPU_CYCLES == DUAL_ISSUE)
+#define CPU_CYCLES_ONE          ssnop; ssnop
+#define CPU_CYCLES_TWO          ssnop; ssnop; ssnop; ssnop
+#endif
+
+/* Sixteen instructions are required to handle the VR5432 errata in
+ * order to fill its instruction prefetch.  See HAZARD_VR5400 macro
+ * for details.
+ */
+#define CPU_CYCLES_SIXTEEN      ssnop; ssnop; ssnop; ssnop; \
+                                ssnop; ssnop; ssnop; ssnop; \
+                                ssnop; ssnop; ssnop; ssnop; \
+                                ssnop; ssnop; ssnop; ssnop				    
+
+/* To assist with handling MIPS hazards, a number of categories of
+ * hazards have been defined here.  
+ *
+ * HAZARD_TLB        After modifying tlb CP0 registers, do not use the
+ *                   TLB for two CPU cycles.
+ * HAZARD_ERET       After modifying the SR, do not return from an
+ *                   exception for two CPU cycles.
+ * HAZARD_INTERRUPT  After modifying the SR, interrupts do not lock
+ *                   for two CPU cycles.
+ * HAZARD_CP_READ    After a read from a Coprocessor register, the
+ *                   result is not available for one CPU cycle.
+ * HAZARD_CP_WRITE   After a write to a Coprocessor register, the
+ *                   result is not effective for two CPU cycles.
+ * HAZARD_CACHE_TAG  Cache TAG load and store instructions should
+ *                   not be used withing one CPU cycle of modifying
+ *                   the TAG registers.
+ * HAZARD_CACHE      Cache instructions should not be used within 2
+ *                   CPU cycles of each other.
+ * HAZARD_VR5400     For the VR5432 CPU only.  Serialized instructions
+ *                   (mtc0, ctc0, mfc0, cfc0, etc) must not appear within
+ *                   16 instructions after a conditional branch or label.
+ *
+ * These hazard macros are intended for use with MIPS architecture-
+ * dependent assembly files which require handling hazards.  For example,
+ * suppose interrupts are being locked, to address the hazard, please
+ * do the following:
+ *
+ * mtc0     t0, C0_SR
+ * HAZARD_INTERRUPT
+ * lw       t0, 0(a0)
+ *
+ * Similarly, when reading from a coprocessor register, please do the
+ * following:
+ *
+ * mfc0     t0, C0_SR
+ * HAZARD_CP_READ
+ * and      t0, t0, t1
+ * mtc0     t0, C0_SR
+ * HAZARD_CP_WRITE
+ *
+ *
+ * For more details on these categories, please refer to MIPS hazard
+ * documentation.
+ */
+
+/* Hazard macros */
+/* If this arch requires non-standard Hazard defs, include the hazard file
+ * defined for this arch.  Otherwise, use the defaults.
+ */
+
+#define HAZARD_STRINGIFY(x)	#x
+#define HAZARD_HDR(file)	HAZARD_STRINGIFY(arch/mips/file)
+#define HAZARD_INCLUDE(file)	HAZARD_HDR(HAZARD_FILE)
+
+#ifdef HAZARD_FILE
+#include HAZARD_INCLUDE(file)
+#else
+#ifdef _WRS_MIPS_FULL_HW_INTERLOCK
+#define HAZARD_TLB
+#define HAZARD_ERET
+#define HAZARD_CP_READ
+#define HAZARD_CP_WRITE
+#define HAZARD_CACHE_TAG
+/* The following is a do-nothing that results in no binary code. It is a 
+ * placeholder req'd for proper macro expansion in cacheMipsALib.s 
+ */
+#define HAZARD_CACHE     . = .
+#define HAZARD_INTERRUPT
+#else
+#define HAZARD_TLB       CPU_CYCLES_TWO
+#define HAZARD_ERET      CPU_CYCLES_TWO
+#define HAZARD_CP_READ   CPU_CYCLES_ONE
+#define HAZARD_CP_WRITE  CPU_CYCLES_TWO
+#define HAZARD_CACHE_TAG CPU_CYCLES_ONE
+#define HAZARD_CACHE     CPU_CYCLES_TWO
+#define HAZARD_INTERRUPT CPU_CYCLES_TWO
+#endif  /* _WRS_MIPS_FULL_HW_INTERLOCK */
+#endif  /*  HAZARD_FILE */
+
+#ifdef _WRS_MIPS_VR5400_ERRATA
+#define HAZARD_VR5400    CPU_CYCLES_SIXTEEN
+#else
+#define HAZARD_VR5400
+#endif
+
+#ifdef CONFIG_CPU_CAVIUM_OCTEON 
+/* Macros to generate instructions */
+
+/* must use register numbers here, not names or with $ prefix. */
+/* defines for register numbers */
+
+#define ZERO	0	/* zero register */
+#define V0	2	/* return reg 0 */
+#define V1	3	/* return reg 1 */
+#define A0	4	/* arg reg 0 */
+#define A1	5	/* arg reg 1 */
+#define A2	6	/* arg reg 2 */
+#define A3	7	/* arg reg 3 */
+#define T0	8	/* caller saved 0 */
+#define T1	9	/* caller saved 1 */
+#define T2	10	/* caller saved 2 */
+#define T3	11	/* caller saved 3 */
+#define T4	12	/* caller saved 4 */
+#define T5	13	/* caller saved 5 */
+#define T6	14	/* caller saved 6 */
+#define T7	15	/* caller saved 7 */
+#define S0	16	/* callee saved 0 */
+#define S1	17	/* callee saved 1 */
+#define S2	18	/* callee saved 2 */
+#define S3	19	/* callee saved 3 */
+#define S4	20	/* callee saved 4 */
+#define S5	21	/* callee saved 5 */
+#define S6	22	/* callee saved 6 */
+#define S7	23	/* callee saved 7 */
+#define T8	24	/* caller saved 8 */
+#define T9	25	/* caller saved 9 */
+
+/* 192-bit * 64-bit Unsigned Multiply and Add: v3mulu */
+#define CAV_V3MULU(rd,rs,rt)	.word	(0x70000011 |	\
+				 ((rd) << 11) | \
+				 ((rs) << 21) | \
+				 ((rt) << 16))
+/* Move to multiplier registers */
+#define CAV_MTM0(rs)		.word	(0x70000008 |	\
+				 ((rs) << 21))
+#define CAV_MTM1(rs)		.word	(0x7000000c |	\
+				 ((rs) << 21))
+#define CAV_MTM2(rs)		.word	(0x7000000d |	\
+				 ((rs) << 21))
+#define CAV_MTP0(rs)		.word	(0x70000009 |	\
+				 ((rs) << 21))
+#define CAV_MTP1(rs)		.word	(0x7000000a |	\
+				 ((rs) << 21))
+#define CAV_MTP2(rs)		.word	(0x7000000b |	\
+				 ((rs) << 21))
+#endif /* CONFIG_CPU_CAVIUM_OCTEON */
+
+/*
+ * Stack frame allocation.
+ * These macros are used in assembly language routines to automate the
+ * allocation and use of stack frames. They create a stack frame that
+ * looks like this:
+ *
+#ifdef _WRS_MIPS_N32_ABI
+ *
+ *	+-------+<---	Original SP (16-byte aligned)
+ *	|  RA   |	Storage for return address (8 bytes for alignment)
+ *	+-------+
+ *	| extra |	Optional additional storage requested by SETFRAME_EXTRA
+ *	+-------+
+ *	| r0-rN |	Storage for up to 4 additional local registers
+ *	+-------+
+ *	| a0-aN |	Storage for up to 8 argument regs
+ *	+-------+<---	Adjusted SP (16-byte aligned)
+ *
+#else /@ _WRS_MIPS_N32_ABI @/
+ *
+ *	+-------+
+ *	| a0-a3 |	Storage provided by ABI contract from calling function
+ *	+-------+<---	Original SP
+ *	|  RA   |	Storage for return address (8 bytes for alignment)
+ *	+-------+
+ *	| extra |	Optional additional storage requested by SETFRAME_EXTRA
+ *	+-------+
+ *	| r0-rN |	Storage for up to 4 additional local registers
+ *	+-------+
+ *	|(a0-a3)|	Storage provided by ABI contract to called function
+ *	+-------+<---   Adjusted SP	
+ *
+#endif /@ _WRS_MIPS_N32_ABI @/
+ *
+ *
+ */
+
+/* Return the size of the frame for the named routine */
+#define FRAMESZ(routine)	_##routine##Fsize
+#ifdef _WRS_MIPS_N32_ABI
+#define FRAMEASZ(routine)	_##routine##ARsize
+#endif
+
+
+#ifdef _WRS_MIPS_N32_ABI
+/*
+ * Calculate the frame size for the named routine
+ * up to 8 register slots allocated for subroutines to store argument registers
+ * 8 bytes are allocated for saving RA (independent of register size).
+ * nregs register locations are reserved for storing locally used registers.
+ * stack is kept 16-byte aligned.
+ */
+#define SETFRAME_EXTRA(routine,naregs,nregs,extra) \
+   FRAMEASZ(routine) = ((_RTypeSize)*(naregs)); \
+   FRAMESZ(routine) = ((((_RTypeSize)*((naregs)+(nregs)))+8+(extra)+15) & ~0x0f)  
+#else /*  _WRS_MIPS_N32_ABI */
+/*
+ * Calculate the frame size for the named routine
+ * 4 register slots allocated for subroutines to store argument registers
+ * 8 bytes are allocated for saving RA (independent of register size).
+ * nregs register locations are reserved for storing locally used registers.
+ * stack is kept 8-byte aligned.
+ */
+#define SETFRAME_EXTRA(routine,naregs,nregs,extra) \
+	FRAMESZ(routine) = ((((_RTypeSize)*(4+(nregs)))+8+(extra)+7) & ~0x07)
+#endif /*  _WRS_MIPS_N32_ABI */
+#define SETFRAME(routine,naregs,nregs) \
+	SETFRAME_EXTRA(routine,naregs,nregs,0)
+
+/* The location at which to store the return address */
+#define FRAMERA(routine) 	(FRAMESZ(routine)-8)
+
+/* Locations at which to store locally used registers */
+
+#ifdef _WRS_MIPS_N32_ABI
+#define FRAMER(routine,regn) 	(FRAMEASZ(routine)+(_RTypeSize)*(regn))
+#else /* _WRS_MIPS_N32_ABI */
+#define FRAMER(routine,regn) 	((_RTypeSize)*(4+(regn)))
+#endif /* _WRS_MIPS_N32_ABI */
+
+#define FRAMER0(routine) FRAMER(routine,0)
+#define FRAMER1(routine) FRAMER(routine,1)
+#define FRAMER2(routine) FRAMER(routine,2)
+#define FRAMER3(routine) FRAMER(routine,3)
+
+/* Locations at which to store argument registers */
+#ifdef _WRS_MIPS_N32_ABI
+#define FRAMEA(routine, regn) (                 (_RTypeSize)*(regn))
+#else
+#define FRAMEA(routine, regn) (FRAMESZ(routine)+(_RTypeSize)*(regn))
+#endif
+#define FRAMEA0(routine) FRAMEA(routine,0)
+#define FRAMEA1(routine) FRAMEA(routine,1)
+#define FRAMEA2(routine) FRAMEA(routine,2)
+#define FRAMEA3(routine) FRAMEA(routine,3)
+#ifdef _WRS_MIPS_N32_ABI
+#define FRAMEA4(routine) FRAMEA(routine,4)
+#define FRAMEA5(routine) FRAMEA(routine,5)
+#define FRAMEA6(routine) FRAMEA(routine,6)
+#define FRAMEA7(routine) FRAMEA(routine,7)
+#endif /* _WRS_MIPS_N32_ABI */
+
+
+/*
+ * _NABI() and _OABI() are used as wrappers for assembly instructions
+ * that should only be emited under the N32 or non-N32 ABI.
+ */
+
+#ifdef _WRS_MIPS_N32_ABI
+#    define _NABI(...)  __VA_ARGS__
+#    define _OABI(...)
+#else
+#    define _NABI(...)
+#    define _OABI(...)  __VA_ARGS__
+#endif
+
+
+/*
+ * razor specific definitions
+ *
+ */
+#define FRAMEBASESZ            16      /* minimum stack frame size */
+
+#ifdef _ASMLANGUAGE
+
+debug_milestone:	.macro
+.Lm\@:
+	dla	$14,.Lm\@
+	.endm
+
+#define SYNCI		.word	0x041f0000
+#define SYNCIOBDMA	.word	0x0000008f
+#define SYNCS		.word	0x0000018f
+#define SYNCW		.word	0x0000010f
+#define DEBUG_MILESTONE debug_milestone
+
+#if 0
+#define AUDIT_STUB_CREATE(x)           	\
+        FUNC_EXPORT(x);            	\
+        FUNC_BEGIN(x);             	\
+        FUNC_END(x);              
+#else
+#define AUDIT_STUB_CREATE(func)         \
+	.globl	func	;		\
+	func:		;             
+#endif
+
+
+#define AUDIT_STUB_VAR(x)              \
+        DATA_EXPORT(x)              \
+        x:
+
+#else	/* _ASMLANGUAGE */
+#define _WRS_ASM(x) __asm volatile (x)	
+#endif
+
+#endif /* __INCsysMips64Asmh */
diff --git a/arch/mips/kernel/Makefile b/arch/mips/kernel/Makefile
index 3bd741a..4d66cef 100644
--- a/arch/mips/kernel/Makefile
+++ b/arch/mips/kernel/Makefile
@@ -102,6 +102,8 @@ obj-$(CONFIG_HAVE_STD_PC_SERIAL_PORT)	+= 8250-platform.o
 
 obj-$(CONFIG_MIPS_CPUFREQ)	+= cpufreq/
 
+obj-$(CONFIG_WRHV)		+= vbi/
+
 EXTRA_CFLAGS += -Werror
 
 obj-$(CONFIG_HW_PERF_EVENTS)	+= perf_event.o
diff --git a/arch/mips/kernel/vbi/Makefile b/arch/mips/kernel/vbi/Makefile
new file mode 100644
index 0000000..98d494b
--- /dev/null
+++ b/arch/mips/kernel/vbi/Makefile
@@ -0,0 +1,4 @@
+#
+# Makefile for the vbi MIPS64.
+#
+obj-y		+= syscalls.o
diff --git a/arch/mips/kernel/vbi/syscalls.S b/arch/mips/kernel/vbi/syscalls.S
new file mode 100644
index 0000000..f4f0cf5
--- /dev/null
+++ b/arch/mips/kernel/vbi/syscalls.S
@@ -0,0 +1,1128 @@
+/*
+ * syscalls.s - hypervisor system calls
+ *
+ * Copyright (c) 2007-2010 Wind River Systems, Inc.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
+ * See the GNU General Public License for more details.
+ *
+ */
+	
+#define	EXCEPTION_FRAME_CTX	REG_SET_SIZE
+
+#define _ASMLANGUAGE
+
+#include <vbi/vbi.h>
+#include <asm/vbi.h>
+#include <asm/reg_vbi.h>
+	
+#define FIX_SIGN_EXTENSION(arg_reg) \
+	dext arg_reg, arg_reg, 0, 32
+
+
+	.text
+	.set	reorder
+
+
+	/* globals */
+	
+	FUNC_EXPORT(vbi_vcore_irq_unlock)
+	FUNC_EXPORT(vbi_vcore_irq_lock)
+	FUNC_EXPORT(vbi_vcore_irq_state)
+	FUNC_EXPORT(vbi_vcore_irq_redirect)
+	FUNC_EXPORT(vbi_io_apic_op)
+	FUNC_EXPORT(vbi_io_apic_ioctl)
+	FUNC_EXPORT(vbi_hy_ioctl)
+	FUNC_EXPORT(vbi_ctx_ctl)
+	FUNC_EXPORT(vbi_bsp_ioctl)
+	FUNC_EXPORT(vbi_send)
+	FUNC_EXPORT(vbi_rx_op)
+	FUNC_EXPORT(vbi_reply)
+	FUNC_EXPORT(vbi_flush_icache)
+	FUNC_EXPORT(vbi_flush_dcache)
+	FUNC_EXPORT(vbi_flush_tlb)
+	FUNC_EXPORT(vbi_panic)
+	FUNC_EXPORT(vbi_ps)
+	FUNC_EXPORT(vbi_kputs)
+	FUNC_EXPORT(vbi_kputc)
+	FUNC_EXPORT(vbi_irq_controller_done)
+	FUNC_EXPORT(vbi_irq_enable)
+	FUNC_EXPORT(vbi_set_mem_attr)
+	FUNC_EXPORT(vbi_get_mem_attr)
+	FUNC_EXPORT(vbi_config_vmmu)
+	FUNC_EXPORT(vbi_enable_vmmu)
+	FUNC_EXPORT(vbi_disable_vmmu)
+	FUNC_EXPORT(vbi_tlb_load_vmmu)
+	FUNC_EXPORT(vbi_tlb_flush_vmmu)
+	FUNC_EXPORT(vbi_create_vmmu)
+	FUNC_EXPORT(vbi_delete_vmmu)
+	FUNC_EXPORT(vbi_get_max_asid_vmmu)
+	FUNC_EXPORT(vbi_vb_mgmt)
+	FUNC_EXPORT(vbi_ns_op)
+	FUNC_EXPORT(vbi_vb_suspend)
+	FUNC_EXPORT(vbi_vb_reset)
+	FUNC_EXPORT(vbi_vb_restart)
+	FUNC_EXPORT(vbi_vb_resume)
+	FUNC_EXPORT(vbi_sys_ctx_load)
+	FUNC_EXPORT(vbi_ctx_load)
+	FUNC_EXPORT(vbi_vb_remote)
+	FUNC_EXPORT(vbi_vb_create)
+	FUNC_EXPORT(vbi_vb_delete)
+	FUNC_EXPORT(vbi_board_simple_config_get)
+	FUNC_EXPORT(vbi_board_config_get)
+	FUNC_EXPORT(vbi_vb_move)
+	FUNC_EXPORT(vbi_vb_priority_set)
+	FUNC_EXPORT(vbi_vb_read_mem)
+	FUNC_EXPORT(vbi_vb_write_mem)
+	FUNC_EXPORT(vbi_vb_read_reg)
+	FUNC_EXPORT(vbi_vb_write_reg)
+	FUNC_EXPORT(vbi_shell_start_debug)
+
+/*
+ * vbi_vb_mgmt - virtual board management
+ * 
+ * This routine executes the specified command on a given virtual board. The
+ * possible commands are:
+ * 
+ * VBI_VBMGMT_ATTACH 
+ * Attach the requesting Virtual Board to the VB management agent for
+ * operations on the specified VB.
+ *
+ * VBI_VBMGMT_DETACH
+ * Detatch the requesting Virtual Board from the VB management agent for
+ * operations on the specified VB.
+ *
+ * VBI_VBMGMT_SUSPEND
+ * Suspends target Virtual Board from operation.  Fails if Virtual Board
+ * has already been suspended
+ *
+ * VBI_VBMGMT_RESET
+ * Resume a target virtual board.  Fails if a Virtual Board has not been
+ * suspended. Currently no options are supported
+ *
+ * VBI_VBMGMT_RESUME
+ * Restarts a target Virtual Board which has Preload=0 set in the xml file.
+ * Fails if Virtual Board is preloaded (Preload=1)
+ *
+ * The fourth argument to this routine specifies an flag that must be defined
+ * when executing VBI_VBMGMT_RESUME operation. Otherwise the command fails.
+ * The possible flgas are:
+ *   VBI_VTLB_OP_UPDATE_PMD	
+ *   VBI_VTLB_OP_UPDATE_PTE	
+ *   VBI_VTLB_OP_DELETE_PMD	
+ *   VBI_VTLB_OP_SET_PTE_AT	
+ *   VBI_VTLB_OP_SET_PTE	
+ *   VBI_VTLB_OP_FLUSH_OPS	
+ *   VBI_VTLB_OP_INIT	
+ * 
+ */
+
+FUNC_LABEL(vbi_vb_mgmt)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a1)
+	FIX_SIGN_EXTENSION(a3)
+        li	v0,VBI_SYS_vbMgmt
+        syscall
+        j ra
+	nop
+FUNC_END(vbi_vb_mgmt)
+	
+
+/*
+ * vbi_vb_suspend - Suspend a virtual board's core
+ *
+ * This routine makes a hypercall in order to suspend one or more cores that
+ * exist within the specified virtual board. The target core(s) enter HALT state
+ * until vbiVbResume() is called change the state of the core(s). This function
+ * will return only after all victim cores are suspended unless the opration
+ * fails to complete. The second argument passed to this function specifies one
+ * or more target cores. For suspending every core within the specified VB the
+ * second argument must be set to VBI_VB_CORES_ALL. This implies that the core
+ * requesting the suspension may also be included in the list to be suspended.
+ * To suspend everyone but the recipient then the second argument passed to this
+ * function should be set to VBI_VB_CORES_OTHERS. Otherwise the second argument
+ * should be a valid core number within the VB. This hypercall sends a message
+ * to a given hypervisor manager that provides virtual board managment service.
+ *
+ */
+
+FUNC_LABEL(vbi_vb_suspend)
+
+	/* 
+	 * a0 - virtual board id
+	 * a1 - virtual core ( a flag or a valid vcore id)
+	 */
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a1)
+
+	li	v0, VBI_SYS_vbSuspend
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_suspend)
+
+/*
+ * vbi_vb_reset - Reset a virtual board's core
+ *
+ * This routine makes a hypercall in order to reset one or more cores that exist
+ * within the specified virtual board. Calling this function puts the target
+ * core(s) program counter to it's ENTRY function. The ENTRY function is 
+ * determined based on the loaded binary image. A core does not execute beyond
+ * it's ENTRY function unless vbiVbRestart() is explitly called. 
+ * Except for core0 within the target VB where VBI_VBMGMT_RESET_AND_START_CORE0
+ * option is set in the flag passed as the third argument to this routine.
+ * The hypercall sends a message to a manager that provides VB managment 
+ * services. 
+ * This function will return only after all victim cores are reset unless the
+ * operation fails to complete. The order of which the victim cores are reset
+ * is not determined. The second argument identifies the cores to perform the
+ * operation on.
+ * The value of the second argument should be set to one of the following:
+ *
+ * VBI_VB_CORES_ALL: Reset all cores in the specified virtual board
+ *
+ * VBI_VB_CORES_OTHERS: Exclude the recipient if it belongs to the victim VB
+ *
+ * A valid core number: Reset the specified core that exist within the Virtual
+ * Board.
+ *
+ * The third argument argument passed to this function specifies options that are
+ * applicable only when the second argument is VBI_VB_CORES_ALL. The options
+ * may be
+ * one of the following or a combination:
+*
+ * VBI_VBMGMT_RESET_DOWNLOAD: Reset the cores and reload the executable images
+ * VBI_VBMGMT_RESET_AND_START_CORE0: Reset and start core0 within the VB
+ */
+
+FUNC_LABEL(vbi_vb_reset)
+
+	/* 
+	 * a0 - virtual board id
+	 * a1 - virtual core ( a flag or a valid vcore id)
+	 * a2 - options
+	 */
+	
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a1)
+	FIX_SIGN_EXTENSION(a2)	
+	li	v0, VBI_SYS_vbReset
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_reset)
+
+
+/*
+ * vbi_vb_restart - Restart a virtual board's core
+ *
+ * This routine makes a hypercall in order to restart a virtual cores from reset.
+ * It's called to start running a core or cores that were previously reset by
+ * calling vbiVbReset(). The target core(s) start(s) executing from the ENTRY
+ * function retrieved from the corresponding binary image.
+ * This function will return only after  all cores are out of reset unless the
+ * operation fails to complete.  The second argument represents the cores to
+ * restart.
+ * For restarting every core in reset mode within the specified VB the second
+ * argument is set to VBI_VB_CORES_ALL. To restart a specific core within the
+ * VB then the core number must be passed in the second argument.
+ *
+ * This hypercall sends a message to a manager that provides VB managment
+ * services.
+ *
+ */
+
+FUNC_LABEL(vbi_vb_restart)
+
+	/* 
+	 * a0 - virtual board id
+	 * a1 - virtual core ( a flag or a valid vcore id)
+	 */
+	
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a1)
+
+	li	v0, VBI_SYS_vbRestart
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_restart)
+
+/*
+ * vbi_vb_resume - Resume a virtual board's core
+ *
+ * This routine makes a hypercall in order to resume one or cores within
+ * the specified virtual board. It reactivates a cores or cores that were
+ * previously suspended by calling vbiVbResume(). This function will return only
+ * after all victim cores are resumed unless the operation fails. The order of
+ * which the cores are resumed is not determined. The second argument may a
+ * magic number instead of a valid core number to indicate that the operation
+ * is intended for more than one core. For resuming every core within the
+ * specified VB then the second argument is set to be equal to VBI_VB_RESUME_ALL.
+ * This implies to resume every core within the specified VB. Using this option
+ * when some of the cores within the VB are already running is not considered
+ * as programming error.
+ *
+ */
+
+FUNC_LABEL(vbi_vb_resume)
+
+	/* 
+	 * a0 - virtual board id
+	 * a1 - virtual core ( a flag or a valid vcore id)
+	 */
+	
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a1)
+
+	li	v0, VBI_SYS_vbResume
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_resume)
+
+/*
+ * vbi_send - send a message to another context
+ *
+ * This system call sends a message to the specified context and waits for
+ * a reply.  The caller will block until the sender replies to the sent
+ * message.
+ *
+ */
+
+FUNC_LABEL(vbi_send)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a2)
+	FIX_SIGN_EXTENSION(a4)		
+	li	v0,VBI_SYS_send
+	syscall
+        j ra
+	nop
+FUNC_END(vbi_send)
+
+
+/*
+ * vbi_rx_op - receive a message from another context
+ *
+ * This system call waits for a message to be received from another context.
+ * The caller will block until a message is received.
+ */
+
+FUNC_LABEL(vbi_rx_op)
+	FIX_SIGN_EXTENSION(a1)
+	li	v0,VBI_SYS_receive
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_rx_op)
+
+
+/*
+ * vbi_reply - reply to a message received from another context
+ *
+ * This system call replies to a message which has previously been receiving
+ * using vbiReceive().  The reply will unblock the recipient which may preempt
+ * the caller.
+ *
+ */
+
+FUNC_LABEL(vbi_reply)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a2)
+	li	v0,VBI_SYS_reply
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_reply)
+	
+/*
+ * vbi_kputs - print a string on the kernel console
+ *
+ * This system call sends the specified string to the system console.
+ *
+ */
+
+FUNC_LABEL(vbi_kputs)
+	li	v0,VBI_SYS_kputs
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_kputs)
+
+
+/*
+ * vbi_kputc - print a character on the kernel console
+ *
+ * This system call sends the specified character to the system console.
+ *
+ */
+
+FUNC_LABEL(vbi_kputc)
+	li	v0,VBI_SYS_kputc
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_kputc)
+
+/*
+ * vbi_panic - panic the system and halt all activity
+ *
+ * This system call causes the hypervisor to enter a panic state and display
+ * various pieces of information on the system console.  The hypervisor
+ * then enters an idle state and stops all CPU processing.
+ *
+ */
+
+FUNC_LABEL(vbi_panic)
+	li	v0,VBI_SYS_panic
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_panic)
+
+
+/*
+ * vbi_pc - display the list of contexts on the console
+ *
+ * This system call sends a "ps" like output of the hypervisor contexts to
+ * the system console.
+ */
+
+FUNC_LABEL(vbi_ps)
+	li	v0,VBI_SYS_ps
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_ps)
+
+
+/*
+ * vbi_flush_icache - flush the instruction cache
+ *
+ * This system call flushes the instruction cache for the specified address
+ * range.
+ *
+ */
+
+FUNC_LABEL(vbi_flush_icache)
+	FIX_SIGN_EXTENSION(a2)
+	li	v0,VBI_SYS_icache_flush
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_flush_icache)
+
+
+/*
+ * vbi_flush_dcache - flush the data cache
+ *
+ * This system call flushes the data cache for the specified address range.
+ *
+ */
+
+FUNC_LABEL(vbi_flush_dcache)
+	FIX_SIGN_EXTENSION(a2)
+	li	v0,VBI_SYS_dcache_flush
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_flush_dcache)
+
+
+/*
+ * vbi_flush_tlb - flush an MMU TLB entry
+ *
+ * This system call flushes the TLB associated with the specified context id 
+ *
+ */
+
+FUNC_LABEL(vbi_flush_tlb)
+	li	v0,VBI_SYS_tlb_flush
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_flush_tlb)
+
+
+/*
+ * vbi_irq_controller_done - signal completion of processing by virtual int controller
+ *
+ * This system notifies the hypervisor that the virtual interrupt controller
+ * in the virtual board has finished procssing the information in the 
+ * virtual interrupt controller registers, and requires a refresh.
+ *
+ */
+
+FUNC_LABEL(vbi_irq_controller_done)
+	li	v0,VBI_SYS_int_controller_done
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_irq_controller_done)
+
+
+/*
+ * vbi_config_vmmu - configure the hypervisor virtual MMU
+ *
+ * This system call configures the context's virtual MMU within the hypervisor.
+ *
+ */
+
+FUNC_LABEL(vbi_config_vmmu)
+	li	v0,VBI_SYS_vmmu_config
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_config_vmmu)
+
+
+/*
+ * vbi_enable_vmmu - enables the virtual MMU
+ *
+ * This system call enables a context's virtual MMU.
+ *
+ */
+
+FUNC_LABEL(vbi_enable_vmmu)
+	li	v0,VBI_SYS_vmmu_enable
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_enable_vmmu)
+
+
+/*
+ * vbi_disable_vmmu - disable the virtual MMU
+ *
+ * This system call disables a context's virtual MMU.
+ *
+ */
+
+FUNC_LABEL(vbi_disable_vmmu)
+	li	v0,VBI_SYS_vmmu_disable
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_disable_vmmu)
+
+
+/*
+ * vbi_tlb_load_vmmu - load a TLB entry into the virtual MMU
+ *
+ * This system call loads the TLB entries for the specified address range into
+ * the virtual MMU.
+ */
+
+FUNC_LABEL(vbi_tlb_load_vmmu)
+	li	v0,VBI_SYS_vmmu_tlbload
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_tlb_load_vmmu)
+
+
+/*
+ * vbi_tlb_flush_vmmu - load a TLB entry into the virtual MMU
+ *
+ * This system call flushes the TLB entries for the specified address range
+ * from the virtual MMU.
+ *
+ */
+
+FUNC_LABEL(vbi_tlb_flush_vmmu)
+	li	v0,VBI_SYS_vmmu_tlbflush
+
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_tlb_flush_vmmu)
+
+
+/*
+ * vbi_hy_ioctl - hypervisor ioctl call
+ *
+ * This system call interfaces to the general purpose hypervisor ioctl
+ * function.
+ *
+ * Possible ioctl commands:
+ *     VBI_HYIOCTL_GETPID
+ *     VBI_HYIOCTL_PSDISPLAY
+ *     VBI_HYIOCTL_GETSTATS
+ *     VBI_HYIOCTL_EXCBASE
+ *		
+ */
+
+FUNC_LABEL(vbi_hy_ioctl)
+	li	v0,VBI_SYS_hyIoctl
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_hy_ioctl)
+
+/*
+ * vbi_ctx_ctl - hypervisor context control call
+ *
+ * This system call interfaces to the general purpose hypervisor context
+ * control function.
+ *
+ * Possbile operations:
+ *	VBI_CTXCTL_IDLE /@ Make this virtual board go idle @/
+ *
+ */
+
+FUNC_LABEL(vbi_ctx_ctl)
+	li	v0,VBI_SYS_ctxctl
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_ctx_ctl)
+
+
+
+
+/*
+* vbi_set_mem_attr - protect a page of memory using the MMU
+ *
+ * This system call protects context memory using the hardware MMU.
+ *
+ */
+
+FUNC_LABEL(vbi_set_mem_attr)
+	li	v0,VBI_SYS_mmu_attr_set
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_set_mem_attr)
+
+
+/*
+ * vbi_get_mem_attr - get MMU page protections
+ *
+ * This system call returns the hardware MMU protection bits.
+ *
+ */
+
+FUNC_LABEL(vbi_get_mem_attr)
+	li	v0,VBI_SYS_mmu_attr_get
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_get_mem_attr)
+
+
+/*
+ * vbi_bsp_ioctl - bsp ioctl call
+ *
+ * This system call interfaces to the Board Support Package
+ * I/O drivers etc
+ *
+ * Knwon BSP ioctl commands:
+ *	VBI_BSPIOCTL_ENABLE_INT   /@ Enable HW interrupt @/
+ *	VBI_BSPIOCTL_DISABLE_INT  /@ Disable HW interrupt@/
+ *	VBI_BSPIOCTL_RESET	  /@ Reset HW device     @/
+ *				
+ */
+
+FUNC_LABEL(vbi_bsp_ioctl)
+	li	v0,VBI_SYS_bspIoctl
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_bsp_ioctl)
+
+/*
+ * vbi_io_apic_ioctl - virtual IO APIC ioctl call
+ *
+ * This system call interfaces to the virtual IO APIC ioctl
+ * function. For MIPS this is a nop routine for now.
+ *
+ * Possible ioctl commands:
+ *     VBI_IOAPICIOCTL_UNMASK
+ *     VBI_IOAPICIOCTL_SEND
+ *     VBI_IOAPICIOCTL_MASK
+ *		
+ */
+
+FUNC_LABEL(vbi_io_apic_ioctl)
+	li	v0,VBI_SYS_vIoapicIoctl
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_io_apic_ioctl)
+
+/*
+ * vbi_ctx_load - load ctx to run
+ *
+ * This system call requests hypervisor to switch to a particular task in guest
+ *
+ */
+
+FUNC_LABEL(vbi_ctx_load)
+	li	v0, VBI_SYS_ctx_load
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_ctx_load)
+
+/*
+ * vbi_ns_op - virtua board name service call
+ *
+ * This system call interfaces to the virtual board
+ *
+ * commands:
+ *	VBI_VBI_NS_REGISTER	   /@ register service	 @/
+ *	VBI_VBI_NS_UNREGISTER	   /@ unregister service @/
+ *	VBI_VBI_NS_LOOKUP	   /@ lookup service	 @/
+ *				
+ */
+
+FUNC_LABEL(vbi_ns_op)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a2)
+	FIX_SIGN_EXTENSION(a4)
+	FIX_SIGN_EXTENSION(a5)
+	li   v0,VBI_SYS_ns_op
+	syscall
+        j ra
+	nop
+FUNC_END(vbi_ns_op)
+
+	
+FUNC_LABEL(vbi_sys_ctx_load)
+	LA 		k1,wr_vb_control 
+        LW		k1,0(k1)
+
+	LW		k0,HREG_SR(sp)
+	SW		k0,VB_CONTROL_SR(k1) 
+
+	LW		k0,PCREG(sp)
+	SW		k0,VB_CONTROL_EPC(k1) 
+	
+	lw		k0,INT_DISABLE(sp)
+	sw		k0,VB_CONTROL_NEW_INT_DISABLE(k1) 
+	
+	LW		k0,V0REG(sp)
+	SW		k0,VB_CONTROL_V0(k1) 
+
+	LW		k0,K0REG(sp)
+	SW		k0,VB_CONTROL_K0(k1) 
+	
+	LW		k0,K1REG(sp)
+	SW		k0,VB_CONTROL_K1(k1) 
+
+	addi	sp,EXCEPTION_FRAME_CTX        
+#if 1 /* FIXME:	 remove following segment */
+	LW		k0,8(sp)  /* k0 */
+	SW 		k0, VB_CONTROL_K0(k1)
+	LW		k0,16(sp) /* k1 */
+	SW 		k0, VB_CONTROL_K1(k1)
+#endif
+	SW 		v0, VB_CONTROL_V0(k1)
+	addi		sp, 40
+	li		v0,VBI_SYS_ctx_load
+	syscall 	
+	
+loop:   
+        b loop        /* should not return */
+	nop
+FUNC_END(vbi_sys_ctx_load)
+
+/*
+ * vbi_irq_enable - Re-enable interrupts in the virtual board
+ *
+ * This call re-enables interrupts in the virtual board, and calls the
+ * hypervisor if interrupts are pending.  The value level is the value returned
+ * by the corresponding 
+ */
+
+FUNC_LABEL(vbi_irq_enable)
+/*
+ * FIXME :        check for int pending
+ */
+	li		v0,VBI_SYS_int_enable
+	syscall 	
+        j ra
+	nop
+FUNC_END(vbi_irq_enable)
+
+
+/*
+ * vbi_vb_remote - VB remote operations
+ *
+ * This system call interfaces to the virtual board and requests for information
+ * about a remote VB
+ *
+ * commands:
+ *	VBI_VBREMOTE_BOARDCONFIG        /@ get guest addr of VB_CONFIG	 @/
+ *	VBI_VBREMOTE_RAMSIZE            /@ get memory size  @/
+ *				
+ */
+
+FUNC_LABEL(vbi_vb_remote)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a1)
+	FIX_SIGN_EXTENSION(a2)
+	li		v0, VBI_SYS_vbRemote
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_remote)
+
+/*
+ *
+ * vbi_vb_create - VB create
+ *
+ * options:
+ *       VBI_CREATE_RESUME        /@ start VB after create @/
+ *       VBI_CREATE_HALT          /@ keep VB halted after creation  @/
+ *
+ * Returns: VB BOARD_ID or 0 if failed.
+ *
+ */
+
+FUNC_LABEL(vbi_vb_create)
+	FIX_SIGN_EXTENSION(a1)
+	li		v0, VBI_SYS_vbCreate
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_create)
+
+/*
+ *
+ * vbi_vb_delete - VB delete
+ *
+ *
+ * Returns: VB BOARD_ID or 0 if failed.
+ *
+ */
+
+FUNC_LABEL(vbi_vb_delete)
+	FIX_SIGN_EXTENSION(a0)
+	li		v0, VBI_SYS_vbDelete
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_delete)
+
+/*
+ *
+ * vbi_board_simple_config_get - Get VB basic configuration info
+ *
+ *
+ */
+
+FUNC_LABEL(vbi_board_simple_config_get)
+	FIX_SIGN_EXTENSION(a0)
+	li		v0, VBI_SYS_vbBoardSimpleConfigGet
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_board_simple_config_get)
+
+/*
+ *
+ * vbi_board_config_get - Get VB configuration and device info
+ *
+ *
+ */
+
+FUNC_LABEL(vbi_board_config_get)
+	FIX_SIGN_EXTENSION(a0)
+	li		v0, VBI_SYS_vbBoardConfigGet
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_board_config_get)
+
+/*
+ *
+ * vbi_vb_move - Move a VB to another core and/or priority
+ *
+ */
+
+FUNC_LABEL(vbi_vb_move)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a2)
+	li		v0, VBI_SYS_vbMove
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_move)
+
+/*
+ *
+ * vbi_vb_priority_set
+ *
+ */
+
+FUNC_LABEL(vbi_vb_priority_set)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a2)
+	li		v0, VBI_SYS_vbPrioSet
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_priority_set)
+
+
+/*
+ * vbi_io_apic_op - virtual IO APIC operation
+ *
+ * This system call interfaces to the virtual IO APIC ioctl
+ * function.
+ *
+ * Possible ioctl commands:
+ *     VBI_IOAPICIOCTL_UNMASK
+ *     VBI_IOAPICIOCTL_SEND
+ *     VBI_IOAPICIOCTL_MASK
+ *		
+ */
+
+FUNC_LABEL(vbi_io_apic_op)
+	FIX_SIGN_EXTENSION(a1)
+	FIX_SIGN_EXTENSION(a2)
+	FIX_SIGN_EXTENSION(a3)
+	li   v0, VBI_SYS_vIoapicIoctl
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_io_apic_op)
+
+/*
+ * vbi_vcore_irq_redirect - redirect an irq to another vcore
+ *
+ */
+
+FUNC_LABEL(vbi_vcore_irq_redirect)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a1)
+	li   v0, VBI_SYS_intRedirect
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vcore_irq_redirect)
+
+/*
+ * vbi_vcore_irq_unlock - unlock interrupts interrupts for running core
+ *
+ * This routine enables interrupts and makes a fast hypercall if pending
+ * interrupts are detected for the calling core. This is a C wrapper function for
+ * the assembly MACRO VBI_INT_VCORE_UNLOCK(). 
+ *
+ */
+
+FUNC_LABEL(vbi_vcore_irq_unlock)
+	LW	t0, wr_vb_control 
+	li      t1, 0
+	sw	t1, VB_CONTROL_INT_DISABLE(t0)
+tryAgain:		
+	LW	t0, wr_vb_status
+	lw	t1, VB_STATUS_INT_PENDING(t0)
+	
+	/* Perform System Call to re-enable ints if ints pending */
+	andi    t1, 0
+	beqz    t1, unlock_done
+
+	li	v0, VBI_SYS_int_enable
+	syscall
+
+	nop
+	b	tryAgain
+unlock_done:
+	j ra
+	nop
+FUNC_END(vbi_vcore_irq_unlock)
+
+/*
+ * vbi_vcore_irq_lock - lock interrupts
+ *
+ * This routine locks interrupts for the calling core. This is a C wrapper 
+ * function for VBI_INT_VCORE_LOCK() assembly macro. It locks interrupts returns
+ * and returns the previous state of interrupts.
+ *
+ */
+
+FUNC_LABEL(vbi_vcore_irq_lock)
+	li	t1, -1
+	LW	t2, wr_vb_control 
+	lw	v0, VB_CONTROL_INT_DISABLE(t2)
+	sw	t1, VB_CONTROL_INT_DISABLE(t2)
+	j ra
+	nop
+FUNC_END(vbi_vcore_irq_lock)
+
+/*
+ * vbi_vcore_irq_state - Get interrupts state for running core
+ *
+ * This routine returns the interrupts state for the calling core. This is C 
+ * wrapper function for VBI_INT_VCORE_STATE_GET(). If interrupts are locked it
+ * returns TRUE if interrupts are locked otherwise FALSE.
+ *
+ */
+
+FUNC_LABEL(vbi_vcore_irq_state)
+	LW	t2, wr_vb_control
+	lw	v0, VB_CONTROL_INT_DISABLE(t2)
+	j ra
+	nop
+FUNC_END(vbi_vcore_irq_state)
+
+	
+/*
+ * vbi_create_vmmu - create the virtual MMU handle
+ *
+ * This system call enables a context's virtual MMU.
+ *
+ */
+
+FUNC_LABEL(vbi_create_vmmu)
+	li	v0, VBI_SYS_vmmu_create
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_create_vmmu)
+
+/*
+ * vbi_delete_vmmu - create the virtual MMU handle
+ *
+ * This system call enables a context's virtual MMU.
+ */
+
+FUNC_LABEL(vbi_delete_vmmu)
+	li	v0, VBI_SYS_vmmu_delete
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_delete_vmmu)
+
+/*
+ * vbi_get_max_asid_vmmu - Gets the maximum number of asids available
+ *
+ * This system call enables a context's virtual MMU.
+ *
+ */
+
+FUNC_LABEL(vbi_get_max_asid_vmmu)
+	li	v0, VBI_SYS_vmmu_maxasid
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_get_max_asid_vmmu)
+
+/*
+ * vbi_vb_read_mem - Read a virtual board's memory
+ *
+ * This routine makes a hypercall to read a remote board's memory. The memory control
+ * structure contains information about the target memory to read and the destination
+ * buffer that hypervisor must populate with the data read. This routine is used
+ * to copy data from a remote VB. It is the user's responsability to ensure that
+ * the memory read is accessed orthogonally.
+ * The sizeIn parameter specifies the number of bytes desired to be copied. 
+ * The sizeOut parameter indicates the number of bytes successfully copied.
+ * A user may set the sizeOut parameter to zero if the output size is not of
+ * interest otherwise to a value different than zero.
+ *
+ */
+
+FUNC_LABEL(vbi_vb_read_mem)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a1)	
+	li	v0, VBI_SYS_memRead_op
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_read_mem)
+
+/*
+ * vbi_vb_write_mem - copy data to a remote board's memory
+ *
+ * This routine makes a hypercall to copy to a remote board memory. If the
+ * VBI_DCACHE_FLUSH is set in the control memory control structure then this
+ * routine flushes the data caches lines corresponding to the range of memory
+ * specified. If VBI_ICACHE_INV then this routine ensure that the instruction
+ * cache lines corresponding to the range of address is invalidated after the
+ * memory is copied. Invalidating the instruction is required if data containing
+ * is updated since the instruction cache is not aware of the content in data
+ * cache. Therefore flushing the data cache ensures that memory contains the
+ * updated data and invalidating the instruction cache ensures that the stale
+ * values in the instruction cache is thrown away. 
+ * The sizeIn parameter specifies the number of bytes desired to be copied. 
+ * The sizeOut parameter indicates the number of bytes successfully copied.
+ * A user may set the sizeOut parameter to zero if the output size is not of
+ * interest otherwise to a value different than zero.
+ * 
+ */
+
+FUNC_LABEL(vbi_vb_write_mem)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a1)	
+	li	v0, VBI_SYS_memWrite_op
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_write_mem)
+
+/*
+ * vbi_vb_read_reg - Read a remote core's registers
+ *
+ * This routine makes a hypercall to read a remote core's registers. The register
+ * control structure contains information about the registers to read and the
+ * destination buffers to store them.
+ * 
+ */
+
+FUNC_LABEL(vbi_vb_read_reg)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a1)
+	FIX_SIGN_EXTENSION(a2)		
+	li	v0, VBI_SYS_RegsRead_op
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_read_reg)
+
+/*
+ * vbi_vb_write_reg - write to a remote core's registers
+ *
+ * This routine makes a hypercall to write to a remote core's registers. The
+ * register control structure contains the set of registers to write. 
+ * The user must ensure to read first the destination core's registers using
+ * vbiVbRegisterRead() then write back the modified set of registers in the 
+ * registers control structure.
+ * 
+ */
+
+FUNC_LABEL(vbi_vb_write_reg)
+	FIX_SIGN_EXTENSION(a0)
+	FIX_SIGN_EXTENSION(a1)	
+	li	v0, VBI_SYS_RegsWrite_op
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_vb_write_reg)
+
+/*
+ * vbi_shell_start_debug - start the hypervisor debug shell
+ *
+ * This routine sends a message to the hypervisor debug shell manager in order
+ * to start the WRHV shell program. The shell program spins therefore does not
+ * share the processor with any other WRHV context. By default a caller of this
+ * routine is detached to allow the caling core to continue executing (as long
+ * as the are not scheduled to run on the same processor). An optional flag
+ * VBI_SHELL_ATTACH can be specified to force the caller virtual board core to
+ * block while the shell program is running.
+ *
+ */
+FUNC_LABEL(vbi_shell_start_debug)
+	li	v0, VBI_SYS_dbgShStart
+	syscall
+	j ra
+	nop
+FUNC_END(vbi_shell_start_debug)
-- 
1.7.0.4

