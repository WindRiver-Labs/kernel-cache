From 298a56a5efc8bd16ffb4d7d8014b20435a99491e Mon Sep 17 00:00:00 2001
From: Yang Shi <yang.shi@windriver.com>
Date: Mon, 1 Mar 2010 22:07:50 -0800
Subject: [PATCH 1/2] MIPS: Octeon: Add Octeon specific TLS thread pointer access optimization support

For MIPS, normally the TLS thread pointer is accessed by the
userspace program executing a "rdhwr" from register $29. This
register doesn't exist, so the kernel emulates the instruction
assigning the thread pointer to the value register. This option
supplies an alternate, faster access to the thread pointer. A
side effect of this option is that the highest 8 bytes of CVMSEG
is used by the kernel to save and restore the thread pointer during
the TLB fault handlers. This CVMSEG address isn't available to user
applications.

Signed-off-by: Yang Shi <yang.shi@windriver.com>
---
 arch/mips/cavium-octeon/Kconfig    |   15 +++++++++++++++
 arch/mips/include/asm/mipsregs.h   |   13 +++++++++++++
 arch/mips/include/asm/stackframe.h |    3 +++
 arch/mips/kernel/genex.S           |    6 ++++++
 arch/mips/kernel/octeon_switch.S   |    9 +++++++++
 arch/mips/kernel/syscall.c         |    3 +++
 arch/mips/kernel/unaligned.c       |   36 ++++++++++++++++++++++++++++++++++++
 arch/mips/mm/tlbex.c               |    6 ++++++
 8 files changed, 91 insertions(+), 0 deletions(-)

diff --git a/arch/mips/cavium-octeon/Kconfig b/arch/mips/cavium-octeon/Kconfig
index 094c17e..fa82974 100644
--- a/arch/mips/cavium-octeon/Kconfig
+++ b/arch/mips/cavium-octeon/Kconfig
@@ -37,6 +37,21 @@ config CAVIUM_OCTEON_CVMSEG_SIZE
 	  legally range is from zero to 54 cache blocks (i.e. CVMSEG LM is
 	  between zero and 6192 bytes).
 
+config FAST_ACCESS_TO_THREAD_POINTER
+	bool "Enable fast access to the thread pointer"
+	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
+	default "y"
+	help
+	  For MIPS, normally the TLS thread pointer is accessed by the
+	  userspace program executing a "rdhwr" from register $29. This
+	  register doesn't exist, so the kernel emulates the instruction
+	  assigning the thread pointer to the value register. This option
+	  supplies an alternate, faster access to the thread pointer. A
+	  side effect of this option is that the highest 8 bytes of CVMSEG
+	  is used by the kernel to save and restore the thread pointer during
+	  the TLB fault handlers. This CVMSEG address isn't available to user
+	  applications.
+
 config CAVIUM_OCTEON_LOCK_L2
 	bool "Lock often used kernel code in the L2"
 	depends on CAVIUM_OCTEON_SPECIFIC_OPTIONS
diff --git a/arch/mips/include/asm/mipsregs.h b/arch/mips/include/asm/mipsregs.h
index f4ab313..95c3f13 100644
--- a/arch/mips/include/asm/mipsregs.h
+++ b/arch/mips/include/asm/mipsregs.h
@@ -592,6 +592,19 @@
 #define MIPS_FPIR_L		(_ULCAST_(1) << 21)
 #define MIPS_FPIR_F64		(_ULCAST_(1) << 22)
 
+/*
+ * These defines are used on Octeon to implement fast access to the thread pointer
+ * from userspace. Octeon uses a 64bit location in CVMSEG to store the thread pointer
+ * for quick access.
+ */
+#define TOP_OF_CVMSEG_STORE        (CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE*128-32768)
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+#define FAST_ACCESS_THREAD_OFFSET       (TOP_OF_CVMSEG_STORE-8)
+#define FAST_ACCESS_THREAD_REGISTER     *(unsigned long *)(FAST_ACCESS_THREAD_OFFSET)
+#else
+#define FAST_ACCESS_THREAD_OFFSET       TOP_OF_CVMSEG_STORE
+#endif
+
 #ifndef __ASSEMBLY__
 
 /*
diff --git a/arch/mips/include/asm/stackframe.h b/arch/mips/include/asm/stackframe.h
index 3b6da33..33bc42e 100644
--- a/arch/mips/include/asm/stackframe.h
+++ b/arch/mips/include/asm/stackframe.h
@@ -430,6 +430,9 @@
 		.macro	RESTORE_SP_AND_RET
 		LONG_L	sp, PT_R29(sp)
 		.set	mips3
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+		LONG_L  k0, FAST_ACCESS_THREAD_OFFSET($0) /* K0 = thread pointer */
+#endif
 		eret
 		.set	mips0
 		.endm
diff --git a/arch/mips/kernel/genex.S b/arch/mips/kernel/genex.S
index 8882e57..d34b1e1 100644
--- a/arch/mips/kernel/genex.S
+++ b/arch/mips/kernel/genex.S
@@ -190,6 +190,9 @@ NESTED(handle_int, PT_SIZE, sp)
 	and	k0, ST0_IE
 	bnez	k0, 1f
 
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	LONG_L  k0, FAST_ACCESS_THREAD_OFFSET($0)
+#endif
 	eret
 #endif
 1:
@@ -532,6 +535,9 @@ NESTED(nmi_handler, PT_SIZE, sp)
 	ori	k1, _THREAD_MASK
 	xori	k1, _THREAD_MASK
 	LONG_L	v1, TI_TP_VALUE(k1)
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	move    k0, v1
+#endif
 	.set	mips3
 	eret
 	.set	mips0
diff --git a/arch/mips/kernel/octeon_switch.S b/arch/mips/kernel/octeon_switch.S
index 3952b83..77bf875 100644
--- a/arch/mips/kernel/octeon_switch.S
+++ b/arch/mips/kernel/octeon_switch.S
@@ -114,6 +114,15 @@
 #endif
 	set_saved_sp	t0, t1, t2
 
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	/* We need to put the thread pointer in CVMMEM immediately. The
+	 * kernel will use this value during TLB exceptions even
+	 * though userspace hasn't accessed CVMMEM
+	 */
+	LONG_L  t1, TI_TP_VALUE($28)
+	LONG_S  t1, FAST_ACCESS_THREAD_OFFSET($0)
+#endif
+
 	mfc0	t1, CP0_STATUS		/* Do we really need this? */
 	li	a3, 0xff01
 	and	t1, a3
diff --git a/arch/mips/kernel/syscall.c b/arch/mips/kernel/syscall.c
index 3f7f466..e6cb831 100644
--- a/arch/mips/kernel/syscall.c
+++ b/arch/mips/kernel/syscall.c
@@ -265,6 +265,9 @@ SYSCALL_DEFINE1(set_thread_area, unsigned long, addr)
 	if (cpu_has_userlocal)
 		write_c0_userlocal(addr);
 
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	FAST_ACCESS_THREAD_REGISTER = addr;
+#endif
 	return 0;
 }
 
diff --git a/arch/mips/kernel/unaligned.c b/arch/mips/kernel/unaligned.c
index 69b039c..7260206 100644
--- a/arch/mips/kernel/unaligned.c
+++ b/arch/mips/kernel/unaligned.c
@@ -513,6 +513,42 @@ asmlinkage void do_ade(struct pt_regs *regs)
 	unsigned int __user *pc;
 	mm_segment_t seg;
 
+#if defined(CONFIG_CPU_CAVIUM_OCTEON) && (CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE > 0)
+	/* This section of code allows tasks to access CVMSEG addresses. These are
+	 * special addresses into the Octeon L1 Cache that can be used as fast
+	 * scratch memory. By default access to this memory is disabled so we
+	 * don't have to save it on context switch. When a userspace task
+	 * references one of these addresses, we enable the region and size it
+	 * to match the app
+	 */
+	const unsigned long CVMSEG_BASE  = (short)0x8000;
+	const unsigned long CVMSEG_IO    = (short)0xa200;
+	uint64_t cvmmemctl               = __read_64bit_c0_register($11, 7);
+	unsigned long cvmseg_size        = (cvmmemctl&0x3f) * 128;
+
+	if ((regs->cp0_badvaddr==CVMSEG_IO) ||
+	    ((regs->cp0_badvaddr>=CVMSEG_BASE) && (regs->cp0_badvaddr<CVMSEG_BASE + cvmseg_size)))
+	{
+		/* Make sure all async operations are done */
+		asm volatile ("synciobdma" ::: "memory");
+		/* Enable userspace access to CVMSEG */
+		cvmmemctl |= 1<<6;
+		__write_64bit_c0_register($11, 7, cvmmemctl);
+
+		pr_debug("Enabling CVMSEG access for task %p (%lu lines)\n", current, (unsigned long)cvmmemctl&0x3f);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+		/* Restore the processes CVMSEG data. Leave off the last 8 bytes since
+		 * the kernel stores the thread pointer there
+		 */
+		memcpy((void*)CVMSEG_BASE, current->thread.cvmseg.cvmseg, cvmseg_size-8);
+#else
+		/* Restore the processes CVMSEG data */
+		memcpy((void*)CVMSEG_BASE, current->thread.cvmseg.cvmseg, cvmseg_size);
+#endif
+		return;
+	}
+#endif
+ 
 	/*
 	 * Did we catch a fault trying to load an instruction?
 	 * Or are we running in MIPS16 mode?
diff --git a/arch/mips/mm/tlbex.c b/arch/mips/mm/tlbex.c
index badcf5e..3d6f48a 100644
--- a/arch/mips/mm/tlbex.c
+++ b/arch/mips/mm/tlbex.c
@@ -763,6 +763,9 @@ static void __cpuinit build_r4000_tlb_refill_handler(void)
 	build_update_entries(&p, K0, K1);
 	build_tlb_write_entry(&p, &l, &r, tlb_random);
 	uasm_l_leave(&l, p);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	UASM_i_LW(&p, K0, FAST_ACCESS_THREAD_OFFSET, 0);  /* K0 = thread ptr */
+#endif
 	uasm_i_eret(&p); /* return from trap */
 
 #ifdef CONFIG_HUGETLB_PAGE
@@ -1242,6 +1245,9 @@ build_r4000_tlbchange_handler_tail(u32 **p, struct uasm_label **l,
 	build_update_entries(p, tmp, ptr);
 	build_tlb_write_entry(p, l, r, tlb_indexed);
 	uasm_l_leave(l, *p);
+#ifdef CONFIG_FAST_ACCESS_TO_THREAD_POINTER
+	UASM_i_LW(p, K0, FAST_ACCESS_THREAD_OFFSET, 0);  /* K0 = thread ptr */
+#endif
 	uasm_i_eret(p); /* return from trap */
 
 #ifdef CONFIG_64BIT
-- 
1.6.5.2

