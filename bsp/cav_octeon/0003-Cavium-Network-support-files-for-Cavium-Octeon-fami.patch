From 019abe638a90cb265f1d81321542a1c2173db057 Mon Sep 17 00:00:00 2001
From: Phil Staub <Phil.Staub@windriver.com>
Date: Thu, 24 Sep 2009 14:12:22 -0700
Subject: [PATCH] Cavium: Network support files for Cavium Octeon family BSP

This is the set of files added with Cavium's SDK 1.9 BSP to support
various forms of networking. The current state of these files reflects
an ongoing development process, and as such implies an extensive
modification history that is not cited in detail here. It is worth
noting, however, that this collection represents the work of the
following people who were involved in that history:

Tomaso Paoletti <tpaoletti@caviumnetworks.com>
David Daney <ddaney@caviumnetworks.com>
Greg Moffatt <greg.moffatt@windriver.com>
Jason HU <yongqi.hu@windriver.com>
Paul Gortmaker <Paul.Gortmaker@windriver.com>
Phil Staub <Phil.Staub@windriver.com>

Signed-off-by: Phil Staub <Phil.Staub@windriver.com>
---
 arch/mips/cavium-octeon/ethernet-mgmt-port.c       |  537 ++++++++++++++
 arch/mips/cavium-octeon/ethernet-pow.c             |  745 ++++++++++++++++++++
 drivers/net/Kconfig                                |    2 +
 drivers/net/Makefile                               |    4 +-
 drivers/net/cavium-ethernet/Kconfig                |   12 +
 drivers/net/cavium-ethernet/Makefile               |   60 ++
 drivers/net/cavium-ethernet/cavium-ethernet.h      |  176 +++++
 drivers/net/cavium-ethernet/ethernet-common.c      |  286 ++++++++
 drivers/net/cavium-ethernet/ethernet-common.h      |   40 +
 drivers/net/cavium-ethernet/ethernet-defines.h     |  117 +++
 drivers/net/cavium-ethernet/ethernet-headers.h     |   50 ++
 drivers/net/cavium-ethernet/ethernet-mdio.c        |  242 +++++++
 drivers/net/cavium-ethernet/ethernet-mdio.h        |   59 ++
 drivers/net/cavium-ethernet/ethernet-mem.c         |  194 +++++
 drivers/net/cavium-ethernet/ethernet-mem.h         |   40 +
 drivers/net/cavium-ethernet/ethernet-proc.c        |  256 +++++++
 drivers/net/cavium-ethernet/ethernet-proc.h        |   40 +
 drivers/net/cavium-ethernet/ethernet-rgmii.c       |  331 +++++++++
 drivers/net/cavium-ethernet/ethernet-rx.c          |  479 +++++++++++++
 drivers/net/cavium-ethernet/ethernet-rx.h          |   44 ++
 drivers/net/cavium-ethernet/ethernet-sgmii.c       |  133 ++++
 drivers/net/cavium-ethernet/ethernet-spi.c         |  284 ++++++++
 drivers/net/cavium-ethernet/ethernet-tx.c          |  582 +++++++++++++++
 drivers/net/cavium-ethernet/ethernet-tx.h          |   42 ++
 drivers/net/cavium-ethernet/ethernet-util.h        |   93 +++
 drivers/net/cavium-ethernet/ethernet-xaui.c        |  131 ++++
 drivers/net/cavium-ethernet/ethernet.c             |  528 ++++++++++++++
 .../net/cavium-ethernet/wrapper-cvmx-includes.h    |   58 ++
 drivers/net/sky2.c                                 |    7 +
 include/net/xfrm.h                                 |    7 +
 net/core/dev.c                                     |   24 +
 net/netfilter/nf_conntrack_proto_tcp.c             |   11 +
 32 files changed, 5613 insertions(+), 1 deletions(-)
 create mode 100644 arch/mips/cavium-octeon/ethernet-mgmt-port.c
 create mode 100644 arch/mips/cavium-octeon/ethernet-pow.c
 create mode 100644 drivers/net/cavium-ethernet/Kconfig
 create mode 100644 drivers/net/cavium-ethernet/Makefile
 create mode 100644 drivers/net/cavium-ethernet/cavium-ethernet.h
 create mode 100644 drivers/net/cavium-ethernet/ethernet-common.c
 create mode 100644 drivers/net/cavium-ethernet/ethernet-common.h
 create mode 100644 drivers/net/cavium-ethernet/ethernet-defines.h
 create mode 100644 drivers/net/cavium-ethernet/ethernet-headers.h
 create mode 100644 drivers/net/cavium-ethernet/ethernet-mdio.c
 create mode 100644 drivers/net/cavium-ethernet/ethernet-mdio.h
 create mode 100644 drivers/net/cavium-ethernet/ethernet-mem.c
 create mode 100644 drivers/net/cavium-ethernet/ethernet-mem.h
 create mode 100644 drivers/net/cavium-ethernet/ethernet-proc.c
 create mode 100644 drivers/net/cavium-ethernet/ethernet-proc.h
 create mode 100644 drivers/net/cavium-ethernet/ethernet-rgmii.c
 create mode 100644 drivers/net/cavium-ethernet/ethernet-rx.c
 create mode 100644 drivers/net/cavium-ethernet/ethernet-rx.h
 create mode 100644 drivers/net/cavium-ethernet/ethernet-sgmii.c
 create mode 100644 drivers/net/cavium-ethernet/ethernet-spi.c
 create mode 100644 drivers/net/cavium-ethernet/ethernet-tx.c
 create mode 100644 drivers/net/cavium-ethernet/ethernet-tx.h
 create mode 100644 drivers/net/cavium-ethernet/ethernet-util.h
 create mode 100644 drivers/net/cavium-ethernet/ethernet-xaui.c
 create mode 100644 drivers/net/cavium-ethernet/ethernet.c
 create mode 100644 drivers/net/cavium-ethernet/wrapper-cvmx-includes.h

diff --git a/arch/mips/cavium-octeon/ethernet-mgmt-port.c b/arch/mips/cavium-octeon/ethernet-mgmt-port.c
new file mode 100644
index 0000000..379ef23
--- /dev/null
+++ b/arch/mips/cavium-octeon/ethernet-mgmt-port.c
@@ -0,0 +1,537 @@
+/*
+ *   Octeon Management Port Ethernet Driver
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2007 Cavium Networks
+ */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/ip.h>
+#include <linux/string.h>
+#include <linux/delay.h>
+#include <linux/ethtool.h>
+
+#undef OCTEON_MODEL
+#define USE_RUNTIME_MODEL_CHECKS 1
+#include "cvmx.h"
+#include "cvmx-mgmt-port.h"
+
+static struct net_device *global_dev[2] = { NULL, NULL };
+
+#define DEBUGPRINT(format, ...) do {if (printk_ratelimit())		\
+					printk(format, ##__VA_ARGS__);	\
+				} while (0)
+
+/**
+ * This is the definition of the Ethernet driver's private
+ * driver state stored in dev->priv.
+ */
+struct device_private {
+	int port;
+	struct net_device_stats stats;	/* Device statistics */
+};
+
+static int mgmt_port_gsettings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	struct device_private *priv = (struct device_private *) dev->priv;
+	int status;
+
+	cmd->supported = 0;	/* tbd */
+	cmd->advertising = 0;	/* tbd */
+	status = cvmx_mgmt_port_get_link(priv->port);
+	switch (status) {
+	case 100:
+		/* 100Mbps, full duplex */
+		cmd->duplex = DUPLEX_FULL;
+		cmd->speed = SPEED_100;
+		break;
+	case 10:
+		/* 10Mbps, full duplex */
+		cmd->duplex = DUPLEX_FULL;
+		cmd->speed = SPEED_10;
+		break;
+	case -10:
+		/* 10Mbps, half duplex */
+		cmd->duplex = DUPLEX_HALF;
+		cmd->speed = SPEED_10;
+		break;
+	case -100:
+		/* 100Mbps, half duplex */
+		cmd->duplex = DUPLEX_HALF;
+		cmd->speed = SPEED_100;
+		break;
+	case 0:
+	default:
+		cmd->duplex = 0;
+		cmd->speed = 0;
+		break;
+	}
+	cmd->transceiver = XCVR_EXTERNAL;
+	cmd->port = PORT_MII;
+	cmd->phy_address = priv->port;
+	cmd->autoneg = 0;	/* tbd */
+	return 0;
+}
+
+static int mgmt_port_ssettings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	/* TBD */
+	return 0;
+}
+
+#define INFOSTR_LEN	32
+static void mgmt_port_gdrvinfo(struct net_device *dev,
+			       struct ethtool_drvinfo *drvinfo)
+{
+	strncpy(drvinfo->driver, "Cavium Octeon mgmt", INFOSTR_LEN);
+	strncpy(drvinfo->version, "0.0", INFOSTR_LEN);
+	strncpy(drvinfo->fw_version, "N/A", INFOSTR_LEN);
+	strncpy(drvinfo->bus_info, "N/A", INFOSTR_LEN);
+	drvinfo->n_stats = 0; /* TBD */
+	drvinfo->testinfo_len = 0;
+	drvinfo->regdump_len = 0;
+	drvinfo->eedump_len = 0;
+}
+
+static u32 mgmt_port_glink(struct net_device *dev)
+{
+	struct device_private *priv = (struct device_private *) dev->priv;
+	int status;
+
+	status = cvmx_mgmt_port_get_link(priv->port);
+	/* 0 means link down... otherwise, link is up */
+	return status != 0;
+}
+
+const struct ethtool_ops ethernet_mgmt_port_ethtool_ops = {
+	.get_settings = mgmt_port_gsettings,
+	.set_settings = mgmt_port_ssettings,
+	.get_drvinfo = mgmt_port_gdrvinfo,	/* ethtool_op_get_link */
+	.get_link = mgmt_port_glink,
+};
+
+/**
+ * Packet transmit
+ *
+ * @param skb    Packet to send
+ * @param dev    Device info structure
+ * @return Always returns zero
+ */
+static int packet_transmit(struct sk_buff *skb, struct net_device *dev)
+{
+	uint64_t flags;
+	struct device_private *priv = (struct device_private *) dev->priv;
+	cvmx_mgmt_port_result_t result;
+	cvmx_mixx_oring2_t mix_oring2;
+	int stop_queue = 0;
+
+	local_irq_save(flags);
+	mix_oring2.u64 = cvmx_read_csr(CVMX_MIXX_ORING2(priv->port));
+	/* stop interface queue if we know the next port_send() is going to
+	 * fail */
+	if (mix_oring2.s.odbell >= (CVMX_MGMT_PORT_NUM_TX_BUFFERS-2))
+		stop_queue = 1;
+	result = cvmx_mgmt_port_send(priv->port, skb->len, skb->data);
+	local_irq_restore(flags);
+	if (result == CVMX_MGMT_PORT_SUCCESS) {
+		priv->stats.tx_packets++;
+		priv->stats.tx_bytes += skb->len;
+		if (stop_queue)
+			netif_stop_queue(dev);
+	} else {
+		/* DEBUGPRINT("ERROR: cvmx_mgmt_port_send() failed with %d\n",
+				result);
+		*/
+		priv->stats.tx_dropped++;
+	}
+	dev_kfree_skb(skb);
+	return 0;
+}
+
+
+/**
+ * Interrupt handler. The interrupt occurs whenever the POW
+ * transitions from 0->1 packets in our group.
+ *
+ * @param cpl
+ * @param dev_id
+ * @param regs
+ * @return
+ */
+static irqreturn_t do_interrupt(int cpl, void *dev_id)
+{
+	uint64_t flags;
+	char dummy[1];
+	int result;
+	struct net_device *dev = (struct net_device *) dev_id;
+	struct device_private *priv = (struct device_private *) dev->priv;
+	cvmx_mixx_isr_t mixx_isr;
+
+	mixx_isr.u64 = cvmx_read_csr(CVMX_MIXX_ISR(priv->port));
+
+	/* check RX interrupts first */
+	if (mixx_isr.s.irthresh) {
+
+		do {
+			struct sk_buff *skb = dev_alloc_skb(dev->mtu+22);
+			local_irq_save(flags);
+			if (skb)
+				result = cvmx_mgmt_port_receive(priv->port,
+								dev->mtu+22,
+								skb->data);
+			else
+				result = cvmx_mgmt_port_receive(priv->port,
+								0, dummy);
+			local_irq_restore(flags);
+
+			/* Silently drop packets if we aren't up */
+			if ((dev->flags & IFF_UP) == 0) {
+				if (skb)
+					dev_kfree_skb(skb);
+				continue;
+			}
+
+			if (result > 0) {
+				skb_put(skb, result);
+				skb->protocol = eth_type_trans(skb, dev);
+				skb->dev = dev;
+				skb->ip_summed = CHECKSUM_NONE;
+				priv->stats.rx_bytes += skb->len;
+				priv->stats.rx_packets++;
+				netif_rx(skb);
+			} else if (result < 0) {
+				DEBUGPRINT
+					("%s: Receive error code %d, packet "
+					 "dropped\n", dev->name, result);
+				priv->stats.rx_errors++;
+				if (skb)
+					dev_kfree_skb(skb);
+			} else {
+				/* No packets to receive */
+				if (skb)
+					dev_kfree_skb(skb);
+			}
+		} while (result != 0);
+
+	}
+
+	/* check TX interrupts now */
+	if (mixx_isr.s.orthresh) {
+		if (cvmx_read_csr(CVMX_MIXX_ORCNT(priv->port)))
+			cvmx_write_csr(CVMX_MIXX_ORCNT(priv->port),
+				       cvmx_read_csr(
+					       CVMX_MIXX_ORCNT(priv->port)));
+
+		/* restart the queue now that we have space */
+		if (netif_queue_stopped(dev))  {
+			netif_wake_queue(dev);
+		}
+	}
+
+	/* Clear any pending interrupts */
+	cvmx_write_csr(CVMX_MIXX_ISR(priv->port),
+		       cvmx_read_csr(CVMX_MIXX_ISR(priv->port)));
+	cvmx_read_csr(CVMX_MIXX_ISR(priv->port));
+
+	return IRQ_HANDLED;
+}
+
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+/**
+ * This is called when the kernel needs to manually poll the
+ * device. For Octeon, this is simply calling the interrupt
+ * handler. We actually poll all the devices, not just the
+ * one supplied.
+ *
+ * @param dev    Device to poll. Unused
+ */
+static void device_poll_controller(struct net_device *dev)
+{
+	do_interrupt(0, dev);
+}
+#endif
+
+
+/**
+ * Open a device for use. Device should be able to send and
+ * receive packets after this is called.
+ *
+ * @param dev    Device to bring up
+ * @return Zero on success
+ */
+static int device_open(struct net_device *dev)
+{
+	/* Clear the statistics whenever the interface is brought up */
+	struct device_private *priv = (struct device_private *) dev->priv;
+	memset(&priv->stats, 0, sizeof(priv->stats));
+	cvmx_mgmt_port_enable(priv->port);
+	return 0;
+}
+
+
+/**
+ * Stop an ethernet device. No more packets should be
+ * received from this device.
+ *
+ * @param dev    Device to bring down
+ * @return Zero on success
+ */
+static int device_close(struct net_device *dev)
+{
+	struct device_private *priv = (struct device_private *) dev->priv;
+	cvmx_mgmt_port_disable(priv->port);
+	return 0;
+}
+
+
+/**
+ * Get the low level ethernet statistics
+ *
+ * @param dev    Device to get the statistics from
+ * @return Pointer to the statistics
+ */
+static struct net_device_stats *device_get_stats(struct net_device *dev)
+{
+	struct device_private *priv = (struct device_private *) dev->priv;
+	return &priv->stats;
+}
+
+
+/**
+ * Set the device MTU
+ *
+ * @param dev     Device to set
+ * @param new_mtu New MTU value
+ *
+ * @return
+ */
+static int device_mtu(struct net_device *dev, int new_mtu)
+{
+	struct device_private *priv = (struct device_private *) dev->priv;
+	/* Limit the MTU to make sure the ethernet packets are between 64 bytes
+	   and 16383 bytes */
+	if ((new_mtu + 14 < 64) || (new_mtu + 14 > 16383)) {
+		printk(KERN_INFO "MTU must be between %d and %d.\n",
+		       64 - 14, 16383 - 14);
+		return -EINVAL;
+	}
+	dev->mtu = new_mtu;
+	cvmx_mgmt_port_set_max_packet_size(priv->port, new_mtu + 14);
+	return 0;
+}
+
+
+/**
+ * Set the multicast list. Currently unimplemented.
+ *
+ * @param dev    Device to work on
+ */
+static void ethernet_mgmt_port_set_multicast_list(struct net_device *dev)
+{
+	struct device_private *priv = (struct device_private *)dev->priv;
+	int port = priv->port;
+	int num_ports;
+	if (OCTEON_IS_MODEL(OCTEON_CN52XX))
+		num_ports = 2;
+	else
+		num_ports = 1;
+	if (port < num_ports)
+		cvmx_mgmt_port_set_multicast_list(port, dev->flags);
+}
+
+/**
+ * Set the hardware MAC address for a management port device
+ *
+ * @param dev    Device to change the MAC address for
+ * @param addr   Address structure to change it too. MAC address is addr + 2.
+ * @return Zero on success
+ */
+static int ethernet_mgmt_port_set_mac_address(struct net_device *dev,
+						void *addr)
+{
+	struct device_private *priv = (struct device_private *) dev->priv;
+	cvmx_agl_gmx_prtx_cfg_t agl_gmx_cfg;
+	int port = priv->port;
+	int num_ports;
+
+	if (OCTEON_IS_MODEL(OCTEON_CN52XX))
+		num_ports = 2;
+	else
+		num_ports = 1;
+
+	memcpy(dev->dev_addr, addr + 2, 6);
+
+	if (port < num_ports) {
+		int i;
+		uint8_t *ptr = addr;
+		uint64_t mac = 0;
+		for (i = 0; i < 6; i++)
+			mac = (mac<<8) | (uint64_t)(ptr[i+2]);
+
+		agl_gmx_cfg.u64 = cvmx_read_csr(CVMX_AGL_GMX_PRTX_CFG(port));
+		cvmx_mgmt_port_set_mac(port, mac);
+		ethernet_mgmt_port_set_multicast_list(dev);
+		cvmx_write_csr(CVMX_AGL_GMX_PRTX_CFG(port), agl_gmx_cfg.u64);
+	}
+	return 0;
+}
+
+/**
+ * Per network device initialization
+ *
+ * @param dev    Device to initialize
+ * @return Zero on success
+ */
+static int device_init(struct net_device *dev)
+{
+	struct device_private *priv = (struct device_private *) dev->priv;
+	uint64_t mac = cvmx_mgmt_port_get_mac(priv->port);
+
+	dev->hard_start_xmit = packet_transmit;
+	dev->get_stats = device_get_stats;
+	dev->open = device_open;
+	dev->stop = device_close;
+	dev->change_mtu = device_mtu;
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	dev->poll_controller = device_poll_controller;
+#endif
+	dev->dev_addr[0] = (mac >> 40) & 0xff;
+	dev->dev_addr[1] = (mac >> 32) & 0xff;
+	dev->dev_addr[2] = (mac >> 24) & 0xff;
+	dev->dev_addr[3] = (mac >> 16) & 0xff;
+	dev->dev_addr[4] = (mac >> 8) & 0xff;
+	dev->dev_addr[5] = (mac >> 0) & 0xff;
+	return 0;
+}
+
+
+/**
+ * Module/ driver initialization. Creates the linux network
+ * devices.
+ *
+ * @return Zero on success
+ */
+static int __init ethernet_mgmt_port_init(void)
+{
+	struct net_device *dev;
+	struct device_private *priv;
+	cvmx_mixx_irhwm_t mix_irhwm;
+	cvmx_mixx_orhwm_t mix_orhwm;
+	cvmx_mixx_intena_t mix_intena;
+	int num_ports;
+	int port;
+
+	if (!OCTEON_IS_MODEL(OCTEON_CN56XX) && !OCTEON_IS_MODEL(OCTEON_CN52XX))
+		return 0;
+
+	if (OCTEON_IS_MODEL(OCTEON_CN52XX))
+		num_ports = 2;
+	else
+		num_ports = 1;
+
+	printk(KERN_INFO "Octeon management port ethernet driver\n");
+
+	for (port = 0; port < num_ports; port++) {
+		if (cvmx_mgmt_port_initialize(port) != CVMX_MGMT_PORT_SUCCESS) {
+			printk(KERN_ERR "ERROR: cvmx_mgmt_port_initialize(%d)"
+				" failed\n", port);
+			return -1;
+		}
+
+		/* Setup is complete, create the virtual ethernet devices */
+		dev = alloc_etherdev(sizeof(struct device_private));
+		if (dev == NULL) {
+			printk(KERN_ERR "ERROR: Failed to allocate device\n");
+			return -1;
+		}
+
+		dev->init = device_init;
+		strcpy(dev->name, "mgmt%d");
+
+		/* Initialize the device private structure. */
+		priv = (struct device_private *) dev->priv;
+		memset(priv, 0, sizeof(struct device_private));
+		priv->port = port;
+
+		if (register_netdev(dev) < 0) {
+			printk(KERN_ERR "ERROR: Failed to register device\n");
+			kfree(dev);
+			return -1;
+		}
+
+		/* Clear any pending interrupts */
+		cvmx_write_csr(CVMX_MIXX_ISR(priv->port),
+			       cvmx_read_csr(CVMX_MIXX_ISR(priv->port)));
+
+		/* Register an IRQ hander for to receive interrupts */
+		dev->irq =
+			(priv->port == 0) ? OCTEON_IRQ_MII0 : OCTEON_IRQ_MII1;
+		if (request_irq(dev->irq, do_interrupt, IRQF_SHARED, dev->name,
+			    dev))
+			pr_err("ethernet-mgmt: failed to assign interrupt %d\n", dev->irq);
+
+		/* Interrupt every single RX packet */
+		mix_irhwm.u64 = 0;
+		mix_irhwm.s.irhwm = 0;
+		cvmx_write_csr(CVMX_MIXX_IRHWM(priv->port), mix_irhwm.u64);
+
+		/* Interrupt when we have space for at least 5 pkts */
+		mix_orhwm.u64 = 0;
+		mix_orhwm.s.orhwm = 5;
+		cvmx_write_csr(CVMX_MIXX_ORHWM(priv->port), mix_orhwm.u64);
+
+		/* Enable receive and transmit interrupts */
+		mix_intena.u64 = 0;
+		mix_intena.s.ithena = 1;
+		mix_intena.s.othena = 1;
+		cvmx_write_csr(CVMX_MIXX_INTENA(priv->port), mix_intena.u64);
+
+		global_dev[priv->port] = dev;
+
+		dev->set_mac_address = ethernet_mgmt_port_set_mac_address;
+		dev->set_multicast_list = ethernet_mgmt_port_set_multicast_list;
+		dev->ethtool_ops = &ethernet_mgmt_port_ethtool_ops;
+	}
+	return 0;
+}
+
+
+/**
+ * Module / driver shutdown
+ *
+ * @return Zero on success
+ */
+static void __exit ethernet_mgmt_port_cleanup(void)
+{
+	int port;
+	for (port = 0; port < 2; port++) {
+		if (global_dev[port]) {
+			struct device_private *priv =
+				(struct device_private *)global_dev[port]->priv;
+			/* Disable interrupt */
+			cvmx_write_csr(CVMX_MIXX_IRHWM(priv->port), 0);
+			cvmx_write_csr(CVMX_MIXX_INTENA(priv->port), 0);
+			cvmx_mgmt_port_shutdown(priv->port);
+
+			/* Free the interrupt handler */
+			free_irq(global_dev[port]->irq, global_dev[port]);
+
+			/* Free the ethernet devices */
+			unregister_netdev(global_dev[port]);
+			kfree(global_dev[port]);
+			global_dev[port] = NULL;
+		}
+	}
+}
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Cavium Networks <support@caviumnetworks.com>");
+MODULE_DESCRIPTION("Cavium Networks Octeon management port ethernet driver.");
+module_init(ethernet_mgmt_port_init);
+module_exit(ethernet_mgmt_port_cleanup);
diff --git a/arch/mips/cavium-octeon/ethernet-pow.c b/arch/mips/cavium-octeon/ethernet-pow.c
new file mode 100644
index 0000000..3b750e2
--- /dev/null
+++ b/arch/mips/cavium-octeon/ethernet-pow.c
@@ -0,0 +1,745 @@
+/*
+ *   Octeon POW Ethernet Driver
+ *
+ * This file is subject to the terms and conditions of the GNU General Public
+ * License.  See the file "COPYING" in the main directory of this archive
+ * for more details.
+ *
+ * Copyright (C) 2005-2007 Cavium Networks
+ */
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/ip.h>
+#include <linux/string.h>
+#include <linux/delay.h>
+#include "hal.h"
+
+#define NUM_GROUPS      16	/* Total number of groups in Octeon */
+#define VIRTUAL_PORT    63	/* Value to put in work->ipprt */
+#define IP_PROTOCOL_TCP 6	/* IP header protocol for TCP */
+#define IP_PROTOCOL_UDP 0x11	/* IP header protocol for UDP */
+
+#define DEBUGPRINT(format, ...) do { if (printk_ratelimit()) 		\
+					printk(format, ##__VA_ARGS__);	\
+				} while (0)
+
+/* These are the Octeon CSR IO addresses we are going to need */
+#define OCTEON_POW_WQ_INT_THRX(offset)  (0x8001670000000080ull+((offset)*8))
+#define OCTEON_POW_WQ_INT               (0x8001670000000200ull)
+#define OCTEON_POW_PP_GRP_MSKX(offset)  (0x8001670000000000ull+((offset)*8))
+#define OCTEON_POW_WORK_SUBMIT(wqe)     (0x8001610000000000ull | (wqe))
+#define OCTEON_POW_WORK_REQUEST(wait)   (0x8001600000000000ull | (wait<<3))
+#define OCTEON_FPA_ALLOC(pool)          (0x8001280000000000ull | ((uint64_t)pool<<40))
+#define OCTEON_FPA_FREE(pool, address)  (0x8001280000000000ull | ((uint64_t)pool<<40) | (address))
+#define OCTEON_IPD_PACKET_MBUFF_SIZE    (0x80014F0000000010ull)
+#define OCTEON_IPD_WQE_FPA_QUEUE        (0x80014F0000000020ull)
+#define OCTEON_IPD_CTL_STATUS           (0x80014F0000000018ull)
+
+int receive_group = -1;
+module_param(receive_group, int, 0444);
+MODULE_PARM_DESC(receive_group,
+		 " 0-16 POW group to receive packets from. This must be unique in\n"
+		 "\t\tthe system. If you don't specify a value, the core ID will\n"
+		 "\t\tbe used.");
+
+int broadcast_groups;
+module_param(broadcast_groups, int, 0644);
+MODULE_PARM_DESC(broadcast_groups,
+		 " Bitmask of groups to send broadcasts to. This MUST be specified.\n"
+		 "\t\tWARNING: Be careful to not send broadcasts to groups that aren't\n"
+		 "\t\tread otherwise you may fill the POW and stop receiving packets.\n");
+
+/**
+ * This is the definition of the Ethernet driver's private
+ * driver state stored in dev->priv.
+ */
+typedef struct {
+	struct net_device_stats stats;	/* Device statistics */
+} device_private_t;
+
+/**
+ * This structure defines a buffer pointer on Octeon
+ */
+typedef union {
+	void *ptr;
+	uint64_t u64;
+	struct {
+		uint64_t i:1;
+		uint64_t back:4;
+		uint64_t pool:3;
+		uint64_t size:16;
+		uint64_t addr:40;
+	} s;
+} octeon_buf_ptr_t;
+
+/**
+ * Work queue entry format
+ */
+typedef struct {
+	uint16_t hw_chksum;
+	uint8_t unused;
+	uint64_t next_ptr:40;
+	uint64_t len:16;
+	uint64_t ipprt:6;
+	uint64_t qos:3;
+	uint64_t grp:4;
+	uint64_t tag_type:3;
+	uint64_t tag:32;
+	union {
+		uint64_t u64;
+		struct {
+			uint64_t bufs:8;
+			uint64_t ip_offset:8;
+			uint64_t vlan_valid:1;
+			uint64_t unassigned:2;
+			uint64_t vlan_cfi:1;
+			uint64_t vlan_id:12;
+			uint64_t unassigned2:12;
+			uint64_t dec_ipcomp:1;
+			uint64_t tcp_or_udp:1;
+			uint64_t dec_ipsec:1;
+			uint64_t is_v6:1;
+			uint64_t software:1;
+			uint64_t L4_error:1;
+			uint64_t is_frag:1;
+			uint64_t IP_exc:1;
+			uint64_t is_bcast:1;
+			uint64_t is_mcast:1;
+			uint64_t not_IP:1;
+			uint64_t rcv_error:1;
+			uint64_t err_code:8;
+		} s;
+		struct {
+			uint64_t bufs:8;
+			uint64_t unused:8;
+			uint64_t vlan_valid:1;
+			uint64_t unassigned:2;
+			uint64_t vlan_cfi:1;
+			uint64_t vlan_id:12;
+			uint64_t unassigned2:16;
+			uint64_t software:1;
+			uint64_t unassigned3:1;
+			uint64_t is_rarp:1;
+			uint64_t is_arp:1;
+			uint64_t is_bcast:1;
+			uint64_t is_mcast:1;
+			uint64_t not_IP:1;
+			uint64_t rcv_error:1;
+			uint64_t err_code:8;
+		} snoip;
+	} word2;
+	octeon_buf_ptr_t packet_ptr;
+	uint8_t packet_data[96];
+} octeon_wqe_t;
+
+static int fpa_wqe_pool = 1;	/* HW FPA pool to use for work queue entries */
+static int fpa_packet_pool;	/* HW FPA pool to use for packet buffers */
+static int fpa_packet_pool_size = 2048;	/* Size of the packet buffers */
+static struct net_device *global_device;
+
+
+/**
+ * Given a packet data address, return a pointer to the
+ * beginning of the packet buffer.
+ *
+ * @param packet_ptr Packet data hardware address
+ * @return Packet buffer pointer
+ */
+static inline void *get_buffer_ptr(octeon_buf_ptr_t packet_ptr)
+{
+	return phys_to_virt(((packet_ptr.s.addr >> 7) -
+			     packet_ptr.s.back) << 7);
+}
+
+
+/**
+ * Get a new block from the FPA
+ *
+ * @param pool   Pool to get the block from
+ * @return Pointer to the block or NULL on failure
+ */
+static inline void *fpa_alloc(uint64_t pool)
+{
+	uint64_t address = cvmx_read_csr(OCTEON_FPA_ALLOC(pool));
+	if (address)
+		return phys_to_virt(address);
+	else
+		return NULL;
+}
+
+
+/**
+ * Free a block allocated with a FPA pool.  Provides required memory
+ * ordering in cases where memory block was modified by core.
+ *
+ * @param ptr    Block to free
+ * @param pool   Pool to put it in
+ * @param num_cache_lines
+ *               Cache lines to invalidate
+ */
+static inline void fpa_free(void *ptr, int pool, int num_cache_lines)
+{
+	wmb();
+	cvmx_write_csr(OCTEON_FPA_FREE(pool, virt_to_phys(ptr)),
+		       num_cache_lines);
+}
+
+
+/**
+ * Submits work to an input queue.  This function updates the work queue entry in DRAM to match
+ * the arguments given.
+ * Note that the tag provided is for the work queue entry submitted, and is unrelated to the tag that
+ * the core currently holds.
+ *
+ * @param wqp      pointer to work queue entry to submit.  This entry is updated to match the other parameters
+ * @param tag      tag value to be assigned to work queue entry
+ * @param tag_type type of tag
+ * @param qos      Input queue to add to.
+ * @param grp      group value for the work queue entry.
+ */
+static inline void pow_work_submit(octeon_wqe_t *wqp, uint32_t tag,
+				   uint64_t tag_type, uint64_t qos,
+				   uint64_t grp)
+{
+	uint64_t tag_req =
+		(4ull << 44) | (qos << 39) | (grp << 35) | (tag_type << 32) |
+		tag;
+	wmb();
+	cvmx_write_csr(OCTEON_POW_WORK_SUBMIT(virt_to_phys(wqp)), tag_req);
+}
+
+
+/**
+ * Synchronous work request.  Requests work from the POW.
+ * This function does NOT wait for previous tag switches to complete,
+ * so the caller must ensure that there is not a pending tag switch.
+ *
+ * @param wait   When set, call stalls until work becomes avaiable, or times out.
+ *               If not set, returns immediately.
+ *
+ * @return Returns the WQE pointer from POW. Returns NULL if no work was available.
+ */
+static inline octeon_wqe_t *pow_work_request_sync(int wait)
+{
+	int64_t result = cvmx_read_csr(OCTEON_POW_WORK_REQUEST(wait));
+	if (result < 0)
+		return NULL;
+	else
+		return (octeon_wqe_t *) phys_to_virt(result);
+}
+
+
+/**
+ * Free a work queue entry received in a intercept callback.
+ *
+ * @param work_queue_entry
+ *               Work queue entry to free
+ * @return Zero on success, Negative on failure.
+ */
+static int free_work(octeon_wqe_t *work)
+{
+	int segments = work->word2.s.bufs;
+	octeon_buf_ptr_t segment_ptr = work->packet_ptr;
+
+	while (segments--) {
+		octeon_buf_ptr_t next_ptr =
+			*(octeon_buf_ptr_t *) phys_to_virt(segment_ptr.s.addr -
+							   8);
+		if (unlikely(!segment_ptr.s.i))
+			fpa_free(get_buffer_ptr(segment_ptr),
+				 segment_ptr.s.pool, 0);
+		segment_ptr = next_ptr;
+	}
+	fpa_free(work, fpa_wqe_pool, 0);
+
+	return 0;
+}
+
+
+/**
+ * Packet transmit to the POW
+ *
+ * @param skb    Packet to send
+ * @param dev    Device info structure
+ * @return Always returns zero
+ */
+static int packet_transmit(struct sk_buff *skb, struct net_device *dev)
+{
+	device_private_t *priv = (device_private_t *) dev->priv;
+	octeon_wqe_t *work = NULL;
+	void *packet_buffer = NULL;
+	void *copy_location;
+	int send_group_mask;
+	int send_group;
+
+	/* Any unknown MAC address goes to all groups in the module param
+	   broadcast_groups. Known MAC addresses use the low order dest mac
+	   byte as the group number */
+	if ((*(uint64_t *) (skb->data) >> 16) < 0x01ff)
+		send_group_mask = 1 << (skb->data[5] & (NUM_GROUPS - 1));
+	else
+		send_group_mask = broadcast_groups;
+	send_group_mask &= ~(1 << receive_group);
+
+	/* It is ugly, but we need to send multiple times for broadcast
+	   packets. The hardware doesn't support submitting work to multiple
+	   groups */
+	for (send_group = 0; send_group < NUM_GROUPS; send_group++) {
+		/* Don't transmit to groups not in our send_group_mask */
+		if (likely((send_group_mask & (1 << send_group)) == 0))
+			continue;
+
+		/* Get a work queue entry */
+		work = fpa_alloc(fpa_wqe_pool);
+		if (unlikely(work == NULL)) {
+			DEBUGPRINT
+				("%s: Failed to allocate a work queue entry\n",
+				 dev->name);
+			goto fail;
+		}
+
+		/* Get a packet buffer */
+		packet_buffer = fpa_alloc(fpa_packet_pool);
+		if (unlikely(packet_buffer == NULL)) {
+			DEBUGPRINT("%s: Failed to allocate a packet buffer\n",
+				   dev->name);
+			goto fail;
+		}
+
+		/* Calculate where we need to copy the data to. We need to
+		   leave 8 bytes for a next pointer (unused). Then we need to
+		   align the IP packet src and dest into the same 64bit word. */
+		copy_location = packet_buffer + sizeof(uint64_t) + 6;
+
+		/* Fail if the packet won't fit in a single buffer */
+		if (unlikely
+		    (copy_location + skb->len >
+		     packet_buffer + fpa_packet_pool_size)) {
+			DEBUGPRINT("%s: Packet too large for FPA buffer\n",
+				   dev->name);
+			goto fail;
+		}
+
+		memcpy(copy_location, skb->data, skb->len);
+
+		/* Fill in some of the work queue fields. We may need to add
+		   more if the software at the other end needs them */
+		work->hw_chksum = skb->csum;
+		work->len = skb->len;
+		work->ipprt = VIRTUAL_PORT;
+		work->qos = 0;
+		work->grp = send_group;
+		work->tag_type = 2;
+		work->tag = 0;
+		work->word2.u64 = 0;	/* Default to zero. Sets of zero later
+					   are commented out */
+		work->word2.s.bufs = 1;
+		work->packet_ptr.u64 = 0;
+		work->packet_ptr.s.addr = virt_to_phys(copy_location);
+		work->packet_ptr.s.pool = fpa_packet_pool;
+		work->packet_ptr.s.size = fpa_packet_pool_size;
+		work->packet_ptr.s.back = (copy_location - packet_buffer) >> 7;
+
+		if (skb->protocol == htons(ETH_P_IP)) {
+			work->word2.s.ip_offset = 14;
+			#if 0
+			work->word2.s.vlan_valid = 0;	/* FIXME */
+			work->word2.s.vlan_cfi = 0;	/* FIXME */
+			work->word2.s.vlan_id = 0;	/* FIXME */
+			work->word2.s.dec_ipcomp = 0;	/* FIXME */
+			#endif
+			work->word2.s.tcp_or_udp =
+				(ip_hdr(skb)->protocol == IP_PROTOCOL_TCP) ||
+				(ip_hdr(skb)->protocol == IP_PROTOCOL_UDP);
+			#if 0
+			work->word2.s.dec_ipsec = 0; /* FIXME */
+			work->word2.s.is_v6 = 0; /* We only support IPv4
+						    right now */
+			work->word2.s.software = 0; /* Hardware would set to
+						       zero */
+			work->word2.s.L4_error = 0; /* No error, packet is
+						       internal */
+			#endif
+			work->word2.s.is_frag = !((ip_hdr(skb)->frag_off == 0)
+						  || (ip_hdr(skb)->frag_off ==
+						      1 << 14));
+			#if 0
+			work->word2.s.IP_exc = 0; /* Assume Linux is sending
+						     a good packet */
+			#endif
+			work->word2.s.is_bcast =
+				(skb->pkt_type == PACKET_BROADCAST);
+			work->word2.s.is_mcast =
+				(skb->pkt_type == PACKET_MULTICAST);
+			#if 0
+			work->word2.s.not_IP = 0; /* This is an IP packet */
+			work->word2.s.rcv_error = 0; /* No error, packet is
+							internal */
+			work->word2.s.err_code = 0;  /* No error, packet is
+							internal */
+			#endif
+
+			/* When copying the data, include 4 bytes of the
+			   ethernet header to align the same way hardware does */
+			memcpy(work->packet_data, skb->data + 10,
+			       sizeof(work->packet_data));
+		} else {
+			#if 0
+			work->word2.snoip.vlan_valid = 0; /* FIXME */
+			work->word2.snoip.vlan_cfi = 0;   /* FIXME */
+			work->word2.snoip.vlan_id = 0;    /* FIXME */
+			work->word2.snoip.software = 0;   /* Hardware would
+							     set to zero */
+			#endif
+			work->word2.snoip.is_rarp =
+				skb->protocol == htons(ETH_P_RARP);
+			work->word2.snoip.is_arp =
+				skb->protocol == htons(ETH_P_ARP);
+			work->word2.snoip.is_bcast =
+				(skb->pkt_type == PACKET_BROADCAST);
+			work->word2.snoip.is_mcast =
+				(skb->pkt_type == PACKET_MULTICAST);
+			work->word2.snoip.not_IP = 1;	/* IP was done up above */
+			#if 0
+			work->word2.snoip.rcv_error = 0; /* No error, packet
+							    is internal */
+			work->word2.snoip.err_code = 0;  /* No error, packet
+							    is internal */
+			#endif
+			memcpy(work->packet_data, skb->data,
+			       sizeof(work->packet_data));
+		}
+
+		/* Submit the packet to the POW */
+		pow_work_submit(work, work->tag, work->tag_type, work->qos,
+				work->grp);
+		work = NULL;
+		packet_buffer = NULL;
+	}
+
+	priv->stats.tx_packets++;
+	priv->stats.tx_bytes += skb->len;
+	dev_kfree_skb(skb);
+	return 0;
+
+fail:
+	if (work)
+		fpa_free(work, fpa_wqe_pool, 0);
+	if (packet_buffer)
+		fpa_free(packet_buffer, fpa_packet_pool, 0);
+	priv->stats.tx_dropped++;
+	dev_kfree_skb(skb);
+	return 0;
+}
+
+
+/**
+ * Interrupt handler. The interrupt occurs whenever the POW
+ * transitions from 0->1 packets in our group.
+ *
+ * @param cpl
+ * @param dev_id
+ * @param regs
+ * @return
+ */
+static irqreturn_t do_interrupt(int cpl, void *dev_id)
+{
+	const uint64_t coreid = cvmx_get_core_num();
+	struct net_device *dev = (struct net_device *) dev_id;
+	device_private_t *priv = (device_private_t *) dev->priv;
+	uint64_t old_group_mask;
+	octeon_wqe_t *work;
+	struct sk_buff *skb;
+
+	/* Make sure any userspace operations are complete */
+	asm volatile ("synciobdma" : : : "memory");
+
+	/* Acknowledge the interrupt */
+	cvmx_write_csr(OCTEON_POW_WQ_INT, 0x10001 << receive_group);
+
+	/* Only allow work for our group */
+	old_group_mask = cvmx_read_csr(OCTEON_POW_PP_GRP_MSKX(coreid));
+	cvmx_write_csr(OCTEON_POW_PP_GRP_MSKX(coreid), 1 << receive_group);
+
+	while (1) {
+		work = pow_work_request_sync(0);
+		if (work == NULL)
+			break;
+
+		/* Silently drop packets that have the wrong input port */
+		if (work->ipprt != VIRTUAL_PORT) {
+			free_work(work);
+			continue;
+		}
+
+		/* Silently drop packets if we aren't up */
+		if ((dev->flags & IFF_UP) == 0) {
+			free_work(work);
+			continue;
+		}
+
+		/* Throw away all packets with receive errors */
+		if (unlikely(work->word2.snoip.rcv_error)) {
+			DEBUGPRINT
+				("%s: Receive error code %d, packet dropped\n",
+				 dev->name, work->word2.snoip.err_code);
+			free_work(work);
+			priv->stats.rx_errors++;
+			continue;
+		}
+
+		/* We have to copy the packet. First allocate an skbuff for it */
+		skb = dev_alloc_skb(work->len);
+		if (!skb) {
+			DEBUGPRINT
+				("%s: Failed to allocate skbuff, packet dropped\n",
+				 dev->name);
+			free_work(work);
+			priv->stats.rx_dropped++;
+			continue;
+		}
+
+		/* Check if we've received a packet that was entirely stored
+		   the work entry. This is untested */
+		if (unlikely(work->word2.s.bufs == 0)) {
+			DEBUGPRINT
+				("%s: Received a work with work->word2.s.bufs=0, untested\n",
+				 dev->name);
+			memcpy(skb_put(skb, work->len), work->packet_data,
+			       work->len);
+		} else {
+			int segments = work->word2.s.bufs;
+			octeon_buf_ptr_t segment_ptr = work->packet_ptr;
+			int len = work->len;
+			while (segments--) {
+				octeon_buf_ptr_t next_ptr =
+					*(octeon_buf_ptr_t *)
+					phys_to_virt(segment_ptr.s.addr - 8);
+				/* Octeon Errata PKI-100: The segment size is
+				   wrong. Until it is fixed, calculate the
+				   segment size based on the packet pool buffer
+				   size. When it is fixed, the following line
+				   should be replaced with this one: int
+				   segment_size = segment_ptr.s.size; */
+				int segment_size =
+					fpa_packet_pool_size -
+					(segment_ptr.s.addr -
+					 (((segment_ptr.s.addr >> 7) -
+					   segment_ptr.s.back) << 7));
+				/* Don't copy more than what is left in the
+				   packet */
+				if (segment_size > len)
+					segment_size = len;
+				/* Copy the data into the packet */
+				memcpy(skb_put(skb, segment_size),
+				       phys_to_virt(segment_ptr.s.addr),
+				       segment_size);
+				/* Reduce the amount of bytes left to copy */
+				len -= segment_size;
+				segment_ptr = next_ptr;
+			}
+		}
+		free_work(work);
+		skb->protocol = eth_type_trans(skb, dev);
+		skb->dev = dev;
+		skb->ip_summed = CHECKSUM_NONE;
+		priv->stats.rx_bytes += skb->len;
+		priv->stats.rx_packets++;
+		netif_rx(skb);
+	}
+
+	/* Restore the original POW group mask */
+	cvmx_write_csr(OCTEON_POW_PP_GRP_MSKX(coreid), old_group_mask);
+	return IRQ_HANDLED;
+}
+
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+/**
+ * This is called when the kernel needs to manually poll the
+ * device. For Octeon, this is simply calling the interrupt
+ * handler. We actually poll all the devices, not just the
+ * one supplied.
+ *
+ * @param dev    Device to poll. Unused
+ */
+static void device_poll_controller(struct net_device *dev)
+{
+	do_interrupt(0, dev);
+}
+#endif
+
+
+/**
+ * Open a device for use. Device should be able to send and
+ * receive packets after this is called.
+ *
+ * @param dev    Device to bring up
+ * @return Zero on success
+ */
+static int device_open(struct net_device *dev)
+{
+	/* Clear the statistics whenever the interface is brought up */
+	device_private_t *priv = (device_private_t *) dev->priv;
+	memset(&priv->stats, 0, sizeof(priv->stats));
+	return 0;
+}
+
+
+/**
+ * Stop an ethernet device. No more packets should be
+ * received from this device.
+ *
+ * @param dev    Device to bring down
+ * @return Zero on success
+ */
+static int device_close(struct net_device *dev)
+{
+	/* Nothing to do */
+	return 0;
+}
+
+
+/**
+ * Get the low level ethernet statistics
+ *
+ * @param dev    Device to get the statistics from
+ * @return Pointer to the statistics
+ */
+static struct net_device_stats *device_get_stats(struct net_device *dev)
+{
+	device_private_t *priv = (device_private_t *) dev->priv;
+	return &priv->stats;
+}
+
+
+/**
+ * Per network device initialization
+ *
+ * @param dev    Device to initialize
+ * @return Zero on success
+ */
+static int device_init(struct net_device *dev)
+{
+	dev->hard_start_xmit = packet_transmit;
+	dev->get_stats = device_get_stats;
+	dev->open = device_open;
+	dev->stop = device_close;
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	dev->poll_controller = device_poll_controller;
+#endif
+	dev->features |= NETIF_F_LLTX;	/* We do our own locking, Linux doesn't
+					   need to */
+	dev->dev_addr[0] = 0;
+	dev->dev_addr[1] = 0;
+	dev->dev_addr[2] = 0;
+	dev->dev_addr[3] = 0;
+	dev->dev_addr[4] = 1;
+	dev->dev_addr[5] = cvmx_get_core_num();
+	return 0;
+}
+
+
+/**
+ * Module/ driver initialization. Creates the linux network
+ * devices.
+ *
+ * @return Zero on success
+ */
+static int __init ethernet_pow_init(void)
+{
+	device_private_t *priv;
+
+	if ((receive_group >= NUM_GROUPS)) {
+		printk("\n\nERROR: Invalid receive group. Must be 0-%d\n",
+		       NUM_GROUPS - 1);
+		return -1;
+	}
+
+	if (!broadcast_groups) {
+		printk("\n\nERROR: You must specify a broadcast group mask.\n");
+		return -1;
+	}
+
+	if ((broadcast_groups & ((1 << NUM_GROUPS) - 1)) != broadcast_groups) {
+		printk("\n\nERROR: Invalid broadcast group mask.\n");
+		return -1;
+	}
+
+	printk("Octeon POW only ethernet driver\n");
+
+	/* If a receive group isn't specified, default to the core id */
+	if (receive_group < 0)
+		receive_group = cvmx_get_core_num();
+
+	/* Setup is complete, create the virtual ethernet devices */
+	global_device = alloc_etherdev(sizeof(device_private_t));
+	if (global_device == NULL) {
+		printk("\n\nERROR: Failed to allocate ethernet device\n");
+		return -1;
+	}
+
+	global_device->init = device_init;
+	strcpy(global_device->name, "oct%d");
+
+	/* Initialize the device private structure. */
+	priv = (device_private_t *) global_device->priv;
+	memset(priv, 0, sizeof(device_private_t));
+
+	/* Spin waiting for another core to setup all the hardware */
+	printk("Waiting for another core to setup the IPD hardware...");
+	while ((cvmx_read_csr(OCTEON_IPD_CTL_STATUS) & 1) == 0)
+		mdelay(100);
+
+	printk("Done\n");
+
+	/* Read the configured size of the FPA packet buffers. This way we
+	   don't need changes if someone chooses to use a different buffer size */
+	fpa_packet_pool_size =
+		(cvmx_read_csr(OCTEON_IPD_PACKET_MBUFF_SIZE) & 0xfff) * 8;
+
+	/* Read the work queue pool */
+	fpa_wqe_pool = cvmx_read_csr(OCTEON_IPD_WQE_FPA_QUEUE) & 7;
+
+	if (register_netdev(global_device) < 0) {
+		printk("\n\nERROR: Failed to register ethernet device\n");
+		kfree(global_device);
+		return -1;
+	}
+
+	/* Register an IRQ hander for to receive POW interrupts */
+	if (request_irq(OCTEON_IRQ_WORKQ0 + receive_group, do_interrupt, IRQF_SHARED,
+			"POW Ethernet", global_device)) {
+	}
+
+	/* Enable POW interrupt when our port has at least one packet */
+	cvmx_write_csr(OCTEON_POW_WQ_INT_THRX(receive_group), 0x1001);
+	return 0;
+}
+
+
+/**
+ * Module / driver shutdown
+ *
+ * @return Zero on success
+ */
+static void __exit ethernet_pow_cleanup(void)
+{
+	/* Disable POW interrupt */
+	cvmx_write_csr(OCTEON_POW_WQ_INT_THRX(receive_group), 0);
+
+	/* Free the interrupt handler */
+	free_irq(OCTEON_IRQ_WORKQ0 + receive_group, global_device);
+
+	/* Free the ethernet devices */
+	unregister_netdev(global_device);
+	kfree(global_device);
+}
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Cavium Networks <support@caviumnetworks.com>");
+MODULE_DESCRIPTION("Cavium Networks Octeon internal only POW ethernet driver.");
+module_init(ethernet_pow_init);
+module_exit(ethernet_pow_cleanup);
diff --git a/drivers/net/Kconfig b/drivers/net/Kconfig
index 280f7de..9bb9413 100644
--- a/drivers/net/Kconfig
+++ b/drivers/net/Kconfig
@@ -2303,6 +2303,8 @@ config ATL1E
 	  To compile this driver as a module, choose M here.  The module
 	  will be called atl1e.
 
+source "drivers/net/cavium-ethernet/Kconfig"
+
 endif # NETDEV_1000
 
 #
diff --git a/drivers/net/Makefile b/drivers/net/Makefile
index de81c8a..ccb4189 100644
--- a/drivers/net/Makefile
+++ b/drivers/net/Makefile
@@ -247,7 +247,6 @@ obj-$(CONFIG_IRDA) += irda/
 obj-$(CONFIG_ETRAX_ETHERNET) += cris/
 obj-$(CONFIG_ENP2611_MSF_NET) += ixp2000/
 
-obj-$(CONFIG_NETCONSOLE) += netconsole.o
 obj-$(CONFIG_KGDBOE) += kgdboe.o
 
 obj-$(CONFIG_FS_ENET) += fs_enet/
@@ -256,4 +255,7 @@ obj-$(CONFIG_NETXEN_NIC) += netxen/
 obj-$(CONFIG_NIU) += niu.o
 obj-$(CONFIG_VIRTIO_NET) += virtio_net.o
 obj-$(CONFIG_SFC) += sfc/
+obj-$(CONFIG_CAVIUM_ETHERNET) += cavium-ethernet/
+
+obj-$(CONFIG_NETCONSOLE) += netconsole.o
 
diff --git a/drivers/net/cavium-ethernet/Kconfig b/drivers/net/cavium-ethernet/Kconfig
new file mode 100644
index 0000000..d822538
--- /dev/null
+++ b/drivers/net/cavium-ethernet/Kconfig
@@ -0,0 +1,12 @@
+config CAVIUM_ETHERNET
+	tristate "Cavium Networks Octeon Ethernet support"
+	depends on CPU_CAVIUM_OCTEON
+	select MII
+	help
+	  This driver supports the builtin ethernet ports on Cavium
+	  Networks products in the Octeon family. This driver supports the
+	  CN3XXX and CN5XXX Octeon processors.
+
+	  To compile this driver as a module, choose M here.  The module
+	  will be called cavium-ethernet.
+
diff --git a/drivers/net/cavium-ethernet/Makefile b/drivers/net/cavium-ethernet/Makefile
new file mode 100644
index 0000000..c2beea0
--- /dev/null
+++ b/drivers/net/cavium-ethernet/Makefile
@@ -0,0 +1,60 @@
+# Author: Cavium Networks info@caviumnetworks.com
+#
+# Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+# reserved.
+#
+# Redistribution and use in source and binary forms, with or without
+# modification, are permitted provided that the following conditions are
+# met:
+#
+#     * Redistributions of source code must retain the above copyright
+#       notice, this list of conditions and the following disclaimer.
+#
+#     * Redistributions in binary form must reproduce the above
+#       copyright notice, this list of conditions and the following
+#       disclaimer in the documentation and/or other materials provided
+#       with the distribution.
+#
+#     * Neither the name of Cavium Networks nor the names of
+#       its contributors may be used to endorse or promote products
+#       derived from this software without specific prior written
+#       permission.
+#
+# TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+# AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+# OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+# RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+# REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+# DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+# OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+# PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+# POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+# OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+
+# Common flags to be passed for driver compilation
+OCTEON_ROOT_IN_KERNEL = $(srctree)/arch/mips/cavium-octeon
+OCTEON_ROOT = $(srctree)/../../host-cross/mips-wrs-linux-gnu/sysroot/usr/include/simple_exec_open
+
+EXTRA_CFLAGS += -Winline -Wall \
+	-I $(srctree)/arch/mips/cavium-octeon \
+	-I $(srctree)/arch/mips/cavium-octeon/gpl-executive/config \
+	-I ${OCTEON_ROOT}/target/include \
+	-I ${OCTEON_ROOT_IN_KERNEL}/executive
+
+obj-${CONFIG_CAVIUM_ETHERNET} :=  cavium-ethernet.o
+
+cavium-ethernet-objs := ethernet.o
+cavium-ethernet-objs += ethernet-common.o
+cavium-ethernet-objs += ethernet-mdio.o
+cavium-ethernet-objs += ethernet-mem.o
+cavium-ethernet-objs += ethernet-proc.o
+cavium-ethernet-objs += ethernet-rgmii.o
+cavium-ethernet-objs += ethernet-rx.o
+cavium-ethernet-objs += ethernet-sgmii.o
+cavium-ethernet-objs += ethernet-spi.o
+cavium-ethernet-objs += ethernet-tx.o
+cavium-ethernet-objs += ethernet-xaui.o
+
+clean:
+	rm -rf .*.cmd *.mod.c *.o *.ko .tmp_versions
+
diff --git a/drivers/net/cavium-ethernet/cavium-ethernet.h b/drivers/net/cavium-ethernet/cavium-ethernet.h
new file mode 100644
index 0000000..750de22
--- /dev/null
+++ b/drivers/net/cavium-ethernet/cavium-ethernet.h
@@ -0,0 +1,176 @@
+/*************************************************************************
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+
+/**
+ * @file
+ * External interface for the Cavium Octeon ethernet driver.
+ *
+ * $Id: cavium-ethernet.h 34415 2008-05-13 16:08:27Z kreese $
+ *
+ */
+#ifndef CAVIUM_ETHERNET_H
+#define CAVIUM_ETHERNET_H
+
+/**
+ * These enumerations are the return codes for the Ethernet
+ * driver intercept callback. Depending on the return code,
+ * the ethernet driver will continue processing in different
+ * ways.
+ */
+typedef enum {
+	CVM_OCT_PASS,               /**< The ethernet driver will pass the packet
+					to the kernel, just as if the intercept
+					callback didn't exist */
+	CVM_OCT_DROP,               /**< The ethernet driver will drop the packet,
+					cleaning of the work queue entry and the
+					skbuff */
+	CVM_OCT_TAKE_OWNERSHIP_WORK,/**< The intercept callback takes over
+					ownership of the work queue entry. It is
+					the responsibility of the callback to free
+					the work queue entry and all associated
+					packet buffers. The ethernet driver will
+					dispose of the skbuff without affecting the
+					work queue entry */
+	CVM_OCT_TAKE_OWNERSHIP_SKB  /**< The intercept callback takes over
+					ownership of the skbuff. The work queue
+					entry and packet buffer will be disposed of
+					in a way keeping the skbuff valid */
+} cvm_oct_callback_result_t;
+
+
+/**
+ * The is the definition of the Ethernet driver intercept
+ * callback. The callback receives three parameters and
+ * returns a struct cvm_oct_callback_result code.
+ *
+ * The first parameter is the linux device for the ethernet
+ * port the packet came in on.
+ * The second parameter is the raw work queue entry from the
+ * hardware.
+ * Th third parameter is the packet converted into a Linux
+ * skbuff.
+ */
+typedef cvm_oct_callback_result_t (*cvm_oct_callback_t)(struct net_device *dev, void *work_queue_entry, struct sk_buff *skb);
+
+/**
+ * This is the definition of the Ethernet driver's private
+ * driver state stored in netdev_priv(dev).
+ */
+typedef struct {
+	int                     port;           /* PKO hardware output port */
+	int                     queue;          /* PKO hardware queue for the port */
+	int                     fau;            /* Hardware fetch and add to count outstanding tx buffers */
+	int                     imode;          /* Type of port. This is one of the enums in cvmx_helper_interface_mode_t */
+	struct sk_buff_head     tx_free_list[16];/* List of outstanding tx buffers per queue */
+	/* Keeping intercept_cb close the the part of stats that is most often
+	 * modified helps throughput. */
+	cvm_oct_callback_t      intercept_cb;   /* Optional intecept callback
+						 *  defined above */
+	struct net_device_stats stats;          /* Device statistics */
+	struct mii_if_info      mii_info;       /* Generic MII info structure */
+	uint64_t                link_info;      /* Last negotiated link state */
+	void (*poll)(struct net_device *dev);   /* Called periodically to check link status */
+} cvm_oct_private_t;
+
+
+/**
+ * Registers a intercept callback for the names ethernet
+ * device. It returns the Linux device structure for the
+ * ethernet port. Usign a callback of NULL will remove
+ * the callback. Note that this callback must not disturb
+ * scratch. It will be called with SYNCIOBDMAs in progress
+ * and userspace may be using scratch. It also must not
+ * disturb the group mask.
+ *
+ * @param device_name
+ *                 Device name to register for. (Example: "eth0")
+ * @param callback Intercept callback to set.
+ * @return Device structure for the ethernet port or NULL on failure.
+ */
+struct net_device *cvm_oct_register_callback(const char *device_name, cvm_oct_callback_t callback);
+
+
+/**
+ * Free a work queue entry received in a intercept callback.
+ *
+ * @param work_queue_entry
+ *               Work queue entry to free
+ * @return Zero on success, Negative on failure.
+ */
+int cvm_oct_free_work(void *work_queue_entry);
+
+
+/**
+ * Transmit a work queue entry out of the ethernet port. Both
+ * the work queue entry and the packet data can optionally be
+ * freed. The work will be freed on error as well.
+ *
+ * @param dev     Device to transmit out.
+ * @param work_queue_entry
+ *                Work queue entry to send
+ * @param do_free True if the work queue entry and packet data should be
+ *                freed. If false, neither will be freed.
+ * @param qos     Index into the queues for this port to transmit on. This
+ *                is used to implement QoS if their are multiple queues per
+ *                port. This parameter must be between 0 and the number of
+ *                queues per port minus 1. Values outside of this range will
+ *                be change to zero.
+ *
+ * @return Zero on success, negative on failure.
+ */
+int cvm_oct_transmit_qos(struct net_device *dev, void *work_queue_entry, int do_free, int qos);
+
+
+/**
+ * Transmit a work queue entry out of the ethernet port. Both
+ * the work queue entry and the packet data can optionally be
+ * freed. The work will be freed on error as well. This simply
+ * wraps cvmx_oct_transmit_qos() for backwards compatability.
+ *
+ * @param dev     Device to transmit out.
+ * @param work_queue_entry
+ *                Work queue entry to send
+ * @param do_free True if the work queue entry and packet data should be
+ *                freed. If false, neither will be freed.
+ *
+ * @return Zero on success, negative on failure.
+ */
+static inline int cvm_oct_transmit(struct net_device *dev, void *work_queue_entry, int do_free)
+{
+	return cvm_oct_transmit_qos(dev, work_queue_entry, do_free, 0);
+}
+
+#endif
diff --git a/drivers/net/cavium-ethernet/ethernet-common.c b/drivers/net/cavium-ethernet/ethernet-common.c
new file mode 100644
index 0000000..02aed05
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-common.c
@@ -0,0 +1,286 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/kernel.h>
+#include <linux/mii.h>
+#include <net/dst.h>
+
+#include "wrapper-cvmx-includes.h"
+#include "ethernet-headers.h"
+
+extern int octeon_is_simulation(void);
+extern cvmx_bootinfo_t *octeon_bootinfo;
+extern int pow_send_group;
+extern int always_use_pow;
+extern char pow_send_list[];
+
+
+/**
+ * Get the low level ethernet statistics
+ *
+ * @param dev    Device to get the statistics from
+ * @return Pointer to the statistics
+ */
+static struct net_device_stats *cvm_oct_common_get_stats(struct net_device *dev)
+{
+	cvmx_pip_port_status_t rx_status;
+	cvmx_pko_port_status_t tx_status;
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+
+	if (priv->port < CVMX_PIP_NUM_INPUT_PORTS) {
+		if (octeon_is_simulation()) {
+			/* The simulator doesn't support statistics */
+			memset(&rx_status, 0, sizeof(rx_status));
+			memset(&tx_status, 0, sizeof(tx_status));
+		} else {
+		cvmx_pip_get_port_status(priv->port, 1, &rx_status);
+		cvmx_pko_get_port_status(priv->port, 1, &tx_status);
+		}
+
+		priv->stats.rx_packets      += rx_status.inb_packets;
+		priv->stats.tx_packets      += tx_status.packets;
+		priv->stats.rx_bytes        += rx_status.inb_octets;
+		priv->stats.tx_bytes        += tx_status.octets;
+		priv->stats.multicast       += rx_status.multicast_packets;
+		priv->stats.rx_crc_errors   += rx_status.inb_errors;
+		priv->stats.rx_frame_errors += rx_status.fcs_align_err_packets;
+
+		/* The drop counter must be incremented atomically since the RX
+		   tasklet also increments it */
+#ifdef CONFIG_64BIT
+		cvmx_atomic_add64_nosync(&priv->stats.rx_dropped, rx_status.dropped_packets);
+#else
+		cvmx_atomic_add32_nosync((int32_t *)&priv->stats.rx_dropped, rx_status.dropped_packets);
+#endif
+	}
+
+	return &priv->stats;
+}
+
+
+/**
+ * Set the multicast list. Currently unimplemented.
+ *
+ * @param dev    Device to work on
+ */
+static void cvm_oct_common_set_multicast_list(struct net_device *dev)
+{
+	cvmx_gmxx_prtx_cfg_t gmx_cfg;
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int interface = INTERFACE(priv->port);
+	int index = INDEX(priv->port);
+
+	if ((interface < 2) && (cvmx_helper_interface_get_mode(interface) != CVMX_HELPER_INTERFACE_MODE_SPI)) {
+		cvmx_gmxx_rxx_adr_ctl_t control;
+		control.u64 = 0;
+		control.s.bcst = 1;     /* Allow broadcast MAC addresses */
+
+		if (dev->mc_list || (dev->flags&IFF_ALLMULTI) ||
+		    (dev->flags & IFF_PROMISC))
+			control.s.mcst = 2; /* Force accept multicast packets */
+		else
+			control.s.mcst = 1; /* Force reject multicat packets */
+
+		if (dev->flags & IFF_PROMISC)
+			control.s.cam_mode = 0; /* Reject matches if promisc. Since CAM is shut off, should accept everything */
+		else
+			control.s.cam_mode = 1; /* Filter packets based on the CAM */
+
+		gmx_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));
+		cvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmx_cfg.u64 & ~1ull);
+
+		cvmx_write_csr(CVMX_GMXX_RXX_ADR_CTL(index, interface), control.u64);
+		if (dev->flags&IFF_PROMISC)
+			cvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM_EN(index, interface), 0);
+		else
+			cvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM_EN(index, interface), 1);
+
+		cvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmx_cfg.u64);
+	}
+}
+
+
+/**
+ * Set the hardware MAC address for a device
+ *
+ * @param dev    Device to change the MAC address for
+ * @param addr   Address structure to change it too. MAC address is addr + 2.
+ * @return Zero on success
+ */
+static int cvm_oct_common_set_mac_address(struct net_device *dev, void *addr)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	cvmx_gmxx_prtx_cfg_t gmx_cfg;
+	int interface = INTERFACE(priv->port);
+	int index = INDEX(priv->port);
+
+	memcpy(dev->dev_addr, addr + 2, 6);
+
+	if ((interface < 2) && (cvmx_helper_interface_get_mode(interface) != CVMX_HELPER_INTERFACE_MODE_SPI)) {
+		int i;
+		uint8_t *ptr = addr;
+		uint64_t mac = 0;
+		for (i = 0; i < 6; i++)
+			mac = (mac<<8) | (uint64_t)(ptr[i+2]);
+
+		gmx_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));
+		cvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmx_cfg.u64 & ~1ull);
+
+		cvmx_write_csr(CVMX_GMXX_SMACX(index, interface), mac);
+		cvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM0(index, interface), ptr[2]);
+		cvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM1(index, interface), ptr[3]);
+		cvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM2(index, interface), ptr[4]);
+		cvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM3(index, interface), ptr[5]);
+		cvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM4(index, interface), ptr[6]);
+		cvmx_write_csr(CVMX_GMXX_RXX_ADR_CAM5(index, interface), ptr[7]);
+		cvm_oct_common_set_multicast_list(dev);
+		cvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmx_cfg.u64);
+	}
+	return 0;
+}
+
+
+/**
+ * Change the link MTU. Unimplemented
+ *
+ * @param dev     Device to change
+ * @param new_mtu The new MTU
+ * @return Zero on success
+ */
+static int cvm_oct_common_change_mtu(struct net_device *dev, int new_mtu)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int interface = INTERFACE(priv->port);
+	int index = INDEX(priv->port);
+#if defined(CONFIG_VLAN_8021Q) || defined(CONFIG_VLAN_8021Q_MODULE)
+	int vlan_bytes = 4;
+#else
+	int vlan_bytes = 0;
+#endif
+
+	/* Limit the MTU to make sure the ethernet packets are between 64 bytes
+	   and 65535 bytes */
+	if ((new_mtu + 14 + 4 + vlan_bytes < 64) ||
+	    (new_mtu + 14 + 4 + vlan_bytes > 65392)) {
+		printk(KERN_INFO "MTU must be between %d and %d.\n",
+		       64-14-4-vlan_bytes, 65392-14-4-vlan_bytes);
+		return -EINVAL;
+	}
+	dev->mtu = new_mtu;
+
+	if ((interface < 2) && (cvmx_helper_interface_get_mode(interface) != CVMX_HELPER_INTERFACE_MODE_SPI)) {
+		/* Add ethernet header and FCS, and VLAN if configured. */
+		int max_packet = new_mtu + 14 + 4 + vlan_bytes;
+
+		if (OCTEON_IS_MODEL(OCTEON_CN3XXX) || OCTEON_IS_MODEL(OCTEON_CN58XX)) {
+			/* Signal errors on packets larger than the MTU */
+			cvmx_write_csr(CVMX_GMXX_RXX_FRM_MAX(index, interface), max_packet);
+		} else {
+			/* Set the hardware to truncate packets larger than the MTU and
+				smaller the 64 bytes */
+			cvmx_pip_frm_len_chkx_t frm_len_chk;
+			frm_len_chk.u64 = 0;
+			frm_len_chk.s.minlen = 64;
+			frm_len_chk.s.maxlen = max_packet;
+			cvmx_write_csr(CVMX_PIP_FRM_LEN_CHKX(interface), frm_len_chk.u64);
+		}
+		/* Set the hardware to truncate packets larger than the MTU. The
+		   jabber register must be set to a multiple of 8 bytes, so round up */
+		cvmx_write_csr(CVMX_GMXX_RXX_JABBER(index, interface), (max_packet + 7) & ~7u);
+	}
+	return 0;
+}
+
+
+/**
+ * Per network device initialization
+ *
+ * @param dev    Device to initialize
+ * @return Zero on success
+ */
+int cvm_oct_common_init(struct net_device *dev)
+{
+	static int count;
+	char mac[8] = {0x00, 0x00,
+		octeon_bootinfo->mac_addr_base[0],
+		octeon_bootinfo->mac_addr_base[1],
+		octeon_bootinfo->mac_addr_base[2],
+		octeon_bootinfo->mac_addr_base[3],
+		octeon_bootinfo->mac_addr_base[4],
+		octeon_bootinfo->mac_addr_base[5] + count};
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+
+
+	/* Force the interface to use the POW send if always_use_pow was
+	   specified or it is in the pow send list */
+	if ((pow_send_group != -1) && (always_use_pow || strstr(pow_send_list, dev->name)))
+		priv->queue = -1;
+
+	if (priv->queue != -1) {
+		dev->hard_start_xmit = cvm_oct_xmit;
+		if (USE_HW_TCPUDP_CHECKSUM)
+			dev->features |= NETIF_F_IP_CSUM;
+	} else
+		dev->hard_start_xmit = cvm_oct_xmit_pow;
+	count++;
+
+	dev->get_stats          = cvm_oct_common_get_stats;
+	dev->set_mac_address    = cvm_oct_common_set_mac_address;
+	dev->set_multicast_list = cvm_oct_common_set_multicast_list;
+	dev->change_mtu         = cvm_oct_common_change_mtu;
+	dev->do_ioctl           = cvm_oct_ioctl;
+	dev->features           |= NETIF_F_LLTX; /* We do our own locking, Linux doesn't need to */
+	SET_ETHTOOL_OPS(dev, &cvm_oct_ethtool_ops);
+#ifdef CONFIG_NET_POLL_CONTROLLER
+	dev->poll_controller    = cvm_oct_poll_controller;
+#endif
+
+	cvm_oct_mdio_setup_device(dev);
+	dev->set_mac_address(dev, mac);
+	dev->change_mtu(dev, dev->mtu);
+
+	/* Zero out stats for port so we won't mistakenly show counters from the
+	   bootloader */
+	memset(dev->get_stats(dev), 0, sizeof(struct net_device_stats));
+
+	return 0;
+}
+
+void cvm_oct_common_uninit(struct net_device *dev)
+{
+    /* Currently nothing to do */
+}
+
diff --git a/drivers/net/cavium-ethernet/ethernet-common.h b/drivers/net/cavium-ethernet/ethernet-common.h
new file mode 100644
index 0000000..9adf6ce
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-common.h
@@ -0,0 +1,40 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+
+int cvm_oct_common_init(struct net_device *dev);
+void cvm_oct_common_uninit(struct net_device *dev);
+
diff --git a/drivers/net/cavium-ethernet/ethernet-defines.h b/drivers/net/cavium-ethernet/ethernet-defines.h
new file mode 100644
index 0000000..2ed49df
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-defines.h
@@ -0,0 +1,117 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+
+/*
+ * A few defines are used to control the operation of this driver:
+ *  CONFIG_CAVIUM_RESERVE32
+ *      This kernel config options controls the amount of memory configured
+ *      in a wired TLB entry for all processes to share. If this is set, the
+ *      driver will use this memory instead of kernel memory for pools. This
+ *      allows 32bit userspace application to access the buffers, but also
+ *      requires all received packets to be copied.
+ *  CONFIG_CAVIUM_OCTEON_NUM_PACKET_BUFFERS
+ *      This kernel config option allows the user to control the number of
+ *      packet and work queue buffers allocated by the driver. If this is zero,
+ *      the driver uses the default from below.
+ *  USE_SKBUFFS_IN_HW
+ *      Tells the driver to populate the packet buffers with kernel skbuffs.
+ *      This allows the driver to receive packets without copying them. It also
+ *      means that 32bit userspace can't access the packet buffers.
+ *  USE_32BIT_SHARED
+ *      This define tells the driver to allocate memory for buffers from the
+ *      32bit sahred region instead of the kernel memory space.
+ *  USE_HW_TCPUDP_CHECKSUM
+ *      Controls if the Octeon TCP/UDP checksum engine is used for packet
+ *      output. If this is zero, the kernel will perform the checksum in
+ *      software.
+ *  USE_MULTICORE_RECEIVE
+ *      Process receive interrupts on multiple cores. This spreads the network
+ *      load across the first 8 processors. If ths is zero, only one core
+ *      processes incomming packets.
+ *  USE_ASYNC_IOBDMA
+ *      Use asynchronous IO access to hardware. This uses Octeon's asynchronous
+ *      IOBDMAs to issue IO accesses without stalling. Set this to zero
+ *      to disable this. Note that IOBDMAs require CVMSEG.
+ *  REUSE_SKBUFFS_WITHOUT_FREE
+ *      Allows the TX path to free an skbuff into the FPA hardware pool. This
+ *      can significantly improve performance for forwarding and bridging, but
+ *      may be somewhat dangerous. Checks are made, but if any buffer is reused
+ *      without the proper Linux cleanup, the networking stack may have very
+ *      bizarre bugs.
+ */
+#ifndef CONFIG_CAVIUM_RESERVE32
+#define CONFIG_CAVIUM_RESERVE32 0
+#endif
+
+#if CONFIG_CAVIUM_RESERVE32
+	#define USE_32BIT_SHARED            1
+	#define USE_SKBUFFS_IN_HW           0
+	#define REUSE_SKBUFFS_WITHOUT_FREE  0
+#else
+	#define USE_32BIT_SHARED            0
+	#define USE_SKBUFFS_IN_HW           1
+	#ifdef CONFIG_NETFILTER
+		#define REUSE_SKBUFFS_WITHOUT_FREE  0
+	#else
+		#define REUSE_SKBUFFS_WITHOUT_FREE  1
+	#endif
+#endif
+
+#define INTERRUPT_LIMIT             10000   /* Max interrupts per second per core */
+/*#define INTERRUPT_LIMIT             0     *//* Don't limit the number of interrupts */
+#define USE_HW_TCPUDP_CHECKSUM      1
+#define USE_MULTICORE_RECEIVE       1
+#define USE_RED                     1	/* Enable Random Early Dropping under load */
+#define USE_ASYNC_IOBDMA            (CONFIG_CAVIUM_OCTEON_CVMSEG_SIZE > 0)
+#define USE_10MBPS_PREAMBLE_WORKAROUND 1    /* Allow SW based preamble removal at 10Mbps to workaround PHYs giving us bad preambles */
+#define DONT_WRITEBACK(x)           (x) /* Use this to have all FPA frees also tell the L2 not to write data to memory */
+/*#define DONT_WRITEBACK(x)         0   *//* Use this to not have FPA frees control L2 */
+
+/* Maximum number of packets to process per interrupt. */
+#define MAX_RX_PACKETS 120
+#define MAX_OUT_QUEUE_DEPTH 1000
+
+#ifndef CONFIG_SMP
+#undef USE_MULTICORE_RECEIVE
+#define USE_MULTICORE_RECEIVE 0
+#endif
+
+#define IP_PROTOCOL_TCP             6
+#define IP_PROTOCOL_UDP             0x11
+#define FAU_NUM_PACKET_BUFFERS_TO_FREE (CVMX_FAU_REG_END - sizeof(uint32_t))
+#define TOTAL_NUMBER_OF_PORTS       (CVMX_PIP_NUM_INPUT_PORTS+1)
+
diff --git a/drivers/net/cavium-ethernet/ethernet-headers.h b/drivers/net/cavium-ethernet/ethernet-headers.h
new file mode 100644
index 0000000..c2cef17
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-headers.h
@@ -0,0 +1,50 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#ifndef __ETHERNET_HEADERS_H__
+#define __ETHERNET_HEADERS_H__
+
+#include "cavium-ethernet.h"
+#include "ethernet-common.h"
+#include "ethernet-defines.h"
+#include "ethernet-mdio.h"
+#include "ethernet-mem.h"
+#include "ethernet-proc.h"
+#include "ethernet-rx.h"
+#include "ethernet-tx.h"
+#include "ethernet-util.h"
+
+#endif
diff --git a/drivers/net/cavium-ethernet/ethernet-mdio.c b/drivers/net/cavium-ethernet/ethernet-mdio.c
new file mode 100644
index 0000000..6ed1c35
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-mdio.c
@@ -0,0 +1,242 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/kernel.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <net/dst.h>
+
+#include "cvmx-sysinfo.h"
+#include "wrapper-cvmx-includes.h"
+#include "ethernet-headers.h"
+
+DECLARE_MUTEX(mdio_sem);
+
+
+/**
+ * Perform an MII read. Called by the generic MII routines
+ *
+ * @param dev      Device to perform read for
+ * @param phy_id   The MII phy id
+ * @param location Register location to read
+ * @return Result from the read or zero on failure
+ */
+static int cvm_oct_mdio_read(struct net_device *dev, int phy_id, int location)
+{
+	cvmx_smi_cmd_t          smi_cmd;
+	cvmx_smi_rd_dat_t       smi_rd;
+
+	smi_cmd.u64 = 0;
+	smi_cmd.s.phy_op = 1;
+	smi_cmd.s.phy_adr = phy_id;
+	smi_cmd.s.reg_adr = location;
+	cvmx_write_csr(CVMX_SMI_CMD, smi_cmd.u64);
+
+	do {
+		if (!in_interrupt())
+			yield();
+		smi_rd.u64 = cvmx_read_csr(CVMX_SMI_RD_DAT);
+	} while (smi_rd.s.pending);
+
+	if (smi_rd.s.val)
+		return smi_rd.s.dat;
+	else
+		return 0;
+}
+
+static int cvm_oct_mdio_dummy_read(struct net_device *dev, int phy_id, int location)
+{
+    return 0xffff;
+}
+
+
+/**
+ * Perform an MII write. Called by the generic MII routines
+ *
+ * @param dev      Device to perform write for
+ * @param phy_id   The MII phy id
+ * @param location Register location to write
+ * @param val      Value to write
+ */
+static void cvm_oct_mdio_write(struct net_device *dev, int phy_id, int location, int val)
+{
+	cvmx_smi_cmd_t          smi_cmd;
+	cvmx_smi_wr_dat_t       smi_wr;
+
+	smi_wr.u64 = 0;
+	smi_wr.s.dat = val;
+	cvmx_write_csr(CVMX_SMI_WR_DAT, smi_wr.u64);
+
+	smi_cmd.u64 = 0;
+	smi_cmd.s.phy_op = 0;
+	smi_cmd.s.phy_adr = phy_id;
+	smi_cmd.s.reg_adr = location;
+	cvmx_write_csr(CVMX_SMI_CMD, smi_cmd.u64);
+
+	do {
+		if (!in_interrupt())
+			yield();
+		smi_wr.u64 = cvmx_read_csr(CVMX_SMI_WR_DAT);
+	} while (smi_wr.s.pending);
+}
+
+static void cvm_oct_mdio_dummy_write(struct net_device *dev, int phy_id, int location, int val)
+{
+}
+
+
+static void cvm_oct_get_drvinfo(struct net_device *dev, struct ethtool_drvinfo *info)
+{
+	strcpy(info->driver, "cavium-ethernet");
+	strcpy(info->version, OCTEON_SDK_VERSION_STRING);
+	strcpy(info->bus_info, "Builtin");
+}
+
+
+static int cvm_oct_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int ret;
+
+	down(&mdio_sem);
+	ret = mii_ethtool_gset(&priv->mii_info, cmd);
+	up(&mdio_sem);
+
+	return ret;
+}
+
+
+static int cvm_oct_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int ret;
+
+	down(&mdio_sem);
+	ret =  mii_ethtool_sset(&priv->mii_info, cmd);
+	up(&mdio_sem);
+
+	return ret;
+}
+
+
+static int cvm_oct_nway_reset(struct net_device *dev)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int ret;
+
+	down(&mdio_sem);
+	ret = mii_nway_restart(&priv->mii_info);
+	up(&mdio_sem);
+
+	return ret;
+}
+
+
+static u32 cvm_oct_get_link(struct net_device *dev)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	u32 ret;
+
+	down(&mdio_sem);
+	ret = mii_link_ok(&priv->mii_info);
+	up(&mdio_sem);
+
+	return ret;
+}
+
+
+struct ethtool_ops cvm_oct_ethtool_ops = {
+	.get_drvinfo    = cvm_oct_get_drvinfo,
+	.get_settings   = cvm_oct_get_settings,
+	.set_settings   = cvm_oct_set_settings,
+	.nway_reset     = cvm_oct_nway_reset,
+	.get_link       = cvm_oct_get_link,
+	.get_sg         = ethtool_op_get_sg,
+	.get_tx_csum    = ethtool_op_get_tx_csum,
+};
+
+
+/**
+ * IOCTL support for PHY control
+ *
+ * @param dev    Device to change
+ * @param rq     the request
+ * @param cmd    the command
+ * @return Zero on success
+ */
+int cvm_oct_ioctl(struct net_device *dev, struct ifreq *rq, int cmd)
+{
+	cvm_oct_private_t      *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	struct mii_ioctl_data  *data = if_mii(rq);
+	unsigned int            duplex_chg;
+	int ret;
+
+	down(&mdio_sem);
+	ret = generic_mii_ioctl(&priv->mii_info, data, cmd, &duplex_chg);
+	up(&mdio_sem);
+
+	return ret;
+}
+
+
+/**
+ * Setup the MDIO device structures
+ *
+ * @param dev    Device to setup
+ *
+ * @return Zero on success, negative on failure
+ */
+int cvm_oct_mdio_setup_device(struct net_device *dev)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int phy_id = cvmx_helper_board_get_mii_address(priv->port);
+	if (phy_id != -1) {
+		priv->mii_info.dev = dev;
+		priv->mii_info.phy_id = phy_id;
+		priv->mii_info.phy_id_mask = 0xff;
+		priv->mii_info.supports_gmii = 1;
+		priv->mii_info.reg_num_mask = 0x1f;
+		priv->mii_info.mdio_read = cvm_oct_mdio_read;
+		priv->mii_info.mdio_write = cvm_oct_mdio_write;
+	} else {
+		/* Supply dummy MDIO routines so the kernel won't crash
+		   if the user tries to read them */
+		priv->mii_info.mdio_read = cvm_oct_mdio_dummy_read;
+		priv->mii_info.mdio_write = cvm_oct_mdio_dummy_write;
+	}
+	return 0;
+}
+
diff --git a/drivers/net/cavium-ethernet/ethernet-mdio.h b/drivers/net/cavium-ethernet/ethernet-mdio.h
new file mode 100644
index 0000000..f00a810
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-mdio.h
@@ -0,0 +1,59 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/init.h>
+#include <linux/etherdevice.h>
+#include <linux/ip.h>
+#include <linux/string.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/seq_file.h>
+#include <linux/proc_fs.h>
+#include <net/dst.h>
+#ifdef CONFIG_XFRM
+#include <linux/xfrm.h>
+#include <net/xfrm.h>
+#endif  /* CONFIG_XFRM */
+
+extern struct ethtool_ops cvm_oct_ethtool_ops;
+extern struct semaphore mdio_sem;
+
+int cvm_oct_ioctl(struct net_device *dev, struct ifreq *rq, int cmd);
+int cvm_oct_mdio_setup_device(struct net_device *dev);
+
diff --git a/drivers/net/cavium-ethernet/ethernet-mem.c b/drivers/net/cavium-ethernet/ethernet-mem.c
new file mode 100644
index 0000000..9e44bfa
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-mem.c
@@ -0,0 +1,194 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/mii.h>
+#include <net/dst.h>
+
+#include "wrapper-cvmx-includes.h"
+#include "ethernet-headers.h"
+
+/**
+ * Fill the supplied hardware pool with skbuffs
+ *
+ * @param pool     Pool to allocate an skbuff for
+ * @param size     Size of the buffer needed for the pool
+ * @param elements Number of buffers to allocate
+ */
+static int cvm_oct_fill_hw_skbuff(int pool, int size, int elements)
+{
+	int freed = elements;
+	while (freed) {
+
+		struct sk_buff *skb = dev_alloc_skb(size + 128);
+		if (unlikely(skb == NULL)) {
+			pr_warning("Failed to allocate skb for hardware pool %d\n",
+				   pool);
+			break;
+		}
+
+		skb_reserve(skb, 128 - (((unsigned long)skb->data) & 0x7f));
+		*(struct sk_buff **)(skb->data - sizeof(void *)) = skb;
+		cvmx_fpa_free(skb->data, pool, DONT_WRITEBACK(size/128));
+		freed--;
+	}
+	return elements - freed;
+}
+
+
+/**
+ * Free the supplied hardware pool of skbuffs
+ *
+ * @param pool     Pool to allocate an skbuff for
+ * @param size     Size of the buffer needed for the pool
+ * @param elements Number of buffers to allocate
+ */
+static void cvm_oct_free_hw_skbuff(int pool, int size, int elements)
+{
+	char *memory;
+
+	do {
+		memory = cvmx_fpa_alloc(pool);
+		if (memory) {
+			struct sk_buff *skb = *(struct sk_buff **)(memory - sizeof(void *));
+			elements--;
+			dev_kfree_skb(skb);
+		}
+	} while (memory);
+
+	if (elements < 0)
+		printk("Warning: Freeing of pool %u had too many skbuffs (%d)\n", pool, elements);
+	else if (elements > 0)
+		printk("Warning: Freeing of pool %u is missing %d skbuffs\n", pool, elements);
+}
+
+
+/**
+ * This function fills a hardware pool with memory. Depending
+ * on the config defines, this memory might come from the
+ * kernel or global 32bit memory allocated with
+ * cvmx_bootmem_alloc.
+ *
+ * @param pool     Pool to populate
+ * @param size     Size of each buffer in the pool
+ * @param elements Number of buffers to allocate
+ */
+static int cvm_oct_fill_hw_memory(int pool, int size, int elements)
+{
+	char *memory;
+	int freed = elements;
+
+	if (USE_32BIT_SHARED) {
+		extern uint64_t octeon_reserve32_memory;
+
+		memory = cvmx_bootmem_alloc_range(elements*size, 128, octeon_reserve32_memory,
+						octeon_reserve32_memory + (CONFIG_CAVIUM_RESERVE32<<20) - 1);
+		if (memory == NULL)
+			panic("Unable to allocate %u bytes for FPA pool %d\n", elements*size, pool);
+
+		printk("Memory range %p - %p reserved for hardware\n", memory, memory + elements*size - 1);
+
+		while (freed) {
+			cvmx_fpa_free(memory, pool, 0);
+			memory += size;
+			freed--;
+		}
+	} else {
+		while (freed) {
+			/* We need to force alignment to 128 bytes here */
+			memory = kmalloc(size + 127, GFP_ATOMIC);
+			if (unlikely(memory == NULL)) {
+				pr_warning("Unable to allocate %u bytes for FPA pool %d\n",
+					   elements*size, pool);
+				break;
+			}
+			memory = (char *)(((unsigned long)memory+127) & -128);
+			cvmx_fpa_free(memory, pool, 0);
+			freed--;
+		}
+	}
+	return elements - freed;
+}
+
+
+/**
+ * Free memory previously allocated with cvm_oct_fill_hw_memory
+ *
+ * @param pool     FPA pool to free
+ * @param size     Size of each buffer in the pool
+ * @param elements Number of buffers that should be in the pool
+ */
+static void cvm_oct_free_hw_memory(int pool, int size, int elements)
+{
+	if (USE_32BIT_SHARED) {
+		printk("Warning: 32 shared memory is not freeable\n");
+	} else {
+		char *memory;
+		do {
+			memory = cvmx_fpa_alloc(pool);
+			if (memory) {
+				elements--;
+				kfree(phys_to_virt(cvmx_ptr_to_phys(memory)));
+			}
+		} while (memory);
+
+		if (elements < 0)
+			printk("Freeing of pool %u had too many buffers (%d)\n", pool, elements);
+		else if (elements > 0)
+			printk("Warning: Freeing of pool %u is missing %d buffers\n", pool, elements);
+	}
+}
+
+
+int cvm_oct_mem_fill_fpa(int pool, int size, int elements)
+{
+	int freed;
+	if (USE_SKBUFFS_IN_HW)
+		freed = cvm_oct_fill_hw_skbuff(pool, size, elements);
+	else
+		freed = cvm_oct_fill_hw_memory(pool, size, elements);
+	return freed;
+}
+
+void cvm_oct_mem_empty_fpa(int pool, int size, int elements)
+{
+	if (USE_SKBUFFS_IN_HW)
+		cvm_oct_free_hw_skbuff(pool, size, elements);
+	else
+		cvm_oct_free_hw_memory(pool, size, elements);
+}
+
diff --git a/drivers/net/cavium-ethernet/ethernet-mem.h b/drivers/net/cavium-ethernet/ethernet-mem.h
new file mode 100644
index 0000000..aa95efc
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-mem.h
@@ -0,0 +1,40 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+
+int cvm_oct_mem_fill_fpa(int pool, int size, int elements);
+void cvm_oct_mem_empty_fpa(int pool, int size, int elements);
+
diff --git a/drivers/net/cavium-ethernet/ethernet-proc.c b/drivers/net/cavium-ethernet/ethernet-proc.c
new file mode 100644
index 0000000..8d4706f
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-proc.c
@@ -0,0 +1,256 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+ TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/kernel.h>
+#include <linux/mii.h>
+#include <linux/seq_file.h>
+#include <linux/proc_fs.h>
+#include <net/dst.h>
+
+#include "wrapper-cvmx-includes.h"
+#include "ethernet-headers.h"
+
+extern struct net_device *cvm_oct_device[];
+
+
+static unsigned long long cvm_oct_stats_read_switch(struct net_device *dev, int phy_id, int offset)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	priv->mii_info.mdio_write(dev, phy_id, 0x1d, 0xcc00 | offset);
+	return ((uint64_t)priv->mii_info.mdio_read(dev, phy_id, 0x1e)<<16) | (uint64_t)priv->mii_info.mdio_read(dev, phy_id, 0x1f);
+}
+
+static int cvm_oct_stats_switch_show(struct seq_file *m, void *v)
+{
+	static const int ports[] = {0, 1, 2, 3, 9, -1};
+	struct net_device *dev = cvm_oct_device[0];
+	int index = 0;
+
+	while (ports[index] != -1) {
+
+		/* Latch port */
+		cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+		priv->mii_info.mdio_write(dev, 0x1b, 0x1d, 0xdc00 | ports[index]);
+		seq_printf(m, "\nSwitch Port %d\n", ports[index]);
+		seq_printf(m, "InGoodOctets:   %12llu\t"
+			   "OutOctets:      %12llu\t"
+			   "64 Octets:      %12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x00) | (cvm_oct_stats_read_switch(dev, 0x1b, 0x01)<<32),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x0E) | (cvm_oct_stats_read_switch(dev, 0x1b, 0x0F)<<32),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x08));
+
+		seq_printf(m, "InBadOctets:    %12llu\t"
+			   "OutUnicast:     %12llu\t"
+			   "65-127 Octets:  %12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x02),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x10),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x09));
+
+		seq_printf(m, "InUnicast:      %12llu\t"
+			   "OutBroadcasts:  %12llu\t"
+			   "128-255 Octets: %12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x04),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x13),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x0A));
+
+		seq_printf(m, "InBroadcasts:   %12llu\t"
+			   "OutMulticasts:  %12llu\t"
+			   "256-511 Octets: %12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x06),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x12),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x0B));
+
+		seq_printf(m, "InMulticasts:   %12llu\t"
+			   "OutPause:       %12llu\t"
+			   "512-1023 Octets:%12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x07),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x15),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x0C));
+
+		seq_printf(m, "InPause:        %12llu\t"
+			   "Excessive:      %12llu\t"
+			   "1024-Max Octets:%12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x16),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x11),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x0D));
+
+		seq_printf(m, "InUndersize:    %12llu\t"
+			   "Collisions:     %12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x18),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x1E));
+
+		seq_printf(m, "InFragments:    %12llu\t"
+			   "Deferred:       %12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x19),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x05));
+
+		seq_printf(m, "InOversize:     %12llu\t"
+			   "Single:         %12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x1A),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x14));
+
+		seq_printf(m, "InJabber:       %12llu\t"
+			   "Multiple:       %12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x1B),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x17));
+
+		seq_printf(m, "In RxErr:       %12llu\t"
+			   "OutFCSErr:      %12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x1C),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x03));
+
+		seq_printf(m, "InFCSErr:       %12llu\t"
+			   "Late:           %12llu\n",
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x1D),
+			   cvm_oct_stats_read_switch(dev, 0x1b, 0x1F));
+		index++;
+	}
+	return 0;
+}
+
+/**
+ * User is reading /proc/octeon_ethernet_stats
+ *
+ * @param m
+ * @param v
+ * @return
+ */
+static int cvm_oct_stats_show(struct seq_file *m, void *v)
+{
+	cvm_oct_private_t *priv;
+	int port;
+
+	for (port = 0; port < TOTAL_NUMBER_OF_PORTS; port++) {
+
+		if (cvm_oct_device[port]) {
+
+			priv = (cvm_oct_private_t *)netdev_priv(cvm_oct_device[port]);
+			seq_printf(m, "\nOcteon Port %d (%s)\n", port, cvm_oct_device[port]->name);
+			seq_printf(m,
+				   "rx_packets:             %12lu\t"
+				   "tx_packets:             %12lu\n",
+				   priv->stats.rx_packets,
+				   priv->stats.tx_packets);
+			seq_printf(m,
+				   "rx_bytes:               %12lu\t"
+				   "tx_bytes:               %12lu\n",
+				   priv->stats.rx_bytes,
+				   priv->stats.tx_bytes);
+			seq_printf(m,
+				   "rx_errors:              %12lu\t"
+				   "tx_errors:              %12lu\n",
+				   priv->stats.rx_errors,
+				   priv->stats.tx_errors);
+			seq_printf(m,
+				   "rx_dropped:             %12lu\t"
+				   "tx_dropped:             %12lu\n",
+				   priv->stats.rx_dropped,
+				   priv->stats.tx_dropped);
+			seq_printf(m,
+				   "rx_length_errors:       %12lu\t"
+				   "tx_aborted_errors:      %12lu\n",
+				   priv->stats.rx_length_errors,
+				   priv->stats.tx_aborted_errors);
+			seq_printf(m,
+				   "rx_over_errors:         %12lu\t"
+				   "tx_carrier_errors:      %12lu\n",
+				   priv->stats.rx_over_errors,
+				   priv->stats.tx_carrier_errors);
+			seq_printf(m,
+				   "rx_crc_errors:          %12lu\t"
+				   "tx_fifo_errors:         %12lu\n",
+				   priv->stats.rx_crc_errors,
+				   priv->stats.tx_fifo_errors);
+			seq_printf(m,
+				   "rx_frame_errors:        %12lu\t"
+				   "tx_heartbeat_errors:    %12lu\n",
+				   priv->stats.rx_frame_errors,
+				   priv->stats.tx_heartbeat_errors);
+			seq_printf(m,
+				   "rx_fifo_errors:         %12lu\t"
+				   "tx_window_errors:       %12lu\n",
+				   priv->stats.rx_fifo_errors,
+				   priv->stats.tx_window_errors);
+			seq_printf(m,
+				   "rx_missed_errors:       %12lu\t"
+				   "multicast:              %12lu\n",
+				   priv->stats.rx_missed_errors,
+				   priv->stats.multicast);
+		}
+	}
+
+	if (cvm_oct_device[0]) {
+		priv = (cvm_oct_private_t *)netdev_priv(cvm_oct_device[0]);
+		if (priv->imode == CVMX_HELPER_INTERFACE_MODE_GMII)
+			cvm_oct_stats_switch_show(m, v);
+	}
+	return 0;
+}
+
+
+/**
+ * /proc/octeon_ethernet_stats was openned. Use the single_open iterator
+ *
+ * @param inode
+ * @param file
+ * @return
+ */
+static int cvm_oct_stats_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, cvm_oct_stats_show, NULL);
+}
+
+
+static struct file_operations cvm_oct_stats_operations = {
+	.open		= cvm_oct_stats_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+
+void cvm_oct_proc_initialize(void)
+{
+	struct proc_dir_entry *entry = create_proc_entry("octeon_ethernet_stats", 0, NULL);
+	if (entry)
+		entry->proc_fops = &cvm_oct_stats_operations;
+}
+
+void cvm_oct_proc_shutdown(void)
+{
+	remove_proc_entry("octeon_ethernet_stats", NULL);
+}
+
diff --git a/drivers/net/cavium-ethernet/ethernet-proc.h b/drivers/net/cavium-ethernet/ethernet-proc.h
new file mode 100644
index 0000000..6dd32da
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-proc.h
@@ -0,0 +1,40 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+
+void cvm_oct_proc_initialize(void);
+void cvm_oct_proc_shutdown(void);
+
diff --git a/drivers/net/cavium-ethernet/ethernet-rgmii.c b/drivers/net/cavium-ethernet/ethernet-rgmii.c
new file mode 100644
index 0000000..88018ba
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-rgmii.c
@@ -0,0 +1,331 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/mii.h>
+#include <net/dst.h>
+
+#include "wrapper-cvmx-includes.h"
+#include "ethernet-headers.h"
+
+extern int octeon_is_simulation(void);
+extern struct net_device *cvm_oct_device[];
+
+DEFINE_SPINLOCK(global_register_lock);
+
+static int number_rgmii_ports;
+
+static void cvm_oct_rgmii_poll(struct net_device *dev)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	unsigned long flags;
+	cvmx_helper_link_info_t link_info;
+
+	/* Take the global register lock since we are going to touch
+	   registers that affect more than one port */
+	spin_lock_irqsave(&global_register_lock, flags);
+
+	link_info = cvmx_helper_link_get(priv->port);
+	if (link_info.u64 == priv->link_info) {
+
+		/* If the 10Mbps preamble workaround is supported and we're
+		   at 10Mbps we may need to do some special checking */
+		if (USE_10MBPS_PREAMBLE_WORKAROUND && (link_info.s.speed == 10)) {
+
+			/* Read the GMXX_RXX_INT_REG[PCTERR] bit and
+			   see if we are getting preamble errors */
+			int interface = INTERFACE(priv->port);
+			int index = INDEX(priv->port);
+			cvmx_gmxx_rxx_int_reg_t gmxx_rxx_int_reg;
+			gmxx_rxx_int_reg.u64 = cvmx_read_csr(CVMX_GMXX_RXX_INT_REG(index, interface));
+			if (gmxx_rxx_int_reg.s.pcterr) {
+
+				/* We are getting preamble errors at 10Mbps.
+				   Most likely the PHY is giving us packets
+				   with mis aligned preambles. In order to get
+				   these packets we need to disable preamble
+				   checking and do it in software */
+				cvmx_gmxx_rxx_frm_ctl_t gmxx_rxx_frm_ctl;
+				cvmx_ipd_sub_port_fcs_t ipd_sub_port_fcs;
+
+				/* Disable preamble checking */
+				gmxx_rxx_frm_ctl.u64 = cvmx_read_csr(CVMX_GMXX_RXX_FRM_CTL(index, interface));
+				gmxx_rxx_frm_ctl.s.pre_chk = 0;
+				cvmx_write_csr(CVMX_GMXX_RXX_FRM_CTL(index, interface), gmxx_rxx_frm_ctl.u64);
+
+				/* Disable FCS stripping */
+				ipd_sub_port_fcs.u64 = cvmx_read_csr(CVMX_IPD_SUB_PORT_FCS);
+				ipd_sub_port_fcs.s.port_bit &= 0xffffffffull ^ (1ull<<priv->port);
+				cvmx_write_csr(CVMX_IPD_SUB_PORT_FCS, ipd_sub_port_fcs.u64);
+
+				/* Clear any error bits */
+				cvmx_write_csr(CVMX_GMXX_RXX_INT_REG(index, interface), gmxx_rxx_int_reg.u64);
+				DEBUGPRINT("%s: Using 10Mbps with software preamble removal\n", dev->name);
+			}
+		}
+		spin_unlock_irqrestore(&global_register_lock, flags);
+		return;
+	}
+
+	/* If the 10Mbps preamble workaround is allowed we need to on
+	   preamble checking, FCS stripping, and clear error bits on
+	   every speed change. If errors occur during 10Mbps operation
+	   the above code will change this stuff */
+	if (USE_10MBPS_PREAMBLE_WORKAROUND) {
+
+		cvmx_gmxx_rxx_frm_ctl_t gmxx_rxx_frm_ctl;
+		cvmx_ipd_sub_port_fcs_t ipd_sub_port_fcs;
+		cvmx_gmxx_rxx_int_reg_t gmxx_rxx_int_reg;
+		int interface = INTERFACE(priv->port);
+		int index = INDEX(priv->port);
+
+		/* Enable preamble checking */
+		gmxx_rxx_frm_ctl.u64 = cvmx_read_csr(CVMX_GMXX_RXX_FRM_CTL(index, interface));
+		gmxx_rxx_frm_ctl.s.pre_chk = 1;
+		cvmx_write_csr(CVMX_GMXX_RXX_FRM_CTL(index, interface), gmxx_rxx_frm_ctl.u64);
+		/* Enable FCS stripping */
+		ipd_sub_port_fcs.u64 = cvmx_read_csr(CVMX_IPD_SUB_PORT_FCS);
+		ipd_sub_port_fcs.s.port_bit |= 1ull<<priv->port;
+		cvmx_write_csr(CVMX_IPD_SUB_PORT_FCS, ipd_sub_port_fcs.u64);
+		/* Clear any error bits */
+		gmxx_rxx_int_reg.u64 = cvmx_read_csr(CVMX_GMXX_RXX_INT_REG(index, interface));
+		cvmx_write_csr(CVMX_GMXX_RXX_INT_REG(index, interface), gmxx_rxx_int_reg.u64);
+	}
+
+	link_info = cvmx_helper_link_autoconf(priv->port);
+	priv->link_info = link_info.u64;
+	spin_unlock_irqrestore(&global_register_lock, flags);
+
+	/* Tell Linux */
+	if (link_info.s.link_up) {
+
+		if (!netif_carrier_ok(dev))
+			netif_carrier_on(dev);
+		if (priv->queue != -1)
+			DEBUGPRINT("%s: %u Mbps %s duplex, port %2d, queue %2d\n",
+				   dev->name, link_info.s.speed,
+				   (link_info.s.full_duplex) ? "Full" : "Half",
+				   priv->port, priv->queue);
+		else
+			DEBUGPRINT("%s: %u Mbps %s duplex, port %2d, POW\n",
+				   dev->name, link_info.s.speed,
+				   (link_info.s.full_duplex) ? "Full" : "Half",
+				   priv->port);
+	} else {
+
+		if (netif_carrier_ok(dev))
+			netif_carrier_off(dev);
+		DEBUGPRINT("%s: Link down\n", dev->name);
+	}
+}
+
+
+static irqreturn_t cvm_oct_rgmii_rml_interrupt(int cpl, void *dev_id)
+{
+	cvmx_npi_rsl_int_blocks_t rsl_int_blocks;
+	int index;
+	irqreturn_t return_status = IRQ_NONE;
+
+	rsl_int_blocks.u64 = cvmx_read_csr(CVMX_NPI_RSL_INT_BLOCKS);
+
+	/* Check and see if this interrupt was caused by the GMX0 block */
+	if (rsl_int_blocks.s.gmx0) {
+
+		int interface = 0;
+		/* Loop through every port of this interface */
+		for (index = 0; index < cvmx_helper_ports_on_interface(interface); index++) {
+
+			/* Read the GMX interrupt status bits */
+			cvmx_gmxx_rxx_int_reg_t gmx_rx_int_reg;
+			gmx_rx_int_reg.u64 = cvmx_read_csr(CVMX_GMXX_RXX_INT_REG(index, interface));
+			gmx_rx_int_reg.u64 &= cvmx_read_csr(CVMX_GMXX_RXX_INT_EN(index, interface));
+			/* Poll the port if inband status changed */
+			if (gmx_rx_int_reg.s.phy_dupx || gmx_rx_int_reg.s.phy_link || gmx_rx_int_reg.s.phy_spd) {
+
+				struct net_device *dev = cvm_oct_device[cvmx_helper_get_ipd_port(interface, index)];
+				if (dev)
+					cvm_oct_rgmii_poll(dev);
+				gmx_rx_int_reg.u64 = 0;
+				gmx_rx_int_reg.s.phy_dupx = 1;
+				gmx_rx_int_reg.s.phy_link = 1;
+				gmx_rx_int_reg.s.phy_spd = 1;
+				cvmx_write_csr(CVMX_GMXX_RXX_INT_REG(index, interface), gmx_rx_int_reg.u64);
+				return_status = IRQ_HANDLED;
+			}
+		}
+	}
+
+	/* Check and see if this interrupt was caused by the GMX1 block */
+	if (rsl_int_blocks.s.gmx1) {
+
+		int interface = 1;
+		/* Loop through every port of this interface */
+		for (index = 0; index < cvmx_helper_ports_on_interface(interface); index++) {
+
+			/* Read the GMX interrupt status bits */
+			cvmx_gmxx_rxx_int_reg_t gmx_rx_int_reg;
+			gmx_rx_int_reg.u64 = cvmx_read_csr(CVMX_GMXX_RXX_INT_REG(index, interface));
+			gmx_rx_int_reg.u64 &= cvmx_read_csr(CVMX_GMXX_RXX_INT_EN(index, interface));
+			/* Poll the port if inband status changed */
+			if (gmx_rx_int_reg.s.phy_dupx || gmx_rx_int_reg.s.phy_link || gmx_rx_int_reg.s.phy_spd) {
+
+				struct net_device *dev = cvm_oct_device[cvmx_helper_get_ipd_port(interface, index)];
+				if (dev)
+					cvm_oct_rgmii_poll(dev);
+				gmx_rx_int_reg.u64 = 0;
+				gmx_rx_int_reg.s.phy_dupx = 1;
+				gmx_rx_int_reg.s.phy_link = 1;
+				gmx_rx_int_reg.s.phy_spd = 1;
+				cvmx_write_csr(CVMX_GMXX_RXX_INT_REG(index, interface), gmx_rx_int_reg.u64);
+				return_status = IRQ_HANDLED;
+			}
+		}
+	}
+	return return_status;
+}
+
+
+static int cvm_oct_rgmii_open(struct net_device *dev)
+{
+	cvmx_gmxx_prtx_cfg_t gmx_cfg;
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int interface = INTERFACE(priv->port);
+	int index = INDEX(priv->port);
+	cvmx_helper_link_info_t link_info;
+
+	gmx_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));
+	gmx_cfg.s.en = 1;
+	cvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmx_cfg.u64);
+
+	if (!octeon_is_simulation()) {
+		link_info = cvmx_helper_link_get(priv->port);
+		if (!link_info.s.link_up)
+			netif_carrier_off(dev);
+	}
+
+	return 0;
+}
+
+static int cvm_oct_rgmii_stop(struct net_device *dev)
+{
+	cvmx_gmxx_prtx_cfg_t gmx_cfg;
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int interface = INTERFACE(priv->port);
+	int index = INDEX(priv->port);
+
+	gmx_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));
+	gmx_cfg.s.en = 0;
+	cvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmx_cfg.u64);
+	return 0;
+}
+
+int cvm_oct_rgmii_init(struct net_device *dev)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int r;
+
+	cvm_oct_common_init(dev);
+	dev->open = cvm_oct_rgmii_open;
+	dev->stop = cvm_oct_rgmii_stop;
+	dev->stop(dev);
+
+	/* Due to GMX errata in CN3XXX series chips, it is necessary to take the
+	   link down immediately whne the PHY changes state. In order to do this
+	   we call the poll function every time the RGMII inband status changes.
+	   This may cause problems if the PHY doesn't implement inband status
+	   properly */
+	if (number_rgmii_ports == 0) {
+		r = request_irq(OCTEON_IRQ_RML, cvm_oct_rgmii_rml_interrupt,
+				IRQF_SHARED, "RGMII", &number_rgmii_ports);
+	}
+	number_rgmii_ports++;
+
+	/* Only true RGMII ports need to be polled. In GMII mode, port 0 is really
+	   a RGMII port */
+	if (((priv->imode == CVMX_HELPER_INTERFACE_MODE_GMII) && (priv->port == 0)) ||
+	    (priv->imode == CVMX_HELPER_INTERFACE_MODE_RGMII)) {
+
+		if (!octeon_is_simulation()) {
+
+			cvmx_gmxx_rxx_int_en_t gmx_rx_int_en;
+			int interface = INTERFACE(priv->port);
+			int index = INDEX(priv->port);
+
+			/* Enable interrupts on inband status changes for this port */
+			gmx_rx_int_en.u64 = cvmx_read_csr(CVMX_GMXX_RXX_INT_EN(index, interface));
+			gmx_rx_int_en.s.phy_dupx = 1;
+			gmx_rx_int_en.s.phy_link = 1;
+			gmx_rx_int_en.s.phy_spd = 1;
+			cvmx_write_csr(CVMX_GMXX_RXX_INT_EN(index, interface), gmx_rx_int_en.u64);
+			priv->poll = cvm_oct_rgmii_poll;
+		}
+	}
+
+	return 0;
+}
+
+void cvm_oct_rgmii_uninit(struct net_device *dev)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	cvm_oct_common_uninit(dev);
+
+	/* Only true RGMII ports need to be polled. In GMII mode, port 0 is really
+	   a RGMII port */
+	if (((priv->imode == CVMX_HELPER_INTERFACE_MODE_GMII) && (priv->port == 0)) ||
+	    (priv->imode == CVMX_HELPER_INTERFACE_MODE_RGMII)) {
+
+		if (!octeon_is_simulation()) {
+
+			cvmx_gmxx_rxx_int_en_t gmx_rx_int_en;
+			int interface = INTERFACE(priv->port);
+			int index = INDEX(priv->port);
+
+			/* Disable interrupts on inband status changes for this port */
+			gmx_rx_int_en.u64 = cvmx_read_csr(CVMX_GMXX_RXX_INT_EN(index, interface));
+			gmx_rx_int_en.s.phy_dupx = 0;
+			gmx_rx_int_en.s.phy_link = 0;
+			gmx_rx_int_en.s.phy_spd = 0;
+			cvmx_write_csr(CVMX_GMXX_RXX_INT_EN(index, interface), gmx_rx_int_en.u64);
+		}
+	}
+
+	/* Remove the interrupt handler when the last port is removed */
+	number_rgmii_ports--;
+	if (number_rgmii_ports == 0)
+		free_irq(OCTEON_IRQ_RML, &number_rgmii_ports);
+}
+
diff --git a/drivers/net/cavium-ethernet/ethernet-rx.c b/drivers/net/cavium-ethernet/ethernet-rx.c
new file mode 100644
index 0000000..dd7eec3
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-rx.c
@@ -0,0 +1,479 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/cache.h>
+#include <linux/netdevice.h>
+#include <linux/init.h>
+#include <linux/etherdevice.h>
+#include <linux/ip.h>
+#include <linux/string.h>
+#include <linux/prefetch.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/seq_file.h>
+#include <linux/proc_fs.h>
+#include <net/dst.h>
+#ifdef CONFIG_XFRM
+#include <linux/xfrm.h>
+#include <net/xfrm.h>
+#endif  /* CONFIG_XFRM */
+
+#include "wrapper-cvmx-includes.h"
+#include "ethernet-headers.h"
+
+extern int pow_receive_group;
+extern struct net_device *cvm_oct_device[];
+struct cvm_tasklet_wrapper {
+	struct tasklet_struct t;
+};/* ____cacheline_aligned_in_smp; */
+
+/* Aligning the tasklet_struct on cachline boundries seems to decrease
+ * throughput even though in theory it would reduce contantion on the
+ * cache lines containing the locks. */
+
+/* __cacheline_aligned_in_smp; */
+static struct cvm_tasklet_wrapper cvm_oct_tasklet[NR_CPUS];
+
+/**
+ * Interrupt handler. The interrupt occurs whenever the POW
+ * transitions from 0->1 packets in our group.
+ *
+ * @param cpl
+ * @param dev_id
+ * @param regs
+ * @return
+ */
+irqreturn_t cvm_oct_do_interrupt(int cpl, void *dev_id)
+{
+	/* Acknowledge the interrupt */
+	if (INTERRUPT_LIMIT)
+		cvmx_write_csr(CVMX_POW_WQ_INT, 1<<pow_receive_group);
+	else
+		cvmx_write_csr(CVMX_POW_WQ_INT, 0x10001<<pow_receive_group);
+	preempt_disable();
+	tasklet_schedule(&cvm_oct_tasklet[smp_processor_id()].t);
+	preempt_enable();
+	return IRQ_HANDLED;
+}
+
+
+#ifdef CONFIG_NET_POLL_CONTROLLER
+/**
+ * This is called when the kernel needs to manually poll the
+ * device. For Octeon, this is simply calling the interrupt
+ * handler. We actually poll all the devices, not just the
+ * one supplied.
+ *
+ * @param dev    Device to poll. Unused
+ */
+void cvm_oct_poll_controller(struct net_device *dev)
+{
+	preempt_disable();
+	tasklet_schedule(&cvm_oct_tasklet[smp_processor_id()].t);
+	preempt_enable();
+}
+#endif
+
+/**
+ * This is called on receive errors, and determines if the packet
+ * can be dropped early-on in cvm_oct_tasklet_rx().
+ *
+ * @param work Work queue entry pointing to the packet.
+ * @return Non-zero if the packet can be dropped, zero otherwise.
+ */
+static inline int cvm_oct_check_rcv_error(cvmx_wqe_t *work)
+{
+	if ((work->word2.snoip.err_code == 10) && (work->len <= 64)) {
+		/* Ignore length errors on min size packets. Some equipment
+		   incorrectly pads packets to 64+4FCS instead of 60+4FCS.
+		   Note these packets still get counted as frame errors. */
+	} else
+	if (USE_10MBPS_PREAMBLE_WORKAROUND && ((work->word2.snoip.err_code == 5) || (work->word2.snoip.err_code == 7))) {
+
+		/* We received a packet with either an alignment error or a
+		   FCS error. This may be signalling that we are running
+		   10Mbps with GMXX_RXX_FRM_CTL[PRE_CHK} off. If this is the
+		   case we need to parse the packet to determine if we can
+		   remove a non spec preamble and generate a correct packet */
+		int interface = cvmx_helper_get_interface_num(work->ipprt);
+		int index = cvmx_helper_get_interface_index_num(work->ipprt);
+		cvmx_gmxx_rxx_frm_ctl_t gmxx_rxx_frm_ctl;
+		gmxx_rxx_frm_ctl.u64 = cvmx_read_csr(CVMX_GMXX_RXX_FRM_CTL(index, interface));
+		if (gmxx_rxx_frm_ctl.s.pre_chk == 0) {
+
+			uint8_t *ptr = cvmx_phys_to_ptr(work->packet_ptr.s.addr);
+			int i = 0;
+
+			while (i < work->len-1) {
+				if (*ptr != 0x55)
+					break;
+				ptr++;
+				i++;
+			}
+
+			if (*ptr == 0xd5) {
+				/*
+				DEBUGPRINT("Port %d received 0xd5 preamble\n", work->ipprt);
+				*/
+				work->packet_ptr.s.addr += i+1;
+				work->len -= i+5;
+			} else
+			if ((*ptr & 0xf) == 0xd) {
+				/*
+				DEBUGPRINT("Port %d received 0x?d preamble\n", work->ipprt);
+				*/
+				work->packet_ptr.s.addr += i;
+				work->len -= i+4;
+				for (i = 0; i < work->len; i++) {
+					*ptr = ((*ptr&0xf0)>>4) | ((*(ptr+1)&0xf)<<4);
+					ptr++;
+				}
+			} else {
+				DEBUGPRINT("Port %d unknown preamble, packet dropped\n", work->ipprt);
+				/*
+				cvmx_helper_dump_packet(work);
+				*/
+				cvm_oct_free_work(work);
+				return 1;
+			}
+		}
+	} else {
+		DEBUGPRINT("Port %d receive error code %d, packet dropped\n", work->ipprt, work->word2.snoip.err_code);
+		cvm_oct_free_work(work);
+		return 1;
+	}
+
+	return 0;
+}
+
+/**
+ * Tasklet function that is scheduled on a core when an interrupt occurs.
+ *
+ * @param unused
+ */
+void cvm_oct_tasklet_rx(unsigned long unused)
+{
+	const int           coreid = cvmx_get_core_num();
+	uint64_t            old_group_mask;
+	uint64_t            old_scratch;
+	int                 rx_count = 0;
+	int                 number_to_free;
+	int                 num_freed;
+	int                 packet_not_copied;
+
+	/* Prefetch cvm_oct_device since we know we need it soon */
+	CVMX_PREFETCH(cvm_oct_device, 0);
+
+	if (USE_ASYNC_IOBDMA) {
+		/* Save scratch in case userspace is using it */
+		CVMX_SYNCIOBDMA;
+		old_scratch = cvmx_scratch_read64(CVMX_SCR_SCRATCH);
+	}
+
+	/* Only allow work for our group (and preserve priorities) */
+	old_group_mask = cvmx_read_csr(CVMX_POW_PP_GRP_MSKX(coreid));
+	cvmx_write_csr(CVMX_POW_PP_GRP_MSKX(coreid),
+		       (old_group_mask & ~0xFFFFull) | 1<<pow_receive_group);
+
+	if (USE_ASYNC_IOBDMA)
+		cvmx_pow_work_request_async(CVMX_SCR_SCRATCH, CVMX_POW_NO_WAIT);
+
+	while (1) {
+		struct sk_buff *skb = NULL;
+		cvm_oct_callback_result_t callback_result;
+		int skb_in_hw;
+		cvmx_wqe_t *work;
+
+		if (USE_ASYNC_IOBDMA) {
+			work = cvmx_pow_work_response_async(CVMX_SCR_SCRATCH);
+		} else {
+			if ((INTERRUPT_LIMIT == 0) || likely(rx_count <
+							     MAX_RX_PACKETS))
+				work = cvmx_pow_work_request_sync(CVMX_POW_NO_WAIT);
+			else
+				work = NULL;
+		}
+		prefetch(work);
+		if (work == NULL)
+			break;
+
+		/* Limit each core to processing MAX_RX_PACKETS packets
+		 * without a break. This way the RX can't starve the TX task. */
+		if (USE_ASYNC_IOBDMA) {
+
+			if ((INTERRUPT_LIMIT == 0) || likely(rx_count <
+							     MAX_RX_PACKETS))
+				cvmx_pow_work_request_async_nocheck(CVMX_SCR_SCRATCH, CVMX_POW_NO_WAIT);
+			else {
+				cvmx_scratch_write64(CVMX_SCR_SCRATCH, 0x8000000000000000ull);
+				cvmx_pow_tag_sw_null_nocheck();
+			}
+		}
+
+		skb_in_hw = USE_SKBUFFS_IN_HW && work->word2.s.bufs == 1;
+		if (likely(skb_in_hw)) {
+			skb = *(struct sk_buff **)
+				(cvm_oct_get_buffer_ptr(work->packet_ptr) -
+				 sizeof(void *));
+			CVMX_PREFETCH(skb, offsetof(struct sk_buff, head));
+			CVMX_PREFETCH(skb, offsetof(struct sk_buff, len));
+		}
+		CVMX_PREFETCH(cvm_oct_device[work->ipprt], 0);
+
+
+		rx_count++;
+		/* Immediately throw away all packets with receive errors */
+		if (unlikely(work->word2.snoip.rcv_error)) {
+			if (cvm_oct_check_rcv_error(work))
+				continue;
+		}
+
+		/* We can only use the zero copy path if skbuffs are in the FPA pool
+		   and the packet fits in a single buffer */
+		if (likely(skb_in_hw)) {
+			/* This calculation was changed in case the skb header is using a
+			   different address aliasing type than the buffer. It doesn't make
+			   any differnece now, but the new one is more correct */
+			skb->data = skb->head + work->packet_ptr.s.addr - cvmx_ptr_to_phys(skb->head);
+			CVMX_PREFETCH(skb->data, 0);
+			skb->len = work->len;
+			skb_set_tail_pointer(skb, skb->len);
+			packet_not_copied = 1;
+		} else {
+
+			/* We have to copy the packet. First allocate an
+			   skbuff for it */
+			skb = dev_alloc_skb(work->len);
+			if (!skb) {
+				DEBUGPRINT("Port %d failed to allocate skbuff, packet dropped\n", work->ipprt);
+				cvm_oct_free_work(work);
+				continue;
+			}
+
+			/* Check if we've received a packet that was entirely
+			   stored in the work entry. This is untested */
+			if (unlikely(work->word2.s.bufs == 0)) {
+				uint8_t *ptr = work->packet_data;
+
+				if (cvmx_likely(!work->word2.s.not_IP)) {
+					/* The beginning of the packet moves
+					   for IP packets */
+					if (work->word2.s.is_v6)
+						ptr += 2;
+					else
+						ptr += 6;
+				}
+				memcpy(skb_put(skb, work->len), ptr, work->len);
+				/* No packet buffers to free */
+			} else {
+				int segments = work->word2.s.bufs;
+				cvmx_buf_ptr_t segment_ptr = work->packet_ptr;
+				int len = work->len;
+
+				while (segments--) {
+					cvmx_buf_ptr_t next_ptr = *(cvmx_buf_ptr_t *)cvmx_phys_to_ptr(segment_ptr.s.addr-8);
+					/* Octeon Errata PKI-100: The segment
+					   size is wrong. Until it is fixed,
+					   calculate the segment size based on
+					   the packet pool buffer size. When
+					   it is fixed, the following line
+					   should be replaced with this one:
+					int segment_size = segment_ptr.s.size; */
+					int segment_size = CVMX_FPA_PACKET_POOL_SIZE - (segment_ptr.s.addr - (((segment_ptr.s.addr >> 7) - segment_ptr.s.back) << 7));
+					/* Don't copy more than what is left
+					   in the packet */
+					if (segment_size > len)
+						segment_size = len;
+					/* Copy the data into the packet */
+					memcpy(skb_put(skb, segment_size), cvmx_phys_to_ptr(segment_ptr.s.addr), segment_size);
+					/* Reduce the amount of bytes left
+					   to copy */
+					len -= segment_size;
+					segment_ptr = next_ptr;
+				}
+			}
+			packet_not_copied = 0;
+		}
+
+		if (likely((work->ipprt < TOTAL_NUMBER_OF_PORTS) &&
+		    cvm_oct_device[work->ipprt])) {
+			struct net_device *dev = cvm_oct_device[work->ipprt];
+			cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+
+			/* Only accept packets for devices
+			   that are currently up */
+			if (likely(dev->flags & IFF_UP)) {
+				skb->protocol = eth_type_trans(skb, dev);
+				skb->dev = dev;
+
+				if (unlikely(work->word2.s.not_IP || work->word2.s.IP_exc || work->word2.s.L4_error))
+					skb->ip_summed = CHECKSUM_NONE;
+				else
+					skb->ip_summed = CHECKSUM_UNNECESSARY;
+
+				/* Increment RX stats for virtual ports */
+				if (work->ipprt >= CVMX_PIP_NUM_INPUT_PORTS) {
+#ifdef CONFIG_64BIT
+					cvmx_atomic_add64_nosync(&priv->stats.rx_packets, 1);
+					cvmx_atomic_add64_nosync(&priv->stats.rx_bytes, skb->len);
+#else
+					cvmx_atomic_add32_nosync((int32_t *)&priv->stats.rx_packets, 1);
+					cvmx_atomic_add32_nosync((int32_t *)&priv->stats.rx_bytes, skb->len);
+#endif
+				}
+
+				if (priv->intercept_cb) {
+					callback_result = priv->intercept_cb(dev, work, skb);
+
+					switch (callback_result) {
+					case CVM_OCT_PASS:
+						netif_receive_skb(skb);
+						break;
+					case CVM_OCT_DROP:
+						dev_kfree_skb_irq(skb);
+#ifdef CONFIG_64BIT
+						cvmx_atomic_add64_nosync(&priv->stats.rx_dropped, 1);
+#else
+						cvmx_atomic_add32_nosync((int32_t *)&priv->stats.rx_dropped, 1);
+#endif
+						break;
+					case CVM_OCT_TAKE_OWNERSHIP_WORK:
+						/* Interceptor stole our work, but
+						   we need to free the skbuff */
+						if (USE_SKBUFFS_IN_HW && likely(packet_not_copied)) {
+							/* We can't free the skbuff since its data is
+							the same as the work. In this case we don't
+							do anything */
+						} else
+							dev_kfree_skb_irq(skb);
+						break;
+					case CVM_OCT_TAKE_OWNERSHIP_SKB:
+						/* Interceptor stole our packet */
+						break;
+					}
+				} else {
+					netif_receive_skb(skb);
+					callback_result = CVM_OCT_PASS;
+				}
+			} else {
+				/* Drop any packet received for a device that isn't up */
+				/*
+				DEBUGPRINT("%s: Device not up, packet dropped\n",
+					   dev->name);
+				*/
+#ifdef CONFIG_64BIT
+				cvmx_atomic_add64_nosync(&priv->stats.rx_dropped, 1);
+#else
+				cvmx_atomic_add32_nosync((int32_t *)&priv->stats.rx_dropped, 1);
+#endif
+				dev_kfree_skb_irq(skb);
+				callback_result = CVM_OCT_DROP;
+			}
+		} else {
+			/* Drop any packet received for a device that
+			   doesn't exist */
+			DEBUGPRINT("Port %d not controlled by Linux, packet dropped\n", work->ipprt);
+			dev_kfree_skb_irq(skb);
+			callback_result = CVM_OCT_DROP;
+		}
+
+		/* We only need to free the work if the interceptor didn't
+		   take over ownership of it */
+		if (callback_result != CVM_OCT_TAKE_OWNERSHIP_WORK) {
+
+			/* Check to see if the skbuff and work share
+			   the same packet buffer */
+			if (USE_SKBUFFS_IN_HW && likely(packet_not_copied)) {
+				/* This buffer needs to be replaced, increment
+				the number of buffers we need to free by one */
+				cvmx_fau_atomic_add32(
+					FAU_NUM_PACKET_BUFFERS_TO_FREE, 1);
+
+				cvmx_fpa_free(work, CVMX_FPA_WQE_POOL,
+					      DONT_WRITEBACK(1));
+			} else
+				cvm_oct_free_work(work);
+		}
+	}
+
+	/* Restore the original POW group mask */
+	cvmx_write_csr(CVMX_POW_PP_GRP_MSKX(coreid), old_group_mask);
+	if (USE_ASYNC_IOBDMA) {
+		/* Restore the scratch area */
+		cvmx_scratch_write64(CVMX_SCR_SCRATCH, old_scratch);
+	}
+
+	if (USE_SKBUFFS_IN_HW) {
+		/* Refill the packet buffer pool */
+		number_to_free =
+		  cvmx_fau_fetch_and_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);
+
+		if (number_to_free > 0) {
+			cvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE,
+					      -number_to_free);
+			num_freed =
+				cvm_oct_mem_fill_fpa(CVMX_FPA_PACKET_POOL,
+						     CVMX_FPA_PACKET_POOL_SIZE,
+						     number_to_free);
+			if (num_freed != number_to_free) {
+				cvmx_fau_atomic_add32(
+					FAU_NUM_PACKET_BUFFERS_TO_FREE,
+					number_to_free - num_freed);
+			}
+		}
+	}
+}
+
+
+
+void cvm_oct_rx_initialize(void)
+{
+	int i;
+	/* Initialize all of the tasklets */
+	for (i = 0; i < NR_CPUS; i++)
+		tasklet_init(&cvm_oct_tasklet[i].t, cvm_oct_tasklet_rx, 0);
+}
+
+void cvm_oct_rx_shutdown(void)
+{
+	int i;
+	/* Shutdown all of the tasklets */
+	for (i = 0; i < NR_CPUS; i++)
+		tasklet_kill(&cvm_oct_tasklet[i].t);
+}
+
diff --git a/drivers/net/cavium-ethernet/ethernet-rx.h b/drivers/net/cavium-ethernet/ethernet-rx.h
new file mode 100644
index 0000000..774ae27
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-rx.h
@@ -0,0 +1,44 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+
+irqreturn_t cvm_oct_do_interrupt(int cpl, void *dev_id);
+void cvm_oct_poll_controller(struct net_device *dev);
+void cvm_oct_tasklet_rx(unsigned long unused);
+
+void cvm_oct_rx_initialize(void);
+void cvm_oct_rx_shutdown(void);
+
diff --git a/drivers/net/cavium-ethernet/ethernet-sgmii.c b/drivers/net/cavium-ethernet/ethernet-sgmii.c
new file mode 100644
index 0000000..7187426
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-sgmii.c
@@ -0,0 +1,133 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/mii.h>
+#include <net/dst.h>
+
+#include "wrapper-cvmx-includes.h"
+#include "ethernet-headers.h"
+
+extern int octeon_is_simulation(void);
+
+static int cvm_oct_sgmii_open(struct net_device *dev)
+{
+	cvmx_gmxx_prtx_cfg_t gmx_cfg;
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int interface = INTERFACE(priv->port);
+	int index = INDEX(priv->port);
+	cvmx_helper_link_info_t link_info;
+
+	gmx_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));
+	gmx_cfg.s.en = 1;
+	cvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmx_cfg.u64);
+
+	if (!octeon_is_simulation()) {
+		link_info = cvmx_helper_link_get(priv->port);
+		if (!link_info.s.link_up)
+			netif_carrier_off(dev);
+	}
+
+	return 0;
+}
+
+static int cvm_oct_sgmii_stop(struct net_device *dev)
+{
+	cvmx_gmxx_prtx_cfg_t gmx_cfg;
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int interface = INTERFACE(priv->port);
+	int index = INDEX(priv->port);
+
+	gmx_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));
+	gmx_cfg.s.en = 0;
+	cvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmx_cfg.u64);
+	return 0;
+}
+
+static void cvm_oct_sgmii_poll(struct net_device *dev)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	cvmx_helper_link_info_t link_info;
+
+	link_info = cvmx_helper_link_get(priv->port);
+	if (link_info.u64 == priv->link_info)
+		return;
+
+	link_info = cvmx_helper_link_autoconf(priv->port);
+	priv->link_info = link_info.u64;
+
+	/* Tell Linux */
+	if (link_info.s.link_up) {
+
+		if (!netif_carrier_ok(dev))
+			netif_carrier_on(dev);
+		if (priv->queue != -1)
+			DEBUGPRINT("%s: %u Mbps %s duplex, port %2d, queue %2d\n",
+				   dev->name, link_info.s.speed,
+				   (link_info.s.full_duplex) ? "Full" : "Half",
+				   priv->port, priv->queue);
+		else
+			DEBUGPRINT("%s: %u Mbps %s duplex, port %2d, POW\n",
+				   dev->name, link_info.s.speed,
+				   (link_info.s.full_duplex) ? "Full" : "Half",
+				   priv->port);
+	} else {
+		if (netif_carrier_ok(dev))
+			netif_carrier_off(dev);
+		DEBUGPRINT("%s: Link down\n", dev->name);
+	}
+}
+
+int cvm_oct_sgmii_init(struct net_device *dev)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	cvm_oct_common_init(dev);
+	dev->open = cvm_oct_sgmii_open;
+	dev->stop = cvm_oct_sgmii_stop;
+	dev->stop(dev);
+	if (!octeon_is_simulation())
+		priv->poll = cvm_oct_sgmii_poll;
+
+	/* FIXME: Need autoneg logic */
+	return 0;
+}
+
+void cvm_oct_sgmii_uninit(struct net_device *dev)
+{
+	cvm_oct_common_uninit(dev);
+}
+
diff --git a/drivers/net/cavium-ethernet/ethernet-spi.c b/drivers/net/cavium-ethernet/ethernet-spi.c
new file mode 100644
index 0000000..3de9861
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-spi.c
@@ -0,0 +1,284 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/mii.h>
+#include <net/dst.h>
+
+#include "wrapper-cvmx-includes.h"
+#include "ethernet-headers.h"
+
+static int number_spi_ports;
+static int need_retrain[2] = {0, 0};
+
+static irqreturn_t cvm_oct_spi_rml_interrupt(int cpl, void *dev_id)
+{
+	irqreturn_t return_status = IRQ_NONE;
+	cvmx_npi_rsl_int_blocks_t rsl_int_blocks;
+
+	/* Check and see if this interrupt was caused by the GMX block */
+	rsl_int_blocks.u64 = cvmx_read_csr(CVMX_NPI_RSL_INT_BLOCKS);
+	if (rsl_int_blocks.s.spx1) { /* 19 - SPX1_INT_REG & STX1_INT_REG */
+
+		cvmx_spxx_int_reg_t spx_int_reg;
+		cvmx_stxx_int_reg_t stx_int_reg;
+
+		spx_int_reg.u64 = cvmx_read_csr(CVMX_SPXX_INT_REG(1));
+		cvmx_write_csr(CVMX_SPXX_INT_REG(1), spx_int_reg.u64);
+		if (!need_retrain[1]) {
+
+			spx_int_reg.u64 &= cvmx_read_csr(CVMX_SPXX_INT_MSK(1));
+			if (spx_int_reg.s.spf)
+				pr_err("SPI1: SRX Spi4 interface down\n");
+			if (spx_int_reg.s.calerr)
+				pr_err("SPI1: SRX Spi4 Calendar table parity error\n");
+			if (spx_int_reg.s.syncerr)
+				pr_err("SPI1: SRX Consecutive Spi4 DIP4 errors have exceeded SPX_ERR_CTL[ERRCNT]\n");
+			if (spx_int_reg.s.diperr)
+				pr_err("SPI1: SRX Spi4 DIP4 error\n");
+			if (spx_int_reg.s.tpaovr)
+				pr_err("SPI1: SRX Selected port has hit TPA overflow\n");
+			if (spx_int_reg.s.rsverr)
+				pr_err("SPI1: SRX Spi4 reserved control word detected\n");
+			if (spx_int_reg.s.drwnng)
+				pr_err("SPI1: SRX Spi4 receive FIFO drowning/overflow\n");
+			if (spx_int_reg.s.clserr)
+				pr_err("SPI1: SRX Spi4 packet closed on non-16B alignment without EOP\n");
+			if (spx_int_reg.s.spiovr)
+				pr_err("SPI1: SRX Spi4 async FIFO overflow\n");
+			if (spx_int_reg.s.abnorm)
+				pr_err("SPI1: SRX Abnormal packet termination (ERR bit)\n");
+			if (spx_int_reg.s.prtnxa)
+				pr_err("SPI1: SRX Port out of range\n");
+		}
+
+		stx_int_reg.u64 = cvmx_read_csr(CVMX_STXX_INT_REG(1));
+		cvmx_write_csr(CVMX_STXX_INT_REG(1), stx_int_reg.u64);
+		if (!need_retrain[1]) {
+
+			stx_int_reg.u64 &= cvmx_read_csr(CVMX_STXX_INT_MSK(1));
+			if (stx_int_reg.s.syncerr)
+				pr_err("SPI1: STX Interface encountered a fatal error\n");
+			if (stx_int_reg.s.frmerr)
+				pr_err("SPI1: STX FRMCNT has exceeded STX_DIP_CNT[MAXFRM]\n");
+			if (stx_int_reg.s.unxfrm)
+				pr_err("SPI1: STX Unexpected framing sequence\n");
+			if (stx_int_reg.s.nosync)
+				pr_err("SPI1: STX ERRCNT has exceeded STX_DIP_CNT[MAXDIP]\n");
+			if (stx_int_reg.s.diperr)
+				pr_err("SPI1: STX DIP2 error on the Spi4 Status channel\n");
+			if (stx_int_reg.s.datovr)
+				pr_err("SPI1: STX Spi4 FIFO overflow error\n");
+			if (stx_int_reg.s.ovrbst)
+				pr_err("SPI1: STX Transmit packet burst too big\n");
+			if (stx_int_reg.s.calpar1)
+				pr_err("SPI1: STX Calendar Table Parity Error Bank1\n");
+			if (stx_int_reg.s.calpar0)
+				pr_err("SPI1: STX Calendar Table Parity Error Bank0\n");
+		}
+
+		cvmx_write_csr(CVMX_SPXX_INT_MSK(1), 0);
+		cvmx_write_csr(CVMX_STXX_INT_MSK(1), 0);
+		need_retrain[1] = 1;
+		return_status = IRQ_HANDLED;
+	}
+
+	if (rsl_int_blocks.s.spx0) { /* 18 - SPX0_INT_REG & STX0_INT_REG */
+		cvmx_spxx_int_reg_t spx_int_reg;
+		cvmx_stxx_int_reg_t stx_int_reg;
+
+		spx_int_reg.u64 = cvmx_read_csr(CVMX_SPXX_INT_REG(0));
+		cvmx_write_csr(CVMX_SPXX_INT_REG(0), spx_int_reg.u64);
+		if (!need_retrain[0]) {
+
+			spx_int_reg.u64 &= cvmx_read_csr(CVMX_SPXX_INT_MSK(0));
+			if (spx_int_reg.s.spf)
+				pr_err("SPI0: SRX Spi4 interface down\n");
+			if (spx_int_reg.s.calerr)
+				pr_err("SPI0: SRX Spi4 Calendar table parity error\n");
+			if (spx_int_reg.s.syncerr)
+				pr_err("SPI0: SRX Consecutive Spi4 DIP4 errors have exceeded SPX_ERR_CTL[ERRCNT]\n");
+			if (spx_int_reg.s.diperr)
+				pr_err("SPI0: SRX Spi4 DIP4 error\n");
+			if (spx_int_reg.s.tpaovr)
+				pr_err("SPI0: SRX Selected port has hit TPA overflow\n");
+			if (spx_int_reg.s.rsverr)
+				pr_err("SPI0: SRX Spi4 reserved control word detected\n");
+			if (spx_int_reg.s.drwnng)
+				pr_err("SPI0: SRX Spi4 receive FIFO drowning/overflow\n");
+			if (spx_int_reg.s.clserr)
+				pr_err("SPI0: SRX Spi4 packet closed on non-16B alignment without EOP\n");
+			if (spx_int_reg.s.spiovr)
+				pr_err("SPI0: SRX Spi4 async FIFO overflow\n");
+			if (spx_int_reg.s.abnorm)
+				pr_err("SPI0: SRX Abnormal packet termination (ERR bit)\n");
+			if (spx_int_reg.s.prtnxa)
+				pr_err("SPI0: SRX Port out of range\n");
+		}
+
+		stx_int_reg.u64 = cvmx_read_csr(CVMX_STXX_INT_REG(0));
+		cvmx_write_csr(CVMX_STXX_INT_REG(0), stx_int_reg.u64);
+		if (!need_retrain[0]) {
+
+			stx_int_reg.u64 &= cvmx_read_csr(CVMX_STXX_INT_MSK(0));
+			if (stx_int_reg.s.syncerr)
+				pr_err("SPI0: STX Interface encountered a fatal error\n");
+			if (stx_int_reg.s.frmerr)
+				pr_err("SPI0: STX FRMCNT has exceeded STX_DIP_CNT[MAXFRM]\n");
+			if (stx_int_reg.s.unxfrm)
+				pr_err("SPI0: STX Unexpected framing sequence\n");
+			if (stx_int_reg.s.nosync)
+				pr_err("SPI0: STX ERRCNT has exceeded STX_DIP_CNT[MAXDIP]\n");
+			if (stx_int_reg.s.diperr)
+				pr_err("SPI0: STX DIP2 error on the Spi4 Status channel\n");
+			if (stx_int_reg.s.datovr)
+				pr_err("SPI0: STX Spi4 FIFO overflow error\n");
+			if (stx_int_reg.s.ovrbst)
+				pr_err("SPI0: STX Transmit packet burst too big\n");
+			if (stx_int_reg.s.calpar1)
+				pr_err("SPI0: STX Calendar Table Parity Error Bank1\n");
+			if (stx_int_reg.s.calpar0)
+				pr_err("SPI0: STX Calendar Table Parity Error Bank0\n");
+		}
+
+		cvmx_write_csr(CVMX_SPXX_INT_MSK(0), 0);
+		cvmx_write_csr(CVMX_STXX_INT_MSK(0), 0);
+		need_retrain[0] = 1;
+		return_status = IRQ_HANDLED;
+	}
+
+	return return_status;
+}
+
+static void cvm_oct_spi_enable_error_reporting(int interface)
+{
+	cvmx_spxx_int_msk_t spxx_int_msk;
+	cvmx_stxx_int_msk_t stxx_int_msk;
+
+	spxx_int_msk.u64 = cvmx_read_csr(CVMX_SPXX_INT_MSK(interface));
+	spxx_int_msk.s.calerr = 1;
+	spxx_int_msk.s.syncerr = 1;
+	spxx_int_msk.s.diperr = 1;
+	spxx_int_msk.s.tpaovr = 1;
+	spxx_int_msk.s.rsverr = 1;
+	spxx_int_msk.s.drwnng = 1;
+	spxx_int_msk.s.clserr = 1;
+	spxx_int_msk.s.spiovr = 1;
+	spxx_int_msk.s.abnorm = 1;
+	spxx_int_msk.s.prtnxa = 1;
+	cvmx_write_csr(CVMX_SPXX_INT_MSK(interface), spxx_int_msk.u64);
+
+	stxx_int_msk.u64 = cvmx_read_csr(CVMX_STXX_INT_MSK(interface));
+	stxx_int_msk.s.frmerr = 1;
+	stxx_int_msk.s.unxfrm = 1;
+	stxx_int_msk.s.nosync = 1;
+	stxx_int_msk.s.diperr = 1;
+	stxx_int_msk.s.datovr = 1;
+	stxx_int_msk.s.ovrbst = 1;
+	stxx_int_msk.s.calpar1 = 1;
+	stxx_int_msk.s.calpar0 = 1;
+	cvmx_write_csr(CVMX_STXX_INT_MSK(interface), stxx_int_msk.u64);
+}
+
+static void cvm_oct_spi_poll(struct net_device *dev)
+{
+	static int spi4000_port;
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int interface;
+
+	for (interface = 0; interface < 2; interface++) {
+
+		if ((priv->port == interface*16) && need_retrain[interface]) {
+
+			if (cvmx_spi_restart_interface(interface, CVMX_SPI_MODE_DUPLEX, 10) == 0) {
+				need_retrain[interface] = 0;
+				cvm_oct_spi_enable_error_reporting(interface);
+			}
+		}
+
+		/* The SPI4000 TWSI interface is very slow. In order not to
+		   bring the system to a crawl, we only poll a single port
+		   every second. This means negotiation speed changes
+		   take up to 10 seconds, but at least we don't waste
+		   absurd amounts of time waiting for TWSI */
+		if (priv->port == spi4000_port) {
+			/* This function does nothing if it is called on an
+			   interface without a SPI4000 */
+			cvmx_spi4000_check_speed(interface, priv->port);
+			/* Normal ordering increments. By decrementing
+			   we only match once per iteration */
+			spi4000_port--;
+			if (spi4000_port < 0)
+				spi4000_port = 10;
+		}
+	}
+}
+
+
+int cvm_oct_spi_init(struct net_device *dev)
+{
+	int r;
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+
+	if (number_spi_ports == 0) {
+		r = request_irq(OCTEON_IRQ_RML, cvm_oct_spi_rml_interrupt,
+				IRQF_SHARED, "SPI", &number_spi_ports);
+	}
+	number_spi_ports++;
+
+	if ((priv->port == 0) || (priv->port == 16)) {
+		cvm_oct_spi_enable_error_reporting(INTERFACE(priv->port));
+		priv->poll = cvm_oct_spi_poll;
+	}
+	cvm_oct_common_init(dev);
+	return 0;
+}
+
+void cvm_oct_spi_uninit(struct net_device *dev)
+{
+	int interface;
+
+	cvm_oct_common_uninit(dev);
+	number_spi_ports--;
+	if (number_spi_ports == 0) {
+		for (interface = 0; interface < 2; interface++) {
+			cvmx_write_csr(CVMX_SPXX_INT_MSK(interface), 0);
+			cvmx_write_csr(CVMX_STXX_INT_MSK(interface), 0);
+		}
+		free_irq(8 + 46, &number_spi_ports);
+	}
+}
diff --git a/drivers/net/cavium-ethernet/ethernet-tx.c b/drivers/net/cavium-ethernet/ethernet-tx.c
new file mode 100644
index 0000000..ca358cc
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-tx.c
@@ -0,0 +1,582 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/init.h>
+#include <linux/etherdevice.h>
+#include <linux/ip.h>
+#include <linux/string.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/seq_file.h>
+#include <linux/proc_fs.h>
+#include <net/dst.h>
+#ifdef CONFIG_XFRM
+#include <linux/xfrm.h>
+#include <net/xfrm.h>
+#endif  /* CONFIG_XFRM */
+
+#include "wrapper-cvmx-includes.h"
+#include "ethernet-headers.h"
+
+/* You can define GET_SKBUFF_QOS() to override how the skbuff output function
+   determines which output queue is used. The default implementation
+   always uses the base queue for the port. If, for example, you wanted
+   to use the skb->priority fieid, define GET_SKBUFF_QOS as:
+   #define GET_SKBUFF_QOS(skb) ((skb)->priority) */
+#ifndef GET_SKBUFF_QOS
+    #define GET_SKBUFF_QOS(skb) 0
+#endif
+
+extern int pow_send_group;
+
+
+/**
+ * Packet transmit
+ *
+ * @param skb    Packet to send
+ * @param dev    Device info structure
+ * @return Always returns zero
+ */
+int cvm_oct_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	cvmx_pko_command_word0_t    pko_command;
+	cvmx_buf_ptr_t              hw_buffer;
+	uint64_t                    old_scratch;
+	uint64_t                    old_scratch2;
+	int                         dropped;
+	int                         qos;
+	cvm_oct_private_t          *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int32_t in_use;
+	int32_t buffers_to_free;
+#if REUSE_SKBUFFS_WITHOUT_FREE
+	unsigned char *fpa_head;
+#endif
+
+	/* Prefetch the private data structure.
+	   It is larger that one cache line */
+	CVMX_PREFETCH(priv, 0);
+
+	/* Start off assuming no drop */
+	dropped = 0;
+
+	/* The check on CVMX_PKO_QUEUES_PER_PORT_* is designed to completely
+	   remove "qos" in the event neither interface supports multiple queues
+	   per port */
+	if ((CVMX_PKO_QUEUES_PER_PORT_INTERFACE0 > 1) ||
+	    (CVMX_PKO_QUEUES_PER_PORT_INTERFACE1 > 1)) {
+		qos = GET_SKBUFF_QOS(skb);
+		if (qos <= 0)
+			qos = 0;
+		else if (qos >= cvmx_pko_get_num_queues(priv->port))
+			qos = 0;
+	} else
+		qos = 0;
+
+	if (USE_ASYNC_IOBDMA) {
+		/* Save scratch in case userspace is using it */
+		CVMX_SYNCIOBDMA;
+		old_scratch = cvmx_scratch_read64(CVMX_SCR_SCRATCH);
+		old_scratch2 = cvmx_scratch_read64(CVMX_SCR_SCRATCH+8);
+
+		/* Assume we're going to be able t osend this packet. Fetch and increment
+		   the number of pending packets for output */
+		cvmx_fau_async_fetch_and_add32(CVMX_SCR_SCRATCH+8, FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);
+		cvmx_fau_async_fetch_and_add32(CVMX_SCR_SCRATCH, priv->fau+qos*4, 1);
+	}
+
+	/* The CN3XXX series of parts has an errata (GMX-401) which causes the
+	   GMX block to hang if a collision occurs towards the end of a
+	   <68 byte packet. As a workaround for this, we pad packets to be
+	   68 bytes whenever we are in half duplex mode. We don't handle
+	   the case of having a small packet but no room to add the padding.
+	   The kernel should always give us at least a cache line */
+	if ((skb->len < 64) && OCTEON_IS_MODEL(OCTEON_CN3XXX)) {
+		cvmx_gmxx_prtx_cfg_t gmx_prt_cfg;
+		int interface = INTERFACE(priv->port);
+		int index = INDEX(priv->port);
+
+		if (interface < 2) {
+			/* We only need to pad packet in half duplex mode */
+			gmx_prt_cfg.u64 =
+				cvmx_read_csr(CVMX_GMXX_PRTX_CFG(index,
+								 interface));
+			if (gmx_prt_cfg.s.duplex == 0) {
+				int add_bytes = 64 - skb->len;
+				if ((skb_tail_pointer(skb) + add_bytes) <=
+				    skb_end_pointer(skb))
+					memset(__skb_put(skb, add_bytes), 0,
+					       add_bytes);
+			}
+		}
+	}
+
+	/* Build the PKO buffer pointer */
+	hw_buffer.u64 = 0;
+	hw_buffer.s.addr = cvmx_ptr_to_phys(skb->data);
+	hw_buffer.s.pool = 0;
+	hw_buffer.s.size = (unsigned long)skb_end_pointer(skb) -
+		(unsigned long)skb->head;
+
+	/* Build the PKO command */
+	pko_command.u64 = 0;
+	pko_command.s.n2 = 1; /* Don't pollute L2 with the outgoing packet */
+	pko_command.s.segs = 1;
+	pko_command.s.total_bytes = skb->len;
+	pko_command.s.size0 = CVMX_FAU_OP_SIZE_32;
+	pko_command.s.subone0 = 1;
+
+	pko_command.s.dontfree = 1;
+	pko_command.s.reg0 = priv->fau+qos*4;
+	/* See if we can put this skb in the FPA pool. Any strange behavior
+	   from the Linux networking stack will most likely be caused by a bug
+	   in the following code. If some field is in use by the network stack
+	   and get carried over when a buffer is reused, bad thing may happen.
+	   If in doubt and you dont need the absolute best performance, disable
+	   the define REUSE_SKBUFFS_WITHOUT_FREE. The reuse of buffers has
+	   shown a 25% increase in performance under some loads */
+#if REUSE_SKBUFFS_WITHOUT_FREE
+	fpa_head = skb->head + 128 - ((unsigned long)skb->head&0x7f);
+	if (unlikely(skb->data < fpa_head)) {
+		/*
+		printk("TX buffer beginning can't meet FPA alignment constraints\n");
+		*/
+		goto dont_put_skbuff_in_hw;
+	}
+	if (unlikely((skb_end_pointer(skb) - fpa_head) <
+		     CVMX_FPA_PACKET_POOL_SIZE)) {
+		/*
+		printk("TX buffer isn't large enough for the FPA\n");
+		*/
+		goto dont_put_skbuff_in_hw;
+	}
+	if (unlikely(skb_shared(skb))) {
+		/*
+		printk("TX buffer sharing data with someone else\n");
+		*/
+		goto dont_put_skbuff_in_hw;
+	}
+	if (unlikely(skb_cloned(skb))) {
+		/*
+		printk("TX buffer has been cloned\n");
+		*/
+		goto dont_put_skbuff_in_hw;
+	}
+	if (unlikely(skb_header_cloned(skb))) {
+		/*
+		printk("TX buffer header has been cloned\n");
+		*/
+		goto dont_put_skbuff_in_hw;
+	}
+	if (unlikely(skb->destructor)) {
+		/*
+		printk("TX buffer has a destructor\n");
+		*/
+		goto dont_put_skbuff_in_hw;
+	}
+	if (unlikely(skb_shinfo(skb)->nr_frags)) {
+		/*
+		printk("TX buffer has fragments\n");
+		*/
+		goto dont_put_skbuff_in_hw;
+	}
+	if (unlikely(skb->truesize != sizeof(*skb) + skb_end_pointer(skb) -
+		     skb->head)) {
+		/*
+		printk("TX buffer truesize has been changed\n");
+		*/
+		goto dont_put_skbuff_in_hw;
+	}
+
+	/* We can use this buffer in the FPA.
+	   We don't need the FAU update anymore */
+	pko_command.s.reg0 = 0;
+	pko_command.s.dontfree = 0;
+
+	hw_buffer.s.back = (skb->data - fpa_head)>>7;
+	*(struct sk_buff **)(fpa_head-sizeof(void *)) = skb;
+
+	/* The skbuff will be reused without ever being freed. We must cleanup a
+	   bunch of Linux stuff */
+	dst_release(skb->dst);
+	skb->dst = NULL;
+#ifdef CONFIG_XFRM
+	secpath_put(skb->sp);
+	skb->sp = NULL;
+#endif
+	nf_reset(skb);
+#ifdef CONFIG_BRIDGE_NETFILTER
+	/* The next two lines are done in nf_reset() for 2.6.21. 2.6.16 needs
+	   them. I'm leaving it for all versions since the compiler will
+	   optimize them away when they aren't needed. It can tell that
+	   skb->nf_bridge was set to NULL in the inlined nf_reset(). */
+	nf_bridge_put(skb->nf_bridge);
+	skb->nf_bridge = NULL;
+#endif /* CONFIG_BRIDGE_NETFILTER */
+#ifdef CONFIG_NET_SCHED
+	skb->tc_index = 0;
+#ifdef CONFIG_NET_CLS_ACT
+	skb->tc_verd = 0;
+#endif /* CONFIG_NET_CLS_ACT */
+#endif /* CONFIG_NET_SCHED */
+
+dont_put_skbuff_in_hw:
+#endif /* REUSE_SKBUFFS_WITHOUT_FREE */
+
+	/* Check if we can use the hardware checksumming */
+	if (USE_HW_TCPUDP_CHECKSUM && (skb->protocol == htons(ETH_P_IP)) &&
+	    (ip_hdr(skb)->version == 4) && (ip_hdr(skb)->ihl == 5) &&
+	    ((ip_hdr(skb)->frag_off == 0) || (ip_hdr(skb)->frag_off == 1<<14)) &&
+	    ((ip_hdr(skb)->protocol == IP_PROTOCOL_TCP) || (ip_hdr(skb)->protocol == IP_PROTOCOL_UDP))) {
+		/* Use hardware checksum calc */
+		pko_command.s.ipoffp1 = sizeof(struct ethhdr) + 1;
+	}
+
+	if (USE_ASYNC_IOBDMA) {
+		/* Get the number of skbuffs in use by the hardware */
+		CVMX_SYNCIOBDMA;
+		in_use = cvmx_scratch_read64(CVMX_SCR_SCRATCH);
+		buffers_to_free = cvmx_scratch_read64(CVMX_SCR_SCRATCH+8);
+	} else {
+		/* Get the number of skbuffs in use by the hardware */
+		in_use = cvmx_fau_fetch_and_add32(priv->fau+qos*4, 1);
+		buffers_to_free = cvmx_fau_fetch_and_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);
+	}
+
+	/* If we're sending faster than the receive can free them then don't do
+	   the HW free */
+	if ((buffers_to_free < -100) && !pko_command.s.dontfree) {
+		pko_command.s.dontfree = 1;
+		pko_command.s.reg0 = priv->fau+qos*4;
+	}
+
+	cvmx_pko_send_packet_prepare(priv->port, priv->queue + qos, CVMX_PKO_LOCK_CMD_QUEUE);
+
+	/* Drop this packet if we have too many already queued to the HW */
+	if (unlikely(skb_queue_len(&priv->tx_free_list[qos]) >=
+		     MAX_OUT_QUEUE_DEPTH)) {
+		/*
+		DEBUGPRINT("%s: Tx dropped. Too many queued\n", dev->name);
+		*/
+		dropped = 1;
+	}
+	/* Send the packet to the output queue */
+	else
+	if (unlikely(cvmx_pko_send_packet_finish(priv->port, priv->queue + qos, pko_command, hw_buffer, CVMX_PKO_LOCK_CMD_QUEUE))) {
+		DEBUGPRINT("%s: Failed to send the packet\n", dev->name);
+		dropped = 1;
+	}
+
+	if (USE_ASYNC_IOBDMA) {
+		/* Restore the scratch area */
+		cvmx_scratch_write64(CVMX_SCR_SCRATCH, old_scratch);
+		cvmx_scratch_write64(CVMX_SCR_SCRATCH+8, old_scratch2);
+	}
+
+	if (unlikely(dropped)) {
+		dev_kfree_skb_any(skb);
+		cvmx_fau_atomic_add32(priv->fau+qos*4, -1);
+		priv->stats.tx_dropped++;
+	} else {
+		if (USE_SKBUFFS_IN_HW) {
+			/* Put this packet on the queue to be freed later */
+			if (pko_command.s.dontfree){
+				if (unlikely(skb_shared(skb)))
+					dev_kfree_skb_any(skb);
+				else
+					skb_queue_tail(&priv->tx_free_list[qos], skb);
+			}
+			else {
+				cvmx_fau_atomic_add32(FAU_NUM_PACKET_BUFFERS_TO_FREE, -1);
+				cvmx_fau_atomic_add32(priv->fau+qos*4, -1);
+			}
+		} else {
+			 if (unlikely(skb_shared(skb)))
+				 dev_kfree_skb_any(skb);
+			 else
+				/* Put this packet on the queue to be freed later */
+				skb_queue_tail(&priv->tx_free_list[qos], skb);
+		}
+	}
+
+	/* Free skbuffs not in use by the hardware, possibly two at a time */
+	if (skb_queue_len(&priv->tx_free_list[qos]) > in_use) {
+		spin_lock(&priv->tx_free_list[qos].lock);
+		/* Check again now that we have the lock. It might have changed */
+		if (skb_queue_len(&priv->tx_free_list[qos]) > in_use)
+			dev_kfree_skb(__skb_dequeue(&priv->tx_free_list[qos]));
+		if (skb_queue_len(&priv->tx_free_list[qos]) > in_use)
+			dev_kfree_skb(__skb_dequeue(&priv->tx_free_list[qos]));
+		spin_unlock(&priv->tx_free_list[qos].lock);
+	}
+
+	return 0;
+}
+
+
+/**
+ * Packet transmit to the POW
+ *
+ * @param skb    Packet to send
+ * @param dev    Device info structure
+ * @return Always returns zero
+ */
+int cvm_oct_xmit_pow(struct sk_buff *skb, struct net_device *dev)
+{
+	cvm_oct_private_t  *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	void               *packet_buffer;
+	void               *copy_location;
+
+	/* Get a work queue entry */
+	cvmx_wqe_t *work = cvmx_fpa_alloc(CVMX_FPA_WQE_POOL);
+	if (unlikely(work == NULL)) {
+		DEBUGPRINT("%s: Failed to allocate a work queue entry\n", dev->name);
+		priv->stats.tx_dropped++;
+		dev_kfree_skb(skb);
+		return 0;
+	}
+
+	/* Get a packet buffer */
+	packet_buffer = cvmx_fpa_alloc(CVMX_FPA_PACKET_POOL);
+	if (unlikely(packet_buffer == NULL)) {
+		DEBUGPRINT("%s: Failed to allocate a packet buffer\n",
+			   dev->name);
+		cvmx_fpa_free(work, CVMX_FPA_WQE_POOL, DONT_WRITEBACK(1));
+		priv->stats.tx_dropped++;
+		dev_kfree_skb(skb);
+		return 0;
+	}
+
+	/* Calculate where we need to copy the data to. We need to leave 8 bytes
+	   for a next pointer (unused). We also need to include any configure
+	   skip. Then we need to align the IP packet src and dest into the same
+	   64bit word. The below calculation may add a little extra, but that
+	   doesn't hurt */
+	copy_location = packet_buffer + sizeof(uint64_t);
+	copy_location += ((CVMX_HELPER_FIRST_MBUFF_SKIP+7)&0xfff8) + 6;
+
+	/* We have to copy the packet since whoever processes this packet
+	   will free it to a hardware pool. We can't use the trick of
+	   counting outstanding packets like in cvm_oct_xmit */
+	memcpy(copy_location, skb->data, skb->len);
+
+	/* Fill in some of the work queue fields. We may need to add more
+	   if the software at the other end needs them */
+	work->hw_chksum     = skb->csum;
+	work->len           = skb->len;
+	work->ipprt         = priv->port;
+	work->qos           = priv->port & 0x7;
+	work->grp           = pow_send_group;
+	work->tag_type      = CVMX_HELPER_INPUT_TAG_TYPE;
+	work->tag           = pow_send_group; /* FIXME */
+	work->word2.u64     = 0;    /* Default to zero. Sets of zero later are commented out */
+	work->word2.s.bufs  = 1;
+	work->packet_ptr.u64 = 0;
+	work->packet_ptr.s.addr = cvmx_ptr_to_phys(copy_location);
+	work->packet_ptr.s.pool = CVMX_FPA_PACKET_POOL;
+	work->packet_ptr.s.size = CVMX_FPA_PACKET_POOL_SIZE;
+	work->packet_ptr.s.back = (copy_location - packet_buffer)>>7;
+
+	if (skb->protocol == htons(ETH_P_IP)) {
+		work->word2.s.ip_offset     = 14;
+		#if 0
+		work->word2.s.vlan_valid  = 0; /* FIXME */
+		work->word2.s.vlan_cfi    = 0; /* FIXME */
+		work->word2.s.vlan_id     = 0; /* FIXME */
+		work->word2.s.dec_ipcomp  = 0; /* FIXME */
+		#endif
+		work->word2.s.tcp_or_udp    = (ip_hdr(skb)->protocol == IP_PROTOCOL_TCP) || (ip_hdr(skb)->protocol == IP_PROTOCOL_UDP);
+		#if 0
+		work->word2.s.dec_ipsec   = 0; /* FIXME */
+		work->word2.s.is_v6       = 0; /* We only support IPv4 right now */
+		work->word2.s.software    = 0; /* Hardware would set to zero */
+		work->word2.s.L4_error    = 0; /* No error, packet is internal */
+		#endif
+		work->word2.s.is_frag       = !((ip_hdr(skb)->frag_off == 0) || (ip_hdr(skb)->frag_off == 1<<14));
+		#if 0
+		work->word2.s.IP_exc      = 0;  /* Assume Linux is sending a good packet */
+		#endif
+		work->word2.s.is_bcast      = (skb->pkt_type == PACKET_BROADCAST);
+		work->word2.s.is_mcast      = (skb->pkt_type == PACKET_MULTICAST);
+		#if 0
+		work->word2.s.not_IP      = 0; /* This is an IP packet */
+		work->word2.s.rcv_error   = 0; /* No error, packet is internal */
+		work->word2.s.err_code    = 0; /* No error, packet is internal */
+		#endif
+
+		/* When copying the data, include 4 bytes of the ethernet header to
+		   align the same way hardware does */
+		memcpy(work->packet_data, skb->data + 10, sizeof(work->packet_data));
+	} else {
+		#if 0
+		work->word2.snoip.vlan_valid  = 0; /* FIXME */
+		work->word2.snoip.vlan_cfi    = 0; /* FIXME */
+		work->word2.snoip.vlan_id     = 0; /* FIXME */
+		work->word2.snoip.software    = 0; /* Hardware would set to zero */
+		#endif
+		work->word2.snoip.is_rarp       = skb->protocol == htons(ETH_P_RARP);
+		work->word2.snoip.is_arp        = skb->protocol == htons(ETH_P_ARP);
+		work->word2.snoip.is_bcast      = (skb->pkt_type == PACKET_BROADCAST);
+		work->word2.snoip.is_mcast      = (skb->pkt_type == PACKET_MULTICAST);
+		work->word2.snoip.not_IP        = 1; /* IP was done up above */
+		#if 0
+		work->word2.snoip.rcv_error   = 0; /* No error, packet is internal */
+		work->word2.snoip.err_code    = 0; /* No error, packet is internal */
+		#endif
+		memcpy(work->packet_data, skb->data, sizeof(work->packet_data));
+	}
+
+	/* Submit the packet to the POW */
+	cvmx_pow_work_submit(work, work->tag, work->tag_type, work->qos, work->grp);
+	priv->stats.tx_packets++;
+	priv->stats.tx_bytes += skb->len;
+	dev_kfree_skb(skb);
+	return 0;
+}
+
+
+/**
+ * Transmit a work queue entry out of the ethernet port. Both
+ * the work queue entry and the packet data can optionally be
+ * freed. The work will be freed on error as well.
+ *
+ * @param dev     Device to transmit out.
+ * @param work_queue_entry
+ *                Work queue entry to send
+ * @param do_free True if the work queue entry and packet data should be
+ *                freed. If false, neither will be freed.
+ * @param qos     Index into the queues for this port to transmit on. This
+ *                is used to implement QoS if their are multiple queues per
+ *                port. This parameter must be between 0 and the number of
+ *                queues per port minus 1. Values outside of this range will
+ *                be change to zero.
+ *
+ * @return Zero on success, negative on failure.
+ */
+int cvm_oct_transmit_qos(struct net_device *dev, void *work_queue_entry, int do_free, int qos)
+{
+	unsigned long              flags;
+	cvmx_buf_ptr_t             hw_buffer;
+	cvmx_pko_command_word0_t   pko_command;
+	int                        dropped;
+	cvm_oct_private_t         *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	cvmx_wqe_t                *work = work_queue_entry;
+
+	if (!(dev->flags & IFF_UP)) {
+		DEBUGPRINT("%s: Device not up\n", dev->name);
+		if (do_free)
+			cvm_oct_free_work(work);
+		return -1;
+	}
+
+	/* The check on CVMX_PKO_QUEUES_PER_PORT_* is designed to completely
+	   remove "qos" in the event neither interface supports
+	   multiple queues per port */
+	if ((CVMX_PKO_QUEUES_PER_PORT_INTERFACE0 > 1) ||
+		(CVMX_PKO_QUEUES_PER_PORT_INTERFACE1 > 1)) {
+		if (qos <= 0)
+			qos = 0;
+		else if (qos >= cvmx_pko_get_num_queues(priv->port))
+			qos = 0;
+	} else
+		qos = 0;
+
+	/* Start off assuming no drop */
+	dropped = 0;
+
+	local_irq_save(flags);
+	cvmx_pko_send_packet_prepare(priv->port, priv->queue + qos, CVMX_PKO_LOCK_CMD_QUEUE);
+
+	/* Build the PKO buffer pointer */
+	hw_buffer.u64 = 0;
+	hw_buffer.s.addr = work->packet_ptr.s.addr;
+	hw_buffer.s.pool = CVMX_FPA_PACKET_POOL;
+	hw_buffer.s.size = CVMX_FPA_PACKET_POOL_SIZE;
+	hw_buffer.s.back = work->packet_ptr.s.back;
+
+	/* Build the PKO command */
+	pko_command.u64 = 0;
+	pko_command.s.n2 = 1; /* Don't pollute L2 with the outgoing packet */
+	pko_command.s.dontfree = !do_free;
+	pko_command.s.segs = work->word2.s.bufs;
+	pko_command.s.total_bytes = work->len;
+
+	/* Check if we can use the hardware checksumming */
+	if (unlikely(work->word2.s.not_IP || work->word2.s.IP_exc))
+		pko_command.s.ipoffp1 = 0;
+	else
+		pko_command.s.ipoffp1 = sizeof(struct ethhdr) + 1;
+
+	/* Send the packet to the output queue */
+	if (unlikely(cvmx_pko_send_packet_finish(priv->port, priv->queue + qos, pko_command, hw_buffer, CVMX_PKO_LOCK_CMD_QUEUE))) {
+		DEBUGPRINT("%s: Failed to send the packet\n", dev->name);
+		dropped = -1;
+	}
+	local_irq_restore(flags);
+
+	if (unlikely(dropped)) {
+		if (do_free)
+			cvm_oct_free_work(work);
+		priv->stats.tx_dropped++;
+	} else
+	if (do_free)
+		cvmx_fpa_free(work, CVMX_FPA_WQE_POOL, DONT_WRITEBACK(1));
+
+	return dropped;
+}
+EXPORT_SYMBOL(cvm_oct_transmit_qos);
+
+
+/**
+ * This function frees all skb that are currenty queued for TX.
+ *
+ * @param dev    Device being shutdown
+ */
+void cvm_oct_tx_shutdown(struct net_device *dev)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	unsigned long flags;
+	int qos;
+
+	for (qos = 0; qos < 16; qos++) {
+		spin_lock_irqsave(&priv->tx_free_list[qos].lock, flags);
+		while (skb_queue_len(&priv->tx_free_list[qos]))
+			dev_kfree_skb_any(__skb_dequeue(&priv->tx_free_list[qos]));
+		spin_unlock_irqrestore(&priv->tx_free_list[qos].lock, flags);
+	}
+}
diff --git a/drivers/net/cavium-ethernet/ethernet-tx.h b/drivers/net/cavium-ethernet/ethernet-tx.h
new file mode 100644
index 0000000..4baccde
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-tx.h
@@ -0,0 +1,42 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+
+int cvm_oct_xmit(struct sk_buff *skb, struct net_device *dev);
+int cvm_oct_xmit_pow(struct sk_buff *skb, struct net_device *dev);
+int cvm_oct_transmit_qos(struct net_device *dev, void *work_queue_entry, int do_free, int qos);
+void cvm_oct_tx_shutdown(struct net_device *dev);
+
diff --git a/drivers/net/cavium-ethernet/ethernet-util.h b/drivers/net/cavium-ethernet/ethernet-util.h
new file mode 100644
index 0000000..e11c5a7
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-util.h
@@ -0,0 +1,93 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+
+#define DEBUGPRINT(format, ...) do { if (printk_ratelimit()) 		\
+					printk(format, ##__VA_ARGS__);	\
+				} while (0)
+
+/**
+ * Given a packet data address, return a pointer to the
+ * beginning of the packet buffer.
+ *
+ * @param packet_ptr Packet data hardware address
+ * @return Packet buffer pointer
+ */
+static inline void *cvm_oct_get_buffer_ptr(cvmx_buf_ptr_t packet_ptr)
+{
+	return cvmx_phys_to_ptr(((packet_ptr.s.addr >> 7) - packet_ptr.s.back) << 7);
+}
+
+
+/**
+ * Given an IPD/PKO port number, return the logical interface it is
+ * on.
+ *
+ * @param ipd_port Port to check
+ *
+ * @return Logical interface
+ */
+static inline int INTERFACE(int ipd_port)
+{
+	if (ipd_port < 32)    /* Interface 0 or 1 for RGMII,GMII,SPI, etc */
+		return ipd_port>>4;
+	else if (ipd_port < 36)   /* Interface 2 for NPI */
+		return 2;
+	else if (ipd_port < 40)   /* Interface 3 for loopback */
+		return 3;
+	else if (ipd_port == 40)  /* Non existant interface for POW0 */
+		return 4;
+	else
+		panic("Illegal ipd_port %d passed to INTERFACE\n", ipd_port);
+}
+
+
+/**
+ * Given an IPD/PKO port number, return the port's index on a
+ * logical interface.
+ *
+ * @param ipd_port Port to check
+ *
+ * @return Index into interface port list
+ */
+static inline int INDEX(int ipd_port)
+{
+	if (ipd_port < 32)
+		return ipd_port & 15;
+	else
+		return ipd_port & 3;
+}
+
diff --git a/drivers/net/cavium-ethernet/ethernet-xaui.c b/drivers/net/cavium-ethernet/ethernet-xaui.c
new file mode 100644
index 0000000..667c687
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet-xaui.c
@@ -0,0 +1,131 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/mii.h>
+#include <net/dst.h>
+#include <hal.h>
+
+#include "wrapper-cvmx-includes.h"
+#include "ethernet-headers.h"
+
+static int cvm_oct_xaui_open(struct net_device *dev)
+{
+	cvmx_gmxx_prtx_cfg_t gmx_cfg;
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int interface = INTERFACE(priv->port);
+	int index = INDEX(priv->port);
+	cvmx_helper_link_info_t link_info;
+
+	gmx_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));
+	gmx_cfg.s.en = 1;
+	cvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmx_cfg.u64);
+
+	if (!octeon_is_simulation()) {
+		link_info = cvmx_helper_link_get(priv->port);
+		if (!link_info.s.link_up)
+			netif_carrier_off(dev);
+	}
+	return 0;
+}
+
+static int cvm_oct_xaui_stop(struct net_device *dev)
+{
+	cvmx_gmxx_prtx_cfg_t gmx_cfg;
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	int interface = INTERFACE(priv->port);
+	int index = INDEX(priv->port);
+
+	gmx_cfg.u64 = cvmx_read_csr(CVMX_GMXX_PRTX_CFG(index, interface));
+	gmx_cfg.s.en = 0;
+	cvmx_write_csr(CVMX_GMXX_PRTX_CFG(index, interface), gmx_cfg.u64);
+	return 0;
+}
+
+static void cvm_oct_xaui_poll(struct net_device *dev)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	cvmx_helper_link_info_t link_info;
+
+	link_info = cvmx_helper_link_get(priv->port);
+	if (link_info.u64 == priv->link_info)
+		return;
+
+	link_info = cvmx_helper_link_autoconf(priv->port);
+	priv->link_info = link_info.u64;
+
+	/* Tell Linux */
+	if (link_info.s.link_up) {
+
+		if (!netif_carrier_ok(dev))
+			netif_carrier_on(dev);
+		if (priv->queue != -1)
+			DEBUGPRINT("%s: %u Mbps %s duplex, port %2d, queue "
+				   "%2d\n", dev->name, link_info.s.speed,
+				   (link_info.s.full_duplex) ? "Full" : "Half",
+				   priv->port, priv->queue);
+		else
+			DEBUGPRINT("%s: %u Mbps %s duplex, port %2d, POW\n",
+				   dev->name, link_info.s.speed,
+				   (link_info.s.full_duplex) ? "Full" : "Half",
+				   priv->port);
+	} else {
+		if (netif_carrier_ok(dev))
+			netif_carrier_off(dev);
+		DEBUGPRINT("%s: Link down\n", dev->name);
+	}
+}
+
+
+int cvm_oct_xaui_init(struct net_device *dev)
+{
+	cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+	cvm_oct_common_init(dev);
+	dev->open = cvm_oct_xaui_open;
+	dev->stop = cvm_oct_xaui_stop;
+	dev->stop(dev);
+	if (!octeon_is_simulation())
+		priv->poll = cvm_oct_xaui_poll;
+
+    return 0;
+}
+
+void cvm_oct_xaui_uninit(struct net_device *dev)
+{
+	cvm_oct_common_uninit(dev);
+}
+
diff --git a/drivers/net/cavium-ethernet/ethernet.c b/drivers/net/cavium-ethernet/ethernet.c
new file mode 100644
index 0000000..84b640f
--- /dev/null
+++ b/drivers/net/cavium-ethernet/ethernet.c
@@ -0,0 +1,528 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/mii.h>
+#include <net/dst.h>
+#include <asm/delay.h>
+
+#include "wrapper-cvmx-includes.h"
+#include "ethernet-headers.h"
+#include "ethernet-mdio.h"
+
+#if defined(CONFIG_CAVIUM_OCTEON_NUM_PACKET_BUFFERS) && \
+	CONFIG_CAVIUM_OCTEON_NUM_PACKET_BUFFERS
+int num_packet_buffers = CONFIG_CAVIUM_OCTEON_NUM_PACKET_BUFFERS;
+#else
+int num_packet_buffers = 1024;
+#endif
+module_param(num_packet_buffers, int, 0444);
+MODULE_PARM_DESC(num_packet_buffers, "\n"
+		 "\t\tNumber of packet buffers to allocate and store in the\n"
+		 "\t\tFPA. By default, 1024 packet buffers are used unless\n"
+		 "\t\tCONFIG_CAVIUM_OCTEON_NUM_PACKET_BUFFERS is defined.");
+
+int pow_receive_group = 15;
+module_param(pow_receive_group, int, 0444);
+MODULE_PARM_DESC(pow_receive_group, "\n"
+		 "\t\tPOW group to receive packets from. All ethernet hardware\n"
+		 "\t\twill be configured to send incomming packets to this POW\n"
+		 "\t\tgroup. Also any other software can submit packets to this\n"
+		 "\t\tgroup for the kernel to process.");
+
+int pow_send_group = -1;
+module_param(pow_send_group, int, 0644);
+MODULE_PARM_DESC(pow_send_group, "\n"
+		 "\t\tPOW group to send packets to other software on. This\n"
+		 "\t\tcontrols the creation of the virtual device pow0.\n"
+		 "\t\talways_use_pow also depends on this value.");
+
+int always_use_pow;
+module_param(always_use_pow, int, 0444);
+MODULE_PARM_DESC(always_use_pow, "\n"
+		 "\t\tWhen set, always send to the pow group. This will cause\n"
+		 "\t\tpackets sent to real ethernet devices to be sent to the\n"
+		 "\t\tPOW group instead of the hardware. Unless some other\n"
+		 "\t\tapplication changes the config, packets will still be\n"
+		 "\t\treceived from the low level hardware. Use this option\n"
+		 "\t\tto allow a CVMX app to intercept all packets from the\n"
+		 "\t\tlinux kernel. You must specify pow_send_group along with\n"
+		 "\t\tthis option.");
+
+char pow_send_list[128] = "";
+module_param_string(pow_send_list, pow_send_list, sizeof(pow_send_list), 0444);
+MODULE_PARM_DESC(pow_send_list, "\n"
+		 "\t\tComma separated list of ethernet devices that should use the\n"
+		 "\t\tPOW for transmit instead of the actual ethernet hardware. This\n"
+		 "\t\tis a per port version of always_use_pow. always_use_pow takes\n"
+		 "\t\tprecedence over this list. For example, setting this to\n"
+		 "\t\t\"eth2,spi3,spi7\" would cause these three devices to transmit\n"
+		 "\t\tusing the pow_send_group.");
+
+
+static int disable_core_queueing = 1;
+module_param(disable_core_queueing, int, 0444);
+MODULE_PARM_DESC(disable_core_queueing, "\n"
+		"\t\tWhen set the networking core's tx_queue_len is set to "
+		 "zero.  This\n"
+		"\t\tallows packets to be sent without lock contention in the "
+		 "packet scheduler\n"
+		"\t\tresulting in some cases in improved throughput.\n");
+
+extern int octeon_is_simulation(void);
+
+/**
+ * Exported from the kernel so we can determine board information. It is
+ * passed by the bootloader to the kernel.
+ */
+extern cvmx_bootinfo_t *octeon_bootinfo;
+
+/**
+ * Periodic timer to check auto negotiation
+ */
+static struct timer_list cvm_oct_poll_timer;
+
+/**
+ * Array of every ethernet device owned by this driver indexed by
+ * the ipd input port number.
+ */
+struct net_device *cvm_oct_device[TOTAL_NUMBER_OF_PORTS];
+
+
+/**
+ * Periodic timer tick for slow management operations
+ *
+ * @param arg    Device to check
+ */
+static void cvm_do_timer(unsigned long arg)
+{
+	static int port;
+	if (port < CVMX_PIP_NUM_INPUT_PORTS) {
+		if (cvm_oct_device[port]) {
+			int queues_per_port;
+			int qos;
+			cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(cvm_oct_device[port]);
+			if (priv->poll) {
+				/* skip polling if we don't get the lock */
+				if (!down_trylock(&mdio_sem)) {
+					priv->poll(cvm_oct_device[port]);
+					up(&mdio_sem);
+				}
+			}
+
+			queues_per_port = cvmx_pko_get_num_queues(port);
+			/* Drain any pending packets in the free list */
+			for (qos = 0; qos < queues_per_port; qos++) {
+				if (skb_queue_len(&priv->tx_free_list[qos])) {
+					spin_lock(&priv->tx_free_list[qos].lock);
+					while (skb_queue_len(&priv->tx_free_list[qos]) > cvmx_fau_fetch_and_add32(priv->fau+qos*4, 0))
+						dev_kfree_skb(__skb_dequeue(&priv->tx_free_list[qos]));
+					spin_unlock(&priv->tx_free_list[qos].lock);
+				}
+			}
+			cvm_oct_device[port]->get_stats(cvm_oct_device[port]);
+		}
+		port++;
+		/* Poll the next port in a 50th of a second.
+		   This spreads the polling of ports out a little bit */
+		mod_timer(&cvm_oct_poll_timer, jiffies + HZ/50);
+	} else {
+		port = 0;
+		/* All ports have been polled. Start the next iteration through
+		   the ports in one second */
+		mod_timer(&cvm_oct_poll_timer, jiffies + HZ);
+	}
+}
+
+
+/**
+ * Configure common hardware for all interfaces
+ */
+static __init void cvm_oct_configure_common_hw(void)
+{
+	int r;
+	/* Setup the FPA */
+	cvmx_fpa_enable();
+	cvm_oct_mem_fill_fpa(CVMX_FPA_PACKET_POOL, CVMX_FPA_PACKET_POOL_SIZE,
+			     num_packet_buffers);
+	cvm_oct_mem_fill_fpa(CVMX_FPA_WQE_POOL, CVMX_FPA_WQE_POOL_SIZE,
+			     num_packet_buffers);
+	if (CVMX_FPA_OUTPUT_BUFFER_POOL != CVMX_FPA_PACKET_POOL)
+		cvm_oct_mem_fill_fpa(CVMX_FPA_OUTPUT_BUFFER_POOL, CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE, 128);
+
+	if (USE_RED)
+		cvmx_helper_setup_red(num_packet_buffers/4,
+				      num_packet_buffers/8);
+
+	/* Enable the MII interface */
+	if (!octeon_is_simulation())
+		cvmx_write_csr(CVMX_SMI_EN, 1);
+
+	/* Register an IRQ hander for to receive POW interrupts */
+	r = request_irq(OCTEON_IRQ_WORKQ0 + pow_receive_group,
+			cvm_oct_do_interrupt, IRQF_SHARED, "Ethernet",
+			cvm_oct_device);
+
+#ifdef CONFIG_SMP
+	if (USE_MULTICORE_RECEIVE) {
+		preempt_disable();
+		{
+			int cpu;
+			for (cpu = 0; cpu < NR_CPUS; cpu++) {
+				if (cpu_online(cpu) &&
+				   (cpu != smp_processor_id())) {
+					cvmx_ciu_intx0_t en;
+					en.u64 = cvmx_read_csr(CVMX_CIU_INTX_EN0(cpu_logical_map(cpu)*2));
+					en.s.workq |= (1<<pow_receive_group);
+					cvmx_write_csr(CVMX_CIU_INTX_EN0(cpu_logical_map(cpu)*2), en.u64);
+				}
+			}
+		}
+		preempt_enable();
+	}
+#endif
+}
+
+
+/**
+ * Registers a intercept callback for the names ethernet
+ * device. It returns the Linux device structure for the
+ * ethernet port. Usign a callback of NULL will remove
+ * the callback. Note that this callback must not disturb
+ * scratch. It will be called with SYNCIOBDMAs in progress
+ * and userspace may be using scratch. It also must not
+ * disturb the group mask.
+ *
+ * @param device_name
+ *                 Device name to register for. (Example: "eth0")
+ * @param callback Intercept callback to set.
+ * @return Device structure for the ethernet port or NULL on failure.
+ */
+struct net_device *cvm_oct_register_callback(const char *device_name, cvm_oct_callback_t callback)
+{
+	int port;
+
+	for (port = 0; port < TOTAL_NUMBER_OF_PORTS; port++) {
+		if (cvm_oct_device[port] &&
+		    (strcmp(device_name, cvm_oct_device[port]->name) == 0)) {
+			cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(cvm_oct_device[port]);
+			priv->intercept_cb = callback;
+			wmb();
+			return cvm_oct_device[port];
+		}
+	}
+
+	return NULL;
+}
+EXPORT_SYMBOL(cvm_oct_register_callback);
+
+
+/**
+ * Free a work queue entry received in a intercept callback.
+ *
+ * @param work_queue_entry
+ *               Work queue entry to free
+ * @return Zero on success, Negative on failure.
+ */
+int cvm_oct_free_work(void *work_queue_entry)
+{
+	cvmx_wqe_t *work = work_queue_entry;
+
+	int segments = work->word2.s.bufs;
+	cvmx_buf_ptr_t segment_ptr = work->packet_ptr;
+
+	while (segments--) {
+		cvmx_buf_ptr_t next_ptr = *(cvmx_buf_ptr_t *)cvmx_phys_to_ptr(segment_ptr.s.addr-8);
+		if (unlikely(!segment_ptr.s.i))
+			cvmx_fpa_free(cvm_oct_get_buffer_ptr(segment_ptr), segment_ptr.s.pool, DONT_WRITEBACK(CVMX_FPA_PACKET_POOL_SIZE/128));
+		segment_ptr = next_ptr;
+	}
+	cvmx_fpa_free(work, CVMX_FPA_WQE_POOL, DONT_WRITEBACK(1));
+
+	return 0;
+}
+EXPORT_SYMBOL(cvm_oct_free_work);
+
+
+/**
+ * Module/ driver initialization. Creates the linux network
+ * devices.
+ *
+ * @return Zero on success
+ */
+static int __init cvm_oct_init_module(void)
+{
+	extern int cvm_oct_rgmii_init(struct net_device *dev);
+	extern void cvm_oct_rgmii_uninit(struct net_device *dev);
+	extern int cvm_oct_sgmii_init(struct net_device *dev);
+	extern void cvm_oct_sgmii_uninit(struct net_device *dev);
+	extern int cvm_oct_spi_init(struct net_device *dev);
+	extern void cvm_oct_spi_uninit(struct net_device *dev);
+	extern int cvm_oct_xaui_init(struct net_device *dev);
+	extern void cvm_oct_xaui_uninit(struct net_device *dev);
+
+	int num_interfaces;
+	int interface;
+	int fau = FAU_NUM_PACKET_BUFFERS_TO_FREE;
+	int qos;
+
+	printk("cavium-ethernet: %s\n", OCTEON_SDK_VERSION_STRING);
+
+	cvm_oct_proc_initialize();
+	cvm_oct_rx_initialize();
+	cvm_oct_configure_common_hw();
+
+	cvmx_helper_initialize_packet_io_global();
+
+	/* Change the input group for all ports before input is enabled */
+	num_interfaces = cvmx_helper_get_number_of_interfaces();
+	for (interface = 0; interface < num_interfaces; interface++) {
+		int num_ports = cvmx_helper_ports_on_interface(interface);
+		int port;
+
+		for (port = cvmx_helper_get_ipd_port(interface, 0); port < cvmx_helper_get_ipd_port(interface, num_ports); port++) {
+			cvmx_pip_prt_tagx_t pip_prt_tagx;
+			pip_prt_tagx.u64 = cvmx_read_csr(CVMX_PIP_PRT_TAGX(port));
+			pip_prt_tagx.s.grp = pow_receive_group;
+			cvmx_write_csr(CVMX_PIP_PRT_TAGX(port), pip_prt_tagx.u64);
+		}
+	}
+
+	cvmx_helper_ipd_and_packet_input_enable();
+
+	memset(cvm_oct_device, 0, sizeof(cvm_oct_device));
+
+	/* Initialize the FAU used for counting packet buffers that need to be freed */
+	cvmx_fau_atomic_write32(FAU_NUM_PACKET_BUFFERS_TO_FREE, 0);
+
+	if ((pow_send_group != -1)) {
+		struct net_device *dev;
+		printk("\tConfiguring device for POW only access\n");
+		dev = alloc_etherdev(sizeof(cvm_oct_private_t));
+		if (dev) {
+			/* Initialize the device private structure. */
+			cvm_oct_private_t *priv = (cvm_oct_private_t *)netdev_priv(dev);
+			memset(priv, 0, sizeof(cvm_oct_private_t));
+
+			dev->init = cvm_oct_common_init;
+			priv->imode = CVMX_HELPER_INTERFACE_MODE_DISABLED;
+			priv->port = CVMX_PIP_NUM_INPUT_PORTS;
+			priv->queue = -1;
+			strcpy(dev->name, "pow%d");
+			for (qos = 0; qos < 16; qos++)
+				skb_queue_head_init(&priv->tx_free_list[qos]);
+
+			if (register_netdev(dev) < 0) {
+				printk("\t\tFailed to register ethernet device for POW\n");
+				kfree(dev);
+			} else {
+				cvm_oct_device[CVMX_PIP_NUM_INPUT_PORTS] = dev;
+				printk("\t\t%s: POW send group %d, receive group %d\n",
+				dev->name, pow_send_group, pow_receive_group);
+			}
+		} else {
+			printk("\t\tFailed to allocate ethernet device for POW\n");
+		}
+	}
+
+	num_interfaces = cvmx_helper_get_number_of_interfaces();
+	for (interface = 0; interface < num_interfaces; interface++) {
+		cvmx_helper_interface_mode_t imode = cvmx_helper_interface_get_mode(interface);
+		int num_ports = cvmx_helper_ports_on_interface(interface);
+		int port;
+
+		for (port = cvmx_helper_get_ipd_port(interface, 0); port < cvmx_helper_get_ipd_port(interface, num_ports); port++) {
+			cvm_oct_private_t *priv;
+			struct net_device *dev = alloc_etherdev(sizeof(cvm_oct_private_t));
+			if (!dev) {
+				printk("\t\tFailed to allocate ethernet device for port %d\n", port);
+				continue;
+			}
+			if (disable_core_queueing)
+				dev->tx_queue_len = 0;
+
+			/* Initialize the device private structure. */
+			priv = (cvm_oct_private_t *)netdev_priv(dev);
+			memset(priv, 0, sizeof(cvm_oct_private_t));
+
+			priv->imode = imode;
+			priv->port = port;
+			priv->queue = cvmx_pko_get_base_queue(priv->port);
+			priv->intercept_cb = NULL;
+			priv->fau = fau - cvmx_pko_get_num_queues(port) * 4;
+			for (qos = 0; qos < 16; qos++)
+				skb_queue_head_init(&priv->tx_free_list[qos]);
+			for (qos = 0; qos < cvmx_pko_get_num_queues(port); qos++)
+				cvmx_fau_atomic_write32(priv->fau+qos*4, 0);
+
+			switch (priv->imode) {
+
+			/* These types don't support ports to IPD/PKO */
+			case CVMX_HELPER_INTERFACE_MODE_DISABLED:
+			case CVMX_HELPER_INTERFACE_MODE_PCIE:
+			case CVMX_HELPER_INTERFACE_MODE_PICMG:
+				break;
+
+			case CVMX_HELPER_INTERFACE_MODE_NPI:
+				dev->init = cvm_oct_common_init;
+				dev->uninit = cvm_oct_common_uninit;
+				strcpy(dev->name, "npi%d");
+				break;
+
+			case CVMX_HELPER_INTERFACE_MODE_XAUI:
+				dev->init = cvm_oct_xaui_init;
+				dev->uninit = cvm_oct_xaui_uninit;
+				strcpy(dev->name, "xaui%d");
+				break;
+
+			case CVMX_HELPER_INTERFACE_MODE_LOOP:
+				dev->init = cvm_oct_common_init;
+				dev->uninit = cvm_oct_common_uninit;
+				strcpy(dev->name, "loop%d");
+				break;
+
+			case CVMX_HELPER_INTERFACE_MODE_SGMII:
+				dev->init = cvm_oct_sgmii_init;
+				dev->uninit = cvm_oct_sgmii_uninit;
+				strcpy(dev->name, "eth%d");
+				break;
+
+			case CVMX_HELPER_INTERFACE_MODE_SPI:
+				dev->init = cvm_oct_spi_init;
+				dev->uninit = cvm_oct_spi_uninit;
+				strcpy(dev->name, "spi%d");
+				break;
+
+			case CVMX_HELPER_INTERFACE_MODE_RGMII:
+			case CVMX_HELPER_INTERFACE_MODE_GMII:
+				dev->init = cvm_oct_rgmii_init;
+				dev->uninit = cvm_oct_rgmii_uninit;
+				strcpy(dev->name, "eth%d");
+				break;
+			}
+
+			if (!dev->init) {
+				kfree(dev);
+			} else
+			if (register_netdev(dev) < 0) {
+				printk("\t\tFailed to register ethernet device for interface %d, port %d\n",
+				interface, priv->port);
+				kfree(dev);
+			} else {
+				cvm_oct_device[priv->port] = dev;
+				fau -= cvmx_pko_get_num_queues(priv->port) * sizeof(uint32_t);
+			}
+		}
+	}
+
+	if (INTERRUPT_LIMIT) {
+		/* Set the POW timer rate to give an interrupt at most INTERRUPT_LIMIT times per second */
+		cvmx_write_csr(CVMX_POW_WQ_INT_PC, octeon_bootinfo->eclock_hz/(INTERRUPT_LIMIT*16*256)<<8);
+
+		/* Enable POW timer interrupt. It will count when there are packets available */
+		cvmx_write_csr(CVMX_POW_WQ_INT_THRX(pow_receive_group), 0x1ful<<24);
+	} else {
+		/* Enable POW interrupt when our port has at least one packet */
+		cvmx_write_csr(CVMX_POW_WQ_INT_THRX(pow_receive_group), 0x1001);
+	}
+
+	/* Enable the poll timer for checking RGMII status */
+	init_timer(&cvm_oct_poll_timer);
+	cvm_oct_poll_timer.data = 0;
+	cvm_oct_poll_timer.function = cvm_do_timer;
+	mod_timer(&cvm_oct_poll_timer, jiffies + HZ);
+
+	return 0;
+}
+
+
+/**
+ * Module / driver shutdown
+ *
+ * @return Zero on success
+ */
+static void __exit cvm_oct_cleanup_module(void)
+{
+	int port;
+
+	/* Disable POW interrupt */
+	cvmx_write_csr(CVMX_POW_WQ_INT_THRX(pow_receive_group), 0);
+
+	cvmx_ipd_disable();
+
+	/* Free the interrupt handler */
+	free_irq(8 + pow_receive_group, cvm_oct_device);
+
+	del_timer(&cvm_oct_poll_timer);
+	cvm_oct_rx_shutdown();
+	cvmx_pko_disable();
+
+	/* Free the ethernet devices */
+	for (port = 0; port < TOTAL_NUMBER_OF_PORTS; port++) {
+		if (cvm_oct_device[port]) {
+			cvm_oct_tx_shutdown(cvm_oct_device[port]);
+			unregister_netdev(cvm_oct_device[port]);
+			kfree(cvm_oct_device[port]);
+			cvm_oct_device[port] = NULL;
+		}
+	}
+
+	cvmx_pko_shutdown();
+	cvm_oct_proc_shutdown();
+
+	cvmx_ipd_free_ptr();
+
+	/* Free the HW pools */
+	cvm_oct_mem_empty_fpa(CVMX_FPA_PACKET_POOL, CVMX_FPA_PACKET_POOL_SIZE,
+			      num_packet_buffers);
+	cvm_oct_mem_empty_fpa(CVMX_FPA_WQE_POOL, CVMX_FPA_WQE_POOL_SIZE,
+			      num_packet_buffers);
+	if (CVMX_FPA_OUTPUT_BUFFER_POOL != CVMX_FPA_PACKET_POOL)
+		cvm_oct_mem_empty_fpa(CVMX_FPA_OUTPUT_BUFFER_POOL, CVMX_FPA_OUTPUT_BUFFER_POOL_SIZE, 128);
+}
+
+/* Note that this module is covered by the GPL even though the files are
+    under a BSD style license. The GPL is inherited from the CVMX files
+    used by this driver. If you would like to use the module under the
+    Cavium proprietary license, you must change the makefile to include
+    the proprietary CVMX files. */
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Cavium Networks <support@caviumnetworks.com>");
+MODULE_DESCRIPTION("Cavium Networks Octeon ethernet driver.");
+module_init(cvm_oct_init_module);
+module_exit(cvm_oct_cleanup_module);
+
diff --git a/drivers/net/cavium-ethernet/wrapper-cvmx-includes.h b/drivers/net/cavium-ethernet/wrapper-cvmx-includes.h
new file mode 100644
index 0000000..702e8af
--- /dev/null
+++ b/drivers/net/cavium-ethernet/wrapper-cvmx-includes.h
@@ -0,0 +1,58 @@
+/*************************************************************************
+* Cavium Octeon Ethernet Driver
+*
+* Author: Cavium Networks info@caviumnetworks.com
+*
+* Copyright (c) 2003-2007  Cavium Networks (support@cavium.com). All rights
+* reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*
+*     * Neither the name of Cavium Networks nor the names of
+*       its contributors may be used to endorse or promote products
+*       derived from this software without specific prior written
+*       permission.
+*
+* TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE SOFTWARE IS PROVIDED "AS IS"
+* AND WITH ALL FAULTS AND CAVIUM NETWORKS MAKES NO PROMISES, REPRESENTATIONS
+* OR WARRANTIES, EITHER EXPRESS, IMPLIED, STATUTORY, OR OTHERWISE, WITH
+* RESPECT TO THE SOFTWARE, INCLUDING ITS CONDITION, ITS CONFORMITY TO ANY
+* REPRESENTATION OR DESCRIPTION, OR THE EXISTENCE OF ANY LATENT OR PATENT
+* DEFECTS, AND CAVIUM SPECIFICALLY DISCLAIMS ALL IMPLIED (IF ANY) WARRANTIES
+* OF TITLE, MERCHANTABILITY, NONINFRINGEMENT, FITNESS FOR A PARTICULAR
+* PURPOSE, LACK OF VIRUSES, ACCURACY OR COMPLETENESS, QUIET ENJOYMENT, QUIET
+* POSSESSION OR CORRESPONDENCE TO DESCRIPTION.  THE ENTIRE RISK ARISING OUT
+* OF USE OR PERFORMANCE OF THE SOFTWARE LIES WITH YOU.
+*************************************************************************/
+#ifndef __WRAPPER_CVMX_INCLUDES_H__
+#define __WRAPPER_CVMX_INCLUDES_H__
+
+#undef OCTEON_MODEL
+#define USE_RUNTIME_MODEL_CHECKS 1
+
+#include "cvmx.h"
+#include "cvmx-version.h"
+#include "cvmx-atomic.h"
+#include "cvmx-ciu.h"
+#include "cvmx-pip.h"
+#include "cvmx-ipd.h"
+#include "cvmx-pko.h"
+#include "cvmx-pow.h"
+#include "cvmx-gmx.h"
+#include "cvmx-spi.h"
+#include "cvmx-bootmem.h"
+#include "cvmx-app-init.h"
+#include "cvmx-helper.h"
+#include "cvmx-helper-board.h"
+
+#endif
diff --git a/drivers/net/sky2.c b/drivers/net/sky2.c
index 42963a9..9c6f1f7 100644
--- a/drivers/net/sky2.c
+++ b/drivers/net/sky2.c
@@ -4071,7 +4071,14 @@ static __devinit struct net_device *sky2_init_netdev(struct sky2_hw *hw,
 	sky2->duplex = -1;
 	sky2->speed = -1;
 	sky2->advertising = sky2_supported_modes(hw);
+#ifdef CONFIG_CPU_CAVIUM_OCTEON
+	/* The PCIe network card I'm using for testing happens to not support
+	   rx csum correctly. I'm turning it off for all Octeons, but it really
+	   is a PCIe card problem */
+	sky2->rx_csum = 0;
+#else
 	sky2->rx_csum = (hw->chip_id != CHIP_ID_YUKON_XL);
+#endif
 	sky2->wol = wol;
 
 	spin_lock_init(&sky2->phy_lock);
diff --git a/include/net/xfrm.h b/include/net/xfrm.h
index 2933d74..ae4d034 100644
--- a/include/net/xfrm.h
+++ b/include/net/xfrm.h
@@ -214,6 +214,10 @@ struct xfrm_state
 	/* Private data of this transformer, format is opaque,
 	 * interpreted by xfrm_type methods. */
 	void			*data;
+#if defined(CONFIG_CAVIUM_OCTEON_IPSEC) && defined(CONFIG_NET_KEY)
+	void			*sa_handle;
+	struct xfrm_policy	*pol;
+#endif  /* defined(CONFIG_CAVIUM_OCTEON_IPSEC) && defined(CONFIG_NET_KEY) */
 };
 
 /* xflags - make enum if more show up */
@@ -474,6 +478,9 @@ struct xfrm_policy
 	/* XXX 1 byte hole, try to pack */
 	struct xfrm_sec_ctx	*security;
 	struct xfrm_tmpl       	xfrm_vec[XFRM_MAX_DEPTH];
+#if defined(CONFIG_CAVIUM_OCTEON_IPSEC) && defined(CONFIG_NET_KEY)
+	struct xfrm_state      *x;
+#endif /* defined(CONFIG_CAVIUM_OCTEON_IPSEC) && defined(CONFIG_NET_KEY) */
 };
 
 struct xfrm_migrate {
diff --git a/net/core/dev.c b/net/core/dev.c
index 01ae913..e125753 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -512,6 +512,11 @@ int netdev_boot_setup_check(struct net_device *dev)
 	return 0;
 }
 
+#ifdef CONFIG_CAVIUM_OCTEON_IPFWD_OFFLOAD
+/* Cavium fast-path rx/tx hooks */
+uint32_t (*cvm_ipfwd_rx_hook)(struct sk_buff *) = NULL;
+int      (*cvm_ipfwd_tx_hook)(struct sk_buff *) = NULL;
+#endif
 
 /**
  *	netdev_boot_base	- get address from boot time settings
@@ -1819,6 +1824,13 @@ int dev_queue_xmit(struct sk_buff *skb)
 	struct Qdisc *q;
 	int rc = -ENOMEM;
 
+#ifdef CONFIG_CAVIUM_OCTEON_IPFWD_OFFLOAD
+	if (cvm_ipfwd_tx_hook) {
+		if (cvm_ipfwd_tx_hook(skb) == (-ENOMEM))
+			goto out_kfree_skb;
+	}
+#endif
+
 	/* GSO will handle the following emulations directly. */
 	if (netif_needs_gso(dev, skb))
 		goto gso;
@@ -2282,6 +2294,13 @@ int netif_receive_skb(struct sk_buff *skb)
 	if (skb->vlan_tci && vlan_hwaccel_do_receive(skb))
 		return NET_RX_SUCCESS;
 
+#ifdef CONFIG_CAVIUM_OCTEON_IPFWD_OFFLOAD
+	if (cvm_ipfwd_rx_hook) {
+		if (!cvm_ipfwd_rx_hook(skb))
+			return NET_RX_SUCCESS;
+	}
+#endif
+
 	/* if we've gotten here through NAPI, check netpoll */
 	if (netpoll_receive_skb(skb))
 		return NET_RX_DROP;
@@ -5005,3 +5024,8 @@ EXPORT_SYMBOL(dev_load);
 #endif
 
 EXPORT_PER_CPU_SYMBOL(softnet_data);
+
+#ifdef CONFIG_CAVIUM_OCTEON_IPFWD_OFFLOAD
+EXPORT_SYMBOL(cvm_ipfwd_rx_hook);
+EXPORT_SYMBOL(cvm_ipfwd_tx_hook);
+#endif
diff --git a/net/netfilter/nf_conntrack_proto_tcp.c b/net/netfilter/nf_conntrack_proto_tcp.c
index fcbc6b9..0b4ab25 100644
--- a/net/netfilter/nf_conntrack_proto_tcp.c
+++ b/net/netfilter/nf_conntrack_proto_tcp.c
@@ -480,6 +480,10 @@ static void tcp_sack(const struct sk_buff *skb, unsigned int dataoff,
 	}
 }
 
+#ifdef CAVIUM_OCTEON_IPFWD_OFFLOAD
+extern uint32_t (*cvm_ipfwd_rx_hook)(struct sk_buff *);
+#endif
+
 static bool tcp_in_window(const struct nf_conn *ct,
 			  struct ip_ct_tcp *state,
 			  enum ip_conntrack_dir dir,
@@ -495,6 +499,13 @@ static bool tcp_in_window(const struct nf_conn *ct,
 	__u32 seq, ack, sack, end, win, swin;
 	bool res;
 
+#ifdef CAVIUM_OCTEON_IPFWD_OFFLOAD
+	if (cvm_ipfwd_rx_hook) {
+		if (skb->cvm_info.cookie == ~0x12345ull)
+			return 1;
+	}
+#endif
+
 	/*
 	 * Get the required data from the packet.
 	 */
-- 
1.5.5.1

