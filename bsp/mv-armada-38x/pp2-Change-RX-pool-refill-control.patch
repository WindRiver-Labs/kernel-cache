From 933b62c8994bd5264a185dc78b38506d6b46639e Mon Sep 17 00:00:00 2001
From: Dmitri Epshtein <dima@marvell.com>
Date: Sun, 28 Jul 2013 13:24:55 -0400
Subject: [PATCH 0901/1825] pp2: Change RX pool refill control

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 146a7125a07fa6c7a7115f07466d51b49e9c4a71

        Use "atomic_t in_use" instead of "u32 __percpu pcpu_in_use"
        Using atomic_t improve SMP routing performance for about 8%

Change-Id: I3b0f2d5fea74dd4b8077b9514cd515634858a20c
Signed-off-by: Dmitri Epshtein <dima@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/2857
Reviewed-by: Nadav Haklai <nadavh@marvell.com>
Tested-by: Nadav Haklai <nadavh@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c      |   55 +++++--------------
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h      |   11 +---
 2 files changed, 17 insertions(+), 49 deletions(-)

diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
index f1b60b1..1976f09 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
@@ -1255,18 +1255,6 @@ static inline int mv_eth_tx_policy(struct eth_port *pp, struct sk_buff *skb)
 }
 
 #ifdef CONFIG_NET_SKB_RECYCLE
-struct bm_in_use_update {
-	struct bm_pool *ppool;
-	int delta;
-};
-void mv_eth_bm_in_use_update(void *data)
-{
-	struct bm_in_use_update *in_use_delta = (struct bm_in_use_update *)data;
-
-	STAT_DBG(in_use_delta->ppool->stats.in_use_update_on_other_cpu++);
-	this_cpu_add(*in_use_delta->ppool->pcpu_in_use, in_use_delta->delta);
-}
-
 int mv_eth_skb_recycle(struct sk_buff *skb)
 {
 	int pool, cpu;
@@ -1307,6 +1295,7 @@ int mv_eth_skb_recycle(struct sk_buff *skb)
 #endif /* CONFIG_MV_ETH_DEBUG_CODE */
 
 		STAT_DBG(ppool->stats.skb_recycled_ok++);
+
 		phys_addr = dma_map_single(NULL, skb->head, RX_BUF_SIZE(ppool->pkt_size), DMA_FROM_DEVICE);
 		/*phys_addr = virt_to_phys(skb->head);*/
 	} else {
@@ -1323,22 +1312,15 @@ int mv_eth_skb_recycle(struct sk_buff *skb)
 		}
 	}
 	mv_eth_pool_refill(ppool, bm, phys_addr, (unsigned long) skb);
-	this_cpu_dec(*ppool->pcpu_in_use);
+	atomic_dec(&ppool->in_use);
 
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
 	if (cpu != smp_processor_id()) {
-		int in_use = *per_cpu_ptr(ppool->pcpu_in_use, smp_processor_id());
-		STAT_DBG(ppool->stats.skb_recycle_on_other_cpu++);
-		if (abs(in_use) > 0xFFFF) {
-			struct bm_in_use_update in_use_update;
-
-			in_use_update.ppool = ppool;
-			in_use_update.delta = in_use;
-			if (smp_call_function_single(cpu, mv_eth_bm_in_use_update, (void *)&in_use_update, 1))
-				pr_err("%s: smp_call_function_single on cpu %d failed\n", __func__, cpu);
-			else
-				this_cpu_sub(*ppool->pcpu_in_use, in_use);
-		}
+		pr_warning("%s on CPU=%d other than RX=%d\n", __func__,
+			smp_processor_id(), cpu);
 	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
 	return !is_recyclable;
 }
 EXPORT_SYMBOL(mv_eth_skb_recycle);
@@ -1443,7 +1425,7 @@ inline int mv_eth_refill(struct bm_pool *ppool, __u32 bm, int is_recycle)
 	}
 	STAT_DBG(ppool->stats.no_recycle++);
 	mv_eth_pool_refill(ppool, bm, phys_addr, (unsigned long) skb);
-	this_cpu_dec(*ppool->pcpu_in_use);
+	atomic_dec(&ppool->in_use);
 
 	return 0;
 }
@@ -1662,7 +1644,7 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 			continue;
 		}
 		skb = (struct sk_buff *)rx_desc->bufCookie;
-		this_cpu_inc(*ppool->pcpu_in_use);
+		atomic_inc(&ppool->in_use);
 
 		/*dma_unmap_single(NULL, rx_desc->bufPhysAddr, RX_BUF_SIZE(ppool->pkt_size), DMA_FROM_DEVICE);*/
 
@@ -2558,7 +2540,8 @@ static MV_STATUS mv_eth_pool_create(int pool, int capacity)
 	bm_pool->capacity = capacity;
 	bm_pool->pkt_size = 0;
 	bm_pool->buf_num = 0;
-	bm_pool->pcpu_in_use = alloc_percpu(int);
+	atomic_set(&bm_pool->in_use, 0);
+
 	spin_lock_init(&bm_pool->lock);
 
 	return MV_OK;
@@ -4543,7 +4526,7 @@ void mv_eth_pool_status_print(int pool)
 {
 	const char *type;
 	struct bm_pool *bm_pool = &mv_eth_pool[pool];
-	int buf_size, total_size, true_size, cpu;
+	int buf_size, total_size, true_size;
 
 	if (MV_ETH_BM_POOL_IS_HWF(bm_pool->type)) {
 		buf_size = RX_HWF_BUF_SIZE(bm_pool->pkt_size);
@@ -4583,8 +4566,9 @@ void mv_eth_pool_status_print(int pool)
 	pr_info("\nBM Pool #%d: pool type = %s, buffers num = %d\n", pool, type, bm_pool->buf_num);
 	pr_info("     packet size = %d, buffer size = %d, total size = %d, true size = %d\n",
 		bm_pool->pkt_size, buf_size, total_size, true_size);
-	pr_info("     capacity=%d, buf_num=%d, port_map=0x%x, in_use_thresh=%u\n",
-		bm_pool->capacity, bm_pool->buf_num, bm_pool->port_map, bm_pool->in_use_thresh);
+	pr_info("     capacity=%d, buf_num=%d, port_map=0x%x, in_use=%u, in_use_thresh=%u\n",
+		bm_pool->capacity, bm_pool->buf_num, bm_pool->port_map,
+		mv_eth_bm_in_use_read(bm_pool), bm_pool->in_use_thresh);
 
 #ifdef CONFIG_MV_ETH_STAT_ERR
 	pr_cont("     skb_alloc_oom=%u", bm_pool->stats.skb_alloc_oom);
@@ -4597,17 +4581,8 @@ void mv_eth_pool_status_print(int pool)
 	pr_info("     no_recycle=%u, skb_recycled_ok=%u, skb_recycled_err=%u, bm_cookie_err=%u\n",
 		bm_pool->stats.no_recycle, bm_pool->stats.skb_recycled_ok,
 		bm_pool->stats.skb_recycled_err, bm_pool->stats.bm_cookie_err);
-
-	pr_info("     skb_recycle_on_other_cpu=%u, in_use_update=%u\n",
-		bm_pool->stats.skb_recycle_on_other_cpu,
-		bm_pool->stats.in_use_update_on_other_cpu);
 #endif /* CONFIG_MV_ETH_STAT_DBG */
 
-	pr_info("in_use[cpu]     = ");
-	for_each_possible_cpu(cpu)
-		pr_cont("%3d  ", *per_cpu_ptr(bm_pool->pcpu_in_use, cpu));
-	pr_cont("  [%d]\n", mv_eth_bm_in_use_read(bm_pool));
-
 	memset(&bm_pool->stats, 0, sizeof(bm_pool->stats));
 }
 
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
index 84070ee..9dcace3 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
@@ -423,8 +423,6 @@ struct pool_stats {
 	u32 skb_recycled_ok;
 	u32 skb_recycled_err;
 	u32 bm_cookie_err;
-	u32 skb_recycle_on_other_cpu;
-	u32 in_use_update_on_other_cpu;
 #endif /* CONFIG_MV_ETH_STAT_DBG */
 };
 
@@ -489,7 +487,7 @@ struct bm_pool {
 	MV_ULONG            physAddr;
 	spinlock_t          lock;
 	u32                 port_map;
-	int        __percpu *pcpu_in_use;
+	atomic_t    in_use;
 	int                 in_use_thresh;
 	struct              pool_stats stats;
 };
@@ -539,12 +537,7 @@ static inline __u32 mv_eth_bm_cookie_build(struct pp2_rx_desc *rx_desc)
 
 static inline int mv_eth_bm_in_use_read(struct bm_pool *bm)
 {
-	int cpu, in_use = 0;
-
-	for_each_possible_cpu(cpu)
-		in_use += *per_cpu_ptr(bm->pcpu_in_use, cpu);
-
-	return in_use;
+	return atomic_read(&bm->in_use);
 }
 
 extern struct bm_pool mv_eth_pool[MV_ETH_BM_POOLS];
-- 
1.7.5.4

