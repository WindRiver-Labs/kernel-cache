From 2c226f7b9b49f399187de44cb3c989fae745ac34 Mon Sep 17 00:00:00 2001
From: Uri Eliyahu <uriel@marvell.com>
Date: Mon, 11 Nov 2013 15:48:22 +0200
Subject: [PATCH 1145/1825] pp2: ppv2.1 add l2fw support

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit f220eccb87e66c1ef9c89d4c456c2a7ccf9bbcba

	- add l2fw support for ppv2.1 (A0)
	- verified on ppv2.0 (Z1)

Change-Id: I657d0708e16e818d03ed2a8d2c26c73814e2e6bf
Signed-off-by: Uri Eliyahu <uriel@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/4385
Reviewed-by: Dmitri Epshtein <dima@marvell.com>
Tested-by: Star_Automation <star@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 .../mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c       |  156 ++++++++++++++------
 .../mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h       |   12 +--
 2 files changed, 116 insertions(+), 52 deletions(-)

diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c
index af18180..00f9956 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c
@@ -45,6 +45,8 @@ static int numHashEntries;
 static int shared;
 
 static struct l2fw_rule **l2fw_hash;
+static struct eth_port_l2fw **mv_eth_ports_l2fw;
+static int eth_ports_l2fw_num;
 
 static MV_U32 l2fw_jhash_iv;
 
@@ -53,9 +55,6 @@ static MV_XOR_DESC *eth_xor_desc;
 static MV_LONG      eth_xor_desc_phys_addr;
 #endif
 
-static struct eth_port_l2fw **mv_eth_ports_l2fw;
-static int eth_ports_l2fw_num;
-
 inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq);
 inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_desc *rx_desc);
 inline int mv_l2fw_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl);
@@ -644,6 +643,7 @@ inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_de
 	struct tx_queue *txq_ctrl;
 	struct aggr_tx_queue *aggr_txq_ctrl = NULL;
 	struct txq_cpu_ctrl *txq_cpu_ptr;
+	int qset, grntd;
 	int cpu = smp_processor_id(), poolId, frags = 1;
 	tx_spec_ptr = &pp->tx_spec;
 	tx_spec_ptr->txq = pp->cpu_config[cpu]->txq;
@@ -652,14 +652,16 @@ inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_de
 	txq_ctrl = &pp->txq_ctrl[tx_spec_ptr->txp * CONFIG_MV_ETH_TXQ + tx_spec_ptr->txq];
 	txq_cpu_ptr = &(txq_ctrl->txq_cpu[cpu]);
 
-	if (!mv_eth_aggr_desc_num_check(aggr_txq_ctrl, frags))
-		goto out;
-
 #ifdef CONFIG_MV_ETH_PP2_1
-	/* TODO: remove ? */
-	if (!mv_eth_reserved_desc_num_proc(pp, tx_spec_ptr->txp, tx_spec_ptr->txq, frags))
+	if (mv_eth_reserved_desc_num_proc(pp, tx_spec_ptr->txp, tx_spec_ptr->txq, frags) ||
+		mv_eth_aggr_desc_num_check(aggr_txq_ctrl, frags)) {
+		frags = 0;
 		goto out;
-#endif
+	}
+#else
+	if (mv_eth_aggr_desc_num_check(aggr_txq_ctrl, frags))
+		goto out;
+#endif /*CONFIG_MV_ETH_PP2_1*/
 
 	/* Get next descriptor for tx, single buffer, so FIRST & LAST */
 	tx_desc = mvPp2AggrTxqNextDescGet(aggr_txq_ctrl->q);
@@ -681,7 +683,8 @@ inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_de
 
 	/* buffers released by HW */
 	tx_cmd |= (poolId << PP2_TX_POOL_INDEX_OFFS) | PP2_TX_BUF_RELEASE_MODE_MASK |
-			PP2_TX_F_DESC_MASK | PP2_TX_L_DESC_MASK | PP2_TX_L4_CSUM_NOT | PP2_TX_IP_CSUM_DISABLE_MASK;
+			PP2_TX_F_DESC_MASK | PP2_TX_L_DESC_MASK |
+			PP2_TX_L4_CSUM_NOT | PP2_TX_IP_CSUM_DISABLE_MASK;
 
 	tx_desc->command = tx_cmd;
 
@@ -707,11 +710,16 @@ inline int mv_l2fw_tx(struct sk_buff *skb, struct eth_port *pp, struct pp2_rx_de
 	if (txq_cpu_ptr->txq_count >= mv_ctrl_txdone)
 		mv_l2fw_txq_done(pp, txq_ctrl);
 
-	tx_desc->dataSize = rx_desc->dataSize - MV_ETH_MH_SIZE;
+	if (MV_PON_PORT(pp->port)) {
+		tx_desc->dataSize  = rx_desc->dataSize;
+		tx_desc->pktOffset = skb_headroom(skb);
+	} else {
+		tx_desc->dataSize  = rx_desc->dataSize - MV_ETH_MH_SIZE;
+		tx_desc->pktOffset = skb_headroom(skb) + MV_ETH_MH_SIZE;
+	}
+
 	tx_desc->bufCookie = (MV_U32)skb;
 	tx_desc->bufPhysAddr = mvOsCacheFlush(NULL, skb->head, tx_desc->dataSize);
-	tx_desc->pktOffset = MV_ETH_MH_SIZE + skb_headroom(skb);
-
 	mv_eth_tx_desc_flush(tx_desc);
 
 	/* TODO - XOR ready check */
@@ -767,41 +775,106 @@ inline int mv_l2fw_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl)
 	return tx_done;
 }
 
-static void mv_l2fw_txq_done_force(struct eth_port *pp, struct tx_queue *txq_ctrl)
+static int mv_l2fw_txq_done_force(struct eth_port *pp, struct tx_queue *txq_ctrl)
 {
-	int cpu;
+	int cpu, tx_done;
 	struct txq_cpu_ctrl *txq_cpu_ptr;
 
 	for_each_possible_cpu(cpu) {
 		txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
+		tx_done += txq_cpu_ptr->txq_count;
 		txq_cpu_ptr->txq_count = 0;
 	}
+	return tx_done;
+}
+
+static int mv_l2fw_txq_clean(int port, int txp, int txq)
+{
+	struct eth_port *pp;
+	struct tx_queue *txq_ctrl;
+	int msec, pending, tx_done;
+
+	if (mvPp2TxpCheck(port, txp))
+		return -EINVAL;
+
+	pp = mv_eth_port_by_id(port);
+	if ((pp == NULL) || (pp->txq_ctrl == NULL))
+		return -ENODEV;
+
+	if (mvPp2MaxCheck(txq, CONFIG_MV_ETH_TXQ, "txq"))
+		return -EINVAL;
+
+	txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+	if (txq_ctrl->q) {
+		/* Enable TXQ drain */
+		mvPp2TxqDrainSet(port, txp, txq, MV_TRUE);
+
+		/* Wait for all packets to be transmitted */
+		msec = 0;
+		do {
+			if (msec >= 1000 /*timeout*/) {
+				pr_err("port=%d, txp=%d txq=%d: timeout for transmit pending descriptors\n",
+					port, txp, txq);
+				break;
+			}
+			mdelay(1);
+			msec++;
+
+			pending = mvPp2TxqPendDescNumGet(port, txp, txq);
+		} while (pending);
+
+		/* Disable TXQ Drain */
+		mvPp2TxqDrainSet(port, txp, txq, MV_FALSE);
+
+		/* release all transmitted packets */
+		tx_done = mv_l2fw_txq_done(pp, txq_ctrl);
+		if (tx_done > 0)
+			mvOsPrintf(KERN_INFO "%s: port=%d, txp=%d txq=%d: Free %d transmitted descriptors\n",
+				__func__, port, txp, txq, tx_done);
+
+		/* release all untransmitted packets */
+		tx_done = mv_l2fw_txq_done_force(pp, txq_ctrl);
+		if (tx_done > 0)
+			mvOsPrintf(KERN_INFO "%s: port=%d, txp=%d txq=%d: Free %d untransmitted descriptors\n",
+				__func__, port, txp, txq, tx_done);
+	}
+	return 0;
 }
 
 static int mv_l2fw_txp_clean(int port, int txp)
 {
-	struct eth_port *pp = mv_eth_port_by_id(port);
-	int queue;
+	struct eth_port *pp;
+	int txq;
 
-	for (queue = 0; queue < CONFIG_MV_ETH_TXQ; queue++) {
-		struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + queue];
-		if (txq_ctrl->q) {
+	if (mvPp2TxpCheck(port, txp))
+		return -EINVAL;
 
-			/* TODO ppv2.1 - add support */
-			/* TODO ppv2.0 - release panding to bm pools */
+	pp = mv_eth_port_by_id(port);
+	if ((pp == NULL) || (pp->txq_ctrl == NULL))
+		return -ENODEV;
 
-			mv_l2fw_txq_done(pp, txq_ctrl);
-			mv_l2fw_txq_done_force(pp, txq_ctrl);
-			/*printk (KERN_ERR "panding = %d\n", mvPp2TxqPendDescNumGet(pp->port, txp, queue));*/
-		}
+	if (pp->flags & MV_ETH_F_STARTED) {
+		printk(KERN_ERR "Port %d must be stopped before\n", port);
+		return -EINVAL;
 	}
 
+	/* Flush TX FIFO */
+	mvPp2TxPortFifoFlush(port, MV_TRUE);
+
+	/* free the skb's in the hal tx ring */
+	for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++)
+		mv_l2fw_txq_clean(port, txp, txq);
+
+	mvPp2TxPortFifoFlush(port, MV_FALSE);
+
 	mvPp2TxpReset(port, txp);
 
-	return MV_OK;
+	return 0;
 }
 
 
+
+
 inline void mv_l2fw_pool_refill(struct eth_port *pp,
 				     struct bm_pool *pool, struct pp2_rx_desc *rx_desc)
 {
@@ -886,11 +959,6 @@ inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 			continue;
 		}
 
-#ifdef CONFIG_MV_ETH_DEBUG_CODE
-		if (pp->dbg_flags & MV_ETH_F_DBG_RX)
-			mvDebugMemDump(skb->data, 64, 1);
-#endif /* CONFIG_MV_ETH_DEBUG_CODE */
-
 		ipOffset = (rx_status & PP2_RX_L3_OFFSET_MASK) >> PP2_RX_L3_OFFSET_OFFS;
 
 		pIph = (MV_IP_HEADER *)(skb->data + ipOffset);
@@ -900,17 +968,21 @@ inline int mv_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 			continue;
 		}
 #ifdef CONFIG_MV_ETH_L2FW_DEBUG
-		if (pIph) {
-			MV_U8 *srcIP, *dstIP;
-			srcIP = (MV_U8 *)&(pIph->srcIP);
-			dstIP = (MV_U8 *)&(pIph->dstIP);
-			printk(KERN_INFO "%u.%u.%u.%u->%u.%u.%u.%u in %s\n",
-					MV_IPQUAD(srcIP), MV_IPQUAD(dstIP), __func__);
-			printk(KERN_INFO "0x%x->0x%x in %s\n", pIph->srcIP, pIph->dstIP, __func__);
-		} else
-			printk(KERN_INFO "pIph is NULL in %s\n", __func__);
-#endif
+		if (pp->dbg_flags & MV_ETH_F_DBG_RX) {
+
+			mvDebugMemDump(skb->data, 64, 1);
 
+			if (pIph) {
+				MV_U8 *srcIP, *dstIP;
+				srcIP = (MV_U8 *)&(pIph->srcIP);
+				dstIP = (MV_U8 *)&(pIph->dstIP);
+				printk(KERN_INFO "%u.%u.%u.%u->%u.%u.%u.%u in %s\n",
+						MV_IPQUAD(srcIP), MV_IPQUAD(dstIP), __func__);
+				printk(KERN_INFO "0x%x->0x%x in %s\n", pIph->srcIP, pIph->dstIP, __func__);
+			} else
+				printk(KERN_INFO "pIph is NULL in %s\n", __func__);
+		}
+#endif
 		if (ppl2fw->lookupEn) {
 			rule = l2fw_lookup(pIph->srcIP, pIph->dstIP);
 
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h
index dcee8c3..4f1cebe 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h
@@ -35,14 +35,10 @@ disclaimer.
 #define	L2FW_HASH_SIZE   (1 << 17)
 #define	L2FW_HASH_MASK   (L2FW_HASH_SIZE - 1)
 
-#define L2FW_PORT_OFFS				0
-#define L2FW_PORT_MASK				0xFF
-#define L2FW_TXP_OFFS				8
-#define L2FW_TXP_MASK				0xFF
-#define L2FW_TXQ_OFFS				16
-#define L2FW_TXQ_MASK				0xFF
+extern struct aggr_tx_queue *aggr_txqs;
 
 /* L2fw defines */
+
 #define CMD_L2FW_AS_IS				0
 #define CMD_L2FW_SWAP_MAC			1
 #define CMD_L2FW_COPY_SWAP			2
@@ -52,9 +48,6 @@ disclaimer.
 #define XOR_CAUSE_DONE_MASK(chan) ((BIT0|BIT1) << (chan * 16))
 #define XOR_THRESHOLD_DEF			2000;
 
-extern spinlock_t l2sec_lock;
-extern struct aggr_tx_queue *aggr_txqs;
-
 struct eth_port_l2fw {
 	int cmd;
 	int lookupEn;
@@ -82,5 +75,4 @@ void mv_l2fw_rules_dump(void);
 void mv_l2fw_ports_dump(void);
 void mv_l2fw_stats(void);
 
-
 #endif
-- 
1.7.5.4

