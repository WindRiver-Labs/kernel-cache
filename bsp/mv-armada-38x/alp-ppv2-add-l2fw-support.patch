From b9b87d859d32b3b324ff8a930873a6f568ebef58 Mon Sep 17 00:00:00 2001
From: Uri Eliyahu <uriel@marvell.com>
Date: Wed, 24 Jul 2013 11:53:23 +0300
Subject: [PATCH 0897/1825] alp:ppv2: add l2fw support

https://github.com/MISL-EBU-System-SW/misl-windriver.git linux-3.4.69-14t2-read
commit 5d95a16946606c8710cd6c91565f5bae109c8d34

	- add l2fw support to pp2

Change-Id: Idadb6c967066c8a7ac4d4c0c4daf179befc0f864
Signed-off-by: Uri Eliyahu <uriel@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/2830
Tested-by: Star_Automation <star@marvell.com>
Reviewed-by: Igor Patrik <igorp@marvell.com>
Signed-off-by: Zhong Hongbo <hongbo.zhong@windriver.com>
---
 .../arm/plat-armada/mv_drivers_lsp/mv_pp2/Makefile |    3 +
 .../mv_drivers_lsp/mv_pp2/l2fw/l2fw_sysfs.c        |  252 +++++
 .../mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c       | 1015 ++++++++++++++++++++
 .../mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h       |   79 ++
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h   |    5 +
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c      |   77 ++-
 .../mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h      |   11 +-
 arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2GbeRegs.h |   11 +
 8 files changed, 1438 insertions(+), 15 deletions(-)
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/l2fw_sysfs.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h

diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Makefile b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Makefile
index 2017c4a..76e1791 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Makefile
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/Makefile
@@ -39,6 +39,9 @@ mv_pp2-objs += cls/cls_sysfs.o cls/cls2_sysfs.o cls/cls3_sysfs.o cls/cls4_sysfs.
 mv_pp2-objs += pme/pme_sysfs.o
 mv_pp2-objs += plcr/plcr_sysfs.o
 
+ifeq ($(CONFIG_MV_ETH_L2FW),y)
+mv_pp2-objs += l2fw/l2fw_sysfs.o l2fw/mv_eth_l2fw.o
+endif
 
 ccflags-y       += -I$(PLAT_PATH_I)/$(HAL_PP2_DIR)
 
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/l2fw_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/l2fw_sysfs.c
new file mode 100644
index 0000000..8245eff
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/l2fw_sysfs.c
@@ -0,0 +1,252 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/capability.h>
+#include <linux/kernel.h>
+#include <linux/platform_device.h>
+
+#include "mvTypes.h"
+#include "mv_eth_l2fw.h"
+#ifdef CONFIG_MV_ETH_L2SEC
+#include "mv_eth_l2sec.h"
+#endif
+#include "linux/inet.h"
+
+
+static ssize_t l2fw_help(char *buf)
+{
+	int off = 0;
+
+	off += sprintf(buf+off, "cat rules_dump      - display L2fw rules DB\n");
+	off += sprintf(buf+off, "cat ports_dump      - display L2fw ports DB\n");
+	off += sprintf(buf+off, "cat stats           - show debug information\n");
+
+	off += sprintf(buf+off, "echo rxp txp mode > l2fw     - set <rxp-->txp,mode> 0-dis,1-as_is,2-swap,3-copy\n");
+	off += sprintf(buf+off, "echo rxp thresh   > l2fw_xor - set for port <rxp> xor threshold ,input in decimal\n");
+	off += sprintf(buf+off, "echo rxp en       > lookup   - set for port <rxp> lookup enable:0 or disable:1\n");
+	off += sprintf(buf+off, "echo 1            > flush    - flush L2fw rules DB\n");
+	off += sprintf(buf+off, "echo sIp dIp txp  > l2fw_ip  - set rule, srcIp and DstIp in ip address format\n");
+#ifdef CONFIG_MV_ETH_L2SEC
+	off += sprintf(buf+off, "echo p chan       > cesa_chan- set cesa channel <chan> for port <p>.\n");
+#endif
+	return off;
+}
+
+static ssize_t l2fw_show(struct device *dev,
+				  struct device_attribute *attr, char *buf)
+{
+	int off = 0;
+	const char *name = attr->attr.name;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	if (!strcmp(name, "help")) {
+		off = l2fw_help(buf);
+		return off;
+	} else if (!strcmp(name, "rules_dump")) {
+		l2fw_rules_dump();
+		return off;
+	} else if (!strcmp(name, "ports_dump")) {
+		l2fw_ports_dump();
+		return off;
+	} else if (!strcmp(name, "stats")) {
+		l2fw_stats();
+		return off;
+	}
+
+	return off;
+}
+
+
+
+static ssize_t l2fw_hex_store(struct device *dev, struct device_attribute *attr,
+				const char *buf, size_t len)
+{
+	const char      *name = attr->attr.name;
+	int             err;
+	unsigned int    addr1, addr2;
+	int port;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+	err = addr1 = addr2 = port = 0;
+
+	local_irq_save(flags);
+
+	if (!strcmp(name, "flush")) {
+		l2fw_flush();
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	return err ? -EINVAL : len;
+}
+
+static ssize_t l2fw_ip_store(struct device *dev,
+			 struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char *name = attr->attr.name;
+
+	unsigned int err = 0;
+	unsigned int srcIp = 0, dstIp = 0;
+	unsigned char *sipArr = (unsigned char *)&srcIp;
+	unsigned char *dipArr = (unsigned char *)&dstIp;
+	int port;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%hhu.%hhu.%hhu.%hhu %hhu.%hhu.%hhu.%hhu %d",
+		sipArr, sipArr+1, sipArr+2, sipArr+3,
+		dipArr, dipArr+1, dipArr+2, dipArr+3, &port);
+
+	printk(KERN_INFO "0x%x->0x%x in %s\n", srcIp, dstIp, __func__);
+	local_irq_save(flags);
+
+	if (!strcmp(name, "l2fw_add_ip"))
+		l2fw_add(srcIp, dstIp, port);
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+
+
+static ssize_t l2fw_store(struct device *dev,
+				   struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char	*name = attr->attr.name;
+	int             err;
+
+	unsigned int    a, b, c;
+	unsigned long   flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	err = a = b = c = 0;
+	sscanf(buf, "%d %d %d", &a, &b, &c);
+
+	local_irq_save(flags);
+	if (!strcmp(name, "lookup"))
+		l2fw_lookupEn(a, b);
+#ifdef CONFIG_MV_INCLUDE_XOR
+	else if (!strcmp(name, "l2fw_xor"))
+		l2fw_xor(a, b);
+#endif
+	else if (!strcmp(name, "l2fw"))
+		l2fw(c, a, b);
+#ifdef CONFIG_MV_ETH_L2SEC
+	else if (!strcmp(name, "cesa_chan"))
+		err = mv_l2sec_set_cesa_chan(a, b);
+#endif
+	local_irq_restore(flags);
+
+	if (err)
+		mvOsPrintf("%s: error %d\n", __func__, err);
+
+	return err ? -EINVAL : len;
+
+}
+
+
+static DEVICE_ATTR(l2fw,		S_IWUSR, l2fw_show, l2fw_store);
+#ifdef CONFIG_MV_INCLUDE_XOR
+static DEVICE_ATTR(l2fw_xor,		S_IWUSR, l2fw_show, l2fw_store);
+#endif
+
+static DEVICE_ATTR(lookup,		S_IWUSR, l2fw_show, l2fw_store);
+static DEVICE_ATTR(l2fw_add_ip,		S_IWUSR, l2fw_show, l2fw_ip_store);
+static DEVICE_ATTR(help,		S_IRUSR, l2fw_show,  NULL);
+static DEVICE_ATTR(rules_dump,		S_IRUSR, l2fw_show,  NULL);
+static DEVICE_ATTR(ports_dump,		S_IRUSR, l2fw_show,  NULL);
+static DEVICE_ATTR(flush,		S_IWUSR, NULL,	l2fw_hex_store);
+static DEVICE_ATTR(stats,		S_IRUSR, l2fw_show, NULL);
+
+#ifdef CONFIG_MV_ETH_L2SEC
+static DEVICE_ATTR(cesa_chan,		S_IWUSR, NULL,  l2fw_store);
+#endif
+
+
+
+static struct attribute *l2fw_attrs[] = {
+	&dev_attr_l2fw.attr,
+#ifdef CONFIG_MV_INCLUDE_XOR
+	&dev_attr_l2fw_xor.attr,
+#endif
+	&dev_attr_lookup.attr,
+	&dev_attr_l2fw_add_ip.attr,
+	&dev_attr_help.attr,
+	&dev_attr_rules_dump.attr,
+	&dev_attr_ports_dump.attr,
+	&dev_attr_flush.attr,
+	&dev_attr_stats.attr,
+#ifdef CONFIG_MV_ETH_L2SEC
+	&dev_attr_cesa_chan.attr,
+#endif
+	NULL
+};
+
+static struct attribute_group l2fw_group = {
+	.name = "l2fw",
+	.attrs = l2fw_attrs,
+};
+
+int mv_pp2_l2fw_sysfs_init(struct kobject *pp2_kobj)
+{
+	int err = 0;
+
+	err = sysfs_create_group(pp2_kobj, &l2fw_group);
+	if (err)
+		printk(KERN_INFO "sysfs group %s failed %d\n", l2fw_group.name, err);
+
+	return err;
+}
+
+int mv_pp2_l2fw_sysfs_exit(struct kobject *pp2_kobj)
+{
+	sysfs_remove_group(pp2_kobj, &l2fw_group);
+
+	return 0;
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c
new file mode 100644
index 0000000..5dd8125
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.c
@@ -0,0 +1,1015 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#include <linux/ctype.h>
+#include <linux/module.h>
+#include  <linux/interrupt.h>
+
+#ifdef CONFIG_MV_INCLUDE_XOR
+#include "xor/mvXor.h"
+#include "xor/mvXorRegs.h"
+#include "mv_hal_if/mvSysXorApi.h"
+#endif
+
+#include "mvOs.h"
+#include "mv_eth_l2fw.h"
+#include "mv_pp2/net_dev/mv_netdev.h"
+#include "gbe/mvPp2Gbe.h"
+#include "gbe/mvPp2GbeRegs.h"
+#include "mvDebug.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+
+#ifdef CONFIG_MV_ETH_L2SEC
+#include "mv_eth_l2sec.h"
+#endif
+
+static int numHashEntries;
+
+struct eth_pbuf *mv_eth_pool_get(struct bm_pool *pool);
+
+static int mv_eth_ports_l2fw_num;
+
+static struct l2fw_rule **l2fw_hash;
+
+static MV_U32 l2fw_jhash_iv;
+
+#ifdef CONFIG_MV_INCLUDE_XOR
+static MV_XOR_DESC *eth_xor_desc;
+static MV_LONG      eth_xor_desc_phys_addr;
+#endif
+struct eth_port_l2fw **mv_eth_ports_l2fw;
+static inline int       mv_eth_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq);
+static inline MV_STATUS mv_eth_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp,
+					   int withXor, struct pp2_rx_desc *rx_desc);
+
+static struct l2fw_rule *l2fw_lookup(MV_U32 srcIP, MV_U32 dstIP)
+{
+	MV_U32 hash;
+	struct l2fw_rule *rule;
+
+	hash = mv_jhash_3words(srcIP, dstIP, (MV_U32) 0, l2fw_jhash_iv);
+	hash &= L2FW_HASH_MASK;
+	rule = l2fw_hash[hash];
+
+	while (rule) {
+		if ((rule->srcIP == srcIP) && (rule->dstIP == dstIP)) {
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+			printk(KERN_INFO "rule is not NULL in %s\n", __func__);
+#endif
+			return rule;
+		}
+
+		rule = rule->next;
+	}
+
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+	printk(KERN_INFO "rule is NULL in %s\n", __func__);
+#endif
+
+	return NULL;
+}
+
+void l2fw_show_numHashEntries(void)
+{
+	mvOsPrintf("number of Hash Entries is %d\n", numHashEntries);
+
+}
+
+
+void l2fw_flush(void)
+{
+	MV_U32 i = 0;
+	mvOsPrintf("\nFlushing L2fw Rule Database:\n");
+	mvOsPrintf("*******************************\n");
+	for (i = 0; i < L2FW_HASH_SIZE; i++)
+		l2fw_hash[i] = NULL;
+	numHashEntries = 0;
+}
+
+
+void l2fw_rules_dump(void)
+{
+	MV_U32 i = 0;
+	struct l2fw_rule *currRule;
+	MV_U8	  *srcIP, *dstIP;
+
+	mvOsPrintf("\nPrinting L2fw Rule Database:\n");
+	mvOsPrintf("*******************************\n");
+
+	for (i = 0; i < L2FW_HASH_SIZE; i++) {
+		currRule = l2fw_hash[i];
+		srcIP = (MV_U8 *)&(currRule->srcIP);
+		dstIP = (MV_U8 *)&(currRule->dstIP);
+
+		while (currRule != NULL) {
+			mvOsPrintf("%u.%u.%u.%u->%u.%u.%u.%u     out port=%d (hash=%x)\n",
+				MV_IPQUAD(srcIP), MV_IPQUAD(dstIP),
+				currRule->port, i);
+			currRule = currRule->next;
+		}
+	}
+
+}
+
+void l2fw_ports_dump(void)
+{
+	MV_U32 rx_port = 0;
+	struct eth_port_l2fw *ppl2fw;
+
+	mvOsPrintf("\nPrinting L2fw ports Database:\n");
+	mvOsPrintf("*******************************\n");
+
+	for (rx_port = 0; rx_port < mv_eth_ports_l2fw_num; rx_port++) {
+		ppl2fw = mv_eth_ports_l2fw[rx_port];
+		mvOsPrintf("rx_port=%d cmd = %d tx_port=%d lookup=%d xor_threshold = %d\n",
+				rx_port, ppl2fw->cmd, ppl2fw->txPort, ppl2fw->lookupEn, ppl2fw->xorThreshold);
+
+	}
+}
+
+
+MV_STATUS l2fw_add(MV_U32 srcIP, MV_U32 dstIP, int port)
+{
+	struct l2fw_rule *rule;
+	MV_U8	  *srcIPchr, *dstIPchr;
+
+	MV_U32 hash = mv_jhash_3words(srcIP, dstIP, (MV_U32) 0, l2fw_jhash_iv);
+	hash &= L2FW_HASH_MASK;
+	if (numHashEntries == L2FW_HASH_SIZE) {
+		printk(KERN_INFO "cannot add entry, hash table is full, there are %d entires\n", L2FW_HASH_SIZE);
+		return MV_ERROR;
+	}
+
+	srcIPchr = (MV_U8 *)&(srcIP);
+	dstIPchr = (MV_U8 *)&(dstIP);
+
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+	mvOsPrintf("srcIP=%x dstIP=%x in %s\n", srcIP, dstIP, __func__);
+	mvOsPrintf("srcIp = %u.%u.%u.%u in %s\n", MV_IPQUAD(srcIPchr), __func__);
+	mvOsPrintf("dstIp = %u.%u.%u.%u in %s\n", MV_IPQUAD(dstIPchr), __func__);
+#endif
+
+	rule = l2fw_lookup(srcIP, dstIP);
+	if (rule) {
+		/* overwite port */
+		rule->port = port;
+		return MV_OK;
+	}
+
+	rule = (struct l2fw_rule *)mvOsMalloc(sizeof(struct l2fw_rule));
+	if (!rule) {
+		mvOsPrintf("%s: OOM\n", __func__);
+		return MV_FAIL;
+	}
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+	mvOsPrintf("adding a rule to l2fw hash in %s\n", __func__);
+#endif
+	rule->srcIP = srcIP;
+	rule->dstIP = dstIP;
+	rule->port = port;
+
+	rule->next = l2fw_hash[hash];
+	l2fw_hash[hash] = rule;
+	numHashEntries++;
+	return MV_OK;
+}
+
+
+#ifdef CONFIG_MV_INCLUDE_XOR
+static void dump_xor(void)
+{
+	mvOsPrintf(" CHANNEL_ARBITER_REG %08x\n",
+		MV_REG_READ(XOR_CHANNEL_ARBITER_REG(1)));
+	mvOsPrintf(" CONFIG_REG          %08x\n",
+		MV_REG_READ(XOR_CONFIG_REG(1, XOR_CHAN(0))));
+	mvOsPrintf(" ACTIVATION_REG      %08x\n",
+		MV_REG_READ(XOR_ACTIVATION_REG(1, XOR_CHAN(0))));
+	mvOsPrintf(" CAUSE_REG           %08x\n",
+		MV_REG_READ(XOR_CAUSE_REG(1)));
+	mvOsPrintf(" MASK_REG            %08x\n",
+		MV_REG_READ(XOR_MASK_REG(1)));
+	mvOsPrintf(" ERROR_CAUSE_REG     %08x\n",
+		MV_REG_READ(XOR_ERROR_CAUSE_REG(1)));
+	mvOsPrintf(" ERROR_ADDR_REG      %08x\n",
+		MV_REG_READ(XOR_ERROR_ADDR_REG(1)));
+	mvOsPrintf(" NEXT_DESC_PTR_REG   %08x\n",
+		MV_REG_READ(XOR_NEXT_DESC_PTR_REG(1, XOR_CHAN(0))));
+	mvOsPrintf(" CURR_DESC_PTR_REG   %08x\n",
+		MV_REG_READ(XOR_CURR_DESC_PTR_REG(1, XOR_CHAN(0))));
+	mvOsPrintf(" BYTE_COUNT_REG      %08x\n\n",
+		MV_REG_READ(XOR_BYTE_COUNT_REG(1, XOR_CHAN(0))));
+	mvOsPrintf("  %08x\n\n", XOR_WINDOW_CTRL_REG(1, XOR_CHAN(0))) ;
+		mvOsPrintf(" XOR_WINDOW_CTRL_REG      %08x\n\n",
+		MV_REG_READ(XOR_WINDOW_CTRL_REG(1, XOR_CHAN(0)))) ;
+}
+#endif
+
+
+static int mv_eth_poll_l2fw(struct napi_struct *napi, int budget)
+{
+	int rx_done = 0;
+	MV_U32 causeRxTx;
+	struct napi_group_ctrl *napi_group;
+	struct eth_port *pp = MV_ETH_PRIV(napi->dev);
+	int cpu = smp_processor_id();
+
+	STAT_INFO(pp->stats.poll[cpu]++);
+
+	/* Read cause register */
+	causeRxTx = mvPp2GbeIsrCauseRxTxGet(pp->port);
+	if (causeRxTx & MV_PP2_CAUSE_MISC_SUM_MASK) {
+		if (causeRxTx & MV_PP2_CAUSE_FCS_ERR_MASK)
+			printk(KERN_ERR "%s: FCS error\n", __func__);
+
+		if (causeRxTx & MV_PP2_CAUSE_RX_FIFO_OVERRUN_MASK)
+			printk(KERN_ERR "%s: RX fifo overrun error\n", __func__);
+
+		if (causeRxTx & MV_PP2_CAUSE_TX_FIFO_UNDERRUN_MASK)
+			printk(KERN_ERR "%s: TX fifo underrun error\n", __func__);
+
+		if (causeRxTx & MV_PP2_CAUSE_MISC_SUM_MASK) {
+			printk(KERN_ERR "%s: misc event\n", __func__);
+			MV_REG_WRITE(MV_PP2_ISR_MISC_CAUSE_REG, 0);
+		}
+
+		causeRxTx &= ~MV_PP2_CAUSE_MISC_SUM_MASK;
+		MV_REG_WRITE(MV_PP2_ISR_RX_TX_CAUSE_REG(MV_PPV2_PORT_PHYS(pp->port)), causeRxTx);
+	}
+	napi_group = pp->cpu_config[smp_processor_id()]->napi_group;
+	causeRxTx |= napi_group->cause_rx_tx;
+
+#ifdef CONFIG_MV_ETH_TXDONE_ISR
+
+	/* TODO check this mode */
+
+	if (mvPp2GbeIsrCauseTxDoneIsSet(pp->port, causeRxTx)) {
+		int tx_todo = 0, cause_tx_done;
+
+		/* TX_DONE process */
+		cause_tx_done = mvPp2GbeIsrCauseTxDoneOffset(pp->port, causeRxTx);
+		if (MV_PON_PORT(pp->port)) {
+			mv_eth_tx_done_pon(pp, &tx_todo);
+			printk(KERN_ERR "enter to mv_eth_tx_done_pon\n", __func__);
+		} else
+			mv_eth_tx_done_gbe(pp, cause_tx_done, &tx_todo);
+	}
+#endif /* CONFIG_MV_ETH_TXDONE_ISR */
+	if (MV_PON_PORT(pp->port))
+		causeRxTx &= ~MV_PP2_PON_CAUSE_TXP_OCCUP_DESC_ALL_MASK;
+	else
+		causeRxTx &= ~MV_PP2_CAUSE_TXQ_OCCUP_DESC_ALL_MASK;
+
+	while ((causeRxTx != 0) && (budget > 0)) {
+		int count, rx_queue;
+
+		rx_queue = mv_eth_rx_policy(causeRxTx);
+		if (rx_queue == -1)
+			break;
+
+		count = mv_eth_l2fw_rx(pp, budget, rx_queue);
+		rx_done += count;
+		budget -= count;
+		if (budget > 0)
+			causeRxTx &= ~((1 << rx_queue) << MV_PP2_CAUSE_RXQ_OCCUP_DESC_OFFS);
+	}
+
+	STAT_DIST((rx_done < pp->dist_stats.rx_dist_size) ? pp->dist_stats.rx_dist[rx_done]++ : 0);
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->dbg_flags & MV_ETH_F_DBG_POLL) {
+		printk(KERN_ERR "%s  EXIT: port=%d, cpu=%d, budget=%d, rx_done=%d\n",
+			__func__, pp->port, cpu, budget, rx_done);
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+	if (budget > 0) {
+		unsigned long flags;
+
+		causeRxTx = 0;
+
+		napi_complete(napi);
+
+		STAT_INFO(pp->stats.poll_exit[smp_processor_id()]++);
+
+		local_irq_save(flags);
+		/* Enable interrupts for all cpus belong to this group */
+		mvPp2GbeCpuInterruptsEnable(pp->port, napi_group->cpu_mask);
+		local_irq_restore(flags);
+	}
+	napi_group->cause_rx_tx = causeRxTx;
+	return rx_done;
+}
+
+
+void mv_eth_set_l2fw(struct eth_port_l2fw *ppl2fw, int cmd, int rx_port, int tx_port)
+{
+	struct eth_port *pp;
+	struct net_device *dev;
+	struct napi_group_ctrl *napi_group;
+	int group;
+
+/*
+	for multiBuffer validation
+	mvGmacMaxRxSizeSet(rx_port, 9000);
+*/
+
+	if (cmd == CMD_L2FW_CESA) {
+		mvOsPrintf("Invalid command (%d) - Ipsec is not defined (%s)\n", cmd, __func__);
+		return;
+	}
+
+	pp = mv_eth_ports[rx_port];
+
+	if (!pp) {
+		mvOsPrintf("pp is NULL in setting L2FW (%s)\n", __func__);
+		return;
+	}
+
+	dev = pp->dev;
+	if (dev == NULL) {
+		mvOsPrintf("device is NULL in setting L2FW (%s)\n", __func__);
+		return;
+	}
+	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
+		mvOsPrintf("Device is down for port=%d ; MV_ETH_F_STARTED_BIT is not set in %s\n", rx_port, __func__);
+		mvOsPrintf("Cannot set to L2FW mode in %s\n", __func__);
+		return;
+	}
+
+	if (cmd == ppl2fw->cmd) {
+		ppl2fw->txPort = tx_port;
+		return;
+	}
+
+	if ((cmd != CMD_L2FW_DISABLE) && (ppl2fw->cmd != CMD_L2FW_DISABLE) && (ppl2fw->cmd != CMD_L2FW_LAST)) {
+		ppl2fw->txPort = tx_port;
+		ppl2fw->cmd	= cmd;
+		return;
+	}
+
+	ppl2fw->txPort = tx_port;
+	ppl2fw->cmd	= cmd;
+
+
+	for (group = 0; group < 1/*MV_ETH_MAX_NAPI_GROUPS*/; group++) {
+		napi_group = pp->napi_group[group];
+		if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
+			napi_disable(napi_group->napi);
+
+		netif_napi_del(napi_group->napi);
+
+		if (cmd == CMD_L2FW_DISABLE)
+			netif_napi_add(dev, napi_group->napi, mv_eth_poll, pp->weight);
+		else
+			netif_napi_add(dev, napi_group->napi, mv_eth_poll_l2fw, pp->weight);
+
+		if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
+			napi_enable(napi_group->napi);
+	}
+
+}
+
+static inline struct eth_pbuf *l2fw_swap_mac(struct eth_pbuf *pRxPktInfo)
+{
+	MV_U16 *pSrc;
+	int i;
+	MV_U16 swap;
+	pSrc = (MV_U16 *)(pRxPktInfo->pBuf + pRxPktInfo->offset + MV_ETH_MH_SIZE);
+
+	for (i = 0; i < 3; i++) {
+		swap = pSrc[i];
+		pSrc[i] = pSrc[i+3];
+		pSrc[i+3] = swap;
+		}
+
+	return  pRxPktInfo;
+}
+
+static inline void l2fw_copy_mac(struct eth_pbuf *pRxPktInfo,
+					 struct eth_pbuf *pTxPktInfo)
+	{
+	/* copy 30 bytes (start after MH header) */
+	/* 12 for SA + DA */
+	/* 18 for the rest */
+	MV_U16 *pSrc;
+	MV_U16 *pDst;
+	int i;
+	pSrc = (MV_U16 *)(pRxPktInfo->pBuf + pRxPktInfo->offset + MV_ETH_MH_SIZE);
+	pDst = (MV_U16 *)(pTxPktInfo->pBuf + pTxPktInfo->offset + MV_ETH_MH_SIZE);
+
+	/* swap mac SA and DA */
+	for (i = 0; i < 3; i++) {
+		pDst[i]   = pSrc[i+3];
+		pDst[i+3] = pSrc[i];
+		}
+	for (i = 6; i < 15; i++)
+		pDst[i] = pSrc[i];
+	}
+
+static inline void l2fw_copy_and_swap_mac(struct eth_pbuf *pRxPktInfo, struct eth_pbuf *pTxPktInfo)
+{
+	MV_U16 *pSrc;
+	MV_U16 *pDst;
+	int i;
+
+	pSrc = (MV_U16 *)(pRxPktInfo->pBuf +  pRxPktInfo->offset + MV_ETH_MH_SIZE);
+	pDst = (MV_U16 *)(pTxPktInfo->pBuf +  pTxPktInfo->offset + MV_ETH_MH_SIZE);
+	for (i = 0; i < 3; i++) {
+		pDst[i]   = pSrc[i+3];
+		pDst[i+3] = pSrc[i];
+		}
+}
+
+static inline
+struct eth_pbuf *eth_l2fw_copy_packet_withOutXor(struct eth_pbuf *pRxPktInfo)
+{
+	MV_U8 *pSrc;
+	MV_U8 *pDst;
+	struct bm_pool *pool;
+	struct eth_pbuf *pTxPktInfo;
+
+	mvOsCacheInvalidate(NULL, pRxPktInfo->pBuf + pRxPktInfo->offset,
+						pRxPktInfo->bytes);
+
+	pool = &mv_eth_pool[pRxPktInfo->pool];
+	pTxPktInfo = mv_eth_pool_get(pool);
+	if (pTxPktInfo == NULL) {
+		mvOsPrintf("pTxPktInfo == NULL in %s\n", __func__);
+		return NULL;
+		}
+	pSrc = pRxPktInfo->pBuf +  pRxPktInfo->offset + MV_ETH_MH_SIZE;
+	pDst = pTxPktInfo->pBuf +  pTxPktInfo->offset + MV_ETH_MH_SIZE;
+
+	memcpy(pDst+12, pSrc+12, pRxPktInfo->bytes-12);
+	l2fw_copy_and_swap_mac(pRxPktInfo, pTxPktInfo);
+	pTxPktInfo->bytes = pRxPktInfo->bytes;
+	mvOsCacheFlush(NULL, pTxPktInfo->pBuf + pTxPktInfo->offset, pTxPktInfo->bytes);
+
+	return pTxPktInfo;
+}
+#ifdef CONFIG_MV_INCLUDE_XOR
+static inline
+struct eth_pbuf *eth_l2fw_copy_packet_withXor(struct eth_pbuf *pRxPktInfo)
+{
+	struct bm_pool *pool;
+	struct eth_pbuf *pTxPktInfo;
+
+	pool = &mv_eth_pool[pRxPktInfo->pool];
+	pTxPktInfo = mv_eth_pool_get(pool);
+	if (pTxPktInfo == NULL) {
+		mvOsPrintf("pTxPktInfo == NULL in %s\n", __func__);
+		return NULL;
+		}
+
+	/* sync between giga and XOR to avoid errors (like checksum errors in TX)
+	   when working with IOCC */
+
+	mvOsCacheIoSync();
+
+	eth_xor_desc->srcAdd0    = pRxPktInfo->physAddr + pRxPktInfo->offset + MV_ETH_MH_SIZE + 30;
+	eth_xor_desc->phyDestAdd = pTxPktInfo->physAddr + pTxPktInfo->offset + MV_ETH_MH_SIZE + 30;
+
+	eth_xor_desc->byteCnt    = pRxPktInfo->bytes - 30;
+
+	eth_xor_desc->phyNextDescPtr = 0;
+	eth_xor_desc->status         = BIT31;
+	/* we had changed only the first part of eth_xor_desc, so flush only one
+	 line of cache */
+	mvOsCacheLineFlush(NULL, eth_xor_desc);
+	MV_REG_WRITE(XOR_NEXT_DESC_PTR_REG(1, XOR_CHAN(0)), eth_xor_desc_phys_addr);
+
+	MV_REG_WRITE(XOR_ACTIVATION_REG(1, XOR_CHAN(0)), XEXACTR_XESTART_MASK);
+
+	mvOsCacheLineInv(NULL, pRxPktInfo->pBuf + pRxPktInfo->offset);
+	l2fw_copy_mac(pRxPktInfo, pTxPktInfo);
+	mvOsCacheLineFlush(NULL, pTxPktInfo->pBuf + pTxPktInfo->offset);
+
+	/* Update TxPktInfo */
+	pTxPktInfo->bytes = pRxPktInfo->bytes;
+	return pTxPktInfo;
+}
+
+
+void setXorDesc(void)
+{
+	unsigned int mode;
+	eth_xor_desc = mvOsMalloc(sizeof(MV_XOR_DESC) + XEXDPR_DST_PTR_DMA_MASK + 32);
+	eth_xor_desc = (MV_XOR_DESC *)MV_ALIGN_UP((MV_U32)eth_xor_desc, XEXDPR_DST_PTR_DMA_MASK+1);
+	eth_xor_desc_phys_addr = mvOsIoVirtToPhys(NULL, eth_xor_desc);
+	mvSysXorInit();
+
+	mode = MV_REG_READ(XOR_CONFIG_REG(1, XOR_CHAN(0)));
+	mode &= ~XEXCR_OPERATION_MODE_MASK;
+	mode |= XEXCR_OPERATION_MODE_DMA;
+	MV_REG_WRITE(XOR_CONFIG_REG(1, XOR_CHAN(0)), mode);
+	MV_REG_WRITE(XOR_NEXT_DESC_PTR_REG(1, XOR_CHAN(0)), eth_xor_desc_phys_addr);
+	dump_xor();
+	/* TODO mask xor intterupts*/
+}
+
+
+static inline int xorReady(void)
+{
+	int timeout = 0;
+
+	while (!(MV_REG_READ(XOR_CAUSE_REG(1)) & XOR_CAUSE_DONE_MASK(XOR_CHAN(0)))) {
+		if (timeout > 0x100000) {
+			mvOsPrintf("XOR timeout\n");
+			return 0;
+			}
+		timeout++;
+	}
+
+	/* Clear int */
+	MV_REG_WRITE(XOR_CAUSE_REG(1), ~(XOR_CAUSE_DONE_MASK(XOR_CHAN(0))));
+
+	return 1;
+}
+
+void l2fw_xor(int rx_port, int threshold)
+{
+	int max_port = mvCtrlEthMaxPortGet() - 1;
+
+	if (rx_port > max_port) {
+		mvOsPrintf("Error: invalid rx port %d\n", rx_port);
+		return;
+	}
+
+	mvOsPrintf("setting port %d threshold to %d in %s\n", rx_port, threshold, __func__);
+	mv_eth_ports_l2fw[rx_port]->xorThreshold = threshold;
+}
+#endif /*CONFIG_MV_INCLUDE_XOR*/
+
+void l2fw(int cmd, int rx_port, int tx_port)
+{
+	struct eth_port_l2fw *ppl2fw;
+	int max_port = mvCtrlEthMaxPortGet() - 1;
+
+	ppl2fw = mv_eth_ports_l2fw[rx_port];
+
+	if ((cmd < CMD_L2FW_DISABLE) || (cmd > CMD_L2FW_LAST)) {
+		mvOsPrintf("Error: invalid command %d\n", cmd);
+		return;
+	}
+
+	if ((rx_port > max_port) || (rx_port < 0)) {
+		mvOsPrintf("Error: invalid rx port %d\n", rx_port);
+		return;
+	}
+
+	if ((tx_port > max_port) || (tx_port < 0)) {
+		mvOsPrintf("Error: invalid tx port %d\n", tx_port);
+		return;
+	}
+
+	mvOsPrintf("cmd=%d rx_port=%d tx_port=%d in %s\n", cmd, rx_port, tx_port, __func__);
+
+	mv_eth_set_l2fw(ppl2fw, cmd, rx_port, tx_port);
+}
+
+
+
+void l2fw_lookupEn(int rx_port, int enable)
+{
+	int max_port = mvCtrlEthMaxPortGet() - 1;
+
+	if (rx_port > max_port) {
+		mvOsPrintf("Error: invalid rx port %d\n", rx_port);
+		return;
+	}
+	mvOsPrintf("setting port %d lookup mode to %s\n", rx_port, (enable == 1) ? "enable" : "disable");
+	mv_eth_ports_l2fw[rx_port]->lookupEn = enable;
+}
+
+void l2fw_stats(void)
+{
+	int i;
+	int ports = mvCtrlEthMaxPortGet();
+
+	for (i = 0; i < ports; i++) {
+		mvOsPrintf("number of errors in port[%d]=%d\n", i, mv_eth_ports_l2fw[i]->statErr);
+		mvOsPrintf("number of drops  in port[%d]=%d\n", i, mv_eth_ports_l2fw[i]->statDrop);
+	}
+
+#ifdef CONFIG_MV_ETH_L2SEC
+	mv_l2sec_stats();
+#endif
+
+}
+
+static inline MV_STATUS mv_eth_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp, int withXor,
+									   struct pp2_rx_desc *rx_desc)
+{
+	struct pp2_tx_desc *tx_desc;
+	u32 tx_cmd = 0;
+	struct mv_eth_tx_spec *tx_spec_ptr = NULL;
+	struct tx_queue *txq_ctrl;
+	struct aggr_tx_queue *aggr_txq_ctrl = NULL;
+	struct txq_cpu_ctrl *txq_cpu_ptr;
+	int cpu = smp_processor_id(), frags = 1;
+	tx_spec_ptr = &pp->tx_spec;
+	tx_spec_ptr->txq = pp->cpu_config[cpu]->txq;
+	aggr_txq_ctrl = &aggr_txqs[cpu];
+
+	txq_ctrl = &pp->txq_ctrl[tx_spec_ptr->txp * CONFIG_MV_ETH_TXQ + tx_spec_ptr->txq];
+	txq_cpu_ptr = &(txq_ctrl->txq_cpu[cpu]);
+
+#ifdef CONFIG_MV_ETH_PP2_1
+	if ((!mv_eth_reserved_desc_num_proc(pp, tx_spec_ptr->txp, tx_spec_ptr->txq, frags)) ||
+		(!mv_eth_aggr_desc_num_check(aggr_txq_ctrl, frags))) {
+
+#else
+	if ((!mv_eth_phys_desc_num_check(txq_cpu_ptr, frags)) ||
+		(!mv_eth_aggr_desc_num_check(aggr_txq_ctrl, frags))) {
+#endif
+		frags = 0;
+		goto out;
+	}
+	/* Get next descriptor for tx, single buffer, so FIRST & LAST */
+	tx_desc = mvPp2AggrTxqNextDescGet(aggr_txq_ctrl->q);
+
+	if (tx_desc == NULL) {
+		pp->dev->stats.tx_dropped++;
+		return MV_DROPPED;
+		/* TODO wait until xor is ready */
+	}
+
+	/* check if buffer header is used */
+	if (rx_desc->status & PP2_RX_BUF_HDR_MASK)
+		tx_cmd |= PP2_TX_BUF_HDR_MASK | PP2_TX_DESC_PER_PKT;
+
+	if (tx_spec_ptr->flags & MV_ETH_TX_F_NO_PAD)
+		tx_cmd |= PP2_TX_PADDING_DISABLE_MASK;
+
+	/* buffers released by HW */
+	tx_cmd |= (pkt->pool << PP2_TX_POOL_INDEX_OFFS) | PP2_TX_BUF_RELEASE_MODE_MASK |
+			PP2_TX_F_DESC_MASK | PP2_TX_L_DESC_MASK | PP2_TX_L4_CSUM_NOT | PP2_TX_IP_CSUM_DISABLE_MASK;
+
+	tx_desc->command = tx_cmd;
+
+#ifdef CONFIG_MV_ETH_PP2_1
+	tx_desc->hwCmd[1] = (pkt->qset << PP2_TX_MOD_QSET_OFFS) | (pkt->grntd << PP2_TX_MOD_GRNTD_BIT);
+#endif
+
+	tx_desc->bufCookie = (MV_U32)pkt;
+
+	tx_desc->physTxq = MV_PPV2_TXQ_PHYS(pp->port, tx_spec_ptr->txp, tx_spec_ptr->txq);
+
+	txq_ctrl = &pp->txq_ctrl[tx_spec_ptr->txp * CONFIG_MV_ETH_TXQ + tx_spec_ptr->txq];
+
+	if (txq_ctrl == NULL) {
+		printk(KERN_ERR "%s: invalidate txp/txq (%d/%d)\n",
+			__func__, tx_spec_ptr->txp, tx_spec_ptr->txq);
+		pp->dev->stats.tx_dropped++;
+		return MV_DROPPED;
+	}
+
+	txq_cpu_ptr = &txq_ctrl->txq_cpu[cpu];
+
+	/* use txq_counter in txq_ctrl*/
+	if (txq_cpu_ptr->txq_count >= mv_ctrl_txdone)
+		mv_eth_txq_done(pp, txq_ctrl);
+
+	tx_desc->dataSize  = pkt->bytes;
+	tx_desc->bufPhysAddr = pkt->physAddr;
+	tx_desc->pktOffset = pkt->offset + MV_ETH_MH_SIZE;
+
+	mv_eth_shadow_push(txq_cpu_ptr, ((MV_ULONG) NULL));
+
+	mv_eth_tx_desc_flush(tx_desc);
+
+	/* TODO - XOR ready check */
+
+#ifdef CONFIG_MV_ETH_PP2_1
+	txq_cpu_ptr->reserved_num--;
+#endif
+	txq_cpu_ptr->txq_count++;
+	aggr_txq_ctrl->txq_count++;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+	if (pp->dbg_flags & MV_ETH_F_DBG_TX) {
+		printk(KERN_ERR "\n");
+		printk(KERN_ERR "%s - eth_l2fw_tx_%lu: cpu=%d, in_intr=0x%lx, port=%d, txp=%d, txq=%d\n",
+			pp->dev->name, pp->dev->stats.tx_packets, smp_processor_id(), in_interrupt(),
+			pp->port, tx_spec_ptr->txp, tx_spec_ptr->txq);
+		printk(KERN_ERR "\t pkt=%p, pBuf=%p, bytes=%d, physAddr=%lx\n",
+				pkt, pkt->pBuf, pkt->bytes, pkt->physAddr);
+		mv_eth_tx_desc_print(tx_desc);
+		mvDebugMemDump(pkt->pBuf + pkt->offset, 64, 1);
+	}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+	/* Enable transmit */
+	wmb();
+	mvPp2AggrTxqPendDescAdd(frags);
+
+	STAT_DBG(aggr_txq_ctrl->stats.txq_tx++);
+	STAT_DBG(txq_ctrl->stats.txq_tx++);
+	STAT_DBG(txq_ctrl->txq_cpu[cpu].stats.txq_tx++);
+
+	pp->dev->stats.tx_packets++;
+	pp->dev->stats.tx_bytes += pkt->bytes;
+
+out:
+#ifndef CONFIG_MV_ETH_TXDONE_ISR
+	if (txq_cpu_ptr->txq_count >= mv_ctrl_txdone)
+		mv_eth_txq_done(pp, txq_ctrl);
+#endif /* CONFIG_MV_ETH_STAT_DIST */
+
+	return NETDEV_TX_OK;
+}
+
+static inline void mv_eth_l2fw_pool_refill(struct eth_port *pp,
+				     struct eth_pbuf *pkt, struct bm_pool *pool, struct pp2_rx_desc *rx_desc)
+{
+
+	if ((rx_desc->status & PP2_RX_BUF_HDR_MASK) == MV_FALSE)
+		mv_eth_pool_refill(pkt, pool, rx_desc);
+	else
+		/* multiBuffer mode */
+		mv_eth_buff_hdr_rx(pp, rx_desc);
+}
+
+static inline int mv_eth_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
+{
+	struct eth_port  *new_pp;
+	struct l2fw_rule *rule;
+	MV_PP2_PHYS_RXQ_CTRL *rx_ctrl = pp->rxq_ctrl[rxq].q;
+	int rx_done, rx_filled;
+	u32 rx_status;
+	struct pp2_rx_desc *rx_desc;
+	struct eth_pbuf *pkt;
+	struct eth_pbuf *newpkt = NULL;
+	struct bm_pool *pool;
+	MV_STATUS status = MV_OK;
+	struct eth_port_l2fw *ppl2fw = mv_eth_ports_l2fw[pp->port];
+	MV_IP_HEADER *pIph = NULL;
+	MV_U8 *pData;
+	int ipOffset;
+	MV_BOOL withXor = MV_FALSE;
+
+	rx_done = mvPp2RxqBusyDescNumGet(pp->port, rxq);
+	mvOsCacheIoSync();
+
+
+	if ((rx_todo > rx_done) || (rx_todo < 0))
+		rx_todo = rx_done;
+
+	if (rx_todo == 0)
+		return 0;
+
+	rx_done = 0;
+	rx_filled = 0;
+
+	/* Fairness NAPI loop */
+	while (rx_done < rx_todo) {
+#ifdef CONFIG_MV_ETH_RX_DESC_PREFETCH
+		rx_desc = mv_eth_rx_prefetch(pp, rx_ctrl, rx_done, rx_todo);
+#else
+		rx_desc = mvPp2RxqNextDescGet(rx_ctrl);
+		mvOsCacheLineInv(NULL, rx_desc);
+		prefetch(rx_desc);
+#endif /* CONFIG_MV_ETH_RX_DESC_PREFETCH */
+
+		if (!rx_desc)
+			printk(KERN_INFO "rx_desc is NULL in %s\n", __func__);
+
+		rx_done++;
+		rx_filled++;
+
+		rx_status = rx_desc->status;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		/* check if buffer header is in used */
+		if (pp->dbg_flags & MV_ETH_F_DBG_BUFF_HDR)
+			if (rx_status & PP2_RX_BUF_HDR_MASK)
+				mv_eth_buff_hdr_rx_dump(pp, rx_desc);
+
+		/* print RX descriptor */
+		if (pp->dbg_flags & MV_ETH_F_DBG_RX)
+			mv_eth_rx_desc_print(rx_desc);
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+		pkt = (struct eth_pbuf *)rx_desc->bufCookie;
+
+		if (!pkt) {
+			printk(KERN_INFO "%s: pkt is NULL, rx_done=%d\n", __func__, rx_done);
+			return rx_done;
+		}
+
+		pool = &mv_eth_pool[pkt->pool];
+
+		if (rx_status & PP2_RX_ES_MASK) {
+			printk(KERN_ERR "giga #%d: bad rx status 0x%08x\n", pp->port, rx_status);
+			mv_eth_l2fw_pool_refill(pp, pkt, pool, rx_desc);
+			continue;
+		}
+#ifdef CONFIG_MV_ETH_PP2_1
+		pkt->qset = (rx_desc->bmQset & PP2_RX_BUFF_QSET_NUM_MASK) >> PP2_RX_BUFF_QSET_NUM_OFFS;
+		pkt->grntd = (rx_desc->bmQset & PP2_RX_BUFF_TYPE_MASK) >> PP2_RX_BUFF_TYPE_OFFS;
+#endif /*CONFIG_MV_ETH_PP2_1*/
+
+		pkt->bytes = rx_desc->dataSize - MV_ETH_MH_SIZE;
+
+#ifdef CONFIG_MV_ETH_DEBUG_CODE
+		if (pp->dbg_flags & MV_ETH_F_DBG_RX) {
+			printk(KERN_ERR "pkt=0x%p, pBuf=0x%p, ksize=%d offset = 0x%x\n",
+						 pkt, pkt->pBuf, ksize(pkt->pBuf), pkt->offset);
+
+			mvDebugMemDump(pkt->pBuf + pkt->offset, 64, 1);
+		}
+#endif /* CONFIG_MV_ETH_DEBUG_CODE */
+
+		pData = pkt->pBuf + pkt->offset;
+
+		ipOffset = (rx_status & PP2_RX_L3_OFFSET_MASK) >> PP2_RX_L3_OFFSET_OFFS;
+
+		pIph = (MV_IP_HEADER *)(pData + ipOffset);
+
+		if (pIph == NULL) {
+			printk(KERN_INFO "pIph==NULL in %s\n", __func__);
+			continue;
+		}
+#ifdef CONFIG_MV_ETH_L2FW_DEBUG
+		if (pIph) {
+			MV_U8 *srcIP, *dstIP;
+			srcIP = (MV_U8 *)&(pIph->srcIP);
+			dstIP = (MV_U8 *)&(pIph->dstIP);
+			printk(KERN_INFO "%u.%u.%u.%u->%u.%u.%u.%u in %s\n",
+					MV_IPQUAD(srcIP), MV_IPQUAD(dstIP), __func__);
+			printk(KERN_INFO "0x%x->0x%x in %s\n", pIph->srcIP, pIph->dstIP, __func__);
+		} else
+			printk(KERN_INFO "pIph is NULL in %s\n", __func__);
+#endif
+
+		if (ppl2fw->lookupEn) {
+			rule = l2fw_lookup(pIph->srcIP, pIph->dstIP);
+
+			new_pp = rule ? mv_eth_ports[rule->port] : mv_eth_ports[ppl2fw->txPort];
+
+		} else
+			new_pp  = mv_eth_ports[ppl2fw->txPort];
+
+		switch (ppl2fw->cmd) {
+		case CMD_L2FW_AS_IS:
+			status = mv_eth_l2fw_tx(pkt, new_pp, 0, rx_desc);
+			break;
+
+		case CMD_L2FW_SWAP_MAC:
+			mvOsCacheLineInv(NULL, pkt->pBuf + pkt->offset);
+			l2fw_swap_mac(pkt);
+			mvOsCacheLineFlush(NULL, pkt->pBuf + pkt->offset);
+			status = mv_eth_l2fw_tx(pkt, new_pp, 0, rx_desc);
+			break;
+
+		case CMD_L2FW_COPY_SWAP:
+			if (rx_status & PP2_RX_BUF_HDR_MASK) {
+				printk(KERN_INFO "%s: not support copy with multibuffer packets.\n", __func__);
+				status = MV_ERROR;
+				break;
+			}
+
+			if (pkt->bytes >= ppl2fw->xorThreshold) {
+				withXor = MV_TRUE;
+				printk(KERN_INFO "%s: xor is not supported\n", __func__);
+				/* newpkt = eth_l2fw_copy_packet_withXor(pkt); */
+			} else
+				newpkt = eth_l2fw_copy_packet_withOutXor(pkt);
+
+			if (newpkt) {
+				status = mv_eth_l2fw_tx(newpkt, new_pp, withXor, rx_desc);
+				/* we do not need the pkt */
+				mv_eth_pool_put(pool, pkt);
+				/*for refill function just in case that status != OK */
+				pkt = newpkt;
+			} else
+				status = MV_ERROR;
+			break;
+#ifdef CONFIG_MV_ETH_L2SEC
+		case CMD_L2FW_CESA:
+			if (rx_status & PP2_RX_BUF_HDR_MASK) {
+				printk(KERN_INFO "%s: not support cesa with multibuffer packets.\n", __func__);
+				status = MV_ERROR;
+				break;
+			}
+				status = mv_l2sec_handle_esp(pkt, rx_desc, new_pp, pp->port);
+			break;
+#endif
+
+		default:
+			printk(KERN_INFO "WARNING:%s invalid mode %d, rx port %d\n", __func__, ppl2fw->cmd, pp->port);
+			mv_eth_pool_refill(pkt, pool, rx_desc);
+		} /*switch*/
+
+		if (status == MV_OK) {
+			/* BM - no refill */
+			mvOsCacheLineInv(NULL, rx_desc);
+			continue;
+		}
+
+		/* status is not OK */
+		mv_eth_l2fw_pool_refill(pp, pkt, pool, rx_desc);
+
+		if (status == MV_DROPPED)
+			ppl2fw->statDrop++;
+
+		if (status == MV_ERROR)
+			ppl2fw->statErr++;
+
+	} /* of while */
+
+	/* Update RxQ management counters */
+	mvOsCacheIoSync();
+	mvPp2RxqDescNumUpdate(pp->port, rxq, rx_done, rx_filled);
+
+	return rx_done;
+}
+
+#ifdef CONFIG_MV_ETH_L2FW
+int __devinit mv_l2fw_init(void)
+{
+	int size, port;
+	MV_U32 bytes;
+	MV_U32 regVal;
+	mv_eth_ports_l2fw_num = mvCtrlEthMaxPortGet();
+	mvOsPrintf("in %s: mv_eth_ports_l2fw_num=%d\n", __func__, mv_eth_ports_l2fw_num);
+
+	size = mv_eth_ports_l2fw_num * sizeof(struct eth_port_l2fw *);
+	mv_eth_ports_l2fw = mvOsMalloc(size);
+	if (!mv_eth_ports_l2fw)
+		goto oom;
+	memset(mv_eth_ports_l2fw, 0, size);
+	for (port = 0; port < mv_eth_ports_l2fw_num; port++) {
+		mv_eth_ports_l2fw[port] =
+			mvOsMalloc(sizeof(struct eth_port_l2fw));
+		if (!mv_eth_ports_l2fw[port])
+			goto oom1;
+		mv_eth_ports_l2fw[port]->cmd    = CMD_L2FW_LAST/*CMD_L2FW_DISABLE*/;
+		mv_eth_ports_l2fw[port]->txPort = -1;
+		mv_eth_ports_l2fw[port]->lookupEn = 0;
+		mv_eth_ports_l2fw[port]->xorThreshold = XOR_THRESHOLD_DEF;
+		mv_eth_ports_l2fw[port]->statErr = 0;
+		mv_eth_ports_l2fw[port]->statDrop = 0;
+	}
+
+	bytes = sizeof(struct l2fw_rule *) * L2FW_HASH_SIZE;
+	l2fw_jhash_iv = mvOsRand();
+
+	l2fw_hash = (struct l2fw_rule **)mvOsMalloc(bytes);
+	if (l2fw_hash == NULL) {
+		mvOsPrintf("l2fw hash: not enough memory\n");
+		return MV_NO_RESOURCE;
+	}
+
+	mvOsMemset(l2fw_hash, 0, bytes);
+
+	mvOsPrintf("L2FW hash init %d entries, %d bytes\n", L2FW_HASH_SIZE, bytes);
+	regVal = 0;
+
+#ifdef CONFIG_MV_ETH_L2SEC
+	mv_l2sec_cesa_init();
+#endif
+
+#ifdef CONFIG_MV_INCLUDE_XOR
+	setXorDesc();
+#endif
+	return 0;
+oom:
+	mvOsPrintf("%s: out of memory in L2FW initialization\n", __func__);
+oom1:
+	mvOsFree(mv_eth_ports_l2fw);
+	return -ENOMEM;
+
+}
+#endif
+
+module_init(mv_l2fw_init);
+
+MODULE_AUTHOR("Rami Rosen");
+MODULE_DESCRIPTION("l2fw module");
+MODULE_LICENSE("GPL");
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h
new file mode 100644
index 0000000..5f3ae42
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/l2fw/mv_eth_l2fw.h
@@ -0,0 +1,79 @@
+/*******************************************************************************
+Copyright (C) Marvell International Ltd. and its affiliates
+
+This software file (the "File") is owned and distributed by Marvell
+International Ltd. and/or its affiliates ("Marvell") under the following
+alternative licensing terms.  Once you have made an election to distribute the
+File under one of the following license alternatives, please (i) delete this
+introductory statement regarding license alternatives, (ii) delete the two
+license alternatives that you have not elected to use and (iii) preserve the
+Marvell copyright notice above.
+
+
+********************************************************************************
+Marvell GPL License Option
+
+If you received this File from Marvell, you may opt to use, redistribute and/or
+modify this File in accordance with the terms and conditions of the General
+Public License Version 2, June 1991 (the "GPL License"), a copy of which is
+available along with the File in the license.txt file or by writing to the Free
+Software Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 or
+on the worldwide web at http://www.gnu.org/licenses/gpl.txt.
+
+THE FILE IS DISTRIBUTED AS-IS, WITHOUT WARRANTY OF ANY KIND, AND THE IMPLIED
+WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE ARE EXPRESSLY
+DISCLAIMED.  The GPL License provides additional details about this warranty
+disclaimer.
+*******************************************************************************/
+
+#ifndef L2FW_MV_ETH_L2FW_H
+#define L2FW_MV_ETH_L2FW_H
+
+#include "mvOs.h"
+#include "mv_pp2/net_dev/mv_netdev.h"
+
+#define	L2FW_HASH_SIZE   (1 << 17)
+#define	L2FW_HASH_MASK   (L2FW_HASH_SIZE - 1)
+
+/* L2fw defines */
+#define CMD_L2FW_DISABLE			0
+#define CMD_L2FW_AS_IS				1
+#define CMD_L2FW_SWAP_MAC			2
+#define CMD_L2FW_COPY_SWAP			3
+#define CMD_L2FW_CESA				4
+#define CMD_L2FW_LAST				5
+
+#define XOR_CAUSE_DONE_MASK(chan) ((BIT0|BIT1) << (chan * 16))
+#define XOR_THRESHOLD_DEF			2000;
+
+extern spinlock_t l2sec_lock;
+extern struct aggr_tx_queue *aggr_txqs;
+
+struct eth_port_l2fw {
+	int cmd;
+	int lookupEn;
+	int xorThreshold;
+	int txPort;
+	/* stats */
+	int statErr;
+	int statDrop;
+};
+
+struct l2fw_rule {
+	MV_U32 srcIP;
+	MV_U32 dstIP;
+	MV_U8 port;
+	struct l2fw_rule *next;
+};
+
+MV_STATUS l2fw_add(MV_U32 srcIP, MV_U32 dstIP, int port);
+
+void l2fw(int cmd, int rx_port, int tx_port);
+void l2fw_xor(int rx_port, int threshold);
+void l2fw_lookupEn(int rx_port, int enable);
+void l2fw_flush(void);
+void l2fw_rules_dump(void);
+void l2fw_ports_dump(void);
+void l2fw_stats(void);
+
+#endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h
index 1a79560..1920c2b 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_eth_sysfs.h
@@ -90,4 +90,9 @@ int mv_pp2_gbe_pme_sysfs_exit(struct kobject *gbe_kobj);
 int mv_pp2_dbg_sysfs_init(struct kobject *pp2_kobj);
 int mv_pp2_dbg_sysfs_exit(struct kobject *pp2_kobj);
 
+#ifdef CONFIG_MV_ETH_L2FW
+int mv_pp2_l2fw_sysfs_init(struct kobject *pp2_kobj);
+int mv_pp2_l2fw_sysfs_exit(struct kobject *pp2_kobj);
+#endif
+
 #endif /* __mv_eth_sysfs_h__ */
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
index 96c069a..1251b39 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.c
@@ -1427,7 +1427,7 @@ inline struct eth_pbuf *mv_eth_pool_get(struct bm_pool *pool)
 }
 
 /* Reuse pkt if possible, allocate new skb and move BM pool or RXQ ring */
-inline int mv_eth_refill(struct eth_port *pp, int rxq,
+inline int mv_eth_refill(struct eth_port *pp,
 				struct eth_pbuf *pkt, struct bm_pool *pool, struct pp2_rx_desc *rx_desc)
 {
 	if (pkt == NULL) {
@@ -1445,7 +1445,7 @@ inline int mv_eth_refill(struct eth_port *pp, int rxq,
 			return 1;
 		}
 	}
-	mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+	mv_eth_pool_refill(pkt, pool, rx_desc);
 
 	return 0;
 }
@@ -1509,15 +1509,23 @@ inline struct pp2_rx_desc *mv_eth_rx_prefetch(struct eth_port *pp, MV_PP2_PHYS_R
 }
 #endif /* CONFIG_MV_ETH_RX_DESC_PREFETCH */
 
-static inline void mv_eth_buff_hdr_rx(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
+
+void mv_eth_buff_hdr_rx(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
 {
 	u32 rx_status = rx_desc->status;
 	int mc_id, pool_id;
 	PP2_BUFF_HDR *buff_hdr;
 	MV_U32 buff_phys_addr, buff_virt_addr, buff_phys_addr_next, buff_virt_addr_next;
+
 #ifdef CONFIG_MV_ETH_DEBUG_CODE
 	int count = 0;
 #endif
+#ifdef CONFIG_MV_ETH_PP2_1
+	int qset, is_grntd;
+
+	qset = (rx_desc->bmQset & PP2_RX_BUFF_QSET_NUM_MASK) >> PP2_RX_BUFF_QSET_NUM_OFFS;
+	is_grntd = (rx_desc->bmQset & PP2_RX_BUFF_TYPE_MASK) >> PP2_RX_BUFF_TYPE_OFFS;
+#endif
 
 	pool_id = (rx_status & PP2_RX_BM_POOL_ALL_MASK) >> PP2_RX_BM_POOL_ID_OFFS;
 	buff_phys_addr = rx_desc->bufPhysAddr;
@@ -1542,15 +1550,55 @@ static inline void mv_eth_buff_hdr_rx(struct eth_port *pp, struct pp2_rx_desc *r
 		buff_virt_addr_next = buff_hdr->nextBuffVirtAddr;
 
 		/* release buffer */
-		mvBmPoolMcPut(pool_id, buff_phys_addr, buff_virt_addr, mc_id, 0);
+#ifdef CONFIG_MV_ETH_PP2_1
+		mvBmPoolQsetMcPut(pool_id, buff_phys_addr, buff_virt_addr, qset, is_grntd, mc_id, 0);
 
+		/* Qset number and buffer type of next buffer */
+		qset = (buff_hdr->bmQset & PP2_BUFF_HDR_BM_QSET_NUM_MASK) >> PP2_BUFF_HDR_BM_QSET_NUM_OFFS;
+		is_grntd = (buff_hdr->bmQset & PP2_BUFF_HDR_BM_QSET_TYPE_MASK) >> PP2_BUFF_HDR_BM_QSET_TYPE_OFFS;
+#else
+		mvBmPoolMcPut(pool_id, buff_phys_addr, buff_virt_addr, mc_id, 0);
+#endif
 		buff_phys_addr = buff_phys_addr_next;
 		buff_virt_addr = buff_virt_addr_next;
+
+		STAT_DBG((&mv_eth_pool[pool_id])->stats.bm_put++);
+
+	} while (!PP2_BUFF_HDR_INFO_IS_LAST(buff_hdr->info));
+
+	STAT_DBG(pp->stats.rx_drop_sw++);
+}
+
+void mv_eth_buff_hdr_rx_dump(struct eth_port *pp, struct pp2_rx_desc *rx_desc)
+{
+	int mc_id;
+	PP2_BUFF_HDR *buff_hdr;
+	MV_U32 buff_phys_addr, buff_virt_addr;
+
+	int count = 0;
+
+	buff_phys_addr = rx_desc->bufPhysAddr;
+	buff_virt_addr = rx_desc->bufCookie;
+		printk(KERN_ERR "------------------------\n");
+	do {
+		printk(KERN_ERR "buff_virt_addr = %x\n", buff_virt_addr);
+		buff_hdr = (PP2_BUFF_HDR *)(((struct eth_pbuf *)buff_virt_addr)->pBuf);
+
+		printk(KERN_ERR "buff_hdr = %p\n", buff_hdr);
+		mc_id = PP2_BUFF_HDR_INFO_MC_ID(buff_hdr->info);
+
+		printk(KERN_ERR "buff header #%d:\n", ++count);
+		mvDebugMemDump(buff_hdr, buff_hdr->byteCount, 1);
+
+		printk(KERN_ERR "byte count = %d   MC ID = %d   last = %d\n",
+			buff_hdr->byteCount, mc_id,
+			PP2_BUFF_HDR_INFO_IS_LAST(buff_hdr->info));
+
+		buff_phys_addr = buff_hdr->nextBuffPhysAddr;
+		buff_virt_addr  = buff_hdr->nextBuffVirtAddr;
+
 	} while (!PP2_BUFF_HDR_INFO_IS_LAST(buff_hdr->info));
 
-#ifdef CONFIG_MV_ETH_STAT_DBG
-	pp->stats.rx_drop_sw++;
-#endif
 }
 
 static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct napi_struct *napi)
@@ -1617,7 +1665,7 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 		if (rx_status & PP2_RX_ES_MASK) {
 			mv_eth_rx_error(pp, rx_desc);
 
-			mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+			mv_eth_pool_refill(pkt, pool, rx_desc);
 			continue;
 		}
 
@@ -1649,7 +1697,7 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 				STAT_INFO(pp->stats.rx_special++);
 
 				/* Refill processing */
-				err = mv_eth_refill(pp, rxq, pkt, pool, rx_desc);
+				err = mv_eth_refill(pp, pkt, pool, rx_desc);
 				if (err) {
 					printk(KERN_ERR "Linux processing - Can't refill\n");
 					pp->rxq_ctrl[rxq].missed++;
@@ -1694,7 +1742,7 @@ static inline int mv_eth_rx(struct eth_port *pp, int rx_todo, int rxq, struct na
 		}
 
 		/* Refill processing: */
-		err = mv_eth_refill(pp, rxq, pkt, pool, rx_desc);
+		err = mv_eth_refill(pp, pkt, pool, rx_desc);
 		if (err) {
 			printk(KERN_ERR "Linux processing - Can't refill\n");
 			pp->rxq_ctrl[rxq].missed++;
@@ -2196,7 +2244,7 @@ static void mv_eth_rxq_drop_pkts(struct eth_port *pp, int rxq)
 
 		pkt = (struct eth_pbuf *)rx_desc->bufCookie;
 		pool = &mv_eth_pool[pkt->pool];
-		mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+		mv_eth_pool_refill(pkt, pool, rx_desc);
 	}
 	if (rx_done) {
 		mvOsCacheIoSync();
@@ -3289,6 +3337,9 @@ static void mv_eth_sysfs_exit(void)
 		printk(KERN_ERR"%s: cannot find pp2 device\n", __func__);
 		return;
 	}
+#ifdef CONFIG_MV_ETH_L2FW
+	mv_pp2_l2fw_sysfs_exit(&pd->kobj);
+#endif
 	mv_pp2_pme_sysfs_exit(&pd->kobj);
 	mv_pp2_plcr_sysfs_exit(&pd->kobj);
 	mv_pp2_mc_sysfs_exit(&pd->kobj);
@@ -3331,6 +3382,10 @@ static int mv_eth_sysfs_init(void)
 	mv_pp2_plcr_sysfs_init(&pd->kobj);
 	mv_pp2_pme_sysfs_init(&pd->kobj);
 	mv_pp2_dbg_sysfs_init(&pd->kobj);
+#ifdef CONFIG_MV_ETH_L2FW
+	mv_pp2_l2fw_sysfs_init(&pd->kobj);
+#endif
+
 
 	return 0;
 }
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
index 73739c4..5015799 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_pp2/net_dev/mv_netdev.h
@@ -208,6 +208,8 @@ struct port_stats {
 #endif /* CONFIG_MV_ETH_STAT_DBG */
 };
 
+#define MV_ETH_TX_DESC_ALIGN		0x1f
+
 /* Used for define type of data saved in shadow: SKB or eth_pbuf or nothing */
 #define MV_ETH_SHADOW_SKB		0x1
 #define MV_ETH_SHADOW_EXT		0x2
@@ -723,8 +725,7 @@ static inline int mv_eth_pool_put(struct bm_pool *pool, struct eth_pbuf *pkt)
 
 
 /* Pass pkt to BM Pool or RXQ ring */
-static inline void mv_eth_rxq_refill(struct eth_port *pp, int rxq,
-				     struct eth_pbuf *pkt, struct bm_pool *pool, struct pp2_rx_desc *rx_desc)
+static inline void mv_eth_pool_refill(struct eth_pbuf *pkt, struct bm_pool *pool, struct pp2_rx_desc *rx_desc)
 {
 	unsigned long flags = 0;
 
@@ -827,6 +828,8 @@ void        mv_eth_pkt_print(struct eth_pbuf *pkt);
 void        mv_eth_rx_desc_print(struct pp2_rx_desc *desc);
 void        mv_eth_skb_print(struct sk_buff *skb);
 void        mv_eth_link_status_print(int port);
+void        mv_eth_buff_hdr_rx_dump(struct eth_port *pp, struct pp2_rx_desc *rx_desc);
+void        mv_eth_buff_hdr_rx(struct eth_port *pp, struct pp2_rx_desc *rx_desc);
 
 /* External MAC support (i.e. PON) */
 /* callback functions to be called by netdev (implemented in external MAC module) */
@@ -870,8 +873,8 @@ int  mv_eth_poll(struct napi_struct *napi, int budget);
 void mv_eth_link_event(struct eth_port *pp, int print);
 
 int mv_eth_rx_policy(u32 cause);
-int mv_eth_refill(struct eth_port *pp, int rxq,
-				struct eth_pbuf *pkt, struct bm_pool *pool, struct pp2_rx_desc *rx_desc);
+int mv_eth_refill(struct eth_port *pp, struct eth_pbuf *pkt,
+			struct bm_pool *pool, struct pp2_rx_desc *rx_desc);
 u32 mv_eth_txq_done(struct eth_port *pp, struct tx_queue *txq_ctrl);
 u32 mv_eth_tx_done_gbe(struct eth_port *pp, u32 cause_tx_done, int *tx_todo);
 u32 mv_eth_tx_done_pon(struct eth_port *pp, int *tx_todo);
diff --git a/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2GbeRegs.h b/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2GbeRegs.h
index f477894..964f5d8 100644
--- a/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2GbeRegs.h
+++ b/arch/arm/plat-armada/mv_hal/pp2/gbe/mvPp2GbeRegs.h
@@ -651,6 +651,9 @@ typedef struct pp2_tx_desc {
 #define PP2_TX_IP_CSUM_DISABLE_BIT		15
 #define PP2_TX_IP_CSUM_DISABLE_MASK		(1 << PP2_TX_IP_CSUM_DISABLE_BIT)
 
+#define PP2_TX_POOL_INDEX_OFFS			16
+#define PP2_TX_POOL_INDEX_MASK			(7 << PP2_TX_POOL_INDEX_OFFS)
+
 #define PP2_TX_PADDING_DISABLE_BIT		23
 #define PP2_TX_PADDING_DISABLE_MASK		(1 << PP2_TX_PADDING_DISABLE_BIT)
 
@@ -668,6 +671,14 @@ typedef struct pp2_tx_desc {
 #define PP2_TX_F_DESC_BIT			29
 #define PP2_TX_F_DESC_MASK			(1 << PP2_TX_F_DESC_BIT)
 
+#define PP2_TX_DESC_FRMT_BIT			30
+#define PP2_TX_DESC_FRMT_MASK			(1 << PP2_TX_DESC_FRMT_BIT)
+#define PP2_TX_DESC_PER_BUF			(0 << PP2_TX_DESC_FRMT_BIT)
+#define PP2_TX_DESC_PER_PKT			(1 << PP2_TX_DESC_FRMT_BIT)
+
+#define PP2_TX_BUF_HDR_BIT			31
+#define PP2_TX_BUF_HDR_MASK			(1 << PP2_TX_BUF_HDR_BIT)
+
 /* Bits of "hwCmd[0]" field - offset 0x10 */
 #define PP2_TX_GEMPID_OFFS                      0
 #define PP2_TX_GEMPID_BITS                      12
-- 
1.7.5.4

